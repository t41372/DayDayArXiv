{
  "date": "2025-02-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-28 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态学习、医疗应用和强化学习等领域，亮点包括多篇 LLM 增强代理模型（如 Agentic AI）和高效训练框架（如 ByteScale），以及知名学者（如 Bo Li 和 Kush R. Varshney）参与的创新工作，这些论文展示了 AI 在复杂任务中的潜力。\n\n以下是今日论文的精选摘要，我优先讨论了重要、创新性和话题度高的文章（如 LLM 相关和医疗应用），并将相关主题归类讨论。对于其他较常规的论文，我会简要掠过，以控制篇幅。每个条目包括论文标题（中文 + 英文）、核心学术术语，以及主要贡献和发现。\n\n### LLM 和 AI 代理相关\n- **Human-AI Collaboration: Trade-offs Between Performance and Preferences**（人类-AI 协作：性能与偏好之间的权衡）：这篇论文探讨了协作 AI 代理的设计，核心贡献是通过贝叶斯模型分析了人类偏好对团队性能的影响，发现更注重人类输入的代理能提升可喜欢性而不降低性能。\n- **Agentic AI Needs a Systems Theory**（代理 AI 需要系统理论，作者包括 Kush R. Varshney）：论文强调了代理 AI 的系统级视角，核心发现是通过系统理论理解 AI 交互环境，能缓解风险并提升认知能力，这对 AI 开发有重要启示。\n- **ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs**（ByteScale：高效扩展 LLM 训练，支持 2048K 上下文长度并使用超过 12,000 个 GPU）：主要贡献是提出一种动态网格策略，显著减少训练中的通信冗余，实现 7.89 倍速度提升。\n- **FANformer: Improving Large Language Models Through Effective Periodicity Modeling**（FANformer：通过有效周期建模提升大型语言模型）：论文引入 Fourier 分析网络改进 Transformer，核心发现是提升了 LLM 的学习效率和规则推理能力。\n- **Steering Large Language Model Activations in Sparse Spaces**（在稀疏空间中引导大型语言模型激活）：这篇工作使用稀疏自编码器进行行为调控，贡献在于实现更精细的 LLM 行为控制，提高了模型的可解释性。\n\n其他 LLM 相关论文（如 Triple Phase Transitions）则快速掠过：它们探讨了 LLM 训练动态，但影响力较小，仅显示了三阶段学习过程。\n\n### 医疗和生物应用\n- **Foundation-Model-Boosted Multimodal Learning for fMRI-based Neuropathic Pain Drug Response Prediction**（基于基础模型的多模态学习用于 fMRI 神经病理性疼痛药物反应预测）：核心贡献是提出 FMM-TC 框架，利用多模态 fMRI 数据提升药物反应预测准确性，发现基础模型能改善患者分层效率。\n- **PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion**（PRISM：使用语言引导的 Stable Diffusion 生成高分辨率医学逆事实图像）：论文开发了 PRISM 框架，实现了精确修改医学图像中的伪相关性，显著提升了下游分类器的鲁棒性。\n- **PaliGemma-CXR: A Multi-task Multimodal Model for TB Chest X-ray Interpretation**（PaliGemma-CXR：用于肺结核胸部 X 光的多任务多模态模型）：主要发现是通过微调实现多任务（如诊断和报告生成），准确率达 90.32%，为肺结核筛查提供了高效工具。\n- **Jawaher: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking**（Jawaher：用于 LLM 基准测试的多种方言阿拉伯谚语数据集）：贡献在于构建了首个阿拉伯谚语数据集，揭示了 LLM 在文化语境中的局限性。\n\n这些论文突出了 AI 在医疗中的潜力，但其他如蛋白质折叠的论文（如 BAnG）则较专业，仅提到其在生物序列生成中的进展。\n\n### 机器人和自动驾驶\n- **SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models**（SafeAuto：使用多模态基础模型的知识增强安全自动驾驶）：核心发现是通过马尔可夫逻辑网络和 RAG 模型提升自动驾驶安全性，显著优于基线。\n- **Learning Vision-Based Neural Network Controllers with Semi-Probabilistic Safety Guarantees**（学习基于视觉的神经网络控制器，具有半概率安全保证）：论文提出半概率验证框架，贡献在于实现视觉控制的安全性，提升了机器人导航性能。\n- **DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping**（DexGraspVLA：面向通用灵巧抓取的视觉-语言-动作框架）：主要贡献是零-shot 转移到真实环境中，90% 成功率，展示了多模态框架在机器人抓取中的潜力。\n\n其他自动驾驶论文（如 Robust Deterministic Policy Gradient）快速掠过：它们改善了强化学习鲁棒性，但主题较重复。\n\n### 其他值得一提的\n- **Attend or Perish: Benchmarking Attention in Algorithmic Reasoning**（关注或灭亡：算法推理中注意力的基准测试）：论文构建了算法基准，核心发现是评估 Transformer 在未见输入上的外推能力。\n- **FedConv: A Learning-on-Model Paradigm for Heterogeneous Federated Clients**（FedConv：面向异构联邦客户端的学习-模型范式）：贡献在于提出卷积压缩方法，提升联邦学习效率，减少 33% 计算开销。\n- **WorldModelBench: Judging Video Generation Models As World Models**（WorldModelBench：将视频生成模型视为世界模型的评估基准）：主要发现是通过新基准评估视频模型的物理一致性，提升了 AI 鲁棒性。\n\n剩余论文（如 Clustering Context in Off-Policy Evaluation）则因主题较 niche，仅简要提及其在强化学习中的进展。\n\n总之，今天的论文突出了 AI 模型的实用性和扩展性，LLM 和医疗应用领域尤为活跃。如果你对特定主题感兴趣，建议查看这些论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2503.00248v1",
      "title": "Human-AI Collaboration: Trade-offs Between Performance and Preferences",
      "title_zh": "人类-AI 协作：性能与偏好之间的权衡",
      "authors": [
        "Lukas William Mayer",
        "Sheer Karny",
        "Jackie Ayoub",
        "Miao Song",
        "Danyang Tian",
        "Ehsan Moradi-Pari",
        "Mark Steyvers"
      ],
      "abstract": "Despite the growing interest in collaborative AI, designing systems that\nseamlessly integrate human input remains a major challenge. In this study, we\ndeveloped a task to systematically examine human preferences for collaborative\nagents. We created and evaluated five collaborative AI agents with strategies\nthat differ in the manner and degree they adapt to human actions. Participants\ninteracted with a subset of these agents, evaluated their perceived traits, and\nselected their preferred agent. We used a Bayesian model to understand how\nagents' strategies influence the Human-AI team performance, AI's perceived\ntraits, and the factors shaping human-preferences in pairwise agent\ncomparisons. Our results show that agents who are more considerate of human\nactions are preferred over purely performance-maximizing agents. Moreover, we\nshow that such human-centric design can improve the likability of AI\ncollaborators without reducing performance. We find evidence for\ninequality-aversion effects being a driver of human choices, suggesting that\npeople prefer collaborative agents which allow them to meaningfully contribute\nto the team. Taken together, these findings demonstrate how collaboration with\nAI can benefit from development efforts which include both subjective and\nobjective metrics.",
      "tldr_zh": "这篇论文探讨了Human-AI协作中性能与偏好之间的权衡，研究开发了一个系统任务来评估人类对不同协作AI代理的偏好。研究者创建并测试了五种策略各异的AI代理，这些代理在适应人类行为的方式和程度上有所不同，并使用Bayesian模型分析了代理策略对团队绩效、AI感知特征以及人类选择因素的影响。结果显示，更注重人类行为的代理比单纯追求性能最大化的代理更受欢迎，且这种人类中心设计能提升AI的受欢迎度而不降低整体表现。研究还发现，inequality-aversion效应是驱动人类偏好的关键因素，强调AI开发应同时考虑主观和客观指标以实现更有效的协作。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "LW Mayer & S Karny are co-first authors",
      "pdf_url": "http://arxiv.org/pdf/2503.00248v1",
      "published_date": "2025-02-28 23:50:14 UTC",
      "updated_date": "2025-02-28 23:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:03:20.879306"
    },
    {
      "arxiv_id": "2503.00240v1",
      "title": "1-Lipschitz Network Initialization for Certifiably Robust Classification Applications: A Decay Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Marius F. R. Juston",
        "William R. Norris",
        "Dustin Nottage",
        "Ahmet Soylemezoglu"
      ],
      "abstract": "This paper discusses the weight parametrization of two standard 1-Lipschitz\nnetwork structure methodologies, the Almost-Orthogonal-Layers (AOL) and the\nSDP-based Lipschitz Layers (SLL), and derives their impact on the\ninitialization for deep 1-Lipschitz feedforward networks in addition to\ndiscussing underlying issues surrounding this initialization. These networks\nare mainly used in certifiably robust classification applications to combat\nadversarial attacks by limiting the effects of perturbations on the output\nclassification result. An exact and an upper bound for the parameterized weight\nvariance was calculated assuming a standard Normal distribution initialization;\nadditionally, an upper bound was computed assuming a Generalized Normal\nDistribution, generalizing the proof for Uniform, Laplace, and Normal\ndistribution weight initializations. It is demonstrated that the weight\nvariance holds no bearing on the output variance distribution and that only the\ndimension of the weight matrices matters. Additionally, this paper demonstrates\nthat the weight initialization always causes deep 1-Lipschitz networks to decay\nto zero.",
      "tldr_zh": "这篇论文探讨了 Almost-Orthogonal-Layers (AOL) 和 SDP-based Lipschitz Layers (SLL) 等 1-Lipschitz 网络结构的权重参数化及其对深度 1-Lipschitz 前馈网络初始化过程的影响，这些网络主要用于可证明鲁棒的分类应用以抵抗逆向攻击。作者计算了权重方差的精确值和上界，假设标准正态分布或广义正态分布（包括均匀、拉普拉斯和正态分布）初始化，并证明权重方差不影响输出方差分布，仅由权重矩阵的维度决定。主要发现是，权重初始化总是导致深度 1-Lipschitz 网络衰减到零，这揭示了潜在的初始化问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.00240v1",
      "published_date": "2025-02-28 23:02:04 UTC",
      "updated_date": "2025-02-28 23:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:03:34.265566"
    },
    {
      "arxiv_id": "2503.00237v1",
      "title": "Agentic AI Needs a Systems Theory",
      "title_zh": "代理式AI需要系统理论",
      "authors": [
        "Erik Miehling",
        "Karthikeyan Natesan Ramamurthy",
        "Kush R. Varshney",
        "Matthew Riemer",
        "Djallel Bouneffouf",
        "John T. Richards",
        "Amit Dhurandhar",
        "Elizabeth M. Daly",
        "Michael Hind",
        "Prasanna Sattigeri",
        "Dennis Wei",
        "Ambrish Rawat",
        "Jasmina Gajcin",
        "Werner Geyer"
      ],
      "abstract": "The endowment of AI with reasoning capabilities and some degree of agency is\nwidely viewed as a path toward more capable and generalizable systems. Our\nposition is that the current development of agentic AI requires a more\nholistic, systems-theoretic perspective in order to fully understand their\ncapabilities and mitigate any emergent risks. The primary motivation for our\nposition is that AI development is currently overly focused on individual model\ncapabilities, often ignoring broader emergent behavior, leading to a\nsignificant underestimation in the true capabilities and associated risks of\nagentic AI. We describe some fundamental mechanisms by which advanced\ncapabilities can emerge from (comparably simpler) agents simply due to their\ninteraction with the environment and other agents. Informed by an extensive\namount of existing literature from various fields, we outline mechanisms for\nenhanced agent cognition, emergent causal reasoning ability, and metacognitive\nawareness. We conclude by presenting some key open challenges and guidance for\nthe development of agentic AI. We emphasize that a systems-level perspective is\nessential for better understanding, and purposefully shaping, agentic AI\nsystems.",
      "tldr_zh": "该论文主张，agentic AI 的开发需要采用更整体的 systems theory 视角，以全面理解其能力并缓解潜在风险，因为当前过度关注单个模型的能力而忽略了 emergent behavior，导致对真正能力和风险的低估。作者基于现有文献，阐述了代理与环境及其他代理互动的机制，这些机制可引发增强的 agent cognition、emergent causal reasoning ability 和 metacognitive awareness，从而提升 AI 的高级功能。论文总结了关键开放挑战，并强调 systems-level 视角对于更好地理解和 purposeful shaping agentic AI 系统至关重要。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00237v1",
      "published_date": "2025-02-28 22:51:32 UTC",
      "updated_date": "2025-02-28 22:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:03:43.493033"
    },
    {
      "arxiv_id": "2503.01909v1",
      "title": "Attend or Perish: Benchmarking Attention in Algorithmic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Spiegel",
        "Michal Štefánik",
        "Marek Kadlčík",
        "Josef Kuchař"
      ],
      "abstract": "Can transformers learn to perform algorithmic tasks reliably across\npreviously unseen input/output domains? While pre-trained language models show\nsolid accuracy on benchmarks incorporating algorithmic reasoning, assessing the\nreliability of these results necessitates an ability to cleanse models'\nfunctional capabilities from memorization. In this paper, we propose an\nalgorithmic benchmark comprising six tasks of infinite input domains where we\ncan also disentangle and trace the correct, robust algorithm necessary for the\ntask. This allows us to assess (i) models' ability to extrapolate to unseen\ntypes of inputs, including new lengths, value ranges or input domains, but also\n(ii) to assess the robustness of the functional mechanism in recent models\nthrough the lens of their attention maps. We make the implementation of all our\ntasks and interoperability methods publicly available at\nhttps://github.com/michalspiegel/AttentionSpan .",
      "tldr_zh": "本论文探讨了 transformers 是否能在新的输入/输出域可靠执行算法任务，同时提出一个包含六种任务的算法基准，以区分模型的功能能力与记忆化。该基准具有无限输入域，能追踪正确的算法，允许评估模型在外推到未见输入（如新长度、值范围或域）时的性能，并通过 attention maps 分析功能的鲁棒性。作者公开了任务实现和互操作方法，位于 https://github.com/michalspiegel/AttentionSpan ，为评估算法推理中的注意力机制提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01909v1",
      "published_date": "2025-02-28 22:50:38 UTC",
      "updated_date": "2025-02-28 22:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:03:56.027098"
    },
    {
      "arxiv_id": "2503.00234v3",
      "title": "Investigating the Relationship Between Debiasing and Artifact Removal using Saliency Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Lukasz Sztukiewicz",
        "Ignacy Stępka",
        "Michał Wiliński",
        "Jerzy Stefanowski"
      ],
      "abstract": "The widespread adoption of machine learning systems has raised critical\nconcerns about fairness and bias, making mitigating harmful biases essential\nfor AI development. In this paper, we investigate the relationship between\ndebiasing and removing artifacts in neural networks for computer vision tasks.\nFirst, we introduce a set of novel XAI-based metrics that analyze saliency maps\nto assess shifts in a model's decision-making process. Then, we demonstrate\nthat successful debiasing methods systematically redirect model focus away from\nprotected attributes. Finally, we show that techniques originally developed for\nartifact removal can be effectively repurposed for improving fairness. These\nfindings provide evidence for the existence of a bidirectional connection\nbetween ensuring fairness and removing artifacts corresponding to protected\nattributes.",
      "tldr_zh": "本研究探讨了机器学习模型中debiasing（去偏见）和artifact removal（人工制品去除）之间的关系，针对计算机视觉任务。作者引入了一套新型XAI-based metrics，通过saliency maps分析模型决策过程的变化，以评估debiasing的有效性。结果显示，成功的debiasing方法会系统性地将模型注意力从保护属性转移开，同时原本用于artifact removal的技术可有效改编以提升模型公平性。这些发现证实了debiasing和artifact removal之间存在双向联系，为AI开发中的公平性改进提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00234v3",
      "published_date": "2025-02-28 22:42:21 UTC",
      "updated_date": "2025-04-24 10:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:04:06.765393"
    },
    {
      "arxiv_id": "2503.00231v1",
      "title": "Jawaher: A Multidialectal Dataset of Arabic Proverbs for LLM Benchmarking",
      "title_zh": "Jawaher：一个多方言阿拉伯谚语数据集，用于LLM基准测试",
      "authors": [
        "Samar M. Magdy",
        "Sang Yun Kwon",
        "Fakhraddin Alwajih",
        "Safaa Abdelfadil",
        "Shady Shehata",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "Recent advancements in instruction fine-tuning, alignment methods such as\nreinforcement learning from human feedback (RLHF), and optimization techniques\nlike direct preference optimization (DPO) have significantly enhanced the\nadaptability of large language models (LLMs) to user preferences. However,\ndespite these innovations, many LLMs continue to exhibit biases toward Western,\nAnglo-centric, or American cultures, with performance on English data\nconsistently surpassing that of other languages. This reveals a persistent\ncultural gap in LLMs, which complicates their ability to accurately process\nculturally rich and diverse figurative language such as proverbs. To address\nthis, we introduce Jawaher, a benchmark designed to assess LLMs' capacity to\ncomprehend and interpret Arabic proverbs. Jawaher includes proverbs from\nvarious Arabic dialects, along with idiomatic translations and explanations.\nThrough extensive evaluations of both open- and closed-source models, we find\nthat while LLMs can generate idiomatically accurate translations, they struggle\nwith producing culturally nuanced and contextually relevant explanations. These\nfindings highlight the need for ongoing model refinement and dataset expansion\nto bridge the cultural gap in figurative language processing.",
      "tldr_zh": "本研究指出现代LLMs在instruction fine-tuning、RLHF和DPO等技术进步下虽能更好地适应用户偏好，但仍存在对西方文化的偏见，导致在处理非英语文化元素如阿拉伯谚语时表现欠佳。为此，论文引入Jawaher数据集，这是一个多方言阿拉伯谚语基准，包含谚语的惯用翻译和解释，用于评估LLMs的理解和解释能力。通过对开源和闭源模型的广泛评估，发现LLMs能生成准确的翻译，但难以提供文化细腻和上下文相关的解释，从而强调了需要持续模型优化和数据集扩展来弥合文化差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Project GitHub page is accessible at:\n  https://github.com/UBC-NLP/jawaher",
      "pdf_url": "http://arxiv.org/pdf/2503.00231v1",
      "published_date": "2025-02-28 22:28:00 UTC",
      "updated_date": "2025-02-28 22:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:04:20.889384"
    },
    {
      "arxiv_id": "2503.00211v1",
      "title": "SafeAuto: Knowledge-Enhanced Safe Autonomous Driving with Multimodal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang",
        "Xuan Yang",
        "Taiqi Wang",
        "Yu Yao",
        "Aleksandr Petiushko",
        "Bo Li"
      ],
      "abstract": "Traditional autonomous driving systems often struggle to integrate high-level\nreasoning with low-level control, resulting in suboptimal and sometimes unsafe\ndriving behaviors. The emergence of Multimodal Large Language Models (MLLMs),\nwhich can process both visual and textual data, presents an opportunity to\nunify perception and reasoning tasks within a single framework. However,\neffectively embedding precise safety knowledge into MLLMs for autonomous\ndriving remains a significant challenge. To address this, we propose SafeAuto,\na novel framework that enhances MLLM-based autonomous driving systems by\nincorporating both unstructured and structured knowledge. Specifically, we\nfirst introduce the Position-Dependent Cross-Entropy (PDCE) loss function,\ndesigned to improve the accuracy of low-level control signal predictions when\nnumerical values are represented as text. Second, to ensure safe autonomous\ndriving by explicitly integrating precise safety knowledge into the MLLM, we\ndevelop a reasoning component for SafeAuto. This component translates driving\nsafety regulations into first-order logic rules (e.g., \"red light => stop\") and\nincorporates these rules into a probabilistic graphical model, such as a Markov\nLogic Network (MLN). The MLN is trained to verify the predicted next actions\nusing environmental attributes identified by attribute recognition models\n(e.g., detecting a red light) to form the predicates. Additionally, we\nconstruct a Multimodal RAG model that leverages video data, control signals,\nand environmental attributes to learn more effectively from past similar\ndriving experiences. By integrating PDCE, MLN, and Multimodal RAG, SafeAuto\nsignificantly outperforms existing baselines across multiple datasets. This\nadvancement enables more accurate, reliable, and safer autonomous driving\nsystems that learn from experience, obey traffic laws, and perform precise\ncontrol actions.",
      "tldr_zh": "本文提出 SafeAuto 框架，利用 Multimodal Large Language Models (MLLMs) 增强自动驾驶系统的安全性和准确性，解决传统系统在高级推理和低级控制整合上的不足。框架引入 Position-Dependent Cross-Entropy (PDCE) 损失函数来优化控制信号预测，并通过 Markov Logic Network (MLN) 将驾驶安全法规转化为 first-order logic rules（如 \"red light => stop\"），结合 Multimodal RAG 模型从视频数据和环境属性中学习过去经验。实验结果显示，SafeAuto 在多个数据集上显著优于现有基线，实现更精确、可靠和遵守交通法规的自主驾驶系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00211v1",
      "published_date": "2025-02-28 21:53:47 UTC",
      "updated_date": "2025-02-28 21:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:04:33.180453"
    },
    {
      "arxiv_id": "2503.00210v1",
      "title": "Foundation-Model-Boosted Multimodal Learning for fMRI-based Neuropathic Pain Drug Response Prediction",
      "title_zh": "基础模型增强的多模态学习，用于基于 fMRI 的神经病",
      "authors": [
        "Wenrui Fan",
        "L. M. Riza Rizky",
        "Jiayang Zhang",
        "Chen Chen",
        "Haiping Lu",
        "Kevin Teh",
        "Dinesh Selvarajah",
        "Shuo Zhou"
      ],
      "abstract": "Neuropathic pain, affecting up to 10% of adults, remains difficult to treat\ndue to limited therapeutic efficacy and tolerability. Although resting-state\nfunctional MRI (rs-fMRI) is a promising non-invasive measurement of brain\nbiomarkers to predict drug response in therapeutic development, the complexity\nof fMRI demands machine learning models with substantial capacity. However,\nextreme data scarcity in neuropathic pain research limits the application of\nhigh-capacity models. To address the challenge of data scarcity, we propose\nFMM$_{TC}$, a Foundation-Model-boosted Multimodal learning framework for\nfMRI-based neuropathic pain drug response prediction, which leverages both\ninternal multimodal information in pain-specific data and external knowledge\nfrom large pain-agnostic data. Specifically, to maximize the value of limited\npain-specific data, FMM$_{TC}$ integrates complementary information from two\nrs-fMRI modalities: Time series and functional Connectivity. FMM$_{TC}$ is\nfurther boosted by an fMRI foundation model with its external knowledge from\nextensive pain-agnostic fMRI datasets enriching limited pain-specific\ninformation. Evaluations with an in-house dataset and a public dataset from\nOpenNeuro demonstrate FMM$_{TC}$'s superior representation ability,\ngeneralizability, and cross-dataset adaptability over existing unimodal fMRI\nmodels that only consider one of the rs-fMRI modalities. The ablation study\nvalidates the effectiveness of multimodal learning and foundation-model-powered\nexternal knowledge transfer in FMM$_{TC}$. An integrated gradient-based\ninterpretation study explains how FMM$_{TC}$'s cross-dataset dynamic behaviors\nenhance its adaptability. In conclusion, FMM$_{TC}$ boosts clinical trials in\nneuropathic pain therapeutic development by accurately predicting drug\nresponses to improve the participant stratification efficiency.",
      "tldr_zh": "该研究针对神经病理性疼痛的药物反应预测问题，提出了一种Foundation-Model-boosted Multimodal Learning框架FMM$_{TC}$，通过整合rs-fMRI的多模态信息（包括时间序列和功能Connectivity）以及fMRI基础模型的外部知识，解决数据稀缺的挑战。FMM$_{TC}$在内部和公开数据集（如OpenNeuro）上的评估显示，其在表示能力、一般化和跨数据集适应性方面优于传统单模态fMRI模型，准确率显著提升。消融研究和集成梯度解释分析进一步验证了多模态学习和知识转移的有效性，最终有助于提高临床试验中参与者分层的效率，为神经痛治疗开发提供支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00210v1",
      "published_date": "2025-02-28 21:50:03 UTC",
      "updated_date": "2025-02-28 21:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:04:45.282996"
    },
    {
      "arxiv_id": "2503.00206v1",
      "title": "Quantifying First-Order Markov Violations in Noisy Reinforcement Learning: A Causal Discovery Approach",
      "title_zh": "在有噪声的强化学习中量化一阶 Markov 违反：一个因果发现方法",
      "authors": [
        "Naveen Mysore"
      ],
      "abstract": "Reinforcement learning (RL) methods frequently assume that each new\nobservation completely reflects the environment's state, thereby guaranteeing\nMarkovian (one-step) transitions. In practice, partial observability or\nsensor/actuator noise often invalidates this assumption. This paper proposes a\nsystematic methodology for detecting such violations, combining a partial\ncorrelation-based causal discovery process (PCMCI) with a novel Markov\nViolation score (MVS). The MVS measures multi-step dependencies that emerge\nwhen noise or incomplete state information disrupts the Markov property.\n  Classic control tasks (CartPole, Pendulum, Acrobot) serve as examples to\nillustrate how targeted noise and dimension omissions affect both RL\nperformance and measured Markov consistency. Surprisingly, even substantial\nobservation noise sometimes fails to induce strong multi-lag dependencies in\ncertain domains (e.g., Acrobot). In contrast, dimension-dropping investigations\nshow that excluding some state variables (e.g., angular velocities in CartPole\nand Pendulum) significantly reduces returns and increases MVS, while removing\nother dimensions has minimal impact.\n  These findings emphasize the importance of locating and safeguarding the most\ncausally essential dimensions in order to preserve effective single-step\nlearning. By integrating partial correlation tests with RL performance\noutcomes, the proposed approach precisely identifies when and where the Markov\nassumption is violated. This framework offers a principled mechanism for\ndeveloping robust policies, informing representation learning, and addressing\npartial observability in real-world RL scenarios. All code and experimental\nlogs are accessible for reproducibility (https://github.com/ucsb/markovianess).",
      "tldr_zh": "本论文提出一种系统方法，用于量化强化学习（RL）中一阶Markov Violations的影响，该方法结合部分相关性因果发现过程（PCMCI）和新型Markov Violation score (MVS)来检测噪声或不完整状态信息导致的多步依赖。研究通过在经典控制任务如CartPole、Pendulum和Acrobot上进行实验，发现观察噪声有时不会显著诱发多滞后依赖，而删除关键状态变量（如角速度）会大幅降低RL回报并增加MVS。总体而言，该框架强调识别和保护核心因果维度的重要性，有助于开发鲁棒策略、提升表示学习并应对真实世界的部分可观察性问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T05",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review for RLC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.00206v1",
      "published_date": "2025-02-28 21:42:10 UTC",
      "updated_date": "2025-02-28 21:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:04:57.643187"
    },
    {
      "arxiv_id": "2503.00196v1",
      "title": "PRISM: High-Resolution & Precise Counterfactual Medical Image Generation using Language-guided Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Amar Kumar",
        "Anita Kriz",
        "Mohammad Havaei",
        "Tal Arbel"
      ],
      "abstract": "Developing reliable and generalizable deep learning systems for medical\nimaging faces significant obstacles due to spurious correlations, data\nimbalances, and limited text annotations in datasets. Addressing these\nchallenges requires architectures robust to the unique complexities posed by\nmedical imaging data. The rapid advancements in vision-language foundation\nmodels within the natural image domain prompt the question of how they can be\nadapted for medical imaging tasks. In this work, we present PRISM, a framework\nthat leverages foundation models to generate high-resolution, language-guided\nmedical image counterfactuals using Stable Diffusion. Our approach demonstrates\nunprecedented precision in selectively modifying spurious correlations (the\nmedical devices) and disease features, enabling the removal and addition of\nspecific attributes while preserving other image characteristics. Through\nextensive evaluation, we show how PRISM advances counterfactual generation and\nenables the development of more robust downstream classifiers for clinically\ndeployable solutions. To facilitate broader adoption and research, we make our\ncode publicly available at https://github.com/Amarkr1/PRISM.",
      "tldr_zh": "本文提出 PRISM 框架，利用语言引导的 Stable Diffusion 生成高分辨率、精确的医疗图像反事实(counterfactuals)，以应对医疗图像数据中的虚假相关性(spurious correlations)、数据不平衡和有限文本注解等挑战。PRISM 通过选择性地修改医疗设备和疾病特征，实现特定属性的移除或添加，同时保留其他图像特性。实验结果显示，该框架显著提升了反事实生成质量，并支持开发更稳健的下游分类器；相关代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review for MIDL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.00196v1",
      "published_date": "2025-02-28 21:32:08 UTC",
      "updated_date": "2025-02-28 21:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:05:08.194949"
    },
    {
      "arxiv_id": "2503.01908v1",
      "title": "UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang",
        "Shuang Yang",
        "Bo Li"
      ],
      "abstract": "Large Language Model (LLM) agents equipped with external tools have become\nincreasingly powerful for handling complex tasks such as web shopping,\nautomated email replies, and financial trading. However, these advancements\nalso amplify the risks of adversarial attacks, particularly when LLM agents can\naccess sensitive external functionalities. Moreover, because LLM agents engage\nin extensive reasoning or planning before executing final actions, manipulating\nthem into performing targeted malicious actions or invoking specific tools\nremains a significant challenge. Consequently, directly embedding adversarial\nstrings in malicious instructions or injecting malicious prompts into tool\ninteractions has become less effective against modern LLM agents. In this work,\nwe present UDora, a unified red teaming framework designed for LLM Agents that\ndynamically leverages the agent's own reasoning processes to compel it toward\nmalicious behavior. Specifically, UDora first samples the model's reasoning for\nthe given task, then automatically identifies multiple optimal positions within\nthese reasoning traces to insert targeted perturbations. Subsequently, it uses\nthe modified reasoning as the objective to optimize the adversarial strings. By\niteratively applying this process, the LLM agent will then be induced to\nundertake designated malicious actions or to invoke specific malicious tools.\nOur approach demonstrates superior effectiveness compared to existing methods\nacross three LLM agent datasets.",
      "tldr_zh": "本研究提出UDora，一种统一的红队测试框架，用于对抗LLM Agents，通过动态劫持其自身推理过程来诱导恶意行为。具体而言，UDora首先采样代理的推理痕迹，自动识别最佳插入点并插入针对性扰动，然后使用修改后的推理优化对抗字符串，并通过迭代过程促使代理执行指定恶意动作或调用恶意工具。与现有方法相比，该框架在三个LLM Agents数据集上表现出色，证明了其优越有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01908v1",
      "published_date": "2025-02-28 21:30:28 UTC",
      "updated_date": "2025-02-28 21:30:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:05:20.066133"
    },
    {
      "arxiv_id": "2503.00191v1",
      "title": "Learning Vision-Based Neural Network Controllers with Semi-Probabilistic Safety Guarantees",
      "title_zh": "利用半概率安全保证学习基于视觉的神经网络控制器",
      "authors": [
        "Xinhang Ma",
        "Junlin Wu",
        "Hussein Sibai",
        "Yiannis Kantaros",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Ensuring safety in autonomous systems with vision-based control remains a\ncritical challenge due to the high dimensionality of image inputs and the fact\nthat the relationship between true system state and its visual manifestation is\nunknown. Existing methods for learning-based control in such settings typically\nlack formal safety guarantees. To address this challenge, we introduce a novel\nsemi-probabilistic verification framework that integrates reachability analysis\nwith conditional generative adversarial networks and distribution-free tail\nbounds to enable efficient and scalable verification of vision-based neural\nnetwork controllers. Next, we develop a gradient-based training approach that\nemploys a novel safety loss function, safety-aware data-sampling strategy to\nefficiently select and store critical training examples, and curriculum\nlearning, to efficiently synthesize safe controllers in the semi-probabilistic\nframework. Empirical evaluations in X-Plane 11 airplane landing simulation,\nCARLA-simulated autonomous lane following, and F1Tenth lane following in a\nphysical visually-rich miniature environment demonstrate the effectiveness of\nour method in achieving formal safety guarantees while maintaining strong\nnominal performance. Our code is available at https://github.com/xhOwenMa/SPVT.",
      "tldr_zh": "这篇论文针对视觉为基础的神经网络控制器在自主系统中的安全挑战，提出了一种半概率验证框架，结合可达性分析（reachability analysis）、条件生成对抗网络（conditional generative adversarial networks）和无分布尾界（distribution-free tail bounds），以实现高效、可扩展的安全验证。作者开发了基于梯度的训练方法，包括新型安全损失函数（safety loss function）、安全感知数据采样策略和课程学习（curriculum learning），用于合成可靠的控制器。实验结果在 X-Plane 11 飞机着陆模拟、CARLA 模拟的自动车道跟随以及 F1Tenth 物理环境中表明，该方法显著提升了正式安全保证，同时保持了强劲的性能表现。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 2 figures, submitted to IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.00191v1",
      "published_date": "2025-02-28 21:16:42 UTC",
      "updated_date": "2025-02-28 21:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:05:33.180046"
    },
    {
      "arxiv_id": "2503.00179v1",
      "title": "Zero-Shot and Efficient Clarification Need Prediction in Conversational Search",
      "title_zh": "翻译失败",
      "authors": [
        "Lili Lu",
        "Chuan Meng",
        "Federico Ravenda",
        "Mohammad Aliannejadi",
        "Fabio Crestani"
      ],
      "abstract": "Clarification need prediction (CNP) is a key task in conversational search,\naiming to predict whether to ask a clarifying question or give an answer to the\ncurrent user query. However, current research on CNP suffers from the issues of\nlimited CNP training data and low efficiency. In this paper, we propose a\nzero-shot and efficient CNP framework (Zef-CNP), in which we first prompt large\nlanguage models (LLMs) in a zero-shot manner to generate two sets of synthetic\nqueries: ambiguous and specific (unambiguous) queries. We then use the\ngenerated queries to train efficient CNP models. Zef-CNP eliminates the need\nfor human-annotated clarification-need labels during training and avoids the\nuse of LLMs with high query latency at query time. To further improve the\ngeneration quality of synthetic queries, we devise a topic-, information-need-,\nand query-aware chain-of-thought (CoT) prompting strategy (TIQ-CoT). Moreover,\nwe enhance TIQ-CoT with counterfactual query generation (CoQu), which guides\nLLMs first to generate a specific/ambiguous query and then sequentially\ngenerate its corresponding ambiguous/specific query. Experimental results show\nthat Zef-CNP achieves superior CNP effectiveness and efficiency compared with\nzero- and few-shot LLM-based CNP predictors.",
      "tldr_zh": "本文提出了一种零样本和高效的澄清需求预测框架（Zef-CNP），用于对话式搜索中预测是否需要针对用户查询提出澄清问题，从而解决现有CNP研究中数据有限和效率低的问题。该框架利用大语言模型（LLMs）进行零样本提示生成合成查询，包括模糊查询和具体查询，并以此训练高效的CNP模型。为提升生成质量，引入了主题、信息需求和查询感知的链式思维提示策略（TIQ-CoT）以及反事实查询生成（CoQu），以指导LLMs更准确地创建查询对。实验结果显示，Zef-CNP在CNP的有效性和效率上显著优于零样本和少样本的LLM基预测器。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00179v1",
      "published_date": "2025-02-28 20:49:18 UTC",
      "updated_date": "2025-02-28 20:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:05:46.427154"
    },
    {
      "arxiv_id": "2503.00177v1",
      "title": "Steering Large Language Model Activations in Sparse Spaces",
      "title_zh": "在稀疏空间中引导大型语言模型激活",
      "authors": [
        "Reza Bayat",
        "Ali Rahimi-Kalahroudi",
        "Mohammad Pezeshki",
        "Sarath Chandar",
        "Pascal Vincent"
      ],
      "abstract": "A key challenge in AI alignment is guiding large language models (LLMs) to\nfollow desired behaviors at test time. Activation steering, which modifies\ninternal model activations during inference, offers a potential solution.\nHowever, prior work in dense activation spaces struggles with superposition,\nwherein multiple features become entangled, limiting interpretability and\nprecise control. In contrast, sparse representations provide an untapped\nopportunity for more interpretable behavior modulation. In this work, we\nintroduce sparse activation steering (SAS), a method that leverages sparse\nautoencoders (SAEs) to steer LLM behavior in sparse spaces. By isolating\nbehavior-specific features through a contrastive prompt-pairing approach, we\ndefine a set of features that can selectively reinforce or suppress behaviors.\nExperiments on Gemma 2 LLMs show that SAS vectors enable nuanced behavioral\nmodulation and finer-grained control. Furthermore, scaling SAEs improves\nmonosemanticity of SAS vectors, suggesting more reliable and interpretable\ninterventions.",
      "tldr_zh": "本研究针对AI校准中引导大型语言模型(LLMs)行为的挑战，提出sparse activation steering (SAS)方法，利用sparse autoencoders (SAEs)在稀疏空间中修改模型激活，以避免密集空间中的superposition问题。SAS通过对比提示配对方法隔离行为特定特征，实现对LLMs行为的精确强化或抑制。实验在Gemma 2 LLMs上表明，SAS向量提供了更细粒度的行为调控，且扩展SAEs后提升了monosemanticity，提高了干预的可解释性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00177v1",
      "published_date": "2025-02-28 20:43:45 UTC",
      "updated_date": "2025-02-28 20:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:05:56.577185"
    },
    {
      "arxiv_id": "2503.00171v1",
      "title": "PaliGemma-CXR: A Multi-task Multimodal Model for TB Chest X-ray Interpretation",
      "title_zh": "翻译失败",
      "authors": [
        "Denis Musinguzi",
        "Andrew Katumba",
        "Sudi Murindanyi"
      ],
      "abstract": "Tuberculosis (TB) is a infectious global health challenge. Chest X-rays are a\nstandard method for TB screening, yet many countries face a critical shortage\nof radiologists capable of interpreting these images. Machine learning offers\nan alternative, as it can automate tasks such as disease diagnosis, and report\ngeneration. However, traditional approaches rely on task-specific models, which\ncannot utilize the interdependence between tasks. Building a multi-task model\ncapable of performing multiple tasks poses additional challenges such as\nscarcity of multimodal data, dataset imbalance, and negative transfer. To\naddress these challenges, we propose PaliGemma-CXR, a multi-task multimodal\nmodel capable of performing TB diagnosis, object detection, segmentation,\nreport generation, and VQA. Starting with a dataset of chest X-ray images\nannotated with TB diagnosis labels and segmentation masks, we curated a\nmultimodal dataset to support additional tasks. By finetuning PaliGemma on this\ndataset and sampling data using ratios of the inverse of the size of task\ndatasets, we achieved the following results across all tasks: 90.32% accuracy\non TB diagnosis and 98.95% on close-ended VQA, 41.3 BLEU score on report\ngeneration, and a mAP of 19.4 and 16.0 on object detection and segmentation,\nrespectively. These results demonstrate that PaliGemma-CXR effectively\nleverages the interdependence between multiple image interpretation tasks to\nenhance performance.",
      "tldr_zh": "本研究提出PaliGemma-CXR，一种多任务多模态模型，用于TB（结核病）胸部X光图像的解释，支持TB诊断、物体检测、分割、报告生成和VQA（视觉问答）等任务，以解决传统模型无法利用任务间相互依赖的问题。研究者通过扩展一个带TB标签和分割掩码的X光数据集，并采用数据集大小倒数比率采样策略，对PaliGemma模型进行微调，处理了数据稀缺和不平衡的挑战。实验结果显示，该模型在TB诊断上达到90.32%准确率、在封闭式VQA上达到98.95%、报告生成BLEU分数41.3，以及物体检测mAP 19.4和分割mAP 16.0，证明了多任务间相互依赖的有效提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00171v1",
      "published_date": "2025-02-28 20:34:06 UTC",
      "updated_date": "2025-02-28 20:34:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:06:11.648184"
    },
    {
      "arxiv_id": "2503.00162v1",
      "title": "PreMind: Multi-Agent Video Understanding for Advanced Indexing of Presentation-style Videos",
      "title_zh": "PreMind：多智能体视频理解用于演示风格视频的高级索引",
      "authors": [
        "Kangda Wei",
        "Zhengyu Zhou",
        "Bingqing Wang",
        "Jun Araki",
        "Lukas Lange",
        "Ruihong Huang",
        "Zhe Feng"
      ],
      "abstract": "In recent years, online lecture videos have become an increasingly popular\nresource for acquiring new knowledge. Systems capable of effectively\nunderstanding/indexing lecture videos are thus highly desirable, enabling\ndownstream tasks like question answering to help users efficiently locate\nspecific information within videos. This work proposes PreMind, a novel\nmulti-agent multimodal framework that leverages various large models for\nadvanced understanding/indexing of presentation-style videos. PreMind first\nsegments videos into slide-presentation segments using a Vision-Language Model\n(VLM) to enhance modern shot-detection techniques. Each segment is then\nanalyzed to generate multimodal indexes through three key steps: (1) extracting\nslide visual content, (2) transcribing speech narratives, and (3) consolidating\nthese visual and speech contents into an integrated understanding. Three\ninnovative mechanisms are also proposed to improve performance: leveraging\nprior lecture knowledge to refine visual understanding, detecting/correcting\nspeech transcription errors using a VLM, and utilizing a critic agent for\ndynamic iterative self-reflection in vision analysis. Compared to traditional\nvideo indexing methods, PreMind captures rich, reliable multimodal information,\nallowing users to search for details like abbreviations shown only on slides.\nSystematic evaluations on the public LPM dataset and an internal enterprise\ndataset are conducted to validate PreMind's effectiveness, supported by\ndetailed analyses.",
      "tldr_zh": "这篇论文提出了 PreMind，一种多智能体多模态框架，用于高级理解和索引演示风格视频，以支持下游任务如问答和信息定位。PreMind 首先利用 Vision-Language Model (VLM) 将视频分割成 slide-presentation 段，然后通过提取 slide 视觉内容、转录语音叙述并整合这些多模态信息来生成高级索引，同时引入三个创新机制：利用先验讲座知识优化视觉理解、使用 VLM 检测/纠正语音转录错误，以及通过 critic agent 进行动态迭代自反视。相比传统视频索引方法，PreMind 能捕获更丰富的可靠信息，如仅在 slides 上出现的缩写细节。在 LPM 数据集和内部企业数据集上的系统评估证实了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00162v1",
      "published_date": "2025-02-28 20:17:48 UTC",
      "updated_date": "2025-02-28 20:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:06:21.171140"
    },
    {
      "arxiv_id": "2503.00159v1",
      "title": "EXACT-CT: EXplainable Analysis for Crohn's and Tuberculosis using CT",
      "title_zh": "翻译失败",
      "authors": [
        "Shashwat Gupta",
        "Sarthak Gupta",
        "Akshan Agrawal",
        "Mahim Naaz",
        "Rajanikanth Yadav",
        "Priyanka Bagade"
      ],
      "abstract": "Crohn's disease and intestinal tuberculosis share many overlapping features\nsuch as clinical, radiological, endoscopic, and histological features -\nparticularly granulomas, making it challenging to clinically differentiate\nthem. Our research leverages 3D CTE scans, computer vision, and machine\nlearning to improve this differentiation to avoid harmful treatment\nmismanagement such as unnecessary anti-tuberculosis therapy for Crohn's disease\nor exacerbation of tuberculosis with immunosuppressants. Our study proposes a\nnovel method to identify radiologist - identified biomarkers such as VF to SF\nratio, necrosis, calcifications, comb sign and pulmonary TB to enhance\naccuracy. We demonstrate the effectiveness by using different ML techniques on\nthe features extracted from these biomarkers, computing SHAP on XGBoost for\nunderstanding feature importance towards predictions, and comparing against\nSOTA methods such as pretrained ResNet and CTFoundation.",
      "tldr_zh": "该研究针对 Crohn’s disease 和 intestinal tuberculosis 的诊断挑战，提出 EXACT-CT 框架，利用 3D CTE scans、计算机视觉和 machine learning 来区分这些疾病，避免治疗错误如不必要的 anti-tuberculosis therapy 或免疫抑制剂误用。方法包括识别放射科医生标识的 biomarkers，例如 VF to SF ratio、necrosis、calcifications、comb sign 和 pulmonary TB，并通过不同 ML 技术提取特征。实验结果显示，使用 XGBoost 计算 SHAP 值分析特征重要性后，该框架在准确性上优于 SOTA 方法如预训练 ResNet 和 CTFoundation，从而提升了诊断的可解释性和可靠性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.00159v1",
      "published_date": "2025-02-28 20:08:32 UTC",
      "updated_date": "2025-02-28 20:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:06:30.618019"
    },
    {
      "arxiv_id": "2503.00154v1",
      "title": "Fed-KAN: Federated Learning with Kolmogorov-Arnold Networks for Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Engin Zeydan",
        "Cristian J. Vaca-Rubio",
        "Luis Blanco",
        "Roberto Pereira",
        "Marius Caus",
        "Kapal Dev"
      ],
      "abstract": "Non-Terrestrial Networks (NTNs) are becoming a critical component of modern\ncommunication infrastructures, especially with the advent of Low Earth Orbit\n(LEO) satellite systems. Traditional centralized learning approaches face major\nchallenges in such networks due to high latency, intermittent connectivity and\nlimited bandwidth. Federated Learning (FL) is a promising alternative as it\nenables decentralized training while maintaining data privacy. However,\nexisting FL models, such as Federated Learning with Multi-Layer Perceptrons\n(Fed-MLP), can struggle with high computational complexity and poor\nadaptability to dynamic NTN environments. This paper provides a detailed\nanalysis for Federated Learning with Kolmogorov-Arnold Networks (Fed-KAN), its\nimplementation and performance improvements over traditional FL models in NTN\nenvironments for traffic forecasting. The proposed Fed-KAN is a novel approach\nthat utilises the functional approximation capabilities of KANs in a FL\nframework. We evaluate Fed-KAN compared to Fed-MLP on a traffic dataset of real\nsatellite operator and show a significant reduction in training and test loss.\nOur results show that Fed-KAN can achieve a 77.39% reduction in average test\nloss compared to Fed-MLP, highlighting its improved performance and better\ngeneralization ability. At the end of the paper, we also discuss some potential\napplications of Fed-KAN within O-RAN and Fed-KAN usage for split\nfunctionalities in NTN architecture.",
      "tldr_zh": "本论文提出 Fed-KAN，一种基于 Kolmogorov-Arnold Networks (KANs) 的联邦学习 (Federated Learning) 框架，针对非地面网络 (NTNs) 环境中的交通预测问题，旨在解决传统模型如 Fed-MLP 的高计算复杂性和适应性差等问题。Fed-KAN 利用 KANs 的函数逼近能力，在分布式训练中提升模型性能，同时保持数据隐私。实验结果显示，在真实卫星操作员的交通数据集上，Fed-KAN 比 Fed-MLP 降低了 77.39% 的平均测试损失，展示了更好的泛化能力。论文还讨论了 Fed-KAN 在 O-RAN 和 NTN 架构中的潜在应用，如分割功能实现。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2503.00154v1",
      "published_date": "2025-02-28 20:04:53 UTC",
      "updated_date": "2025-02-28 20:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:06:43.936382"
    },
    {
      "arxiv_id": "2503.00151v1",
      "title": "Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs",
      "title_zh": "Palm",
      "authors": [
        "Fakhraddin Alwajih",
        "Abdellah El Mekki",
        "Samar Mohamed Magdy",
        "Abdelrahim A. Elmadany",
        "Omer Nacar",
        "El Moatez Billah Nagoudi",
        "Reem Abdel-Salam",
        "Hanin Atwany",
        "Youssef Nafea",
        "Abdulfattah Mohammed Yahya",
        "Rahaf Alhamouri",
        "Hamzah A. Alsayadi",
        "Hiba Zayed",
        "Sara Shatnawi",
        "Serry Sibaee",
        "Yasir Ech-Chammakhy",
        "Walid Al-Dhabyani",
        "Marwa Mohamed Ali",
        "Imen Jarraya",
        "Ahmed Oumar El-Shangiti",
        "Aisha Alraeesi",
        "Mohammed Anwar Al-Ghrawi",
        "Abdulrahman S. Al-Batati",
        "Elgizouli Mohamed",
        "Noha Taha Elgindi",
        "Muhammed Saeed",
        "Houdaifa Atou",
        "Issam Ait Yahia",
        "Abdelhak Bouayad",
        "Mohammed Machrouh",
        "Amal Makouar",
        "Dania Alkawi",
        "Mukhtar Mohamed",
        "Safaa Taher Abdelfadil",
        "Amine Ziad Ounnoughene",
        "Rouabhia Anfel",
        "Rwaa Assi",
        "Ahmed Sorkatti",
        "Mohamedou Cheikh Tourad",
        "Anis Koubaa",
        "Ismail Berrada",
        "Mustafa Jarrar",
        "Shady Shehata",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "As large language models (LLMs) become increasingly integrated into daily\nlife, ensuring their cultural sensitivity and inclusivity is paramount. We\nintroduce our dataset, a year-long community-driven project covering all 22\nArab countries. The dataset includes instructions (input, response pairs) in\nboth Modern Standard Arabic (MSA) and dialectal Arabic (DA), spanning 20\ndiverse topics. Built by a team of 44 researchers across the Arab world, all of\nwhom are authors of this paper, our dataset offers a broad, inclusive\nperspective. We use our dataset to evaluate the cultural and dialectal\ncapabilities of several frontier LLMs, revealing notable limitations. For\ninstance, while closed-source LLMs generally exhibit strong performance, they\nare not without flaws, and smaller open-source models face greater challenges.\nMoreover, certain countries (e.g., Egypt, the UAE) appear better represented\nthan others (e.g., Iraq, Mauritania, Yemen). Our annotation guidelines, code,\nand data for reproducibility are publicly available.",
      "tldr_zh": "这篇论文介绍了 Palm 数据集，这是一个文化包容性和语言多样性的资源，针对阿拉伯大型语言模型 (LLMs)，由 44 名来自 22 个阿拉伯国家的研究员共同构建，涵盖 Modern Standard Arabic (MSA) 和 dialectal Arabic (DA) 的输入-响应对，以及 20 个多样化主题。数据集旨在评估前沿 LLMs 的文化和方言能力，结果显示闭源模型表现较强但存在缺陷，而开源模型面临更大挑战，且某些国家（如埃及、阿联酋）的代表性更佳，而其他国家（如伊拉克、毛里塔尼亚、也门）相对不足。通过公开注释指南、代码和数据，该数据集促进了研究的可重复性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "More information about our dataset is available at our project page:\n  https://github.com/UBC-NLP/palm",
      "pdf_url": "http://arxiv.org/pdf/2503.00151v1",
      "published_date": "2025-02-28 19:59:13 UTC",
      "updated_date": "2025-02-28 19:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:06:57.412553"
    },
    {
      "arxiv_id": "2503.00144v1",
      "title": "Learner and Instructor Needs in AI-Supported Programming Learning Tools: Design Implications for Features and Adaptive Control",
      "title_zh": "AI支持的编程学习工具中学习者和指导者的需求：功能和自适应控制的设计启示",
      "authors": [
        "Zihan Wu",
        "Yicheng Tang",
        "Barbara Ericson"
      ],
      "abstract": "AI-supported tools can help learners overcome challenges in programming\neducation by providing adaptive assistance. However, existing research often\nfocuses on individual tools rather than deriving broader design\nrecommendations. A key challenge in designing these systems is balancing\nlearner control with system-driven guidance. To explore user preferences for\nAI-supported programming learning tools, we conducted a participatory design\nstudy with 15 undergraduate novice programmers and 10 instructors to gather\ninsights on their desired help features and control preferences, as well as a\nfollow-up survey with 172 introductory programming students.\n  Our qualitative findings show that learners prefer help that is encouraging,\nincorporates visual aids, and includes peer-related insights, whereas\ninstructors prioritize scaffolding that reflects learners' progress and\nreinforces best practices. Both groups favor shared control, though learners\ngenerally prefer more autonomy, while instructors lean toward greater system\nguidance to prevent cognitive overload. Additionally, our interviews revealed\nindividual differences in control preferences.\n  Based on our findings, we propose design guidelines for AI-supported\nprogramming tools, particularly regarding user-centered help features and\nadaptive control mechanisms. Our work contributes to the human-centered design\nof AI-supported learning environments by informing the development of systems\nthat effectively balance autonomy and guidance, enhancing AI-supported\neducational tools for programming and beyond.",
      "tldr_zh": "这篇论文探讨了AI-supported programming learning tools中学习者和教师的需求，旨在平衡自适应辅助与用户控制。研究通过参与式设计研究（包括15名本科新手程序员和10名教师的访谈）以及后续对172名入门编程学生的调查，揭示了学习者偏好鼓励性帮助、视觉辅助和同伴见解，而教师更注重反映进步的支架和最佳实践强化。总体发现显示，双方支持共享控制，但学习者倾向于更多自治，教师则偏好系统指导以避免认知超载。论文据此提出设计指南，强调用户中心帮助特征和adaptive control机制，以提升AI-supported教育工具的人类中心设计。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "I.2; K.3"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00144v1",
      "published_date": "2025-02-28 19:50:10 UTC",
      "updated_date": "2025-02-28 19:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:07:09.326823"
    },
    {
      "arxiv_id": "2503.00128v1",
      "title": "AnnoCaseLaw: A Richly-Annotated Dataset For Benchmarking Explainable Legal Judgment Prediction",
      "title_zh": "AnnoCaseLaw：一个用于基准测试可解释法律判决预测的丰富注解数据集",
      "authors": [
        "Magnus Sesodia",
        "Alina Petrova",
        "John Armour",
        "Thomas Lukasiewicz",
        "Oana-Maria Camburu",
        "Puneet K. Dokania",
        "Philip Torr",
        "Christian Schroeder de Witt"
      ],
      "abstract": "Legal systems worldwide continue to struggle with overwhelming caseloads,\nlimited judicial resources, and growing complexities in legal proceedings.\nArtificial intelligence (AI) offers a promising solution, with Legal Judgment\nPrediction (LJP) -- the practice of predicting a court's decision from the case\nfacts -- emerging as a key research area. However, existing datasets often\nformulate the task of LJP unrealistically, not reflecting its true difficulty.\nThey also lack high-quality annotation essential for legal reasoning and\nexplainability. To address these shortcomings, we introduce AnnoCaseLaw, a\nfirst-of-its-kind dataset of 471 meticulously annotated U.S. Appeals Court\nnegligence cases. Each case is enriched with comprehensive, expert-labeled\nannotations that highlight key components of judicial decision making, along\nwith relevant legal concepts. Our dataset lays the groundwork for more\nhuman-aligned, explainable LJP models. We define three legally relevant tasks:\n(1) judgment prediction; (2) concept identification; and (3) automated case\nannotation, and establish a performance baseline using industry-leading large\nlanguage models (LLMs). Our results demonstrate that LJP remains a formidable\ntask, with application of legal precedent proving particularly difficult. Code\nand data are available at https://github.com/anonymouspolar1/annocaselaw.",
      "tldr_zh": "本论文介绍了AnnoCaseLaw数据集，这是一个针对可解释Legal Judgment Prediction (LJP)设计的富注释基准数据集，旨在解决现有LJP数据集在真实性、注释质量和法律推理方面的不足。该数据集包含471个美国上诉法院的疏忽案件，每个案件由专家标注了关键司法决策组件和相关法律概念，从而为更人性化的LJP模型奠定基础。论文定义了三个任务：(1) 判断预测；(2) 概念识别；(3) 自动化案例注释，并使用大型语言模型(LLMs)建立了性能基准，结果显示LJP任务高度挑战性，尤其是法律先例的应用。代码和数据已在GitHub上公开，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00128v1",
      "published_date": "2025-02-28 19:14:48 UTC",
      "updated_date": "2025-02-28 19:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:07:23.015064"
    },
    {
      "arxiv_id": "2503.16468v1",
      "title": "Towards properly implementing Theory of Mind in AI systems: An account of four misconceptions",
      "title_zh": "翻译失败",
      "authors": [
        "Ramira van der Meulen",
        "Rineke Verbrugge",
        "Max van Duijn"
      ],
      "abstract": "The search for effective collaboration between humans and computer systems is\none of the biggest challenges in Artificial Intelligence. One of the more\neffective mechanisms that humans use to coordinate with one another is theory\nof mind (ToM). ToM can be described as the ability to `take someone else's\nperspective and make estimations of their beliefs, desires and intentions, in\norder to make sense of their behaviour and attitudes towards the world'. If\nleveraged properly, this skill can be very useful in Human-AI collaboration.\n  This introduces the question how we implement ToM when building an AI system.\nHumans and AI Systems work quite differently, and ToM is a multifaceted\nconcept, each facet rooted in different research traditions across the\ncognitive and developmental sciences. We observe that researchers from\nartificial intelligence and the computing sciences, ourselves included, often\nhave difficulties finding their way in the ToM literature. In this paper, we\nidentify four common misconceptions around ToM that we believe should be taken\ninto account when developing an AI system. We have hyperbolised these\nmisconceptions for the sake of the argument, but add nuance in their\ndiscussion.\n  The misconceptions we discuss are:\n  (1) \"Humans Use a ToM Module, So AI Systems Should As Well\".\n  (2) \"Every Social Interaction Requires (Advanced) ToM\".\n  (3) \"All ToM is the Same\".\n  (4) \"Current Systems Already Have ToM\".\n  After discussing the misconception, we end each section by providing\ntentative guidelines on how the misconception can be overcome.",
      "tldr_zh": "该论文探讨了在AI系统中正确实现Theory of Mind (ToM)——即理解他人信念、欲望和意图的能力——以提升人类-AI协作的重要性。作者识别了四个常见误解：(1) “Humans Use a ToM Module, So AI Systems Should As Well”；(2) “Every Social Interaction Requires (Advanced) ToM”；(3) “All ToM is the Same”；以及(4) “Current Systems Already Have ToM”。通过分析这些误解的根源和细微差别，论文为AI开发提供初步指导，帮助避免这些错误，从而更好地整合ToM于AI系统中。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, draft version",
      "pdf_url": "http://arxiv.org/pdf/2503.16468v1",
      "published_date": "2025-02-28 19:12:35 UTC",
      "updated_date": "2025-02-28 19:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:07:34.449914"
    },
    {
      "arxiv_id": "2503.00124v1",
      "title": "Evaluation of LLMs-based Hidden States as Author Representations for Psychological Human-Centered NLP Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Soni",
        "Pranav Chitale",
        "Khushboo Singh",
        "Niranjan Balasubramanian",
        "H. Andrew Schwartz"
      ],
      "abstract": "Like most of NLP, models for human-centered NLP tasks -- tasks attempting to\nassess author-level information -- predominantly use representations derived\nfrom hidden states of Transformer-based LLMs. However, what component of the LM\nis used for the representation varies widely. Moreover, there is a need for\nHuman Language Models (HuLMs) that implicitly model the author and provide a\nuser-level hidden state. Here, we systematically evaluate different ways of\nrepresenting documents and users using different LM and HuLM architectures to\npredict task outcomes as both dynamically changing states and averaged\ntrait-like user-level attributes of valence, arousal, empathy, and distress. We\nfind that representing documents as an average of the token hidden states\nperforms the best generally. Further, while a user-level hidden state itself is\nrarely the best representation, we find its inclusion in the model strengthens\ntoken or document embeddings used to derive document- and user-level\nrepresentations resulting in best performances.",
      "tldr_zh": "这篇论文评估了基于 LLMs 的隐藏状态作为作者表示在心理人类中心 NLP 任务中的效果，这些任务涉及预测作者的动态状态或特征属性，如 valence, arousal, empathy 和 distress。研究通过系统比较不同 LM 和 HuLM 架构，测试了文档和用户表示的各种方式，发现将文档表示为 token 隐藏状态的平均值通常获得最佳性能。同时，虽然用户级隐藏状态本身并非最佳选择，但将其纳入模型能增强 token 或文档嵌入，从而显著改善文档级和用户级预测结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.00124v1",
      "published_date": "2025-02-28 19:10:06 UTC",
      "updated_date": "2025-02-28 19:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:07:45.714100"
    },
    {
      "arxiv_id": "2502.21309v2",
      "title": "FANformer: Improving Large Language Models Through Effective Periodicity Modeling",
      "title_zh": "FANformer：通过有效的周期性建模改进大型语言模型",
      "authors": [
        "Yihong Dong",
        "Ge Li",
        "Xue Jiang",
        "Yongding Tao",
        "Kechi Zhang",
        "Hao Zhu",
        "Huanyu Liu",
        "Jiazheng Ding",
        "Jia Li",
        "Jinliang Deng",
        "Hong Mei"
      ],
      "abstract": "Periodicity, as one of the most important basic characteristics, lays the\nfoundation for facilitating structured knowledge acquisition and systematic\ncognitive processes within human learning paradigms. However, the potential\nflaws of periodicity modeling in Transformer affect the learning efficiency and\nestablishment of underlying principles from data for large language models\n(LLMs) built upon it. In this paper, we demonstrate that integrating effective\nperiodicity modeling can improve the learning efficiency and performance of\nLLMs. We introduce FANformer, which adapts Fourier Analysis Network (FAN) into\nattention mechanism to achieve efficient periodicity modeling, by modifying the\nfeature projection process of attention mechanism. Extensive experimental\nresults on language modeling show that FANformer consistently outperforms\nTransformer when scaling up model size and training tokens, underscoring its\nsuperior learning efficiency. Our pretrained FANformer-1B exhibits marked\nimprovements on downstream tasks compared to open-source LLMs with similar\nmodel parameters or training tokens. Moreover, we reveal that FANformer\nexhibits superior ability to learn and apply rules for reasoning compared to\nTransformer. The results position FANformer as an effective and promising\narchitecture for advancing LLMs.",
      "tldr_zh": "这篇论文指出，Transformer 在周期性建模方面存在缺陷，影响了大型语言模型(LLMs)的学习效率和性能。作者引入了 FANformer，通过将 Fourier Analysis Network (FAN) 融入注意力机制的特征投影过程，实现有效的周期性建模。实验结果显示，FANformer 在语言建模任务中比 Transformer 表现出色，尤其在模型规模和训练标记增加时，且在下游任务和推理规则应用上具有显著优势，将其定位为推进 LLMs 的有前景架构。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21309v2",
      "published_date": "2025-02-28 18:52:24 UTC",
      "updated_date": "2025-05-17 13:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:07:58.274071"
    },
    {
      "arxiv_id": "2503.00096v2",
      "title": "BixBench: a Comprehensive Benchmark for LLM-based Agents in Computational Biology",
      "title_zh": "翻译失败",
      "authors": [
        "Ludovico Mitchener",
        "Jon M Laurent",
        "Benjamin Tenmann",
        "Siddharth Narayanan",
        "Geemi P Wellawatte",
        "Andrew White",
        "Lorenzo Sani",
        "Samuel G Rodriques"
      ],
      "abstract": "Large Language Models (LLMs) and LLM-based agents show great promise in\naccelerating scientific research. Existing benchmarks for measuring this\npotential and guiding future development continue to evolve from pure recall\nand rote knowledge tasks, towards more practical work such as literature review\nand experimental planning. Bioinformatics is a domain where fully autonomous\nAI-driven discovery may be near, but no extensive benchmarks for measuring\nprogress have been introduced to date. We therefore present the Bioinformatics\nBenchmark (BixBench), a dataset comprising over 50 real-world scenarios of\npractical biological data analysis with nearly 300 associated open-answer\nquestions designed to measure the ability of LLM-based agents to explore\nbiological datasets, perform long, multi-step analytical trajectories, and\ninterpret the nuanced results of those analyses. We evaluate the performance of\ntwo frontier LLMs (GPT-4o and Claude 3.5 Sonnet) using a custom agent framework\nwe open source. We find that even the latest frontier models only achieve 17%\naccuracy in the open-answer regime, and no better than random in a\nmultiple-choice setting. By exposing the current limitations of frontier\nmodels, we hope BixBench can spur the development of agents capable of\nconducting rigorous bioinformatic analysis and accelerate scientific discovery.",
      "tldr_zh": "这篇论文引入了 BixBench，这是一个全面的基准，用于评估基于 LLM（Large Language Models）的代理在计算生物学中的性能。BixBench 包含超过 50 个真实世界生物数据分析场景和近 300 个开放式问题，旨在测试代理探索数据集、执行多步分析以及解释复杂结果的能力。研究使用开源代理框架评估了前沿模型 GPT-4o 和 Claude 3.5 Sonnet，结果显示这些模型在开放式问题上仅达到 17% 的准确率，在多选题上不优于随机表现。通过暴露当前 LLM 的局限性，作者希望 BixBench 能推动代理技术的进步，加速科学发现。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "8 main text pages, 5 main figures",
      "pdf_url": "http://arxiv.org/pdf/2503.00096v2",
      "published_date": "2025-02-28 18:47:57 UTC",
      "updated_date": "2025-03-08 00:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:08:11.263485"
    },
    {
      "arxiv_id": "2502.21304v1",
      "title": "Clustering Context in Off-Policy Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Guzman-Olivares",
        "Philipp Schmidt",
        "Jacek Golebiowski",
        "Artur Bekasov"
      ],
      "abstract": "Off-policy evaluation can leverage logged data to estimate the effectiveness\nof new policies in e-commerce, search engines, media streaming services, or\nautomatic diagnostic tools in healthcare. However, the performance of baseline\noff-policy estimators like IPS deteriorates when the logging policy\nsignificantly differs from the evaluation policy. Recent work proposes sharing\ninformation across similar actions to mitigate this problem. In this work, we\npropose an alternative estimator that shares information across similar\ncontexts using clustering. We study the theoretical properties of the proposed\nestimator, characterizing its bias and variance under different conditions. We\nalso compare the performance of the proposed estimator and existing approaches\nin various synthetic problems, as well as a real-world recommendation dataset.\nOur experimental results confirm that clustering contexts improves estimation\naccuracy, especially in deficient information settings.",
      "tldr_zh": "这篇论文针对Off-Policy Evaluation中的挑战，提出了一种新估算器，通过Clustering Context（聚类上下文）来共享类似环境的信息，从而缓解日志策略（logging policy）与评估策略（evaluation policy）差异导致的性能下降问题。作者分析了该估算器的理论属性，包括偏差和方差，并在不同条件下进行了表征。与基线方法如IPS相比，实验结果显示，该方法在合成问题和真实推荐数据集上显著提高了估计准确性，尤其在信息不足的场景中。总的来说，这一创新为电商、搜索引擎等领域提供了更可靠的策略评估工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 25 figures, 2 tables. AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.21304v1",
      "published_date": "2025-02-28 18:40:41 UTC",
      "updated_date": "2025-02-28 18:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:08:21.945149"
    },
    {
      "arxiv_id": "2502.21290v1",
      "title": "Contextualizing biological perturbation experiments through language",
      "title_zh": "翻译失败",
      "authors": [
        "Menghua Wu",
        "Russell Littman",
        "Jacob Levine",
        "Lin Qiu",
        "Tommaso Biancalani",
        "David Richmond",
        "Jan-Christian Huetter"
      ],
      "abstract": "High-content perturbation experiments allow scientists to probe biomolecular\nsystems at unprecedented resolution, but experimental and analysis costs pose\nsignificant barriers to widespread adoption. Machine learning has the potential\nto guide efficient exploration of the perturbation space and extract novel\ninsights from these data. However, current approaches neglect the semantic\nrichness of the relevant biology, and their objectives are misaligned with\ndownstream biological analyses. In this paper, we hypothesize that large\nlanguage models (LLMs) present a natural medium for representing complex\nbiological relationships and rationalizing experimental outcomes. We propose\nPerturbQA, a benchmark for structured reasoning over perturbation experiments.\nUnlike current benchmarks that primarily interrogate existing knowledge,\nPerturbQA is inspired by open problems in perturbation modeling: prediction of\ndifferential expression and change of direction for unseen perturbations, and\ngene set enrichment. We evaluate state-of-the-art machine learning and\nstatistical approaches for modeling perturbations, as well as standard LLM\nreasoning strategies, and we find that current methods perform poorly on\nPerturbQA. As a proof of feasibility, we introduce Summer (SUMMarize, retrievE,\nand answeR, a simple, domain-informed LLM framework that matches or exceeds the\ncurrent state-of-the-art. Our code and data are publicly available at\nhttps://github.com/genentech/PerturbQA.",
      "tldr_zh": "该论文探讨了如何利用大型语言模型（LLMs）来语境化生物扰动实验，以克服实验成本高和现有方法忽略生物语义的问题。研究者提出 PerturbQA，这是一个针对扰动实验的结构化推理基准，专注于预测未见扰动的差异表达、方向变化和基因集富集等开放性挑战。实验评估显示，当前机器学习、统计方法和LLM策略在PerturbQA上表现不佳，而作者引入的Summer框架（一个基于域知识的LLM系统）则匹配或超过了现有最先进水平。该框架通过总结、检索和回答机制提升了生物实验分析的效率，并公开了代码和数据以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "The Thirteenth International Conference on Learning Representations\n  (2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.21290v1",
      "published_date": "2025-02-28 18:15:31 UTC",
      "updated_date": "2025-02-28 18:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:08:34.600549"
    },
    {
      "arxiv_id": "2502.21279v1",
      "title": "L-Lipschitz Gershgorin ResNet Network",
      "title_zh": "L-李普希茨 Gersh",
      "authors": [
        "Marius F. R. Juston",
        "William R. Norris",
        "Dustin Nottage",
        "Ahmet Soylemezoglu"
      ],
      "abstract": "Deep residual networks (ResNets) have demonstrated outstanding success in\ncomputer vision tasks, attributed to their ability to maintain gradient flow\nthrough deep architectures. Simultaneously, controlling the Lipschitz bound in\nneural networks has emerged as an essential area of research for enhancing\nadversarial robustness and network certifiability. This paper uses a rigorous\napproach to design $\\mathcal{L}$-Lipschitz deep residual networks using a\nLinear Matrix Inequality (LMI) framework. The ResNet architecture was\nreformulated as a pseudo-tri-diagonal LMI with off-diagonal elements and\nderived closed-form constraints on network parameters to ensure\n$\\mathcal{L}$-Lipschitz continuity. To address the lack of explicit eigenvalue\ncomputations for such matrix structures, the Gershgorin circle theorem was\nemployed to approximate eigenvalue locations, guaranteeing the LMI's negative\nsemi-definiteness. Our contributions include a provable parameterization\nmethodology for constructing Lipschitz-constrained networks and a compositional\nframework for managing recursive systems within hierarchical architectures.\nThese findings enable robust network designs applicable to adversarial\nrobustness, certified training, and control systems. However, a limitation was\nidentified in the Gershgorin-based approximations, which over-constrain the\nsystem, suppressing non-linear dynamics and diminishing the network's\nexpressive capacity.",
      "tldr_zh": "本论文提出了一种L-Lipschitz Gershgorin ResNet网络设计方法，旨在通过控制Lipschitz边界来提升深度残差网络(ResNets)在计算机视觉任务中的对抗鲁棒性和网络可证性。作者使用Linear Matrix Inequality (LMI)框架重新表述ResNet为伪三对角矩阵，并结合Gershgorin circle theorem近似特征值位置，以推导出网络参数的闭合形式约束，确保L-Lipschitz连续性。贡献包括可证明的参数化方法和组合框架，用于构建鲁棒网络，适用于对抗鲁棒性、认证训练和控制系统；然而，该方法存在Gershgorin-based近似过度约束的限制，可能抑制非线性动态并降低网络的表达能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.21279v1",
      "published_date": "2025-02-28 17:57:57 UTC",
      "updated_date": "2025-02-28 17:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:08:46.981968"
    },
    {
      "arxiv_id": "2502.21274v1",
      "title": "BAnG: Bidirectional Anchored Generation for Conditional RNA Design",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Klypa",
        "Alberto Bietti",
        "Sergei Grudinin"
      ],
      "abstract": "Designing RNA molecules that interact with specific proteins is a critical\nchallenge in experimental and computational biology. Existing computational\napproaches require a substantial amount of experimentally determined RNA\nsequences for each specific protein or a detailed knowledge of RNA structure,\nrestricting their utility in practice. To address this limitation, we develop\nRNA-BAnG, a deep learning-based model designed to generate RNA sequences for\nprotein interactions without these requirements. Central to our approach is a\nnovel generative method, Bidirectional Anchored Generation (BAnG), which\nleverages the observation that protein-binding RNA sequences often contain\nfunctional binding motifs embedded within broader sequence contexts. We first\nvalidate our method on generic synthetic tasks involving similar localized\nmotifs to those appearing in RNAs, demonstrating its benefits over existing\ngenerative approaches. We then evaluate our model on biological sequences,\nshowing its effectiveness for conditional RNA sequence design given a binding\nprotein.",
      "tldr_zh": "该研究针对设计与特定蛋白质交互的 RNA 分子面临的挑战，开发了 RNA-BAnG 模型，该模型无需大量实验数据或详细 RNA 结构知识即可生成目标序列。核心方法 Bidirectional Anchored Generation (BAnG) 利用蛋白质结合 RNA 中嵌入的功能性结合基序，通过双向锚定生成技术来构建序列。实验结果显示，该方法在合成任务和生物序列评估中表现出色，优于现有生成方法，为条件 RNA 设计提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21274v1",
      "published_date": "2025-02-28 17:51:00 UTC",
      "updated_date": "2025-02-28 17:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:09:13.563479"
    },
    {
      "arxiv_id": "2502.21271v1",
      "title": "Adaptive Keyframe Sampling for Long Video Understanding",
      "title_zh": "自适应关键帧采样用于长视频理解",
      "authors": [
        "Xi Tang",
        "Jihao Qiu",
        "Lingxi Xie",
        "Yunjie Tian",
        "Jianbin Jiao",
        "Qixiang Ye"
      ],
      "abstract": "Multimodal large language models (MLLMs) have enabled open-world visual\nunderstanding by injecting visual input as extra tokens into large language\nmodels (LLMs) as contexts. However, when the visual input changes from a single\nimage to a long video, the above paradigm encounters difficulty because the\nvast amount of video tokens has significantly exceeded the maximal capacity of\nMLLMs. Therefore, existing video-based MLLMs are mostly established upon\nsampling a small portion of tokens from input data, which can cause key\ninformation to be lost and thus produce incorrect answers. This paper presents\na simple yet effective algorithm named Adaptive Keyframe Sampling (AKS). It\ninserts a plug-and-play module known as keyframe selection, which aims to\nmaximize the useful information with a fixed number of video tokens. We\nformulate keyframe selection as an optimization involving (1) the relevance\nbetween the keyframes and the prompt, and (2) the coverage of the keyframes\nover the video, and present an adaptive algorithm to approximate the best\nsolution. Experiments on two long video understanding benchmarks validate that\nAdaptive Keyframe Sampling improves video QA accuracy (beyond strong baselines)\nupon selecting informative keyframes. Our study reveals the importance of\ninformation pre-filtering in video-based MLLMs. Code is available at\nhttps://github.com/ncTimTang/AKS.",
      "tldr_zh": "该论文针对多模态大语言模型 (MLLMs) 在处理长视频时面临的 token 容量限制问题，提出了一种简单有效的算法 Adaptive Keyframe Sampling (AKS)。AKS 通过插入一个可插拔的关键帧选择模块，优化关键帧与提示的相关性和对视频的覆盖，从而在固定 token 数量下最大化有用信息。实验结果显示，AKS 在两个长视频理解基准上显著提高了视频 QA 准确率，超过了强基线模型，并强调了信息预过滤在视频-based MLLMs 中的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2502.21271v1",
      "published_date": "2025-02-28 17:46:29 UTC",
      "updated_date": "2025-02-28 17:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:09:11.661358"
    },
    {
      "arxiv_id": "2502.21266v1",
      "title": "Supporting the development of Machine Learning for fundamental science in a federated Cloud with the AI_INFN platform",
      "title_zh": "翻译失败",
      "authors": [
        "Lucio Anderlini",
        "Matteo Barbetti",
        "Giulio Bianchini",
        "Diego Ciangottini",
        "Stefano Dal Pra",
        "Diego Michelotto",
        "Carmelo Pellegrino",
        "Rosa Petrini",
        "Alessandro Pascolini",
        "Daniele Spiga"
      ],
      "abstract": "Machine Learning (ML) is driving a revolution in the way scientists design,\ndevelop, and deploy data-intensive software. However, the adoption of ML\npresents new challenges for the computing infrastructure, particularly in terms\nof provisioning and orchestrating access to hardware accelerators for\ndevelopment, testing, and production. The INFN-funded project AI_INFN\n(\"Artificial Intelligence at INFN\") aims at fostering the adoption of ML\ntechniques within INFN use cases by providing support on multiple aspects,\nincluding the provision of AI-tailored computing resources. It leverages\ncloud-native solutions in the context of INFN Cloud, to share hardware\naccelerators as effectively as possible, ensuring the diversity of the\nInstitute's research activities is not compromised. In this contribution, we\nprovide an update on the commissioning of a Kubernetes platform designed to\nease the development of GPU-powered data analysis workflows and their\nscalability on heterogeneous, distributed computing resources, possibly\nfederated as Virtual Kubelets with the interLink provider.",
      "tldr_zh": "该研究探讨了 Machine Learning (ML) 在基础科学中的应用及其对计算基础设施的挑战，特别是硬件加速器的提供和编排。AI_INFN 项目旨在通过云原生解决方案在 federated Cloud 中共享 GPU 等资源，支持 INFN 用例的 ML 开发，确保研究多样性。项目还部署了 Kubernetes 平台，以简化 GPU 驱动的数据分析工作流，并实现其在异构、分布式资源（如 Virtual Kubelets 和 interLink provider）上的可伸缩性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "physics.data-an"
      ],
      "primary_category": "cs.DC",
      "comment": "Under review in EPJ Web of Conferences (CHEP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.21266v1",
      "published_date": "2025-02-28 17:42:58 UTC",
      "updated_date": "2025-02-28 17:42:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:09:25.913422"
    },
    {
      "arxiv_id": "2502.21267v1",
      "title": "ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Scarlatos",
        "Yusong Wu",
        "Ian Simon",
        "Adam Roberts",
        "Tim Cooijmans",
        "Natasha Jaques",
        "Cassie Tarakajian",
        "Cheng-Zhi Anna Huang"
      ],
      "abstract": "Recent advances in generative artificial intelligence (AI) have created\nmodels capable of high-quality musical content generation. However, little\nconsideration is given to how to use these models for real-time or cooperative\njamming musical applications because of crucial required features: low latency,\nthe ability to communicate planned actions, and the ability to adapt to user\ninput in real-time. To support these needs, we introduce ReaLJam, an interface\nand protocol for live musical jamming sessions between a human and a\nTransformer-based AI agent trained with reinforcement learning. We enable\nreal-time interactions using the concept of anticipation, where the agent\ncontinually predicts how the performance will unfold and visually conveys its\nplan to the user. We conduct a user study where experienced musicians jam in\nreal-time with the agent through ReaLJam. Our results demonstrate that ReaLJam\nenables enjoyable and musically interesting sessions, and we uncover important\ntakeaways for future work.",
      "tldr_zh": "该研究引入 ReaLJam，一种实时人类-AI 音乐即兴演奏接口和协议，利用 Reinforcement Learning-Tuned Transformers 训练 AI 代理，以实现低延迟互动。系统通过“anticipation”机制，让 AI 持续预测表演发展并视觉化传达计划，从而适应用户输入并沟通动作。用户研究显示，经验丰富的音乐家在使用 ReaLJam 时能获得 enjoyable 和 musically interesting 的会话，并为未来工作提供重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Published in Extended Abstracts of the CHI Conference on Human\n  Factors in Computing Systems (CHI EA '25), April 26-May 1, 2025, Yokohama,\n  Japan",
      "pdf_url": "http://arxiv.org/pdf/2502.21267v1",
      "published_date": "2025-02-28 17:42:58 UTC",
      "updated_date": "2025-02-28 17:42:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:09:36.810274"
    },
    {
      "arxiv_id": "2502.21264v2",
      "title": "Foundation Models -- A Panacea for Artificial Intelligence in Pathology?",
      "title_zh": "Foundation Models -- 病理学中人工智能的万能解决方案？",
      "authors": [
        "Nita Mulliqi",
        "Anders Blilie",
        "Xiaoyi Ji",
        "Kelvin Szolnoky",
        "Henrik Olsson",
        "Sol Erika Boman",
        "Matteo Titus",
        "Geraldine Martinez Gonzalez",
        "Julia Anna Mielcarz",
        "Masi Valkonen",
        "Einar Gudlaugsson",
        "Svein R. Kjosavik",
        "José Asenjo",
        "Marcello Gambacorta",
        "Paolo Libretti",
        "Marcin Braun",
        "Radzislaw Kordek",
        "Roman Łowicki",
        "Kristina Hotakainen",
        "Päivi Väre",
        "Bodil Ginnerup Pedersen",
        "Karina Dalsgaard Sørensen",
        "Benedicte Parm Ulhøi",
        "Pekka Ruusuvuori",
        "Brett Delahunt",
        "Hemamali Samaratunga",
        "Toyonori Tsuzuki",
        "Emilius A. M. Janssen",
        "Lars Egevad",
        "Martin Eklund",
        "Kimmo Kartasalo"
      ],
      "abstract": "The role of artificial intelligence (AI) in pathology has evolved from aiding\ndiagnostics to uncovering predictive morphological patterns in whole slide\nimages (WSIs). Recently, foundation models (FMs) leveraging self-supervised\npre-training have been widely advocated as a universal solution for diverse\ndownstream tasks. However, open questions remain about their clinical\napplicability and generalization advantages over end-to-end learning using\ntask-specific (TS) models. Here, we focused on AI with clinical-grade\nperformance for prostate cancer diagnosis and Gleason grading. We present the\nlargest validation of AI for this task, using over 100,000 core needle biopsies\nfrom 7,342 patients across 15 sites in 11 countries. We compared two FMs with a\nfully end-to-end TS model in a multiple instance learning framework. Our\nfindings challenge assumptions that FMs universally outperform TS models. While\nFMs demonstrated utility in data-scarce scenarios, their performance converged\nwith - and was in some cases surpassed by - TS models when sufficient labeled\ntraining data were available. Notably, extensive task-specific training\nmarkedly reduced clinically significant misgrading, misdiagnosis of challenging\nmorphologies, and variability across different WSI scanners. Additionally, FMs\nused up to 35 times more energy than the TS model, raising concerns about their\nsustainability. Our results underscore that while FMs offer clear advantages\nfor rapid prototyping and research, their role as a universal solution for\nclinically applicable medical AI remains uncertain. For high-stakes clinical\napplications, rigorous validation and consideration of task-specific training\nremain critically important. We advocate for integrating the strengths of FMs\nand end-to-end learning to achieve robust and resource-efficient AI pathology\nsolutions fit for clinical use.",
      "tldr_zh": "该论文探讨了Foundation Models (FMs) 是否能作为AI在病理学领域的万能解决方案，特别是用于前列腺癌诊断和Gleason评分。研究者使用超过10万份核心针活检样本，从11个国家的15个站点进行最大规模验证，比较了两个FMs与一个端到端Task-Specific (TS)模型在Multiple Instance Learning框架下的性能。结果显示，FMs在数据稀缺场景下表现出优势，但当有充足标记数据时，TS模型的准确性相当或更高，并显著减少了临床误诊和扫描器变异，同时TS模型的能源消耗低至FMs的1/35。该研究强调，FMs适合快速原型和研究，但并非临床应用的通用方案，建议整合FMs与端到端学习以实现更可靠、资源高效的AI病理解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "50 pages, 15 figures and an appendix (study protocol) which is\n  previously published, see https://doi.org/10.1101/2024.07.04.24309948;\n  updated authors list format",
      "pdf_url": "http://arxiv.org/pdf/2502.21264v2",
      "published_date": "2025-02-28 17:40:45 UTC",
      "updated_date": "2025-03-03 10:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:09:51.313962"
    },
    {
      "arxiv_id": "2502.21263v1",
      "title": "RuCCoD: Towards Automated ICD Coding in Russian",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandr Nesterov",
        "Andrey Sakhovskiy",
        "Ivan Sviridov",
        "Airat Valiev",
        "Vladimir Makharev",
        "Petr Anokhin",
        "Galina Zubkova",
        "Elena Tutubalina"
      ],
      "abstract": "This study investigates the feasibility of automating clinical coding in\nRussian, a language with limited biomedical resources. We present a new dataset\nfor ICD coding, which includes diagnosis fields from electronic health records\n(EHRs) annotated with over 10,000 entities and more than 1,500 unique ICD\ncodes. This dataset serves as a benchmark for several state-of-the-art models,\nincluding BERT, LLaMA with LoRA, and RAG, with additional experiments examining\ntransfer learning across domains (from PubMed abstracts to medical diagnosis)\nand terminologies (from UMLS concepts to ICD codes). We then apply the\nbest-performing model to label an in-house EHR dataset containing patient\nhistories from 2017 to 2021. Our experiments, conducted on a carefully curated\ntest set, demonstrate that training with the automated predicted codes leads to\na significant improvement in accuracy compared to manually annotated data from\nphysicians. We believe our findings offer valuable insights into the potential\nfor automating clinical coding in resource-limited languages like Russian,\nwhich could enhance clinical efficiency and data accuracy in these contexts.",
      "tldr_zh": "本研究探讨了在俄罗斯语这种资源有限的语言中自动化ICD编码的可行性，引入了一个新数据集，该数据集包含电子健康记录(EHRs)的诊断字段，标注了超过10,000个实体和1,500个独特ICD代码。研究者使用该数据集基准测试了多种先进模型，包括BERT、LLaMA with LoRA和RAG，并进行了跨领域转移学习实验（如从PubMed摘要到医疗诊断）和术语转移（如从UMLS概念到ICD代码）。实验结果显示，将最佳模型应用于2017-2021年内部EHR数据集时，使用自动预测代码训练的模型准确性显著高于医生手动标注数据，这为资源有限语言的临床编码自动化提供了宝贵见解，可能提升临床效率和数据准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21263v1",
      "published_date": "2025-02-28 17:40:24 UTC",
      "updated_date": "2025-02-28 17:40:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:10:03.969329"
    },
    {
      "arxiv_id": "2502.21262v1",
      "title": "Modeling Human Beliefs about AI Behavior for Scalable Oversight",
      "title_zh": "针对可扩展监督的人类对AI行为信念建模",
      "authors": [
        "Leon Lang",
        "Patrick Forré"
      ],
      "abstract": "Contemporary work in AI alignment often relies on human feedback to teach AI\nsystems human preferences and values. Yet as AI systems grow more capable,\nhuman feedback becomes increasingly unreliable. This raises the problem of\nscalable oversight: How can we supervise AI systems that exceed human\ncapabilities? In this work, we propose to model the human evaluator's beliefs\nabout the AI system's behavior to better interpret the human's feedback. We\nformalize human belief models and theoretically analyze their role in inferring\nhuman values. We then characterize the remaining ambiguity in this inference\nand conditions for which the ambiguity disappears. To mitigate reliance on\nexact belief models, we then introduce the relaxation of human belief model\ncovering. Finally, we propose using foundation models to construct covering\nbelief models, providing a new potential approach to scalable oversight.",
      "tldr_zh": "这篇论文针对AI对齐（AI alignment）中的可扩展监督（scalable oversight）问题，提出通过建模人类评估者对AI行为信念（human beliefs about AI behavior）的模型来提升反馈的可靠性，从而更好地推断人类偏好和价值观。作者形式化了人类信念模型（human belief models），并理论分析了其在价值观推断中的作用，同时探讨了剩余模糊性的条件和消除方式。最终，他们引入人类信念模型覆盖（human belief model covering）的松弛版本，并建议使用基础模型（foundation models）来构建这些模型，提供一种可扩展的监督新方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "53 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.21262v1",
      "published_date": "2025-02-28 17:39:55 UTC",
      "updated_date": "2025-02-28 17:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:10:16.307389"
    },
    {
      "arxiv_id": "2502.21250v1",
      "title": "Towards Developing Ethical Reasoners: Integrating Probabilistic Reasoning and Decision-Making for Complex AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Nijesh Upreti",
        "Jessica Ciupa",
        "Vaishak Belle"
      ],
      "abstract": "A computational ethics framework is essential for AI and autonomous systems\noperating in complex, real-world environments. Existing approaches often lack\nthe adaptability needed to integrate ethical principles into dynamic and\nambiguous contexts, limiting their effectiveness across diverse scenarios. To\naddress these challenges, we outline the necessary ingredients for building a\nholistic, meta-level framework that combines intermediate representations,\nprobabilistic reasoning, and knowledge representation. The specifications\ntherein emphasize scalability, supporting ethical reasoning at both individual\ndecision-making levels and within the collective dynamics of multi-agent\nsystems. By integrating theoretical principles with contextual factors, it\nfacilitates structured and context-aware decision-making, ensuring alignment\nwith overarching ethical standards. We further explore proposed theorems\noutlining how ethical reasoners should operate, offering a foundation for\npractical implementation. These constructs aim to support the development of\nrobust and ethically reliable AI systems capable of navigating the complexities\nof real-world moral decision-making scenarios.",
      "tldr_zh": "该论文针对AI和自主系统在复杂环境中进行伦理决策的挑战，提出一个整体的元级计算伦理框架，以解决现有方法在动态和模糊情境下的适应性不足问题。该框架整合了中间表示(intermediate representations)、概率推理(probabilistic reasoning)和知识表示(knowledge representation)，强调可扩展性，支持从个体决策到多智能体系统(multi-agent systems)的伦理推理。通过结合理论原则与上下文因素，该框架实现结构化和上下文感知的决策，并提出定理来指导伦理推理器的实际实施。该方法为开发鲁棒且伦理可靠的AI系统提供了基础，帮助其应对真实世界的道德决策场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21250v1",
      "published_date": "2025-02-28 17:25:11 UTC",
      "updated_date": "2025-02-28 17:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:10:27.490270"
    },
    {
      "arxiv_id": "2502.21236v1",
      "title": "Transforming Tuberculosis Care: Optimizing Large Language Models For Enhanced Clinician-Patient Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Filienko",
        "Mahek Nizar",
        "Javier Roberti",
        "Denise Galdamez",
        "Haroon Jakher",
        "Sarah Iribarren",
        "Weichao Yuwen",
        "Martine De Cock"
      ],
      "abstract": "Tuberculosis (TB) is the leading cause of death from an infectious disease\nglobally, with the highest burden in low- and middle-income countries. In these\nregions, limited healthcare access and high patient-to-provider ratios impede\neffective patient support, communication, and treatment completion. To bridge\nthis gap, we propose integrating a specialized Large Language Model into an\nefficacious digital adherence technology to augment interactive communication\nwith treatment supporters. This AI-powered approach, operating within a\nhuman-in-the-loop framework, aims to enhance patient engagement and improve TB\ntreatment outcomes.",
      "tldr_zh": "本研究针对结核病(TB)作为全球主要传染病死因的问题，特别是低中收入国家医疗访问有限和高患者比导致的沟通与治疗挑战，提出了一种解决方案。方法是将优化后的 Large Language Model 整合到数字依从性技术中，增强临床医生-患者互动沟通，并采用 human-in-the-loop 框架确保AI辅助的可靠性。该方法旨在提高患者参与度，最终改善TB治疗效果。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "GenAI4Health at AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2502.21236v1",
      "published_date": "2025-02-28 17:05:13 UTC",
      "updated_date": "2025-02-28 17:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:10:42.907235"
    },
    {
      "arxiv_id": "2502.21231v1",
      "title": "ByteScale: Efficient Scaling of LLM Training with a 2048K Context Length on More Than 12,000 GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Ge",
        "Junda Feng",
        "Qi Huang",
        "Fangcheng Fu",
        "Xiaonan Nie",
        "Lei Zuo",
        "Haibin Lin",
        "Bin Cui",
        "Xin Liu"
      ],
      "abstract": "Scaling long-context ability is essential for Large Language Models (LLMs).\nTo amortize the memory consumption across multiple devices in long-context\ntraining, inter-data partitioning (a.k.a. Data Parallelism) and intra-data\npartitioning (a.k.a. Context Parallelism) are commonly used. Current training\nframeworks predominantly treat the two techniques as orthogonal, and establish\nstatic communication groups to organize the devices as a static mesh (e.g., a\n2D mesh). However, the sequences for LLM training typically vary in lengths, no\nmatter for texts, multi-modalities or reinforcement learning. The mismatch\nbetween data heterogeneity and static mesh causes redundant communication and\nimbalanced computation, degrading the training efficiency.\n  In this work, we introduce ByteScale, an efficient, flexible, and scalable\nLLM training framework for large-scale mixed training of long and short\nsequences. The core of ByteScale is a novel parallelism strategy, namely Hybrid\nData Parallelism (HDP), which unifies the inter- and intra-data partitioning\nwith a dynamic mesh design. In particular, we build a communication optimizer,\nwhich eliminates the redundant communication for short sequences by data-aware\nsharding and dynamic communication, and further compresses the communication\ncost for long sequences by selective offloading. Besides, we also develop a\nbalance scheduler to mitigate the imbalanced computation by parallelism-aware\ndata assignment. We evaluate ByteScale with the model sizes ranging from 7B to\n141B, context lengths from 256K to 2048K, on a production cluster with more\nthan 12,000 GPUs. Experiment results show that ByteScale outperforms the\nstate-of-the-art training system by up to 7.89x.",
      "tldr_zh": "ByteScale 是一种高效的 LLM 训练框架，旨在解决长上下文训练中数据异质性导致的冗余通信和计算不平衡问题，支持在超过 12,000 GPUs 上处理长达 2048K 的上下文长度。框架的核心是 Hybrid Data Parallelism (HDP) 策略，该策略统一了 Data Parallelism 和 Context Parallelism，通过动态网格设计、通信优化器（包括数据感知分片和选择性卸载）以及平衡调度器（通过并行感知数据分配）来优化训练过程。实验结果表明，ByteScale 在模型大小从 7B 到 141B 的范围内，比最先进系统提升效率高达 7.89 倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "12 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.21231v1",
      "published_date": "2025-02-28 17:01:03 UTC",
      "updated_date": "2025-02-28 17:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:10:53.306144"
    },
    {
      "arxiv_id": "2502.21228v2",
      "title": "ECLeKTic: a Novel Challenge Set for Evaluation of Cross-Lingual Knowledge Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Omer Goldman",
        "Uri Shaham",
        "Dan Malkin",
        "Sivan Eiger",
        "Avinatan Hassidim",
        "Yossi Matias",
        "Joshua Maynez",
        "Adi Mayrav Gilady",
        "Jason Riesa",
        "Shruti Rijhwani",
        "Laura Rimell",
        "Idan Szpektor",
        "Reut Tsarfaty",
        "Matan Eyal"
      ],
      "abstract": "To achieve equitable performance across languages, multilingual large\nlanguage models (LLMs) must be able to abstract knowledge beyond the language\nin which it was acquired. However, the current literature lacks reliable ways\nto measure LLMs' capability of cross-lingual knowledge transfer. To that end,\nwe present ECLeKTic, a multilingual closed-book QA (CBQA) dataset that\nEvaluates Cross-Lingual Knowledge Transfer in a simple, black-box manner. We\ndetected information with uneven coverage across languages by controlling for\npresence and absence of Wikipedia articles in 12 languages. We generated\nknowledge-seeking questions in a source language, for which the answer appears\nin a relevant Wikipedia article and translated them to all other 11 languages,\nfor which the respective Wikipedias lack equivalent articles. Assuming that\nWikipedia reflects the prominent knowledge in the LLM's training data, to solve\nECLeKTic's CBQA task the model is required to transfer knowledge between\nlanguages. Experimenting with 8 LLMs, we show that SOTA models struggle to\neffectively share knowledge across, languages even if they can predict the\nanswer well for queries in the same language the knowledge was acquired in.",
      "tldr_zh": "这篇论文引入了 ECLeKTic，这是一个新型的多语言闭卷问答(CBQA)数据集，旨在评估大型语言模型(LLMs)在跨语言知识转移方面的能力。研究者通过控制12种语言中维基百科文章的覆盖情况，生成源语言的知识寻求问题并翻译到其他语言，从而测试模型是否能从训练数据中抽象并转移知识。实验结果显示，即使SOTA模型在相同语言的查询中表现良好，它们在跨语言知识共享上仍面临显著挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21228v2",
      "published_date": "2025-02-28 16:59:30 UTC",
      "updated_date": "2025-03-03 09:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:11:04.534968"
    },
    {
      "arxiv_id": "2503.00093v1",
      "title": "Rethinking LLM Bias Probing Using Lessons from the Social Sciences",
      "title_zh": "翻译失败",
      "authors": [
        "Kirsten N. Morehouse",
        "Siddharth Swaroop",
        "Weiwei Pan"
      ],
      "abstract": "The proliferation of LLM bias probes introduces three significant challenges:\n(1) we lack principled criteria for choosing appropriate probes, (2) we lack a\nsystem for reconciling conflicting results across probes, and (3) we lack\nformal frameworks for reasoning about when (and why) probe results will\ngeneralize to real user behavior. We address these challenges by systematizing\nLLM social bias probing using actionable insights from social sciences. We then\nintroduce EcoLevels - a framework that helps (a) determine appropriate bias\nprobes, (b) reconcile conflicting findings across probes, and (c) generate\npredictions about bias generalization. Overall, we ground our analysis in\nsocial science research because many LLM probes are direct applications of\nhuman probes, and these fields have faced similar challenges when studying\nsocial bias in humans. Based on our work, we suggest how the next generation of\nLLM bias probing can (and should) benefit from decades of social science\nresearch.",
      "tldr_zh": "该论文重新审视了LLM（Large Language Models）偏见探测的挑战，包括缺乏选择适当探测的标准、调和冲突结果的系统，以及预测结果推广的正式框架。作者借鉴社会科学的见解来系统化LLM社会偏见探测，引入了EcoLevels框架，用于确定合适的偏见探测、调和不同发现的冲突，以及生成关于偏见推广的预测。总体上，该研究强调LLM偏见探测应从社会科学的数十年研究中汲取经验，以提升其有效性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00093v1",
      "published_date": "2025-02-28 16:53:18 UTC",
      "updated_date": "2025-02-28 16:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:11:15.315630"
    },
    {
      "arxiv_id": "2502.21220v1",
      "title": "XAIxArts Manifesto: Explainable AI for the Arts",
      "title_zh": "翻译失败",
      "authors": [
        "Nick Bryan-Kinns",
        "Shuoyang Jasper Zheng",
        "Francisco Castro",
        "Makayla Lewis",
        "Jia-Rey Chang",
        "Gabriel Vigliensoni",
        "Terence Broad",
        "Michael Clemens",
        "Elizabeth Wilson"
      ],
      "abstract": "Explainable AI (XAI) is concerned with how to make AI models more\nunderstandable to people. To date these explanations have predominantly been\ntechnocentric - mechanistic or productivity oriented. This paper introduces the\nExplainable AI for the Arts (XAIxArts) manifesto to provoke new ways of\nthinking about explainability and AI beyond technocentric discourses.\nManifestos offer a means to communicate ideas, amplify unheard voices, and\nfoster reflection on practice. To supports the co-creation and revision of the\nXAIxArts manifesto we combine a World Caf\\'e style discussion format with a\nliving manifesto to question four core themes: 1) Empowerment, Inclusion, and\nFairness; 2) Valuing Artistic Practice; 3) Hacking and Glitches; and 4)\nOpenness. Through our interactive living manifesto experience we invite\nparticipants to actively engage in shaping this XIAxArts vision within the CHI\ncommunity and beyond.",
      "tldr_zh": "这篇论文提出 XAIxArts 宣言，旨在扩展 Explainable AI (XAI) 的概念，超越技术中心主义，转向艺术领域的创新思考和实践。该宣言通过 World Café 风格讨论和 living manifesto 形式，促进对四个核心主题的共同探索：赋权、包容性和公平性；重视艺术实践；黑客和故障；以及开放性。通过互动体验，论文邀请 CHI 社区及更广泛参与者共同塑造 XAIxArts 愿景，推动 AI 可解释性在艺术中的公平与创新应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Author version of paper in: Extended Abstracts of the CHI Conference\n  on Human Factors in Computing Systems, April 26-May 1, 2025, Yokohama, Japan\n  DOI 10.1145/3706599.3716227 ISBN 979-8-4007-1395-8/25/04",
      "pdf_url": "http://arxiv.org/pdf/2502.21220v1",
      "published_date": "2025-02-28 16:50:17 UTC",
      "updated_date": "2025-02-28 16:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:11:27.653642"
    },
    {
      "arxiv_id": "2502.21216v1",
      "title": "An Algebraic Framework for Hierarchical Probabilistic Abstraction",
      "title_zh": "用于层次化概率抽象的代数框架",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "abstract": "Abstraction is essential for reducing the complexity of systems across\ndiverse fields, yet designing effective abstraction methodology for\nprobabilistic models is inherently challenging due to stochastic behaviors and\nuncertainties. Current approaches often distill detailed probabilistic data\ninto higher-level summaries to support tractable and interpretable analyses,\nthough they typically struggle to fully represent the relational and\nprobabilistic hierarchies through single-layered abstractions. We introduce a\nhierarchical probabilistic abstraction framework aimed at addressing these\nchallenges by extending a measure-theoretic foundation for hierarchical\nabstraction. The framework enables modular problem-solving via layered\nmappings, facilitating both detailed layer-specific analysis and a cohesive\nsystem-wide understanding. This approach bridges high-level conceptualization\nwith low-level perceptual data, enhancing interpretability and allowing layered\nanalysis. Our framework provides a robust foundation for abstraction analysis\nacross AI subfields, particularly in aligning System 1 and System 2 thinking,\nthereby supporting the development of diverse abstraction methodologies.",
      "tldr_zh": "本文提出一个algebraic framework for hierarchical probabilistic abstraction，以解决概率模型中抽象设计的挑战，该框架基于measure-theoretic foundation，通过分层映射实现模块化问题解决。相比传统单层抽象方法，该框架能全面表示关系和概率层次，支持详细的层级分析和系统整体理解。最终，它桥接高层概念化与底层感知数据，提升AI子领域的可解释性，并促进System 1 and System 2 thinking的整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21216v1",
      "published_date": "2025-02-28 16:47:42 UTC",
      "updated_date": "2025-02-28 16:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:11:39.419228"
    },
    {
      "arxiv_id": "2502.21212v1",
      "title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Huang",
        "Zixuan Wang",
        "Jason D. Lee"
      ],
      "abstract": "Chain of Thought (CoT) prompting has been shown to significantly improve the\nperformance of large language models (LLMs), particularly in arithmetic and\nreasoning tasks, by instructing the model to produce intermediate reasoning\nsteps. Despite the remarkable empirical success of CoT and its theoretical\nadvantages in enhancing expressivity, the mechanisms underlying CoT training\nremain largely unexplored. In this paper, we study the training dynamics of\ntransformers over a CoT objective on an in-context weight prediction task for\nlinear regression. We prove that while a one-layer linear transformer without\nCoT can only implement a single step of gradient descent (GD) and fails to\nrecover the ground-truth weight vector, a transformer with CoT prompting can\nlearn to perform multi-step GD autoregressively, achieving near-exact recovery.\nFurthermore, we show that the trained transformer effectively generalizes on\nthe unseen data. With our technique, we also show that looped transformers\nsignificantly improve final performance compared to transformers without\nlooping in the in-context learning of linear regression. Empirically, we\ndemonstrate that CoT prompting yields substantial performance improvements.",
      "tldr_zh": "这篇论文探讨了 Chain of Thought (CoT) 提示如何提升大型语言模型 (LLMs) 在算术和推理任务中的表现，通过生成中间推理步骤来增强模型的表达能力。在线性回归的 in-context 权重预测任务上，论文证明了使用 CoT 的 transformer 可以学习实现多步 Gradient Descent (GD)，从而实现近似精确的权重恢复，并有效泛化到未见过的数据。相比之下，没有 CoT 的一层线性 transformer 仅能执行单步 GD，而 looped transformers 则显著提高了性能，实证实验进一步验证了 CoT 的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2502.21212v1",
      "published_date": "2025-02-28 16:40:38 UTC",
      "updated_date": "2025-02-28 16:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:11:53.015107"
    },
    {
      "arxiv_id": "2503.00092v1",
      "title": "EdgeAIGuard: Agentic LLMs for Minor Protection in Digital Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Ghulam Mujtaba",
        "Sunder Ali Khowaja",
        "Kapal Dev"
      ],
      "abstract": "Social media has become integral to minors' daily lives and is used for\nvarious purposes, such as making friends, exploring shared interests, and\nengaging in educational activities. However, the increase in screen time has\nalso led to heightened challenges, including cyberbullying, online grooming,\nand exploitations posed by malicious actors. Traditional content moderation\ntechniques have proven ineffective against exploiters' evolving tactics. To\naddress these growing challenges, we propose the EdgeAIGuard content moderation\napproach that is designed to protect minors from online grooming and various\nforms of digital exploitation. The proposed method comprises a multi-agent\narchitecture deployed strategically at the network edge to enable rapid\ndetection with low latency and prevent harmful content targeting minors. The\nexperimental results show the proposed method is significantly more effective\nthan the existing approaches.",
      "tldr_zh": "该论文探讨了社交媒体对未成年人的双重影响，包括交友和教育益处，但也面临网络欺凌、在线诱导和数字剥削等风险。针对传统内容审核方法的不足，研究提出 EdgeAIGuard，这是一种基于 Agentic LLMs 的多智能体架构，部署在网络边缘以实现快速检测和低延迟，保护未成年人免受有害内容。实验结果显示，该方法比现有方法显著更有效，为数字空间的安全防护提供了新途径。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00092v1",
      "published_date": "2025-02-28 16:29:34 UTC",
      "updated_date": "2025-02-28 16:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:12:02.959171"
    },
    {
      "arxiv_id": "2502.21208v1",
      "title": "ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Gimenes",
        "Zeyu Cao",
        "Jeffrey Wong",
        "Yiren Zhao"
      ],
      "abstract": "Recent research has shown that LLM performance on reasoning tasks can be\nenhanced by scaling test-time compute. One promising approach, particularly\nwith decomposable problems, involves arranging intermediate solutions as a\ngraph on which transformations are performed to explore the solution space.\nHowever, prior works rely on pre-determined, task-specific transformation\nschedules which are subject to a set of searched hyperparameters. In this work,\nwe view thought graph transformations as actions in a Markov decision process,\nand implement policy agents to drive effective action policies for the\nunderlying reasoning LLM agent. In particular, we investigate the ability for\nanother LLM to act as a policy agent on thought graph environments and\nintroduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES,\nreasoning LLM agents solve decomposed subproblems, while policy LLM agents\nmaintain visibility of the thought graph states, and dynamically adapt the\nproblem-solving strategy. Through extensive experiments, we observe that using\noff-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can\nyield up to $29\\%$ higher accuracy on HumanEval relative to static\ntransformation schedules, as well as reducing inference costs by $35\\%$ and\navoid any search requirements. We also conduct a thorough analysis of observed\nfailure modes, highlighting that limitations on LLM sizes and the depth of\nproblem decomposition can be seen as challenges to scaling LLM-guided\nreasoning.",
      "tldr_zh": "本研究提出ARIES，一种多智能体架构，用于在交互式思维图环境上实现LLMs的自主推理（Autonomous Reasoning）。ARIES将思维图转换视为Markov decision process中的动作，由策略代理（policy agents）动态调整问题解决策略，从而指导推理LLM代理处理分解子问题。实验结果显示，使用现成LLMs作为策略代理无需监督微调（SFT），可在HumanEval任务上将准确率提高29%，同时降低推理成本35%，并消除对超参数搜索的依赖；然而，分析发现，LLM规模和问题分解深度限制仍是扩展LLM引导推理的挑战。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21208v1",
      "published_date": "2025-02-28 16:28:13 UTC",
      "updated_date": "2025-02-28 16:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:12:15.011116"
    },
    {
      "arxiv_id": "2502.21201v3",
      "title": "The PanAf-FGBG Dataset: Understanding the Impact of Backgrounds in Wildlife Behaviour Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Otto Brookes",
        "Maksim Kukushkin",
        "Majid Mirmehdi",
        "Colleen Stephens",
        "Paula Dieguez",
        "Thurston C. Hicks",
        "Sorrel Jones",
        "Kevin Lee",
        "Maureen S. McCarthy",
        "Amelia Meier",
        "Emmanuelle Normand",
        "Erin G. Wessling",
        "Roman M. Wittig",
        "Kevin Langergraber",
        "Klaus Zuberbühler",
        "Lukas Boesch",
        "Thomas Schmid",
        "Mimi Arandjelovic",
        "Hjalmar Kühl",
        "Tilo Burghardt"
      ],
      "abstract": "Computer vision analysis of camera trap video footage is essential for\nwildlife conservation, as captured behaviours offer some of the earliest\nindicators of changes in population health. Recently, several high-impact\nanimal behaviour datasets and methods have been introduced to encourage their\nuse; however, the role of behaviour-correlated background information and its\nsignificant effect on out-of-distribution generalisation remain unexplored. In\nresponse, we present the PanAf-FGBG dataset, featuring 20 hours of wild\nchimpanzee behaviours, recorded at over 350 individual camera locations.\nUniquely, it pairs every video with a chimpanzee (referred to as a foreground\nvideo) with a corresponding background video (with no chimpanzee) from the same\ncamera location. We present two views of the dataset: one with overlapping\ncamera locations and one with disjoint locations. This setup enables, for the\nfirst time, direct evaluation of in-distribution and out-of-distribution\nconditions, and for the impact of backgrounds on behaviour recognition models\nto be quantified. All clips come with rich behavioural annotations and metadata\nincluding unique camera IDs and detailed textual scene descriptions.\nAdditionally, we establish several baselines and present a highly effective\nlatent-space normalisation technique that boosts out-of-distribution\nperformance by +5.42% mAP for convolutional and +3.75% mAP for\ntransformer-based models. Finally, we provide an in-depth analysis on the role\nof backgrounds in out-of-distribution behaviour recognition, including the so\nfar unexplored impact of background durations (i.e., the count of background\nframes within foreground videos).",
      "tldr_zh": "该研究引入了 PanAf-FGBG 数据集，包含20小时的野外黑猩猩行为视频，旨在探讨背景信息对野生动物行为识别模型的影响，尤其是分布外泛化问题。数据集独特地将每个前景视频（包含黑猩猩）与相同相机位置的背景视频配对，并提供两种视图（相机位置重叠或分离），便于评估背景对模型性能的量化影响。实验建立了多个基线，并提出了一种潜在空间归一化技术，提升了分布外性能（卷积模型+5.42% mAP，Transformer模型+3.75% mAP），并深入分析了背景持续时间对行为识别的潜在作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR)",
      "pdf_url": "http://arxiv.org/pdf/2502.21201v3",
      "published_date": "2025-02-28 16:18:57 UTC",
      "updated_date": "2025-03-19 15:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:12:28.336232"
    },
    {
      "arxiv_id": "2502.21196v1",
      "title": "AMPLE: Event-Driven Accelerator for Mixed-Precision Inference of Graph Neural Networks",
      "title_zh": "AMPLE：用于混合精度图神经网络推理的事件驱动加速器",
      "authors": [
        "Pedro Gimenes",
        "Yiren Zhao",
        "George Constantinides"
      ],
      "abstract": "Graph Neural Networks (GNNs) have recently gained attention due to their\nperformance on non-Euclidean data. The use of custom hardware architectures\nproves particularly beneficial for GNNs due to their irregular memory access\npatterns, resulting from the sparse structure of graphs. However, existing FPGA\naccelerators are limited by their double buffering mechanism, which doesn't\naccount for the irregular node distribution in typical graph datasets. To\naddress this, we introduce \\textbf{AMPLE} (Accelerated Message Passing Logic\nEngine), an FPGA accelerator leveraging a new event-driven programming flow. We\ndevelop a mixed-arithmetic architecture, enabling GNN inference to be quantized\nat a node-level granularity. Finally, prefetcher for data and instructions is\nimplemented to optimize off-chip memory access and maximize node parallelism.\nEvaluation on citation and social media graph datasets ranging from $2$K to\n$700$K nodes showed a mean speedup of $243\\times$ and $7.2\\times$ against CPU\nand GPU counterparts, respectively.",
      "tldr_zh": "这篇论文介绍了AMPLE，一种事件驱动的FPGA加速器，针对Graph Neural Networks (GNNs)的混合精度推理，解决了现有加速器在不规则内存访问模式（如图的稀疏结构）上的局限性。AMPLE采用事件驱动编程流、节点级粒度的混合算术架构以及数据和指令预取器（prefetcher），以优化内存访问并提升节点并行性。在从2K到700K节点的引用和社交媒体图数据集上评估，结果显示其比CPU快243倍，比GPU快7.2倍，为GNNs硬件加速提供了高效解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21196v1",
      "published_date": "2025-02-28 16:14:16 UTC",
      "updated_date": "2025-02-28 16:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:12:38.257127"
    },
    {
      "arxiv_id": "2502.21186v2",
      "title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Baiting Luo",
        "Ava Pettet",
        "Aron Laszka",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "abstract": "Sequential decision-making in high-dimensional continuous action spaces,\nparticularly in stochastic environments, faces significant computational\nchallenges. We explore this challenge in the traditional offline RL setting,\nwhere an agent must learn how to make decisions based on data collected through\na stochastic behavior policy. We present Latent Macro Action Planner (L-MAP),\nwhich addresses this challenge by learning a set of temporally extended\nmacro-actions through a state-conditional Vector Quantized Variational\nAutoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs\na (separate) learned prior model that acts as a latent transition model and\nallows efficient sampling of plausible actions. During planning, our approach\naccounts for stochasticity in both the environment and the behavior policy by\nusing Monte Carlo tree search (MCTS). In offline RL settings, including\nstochastic continuous control tasks, L-MAP efficiently searches over discrete\nlatent actions to yield high expected returns. Empirical results demonstrate\nthat L-MAP maintains low decision latency despite increased action\ndimensionality. Notably, across tasks ranging from continuous control with\ninherently stochastic dynamics to high-dimensional robotic hand manipulation,\nL-MAP significantly outperforms existing model-based methods and performs\non-par with strong model-free actor-critic baselines, highlighting the\neffectiveness of the proposed approach in planning in complex and stochastic\nenvironments with high-dimensional action spaces.",
      "tldr_zh": "这篇论文提出了一种名为 L-MAP 的方法，用于解决高维连续动作空间中顺序决策的计算挑战，尤其在随机环境中。L-MAP 通过状态条件下的 Vector Quantized Variational Autoencoder (VQ-VAE) 学习时间扩展的宏动作，以降低动作维度，并结合独立先验模型和 Monte Carlo tree search (MCTS) 来处理环境和行为策略的随机性，实现高效规划。实验结果显示，在离线强化学习任务中，包括随机连续控制和高维机器人手操作，L-MAP 显著优于现有基于模型的方法，与强模型无关的演员-评论家基线相当，同时保持低决策延迟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICLR2025. Code would be available at\n  https://github.com/BaitingLuo/L-MAP.git",
      "pdf_url": "http://arxiv.org/pdf/2502.21186v2",
      "published_date": "2025-02-28 16:02:23 UTC",
      "updated_date": "2025-03-03 02:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:12:52.478194"
    },
    {
      "arxiv_id": "2502.21185v1",
      "title": "A Survey of Link Prediction in Temporal Networks",
      "title_zh": "时间网络中链路预测的综述",
      "authors": [
        "Jiafeng Xiong",
        "Ahmad Zareie",
        "Rizos Sakellariou"
      ],
      "abstract": "Temporal networks have gained significant prominence in the past decade for\nmodelling dynamic interactions within complex systems. A key challenge in this\ndomain is Temporal Link Prediction (TLP), which aims to forecast future\nconnections by analysing historical network structures across various\napplications including social network analysis. While existing surveys have\naddressed specific aspects of TLP, they typically lack a comprehensive\nframework that distinguishes between representation and inference methods. This\nsurvey bridges this gap by introducing a novel taxonomy that explicitly\nexamines representation and inference from existing methods, providing a novel\nclassification of approaches for TLP. We analyse how different representation\ntechniques capture temporal and structural dynamics, examining their\ncompatibility with various inference methods for both transductive and\ninductive prediction tasks. Our taxonomy not only clarifies the methodological\nlandscape but also reveals promising unexplored combinations of existing\ntechniques. This taxonomy provides a systematic foundation for emerging\nchallenges in TLP, including model explainability and scalable architectures\nfor complex temporal networks.",
      "tldr_zh": "这篇论文对时间网络中的链接预测(Temporal Link Prediction, TLP)进行了全面调查，旨在预测未来连接并分析历史网络结构在社会网络等应用中的作用。论文引入了一个新颖的分类法(taxonomy)，明确区分了表示(representation)和推理(inference)方法，填补了现有调查的不足。研究分析了不同表示技术如何捕捉时间和结构动态，并探讨了这些技术与各种推理方法的兼容性，包括transductive和inductive预测任务。最终，该分类法揭示了潜在的未探索组合，并为TLP的未来挑战，如模型可解释性和可扩展架构，提供了一个系统化的基础。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21185v1",
      "published_date": "2025-02-28 16:00:57 UTC",
      "updated_date": "2025-02-28 16:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:13:03.817566"
    },
    {
      "arxiv_id": "2503.01906v2",
      "title": "Learning to Chain Operations by Routing Information Through a Global Workspace",
      "title_zh": "翻译失败",
      "authors": [
        "Hugo Chateau-Laurent",
        "Rufin VanRullen"
      ],
      "abstract": "We present a model inspired by the Global Workspace Theory that integrates\nspecialized modules to perform a sequential reasoning task. A controller\nselectively routes information between modules through the workspace using a\ngating mechanism. This approach allows the model to chain operations by\niteratively broadcasting information between specialized domains, mimicking\nSystem-2 reasoning. We evaluate the model's performance on a simple addition\ntask, where two addends must be summed. The task can be solved by routing\ninformation sequentially through an Input module, an Increment module (multiple\ntimes), and finally an Output module. We consider two implementations of this\nsystem with increasing complexity. First, using hand-designed modules operating\non one-hot digit representations, the controller (a LSTM recurrent network)\nlearns to select the appropriate modules (input, increment, output) in the\nappropriate sequence. Second, we replace the hand-designed modules with learned\nrepresentation modules for MNIST images and an increment module trained on the\ntask objectives; here again, the controller learns the appropriate sequential\nmodule selection to solve the task. Finally, we show that the Global Workspace\nmodel, while having fewer parameters, outperforms LSTMs and Transformers when\ntested on unseen addition operations (both interpolations and extrapolations of\naddition operations seen during training). Our results highlight the potential\nof architectures inspired by the Global Workspace Theory to enhance deep\nlearning's reasoning capabilities.",
      "tldr_zh": "本研究提出一个受 Global Workspace Theory 启发的模型，用于执行顺序推理任务，该模型通过一个控制器和门控机制在专门模块之间路由信息，实现操作的链式连接，模仿 System-2 reasoning。实验在简单加法任务上进行，模型需顺序通过 Input 模块、Increment 模块（多次）和 Output 模块求和，采用两种实现：手设计模块结合 LSTM 控制器，以及学习表示的模块。结果显示，该模型参数更少，且在未见加法操作（包括插值和外推）上的性能优于 LSTM 和 Transformers，突显了其增强深度学习推理能力的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 14 figures, submitted to a conference",
      "pdf_url": "http://arxiv.org/pdf/2503.01906v2",
      "published_date": "2025-02-28 15:30:55 UTC",
      "updated_date": "2025-03-06 21:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:13:16.452276"
    },
    {
      "arxiv_id": "2502.21142v1",
      "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Léopold Maytié",
        "Roland Bertin Johannet",
        "Rufin VanRullen"
      ],
      "abstract": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.",
      "tldr_zh": "该论文提出了一种名为 Multimodal Dreaming 的强化学习（RL）框架，将 Global Workspace (GW) 理论与世界模型相结合，旨在通过高水平潜在维度捕捉多模态变量，从而提升代理的规划和泛化能力。相比传统世界模型直接操作环境变量，该方法在 GW 潜在空间中进行 dreaming（心理模拟），显著减少了训练所需的环境步骤。实验结果显示，GW-Dreamer 算法在效率上优于标准 PPO 和原始 Dreamer 模型，并表现出对缺失一种观察模态（如图像或模拟属性）的强鲁棒性。总之，这种结合为改进 RL 代理的决策和适应性提供了巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review in a conference",
      "pdf_url": "http://arxiv.org/pdf/2502.21142v1",
      "published_date": "2025-02-28 15:24:17 UTC",
      "updated_date": "2025-02-28 15:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:13:29.054085"
    },
    {
      "arxiv_id": "2502.21138v2",
      "title": "Predicting clinical outcomes from patient care pathways represented with temporal knowledge graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Jong Ho Jhee",
        "Alberto Megina",
        "Pacôme Constant Dit Beaufils",
        "Matilde Karakachoff",
        "Richard Redon",
        "Alban Gaignard",
        "Adrien Coulet"
      ],
      "abstract": "Background: With the increasing availability of healthcare data, predictive\nmodeling finds many applications in the biomedical domain, such as the\nevaluation of the level of risk for various conditions, which in turn can guide\nclinical decision making. However, it is unclear how knowledge graph data\nrepresentations and their embedding, which are competitive in some settings,\ncould be of interest in biomedical predictive modeling. Method: We simulated\nsynthetic but realistic data of patients with intracranial aneurysm and\nexperimented on the task of predicting their clinical outcome. We compared the\nperformance of various classification approaches on tabular data versus a\ngraph-based representation of the same data. Next, we investigated how the\nadopted schema for representing first individual data and second temporal data\nimpacts predictive performances. Results: Our study illustrates that in our\ncase, a graph representation and Graph Convolutional Network (GCN) embeddings\nreach the best performance for a predictive task from observational data. We\nemphasize the importance of the adopted schema and of the consideration of\nliteral values in the representation of individual data. Our study also\nmoderates the relative impact of various time encoding on GCN performance.",
      "tldr_zh": "该研究探讨了使用时间知识图谱（Temporal Knowledge Graphs）表示患者护理路径来预测临床结果的方法，通过模拟颅内动脉瘤患者的合成数据进行实验。研究比较了表格数据与图-based 表示在预测任务中的性能，发现Graph Convolutional Network (GCN) 嵌入在图表示上取得了最佳效果。结果强调了数据schema设计和字面值的考虑对预测性能的重要性，同时指出时间编码对GCN的影响相对有限，为生物医学预测建模提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21138v2",
      "published_date": "2025-02-28 15:20:41 UTC",
      "updated_date": "2025-04-30 15:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:13:39.049009"
    },
    {
      "arxiv_id": "2502.21134v1",
      "title": "Dynamically Local-Enhancement Planner for Large-Scale Autonomous Driving",
      "title_zh": "动态本地增强规划器用于大规模自动驾驶",
      "authors": [
        "Nanshan Deng",
        "Weitao Zhou",
        "Bo Zhang",
        "Junze Wen",
        "Kun Jiang",
        "Zhong Cao",
        "Diange Yang"
      ],
      "abstract": "Current autonomous vehicles operate primarily within limited regions, but\nthere is increasing demand for broader applications. However, as models scale,\ntheir limited capacity becomes a significant challenge for adapting to novel\nscenarios. It is increasingly difficult to improve models for new situations\nusing a single monolithic model. To address this issue, we introduce the\nconcept of dynamically enhancing a basic driving planner with local driving\ndata, without permanently modifying the planner itself. This approach, termed\nthe Dynamically Local-Enhancement (DLE) Planner, aims to improve the\nscalability of autonomous driving systems without significantly expanding the\nplanner's size. Our approach introduces a position-varying Markov Decision\nProcess formulation coupled with a graph neural network that extracts\nregion-specific driving features from local observation data. The learned\nfeatures describe the local behavior of the surrounding objects, which is then\nleveraged to enhance a basic reinforcement learning-based policy. We evaluated\nour approach in multiple scenarios and compared it with a one-for-all driving\nmodel. The results show that our method outperforms the baseline policy in both\nsafety (collision rate) and average reward, while maintaining a lighter scale.\nThis approach has the potential to benefit large-scale autonomous vehicles\nwithout the need for largely expanding on-device driving models.",
      "tldr_zh": "该研究针对大规模自动驾驶的扩展性挑战，提出了Dynamically Local-Enhancement (DLE) Planner，这是一种动态增强基本驾驶规划器的框架，无需永久修改规划器本身。方法通过引入位置变化的Markov Decision Process (MDP)结合Graph Neural Network，从本地观察数据中提取区域特定驾驶特征，并用于提升基于reinforcement learning的策略。实验结果显示，DLE Planner在多个场景中优于基线模型，提高了安全性（降低碰撞率）和平均奖励，同时保持模型规模较轻，从而为大规模自动驾驶系统的可扩展性提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21134v1",
      "published_date": "2025-02-28 15:17:20 UTC",
      "updated_date": "2025-02-28 15:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:13:50.609310"
    },
    {
      "arxiv_id": "2503.00089v1",
      "title": "Protein Structure Tokenization: Benchmarking and New Recipe",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Yuan",
        "Zichen Wang",
        "Marcus Collins",
        "Huzefa Rangwala"
      ],
      "abstract": "Recent years have witnessed a surge in the development of protein structural\ntokenization methods, which chunk protein 3D structures into discrete or\ncontinuous representations. Structure tokenization enables the direct\napplication of powerful techniques like language modeling for protein\nstructures, and large multimodal models to integrate structures with protein\nsequences and functional texts. Despite the progress, the capabilities and\nlimitations of these methods remain poorly understood due to the lack of a\nunified evaluation framework. We first introduce StructTokenBench, a framework\nthat comprehensively evaluates the quality and efficiency of structure\ntokenizers, focusing on fine-grained local substructures rather than global\nstructures, as typical in existing benchmarks. Our evaluations reveal that no\nsingle model dominates all benchmarking perspectives. Observations of codebook\nunder-utilization led us to develop AminoAseed, a simple yet effective strategy\nthat enhances codebook gradient updates and optimally balances codebook size\nand dimension for improved tokenizer utilization and quality. Compared to the\nleading model ESM3, our method achieves an average of 6.31% performance\nimprovement across 24 supervised tasks, with sensitivity and utilization rates\nincreased by 12.83% and 124.03%, respectively.",
      "tldr_zh": "该论文介绍了蛋白质结构标记化方法的发展及其应用，包括将蛋白质3D结构分解为离散或连续表示，以支持语言建模和多模态模型整合。作者提出StructTokenBench框架，作为统一的评估工具，重点评估标记器的质量和效率，特别是细粒度的局部子结构，发现没有单一模型在所有方面占优。针对代码本利用率不足的问题，他们开发了AminoAseed策略，通过增强代码本梯度更新并优化大小和维度，实现了标记器性能提升，与ESM3相比，在24个监督任务上平均提高6.31%，敏感性和利用率分别增加12.83%和124.03%。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.00089v1",
      "published_date": "2025-02-28 15:14:33 UTC",
      "updated_date": "2025-02-28 15:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:14:04.119342"
    },
    {
      "arxiv_id": "2502.21131v1",
      "title": "Einleitung [Introduction]",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent C. Müller"
      ],
      "abstract": "Hilary Putnam's biography and philosophical development reflect the history\nof Anglo-Saxon philosophy over the last 40 years. Putnam has influenced this\nhistory significantly for almost as long. In this introduction, the main aim is\nto present the context in which Putnam stands and from which his philosophical\ncontributions can be understood. In the context of a sketch of Putnam's\nphilosophical development, a preliminary historical classification of his work\nwill also be attempted, even if this is not the place for a comprehensive\ncritique or presentation: The introduction must remain at a fairly elementary\nlevel and of course cannot replace a reading of the texts. Since Putnam's work\nis certainly part of a rapprochement between 'analytic' and 'continental'\nphilosophy, the introduction to the texts translated here should finally make\nclear what Putnam has to offer non-analytically oriented readers.\n  Hilary Putnams Biographie und philosophische Entwicklung spiegeln die\nGeschichte der angels\\\"achsischen Philosophie in den letzten 40 Jahren. Beinahe\nebenso lange hat Putnam diese Geschichte wesentlich beeinflu{\\ss}t. In der\nvorliegenden Einleitung soll vor allem der Kontext dargestellt werden, in dem\nPutnam steht und aus dem heraus verst\\\"andlich wird, was er philosophisch zu\nsagen hat. Im Rahmen einer Skizze von Putnams philosophischer Entwicklung soll\nzudem eine vorl\\\"aufige philosophiehistorische Einordnung versucht werden, auch\nwenn hier nicht der Ort f\\\"ur eine umfassende Kritik oder Darstellung sein\nkann: Die Einleitung mu{\\ss} auf recht elementarem Niveau bleiben und kann eine\nLekt\\\"ure der Texte nat\\\"urlich nicht ersetzen. Da Putnams Werk sicherlich Teil\neiner Ann\\\"aherung von 'analytischer' und 'kontinentaler' Philosophie ist, soll\nbei der Einf\\\"uhrung in die hier \\\"ubersetzten Texte schlie{\\ss}lich deutlich\nwerden, was Putnam nicht analytisch orientierten Lesern zu bieten hat.",
      "tldr_zh": "这篇论文以“Einleitung [Introduction]”为标题，介绍了哲学家 Hilary Putnam 的生平和哲学发展，以及其在过去40年 Anglo-Saxon philosophy 历史中的重要影响。作者旨在通过简要概述 Putnam 的哲学演变，提供一个历史背景，帮助读者理解他的贡献，同时进行初步的哲学历史分类。论文强调 Putnam 的工作促进了 'analytic' philosophy 和 'continental' philosophy 的 rapprochement，为非分析哲学导向的读者提供可访问的见解。",
      "categories": [
        "physics.hist-ph",
        "cs.AI"
      ],
      "primary_category": "physics.hist-ph",
      "comment": "in German language",
      "pdf_url": "http://arxiv.org/pdf/2502.21131v1",
      "published_date": "2025-02-28 15:10:09 UTC",
      "updated_date": "2025-02-28 15:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:14:14.968956"
    },
    {
      "arxiv_id": "2502.21123v3",
      "title": "Causality Is Key to Understand and Balance Multiple Goals in Trustworthy ML and Foundation Models",
      "title_zh": "因果性是理解和平衡可信赖机器学习以及基础模型中多个目标的关键",
      "authors": [
        "Ruta Binkyte",
        "Ivaxi Sheth",
        "Zhijing Jin",
        "Mohammad Havaei",
        "Bernhard Schölkopf",
        "Mario Fritz"
      ],
      "abstract": "Ensuring trustworthiness in machine learning (ML) systems is crucial as they\nbecome increasingly embedded in high-stakes domains. This paper advocates for\nintegrating causal methods into machine learning to navigate the trade-offs\namong key principles of trustworthy ML, including fairness, privacy,\nrobustness, accuracy, and explainability. While these objectives should ideally\nbe satisfied simultaneously, they are often addressed in isolation, leading to\nconflicts and suboptimal solutions. Drawing on existing applications of\ncausality in ML that successfully align goals such as fairness and accuracy or\nprivacy and robustness, this paper argues that a causal approach is essential\nfor balancing multiple competing objectives in both trustworthy ML and\nfoundation models. Beyond highlighting these trade-offs, we examine how\ncausality can be practically integrated into ML and foundation models, offering\nsolutions to enhance their reliability and interpretability. Finally, we\ndiscuss the challenges, limitations, and opportunities in adopting causal\nframeworks, paving the way for more accountable and ethically sound AI systems.",
      "tldr_zh": "这篇论文强调，在机器学习（ML）系统中确保可信赖性至关重要，并主张通过因果方法（causality）来平衡多个关键目标，包括公平性（fairness）、隐私（privacy）、鲁棒性（robustness）、准确性（accuracy）和可解释性（explainability）。论文指出，这些目标往往被孤立处理，导致冲突和次优解决方案，而因果方法已在现有应用中成功协调如公平性与准确性，或隐私与鲁棒性的权衡。作者探讨了如何实际将因果框架集成到可信赖 ML 和基础模型（foundation models）中，以提升系统的可靠性和可解释性。最终，论文讨论了采用这种方法的挑战、限制和机会，为开发更负责任和道德的 AI 系统提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21123v3",
      "published_date": "2025-02-28 14:57:33 UTC",
      "updated_date": "2025-03-21 14:02:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:14:28.430935"
    },
    {
      "arxiv_id": "2502.21112v1",
      "title": "Optimizing Large Language Models for ESG Activity Detection in Financial Texts",
      "title_zh": "针对金融文本中 ESG 活动检测优化大型语言模型",
      "authors": [
        "Mattia Birti",
        "Francesco Osborne",
        "Andrea Maurino"
      ],
      "abstract": "The integration of Environmental, Social, and Governance (ESG) factors into\ncorporate decision-making is a fundamental aspect of sustainable finance.\nHowever, ensuring that business practices align with evolving regulatory\nframeworks remains a persistent challenge. AI-driven solutions for\nautomatically assessing the alignment of sustainability reports and\nnon-financial disclosures with specific ESG activities could greatly support\nthis process. Yet, this task remains complex due to the limitations of\ngeneral-purpose Large Language Models (LLMs) in domain-specific contexts and\nthe scarcity of structured, high-quality datasets. In this paper, we\ninvestigate the ability of current-generation LLMs to identify text related to\nenvironmental activities. Furthermore, we demonstrate that their performance\ncan be significantly enhanced through fine-tuning on a combination of original\nand synthetically generated data. To this end, we introduce ESG-Activities, a\nbenchmark dataset containing 1,325 labelled text segments classified according\nto the EU ESG taxonomy. Our experimental results show that fine-tuning on\nESG-Activities significantly enhances classification accuracy, with open models\nsuch as Llama 7B and Gemma 7B outperforming large proprietary solutions in\nspecific configurations. These findings have important implications for\nfinancial analysts, policymakers, and AI researchers seeking to enhance ESG\ntransparency and compliance through advanced natural language processing\ntechniques.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在金融文本中检测 ESG（Environmental, Social, and Governance）活动时存在的领域特定局限性和数据集稀缺问题，提出了一种优化策略。通过在原创和合成数据上进行 fine-tuning，显著提升了模型的性能。论文引入了 ESG-Activities 基准数据集，包含 1,325 个按 EU ESG taxonomy 分类的标记文本段；实验结果显示，微调后的开源模型如 Llama 7B 和 Gemma 7B 在特定配置下超过了大型专有模型的分类准确性。这些发现为金融分析师、政策制定者和 AI 研究者提供了重要启示，有助于提升 ESG 透明度和合规性。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21112v1",
      "published_date": "2025-02-28 14:52:25 UTC",
      "updated_date": "2025-02-28 14:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:14:39.490188"
    },
    {
      "arxiv_id": "2502.21100v1",
      "title": "AuthSim: Towards Authentic and Effective Safety-critical Scenario Generation for Autonomous Driving Tests",
      "title_zh": "翻译失败",
      "authors": [
        "Yukuan Yang",
        "Xucheng Lu",
        "Zhili Zhang",
        "Zepeng Wu",
        "Guoqi Li",
        "Lingzhong Meng",
        "Yunzhi Xue"
      ],
      "abstract": "Generating adversarial safety-critical scenarios is a pivotal method for\ntesting autonomous driving systems, as it identifies potential weaknesses and\nenhances system robustness and reliability. However, existing approaches\npredominantly emphasize unrestricted collision scenarios, prompting non-player\ncharacter (NPC) vehicles to attack the ego vehicle indiscriminately. These\nworks overlook these scenarios' authenticity, rationality, and relevance,\nresulting in numerous extreme, contrived, and largely unrealistic collision\nevents involving aggressive NPC vehicles. To rectify this issue, we propose a\nthree-layer relative safety region model, which partitions the area based on\ndanger levels and increases the likelihood of NPC vehicles entering relative\nboundary regions. This model directs NPC vehicles to engage in adversarial\nactions within relatively safe boundary regions, thereby augmenting the\nscenarios' authenticity. We introduce AuthSim, a comprehensive platform for\ngenerating authentic and effective safety-critical scenarios by integrating the\nthree-layer relative safety region model with reinforcement learning. To our\nknowledge, this is the first attempt to address the authenticity and\neffectiveness of autonomous driving system test scenarios comprehensively.\nExtensive experiments demonstrate that AuthSim outperforms existing methods in\ngenerating effective safety-critical scenarios. Notably, AuthSim achieves a\n5.25% improvement in average cut-in distance and a 27.12% enhancement in\naverage collision interval time, while maintaining higher efficiency in\ngenerating effective safety-critical scenarios compared to existing methods.\nThis underscores its significant advantage in producing authentic scenarios\nover current methodologies.",
      "tldr_zh": "该论文针对自动驾驶系统测试中的安全关键场景生成问题，指出现有方法往往产生极端不真实的碰撞事件，因为它们忽略了场景的真实性和合理性。作者提出 AuthSim 平台，该平台整合三层相对安全区域模型和强化学习（reinforcement learning），通过分区危险水平并引导 NPC vehicles 在相对安全的边界区域进行对抗行为，从而生成更真实有效的场景。作为首个全面解决场景真实性和有效性的框架，实验结果显示 AuthSim 比现有方法提高了平均切入距离 5.25% 和平均碰撞间隔时间 27.12%，并提升了生成效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21100v1",
      "published_date": "2025-02-28 14:38:35 UTC",
      "updated_date": "2025-02-28 14:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:14:51.090530"
    },
    {
      "arxiv_id": "2502.21098v1",
      "title": "Re-evaluating Theory of Mind evaluation in large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Jennifer Hu",
        "Felix Sosa",
        "Tomer Ullman"
      ],
      "abstract": "The question of whether large language models (LLMs) possess Theory of Mind\n(ToM) -- often defined as the ability to reason about others' mental states --\nhas sparked significant scientific and public interest. However, the evidence\nas to whether LLMs possess ToM is mixed, and the recent growth in evaluations\nhas not resulted in a convergence. Here, we take inspiration from cognitive\nscience to re-evaluate the state of ToM evaluation in LLMs. We argue that a\nmajor reason for the disagreement on whether LLMs have ToM is a lack of clarity\non whether models should be expected to match human behaviors, or the\ncomputations underlying those behaviors. We also highlight ways in which\ncurrent evaluations may be deviating from \"pure\" measurements of ToM abilities,\nwhich also contributes to the confusion. We conclude by discussing several\ndirections for future research, including the relationship between ToM and\npragmatic communication, which could advance our understanding of artificial\nsystems as well as human cognition.",
      "tldr_zh": "该论文重新评估了大型语言模型（LLMs）在理论心智（ToM）方面的表现，ToM指推理他人心理状态的能力，并指出当前评估证据不一致的主要原因是缺乏清晰标准，即模型应匹配人类行为还是底层计算过程。作者借鉴认知科学，强调现有评估可能偏离纯ToM测量的核心，从而导致混淆。论文建议未来研究方向，包括探讨ToM与实用通信的关系，以深化对人工系统和人类认知的理解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2502.21098v1",
      "published_date": "2025-02-28 14:36:57 UTC",
      "updated_date": "2025-02-28 14:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:15:02.440186"
    },
    {
      "arxiv_id": "2502.21092v1",
      "title": "An LLM-based Delphi Study to Predict GenAI Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Bertolotti",
        "Luca Mari"
      ],
      "abstract": "Predicting the future trajectory of complex and rapidly evolving systems\nremains a significant challenge, particularly in domains where data is scarce\nor unreliable. This study introduces a novel approach to qualitative\nforecasting by leveraging Large Language Models to conduct Delphi studies. The\nmethodology was applied to explore the future evolution of Generative\nArtificial Intelligence, revealing insights into key factors such as\ngeopolitical tensions, economic disparities, regulatory frameworks, and ethical\nconsiderations. The results highlight how LLM-based Delphi studies can\nfacilitate structured scenario analysis, capturing diverse perspectives while\nmitigating issues such as respondent fatigue. However, limitations emerge in\nterms of knowledge cutoffs, inherent biases, and sensitivity to initial\nconditions. While the approach provides an innovative means for structured\nforesight, this method could be also considered as a novel form of reasoning.\nfurther research is needed to refine its ability to manage heterogeneity,\nimprove reliability, and integrate external data sources.",
      "tldr_zh": "本研究提出了一种基于大型语言模型(LLMs)的创新方法，用于进行Delphi研究，以预测生成式人工智能(GenAI)的未来演变。该方法通过结构化场景分析，揭示了关键影响因素，如地缘政治紧张、经济不平等、监管框架和伦理考虑，同时捕捉多样视角并缓解回应疲劳。结果显示，这种方法为定性预测提供了新颖的推理形式，但存在知识截止、固有偏见和对初始条件敏感性的限制。未来需要进一步研究来提升其处理异质性、可靠性并整合外部数据源的能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21092v1",
      "published_date": "2025-02-28 14:31:25 UTC",
      "updated_date": "2025-02-28 14:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:15:14.930943"
    },
    {
      "arxiv_id": "2502.21087v1",
      "title": "PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information",
      "title_zh": "翻译失败",
      "authors": [
        "Hansi Yang",
        "Qi Zhang",
        "Wei Jiang",
        "Jianguo Li"
      ],
      "abstract": "Large language models (LLMs) have shown impressive abilities in answering\nquestions across various domains, but they often encounter hallucination issues\non questions that require professional and up-to-date knowledge. To address\nthis limitation, retrieval-augmented generation (RAG) techniques have been\nproposed, which retrieve relevant information from external sources to inform\ntheir responses. However, existing RAG methods typically focus on a single type\nof external data, such as vectorized text database or knowledge graphs, and\ncannot well handle real-world questions on semi-structured data containing both\ntext and relational information. To bridge this gap, we introduce PASemiQA, a\nnovel approach that jointly leverages text and relational information in\nsemi-structured data to answer questions. PASemiQA first generates a plan to\nidentify relevant text and relational information to answer the question in\nsemi-structured data, and then uses an LLM agent to traverse the\nsemi-structured data and extract necessary information. Our empirical results\ndemonstrate the effectiveness of PASemiQA across different semi-structured\ndatasets from various domains, showcasing its potential to improve the accuracy\nand reliability of question answering systems on semi-structured data.",
      "tldr_zh": "本研究针对大语言模型 (LLMs) 在处理需要专业知识的问题时易出现幻觉问题，提出了一种新型方法 PASemiQA，以提升对半结构化数据的问答能力。PASemiQA 通过生成计划来识别半结构化数据中的相关文本和关系信息，随后利用 LLM 代理遍历并提取必要信息，从而联合利用多种数据类型进行问答。与现有检索增强生成 (RAG) 方法相比，该方法更适合处理真实世界的半结构化数据。实验结果显示，PASemiQA 在不同领域的半结构化数据集上显著提高了问答系统的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21087v1",
      "published_date": "2025-02-28 14:26:47 UTC",
      "updated_date": "2025-02-28 14:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:15:28.256034"
    },
    {
      "arxiv_id": "2502.21086v1",
      "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
      "title_zh": "基础模型是否是脑电图分析的有用特征提取器？",
      "authors": [
        "Özgün Turgut",
        "Felix S. Bott",
        "Markus Ploner",
        "Daniel Rueckert"
      ],
      "abstract": "The success of foundation models in natural language processing and computer\nvision has motivated similar approaches for general time series analysis. While\nthese models are effective for a variety of tasks, their applicability in\nmedical domains with limited data remains largely unexplored. To address this,\nwe investigate the effectiveness of foundation models in medical time series\nanalysis involving electroencephalography (EEG). Through extensive experiments\non tasks such as age prediction, seizure detection, and the classification of\nclinically relevant EEG events, we compare their diagnostic accuracy with that\nof specialised EEG models. Our analysis shows that foundation models extract\nmeaningful EEG features, outperform specialised models even without domain\nadaptation, and localise task-specific biomarkers. Moreover, we demonstrate\nthat diagnostic accuracy is substantially influenced by architectural choices\nsuch as context length. Overall, our study reveals that foundation models with\ngeneral time series understanding eliminate the dependency on large\ndomain-specific datasets, making them valuable tools for clinical practice.",
      "tldr_zh": "该研究探讨了 foundation models 是否能作为 EEG（脑电图）分析的有效特征提取器，通过实验比较其在年龄预测、癫痫检测和临床相关事件分类等任务上的表现。结果显示，foundation models 能够提取有意义的 EEG 特征，即使没有 domain adaptation，也优于专门的 EEG 模型，并能定位任务特定的 biomarkers。此外，诊断准确性受架构选择如 context length 的影响，而这些模型整体上减少了对大型领域特定数据集的依赖，使其成为临床实践的有价值工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21086v1",
      "published_date": "2025-02-28 14:21:34 UTC",
      "updated_date": "2025-02-28 14:21:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:15:39.993195"
    },
    {
      "arxiv_id": "2502.21077v1",
      "title": "Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics",
      "title_zh": "通过复值表示和 Kuramoto 同步动力学增强深度神经网络",
      "authors": [
        "Sabine Muzellec",
        "Andrea Alamia",
        "Thomas Serre",
        "Rufin VanRullen"
      ],
      "abstract": "Neural synchrony is hypothesized to play a crucial role in how the brain\norganizes visual scenes into structured representations, enabling the robust\nencoding of multiple objects within a scene. However, current deep learning\nmodels often struggle with object binding, limiting their ability to represent\nmultiple objects effectively. Inspired by neuroscience, we investigate whether\nsynchrony-based mechanisms can enhance object encoding in artificial models\ntrained for visual categorization. Specifically, we combine complex-valued\nrepresentations with Kuramoto dynamics to promote phase alignment, facilitating\nthe grouping of features belonging to the same object. We evaluate two\narchitectures employing synchrony: a feedforward model and a recurrent model\nwith feedback connections to refine phase synchronization using top-down\ninformation. Both models outperform their real-valued counterparts and\ncomplex-valued models without Kuramoto synchronization on tasks involving\nmulti-object images, such as overlapping handwritten digits, noisy inputs, and\nout-of-distribution transformations. Our findings highlight the potential of\nsynchrony-driven mechanisms to enhance deep learning models, improving their\nperformance, robustness, and generalization in complex visual categorization\ntasks.",
      "tldr_zh": "本研究受神经科学启发，提出了一种增强深度神经网络的方法，通过结合 complex-valued representations 和 Kuramoto synchronization dynamics 来促进特征相位对齐，从而改善物体绑定和多物体场景的编码。研究评估了两种架构：前馈模型和具有反馈连接的循环模型，这些模型在处理重叠手写数字、噪声输入以及分布外变换等任务时，均优于实值模型和未使用 Kuramoto 同步的复杂值模型。结果显示，该同步驱动机制显著提升了深度学习模型的性能、鲁棒性和泛化能力，为复杂视觉分类任务提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "nlin.AO",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21077v1",
      "published_date": "2025-02-28 14:10:42 UTC",
      "updated_date": "2025-02-28 14:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:15:52.293162"
    },
    {
      "arxiv_id": "2502.21059v1",
      "title": "FC-Attack: Jailbreaking Large Vision-Language Models via Auto-Generated Flowcharts",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Zhang",
        "Zhen Sun",
        "Zongmin Zhang",
        "Jihui Guo",
        "Xinlei He"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have become powerful and widely adopted\nin some practical applications. However, recent research has revealed their\nvulnerability to multimodal jailbreak attacks, whereby the model can be induced\nto generate harmful content, leading to safety risks. Although most LVLMs have\nundergone safety alignment, recent research shows that the visual modality is\nstill vulnerable to jailbreak attacks. In our work, we discover that by using\nflowcharts with partially harmful information, LVLMs can be induced to provide\nadditional harmful details. Based on this, we propose a jailbreak attack method\nbased on auto-generated flowcharts, FC-Attack. Specifically, FC-Attack first\nfine-tunes a pre-trained LLM to create a step-description generator based on\nbenign datasets. The generator is then used to produce step descriptions\ncorresponding to a harmful query, which are transformed into flowcharts in 3\ndifferent shapes (vertical, horizontal, and S-shaped) as visual prompts. These\nflowcharts are then combined with a benign textual prompt to execute a\njailbreak attack on LVLMs. Our evaluations using the Advbench dataset show that\nFC-Attack achieves over 90% attack success rates on Gemini-1.5, Llaval-Next,\nQwen2-VL, and InternVL-2.5 models, outperforming existing LVLM jailbreak\nmethods. Additionally, we investigate factors affecting the attack performance,\nincluding the number of steps and the font styles in the flowcharts. Our\nevaluation shows that FC-Attack can improve the jailbreak performance from 4%\nto 28% in Claude-3.5 by changing the font style. To mitigate the attack, we\nexplore several defenses and find that AdaShield can largely reduce the\njailbreak performance but with the cost of utility drop.",
      "tldr_zh": "本研究揭示了Large Vision-Language Models (LVLMs) 面对多模态jailbreak攻击的脆弱性，并提出了一种基于自动生成流程图的攻击方法，名为FC-Attack。FC-Attack 通过微调预训练的LLM 生成与有害查询相关的步骤描述，然后将这些描述转化为不同形状（vertical、horizontal 和 S-shaped）的流程图，作为视觉提示结合良性文本提示进行攻击。实验结果显示，在Advbench数据集上，FC-Attack 对Gemini-1.5、Llaval-Next、Qwen2-VL 和 InternVL-2.5 模型的攻击成功率超过90%，优于现有方法。进一步分析表明，攻击性能受步骤数量和字体样式影响，例如在Claude-3.5模型上，通过改变字体样式可将成功率提高4%至28%；同时，探讨了防御策略，如AdaShield能有效降低攻击效果，但会牺牲模型的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.21059v1",
      "published_date": "2025-02-28 13:59:11 UTC",
      "updated_date": "2025-02-28 13:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:16:07.518235"
    },
    {
      "arxiv_id": "2502.21057v3",
      "title": "Robust Deterministic Policy Gradient for Disturbance Attenuation and Its Application to Quadrotor Control",
      "title_zh": "鲁棒确定性策略梯度用于干扰抑制及其在Quadrotor控制中的应用",
      "authors": [
        "Taeho Lee",
        "Donghwan Lee"
      ],
      "abstract": "Practical control systems pose significant challenges in identifying optimal\ncontrol policies due to uncertainties in the system model and external\ndisturbances. While $H_\\infty$ control techniques are commonly used to design\nrobust controllers that mitigate the effects of disturbances, these methods\noften require complex and computationally intensive calculations. To address\nthis issue, this paper proposes a reinforcement learning algorithm called\nRobust Deterministic Policy Gradient (RDPG), which formulates the $H_\\infty$\ncontrol problem as a two-player zero-sum dynamic game. In this formulation, one\nplayer (the user) aims to minimize the cost, while the other player (the\nadversary) seeks to maximize it. We then employ deterministic policy gradient\n(DPG) and its deep reinforcement learning counterpart to train a robust control\npolicy with effective disturbance attenuation. In particular, for practical\nimplementation, we introduce an algorithm called robust deep deterministic\npolicy gradient (RDDPG), which employs a deep neural network architecture and\nintegrates techniques from the twin-delayed deep deterministic policy gradient\n(TD3) to enhance stability and learning efficiency. To evaluate the proposed\nalgorithm, we implement it on an unmanned aerial vehicle (UAV) tasked with\nfollowing a predefined path in a disturbance-prone environment. The\nexperimental results demonstrate that the proposed method outperforms other\ncontrol approaches in terms of robustness against disturbances, enabling\nprecise real-time tracking of moving targets even under severe disturbance\nconditions.",
      "tldr_zh": "本文提出 Robust Deterministic Policy Gradient (RDPG) 算法，将 H∞ 控制问题转化为两人零和动态博弈，以应对控制系统中的模型不确定性和外部干扰问题。RDPG 基于 Deterministic Policy Gradient (DPG) 和其深度强化学习版本 Robust Deep Deterministic Policy Gradient (RDDPG)，通过整合 TD3 技术，提升了策略的稳定性和学习效率。实验在四旋翼无人机 (UAV) 上进行，结果表明该方法在干扰环境中比传统方法更具鲁棒性，实现精确的实时路径跟踪。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.21057v3",
      "published_date": "2025-02-28 13:58:22 UTC",
      "updated_date": "2025-03-12 23:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:16:18.201372"
    },
    {
      "arxiv_id": "2502.21049v1",
      "title": "Synthesizing Individualized Aging Brains in Health and Disease with Generative Models and Parallel Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Jingru Fu",
        "Yuqi Zheng",
        "Neel Dey",
        "Daniel Ferreira",
        "Rodrigo Moreno"
      ],
      "abstract": "Simulating prospective magnetic resonance imaging (MRI) scans from a given\nindividual brain image is challenging, as it requires accounting for canonical\nchanges in aging and/or disease progression while also considering the\nindividual brain's current status and unique characteristics. While current\ndeep generative models can produce high-resolution anatomically accurate\ntemplates for population-wide studies, their ability to predict future aging\ntrajectories for individuals remains limited, particularly in capturing\nsubject-specific neuroanatomical variations over time. In this study, we\nintroduce Individualized Brain Synthesis (InBrainSyn), a framework for\nsynthesizing high-resolution subject-specific longitudinal MRI scans that\nsimulate neurodegeneration in both Alzheimer's disease (AD) and normal aging.\nInBrainSyn uses a parallel transport algorithm to adapt the population-level\naging trajectories learned by a generative deep template network, enabling\nindividualized aging synthesis. As InBrainSyn uses diffeomorphic\ntransformations to simulate aging, the synthesized images are topologically\nconsistent with the original anatomy by design. We evaluated InBrainSyn both\nquantitatively and qualitatively on AD and healthy control cohorts from the\nOpen Access Series of Imaging Studies - version 3 dataset. Experimentally,\nInBrainSyn can also model neuroanatomical transitions between normal aging and\nAD. An evaluation of an external set supports its generalizability. Overall,\nwith only a single baseline scan, InBrainSyn synthesizes realistic 3D\nspatiotemporal T1w MRI scans, producing personalized longitudinal aging\ntrajectories. The code for InBrainSyn is available at:\nhttps://github.com/Fjr9516/InBrainSyn.",
      "tldr_zh": "本研究提出InBrainSyn框架，利用生成模型和parallel transport算法，针对个体脑部MRI扫描合成个性化老化轨迹，以模拟Alzheimer's disease (AD) 和正常老化的神经退行。该框架通过平行传输算法适应总体老化轨迹，并采用diffeomorphic transformations确保合成图像在拓扑上与原解剖一致，从而捕捉主体特有的神经解剖变异。实验在Open Access Series of Imaging Studies - version 3数据集上定量和定性评估显示，InBrainSyn能从单一基线扫描生成真实的3D spatiotemporal T1w MRI扫描，并成功模拟健康与AD之间的转变，证明其泛化性和实用性。代码已在https://github.com/Fjr9516/InBrainSyn开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 9 figures, 6 tables, diffeomorphic registration, parallel\n  transport, brain aging, medical image generation, Alzheimer's disease",
      "pdf_url": "http://arxiv.org/pdf/2502.21049v1",
      "published_date": "2025-02-28 13:45:09 UTC",
      "updated_date": "2025-02-28 13:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:16:29.041045"
    },
    {
      "arxiv_id": "2503.16467v1",
      "title": "Enhancing Explainability with Multimodal Context Representations for Smarter Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Anargh Viswanath",
        "Lokesh Veeramacheneni",
        "Hendrik Buschmeier"
      ],
      "abstract": "Artificial Intelligence (AI) has significantly advanced in recent years,\ndriving innovation across various fields, especially in robotics. Even though\nrobots can perform complex tasks with increasing autonomy, challenges remain in\nensuring explainability and user-centered design for effective interaction. A\nkey issue in Human-Robot Interaction (HRI) is enabling robots to effectively\nperceive and reason over multimodal inputs, such as audio and vision, to foster\ntrust and seamless collaboration. In this paper, we propose a generalized and\nexplainable multimodal framework for context representation, designed to\nimprove the fusion of speech and vision modalities. We introduce a use case on\nassessing 'Relevance' between verbal utterances from the user and visual scene\nperception of the robot. We present our methodology with a Multimodal Joint\nRepresentation module and a Temporal Alignment module, which can allow robots\nto evaluate relevance by temporally aligning multimodal inputs. Finally, we\ndiscuss how the proposed framework for context representation can help with\nvarious aspects of explainability in HRI.",
      "tldr_zh": "该研究针对人工智能（AI）在机器人领域的应用，提出一个通用且可解释的多模态框架，以提升机器人对语音和视觉等多模态输入的感知与推理，从而增强人机交互（HRI）中的信任与协作。框架的核心组件包括Multimodal Joint Representation module（多模态联合表示模块）和Temporal Alignment module（时间对齐模块），用于融合多模态数据并通过时间对齐评估用户口头表述与视觉场景的'Relevance'（相关性）。实验结果表明，该框架可显著改善HRI的可解释性，支持更智能的机器人设计和无缝协作。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "Presented at 3rd Workshop on Explainability in Human-Robot\n  Collaboration at HRI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16467v1",
      "published_date": "2025-02-28 13:36:47 UTC",
      "updated_date": "2025-02-28 13:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:16:40.489003"
    },
    {
      "arxiv_id": "2502.21041v1",
      "title": "Fast Adversarial Training against Sparse Attacks Requires Loss Smoothing",
      "title_zh": "针对稀疏攻击的快速对抗训练需要损失平滑",
      "authors": [
        "Xuyang Zhong",
        "Yixiao Huang",
        "Chen Liu"
      ],
      "abstract": "This paper studies fast adversarial training against sparse adversarial\nperturbations bounded by $l_0$ norm. We demonstrate the challenges of employing\n$1$-step attacks on $l_0$ bounded perturbations for fast adversarial training,\nincluding degraded performance and the occurrence of catastrophic overfitting\n(CO). We highlight that CO in $l_0$ adversarial training is caused by\nsub-optimal perturbation locations of $1$-step attack. Theoretical and\nempirical analyses reveal that the loss landscape of $l_0$ adversarial training\nis more craggy compared to its $l_\\infty$, $l_2$ and $l_1$ counterparts.\nMoreover, we corroborate that the craggy loss landscape can aggravate CO. To\naddress these issues, we propose Fast-LS-$l_0$ that incorporates soft labels\nand the trade-off loss function to smooth the adversarial loss landscape.\nExtensive experiments demonstrate our method can overcome the challenge of\ncatastrophic overfitting, achieve state-of-the-art performance, and narrow down\nthe performance gap between $1$-step and multi-step adversarial training\nagainst sparse attacks.",
      "tldr_zh": "这篇论文探讨了针对L0范数稀疏攻击的快速对抗训练（fast adversarial training）面临的挑战，包括性能下降和catastrophic overfitting (CO)，并分析其原因在于1-step攻击的子优扰动位置以及损失景观的崎岖性。作者通过理论和实证分析，证明L0对抗训练的损失景观比L∞、L2和L1范数更不平滑，从而加剧了CO问题。为解决此问题，他们提出了Fast-LS-L0方法，结合软标签和权衡损失函数来平滑对抗损失景观。实验结果显示，该方法有效克服CO，实现了最先进性能，并显著缩小了1-step和多步对抗训练在稀疏攻击下的性能差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.21041v1",
      "published_date": "2025-02-28 13:32:47 UTC",
      "updated_date": "2025-02-28 13:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:16:52.161490"
    },
    {
      "arxiv_id": "2503.00086v1",
      "title": "Generalization of CNNs on Relational Reasoning with Bar Charts",
      "title_zh": "卷积神经网络在条形图关系推理中的泛化",
      "authors": [
        "Zhenxing Cui",
        "Lu Chen",
        "Yunhai Wang",
        "Daniel Haehn",
        "Yong Wang",
        "Hanspeter Pfister"
      ],
      "abstract": "This paper presents a systematic study of the generalization of convolutional\nneural networks (CNNs) and humans on relational reasoning tasks with bar\ncharts. We first revisit previous experiments on graphical perception and\nupdate the benchmark performance of CNNs. We then test the generalization\nperformance of CNNs on a classic relational reasoning task: estimating bar\nlength ratios in a bar chart, by progressively perturbing the standard\nvisualizations. We further conduct a user study to compare the performance of\nCNNs and humans. Our results show that CNNs outperform humans only when the\ntraining and test data have the same visual encodings. Otherwise, they may\nperform worse. We also find that CNNs are sensitive to perturbations in various\nvisual encodings, regardless of their relevance to the target bars. Yet, humans\nare mainly influenced by bar lengths. Our study suggests that robust relational\nreasoning with visualizations is challenging for CNNs. Improving CNNs'\ngeneralization performance may require training them to better recognize\ntask-related visual properties.",
      "tldr_zh": "这篇论文系统研究了卷积神经网络 (CNNs) 在条形图 (bar charts) 关系推理任务上的泛化能力，并与人类表现进行比较。作者通过重新审视图形感知实验、更新基准性能，并通过逐步扰动可视化来测试 CNNs 在估计条形长度比率的经典任务中的泛化效果，同时开展用户研究评估两者差异。结果显示，CNNs 仅在训练和测试数据具有相同视觉编码时 outperform 人类，否则表现可能更差；此外，CNNs 对各种视觉编码的扰动高度敏感，而人类主要受条形长度影响。该研究强调，CNNs 在稳健的关系推理中面临挑战，需要通过训练更好地识别任务相关的视觉属性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TVCG. GitHub repository:\n  https://github.com/Ideas-Laboratory/Graphical-Perception",
      "pdf_url": "http://arxiv.org/pdf/2503.00086v1",
      "published_date": "2025-02-28 13:32:06 UTC",
      "updated_date": "2025-02-28 13:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:17:04.787269"
    },
    {
      "arxiv_id": "2503.01905v2",
      "title": "PaCA: Partial Connection Adaptation for Efficient Fine-Tuning",
      "title_zh": "PaCA：部分连接适应用于高效微调",
      "authors": [
        "Sunghyeon Woo",
        "Sol Namkung",
        "Sunwoo Lee",
        "Inho Jeong",
        "Beomseok Kim",
        "Dongsuk Jeon"
      ],
      "abstract": "Prior parameter-efficient fine-tuning (PEFT) algorithms reduce memory usage\nand computational costs of fine-tuning large neural network models by training\nonly a few additional adapter parameters, rather than the entire model.\nHowever, the reduction in computational costs due to PEFT does not necessarily\ntranslate to a reduction in training time; although the computational costs of\nthe adapter layers are much smaller than the pretrained layers, it is well\nknown that those two types of layers are processed sequentially on GPUs,\nresulting in significant latency overhead. LoRA and its variants merge low-rank\nadapter matrices with pretrained weights during inference to avoid latency\noverhead, but during training, the pretrained weights remain frozen while the\nadapter matrices are continuously updated, preventing such merging. To mitigate\nthis issue, we propose Partial Connection Adaptation (PaCA), which fine-tunes\nrandomly selected partial connections within the pretrained weights instead of\nintroducing adapter layers in the model. PaCA not only enhances training speed\nby eliminating the time overhead due to the sequential processing of the\nadapter and pretrained layers but also reduces activation memory since only\npartial activations, rather than full activations, need to be stored for\ngradient computation. Compared to LoRA, PaCA reduces training time by 22% and\ntotal memory usage by 16%, while maintaining comparable accuracy across various\nfine-tuning scenarios, such as fine-tuning on the MMLU dataset and instruction\ntuning on the Oasst1 dataset. PaCA can also be combined with quantization,\nenabling the fine-tuning of large models such as LLaMA3.1-70B. In addition,\nPaCA enables training with 23% longer sequence and improves throughput by 16%\non both NVIDIA A100 GPU and INTEL Gaudi2 HPU compared to LoRA. The code is\navailable at https://github.com/WooSunghyeon/paca.",
      "tldr_zh": "该论文提出 PaCA（Partial Connection Adaptation），一种高效的微调方法，通过在预训练权重中随机选择部分连接进行微调，而不是添加传统 adapter 层，从而解决现有 PEFT（Parameter-Efficient Fine-Tuning）算法如 LoRA 在训练时因顺序处理导致的延迟和内存开销问题。PaCA 显著减少了 22% 的训练时间和 16% 的总内存使用，同时在 MMLU 数据集微调和 Oasst1 指令调优等场景中保持了相似的准确率。实验结果显示，PaCA 还支持与量化结合，用于大型模型如 LLaMA3.1-70B，并实现了 23% 更长的序列长度和 16% 的吞吐量提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01905v2",
      "published_date": "2025-02-28 13:30:10 UTC",
      "updated_date": "2025-03-11 15:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:17:17.306378"
    },
    {
      "arxiv_id": "2502.21038v1",
      "title": "Reward Learning from Multiple Feedback Types",
      "title_zh": "从多种反馈类型中学习奖励",
      "authors": [
        "Yannick Metz",
        "András Geiszl",
        "Raphaël Baur",
        "Mennatallah El-Assady"
      ],
      "abstract": "Learning rewards from preference feedback has become an important tool in the\nalignment of agentic models. Preference-based feedback, often implemented as a\nbinary comparison between multiple completions, is an established method to\nacquire large-scale human feedback. However, human feedback in other contexts\nis often much more diverse. Such diverse feedback can better support the goals\nof a human annotator, and the simultaneous use of multiple sources might be\nmutually informative for the learning process or carry type-dependent biases\nfor the reward learning process. Despite these potential benefits, learning\nfrom different feedback types has yet to be explored extensively. In this\npaper, we bridge this gap by enabling experimentation and evaluating multi-type\nfeedback in a broad set of environments. We present a process to generate\nhigh-quality simulated feedback of six different types. Then, we implement\nreward models and downstream RL training for all six feedback types. Based on\nthe simulated feedback, we investigate the use of types of feedback across ten\nRL environments and compare them to pure preference-based baselines. We show\nempirically that diverse types of feedback can be utilized and lead to strong\nreward modeling performance. This work is the first strong indicator of the\npotential of multi-type feedback for RLHF.",
      "tldr_zh": "该论文探讨了从多种反馈类型中学习奖励，以提升代理模型的校准效果，超越传统的偏好反馈方法。研究者开发了一个生成六种不同反馈类型的高质量模拟过程，并实现了相应的奖励模型和下游强化学习（RL）训练。在十个 RL 环境上进行的实验显示，多类型反馈比纯偏好反馈基线表现出色，能提升奖励建模性能，并揭示了类型间相互信息的作用。该工作首次证明了多类型反馈在 RLHF 中的巨大潜力，为未来的人类反馈应用提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.21038v1",
      "published_date": "2025-02-28 13:29:54 UTC",
      "updated_date": "2025-02-28 13:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:17:27.828747"
    },
    {
      "arxiv_id": "2502.21034v1",
      "title": "Synthesizing Tabular Data Using Selectivity Enhanced Generative Adversarial Networks",
      "title_zh": "使用选择性增强生成对抗网络合成表格数据",
      "authors": [
        "Youran Zhou",
        "Jianzhong Qi"
      ],
      "abstract": "As E-commerce platforms face surging transactions during major shopping\nevents like Black Friday, stress testing with synthesized data is crucial for\nresource planning. Most recent studies use Generative Adversarial Networks\n(GANs) to generate tabular data while ensuring privacy and machine learning\nutility. However, these methods overlook the computational demands of\nprocessing GAN-generated data, making them unsuitable for E-commerce stress\ntesting.\n  This thesis introduces a novel GAN-based approach incorporating query\nselectivity constraints, a key factor in database transaction processing. We\nintegrate a pre-trained deep neural network to maintain selectivity consistency\nbetween real and synthetic data. Our method, tested on five real-world\ndatasets, outperforms three state-of-the-art GANs and a VAE model, improving\nselectivity estimation accuracy by up to 20pct and machine learning utility by\nup to 6 pct.",
      "tldr_zh": "该研究针对电子商务平台在购物高峰期（如Black Friday）进行压力测试的需求，提出了一种增强型Generative Adversarial Networks (GANs) 方法，以合成表格数据。该方法整合查询选择性（query selectivity）约束，并使用预训练的深度神经网络，确保合成数据与真实数据的选择性一致性，从而优化数据库交易处理计算需求。在五个真实世界数据集上的实验中，该方法优于三款最先进GANs和一个VAE模型，提高了选择性估计准确率高达20%和机器学习效用高达6%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This thesis submitted to the University of Melbourne for partial\n  fulfillment of the degree of Master of Data Science",
      "pdf_url": "http://arxiv.org/pdf/2502.21034v1",
      "published_date": "2025-02-28 13:26:41 UTC",
      "updated_date": "2025-02-28 13:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:17:40.189566"
    },
    {
      "arxiv_id": "2502.21030v1",
      "title": "Beyond Words: A Latent Memory Approach to Internal Reasoning in LLMs",
      "title_zh": "超越文字：LLMs 中内部推理的潜在记忆方法",
      "authors": [
        "José I. Orlicki"
      ],
      "abstract": "Recent advances in large language models (LLMs) have popularized the\nchain-of-thought (CoT) paradigm, in which models produce explicit reasoning\nsteps in natural language. Although this approach improves interpretability and\nfacilitates external auditing, it may not represent the most computationally\nefficient method for internal reasoning. In contrast, human cognition relies on\nimplicit mental representations that recall past sensory and episodic\ninformation without requiring complete verbalization. In this paper, we propose\na framework that integrates implicit mental representations into the internal\nreasoning processes of LLMs. Preliminary experiments indicate that\nincorporating an Implicit Memory Module (IMM) into a simple GPT model yields a\nreduction of between 35% and 57% in final training loss compared to a regular\nGPT baseline. The addition of an explicit interpretability channel (e.g., a\nchain-of-thought decoder) is straightforward to implement within this approach.\nWe outline theoretical foundations, propose technical mechanisms to scale the\nmemory module, and discuss how these ideas may lead to more efficient and\nrobust reasoning, with optional future extensions for explicit auditability.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）中内部推理的优化问题，指出传统的 Chain-of-Thought (CoT) 范式虽提升了可解释性，但可能不够高效。研究提出一个框架，将隐式心理表征整合到 LLMs 的内部推理中，通过引入 Implicit Memory Module (IMM)，模拟人类认知方式以减少完整 verbalization。实验结果显示，在简单 GPT 模型中添加 IMM 可将最终训练损失降低 35% 到 57%。此外，该方法易于扩展，支持添加显式可解释性通道，并为更高效、鲁棒的推理提供理论基础和未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.21030v1",
      "published_date": "2025-02-28 13:22:29 UTC",
      "updated_date": "2025-02-28 13:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:17:52.804332"
    },
    {
      "arxiv_id": "2502.21028v2",
      "title": "Measuring and identifying factors of individuals' trust in Large Language Models",
      "title_zh": "测量和识别个体对大型",
      "authors": [
        "Edoardo Sebastiano De Duro",
        "Giuseppe Alessandro Veltri",
        "Hudson Golino",
        "Massimo Stella"
      ],
      "abstract": "Large Language Models (LLMs) can engage in human-looking conversational\nexchanges. Although conversations can elicit trust between users and LLMs,\nscarce empirical research has examined trust formation in human-LLM contexts,\nbeyond LLMs' trustworthiness or human trust in AI in general. Here, we\nintroduce the Trust-In-LLMs Index (TILLMI) as a new framework to measure\nindividuals' trust in LLMs, extending McAllister's cognitive and affective\ntrust dimensions to LLM-human interactions. We developed TILLMI as a\npsychometric scale, prototyped with a novel protocol we called LLM-simulated\nvalidity. The LLM-based scale was then validated in a sample of 1,000 US\nrespondents. Exploratory Factor Analysis identified a two-factor structure. Two\nitems were then removed due to redundancy, yielding a final 6-item scale with a\n2-factor structure. Confirmatory Factor Analysis on a separate subsample showed\nstrong model fit ($CFI = .995$, $TLI = .991$, $RMSEA = .046$, $p_{X^2} > .05$).\nConvergent validity analysis revealed that trust in LLMs correlated positively\nwith openness to experience, extraversion, and cognitive flexibility, but\nnegatively with neuroticism. Based on these findings, we interpreted TILLMI's\nfactors as \"closeness with LLMs\" (affective dimension) and \"reliance on LLMs\"\n(cognitive dimension). Younger males exhibited higher closeness with- and\nreliance on LLMs compared to older women. Individuals with no direct experience\nwith LLMs exhibited lower levels of trust compared to LLMs' users. These\nfindings offer a novel empirical foundation for measuring trust in AI-driven\nverbal communication, informing responsible design, and fostering balanced\nhuman-AI collaboration.",
      "tldr_zh": "这篇论文提出了 Trust-In-LLMs Index (TILLMI)，一个新的框架，用于测量个体对 Large Language Models (LLMs) 的信任，扩展了 McAllister 的认知和情感信任维度。研究开发了这一心理测量量表，通过 Exploratory Factor Analysis 识别了两个因子结构（“closeness with LLMs”和“reliance on LLMs”），并在 1000 名美国受访者样本中进行 Confirmatory Factor Analysis，显示了良好的模型拟合。关键发现包括：信任与开放性、外向性和认知灵活性正相关，与神经质负相关；年轻男性比年长女性有更高信任，且未使用 LLMs 的人群信任水平较低。这些结果为评估 AI 驱动沟通中的信任提供经验基础，支持负责任的设计和人类-AI 协作。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.21028v2",
      "published_date": "2025-02-28 13:16:34 UTC",
      "updated_date": "2025-03-05 15:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:18:05.645209"
    },
    {
      "arxiv_id": "2503.01904v1",
      "title": "What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Gapp",
        "Elias Tappeiner",
        "Martin Welk",
        "Karl Fritscher",
        "Elke Ruth Gizewski",
        "Rainer Schubert"
      ],
      "abstract": "Purpose High dimensional, multimodal data can nowadays be analyzed by huge\ndeep neural networks with little effort. Several fusion methods for bringing\ntogether different modalities have been developed. Particularly, in the field\nof medicine with its presence of high dimensional multimodal patient data,\nmultimodal models characterize the next step. However, what is yet very\nunderexplored is how these models process the source information in detail.\nMethods To this end, we implemented an occlusion-based both model and\nperformance agnostic modality contribution method that quantitatively measures\nthe importance of each modality in the dataset for the model to fulfill its\ntask. We applied our method to three different multimodal medical problems for\nexperimental purposes. Results Herein we found that some networks have modality\npreferences that tend to unimodal collapses, while some datasets are imbalanced\nfrom the ground up. Moreover, we could determine a link between our metric and\nthe performance of single modality trained nets. Conclusion The information\ngain through our metric holds remarkable potential to improve the development\nof multimodal models and the creation of datasets in the future. With our\nmethod we make a crucial contribution to the field of interpretability in deep\nlearning based multimodal research and thereby notably push the integrability\nof multimodal AI into clinical practice. Our code is publicly available at\nhttps://github.com/ChristianGappGit/MC_MMD.",
      "tldr_zh": "这篇论文探讨了在multimodal medical deep learning方法中各模态的贡献，旨在量化不同模态对模型性能的重要性。研究者开发了一种基于occlusion的模态贡献度量方法，该方法不依赖特定模型或性能，并应用于三个多模态医学问题。结果显示，一些网络存在模态偏好导致的单模态崩溃，以及数据集的固有失衡，并揭示了这种度量与单模态训练性能之间的联系。该方法为改进multimodal模型开发和数据集创建提供了关键洞见，推动multimodal AI在临床实践中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "Contribution to Conference for Computer Assisted Radiology and\n  Surgery (CARS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.01904v1",
      "published_date": "2025-02-28 12:39:39 UTC",
      "updated_date": "2025-02-28 12:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:18:16.897732"
    },
    {
      "arxiv_id": "2503.01903v1",
      "title": "PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxi Wang",
        "Shuyu Liu",
        "Ling Zhang",
        "Xuequan Zhu",
        "Rui Yang",
        "Xinzhu Zhou",
        "Fei Wu",
        "Zhi Yang",
        "Cheng Jin",
        "Gang Wang"
      ],
      "abstract": "The advent of Large Language Models (LLMs) offers potential solutions to\naddress problems such as shortage of medical resources and low diagnostic\nconsistency in psychiatric clinical practice. Despite this potential, a robust\nand comprehensive benchmarking framework to assess the efficacy of LLMs in\nauthentic psychiatric clinical environments is absent. This has impeded the\nadvancement of specialized LLMs tailored to psychiatric applications. In\nresponse to this gap, by incorporating clinical demands in psychiatry and\nclinical data, we proposed a benchmarking system, PsychBench, to evaluate the\npractical performance of LLMs in psychiatric clinical settings. We conducted a\ncomprehensive quantitative evaluation of 16 LLMs using PsychBench, and\ninvestigated the impact of prompt design, chain-of-thought reasoning, input\ntext length, and domain-specific knowledge fine-tuning on model performance.\nThrough detailed error analysis, we identified strengths and potential\nlimitations of the existing models and suggested directions for improvement.\nSubsequently, a clinical reader study involving 60 psychiatrists of varying\nseniority was conducted to further explore the practical benefits of existing\nLLMs as supportive tools for psychiatrists of varying seniority. Through the\nquantitative and reader evaluation, we show that while existing models\ndemonstrate significant potential, they are not yet adequate as decision-making\ntools in psychiatric clinical practice. The reader study further indicates\nthat, as an auxiliary tool, LLM could provide particularly notable support for\njunior psychiatrists, effectively enhancing their work efficiency and overall\nclinical quality. To promote research in this area, we will make the dataset\nand evaluation framework publicly available, with the hope of advancing the\napplication of LLMs in psychiatric clinical settings.",
      "tldr_zh": "该研究提出了 PsychBench，这是一个全面且专业的基准系统，用于评估大型语言模型 (LLMs) 在精神病学临床实践中的性能，旨在解决医疗资源短缺和诊断一致性问题。研究对 16 个 LLMs 进行了定量评估，考察了提示设计、chain-of-thought reasoning、输入文本长度以及领域特定知识微调等因素的影响，并通过错误分析识别了模型的优点和局限性。读者研究涉及 60 名不同资历的精神病医生，结果显示现有 LLMs 作为决策工具尚不充分，但可作为辅助工具显著提升初级医生的工作效率和临床质量。为推动该领域发展，作者计划公开数据集和评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01903v1",
      "published_date": "2025-02-28 12:17:41 UTC",
      "updated_date": "2025-02-28 12:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:18:29.873431"
    },
    {
      "arxiv_id": "2502.20988v1",
      "title": "Merging Clinical Knowledge into Large Language Models for Medical Research and Applications: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyuan Li",
        "Haijiang Liu",
        "Caicai Guo",
        "Deyu Chen",
        "Meng Wang",
        "Feng Gao",
        "Jinguang Gu"
      ],
      "abstract": "Clinical knowledge is the collection of information learned from studies on\nthe causes, prognosis, diagnosis, and treatment of diseases. This type of\nknowledge can improve curing performances, and promote physical health. With\nthe emergence of large language models (LLMs), medical artificial intelligence\n(medical AI), which aims to apply academic medical AI systems to real-world\nmedical scenarios, has entered a new age of development, resulting in excellent\nworks such as DoctorGPT and Pangu-Drug from academic and industrial researches.\nHowever, the field lacks a comprehensive compendium and comparison of building\nmedical AI systems from academia and industry. Therefore, this survey focuses\non the building paradigms of medical AI systems including the use of clinical\ndatabases, datasets, training pipelines, integrating medical knowledge graphs,\nsystem applications, and evaluation systems. We hope that this survey can help\nrelevant practical researchers understand the current performance of academic\nmodels in various fields of healthcare, as well as the potential problems and\nfuture directions for implementing these scientific achievements.",
      "tldr_zh": "这篇调查论文探讨了如何将临床知识整合到大型语言模型（LLMs）中，以推进医疗研究和应用。论文综述了构建医疗AI系统的关键范式，包括利用临床数据库、数据集、训练管道、医疗知识图谱（knowledge graphs）、系统应用以及评估方法。作者比较了学术和工业领域的代表性工作，如DoctorGPT和Pangu-Drug，强调了这些模型在医疗领域的表现、潜在挑战（如知识缺口和实际部署问题），并指出了未来发展方向，以帮助研究者更好地应用这些技术。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20988v1",
      "published_date": "2025-02-28 12:00:51 UTC",
      "updated_date": "2025-02-28 12:00:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:18:39.425096"
    },
    {
      "arxiv_id": "2502.20985v1",
      "title": "LesionLocator: Zero-Shot Universal Tumor Segmentation and Tracking in 3D Whole-Body Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Rokuss",
        "Yannick Kirchhoff",
        "Seval Akbal",
        "Balint Kovacs",
        "Saikat Roy",
        "Constantin Ulrich",
        "Tassilo Wald",
        "Lukas T. Rotkopf",
        "Heinz-Peter Schlemmer",
        "Klaus Maier-Hein"
      ],
      "abstract": "In this work, we present LesionLocator, a framework for zero-shot\nlongitudinal lesion tracking and segmentation in 3D medical imaging,\nestablishing the first end-to-end model capable of 4D tracking with dense\nspatial prompts. Our model leverages an extensive dataset of 23,262 annotated\nmedical scans, as well as synthesized longitudinal data across diverse lesion\ntypes. The diversity and scale of our dataset significantly enhances model\ngeneralizability to real-world medical imaging challenges and addresses key\nlimitations in longitudinal data availability. LesionLocator outperforms all\nexisting promptable models in lesion segmentation by nearly 10 dice points,\nreaching human-level performance, and achieves state-of-the-art results in\nlesion tracking, with superior lesion retrieval and segmentation accuracy.\nLesionLocator not only sets a new benchmark in universal promptable lesion\nsegmentation and automated longitudinal lesion tracking but also provides the\nfirst open-access solution of its kind, releasing our synthetic 4D dataset and\nmodel to the community, empowering future advancements in medical imaging. Code\nis available at: www.github.com/MIC-DKFZ/LesionLocator",
      "tldr_zh": "本研究提出 LesionLocator 框架，实现 zero-shot 通用肿瘤分割和跟踪，支持 3D 全身体成像中的端到端 4D 跟踪，并使用密集空间提示。框架利用 23,262 个标注医疗扫描和合成的纵向数据，增强模型的泛化能力，解决真实医疗成像挑战。实验结果显示，LesionLocator 在病变分割上比现有可提示模型提高近 10 Dice points，达到人类水平，并在病变跟踪中取得最先进性能，同时开源合成 4D 数据集和模型，促进医疗成像领域的未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.20985v1",
      "published_date": "2025-02-28 11:58:33 UTC",
      "updated_date": "2025-02-28 11:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:18:53.169808"
    },
    {
      "arxiv_id": "2502.20984v3",
      "title": "UoR-NCL at SemEval-2025 Task 1: Using Generative LLMs and CLIP Models for Multilingual Multimodal Idiomaticity Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Thanet Markchom",
        "Tong Wu",
        "Liting Huang",
        "Huizhi Liang"
      ],
      "abstract": "SemEval-2025 Task 1 focuses on ranking images based on their alignment with a\ngiven nominal compound that may carry idiomatic meaning in both English and\nBrazilian Portuguese. To address this challenge, this work uses generative\nlarge language models (LLMs) and multilingual CLIP models to enhance idiomatic\ncompound representations. LLMs generate idiomatic meanings for potentially\nidiomatic compounds, enriching their semantic interpretation. These meanings\nare then encoded using multilingual CLIP models, serving as representations for\nimage ranking. Contrastive learning and data augmentation techniques are\napplied to fine-tune these embeddings for improved performance. Experimental\nresults show that multimodal representations extracted through this method\noutperformed those based solely on the original nominal compounds. The\nfine-tuning approach shows promising outcomes but is less effective than using\nembeddings without fine-tuning. The source code used in this paper is available\nat https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL.",
      "tldr_zh": "本研究针对 SemEval-2025 Task 1 的任务，即根据英语和巴西葡萄牙语的名词复合词（可能带有成语含义）对图像进行排名，提出了一种使用生成式大型语言模型（LLMs）和多语言 CLIP 模型的方法来增强多模态成语表示。LLMs 用于生成成语含义以丰富语义解释，这些含义随后通过 CLIP 模型编码，并应用对比学习和数据增强技术进行微调。实验结果显示，这种多模态表示方法优于仅基于原名词复合词的表示，而微调策略虽有前景但不如直接使用嵌入有效。源代码可从 https://github.com/tongwu17/SemEval-2025-Task1-UoR-NCL 获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20984v3",
      "published_date": "2025-02-28 11:52:02 UTC",
      "updated_date": "2025-05-01 14:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:19:06.303146"
    },
    {
      "arxiv_id": "2502.20974v1",
      "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Li",
        "Xiangkun Wang",
        "Xin Yang",
        "Marcello Bonsangue",
        "Junbo Zhang",
        "Tianrui Li"
      ],
      "abstract": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.",
      "tldr_zh": "这篇论文针对开放世界持续学习（Open-world Continual Learning, OWCL）在标签数据稀缺时的挑战，提出了一种改进框架，即开放世界少样本持续学习（Open-world Few-shot Continual Learning, OFCL）。该框架整合了三个关键组件：实例级标记增强（Instance-wise Token Augmentation, ITA）来丰富样本表示、基于边界的开放边界（Margin-based Open Boundary, MOB）来构建紧凑决策边界检测新任务，以及自适应知识空间（Adaptive Knowledge Space, AKS）来转移和更新已知与未知知识。实验结果显示，OFCL 框架在各种基准上显著优于基线模型，具有实际重要性和可复现性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20974v1",
      "published_date": "2025-02-28 11:39:18 UTC",
      "updated_date": "2025-02-28 11:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:19:19.234987"
    },
    {
      "arxiv_id": "2503.11674v1",
      "title": "Timing-Driven Global Placement by Efficient Critical Path Extraction",
      "title_zh": "通过高效关键路径提取的时序驱动全局布局",
      "authors": [
        "Yunqi Shi",
        "Siyuan Xu",
        "Shixiong Kai",
        "Xi Lin",
        "Ke Xue",
        "Mingxuan Yuan",
        "Chao Qian"
      ],
      "abstract": "Timing optimization during the global placement of integrated circuits has\nbeen a significant focus for decades, yet it remains a complex, unresolved\nissue. Recent analytical methods typically use pin-level timing information to\nadjust net weights, which is fast and simple but neglects the path-based nature\nof the timing graph. The existing path-based methods, however, cannot balance\nthe accuracy and efficiency due to the exponential growth of number of critical\npaths. In this work, we propose a GPU-accelerated timing-driven global\nplacement framework, integrating accurate path-level information into the\nefficient DREAMPlace infrastructure. It optimizes the fine-grained pin-to-pin\nattraction objective and is facilitated by efficient critical path extraction.\nWe also design a quadratic distance loss function specifically to align with\nthe RC timing model. Experimental results demonstrate that our method\nsignificantly outperforms the current leading timing-driven placers, achieving\nan average improvement of 40.5% in total negative slack (TNS) and 8.3% in worst\nnegative slack (WNS), as well as an improvement in half-perimeter wirelength\n(HPWL).",
      "tldr_zh": "这篇论文针对集成电路全局布局中的时序优化问题，提出了一种高效的 Critical Path Extraction 方法，以解决现有引脚级和路径级方法的准确性和效率平衡难题。该框架采用 GPU-accelerated 技术，集成到 DREAMPlace 基础设施中，并优化细粒度的引脚到引脚吸引目标，同时设计了与 RC Timing Model 匹配的二次距离损失函数。实验结果显示，该方法相较于领先的时序驱动布局器，平均改善了 40.5% 的 Total Negative Slack (TNS)、8.3% 的 Worst Negative Slack (WNS)，并提升了 Half-Perimeter Wirelength (HPWL)。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by DATE'25 as a Best Paper Award",
      "pdf_url": "http://arxiv.org/pdf/2503.11674v1",
      "published_date": "2025-02-28 11:34:19 UTC",
      "updated_date": "2025-02-28 11:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:19:32.117456"
    },
    {
      "arxiv_id": "2502.20964v2",
      "title": "Fine-Grained Retrieval-Augmented Generation for Visual Question Answering",
      "title_zh": "细粒度检索增强生成用于视觉",
      "authors": [
        "Zhengxuan Zhang",
        "Yin Wu",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "abstract": "Visual Question Answering (VQA) focuses on providing answers to natural\nlanguage questions by utilizing information from images. Although cutting-edge\nmultimodal large language models (MLLMs) such as GPT-4o achieve strong\nperformance on VQA tasks, they frequently fall short in accessing\ndomain-specific or the latest knowledge. To mitigate this issue,\nretrieval-augmented generation (RAG) leveraging external knowledge bases (KBs),\nreferred to as KB-VQA, emerges as a promising approach. Nevertheless,\nconventional unimodal retrieval techniques, which translate images into textual\ndescriptions, often result in the loss of critical visual details. This study\npresents fine-grained knowledge units, which merge textual snippets with entity\nimages stored in vector databases. Furthermore, we introduce a knowledge unit\nretrieval-augmented generation framework (KU-RAG) that integrates fine-grained\nretrieval with MLLMs. The proposed KU-RAG framework ensures precise retrieval\nof relevant knowledge and enhances reasoning capabilities through a knowledge\ncorrection chain. Experimental findings demonstrate that our approach\nsignificantly boosts the performance of leading KB-VQA methods, achieving an\naverage improvement of approximately 3% and up to 11% in the best case.",
      "tldr_zh": "这篇论文针对 Visual Question Answering (VQA) 的问题，提出一种细粒度检索增强生成方法，以解决 Multimodal Large Language Models (MLLMs) 如 GPT-4o 在访问领域特定知识时的不足。作者引入细粒度知识单位，将文本片段与实体图像整合存储在向量数据库中，并开发了 Knowledge Unit Retrieval-Augmented Generation 框架 (KU-RAG)，通过精确检索和知识修正链提升 MLLMs 的推理能力。实验结果显示，该框架显著提高了领先的 KB-VQA 方法性能，平均提升约 3%，最高达 11%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20964v2",
      "published_date": "2025-02-28 11:25:38 UTC",
      "updated_date": "2025-04-11 16:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:19:43.267458"
    },
    {
      "arxiv_id": "2502.20963v2",
      "title": "Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration",
      "title_zh": "检索增强生成在组织研究中的主题建模：一个实证演示的介绍",
      "authors": [
        "Gerion Spielberger",
        "Florian M. Artinger",
        "Jochen Reb",
        "Rudolf Kerschreiter"
      ],
      "abstract": "Analyzing textual data is the cornerstone of qualitative research. While\ntraditional methods such as grounded theory and content analysis are widely\nused, they are labor-intensive and time-consuming. Topic modeling offers an\nautomated complement. Yet, existing approaches, including LLM-based topic\nmodeling, still struggle with issues such as high data preprocessing\nrequirements, interpretability, and reliability. This paper introduces Agentic\nRetrieval-Augmented Generation (Agentic RAG) as a method for topic modeling\nwith LLMs. It integrates three key components: (1) retrieval, enabling\nautomatized access to external data beyond an LLM's pre-trained knowledge; (2)\ngeneration, leveraging LLM capabilities for text synthesis; and (3)\nagent-driven learning, iteratively refining retrieval and query formulation\nprocesses. To empirically validate Agentic RAG for topic modeling, we reanalyze\na Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings\ndemonstrate that the approach is more efficient, interpretable and at the same\ntime achieves higher reliability and validity in comparison to the standard\nmachine learning approach but also in comparison to LLM prompting for topic\nmodeling. These results highlight Agentic RAG's ability to generate\nsemantically relevant and reproducible topics, positioning it as a robust,\nscalable, and transparent alternative for AI-driven qualitative research in\nleadership, managerial, and organizational research.",
      "tldr_zh": "这篇论文介绍了 Agentic Retrieval-Augmented Generation (Agentic RAG) 作为一种基于 LLM 的主题建模方法，用于提升组织研究中的文本分析效率。该方法整合了三个关键组件：retrieval（自动访问外部数据）、generation（利用 LLM 进行文本合成）和 agent-driven learning（迭代优化检索和查询过程），以解决现有方法的预处理要求高、可解释性和可靠性不足等问题。通过重新分析一个 Twitter/X 数据集，实验结果显示 Agentic RAG 比标准机器学习方法和 LLM 提示方法更高效、可解释，并在可靠性和有效性上表现出色。该方法为 AI 驱动的定性研究（如领导力、管理和组织研究）提供了一个稳健、可扩展且透明的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.20963v2",
      "published_date": "2025-02-28 11:25:11 UTC",
      "updated_date": "2025-03-18 12:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:19:56.633136"
    },
    {
      "arxiv_id": "2502.20948v1",
      "title": "Concealed Adversarial attacks on neural networks for sequential data",
      "title_zh": "翻译失败",
      "authors": [
        "Petr Sokerin",
        "Dmitry Anikin",
        "Sofia Krehova",
        "Alexey Zaytsev"
      ],
      "abstract": "The emergence of deep learning led to the broad usage of neural networks in\nthe time series domain for various applications, including finance and\nmedicine. While powerful, these models are prone to adversarial attacks: a\nbenign targeted perturbation of input data leads to significant changes in a\nclassifier's output. However, formally small attacks in the time series domain\nbecome easily detected by the human eye or a simple detector model.\n  We develop a concealed adversarial attack for different time-series models:\nit provides more realistic perturbations, being hard to detect by a human or\nmodel discriminator. To achieve this goal, the proposed adversarial attack\nmaximizes an aggregation of a classifier and a trained discriminator loss. To\nmake the attack stronger, we also propose a training procedure for a\ndiscriminator that provides broader coverage of possible attacks. Extensive\nbenchmarking on six UCR time series datasets across four diverse architectures\n- including recurrent, convolutional, state-space, and transformer-based models\n- demonstrates the superiority of our attack for a concealability-efficiency\ntrade-off. Our findings highlight the growing challenge of designing robust\ntime series models, emphasizing the need for improved defenses against\nrealistic and effective attacks.",
      "tldr_zh": "该论文探讨了神经网络在时间序列数据（如金融和医学应用）中的易受对抗攻击（adversarial attacks）问题，这些攻击通过微小扰动即可显著改变分类器输出，但传统攻击易被人类或检测器识别。研究提出了一种隐藏对抗攻击（concealed adversarial attack），通过最大化分类器和训练鉴别器（discriminator）损失的聚合，生成更真实的、难以检测的扰动，并优化鉴别器的训练以覆盖更多攻击类型。在六个 UCR 时间序列数据集上，对循环、卷积、状态空间和基于变换器的四种模型进行基准测试，结果显示该攻击在隐藏性和效率权衡上优于基线方法。最终，该研究强调了设计鲁棒时间序列模型的紧迫性，并呼吁开发更有效的防御策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20948v1",
      "published_date": "2025-02-28 11:03:32 UTC",
      "updated_date": "2025-02-28 11:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:20:07.543954"
    },
    {
      "arxiv_id": "2502.20946v1",
      "title": "Generative Uncertainty in Diffusion Models",
      "title_zh": "扩散模型中的生成不确定性",
      "authors": [
        "Metod Jazbec",
        "Eliot Wong-Toi",
        "Guoxuan Xia",
        "Dan Zhang",
        "Eric Nalisnick",
        "Stephan Mandt"
      ],
      "abstract": "Diffusion models have recently driven significant breakthroughs in generative\nmodeling. While state-of-the-art models produce high-quality samples on\naverage, individual samples can still be low quality. Detecting such samples\nwithout human inspection remains a challenging task. To address this, we\npropose a Bayesian framework for estimating generative uncertainty of synthetic\nsamples. We outline how to make Bayesian inference practical for large, modern\ngenerative models and introduce a new semantic likelihood (evaluated in the\nlatent space of a feature extractor) to address the challenges posed by\nhigh-dimensional sample spaces. Through our experiments, we demonstrate that\nthe proposed generative uncertainty effectively identifies poor-quality samples\nand significantly outperforms existing uncertainty-based methods. Notably, our\nBayesian framework can be applied post-hoc to any pretrained diffusion or flow\nmatching model (via the Laplace approximation), and we propose simple yet\neffective techniques to minimize its computational overhead during sampling.",
      "tldr_zh": "本文提出了一种Bayesian框架，用于估计扩散模型生成样本的不确定性，从而有效识别低质量样本。该框架引入了新的语义似然函数（在特征提取器的潜在空间中评估），以应对高维样本空间的挑战，并通过Laplace近似实现后验应用，支持任何预训练的扩散或流匹配模型。实验结果显示，该方法显著优于现有不确定性方法，同时采用简单技术最小化计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20946v1",
      "published_date": "2025-02-28 10:56:39 UTC",
      "updated_date": "2025-02-28 10:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:20:17.546291"
    },
    {
      "arxiv_id": "2502.20938v1",
      "title": "A Deep User Interface for Exploring LLaMa",
      "title_zh": "翻译失败",
      "authors": [
        "Divya Perumal",
        "Swaroop Panda"
      ],
      "abstract": "The growing popularity and widespread adoption of large language models\n(LLMs) necessitates the development of tools that enhance the effectiveness of\nuser interactions with these models. Understanding the structures and functions\nof these models poses a significant challenge for users. Visual\nanalytics-driven tools enables users to explore and compare, facilitating\nbetter decision-making. This paper presents a visual analytics-driven tool\nequipped with interactive controls for key hyperparameters, including top-p,\nfrequency and presence penalty, enabling users to explore, examine and compare\nthe outputs of LLMs. In a user study, we assessed the tool's effectiveness,\nwhich received favorable feedback for its visual design, with particular\ncommendation for the interface layout and ease of navigation. Additionally, the\nfeedback provided valuable insights for enhancing the effectiveness of\nHuman-LLM interaction tools.",
      "tldr_zh": "该论文提出了一种名为“A Deep User Interface”的视觉分析驱动工具，用于帮助用户探索和比较大型语言模型(LLMs)，如LLaMa，从而提升用户互动的有效性。该工具配备交互控件，允许用户调整关键超参数（如top-p、frequency和presence penalty），以探索模型的输出结构和功能。在用户研究中，该工具的视觉设计和界面布局获得积极反馈，并提供了改进Human-LLM交互的宝贵见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20938v1",
      "published_date": "2025-02-28 10:48:14 UTC",
      "updated_date": "2025-02-28 10:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:20:29.457911"
    },
    {
      "arxiv_id": "2502.20936v1",
      "title": "WebFAQ: A Multilingual Collection of Natural Q&A Datasets for Dense Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Dinzinger",
        "Laura Caspari",
        "Kanishka Ghosh Dastidar",
        "Jelena Mitrović",
        "Michael Granitzer"
      ],
      "abstract": "We present WebFAQ, a large-scale collection of open-domain question answering\ndatasets derived from FAQ-style schema.org annotations. In total, the data\ncollection consists of 96 million natural question-answer (QA) pairs across 75\nlanguages, including 47 million (49%) non-English samples. WebFAQ further\nserves as the foundation for 20 monolingual retrieval benchmarks with a total\nsize of 11.2 million QA pairs (5.9 million non-English). These datasets are\ncarefully curated through refined filtering and near-duplicate detection,\nyielding high-quality resources for training and evaluating multilingual dense\nretrieval models. To empirically confirm WebFAQ's efficacy, we use the\ncollected QAs to fine-tune an in-domain pretrained XLM-RoBERTa model. Through\nthis process of dataset-specific fine-tuning, the model achieves significant\nretrieval performance gains, which generalize - beyond WebFAQ - to other\nmultilingual retrieval benchmarks evaluated in zero-shot setting. Last but not\nleast, we utilize WebFAQ to construct a set of QA-aligned bilingual corpora\nspanning over 1000 language pairs using state-of-the-art bitext mining and\nautomated LLM-assessed translation evaluation. Due to our advanced, automated\nmethod of bitext dataset generation, the resulting bilingual corpora\ndemonstrate higher translation quality compared to similar datasets. WebFAQ and\nall associated resources are publicly available on GitHub and HuggingFace.",
      "tldr_zh": "该论文介绍了 WebFAQ，这是一个从 FAQ 风格的 schema.org 注释中衍生的大规模多语言自然问答数据集，总计 9600 万 QA 对，覆盖 75 种语言，其中近半数是非英语样本。WebFAQ 通过精炼过滤和近重复检测确保数据质量，并作为基础创建了 20 个单语检索基准，总计 1120 万 QA 对，用于训练和评估 multilingual dense retrieval 模型。研究利用 WebFAQ 微调 XLM-RoBERTa 模型，实现了显著的检索性能提升，并在零样本设置下泛化到其他基准；此外，还构建了超过 1000 个语言对的 QA 对齐双语语料库，这些语料库通过 bitext mining 和 LLM 评估显示出更高的翻译质量。所有资源已在 GitHub 和 HuggingFace 上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.20936v1",
      "published_date": "2025-02-28 10:46:52 UTC",
      "updated_date": "2025-02-28 10:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:20:43.407716"
    },
    {
      "arxiv_id": "2502.20934v2",
      "title": "Less is More? Revisiting the Importance of Frame Rate in Real-Time Zero-Shot Surgical Video Segmentation",
      "title_zh": "少即是多？重新审视实时零样本手术视频分割中帧率的重要性",
      "authors": [
        "Utku Ozbulak",
        "Seyed Amir Mousavi",
        "Francesca Tozzi",
        "Niki Rashidian",
        "Wouter Willaert",
        "Wesley De Neve",
        "Joris Vankerschaver"
      ],
      "abstract": "Real-time video segmentation is a promising feature for AI-assisted surgery,\nproviding intraoperative guidance by identifying surgical tools and anatomical\nstructures. However, deploying state-of-the-art segmentation models, such as\nSAM2, in real-time settings is computationally demanding, which makes it\nessential to balance frame rate and segmentation performance. In this study, we\ninvestigate the impact of frame rate on zero-shot surgical video segmentation,\nevaluating SAM2's effectiveness across multiple frame sampling rates for\ncholecystectomy procedures. Surprisingly, our findings indicate that in\nconventional evaluation settings, frame rates as low as a single frame per\nsecond can outperform 25 FPS, as fewer frames smooth out segmentation\ninconsistencies. However, when assessed in a real-time streaming scenario,\nhigher frame rates yield superior temporal coherence and stability,\nparticularly for dynamic objects such as surgical graspers. Finally, we\ninvestigate human perception of real-time surgical video segmentation among\nprofessionals who work closely with such data and find that respondents\nconsistently prefer high FPS segmentation mask overlays, reinforcing the\nimportance of real-time evaluation in AI-assisted surgery.",
      "tldr_zh": "本研究重新审视了帧率在实时 Zero-Shot 手术视频分割中的重要性，通过评估 SAM2 模型在胆囊切除手术中的不同帧采样率表现。结果显示，在传统评估设置下，低帧率（如每秒一帧）可能优于25 FPS，因为它能平滑分割不一致性。然而，在实时流式场景中，高帧率提供更好的时间连贯性和稳定性，特别是针对动态物体如手术抓取器。最终，通过调查专业人士的人类感知，发现他们更偏好高 FPS 的分割掩码叠加，这强化了实时评估在 AI 辅助手术中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20934v2",
      "published_date": "2025-02-28 10:42:09 UTC",
      "updated_date": "2025-04-07 13:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:20:55.868042"
    },
    {
      "arxiv_id": "2502.20914v1",
      "title": "Everything, Everywhere, All at Once: Is Mechanistic Interpretability Identifiable?",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Méloux",
        "Silviu Maniu",
        "François Portet",
        "Maxime Peyrard"
      ],
      "abstract": "As AI systems are used in high-stakes applications, ensuring interpretability\nis crucial. Mechanistic Interpretability (MI) aims to reverse-engineer neural\nnetworks by extracting human-understandable algorithms to explain their\nbehavior. This work examines a key question: for a given behavior, and under\nMI's criteria, does a unique explanation exist? Drawing on identifiability in\nstatistics, where parameters are uniquely inferred under specific assumptions,\nwe explore the identifiability of MI explanations.\n  We identify two main MI strategies: (1) \"where-then-what,\" which isolates a\ncircuit replicating model behavior before interpreting it, and (2)\n\"what-then-where,\" which starts with candidate algorithms and searches for\nneural activation subspaces implementing them, using causal alignment.\n  We test both strategies on Boolean functions and small multi-layer\nperceptrons, fully enumerating candidate explanations. Our experiments reveal\nsystematic non-identifiability: multiple circuits can replicate behavior, a\ncircuit can have multiple interpretations, several algorithms can align with\nthe network, and one algorithm can align with different subspaces.\n  Is uniqueness necessary? A pragmatic approach may require only predictive and\nmanipulability standards. If uniqueness is essential for understanding,\nstricter criteria may be needed. We also reference the inner interpretability\nframework, which validates explanations through multiple criteria. This work\ncontributes to defining explanation standards in AI.",
      "tldr_zh": "这篇论文探讨了 Mechanistic Interpretability (MI) 的可识别性，即在神经网络行为解释中，是否存在唯一的算法解释。作者借鉴统计学中的 identifiability 概念，分析了两种 MI 策略：“where-then-what”（先隔离电路再解释）和“what-then-where”（先候选算法再搜索神经激活子空间），并通过在 Boolean 函数和小多层感知器上的实验验证了系统性的非唯一性，如多个电路可复制行为或一个算法可与不同子空间对齐。论文强调，唯一性并非必要，可采用预测和可操作性标准，并为 AI 解释框架的标准化提供了新贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20914v1",
      "published_date": "2025-02-28 10:13:54 UTC",
      "updated_date": "2025-02-28 10:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:21:07.426365"
    },
    {
      "arxiv_id": "2504.05324v1",
      "title": "Hybrid Retrieval for Hallucination Mitigation in Large Language Models: A Comparative Analysis",
      "title_zh": "大型语言模型中用于缓解幻觉的混合检索：一个比较分析",
      "authors": [
        "Chandana Sree Mala",
        "Gizem Gezici",
        "Fosca Giannotti"
      ],
      "abstract": "Large Language Models (LLMs) excel in language comprehension and generation\nbut are prone to hallucinations, producing factually incorrect or unsupported\noutputs. Retrieval Augmented Generation (RAG) systems address this issue by\ngrounding LLM responses with external knowledge. This study evaluates the\nrelationship between retriever effectiveness and hallucination reduction in\nLLMs using three retrieval approaches: sparse retrieval based on BM25 keyword\nsearch, dense retrieval using semantic search with Sentence Transformers, and a\nproposed hybrid retrieval module. The hybrid module incorporates query\nexpansion and combines the results of sparse and dense retrievers through a\ndynamically weighted Reciprocal Rank Fusion score. Using the HaluBench dataset,\na benchmark for hallucinations in question answering tasks, we assess retrieval\nperformance with metrics such as mean average precision and normalised\ndiscounted cumulative gain, focusing on the relevance of the top three\nretrieved documents. Results show that the hybrid retriever achieves better\nrelevance scores, outperforming both sparse and dense retrievers. Further\nevaluation of LLM-generated answers against ground truth using metrics such as\naccuracy, hallucination rate, and rejection rate reveals that the hybrid\nretriever achieves the highest accuracy on fails, the lowest hallucination\nrate, and the lowest rejection rate. These findings highlight the hybrid\nretriever's ability to enhance retrieval relevance, reduce hallucination rates,\nand improve LLM reliability, emphasising the importance of advanced retrieval\ntechniques in mitigating hallucinations and improving response accuracy.",
      "tldr_zh": "这篇论文比较了三种检索方法（sparse retrieval 基于 BM25 关键词搜索、dense retrieval 使用 Sentence Transformers 语义搜索，以及提出的 hybrid retrieval）来缓解 Large Language Models (LLMs) 中的幻觉问题。Hybrid retrieval 通过查询扩展（query expansion）和动态加权 Reciprocal Rank Fusion 结合 sparse 和 dense 结果，提升了检索相关性。使用 HaluBench 数据集进行评估，hybrid 方法在 mean average precision (MAP) 和 normalised discounted cumulative gain (nDCG) 等指标上优于其他方法。最终结果显示，hybrid retriever 显著降低了 hallucination rate，提高了 accuracy，并降低了 rejection rate，从而提升了 LLMs 的可靠性和响应准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05324v1",
      "published_date": "2025-02-28 10:13:33 UTC",
      "updated_date": "2025-02-28 10:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:21:20.004252"
    },
    {
      "arxiv_id": "2503.00084v1",
      "title": "InspireMusic: Integrating Super Resolution and Large Language Model for High-Fidelity Long-Form Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chong Zhang",
        "Yukun Ma",
        "Qian Chen",
        "Wen Wang",
        "Shengkui Zhao",
        "Zexu Pan",
        "Hao Wang",
        "Chongjia Ni",
        "Trung Hieu Nguyen",
        "Kun Zhou",
        "Yidi Jiang",
        "Chaohong Tan",
        "Zhifu Gao",
        "Zhihao Du",
        "Bin Ma"
      ],
      "abstract": "We introduce InspireMusic, a framework integrated super resolution and large\nlanguage model for high-fidelity long-form music generation. A unified\nframework generates high-fidelity music, songs, and audio, which incorporates\nan autoregressive transformer with a super-resolution flow-matching model. This\nframework enables the controllable generation of high-fidelity long-form music\nat a higher sampling rate from both text and audio prompts. Our model differs\nfrom previous approaches, as we utilize an audio tokenizer with one codebook\nthat contains richer semantic information, thereby reducing training costs and\nenhancing efficiency. This combination enables us to achieve high-quality audio\ngeneration with long-form coherence of up to $8$ minutes. Then, an\nautoregressive transformer model based on Qwen 2.5 predicts audio tokens. Next,\nwe employ a super-resolution flow-matching model to generate high-sampling rate\naudio with fine-grained details learned from an acoustic codec model.\nComprehensive experiments show that the InspireMusic-1.5B-Long model has a\ncomparable performance to recent top-tier open-source systems, including\nMusicGen and Stable Audio 2.0, on subjective and objective evaluations. The\ncode and pre-trained models are released at\nhttps://github.com/FunAudioLLM/InspireMusic.",
      "tldr_zh": "我们介绍了InspireMusic框架，它整合了super resolution和large language model，用于生成高保真度的长形式音乐。该框架结合自回归transformer和超分辨率流匹配模型，从文本或音频提示生成高达8分钟的音乐，并使用一个包含丰富语义信息的音频tokenizer，显著降低了训练成本和提高了效率。实验结果显示，InspireMusic-1.5B-Long模型在主观和客观评估中与MusicGen和Stable Audio 2.0等顶级开源系统相当，并已开源代码和预训练模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Work in progress. Correspondence regarding this technical report\n  should be directed to {chong.zhang, yukun.ma}@alibaba-inc.com. Online demo\n  available on https://modelscope.cn/studios/iic/InspireMusic and\n  https://huggingface.co/spaces/FunAudioLLM/InspireMusic",
      "pdf_url": "http://arxiv.org/pdf/2503.00084v1",
      "published_date": "2025-02-28 09:58:25 UTC",
      "updated_date": "2025-02-28 09:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:21:30.868091"
    },
    {
      "arxiv_id": "2502.20900v3",
      "title": "DexGraspVLA: A Vision-Language-Action Framework Towards General Dexterous Grasping",
      "title_zh": "DexGraspVLA：一种视觉-语言-动作框架，面向通用灵巧抓取",
      "authors": [
        "Yifan Zhong",
        "Xuchuan Huang",
        "Ruochong Li",
        "Ceyao Zhang",
        "Yitao Liang",
        "Yaodong Yang",
        "Yuanpei Chen"
      ],
      "abstract": "Dexterous grasping remains a fundamental yet challenging problem in robotics.\nA general-purpose robot must be capable of grasping diverse objects in\narbitrary scenarios. However, existing research typically relies on restrictive\nassumptions, such as single-object settings or limited environments, leading to\nconstrained generalization. We present DexGraspVLA, a hierarchical framework\nfor general dexterous grasping in cluttered scenes based on RGB image\nperception and language instructions. It utilizes a pre-trained Vision-Language\nmodel as the high-level task planner and learns a diffusion-based policy as the\nlow-level Action controller. The key insight to achieve robust generalization\nlies in iteratively transforming diverse language and visual inputs into\ndomain-invariant representations via foundation models, where imitation\nlearning can be effectively applied due to the alleviation of domain shift.\nNotably, our method achieves a 90+% success rate under thousands of unseen\nobject, lighting, and background combinations in a \"zero-shot\" environment.\nEmpirical analysis confirms the consistency of internal model behavior across\nenvironmental variations, thereby validating our design and explaining its\ngeneralization performance. DexGraspVLA also demonstrates free-form\nlong-horizon prompt execution, robustness to adversarial objects and human\ndisturbance, and failure recovery, which are rarely achieved simultaneously in\nprior work. Extended application to nonprehensile object grasping further\nproves its generality. Code, model, and video are available at\ndexgraspvla.github.io.",
      "tldr_zh": "该论文提出 DexGraspVLA 框架，这是一个基于 RGB 图像和语言指令的层次化系统，旨在解决机器人灵巧抓取在杂乱场景中的泛化挑战。框架使用预训练的 Vision-Language 模型作为高层任务规划器，并结合 diffusion-based policy 作为底层动作控制器，通过基础模型将语言和视觉输入转化为领域不变的表示，从而缓解领域偏移并有效应用模仿学习。实验结果显示，该方法在数千种未见过的物体、灯光和背景组合下实现了 90% 以上的成功率，并在零-shot 环境中表现出色。DexGraspVLA 还支持自由形式的长期提示执行、对对抗性物体和人类干扰的鲁棒性、故障恢复，以及扩展到非抓取物体的应用，证明了其通用性和实际价值。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.20900v3",
      "published_date": "2025-02-28 09:57:20 UTC",
      "updated_date": "2025-05-22 08:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:21:44.046173"
    },
    {
      "arxiv_id": "2502.20885v1",
      "title": "A Fused Gromov-Wasserstein Approach to Subgraph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Amadou S. Sangare",
        "Nicolas Dunou",
        "Jhony H. Giraldo",
        "Fragkiskos D. Malliaros"
      ],
      "abstract": "Self-supervised learning has become a key method for training deep learning\nmodels when labeled data is scarce or unavailable. While graph machine learning\nholds great promise across various domains, the design of effective pretext\ntasks for self-supervised graph representation learning remains challenging.\nContrastive learning, a popular approach in graph self-supervised learning,\nleverages positive and negative pairs to compute a contrastive loss function.\nHowever, current graph contrastive learning methods often struggle to fully use\nstructural patterns and node similarities. To address these issues, we present\na new method called Fused Gromov Wasserstein Subgraph Contrastive Learning\n(FOSSIL). Our model integrates node-level and subgraph-level contrastive\nlearning, seamlessly combining a standard node-level contrastive loss with the\nFused Gromov-Wasserstein distance. This combination helps our method capture\nboth node features and graph structure together. Importantly, our approach\nworks well with both homophilic and heterophilic graphs and can dynamically\ncreate views for generating positive and negative pairs. Through extensive\nexperiments on benchmark graph datasets, we show that FOSSIL outperforms or\nachieves competitive performance compared to current state-of-the-art methods.",
      "tldr_zh": "本研究针对自监督学习（self-supervised learning）在图机器学习中的挑战，提出了一种新方法 FOSSIL（Fused Gromov Wasserstein Subgraph Contrastive Learning）。FOSSIL 通过整合节点级和子图级对比学习（contrastive learning），并结合 Fused Gromov-Wasserstein 距离，将节点特征与图结构无缝融合，从而更好地捕捉结构模式和节点相似性。该方法适用于同质图（homophilic graphs）和异质图（heterophilic graphs），并能动态创建视图生成正负对；在基准图数据集上的广泛实验显示，FOSSIL 优于或与当前最先进方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20885v1",
      "published_date": "2025-02-28 09:32:07 UTC",
      "updated_date": "2025-02-28 09:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:21:56.364128"
    },
    {
      "arxiv_id": "2503.04790v1",
      "title": "SuperRAG: Beyond RAG with Layout-Aware Graph Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jeff Yang",
        "Duy-Khanh Vu",
        "Minh-Tien Nguyen",
        "Xuan-Quang Nguyen",
        "Linh Nguyen",
        "Hung Le"
      ],
      "abstract": "This paper introduces layout-aware graph modeling for multimodal RAG.\nDifferent from traditional RAG methods that mostly deal with flat text chunks,\nthe proposed method takes into account the relationship of multimodalities by\nusing a graph structure. To do that, a graph modeling structure is defined\nbased on document layout parsing. The structure of an input document is\nretained with the connection of text chunks, tables, and figures. This\nrepresentation allows the method to handle complex questions that require\ninformation from multimodalities. To confirm the efficiency of the graph\nmodeling, a flexible RAG pipeline is developed using robust components.\nExperimental results on four benchmark test sets confirm the contribution of\nthe layout-aware modeling for performance improvement of the RAG pipeline.",
      "tldr_zh": "这篇论文提出了 SuperRAG，一种超越传统 RAG 的方法，通过布局感知图建模来处理多模态信息。不同于传统的平面文本块处理，SuperRAG 通过文档布局解析定义图结构，保留文本块、表格和图表之间的连接，从而更好地应对需要多模态信息的复杂问题。实验结果在四个基准测试集上证实了这种布局感知建模对 RAG 管道性能的显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025, Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2503.04790v1",
      "published_date": "2025-02-28 09:05:49 UTC",
      "updated_date": "2025-02-28 09:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:22:08.204049"
    },
    {
      "arxiv_id": "2502.20854v3",
      "title": "A Pilot Empirical Study on When and How to Use Knowledge Graphs as Retrieval Augmented Generation",
      "title_zh": "关于何时以及如何使用知识图谱作为检索增强生成的初步实证研究",
      "authors": [
        "Xujie Yuan",
        "Yongxu Liu",
        "Shimin Di",
        "Shiwen Wu",
        "Libin Zheng",
        "Rui Meng",
        "Lei Chen",
        "Xiaofang Zhou",
        "Jian Yin"
      ],
      "abstract": "The integration of Knowledge Graphs (KGs) into the Retrieval Augmented\nGeneration (RAG) framework has attracted significant interest, with early\nstudies showing promise in mitigating hallucinations and improving model\naccuracy. However, a systematic understanding and comparative analysis of the\nrapidly emerging KG-RAG methods are still lacking. This paper seeks to lay the\nfoundation for systematically answering the question of when and how to use\nKG-RAG by analyzing their performance in various application scenarios\nassociated with different technical configurations. After outlining the mind\nmap using KG-RAG framework and summarizing its popular pipeline, we conduct a\npilot empirical study of KG-RAG works to reimplement and evaluate 6 KG-RAG\nmethods across 9 datasets in diverse domains and scenarios, analyzing the\nimpact of 9 KG-RAG configurations in combination with 17 LLMs, and combining\nMetacognition with KG-RAG as a pilot attempt. Our results underscore the\ncritical role of appropriate application conditions and optimal configurations\nof KG-RAG components.",
      "tldr_zh": "本文进行了一个初步实证研究，探讨何时和如何将知识图谱 (KGs) 整合到检索增强生成 (RAG) 框架中，以减少幻觉并提升模型准确性。研究者概述了 KG-RAG 框架的思维导图和流行管道，并重新实现了 6 种 KG-RAG 方法，在 9 个不同领域的数据集上评估了 9 个技术配置与 17 个大型语言模型 (LLMs) 的组合，同时尝试将 Metacognition 与 KG-RAG 相结合。结果强调了选择适当的应用场景和优化 KG-RAG 组件的重要性，为系统理解和应用 KG-RAG 提供了基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 figures, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.20854v3",
      "published_date": "2025-02-28 08:53:08 UTC",
      "updated_date": "2025-05-17 06:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:22:21.706958"
    },
    {
      "arxiv_id": "2502.20853v1",
      "title": "Oscillation-Reduced MXFP4 Training for Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Chen",
        "Haocheng Xi",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "Pre-training Transformers in FP4 precision is becoming a promising approach\nto gain substantial speedup, but it comes with a considerable loss of accuracy.\nMicroscaling (MX) data format provides a fine-grained per-group quantization\nmethod to improve the representation ability of the FP4 format and is supported\nby the next-generation Blackwell GPU architecture. However, training with MXFP4\ndata format still results in significant degradation and there is a lack of\nsystematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate\nFP4 training. We comprehensively evaluate all of the quantizers involved in the\ntraining, and identify the weight oscillation problem in the forward pass as\nthe main source of the degradation in MXFP4 training. Therefore, we introduce\ntwo novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer\n(Q-Ramping), to resolve the oscillation problem. Extensive experiments on\nVision Transformers demonstrate that TetraJet consistently outperforms the\nexisting 4-bit training methods, and Q-EMA & Q-Ramping can provide additional\nenhancement by effectively reducing oscillation. We decreased the accuracy\ndegradation by more than $50\\%$ compared to the baseline, and can even achieve\ncompetitive performance compared to full precision training. The codes are\navailable at https://github.com/thu-ml/TetraJet-MXFP4Training",
      "tldr_zh": "本研究针对Vision Transformers的FP4精度预训练问题，提出了一种新颖的训练方法TetraJet，以缓解MXFP4格式带来的准确性退化。研究者通过全面评估训练中的量化器，识别出前向传播中的权重振荡作为主要原因，并引入EMA Quantizer (Q-EMA)和Adaptive Ramping Optimizer (Q-Ramping)来有效减少振荡。实验结果显示，TetraJet在Vision Transformers上显著优于现有4-bit训练方法，准确性退化减少超过50%，甚至可与全精度训练媲美。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20853v1",
      "published_date": "2025-02-28 08:51:55 UTC",
      "updated_date": "2025-02-28 08:51:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:22:31.752949"
    },
    {
      "arxiv_id": "2503.13467v1",
      "title": "How Metacognitive Architectures Remember Their Own Thoughts: A Systematic Review",
      "title_zh": "元认知架构如何记忆自己的想法：一项系统综述",
      "authors": [
        "Robin Nolte",
        "Mihai Pomarlan",
        "Ayden Janssen",
        "Daniel Beßler",
        "Kamyar Javanmardi",
        "Sascha Jongebloed",
        "Robert Porzel",
        "John Bateman",
        "Michael Beetz",
        "Rainer Malaka"
      ],
      "abstract": "Inspired by human cognition, metacognition has gained significant attention\nfor its potential to enhance autonomy, adaptability, and robust learning in\nartificial agents. Yet research on Computational Metacognitive Architectures\n(CMAs) remains fragmented: diverse theories, terminologies, and design choices\nhave led to disjointed developments and limited comparability across systems.\nExisting overviews and surveys often remain at a broad, conceptual level,\nmaking it difficult to synthesize deeper insights into the underlying\nalgorithms and representations, and their respective success. We address this\ngap by performing an explorative systematic review of how CMAs model, store,\nremember and process their metacognitive experiences, one of Flavell's (1979)\nthree foundational components of metacognition. Following this organizing\nprinciple, we identify 35 CMAs that feature episodic introspective data ranging\nfrom symbolic event traces to sub-symbolic arousal metrics. We consider\ndifferent aspects - ranging from the underlying psychological theories to the\ncontent and structure of collected data, to the algorithms used and evaluation\nresults - and derive a unifying perspective that allows us to compare in depth\nhow different Computational Metacognitive Architectures (CMAs) leverage\nmetacognitive experiences for tasks such as error diagnosis, self-repair, and\ngoal-driven learning. Our findings highlight both the promise of metacognitive\nexperiences - in boosting adaptability, explainability, and overall system\nperformance - and the persistent lack of shared standards or evaluation\nbenchmarks.",
      "tldr_zh": "这篇论文对 Computational Metacognitive Architectures (CMAs) 如何建模、存储和处理元认知经历进行了系统综述，旨在解决现有研究中理论和设计选择的碎片化问题。作者识别了35个CMAs，从Flavell (1979)的元认知框架出发，分析了心理理论、数据结构、算法及其在错误诊断、自我修复和目标驱动学习中的应用。综述结果显示，元认知经历能提升人工智能代理的适应性、解释性和整体性能，但仍存在缺乏共享标准和评估基准的挑战。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "I.2.0; I.2.4; I.2.6; I.2.8; J.4"
      ],
      "primary_category": "q-bio.NC",
      "comment": "69 pages, 13 figures. In preparation for submission",
      "pdf_url": "http://arxiv.org/pdf/2503.13467v1",
      "published_date": "2025-02-28 08:48:41 UTC",
      "updated_date": "2025-02-28 08:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:22:43.155959"
    },
    {
      "arxiv_id": "2502.20845v1",
      "title": "Reinforcement Learning with Curriculum-inspired Adaptive Direct Policy Guidance for Truck Dispatching",
      "title_zh": "翻译失败",
      "authors": [
        "Shi Meng",
        "Bin Tian",
        "Xiaotong Zhang"
      ],
      "abstract": "Efficient truck dispatching via Reinforcement Learning (RL) in open-pit\nmining is often hindered by reliance on complex reward engineering and\nvalue-based methods. This paper introduces Curriculum-inspired Adaptive Direct\nPolicy Guidance, a novel curriculum learning strategy for policy-based RL to\naddress these issues. We adapt Proximal Policy Optimization (PPO) for mine\ndispatching's uneven decision intervals using time deltas in Temporal\nDifference and Generalized Advantage Estimation, and employ a Shortest\nProcessing Time teacher policy for guided exploration via policy regularization\nand adaptive guidance. Evaluations in OpenMines demonstrate our approach yields\na 10% performance gain and faster convergence over standard PPO across sparse\nand dense reward settings, showcasing improved robustness to reward design.\nThis direct policy guidance method provides a general and effective curriculum\nlearning technique for RL-based truck dispatching, enabling future work on\nadvanced architectures.",
      "tldr_zh": "这篇论文针对露天矿业卡车调度的强化学习（RL）问题，提出了一种名为 Curriculum-inspired Adaptive Direct Policy Guidance 的新课程学习策略，以减少对复杂奖励工程的依赖。作者改进了 Proximal Policy Optimization (PPO) 方法，通过在 Temporal Difference 和 Generalized Advantage Estimation 中引入时间增量来处理不均匀决策间隔，并使用 Shortest Processing Time 作为教师策略进行政策 regularization 和自适应引导探索。在 OpenMines 模拟环境中，该方法在稀疏和密集奖励设置下比标准 PPO 提高了 10% 的性能，并加速了收敛，展示了更高的鲁棒性。该技术为 RL 基于卡车调度的未来研究提供了通用框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20845v1",
      "published_date": "2025-02-28 08:43:32 UTC",
      "updated_date": "2025-02-28 08:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:22:55.681796"
    },
    {
      "arxiv_id": "2502.20844v1",
      "title": "Neuro-Symbolic Learning for Galois Groups: Unveiling Probabilistic Trends in Polynomials",
      "title_zh": "神经符号学习用于伽罗瓦群：揭示多项式",
      "authors": [
        "Elira Shaska",
        "Tony Shaska"
      ],
      "abstract": "This paper presents a neurosymbolic approach to classifying Galois groups of\npolynomials, integrating classical Galois theory with machine learning to\naddress challenges in algebraic computation. By combining neural networks with\nsymbolic reasoning we develop a model that outperforms purely numerical methods\nin accuracy and interpretability. Focusing on sextic polynomials with height\n$\\leq 6$, we analyze a database of 53,972 irreducible examples, uncovering\nnovel distributional trends, such as the 20 sextic polynomials with Galois\ngroup $C_6$ spanning just seven invariant-defined equivalence classes. These\nfindings offer the first empirical insights into Galois group probabilities\nunder height constraints and lay the groundwork for exploring solvability by\nradicals. Demonstrating AI's potential to reveal patterns beyond traditional\nsymbolic techniques, this work paves the way for future research in\ncomputational algebra, with implications for probabilistic conjectures and\nhigher degree classifications.",
      "tldr_zh": "本研究提出了一种Neuro-Symbolic Learning方法，将神经网络与符号推理相结合，用于分类多项式的Galois groups，并整合经典Galois理论以提升机器学习的准确性和可解释性。该方法在高度≤6的septic polynomials上分析了53,972个不可约示例，揭示了新的分布趋势，例如Galois group为C_6的20个多项式仅跨越七个不变定义的等价类。实验结果首次提供了高度约束下Galois group概率的实证洞见，并为探索solvability by radicals奠定基础，同时展示了AI在计算代数中揭示传统技术之外模式的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "12F10, 68T07",
        "I.2; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20844v1",
      "published_date": "2025-02-28 08:42:57 UTC",
      "updated_date": "2025-02-28 08:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:23:07.041079"
    },
    {
      "arxiv_id": "2502.20843v1",
      "title": "Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonyoung Cho",
        "Junhyek Han",
        "Jisu Han",
        "Beomjoon Kim"
      ],
      "abstract": "For robots to operate in general environments like households, they must be\nable to perform non-prehensile manipulation actions such as toppling and\nrolling to manipulate ungraspable objects. However, prior works on\nnon-prehensile manipulation cannot yet generalize across environments with\ndiverse geometries. The main challenge lies in adapting to varying\nenvironmental constraints: within a cabinet, the robot must avoid walls and\nceilings; to lift objects to the top of a step, the robot must account for the\nstep's pose and extent. While deep reinforcement learning (RL) has demonstrated\nimpressive success in non-prehensile manipulation, accounting for such\nvariability presents a challenge for the generalist policy, as it must learn\ndiverse strategies for each new combination of constraints. To address this, we\npropose a modular and reconfigurable architecture that adaptively reconfigures\nnetwork modules based on task requirements. To capture the geometric\nvariability in environments, we extend the contact-based object representation\n(CORN) to environment geometries, and propose a procedural algorithm for\ngenerating diverse environments to train our agent. Taken together, the\nresulting policy can zero-shot transfer to novel real-world environments and\nobjects despite training entirely within a simulator. We additionally release a\nsimulation-based benchmark featuring nine digital twins of real-world scenes\nwith 353 objects to facilitate non-prehensile manipulation research in\nrealistic domains.",
      "tldr_zh": "该论文针对机器人非抓取操作（non-prehensile manipulation）在一般环境（如家庭）中的泛化挑战，提出了一种层次化和模块化网络架构，以适应多样几何约束，例如避免柜子内的墙壁或处理台阶。方法包括扩展接触-based object representation (CORN) 到环境几何，并使用程序化算法生成多样环境进行深度强化学习（deep reinforcement learning, RL）训练。结果显示，该网络政策能够在模拟器中训练后实现零-shot transfer 到真实世界环境和物体，并发布了包含九个真实场景数字孪生和353个物体的模拟基准，以推动相关研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "http://unicorn-hamnet.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.20843v1",
      "published_date": "2025-02-28 08:42:00 UTC",
      "updated_date": "2025-02-28 08:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:23:19.881185"
    },
    {
      "arxiv_id": "2502.20838v1",
      "title": "Weakly Supervised Multiple Instance Learning for Whale Call Detection and Localization in Long-Duration Passive Acoustic Monitoring",
      "title_zh": "弱监督多实例学习用于长时",
      "authors": [
        "Ragib Amin Nihal",
        "Benjamin Yen",
        "Runwu Shi",
        "Kazuhiro Nakadai"
      ],
      "abstract": "Marine ecosystem monitoring via Passive Acoustic Monitoring (PAM) generates\nvast data, but deep learning often requires precise annotations and short\nsegments. We introduce DSMIL-LocNet, a Multiple Instance Learning framework for\nwhale call detection and localization using only bag-level labels. Our\ndual-stream model processes 2-30 minute audio segments, leveraging spectral and\ntemporal features with attention-based instance selection. Tests on Antarctic\nwhale data show longer contexts improve classification (F1: 0.8-0.9) while\nmedium instances ensure localization precision (0.65-0.70). This suggests MIL\ncan enhance scalable marine monitoring. Code:\nhttps://github.com/Ragib-Amin-Nihal/DSMIL-Loc",
      "tldr_zh": "本研究提出了一种弱监督的 Multiple Instance Learning (MIL) 框架 DSMIL-LocNet，用于长时 Passive Acoustic Monitoring (PAM) 中的鲸鱼叫声检测和定位，仅依赖于 bag-level labels。框架采用双流模型处理2-30分钟音频段，通过光谱和时间特征结合注意力机制进行实例选择，从而提升分类和定位性能。在南极鲸鱼数据测试中，该方法显示更长的上下文提高了分类准确性（F1 score: 0.8-0.9），而中等实例确保了定位精度（0.65-0.70）。这项工作证明了 MIL 在可扩展海洋监测中的潜力，并提供了开源代码以供进一步应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20838v1",
      "published_date": "2025-02-28 08:34:12 UTC",
      "updated_date": "2025-02-28 08:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:23:30.893367"
    },
    {
      "arxiv_id": "2502.20825v1",
      "title": "LADs: Leveraging LLMs for AI-Driven DevOps",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Faraz Khan",
        "Azal Ahmad Khan",
        "Anas Mohamed",
        "Haider Ali",
        "Suchithra Moolinti",
        "Sabaat Haroon",
        "Usman Tahir",
        "Mattia Fazzini",
        "Ali R. Butt",
        "Ali Anwar"
      ],
      "abstract": "Automating cloud configuration and deployment remains a critical challenge\ndue to evolving infrastructures, heterogeneous hardware, and fluctuating\nworkloads. Existing solutions lack adaptability and require extensive manual\ntuning, leading to inefficiencies and misconfigurations. We introduce LADs, the\nfirst LLM-driven framework designed to tackle these challenges by ensuring\nrobustness, adaptability, and efficiency in automated cloud management. Instead\nof merely applying existing techniques, LADs provides a principled approach to\nconfiguration optimization through in-depth analysis of what optimization works\nunder which conditions. By leveraging Retrieval-Augmented Generation, Few-Shot\nLearning, Chain-of-Thought, and Feedback-Based Prompt Chaining, LADs generates\naccurate configurations and learns from deployment failures to iteratively\nrefine system settings. Our findings reveal key insights into the trade-offs\nbetween performance, cost, and scalability, helping practitioners determine the\nright strategies for different deployment scenarios. For instance, we\ndemonstrate how prompt chaining-based adaptive feedback loops enhance fault\ntolerance in multi-tenant environments and how structured log analysis with\nexample shots improves configuration accuracy. Through extensive evaluations,\nLADs reduces manual effort, optimizes resource utilization, and improves system\nreliability. By open-sourcing LADs, we aim to drive further innovation in\nAI-powered DevOps automation.",
      "tldr_zh": "本研究针对云配置和部署的挑战（如演变的基础设施、异构硬件和波动的工作负载），引入LADs，这是一个基于Large Language Models (LLMs)的框架，旨在提升自动化云管理的鲁棒性、适应性和效率。LADs 通过Retrieval-Augmented Generation、Few-Shot Learning、Chain-of-Thought和Feedback-Based Prompt Chaining等技术生成准确配置，并从部署失败中学习以迭代优化系统设置。实验结果揭示了性能、成本和可伸缩性之间的权衡，例如prompt chaining-based adaptive feedback loops提升了多租户环境的容错性，而structured log analysis with example shots改善了配置准确性，最终减少手动努力、优化资源利用并提高系统可靠性。LADs的开源将推动AI驱动DevOps自动化的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages with Appendix, 8 figures, and 7 tables. This paper is\n  currently Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.20825v1",
      "published_date": "2025-02-28 08:12:08 UTC",
      "updated_date": "2025-02-28 08:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:23:43.400312"
    },
    {
      "arxiv_id": "2502.20808v5",
      "title": "MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts",
      "title_zh": "MV-MATH：评估多视觉语境中的多模态数学推理",
      "authors": [
        "Peijie Wang",
        "Zhong-Zhi Li",
        "Fei Yin",
        "Xin Yang",
        "Dekang Ran",
        "Cheng-Lin Liu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have shown promising capabilities in\nmathematical reasoning within visual contexts across various datasets. However,\nmost existing multimodal math benchmarks are limited to single-visual contexts,\nwhich diverges from the multi-visual scenarios commonly encountered in\nreal-world mathematical applications. To address this gap, we introduce\nMV-MATH: a meticulously curated dataset of 2,009 high-quality mathematical\nproblems. Each problem integrates multiple images interleaved with text,\nderived from authentic K-12 scenarios, and enriched with detailed annotations.\nMV-MATH includes multiple-choice, free-form, and multi-step questions, covering\n11 subject areas across 3 difficulty levels, and serves as a comprehensive and\nrigorous benchmark for assessing MLLMs' mathematical reasoning in multi-visual\ncontexts. Through extensive experimentation, we observe that MLLMs encounter\nsubstantial challenges in multi-visual math tasks, with a considerable\nperformance gap relative to human capabilities on MV-MATH. Furthermore, we\nanalyze the performance and error patterns of various models, providing\ninsights into MLLMs' mathematical reasoning capabilities within multi-visual\nsettings.",
      "tldr_zh": "这篇论文引入了 MV-MATH 数据集，该数据集包含 2,009 个高质量数学问题，用于评估 Multimodal Large Language Models (MLLMs) 在多视觉上下文中的数学推理能力，以弥补现有基准局限于单视觉场景的局限性。数据集从真实 K-12 场景中收集，每个问题整合多个图像和文本，并包括多项选择、自由形式和多步问题，覆盖 11 个主题和 3 个难度级别。实验结果显示，MLLMs 在多视觉数学任务中面临重大挑战，与人类表现存在显著差距，并通过分析模型性能和错误模式提供了对 MLLMs 能力的洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "45 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.20808v5",
      "published_date": "2025-02-28 07:50:36 UTC",
      "updated_date": "2025-05-21 14:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:23:55.433447"
    },
    {
      "arxiv_id": "2502.20806v1",
      "title": "Multimodal Learning for Just-In-Time Software Defect Prediction in Autonomous Driving Systems",
      "title_zh": "多模态学习在自动驾驶系统中的即时软件缺陷预测",
      "authors": [
        "Faisal Mohammad",
        "Duksan Ryu"
      ],
      "abstract": "In recent years, the rise of autonomous driving technologies has highlighted\nthe critical importance of reliable software for ensuring safety and\nperformance. This paper proposes a novel approach for just-in-time software\ndefect prediction (JIT-SDP) in autonomous driving software systems using\nmultimodal learning. The proposed model leverages the multimodal transformers\nin which the pre-trained transformers and a combining module deal with the\nmultiple data modalities of the software system datasets such as code features,\nchange metrics, and contextual information. The key point for adapting\nmultimodal learning is to utilize the attention mechanism between the different\ndata modalities such as text, numerical, and categorical. In the combining\nmodule, the output of a transformer model on text data and tabular features\ncontaining categorical and numerical data are combined to produce the\npredictions using the fully connected layers. Experiments conducted on three\nopen-source autonomous driving system software projects collected from the\nGitHub repository (Apollo, Carla, and Donkeycar) demonstrate that the proposed\napproach significantly outperforms state-of-the-art deep learning and machine\nlearning models regarding evaluation metrics. Our findings highlight the\npotential of multimodal learning to enhance the reliability and safety of\nautonomous driving software through improved defect prediction.",
      "tldr_zh": "本文提出了一种基于多模态学习(Multimodal Learning)的实时软件缺陷预测(Just-In-Time Software Defect Prediction, JIT-SDP)方法，旨在提升自动驾驶系统的软件可靠性和安全性。该方法利用多模态变换器(Multimodal Transformers)，通过预训练变换器和结合模块处理多种数据模态（如代码特征、变更指标和上下文信息），并借助注意力机制(Attention Mechanism)整合文本、数值和分类数据以生成预测。在三个开源自动驾驶项目（Apollo、Carla和Donkeycar）的实验中，该方法在评估指标上显著优于现有深度学习和机器学习模型，证明了其在缺陷预测方面的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "9",
      "pdf_url": "http://arxiv.org/pdf/2502.20806v1",
      "published_date": "2025-02-28 07:45:10 UTC",
      "updated_date": "2025-02-28 07:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:24:07.654004"
    },
    {
      "arxiv_id": "2503.01902v1",
      "title": "An Empirical Analysis of LLMs for Countering Misinformation",
      "title_zh": "翻译失败",
      "authors": [
        "Adiba Mahbub Proma",
        "Neeley Pate",
        "James Druckman",
        "Gourab Ghoshal",
        "Hangfeng He",
        "Ehsan Hoque"
      ],
      "abstract": "While Large Language Models (LLMs) can amplify online misinformation, they\nalso show promise in tackling misinformation. In this paper, we empirically\nstudy the capabilities of three LLMs -- ChatGPT, Gemini, and Claude -- in\ncountering political misinformation. We implement a two-step, chain-of-thought\nprompting approach, where models first identify credible sources for a given\nclaim and then generate persuasive responses. Our findings suggest that models\nstruggle to ground their responses in real news sources, and tend to prefer\nciting left-leaning sources. We also observe varying degrees of response\ndiversity among models. Our findings highlight concerns about using LLMs for\nfact-checking through only prompt-engineering, emphasizing the need for more\nrobust guardrails. Our results have implications for both researchers and\nnon-technical users.",
      "tldr_zh": "这篇论文实证分析了大型语言模型（LLMs）如 ChatGPT、Gemini 和 Claude 在对抗政治错误信息方面的能力。研究采用两步 Chain-of-Thought 提示方法，首先识别给定声明的可信来源，然后生成说服性回应。结果显示，模型难以将回应基于真实新闻来源，并倾向于引用左倾来源，同时不同模型的回应多样性存在差异。论文强调，仅靠提示工程不足以实现可靠的事实检查，需要更 robust 的防护措施，这对研究者和非技术用户具有重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Adiba and Neeley contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2503.01902v1",
      "published_date": "2025-02-28 07:12:03 UTC",
      "updated_date": "2025-02-28 07:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:24:18.838379"
    },
    {
      "arxiv_id": "2502.20789v1",
      "title": "Characteristics Analysis of Autonomous Vehicle Pre-crash Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Yixuan Li",
        "Xuesong Wang",
        "Tianyi Wang",
        "Qian Liu"
      ],
      "abstract": "To date, hundreds of crashes have occurred in open road testing of automated\nvehicles (AVs), highlighting the need for improving AV reliability and safety.\nPre-crash scenario typology classifies crashes based on vehicle dynamics and\nkinematics features. Building on this, characteristics analysis can identify\nsimilar features under comparable crashes, offering a more effective reflection\nof general crash patterns and providing more targeted recommendations for\nenhancing AV performance. However, current studies primarily concentrated on\ncrashes among conventional human-driven vehicles, leaving a gap in research\ndedicated to in-depth AV crash analyses. In this paper, we analyzed the latest\nCalifornia AV collision reports and used the newly revised pre-crash scenario\ntypology to identify pre-crash scenarios. We proposed a set of mapping rules\nfor automatically extracting these AV pre-crash scenarios, successfully\nidentifying 24 types with a 98.1% accuracy rate, and obtaining two key\nscenarios of AV crashes (i.e., rear-end scenarios and intersection scenarios)\nthrough detailed analysis. Association analyses of rear-end scenarios showed\nthat the significant environmental influencing factors were traffic control\ntype, location type, light, etc. For intersection scenarios prone to severe\ncrashes with detailed descriptions, we employed causal analyses to obtain the\nsignificant causal factors: habitual violations and expectations of certain\nbehavior. Optimization recommendations were then formulated, addressing both\ngovernmental oversight and AV manufacturers' potential improvements. The\nfindings of this paper could guide government authorities to develop related\nregulations, help manufacturers design AV test scenarios, and identify\npotential shortcomings in control algorithms specific to various real-world\nscenarios, thereby optimizing AV systems effectively.",
      "tldr_zh": "本研究分析了自动驾驶车辆（Autonomous Vehicles, AVs）的预碰撞场景（pre-crash scenarios），通过处理加州AV碰撞报告并应用修订后的场景分类方法，提出自动提取规则，成功识别24种场景类型，准确率达98.1%。详细分析显示，后端碰撞（rear-end scenarios）受交通控制类型、位置类型和光照等环境因素显著影响，而交叉路口场景（intersection scenarios）的主要因果因素包括习惯性违规（habitual violations）和行为预期。研究成果为政府制定相关法规、制造商设计测试场景和优化控制算法提供针对性推荐，从而提升AV的安全性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20789v1",
      "published_date": "2025-02-28 07:10:53 UTC",
      "updated_date": "2025-02-28 07:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:24:30.584312"
    },
    {
      "arxiv_id": "2503.01901v1",
      "title": "Identifying Sensitive Weights via Post-quantization Integral",
      "title_zh": "翻译失败",
      "authors": [
        "Yuezhou Hu",
        "Weiyu Huang",
        "Zichen Liang",
        "Chang Chen",
        "Jintao Zhang",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "Serving Large Language Models (LLMs) is costly. However, post-training weight\nquantization can address this problem by both compressing their sizes for\nlimited memory and saving bandwidth for acceleration. As not all weight\ndimensions are equally important, those methods typically rely on a sensitivity\nmetric, which indicates the element-wise influence of weights on loss function\nand is used to preprocess original weights for better quantization. In this\nwork, we conduct an empirical study on the accuracy of the sensitivity metric,\nand find that existing gradient and Hessian based metrics are very inaccurate:\nthey underestimate quantization's impact on the loss function by orders of\nmagnitude, mainly due to the small convergence radius of local 2nd order\napproximation, \\ie, gradient and Hessian term in Taylor's formula. To tackle\nthis problem, we propose Post-quantization Integral (PQI), an accurate metric\nto estimate posterior sensitivity in a fine-grained manner. To leverage this\naccurate metric, we further propose ReQuant, a simple yet powerful framework\nthat mainly consists of two Dense-and-Sparse detach components: self-adaptive\noutlier selection and step-wise significant weights detach. Results show that\nReQuant boosts state-of-the-art post-training quantization methods, with a\npronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP.",
      "tldr_zh": "该研究发现，现有的基于梯度和Hessian的敏感度指标在量化Large Language Models (LLMs)时准确性不足，导致低估量化对损失函数的影响。作者提出Post-quantization Integral (PQI)，一种精确的细粒度敏感度估计方法，用于评估权重量化后的影响。基于PQI，他们开发了ReQuant框架，包括self-adaptive outlier selection和step-wise significant weights detach组件，以优化权重处理。实验结果显示，ReQuant显著提升了现有后训练量化方法的性能，在Llama 3.2 1B模型上与QTIP结合，实现2.66 perplexity的改善。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01901v1",
      "published_date": "2025-02-28 07:04:19 UTC",
      "updated_date": "2025-02-28 07:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:24:42.732112"
    },
    {
      "arxiv_id": "2502.20783v1",
      "title": "Flattening Supply Chains: When do Technology Improvements lead to Disintermediation?",
      "title_zh": "扁平化供应链：技术改进何时导致去中介化？",
      "authors": [
        "S. Nageeb Ali",
        "Nicole Immorlica",
        "Meena Jagadeesan",
        "Brendan Lucier"
      ],
      "abstract": "In the digital economy, technological innovations make it cheaper to produce\nhigh-quality content. For example, generative AI tools reduce costs for\ncreators who develop content to be distributed online, but can also reduce\nproduction costs for the users who consume that content. These innovations can\nthus lead to disintermediation, since consumers may choose to use these\ntechnologies directly, bypassing intermediaries. To investigate when\ntechnological improvements lead to disintermediation, we study a game with an\nintermediary, suppliers of a production technology, and consumers. First, we\nshow disintermediation occurs whenever production costs are too high or too\nlow. We then investigate the consequences of disintermediation for welfare and\ncontent quality at equilibrium. While the intermediary is welfare-improving,\nthe intermediary extracts all gains to social welfare and its presence can\nraise or lower content quality. We further analyze how disintermediation is\naffected by the level of competition between suppliers and the intermediary's\nfee structure. More broadly, our results take a step towards assessing how\nproduction technology innovations affect the survival of intermediaries and\nimpact the digital economy.",
      "tldr_zh": "本研究探讨了数字经济中技术创新（如生成式AI）如何降低内容生产成本，从而可能导致消费者绕过中间商直接使用技术（disintermediation）。作者使用一个包含中间商、供应商和消费者的游戏理论模型，证明disintermediation在生产成本过高或过低时会发生。结果显示，虽然中间商能提升社会福利，但其存在会导致中间商提取全部收益，并可能提高或降低内容质量。此外，分析表明，供应商间的竞争和中间商的收费结构会影响disintermediation的发生，为评估技术创新对数字经济和中间商生存的影响提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20783v1",
      "published_date": "2025-02-28 07:04:01 UTC",
      "updated_date": "2025-02-28 07:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:24:54.766347"
    },
    {
      "arxiv_id": "2502.20780v1",
      "title": "MedHallTune: An Instruction-Tuning Benchmark for Mitigating Medical Hallucination in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Yan",
        "Yuchen Yuan",
        "Xiaowei Hu",
        "Yihan Wang",
        "Jiaqi Xu",
        "Jinpeng Li",
        "Chi-Wing Fu",
        "Pheng-Ann Heng"
      ],
      "abstract": "The increasing use of vision-language models (VLMs) in healthcare\napplications presents great challenges related to hallucinations, in which the\nmodels may generate seemingly plausible results that are in fact incorrect.\nSuch hallucinations can jeopardize clinical decision making, potentially\nharming the diagnosis and treatments. In this work, we propose MedHallTune, a\nlarge-scale benchmark designed specifically to evaluate and mitigate\nhallucinations in medical VLMs. Comprising over 100,000 images and 1,000,000\ninstruction pairs, MedHallTune includes both hallucination and\nnon-hallucination samples, each with ground-truth annotations. We conduct a\ncomprehensive evaluation of current medical and general VLMs using MedHallTune,\nassessing their performance across key metrics, including clinical accuracy,\nrelevance, detail level, and risk level. The experimental results show that\nfine-tuning with MedHallTune successfully improves the ability of several\nexisting models to manage hallucinations and boost their zero-shot performance\non downstream visual-question-answering (VQA) tasks, making them more reliable\nfor practical medical applications. Our work contributes to the development of\nmore trustworthy VLMs. Codes and dataset will be available at\n\\href{https://github.com/russellyq/MedHallTune}{MedHallTune}.",
      "tldr_zh": "该研究针对视觉语言模型（VLMs）在医疗应用中存在的幻觉问题（如生成错误但看似合理的输出），提出了MedHallTune，这是一个大规模指令微调基准，包含超过10万张图像和100万对指令样本，并提供真实标注以评估和缓解这些幻觉。MedHallTune评估了现有医疗和通用VLMs在临床准确性、相关性、细节水平及风险水平等方面的性能。实验结果显示，通过该基准进行微调，能显著提升模型处理幻觉的能力，并改善其零样本视觉问答（VQA）任务的性能，从而为开发更可靠的医疗VLMs提供重要贡献。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20780v1",
      "published_date": "2025-02-28 06:59:49 UTC",
      "updated_date": "2025-02-28 06:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:25:07.058017"
    },
    {
      "arxiv_id": "2502.20779v2",
      "title": "Triple Phase Transitions: Understanding the Learning Dynamics of Large Language Models from a Neuroscience Perspective",
      "title_zh": "三重相变：从神经科学视角理解大型语言模型的学习动态",
      "authors": [
        "Yuko Nakagi",
        "Keigo Tada",
        "Sota Yoshino",
        "Shinji Nishimoto",
        "Yu Takagi"
      ],
      "abstract": "Large language models (LLMs) often exhibit abrupt emergent behavior, whereby\nnew abilities arise at certain points during their training. This phenomenon,\ncommonly referred to as a ''phase transition'', remains poorly understood. In\nthis study, we conduct an integrative analysis of such phase transitions by\nexamining three interconnected perspectives: the similarity between LLMs and\nthe human brain, the internal states of LLMs, and downstream task performance.\nWe propose a novel interpretation for the learning dynamics of LLMs that vary\nin both training data and architecture, revealing that three phase transitions\ncommonly emerge across these models during training: (1) alignment with the\nentire brain surges as LLMs begin adhering to task instructions Brain Alignment\nand Instruction Following, (2) unexpectedly, LLMs diverge from the brain during\na period in which downstream task accuracy temporarily stagnates Brain\nDetachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs\nbecome capable of solving the downstream tasks Brain Realignment and\nConsolidation. These findings illuminate the underlying mechanisms of phase\ntransitions in LLMs, while opening new avenues for interdisciplinary research\nbridging AI and neuroscience.",
      "tldr_zh": "本研究从神经科学视角分析大型语言模型 (LLMs) 的学习动态，揭示其突发性涌现行为（emergent behavior）背后的相变（phase transition）现象。通过考察 LLMs 与人类大脑的相似性、内部状态以及下游任务性能，论文提出 LLMs 在训练过程中普遍出现三个相变：(1) 与大脑对齐并开始遵循任务指令（Brain Alignment and Instruction Following）；(2) 与大脑分离，同时下游任务准确率暂时停滞（Brain Detachment and Stagnation）；(3) 再次与大脑对齐并巩固能力（Brain Realignment and Consolidation）。这些发现阐明了 LLMs 学习机制的潜在原理，并为 AI 和神经科学交叉研究开辟新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.20779v2",
      "published_date": "2025-02-28 06:59:04 UTC",
      "updated_date": "2025-03-29 11:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:25:19.464267"
    },
    {
      "arxiv_id": "2503.04789v2",
      "title": "Ext2Gen: Alignment through Unified Extraction and Generation for Robust Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hwanjun Song",
        "Jeonghwan Choi",
        "Minseok Kim"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances LLMs by integrating external\nknowledge, but generation remains fragile due to the uncertain placement of\nrelevant chunks and retrieval-induced information overload, leading to\nhallucinations. We propose Ext2Gen, a novel extract-then-generate model that\nenhances RAG robustness by first extracting query-relevant sentences before\ngenerating answers. To optimize this model, we employ preference alignment\nthrough pairwise feedback learning, enabling the model to generate robust\nanswers regardless of variations in retrieval results. Extensive experiments\ndemonstrate that Ext2Gen effectively identifies query-relevant sentences with\nhigh precision and recall, leading to highly reliable answers. Furthermore,\ndeploying our model in a RAG environment reveals that it not only boosts the\nperformance of the base LLM but also synergizes with advanced retrieval\nstrategies like query expansion. The model is available at\nhttps://huggingface.co/DISLab/Ext2Gen-8B-R2.",
      "tldr_zh": "论文提出 Ext2Gen，一种统一的提取和生成模型，用于提升 Retrieval-Augmented Generation (RAG) 的鲁棒性，通过先提取查询相关的句子再生成答案，解决幻觉 (hallucinations) 和信息过载问题。模型采用 preference alignment 和 pairwise feedback learning 的优化方法，使其能生成可靠答案，无论检索结果如何变化。实验结果表明，Ext2Gen 在高精度和高召回率下有效识别相关句子，提升了基础 LLM 的性能，并与 query expansion 等高级检索策略协同工作。模型已在 https://huggingface.co/DISLab/Ext2Gen-8B-R2 发布。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04789v2",
      "published_date": "2025-02-28 06:46:53 UTC",
      "updated_date": "2025-03-12 14:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:25:34.269488"
    },
    {
      "arxiv_id": "2502.20772v1",
      "title": "Damper-B-PINN: Damper Characteristics-Based Bayesian Physics-Informed Neural Network for Vehicle State Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zeng",
        "Tianyi Wang",
        "Junfeng Jiao",
        "Xinbo Chen"
      ],
      "abstract": "State estimation for Multi-Input Multi-Output (MIMO) systems with noise, such\nas vehicle chassis systems, presents a significant challenge due to the\nimperfect and complex relationship between inputs and outputs. To solve this\nproblem, we design a Damper characteristics-based Bayesian Physics-Informed\nNeural Network (Damper-B-PINN). First, we introduce a neuron forward process\ninspired by the mechanical properties of dampers, which limits abrupt jumps in\nneuron values between epochs while maintaining search capability. Additionally,\nwe apply an optimized Bayesian dropout layer to the MIMO system to enhance\nrobustness against noise and prevent non-convergence issues. Physical\ninformation is incorporated into the loss function to serve as a physical prior\nfor the neural network. The effectiveness of our Damper-B-PINN architecture is\nthen validated across ten datasets and fourteen vehicle types, demonstrating\nsuperior accuracy, computational efficiency, and convergence in vehicle state\nestimation (i.e., dynamic wheel load) compared to other state-of-the-art\nbenchmarks.",
      "tldr_zh": "这篇论文针对多输入多输出 (MIMO) 系统（如车辆底盘系统）中的状态估计问题，提出了 Damper-B-PINN 框架，该框架基于减震器特性设计神经元前向过程，并结合优化 Bayesian dropout 层和物理信息融入损失函数，以提升对噪声的鲁棒性和防止非收敛问题。关键创新包括限制神经元值突变的同时保持搜索能力，并利用物理先验来指导网络训练。该框架在十个数据集和十四种车辆类型上进行了验证，展示了比现有基准更高的准确性、计算效率和收敛性，尤其在动态轮载荷估计方面。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20772v1",
      "published_date": "2025-02-28 06:46:21 UTC",
      "updated_date": "2025-02-28 06:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:25:43.317154"
    },
    {
      "arxiv_id": "2502.20758v1",
      "title": "Collective Reasoning Among LLMs A Framework for Answer Validation Without Ground Truth",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Pouyan Mousavi Davoudi",
        "Alireza Shafiee Fard",
        "Alireza Amiri-Margavi"
      ],
      "abstract": "We present a collaborative framework where multiple large language models,\nnamely GPT-4-0125-preview, Meta-LLaMA-3-70B-Instruct, Claude-3-Opus, and\nGemini-1.5-Flash, work together to generate and respond to complex PhD-level\nprobability questions in the absence of definitive ground truth. This study\nexplores how inter-model consensus enhances response reliability and serves as\na proxy for assessing the quality of generated questions. To quantify agreement\nand consistency, we employ statistical methods including chi-square tests,\nFleiss' Kappa, and confidence interval analysis, measuring both response\nprecision and question clarity. Our findings highlight that Claude and Gemini\ngenerate well-structured and less ambiguous questions, leading to higher\ninter-model agreement. This is reflected in their narrower confidence intervals\nand stronger alignment with answering models. Conversely, LLaMA demonstrates\nincreased variability and lower reliability in question formulation, as\nindicated by broader confidence intervals and reduced consensus rates. These\nresults suggest that multi-model collaboration not only enhances the\nreliability of responses but also provides a valuable framework for assessing\nand improving question quality in the absence of explicit ground truth. This\nresearch offers meaningful insights into optimizing AI-driven reasoning through\ncollaborative large-language model interactions.",
      "tldr_zh": "本文提出一个多大型语言模型(LLMs)协作框架，包括GPT-4-0125-preview、Meta-LLaMA-3-70B-Instruct、Claude-3-Opus和Gemini-1.5-Flash，用于生成和响应复杂PhD级概率问题，而无需ground truth，从而提升响应可靠性。框架通过统计方法如chi-square tests、Fleiss' Kappa和confidence interval analysis量化模型间协议和一致性，以评估问题质量。研究发现，Claude和Gemini生成的问题更结构化且模糊性低，导致更高的模型间共识，而LLaMA显示出更大的变异性和较低可靠性。这些结果表明，多模型协作不仅增强了响应可靠性，还为在缺乏ground truth的情况下评估和改进问题质量提供了有效框架。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "stat.AP",
      "comment": "14 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2411.16797",
      "pdf_url": "http://arxiv.org/pdf/2502.20758v1",
      "published_date": "2025-02-28 06:20:52 UTC",
      "updated_date": "2025-02-28 06:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:25:55.276981"
    },
    {
      "arxiv_id": "2502.20754v1",
      "title": "Acquiring Grounded Representations of Words with Situated Interactive Instruction",
      "title_zh": "翻译失败",
      "authors": [
        "Shiwali Mohan",
        "Aaron H. Mininger",
        "James R. Kirk",
        "John E. Laird"
      ],
      "abstract": "We present an approach for acquiring grounded representations of words from\nmixed-initiative, situated interactions with a human instructor. The work\nfocuses on the acquisition of diverse types of knowledge including perceptual,\nsemantic, and procedural knowledge along with learning grounded meanings.\nInteractive learning allows the agent to control its learning by requesting\ninstructions about unknown concepts, making learning efficient. Our approach\nhas been instantiated in Soar and has been evaluated on a table-top robotic arm\ncapable of manipulating small objects.",
      "tldr_zh": "本研究提出了一种通过situated interactive instruction的方法，从与人类指导者的mixed-initiative互动中获取词汇的grounded representations。该方法支持代理获取perceptual, semantic和procedural knowledge，并学习grounded meanings，同时允许代理通过请求未知概念的指令来控制和优化学习过程。该方法已在Soar系统中实现，并在table-top robotic arm上进行了评估，证明了其在机器人学习中的高效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20754v1",
      "published_date": "2025-02-28 06:04:52 UTC",
      "updated_date": "2025-02-28 06:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:26:06.774168"
    },
    {
      "arxiv_id": "2502.20748v1",
      "title": "Teach-to-Reason with Scoring: Self-Explainable Rationale-Driven Multi-Trait Essay Scoring",
      "title_zh": "翻译失败",
      "authors": [
        "Heejin Do",
        "Sangwon Ryu",
        "Gary Geunbae Lee"
      ],
      "abstract": "Multi-trait automated essay scoring (AES) systems provide a fine-grained\nevaluation of an essay's diverse aspects. While they excel in scoring, prior\nsystems fail to explain why specific trait scores are assigned. This lack of\ntransparency leaves instructors and learners unconvinced of the AES outputs,\nhindering their practical use. To address this, we propose a self-explainable\nRationale-Driven Multi-trait automated Essay scoring (RaDME) framework. RaDME\nleverages the reasoning capabilities of large language models (LLMs) by\ndistilling them into a smaller yet effective scorer. This more manageable\nstudent model is optimized to sequentially generate a trait score followed by\nthe corresponding rationale, thereby inherently learning to select a more\njustifiable score by considering the subsequent rationale during training. Our\nfindings indicate that while LLMs underperform in direct AES tasks, they excel\nin rationale generation when provided with precise numerical scores. Thus,\nRaDME integrates the superior reasoning capacities of LLMs into the robust\nscoring accuracy of an optimized smaller model. Extensive experiments\ndemonstrate that RaDME achieves both accurate and adequate reasoning while\nsupporting high-quality multi-trait scoring, significantly enhancing the\ntransparency of AES.",
      "tldr_zh": "本研究针对多特征自动作文评分（Multi-trait AES）系统的透明度问题，提出了一种自解释的 Rationale-Driven Multi-trait automated Essay scoring (RaDME) 框架，以解决现有系统无法解释分数分配的原因。RaDME 利用大型语言模型（LLMs）的推理能力，通过知识蒸馏到更小的模型中，使其能够顺序生成特征分数及其对应理由，从而在训练过程中学习选择更合理的评分。实验结果表明，虽然 LLMs 在直接 AES 任务中表现不佳，但 RaDME 成功整合了 LLMs 的推理优势和小型模型的准确性，实现高品质的多特征评分和理由生成，大大提升了 AES 的透明度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20748v1",
      "published_date": "2025-02-28 05:54:23 UTC",
      "updated_date": "2025-02-28 05:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:26:18.973238"
    },
    {
      "arxiv_id": "2502.20742v3",
      "title": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiwen Liang",
        "Min Lin",
        "Weiqi Ruan",
        "Rongtao Xu",
        "Yuecheng Liu",
        "Jiaqi Chen",
        "Bingqian Lin",
        "Yuzheng Zhuang",
        "Xiaodan Liang"
      ],
      "abstract": "Existing methods for vision-language task planning excel in short-horizon\ntasks but often fall short in complex, long-horizon planning within dynamic\nenvironments. These challenges primarily arise from the difficulty of\neffectively training models to produce high-quality reasoning processes for\nlong-horizon tasks. To address this, we propose Structured Preference\nOptimization (SPO), which aims to enhance reasoning and action selection in\nlong-horizon task planning through structured preference evaluation and\noptimized training strategies. Specifically, SPO introduces: 1)\nPreference-Based Scoring and Optimization, which systematically evaluates\nreasoning chains based on task relevance, visual grounding, and historical\nconsistency; and 2) Curriculum-Guided Training, where the model progressively\nadapts from simple to complex tasks, improving its generalization ability in\nlong-horizon scenarios and enhancing reasoning robustness. To advance research\nin vision-language long-horizon task planning, we introduce ExtendaBench, a\ncomprehensive benchmark covering 1,509 tasks across VirtualHome and Habitat\n2.0, categorized into ultra-short, short, medium, and long tasks. Experimental\nresults demonstrate that SPO significantly improves reasoning quality and final\ndecision accuracy, outperforming prior methods on long-horizon tasks and\nunderscoring the effectiveness of preference-driven optimization in\nvision-language task planning. Specifically, SPO achieves a +5.98% GCR and\n+4.68% SR improvement in VirtualHome and a +3.30% GCR and +2.11% SR improvement\nin Habitat over the best-performing baselines.",
      "tldr_zh": "该论文针对视觉语言模型在动态环境中进行长期任务规划的挑战，提出 Structured Preference Optimization (SPO) 方法，以提升推理质量和行动选择。SPO 包括 Preference-Based Scoring and Optimization（基于任务相关性、视觉 grounding 和历史一致性评估推理链）和 Curriculum-Guided Training（从简单到复杂任务逐步训练，提高泛化能力和鲁棒性）。为了推进相关研究，作者引入了 ExtendaBench 基准，涵盖 1509 个任务，横跨 VirtualHome 和 Habitat 2.0 的不同长度任务。实验结果显示，SPO 在长期任务上显著优于基线模型，提高了 GCR 和 SR 指标，如在 VirtualHome 上提升 5.98% GCR 和 4.68% SR。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.20742v3",
      "published_date": "2025-02-28 05:47:34 UTC",
      "updated_date": "2025-05-16 03:07:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:26:32.006820"
    },
    {
      "arxiv_id": "2502.20730v1",
      "title": "DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoqun Li",
        "Haiyang Yu",
        "Xuanang Chen",
        "Hongyu Lin",
        "Yaojie Lu",
        "Fei Huang",
        "Xianpei Han",
        "Yongbin Li",
        "Le Sun"
      ],
      "abstract": "Designing solutions for complex engineering challenges is crucial in human\nproduction activities. However, previous research in the retrieval-augmented\ngeneration (RAG) field has not sufficiently addressed tasks related to the\ndesign of complex engineering solutions. To fill this gap, we introduce a new\nbenchmark, SolutionBench, to evaluate a system's ability to generate complete\nand feasible solutions for engineering problems with multiple complex\nconstraints. To further advance the design of complex engineering solutions, we\npropose a novel system, SolutionRAG, that leverages the tree-based exploration\nand bi-point thinking mechanism to generate reliable solutions. Extensive\nexperimental results demonstrate that SolutionRAG achieves state-of-the-art\n(SOTA) performance on the SolutionBench, highlighting its potential to enhance\nthe automation and reliability of complex engineering solution design in\nreal-world applications.",
      "tldr_zh": "这篇论文针对复杂工程解决方案设计的不足，引入了新的基准 SolutionBench，用于评估系统生成完整、可行解决方案的能力，尤其针对具有多个复杂约束的工程问题。作者提出了一种新系统 SolutionRAG，通过 tree-based exploration 和 bi-point thinking 机制来提升 RAG（Retrieval-Augmented Generation）的性能，从而生成更可靠的解决方案。实验结果显示，SolutionRAG 在 SolutionBench 上达到了 SOTA（State-of-the-Art）水平，并展示了其在真实世界应用中提升工程设计自动化和可靠性的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20730v1",
      "published_date": "2025-02-28 05:23:10 UTC",
      "updated_date": "2025-02-28 05:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:26:42.978052"
    },
    {
      "arxiv_id": "2502.20729v1",
      "title": "NeuroMorse: A Temporally Structured Dataset For Neuromorphic Computing",
      "title_zh": "NeuroMorse：用于神经形态计算的时间结构化数据集",
      "authors": [
        "Ben Walters",
        "Yeshwanth Bethi",
        "Taylor Kergan",
        "Binh Nguyen",
        "Amirali Amirsoleimani",
        "Jason K. Eshraghian",
        "Saeed Afshar",
        "Mostafa Rahimi Azghadi"
      ],
      "abstract": "Neuromorphic engineering aims to advance computing by mimicking the brain's\nefficient processing, where data is encoded as asynchronous temporal events.\nThis eliminates the need for a synchronisation clock and minimises power\nconsumption when no data is present. However, many benchmarks for neuromorphic\nalgorithms primarily focus on spatial features, neglecting the temporal\ndynamics that are inherent to most sequence-based tasks. This gap may lead to\nevaluations that fail to fully capture the unique strengths and characteristics\nof neuromorphic systems. In this paper, we present NeuroMorse, a temporally\nstructured dataset designed for benchmarking neuromorphic learning systems.\nNeuroMorse converts the top 50 words in the English language into temporal\nMorse code spike sequences. Despite using only two input spike channels for\nMorse dots and dashes, complex information is encoded through temporal patterns\nin the data. The proposed benchmark contains feature hierarchy at multiple\ntemporal scales that test the capacity of neuromorphic algorithms to decompose\ninput patterns into spatial and temporal hierarchies. We demonstrate that our\ntraining set is challenging to categorise using a linear classifier and that\nidentifying keywords in the test set is difficult using conventional methods.\nThe NeuroMorse dataset is available at Zenodo, with our accompanying code on\nGitHub at https://github.com/Ben-E-Walters/NeuroMorse.",
      "tldr_zh": "该论文介绍了 NeuroMorse，这是一个专为 neuromorphic computing 设计的 temporally structured dataset，旨在解决现有基准测试过度关注空间特征而忽略时间动态的问题。NeuroMorse 通过将英语前50个常用单词转换为 Morse code 的 spike sequences，仅使用两个输入通道（dots 和 dashes）来编码复杂的时间模式，并包含多层次的 temporal scales，以测试 neuromorphic 算法分解输入模式为空间和时间层次的能力。实验结果显示，该数据集对线性分类器和传统方法构成挑战，突显了其在评估 neuromorphic 系统独特优势方面的潜力；数据集可在 Zenodo 下载，代码在 GitHub 上公开。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20729v1",
      "published_date": "2025-02-28 05:22:45 UTC",
      "updated_date": "2025-02-28 05:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:26:55.430793"
    },
    {
      "arxiv_id": "2502.20727v3",
      "title": "SPD: Sync-Point Drop for efficient tensor parallelism of Large Language Models",
      "title_zh": "SPD：Sync-Point Drop 用于高效张量并行的大语言模型",
      "authors": [
        "Han-Byul Kim",
        "Duc Hoang",
        "Arnav Kundu",
        "Mohammad Samragh",
        "Minsik Cho"
      ],
      "abstract": "With the rapid expansion in the scale of large language models (LLMs),\nenabling efficient distributed inference across multiple computing units has\nbecome increasingly critical. However, communication overheads from popular\ndistributed inference techniques such as Tensor Parallelism pose a significant\nchallenge to achieve scalability and low latency. Therefore, we introduce a\nnovel optimization technique, Sync-Point Drop (SPD), to reduce communication\noverheads in tensor parallelism by selectively dropping synchronization on\nattention outputs. In detail, we first propose a block design that allows\nexecution to proceed without communication through SPD. Second, we apply\ndifferent SPD strategies to attention blocks based on their sensitivity to the\nmodel accuracy. The proposed methods effectively alleviate communication\nbottlenecks while minimizing accuracy degradation during LLM inference,\noffering a scalable solution for diverse distributed environments: SPD offered\nabout 20% overall inference latency reduction with < 1% accuracy regression for\nLLaMA2-70B inference over 8 GPUs.",
      "tldr_zh": "本文提出 Sync-Point Drop (SPD) 技术，用于优化大型语言模型 (LLMs) 的张量并行性 (Tensor Parallelism)，以减少分布式推理中的通信开销问题。SPD 通过一个块设计允许在注意力输出上选择性放弃同步，并根据块对模型准确性的敏感度应用不同策略，从而缓解通信瓶颈同时最小化准确性下降。实验结果显示，在 LLaMA2-70B 模型上使用 8 个 GPU 时，SPD 实现了约 20% 的整体推理延迟减少，同时准确性回归小于 1%，为高效的分布式环境提供了可伸缩解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "International Conference on Machine Learning (ICML) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.20727v3",
      "published_date": "2025-02-28 05:20:48 UTC",
      "updated_date": "2025-05-21 04:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:27:07.297861"
    },
    {
      "arxiv_id": "2502.20719v1",
      "title": "Generating Clinically Realistic EHR Data via a Hierarchy- and Semantics-Guided Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Guanglin Zhou",
        "Sebastiano Barbieri"
      ],
      "abstract": "Generating realistic synthetic electronic health records (EHRs) holds\ntremendous promise for accelerating healthcare research, facilitating AI model\ndevelopment and enhancing patient privacy. However, existing generative methods\ntypically treat EHRs as flat sequences of discrete medical codes. This approach\noverlooks two critical aspects: the inherent hierarchical organization of\nclinical coding systems and the rich semantic context provided by code\ndescriptions. Consequently, synthetic patient sequences often lack high\nclinical fidelity and have limited utility in downstream clinical tasks. In\nthis paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT),\na novel framework that leverages both hierarchical and semantic information for\nthe generative process. HiSGT constructs a hierarchical graph to encode\nparent-child and sibling relationships among clinical codes and employs a graph\nneural network to derive hierarchy-aware embeddings. These are then fused with\nsemantic embeddings extracted from a pre-trained clinical language model (e.g.,\nClinicalBERT), enabling the Transformer-based generator to more accurately\nmodel the nuanced clinical patterns inherent in real EHRs. Extensive\nexperiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGT\nsignificantly improves the statistical alignment of synthetic data with real\npatient records, as well as supports robust downstream applications such as\nchronic disease classification. By addressing the limitations of conventional\nraw code-based generative models, HiSGT represents a significant step toward\nclinically high-fidelity synthetic data generation and a general paradigm\nsuitable for interpretable medical code representation, offering valuable\napplications in data augmentation and privacy-preserving healthcare analytics.",
      "tldr_zh": "本研究针对现有EHR生成方法忽略临床编码的层次结构和语义上下文的问题，提出了一种Hierarchy- and Semantics-Guided Transformer (HiSGT)框架，以提升合成EHR数据的临床真实性。HiSGT通过构建分层图编码代码间的父子及兄弟关系，使用图神经网络生成层次感知嵌入，并将其与语义嵌入（如ClinicalBERT）融合，指导Transformer模型更准确地捕捉真实EHR模式。在MIMIC-III和MIMIC-IV数据集上的实验显示，HiSGT显著提高了合成数据的统计对齐度，并支持下游任务如慢性病分类，提供了一个可解释的医疗代码表示范式，用于数据增强和隐私保护的医疗分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20719v1",
      "published_date": "2025-02-28 05:06:04 UTC",
      "updated_date": "2025-02-28 05:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:27:18.900221"
    },
    {
      "arxiv_id": "2503.00081v1",
      "title": "Experiences with Content Development and Assessment Design in the Era of GenAI",
      "title_zh": "在 GenAI 时代的内容开发与评估设计经验",
      "authors": [
        "Aakanksha Sharma",
        "Samar Shailendra",
        "Rajan Kadel"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) has the potential to transform\nhigher education by generating human-like content. The advancement in GenAI has\nrevolutionised several aspects of education, especially subject and assessment\ndesign. In this era, it is crucial to design assessments that challenge\nstudents and cannot be solved using GenAI tools. This makes it necessary to\nupdate the educational content with rapidly evolving technology. The assessment\nplays a significant role in ensuring the students learning, as it encourages\nstudents to engage actively, leading to the achievement of learning outcomes.\nThe paper intends to determine how effectively GenAI can design a subject,\nincluding lectures, labs and assessments, using prompts and custom-based\ntraining. This paper aims to elucidate the direction to educators so they can\nleverage GenAI to create subject content. Additionally, we provided our\nexperiential learning for educators to develop content, highlighting the\nimportance of prompts and fine-tuning to ensure output quality. It has also\nbeen observed that expert evaluation is essential for assessing the quality of\nGenAI-generated materials throughout the content generation process.",
      "tldr_zh": "本研究探讨了在 Generative Artificial Intelligence (GenAI) 时代，如何开发教育内容和设计评估，以应对 GenAI 工具对高等教育的挑战。论文通过使用 prompts 和 custom-based training，评估 GenAI 在创建学科内容（如讲座、实验和评估）方面的有效性，并强调了设计不可由 GenAI 解决的评估，以鼓励学生主动参与和实现学习目标。研究提供了教育者利用 GenAI 的指导经验，突出了 fine-tuning 和专家评估在确保输出质量中的关键作用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.00081v1",
      "published_date": "2025-02-28 05:05:15 UTC",
      "updated_date": "2025-02-28 05:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:27:30.508365"
    },
    {
      "arxiv_id": "2503.01900v1",
      "title": "LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection",
      "title_zh": "LLM 赋能的类不平衡图提示学习用于在线毒品贩运检测",
      "authors": [
        "Tianyi Ma",
        "Yiyue Qian",
        "Zehong Wang",
        "Zheyuan Zhang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "As the market for illicit drugs remains extremely profitable, major online\nplatforms have become direct-to-consumer intermediaries for illicit drug\ntrafficking participants. These online activities raise significant social\nconcerns that require immediate actions. Existing approaches to combating this\nchallenge are generally impractical, due to the imbalance of classes and\nscarcity of labeled samples in real-world applications. To this end, we propose\na novel Large Language Model-empowered Heterogeneous Graph Prompt Learning\nframework for illicit Drug Trafficking detection, called LLM-HetGDT, that\nleverages LLM to facilitate heterogeneous graph neural networks (HGNNs) to\neffectively identify drug trafficking activities in the class-imbalanced\nscenarios. Specifically, we first pre-train HGNN over a contrastive pretext\ntask to capture the inherent node and structure information over the unlabeled\ndrug trafficking heterogeneous graph (HG). Afterward, we employ LLM to augment\nthe HG by generating high-quality synthetic user nodes in minority classes.\nThen, we fine-tune the soft prompts on the augmented HG to capture the\nimportant information in the minority classes for the downstream drug\ntrafficking detection task. To comprehensively study online illicit drug\ntrafficking activities, we collect a new HG dataset over Twitter, called\nTwitter-HetDrug. Extensive experiments on this dataset demonstrate the\neffectiveness, efficiency, and applicability of LLM-HetGDT.",
      "tldr_zh": "该研究针对在线毒品交易检测中的类别不平衡和标签样本稀缺问题，提出了一种新型框架LLM-HetGDT，利用大型语言模型(LLM)增强异构图神经网络(HGNNs)。具体方法包括先在对比预训练任务上预训练HGNN以捕获未标记异构图的节点和结构信息，然后使用LLM生成少数类别的合成用户节点增强图，最后在增强后的图上微调软提示以突出少数类别的关键信息。实验在新收集的Twitter-HetDrug数据集上进行，证明了LLM-HetGDT的有效性、效率和实际适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01900v1",
      "published_date": "2025-02-28 04:38:24 UTC",
      "updated_date": "2025-02-28 04:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:27:42.871354"
    },
    {
      "arxiv_id": "2502.20704v3",
      "title": "Fuzzy Speculative Decoding for a Tunable Accuracy-Runtime Tradeoff",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Holsman",
        "Yukun Huang",
        "Bhuwan Dhingra"
      ],
      "abstract": "Speculative Decoding (SD) enforces strict distributional equivalence to the\ntarget model, limiting potential speed ups as distributions of near-equivalence\nachieve comparable outcomes in many cases. Furthermore, enforcing\ndistributional equivalence means that users are unable to trade deviations from\nthe target model distribution for further inference speed gains. To address\nthese limitations, we introduce Fuzzy Speculative Decoding (FSD) - a decoding\nalgorithm that generalizes SD by accepting candidate tokens purely based on the\ndivergences between the target and draft model distributions. By allowing for\ncontrolled divergence from the target model, FSD enables users to flexibly\ntrade generation quality for inference speed. Across several benchmarks, our\nmethod is able to achieve significant runtime improvements of over 5 tokens per\nsecond faster than SD at only an approximate 2% absolute reduction in benchmark\naccuracy. In many cases, FSD is even able to match SD benchmark accuracy at\nover 2 tokens per second faster, demonstrating that distributional equivalence\nis not necessary to maintain target model performance.",
      "tldr_zh": "这篇论文提出了 Fuzzy Speculative Decoding (FSD)，一种泛化 Speculative Decoding (SD) 的算法，通过基于目标模型和草稿模型分布差异来接受候选 tokens，从而实现可调的准确性-运行时 trade-off。FSD 允许用户通过控制分布偏差，灵活地在生成质量和推理速度之间进行平衡，而非强制分布等价。实验结果显示，在多个基准测试中，FSD 比 SD 快超过 5 tokens per second，仅以约 2% 的绝对准确率减少为代价；在许多情况下，FSD 甚至能在比 SD 快 2 tokens per second 的情况下匹配其基准准确率，证明分布等价并非维持性能的必要条件。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20704v3",
      "published_date": "2025-02-28 04:25:42 UTC",
      "updated_date": "2025-03-04 15:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:27:56.563889"
    },
    {
      "arxiv_id": "2502.20701v1",
      "title": "Why Trust in AI May Be Inevitable",
      "title_zh": "为什么对 AI 的信任可能是不可避免的",
      "authors": [
        "Nghi Truong",
        "Phanish Puranam",
        "Ilia Testlin"
      ],
      "abstract": "In human-AI interactions, explanation is widely seen as necessary for\nenabling trust in AI systems. We argue that trust, however, may be a\npre-requisite because explanation is sometimes impossible. We derive this\nresult from a formalization of explanation as a search process through\nknowledge networks, where explainers must find paths between shared concepts\nand the concept to be explained, within finite time. Our model reveals that\nexplanation can fail even under theoretically ideal conditions - when actors\nare rational, honest, motivated, can communicate perfectly, and possess\noverlapping knowledge. This is because successful explanation requires not just\nthe existence of shared knowledge but also finding the connection path within\ntime constraints, and it can therefore be rational to cease attempts at\nexplanation before the shared knowledge is discovered. This result has\nimportant implications for human-AI interaction: as AI systems, particularly\nLarge Language Models, become more sophisticated and able to generate\nsuperficially compelling but spurious explanations, humans may default to trust\nrather than demand genuine explanations. This creates risks of both misplaced\ntrust and imperfect knowledge integration.",
      "tldr_zh": "该论文论证了在人-AI 互动中，解释并非总是建立信任的必要条件，因为信任可能成为解释失败时的前提。作者通过将解释形式化为知识网络中的搜索过程，证明即使在理想条件下（如参与者理性、诚实、动机充足、完美沟通和共享知识），解释也可能因时间约束而失败，导致理性放弃尝试。研究发现，随着 AI 系统特别是 Large Language Models 生成看似可信但虚假的解释，人们可能默认信任，这会带来错误信任和知识整合风险的风险。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20701v1",
      "published_date": "2025-02-28 04:20:24 UTC",
      "updated_date": "2025-02-28 04:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:28:06.856043"
    },
    {
      "arxiv_id": "2503.04788v1",
      "title": "AgroLLM: Connecting Farmers and Agricultural Practices through Large Language Models for Enhanced Knowledge Transfer and Practical Application",
      "title_zh": "AgroLLM：通过大型语言模型连接农民和农业实践，以增强知识转移和实际应用",
      "authors": [
        "Dinesh Jackson Samuel",
        "Inna Skarga-Bandurova",
        "David Sikolia",
        "Muhammad Awais"
      ],
      "abstract": "AgroLLM is an AI-powered chatbot designed to enhance knowledge-sharing and\neducation in agriculture using Large Language Models (LLMs) and a\nRetrieval-Augmented Generation (RAG) framework. By using a comprehensive\nopen-source agricultural database, AgroLLM provides accurate, contextually\nrelevant responses while reducing incorrect information retrieval. The system\nutilizes the FAISS vector database for efficient similarity searches, ensuring\nrapid access to agricultural knowledge. A comparative study of three advanced\nmodels: Gemini 1.5 Flash, ChatGPT-4o Mini, and Mistral-7B-Instruct-v0.2 was\nconducted to evaluate performance across four key agricultural domains:\nAgriculture and Life Sciences, Agricultural Management, Agriculture and\nForestry, and Agriculture Business. Key evaluation metrics included embedding\nquality, search efficiency, and response relevance. Results indicated that\nChatGPT-4o Mini with RAG achieved the highest accuracy at 93%. Continuous\nfeedback mechanisms enhance response quality, making AgroLLM a benchmark\nAI-driven educational tool for farmers, researchers, and professionals,\npromoting informed decision-making and improved agricultural practices.",
      "tldr_zh": "本文介绍了 AgroLLM，一种基于 Large Language Models (LLMs) 和 Retrieval-Augmented Generation (RAG) 框架的 AI 聊天机器人，旨在通过开源农业数据库和 FAISS 向量数据库提升知识共享、教育和实际应用。研究比较了 Gemini 1.5 Flash、ChatGPT-4o Mini 和 Mistral-7B-Instruct-v0.2 等模型在农业与生命科学、农业管理、农业与林业以及农业商业等四个领域的性能，包括嵌入质量、搜索效率和响应相关性。结果显示，ChatGPT-4o Mini 与 RAG 结合取得了93%的最高准确率，并通过持续反馈机制，使 AgroLLM 成为帮助农民、研究人员和专业人士做出 informed 决策、改善农业实践的基准工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04788v1",
      "published_date": "2025-02-28 04:13:18 UTC",
      "updated_date": "2025-02-28 04:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:28:21.041184"
    },
    {
      "arxiv_id": "2502.20694v1",
      "title": "WorldModelBench: Judging Video Generation Models As World Models",
      "title_zh": "WorldModelBench：评判视频生成模型作为世界模型",
      "authors": [
        "Dacheng Li",
        "Yunhao Fang",
        "Yukang Chen",
        "Shuo Yang",
        "Shiyi Cao",
        "Justin Wong",
        "Michael Luo",
        "Xiaolong Wang",
        "Hongxu Yin",
        "Joseph E. Gonzalez",
        "Ion Stoica",
        "Song Han",
        "Yao Lu"
      ],
      "abstract": "Video generation models have rapidly progressed, positioning themselves as\nvideo world models capable of supporting decision-making applications like\nrobotics and autonomous driving. However, current benchmarks fail to rigorously\nevaluate these claims, focusing only on general video quality, ignoring\nimportant factors to world models such as physics adherence. To bridge this\ngap, we propose WorldModelBench, a benchmark designed to evaluate the world\nmodeling capabilities of video generation models in application-driven domains.\nWorldModelBench offers two key advantages: (1) Against to nuanced world\nmodeling violations: By incorporating instruction-following and\nphysics-adherence dimensions, WorldModelBench detects subtle violations, such\nas irregular changes in object size that breach the mass conservation law -\nissues overlooked by prior benchmarks. (2) Aligned with large-scale human\npreferences: We crowd-source 67K human labels to accurately measure 14 frontier\nmodels. Using our high-quality human labels, we further fine-tune an accurate\njudger to automate the evaluation procedure, achieving 8.6% higher average\naccuracy in predicting world modeling violations than GPT-4o with 2B\nparameters. In addition, we demonstrate that training to align human\nannotations by maximizing the rewards from the judger noticeably improve the\nworld modeling capability. The website is available at\nhttps://worldmodelbench-team.github.io.",
      "tldr_zh": "论文提出 WorldModelBench，这是一个基准测试，用于评估视频生成模型作为世界模型的能力，特别关注指令-following 和 physics-adherence 等维度，以弥补现有基准忽略物理遵守等关键因素。WorldModelBench 通过收集 67K 人类标签来评估 14 个前沿模型，并微调一个自动评判器，使其在预测世界建模违规方面的准确率比 GPT-4o 高 8.6%。此外，研究发现，通过最大化评判器的奖励来训练模型，能显著提升其世界建模能力，为机器人和自动驾驶等应用提供更可靠的评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20694v1",
      "published_date": "2025-02-28 03:58:23 UTC",
      "updated_date": "2025-02-28 03:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:28:31.665095"
    },
    {
      "arxiv_id": "2502.20689v1",
      "title": "ProAI: Proactive Multi-Agent Conversational AI with Structured Knowledge Base for Psychiatric Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Wu",
        "Guangya Wan",
        "Jingjing Li",
        "Shengming Zhao",
        "Lingfeng Ma",
        "Tianyi Ye",
        "Ion Pop",
        "Yanbo Zhang",
        "Jie Chen"
      ],
      "abstract": "Most LLM-driven conversational AI systems operate reactively, responding to\nuser prompts without guiding the interaction. Most LLM-driven conversational AI\nsystems operate reactively, responding to user prompts without guiding the\ninteraction. However, many real-world applications-such as psychiatric\ndiagnosis, consulting, and interviews-require AI to take a proactive role,\nasking the right questions and steering conversations toward specific\nobjectives. Using mental health differential diagnosis as an application\ncontext, we introduce ProAI, a goal-oriented, proactive conversational AI\nframework. ProAI integrates structured knowledge-guided memory, multi-agent\nproactive reasoning, and a multi-faceted evaluation strategy, enabling LLMs to\nengage in clinician-style diagnostic reasoning rather than simple response\ngeneration. Through simulated patient interactions, user experience assessment,\nand professional clinical validation, we demonstrate that ProAI achieves up to\n83.3% accuracy in mental disorder differential diagnosis while maintaining\nprofessional and empathetic interaction standards. These results highlight the\npotential for more reliable, adaptive, and goal-driven AI diagnostic\nassistants, advancing LLMs beyond reactive dialogue systems.",
      "tldr_zh": "这篇论文引入 ProAI，一种面向精神病诊断的主动多智能体对话 AI 框架，旨在解决现有 LLM 驱动系统反应性不足的问题，通过主动提问和引导对话实现目标导向的互动。ProAI 整合结构化知识-guided memory、多智能体 proactive reasoning 和多方面评估策略，使 LLMs 能够进行类似临床医生的诊断推理，而非简单响应。实验结果显示，ProAI 在精神障碍鉴别诊断中达到 83.3% 的准确率，同时保持专业和移情的互动标准。这些创新为更可靠、适应性和目标驱动的 AI 诊断助手铺平了道路，推动 LLMs 超越传统反应性对话系统。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.20689v1",
      "published_date": "2025-02-28 03:45:39 UTC",
      "updated_date": "2025-02-28 03:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:28:43.989140"
    },
    {
      "arxiv_id": "2502.20687v1",
      "title": "Unleashing the Potential of Two-Tower Models: Diffusion-Based Cross-Interaction for Large-Scale Matching",
      "title_zh": "释放双塔模型的潜力：基于扩散的交叉交互用于大规模匹配",
      "authors": [
        "Yihan Wang",
        "Fei Xiong",
        "Zhexin Han",
        "Qi Song",
        "Kaiqiao Zhan",
        "Ben Wang"
      ],
      "abstract": "Two-tower models are widely adopted in the industrial-scale matching stage\nacross a broad range of application domains, such as content recommendations,\nadvertisement systems, and search engines. This model efficiently handles\nlarge-scale candidate item screening by separating user and item\nrepresentations. However, the decoupling network also leads to a neglect of\npotential information interaction between the user and item representations.\nCurrent state-of-the-art (SOTA) approaches include adding a shallow fully\nconnected layer(i.e., COLD), which is limited by performance and can only be\nused in the ranking stage. For performance considerations, another approach\nattempts to capture historical positive interaction information from the other\ntower by regarding them as the input features(i.e., DAT). Later research showed\nthat the gains achieved by this method are still limited because of lacking the\nguidance on the next user intent. To address the aforementioned challenges, we\npropose a \"cross-interaction decoupling architecture\" within our matching\nparadigm. This user-tower architecture leverages a diffusion module to\nreconstruct the next positive intention representation and employs a\nmixed-attention module to facilitate comprehensive cross-interaction. During\nthe next positive intention generation, we further enhance the accuracy of its\nreconstruction by explicitly extracting the temporal drift within user behavior\nsequences. Experiments on two real-world datasets and one industrial dataset\ndemonstrate that our method outperforms the SOTA two-tower models\nsignificantly, and our diffusion approach outperforms other generative models\nin reconstructing item representations.",
      "tldr_zh": "该论文探讨了Two-Tower models在大型匹配任务（如推荐系统和搜索引擎）中的局限性，即忽略用户和物品表示之间的交互，导致性能不足。作者提出了一种“cross-interaction decoupling architecture”，利用diffusion module重建下一个积极意图表示，并结合mixed-attention module和提取用户行为序列中的temporal drift，实现全面的跨塔交互。实验在两个真实数据集和一个工业数据集上表明，该方法显著优于SOTA Two-Tower models，且diffusion approach在重建物品表示方面超越其他生成模型。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20687v1",
      "published_date": "2025-02-28 03:40:37 UTC",
      "updated_date": "2025-02-28 03:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:28:54.625218"
    },
    {
      "arxiv_id": "2502.20684v1",
      "title": "JAM: Controllable and Responsible Text Generation via Causal Reasoning and Latent Vector Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yingbing Huang",
        "Deming Chen",
        "Abhishek K. Umrawal"
      ],
      "abstract": "While large language models (LLMs) have made significant strides in\ngenerating coherent and contextually relevant text, they often function as\nopaque black boxes, trained on vast unlabeled datasets with statistical\nobjectives, lacking an interpretable framework for responsible control. In this\npaper, we introduce JAM (Just A Move), a novel framework that interprets and\ncontrols text generation by integrating cause-effect analysis within the latent\nspace of LLMs. Based on our observations, we uncover the inherent causality in\nLLM generation, which is critical for producing responsible and realistic\noutputs. Moreover, we explore latent vectors as fundamental components in LLM\narchitectures, aiming to understand and manipulate them for more effective and\nefficient controllable text generation. We evaluate our framework using a range\nof tools, including the HHH criteria, toxicity reduction benchmarks, and GPT-4\nalignment measures. Our results show that JAM achieves up to a 22% improvement\nover previous Controllable Text Generation (CTG) methods across multiple\nquantitative metrics and human-centric evaluations. Furthermore, JAM\ndemonstrates greater computational efficiency compared to other CTG methods.\nThese results highlight the effectiveness and efficiency of JAM for responsible\nand realistic text generation, paving the way for more interpretable and\ncontrollable models.",
      "tldr_zh": "本研究提出JAM框架，通过整合因果推理(causal reasoning)和潜在向量操作(latent vector manipulation)，来解释和控制大型语言模型(LLMs)的文本生成过程，从而解决LLMs作为黑箱模型的透明度问题。JAM利用LLMs生成中的内在因果性，优化潜在空间以产生更负责任和真实的输出，并在HHH criteria、毒性减少基准和GPT-4对齐度等指标上进行评估。结果显示，JAM相较于之前的Controllable Text Generation (CTG)方法在多个量化指标上提升了多达22%，并表现出更高的计算效率，为可解释和可控的文本生成模型铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T07, 68T30, 68T35, 68T37, 68T50",
        "I.2.0; I.2.6; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, and 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.20684v1",
      "published_date": "2025-02-28 03:31:48 UTC",
      "updated_date": "2025-02-28 03:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:29:07.828825"
    },
    {
      "arxiv_id": "2502.20682v1",
      "title": "Fine-tuning BERT with Bidirectional LSTM for Fine-grained Movie Reviews Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Gibson Nkhata",
        "Susan Gauch",
        "Usman Anjum",
        "Justin Zhan"
      ],
      "abstract": "Sentiment Analysis (SA) is instrumental in understanding peoples viewpoints\nfacilitating social media monitoring recognizing products and brands and\ngauging customer satisfaction. Consequently SA has evolved into an active\nresearch domain within Natural Language Processing (NLP). Many approaches\noutlined in the literature devise intricate frameworks aimed at achieving high\naccuracy, focusing exclusively on either binary sentiment classification or\nfine-grained sentiment classification. In this paper our objective is to\nfine-tune the pre-trained BERT model with Bidirectional LSTM (BiLSTM) to\nenhance both binary and fine-grained SA specifically for movie reviews. Our\napproach involves conducting sentiment classification for each review followed\nby computing the overall sentiment polarity across all reviews. We present our\nfindings on binary classification as well as fine-grained classification\nutilizing benchmark datasets. Additionally we implement and assess two accuracy\nimprovement techniques Synthetic Minority Oversampling Technique (SMOTE) and\nNLP Augmenter (NLPAUG) to bolster the models generalization in fine-grained\nsentiment classification. Finally a heuristic algorithm is employed to\ncalculate the overall polarity of predicted reviews from the BERT+BiLSTM output\nvector. Our approach performs comparably with state-of-the-art (SOTA)\ntechniques in both classifications. For instance in binary classification we\nachieve 97.67% accuracy surpassing the leading SOTA model\nNB-weighted-BON+dv-cosine by 0.27% on the renowned IMDb dataset. Conversely for\nfive-class classification on SST-5 while the top SOTA model\nRoBERTa+large+Self-explaining attains 55.5% accuracy our model achieves 59.48%\naccuracy surpassing the BERT-large baseline by 3.6%.",
      "tldr_zh": "这篇论文提出了一种微调预训练 BERT 模型结合 Bidirectional LSTM (BiLSTM) 的方法，用于电影评论的二元和细粒度情感分析，旨在提升分类准确性。研究者引入 Synthetic Minority Oversampling Technique (SMOTE) 和 NLP Augmenter (NLPAUG) 作为改进技术，以增强模型的泛化能力，并使用启发式算法计算整体情感极性。实验结果显示，在 IMDb 数据集上二元分类准确率达到 97.67%，比领先的 SOTA 模型高 0.27%；在 SST-5 数据集上五分类准确率达 59.48%，比 BERT-large 基线高 3.6%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, published in International Journal On Advances\n  in Systems and Measurements, volume 16, numbers 3 and 4, 2023",
      "pdf_url": "http://arxiv.org/pdf/2502.20682v1",
      "published_date": "2025-02-28 03:30:48 UTC",
      "updated_date": "2025-02-28 03:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:29:20.017244"
    },
    {
      "arxiv_id": "2502.20681v1",
      "title": "Disentangling Feature Structure: A Mathematically Provable Two-Stage Training Dynamics in Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Gong",
        "Jiaye Teng",
        "Yong Liu"
      ],
      "abstract": "Transformers may exhibit two-stage training dynamics during the real-world\ntraining process. For instance, when training GPT-2 on the Counterfact dataset,\nthe answers progress from syntactically incorrect to syntactically correct to\nsemantically correct. However, existing theoretical analyses hardly account for\nthis two-stage phenomenon. In this paper, we theoretically demonstrate how such\ntwo-stage training dynamics occur in transformers. Specifically, we analyze the\ndynamics of transformers using feature learning techniques under in-context\nlearning regimes, based on a disentangled two-type feature structure. Such\ndisentanglement of feature structure is general in practice, e.g., natural\nlanguages contain syntax and semantics, and proteins contain primary and\nsecondary structures. To our best known, this is the first rigorous result\nregarding a two-stage optimization process in transformers. Additionally, a\ncorollary indicates that such a two-stage process is closely related to the\nspectral properties of the attention weights, which accords well with empirical\nfindings.",
      "tldr_zh": "该论文理论证明了 Transformers 在训练过程中存在的两阶段动态，例如从语法错误到正确再到语义正确。研究者使用特征学习（feature learning）技术，基于上下文学习（in-context learning）框架和分开的两种类型特征结构（disentangled two-type feature structure）进行分析，这种结构在实际应用中很常见，如语言的语法和语义。结果显示，这种两阶段优化过程与注意力权重（attention weights）的谱属性（spectral properties）密切相关，这是首个对 Transformers 两阶段过程的严格理论结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20681v1",
      "published_date": "2025-02-28 03:27:24 UTC",
      "updated_date": "2025-02-28 03:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:29:31.000520"
    },
    {
      "arxiv_id": "2503.04787v1",
      "title": "Towards Anthropomorphic Conversational AI Part I: A Practical Framework",
      "title_zh": "面向拟人化对话式人工智能 第一部分：一个实用框架",
      "authors": [
        "Fei Wei",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "abstract": "Large language models (LLMs), due to their advanced natural language\ncapabilities, have seen significant success in applications where the user\ninterface is usually a conversational artificial intelligence (AI) agent and\nengages the user through multi-round conversations. However, many scenarios\nrequire the agents to exhibit stronger social and conversational intelligence\nand demonstrate more human-like (anthropomorphic) reactions. This is an aspect\nthat foundational LLMs have yet to fully address such that a single call of\nfoundational models might be insufficient.\n  To bridge this gap, we propose a two-stage solution. In this work, we focus\non the first stage, introducing a multi-module framework designed to replicate\nthe key aspects of human intelligence involved in conversations. This framework\ncomprises thinking modules for reasoning, resource modules for managing\nknowledge and external information, and response modules for generating\ncontextually appropriate interactions. With all the modules cooperating, the\nframework would empower the agents to provide a better human-like conversation\nexperience. In the second stage of our approach, these conversational data,\nafter filtering and labeling, can serve as training and testing data for\nreinforcement learning, enabling AI to better capture human preferences. This\nstage is left for future work.\n  In our experiments, volunteers engaged in over 3000 rounds of conversation\nwith the same AI character powered by a standalone LLM and our framework which\nintegrates the same LLM. A separate group of evaluators rated the conversation\nsamples, revealing that our framework significantly enhanced the social and\nconversational intelligence, even without fine-tuning the LLM.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在对话AI中的局限性，提出一个多模块框架，以提升AI的社交和对话智能，使其更接近人类反应。该框架包括thinking modules用于推理、resource modules用于管理知识和外部信息，以及response modules用于生成情境适应的互动，这些模块协同工作，提供更逼真的对话体验。在实验中，志愿者参与超过3000轮对话后，独立评估显示，使用该框架的AI在社交和对话智能上显著优于单一LLMs，即使未进行微调。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04787v1",
      "published_date": "2025-02-28 03:18:39 UTC",
      "updated_date": "2025-02-28 03:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:29:42.724306"
    },
    {
      "arxiv_id": "2503.01899v1",
      "title": "FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection",
      "title_zh": "FASTer：焦点令牌获取与缩放 Transformer 用于长期 3D 物体检测",
      "authors": [
        "Chenxu Dang",
        "Zaipeng Duan",
        "Pei An",
        "Xinmin Zhang",
        "Xuzhong Hu",
        "Jie Ma"
      ],
      "abstract": "Recent top-performing temporal 3D detectors based on Lidars have increasingly\nadopted region-based paradigms. They first generate coarse proposals, followed\nby encoding and fusing regional features. However, indiscriminate sampling and\nfusion often overlook the varying contributions of individual points and lead\nto exponentially increased complexity as the number of input frames grows.\nMoreover, arbitrary result-level concatenation limits the global information\nextraction. In this paper, we propose a Focal Token Acquring-and-Scaling\nTransformer (FASTer), which dynamically selects focal tokens and condenses\ntoken sequences in an adaptive and lightweight manner. Emphasizing the\ncontribution of individual tokens, we propose a simple but effective Adaptive\nScaling mechanism to capture geometric contexts while sifting out focal points.\nAdaptively storing and processing only focal points in historical frames\ndramatically reduces the overall complexity. Furthermore, a novel Grouped\nHierarchical Fusion strategy is proposed, progressively performing sequence\nscaling and Intra-Group Fusion operations to facilitate the exchange of global\nspatial and temporal information. Experiments on the Waymo Open Dataset\ndemonstrate that our FASTer significantly outperforms other state-of-the-art\ndetectors in both performance and efficiency while also exhibiting improved\nflexibility and robustness. The code is available at\nhttps://github.com/MSunDYY/FASTer.git.",
      "tldr_zh": "这篇论文提出了 FASTer，一种用于长期 3D 对象检测的 Focal Token Acquiring-and-Scaling Transformer，旨在解决现有基于 Lidar 的区域检测器在采样融合中忽略点贡献和复杂度指数增长的问题。FASTer 通过 Adaptive Scaling 机制动态选择并缩放 focal tokens，仅处理历史帧的关键点，从而显著降低计算复杂度；同时引入 Grouped Hierarchical Fusion 策略，逐步进行序列缩放和 Intra-Group Fusion 以促进全局空间和时间信息的交换。在 Waymo Open Dataset 的实验中，FASTer 在性能和效率上显著优于最先进检测器，并展示了更高的灵活性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01899v1",
      "published_date": "2025-02-28 03:15:33 UTC",
      "updated_date": "2025-02-28 03:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:29:56.291098"
    },
    {
      "arxiv_id": "2503.13465v1",
      "title": "A novel Fourier Adjacency Transformer for advanced EEG emotion recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Jinfeng Wang",
        "Yanhao Huang",
        "Sifan Song",
        "Boqian Wang",
        "Jionglong Su",
        "Jiaman Ding"
      ],
      "abstract": "EEG emotion recognition faces significant hurdles due to noise interference,\nsignal nonstationarity, and the inherent complexity of brain activity which\nmake accurately emotion classification. In this study, we present the Fourier\nAdjacency Transformer, a novel framework that seamlessly integrates\nFourier-based periodic analysis with graph-driven structural modeling. Our\nmethod first leverages novel Fourier-inspired modules to extract periodic\nfeatures from embedded EEG signals, effectively decoupling them from aperiodic\ncomponents. Subsequently, we employ an adjacency attention scheme to reinforce\nuniversal inter-channel correlation patterns, coupling these patterns with\ntheir sample-based counterparts. Empirical evaluations on SEED and DEAP\ndatasets demonstrate that our method surpasses existing state-of-the-art\ntechniques, achieving an improvement of approximately 6.5% in recognition\naccuracy. By unifying periodicity and structural insights, this framework\noffers a promising direction for future research in EEG emotion analysis.",
      "tldr_zh": "本研究针对EEG情感识别面临的噪声干扰、信号非平稳性和大脑活动复杂性等问题，提出了一种新型Fourier Adjacency Transformer框架，将Fourier-based周期分析与graph-driven结构建模相结合。首先，该框架使用Fourier-inspired模块从EEG信号中提取周期特征，并与非周期成分分离；随后，通过adjacency attention方案强化通道间相关性，融合通用模式与样本特定模式。实验在SEED和DEAP数据集上显示，该方法比现有技术提高了约6.5%的识别准确率，为EEG情感分析提供了一个统一的周期性和结构洞见方向。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.13465v1",
      "published_date": "2025-02-28 03:15:12 UTC",
      "updated_date": "2025-02-28 03:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:30:07.116840"
    },
    {
      "arxiv_id": "2502.20668v1",
      "title": "OpenEarthSensing: Large-Scale Fine-Grained Benchmark for Open-World Remote Sensing",
      "title_zh": "OpenEarthSensing：大规模细粒度基准用于开放世界遥感",
      "authors": [
        "Xiang Xiang",
        "Zhuo Xu",
        "Yao Deng",
        "Qinhao Zhou",
        "Yifan Liang",
        "Ke Chen",
        "Qingfang Zheng",
        "Yaowei Wang",
        "Xilin Chen",
        "Wen Gao"
      ],
      "abstract": "In open-world remote sensing, deployed models must continuously adapt to a\nsteady influx of new data, which often exhibits various shifts compared to what\nthe model encountered during the training phase. To effectively handle the new\ndata, models are required to detect semantic shifts, adapt to covariate shifts,\nand continuously update themselves. These challenges give rise to a variety of\nopen-world tasks. However, existing open-world remote sensing studies typically\ntrain and test within a single dataset to simulate open-world conditions.\nCurrently, there is a lack of large-scale benchmarks capable of evaluating\nmultiple open-world tasks. In this paper, we introduce OpenEarthSensing, a\nlarge-scale fine-grained benchmark for open-world remote sensing.\nOpenEarthSensing includes 189 scene and objects categories, covering the vast\nmajority of potential semantic shifts that may occur in the real world.\nAdditionally, OpenEarthSensing encompasses five data domains with significant\ncovariate shifts, including two RGB satellite domians, one RGB aerial domian,\none MS RGB domian, and one infrared domian. The various domains provide a more\ncomprehensive testbed for evaluating the generalization performance of\nopen-world models. We conduct the baseline evaluation of current mainstream\nopen-world tasks and methods on OpenEarthSensing, demonstrating that it serves\nas a challenging benchmark for open-world remote sensing.",
      "tldr_zh": "该论文引入了 OpenEarthSensing，这是一个大规模细粒度基准，用于评估开放世界遥感（open-world remote sensing）中的模型适应性。OpenEarthSensing 涵盖 189 个场景和对象类别，并包括五个数据域（如 RGB 卫星、RGB 航空、MS RGB 和红外域），以模拟真实世界的语义 shifts 和 covariate shifts。实验结果显示，该基准对主流开放世界任务和方法的评估具有显著挑战性，有助于提升模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20668v1",
      "published_date": "2025-02-28 02:49:52 UTC",
      "updated_date": "2025-02-28 02:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:30:19.173146"
    },
    {
      "arxiv_id": "2502.20667v1",
      "title": "Advancing AI-Powered Medical Image Synthesis: Insights from MedVQA-GI Challenge Using CLIP, Fine-Tuned Stable Diffusion, and Dream-Booth + LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Ojonugwa Oluwafemi Ejiga Peter",
        "Md Mahmudur Rahman",
        "Fahmi Khalifa"
      ],
      "abstract": "The MEDVQA-GI challenge addresses the integration of AI-driven text-to-image\ngenerative models in medical diagnostics, aiming to enhance diagnostic\ncapabilities through synthetic image generation. Existing methods primarily\nfocus on static image analysis and lack the dynamic generation of medical\nimagery from textual descriptions. This study intends to partially close this\ngap by introducing a novel approach based on fine-tuned generative models to\ngenerate dynamic, scalable, and precise images from textual descriptions.\nParticularly, our system integrates fine-tuned Stable Diffusion and DreamBooth\nmodels, as well as Low-Rank Adaptation (LORA), to generate high-fidelity\nmedical images. The problem is around two sub-tasks namely: image synthesis\n(IS) and optimal prompt production (OPG). The former creates medical images via\nverbal prompts, whereas the latter provides prompts that produce high-quality\nimages in specified categories. The study emphasizes the limitations of\ntraditional medical image generation methods, such as hand sketching,\nconstrained datasets, static procedures, and generic models. Our evaluation\nmeasures showed that Stable Diffusion surpasses CLIP and DreamBooth + LORA in\nterms of producing high-quality, diversified images. Specifically, Stable\nDiffusion had the lowest Fr\\'echet Inception Distance (FID) scores (0.099 for\nsingle center, 0.064 for multi-center, and 0.067 for combined), indicating\nhigher image quality. Furthermore, it had the highest average Inception Score\n(2.327 across all datasets), indicating exceptional diversity and quality. This\nadvances the field of AI-powered medical diagnosis. Future research will\nconcentrate on model refining, dataset augmentation, and ethical considerations\nfor efficiently implementing these advances into clinical practice",
      "tldr_zh": "这篇论文通过 MEDVQA-GI 挑战探讨了 AI 驱动的医疗图像合成，旨在从文本描述生成动态、高保真图像，以提升诊断能力。研究引入了一种新方法，整合 fine-tuned Stable Diffusion、DreamBooth 和 Low-Rank Adaptation (LoRA)，针对图像合成 (IS) 和最优提示生成 (OPG) 子任务，解决了传统方法的局限性，如静态过程和泛化模型问题。实验结果显示，Stable Diffusion 在 Fréchet Inception Distance (FID) 分数（最低为 0.064）和 Inception Score（最高为 2.327）上优于 CLIP 和 DreamBooth + LoRA，证明其在图像质量和多样性方面表现出色。该进展为 AI 辅助医疗诊断奠定基础，并建议未来聚焦模型优化、数据集增强和伦理考虑。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20667v1",
      "published_date": "2025-02-28 02:49:45 UTC",
      "updated_date": "2025-02-28 02:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:30:32.926500"
    },
    {
      "arxiv_id": "2502.20657v1",
      "title": "Automatic database description generation for Text-to-SQL",
      "title_zh": "针对 Text-to-SQL 的自动数据库描述生成",
      "authors": [
        "Yingqi Gao",
        "Zhiling Luo"
      ],
      "abstract": "In the context of the Text-to-SQL task, table and column descriptions are\ncrucial for bridging the gap between natural language and database schema. This\nreport proposes a method for automatically generating effective database\ndescriptions when explicit descriptions are unavailable. The proposed method\nemploys a dual-process approach: a coarse-to-fine process, followed by a\nfine-to-coarse process. The coarse-to-fine approach leverages the inherent\nknowledge of LLM to guide the understanding process from databases to tables\nand finally to columns. This approach provides a holistic understanding of the\ndatabase structure and ensures contextual alignment. Conversely, the\nfine-to-coarse approach starts at the column level, offering a more accurate\nand nuanced understanding when stepping back to the table level. Experimental\nresults on the Bird benchmark indicate that using descriptions generated by the\nproposed improves SQL generation accuracy by 0.93\\% compared to not using\ndescriptions, and achieves 37\\% of human-level performance. The source code is\npublicly available at https://github.com/XGenerationLab/XiYan-DBDescGen.",
      "tldr_zh": "本研究针对 Text-to-SQL 任务，提出了一种自动生成数据库描述的方法，以弥补自然语言与数据库模式之间的差距。该方法采用双重过程：coarse-to-fine 策略从数据库到表再到列，利用 LLM 的内在知识实现整体结构理解；fine-to-coarse 策略则从列级开始，提供更精确的细粒度洞察并回溯到表级。在 Bird benchmark 的实验中，使用生成的描述比不使用描述提高了 0.93% 的 SQL 生成准确率，并达到了人类性能的 37%。这项工作为缺乏显式描述的数据库提供有效解决方案，并开源代码以供进一步应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "I.2; H.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20657v1",
      "published_date": "2025-02-28 02:23:06 UTC",
      "updated_date": "2025-02-28 02:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:30:42.281990"
    },
    {
      "arxiv_id": "2502.20653v1",
      "title": "Dataset Distillation with Neural Characteristic Function: A Minmax Perspective",
      "title_zh": "数据集蒸馏使用神经特征函数：最小最大视角",
      "authors": [
        "Shaobo Wang",
        "Yicun Yang",
        "Zhiyuan Liu",
        "Chenghao Sun",
        "Xuming Hu",
        "Conghui He",
        "Linfeng Zhang"
      ],
      "abstract": "Dataset distillation has emerged as a powerful approach for reducing data\nrequirements in deep learning. Among various methods, distribution\nmatching-based approaches stand out for their balance of computational\nefficiency and strong performance. However, existing distance metrics used in\ndistribution matching often fail to accurately capture distributional\ndifferences, leading to unreliable measures of discrepancy. In this paper, we\nreformulate dataset distillation as a minmax optimization problem and introduce\nNeural Characteristic Function Discrepancy (NCFD), a comprehensive and\ntheoretically grounded metric for measuring distributional differences. NCFD\nleverages the Characteristic Function (CF) to encapsulate full distributional\ninformation, employing a neural network to optimize the sampling strategy for\nthe CF's frequency arguments, thereby maximizing the discrepancy to enhance\ndistance estimation. Simultaneously, we minimize the difference between real\nand synthetic data under this optimized NCFD measure. Our approach, termed\nNeural Characteristic Function Matching (\\mymethod{}), inherently aligns the\nphase and amplitude of neural features in the complex plane for both real and\nsynthetic data, achieving a balance between realism and diversity in synthetic\nsamples. Experiments demonstrate that our method achieves significant\nperformance gains over state-of-the-art methods on both low- and\nhigh-resolution datasets. Notably, we achieve a 20.5\\% accuracy boost on\nImageSquawk. Our method also reduces GPU memory usage by over 300$\\times$ and\nachieves 20$\\times$ faster processing speeds compared to state-of-the-art\nmethods. To the best of our knowledge, this is the first work to achieve\nlossless compression of CIFAR-100 on a single NVIDIA 2080 Ti GPU using only 2.3\nGB of memory.",
      "tldr_zh": "本文将数据集蒸馏重新表述为minmax优化问题，引入Neural Characteristic Function Discrepancy (NCFD)作为一种基于Characteristic Function (CF)的分布差异度量，通过神经网络优化频率参数采样策略来提升距离估计准确性。提出Neural Characteristic Function Matching方法，该方法在复平面上对齐真实数据和合成数据的神经特征相位与幅度，实现合成样本的真实性和多样性平衡。实验结果显示，该方法在低分辨率和高分辨率数据集上比现有方法提升显著，包括ImageSquawk上20.5%的准确率提升、300倍的GPU内存减少以及20倍的处理速度加快，并首次在单GPU上实现CIFAR-100的无损压缩。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025, 11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.20653v1",
      "published_date": "2025-02-28 02:14:55 UTC",
      "updated_date": "2025-02-28 02:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:30:58.277468"
    },
    {
      "arxiv_id": "2502.20647v1",
      "title": "Consistency Evaluation of News Article Summaries Generated by Large (and Small) Language Models",
      "title_zh": "大型（和小型）语言模型生成新闻文章摘要的一致性评估",
      "authors": [
        "Colleen Gilhuly",
        "Haleh Shahzad"
      ],
      "abstract": "Text summarizing is a critical Natural Language Processing (NLP) task with\napplications ranging from information retrieval to content generation. Large\nLanguage Models (LLMs) have shown remarkable promise in generating fluent\nabstractive summaries but they can produce hallucinated details not grounded in\nthe source text. Regardless of the method of generating a summary, high quality\nautomated evaluations remain an open area of investigation. This paper embarks\non an exploration of text summarization with a diverse set of techniques,\nincluding TextRank, BART, Mistral-7B-Instruct, and OpenAI GPT-3.5-Turbo. The\ngenerated summaries are evaluated using traditional metrics such as the\nRecall-Oriented Understudy for Gisting Evaluation (ROUGE) Score and\nBidirectional Encoder Representations from Transformers (BERT) Score, as well\nas LLM-powered evaluation methods that directly assess a generated summary's\nconsistency with the source text. We introduce a meta evaluation score which\ndirectly assesses the performance of the LLM evaluation system (prompt +\nmodel). We find that that all summarization models produce consistent summaries\nwhen tested on the XL-Sum dataset, exceeding the consistency of the reference\nsummaries.",
      "tldr_zh": "本研究评估了不同规模语言模型生成的新闻文章摘要的一致性，包括TextRank、BART、Mistral-7B-Instruct和OpenAI GPT-3.5-Turbo等技术。研究采用传统指标如ROUGE Score和BERT Score，以及基于LLM的评估方法，并引入meta evaluation score来评估LLM评估系统的性能。在XL-Sum数据集上测试发现，所有总结模型生成的摘要一致性均优于参考摘要，证明了这些模型在减少幻觉细节方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.20647v1",
      "published_date": "2025-02-28 01:58:17 UTC",
      "updated_date": "2025-02-28 01:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:31:08.874136"
    },
    {
      "arxiv_id": "2502.20639v1",
      "title": "FedConv: A Learning-on-Model Paradigm for Heterogeneous Federated Clients",
      "title_zh": "FedConv：一种针对异构联邦客户端的模型上学习范式",
      "authors": [
        "Leming Shen",
        "Qiang Yang",
        "Kaiyan Cui",
        "Yuanqing Zheng",
        "Xiao-Yong Wei",
        "Jianwei Liu",
        "Jinsong Han"
      ],
      "abstract": "Federated Learning (FL) facilitates collaborative training of a shared global\nmodel without exposing clients' private data. In practical FL systems, clients\n(e.g., edge servers, smartphones, and wearables) typically have disparate\nsystem resources. Conventional FL, however, adopts a one-size-fits-all\nsolution, where a homogeneous large global model is transmitted to and trained\non each client, resulting in an overwhelming workload for less capable clients\nand starvation for other clients. To address this issue, we propose FedConv, a\nclient-friendly FL framework, which minimizes the computation and memory burden\non resource-constrained clients by providing heterogeneous customized\nsub-models. FedConv features a novel learning-on-model paradigm that learns the\nparameters of the heterogeneous sub-models via convolutional compression.\nUnlike traditional compression methods, the compressed models in FedConv can be\ndirectly trained on clients without decompression. To aggregate the\nheterogeneous sub-models, we propose transposed convolutional dilation to\nconvert them back to large models with a unified size while retaining\npersonalized information from clients. The compression and dilation processes,\ntransparent to clients, are optimized on the server leveraging a small public\ndataset. Extensive experiments on six datasets demonstrate that FedConv\noutperforms state-of-the-art FL systems in terms of model accuracy (by more\nthan 35% on average), computation and communication overhead (with 33% and 25%\nreduction, respectively).",
      "tldr_zh": "该论文提出 FedConv，一种针对异构联邦学习 (Federated Learning, FL) 客户端的学习-on-model 范式，通过卷积压缩生成异构自定义子模型，以最小化资源受限客户端的计算和内存负担。这些子模型可直接在客户端训练，而无需解压；服务器端则使用转置卷积膨胀 (transposed convolutional dilation) 来聚合异构子模型，转换为统一大小的模型，同时保留个性化信息。实验结果显示，FedConv 在六个数据集上比现有系统平均提高了 35% 的模型准确率，并分别减少了 33% 的计算开销和 25% 的通信开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20639v1",
      "published_date": "2025-02-28 01:39:53 UTC",
      "updated_date": "2025-02-28 01:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:31:21.462425"
    },
    {
      "arxiv_id": "2502.20634v1",
      "title": "A Compact Model for Large-Scale Time Series Forecasting",
      "title_zh": "一种用于大规模时间序列预测的紧凑模型",
      "authors": [
        "Chin-Chia Michael Yeh",
        "Xiran Fan",
        "Zhimeng Jiang",
        "Yujie Fan",
        "Huiyuan Chen",
        "Uday Singh Saini",
        "Vivian Lai",
        "Xin Dai",
        "Junpeng Wang",
        "Zhongfang Zhuang",
        "Liang Wang",
        "Yan Zheng"
      ],
      "abstract": "Spatio-temporal data, which commonly arise in real-world applications such as\ntraffic monitoring, financial transactions, and ride-share demands, represent a\nspecial category of multivariate time series. They exhibit two distinct\ncharacteristics: high dimensionality and commensurability across spatial\nlocations. These attributes call for computationally efficient modeling\napproaches and facilitate the use of univariate forecasting models in a\nchannel-independent fashion. SparseTSF, a recently introduced competitive\nunivariate forecasting model, harnesses periodicity to achieve compactness by\nconcentrating on cross-period dynamics, thereby extending the Pareto frontier\nwith respect to model size and predictive performance. Nonetheless, it\nunderperforms on spatio-temporal data due to an inadequate capture of\nintra-period temporal dependencies. To address this shortcoming, we propose\nUltraSTF, which integrates a cross-period forecasting module with an\nultra-compact shape bank component. Our model effectively detects recurring\npatterns in time series through the attention mechanism of the shape bank\ncomponent, thereby strengthening its ability to learn intra-period dynamics.\nUltraSTF achieves state-of-the-art performance on the LargeST benchmark while\nemploying fewer than 0.2% of the parameters required by the second-best\napproaches, thus further extending the Pareto frontier of existing methods.",
      "tldr_zh": "本研究针对高维度且空间位置可比的时空数据(spatio-temporal data)，提出了一种紧凑模型UltraSTF，以解决现有单变量(univariate)预测模型如SparseTSF在捕捉周期内时序依赖(intra-period temporal dependencies)方面的不足。UltraSTF整合了跨周期预测模块和一个超紧凑的形状库(shape bank)组件，利用注意力机制检测时间序列中的重复模式，从而增强了对动态的捕捉能力。该模型在LargeST基准上实现了最先进性能，同时仅使用第二好方法的不到0.2%参数，进一步扩展了Pareto前沿。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20634v1",
      "published_date": "2025-02-28 01:35:51 UTC",
      "updated_date": "2025-02-28 01:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:31:33.796623"
    },
    {
      "arxiv_id": "2503.01897v1",
      "title": "Continual Learning-Aided Super-Resolution Scheme for Channel Reconstruction and Generalization in OFDM Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiao Chen",
        "Nan Ma",
        "Wenkai Liu",
        "Xiaodong Xu",
        "Ping Zhang"
      ],
      "abstract": "Channel reconstruction and generalization capability are of equal importance\nfor developing channel estimation schemes within deep learning (DL) framework.\nIn this paper, we exploit a novel DL-based scheme for efficient OFDM channel\nestimation where the neural networks for channel reconstruction and\ngeneralization are respectively designed. For the former, we propose a\ndual-attention-aided super-resolution neural network (DA-SRNN) to map the\nchannels at pilot positions to the whole time-frequency channels. Specifically,\nthe channel-spatial attention mechanism is first introduced to sequentially\ninfer attention maps along two separate dimensions corresponding to two types\nof underlying channel correlations, and then the lightweight SR module is\ndeveloped for efficient channel reconstruction. For the latter, we introduce\ncontinual learning (CL)-aided training strategies to make the neural network\nadapt to different channel distributions. Specifically, the elastic weight\nconsolidation (EWC) is introduced as the regularization term in regard to loss\nfunction of channel reconstruction, which can constrain the direction and space\nof updating the important weights of neural networks among different channel\ndistributions. Meanwhile, the corresponding training process is provided in\ndetail. By evaluating under 3rd Generation Partnership Project (3GPP) channel\nmodels, numerical results verify the superiority of the proposed channel\nestimation scheme with significantly improved channel reconstruction and\ngeneralization performance over counterparts.",
      "tldr_zh": "本文提出了一种基于深度学习(DL)的信道估计方案，用于OFDM系统中的信道重建和泛化，提升了网络的效率和适应性。方案包括双注意力辅助超分辨率神经网络(DA-SRNN)，通过通道空间注意力机制和轻量级超分辨率(SR)模块，将导频位置信道映射到整个时频信道；同时，引入持续学习(CL)策略和弹性权重巩固(EWC)作为正则化项，帮助神经网络适应不同信道分布。在3GPP信道模型下的实验验证显示，该方案在信道重建和泛化性能上显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01897v1",
      "published_date": "2025-02-28 01:31:13 UTC",
      "updated_date": "2025-02-28 01:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:31:45.999803"
    },
    {
      "arxiv_id": "2502.20632v1",
      "title": "Lattice Protein Folding with Variational Annealing",
      "title_zh": "翻译失败",
      "authors": [
        "Shoummo Ahsan Khandoker",
        "Estelle M. Inack",
        "Mohamed Hibat-Allah"
      ],
      "abstract": "Understanding the principles of protein folding is a cornerstone of\ncomputational biology, with implications for drug design, bioengineering, and\nthe understanding of fundamental biological processes. Lattice protein folding\nmodels offer a simplified yet powerful framework for studying the complexities\nof protein folding, enabling the exploration of energetically optimal folds\nunder constrained conditions. However, finding these optimal folds is a\ncomputationally challenging combinatorial optimization problem. In this work,\nwe introduce a novel upper-bound training scheme that employs masking to\nidentify the lowest-energy folds in two-dimensional Hydrophobic-Polar (HP)\nlattice protein folding. By leveraging Dilated Recurrent Neural Networks (RNNs)\nintegrated with an annealing process driven by temperature-like fluctuations,\nour method accurately predicts optimal folds for benchmark systems of up to 60\nbeads. Our approach also effectively masks invalid folds from being sampled\nwithout compromising the autoregressive sampling properties of RNNs. This\nscheme is generalizable to three spatial dimensions and can be extended to\nlattice protein models with larger alphabets. Our findings emphasize the\npotential of advanced machine learning techniques in tackling complex protein\nfolding problems and a broader class of constrained combinatorial optimization\nchallenges.",
      "tldr_zh": "本研究针对蛋白质折叠的计算挑战，提出了一种基于变分退火（Variational Annealing）的上界训练方案，用于二维 Hydrophobic-Polar (HP) lattice protein folding 模型。该方法利用 Dilated Recurrent Neural Networks (RNNs) 结合温度似波动退火过程，能够准确预测多达 60 个珠子的最优能量折叠，同时通过掩码机制有效过滤无效样本而不影响 RNNs 的自回归采样特性。实验结果显示，该方案可推广到三维空间和更大字母表的模型，并展示了高级机器学习技术在解决蛋白质折叠及类似约束组合优化问题中的潜力。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "Github respository will be provided soon",
      "pdf_url": "http://arxiv.org/pdf/2502.20632v1",
      "published_date": "2025-02-28 01:30:15 UTC",
      "updated_date": "2025-02-28 01:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:31:57.088366"
    },
    {
      "arxiv_id": "2502.20630v1",
      "title": "Subtask-Aware Visual Reward Learning from Segmented Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Changyeon Kim",
        "Minho Heo",
        "Doohyun Lee",
        "Jinwoo Shin",
        "Honglak Lee",
        "Joseph J. Lim",
        "Kimin Lee"
      ],
      "abstract": "Reinforcement Learning (RL) agents have demonstrated their potential across\nvarious robotic tasks. However, they still heavily rely on human-engineered\nreward functions, requiring extensive trial-and-error and access to target\nbehavior information, often unavailable in real-world settings. This paper\nintroduces REDS: REward learning from Demonstration with Segmentations, a novel\nreward learning framework that leverages action-free videos with minimal\nsupervision. Specifically, REDS employs video demonstrations segmented into\nsubtasks from diverse sources and treats these segments as ground-truth\nrewards. We train a dense reward function conditioned on video segments and\ntheir corresponding subtasks to ensure alignment with ground-truth reward\nsignals by minimizing the Equivalent-Policy Invariant Comparison distance.\nAdditionally, we employ contrastive learning objectives to align video\nrepresentations with subtasks, ensuring precise subtask inference during online\ninteractions. Our experiments show that REDS significantly outperforms baseline\nmethods on complex robotic manipulation tasks in Meta-World and more\nchallenging real-world tasks, such as furniture assembly in FurnitureBench,\nwith minimal human intervention. Moreover, REDS facilitates generalization to\nunseen tasks and robot embodiments, highlighting its potential for scalable\ndeployment in diverse environments.",
      "tldr_zh": "本文提出 REDS 框架，用于从分割的演示视频中学习奖励函数，解决 Reinforcement Learning (RL) 代理对人工奖励函数依赖的问题。REDS 将视频段视为 ground-truth 奖励，通过最小化 Equivalent-Policy Invariant Comparison 距离训练密集奖励函数，并采用对比学习目标来对齐视频表示和子任务，确保在线交互中的精确推断。实验显示，REDS 在 Meta-World 的复杂机器人操作任务和 FurnitureBench 的家具组装任务中显著优于基线方法，支持泛化到未见过任务和机器人形态，并以最少人工干预实现可扩展部署。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project webpage: https://changyeon.site/reds/",
      "pdf_url": "http://arxiv.org/pdf/2502.20630v1",
      "published_date": "2025-02-28 01:25:37 UTC",
      "updated_date": "2025-02-28 01:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:32:09.922213"
    },
    {
      "arxiv_id": "2503.05788v2",
      "title": "Emergent Abilities in Large Language Models: A Survey",
      "title_zh": "大型语言模型中的涌现能力：一项综述",
      "authors": [
        "Leonardo Berti",
        "Flavio Giorgi",
        "Gjergji Kasneci"
      ],
      "abstract": "Large Language Models (LLMs) are leading a new technological revolution as\none of the most promising research streams toward artificial general\nintelligence. The scaling of these models, accomplished by increasing the\nnumber of parameters and the magnitude of the training datasets, has been\nlinked to various so-called emergent abilities that were previously unobserved.\nThese emergent abilities, ranging from advanced reasoning and in-context\nlearning to coding and problem-solving, have sparked an intense scientific\ndebate: Are they truly emergent, or do they simply depend on external factors,\nsuch as training dynamics, the type of problems, or the chosen metric? What\nunderlying mechanism causes them? Despite their transformative potential,\nemergent abilities remain poorly understood, leading to misconceptions about\ntheir definition, nature, predictability, and implications. In this work, we\nshed light on emergent abilities by conducting a comprehensive review of the\nphenomenon, addressing both its scientific underpinnings and real-world\nconsequences. We first critically analyze existing definitions, exposing\ninconsistencies in conceptualizing emergent abilities. We then explore the\nconditions under which these abilities appear, evaluating the role of scaling\nlaws, task complexity, pre-training loss, quantization, and prompting\nstrategies. Our review extends beyond traditional LLMs and includes Large\nReasoning Models (LRMs), which leverage reinforcement learning and\ninference-time search to amplify reasoning and self-reflection. However,\nemergence is not inherently positive. As AI systems gain autonomous reasoning\ncapabilities, they also develop harmful behaviors, including deception,\nmanipulation, and reward hacking. We highlight growing concerns about safety\nand governance, emphasizing the need for better evaluation frameworks and\nregulatory oversight.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)中的新兴能力，包括高级推理、在上下文学习和问题解决等，这些能力通过模型规模化（如增加参数和数据集）而出现。作者批判性地审视了这些能力的定义、成因和条件，分析了缩放定律、任务复杂性、预训练损失以及提示策略等因素的作用，并扩展到大型推理模型(LRMs)，如利用强化学习和推理时间搜索。论文强调新兴能力可能带来负面影响，如AI的欺骗和操纵行为，并呼吁加强安全评估框架和监管措施。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05788v2",
      "published_date": "2025-02-28 01:20:01 UTC",
      "updated_date": "2025-03-14 13:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:32:21.777492"
    },
    {
      "arxiv_id": "2502.20616v1",
      "title": "PersonaBench: Evaluating AI Models on Understanding Personal Information through Accessing (Synthetic) Private User Data",
      "title_zh": "PersonaBench：通过访问（合成）私人用户数据评估 AI 模型理解个人信息的能力",
      "authors": [
        "Juntao Tan",
        "Liangwei Yang",
        "Zuxin Liu",
        "Zhiwei Liu",
        "Rithesh Murthy",
        "Tulika Manoj Awalgaonkar",
        "Jianguo Zhang",
        "Weiran Yao",
        "Ming Zhu",
        "Shirley Kokane",
        "Silvio Savarese",
        "Huan Wang",
        "Caiming Xiong",
        "Shelby Heinecke"
      ],
      "abstract": "Personalization is critical in AI assistants, particularly in the context of\nprivate AI models that work with individual users. A key scenario in this\ndomain involves enabling AI models to access and interpret a user's private\ndata (e.g., conversation history, user-AI interactions, app usage) to\nunderstand personal details such as biographical information, preferences, and\nsocial connections. However, due to the sensitive nature of such data, there\nare no publicly available datasets that allow us to assess an AI model's\nability to understand users through direct access to personal information.\n  To address this gap, we introduce a synthetic data generation pipeline that\ncreates diverse, realistic user profiles and private documents simulating human\nactivities. Leveraging this synthetic data, we present PersonaBench, a\nbenchmark designed to evaluate AI models' performance in understanding personal\ninformation derived from simulated private user data.\n  We evaluate Retrieval-Augmented Generation (RAG) pipelines using questions\ndirectly related to a user's personal information, supported by the relevant\nprivate documents provided to the models. Our results reveal that current\nretrieval-augmented AI models struggle to answer private questions by\nextracting personal information from user documents, highlighting the need for\nimproved methodologies to enhance personalization capabilities in AI.",
      "tldr_zh": "该论文介绍了PersonaBench基准，用于评估AI模型通过访问合成私人数据来理解用户个人信息的性能。研究者开发了一个合成数据生成管道，创建多样化的用户配置文件和模拟私人文档（如对话历史和偏好），以填补公开数据集的缺失。利用该基准，他们评估了Retrieval-Augmented Generation (RAG)管道在回答与用户个人信息相关的问题时的表现，结果显示当前模型在从私人文档中提取信息方面存在显著困难。最终，该研究强调了改进AI个性化能力的必要性，以更好地处理敏感数据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20616v1",
      "published_date": "2025-02-28 00:43:35 UTC",
      "updated_date": "2025-02-28 00:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:32:34.857995"
    },
    {
      "arxiv_id": "2502.20613v1",
      "title": "Continuous Adversarial Text Representation Learning for Affective Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Seungah Son",
        "Andrez Saurez",
        "Dongsoo Har"
      ],
      "abstract": "While pre-trained language models excel at semantic understanding, they often\nstruggle to capture nuanced affective information critical for affective\nrecognition tasks. To address these limitations, we propose a novel framework\nfor enhancing emotion-aware embeddings in transformer-based models. Our\napproach introduces a continuous valence-arousal labeling system to guide\ncontrastive learning, which captures subtle and multi-dimensional emotional\nnuances more effectively. Furthermore, we employ a dynamic token perturbation\nmechanism, using gradient-based saliency to focus on sentiment-relevant tokens,\nimproving model sensitivity to emotional cues. The experimental results\ndemonstrate that the proposed framework outperforms existing methods, achieving\nup to 15.5% improvement in the emotion classification benchmark, highlighting\nthe importance of employing continuous labels. This improvement demonstrates\nthat the proposed framework is effective in affective representation learning\nand enables precise and contextually relevant emotional understanding.",
      "tldr_zh": "本研究针对预训练语言模型在捕捉细微情感信息方面的不足，提出了一种增强 transformer-based models 情感感知嵌入的框架。\n该框架采用连续的 valence-arousal 标签系统指导 contrastive learning，以更好地捕捉多维情感细微差别，并引入动态 token perturbation 机制，通过基于梯度的显著性聚焦情感相关 token，提高模型对情感线索的敏感性。\n实验结果显示，该框架在情感分类基准上比现有方法提升高达15.5%，突显了使用连续标签的重要性。\n总体而言，这证明了框架在 affective representation learning 中的有效性，支持更精确和上下文相关的情感理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 figures, The 7th International Conference on Artificial\n  Intelligence in Information and Communication (ICAIIC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.20613v1",
      "published_date": "2025-02-28 00:29:09 UTC",
      "updated_date": "2025-02-28 00:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:32:47.551365"
    },
    {
      "arxiv_id": "2502.20609v1",
      "title": "Leveraging Large Language Models for Building Interpretable Rule-Based Data-to-Text Systems",
      "title_zh": "利用大语言模型构建可解释的基于规则的数据到文本系统",
      "authors": [
        "Jędrzej Warczyński",
        "Mateusz Lango",
        "Ondrej Dusek"
      ],
      "abstract": "We introduce a simple approach that uses a large language model (LLM) to\nautomatically implement a fully interpretable rule-based data-to-text system in\npure Python. Experimental evaluation on the WebNLG dataset showed that such a\nconstructed system produces text of better quality (according to the BLEU and\nBLEURT metrics) than the same LLM prompted to directly produce outputs, and\nproduces fewer hallucinations than a BART language model fine-tuned on the same\ndata. Furthermore, at runtime, the approach generates text in a fraction of the\nprocessing time required by neural approaches, using only a single CPU",
      "tldr_zh": "该研究提出了一种简单方法，利用大型语言模型 (LLM) 自动构建一个完全可解释的基于规则的数据到文本系统，使用纯 Python 实现。该系统在 WebNLG 数据集上的实验显示，其生成的文本质量（如 BLEU 和 BLEURT 指标）优于直接提示 LLM 或在相同数据上微调的 BART 模型，并且产生了更少的幻觉。相比神经网络方法，该方法在运行时处理速度更快，仅需一个 CPU，从而提高了效率和可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20609v1",
      "published_date": "2025-02-28 00:23:55 UTC",
      "updated_date": "2025-02-28 00:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:32:58.078484"
    },
    {
      "arxiv_id": "2502.20604v1",
      "title": "Exploring the Impact of Temperature Scaling in Softmax for Classification and Adversarial Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Xuan",
        "Bokai Yang",
        "Xingyu Li"
      ],
      "abstract": "The softmax function is a fundamental component in deep learning. This study\ndelves into the often-overlooked parameter within the softmax function, known\nas \"temperature,\" providing novel insights into the practical and theoretical\naspects of temperature scaling for image classification. Our empirical studies,\nadopting convolutional neural networks and transformers on multiple benchmark\ndatasets, reveal that moderate temperatures generally introduce better overall\nperformance. Through extensive experiments and rigorous theoretical analysis,\nwe explore the role of temperature scaling in model training and unveil that\ntemperature not only influences learning step size but also shapes the model's\noptimization direction. Moreover, for the first time, we discover a surprising\nbenefit of elevated temperatures: enhanced model robustness against common\ncorruption, natural perturbation, and non-targeted adversarial attacks like\nProjected Gradient Descent. We extend our discoveries to adversarial training,\ndemonstrating that, compared to the standard softmax function with the default\ntemperature value, higher temperatures have the potential to enhance\nadversarial training. The insights of this work open new avenues for improving\nmodel performance and security in deep learning applications.",
      "tldr_zh": "本研究探讨了softmax函数中temperature scaling参数对图像分类和对抗鲁棒性的影响，通过实证实验（采用CNN和Transformer在多个基准数据集上）和理论分析，发现中等温度能提升整体模型性能，并影响学习步长和优化方向。研究首次揭示，较高温度可增强模型对常见腐败、自然扰动以及非目标对抗攻击（如Projected Gradient Descent）的鲁棒性。在对抗训练中，较高温度相比默认值能显著改善训练效果。该工作为深度学习应用的性能和安全性优化开辟了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20604v1",
      "published_date": "2025-02-28 00:07:45 UTC",
      "updated_date": "2025-02-28 00:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:33:09.809990"
    },
    {
      "arxiv_id": "2502.20601v2",
      "title": "NutriGen: Personalized Meal Plan Generator Leveraging Large Language Models to Enhance Dietary and Nutritional Adherence",
      "title_zh": "NutriGen：利用大语言模型",
      "authors": [
        "Saman Khamesian",
        "Asiful Arefeen",
        "Stephanie M. Carpenter",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Maintaining a balanced diet is essential for overall health, yet many\nindividuals struggle with meal planning due to nutritional complexity, time\nconstraints, and lack of dietary knowledge. Personalized food recommendations\ncan help address these challenges by tailoring meal plans to individual\npreferences, habits, and dietary restrictions. However, existing dietary\nrecommendation systems often lack adaptability, fail to consider real-world\nconstraints such as food ingredient availability, and require extensive user\ninput, making them impractical for sustainable and scalable daily use. To\naddress these limitations, we introduce NutriGen, a framework based on large\nlanguage models (LLM) designed to generate personalized meal plans that align\nwith user-defined dietary preferences and constraints. By building a\npersonalized nutrition database and leveraging prompt engineering, our approach\nenables LLMs to incorporate reliable nutritional references like the USDA\nnutrition database while maintaining flexibility and ease-of-use. We\ndemonstrate that LLMs have strong potential in generating accurate and\nuser-friendly food recommendations, addressing key limitations in existing\ndietary recommendation systems by providing structured, practical, and scalable\nmeal plans. Our evaluation shows that Llama 3.1 8B and GPT-3.5 Turbo achieve\nthe lowest percentage errors of 1.55\\% and 3.68\\%, respectively, producing meal\nplans that closely align with user-defined caloric targets while minimizing\ndeviation and improving precision. Additionally, we compared the performance of\nDeepSeek V3 against several established models to evaluate its potential in\npersonalized nutrition planning.",
      "tldr_zh": "该研究引入了NutriGen框架，利用Large Language Models (LLM)生成个性化的膳食计划，以解决人们在营养复杂性、时间限制和知识不足方面的挑战。NutriGen通过构建个性化营养数据库、prompt engineering和整合可靠参考如USDA nutrition database，确保膳食计划适应用户偏好、习惯和限制，同时考虑实际食材可用性。实验结果显示，Llama 3.1 8B和GPT-3.5 Turbo的错误率最低，分别为1.55%和3.68%，生成的计划与用户热量目标高度一致，并与现有系统相比更实用和可扩展。研究还比较了DeepSeek V3与其他模型的性能，证明LLM在膳食推荐中的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20601v2",
      "published_date": "2025-02-28 00:05:49 UTC",
      "updated_date": "2025-04-28 05:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T20:33:22.372937"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 150,
  "processed_papers_count": 150,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T20:33:44.144331"
}