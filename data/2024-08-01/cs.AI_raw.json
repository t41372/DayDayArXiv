[
  {
    "arxiv_id": "2408.00946v1",
    "title": "Generalisation of Total Uncertainty in AI: A Theoretical Study",
    "authors": [
      "Keivan Shariatmadar"
    ],
    "abstract": "AI has been dealing with uncertainty to have highly accurate results. This\nbecomes even worse with reasonably small data sets or a variation in the data\nsets. This has far-reaching effects on decision-making, forecasting and\nlearning mechanisms. This study seeks to unpack the nature of uncertainty that\nexists within AI by drawing ideas from established works, the latest\ndevelopments and practical applications and provide a novel total uncertainty\ndefinition in AI.\n  From inception theories up to current methodologies, this paper provides an\nintegrated view of dealing with better total uncertainty as well as\ncomplexities of uncertainty in AI that help us understand its meaning and value\nacross different domains.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.PR",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.00946v1",
    "published_date": "2024-08-01 22:55:40 UTC",
    "updated_date": "2024-08-01 22:55:40 UTC"
  },
  {
    "arxiv_id": "2408.00938v2",
    "title": "CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression",
    "authors": [
      "Caiwen Jiang",
      "Xiaodan Xing",
      "Zaixin Ou",
      "Mianxin Liu",
      "Walsh Simon",
      "Guang Yang",
      "Dinggang Shen"
    ],
    "abstract": "The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly\ncorrelates with higher patient mortality rates. Early detection of IPF\nprogression is critical for initiating timely treatment, which can effectively\nslow down the advancement of the disease. However, the current clinical\ncriteria define disease progression requiring two CT scans with a one-year\ninterval, presenting a dilemma: a disease progression is identified only after\nthe disease has already progressed. To this end, in this paper, we develop a\nnovel diffusion model to accurately predict the progression of IPF by\ngenerating patient's follow-up CT scan from the initial CT scan. Specifically,\nfrom the clinical prior knowledge, we tailor improvements to the traditional\ndiffusion model and propose a Clinically-Informed Residual Diffusion model,\ncalled CIResDiff. The key innovations of CIResDiff include 1) performing the\ntarget region pre-registration to align the lung regions of two CT scans at\ndifferent time points for reducing the generation difficulty, 2) adopting the\nresidual diffusion instead of traditional diffusion to enable the model focus\nmore on differences (i.e., lesions) between the two CT scans rather than the\nlargely identical anatomical content, and 3) designing the clinically-informed\nprocess based on CLIP technology to integrate lung function information which\nis highly relevant to diagnosis into the reverse process for assisting\ngeneration. Extensive experiments on clinical data demonstrate that our\napproach can outperform state-of-the-art methods and effectively predict the\nprogression of IPF.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00938v2",
    "published_date": "2024-08-01 22:01:42 UTC",
    "updated_date": "2024-08-05 09:32:30 UTC"
  },
  {
    "arxiv_id": "2408.00930v1",
    "title": "Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research",
    "authors": [
      "Tian Lan",
      "Huan Wang",
      "Caiming Xiong",
      "Silvio Savarese"
    ],
    "abstract": "We introduce WarpSci, a domain agnostic framework designed to overcome\ncrucial system bottlenecks encountered in the application of reinforcement\nlearning to intricate environments with vast datasets featuring\nhigh-dimensional observation or action spaces. Notably, our framework\neliminates the need for data transfer between the CPU and GPU, enabling the\nconcurrent execution of thousands of simulations on a single or multiple GPUs.\nThis high data throughput architecture proves particularly advantageous for\ndata-driven scientific research, where intricate environment models are\ncommonly essential.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00930v1",
    "published_date": "2024-08-01 21:38:09 UTC",
    "updated_date": "2024-08-01 21:38:09 UTC"
  },
  {
    "arxiv_id": "2408.00925v1",
    "title": "WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes",
    "authors": [
      "Victor Valbuena"
    ],
    "abstract": "The cross-prompt injection attack (XPIA) is an effective technique that can\nbe used for data exfiltration, and that has seen increasing use. In this\nattack, the attacker injects a malicious instruction into third party data\nwhich an LLM is likely to consume when assisting a user, who is the victim.\nXPIA is often used as a means for data exfiltration, and the estimated cost of\nthe average data breach for a business is nearly $4.5 million, which includes\nbreaches such as compromised enterprise credentials. With the rise of\ngradient-based attacks such as the GCG suffix attack, the odds of an XPIA\noccurring which uses a GCG suffix are worryingly high. As part of my work in\nMicrosoft's AI Red Team, I demonstrated a viable attack model using a GCG\nsuffix paired with an injection in a simulated XPIA scenario. The results\nindicate that the presence of a GCG suffix can increase the odds of successful\ndata exfiltration by nearly 20%, with some caveats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 8 figures. Conducted as part of employment at Microsoft\n  Corporation",
    "pdf_url": "http://arxiv.org/pdf/2408.00925v1",
    "published_date": "2024-08-01 21:28:27 UTC",
    "updated_date": "2024-08-01 21:28:27 UTC"
  },
  {
    "arxiv_id": "2408.00923v1",
    "title": "Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit Quantization",
    "authors": [
      "Róisín Luo",
      "Alexandru Drimbarean",
      "James McDermott",
      "Colm O'Riordan"
    ],
    "abstract": "This paper explores a novel paradigm in low-bit (i.e. 4-bits or lower)\nquantization, differing from existing state-of-the-art methods, by framing\noptimal quantization as an architecture search problem within convolutional\nneural networks (ConvNets). Our framework, dubbed \\textbf{CoRa} (Optimal\nQuantization Residual \\textbf{Co}nvolutional Operator Low-\\textbf{Ra}nk\nAdaptation), is motivated by two key aspects. Firstly, quantization residual\nknowledge, i.e. the lost information between floating-point weights and\nquantized weights, has long been neglected by the research community.\nReclaiming the critical residual knowledge, with an infinitesimal extra\nparameter cost, can reverse performance degradation without training. Secondly,\nstate-of-the-art quantization frameworks search for optimal quantized weights\nto address the performance degradation. Yet, the vast search spaces in weight\noptimization pose a challenge for the efficient optimization in large models.\nFor example, state-of-the-art BRECQ necessitates $2 \\times 10^4$ iterations to\nquantize models. Fundamentally differing from existing methods, \\textbf{CoRa}\nsearches for the optimal architectures of low-rank adapters, reclaiming\ncritical quantization residual knowledge, within the search spaces smaller\ncompared to the weight spaces, by many orders of magnitude. The low-rank\nadapters approximate the quantization residual weights, discarded in previous\nmethods. We evaluate our approach over multiple pre-trained ConvNets on\nImageNet. \\textbf{CoRa} achieves comparable performance against both\nstate-of-the-art quantization-aware training and post-training quantization\nbaselines, in $4$-bit and $3$-bit quantization, by using less than $250$\niterations on a small calibration set with $1600$ images. Thus, \\textbf{CoRa}\nestablishes a new state-of-the-art in terms of the optimization efficiency in\nlow-bit quantization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by The 35th British Machine Vision Conference (BMVC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.00923v1",
    "published_date": "2024-08-01 21:27:31 UTC",
    "updated_date": "2024-08-01 21:27:31 UTC"
  },
  {
    "arxiv_id": "2408.00914v1",
    "title": "Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection",
    "authors": [
      "Steven Fincke",
      "Adrien Bibal",
      "Elizabeth Boschee"
    ],
    "abstract": "Large Language Models (LLMs) such as GPT-4 have shown enough promise in the\nfew-shot learning context to suggest use in the generation of \"silver\" data and\nrefinement of new ontologies through iterative application and review. Such\nworkflows become more effective with reliable confidence estimation.\nUnfortunately, confidence estimation is a documented weakness of models such as\nGPT-4, and established methods to compensate require significant additional\ncomplexity and computation. The present effort explores methods for effective\nconfidence estimation with GPT-4 with few-shot learning for event detection in\nthe BETTER ontology as a vehicle. The key innovation is expanding the prompt\nand task presented to GPT-4 to provide License to speculate when unsure and\nOpportunity to quantify and explain its uncertainty (L&O). This approach\nimproves accuracy and provides usable confidence measures (0.759 AUC) with no\nadditional machinery.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00914v1",
    "published_date": "2024-08-01 21:08:07 UTC",
    "updated_date": "2024-08-01 21:08:07 UTC"
  },
  {
    "arxiv_id": "2408.00906v1",
    "title": "Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations",
    "authors": [
      "Christopher Neves",
      "Yong Zeng",
      "Yiming Xiao"
    ],
    "abstract": "Parkinson's disease (PD) is a debilitating neurodegenerative disease that has\nsevere impacts on an individual's quality of life. Compared with structural and\nfunctional MRI-based biomarkers for the disease, electroencephalography (EEG)\ncan provide more accessible alternatives for clinical insights. While deep\nlearning (DL) techniques have provided excellent outcomes, many techniques fail\nto model spatial information and dynamic brain connectivity, and face\nchallenges in robust feature learning, limited data sizes, and poor\nexplainability. To address these issues, we proposed a novel graph neural\nnetwork (GNN) technique for explainable PD detection using resting state EEG.\nSpecifically, we employ structured global convolutions with contrastive\nlearning to better model complex features with limited data, a novel multi-head\ngraph structure learner to capture the non-Euclidean structure of EEG data, and\na head-wise gradient-weighted graph attention explainer to offer neural\nconnectivity insights. We developed and evaluated our method using the UC San\nDiego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy\nin subject-wise leave-one-out cross-validation while generating intuitive\nexplanations for the learnt graph topology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at MLCN 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00906v1",
    "published_date": "2024-08-01 20:54:33 UTC",
    "updated_date": "2024-08-01 20:54:33 UTC"
  },
  {
    "arxiv_id": "2408.00900v2",
    "title": "Expressive MIDI-format Piano Performance Generation",
    "authors": [
      "Jingwei Liu"
    ],
    "abstract": "This work presents a generative neural network that's able to generate\nexpressive piano performance in MIDI format. The musical expressivity is\nreflected by vivid micro-timing, rich polyphonic texture, varied dynamics, and\nthe sustain pedal effects. This model is innovative from many aspects of data\nprocessing to neural network design. We claim that this symbolic music\ngeneration model overcame the common critics of symbolic music and is able to\ngenerate expressive music flows as good as, if not better than generations with\nraw audio. One drawback is that, due to the limited time for submission, the\nmodel is not fine-tuned and sufficiently trained, thus the generation may sound\nincoherent and random at certain points. Despite that, this model shows its\npowerful generative ability to generate expressive piano pieces.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "4 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00900v2",
    "published_date": "2024-08-01 20:36:37 UTC",
    "updated_date": "2024-12-13 23:35:16 UTC"
  },
  {
    "arxiv_id": "2408.03345v1",
    "title": "Artifical intelligence and inherent mathematical difficulty",
    "authors": [
      "Walter Dean",
      "Alberto Naibo"
    ],
    "abstract": "This paper explores the relationship of artificial intelligence to the task\nof resolving open questions in mathematics. We first present an updated version\nof a traditional argument that limitative results from computability and\ncomplexity theory show that proof discovery is an inherently difficult problem.\nWe then illustrate how several recent applications of artificial\nintelligence-inspired methods -- respectively involving automated theorem\nproving, SAT-solvers, and large language models -- do indeed raise novel\nquestions about the nature of mathematical proof. We also argue that the\nresults obtained by such techniques do not tell against our basic argument.\nThis is so because they are embodiments of brute force search and are thus\ncapable of deciding only statements of low logical complexity.",
    "categories": [
      "math.HO",
      "cs.AI",
      "cs.CC",
      "math.LO",
      "03B35, 68V05, 68V15, 68T01",
      "F.2.2; F.4.0; I.2.0; I.2.3; K.2"
    ],
    "primary_category": "math.HO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.03345v1",
    "published_date": "2024-08-01 20:08:31 UTC",
    "updated_date": "2024-08-01 20:08:31 UTC"
  },
  {
    "arxiv_id": "2408.07225v1",
    "title": "Longitudinal Evaluation of Child Face Recognition and the Impact of Underlying Age",
    "authors": [
      "Surendra Singh",
      "Keivan Bahmani",
      "Stephanie Schuckers"
    ],
    "abstract": "The need for reliable identification of children in various emerging\napplications has sparked interest in leveraging child face recognition\ntechnology. This study introduces a longitudinal approach to enrollment and\nverification accuracy for child face recognition, focusing on the YFA database\ncollected by Clarkson University CITeR research group over an 8 year period, at\n6 month intervals.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07225v1",
    "published_date": "2024-08-01 19:40:55 UTC",
    "updated_date": "2024-08-01 19:40:55 UTC"
  },
  {
    "arxiv_id": "2408.00876v2",
    "title": "On the Relationship Between Monotone and Squared Probabilistic Circuits",
    "authors": [
      "Benjie Wang",
      "Guy Van den Broeck"
    ],
    "abstract": "Probabilistic circuits are a unifying representation of functions as\ncomputation graphs of weighted sums and products. Their primary application is\nin probabilistic modeling, where circuits with non-negative weights (monotone\ncircuits) can be used to represent and learn density/mass functions, with\ntractable marginal inference. Recently, it was proposed to instead represent\ndensities as the square of the circuit function (squared circuits); this allows\nthe use of negative weights while retaining tractability, and can be\nexponentially more expressive efficient than monotone circuits. Unfortunately,\nwe show the reverse also holds, meaning that monotone circuits and squared\ncircuits are incomparable in general. This raises the question of whether we\ncan reconcile, and indeed improve upon the two modeling approaches. We answer\nin the positive by proposing Inception PCs, a novel type of circuit that\nnaturally encompasses both monotone circuits and squared circuits as special\ncases, and employs complex parameters. Empirically, we validate that Inception\nPCs can outperform both monotone and squared circuits on a range of tabular and\nimage datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.00876v2",
    "published_date": "2024-08-01 18:56:08 UTC",
    "updated_date": "2025-02-24 23:53:15 UTC"
  },
  {
    "arxiv_id": "2408.00872v2",
    "title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability",
    "authors": [
      "Jiasheng Zhang",
      "Rex Ying",
      "Jie Shao"
    ],
    "abstract": "Temporal knowledge graphs (TKGs) are valuable resources for capturing\nevolving relationships among entities, yet they are often plagued by noise,\nnecessitating robust anomaly detection mechanisms. Existing dynamic graph\nanomaly detection approaches struggle to capture the rich semantics introduced\nby node and edge categories within TKGs, while TKG embedding methods lack\ninterpretability, undermining the credibility of anomaly detection. Moreover,\nthese methods falter in adapting to pattern changes and semantic drifts\nresulting from knowledge updates. To tackle these challenges, we introduce\nAnoT, an efficient TKG summarization method tailored for interpretable online\nanomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule\ngraph, enabling flexible inference of complex patterns in TKGs. When new\nknowledge emerges, AnoT maps it onto a node in the rule graph and traverses the\nrule graph recursively to derive the anomaly score of the knowledge. The\ntraversal yields reachable nodes that furnish interpretable evidence for the\nvalidity or the anomalous of the new knowledge. Overall, AnoT embodies a\ndetector-updater-monitor architecture, encompassing a detector for offline TKG\nsummarization and online scoring, an updater for real-time rule graph updates\nbased on emerging knowledge, and a monitor for estimating the approximation\nerror of the rule graph. Experimental results on four real-world datasets\ndemonstrate that AnoT surpasses existing methods significantly in terms of\naccuracy and interoperability. All of the raw datasets and the implementation\nof AnoT are provided in https://github.com/zjs123/ANoT.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 10 figures. Accepted by SIGMOD 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.00872v2",
    "published_date": "2024-08-01 18:46:05 UTC",
    "updated_date": "2024-09-02 17:41:24 UTC"
  },
  {
    "arxiv_id": "2408.00863v1",
    "title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation",
    "authors": [
      "Juzheng Zhang",
      "Yatao Bian",
      "Yongqiang Chen",
      "Quanming Yao"
    ],
    "abstract": "The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00863v1",
    "published_date": "2024-08-01 18:31:31 UTC",
    "updated_date": "2024-08-01 18:31:31 UTC"
  },
  {
    "arxiv_id": "2408.00860v3",
    "title": "UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization",
    "authors": [
      "Ziwen Guo",
      "Zi Fang",
      "Zhuang Fu"
    ],
    "abstract": "Three-dimensional ultrasound imaging is a critical technology widely used in\nmedical diagnostics. However, traditional 3D ultrasound imaging methods have\nlimitations such as fixed resolution, low storage efficiency, and insufficient\ncontextual connectivity, leading to poor performance in handling complex\nartifacts and reflection characteristics. Recently, techniques based on NeRF\n(Neural Radiance Fields) have made significant progress in view synthesis and\n3D reconstruction, but there remains a research gap in high-quality ultrasound\nimaging. To address these issues, we propose a new model, UlRe-NeRF, which\ncombines implicit neural networks and explicit ultrasound volume rendering into\nan ultrasound neural rendering architecture. This model incorporates reflection\ndirection parameterization and harmonic encoding, using a directional MLP\nmodule to generate view-dependent high-frequency reflection intensity\nestimates, and a spatial MLP module to produce the medium's physical property\nparameters. These parameters are used in the volume rendering process to\naccurately reproduce the propagation and reflection behavior of ultrasound\nwaves in the medium. Experimental results demonstrate that the UlRe-NeRF model\nsignificantly enhances the realism and accuracy of high-fidelity ultrasound\nimage reconstruction, especially in handling complex medium structures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00860v3",
    "published_date": "2024-08-01 18:22:29 UTC",
    "updated_date": "2024-09-13 13:40:31 UTC"
  },
  {
    "arxiv_id": "2408.00859v2",
    "title": "GLoCIM: Global-view Long Chain Interest Modeling for news recommendation",
    "authors": [
      "Zhen Yang",
      "Wenhui Wang",
      "Tao Qi",
      "Peng Zhang",
      "Tianyun Zhang",
      "Ru Zhang",
      "Jianyi Liu",
      "Yongfeng Huang"
    ],
    "abstract": "Accurately recommending candidate news articles to users has always been the\ncore challenge of news recommendation system. News recommendations often\nrequire modeling of user interest to match candidate news. Recent efforts have\nprimarily focused on extracting local subgraph information in a global click\ngraph constructed by the clicked news sequence of all users. Howerer, the\ncomputational complexity of extracting global click graph information has\nhindered the ability to utilize far-reaching linkage which is hidden between\ntwo distant nodes in global click graph collaboratively among similar users. To\novercome the problem above, we propose a Global-view Long Chain Interests\nModeling for news recommendation (GLoCIM), which combines neighbor interest\nwith long chain interest distilled from a global click graph, leveraging the\ncollaboration among similar users to enhance news recommendation. We therefore\ndesign a long chain selection algorithm and long chain interest encoder to\nobtain global-view long chain interest from the global click graph. We design a\ngated network to integrate long chain interest with neighbor interest to\nachieve the collaborative interest among similar users. Subsequently we\naggregate it with local news category-enhanced representation to generate final\nuser representation. Then candidate news representation can be formed to match\nuser representation to achieve news recommendation. Experimental results on\nreal-world datasets validate the effectiveness of our method to improve the\nperformance of news recommendation.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00859v2",
    "published_date": "2024-08-01 18:17:25 UTC",
    "updated_date": "2024-09-24 16:54:35 UTC"
  },
  {
    "arxiv_id": "2408.00838v2",
    "title": "Calibrating Bayesian Generative Machine Learning for Bayesiamplification",
    "authors": [
      "Sebastian Bieringer",
      "Sascha Diefenbacher",
      "Gregor Kasieczka",
      "Mathias Trabs"
    ],
    "abstract": "Recently, combinations of generative and Bayesian machine learning have been\nintroduced in particle physics for both fast detector simulation and inference\ntasks. These neural networks aim to quantify the uncertainty on the generated\ndistribution originating from limited training statistics. The interpretation\nof a distribution-wide uncertainty however remains ill-defined. We show a clear\nscheme for quantifying the calibration of Bayesian generative machine learning\nmodels. For a Continuous Normalizing Flow applied to a low-dimensional toy\nexample, we evaluate the calibration of Bayesian uncertainties from either a\nmean-field Gaussian weight posterior, or Monte Carlo sampling network weights,\nto gauge their behaviour on unsteady distribution edges. Well calibrated\nuncertainties can then be used to roughly estimate the number of uncorrelated\ntruth samples that are equivalent to the generated sample and clearly indicate\ndata amplification for smooth features of the distribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures, updated references, fixed typo",
    "pdf_url": "http://arxiv.org/pdf/2408.00838v2",
    "published_date": "2024-08-01 18:00:05 UTC",
    "updated_date": "2024-11-13 15:48:34 UTC"
  },
  {
    "arxiv_id": "2408.00765v2",
    "title": "MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities",
    "authors": [
      "Weihao Yu",
      "Zhengyuan Yang",
      "Lingfeng Ren",
      "Linjie Li",
      "Jianfeng Wang",
      "Kevin Lin",
      "Chung-Ching Lin",
      "Zicheng Liu",
      "Lijuan Wang",
      "Xinchao Wang"
    ],
    "abstract": "MM-Vet, with open-ended vision-language questions targeting at evaluating\nintegrated capabilities, has become one of the most popular benchmarks for\nlarge multimodal model evaluation. MM-Vet assesses six core vision-language\n(VL) capabilities: recognition, knowledge, spatial awareness, language\ngeneration, OCR, and math. However, its question format is restricted to single\nimage-text pairs, lacking the interleaved image and text sequences prevalent in\nreal-world scenarios. To address this limitation, we introduce MM-Vet v2, which\nincludes a new VL capability called \"image-text sequence understanding\",\nevaluating models' ability to process VL sequences. Furthermore, we maintain\nthe high quality of evaluation samples while further expanding the evaluation\nset size. Using MM-Vet v2 to benchmark large multimodal models, we found that\nClaude 3.5 Sonnet is the best model with a score of 71.8, slightly\noutperforming GPT-4o which scored 71.0. Among open-weight models,\nInternVL2-Llama3-76B leads with a score of 68.4. The code, data, and\nleaderboard are accessible at https://github.com/yuweihao/MM-Vet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Code, data and leaderboard: https://github.com/yuweihao/MM-Vet",
    "pdf_url": "http://arxiv.org/pdf/2408.00765v2",
    "published_date": "2024-08-01 17:59:54 UTC",
    "updated_date": "2024-12-01 06:08:00 UTC"
  },
  {
    "arxiv_id": "2408.00764v3",
    "title": "AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation",
    "authors": [
      "Mengkang Hu",
      "Pu Zhao",
      "Can Xu",
      "Qingfeng Sun",
      "Jianguang Lou",
      "Qingwei Lin",
      "Ping Luo",
      "Saravan Rajmohan"
    ],
    "abstract": "Large Language Model-based agents have garnered significant attention and are\nbecoming increasingly popular. Furthermore, planning ability is a crucial\ncomponent of an LLM-based agent, which generally entails achieving a desired\ngoal from an initial state. This paper investigates enhancing the planning\nabilities of LLMs through instruction tuning, referred to as agent training.\nRecent studies have demonstrated that utilizing expert-level trajectory for\ninstruction-tuning LLMs effectively enhances their planning capabilities.\nHowever, existing work primarily focuses on synthesizing trajectories from\nmanually designed planning tasks and environments. The labor-intensive nature\nof creating these environments and tasks impedes the generation of sufficiently\nvaried and extensive trajectories. To address this limitation, this paper\nexplores the automated synthesis of diverse environments and a gradual range of\nplanning tasks, from easy to difficult. We introduce a framework, AgentGen,\nthat leverages LLMs first to generate environments and subsequently generate\nplanning tasks conditioned on these environments. Specifically, to improve\nenvironmental diversity, we propose using an inspiration corpus composed of\nvarious domain-specific text segments as the context for synthesizing\nenvironments. Moreover, to increase the difficulty diversity of generated\nplanning tasks, we propose a bidirectional evolution method, Bi-Evol, that\nevolves planning tasks from easier and harder directions to synthesize a task\nset with a smoother difficulty curve. The evaluation results derived from\nAgentBoard show that AgentGen greatly improves LLMs' planning ability, e.g.,\nthe AgentGen instruction-tuned Llama-3.1-8B surpasses GPT-3.5 in overall\nperformance. Moreover, the AgentGen-tuned Llama-3.1-70B model achieves\nstate-of-the-art results in planning tasks. Project page:\nhttps://agent-gen.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by KDD 2025 (Research Track). Project page:\n  https://agent-gen.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2408.00764v3",
    "published_date": "2024-08-01 17:59:46 UTC",
    "updated_date": "2025-02-06 09:17:39 UTC"
  },
  {
    "arxiv_id": "2408.00761v4",
    "title": "Tamper-Resistant Safeguards for Open-Weight LLMs",
    "authors": [
      "Rishub Tamirisa",
      "Bhrugu Bharathi",
      "Long Phan",
      "Andy Zhou",
      "Alice Gatti",
      "Tarun Suresh",
      "Maxwell Lin",
      "Justin Wang",
      "Rowan Wang",
      "Ron Arel",
      "Andy Zou",
      "Dawn Song",
      "Bo Li",
      "Dan Hendrycks",
      "Mantas Mazeika"
    ],
    "abstract": "Rapid advances in the capabilities of large language models (LLMs) have\nraised widespread concerns regarding their potential for malicious use.\nOpen-weight LLMs present unique challenges, as existing safeguards lack\nrobustness to tampering attacks that modify model weights. For example, recent\nworks have demonstrated that refusal and unlearning safeguards can be trivially\nremoved with a few steps of fine-tuning. These vulnerabilities necessitate new\napproaches for enabling the safe release of open-weight LLMs. We develop a\nmethod, called TAR, for building tamper-resistant safeguards into open-weight\nLLMs such that adversaries cannot remove the safeguards even after hundreds of\nsteps of fine-tuning. In extensive evaluations and red teaming analyses, we\nfind that our method greatly improves tamper-resistance while preserving benign\ncapabilities. Our results demonstrate that progress on tamper-resistance is\npossible, opening up a promising new avenue to improve the safety and security\nof open-weight LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://www.tamper-resistant-safeguards.com",
    "pdf_url": "http://arxiv.org/pdf/2408.00761v4",
    "published_date": "2024-08-01 17:59:12 UTC",
    "updated_date": "2025-02-10 18:26:14 UTC"
  },
  {
    "arxiv_id": "2408.00760v2",
    "title": "Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention",
    "authors": [
      "Susung Hong"
    ],
    "abstract": "Conditional diffusion models have shown remarkable success in visual content\ngeneration, producing high-quality samples across various domains, largely due\nto classifier-free guidance (CFG). Recent attempts to extend guidance to\nunconditional models have relied on heuristic techniques, resulting in\nsuboptimal generation quality and unintended effects. In this work, we propose\nSmoothed Energy Guidance (SEG), a novel training- and condition-free approach\nthat leverages the energy-based perspective of the self-attention mechanism to\nenhance image generation. By defining the energy of self-attention, we\nintroduce a method to reduce the curvature of the energy landscape of attention\nand use the output as the unconditional prediction. Practically, we control the\ncurvature of the energy landscape by adjusting the Gaussian kernel parameter\nwhile keeping the guidance scale parameter fixed. Additionally, we present a\nquery blurring method that is equivalent to blurring the entire attention\nweights without incurring quadratic complexity in the number of tokens. In our\nexperiments, SEG achieves a Pareto improvement in both quality and the\nreduction of side effects. The code is available at\nhttps://github.com/SusungHong/SEG-SDXL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00760v2",
    "published_date": "2024-08-01 17:59:09 UTC",
    "updated_date": "2024-10-01 01:04:58 UTC"
  },
  {
    "arxiv_id": "2408.00756v3",
    "title": "Segment anything model 2: an application to 2D and 3D medical images",
    "authors": [
      "Haoyu Dong",
      "Hanxue Gu",
      "Yaqian Chen",
      "Jichen Yang",
      "Yuwen Chen",
      "Maciej A. Mazurowski"
    ],
    "abstract": "Segment Anything Model (SAM) has gained significant attention because of its\nability to segment various objects in images given a prompt. The recently\ndeveloped SAM 2 has extended this ability to video inputs. This opens an\nopportunity to apply SAM to 3D images, one of the fundamental tasks in the\nmedical imaging field. In this paper, we extensively evaluate SAM 2's ability\nto segment both 2D and 3D medical images by first collecting 21 medical imaging\ndatasets, including surgical videos, common 3D modalities such as computed\ntomography (CT), magnetic resonance imaging (MRI), and positron emission\ntomography (PET) as well as 2D modalities such as X-ray and ultrasound. Two\nevaluation settings of SAM 2 are considered: (1) multi-frame 3D segmentation,\nwhere prompts are provided to one or multiple slice(s) selected from the\nvolume, and (2) single-frame 2D segmentation, where prompts are provided to\neach slice. The former only applies to videos and 3D modalities, while the\nlatter applies to all datasets. Our results show that SAM 2 exhibits similar\nperformance as SAM under single-frame 2D segmentation, and has variable\nperformance under multi-frame 3D segmentation depending on the choices of\nslices to annotate, the direction of the propagation, the predictions utilized\nduring the propagation, etc. We believe our work enhances the understanding of\nSAM 2's behavior in the medical field and provides directions for future work\nin adapting SAM 2 to this domain. Our code is available at:\nhttps://github.com/mazurowski-lab/segment-anything2-medical-evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 13 figures. Codes are available at\n  https://github.com/mazurowski-lab/segment-anything2-medical-evaluation",
    "pdf_url": "http://arxiv.org/pdf/2408.00756v3",
    "published_date": "2024-08-01 17:57:25 UTC",
    "updated_date": "2024-08-22 16:38:20 UTC"
  },
  {
    "arxiv_id": "2408.00753v2",
    "title": "A deep learning-enabled smart garment for accurate and versatile sleep conditions monitoring in daily life",
    "authors": [
      "Chenyu Tang",
      "Wentian Yi",
      "Muzi Xu",
      "Yuxuan Jin",
      "Zibo Zhang",
      "Xuhang Chen",
      "Caizhi Liao",
      "Peter Smielewski",
      "Luigi G. Occhipinti"
    ],
    "abstract": "In wearable smart systems, continuous monitoring and accurate classification\nof different sleep-related conditions are critical for enhancing sleep quality\nand preventing sleep-related chronic conditions. However, the requirements for\ndevice-skin coupling quality in electrophysiological sleep monitoring systems\nhinder the comfort and reliability of night wearing. Here, we report a\nwashable, skin-compatible smart garment sleep monitoring system that captures\nlocal skin strain signals under weak device-skin coupling conditions without\npositioning or skin preparation requirements. A printed textile-based strain\nsensor array responds to strain from 0.1% to 10% with a gauge factor as high as\n100 and shows independence to extrinsic motion artefacts via strain-isolating\nprinted pattern design. Through reversible starching treatment, ink penetration\ndepth during direct printing on garments is controlled to achieve\nbatch-to-batch performance variation < 10%. Coupled with deep learning,\nexplainable artificial intelligence (XAI), and transfer learning data\nprocessing, the smart garment is capable of classifying six sleep states with\nan accuracy of 98.6%, maintaining excellent explainability (classification with\nlow bias) and generalization (95% accuracy on new users with few-shot learning\nless than 15 samples per class) in practical applications, paving the way for\nnext-generation daily sleep healthcare management.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "20 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.00753v2",
    "published_date": "2024-08-01 17:56:25 UTC",
    "updated_date": "2024-10-03 16:13:26 UTC"
  },
  {
    "arxiv_id": "2408.00751v1",
    "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence",
    "authors": [
      "Mingyang Liu",
      "Gabriele Farina",
      "Asuman Ozdaglar"
    ],
    "abstract": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating counterfactual values (as opposed to Q values),\nwhich are incompatible with policy gradient methodologies. In this paper, we\ninvestigate whether policy gradient can be safely used in two-player zero-sum\nimperfect-information extensive-form games (EFGs). We establish positive\nresults, showing for the first time that a policy gradient method leads to\nprovable best-iterate convergence to a regularized Nash equilibrium in\nself-play.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00751v1",
    "published_date": "2024-08-01 17:54:01 UTC",
    "updated_date": "2024-08-01 17:54:01 UTC"
  },
  {
    "arxiv_id": "2408.00749v1",
    "title": "Leaf Angle Estimation using Mask R-CNN and LETR Vision Transformer",
    "authors": [
      "Venkat Margapuri",
      "Prapti Thapaliya",
      "Trevor Rife"
    ],
    "abstract": "Modern day studies show a high degree of correlation between high yielding\ncrop varieties and plants with upright leaf angles. It is observed that plants\nwith upright leaf angles intercept more light than those without upright leaf\nangles, leading to a higher rate of photosynthesis. Plant scientists and\nbreeders benefit from tools that can directly measure plant parameters in the\nfield i.e. on-site phenotyping. The estimation of leaf angles by manual means\nin a field setting is tedious and cumbersome. We mitigate the tedium using a\ncombination of the Mask R-CNN instance segmentation neural network, and Line\nSegment Transformer (LETR), a vision transformer. The proposed Computer Vision\n(CV) pipeline is applied on two image datasets, Summer 2015-Ames ULA and Summer\n2015- Ames MLA, with a combined total of 1,827 plant images collected in the\nfield using FieldBook, an Android application aimed at on-site phenotyping. The\nleaf angles estimated by the proposed pipeline on the image datasets are\ncompared to two independent manual measurements using ImageJ, a Java-based\nimage processing program developed at the National Institutes of Health and the\nLaboratory for Optical and Computational Instrumentation. The results, when\ncompared for similarity using the Cosine Similarity measure, exhibit 0.98\nsimilarity scores on both independent measurements of Summer 2015-Ames ULA and\nSummer 2015-Ames MLA image datasets, demonstrating the feasibility of the\nproposed pipeline for on-site measurement of leaf angles.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00749v1",
    "published_date": "2024-08-01 17:52:10 UTC",
    "updated_date": "2024-08-01 17:52:10 UTC"
  },
  {
    "arxiv_id": "2408.00741v1",
    "title": "DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency",
    "authors": [
      "Jovan Stojkovic",
      "Chaojie Zhang",
      "Íñigo Goiri",
      "Josep Torrellas",
      "Esha Choukse"
    ],
    "abstract": "The rapid evolution and widespread adoption of generative large language\nmodels (LLMs) have made them a pivotal workload in various applications. Today,\nLLM inference clusters receive a large number of queries with strict Service\nLevel Objectives (SLOs). To achieve the desired performance, these models\nexecute on power-hungry GPUs causing the inference clusters to consume large\namount of energy and, consequently, result in excessive carbon emissions.\nFortunately, we find that there is a great opportunity to exploit the\nheterogeneity in inference compute properties and fluctuations in inference\nworkloads, to significantly improve energy-efficiency. However, such a diverse\nand dynamic environment creates a large search-space where different system\nconfigurations (e.g., number of instances, model parallelism, and GPU\nfrequency) translate into different energy-performance trade-offs. To address\nthese challenges, we propose DynamoLLM, the first energy-management framework\nfor LLM inference environments. DynamoLLM automatically and dynamically\nreconfigures the inference cluster to optimize for energy and cost of LLM\nserving under the service's performance SLOs. We show that at a service-level,\nDynamoLLM conserves 53% energy and 38% operational carbon emissions, and\nreduces 61% cost to the customer, while meeting the latency SLOs.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00741v1",
    "published_date": "2024-08-01 17:40:45 UTC",
    "updated_date": "2024-08-01 17:40:45 UTC"
  },
  {
    "arxiv_id": "2408.00727v3",
    "title": "Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions",
    "authors": [
      "Guangzhi Xiong",
      "Qiao Jin",
      "Xiao Wang",
      "Minjia Zhang",
      "Zhiyong Lu",
      "Aidong Zhang"
    ],
    "abstract": "The emergent abilities of large language models (LLMs) have demonstrated\ngreat potential in solving medical questions. They can possess considerable\nmedical knowledge, but may still hallucinate and are inflexible in the\nknowledge updates. While Retrieval-Augmented Generation (RAG) has been proposed\nto enhance the medical question-answering capabilities of LLMs with external\nknowledge bases, it may still fail in complex cases where multiple rounds of\ninformation-seeking are required. To address such an issue, we propose\niterative RAG for medicine (i-MedRAG), where LLMs can iteratively ask follow-up\nqueries based on previous information-seeking attempts. In each iteration of\ni-MedRAG, the follow-up queries will be answered by a conventional RAG system\nand they will be further used to guide the query generation in the next\niteration. Our experiments show the improved performance of various LLMs\nbrought by i-MedRAG compared with conventional RAG on complex questions from\nclinical vignettes in the United States Medical Licensing Examination (USMLE),\nas well as various knowledge tests in the Massive Multitask Language\nUnderstanding (MMLU) dataset. Notably, our zero-shot i-MedRAG outperforms all\nexisting prompt engineering and fine-tuning methods on GPT-3.5, achieving an\naccuracy of 69.68% on the MedQA dataset. In addition, we characterize the\nscaling properties of i-MedRAG with different iterations of follow-up queries\nand different numbers of queries per iteration. Our case studies show that\ni-MedRAG can flexibly ask follow-up queries to form reasoning chains, providing\nan in-depth analysis of medical questions. To the best of our knowledge, this\nis the first-of-its-kind study on incorporating follow-up queries into medical\nRAG. The implementation of i-MedRAG is available at\nhttps://github.com/Teddy-XiongGZ/MedRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to PSB 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.00727v3",
    "published_date": "2024-08-01 17:18:17 UTC",
    "updated_date": "2024-10-11 01:00:48 UTC"
  },
  {
    "arxiv_id": "2408.00818v1",
    "title": "Y Social: an LLM-powered Social Media Digital Twin",
    "authors": [
      "Giulio Rossetti",
      "Massimo Stella",
      "Rémy Cazabet",
      "Katherine Abramski",
      "Erica Cau",
      "Salvatore Citraro",
      "Andrea Failla",
      "Riccardo Improta",
      "Virginia Morini",
      "Valentina Pansanella"
    ],
    "abstract": "In this paper we introduce Y, a new-generation digital twin designed to\nreplicate an online social media platform. Digital twins are virtual replicas\nof physical systems that allow for advanced analyses and experimentation. In\nthe case of social media, a digital twin such as Y provides a powerful tool for\nresearchers to simulate and understand complex online interactions. {\\tt Y}\nleverages state-of-the-art Large Language Models (LLMs) to replicate\nsophisticated agent behaviors, enabling accurate simulations of user\ninteractions, content dissemination, and network dynamics. By integrating these\naspects, Y offers valuable insights into user engagement, information spread,\nand the impact of platform policies. Moreover, the integration of LLMs allows Y\nto generate nuanced textual content and predict user responses, facilitating\nthe study of emergent phenomena in online environments.\n  To better characterize the proposed digital twin, in this paper we describe\nthe rationale behind its implementation, provide examples of the analyses that\ncan be performed on the data it enables to be generated, and discuss its\nrelevance for multidisciplinary research.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00818v1",
    "published_date": "2024-08-01 17:16:21 UTC",
    "updated_date": "2024-08-01 17:16:21 UTC"
  },
  {
    "arxiv_id": "2408.00724v3",
    "title": "Inference Scaling Laws: An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models",
    "authors": [
      "Yangzhen Wu",
      "Zhiqing Sun",
      "Shanda Li",
      "Sean Welleck",
      "Yiming Yang"
    ],
    "abstract": "While the scaling laws of large language models (LLMs) training have been\nextensively studied, optimal inference configurations of LLMs remain\nunderexplored. We study inference scaling laws (aka test-time scaling laws) and\ncompute-optimal inference, focusing on the trade-offs between model sizes and\ngenerating additional tokens with different inference strategies. As a first\nstep towards understanding and designing compute-optimal inference methods, we\nstudied cost-performance trade-offs for inference strategies such as greedy\nsearch, majority voting, best-of-$n$, weighted voting, and two different tree\nsearch algorithms, using different model sizes and compute budgets. Our\nfindings suggest that scaling inference compute with inference strategies can\nbe more computationally efficient than scaling model parameters. Additionally,\nsmaller models combined with advanced inference algorithms offer Pareto-optimal\ntrade-offs in cost and performance. For example, the Llemma-7B model, when\npaired with our novel tree search algorithm, consistently outperforms the\nLlemma-34B model across all tested inference strategies on the MATH benchmark.\nWe hope these insights contribute to a deeper understanding of inference\nscaling laws (test-time scaling laws) for LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00724v3",
    "published_date": "2024-08-01 17:16:04 UTC",
    "updated_date": "2025-03-03 07:53:32 UTC"
  },
  {
    "arxiv_id": "2408.00722v2",
    "title": "Pathway to Secure and Trustworthy ZSM for LLMs: Attacks, Defense, and Opportunities",
    "authors": [
      "Sunder Ali Khowaja",
      "Parus Khuwaja",
      "Kapal Dev",
      "Hussam Al Hamadi",
      "Engin Zeydan"
    ],
    "abstract": "Recently, large language models (LLMs) have been gaining a lot of interest\ndue to their adaptability and extensibility in emerging applications, including\ncommunication networks. It is anticipated that ZSM networks will be able to\nsupport LLMs as a service, as they provide ultra reliable low-latency\ncommunications and closed loop massive connectivity. However, LLMs are\nvulnerable to data and model privacy issues that affect the trustworthiness of\nLLMs to be deployed for user-based services. In this paper, we explore the\nsecurity vulnerabilities associated with fine-tuning LLMs in ZSM networks, in\nparticular the membership inference attack. We define the characteristics of an\nattack network that can perform a membership inference attack if the attacker\nhas access to the fine-tuned model for the downstream task. We show that the\nmembership inference attacks are effective for any downstream task, which can\nlead to a personal data breach when using LLM as a service. The experimental\nresults show that the attack success rate of maximum 92% can be achieved on\nnamed entity recognition task. Based on the experimental analysis, we discuss\npossible defense mechanisms and present possible research directions to make\nthe LLMs more trustworthy in the context of ZSM networks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00722v2",
    "published_date": "2024-08-01 17:15:13 UTC",
    "updated_date": "2025-01-06 15:09:06 UTC"
  },
  {
    "arxiv_id": "2408.00714v2",
    "title": "SAM 2: Segment Anything in Images and Videos",
    "authors": [
      "Nikhila Ravi",
      "Valentin Gabeur",
      "Yuan-Ting Hu",
      "Ronghang Hu",
      "Chaitanya Ryali",
      "Tengyu Ma",
      "Haitham Khedr",
      "Roman Rädle",
      "Chloe Rolland",
      "Laura Gustafson",
      "Eric Mintun",
      "Junting Pan",
      "Kalyan Vasudev Alwala",
      "Nicolas Carion",
      "Chao-Yuan Wu",
      "Ross Girshick",
      "Piotr Dollár",
      "Christoph Feichtenhofer"
    ],
    "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards\nsolving promptable visual segmentation in images and videos. We build a data\nengine, which improves model and data via user interaction, to collect the\nlargest video segmentation dataset to date. Our model is a simple transformer\narchitecture with streaming memory for real-time video processing. SAM 2\ntrained on our data provides strong performance across a wide range of tasks.\nIn video segmentation, we observe better accuracy, using 3x fewer interactions\nthan prior approaches. In image segmentation, our model is more accurate and 6x\nfaster than the Segment Anything Model (SAM). We believe that our data, model,\nand insights will serve as a significant milestone for video segmentation and\nrelated perception tasks. We are releasing our main model, dataset, as well as\ncode for model training and our demo.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Website: https://ai.meta.com/sam2",
    "pdf_url": "http://arxiv.org/pdf/2408.00714v2",
    "published_date": "2024-08-01 17:00:08 UTC",
    "updated_date": "2024-10-28 16:37:57 UTC"
  },
  {
    "arxiv_id": "2408.00711v1",
    "title": "Investigating Brain Connectivity and Regional Statistics from EEG for early stage Parkinson's Classification",
    "authors": [
      "Amarpal Sahota",
      "Amber Roguski",
      "Matthew W Jones",
      "Zahraa S. Abdallah",
      "Raul Santos-Rodriguez"
    ],
    "abstract": "We evaluate the effectiveness of combining brain connectivity metrics with\nsignal statistics for early stage Parkinson's Disease (PD) classification using\nelectroencephalogram data (EEG). The data is from 5 arousal states - wakeful\nand four sleep stages (N1, N2, N3 and REM). Our pipeline uses an Ada Boost\nmodel for classification on a challenging early stage PD classification task\nwith with only 30 participants (11 PD , 19 Healthy Control). Evaluating 9 brain\nconnectivity metrics we find the best connectivity metric to be different for\neach arousal state with Phase Lag Index achieving the highest individual\nclassification accuracy of 86\\% on N1 data. Further to this our pipeline using\nregional signal statistics achieves an accuracy of 78\\%, using brain\nconnectivity only achieves an accuracy of 86\\% whereas combining the two\nachieves a best accuracy of 91\\%. This best performance is achieved on N1 data\nusing Phase Lag Index (PLI) combined with statistics derived from the frequency\ncharacteristics of the EEG signal. This model also achieves a recall of 80 \\%\nand precision of 96\\%. Furthermore we find that on data from each arousal\nstate, combining PLI with regional signal statistics improves classification\naccuracy versus using signal statistics or brain connectivity alone. Thus we\nconclude that combining brain connectivity statistics with regional EEG\nstatistics is optimal for classifier performance on early stage Parkinson's.\nAdditionally, we find outperformance of N1 EEG for classification of\nParkinson's and expect this could be due to disrupted N1 sleep in PD. This\nshould be explored in future work.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00711v1",
    "published_date": "2024-08-01 16:58:21 UTC",
    "updated_date": "2024-08-01 16:58:21 UTC"
  },
  {
    "arxiv_id": "2408.00706v1",
    "title": "Point-supervised Brain Tumor Segmentation with Box-prompted MedSAM",
    "authors": [
      "Xiaofeng Liu",
      "Jonghye Woo",
      "Chao Ma",
      "Jinsong Ouyang",
      "Georges El Fakhri"
    ],
    "abstract": "Delineating lesions and anatomical structure is important for image-guided\ninterventions. Point-supervised medical image segmentation (PSS) has great\npotential to alleviate costly expert delineation labeling. However, due to the\nlack of precise size and boundary guidance, the effectiveness of PSS often\nfalls short of expectations. Although recent vision foundational models, such\nas the medical segment anything model (MedSAM), have made significant\nadvancements in bounding-box-prompted segmentation, it is not straightforward\nto utilize point annotation, and is prone to semantic ambiguity. In this\npreliminary study, we introduce an iterative framework to facilitate\nsemantic-aware point-supervised MedSAM. Specifically, the semantic box-prompt\ngenerator (SBPG) module has the capacity to convert the point input into\npotential pseudo bounding box suggestions, which are explicitly refined by the\nprototype-based semantic similarity. This is then succeeded by a prompt-guided\nspatial refinement (PGSR) module that harnesses the exceptional\ngeneralizability of MedSAM to infer the segmentation mask, which also updates\nthe box proposal seed in SBPG. Performance can be progressively improved with\nadequate iterations. We conducted an evaluation on BraTS2018 for the\nsegmentation of whole brain tumors and demonstrated its superior performance\ncompared to traditional PSS methods and on par with box-supervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 IEEE Nuclear Science Symposium and Medical Imaging Conference",
    "pdf_url": "http://arxiv.org/pdf/2408.00706v1",
    "published_date": "2024-08-01 16:52:39 UTC",
    "updated_date": "2024-08-01 16:52:39 UTC"
  },
  {
    "arxiv_id": "2408.00703v1",
    "title": "Future of Artificial Intelligence in Agile Software Development",
    "authors": [
      "Mariyam Mahboob",
      "Mohammed Rayyan Uddin Ahmed",
      "Zoiba Zia",
      "Mariam Shakeel Ali",
      "Ayman Khaleel Ahmed"
    ],
    "abstract": "The advent of Artificial intelligence has promising advantages that can be\nutilized to transform the landscape of software project development. The\nSoftware process framework consists of activities that constantly require\nroutine human interaction, leading to the possibility of errors and\nuncertainties. AI can assist software development managers, software testers,\nand other team members by leveraging LLMs, GenAI models, and AI agents to\nperform routine tasks, risk analysis and prediction, strategy recommendations,\nand support decision making. AI has the potential to increase efficiency and\nreduce the risks encountered by the project management team while increasing\nthe project success rates. Additionally, it can also break down complex notions\nand development processes for stakeholders to make informed decisions. In this\npaper, we propose an approach in which AI tools and technologies can be\nutilized to bestow maximum assistance for agile software projects, which have\nbecome increasingly favored in the industry in recent years.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00703v1",
    "published_date": "2024-08-01 16:49:50 UTC",
    "updated_date": "2024-08-01 16:49:50 UTC"
  },
  {
    "arxiv_id": "2408.00695v1",
    "title": "Accelerating Full Waveform Inversion By Transfer Learning",
    "authors": [
      "Divya Shyam Singh",
      "Leon Herrmann",
      "Qing Sun",
      "Tim Bürchner",
      "Felix Dietrich",
      "Stefan Kollmannsberger"
    ],
    "abstract": "Full waveform inversion (FWI) is a powerful tool for reconstructing material\nfields based on sparsely measured data obtained by wave propagation. For\nspecific problems, discretizing the material field with a neural network (NN)\nimproves the robustness and reconstruction quality of the corresponding\noptimization problem. We call this method NN-based FWI. Starting from an\ninitial guess, the weights of the NN are iteratively updated to fit the\nsimulated wave signals to the sparsely measured data set. For gradient-based\noptimization, a suitable choice of the initial guess, i.e., a suitable NN\nweight initialization, is crucial for fast and robust convergence.\n  In this paper, we introduce a novel transfer learning approach to further\nimprove NN-based FWI. This approach leverages supervised pretraining to provide\na better NN weight initialization, leading to faster convergence of the\nsubsequent optimization problem. Moreover, the inversions yield physically more\nmeaningful local minima. The network is pretrained to predict the unknown\nmaterial field using the gradient information from the first iteration of\nconventional FWI. In our computational experiments on two-dimensional domains,\nthe training data set consists of reference simulations with arbitrarily\npositioned elliptical voids of different shapes and orientations. We compare\nthe performance of the proposed transfer learning NN-based FWI with three other\nmethods: conventional FWI, NN-based FWI without pretraining and conventional\nFWI with an initial guess predicted from the pretrained NN. Our results show\nthat transfer learning NN-based FWI outperforms the other methods in terms of\nconvergence speed and reconstruction quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00695v1",
    "published_date": "2024-08-01 16:39:06 UTC",
    "updated_date": "2024-08-01 16:39:06 UTC"
  },
  {
    "arxiv_id": "2408.00686v1",
    "title": "Can Developers Prompt? A Controlled Experiment for Code Documentation Generation",
    "authors": [
      "Hans-Alexander Kruse",
      "Tim Puhlfürß",
      "Walid Maalej"
    ],
    "abstract": "Large language models (LLMs) bear great potential for automating tedious\ndevelopment tasks such as creating and maintaining code documentation. However,\nit is unclear to what extent developers can effectively prompt LLMs to create\nconcise and useful documentation. We report on a controlled experiment with 20\nprofessionals and 30 computer science students tasked with code documentation\ngeneration for two Python functions. The experimental group freely entered\nad-hoc prompts in a ChatGPT-like extension of Visual Studio Code, while the\ncontrol group executed a predefined few-shot prompt. Our results reveal that\nprofessionals and students were unaware of or unable to apply prompt\nengineering techniques. Especially students perceived the documentation\nproduced from ad-hoc prompts as significantly less readable, less concise, and\nless helpful than documentation from prepared prompts. Some professionals\nproduced higher quality documentation by just including the keyword Docstring\nin their ad-hoc prompts. While students desired more support in formulating\nprompts, professionals appreciated the flexibility of ad-hoc prompting.\nParticipants in both groups rarely assessed the output as perfect. Instead,\nthey understood the tools as support to iteratively refine the documentation.\nFurther research is needed to understand which prompting skills and preferences\ndevelopers have and which support they need for certain tasks.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 40th IEEE International Conference on Software\n  Maintenance and Evolution (ICSME)",
    "pdf_url": "http://arxiv.org/pdf/2408.00686v1",
    "published_date": "2024-08-01 16:28:14 UTC",
    "updated_date": "2024-08-01 16:28:14 UTC"
  },
  {
    "arxiv_id": "2408.00682v1",
    "title": "Learning in Multi-Objective Public Goods Games with Non-Linear Utilities",
    "authors": [
      "Nicole Orzan",
      "Erman Acar",
      "Davide Grossi",
      "Patrick Mannion",
      "Roxana Rădulescu"
    ],
    "abstract": "Addressing the question of how to achieve optimal decision-making under risk\nand uncertainty is crucial for enhancing the capabilities of artificial agents\nthat collaborate with or support humans. In this work, we address this question\nin the context of Public Goods Games. We study learning in a novel\nmulti-objective version of the Public Goods Game where agents have different\nrisk preferences, by means of multi-objective reinforcement learning. We\nintroduce a parametric non-linear utility function to model risk preferences at\nthe level of individual agents, over the collective and individual reward\ncomponents of the game. We study the interplay between such preference\nmodelling and environmental uncertainty on the incentive alignment level in the\ngame. We demonstrate how different combinations of individual preferences and\nenvironmental uncertainties sustain the emergence of cooperative patterns in\nnon-cooperative environments (i.e., where competitive strategies are dominant),\nwhile others sustain competitive patterns in cooperative environments (i.e.,\nwhere cooperative strategies are dominant).",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "In press at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00682v1",
    "published_date": "2024-08-01 16:24:37 UTC",
    "updated_date": "2024-08-01 16:24:37 UTC"
  },
  {
    "arxiv_id": "2408.00655v5",
    "title": "SentenceVAE: Enable Next-sentence Prediction for Large Language Models with Faster Speed, Higher Accuracy and Longer Context",
    "authors": [
      "Hongjun An",
      "Yifan Chen",
      "Zhe Sun",
      "Xuelong Li"
    ],
    "abstract": "Current large language models (LLMs) primarily utilize next-token prediction\nmethod for inference, which significantly impedes their processing speed. In\nthis paper, we introduce a novel inference methodology termed next-sentence\nprediction, aiming at enhancing the inference efficiency of LLMs. We present\nSentence Variational Autoencoder (SentenceVAE), which includes a Sentence\nEncoder to compress multiple tokens in a sentence into a single token, and a\nSentence Decoder to reconstruct it. By integrating SentenceVAE into the input\nand output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a\nsentence-by-sentence inference method. In addition, the SentenceVAE module of\nSLLMs can maintain the integrity of the original semantic content by segmenting\nthe context into sentences, thereby improving accuracy while boosting inference\nspeed. Moreover, compared to previous LLMs, SLLMs process fewer tokens over\nequivalent context length, significantly reducing memory demands for\nself-attention computation and facilitating the handling of longer context.\nExtensive experiments on Wanjuan dataset have revealed that the proposed method\ncan accelerate inference speed by 204~365%, reduce perplexity (PPL) to 46~75%\nof its original metric, and decrease memory overhead by 86~91% for the\nequivalent context length, compared to previous token-by-token methods.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "update the article",
    "pdf_url": "http://arxiv.org/pdf/2408.00655v5",
    "published_date": "2024-08-01 15:45:19 UTC",
    "updated_date": "2024-08-14 07:34:44 UTC"
  },
  {
    "arxiv_id": "2408.00640v2",
    "title": "AMAES: Augmented Masked Autoencoder Pretraining on Public Brain MRI Data for 3D-Native Segmentation",
    "authors": [
      "Asbjørn Munk",
      "Jakob Ambsdorf",
      "Sebastian Llambias",
      "Mads Nielsen"
    ],
    "abstract": "This study investigates the impact of self-supervised pretraining of 3D\nsemantic segmentation models on a large-scale, domain-specific dataset. We\nintroduce BRAINS-45K, a dataset of 44,756 brain MRI volumes from public\nsources, the largest public dataset available, and revisit a number of design\nchoices for pretraining modern segmentation architectures by simplifying and\noptimizing state-of-the-art methods, and combining them with a novel\naugmentation strategy. The resulting AMAES framework is based on\nmasked-image-modeling and intensity-based augmentation reversal and balances\nmemory usage, runtime, and finetuning performance. Using the popular U-Net and\nthe recent MedNeXt architecture as backbones, we evaluate the effect of\npretraining on three challenging downstream tasks, covering single-sequence,\nlow-resource settings, and out-of-domain generalization. The results highlight\nthat pretraining on the proposed dataset with AMAES significantly improves\nsegmentation performance in the majority of evaluated cases, and that it is\nbeneficial to pretrain the model with augmentations, despite pretraing on a\nlarge-scale dataset. Code and model checkpoints for reproducing results, as\nwell as the BRAINS-45K dataset are available at\n\\url{https://github.com/asbjrnmunk/amaes}.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at ADSMI @ MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00640v2",
    "published_date": "2024-08-01 15:27:48 UTC",
    "updated_date": "2024-08-15 08:56:45 UTC"
  },
  {
    "arxiv_id": "2408.07822v1",
    "title": "Exploration of LLMs, EEG, and behavioral data to measure and support attention and sleep",
    "authors": [
      "Akane Sano",
      "Judith Amores",
      "Mary Czerwinski"
    ],
    "abstract": "We explore the application of large language models (LLMs), pre-trained\nmodels with massive textual data for detecting and improving these altered\nstates. We investigate the use of LLMs to estimate attention states, sleep\nstages, and sleep quality and generate sleep improvement suggestions and\nadaptive guided imagery scripts based on electroencephalogram (EEG) and\nphysical activity data (e.g. waveforms, power spectrogram images, numerical\nfeatures). Our results show that LLMs can estimate sleep quality based on human\ntextual behavioral features and provide personalized sleep improvement\nsuggestions and guided imagery scripts; however detecting attention, sleep\nstages, and sleep quality based on EEG and activity data requires further\ntraining data and domain-specific knowledge.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07822v1",
    "published_date": "2024-08-01 15:17:54 UTC",
    "updated_date": "2024-08-01 15:17:54 UTC"
  },
  {
    "arxiv_id": "2408.00633v1",
    "title": "DisTrack: a new Tool for Semi-automatic Misinformation Tracking in Online Social Networks",
    "authors": [
      "Guillermo Villar-Rodríguez",
      "Álvaro Huertas-García",
      "Alejandro Martín",
      "Javier Huertas-Tato",
      "David Camacho"
    ],
    "abstract": "Introduction: This article introduces DisTrack, a methodology and a tool\ndeveloped for tracking and analyzing misinformation within Online Social\nNetworks (OSNs). DisTrack is designed to combat the spread of misinformation\nthrough a combination of Natural Language Processing (NLP) Social Network\nAnalysis (SNA) and graph visualization. The primary goal is to detect\nmisinformation, track its propagation, identify its sources, and assess the\ninfluence of various actors within the network.\n  Methods: DisTrack's architecture incorporates a variety of methodologies\nincluding keyword search, semantic similarity assessments, and graph generation\ntechniques. These methods collectively facilitate the monitoring of\nmisinformation, the categorization of content based on alignment with known\nfalse claims, and the visualization of dissemination cascades through detailed\ngraphs. The tool is tailored to capture and analyze the dynamic nature of\nmisinformation spread in digital environments.\n  Results: The effectiveness of DisTrack is demonstrated through three case\nstudies focused on different themes: discredit/hate speech, anti-vaccine\nmisinformation, and false narratives about the Russia-Ukraine conflict. These\nstudies show DisTrack's capabilities in distinguishing posts that propagate\nfalsehoods from those that counteract them, and tracing the evolution of\nmisinformation from its inception.\n  Conclusions: The research confirms that DisTrack is a valuable tool in the\nfield of misinformation analysis. It effectively distinguishes between\ndifferent types of misinformation and traces their development over time. By\nproviding a comprehensive approach to understanding and combating\nmisinformation in digital spaces, DisTrack proves to be an essential asset for\nresearchers and practitioners working to mitigate the impact of false\ninformation in online social environments.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00633v1",
    "published_date": "2024-08-01 15:17:33 UTC",
    "updated_date": "2024-08-01 15:17:33 UTC"
  },
  {
    "arxiv_id": "2408.00613v1",
    "title": "Unlocking Fair Use in the Generative AI Supply Chain: A Systematized Literature Review",
    "authors": [
      "Amruta Mahuli",
      "Asia Biega"
    ],
    "abstract": "Through a systematization of generative AI (GenAI) stakeholder goals and\nexpectations, this work seeks to uncover what value different stakeholders see\nin their contributions to the GenAI supply line. This valuation enables us to\nunderstand whether fair use advocated by GenAI companies to train model\nprogresses the copyright law objective of promoting science and arts. While\nassessing the validity and efficacy of the fair use argument, we uncover\nresearch gaps and potential avenues for future works for researchers and\npolicymakers to address.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00613v1",
    "published_date": "2024-08-01 14:53:11 UTC",
    "updated_date": "2024-08-01 14:53:11 UTC"
  },
  {
    "arxiv_id": "2408.00584v1",
    "title": "Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses",
    "authors": [
      "Gabriele Sarti",
      "Tommaso Caselli",
      "Malvina Nissim",
      "Arianna Bisazza"
    ],
    "abstract": "Rebuses are puzzles requiring constrained multi-step reasoning to identify a\nhidden phrase from a set of images and letters. In this work, we introduce a\nlarge collection of verbalized rebuses for the Italian language and use it to\nassess the rebus-solving capabilities of state-of-the-art large language\nmodels. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly\non this task, ad-hoc fine-tuning seems to improve models' performance. However,\nwe find that performance gains from training are largely motivated by\nmemorization. Our results suggest that rebus solving remains a challenging test\nbed to evaluate large language models' linguistic proficiency and sequential\ninstruction-following skills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code: https://github.com/gsarti/verbalized-rebus. Artifacts:\n  https://huggingface.co/collections/gsarti/verbalized-rebus-clic-it-2024-66ab8f11cb04e68bdf4fb028",
    "pdf_url": "http://arxiv.org/pdf/2408.00584v1",
    "published_date": "2024-08-01 14:14:15 UTC",
    "updated_date": "2024-08-01 14:14:15 UTC"
  },
  {
    "arxiv_id": "2408.00555v1",
    "title": "Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation",
    "authors": [
      "Xiaoye Qu",
      "Qiyuan Chen",
      "Wei Wei",
      "Jishuo Sun",
      "Jianfeng Dong"
    ],
    "abstract": "Despite the remarkable ability of large vision-language models (LVLMs) in\nimage comprehension, these models frequently generate plausible yet factually\nincorrect responses, a phenomenon known as hallucination.Recently, in large\nlanguage models (LLMs), augmenting LLMs by retrieving information from external\nknowledge resources has been proven as a promising solution to mitigate\nhallucinations.However, the retrieval augmentation in LVLM significantly lags\nbehind the widespread applications of LVLM. Moreover, when transferred to\naugmenting LVLMs, sometimes the hallucination degree of the model is even\nexacerbated.Motivated by the research gap and counter-intuitive phenomenon, we\nintroduce a novel framework, the Active Retrieval-Augmented large\nvision-language model (ARA), specifically designed to address hallucinations by\nincorporating three critical dimensions: (i) dissecting the retrieval targets\nbased on the inherent hierarchical structures of images. (ii) pinpointing the\nmost effective retrieval methods and filtering out the reliable retrieval\nresults. (iii) timing the retrieval process to coincide with episodes of low\ncertainty, while circumventing unnecessary retrieval during periods of high\ncertainty. To assess the capability of our proposed ARA model in reducing\nhallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and\nmPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by\nutilizing fitting retrieval mechanisms and timing the retrieval judiciously, we\ncan effectively mitigate the hallucination problem. We hope that this study can\nprovide deeper insights into how to adapt the retrieval augmentation to LVLMs\nfor reducing hallucinations with more effective retrieval and minimal retrieval\noccurrences.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00555v1",
    "published_date": "2024-08-01 13:38:58 UTC",
    "updated_date": "2024-08-01 13:38:58 UTC"
  },
  {
    "arxiv_id": "2408.00550v1",
    "title": "Mitigating Multilingual Hallucination in Large Vision-Language Models",
    "authors": [
      "Xiaoye Qu",
      "Mingyang Song",
      "Wei Wei",
      "Jianfeng Dong",
      "Yu Cheng"
    ],
    "abstract": "While Large Vision-Language Models (LVLMs) have exhibited remarkable\ncapabilities across a wide range of tasks, they suffer from hallucination\nproblems, where models generate plausible yet incorrect answers given the input\nimage-query pair. This hallucination phenomenon is even more severe when\nquerying the image in non-English languages, while existing methods for\nmitigating hallucinations in LVLMs only consider the English scenarios. In this\npaper, we make the first attempt to mitigate this important multilingual\nhallucination in LVLMs. With thorough experiment analysis, we found that\nmultilingual hallucination in LVLMs is a systemic problem that could arise from\ndeficiencies in multilingual capabilities or inadequate multimodal abilities.\nTo this end, we propose a two-stage Multilingual Hallucination Removal (MHR)\nframework for LVLMs, aiming to improve resistance to hallucination for both\nhigh-resource and low-resource languages. Instead of relying on the intricate\nmanual annotations of multilingual resources, we fully leverage the inherent\ncapabilities of the LVLM and propose a novel cross-lingual alignment method,\nwhich generates multiple responses for each image-query input and then\nidentifies the hallucination-aware pairs for each language. These data pairs\nare finally used for direct preference optimization to prompt the LVLMs to\nfavor non-hallucinating responses. Experimental results show that our MHR\nachieves a substantial reduction in hallucination generation for LVLMs.\nNotably, on our extended multilingual POPE benchmark, our framework delivers an\naverage increase of 19.0% in accuracy across 13 different languages. Our code\nand model weights are available at https://github.com/ssmisya/MHR",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00550v1",
    "published_date": "2024-08-01 13:34:35 UTC",
    "updated_date": "2024-08-01 13:34:35 UTC"
  },
  {
    "arxiv_id": "2408.00549v2",
    "title": "Learning to Embed Distributions via Maximum Kernel Entropy",
    "authors": [
      "Oleksii Kachaiev",
      "Stefano Recanatesi"
    ],
    "abstract": "Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00549v2",
    "published_date": "2024-08-01 13:34:19 UTC",
    "updated_date": "2024-11-28 18:20:26 UTC"
  },
  {
    "arxiv_id": "2408.00544v1",
    "title": "Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model",
    "authors": [
      "Felipe Mahlow",
      "André Felipe Zanella",
      "William Alberto Cruz Castañeda",
      "Regilene Aparecida Sarzi-Ribeiro"
    ],
    "abstract": "In recent years, Generative Artificial Intelligence (GenAI) has undergone a\nprofound transformation in addressing intricate tasks involving diverse\nmodalities such as textual, auditory, visual, and pictorial generation. Within\nthis spectrum, text-to-image (TTI) models have emerged as a formidable approach\nto generating varied and aesthetically appealing compositions, spanning\napplications from artistic creation to realistic facial synthesis, and\ndemonstrating significant advancements in computer vision, image processing,\nand multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a\nparadigm shift in the domain of AI capabilities. This article delves into the\nfeasibility of employing the Stable Diffusion LDM to illustrate literary works.\nFor this exploration, seven classic Brazilian books have been selected as case\nstudies. The objective is to ascertain the practicality of this endeavor and to\nevaluate the potential of Stable Diffusion in producing illustrations that\naugment and enrich the reader's experience. We will outline the beneficial\naspects, such as the capacity to generate distinctive and contextually\npertinent images, as well as the drawbacks, including any shortcomings in\nfaithfully capturing the essence of intricate literary depictions. Through this\nstudy, we aim to provide a comprehensive assessment of the viability and\nefficacy of utilizing AI-generated illustrations in literary contexts,\nelucidating both the prospects and challenges encountered in this pioneering\napplication of technology.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00544v1",
    "published_date": "2024-08-01 13:28:15 UTC",
    "updated_date": "2024-08-01 13:28:15 UTC"
  },
  {
    "arxiv_id": "2408.00540v3",
    "title": "The Energy Cost of Artificial Intelligence Lifecycle in Communication Networks",
    "authors": [
      "Shih-Kai Chou",
      "Jernej Hribar",
      "Vid Hanžel",
      "Mihael Mohorčič",
      "Carolina Fortuna"
    ],
    "abstract": "Artificial Intelligence (AI) is being incorporated in several optimization,\nscheduling, orchestration as well as in native communication network functions.\nWhile this paradigm shift results in increased energy consumption, quantifying\nthe end-toend energy consumption of adding intelligence to such systems is\nparticularly challenging. Conventional metrics focus on either communication,\ncomputation infrastructure, or model development. To address this, we propose a\nnew metric, the Energy Cost of AI Lifecycle (eCAL) of one AI model in a system.\neCAL captures the energy consumption throughout the development and deployment\nof an AI-model providing intelligence in a wireless communication network by\nanalyzing the complexity of data collection and manipulation in individual\ncomponents and deriving overall and per-bit energy consumption. We show that\nthe better a model is and the more it is used, the more energy efficient an\ninference is. For a simple case study, eCAL for making 100 inferences is 2.73\ntimes higher than for 1000 inferences. Additionally, we have developed a\nmodular and extendable opensource simulation tool to enable researchers,\npractitioners, and engineers to calculate the end-to-end energy cost with\nvarious configurations and across various systems, ensuring adaptability to\ndiverse use cases.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.ET",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00540v3",
    "published_date": "2024-08-01 13:23:15 UTC",
    "updated_date": "2025-05-12 11:18:06 UTC"
  },
  {
    "arxiv_id": "2408.00539v1",
    "title": "Intermittent Semi-working Mask: A New Masking Paradigm for LLMs",
    "authors": [
      "Mingcong Lu",
      "Jiangcai Zhu",
      "Wang Hao",
      "Zheng Li",
      "Shusheng Zhang",
      "Kailai Shao",
      "Chao Chen",
      "Nan Li",
      "Feng Wang",
      "Xin Lu"
    ],
    "abstract": "Multi-turn dialogues are a key interaction method between humans and Large\nLanguage Models (LLMs), as conversations extend over multiple rounds, keeping\nLLMs' high generation quality and low latency is a challenge. Mainstream LLMs\ncan be grouped into two categories based on masking strategy: causal LLM and\nprefix LLM. Several works have demonstrated that prefix LLMs tend to outperform\ncausal ones in scenarios that heavily depend on historical context such as\nmulti-turn dialogues or in-context learning, thanks to their bidirectional\nattention on prefix sequences. However, prefix LLMs have an inherent\ninefficient training problem in multi-turn dialogue datasets. In addition, the\nattention mechanism of prefix LLM makes it unable to reuse Key-Value Cache (KV\nCache) across dialogue rounds to reduce generation latency. In this paper, we\npropose a novel masking scheme called Intermittent Semi-working Mask (ISM) to\naddress these problems. Specifically, we apply alternate bidirectional and\nunidirectional attention on queries and answers in the dialogue history. In\nthis way, ISM is able to maintain the high quality of prefix LLM and low\ngeneration latency of causal LLM, simultaneously. Extensive experiments\nillustrate that our ISM achieves significant performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00539v1",
    "published_date": "2024-08-01 13:22:01 UTC",
    "updated_date": "2024-08-01 13:22:01 UTC"
  },
  {
    "arxiv_id": "2408.00814v1",
    "title": "Adaptive traffic signal safety and efficiency improvement by multi objective deep reinforcement learning approach",
    "authors": [
      "Shahin Mirbakhsh",
      "Mahdi Azizi"
    ],
    "abstract": "This research introduces an innovative method for adaptive traffic signal\ncontrol (ATSC) through the utilization of multi-objective deep reinforcement\nlearning (DRL) techniques. The proposed approach aims to enhance control\nstrategies at intersections while simultaneously addressing safety, efficiency,\nand decarbonization objectives. Traditional ATSC methods typically prioritize\ntraffic efficiency and often struggle to adapt to real-time dynamic traffic\nconditions. To address these challenges, the study suggests a DRL-based ATSC\nalgorithm that incorporates the Dueling Double Deep Q Network (D3QN) framework.\nThe performance of this algorithm is assessed using a simulated intersection in\nChangsha, China. Notably, the proposed ATSC algorithm surpasses both\ntraditional ATSC and ATSC algorithms focused solely on efficiency optimization\nby achieving over a 16% reduction in traffic conflicts and a 4% decrease in\ncarbon emissions. Regarding traffic efficiency, waiting time is reduced by 18%\ncompared to traditional ATSC, albeit showing a slight increase (0.64%) compared\nto the DRL-based ATSC algorithm integrating the D3QN framework. This marginal\nincrease suggests a trade-off between efficiency and other objectives like\nsafety and decarbonization. Additionally, the proposed approach demonstrates\nsuperior performance, particularly in scenarios with high traffic demand,\nacross all three objectives. These findings contribute to advancing traffic\ncontrol systems by offering a practical and effective solution for optimizing\nsignal control strategies in real-world traffic situations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00814v1",
    "published_date": "2024-08-01 13:10:41 UTC",
    "updated_date": "2024-08-01 13:10:41 UTC"
  },
  {
    "arxiv_id": "2408.00526v1",
    "title": "Hilbert curves for efficient exploratory landscape analysis neighbourhood sampling",
    "authors": [
      "Johannes J. Pienaar",
      "Anna S. Bosman",
      "Katherine M. Malan"
    ],
    "abstract": "Landscape analysis aims to characterise optimisation problems based on their\nobjective (or fitness) function landscape properties. The problem search space\nis typically sampled, and various landscape features are estimated based on the\nsamples. One particularly salient set of features is information content, which\nrequires the samples to be sequences of neighbouring solutions, such that the\nlocal relationships between consecutive sample points are preserved. Generating\nsuch spatially correlated samples that also provide good search space coverage\nis challenging. It is therefore common to first obtain an unordered sample with\ngood search space coverage, and then apply an ordering algorithm such as the\nnearest neighbour to minimise the distance between consecutive points in the\nsample. However, the nearest neighbour algorithm becomes computationally\nprohibitive in higher dimensions, thus there is a need for more efficient\nalternatives. In this study, Hilbert space-filling curves are proposed as a\nmethod to efficiently obtain high-quality ordered samples. Hilbert curves are a\nspecial case of fractal curves, and guarantee uniform coverage of a bounded\nsearch space while providing a spatially correlated sample. We study the\neffectiveness of Hilbert curves as samplers, and discover that they are capable\nof extracting salient features at a fraction of the computational cost compared\nto Latin hypercube sampling with post-factum ordering. Further, we investigate\nthe use of Hilbert curves as an ordering strategy, and find that they order the\nsample significantly faster than the nearest neighbour ordering, without\nsacrificing the saliency of the extracted features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "A version of this paper is published as conference proceedings of\n  EvoApps 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00526v1",
    "published_date": "2024-08-01 12:57:35 UTC",
    "updated_date": "2024-08-01 12:57:35 UTC"
  },
  {
    "arxiv_id": "2408.00523v2",
    "title": "Jailbreaking Text-to-Image Models with LLM-Based Agents",
    "authors": [
      "Yingkai Dong",
      "Zheng Li",
      "Xiangtao Meng",
      "Ning Yu",
      "Shanqing Guo"
    ],
    "abstract": "Recent advancements have significantly improved automated task-solving\ncapabilities using autonomous agents powered by large language models (LLMs).\nHowever, most LLM-based agents focus on dialogue, programming, or specialized\ndomains, leaving their potential for addressing generative AI safety tasks\nlargely unexplored. In this paper, we propose Atlas, an advanced LLM-based\nmulti-agent framework targeting generative AI models, specifically focusing on\njailbreak attacks against text-to-image (T2I) models with built-in safety\nfilters. Atlas consists of two agents, namely the mutation agent and the\nselection agent, each comprising four key modules: a vision-language model\n(VLM) or LLM brain, planning, memory, and tool usage. The mutation agent uses\nits VLM brain to determine whether a prompt triggers the T2I model's safety\nfilter. It then collaborates iteratively with the LLM brain of the selection\nagent to generate new candidate jailbreak prompts with the highest potential to\nbypass the filter. In addition to multi-agent communication, we leverage\nin-context learning (ICL) memory mechanisms and the chain-of-thought (COT)\napproach to learn from past successes and failures, thereby enhancing Atlas's\nperformance. Our evaluation demonstrates that Atlas successfully jailbreaks\nseveral state-of-the-art T2I models equipped with multi-modal safety filters in\na black-box setting. Additionally, Atlas outperforms existing methods in both\nquery efficiency and the quality of generated images. This work convincingly\ndemonstrates the successful application of LLM-based agents in studying the\nsafety vulnerabilities of popular text-to-image generation models. We urge the\ncommunity to consider advanced techniques like ours in response to the rapidly\nevolving text-to-image generation field.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00523v2",
    "published_date": "2024-08-01 12:54:46 UTC",
    "updated_date": "2024-09-09 08:09:14 UTC"
  },
  {
    "arxiv_id": "2408.00521v2",
    "title": "A new approach for encoding code and assisting code understanding",
    "authors": [
      "Mengdan Fan",
      "Wei Zhang",
      "Haiyan Zhao",
      "Zhi Jin"
    ],
    "abstract": "Some companies (e.g., Microsoft Research and Google DeepMind) have discovered\nsome of the limitations of GPTs' autoregressive paradigm next-word prediction,\nmanifested in the model's lack of planning, working memory, backtracking, and\nreasoning skills. GPTs rely on a local and greedy process of generating the\nnext word, without a global understanding of the task or the output. We have\nconfirmed the above limitations through specialized empirical studies of code\ncomprehension. Although GPT-4 is good at producing fluent and coherent text, it\ncannot handle complex logic and generate new code that hasn't been seen, and it\nrelies too much on the formatting of the prompt to generate the correct code.\nWe propose a new paradigm for code understanding that goes beyond the next-word\nprediction paradigm, inspired by the successful application of diffusion\ntechniques to image generation (Dalle-2, Sora) and protein structure generation\n(AlphaFold-3), which have no autoregressive constraints. Instead of encoding\nthe code in a form that mimics natural language, we encode the code as a\nheterogeneous image paradigm with a memory of global information that mimics\nboth images and protein structures. We then refer to Sora's CLIP upstream\ntext-to-image encoder model to design a text-to-code encoder model that can be\napplied to various downstream code understanding tasks. The model learns the\nglobal understanding of code under the new paradigm heterogeneous image,\nconnects the encoding space of text and code, and encodes the input of text\ninto the vector of code most similar to it. Using self-supervised comparative\nlearning on 456,360 text-code pairs, the model achieved a zero-shot prediction\nof new data. This work is the basis for future work on code generation using\ndiffusion techniques under a new paradigm to avoid autoregressive limitations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 page, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00521v2",
    "published_date": "2024-08-01 12:52:48 UTC",
    "updated_date": "2025-03-23 11:30:23 UTC"
  },
  {
    "arxiv_id": "2408.03963v1",
    "title": "A self-adaptive system of systems architecture to enable its ad-hoc scalability: Unmanned Vehicle Fleet -- Mission Control Center Case study",
    "authors": [
      "Ahmed R. Sadik",
      "Bram Bolder",
      "Pero Subasic"
    ],
    "abstract": "A System of Systems (SoS) comprises Constituent Systems (CSs) that interact\nto provide unique capabilities beyond any single CS. A key challenge in SoS is\nad-hoc scalability, meaning the system size changes during operation by adding\nor removing CSs. This research focuses on an Unmanned Vehicle Fleet (UVF) as a\npractical SoS example, addressing uncertainties like mission changes, range\nextensions, and UV failures. The proposed solution involves a self-adaptive\nsystem that dynamically adjusts UVF architecture, allowing the Mission Control\nCenter (MCC) to scale UVF size automatically based on performance criteria or\nmanually by operator decision. A multi-agent environment and rule management\nengine were implemented to simulate and verify this approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "2023 7th International Conference on Intelligent Systems,\n  Metaheuristics & Swarm Intelligence (ISMSI 2023)",
    "pdf_url": "http://arxiv.org/pdf/2408.03963v1",
    "published_date": "2024-08-01 12:51:26 UTC",
    "updated_date": "2024-08-01 12:51:26 UTC"
  },
  {
    "arxiv_id": "2408.00490v4",
    "title": "Graph Representation Learning via Causal Diffusion for Out-of-Distribution Recommendation",
    "authors": [
      "Chu Zhao",
      "Enneng Yang",
      "Yuliang Liang",
      "Pengxiang Lan",
      "Yuting Liu",
      "Jianzhe Zhao",
      "Guibing Guo",
      "Xingwei Wang"
    ],
    "abstract": "Graph Neural Networks (GNNs)-based recommendation algorithms typically assume\nthat training and testing data are drawn from independent and identically\ndistributed (IID) spaces. However, this assumption often fails in the presence\nof out-of-distribution (OOD) data, resulting in significant performance\ndegradation. In this study, we construct a Structural Causal Model (SCM) to\nanalyze interaction data, revealing that environmental confounders (e.g., the\nCOVID-19 pandemic) lead to unstable correlations in GNN-based models, thus\nimpairing their generalization to OOD data. To address this issue, we propose a\nnovel approach, graph representation learning via causal diffusion\n(CausalDiffRec) for OOD recommendation. This method enhances the model's\ngeneralization on OOD data by eliminating environmental confounding factors and\nlearning invariant graph representations. Specifically, we use backdoor\nadjustment and variational inference to infer the real environmental\ndistribution, thereby eliminating the impact of environmental confounders. This\ninferred distribution is then used as prior knowledge to guide the\nrepresentation learning in the reverse phase of the diffusion process to learn\nthe invariant representation. In addition, we provide a theoretical derivation\nthat proves optimizing the objective function of CausalDiffRec can encourage\nthe model to learn environment-invariant graph representations, thereby\nachieving excellent generalization performance in recommendations under\ndistribution shifts. Our extensive experiments validate the effectiveness of\nCausalDiffRec in improving the generalization of OOD data, and the average\nimprovement is up to 10.69% on Food, 18.83% on KuaiRec, 22.41% on Yelp2018, and\n11.65% on Douban datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, accepted by WWW2025",
    "pdf_url": "http://arxiv.org/pdf/2408.00490v4",
    "published_date": "2024-08-01 11:51:52 UTC",
    "updated_date": "2025-04-02 13:16:51 UTC"
  },
  {
    "arxiv_id": "2408.00483v1",
    "title": "A Systematic Review on Long-Tailed Learning",
    "authors": [
      "Chongsheng Zhang",
      "George Almpanidis",
      "Gaojuan Fan",
      "Binquan Deng",
      "Yanbo Zhang",
      "Ji Liu",
      "Aouaidjia Kamel",
      "Paolo Soda",
      "João Gama"
    ],
    "abstract": "Long-tailed data is a special type of multi-class imbalanced data with a very\nlarge amount of minority/tail classes that have a very significant combined\ninfluence. Long-tailed learning aims to build high-performance models on\ndatasets with long-tailed distributions, which can identify all the classes\nwith high accuracy, in particular the minority/tail classes. It is a\ncutting-edge research direction that has attracted a remarkable amount of\nresearch effort in the past few years. In this paper, we present a\ncomprehensive survey of latest advances in long-tailed visual learning. We\nfirst propose a new taxonomy for long-tailed learning, which consists of eight\ndifferent dimensions, including data balancing, neural architecture, feature\nenrichment, logits adjustment, loss function, bells and whistles, network\noptimization, and post hoc processing techniques. Based on our proposed\ntaxonomy, we present a systematic review of long-tailed learning methods,\ndiscussing their commonalities and alignable differences. We also analyze the\ndifferences between imbalance learning and long-tailed learning approaches.\nFinally, we discuss prospects and future directions in this field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "Current Under Revision at IEEE TNNLS. [This is the long/Full-length\n  version of our Long-Tailed Learning Survey paper]",
    "pdf_url": "http://arxiv.org/pdf/2408.00483v1",
    "published_date": "2024-08-01 11:39:45 UTC",
    "updated_date": "2024-08-01 11:39:45 UTC"
  },
  {
    "arxiv_id": "2408.00481v1",
    "title": "HBot: A Chatbot for Healthcare Applications in Traditional Chinese Medicine Based on Human Body 3D Visualization",
    "authors": [
      "Bolin Zhang",
      "Zhiwei Yi",
      "Jiahao Wang",
      "Dianbo Sui",
      "Zhiying Tu",
      "Dianhui Chu"
    ],
    "abstract": "The unique diagnosis and treatment techniques and remarkable clinical\nefficacy of traditional Chinese medicine (TCM) make it play an important role\nin the field of elderly care and healthcare, especially in the rehabilitation\nof some common chronic diseases of the elderly. Therefore, building a TCM\nchatbot for healthcare application will help users obtain consultation services\nin a direct and natural way. However, concepts such as acupuncture points\n(acupoints) and meridians involved in TCM always appear in the consultation,\nwhich cannot be displayed intuitively. To this end, we develop a\n\\textbf{h}ealthcare chat\\textbf{bot} (HBot) based on a human body model in 3D\nand knowledge graph, which provides conversational services such as knowledge\nQ\\&A, prescription recommendation, moxibustion therapy recommendation, and\nacupoint search. When specific acupoints are involved in the conversations\nbetween user and HBot, the 3D body will jump to the corresponding acupoints and\nhighlight them. Moreover, Hbot can also be used in training scenarios to\naccelerate the teaching process of TCM by intuitively displaying acupuncture\npoints and knowledge cards. The demonstration video is available at\nhttps://www.youtube.com/watch?v=UhQhutSKkTU . Our code and dataset are publicly\navailable at Gitee: https://gitee.com/plabrolin/interactive-3d-acup.git",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "System Demonstration",
    "pdf_url": "http://arxiv.org/pdf/2408.00481v1",
    "published_date": "2024-08-01 11:36:18 UTC",
    "updated_date": "2024-08-01 11:36:18 UTC"
  },
  {
    "arxiv_id": "2408.00473v1",
    "title": "Towards Explainable and Interpretable Musical Difficulty Estimation: A Parameter-efficient Approach",
    "authors": [
      "Pedro Ramoneda",
      "Vsevolod Eremenko",
      "Alexandre D'Hooge",
      "Emilia Parada-Cabaleiro",
      "Xavier Serra"
    ],
    "abstract": "Estimating music piece difficulty is important for organizing educational\nmusic collections. This process could be partially automatized to facilitate\nthe educator's role. Nevertheless, the decisions performed by prevalent\ndeep-learning models are hardly understandable, which may impair the acceptance\nof such a technology in music education curricula. Our work employs explainable\ndescriptors for difficulty estimation in symbolic music representations.\nFurthermore, through a novel parameter-efficient white-box model, we outperform\nprevious efforts while delivering interpretable results. These comprehensible\noutcomes emulate the functionality of a rubric, a tool widely used in music\neducation. Our approach, evaluated in piano repertoire categorized in 9\nclasses, achieved 41.4% accuracy independently, with a mean squared error (MSE)\nof 1.7, showing precise difficulty estimation. Through our baseline, we\nillustrate how building on top of past research can offer alternatives for\nmusic difficulty assessment which are explainable and interpretable. With this,\nwe aim to promote a more effective communication between the Music Information\nRetrieval (MIR) community and the music education one.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00473v1",
    "published_date": "2024-08-01 11:23:42 UTC",
    "updated_date": "2024-08-01 11:23:42 UTC"
  },
  {
    "arxiv_id": "2408.00470v1",
    "title": "Image Super-Resolution with Taylor Expansion Approximation and Large Field Reception",
    "authors": [
      "Jiancong Feng",
      "Yuan-Gen Wang",
      "Mingjie Li",
      "Fengchuang Xing"
    ],
    "abstract": "Self-similarity techniques are booming in blind super-resolution (SR) due to\naccurate estimation of the degradation types involved in low-resolution images.\nHowever, high-dimensional matrix multiplication within self-similarity\ncomputation prohibitively consumes massive computational costs. We find that\nthe high-dimensional attention map is derived from the matrix multiplication\nbetween Query and Key, followed by a softmax function. This softmax makes the\nmatrix multiplication between Query and Key inseparable, posing a great\nchallenge in simplifying computational complexity. To address this issue, we\nfirst propose a second-order Taylor expansion approximation (STEA) to separate\nthe matrix multiplication of Query and Key, resulting in the complexity\nreduction from $\\mathcal{O}(N^2)$ to $\\mathcal{O}(N)$. Then, we design a\nmulti-scale large field reception (MLFR) to compensate for the performance\ndegradation caused by STEA. Finally, we apply these two core designs to\nlaboratory and real-world scenarios by constructing LabNet and RealNet,\nrespectively. Extensive experimental results tested on five synthetic datasets\ndemonstrate that our LabNet sets a new benchmark in qualitative and\nquantitative evaluations. Tested on the RealWorld38 dataset, our RealNet\nachieves superior visual quality over existing methods. Ablation studies\nfurther verify the contributions of STEA and MLFR towards both LabNet and\nRealNet frameworks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00470v1",
    "published_date": "2024-08-01 11:16:26 UTC",
    "updated_date": "2024-08-01 11:16:26 UTC"
  },
  {
    "arxiv_id": "2408.00447v1",
    "title": "DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration",
    "authors": [
      "Chengbo Zheng",
      "Yuanhao Zhang",
      "Zeyu Huang",
      "Chuhan Shi",
      "Minrui Xu",
      "Xiaojuan Ma"
    ],
    "abstract": "Interdisciplinary studies often require researchers to explore literature in\ndiverse branches of knowledge. Yet, navigating through the highly scattered\nknowledge from unfamiliar disciplines poses a significant challenge. In this\npaper, we introduce DiscipLink, a novel interactive system that facilitates\ncollaboration between researchers and large language models (LLMs) in\ninterdisciplinary information seeking (IIS). Based on users' topics of\ninterest, DiscipLink initiates exploratory questions from the perspectives of\npossible relevant fields of study, and users can further tailor these\nquestions. DiscipLink then supports users in searching and screening papers\nunder selected questions by automatically expanding queries with\ndisciplinary-specific terminologies, extracting themes from retrieved papers,\nand highlighting the connections between papers and questions. Our evaluation,\ncomprising a within-subject comparative experiment and an open-ended\nexploratory study, reveals that DiscipLink can effectively support researchers\nin breaking down disciplinary boundaries and integrating scattered knowledge in\ndiverse fields. The findings underscore the potential of LLM-powered tools in\nfostering information-seeking practices and bolstering interdisciplinary\nresearch.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00447v1",
    "published_date": "2024-08-01 10:36:00 UTC",
    "updated_date": "2024-08-01 10:36:00 UTC"
  },
  {
    "arxiv_id": "2408.00444v1",
    "title": "Ontological Relations from Word Embeddings",
    "authors": [
      "Mathieu d'Aquin",
      "Emmanuel Nauer"
    ],
    "abstract": "It has been reliably shown that the similarity of word embeddings obtained\nfrom popular neural models such as BERT approximates effectively a form of\nsemantic similarity of the meaning of those words. It is therefore natural to\nwonder if those embeddings contain enough information to be able to connect\nthose meanings through ontological relationships such as the one of\nsubsumption. If so, large knowledge models could be built that are capable of\nsemantically relating terms based on the information encapsulated in word\nembeddings produced by pre-trained models, with implications not only for\nontologies (ontology matching, ontology evolution, etc.) but also on the\nability to integrate ontological knowledge in neural models. In this paper, we\ntest how embeddings produced by several pre-trained models can be used to\npredict relations existing between classes and properties of popular\nupper-level and general ontologies. We show that even a simple feed-forward\narchitecture on top of those embeddings can achieve promising accuracies, with\nvarying generalisation abilities depending on the input data. To achieve that,\nwe produce a dataset that can be used to further enhance those models, opening\nnew possibilities for applications integrating knowledge from web ontologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00444v1",
    "published_date": "2024-08-01 10:31:32 UTC",
    "updated_date": "2024-08-01 10:31:32 UTC"
  },
  {
    "arxiv_id": "2408.00441v1",
    "title": "Focus, Distinguish, and Prompt: Unleashing CLIP for Efficient and Flexible Scene Text Retrieval",
    "authors": [
      "Gangyan Zeng",
      "Yuan Zhang",
      "Jin Wei",
      "Dongbao Yang",
      "Peng Zhang",
      "Yiwen Gao",
      "Xugong Qin",
      "Yu Zhou"
    ],
    "abstract": "Scene text retrieval aims to find all images containing the query text from\nan image gallery. Current efforts tend to adopt an Optical Character\nRecognition (OCR) pipeline, which requires complicated text detection and/or\nrecognition processes, resulting in inefficient and inflexible retrieval.\nDifferent from them, in this work we propose to explore the intrinsic potential\nof Contrastive Language-Image Pre-training (CLIP) for OCR-free scene text\nretrieval. Through empirical analysis, we observe that the main challenges of\nCLIP as a text retriever are: 1) limited text perceptual scale, and 2)\nentangled visual-semantic concepts. To this end, a novel model termed FDP\n(Focus, Distinguish, and Prompt) is developed. FDP first focuses on scene text\nvia shifting the attention to the text area and probing the hidden text\nknowledge, and then divides the query text into content word and function word\nfor processing, in which a semantic-aware prompting scheme and a distracted\nqueries assistance module are utilized. Extensive experiments show that FDP\nsignificantly enhances the inference speed while achieving better or\ncompetitive retrieval accuracy compared to existing methods. Notably, on the\nIIIT-STR benchmark, FDP surpasses the state-of-the-art model by 4.37% with a 4\ntimes faster speed. Furthermore, additional experiments under phrase-level and\nattribute-aware scene text retrieval settings validate FDP's particular\nadvantages in handling diverse forms of query text. The source code will be\npublicly available at https://github.com/Gyann-z/FDP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00441v1",
    "published_date": "2024-08-01 10:25:14 UTC",
    "updated_date": "2024-08-01 10:25:14 UTC"
  },
  {
    "arxiv_id": "2408.00435v1",
    "title": "A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality",
    "authors": [
      "M. Mehdi Kholoosi",
      "M. Ali Babar",
      "Roland Croft"
    ],
    "abstract": "Artificial Intelligence (AI) advancements have enabled the development of\nLarge Language Models (LLMs) that can perform a variety of tasks with\nremarkable semantic understanding and accuracy. ChatGPT is one such LLM that\nhas gained significant attention due to its impressive capabilities for\nassisting in various knowledge-intensive tasks. Due to the knowledge-intensive\nnature of engineering secure software, ChatGPT's assistance is expected to be\nexplored for security-related tasks during the development/evolution of\nsoftware. To gain an understanding of the potential of ChatGPT as an emerging\ntechnology for supporting software security, we adopted a two-fold approach.\nInitially, we performed an empirical study to analyse the perceptions of those\nwho had explored the use of ChatGPT for security tasks and shared their views\non Twitter. It was determined that security practitioners view ChatGPT as\nbeneficial for various software security tasks, including vulnerability\ndetection, information retrieval, and penetration testing. Secondly, we\ndesigned an experiment aimed at investigating the practicality of this\ntechnology when deployed as an oracle in real-world settings. In particular, we\nfocused on vulnerability detection and qualitatively examined ChatGPT outputs\nfor given prompts within this prominent software security task. Based on our\nanalysis, responses from ChatGPT in this task are largely filled with generic\nsecurity information and may not be appropriate for industry use. To prevent\ndata leakage, we performed this analysis on a vulnerability dataset compiled\nafter the OpenAI data cut-off date from real-world projects covering 40\ndistinct vulnerability types and 12 programming languages. We assert that the\nfindings from this study would contribute to future research aimed at\ndeveloping and evaluating LLMs dedicated to software security.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication at International Conference on Trust,\n  Privacy and Security - 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00435v1",
    "published_date": "2024-08-01 10:14:05 UTC",
    "updated_date": "2024-08-01 10:14:05 UTC"
  },
  {
    "arxiv_id": "2408.00429v1",
    "title": "Augmenting Channel Simulator and Semi- Supervised Learning for Efficient Indoor Positioning",
    "authors": [
      "Yupeng Li",
      "Xinyu Ning",
      "Shijian Gao",
      "Yitong Liu",
      "Zhi Sun",
      "Qixing Wang",
      "Jiangzhou Wang"
    ],
    "abstract": "This work aims to tackle the labor-intensive and resource-consuming task of\nindoor positioning by proposing an efficient approach. The proposed approach\ninvolves the introduction of a semi-supervised learning (SSL) with a biased\nteacher (SSLB) algorithm, which effectively utilizes both labeled and unlabeled\nchannel data. To reduce measurement expenses, unlabeled data is generated using\nan updated channel simulator (UCHS), and then weighted by adaptive confidence\nvalues to simplify the tuning of hyperparameters. Simulation results\ndemonstrate that the proposed strategy achieves superior performance while\nminimizing measurement overhead and training expense compared to existing\nbenchmarks, offering a valuable and practical solution for indoor positioning.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "ACCEPTED for presentation at 2024 IEEE Global Communications\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2408.00429v1",
    "published_date": "2024-08-01 10:06:02 UTC",
    "updated_date": "2024-08-01 10:06:02 UTC"
  },
  {
    "arxiv_id": "2408.00427v2",
    "title": "CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images",
    "authors": [
      "Thiziri Nait Saada",
      "Valentina Di Proietto",
      "Benoit Schmauch",
      "Katharina Von Loga",
      "Lucas Fidon"
    ],
    "abstract": "Multiple Instance Learning (MIL) models have proven effective for cancer\nprognosis from Whole Slide Images. However, the original MIL formulation\nincorrectly assumes the patches of the same image to be independent, leading to\na loss of spatial context as information flows through the network.\nIncorporating contextual knowledge into predictions is particularly important\ngiven the inclination for cancerous cells to form clusters and the presence of\nspatial indicators for tumors. State-of-the-art methods often use attention\nmechanisms eventually combined with graphs to capture spatial knowledge. In\nthis paper, we take a novel and transversal approach, addressing this issue\nthrough the lens of regularization. We propose Context-Aware Regularization for\nMultiple Instance Learning (CARMIL), a versatile regularization scheme designed\nto seamlessly integrate spatial knowledge into any MIL model. Additionally, we\npresent a new and generic metric to quantify the Context-Awareness of any MIL\nmodel when applied to Whole Slide Images, resolving a previously unexplored gap\nin the field. The efficacy of our framework is evaluated for two survival\nanalysis tasks on glioblastoma (TCGA GBM) and colon cancer data (TCGA COAD).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00427v2",
    "published_date": "2024-08-01 09:59:57 UTC",
    "updated_date": "2024-08-12 08:45:19 UTC"
  },
  {
    "arxiv_id": "2408.00421v1",
    "title": "Towards Evolutionary-based Automated Machine Learning for Small Molecule Pharmacokinetic Prediction",
    "authors": [
      "Alex G. C. de Sá",
      "David B. Ascher"
    ],
    "abstract": "Machine learning (ML) is revolutionising drug discovery by expediting the\nprediction of small molecule properties essential for developing new drugs.\nThese properties -- including absorption, distribution, metabolism and\nexcretion (ADME)-- are crucial in the early stages of drug development since\nthey provide an understanding of the course of the drug in the organism, i.e.,\nthe drug's pharmacokinetics. However, existing methods lack personalisation and\nrely on manually crafted ML algorithms or pipelines, which can introduce\ninefficiencies and biases into the process. To address these challenges, we\npropose a novel evolutionary-based automated ML method (AutoML) specifically\ndesigned for predicting small molecule properties, with a particular focus on\npharmacokinetics. Leveraging the advantages of grammar-based genetic\nprogramming, our AutoML method streamlines the process by automatically\nselecting algorithms and designing predictive pipelines tailored to the\nparticular characteristics of input molecular data. Results demonstrate\nAutoML's effectiveness in selecting diverse ML algorithms, resulting in\ncomparable or even improved predictive performances compared to conventional\napproaches. By offering personalised ML-driven pipelines, our method promises\nto enhance small molecule research in drug discovery, providing researchers\nwith a valuable tool for accelerating the development of novel therapeutic\ndrugs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted and presented at the 14th Workshop on Evolutionary\n  Computation for the Automated Design of Algorithms (ECADA), which happened\n  during the Genetic and Evolutionary Computation Conference (GECCO)",
    "pdf_url": "http://arxiv.org/pdf/2408.00421v1",
    "published_date": "2024-08-01 09:46:06 UTC",
    "updated_date": "2024-08-01 09:46:06 UTC"
  },
  {
    "arxiv_id": "2408.00420v1",
    "title": "MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition",
    "authors": [
      "Wenqing Gan",
      "Yan Sun",
      "Feiran Liu",
      "Xiangfeng Luo"
    ],
    "abstract": "The objective of the panoramic activity recognition task is to identify\nbehaviors at various granularities within crowded and complex environments,\nencompassing individual actions, social group activities, and global\nactivities. Existing methods generally use either parameter-independent modules\nto capture task-specific features or parameter-sharing modules to obtain common\nfeatures across all tasks. However, there is often a strong interrelatedness\nand complementary effect between tasks of different granularities that previous\nmethods have yet to notice. In this paper, we propose a model called MPT-PAR\nthat considers both the unique characteristics of each task and the synergies\nbetween different tasks simultaneously, thereby maximizing the utilization of\nfeatures across multi-granularity activity recognition. Furthermore, we\nemphasize the significance of temporal and spatial information by introducing a\nspatio-temporal relation-enhanced module and a scene representation learning\nmodule, which integrate the the spatio-temporal context of action and global\nscene into the feature map of each granularity. Our method achieved an overall\nF1 score of 47.5\\% on the JRDB-PAR dataset, significantly outperforming all the\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00420v1",
    "published_date": "2024-08-01 09:42:44 UTC",
    "updated_date": "2024-08-01 09:42:44 UTC"
  },
  {
    "arxiv_id": "2408.00415v1",
    "title": "DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving",
    "authors": [
      "Xuemeng Yang",
      "Licheng Wen",
      "Yukai Ma",
      "Jianbiao Mei",
      "Xin Li",
      "Tiantian Wei",
      "Wenjie Lei",
      "Daocheng Fu",
      "Pinlong Cai",
      "Min Dou",
      "Botian Shi",
      "Liang He",
      "Yong Liu",
      "Yu Qiao"
    ],
    "abstract": "This paper presented DriveArena, the first high-fidelity closed-loop\nsimulation system designed for driving agents navigating in real scenarios.\nDriveArena features a flexible, modular architecture, allowing for the seamless\ninterchange of its core components: Traffic Manager, a traffic simulator\ncapable of generating realistic traffic flow on any worldwide street map, and\nWorld Dreamer, a high-fidelity conditional generative model with infinite\nautoregression. This powerful synergy empowers any driving agent capable of\nprocessing real-world images to navigate in DriveArena's simulated environment.\nThe agent perceives its surroundings through images generated by World Dreamer\nand output trajectories. These trajectories are fed into Traffic Manager,\nachieving realistic interactions with other vehicles and producing a new scene\nlayout. Finally, the latest scene layout is relayed back into World Dreamer,\nperpetuating the simulation cycle. This iterative process fosters closed-loop\nexploration within a highly realistic environment, providing a valuable\nplatform for developing and evaluating driving agents across diverse and\nchallenging scenarios. DriveArena signifies a substantial leap forward in\nleveraging generative image data for the driving simulation platform, opening\ninsights for closed-loop autonomous driving. Code will be available soon on\nGitHub: https://github.com/PJLab-ADG/DriveArena",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "19 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00415v1",
    "published_date": "2024-08-01 09:32:01 UTC",
    "updated_date": "2024-08-01 09:32:01 UTC"
  },
  {
    "arxiv_id": "2408.00399v1",
    "title": "Unsupervised Pairwise Causal Discovery on Heterogeneous Data using Mutual Information Measures",
    "authors": [
      "Alexandre Trilla",
      "Nenad Mijatovic"
    ],
    "abstract": "A fundamental task in science is to determine the underlying causal relations\nbecause it is the knowledge of this functional structure what leads to the\ncorrect interpretation of an effect given the apparent associations in the\nobserved data. In this sense, Causal Discovery is a technique that tackles this\nchallenge by analyzing the statistical properties of the constituent variables.\nIn this work, we target the generalizability of the discovery method by\nfollowing a reductionist approach that only involves two variables, i.e., the\npairwise or bi-variate setting. We question the current (possibly misleading)\nbaseline results on the basis that they were obtained through supervised\nlearning, which is arguably contrary to this genuinely exploratory endeavor. In\nconsequence, we approach this problem in an unsupervised way, using robust\nMutual Information measures, and observing the impact of the different variable\ntypes, which is oftentimes ignored in the design of solutions. Thus, we provide\na novel set of standard unbiased results that can serve as a reference to guide\nfuture discovery tasks in completely unknown environments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "26th International Conference of the Catalan Association for\n  Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2408.00399v1",
    "published_date": "2024-08-01 09:11:08 UTC",
    "updated_date": "2024-08-01 09:11:08 UTC"
  },
  {
    "arxiv_id": "2408.05231v3",
    "title": "Predictive maintenance solution for industrial systems -- an unsupervised approach based on log periodic power law",
    "authors": [
      "Bogdan Łobodziński"
    ],
    "abstract": "A new unsupervised predictive maintenance analysis method based on the\nrenormalization group approach used to discover critical behavior in complex\nsystems has been proposed. The algorithm analyzes univariate time series and\ndetects critical points based on a newly proposed theorem that identifies\ncritical points using a Log Periodic Power Law function fits. Application of a\nnew algorithm for predictive maintenance analysis of industrial data collected\nfrom reciprocating compressor systems is presented. Based on the knowledge of\nthe dynamics of the analyzed compressor system, the proposed algorithm predicts\nvalve and piston rod seal failures well in advance.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "stat.AP",
    "comment": "14 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.05231v3",
    "published_date": "2024-08-01 09:01:27 UTC",
    "updated_date": "2025-04-29 13:37:38 UTC"
  },
  {
    "arxiv_id": "2408.00380v3",
    "title": "EXAONEPath 1.0 Patch-level Foundation Model for Pathology",
    "authors": [
      "Juseung Yun",
      "Yi Hu",
      "Jinhyung Kim",
      "Jongseong Jang",
      "Soonyoung Lee"
    ],
    "abstract": "Recent advancements in digital pathology have led to the development of\nnumerous foundational models that utilize self-supervised learning on patches\nextracted from gigapixel whole slide images (WSIs). While this approach\nleverages vast amounts of unlabeled data, we have discovered a significant\nissue: features extracted from these self-supervised models tend to cluster by\nindividual WSIs, a phenomenon we term WSI-specific feature collapse. This\nproblem can potentially limit the model's generalization ability and\nperformance on various downstream tasks. To address this issue, we introduce\nEXAONEPath, a novel foundational model trained on patches that have undergone\nstain normalization. Stain normalization helps reduce color variability arising\nfrom different laboratories and scanners, enabling the model to learn more\nconsistent features. EXAONEPath is trained using 285,153,903 patches extracted\nfrom a total of 34,795 WSIs. Our experiments demonstrate that EXAONEPath\nsignificantly mitigates the feature collapse problem, indicating that the model\nhas learned more generalized features rather than overfitting to individual WSI\ncharacteristics. We compared EXAONEPath with state-of-the-art models across six\ndownstream task datasets, and our results show that EXAONEPath achieves\nsuperior performance relative to the number of WSIs used and the model's\nparameter count. This suggests that the application of stain normalization has\nsubstantially improved the model's efficiency and generalization capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "License updated",
    "pdf_url": "http://arxiv.org/pdf/2408.00380v3",
    "published_date": "2024-08-01 08:41:13 UTC",
    "updated_date": "2024-08-22 05:07:18 UTC"
  },
  {
    "arxiv_id": "2408.00376v1",
    "title": "On the Limitations and Prospects of Machine Unlearning for Generative AI",
    "authors": [
      "Shiji Zhou",
      "Lianzhe Wang",
      "Jiangnan Ye",
      "Yongliang Wu",
      "Heng Chang"
    ],
    "abstract": "Generative AI (GenAI), which aims to synthesize realistic and diverse data\nsamples from latent variables or other data modalities, has achieved remarkable\nresults in various domains, such as natural language, images, audio, and\ngraphs. However, they also pose challenges and risks to data privacy, security,\nand ethics. Machine unlearning is the process of removing or weakening the\ninfluence of specific data samples or features from a trained model, without\naffecting its performance on other data or tasks. While machine unlearning has\nshown significant efficacy in traditional machine learning tasks, it is still\nunclear if it could help GenAI become safer and aligned with human desire. To\nthis end, this position paper provides an in-depth discussion of the machine\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\nunlearning tasks on GenAI and introduce the background. Subsequently, we\nsystematically examine the limitations of machine unlearning on GenAI models by\nfocusing on the two representative branches: LLMs and image generative\n(diffusion) models. Finally, we provide our prospects mainly from three\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\nconscientiously advocate for the future development of this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00376v1",
    "published_date": "2024-08-01 08:35:40 UTC",
    "updated_date": "2024-08-01 08:35:40 UTC"
  },
  {
    "arxiv_id": "2408.00374v3",
    "title": "Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving",
    "authors": [
      "Xi Chen",
      "Rahul Bhadani",
      "Larry Head"
    ],
    "abstract": "Current research on trajectory prediction primarily relies on data collected\nby onboard sensors of an ego vehicle. With the rapid advancement in connected\ntechnologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure\n(V2I) communication, valuable information from alternate views becomes\naccessible via wireless networks. The integration of information from\nalternative views has the potential to overcome the inherent limitations\nassociated with a single viewpoint, such as occlusions and limited field of\nview. In this work, we introduce V2INet, a novel trajectory prediction\nframework designed to model multi-view data by extending existing single-view\nmodels. Unlike previous approaches where the multi-view data is manually fused\nor formulated as a separate training stage, our model supports end-to-end\ntraining, enhancing both flexibility and performance. Moreover, the predicted\nmultimodal trajectories are calibrated by a post-hoc conformal prediction\nmodule to get valid and efficient confidence regions. We evaluated the entire\nframework using the real-world V2I dataset V2X-Seq. Our results demonstrate\nsuperior performance in terms of Final Displacement Error (FDE) and Miss Rate\n(MR) using a single GPU. The code is publicly available at:\nhttps://github.com/xichennn/V2I_trajectory_prediction.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00374v3",
    "published_date": "2024-08-01 08:32:03 UTC",
    "updated_date": "2025-03-11 18:19:56 UTC"
  },
  {
    "arxiv_id": "2408.00370v1",
    "title": "DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework",
    "authors": [
      "Fan Zhang",
      "Naye Ji",
      "Fuxing Gao",
      "Bozuo Zhao",
      "Jingmei Wu",
      "Yanbing Jiang",
      "Hui Du",
      "Zhenqing Ye",
      "Jiayang Zhu",
      "WeiFan Zhong",
      "Leyao Yan",
      "Xiaomeng Ma"
    ],
    "abstract": "Speech-driven gesture generation is an emerging domain within virtual human\ncreation, where current methods predominantly utilize Transformer-based\narchitectures that necessitate extensive memory and are characterized by slow\ninference speeds. In response to these limitations, we propose\n\\textit{DiM-Gestures}, a novel end-to-end generative model crafted to create\nhighly personalized 3D full-body gestures solely from raw speech audio,\nemploying Mamba-based architectures. This model integrates a Mamba-based fuzzy\nfeature extractor with a non-autoregressive Adaptive Layer Normalization\n(AdaLN) Mamba-2 diffusion architecture. The extractor, leveraging a Mamba\nframework and a WavLM pre-trained model, autonomously derives implicit,\ncontinuous fuzzy features, which are then unified into a singular latent\nfeature. This feature is processed by the AdaLN Mamba-2, which implements a\nuniform conditional mechanism across all tokens to robustly model the interplay\nbetween the fuzzy features and the resultant gesture sequence. This innovative\napproach guarantees high fidelity in gesture-speech synchronization while\nmaintaining the naturalness of the gestures. Employing a diffusion model for\ntraining and inference, our framework has undergone extensive subjective and\nobjective evaluations on the ZEGGS and BEAT datasets. These assessments\nsubstantiate our model's enhanced performance relative to contemporary\nstate-of-the-art methods, demonstrating competitive outcomes with the DiTs\narchitecture (Persona-Gestors) while optimizing memory usage and accelerating\ninference speed.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.RO",
      "cs.SD"
    ],
    "primary_category": "cs.GR",
    "comment": "10 pages,10 figures. arXiv admin note: text overlap with\n  arXiv:2403.10805",
    "pdf_url": "http://arxiv.org/pdf/2408.00370v1",
    "published_date": "2024-08-01 08:22:47 UTC",
    "updated_date": "2024-08-01 08:22:47 UTC"
  },
  {
    "arxiv_id": "2408.07287v2",
    "title": "Abductive Reasoning in a Paraconsistent Framework",
    "authors": [
      "Meghyn Bienvenu",
      "Katsumi Inoue",
      "Daniil Kozhemiachenko"
    ],
    "abstract": "We explore the problem of explaining observations starting from a classically\ninconsistent theory by adopting a paraconsistent framework. We consider two\nexpansions of the well-known Belnap--Dunn paraconsistent four-valued logic\n$\\mathsf{BD}$: $\\mathsf{BD}_\\circ$ introduces formulas of the form $\\circ\\phi$\n(the information on $\\phi$ is reliable), while $\\mathsf{BD}_\\triangle$ augments\nthe language with $\\triangle\\phi$'s (there is information that $\\phi$ is true).\nWe define and motivate the notions of abduction problems and explanations in\n$\\mathsf{BD}_\\circ$ and $\\mathsf{BD}_\\triangle$ and show that they are not\nreducible to one another. We analyse the complexity of standard abductive\nreasoning tasks (solution recognition, solution existence, and relevance /\nnecessity of hypotheses) in both logics. Finally, we show how to reduce\nabduction in $\\mathsf{BD}_\\circ$ and $\\mathsf{BD}_\\triangle$ to abduction in\nclassical propositional logic, thereby enabling the reuse of existing abductive\nreasoning procedures.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "math.LO"
    ],
    "primary_category": "cs.LO",
    "comment": "This is an extended version of a paper with the same title appearing\n  at the 21st International Conference on Principles of Knowledge\n  Representation and Reasoning (KR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.07287v2",
    "published_date": "2024-08-01 08:12:52 UTC",
    "updated_date": "2024-08-23 14:05:17 UTC"
  },
  {
    "arxiv_id": "2408.07283v2",
    "title": "Queries With Exact Truth Values in Paraconsistent Description Logics",
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux",
      "Daniil Kozhemiachenko"
    ],
    "abstract": "We present a novel approach to querying classical inconsistent description\nlogic (DL) knowledge bases by adopting a~paraconsistent semantics with the four\nBelnapian values: exactly true ($\\mathbf{T}$), exactly false ($\\mathbf{F}$),\nboth ($\\mathbf{B}$), and neither ($\\mathbf{N}$). In contrast to prior studies\non paraconsistent DLs, we allow truth value operators in the query language,\nwhich can be used to differentiate between answers having contradictory\nevidence and those having only positive evidence. We present a reduction to\nclassical DL query answering that allows us to pinpoint the precise combined\nand data complexity of answering queries with values in paraconsistent\n$\\mathcal{ALCHI}$ and its sublogics. Notably, we show that tractable data\ncomplexity is retained for Horn DLs. We present a comparison with repair-based\ninconsistency-tolerant semantics, showing that the two approaches are\nincomparable.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.DB",
      "math.LO"
    ],
    "primary_category": "cs.LO",
    "comment": "This is an extended version of a paper with the same title appearing\n  at the 21st International Conference on Principles of Knowledge\n  Representation and Reasoning (KR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.07283v2",
    "published_date": "2024-08-01 08:11:50 UTC",
    "updated_date": "2024-08-15 07:33:58 UTC"
  },
  {
    "arxiv_id": "2408.00365v2",
    "title": "Multimodal Fusion and Coherence Modeling for Video Topic Segmentation",
    "authors": [
      "Hai Yu",
      "Chong Deng",
      "Qinglin Zhang",
      "Jiaqing Liu",
      "Qian Chen",
      "Wen Wang"
    ],
    "abstract": "The video topic segmentation (VTS) task segments videos into intelligible,\nnon-overlapping topics, facilitating efficient comprehension of video content\nand quick access to specific content. VTS is also critical to various\ndownstream video understanding tasks. Traditional VTS methods using shallow\nfeatures or unsupervised approaches struggle to accurately discern the nuances\nof topical transitions. Recently, supervised approaches have achieved superior\nperformance on video action or scene segmentation over unsupervised approaches.\nIn this work, we improve supervised VTS by thoroughly exploring multimodal\nfusion and multimodal coherence modeling. Specifically, (1) we enhance\nmultimodal fusion by exploring different architectures using cross-attention\nand mixture of experts. (2) To generally strengthen multimodality alignment and\nfusion, we pre-train and fine-tune the model with multimodal contrastive\nlearning. (3) We propose a new pre-training task tailored for the VTS task, and\na novel fine-tuning task for enhancing multimodal coherence modeling for VTS.\nWe evaluate the proposed approaches on educational videos, in the form of\nlectures, due to the vital role of topic segmentation of educational videos in\nboosting learning experiences. Additionally, we introduce a large-scale Chinese\nlecture video dataset to augment the existing English corpus, promoting further\nresearch in VTS. Experiments on both English and Chinese lecture datasets\ndemonstrate that our model achieves superior VTS performance compared to\ncompetitive unsupervised and supervised baselines.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00365v2",
    "published_date": "2024-08-01 08:10:32 UTC",
    "updated_date": "2024-12-30 02:50:49 UTC"
  },
  {
    "arxiv_id": "2408.00355v3",
    "title": "DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved Denoising Training",
    "authors": [
      "Yu Xie",
      "Qian Qiao",
      "Jun Gao",
      "Tianxiang Wu",
      "Jiaqing Fan",
      "Yue Zhang",
      "Jielei Zhang",
      "Huyang Sun"
    ],
    "abstract": "More and more end-to-end text spotting methods based on Transformer\narchitecture have demonstrated superior performance. These methods utilize a\nbipartite graph matching algorithm to perform one-to-one optimal matching\nbetween predicted objects and actual objects. However, the instability of\nbipartite graph matching can lead to inconsistent optimization targets, thereby\naffecting the training performance of the model. Existing literature applies\ndenoising training to solve the problem of bipartite graph matching instability\nin object detection tasks. Unfortunately, this denoising training method cannot\nbe directly applied to text spotting tasks, as these tasks need to perform\nirregular shape detection tasks and more complex text recognition tasks than\nclassification. To address this issue, we propose a novel denoising training\nmethod (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we\ndecompose the queries of the denoising part into noised positional queries and\nnoised content queries. We use the four Bezier control points of the Bezier\ncenter curve to generate the noised positional queries. For the noised content\nqueries, considering that the output of the text in a fixed positional order is\nnot conducive to aligning position with content, we employ a masked character\nsliding method to initialize noised content queries, thereby assisting in the\nalignment of text content and position. To improve the model's perception of\nthe background, we further utilize an additional loss function for background\ncharacters classification in the denoising training part.Although DNTextSpotter\nis conceptually simple, it outperforms the state-of-the-art methods on four\nbenchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially\nyielding an improvement of 11.3% against the best approach in Inverse-Text\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM'MM2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00355v3",
    "published_date": "2024-08-01 07:52:07 UTC",
    "updated_date": "2024-11-03 14:33:34 UTC"
  },
  {
    "arxiv_id": "2408.00350v1",
    "title": "A Simple Background Augmentation Method for Object Detection with Diffusion Model",
    "authors": [
      "Yuhang Li",
      "Xin Dong",
      "Chen Chen",
      "Weiming Zhuang",
      "Lingjuan Lyu"
    ],
    "abstract": "In computer vision, it is well-known that a lack of data diversity will\nimpair model performance. In this study, we address the challenges of enhancing\nthe dataset diversity problem in order to benefit various downstream tasks such\nas object detection and instance segmentation. We propose a simple yet\neffective data augmentation approach by leveraging advancements in generative\nmodels, specifically text-to-image synthesis technologies like Stable\nDiffusion. Our method focuses on generating variations of labeled real images,\nutilizing generative object and background augmentation via inpainting to\naugment existing training data without the need for additional annotations. We\nfind that background augmentation, in particular, significantly improves the\nmodels' robustness and generalization capabilities. We also investigate how to\nadjust the prompt and mask to ensure the generated content comply with the\nexisting annotations. The efficacy of our augmentation techniques is validated\nthrough comprehensive evaluations of the COCO dataset and several other key\nobject detection benchmarks, demonstrating notable enhancements in model\nperformance across diverse scenarios. This approach offers a promising solution\nto the challenges of dataset enhancement, contributing to the development of\nmore accurate and robust computer vision models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00350v1",
    "published_date": "2024-08-01 07:40:00 UTC",
    "updated_date": "2024-08-01 07:40:00 UTC"
  },
  {
    "arxiv_id": "2408.00348v2",
    "title": "Securing the Diagnosis of Medical Imaging: An In-depth Analysis of AI-Resistant Attacks",
    "authors": [
      "Md Abdullah Al Nasim",
      "Parag Biswas",
      "Abdur Rashid",
      "Kishor Datta Gupta",
      "Roy George",
      "Sovon Chakraborty",
      "Khalil Shujaee"
    ],
    "abstract": "Machine learning (ML) is a rapidly developing area of medicine that uses\nsignificant resources to apply computer science and statistics to medical\nissues. ML's proponents laud its capacity to handle vast, complicated, and\nerratic medical data. It's common knowledge that attackers might cause\nmisclassification by deliberately creating inputs for machine learning\nclassifiers. Research on adversarial examples has been extensively conducted in\nthe field of computer vision applications. Healthcare systems are thought to be\nhighly difficult because of the security and life-or-death considerations they\ninclude, and performance accuracy is very important. Recent arguments have\nsuggested that adversarial attacks could be made against medical image analysis\n(MedIA) technologies because of the accompanying technology infrastructure and\npowerful financial incentives. Since the diagnosis will be the basis for\nimportant decisions, it is essential to assess how strong medical DNN tasks are\nagainst adversarial attacks. Simple adversarial attacks have been taken into\naccount in several earlier studies. However, DNNs are susceptible to more risky\nand realistic attacks. The present paper covers recent proposed adversarial\nattack strategies against DNNs for medical imaging as well as countermeasures.\nIn this study, we review current techniques for adversarial imaging attacks,\ndetections. It also encompasses various facets of these techniques and offers\nsuggestions for the robustness of neural networks to be improved in the future.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00348v2",
    "published_date": "2024-08-01 07:37:27 UTC",
    "updated_date": "2024-10-19 19:15:21 UTC"
  },
  {
    "arxiv_id": "2408.00347v2",
    "title": "Advancing Medical Image Segmentation: Morphology-Driven Learning with Diffusion Transformer",
    "authors": [
      "Sungmin Kang",
      "Jaeha Song",
      "Jihie Kim"
    ],
    "abstract": "Understanding the morphological structure of medical images and precisely\nsegmenting the region of interest or abnormality is an important task that can\nassist in diagnosis. However, the unique properties of medical imaging make\nclear segmentation difficult,and the high cost and time-consuming task of\nlabeling leads to a coarse-grained representation of ground truth. Facing with\nthese problems, we propose a novel Diffusion Transformer Segmentation (DTS)\nmodel for robust segmentation in the presence of noise. We propose an\nalternative to the dominant Denoising U-Net encoder through experiments\napplying a transformer architecture, which captures global dependency through\nself-attention. Additionally, we propose k-neighbor label smoothing, reverse\nboundary attention, and self-supervised learning with morphology-driven\nlearning to improve the ability to identify complex structures. Our model,\nwhich analyzes the morphological representation of images, shows better results\nthan the previous models in various medical imaging modalities, including CT,\nMRI, and lesion images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in BMVC 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00347v2",
    "published_date": "2024-08-01 07:35:54 UTC",
    "updated_date": "2024-09-01 03:52:51 UTC"
  },
  {
    "arxiv_id": "2408.00346v1",
    "title": "Neural Graph Matching for Video Retrieval in Large-Scale Video-driven E-commerce",
    "authors": [
      "Houye Ji",
      "Ye Tang",
      "Zhaoxin Chen",
      "Lixi Deng",
      "Jun Hu",
      "Lei Su"
    ],
    "abstract": "With the rapid development of the short video industry, traditional\ne-commerce has encountered a new paradigm, video-driven e-commerce, which\nleverages attractive videos for product showcases and provides both video and\nitem services for users. Benefitting from the dynamic and visualized\nintroduction of items,video-driven e-commerce has shown huge potential in\nstimulating consumer confidence and promoting sales. In this paper, we focus on\nthe video retrieval task, facing the following challenges: (1) Howto handle the\nheterogeneities among users, items, and videos? (2)How to mine the\ncomplementarity between items and videos for better user understanding? In this\npaper, we first leverage the dual graph to model the co-existing of user-video\nand user-item interactions in video-driven e-commerce and innovatively reduce\nuser preference understanding to a graph matching problem. To solve it, we\nfurther propose a novel bi-level Graph Matching Network(GMN), which mainly\nconsists of node- and preference-level graph matching. Given a user, node-level\ngraph matching aims to match videos and items, while preference-level graph\nmatching aims to match multiple user preferences extracted from both videos and\nitems. Then the proposed GMN can generate and improve user embedding by\naggregating matched nodes or preferences from the dual graph in a bi-level\nmanner. Comprehensive experiments show the superiority of the proposed GMN with\nsignificant improvements over state-of-the-art approaches (e.g., AUC+1.9% and\nCTR+7.15%). We have developed it on a well-known video-driven e-commerce\nplatform, serving hundreds of millions of users every day",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00346v1",
    "published_date": "2024-08-01 07:31:23 UTC",
    "updated_date": "2024-08-01 07:31:23 UTC"
  },
  {
    "arxiv_id": "2408.00342v1",
    "title": "MuJoCo MPC for Humanoid Control: Evaluation on HumanoidBench",
    "authors": [
      "Moritz Meser",
      "Aditya Bhatt",
      "Boris Belousov",
      "Jan Peters"
    ],
    "abstract": "We tackle the recently introduced benchmark for whole-body humanoid control\nHumanoidBench using MuJoCo MPC. We find that sparse reward functions of\nHumanoidBench yield undesirable and unrealistic behaviors when optimized;\ntherefore, we propose a set of regularization terms that stabilize the robot\nbehavior across tasks. Current evaluations on a subset of tasks demonstrate\nthat our proposed reward function allows achieving the highest HumanoidBench\nscores while maintaining realistic posture and smooth control signals. Our code\nis publicly available and will become a part of MuJoCo MPC, enabling rapid\nprototyping of robot behaviors.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "3 pages, 3 figures, submitted to IEEE Conference on Robotics and\n  Automation (ICRA@40)",
    "pdf_url": "http://arxiv.org/pdf/2408.00342v1",
    "published_date": "2024-08-01 07:27:18 UTC",
    "updated_date": "2024-08-01 07:27:18 UTC"
  },
  {
    "arxiv_id": "2408.00329v1",
    "title": "OTAD: An Optimal Transport-Induced Robust Model for Agnostic Adversarial Attack",
    "authors": [
      "Kuo Gai",
      "Sicong Wang",
      "Shihua Zhang"
    ],
    "abstract": "Deep neural networks (DNNs) are vulnerable to small adversarial perturbations\nof the inputs, posing a significant challenge to their reliability and\nrobustness. Empirical methods such as adversarial training can defend against\nparticular attacks but remain vulnerable to more powerful attacks.\nAlternatively, Lipschitz networks provide certified robustness to unseen\nperturbations but lack sufficient expressive power. To harness the advantages\nof both approaches, we design a novel two-step Optimal Transport induced\nAdversarial Defense (OTAD) model that can fit the training data accurately\nwhile preserving the local Lipschitz continuity. First, we train a DNN with a\nregularizer derived from optimal transport theory, yielding a discrete optimal\ntransport map linking data to its features. By leveraging the map's inherent\nregularity, we interpolate the map by solving the convex integration problem\n(CIP) to guarantee the local Lipschitz property. OTAD is extensible to diverse\narchitectures of ResNet and Transformer, making it suitable for complex data.\nFor efficient computation, the CIP can be solved through training neural\nnetworks. OTAD opens a novel avenue for developing reliable and secure deep\nlearning systems through the regularity of optimal transport maps. Empirical\nresults demonstrate that OTAD can outperform other robust models on diverse\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00329v1",
    "published_date": "2024-08-01 07:04:18 UTC",
    "updated_date": "2024-08-01 07:04:18 UTC"
  },
  {
    "arxiv_id": "2408.00315v4",
    "title": "ADBM: Adversarial diffusion bridge model for reliable adversarial purification",
    "authors": [
      "Xiao Li",
      "Wenxuan Sun",
      "Huanran Chen",
      "Qiongxiu Li",
      "Yining Liu",
      "Yingzhe He",
      "Jie Shi",
      "Xiaolin Hu"
    ],
    "abstract": "Recently Diffusion-based Purification (DiffPure) has been recognized as an\neffective defense method against adversarial examples. However, we find\nDiffPure which directly employs the original pre-trained diffusion models for\nadversarial purification, to be suboptimal. This is due to an inherent\ntrade-off between noise purification performance and data recovery quality.\nAdditionally, the reliability of existing evaluations for DiffPure is\nquestionable, as they rely on weak adaptive attacks. In this work, we propose a\nnovel Adversarial Diffusion Bridge Model, termed ADBM. ADBM directly constructs\na reverse bridge from the diffused adversarial data back to its original clean\nexamples, enhancing the purification capabilities of the original diffusion\nmodels. Through theoretical analysis and experimental validation across various\nscenarios, ADBM has proven to be a superior and robust defense mechanism,\noffering significant promise for practical applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, fix typos in the proof",
    "pdf_url": "http://arxiv.org/pdf/2408.00315v4",
    "published_date": "2024-08-01 06:26:05 UTC",
    "updated_date": "2025-03-19 05:26:47 UTC"
  },
  {
    "arxiv_id": "2408.00309v1",
    "title": "Discretizing Continuous Action Space with Unimodal Probability Distributions for On-Policy Reinforcement Learning",
    "authors": [
      "Yuanyang Zhu",
      "Zhi Wang",
      "Yuanheng Zhu",
      "Chunlin Chen",
      "Dongbin Zhao"
    ],
    "abstract": "For on-policy reinforcement learning, discretizing action space for\ncontinuous control can easily express multiple modes and is straightforward to\noptimize. However, without considering the inherent ordering between the\ndiscrete atomic actions, the explosion in the number of discrete actions can\npossess undesired properties and induce a higher variance for the policy\ngradient estimator. In this paper, we introduce a straightforward architecture\nthat addresses this issue by constraining the discrete policy to be unimodal\nusing Poisson probability distributions. This unimodal architecture can better\nleverage the continuity in the underlying continuous action space using\nexplicit unimodal probability distributions. We conduct extensive experiments\nto show that the discrete policy with the unimodal probability distribution\nprovides significantly faster convergence and higher performance for on-policy\nreinforcement learning algorithms in challenging control tasks, especially in\nhighly complex tasks such as Humanoid. We provide theoretical analysis on the\nvariance of the policy gradient estimator, which suggests that our attentively\ndesigned unimodal discrete policy can retain a lower variance and yield a\nstable learning process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE Transactions on Neural Networks and Learning Systems",
    "pdf_url": "http://arxiv.org/pdf/2408.00309v1",
    "published_date": "2024-08-01 06:06:53 UTC",
    "updated_date": "2024-08-01 06:06:53 UTC"
  },
  {
    "arxiv_id": "2408.00307v1",
    "title": "ABC Align: Large Language Model Alignment for Safety & Accuracy",
    "authors": [
      "Gareth Seneque",
      "Lap-Hang Ho",
      "Ariel Kuperman",
      "Nafise Erfanian Saeedi",
      "Jeffrey Molendijk"
    ],
    "abstract": "Alignment of Large Language Models (LLMs) remains an unsolved problem. Human\npreferences are highly distributed and can be captured at multiple levels of\nabstraction, from the individual to diverse populations. Organisational\npreferences, represented by standards and principles, are defined to mitigate\nreputational risk or meet legislative obligations. In this paper, we present\nABC Align, a novel alignment methodology for LLMs that enables integration of\nthe standards and preferences of a large media organisation into the LLM\nitself. We combine a set of data and methods that build on recent breakthroughs\nin synthetic data generation, preference optimisation, and post-training model\nquantisation. Our unified approach mitigates bias and improves accuracy, while\npreserving reasoning capability, as measured against standard benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00307v1",
    "published_date": "2024-08-01 06:06:25 UTC",
    "updated_date": "2024-08-01 06:06:25 UTC"
  },
  {
    "arxiv_id": "2408.00295v1",
    "title": "Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck",
    "authors": [
      "Yuntao Shou",
      "Haozhi Lan",
      "Xiangyong Cao"
    ],
    "abstract": "Graph Neural Networks (GNNs) have received extensive research attention due\nto their powerful information aggregation capabilities. Despite the success of\nGNNs, most of them suffer from the popularity bias issue in a graph caused by a\nsmall number of popular categories. Additionally, real graph datasets always\ncontain incorrect node labels, which hinders GNNs from learning effective node\nrepresentations. Graph contrastive learning (GCL) has been shown to be\neffective in solving the above problems for node classification tasks. Most\nexisting GCL methods are implemented by randomly removing edges and nodes to\ncreate multiple contrasting views, and then maximizing the mutual information\n(MI) between these contrasting views to improve the node feature\nrepresentation. However, maximizing the mutual information between multiple\ncontrasting views may lead the model to learn some redundant information\nirrelevant to the node classification task. To tackle this issue, we propose an\neffective Contrastive Graph Representation Learning with Adversarial Cross-view\nReconstruction and Information Bottleneck (CGRL) for node classification, which\ncan adaptively learn to mask the nodes and edges in the graph to obtain the\noptimal graph structure representation. Furthermore, we innovatively introduce\nthe information bottleneck theory into GCLs to remove redundant information in\nmultiple contrasting views while retaining as much information as possible\nabout node classification. Moreover, we add noise perturbations to the original\nviews and reconstruct the augmented views by constructing adversarial views to\nimprove the robustness of node feature representation. Extensive experiments on\nreal-world public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.00295v1",
    "published_date": "2024-08-01 05:45:21 UTC",
    "updated_date": "2024-08-01 05:45:21 UTC"
  },
  {
    "arxiv_id": "2408.00290v1",
    "title": "Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network",
    "authors": [
      "Bin Cheng",
      "Jiaxuan Lu"
    ],
    "abstract": "With the advent of the era of foundation models, pre-training and fine-tuning\nhave become common paradigms. Recently, parameter-efficient fine-tuning has\ngarnered widespread attention due to its better balance between the number of\nlearnable parameters and performance. However, some current parameter-efficient\nfine-tuning methods only model a single modality and lack the utilization of\nstructural knowledge in downstream tasks. To address this issue, this paper\nproposes a multi-modal parameter-efficient fine-tuning method based on graph\nnetworks. Each image is fed into a multi-modal large language model (MLLM) to\ngenerate a text description. The image and its corresponding text description\nare then processed by a frozen image encoder and text encoder to generate image\nfeatures and text features, respectively. A graph is constructed based on the\nsimilarity of the multi-modal feature nodes, and knowledge and relationships\nrelevant to these features are extracted from each node. Additionally, Elastic\nWeight Consolidation (EWC) regularization is incorporated into the loss\nfunction to mitigate the problem of forgetting during task learning. The\nproposed model achieves test accuracies on the OxfordPets, Flowers102, and\nFood101 datasets that improve by 4.45%, 2.92%, and 0.23%, respectively. The\ncode is available at https://github.com/yunche0/GA-Net/tree/master.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00290v1",
    "published_date": "2024-08-01 05:24:20 UTC",
    "updated_date": "2024-08-01 05:24:20 UTC"
  },
  {
    "arxiv_id": "2408.00288v1",
    "title": "Gradient Harmonization in Unsupervised Domain Adaptation",
    "authors": [
      "Fuxiang Huang",
      "Suqi Song",
      "Lei Zhang"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) intends to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. Many current methods focus\non learning feature representations that are both discriminative for\nclassification and invariant across domains by simultaneously optimizing domain\nalignment and classification tasks. However, these methods often overlook a\ncrucial challenge: the inherent conflict between these two tasks during\ngradient-based optimization. In this paper, we delve into this issue and\nintroduce two effective solutions known as Gradient Harmonization, including GH\nand GH++, to mitigate the conflict between domain alignment and classification\ntasks. GH operates by altering the gradient angle between different tasks from\nan obtuse angle to an acute angle, thus resolving the conflict and trade-offing\nthe two tasks in a coordinated manner. Yet, this would cause both tasks to\ndeviate from their original optimization directions. We thus further propose an\nimproved version, GH++, which adjusts the gradient angle between tasks from an\nobtuse angle to a vertical angle. This not only eliminates the conflict but\nalso minimizes deviation from the original gradient directions. Finally, for\noptimization convenience and efficiency, we evolve the gradient harmonization\nstrategies into a dynamically weighted loss function using an integral operator\non the harmonized gradient. Notably, GH/GH++ are orthogonal to UDA and can be\nseamlessly integrated into most existing UDA models. Theoretical insights and\nexperimental analyses demonstrate that the proposed approaches not only enhance\npopular UDA baselines but also improve recent state-of-the-art models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE TPAMI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00288v1",
    "published_date": "2024-08-01 05:22:41 UTC",
    "updated_date": "2024-08-01 05:22:41 UTC"
  },
  {
    "arxiv_id": "2408.00280v1",
    "title": "Towards Scalable GPU-Accelerated SNN Training via Temporal Fusion",
    "authors": [
      "Yanchen Li",
      "Jiachun Li",
      "Kebin Sun",
      "Luziwei Leng",
      "Ran Cheng"
    ],
    "abstract": "Drawing on the intricate structures of the brain, Spiking Neural Networks\n(SNNs) emerge as a transformative development in artificial intelligence,\nclosely emulating the complex dynamics of biological neural networks. While\nSNNs show promising efficiency on specialized sparse-computational hardware,\ntheir practical training often relies on conventional GPUs. This reliance\nfrequently leads to extended computation times when contrasted with traditional\nArtificial Neural Networks (ANNs), presenting significant hurdles for advancing\nSNN research. To navigate this challenge, we present a novel temporal fusion\nmethod, specifically designed to expedite the propagation dynamics of SNNs on\nGPU platforms, which serves as an enhancement to the current significant\napproaches for handling deep learning tasks with SNNs. This method underwent\nthorough validation through extensive experiments in both authentic training\nscenarios and idealized conditions, confirming its efficacy and adaptability\nfor single and multi-GPU systems. Benchmarked against various existing SNN\nlibraries/implementations, our method achieved accelerations ranging from\n$5\\times$ to $40\\times$ on NVIDIA A100 GPUs. Publicly available experimental\ncodes can be found at https://github.com/EMI-Group/snn-temporal-fusion.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "International Conference on Artificial Neural Networks (ICANN) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00280v1",
    "published_date": "2024-08-01 04:41:56 UTC",
    "updated_date": "2024-08-01 04:41:56 UTC"
  },
  {
    "arxiv_id": "2408.00278v1",
    "title": "High Performance Im2win and Direct Convolutions using Three Tensor Layouts on SIMD Architectures",
    "authors": [
      "Xiang Fu",
      "Xinpeng Zhang",
      "Jixiang Ma",
      "Peng Zhao",
      "Shuai Lu",
      "Xu T. Liu"
    ],
    "abstract": "Convolution is the core component within deep neural networks and it is\ncomputationally intensive and time consuming. Tensor data layouts significantly\nimpact convolution operations in terms of memory access and computational\nefficiency. Yet, there is still a lack of comprehensive performance\ncharacterization on data layouts on SIMD architectures concerning convolution\nmethods. This paper proposes three novel data layouts for im2win convolution:\nNHWC, CHWN, and CHWN8, and introduces a set of general optimization techniques\nfor both direct and im2win convolutions. We compare the optimized im2win\nconvolution with the direct convolution and PyTorch's im2col-based convolution\nacross the aforementioned layouts on SIMD machines. The experiments\ndemonstrated that the im2win convolution with the new NHWC layout achieved up\nto 355% performance speedup over NCHW layout. Our optimizations also\nsignificantly improve the performance of both im2win and direct convolutions.\nOur optimized im2win and direct convolutions achieved up to 95% and 94% of\nmachine's theoretical peak performance, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00278v1",
    "published_date": "2024-08-01 04:37:03 UTC",
    "updated_date": "2024-08-01 04:37:03 UTC"
  },
  {
    "arxiv_id": "2408.00274v1",
    "title": "QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression",
    "authors": [
      "Wenshan Wang",
      "Yihang Wang",
      "Yixing Fan",
      "Huaming Liao",
      "Jiafeng Guo"
    ],
    "abstract": "In-context learning (ICL) capabilities are foundational to the success of\nlarge language models (LLMs). Recently, context compression has attracted\ngrowing interest since it can largely reduce reasoning complexities and\ncomputation costs of LLMs. In this paper, we introduce a novel Query-gUIded\naTtention cOmpression (QUITO) method, which leverages attention of the question\nover the contexts to filter useless information. Specifically, we take a\ntrigger token to calculate the attention distribution of the context in\nresponse to the question. Based on the distribution, we propose three different\nfiltering methods to satisfy the budget constraints of the context length. We\nevaluate the QUITO using two widely-used datasets, namely, NaturalQuestions and\nASQA. Experimental results demonstrate that QUITO significantly outperforms\nestablished baselines across various datasets and downstream LLMs, underscoring\nits effectiveness. Our code is available at\nhttps://github.com/Wenshansilvia/attention_compressor.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00274v1",
    "published_date": "2024-08-01 04:28:38 UTC",
    "updated_date": "2024-08-01 04:28:38 UTC"
  },
  {
    "arxiv_id": "2408.00264v1",
    "title": "Clover-2: Accurate Inference for Regressive Lightweight Speculative Decoding",
    "authors": [
      "Bin Xiao",
      "Lujun Gui",
      "Lei Su",
      "Weipeng Chen"
    ],
    "abstract": "Large Language Models (LLMs) frequently suffer from inefficiencies, largely\nattributable to the discord between the requirements of auto-regressive\ndecoding and the architecture of contemporary GPUs. Recently, regressive\nlightweight speculative decoding has garnered attention for its notable\nefficiency improvements in text generation tasks. This approach utilizes a\nlightweight regressive draft model, like a Recurrent Neural Network (RNN) or a\nsingle transformer decoder layer, leveraging sequential information to\niteratively predict potential tokens. Specifically, RNN draft models are\ncomputationally economical but tend to deliver lower accuracy, while attention\ndecoder layer models exhibit the opposite traits. This paper presents Clover-2,\nan advanced iteration of Clover, an RNN-based draft model designed to achieve\ncomparable accuracy to that of attention decoder layer models while maintaining\nminimal computational overhead. Clover-2 enhances the model architecture and\nincorporates knowledge distillation to increase Clover's accuracy and improve\noverall efficiency. We conducted experiments using the open-source Vicuna 7B\nand LLaMA3-Instruct 8B models. The results demonstrate that Clover-2 surpasses\nexisting methods across various model architectures, showcasing its efficacy\nand robustness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00264v1",
    "published_date": "2024-08-01 03:43:32 UTC",
    "updated_date": "2024-08-01 03:43:32 UTC"
  },
  {
    "arxiv_id": "2408.00257v1",
    "title": "RoCo:Robust Collaborative Perception By Iterative Object Matching and Pose Adjustment",
    "authors": [
      "Zhe Huang",
      "Shuo Wang",
      "Yongcai Wang",
      "Wanting Li",
      "Deying Li",
      "Lei Wang"
    ],
    "abstract": "Collaborative autonomous driving with multiple vehicles usually requires the\ndata fusion from multiple modalities. To ensure effective fusion, the data from\neach individual modality shall maintain a reasonably high quality. However, in\ncollaborative perception, the quality of object detection based on a modality\nis highly sensitive to the relative pose errors among the agents. It leads to\nfeature misalignment and significantly reduces collaborative performance. To\naddress this issue, we propose RoCo, a novel unsupervised framework to conduct\niterative object matching and agent pose adjustment. To the best of our\nknowledge, our work is the first to model the pose correction problem in\ncollaborative perception as an object matching task, which reliably associates\ncommon objects detected by different agents. On top of this, we propose a graph\noptimization process to adjust the agent poses by minimizing the alignment\nerrors of the associated objects, and the object matching is re-done based on\nthe adjusted agent poses. This process is carried out iteratively until\nconvergence. Experimental study on both simulated and real-world datasets\ndemonstrates that the proposed framework RoCo consistently outperforms existing\nrelevant methods in terms of the collaborative object detection performance,\nand exhibits highly desired robustness when the pose information of agents is\nwith high-level noise. Ablation studies are also provided to show the impact of\nits key parameters and components. The code is released at\nhttps://github.com/HuangZhe885/RoCo.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ACM MM2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00257v1",
    "published_date": "2024-08-01 03:29:33 UTC",
    "updated_date": "2024-08-01 03:29:33 UTC"
  },
  {
    "arxiv_id": "2408.00241v2",
    "title": "Multiple Greedy Quasi-Newton Methods for Saddle Point Problems",
    "authors": [
      "Minheng Xiao",
      "Shi Bo",
      "Zhizhong Wu"
    ],
    "abstract": "This paper introduces the Multiple Greedy Quasi-Newton (MGSR1-SP) method, a\nnovel approach to solving strongly-convex-strongly-concave (SCSC) saddle point\nproblems. Our method enhances the approximation of the squared indefinite\nHessian matrix inherent in these problems, significantly improving both\nstability and efficiency through iterative greedy updates. We provide a\nthorough theoretical analysis of MGSR1-SP, demonstrating its linear-quadratic\nconvergence rate. Numerical experiments conducted on AUC maximization and\nadversarial debiasing problems, compared with state-of-the-art algorithms,\nunderscore our method's enhanced convergence rate. These results affirm the\npotential of MGSR1-SP to improve performance across a broad spectrum of machine\nlearning applications where efficient and accurate Hessian approximations are\ncrucial.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to DOCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00241v2",
    "published_date": "2024-08-01 02:40:37 UTC",
    "updated_date": "2025-01-28 02:49:43 UTC"
  },
  {
    "arxiv_id": "2408.00230v2",
    "title": "Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models",
    "authors": [
      "Juntu Zhao",
      "Junyu Deng",
      "Yixin Ye",
      "Chongxuan Li",
      "Zhijie Deng",
      "Dequan Wang"
    ],
    "abstract": "Advancements in text-to-image diffusion models have broadened extensive\ndownstream practical applications, but such models often encounter misalignment\nissues between text and image. Taking the generation of a combination of two\ndisentangled concepts as an example, say given the prompt \"a tea cup of iced\ncoke\", existing models usually generate a glass cup of iced coke because the\niced coke usually co-occurs with the glass cup instead of the tea one during\nmodel training. The root of such misalignment is attributed to the confusion in\nthe latent semantic space of text-to-image diffusion models, and hence we refer\nto the \"a tea cup of iced coke\" phenomenon as Latent Concept Misalignment\n(LC-Mis). We leverage large language models (LLMs) to thoroughly investigate\nthe scope of LC-Mis, and develop an automated pipeline for aligning the latent\nsemantics of diffusion models to text prompts. Empirical assessments confirm\nthe effectiveness of our approach, substantially reducing LC-Mis errors and\nenhancing the robustness and versatility of text-to-image diffusion models. The\ncode and dataset are here: https://github.com/RossoneriZhao/iced_coke.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 18th European Conference on Computer Vision ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.00230v2",
    "published_date": "2024-08-01 01:54:17 UTC",
    "updated_date": "2024-08-05 08:36:20 UTC"
  },
  {
    "arxiv_id": "2408.00210v1",
    "title": "A Prior Embedding-Driven Architecture for Long Distance Blind Iris Recognition",
    "authors": [
      "Qi Xiong",
      "Xinman Zhang",
      "Jun Shen"
    ],
    "abstract": "Blind iris images, which result from unknown degradation during the process\nof iris recognition at long distances, often lead to decreased iris recognition\nrates. Currently, little existing literature offers a solution to this problem.\nIn response, we propose a prior embedding-driven architecture for long distance\nblind iris recognition. We first proposed a blind iris image restoration\nnetwork called Iris-PPRGAN. To effectively restore the texture of the blind\niris, Iris-PPRGAN includes a Generative Adversarial Network (GAN) used as a\nPrior Decoder, and a DNN used as the encoder. To extract iris features more\nefficiently, we then proposed a robust iris classifier by modifying the\nbottleneck module of InsightFace, which called Insight-Iris. A low-quality\nblind iris image is first restored by Iris-PPRGAN, then the restored iris image\nundergoes recognition via Insight-Iris. Experimental results on the public\nCASIA-Iris-distance dataset demonstrate that our proposed method significantly\nsuperior results to state-of-the-art blind iris restoration methods both\nquantitatively and qualitatively, Specifically, the recognition rate for\nlong-distance blind iris images reaches 90% after processing with our methods,\nrepresenting an improvement of approximately ten percentage points compared to\nimages without restoration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00210v1",
    "published_date": "2024-08-01 00:40:17 UTC",
    "updated_date": "2024-08-01 00:40:17 UTC"
  },
  {
    "arxiv_id": "2408.00203v1",
    "title": "OmniParser for Pure Vision Based GUI Agent",
    "authors": [
      "Yadong Lu",
      "Jianwei Yang",
      "Yelong Shen",
      "Ahmed Awadallah"
    ],
    "abstract": "The recent success of large vision language models shows great potential in\ndriving the agent system operating on user interfaces. However, we argue that\nthe power multimodal models like GPT-4V as a general agent on multiple\noperating systems across different applications is largely underestimated due\nto the lack of a robust screen parsing technique capable of: 1) reliably\nidentifying interactable icons within the user interface, and 2) understanding\nthe semantics of various elements in a screenshot and accurately associate the\nintended action with the corresponding region on the screen. To fill these\ngaps, we introduce \\textsc{OmniParser}, a comprehensive method for parsing user\ninterface screenshots into structured elements, which significantly enhances\nthe ability of GPT-4V to generate actions that can be accurately grounded in\nthe corresponding regions of the interface. We first curated an interactable\nicon detection dataset using popular webpages and an icon description dataset.\nThese datasets were utilized to fine-tune specialized models: a detection model\nto parse interactable regions on the screen and a caption model to extract the\nfunctional semantics of the detected elements. \\textsc{OmniParser}\nsignificantly improves GPT-4V's performance on ScreenSpot benchmark. And on\nMind2Web and AITW benchmark, \\textsc{OmniParser} with screenshot only input\noutperforms the GPT-4V baselines requiring additional information outside of\nscreenshot.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.00203v1",
    "published_date": "2024-08-01 00:00:43 UTC",
    "updated_date": "2024-08-01 00:00:43 UTC"
  }
]