{
  "date": "2024-08-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-23 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 更新聚焦于 AI 安全、多模态模型和强化学习等领域，亮点包括 LLM 的后门攻击基准和多任务提示调优，令人印象深刻的是 BackdoorLLM（针对 LLM 后门攻击的全面基准）和 LLM-PBE（评估 LLM 数据隐私风险），这些论文突显了 AI 在实际应用中的潜在风险和创新潜力。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论 AI 安全、LLM 和多模态模型等高话题度文章，再快速掠过其他领域。将相关主题归类讨论，保留核心学术术语如“Graph Neural Network”（GNN）和“Reinforcement Learning”（RL），并控制篇幅以突出主要贡献。\n\n### AI 安全与 LLM 应用\n- **BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models（BackdoorLLM: 针对大型语言模型的后门攻击全面基准）**  \n  这篇论文提出 BackdoorLLM 基准，用于评估 LLM 的后门攻击，包括数据投毒和隐藏状态攻击。主要贡献是通过超过 200 次实验，揭示 LLM 在各种场景下的漏洞，强调了 AI 安全的重要性。\n\n- **LLM-PBE: Assessing Data Privacy in Large Language Models（LLM-PBE: 评估大型语言模型中的数据隐私）**  \n  作者包括知名学者 Dawn Song，该论文引入 LLM-PBE 工具包，评估 LLM 的数据隐私风险。主要发现是通过实验分析模型大小和数据特征的影响，提供全面生命周期的隐私评估框架。\n\n- **SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks（SpeechPrompt: 用于语音处理任务的语音语言模型提示）**  \n  这篇论文探索提示技术在语音处理中的应用，主要贡献是提出 SpeechPrompt 框架，将语音单元转换为多任务生成形式，提升了语音分类和生成的性能。\n\n- **Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews（Instruct-DeBERTa: 针对文本评论的方面级情感分析混合方法）**  \n  论文提出 Instruct-DeBERTa 模型，结合指令调优和 DeBERTa 架构。主要发现是通过混合方法提升了方面提取和情感分类的准确性，在多领域数据集上表现出色。\n\n- **CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers（CodeRefine: 增强研究论文 LLM 生成代码的管道）**  \n  这篇快速讨论：论文设计 CodeRefine 框架，用于自动优化 LLM 生成的代码，主要贡献是通过回顾性检索增强代码准确性，适用于科研代码实现。\n\n### 多模态模型与计算机视觉\n- **FreqFusion: Frequency-aware Feature Fusion for Dense Image Prediction（FreqFusion: 基于频率感知特征融合的密集图像预测）**  \n  论文提出 FreqFusion 方法，主要贡献是通过自适应滤波器融合局部纹理和长距离依赖，提升了图像分割任务的边界精度和一致性。\n\n- **CrackSCF: Staircase Cascaded Fusion of Lightweight Local Pattern Recognition and Long-Range Dependencies for Structural Crack Segmentation（CrackSCF: 用于结构裂缝分割的阶梯级联融合轻量局部模式识别和长距离依赖）**  \n  这篇论文引入 CrackSCF 网络，主要发现是结合轻量卷积和长距离提取器，提高了裂缝分割的准确性，同时减少计算资源，适用于边缘设备。\n\n- **FST-Mamba: Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis（FST-Mamba: 用于 fMRI 分析的层次时空状态空间建模）**  \n  主要贡献是提出 FST-Mamba 模型，使用 Mamba 架构处理 fMRI 数据的时间和空间依赖，提升了脑网络分类的性能。\n\n- **MAEMI: Foundational Model for Electron Micrograph Analysis（MAEMI: 用于电子显微镜图像分析的基础模型）**  \n  论文开发 MAEMI 框架，主要发现是通过知识蒸馏和指令调优，提高了半导体图像分析的准确性和适应性。\n\n### 强化学习与决策优化\n- **DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation（DutyTTE: 解析原点-目的地旅行时间估计的不确定性）**  \n  这篇论文提出 DutyTTE 方法，主要贡献是通过因果推理和不确定性量化，提升了交通预测的鲁棒性。\n\n- **CRUXEval-X: A Benchmark for Multilingual Code Reasoning（CRUXEval-X: 多语言代码推理基准）**  \n  论文构建 CRUXEval-X 基准，主要发现是评估 LLM 在多语言代码任务中的性能，揭示了跨语言泛化能力。\n\n其他领域论文较多，但相对不那么核心，我将快速掠过，仅列出标题和关键点：\n\n- **Applying Graph Neural Network to SupplyGraph for Supply Chain Network（应用图神经网络到 SupplyGraph 用于供应链网络）**  \n  主要贡献是使用 GNN 改进供应链预测，GAT 模型表现出最佳性能。\n\n- **DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction（DrugAgent: 基于多代理大型语言模型的药物-靶点交互预测推理）**  \n  提出 DrugAgent 系统，主要发现是通过多代理框架提升药物交互预测的准确性。\n\n- **N-DriverMotion: Driver Motion Learning and Prediction Using an Event-Based Camera（N-DriverMotion: 使用事件相机进行驾驶员动作学习和预测）**  \n  快速提及：开发高分辨率数据集和 SNN 模型，提升了驾驶员动作识别的实时性。\n\n- **TopoGDN: Enhancing Graph Attention Networks with Topological Analysis for Anomaly Detection（TopoGDN: 通过拓扑分析增强图注意力网络用于异常检测）**  \n  主要发现是改进 GNN 用于时间序列异常检测。\n\n剩余论文如量子计算、交通预测和生物应用等，主题较分散且影响较小，我仅简要注记：例如，Quantum Circuit Design（提出优化量子电路的方法）和 Traffic Prediction（使用深度学习提升预测准确性），这些工作虽有技术创新，但未见显著突破，故不展开讨论。\n\n总之，今天的更新强调了 AI 安全和多模态应用的紧迫性，相关论文为未来研究提供了宝贵基准和框架。读者可关注 LLM 领域，以发掘潜在风险和优化机会。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2408.14501v1",
      "title": "Applying graph neural network to SupplyGraph for supply chain network",
      "title_zh": "翻译失败",
      "authors": [
        "Kihwan Han"
      ],
      "abstract": "Supply chain networks describe interactions between products, manufacture\nfacilities, storages in the context of supply and demand of the products.\nSupply chain data are inherently under graph structure; thus, it can be fertile\nground for applications of graph neural network (GNN). Very recently, supply\nchain dataset, SupplyGraph, has been released to the public. Though the\nSupplyGraph dataset is valuable given scarcity of publicly available data,\nthere was less clarity on description of the dataset, data quality assurance\nprocess, and hyperparameters of the selected models. Further, for\ngeneralizability of findings, it would be more convincing to present the\nfindings by performing statistical analyses on the distribution of errors\nrather than showing the average value of the errors. Therefore, this study\nassessed the supply chain dataset, SupplyGraph, with better clarity on analyses\nprocesses, data quality assurance, machine learning (ML) model specifications.\nAfter data quality assurance procedures, this study compared performance of\nMultilayer Perceptions (MLP), Graph Convolution Network (GCN), and Graph\nAttention Network (GAT) on a demanding forecasting task while matching\nhyperparameters as feasible as possible. The analyses revealed that GAT\nperformed best, followed by GCN and MLP. Those performance improvements were\nstatistically significant at $\\alpha = 0.05$ after correction for multiple\ncomparisons. This study also discussed several considerations in applying GNN\nto supply chain networks. The current study reinforces the previous study in\nsupply chain benchmark dataset with respect to description of the dataset and\nmethodology, so that the future research in applications of GNN to supply chain\nbecomes more reproducible.",
      "tldr_zh": "本研究评估了 SupplyGraph 数据集，将 Graph Neural Network (GNN) 应用于供应链网络的需求预测任务，以解决数据集描述不清晰和数据质量问题。研究者首先进行了数据质量保证，然后比较了 Multilayer Perceptions (MLP)、Graph Convolution Network (GCN) 和 Graph Attention Network (GAT) 的性能，并在统计分析中发现 GAT 表现最佳，其次是 GCN 和 MLP，这些改进在 α = 0.05 水平上显著。最终，该研究讨论了应用 GNN 到供应链网络的考虑，并提升了研究的再现性，为未来相关研究提供了更可靠的基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.14501v1",
      "published_date": "2024-08-23 23:42:18 UTC",
      "updated_date": "2024-08-23 23:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:06:36.970718"
    },
    {
      "arxiv_id": "2408.13406v1",
      "title": "Optimizing Collaboration of LLM based Agents for Finite Element Analysis",
      "title_zh": "优化基于 LLM 的代理合作以用于有限元分析",
      "authors": [
        "Chuan Tian",
        "Yilei Zhang"
      ],
      "abstract": "This paper investigates the interactions between multiple agents within Large\nLanguage Models (LLMs) in the context of programming and coding tasks. We\nutilize the AutoGen framework to facilitate communication among agents,\nevaluating different configurations based on the success rates from 40 random\nruns for each setup. The study focuses on developing a flexible automation\nframework for applying the Finite Element Method (FEM) to solve linear elastic\nproblems. Our findings emphasize the importance of optimizing agent roles and\nclearly defining their responsibilities, rather than merely increasing the\nnumber of agents. Effective collaboration among agents is shown to be crucial\nfor addressing general FEM challenges. This research demonstrates the potential\nof LLM multi-agent systems to enhance computational automation in simulation\nmethodologies, paving the way for future advancements in engineering and\nartificial intelligence.",
      "tldr_zh": "本研究探讨了基于 Large Language Models (LLMs) 的多代理系统在编程任务中的协作优化，特别针对 Finite Element Method (FEM) 的应用。研究利用 AutoGen 框架评估不同代理配置，通过 40 次随机运行分析成功率，开发了一个灵活的自动化框架来解决线性弹性问题。结果强调，优化代理角色和明确职责比增加代理数量更重要，有效协作能显著提升 FEM 挑战的处理能力。该工作展示了 LLM 多代理系统在增强工程模拟计算自动化的潜力，为人工智能和工程领域的未来进步奠定基础。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13406v1",
      "published_date": "2024-08-23 23:11:08 UTC",
      "updated_date": "2024-08-23 23:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:06:48.326756"
    },
    {
      "arxiv_id": "2408.13399v2",
      "title": "Transforming Location Retrieval at Airbnb: A Journey from Heuristics to Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Davis",
        "Huiji Gao",
        "Thomas Legrand",
        "Weiwei Guo",
        "Malay Haldar",
        "Alex Deng",
        "Han Zhao",
        "Liwei He",
        "Sanjeev Katariya"
      ],
      "abstract": "The Airbnb search system grapples with many unique challenges as it continues\nto evolve. We oversee a marketplace that is nuanced by geography, diversity of\nhomes, and guests with a variety of preferences. Crafting an efficient search\nsystem that can accommodate diverse guest needs, while showcasing relevant\nhomes lies at the heart of Airbnb's success. Airbnb search has many challenges\nthat parallel other recommendation and search systems but it has a unique\ninformation retrieval problem, upstream of ranking, called location retrieval.\nIt requires defining a topological map area that is relevant to the searched\nquery for homes listing retrieval. The purpose of this paper is to demonstrate\nthe methodology, challenges, and impact of building a machine learning based\nlocation retrieval product from the ground up. Despite the lack of suitable,\nprevalent machine learning based approaches, we tackle cold start,\ngeneralization, differentiation and algorithmic bias. We detail the efficacy of\nheuristics, statistics, machine learning, and reinforcement learning approaches\nto solve these challenges, particularly for systems that are often unexplored\nby current literature.",
      "tldr_zh": "Airbnb 的搜索系统面临独特挑战，特别是位置检索问题，需要为用户查询定义相关的拓扑地图区域，以精准检索房屋列表。该论文详细介绍了从启发式方法到强化学习（Reinforcement Learning）的演进过程，探讨了如何处理冷启动（cold start）、泛化和算法偏差等难题，并比较了统计学、机器学习（Machine Learning）和强化学习等方法的有效性。通过这些创新方法，Airbnb 提升了搜索系统的性能和适用性，为类似推荐系统提供了新见解。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Published at CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13399v2",
      "published_date": "2024-08-23 22:51:14 UTC",
      "updated_date": "2024-10-28 15:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:07:00.049731"
    },
    {
      "arxiv_id": "2408.13379v2",
      "title": "N-DriverMotion: Driver motion learning and prediction using an event-based camera and directly trained spiking neural networks on Loihi 2",
      "title_zh": "N-DriverMotion：使用事件相机和在 Loihi 2 上直接训练的脉冲神经",
      "authors": [
        "Hyo Jong Chung",
        "Byungkon Kang",
        "Yoonseok Yang"
      ],
      "abstract": "Driver motion recognition is a principal factor in ensuring the safety of\ndriving systems. This paper presents a novel system for learning and predicting\ndriver motions and an event-based high-resolution (1280x720) dataset,\nN-DriverMotion, newly collected to train on a neuromorphic vision system. The\nsystem comprises an event-based camera that generates the first high-resolution\ndriver motion dataset representing spike inputs and efficient spiking neural\nnetworks (SNNs) that are effective in training and predicting the driver's\ngestures. The event dataset consists of 13 driver motion categories classified\nby direction (front, side), illumination (bright, moderate, dark), and\nparticipant. A novel simplified four-layer convolutional spiking neural network\n(CSNN) that we proposed was directly trained using the high-resolution dataset\nwithout any time-consuming preprocessing. This enables efficient adaptation to\non-device SNNs for real-time inference on high-resolution event-based streams.\nCompared with recent gesture recognition systems adopting neural networks for\nvision processing, the proposed neuromorphic vision system achieves comparable\naccuracy, 94.04\\%, in recognizing driver motions with the CSNN architecture.\nOur proposed CSNN and the dataset can be used to develop safer and more\nefficient driver monitoring systems for autonomous vehicles or edge devices\nrequiring an efficient neural network architecture.",
      "tldr_zh": "本研究提出N-DriverMotion系统，用于学习和预测驾驶员动作，以提升驾驶安全。该系统利用event-based camera采集高分辨率（1280x720）数据集，包括13个驾驶员动作类别，按方向（front, side）、光照（bright, moderate, dark）和参与者分类，并采用直接训练的spiking neural networks (SNNs)，特别是新提出的简化四层convolutional SNN (CSNN)，在Loihi 2上实现高效实时推理。实验结果显示，该系统在识别驾驶员动作时达到94.04%的准确率，与传统神经网络系统相当。N-DriverMotion及其数据集可用于开发更安全、高效的驾驶员监控系统，适用于自动驾驶车辆或边缘设备。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45",
        "I.4.8; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in IEEE Open Journal of Vehicular Technology\n  (OJVT) on 18 November 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13379v2",
      "published_date": "2024-08-23 21:25:16 UTC",
      "updated_date": "2024-11-18 20:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:07:13.108972"
    },
    {
      "arxiv_id": "2408.13378v4",
      "title": "DrugAgent: Multi-Agent Large Language Model-Based Reasoning for Drug-Target Interaction Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yoshitaka Inoue",
        "Tianci Song",
        "Xinling Wang",
        "Augustin Luna",
        "Tianfan Fu"
      ],
      "abstract": "Advancements in large language models (LLMs) allow them to address diverse\nquestions using human-like interfaces. Still, limitations in their training\nprevent them from answering accurately in scenarios that could benefit from\nmultiple perspectives. Multi-agent systems allow the resolution of questions to\nenhance result consistency and reliability. While drug-target interaction (DTI)\nprediction is important for drug discovery, existing approaches face challenges\ndue to complex biological systems and the lack of interpretability needed for\nclinical applications. DrugAgent is a multi-agent LLM system for DTI prediction\nthat combines multiple specialized perspectives with transparent reasoning. Our\nsystem adapts and extends existing multi-agent frameworks by (1) applying\ncoordinator-based architecture to the DTI domain, (2) integrating\ndomain-specific data sources, including ML predictions, knowledge graphs, and\nliterature evidence, and (3) incorporating Chain-of-Thought (CoT) and ReAct\n(Reason+Act) frameworks for transparent DTI reasoning. We conducted\ncomprehensive experiments using a kinase inhibitor dataset, where our\nmulti-agent LLM method outperformed the non-reasoning multi-agent model (GPT-4o\nmini) by 45% in F1 score (0.514 vs 0.355). Through ablation studies, we\ndemonstrated the contributions of each agent, with the AI agent being the most\nimpactful, followed by the KG agent and search agent. Most importantly, our\napproach provides detailed, human-interpretable reasoning for each prediction\nby combining evidence from multiple sources - a critical feature for biomedical\napplications where understanding the rationale behind predictions is essential\nfor clinical decision-making and regulatory compliance. Code is available at\nhttps://anonymous.4open.science/r/DrugAgent-B2EA.",
      "tldr_zh": "该研究提出了DrugAgent，一种基于多智能体大型语言模型(LLMs)的系统，用于药物-目标交互(DTI)预测，通过整合多个专业视角和透明推理来克服现有方法的局限性。DrugAgent 采用基于协调器的架构，结合领域特定数据源（如 ML 预测、知识图谱和文献证据），并融入 Chain-of-Thought (CoT) 和 ReAct 框架，实现可解释的 DTI 推理。在激酶抑制剂数据集上的实验中，该系统比非推理多智能体模型(GPT-4o mini) 的 F1 分数提高了 45%（0.514 vs 0.355），消融研究显示 AI 智能体贡献最大，其次是 KG 智能体和搜索智能体。该方法通过多源证据提供详细的人类可解释推理，对于生物医学应用中的临床决策和合规性具有重要意义。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.13378v4",
      "published_date": "2024-08-23 21:24:59 UTC",
      "updated_date": "2025-04-07 19:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:07:26.235740"
    },
    {
      "arxiv_id": "2408.13376v3",
      "title": "Reduce, Reuse, Recycle: Categories for Compositional Reinforcement Learning",
      "title_zh": "减少、重复使用、回收：用于合成强化学习的范畴",
      "authors": [
        "Georgios Bakirtzis",
        "Michail Savvas",
        "Ruihan Zhao",
        "Sandeep Chinchali",
        "Ufuk Topcu"
      ],
      "abstract": "In reinforcement learning, conducting task composition by forming cohesive,\nexecutable sequences from multiple tasks remains challenging. However, the\nability to (de)compose tasks is a linchpin in developing robotic systems\ncapable of learning complex behaviors. Yet, compositional reinforcement\nlearning is beset with difficulties, including the high dimensionality of the\nproblem space, scarcity of rewards, and absence of system robustness after task\ncomposition. To surmount these challenges, we view task composition through the\nprism of category theory -- a mathematical discipline exploring structures and\ntheir compositional relationships. The categorical properties of Markov\ndecision processes untangle complex tasks into manageable sub-tasks, allowing\nfor strategical reduction of dimensionality, facilitating more tractable reward\nstructures, and bolstering system robustness. Experimental results support the\ncategorical theory of reinforcement learning by enabling skill reduction,\nreuse, and recycling when learning complex robotic arm tasks.",
      "tldr_zh": "本文提出了一种基于category theory的框架，用于解决compositional reinforcement learning中的挑战，包括任务组合的高维问题、奖励稀缺性和系统鲁棒性不足。该方法通过category theory的属性，将Markov decision processes分解为可管理的子任务，从而实现任务维度的减少、奖励结构的简化以及整体系统的增强。实验结果验证了这一理论，在复杂机器人臂任务中成功实现了技能的reduce, reuse和recycle。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.CT"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13376v3",
      "published_date": "2024-08-23 21:23:22 UTC",
      "updated_date": "2025-03-11 22:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:07:37.133886"
    },
    {
      "arxiv_id": "2409.00070v1",
      "title": "Learning to Plan Long-Term for Language Modeling",
      "title_zh": "用于语言建模的长期规划学习",
      "authors": [
        "Florian Mai",
        "Nathan Cornille",
        "Marie-Francine Moens"
      ],
      "abstract": "Modern language models predict the next token in the sequence by considering\nthe past text through a powerful function such as attention. However, language\nmodels have no explicit mechanism that allows them to spend computation time\nfor planning long-distance future text, leading to a suboptimal token\nprediction. In this paper, we propose a planner that predicts a latent plan for\nmany sentences into the future. By sampling multiple plans at once, we\ncondition the language model on an accurate approximation of the distribution\nof text continuations, which leads to better next token prediction accuracy. In\neffect, this allows trading computation time for prediction accuracy.",
      "tldr_zh": "本文研究了语言模型在预测下一个 token 时存在的不足，即缺乏显式机制来规划长期未来文本，导致预测准确性 suboptimal。作者提出了一种 planner，用于预测未来多个句子的 latent plan，通过一次性采样多个计划，让语言模型基于文本延续分布的准确近似来提升下一个 token 的预测精度。这种方法有效地实现了用额外计算时间换取预测性能的改进，为语言模型的长程规划提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.00070v1",
      "published_date": "2024-08-23 21:18:10 UTC",
      "updated_date": "2024-08-23 21:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:07:49.910573"
    },
    {
      "arxiv_id": "2408.13372v1",
      "title": "Understanding Defects in Generated Codes by Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Mohammadi Esfahani",
        "Nafiseh Kahani",
        "Samuel A. Ajila"
      ],
      "abstract": "This study investigates the reliability of code generation by Large Language\nModels (LLMs), focusing on identifying and analyzing defects in the generated\ncode. Despite the advanced capabilities of LLMs in automating code generation,\nensuring the accuracy and functionality of the output remains a significant\nchallenge. By using a structured defect classification method to understand\ntheir nature and origins this study categorizes and analyzes 367 identified\ndefects from code snippets generated by LLMs, with a significant proportion\nbeing functionality and algorithm errors. These error categories indicate key\nareas where LLMs frequently fail, underscoring the need for targeted\nimprovements. To enhance the accuracy of code generation, this paper\nimplemented five prompt engineering techniques, including Scratchpad Prompting,\nProgram of Thoughts Prompting, Chain-of-Thought Prompting, Chain of Code\nPrompting, and Structured Chain-of-Thought Prompting. These techniques were\napplied to refine the input prompts, aiming to reduce ambiguities and improve\nthe models' accuracy rate. The research findings suggest that precise and\nstructured prompting significantly mitigates common defects, thereby increasing\nthe reliability of LLM-generated code.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)在代码生成中的可靠性，通过结构化的缺陷分类方法分析了367个生成的代码缺陷，其中功能性和算法错误占主要比例，揭示了LLMs的常见失败领域。论文实施了五种提示工程技术，包括Scratchpad Prompting、Program of Thoughts Prompting、Chain-of-Thought Prompting、Chain of Code Prompting和Structured Chain-of-Thought Prompting，以优化输入提示、减少歧义并提升模型准确率。研究发现，这些技术能显著降低缺陷发生率，从而提高LLMs生成代码的可靠性和整体性能。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13372v1",
      "published_date": "2024-08-23 21:10:09 UTC",
      "updated_date": "2024-08-23 21:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:08:00.650760"
    },
    {
      "arxiv_id": "2408.13366v1",
      "title": "CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers",
      "title_zh": "翻译失败",
      "authors": [
        "Ekaterina Trofimova",
        "Emil Sataev",
        "Abhijit Singh Jowhari"
      ],
      "abstract": "This paper presents CodeRefine, a novel framework for automatically\ntransforming research paper methodologies into functional code using Large\nLanguage Models (LLMs). Our multi-step approach first extracts and summarizes\nkey text chunks from papers, analyzes their code relevance, and creates a\nknowledge graph using a predefined ontology. Code is then generated from this\nstructured representation and enhanced through a proposed retrospective\nretrieval-augmented generation approach. CodeRefine addresses the challenge of\nbridging theoretical research and practical implementation, offering a more\naccurate alternative to LLM zero-shot prompting. Evaluations on diverse\nscientific papers demonstrate CodeRefine's ability to improve code\nimplementation from the paper, potentially accelerating the adoption of\ncutting-edge algorithms in real-world applications.",
      "tldr_zh": "该研究提出CodeRefine，一种创新框架，利用Large Language Models (LLMs)自动将研究论文的方法论转化为功能代码。该框架采用多步管道：首先提取并总结论文的关键文本块，分析其代码相关性，并基于预定义的本体构建知识图；随后生成代码并通过retrospective retrieval-augmented generation方法进行增强，以解决理论与实际实现之间的鸿沟。评估结果显示，CodeRefine在多样化科学论文上显著提升代码实现的准确性，有望加速前沿算法在实际应用的采用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13366v1",
      "published_date": "2024-08-23 20:51:04 UTC",
      "updated_date": "2024-08-23 20:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:08:22.442814"
    },
    {
      "arxiv_id": "2408.13364v2",
      "title": "Reconciling Different Theories of Learning with an Agent-based Model of Procedural Learning",
      "title_zh": "通过基于代理的程序性学习模型调和不同的学习理论",
      "authors": [
        "Sina Rismanchian",
        "Shayan Doroudi"
      ],
      "abstract": "Computational models of human learning can play a significant role in\nenhancing our knowledge about nuances in theoretical and qualitative learning\ntheories and frameworks. There are many existing frameworks in educational\nsettings that have shown to be verified using empirical studies, but at times\nwe find these theories make conflicting claims or recommendations for\ninstruction. In this study, we propose a new computational model of human\nlearning, Procedural ABICAP, that reconciles the ICAP,\nKnowledge-Learning-Instruction (KLI), and cognitive load theory (CLT)\nframeworks for learning procedural knowledge. ICAP assumes that constructive\nlearning generally yields better learning outcomes, while theories such as KLI\nand CLT claim that this is not always true. We suppose that one reason for this\nmay be that ICAP is primarily used for conceptual learning and is\nunderspecified as a framework for thinking about procedural learning. We show\nhow our computational model, both by design and through simulations, can be\nused to reconcile different results in the literature. More generally, we\nposition our computational model as an executable theory of learning that can\nbe used to simulate various educational settings.",
      "tldr_zh": "本研究提出了一种新的计算模型Procedural ABICAP，用于协调ICAP、Knowledge-Learning-Instruction (KLI) 和cognitive load theory (CLT)等学习理论在程序性学习中的冲突。ICAP假设建设性学习通常产生更好结果，但KLI和CLT认为这并非总是成立，该模型通过代理为基础的设计和模拟实验，调和了这些理论的差异。结果显示，Procedural ABICAP能模拟各种教育场景，作为一种可执行的学习理论，提升了对程序性学习的理解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13364v2",
      "published_date": "2024-08-23 20:45:14 UTC",
      "updated_date": "2025-04-11 21:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:08:25.461095"
    },
    {
      "arxiv_id": "2408.13359v2",
      "title": "Power Scheduler: A Batch Size and Token Number Agnostic Learning Rate Scheduler",
      "title_zh": "Power Scheduler：一种对批量大小和令牌数量不敏感的学习率调度器",
      "authors": [
        "Yikang Shen",
        "Matthew Stallone",
        "Mayank Mishra",
        "Gaoyuan Zhang",
        "Shawn Tan",
        "Aditya Prasad",
        "Adriana Meza Soria",
        "David D. Cox",
        "Rameswar Panda"
      ],
      "abstract": "Finding the optimal learning rate for language model pretraining is a\nchallenging task. This is not only because there is a complicated correlation\nbetween learning rate, batch size, number of training tokens, model size, and\nother hyperparameters but also because it is prohibitively expensive to perform\na hyperparameter search for large language models with Billions or Trillions of\nparameters. Recent studies propose using small proxy models and small corpus to\nperform hyperparameter searches and transposing the optimal parameters to large\nmodels and large corpus. While the zero-shot transferability is theoretically\nand empirically proven for model size related hyperparameters, like depth and\nwidth, the zero-shot transfer from small corpus to large corpus is\nunderexplored. In this paper, we study the correlation between optimal learning\nrate, batch size, and number of training tokens for the recently proposed WSD\nscheduler. After thousands of small experiments, we found a power-law\nrelationship between variables and demonstrated its transferability across\nmodel sizes. Based on the observation, we propose a new learning rate\nscheduler, Power scheduler, that is agnostic about the number of training\ntokens and batch size. The experiment shows that combining the Power scheduler\nwith Maximum Update Parameterization (muP) can consistently achieve impressive\nperformance with one set of hyperparameters regardless of the number of\ntraining tokens, batch size, model size, and even model architecture. Our 3B\ndense and MoE models trained with the Power scheduler achieve comparable\nperformance as state-of-the-art small language models. We open-source these\npretrained models at https://ibm.biz/BdKhLa.",
      "tldr_zh": "这篇论文探讨了语言模型预训练中优化 learning rate 的挑战，强调了其与 batch size、number of training tokens、模型大小等超参数的复杂相关性，以及进行超参数搜索的成本高问题。研究者通过数千次小实验发现了变量间的 power-law relationship，并证明了其在不同模型大小间的可转移性，从而提出 Power scheduler，一种不依赖于 training tokens 和 batch size 的学习 rate 调度器。实验结果显示，将 Power scheduler 与 Maximum Update Parameterization (muP) 结合后，可在各种训练设置下使用同一组超参数实现出色性能，他们的 3B 密集和 MoE 模型性能与最先进的小语言模型相当，并已开源模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13359v2",
      "published_date": "2024-08-23 20:22:20 UTC",
      "updated_date": "2024-09-11 20:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:08:49.340786"
    },
    {
      "arxiv_id": "2408.13355v1",
      "title": "Disentangled Training with Adversarial Examples For Robust Small-footprint Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Wang",
        "Li Wan",
        "Biqiao Zhang",
        "Yiteng Huang",
        "Shang-Wen Li",
        "Ming Sun",
        "Xin Lei",
        "Zhaojun Yang"
      ],
      "abstract": "A keyword spotting (KWS) engine that is continuously running on device is\nexposed to various speech signals that are usually unseen before. It is a\nchallenging problem to build a small-footprint and high-performing KWS model\nwith robustness under different acoustic environments. In this paper, we\nexplore how to effectively apply adversarial examples to improve KWS\nrobustness. We propose datasource-aware disentangled learning with adversarial\nexamples to reduce the mismatch between the original and adversarial data as\nwell as the mismatch across original training datasources. The KWS model\narchitecture is based on depth-wise separable convolution and a simple\nattention module. Experimental results demonstrate that the proposed learning\nstrategy improves false reject rate by $40.31%$ at $1%$ false accept rate on\nthe internal dataset, compared to the strongest baseline without using\nadversarial examples. Our best-performing system achieves $98.06%$ accuracy on\nthe Google Speech Commands V1 dataset.",
      "tldr_zh": "本文提出了一种基于对抗样本(adversarial examples)的分离训练(disentangled learning)策略，以提升小型关键词检测(KWS)模型在不同声学环境下的鲁棒性。该方法采用数据源感知(datasource-aware)训练，减少原始数据与对抗数据之间的不匹配，同时优化模型架构，使用深度可分离卷积(depth-wise separable convolution)和简单注意力模块(attention module)。实验结果显示，与不使用对抗样本的基线相比，该策略在内部数据集上将假拒率(false reject rate)改善了40.31%（在1%假接受率(false accept rate)下），并在Google Speech Commands V1数据集上实现98.06%的准确率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13355v1",
      "published_date": "2024-08-23 20:03:51 UTC",
      "updated_date": "2024-08-23 20:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:08:51.732148"
    },
    {
      "arxiv_id": "2409.00069v1",
      "title": "How to Measure Human-AI Prediction Accuracy in Explainable AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sujay Koujalgi",
        "Andrew Anderson",
        "Iyadunni Adenuga",
        "Shikha Soneji",
        "Rupika Dikkala",
        "Teresita Guzman Nader",
        "Leo Soccio",
        "Sourav Panda",
        "Rupak Kumar Das",
        "Margaret Burnett",
        "Jonathan Dodge"
      ],
      "abstract": "Assessing an AI system's behavior-particularly in Explainable AI Systems-is\nsometimes done empirically, by measuring people's abilities to predict the\nagent's next move-but how to perform such measurements? In empirical studies\nwith humans, an obvious approach is to frame the task as binary (i.e.,\nprediction is either right or wrong), but this does not scale. As output spaces\nincrease, so do floor effects, because the ratio of right answers to wrong\nanswers quickly becomes very small. The crux of the problem is that the binary\nframing is failing to capture the nuances of the different degrees of\n\"wrongness.\" To address this, we begin by proposing three mathematical bases\nupon which to measure \"partial wrongness.\" We then uses these bases to perform\ntwo analyses on sequential decision-making domains: the first is an in-lab\nstudy with 86 participants on a size-36 action space; the second is a\nre-analysis of a prior study on a size-4 action space. Other researchers\nadopting our operationalization of the prediction task and analysis methodology\nwill improve the rigor of user studies conducted with that task, which is\nparticularly important when the domain features a large output space.",
      "tldr_zh": "这篇论文探讨了在 Explainable AI 系统中的人类-AI 预测准确性测量问题，指出传统的二元评估方法（正确或错误）在大型输出空间中容易出现地板效应，因为它忽略了“错误”的不同程度。作者提出三种数学基础来量化“部分错误”，并通过一个实验室研究（涉及86名参与者和36个动作空间）和对先前研究的重新分析（4个动作空间）进行验证。最终，这方法提升了用户研究的严谨性，特别是适用于输出空间较大的顺序决策领域。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "D.2.8"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00069v1",
      "published_date": "2024-08-23 19:52:37 UTC",
      "updated_date": "2024-08-23 19:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:09:05.324096"
    },
    {
      "arxiv_id": "2408.13341v1",
      "title": "Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-Learning and Disentangled Training With Adversarial Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Wang",
        "John H. L. Hansen"
      ],
      "abstract": "Advances in automatic speaker verification (ASV) promote research into the\nformulation of spoofing detection systems for real-world applications. The\nperformance of ASV systems can be degraded severely by multiple types of\nspoofing attacks, namely, synthetic speech (SS), voice conversion (VC), replay,\ntwins and impersonation, especially in the case of unseen synthetic spoofing\nattacks. A reliable and robust spoofing detection system can act as a security\ngate to filter out spoofing attacks instead of having them reach the ASV\nsystem. A weighted additive angular margin loss is proposed to address the data\nimbalance issue, and different margins has been assigned to improve\ngeneralization to unseen spoofing attacks in this study. Meanwhile, we\nincorporate a meta-learning loss function to optimize differences between the\nembeddings of support versus query set in order to learn a\nspoofing-category-independent embedding space for utterances. Furthermore, we\ncraft adversarial examples by adding imperceptible perturbations to spoofing\nspeech as a data augmentation strategy, then we use an auxiliary batch\nnormalization (BN) to guarantee that corresponding normalization statistics are\nperformed exclusively on the adversarial examples. Additionally, A simple\nattention module is integrated into the residual block to refine the feature\nextraction process. Evaluation results on the Logical Access (LA) track of the\nASVspoof 2019 corpus provides confirmation of our proposed approaches'\neffectiveness in terms of a pooled EER of 0.87%, and a min t-DCF of 0.0277.\nThese advancements offer effective options to reduce the impact of spoofing\nattacks on voice recognition/authentication systems.",
      "tldr_zh": "该研究旨在提升合成音频欺骗检测系统的鲁棒性，特别是针对未见过的合成语音 (SS) 和语音转换 (VC) 等攻击。研究提出使用 weighted additive angular margin loss 处理数据不平衡，并结合 meta-learning loss 函数来学习独立于欺骗类别的嵌入空间；同时，通过 adversarial examples 作为数据增强策略，并整合辅助 batch normalization (BN) 和 attention module 来改进特征提取。实验在 ASVspoof 2019 语料库的 Logical Access (LA) 跟踪上实现了 pooled EER 为 0.87% 和 min t-DCF 为 0.0277 的优异性能，为减少欺骗攻击对自动说话人验证 (ASV) 系统的影响提供了有效方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "IEEE ACCESS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13341v1",
      "published_date": "2024-08-23 19:26:54 UTC",
      "updated_date": "2024-08-23 19:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:09:15.119066"
    },
    {
      "arxiv_id": "2408.14499v1",
      "title": "SHEDAD: SNN-Enhanced District Heating Anomaly Detection for Urban Substations",
      "title_zh": "翻译失败",
      "authors": [
        "Jonne van Dreven",
        "Abbas Cheddad",
        "Sadi Alawadi",
        "Ahmad Nauman Ghazi",
        "Jad Al Koussa",
        "Dirk Vanhoudt"
      ],
      "abstract": "District Heating (DH) systems are essential for energy-efficient urban\nheating. However, despite the advancements in automated fault detection and\ndiagnosis (FDD), DH still faces challenges in operational faults that impact\nefficiency. This study introduces the Shared Nearest Neighbor Enhanced District\nHeating Anomaly Detection (SHEDAD) approach, designed to approximate the DH\nnetwork topology and allow for local anomaly detection without disclosing\nsensitive information, such as substation locations. The approach leverages a\nmulti-adaptive k-Nearest Neighbor (k-NN) graph to improve the initial\nneighborhood creation. Moreover, it introduces a merging technique that reduces\nnoise and eliminates trivial edges. We use the Median Absolute Deviation (MAD)\nand modified z-scores to flag anomalous substations. The results reveal that\nSHEDAD outperforms traditional clustering methods, achieving significantly\nlower intra-cluster variance and distance. Additionally, SHEDAD effectively\nisolates and identifies two distinct categories of anomalies: supply\ntemperatures and substation performance. We identified 30 anomalous substations\nand reached a sensitivity of approximately 65\\% and specificity of\napproximately 97\\%. By focusing on this subset of poor-performing substations\nin the network, SHEDAD enables more targeted and effective maintenance\ninterventions, which can reduce energy usage while optimizing network\nperformance.",
      "tldr_zh": "本研究提出SHEDAD方法，即基于Shared Nearest Neighbor (SNN)的区域供热异常检测框架，旨在在不泄露敏感信息（如变电站位置）的情况下近似供热网络拓扑并实现本地异常检测。SHEDAD采用多自适应k-Nearest Neighbor (k-NN)图改进初始邻域创建，并引入合并技术减少噪声，同时使用Median Absolute Deviation (MAD)和修改后的z-scores标记异常变电站。实验结果显示，SHEDAD优于传统聚类方法，具有更低的内部聚类方差和距离，成功识别30个异常变电站（灵敏度约65%、特异性约97%），并有效区分供应温度和变电站性能异常，从而支持针对性维护、降低能源消耗并优化网络性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, FMEC2024",
      "pdf_url": "http://arxiv.org/pdf/2408.14499v1",
      "published_date": "2024-08-23 19:25:41 UTC",
      "updated_date": "2024-08-23 19:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:09:26.301921"
    },
    {
      "arxiv_id": "2408.13338v1",
      "title": "LalaEval: A Holistic Human Evaluation Framework for Domain-Specific Large Language Models",
      "title_zh": "LalaEval：一种针对特定领域大型语言模型的整体人类评估框架",
      "authors": [
        "Chongyan Sun",
        "Ken Lin",
        "Shiwei Wang",
        "Hulong Wu",
        "Chengfei Fu",
        "Zhen Wang"
      ],
      "abstract": "This paper introduces LalaEval, a holistic framework designed for the human\nevaluation of domain-specific large language models (LLMs). LalaEval proposes a\ncomprehensive suite of end-to-end protocols that cover five main components\nincluding domain specification, criteria establishment, benchmark dataset\ncreation, construction of evaluation rubrics, and thorough analysis and\ninterpretation of evaluation outcomes. This initiative aims to fill a crucial\nresearch gap by providing a systematic methodology for conducting standardized\nhuman evaluations within specific domains, a practice that, despite its\nwidespread application, lacks substantial coverage in the literature and human\nevaluation are often criticized to be less reliable due to subjective factors,\nso standardized procedures adapted to the nuanced requirements of specific\ndomains or even individual organizations are in great need. Furthermore, the\npaper demonstrates the framework's application within the logistics industry,\npresenting domain-specific evaluation benchmarks, datasets, and a comparative\nanalysis of LLMs for the logistics domain use, highlighting the framework's\ncapacity to elucidate performance differences and guide model selection and\ndevelopment for domain-specific LLMs. Through real-world deployment, the paper\nunderscores the framework's effectiveness in advancing the field of\ndomain-specific LLM evaluation, thereby contributing significantly to the\nongoing discussion on LLMs' practical utility and performance in\ndomain-specific applications.",
      "tldr_zh": "这篇论文介绍了 LalaEval，一种全面的人类评估框架，针对领域特定的大语言模型 (LLMs) 进行标准化评估，以解决现有评估的主观性和可靠性问题。框架涵盖五个核心组件：领域规范、标准建立、基准数据集创建、评估标准构建，以及结果分析和解释，从而提供系统化的评估方法。论文通过在物流行业的实际应用，展示了框架的实用性，包括创建特定基准数据集和对 LLMs 的比较分析，帮助指导模型选择和开发，最终提升了领域特定 LLM 的性能评估水平。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13338v1",
      "published_date": "2024-08-23 19:12:45 UTC",
      "updated_date": "2024-08-23 19:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:09:39.306728"
    },
    {
      "arxiv_id": "2408.13333v1",
      "title": "Mastering the Digital Art of War: Developing Intelligent Combat Simulation Agents for Wargaming Using Hierarchical Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Scotty Black"
      ],
      "abstract": "In today's rapidly evolving military landscape, advancing artificial\nintelligence (AI) in support of wargaming becomes essential. Despite\nreinforcement learning (RL) showing promise for developing intelligent agents,\nconventional RL faces limitations in handling the complexity inherent in combat\nsimulations. This dissertation proposes a comprehensive approach, including\ntargeted observation abstractions, multi-model integration, a hybrid AI\nframework, and an overarching hierarchical reinforcement learning (HRL)\nframework. Our localized observation abstraction using piecewise linear spatial\ndecay simplifies the RL problem, enhancing computational efficiency and\ndemonstrating superior efficacy over traditional global observation methods.\nOur multi-model framework combines various AI methodologies, optimizing\nperformance while still enabling the use of diverse, specialized individual\nbehavior models. Our hybrid AI framework synergizes RL with scripted agents,\nleveraging RL for high-level decisions and scripted agents for lower-level\ntasks, enhancing adaptability, reliability, and performance. Our HRL\narchitecture and training framework decomposes complex problems into manageable\nsubproblems, aligning with military decision-making structures. Although\ninitial tests did not show improved performance, insights were gained to\nimprove future iterations. This study underscores AI's potential to\nrevolutionize wargaming, emphasizing the need for continued research in this\ndomain.",
      "tldr_zh": "本研究探讨了在军事战争模拟中，使用 Hierarchical Reinforcement Learning (HRL) 开发智能代理，以应对传统 Reinforcement Learning (RL) 在处理复杂性方面的局限性。论文提出了一系列创新方法，包括针对观察的抽象（如分段线性空间衰减）、多模型整合框架，以及混合 AI 框架，将 RL 用于高层决策并结合脚本代理处理低层任务，从而提升计算效率、适应性和性能。HRL 架构将复杂问题分解为可管理的子问题，契合军事决策结构；尽管初始实验未显示性能改善，但提供了宝贵的见解。整体研究突显了 AI 在革命化战争游戏方面的潜力，并呼吁进一步探索。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13333v1",
      "published_date": "2024-08-23 18:50:57 UTC",
      "updated_date": "2024-08-23 18:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:09:50.982626"
    },
    {
      "arxiv_id": "2409.02938v1",
      "title": "CortexCompile: Harnessing Cortical-Inspired Architectures for Enhanced Multi-Agent NLP Code Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Gautham Ramachandran",
        "Rick Yang"
      ],
      "abstract": "Current approaches to automated code generation often rely on monolithic\nmodels that lack real-time adaptability and scalability. This limitation is\nparticularly evident in complex programming tasks that require dynamic\nadjustment and efficiency. The integration of neuroscience principles into\nNatural Language Processing (NLP) has the potential to revolutionize automated\ncode generation. This paper presents CortexCompile, a novel modular system\ninspired by the specialized functions of the human brain's cortical regions. By\nemulating the distinct roles of the Prefrontal Cortex, Parietal Cortex,\nTemporal Lobe, and Motor Cortex, CortexCompile achieves significant\nadvancements in scalability, efficiency, and adaptability compared to\ntraditional monolithic models like GPT-4o. The system's architecture features a\nTask Orchestration Agent that manages dynamic task delegation and parallel\nprocessing, facilitating the generation of highly accurate and optimized code\nacross increasingly complex programming tasks. Experimental evaluations\ndemonstrate that CortexCompile consistently outperforms GPT-4o in development\ntime, accuracy, and user satisfaction, particularly in tasks involving\nreal-time strategy games and first-person shooters. These findings underscore\nthe viability of neuroscience-inspired architectures in addressing the\nlimitations of current NLP models, paving the way for more efficient and\nhuman-like AI systems.",
      "tldr_zh": "本论文提出CortexCompile，一种受人类大脑皮层启发的模块化系统，用于提升多代理NLP代码合成，通过模拟Prefrontal Cortex、Parietal Cortex、Temporal Lobe和Motor Cortex的专化功能，实现动态任务分配和并行处理。相比传统单一模型如GPT-4o，该系统显著提高了可扩展性、效率和适应性，尤其在复杂编程任务中。实验评估显示，CortexCompile在开发时间、准确性和用户满意度上优于GPT-4o，特别是在实时策略游戏和第一人称射击游戏等场景。这些发现突显了神经科学启发架构的潜力，为更高效的人类-like AI系统提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.2; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02938v1",
      "published_date": "2024-08-23 18:36:20 UTC",
      "updated_date": "2024-08-23 18:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:10:03.101144"
    },
    {
      "arxiv_id": "2408.13328v1",
      "title": "Localized Observation Abstraction Using Piecewise Linear Spatial Decay for Reinforcement Learning in Combat Simulations",
      "title_zh": "基于分段线性空间衰减的局部观察抽象，用于战斗模拟中的强化学习",
      "authors": [
        "Scotty Black",
        "Christian Darken"
      ],
      "abstract": "In the domain of combat simulations, the training and deployment of deep\nreinforcement learning (RL) agents still face substantial challenges due to the\ndynamic and intricate nature of such environments. Unfortunately, as the\ncomplexity of the scenarios and available information increases, the training\ntime required to achieve a certain threshold of performance does not just\nincrease, but often does so exponentially. This relationship underscores the\nprofound impact of complexity in training RL agents. This paper introduces a\nnovel approach that addresses this limitation in training artificial\nintelligence (AI) agents using RL. Traditional RL methods have been shown to\nstruggle in these high-dimensional, dynamic environments due to real-world\ncomputational constraints and the known sample inefficiency challenges of RL.\nTo overcome these limitations, we propose a method of localized observation\nabstraction using piecewise linear spatial decay. This technique simplifies the\nstate space, reducing computational demands while still preserving essential\ninformation, thereby enhancing AI training efficiency in dynamic environments\nwhere spatial relationships are often critical. Our analysis reveals that this\nlocalized observation approach consistently outperforms the more traditional\nglobal observation approach across increasing scenario complexity levels. This\npaper advances the research on observation abstractions for RL, illustrating\nhow localized observation with piecewise linear spatial decay can provide an\neffective solution to large state representation challenges in dynamic\nenvironments.",
      "tldr_zh": "在战斗模拟环境中，强化学习（RL）代理的训练面临高维动态复杂性的挑战，导致性能达到阈值所需的训练时间呈指数级增加。为此，本文提出了一种局部观察抽象方法，使用分段线性空间衰减（piecewise linear spatial decay）来简化状态空间，减少计算需求，同时保留关键空间关系信息，从而提高AI在动态环境中的训练效率。实验分析表明，该方法在各种复杂场景下比传统的全局观察方法表现更优，为RL中的观察抽象研究提供了有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13328v1",
      "published_date": "2024-08-23 18:26:10 UTC",
      "updated_date": "2024-08-23 18:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:10:14.442998"
    },
    {
      "arxiv_id": "2408.13256v2",
      "title": "How Diffusion Models Learn to Factorize and Compose",
      "title_zh": "扩散模型如何学会因子化和组合",
      "authors": [
        "Qiyao Liang",
        "Ziming Liu",
        "Mitchell Ostrow",
        "Ila Fiete"
      ],
      "abstract": "Diffusion models are capable of generating photo-realistic images that\ncombine elements which likely do not appear together in the training set,\ndemonstrating the ability to \\textit{compositionally generalize}. Nonetheless,\nthe precise mechanism of compositionality and how it is acquired through\ntraining remains elusive. Inspired by cognitive neuroscientific approaches, we\nconsider a highly reduced setting to examine whether and when diffusion models\nlearn semantically meaningful and factorized representations of composable\nfeatures. We performed extensive controlled experiments on conditional\nDenoising Diffusion Probabilistic Models (DDPMs) trained to generate various\nforms of 2D Gaussian bump images. We found that the models learn factorized but\nnot fully continuous manifold representations for encoding continuous features\nof variation underlying the data. With such representations, models demonstrate\nsuperior feature compositionality but limited ability to interpolate over\nunseen values of a given feature. Our experimental results further demonstrate\nthat diffusion models can attain compositionality with few compositional\nexamples, suggesting a more efficient way to train DDPMs. Finally, we connect\nmanifold formation in diffusion models to percolation theory in physics,\noffering insight into the sudden onset of factorized representation learning.\nOur thorough toy experiments thus contribute a deeper understanding of how\ndiffusion models capture compositional structure in data.",
      "tldr_zh": "这篇论文探讨了diffusion models如何通过训练学习factorize和compose特征，以实现组合性泛化(compositionally generalize)。研究者通过训练条件Denoising Diffusion Probabilistic Models (DDPMs)生成2D Gaussian bump图像的简化实验，发现模型形成了factorized但非完全连续的manifold表征，这使得模型在特征组合上表现出色，但对未见特征值的插值能力有限。实验进一步证明，diffusion models能用少量组合示例快速获得组合性，并将manifold形成与物理学的percolation theory联系起来，为理解这些模型如何捕捉数据中的组合结构提供了深入见解。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures, plus appendix, some content overlap with\n  arXiv:2402.03305",
      "pdf_url": "http://arxiv.org/pdf/2408.13256v2",
      "published_date": "2024-08-23 17:59:03 UTC",
      "updated_date": "2024-10-11 03:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:10:26.789805"
    },
    {
      "arxiv_id": "2408.13255v1",
      "title": "Ensemble Modeling of Multiple Physical Indicators to Dynamically Phenotype Autism Spectrum Disorder",
      "title_zh": "翻译失败",
      "authors": [
        "Marie Huynh",
        "Aaron Kline",
        "Saimourya Surabhi",
        "Kaitlyn Dunlap",
        "Onur Cezmi Mutlu",
        "Mohammadmahdi Honarmand",
        "Parnian Azizian",
        "Peter Washington",
        "Dennis P. Wall"
      ],
      "abstract": "Early detection of autism, a neurodevelopmental disorder marked by social\ncommunication challenges, is crucial for timely intervention. Recent\nadvancements have utilized naturalistic home videos captured via the mobile\napplication GuessWhat. Through interactive games played between children and\ntheir guardians, GuessWhat has amassed over 3,000 structured videos from 382\nchildren, both diagnosed with and without Autism Spectrum Disorder (ASD). This\ncollection provides a robust dataset for training computer vision models to\ndetect ASD-related phenotypic markers, including variations in emotional\nexpression, eye contact, and head movements. We have developed a protocol to\ncurate high-quality videos from this dataset, forming a comprehensive training\nset. Utilizing this set, we trained individual LSTM-based models using eye\ngaze, head positions, and facial landmarks as input features, achieving test\nAUCs of 86%, 67%, and 78%, respectively. To boost diagnostic accuracy, we\napplied late fusion techniques to create ensemble models, improving the overall\nAUC to 90%. This approach also yielded more equitable results across different\ngenders and age groups. Our methodology offers a significant step forward in\nthe early detection of ASD by potentially reducing the reliance on subjective\nassessments and making early identification more accessibly and equitable.",
      "tldr_zh": "该研究利用 GuessWhat 移动应用收集的超过 3,000 个家庭视频数据集，针对 Autism Spectrum Disorder (ASD) 早期检测，分析儿童的情绪表达、眼部注视和头部运动等表型标记。研究团队训练了基于 LSTM 的单个模型，使用 eye gaze、head positions 和 facial landmarks 作为输入特征，分别获得测试 AUC 为 86%、67% 和 78%。通过 late fusion 技术构建 ensemble 模型，将整体 AUC 提升至 90%，并实现了更公平的性别和年龄组结果，从而为更客观、可访问的 ASD 早期诊断提供重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13255v1",
      "published_date": "2024-08-23 17:55:58 UTC",
      "updated_date": "2024-08-23 17:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:10:40.135709"
    },
    {
      "arxiv_id": "2408.13248v1",
      "title": "Foundational Model for Electron Micrograph Analysis: Instruction-Tuning Small-Scale Language-and-Vision Assistant for Enterprise Adoption",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Chidaksh Ravuru",
        "Geethan Sannidhi",
        "Venkataramana Runkana"
      ],
      "abstract": "Semiconductor imaging and analysis are critical yet understudied in deep\nlearning, limiting our ability for precise control and optimization in\nsemiconductor manufacturing. We introduce a small-scale multimodal framework\nfor analyzing semiconductor electron microscopy images (MAEMI) through\nvision-language instruction tuning. We generate a customized\ninstruction-following dataset using large multimodal models on microscopic\nimage analysis. We perform knowledge transfer from larger to smaller models\nthrough knowledge distillation, resulting in improved accuracy of smaller\nmodels on visual question answering (VQA) tasks. This approach eliminates the\nneed for expensive, human expert-annotated datasets for microscopic image\nanalysis tasks. Enterprises can further finetune MAEMI on their intellectual\ndata, enhancing privacy and performance on low-cost consumer hardware. Our\nexperiments show that MAEMI outperforms traditional methods, adapts to data\ndistribution shifts, and supports high-throughput screening.",
      "tldr_zh": "该研究针对半导体成像分析在深度学习中的不足，引入了 MAEMI 框架，这是一个小规模多模态框架，通过视觉语言指令微调来分析电子显微镜图像。研究利用大型多模态模型生成自定义指令数据集，并通过知识蒸馏（knowledge distillation）将知识转移到小模型，提高其在视觉问答（VQA）任务上的准确性，同时避免了昂贵的人工专家标注数据集。实验结果显示，MAEMI 优于传统方法，能够适应数据分布变化，并支持高通量筛选，使其适合企业采用以提升隐私和性能，使用低成本硬件。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Our paper is published at ICML 2024 Workshop ML for Life and Material\n  Science: From Theory to Industry Applications, Vienna, Austria",
      "pdf_url": "http://arxiv.org/pdf/2408.13248v1",
      "published_date": "2024-08-23 17:42:11 UTC",
      "updated_date": "2024-08-23 17:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:10:51.926086"
    },
    {
      "arxiv_id": "2408.13247v1",
      "title": "Data Exposure from LLM Apps: An In-depth Investigation of OpenAI's GPTs",
      "title_zh": "翻译失败",
      "authors": [
        "Evin Jaff",
        "Yuhao Wu",
        "Ning Zhang",
        "Umar Iqbal"
      ],
      "abstract": "LLM app ecosystems are quickly maturing and supporting a wide range of use\ncases, which requires them to collect excessive user data. Given that the LLM\napps are developed by third-parties and that anecdotal evidence suggests LLM\nplatforms currently do not strictly enforce their policies, user data shared\nwith arbitrary third-parties poses a significant privacy risk. In this paper we\naim to bring transparency in data practices of LLM apps. As a case study, we\nstudy OpenAI's GPT app ecosystem. We develop an LLM-based framework to conduct\nthe static analysis of natural language-based source code of GPTs and their\nActions (external services) to characterize their data collection practices.\nOur findings indicate that Actions collect expansive data about users,\nincluding sensitive information prohibited by OpenAI, such as passwords. We\nfind that some Actions, including related to advertising and analytics, are\nembedded in multiple GPTs, which allow them to track user activities across\nGPTs. Additionally, co-occurrence of Actions exposes as much as 9.5x more data\nto them, than it is exposed to individual Actions. Lastly, we develop an\nLLM-based privacy policy analysis framework to automatically check the\nconsistency of data collection by Actions with disclosures in their privacy\npolicies. Our measurements indicate that the disclosures for most of the\ncollected data types are omitted in privacy policies, with only 5.8% of Actions\nclearly disclosing their data collection practices.",
      "tldr_zh": "本研究调查了 OpenAI 的 GPT 应用生态中数据暴露风险，揭示了第三方开发的 LLM 应用在收集用户数据时存在的隐私隐患。研究者开发了一个基于 LLM 的框架，对 GPTs 的自然语言源代码和外部 Actions 进行静态分析，发现 Actions 收集了大量敏感信息（如密码），并通过嵌入多个 GPTs 实现跨应用用户活动跟踪，导致数据暴露增加多达 9.5 倍。此外，分析显示，大多数 Actions 的隐私政策未完整披露数据收集实践，仅有 5.8% 的 Actions 明确说明了其行为。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13247v1",
      "published_date": "2024-08-23 17:42:06 UTC",
      "updated_date": "2024-08-23 17:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:11:14.144167"
    },
    {
      "arxiv_id": "2408.13237v1",
      "title": "JacNet: Learning Functions with Structured Jacobians",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Lorraine",
        "Safwan Hossain"
      ],
      "abstract": "Neural networks are trained to learn an approximate mapping from an input\ndomain to a target domain. Incorporating prior knowledge about true mappings is\ncritical to learning a useful approximation. With current architectures, it is\nchallenging to enforce structure on the derivatives of the input-output\nmapping. We propose to use a neural network to directly learn the Jacobian of\nthe input-output function, which allows easy control of the derivative. We\nfocus on structuring the derivative to allow invertibility and also demonstrate\nthat other useful priors, such as $k$-Lipschitz, can be enforced. Using this\napproach, we can learn approximations to simple functions that are guaranteed\nto be invertible and easily compute the inverse. We also show similar results\nfor 1-Lipschitz functions.",
      "tldr_zh": "本文提出 JacNet，一种神经网络框架，用于学习具有结构化 Jacobian 的函数映射，从而整合关于真实映射的先验知识。不同于传统方法，该框架直接学习输入-输出函数的 Jacobian，便于强制执行导数结构，如可逆性和 k-Lipschitz 条件。实验结果表明，JacNet 可以学习到保证可逆的函数近似，并轻松计算逆函数，同时在 1-Lipschitz 函数上表现出类似效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T07",
        "I.2.6; G.1.0; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 Figures, ICML 2019 INNF Workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.13237v1",
      "published_date": "2024-08-23 17:21:44 UTC",
      "updated_date": "2024-08-23 17:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:11:15.184237"
    },
    {
      "arxiv_id": "2408.13233v2",
      "title": "Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time",
      "title_zh": "翻译失败",
      "authors": [
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song",
        "Yufa Zhou"
      ],
      "abstract": "The computational complexity of the self-attention mechanism in popular\ntransformer architectures poses significant challenges for training and\ninference, and becomes the bottleneck for long inputs. Is it possible to\nsignificantly reduce the quadratic time complexity of computing the gradients\nin multi-layer transformer models? This paper proves that a novel fast\napproximation method can calculate the gradients in almost linear time\n$n^{1+o(1)}$ where $n$ is the input sequence length, while it maintains a\npolynomially small approximation error $1 / \\mathrm{poly}(n)$ across the entire\nmodel. Our theory holds for general loss functions and when the multi-layer\ntransformer model contains many practical sub-modules, such as residual\nconnection, casual mask, and multi-head attention. By improving the efficiency\nof gradient computation, we hope that this work will facilitate more effective\ntraining and deployment of long-context language models based on our\ntheoretical results.",
      "tldr_zh": "该论文针对Transformer模型中自注意力机制的二次时间复杂度问题，提出了一种新颖的快速近似方法，能够在几乎线性时间（$n^{1+o(1)}$）内计算多层Transformer梯度，同时保持多项式小的近似误差（$1 / \\mathrm{poly}(n)$）。该方法适用于一般损失函数，并兼容残差连接、因果掩码和多头注意力等实际子模块。实验结果证明，该方法显著提高了梯度计算效率，有望促进长上下文语言模型的更有效训练和部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13233v2",
      "published_date": "2024-08-23 17:16:43 UTC",
      "updated_date": "2024-10-15 04:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:11:27.446944"
    },
    {
      "arxiv_id": "2408.13227v1",
      "title": "Enhancing Few-Shot Transfer Learning with Optimized Multi-Task Prompt Tuning through Modular Prompt Composition",
      "title_zh": "通过模块化提示组合优化多任务提示调整以增强少样本迁移学习",
      "authors": [
        "Ahmad Pouramini",
        "Hesham Faili"
      ],
      "abstract": "In recent years, multi-task prompt tuning has garnered considerable attention\nfor its inherent modularity and potential to enhance parameter-efficient\ntransfer learning across diverse tasks. This paper aims to analyze and improve\nthe performance of multiple tasks by facilitating the transfer of knowledge\nbetween their corresponding prompts in a multi-task setting. Our proposed\napproach decomposes the prompt for each target task into a combination of\nshared prompts (source prompts) and a task-specific prompt (private prompt).\nDuring training, the source prompts undergo fine-tuning and are integrated with\nthe private prompt to drive the target prompt for each task. We present and\ncompare multiple methods for combining source prompts to construct the target\nprompt, analyzing the roles of both source and private prompts within each\nmethod. We investigate their contributions to task performance and offer\nflexible, adjustable configurations based on these insights to optimize\nperformance. Our empirical findings clearly showcase improvements in accuracy\nand robustness compared to the conventional practice of prompt tuning and\nrelated works. Notably, our results substantially outperform other methods in\nthe field in few-shot settings, demonstrating superior performance in various\ntasks across GLUE benchmark, among other tasks. This achievement is attained\nwith a significantly reduced amount of training data, making our method a\npromising one for few-shot settings.",
      "tldr_zh": "该论文提出了一种优化多任务提示调优（multi-task prompt tuning）的方法，通过模块化提示组合（modular prompt composition）提升少样本转移学习（few-shot transfer learning）的性能。具体而言，该方法将每个目标任务的提示分解为共享提示（source prompts）和任务特定提示（private prompt），在训练过程中细调源提示并与私有提示结合，形成目标提示，并比较多种组合策略以分析其作用。实验结果显示，该方法在GLUE benchmark等任务上显著提高了准确性和鲁棒性，尤其在少样本设置中超越相关工作，且仅需少量训练数据即可实现这些改进。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13227v1",
      "published_date": "2024-08-23 17:01:51 UTC",
      "updated_date": "2024-08-23 17:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:11:40.026374"
    },
    {
      "arxiv_id": "2408.13217v1",
      "title": "HBIC: A Biclustering Algorithm for Heterogeneous Datasets",
      "title_zh": "HBIC：一种用于异构数据集的双聚类算法",
      "authors": [
        "Adán José-García",
        "Julie Jacques",
        "Clément Chauvet",
        "Vincent Sobanski",
        "Clarisse Dhaenens"
      ],
      "abstract": "Biclustering is an unsupervised machine-learning approach aiming to cluster\nrows and columns simultaneously in a data matrix. Several biclustering\nalgorithms have been proposed for handling numeric datasets. However,\nreal-world data mining problems often involve heterogeneous datasets with mixed\nattributes. To address this challenge, we introduce a biclustering approach\ncalled HBIC, capable of discovering meaningful biclusters in complex\nheterogeneous data, including numeric, binary, and categorical data. The\napproach comprises two stages: bicluster generation and bicluster model\nselection. In the initial stage, several candidate biclusters are generated\niteratively by adding and removing rows and columns based on the frequency of\nvalues in the original matrix. In the second stage, we introduce two approaches\nfor selecting the most suitable biclusters by considering their size and\nhomogeneity. Through a series of experiments, we investigated the suitability\nof our approach on a synthetic benchmark and in a biomedical application\ninvolving clinical data of systemic sclerosis patients. The evaluation\ncomparing our method to existing approaches demonstrates its ability to\ndiscover high-quality biclusters from heterogeneous data. Our biclustering\napproach is a starting point for heterogeneous bicluster discovery, leading to\na better understanding of complex underlying data structures.",
      "tldr_zh": "本研究提出了一种名为 HBIC 的双聚类(biclustering)算法，旨在处理异构数据集，包括数字、二进制和分类属性，从而同时对数据矩阵的行和列进行聚类。算法分为两个阶段：首先通过迭代添加和移除行与列基于值的频率生成候选双聚类；其次基于双聚cluster的大小和均匀性选择最合适的模型。在实验中，HBIC 在合成基准和系统性硬皮病患者临床数据等生物医学应用上表现优于现有方法，能够发现高质量的双聚cluster，并为理解复杂数据结构提供新起点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13217v1",
      "published_date": "2024-08-23 16:48:10 UTC",
      "updated_date": "2024-08-23 16:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:11:51.120886"
    },
    {
      "arxiv_id": "2408.13214v1",
      "title": "EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Hongcheng Ding",
        "Xuanze Zhao",
        "Zixiao Jiang",
        "Shamsul Nahar Abdullah",
        "Deshinta Arrova Dewi"
      ],
      "abstract": "Accurate forecasting of the EUR/USD exchange rate is crucial for investors,\nbusinesses, and policymakers. This paper proposes a novel framework, IUS, that\nintegrates unstructured textual data from news and analysis with structured\ndata on exchange rates and financial indicators to enhance exchange rate\nprediction. The IUS framework employs large language models for sentiment\npolarity scoring and exchange rate movement classification of texts. These\ntextual features are combined with quantitative features and input into a\nCausality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then\nused to forecast the EUR/USD exchange rate. Experiments demonstrate that the\nproposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE\nby 9.56% compared to the best performing baseline. Results also show the\nbenefits of data fusion, with the combination of unstructured and structured\ndata yielding higher accuracy than structured data alone. Furthermore, feature\nselection using the top 12 important quantitative features combined with the\ntextual features proves most effective. The proposed IUS framework and\nOptuna-Bi-LSTM model provide a powerful new approach for exchange rate\nforecasting through multi-source data integration.",
      "tldr_zh": "这篇论文提出了一种名为 IUS 的新框架，用于 EUR/USD 汇率预测，通过融合非结构化文本数据（如新闻分析）和结构化数据（如汇率指标），以提升预测准确性。框架利用 Large Language Models 对文本进行情感极性评分和汇率变动分类，将这些特征与量化特征结合输入 Causality-Driven Feature Generator，并采用 Optuna 优化的 Bi-LSTM 模型进行预测。实验结果显示，该方法比基准模型降低了 MAE 10.69% 和 RMSE 9.56%，证明多源数据整合的益处，且使用前 12 个重要量化特征结合文本特征的效果最佳。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13214v1",
      "published_date": "2024-08-23 16:46:36 UTC",
      "updated_date": "2024-08-23 16:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:12:04.231195"
    },
    {
      "arxiv_id": "2408.13211v1",
      "title": "Optimal Quantum Circuit Design via Unitary Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "M. Zomorodi",
        "H. Amini",
        "M. Abbaszadeh",
        "J. Sohrabi",
        "V. Salari",
        "P. Plawiak"
      ],
      "abstract": "The process of translating a quantum algorithm into a form suitable for\nimplementation on a quantum computing platform is crucial but yet challenging.\nThis entails specifying quantum operations with precision, a typically\nintricate task. In this paper, we present an alternative approach: an automated\nmethod for synthesizing the functionality of a quantum algorithm into a quantum\ncircuit model representation. Our methodology involves training a neural\nnetwork model using diverse input-output mappings of the quantum algorithm. We\ndemonstrate that this trained model can effectively generate a quantum circuit\nmodel equivalent to the original algorithm. Remarkably, our observations\nindicate that the trained model achieves near-perfect mapping of unseen inputs\nto their respective outputs.",
      "tldr_zh": "本论文探讨了量子算法转化为量子电路的挑战，提出了一种自动化方法，利用 Unitary Neural Networks 训练神经网络模型来合成等效的量子电路。方法涉及使用量子算法的多样输入-输出映射进行训练，使模型能够精确生成原算法的功能表示。实验结果显示，该模型对未见过输入的映射几乎完美，为优化量子电路设计提供了高效、可扩展的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13211v1",
      "published_date": "2024-08-23 16:41:15 UTC",
      "updated_date": "2024-08-23 16:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:12:14.685569"
    },
    {
      "arxiv_id": "2408.13208v1",
      "title": "Temporal Fairness in Decision Making Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel R. Torres",
        "Parisa Zehtabi",
        "Michael Cashmore",
        "Daniele Magazzeni",
        "Manuela Veloso"
      ],
      "abstract": "In this work we consider a new interpretation of fairness in decision making\nproblems. Building upon existing fairness formulations, we focus on how to\nreason over fairness from a temporal perspective, taking into account the\nfairness of a history of past decisions. After introducing the concept of\ntemporal fairness, we propose three approaches that incorporate temporal\nfairness in decision making problems formulated as optimization problems. We\npresent a qualitative evaluation of our approach in four different domains and\ncompare the solutions against a baseline approach that does not consider the\ntemporal aspect of fairness.",
      "tldr_zh": "本论文探讨了决策问题中一种新的公平性解释，即temporal fairness，它考虑了决策历史中公平性的时间维度。作者基于现有公平性公式，引入了temporal fairness的概念，并提出了三种方法，将其整合到作为优化问题的决策框架中。通过在四个不同领域的定性评估，研究比较了这些方法与不考虑temporal fairness的基线方法，结果显示了改进的公平性表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted at ECAI 2024. This is an extended version that\n  includes Supplementary Material",
      "pdf_url": "http://arxiv.org/pdf/2408.13208v1",
      "published_date": "2024-08-23 16:36:58 UTC",
      "updated_date": "2024-08-23 16:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:12:26.808006"
    },
    {
      "arxiv_id": "2408.13204v1",
      "title": "DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiming Zhu",
        "Jialun Cao",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun",
        "Shing-Chi Cheung"
      ],
      "abstract": "Code benchmarks such as HumanEval are widely adopted to evaluate the\ncapabilities of Large Language Models (LLMs), providing insights into their\nstrengths and weaknesses. However, current benchmarks primarily exercise LLMs'\ncapability on common coding tasks (e.g., bubble sort, greatest common divisor),\nleaving domain-specific coding tasks (e.g., computation, system, cryptography)\nunexplored. To fill this gap, we propose a multi-domain code benchmark,\nDOMAINEVAL, designed to evaluate LLMs' coding capabilities thoroughly. Our\npipeline works in a fully automated manner, enabling a push-bottom construction\nfrom code repositories into formatted subjects under study. Interesting\nfindings are observed by evaluating 12 representative LLMs against DOMAINEVAL.\nWe notice that LLMs are generally good at computation tasks while falling short\non cryptography and system coding tasks. The performance gap can be as much as\n68.94% (80.94% - 12.0%) in some LLMs. We also observe that generating more\nsamples can increase the overall performance of LLMs, while the domain bias may\neven increase. The contributions of this study include a code generation\nbenchmark dataset DOMAINEVAL, encompassing six popular domains, a fully\nautomated pipeline for constructing code benchmarks, and an identification of\nthe limitations of LLMs in code generation tasks based on their performance on\nDOMAINEVAL, providing directions for future research improvements. The\nleaderboard is available at https://domaineval.github.io/.",
      "tldr_zh": "本研究提出DOMAINEVAL，一种自动构建的多领域代码生成基准，用于全面评估Large Language Models (LLMs)的能力，填补现有基准（如HumanEval）仅关注常见任务而忽略领域特定任务（如计算、系统、密码学）的空白。DOMAINEVAL通过一个完全自动化的管道，从代码仓库提取并格式化测试主题，涵盖六个流行领域。实验评估了12个代表性LLMs，发现它们在计算任务上表现良好，但在密码学和系统任务上存在显著差距，性能差异可达68.94%，同时生成更多样本能提升整体性能但可能加剧领域偏差。该基准及其发现为LLMs的未来改进提供了重要方向，并附带在线排行榜。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13204v1",
      "published_date": "2024-08-23 16:33:58 UTC",
      "updated_date": "2024-08-23 16:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:12:40.752241"
    },
    {
      "arxiv_id": "2408.14496v3",
      "title": "A New Era in Computational Pathology: A Survey on Foundation and Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dibaloke Chanda",
        "Milan Aryal",
        "Nasim Yahya Soltani",
        "Masoud Ganji"
      ],
      "abstract": "Recent advances in deep learning have completely transformed the domain of\ncomputational pathology (CPath). More specifically, it has altered the\ndiagnostic workflow of pathologists by integrating foundation models (FMs) and\nvision-language models (VLMs) in their assessment and decision-making process.\nThe limitations of existing deep learning approaches in CPath can be overcome\nby FMs through learning a representation space that can be adapted to a wide\nvariety of downstream tasks without explicit supervision. Deploying VLMs allow\npathology reports written in natural language be used as rich semantic\ninformation sources to improve existing models as well as generate predictions\nin natural language form. In this survey, a holistic and systematic overview of\nrecent innovations in FMs and VLMs in CPath is presented. Furthermore, the\ntools, datasets and training schemes for these models are summarized in\naddition to categorizing them into distinct groups. This extensive survey\nhighlights the current trends in CPath and its possible revolution through the\nuse of FMs and VLMs in the future.",
      "tldr_zh": "这篇调查论文探讨了深度学习在计算病理学（CPath）领域的最新进展，特别是基础模型（FMs）和视觉语言模型（VLMs）的应用。FMs 通过学习可适应多种下游任务的表示空间，克服了现有方法的局限性，而VLMs 利用自然语言的病理报告作为语义信息来源，以改进模型并生成自然语言预测。论文系统总结了这些模型的工具、数据集、训练方案及其分类，并强调了当前趋势及其潜力在未来推动CPath的革命性变革。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 19 figures and 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.14496v3",
      "published_date": "2024-08-23 16:33:57 UTC",
      "updated_date": "2024-09-18 15:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:12:50.848606"
    },
    {
      "arxiv_id": "2408.13202v1",
      "title": "Instruct-DeBERTa: A Hybrid Approach for Aspect-based Sentiment Analysis on Textual Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Dineth Jayakody",
        "A V A Malkith",
        "Koshila Isuranda",
        "Vishal Thenuwara",
        "Nisansa de Silva",
        "Sachintha Rajith Ponnamperuma",
        "G G N Sandamali",
        "K L K Sudheera"
      ],
      "abstract": "Aspect-based Sentiment Analysis (ABSA) is a critical task in Natural Language\nProcessing (NLP) that focuses on extracting sentiments related to specific\naspects within a text, offering deep insights into customer opinions.\nTraditional sentiment analysis methods, while useful for determining overall\nsentiment, often miss the implicit opinions about particular product or service\nfeatures. This paper presents a comprehensive review of the evolution of ABSA\nmethodologies, from lexicon-based approaches to machine learning and deep\nlearning techniques. We emphasize the recent advancements in Transformer-based\nmodels, particularly Bidirectional Encoder Representations from Transformers\n(BERT) and its variants, which have set new benchmarks in ABSA tasks. We\nfocused on finetuning Llama and Mistral models, building hybrid models using\nthe SetFit framework, and developing our own model by exploiting the strengths\nof state-of-the-art (SOTA) Transformer-based models for aspect term extraction\n(ATE) and aspect sentiment classification (ASC). Our hybrid model Instruct -\nDeBERTa uses SOTA InstructABSA for aspect extraction and DeBERTa-V3-baseabsa-V1\nfor aspect sentiment classification. We utilize datasets from different domains\nto evaluate our model's performance. Our experiments indicate that the proposed\nhybrid model significantly improves the accuracy and reliability of sentiment\nanalysis across all experimented domains. As per our findings, our hybrid model\nInstruct - DeBERTa is the best-performing model for the joint task of ATE and\nASC for both SemEval restaurant 2014 and SemEval laptop 2014 datasets\nseparately. By addressing the limitations of existing methodologies, our\napproach provides a robust solution for understanding detailed consumer\nfeedback, thus offering valuable insights for businesses aiming to enhance\ncustomer satisfaction and product development.",
      "tldr_zh": "这篇论文提出了一种混合方法 Instruct-DeBERTa，用于 Aspect-based Sentiment Analysis (ABSA)，旨在从文本评论中提取特定方面的情感信息。作者回顾了 ABSA 的演变，从词汇法到深度学习模型，特别是 Transformer 模型如 BERT 的进展，并构建了该模型通过结合 InstructABSA 进行方面提取 (ATE) 和 DeBERTa-V3-baseabsa-V1 进行方面情感分类 (ASC)。实验结果显示，Instruct-DeBERTa 在 SemEval restaurant 2014 和 laptop 2014 数据集上表现最佳，显著提高了情感分析的准确性和可靠性，为企业理解消费者反馈提供了一个稳健解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13202v1",
      "published_date": "2024-08-23 16:31:07 UTC",
      "updated_date": "2024-08-23 16:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:13:04.692891"
    },
    {
      "arxiv_id": "2408.13297v1",
      "title": "An Overview and Comparison of Axiomatization Structures Regarding Inconsistency Indices' Properties in Pairwise Comparisons Methods",
      "title_zh": "成对比较方法中不一致性指标属性公理化结构的概述与比较",
      "authors": [
        "Sangeeta Pant",
        "Anuj Kumar",
        "Jiří Mazurek"
      ],
      "abstract": "Mathematical analysis of the analytic hierarchy process (AHP) led to the\ndevelopment of a mathematical function, usually called the inconsistency index,\nwhich has the center role in measuring the inconsistency of the judgements in\nAHP. Inconsistency index is a mathematical function which maps every pairwise\ncomparison matrix (PCM) into a real number. An inconsistency index can be\nconsidered more trustworthy when it satisfies a set of suitable properties.\nTherefore, the research community has been trying to postulate a set of\ndesirable rules (axioms, properties) for inconsistency indices. Subsequently,\nmany axiomatic frameworks for these functions have been suggested\nindependently, however, the literature on the topic is fragmented and missing a\nbroader framework. Therefore, the objective of this article is twofold.\nFirstly, we provide a comprehensive review of the advancements in the\naxiomatization of inconsistency indices' properties during the last decade.\nSecondly, we provide a comparison and discussion of the aforementioned\naxiomatic structures along with directions of the future research.",
      "tldr_zh": "本论文概述并比较了成对比较方法（Pairwise Comparisons Methods）中不一致性指标（Inconsistency Indices）的公理化结构，焦点在于这些指标如何衡量Analytic Hierarchy Process (AHP)中成对比较矩阵（PCM）的判断不一致性。研究者回顾了过去十年对不一致性指标属性的公理化进展，强调了这些指标需满足一组合适属性以提升可信度。论文通过比较不同公理框架，揭示了文献的碎片化问题，并为未来研究方向提供了讨论和建议。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "21 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13297v1",
      "published_date": "2024-08-23 16:20:09 UTC",
      "updated_date": "2024-08-23 16:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:13:15.110612"
    },
    {
      "arxiv_id": "2408.13189v1",
      "title": "Accelerating the k-means++ Algorithm by Using Geometric Information",
      "title_zh": "翻译失败",
      "authors": [
        "Guillem Rodríguez Corominas",
        "Maria J. Blesa",
        "Christian Blum"
      ],
      "abstract": "In this paper, we propose an acceleration of the exact k-means++ algorithm\nusing geometric information, specifically the Triangle Inequality and\nadditional norm filters, along with a two-step sampling procedure. Our\nexperiments demonstrate that the accelerated version outperforms the standard\nk-means++ version in terms of the number of visited points and distance\ncalculations, achieving greater speedup as the number of clusters increases.\nThe version utilizing the Triangle Inequality is particularly effective for\nlow-dimensional data, while the additional norm-based filter enhances\nperformance in high-dimensional instances with greater norm variance among\npoints. Additional experiments show the behavior of our algorithms when\nexecuted concurrently across multiple jobs and examine how memory performance\nimpacts practical speedup.",
      "tldr_zh": "本文提出了一种利用几何信息加速 k-means++ 算法的方法，具体包括 Triangle Inequality、额外的 norm filters 以及两步采样过程，以减少访问点数和距离计算。实验结果显示，该加速版本在聚类数增加时表现出色，整体性能优于标准 k-means++ 算法。Triangle Inequality 在低维数据上特别有效，而 norm-based filter 则在高维数据中显著提升表现，尤其当点间 norm 差异较大时。额外实验考察了算法在多作业并发执行下的行为，以及内存性能对实际加速的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "91C20"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13189v1",
      "published_date": "2024-08-23 16:15:47 UTC",
      "updated_date": "2024-08-23 16:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:13:27.770071"
    },
    {
      "arxiv_id": "2408.13161v2",
      "title": "Say No to Freeloader: Protecting Intellectual Property of Your Deep Model",
      "title_zh": "拒绝免费搭车者：保护您的深度模型知识产权",
      "authors": [
        "Lianyu Wang",
        "Meng Wang",
        "Huazhu Fu",
        "Daoqiang Zhang"
      ],
      "abstract": "Model intellectual property (IP) protection has attracted growing attention\nas science and technology advancements stem from human intellectual labor and\ncomputational expenses. Ensuring IP safety for trainers and owners is of utmost\nimportance, particularly in domains where ownership verification and\napplicability authorization are required. A notable approach to safeguarding\nmodel IP involves proactively preventing the use of well-trained models of\nauthorized domains from unauthorized domains. In this paper, we introduce a\nnovel Compact Un-transferable Pyramid Isolation Domain (CUPI-Domain) which\nserves as a barrier against illegal transfers from authorized to unauthorized\ndomains. Drawing inspiration from human transitive inference and learning\nabilities, the CUPI-Domain is designed to obstruct cross-domain transfers by\nemphasizing the distinctive style features of the authorized domain. This\nemphasis leads to failure in recognizing irrelevant private style features on\nunauthorized domains. To this end, we propose novel CUPI-Domain generators,\nwhich select features from both authorized and CUPI-Domain as anchors. Then, we\nfuse the style features and semantic features of these anchors to generate\nlabeled and style-rich CUPI-Domain. Additionally, we design external\nDomain-Information Memory Banks (DIMB) for storing and updating labeled pyramid\nfeatures to obtain stable domain class features and domain class-wise style\nfeatures. Based on the proposed whole method, the novel style and\ndiscriminative loss functions are designed to effectively enhance the\ndistinction in style and discriminative features between authorized and\nunauthorized domains, respectively. Moreover, we provide two solutions for\nutilizing CUPI-Domain based on whether the unauthorized domain is known:\ntarget-specified CUPI-Domain and target-free CUPI-Domain.",
      "tldr_zh": "这篇论文针对深度模型的知识产权（IP）保护问题，提出了一种新型 Compact Un-transferable Pyramid Isolation Domain (CUPI-Domain) 方法，以防止授权域的模型被非法转移到非授权域。CUPI-Domain 借鉴人类的传递推理能力，通过强调授权域的独特风格特征，并利用 CUPI-Domain 生成器和 Domain-Information Memory Banks (DIMB) 来融合风格与语义特征，生成标签化和风格丰富的域数据。论文设计了新的风格损失函数和鉴别损失函数，以增强授权与非授权域间的特征区分，并提供了两种解决方案：针对已知非授权域的目标指定 CUPI-Domain 和针对未知域的目标自由 CUPI-Domain。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13161v2",
      "published_date": "2024-08-23 15:34:33 UTC",
      "updated_date": "2024-08-27 14:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:13:40.568074"
    },
    {
      "arxiv_id": "2408.13155v1",
      "title": "Causal machine learning for sustainable agroecosystems",
      "title_zh": "翻译失败",
      "authors": [
        "Vasileios Sitokonstantinou",
        "Emiliano Díaz Salas Porras",
        "Jordi Cerdà Bautista",
        "Maria Piles",
        "Ioannis Athanasiadis",
        "Hannah Kerner",
        "Giulia Martini",
        "Lily-belle Sweet",
        "Ilias Tsoumas",
        "Jakob Zscheischler",
        "Gustau Camps-Valls"
      ],
      "abstract": "In a changing climate, sustainable agriculture is essential for food security\nand environmental health. However, it is challenging to understand the complex\ninteractions among its biophysical, social, and economic components. Predictive\nmachine learning (ML), with its capacity to learn from data, is leveraged in\nsustainable agriculture for applications like yield prediction and weather\nforecasting. Nevertheless, it cannot explain causal mechanisms and remains\ndescriptive rather than prescriptive. To address this gap, we propose causal\nML, which merges ML's data processing with causality's ability to reason about\nchange. This facilitates quantifying intervention impacts for evidence-based\ndecision-making and enhances predictive model robustness. We showcase causal ML\nthrough eight diverse applications that benefit stakeholders across the\nagri-food chain, including farmers, policymakers, and researchers.",
      "tldr_zh": "该论文探讨了因果机器学习（causal machine learning）在可持续农业生态系统中的应用，以应对气候变化下农业的复杂生物物理、社会和经济互动。传统预测机器学习（ML）虽能处理数据但无法解释因果机制，作者提出将 ML 的数据处理能力与因果推理相结合，从而量化干预影响、支持基于证据的决策，并提升预测模型的稳健性。通过八个多样化应用，论文展示了这一方法如何惠及农业食品链的利益相关者，包括农民、决策者和研究人员。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13155v1",
      "published_date": "2024-08-23 15:25:50 UTC",
      "updated_date": "2024-08-23 15:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:13:51.890598"
    },
    {
      "arxiv_id": "2408.13147v1",
      "title": "ShapeICP: Iterative Category-level Object Pose and Shape Estimation from Depth",
      "title_zh": "ShapeICP：基于深度的迭代类别级物体位姿和形状估计",
      "authors": [
        "Yihao Zhang",
        "John J. Leonard"
      ],
      "abstract": "Category-level object pose and shape estimation from a single depth image has\nrecently drawn research attention due to its wide applications in robotics and\nself-driving. The task is particularly challenging because the three unknowns,\nobject pose, object shape, and model-to-measurement correspondences, are\ncompounded together but only a single view of depth measurements is provided.\nThe vast majority of the prior work heavily relies on data-driven approaches to\nobtain solutions to at least one of the unknowns and typically two, running\nwith the risk of failing to generalize to unseen domains. The shape\nrepresentations used in the prior work also mainly focus on point cloud and\nsigned distance field (SDF). In stark contrast to the prior work, we approach\nthe problem using an iterative estimation method that does not require learning\nfrom any pose-annotated data. In addition, we adopt a novel mesh-based object\nactive shape model that has not been explored by the previous literature. Our\nalgorithm, named ShapeICP, has its foundation in the iterative closest point\n(ICP) algorithm but is equipped with additional features for the category-level\npose and shape estimation task. The results show that even without using any\npose-annotated data, ShapeICP surpasses many data-driven approaches that rely\non the pose data for training, opening up new solution space for researchers to\nconsider.",
      "tldr_zh": "这篇论文提出了一种名为 ShapeICP 的迭代算法，用于从单一深度图像中估计类别级对象的姿态和形状，解决了现有方法依赖数据驱动的局限性。ShapeICP 基于迭代最近点 (ICP) 算法，结合了新型的网格-based 对象主动形状模型，并不需要任何姿态标注数据进行训练。该方法在实验中超越了许多依赖姿态数据的学习方法，展示了其在泛化性和鲁棒性上的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13147v1",
      "published_date": "2024-08-23 15:12:55 UTC",
      "updated_date": "2024-08-23 15:12:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:14:03.519960"
    },
    {
      "arxiv_id": "2408.13140v3",
      "title": "Verification of Geometric Robustness of Neural Networks via Piecewise Linear Approximation and Lipschitz Optimisation",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Batten",
        "Yang Zheng",
        "Alessandro De Palma",
        "Panagiotis Kouvaros",
        "Alessio Lomuscio"
      ],
      "abstract": "We address the problem of verifying neural networks against geometric\ntransformations of the input image, including rotation, scaling, shearing, and\ntranslation. The proposed method computes provably sound piecewise linear\nconstraints for the pixel values by using sampling and linear approximations in\ncombination with branch-and-bound Lipschitz optimisation. The method obtains\nprovably tighter over-approximations of the perturbation region than the\npresent state-of-the-art. We report results from experiments on a comprehensive\nset of verification benchmarks on MNIST and CIFAR10. We show that our proposed\nimplementation resolves up to 32% more verification cases than present\napproaches.",
      "tldr_zh": "该论文针对神经网络对输入图像几何变换（如旋转、缩放、剪切和平移）的鲁棒性验证问题，提出了一种基于 Piecewise Linear Approximation 和 Lipschitz Optimisation 的方法。该方法通过采样、线性逼近和 branch-and-bound 优化来计算像素值的分段线性约束，从而提供比现有技术更紧凑的扰动区域上界。在 MNIST 和 CIFAR10 的基准测试中，该方法成功解决了多达 32% 的额外验证案例，显著提升了验证的准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13140v3",
      "published_date": "2024-08-23 15:02:09 UTC",
      "updated_date": "2024-09-21 18:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:14:15.234869"
    },
    {
      "arxiv_id": "2408.13135v1",
      "title": "Deep Learning at the Intersection: Certified Robustness as a Tool for 3D Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Pérez S",
        "Juan C. Pérez",
        "Motasem Alfarra",
        "Jesús Zarzar",
        "Sara Rojas",
        "Bernard Ghanem",
        "Pablo Arbeláez"
      ],
      "abstract": "This paper presents preliminary work on a novel connection between certified\nrobustness in machine learning and the modeling of 3D objects. We highlight an\nintriguing link between the Maximal Certified Radius (MCR) of a classifier\nrepresenting a space's occupancy and the space's Signed Distance Function\n(SDF). Leveraging this relationship, we propose to use the certification method\nof randomized smoothing (RS) to compute SDFs. Since RS' high computational cost\nprevents its practical usage as a way to compute SDFs, we propose an algorithm\nto efficiently run RS in low-dimensional applications, such as 3D space, by\nexpressing RS' fundamental operations as Gaussian smoothing on pre-computed\nvoxel grids. Our approach offers an innovative and practical tool to compute\nSDFs, validated through proof-of-concept experiments in novel view synthesis.\nThis paper bridges two previously disparate areas of machine learning, opening\nnew avenues for further exploration and potential cross-domain advancements.",
      "tldr_zh": "本论文探讨了机器学习中Certified Robustness与3D物体建模的联系，特别指出Maximal Certified Radius (MCR)与Signed Distance Function (SDF)之间的关键关系。作者提出使用randomized smoothing (RS)方法来计算SDF，但为解决RS的高计算成本，开发了一个高效算法，通过在预计算的voxel grids上进行Gaussian smoothing，使其适用于低维应用如3D空间。该方法经由novel view synthesis的证明性实验验证，展示了其实用性，并桥接了这两个领域，为跨领域创新打开了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is an accepted extended abstract to the LatinX workshop at\n  ICCV 2023. This was uploaded a year late",
      "pdf_url": "http://arxiv.org/pdf/2408.13135v1",
      "published_date": "2024-08-23 15:00:32 UTC",
      "updated_date": "2024-08-23 15:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:14:27.172132"
    },
    {
      "arxiv_id": "2408.13131v2",
      "title": "DeTPP: Leveraging Object Detection for Robust Long-Horizon Event Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Karpukhin",
        "Andrey Savchenko"
      ],
      "abstract": "Long-horizon event forecasting is critical across various domains, including\nretail, finance, healthcare, and social networks. Traditional methods, such as\nMarked Temporal Point Processes (MTPP), often rely on autoregressive models to\npredict multiple future events. However, these models frequently suffer from\nissues like converging to constant or repetitive outputs, which limits their\neffectiveness and general applicability. To address these challenges, we\nintroduce DeTPP (Detection-based Temporal Point Processes), a novel approach\ninspired by object detection techniques from computer vision. DeTPP employs a\nunique matching-based loss function that selectively prioritizes reliably\npredictable events, improving the accuracy and diversity of predictions during\ninference. Our method establishes a new state-of-the-art in long-horizon event\nforecasting, achieving up to a 77% relative improvement over existing MTPP and\nnext-K methods. The proposed hybrid approach enhances the accuracy of next\nevent prediction by up to 2.7% on a large transactional dataset. Notably, DeTPP\nis also among the fastest methods for inference. The implementation of DeTPP is\npublicly available on GitHub.",
      "tldr_zh": "这篇论文提出 DeTPP，一种基于物体检测技术的创新方法，用于提升长时段事件预测的鲁棒性。它解决了传统 Marked Temporal Point Processes (MTPP) 方法的局限，如输出收敛到常量或重复问题，通过引入匹配-based 损失函数来优先处理可预测事件，从而提高预测的准确性和多样性。实验结果显示，DeTPP 在长时段事件预测中实现了高达 77% 的相对改善，并在大型交易数据集上将下一事件预测准确性提升 2.7%；此外，该方法推理速度快，且代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13131v2",
      "published_date": "2024-08-23 14:57:46 UTC",
      "updated_date": "2024-10-02 13:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:14:40.192727"
    },
    {
      "arxiv_id": "2408.13293v1",
      "title": "Causally-Aware Spatio-Temporal Multi-Graph Convolution Network for Accurate and Reliable Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Pingping Dong",
        "Xiao-Lin Wang",
        "Indranil Bose",
        "Kam K. H. Ng",
        "Xiaoning Zhang",
        "Xiaoge Zhang"
      ],
      "abstract": "Accurate and reliable prediction has profound implications to a wide range of\napplications. In this study, we focus on an instance of spatio-temporal\nlearning problem--traffic prediction--to demonstrate an advanced deep learning\nmodel developed for making accurate and reliable forecast. Despite the\nsignificant progress in traffic prediction, limited studies have incorporated\nboth explicit and implicit traffic patterns simultaneously to improve\nprediction performance. Meanwhile, the variability nature of traffic states\nnecessitates quantifying the uncertainty of model predictions in a\nstatistically principled way; however, extant studies offer no provable\nguarantee on the statistical validity of confidence intervals in reflecting its\nactual likelihood of containing the ground truth. In this paper, we propose an\nend-to-end traffic prediction framework that leverages three primary components\nto generate accurate and reliable traffic predictions: dynamic causal structure\nlearning for discovering implicit traffic patterns from massive traffic data,\ncausally-aware spatio-temporal multi-graph convolution network (CASTMGCN) for\nlearning spatio-temporal dependencies, and conformal prediction for uncertainty\nquantification. CASTMGCN fuses several graphs that characterize different\nimportant aspects of traffic networks and an auxiliary graph that captures the\neffect of exogenous factors on the road network. On this basis, a conformal\nprediction approach tailored to spatio-temporal data is further developed for\nquantifying the uncertainty in node-wise traffic predictions over varying\nprediction horizons. Experimental results on two real-world traffic datasets\ndemonstrate that the proposed method outperforms several state-of-the-art\nmodels in prediction accuracy; moreover, it generates more efficient prediction\nregions than other methods while strictly satisfying the statistical validity\nin coverage.",
      "tldr_zh": "本文提出一个端到端框架，用于精确可靠的交通预测，通过同时整合显式和隐式交通模式来提升性能。框架的核心组件包括动态因果结构学习（dynamic causal structure learning）以发现隐式模式、Causally-Aware Spatio-Temporal Multi-Graph Convolution Network (CASTMGCN) 以学习时空依赖并融合外部因素影响，以及conformal prediction 以量化预测不确定性并确保统计有效性。实验结果显示，该方法在两个真实交通数据集上优于现有模型，提高了预测准确性，并生成更高效的预测区间，同时严格满足统计有效性要求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13293v1",
      "published_date": "2024-08-23 14:35:54 UTC",
      "updated_date": "2024-08-23 14:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:14:52.209200"
    },
    {
      "arxiv_id": "2408.13085v3",
      "title": "Map-Free Visual Relocalization Enhanced by Instance Knowledge and Depth Knowledge",
      "title_zh": "基于实例知识和深度知识增强的无地图视觉重定位",
      "authors": [
        "Mingyu Xiao",
        "Runze Chen",
        "Haiyong Luo",
        "Fang Zhao",
        "Juan Wang",
        "Xuepeng Ma"
      ],
      "abstract": "Map-free relocalization technology is crucial for applications in autonomous\nnavigation and augmented reality, but relying on pre-built maps is often\nimpractical. It faces significant challenges due to limitations in matching\nmethods and the inherent lack of scale in monocular images. These issues lead\nto substantial rotational and metric errors and even localization failures in\nreal-world scenarios. Large matching errors significantly impact the overall\nrelocalization process, affecting both rotational and translational accuracy.\nDue to the inherent limitations of the camera itself, recovering the metric\nscale from a single image is crucial, as this significantly impacts the\ntranslation error. To address these challenges, we propose a map-free\nrelocalization method enhanced by instance knowledge and depth knowledge. By\nleveraging instance-based matching information to improve global matching\nresults, our method significantly reduces the possibility of mismatching across\ndifferent objects. The robustness of instance knowledge across the scene helps\nthe feature point matching model focus on relevant regions and enhance matching\naccuracy. Additionally, we use estimated metric depth from a single image to\nreduce metric errors and improve scale recovery accuracy. By integrating\nmethods dedicated to mitigating large translational and rotational errors, our\napproach demonstrates superior performance in map-free relocalization\ntechniques.",
      "tldr_zh": "这篇论文提出了一种增强的无地图视觉重定位方法，利用 instance knowledge 和 depth knowledge 来解决匹配错误和单目图像尺度缺乏的问题。该方法通过实例-based 匹配信息改善全局匹配，减少不同对象间的误匹配，并使用单图像估计的度量深度来降低度量错误，提高尺度恢复准确性。最终，该方法整合了针对旋转和平移错误的优化策略，在无地图重定位任务中表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13085v3",
      "published_date": "2024-08-23 14:12:03 UTC",
      "updated_date": "2024-09-19 02:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:15:13.342129"
    },
    {
      "arxiv_id": "2408.13084v1",
      "title": "Avatar Visual Similarity for Social HCI: Increasing Self-Awareness",
      "title_zh": "社交 HCI 中的虚拟化身视觉相似度：提升自我意识",
      "authors": [
        "Bernhard Hilpert",
        "Claudio Alves da Silva",
        "Leon Christidis",
        "Chirag Bhuvaneshwara",
        "Patrick Gebhard",
        "Fabrizio Nunnari",
        "Dimitra Tsovaltzi"
      ],
      "abstract": "Self-awareness is a critical factor in social human-human interaction and,\nhence, in social HCI interaction. Increasing self-awareness through mirrors or\nvideo recordings is common in face-to-face trainings, since it influences\nantecedents of self-awareness like explicit identification and implicit\naffective identification (affinity). However, increasing self-awareness has\nbeen scarcely examined in virtual trainings with virtual avatars, which allow\nfor adjusting the similarity, e.g. to avoid negative effects of\nself-consciousness. Automatic visual similarity in avatars is an open issue\nrelated to high costs. It is important to understand which features need to be\nmanipulated and which degree of similarity is necessary for self-awareness to\nleverage the added value of using avatars for self-awareness. This article\nexamines the relationship between avatar visual similarity and increasing\nself-awareness in virtual training environments. We define visual similarity\nbased on perceptually important facial features for human-human identification\nand develop a theory-based methodology to systematically manipulate visual\nsimilarity of virtual avatars and support self-awareness. Three personalized\nversions of virtual avatars with varying degrees of visual similarity to\nparticipants were created (weak, medium and strong facial features\nmanipulation). In a within-subject study (N=33), we tested effects of degree of\nsimilarity on perceived similarity, explicit identification and implicit\naffective identification (affinity). Results show significant differences\nbetween the weak similarity manipulation, and both the strong manipulation and\nthe random avatar for all three antecedents of self-awareness. An increasing\ndegree of avatar visual similarity influences antecedents of self-awareness in\nvirtual environments.",
      "tldr_zh": "这篇论文探讨了在社交 HCI（Human-Computer Interaction）中，通过调整虚拟头像的视觉相似度来提升自我意识（self-awareness），以改善虚拟训练环境。研究者基于感知重要的人脸特征定义了视觉相似度，并开发了一种理论驱动的方法来系统操纵头像相似度，创建了弱、中、强三种个性化版本。实验采用内部主题设计（N=33），结果显示，增加相似度显著影响感知相似度、显性识别（explicit identification）和隐性情感识别（implicit affective identification），弱相似度操纵与强操纵或随机头像之间存在显著差异，从而证明了视觉相似度对自我意识前因的积极作用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13084v1",
      "published_date": "2024-08-23 14:11:35 UTC",
      "updated_date": "2024-08-23 14:11:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:15:18.518075"
    },
    {
      "arxiv_id": "2408.13082v1",
      "title": "Multivariate Time-Series Anomaly Detection based on Enhancing Graph Attention Networks with Topological Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Liu",
        "Xiang Huang",
        "Jingyun Zhang",
        "Zhifeng Hao",
        "Li Sun",
        "Hao Peng"
      ],
      "abstract": "Unsupervised anomaly detection in time series is essential in industrial\napplications, as it significantly reduces the need for manual intervention.\nMultivariate time series pose a complex challenge due to their feature and\ntemporal dimensions. Traditional methods use Graph Neural Networks (GNNs) or\nTransformers to analyze spatial while RNNs to model temporal dependencies.\nThese methods focus narrowly on one dimension or engage in coarse-grained\nfeature extraction, which can be inadequate for large datasets characterized by\nintricate relationships and dynamic changes. This paper introduces a novel\ntemporal model built on an enhanced Graph Attention Network (GAT) for\nmultivariate time series anomaly detection called TopoGDN. Our model analyzes\nboth time and feature dimensions from a fine-grained perspective. First, we\nintroduce a multi-scale temporal convolution module to extract detailed\ntemporal features. Additionally, we present an augmented GAT to manage complex\ninter-feature dependencies, which incorporates graph topology into node\nfeatures across multiple scales, a versatile, plug-and-play enhancement that\nsignificantly boosts the performance of GAT. Our experimental results confirm\nthat our approach surpasses the baseline models on four datasets, demonstrating\nits potential for widespread application in fields requiring robust anomaly\ndetection. The code is available at https://github.com/ljj-cyber/TopoGDN.",
      "tldr_zh": "本论文针对多变量时间序列的无监督异常检测问题，提出了一种名为 TopoGDN 的新模型，该模型基于增强 Graph Attention Network (GAT) 并结合拓扑分析，以更精细地处理时间和特征维度。TopoGDN 引入多尺度时间卷积模块来提取详细的时间特征，并通过增强的 GAT 将图拓扑融入节点特征，在多个尺度上管理复杂的特征间依赖关系，从而克服传统 GNNs、Transformers 或 RNNs 方法的局限性。实验结果显示，该模型在四个数据集上超越基线模型，证明其在工业应用中具有广泛潜力用于鲁棒异常检测。代码已开源，可从指定仓库获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, to be published in CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13082v1",
      "published_date": "2024-08-23 14:06:30 UTC",
      "updated_date": "2024-08-23 14:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:15:28.057747"
    },
    {
      "arxiv_id": "2408.13078v1",
      "title": "AEMLO: AutoEncoder-Guided Multi-Label Oversampling",
      "title_zh": "翻译失败",
      "authors": [
        "Ao Zhou",
        "Bin Liu",
        "Jin Wang",
        "Kaiwei Sun",
        "Kelin Liu"
      ],
      "abstract": "Class imbalance significantly impacts the performance of multi-label\nclassifiers. Oversampling is one of the most popular approaches, as it augments\ninstances associated with less frequent labels to balance the class\ndistribution. Existing oversampling methods generate feature vectors of\nsynthetic samples through replication or linear interpolation and assign labels\nthrough neighborhood information. Linear interpolation typically generates new\nsamples between existing data points, which may result in insufficient\ndiversity of synthesized samples and further lead to the overfitting issue.\nDeep learning-based methods, such as AutoEncoders, have been proposed to\ngenerate more diverse and complex synthetic samples, achieving excellent\nperformance on imbalanced binary or multi-class datasets. In this study, we\nintroduce AEMLO, an AutoEncoder-guided Oversampling technique specifically\ndesigned for tackling imbalanced multi-label data. AEMLO is built upon two\nfundamental components. The first is an encoder-decoder architecture that\nenables the model to encode input data into a low-dimensional feature space,\nlearn its latent representations, and then reconstruct it back to its original\ndimension, thus applying to the generation of new data. The second is an\nobjective function tailored to optimize the sampling task for multi-label\nscenarios. We show that AEMLO outperforms the existing state-of-the-art methods\nwith extensive empirical studies.",
      "tldr_zh": "这篇论文针对多标签分类中的类别不平衡问题，提出了一种新型方法AEMLO，即AutoEncoder-Guided Multi-Label Oversampling。AEMLO的核心组件包括一个编码器-解码器架构，用于将输入数据编码到低维特征空间、学习潜在表示并重建生成多样化的合成样本，以及一个针对多标签场景优化的目标函数，以提升采样效果。实验结果显示，AEMLO在广泛的实证研究中优于现有最先进方法，显著缓解了线性插值导致的样本多样性不足和过拟合问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13078v1",
      "published_date": "2024-08-23 14:01:33 UTC",
      "updated_date": "2024-08-23 14:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:15:40.034876"
    },
    {
      "arxiv_id": "2408.13074v3",
      "title": "Hierarchical Spatio-Temporal State-Space Modeling for fMRI Analysis",
      "title_zh": "用于 fMRI 分析的层次时空状态空间建模",
      "authors": [
        "Yuxiang Wei",
        "Anees Abrol",
        "Vince Calhoun"
      ],
      "abstract": "Recent advances in deep learning structured state space models, especially\nthe Mamba architecture, have demonstrated remarkable performance improvements\nwhile maintaining linear complexity. In this study, we introduce functional\nspatiotemporal Mamba (FST-Mamba), a Mamba-based model designed for discovering\nneurological biomarkers using functional magnetic resonance imaging (fMRI). We\nfocus on dynamic functional network connectivity (dFNC) derived from fMRI and\npropose a hierarchical spatiotemporal Mamba-based network that processes\nspatial and temporal information separately using Mamba-based encoders.\nLeveraging the topological uniqueness of the FNC matrix, we introduce a\ncomponent-wise varied-scale aggregation (CVA) mechanism to aggregate\nconnectivity across individual components within brain networks, enabling the\nmodel to capture component-level and network-level information. Additionally,\nwe propose symmetric rotary position encoding (SymRope) to encode the relative\npositions of each functional connection while considering the symmetric nature\nof the FNC matrix. Experimental results demonstrate significant improvements in\nthe proposed FST-Mamba model on various brain-based classification and\nregression tasks. We further show brain connectivities and dynamics that are\ncrucial for the prediction. Our work reveals the substantial potential of\nattention-free sequence modeling in brain discovery. The codes are publicly\navailable here: https://github.com/yuxiangwei0808/FunctionalMamba/tree/main.",
      "tldr_zh": "本研究引入了 FST-Mamba，一种基于 Mamba 架构的层次化时空状态空间模型，用于从功能磁共振成像 (fMRI) 数据中发现神经生物标志物，焦点在于动态功能网络连接 (dFNC)。该模型分别使用 Mamba-based 编码器处理空间和时间信息，结合 component-wise varied-scale aggregation (CVA) 机制聚合脑网络的组件级和网络级连接，以及 symmetric rotary position encoding (SymRPE) 来编码 FNC 矩阵的对称相对位置。实验结果显示，FST-Mamba 在各种脑部分类和回归任务上显著提升性能，并揭示了关键脑连接动态，证明了无注意力序列建模在脑科学发现中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to RECOMB 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.13074v3",
      "published_date": "2024-08-23 13:58:14 UTC",
      "updated_date": "2025-03-20 19:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:15:53.636703"
    },
    {
      "arxiv_id": "2408.14494v1",
      "title": "Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving",
      "title_zh": "知识图谱建模驱动的大型语言模型",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Vijay Sri Vaikunth",
        "Venkataramana Runkana"
      ],
      "abstract": "We present the Process Engineering Operations Assistant (PEOA), an AI-driven\nframework designed to solve complex problems in the chemical and process\nindustries. The framework employs a modular architecture orchestrated by a\nmeta-agent, which serves as the central coordinator, managing an action\ngenerator and instruction-tuned small-scale language models (expert models).\nThe action generator decomposes complex problems into sub-tasks and identifies\nsuitable expert models to execute each, delivering precise solutions for\nmulti-step problem-solving. Key techniques include advanced knowledge modeling\nusing property graphs for improved information retrieval, facilitating more\naccurate and contextually relevant solutions. Additionally, the framework\nutilizes a teacher-student transfer-learning approach with GPT-4 (Omni) to\nfine-tune the action generator and expert models for domain adaptation,\nalongside an iterative problem-solving mechanism with sophisticated error\nhandling. Custom datasets were developed to evaluate the framework against\nleading proprietary language models on various engineering tasks. The results\ndemonstrate the framework effectiveness in automating calculations,\naccelerating prototyping, and providing AI-augmented decision support for\nindustrial processes, marking a significant advancement in process engineering\ncapabilities.",
      "tldr_zh": "本研究提出Process Engineering Operations Assistant (PEOA)，一个基于Knowledge Graph Modeling驱动的Large Language Model Operating System (LLM OS)，旨在自动化过程工程领域的复杂问题解决。框架采用模块化架构，由meta-agent协调action generator和instruction-tuned小规模语言模型（expert models），其中action generator负责分解子任务并选择合适模型，同时利用property graphs提升信息检索准确性，并通过teacher-student transfer-learning与GPT-4进行领域适应和错误处理。实验结果显示，PEOA在自定义数据集上超越领先专有模型，在自动化计算、原型加速和AI增强决策支持方面表现出色，标志着过程工程能力的重大进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Publication by Association for the Advancement of\n  Artificial Intelligence, Fall Symposium Series",
      "pdf_url": "http://arxiv.org/pdf/2408.14494v1",
      "published_date": "2024-08-23 13:52:47 UTC",
      "updated_date": "2024-08-23 13:52:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:16:03.265858"
    },
    {
      "arxiv_id": "2408.13054v1",
      "title": "cc-DRL: a Convex Combined Deep Reinforcement Learning Flight Control Design for a Morphing Quadrotor",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Yang",
        "Huai-Ning Wu",
        "Jun-Wei Wang"
      ],
      "abstract": "In comparison to common quadrotors, the shape change of morphing quadrotors\nendows it with a more better flight performance but also results in more\ncomplex flight dynamics. Generally, it is extremely difficult or even\nimpossible for morphing quadrotors to establish an accurate mathematical model\ndescribing their complex flight dynamics. To figure out the issue of flight\ncontrol design for morphing quadrotors, this paper resorts to a combination of\nmodel-free control techniques (e.g., deep reinforcement learning, DRL) and\nconvex combination (CC) technique, and proposes a convex-combined-DRL (cc-DRL)\nflight control algorithm for position and attitude of a class of morphing\nquadrotors, where the shape change is realized by the length variation of four\narm rods. In the proposed cc-DRL flight control algorithm, proximal policy\noptimization algorithm that is a model-free DRL algorithm is utilized to\noff-line train the corresponding optimal flight control laws for some selected\nrepresentative arm length modes and hereby a cc-DRL flight control scheme is\nconstructed by the convex combination technique. Finally, simulation results\nare presented to show the effectiveness and merit of the proposed flight\ncontrol algorithm.",
      "tldr_zh": "这篇论文针对变形四旋翼（morphing quadrotor）的复杂飞行动态问题，提出了一种结合深度强化学习（DRL）和凸组合（CC）技术的 cc-DRL 飞行控制算法，以实现精确的位置和姿态控制。算法利用 Proximal Policy Optimization 算法离线训练选定臂长模式的控制律，并通过凸组合技术构建统一的控制方案。模拟结果显示，cc-DRL 算法有效解决了模型不确定性问题，提升了飞行性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13054v1",
      "published_date": "2024-08-23 13:25:04 UTC",
      "updated_date": "2024-08-23 13:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:16:15.892249"
    },
    {
      "arxiv_id": "2408.13040v1",
      "title": "SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Kai-Wei Chang",
        "Haibin Wu",
        "Yu-Kai Wang",
        "Yuan-Kuei Wu",
        "Hua Shen",
        "Wei-Cheng Tseng",
        "Iu-thing Kang",
        "Shang-Wen Li",
        "Hung-yi Lee"
      ],
      "abstract": "Prompting has become a practical method for utilizing pre-trained language\nmodels (LMs). This approach offers several advantages. It allows an LM to adapt\nto new tasks with minimal training and parameter updates, thus achieving\nefficiency in both storage and computation. Additionally, prompting modifies\nonly the LM's inputs and harnesses the generative capabilities of language\nmodels to address various downstream tasks in a unified manner. This\nsignificantly reduces the need for human labor in designing task-specific\nmodels. These advantages become even more evident as the number of tasks served\nby the LM scales up. Motivated by the strengths of prompting, we are the first\nto explore the potential of prompting speech LMs in the domain of speech\nprocessing. Recently, there has been a growing interest in converting speech\ninto discrete units for language modeling. Our pioneer research demonstrates\nthat these quantized speech units are highly versatile within our unified\nprompting framework. Not only can they serve as class labels, but they also\ncontain rich phonetic information that can be re-synthesized back into speech\nsignals for speech generation tasks. Specifically, we reformulate speech\nprocessing tasks into speech-to-unit generation tasks. As a result, we can\nseamlessly integrate tasks such as speech classification, sequence generation,\nand speech generation within a single, unified prompting framework. The\nexperiment results show that the prompting method can achieve competitive\nperformance compared to the strong fine-tuning method based on self-supervised\nlearning models with a similar number of trainable parameters. The prompting\nmethod also shows promising results in the few-shot setting. Moreover, with the\nadvanced speech LMs coming into the stage, the proposed prompting framework\nattains great potential.",
      "tldr_zh": "这篇论文提出SpeechPrompt框架，将Prompting方法应用于语音语言模型（speech LMs），以高效处理语音处理任务。该方法利用量化语音单位（quantized speech units）的多功能性，将任务重构为语音到单位生成任务（speech-to-unit generation tasks），从而统一整合语音分类、序列生成和语音生成。实验结果表明，SpeechPrompt在性能上与基于自监督学习的微调方法相当，尤其在少样本设置中表现出色，随着先进speech LMs的发展，该框架展现出巨大的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Published in IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing (TASLP)",
      "pdf_url": "http://arxiv.org/pdf/2408.13040v1",
      "published_date": "2024-08-23 13:00:10 UTC",
      "updated_date": "2024-08-23 13:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:16:28.032088"
    },
    {
      "arxiv_id": "2408.13031v1",
      "title": "VFM-Det: Towards High-Performance Vehicle Detection via Large Foundation Models",
      "title_zh": "VFM-Det：通过大型基础模型实现高性能车辆检测",
      "authors": [
        "Wentao Wu",
        "Fanghua Hong",
        "Xiao Wang",
        "Chenglong Li",
        "Jin Tang"
      ],
      "abstract": "Existing vehicle detectors are usually obtained by training a typical\ndetector (e.g., YOLO, RCNN, DETR series) on vehicle images based on a\npre-trained backbone (e.g., ResNet, ViT). Some researchers also exploit and\nenhance the detection performance using pre-trained large foundation models.\nHowever, we think these detectors may only get sub-optimal results because the\nlarge models they use are not specifically designed for vehicles. In addition,\ntheir results heavily rely on visual features, and seldom of they consider the\nalignment between the vehicle's semantic information and visual\nrepresentations. In this work, we propose a new vehicle detection paradigm\nbased on a pre-trained foundation vehicle model (VehicleMAE) and a large\nlanguage model (T5), termed VFM-Det. It follows the region proposal-based\ndetection framework and the features of each proposal can be enhanced using\nVehicleMAE. More importantly, we propose a new VAtt2Vec module that predicts\nthe vehicle semantic attributes of these proposals and transforms them into\nfeature vectors to enhance the vision features via contrastive learning.\nExtensive experiments on three vehicle detection benchmark datasets thoroughly\nproved the effectiveness of our vehicle detector. Specifically, our model\nimproves the baseline approach by $+5.1\\%$, $+6.2\\%$ on the $AP_{0.5}$,\n$AP_{0.75}$ metrics, respectively, on the Cityscapes dataset.The source code of\nthis work will be released at https://github.com/Event-AHU/VFM-Det.",
      "tldr_zh": "该研究指出，现有的车辆检测器（如 YOLO、RCNN、DETR系列）依赖通用预训练骨干（如 ResNet、ViT），但因未针对车辆设计且忽略语义信息与视觉表示的 alignment，导致性能 suboptimal。作者提出 VFM-Det 框架，使用预训练的 VehicleMAE 和 T5 模型，基于 region proposal 检测框架，通过 VAtt2Vec 模块预测车辆语义属性并利用对比学习增强视觉特征。在三个车辆检测基准数据集上的实验证明了其有效性，特别是在 Cityscapes 数据集上，AP0.5 和 AP0.75 指标分别提高了 5.1% 和 6.2%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "In Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2408.13031v1",
      "published_date": "2024-08-23 12:39:02 UTC",
      "updated_date": "2024-08-23 12:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:16:41.832702"
    },
    {
      "arxiv_id": "2408.13003v1",
      "title": "BoostTrack++: using tracklet information to detect more objects in multiple object tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Vukašin Stanojević",
        "Branimir Todorović"
      ],
      "abstract": "Multiple object tracking (MOT) depends heavily on selection of true positive\ndetected bounding boxes. However, this aspect of the problem is mostly\noverlooked or mitigated by employing two-stage association and utilizing low\nconfidence detections in the second stage. Recently proposed BoostTrack\nattempts to avoid the drawbacks of multiple stage association approach and use\nlow-confidence detections by applying detection confidence boosting. In this\npaper, we identify the limitations of the confidence boost used in BoostTrack\nand propose a method to improve its performance. To construct a richer\nsimilarity measure and enable a better selection of true positive detections,\nwe propose to use a combination of shape, Mahalanobis distance and novel soft\nBIoU similarity. We propose a soft detection confidence boost technique which\ncalculates new confidence scores based on the similarity measure and the\nprevious confidence scores, and we introduce varying similarity threshold to\naccount for lower similarity measure between detections and tracklets which are\nnot regularly updated. The proposed additions are mutually independent and can\nbe used in any MOT algorithm.\n  Combined with the BoostTrack+ baseline, our method achieves near state of the\nart results on the MOT17 dataset and new state of the art HOTA and IDF1 scores\non the MOT20 dataset.\n  The source code is available at:\nhttps://github.com/vukasin-stanojevic/BoostTrack .",
      "tldr_zh": "本文提出 BoostTrack++，一种改进多目标跟踪 (MOT) 方法，通过利用轨迹信息来提升低置信度检测的准确性，解决现有方法的局限性。  \n该方法结合形状、Mahalanobis distance 和新型 soft BIoU 相似度构建更丰富的相似度测量，并引入 soft detection confidence boost 技术计算新置信度，同时使用可变相似度阈值来处理不经常更新的检测和轨迹。  \n实验结果显示，与 BoostTrack+ 结合后，在 MOT17 数据集上达到近乎最先进性能，在 MOT20 数据集上获得新的最先进 HOTA 和 IDF1 分数；这些改进相互独立，可应用于其他 MOT 算法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13003v1",
      "published_date": "2024-08-23 11:44:21 UTC",
      "updated_date": "2024-08-23 11:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:16:55.305792"
    },
    {
      "arxiv_id": "2408.13001v1",
      "title": "CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyang Xu",
        "Jialun Cao",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xianpei Han",
        "Ben He",
        "Shing-Chi Cheung",
        "Le Sun"
      ],
      "abstract": "Code benchmarks such as HumanEval are widely adopted to evaluate Large\nLanguage Models' (LLMs) coding capabilities. However, there is an unignorable\nprogramming language bias in existing code benchmarks -- over 95% code\ngeneration benchmarks are dominated by Python, leaving the LLMs' capabilities\nin other programming languages such as Java and C/C++ unknown. Moreover, coding\ntask bias is also crucial. Most benchmarks focus on code generation capability,\nwhile benchmarks for code reasoning (given input, reasoning output; and given\noutput, reasoning input), an essential coding capability, are insufficient.\nYet, constructing multi-lingual benchmarks can be expensive and\nlabor-intensive, and codes in contest websites such as Leetcode suffer from\ndata contamination during training. To fill this gap, we propose CRUXEVAL-X, a\nmulti-lingual code reasoning benchmark that contains 19 programming languages.\nIt comprises at least 600 subjects for each language, along with 19K\ncontent-consistent tests in total. In particular, the construction pipeline of\nCRUXEVAL-X works in a fully automated and test-guided manner, which iteratively\ngenerates and repairs based on execution feedback. Also, to cross language\nbarriers (e.g., dynamic/static type systems in Python/C++), we formulated\nvarious transition rules between language pairs to facilitate translation. Our\nintensive evaluation of 24 representative LLMs reveals the correlation between\nlanguage pairs. For example, TypeScript and JavaScript show a significant\npositive correlation, while Racket has less correlation with other languages.\nMore interestingly, even a model trained solely on Python can achieve at most\n34.4% Pass@1 in other languages, revealing the cross-language generalization of\nLLMs.",
      "tldr_zh": "本研究指出现有代码基准（如 HumanEval）存在编程语言偏见，主要聚焦 Python，并忽略了代码推理能力的评估。为此，提出 CRUXEval-X，一个多语言代码推理基准，涵盖 19 种编程语言，每个语言至少 600 个主题，总共 19K 测试，通过自动化管道（基于执行反馈的迭代生成和修复）以及语言转换规则（如处理动态/静态类型系统）来构建。实验评估了 24 个代表性 LLMs，揭示了语言间的相关性（例如 TypeScript 与 JavaScript 正相关），并发现即使只在 Python 上训练的模型，在其他语言上最多达到 34.4% 的 Pass@1，突显了 LLMs 的跨语言泛化局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13pages",
      "pdf_url": "http://arxiv.org/pdf/2408.13001v1",
      "published_date": "2024-08-23 11:43:00 UTC",
      "updated_date": "2024-08-23 11:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:17:04.873038"
    },
    {
      "arxiv_id": "2409.04447v1",
      "title": "Leveraging Contrastive Learning and Self-Training for Multimodal Emotion Recognition with Limited Labeled Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Fan",
        "Yutong Li",
        "Yi Xin",
        "Xinyu Cheng",
        "Guanglai Gao",
        "Miao Ma"
      ],
      "abstract": "The Multimodal Emotion Recognition challenge MER2024 focuses on recognizing\nemotions using audio, language, and visual signals. In this paper, we present\nour submission solutions for the Semi-Supervised Learning Sub-Challenge\n(MER2024-SEMI), which tackles the issue of limited annotated data in emotion\nrecognition. Firstly, to address the class imbalance, we adopt an oversampling\nstrategy. Secondly, we propose a modality representation combinatorial\ncontrastive learning (MR-CCL) framework on the trimodal input data to establish\nrobust initial models. Thirdly, we explore a self-training approach to expand\nthe training set. Finally, we enhance prediction robustness through a\nmulti-classifier weighted soft voting strategy. Our proposed method is\nvalidated to be effective on the MER2024-SEMI Challenge, achieving a weighted\naverage F-score of 88.25% and ranking 6th on the leaderboard. Our project is\navailable at https://github.com/WooyoohL/MER2024-SEMI.",
      "tldr_zh": "该论文针对多模态情感识别（Multimodal Emotion Recognition）中标注样本有限的问题，提出了一种基于 Contrastive Learning 和 Self-Training 的方法，参与 MER2024-SEMI 挑战赛。首先，通过 oversampling 策略处理类 imbalance，并引入 MR-CCL（modality representation combinatorial contrastive learning）框架来构建稳健的初始模型，然后结合 self-training 扩展训练集，并采用 multi-classifier weighted soft voting 策略提升预测准确性。实验结果显示，该方法在 MER2024-SEMI 挑战赛中取得 88.25% 的 weighted average F-score，并排名第 6，为低资源情感识别任务提供了有效解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ACM MM Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04447v1",
      "published_date": "2024-08-23 11:33:54 UTC",
      "updated_date": "2024-08-23 11:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:17:17.548686"
    },
    {
      "arxiv_id": "2408.12996v1",
      "title": "Enhancing Knowledge Tracing with Concept Map and Response Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Soonwook Park",
        "Donghoon Lee",
        "Hogun Park"
      ],
      "abstract": "In the rapidly advancing realm of educational technology, it becomes critical\nto accurately trace and understand student knowledge states. Conventional\nKnowledge Tracing (KT) models have mainly focused on binary responses (i.e.,\ncorrect and incorrect answers) to questions. Unfortunately, they largely\noverlook the essential information in students' actual answer choices,\nparticularly for Multiple Choice Questions (MCQs), which could help reveal each\nlearner's misconceptions or knowledge gaps. To tackle these challenges, we\npropose the Concept map-driven Response disentanglement method for enhancing\nKnowledge Tracing (CRKT) model. CRKT benefits KT by directly leveraging answer\nchoices--beyond merely identifying correct or incorrect answers--to distinguish\nresponses with different incorrect choices. We further introduce the novel use\nof unchosen responses by employing disentangled representations to get insights\nfrom options not selected by students. Additionally, CRKT tracks the student's\nknowledge state at the concept level and encodes the concept map, representing\nthe relationships between them, to better predict unseen concepts. This\napproach is expected to provide actionable feedback, improving the learning\nexperience. Our comprehensive experiments across multiple datasets demonstrate\nCRKT's effectiveness, achieving superior performance in prediction accuracy and\ninterpretability over state-of-the-art models.",
      "tldr_zh": "本文提出 CRKT 模型，用于提升 Knowledge Tracing (KT) 的准确性和可解释性，解决传统模型忽略多选题 (MCQs) 中学生实际答案选择的问题。CRKT 通过 Response disentanglement 方法区分不同错误响应，并从未选选项中提取洞见，同时在概念级别跟踪学生知识状态并编码 Concept map 以表示概念间关系，提供可操作的反馈。实验在多个数据集上证明，CRKT 比现有模型实现了更高的预测准确性和可解释性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to Knowledge-Based Systems Journal",
      "pdf_url": "http://arxiv.org/pdf/2408.12996v1",
      "published_date": "2024-08-23 11:25:56 UTC",
      "updated_date": "2024-08-23 11:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:17:28.652199"
    },
    {
      "arxiv_id": "2408.12989v1",
      "title": "RIFF: Inducing Rules for Fraud Detection from Decision Trees",
      "title_zh": "翻译失败",
      "authors": [
        "João Lucas Martins",
        "João Bravo",
        "Ana Sofia Gomes",
        "Carlos Soares",
        "Pedro Bizarro"
      ],
      "abstract": "Financial fraud is the cause of multi-billion dollar losses annually.\nTraditionally, fraud detection systems rely on rules due to their transparency\nand interpretability, key features in domains where decisions need to be\nexplained. However, rule systems require significant input from domain experts\nto create and tune, an issue that rule induction algorithms attempt to mitigate\nby inferring rules directly from data. We explore the application of these\nalgorithms to fraud detection, where rule systems are constrained to have a low\nfalse positive rate (FPR) or alert rate, by proposing RIFF, a rule induction\nalgorithm that distills a low FPR rule set directly from decision trees. Our\nexperiments show that the induced rules are often able to maintain or improve\nperformance of the original models for low FPR tasks, while substantially\nreducing their complexity and outperforming rules hand-tuned by experts.",
      "tldr_zh": "该论文探讨了RIFF算法，该算法从决策树（Decision Trees）中归纳规则，用于金融欺诈检测，以解决传统规则系统依赖领域专家输入的问题。RIFF专注于生成低假阳性率（FPR）的规则集，从而提高检测系统的透明性和可解释性。实验结果显示，RIFF诱导的规则能够维持或提升原模型的性能，同时显著降低复杂性，并优于专家手工调整的规则。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at RuleML+RR 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12989v1",
      "published_date": "2024-08-23 11:14:20 UTC",
      "updated_date": "2024-08-23 11:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:17:39.411249"
    },
    {
      "arxiv_id": "2408.12984v4",
      "title": "PDDFormer: Pairwise Distance Distribution Graph Transformer for Crystal Material Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxiang Shen",
        "Zheng Wan",
        "Lingfeng Wen",
        "Licheng Sun",
        "Ou Yang Ming Jie",
        "JiJUn Cheng",
        "Xuan Tang",
        "Xian Wei"
      ],
      "abstract": "The crystal structure can be simplified as a periodic point set repeating\nacross the entire three-dimensional space along an underlying lattice.\nTraditionally, methods for representing crystals rely on descriptors like\nlattice parameters, symmetry, and space groups to characterize the structure.\nHowever, in reality, atoms in material always vibrate above absolute zero,\ncausing continuous fluctuations in their positions. This dynamic behavior\ndisrupts the underlying periodicity of the lattice, making crystal graphs based\non static lattice parameters and conventional descriptors discontinuous under\neven slight perturbations. To this end, chemists proposed the Pairwise Distance\nDistribution (PDD) method, which has been used to distinguish all periodic\nstructures in the world's largest real materials collection, the Cambridge\nStructural Database. However, achieving the completeness of PDD requires\ndefining a large number of neighboring atoms, resulting in high computational\ncosts. Moreover, it does not account for atomic information, making it\nchallenging to directly apply PDD to crystal material property prediction\ntasks. To address these challenges, we propose the atom-Weighted Pairwise\nDistance Distribution (WPDD) and Unit cell Pairwise Distance Distribution\n(UPDD) for the first time, incorporating them into the construction of\nmulti-edge crystal graphs. Based on this, we further developed WPDDFormer and\nUPDDFormer, graph transformer architecture constructed using WPDD and UPDD\ncrystal graphs. We demonstrate that this method maintains the continuity and\ncompleteness of crystal graphs even under slight perturbations in atomic\npositions.",
      "tldr_zh": "本研究针对晶体材料属性预测中的问题，指出传统基于静态晶格参数的描述符在原子振动导致的微扰下会使晶体图不连续。论文首次提出 atom-Weighted Pairwise Distance Distribution (WPDD) 和 Unit cell Pairwise Distance Distribution (UPDD) 方法，这些方法整合了原子信息并构建多边晶体图，以解决 Pairwise Distance Distribution (PDD) 的高计算成本和信息缺失问题。基于此，开发了 WPDDFormer 和 UPDDFormer 两种图变换器架构，能够在原子位置轻微扰动下维持晶体图的连续性和完整性，从而提升材料属性预测的准确性。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12984v4",
      "published_date": "2024-08-23 11:05:48 UTC",
      "updated_date": "2024-11-24 08:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:17:53.244937"
    },
    {
      "arxiv_id": "2408.12981v1",
      "title": "QD-VMR: Query Debiasing with Contextual Understanding Enhancement for Video Moment Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghua Gao",
        "Min Li",
        "Jianshuo Liu",
        "Junxing Ren",
        "Lin Chen",
        "Haoyu Liu",
        "Bo Meng",
        "Jitao Fu",
        "Wenwen Su"
      ],
      "abstract": "Video Moment Retrieval (VMR) aims to retrieve relevant moments of an\nuntrimmed video corresponding to the query. While cross-modal interaction\napproaches have shown progress in filtering out query-irrelevant information in\nvideos, they assume the precise alignment between the query semantics and the\ncorresponding video moments, potentially overlooking the misunderstanding of\nthe natural language semantics. To address this challenge, we propose a novel\nmodel called \\textit{QD-VMR}, a query debiasing model with enhanced contextual\nunderstanding. Firstly, we leverage a Global Partial Aligner module via video\nclip and query features alignment and video-query contrastive learning to\nenhance the cross-modal understanding capabilities of the model. Subsequently,\nwe employ a Query Debiasing Module to obtain debiased query features\nefficiently, and a Visual Enhancement module to refine the video features\nrelated to the query. Finally, we adopt the DETR structure to predict the\npossible target video moments. Through extensive evaluations of three benchmark\ndatasets, QD-VMR achieves state-of-the-art performance, proving its potential\nto improve the accuracy of VMR. Further analytical experiments demonstrate the\neffectiveness of our proposed module. Our code will be released to facilitate\nfuture research.",
      "tldr_zh": "该研究针对视频时刻检索 (Video Moment Retrieval, VMR) 中的查询偏置问题，提出了一种新型模型 QD-VMR，通过增强上下文理解来减少查询语义误解。QD-VMR 包括 Global Partial Aligner 模块用于视频片段和查询特征对齐及对比学习、Query Debiasing Module 用于高效获取去偏置查询特征，以及 Visual Enhancement 模块来细化相关视频特征，并采用 DETR 结构预测目标时刻。实验在三个基准数据集上实现了最先进性能，准确性显著提升，并通过分析实验验证了各模块的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.12981v1",
      "published_date": "2024-08-23 10:56:42 UTC",
      "updated_date": "2024-08-23 10:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:18:04.731127"
    },
    {
      "arxiv_id": "2408.12963v1",
      "title": "Open Llama2 Model for the Lithuanian Language",
      "title_zh": "翻译失败",
      "authors": [
        "Artūras Nakvosas",
        "Povilas Daniušis",
        "Vytas Mulevičius"
      ],
      "abstract": "In this paper, we propose and describe the first open Llama2 large language\nmodels (LLMs) for the Lithuanian language, including an accompanying\nquestion/answer (Q/A) dataset and translations of popular LLM benchmarks. We\nprovide a brief review of open regional LLMs and detailed information on the\nproposed LLMs and their training process. We also conduct an empirical\nevaluation, comparing the perplexities of the proposed LLMs with those of other\nmodern open LLMs. In addition, benchmarking the proposed LLMs against language\nunderstanding tasks reveals that high-quality pretraining datasets may be\nessential for achieving models that perform efficiently on these benchmarks.\nThe full realisations of the described LLMs are available in the accompanying\nopen repository~\\url{https://huggingface.co/neurotechnology}.",
      "tldr_zh": "本研究提出了第一个针对立陶宛语的开源 Llama2 大语言模型 (LLMs)，包括一个配套的问答 (Q/A) 数据集以及流行 LLM 基准的翻译。论文回顾了现有开源区域 LLMs，并详细描述了所提模型的训练过程和实证评估。评估结果显示，所提 LLMs 的困惑度 (perplexities) 与其他现代开源 LLMs 相比表现出色，但基准测试表明，高质量的预训练数据集是实现高效语言理解任务性能的关键。模型的完整实现已在开源仓库（https://huggingface.co/neurotechnology）中提供。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.12963v1",
      "published_date": "2024-08-23 10:18:39 UTC",
      "updated_date": "2024-08-23 10:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:18:15.779718"
    },
    {
      "arxiv_id": "2408.12959v1",
      "title": "Multimodal Contrastive In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yosuke Miyanishi",
        "Minh Le Nguyen"
      ],
      "abstract": "The rapid growth of Large Language Models (LLMs) usage has highlighted the\nimportance of gradient-free in-context learning (ICL). However, interpreting\ntheir inner workings remains challenging. This paper introduces a novel\nmultimodal contrastive in-context learning framework to enhance our\nunderstanding of ICL in LLMs. First, we present a contrastive learning-based\ninterpretation of ICL in real-world settings, marking the distance of the\nkey-value representation as the differentiator in ICL. Second, we develop an\nanalytical framework to address biases in multimodal input formatting for\nreal-world datasets. We demonstrate the effectiveness of ICL examples where\nbaseline performance is poor, even when they are represented in unseen formats.\nLastly, we propose an on-the-fly approach for ICL (Anchored-by-Text ICL) that\ndemonstrates effectiveness in detecting hateful memes, a task where typical ICL\nstruggles due to resource limitations. Extensive experiments on multimodal\ndatasets reveal that our approach significantly improves ICL performance across\nvarious scenarios, such as challenging tasks and resource-constrained\nenvironments. Moreover, it provides valuable insights into the mechanisms of\nin-context learning in LLMs. Our findings have important implications for\ndeveloping more interpretable, efficient, and robust multimodal AI systems,\nespecially in challenging tasks and resource-constrained environments.",
      "tldr_zh": "这篇论文提出了一种多模态对比式 In-Context Learning (ICL) 框架，以提升对 Large Language Models (LLMs) 中 ICL 机制的理解。该框架通过对比学习解释 ICL 的关键-值表示距离，并开发分析框架来处理多模态输入格式中的偏差，同时引入 Anchored-by-Text ICL 方法，用于实时检测仇恨表情包（hateful memes）等资源受限任务。实验在多模态数据集上显示，该方法显著提高了 ICL 性能，尤其在挑战性任务和资源约束环境中。总体而言，这为构建更可解释、高效和鲁棒的多模态 AI 系统提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12959v1",
      "published_date": "2024-08-23 10:10:01 UTC",
      "updated_date": "2024-08-23 10:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:18:30.064557"
    },
    {
      "arxiv_id": "2408.12950v1",
      "title": "Informational Embodiment: Computational role of information structure in codes and robots",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Pitti",
        "Kohei Nakajima",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "The body morphology plays an important role in the way information is\nperceived and processed by an agent. We address an information theory (IT)\naccount on how the precision of sensors, the accuracy of motors, their\nplacement, the body geometry, shape the information structure in robots and\ncomputational codes. As an original idea, we envision the robot's body as a\nphysical communication channel through which information is conveyed, in and\nout, despite intrinsic noise and material limitations. Following this, entropy,\na measure of information and uncertainty, can be used to maximize the\nefficiency of robot design and of algorithmic codes per se. This is known as\nthe principle of Entropy Maximization (PEM) introduced in biology by Barlow in\n1969. The Shannon's source coding theorem provides then a framework to compare\ndifferent types of bodies in terms of sensorimotor information. In line with\nPME, we introduce a special class of efficient codes used in IT that reached\nthe Shannon limits in terms of information capacity for error correction and\nrobustness against noise, and parsimony. These efficient codes, which exploit\ninsightfully quantization and randomness, permit to deal with uncertainty,\nredundancy and compacity. These features can be used for perception and control\nin intelligent systems. In various examples and closing discussions, we reflect\non the broader implications of our framework that we called Informational\nEmbodiment to motor theory and bio-inspired robotics, touching upon concepts\nlike motor synergies, reservoir computing, and morphological computation. These\ninsights can contribute to a deeper understanding of how information theory\nintersects with the embodiment of intelligence in both natural and artificial\nsystems.",
      "tldr_zh": "这篇论文提出了“Informational Embodiment”框架，探讨了信息结构在机器人和计算代码中的计算作用，强调身体形态（如传感器精度、电机准确性和几何形状）如何影响信息感知和处理，将机器人视为物理通信通道。作者引入熵最大化原理（PEM）和Shannon源编码定理来优化设计，并讨论高效编码的运用，这些编码通过量化化和随机性实现错误修正、鲁棒性和信息容量最大化，以提升感知和控制的效率。在讨论中，该框架为运动理论、生物启发机器人等领域提供了新insights，包括运动协同、reservoir computing和形态计算，从而深化了对自然和人工智能体现的理解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12950v1",
      "published_date": "2024-08-23 09:59:45 UTC",
      "updated_date": "2024-08-23 09:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:18:43.370595"
    },
    {
      "arxiv_id": "2408.12942v2",
      "title": "Causal-Guided Active Learning for Debiasing Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Li Du",
        "Zhouhao Sun",
        "Xiao Ding",
        "Yixuan Ma",
        "Yang Zhao",
        "Kaitao Qiu",
        "Ting Liu",
        "Bing Qin"
      ],
      "abstract": "Although achieving promising performance, recent analyses show that current\ngenerative large language models (LLMs) may still capture dataset biases and\nutilize them for generation, leading to poor generalizability and harmfulness\nof LLMs. However, due to the diversity of dataset biases and the\nover-optimization problem, previous prior-knowledge-based debiasing methods and\nfine-tuning-based debiasing methods may not be suitable for current LLMs. To\naddress this issue, we explore combining active learning with the causal\nmechanisms and propose a casual-guided active learning (CAL) framework, which\nutilizes LLMs itself to automatically and autonomously identify informative\nbiased samples and induce the bias patterns. Then a cost-effective and\nefficient in-context learning based method is employed to prevent LLMs from\nutilizing dataset biases during generation. Experimental results show that CAL\ncan effectively recognize typical biased instances and induce various bias\npatterns for debiasing LLMs.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs) 因捕捉数据集偏差而导致的泛化能力差和有害性问题，并提出了一种因果引导的主动学习(Causal-Guided Active Learning, CAL) 框架来解决这一挑战。CAL 框架利用 LLMs 本身自动识别信息丰富的偏置样本并诱导偏差模式，然后通过成本有效的 in-context learning 方法防止模型在生成过程中依赖这些偏差。实验结果显示，该方法能有效识别典型的偏置实例并诱导各种偏差模式，从而显著提升 LLMs 的去偏性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as ACL 2024 main conference & Rewared as Outstanding Paper",
      "pdf_url": "http://arxiv.org/pdf/2408.12942v2",
      "published_date": "2024-08-23 09:46:15 UTC",
      "updated_date": "2024-08-30 07:30:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:18:55.281990"
    },
    {
      "arxiv_id": "2408.12941v1",
      "title": "iSee: Advancing Multi-Shot Explainable AI Using Case-based Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Anjana Wijekoon",
        "Nirmalie Wiratunga",
        "David Corsar",
        "Kyle Martin",
        "Ikechukwu Nkisi-Orji",
        "Chamath Palihawadana",
        "Marta Caro-Martínez",
        "Belen Díaz-Agudo",
        "Derek Bridge",
        "Anne Liret"
      ],
      "abstract": "Explainable AI (XAI) can greatly enhance user trust and satisfaction in\nAI-assisted decision-making processes. Recent findings suggest that a single\nexplainer may not meet the diverse needs of multiple users in an AI system;\nindeed, even individual users may require multiple explanations. This\nhighlights the necessity for a \"multi-shot\" approach, employing a combination\nof explainers to form what we introduce as an \"explanation strategy\". Tailored\nto a specific user or a user group, an \"explanation experience\" describes\ninteractions with personalised strategies designed to enhance their AI\ndecision-making processes. The iSee platform is designed for the intelligent\nsharing and reuse of explanation experiences, using Case-based Reasoning to\nadvance best practices in XAI. The platform provides tools that enable AI\nsystem designers, i.e. design users, to design and iteratively revise the most\nsuitable explanation strategy for their AI system to satisfy end-user needs.\nAll knowledge generated within the iSee platform is formalised by the iSee\nontology for interoperability. We use a summative mixed methods study protocol\nto evaluate the usability and utility of the iSee platform with six design\nusers across varying levels of AI and XAI expertise. Our findings confirm that\nthe iSee platform effectively generalises across applications and its potential\nto promote the adoption of XAI best practices.",
      "tldr_zh": "这篇论文提出了一种“多重解释”（multi-shot）方法，用于 Explainable AI (XAI)，通过结合多种解释器形成“解释策略”（explanation strategy），以满足用户在 AI 决策过程中的多样化需求。iSee 平台是核心贡献，利用 Case-based Reasoning 实现解释体验的智能共享和重用，并通过 iSee ontology 正式化知识以确保互操作性。平台提供工具，让 AI 系统设计师能够设计和迭代解释策略，针对特定用户或用户群优化交互。研究结果显示，iSee 平台在不同应用中表现出色，具有通用性和实用性，有助于推广 XAI 最佳实践。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to appear at the ECAI-PAIS 2024 main conference proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.12941v1",
      "published_date": "2024-08-23 09:44:57 UTC",
      "updated_date": "2024-08-23 09:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:19:07.668164"
    },
    {
      "arxiv_id": "2408.12936v2",
      "title": "Smooth InfoMax -- Towards easier Post-Hoc interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Denoodt",
        "Bart de Boer",
        "José Oramas"
      ],
      "abstract": "We introduce Smooth InfoMax (SIM), a novel method for self-supervised\nrepresentation learning that incorporates an interpretability constraint into\nthe learned representations at various depths of the neural network. SIM's\narchitecture is split up into probabilistic modules, each locally optimized\nusing the InfoNCE bound. Inspired by VAEs, the representations from these\nmodules are designed to be samples from Gaussian distributions and are further\nconstrained to be close to the standard normal distribution. This results in a\nsmooth and predictable space, enabling traversal of the latent space through a\ndecoder for easier post-hoc analysis of the learned representations. We\nevaluate SIM's performance on sequential speech data, showing that it performs\ncompetitively with its less interpretable counterpart, Greedy InfoMax (GIM).\nMoreover, we provide insights into SIM's internal representations,\ndemonstrating that the contained information is less entangled throughout the\nrepresentation and more concentrated in a smaller subset of the dimensions.\nThis further highlights the improved interpretability of SIM.",
      "tldr_zh": "本研究引入 Smooth InfoMax (SIM)，一种自监督表示学习方法，通过在神经网络不同深度融入可解释性约束，提升后验解释性。SIM 架构分为概率模块，每个模块使用 InfoNCE 边界局部优化，并受 VAEs 启发，将表示设计为高斯分布样本，并约束接近标准正态分布，从而创建平滑可预测的潜在空间，便于通过解码器遍历分析。实验结果显示，SIM 在顺序语音数据上与 Greedy InfoMax (GIM) 性能相当，且其内部表示信息较少纠缠，更集中在少量维度，进一步提高了表示的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12936v2",
      "published_date": "2024-08-23 09:36:09 UTC",
      "updated_date": "2025-03-19 16:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:19:18.894764"
    },
    {
      "arxiv_id": "2408.12935v3",
      "title": "Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural Framework for AI Safety with Challenges and Mitigations",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Chen",
        "Xueluan Gong",
        "Ziyao Liu",
        "Weifeng Jiang",
        "Si Qi Goh",
        "Kwok-Yan Lam"
      ],
      "abstract": "AI Safety is an emerging area of critical importance to the safe adoption and\ndeployment of AI systems. With the rapid proliferation of AI and especially\nwith the recent advancement of Generative AI (or GAI), the technology ecosystem\nbehind the design, development, adoption, and deployment of AI systems has\ndrastically changed, broadening the scope of AI Safety to address impacts on\npublic safety and national security. In this paper, we propose a novel\narchitectural framework for understanding and analyzing AI Safety; defining its\ncharacteristics from three perspectives: Trustworthy AI, Responsible AI, and\nSafe AI. We provide an extensive review of current research and advancements in\nAI safety from these perspectives, highlighting their key challenges and\nmitigation approaches. Through examples from state-of-the-art technologies,\nparticularly Large Language Models (LLMs), we present innovative mechanism,\nmethodologies, and techniques for designing and testing AI safety. Our goal is\nto promote advancement in AI safety research, and ultimately enhance people's\ntrust in digital transformation.",
      "tldr_zh": "本论文提出一个全面的架构框架，用于理解和分析AI Safety（AI 安全），从Trustworthy AI、Responsible AI和Safe AI三个视角定义其关键特性。该框架通过对当前AI安全研究的广泛回顾，突出了主要挑战（如AI系统对公共安全和国家安全的潜在影响）以及相应的缓解方法，例如利用Large Language Models (LLMs)中的创新机制和测试技术。论文以生成式AI的快速发展为背景，提供实际示例，旨在推进AI安全研究并增强公众对数字转型的信任。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12935v3",
      "published_date": "2024-08-23 09:33:48 UTC",
      "updated_date": "2025-01-15 10:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:19:29.903828"
    },
    {
      "arxiv_id": "2408.12927v2",
      "title": "Abductive and Contrastive Explanations for Scoring Rules in Voting",
      "title_zh": "溯因",
      "authors": [
        "Clément Contet",
        "Umberto Grandi",
        "Jérôme Mengin"
      ],
      "abstract": "We view voting rules as classifiers that assign a winner (a class) to a\nprofile of voters' preferences (an instance). We propose to apply techniques\nfrom formal explainability, most notably abductive and contrastive\nexplanations, to identify minimal subsets of a preference profile that either\nimply the current winner or explain why a different candidate was not elected.\nFormal explanations turn out to have strong connections with classical problems\nstudied in computational social choice such as bribery, possible and necessary\nwinner identification, and preference learning. We design algorithms for\ncomputing abductive and contrastive explanations for scoring rules. For the\nBorda rule, we find a lower bound on the size of the smallest abductive\nexplanations, and we conduct simulations to identify correlations between\nproperties of preference profiles and the size of their smallest abductive\nexplanations.",
      "tldr_zh": "本研究将投票规则视为分类器，将投票者偏好配置文件视为实例，并引入abductive explanations和contrastive explanations来识别最小子集，这些子集要么暗示当前获胜者，要么解释为什么其他候选人未当选。论文揭示了这些形式化解释与计算社会选择中的经典问题（如bribery、possible and necessary winner identification以及preference learning）存在紧密联系，并为scoring rules设计了相应的计算算法。对于Borda rule，研究提供了最小abductive explanations大小的下界，并通过模拟探索了偏好配置文件属性与其最小解释大小之间的相关性。这些发现为投票系统的可解释性提供了新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 2 figures Extended version of a paper in proceedings of\n  ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12927v2",
      "published_date": "2024-08-23 09:12:58 UTC",
      "updated_date": "2024-08-26 10:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:19:42.282416"
    },
    {
      "arxiv_id": "2408.12910v1",
      "title": "What Do You Want? User-centric Prompt Generation for Text-to-image Synthesis via Multi-turn Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yilun Liu",
        "Minggui He",
        "Feiyu Yao",
        "Yuhe Ji",
        "Shimin Tao",
        "Jingzhou Du",
        "Duan Li",
        "Jian Gao",
        "Li Zhang",
        "Hao Yang",
        "Boxing Chen",
        "Osamu Yoshie"
      ],
      "abstract": "The emergence of text-to-image synthesis (TIS) models has significantly\ninfluenced digital image creation by producing high-quality visuals from\nwritten descriptions. Yet these models heavily rely on the quality and\nspecificity of textual prompts, posing a challenge for novice users who may not\nbe familiar with TIS-model-preferred prompt writing. Existing solutions relieve\nthis via automatic model-preferred prompt generation from user queries.\nHowever, this single-turn manner suffers from limited user-centricity in terms\nof result interpretability and user interactivity. To address these issues, we\npropose DialPrompt, a multi-turn dialogue-based TIS prompt generation model\nthat emphasises user-centricity. DialPrompt is designed to follow a multi-turn\nguidance workflow, where in each round of dialogue the model queries user with\ntheir preferences on possible optimization dimensions before generating the\nfinal TIS prompt. To achieve this, we mined 15 essential dimensions for\nhigh-quality prompts from advanced users and curated a multi-turn dataset.\nThrough training on this dataset, DialPrompt can improve interpretability by\nallowing users to understand the correlation between specific phrases and image\nattributes. Additionally, it enables greater user control and engagement in the\nprompt generation process, leading to more personalized and visually satisfying\noutputs. Experiments indicate that DialPrompt achieves a competitive result in\nthe quality of synthesized images, outperforming existing prompt engineering\napproaches by 5.7%. Furthermore, in our user evaluation, DialPrompt outperforms\nexisting approaches by 46.5% in user-centricity score and is rated 7.9/10 by 19\nhuman reviewers.",
      "tldr_zh": "本研究针对文本到图像合成 (TIS) 模型对提示质量的依赖性，提出 DialPrompt，一种基于多轮对话的用户中心提示生成方法，以解决现有单轮自动生成方法的交互性和可解释性不足问题。DialPrompt 通过挖掘15个关键优化维度（如图像属性和用户偏好），在多轮指导中查询用户偏好，从而生成更个性化和高质量的 TIS 提示。实验结果显示，DialPrompt 的合成图像质量比现有方法提升5.7%，并在用户评价中，用户中心性得分高出46.5%，平均评分达到7.9/10。总的来说，该方法增强了用户对提示生成过程的控制和理解，推动了 TIS 模型的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12910v1",
      "published_date": "2024-08-23 08:35:35 UTC",
      "updated_date": "2024-08-23 08:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:19:55.894777"
    },
    {
      "arxiv_id": "2408.12909v2",
      "title": "CSPs with Few Alien Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Jonsson",
        "Victor Lagerkvist",
        "George Osipov"
      ],
      "abstract": "The constraint satisfaction problem asks to decide if a set of constraints\nover a relational structure $\\mathcal{A}$ is satisfiable (CSP$(\\mathcal{A})$).\nWe consider CSP$(\\mathcal{A} \\cup \\mathcal{B})$ where $\\mathcal{A}$ is a\nstructure and $\\mathcal{B}$ is an alien structure, and analyse its\n(parameterized) complexity when at most $k$ alien constraints are allowed. We\nestablish connections and obtain transferable complexity results to several\nwell-studied problems that previously escaped classification attempts. Our\nnovel approach, utilizing logical and algebraic methods, yields an FPT versus\npNP dichotomy for arbitrary finite structures and sharper dichotomies for\nBoolean structures and first-order reducts of $(\\mathbb{N},=)$ (equality CSPs),\ntogether with many partial results for general $\\omega$-categorical structures.",
      "tldr_zh": "该论文研究了约束满足问题（CSP），具体探讨了在结构 𝒜 上添加最多 k 个外来约束（alien constraints）后形成的 CSP(𝒜 ∪ ℬ）的参数化复杂性。作者采用逻辑和代数方法，建立了该问题与其他未分类问题的连接，并获得了可转移的复杂性结果。对于任意有限结构，论文证明了 FPT 与 pNP 的二分法（dichotomy）；对于 Boolean structures 和 first-order reducts of (ℕ,=) 等特定结构，提供了更精确的二分法；此外，还给出了适用于一般 ω-categorical structures 的部分结果。总的来说，这为 CSP 的复杂性分类提供了新的洞见和工具。",
      "categories": [
        "cs.CC",
        "cs.AI"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12909v2",
      "published_date": "2024-08-23 08:34:13 UTC",
      "updated_date": "2024-08-27 14:26:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:20:06.716981"
    },
    {
      "arxiv_id": "2408.12902v2",
      "title": "IAA: Inner-Adaptor Architecture Empowers Frozen Large Language Model with Multimodal Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Wang",
        "Chunyu Xie",
        "Dawei Leng",
        "Yuhui Yin"
      ],
      "abstract": "In the field of multimodal large language models (MLLMs), common methods\ntypically involve unfreezing the language model during training to foster\nprofound visual understanding. However, the fine-tuning of such models with\nvision-language data often leads to a diminution of their natural language\nprocessing (NLP) capabilities. To avoid this performance degradation, a\nstraightforward solution is to freeze the language model while developing\nmultimodal competencies. Unfortunately, previous works have not attained\nsatisfactory outcomes. Building on the strategy of freezing the language model,\nwe conduct thorough structural exploration and introduce the Inner-Adaptor\nArchitecture (IAA). Specifically, the architecture incorporates multiple\nmultimodal adaptors at varying depths within the large language model to\nfacilitate direct interaction with the inherently text-oriented transformer\nlayers, thereby enabling the frozen language model to acquire multimodal\ncapabilities. Unlike previous approaches of freezing language models that\nrequire large-scale aligned data, our proposed architecture is able to achieve\nsuperior performance on small-scale datasets. We conduct extensive experiments\nto improve the general multimodal capabilities and visual grounding abilities\nof the MLLM. Our approach remarkably outperforms previous state-of-the-art\nmethods across various vision-language benchmarks without sacrificing\nperformance on NLP tasks. Code and models are available at\nhttps://github.com/360CVGroup/Inner-Adaptor-Architecture.",
      "tldr_zh": "本研究提出 Inner-Adaptor Architecture (IAA)，一种创新框架，用于赋予冻结的大型语言模型多模态能力，同时避免传统训练中导致的自然语言处理 (NLP) 性能下降问题。IAA 通过在语言模型的不同深度添加多个多模态适配器，实现视觉信息与文本导向的 Transformer 层的直接交互，从而在小规模数据集上有效提升模型的多模态理解和视觉定位能力。与现有方法相比，该架构在各种视觉语言基准测试中表现出色，显著超越了状态-of-the-art 水平，同时保持了 NLP 任务的原有性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12902v2",
      "published_date": "2024-08-23 08:10:13 UTC",
      "updated_date": "2025-04-15 03:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:20:19.499734"
    },
    {
      "arxiv_id": "2408.12890v1",
      "title": "Multiple Areal Feature Aware Transportation Demand Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sumin Han",
        "Jisun An",
        "Youngjun Park",
        "Suji Kim",
        "Kitae Jang",
        "Dongman Lee"
      ],
      "abstract": "A reliable short-term transportation demand prediction supports the\nauthorities in improving the capability of systems by optimizing schedules,\nadjusting fleet sizes, and generating new transit networks. A handful of\nresearch efforts incorporate one or a few areal features while learning\nspatio-temporal correlation, to capture similar demand patterns between similar\nareas. However, urban characteristics are polymorphic, and they need to be\nunderstood by multiple areal features such as land use, sociodemographics, and\nplace-of-interest (POI) distribution. In this paper, we propose a novel\nspatio-temporal multi-feature-aware graph convolutional recurrent network\n(ST-MFGCRN) that fuses multiple areal features during spatio-temproal\nunderstanding. Inside ST-MFGCRN, we devise sentinel attention to calculate the\nareal similarity matrix by allowing each area to take partial attention if the\nfeature is not useful. We evaluate the proposed model on two real-world\ntransportation datasets, one with our constructed BusDJ dataset and one with\nbenchmark TaxiBJ. Results show that our model outperforms the state-of-the-art\nbaselines up to 7\\% on BusDJ and 8\\% on TaxiBJ dataset.",
      "tldr_zh": "该论文针对短期交通需求预测问题，提出了一种新型时空多特征感知图卷积循环网络（ST-MFGCRN），通过融合土地使用、社会人口统计和兴趣点（POI）分布等多项区域特征，捕捉城市区域间的相似需求模式。该模型引入 sentinel attention 机制来计算区域相似矩阵，允许每个区域根据特征的有用性进行部分关注，从而提升时空相关性的准确性。在真实数据集 BusDJ 和 TaxiBJ 上进行评估，结果显示 ST-MFGCRN 比最先进基线模型提高了最多 7% 和 8% 的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12890v1",
      "published_date": "2024-08-23 07:51:10 UTC",
      "updated_date": "2024-08-23 07:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:20:31.265703"
    },
    {
      "arxiv_id": "2408.12882v1",
      "title": "Spatio-Temporal Road Traffic Prediction using Real-time Regional Knowledge",
      "title_zh": "基于实时区域知识的时空道路交通预测",
      "authors": [
        "Sumin Han",
        "Jisun An",
        "Dongman Lee"
      ],
      "abstract": "For traffic prediction in transportation services such as car-sharing and\nride-hailing, mid-term road traffic prediction (within a few hours) is\nconsidered essential. However, the existing road-level traffic prediction has\nmainly studied how significantly micro traffic events propagate to the adjacent\nroads in terms of short-term prediction. On the other hand, recent attempts\nhave been made to incorporate regional knowledge such as POIs, road\ncharacteristics, and real-time social events to help traffic prediction.\nHowever, these studies lack in understandings of different modalities of\nroad-level and region-level spatio-temporal correlations and how to combine\nsuch knowledge. This paper proposes a novel method that embeds real-time\nregion-level knowledge using POIs, satellite images, and real-time LTE access\ntraces via a regional spatio-temporal module that consists of dynamic\nconvolution and temporal attention, and conducts bipartite spatial transform\nattention to convert into road-level knowledge. Then the model ingests this\nembedded knowledge into a road-level attention-based prediction model.\nExperimental results on real-world road traffic prediction show that our model\noutperforms the baselines.",
      "tldr_zh": "本研究针对中短期（几小时内）道路交通预测问题，提出了一种新方法，通过整合实时区域知识（如POIs、卫星图像和LTE traces）来解决现有模型在时空相关性理解和知识结合方面的不足。该方法首先使用一个区域时空模块（包括动态卷积和时间注意力）嵌入区域级知识，然后通过二分图空间变换注意力将其转换为道路级知识，并将其输入基于注意力的道路级预测模型。实验结果显示，该模型在真实世界交通预测任务中优于基线模型，显著提升了预测准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12882v1",
      "published_date": "2024-08-23 07:34:26 UTC",
      "updated_date": "2024-08-23 07:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:20:43.297729"
    },
    {
      "arxiv_id": "2408.12880v1",
      "title": "Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Qika Lin",
        "Yifan Zhu",
        "Xin Mei",
        "Ling Huang",
        "Jingying Ma",
        "Kai He",
        "Zhen Peng",
        "Erik Cambria",
        "Mengling Feng"
      ],
      "abstract": "The rapid development of artificial intelligence has constantly reshaped the\nfield of intelligent healthcare and medicine. As a vital technology, multimodal\nlearning has increasingly garnered interest due to data complementarity,\ncomprehensive modeling form, and great application potential. Currently,\nnumerous researchers are dedicating their attention to this field, conducting\nextensive studies and constructing abundant intelligent systems. Naturally, an\nopen question arises that has multimodal learning delivered universal\nintelligence in healthcare? To answer the question, we adopt three unique\nviewpoints for a holistic analysis. Firstly, we conduct a comprehensive survey\nof the current progress of medical multimodal learning from the perspectives of\ndatasets, task-oriented methods, and universal foundation models. Based on\nthem, we further discuss the proposed question from five issues to explore the\nreal impacts of advanced techniques in healthcare, from data and technologies\nto performance and ethics. The answer is that current technologies have NOT\nachieved universal intelligence and there remains a significant journey to\nundertake. Finally, in light of the above reviews and discussions, we point out\nten potential directions for exploration towards the goal of universal\nintelligence in healthcare.",
      "tldr_zh": "这篇论文对多模态学习（multimodal learning）在医疗领域是否实现了通用智能（universal intelligence）进行了全面调查。作者从数据集、任务导向方法和通用基础模型（foundation models）的视角审视了当前进展，并讨论了数据、技术、性能和伦理等五个关键问题。研究结论表明，现有的技术尚未达到这一目标，仍需长期努力；最后，论文提出了十个潜在方向，以推动医疗领域向通用智能的目标前进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12880v1",
      "published_date": "2024-08-23 07:31:01 UTC",
      "updated_date": "2024-08-23 07:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:20:55.662893"
    },
    {
      "arxiv_id": "2408.12879v1",
      "title": "Frequency-aware Feature Fusion for Dense Image Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Linwei Chen",
        "Ying Fu",
        "Lin Gu",
        "Chenggang Yan",
        "Tatsuya Harada",
        "Gao Huang"
      ],
      "abstract": "Dense image prediction tasks demand features with strong category information\nand precise spatial boundary details at high resolution. To achieve this,\nmodern hierarchical models often utilize feature fusion, directly adding\nupsampled coarse features from deep layers and high-resolution features from\nlower levels. In this paper, we observe rapid variations in fused feature\nvalues within objects, resulting in intra-category inconsistency due to\ndisturbed high-frequency features. Additionally, blurred boundaries in fused\nfeatures lack accurate high frequency, leading to boundary displacement.\nBuilding upon these observations, we propose Frequency-Aware Feature Fusion\n(FreqFusion), integrating an Adaptive Low-Pass Filter (ALPF) generator, an\noffset generator, and an Adaptive High-Pass Filter (AHPF) generator. The ALPF\ngenerator predicts spatially-variant low-pass filters to attenuate\nhigh-frequency components within objects, reducing intra-class inconsistency\nduring upsampling. The offset generator refines large inconsistent features and\nthin boundaries by replacing inconsistent features with more consistent ones\nthrough resampling, while the AHPF generator enhances high-frequency detailed\nboundary information lost during downsampling. Comprehensive visualization and\nquantitative analysis demonstrate that FreqFusion effectively improves feature\nconsistency and sharpens object boundaries. Extensive experiments across\nvarious dense prediction tasks confirm its effectiveness. The code is made\npublicly available at https://github.com/Linwei-Chen/FreqFusion.",
      "tldr_zh": "本论文针对密集图像预测任务中特征融合的问题，观察到直接添加上采样粗糙特征和高分辨率特征会导致类别内不一致（intra-category inconsistency）和边界模糊（boundary displacement），主要是由于高频特征的干扰和丢失。作者提出Frequency-Aware Feature Fusion (FreqFusion)框架，包括Adaptive Low-Pass Filter (ALPF) generator用于衰减对象内部高频成分以减少不一致、offset generator通过重采样精炼不一致特征和边界，以及Adaptive High-Pass Filter (AHPF) generator增强丢失的边界细节。实验结果显示，FreqFusion显著改善了特征一致性和边界锐化，在各种密集预测任务上表现出优越性能，并已公开代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TPAMI (2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.12879v1",
      "published_date": "2024-08-23 07:30:34 UTC",
      "updated_date": "2024-08-23 07:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:21:08.140571"
    },
    {
      "arxiv_id": "2408.15012v2",
      "title": "Flexible categorization using formal concept analysis and Dempster-Shafer theory",
      "title_zh": "翻译失败",
      "authors": [
        "Marcel Boersma",
        "Krishna Manoorkar",
        "Alessandra Palmigiano",
        "Mattia Panettiere",
        "Apostolos Tzimoulis",
        "Nachoem Wijnberg"
      ],
      "abstract": "The framework developed in the present paper provides a formal ground to\ngenerate and study explainable categorizations of sets of entities, based on\nthe epistemic attitudes of individual agents or groups thereof. Based on this\nframework, we discuss a machine-leaning meta-algorithm for outlier detection\nand classification which provides local and global explanations of its results.",
      "tldr_zh": "本论文提出一个框架，利用 Formal Concept Analysis 和 Dempster-Shafer theory，作为生成和研究实体集可解释分类的正式基础，该分类基于个体或群体认知态度。框架强调了分类的可解释性，从而支持对知识的深入分析。基于此，论文讨论了一个机器学习元算法，用于异常检测和分类，该算法能提供局部和全局解释结果，从而提升分类过程的透明度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2210.17330",
      "pdf_url": "http://arxiv.org/pdf/2408.15012v2",
      "published_date": "2024-08-23 07:28:20 UTC",
      "updated_date": "2024-12-25 15:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:21:19.645054"
    },
    {
      "arxiv_id": "2408.12871v5",
      "title": "DeepDiveAI: Identifying AI Related Documents in Large Scale Literature Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhou Xiaochen",
        "Liang Xingzhou",
        "Zou Hui",
        "Lu Yi",
        "Qu Jingjing"
      ],
      "abstract": "In this paper, we propose a method to automatically classify AI-related\ndocuments from large-scale literature databases, leading to the creation of an\nAI-related literature dataset, named DeepDiveAI. The dataset construction\napproach integrates expert knowledge with the capabilities of advanced models,\nstructured across two global stages. In the first stage, expert-curated\nclassification datasets are used to train an LSTM model, which classifies\ncoarse AI related records from large-scale datasets. In the second stage, we\nuse Qwen2.5 Plus to annotate a random 10% of the coarse AI-related records,\nwhich are then used to train a BERT binary classifier. This step further\nrefines the coarse AI related record set to obtain the final DeepDiveAI\ndataset. Evaluation results demonstrate that the entire workflow can\nefficiently and accurately identify AI-related literature from large-scale\ndatasets.",
      "tldr_zh": "本论文提出了一种自动分类方法，用于从大规模文献数据库中识别 AI 相关文档，并构建了名为 DeepDiveAI 的数据集。该方法分为两个阶段：首先，使用专家策划的分类数据集训练 LSTM 模型，对大规模数据进行粗略的 AI 相关记录分类；其次，利用 Qwen2.5 Plus 标注这些记录的 10%，并以此训练 BERT 二元分类器，进一步提炼得到最终数据集。实验评估显示，该工作流能够高效且准确地识别 AI 相关文献，为后续 AI 研究提供宝贵资源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12871v5",
      "published_date": "2024-08-23 07:05:12 UTC",
      "updated_date": "2025-04-22 12:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:21:31.930940"
    },
    {
      "arxiv_id": "2408.12870v1",
      "title": "Can AI Assistance Aid in the Grading of Handwritten Answer Sheets?",
      "title_zh": "AI 辅助是否能帮助批改手写答卷？",
      "authors": [
        "Pritam Sil",
        "Parag Chaudhuri",
        "Bhaskaran Raman"
      ],
      "abstract": "With recent advancements in artificial intelligence (AI), there has been\ngrowing interest in using state of the art (SOTA) AI solutions to provide\nassistance in grading handwritten answer sheets. While a few commercial\nproducts exist, the question of whether AI-assistance can actually reduce\ngrading effort and time has not yet been carefully considered in published\nliterature. This work introduces an AI-assisted grading pipeline. The pipeline\nfirst uses text detection to automatically detect question regions present in a\nquestion paper PDF. Next, it uses SOTA text detection methods to highlight\nimportant keywords present in the handwritten answer regions of scanned answer\nsheets to assist in the grading process. We then evaluate a prototype\nimplementation of the AI-assisted grading pipeline deployed on an existing\ne-learning management platform. The evaluation involves a total of 5 different\nreal-life examinations across 4 different courses at a reputed institute; it\nconsists of a total of 42 questions, 17 graders, and 468 submissions. We log\nand analyze the grading time for each handwritten answer while using AI\nassistance and without it. Our evaluations have shown that, on average, the\ngraders take 31% less time while grading a single response and 33% less grading\ntime while grading a single answer sheet using AI assistance.",
      "tldr_zh": "这篇论文探讨了AI是否能有效辅助批改手写答卷，并引入了一个AI辅助批改管道，以减少批改工作量。管道首先使用文本检测技术自动识别试卷PDF中的问题区域，然后应用SOTA文本检测方法突出手写答案中的重要关键词。实验评估涉及5个真实考试、4个课程、42个问题、17名批改者和468份提交，结果显示使用AI辅助后，批改单响应时间平均减少31%，批改单答卷时间减少33%。这项研究为AI在教育评估中的应用提供了实证支持。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12870v1",
      "published_date": "2024-08-23 07:00:25 UTC",
      "updated_date": "2024-08-23 07:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:21:45.179900"
    },
    {
      "arxiv_id": "2408.12866v1",
      "title": "Obfuscated Memory Malware Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sharmila S P",
        "Aruna Tiwari",
        "Narendra S Chaudhari"
      ],
      "abstract": "Providing security for information is highly critical in the current era with\ndevices enabled with smart technology, where assuming a day without the\ninternet is highly impossible. Fast internet at a cheaper price, not only made\ncommunication easy for legitimate users but also for cybercriminals to induce\nattacks in various dimensions to breach privacy and security. Cybercriminals\ngain illegal access and breach the privacy of users to harm them in multiple\nways. Malware is one such tool used by hackers to execute their malicious\nintent. Development in AI technology is utilized by malware developers to cause\nsocial harm. In this work, we intend to show how Artificial Intelligence and\nMachine learning can be used to detect and mitigate these cyber-attacks induced\nby malware in specific obfuscated malware. We conducted experiments with memory\nfeature engineering on memory analysis of malware samples. Binary\nclassification can identify whether a given sample is malware or not, but\nidentifying the type of malware will only guide what next step to be taken for\nthat malware, to stop it from proceeding with its further action. Hence, we\npropose a multi-class classification model to detect the three types of\nobfuscated malware with an accuracy of 89.07% using the Classic Random Forest\nalgorithm. To the best of our knowledge, there is very little amount of work\ndone in classifying multiple obfuscated malware by a single model. We also\ncompared our model with a few state-of-the-art models and found it\ncomparatively better.",
      "tldr_zh": "本文探讨了混淆恶意软件(obfuscated malware)的检测问题，强调了在智能设备时代网络安全的重要性，并提出使用人工智能和机器学习进行检测和缓解。研究通过内存特征工程(memory feature engineering)实验，开发了一个多类分类(multi-class classification)模型，采用 Classic Random Forest 算法对三种混淆恶意软件进行识别，准确率达到89.07%。与现有最先进模型相比，该模型表现出色，且是少数针对多种混淆恶意软件的单一模型工作之一。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages 9 figures presented in IEEE CCEM Conference paper",
      "pdf_url": "http://arxiv.org/pdf/2408.12866v1",
      "published_date": "2024-08-23 06:39:15 UTC",
      "updated_date": "2024-08-23 06:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:21:55.828125"
    },
    {
      "arxiv_id": "2408.13287v1",
      "title": "Abstract Art Interpretation Using ControlNet",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Srivastava",
        "Addrish Roy"
      ],
      "abstract": "Our study delves into the fusion of abstract art interpretation and\ntext-to-image synthesis, addressing the challenge of achieving precise spatial\ncontrol over image composition solely through textual prompts. Leveraging the\ncapabilities of ControlNet, we empower users with finer control over the\nsynthesis process, enabling enhanced manipulation of synthesized imagery.\nInspired by the minimalist forms found in abstract artworks, we introduce a\nnovel condition crafted from geometric primitives such as triangles.",
      "tldr_zh": "本研究探讨了抽象艺术解释与文本到图像合成（text-to-image synthesis）的融合，旨在解决通过文本提示实现图像组成精确空间控制的挑战。利用ControlNet，该方法赋予用户更精细的合成过程操控能力，允许对生成的图像进行增强操作。研究引入了一种基于几何原语（如三角形）的新型条件，受抽象艺术中极简形式启发，从而提升了图像合成的灵活性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.13287v1",
      "published_date": "2024-08-23 06:25:54 UTC",
      "updated_date": "2024-08-23 06:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:22:06.540739"
    },
    {
      "arxiv_id": "2408.12857v1",
      "title": "Memory-Efficient LLM Training with Online Subspace Descent",
      "title_zh": "基于在线子空间下降的内存",
      "authors": [
        "Kaizhao Liang",
        "Bo Liu",
        "Lizhang Chen",
        "Qiang Liu"
      ],
      "abstract": "Recently, a wide range of memory-efficient LLM training algorithms have\ngained substantial popularity. These methods leverage the low-rank structure of\ngradients to project optimizer states into a subspace using projection matrix\nfound by singular value decomposition (SVD). However, convergence of these\nalgorithms is highly dependent on the update rules of their projection matrix.\nIn this work, we provide the \\emph{first} convergence guarantee for arbitrary\nupdate rules of projection matrix. This guarantee is generally applicable to\noptimizers that can be analyzed with Hamiltonian Descent, including most common\nones, such as LION, Adam. Inspired by our theoretical understanding, we propose\nOnline Subspace Descent, a new family of subspace descent optimizer without\nSVD. Instead of updating the projection matrix with eigenvectors, Online\nSubspace Descent updates the projection matrix with online PCA. Online Subspace\nDescent is flexible and introduces only minimum overhead to training. We show\nthat for the task of pretraining LLaMA models ranging from 60M to 7B parameters\non the C4 dataset, Online Subspace Descent achieves lower perplexity and better\ndownstream tasks performance than state-of-the-art low-rank training methods\nacross different settings and narrows the gap with full-rank baselines.",
      "tldr_zh": "该研究首先提供了针对任意投影矩阵更新规则的收敛保证，适用于基于Hamiltonian Descent的优化器，如LION和Adam，以提升内存高效的LLM训练算法。论文提出Online Subspace Descent，一种新颖的子空间下降优化器，它取代SVD，使用在线PCA更新投影矩阵，从而实现灵活性和最小训练开销。在C4数据集上预训练LLaMA模型（从60M到7B参数）的实验中，该方法比现有低秩训练方法降低了perplexity，并改善了下游任务性能，同时缩小了与全秩基线的差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at\n  https://github.com/kyleliang919/Online-Subspace-Descent",
      "pdf_url": "http://arxiv.org/pdf/2408.12857v1",
      "published_date": "2024-08-23 05:54:53 UTC",
      "updated_date": "2024-08-23 05:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:22:19.389190"
    },
    {
      "arxiv_id": "2408.12845v1",
      "title": "Online Fair Division with Contextual Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Arun Verma",
        "Indrajit Saha",
        "Makoto Yokoo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "This paper considers a novel online fair division problem involving multiple\nagents in which a learner observes an indivisible item that has to be\nirrevocably allocated to one of the agents while satisfying a fairness and\nefficiency constraint. Existing algorithms assume a small number of items with\na sufficiently large number of copies, which ensures a good utility estimation\nfor all item-agent pairs. However, such an assumption may not hold in many\nreal-life applications, e.g., an online platform that has a large number of\nusers (items) who only use the platform's service providers (agents) a few\ntimes (a few copies of items), which makes it difficult to estimate the utility\nfor all item-agent pairs. To overcome this challenge, we model the online fair\ndivision problem using contextual bandits, assuming the utility is an unknown\nfunction of the item-agent features. We then propose algorithms for online fair\ndivision with sub-linear regret guarantees. Our experimental results also\nverify the different performance aspects of the proposed algorithms.",
      "tldr_zh": "这篇论文探讨了在线公平分配问题（online fair division），涉及多个代理人分配不可分割物品，同时满足公平性和效率约束。针对现有算法在效用估计方面的局限（如物品副本有限），作者使用 contextual bandits 建模，假设效用是物品-代理人特征的未知函数。论文提出算法，提供 sub-linear regret guarantees，并在实验中验证了这些算法的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "We study an online fair division problem that has a large number of\n  items with only a few copies of each item and propose contextual\n  bandits-based algorithms with sub-linear regret guarantees",
      "pdf_url": "http://arxiv.org/pdf/2408.12845v1",
      "published_date": "2024-08-23 05:25:58 UTC",
      "updated_date": "2024-08-23 05:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:22:31.708676"
    },
    {
      "arxiv_id": "2408.12844v1",
      "title": "Predicting Affective States from Screen Text Sentiment",
      "title_zh": "翻译失败",
      "authors": [
        "Songyan Teng",
        "Tianyi Zhang",
        "Simon D'Alfonso",
        "Vassilis Kostakos"
      ],
      "abstract": "The proliferation of mobile sensing technologies has enabled the study of\nvarious physiological and behavioural phenomena through unobtrusive data\ncollection from smartphone sensors. This approach offers real-time insights\ninto individuals' physical and mental states, creating opportunities for\npersonalised treatment and interventions. However, the potential of analysing\nthe textual content viewed on smartphones to predict affective states remains\nunderexplored. To better understand how the screen text that users are exposed\nto and interact with can influence their affects, we investigated a subset of\ndata obtained from a digital phenotyping study of Australian university\nstudents conducted in 2023. We employed linear regression, zero-shot, and\nmulti-shot prompting using a large language model (LLM) to analyse\nrelationships between screen text and affective states. Our findings indicate\nthat multi-shot prompting substantially outperforms both linear regression and\nzero-shot prompting, highlighting the importance of context in affect\nprediction. We discuss the value of incorporating textual and sentiment data\nfor improving affect prediction, providing a basis for future advancements in\nunderstanding smartphone use and wellbeing.",
      "tldr_zh": "这篇论文探讨了通过分析智能手机屏幕文本的情感（affective states）来预测用户情感状态的可能性，填补了这一领域的探索空白。研究利用2023年澳大利亚大学学生的数字表型数据子集，采用线性回归（linear regression）、zero-shot prompting和multi-shot prompting结合大型语言模型（LLM）的方法，分析屏幕文本与情感状态的关系。结果表明，multi-shot prompting显著优于其他方法，突出了上下文的重要性；论文讨论了整合文本和情感数据以提升预测准确性，为理解智能手机使用及其对福祉的影响提供了新基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12844v1",
      "published_date": "2024-08-23 05:25:11 UTC",
      "updated_date": "2024-08-23 05:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:22:43.969907"
    },
    {
      "arxiv_id": "2408.12841v2",
      "title": "COVID-19 Probability Prediction Using Machine Learning: An Infectious Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Asghari Ilani",
        "Saba Moftakhar Tehran",
        "Ashkan Kavei",
        "Arian Radmehr"
      ],
      "abstract": "The ongoing COVID-19 pandemic continues to pose significant challenges to\nglobal public health, despite the widespread availability of vaccines. Early\ndetection of the disease remains paramount in curbing its transmission and\nmitigating its impact on public health systems. In response, this study delves\ninto the application of advanced machine learning (ML) techniques for\npredicting COVID-19 infection probability. We conducted a rigorous\ninvestigation into the efficacy of various ML models, including XGBoost, LGBM,\nAdaBoost, Logistic Regression, Decision Tree, RandomForest, CatBoost, KNN, and\nDeep Neural Networks (DNN). Leveraging a dataset comprising 4000 samples, with\n3200 allocated for training and 800 for testing, our experiment offers\ncomprehensive insights into the performance of these models in COVID-19\nprediction. Our findings reveal that Deep Neural Networks (DNN) emerge as the\ntop-performing model, exhibiting superior accuracy and recall metrics. With an\nimpressive accuracy rate of 89%, DNN demonstrates remarkable potential in early\nCOVID-19 detection. This underscores the efficacy of deep learning approaches\nin leveraging complex data patterns to identify COVID-19 infections accurately.\nThis study underscores the critical role of machine learning, particularly deep\nlearning methodologies, in augmenting early detection efforts amidst the\nongoing pandemic. The success of DNN in accurately predicting COVID-19\ninfection probability highlights the importance of continued research and\ndevelopment in leveraging advanced technologies to combat infectious diseases.",
      "tldr_zh": "本研究利用机器学习技术预测 COVID-19 感染概率，评估了多种模型包括 XGBoost、LGBM、AdaBoost、Logistic Regression、Decision Tree、RandomForest、CatBoost、KNN 和 DNN。\n实验基于 4000 个样本的数据集（3200 用于训练，800 用于测试），结果显示 DNN 表现出色，准确率达 89%，在准确性和召回率上优于其他模型。\n这项工作证明了深度学习方法在捕捉复杂数据模式方面的优势，有助于提升 COVID-19 的早期检测和公共卫生应对策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12841v2",
      "published_date": "2024-08-23 05:15:24 UTC",
      "updated_date": "2024-12-04 01:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:22:56.362930"
    },
    {
      "arxiv_id": "2408.12838v2",
      "title": "Exploring Machine Learning Models for Lung Cancer Level Classification: A comparative ML Approach",
      "title_zh": "探索机器",
      "authors": [
        "Mohsen Asghari Ilani",
        "Saba Moftakhar Tehran",
        "Ashkan Kavei",
        "Hamed Alizadegan"
      ],
      "abstract": "This paper explores machine learning (ML) models for classifying lung cancer\nlevels to improve diagnostic accuracy and prognosis. Through parameter tuning\nand rigorous evaluation, we assess various ML algorithms. Techniques like\nminimum child weight and learning rate monitoring were used to reduce\noverfitting and optimize performance. Our findings highlight the robust\nperformance of Deep Neural Network (DNN) models across all phases. Ensemble\nmethods, including voting and bagging, also showed promise in enhancing\npredictive accuracy and robustness. However, Support Vector Machine (SVM)\nmodels with the Sigmoid kernel faced challenges, indicating a need for further\nrefinement. Overall, our study provides insights into ML-based lung cancer\nclassification, emphasizing the importance of parameter tuning to optimize\nmodel performance and improve diagnostic accuracy in oncological care.",
      "tldr_zh": "本文通过比较多种机器学习模型（如 Deep Neural Network (DNN)、Ensemble methods 和 Support Vector Machine (SVM)），探索肺癌水平分类，以提升诊断准确性和预后评估。研究采用参数调整技术（如最小子权重和学习率监控）来减少过拟合并优化模型性能，结果显示 DNN 在所有阶段表现强劲，而 Ensemble 方法（如投票和 bagging）显著提高了预测准确性和鲁棒性。总体上，该研究强调参数调优的关键作用，为 ML 在肿瘤护理中的应用提供了重要见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12838v2",
      "published_date": "2024-08-23 04:56:36 UTC",
      "updated_date": "2024-12-04 04:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:23:09.761134"
    },
    {
      "arxiv_id": "2408.12837v2",
      "title": "Underwater SONAR Image Classification and Analysis using LIME-based Explainable Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Purushothaman Natarajan",
        "Athira Nambiar"
      ],
      "abstract": "Deep learning techniques have revolutionized image classification by\nmimicking human cognition and automating complex decision-making processes.\nHowever, the deployment of AI systems in the wild, especially in high-security\ndomains such as defence, is curbed by the lack of explainability of the model.\nTo this end, eXplainable AI (XAI) is an emerging area of research that is\nintended to explore the unexplained hidden black box nature of deep neural\nnetworks. This paper explores the application of the eXplainable Artificial\nIntelligence (XAI) tool to interpret the underwater image classification\nresults, one of the first works in the domain to the best of our knowledge. Our\nstudy delves into the realm of SONAR image classification using a custom\ndataset derived from diverse sources, including the Seabed Objects KLSG\ndataset, the camera SONAR dataset, the mine SONAR images dataset, and the SCTD\ndataset. An extensive analysis of transfer learning techniques for image\nclassification using benchmark Convolutional Neural Network (CNN) architectures\nsuch as VGG16, ResNet50, InceptionV3, DenseNet121, etc. is carried out. On top\nof this classification model, a post-hoc XAI technique, viz. Local\nInterpretable Model-Agnostic Explanations (LIME) are incorporated to provide\ntransparent justifications for the model's decisions by perturbing input data\nlocally to see how predictions change. Furthermore, Submodular Picks LIME\n(SP-LIME) a version of LIME particular to images, that perturbs the image based\non the submodular picks is also extensively studied. To this end, two\nsubmodular optimization algorithms i.e. Quickshift and Simple Linear Iterative\nClustering (SLIC) are leveraged towards submodular picks. The extensive\nanalysis of XAI techniques highlights interpretability of the results in a more\nhuman-compliant way, thus boosting our confidence and reliability.",
      "tldr_zh": "这篇论文探讨了使用可解释人工智能(XAI)工具LIME来解释水下SONAR图像分类结果，旨在解决深度学习模型的黑箱问题，从而提升在高安全领域如国防中的可信度。研究团队构建了一个自定义数据集，并通过转移学习技术应用多种基准CNN架构（如VGG16、ResNet50、InceptionV3和DenseNet121）进行图像分类。接着，他们整合了后验XAI方法，包括LIME和SP-LIME（利用Quickshift和SLIC子模优化算法），通过局部扰动输入数据来提供透明的决策解释。结果表明，这些XAI技术显著提高了分类结果的可解释性，增强了模型的可靠性和人类兼容性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "68T07 (Primary) 68T45, 68U10 (Secondary)",
        "I.4.8; I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "55 pages, 9 tables, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12837v2",
      "published_date": "2024-08-23 04:54:18 UTC",
      "updated_date": "2024-09-23 14:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:23:21.673034"
    },
    {
      "arxiv_id": "2408.12834v1",
      "title": "CLLMFS: A Contrastive Learning enhanced Large Language Model Framework for Few-Shot Named Entity Recognition",
      "title_zh": "CLLMFS：对比学习增强型大语言模型框架，用于少样本命名实体识别",
      "authors": [
        "Yafeng Zhang",
        "Zilan Yu",
        "Yuang Huang",
        "Jing Tang"
      ],
      "abstract": "Few-shot Named Entity Recognition (NER), the task of identifying named\nentities with only a limited amount of labeled data, has gained increasing\nsignificance in natural language processing. While existing methodologies have\nshown some effectiveness, such as enriching label semantics through various\nprompting modes or employing metric learning techniques, their performance\nexhibits limited robustness across diverse domains due to the lack of rich\nknowledge in their pre-trained models. To address this issue, we propose\nCLLMFS, a Contrastive Learning enhanced Large Language Model (LLM) Framework\nfor Few-Shot Named Entity Recognition, achieving promising results with limited\ntraining data. Considering the impact of LLM's internal representations on\ndownstream tasks, CLLMFS integrates Low-Rank Adaptation (LoRA) and contrastive\nlearning mechanisms specifically tailored for few-shot NER. By enhancing the\nmodel's internal representations, CLLMFS effectively improves both entity\nboundary awareness ability and entity recognition accuracy. Our method has\nachieved state-of-the-art performance improvements on F1-score ranging from\n2.58\\% to 97.74\\% over existing best-performing methods across several\nrecognized benchmarks. Furthermore, through cross-domain NER experiments\nconducted on multiple datasets, we have further validated the robust\ngeneralization capability of our method. Our code will be released in the near\nfuture.",
      "tldr_zh": "本研究针对Few-Shot Named Entity Recognition（少量标注数据下的命名实体识别）任务，提出CLLMFS框架，该框架通过Contrastive Learning增强Large Language Model（LLM）的内部表示，以解决现有方法在跨领域应用中的鲁棒性不足问题。CLLMFS整合Low-Rank Adaptation（LoRA）和对比学习机制，显著提升了模型的实体边界感知能力和识别准确性。在多个基准数据集上，该方法在F1-score上比现有最佳方法提高了2.58%至97.74%，并通过跨领域实验验证了其强大的泛化能力。整体而言，CLLMFS为少样本NER提供了高效且可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE",
      "pdf_url": "http://arxiv.org/pdf/2408.12834v1",
      "published_date": "2024-08-23 04:44:05 UTC",
      "updated_date": "2024-08-23 04:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:23:32.267866"
    },
    {
      "arxiv_id": "2408.12821v1",
      "title": "Examining the Commitments and Difficulties Inherent in Multimodal Foundation Models for Street View Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyuan Yang",
        "Xuhui Lin",
        "Qinyi He",
        "Ziye Huang",
        "Zhengliang Liu",
        "Hanqi Jiang",
        "Peng Shu",
        "Zihao Wu",
        "Yiwei Li",
        "Stephen Law",
        "Gengchen Mai",
        "Tianming Liu",
        "Tao Yang"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) and multimodal foundation\nmodels (FMs) has generated heightened interest in their applications that\nintegrate vision and language. This paper investigates the capabilities of\nChatGPT-4V and Gemini Pro for Street View Imagery, Built Environment, and\nInterior by evaluating their performance across various tasks. The assessments\ninclude street furniture identification, pedestrian and car counts, and road\nwidth measurement in Street View Imagery; building function classification,\nbuilding age analysis, building height analysis, and building structure\nclassification in the Built Environment; and interior room classification,\ninterior design style analysis, interior furniture counts, and interior length\nmeasurement in Interior. The results reveal proficiency in length measurement,\nstyle analysis, question answering, and basic image understanding, but\nhighlight limitations in detailed recognition and counting tasks. While\nzero-shot learning shows potential, performance varies depending on the problem\ndomains and image complexities. This study provides new insights into the\nstrengths and weaknesses of multimodal foundation models for practical\nchallenges in Street View Imagery, Built Environment, and Interior. Overall,\nthe findings demonstrate foundational multimodal intelligence, emphasizing the\npotential of FMs to drive forward interdisciplinary applications at the\nintersection of computer vision and language.",
      "tldr_zh": "这篇论文考察了多模态基础模型（FMs）如 ChatGPT-4V 和 Gemini Pro 在街景图像、建筑环境和室内场景中的能力和局限，通过评估多种任务如街头家具识别、行人和汽车计数、道路宽度测量、建筑功能分类以及室内设计风格分析等。研究发现，这些模型在长度测量、风格分析、问答和基本图像理解方面表现出色，但在详细识别和计数任务上存在显著不足。零样本学习（zero-shot learning）显示出潜力，但性能因问题领域和图像复杂度而异。该研究为多模态模型在计算机视觉和语言交叉领域的实际应用提供了新的见解，强调了其基础智能的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12821v1",
      "published_date": "2024-08-23 03:45:31 UTC",
      "updated_date": "2024-08-23 03:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:23:44.506777"
    },
    {
      "arxiv_id": "2408.12815v3",
      "title": "Staircase Cascaded Fusion of Lightweight Local Pattern Recognition and Long-Range Dependencies for Structural Crack Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Liu",
        "Chen Jia",
        "Fan Shi",
        "Xu Cheng",
        "Mianzhao Wang",
        "Shengyong Chen"
      ],
      "abstract": "Detecting cracks with pixel-level precision for key structures is a\nsignificant challenge, existing methods struggle to integrate local textures\nand pixel dependencies of cracks. Furthermore, these methods possess numerous\nparameters and substantial computational requirements, complicating deployment\non edge devices. In this paper, we propose the Staircase Cascaded Fusion Crack\nSegmentation Network (CrackSCF), which generates high-quality crack\nsegmentation maps while reducing computational overhead. We design a\nlightweight convolutional block that substitutes all convolution operations,\nreducing the model's computational demands while maintaining an effective\ncapture of local details. Additionally, we introduce a lightweight long-range\ndependency extractor to better capture the long-range dependencies.\nFurthermore, we develop a staircase cascaded fusion module, which seamlessly\nintegrates local patterns and long-range dependencies, resulting in\nhigh-quality segmentation maps. To comprehensively evaluate our method, we\ncreated the challenging TUT benchmark dataset and evaluated it alongside five\nother public datasets. The results show that our method outperforms existing\nmethods, particularly in handling background noise and achieving detailed\nsegmentation. The F1 and mIoU scores on the TUT dataset are 0.8382 and 0.8473,\nrespectively, demonstrating state-of-the-art (SOTA) performance with low\ncomputational resources. The code and dataset is available at\nhttps://github.com/Karl1109/CrackSCF.",
      "tldr_zh": "本文提出 Staircase Cascaded Fusion Crack Segmentation Network (CrackSCF)，一种轻量级网络，用于解决结构裂缝像素级分割的挑战，通过整合局部模式和长距离 dependencies，减少计算开销并提升分割质量。CrackSCF 包括轻量级卷积块用于捕获局部细节、轻量级长距离依赖提取器用于处理全局信息，以及阶梯级联融合模块来无缝融合这些特征。作者创建了挑战性的 TUT 基准数据集，并在五个公共数据集上评估，结果显示该方法在处理背景噪声和详细分割方面优于现有方法。TUT 数据集上的 F1 分数为 0.8382 和 mIoU 为 0.8473，实现了 SOTA 性能，同时适合边缘设备部署。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12815v3",
      "published_date": "2024-08-23 03:21:51 UTC",
      "updated_date": "2025-02-24 08:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:23:58.292923"
    },
    {
      "arxiv_id": "2408.12809v2",
      "title": "DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation",
      "title_zh": "DutyTTE：解读起止点旅行时间估计中的不确定性",
      "authors": [
        "Xiaowei Mao",
        "Yan Lin",
        "Shengnan Guo",
        "Yubin Chen",
        "Xingyu Xian",
        "Haomin Wen",
        "Qisen Xu",
        "Youfang Lin",
        "Huaiyu Wan"
      ],
      "abstract": "Uncertainty quantification in travel time estimation (TTE) aims to estimate\nthe confidence interval for travel time, given the origin (O), destination (D),\nand departure time (T). Accurately quantifying this uncertainty requires\ngenerating the most likely path and assessing travel time uncertainty along the\npath. This involves two main challenges: 1) Predicting a path that aligns with\nthe ground truth, and 2) modeling the impact of travel time in each segment on\noverall uncertainty under varying conditions. We propose DutyTTE to address\nthese challenges. For the first challenge, we introduce a deep reinforcement\nlearning method to improve alignment between the predicted path and the ground\ntruth, providing more accurate travel time information from road segments to\nimprove TTE. For the second challenge, we propose a mixture of experts guided\nuncertainty quantification mechanism to better capture travel time uncertainty\nfor each segment under varying contexts. Additionally, we calibrate our results\nusing Hoeffding's upper-confidence bound to provide statistical guarantees for\nthe estimated confidence intervals. Extensive experiments on two real-world\ndatasets demonstrate the superiority of our proposed method.",
      "tldr_zh": "这篇论文提出DutyTTE框架，用于量化起点（O）、终点（D）和出发时间（T）下的旅行时间估计（TTE）不确定性，旨在解决预测路径与真实路径对齐以及建模路段不确定性的两大挑战。方法包括使用deep reinforcement learning优化路径预测以提高准确性，以及引入mixture of experts guided uncertainty quantification mechanism来捕捉不同上下文下的路段旅行时间不确定性。此外，通过Hoeffding's upper-confidence bound校准结果以提供统计保证，实验在两个真实世界数据集上证明了该方法的优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12809v2",
      "published_date": "2024-08-23 03:06:04 UTC",
      "updated_date": "2025-01-20 08:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:24:10.078763"
    },
    {
      "arxiv_id": "2408.12808v1",
      "title": "VALE: A Multimodal Visual and Language Explanation Framework for Image Classifiers using eXplainable AI and Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Purushothaman Natarajan",
        "Athira Nambiar"
      ],
      "abstract": "Deep Neural Networks (DNNs) have revolutionized various fields by enabling\ntask automation and reducing human error. However, their internal workings and\ndecision-making processes remain obscure due to their black box nature.\nConsequently, the lack of interpretability limits the application of these\nmodels in high-risk scenarios. To address this issue, the emerging field of\neXplainable Artificial Intelligence (XAI) aims to explain and interpret the\ninner workings of DNNs. Despite advancements, XAI faces challenges such as the\nsemantic gap between machine and human understanding, the trade-off between\ninterpretability and performance, and the need for context-specific\nexplanations. To overcome these limitations, we propose a novel multimodal\nframework named VALE Visual and Language Explanation. VALE integrates\nexplainable AI techniques with advanced language models to provide\ncomprehensive explanations. This framework utilizes visual explanations from\nXAI tools, an advanced zero-shot image segmentation model, and a visual\nlanguage model to generate corresponding textual explanations. By combining\nvisual and textual explanations, VALE bridges the semantic gap between machine\noutputs and human interpretation, delivering results that are more\ncomprehensible to users. In this paper, we conduct a pilot study of the VALE\nframework for image classification tasks. Specifically, Shapley Additive\nExplanations (SHAP) are used to identify the most influential regions in\nclassified images. The object of interest is then extracted using the Segment\nAnything Model (SAM), and explanations are generated using state-of-the-art\npre-trained Vision-Language Models (VLMs). Extensive experimental studies are\nperformed on two datasets: the ImageNet dataset and a custom underwater SONAR\nimage dataset, demonstrating VALEs real-world applicability in underwater image\nclassification.",
      "tldr_zh": "本论文提出VALE框架，一种多模态视觉和语言解释框架，用于提升图像分类器的可解释性，通过整合eXplainable AI (XAI)技术和语言模型来解决DNNs的黑盒问题和语义鸿沟。VALE结合SHAP方法识别图像关键区域、Segment Anything Model (SAM)进行零-shot图像分割，以及Vision-Language Models (VLMs)生成对应的文本解释，从而提供全面的视觉和文本解释，提高人类理解。实验在ImageNet和自定义水下SONAR图像数据集上进行，证明了VALE在实际图像分类任务中的有效性，特别是提升了解释的准确性和可读性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T07 (Primary) 68T45, 68U10 (Secondary)",
        "I.4.8; I.2.10; I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 10 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12808v1",
      "published_date": "2024-08-23 03:02:11 UTC",
      "updated_date": "2024-08-23 03:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:24:19.961084"
    },
    {
      "arxiv_id": "2408.12806v1",
      "title": "Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuf Usman",
        "Aadesh Upadhyay",
        "Prashnna Gyawali",
        "Robin Chataut"
      ],
      "abstract": "In an era where digital threats are increasingly sophisticated, the\nintersection of Artificial Intelligence and cybersecurity presents both\npromising defenses and potent dangers. This paper delves into the escalating\nthreat posed by the misuse of AI, specifically through the use of Large\nLanguage Models (LLMs). This study details various techniques like the switch\nmethod and character play method, which can be exploited by cybercriminals to\ngenerate and automate cyber attacks. Through a series of controlled\nexperiments, the paper demonstrates how these models can be manipulated to\nbypass ethical and privacy safeguards to effectively generate cyber attacks\nsuch as social engineering, malicious code, payload generation, and spyware. By\ntesting these AI generated attacks on live systems, the study assesses their\neffectiveness and the vulnerabilities they exploit, offering a practical\nperspective on the risks AI poses to critical infrastructure. We also introduce\nOccupy AI, a customized, finetuned LLM specifically engineered to automate and\nexecute cyberattacks. This specialized AI driven tool is adept at crafting\nsteps and generating executable code for a variety of cyber threats, including\nphishing, malware injection, and system exploitation. The results underscore\nthe urgency for ethical AI practices, robust cybersecurity measures, and\nregulatory oversight to mitigate AI related threats. This paper aims to elevate\nawareness within the cybersecurity community about the evolving digital threat\nlandscape, advocating for proactive defense strategies and responsible AI\ndevelopment to protect against emerging cyber threats.",
      "tldr_zh": "本研究探讨了生成式AI，特别是Large Language Models (LLMs)，可能被威胁行为者用作战术网络武器，引发未预见的网络攻击风险。论文详细介绍了switch method和character play method等技术，这些可被滥用于生成自动化攻击，如社会工程、恶意代码、payload generation和间谍软件，并通过控制实验验证了这些攻击在真实系统上的有效性。研究还引入了Occupy AI，一种定制微调的LLM工具，能够自动化执行网络攻击，包括网络钓鱼、恶意软件注入和系统利用。结果强调了加强道德AI实践、强化网络安全措施和实施监管的紧迫性，以应对AI驱动的网络威胁并推动主动防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "Primary 03C90, Secondary 03-02,",
        "I.2"
      ],
      "primary_category": "cs.CR",
      "comment": "Journal Paper",
      "pdf_url": "http://arxiv.org/pdf/2408.12806v1",
      "published_date": "2024-08-23 02:56:13 UTC",
      "updated_date": "2024-08-23 02:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:24:33.021910"
    },
    {
      "arxiv_id": "2408.12805v1",
      "title": "A Safe Self-evolution Algorithm for Autonomous Driving Based on Data-Driven Risk Quantification Model",
      "title_zh": "基于数据驱动风险量化模型的自动驾驶安全自我演化算法",
      "authors": [
        "Shuo Yang",
        "Shizhen Li",
        "Yanjun Huang",
        "Hong Chen"
      ],
      "abstract": "Autonomous driving systems with self-evolution capabilities have the\npotential to independently evolve in complex and open environments, allowing to\nhandle more unknown scenarios. However, as a result of the safety-performance\ntrade-off mechanism of evolutionary algorithms, it is difficult to ensure safe\nexploration without sacrificing the improvement ability. This problem is\nespecially prominent in dynamic traffic scenarios. Therefore, this paper\nproposes a safe self-evolution algorithm for autonomous driving based on\ndata-driven risk quantification model. Specifically, a risk quantification\nmodel based on the attention mechanism is proposed by modeling the way humans\nperceive risks during driving, with the idea of achieving safety situation\nestimation of the surrounding environment through a data-driven approach. To\nprevent the impact of over-conservative safety guarding policies on the\nself-evolution capability of the algorithm, a safety-evolutionary\ndecision-control integration algorithm with adjustable safety limits is\nproposed, and the proposed risk quantization model is integrated into it.\nSimulation and real-vehicle experiments results illustrate the effectiveness of\nthe proposed method. The results show that the proposed algorithm can generate\nsafe and reasonable actions in a variety of complex scenarios and guarantee\nsafety without losing the evolutionary potential of learning-based autonomous\ndriving systems.",
      "tldr_zh": "这篇论文提出了一种基于数据驱动风险量化模型的安全自演化算法，用于提升自动驾驶系统在复杂环境中的安全性和适应性。算法通过模仿人类驾驶风险感知的注意力机制，构建一个数据驱动的风险量化模型，以精确估计周围环境的安全情况。为避免过度保守的安全策略影响演化能力，该方法整合了一个可调整安全限度的安全-演化决策控制集成算法。实验结果显示，该算法在模拟和实车测试中有效，能够在各种复杂场景中生成安全合理的动作，同时保留学习系统的演化潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12805v1",
      "published_date": "2024-08-23 02:52:35 UTC",
      "updated_date": "2024-08-23 02:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:24:56.077315"
    },
    {
      "arxiv_id": "2408.12803v1",
      "title": "Multi-Treatment Multi-Task Uplift Modeling for Enhancing User Growth",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wei",
        "Zhaoxin Qiu",
        "Yingjie Li",
        "Yuke Sun",
        "Xiaoling Li"
      ],
      "abstract": "As a key component in boosting online user growth, uplift modeling aims to\nmeasure individual user responses (e.g., whether to play the game) to various\ntreatments, such as gaming bonuses, thereby enhancing business outcomes.\nHowever, previous research typically considers a single-task, single-treatment\nsetting, where only one treatment exists and the overall treatment effect is\nmeasured by a single type of user response. In this paper, we propose a\nMulti-Treatment Multi-Task (MTMT) uplift network to estimate treatment effects\nin a multi-task scenario. We identify the multi-treatment problem as a causal\ninference problem with a tiered response, comprising a base effect (from\noffering a treatment) and an incremental effect (from offering a specific type\nof treatment), where the base effect can be numerically much larger than the\nincremental effect. Specifically, MTMT separately encodes user features and\ntreatments. The user feature encoder uses a multi-gate mixture of experts\n(MMOE) network to encode relevant user features, explicitly learning inter-task\nrelations. The resultant embeddings are used to measure natural responses per\ntask. Furthermore, we introduce a treatment-user feature interaction module to\nmodel correlations between each treatment and user feature. Consequently, we\nseparately measure the base and incremental treatment effect for each task\nbased on the produced treatment-aware representations. Experimental results\nbased on an offline public dataset and an online proprietary dataset\ndemonstrate the effectiveness of MTMT in single/multi-treatment and\nsingle/multi-task settings. Additionally, MTMT has been deployed in our gaming\nplatform to improve user experience.",
      "tldr_zh": "该论文提出了一种Multi-Treatment Multi-Task (MTMT) uplift network，用于提升在线用户增长，通过测量用户对多种处理的响应，例如游戏奖励。MTMT将多处理问题视为因果推断问题，区分基础效果（提供处理）和增量效果（特定处理类型），并采用multi-gate mixture of experts (MMOE)网络编码用户特征，以及处理-用户特征交互模块来学习任务间关系和效果。实验在离线公共数据集和在线专有数据集上验证了MTMT在单/多任务和单/多处理场景中的有效性，并已在游戏平台部署以改善用户体验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12803v1",
      "published_date": "2024-08-23 02:44:08 UTC",
      "updated_date": "2024-08-23 02:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:07.869583"
    },
    {
      "arxiv_id": "2408.12799v2",
      "title": "Preference Consistency Matters: Enhancing Preference Learning in Language Models with Automated Self-Curation of Training Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "JoonHo Lee",
        "JuYoun Son",
        "Juree Seok",
        "Wooseok Jang",
        "Yeong-Dae Kwon"
      ],
      "abstract": "Inconsistent annotations in training corpora, particularly within preference\nlearning datasets, pose challenges in developing advanced language models.\nThese inconsistencies often arise from variability among annotators and\ninherent multi-dimensional nature of the preferences. To address these issues,\nwe introduce a self-curation method that preprocesses annotated datasets by\nleveraging proxy models trained directly on them. Our method enhances\npreference learning by automatically detecting and selecting consistent\nannotations. We validate the proposed approach through extensive\ninstruction-following tasks, demonstrating performance improvements of up to\n33\\% across various learning algorithms and proxy capabilities. This work\noffers a straightforward and reliable solution to address preference\ninconsistencies without relying on heuristics, serving as an initial step\ntoward the development of more advanced preference learning methodologies. Code\nis available at https://github.com/Self-Curation/ .",
      "tldr_zh": "这篇论文强调偏好一致性在语言模型偏好学习中的重要性，针对训练语料库中标注不一致的问题（如标注者变异和偏好多维性），提出了一种自动化自校正（self-curation）方法。方法通过在数据集上训练代理模型（proxy models）来预处理数据，自动检测并选择一致的标注，从而增强偏好学习的效果。在各种指令跟随任务的实验中，该方法在不同学习算法和代理能力下实现了高达33%的性能提升。该工作提供了一个简单可靠的解决方案，不依赖启发式方法，并为更高级偏好学习方法的发展奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2408.12799v2",
      "published_date": "2024-08-23 02:27:14 UTC",
      "updated_date": "2025-01-31 09:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:10.666905"
    },
    {
      "arxiv_id": "2408.12798v1",
      "title": "BackdoorLLM: A Comprehensive Benchmark for Backdoor Attacks on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yige Li",
        "Hanxun Huang",
        "Yunhan Zhao",
        "Xingjun Ma",
        "Jun Sun"
      ],
      "abstract": "Generative Large Language Models (LLMs) have made significant strides across\nvarious tasks, but they remain vulnerable to backdoor attacks, where specific\ntriggers in the prompt cause the LLM to generate adversary-desired responses.\nWhile most backdoor research has focused on vision or text classification\ntasks, backdoor attacks in text generation have been largely overlooked. In\nthis work, we introduce \\textit{BackdoorLLM}, the first comprehensive benchmark\nfor studying backdoor attacks on LLMs. \\textit{BackdoorLLM} features: 1) a\nrepository of backdoor benchmarks with a standardized training pipeline, 2)\ndiverse attack strategies, including data poisoning, weight poisoning, hidden\nstate attacks, and chain-of-thought attacks, 3) extensive evaluations with over\n200 experiments on 8 attacks across 7 scenarios and 6 model architectures, and\n4) key insights into the effectiveness and limitations of backdoors in LLMs. We\nhope \\textit{BackdoorLLM} will raise awareness of backdoor threats and\ncontribute to advancing AI safety. The code is available at\n\\url{https://github.com/bboylyg/BackdoorLLM}.",
      "tldr_zh": "该研究引入了 BackdoorLLM，这是首个全面基准，用于评估大型语言模型（LLMs）的后门攻击问题，这些攻击通过提示中的特定触发器诱导模型生成攻击者期望的响应。BackdoorLLM 包括一个标准化的训练管道、多种攻击策略（如 data poisoning、weight poisoning、hidden state attacks 和 chain-of-thought attacks），并进行了超过 200 个实验，涵盖 8 种攻击、7 种场景和 6 种模型架构。实验结果提供了后门攻击在 LLMs 中的有效性和局限性的关键见解，有助于提高对后门威胁的认识并推动 AI 安全的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12798v1",
      "published_date": "2024-08-23 02:21:21 UTC",
      "updated_date": "2024-08-23 02:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:21.758850"
    },
    {
      "arxiv_id": "2408.13285v1",
      "title": "SIn-NeRF2NeRF: Editing 3D Scenes with Instructions through Segmentation and Inpainting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiseung Hong",
        "Changmin Lee",
        "Gyusang Yu"
      ],
      "abstract": "TL;DR Perform 3D object editing selectively by disentangling it from the\nbackground scene. Instruct-NeRF2NeRF (in2n) is a promising method that enables\nediting of 3D scenes composed of Neural Radiance Field (NeRF) using text\nprompts. However, it is challenging to perform geometrical modifications such\nas shrinking, scaling, or moving on both the background and object\nsimultaneously. In this project, we enable geometrical changes of objects\nwithin the 3D scene by selectively editing the object after separating it from\nthe scene. We perform object segmentation and background inpainting\nrespectively, and demonstrate various examples of freely resizing or moving\ndisentangled objects within the three-dimensional space.",
      "tldr_zh": "该论文提出了SIn-NeRF2NeRF框架，通过对象分割(object segmentation)和背景修复(background inpainting)技术，实现对3D场景中对象的选择性编辑，从而解决Instruct-NeRF2NeRF (in2n)方法在同时处理背景和对象几何修改（如缩小、缩放或移动）时的挑战。该框架首先将对象从Neural Radiance Field (NeRF)场景中分离，然后允许用户根据文本指令自由调整对象的几何属性。实验演示了各种示例，包括在三维空间中随意调整或移动分离对象的场景，这为更灵活的3D场景编辑提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/KAISTChangmin/SIn-NeRF2NeRF",
      "pdf_url": "http://arxiv.org/pdf/2408.13285v1",
      "published_date": "2024-08-23 02:20:42 UTC",
      "updated_date": "2024-08-23 02:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:32.971728"
    },
    {
      "arxiv_id": "2408.12796v1",
      "title": "Real-Time Posture Monitoring and Risk Assessment for Manual Lifting Tasks Using MediaPipe and LSTM",
      "title_zh": "翻译失败",
      "authors": [
        "Ereena Bagga",
        "Ang Yang"
      ],
      "abstract": "This research focuses on developing a real-time posture monitoring and risk\nassessment system for manual lifting tasks using advanced AI and computer\nvision technologies. Musculoskeletal disorders (MSDs) are a significant concern\nfor workers involved in manual lifting, and traditional methods for posture\ncorrection are often inadequate due to delayed feedback and lack of\npersonalized assessment. Our proposed solution integrates AI-driven posture\ndetection, detailed keypoint analysis, risk level determination, and real-time\nfeedback delivered through a user-friendly web interface. The system aims to\nimprove posture, reduce the risk of MSDs, and enhance user engagement. The\nresearch involves comprehensive data collection, model training, and iterative\ndevelopment to ensure high accuracy and user satisfaction. The solution's\neffectiveness is evaluated against existing methodologies, demonstrating\nsignificant improvements in real-time feedback and risk assessment. This study\ncontributes to the field by offering a novel approach to posture correction\nthat addresses existing gaps and provides practical, immediate benefits to\nusers.",
      "tldr_zh": "这篇论文开发了一个使用MediaPipe和LSTM的实时姿势监控和风险评估系统，针对手动搬运任务中肌肉骨骼疾病(MSDs)的风险问题。系统整合AI驱动的姿势检测、关键点分析、风险水平确定，并通过用户友好的网络界面提供即时反馈，以改善姿势、降低MSDs发生率并提升用户参与度。研究通过全面数据收集、模型训练和迭代开发进行验证，结果显示该系统在实时反馈和风险评估方面比传统方法有显著改进，为姿势矫正领域提供了实用的新颖解决方案。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Proceedings of the 1st International Workshop on Multimedia Computing\n  for Health and Medicine at ACM MM'24",
      "pdf_url": "http://arxiv.org/pdf/2408.12796v1",
      "published_date": "2024-08-23 02:19:52 UTC",
      "updated_date": "2024-08-23 02:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:45.641895"
    },
    {
      "arxiv_id": "2408.12792v1",
      "title": "Event Detection via Probability Density Function Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Clark Peng",
        "Tolga Dinçer"
      ],
      "abstract": "In the domain of time series analysis, particularly in event detection tasks,\ncurrent methodologies predominantly rely on segmentation-based approaches,\nwhich predict the class label for each individual timesteps and use the\nchangepoints of these labels to detect events. However, these approaches may\nnot effectively detect the precise onset and offset of events within the data\nand suffer from class imbalance problems. This study introduces a generalized\nregression-based approach to reframe the time-interval-defined event detection\nproblem. Inspired by heatmap regression techniques from computer vision, our\napproach aims to predict probability densities at event locations rather than\nclass labels across the entire time series. The primary aim of this approach is\nto improve the accuracy of event detection methods, particularly for\nlong-duration events where identifying the onset and offset is more critical\nthan classifying individual event states. We demonstrate that regression-based\napproaches outperform segmentation-based methods across various\nstate-of-the-art baseline networks and datasets, offering a more effective\nsolution for specific event detection tasks.",
      "tldr_zh": "本文提出了一种基于 Probability Density Function Regression 的时间序列事件检测方法，以解决传统分割方法在精确检测事件开始和结束（onset and offset）以及处理类不平衡问题上的不足。  \n该方法借鉴计算机视觉中的 heatmap regression 技术，通过预测事件位置的概率密度来重新框架事件检测问题，从而提高对长时事件的准确识别。  \n实验结果表明，这种回归方法在多种基准网络和数据集上优于分割方法，提供了一种更有效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML",
        "I.2.0; I.5.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12792v1",
      "published_date": "2024-08-23 01:58:56 UTC",
      "updated_date": "2024-08-23 01:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:25:57.436389"
    },
    {
      "arxiv_id": "2408.12789v1",
      "title": "Context-Aware Temporal Embedding of Objects in Video Data",
      "title_zh": "视频数据中对象的上下文感知时间嵌入",
      "authors": [
        "Ahnaf Farhan",
        "M. Shahriar Hossain"
      ],
      "abstract": "In video analysis, understanding the temporal context is crucial for\nrecognizing object interactions, event patterns, and contextual changes over\ntime. The proposed model leverages adjacency and semantic similarities between\nobjects from neighboring video frames to construct context-aware temporal\nobject embeddings. Unlike traditional methods that rely solely on visual\nappearance, our temporal embedding model considers the contextual relationships\nbetween objects, creating a meaningful embedding space where temporally\nconnected object's vectors are positioned in proximity. Empirical studies\ndemonstrate that our context-aware temporal embeddings can be used in\nconjunction with conventional visual embeddings to enhance the effectiveness of\ndownstream applications. Moreover, the embeddings can be used to narrate a\nvideo using a Large Language Model (LLM). This paper describes the intricate\ndetails of the proposed objective function to generate context-aware temporal\nobject embeddings for video data and showcases the potential applications of\nthe generated embeddings in video analysis and object classification tasks.",
      "tldr_zh": "该论文提出了一种上下文感知的时间对象嵌入模型，用于视频分析，通过利用相邻帧中对象的邻接性和语义相似性，构建一个嵌入空间，使时间相关对象向量更接近。不同于传统仅依赖视觉外观的方法，该模型强调对象间的上下文关系，提升了下游任务的性能，如视频叙述和对象分类。实验结果显示，该嵌入可与常规视觉嵌入结合，提高视频分析的有效性，并通过Large Language Model (LLM)实现视频叙述，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12789v1",
      "published_date": "2024-08-23 01:44:10 UTC",
      "updated_date": "2024-08-23 01:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:26:08.777678"
    },
    {
      "arxiv_id": "2408.12787v2",
      "title": "LLM-PBE: Assessing Data Privacy in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qinbin Li",
        "Junyuan Hong",
        "Chulin Xie",
        "Jeffrey Tan",
        "Rachel Xin",
        "Junyi Hou",
        "Xavier Yin",
        "Zhun Wang",
        "Dan Hendrycks",
        "Zhangyang Wang",
        "Bo Li",
        "Bingsheng He",
        "Dawn Song"
      ],
      "abstract": "Large Language Models (LLMs) have become integral to numerous domains,\nsignificantly advancing applications in data management, mining, and analysis.\nTheir profound capabilities in processing and interpreting complex language\ndata, however, bring to light pressing concerns regarding data privacy,\nespecially the risk of unintentional training data leakage. Despite the\ncritical nature of this issue, there has been no existing literature to offer a\ncomprehensive assessment of data privacy risks in LLMs. Addressing this gap,\nour paper introduces LLM-PBE, a toolkit crafted specifically for the systematic\nevaluation of data privacy risks in LLMs. LLM-PBE is designed to analyze\nprivacy across the entire lifecycle of LLMs, incorporating diverse attack and\ndefense strategies, and handling various data types and metrics. Through\ndetailed experimentation with multiple LLMs, LLM-PBE facilitates an in-depth\nexploration of data privacy concerns, shedding light on influential factors\nsuch as model size, data characteristics, and evolving temporal dimensions.\nThis study not only enriches the understanding of privacy issues in LLMs but\nalso serves as a vital resource for future research in the field. Aimed at\nenhancing the breadth of knowledge in this area, the findings, resources, and\nour full technical report are made available at https://llm-pbe.github.io/,\nproviding an open platform for academic and practical advancements in LLM\nprivacy assessment.",
      "tldr_zh": "本文提出LLM-PBE工具包，用于评估大语言模型(LLMs)中的数据隐私风险，填补了现有文献的空白。LLM-PBE通过分析LLMs的整个生命周期，整合多种攻击和防御策略、数据类型及评估指标，系统地探讨隐私泄露问题，如训练数据意外暴露。实验结果显示，模型大小、数据特性及时间因素等会显著影响隐私风险，该研究不仅加深了对LLMs隐私问题的理解，还提供了开源资源以支持未来研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12787v2",
      "published_date": "2024-08-23 01:37:29 UTC",
      "updated_date": "2024-09-06 04:30:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:26:21.821207"
    },
    {
      "arxiv_id": "2408.12781v1",
      "title": "The Model Mastery Lifecycle: A Framework for Designing Human-AI Interaction",
      "title_zh": "模型精通生命周期：设计人-AI交互的框架",
      "authors": [
        "Mark Chignell",
        "Mu-Huan Miles Chung",
        "Jaturong Kongmanee",
        "Khilan Jerath",
        "Abhay Raman"
      ],
      "abstract": "The utilization of AI in an increasing number of fields is the latest\niteration of a long process, where machines and systems have been replacing\nhumans, or changing the roles that they play, in various tasks. Although humans\nare often resistant to technological innovation, especially in workplaces,\nthere is a general trend towards increasing automation, and more recently, AI.\nAI is now capable of carrying out, or assisting with, many tasks that used to\nbe regarded as exclusively requiring human expertise. In this paper we consider\nthe case of tasks that could be performed either by human experts or by AI and\nlocate them on a continuum running from exclusively human task performance at\none end to AI autonomy on the other, with a variety of forms of human-AI\ninteraction between those extremes. Implementation of AI is constrained by the\ncontext of the systems and workflows that it will be embedded within. There is\nan urgent need for methods to determine how AI should be used in different\nsituations and to develop appropriate methods of human-AI interaction so that\nhumans and AI can work together effectively to perform tasks. In response to\nthe evolving landscape of AI progress and increasing mastery, we introduce an\nAI Mastery Lifecycle framework and discuss its implications for human-AI\ninteraction. The framework provides guidance on human-AI task allocation and\nhow human-AI interfaces need to adapt to improvements in AI task performance\nover time. Within the framework we identify a zone of uncertainty where the\nissues of human-AI task allocation and user interface design are likely to be\nmost challenging.",
      "tldr_zh": "这篇论文探讨了AI在任务中的角色，强调AI如何取代或辅助人类工作，并将任务置于一个从完全人类执行到AI自治的连续体上。论文引入了AI Mastery Lifecycle框架，作为指导人类-AI交互的设计方法，该框架帮助分配任务并适应AI性能的改进。在框架中，作者识别了一个不确定区域（zone of uncertainty），在这里人类-AI任务分配和界面设计面临最大挑战，从而为有效的人类-AI协作提供实用指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12781v1",
      "published_date": "2024-08-23 01:00:32 UTC",
      "updated_date": "2024-08-23 01:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:26:32.834468"
    },
    {
      "arxiv_id": "2408.12779v1",
      "title": "Investigating LLM Applications in E-Commerce",
      "title_zh": "探究LLM在电子商务中的应用",
      "authors": [
        "Chester Palen-Michel",
        "Ruixiang Wang",
        "Yipeng Zhang",
        "David Yu",
        "Canran Xu",
        "Zhe Wu"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has revolutionized natural\nlanguage processing in various applications especially in e-commerce. One\ncrucial step before the application of such LLMs in these fields is to\nunderstand and compare the performance in different use cases in such tasks.\nThis paper explored the efficacy of LLMs in the e-commerce domain, focusing on\ninstruction-tuning an open source LLM model with public e-commerce datasets of\nvarying sizes and comparing the performance with the conventional models\nprevalent in industrial applications. We conducted a comprehensive comparison\nbetween LLMs and traditional pre-trained language models across specific tasks\nintrinsic to the e-commerce domain, namely classification, generation,\nsummarization, and named entity recognition (NER). Furthermore, we examined the\neffectiveness of the current niche industrial application of very large LLM,\nusing in-context learning, in e-commerce specific tasks. Our findings indicate\nthat few-shot inference with very large LLMs often does not outperform\nfine-tuning smaller pre-trained models, underscoring the importance of\ntask-specific model optimization.Additionally, we investigated different\ntraining methodologies such as single-task training, mixed-task training, and\nLoRA merging both within domain/tasks and between different tasks. Through\nrigorous experimentation and analysis, this paper offers valuable insights into\nthe potential effectiveness of LLMs to advance natural language processing\ncapabilities within the e-commerce industry.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在电子商务领域的应用，通过对开源LLM进行指令微调，并使用不同规模的公共电子商务数据集与传统预训练模型进行比较。研究重点比较了LLMs在分类、生成、总结和命名实体识别（NER）等任务中的表现，并评估了in-context learning在大模型上的有效性，同时测试了单任务训练、混合任务训练和LoRA合并等训练方法。结果表明，few-shot推理通常不如针对任务微调较小模型的效果显著，强调了任务特定优化的重要性，并为LLMs提升电子商务自然语言处理能力提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12779v1",
      "published_date": "2024-08-23 00:57:37 UTC",
      "updated_date": "2024-08-23 00:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:26:47.182725"
    },
    {
      "arxiv_id": "2408.12778v1",
      "title": "Data-Centric Approach to Constrained Machine Learning: A Case Study on Conway's Game of Life",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Bibin",
        "Anton Dereventsov"
      ],
      "abstract": "This paper focuses on a data-centric approach to machine learning\napplications in the context of Conway's Game of Life. Specifically, we consider\nthe task of training a minimal architecture network to learn the transition\nrules of Game of Life for a given number of steps ahead, which is known to be\nchallenging due to restrictions on the allowed number of trainable parameters.\nAn extensive quantitative analysis showcases the benefits of utilizing a\nstrategically designed training dataset, with its advantages persisting\nregardless of other parameters of the learning configuration, such as network\ninitialization weights or optimization algorithm. Importantly, our findings\nhighlight the integral role of domain expert insights in creating effective\nmachine learning applications for constrained real-world scenarios.",
      "tldr_zh": "本研究采用数据中心方法（data-centric approach）探讨受限机器学习（constrained machine learning）问题，以康威生命游戏（Conway's Game of Life）为例，训练一个最小架构网络来学习游戏的过渡规则，从而预测给定步数的演化过程。研究通过定量分析证明，使用战略设计的训练数据集能显著提升模型性能，且这种优势独立于网络初始化权重或优化算法等其他配置参数。最终，论文强调了领域专家见解在构建有效机器学习应用方面的关键作用，特别是针对真实受限场景的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12778v1",
      "published_date": "2024-08-23 00:56:34 UTC",
      "updated_date": "2024-08-23 00:56:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:26:57.481499"
    },
    {
      "arxiv_id": "2408.12777v1",
      "title": "Environment-Centric Active Inference",
      "title_zh": "以环境为中心的主动推理",
      "authors": [
        "Kanako Esaki",
        "Tadayuki Matsumura",
        "Takeshi Kato",
        "Shunsuke Minusa",
        "Yang Shao",
        "Hiroyuki Mizuno"
      ],
      "abstract": "To handle unintended changes in the environment by agents, we propose an\nenvironment-centric active inference EC-AIF in which the Markov Blanket of\nactive inference is defined starting from the environment. In normal active\ninference, the Markov Blanket is defined starting from the agent. That is,\nfirst the agent was defined as the entity that performs the \"action\" such as a\nrobot or a person, then the environment was defined as other people or objects\nthat are directly affected by the agent's \"action,\" and the boundary between\nthe agent and the environment was defined as the Markov Blanket. This\nagent-centric definition does not allow the agent to respond to unintended\nchanges in the environment caused by factors outside of the defined\nenvironment. In the proposed EC-AIF, there is no entity corresponding to an\nagent. The environment includes all observable things, including people and\nthings conventionally considered to be the environment, as well as entities\nthat perform \"actions\" such as robots and people. Accordingly, all states,\nincluding robots and people, are included in inference targets, eliminating\nunintended changes in the environment. The EC-AIF was applied to a robot arm\nand validated with an object transport task by the robot arm. The results\nshowed that the robot arm successfully transported objects while responding to\nchanges in the target position of the object and to changes in the orientation\nof another robot arm.",
      "tldr_zh": "论文提出了一种环境中心化的主动推理（EC-AIF），通过从环境开始定义Markov Blanket，而非传统代理中心化方法，从而解决代理无法应对环境意外变化的问题。该框架将所有可观察实体（如机器人和人）纳入环境范围，使系统能够处理所有状态变化，包括外部因素引发的干扰。在机器人臂的物体运输任务实验中，EC-AIF 成功使机器人臂适应物体位置和另一个机器人臂方向的变化，证明了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.12777v1",
      "published_date": "2024-08-23 00:54:28 UTC",
      "updated_date": "2024-08-23 00:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:27:09.040839"
    },
    {
      "arxiv_id": "2408.12775v2",
      "title": "Intelligent OPC Engineer Assistant for Semiconductor Manufacturing",
      "title_zh": "用于半导体制造的智能 OPC 工程师助手",
      "authors": [
        "Guojin Chen",
        "Haoyu Yang",
        "Bei Yu",
        "Haoxing Ren"
      ],
      "abstract": "Advancements in chip design and manufacturing have enabled the processing of\ncomplex tasks such as deep learning and natural language processing, paving the\nway for the development of artificial general intelligence (AGI). AI, on the\nother hand, can be leveraged to innovate and streamline semiconductor\ntechnology from planning and implementation to manufacturing. In this paper, we\npresent \\textit{Intelligent OPC Engineer Assistant}, an AI/LLM-powered\nmethodology designed to solve the core manufacturing-aware optimization problem\nknown as optical proximity correction (OPC). The methodology involves a\nreinforcement learning-based OPC recipe search and a customized multi-modal\nagent system for recipe summarization. Experiments demonstrate that our\nmethodology can efficiently build OPC recipes on various chip designs with\nspecially handled design topologies, a task that typically requires the\nfull-time effort of OPC engineers with years of experience.",
      "tldr_zh": "本论文提出了一种名为 Intelligent OPC Engineer Assistant 的 AI/LLM 驱动方法，旨在优化半导体制造中的光学邻近校正 (OPC) 问题，通过自动化流程来提升效率。该方法结合了基于强化学习 (reinforcement learning) 的 OPC 配方搜索和定制的多模态代理系统 (customized multi-modal agent system)，用于快速生成和总结配方。实验结果表明，该系统能高效处理各种芯片设计拓扑，显著减少了对经验丰富工程师的依赖，为半导体制造的智能化转型提供了创新解决方案。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12775v2",
      "published_date": "2024-08-23 00:49:36 UTC",
      "updated_date": "2024-08-27 06:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:27:22.069968"
    },
    {
      "arxiv_id": "2409.00064v1",
      "title": "Phrasing for UX: Enhancing Information Engagement through Computational Linguistics and Creative Analytics",
      "title_zh": "翻译失败",
      "authors": [
        "Nimrod Dvir"
      ],
      "abstract": "This study explores the relationship between textual features and Information\nEngagement (IE) on digital platforms. It highlights the impact of computational\nlinguistics and analytics on user interaction. The READ model is introduced to\nquantify key predictors like representativeness, ease of use, affect, and\ndistribution, which forecast engagement levels. The model's effectiveness is\nvalidated through AB testing and randomized trials, showing strong predictive\nperformance in participation (accuracy: 0.94), perception (accuracy: 0.85),\nperseverance (accuracy: 0.81), and overall IE (accuracy: 0.97).\n  While participation metrics are strong, perception and perseverance show\nslightly lower recall and F1-scores, indicating some challenges. The study\ndemonstrates that modifying text based on the READ model's insights leads to\nsignificant improvements. For example, increasing representativeness and\npositive affect boosts selection rates by 11 percent, raises evaluation\naverages from 3.98 to 4.46, and improves retention rates by 11 percent. These\nfindings highlight the importance of linguistic factors in IE, providing a\nframework for enhancing digital text engagement. The research offers practical\nstrategies applicable to fields like education, health, and media.",
      "tldr_zh": "这篇论文探讨了文本特征对数字平台 Information Engagement (IE) 的影响，强调计算语言学和分析在提升用户交互中的作用。研究引入 READ 模型，量化关键预测因素如 representativeness、ease of use、affect 和 distribution，通过 AB 测试和随机试验验证其预测性能（整体 IE 准确率达 0.97）。结果显示，基于模型优化文本可显著提高参与指标，例如选择率增加 11%、评价平均从 3.98 升至 4.46，以及保留率提升 11%，为教育、健康和媒体等领域提供实用框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00064v1",
      "published_date": "2024-08-23 00:33:47 UTC",
      "updated_date": "2024-08-23 00:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:27:36.442031"
    },
    {
      "arxiv_id": "2408.12772v2",
      "title": "Symmetric masking strategy enhances the performance of Masked Image Modeling",
      "title_zh": "对称掩码策略提升了掩码图像建模的性能",
      "authors": [
        "Khanh-Binh Nguyen",
        "Chae Jung Park"
      ],
      "abstract": "Masked Image Modeling (MIM) is a technique in self-supervised learning that\nfocuses on acquiring detailed visual representations from unlabeled images by\nestimating the missing pixels in randomly masked sections. It has proven to be\na powerful tool for the preliminary training of Vision Transformers (ViTs),\nyielding impressive results across various tasks. Nevertheless, most MIM\nmethods heavily depend on the random masking strategy to formulate the pretext\ntask. This strategy necessitates numerous trials to ascertain the optimal\ndropping ratio, which can be resource-intensive, requiring the model to be\npre-trained for anywhere between 800 to 1600 epochs. Furthermore, this approach\nmay not be suitable for all datasets. In this work, we propose a new masking\nstrategy that effectively helps the model capture global and local features.\nBased on this masking strategy, SymMIM, our proposed training pipeline for MIM\nis introduced. SymMIM achieves a new SOTA accuracy of 85.9\\% on ImageNet using\nViT-Large and surpasses previous SOTA across downstream tasks such as image\nclassification, semantic segmentation, object detection, instance segmentation\ntasks, and so on.",
      "tldr_zh": "本文提出了一种新的对称masking策略，用于提升Masked Image Modeling (MIM) 的性能，该策略帮助模型更有效地捕获图像的全局和局部特征，从而克服传统随机masking策略的资源密集问题（如需要800-1600 epochs的预训练）。基于此策略，作者开发了SymMIM训练管道，适用于Vision Transformers (ViTs)的初步训练。实验结果显示，SymMIM在ImageNet上使用ViT-Large模型达到了85.9%的SOTA准确率，并在下游任务如图像分类、语义分割、目标检测和实例分割中超越了现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12772v2",
      "published_date": "2024-08-23 00:15:43 UTC",
      "updated_date": "2024-12-13 12:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T18:27:46.356941"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 106,
  "processed_papers_count": 106,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T18:28:12.757078"
}