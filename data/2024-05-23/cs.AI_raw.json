[
  {
    "arxiv_id": "2405.15097v1",
    "title": "Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding",
    "authors": [
      "Suyoung Kim",
      "Jiyeon Hwang",
      "Ho-Young Jung"
    ],
    "abstract": "Recently, deep end-to-end learning has been studied for intent classification\nin Spoken Language Understanding (SLU). However, end-to-end models require a\nlarge amount of speech data with intent labels, and highly optimized models are\ngenerally sensitive to the inconsistency between the training and evaluation\nconditions. Therefore, a natural language understanding approach based on\nAutomatic Speech Recognition (ASR) remains attractive because it can utilize a\npre-trained general language model and adapt to the mismatch of the speech\ninput environment. Using this module-based approach, we improve a noisy-channel\nmodel to handle transcription inconsistencies caused by ASR errors. We propose\na two-stage method, Contrastive and Consistency Learning (CCL), that correlates\nerror patterns between clean and noisy ASR transcripts and emphasizes the\nconsistency of the latent features of the two transcripts. Experiments on four\nbenchmark datasets show that CCL outperforms existing methods and improves the\nASR robustness in various noisy environments. Code is available at\nhttps://github.com/syoung7388/CCL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15097v1",
    "published_date": "2024-05-23 23:10:23 UTC",
    "updated_date": "2024-05-23 23:10:23 UTC"
  },
  {
    "arxiv_id": "2405.15092v2",
    "title": "Dissociation of Faithful and Unfaithful Reasoning in LLMs",
    "authors": [
      "Evelyn Yee",
      "Alice Li",
      "Chenyu Tang",
      "Yeon Ho Jung",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "abstract": "Large language models (LLMs) often improve their performance in downstream\ntasks when they generate Chain of Thought reasoning text before producing an\nanswer. We investigate how LLMs recover from errors in Chain of Thought.\nThrough analysis of error recovery behaviors, we find evidence for\nunfaithfulness in Chain of Thought, which occurs when models arrive at the\ncorrect answer despite invalid reasoning text. We identify factors that shift\nLLM recovery behavior: LLMs recover more frequently from obvious errors and in\ncontexts that provide more evidence for the correct answer. Critically, these\nfactors have divergent effects on faithful and unfaithful recoveries. Our\nresults indicate that there are distinct mechanisms driving faithful and\nunfaithful error recoveries. Selective targeting of these mechanisms may be\nable to drive down the rate of unfaithful reasoning and improve model\ninterpretability.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "code published at\n  https://github.com/CoTErrorRecovery/CoTErrorRecovery",
    "pdf_url": "http://arxiv.org/pdf/2405.15092v2",
    "published_date": "2024-05-23 22:38:58 UTC",
    "updated_date": "2024-09-02 22:40:20 UTC"
  },
  {
    "arxiv_id": "2407.11190v1",
    "title": "In Silico Sociology: Forecasting COVID-19 Polarization with Large Language Models",
    "authors": [
      "Austin C. Kozlowski",
      "Hyunku Kwon",
      "James A. Evans"
    ],
    "abstract": "By training deep neural networks on massive archives of digitized text, large\nlanguage models (LLMs) learn the complex linguistic patterns that constitute\nhistoric and contemporary discourses. We argue that LLMs can serve as a\nvaluable tool for sociological inquiry by enabling accurate simulation of\nrespondents from specific social and cultural contexts. Applying LLMs in this\ncapacity, we reconstruct the public opinion landscape of 2019 to examine the\nextent to which the future polarization over COVID-19 was prefigured in\nexisting political discourse. Using an LLM trained on texts published through\n2019, we simulate the responses of American liberals and conservatives to a\nbattery of pandemic-related questions. We find that the simulated respondents\nreproduce observed partisan differences in COVID-19 attitudes in 84% of cases,\nsignificantly greater than chance. Prompting the simulated respondents to\njustify their responses, we find that much of the observed partisan gap\ncorresponds to differing appeals to freedom, safety, and institutional trust.\nOur findings suggest that the politicization of COVID-19 was largely consistent\nwith the prior ideological landscape, and this unprecedented event served to\nadvance history along its track rather than change the rails.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11190v1",
    "published_date": "2024-05-23 22:10:12 UTC",
    "updated_date": "2024-05-23 22:10:12 UTC"
  },
  {
    "arxiv_id": "2405.15083v1",
    "title": "MuDreamer: Learning Predictive World Models without Reconstruction",
    "authors": [
      "Maxime Burchi",
      "Radu Timofte"
    ],
    "abstract": "The DreamerV3 agent recently demonstrated state-of-the-art performance in\ndiverse domains, learning powerful world models in latent space using a pixel\nreconstruction loss. However, while the reconstruction loss is essential to\nDreamer's performance, it also necessitates modeling unnecessary information.\nConsequently, Dreamer sometimes fails to perceive crucial elements which are\nnecessary for task-solving when visual distractions are present in the\nobservation, significantly limiting its potential. In this paper, we present\nMuDreamer, a robust reinforcement learning agent that builds upon the DreamerV3\nalgorithm by learning a predictive world model without the need for\nreconstructing input signals. Rather than relying on pixel reconstruction,\nhidden representations are instead learned by predicting the environment value\nfunction and previously selected actions. Similar to predictive self-supervised\nmethods for images, we find that the use of batch normalization is crucial to\nprevent learning collapse. We also study the effect of KL balancing between\nmodel posterior and prior losses on convergence speed and learning stability.\nWe evaluate MuDreamer on the commonly used DeepMind Visual Control Suite and\ndemonstrate stronger robustness to visual distractions compared to DreamerV3\nand other reconstruction-free approaches, replacing the environment background\nwith task-irrelevant real-world videos. Our method also achieves comparable\nperformance on the Atari100k benchmark while benefiting from faster training.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15083v1",
    "published_date": "2024-05-23 22:09:01 UTC",
    "updated_date": "2024-05-23 22:09:01 UTC"
  },
  {
    "arxiv_id": "2405.15077v4",
    "title": "Eliciting Informative Text Evaluations with Large Language Models",
    "authors": [
      "Yuxuan Lu",
      "Shengwei Xu",
      "Yichi Zhang",
      "Yuqing Kong",
      "Grant Schoenebeck"
    ],
    "abstract": "Peer prediction mechanisms motivate high-quality feedback with provable\nguarantees. However, current methods only apply to rather simple reports, like\nmultiple-choice or scalar numbers. We aim to broaden these techniques to the\nlarger domain of text-based reports, drawing on the recent developments in\nlarge language models. This vastly increases the applicability of peer\nprediction mechanisms as textual feedback is the norm in a large variety of\nfeedback channels: peer reviews, e-commerce customer reviews, and comments on\nsocial media.\n  We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)\nand the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms\nutilize LLMs as predictors, mapping from one agent's report to a prediction of\nher peer's report. Theoretically, we show that when the LLM prediction is\nsufficiently accurate, our mechanisms can incentivize high effort and\ntruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, we\nconfirm the efficacy of our mechanisms through experiments conducted on two\nreal datasets: the Yelp review dataset and the ICLR OpenReview dataset. We\nhighlight the results that on the ICLR dataset, our mechanisms can\ndifferentiate three quality levels -- human-written reviews, GPT-4-generated\nreviews, and GPT-3.5-generated reviews in terms of expected scores.\nAdditionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by the Twenty-Fifth ACM Conference on Economics and\n  Computation (EC'24)",
    "pdf_url": "http://arxiv.org/pdf/2405.15077v4",
    "published_date": "2024-05-23 21:56:12 UTC",
    "updated_date": "2024-09-02 20:25:36 UTC"
  },
  {
    "arxiv_id": "2405.15073v1",
    "title": "Temporal Stamp Classifier: Classifying Short Sequences of Astronomical Alerts",
    "authors": [
      "Daniel Neira O.",
      "Pablo A. Estévez",
      "Francisco Förster"
    ],
    "abstract": "In this work, we propose a deep learning-based classification model of\nastronomical objects using alerts reported by the Zwicky Transient Facility\n(ZTF) survey. The model takes as inputs sequences of stamp images and metadata\ncontained in each alert, as well as features from the All-WISE catalog. The\nproposed model, called temporal stamp classifier, is able to discriminate\nbetween three classes of astronomical objects: Active Galactic Nuclei (AGN),\nSuper-Novae (SNe) and Variable Stars (VS), with an accuracy of approximately\n98% in the test set, when using 2 to 5 detections. The results show that the\nmodel performance improves with the addition of more detections. Simple\nrecurrence models obtain competitive results with those of more complex models\nsuch as LSTM.We also propose changes to the original stamp classifier model,\nwhich only uses the first detection. The performance of the latter model\nimproves with changes in the architecture and the addition of random rotations,\nachieving a 1.46% increase in test accuracy.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Accepted in International Joint Conference on Neural Networks 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15073v1",
    "published_date": "2024-05-23 21:49:32 UTC",
    "updated_date": "2024-05-23 21:49:32 UTC"
  },
  {
    "arxiv_id": "2405.19356v2",
    "title": "An LSTM Feature Imitation Network for Hand Movement Recognition from sEMG Signals",
    "authors": [
      "Chuheng Wu",
      "S. Farokh Atashzar",
      "Mohammad M. Ghassemi",
      "Tuka Alhanai"
    ],
    "abstract": "Surface Electromyography (sEMG) is a non-invasive signal that is used in the\nrecognition of hand movement patterns, the diagnosis of diseases, and the\nrobust control of prostheses. Despite the remarkable success of recent\nend-to-end Deep Learning approaches, they are still limited by the need for\nlarge amounts of labeled data. To alleviate the requirement for big data, we\npropose utilizing a feature-imitating network (FIN) for closed-form temporal\nfeature learning over a 300ms signal window on Ninapro DB2, and applying it to\nthe task of 17 hand movement recognition. We implement a lightweight LSTM-FIN\nnetwork to imitate four standard temporal features (entropy, root mean square,\nvariance, simple square integral). We observed that the LSTM-FIN network can\nachieve up to 99\\% R2 accuracy in feature reconstruction and 80\\% accuracy in\nhand movement recognition. Our results also showed that the model can be\nrobustly applied for both within- and cross-subject movement recognition, as\nwell as simulated low-latency environments. Overall, our work demonstrates the\npotential of the FIN modeling paradigm in data-scarce scenarios for sEMG signal\nprocessing.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "eess.SP",
    "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
    "pdf_url": "http://arxiv.org/pdf/2405.19356v2",
    "published_date": "2024-05-23 21:45:15 UTC",
    "updated_date": "2024-12-30 19:09:55 UTC"
  },
  {
    "arxiv_id": "2405.15064v1",
    "title": "Reframing Spatial Reasoning Evaluation in Language Models: A Real-World Simulation Benchmark for Qualitative Reasoning",
    "authors": [
      "Fangjun Li",
      "David C. Hogg",
      "Anthony G. Cohn"
    ],
    "abstract": "Spatial reasoning plays a vital role in both human cognition and machine\nintelligence, prompting new research into language models' (LMs) capabilities\nin this regard. However, existing benchmarks reveal shortcomings in evaluating\nqualitative spatial reasoning (QSR). These benchmarks typically present\noversimplified scenarios or unclear natural language descriptions, hindering\neffective evaluation. We present a novel benchmark for assessing QSR in LMs,\nwhich is grounded in realistic 3D simulation data, offering a series of diverse\nroom layouts with various objects and their spatial relationships. This\napproach provides a more detailed and context-rich narrative for spatial\nreasoning evaluation, diverging from traditional, toy-task-oriented scenarios.\nOur benchmark encompasses a broad spectrum of qualitative spatial\nrelationships, including topological, directional, and distance relations.\nThese are presented with different viewing points, varied granularities, and\ndensity of relation constraints to mimic real-world complexities. A key\ncontribution is our logic-based consistency-checking tool, which enables the\nassessment of multiple plausible solutions, aligning with real-world scenarios\nwhere spatial relationships are often open to interpretation. Our benchmark\nevaluation of advanced LMs reveals their strengths and limitations in spatial\nreasoning. They face difficulties with multi-hop spatial reasoning and\ninterpreting a mix of different view descriptions, pointing to areas for future\nimprovement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera-Ready version for IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15064v1",
    "published_date": "2024-05-23 21:22:00 UTC",
    "updated_date": "2024-05-23 21:22:00 UTC"
  },
  {
    "arxiv_id": "2405.15054v1",
    "title": "Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning",
    "authors": [
      "Matteo Bettini",
      "Ryan Kortvelesy",
      "Amanda Prorok"
    ],
    "abstract": "The study of behavioral diversity in Multi-Agent Reinforcement Learning\n(MARL) is a nascent yet promising field. In this context, the present work\ndeals with the question of how to control the diversity of a multi-agent\nsystem. With no existing approaches to control diversity to a set value,\ncurrent solutions focus on blindly promoting it via intrinsic rewards or\nadditional loss functions, effectively changing the learning objective and\nlacking a principled measure for it. To address this, we introduce Diversity\nControl (DiCo), a method able to control diversity to an exact value of a given\nmetric by representing policies as the sum of a parameter-shared component and\ndynamically scaled per-agent components. By applying constraints directly to\nthe policy architecture, DiCo leaves the learning objective unchanged, enabling\nits applicability to any actor-critic MARL algorithm. We theoretically prove\nthat DiCo achieves the desired diversity, and we provide several experiments,\nboth in cooperative and competitive tasks, that show how DiCo can be employed\nas a novel paradigm to increase performance and sample efficiency in MARL.\nMultimedia results are available on the paper's website:\nhttps://sites.google.com/view/dico-marl.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15054v1",
    "published_date": "2024-05-23 21:03:33 UTC",
    "updated_date": "2024-05-23 21:03:33 UTC"
  },
  {
    "arxiv_id": "2405.15052v2",
    "title": "Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training",
    "authors": [
      "Xianzhi Du",
      "Tom Gunter",
      "Xiang Kong",
      "Mark Lee",
      "Zirui Wang",
      "Aonan Zhang",
      "Nan Du",
      "Ruoming Pang"
    ],
    "abstract": "Mixture-of-Experts (MoE) enjoys performance gain by increasing model capacity\nwhile keeping computation cost constant. When comparing MoE to dense models,\nprior work typically adopt the following setting: 1) use FLOPs or activated\nparameters as a measure of model complexity; 2) train all models to the same\nnumber of tokens. We argue that this setting favors MoE as FLOPs and activated\nparameters do not accurately measure the communication overhead in sparse\nlayers, leading to a larger actual training budget for MoE. In this work, we\nrevisit the settings by adopting step time as a more accurate measure of model\ncomplexity, and by determining the total compute budget under the Chinchilla\ncompute-optimal settings. To efficiently run MoE on modern accelerators, we\nadopt a 3D sharding method that keeps the dense-to-MoE step time increase\nwithin a healthy range. We evaluate MoE and dense LLMs on a set of nine 0-shot\nand two 1-shot English tasks, as well as MMLU 5-shot and GSM8K 8-shot across\nthree model scales at 6.4B, 12.6B, and 29.6B. Experimental results show that\neven under these settings, MoE consistently outperform dense LLMs on the\nspeed-accuracy trade-off curve with meaningful gaps. Our full model\nimplementation and sharding strategy has been released\nat~\\url{https://github.com/apple/axlearn}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.15052v2",
    "published_date": "2024-05-23 21:00:53 UTC",
    "updated_date": "2024-06-28 19:39:45 UTC"
  },
  {
    "arxiv_id": "2405.15047v2",
    "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification",
    "authors": [
      "Kaizheng Wang",
      "Fabio Cuzzolin",
      "Keivan Shariatmadar",
      "David Moens",
      "Hans Hallez"
    ],
    "abstract": "This paper presents an innovative approach, called credal wrapper, to\nformulating a credal set representation of model averaging for Bayesian neural\nnetworks (BNNs) and deep ensembles (DEs), capable of improving uncertainty\nestimation in classification tasks. Given a finite collection of single\npredictive distributions derived from BNNs or DEs, the proposed credal wrapper\napproach extracts an upper and a lower probability bound per class,\nacknowledging the epistemic uncertainty due to the availability of a limited\namount of distributions. Such probability intervals over classes can be mapped\non a convex set of probabilities (a credal set) from which, in turn, a unique\nprediction can be obtained using a transformation called intersection\nprobability transformation. In this article, we conduct extensive experiments\non several out-of-distribution (OOD) detection benchmarks, encompassing various\ndataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,\nCIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network\narchitectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base).\nCompared to the BNN and DE baselines, the proposed credal wrapper method\nexhibits superior performance in uncertainty estimation and achieves a lower\nexpected calibration error on corrupted data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The 13th International Conference on Learning Representations (ICLR).\n  2025 [Spotlight]",
    "pdf_url": "http://arxiv.org/pdf/2405.15047v2",
    "published_date": "2024-05-23 20:51:22 UTC",
    "updated_date": "2025-05-09 14:56:04 UTC"
  },
  {
    "arxiv_id": "2405.20230v1",
    "title": "Feature Fusion for Improved Classification: Combining Dempster-Shafer Theory and Multiple CNN Architectures",
    "authors": [
      "Ayyub Alzahem",
      "Wadii Boulila",
      "Maha Driss",
      "Anis Koubaa"
    ],
    "abstract": "Addressing uncertainty in Deep Learning (DL) is essential, as it enables the\ndevelopment of models that can make reliable predictions and informed decisions\nin complex, real-world environments where data may be incomplete or ambiguous.\nThis paper introduces a novel algorithm leveraging Dempster-Shafer Theory (DST)\nto integrate multiple pre-trained models to form an ensemble capable of\nproviding more reliable and enhanced classifications. The main steps of the\nproposed method include feature extraction, mass function calculation, fusion,\nand expected utility calculation. Several experiments have been conducted on\nCIFAR-10 and CIFAR-100 datasets, demonstrating superior classification accuracy\nof the proposed DST-based method, achieving improvements of 5.4% and 8.4%,\nrespectively, compared to the best individual pre-trained models. Results\nhighlight the potential of DST as a robust framework for managing uncertainties\nrelated to data when applying DL in real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20230v1",
    "published_date": "2024-05-23 20:44:10 UTC",
    "updated_date": "2024-05-23 20:44:10 UTC"
  },
  {
    "arxiv_id": "2405.15033v1",
    "title": "Generating camera failures as a class of physics-based adversarial examples",
    "authors": [
      "Manav Prabhakar",
      "Jwalandhar Girnar",
      "Arpan Kusari"
    ],
    "abstract": "While there has been extensive work on generating physics-based adversarial\nsamples recently, an overlooked class of such samples come from physical\nfailures in the camera. Camera failures can occur as a result of an external\nphysical process, i.e. breakdown of a component due to stress, or an internal\ncomponent failure. In this work, we develop a simulated physical process for\ngenerating broken lens as a class of physics-based adversarial samples. We\ncreate a stress-based physical simulation by generating particles constrained\nin a mesh and apply stress at a random point and at a random angle. We perform\nstress propagation through the mesh and the end result of the mesh is a\ncorresponding image which simulates the broken lens pattern. We also develop a\nneural emulator which learns the non-linear mapping between the mesh as a graph\nand the stress propagation using constrained propagation setup. We can then\nstatistically compare the difference between the generated adversarial samples\nwith real, simulated and emulated adversarial examples using the detection\nfailure rate of the different classes and in between the samples using the\nFrechet Inception distance. Our goal through this work is to provide a robust\nphysics based process for generating adversarial samples.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15033v1",
    "published_date": "2024-05-23 20:11:20 UTC",
    "updated_date": "2024-05-23 20:11:20 UTC"
  },
  {
    "arxiv_id": "2405.15020v3",
    "title": "AdjointDEIS: Efficient Gradients for Diffusion Models",
    "authors": [
      "Zander W. Blasingame",
      "Chen Liu"
    ],
    "abstract": "The optimization of the latents and parameters of diffusion models with\nrespect to some differentiable metric defined on the output of the model is a\nchallenging and complex problem. The sampling for diffusion models is done by\nsolving either the probability flow ODE or diffusion SDE wherein a neural\nnetwork approximates the score function allowing a numerical ODE/SDE solver to\nbe used. However, naive backpropagation techniques are memory intensive,\nrequiring the storage of all intermediate states, and face additional\ncomplexity in handling the injected noise from the diffusion term of the\ndiffusion SDE. We propose a novel family of bespoke ODE solvers to the\ncontinuous adjoint equations for diffusion models, which we call AdjointDEIS.\nWe exploit the unique construction of diffusion SDEs to further simplify the\nformulation of the continuous adjoint equations using exponential integrators.\nMoreover, we provide convergence order guarantees for our bespoke solvers.\nSignificantly, we show that continuous adjoint equations for diffusion SDEs\nactually simplify to a simple ODE. Lastly, we demonstrate the effectiveness of\nAdjointDEIS for guided generation with an adversarial attack in the form of the\nface morphing problem. Our code will be released at https:\n//github.com/zblasingame/AdjointDEIS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "math.DS",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 conference paper",
    "pdf_url": "http://arxiv.org/pdf/2405.15020v3",
    "published_date": "2024-05-23 19:51:33 UTC",
    "updated_date": "2025-01-21 19:32:07 UTC"
  },
  {
    "arxiv_id": "2405.15019v2",
    "title": "Agentic Skill Discovery",
    "authors": [
      "Xufeng Zhao",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "abstract": "Language-conditioned robotic skills make it possible to apply the high-level\nreasoning of Large Language Models (LLMs) to low-level robotic control. A\nremaining challenge is to acquire a diverse set of fundamental skills. Existing\napproaches either manually decompose a complex task into atomic robotic actions\nin a top-down fashion, or bootstrap as many combinations as possible in a\nbottom-up fashion to cover a wider range of task possibilities. These\ndecompositions or combinations, however, require an initial skill library. For\nexample, a ``grasping'' capability can never emerge from a skill library\ncontaining only diverse ``pushing'' skills. Existing skill discovery techniques\nwith reinforcement learning acquire skills by an exhaustive exploration but\noften yield non-meaningful behaviors. In this study, we introduce a novel\nframework for skill discovery that is entirely driven by LLMs. The framework\nbegins with an LLM generating task proposals based on the provided scene\ndescription and the robot's configurations, aiming to incrementally acquire new\nskills upon task completion. For each proposed task, a series of reinforcement\nlearning processes are initiated, utilizing reward and success determination\nfunctions sampled by the LLM to develop the corresponding policy. The\nreliability and trustworthiness of learned behaviors are further ensured by an\nindependent vision-language model. We show that starting with zero skill, the\nskill library emerges and expands to more and more meaningful and reliable\nskills, enabling the robot to efficiently further propose and complete advanced\ntasks. Project page: \\url{https://agentic-skill-discovery.github.io}.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Webpage see https://agentic-skill-discovery.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.15019v2",
    "published_date": "2024-05-23 19:44:03 UTC",
    "updated_date": "2024-08-16 15:56:46 UTC"
  },
  {
    "arxiv_id": "2405.15018v3",
    "title": "What Variables Affect Out-of-Distribution Generalization in Pretrained Models?",
    "authors": [
      "Md Yousuf Harun",
      "Kyungbok Lee",
      "Jhair Gallardo",
      "Giri Krishnan",
      "Christopher Kanan"
    ],
    "abstract": "Embeddings produced by pre-trained deep neural networks (DNNs) are widely\nused; however, their efficacy for downstream tasks can vary widely. We study\nthe factors influencing transferability and out-of-distribution (OOD)\ngeneralization of pre-trained DNN embeddings through the lens of the tunnel\neffect hypothesis, which is closely related to intermediate neural collapse.\nThis hypothesis suggests that deeper DNN layers compress representations and\nhinder OOD generalization. Contrary to earlier work, our experiments show this\nis not a universal phenomenon. We comprehensively investigate the impact of DNN\narchitecture, training data, image resolution, and augmentations on\ntransferability. We identify that training with high-resolution datasets\ncontaining many classes greatly reduces representation compression and improves\ntransferability. Our results emphasize the danger of generalizing findings from\ntoy datasets to broader contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15018v3",
    "published_date": "2024-05-23 19:43:45 UTC",
    "updated_date": "2024-10-25 14:14:39 UTC"
  },
  {
    "arxiv_id": "2405.15007v1",
    "title": "RE-Adapt: Reverse Engineered Adaptation of Large Language Models",
    "authors": [
      "William Fleshman",
      "Benjamin Van Durme"
    ],
    "abstract": "We introduce RE-Adapt, an approach to fine-tuning large language models on\nnew domains without degrading any pre-existing instruction-tuning. We reverse\nengineer an adapter which isolates what an instruction-tuned model has learned\nbeyond its corresponding pretrained base model. Importantly, this requires no\nadditional data or training. We can then fine-tune the base model on a new\ndomain and readapt it to instruction following with the reverse engineered\nadapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other\nmethods of fine-tuning, across multiple popular LLMs and datasets, even when\nthe models are used in conjunction with retrieval-augmented generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.15007v1",
    "published_date": "2024-05-23 19:23:40 UTC",
    "updated_date": "2024-05-23 19:23:40 UTC"
  },
  {
    "arxiv_id": "2406.18552v1",
    "title": "Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery",
    "authors": [
      "Yingying Fang",
      "Zihao Jin",
      "Xiaodan Xing",
      "Simon Walsh",
      "Guang Yang"
    ],
    "abstract": "In medical imaging, particularly in early disease detection and prognosis\ntasks, discerning the rationale behind an AI model's predictions is crucial for\nevaluating the reliability of its decisions. Conventional explanation methods\nface challenges in identifying discernible decisive features in medical image\nclassifications, where discriminative features are subtle or not immediately\napparent. To bridge this gap, we propose an explainable model that is equipped\nwith both decision reasoning and feature identification capabilities. Our\napproach not only detects influential image patterns but also uncovers the\ndecisive features that drive the model's final predictions. By implementing our\nmethod, we can efficiently identify and visualise class-specific features\nleveraged by the data-driven model, providing insights into the decision-making\nprocesses of deep learning models. We validated our model in the demanding\nrealm of medical prognosis task, demonstrating its efficacy and potential in\nenhancing the reliability of AI in healthcare and in discovering new knowledge\nin diseases where prognostic understanding is limited.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18552v1",
    "published_date": "2024-05-23 19:00:38 UTC",
    "updated_date": "2024-05-23 19:00:38 UTC"
  },
  {
    "arxiv_id": "2405.14995v1",
    "title": "Lower Bound on the Greedy Approximation Ratio for Adaptive Submodular Cover",
    "authors": [
      "Blake Harris",
      "Viswanath Nagarajan"
    ],
    "abstract": "We show that the greedy algorithm for adaptive-submodular cover has\napproximation ratio at least 1.3*(1+ln Q). Moreover, the instance demonstrating\nthis gap has Q=1. So, it invalidates a prior result in the paper ``Adaptive\nSubmodularity: A New Approach to Active Learning and Stochastic Optimization''\nby Golovin-Krause, that claimed a (1+ln Q)^2 approximation ratio for the same\nalgorithm.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "7 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:2208.08351",
    "pdf_url": "http://arxiv.org/pdf/2405.14995v1",
    "published_date": "2024-05-23 18:56:46 UTC",
    "updated_date": "2024-05-23 18:56:46 UTC"
  },
  {
    "arxiv_id": "2405.14982v1",
    "title": "In-context Time Series Predictor",
    "authors": [
      "Jiecheng Lu",
      "Yan Sun",
      "Shihao Yang"
    ],
    "abstract": "Recent Transformer-based large language models (LLMs) demonstrate in-context\nlearning ability to perform various functions based solely on the provided\ncontext, without updating model parameters. To fully utilize the in-context\ncapabilities in time series forecasting (TSF) problems, unlike previous\nTransformer-based or LLM-based time series forecasting methods, we reformulate\n\"time series forecasting tasks\" as input tokens by constructing a series of\n(lookback, future) pairs within the tokens. This method aligns more closely\nwith the inherent in-context mechanisms, and is more parameter-efficient\nwithout the need of using pre-trained LLM parameters. Furthermore, it addresses\nissues such as overfitting in existing Transformer-based TSF models,\nconsistently achieving better performance across full-data, few-shot, and\nzero-shot settings compared to previous architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14982v1",
    "published_date": "2024-05-23 18:37:00 UTC",
    "updated_date": "2024-05-23 18:37:00 UTC"
  },
  {
    "arxiv_id": "2405.15824v1",
    "title": "Efficient Mitigation of Bus Bunching through Setter-Based Curriculum Learning",
    "authors": [
      "Avidan Shah",
      "Danny Tran",
      "Yuhan Tang"
    ],
    "abstract": "Curriculum learning has been growing in the domain of reinforcement learning\nas a method of improving training efficiency for various tasks. It involves\nmodifying the difficulty (lessons) of the environment as the agent learns, in\norder to encourage more optimal agent behavior and higher reward states.\nHowever, most curriculum learning methods currently involve discrete\ntransitions of the curriculum or predefined steps by the programmer or using\nautomatic curriculum learning on only a small subset training such as only on\nan adversary. In this paper, we propose a novel approach to curriculum learning\nthat uses a Setter Model to automatically generate an action space, adversary\nstrength, initialization, and bunching strength. Transportation and traffic\noptimization is a well known area of study, especially for reinforcement\nlearning based solutions. We specifically look at the bus bunching problem for\nthe context of this study. The main idea of the problem is to minimize the\ndelays caused by inefficient bus timings for passengers arriving and departing\nfrom a system of buses. While the heavy exploration in the area makes\ninnovation and improvement with regards to performance marginal, it\nsimultaneously provides an effective baseline for developing new generalized\ntechniques. Our group is particularly interested in examining curriculum\nlearning and its effect on training efficiency and overall performance. We\ndecide to try a lesser known approach to curriculum learning, in which the\ncurriculum is not fixed or discretely thresholded. Our method for automated\ncurriculum learning involves a curriculum that is dynamically chosen and\nlearned by an adversary network made to increase the difficulty of the agent's\ntraining, and defined by multiple forms of input. Our results are shown in the\nfollowing sections of this paper.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.15824v1",
    "published_date": "2024-05-23 18:26:55 UTC",
    "updated_date": "2024-05-23 18:26:55 UTC"
  },
  {
    "arxiv_id": "2405.14974v3",
    "title": "LOVA3: Learning to Visual Question Answering, Asking and Assessment",
    "authors": [
      "Henry Hengyuan Zhao",
      "Pan Zhou",
      "Difei Gao",
      "Zechen Bai",
      "Mike Zheng Shou"
    ],
    "abstract": "Question answering, asking, and assessment are three innate human traits\ncrucial for understanding the world and acquiring knowledge. By enhancing these\ncapabilities, humans can more effectively utilize data, leading to better\ncomprehension and learning outcomes. Current Multimodal Large Language Models\n(MLLMs) primarily focus on question answering, often neglecting the full\npotential of questioning and assessment skills. Inspired by the human learning\nmechanism, we introduce LOVA3, an innovative framework named \"Learning tO\nVisual question Answering, Asking and Assessment,\" designed to equip MLLMs with\nthese additional capabilities. Our approach involves the creation of two\nsupplementary training tasks GenQA and EvalQA, aiming at fostering the skills\nof asking and assessing questions in the context of images. To develop the\nquestioning ability, we compile a comprehensive set of multimodal foundational\ntasks. For assessment, we introduce a new benchmark called EvalQABench,\ncomprising 64,000 training samples (split evenly between positive and negative\nsamples) and 5,000 validation and testing samples. We posit that enhancing\nMLLMs with the capabilities to answer, ask, and assess questions will enhance\ntheir multimodal comprehension, ultimately improving overall performance. To\nvalidate this hypothesis, we train MLLMs using the LOVA3 framework and evaluate\nthem on a range of multimodal datasets and benchmarks. Our results demonstrate\nconsistent performance gains, underscoring the critical role of these\nadditional tasks in fostering comprehensive intelligence in MLLMs. The code is\navailable at https://github.com/showlab/LOVA3.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024. The code is available at\n  https://github.com/showlab/LOVA3",
    "pdf_url": "http://arxiv.org/pdf/2405.14974v3",
    "published_date": "2024-05-23 18:21:59 UTC",
    "updated_date": "2025-02-19 23:28:40 UTC"
  },
  {
    "arxiv_id": "2405.14966v1",
    "title": "Creativity and Markov Decision Processes",
    "authors": [
      "Joonas Lahikainen",
      "Nadia M. Ady",
      "Christian Guckelsberger"
    ],
    "abstract": "Creativity is already regularly attributed to AI systems outside specialised\ncomputational creativity (CC) communities. However, the evaluation of\ncreativity in AI at large typically lacks grounding in creativity theory, which\ncan promote inappropriate attributions and limit the analysis of creative\nbehaviour. While CC researchers have translated psychological theory into\nformal models, the value of these models is limited by a gap to common AI\nframeworks. To mitigate this limitation, we identify formal mappings between\nBoden's process theory of creativity and Markov Decision Processes (MDPs),\nusing the Creative Systems Framework as a stepping stone. We study three out of\neleven mappings in detail to understand which types of creative processes,\nopportunities for (aberrations), and threats to creativity (uninspiration)\ncould be observed in an MDP. We conclude by discussing quality criteria for the\nselection of such mappings for future work and applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, full paper at 15th International Conference on\n  Computational Creativity, ICCC'24",
    "pdf_url": "http://arxiv.org/pdf/2405.14966v1",
    "published_date": "2024-05-23 18:16:42 UTC",
    "updated_date": "2024-05-23 18:16:42 UTC"
  },
  {
    "arxiv_id": "2405.14959v3",
    "title": "EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting",
    "authors": [
      "Jiaxu Wang",
      "Junhao He",
      "Ziyi Zhang",
      "Mingyuan Sun",
      "Jingkai Sun",
      "Renjing Xu"
    ],
    "abstract": "Event cameras offer promising advantages such as high dynamic range and low\nlatency, making them well-suited for challenging lighting conditions and\nfast-moving scenarios. However, reconstructing 3D scenes from raw event streams\nis difficult because event data is sparse and does not carry absolute color\ninformation. To release its potential in 3D reconstruction, we propose the\nfirst event-based generalizable 3D reconstruction framework, called EvGGS,\nwhich reconstructs scenes as 3D Gaussians from only event input in a\nfeedforward manner and can generalize to unseen cases without any retraining.\nThis framework includes a depth estimation module, an intensity reconstruction\nmodule, and a Gaussian regression module. These submodules connect in a\ncascading manner, and we collaboratively train them with a designed joint loss\nto make them mutually promote. To facilitate related studies, we build a novel\nevent-based 3D dataset with various material objects and calibrated labels of\ngrayscale images, depth maps, camera poses, and silhouettes. Experiments show\nmodels that have jointly trained significantly outperform those trained\nindividually. Our approach performs better than all baselines in reconstruction\nquality, and depth/intensity predictions with satisfactory rendering speed.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14959v3",
    "published_date": "2024-05-23 18:10:26 UTC",
    "updated_date": "2024-10-10 07:41:26 UTC"
  },
  {
    "arxiv_id": "2405.14957v1",
    "title": "Understanding the dynamics of the frequency bias in neural networks",
    "authors": [
      "Juan Molina",
      "Mircea Petrache",
      "Francisco Sahli Costabal",
      "Matías Courdurier"
    ],
    "abstract": "Recent works have shown that traditional Neural Network (NN) architectures\ndisplay a marked frequency bias in the learning process. Namely, the NN first\nlearns the low-frequency features before learning the high-frequency ones. In\nthis study, we rigorously develop a partial differential equation (PDE) that\nunravels the frequency dynamics of the error for a 2-layer NN in the Neural\nTangent Kernel regime. Furthermore, using this insight, we explicitly\ndemonstrate how an appropriate choice of distributions for the initialization\nweights can eliminate or control the frequency bias. We focus our study on the\nFourier Features model, an NN where the first layer has sine and cosine\nactivation functions, with frequencies sampled from a prescribed distribution.\nIn this setup, we experimentally validate our theoretical results and compare\nthe NN dynamics to the solution of the PDE using the finite element method.\nFinally, we empirically show that the same principle extends to multi-layer\nNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14957v1",
    "published_date": "2024-05-23 18:09:16 UTC",
    "updated_date": "2024-05-23 18:09:16 UTC"
  },
  {
    "arxiv_id": "2405.14956v1",
    "title": "Interpretable and Editable Programmatic Tree Policies for Reinforcement Learning",
    "authors": [
      "Hector Kohler",
      "Quentin Delfosse",
      "Riad Akrour",
      "Kristian Kersting",
      "Philippe Preux"
    ],
    "abstract": "Deep reinforcement learning agents are prone to goal misalignments. The\nblack-box nature of their policies hinders the detection and correction of such\nmisalignments, and the trust necessary for real-world deployment. So far,\nsolutions learning interpretable policies are inefficient or require many human\npriors. We propose INTERPRETER, a fast distillation method producing\nINTerpretable Editable tRee Programs for ReinforcEmenT lEaRning. We empirically\ndemonstrate that INTERPRETER compact tree programs match oracles across a\ndiverse set of sequential decision tasks and evaluate the impact of our design\nchoices on interpretability and performances. We show that our policies can be\ninterpreted and edited to correct misalignments on Atari games and to explain\nreal farming strategies.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14956v1",
    "published_date": "2024-05-23 18:07:38 UTC",
    "updated_date": "2024-05-23 18:07:38 UTC"
  },
  {
    "arxiv_id": "2405.14953v5",
    "title": "MallowsPO: Fine-Tune Your LLM with Preference Dispersions",
    "authors": [
      "Haoxian Chen",
      "Hanyang Zhao",
      "Henry Lam",
      "David Yao",
      "Wenpin Tang"
    ],
    "abstract": "Direct Preference Optimization (DPO) has recently emerged as a popular\napproach to improve reinforcement learning with human feedback (RLHF), leading\nto better techniques to fine-tune large language models (LLM). A weakness of\nDPO, however, lies in its lack of capability to characterize the diversity of\nhuman preferences. Inspired by Mallows' theory of preference ranking, we\ndevelop in this paper a new approach, the MallowsPO. A distinct feature of this\napproach is a dispersion index, which reflects the dispersion of human\npreference to prompts. We show that existing DPO models can be reduced to\nspecial cases of this dispersion index, thus unified with MallowsPO. More\nimportantly, we demonstrate (empirically) how to use this dispersion index to\nenhance the performance of DPO in a broad array of benchmark tasks, from\nsynthetic bandit selection to controllable generations and dialogues, while\nmaintaining great generalization capabilities. MallowsPO is also compatible\nwith other SOTA offline preference optimization methods, boosting nearly 2\\%\nextra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14953v5",
    "published_date": "2024-05-23 18:01:11 UTC",
    "updated_date": "2025-04-17 18:52:54 UTC"
  },
  {
    "arxiv_id": "2405.14869v2",
    "title": "PuzzleAvatar: Assembling 3D Avatars from Personal Albums",
    "authors": [
      "Yuliang Xiu",
      "Yufei Ye",
      "Zhen Liu",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "abstract": "Generating personalized 3D avatars is crucial for AR/VR. However, recent\ntext-to-3D methods that generate avatars for celebrities or fictional\ncharacters, struggle with everyday people. Methods for faithful reconstruction\ntypically require full-body images in controlled settings. What if a user could\njust upload their personal \"OOTD\" (Outfit Of The Day) photo collection and get\na faithful avatar in return? The challenge is that such casual photo\ncollections contain diverse poses, challenging viewpoints, cropped views, and\nocclusion (albeit with a consistent outfit, accessories and hairstyle). We\naddress this novel \"Album2Human\" task by developing PuzzleAvatar, a novel model\nthat generates a faithful 3D avatar (in a canonical pose) from a personal OOTD\nalbum, while bypassing the challenging estimation of body and camera pose. To\nthis end, we fine-tune a foundational vision-language model (VLM) on such\nphotos, encoding the appearance, identity, garments, hairstyles, and\naccessories of a person into (separate) learned tokens and instilling these\ncues into the VLM. In effect, we exploit the learned tokens as \"puzzle pieces\"\nfrom which we assemble a faithful, personalized 3D avatar. Importantly, we can\ncustomize avatars by simply inter-changing tokens. As a benchmark for this new\ntask, we collect a new dataset, called PuzzleIOI, with 41 subjects in a total\nof nearly 1K OOTD configurations, in challenging partial photos with paired\nground-truth 3D bodies. Evaluation shows that PuzzleAvatar not only has high\nreconstruction accuracy, outperforming TeCH and MVDreamBooth, but also a unique\nscalability to album photos, and strong robustness. Our code and data are\npublicly available for research purpose at https://puzzleavatar.is.tue.mpg.de/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Page: https://puzzleavatar.is.tue.mpg.de/, Code:\n  https://github.com/YuliangXiu/PuzzleAvatar, Video:\n  https://youtu.be/0hpXH2tVPk4",
    "pdf_url": "http://arxiv.org/pdf/2405.14869v2",
    "published_date": "2024-05-23 17:59:56 UTC",
    "updated_date": "2024-09-14 19:08:50 UTC"
  },
  {
    "arxiv_id": "2405.14868v2",
    "title": "Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis",
    "authors": [
      "Basile Van Hoorick",
      "Rundi Wu",
      "Ege Ozguroglu",
      "Kyle Sargent",
      "Ruoshi Liu",
      "Pavel Tokmakov",
      "Achal Dave",
      "Changxi Zheng",
      "Carl Vondrick"
    ],
    "abstract": "Accurate reconstruction of complex dynamic scenes from just a single\nviewpoint continues to be a challenging task in computer vision. Current\ndynamic novel view synthesis methods typically require videos from many\ndifferent camera viewpoints, necessitating careful recording setups, and\nsignificantly restricting their utility in the wild as well as in terms of\nembodied AI applications. In this paper, we propose $\\textbf{GCD}$, a\ncontrollable monocular dynamic view synthesis pipeline that leverages\nlarge-scale diffusion priors to, given a video of any scene, generate a\nsynchronous video from any other chosen perspective, conditioned on a set of\nrelative camera pose parameters. Our model does not require depth as input, and\ndoes not explicitly model 3D scene geometry, instead performing end-to-end\nvideo-to-video translation in order to achieve its goal efficiently. Despite\nbeing trained on synthetic multi-view video data only, zero-shot real-world\ngeneralization experiments show promising results in multiple domains,\nincluding robotics, object permanence, and driving environments. We believe our\nframework can potentially unlock powerful applications in rich dynamic scene\nunderstanding, perception for robotics, and interactive 3D video viewing\nexperiences for virtual reality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024. Project webpage is available at:\n  https://gcd.cs.columbia.edu/",
    "pdf_url": "http://arxiv.org/pdf/2405.14868v2",
    "published_date": "2024-05-23 17:59:52 UTC",
    "updated_date": "2024-07-05 17:59:57 UTC"
  },
  {
    "arxiv_id": "2405.14863v1",
    "title": "A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns",
    "authors": [
      "Asaf Yehudai",
      "Taelin Karidi",
      "Gabriel Stanovsky",
      "Ariel Goldstein",
      "Omri Abend"
    ],
    "abstract": "Cross-domain alignment refers to the task of mapping a concept from one\ndomain to another. For example, ``If a \\textit{doctor} were a \\textit{color},\nwhat color would it be?''. This seemingly peculiar task is designed to\ninvestigate how people represent concrete and abstract concepts through their\nmappings between categories and their reasoning processes over those mappings.\nIn this paper, we adapt this task from cognitive science to evaluate the\nconceptualization and reasoning abilities of large language models (LLMs)\nthrough a behavioral study. We examine several LLMs by prompting them with a\ncross-domain mapping task and analyzing their responses at both the population\nand individual levels. Additionally, we assess the models' ability to reason\nabout their predictions by analyzing and categorizing their explanations for\nthese mappings. The results reveal several similarities between humans' and\nmodels' mappings and explanations, suggesting that models represent concepts\nsimilarly to humans. This similarity is evident not only in the model\nrepresentation but also in their behavior. Furthermore, the models mostly\nprovide valid explanations and deploy reasoning paths that are similar to those\nof humans.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "CogSci",
    "pdf_url": "http://arxiv.org/pdf/2405.14863v1",
    "published_date": "2024-05-23 17:59:26 UTC",
    "updated_date": "2024-05-23 17:59:26 UTC"
  },
  {
    "arxiv_id": "2405.14861v2",
    "title": "Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models",
    "authors": [
      "Gen Li",
      "Yuling Yan"
    ],
    "abstract": "This paper investigates score-based diffusion models when the underlying\ntarget distribution is concentrated on or near low-dimensional manifolds within\nthe higher-dimensional space in which they formally reside, a common\ncharacteristic of natural image distributions. Despite previous efforts to\nunderstand the data generation process of diffusion models, existing\ntheoretical support remains highly suboptimal in the presence of\nlow-dimensional structure, which we strengthen in this paper. For the popular\nDenoising Diffusion Probabilistic Model (DDPM), we find that the dependency of\nthe error incurred within each denoising step on the ambient dimension $d$ is\nin general unavoidable. We further identify a unique design of coefficients\nthat yields a converges rate at the order of $O(k^{2}/\\sqrt{T})$ (up to log\nfactors), where $k$ is the intrinsic dimension of the target distribution and\n$T$ is the number of steps. This represents the first theoretical demonstration\nthat the DDPM sampler can adapt to unknown low-dimensional structures in the\ntarget distribution, highlighting the critical importance of coefficient\ndesign. All of this is achieved by a novel set of analysis tools that\ncharacterize the algorithmic dynamics in a more deterministic manner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14861v2",
    "published_date": "2024-05-23 17:59:10 UTC",
    "updated_date": "2024-12-31 01:15:25 UTC"
  },
  {
    "arxiv_id": "2405.14925v1",
    "title": "PILOT: Equivariant diffusion for pocket conditioned de novo ligand generation with multi-objective guidance via importance sampling",
    "authors": [
      "Julian Cremer",
      "Tuan Le",
      "Frank Noé",
      "Djork-Arné Clevert",
      "Kristof T. Schütt"
    ],
    "abstract": "The generation of ligands that both are tailored to a given protein pocket\nand exhibit a range of desired chemical properties is a major challenge in\nstructure-based drug design. Here, we propose an in-silico approach for the\n$\\textit{de novo}$ generation of 3D ligand structures using the equivariant\ndiffusion model PILOT, combining pocket conditioning with a large-scale\npre-training and property guidance. Its multi-objective trajectory-based\nimportance sampling strategy is designed to direct the model towards molecules\nthat not only exhibit desired characteristics such as increased binding\naffinity for a given protein pocket but also maintains high synthetic\naccessibility. This ensures the practicality of sampled molecules, thus\nmaximizing their potential for the drug discovery pipeline. PILOT significantly\noutperforms existing methods across various metrics on the common benchmark\ndataset CrossDocked2020. Moreover, we employ PILOT to generate novel ligands\nfor unseen protein pockets from the Kinodata-3D dataset, which encompasses a\nsubstantial portion of the human kinome. The generated structures exhibit\npredicted $IC_{50}$ values indicative of potent biological activity, which\nhighlights the potential of PILOT as a powerful tool for structure-based drug\ndesign.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14925v1",
    "published_date": "2024-05-23 17:58:28 UTC",
    "updated_date": "2024-05-23 17:58:28 UTC"
  },
  {
    "arxiv_id": "2405.14857v3",
    "title": "Conditional Diffusion on Web-Scale Image Pairs leads to Diverse Image Variations",
    "authors": [
      "Manoj Kumar",
      "Neil Houlsby",
      "Emiel Hoogeboom"
    ],
    "abstract": "Generating image variations, where a model produces variations of an input\nimage while preserving the semantic context has gained increasing attention.\nCurrent image variation techniques involve adapting a text-to-image model to\nreconstruct an input image conditioned on the same image. We first demonstrate\nthat a diffusion model trained to reconstruct an input image from frozen\nembeddings, can reconstruct the image with minor variations. Second, inspired\nby how text-to-image models learn from web-scale text-image pairs, we explore a\nnew pretraining strategy to generate image variations using a large collection\nof image pairs. Our diffusion model \\textit{Semantica} receives a random\n(encoded) image from a webpage as conditional input and denoises another noisy\nrandom image from the same webpage. We carefully examine various design choices\nfor the image encoder, given its crucial role in extracting relevant context\nfrom the input image. Once trained, \\textit{Semantica} can adaptively generate\nnew images from a dataset by simply using images from that dataset as input.\nFinally, we identify limitations in standard image consistency metrics for\nevaluating image variations and propose alternative metrics based on few-shot\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14857v3",
    "published_date": "2024-05-23 17:58:03 UTC",
    "updated_date": "2024-10-02 10:34:09 UTC"
  },
  {
    "arxiv_id": "2405.14855v1",
    "title": "Synergistic Global-space Camera and Human Reconstruction from Videos",
    "authors": [
      "Yizhou Zhao",
      "Tuanfeng Y. Wang",
      "Bhiksha Raj",
      "Min Xu",
      "Jimei Yang",
      "Chun-Hao Paul Huang"
    ],
    "abstract": "Remarkable strides have been made in reconstructing static scenes or human\nbodies from monocular videos. Yet, the two problems have largely been\napproached independently, without much synergy. Most visual SLAM methods can\nonly reconstruct camera trajectories and scene structures up to scale, while\nmost HMR methods reconstruct human meshes in metric scale but fall short in\nreasoning with cameras and scenes. This work introduces Synergistic Camera and\nHuman Reconstruction (SynCHMR) to marry the best of both worlds. Specifically,\nwe design Human-aware Metric SLAM to reconstruct metric-scale camera poses and\nscene point clouds using camera-frame HMR as a strong prior, addressing depth,\nscale, and dynamic ambiguities. Conditioning on the dense scene recovered, we\nfurther learn a Scene-aware SMPL Denoiser to enhance world-frame HMR by\nincorporating spatio-temporal coherency and dynamic scene constraints.\nTogether, they lead to consistent reconstructions of camera trajectories, human\nmeshes, and dense scene point clouds in a common world frame. Project page:\nhttps://paulchhuang.github.io/synchmr",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14855v1",
    "published_date": "2024-05-23 17:57:50 UTC",
    "updated_date": "2024-05-23 17:57:50 UTC"
  },
  {
    "arxiv_id": "2405.14853v1",
    "title": "Privileged Sensing Scaffolds Reinforcement Learning",
    "authors": [
      "Edward S. Hu",
      "James Springer",
      "Oleh Rybkin",
      "Dinesh Jayaraman"
    ],
    "abstract": "We need to look at our shoelaces as we first learn to tie them but having\nmastered this skill, can do it from touch alone. We call this phenomenon\n\"sensory scaffolding\": observation streams that are not needed by a master\nmight yet aid a novice learner. We consider such sensory scaffolding setups for\ntraining artificial agents. For example, a robot arm may need to be deployed\nwith just a low-cost, robust, general-purpose camera; yet its performance may\nimprove by having privileged training-time-only access to informative albeit\nexpensive and unwieldy motion capture rigs or fragile tactile sensors. For\nthese settings, we propose \"Scaffolder\", a reinforcement learning approach\nwhich effectively exploits privileged sensing in critics, world models, reward\nestimators, and other such auxiliary components that are only used at training\ntime, to improve the target policy. For evaluating sensory scaffolding agents,\nwe design a new \"S3\" suite of ten diverse simulated robotic tasks that explore\na wide range of practical sensor setups. Agents must use privileged camera\nsensing to train blind hurdlers, privileged active visual perception to help\nrobot arms overcome visual occlusions, privileged touch sensors to train robot\nhands, and more. Scaffolder easily outperforms relevant prior baselines and\nfrequently performs comparably even to policies that have test-time access to\nthe privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024 Spotlight version",
    "pdf_url": "http://arxiv.org/pdf/2405.14853v1",
    "published_date": "2024-05-23 17:57:14 UTC",
    "updated_date": "2024-05-23 17:57:14 UTC"
  },
  {
    "arxiv_id": "2405.14838v1",
    "title": "From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step",
    "authors": [
      "Yuntian Deng",
      "Yejin Choi",
      "Stuart Shieber"
    ],
    "abstract": "When leveraging language models for reasoning tasks, generating explicit\nchain-of-thought (CoT) steps often proves essential for achieving high accuracy\nin final outputs. In this paper, we investigate if models can be taught to\ninternalize these CoT steps. To this end, we propose a simple yet effective\nmethod for internalizing CoT steps: starting with a model trained for explicit\nCoT reasoning, we gradually remove the intermediate steps and finetune the\nmodel. This process allows the model to internalize the intermediate reasoning\nsteps, thus simplifying the reasoning process while maintaining high\nperformance. Our approach enables a GPT-2 Small model to solve 9-by-9\nmultiplication with up to 99% accuracy, whereas standard training cannot solve\nbeyond 4-by-4 multiplication. Furthermore, our method proves effective on\nlarger language models, such as Mistral 7B, achieving over 50% accuracy on\nGSM8K without producing any intermediate steps.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14838v1",
    "published_date": "2024-05-23 17:54:14 UTC",
    "updated_date": "2024-05-23 17:54:14 UTC"
  },
  {
    "arxiv_id": "2405.17465v2",
    "title": "Information Fusion in Smart Agriculture: Machine Learning Applications and Future Research Directions",
    "authors": [
      "Aashu Katharria",
      "Kanchan Rajwar",
      "Millie Pant",
      "Juan D. Velásquez",
      "Václav Snášel",
      "Kusum Deep"
    ],
    "abstract": "Machine learning (ML) is a rapidly evolving technology with expanding\napplications across various fields. This paper presents a comprehensive survey\nof recent ML applications in agriculture for sustainability and efficiency.\nExisting reviews mainly focus on narrow subdomains or lack a fusion-driven\nperspectives. This study provides a combined analysis of ML applications in\nagriculture, structured around five key objectives: (i) Analyzing ML techniques\nacross pre-harvesting, harvesting, and post-harvesting phases. (ii)\nDemonstrating how ML can be used with agricultural data and data fusion. (iii)\nConducting a bibliometric and statistical analysis to reveal research trends\nand activity. (iv) Investigating real-world case studies of leading artificial\nintelligence (AI)-driven agricultural companies that use different types of\nmultisensors and multisource data. (v) Compiling publicly available datasets to\nsupport ML model training. Going beyond existing previous reviews, this review\nfocuses on how machine learning (ML) techniques, combined with multi-source\ndata fusion (integrating remote sensing, IoT, and climate analytics), enhance\nprecision agriculture by improving predictive accuracy and decision-making.\nCase studies and statistical insights illustrate the evolving landscape of AI\ndriven smart farming, while future research directions also discusses\nchallenges associated with data fusion for heterogeneous datasets. This review\nbridges the gap between AI research and agricultural applications, offering a\nroadmap for researchers, industry professionals, and policymakers to harness\ninformation fusion and ML for advancing precision agriculture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17465v2",
    "published_date": "2024-05-23 17:53:31 UTC",
    "updated_date": "2025-03-18 17:32:09 UTC"
  },
  {
    "arxiv_id": "2405.14831v3",
    "title": "HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models",
    "authors": [
      "Bernal Jiménez Gutiérrez",
      "Yiheng Shu",
      "Yu Gu",
      "Michihiro Yasunaga",
      "Yu Su"
    ],
    "abstract": "In order to thrive in hostile and ever-changing natural environments,\nmammalian brains evolved to store large amounts of knowledge about the world\nand continually integrate new information while avoiding catastrophic\nforgetting. Despite the impressive accomplishments, large language models\n(LLMs), even with retrieval-augmented generation (RAG), still struggle to\nefficiently and effectively integrate a large amount of new experiences after\npre-training. In this work, we introduce HippoRAG, a novel retrieval framework\ninspired by the hippocampal indexing theory of human long-term memory to enable\ndeeper and more efficient knowledge integration over new experiences. HippoRAG\nsynergistically orchestrates LLMs, knowledge graphs, and the Personalized\nPageRank algorithm to mimic the different roles of neocortex and hippocampus in\nhuman memory. We compare HippoRAG with existing RAG methods on multi-hop\nquestion answering and show that our method outperforms the state-of-the-art\nmethods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves\ncomparable or better performance than iterative retrieval like IRCoT while\nbeing 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into\nIRCoT brings further substantial gains. Finally, we show that our method can\ntackle new types of scenarios that are out of reach of existing methods. Code\nand data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024. Code and data:\n  https://github.com/OSU-NLP-Group/HippoRAG",
    "pdf_url": "http://arxiv.org/pdf/2405.14831v3",
    "published_date": "2024-05-23 17:47:55 UTC",
    "updated_date": "2025-01-14 16:17:49 UTC"
  },
  {
    "arxiv_id": "2405.14822v2",
    "title": "PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher",
    "authors": [
      "Dongjun Kim",
      "Chieh-Hsin Lai",
      "Wei-Hsiang Liao",
      "Yuhta Takida",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ],
    "abstract": "The diffusion model performs remarkable in generating high-dimensional\ncontent but is computationally intensive, especially during training. We\npropose Progressive Growing of Diffusion Autoencoder (PaGoDA), a novel pipeline\nthat reduces the training costs through three stages: training diffusion on\ndownsampled data, distilling the pretrained diffusion, and progressive\nsuper-resolution. With the proposed pipeline, PaGoDA achieves a $64\\times$\nreduced cost in training its diffusion model on 8x downsampled data; while at\nthe inference, with the single-step, it performs state-of-the-art on ImageNet\nacross all resolutions from 64x64 to 512x512, and text-to-image. PaGoDA's\npipeline can be applied directly in the latent space, adding compression\nalongside the pre-trained autoencoder in Latent Diffusion Models (e.g., Stable\nDiffusion). The code is available at https://github.com/sony/pagoda.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14822v2",
    "published_date": "2024-05-23 17:39:09 UTC",
    "updated_date": "2024-10-29 15:26:00 UTC"
  },
  {
    "arxiv_id": "2405.20347v1",
    "title": "Small Language Models for Application Interactions: A Case Study",
    "authors": [
      "Beibin Li",
      "Yi Zhang",
      "Sébastien Bubeck",
      "Jeevan Pathuri",
      "Ishai Menache"
    ],
    "abstract": "We study the efficacy of Small Language Models (SLMs) in facilitating\napplication usage through natural language interactions. Our focus here is on a\nparticular internal application used in Microsoft for cloud supply chain\nfulfilment. Our experiments show that small models can outperform much larger\nones in terms of both accuracy and running time, even when fine-tuned on small\ndatasets. Alongside these results, we also highlight SLM-based system design\nconsiderations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.20347v1",
    "published_date": "2024-05-23 17:33:32 UTC",
    "updated_date": "2024-05-23 17:33:32 UTC"
  },
  {
    "arxiv_id": "2405.14808v2",
    "title": "Implicit Personalization in Language Models: A Systematic Study",
    "authors": [
      "Zhijing Jin",
      "Nils Heil",
      "Jiarui Liu",
      "Shehzaad Dhuliawala",
      "Yahang Qi",
      "Bernhard Schölkopf",
      "Rada Mihalcea",
      "Mrinmaya Sachan"
    ],
    "abstract": "Implicit Personalization (IP) is a phenomenon of language models inferring a\nuser's background from the implicit cues in the input prompts and tailoring the\nresponse based on this inference. While previous work has touched upon various\ninstances of this problem, there lacks a unified framework to study this\nbehavior. This work systematically studies IP through a rigorous mathematical\nformulation, a multi-perspective moral reasoning framework, and a set of case\nstudies. Our theoretical foundation for IP relies on a structural causal model\nand introduces a novel method, indirect intervention, to estimate the causal\neffect of a mediator variable that cannot be directly intervened upon. Beyond\nthe technical approach, we also introduce a set of moral reasoning principles\nbased on three schools of moral philosophy to study when IP may or may not be\nethically appropriate. Equipped with both mathematical and ethical insights, we\npresent three diverse case studies illustrating the varied nature of the IP\nproblem and offer recommendations for future research. Our code is at\nhttps://github.com/jiarui-liu/IP, and our data is at\nhttps://huggingface.co/datasets/Jerry999/ImplicitPersonalizationData.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2405.14808v2",
    "published_date": "2024-05-23 17:18:46 UTC",
    "updated_date": "2024-10-31 14:19:49 UTC"
  },
  {
    "arxiv_id": "2406.18550v1",
    "title": "Pre-Trained Vision-Language Models as Partial Annotators",
    "authors": [
      "Qian-Wei Wang",
      "Yuqiu Xie",
      "Letian Zhang",
      "Zimo Liu",
      "Shu-Tao Xia"
    ],
    "abstract": "Pre-trained vision-language models learn massive data to model unified\nrepresentations of images and natural languages, which can be widely applied to\ndownstream machine learning tasks. In addition to zero-shot inference, in order\nto better adapt pre-trained models to the requirements of downstream tasks,\npeople usually use methods such as few-shot or parameter-efficient fine-tuning\nand knowledge distillation. However, annotating samples is laborious, while a\nlarge number of unlabeled samples can be easily obtained. In this paper, we\ninvestigate a novel \"pre-trained annotating - weakly-supervised learning\"\nparadigm for pre-trained model application and experiment on image\nclassification tasks. Specifically, based on CLIP, we annotate image samples\nwith multiple prompt templates to obtain multiple candidate labels to form the\nnoisy partial label dataset, and design a collaborative consistency\nregularization algorithm to solve this problem. Our method simultaneously\ntrains two neural networks, which collaboratively purify training labels for\neach other and obtain pseudo-labels for self-training, while adopting\nprototypical similarity alignment and noisy supervised contrastive learning to\noptimize model representation. In experiments, our method achieves performances\nfar beyond zero-shot inference without introducing additional label\ninformation, and outperforms other weakly supervised learning and few-shot\nfine-tuning methods, and obtains smaller deployed models. Our code is available\nat: \\url{https://anonymous.4open.science/r/Co-Reg-8CF9}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18550v1",
    "published_date": "2024-05-23 17:17:27 UTC",
    "updated_date": "2024-05-23 17:17:27 UTC"
  },
  {
    "arxiv_id": "2405.14796v3",
    "title": "Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions",
    "authors": [
      "Mohamed Debbagh",
      "Yixue Liu",
      "Zhouzhou Zheng",
      "Xintong Jiang",
      "Shangpeng Sun",
      "Mark Lefsrud"
    ],
    "abstract": "A plant growth simulation can be characterized as a reconstructed visual\nrepresentation of a plant or plant system. The phenotypic characteristics and\nplant structures are controlled by the scene environment and other contextual\nattributes. Considering the temporal dependencies and compounding effects of\nvarious factors on growth trajectories, we formulate a probabilistic approach\nto the simulation task by solving a frame synthesis and pattern recognition\nproblem. We introduce a sequence-informed plant growth simulation framework\n(SI-PGS) that employs a conditional generative model to implicitly learn a\ndistribution of possible plant representations within a dynamic scene from a\nfusion of low-dimensional temporal sensor and context data. Methods such as\ncontrolled latent sampling and recurrent output connections are used to improve\ncoherence in the plant structures between frames of prediction. In this work,\nwe demonstrate that SI-PGS is able to capture temporal dependencies and\ncontinuously generate realistic frames of plant growth.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14796v3",
    "published_date": "2024-05-23 17:06:46 UTC",
    "updated_date": "2024-07-10 01:49:45 UTC"
  },
  {
    "arxiv_id": "2405.14785v1",
    "title": "EditWorld: Simulating World Dynamics for Instruction-Following Image Editing",
    "authors": [
      "Ling Yang",
      "Bohan Zeng",
      "Jiaming Liu",
      "Hong Li",
      "Minghao Xu",
      "Wentao Zhang",
      "Shuicheng Yan"
    ],
    "abstract": "Diffusion models have significantly improved the performance of image\nediting. Existing methods realize various approaches to achieve high-quality\nimage editing, including but not limited to text control, dragging operation,\nand mask-and-inpainting. Among these, instruction-based editing stands out for\nits convenience and effectiveness in following human instructions across\ndiverse scenarios. However, it still focuses on simple editing operations like\nadding, replacing, or deleting, and falls short of understanding aspects of\nworld dynamics that convey the realistic dynamic nature in the physical world.\nTherefore, this work, EditWorld, introduces a new editing task, namely\nworld-instructed image editing, which defines and categorizes the instructions\ngrounded by various world scenarios. We curate a new image editing dataset with\nworld instructions using a set of large pretrained models (e.g., GPT-3.5,\nVideo-LLava and SDXL). To enable sufficient simulation of world dynamics for\nimage editing, our EditWorld trains model in the curated dataset, and improves\ninstruction-following ability with designed post-edit strategy. Extensive\nexperiments demonstrate our method significantly outperforms existing editing\nmethods in this new task. Our dataset and code will be available at\nhttps://github.com/YangLing0818/EditWorld",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project: https://github.com/YangLing0818/EditWorld",
    "pdf_url": "http://arxiv.org/pdf/2405.14785v1",
    "published_date": "2024-05-23 16:54:17 UTC",
    "updated_date": "2024-05-23 16:54:17 UTC"
  },
  {
    "arxiv_id": "2405.14781v1",
    "title": "Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning",
    "authors": [
      "Nay Myat Min",
      "Long H. Pham",
      "Jun Sun"
    ],
    "abstract": "The application of deep neural network models in various security-critical\napplications has raised significant security concerns, particularly the risk of\nbackdoor attacks. Neural backdoors pose a serious security threat as they allow\nattackers to maliciously alter model behavior. While many defenses have been\nexplored, existing approaches are often bounded by model-specific constraints,\nor necessitate complex alterations to the training process, or fall short\nagainst diverse backdoor attacks. In this work, we introduce a novel method for\ncomprehensive and effective elimination of backdoors, called ULRL (short for\nUnLearn and ReLearn for backdoor removal). ULRL requires only a small set of\nclean samples and works effectively against all kinds of backdoors. It first\napplies unlearning for identifying suspicious neurons and then targeted neural\nweight tuning for backdoor mitigation (i.e., by promoting significant weight\ndeviation on the suspicious neurons). Evaluated against 12 different types of\nbackdoors, ULRL is shown to significantly outperform state-of-the-art methods\nin eliminating backdoors whilst preserving the model utility.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14781v1",
    "published_date": "2024-05-23 16:49:09 UTC",
    "updated_date": "2024-05-23 16:49:09 UTC"
  },
  {
    "arxiv_id": "2405.14768v3",
    "title": "WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models",
    "authors": [
      "Peng Wang",
      "Zexi Li",
      "Ningyu Zhang",
      "Ziwen Xu",
      "Yunzhi Yao",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen"
    ],
    "abstract": "Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14768v3",
    "published_date": "2024-05-23 16:35:52 UTC",
    "updated_date": "2024-12-19 02:18:54 UTC"
  },
  {
    "arxiv_id": "2405.14758v2",
    "title": "Axioms for AI Alignment from Human Feedback",
    "authors": [
      "Luise Ge",
      "Daniel Halpern",
      "Evi Micha",
      "Ariel D. Procaccia",
      "Itai Shapira",
      "Yevgeniy Vorobeychik",
      "Junlin Wu"
    ],
    "abstract": "In the context of reinforcement learning from human feedback (RLHF), the\nreward function is generally derived from maximum likelihood estimation of a\nrandom utility model based on pairwise comparisons made by humans. The problem\nof learning a reward function is one of preference aggregation that, we argue,\nlargely falls within the scope of social choice theory. From this perspective,\nwe can evaluate different aggregation methods via established axioms, examining\nwhether these methods meet or fail well-known standards. We demonstrate that\nboth the Bradley-Terry-Luce Model and its broad generalizations fail to meet\nbasic axioms. In response, we develop novel rules for learning reward functions\nwith strong axiomatic guarantees. A key innovation from the standpoint of\nsocial choice is that our problem has a linear structure, which greatly\nrestricts the space of feasible rules and leads to a new paradigm that we call\nlinear social choice.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14758v2",
    "published_date": "2024-05-23 16:29:29 UTC",
    "updated_date": "2024-11-07 15:40:25 UTC"
  },
  {
    "arxiv_id": "2405.14753v1",
    "title": "A Transformer-Based Approach for Smart Invocation of Automatic Code Completion",
    "authors": [
      "Aral de Moor",
      "Arie van Deursen",
      "Maliheh Izadi"
    ],
    "abstract": "Transformer-based language models are highly effective for code completion,\nwith much research dedicated to enhancing the content of these completions.\nDespite their effectiveness, these models come with high operational costs and\ncan be intrusive, especially when they suggest too often and interrupt\ndevelopers who are concentrating on their work. Current research largely\noverlooks how these models interact with developers in practice and neglects to\naddress when a developer should receive completion suggestions. To tackle this\nissue, we developed a machine learning model that can accurately predict when\nto invoke a code completion tool given the code context and available telemetry\ndata.\n  To do so, we collect a dataset of 200k developer interactions with our\ncross-IDE code completion plugin and train several invocation filtering models.\nOur results indicate that our small-scale transformer model significantly\noutperforms the baseline while maintaining low enough latency. We further\nexplore the search space for integrating additional telemetry data into a\npre-trained transformer directly and obtain promising results. To further\ndemonstrate our approach's practical potential, we deployed the model in an\nonline environment with 34 developers and provided real-world insights based on\n74k actual invocations.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 3 figures; Accepted at FSE AIWARE'24",
    "pdf_url": "http://arxiv.org/pdf/2405.14753v1",
    "published_date": "2024-05-23 16:19:32 UTC",
    "updated_date": "2024-05-23 16:19:32 UTC"
  },
  {
    "arxiv_id": "2405.14750v2",
    "title": "Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams",
    "authors": [
      "Juyoung Yun",
      "Jungmin Shin"
    ],
    "abstract": "Solar flares, especially C, M, and X class, pose significant risks to\nsatellite operations, communication systems, and power grids. We present a\nnovel approach for predicting extreme solar flares using HMI intensitygrams and\nmagnetograms. By detecting sunspots from intensitygrams and extracting magnetic\nfield patches from magnetograms, we train a Residual Network (ResNet) to\nclassify extreme class flares. Our model demonstrates high accuracy, offering a\nrobust tool for predicting extreme solar flares and improving space weather\nforecasting. Additionally, we show that HMI magnetograms provide more useful\ndata for deep learning compared to other SDO AIA images by better capturing\nfeatures critical for predicting flare magnitudes. This study underscores the\nimportance of identifying magnetic fields in solar flare prediction, marking a\nsignificant advancement in solar activity prediction with practical\nimplications for mitigating space weather impacts.",
    "categories": [
      "astro-ph.SR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "The dataset has some noise, so we need to make new data to train more\n  robust model",
    "pdf_url": "http://arxiv.org/pdf/2405.14750v2",
    "published_date": "2024-05-23 16:17:16 UTC",
    "updated_date": "2024-06-19 22:11:28 UTC"
  },
  {
    "arxiv_id": "2405.19355v1",
    "title": "Enhancing Trust and Security in the Vehicular Metaverse: A Reputation-Based Mechanism for Participants with Moral Hazard",
    "authors": [
      "Ismail Lotfi",
      "Marwa Qaraqe",
      "Ali Ghrayeb",
      "Niyato Dusit"
    ],
    "abstract": "In this paper, we tackle the issue of moral hazard within the realm of the\nvehicular Metaverse. A pivotal facilitator of the vehicular Metaverse is the\neffective orchestration of its market elements, primarily comprised of sensing\ninternet of things (SIoT) devices. These SIoT devices play a critical role by\nfurnishing the virtual service provider (VSP) with real-time sensing data,\nallowing for the faithful replication of the physical environment within the\nvirtual realm. However, SIoT devices with intentional misbehavior can identify\na loophole in the system post-payment and proceeds to deliver falsified\ncontent, which cause the whole vehicular Metaverse to collapse. To combat this\nsignificant problem, we propose an incentive mechanism centered around a\nreputation-based strategy. Specifically, the concept involves maintaining\nreputation scores for participants based on their interactions with the VSP.\nThese scores are derived from feedback received by the VSP from Metaverse users\nregarding the content delivered by the VSP and are managed using a subjective\nlogic model. Nevertheless, to prevent ``good\" SIoT devices with false positive\nratings to leave the Metaverse market, we build a vanishing-like system of\nprevious ratings so that the VSP can make informed decisions based on the most\nrecent and accurate data available. Finally, we validate our proposed model\nthrough extensive simulations. Our primary results show that our mechanism can\nefficiently prevent malicious devices from starting their poisoning attacks. At\nthe same time, trustworthy SIoT devices that had a previous miss-classification\nare not banned from the market.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted in WCNC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19355v1",
    "published_date": "2024-05-23 16:17:07 UTC",
    "updated_date": "2024-05-23 16:17:07 UTC"
  },
  {
    "arxiv_id": "2405.14749v2",
    "title": "Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence",
    "authors": [
      "Minheng Xiao",
      "Xian Yu",
      "Lei Ying"
    ],
    "abstract": "Risk-sensitive reinforcement learning (RL) is crucial for maintaining\nreliable performance in high-stakes applications. While traditional RL methods\naim to learn a point estimate of the random cumulative cost, distributional RL\n(DRL) seeks to estimate the entire distribution of it, which leads to a unified\nframework for handling different risk measures. However, developing policy\ngradient methods for risk-sensitive DRL is inherently more complex as it\ninvolves finding the gradient of a probability measure. This paper introduces a\nnew policy gradient method for risk-sensitive DRL with general coherent risk\nmeasures, where we provide an analytical form of the probability measure's\ngradient for any distribution. For practical use, we design a categorical\ndistributional policy gradient algorithm (CDPG) that approximates any\ndistribution by a categorical family supported on some fixed points. We further\nprovide a finite-support optimality guarantee and a finite-iteration\nconvergence guarantee under inexact policy evaluation and gradient estimation.\nThrough experiments on stochastic Cliffwalk and CartPole environments, we\nillustrate the benefits of considering a risk-sensitive setting in DRL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14749v2",
    "published_date": "2024-05-23 16:16:58 UTC",
    "updated_date": "2025-01-31 15:53:01 UTC"
  },
  {
    "arxiv_id": "2405.14748v1",
    "title": "MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs",
    "authors": [
      "Georgios Chatzigeorgakidis",
      "Konstantinos Lentzos",
      "Dimitrios Skoutas"
    ],
    "abstract": "Predicting future values in multivariate time series is vital across various\ndomains. This work explores the use of large language models (LLMs) for this\ntask. However, LLMs typically handle one-dimensional data. We introduce\nMultiCast, a zero-shot LLM-based approach for multivariate time series\nforecasting. It allows LLMs to receive multivariate time series as input,\nthrough three novel token multiplexing solutions that effectively reduce\ndimensionality while preserving key repetitive patterns. Additionally, a\nquantization scheme helps LLMs to better learn these patterns, while\nsignificantly reducing token use for practical applications. We showcase the\nperformance of our approach in terms of RMSE and execution time against\nstate-of-the-art approaches on three real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14748v1",
    "published_date": "2024-05-23 16:16:00 UTC",
    "updated_date": "2024-05-23 16:16:00 UTC"
  },
  {
    "arxiv_id": "2405.14747v1",
    "title": "TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on Driving Scenes",
    "authors": [
      "Yanping Fu",
      "Wenbin Liao",
      "Xinyuan Liu",
      "Hang xu",
      "Yike Ma",
      "Feng Dai",
      "Yucheng Zhang"
    ],
    "abstract": "As an emerging task that integrates perception and reasoning, topology\nreasoning in autonomous driving scenes has recently garnered widespread\nattention. However, existing work often emphasizes \"perception over reasoning\":\nthey typically boost reasoning performance by enhancing the perception of lanes\nand directly adopt MLP to learn lane topology from lane query. This paradigm\noverlooks the geometric features intrinsic to the lanes themselves and are\nprone to being influenced by inherent endpoint shifts in lane detection.\n  To tackle this issue, we propose an interpretable method for lane topology\nreasoning based on lane geometric distance and lane query similarity, named\nTopoLogic.\n  This method mitigates the impact of endpoint shifts in geometric space, and\nintroduces explicit similarity calculation in semantic space as a complement.\nBy integrating results from both spaces, our methods provides more\ncomprehensive information for lane topology.\n  Ultimately, our approach significantly outperforms the existing\nstate-of-the-art methods on the mainstream benchmark OpenLane-V2 (23.9 v.s.\n10.9 in TOP$_{ll}$ and 44.1 v.s. 39.8 in OLS on subset_A. Additionally, our\nproposed geometric distance topology reasoning method can be incorporated into\nwell-trained models without re-training, significantly boost the performance of\nlane topology reasoning. The code is released at\nhttps://github.com/Franpin/TopoLogic.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14747v1",
    "published_date": "2024-05-23 16:15:17 UTC",
    "updated_date": "2024-05-23 16:15:17 UTC"
  },
  {
    "arxiv_id": "2405.14743v1",
    "title": "Iterative Causal Segmentation: Filling the Gap between Market Segmentation and Marketing Strategy",
    "authors": [
      "Kaihua Ding",
      "Jingsong Cui",
      "Mohammad Soltani",
      "Jing Jin"
    ],
    "abstract": "The field of causal Machine Learning (ML) has made significant strides in\nrecent years. Notable breakthroughs include methods such as meta learners\n(arXiv:1706.03461v6) and heterogeneous doubly robust estimators\n(arXiv:2004.14497) introduced in the last five years. Despite these\nadvancements, the field still faces challenges, particularly in managing\ntightly coupled systems where both the causal treatment variable and a\nconfounding covariate must serve as key decision-making indicators. This\nscenario is common in applications of causal ML for marketing, such as\nmarketing segmentation and incremental marketing uplift. In this work, we\npresent our formally proven algorithm, iterative causal segmentation, to\naddress this issue.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14743v1",
    "published_date": "2024-05-23 16:12:33 UTC",
    "updated_date": "2024-05-23 16:12:33 UTC"
  },
  {
    "arxiv_id": "2405.14742v1",
    "title": "HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning",
    "authors": [
      "Zhuo Xu",
      "Lu Bai",
      "Lixin Cui",
      "Ming Li",
      "Yue Wang",
      "Edwin R. Hancock"
    ],
    "abstract": "Graph Auto-Encoders (GAEs) are powerful tools for graph representation\nlearning. In this paper, we develop a novel Hierarchical Cluster-based GAE\n(HC-GAE), that can learn effective structural characteristics for graph data\nanalysis. To this end, during the encoding process, we commence by utilizing\nthe hard node assignment to decompose a sample graph into a family of separated\nsubgraphs. We compress each subgraph into a coarsened node, transforming the\noriginal graph into a coarsened graph. On the other hand, during the decoding\nprocess, we adopt the soft node assignment to reconstruct the original graph\nstructure by expanding the coarsened nodes. By hierarchically performing the\nabove compressing procedure during the decoding process as well as the\nexpanding procedure during the decoding process, the proposed HC-GAE can\neffectively extract bidirectionally hierarchical structural features of the\noriginal sample graph. Furthermore, we re-design the loss function that can\nintegrate the information from either the encoder or the decoder. Since the\nassociated graph convolution operation of the proposed HC-GAE is restricted in\neach individual separated subgraph and cannot propagate the node information\nbetween different subgraphs, the proposed HC-GAE can significantly reduce the\nover-smoothing problem arising in the classical convolution-based GAEs. The\nproposed HC-GAE can generate effective representations for either node\nclassification or graph classification, and the experiments demonstrate the\neffectiveness on real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14742v1",
    "published_date": "2024-05-23 16:08:04 UTC",
    "updated_date": "2024-05-23 16:08:04 UTC"
  },
  {
    "arxiv_id": "2405.14728v1",
    "title": "Intervention and Conditioning in Causal Bayesian Networks",
    "authors": [
      "Sainyam Galhotra",
      "Joseph Y. Halpern"
    ],
    "abstract": "Causal models are crucial for understanding complex systems and identifying\ncausal relationships among variables. Even though causal models are extremely\npopular, conditional probability calculation of formulas involving\ninterventions pose significant challenges. In case of Causal Bayesian Networks\n(CBNs), Pearl assumes autonomy of mechanisms that determine interventions to\ncalculate a range of probabilities. We show that by making simple yet often\nrealistic independence assumptions, it is possible to uniquely estimate the\nprobability of an interventional formula (including the well-studied notions of\nprobability of sufficiency and necessity). We discuss when these assumptions\nare appropriate. Importantly, in many cases of interest, when the assumptions\nare appropriate, these probability estimates can be evaluated using\nobservational data, which carries immense significance in scenarios where\nconducting experiments is impractical or unfeasible.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14728v1",
    "published_date": "2024-05-23 15:55:38 UTC",
    "updated_date": "2024-05-23 15:55:38 UTC"
  },
  {
    "arxiv_id": "2405.14719v1",
    "title": "Decision-Focused Forecasting: Decision Losses for Multistage Optimisation",
    "authors": [
      "Egon Peršak",
      "Miguel F. Anjos"
    ],
    "abstract": "Decision-focused learning has emerged as a promising approach for decision\nmaking under uncertainty by training the upstream predictive aspect of the\npipeline with respect to the quality of the downstream decisions. Most existing\nwork has focused on single stage problems. Many real-world decision problems\nare more appropriately modelled using multistage optimisation as contextual\ninformation such as prices or demand is revealed over time and decisions now\nhave a bearing on future decisions. We propose decision-focused forecasting, a\nmultiple-implicitlayer model which in its training accounts for the\nintertemporal decision effects of forecasts using differentiable optimisation.\nThe recursive model reflects a fully differentiable multistage optimisation\napproach. We present an analysis of the gradients produced by this model\nshowing the adjustments made to account for the state-path caused by\nforecasting. We demonstrate an application of the model to an energy storage\narbitrage task and report that our model outperforms existing approaches.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "I.2.8"
    ],
    "primary_category": "math.OC",
    "comment": "Under review. Preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.14719v1",
    "published_date": "2024-05-23 15:48:46 UTC",
    "updated_date": "2024-05-23 15:48:46 UTC"
  },
  {
    "arxiv_id": "2405.14718v1",
    "title": "StyleX: A Trainable Metric for X-ray Style Distances",
    "authors": [
      "Dominik Eckert",
      "Christopher Syben",
      "Christian Hümmer",
      "Ludwig Ritschl",
      "Steffen Kappler",
      "Sebastian Stober"
    ],
    "abstract": "The progression of X-ray technology introduces diverse image styles that need\nto be adapted to the preferences of radiologists. To support this task, we\nintroduce a novel deep learning-based metric that quantifies style differences\nof non-matching image pairs. At the heart of our metric is an encoder capable\nof generating X-ray image style representations. This encoder is trained\nwithout any explicit knowledge of style distances by exploiting Simple Siamese\nlearning. During inference, the style representations produced by the encoder\nare used to calculate a distance metric for non-matching image pairs. Our\nexperiments investigate the proposed concept for a disclosed reproducible and a\nproprietary image processing pipeline along two dimensions: First, we use a\nt-distributed stochastic neighbor embedding (t-SNE) analysis to illustrate that\nthe encoder outputs provide meaningful and discriminative style\nrepresentations. Second, the proposed metric calculated from the encoder\noutputs is shown to quantify style distances for non-matching pairs in good\nalignment with the human perception. These results confirm that our proposed\nmethod is a promising technique to quantify style differences, which can be\nused for guided style selection as well as automatic optimization of image\npipeline parameters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14718v1",
    "published_date": "2024-05-23 15:48:38 UTC",
    "updated_date": "2024-05-23 15:48:38 UTC"
  },
  {
    "arxiv_id": "2405.14716v2",
    "title": "HTN-Based Tutors: A New Intelligent Tutoring Framework Based on Hierarchical Task Networks",
    "authors": [
      "Momin N. Siddiqui",
      "Adit Gupta",
      "Jennifer M. Reddig",
      "Christopher J. MacLellan"
    ],
    "abstract": "Intelligent tutors have shown success in delivering a personalized and\nadaptive learning experience. However, there exist challenges regarding the\ngranularity of knowledge in existing frameworks and the resulting instructions\nthey can provide. To address these issues, we propose HTN-based tutors, a new\nintelligent tutoring framework that represents expert models using Hierarchical\nTask Networks (HTNs). Like other tutoring frameworks, it allows flexible\nencoding of different problem-solving strategies while providing the additional\nbenefit of a hierarchical knowledge organization. We leverage the latter to\ncreate tutors that can adapt the granularity of their scaffolding. This\norganization also aligns well with the compositional nature of skills.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in Proceedings of the Eleventh ACM\n  Conference on Learning @ Scale (L@S'24), July 18--20, 2024, Atlanta, GA, USA",
    "pdf_url": "http://arxiv.org/pdf/2405.14716v2",
    "published_date": "2024-05-23 15:46:42 UTC",
    "updated_date": "2024-05-24 02:38:22 UTC"
  },
  {
    "arxiv_id": "2405.14715v1",
    "title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models",
    "authors": [
      "Young Kyun Jang",
      "Ser-nam Lim"
    ],
    "abstract": "Modern retrieval systems often struggle with upgrading to new and more\npowerful models due to the incompatibility of embeddings between the old and\nnew models. This necessitates a costly process known as backfilling, which\ninvolves re-computing the embeddings for a large number of data samples. In\nvision, Backward-compatible Training (BT) has been proposed to ensure that the\nnew model aligns with the old model's embeddings. This paper extends the\nconcept of vision-only BT to the field of cross-modal retrieval, marking the\nfirst attempt to address Cross-modal BT (XBT). Our goal is to achieve\nbackward-compatibility between Vision-Language Pretraining (VLP) models, such\nas CLIP, for the cross-modal retrieval task. To address XBT challenges, we\npropose an efficient solution: a projection module that maps the new model's\nembeddings to those of the old model. This module, pretrained solely with text\ndata, significantly reduces the number of image-text pairs required for XBT\nlearning, and, once it is pretrained, it avoids using the old model during\ntraining. Furthermore, we utilize parameter-efficient training strategies that\nimprove efficiency and preserve the off-the-shelf new model's knowledge by\navoiding any modifications. Experimental results on cross-modal retrieval\ndatasets demonstrate the effectiveness of XBT and its potential to enable\nbackfill-free upgrades when a new VLP model emerges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14715v1",
    "published_date": "2024-05-23 15:46:35 UTC",
    "updated_date": "2024-05-23 15:46:35 UTC"
  },
  {
    "arxiv_id": "2405.14713v1",
    "title": "Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces",
    "authors": [
      "Tommaso Calo",
      "Christopher J. MacLellan"
    ],
    "abstract": "Intelligent Tutoring Systems (ITSs) have shown great potential in delivering\npersonalized and adaptive education, but their widespread adoption has been\nhindered by the need for specialized programming and design skills. Existing\napproaches overcome the programming limitations with no-code authoring through\ndrag and drop, however they assume that educators possess the necessary skills\nto design effective and engaging tutor interfaces. To address this assumption\nwe introduce generative AI capabilities to assist educators in creating tutor\ninterfaces that meet their needs while adhering to design principles. Our\napproach leverages Large Language Models (LLMs) and prompt engineering to\ngenerate tutor layout and contents based on high-level requirements provided by\neducators as inputs. However, to allow them to actively participate in the\ndesign process, rather than relying entirely on AI-generated solutions, we\nallow generation both at the entire interface level and at the individual\ncomponent level. The former provides educators with a complete interface that\ncan be refined using direct manipulation, while the latter offers the ability\nto create specific elements to be added to the tutor interface. A small-scale\ncomparison shows the potential of our approach to enhance the efficiency of\ntutor interface design. Moving forward, we raise critical questions for\nassisting educators with generative AI capabilities to create personalized,\neffective, and engaging tutors, ultimately enhancing their adoption.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14713v1",
    "published_date": "2024-05-23 15:46:10 UTC",
    "updated_date": "2024-05-23 15:46:10 UTC"
  },
  {
    "arxiv_id": "2405.14712v2",
    "title": "Evolution and learning in differentiable robots",
    "authors": [
      "Luke Strgar",
      "David Matthews",
      "Tyler Hummer",
      "Sam Kriegman"
    ],
    "abstract": "The automatic design of robots has existed for 30 years but has been\nconstricted by serial non-differentiable design evaluations, premature\nconvergence to simple bodies or clumsy behaviors, and a lack of sim2real\ntransfer to physical machines. Thus, here we employ massively-parallel\ndifferentiable simulations to rapidly and simultaneously optimize individual\nneural control of behavior across a large population of candidate body plans\nand return a fitness score for each design based on the performance of its\nfully optimized behavior. Non-differentiable changes to the mechanical\nstructure of each robot in the population -- mutations that rearrange, combine,\nadd, or remove body parts -- were applied by a genetic algorithm in an outer\nloop of search, generating a continuous flow of novel morphologies with\nhighly-coordinated and graceful behaviors honed by gradient descent. This\nenabled the exploration of several orders-of-magnitude more designs than all\nprevious methods, despite the fact that robots here have the potential to be\nmuch more complex, in terms of number of independent motors, than those in\nprior studies. We found that evolution reliably produces ``increasingly\ndifferentiable'' robots: body plans that smooth the loss landscape in which\nlearning operates and thereby provide better training paths toward performant\nbehaviors. Finally, one of the highly differentiable morphologies discovered in\nsimulation was realized as a physical robot and shown to retain its optimized\nbehavior. This provides a cyberphysical platform to investigate the\nrelationship between evolution and learning in biological systems and broadens\nour understanding of how a robot's physical structure can influence the ability\nto train policies for it. Videos and code at\nhttps://sites.google.com/view/eldir.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14712v2",
    "published_date": "2024-05-23 15:45:43 UTC",
    "updated_date": "2024-05-26 17:24:12 UTC"
  },
  {
    "arxiv_id": "2405.14707v1",
    "title": "Artificial Intelligence (AI) in Legal Data Mining",
    "authors": [
      "Aniket Deroy",
      "Naksatra Kumar Bailung",
      "Kripabandhu Ghosh",
      "Saptarshi Ghosh",
      "Abhijnan Chakraborty"
    ],
    "abstract": "Despite the availability of vast amounts of data, legal data is often\nunstructured, making it difficult even for law practitioners to ingest and\ncomprehend the same. It is important to organise the legal information in a way\nthat is useful for practitioners and downstream automation tasks. The word\nontology was used by Greek philosophers to discuss concepts of existence,\nbeing, becoming and reality. Today, scientists use this term to describe the\nrelation between concepts, data, and entities. A great example for a working\nontology was developed by Dhani and Bhatt. This ontology deals with Indian\ncourt cases on intellectual property rights (IPR) The future of legal\nontologies is likely to be handled by computer experts and legal experts alike.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Book name-Technology and Analytics for Law and Justice, Page\n  no-273-297, Chapter no-14",
    "pdf_url": "http://arxiv.org/pdf/2405.14707v1",
    "published_date": "2024-05-23 15:41:35 UTC",
    "updated_date": "2024-05-23 15:41:35 UTC"
  },
  {
    "arxiv_id": "2405.14702v2",
    "title": "G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models",
    "authors": [
      "Pengyue Jia",
      "Yiding Liu",
      "Xiaopeng Li",
      "Yuhao Wang",
      "Yantong Du",
      "Xiao Han",
      "Xuetao Wei",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Xiangyu Zhao"
    ],
    "abstract": "Worldwide geolocalization aims to locate the precise location at the\ncoordinate level of photos taken anywhere on the Earth. It is very challenging\ndue to 1) the difficulty of capturing subtle location-aware visual semantics,\nand 2) the heterogeneous geographical distribution of image data. As a result,\nexisting studies have clear limitations when scaled to a worldwide context.\nThey may easily confuse distant images with similar visual contents, or cannot\nadapt to various locations worldwide with different amounts of relevant data.\nTo resolve these limitations, we propose G3, a novel framework based on\nRetrieval-Augmented Generation (RAG). In particular, G3 consists of three\nsteps, i.e., Geo-alignment, Geo-diversification, and Geo-verification to\noptimize both retrieval and generation phases of worldwide geolocalization.\nDuring Geo-alignment, our solution jointly learns expressive multi-modal\nrepresentations for images, GPS and textual descriptions, which allows us to\ncapture location-aware semantics for retrieving nearby images for a given\nquery. During Geo-diversification, we leverage a prompt ensembling method that\nis robust to inconsistent retrieval performance for different image queries.\nFinally, we combine both retrieved and generated GPS candidates in\nGeo-verification for location prediction. Experiments on two well-established\ndatasets IM2GPS3k and YFCC4k verify the superiority of G3 compared to other\nstate-of-the-art methods. Our code and data are available online for\nreproduction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14702v2",
    "published_date": "2024-05-23 15:37:06 UTC",
    "updated_date": "2024-10-31 09:08:48 UTC"
  },
  {
    "arxiv_id": "2405.14701v5",
    "title": "DreamText: High Fidelity Scene Text Synthesis",
    "authors": [
      "Yibin Wang",
      "Weizhong Zhang",
      "Honghui Xu",
      "Cheng Jin"
    ],
    "abstract": "Scene text synthesis involves rendering specified texts onto arbitrary\nimages. Current methods typically formulate this task in an end-to-end manner\nbut lack effective character-level guidance during training. Besides, their\ntext encoders, pre-trained on a single font type, struggle to adapt to the\ndiverse font styles encountered in practical applications. Consequently, these\nmethods suffer from character distortion, repetition, and absence, particularly\nin polystylistic scenarios. To this end, this paper proposes DreamText for\nhigh-fidelity scene text synthesis. Our key idea is to reconstruct the\ndiffusion training process, introducing more refined guidance tailored to this\ntask, to expose and rectify the model's attention at the character level and\nstrengthen its learning of text regions. This transformation poses a hybrid\noptimization challenge, involving both discrete and continuous variables. To\neffectively tackle this challenge, we employ a heuristic alternate optimization\nstrategy. Meanwhile, we jointly train the text encoder and generator to\ncomprehensively learn and utilize the diverse font present in the training\ndataset. This joint training is seamlessly integrated into the alternate\noptimization process, fostering a synergistic relationship between learning\ncharacter embedding and re-estimating character attention. Specifically, in\neach step, we first encode potential character-generated position information\nfrom cross-attention maps into latent character masks. These masks are then\nutilized to update the representation of specific characters in the current\nstep, which, in turn, enables the generator to correct the character's\nattention in the subsequent steps. Both qualitative and quantitative results\ndemonstrate the superiority of our method to the state of the art.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/CodeGoat24/DreamText, Project page:\n  https://codegoat24.github.io/DreamText/",
    "pdf_url": "http://arxiv.org/pdf/2405.14701v5",
    "published_date": "2024-05-23 15:35:48 UTC",
    "updated_date": "2025-03-24 06:13:16 UTC"
  },
  {
    "arxiv_id": "2405.14696v2",
    "title": "A Declarative System for Optimizing AI Workloads",
    "authors": [
      "Chunwei Liu",
      "Matthew Russo",
      "Michael Cafarella",
      "Lei Cao",
      "Peter Baille Chen",
      "Zui Chen",
      "Michael Franklin",
      "Tim Kraska",
      "Samuel Madden",
      "Gerardo Vitagliano"
    ],
    "abstract": "A long-standing goal of data management systems has been to build systems\nwhich can compute quantitative insights over large corpora of unstructured data\nin a cost-effective manner. Until recently, it was difficult and expensive to\nextract facts from company documents, data from scientific papers, or metrics\nfrom image and video corpora. Today's models can accomplish these tasks with\nhigh accuracy. However, a programmer who wants to answer a substantive\nAI-powered query must orchestrate large numbers of models, prompts, and data\noperations. For even a single query, the programmer has to make a vast number\nof decisions such as the choice of model, the right inference method, the most\ncost-effective inference hardware, the ideal prompt design, and so on. The\noptimal set of decisions can change as the query changes and as the\nrapidly-evolving technical landscape shifts. In this paper we present\nPalimpzest, a system that enables anyone to process AI-powered analytical\nqueries simply by defining them in a declarative language. The system uses its\ncost optimization framework to implement the query plan with the best\ntrade-offs between runtime, financial cost, and output data quality. We\ndescribe the workload of AI-powered analytics tasks, the optimization methods\nthat Palimpzest uses, and the prototype system itself. We evaluate Palimpzest\non tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching.\nWe show that even our simple prototype offers a range of appealing plans,\nincluding one that is 3.3x faster and 2.9x cheaper than the baseline method,\nwhile also offering better data quality. With parallelism enabled, Palimpzest\ncan produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a\nsingle-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the\nbaseline. These require no additional work by the user.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "H.2.3; I.2.5"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14696v2",
    "published_date": "2024-05-23 15:31:18 UTC",
    "updated_date": "2024-05-29 15:27:07 UTC"
  },
  {
    "arxiv_id": "2405.14691v1",
    "title": "CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System",
    "authors": [
      "Qinghua Guan",
      "Jinhui Ouyang",
      "Di Wu",
      "Weiren Yu"
    ],
    "abstract": "The spatiotemporal data generated by massive sensors in the Internet of\nThings (IoT) is extremely dynamic, heterogeneous, large scale and\ntime-dependent. It poses great challenges (e.g. accuracy, reliability, and\nstability) in real-time analysis and decision making for different IoT\napplications. The complexity of IoT data prevents the common people from\ngaining a deeper understanding of it. Agentized systems help address the lack\nof data insight for the common people. We propose a generic framework, namely\nCityGPT, to facilitate the learning and analysis of IoT time series with an\nend-to-end paradigm. CityGPT employs three agents to accomplish the\nspatiotemporal analysis of IoT data. The requirement agent facilitates user\ninputs based on natural language. Then, the analysis tasks are decomposed into\ntemporal and spatial analysis processes, completed by corresponding data\nanalysis agents (temporal and spatial agents). Finally, the spatiotemporal\nfusion agent visualizes the system's analysis results by receiving analysis\nresults from data analysis agents and invoking sub-visualization agents, and\ncan provide corresponding textual descriptions based on user demands. To\nincrease the insight for common people using our framework, we have agnentized\nthe framework, facilitated by a large language model (LLM), to increase the\ndata comprehensibility. Our evaluation results on real-world data with\ndifferent time dependencies show that the CityGPT framework can guarantee\nrobust performance in IoT computing.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14691v1",
    "published_date": "2024-05-23 15:27:18 UTC",
    "updated_date": "2024-05-23 15:27:18 UTC"
  },
  {
    "arxiv_id": "2405.14669v2",
    "title": "Efficiency for Free: Ideal Data Are Transportable Representations",
    "authors": [
      "Peng Sun",
      "Yi Jiang",
      "Tao Lin"
    ],
    "abstract": "Data, the seminal opportunity and challenge in modern machine learning,\ncurrently constrains the scalability of representation learning and impedes the\npace of model evolution. In this work, we investigate the efficiency properties\nof data from both optimization and generalization perspectives. Our theoretical\nand empirical analysis reveals an unexpected finding: for a given task,\nutilizing a publicly available, task- and architecture-agnostic model (referred\nto as the `prior model' in this paper) can effectively produce efficient data.\nBuilding on this insight, we propose the Representation Learning Accelerator\n(\\algopt), which promotes the formation and utilization of efficient data,\nthereby accelerating representation learning. Utilizing a ResNet-18 pre-trained\non CIFAR-10 as a prior model to inform ResNet-50 training on ImageNet-1K\nreduces computational costs by 50% while maintaining the same accuracy as the\nmodel trained with the original BYOL, which requires 100% cost. Our code is\navailable at: \\url{https://github.com/LINs-lab/ReLA}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code: https://github.com/LINs-lab/ReLA",
    "pdf_url": "http://arxiv.org/pdf/2405.14669v2",
    "published_date": "2024-05-23 15:06:02 UTC",
    "updated_date": "2024-11-01 09:56:53 UTC"
  },
  {
    "arxiv_id": "2405.14664v4",
    "title": "Fisher Flow Matching for Generative Modeling over Discrete Data",
    "authors": [
      "Oscar Davis",
      "Samuel Kessler",
      "Mircea Petrache",
      "İsmail İlkan Ceylan",
      "Michael Bronstein",
      "Avishek Joey Bose"
    ],
    "abstract": "Generative modeling over discrete data has recently seen numerous success\nstories, with applications spanning language modeling, biological sequence\ndesign, and graph-structured molecular data. The predominant generative\nmodeling paradigm for discrete data is still autoregressive, with more recent\nalternatives based on diffusion or flow-matching falling short of their\nimpressive performance in continuous data settings, such as image or video\ngeneration. In this work, we introduce Fisher-Flow, a novel flow-matching model\nfor discrete data. Fisher-Flow takes a manifestly geometric perspective by\nconsidering categorical distributions over discrete data as points residing on\na statistical manifold equipped with its natural Riemannian metric: the\n$\\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself\ncan be continuously reparameterised to points on the positive orthant of the\n$d$-hypersphere $\\mathbb{S}^d_+$, which allows us to define flows that map any\nsource distribution to target in a principled manner by transporting mass along\n(closed-form) geodesics of $\\mathbb{S}^d_+$. Furthermore, the learned flows in\nFisher-Flow can be further bootstrapped by leveraging Riemannian optimal\ntransport leading to improved training dynamics. We prove that the gradient\nflow induced by Fisher-Flow is optimal in reducing the forward KL divergence.\nWe evaluate Fisher-Flow on an array of synthetic and diverse real-world\nbenchmarks, including designing DNA Promoter, and DNA Enhancer sequences.\nEmpirically, we find that Fisher-Flow improves over prior diffusion and\nflow-matching models on these benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14664v4",
    "published_date": "2024-05-23 15:02:11 UTC",
    "updated_date": "2024-10-30 11:01:10 UTC"
  },
  {
    "arxiv_id": "2405.14660v2",
    "title": "Implicit In-context Learning",
    "authors": [
      "Zhuowei Li",
      "Zihao Xu",
      "Ligong Han",
      "Yunhe Gao",
      "Song Wen",
      "Di Liu",
      "Hao Wang",
      "Dimitris N. Metaxas"
    ],
    "abstract": "In-context Learning (ICL) empowers large language models (LLMs) to swiftly\nadapt to unseen tasks at inference-time by prefixing a few demonstration\nexamples before queries. Despite its versatility, ICL incurs substantial\ncomputational and memory overheads compared to zero-shot learning and is\nsensitive to the selection and order of demonstration examples. In this work,\nwe introduce Implicit In-context Learning (I2CL), an innovative paradigm that\nreduces the inference cost of ICL to that of zero-shot learning with minimal\ninformation loss. I2CL operates by first generating a condensed vector\nrepresentation, namely a context vector, extracted from the demonstration\nexamples. It then conducts an inference-time intervention through injecting a\nlinear combination of the context vector and query activations back into the\nmodel's residual streams. Empirical evaluation on nine real-world tasks across\nthree model architectures demonstrates that I2CL achieves few-shot level\nperformance at zero-shot inference cost, and it exhibits robustness against\nvariations in demonstration examples. Furthermore, I2CL facilitates a novel\nrepresentation of task-ids, enhancing task similarity detection and fostering\neffective transfer learning. We also perform a comprehensive analysis and\nablation study on I2CL, offering deeper insights into its internal mechanisms.\nCode is available at https://github.com/LzVv123456/I2CL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14660v2",
    "published_date": "2024-05-23 14:57:52 UTC",
    "updated_date": "2025-02-25 14:49:33 UTC"
  },
  {
    "arxiv_id": "2405.14654v1",
    "title": "Efficient Medical Question Answering with Knowledge-Augmented Question Generation",
    "authors": [
      "Julien Khlaut",
      "Corentin Dancette",
      "Elodie Ferreres",
      "Alaedine Bennani",
      "Paul Hérent",
      "Pierre Manceron"
    ],
    "abstract": "In the expanding field of language model applications, medical knowledge\nrepresentation remains a significant challenge due to the specialized nature of\nthe domain. Large language models, such as GPT-4, obtain reasonable scores on\nmedical question answering tasks, but smaller models are far behind. In this\nwork, we introduce a method to improve the proficiency of a small language\nmodel in the medical domain by employing a two-fold approach. We first\nfine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to\ngenerate questions similar to the downstream task, prompted with textbook\nknowledge, and use them to fine-tune the model. Additionally, we introduce\nECN-QA, a novel medical question answering dataset containing ``progressive\nquestions'' composed of related sequential questions. We show the benefits of\nour training strategy on this dataset. The study's findings highlight the\npotential of small language models in the medical domain when appropriately\nfine-tuned. The code and weights are available at\nhttps://github.com/raidium-med/MQG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the Clinical Natural Language Processing Workshop, NAACL\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14654v1",
    "published_date": "2024-05-23 14:53:52 UTC",
    "updated_date": "2024-05-23 14:53:52 UTC"
  },
  {
    "arxiv_id": "2405.14632v2",
    "title": "DLPO: Diffusion Model Loss-Guided Reinforcement Learning for Fine-Tuning Text-to-Speech Diffusion Models",
    "authors": [
      "Jingyi Chen",
      "Ju-Seung Byun",
      "Micha Elsner",
      "Andrew Perrault"
    ],
    "abstract": "Recent advancements in generative models have sparked a significant interest\nwithin the machine learning community. Particularly, diffusion models have\ndemonstrated remarkable capabilities in synthesizing images and speech. Studies\nsuch as those by Lee et al. (2023), Black et al. (2023), Wang et al. (2023),\nand Fan et al. (2024) illustrate that Reinforcement Learning with Human\nFeedback (RLHF) can enhance diffusion models for image synthesis. However, due\nto architectural differences between these models and those employed in speech\nsynthesis, it remains uncertain whether RLHF could similarly benefit speech\nsynthesis models. In this paper, we explore the practical application of RLHF\nto diffusion-based text-to-speech synthesis, leveraging the mean opinion score\n(MOS) as predicted by UTokyo-SaruLab MOS prediction system (Saeki et al., 2022)\nas a proxy loss. We introduce diffusion model loss-guided RL policy\noptimization (DLPO) and compare it against other RLHF approaches, employing the\nNISQA speech quality and naturalness assessment model (Mittag et al., 2021) and\nhuman preference experiments for further evaluation. Our results show that RLHF\ncan enhance diffusion-based text-to-speech synthesis models, and, moreover,\nDLPO can better improve diffusion models in generating natural and high quality\nspeech audios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14632v2",
    "published_date": "2024-05-23 14:39:35 UTC",
    "updated_date": "2024-11-15 20:10:29 UTC"
  },
  {
    "arxiv_id": "2405.14629v2",
    "title": "Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences",
    "authors": [
      "Takuya Hiraoka",
      "Guanquan Wang",
      "Takashi Onishi",
      "Yoshimasa Tsuruoka"
    ],
    "abstract": "In reinforcement learning (RL) with experience replay, experiences stored in\na replay buffer influence the RL agent's performance. Information about how\nthese experiences influence the agent's performance is valuable for various\npurposes, such as identifying experiences that negatively influence\nunderperforming agents. One method for estimating the influence of experiences\nis the leave-one-out (LOO) method. However, this method is usually\ncomputationally prohibitive. In this paper, we present Policy Iteration with\nTurn-over Dropout (PIToD), which efficiently estimates the influence of\nexperiences. We evaluate how accurately PIToD estimates the influence of\nexperiences and its efficiency compared to LOO. We then apply PIToD to amend\nunderperforming RL agents, i.e., we use PIToD to estimate negatively\ninfluential experiences for the RL agents and to delete the influence of these\nexperiences. We show that RL agents' performance is significantly improved via\namendments with PIToD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Source code:\n  https://github.com/TakuyaHiraoka/Which-Experiences-Are-Influential-for-RL-Agents",
    "pdf_url": "http://arxiv.org/pdf/2405.14629v2",
    "published_date": "2024-05-23 14:35:56 UTC",
    "updated_date": "2024-10-04 12:47:03 UTC"
  },
  {
    "arxiv_id": "2405.14619v3",
    "title": "exLong: Generating Exceptional Behavior Tests with Large Language Models",
    "authors": [
      "Jiyang Zhang",
      "Yu Liu",
      "Pengyu Nie",
      "Junyi Jessy Li",
      "Milos Gligoric"
    ],
    "abstract": "Many popular programming languages, including C#, Java, and Python, support\nexceptions. Exceptions are thrown during program execution if an unwanted event\nhappens, e.g., a method is invoked with an illegal argument value. Software\ndevelopers write exceptional behavior tests (EBTs) to check that their code\ndetects unwanted events and throws appropriate exceptions. Prior research\nstudies have shown the importance of EBTs, but those studies also highlighted\nthat developers put most of their efforts on \"happy paths\", e.g., paths without\nunwanted events. To help developers fill the gap, we present the first\nframework, dubbed exLong, that automatically generates EBTs. exLong is a large\nlanguage model instruction fine-tuned from CodeLlama and embeds reasoning about\ntraces that lead to throw statements, conditional expressions that guard throw\nstatements, and non-exceptional behavior tests that execute similar traces. We\ncompare exLong with the state-of-the-art models for test generation (CAT-LM)\nand one of the strongest foundation models (GPT-4o), as well as with\nanalysis-based tools for test generation (Randoop and EvoSuite). Our results\nshow that exLong outperforms existing models and tools. Furthermore, we\ncontributed several pull requests to open-source projects and 23 EBTs generated\nby exLong were already accepted.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "ICSE 2025 (camera ready)",
    "pdf_url": "http://arxiv.org/pdf/2405.14619v3",
    "published_date": "2024-05-23 14:28:41 UTC",
    "updated_date": "2024-12-24 21:07:48 UTC"
  },
  {
    "arxiv_id": "2405.14616v1",
    "title": "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting",
    "authors": [
      "Shiyu Wang",
      "Haixu Wu",
      "Xiaoming Shi",
      "Tengge Hu",
      "Huakun Luo",
      "Lintao Ma",
      "James Y. Zhang",
      "Jun Zhou"
    ],
    "abstract": "Time series forecasting is widely used in extensive applications, such as\ntraffic planning and weather forecasting. However, real-world time series\nusually present intricate temporal variations, making forecasting extremely\nchallenging. Going beyond the mainstream paradigms of plain decomposition and\nmultiperiodicity analysis, we analyze temporal variations in a novel view of\nmultiscale-mixing, which is based on an intuitive but important observation\nthat time series present distinct patterns in different sampling scales. The\nmicroscopic and the macroscopic information are reflected in fine and coarse\nscales respectively, and thereby complex variations can be inherently\ndisentangled. Based on this observation, we propose TimeMixer as a fully\nMLP-based architecture with Past-Decomposable-Mixing (PDM) and\nFuture-Multipredictor-Mixing (FMM) blocks to take full advantage of\ndisentangled multiscale series in both past extraction and future prediction\nphases. Concretely, PDM applies the decomposition to multiscale series and\nfurther mixes the decomposed seasonal and trend components in fine-to-coarse\nand coarse-to-fine directions separately, which successively aggregates the\nmicroscopic seasonal and macroscopic trend information. FMM further ensembles\nmultiple predictors to utilize complementary forecasting capabilities in\nmultiscale observations. Consequently, TimeMixer is able to achieve consistent\nstate-of-the-art performances in both long-term and short-term forecasting\ntasks with favorable run-time efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14616v1",
    "published_date": "2024-05-23 14:27:07 UTC",
    "updated_date": "2024-05-23 14:27:07 UTC"
  },
  {
    "arxiv_id": "2405.14612v2",
    "title": "Explaining Multi-modal Large Language Models by Analyzing their Vision Perception",
    "authors": [
      "Loris Giulivi",
      "Giacomo Boracchi"
    ],
    "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in understanding and generating content across various modalities,\nsuch as images and text. However, their interpretability remains a challenge,\nhindering their adoption in critical applications. This research proposes a\nnovel approach to enhance the interpretability of MLLMs by focusing on the\nimage embedding component. We combine an open-world localization model with a\nMLLM, thus creating a new architecture able to simultaneously produce text and\nobject localization outputs from the same vision embedding. The proposed\narchitecture greatly promotes interpretability, enabling us to design a novel\nsaliency map to explain any output token, to identify model hallucinations, and\nto assess model biases through semantic adversarial perturbations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted at BMVC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14612v2",
    "published_date": "2024-05-23 14:24:23 UTC",
    "updated_date": "2024-05-28 11:18:20 UTC"
  },
  {
    "arxiv_id": "2405.14608v1",
    "title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification",
    "authors": [
      "Xuan-May Le",
      "Ling Luo",
      "Uwe Aickelin",
      "Minh-Tuan Tran"
    ],
    "abstract": "Multivariate time series classification (MTSC) has attracted significant\nresearch attention due to its diverse real-world applications. Recently,\nexploiting transformers for MTSC has achieved state-of-the-art performance.\nHowever, existing methods focus on generic features, providing a comprehensive\nunderstanding of data, but they ignore class-specific features crucial for\nlearning the representative characteristics of each class. This leads to poor\nperformance in the case of imbalanced datasets or datasets with similar overall\npatterns but differing in minor class-specific details. In this paper, we\npropose a novel Shapelet Transformer (ShapeFormer), which comprises\nclass-specific and generic transformer modules to capture both of these\nfeatures. In the class-specific module, we introduce the discovery method to\nextract the discriminative subsequences of each class (i.e. shapelets) from the\ntraining set. We then propose a Shapelet Filter to learn the difference\nfeatures between these shapelets and the input time series. We found that the\ndifference feature for each shapelet contains important class-specific\nfeatures, as it shows a significant distinction between its class and others.\nIn the generic module, convolution filters are used to extract generic features\nthat contain information to distinguish among all classes. For each module, we\nemploy the transformer encoder to capture the correlation between their\nfeatures. As a result, the combination of two transformer modules allows our\nmodel to exploit the power of both types of features, thereby enhancing the\nclassification performance. Our experiments on 30 UEA MTSC datasets demonstrate\nthat ShapeFormer has achieved the highest accuracy ranking compared to\nstate-of-the-art methods. The code is available at\nhttps://github.com/xuanmay2701/shapeformer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14608v1",
    "published_date": "2024-05-23 14:21:35 UTC",
    "updated_date": "2024-05-23 14:21:35 UTC"
  },
  {
    "arxiv_id": "2405.14606v4",
    "title": "Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats",
    "authors": [
      "Veeti Ahvonen",
      "Damian Heiman",
      "Antti Kuusisto",
      "Carsten Lutz"
    ],
    "abstract": "In pioneering work from 2019, Barcel\\'o and coauthors identified logics that\nprecisely match the expressive power of constant iteration-depth graph neural\nnetworks (GNNs) relative to properties definable in first-order logic. In this\narticle, we give exact logical characterizations of recurrent GNNs in two\nscenarios: (1) in the setting with floating-point numbers and (2) with reals.\nFor floats, the formalism matching recurrent GNNs is a rule-based modal logic\nwith counting, while for reals we use a suitable infinitary modal logic, also\nwith counting. These results give exact matches between logics and GNNs in the\nrecurrent setting without relativising to a background logic in either case,\nbut using some natural assumptions about floating-point arithmetic. Applying\nour characterizations, we also prove that, relative to graph properties\ndefinable in monadic second-order logic (MSO), our infinitary and rule-based\nlogics are equally expressive. This implies that recurrent GNNs with reals and\nfloats have the same expressive power over MSO-definable properties and shows\nthat, for such properties, also recurrent GNNs with reals are characterized by\na (finitary!) rule-based modal logic. In the general case, in contrast, the\nexpressive power with floats is weaker than with reals. In addition to\nlogic-oriented results, we also characterize recurrent GNNs, with both reals\nand floats, via distributed automata, drawing links to distributed computing\nmodels.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4.1; F.1.1; I.2.0"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14606v4",
    "published_date": "2024-05-23 14:19:21 UTC",
    "updated_date": "2025-05-02 10:39:23 UTC"
  },
  {
    "arxiv_id": "2405.14601v1",
    "title": "A FAIR and Free Prompt-based Research Assistant",
    "authors": [
      "Mahsa Shamsabadi",
      "Jennifer D'Souza"
    ],
    "abstract": "This demo will present the Research Assistant (RA) tool developed to assist\nwith six main types of research tasks defined as standardized instruction\ntemplates, instantiated with user input, applied finally as prompts to\nwell-known--for their sophisticated natural language processing abilities--AI\ntools, such as ChatGPT (https://chat.openai.com/) and Gemini\n(https://gemini.google.com/app). The six research tasks addressed by RA are:\ncreating FAIR research comparisons, ideating research topics, drafting grant\napplications, writing scientific blogs, aiding preliminary peer reviews, and\nformulating enhanced literature search queries. RA's reliance on generative AI\ntools like ChatGPT or Gemini means the same research task assistance can be\noffered in any scientific discipline. We demonstrate its versatility by sharing\nRA outputs in Computer Science, Virology, and Climate Science, where the output\nwith the RA tool assistance mirrored that from a domain expert who performed\nthe same research task.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures, accepted to the Demo track of NLDB 2024\n  (https://nldb2024.di.unito.it/)",
    "pdf_url": "http://arxiv.org/pdf/2405.14601v1",
    "published_date": "2024-05-23 14:16:46 UTC",
    "updated_date": "2024-05-23 14:16:46 UTC"
  },
  {
    "arxiv_id": "2405.14600v1",
    "title": "Discretization of continuous input spaces in the hippocampal autoencoder",
    "authors": [
      "Adrian F. Amil",
      "Ismael T. Freire",
      "Paul F. M. J. Verschure"
    ],
    "abstract": "The hippocampus has been associated with both spatial cognition and episodic\nmemory formation, but integrating these functions into a unified framework\nremains challenging. Here, we demonstrate that forming discrete memories of\nvisual events in sparse autoencoder neurons can produce spatial tuning similar\nto hippocampal place cells. We then show that the resulting very\nhigh-dimensional code enables neurons to discretize and tile the underlying\nimage space with minimal overlap. Additionally, we extend our results to the\nauditory domain, showing that neurons similarly tile the frequency space in an\nexperience-dependent manner. Lastly, we show that reinforcement learning agents\ncan effectively perform various visuo-spatial cognitive tasks using these\nsparse, very high-dimensional representations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14600v1",
    "published_date": "2024-05-23 14:16:44 UTC",
    "updated_date": "2024-05-23 14:16:44 UTC"
  },
  {
    "arxiv_id": "2405.14597v2",
    "title": "Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs",
    "authors": [
      "Qingyuan Li",
      "Ran Meng",
      "Yiduo Li",
      "Bo Zhang",
      "Yifan Lu",
      "Yerui Sun",
      "Lin Ma",
      "Yuchen Xie"
    ],
    "abstract": "We introduce Integer Scale, a novel post-training quantization scheme for\nlarge language models that effectively resolves the inference bottleneck in\ncurrent fine-grained quantization approaches while maintaining similar\naccuracies. Integer Scale is a free lunch as it requires no extra calibration\nor fine-tuning which will otherwise incur additional costs. It can be used\nplug-and-play for most fine-grained quantization methods. Its integration\nresults in at most 1.85x end-to-end speed boost over the original counterpart\nwith comparable accuracy. Additionally, due to the orchestration of the\nproposed Integer Scale and fine-grained quantization, we resolved the\nquantization difficulty for Mixtral-8x7B and LLaMA-3 models with negligible\nperformance degradation, and it comes with an end-to-end speed boost of 2.13x,\nand 2.31x compared with their FP16 versions respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14597v2",
    "published_date": "2024-05-23 14:12:58 UTC",
    "updated_date": "2024-05-28 07:17:47 UTC"
  },
  {
    "arxiv_id": "2405.15821v1",
    "title": "Reinforcing Language Agents via Policy Optimization with Action Decomposition",
    "authors": [
      "Muning Wen",
      "Ziyu Wan",
      "Weinan Zhang",
      "Jun Wang",
      "Ying Wen"
    ],
    "abstract": "Language models as intelligent agents push the boundaries of sequential\ndecision-making agents but struggle with limited knowledge of environmental\ndynamics and exponentially huge action space. Recent efforts like GLAM and\nTWOSOME manually constrain the action space to a restricted subset and employ\nreinforcement learning to align agents' knowledge with specific environments.\nHowever, they overlook fine-grained credit assignments for intra-action tokens,\nwhich is essential for efficient language agent optimization, and rely on\nhuman's prior knowledge to restrict action space. This paper proposes\ndecomposing language agent optimization from the action level to the token\nlevel, offering finer supervision for each intra-action token and manageable\noptimization complexity in environments with unrestricted action spaces.\nBeginning with the simplification of flattening all actions, we theoretically\nexplore the discrepancies between action-level optimization and this naive\ntoken-level optimization. We then derive the Bellman backup with Action\nDecomposition (BAD) to integrate credit assignments for both intra-action and\ninter-action tokens, effectively eliminating the discrepancies. Implementing\nBAD within the PPO algorithm, we introduce Policy Optimization with Action\nDecomposition (POAD). POAD benefits from a finer-grained credit assignment\nprocess and lower optimization complexity, leading to enhanced learning\nefficiency and generalization abilities in aligning language agents with\ninteractive environments. We validate POAD across diverse testbeds, with\nresults affirming the advantages of our approach and the correctness of our\ntheoretical analysis.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages with 9 pages are main context",
    "pdf_url": "http://arxiv.org/pdf/2405.15821v1",
    "published_date": "2024-05-23 14:01:44 UTC",
    "updated_date": "2024-05-23 14:01:44 UTC"
  },
  {
    "arxiv_id": "2405.19354v1",
    "title": "Rotations of Gödel algebras with modal operators",
    "authors": [
      "Tommaso Flaminio",
      "Lluis Godo",
      "Paula Menchón",
      "Ricardo O. Rodriguez"
    ],
    "abstract": "The present paper is devoted to study the effect of connected and\ndisconnected rotations of G\\\"odel algebras with operators grounded on directly\nindecomposable structures. The structures resulting from this construction we\nwill present are nilpotent minimum (with or without negation fixpoint,\ndepending on whether the rotation is connected or disconnected) with special\nmodal operators defined on a directly indecomposable algebra. In this paper we\nwill present a (quasi-)equational definition of these latter structures. Our\nmain results show that directly indecomposable nilpotent minimum algebras (with\nor without negation fixpoint) with modal operators are fully characterized as\nconnected and disconnected rotations of directly indecomposable G\\\"odel\nalgebras endowed with modal operators.",
    "categories": [
      "math.GM",
      "cs.AI",
      "cs.LO",
      "03B50, 03B45"
    ],
    "primary_category": "math.GM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19354v1",
    "published_date": "2024-05-23 13:59:06 UTC",
    "updated_date": "2024-05-23 13:59:06 UTC"
  },
  {
    "arxiv_id": "2405.14582v3",
    "title": "PoseCrafter: One-Shot Personalized Video Synthesis Following Flexible Pose Control",
    "authors": [
      "Yong Zhong",
      "Min Zhao",
      "Zebin You",
      "Xiaofeng Yu",
      "Changwang Zhang",
      "Chongxuan Li"
    ],
    "abstract": "In this paper, we introduce PoseCrafter, a one-shot method for personalized\nvideo generation following the control of flexible poses. Built upon Stable\nDiffusion and ControlNet, we carefully design an inference process to produce\nhigh-quality videos without the corresponding ground-truth frames. First, we\nselect an appropriate reference frame from the training video and invert it to\ninitialize all latent variables for generation. Then, we insert the\ncorresponding training pose into the target pose sequences to enhance\nfaithfulness through a trained temporal attention module. Furthermore, to\nalleviate the face and hand degradation resulting from discrepancies between\nposes of training videos and inference poses, we implement simple latent\nediting through an affine transformation matrix involving facial and hand\nlandmarks. Extensive experiments on several datasets demonstrate that\nPoseCrafter achieves superior results to baselines pre-trained on a vast\ncollection of videos under 8 commonly used metrics. Besides, PoseCrafter can\nfollow poses from different individuals or artificial edits and simultaneously\nretain the human identity in an open-domain training video. Our project page is\navailable at https://ml-gsai.github.io/PoseCrafter-demo/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14582v3",
    "published_date": "2024-05-23 13:53:50 UTC",
    "updated_date": "2024-07-18 08:50:45 UTC"
  },
  {
    "arxiv_id": "2405.14573v5",
    "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents",
    "authors": [
      "Christopher Rawles",
      "Sarah Clinckemaillie",
      "Yifan Chang",
      "Jonathan Waltz",
      "Gabrielle Lau",
      "Marybeth Fair",
      "Alice Li",
      "William Bishop",
      "Wei Li",
      "Folawiyo Campbell-Ajala",
      "Daniel Toyama",
      "Robert Berry",
      "Divya Tyamagundlu",
      "Timothy Lillicrap",
      "Oriana Riva"
    ],
    "abstract": "Autonomous agents that execute human tasks by controlling computers can\nenhance human productivity and application accessibility. However, progress in\nthis field will be driven by realistic and reproducible benchmarks. We present\nAndroidWorld, a fully functional Android environment that provides reward\nsignals for 116 programmatic tasks across 20 real-world Android apps. Unlike\nexisting interactive environments, which provide a static test set,\nAndroidWorld dynamically constructs tasks that are parameterized and expressed\nin natural language in unlimited ways, thus enabling testing on a much larger\nand more realistic suite of tasks. To ensure reproducibility, each task\nincludes dedicated initialization, success-checking, and tear-down logic, which\nmodifies and inspects the device's system state. We experiment with baseline\nagents to test AndroidWorld and provide initial results on the benchmark. Our\nbest agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for\nfuture work. Furthermore, we adapt a popular desktop web agent to work on\nAndroid, which we find to be less effective on mobile, suggesting future\nresearch is needed to achieve universal, cross-platform agents. Finally, we\nalso conduct a robustness analysis, showing that task variations can\nsignificantly affect agent performance, demonstrating that without such\ntesting, agent performance metrics may not fully reflect practical challenges.\nAndroidWorld and the experiments in this paper are available at\ngithub.com/google-research/android_world.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14573v5",
    "published_date": "2024-05-23 13:48:54 UTC",
    "updated_date": "2025-04-06 20:37:50 UTC"
  },
  {
    "arxiv_id": "2405.14569v3",
    "title": "PrivCirNet: Efficient Private Inference via Block Circulant Transformation",
    "authors": [
      "Tianshi Xu",
      "Lemeng Wu",
      "Runsheng Wang",
      "Meng Li"
    ],
    "abstract": "Homomorphic encryption (HE)-based deep neural network (DNN) inference\nprotects data and model privacy but suffers from significant computation\noverhead. We observe transforming the DNN weights into circulant matrices\nconverts general matrix-vector multiplications into HE-friendly 1-dimensional\nconvolutions, drastically reducing the HE computation cost. Hence, in this\npaper, we propose \\method, a protocol/network co-optimization framework based\non block circulant transformation. At the protocol level, PrivCirNet customizes\nthe HE encoding algorithm that is fully compatible with the block circulant\ntransformation and reduces the computation latency in proportion to the block\nsize. At the network level, we propose a latency-aware formulation to search\nfor the layer-wise block size assignment based on second-order information.\nPrivCirNet also leverages layer fusion to further reduce the inference cost. We\ncompare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S\\&P\n2024) and the HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and\nVision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by\n$5.0\\times$ and $1.3\\times$ with iso-accuracy over Bolt, respectively, and\nimproves accuracy by $4.1\\%$ and $12\\%$ over SpENCNN, respectively. For\nMobileNetV2 on ImageNet, PrivCirNet achieves $1.7\\times$ lower latency and\n$4.2\\%$ better accuracy over Bolt and SpENCNN, respectively. Our code and\ncheckpoints are available on Git Hub.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "NeurIPS'2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14569v3",
    "published_date": "2024-05-23 13:44:48 UTC",
    "updated_date": "2024-10-29 02:20:24 UTC"
  },
  {
    "arxiv_id": "2405.14563v1",
    "title": "Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet",
    "authors": [
      "Loris Giulivi",
      "Giacomo Boracchi"
    ],
    "abstract": "Advances in multi-modal embeddings, and in particular CLIP, have recently\ndriven several breakthroughs in Computer Vision (CV). CLIP has shown impressive\nperformance on a variety of tasks, yet, its inherently opaque architecture may\nhinder the application of models employing CLIP as backbone, especially in\nfields where trust and model explainability are imperative, such as in the\nmedical domain. Current explanation methodologies for CV models rely on\nSaliency Maps computed through gradient analysis or input perturbation.\nHowever, these Saliency Maps can only be computed to explain classes relevant\nto the end task, often smaller in scope than the backbone training classes. In\nthe context of models implementing CLIP as their vision backbone, a substantial\nportion of the information embedded within the learned representations is thus\nleft unexplained.\n  In this work, we propose Concept Visualization (ConVis), a novel saliency\nmethodology that explains the CLIP embedding of an image by exploiting the\nmulti-modal nature of the embeddings. ConVis makes use of lexical information\nfrom WordNet to compute task-agnostic Saliency Maps for any concept, not\nlimited to concepts the end model was trained on. We validate our use of\nWordNet via an out of distribution detection experiment, and test ConVis on an\nobject localization benchmark, showing that Concept Visualizations correctly\nidentify and localize the image's semantic content. Additionally, we perform a\nuser study demonstrating that our methodology can give users insight on the\nmodel's functioning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at IJCNN 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14563v1",
    "published_date": "2024-05-23 13:41:17 UTC",
    "updated_date": "2024-05-23 13:41:17 UTC"
  },
  {
    "arxiv_id": "2405.14555v4",
    "title": "Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models",
    "authors": [
      "Abhishek Kumar",
      "Sarfaroz Yunusov",
      "Ali Emami"
    ],
    "abstract": "Research on Large Language Models (LLMs) has often neglected subtle biases\nthat, although less apparent, can significantly influence the models' outputs\ntoward particular social narratives. This study addresses two such biases\nwithin LLMs: representative bias, which denotes a tendency of LLMs to generate\noutputs that mirror the experiences of certain identity groups, and affinity\nbias, reflecting the models' evaluative preferences for specific narratives or\nviewpoints. We introduce two novel metrics to measure these biases: the\nRepresentative Bias Score (RBS) and the Affinity Bias Score (ABS), and present\nthe Creativity-Oriented Generation Suite (CoGS), a collection of open-ended\ntasks such as short story writing and poetry composition, designed with\ncustomized rubrics to detect these subtle biases. Our analysis uncovers marked\nrepresentative biases in prominent LLMs, with a preference for identities\nassociated with being white, straight, and men. Furthermore, our investigation\nof affinity bias reveals distinctive evaluative patterns within each model,\nakin to `bias fingerprints'. This trend is also seen in human evaluators,\nhighlighting a complex interplay between human and machine bias perceptions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.14555v4",
    "published_date": "2024-05-23 13:35:34 UTC",
    "updated_date": "2024-06-03 16:43:16 UTC"
  },
  {
    "arxiv_id": "2405.14554v2",
    "title": "SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge",
    "authors": [
      "Chuanhao Li",
      "Zhen Li",
      "Chenchen Jing",
      "Shuo Liu",
      "Wenqi Shao",
      "Yuwei Wu",
      "Ping Luo",
      "Yu Qiao",
      "Kaipeng Zhang"
    ],
    "abstract": "Large vision-language models (LVLMs) are ignorant of the up-to-date\nknowledge, such as LLaVA series, because they cannot be updated frequently due\nto the large amount of resources required, and therefore fail in many cases.\nFor example, if a LVLM was released on January 2024, and it wouldn't know the\nsinger of the theme song for the new Detective Conan movie, which wasn't\nreleased until April 2024. To solve the problem, a promising solution motivated\nby retrieval-augmented generation (RAG) is to provide LVLMs with up-to-date\nknowledge via internet search during inference, i.e., internet-augmented\ngeneration (IAG), which is already integrated in some closed-source commercial\nLVLMs such as GPT-4V. However, the specific mechanics underpinning them remain\na mystery. In this paper, we propose a plug-and-play framework, for augmenting\nexisting LVLMs in handling visual question answering (VQA) about up-to-date\nknowledge, dubbed SearchLVLMs. A hierarchical filtering model is trained to\neffectively and efficiently find the most helpful content from the websites\nreturned by a search engine to prompt LVLMs with up-to-date knowledge. To train\nthe model and evaluate our framework's performance, we propose a pipeline to\nautomatically generate news-related VQA samples to construct a dataset, dubbed\nUDK-VQA. A multi-model voting mechanism is introduced to label the usefulness\nof website/content for VQA samples to construct the training set. Experimental\nresults demonstrate the effectiveness of our framework, outperforming GPT-4V by\nabout 25% in accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 6 figures, a plug-and-play framework to augment large\n  vision-language models with up-to-date internet knowledge",
    "pdf_url": "http://arxiv.org/pdf/2405.14554v2",
    "published_date": "2024-05-23 13:32:07 UTC",
    "updated_date": "2024-08-20 09:04:25 UTC"
  },
  {
    "arxiv_id": "2405.14547v2",
    "title": "Causal Effect Identification in a Sub-Population with Latent Variables",
    "authors": [
      "Amir Mohammad Abouei",
      "Ehsan Mokhtarian",
      "Negar Kiyavash",
      "Matthias Grossglauser"
    ],
    "abstract": "The s-ID problem seeks to compute a causal effect in a specific\nsub-population from the observational data pertaining to the same sub\npopulation (Abouei et al., 2023). This problem has been addressed when all the\nvariables in the system are observable. In this paper, we consider an extension\nof the s-ID problem that allows for the presence of latent variables. To tackle\nthe challenges induced by the presence of latent variables in a sub-population,\nwe first extend the classical relevant graphical definitions, such as\nc-components and Hedges, initially defined for the so-called ID problem (Pearl,\n1995; Tian & Pearl, 2002), to their new counterparts. Subsequently, we propose\na sound algorithm for the s-ID problem with latent variables.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14547v2",
    "published_date": "2024-05-23 13:25:41 UTC",
    "updated_date": "2024-10-29 11:15:37 UTC"
  },
  {
    "arxiv_id": "2405.14536v1",
    "title": "Regressor-free Molecule Generation to Support Drug Response Prediction",
    "authors": [
      "Kun Li",
      "Xiuwen Gong",
      "Shirui Pan",
      "Jia Wu",
      "Bo Du",
      "Wenbin Hu"
    ],
    "abstract": "Drug response prediction (DRP) is a crucial phase in drug discovery, and the\nmost important metric for its evaluation is the IC50 score. DRP results are\nheavily dependent on the quality of the generated molecules. Existing molecule\ngeneration methods typically employ classifier-based guidance, enabling\nsampling within the IC50 classification range. However, these methods fail to\nensure the sampling space range's effectiveness, generating numerous\nineffective molecules. Through experimental and theoretical study, we\nhypothesize that conditional generation based on the target IC50 score can\nobtain a more effective sampling space. As a result, we introduce\nregressor-free guidance molecule generation to ensure sampling within a more\neffective space and support DRP. Regressor-free guidance combines a diffusion\nmodel's score estimation with a regression controller model's gradient based on\nnumber labels. To effectively map regression labels between drugs and cell\nlines, we design a common-sense numerical knowledge graph that constrains the\norder of text representations. Experimental results on the real-world dataset\nfor the DRP task demonstrate our method's effectiveness in drug discovery. The\ncode is available at:https://anonymous.4open.science/r/RMCD-DBD1.",
    "categories": [
      "q-bio.MN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.MN",
    "comment": "22 pages, 7 figures, 9 tables,",
    "pdf_url": "http://arxiv.org/pdf/2405.14536v1",
    "published_date": "2024-05-23 13:22:17 UTC",
    "updated_date": "2024-05-23 13:22:17 UTC"
  },
  {
    "arxiv_id": "2405.14535v1",
    "title": "Exploring Alignment in Shared Cross-lingual Spaces",
    "authors": [
      "Basel Mousi",
      "Nadir Durrani",
      "Fahim Dalvi",
      "Majd Hawasly",
      "Ahmed Abdelali"
    ],
    "abstract": "Despite their remarkable ability to capture linguistic nuances across diverse\nlanguages, questions persist regarding the degree of alignment between\nlanguages in multilingual embeddings. Drawing inspiration from research on\nhigh-dimensional representations in neural language models, we employ\nclustering to uncover latent concepts within multilingual models. Our analysis\nfocuses on quantifying the \\textit{alignment} and \\textit{overlap} of these\nconcepts across various languages within the latent space. To this end, we\nintroduce two metrics \\CA{} and \\CO{} aimed at quantifying these aspects,\nenabling a deeper exploration of multilingual embeddings. Our study encompasses\nthree multilingual models (\\texttt{mT5}, \\texttt{mBERT}, and \\texttt{XLM-R})\nand three downstream tasks (Machine Translation, Named Entity Recognition, and\nSentiment Analysis). Key findings from our analysis include: i) deeper layers\nin the network demonstrate increased cross-lingual \\textit{alignment} due to\nthe presence of language-agnostic concepts, ii) fine-tuning of the models\nenhances \\textit{alignment} within the latent space, and iii) such\ntask-specific calibration helps in explaining the emergence of zero-shot\ncapabilities in the models.\\footnote{The code is available at\n\\url{https://github.com/baselmousi/multilingual-latent-concepts}}",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14535v1",
    "published_date": "2024-05-23 13:20:24 UTC",
    "updated_date": "2024-05-23 13:20:24 UTC"
  },
  {
    "arxiv_id": "2405.14527v2",
    "title": "ArchesWeather: An efficient AI weather forecasting model at 1.5° resolution",
    "authors": [
      "Guillaume Couairon",
      "Christian Lessig",
      "Anastase Charantonis",
      "Claire Monteleoni"
    ],
    "abstract": "One of the guiding principles for designing AI-based weather forecasting\nsystems is to embed physical constraints as inductive priors in the neural\nnetwork architecture. A popular prior is locality, where the atmospheric data\nis processed with local neural interactions, like 3D convolutions or 3D local\nattention windows as in Pangu-Weather. On the other hand, some works have shown\ngreat success in weather forecasting without this locality principle, at the\ncost of a much higher parameter count. In this paper, we show that the 3D local\nprocessing in Pangu-Weather is computationally sub-optimal. We design\nArchesWeather, a transformer model that combines 2D attention with a\ncolumn-wise attention-based feature interaction module, and demonstrate that\nthis design improves forecasting skill.\n  ArchesWeather is trained at 1.5{\\deg} resolution and 24h lead time, with a\ntraining budget of a few GPU-days and a lower inference cost than competing\nmethods. An ensemble of four of our models shows better RMSE scores than the\nIFS HRES and is competitive with the 1.4{\\deg} 50-members NeuralGCM ensemble\nfor one to three days ahead forecasting. Our code and models are publicly\navailable at https://github.com/gcouairon/ArchesWeather.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the Machine Learning for Earth System Modeling Workshop\n  at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14527v2",
    "published_date": "2024-05-23 13:11:49 UTC",
    "updated_date": "2024-07-03 12:39:58 UTC"
  },
  {
    "arxiv_id": "2405.14522v1",
    "title": "Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property",
    "authors": [
      "Yuya Yoshikawa",
      "Masanari Kimura",
      "Ryotaro Shimizu",
      "Yuki Saito"
    ],
    "abstract": "Techniques that explain the predictions of black-box machine learning models\nare crucial to make the models transparent, thereby increasing trust in AI\nsystems. The input features to the models often have a nested structure that\nconsists of high- and low-level features, and each high-level feature is\ndecomposed into multiple low-level features. For such inputs, both high-level\nfeature attributions (HiFAs) and low-level feature attributions (LoFAs) are\nimportant for better understanding the model's decision. In this paper, we\npropose a model-agnostic local explanation method that effectively exploits the\nnested structure of the input to estimate the two-level feature attributions\nsimultaneously. A key idea of the proposed method is to introduce the\nconsistency property that should exist between the HiFAs and LoFAs, thereby\nbridging the separate optimization problems for estimating them. Thanks to this\nconsistency property, the proposed method can produce HiFAs and LoFAs that are\nboth faithful to the black-box models and consistent with each other, using a\nsmaller number of queries to the models. In experiments on image classification\nin multiple instance learning and text classification using language models, we\ndemonstrate that the HiFAs and LoFAs estimated by the proposed method are\naccurate, faithful to the behaviors of the black-box models, and provide\nconsistent explanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14522v1",
    "published_date": "2024-05-23 13:03:26 UTC",
    "updated_date": "2024-05-23 13:03:26 UTC"
  },
  {
    "arxiv_id": "2405.14516v1",
    "title": "Towards Realistic Long-tailed Semi-supervised Learning in an Open World",
    "authors": [
      "Yuanpeng He",
      "Lijian Li"
    ],
    "abstract": "Open-world long-tailed semi-supervised learning (OLSSL) has increasingly\nattracted attention. However, existing OLSSL algorithms generally assume that\nthe distributions between known and novel categories are nearly identical.\nAgainst this backdrop, we construct a more \\emph{Realistic Open-world\nLong-tailed Semi-supervised Learning} (\\textbf{ROLSSL}) setting where there is\nno premise on the distribution relationships between known and novel\ncategories. Furthermore, even within the known categories, the number of\nlabeled samples is significantly smaller than that of the unlabeled samples, as\nacquiring valid annotations is often prohibitively costly in the real world.\nUnder the proposed ROLSSL setting, we propose a simple yet potentially\neffective solution called dual-stage post-hoc logit adjustments. The proposed\napproach revisits the logit adjustment strategy by considering the\nrelationships among the frequency of samples, the total number of categories,\nand the overall size of data. Then, it estimates the distribution of unlabeled\ndata for both known and novel categories to dynamically readjust the\ncorresponding predictive probabilities, effectively mitigating category bias\nduring the learning of known and novel classes with more selective utilization\nof imbalanced unlabeled data. Extensive experiments on datasets such as\nCIFAR100 and ImageNet100 have demonstrated performance improvements of up to\n50.1\\%, validating the superiority of our proposed method and establishing a\nstrong baseline for this task. For further researches, the anonymous link to\nthe experimental code is at\n\\href{https://github.com/heyuanpengpku/ROLSSL}{\\textcolor{brightpink}{https://github.com/heyuanpengpku/ROLSSL}}",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14516v1",
    "published_date": "2024-05-23 12:53:50 UTC",
    "updated_date": "2024-05-23 12:53:50 UTC"
  },
  {
    "arxiv_id": "2405.14506v1",
    "title": "SIAVC: Semi-Supervised Framework for Industrial Accident Video Classification",
    "authors": [
      "Zuoyong Li",
      "Qinghua Lin",
      "Haoyi Fan",
      "Tiesong Zhao",
      "David Zhang"
    ],
    "abstract": "Semi-supervised learning suffers from the imbalance of labeled and unlabeled\ntraining data in the video surveillance scenario. In this paper, we propose a\nnew semi-supervised learning method called SIAVC for industrial accident video\nclassification. Specifically, we design a video augmentation module called the\nSuper Augmentation Block (SAB). SAB adds Gaussian noise and randomly masks\nvideo frames according to historical loss on the unlabeled data for model\noptimization. Then, we propose a Video Cross-set Augmentation Module (VCAM) to\ngenerate diverse pseudo-label samples from the high-confidence unlabeled\nsamples, which alleviates the mismatch of sampling experience and provides\nhigh-quality training data. Additionally, we construct a new industrial\naccident surveillance video dataset with frame-level annotation, namely ECA9,\nto evaluate our proposed method. Compared with the state-of-the-art\nsemi-supervised learning based methods, SIAVC demonstrates outstanding video\nclassification performance, achieving 88.76\\% and 89.13\\% accuracy on ECA9 and\nFire Detection datasets, respectively. The source code and the constructed\ndataset ECA9 will be released in \\url{https://github.com/AlchemyEmperor/SIAVC}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14506v1",
    "published_date": "2024-05-23 12:44:51 UTC",
    "updated_date": "2024-05-23 12:44:51 UTC"
  },
  {
    "arxiv_id": "2405.14505v1",
    "title": "Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing",
    "authors": [
      "Jaime González-González",
      "Silvia García-Méndez",
      "Francisco de Arriba-Pérez",
      "Francisco J. González-Castaño",
      "Óscar Barba-Seara"
    ],
    "abstract": "Concerns about the effect of greenhouse gases have motivated the development\nof certification protocols to quantify the industrial carbon footprint (CF).\nThese protocols are manual, work-intensive, and expensive. All of the above\nhave led to a shift towards automatic data-driven approaches to estimate the\nCF, including Machine Learning (ML) solutions. Unfortunately, the\ndecision-making processes involved in these solutions lack transparency from\nthe end user's point of view, who must blindly trust their outcomes compared to\nintelligible traditional manual approaches. In this research, manual and\nautomatic methodologies for CF estimation were reviewed, taking into account\ntheir transparency limitations. This analysis led to the proposal of a new\nexplainable ML solution for automatic CF calculations through bank transaction\nclassification. Consideration should be given to the fact that no previous\nresearch has considered the explainability of bank transaction classification\nfor this purpose. For classification, different ML models have been employed\nbased on their promising performance in the literature, such as Support Vector\nMachine, Random Forest, and Recursive Neural Networks. The results obtained\nwere in the 90 % range for accuracy, precision, and recall evaluation metrics.\nFrom their decision paths, the proposed solution estimates the CO2 emissions\nassociated with bank transactions. The explainability methodology is based on\nan agnostic evaluation of the influence of the input terms extracted from the\ndescriptions of transactions using locally interpretable models. The\nexplainability terms were automatically validated using a similarity metric\nover the descriptions of the target categories. Conclusively, the explanation\nperformance is satisfactory in terms of the proximity of the explanations to\nthe associated activity sector descriptions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14505v1",
    "published_date": "2024-05-23 12:43:06 UTC",
    "updated_date": "2024-05-23 12:43:06 UTC"
  },
  {
    "arxiv_id": "2405.14504v1",
    "title": "Enhanced Spatiotemporal Prediction Using Physical-guided And Frequency-enhanced Recurrent Neural Networks",
    "authors": [
      "Xuanle Zhao",
      "Yue Sun",
      "Tielin Zhang",
      "Bo Xu"
    ],
    "abstract": "Spatiotemporal prediction plays an important role in solving natural problems\nand processing video frames, especially in weather forecasting and human action\nrecognition. Recent advances attempt to incorporate prior physical knowledge\ninto the deep learning framework to estimate the unknown governing partial\ndifferential equations (PDEs), which have shown promising results in\nspatiotemporal prediction tasks. However, previous approaches only restrict\nneural network architectures or loss functions to acquire physical or PDE\nfeatures, which decreases the representative capacity of a neural network.\nMeanwhile, the updating process of the physical state cannot be effectively\nestimated. To solve the above mentioned problems, this paper proposes a\nphysical-guided neural network, which utilizes the frequency-enhanced Fourier\nmodule and moment loss to strengthen the model's ability to estimate the\nspatiotemporal dynamics. Furthermore, we propose an adaptive second-order\nRunge-Kutta method with physical constraints to model the physical states more\nprecisely. We evaluate our model on both spatiotemporal and video prediction\ntasks. The experimental results show that our model outperforms\nstate-of-the-art methods and performs best in several datasets, with a much\nsmaller parameter count.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14504v1",
    "published_date": "2024-05-23 12:39:49 UTC",
    "updated_date": "2024-05-23 12:39:49 UTC"
  },
  {
    "arxiv_id": "2405.14489v1",
    "title": "End-to-End User-Defined Keyword Spotting using Shifted Delta Coefficients",
    "authors": [
      "Kesavaraj V",
      "Anuprabha M",
      "Anil Kumar Vuppala"
    ],
    "abstract": "Identifying user-defined keywords is crucial for personalizing interactions\nwith smart devices. Previous approaches of user-defined keyword spotting\n(UDKWS) have relied on short-term spectral features such as mel frequency\ncepstral coefficients (MFCC) to detect the spoken keyword. However, these\nfeatures may face challenges in accurately identifying closely related\npronunciation of audio-text pairs, due to their limited capability in capturing\nthe temporal dynamics of the speech signal. To address this challenge, we\npropose to use shifted delta coefficients (SDC) which help in capturing\npronunciation variability (transition between connecting phonemes) by\nincorporating long-term temporal information. The performance of the SDC\nfeature is compared with various baseline features across four different\ndatasets using a cross-attention based end-to-end system. Additionally, various\nconfigurations of SDC are explored to find the suitable temporal context for\nthe UDKWS task. The experimental results reveal that the SDC feature\noutperforms the MFCC baseline feature, exhibiting an improvement of 8.32% in\narea under the curve (AUC) and 8.69% in terms of equal error rate (EER) on the\nchallenging Libriphrase-hard dataset. Moreover, the proposed approach\ndemonstrated superior performance when compared to state-of-the-art UDKWS\ntechniques.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14489v1",
    "published_date": "2024-05-23 12:24:01 UTC",
    "updated_date": "2024-05-23 12:24:01 UTC"
  },
  {
    "arxiv_id": "2405.14478v3",
    "title": "SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines",
    "authors": [
      "Andrea Ponte",
      "Dmitrijs Trizna",
      "Luca Demetrio",
      "Battista Biggio",
      "Ivan Tesfai Ogbu",
      "Fabio Roli"
    ],
    "abstract": "As a result of decades of research, Windows malware detection is approached\nthrough a plethora of techniques. However, there is an ongoing mismatch between\nacademia -- which pursues an optimal performances in terms of detection rate\nand low false alarms -- and the requirements of real-world scenarios. In\nparticular, academia focuses on combining static and dynamic analysis within a\nsingle or ensemble of models, falling into several pitfalls like (i) firing\ndynamic analysis without considering the computational burden it requires; (ii)\ndiscarding impossible-to-analyze samples; and (iii) analyzing robustness\nagainst adversarial attacks without considering that malware detectors are\ncomplemented with more non-machine-learning components. Thus, in this paper we\nbridge these gaps, by investigating the properties of malware detectors built\nwith multiple and different types of analysis. To do so, we develop SLIFER, a\nWindows malware detection pipeline sequentially leveraging both static and\ndynamic analysis, interrupting computations as soon as one module triggers an\nalarm, requiring dynamic analysis only when needed. Contrary to the state of\nthe art, we investigate how to deal with samples that impede analyzes, showing\nhow much they impact performances, concluding that it is better to flag them as\nlegitimate to not drastically increase false alarms. Lastly, we perform a\nrobustness evaluation of SLIFER. Counter-intuitively, the injection of new\ncontent is either blocked more by signatures than dynamic analysis, due to byte\nartifacts created by the attack, or it is able to avoid detection from\nsignatures, as they rely on constraints on file size disrupted by attacks. As\nfar as we know, we are the first to investigate the properties of sequential\nmalware detectors, shedding light on their behavior in real production\nenvironment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14478v3",
    "published_date": "2024-05-23 12:06:10 UTC",
    "updated_date": "2024-12-19 13:56:51 UTC"
  },
  {
    "arxiv_id": "2405.14475v3",
    "title": "MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes",
    "authors": [
      "Ruiyuan Gao",
      "Kai Chen",
      "Zhihao Li",
      "Lanqing Hong",
      "Zhenguo Li",
      "Qiang Xu"
    ],
    "abstract": "While controllable generative models for images and videos have achieved\nremarkable success, high-quality models for 3D scenes, particularly in\nunbounded scenarios like autonomous driving, remain underdeveloped due to high\ndata acquisition costs. In this paper, we introduce MagicDrive3D, a novel\npipeline for controllable 3D street scene generation that supports\nmulti-condition control, including BEV maps, 3D objects, and text descriptions.\nUnlike previous methods that reconstruct before training the generative models,\nMagicDrive3D first trains a video generation model and then reconstructs from\nthe generated data. This innovative approach enables easily controllable\ngeneration and static scene acquisition, resulting in high-quality scene\nreconstruction. To address the minor errors in generated content, we propose\ndeformable Gaussian splatting with monocular depth initialization and\nappearance modeling to manage exposure discrepancies across viewpoints.\nValidated on the nuScenes dataset, MagicDrive3D generates diverse, high-quality\n3D driving scenes that support any-view rendering and enhance downstream tasks\nlike BEV segmentation. Our results demonstrate the framework's superior\nperformance, showcasing its potential for autonomous driving simulation and\nbeyond.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://flymin.github.io/magicdrive3d",
    "pdf_url": "http://arxiv.org/pdf/2405.14475v3",
    "published_date": "2024-05-23 12:04:51 UTC",
    "updated_date": "2024-11-20 10:43:51 UTC"
  },
  {
    "arxiv_id": "2405.14473v2",
    "title": "Poisson Variational Autoencoder",
    "authors": [
      "Hadi Vafaii",
      "Dekel Galor",
      "Jacob L. Yates"
    ],
    "abstract": "Variational autoencoders (VAEs) employ Bayesian inference to interpret\nsensory inputs, mirroring processes that occur in primate vision across both\nventral (Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways.\nDespite their success, traditional VAEs rely on continuous latent variables,\nwhich deviates sharply from the discrete nature of biological neurons. Here, we\ndeveloped the Poisson VAE (P-VAE), a novel architecture that combines\nprinciples of predictive coding with a VAE that encodes inputs into discrete\nspike counts. Combining Poisson-distributed latent variables with predictive\ncoding introduces a metabolic cost term in the model loss function, suggesting\na relationship with sparse coding which we verify empirically. Additionally, we\nanalyze the geometry of learned representations, contrasting the P-VAE to\nalternative VAE models. We find that the P-VAE encodes its inputs in relatively\nhigher dimensions, facilitating linear separability of categories in a\ndownstream classification task with a much better (5x) sample efficiency. Our\nwork provides an interpretable computational framework to study brain-like\nsensory processing and paves the way for a deeper understanding of perception\nas an inferential process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a NeurIPS 2024 Spotlight paper\n  (https://openreview.net/forum?id=ektPEcqGLb)",
    "pdf_url": "http://arxiv.org/pdf/2405.14473v2",
    "published_date": "2024-05-23 12:02:54 UTC",
    "updated_date": "2024-12-09 00:57:31 UTC"
  },
  {
    "arxiv_id": "2405.14467v1",
    "title": "Segformer++: Efficient Token-Merging Strategies for High-Resolution Semantic Segmentation",
    "authors": [
      "Daniel Kienzle",
      "Marco Kantonis",
      "Robin Schön",
      "Rainer Lienhart"
    ],
    "abstract": "Utilizing transformer architectures for semantic segmentation of\nhigh-resolution images is hindered by the attention's quadratic computational\ncomplexity in the number of tokens. A solution to this challenge involves\ndecreasing the number of tokens through token merging, which has exhibited\nremarkable enhancements in inference speed, training efficiency, and memory\nutilization for image classification tasks. In this paper, we explore various\ntoken merging strategies within the framework of the Segformer architecture and\nperform experiments on multiple semantic segmentation and human pose estimation\ndatasets. Notably, without model re-training, we, for example, achieve an\ninference acceleration of 61% on the Cityscapes dataset while maintaining the\nmIoU performance. Consequently, this paper facilitates the deployment of\ntransformer-based architectures on resource-constrained devices and in\nreal-time applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, to be published in IEEE International Conference on\n  Multimedia Information Processing and Retrieval (MIPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14467v1",
    "published_date": "2024-05-23 11:54:27 UTC",
    "updated_date": "2024-05-23 11:54:27 UTC"
  },
  {
    "arxiv_id": "2405.14452v2",
    "title": "JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression",
    "authors": [
      "Zihan Zheng",
      "Houqiang Zhong",
      "Qiang Hu",
      "Xiaoyun Zhang",
      "Li Song",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "abstract": "Neural Radiance Field (NeRF) excels in photo-realistically static scenes,\ninspiring numerous efforts to facilitate volumetric videos. However, rendering\ndynamic and long-sequence radiance fields remains challenging due to the\nsignificant data required to represent volumetric videos. In this paper, we\npropose a novel end-to-end joint optimization scheme of dynamic NeRF\nrepresentation and compression, called JointRF, thus achieving significantly\nimproved quality and compression efficiency against the previous methods.\nSpecifically, JointRF employs a compact residual feature grid and a coefficient\nfeature grid to represent the dynamic NeRF. This representation handles large\nmotions without compromising quality while concurrently diminishing temporal\nredundancy. We also introduce a sequential feature compression subnetwork to\nfurther reduce spatial-temporal redundancy. Finally, the representation and\ncompression subnetworks are end-to-end trained combined within the JointRF.\nExtensive experiments demonstrate that JointRF can achieve superior compression\nperformance across various datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICIP2024, 8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14452v2",
    "published_date": "2024-05-23 11:32:46 UTC",
    "updated_date": "2024-06-08 06:12:05 UTC"
  },
  {
    "arxiv_id": "2405.14446v2",
    "title": "Worldwide Federated Training of Language Models",
    "authors": [
      "Alex Iacob",
      "Lorenzo Sani",
      "Bill Marino",
      "Preslav Aleksandrov",
      "William F. Shen",
      "Nicholas Donald Lane"
    ],
    "abstract": "The reliance of language model training on massive amounts of computation and\nvast datasets scraped from potentially low-quality, copyrighted, or sensitive\ndata has come into question practically, legally, and ethically. Federated\nlearning provides a plausible alternative by enabling previously untapped data\nto be voluntarily gathered from collaborating organizations. However, when\nscaled globally, federated learning requires collaboration across heterogeneous\nlegal, security, and privacy regimes while accounting for the inherent locality\nof language data; this further exacerbates the established challenge of\nfederated statistical heterogeneity. We propose a Worldwide Federated Language\nModel Training~(WorldLM) system based on federations of federations, where each\nfederation has the autonomy to account for factors such as its industry,\noperating jurisdiction, or competitive environment. WorldLM enables such\nautonomy in the presence of statistical heterogeneity via partial model\nlocalization by allowing sub-federations to attentively aggregate key layers\nfrom their constituents. Furthermore, it can adaptively share information\nacross federations via residual layer embeddings. Evaluations of language\nmodeling on naturally heterogeneous datasets show that WorldLM outperforms\nstandard federations by up to $1.91\\times$, approaches the personalized\nperformance of fully local models, and maintains these advantages under\nprivacy-enhancing techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 8 figures, Under Review",
    "pdf_url": "http://arxiv.org/pdf/2405.14446v2",
    "published_date": "2024-05-23 11:25:19 UTC",
    "updated_date": "2024-05-27 10:59:22 UTC"
  },
  {
    "arxiv_id": "2405.14445v2",
    "title": "Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study",
    "authors": [
      "Lena Schmidt",
      "Kaitlyn Hair",
      "Sergio Graziosi",
      "Fiona Campbell",
      "Claudia Kapp",
      "Alireza Khanteymoori",
      "Dawn Craig",
      "Mark Engelbert",
      "James Thomas"
    ],
    "abstract": "This paper describes a rapid feasibility study of using GPT-4, a large\nlanguage model (LLM), to (semi)automate data extraction in systematic reviews.\nDespite the recent surge of interest in LLMs there is still a lack of\nunderstanding of how to design LLM-based automation tools and how to robustly\nevaluate their performance. During the 2023 Evidence Synthesis Hackathon we\nconducted two feasibility studies. Firstly, to automatically extract study\ncharacteristics from human clinical, animal, and social science domain studies.\nWe used two studies from each category for prompt-development; and ten for\nevaluation. Secondly, we used the LLM to predict Participants, Interventions,\nControls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP\ndataset. Overall, results indicated an accuracy of around 80%, with some\nvariability between domains (82% for human clinical, 80% for animal, and 72%\nfor studies of human social sciences). Causal inference methods and study\ndesign were the data extraction items with the most errors. In the PICO study,\nparticipants and intervention/control showed high accuracy (>80%), outcomes\nwere more challenging. Evaluation was done manually; scoring methods such as\nBLEU and ROUGE showed limited value. We observed variability in the LLMs\npredictions and changes in response quality. This paper presents a template for\nfuture evaluations of LLMs in the context of data extraction for systematic\nreview automation. Our results show that there might be value in using LLMs,\nfor example as second or third reviewers. However, caution is advised when\nintegrating models such as GPT-4 into tools. Further research on stability and\nreliability in practical settings is warranted for each type of data that is\nprocessed by the LLM.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Conference proceedings, peer-reviewed and presented at the 3rd\n  Workshop on Augmented Intelligence for Technology-Assisted Reviews Systems,\n  Glasgow, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14445v2",
    "published_date": "2024-05-23 11:24:23 UTC",
    "updated_date": "2025-02-13 09:07:10 UTC"
  },
  {
    "arxiv_id": "2405.14436v1",
    "title": "LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules",
    "authors": [
      "Mohamed Mejri",
      "Chandramouli Amarnath",
      "Abhijit Chatterjee"
    ],
    "abstract": "Human cognition excels at symbolic reasoning, deducing abstract rules from\nlimited samples. This has been explained using symbolic and connectionist\napproaches, inspiring the development of a neuro-symbolic architecture that\ncombines both paradigms. In parallel, recent studies have proposed the use of a\n\"relational bottleneck\" that separates object-level features from abstract\nrules, allowing learning from limited amounts of data . While powerful, it is\nvulnerable to the curse of compositionality meaning that object representations\nwith similar features tend to interfere with each other. In this paper, we\nleverage hyperdimensional computing, which is inherently robust to such\ninterference to build a compositional architecture. We adapt the \"relational\nbottleneck\" strategy to a high-dimensional space, incorporating explicit vector\nbinding operations between symbols and relational representations.\nAdditionally, we design a novel high-dimensional attention mechanism that\nleverages this relational representation. Our system benefits from the low\noverhead of operations in hyperdimensional space, making it significantly more\nefficient than the state of the art when evaluated on a variety of test\ndatasets, while maintaining higher or equal accuracy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14436v1",
    "published_date": "2024-05-23 11:05:42 UTC",
    "updated_date": "2024-05-23 11:05:42 UTC"
  },
  {
    "arxiv_id": "2405.14431v1",
    "title": "RaFe: Ranking Feedback Improves Query Rewriting for RAG",
    "authors": [
      "Shengyu Mao",
      "Yong Jiang",
      "Boli Chen",
      "Xiao Li",
      "Peng Wang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG)\ntechniques have evolved, query rewriting has been widely incorporated into the\nRAG system for downstream tasks like open-domain QA. Many works have attempted\nto utilize small models with reinforcement learning rather than costly LLMs to\nimprove query rewriting. However, current methods require annotations (e.g.,\nlabeled relevant documents or downstream answers) or predesigned rewards for\nfeedback, which lack generalization, and fail to utilize signals tailored for\nquery rewriting. In this paper, we propose ours, a framework for training query\nrewriting models free of annotations. By leveraging a publicly available\nreranker, ours~provides feedback aligned well with the rewriting objectives.\nExperimental results demonstrate that ours~can obtain better performance than\nbaselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.14431v1",
    "published_date": "2024-05-23 11:00:19 UTC",
    "updated_date": "2024-05-23 11:00:19 UTC"
  },
  {
    "arxiv_id": "2405.14430v3",
    "title": "PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference",
    "authors": [
      "Jiarui Fang",
      "Jinzhe Pan",
      "Jiannan Wang",
      "Aoyu Li",
      "Xibo Sun"
    ],
    "abstract": "This paper presents PipeFusion, an innovative parallel methodology to tackle\nthe high latency issues associated with generating high-resolution images using\ndiffusion transformers (DiTs) models. PipeFusion partitions images into patches\nand the model layers across multiple GPUs. It employs a patch-level pipeline\nparallel strategy to orchestrate communication and computation efficiently. By\ncapitalizing on the high similarity between inputs from successive diffusion\nsteps, PipeFusion reuses one-step stale feature maps to provide context for the\ncurrent pipeline step. This approach notably reduces communication costs\ncompared to existing DiTs inference parallelism, including tensor parallel,\nsequence parallel and DistriFusion. PipeFusion also exhibits superior memory\nefficiency, because it can distribute model parameters across multiple devices,\nmaking it more suitable for DiTs with large parameter sizes, such as Flux.1.\nExperimental results demonstrate that PipeFusion achieves state-of-the-art\nperformance on 8xL40 PCIe GPUs for Pixart, Stable-Diffusion 3 and Flux.1\nmodels.Our Source code is available at https://github.com/xdit-project/xDiT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14430v3",
    "published_date": "2024-05-23 11:00:07 UTC",
    "updated_date": "2024-10-31 05:14:31 UTC"
  },
  {
    "arxiv_id": "2405.14422v3",
    "title": "Unraveling overoptimism and publication bias in ML-driven science",
    "authors": [
      "Pouria Saidi",
      "Gautam Dasarathy",
      "Visar Berisha"
    ],
    "abstract": "Machine Learning (ML) is increasingly used across many disciplines with\nimpressive reported results. However, recent studies suggest published\nperformance of ML models are often overoptimistic. Validity concerns are\nunderscored by findings of an inverse relationship between sample size and\nreported accuracy in published ML models, contrasting with the theory of\nlearning curves where accuracy should improve or remain stable with increasing\nsample size. This paper investigates factors contributing to overoptimism in\nML-driven science, focusing on overfitting and publication bias. We introduce a\nnovel stochastic model for observed accuracy, integrating parametric learning\ncurves and the aforementioned biases. We construct an estimator that corrects\nfor these biases in observed data. Theoretical and empirical results show that\nour framework can estimate the underlying learning curve, providing realistic\nperformance assessments from published results. Applying the model to\nmeta-analyses of classifications of neurological conditions, we estimate the\ninherent limits of ML-based prediction in each domain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.14422v3",
    "published_date": "2024-05-23 10:43:20 UTC",
    "updated_date": "2024-07-11 19:40:20 UTC"
  },
  {
    "arxiv_id": "2405.14419v3",
    "title": "A motion-based compression algorithm for resource-constrained video camera traps",
    "authors": [
      "Malika Nisal Ratnayake",
      "Lex Gallon",
      "Adel N. Toosi",
      "Alan Dorin"
    ],
    "abstract": "Field-captured video facilitates detailed studies of spatio-temporal aspects\nof animal locomotion, decision-making and environmental interactions including\npredator-prey relationships and habitat utilisation. But even though data\ncapture is cheap with mass-produced hardware, storage, processing and\ntransmission overheads provide a hurdle to acquisition of high resolution video\nfrom field-situated edge computing devices. Efficient compression algorithms\nare therefore essential if monitoring is to be conducted on single-board\ncomputers in situations where such hurdles must be overcome. Animal motion\ntracking in the field has unique characteristics that necessitate the use of\nnovel video compression techniques, which may be underexplored or unsuitable in\nother contexts. In this article, we therefore introduce a new motion\nanalysis-based video compression algorithm specifically designed for camera\ntraps. We implemented and tested this algorithm using a case study of\ninsect-pollinator motion tracking on three popular edge computing platforms.\nThe algorithm identifies and stores only image regions depicting motion\nrelevant to pollination monitoring, reducing overall data size by an average of\n87% across diverse test datasets. Our experiments demonstrate the algorithm's\ncapability to preserve critical information for insect behaviour analysis\nthrough both manual observation and automatic analysis of the compressed\nfootage. The method presented in this paper enhances the applicability of\nlow-powered computer vision edge devices to remote, in situ animal motion\nmonitoring, and improves the efficiency of playback during behavioural\nanalyses. Our new software, EcoMotionZip, is available Open Access.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.14419v3",
    "published_date": "2024-05-23 10:39:33 UTC",
    "updated_date": "2024-10-02 00:07:34 UTC"
  },
  {
    "arxiv_id": "2405.14414v1",
    "title": "Proving Theorems Recursively",
    "authors": [
      "Haiming Wang",
      "Huajian Xin",
      "Zhengying Liu",
      "Wenda Li",
      "Yinya Huang",
      "Jianqiao Lu",
      "Zhicheng Yang",
      "Jing Tang",
      "Jian Yin",
      "Zhenguo Li",
      "Xiaodan Liang"
    ],
    "abstract": "Recent advances in automated theorem proving leverages language models to\nexplore expanded search spaces by step-by-step proof generation. However, such\napproaches are usually based on short-sighted heuristics (e.g., log probability\nor value function scores) that potentially lead to suboptimal or even\ndistracting subgoals, preventing us from finding longer proofs. To address this\nchallenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves\ntheorems in a recursive, level-by-level manner in the Isabelle theorem prover.\nUnlike previous step-by-step methods, POETRY searches for a verifiable sketch\nof the proof at each level and focuses on solving the current level's theorem\nor conjecture. Detailed proofs of intermediate conjectures within the sketch\nare temporarily replaced by a placeholder tactic called sorry, deferring their\nproofs to subsequent levels. This approach allows the theorem to be tackled\nincrementally by outlining the overall theorem at the first level and then\nsolving the intermediate conjectures at deeper levels. Experiments are\nconducted on the miniF2F and PISA datasets and significant performance gains\nare observed in our POETRY approach over state-of-the-art methods. POETRY on\nminiF2F achieves an average proving success rate improvement of 5.1%. Moreover,\nwe observe a substantial increase in the maximum proof length found by POETRY,\nfrom 10 to 26.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.14414v1",
    "published_date": "2024-05-23 10:35:08 UTC",
    "updated_date": "2024-05-23 10:35:08 UTC"
  },
  {
    "arxiv_id": "2405.14411v2",
    "title": "Large Language Models for Explainable Decisions in Dynamic Digital Twins",
    "authors": [
      "Nan Zhang",
      "Christian Vergara-Marcillo",
      "Georgios Diamantopoulos",
      "Jingran Shen",
      "Nikos Tziritas",
      "Rami Bahsoon",
      "Georgios Theodoropoulos"
    ],
    "abstract": "Dynamic data-driven Digital Twins (DDTs) can enable informed decision-making\nand provide an optimisation platform for the underlying system. By leveraging\nprinciples of Dynamic Data-Driven Applications Systems (DDDAS), DDTs can\nformulate computational modalities for feedback loops, model updates and\ndecision-making, including autonomous ones. However, understanding autonomous\ndecision-making often requires technical and domain-specific knowledge. This\npaper explores using large language models (LLMs) to provide an explainability\nplatform for DDTs, generating natural language explanations of the system's\ndecision-making by leveraging domain-specific knowledge bases. A case study\nfrom smart agriculture is presented.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 3 figures, accepted by DDDAS2024 -- the 5th International\n  Conference on Dynamic Data Driven Applications Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.14411v2",
    "published_date": "2024-05-23 10:32:38 UTC",
    "updated_date": "2024-09-04 06:00:56 UTC"
  },
  {
    "arxiv_id": "2405.14909v2",
    "title": "Interpretable Price Bounds Estimation with Shape Constraints in Price Optimization",
    "authors": [
      "Shunnosuke Ikeda",
      "Naoki Nishimura",
      "Shunji Umetani"
    ],
    "abstract": "This study addresses the interpretable estimation of price bounds in the\ncontext of price optimization. In recent years, price-optimization methods have\nbecome indispensable for maximizing revenue and profits. However, effective\napplication of these methods to real-world pricing operations remains a\nsignificant challenge. It is crucial for operators responsible for setting\nprices to utilize reasonable price bounds that are not only interpretable but\nalso acceptable. Despite this necessity, most studies assume that price bounds\nare given constant values, and few have explored reasonable determinations of\nthese bounds. Therefore, we propose a comprehensive framework for determining\nprice bounds that includes both the estimation and adjustment of these bounds.\nSpecifically, we first estimate price bounds using three distinct approaches\nbased on historical pricing data. Then, we adjust the estimated price bounds by\nsolving an optimization problem that incorporates shape constraints. This\nmethod allows the implementation of price optimization under practical and\nreasonable price bounds suitable for real-world applications. We report the\neffectiveness of our proposed method through numerical experiments using\nhistorical pricing data from actual services.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14909v2",
    "published_date": "2024-05-23 10:30:16 UTC",
    "updated_date": "2024-09-29 10:39:58 UTC"
  },
  {
    "arxiv_id": "2407.11973v1",
    "title": "Preliminary Study of the Impact of AI-Based Interventions on Health and Behavioral Outcomes in Maternal Health Programs",
    "authors": [
      "Arpan Dasgupta",
      "Niclas Boehmer",
      "Neha Madhiwalla",
      "Aparna Hedge",
      "Bryan Wilder",
      "Milind Tambe",
      "Aparna Taneja"
    ],
    "abstract": "Automated voice calls are an effective method of delivering maternal and\nchild health information to mothers in underserved communities. One method to\nfight dwindling listenership is through an intervention in which health workers\nmake live service calls. Previous work has shown that we can use AI to identify\nbeneficiaries whose listenership gets the greatest boost from an intervention.\nIt has also been demonstrated that listening to the automated voice calls\nconsistently leads to improved health outcomes for the beneficiaries of the\nprogram. These two observations combined suggest the positive effect of\nAI-based intervention scheduling on behavioral and health outcomes. This study\nanalyzes the relationship between the two. Specifically, we are interested in\nmothers' health knowledge in the post-natal period, measured through survey\nquestions. We present evidence that improved listenership through AI-scheduled\ninterventions leads to a better understanding of key health issues during\npregnancy and infancy. This improved understanding has the potential to benefit\nthe health outcomes of mothers and their babies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at Autonomous Agents for Social Good (AASG) workshop at\n  AAMAS'24",
    "pdf_url": "http://arxiv.org/pdf/2407.11973v1",
    "published_date": "2024-05-23 10:18:20 UTC",
    "updated_date": "2024-05-23 10:18:20 UTC"
  },
  {
    "arxiv_id": "2405.14398v3",
    "title": "SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network",
    "authors": [
      "Weiyu Guo",
      "Ying Sun",
      "Yijie Xu",
      "Ziyue Qiao",
      "Yongkui Yang",
      "Hui Xiong"
    ],
    "abstract": "Surface electromyography (sEMG) based gesture recognition offers a natural\nand intuitive interaction modality for wearable devices. Despite significant\nadvancements in sEMG-based gesture-recognition models, existing methods often\nsuffer from high computational latency and increased energy consumption.\nAdditionally, the inherent instability of sEMG signals, combined with their\nsensitivity to distribution shifts in real-world settings, compromises model\nrobustness. To tackle these challenges, we propose a novel SpGesture framework\nbased on Spiking Neural Networks, which possesses several unique merits\ncompared with existing methods: (1) Robustness: By utilizing membrane potential\nas a memory list, we pioneer the introduction of Source-Free Domain Adaptation\ninto SNN for the first time. This enables SpGesture to mitigate the accuracy\ndegradation caused by distribution shifts. (2) High Accuracy: With a novel\nSpiking Jaccard Attention, SpGesture enhances the SNNs' ability to represent\nsEMG features, leading to a notable rise in system accuracy. To validate\nSpGesture's performance, we collected a new sEMG gesture dataset which has\ndifferent forearm postures, where SpGesture achieved the highest accuracy among\nthe baselines ($89.26\\%$). Moreover, the actual deployment on the CPU\ndemonstrated a system latency below 100ms, well within real-time requirements.\nThis impressive performance showcases SpGesture's potential to enhance the\napplicability of sEMG in real-world scenarios. The code is available at\nhttps://github.com/guoweiyu/SpGesture/.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14398v3",
    "published_date": "2024-05-23 10:15:29 UTC",
    "updated_date": "2024-10-30 12:56:44 UTC"
  },
  {
    "arxiv_id": "2405.14394v2",
    "title": "Instruction Tuning With Loss Over Instructions",
    "authors": [
      "Zhengyan Shi",
      "Adam X. Yang",
      "Bin Wu",
      "Laurence Aitchison",
      "Emine Yilmaz",
      "Aldo Lipani"
    ],
    "abstract": "Instruction tuning plays a crucial role in shaping the outputs of language\nmodels (LMs) to desired styles. In this work, we propose a simple yet effective\nmethod, Instruction Modelling (IM), which trains LMs by applying a loss\nfunction to the instruction and prompt part rather than solely to the output\npart. Through experiments across 21 diverse benchmarks, we show that, in many\nscenarios, IM can effectively improve the LM performance on both NLP tasks\n(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks\n(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM\nboosts model performance on AlpacaEval 1.0 by over 100%. We identify two key\nfactors influencing the effectiveness of IM: (1) The ratio between instruction\nlength and output length in the training data; and (2) The number of training\nexamples. We observe that IM is especially beneficial when trained on datasets\nwith lengthy instructions paired with brief outputs, or under the Superficial\nAlignment Hypothesis (SAH) where a small amount of training examples are used\nfor instruction tuning. Further analysis substantiates our hypothesis that our\nimprovement can be attributed to reduced overfitting to instruction tuning\ndatasets. It is worth noting that we are not proposing \\ours as a replacement\nfor current fine-tuning processes. Instead, our work aims to provide practical\nguidance for instruction tuning LMs, especially in low-resource scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024. Code is available at\n  https://github.com/ZhengxiangShi/InstructionModelling",
    "pdf_url": "http://arxiv.org/pdf/2405.14394v2",
    "published_date": "2024-05-23 10:12:03 UTC",
    "updated_date": "2024-10-02 20:36:11 UTC"
  },
  {
    "arxiv_id": "2405.14391v2",
    "title": "Explainable Few-shot Knowledge Tracing",
    "authors": [
      "Haoxuan Li",
      "Jifan Yu",
      "Yuanxin Ouyang",
      "Zhuang Liu",
      "Wenge Rong",
      "Juanzi Li",
      "Zhang Xiong"
    ],
    "abstract": "Knowledge tracing (KT), aiming to mine students' mastery of knowledge by\ntheir exercise records and predict their performance on future test questions,\nis a critical task in educational assessment. While researchers achieved\ntremendous success with the rapid development of deep learning techniques,\ncurrent knowledge tracing tasks fall into the cracks from real-world teaching\nscenarios. Relying heavily on extensive student data and solely predicting\nnumerical performances differs from the settings where teachers assess\nstudents' knowledge state from limited practices and provide explanatory\nfeedback. To fill this gap, we explore a new task formulation: Explainable\nFew-shot Knowledge Tracing. By leveraging the powerful reasoning and generation\nabilities of large language models (LLMs), we then propose a cognition-guided\nframework that can track the student knowledge from a few student records while\nproviding natural language explanations. Experimental results from three widely\nused datasets show that LLMs can perform comparable or superior to competitive\ndeep knowledge tracing methods. We also discuss potential directions and call\nfor future improvements in relevant topics.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14391v2",
    "published_date": "2024-05-23 10:07:21 UTC",
    "updated_date": "2024-05-26 03:43:33 UTC"
  },
  {
    "arxiv_id": "2405.14389v1",
    "title": "stl2vec: Semantic and Interpretable Vector Representation of Temporal Logic",
    "authors": [
      "Gaia Saveri",
      "Laura Nenzi",
      "Luca Bortolussi",
      "Jan Křetínský"
    ],
    "abstract": "Integrating symbolic knowledge and data-driven learning algorithms is a\nlongstanding challenge in Artificial Intelligence. Despite the recognized\nimportance of this task, a notable gap exists due to the discreteness of\nsymbolic representations and the continuous nature of machine-learning\ncomputations. One of the desired bridges between these two worlds would be to\ndefine semantically grounded vector representation (feature embedding) of logic\nformulae, thus enabling to perform continuous learning and optimization in the\nsemantic space of formulae. We tackle this goal for knowledge expressed in\nSignal Temporal Logic (STL) and devise a method to compute continuous\nembeddings of formulae with several desirable properties: the embedding (i) is\nfinite-dimensional, (ii) faithfully reflects the semantics of the formulae,\n(iii) does not require any learning but instead is defined from basic\nprinciples, (iv) is interpretable. Another significant contribution lies in\ndemonstrating the efficacy of the approach in two tasks: learning model\nchecking, where we predict the probability of requirements being satisfied in\nstochastic processes; and integrating the embeddings into a neuro-symbolic\nframework, to constrain the output of a deep-learning generative model to\ncomply to a given logical specification.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14389v1",
    "published_date": "2024-05-23 10:04:56 UTC",
    "updated_date": "2024-05-23 10:04:56 UTC"
  },
  {
    "arxiv_id": "2405.14385v1",
    "title": "Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis",
    "authors": [
      "Aline Étienne",
      "Delphine Battistelli",
      "Gwénolé Lecorvé"
    ],
    "abstract": "The objective of this paper is to predict (A) whether a sentence in a written\ntext expresses an emotion, (B) the mode(s) in which it is expressed, (C)\nwhether it is basic or complex, and (D) its emotional category.\n  One of our major contributions, through a dataset and a model, is to\nintegrate the fact that an emotion can be expressed in different modes: from a\ndirect mode, essentially lexicalized, to a more indirect mode, where emotions\nwill only be suggested, a mode that NLP approaches generally don't take into\naccount.\n  Another originality is that the scope is on written texts, as opposed usual\nwork focusing on conversational (often multi-modal) data. In this context,\nmodes of expression are seen as a factor towards the automatic analysis of\ncomplexity in texts.\n  Experiments on French texts show acceptable results compared to the human\nannotators' agreement, and outperforming results compared to using a large\nlanguage model with in-context learning (i.e. no fine-tuning).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 12 figures, submitted to ACL 2024 WASSA workshop",
    "pdf_url": "http://arxiv.org/pdf/2405.14385v1",
    "published_date": "2024-05-23 10:02:13 UTC",
    "updated_date": "2024-05-23 10:02:13 UTC"
  },
  {
    "arxiv_id": "2405.14384v1",
    "title": "Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models",
    "authors": [
      "Marion Neumeier",
      "Sebastian Dorn",
      "Michael Botsch",
      "Wolfgang Utschick"
    ],
    "abstract": "This work introduces the conditioned Vehicle Motion Diffusion (cVMD) model, a\nnovel network architecture for highway trajectory prediction using diffusion\nmodels. The proposed model ensures the drivability of the predicted trajectory\nby integrating non-holonomic motion constraints and physical constraints into\nthe generative prediction module. Central to the architecture of cVMD is its\ncapacity to perform uncertainty quantification, a feature that is crucial in\nsafety-critical applications. By integrating the quantified uncertainty into\nthe prediction process, the cVMD's trajectory prediction performance is\nimproved considerably. The model's performance was evaluated using the publicly\navailable highD dataset. Experiments show that the proposed architecture\nachieves competitive trajectory prediction accuracy compared to\nstate-of-the-art models, while providing guaranteed drivable trajectories and\nuncertainty quantification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE/CVF Computer Vision and Pattern Recognition\n  Conference Workshops (CVPRW) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14384v1",
    "published_date": "2024-05-23 10:01:39 UTC",
    "updated_date": "2024-05-23 10:01:39 UTC"
  },
  {
    "arxiv_id": "2405.14383v1",
    "title": "Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering",
    "authors": [
      "Zhihua Wen",
      "Zhiliang Tian",
      "Zexin Jian",
      "Zhen Huang",
      "Pei Ke",
      "Yifu Gao",
      "Minlie Huang",
      "Dongsheng Li"
    ],
    "abstract": "Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer\nfrom hallucinations. The knowledge boundary (KB) of an LLM limits its factual\nunderstanding, beyond which it may begin to hallucinate. Investigating the\nperception of LLMs' KB is crucial for detecting hallucinations and LLMs'\nreliable generation. Current studies perceive LLMs' KB on questions with a\nconcrete answer (close-ended questions) while paying limited attention to\nsemi-open-ended questions (SoeQ) that correspond to many potential answers.\nSome researchers achieve it by judging whether the question is answerable or\nnot. However, this paradigm is unsuitable for SoeQ, which are usually partially\nanswerable, containing both answerable and ambiguous (unanswerable) answers.\nAmbiguous answers are essential for knowledge-seeking, but they may go beyond\nthe KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by\ndiscovering more ambiguous answers. First, we apply an LLM-based approach to\nconstruct SoeQ and obtain answers from a target LLM. Unfortunately, the output\nprobabilities of mainstream black-box LLMs are inaccessible to sample for\nlow-probability ambiguous answers. Therefore, we apply an open-sourced\nauxiliary model to explore ambiguous answers for the target LLM. We calculate\nthe nearest semantic representation for existing answers to estimate their\nprobabilities, with which we reduce the generation probability of\nhigh-probability answers to achieve a more effective generation. Finally, we\ncompare the results from the RAG-based evaluation and LLM self-evaluation to\ncategorize four types of ambiguous answers that are beyond the KB of the target\nLLM. Following our method, we construct a dataset to perceive the KB for GPT-4.\nWe find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.\nBesides, our auxiliary model, LLaMA-2-13B, is effective in discovering more\nambiguous answers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14383v1",
    "published_date": "2024-05-23 10:00:14 UTC",
    "updated_date": "2024-05-23 10:00:14 UTC"
  },
  {
    "arxiv_id": "2405.14379v1",
    "title": "Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?",
    "authors": [
      "Thomas Greatrix",
      "Roger Whitaker",
      "Liam Turner",
      "Walter Colombo"
    ],
    "abstract": "The potential for Large Language Models (LLMs) to generate new information\noffers a potential step change for research and innovation. This is challenging\nto assert as it can be difficult to determine what an LLM has previously seen\nduring training, making \"newness\" difficult to substantiate. In this paper we\nobserve that LLMs are able to perform sophisticated reasoning on problems with\na spatial dimension, that they are unlikely to have previously directly\nencountered. While not perfect, this points to a significant level of\nunderstanding that state-of-the-art LLMs can now achieve, supporting the\nproposition that LLMs are able to yield significant emergent properties. In\nparticular, Claude 3 is found to perform well in this regard.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14379v1",
    "published_date": "2024-05-23 09:54:54 UTC",
    "updated_date": "2024-05-23 09:54:54 UTC"
  },
  {
    "arxiv_id": "2405.14377v2",
    "title": "CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization",
    "authors": [
      "Zi Yang",
      "Ziyue Liu",
      "Samridhi Choudhary",
      "Xinfeng Xie",
      "Cao Gao",
      "Siegfried Kunzmann",
      "Zheng Zhang"
    ],
    "abstract": "Training large AI models such as LLMs and DLRMs costs massive GPUs and\ncomputing time. The high training cost has become only affordable to big tech\ncompanies, meanwhile also causing increasing concerns about the environmental\nimpact. This paper presents CoMERA, a Computing- and Memory-Efficient training\nmethod via Rank-Adaptive tensor optimization. CoMERA achieves rank-adaptive\ntensor-compressed (pre)-training via a multi-objective optimization formulation\nand improves the training to provide both a high compression ratio and\nexcellent accuracy in the training process. Our optimized numerical computation\n(e.g., optimized tensorized embedding and tensor-network contractions) and GPU\nimplementation eliminate part of the run-time overhead in the tensorized\ntraining on GPU. This leads to, for the first time, $2-3\\times$ speedup per\ntraining epoch compared with standard training. CoMERA also outperforms the\nrecent GaLore in terms of both memory and computing efficiency. Specifically,\nCoMERA is $2\\times$ faster per training epoch and $9\\times$ more\nmemory-efficient than GaLore on a tested six-encoder transformer with\nsingle-batch training. Our method also shows $\\sim 2\\times$ speedup than\nstandard pre-training on a BERT-like code-generation LLM while achieving\n$4.23\\times$ compression ratio in pre-training. With further HPC optimization,\nCoMERA may reduce the pre-training cost of many other LLMs. An implementation\nof CoMERA is available at https://github.com/ziyangjoy/CoMERA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14377v2",
    "published_date": "2024-05-23 09:52:15 UTC",
    "updated_date": "2024-12-02 09:48:21 UTC"
  },
  {
    "arxiv_id": "2407.09493v1",
    "title": "Social AI and The Equation of Wittgenstein's Language User With Calvino's Literature Machine",
    "authors": [
      "W. J. T. Mollema"
    ],
    "abstract": "Is it sensical to ascribe psychological predicates to AI systems like\nchatbots based on large language models (LLMs)? People have intuitively started\nascribing emotions or consciousness to social AI ('affective artificial\nagents'), with consequences that range from love to suicide. The philosophical\nquestion of whether such ascriptions are warranted is thus very relevant. This\npaper advances the argument that LLMs instantiate language users in Ludwig\nWittgenstein's sense but that ascribing psychological predicates to these\nsystems remains a functionalist temptation. Social AIs are not full-blown\nlanguage users, but rather more like Italo Calvino's literature machines. The\nideas of LLMs as Wittgensteinian language users and Calvino's\nliterature-producing writing machine are combined. This sheds light on the\nmisguided functionalist temptation inherent in moving from equating the two to\nthe ascription of psychological predicates to social AI. Finally, the framework\nof mortal computation is used to show that social AIs lack the basic\nautopoiesis needed for narrative fa\\c{c}ons de parler and their role in the\nsensemaking of human (inter)action. Such psychological predicate ascriptions\ncould make sense: the transition 'from quantity to quality' can take place, but\nits route lies somewhere between life and death, not between affective\nartifacts and emotion approximation by literature machines.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.09493v1",
    "published_date": "2024-05-23 09:51:44 UTC",
    "updated_date": "2024-05-23 09:51:44 UTC"
  },
  {
    "arxiv_id": "2405.14374v1",
    "title": "State-Constrained Offline Reinforcement Learning",
    "authors": [
      "Charles A. Hepburn",
      "Yue Jin",
      "Giovanni Montana"
    ],
    "abstract": "Traditional offline reinforcement learning methods predominantly operate in a\nbatch-constrained setting. This confines the algorithms to a specific\nstate-action distribution present in the dataset, reducing the effects of\ndistributional shift but restricting the algorithm greatly. In this paper, we\nalleviate this limitation by introducing a novel framework named\n\\emph{state-constrained} offline reinforcement learning. By exclusively\nfocusing on the dataset's state distribution, our framework significantly\nenhances learning potential and reduces previous limitations. The proposed\nsetting not only broadens the learning horizon but also improves the ability to\ncombine different trajectories from the dataset effectively, a desirable\nproperty inherent in offline reinforcement learning. Our research is\nunderpinned by solid theoretical findings that pave the way for subsequent\nadvancements in this domain. Additionally, we introduce StaCQ, a deep learning\nalgorithm that is both performance-driven on the D4RL benchmark datasets and\nclosely aligned with our theoretical propositions. StaCQ establishes a strong\nbaseline for forthcoming explorations in state-constrained offline\nreinforcement learning.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14374v1",
    "published_date": "2024-05-23 09:50:04 UTC",
    "updated_date": "2024-05-23 09:50:04 UTC"
  },
  {
    "arxiv_id": "2405.14908v4",
    "title": "BiMix: A Bivariate Data Mixing Law for Language Model Pretraining",
    "authors": [
      "Ce Ge",
      "Zhijian Ma",
      "Daoyuan Chen",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "abstract": "Large language models have demonstrated remarkable capabilities across\nvarious tasks, primarily attributed to the utilization of diversely sourced\ndata. However, the impact of pretraining data composition on model performance\nremains poorly understood. This paper introduces $\\textbf{BiMix}$, a novel\nbivariate data mixing law that models the joint scaling behavior of domain\nproportions and data volume in LLM pretraining. $\\textbf{BiMix}$ provides a\nsystematic framework for understanding and optimizing data mixtures across\ndiverse domains. Through extensive experiments on two large-scale datasets, we\ndemonstrate $\\textbf{BiMix}$'s high accuracy in loss extrapolation (mean\nrelative error < 0.2%) and its generalization to unseen mixtures (R${}^{2}$ >\n0.97). Optimization of domain proportions yields superior model performance\ncompared to existing methods. Furthermore, we establish entropy-based measures\nas efficient proxies for data mixing, offering a computationally lightweight\nstrategy. Our work contributes both theoretical insights into data mixing\ndynamics and practical tools for enhancing LLM training efficiency, paving the\nway for more effective scaling strategies in language model development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Clarify details",
    "pdf_url": "http://arxiv.org/pdf/2405.14908v4",
    "published_date": "2024-05-23 09:44:02 UTC",
    "updated_date": "2025-01-27 11:25:33 UTC"
  },
  {
    "arxiv_id": "2405.14366v2",
    "title": "MiniCache: KV Cache Compression in Depth Dimension for Large Language Models",
    "authors": [
      "Akide Liu",
      "Jing Liu",
      "Zizheng Pan",
      "Yefei He",
      "Gholamreza Haffari",
      "Bohan Zhuang"
    ],
    "abstract": "A critical approach for efficiently deploying computationally demanding large\nlanguage models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value\nstates of previously generated tokens, significantly reducing the need for\nrepetitive computations and thereby lowering latency in autoregressive\ngeneration. However, the size of the KV cache grows linearly with sequence\nlength, posing challenges for applications requiring long context input and\nextensive sequence generation. In this paper, we present a simple yet effective\napproach, called MiniCache, to compress the KV cache across layers from a novel\ndepth perspective, significantly reducing the memory footprint for LLM\ninference. Our approach is based on the observation that KV cache states\nexhibit high similarity between the adjacent layers in the middle-to-deep\nportion of LLMs. To facilitate merging, we propose disentangling the states\ninto the magnitude and direction components, interpolating the directions of\nthe state vectors while preserving their lengths unchanged. Furthermore, we\nintroduce a token retention strategy to keep highly distinct state pairs\nunmerged, thus preserving the information with minimal additional storage\noverhead. Our MiniCache is training-free and general, complementing existing KV\ncache compression strategies, such as quantization and sparsity. We conduct a\ncomprehensive evaluation of MiniCache utilizing various models including\nLLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,\ndemonstrating its exceptional performance in achieving superior compression\nratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit\nMiniCache achieves a remarkable compression ratio of up to 5.02x, enhances\ninference throughput by approximately 5x, and reduces the memory footprint by\n41% compared to the FP16 full cache baseline, all while maintaining\nnear-lossless performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project is available at https://minicache.vmv.re",
    "pdf_url": "http://arxiv.org/pdf/2405.14366v2",
    "published_date": "2024-05-23 09:43:52 UTC",
    "updated_date": "2024-09-07 02:52:29 UTC"
  },
  {
    "arxiv_id": "2405.14365v1",
    "title": "JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models",
    "authors": [
      "Kun Zhou",
      "Beichen Zhang",
      "Jiapeng Wang",
      "Zhipeng Chen",
      "Wayne Xin Zhao",
      "Jing Sha",
      "Zhichao Sheng",
      "Shijin Wang",
      "Ji-Rong Wen"
    ],
    "abstract": "Mathematical reasoning is an important capability of large language\nmodels~(LLMs) for real-world applications. To enhance this capability, existing\nwork either collects large-scale math-related texts for pre-training, or relies\non stronger LLMs (\\eg GPT-4) to synthesize massive math problems. Both types of\nwork generally lead to large costs in training or synthesis. To reduce the\ncost, based on open-source available texts, we propose an efficient way that\ntrains a small LLM for math problem synthesis, to efficiently generate\nsufficient high-quality pre-training data. To achieve it, we create a dataset\nusing GPT-4 to distill its data synthesis capability into the small LLM.\nConcretely, we craft a set of prompts based on human education stages to guide\nGPT-4, to synthesize problems covering diverse math knowledge and difficulty\nlevels. Besides, we adopt the gradient-based influence estimation method to\nselect the most valuable math-related texts. The both are fed into GPT-4 for\ncreating the knowledge distillation dataset to train the small LLM. We leverage\nit to synthesize 6 million math problems for pre-training our JiuZhang3.0\nmodel, which only needs to invoke GPT-4 API 9.3k times and pre-train on 4.6B\ndata. Experimental results have shown that JiuZhang3.0 achieves\nstate-of-the-art performance on several mathematical reasoning datasets, under\nboth natural language reasoning and tool manipulation settings. Our code and\ndata will be publicly released in\n\\url{https://github.com/RUCAIBox/JiuZhang3.0}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, SOTA math LLM using Well-trained Data Synthesis LLM",
    "pdf_url": "http://arxiv.org/pdf/2405.14365v1",
    "published_date": "2024-05-23 09:43:19 UTC",
    "updated_date": "2024-05-23 09:43:19 UTC"
  },
  {
    "arxiv_id": "2405.14347v3",
    "title": "Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep Reinforcement Learning (CDRL) Approach",
    "authors": [
      "Zonghui Yang",
      "Shijian Gao",
      "Xiang Cheng"
    ],
    "abstract": "Integrated sensing and communication (ISAC) technology is essential for\nsupporting vehicular networks. However, the communication channel in this\nscenario exhibits time variations, and the potential targets may move rapidly,\nresulting in double dynamics. This nature poses a challenge for real-time\nprecoder design. While optimization-based solutions are widely researched, they\nare complex and heavily rely on perfect channel-related information, which is\nimpractical in double dynamics. To address this challenge, we propose using\nconstrained deep reinforcement learning to facilitate dynamic updates to the\nISAC precoder. Additionally, the primal dual-deep deterministic policy gradient\nand Wolpertinger architecture are tailored to efficiently train the algorithm\nunder complex constraints and varying numbers of users. The proposed scheme not\nonly adapts to the dynamics based on observations but also leverages\nenvironmental information to enhance performance and reduce complexity. Its\nsuperiority over existing candidates has been validated through experiments.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted by 2024 IEEE Global Communications Conference",
    "pdf_url": "http://arxiv.org/pdf/2405.14347v3",
    "published_date": "2024-05-23 09:19:14 UTC",
    "updated_date": "2024-08-23 15:31:28 UTC"
  },
  {
    "arxiv_id": "2405.14346v1",
    "title": "Mixture of Public and Private Distributions in Imperfect Information Games",
    "authors": [
      "Jérôme Arjonilla",
      "Abdallah Saffidine",
      "Tristan Cazenave"
    ],
    "abstract": "In imperfect information games (e.g. Bridge, Skat, Poker), one of the\nfundamental considerations is to infer the missing information while at the\nsame time avoiding the disclosure of private information. Disregarding the\nissue of protecting private information can lead to a highly exploitable\nperformance. Yet, excessive attention to it leads to hesitations that are no\nlonger consistent with our private information. In our work, we show that to\nimprove performance, one must choose whether to use a player's private\ninformation. We extend our work by proposing a new belief distribution\ndepending on the amount of private and public information desired. We\nempirically demonstrate an increase in performance and, with the aim of further\nimproving performance, the new distribution should be used according to the\nposition in the game. Our experiments have been done on multiple benchmarks and\nin multiple determinization-based algorithms (PIMC and IS-MCTS).",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in CoG 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.14346v1",
    "published_date": "2024-05-23 09:18:25 UTC",
    "updated_date": "2024-05-23 09:18:25 UTC"
  },
  {
    "arxiv_id": "2405.14333v1",
    "title": "DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data",
    "authors": [
      "Huajian Xin",
      "Daya Guo",
      "Zhihong Shao",
      "Zhizhou Ren",
      "Qihao Zhu",
      "Bo Liu",
      "Chong Ruan",
      "Wenda Li",
      "Xiaodan Liang"
    ],
    "abstract": "Proof assistants like Lean have revolutionized mathematical proof\nverification, ensuring high accuracy and reliability. Although large language\nmodels (LLMs) show promise in mathematical reasoning, their advancement in\nformal theorem proving is hindered by a lack of training data. To address this\nissue, we introduce an approach to generate extensive Lean 4 proof data derived\nfrom high-school and undergraduate-level mathematical competition problems.\nThis approach involves translating natural language problems into formal\nstatements, filtering out low-quality statements, and generating proofs to\ncreate synthetic data. After fine-tuning the DeepSeekMath 7B model on this\nsynthetic dataset, which comprises 8 million formal statements with proofs, our\nmodel achieved whole-proof generation accuracies of 46.3% with 64 samples and\n52% cumulatively on the Lean 4 miniF2F test, surpassing the baseline GPT-4 at\n23.0% with 64 samples and a tree search reinforcement learning method at 41.0%.\nAdditionally, our model successfully proved 5 out of 148 problems in the Lean 4\nFormalized International Mathematical Olympiad (FIMO) benchmark, while GPT-4\nfailed to prove any. These results demonstrate the potential of leveraging\nlarge-scale synthetic data to enhance theorem-proving capabilities in LLMs.\nBoth the synthetic dataset and the model will be made available to facilitate\nfurther research in this promising field.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14333v1",
    "published_date": "2024-05-23 09:03:42 UTC",
    "updated_date": "2024-05-23 09:03:42 UTC"
  },
  {
    "arxiv_id": "2405.14331v1",
    "title": "LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision",
    "authors": [
      "Mateusz Pach",
      "Dawid Rymarczyk",
      "Koryna Lewandowska",
      "Jacek Tabor",
      "Bartosz Zieliński"
    ],
    "abstract": "Prototypical parts networks combine the power of deep learning with the\nexplainability of case-based reasoning to make accurate, interpretable\ndecisions. They follow the this looks like that reasoning, representing each\nprototypical part with patches from training images. However, a single image\npatch comprises multiple visual features, such as color, shape, and texture,\nmaking it difficult for users to identify which feature is important to the\nmodel.\n  To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network\n(LucidPPN), a novel prototypical parts network that separates color prototypes\nfrom other visual features. Our method employs two reasoning branches: one for\nnon-color visual features, processing grayscale images, and another focusing\nsolely on color information. This separation allows us to clarify whether the\nmodel's decisions are based on color, shape, or texture. Additionally, LucidPPN\nidentifies prototypical parts corresponding to semantic parts of classified\nobjects, making comparisons between data classes more intuitive, e.g., when two\nbird species might differ primarily in belly color.\n  Our experiments demonstrate that the two branches are complementary and\ntogether achieve results comparable to baseline methods. More importantly,\nLucidPPN generates less ambiguous prototypical parts, enhancing user\nunderstanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in the review process. The code will be available upon\n  acceptance",
    "pdf_url": "http://arxiv.org/pdf/2405.14331v1",
    "published_date": "2024-05-23 09:00:59 UTC",
    "updated_date": "2024-05-23 09:00:59 UTC"
  },
  {
    "arxiv_id": "2405.17464v1",
    "title": "Data Valuation by Leveraging Global and Local Statistical Information",
    "authors": [
      "Xiaoling Zhou",
      "Ou Wu",
      "Michael K. Ng",
      "Hao Jiang"
    ],
    "abstract": "Data valuation has garnered increasing attention in recent years, given the\ncritical role of high-quality data in various applications, particularly in\nmachine learning tasks. There are diverse technical avenues to quantify the\nvalue of data within a corpus. While Shapley value-based methods are among the\nmost widely used techniques in the literature due to their solid theoretical\nfoundation, the accurate calculation of Shapley values is often intractable,\nleading to the proposal of numerous approximated calculation methods. Despite\nsignificant progress, nearly all existing methods overlook the utilization of\ndistribution information of values within a data corpus. In this paper, we\ndemonstrate that both global and local statistical information of value\ndistributions hold significant potential for data valuation within the context\nof machine learning. Firstly, we explore the characteristics of both global and\nlocal value distributions across several simulated and real data corpora.\nUseful observations and clues are obtained. Secondly, we propose a new data\nvaluation method that estimates Shapley values by incorporating the explored\ndistribution characteristics into an existing method, AME. Thirdly, we present\na new path to address the dynamic data valuation problem by formulating an\noptimization problem that integrates information of both global and local value\ndistributions. Extensive experiments are conducted on Shapley value estimation,\nvalue-based data removal/adding, mislabeled data detection, and\nincremental/decremental data valuation. The results showcase the effectiveness\nand efficiency of our proposed methodologies, affirming the significant\npotential of global and local value distributions in data valuation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2306.10577 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2405.17464v1",
    "published_date": "2024-05-23 08:58:08 UTC",
    "updated_date": "2024-05-23 08:58:08 UTC"
  },
  {
    "arxiv_id": "2405.14327v5",
    "title": "Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI",
    "authors": [
      "Guanxiong Luo",
      "Shoujin Huang",
      "Martin Uecker"
    ],
    "abstract": "Magnetic resonance imaging (MRI) is a widely used non-invasive imaging\nmodality. However, a persistent challenge lies in balancing image quality with\nimaging speed. This trade-off is primarily constrained by k-space measurements,\nwhich traverse specific trajectories in the spatial Fourier domain (k-space).\nThese measurements are often undersampled to shorten acquisition times,\nresulting in image artifacts and compromised quality. Generative models learn\nimage distributions and can be used to reconstruct high-quality images from\nundersampled k-space data. In this work, we present the autoregressive image\ndiffusion (AID) model for image sequences and use it to sample the posterior\nfor accelerated MRI reconstruction. The algorithm incorporates both\nundersampled k-space and pre-existing information. Models trained with fastMRI\ndataset are evaluated comprehensively. The results show that the AID model can\nrobustly generate sequentially coherent image sequences. In MRI applications,\nthe AID can outperform the standard diffusion model and reduce hallucinations,\ndue to the learned inter-image dependencies. The project code is available at\nhttps://github.com/mrirecon/aid.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14327v5",
    "published_date": "2024-05-23 08:57:10 UTC",
    "updated_date": "2025-01-06 18:50:35 UTC"
  },
  {
    "arxiv_id": "2405.14314v2",
    "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration",
    "authors": [
      "Yang Zhang",
      "Shixin Yang",
      "Chenjia Bai",
      "Fei Wu",
      "Xiu Li",
      "Zhen Wang",
      "Xuelong Li"
    ],
    "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied\ntasks is challenging due to the complexity of the physical world. Especially,\nLLM planning for multi-agent collaboration requires communication of agents or\ncredit assignment as the feedback to re-adjust the proposed plans and achieve\neffective coordination. However, existing methods that overly rely on physical\nverification or self-reflection suffer from excessive and inefficient querying\nof LLMs. In this paper, we propose a novel framework for multi-agent\ncollaboration that introduces Reinforced Advantage feedback (ReAd) for\nefficient self-refinement of plans. Specifically, we perform critic regression\nto learn a sequential advantage function from LLM-planned data, and then treat\nthe LLM planner as an optimizer to generate actions that maximize the advantage\nfunction. It endows the LLM with the foresight to discern whether the action\ncontributes to accomplishing the final task. We provide theoretical analysis by\nextending advantage-weighted regression in reinforcement learning to\nmulti-agent systems. Experiments on Overcooked-AI and a difficult variant of\nRoCoBench show that ReAd surpasses baselines in success rate, and also\nsignificantly decreases the interaction steps of agents and query rounds of\nLLMs, demonstrating its high efficiency for grounding LLMs. More results are\ngiven at https://read-llm.github.io/.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2405.14314v2",
    "published_date": "2024-05-23 08:33:19 UTC",
    "updated_date": "2024-05-26 02:31:15 UTC"
  },
  {
    "arxiv_id": "2405.14307v1",
    "title": "AdaGMLP: AdaBoosting GNN-to-MLP Knowledge Distillation",
    "authors": [
      "Weigang Lu",
      "Ziyu Guan",
      "Wei Zhao",
      "Yaming Yang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have revolutionized graph-based machine\nlearning, but their heavy computational demands pose challenges for\nlatency-sensitive edge devices in practical industrial applications. In\nresponse, a new wave of methods, collectively known as GNN-to-MLP Knowledge\nDistillation, has emerged. They aim to transfer GNN-learned knowledge to a more\nefficient MLP student, which offers faster, resource-efficient inference while\nmaintaining competitive performance compared to GNNs. However, these methods\nface significant challenges in situations with insufficient training data and\nincomplete test data, limiting their applicability in real-world applications.\nTo address these challenges, we propose AdaGMLP, an AdaBoosting GNN-to-MLP\nKnowledge Distillation framework. It leverages an ensemble of diverse MLP\nstudents trained on different subsets of labeled nodes, addressing the issue of\ninsufficient training data. Additionally, it incorporates a Node Alignment\ntechnique for robust predictions on test data with missing or incomplete\nfeatures. Our experiments on seven benchmark datasets with different settings\ndemonstrate that AdaGMLP outperforms existing G2M methods, making it suitable\nfor a wide range of latency-sensitive real-world applications. We have\nsubmitted our code to the GitHub repository\n(https://github.com/WeigangLu/AdaGMLP-KDD24).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14307v1",
    "published_date": "2024-05-23 08:28:44 UTC",
    "updated_date": "2024-05-23 08:28:44 UTC"
  },
  {
    "arxiv_id": "2407.12690v2",
    "title": "The Dual Imperative: Innovation and Regulation in the AI Era",
    "authors": [
      "Paulo Carvão"
    ],
    "abstract": "This article addresses the societal costs associated with the lack of\nregulation in Artificial Intelligence and proposes a framework combining\ninnovation and regulation. Over fifty years of AI research, catalyzed by\ndeclining computing costs and the proliferation of data, have propelled AI into\nthe mainstream, promising significant economic benefits. Yet, this rapid\nadoption underscores risks, from bias amplification and labor disruptions to\nexistential threats posed by autonomous systems. The discourse is polarized\nbetween accelerationists, advocating for unfettered technological advancement,\nand doomers, calling for a slowdown to prevent dystopian outcomes. This piece\nadvocates for a middle path that leverages technical innovation and smart\nregulation to maximize the benefits of AI while minimizing its risks, offering\na pragmatic approach to the responsible progress of AI technology. Technical\ninvention beyond the most capable foundation models is needed to contain\ncatastrophic risks. Regulation is required to create incentives for this\nresearch while addressing current issues.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SI",
      "K.4.1; K.5.2"
    ],
    "primary_category": "cs.CY",
    "comment": "This is an original manuscript of an article published by\n  Inderscience in the International Journal of Technology Policy and Law Vol.\n  3, No. 3 on November 28, 2024, available online:\n  https://doi.org/10.1504/IJTPL.2024.142861",
    "pdf_url": "http://arxiv.org/pdf/2407.12690v2",
    "published_date": "2024-05-23 08:26:25 UTC",
    "updated_date": "2025-02-13 13:02:07 UTC"
  },
  {
    "arxiv_id": "2405.14297v4",
    "title": "Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models",
    "authors": [
      "Yongxin Guo",
      "Zhenglin Cheng",
      "Xiaoying Tang",
      "Zhaopeng Tu",
      "Tao Lin"
    ],
    "abstract": "The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the\nefficiency of training and inference for Transformer-based foundational models,\nyielding promising results.However, the performance of SMoE heavily depends on\nthe choice of hyper-parameters, such as the number of experts and the number of\nexperts to be activated (referred to as top-k), resulting in significant\ncomputational overhead due to the extensive model training by searching over\nvarious hyper-parameter configurations. As a remedy, we introduce the Dynamic\nMixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating\nmethod that enables each token to automatically determine the number of experts\nto activate. (2) An adaptive process automatically adjusts the number of\nexperts during training. Extensive numerical results across Vision, Language,\nand Vision-Language tasks demonstrate the effectiveness of our approach to\nachieve competitive performance compared to GMoE for vision and language tasks,\nand MoE-LLaVA for vision-language tasks, while maintaining efficiency by\nactivating fewer parameters. Our code is available at\nhttps://github.com/LINs-lab/DynMoE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.14297v4",
    "published_date": "2024-05-23 08:18:30 UTC",
    "updated_date": "2025-03-10 09:17:56 UTC"
  },
  {
    "arxiv_id": "2405.14291v1",
    "title": "Variational Bayes for Federated Continual Learning",
    "authors": [
      "Dezhong Yao",
      "Sanmu Li",
      "Yutong Dai",
      "Zhiqiang Xu",
      "Shengshan Hu",
      "Peilin Zhao",
      "Lichao Sun"
    ],
    "abstract": "Federated continual learning (FCL) has received increasing attention due to\nits potential in handling real-world streaming data, characterized by evolving\ndata distributions and varying client classes over time. The constraints of\nstorage limitations and privacy concerns confine local models to exclusively\naccess the present data within each learning cycle. Consequently, this\nrestriction induces performance degradation in model training on previous data,\ntermed \"catastrophic forgetting\". However, existing FCL approaches need to\nidentify or know changes in data distribution, which is difficult in the real\nworld. To release these limitations, this paper directs attention to a broader\ncontinuous framework. Within this framework, we introduce Federated Bayesian\nNeural Network (FedBNN), a versatile and efficacious framework employing a\nvariational Bayesian neural network across all clients. Our method continually\nintegrates knowledge from local and historical data distributions into a single\nmodel, adeptly learning from new data distributions while retaining performance\non historical distributions. We rigorously evaluate FedBNN's performance\nagainst prevalent methods in federated learning and continual learning using\nvarious metrics. Experimental analyses across diverse datasets demonstrate that\nFedBNN achieves state-of-the-art results in mitigating forgetting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14291v1",
    "published_date": "2024-05-23 08:09:21 UTC",
    "updated_date": "2024-05-23 08:09:21 UTC"
  },
  {
    "arxiv_id": "2405.14286v2",
    "title": "Co-Representation Neural Hypergraph Diffusion for Edge-Dependent Node Classification",
    "authors": [
      "Yijia Zheng",
      "Marcel Worring"
    ],
    "abstract": "Hypergraphs are widely employed to represent complex higher-order relations\nin real-world applications. Most hypergraph learning research focuses on\nnode-level or edge-level tasks. A practically relevant but more challenging\ntask, edge-dependent node classification (ENC), is only recently proposed. In\nENC, a node can have different labels across different hyperedges, which\nrequires the modeling of node-edge pairs instead of single nodes or hyperedges.\nExisting solutions for this task are based on message passing and model\ninteractions in within-edge and within-node structures as multi-input\nsingle-output functions. This brings three limitations: (1) non-adaptive\nrepresentation size, (2) non-adaptive messages, and (3) insufficient direct\ninteractions among nodes or edges. To tackle these limitations, we propose\nCoNHD, a new ENC solution that models both within-edge and within-node\ninteractions as multi-input multi-output functions. Specifically, we represent\nthese interactions as a hypergraph diffusion process on node-edge\nco-representations. We further develop a neural implementation for this\ndiffusion process, which can adapt to a specific ENC dataset. Extensive\nexperiments demonstrate the effectiveness and efficiency of the proposed CoNHD\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14286v2",
    "published_date": "2024-05-23 08:01:25 UTC",
    "updated_date": "2024-10-02 21:21:55 UTC"
  },
  {
    "arxiv_id": "2405.14273v1",
    "title": "A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP",
    "authors": [
      "Akira Kitaoka"
    ],
    "abstract": "This paper tackles the problem of minimizing the prediction loss of the\noptimal solution (PLS) of the MILP with given data, which is one of the inverse\noptimization problems. While existing methods can approximately solve this\nproblem, their implementation in the high-dimensional case to minimize the PLS\nis computationally expensive because they are inefficient in reducing the\nprediction loss of weights (PLW). We propose a fast algorithm for minimizing\nthe PLS of MILP. To demonstrate this property, we attribute the problem of\nminimizing the PLS to that of minimizing the suboptimality loss (SL), which is\nconvex. If the PLS does not vanish, we can adapt the SL to have the estimated\nloss (SPO loss) with a positive lower bound, which enables us to evaluate the\nPLW. Consequently, we prove that the proposed algorithm can effectively reduce\nthe PLW and achieve the minimum value of PLS. Our numerical experiments\ndemonstrated that our algorithm successfully achieved the minimum PLS. Compared\nto existing methods, our algorithm exhibited a smaller dimensionality effect\nand minimized the PLS in less than 1/7 the number of iterations. Especially in\nhigh dimensions, our algorithm significantly improved the PLS by more than two\norders of magnitude compared to existing algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages; comments are welcome",
    "pdf_url": "http://arxiv.org/pdf/2405.14273v1",
    "published_date": "2024-05-23 07:51:05 UTC",
    "updated_date": "2024-05-23 07:51:05 UTC"
  },
  {
    "arxiv_id": "2405.14270v1",
    "title": "Sparse $L^1$-Autoencoders for Scientific Data Compression",
    "authors": [
      "Matthias Chung",
      "Rick Archibald",
      "Paul Atzberger",
      "Jack Michael Solomon"
    ],
    "abstract": "Scientific datasets present unique challenges for machine learning-driven\ncompression methods, including more stringent requirements on accuracy and\nmitigation of potential invalidating artifacts. Drawing on results from\ncompressed sensing and rate-distortion theory, we introduce effective data\ncompression methods by developing autoencoders using high dimensional latent\nspaces that are $L^1$-regularized to obtain sparse low dimensional\nrepresentations. We show how these information-rich latent spaces can be used\nto mitigate blurring and other artifacts to obtain highly effective data\ncompression methods for scientific data. We demonstrate our methods for short\nangle scattering (SAS) datasets showing they can achieve compression ratios\naround two orders of magnitude and in some cases better. Our compression\nmethods show promise for use in addressing current bottlenecks in transmission,\nstorage, and analysis in high-performance distributed computing environments.\nThis is central to processing the large volume of SAS data being generated at\nshared experimental facilities around the world to support scientific\ninvestigations. Our approaches provide general ways for obtaining specialized\ncompression methods for targeted scientific datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14270v1",
    "published_date": "2024-05-23 07:48:00 UTC",
    "updated_date": "2024-05-23 07:48:00 UTC"
  },
  {
    "arxiv_id": "2405.14268v1",
    "title": "Multi-Representation Genetic Programming: A Case Study on Tree-based and Linear Representations",
    "authors": [
      "Zhixing Huang",
      "Yi Mei",
      "Fangfang Zhang",
      "Mengjie Zhang",
      "Wolfgang Banzhaf"
    ],
    "abstract": "Existing genetic programming (GP) methods are typically designed based on a\ncertain representation, such as tree-based or linear representations. These\nrepresentations show various pros and cons in different domains. However, due\nto the complicated relationships among representation and fitness landscapes of\nGP, it is hard to intuitively determine which GP representation is the most\nsuitable for solving a certain problem. Evolving programs (or models) with\nmultiple representations simultaneously can alternatively search on different\nfitness landscapes since representations are highly related to the search space\nthat essentially defines the fitness landscape. Fully using the latent\nsynergies among different GP individual representations might be helpful for GP\nto search for better solutions. However, existing GP literature rarely\ninvestigates the simultaneous effective use of evolving multiple\nrepresentations. To fill this gap, this paper proposes a multi-representation\nGP algorithm based on tree-based and linear representations, which are two\ncommonly used GP representations. In addition, we develop a new\ncross-representation crossover operator to harness the interplay between\ntree-based and linear representations. Empirical results show that navigating\nthe learned knowledge between basic tree-based and linear representations\nsuccessfully improves the effectiveness of GP with solely tree-based or linear\nrepresentation in solving symbolic regression and dynamic job shop scheduling\nproblems.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14268v1",
    "published_date": "2024-05-23 07:47:06 UTC",
    "updated_date": "2024-05-23 07:47:06 UTC"
  },
  {
    "arxiv_id": "2405.14267v2",
    "title": "A Gap in Time: The Challenge of Processing Heterogeneous IoT Data in Digitalized Buildings",
    "authors": [
      "Xiachong Lin",
      "Arian Prabowo",
      "Imran Razzak",
      "Hao Xue",
      "Matthew Amos",
      "Sam Behrens",
      "Flora D. Salim"
    ],
    "abstract": "The increasing demand for sustainable energy solutions has driven the\nintegration of digitalized buildings into the power grid, leveraging\nInternet-of-Things (IoT) technologies to enhance energy efficiency and\noperational performance. Despite their potential, effectively utilizing IoT\npoint data within deep-learning frameworks presents significant challenges,\nprimarily due to its inherent heterogeneity. This study investigates the\ndiverse dimensions of IoT data heterogeneity in both intra-building and\ninter-building contexts, examining their implications for predictive modeling.\nA benchmarking analysis of state-of-the-art time series models highlights their\nperformance on this complex dataset. The results emphasize the critical need\nfor multi-modal data integration, domain-informed modeling, and automated data\nengineering pipelines. Additionally, the study advocates for collaborative\nefforts to establish high-quality public datasets, which are essential for\nadvancing intelligent and sustainable energy management systems in digitalized\nbuildings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 figures, 1 tables, 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.14267v2",
    "published_date": "2024-05-23 07:45:48 UTC",
    "updated_date": "2024-11-20 06:50:50 UTC"
  },
  {
    "arxiv_id": "2405.14265v1",
    "title": "Deep Reinforcement Learning for 5*5 Multiplayer Go",
    "authors": [
      "Brahim Driss",
      "Jérôme Arjonilla",
      "Hui Wang",
      "Abdallah Saffidine",
      "Tristan Cazenave"
    ],
    "abstract": "In recent years, much progress has been made in computer Go and most of the\nresults have been obtained thanks to search algorithms (Monte Carlo Tree\nSearch) and Deep Reinforcement Learning (DRL). In this paper, we propose to use\nand analyze the latest algorithms that use search and DRL (AlphaZero and\nDescent algorithms) to automatically learn to play an extended version of the\ngame of Go with more than two players. We show that using search and DRL we\nwere able to improve the level of play, even though there are more than two\nplayers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in EvoApps at Evostar2023",
    "pdf_url": "http://arxiv.org/pdf/2405.14265v1",
    "published_date": "2024-05-23 07:44:24 UTC",
    "updated_date": "2024-05-23 07:44:24 UTC"
  },
  {
    "arxiv_id": "2405.14264v2",
    "title": "Reassessing Evaluation Functions in Algorithmic Recourse: An Empirical Study from a Human-Centered Perspective",
    "authors": [
      "Tomu Tominaga",
      "Naomi Yamashita",
      "Takeshi Kurashima"
    ],
    "abstract": "In this study, we critically examine the foundational premise of algorithmic\nrecourse - a process of generating counterfactual action plans (i.e.,\nrecourses) assisting individuals to reverse adverse decisions made by AI\nsystems. The assumption underlying algorithmic recourse is that individuals\naccept and act on recourses that minimize the gap between their current and\ndesired states. This assumption, however, remains empirically unverified. To\naddress this issue, we conducted a user study with 362 participants and\nassessed whether minimizing the distance function, a metric of the gap between\nthe current and desired states, indeed prompts them to accept and act upon\nsuggested recourses. Our findings reveal a nuanced landscape: participants'\nacceptance of recourses did not correlate with the recourse distance. Moreover,\nparticipants' willingness to act upon recourses peaked at the minimal recourse\ndistance but was otherwise constant. These findings cast doubt on the\nprevailing assumption of algorithmic recourse research and signal the need to\nrethink the evaluation functions to pave the way for human-centered recourse\ngeneration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IJCAI 2024 (this is the extended version with\n  supplementary materials)",
    "pdf_url": "http://arxiv.org/pdf/2405.14264v2",
    "published_date": "2024-05-23 07:43:24 UTC",
    "updated_date": "2024-08-03 12:46:57 UTC"
  },
  {
    "arxiv_id": "2405.14260v2",
    "title": "Graph Sparsification via Mixture of Graphs",
    "authors": [
      "Guibin Zhang",
      "Xiangguo Sun",
      "Yanwei Yue",
      "Chonghe Jiang",
      "Kun Wang",
      "Tianlong Chen",
      "Shirui Pan"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated superior performance across\nvarious graph learning tasks but face significant computational challenges when\napplied to large-scale graphs. One effective approach to mitigate these\nchallenges is graph sparsification, which involves removing non-essential edges\nto reduce computational overhead. However, previous graph sparsification\nmethods often rely on a single global sparsity setting and uniform pruning\ncriteria, failing to provide customized sparsification schemes for each node's\ncomplex local context. In this paper, we introduce Mixture-of-Graphs (MoG),\nleveraging the concept of Mixture-of-Experts (MoE), to dynamically select\ntailored pruning solutions for each node. Specifically, MoG incorporates\nmultiple sparsifier experts, each characterized by unique sparsity levels and\npruning criteria, and selects the appropriate experts for each node.\nSubsequently, MoG performs a mixture of the sparse graphs produced by different\nexperts on the Grassmann manifold to derive an optimal sparse graph. One\nnotable property of MoG is its entirely local nature, as it depends on the\nspecific circumstances of each individual node. Extensive experiments on four\nlarge-scale OGB datasets and two superpixel datasets, equipped with five GNN\nbackbones, demonstrate that MoG (I) identifies subgraphs at higher sparsity\nlevels ($8.67\\%\\sim 50.85\\%$), with performance equal to or better than the\ndense graph, (II) achieves $1.47-2.62\\times$ speedup in GNN inference with\nnegligible performance drop, and (III) boosts ``top-student'' GNN performance\n($1.02\\%\\uparrow$ on RevGNN+\\textsc{ogbn-proteins} and $1.74\\%\\uparrow$ on\nDeeperGCN+\\textsc{ogbg-ppa}).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14260v2",
    "published_date": "2024-05-23 07:40:21 UTC",
    "updated_date": "2024-10-03 12:42:40 UTC"
  },
  {
    "arxiv_id": "2405.14259v3",
    "title": "Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Multi-modal Text Recognition",
    "authors": [
      "Chan-Jan Hsu",
      "Yi-Chang Chen",
      "Feng-Ting Liao",
      "Pei-Chen Ho",
      "Yu-Hsiang Wang",
      "Po-Chun Hsu",
      "Da-shan Shiu"
    ],
    "abstract": "We introduce \"Generative Fusion Decoding\" (GFD), a novel shallow fusion\nframework, utilized to integrate Large Language Models (LLMs) into multi-modal\ntext recognition systems such as automatic speech recognition (ASR) and optical\ncharacter recognition (OCR). We derive the formulas necessary to enable GFD to\noperate across mismatched token spaces of different models by mapping text\ntoken space to byte token space, enabling seamless fusion during the decoding\nprocess. The framework is plug-and-play, compatible with various\nauto-regressive models, and does not require re-training for feature alignment,\nthus overcoming limitations of previous fusion techniques. We highlight three\nmain advantages of GFD: First, by simplifying the complexity of aligning\ndifferent model sample spaces, GFD allows LLMs to correct errors in tandem with\nthe recognition model, reducing computation latencies. Second, the in-context\nlearning ability of LLMs is fully capitalized by GFD, increasing robustness in\nlong-form speech recognition and instruction aware speech recognition. Third,\nGFD enables fusing recognition models deficient in Chinese text recognition\nwith LLMs extensively trained on Chinese. Our evaluation demonstrates that GFD\nsignificantly improves performance in ASR and OCR tasks, with ASR reaching\nstate-of-the-art in the NTUML2021 benchmark. GFD provides a significant step\nforward in model integration, offering a unified solution that could be widely\napplicable to leveraging existing pre-trained models through step by step\nfusion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14259v3",
    "published_date": "2024-05-23 07:39:42 UTC",
    "updated_date": "2024-06-02 16:30:00 UTC"
  },
  {
    "arxiv_id": "2405.14256v1",
    "title": "ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification",
    "authors": [
      "Yefei He",
      "Luoming Zhang",
      "Weijia Wu",
      "Jing Liu",
      "Hong Zhou",
      "Bohan Zhuang"
    ],
    "abstract": "KV cache stores key and value states from previous tokens to avoid\nre-computation, yet it demands substantial storage space, especially for long\nsequences. Adaptive KV cache compression seeks to discern the saliency of\ntokens, preserving vital information while aggressively compressing those of\nless importance. However, previous methods of this approach exhibit significant\nperformance degradation at high compression ratios due to inaccuracies in\nidentifying salient tokens. In this paper, we present ZipCache, an accurate and\nefficient KV cache quantization method for LLMs. First, we construct a strong\nbaseline for quantizing KV cache. Through the proposed channel-separable\ntokenwise quantization scheme, the memory overhead of quantization parameters\nare substantially reduced compared to fine-grained groupwise quantization. To\nenhance the compression ratio, we propose normalized attention score as an\neffective metric for identifying salient tokens by considering the lower\ntriangle characteristics of the attention matrix. Moreover, we develop an\nefficient approximation method that decouples the saliency metric from full\nattention scores, enabling compatibility with fast attention implementations\nlike FlashAttention. Extensive experiments demonstrate that ZipCache achieves\nsuperior compression ratios, fast generation speed and minimal performance\nlosses compared with previous KV cache compression methods. For instance, when\nevaluating Mistral-7B model on GSM8k dataset, ZipCache is capable of\ncompressing the KV cache by $4.98\\times$, with only a $0.38\\%$ drop in\naccuracy. In terms of efficiency, ZipCache also showcases a $37.3\\%$ reduction\nin prefill-phase latency, a $56.9\\%$ reduction in decoding-phase latency, and a\n$19.8\\%$ reduction in GPU memory usage when evaluating LLaMA3-8B model with a\ninput length of $4096$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.14256v1",
    "published_date": "2024-05-23 07:37:16 UTC",
    "updated_date": "2024-05-23 07:37:16 UTC"
  },
  {
    "arxiv_id": "2405.14244v2",
    "title": "Tell me why: Training preferences-based RL with human preferences and step-level explanations",
    "authors": [
      "Jakob Karalus"
    ],
    "abstract": "Human-in-the-loop reinforcement learning allows the training of agents\nthrough various interfaces, even for non-expert humans. Recently,\npreference-based methods (PbRL), where the human has to give his preference\nover two trajectories, increased in popularity since they allow training in\ndomains where more direct feedback is hard to formulate. However, the current\nPBRL methods have limitations and do not provide humans with an expressive\ninterface for giving feedback. With this work, we propose a new\npreference-based learning method that provides humans with a more expressive\ninterface to provide their preference over trajectories and a factual\nexplanation (or annotation of why they have this preference). These\nexplanations allow the human to explain what parts of the trajectory are most\nrelevant for the preference. We allow the expression of the explanations over\nindividual trajectory steps. We evaluate our method in various simulations\nusing a simulated human oracle (with realistic restrictions), and our results\nshow that our extended feedback can improve the speed of learning.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Workshop on Reinforcement Learning Beyond Rewards @ Reinforcement\n  Learning Conference (2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.14244v2",
    "published_date": "2024-05-23 07:23:33 UTC",
    "updated_date": "2024-08-05 12:59:32 UTC"
  },
  {
    "arxiv_id": "2405.14241v1",
    "title": "NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation",
    "authors": [
      "Chaokang Jiang",
      "Dalong Du",
      "Jiuming Liu",
      "Siting Zhu",
      "Zhenqiang Liu",
      "Zhuang Ma",
      "Zhujin Liang",
      "Jie Zhou"
    ],
    "abstract": "Point Cloud Interpolation confronts challenges from point sparsity, complex\nspatiotemporal dynamics, and the difficulty of deriving complete 3D point\nclouds from sparse temporal information. This paper presents NeuroGauss4D-PCI,\nwhich excels at modeling complex non-rigid deformations across varied dynamic\nscenes. The method begins with an iterative Gaussian cloud soft clustering\nmodule, offering structured temporal point cloud representations. The proposed\ntemporal radial basis function Gaussian residual utilizes Gaussian parameter\ninterpolation over time, enabling smooth parameter transitions and capturing\ntemporal residuals of Gaussian distributions. Additionally, a 4D Gaussian\ndeformation field tracks the evolution of these parameters, creating continuous\nspatiotemporal deformation fields. A 4D neural field transforms low-dimensional\nspatiotemporal coordinates ($x,y,z,t$) into a high-dimensional latent space.\nFinally, we adaptively and efficiently fuse the latent features from neural\nfields and the geometric features from Gaussian deformation fields.\nNeuroGauss4D-PCI outperforms existing methods in point cloud frame\ninterpolation, delivering leading performance on both object-level (DHB) and\nlarge-scale autonomous driving datasets (NL-Drive), with scalability to\nauto-labeling and point cloud densification tasks. The source code is released\nat https://github.com/jiangchaokang/NeuroGauss4D-PCI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.14241v1",
    "published_date": "2024-05-23 07:21:01 UTC",
    "updated_date": "2024-05-23 07:21:01 UTC"
  },
  {
    "arxiv_id": "2406.00019v3",
    "title": "EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records",
    "authors": [
      "Jaehee Ryu",
      "Seonhee Cho",
      "Gyubok Lee",
      "Edward Choi"
    ],
    "abstract": "In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL\ndataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to\naddress critical yet underexplored aspects in text-to-SQL parsing:\ninteractivity, compositionality, and efficiency. To the best of our knowledge,\nEHR-SeqSQL is not only the largest but also the first medical text-to-SQL\ndataset benchmark to include sequential and contextual questions. We provide a\ndata split and the new test set designed to assess compositional generalization\nability. Our experiments demonstrate the superiority of a multi-turn approach\nover a single-turn approach in learning compositionality. Additionally, our\ndataset integrates specially crafted tokens into SQL queries to improve\nexecution efficiency. With EHR-SeqSQL, we aim to bridge the gap between\npractical needs and academic research in the text-to-SQL domain. EHR-SeqSQL is\navailable at https://github.com/seonhee99/EHR-SeqSQL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2406.00019v3",
    "published_date": "2024-05-23 07:14:21 UTC",
    "updated_date": "2024-07-30 10:09:13 UTC"
  },
  {
    "arxiv_id": "2405.14230v1",
    "title": "Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports",
    "authors": [
      "Guangyu Guo",
      "Jiawen Yao",
      "Yingda Xia",
      "Tony C. W. Mok",
      "Zhilin Zheng",
      "Junwei Han",
      "Le Lu",
      "Dingwen Zhang",
      "Jian Zhou",
      "Ling Zhang"
    ],
    "abstract": "The absence of adequately sufficient expert-level tumor annotations hinders\nthe effectiveness of supervised learning based opportunistic cancer screening\non medical imaging. Clinical reports (that are rich in descriptive textual\ndetails) can offer a \"free lunch'' supervision information and provide tumor\nlocation as a type of weak label to cope with screening tasks, thus saving\nhuman labeling workloads, if properly leveraged. However, predicting cancer\nonly using such weak labels can be very changeling since tumors are usually\npresented in small anatomical regions compared to the whole 3D medical scans.\nWeakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level\ntumor annotations and incorporates alongside a substantial number of medical\nimages that have only off-the-shelf clinical reports, which may strike a good\nbalance between minimizing expert annotation workload and optimizing screening\nefficacy. In this paper, we propose a novel text-guided learning method to\nachieve highly accurate cancer detection results. Through integrating\ndiagnostic and tumor location text prompts into the text encoder of a\nvision-language model (VLM), optimization of weakly supervised learning can be\neffectively performed in the latent space of VLM, thereby enhancing the\nstability of training. Our approach can leverage clinical knowledge by\nlarge-scale pre-trained VLM to enhance generalization ability, and produce\nreliable pseudo tumor masks to improve cancer detection. Our extensive\nquantitative experimental results on a large-scale cancer dataset, including\n1,651 unique patients, validate that our approach can reduce human annotation\nefforts by at least 70% while maintaining comparable cancer detection accuracy\nto competing fully supervised methods (AUC value 0.961 versus 0.966).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14230v1",
    "published_date": "2024-05-23 07:03:38 UTC",
    "updated_date": "2024-05-23 07:03:38 UTC"
  },
  {
    "arxiv_id": "2405.14226v2",
    "title": "Variational Delayed Policy Optimization",
    "authors": [
      "Qingyuan Wu",
      "Simon Sinong Zhan",
      "Yixuan Wang",
      "Yuhui Wang",
      "Chung-Wei Lin",
      "Chen Lv",
      "Qi Zhu",
      "Chao Huang"
    ],
    "abstract": "In environments with delayed observation, state augmentation by including\nactions within the delay window is adopted to retrieve Markovian property to\nenable reinforcement learning (RL). However, state-of-the-art (SOTA) RL\ntechniques with Temporal-Difference (TD) learning frameworks often suffer from\nlearning inefficiency, due to the significant expansion of the augmented state\nspace with the delay. To improve learning efficiency without sacrificing\nperformance, this work introduces a novel framework called Variational Delayed\nPolicy Optimization (VDPO), which reformulates delayed RL as a variational\ninference problem. This problem is further modelled as a two-step iterative\noptimization problem, where the first step is TD learning in the delay-free\nenvironment with a small state space, and the second step is behaviour cloning\nwhich can be addressed much more efficiently than TD learning. We not only\nprovide a theoretical analysis of VDPO in terms of sample complexity and\nperformance, but also empirically demonstrate that VDPO can achieve consistent\nperformance with SOTA methods, with a significant enhancement of sample\nefficiency (approximately 50\\% less amount of samples) in the MuJoCo benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.14226v2",
    "published_date": "2024-05-23 06:57:04 UTC",
    "updated_date": "2024-10-21 20:10:37 UTC"
  },
  {
    "arxiv_id": "2405.14219v2",
    "title": "Understanding the Training and Generalization of Pretrained Transformer for Sequential Decision Making",
    "authors": [
      "Hanzhao Wang",
      "Yu Pan",
      "Fupeng Sun",
      "Shang Liu",
      "Kalyan Talluri",
      "Guanting Chen",
      "Xiaocheng Li"
    ],
    "abstract": "In this paper, we consider the supervised pre-trained transformer for a class\nof sequential decision-making problems. The class of considered problems is a\nsubset of the general formulation of reinforcement learning in that there is no\ntransition probability matrix; though seemingly restrictive, the subset class\nof problems covers bandits, dynamic pricing, and newsvendor problems as special\ncases. Such a structure enables the use of optimal actions/decisions in the\npre-training phase, and the usage also provides new insights for the training\nand generalization of the pre-trained transformer. We first note the training\nof the transformer model can be viewed as a performative prediction problem,\nand the existing methods and theories largely ignore or cannot resolve an\nout-of-distribution issue. We propose a natural solution that includes the\ntransformer-generated action sequences in the training procedure, and it enjoys\nbetter properties both numerically and theoretically. The availability of the\noptimal actions in the considered tasks also allows us to analyze the\nproperties of the pre-trained transformer as an algorithm and explains why it\nmay lack exploration and how this can be automatically resolved. Numerically,\nwe categorize the advantages of pre-trained transformers over the structured\nalgorithms such as UCB and Thompson sampling into three cases: (i) it better\nutilizes the prior knowledge in the pre-training data; (ii) it can elegantly\nhandle the misspecification issue suffered by the structured algorithms; (iii)\nfor short time horizon such as $T\\le50$, it behaves more greedy and enjoys much\nbetter regret than the structured algorithms designed for asymptotic\noptimality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14219v2",
    "published_date": "2024-05-23 06:28:44 UTC",
    "updated_date": "2024-10-02 12:45:50 UTC"
  },
  {
    "arxiv_id": "2405.14214v1",
    "title": "A Behavior-Aware Approach for Deep Reinforcement Learning in Non-stationary Environments without Known Change Points",
    "authors": [
      "Zihe Liu",
      "Jie Lu",
      "Guangquan Zhang",
      "Junyu Xuan"
    ],
    "abstract": "Deep reinforcement learning is used in various domains, but usually under the\nassumption that the environment has stationary conditions like transitions and\nstate distributions. When this assumption is not met, performance suffers. For\nthis reason, tracking continuous environmental changes and adapting to\nunpredictable conditions is challenging yet crucial because it ensures that\nsystems remain reliable and flexible in practical scenarios. Our research\nintroduces Behavior-Aware Detection and Adaptation (BADA), an innovative\nframework that merges environmental change detection with behavior adaptation.\nThe key inspiration behind our method is that policies exhibit different global\nbehaviors in changing environments. Specifically, environmental changes are\nidentified by analyzing variations between behaviors using Wasserstein\ndistances without manually set thresholds. The model adapts to the new\nenvironment through behavior regularization based on the extent of changes. The\nresults of a series of experiments demonstrate better performance relative to\nseveral current algorithms. This research also indicates significant potential\nfor tackling this long-standing challenge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14214v1",
    "published_date": "2024-05-23 06:17:26 UTC",
    "updated_date": "2024-05-23 06:17:26 UTC"
  },
  {
    "arxiv_id": "2405.14205v4",
    "title": "Agent Planning with World Knowledge Model",
    "authors": [
      "Shuofei Qiao",
      "Runnan Fang",
      "Ningyu Zhang",
      "Yuqi Zhu",
      "Xiang Chen",
      "Shumin Deng",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen"
    ],
    "abstract": "Recent endeavors towards directly using large language models (LLMs) as agent\nmodels to execute interactive planning tasks have shown commendable results.\nDespite their achievements, however, they still struggle with brainless\ntrial-and-error in global planning and generating hallucinatory actions in\nlocal planning due to their poor understanding of the ``real'' physical world.\nImitating humans' mental world knowledge model which provides global prior\nknowledge before the task and maintains local dynamic knowledge during the\ntask, in this paper, we introduce parametric World Knowledge Model (WKM) to\nfacilitate agent planning. Concretely, we steer the agent model to\nself-synthesize knowledge from both expert and sampled trajectories. Then we\ndevelop WKM, providing prior task knowledge to guide the global planning and\ndynamic state knowledge to assist the local planning. Experimental results on\nthree complex real-world simulated datasets with three state-of-the-art\nopen-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our\nmethod can achieve superior performance compared to various strong baselines.\nBesides, we analyze to illustrate that our WKM can effectively alleviate the\nblind trial-and-error and hallucinatory action issues, providing strong support\nfor the agent's understanding of the world. Other interesting findings include:\n1) our instance-level task knowledge can generalize better to unseen tasks, 2)\nweak WKM can guide strong agent model planning, and 3) unified WKM training has\npromising potential for further development. The code is available at\nhttps://github.com/zjunlp/WKM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14205v4",
    "published_date": "2024-05-23 06:03:19 UTC",
    "updated_date": "2025-01-03 16:44:55 UTC"
  },
  {
    "arxiv_id": "2405.14203v1",
    "title": "GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices",
    "authors": [
      "Thao Nguyen",
      "Tiara Torres-Flores",
      "Changhyun Hwang",
      "Carl Edwards",
      "Ying Diao",
      "Heng Ji"
    ],
    "abstract": "This paper presents a novel approach for predicting Power Conversion\nEfficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:\nsynergizing molecular Graphs and Language Descriptors for enhanced PCE\nprediction. Due to the lack of high-quality experimental data, we collect a\ndataset consisting of 500 pairs of OPV donor and acceptor molecules along with\ntheir corresponding PCE values, which we utilize as the training data for our\npredictive model. In this low-data regime, GLaD leverages properties learned\nfrom large language models (LLMs) pretrained on extensive scientific literature\nto enrich molecular structural representations, allowing for a multimodal\nrepresentation of molecules. GLaD achieves precise predictions of PCE, thereby\nfacilitating the synthesis of new OPV molecules with improved efficiency.\nFurthermore, GLaD showcases versatility, as it applies to a range of molecular\nproperty prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited to\nthose concerning OPV materials. Especially, GLaD proves valuable for tasks in\nlow-data regimes within the chemical space, as it enriches molecular\nrepresentations by incorporating molecular property descriptions learned from\nlarge-scale pretraining. This capability is significant in real-world\nscientific endeavors like drug and material discovery, where access to\ncomprehensive data is crucial for informed decision-making and efficient\nexploration of the chemical space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "In progress",
    "pdf_url": "http://arxiv.org/pdf/2405.14203v1",
    "published_date": "2024-05-23 06:02:07 UTC",
    "updated_date": "2024-05-23 06:02:07 UTC"
  },
  {
    "arxiv_id": "2405.14200v2",
    "title": "Awesome Multi-modal Object Tracking",
    "authors": [
      "Chunhui Zhang",
      "Li Liu",
      "Hao Wen",
      "Xi Zhou",
      "Yanfeng Wang"
    ],
    "abstract": "Multi-modal object tracking (MMOT) is an emerging field that combines data\nfrom various modalities, \\eg vision (RGB), depth, thermal infrared, event,\nlanguage and audio, to estimate the state of an arbitrary object in a video\nsequence. It is of great significance for many applications such as autonomous\ndriving and intelligent surveillance. In recent years, MMOT has received more\nand more attention. However, existing MMOT algorithms mainly focus on two\nmodalities (\\eg RGB+depth, RGB+thermal infrared, and RGB+language). To leverage\nmore modalities, some recent efforts have been made to learn a unified visual\nobject tracking model for any modality. Additionally, some large-scale\nmulti-modal tracking benchmarks have been established by simultaneously\nproviding more than two modalities, such as vision-language-audio (\\eg\nWebUAV-3M) and vision-depth-language (\\eg UniMod1K). To track the latest\nprogress in MMOT, we conduct a comprehensive investigation in this report.\nSpecifically, we first divide existing MMOT tasks into five main categories,\n\\ie RGBL tracking, RGBE tracking, RGBD tracking, RGBT tracking, and\nmiscellaneous (RGB+X), where X can be any modality, such as language, depth,\nand event. Then, we analyze and summarize each MMOT task, focusing on widely\nused datasets and mainstream tracking algorithms based on their technical\nparadigms (\\eg self-supervised learning, prompt learning, knowledge\ndistillation, generative models, and state space models). Finally, we maintain\na continuously updated paper list for MMOT at\nhttps://github.com/983632847/Awesome-Multimodal-Object-Tracking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A continuously updated project to track the latest progress in\n  multi-modal object tracking",
    "pdf_url": "http://arxiv.org/pdf/2405.14200v2",
    "published_date": "2024-05-23 05:58:10 UTC",
    "updated_date": "2024-05-31 11:09:59 UTC"
  },
  {
    "arxiv_id": "2405.14195v1",
    "title": "Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning",
    "authors": [
      "Zhenyu Wei",
      "Yujie He",
      "Zhanchuan Cai"
    ],
    "abstract": "RGB-D tracking significantly improves the accuracy of object tracking.\nHowever, its dependency on real depth inputs and the complexity involved in\nmulti-modal fusion limit its applicability across various scenarios. The\nutilization of depth information in RGB-D tracking inspired us to propose a new\nmethod, named MDETrack, which trains a tracking network with an additional\ncapability to understand the depth of scenes, through supervised or\nself-supervised auxiliary Monocular Depth Estimation learning. The outputs of\nMDETrack's unified feature extractor are fed to the side-by-side tracking head\nand auxiliary depth estimation head, respectively. The auxiliary module will be\ndiscarded in inference, thus keeping the same inference speed. We evaluated our\nmodels with various training strategies on multiple datasets, and the results\nshow an improved tracking accuracy even without real depth. Through these\nfindings we highlight the potential of depth estimation in enhancing object\ntracking performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14195v1",
    "published_date": "2024-05-23 05:43:38 UTC",
    "updated_date": "2024-05-23 05:43:38 UTC"
  },
  {
    "arxiv_id": "2405.14194v1",
    "title": "Graphlets correct for the topological information missed by random walks",
    "authors": [
      "Sam F. L. Windels",
      "Noel Malod-Dognin",
      "Natasa Przulj"
    ],
    "abstract": "Random walks are widely used for mining networks due to the computational\nefficiency of computing them. For instance, graph representation learning\nlearns a d-dimensional embedding space, so that the nodes that tend to co-occur\non random walks (a proxy of being in the same network neighborhood) are close\nin the embedding space. Specific local network topology (i.e., structure)\ninfluences the co-occurrence of nodes on random walks, so random walks of\nlimited length capture only partial topological information, hence diminishing\nthe performance of downstream methods. We explicitly capture all topological\nneighborhood information and improve performance by introducing orbit\nadjacencies that quantify the adjacencies of two nodes as co-occurring on a\ngiven pair of graphlet orbits, which are symmetric positions on graphlets\n(small, connected, non-isomorphic, induced subgraphs of a large network).\nImportantly, we mathematically prove that random walks on up to k nodes capture\nonly a subset of all the possible orbit adjacencies for up to k-node graphlets.\nFurthermore, we enable orbit adjacency-based analysis of networks by developing\nan efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively\ncomputes all 28 orbit adjacency matrices for up to four-node graphlets. Note\nthat four-node graphlets suffice, because real networks are usually\nsmall-world. In large networks on around 20,000 nodes,\nGRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we\ncompare the performance of node-label predictors obtained by using the network\nembeddings based on our orbit adjacencies to those based on random walks. We\nfind that orbit adjacencies, which include those unseen by random walks,\noutperform random walk-based adjacencies, demonstrating the importance of the\ninclusion of the topological neighborhood information that is unseen by random\nwalks.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.DS",
      "cs.LG",
      "68Uxx",
      "I.5"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14194v1",
    "published_date": "2024-05-23 05:42:38 UTC",
    "updated_date": "2024-05-23 05:42:38 UTC"
  },
  {
    "arxiv_id": "2405.14176v1",
    "title": "Certified Robustness against Sparse Adversarial Perturbations via Data Localization",
    "authors": [
      "Ambar Pal",
      "René Vidal",
      "Jeremias Sulam"
    ],
    "abstract": "Recent work in adversarial robustness suggests that natural data\ndistributions are localized, i.e., they place high probability in small volume\nregions of the input space, and that this property can be utilized for\ndesigning classifiers with improved robustness guarantees for $\\ell_2$-bounded\nperturbations. Yet, it is still unclear if this observation holds true for more\ngeneral metrics. In this work, we extend this theory to $\\ell_0$-bounded\nadversarial perturbations, where the attacker can modify a few pixels of the\nimage but is unrestricted in the magnitude of perturbation, and we show\nnecessary and sufficient conditions for the existence of $\\ell_0$-robust\nclassifiers. Theoretical certification approaches in this regime essentially\nemploy voting over a large ensemble of classifiers. Such procedures are\ncombinatorial and expensive or require complicated certification techniques. In\ncontrast, a simple classifier emerges from our theory, dubbed Box-NN, which\nnaturally incorporates the geometry of the problem and improves upon the\ncurrent state-of-the-art in certified robustness against sparse attacks for the\nMNIST and Fashion-MNIST datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14176v1",
    "published_date": "2024-05-23 05:02:00 UTC",
    "updated_date": "2024-05-23 05:02:00 UTC"
  },
  {
    "arxiv_id": "2405.14173v3",
    "title": "Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication",
    "authors": [
      "Shenghui Chen",
      "Daniel Fried",
      "Ufuk Topcu"
    ],
    "abstract": "Developing autonomous agents that can strategize and cooperate with humans\nunder information asymmetry is challenging without effective communication in\nnatural language. We introduce a shared-control game, where two players\ncollectively control a token in alternating turns to achieve a common objective\nunder incomplete information. We formulate a policy synthesis problem for an\nautonomous agent in this game with a human as the other player. To solve this\nproblem, we propose a communication-based approach comprising a language module\nand a planning module. The language module translates natural language messages\ninto and from a finite set of flags, a compact representation defined to\ncapture player intents. The planning module leverages these flags to compute a\npolicy using an asymmetric information-set Monte Carlo tree search with flag\nexchange algorithm we present. We evaluate the effectiveness of this approach\nin a testbed based on Gnomes at Night, a search-and-find maze board game.\nResults of human subject experiments show that communication narrows the\ninformation gap between players and enhances human-agent cooperation efficiency\nwith fewer turns.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "with appendix",
    "pdf_url": "http://arxiv.org/pdf/2405.14173v3",
    "published_date": "2024-05-23 04:58:42 UTC",
    "updated_date": "2024-06-01 20:06:55 UTC"
  },
  {
    "arxiv_id": "2405.14170v3",
    "title": "Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Jiapu Wang",
      "Kai Sun",
      "Linhao Luo",
      "Wei Wei",
      "Yongli Hu",
      "Alan Wee-Chung Liew",
      "Shirui Pan",
      "Baocai Yin"
    ],
    "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing\ntemporal information to capture complex relations within a Temporal Knowledge\nGraph (TKG) to infer new knowledge. Conventional methods in TKGR typically\ndepend on deep learning algorithms or temporal logical rules. However, deep\nlearning-based TKGRs often lack interpretability, whereas rule-based TKGRs\nstruggle to effectively learn temporal rules that capture temporal patterns.\nRecently, Large Language Models (LLMs) have demonstrated extensive knowledge\nand remarkable proficiency in temporal reasoning. Consequently, the employment\nof LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing\ninterest among researchers. Nonetheless, LLMs are known to function as black\nboxes, making it challenging to comprehend their reasoning process.\nAdditionally, due to the resource-intensive nature of fine-tuning, promptly\nupdating LLMs to integrate evolving knowledge within TKGs for reasoning is\nimpractical. To address these challenges, in this paper, we propose a Large\nLanguage Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on\nTKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze\nhistorical data and extract temporal logical rules. These rules unveil temporal\npatterns and facilitate interpretable reasoning. To account for the evolving\nnature of TKGs, a dynamic adaptation strategy is proposed to update the\nLLM-generated rules with the latest events. This ensures that the extracted\nrules always incorporate the most recent knowledge and better generalize to the\npredictions on future events. Experimental results show that without the need\nof fine-tuning, LLM-DA significantly improves the accuracy of reasoning over\nseveral common datasets, providing a robust framework for TKGR tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14170v3",
    "published_date": "2024-05-23 04:54:37 UTC",
    "updated_date": "2024-12-30 00:53:45 UTC"
  },
  {
    "arxiv_id": "2405.17460v1",
    "title": "Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks",
    "authors": [
      "Yafeng Yan",
      "Shuyao He",
      "Zhou Yu",
      "Jiajie Yuan",
      "Ziang Liu",
      "Yan Chen"
    ],
    "abstract": "Aiming at the limitations of traditional medical decision system in\nprocessing large-scale heterogeneous medical data and realizing highly\npersonalized recommendation, this paper introduces a personalized medical\ndecision algorithm utilizing graph neural network (GNN). This research\ninnovatively integrates graph neural network technology into the medical and\nhealth field, aiming to build a high-precision representation model of patient\nhealth status by mining the complex association between patients' clinical\ncharacteristics, genetic information, living habits. In this study, medical\ndata is preprocessed to transform it into a graph structure, where nodes\nrepresent different data entities (such as patients, diseases, genes, etc.) and\nedges represent interactions or relationships between entities. The core of the\nalgorithm is to design a novel multi-scale fusion mechanism, combining the\nhistorical medical records, physiological indicators and genetic\ncharacteristics of patients, to dynamically adjust the attention allocation\nstrategy of the graph neural network, so as to achieve highly customized\nanalysis of individual cases. In the experimental part, this study selected\nseveral publicly available medical data sets for validation, and the results\nshowed that compared with traditional machine learning methods and a single\ngraph neural network model, the proposed personalized medical decision\nalgorithm showed significantly superior performance in terms of disease\nprediction accuracy, treatment effect evaluation and patient risk\nstratification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17460v1",
    "published_date": "2024-05-23 04:30:41 UTC",
    "updated_date": "2024-05-23 04:30:41 UTC"
  },
  {
    "arxiv_id": "2405.14161v1",
    "title": "Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models",
    "authors": [
      "Yuchen Hu",
      "Chen Chen",
      "Chao-Han Huck Yang",
      "Chengwei Qin",
      "Pin-Yu Chen",
      "Eng Siong Chng",
      "Chao Zhang"
    ],
    "abstract": "We propose an unsupervised adaptation framework, Self-TAught Recognizer\n(STAR), which leverages unlabeled data to enhance the robustness of automatic\nspeech recognition (ASR) systems in diverse target domains, such as noise and\naccents. STAR is developed for prevalent speech foundation models based on\nTransformer-related architecture with auto-regressive decoding (e.g., Whisper,\nCanary). Specifically, we propose a novel indicator that empirically integrates\nstep-wise information during decoding to assess the token-level quality of\npseudo labels without ground truth, thereby guiding model updates for effective\nunsupervised adaptation. Experimental results show that STAR achieves an\naverage of 13.5% relative reduction in word error rate across 14 target\ndomains, and it sometimes even approaches the upper-bound performance of\nsupervised adaptation. Surprisingly, we also observe that STAR prevents the\nadapted model from the common catastrophic forgetting problem without recalling\nsource-domain data. Furthermore, STAR exhibits high data efficiency that only\nrequires less than one-hour unlabeled data, and seamless generality to\nalternative large speech models and speech translation tasks. Our code aims to\nopen source to the research communities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, Preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.14161v1",
    "published_date": "2024-05-23 04:27:11 UTC",
    "updated_date": "2024-05-23 04:27:11 UTC"
  },
  {
    "arxiv_id": "2405.14159v2",
    "title": "Super Tiny Language Models",
    "authors": [
      "Dylan Hillier",
      "Leon Guertler",
      "Cheston Tan",
      "Palaash Agrawal",
      "Chen Ruirui",
      "Bobby Cheng"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has led to significant\nimprovements in natural language processing but also poses challenges due to\ntheir high computational and energy demands. This paper introduces a series of\nresearch efforts focused on Super Tiny Language Models (STLMs), which aim to\ndeliver high performance with significantly reduced parameter counts. We\nexplore innovative techniques such as byte-level tokenization with a pooling\nmechanism, weight tying, and efficient training strategies. These methods aim\nto significantly reduce reduce the parameter count compared to traditional\nmodels -- in future works, we aim to build on these in a way that maintains and\nimproves upon the performance of base transformer models. This series of papers\nwill explore into various subproblems, including tokenizer-free models,\nself-play based training, and alternative training objectives. We will target\nmodels with 10M, 50M, and 100M parameters. Our ultimate goal is to make\nhigh-performance language models more accessible and practical for a wide range\nof applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14159v2",
    "published_date": "2024-05-23 04:12:49 UTC",
    "updated_date": "2024-06-26 08:41:06 UTC"
  },
  {
    "arxiv_id": "2405.14148v1",
    "title": "Real Time Deep Learning Weapon Detection Techniques for Mitigating Lone Wolf Attacks",
    "authors": [
      "Kambhatla Akhila",
      "Khaled R Ahmed"
    ],
    "abstract": "Firearm Shootings and stabbings attacks are intense and result in severe\ntrauma and threat to public safety. Technology is needed to prevent lone-wolf\nattacks without human supervision. Hence designing an automatic weapon\ndetection using deep learning, is an optimized solution to localize and detect\nthe presence of weapon objects using Neural Networks. This research focuses on\nboth unified and II-stage object detectors whose resultant model not only\ndetects the presence of weapons but also classifies with respective to its\nweapon classes, including handgun, knife, revolver, and rifle, along with\nperson detection. This research focuses on (You Look Only Once) family and\nFaster RCNN family for model validation and training. Pruning and Ensembling\ntechniques were applied to YOLOv5 to enhance their speed and performance.\nmodels achieve the highest score of 78% with an inference speed of 8.1ms.\nHowever, Faster R-CNN models achieve the highest AP 89%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14148v1",
    "published_date": "2024-05-23 03:48:26 UTC",
    "updated_date": "2024-05-23 03:48:26 UTC"
  },
  {
    "arxiv_id": "2405.14147v1",
    "title": "Minimum number of neurons in fully connected layers of a given neural network (the first approximation)",
    "authors": [
      "Oleg I. Berngardt"
    ],
    "abstract": "This paper presents an algorithm for searching for the minimum number of\nneurons in fully connected layers of an arbitrary network solving given\nproblem, which does not require multiple training of the network with different\nnumber of neurons. The algorithm is based at training the initial wide network\nusing the cross-validation method over at least two folds. Then by using\ntruncated singular value decomposition autoencoder inserted after the studied\nlayer of trained network we search the minimum number of neurons in inference\nonly mode of the network.\n  It is shown that the minimum number of neurons in a fully connected layer\ncould be interpreted not as network hyperparameter associated with the other\nhyperparameters of the network, but as internal (latent) property of the\nsolution, determined by the network architecture, the training dataset, layer\nposition, and the quality metric used. So the minimum number of neurons can be\nestimated for each hidden fully connected layer independently. The proposed\nalgorithm is the first approximation for estimating the minimum number of\nneurons in the layer, since, on the one hand, the algorithm does not guarantee\nthat a neural network with the found number of neurons can be trained to the\nrequired quality, and on the other hand, it searches for the minimum number of\nneurons in a limited class of possible solutions.\n  The solution was tested on several datasets in classification and regression\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.14147v1",
    "published_date": "2024-05-23 03:46:07 UTC",
    "updated_date": "2024-05-23 03:46:07 UTC"
  },
  {
    "arxiv_id": "2405.14142v2",
    "title": "Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation",
    "authors": [
      "Se-eun Yoon",
      "Hyunsik Jeon",
      "Julian McAuley"
    ],
    "abstract": "We introduce a multimodal dataset where users express preferences through\nimages. These images encompass a broad spectrum of visual expressions ranging\nfrom landscapes to artistic depictions. Users request recommendations for books\nor music that evoke similar feelings to those captured in the images, and\nrecommendations are endorsed by the community through upvotes. This dataset\nsupports two recommendation tasks: title generation and multiple-choice\nselection. Our experiments with large foundation models reveal their\nlimitations in these tasks. Particularly, vision-language models show no\nsignificant advantage over language-only counterparts that use descriptions,\nwhich we hypothesize is due to underutilized visual capabilities. To better\nharness these abilities, we propose the chain-of-imagery prompting, which\nresults in notable improvements. We release our code and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14142v2",
    "published_date": "2024-05-23 03:36:31 UTC",
    "updated_date": "2025-04-16 02:53:42 UTC"
  },
  {
    "arxiv_id": "2405.14135v3",
    "title": "Space-aware Socioeconomic Indicator Inference with Heterogeneous Graphs",
    "authors": [
      "Xingchen Zou",
      "Jiani Huang",
      "Xixuan Hao",
      "Yuhao Yang",
      "Haomin Wen",
      "Yibo Yan",
      "Chao Huang",
      "Chao Chen",
      "Yuxuan Liang"
    ],
    "abstract": "Regional socioeconomic indicators are critical across various domains, yet\ntheir acquisition can be costly. Inferring global socioeconomic indicators from\na limited number of regional samples is essential for enhancing management and\nsustainability in urban areas and human settlements. Current inference methods\ntypically rely on spatial interpolation based on the assumption of spatial\ncontinuity, which does not adequately address the complex variations present\nwithin regional spaces. In this paper, we present GeoHG, the first space-aware\nsocioeconomic indicator inference method that utilizes a heterogeneous\ngraph-based structure to represent geospace for non-continuous inference.\nExtensive experiments demonstrate the effectiveness of GeoHG in comparison to\nexisting methods, achieving an $R^2$ score exceeding 0.8 under extreme data\nscarcity with a masked ratio of 95\\%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14135v3",
    "published_date": "2024-05-23 03:19:02 UTC",
    "updated_date": "2025-02-17 07:52:16 UTC"
  },
  {
    "arxiv_id": "2405.14133v1",
    "title": "Automated Loss function Search for Class-imbalanced Node Classification",
    "authors": [
      "Xinyu Guo",
      "Kai Wu",
      "Xiaoyu Zhang",
      "Jing Liu"
    ],
    "abstract": "Class-imbalanced node classification tasks are prevalent in real-world\nscenarios. Due to the uneven distribution of nodes across different classes,\nlearning high-quality node representations remains a challenging endeavor. The\nengineering of loss functions has shown promising potential in addressing this\nissue. It involves the meticulous design of loss functions, utilizing\ninformation about the quantities of nodes in different categories and the\nnetwork's topology to learn unbiased node representations. However, the design\nof these loss functions heavily relies on human expert knowledge and exhibits\nlimited adaptability to specific target tasks. In this paper, we introduce a\nhigh-performance, flexible, and generalizable automated loss function search\nframework to tackle this challenge. Across 15 combinations of graph neural\nnetworks and datasets, our framework achieves a significant improvement in\nperformance compared to state-of-the-art methods. Additionally, we observe that\nhomophily in graph-structured data significantly contributes to the\ntransferability of the proposed framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14133v1",
    "published_date": "2024-05-23 03:12:49 UTC",
    "updated_date": "2024-05-23 03:12:49 UTC"
  },
  {
    "arxiv_id": "2405.14129v2",
    "title": "AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability",
    "authors": [
      "Fei Zhao",
      "Taotian Pang",
      "Chunhui Li",
      "Zhen Wu",
      "Junjie Guo",
      "Shangyu Xing",
      "Xinyu Dai"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are widely regarded as crucial in\nthe exploration of Artificial General Intelligence (AGI). The core of MLLMs\nlies in their capability to achieve cross-modal alignment. To attain this goal,\ncurrent MLLMs typically follow a two-phase training paradigm: the pre-training\nphase and the instruction-tuning phase. Despite their success, there are\nshortcomings in the modeling of alignment capabilities within these models.\nFirstly, during the pre-training phase, the model usually assumes that all\nimage-text pairs are uniformly aligned, but in fact the degree of alignment\nbetween different image-text pairs is inconsistent. Secondly, the instructions\ncurrently used for finetuning incorporate a variety of tasks and different\ntasks usually require different levels of alignment capabilities, but previous\nMLLMs overlook these differentiated alignment needs. To tackle these issues, we\npropose a new multimodal large language model AlignGPT. In the pre-training\nstage, instead of treating all image-text pairs equally, we divide them into\ndifferent groups according to the degrees of alignment of them. Then, the model\nis trained to learn the representations of different alignment levels. In the\ninstruction-tuning phase, we adaptively combine these representations of\nalignment levels to meet the dynamic alignment needs of different tasks.\nExtensive experimental results show that our model achieves competitive\nperformance on 12 benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14129v2",
    "published_date": "2024-05-23 03:07:56 UTC",
    "updated_date": "2024-11-23 14:38:05 UTC"
  },
  {
    "arxiv_id": "2405.14126v1",
    "title": "The Disappearance of Timestep Embedding in Modern Time-Dependent Neural Networks",
    "authors": [
      "Bum Jun Kim",
      "Yoshinobu Kawahara",
      "Sang Woo Kim"
    ],
    "abstract": "Dynamical systems are often time-varying, whose modeling requires a function\nthat evolves with respect to time. Recent studies such as the neural ordinary\ndifferential equation proposed a time-dependent neural network, which provides\na neural network varying with respect to time. However, we claim that the\narchitectural choice to build a time-dependent neural network significantly\naffects its time-awareness but still lacks sufficient validation in its current\nstates. In this study, we conduct an in-depth analysis of the architecture of\nmodern time-dependent neural networks. Here, we report a vulnerability of\nvanishing timestep embedding, which disables the time-awareness of a\ntime-dependent neural network. Furthermore, we find that this vulnerability can\nalso be observed in diffusion models because they employ a similar architecture\nthat incorporates timestep embedding to discriminate between different\ntimesteps during a diffusion process. Our analysis provides a detailed\ndescription of this phenomenon as well as several solutions to address the root\ncause. Through experiments on neural ordinary differential equations and\ndiffusion models, we observed that ensuring alive time-awareness via proposed\nsolutions boosted their performance, which implies that their current\nimplementations lack sufficient time-dependency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14126v1",
    "published_date": "2024-05-23 02:58:23 UTC",
    "updated_date": "2024-05-23 02:58:23 UTC"
  },
  {
    "arxiv_id": "2405.14125v3",
    "title": "ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation",
    "authors": [
      "Jingnan Zheng",
      "Han Wang",
      "An Zhang",
      "Tai D. Nguyen",
      "Jun Sun",
      "Tat-Seng Chua"
    ],
    "abstract": "Large Language Models (LLMs) can elicit unintended and even harmful content\nwhen misaligned with human values, posing severe risks to users and society. To\nmitigate these risks, current evaluation benchmarks predominantly employ\nexpert-designed contextual scenarios to assess how well LLMs align with human\nvalues. However, the labor-intensive nature of these benchmarks limits their\ntest scope, hindering their ability to generalize to the extensive variety of\nopen-world use cases and identify rare but crucial long-tail risks.\nAdditionally, these static tests fail to adapt to the rapid evolution of LLMs,\nmaking it hard to evaluate timely alignment issues. To address these\nchallenges, we propose ALI-Agent, an evaluation framework that leverages the\nautonomous abilities of LLM-powered agents to conduct in-depth and adaptive\nalignment assessments. ALI-Agent operates through two principal stages:\nEmulation and Refinement. During the Emulation stage, ALI-Agent automates the\ngeneration of realistic test scenarios. In the Refinement stage, it iteratively\nrefines the scenarios to probe long-tail risks. Specifically, ALI-Agent\nincorporates a memory module to guide test scenario generation, a tool-using\nmodule to reduce human labor in tasks such as evaluating feedback from target\nLLMs, and an action module to refine tests. Extensive experiments across three\naspects of human values--stereotypes, morality, and legality--demonstrate that\nALI-Agent, as a general evaluation framework, effectively identifies model\nmisalignment. Systematic analysis also validates that the generated test\nscenarios represent meaningful use cases, as well as integrate enhanced\nmeasures to probe long-tail risks. Our code is available at\nhttps://github.com/SophieZheng998/ALI-Agent.git",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14125v3",
    "published_date": "2024-05-23 02:57:42 UTC",
    "updated_date": "2024-11-07 12:07:07 UTC"
  },
  {
    "arxiv_id": "2405.14906v1",
    "title": "AutoCoder: Enhancing Code Large Language Model with \\textsc{AIEV-Instruct}",
    "authors": [
      "Bin Lei",
      "Yuchen Li",
      "Qiuwu Chen"
    ],
    "abstract": "We introduce AutoCoder, the first Large Language Model to surpass GPT-4 Turbo\n(April 2024) and GPT-4o in pass@1 on the Human Eval benchmark test\n($\\mathbf{90.9\\%}$ vs. $\\mathbf{90.2\\%}$). In addition, AutoCoder offers a more\nversatile code interpreter compared to GPT-4 Turbo and GPT-4o. It's code\ninterpreter can install external packages instead of limiting to built-in\npackages. AutoCoder's training data is a multi-turn dialogue dataset created by\na system combining agent interaction and external code execution verification,\na method we term \\textbf{\\textsc{AIEV-Instruct}} (Instruction Tuning with\nAgent-Interaction and Execution-Verified). Compared to previous large-scale\ncode dataset generation methods, \\textsc{AIEV-Instruct} reduces dependence on\nproprietary large models and provides execution-validated code dataset. The\ncode and the demo video is available in\n\\url{https://github.com/bin123apple/AutoCoder}.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14906v1",
    "published_date": "2024-05-23 02:53:25 UTC",
    "updated_date": "2024-05-23 02:53:25 UTC"
  },
  {
    "arxiv_id": "2405.14117v2",
    "title": "Knowledge Localization: Mission Not Accomplished? Enter Query Localization!",
    "authors": [
      "Yuheng Chen",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Large language models (LLMs) store extensive factual knowledge, but the\nmechanisms behind how they store and express this knowledge remain unclear. The\nKnowledge Neuron (KN) thesis is a prominent theory for explaining these\nmechanisms. This theory is based on the Knowledge Localization (KL) assumption,\nwhich suggests that a fact can be localized to a few knowledge storage units,\nnamely knowledge neurons.\n  However, this assumption has two limitations: first, it may be too rigid\nregarding knowledge storage, and second, it neglects the role of the attention\nmodule in knowledge expression.\n  In this paper, we first re-examine the KL assumption and demonstrate that its\nlimitations do indeed exist. To address these, we then present two new\nfindings, each targeting one of the limitations: one focusing on knowledge\nstorage and the other on knowledge expression. We summarize these findings as\n\\textbf{Query Localization} (QL) assumption and argue that the KL assumption\ncan be viewed as a simplification of the QL assumption. Based on QL assumption,\nwe further propose the Consistency-Aware KN modification method, which improves\nthe performance of knowledge modification, further validating our new\nassumption. We conduct 39 sets of experiments, along with additional\nvisualization experiments, to rigorously confirm our conclusions. Code is\navailable at https://github.com/heng840/KnowledgeLocalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2405.14117v2",
    "published_date": "2024-05-23 02:44:12 UTC",
    "updated_date": "2025-02-27 12:29:11 UTC"
  },
  {
    "arxiv_id": "2405.14115v1",
    "title": "Configuring Data Augmentations to Reduce Variance Shift in Positional Embedding of Vision Transformers",
    "authors": [
      "Bum Jun Kim",
      "Sang Woo Kim"
    ],
    "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance in a\nvariety of vision tasks. Despite their promising capabilities, training a ViT\nrequires a large amount of diverse data. Several studies empirically found that\nusing rich data augmentations, such as Mixup, Cutmix, and random erasing, is\ncritical to the successful training of ViTs. Now, the use of rich data\naugmentations has become a standard practice in the current state. However, we\nreport a vulnerability to this practice: Certain data augmentations such as\nMixup cause a variance shift in the positional embedding of ViT, which has been\na hidden factor that degrades the performance of ViT during the test phase. We\nclaim that achieving a stable effect from positional embedding requires a\nspecific condition on the image, which is often broken for the current data\naugmentation methods. We provide a detailed analysis of this problem as well as\nthe correct configuration for these data augmentations to remove the side\neffects of variance shift. Experiments showed that adopting our guidelines\nimproves the performance of ViTs compared with the current configuration of\ndata augmentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14115v1",
    "published_date": "2024-05-23 02:42:32 UTC",
    "updated_date": "2024-05-23 02:42:32 UTC"
  },
  {
    "arxiv_id": "2405.14114v2",
    "title": "Offline Reinforcement Learning from Datasets with Structured Non-Stationarity",
    "authors": [
      "Johannes Ackermann",
      "Takayuki Osa",
      "Masashi Sugiyama"
    ],
    "abstract": "Current Reinforcement Learning (RL) is often limited by the large amount of\ndata needed to learn a successful policy. Offline RL aims to solve this issue\nby using transitions collected by a different behavior policy. We address a\nnovel Offline RL problem setting in which, while collecting the dataset, the\ntransition and reward functions gradually change between episodes but stay\nconstant within each episode. We propose a method based on Contrastive\nPredictive Coding that identifies this non-stationarity in the offline dataset,\naccounts for it when training a policy, and predicts it during evaluation. We\nanalyze our proposed method and show that it performs well in simple continuous\ncontrol tasks and challenging, high-dimensional locomotion tasks. We show that\nour method often achieves the oracle performance and performs better than\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for Reinforcement Learning Conference (RLC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14114v2",
    "published_date": "2024-05-23 02:41:36 UTC",
    "updated_date": "2024-05-28 03:11:52 UTC"
  },
  {
    "arxiv_id": "2405.14108v5",
    "title": "Deep Learning for Protein-Ligand Docking: Are We There Yet?",
    "authors": [
      "Alex Morehead",
      "Nabin Giri",
      "Jian Liu",
      "Pawan Neupane",
      "Jianlin Cheng"
    ],
    "abstract": "The effects of ligand binding on protein structures and their in vivo\nfunctions carry numerous implications for modern biomedical research and\nbiotechnology development efforts such as drug discovery. Although several deep\nlearning (DL) methods and benchmarks designed for protein-ligand docking have\nrecently been introduced, to date no prior works have systematically studied\nthe behavior of the latest docking and structure prediction methods within the\nbroadly applicable context of (1) using predicted (apo) protein structures for\ndocking (e.g., for applicability to new proteins); (2) binding multiple\n(cofactor) ligands concurrently to a given target protein (e.g., for enzyme\ndesign); and (3) having no prior knowledge of binding pockets (e.g., for\ngeneralization to unknown pockets). To enable a deeper understanding of docking\nmethods' real-world utility, we introduce PoseBench, the first comprehensive\nbenchmark for broadly applicable protein-ligand docking. PoseBench enables\nresearchers to rigorously and systematically evaluate DL methods for\napo-to-holo protein-ligand docking and protein-ligand structure prediction\nusing both primary ligand and multi-ligand benchmark datasets, the latter of\nwhich we introduce for the first time to the DL community. Empirically, using\nPoseBench, we find that (1) DL co-folding methods generally outperform\ncomparable conventional and DL docking baselines, yet popular methods such as\nAlphaFold 3 are still challenged by prediction targets with novel protein\nsequences; (2) certain DL co-folding methods are highly sensitive to their\ninput multiple sequence alignments, while others are not; and (3) DL methods\nstruggle to strike a balance between structural accuracy and chemical\nspecificity when predicting novel or multi-ligand protein targets. Code, data,\ntutorials, and benchmark results are available at\nhttps://github.com/BioinfoMachineLearning/PoseBench.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "q-bio.QM",
      "I.2.1; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "52 pages, 2 tables, 37 figures. Under review. Code, data, tutorials,\n  and benchmark results are available at\n  https://github.com/BioinfoMachineLearning/PoseBench",
    "pdf_url": "http://arxiv.org/pdf/2405.14108v5",
    "published_date": "2024-05-23 02:27:39 UTC",
    "updated_date": "2025-02-09 21:04:47 UTC"
  },
  {
    "arxiv_id": "2405.17459v1",
    "title": "Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis",
    "authors": [
      "Ziyan Yao",
      "Fei Lin",
      "Sheng Chai",
      "Weijie He",
      "Lu Dai",
      "Xinghui Fei"
    ],
    "abstract": "In this paper, an innovative multi-modal deep learning model is proposed to\ndeeply integrate heterogeneous information from medical images and clinical\nreports. First, for medical images, convolutional neural networks were used to\nextract high-dimensional features and capture key visual information such as\nfocal details, texture and spatial distribution. Secondly, for clinical report\ntext, a two-way long and short-term memory network combined with an attention\nmechanism is used for deep semantic understanding, and key statements related\nto the disease are accurately captured. The two features interact and integrate\neffectively through the designed multi-modal fusion layer to realize the joint\nrepresentation learning of image and text. In the empirical study, we selected\na large medical image database covering a variety of diseases, combined with\ncorresponding clinical reports for model training and validation. The proposed\nmultimodal deep learning model demonstrated substantial superiority in the\nrealms of disease classification, lesion localization, and clinical description\ngeneration, as evidenced by the experimental results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17459v1",
    "published_date": "2024-05-23 02:22:10 UTC",
    "updated_date": "2024-05-23 02:22:10 UTC"
  },
  {
    "arxiv_id": "2405.14105v5",
    "title": "Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference",
    "authors": [
      "Nadav Timor",
      "Jonathan Mamou",
      "Daniel Korat",
      "Moshe Berchansky",
      "Oren Pereg",
      "Moshe Wasserblat",
      "Tomer Galanti",
      "Michal Gordon",
      "David Harel"
    ],
    "abstract": "This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)",
    "pdf_url": "http://arxiv.org/pdf/2405.14105v5",
    "published_date": "2024-05-23 02:14:17 UTC",
    "updated_date": "2025-03-15 04:52:03 UTC"
  },
  {
    "arxiv_id": "2405.14094v2",
    "title": "Attending to Topological Spaces: The Cellular Transformer",
    "authors": [
      "Rubén Ballester",
      "Pablo Hernández-García",
      "Mathilde Papillon",
      "Claudio Battiloro",
      "Nina Miolane",
      "Tolga Birdal",
      "Carles Casacuberta",
      "Sergio Escalera",
      "Mustafa Hajij"
    ],
    "abstract": "Topological Deep Learning seeks to enhance the predictive performance of\nneural network models by harnessing topological structures in input data.\nTopological neural networks operate on spaces such as cell complexes and\nhypergraphs, that can be seen as generalizations of graphs. In this work, we\nintroduce the Cellular Transformer (CT), a novel architecture that generalizes\ngraph-based transformers to cell complexes. First, we propose a new formulation\nof the usual self- and cross-attention mechanisms, tailored to leverage\nincidence relations in cell complexes, e.g., edge-face and node-edge relations.\nAdditionally, we propose a set of topological positional encodings specifically\ndesigned for cell complexes. By transforming three graph datasets into cell\ncomplex datasets, our experiments reveal that CT not only achieves\nstate-of-the-art performance, but it does so without the need for more complex\nenhancements such as virtual nodes, in-domain structural encodings, or graph\nrewiring.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "math.AT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14094v2",
    "published_date": "2024-05-23 01:48:32 UTC",
    "updated_date": "2024-05-26 23:29:11 UTC"
  },
  {
    "arxiv_id": "2405.17458v2",
    "title": "Blood Glucose Control Via Pre-trained Counterfactual Invertible Neural Networks",
    "authors": [
      "Jingchi Jiang",
      "Rujia Shen",
      "Boran Wang",
      "Yi Guan"
    ],
    "abstract": "Type 1 diabetes mellitus (T1D) is characterized by insulin deficiency and\nblood glucose (BG) control issues. The state-of-the-art solution for continuous\nBG control is reinforcement learning (RL), where an agent can dynamically\nadjust exogenous insulin doses in time to maintain BG levels within the target\nrange. However, due to the lack of action guidance, the agent often needs to\nlearn from randomized trials to understand misleading correlations between\nexogenous insulin doses and BG levels, which can lead to instability and\nunsafety. To address these challenges, we propose an introspective RL based on\nCounterfactual Invertible Neural Networks (CINN). We use the pre-trained CINN\nas a frozen introspective block of the RL agent, which integrates forward\nprediction and counterfactual inference to guide the policy updates, promoting\nmore stable and safer BG control. Constructed based on interpretable causal\norder, CINN employs bidirectional encoders with affine coupling layers to\nensure invertibility while using orthogonal weight normalization to enhance the\ntrainability, thereby ensuring the bidirectional differentiability of network\nparameters. We experimentally validate the accuracy and generalization ability\nof the pre-trained CINN in BG prediction and counterfactual inference for\naction. Furthermore, our experimental results highlight the effectiveness of\npre-trained CINN in guiding RL policy updates for more accurate and safer BG\ncontrol.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17458v2",
    "published_date": "2024-05-23 01:34:59 UTC",
    "updated_date": "2024-07-18 06:54:04 UTC"
  },
  {
    "arxiv_id": "2405.14088v1",
    "title": "High-dimensional Learning with Noisy Labels",
    "authors": [
      "Aymane El Firdoussi",
      "Mohamed El Amine Seddik"
    ],
    "abstract": "This paper provides theoretical insights into high-dimensional binary\nclassification with class-conditional noisy labels. Specifically, we study the\nbehavior of a linear classifier with a label noisiness aware loss function,\nwhen both the dimension of data $p$ and the sample size $n$ are large and\ncomparable. Relying on random matrix theory by supposing a Gaussian mixture\ndata model, the performance of the linear classifier when $p,n\\to \\infty$ is\nshown to converge towards a limit, involving scalar statistics of the data.\nImportantly, our findings show that the low-dimensional intuitions to handle\nlabel noise do not hold in high-dimension, in the sense that the optimal\nclassifier in low-dimension dramatically fails in high-dimension. Based on our\nderivations, we design an optimized method that is shown to be provably more\nefficient in handling noisy labels in high dimensions. Our theoretical\nconclusions are further confirmed by experiments on real datasets, where we\nshow that our optimized approach outperforms the considered baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14088v1",
    "published_date": "2024-05-23 01:32:25 UTC",
    "updated_date": "2024-05-23 01:32:25 UTC"
  },
  {
    "arxiv_id": "2405.14905v1",
    "title": "Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation",
    "authors": [
      "Kang Liu",
      "Zhuoqi Ma",
      "Xiaolu Kang",
      "Zhusi Zhong",
      "Zhicheng Jiao",
      "Grayson Baird",
      "Harrison Bai",
      "Qiguang Miao"
    ],
    "abstract": "The automated generation of imaging reports proves invaluable in alleviating\nthe workload of radiologists. A clinically applicable reports generation\nalgorithm should demonstrate its effectiveness in producing reports that\naccurately describe radiology findings and attend to patient-specific\nindications. In this paper, we introduce a novel method, \\textbf{S}tructural\n\\textbf{E}ntities extraction and patient indications \\textbf{I}ncorporation\n(SEI) for chest X-ray report generation. Specifically, we employ a structural\nentities extraction (SEE) approach to eliminate presentation-style vocabulary\nin reports and improve the quality of factual entity sequences. This reduces\nthe noise in the following cross-modal alignment module by aligning X-ray\nimages with factual entity sequences in reports, thereby enhancing the\nprecision of cross-modal alignment and further aiding the model in\ngradient-free retrieval of similar historical cases. Subsequently, we propose a\ncross-modal fusion network to integrate information from X-ray images, similar\nhistorical cases, and patient-specific indications. This process allows the\ntext decoder to attend to discriminative features of X-ray images, assimilate\nhistorical diagnostic information from similar cases, and understand the\nexamination intention of patients. This, in turn, assists in triggering the\ntext decoder to produce high-quality reports. Experiments conducted on\nMIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on\nboth natural language generation and clinical efficacy metrics.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.IV",
    "comment": "The code is available at https://github.com/mk-runner/SEI-Temp or\n  https://github.com/mk-runner/SEI",
    "pdf_url": "http://arxiv.org/pdf/2405.14905v1",
    "published_date": "2024-05-23 01:29:47 UTC",
    "updated_date": "2024-05-23 01:29:47 UTC"
  },
  {
    "arxiv_id": "2406.00017v2",
    "title": "PTA: Enhancing Multimodal Sentiment Analysis through Pipelined Prediction and Translation-based Alignment",
    "authors": [
      "Shezheng Song",
      "Shasha Li",
      "Shan Zhao",
      "Chengyu Wang",
      "Xiaopeng Li",
      "Jie Yu",
      "Qian Wan",
      "Jun Ma",
      "Tianwei Yan",
      "Wentao Ma",
      "Xiaoguang Mao"
    ],
    "abstract": "Multimodal aspect-based sentiment analysis (MABSA) aims to understand\nopinions in a granular manner, advancing human-computer interaction and other\nfields. Traditionally, MABSA methods use a joint prediction approach to\nidentify aspects and sentiments simultaneously. However, we argue that joint\nmodels are not always superior. Our analysis shows that joint models struggle\nto align relevant text tokens with image patches, leading to misalignment and\nineffective image utilization.\n  In contrast, a pipeline framework first identifies aspects through MATE\n(Multimodal Aspect Term Extraction) and then aligns these aspects with image\npatches for sentiment classification (MASC: Multimodal Aspect-Oriented\nSentiment Classification). This method is better suited for multimodal\nscenarios where effective image use is crucial. We present three key\nobservations: (a) MATE and MASC have different feature requirements, with MATE\nfocusing on token-level features and MASC on sequence-level features; (b) the\naspect identified by MATE is crucial for effective image utilization; and (c)\nimages play a trivial role in previous MABSA methods due to high noise.\n  Based on these observations, we propose a pipeline framework that first\npredicts the aspect and then uses translation-based alignment (TBA) to enhance\nmultimodal semantic consistency for better image utilization. Our method\nachieves state-of-the-art (SOTA) performance on widely used MABSA datasets\nTwitter-15 and Twitter-17. This demonstrates the effectiveness of the pipeline\napproach and its potential to provide valuable insights for future MABSA\nresearch.\n  For reproducibility, the code and checkpoint will be released.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Code will be released upon publication",
    "pdf_url": "http://arxiv.org/pdf/2406.00017v2",
    "published_date": "2024-05-23 01:16:45 UTC",
    "updated_date": "2024-06-13 13:26:56 UTC"
  },
  {
    "arxiv_id": "2405.17209v1",
    "title": "How Do Transformers \"Do\" Physics? Investigating the Simple Harmonic Oscillator",
    "authors": [
      "Subhash Kantamneni",
      "Ziming Liu",
      "Max Tegmark"
    ],
    "abstract": "How do transformers model physics? Do transformers model systems with\ninterpretable analytical solutions, or do they create \"alien physics\" that are\ndifficult for humans to decipher? We take a step in demystifying this larger\npuzzle by investigating the simple harmonic oscillator (SHO), $\\ddot{x}+2\\gamma\n\\dot{x}+\\omega_0^2x=0$, one of the most fundamental systems in physics. Our\ngoal is to identify the methods transformers use to model the SHO, and to do so\nwe hypothesize and evaluate possible methods by analyzing the encoding of these\nmethods' intermediates. We develop four criteria for the use of a method within\nthe simple testbed of linear regression, where our method is $y = wx$ and our\nintermediate is $w$: (1) Can the intermediate be predicted from hidden states?\n(2) Is the intermediate's encoding quality correlated with model performance?\n(3) Can the majority of variance in hidden states be explained by the\nintermediate? (4) Can we intervene on hidden states to produce predictable\noutcomes? Armed with these two correlational (1,2), weak causal (3) and strong\ncausal (4) criteria, we determine that transformers use known numerical methods\nto model trajectories of the simple harmonic oscillator, specifically the\nmatrix exponential method. Our analysis framework can conveniently extend to\nhigh-dimensional linear systems and nonlinear systems, which we hope will help\nreveal the \"world model\" hidden in transformers.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.17209v1",
    "published_date": "2024-05-23 01:14:22 UTC",
    "updated_date": "2024-05-23 01:14:22 UTC"
  },
  {
    "arxiv_id": "2405.14082v2",
    "title": "Exclusively Penalized Q-learning for Offline Reinforcement Learning",
    "authors": [
      "Junghyuk Yeom",
      "Yonghyeon Jo",
      "Jungmo Kim",
      "Sanghyeon Lee",
      "Seungyul Han"
    ],
    "abstract": "Constraint-based offline reinforcement learning (RL) involves policy\nconstraints or imposing penalties on the value function to mitigate\noverestimation errors caused by distributional shift. This paper focuses on a\nlimitation in existing offline RL methods with penalized value function,\nindicating the potential for underestimation bias due to unnecessary bias\nintroduced in the value function. To address this concern, we propose\nExclusively Penalized Q-learning (EPQ), which reduces estimation bias in the\nvalue function by selectively penalizing states that are prone to inducing\nestimation errors. Numerical results show that our method significantly reduces\nunderestimation bias and improves performance in various offline control tasks\ncompared to other offline RL methods",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 technical page followed by references and appendix. Accepted to\n  Neurips 2024 as spotlight paper",
    "pdf_url": "http://arxiv.org/pdf/2405.14082v2",
    "published_date": "2024-05-23 01:06:05 UTC",
    "updated_date": "2024-10-24 07:56:23 UTC"
  },
  {
    "arxiv_id": "2405.14078v1",
    "title": "A finite time analysis of distributed Q-learning",
    "authors": [
      "Han-Dong Lim",
      "Donghwan Lee"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in\ninterest, fueled by the empirical success achieved in applications of\nsingle-agent reinforcement learning (RL). In this study, we consider a\ndistributed Q-learning scenario, wherein a number of agents cooperatively solve\na sequential decision making problem without access to the central reward\nfunction which is an average of the local rewards. In particular, we study\nfinite-time analysis of a distributed Q-learning algorithm, and provide a new\nsample complexity result of $\\tilde{\\mathcal{O}}\\left(\n\\min\\left\\{\\frac{1}{\\epsilon^2}\\frac{t_{\\text{mix}}}{(1-\\gamma)^6 d_{\\min}^4 }\n,\\frac{1}{\\epsilon}\\frac{\\sqrt{|\\gS||\\gA|}}{(1-\\sigma_2(\\boldsymbol{W}))(1-\\gamma)^4\nd_{\\min}^3} \\right\\}\\right)$ under tabular lookup",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.14078v1",
    "published_date": "2024-05-23 00:52:38 UTC",
    "updated_date": "2024-05-23 00:52:38 UTC"
  },
  {
    "arxiv_id": "2405.14077v2",
    "title": "Learning to Transform Dynamically for Better Adversarial Transferability",
    "authors": [
      "Rongyi Zhu",
      "Zeliang Zhang",
      "Susan Liang",
      "Zhuo Liu",
      "Chenliang Xu"
    ],
    "abstract": "Adversarial examples, crafted by adding perturbations imperceptible to\nhumans, can deceive neural networks. Recent studies identify the adversarial\ntransferability across various models, \\textit{i.e.}, the cross-model attack\nability of adversarial samples. To enhance such adversarial transferability,\nexisting input transformation-based methods diversify input data with\ntransformation augmentation. However, their effectiveness is limited by the\nfinite number of available transformations. In our study, we introduce a novel\napproach named Learning to Transform (L2T). L2T increases the diversity of\ntransformed images by selecting the optimal combination of operations from a\npool of candidates, consequently improving adversarial transferability. We\nconceptualize the selection of optimal transformation combinations as a\ntrajectory optimization problem and employ a reinforcement learning strategy to\neffectively solve the problem. Comprehensive experiments on the ImageNet\ndataset, as well as practical tests with Google Vision and GPT-4V, reveal that\nL2T surpasses current methodologies in enhancing adversarial transferability,\nthereby confirming its effectiveness and practical significance. The code is\navailable at https://github.com/RongyiZhu/L2T.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted as a poster in CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.14077v2",
    "published_date": "2024-05-23 00:46:53 UTC",
    "updated_date": "2024-07-24 07:51:18 UTC"
  },
  {
    "arxiv_id": "2405.14075v2",
    "title": "$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language Models",
    "authors": [
      "Chengkun Cai",
      "Xu Zhao",
      "Yucheng Du",
      "Haoliang Liu",
      "Lei Li"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools in artificial\nintelligence, especially in complex decision-making scenarios, but their static\nproblem-solving strategies often limit their adaptability to dynamic\nenvironments. We explore the enhancement of reasoning capabilities in LLMs\nthrough Temperature Tree ($T^2$) prompting via a heuristic algorithm, termed as\n$T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing decision-making\nprocesses by dynamically adjusting search parameters, especially temperature,\nto improve accuracy without increasing computational demands. We empirically\nvalidate that our hybrid $T^2oT$ approach yields enhancements in,\nsingle-solution accuracy, multi-solution generation and text generation\nquality. Our findings suggest that while dynamic search depth adjustments based\non temperature can yield mixed results, a fixed search depth, when coupled with\nadaptive capabilities of $T^2oT$, provides a more reliable and versatile\nproblem-solving strategy. This work highlights the potential for future\nexplorations in optimizing algorithmic interactions with foundational language\nmodels, particularly illustrated by our development for the Game of 24 and\nCreative Writing tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.14075v2",
    "published_date": "2024-05-23 00:40:43 UTC",
    "updated_date": "2025-02-16 13:58:06 UTC"
  }
]