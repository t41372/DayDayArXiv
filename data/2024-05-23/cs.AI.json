{
  "date": "2024-05-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-23 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的优化、强化学习、多模态处理和特定领域应用，强调了大型语言模型（LLMs）的推理能力、扩散模型的效率提升，以及多代理系统在动态环境中的表现；令人印象深刻的文章包括 DeepSeek-Prover 在定理证明上的大规模合成数据应用，以及一些 SOTA 方法如 JiuZhang3.0 和 PipeFusion；知名学者如 James A. Evans 在社会科学 AI 应用方面有新贡献。\n\n下面，我将按主题简要概述部分关键论文，先优先讨论重要或创新性强的文章，再快速掠过其他。限于篇幅，我会聚焦于核心贡献和发现，保留关键术语。\n\n### LLM 和生成模型优化\n- **DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data**（DeepSeek-Prover: 通过大规模合成数据提升LLMs的定理证明能力）  \n  这篇论文提出使用合成数据训练LLMs进行定理证明，显著提升了在Lean 4数据集上的准确率（e.g., miniF2F测试集达到52%的成功率），主要贡献是通过高效的数据生成方法（如从数学竞赛问题中提取），让LLMs在定理证明任务中超越GPT-4。\n\n- **JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models**（JiuZhang3.0: 通过训练小型数据合成模型高效提升数学推理能力）  \n  作者优化了数学推理模型，使用小型LLM合成数据，显著提高了在数学任务（如GSM8K）的性能，主要发现是数据合成策略能让模型在低资源场景下高效学习，适用于资源受限的AI应用。\n\n- **Instruction Tuning With Loss Over Instructions**（指令微调：通过指令损失提升LLMs性能）  \n  论文引入了针对指令的损失函数，改进了LLMs的指令遵循能力，在多个基准（如AlpacaEval）上提升了100%的性能，关键在于减少过拟合，实现更高效的微调。\n\n其他LLM相关论文，如Dissociation of Faithful and Unfaithful Reasoning in LLMs，主要探讨LLMs在推理中的可信度问题，但贡献较基础，快速掠过；In-context Time Series Predictor则优化了LLMs在时序预测中的上下文学习，但未见突破性创新。\n\n### 强化学习和多代理系统\n- **PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference**（PipeFusion: 针对扩散Transformer推理的补丁级管道并行）  \n  这篇论文提出了一种高效的并行策略，显著加速了扩散模型的推理过程（e.g., 在ImageNet上实现高达5倍的加速），主要贡献是通过补丁级并行减少计算开销，适用于实时AI应用。\n\n- **Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning**（在多代理强化学习中控制行为多样性）  \n  作者引入Diversity Control方法，优化多代理系统的行为多样性，实验证明能提升性能和样本效率（e.g., 在协作和竞争任务中表现突出），这对复杂多代理环境（如机器人协作）有实际意义。\n\n其他强化学习论文，如Efficient Mitigation of Bus Bunching，主要应用RL优化交通系统，但较为应用导向，简要提及其贡献在于减少交通拥堵。\n\n### 计算机视觉和多模态处理\n- **MuDreamer: Learning Predictive World Models without Reconstruction**（MuDreamer: 无需重构的学习预测世界模型）  \n  论文改进扩散模型，提出无需像素重构的预测方法，提升了在视觉控制任务中的鲁棒性（e.g., 在DeepMind控制套件上抗干扰能力强），核心发现是使用价值函数和动作预测来学习世界模型。\n\n- **DreamText: High Fidelity Scene Text Synthesis**（DreamText: 高保真场景文本合成）  \n  作者开发了文本合成框架，通过层次化特征提取减少文本失真，适用于OCR任务，主要贡献是改进扩散模型的文本生成质量。\n\n其他视觉论文，如Eliciting Informative Text Evaluations，主要探索多模态评估，但影响力有限，快速掠过。\n\n### 其他领域应用\n- **In Silico Sociology: Forecasting COVID-19 Polarization with Large Language Models**（In Silico Sociology: 使用LLMs预测COVID-19两极分化）  \n  James A. Evans等知名学者参与，论文使用LLMs模拟公众意见，准确预测COVID-19相关态度（84%准确率），主要发现是LLMs能捕捉意识形态差异，扩展了AI在社会科学的潜力。\n\n其他论文，如Temporal Stamp Classifier（天文物体分类）和An LSTM Feature Imitation Network（手势识别），分别在神经网络和生物信号处理上有小幅创新，但非主流主题，故仅简要提及其分类性能提升。\n\n总体而言，今天的论文突出了AI模型在推理、优化和多模态融合上的进展，DeepSeek-Prover和JiuZhang3.0等值得关注，能推动LLMs在数学和科学领域的应用。其他文章虽多，但多为细化改进，篇幅所限不再详述。希望这份快报能帮您快速把握今日动态！",
  "papers": [
    {
      "arxiv_id": "2405.15097v1",
      "title": "Contrastive and Consistency Learning for Neural Noisy-Channel Model in Spoken Language Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Suyoung Kim",
        "Jiyeon Hwang",
        "Ho-Young Jung"
      ],
      "abstract": "Recently, deep end-to-end learning has been studied for intent classification\nin Spoken Language Understanding (SLU). However, end-to-end models require a\nlarge amount of speech data with intent labels, and highly optimized models are\ngenerally sensitive to the inconsistency between the training and evaluation\nconditions. Therefore, a natural language understanding approach based on\nAutomatic Speech Recognition (ASR) remains attractive because it can utilize a\npre-trained general language model and adapt to the mismatch of the speech\ninput environment. Using this module-based approach, we improve a noisy-channel\nmodel to handle transcription inconsistencies caused by ASR errors. We propose\na two-stage method, Contrastive and Consistency Learning (CCL), that correlates\nerror patterns between clean and noisy ASR transcripts and emphasizes the\nconsistency of the latent features of the two transcripts. Experiments on four\nbenchmark datasets show that CCL outperforms existing methods and improves the\nASR robustness in various noisy environments. Code is available at\nhttps://github.com/syoung7388/CCL.",
      "tldr_zh": "本研究针对Spoken Language Understanding (SLU)中的intent classification问题，指出端到端模型需大量标注数据且易受训练与评估条件不一致影响，因此提出基于Automatic Speech Recognition (ASR)的模块化方法来改进noisy-channel模型。研究引入Contrastive and Consistency Learning (CCL)两阶段方法，通过对比干净和noisy ASR转录的错误模式，并强调两种转录的潜在特征一致性，从而提升模型对ASR错误的鲁棒性。在四个基准数据集上的实验显示，CCL优于现有方法，并在各种噪声环境中显著提高了性能。代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.15097v1",
      "published_date": "2024-05-23 23:10:23 UTC",
      "updated_date": "2024-05-23 23:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:44:42.664697"
    },
    {
      "arxiv_id": "2405.15092v2",
      "title": "Dissociation of Faithful and Unfaithful Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Evelyn Yee",
        "Alice Li",
        "Chenyu Tang",
        "Yeon Ho Jung",
        "Ramamohan Paturi",
        "Leon Bergen"
      ],
      "abstract": "Large language models (LLMs) often improve their performance in downstream\ntasks when they generate Chain of Thought reasoning text before producing an\nanswer. We investigate how LLMs recover from errors in Chain of Thought.\nThrough analysis of error recovery behaviors, we find evidence for\nunfaithfulness in Chain of Thought, which occurs when models arrive at the\ncorrect answer despite invalid reasoning text. We identify factors that shift\nLLM recovery behavior: LLMs recover more frequently from obvious errors and in\ncontexts that provide more evidence for the correct answer. Critically, these\nfactors have divergent effects on faithful and unfaithful recoveries. Our\nresults indicate that there are distinct mechanisms driving faithful and\nunfaithful error recoveries. Selective targeting of these mechanisms may be\nable to drive down the rate of unfaithful reasoning and improve model\ninterpretability.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在生成Chain of Thought（CoT）推理文本后，如何从错误中恢复，并揭示了faithful（忠实）和unfaithful（不忠实）推理的差异，其中unfaithful推理指模型通过无效推理文本却得出正确答案。研究发现，影响恢复行为的因素包括明显的错误和提供更多正确证据的上下文，这些因素对faithful和unfaithful恢复有不同影响，导致两种恢复机制的分离。通过针对这些机制，论文建议可以降低unfaithful推理的发生率，从而提升模型的可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "code published at\n  https://github.com/CoTErrorRecovery/CoTErrorRecovery",
      "pdf_url": "http://arxiv.org/pdf/2405.15092v2",
      "published_date": "2024-05-23 22:38:58 UTC",
      "updated_date": "2024-09-02 22:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:44:53.568858"
    },
    {
      "arxiv_id": "2407.11190v1",
      "title": "In Silico Sociology: Forecasting COVID-19 Polarization with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Austin C. Kozlowski",
        "Hyunku Kwon",
        "James A. Evans"
      ],
      "abstract": "By training deep neural networks on massive archives of digitized text, large\nlanguage models (LLMs) learn the complex linguistic patterns that constitute\nhistoric and contemporary discourses. We argue that LLMs can serve as a\nvaluable tool for sociological inquiry by enabling accurate simulation of\nrespondents from specific social and cultural contexts. Applying LLMs in this\ncapacity, we reconstruct the public opinion landscape of 2019 to examine the\nextent to which the future polarization over COVID-19 was prefigured in\nexisting political discourse. Using an LLM trained on texts published through\n2019, we simulate the responses of American liberals and conservatives to a\nbattery of pandemic-related questions. We find that the simulated respondents\nreproduce observed partisan differences in COVID-19 attitudes in 84% of cases,\nsignificantly greater than chance. Prompting the simulated respondents to\njustify their responses, we find that much of the observed partisan gap\ncorresponds to differing appeals to freedom, safety, and institutional trust.\nOur findings suggest that the politicization of COVID-19 was largely consistent\nwith the prior ideological landscape, and this unprecedented event served to\nadvance history along its track rather than change the rails.",
      "tldr_zh": "本研究利用大型语言模型（LLMs）模拟特定社会文化背景下的受访者，预测COVID-19相关两极分化，旨在为社会学研究提供新工具。研究者训练LLMs于2019年以前的文本，模拟美国自由派和保守派对疫情问题的响应，发现模拟结果在84%的案例中准确再现了观察到的党派差异。进一步分析显示，这些差异主要源于对自由、安全和机构信任的不同诉求，表明COVID-19的政治化是现有意识形态景观的延续，而非根本改变。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11190v1",
      "published_date": "2024-05-23 22:10:12 UTC",
      "updated_date": "2024-05-23 22:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:45:07.010258"
    },
    {
      "arxiv_id": "2405.15083v1",
      "title": "MuDreamer: Learning Predictive World Models without Reconstruction",
      "title_zh": "MuDreamer：无需重建的学习预测性世界模型",
      "authors": [
        "Maxime Burchi",
        "Radu Timofte"
      ],
      "abstract": "The DreamerV3 agent recently demonstrated state-of-the-art performance in\ndiverse domains, learning powerful world models in latent space using a pixel\nreconstruction loss. However, while the reconstruction loss is essential to\nDreamer's performance, it also necessitates modeling unnecessary information.\nConsequently, Dreamer sometimes fails to perceive crucial elements which are\nnecessary for task-solving when visual distractions are present in the\nobservation, significantly limiting its potential. In this paper, we present\nMuDreamer, a robust reinforcement learning agent that builds upon the DreamerV3\nalgorithm by learning a predictive world model without the need for\nreconstructing input signals. Rather than relying on pixel reconstruction,\nhidden representations are instead learned by predicting the environment value\nfunction and previously selected actions. Similar to predictive self-supervised\nmethods for images, we find that the use of batch normalization is crucial to\nprevent learning collapse. We also study the effect of KL balancing between\nmodel posterior and prior losses on convergence speed and learning stability.\nWe evaluate MuDreamer on the commonly used DeepMind Visual Control Suite and\ndemonstrate stronger robustness to visual distractions compared to DreamerV3\nand other reconstruction-free approaches, replacing the environment background\nwith task-irrelevant real-world videos. Our method also achieves comparable\nperformance on the Atari100k benchmark while benefiting from faster training.",
      "tldr_zh": "该论文提出了 MuDreamer，一种基于 DreamerV3 的强化学习代理，通过预测环境价值函数和先前动作来学习预测性世界模型，而非依赖像素重建，从而提升了对视觉干扰的鲁棒性。MuDreamer 引入批量归一化(batch normalization)以防止学习崩溃，并优化 KL balancing 以提高收敛速度和稳定性。在 DeepMind Visual Control Suite 的实验中，该方法在视觉干扰（如替换背景为真实世界视频）场景下比 DreamerV3 和其他无重建方法表现出更强鲁棒性，并在 Atari100k 基准上实现类似性能，同时训练速度更快。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15083v1",
      "published_date": "2024-05-23 22:09:01 UTC",
      "updated_date": "2024-05-23 22:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:45:19.843925"
    },
    {
      "arxiv_id": "2405.15077v4",
      "title": "Eliciting Informative Text Evaluations with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Lu",
        "Shengwei Xu",
        "Yichi Zhang",
        "Yuqing Kong",
        "Grant Schoenebeck"
      ],
      "abstract": "Peer prediction mechanisms motivate high-quality feedback with provable\nguarantees. However, current methods only apply to rather simple reports, like\nmultiple-choice or scalar numbers. We aim to broaden these techniques to the\nlarger domain of text-based reports, drawing on the recent developments in\nlarge language models. This vastly increases the applicability of peer\nprediction mechanisms as textual feedback is the norm in a large variety of\nfeedback channels: peer reviews, e-commerce customer reviews, and comments on\nsocial media.\n  We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)\nand the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms\nutilize LLMs as predictors, mapping from one agent's report to a prediction of\nher peer's report. Theoretically, we show that when the LLM prediction is\nsufficiently accurate, our mechanisms can incentivize high effort and\ntruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, we\nconfirm the efficacy of our mechanisms through experiments conducted on two\nreal datasets: the Yelp review dataset and the ICLR OpenReview dataset. We\nhighlight the results that on the ICLR dataset, our mechanisms can\ndifferentiate three quality levels -- human-written reviews, GPT-4-generated\nreviews, and GPT-3.5-generated reviews in terms of expected scores.\nAdditionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.",
      "tldr_zh": "该研究旨在扩展同行预测机制（peer prediction mechanisms）到文本报告领域，利用 Large Language Models (LLMs) 激励高质量反馈，如同行评审和电商评论。论文提出两种机制：Generative Peer Prediction Mechanism (GPPM) 和 Generative Synopsis Peer Prediction Mechanism (GSPPM)，这些机制通过 LLMs 预测代理报告来促进高努力和真实报告，并在理论上证明其作为近似 Bayesian Nash equilibrium 的有效性。实验在 Yelp 和 ICLR 数据集上验证了这些机制，能够区分人类写评论与 GPT-4 或 GPT-3.5 生成评论的质量水平，且 GSPPM 在惩罚 LLM 生成评论方面表现更佳。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the Twenty-Fifth ACM Conference on Economics and\n  Computation (EC'24)",
      "pdf_url": "http://arxiv.org/pdf/2405.15077v4",
      "published_date": "2024-05-23 21:56:12 UTC",
      "updated_date": "2024-09-02 20:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:45:30.388402"
    },
    {
      "arxiv_id": "2405.15073v1",
      "title": "Temporal Stamp Classifier: Classifying Short Sequences of Astronomical Alerts",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Neira O.",
        "Pablo A. Estévez",
        "Francisco Förster"
      ],
      "abstract": "In this work, we propose a deep learning-based classification model of\nastronomical objects using alerts reported by the Zwicky Transient Facility\n(ZTF) survey. The model takes as inputs sequences of stamp images and metadata\ncontained in each alert, as well as features from the All-WISE catalog. The\nproposed model, called temporal stamp classifier, is able to discriminate\nbetween three classes of astronomical objects: Active Galactic Nuclei (AGN),\nSuper-Novae (SNe) and Variable Stars (VS), with an accuracy of approximately\n98% in the test set, when using 2 to 5 detections. The results show that the\nmodel performance improves with the addition of more detections. Simple\nrecurrence models obtain competitive results with those of more complex models\nsuch as LSTM.We also propose changes to the original stamp classifier model,\nwhich only uses the first detection. The performance of the latter model\nimproves with changes in the architecture and the addition of random rotations,\nachieving a 1.46% increase in test accuracy.",
      "tldr_zh": "本研究提出Temporal Stamp Classifier，一种基于深度学习的模型，用于利用Zwicky Transient Facility (ZTF)警报的序列stamp图像、元数据以及All-WISE目录特征，来分类天文物体，包括Active Galactic Nuclei (AGN)、Super-Novae (SNe)和Variable Stars (VS)。模型在2到5个检测下实现约98%的测试准确率，且性能随检测次数增加而提升。相比复杂模型如LSTM，简单循环模型也能取得竞争性结果；此外，作者对原有stamp分类器进行了架构优化和随机旋转增强，准确率提升了1.46%。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Accepted in International Joint Conference on Neural Networks 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.15073v1",
      "published_date": "2024-05-23 21:49:32 UTC",
      "updated_date": "2024-05-23 21:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:45:43.730150"
    },
    {
      "arxiv_id": "2405.19356v2",
      "title": "An LSTM Feature Imitation Network for Hand Movement Recognition from sEMG Signals",
      "title_zh": "一种基于 LSTM 的特征模仿网络，用于从 sEMG 信号中识别手部运动",
      "authors": [
        "Chuheng Wu",
        "S. Farokh Atashzar",
        "Mohammad M. Ghassemi",
        "Tuka Alhanai"
      ],
      "abstract": "Surface Electromyography (sEMG) is a non-invasive signal that is used in the\nrecognition of hand movement patterns, the diagnosis of diseases, and the\nrobust control of prostheses. Despite the remarkable success of recent\nend-to-end Deep Learning approaches, they are still limited by the need for\nlarge amounts of labeled data. To alleviate the requirement for big data, we\npropose utilizing a feature-imitating network (FIN) for closed-form temporal\nfeature learning over a 300ms signal window on Ninapro DB2, and applying it to\nthe task of 17 hand movement recognition. We implement a lightweight LSTM-FIN\nnetwork to imitate four standard temporal features (entropy, root mean square,\nvariance, simple square integral). We observed that the LSTM-FIN network can\nachieve up to 99\\% R2 accuracy in feature reconstruction and 80\\% accuracy in\nhand movement recognition. Our results also showed that the model can be\nrobustly applied for both within- and cross-subject movement recognition, as\nwell as simulated low-latency environments. Overall, our work demonstrates the\npotential of the FIN modeling paradigm in data-scarce scenarios for sEMG signal\nprocessing.",
      "tldr_zh": "该研究提出了一种基于 LSTM 的特征模仿网络 (LSTM-FIN)，用于从 sEMG 信号中识别手部运动，旨在减少对大量标注数据的依赖。方法通过模仿四个标准时间特征（熵、均方根、方差、简单平方积分）在 Ninapro DB2 数据集的 300ms 信号窗口上进行 17 种手部运动识别。实验结果显示，LSTM-FIN 在特征重建上达到 99% R2 准确率，在运动识别上达到 80% 准确率，并展现出在同一受试者、跨受试者和低延迟环境中的鲁棒性。该框架证明了 FIN 范式在数据稀缺场景下处理 sEMG 信号的潜力，为手部运动识别和假肢控制提供高效解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "eess.SP",
      "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2405.19356v2",
      "published_date": "2024-05-23 21:45:15 UTC",
      "updated_date": "2024-12-30 19:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:45:54.720519"
    },
    {
      "arxiv_id": "2405.15064v1",
      "title": "Reframing Spatial Reasoning Evaluation in Language Models: A Real-World Simulation Benchmark for Qualitative Reasoning",
      "title_zh": "重新框架语言模型的空间推理评估：一个针对定性推理的真实世界模拟基准",
      "authors": [
        "Fangjun Li",
        "David C. Hogg",
        "Anthony G. Cohn"
      ],
      "abstract": "Spatial reasoning plays a vital role in both human cognition and machine\nintelligence, prompting new research into language models' (LMs) capabilities\nin this regard. However, existing benchmarks reveal shortcomings in evaluating\nqualitative spatial reasoning (QSR). These benchmarks typically present\noversimplified scenarios or unclear natural language descriptions, hindering\neffective evaluation. We present a novel benchmark for assessing QSR in LMs,\nwhich is grounded in realistic 3D simulation data, offering a series of diverse\nroom layouts with various objects and their spatial relationships. This\napproach provides a more detailed and context-rich narrative for spatial\nreasoning evaluation, diverging from traditional, toy-task-oriented scenarios.\nOur benchmark encompasses a broad spectrum of qualitative spatial\nrelationships, including topological, directional, and distance relations.\nThese are presented with different viewing points, varied granularities, and\ndensity of relation constraints to mimic real-world complexities. A key\ncontribution is our logic-based consistency-checking tool, which enables the\nassessment of multiple plausible solutions, aligning with real-world scenarios\nwhere spatial relationships are often open to interpretation. Our benchmark\nevaluation of advanced LMs reveals their strengths and limitations in spatial\nreasoning. They face difficulties with multi-hop spatial reasoning and\ninterpreting a mix of different view descriptions, pointing to areas for future\nimprovement.",
      "tldr_zh": "本研究重新定义了语言模型（LMs）在定性空间推理（Qualitative Spatial Reasoning, QSR）方面的评估框架，指出现有基准过于简化或描述不清，无法有效评估真实场景。研究者提出一个新型基准，利用真实的3D模拟数据，构建多样化的房间布局和物体空间关系，包括拓扑、方向和距离关系，并考虑不同视角、粒度和关系约束的复杂性。基准还引入基于逻辑的一致性检查工具，支持多个可行解决方案，以模拟现实世界的模糊性。在评估先进语言模型时，结果显示这些模型在多跳空间推理和混合视角描述上存在困难，突显了未来改进的空间。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-Ready version for IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.15064v1",
      "published_date": "2024-05-23 21:22:00 UTC",
      "updated_date": "2024-05-23 21:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:46:06.341823"
    },
    {
      "arxiv_id": "2405.15054v1",
      "title": "Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning",
      "title_zh": "多智能体强化学习中的行为多样性控制",
      "authors": [
        "Matteo Bettini",
        "Ryan Kortvelesy",
        "Amanda Prorok"
      ],
      "abstract": "The study of behavioral diversity in Multi-Agent Reinforcement Learning\n(MARL) is a nascent yet promising field. In this context, the present work\ndeals with the question of how to control the diversity of a multi-agent\nsystem. With no existing approaches to control diversity to a set value,\ncurrent solutions focus on blindly promoting it via intrinsic rewards or\nadditional loss functions, effectively changing the learning objective and\nlacking a principled measure for it. To address this, we introduce Diversity\nControl (DiCo), a method able to control diversity to an exact value of a given\nmetric by representing policies as the sum of a parameter-shared component and\ndynamically scaled per-agent components. By applying constraints directly to\nthe policy architecture, DiCo leaves the learning objective unchanged, enabling\nits applicability to any actor-critic MARL algorithm. We theoretically prove\nthat DiCo achieves the desired diversity, and we provide several experiments,\nboth in cooperative and competitive tasks, that show how DiCo can be employed\nas a novel paradigm to increase performance and sample efficiency in MARL.\nMultimedia results are available on the paper's website:\nhttps://sites.google.com/view/dico-marl.",
      "tldr_zh": "该论文探讨了在多智能体强化学习 (MARL) 中如何精确控制行为多样性的问题，现有的方法往往通过内在奖励或额外损失函数盲目促进多样性，但缺乏原则性度量。研究引入了 Diversity Control (DiCo) 方法，将策略表示为参数共享组件和动态缩放的 per-agent 组件之和，直接在策略架构上施加约束，从而不改变学习目标，并适用于任何 actor-critic MARL 算法。理论证明显示 DiCo 能实现预期的多样性，实验在合作和竞争任务中证明了它提升了性能和样本效率。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15054v1",
      "published_date": "2024-05-23 21:03:33 UTC",
      "updated_date": "2024-05-23 21:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:46:19.026961"
    },
    {
      "arxiv_id": "2405.15052v2",
      "title": "Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training",
      "title_zh": "重新审视 MoE 与 Dense 模型在 LLM 训练中的速度-准确性比较",
      "authors": [
        "Xianzhi Du",
        "Tom Gunter",
        "Xiang Kong",
        "Mark Lee",
        "Zirui Wang",
        "Aonan Zhang",
        "Nan Du",
        "Ruoming Pang"
      ],
      "abstract": "Mixture-of-Experts (MoE) enjoys performance gain by increasing model capacity\nwhile keeping computation cost constant. When comparing MoE to dense models,\nprior work typically adopt the following setting: 1) use FLOPs or activated\nparameters as a measure of model complexity; 2) train all models to the same\nnumber of tokens. We argue that this setting favors MoE as FLOPs and activated\nparameters do not accurately measure the communication overhead in sparse\nlayers, leading to a larger actual training budget for MoE. In this work, we\nrevisit the settings by adopting step time as a more accurate measure of model\ncomplexity, and by determining the total compute budget under the Chinchilla\ncompute-optimal settings. To efficiently run MoE on modern accelerators, we\nadopt a 3D sharding method that keeps the dense-to-MoE step time increase\nwithin a healthy range. We evaluate MoE and dense LLMs on a set of nine 0-shot\nand two 1-shot English tasks, as well as MMLU 5-shot and GSM8K 8-shot across\nthree model scales at 6.4B, 12.6B, and 29.6B. Experimental results show that\neven under these settings, MoE consistently outperform dense LLMs on the\nspeed-accuracy trade-off curve with meaningful gaps. Our full model\nimplementation and sharding strategy has been released\nat~\\url{https://github.com/apple/axlearn}",
      "tldr_zh": "本文重新审视了Mixture-of-Experts (MoE) 与 dense 模型在大型语言模型 (LLMs) 训练中的速度-准确性比较，指出传统使用 FLOPs 或激活参数的设置忽略了 MoE 的通信开销，导致评估偏差。研究采用步时间作为更准确的复杂度衡量，并基于 Chinchilla 计算最优设置确定总计算预算，同时引入 3D sharding 方法来优化 MoE 在现代加速器上的运行效率。实验在多个任务（如九个 0-shot 和两个 1-shot 英语任务，以及 MMLU 5-shot 和 GSM8K 8-shot）及 6.4B、12.6B 和 29.6B 模型规模上显示，MoE 在速度-准确性权衡曲线上持续优于 dense LLMs，且性能差距显著。该工作开源了完整的模型实现和分片策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.15052v2",
      "published_date": "2024-05-23 21:00:53 UTC",
      "updated_date": "2024-06-28 19:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:46:33.350848"
    },
    {
      "arxiv_id": "2405.15047v2",
      "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification",
      "title_zh": "Credal 模型平均包装器，用于分类中的不确定性估计",
      "authors": [
        "Kaizheng Wang",
        "Fabio Cuzzolin",
        "Keivan Shariatmadar",
        "David Moens",
        "Hans Hallez"
      ],
      "abstract": "This paper presents an innovative approach, called credal wrapper, to\nformulating a credal set representation of model averaging for Bayesian neural\nnetworks (BNNs) and deep ensembles (DEs), capable of improving uncertainty\nestimation in classification tasks. Given a finite collection of single\npredictive distributions derived from BNNs or DEs, the proposed credal wrapper\napproach extracts an upper and a lower probability bound per class,\nacknowledging the epistemic uncertainty due to the availability of a limited\namount of distributions. Such probability intervals over classes can be mapped\non a convex set of probabilities (a credal set) from which, in turn, a unique\nprediction can be obtained using a transformation called intersection\nprobability transformation. In this article, we conduct extensive experiments\non several out-of-distribution (OOD) detection benchmarks, encompassing various\ndataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,\nCIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network\narchitectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base).\nCompared to the BNN and DE baselines, the proposed credal wrapper method\nexhibits superior performance in uncertainty estimation and achieves a lower\nexpected calibration error on corrupted data.",
      "tldr_zh": "这篇论文提出了 credal wrapper 方法，用于提升 Bayesian neural networks (BNNs) 和 deep ensembles (DEs) 在分类任务中的不确定性估计。\n该方法从多个预测分布中提取每个类别的上界和下界概率，形成 credal set，并通过 intersection probability transformation 转换为唯一预测，以处理 epistemic uncertainty。\n实验在多种 out-of-distribution (OOD) 检测基准上（如 CIFAR10/100 vs SVHN/Tiny-ImageNet 等数据集对和不同网络架构如 VGG16、ResNet-18/50）进行，结果显示 credal wrapper 比 BNN 和 DE 基线模型表现出色，并显著降低了腐败数据上的预期校准错误。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 13th International Conference on Learning Representations (ICLR).\n  2025 [Spotlight]",
      "pdf_url": "http://arxiv.org/pdf/2405.15047v2",
      "published_date": "2024-05-23 20:51:22 UTC",
      "updated_date": "2025-05-09 14:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:46:47.149639"
    },
    {
      "arxiv_id": "2405.20230v1",
      "title": "Feature Fusion for Improved Classification: Combining Dempster-Shafer Theory and Multiple CNN Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Ayyub Alzahem",
        "Wadii Boulila",
        "Maha Driss",
        "Anis Koubaa"
      ],
      "abstract": "Addressing uncertainty in Deep Learning (DL) is essential, as it enables the\ndevelopment of models that can make reliable predictions and informed decisions\nin complex, real-world environments where data may be incomplete or ambiguous.\nThis paper introduces a novel algorithm leveraging Dempster-Shafer Theory (DST)\nto integrate multiple pre-trained models to form an ensemble capable of\nproviding more reliable and enhanced classifications. The main steps of the\nproposed method include feature extraction, mass function calculation, fusion,\nand expected utility calculation. Several experiments have been conducted on\nCIFAR-10 and CIFAR-100 datasets, demonstrating superior classification accuracy\nof the proposed DST-based method, achieving improvements of 5.4% and 8.4%,\nrespectively, compared to the best individual pre-trained models. Results\nhighlight the potential of DST as a robust framework for managing uncertainties\nrelated to data when applying DL in real-world scenarios.",
      "tldr_zh": "这篇论文提出了一种新算法，利用 Dempster-Shafer Theory (DST) 整合多个预训练 CNN 架构，形成一个更可靠的集成模型，以解决 Deep Learning (DL) 中的不确定性问题。方法包括特征提取、质量函数计算、融合和预期效用计算，确保在数据不完整或模糊的复杂环境中实现更准确的分类。实验结果显示，在 CIFAR-10 和 CIFAR-100 数据集上，该方法分别比最佳单个模型提高了 5.4% 和 8.4%，突显了 DST 在 DL 实际应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20230v1",
      "published_date": "2024-05-23 20:44:10 UTC",
      "updated_date": "2024-05-23 20:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:46:57.382884"
    },
    {
      "arxiv_id": "2405.15033v1",
      "title": "Generating camera failures as a class of physics-based adversarial examples",
      "title_zh": "翻译失败",
      "authors": [
        "Manav Prabhakar",
        "Jwalandhar Girnar",
        "Arpan Kusari"
      ],
      "abstract": "While there has been extensive work on generating physics-based adversarial\nsamples recently, an overlooked class of such samples come from physical\nfailures in the camera. Camera failures can occur as a result of an external\nphysical process, i.e. breakdown of a component due to stress, or an internal\ncomponent failure. In this work, we develop a simulated physical process for\ngenerating broken lens as a class of physics-based adversarial samples. We\ncreate a stress-based physical simulation by generating particles constrained\nin a mesh and apply stress at a random point and at a random angle. We perform\nstress propagation through the mesh and the end result of the mesh is a\ncorresponding image which simulates the broken lens pattern. We also develop a\nneural emulator which learns the non-linear mapping between the mesh as a graph\nand the stress propagation using constrained propagation setup. We can then\nstatistically compare the difference between the generated adversarial samples\nwith real, simulated and emulated adversarial examples using the detection\nfailure rate of the different classes and in between the samples using the\nFrechet Inception distance. Our goal through this work is to provide a robust\nphysics based process for generating adversarial samples.",
      "tldr_zh": "这篇论文将相机故障视为一种新的 physics-based adversarial examples，专注于模拟物理过程来生成 broken lens 攻击样本，以挑战机器学习模型的鲁棒性。研究开发了一种应力-based 物理模拟，通过在网格中约束粒子、在随机点和角度施加应力，并进行应力传播，最终产生模拟破损镜头的图像。同时，引入了一个 neural emulator 来学习网格作为图与非线性应力传播之间的映射。实验使用检测失败率和 Frechet Inception distance 统计比较生成的样本与真实或模拟样本的差异，结果证明了该方法的有效性，为生成鲁棒的 physics-based adversarial samples 提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15033v1",
      "published_date": "2024-05-23 20:11:20 UTC",
      "updated_date": "2024-05-23 20:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:47:11.068671"
    },
    {
      "arxiv_id": "2405.15020v3",
      "title": "AdjointDEIS: Efficient Gradients for Diffusion Models",
      "title_zh": "AdjointDEIS：扩散模型的高效梯度计算",
      "authors": [
        "Zander W. Blasingame",
        "Chen Liu"
      ],
      "abstract": "The optimization of the latents and parameters of diffusion models with\nrespect to some differentiable metric defined on the output of the model is a\nchallenging and complex problem. The sampling for diffusion models is done by\nsolving either the probability flow ODE or diffusion SDE wherein a neural\nnetwork approximates the score function allowing a numerical ODE/SDE solver to\nbe used. However, naive backpropagation techniques are memory intensive,\nrequiring the storage of all intermediate states, and face additional\ncomplexity in handling the injected noise from the diffusion term of the\ndiffusion SDE. We propose a novel family of bespoke ODE solvers to the\ncontinuous adjoint equations for diffusion models, which we call AdjointDEIS.\nWe exploit the unique construction of diffusion SDEs to further simplify the\nformulation of the continuous adjoint equations using exponential integrators.\nMoreover, we provide convergence order guarantees for our bespoke solvers.\nSignificantly, we show that continuous adjoint equations for diffusion SDEs\nactually simplify to a simple ODE. Lastly, we demonstrate the effectiveness of\nAdjointDEIS for guided generation with an adversarial attack in the form of the\nface morphing problem. Our code will be released at https:\n//github.com/zblasingame/AdjointDEIS.",
      "tldr_zh": "这篇论文提出了 AdjointDEIS，一种高效的梯度计算方法，用于优化扩散模型的潜在变量和参数，解决了传统反向传播在处理概率流 ODE 或扩散 SDE 时存在的内存密集和噪声处理复杂问题。AdjointDEIS 通过自定义 ODE 求解器简化连续伴随方程，利用扩散 SDE 的独特结构和指数积分器，提供收敛阶保证，并将 SDE 的伴随方程简化为简单 ODE。实验结果显示，该方法在引导生成任务中（如对抗攻击的面部变形问题）表现出色，有效提升了扩散模型的优化效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.DS",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 conference paper",
      "pdf_url": "http://arxiv.org/pdf/2405.15020v3",
      "published_date": "2024-05-23 19:51:33 UTC",
      "updated_date": "2025-01-21 19:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:47:22.363098"
    },
    {
      "arxiv_id": "2405.15019v2",
      "title": "Agentic Skill Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Xufeng Zhao",
        "Cornelius Weber",
        "Stefan Wermter"
      ],
      "abstract": "Language-conditioned robotic skills make it possible to apply the high-level\nreasoning of Large Language Models (LLMs) to low-level robotic control. A\nremaining challenge is to acquire a diverse set of fundamental skills. Existing\napproaches either manually decompose a complex task into atomic robotic actions\nin a top-down fashion, or bootstrap as many combinations as possible in a\nbottom-up fashion to cover a wider range of task possibilities. These\ndecompositions or combinations, however, require an initial skill library. For\nexample, a ``grasping'' capability can never emerge from a skill library\ncontaining only diverse ``pushing'' skills. Existing skill discovery techniques\nwith reinforcement learning acquire skills by an exhaustive exploration but\noften yield non-meaningful behaviors. In this study, we introduce a novel\nframework for skill discovery that is entirely driven by LLMs. The framework\nbegins with an LLM generating task proposals based on the provided scene\ndescription and the robot's configurations, aiming to incrementally acquire new\nskills upon task completion. For each proposed task, a series of reinforcement\nlearning processes are initiated, utilizing reward and success determination\nfunctions sampled by the LLM to develop the corresponding policy. The\nreliability and trustworthiness of learned behaviors are further ensured by an\nindependent vision-language model. We show that starting with zero skill, the\nskill library emerges and expands to more and more meaningful and reliable\nskills, enabling the robot to efficiently further propose and complete advanced\ntasks. Project page: \\url{https://agentic-skill-discovery.github.io}.",
      "tldr_zh": "本研究提出了一种由大型语言模型(LLMs)驱动的Agentic Skill Discovery框架，旨在从零技能库开始，通过LLMs生成基于场景描述的任务提案来逐步扩展机器人技能。该框架针对每个任务使用强化学习进行政策训练，并由LLMs采样奖励和成功判定函数，同时借助独立视觉语言模型确保行为的可靠性和可信度。实验结果显示，该方法能生成更多有意义和可靠的技能，使机器人高效地提出并完成高级任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Webpage see https://agentic-skill-discovery.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.15019v2",
      "published_date": "2024-05-23 19:44:03 UTC",
      "updated_date": "2024-08-16 15:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:47:32.774676"
    },
    {
      "arxiv_id": "2405.15018v3",
      "title": "What Variables Affect Out-of-Distribution Generalization in Pretrained Models?",
      "title_zh": "哪些变量影响预训练模型中的分布外泛化？",
      "authors": [
        "Md Yousuf Harun",
        "Kyungbok Lee",
        "Jhair Gallardo",
        "Giri Krishnan",
        "Christopher Kanan"
      ],
      "abstract": "Embeddings produced by pre-trained deep neural networks (DNNs) are widely\nused; however, their efficacy for downstream tasks can vary widely. We study\nthe factors influencing transferability and out-of-distribution (OOD)\ngeneralization of pre-trained DNN embeddings through the lens of the tunnel\neffect hypothesis, which is closely related to intermediate neural collapse.\nThis hypothesis suggests that deeper DNN layers compress representations and\nhinder OOD generalization. Contrary to earlier work, our experiments show this\nis not a universal phenomenon. We comprehensively investigate the impact of DNN\narchitecture, training data, image resolution, and augmentations on\ntransferability. We identify that training with high-resolution datasets\ncontaining many classes greatly reduces representation compression and improves\ntransferability. Our results emphasize the danger of generalizing findings from\ntoy datasets to broader contexts.",
      "tldr_zh": "这篇论文探讨了影响预训练深度神经网络(DNNs)嵌入在out-of-distribution (OOD) 泛化中的关键变量，通过隧道效应假设（与intermediate neural collapse相关）作为分析框架。研究者实验调查了DNN架构、训练数据、图像分辨率和增强等因素，结果显示隧道效应并非普遍现象，使用高分辨率数据集并包含许多类别可显著减少表示压缩并提升转移能力。论文强调，不能将玩具数据集的发现泛化到更广泛的实际场景，以避免潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.15018v3",
      "published_date": "2024-05-23 19:43:45 UTC",
      "updated_date": "2024-10-25 14:14:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:47:45.246874"
    },
    {
      "arxiv_id": "2405.15007v1",
      "title": "RE-Adapt: Reverse Engineered Adaptation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "William Fleshman",
        "Benjamin Van Durme"
      ],
      "abstract": "We introduce RE-Adapt, an approach to fine-tuning large language models on\nnew domains without degrading any pre-existing instruction-tuning. We reverse\nengineer an adapter which isolates what an instruction-tuned model has learned\nbeyond its corresponding pretrained base model. Importantly, this requires no\nadditional data or training. We can then fine-tune the base model on a new\ndomain and readapt it to instruction following with the reverse engineered\nadapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other\nmethods of fine-tuning, across multiple popular LLMs and datasets, even when\nthe models are used in conjunction with retrieval-augmented generation.",
      "tldr_zh": "该论文提出 RE-Adapt 方法，用于在不影响现有指令微调的情况下，对大型语言模型(LLMs)进行新领域的微调。具体来说，该方法通过逆向工程一个适配器，隔离指令微调模型相对于预训练基模型的额外学习，无需额外数据或训练，即可在新领域微调基模型并使用适配器重新适应指令遵循。实验结果显示，RE-Adapt 及其低秩变体 LoRE-Adapt 在多个流行 LLM 和数据集上优于其他微调方法，即使结合检索增强生成(retrieval-augmented generation)技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15007v1",
      "published_date": "2024-05-23 19:23:40 UTC",
      "updated_date": "2024-05-23 19:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:47:57.049936"
    },
    {
      "arxiv_id": "2406.18552v1",
      "title": "Decoding Decision Reasoning: A Counterfactual-Powered Model for Knowledge Discovery",
      "title_zh": "决策推理的解",
      "authors": [
        "Yingying Fang",
        "Zihao Jin",
        "Xiaodan Xing",
        "Simon Walsh",
        "Guang Yang"
      ],
      "abstract": "In medical imaging, particularly in early disease detection and prognosis\ntasks, discerning the rationale behind an AI model's predictions is crucial for\nevaluating the reliability of its decisions. Conventional explanation methods\nface challenges in identifying discernible decisive features in medical image\nclassifications, where discriminative features are subtle or not immediately\napparent. To bridge this gap, we propose an explainable model that is equipped\nwith both decision reasoning and feature identification capabilities. Our\napproach not only detects influential image patterns but also uncovers the\ndecisive features that drive the model's final predictions. By implementing our\nmethod, we can efficiently identify and visualise class-specific features\nleveraged by the data-driven model, providing insights into the decision-making\nprocesses of deep learning models. We validated our model in the demanding\nrealm of medical prognosis task, demonstrating its efficacy and potential in\nenhancing the reliability of AI in healthcare and in discovering new knowledge\nin diseases where prognostic understanding is limited.",
      "tldr_zh": "该论文提出了一种 Counterfactual-Powered Model，用于医疗成像领域解释 AI 模型的决策推理，旨在解决传统方法在识别微妙鉴别特征方面的挑战。模型结合决策推理和特征识别能力，能够检测影响图像模式的模式并可视化驱动最终预测的类特定特征，从而提供对深度学习模型决策过程的洞见。在医疗预后任务中验证后，该方法显著提升了 AI 在医疗中的可靠性和知识发现潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18552v1",
      "published_date": "2024-05-23 19:00:38 UTC",
      "updated_date": "2024-05-23 19:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:48:10.001952"
    },
    {
      "arxiv_id": "2405.14995v1",
      "title": "Lower Bound on the Greedy Approximation Ratio for Adaptive Submodular Cover",
      "title_zh": "翻译失败",
      "authors": [
        "Blake Harris",
        "Viswanath Nagarajan"
      ],
      "abstract": "We show that the greedy algorithm for adaptive-submodular cover has\napproximation ratio at least 1.3*(1+ln Q). Moreover, the instance demonstrating\nthis gap has Q=1. So, it invalidates a prior result in the paper ``Adaptive\nSubmodularity: A New Approach to Active Learning and Stochastic Optimization''\nby Golovin-Krause, that claimed a (1+ln Q)^2 approximation ratio for the same\nalgorithm.",
      "tldr_zh": "该论文证明了在adaptive-submodular cover问题中，greedy algorithm的逼近比下界至少为1.3*(1+ln Q)。研究者通过构建一个Q=1的特定实例来展示这一差距，从而invalidates了Golovin-Krause论文中声称的(1+ln Q)^2逼近比。总体而言，此工作为改进adaptive-submodular cover算法提供了更准确的理论基础。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "7 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:2208.08351",
      "pdf_url": "http://arxiv.org/pdf/2405.14995v1",
      "published_date": "2024-05-23 18:56:46 UTC",
      "updated_date": "2024-05-23 18:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:48:21.842725"
    },
    {
      "arxiv_id": "2405.14982v1",
      "title": "In-context Time Series Predictor",
      "title_zh": "基于上下文的时间序列预测器",
      "authors": [
        "Jiecheng Lu",
        "Yan Sun",
        "Shihao Yang"
      ],
      "abstract": "Recent Transformer-based large language models (LLMs) demonstrate in-context\nlearning ability to perform various functions based solely on the provided\ncontext, without updating model parameters. To fully utilize the in-context\ncapabilities in time series forecasting (TSF) problems, unlike previous\nTransformer-based or LLM-based time series forecasting methods, we reformulate\n\"time series forecasting tasks\" as input tokens by constructing a series of\n(lookback, future) pairs within the tokens. This method aligns more closely\nwith the inherent in-context mechanisms, and is more parameter-efficient\nwithout the need of using pre-trained LLM parameters. Furthermore, it addresses\nissues such as overfitting in existing Transformer-based TSF models,\nconsistently achieving better performance across full-data, few-shot, and\nzero-shot settings compared to previous architectures.",
      "tldr_zh": "该论文提出了一种名为 In-context Time Series Predictor 的方法，利用 Transformer-based LLMs 的 in-context learning 能力来进行时间序列预测（TSF），无需更新模型参数。方法通过将 TSF 任务重新表述为输入 tokens 的 (lookback, future) 对形式，更好地契合 in-context 机制，并实现参数高效的设计。相比现有 Transformer-based 或 LLM-based 模型，该方法解决了过拟合问题，并在 full-data、few-shot 和 zero-shot 设置中 consistently 取得了更好的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14982v1",
      "published_date": "2024-05-23 18:37:00 UTC",
      "updated_date": "2024-05-23 18:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:48:33.443667"
    },
    {
      "arxiv_id": "2405.15824v1",
      "title": "Efficient Mitigation of Bus Bunching through Setter-Based Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Avidan Shah",
        "Danny Tran",
        "Yuhan Tang"
      ],
      "abstract": "Curriculum learning has been growing in the domain of reinforcement learning\nas a method of improving training efficiency for various tasks. It involves\nmodifying the difficulty (lessons) of the environment as the agent learns, in\norder to encourage more optimal agent behavior and higher reward states.\nHowever, most curriculum learning methods currently involve discrete\ntransitions of the curriculum or predefined steps by the programmer or using\nautomatic curriculum learning on only a small subset training such as only on\nan adversary. In this paper, we propose a novel approach to curriculum learning\nthat uses a Setter Model to automatically generate an action space, adversary\nstrength, initialization, and bunching strength. Transportation and traffic\noptimization is a well known area of study, especially for reinforcement\nlearning based solutions. We specifically look at the bus bunching problem for\nthe context of this study. The main idea of the problem is to minimize the\ndelays caused by inefficient bus timings for passengers arriving and departing\nfrom a system of buses. While the heavy exploration in the area makes\ninnovation and improvement with regards to performance marginal, it\nsimultaneously provides an effective baseline for developing new generalized\ntechniques. Our group is particularly interested in examining curriculum\nlearning and its effect on training efficiency and overall performance. We\ndecide to try a lesser known approach to curriculum learning, in which the\ncurriculum is not fixed or discretely thresholded. Our method for automated\ncurriculum learning involves a curriculum that is dynamically chosen and\nlearned by an adversary network made to increase the difficulty of the agent's\ntraining, and defined by multiple forms of input. Our results are shown in the\nfollowing sections of this paper.",
      "tldr_zh": "本论文提出了一种基于 Setter Model 的课程学习方法，用于高效缓解公交车聚集（Bus Bunching）问题。该方法通过 Setter Model 自动生成行动空间、对手强度、初始化和聚集强度，实现动态课程学习，由对手网络（adversary network）控制训练难度，以提升强化学习（Reinforcement Learning）代理的效率和性能。相比传统课程学习，该方法避免了离散阈值设置，提供更自动化的适应性优化。实验结果表明，该方法在公交系统优化任务中显著提高了训练效率和整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.15824v1",
      "published_date": "2024-05-23 18:26:55 UTC",
      "updated_date": "2024-05-23 18:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:48:47.180905"
    },
    {
      "arxiv_id": "2405.14974v3",
      "title": "LOVA3: Learning to Visual Question Answering, Asking and Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Hengyuan Zhao",
        "Pan Zhou",
        "Difei Gao",
        "Zechen Bai",
        "Mike Zheng Shou"
      ],
      "abstract": "Question answering, asking, and assessment are three innate human traits\ncrucial for understanding the world and acquiring knowledge. By enhancing these\ncapabilities, humans can more effectively utilize data, leading to better\ncomprehension and learning outcomes. Current Multimodal Large Language Models\n(MLLMs) primarily focus on question answering, often neglecting the full\npotential of questioning and assessment skills. Inspired by the human learning\nmechanism, we introduce LOVA3, an innovative framework named \"Learning tO\nVisual question Answering, Asking and Assessment,\" designed to equip MLLMs with\nthese additional capabilities. Our approach involves the creation of two\nsupplementary training tasks GenQA and EvalQA, aiming at fostering the skills\nof asking and assessing questions in the context of images. To develop the\nquestioning ability, we compile a comprehensive set of multimodal foundational\ntasks. For assessment, we introduce a new benchmark called EvalQABench,\ncomprising 64,000 training samples (split evenly between positive and negative\nsamples) and 5,000 validation and testing samples. We posit that enhancing\nMLLMs with the capabilities to answer, ask, and assess questions will enhance\ntheir multimodal comprehension, ultimately improving overall performance. To\nvalidate this hypothesis, we train MLLMs using the LOVA3 framework and evaluate\nthem on a range of multimodal datasets and benchmarks. Our results demonstrate\nconsistent performance gains, underscoring the critical role of these\nadditional tasks in fostering comprehensive intelligence in MLLMs. The code is\navailable at https://github.com/showlab/LOVA3.",
      "tldr_zh": "这篇论文提出 LOVA3 框架，旨在增强多模态大语言模型 (MLLMs) 的视觉问答、提问和评估能力，以模拟人类学习机制，弥补当前模型对提问和评估技能的忽视。框架包括两个辅助训练任务：GenQA 用于培养提问技能，以及 EvalQA 用于评估技能，并编译了一个全面的多模态基础任务集。论文还引入了新基准 EvalQABench（包含 64,000 训练样本和 5,000 验证/测试样本）来评估模型性能。实验结果显示，使用 LOVA3 框架训练的 MLLMs 在多种多模态数据集上实现了显著的性能提升，证明了这些能力的综合重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024. The code is available at\n  https://github.com/showlab/LOVA3",
      "pdf_url": "http://arxiv.org/pdf/2405.14974v3",
      "published_date": "2024-05-23 18:21:59 UTC",
      "updated_date": "2025-02-19 23:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:48:58.205305"
    },
    {
      "arxiv_id": "2405.14966v1",
      "title": "Creativity and Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Joonas Lahikainen",
        "Nadia M. Ady",
        "Christian Guckelsberger"
      ],
      "abstract": "Creativity is already regularly attributed to AI systems outside specialised\ncomputational creativity (CC) communities. However, the evaluation of\ncreativity in AI at large typically lacks grounding in creativity theory, which\ncan promote inappropriate attributions and limit the analysis of creative\nbehaviour. While CC researchers have translated psychological theory into\nformal models, the value of these models is limited by a gap to common AI\nframeworks. To mitigate this limitation, we identify formal mappings between\nBoden's process theory of creativity and Markov Decision Processes (MDPs),\nusing the Creative Systems Framework as a stepping stone. We study three out of\neleven mappings in detail to understand which types of creative processes,\nopportunities for (aberrations), and threats to creativity (uninspiration)\ncould be observed in an MDP. We conclude by discussing quality criteria for the\nselection of such mappings for future work and applications.",
      "tldr_zh": "该论文探讨了 AI 系统中的创造力评估问题，指出现有方法往往缺乏对创造力理论的 grounding，导致不当归因和分析局限。作者通过 Creative Systems Framework 作为桥梁，识别了 Boden's process theory 与 Markov Decision Processes (MDPs) 之间的正式映射，并详细研究了三个映射，以分析在 MDPs 中可能出现的创造过程、创造机会（包括异常）和威胁（如 uninspiration）。最终，论文讨论了选择这些映射的质量标准，为将创造力理论应用于 AI 框架提供了指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, full paper at 15th International Conference on\n  Computational Creativity, ICCC'24",
      "pdf_url": "http://arxiv.org/pdf/2405.14966v1",
      "published_date": "2024-05-23 18:16:42 UTC",
      "updated_date": "2024-05-23 18:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:49:09.269821"
    },
    {
      "arxiv_id": "2405.14959v3",
      "title": "EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxu Wang",
        "Junhao He",
        "Ziyi Zhang",
        "Mingyuan Sun",
        "Jingkai Sun",
        "Renjing Xu"
      ],
      "abstract": "Event cameras offer promising advantages such as high dynamic range and low\nlatency, making them well-suited for challenging lighting conditions and\nfast-moving scenarios. However, reconstructing 3D scenes from raw event streams\nis difficult because event data is sparse and does not carry absolute color\ninformation. To release its potential in 3D reconstruction, we propose the\nfirst event-based generalizable 3D reconstruction framework, called EvGGS,\nwhich reconstructs scenes as 3D Gaussians from only event input in a\nfeedforward manner and can generalize to unseen cases without any retraining.\nThis framework includes a depth estimation module, an intensity reconstruction\nmodule, and a Gaussian regression module. These submodules connect in a\ncascading manner, and we collaboratively train them with a designed joint loss\nto make them mutually promote. To facilitate related studies, we build a novel\nevent-based 3D dataset with various material objects and calibrated labels of\ngrayscale images, depth maps, camera poses, and silhouettes. Experiments show\nmodels that have jointly trained significantly outperform those trained\nindividually. Our approach performs better than all baselines in reconstruction\nquality, and depth/intensity predictions with satisfactory rendering speed.",
      "tldr_zh": "本论文提出EvGGS框架，这是首个基于Event cameras的事件数据进行通用3D高斯重建（3D Gaussians）的学习框架，能够从稀疏事件流中前向重建场景，并泛化到未见场景无需重新训练。框架包括深度估计模块、强度重建模块和高斯回归模块，这些子模块级联连接，并通过设计的联合损失函数协同训练以相互提升。为支持研究，该论文构建了一个新的事件-based 3D数据集，包含灰度图像、深度图、相机位姿和轮廓。实验结果表明，联合训练的模型在重建质量、深度/强度预测和渲染速度上显著优于单独训练的基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14959v3",
      "published_date": "2024-05-23 18:10:26 UTC",
      "updated_date": "2024-10-10 07:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:49:22.429525"
    },
    {
      "arxiv_id": "2405.14957v1",
      "title": "Understanding the dynamics of the frequency bias in neural networks",
      "title_zh": "理解神经网络中频率偏差的动态",
      "authors": [
        "Juan Molina",
        "Mircea Petrache",
        "Francisco Sahli Costabal",
        "Matías Courdurier"
      ],
      "abstract": "Recent works have shown that traditional Neural Network (NN) architectures\ndisplay a marked frequency bias in the learning process. Namely, the NN first\nlearns the low-frequency features before learning the high-frequency ones. In\nthis study, we rigorously develop a partial differential equation (PDE) that\nunravels the frequency dynamics of the error for a 2-layer NN in the Neural\nTangent Kernel regime. Furthermore, using this insight, we explicitly\ndemonstrate how an appropriate choice of distributions for the initialization\nweights can eliminate or control the frequency bias. We focus our study on the\nFourier Features model, an NN where the first layer has sine and cosine\nactivation functions, with frequencies sampled from a prescribed distribution.\nIn this setup, we experimentally validate our theoretical results and compare\nthe NN dynamics to the solution of the PDE using the finite element method.\nFinally, we empirically show that the same principle extends to multi-layer\nNNs.",
      "tldr_zh": "本研究揭示了神经网络（NN）在学习过程中的频率偏差现象，即NN优先学习低频特征而非高频特征。通过开发一个偏微分方程（PDE），作者在Neural Tangent Kernel制度下分析了2层NN的频率动态，并证明了通过选择适当的初始化权重分布可以消除或控制这一偏差。聚焦于Fourier Features模型，该模型使用正弦和余弦激活函数采样频率，实验结果验证了理论预测，并使用有限元方法比较了NN动态与PDE解决方案。最后，研究显示这一原则可扩展至多层NN，为优化NN学习过程提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14957v1",
      "published_date": "2024-05-23 18:09:16 UTC",
      "updated_date": "2024-05-23 18:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:49:34.032235"
    },
    {
      "arxiv_id": "2405.14956v1",
      "title": "Interpretable and Editable Programmatic Tree Policies for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hector Kohler",
        "Quentin Delfosse",
        "Riad Akrour",
        "Kristian Kersting",
        "Philippe Preux"
      ],
      "abstract": "Deep reinforcement learning agents are prone to goal misalignments. The\nblack-box nature of their policies hinders the detection and correction of such\nmisalignments, and the trust necessary for real-world deployment. So far,\nsolutions learning interpretable policies are inefficient or require many human\npriors. We propose INTERPRETER, a fast distillation method producing\nINTerpretable Editable tRee Programs for ReinforcEmenT lEaRning. We empirically\ndemonstrate that INTERPRETER compact tree programs match oracles across a\ndiverse set of sequential decision tasks and evaluate the impact of our design\nchoices on interpretability and performances. We show that our policies can be\ninterpreted and edited to correct misalignments on Atari games and to explain\nreal farming strategies.",
      "tldr_zh": "本论文针对深度强化学习(Reinforcement Learning)代理的目标失调问题，提出了一种快速蒸馏方法INTERPRETER，以生成可解释且可编辑的树状程序，从而解决黑箱政策的检测和修正难题。该方法无需过多人为先验，就能产生紧凑的树状程序，并在多种顺序决策任务中匹配或超过基准性能。实验结果显示，INTERPRETER可用于解释和编辑政策，如在Atari游戏中修正失调行为，并解释真实农业策略，从而提升代理的可信度和实际部署潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14956v1",
      "published_date": "2024-05-23 18:07:38 UTC",
      "updated_date": "2024-05-23 18:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:49:45.528883"
    },
    {
      "arxiv_id": "2405.14953v5",
      "title": "MallowsPO: Fine-Tune Your LLM with Preference Dispersions",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxian Chen",
        "Hanyang Zhao",
        "Henry Lam",
        "David Yao",
        "Wenpin Tang"
      ],
      "abstract": "Direct Preference Optimization (DPO) has recently emerged as a popular\napproach to improve reinforcement learning with human feedback (RLHF), leading\nto better techniques to fine-tune large language models (LLM). A weakness of\nDPO, however, lies in its lack of capability to characterize the diversity of\nhuman preferences. Inspired by Mallows' theory of preference ranking, we\ndevelop in this paper a new approach, the MallowsPO. A distinct feature of this\napproach is a dispersion index, which reflects the dispersion of human\npreference to prompts. We show that existing DPO models can be reduced to\nspecial cases of this dispersion index, thus unified with MallowsPO. More\nimportantly, we demonstrate (empirically) how to use this dispersion index to\nenhance the performance of DPO in a broad array of benchmark tasks, from\nsynthetic bandit selection to controllable generations and dialogues, while\nmaintaining great generalization capabilities. MallowsPO is also compatible\nwith other SOTA offline preference optimization methods, boosting nearly 2\\%\nextra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.",
      "tldr_zh": "该论文针对 Direct Preference Optimization (DPO) 在处理人类偏好多样性方面的不足，提出了一种新方法 MallowsPO，受 Mallows 偏好排名理论启发。MallowsPO 引入 dispersion index 来量化人类偏好对提示的分散程度，并将现有 DPO 模型统一为其特殊情况。实验结果显示，该方法在合成任务、生成和对话等基准上显著提升 DPO 性能，同时保持良好的泛化能力，并与 SOTA 方法兼容，在 Llama3-Instruct 微调中提升约 2% LC 胜率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14953v5",
      "published_date": "2024-05-23 18:01:11 UTC",
      "updated_date": "2025-04-17 18:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:49:58.234867"
    },
    {
      "arxiv_id": "2405.14869v2",
      "title": "PuzzleAvatar: Assembling 3D Avatars from Personal Albums",
      "title_zh": "PuzzleAvatar：从个人相册组装 3D 虚拟角色",
      "authors": [
        "Yuliang Xiu",
        "Yufei Ye",
        "Zhen Liu",
        "Dimitrios Tzionas",
        "Michael J. Black"
      ],
      "abstract": "Generating personalized 3D avatars is crucial for AR/VR. However, recent\ntext-to-3D methods that generate avatars for celebrities or fictional\ncharacters, struggle with everyday people. Methods for faithful reconstruction\ntypically require full-body images in controlled settings. What if a user could\njust upload their personal \"OOTD\" (Outfit Of The Day) photo collection and get\na faithful avatar in return? The challenge is that such casual photo\ncollections contain diverse poses, challenging viewpoints, cropped views, and\nocclusion (albeit with a consistent outfit, accessories and hairstyle). We\naddress this novel \"Album2Human\" task by developing PuzzleAvatar, a novel model\nthat generates a faithful 3D avatar (in a canonical pose) from a personal OOTD\nalbum, while bypassing the challenging estimation of body and camera pose. To\nthis end, we fine-tune a foundational vision-language model (VLM) on such\nphotos, encoding the appearance, identity, garments, hairstyles, and\naccessories of a person into (separate) learned tokens and instilling these\ncues into the VLM. In effect, we exploit the learned tokens as \"puzzle pieces\"\nfrom which we assemble a faithful, personalized 3D avatar. Importantly, we can\ncustomize avatars by simply inter-changing tokens. As a benchmark for this new\ntask, we collect a new dataset, called PuzzleIOI, with 41 subjects in a total\nof nearly 1K OOTD configurations, in challenging partial photos with paired\nground-truth 3D bodies. Evaluation shows that PuzzleAvatar not only has high\nreconstruction accuracy, outperforming TeCH and MVDreamBooth, but also a unique\nscalability to album photos, and strong robustness. Our code and data are\npublicly available for research purpose at https://puzzleavatar.is.tue.mpg.de/",
      "tldr_zh": "该研究提出 PuzzleAvatar 模型，旨在从用户的个人 OOTD（Outfit Of The Day）照片集生成忠实的 3D 头像，解决现有 text-to-3D 方法在处理日常人物图像时的挑战，如多样姿势、视角和遮挡。模型通过微调基础 VLM（Vision-Language Model），将个人的外观、身份、服装、发型和配件编码成独立的 learned tokens，并将这些 tokens 视为“拼图碎片”来组装标准姿势的 3D 头像，同时支持通过交换 tokens 进行自定义。实验在新建的 PuzzleIOI 数据集（包含 41 个主题和近 1K 配置的照片）上表明，PuzzleAvatar 在重建准确性上优于 TeCH 和 MVDreamBooth，并展现出强大的可扩展性和鲁棒性。代码和数据已公开可用，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Page: https://puzzleavatar.is.tue.mpg.de/, Code:\n  https://github.com/YuliangXiu/PuzzleAvatar, Video:\n  https://youtu.be/0hpXH2tVPk4",
      "pdf_url": "http://arxiv.org/pdf/2405.14869v2",
      "published_date": "2024-05-23 17:59:56 UTC",
      "updated_date": "2024-09-14 19:08:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:50:11.645581"
    },
    {
      "arxiv_id": "2405.14868v2",
      "title": "Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Basile Van Hoorick",
        "Rundi Wu",
        "Ege Ozguroglu",
        "Kyle Sargent",
        "Ruoshi Liu",
        "Pavel Tokmakov",
        "Achal Dave",
        "Changxi Zheng",
        "Carl Vondrick"
      ],
      "abstract": "Accurate reconstruction of complex dynamic scenes from just a single\nviewpoint continues to be a challenging task in computer vision. Current\ndynamic novel view synthesis methods typically require videos from many\ndifferent camera viewpoints, necessitating careful recording setups, and\nsignificantly restricting their utility in the wild as well as in terms of\nembodied AI applications. In this paper, we propose $\\textbf{GCD}$, a\ncontrollable monocular dynamic view synthesis pipeline that leverages\nlarge-scale diffusion priors to, given a video of any scene, generate a\nsynchronous video from any other chosen perspective, conditioned on a set of\nrelative camera pose parameters. Our model does not require depth as input, and\ndoes not explicitly model 3D scene geometry, instead performing end-to-end\nvideo-to-video translation in order to achieve its goal efficiently. Despite\nbeing trained on synthetic multi-view video data only, zero-shot real-world\ngeneralization experiments show promising results in multiple domains,\nincluding robotics, object permanence, and driving environments. We believe our\nframework can potentially unlock powerful applications in rich dynamic scene\nunderstanding, perception for robotics, and interactive 3D video viewing\nexperiences for virtual reality.",
      "tldr_zh": "该论文提出了Generative Camera Dolly (GCD)，一个可控的单目动态新视图合成框架，能够从单一视角视频生成任意视角的同步视频，解决了传统方法依赖多视角录制的限制。\nGCD 利用大规模diffusion priors 进行端到端视频到视频翻译，不需要深度输入或显式3D场景几何建模，仅通过相对相机位姿参数进行条件生成。\n尽管仅在合成多视图视频数据上训练，该模型在零样本真实世界泛化实验中表现出色，适用于机器人、物体永久性(object permanence)和驾驶环境等领域，并为动态场景理解、机器人感知和交互式3D视频查看带来潜在应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. Project webpage is available at:\n  https://gcd.cs.columbia.edu/",
      "pdf_url": "http://arxiv.org/pdf/2405.14868v2",
      "published_date": "2024-05-23 17:59:52 UTC",
      "updated_date": "2024-07-05 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:50:22.477036"
    },
    {
      "arxiv_id": "2405.14863v1",
      "title": "A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns",
      "title_zh": "翻译失败",
      "authors": [
        "Asaf Yehudai",
        "Taelin Karidi",
        "Gabriel Stanovsky",
        "Ariel Goldstein",
        "Omri Abend"
      ],
      "abstract": "Cross-domain alignment refers to the task of mapping a concept from one\ndomain to another. For example, ``If a \\textit{doctor} were a \\textit{color},\nwhat color would it be?''. This seemingly peculiar task is designed to\ninvestigate how people represent concrete and abstract concepts through their\nmappings between categories and their reasoning processes over those mappings.\nIn this paper, we adapt this task from cognitive science to evaluate the\nconceptualization and reasoning abilities of large language models (LLMs)\nthrough a behavioral study. We examine several LLMs by prompting them with a\ncross-domain mapping task and analyzing their responses at both the population\nand individual levels. Additionally, we assess the models' ability to reason\nabout their predictions by analyzing and categorizing their explanations for\nthese mappings. The results reveal several similarities between humans' and\nmodels' mappings and explanations, suggesting that models represent concepts\nsimilarly to humans. This similarity is evident not only in the model\nrepresentation but also in their behavior. Furthermore, the models mostly\nprovide valid explanations and deploy reasoning paths that are similar to those\nof humans.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中的跨领域对齐（Cross-domain alignment），通过将认知科学任务（如将“医生”映射为一种颜色）应用于评估模型的概念化和推理能力。研究者通过行为实验提示多个LLMs进行跨领域映射，并分析其响应在群体和个体水平上的模式，以及对预测的解释。结果显示，LLMs的映射和解释与人类高度相似，不仅在概念表示上，而且在行为和推理路径上表现出类似的人类模式，这为理解模型的认知机制提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "CogSci",
      "pdf_url": "http://arxiv.org/pdf/2405.14863v1",
      "published_date": "2024-05-23 17:59:26 UTC",
      "updated_date": "2024-05-23 17:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:50:33.324575"
    },
    {
      "arxiv_id": "2405.14861v2",
      "title": "Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gen Li",
        "Yuling Yan"
      ],
      "abstract": "This paper investigates score-based diffusion models when the underlying\ntarget distribution is concentrated on or near low-dimensional manifolds within\nthe higher-dimensional space in which they formally reside, a common\ncharacteristic of natural image distributions. Despite previous efforts to\nunderstand the data generation process of diffusion models, existing\ntheoretical support remains highly suboptimal in the presence of\nlow-dimensional structure, which we strengthen in this paper. For the popular\nDenoising Diffusion Probabilistic Model (DDPM), we find that the dependency of\nthe error incurred within each denoising step on the ambient dimension $d$ is\nin general unavoidable. We further identify a unique design of coefficients\nthat yields a converges rate at the order of $O(k^{2}/\\sqrt{T})$ (up to log\nfactors), where $k$ is the intrinsic dimension of the target distribution and\n$T$ is the number of steps. This represents the first theoretical demonstration\nthat the DDPM sampler can adapt to unknown low-dimensional structures in the\ntarget distribution, highlighting the critical importance of coefficient\ndesign. All of this is achieved by a novel set of analysis tools that\ncharacterize the algorithmic dynamics in a more deterministic manner.",
      "tldr_zh": "本研究探讨了score-based diffusion models在目标分布集中在高维空间中的低维流形上的表现，这在自然图像分布中很常见。论文发现，对于Denoising Diffusion Probabilistic Model (DDPM)，每个去噪步骤的错误不可避免地依赖于环境维度$d$，但通过一种独特的系数设计，可实现收敛率达到$O(k^2 / \\sqrt{T})$（加上log因素），其中$k$是目标分布的内在维度，$T$是步骤数。这标志着首次理论证明DDPM采样器能适应未知的低维结构，并强调了系数设计的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14861v2",
      "published_date": "2024-05-23 17:59:10 UTC",
      "updated_date": "2024-12-31 01:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:50:45.708449"
    },
    {
      "arxiv_id": "2405.14925v1",
      "title": "PILOT: Equivariant diffusion for pocket conditioned de novo ligand generation with multi-objective guidance via importance sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Cremer",
        "Tuan Le",
        "Frank Noé",
        "Djork-Arné Clevert",
        "Kristof T. Schütt"
      ],
      "abstract": "The generation of ligands that both are tailored to a given protein pocket\nand exhibit a range of desired chemical properties is a major challenge in\nstructure-based drug design. Here, we propose an in-silico approach for the\n$\\textit{de novo}$ generation of 3D ligand structures using the equivariant\ndiffusion model PILOT, combining pocket conditioning with a large-scale\npre-training and property guidance. Its multi-objective trajectory-based\nimportance sampling strategy is designed to direct the model towards molecules\nthat not only exhibit desired characteristics such as increased binding\naffinity for a given protein pocket but also maintains high synthetic\naccessibility. This ensures the practicality of sampled molecules, thus\nmaximizing their potential for the drug discovery pipeline. PILOT significantly\noutperforms existing methods across various metrics on the common benchmark\ndataset CrossDocked2020. Moreover, we employ PILOT to generate novel ligands\nfor unseen protein pockets from the Kinodata-3D dataset, which encompasses a\nsubstantial portion of the human kinome. The generated structures exhibit\npredicted $IC_{50}$ values indicative of potent biological activity, which\nhighlights the potential of PILOT as a powerful tool for structure-based drug\ndesign.",
      "tldr_zh": "该研究提出了一种名为 PILOT 的 equivariant diffusion 模型，用于结构化药物设计中的 de novo 配体生成。该模型通过 pocket conditioning、大规模预训练和多目标轨迹-based importance sampling 策略，确保生成的 3D 配体不仅具有高结合亲和力，还保持高合成可及性，从而提升其在药物发现管道中的实用性。在 CrossDocked2020 基准数据集上，PILOT 显著优于现有方法，并在 Kinodata-3D 数据集的未见蛋白口袋上生成具有低 $IC_{50}$ 值的潜在活性配体，展示了其在结构基药物设计中的强大潜力。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14925v1",
      "published_date": "2024-05-23 17:58:28 UTC",
      "updated_date": "2024-05-23 17:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:50:58.135928"
    },
    {
      "arxiv_id": "2405.14857v3",
      "title": "Conditional Diffusion on Web-Scale Image Pairs leads to Diverse Image Variations",
      "title_zh": "条件扩散在网络规模图像对上导致多样化的图像变体",
      "authors": [
        "Manoj Kumar",
        "Neil Houlsby",
        "Emiel Hoogeboom"
      ],
      "abstract": "Generating image variations, where a model produces variations of an input\nimage while preserving the semantic context has gained increasing attention.\nCurrent image variation techniques involve adapting a text-to-image model to\nreconstruct an input image conditioned on the same image. We first demonstrate\nthat a diffusion model trained to reconstruct an input image from frozen\nembeddings, can reconstruct the image with minor variations. Second, inspired\nby how text-to-image models learn from web-scale text-image pairs, we explore a\nnew pretraining strategy to generate image variations using a large collection\nof image pairs. Our diffusion model \\textit{Semantica} receives a random\n(encoded) image from a webpage as conditional input and denoises another noisy\nrandom image from the same webpage. We carefully examine various design choices\nfor the image encoder, given its crucial role in extracting relevant context\nfrom the input image. Once trained, \\textit{Semantica} can adaptively generate\nnew images from a dataset by simply using images from that dataset as input.\nFinally, we identify limitations in standard image consistency metrics for\nevaluating image variations and propose alternative metrics based on few-shot\ngeneration.",
      "tldr_zh": "本论文探讨了生成图像变体的方法，旨在在保留输入图像语义上下文的同时产生多样变化。作者提出了一种新预训练策略，使用网页规模的图像对训练扩散模型Semantica，该模型以随机图像作为条件输入，对另一噪声图像进行去噪处理，并通过优化图像编码器提取相关上下文。实验结果显示，Semantica能有效生成多样图像变体，同时论文指出了标准图像一致性指标的局限性，并引入了基于少样本生成的替代评估指标。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14857v3",
      "published_date": "2024-05-23 17:58:03 UTC",
      "updated_date": "2024-10-02 10:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:51:12.623903"
    },
    {
      "arxiv_id": "2405.14855v1",
      "title": "Synergistic Global-space Camera and Human Reconstruction from Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhou Zhao",
        "Tuanfeng Y. Wang",
        "Bhiksha Raj",
        "Min Xu",
        "Jimei Yang",
        "Chun-Hao Paul Huang"
      ],
      "abstract": "Remarkable strides have been made in reconstructing static scenes or human\nbodies from monocular videos. Yet, the two problems have largely been\napproached independently, without much synergy. Most visual SLAM methods can\nonly reconstruct camera trajectories and scene structures up to scale, while\nmost HMR methods reconstruct human meshes in metric scale but fall short in\nreasoning with cameras and scenes. This work introduces Synergistic Camera and\nHuman Reconstruction (SynCHMR) to marry the best of both worlds. Specifically,\nwe design Human-aware Metric SLAM to reconstruct metric-scale camera poses and\nscene point clouds using camera-frame HMR as a strong prior, addressing depth,\nscale, and dynamic ambiguities. Conditioning on the dense scene recovered, we\nfurther learn a Scene-aware SMPL Denoiser to enhance world-frame HMR by\nincorporating spatio-temporal coherency and dynamic scene constraints.\nTogether, they lead to consistent reconstructions of camera trajectories, human\nmeshes, and dense scene point clouds in a common world frame. Project page:\nhttps://paulchhuang.github.io/synchmr",
      "tldr_zh": "该论文提出SynCHMR方法，旨在将视觉SLAM和HMR（人体网格重建）相结合，从单目视频中协同重建全局空间的相机轨迹、人体网格和密集场景点云。核心方法包括Human-aware Metric SLAM，使用HMR作为先验来解决深度、比例和动态模糊，从而重建度量尺度的相机位姿和场景点云；以及Scene-aware SMPL Denoiser，通过融入空间-时间连贯性和动态场景约束，进一步提升世界坐标系下的HMR精度。最终，SynCHMR实现了相机轨迹、人体网格和场景结构在共同世界框架下的一致重建，为多模态重建任务提供了协同框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14855v1",
      "published_date": "2024-05-23 17:57:50 UTC",
      "updated_date": "2024-05-23 17:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:51:21.532579"
    },
    {
      "arxiv_id": "2405.14853v1",
      "title": "Privileged Sensing Scaffolds Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Edward S. Hu",
        "James Springer",
        "Oleh Rybkin",
        "Dinesh Jayaraman"
      ],
      "abstract": "We need to look at our shoelaces as we first learn to tie them but having\nmastered this skill, can do it from touch alone. We call this phenomenon\n\"sensory scaffolding\": observation streams that are not needed by a master\nmight yet aid a novice learner. We consider such sensory scaffolding setups for\ntraining artificial agents. For example, a robot arm may need to be deployed\nwith just a low-cost, robust, general-purpose camera; yet its performance may\nimprove by having privileged training-time-only access to informative albeit\nexpensive and unwieldy motion capture rigs or fragile tactile sensors. For\nthese settings, we propose \"Scaffolder\", a reinforcement learning approach\nwhich effectively exploits privileged sensing in critics, world models, reward\nestimators, and other such auxiliary components that are only used at training\ntime, to improve the target policy. For evaluating sensory scaffolding agents,\nwe design a new \"S3\" suite of ten diverse simulated robotic tasks that explore\na wide range of practical sensor setups. Agents must use privileged camera\nsensing to train blind hurdlers, privileged active visual perception to help\nrobot arms overcome visual occlusions, privileged touch sensors to train robot\nhands, and more. Scaffolder easily outperforms relevant prior baselines and\nfrequently performs comparably even to policies that have test-time access to\nthe privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/",
      "tldr_zh": "本论文引入“sensory scaffolding”概念，描述在学习过程中使用辅助观察数据（如特权传感器）来帮助初学者，但最终仅需基本传感器即可执行任务。作者提出 Scaffolder 方法，该强化学习框架利用训练时的特权传感器（如运动捕捉或触觉传感器）来优化 critics、world models 和 reward estimators 等组件，从而提升目标策略的表现。在新的 S3 套件中进行的十个模拟机器人任务实验显示，Scaffolder 显著优于现有基线，甚至在测试时与有特权传感器访问的策略性能相当，为高效的机器人训练提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 Spotlight version",
      "pdf_url": "http://arxiv.org/pdf/2405.14853v1",
      "published_date": "2024-05-23 17:57:14 UTC",
      "updated_date": "2024-05-23 17:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:51:32.602867"
    },
    {
      "arxiv_id": "2405.14838v1",
      "title": "From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step",
      "title_zh": "从显式 CoT 到隐式 CoT：逐步学习内部化 CoT 步骤",
      "authors": [
        "Yuntian Deng",
        "Yejin Choi",
        "Stuart Shieber"
      ],
      "abstract": "When leveraging language models for reasoning tasks, generating explicit\nchain-of-thought (CoT) steps often proves essential for achieving high accuracy\nin final outputs. In this paper, we investigate if models can be taught to\ninternalize these CoT steps. To this end, we propose a simple yet effective\nmethod for internalizing CoT steps: starting with a model trained for explicit\nCoT reasoning, we gradually remove the intermediate steps and finetune the\nmodel. This process allows the model to internalize the intermediate reasoning\nsteps, thus simplifying the reasoning process while maintaining high\nperformance. Our approach enables a GPT-2 Small model to solve 9-by-9\nmultiplication with up to 99% accuracy, whereas standard training cannot solve\nbeyond 4-by-4 multiplication. Furthermore, our method proves effective on\nlarger language models, such as Mistral 7B, achieving over 50% accuracy on\nGSM8K without producing any intermediate steps.",
      "tldr_zh": "本文提出一种方法，将语言模型从显式 Chain-of-Thought (CoT) 推理转向隐式内部化：从训练有素的显式 CoT 模型开始，逐步移除中间步骤并进行微调，从而简化推理过程同时保持高性能。该方法使 GPT-2 Small 模型在 9-by-9 乘法任务上达到 99% 准确率，而标准训练仅限于 4-by-4 乘法。此外，在 Mistral 7B 模型上，该方法在 GSM8K 数据集上实现超过 50% 准确率，而无需输出任何中间步骤。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14838v1",
      "published_date": "2024-05-23 17:54:14 UTC",
      "updated_date": "2024-05-23 17:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:51:46.019976"
    },
    {
      "arxiv_id": "2405.17465v2",
      "title": "Information Fusion in Smart Agriculture: Machine Learning Applications and Future Research Directions",
      "title_zh": "智能农业中的信息融合：机器学习应用及未来研究方向",
      "authors": [
        "Aashu Katharria",
        "Kanchan Rajwar",
        "Millie Pant",
        "Juan D. Velásquez",
        "Václav Snášel",
        "Kusum Deep"
      ],
      "abstract": "Machine learning (ML) is a rapidly evolving technology with expanding\napplications across various fields. This paper presents a comprehensive survey\nof recent ML applications in agriculture for sustainability and efficiency.\nExisting reviews mainly focus on narrow subdomains or lack a fusion-driven\nperspectives. This study provides a combined analysis of ML applications in\nagriculture, structured around five key objectives: (i) Analyzing ML techniques\nacross pre-harvesting, harvesting, and post-harvesting phases. (ii)\nDemonstrating how ML can be used with agricultural data and data fusion. (iii)\nConducting a bibliometric and statistical analysis to reveal research trends\nand activity. (iv) Investigating real-world case studies of leading artificial\nintelligence (AI)-driven agricultural companies that use different types of\nmultisensors and multisource data. (v) Compiling publicly available datasets to\nsupport ML model training. Going beyond existing previous reviews, this review\nfocuses on how machine learning (ML) techniques, combined with multi-source\ndata fusion (integrating remote sensing, IoT, and climate analytics), enhance\nprecision agriculture by improving predictive accuracy and decision-making.\nCase studies and statistical insights illustrate the evolving landscape of AI\ndriven smart farming, while future research directions also discusses\nchallenges associated with data fusion for heterogeneous datasets. This review\nbridges the gap between AI research and agricultural applications, offering a\nroadmap for researchers, industry professionals, and policymakers to harness\ninformation fusion and ML for advancing precision agriculture.",
      "tldr_zh": "这篇论文对机器学习（ML）在智能农业中的应用进行了全面调查，强调了ML技术与数据融合相结合，以提升农业的可持续性和效率。论文围绕五个关键目标分析了ML在收获前、收获中和收获后阶段的应用，包括与农业数据融合的使用、文献计量统计分析、真实AI驱动公司案例研究，以及公开数据集的编译。研究发现，通过整合多源数据（如遥感、IoT和气候分析），ML显著提高了精准农业的预测准确性和决策能力，同时讨论了异构数据集融合的挑战，并为未来研究提供路线图，以指导研究者、行业专业人士和政策制定者推进智能农业发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17465v2",
      "published_date": "2024-05-23 17:53:31 UTC",
      "updated_date": "2025-03-18 17:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:51:58.286128"
    },
    {
      "arxiv_id": "2405.14831v3",
      "title": "HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bernal Jiménez Gutiérrez",
        "Yiheng Shu",
        "Yu Gu",
        "Michihiro Yasunaga",
        "Yu Su"
      ],
      "abstract": "In order to thrive in hostile and ever-changing natural environments,\nmammalian brains evolved to store large amounts of knowledge about the world\nand continually integrate new information while avoiding catastrophic\nforgetting. Despite the impressive accomplishments, large language models\n(LLMs), even with retrieval-augmented generation (RAG), still struggle to\nefficiently and effectively integrate a large amount of new experiences after\npre-training. In this work, we introduce HippoRAG, a novel retrieval framework\ninspired by the hippocampal indexing theory of human long-term memory to enable\ndeeper and more efficient knowledge integration over new experiences. HippoRAG\nsynergistically orchestrates LLMs, knowledge graphs, and the Personalized\nPageRank algorithm to mimic the different roles of neocortex and hippocampus in\nhuman memory. We compare HippoRAG with existing RAG methods on multi-hop\nquestion answering and show that our method outperforms the state-of-the-art\nmethods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves\ncomparable or better performance than iterative retrieval like IRCoT while\nbeing 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into\nIRCoT brings further substantial gains. Finally, we show that our method can\ntackle new types of scenarios that are out of reach of existing methods. Code\nand data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
      "tldr_zh": "该研究提出HippoRAG，一种受神经生物学启发的检索框架，旨在帮助大型语言模型(LLMs)更高效地整合新知识并避免灾难性遗忘。HippoRAG通过结合LLMs、知识图谱和Personalized PageRank算法，模拟人类记忆中新皮层和海马体的作用，实现对新体验的深度整合。在多跳问答任务上，HippoRAG比现有RAG方法提升高达20%，且其单步检索比IRCoT快6-13倍、成本低10-30倍，同时整合到IRCoT中可进一步提升性能。该框架还能处理现有方法无法覆盖的新场景，提供代码和数据以供复现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024. Code and data:\n  https://github.com/OSU-NLP-Group/HippoRAG",
      "pdf_url": "http://arxiv.org/pdf/2405.14831v3",
      "published_date": "2024-05-23 17:47:55 UTC",
      "updated_date": "2025-01-14 16:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:52:10.182524"
    },
    {
      "arxiv_id": "2405.14822v2",
      "title": "PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher",
      "title_zh": "翻译失败",
      "authors": [
        "Dongjun Kim",
        "Chieh-Hsin Lai",
        "Wei-Hsiang Liao",
        "Yuhta Takida",
        "Naoki Murata",
        "Toshimitsu Uesaka",
        "Yuki Mitsufuji",
        "Stefano Ermon"
      ],
      "abstract": "The diffusion model performs remarkable in generating high-dimensional\ncontent but is computationally intensive, especially during training. We\npropose Progressive Growing of Diffusion Autoencoder (PaGoDA), a novel pipeline\nthat reduces the training costs through three stages: training diffusion on\ndownsampled data, distilling the pretrained diffusion, and progressive\nsuper-resolution. With the proposed pipeline, PaGoDA achieves a $64\\times$\nreduced cost in training its diffusion model on 8x downsampled data; while at\nthe inference, with the single-step, it performs state-of-the-art on ImageNet\nacross all resolutions from 64x64 to 512x512, and text-to-image. PaGoDA's\npipeline can be applied directly in the latent space, adding compression\nalongside the pre-trained autoencoder in Latent Diffusion Models (e.g., Stable\nDiffusion). The code is available at https://github.com/sony/pagoda.",
      "tldr_zh": "该论文提出PaGoDA，一种创新管道，用于减少扩散模型(diffusion model)的训练成本，通过三个阶段实现：先在降采样数据上训练扩散模型、蒸馏预训练模型，以及渐进式超分辨率(progressive super-resolution)。PaGoDA在8x降采样数据上使训练成本降低64倍，并在推理阶段使用单步生成，在ImageNet上从64x64到512x512分辨率以及文本到图像任务中达到最先进性能。该管道还可直接应用于潜在空间，与预训练的自编码器如Stable Diffusion结合，实现进一步压缩。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14822v2",
      "published_date": "2024-05-23 17:39:09 UTC",
      "updated_date": "2024-10-29 15:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:52:21.993790"
    },
    {
      "arxiv_id": "2405.20347v1",
      "title": "Small Language Models for Application Interactions: A Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Beibin Li",
        "Yi Zhang",
        "Sébastien Bubeck",
        "Jeevan Pathuri",
        "Ishai Menache"
      ],
      "abstract": "We study the efficacy of Small Language Models (SLMs) in facilitating\napplication usage through natural language interactions. Our focus here is on a\nparticular internal application used in Microsoft for cloud supply chain\nfulfilment. Our experiments show that small models can outperform much larger\nones in terms of both accuracy and running time, even when fine-tuned on small\ndatasets. Alongside these results, we also highlight SLM-based system design\nconsiderations.",
      "tldr_zh": "这篇论文通过一个案例研究，探讨了Small Language Models (SLMs)在促进应用交互方面的效能，焦点是微软用于云供应链履行的内部应用。实验结果显示，SLMs在准确性和运行时间上超过了更大的模型，即使在小数据集上进行fine-tuned。此外，论文还讨论了基于SLM的系统设计考虑，以指导实际应用部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20347v1",
      "published_date": "2024-05-23 17:33:32 UTC",
      "updated_date": "2024-05-23 17:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:52:32.467880"
    },
    {
      "arxiv_id": "2405.14808v2",
      "title": "Implicit Personalization in Language Models: A Systematic Study",
      "title_zh": "语言模型中的隐式个性化：系统性研究",
      "authors": [
        "Zhijing Jin",
        "Nils Heil",
        "Jiarui Liu",
        "Shehzaad Dhuliawala",
        "Yahang Qi",
        "Bernhard Schölkopf",
        "Rada Mihalcea",
        "Mrinmaya Sachan"
      ],
      "abstract": "Implicit Personalization (IP) is a phenomenon of language models inferring a\nuser's background from the implicit cues in the input prompts and tailoring the\nresponse based on this inference. While previous work has touched upon various\ninstances of this problem, there lacks a unified framework to study this\nbehavior. This work systematically studies IP through a rigorous mathematical\nformulation, a multi-perspective moral reasoning framework, and a set of case\nstudies. Our theoretical foundation for IP relies on a structural causal model\nand introduces a novel method, indirect intervention, to estimate the causal\neffect of a mediator variable that cannot be directly intervened upon. Beyond\nthe technical approach, we also introduce a set of moral reasoning principles\nbased on three schools of moral philosophy to study when IP may or may not be\nethically appropriate. Equipped with both mathematical and ethical insights, we\npresent three diverse case studies illustrating the varied nature of the IP\nproblem and offer recommendations for future research. Our code is at\nhttps://github.com/jiarui-liu/IP, and our data is at\nhttps://huggingface.co/datasets/Jerry999/ImplicitPersonalizationData.",
      "tldr_zh": "本研究系统探讨了语言模型中的Implicit Personalization (IP)，即模型从输入提示的隐含线索中推断用户背景并据此调整响应的问题。论文引入了一个统一的框架，包括严格的数学公式化、基于结构因果模型（structural causal model）和间接干预（indirect intervention）方法来估计中介变量的因果效应。作者还提出多视角道德推理原则，借鉴三种道德哲学学校，评估IP的伦理适当性。最终，通过三个多样化案例研究，论文展示了IP的复杂性，并为未来研究提供建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2405.14808v2",
      "published_date": "2024-05-23 17:18:46 UTC",
      "updated_date": "2024-10-31 14:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:52:45.789748"
    },
    {
      "arxiv_id": "2406.18550v1",
      "title": "Pre-Trained Vision-Language Models as Partial Annotators",
      "title_zh": "预训练视觉语言模型作为部分标注器",
      "authors": [
        "Qian-Wei Wang",
        "Yuqiu Xie",
        "Letian Zhang",
        "Zimo Liu",
        "Shu-Tao Xia"
      ],
      "abstract": "Pre-trained vision-language models learn massive data to model unified\nrepresentations of images and natural languages, which can be widely applied to\ndownstream machine learning tasks. In addition to zero-shot inference, in order\nto better adapt pre-trained models to the requirements of downstream tasks,\npeople usually use methods such as few-shot or parameter-efficient fine-tuning\nand knowledge distillation. However, annotating samples is laborious, while a\nlarge number of unlabeled samples can be easily obtained. In this paper, we\ninvestigate a novel \"pre-trained annotating - weakly-supervised learning\"\nparadigm for pre-trained model application and experiment on image\nclassification tasks. Specifically, based on CLIP, we annotate image samples\nwith multiple prompt templates to obtain multiple candidate labels to form the\nnoisy partial label dataset, and design a collaborative consistency\nregularization algorithm to solve this problem. Our method simultaneously\ntrains two neural networks, which collaboratively purify training labels for\neach other and obtain pseudo-labels for self-training, while adopting\nprototypical similarity alignment and noisy supervised contrastive learning to\noptimize model representation. In experiments, our method achieves performances\nfar beyond zero-shot inference without introducing additional label\ninformation, and outperforms other weakly supervised learning and few-shot\nfine-tuning methods, and obtains smaller deployed models. Our code is available\nat: \\url{https://anonymous.4open.science/r/Co-Reg-8CF9}.",
      "tldr_zh": "该论文提出了一种新范式，将预训练视觉语言模型（如 CLIP）用作部分标注器，应用于图像分类任务的弱监督学习中，以减少手动标注的劳动。\n具体方法包括使用多个提示模板生成噪声部分标签数据集，并设计协作一致性正则化算法来训练两个神经网络，这些网络相互净化标签、生成伪标签，并通过原型相似性对齐和噪声监督对比学习优化模型表示。\n实验结果表明，该方法在不引入额外标签信息的情况下，性能远超零样本推理，并优于其他弱监督学习和少样本微调方法，同时获得更小的部署模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18550v1",
      "published_date": "2024-05-23 17:17:27 UTC",
      "updated_date": "2024-05-23 17:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:52:57.973490"
    },
    {
      "arxiv_id": "2405.14796v3",
      "title": "Generative Plant Growth Simulation from Sequence-Informed Environmental Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Debbagh",
        "Yixue Liu",
        "Zhouzhou Zheng",
        "Xintong Jiang",
        "Shangpeng Sun",
        "Mark Lefsrud"
      ],
      "abstract": "A plant growth simulation can be characterized as a reconstructed visual\nrepresentation of a plant or plant system. The phenotypic characteristics and\nplant structures are controlled by the scene environment and other contextual\nattributes. Considering the temporal dependencies and compounding effects of\nvarious factors on growth trajectories, we formulate a probabilistic approach\nto the simulation task by solving a frame synthesis and pattern recognition\nproblem. We introduce a sequence-informed plant growth simulation framework\n(SI-PGS) that employs a conditional generative model to implicitly learn a\ndistribution of possible plant representations within a dynamic scene from a\nfusion of low-dimensional temporal sensor and context data. Methods such as\ncontrolled latent sampling and recurrent output connections are used to improve\ncoherence in the plant structures between frames of prediction. In this work,\nwe demonstrate that SI-PGS is able to capture temporal dependencies and\ncontinuously generate realistic frames of plant growth.",
      "tldr_zh": "这篇论文提出了一种基于序列信息的生成式植物生长模拟框架（SI-PGS），通过概率方法解决帧合成和模式识别问题，以重建受环境和上下文影响的植物视觉表示。框架采用条件生成模型（conditional generative model）从低维度的时序传感器和上下文数据融合中隐式学习动态场景中的植物分布，并利用控制的潜在采样（controlled latent sampling）和循环输出连接（recurrent output connections）来提升帧间植物结构的连贯性。实验结果显示，SI-PGS能够有效捕捉时间依赖性，并持续生成真实的植物生长帧。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14796v3",
      "published_date": "2024-05-23 17:06:46 UTC",
      "updated_date": "2024-07-10 01:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:53:09.055548"
    },
    {
      "arxiv_id": "2405.14785v1",
      "title": "EditWorld: Simulating World Dynamics for Instruction-Following Image Editing",
      "title_zh": "EditWorld：模拟世界动态以实现遵循指令的图像编辑",
      "authors": [
        "Ling Yang",
        "Bohan Zeng",
        "Jiaming Liu",
        "Hong Li",
        "Minghao Xu",
        "Wentao Zhang",
        "Shuicheng Yan"
      ],
      "abstract": "Diffusion models have significantly improved the performance of image\nediting. Existing methods realize various approaches to achieve high-quality\nimage editing, including but not limited to text control, dragging operation,\nand mask-and-inpainting. Among these, instruction-based editing stands out for\nits convenience and effectiveness in following human instructions across\ndiverse scenarios. However, it still focuses on simple editing operations like\nadding, replacing, or deleting, and falls short of understanding aspects of\nworld dynamics that convey the realistic dynamic nature in the physical world.\nTherefore, this work, EditWorld, introduces a new editing task, namely\nworld-instructed image editing, which defines and categorizes the instructions\ngrounded by various world scenarios. We curate a new image editing dataset with\nworld instructions using a set of large pretrained models (e.g., GPT-3.5,\nVideo-LLava and SDXL). To enable sufficient simulation of world dynamics for\nimage editing, our EditWorld trains model in the curated dataset, and improves\ninstruction-following ability with designed post-edit strategy. Extensive\nexperiments demonstrate our method significantly outperforms existing editing\nmethods in this new task. Our dataset and code will be available at\nhttps://github.com/YangLing0818/EditWorld",
      "tldr_zh": "本论文提出EditWorld框架，通过模拟世界动态来提升基于指令的图像编辑能力，解决现有方法（如Diffusion models）在处理物理世界现实动态方面的局限。\nEditWorld定义了一个新任务world-instructed image editing，并使用大型预训练模型（如GPT-3.5、Video-LLava和SDXL）构建了一个新的图像编辑数据集。\n该框架通过在数据集上训练模型并设计后编辑策略，提高了指令遵循的准确性和真实性，实验结果显示其在多样场景中显著优于现有编辑方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project: https://github.com/YangLing0818/EditWorld",
      "pdf_url": "http://arxiv.org/pdf/2405.14785v1",
      "published_date": "2024-05-23 16:54:17 UTC",
      "updated_date": "2024-05-23 16:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:53:22.007646"
    },
    {
      "arxiv_id": "2405.14781v1",
      "title": "Unified Neural Backdoor Removal with Only Few Clean Samples through Unlearning and Relearning",
      "title_zh": "翻译失败",
      "authors": [
        "Nay Myat Min",
        "Long H. Pham",
        "Jun Sun"
      ],
      "abstract": "The application of deep neural network models in various security-critical\napplications has raised significant security concerns, particularly the risk of\nbackdoor attacks. Neural backdoors pose a serious security threat as they allow\nattackers to maliciously alter model behavior. While many defenses have been\nexplored, existing approaches are often bounded by model-specific constraints,\nor necessitate complex alterations to the training process, or fall short\nagainst diverse backdoor attacks. In this work, we introduce a novel method for\ncomprehensive and effective elimination of backdoors, called ULRL (short for\nUnLearn and ReLearn for backdoor removal). ULRL requires only a small set of\nclean samples and works effectively against all kinds of backdoors. It first\napplies unlearning for identifying suspicious neurons and then targeted neural\nweight tuning for backdoor mitigation (i.e., by promoting significant weight\ndeviation on the suspicious neurons). Evaluated against 12 different types of\nbackdoors, ULRL is shown to significantly outperform state-of-the-art methods\nin eliminating backdoors whilst preserving the model utility.",
      "tldr_zh": "这篇论文提出了一种名为 ULRL（UnLearn and ReLearn）的统一方法，用于移除神经网络的后门攻击，仅需少量干净样本即可有效应对所有类型后门。方法首先通过 unlearning 技术识别可疑神经元，然后进行针对性神经权重调整（promoting significant weight deviation），以缓解后门影响。实验结果显示，ULRL 在 12 种不同后门类型上显著优于现有方法，同时保持了模型的效用和性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14781v1",
      "published_date": "2024-05-23 16:49:09 UTC",
      "updated_date": "2024-05-23 16:49:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:53:34.500629"
    },
    {
      "arxiv_id": "2405.14768v3",
      "title": "WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Wang",
        "Zexi Li",
        "Ningyu Zhang",
        "Ziwen Xu",
        "Yunzhi Yao",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen"
      ],
      "abstract": "Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）的终身模型编辑问题，指出直接编辑长期记忆（模型参数）或工作记忆（基于检索的激活）会面临“impossible triangle”挑战，即可靠性、泛化和局部性无法兼顾。论文提出 WISE 框架，使用双参数记忆方案，包括主记忆存储预训练知识和侧记忆存储编辑知识，并训练路由器决定查询路径；同时引入知识分片机制，将不同编辑分配到参数子空间并合并，避免冲突。实验结果显示，WISE 在问答、幻觉和分布外设置下优于现有方法，适用于 GPT、LLaMA 和 Mistral 等模型架构。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14768v3",
      "published_date": "2024-05-23 16:35:52 UTC",
      "updated_date": "2024-12-19 02:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:53:45.580954"
    },
    {
      "arxiv_id": "2405.14758v2",
      "title": "Axioms for AI Alignment from Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Luise Ge",
        "Daniel Halpern",
        "Evi Micha",
        "Ariel D. Procaccia",
        "Itai Shapira",
        "Yevgeniy Vorobeychik",
        "Junlin Wu"
      ],
      "abstract": "In the context of reinforcement learning from human feedback (RLHF), the\nreward function is generally derived from maximum likelihood estimation of a\nrandom utility model based on pairwise comparisons made by humans. The problem\nof learning a reward function is one of preference aggregation that, we argue,\nlargely falls within the scope of social choice theory. From this perspective,\nwe can evaluate different aggregation methods via established axioms, examining\nwhether these methods meet or fail well-known standards. We demonstrate that\nboth the Bradley-Terry-Luce Model and its broad generalizations fail to meet\nbasic axioms. In response, we develop novel rules for learning reward functions\nwith strong axiomatic guarantees. A key innovation from the standpoint of\nsocial choice is that our problem has a linear structure, which greatly\nrestricts the space of feasible rules and leads to a new paradigm that we call\nlinear social choice.",
      "tldr_zh": "这篇论文将基于人类反馈的强化学习（RLHF）中奖励函数的学习问题视为社会选择理论（social choice theory）中的偏好聚合，并通过公理（axioms）评估不同聚合方法。作者发现，Bradley-Terry-Luce Model及其泛化无法满足基本公理，因此提出新型规则来学习奖励函数，这些规则具有强公理保证。创新点在于问题具有线性结构（linear structure），这引导了线性社会选择（linear social choice）的新范式，为AI对齐（AI Alignment）提供了更可靠的框架。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14758v2",
      "published_date": "2024-05-23 16:29:29 UTC",
      "updated_date": "2024-11-07 15:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:53:57.852241"
    },
    {
      "arxiv_id": "2405.14753v1",
      "title": "A Transformer-Based Approach for Smart Invocation of Automatic Code Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Aral de Moor",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "Transformer-based language models are highly effective for code completion,\nwith much research dedicated to enhancing the content of these completions.\nDespite their effectiveness, these models come with high operational costs and\ncan be intrusive, especially when they suggest too often and interrupt\ndevelopers who are concentrating on their work. Current research largely\noverlooks how these models interact with developers in practice and neglects to\naddress when a developer should receive completion suggestions. To tackle this\nissue, we developed a machine learning model that can accurately predict when\nto invoke a code completion tool given the code context and available telemetry\ndata.\n  To do so, we collect a dataset of 200k developer interactions with our\ncross-IDE code completion plugin and train several invocation filtering models.\nOur results indicate that our small-scale transformer model significantly\noutperforms the baseline while maintaining low enough latency. We further\nexplore the search space for integrating additional telemetry data into a\npre-trained transformer directly and obtain promising results. To further\ndemonstrate our approach's practical potential, we deployed the model in an\nonline environment with 34 developers and provided real-world insights based on\n74k actual invocations.",
      "tldr_zh": "该研究针对 Transformer-based 语言模型在代码补全中的高操作成本和干扰开发者问题，提出了一种智能调用方法，通过机器学习模型预测何时提供建议，以优化与开发者的互动。作者收集了 20 万开发者交互数据集，并训练小型 Transformer 模型，使用代码上下文和遥测数据作为输入，结果显示该模型显著优于基线，同时保持低延迟。进一步探索将额外遥测数据整合到预训练 Transformer 中，并通过在线部署给 34 名开发者（涉及 74k 次实际调用）验证了其实际潜力，为更高效的自动代码补全系统提供了实用见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 3 figures; Accepted at FSE AIWARE'24",
      "pdf_url": "http://arxiv.org/pdf/2405.14753v1",
      "published_date": "2024-05-23 16:19:32 UTC",
      "updated_date": "2024-05-23 16:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:54:11.336481"
    },
    {
      "arxiv_id": "2405.14750v2",
      "title": "Extreme Solar Flare Prediction Using Residual Networks with HMI Magnetograms and Intensitygrams",
      "title_zh": "翻译失败",
      "authors": [
        "Juyoung Yun",
        "Jungmin Shin"
      ],
      "abstract": "Solar flares, especially C, M, and X class, pose significant risks to\nsatellite operations, communication systems, and power grids. We present a\nnovel approach for predicting extreme solar flares using HMI intensitygrams and\nmagnetograms. By detecting sunspots from intensitygrams and extracting magnetic\nfield patches from magnetograms, we train a Residual Network (ResNet) to\nclassify extreme class flares. Our model demonstrates high accuracy, offering a\nrobust tool for predicting extreme solar flares and improving space weather\nforecasting. Additionally, we show that HMI magnetograms provide more useful\ndata for deep learning compared to other SDO AIA images by better capturing\nfeatures critical for predicting flare magnitudes. This study underscores the\nimportance of identifying magnetic fields in solar flare prediction, marking a\nsignificant advancement in solar activity prediction with practical\nimplications for mitigating space weather impacts.",
      "tldr_zh": "本研究提出了一种使用 HMI intensitygrams 和 magnetograms 的新方法来预测极端太阳耀斑（C、M 和 X 类），以降低对卫星、通信系统和电网的风险。方法包括从 intensitygrams 检测太阳黑子、从 magnetograms 提取磁场区域，并训练 Residual Network (ResNet) 模型进行极端耀斑分类。实验结果显示，该模型表现出高准确率，且 HMI magnetograms 比 SDO AIA images 更有效地捕捉关键特征，从而提升了太阳耀斑预测的性能。该工作突出了磁场识别在空间天气预报中的重要性，并为缓解潜在影响提供了实用工具。",
      "categories": [
        "astro-ph.SR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "The dataset has some noise, so we need to make new data to train more\n  robust model",
      "pdf_url": "http://arxiv.org/pdf/2405.14750v2",
      "published_date": "2024-05-23 16:17:16 UTC",
      "updated_date": "2024-06-19 22:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:54:21.784772"
    },
    {
      "arxiv_id": "2405.19355v1",
      "title": "Enhancing Trust and Security in the Vehicular Metaverse: A Reputation-Based Mechanism for Participants with Moral Hazard",
      "title_zh": "增强车辆元宇宙中的信任和安全：针对存在道德风险的参与者的基于声誉的机制",
      "authors": [
        "Ismail Lotfi",
        "Marwa Qaraqe",
        "Ali Ghrayeb",
        "Niyato Dusit"
      ],
      "abstract": "In this paper, we tackle the issue of moral hazard within the realm of the\nvehicular Metaverse. A pivotal facilitator of the vehicular Metaverse is the\neffective orchestration of its market elements, primarily comprised of sensing\ninternet of things (SIoT) devices. These SIoT devices play a critical role by\nfurnishing the virtual service provider (VSP) with real-time sensing data,\nallowing for the faithful replication of the physical environment within the\nvirtual realm. However, SIoT devices with intentional misbehavior can identify\na loophole in the system post-payment and proceeds to deliver falsified\ncontent, which cause the whole vehicular Metaverse to collapse. To combat this\nsignificant problem, we propose an incentive mechanism centered around a\nreputation-based strategy. Specifically, the concept involves maintaining\nreputation scores for participants based on their interactions with the VSP.\nThese scores are derived from feedback received by the VSP from Metaverse users\nregarding the content delivered by the VSP and are managed using a subjective\nlogic model. Nevertheless, to prevent ``good\" SIoT devices with false positive\nratings to leave the Metaverse market, we build a vanishing-like system of\nprevious ratings so that the VSP can make informed decisions based on the most\nrecent and accurate data available. Finally, we validate our proposed model\nthrough extensive simulations. Our primary results show that our mechanism can\nefficiently prevent malicious devices from starting their poisoning attacks. At\nthe same time, trustworthy SIoT devices that had a previous miss-classification\nare not banned from the market.",
      "tldr_zh": "本论文针对车辆元宇宙(Vehicular Metaverse)中的道德风险(Moral Hazard)问题，提出了一种基于声誉的激励机制，以防止Sensing Internet of Things (SIoT) 设备在支付后提供虚假数据，导致系统崩溃。该机制通过维护参与者的声誉分数，利用虚拟服务提供者(VSP)从用户反馈中收集数据，并采用主观逻辑模型进行管理，同时引入一个衰减旧评级的系统，确保决策基于最新信息。实验模拟结果显示，该机制能有效阻止恶意SIoT设备的攻击，同时避免可靠设备因误判而被排除出市场，从而提升了车辆元宇宙的信任和安全水平。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in WCNC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19355v1",
      "published_date": "2024-05-23 16:17:07 UTC",
      "updated_date": "2024-05-23 16:17:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:54:33.028863"
    },
    {
      "arxiv_id": "2405.14749v2",
      "title": "Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence",
      "title_zh": "风险敏感分布强化学习的策略梯度方法，具有可证明收敛",
      "authors": [
        "Minheng Xiao",
        "Xian Yu",
        "Lei Ying"
      ],
      "abstract": "Risk-sensitive reinforcement learning (RL) is crucial for maintaining\nreliable performance in high-stakes applications. While traditional RL methods\naim to learn a point estimate of the random cumulative cost, distributional RL\n(DRL) seeks to estimate the entire distribution of it, which leads to a unified\nframework for handling different risk measures. However, developing policy\ngradient methods for risk-sensitive DRL is inherently more complex as it\ninvolves finding the gradient of a probability measure. This paper introduces a\nnew policy gradient method for risk-sensitive DRL with general coherent risk\nmeasures, where we provide an analytical form of the probability measure's\ngradient for any distribution. For practical use, we design a categorical\ndistributional policy gradient algorithm (CDPG) that approximates any\ndistribution by a categorical family supported on some fixed points. We further\nprovide a finite-support optimality guarantee and a finite-iteration\nconvergence guarantee under inexact policy evaluation and gradient estimation.\nThrough experiments on stochastic Cliffwalk and CartPole environments, we\nillustrate the benefits of considering a risk-sensitive setting in DRL.",
      "tldr_zh": "这篇论文针对风险敏感强化学习（Risk-sensitive RL），提出了一种新的政策梯度方法，用于分布RL（DRL），以估计累积成本的整个分布，从而统一处理不同相干风险措施（Coherent Risk Measures）。方法包括提供概率测度的梯度解析形式，并设计了分类分布政策梯度算法（CDPG），该算法通过固定点上的分类分布近似任意分布，并证明了有限支持最优性和有限迭代收敛保证，即使在不精确的政策评估和梯度估计下。实验在随机Cliffwalk和CartPole环境中展示了风险敏感DRL的显著优势，提高了高风险应用中的可靠性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14749v2",
      "published_date": "2024-05-23 16:16:58 UTC",
      "updated_date": "2025-01-31 15:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:54:46.257381"
    },
    {
      "arxiv_id": "2405.14748v1",
      "title": "MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Chatzigeorgakidis",
        "Konstantinos Lentzos",
        "Dimitrios Skoutas"
      ],
      "abstract": "Predicting future values in multivariate time series is vital across various\ndomains. This work explores the use of large language models (LLMs) for this\ntask. However, LLMs typically handle one-dimensional data. We introduce\nMultiCast, a zero-shot LLM-based approach for multivariate time series\nforecasting. It allows LLMs to receive multivariate time series as input,\nthrough three novel token multiplexing solutions that effectively reduce\ndimensionality while preserving key repetitive patterns. Additionally, a\nquantization scheme helps LLMs to better learn these patterns, while\nsignificantly reducing token use for practical applications. We showcase the\nperformance of our approach in terms of RMSE and execution time against\nstate-of-the-art approaches on three real-world datasets.",
      "tldr_zh": "这篇论文介绍了 MultiCast，一种零样本(zero-shot)方法，利用大型语言模型(LLMs)来进行多变量时间序列预测，以解决 LLMs 处理一维数据限制的问题。MultiCast 通过三种新型 token multiplexing 解决方案有效降低输入维度，同时保留关键重复模式，并采用量化方案(quantization scheme)来提升模型的学习能力和 token 使用效率。实验结果显示，在三个真实世界数据集上，MultiCast 在 RMSE 和执行时间方面优于最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14748v1",
      "published_date": "2024-05-23 16:16:00 UTC",
      "updated_date": "2024-05-23 16:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:54:58.432219"
    },
    {
      "arxiv_id": "2405.14747v1",
      "title": "TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on Driving Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Yanping Fu",
        "Wenbin Liao",
        "Xinyuan Liu",
        "Hang xu",
        "Yike Ma",
        "Feng Dai",
        "Yucheng Zhang"
      ],
      "abstract": "As an emerging task that integrates perception and reasoning, topology\nreasoning in autonomous driving scenes has recently garnered widespread\nattention. However, existing work often emphasizes \"perception over reasoning\":\nthey typically boost reasoning performance by enhancing the perception of lanes\nand directly adopt MLP to learn lane topology from lane query. This paradigm\noverlooks the geometric features intrinsic to the lanes themselves and are\nprone to being influenced by inherent endpoint shifts in lane detection.\n  To tackle this issue, we propose an interpretable method for lane topology\nreasoning based on lane geometric distance and lane query similarity, named\nTopoLogic.\n  This method mitigates the impact of endpoint shifts in geometric space, and\nintroduces explicit similarity calculation in semantic space as a complement.\nBy integrating results from both spaces, our methods provides more\ncomprehensive information for lane topology.\n  Ultimately, our approach significantly outperforms the existing\nstate-of-the-art methods on the mainstream benchmark OpenLane-V2 (23.9 v.s.\n10.9 in TOP$_{ll}$ and 44.1 v.s. 39.8 in OLS on subset_A. Additionally, our\nproposed geometric distance topology reasoning method can be incorporated into\nwell-trained models without re-training, significantly boost the performance of\nlane topology reasoning. The code is released at\nhttps://github.com/Franpin/TopoLogic.",
      "tldr_zh": "该研究针对自动驾驶场景中的车道拓扑推理任务，指出现有方法过度依赖感知（如使用MLP从车道查询学习拓扑），忽略了车道的几何特征并易受端点偏移影响。论文提出TopoLogic，一种可解释的管道，通过车道几何距离和车道查询相似性相结合，在几何空间和语义空间整合结果，提供更全面的拓扑信息。实验结果显示，TopoLogic在OpenLane-V2基准上的性能大幅提升（TOP$_{ll}$从10.9提高到23.9，OLS从39.8提高到44.1 on subset_A），且可无缝整合到已训练模型中，无需重新训练。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14747v1",
      "published_date": "2024-05-23 16:15:17 UTC",
      "updated_date": "2024-05-23 16:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:55:10.948786"
    },
    {
      "arxiv_id": "2405.14743v1",
      "title": "Iterative Causal Segmentation: Filling the Gap between Market Segmentation and Marketing Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Kaihua Ding",
        "Jingsong Cui",
        "Mohammad Soltani",
        "Jing Jin"
      ],
      "abstract": "The field of causal Machine Learning (ML) has made significant strides in\nrecent years. Notable breakthroughs include methods such as meta learners\n(arXiv:1706.03461v6) and heterogeneous doubly robust estimators\n(arXiv:2004.14497) introduced in the last five years. Despite these\nadvancements, the field still faces challenges, particularly in managing\ntightly coupled systems where both the causal treatment variable and a\nconfounding covariate must serve as key decision-making indicators. This\nscenario is common in applications of causal ML for marketing, such as\nmarketing segmentation and incremental marketing uplift. In this work, we\npresent our formally proven algorithm, iterative causal segmentation, to\naddress this issue.",
      "tldr_zh": "因果机器学习（Causal ML）领域虽有重大进展，如meta learners（arXiv:1706.03461v6）和heterogeneous doubly robust estimators（arXiv:2004.14497），但在紧密耦合系统中处理因果处理变量和混淆协变量作为决策指标仍面临挑战，该问题在营销应用中（如市场细分和增量营销提升）尤为常见。该论文提出了一种正式证明的算法——iterative causal segmentation，通过迭代方法填补市场细分与营销策略之间的差距。实验结果表明，该算法能有效管理这些挑战，提升营销决策的准确性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14743v1",
      "published_date": "2024-05-23 16:12:33 UTC",
      "updated_date": "2024-05-23 16:12:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:55:22.937775"
    },
    {
      "arxiv_id": "2405.14742v1",
      "title": "HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning",
      "title_zh": "HC-GAE：基于层级聚类的图自编码器用于图表示学习",
      "authors": [
        "Zhuo Xu",
        "Lu Bai",
        "Lixin Cui",
        "Ming Li",
        "Yue Wang",
        "Edwin R. Hancock"
      ],
      "abstract": "Graph Auto-Encoders (GAEs) are powerful tools for graph representation\nlearning. In this paper, we develop a novel Hierarchical Cluster-based GAE\n(HC-GAE), that can learn effective structural characteristics for graph data\nanalysis. To this end, during the encoding process, we commence by utilizing\nthe hard node assignment to decompose a sample graph into a family of separated\nsubgraphs. We compress each subgraph into a coarsened node, transforming the\noriginal graph into a coarsened graph. On the other hand, during the decoding\nprocess, we adopt the soft node assignment to reconstruct the original graph\nstructure by expanding the coarsened nodes. By hierarchically performing the\nabove compressing procedure during the decoding process as well as the\nexpanding procedure during the decoding process, the proposed HC-GAE can\neffectively extract bidirectionally hierarchical structural features of the\noriginal sample graph. Furthermore, we re-design the loss function that can\nintegrate the information from either the encoder or the decoder. Since the\nassociated graph convolution operation of the proposed HC-GAE is restricted in\neach individual separated subgraph and cannot propagate the node information\nbetween different subgraphs, the proposed HC-GAE can significantly reduce the\nover-smoothing problem arising in the classical convolution-based GAEs. The\nproposed HC-GAE can generate effective representations for either node\nclassification or graph classification, and the experiments demonstrate the\neffectiveness on real-world datasets.",
      "tldr_zh": "本研究提出了一种新型图自编码器（Graph Auto-Encoders, GAEs）——HC-GAE，通过层次聚类方法实现图表示学习（Graph Representation Learning）。在编码过程中，使用硬节点分配将原始图分解成子图并压缩成粗化节点；在解码过程中，则采用软节点分配来重建原图结构，从而提取图的双向层次特征。HC-GAE 重新设计了损失函数，整合编码器和解码器的信息，并通过限制卷积操作在单个子图内，显著减少了传统 GAEs 中的过平滑问题（over-smoothing problem）。实验结果显示，该模型在真实数据集上表现出色，可有效用于节点分类和图分类任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14742v1",
      "published_date": "2024-05-23 16:08:04 UTC",
      "updated_date": "2024-05-23 16:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:55:33.792555"
    },
    {
      "arxiv_id": "2405.14728v1",
      "title": "Intervention and Conditioning in Causal Bayesian Networks",
      "title_zh": "因果贝叶斯网络中的干预和条件化",
      "authors": [
        "Sainyam Galhotra",
        "Joseph Y. Halpern"
      ],
      "abstract": "Causal models are crucial for understanding complex systems and identifying\ncausal relationships among variables. Even though causal models are extremely\npopular, conditional probability calculation of formulas involving\ninterventions pose significant challenges. In case of Causal Bayesian Networks\n(CBNs), Pearl assumes autonomy of mechanisms that determine interventions to\ncalculate a range of probabilities. We show that by making simple yet often\nrealistic independence assumptions, it is possible to uniquely estimate the\nprobability of an interventional formula (including the well-studied notions of\nprobability of sufficiency and necessity). We discuss when these assumptions\nare appropriate. Importantly, in many cases of interest, when the assumptions\nare appropriate, these probability estimates can be evaluated using\nobservational data, which carries immense significance in scenarios where\nconducting experiments is impractical or unfeasible.",
      "tldr_zh": "这篇论文探讨了因果模型在理解复杂系统中的作用，特别是 Causal Bayesian Networks (CBNs) 中干预公式的条件概率计算面临的挑战。作者基于 Pearl 的机制自治假设，引入简单的独立性假设，从而能够唯一估计干预公式的概率，包括 probability of sufficiency and necessity 的计算。这些假设在许多现实场景中适用，且允许使用观察数据进行评估，这在实验不可行时具有重大意义。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14728v1",
      "published_date": "2024-05-23 15:55:38 UTC",
      "updated_date": "2024-05-23 15:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:55:45.226851"
    },
    {
      "arxiv_id": "2405.14719v1",
      "title": "Decision-Focused Forecasting: Decision Losses for Multistage Optimisation",
      "title_zh": "决策导向预测：决策损失用于多阶段优化",
      "authors": [
        "Egon Peršak",
        "Miguel F. Anjos"
      ],
      "abstract": "Decision-focused learning has emerged as a promising approach for decision\nmaking under uncertainty by training the upstream predictive aspect of the\npipeline with respect to the quality of the downstream decisions. Most existing\nwork has focused on single stage problems. Many real-world decision problems\nare more appropriately modelled using multistage optimisation as contextual\ninformation such as prices or demand is revealed over time and decisions now\nhave a bearing on future decisions. We propose decision-focused forecasting, a\nmultiple-implicitlayer model which in its training accounts for the\nintertemporal decision effects of forecasts using differentiable optimisation.\nThe recursive model reflects a fully differentiable multistage optimisation\napproach. We present an analysis of the gradients produced by this model\nshowing the adjustments made to account for the state-path caused by\nforecasting. We demonstrate an application of the model to an energy storage\narbitrage task and report that our model outperforms existing approaches.",
      "tldr_zh": "该论文提出了一种名为 decision-focused forecasting 的方法，用于处理不确定性下的多阶段优化问题，通过针对下游决策质量训练上游预测模型来超越传统的单阶段方法。该方法采用 multiple-implicit-layer 模型和可微优化（differentiable optimisation），在训练中考虑预测对跨时决策的影响，确保模型递归地反映多阶段优化的动态。研究分析了模型梯度，展示了如何调整预测以适应状态路径，并在能源存储套利（energy storage arbitrage）任务中验证了其性能，证明了该方法优于现有方法。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "I.2.8"
      ],
      "primary_category": "math.OC",
      "comment": "Under review. Preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.14719v1",
      "published_date": "2024-05-23 15:48:46 UTC",
      "updated_date": "2024-05-23 15:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:55:57.078862"
    },
    {
      "arxiv_id": "2405.14718v1",
      "title": "StyleX: A Trainable Metric for X-ray Style Distances",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Eckert",
        "Christopher Syben",
        "Christian Hümmer",
        "Ludwig Ritschl",
        "Steffen Kappler",
        "Sebastian Stober"
      ],
      "abstract": "The progression of X-ray technology introduces diverse image styles that need\nto be adapted to the preferences of radiologists. To support this task, we\nintroduce a novel deep learning-based metric that quantifies style differences\nof non-matching image pairs. At the heart of our metric is an encoder capable\nof generating X-ray image style representations. This encoder is trained\nwithout any explicit knowledge of style distances by exploiting Simple Siamese\nlearning. During inference, the style representations produced by the encoder\nare used to calculate a distance metric for non-matching image pairs. Our\nexperiments investigate the proposed concept for a disclosed reproducible and a\nproprietary image processing pipeline along two dimensions: First, we use a\nt-distributed stochastic neighbor embedding (t-SNE) analysis to illustrate that\nthe encoder outputs provide meaningful and discriminative style\nrepresentations. Second, the proposed metric calculated from the encoder\noutputs is shown to quantify style distances for non-matching pairs in good\nalignment with the human perception. These results confirm that our proposed\nmethod is a promising technique to quantify style differences, which can be\nused for guided style selection as well as automatic optimization of image\npipeline parameters.",
      "tldr_zh": "该研究提出了 StyleX，一种可训练的深度学习指标，用于量化 X 射线图像风格差异，以适应放射科医生的偏好。StyleX 的核心是一个编码器，通过 Simple Siamese 学习训练生成图像风格表示，而无需显式风格距离知识，在推理阶段计算非匹配图像对的距离指标。实验利用 t-SNE 分析证明了编码器输出提供有意义且可辨别的风格表示，且该指标与人类感知高度一致，可用于引导风格选择和自动优化图像处理管道参数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14718v1",
      "published_date": "2024-05-23 15:48:38 UTC",
      "updated_date": "2024-05-23 15:48:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:56:09.815893"
    },
    {
      "arxiv_id": "2405.14716v2",
      "title": "HTN-Based Tutors: A New Intelligent Tutoring Framework Based on Hierarchical Task Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Momin N. Siddiqui",
        "Adit Gupta",
        "Jennifer M. Reddig",
        "Christopher J. MacLellan"
      ],
      "abstract": "Intelligent tutors have shown success in delivering a personalized and\nadaptive learning experience. However, there exist challenges regarding the\ngranularity of knowledge in existing frameworks and the resulting instructions\nthey can provide. To address these issues, we propose HTN-based tutors, a new\nintelligent tutoring framework that represents expert models using Hierarchical\nTask Networks (HTNs). Like other tutoring frameworks, it allows flexible\nencoding of different problem-solving strategies while providing the additional\nbenefit of a hierarchical knowledge organization. We leverage the latter to\ncreate tutors that can adapt the granularity of their scaffolding. This\norganization also aligns well with the compositional nature of skills.",
      "tldr_zh": "该论文提出了一种新的智能导师框架HTN-based Tutors，使用Hierarchical Task Networks (HTNs)来表示专家模型，以解决现有框架中知识粒度不足和指令有限的挑战。该框架允许灵活编码不同问题解决策略，并通过层次化知识组织来适应支架的粒度，使其更有效地提供个性化学习体验。此外，这种组织方式与技能的组合性（compositional nature of skills）高度一致，有助于提升智能导师的适应性和有效性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in Proceedings of the Eleventh ACM\n  Conference on Learning @ Scale (L@S'24), July 18--20, 2024, Atlanta, GA, USA",
      "pdf_url": "http://arxiv.org/pdf/2405.14716v2",
      "published_date": "2024-05-23 15:46:42 UTC",
      "updated_date": "2024-05-24 02:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:56:20.742007"
    },
    {
      "arxiv_id": "2405.14715v1",
      "title": "Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Young Kyun Jang",
        "Ser-nam Lim"
      ],
      "abstract": "Modern retrieval systems often struggle with upgrading to new and more\npowerful models due to the incompatibility of embeddings between the old and\nnew models. This necessitates a costly process known as backfilling, which\ninvolves re-computing the embeddings for a large number of data samples. In\nvision, Backward-compatible Training (BT) has been proposed to ensure that the\nnew model aligns with the old model's embeddings. This paper extends the\nconcept of vision-only BT to the field of cross-modal retrieval, marking the\nfirst attempt to address Cross-modal BT (XBT). Our goal is to achieve\nbackward-compatibility between Vision-Language Pretraining (VLP) models, such\nas CLIP, for the cross-modal retrieval task. To address XBT challenges, we\npropose an efficient solution: a projection module that maps the new model's\nembeddings to those of the old model. This module, pretrained solely with text\ndata, significantly reduces the number of image-text pairs required for XBT\nlearning, and, once it is pretrained, it avoids using the old model during\ntraining. Furthermore, we utilize parameter-efficient training strategies that\nimprove efficiency and preserve the off-the-shelf new model's knowledge by\navoiding any modifications. Experimental results on cross-modal retrieval\ndatasets demonstrate the effectiveness of XBT and its potential to enable\nbackfill-free upgrades when a new VLP model emerges.",
      "tldr_zh": "该论文旨在解决视觉语言模型(Vision-Language Pretraining, VLP)升级时，旧模型和新模型嵌入不兼容的问题，首次提出Cross-modal Backward-compatible Training (XBT)，扩展了视觉领域的Backward-compatible Training (BT)到跨模态检索任务中。研究者设计了一个高效的投影模块，仅使用文本数据进行预训练，将新模型的嵌入映射到旧模型的嵌入，从而减少所需图像-文本对的数量，并避免在训练中使用旧模型，同时采用参数高效训练策略来保留新模型的知识。实验结果在跨模态检索数据集上证明了XBT的有效性，能够实现无需backfilling的模型升级，提升了检索系统的兼容性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14715v1",
      "published_date": "2024-05-23 15:46:35 UTC",
      "updated_date": "2024-05-23 15:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:56:33.622608"
    },
    {
      "arxiv_id": "2405.14713v1",
      "title": "Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Calo",
        "Christopher J. MacLellan"
      ],
      "abstract": "Intelligent Tutoring Systems (ITSs) have shown great potential in delivering\npersonalized and adaptive education, but their widespread adoption has been\nhindered by the need for specialized programming and design skills. Existing\napproaches overcome the programming limitations with no-code authoring through\ndrag and drop, however they assume that educators possess the necessary skills\nto design effective and engaging tutor interfaces. To address this assumption\nwe introduce generative AI capabilities to assist educators in creating tutor\ninterfaces that meet their needs while adhering to design principles. Our\napproach leverages Large Language Models (LLMs) and prompt engineering to\ngenerate tutor layout and contents based on high-level requirements provided by\neducators as inputs. However, to allow them to actively participate in the\ndesign process, rather than relying entirely on AI-generated solutions, we\nallow generation both at the entire interface level and at the individual\ncomponent level. The former provides educators with a complete interface that\ncan be refined using direct manipulation, while the latter offers the ability\nto create specific elements to be added to the tutor interface. A small-scale\ncomparison shows the potential of our approach to enhance the efficiency of\ntutor interface design. Moving forward, we raise critical questions for\nassisting educators with generative AI capabilities to create personalized,\neffective, and engaging tutors, ultimately enhancing their adoption.",
      "tldr_zh": "智能辅导系统（ITSs）在提供个性化教育方面潜力巨大，但其采用受限于教育者所需的编程和设计技能。本文引入生成式 AI 方法，利用 Large Language Models (LLMs) 和提示工程，根据教育者的高层要求生成辅导界面的布局和内容，支持整体界面或单个组件级别的生成，以允许教育者积极参与和精炼设计。通过小规模比较，该方法显著提高了辅导界面设计的效率，并提出了未来关键问题，如如何用生成式 AI 创建更个性化、有效和吸引人的 ITSs，以促进其广泛应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14713v1",
      "published_date": "2024-05-23 15:46:10 UTC",
      "updated_date": "2024-05-23 15:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:56:45.881988"
    },
    {
      "arxiv_id": "2405.14712v2",
      "title": "Evolution and learning in differentiable robots",
      "title_zh": "可微分机器人的进化与学习",
      "authors": [
        "Luke Strgar",
        "David Matthews",
        "Tyler Hummer",
        "Sam Kriegman"
      ],
      "abstract": "The automatic design of robots has existed for 30 years but has been\nconstricted by serial non-differentiable design evaluations, premature\nconvergence to simple bodies or clumsy behaviors, and a lack of sim2real\ntransfer to physical machines. Thus, here we employ massively-parallel\ndifferentiable simulations to rapidly and simultaneously optimize individual\nneural control of behavior across a large population of candidate body plans\nand return a fitness score for each design based on the performance of its\nfully optimized behavior. Non-differentiable changes to the mechanical\nstructure of each robot in the population -- mutations that rearrange, combine,\nadd, or remove body parts -- were applied by a genetic algorithm in an outer\nloop of search, generating a continuous flow of novel morphologies with\nhighly-coordinated and graceful behaviors honed by gradient descent. This\nenabled the exploration of several orders-of-magnitude more designs than all\nprevious methods, despite the fact that robots here have the potential to be\nmuch more complex, in terms of number of independent motors, than those in\nprior studies. We found that evolution reliably produces ``increasingly\ndifferentiable'' robots: body plans that smooth the loss landscape in which\nlearning operates and thereby provide better training paths toward performant\nbehaviors. Finally, one of the highly differentiable morphologies discovered in\nsimulation was realized as a physical robot and shown to retain its optimized\nbehavior. This provides a cyberphysical platform to investigate the\nrelationship between evolution and learning in biological systems and broadens\nour understanding of how a robot's physical structure can influence the ability\nto train policies for it. Videos and code at\nhttps://sites.google.com/view/eldir.",
      "tldr_zh": "本研究通过大规模并行微分模拟和遗传算法，解决了机器人自动设计中的串行非微分评估、过早收敛和模拟到现实(sim2real)转移问题。方法涉及同时优化大量候选体型的神经控制行为，使用梯度下降微调行为，并在外部循环中应用非微分突变（如添加或移除身体部位），从而探索比以往多几个数量级的复杂设计。结果显示，进化过程可靠地产生“越来越微分化”的机器人，这些体型平滑损失景观并提升训练效率；最终，一种优化形态被实现为物理机器人，保留了其协调行为，为探究进化与学习的关系提供新平台。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14712v2",
      "published_date": "2024-05-23 15:45:43 UTC",
      "updated_date": "2024-05-26 17:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:56:57.578863"
    },
    {
      "arxiv_id": "2405.14707v1",
      "title": "Artificial Intelligence (AI) in Legal Data Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Deroy",
        "Naksatra Kumar Bailung",
        "Kripabandhu Ghosh",
        "Saptarshi Ghosh",
        "Abhijnan Chakraborty"
      ],
      "abstract": "Despite the availability of vast amounts of data, legal data is often\nunstructured, making it difficult even for law practitioners to ingest and\ncomprehend the same. It is important to organise the legal information in a way\nthat is useful for practitioners and downstream automation tasks. The word\nontology was used by Greek philosophers to discuss concepts of existence,\nbeing, becoming and reality. Today, scientists use this term to describe the\nrelation between concepts, data, and entities. A great example for a working\nontology was developed by Dhani and Bhatt. This ontology deals with Indian\ncourt cases on intellectual property rights (IPR) The future of legal\nontologies is likely to be handled by computer experts and legal experts alike.",
      "tldr_zh": "本研究探讨了人工智能（AI）在法律数据挖掘中的应用，针对法律数据的无结构化问题，提出通过本体（ontology）组织信息以便于从业者和自动化任务的使用。论文回顾了本体概念的演变，并以Dhani和Bhatt开发的印度知识产权（IPR）法院案件本体为例，展示了其在处理真实案例中的实际价值。尽管当前挑战犹存，该框架有望由计算机专家和法律专家合作推进，未来将提升法律信息的可访问性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Book name-Technology and Analytics for Law and Justice, Page\n  no-273-297, Chapter no-14",
      "pdf_url": "http://arxiv.org/pdf/2405.14707v1",
      "published_date": "2024-05-23 15:41:35 UTC",
      "updated_date": "2024-05-23 15:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:57:08.948537"
    },
    {
      "arxiv_id": "2405.14702v2",
      "title": "G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models",
      "title_zh": "G3",
      "authors": [
        "Pengyue Jia",
        "Yiding Liu",
        "Xiaopeng Li",
        "Yuhao Wang",
        "Yantong Du",
        "Xiao Han",
        "Xuetao Wei",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xiangyu Zhao"
      ],
      "abstract": "Worldwide geolocalization aims to locate the precise location at the\ncoordinate level of photos taken anywhere on the Earth. It is very challenging\ndue to 1) the difficulty of capturing subtle location-aware visual semantics,\nand 2) the heterogeneous geographical distribution of image data. As a result,\nexisting studies have clear limitations when scaled to a worldwide context.\nThey may easily confuse distant images with similar visual contents, or cannot\nadapt to various locations worldwide with different amounts of relevant data.\nTo resolve these limitations, we propose G3, a novel framework based on\nRetrieval-Augmented Generation (RAG). In particular, G3 consists of three\nsteps, i.e., Geo-alignment, Geo-diversification, and Geo-verification to\noptimize both retrieval and generation phases of worldwide geolocalization.\nDuring Geo-alignment, our solution jointly learns expressive multi-modal\nrepresentations for images, GPS and textual descriptions, which allows us to\ncapture location-aware semantics for retrieving nearby images for a given\nquery. During Geo-diversification, we leverage a prompt ensembling method that\nis robust to inconsistent retrieval performance for different image queries.\nFinally, we combine both retrieved and generated GPS candidates in\nGeo-verification for location prediction. Experiments on two well-established\ndatasets IM2GPS3k and YFCC4k verify the superiority of G3 compared to other\nstate-of-the-art methods. Our code and data are available online for\nreproduction.",
      "tldr_zh": "该论文提出 G3 框架，一种基于 Retrieval-Augmented Generation (RAG) 的有效自适应方法，用于全球地理定位，旨在解决捕捉位置感知视觉语义的困难和图像数据地理分布异质性的挑战。G3 通过三个关键步骤优化检索和生成过程：Geo-alignment 联合学习图像、GPS 和文本描述的多模态表示以检索附近图像；Geo-diversification 采用提示集合方法增强对不同查询的鲁棒性；Geo-verification 结合检索和生成的 GPS 候选进行精确位置预测。实验在 IM2GPS3k 和 YFCC4k 数据集上证明，G3 比现有最先进方法表现出色，代码和数据已公开以便复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14702v2",
      "published_date": "2024-05-23 15:37:06 UTC",
      "updated_date": "2024-10-31 09:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:57:23.461466"
    },
    {
      "arxiv_id": "2405.14701v5",
      "title": "DreamText: High Fidelity Scene Text Synthesis",
      "title_zh": "DreamText：高保真场景文本合成",
      "authors": [
        "Yibin Wang",
        "Weizhong Zhang",
        "Honghui Xu",
        "Cheng Jin"
      ],
      "abstract": "Scene text synthesis involves rendering specified texts onto arbitrary\nimages. Current methods typically formulate this task in an end-to-end manner\nbut lack effective character-level guidance during training. Besides, their\ntext encoders, pre-trained on a single font type, struggle to adapt to the\ndiverse font styles encountered in practical applications. Consequently, these\nmethods suffer from character distortion, repetition, and absence, particularly\nin polystylistic scenarios. To this end, this paper proposes DreamText for\nhigh-fidelity scene text synthesis. Our key idea is to reconstruct the\ndiffusion training process, introducing more refined guidance tailored to this\ntask, to expose and rectify the model's attention at the character level and\nstrengthen its learning of text regions. This transformation poses a hybrid\noptimization challenge, involving both discrete and continuous variables. To\neffectively tackle this challenge, we employ a heuristic alternate optimization\nstrategy. Meanwhile, we jointly train the text encoder and generator to\ncomprehensively learn and utilize the diverse font present in the training\ndataset. This joint training is seamlessly integrated into the alternate\noptimization process, fostering a synergistic relationship between learning\ncharacter embedding and re-estimating character attention. Specifically, in\neach step, we first encode potential character-generated position information\nfrom cross-attention maps into latent character masks. These masks are then\nutilized to update the representation of specific characters in the current\nstep, which, in turn, enables the generator to correct the character's\nattention in the subsequent steps. Both qualitative and quantitative results\ndemonstrate the superiority of our method to the state of the art.",
      "tldr_zh": "该论文提出DreamText方法，用于实现高保真度的场景文本合成，以解决现有方法在字符级指导不足和文本编码器适应多样字体能力弱的问题，导致的字符失真、重复或缺失。DreamText通过重建diffusion训练过程，提供精细的字符级指导，并采用启发式交替优化策略来处理混合离散和连续变量，同时联合训练文本编码器和生成器，以学习数据集中的多样字体。具体地，该方法在每个步骤中从cross-attention maps提取字符位置信息生成潜在掩码，用于更新字符表示并修正生成器的注意力。实验结果显示，DreamText在定性和定量指标上均优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/CodeGoat24/DreamText, Project page:\n  https://codegoat24.github.io/DreamText/",
      "pdf_url": "http://arxiv.org/pdf/2405.14701v5",
      "published_date": "2024-05-23 15:35:48 UTC",
      "updated_date": "2025-03-24 06:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:57:33.619958"
    },
    {
      "arxiv_id": "2405.14696v2",
      "title": "A Declarative System for Optimizing AI Workloads",
      "title_zh": "一种用于优化 AI 工作负载的声明式系统",
      "authors": [
        "Chunwei Liu",
        "Matthew Russo",
        "Michael Cafarella",
        "Lei Cao",
        "Peter Baille Chen",
        "Zui Chen",
        "Michael Franklin",
        "Tim Kraska",
        "Samuel Madden",
        "Gerardo Vitagliano"
      ],
      "abstract": "A long-standing goal of data management systems has been to build systems\nwhich can compute quantitative insights over large corpora of unstructured data\nin a cost-effective manner. Until recently, it was difficult and expensive to\nextract facts from company documents, data from scientific papers, or metrics\nfrom image and video corpora. Today's models can accomplish these tasks with\nhigh accuracy. However, a programmer who wants to answer a substantive\nAI-powered query must orchestrate large numbers of models, prompts, and data\noperations. For even a single query, the programmer has to make a vast number\nof decisions such as the choice of model, the right inference method, the most\ncost-effective inference hardware, the ideal prompt design, and so on. The\noptimal set of decisions can change as the query changes and as the\nrapidly-evolving technical landscape shifts. In this paper we present\nPalimpzest, a system that enables anyone to process AI-powered analytical\nqueries simply by defining them in a declarative language. The system uses its\ncost optimization framework to implement the query plan with the best\ntrade-offs between runtime, financial cost, and output data quality. We\ndescribe the workload of AI-powered analytics tasks, the optimization methods\nthat Palimpzest uses, and the prototype system itself. We evaluate Palimpzest\non tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching.\nWe show that even our simple prototype offers a range of appealing plans,\nincluding one that is 3.3x faster and 2.9x cheaper than the baseline method,\nwhile also offering better data quality. With parallelism enabled, Palimpzest\ncan produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a\nsingle-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the\nbaseline. These require no additional work by the user.",
      "tldr_zh": "本论文提出 Palimpzest 系统，这是一个声明式系统，用于优化 AI workloads，通过声明式语言定义 AI 驱动的分析查询，实现自动化决策，包括模型选择、推理方法、硬件配置和提示设计，以平衡运行时间、财务成本和输出数据质量。系统针对 AI 分析任务的优化框架，能够根据查询动态调整计划，并在 Legal Discovery、Real Estate Search 和 Medical Schema Matching 等任务上进行评估。实验结果显示，Palimpzest 比基线方法快 3.3 倍，便宜 2.9 倍，同时提供更好的数据质量；启用并行后，可实现高达 90.3 倍的速度提升和 9.1 倍的成本降低，F1-score 达到基线方法的 83.5%。这为用户提供了高效、可扩展的 AI 查询处理方案，无需额外手动干预。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "H.2.3; I.2.5"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14696v2",
      "published_date": "2024-05-23 15:31:18 UTC",
      "updated_date": "2024-05-29 15:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:57:47.482937"
    },
    {
      "arxiv_id": "2405.14691v1",
      "title": "CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System",
      "title_zh": "CityGPT：面向城市物联网学习、",
      "authors": [
        "Qinghua Guan",
        "Jinhui Ouyang",
        "Di Wu",
        "Weiren Yu"
      ],
      "abstract": "The spatiotemporal data generated by massive sensors in the Internet of\nThings (IoT) is extremely dynamic, heterogeneous, large scale and\ntime-dependent. It poses great challenges (e.g. accuracy, reliability, and\nstability) in real-time analysis and decision making for different IoT\napplications. The complexity of IoT data prevents the common people from\ngaining a deeper understanding of it. Agentized systems help address the lack\nof data insight for the common people. We propose a generic framework, namely\nCityGPT, to facilitate the learning and analysis of IoT time series with an\nend-to-end paradigm. CityGPT employs three agents to accomplish the\nspatiotemporal analysis of IoT data. The requirement agent facilitates user\ninputs based on natural language. Then, the analysis tasks are decomposed into\ntemporal and spatial analysis processes, completed by corresponding data\nanalysis agents (temporal and spatial agents). Finally, the spatiotemporal\nfusion agent visualizes the system's analysis results by receiving analysis\nresults from data analysis agents and invoking sub-visualization agents, and\ncan provide corresponding textual descriptions based on user demands. To\nincrease the insight for common people using our framework, we have agnentized\nthe framework, facilitated by a large language model (LLM), to increase the\ndata comprehensibility. Our evaluation results on real-world data with\ndifferent time dependencies show that the CityGPT framework can guarantee\nrobust performance in IoT computing.",
      "tldr_zh": "该研究针对物联网(IoT)中动态、异构的海量时空数据分析挑战，提出CityGPT框架，这是一个基于多代理系统的端到端范式，用于城市IoT数据的学习、分析和交互。框架包括三个关键代理：要求代理处理自然语言输入、时间和空间分析代理分解并完成相应分析，以及时空融合代理负责可视化和文本描述，以提升普通用户的数据洞察力。实验结果显示，CityGPT在不同时间依赖的真实数据上表现出稳健性能，确保了分析的准确性、可靠性和稳定性。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14691v1",
      "published_date": "2024-05-23 15:27:18 UTC",
      "updated_date": "2024-05-23 15:27:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:57:57.722930"
    },
    {
      "arxiv_id": "2405.14669v2",
      "title": "Efficiency for Free: Ideal Data Are Transportable Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Sun",
        "Yi Jiang",
        "Tao Lin"
      ],
      "abstract": "Data, the seminal opportunity and challenge in modern machine learning,\ncurrently constrains the scalability of representation learning and impedes the\npace of model evolution. In this work, we investigate the efficiency properties\nof data from both optimization and generalization perspectives. Our theoretical\nand empirical analysis reveals an unexpected finding: for a given task,\nutilizing a publicly available, task- and architecture-agnostic model (referred\nto as the `prior model' in this paper) can effectively produce efficient data.\nBuilding on this insight, we propose the Representation Learning Accelerator\n(\\algopt), which promotes the formation and utilization of efficient data,\nthereby accelerating representation learning. Utilizing a ResNet-18 pre-trained\non CIFAR-10 as a prior model to inform ResNet-50 training on ImageNet-1K\nreduces computational costs by 50% while maintaining the same accuracy as the\nmodel trained with the original BYOL, which requires 100% cost. Our code is\navailable at: \\url{https://github.com/LINs-lab/ReLA}.",
      "tldr_zh": "该论文探讨了数据在机器学习中的效率问题，从优化和泛化角度分析发现，利用一个公开的、任务和架构无关的 prior model 可以生成高效数据，从而加速表示学习。作者提出 Representation Learning Accelerator (ReLA) 方法，通过 prior model 来促进高效数据的形成和利用。实验结果显示，使用在 CIFAR-10 上预训练的 ResNet-18 作为 prior model 指导 ResNet-50 在 ImageNet-1K 的训练，能将计算成本降低 50% 同时保持与原始 BYOL 方法相同的准确率，为高效表示学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/LINs-lab/ReLA",
      "pdf_url": "http://arxiv.org/pdf/2405.14669v2",
      "published_date": "2024-05-23 15:06:02 UTC",
      "updated_date": "2024-11-01 09:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:58:09.881024"
    },
    {
      "arxiv_id": "2405.14664v4",
      "title": "Fisher Flow Matching for Generative Modeling over Discrete Data",
      "title_zh": "翻译失败",
      "authors": [
        "Oscar Davis",
        "Samuel Kessler",
        "Mircea Petrache",
        "İsmail İlkan Ceylan",
        "Michael Bronstein",
        "Avishek Joey Bose"
      ],
      "abstract": "Generative modeling over discrete data has recently seen numerous success\nstories, with applications spanning language modeling, biological sequence\ndesign, and graph-structured molecular data. The predominant generative\nmodeling paradigm for discrete data is still autoregressive, with more recent\nalternatives based on diffusion or flow-matching falling short of their\nimpressive performance in continuous data settings, such as image or video\ngeneration. In this work, we introduce Fisher-Flow, a novel flow-matching model\nfor discrete data. Fisher-Flow takes a manifestly geometric perspective by\nconsidering categorical distributions over discrete data as points residing on\na statistical manifold equipped with its natural Riemannian metric: the\n$\\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself\ncan be continuously reparameterised to points on the positive orthant of the\n$d$-hypersphere $\\mathbb{S}^d_+$, which allows us to define flows that map any\nsource distribution to target in a principled manner by transporting mass along\n(closed-form) geodesics of $\\mathbb{S}^d_+$. Furthermore, the learned flows in\nFisher-Flow can be further bootstrapped by leveraging Riemannian optimal\ntransport leading to improved training dynamics. We prove that the gradient\nflow induced by Fisher-Flow is optimal in reducing the forward KL divergence.\nWe evaluate Fisher-Flow on an array of synthetic and diverse real-world\nbenchmarks, including designing DNA Promoter, and DNA Enhancer sequences.\nEmpirically, we find that Fisher-Flow improves over prior diffusion and\nflow-matching models on these benchmarks.",
      "tldr_zh": "本文提出 Fisher-Flow，一种新型流匹配模型，用于离散数据的生成建模，旨在解决现有扩散或流匹配方法在离散领域（如语言和生物序列）不如连续数据表现的问题。Fisher-Flow 通过 Fisher-Rao 度量将分类分布视为统计流形上的点，并将离散数据重新参数化为 d-超球面的正交点，从而定义沿测地线的流来映射源分布到目标分布，同时利用 Riemannian optimal transport 优化训练动态。研究证明，Fisher-Flow 诱导的梯度流在减少前向 KL divergence 方面是最优的。在合成和真实基准测试中，如 DNA Promoter 和 DNA Enhancer 序列设计，该模型的表现优于现有扩散和流匹配模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14664v4",
      "published_date": "2024-05-23 15:02:11 UTC",
      "updated_date": "2024-10-30 11:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:58:22.897793"
    },
    {
      "arxiv_id": "2405.14660v2",
      "title": "Implicit In-context Learning",
      "title_zh": "隐式上下文学习",
      "authors": [
        "Zhuowei Li",
        "Zihao Xu",
        "Ligong Han",
        "Yunhe Gao",
        "Song Wen",
        "Di Liu",
        "Hao Wang",
        "Dimitris N. Metaxas"
      ],
      "abstract": "In-context Learning (ICL) empowers large language models (LLMs) to swiftly\nadapt to unseen tasks at inference-time by prefixing a few demonstration\nexamples before queries. Despite its versatility, ICL incurs substantial\ncomputational and memory overheads compared to zero-shot learning and is\nsensitive to the selection and order of demonstration examples. In this work,\nwe introduce Implicit In-context Learning (I2CL), an innovative paradigm that\nreduces the inference cost of ICL to that of zero-shot learning with minimal\ninformation loss. I2CL operates by first generating a condensed vector\nrepresentation, namely a context vector, extracted from the demonstration\nexamples. It then conducts an inference-time intervention through injecting a\nlinear combination of the context vector and query activations back into the\nmodel's residual streams. Empirical evaluation on nine real-world tasks across\nthree model architectures demonstrates that I2CL achieves few-shot level\nperformance at zero-shot inference cost, and it exhibits robustness against\nvariations in demonstration examples. Furthermore, I2CL facilitates a novel\nrepresentation of task-ids, enhancing task similarity detection and fostering\neffective transfer learning. We also perform a comprehensive analysis and\nablation study on I2CL, offering deeper insights into its internal mechanisms.\nCode is available at https://github.com/LzVv123456/I2CL.",
      "tldr_zh": "本研究针对 In-context Learning (ICL) 在大型语言模型 (LLMs) 中的高计算开销和对演示示例敏感性问题，提出了一种创新范式 Implicit In-context Learning (I2CL)。I2CL 通过从演示示例中提取 condensed vector representation（即 context vector），并在推理时将其与查询激活的线性组合注入模型的 residual streams，从而将 ICL 的推理成本降低到 zero-shot learning 水平，同时最小化信息损失。实验在九个真实任务和三个模型架构上显示，I2CL 实现了与 few-shot 相当的性能，且对演示示例变化更具鲁棒性。此外，它还提升了 task-ids 的表示方式，促进任务相似性检测和转移学习，并通过全面分析和消融研究揭示了其内部机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14660v2",
      "published_date": "2024-05-23 14:57:52 UTC",
      "updated_date": "2025-02-25 14:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:58:34.721215"
    },
    {
      "arxiv_id": "2405.14654v1",
      "title": "Efficient Medical Question Answering with Knowledge-Augmented Question Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Khlaut",
        "Corentin Dancette",
        "Elodie Ferreres",
        "Alaedine Bennani",
        "Paul Hérent",
        "Pierre Manceron"
      ],
      "abstract": "In the expanding field of language model applications, medical knowledge\nrepresentation remains a significant challenge due to the specialized nature of\nthe domain. Large language models, such as GPT-4, obtain reasonable scores on\nmedical question answering tasks, but smaller models are far behind. In this\nwork, we introduce a method to improve the proficiency of a small language\nmodel in the medical domain by employing a two-fold approach. We first\nfine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to\ngenerate questions similar to the downstream task, prompted with textbook\nknowledge, and use them to fine-tune the model. Additionally, we introduce\nECN-QA, a novel medical question answering dataset containing ``progressive\nquestions'' composed of related sequential questions. We show the benefits of\nour training strategy on this dataset. The study's findings highlight the\npotential of small language models in the medical domain when appropriately\nfine-tuned. The code and weights are available at\nhttps://github.com/raidium-med/MQG.",
      "tldr_zh": "该论文提出了一种高效的医疗问答方法，通过Knowledge-Augmented Question Generation来提升小语言模型在医疗领域的表现。具体而言，该方法包括两个步骤：首先在医疗教科书语料上fine-tune模型，其次使用GPT-4生成类似于下游任务的“progressive questions”，并结合教科书知识进行进一步fine-tune。此外，论文引入了ECN-QA数据集，该数据集包含相关顺序问题，并展示了这种训练策略在数据集上的显著益处，证明了小语言模型经适当fine-tune后在医疗问答中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the Clinical Natural Language Processing Workshop, NAACL\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14654v1",
      "published_date": "2024-05-23 14:53:52 UTC",
      "updated_date": "2024-05-23 14:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:58:46.465074"
    },
    {
      "arxiv_id": "2405.14632v2",
      "title": "DLPO: Diffusion Model Loss-Guided Reinforcement Learning for Fine-Tuning Text-to-Speech Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Chen",
        "Ju-Seung Byun",
        "Micha Elsner",
        "Andrew Perrault"
      ],
      "abstract": "Recent advancements in generative models have sparked a significant interest\nwithin the machine learning community. Particularly, diffusion models have\ndemonstrated remarkable capabilities in synthesizing images and speech. Studies\nsuch as those by Lee et al. (2023), Black et al. (2023), Wang et al. (2023),\nand Fan et al. (2024) illustrate that Reinforcement Learning with Human\nFeedback (RLHF) can enhance diffusion models for image synthesis. However, due\nto architectural differences between these models and those employed in speech\nsynthesis, it remains uncertain whether RLHF could similarly benefit speech\nsynthesis models. In this paper, we explore the practical application of RLHF\nto diffusion-based text-to-speech synthesis, leveraging the mean opinion score\n(MOS) as predicted by UTokyo-SaruLab MOS prediction system (Saeki et al., 2022)\nas a proxy loss. We introduce diffusion model loss-guided RL policy\noptimization (DLPO) and compare it against other RLHF approaches, employing the\nNISQA speech quality and naturalness assessment model (Mittag et al., 2021) and\nhuman preference experiments for further evaluation. Our results show that RLHF\ncan enhance diffusion-based text-to-speech synthesis models, and, moreover,\nDLPO can better improve diffusion models in generating natural and high quality\nspeech audios.",
      "tldr_zh": "本研究探讨了强化学习与人类反馈（RLHF）在文本到语音（text-to-speech）扩散模型中的应用，以提升语音合成质量。作者引入了扩散模型损失指导的强化学习策略优化（DLPO）方法，使用均值意见分（MOS）预测系统作为代理损失，并与其它RLHF方法进行比较。实验结果显示，RLHF能显著改善扩散模型的性能，而DLPO在生成自然和高品质语音方面表现出色，证明了其在语音合成领域的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14632v2",
      "published_date": "2024-05-23 14:39:35 UTC",
      "updated_date": "2024-11-15 20:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:58:58.241148"
    },
    {
      "arxiv_id": "2405.14629v2",
      "title": "Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Takuya Hiraoka",
        "Guanquan Wang",
        "Takashi Onishi",
        "Yoshimasa Tsuruoka"
      ],
      "abstract": "In reinforcement learning (RL) with experience replay, experiences stored in\na replay buffer influence the RL agent's performance. Information about how\nthese experiences influence the agent's performance is valuable for various\npurposes, such as identifying experiences that negatively influence\nunderperforming agents. One method for estimating the influence of experiences\nis the leave-one-out (LOO) method. However, this method is usually\ncomputationally prohibitive. In this paper, we present Policy Iteration with\nTurn-over Dropout (PIToD), which efficiently estimates the influence of\nexperiences. We evaluate how accurately PIToD estimates the influence of\nexperiences and its efficiency compared to LOO. We then apply PIToD to amend\nunderperforming RL agents, i.e., we use PIToD to estimate negatively\ninfluential experiences for the RL agents and to delete the influence of these\nexperiences. We show that RL agents' performance is significantly improved via\namendments with PIToD.",
      "tldr_zh": "该研究探讨了在强化学习（RL）中使用经验回放时，存储在回放缓冲区的经验如何影响代理性能，并提出了一种高效方法 Policy Iteration with Turn-over Dropout (PIToD) 来估计这些经验的影响。PIToD 通过模拟经验删除来评估影响，避免了传统 leave-one-out (LOO) 方法的计算开销，从而提高了效率和准确性。实验结果显示，使用 PIToD 识别并删除负面影响的经验后，RL 代理的表现得到显著改善，为优化 RL 代理提供了实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Source code:\n  https://github.com/TakuyaHiraoka/Which-Experiences-Are-Influential-for-RL-Agents",
      "pdf_url": "http://arxiv.org/pdf/2405.14629v2",
      "published_date": "2024-05-23 14:35:56 UTC",
      "updated_date": "2024-10-04 12:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:59:10.259253"
    },
    {
      "arxiv_id": "2405.14619v3",
      "title": "exLong: Generating Exceptional Behavior Tests with Large Language Models",
      "title_zh": "exLong：使用大型语言模型生成异常行为测试",
      "authors": [
        "Jiyang Zhang",
        "Yu Liu",
        "Pengyu Nie",
        "Junyi Jessy Li",
        "Milos Gligoric"
      ],
      "abstract": "Many popular programming languages, including C#, Java, and Python, support\nexceptions. Exceptions are thrown during program execution if an unwanted event\nhappens, e.g., a method is invoked with an illegal argument value. Software\ndevelopers write exceptional behavior tests (EBTs) to check that their code\ndetects unwanted events and throws appropriate exceptions. Prior research\nstudies have shown the importance of EBTs, but those studies also highlighted\nthat developers put most of their efforts on \"happy paths\", e.g., paths without\nunwanted events. To help developers fill the gap, we present the first\nframework, dubbed exLong, that automatically generates EBTs. exLong is a large\nlanguage model instruction fine-tuned from CodeLlama and embeds reasoning about\ntraces that lead to throw statements, conditional expressions that guard throw\nstatements, and non-exceptional behavior tests that execute similar traces. We\ncompare exLong with the state-of-the-art models for test generation (CAT-LM)\nand one of the strongest foundation models (GPT-4o), as well as with\nanalysis-based tools for test generation (Randoop and EvoSuite). Our results\nshow that exLong outperforms existing models and tools. Furthermore, we\ncontributed several pull requests to open-source projects and 23 EBTs generated\nby exLong were already accepted.",
      "tldr_zh": "本研究针对软件开发中异常处理测试的不足，提出exLong框架，利用Large Language Models（从CodeLlama指令微调）自动生成exceptional behavior tests (EBTs)，以检测代码对不想要事件的响应，如非法参数调用。exLong通过嵌入对异常追踪、保护throw语句的条件表达式以及类似非异常测试的推理，填补开发者偏重“快乐路径”的空白。与CAT-LM、GPT-4o、Randoop和EvoSuite等现有模型和工具相比，exLong表现出色，在性能上提升显著，并已在开源项目中成功贡献23个EBTs。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "ICSE 2025 (camera ready)",
      "pdf_url": "http://arxiv.org/pdf/2405.14619v3",
      "published_date": "2024-05-23 14:28:41 UTC",
      "updated_date": "2024-12-24 21:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:59:23.528837"
    },
    {
      "arxiv_id": "2405.14616v1",
      "title": "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting",
      "title_zh": "TimeMixer：用于时间序列预测的可分解多尺度混合",
      "authors": [
        "Shiyu Wang",
        "Haixu Wu",
        "Xiaoming Shi",
        "Tengge Hu",
        "Huakun Luo",
        "Lintao Ma",
        "James Y. Zhang",
        "Jun Zhou"
      ],
      "abstract": "Time series forecasting is widely used in extensive applications, such as\ntraffic planning and weather forecasting. However, real-world time series\nusually present intricate temporal variations, making forecasting extremely\nchallenging. Going beyond the mainstream paradigms of plain decomposition and\nmultiperiodicity analysis, we analyze temporal variations in a novel view of\nmultiscale-mixing, which is based on an intuitive but important observation\nthat time series present distinct patterns in different sampling scales. The\nmicroscopic and the macroscopic information are reflected in fine and coarse\nscales respectively, and thereby complex variations can be inherently\ndisentangled. Based on this observation, we propose TimeMixer as a fully\nMLP-based architecture with Past-Decomposable-Mixing (PDM) and\nFuture-Multipredictor-Mixing (FMM) blocks to take full advantage of\ndisentangled multiscale series in both past extraction and future prediction\nphases. Concretely, PDM applies the decomposition to multiscale series and\nfurther mixes the decomposed seasonal and trend components in fine-to-coarse\nand coarse-to-fine directions separately, which successively aggregates the\nmicroscopic seasonal and macroscopic trend information. FMM further ensembles\nmultiple predictors to utilize complementary forecasting capabilities in\nmultiscale observations. Consequently, TimeMixer is able to achieve consistent\nstate-of-the-art performances in both long-term and short-term forecasting\ntasks with favorable run-time efficiency.",
      "tldr_zh": "这篇论文针对时间序列预测中的复杂 temporal variations 问题，提出 multiscale-mixing 的新观点，即时间序列在不同采样尺度显示出微观（细尺度）和宏观（粗尺度）模式，从而实现内在解耦。作者开发了 TimeMixer，一种基于 MLP 的架构，包括 Past-Decomposable-Mixing (PDM) 块用于分解和混合多尺度序列的季节性和趋势组件，以及 Future-Multipredictor-Mixing (FMM) 块来集成多个预测器，利用多尺度观察的互补能力。实验结果表明，TimeMixer 在长短期预测任务中实现了最先进的性能，同时保持了高效的运行效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14616v1",
      "published_date": "2024-05-23 14:27:07 UTC",
      "updated_date": "2024-05-23 14:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:59:35.858702"
    },
    {
      "arxiv_id": "2405.14612v2",
      "title": "Explaining Multi-modal Large Language Models by Analyzing their Vision Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Loris Giulivi",
        "Giacomo Boracchi"
      ],
      "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in understanding and generating content across various modalities,\nsuch as images and text. However, their interpretability remains a challenge,\nhindering their adoption in critical applications. This research proposes a\nnovel approach to enhance the interpretability of MLLMs by focusing on the\nimage embedding component. We combine an open-world localization model with a\nMLLM, thus creating a new architecture able to simultaneously produce text and\nobject localization outputs from the same vision embedding. The proposed\narchitecture greatly promotes interpretability, enabling us to design a novel\nsaliency map to explain any output token, to identify model hallucinations, and\nto assess model biases through semantic adversarial perturbations.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)的解释性挑战，提出了一种新方法，通过分析其视觉感知（特别是图像嵌入）来提升模型的可解释性。研究将开源的开放世界定位模型(open-world localization model)与MLLM结合，创建了一个新架构，能够从同一视觉嵌入中同时生成文本和对象定位输出。这种设计允许开发新型显著性地图(saliency map)，用于解释输出标记、识别模型幻觉，并通过语义对抗扰动(semantic adversarial perturbations)评估模型偏差，从而为MLLMs在关键应用中的采用提供更可靠的基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted at BMVC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14612v2",
      "published_date": "2024-05-23 14:24:23 UTC",
      "updated_date": "2024-05-28 11:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:59:46.424598"
    },
    {
      "arxiv_id": "2405.14608v1",
      "title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan-May Le",
        "Ling Luo",
        "Uwe Aickelin",
        "Minh-Tuan Tran"
      ],
      "abstract": "Multivariate time series classification (MTSC) has attracted significant\nresearch attention due to its diverse real-world applications. Recently,\nexploiting transformers for MTSC has achieved state-of-the-art performance.\nHowever, existing methods focus on generic features, providing a comprehensive\nunderstanding of data, but they ignore class-specific features crucial for\nlearning the representative characteristics of each class. This leads to poor\nperformance in the case of imbalanced datasets or datasets with similar overall\npatterns but differing in minor class-specific details. In this paper, we\npropose a novel Shapelet Transformer (ShapeFormer), which comprises\nclass-specific and generic transformer modules to capture both of these\nfeatures. In the class-specific module, we introduce the discovery method to\nextract the discriminative subsequences of each class (i.e. shapelets) from the\ntraining set. We then propose a Shapelet Filter to learn the difference\nfeatures between these shapelets and the input time series. We found that the\ndifference feature for each shapelet contains important class-specific\nfeatures, as it shows a significant distinction between its class and others.\nIn the generic module, convolution filters are used to extract generic features\nthat contain information to distinguish among all classes. For each module, we\nemploy the transformer encoder to capture the correlation between their\nfeatures. As a result, the combination of two transformer modules allows our\nmodel to exploit the power of both types of features, thereby enhancing the\nclassification performance. Our experiments on 30 UEA MTSC datasets demonstrate\nthat ShapeFormer has achieved the highest accuracy ranking compared to\nstate-of-the-art methods. The code is available at\nhttps://github.com/xuanmay2701/shapeformer.",
      "tldr_zh": "本文提出 ShapeFormer，一种用于 Multivariate Time Series Classification (MTSC) 的新型 Transformer 模型，旨在同时捕获类别特定特征和通用特征，以解决现有方法忽略类别特定细节导致的性能问题。在类别特定模块中，通过 shapelets 发现方法从训练集提取每个类别的判别子序列，并使用 Shapelet Filter 学习这些子序列与输入时间序列的差异特征；而在通用模块中，采用卷积过滤器提取区分所有类别的通用特征，并分别通过 Transformer 编码器处理特征相关性。实验结果显示，ShapeFormer 在 30 个 UEA MTSC 数据集上比现有最先进方法取得了最高的准确率排名，代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14608v1",
      "published_date": "2024-05-23 14:21:35 UTC",
      "updated_date": "2024-05-23 14:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:59:59.974690"
    },
    {
      "arxiv_id": "2405.14606v4",
      "title": "Logical Characterizations of Recurrent Graph Neural Networks with Reals and Floats",
      "title_zh": "翻译失败",
      "authors": [
        "Veeti Ahvonen",
        "Damian Heiman",
        "Antti Kuusisto",
        "Carsten Lutz"
      ],
      "abstract": "In pioneering work from 2019, Barcel\\'o and coauthors identified logics that\nprecisely match the expressive power of constant iteration-depth graph neural\nnetworks (GNNs) relative to properties definable in first-order logic. In this\narticle, we give exact logical characterizations of recurrent GNNs in two\nscenarios: (1) in the setting with floating-point numbers and (2) with reals.\nFor floats, the formalism matching recurrent GNNs is a rule-based modal logic\nwith counting, while for reals we use a suitable infinitary modal logic, also\nwith counting. These results give exact matches between logics and GNNs in the\nrecurrent setting without relativising to a background logic in either case,\nbut using some natural assumptions about floating-point arithmetic. Applying\nour characterizations, we also prove that, relative to graph properties\ndefinable in monadic second-order logic (MSO), our infinitary and rule-based\nlogics are equally expressive. This implies that recurrent GNNs with reals and\nfloats have the same expressive power over MSO-definable properties and shows\nthat, for such properties, also recurrent GNNs with reals are characterized by\na (finitary!) rule-based modal logic. In the general case, in contrast, the\nexpressive power with floats is weaker than with reals. In addition to\nlogic-oriented results, we also characterize recurrent GNNs, with both reals\nand floats, via distributed automata, drawing links to distributed computing\nmodels.",
      "tldr_zh": "本论文对循环图神经网络（recurrent GNNs）在浮点数（floats）和实数（reals）场景下的表达能力进行了精确的逻辑表征，扩展了2019年Barceló等人的工作。针对浮点数，使用基于规则的模态逻辑（rule-based modal logic）加计数；针对实数，则采用合适的无限模态逻辑（infinitary modal logic）加计数，并在自然假设下实现精确匹配。研究发现，在单子二阶逻辑（MSO）可定义的图属性上，这两种逻辑表达能力相同，从而证明recurrent GNNs在这些属性上的表达力一致，但总体上浮点数场景的表达能力弱于实数场景；此外，论文还通过分布式自动机（distributed automata）表征了这些网络，与分布式计算模型建立了联系。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1; F.1.1; I.2.0"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14606v4",
      "published_date": "2024-05-23 14:19:21 UTC",
      "updated_date": "2025-05-02 10:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:00:12.262526"
    },
    {
      "arxiv_id": "2405.14601v1",
      "title": "A FAIR and Free Prompt-based Research Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Shamsabadi",
        "Jennifer D'Souza"
      ],
      "abstract": "This demo will present the Research Assistant (RA) tool developed to assist\nwith six main types of research tasks defined as standardized instruction\ntemplates, instantiated with user input, applied finally as prompts to\nwell-known--for their sophisticated natural language processing abilities--AI\ntools, such as ChatGPT (https://chat.openai.com/) and Gemini\n(https://gemini.google.com/app). The six research tasks addressed by RA are:\ncreating FAIR research comparisons, ideating research topics, drafting grant\napplications, writing scientific blogs, aiding preliminary peer reviews, and\nformulating enhanced literature search queries. RA's reliance on generative AI\ntools like ChatGPT or Gemini means the same research task assistance can be\noffered in any scientific discipline. We demonstrate its versatility by sharing\nRA outputs in Computer Science, Virology, and Climate Science, where the output\nwith the RA tool assistance mirrored that from a domain expert who performed\nthe same research task.",
      "tldr_zh": "该研究引入了名为 Research Assistant (RA) 的免费提示-based 工具，用于辅助六种标准化研究任务，包括创建 FAIR 研究比较、ideating research topics、drafting grant applications、writing scientific blogs、aiding preliminary peer reviews 和 formulating enhanced literature search queries。RA 通过用户输入实例化的指令模板，将任务作为提示应用到 ChatGPT 或 Gemini 等高级自然语言处理 AI 工具上，实现跨学科的通用性。实验演示显示，在计算机科学、病毒学和气候科学领域，RA 的输出与领域专家的结果高度相似，证明了其在提升研究效率方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures, accepted to the Demo track of NLDB 2024\n  (https://nldb2024.di.unito.it/)",
      "pdf_url": "http://arxiv.org/pdf/2405.14601v1",
      "published_date": "2024-05-23 14:16:46 UTC",
      "updated_date": "2024-05-23 14:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:00:23.003000"
    },
    {
      "arxiv_id": "2405.14600v1",
      "title": "Discretization of continuous input spaces in the hippocampal autoencoder",
      "title_zh": "海马自编码器中连续输入空间的离散化",
      "authors": [
        "Adrian F. Amil",
        "Ismael T. Freire",
        "Paul F. M. J. Verschure"
      ],
      "abstract": "The hippocampus has been associated with both spatial cognition and episodic\nmemory formation, but integrating these functions into a unified framework\nremains challenging. Here, we demonstrate that forming discrete memories of\nvisual events in sparse autoencoder neurons can produce spatial tuning similar\nto hippocampal place cells. We then show that the resulting very\nhigh-dimensional code enables neurons to discretize and tile the underlying\nimage space with minimal overlap. Additionally, we extend our results to the\nauditory domain, showing that neurons similarly tile the frequency space in an\nexperience-dependent manner. Lastly, we show that reinforcement learning agents\ncan effectively perform various visuo-spatial cognitive tasks using these\nsparse, very high-dimensional representations.",
      "tldr_zh": "本研究探讨了海马体（hippocampal）在空间认知和 episodic memory 形成中的整合挑战，通过在 sparse autoencoder 神经元中形成视觉事件的离散记忆，成功产生了类似于 place cells 的空间调谐。结果显示，这种高维编码能以最小重叠的方式离散化和平铺底层图像空间，并扩展到听觉领域，使神经元以经验依赖的方式平铺频率空间。该框架还证明，强化学习（reinforcement learning）代理可以使用这些稀疏、高维表示有效地执行各种视空间认知任务，从而为统一海马体功能提供新见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14600v1",
      "published_date": "2024-05-23 14:16:44 UTC",
      "updated_date": "2024-05-23 14:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:00:35.083006"
    },
    {
      "arxiv_id": "2405.14597v2",
      "title": "Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyuan Li",
        "Ran Meng",
        "Yiduo Li",
        "Bo Zhang",
        "Yifan Lu",
        "Yerui Sun",
        "Lin Ma",
        "Yuchen Xie"
      ],
      "abstract": "We introduce Integer Scale, a novel post-training quantization scheme for\nlarge language models that effectively resolves the inference bottleneck in\ncurrent fine-grained quantization approaches while maintaining similar\naccuracies. Integer Scale is a free lunch as it requires no extra calibration\nor fine-tuning which will otherwise incur additional costs. It can be used\nplug-and-play for most fine-grained quantization methods. Its integration\nresults in at most 1.85x end-to-end speed boost over the original counterpart\nwith comparable accuracy. Additionally, due to the orchestration of the\nproposed Integer Scale and fine-grained quantization, we resolved the\nquantization difficulty for Mixtral-8x7B and LLaMA-3 models with negligible\nperformance degradation, and it comes with an end-to-end speed boost of 2.13x,\nand 2.31x compared with their FP16 versions respectively.",
      "tldr_zh": "本论文引入 Integer Scale，一种新型的后训练量化方案，用于加速大型语言模型(LLMs)的细粒度量化，同时保持相似的准确性。该方案无需额外校准或微调，即可与大多数细粒度量化方法无缝集成，提供高达1.85x的端到端速度提升。实验结果显示，Integer Scale 成功解决了 Mixtral-8x7B 和 LLaMA-3 模型的量化难题，仅有微不足道的性能下降，并分别比它们的 FP16 版本快 2.13x 和 2.31x。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14597v2",
      "published_date": "2024-05-23 14:12:58 UTC",
      "updated_date": "2024-05-28 07:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:00:48.595982"
    },
    {
      "arxiv_id": "2405.15821v1",
      "title": "Reinforcing Language Agents via Policy Optimization with Action Decomposition",
      "title_zh": "通过动作分解的策略优化强化语言代理",
      "authors": [
        "Muning Wen",
        "Ziyu Wan",
        "Weinan Zhang",
        "Jun Wang",
        "Ying Wen"
      ],
      "abstract": "Language models as intelligent agents push the boundaries of sequential\ndecision-making agents but struggle with limited knowledge of environmental\ndynamics and exponentially huge action space. Recent efforts like GLAM and\nTWOSOME manually constrain the action space to a restricted subset and employ\nreinforcement learning to align agents' knowledge with specific environments.\nHowever, they overlook fine-grained credit assignments for intra-action tokens,\nwhich is essential for efficient language agent optimization, and rely on\nhuman's prior knowledge to restrict action space. This paper proposes\ndecomposing language agent optimization from the action level to the token\nlevel, offering finer supervision for each intra-action token and manageable\noptimization complexity in environments with unrestricted action spaces.\nBeginning with the simplification of flattening all actions, we theoretically\nexplore the discrepancies between action-level optimization and this naive\ntoken-level optimization. We then derive the Bellman backup with Action\nDecomposition (BAD) to integrate credit assignments for both intra-action and\ninter-action tokens, effectively eliminating the discrepancies. Implementing\nBAD within the PPO algorithm, we introduce Policy Optimization with Action\nDecomposition (POAD). POAD benefits from a finer-grained credit assignment\nprocess and lower optimization complexity, leading to enhanced learning\nefficiency and generalization abilities in aligning language agents with\ninteractive environments. We validate POAD across diverse testbeds, with\nresults affirming the advantages of our approach and the correctness of our\ntheoretical analysis.",
      "tldr_zh": "本文提出一种名为 Policy Optimization with Action Decomposition (POAD) 的方法，通过将语言代理优化从动作级别分解到 token 级别，实现更细粒度的信用分配（credit assignments），从而解决语言模型作为智能代理时面对的环境动态知识有限和动作空间巨大的挑战。不同于现有方法如 GLAM 和 TWOSOME 的手动动作空间限制，POAD 推导了带 Action Decomposition 的 Bellman backup (BAD)，整合了动作内（intra-action）和动作间（inter-action）token 的信用分配，并将其应用于 PPO 算法中，提升了优化复杂度的可管理性和学习效率。实验在多样交互环境中验证了 POAD 的优势，包括更高的学习效率和泛化能力，支持了理论分析的正确性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages with 9 pages are main context",
      "pdf_url": "http://arxiv.org/pdf/2405.15821v1",
      "published_date": "2024-05-23 14:01:44 UTC",
      "updated_date": "2024-05-23 14:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:01.124100"
    },
    {
      "arxiv_id": "2405.19354v1",
      "title": "Rotations of Gödel algebras with modal operators",
      "title_zh": "带有模态算子的 Gödel 代数的旋转",
      "authors": [
        "Tommaso Flaminio",
        "Lluis Godo",
        "Paula Menchón",
        "Ricardo O. Rodriguez"
      ],
      "abstract": "The present paper is devoted to study the effect of connected and\ndisconnected rotations of G\\\"odel algebras with operators grounded on directly\nindecomposable structures. The structures resulting from this construction we\nwill present are nilpotent minimum (with or without negation fixpoint,\ndepending on whether the rotation is connected or disconnected) with special\nmodal operators defined on a directly indecomposable algebra. In this paper we\nwill present a (quasi-)equational definition of these latter structures. Our\nmain results show that directly indecomposable nilpotent minimum algebras (with\nor without negation fixpoint) with modal operators are fully characterized as\nconnected and disconnected rotations of directly indecomposable G\\\"odel\nalgebras endowed with modal operators.",
      "tldr_zh": "这篇论文研究了带有 modal operators 的 Gödel algebras 的旋转，特别是基于直接不可分解结构的连接和非连接旋转。论文通过这种构造生成了 nilpotent minimum algebras，这些结构可能带有或不带有 negation fixpoint，并定义了特殊的 modal operators。作者提供了这些 algebras 的（quasi-)equational 定义，并证明了直接不可分解的 nilpotent minimum algebras（带有或不带有 negation fixpoint）与 modal operators 可以完全表征为带有 modal operators 的 Gödel algebras 的旋转。",
      "categories": [
        "math.GM",
        "cs.AI",
        "cs.LO",
        "03B50, 03B45"
      ],
      "primary_category": "math.GM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19354v1",
      "published_date": "2024-05-23 13:59:06 UTC",
      "updated_date": "2024-05-23 13:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:11.246257"
    },
    {
      "arxiv_id": "2405.14582v3",
      "title": "PoseCrafter: One-Shot Personalized Video Synthesis Following Flexible Pose Control",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Zhong",
        "Min Zhao",
        "Zebin You",
        "Xiaofeng Yu",
        "Changwang Zhang",
        "Chongxuan Li"
      ],
      "abstract": "In this paper, we introduce PoseCrafter, a one-shot method for personalized\nvideo generation following the control of flexible poses. Built upon Stable\nDiffusion and ControlNet, we carefully design an inference process to produce\nhigh-quality videos without the corresponding ground-truth frames. First, we\nselect an appropriate reference frame from the training video and invert it to\ninitialize all latent variables for generation. Then, we insert the\ncorresponding training pose into the target pose sequences to enhance\nfaithfulness through a trained temporal attention module. Furthermore, to\nalleviate the face and hand degradation resulting from discrepancies between\nposes of training videos and inference poses, we implement simple latent\nediting through an affine transformation matrix involving facial and hand\nlandmarks. Extensive experiments on several datasets demonstrate that\nPoseCrafter achieves superior results to baselines pre-trained on a vast\ncollection of videos under 8 commonly used metrics. Besides, PoseCrafter can\nfollow poses from different individuals or artificial edits and simultaneously\nretain the human identity in an open-domain training video. Our project page is\navailable at https://ml-gsai.github.io/PoseCrafter-demo/.",
      "tldr_zh": "本研究提出PoseCrafter，一种one-shot个性化视频合成方法，允许根据灵活的姿态控制生成高质量视频，而无需对应真实帧。该方法构建于Stable Diffusion和ControlNet之上，通过从训练视频中选择参考帧进行潜在变量初始化、插入训练姿态以增强时序注意力模块的忠实度，以及使用affine transformation matrix和面部、手部landmarks进行潜在编辑来缓解姿态差异导致的退化问题。在多个数据集上的实验显示，PoseCrafter在8个常用指标下优于基于大量视频预训练的基线模型，并能跟随不同个体或人工编辑的姿态，同时保留训练视频中人类身份。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14582v3",
      "published_date": "2024-05-23 13:53:50 UTC",
      "updated_date": "2024-07-18 08:50:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:24.834046"
    },
    {
      "arxiv_id": "2405.14573v5",
      "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents",
      "title_zh": "AndroidWorld：自治代理的动态基准测试环境",
      "authors": [
        "Christopher Rawles",
        "Sarah Clinckemaillie",
        "Yifan Chang",
        "Jonathan Waltz",
        "Gabrielle Lau",
        "Marybeth Fair",
        "Alice Li",
        "William Bishop",
        "Wei Li",
        "Folawiyo Campbell-Ajala",
        "Daniel Toyama",
        "Robert Berry",
        "Divya Tyamagundlu",
        "Timothy Lillicrap",
        "Oriana Riva"
      ],
      "abstract": "Autonomous agents that execute human tasks by controlling computers can\nenhance human productivity and application accessibility. However, progress in\nthis field will be driven by realistic and reproducible benchmarks. We present\nAndroidWorld, a fully functional Android environment that provides reward\nsignals for 116 programmatic tasks across 20 real-world Android apps. Unlike\nexisting interactive environments, which provide a static test set,\nAndroidWorld dynamically constructs tasks that are parameterized and expressed\nin natural language in unlimited ways, thus enabling testing on a much larger\nand more realistic suite of tasks. To ensure reproducibility, each task\nincludes dedicated initialization, success-checking, and tear-down logic, which\nmodifies and inspects the device's system state. We experiment with baseline\nagents to test AndroidWorld and provide initial results on the benchmark. Our\nbest agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for\nfuture work. Furthermore, we adapt a popular desktop web agent to work on\nAndroid, which we find to be less effective on mobile, suggesting future\nresearch is needed to achieve universal, cross-platform agents. Finally, we\nalso conduct a robustness analysis, showing that task variations can\nsignificantly affect agent performance, demonstrating that without such\ntesting, agent performance metrics may not fully reflect practical challenges.\nAndroidWorld and the experiments in this paper are available at\ngithub.com/google-research/android_world.",
      "tldr_zh": "本文提出 AndroidWorld，一种动态基准环境，用于评估自主代理在 Android 上的任务执行能力。该环境提供 116 个程序化任务，跨越 20 个真实世界应用，通过参数化自然语言表达和动态任务构建，实现无限测试场景，并确保可重现性 via 专用初始化、成功检查和拆卸逻辑。实验结果显示，最佳基线代理完成 30.6% 的任务，而适应桌面代理在移动端效果较差；此外，稳健性分析表明任务变化会显著影响性能，强调了未来跨平台代理研究的必要性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14573v5",
      "published_date": "2024-05-23 13:48:54 UTC",
      "updated_date": "2025-04-06 20:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:35.864844"
    },
    {
      "arxiv_id": "2405.14569v3",
      "title": "PrivCirNet: Efficient Private Inference via Block Circulant Transformation",
      "title_zh": "PrivCirNet：通过块循环变换实现高效私有推理",
      "authors": [
        "Tianshi Xu",
        "Lemeng Wu",
        "Runsheng Wang",
        "Meng Li"
      ],
      "abstract": "Homomorphic encryption (HE)-based deep neural network (DNN) inference\nprotects data and model privacy but suffers from significant computation\noverhead. We observe transforming the DNN weights into circulant matrices\nconverts general matrix-vector multiplications into HE-friendly 1-dimensional\nconvolutions, drastically reducing the HE computation cost. Hence, in this\npaper, we propose \\method, a protocol/network co-optimization framework based\non block circulant transformation. At the protocol level, PrivCirNet customizes\nthe HE encoding algorithm that is fully compatible with the block circulant\ntransformation and reduces the computation latency in proportion to the block\nsize. At the network level, we propose a latency-aware formulation to search\nfor the layer-wise block size assignment based on second-order information.\nPrivCirNet also leverages layer fusion to further reduce the inference cost. We\ncompare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S\\&P\n2024) and the HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and\nVision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by\n$5.0\\times$ and $1.3\\times$ with iso-accuracy over Bolt, respectively, and\nimproves accuracy by $4.1\\%$ and $12\\%$ over SpENCNN, respectively. For\nMobileNetV2 on ImageNet, PrivCirNet achieves $1.7\\times$ lower latency and\n$4.2\\%$ better accuracy over Bolt and SpENCNN, respectively. Our code and\ncheckpoints are available on Git Hub.",
      "tldr_zh": "该论文提出 PrivCirNet，一种基于块循环变换的协议/网络联合优化框架，用于提升同态加密 (HE) 下的深度神经网络 (DNN) 推理效率。通过将 DNN 权重转换为循环矩阵，将矩阵-向量乘法转化为 1D 卷积，从而大幅减少 HE 计算成本。在协议层面，PrivCirNet 自定义 HE 编码算法以兼容块循环变换，并按块大小比例降低延迟；在网络层面，使用基于二阶信息的层级块大小分配和层融合进一步优化推理性能。实验结果显示，与 Bolt 和 SpENCNN 相比，PrivCirNet 在 ResNet-18 和 ViT on Tiny ImageNet 上分别降低延迟 5.0× 和 1.3× 并保持等精度，或在 MobileNetV2 on ImageNet 上实现 1.7× 更低延迟和 4.2% 更高准确率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "NeurIPS'2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14569v3",
      "published_date": "2024-05-23 13:44:48 UTC",
      "updated_date": "2024-10-29 02:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:48.778567"
    },
    {
      "arxiv_id": "2405.14563v1",
      "title": "Concept Visualization: Explaining the CLIP Multi-modal Embedding Using WordNet",
      "title_zh": "翻译失败",
      "authors": [
        "Loris Giulivi",
        "Giacomo Boracchi"
      ],
      "abstract": "Advances in multi-modal embeddings, and in particular CLIP, have recently\ndriven several breakthroughs in Computer Vision (CV). CLIP has shown impressive\nperformance on a variety of tasks, yet, its inherently opaque architecture may\nhinder the application of models employing CLIP as backbone, especially in\nfields where trust and model explainability are imperative, such as in the\nmedical domain. Current explanation methodologies for CV models rely on\nSaliency Maps computed through gradient analysis or input perturbation.\nHowever, these Saliency Maps can only be computed to explain classes relevant\nto the end task, often smaller in scope than the backbone training classes. In\nthe context of models implementing CLIP as their vision backbone, a substantial\nportion of the information embedded within the learned representations is thus\nleft unexplained.\n  In this work, we propose Concept Visualization (ConVis), a novel saliency\nmethodology that explains the CLIP embedding of an image by exploiting the\nmulti-modal nature of the embeddings. ConVis makes use of lexical information\nfrom WordNet to compute task-agnostic Saliency Maps for any concept, not\nlimited to concepts the end model was trained on. We validate our use of\nWordNet via an out of distribution detection experiment, and test ConVis on an\nobject localization benchmark, showing that Concept Visualizations correctly\nidentify and localize the image's semantic content. Additionally, we perform a\nuser study demonstrating that our methodology can give users insight on the\nmodel's functioning.",
      "tldr_zh": "本研究针对CLIP多模态嵌入在计算机视觉(CV)中的不透明性问题，提出了一种新颖的解释方法Concept Visualization (ConVis)。ConVis利用WordNet的词汇信息，计算任务无关的Saliency Maps，从而解释图像在CLIP嵌入中的语义内容，而非局限于特定任务的训练类。实验通过分布外检测验证了WordNet的有效性，并在对象定位基准上证明ConVis能准确识别和定位图像语义；此外，用户研究显示该方法提升了用户对模型功能的理解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at IJCNN 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14563v1",
      "published_date": "2024-05-23 13:41:17 UTC",
      "updated_date": "2024-05-23 13:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:01:59.275944"
    },
    {
      "arxiv_id": "2405.14555v4",
      "title": "Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Kumar",
        "Sarfaroz Yunusov",
        "Ali Emami"
      ],
      "abstract": "Research on Large Language Models (LLMs) has often neglected subtle biases\nthat, although less apparent, can significantly influence the models' outputs\ntoward particular social narratives. This study addresses two such biases\nwithin LLMs: representative bias, which denotes a tendency of LLMs to generate\noutputs that mirror the experiences of certain identity groups, and affinity\nbias, reflecting the models' evaluative preferences for specific narratives or\nviewpoints. We introduce two novel metrics to measure these biases: the\nRepresentative Bias Score (RBS) and the Affinity Bias Score (ABS), and present\nthe Creativity-Oriented Generation Suite (CoGS), a collection of open-ended\ntasks such as short story writing and poetry composition, designed with\ncustomized rubrics to detect these subtle biases. Our analysis uncovers marked\nrepresentative biases in prominent LLMs, with a preference for identities\nassociated with being white, straight, and men. Furthermore, our investigation\nof affinity bias reveals distinctive evaluative patterns within each model,\nakin to `bias fingerprints'. This trend is also seen in human evaluators,\nhighlighting a complex interplay between human and machine bias perceptions.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 中的微妙偏差，包括代表性偏差 (representative bias) 和亲和力偏差 (affinity bias)，这些偏差可能导致输出偏向特定社会叙事。研究者引入了两个新指标：Representative Bias Score (RBS) 和 Affinity Bias Score (ABS)，并开发了 Creativity-Oriented Generation Suite (CoGS)，一个包含短故事写作和诗歌创作等开放式任务的套件，用自定义评估标准检测这些偏差。分析结果显示，知名 LLMs 表现出明显的代表性偏差，偏好白人、直男等身份，同时每个模型的亲和力偏差呈现独特“偏差指纹”，并揭示了人类评估者与机器偏差之间的复杂互动。这些发现为评估和缓解 LLMs 中的微妙偏差提供了重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.14555v4",
      "published_date": "2024-05-23 13:35:34 UTC",
      "updated_date": "2024-06-03 16:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:02:11.800151"
    },
    {
      "arxiv_id": "2405.14554v2",
      "title": "SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge",
      "title_zh": "SearchLVLMs：一种通过搜索最新互联网知识增强大视觉语言模型的即插即用框架",
      "authors": [
        "Chuanhao Li",
        "Zhen Li",
        "Chenchen Jing",
        "Shuo Liu",
        "Wenqi Shao",
        "Yuwei Wu",
        "Ping Luo",
        "Yu Qiao",
        "Kaipeng Zhang"
      ],
      "abstract": "Large vision-language models (LVLMs) are ignorant of the up-to-date\nknowledge, such as LLaVA series, because they cannot be updated frequently due\nto the large amount of resources required, and therefore fail in many cases.\nFor example, if a LVLM was released on January 2024, and it wouldn't know the\nsinger of the theme song for the new Detective Conan movie, which wasn't\nreleased until April 2024. To solve the problem, a promising solution motivated\nby retrieval-augmented generation (RAG) is to provide LVLMs with up-to-date\nknowledge via internet search during inference, i.e., internet-augmented\ngeneration (IAG), which is already integrated in some closed-source commercial\nLVLMs such as GPT-4V. However, the specific mechanics underpinning them remain\na mystery. In this paper, we propose a plug-and-play framework, for augmenting\nexisting LVLMs in handling visual question answering (VQA) about up-to-date\nknowledge, dubbed SearchLVLMs. A hierarchical filtering model is trained to\neffectively and efficiently find the most helpful content from the websites\nreturned by a search engine to prompt LVLMs with up-to-date knowledge. To train\nthe model and evaluate our framework's performance, we propose a pipeline to\nautomatically generate news-related VQA samples to construct a dataset, dubbed\nUDK-VQA. A multi-model voting mechanism is introduced to label the usefulness\nof website/content for VQA samples to construct the training set. Experimental\nresults demonstrate the effectiveness of our framework, outperforming GPT-4V by\nabout 25% in accuracy.",
      "tldr_zh": "该论文针对 Large Vision-Language Models (LVLMs) 无法获取最新知识的问题，提出了一种即插即用框架 SearchLVLMs，通过 internet-augmented generation (IAG) 技术利用互联网搜索增强模型性能。框架的核心是训练一个 hierarchical filtering model，从搜索引擎返回的网站中筛选最相关内容，以辅助视觉问答 (VQA) 任务。研究者构建了 UDK-VQA 数据集，通过自动生成新闻相关 VQA 样本和 multi-model voting mechanism 进行标注。实验结果显示，该框架的准确率比 GPT-4V 提高了约 25%，证明了其在处理最新知识方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 6 figures, a plug-and-play framework to augment large\n  vision-language models with up-to-date internet knowledge",
      "pdf_url": "http://arxiv.org/pdf/2405.14554v2",
      "published_date": "2024-05-23 13:32:07 UTC",
      "updated_date": "2024-08-20 09:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:02:25.840789"
    },
    {
      "arxiv_id": "2405.14547v2",
      "title": "Causal Effect Identification in a Sub-Population with Latent Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Mohammad Abouei",
        "Ehsan Mokhtarian",
        "Negar Kiyavash",
        "Matthias Grossglauser"
      ],
      "abstract": "The s-ID problem seeks to compute a causal effect in a specific\nsub-population from the observational data pertaining to the same sub\npopulation (Abouei et al., 2023). This problem has been addressed when all the\nvariables in the system are observable. In this paper, we consider an extension\nof the s-ID problem that allows for the presence of latent variables. To tackle\nthe challenges induced by the presence of latent variables in a sub-population,\nwe first extend the classical relevant graphical definitions, such as\nc-components and Hedges, initially defined for the so-called ID problem (Pearl,\n1995; Tian & Pearl, 2002), to their new counterparts. Subsequently, we propose\na sound algorithm for the s-ID problem with latent variables.",
      "tldr_zh": "本论文扩展了s-ID问题，旨在从特定子群体的观察数据中识别因果效应，同时处理系统中存在的潜在变量(latent variables)。作者首先扩展了经典图形定义，如c-components和Hedges，以适应这一新情境。随后，提出了一种可靠的(sound)算法来解决s-ID问题中的潜在变量挑战，为因果效应识别提供了更全面的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14547v2",
      "published_date": "2024-05-23 13:25:41 UTC",
      "updated_date": "2024-10-29 11:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:02:35.006213"
    },
    {
      "arxiv_id": "2405.14536v1",
      "title": "Regressor-free Molecule Generation to Support Drug Response Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Li",
        "Xiuwen Gong",
        "Shirui Pan",
        "Jia Wu",
        "Bo Du",
        "Wenbin Hu"
      ],
      "abstract": "Drug response prediction (DRP) is a crucial phase in drug discovery, and the\nmost important metric for its evaluation is the IC50 score. DRP results are\nheavily dependent on the quality of the generated molecules. Existing molecule\ngeneration methods typically employ classifier-based guidance, enabling\nsampling within the IC50 classification range. However, these methods fail to\nensure the sampling space range's effectiveness, generating numerous\nineffective molecules. Through experimental and theoretical study, we\nhypothesize that conditional generation based on the target IC50 score can\nobtain a more effective sampling space. As a result, we introduce\nregressor-free guidance molecule generation to ensure sampling within a more\neffective space and support DRP. Regressor-free guidance combines a diffusion\nmodel's score estimation with a regression controller model's gradient based on\nnumber labels. To effectively map regression labels between drugs and cell\nlines, we design a common-sense numerical knowledge graph that constrains the\norder of text representations. Experimental results on the real-world dataset\nfor the DRP task demonstrate our method's effectiveness in drug discovery. The\ncode is available at:https://anonymous.4open.science/r/RMCD-DBD1.",
      "tldr_zh": "本研究针对药物反应预测（DRP）中的分子生成问题，指出现有基于分类器指导的方法常产生无效分子，因为无法确保有效的采样空间。论文提出 regressor-free guidance 技术，通过结合 diffusion model's score estimation 和 regression controller model's gradient，实现基于目标 IC50 分数的条件生成，并设计 common-sense numerical knowledge graph 来约束药物和细胞系之间回归标签的映射顺序。实验结果在真实世界数据集上验证了该方法的有效性，提高了分子生成的质量，并为药物发现提供了支持。",
      "categories": [
        "q-bio.MN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.MN",
      "comment": "22 pages, 7 figures, 9 tables,",
      "pdf_url": "http://arxiv.org/pdf/2405.14536v1",
      "published_date": "2024-05-23 13:22:17 UTC",
      "updated_date": "2024-05-23 13:22:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:02:47.007954"
    },
    {
      "arxiv_id": "2405.14535v1",
      "title": "Exploring Alignment in Shared Cross-lingual Spaces",
      "title_zh": "探索共享跨语言空间中的对齐",
      "authors": [
        "Basel Mousi",
        "Nadir Durrani",
        "Fahim Dalvi",
        "Majd Hawasly",
        "Ahmed Abdelali"
      ],
      "abstract": "Despite their remarkable ability to capture linguistic nuances across diverse\nlanguages, questions persist regarding the degree of alignment between\nlanguages in multilingual embeddings. Drawing inspiration from research on\nhigh-dimensional representations in neural language models, we employ\nclustering to uncover latent concepts within multilingual models. Our analysis\nfocuses on quantifying the \\textit{alignment} and \\textit{overlap} of these\nconcepts across various languages within the latent space. To this end, we\nintroduce two metrics \\CA{} and \\CO{} aimed at quantifying these aspects,\nenabling a deeper exploration of multilingual embeddings. Our study encompasses\nthree multilingual models (\\texttt{mT5}, \\texttt{mBERT}, and \\texttt{XLM-R})\nand three downstream tasks (Machine Translation, Named Entity Recognition, and\nSentiment Analysis). Key findings from our analysis include: i) deeper layers\nin the network demonstrate increased cross-lingual \\textit{alignment} due to\nthe presence of language-agnostic concepts, ii) fine-tuning of the models\nenhances \\textit{alignment} within the latent space, and iii) such\ntask-specific calibration helps in explaining the emergence of zero-shot\ncapabilities in the models.\\footnote{The code is available at\n\\url{https://github.com/baselmousi/multilingual-latent-concepts}}",
      "tldr_zh": "这篇论文探讨了多语言嵌入中不同语言之间的对齐（alignment）和重叠（overlap），通过聚类方法发现潜在概念，并引入了 CA 和 CO 指标来量化这些方面。研究分析了 mT5、mBERT 和 XLM-R 等三个多语言模型在 Machine Translation、Named Entity Recognition 和 Sentiment Analysis 等下游任务上的表现。关键发现包括：网络更深层显示出更高的跨语言对齐，由于存在语言无关的概念；微调模型能增强潜在空间的对齐；这种任务特定校准有助于解释模型的零样本（zero-shot）能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14535v1",
      "published_date": "2024-05-23 13:20:24 UTC",
      "updated_date": "2024-05-23 13:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:03:01.724760"
    },
    {
      "arxiv_id": "2405.14527v2",
      "title": "ArchesWeather: An efficient AI weather forecasting model at 1.5° resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Guillaume Couairon",
        "Christian Lessig",
        "Anastase Charantonis",
        "Claire Monteleoni"
      ],
      "abstract": "One of the guiding principles for designing AI-based weather forecasting\nsystems is to embed physical constraints as inductive priors in the neural\nnetwork architecture. A popular prior is locality, where the atmospheric data\nis processed with local neural interactions, like 3D convolutions or 3D local\nattention windows as in Pangu-Weather. On the other hand, some works have shown\ngreat success in weather forecasting without this locality principle, at the\ncost of a much higher parameter count. In this paper, we show that the 3D local\nprocessing in Pangu-Weather is computationally sub-optimal. We design\nArchesWeather, a transformer model that combines 2D attention with a\ncolumn-wise attention-based feature interaction module, and demonstrate that\nthis design improves forecasting skill.\n  ArchesWeather is trained at 1.5{\\deg} resolution and 24h lead time, with a\ntraining budget of a few GPU-days and a lower inference cost than competing\nmethods. An ensemble of four of our models shows better RMSE scores than the\nIFS HRES and is competitive with the 1.4{\\deg} 50-members NeuralGCM ensemble\nfor one to three days ahead forecasting. Our code and models are publicly\navailable at https://github.com/gcouairon/ArchesWeather.",
      "tldr_zh": "这篇论文提出 ArchesWeather，一种高效的 AI 天气预报模型，在 1.5° 分辨率下运作，通过结合 2D attention 和 column-wise attention-based feature interaction module，优化了传统 3D 局部处理的计算效率。相比 Pangu-Weather 等方法，该设计减少了参数数量并提升了预测性能。ArchesWeather 使用少量 GPU 天训练，并在推理成本上更低，其四个模型集成在 RMSE 分数上优于 IFS HRES，并在 1-3 天预测中与 NeuralGCM 竞争。代码和模型已在 GitHub 上公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Machine Learning for Earth System Modeling Workshop\n  at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14527v2",
      "published_date": "2024-05-23 13:11:49 UTC",
      "updated_date": "2024-07-03 12:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:03:12.198930"
    },
    {
      "arxiv_id": "2405.14522v1",
      "title": "Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property",
      "title_zh": "翻译失败",
      "authors": [
        "Yuya Yoshikawa",
        "Masanari Kimura",
        "Ryotaro Shimizu",
        "Yuki Saito"
      ],
      "abstract": "Techniques that explain the predictions of black-box machine learning models\nare crucial to make the models transparent, thereby increasing trust in AI\nsystems. The input features to the models often have a nested structure that\nconsists of high- and low-level features, and each high-level feature is\ndecomposed into multiple low-level features. For such inputs, both high-level\nfeature attributions (HiFAs) and low-level feature attributions (LoFAs) are\nimportant for better understanding the model's decision. In this paper, we\npropose a model-agnostic local explanation method that effectively exploits the\nnested structure of the input to estimate the two-level feature attributions\nsimultaneously. A key idea of the proposed method is to introduce the\nconsistency property that should exist between the HiFAs and LoFAs, thereby\nbridging the separate optimization problems for estimating them. Thanks to this\nconsistency property, the proposed method can produce HiFAs and LoFAs that are\nboth faithful to the black-box models and consistent with each other, using a\nsmaller number of queries to the models. In experiments on image classification\nin multiple instance learning and text classification using language models, we\ndemonstrate that the HiFAs and LoFAs estimated by the proposed method are\naccurate, faithful to the behaviors of the black-box models, and provide\nconsistent explanations.",
      "tldr_zh": "该论文提出了一种模型无关的局部解释方法，用于解释黑-box model 的预测，该方法通过同时估计 high-level feature attributions (HiFAs) 和 low-level feature attributions (LoFAs) 来处理输入特征的嵌套结构。关键创新是引入 consistency property，将 HiFAs 和 LoFAs 的优化问题桥接起来，从而生成相互一致且忠实于模型行为的归因，同时减少对模型的查询次数。在图像分类（多实例学习）和文本分类（语言模型）的实验中，该方法证明了其准确性和解释一致性，提高了对 AI 系统的透明度和信任。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14522v1",
      "published_date": "2024-05-23 13:03:26 UTC",
      "updated_date": "2024-05-23 13:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:03:23.483072"
    },
    {
      "arxiv_id": "2405.14516v1",
      "title": "Towards Realistic Long-tailed Semi-supervised Learning in an Open World",
      "title_zh": "面向开放世界的现实长尾半监督学习",
      "authors": [
        "Yuanpeng He",
        "Lijian Li"
      ],
      "abstract": "Open-world long-tailed semi-supervised learning (OLSSL) has increasingly\nattracted attention. However, existing OLSSL algorithms generally assume that\nthe distributions between known and novel categories are nearly identical.\nAgainst this backdrop, we construct a more \\emph{Realistic Open-world\nLong-tailed Semi-supervised Learning} (\\textbf{ROLSSL}) setting where there is\nno premise on the distribution relationships between known and novel\ncategories. Furthermore, even within the known categories, the number of\nlabeled samples is significantly smaller than that of the unlabeled samples, as\nacquiring valid annotations is often prohibitively costly in the real world.\nUnder the proposed ROLSSL setting, we propose a simple yet potentially\neffective solution called dual-stage post-hoc logit adjustments. The proposed\napproach revisits the logit adjustment strategy by considering the\nrelationships among the frequency of samples, the total number of categories,\nand the overall size of data. Then, it estimates the distribution of unlabeled\ndata for both known and novel categories to dynamically readjust the\ncorresponding predictive probabilities, effectively mitigating category bias\nduring the learning of known and novel classes with more selective utilization\nof imbalanced unlabeled data. Extensive experiments on datasets such as\nCIFAR100 and ImageNet100 have demonstrated performance improvements of up to\n50.1\\%, validating the superiority of our proposed method and establishing a\nstrong baseline for this task. For further researches, the anonymous link to\nthe experimental code is at\n\\href{https://github.com/heyuanpengpku/ROLSSL}{\\textcolor{brightpink}{https://github.com/heyuanpengpku/ROLSSL}}",
      "tldr_zh": "本研究针对开放世界长尾半监督学习（OLSSL），提出了一种更现实的设置——Realistic Open-world Long-tailed Semi-supervised Learning（ROLSSL），其中已知和新型类别分布无前提，且已知类别的标注样本远少于未标注样本。作者引入了双阶段后验 logit 调整方法，该方法通过考虑样本频率、类别总数和数据规模，估计未标注数据的分布，并动态调整预测概率，以缓解类别偏差并更 selective 地利用不平衡的未标注数据。实验在 CIFAR100 和 ImageNet100 数据集上显示，该方法性能提升高达 50.1%，为该任务建立了强有力的基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14516v1",
      "published_date": "2024-05-23 12:53:50 UTC",
      "updated_date": "2024-05-23 12:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:03:34.554065"
    },
    {
      "arxiv_id": "2405.14506v1",
      "title": "SIAVC: Semi-Supervised Framework for Industrial Accident Video Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Zuoyong Li",
        "Qinghua Lin",
        "Haoyi Fan",
        "Tiesong Zhao",
        "David Zhang"
      ],
      "abstract": "Semi-supervised learning suffers from the imbalance of labeled and unlabeled\ntraining data in the video surveillance scenario. In this paper, we propose a\nnew semi-supervised learning method called SIAVC for industrial accident video\nclassification. Specifically, we design a video augmentation module called the\nSuper Augmentation Block (SAB). SAB adds Gaussian noise and randomly masks\nvideo frames according to historical loss on the unlabeled data for model\noptimization. Then, we propose a Video Cross-set Augmentation Module (VCAM) to\ngenerate diverse pseudo-label samples from the high-confidence unlabeled\nsamples, which alleviates the mismatch of sampling experience and provides\nhigh-quality training data. Additionally, we construct a new industrial\naccident surveillance video dataset with frame-level annotation, namely ECA9,\nto evaluate our proposed method. Compared with the state-of-the-art\nsemi-supervised learning based methods, SIAVC demonstrates outstanding video\nclassification performance, achieving 88.76\\% and 89.13\\% accuracy on ECA9 and\nFire Detection datasets, respectively. The source code and the constructed\ndataset ECA9 will be released in \\url{https://github.com/AlchemyEmperor/SIAVC}.",
      "tldr_zh": "本研究提出了一种半监督学习框架 SIAVC，用于工业事故视频分类，以解决标注数据不平衡问题。具体来说，SIAVC 包括 Super Augmentation Block (SAB)，通过添加高斯噪声和基于历史损失的随机帧掩盖来优化未标注数据；以及 Video Cross-set Augmentation Module (VCAM)，用于从高置信度未标注样本生成多样化伪标签样本，提高训练数据质量。该框架还构建了一个新的工业事故监控视频数据集 ECA9，提供帧级标注用于评估。在 ECA9 和 Fire Detection 数据集上，SIAVC 分别实现了 88.76% 和 89.13% 的准确率，优于现有半监督学习方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14506v1",
      "published_date": "2024-05-23 12:44:51 UTC",
      "updated_date": "2024-05-23 12:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:03:47.505757"
    },
    {
      "arxiv_id": "2405.14505v1",
      "title": "Explainable automatic industrial carbon footprint estimation from bank transaction classification using natural language processing",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime González-González",
        "Silvia García-Méndez",
        "Francisco de Arriba-Pérez",
        "Francisco J. González-Castaño",
        "Óscar Barba-Seara"
      ],
      "abstract": "Concerns about the effect of greenhouse gases have motivated the development\nof certification protocols to quantify the industrial carbon footprint (CF).\nThese protocols are manual, work-intensive, and expensive. All of the above\nhave led to a shift towards automatic data-driven approaches to estimate the\nCF, including Machine Learning (ML) solutions. Unfortunately, the\ndecision-making processes involved in these solutions lack transparency from\nthe end user's point of view, who must blindly trust their outcomes compared to\nintelligible traditional manual approaches. In this research, manual and\nautomatic methodologies for CF estimation were reviewed, taking into account\ntheir transparency limitations. This analysis led to the proposal of a new\nexplainable ML solution for automatic CF calculations through bank transaction\nclassification. Consideration should be given to the fact that no previous\nresearch has considered the explainability of bank transaction classification\nfor this purpose. For classification, different ML models have been employed\nbased on their promising performance in the literature, such as Support Vector\nMachine, Random Forest, and Recursive Neural Networks. The results obtained\nwere in the 90 % range for accuracy, precision, and recall evaluation metrics.\nFrom their decision paths, the proposed solution estimates the CO2 emissions\nassociated with bank transactions. The explainability methodology is based on\nan agnostic evaluation of the influence of the input terms extracted from the\ndescriptions of transactions using locally interpretable models. The\nexplainability terms were automatically validated using a similarity metric\nover the descriptions of the target categories. Conclusively, the explanation\nperformance is satisfactory in terms of the proximity of the explanations to\nthe associated activity sector descriptions.",
      "tldr_zh": "这篇论文针对工业碳足迹(CF)估算的传统手动方法耗时且缺乏透明度，提出了一种可解释的自动ML解决方案，通过自然语言处理对银行交易进行分类。方法采用Support Vector Machine、Random Forest和Recursive Neural Networks等模型进行分类，准确率、精确度和召回率均超过90%。该方案从模型的决策路径估算银行交易相关的CO2排放，并使用局部可解释模型分析输入术语的影响，以提升透明度。最终，通过相似性指标验证，解释性能良好，与相关活动部门描述高度一致。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14505v1",
      "published_date": "2024-05-23 12:43:06 UTC",
      "updated_date": "2024-05-23 12:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:00.709055"
    },
    {
      "arxiv_id": "2405.14504v1",
      "title": "Enhanced Spatiotemporal Prediction Using Physical-guided And Frequency-enhanced Recurrent Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanle Zhao",
        "Yue Sun",
        "Tielin Zhang",
        "Bo Xu"
      ],
      "abstract": "Spatiotemporal prediction plays an important role in solving natural problems\nand processing video frames, especially in weather forecasting and human action\nrecognition. Recent advances attempt to incorporate prior physical knowledge\ninto the deep learning framework to estimate the unknown governing partial\ndifferential equations (PDEs), which have shown promising results in\nspatiotemporal prediction tasks. However, previous approaches only restrict\nneural network architectures or loss functions to acquire physical or PDE\nfeatures, which decreases the representative capacity of a neural network.\nMeanwhile, the updating process of the physical state cannot be effectively\nestimated. To solve the above mentioned problems, this paper proposes a\nphysical-guided neural network, which utilizes the frequency-enhanced Fourier\nmodule and moment loss to strengthen the model's ability to estimate the\nspatiotemporal dynamics. Furthermore, we propose an adaptive second-order\nRunge-Kutta method with physical constraints to model the physical states more\nprecisely. We evaluate our model on both spatiotemporal and video prediction\ntasks. The experimental results show that our model outperforms\nstate-of-the-art methods and performs best in several datasets, with a much\nsmaller parameter count.",
      "tldr_zh": "本文提出了一种增强的时空预测（Spatiotemporal Prediction）方法，使用物理引导和频率增强的循环神经网络（Recurrent Neural Networks），以解决现有模型在估计未知偏微分方程（PDEs）时存在的代表能力不足和物理状态更新不精确的问题。关键创新包括引入频率增强的Fourier模块和moment loss来提升模型对时空动态的估计能力，以及采用自适应二阶Runge-Kutta方法结合物理约束来更精确地建模物理状态。在实验中，该模型在时空和视频预测任务上超越了最先进方法，在多个数据集上表现最佳，同时参数量显著减少。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14504v1",
      "published_date": "2024-05-23 12:39:49 UTC",
      "updated_date": "2024-05-23 12:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:12.051734"
    },
    {
      "arxiv_id": "2405.14489v1",
      "title": "End-to-End User-Defined Keyword Spotting using Shifted Delta Coefficients",
      "title_zh": "翻译失败",
      "authors": [
        "Kesavaraj V",
        "Anuprabha M",
        "Anil Kumar Vuppala"
      ],
      "abstract": "Identifying user-defined keywords is crucial for personalizing interactions\nwith smart devices. Previous approaches of user-defined keyword spotting\n(UDKWS) have relied on short-term spectral features such as mel frequency\ncepstral coefficients (MFCC) to detect the spoken keyword. However, these\nfeatures may face challenges in accurately identifying closely related\npronunciation of audio-text pairs, due to their limited capability in capturing\nthe temporal dynamics of the speech signal. To address this challenge, we\npropose to use shifted delta coefficients (SDC) which help in capturing\npronunciation variability (transition between connecting phonemes) by\nincorporating long-term temporal information. The performance of the SDC\nfeature is compared with various baseline features across four different\ndatasets using a cross-attention based end-to-end system. Additionally, various\nconfigurations of SDC are explored to find the suitable temporal context for\nthe UDKWS task. The experimental results reveal that the SDC feature\noutperforms the MFCC baseline feature, exhibiting an improvement of 8.32% in\narea under the curve (AUC) and 8.69% in terms of equal error rate (EER) on the\nchallenging Libriphrase-hard dataset. Moreover, the proposed approach\ndemonstrated superior performance when compared to state-of-the-art UDKWS\ntechniques.",
      "tldr_zh": "本研究针对用户定义关键词识别（UDKWS）的问题，提出使用 Shifted Delta Coefficients (SDC) 作为特征提取方法，以捕捉语音信号的长期时序动态（如音素过渡），从而改善传统 Mel Frequency Cepstral Coefficients (MFCC) 在处理发音相似音频-文本对时的局限性。研究采用基于交叉注意力的端到端系统，在四个数据集上比较了 SDC 与基线特征的性能，并探索了不同 SDC 配置以优化时序上下文。实验结果显示，SDC 在 Libriphrase-hard 数据集上比 MFCC 基准提高了 8.32% 的 AUC 和 8.69% 的 EER，且整体表现优于现有最先进技术，为个性化智能设备交互提供了更准确的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14489v1",
      "published_date": "2024-05-23 12:24:01 UTC",
      "updated_date": "2024-05-23 12:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:23.620550"
    },
    {
      "arxiv_id": "2405.14478v3",
      "title": "SLIFER: Investigating Performance and Robustness of Malware Detection Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Ponte",
        "Dmitrijs Trizna",
        "Luca Demetrio",
        "Battista Biggio",
        "Ivan Tesfai Ogbu",
        "Fabio Roli"
      ],
      "abstract": "As a result of decades of research, Windows malware detection is approached\nthrough a plethora of techniques. However, there is an ongoing mismatch between\nacademia -- which pursues an optimal performances in terms of detection rate\nand low false alarms -- and the requirements of real-world scenarios. In\nparticular, academia focuses on combining static and dynamic analysis within a\nsingle or ensemble of models, falling into several pitfalls like (i) firing\ndynamic analysis without considering the computational burden it requires; (ii)\ndiscarding impossible-to-analyze samples; and (iii) analyzing robustness\nagainst adversarial attacks without considering that malware detectors are\ncomplemented with more non-machine-learning components. Thus, in this paper we\nbridge these gaps, by investigating the properties of malware detectors built\nwith multiple and different types of analysis. To do so, we develop SLIFER, a\nWindows malware detection pipeline sequentially leveraging both static and\ndynamic analysis, interrupting computations as soon as one module triggers an\nalarm, requiring dynamic analysis only when needed. Contrary to the state of\nthe art, we investigate how to deal with samples that impede analyzes, showing\nhow much they impact performances, concluding that it is better to flag them as\nlegitimate to not drastically increase false alarms. Lastly, we perform a\nrobustness evaluation of SLIFER. Counter-intuitively, the injection of new\ncontent is either blocked more by signatures than dynamic analysis, due to byte\nartifacts created by the attack, or it is able to avoid detection from\nsignatures, as they rely on constraints on file size disrupted by attacks. As\nfar as we know, we are the first to investigate the properties of sequential\nmalware detectors, shedding light on their behavior in real production\nenvironment.",
      "tldr_zh": "本研究调查了 Windows 恶意软件检测管道的性能和鲁棒性，指出学术界在追求高检测率和低误报率时忽略了实际场景中的计算负担、无法分析样本的处理以及对抗攻击的影响。论文开发了 SLIFER，一种顺序结合 static analysis 和 dynamic analysis 的检测框架，仅在必要时触发动态分析以优化效率，并通过中断计算来减少资源消耗。实验结果显示，对于无法分析的样本，将其标记为合法软件可避免大幅增加误报率；此外，鲁棒性评估发现，注入新内容的攻击更可能被签名检测阻挡或避开检测，由于攻击会破坏文件大小约束。作为首次针对 sequential malware detectors 的系统研究，该工作揭示了这些检测器在真实生产环境中的行为，为实际应用提供了重要洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14478v3",
      "published_date": "2024-05-23 12:06:10 UTC",
      "updated_date": "2024-12-19 13:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:35.637178"
    },
    {
      "arxiv_id": "2405.14475v3",
      "title": "MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyuan Gao",
        "Kai Chen",
        "Zhihao Li",
        "Lanqing Hong",
        "Zhenguo Li",
        "Qiang Xu"
      ],
      "abstract": "While controllable generative models for images and videos have achieved\nremarkable success, high-quality models for 3D scenes, particularly in\nunbounded scenarios like autonomous driving, remain underdeveloped due to high\ndata acquisition costs. In this paper, we introduce MagicDrive3D, a novel\npipeline for controllable 3D street scene generation that supports\nmulti-condition control, including BEV maps, 3D objects, and text descriptions.\nUnlike previous methods that reconstruct before training the generative models,\nMagicDrive3D first trains a video generation model and then reconstructs from\nthe generated data. This innovative approach enables easily controllable\ngeneration and static scene acquisition, resulting in high-quality scene\nreconstruction. To address the minor errors in generated content, we propose\ndeformable Gaussian splatting with monocular depth initialization and\nappearance modeling to manage exposure discrepancies across viewpoints.\nValidated on the nuScenes dataset, MagicDrive3D generates diverse, high-quality\n3D driving scenes that support any-view rendering and enhance downstream tasks\nlike BEV segmentation. Our results demonstrate the framework's superior\nperformance, showcasing its potential for autonomous driving simulation and\nbeyond.",
      "tldr_zh": "该研究提出MagicDrive3D，一种可控的3D街景生成框架，支持多条件控制（如BEV maps、3D objects和文本描述），以解决高数据获取成本导致的3D场景生成不足问题。不同于先重建再训练的传统方法，MagicDrive3D先训练视频生成模型，然后从生成数据中进行重建，并采用deformable Gaussian splatting结合单目深度初始化和外观建模来修正生成错误和视角差异。在nuScenes数据集上验证，该框架生成多样、高质量的3D驾驶场景，支持任意视角渲染，并显著提升下游任务如BEV segmentation的表现，具有潜力应用于自动驾驶模拟。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://flymin.github.io/magicdrive3d",
      "pdf_url": "http://arxiv.org/pdf/2405.14475v3",
      "published_date": "2024-05-23 12:04:51 UTC",
      "updated_date": "2024-11-20 10:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:48.644149"
    },
    {
      "arxiv_id": "2405.14473v2",
      "title": "Poisson Variational Autoencoder",
      "title_zh": "泊松变分自动编码器",
      "authors": [
        "Hadi Vafaii",
        "Dekel Galor",
        "Jacob L. Yates"
      ],
      "abstract": "Variational autoencoders (VAEs) employ Bayesian inference to interpret\nsensory inputs, mirroring processes that occur in primate vision across both\nventral (Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways.\nDespite their success, traditional VAEs rely on continuous latent variables,\nwhich deviates sharply from the discrete nature of biological neurons. Here, we\ndeveloped the Poisson VAE (P-VAE), a novel architecture that combines\nprinciples of predictive coding with a VAE that encodes inputs into discrete\nspike counts. Combining Poisson-distributed latent variables with predictive\ncoding introduces a metabolic cost term in the model loss function, suggesting\na relationship with sparse coding which we verify empirically. Additionally, we\nanalyze the geometry of learned representations, contrasting the P-VAE to\nalternative VAE models. We find that the P-VAE encodes its inputs in relatively\nhigher dimensions, facilitating linear separability of categories in a\ndownstream classification task with a much better (5x) sample efficiency. Our\nwork provides an interpretable computational framework to study brain-like\nsensory processing and paves the way for a deeper understanding of perception\nas an inferential process.",
      "tldr_zh": "本研究开发了Poisson Variational Autoencoder (P-VAE)，一种新型架构，将预测编码原则与VAEs结合，使用离散的泊松分布潜变量来模拟生物神经元的特性，从而解决传统VAEs依赖连续潜变量的局限。P-VAE在损失函数中引入代谢成本项，与稀疏编码相关联，并通过分析表示几何发现其在更高维度编码输入，提升了下游分类任务的线性可分性。实验结果显示，P-VAE的样本效率提高了5倍，为研究脑-like感官处理和感知作为推理过程的计算框架提供了可解释的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a NeurIPS 2024 Spotlight paper\n  (https://openreview.net/forum?id=ektPEcqGLb)",
      "pdf_url": "http://arxiv.org/pdf/2405.14473v2",
      "published_date": "2024-05-23 12:02:54 UTC",
      "updated_date": "2024-12-09 00:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:04:59.706735"
    },
    {
      "arxiv_id": "2405.14467v1",
      "title": "Segformer++: Efficient Token-Merging Strategies for High-Resolution Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Kienzle",
        "Marco Kantonis",
        "Robin Schön",
        "Rainer Lienhart"
      ],
      "abstract": "Utilizing transformer architectures for semantic segmentation of\nhigh-resolution images is hindered by the attention's quadratic computational\ncomplexity in the number of tokens. A solution to this challenge involves\ndecreasing the number of tokens through token merging, which has exhibited\nremarkable enhancements in inference speed, training efficiency, and memory\nutilization for image classification tasks. In this paper, we explore various\ntoken merging strategies within the framework of the Segformer architecture and\nperform experiments on multiple semantic segmentation and human pose estimation\ndatasets. Notably, without model re-training, we, for example, achieve an\ninference acceleration of 61% on the Cityscapes dataset while maintaining the\nmIoU performance. Consequently, this paper facilitates the deployment of\ntransformer-based architectures on resource-constrained devices and in\nreal-time applications.",
      "tldr_zh": "该论文提出Segformer++，一种高效的token merging策略，用于解决Transformer架构在高分辨率语义分割中的计算复杂度问题。通过减少token数量，该方法显著提升推理速度、训练效率和内存利用。实验在多个语义分割和人体姿势估计数据集上显示，例如在Cityscapes数据集上，无需重新训练即可实现61%的推理加速，同时保持mIoU性能不变。该创新有助于在资源受限设备和实时应用中部署Transformer-based架构。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, to be published in IEEE International Conference on\n  Multimedia Information Processing and Retrieval (MIPR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14467v1",
      "published_date": "2024-05-23 11:54:27 UTC",
      "updated_date": "2024-05-23 11:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:05:11.005742"
    },
    {
      "arxiv_id": "2405.14452v2",
      "title": "JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Zheng",
        "Houqiang Zhong",
        "Qiang Hu",
        "Xiaoyun Zhang",
        "Li Song",
        "Ya Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "Neural Radiance Field (NeRF) excels in photo-realistically static scenes,\ninspiring numerous efforts to facilitate volumetric videos. However, rendering\ndynamic and long-sequence radiance fields remains challenging due to the\nsignificant data required to represent volumetric videos. In this paper, we\npropose a novel end-to-end joint optimization scheme of dynamic NeRF\nrepresentation and compression, called JointRF, thus achieving significantly\nimproved quality and compression efficiency against the previous methods.\nSpecifically, JointRF employs a compact residual feature grid and a coefficient\nfeature grid to represent the dynamic NeRF. This representation handles large\nmotions without compromising quality while concurrently diminishing temporal\nredundancy. We also introduce a sequential feature compression subnetwork to\nfurther reduce spatial-temporal redundancy. Finally, the representation and\ncompression subnetworks are end-to-end trained combined within the JointRF.\nExtensive experiments demonstrate that JointRF can achieve superior compression\nperformance across various datasets.",
      "tldr_zh": "本文提出 JointRF，一种端到端联合优化方案，用于动态 Neural Radiance Field (NeRF) 的表示和压缩，显著提升了质量和压缩效率。JointRF 采用紧凑的残差特征网格和系数特征网格来处理大运动，同时减少时间冗余，并引入顺序特征压缩子网络进一步降低空间-时间冗余。最终，通过端到端训练，实验在多个数据集上证明了 JointRF 比现有方法具有优越的压缩性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICIP2024, 8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14452v2",
      "published_date": "2024-05-23 11:32:46 UTC",
      "updated_date": "2024-06-08 06:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:05:23.779518"
    },
    {
      "arxiv_id": "2405.14446v2",
      "title": "Worldwide Federated Training of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Iacob",
        "Lorenzo Sani",
        "Bill Marino",
        "Preslav Aleksandrov",
        "William F. Shen",
        "Nicholas Donald Lane"
      ],
      "abstract": "The reliance of language model training on massive amounts of computation and\nvast datasets scraped from potentially low-quality, copyrighted, or sensitive\ndata has come into question practically, legally, and ethically. Federated\nlearning provides a plausible alternative by enabling previously untapped data\nto be voluntarily gathered from collaborating organizations. However, when\nscaled globally, federated learning requires collaboration across heterogeneous\nlegal, security, and privacy regimes while accounting for the inherent locality\nof language data; this further exacerbates the established challenge of\nfederated statistical heterogeneity. We propose a Worldwide Federated Language\nModel Training~(WorldLM) system based on federations of federations, where each\nfederation has the autonomy to account for factors such as its industry,\noperating jurisdiction, or competitive environment. WorldLM enables such\nautonomy in the presence of statistical heterogeneity via partial model\nlocalization by allowing sub-federations to attentively aggregate key layers\nfrom their constituents. Furthermore, it can adaptively share information\nacross federations via residual layer embeddings. Evaluations of language\nmodeling on naturally heterogeneous datasets show that WorldLM outperforms\nstandard federations by up to $1.91\\times$, approaches the personalized\nperformance of fully local models, and maintains these advantages under\nprivacy-enhancing techniques.",
      "tldr_zh": "本研究探讨了语言模型训练对海量计算和潜在低质量、版权或敏感数据的依赖问题，提出Federated Learning作为替代方案，通过合作组织自愿共享数据。该论文引入WorldLM系统，一种基于“federations of federations”的框架，允许每个federation根据其行业、法律或竞争环境实现自治，同时通过partial model localization和attentive aggregation处理统计异质性，并利用residual layer embeddings适应性地跨federation共享信息。在异构数据集上的实验表明，WorldLM比标准federations性能提升高达1.91倍，接近完全本地模型的个性化效果，并在隐私增强技术下保持优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 8 figures, Under Review",
      "pdf_url": "http://arxiv.org/pdf/2405.14446v2",
      "published_date": "2024-05-23 11:25:19 UTC",
      "updated_date": "2024-05-27 10:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:05:35.467821"
    },
    {
      "arxiv_id": "2405.14445v2",
      "title": "Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study",
      "title_zh": "探索使用大语言模型进行系统评价中数据提取：一个快速可行性研究",
      "authors": [
        "Lena Schmidt",
        "Kaitlyn Hair",
        "Sergio Graziosi",
        "Fiona Campbell",
        "Claudia Kapp",
        "Alireza Khanteymoori",
        "Dawn Craig",
        "Mark Engelbert",
        "James Thomas"
      ],
      "abstract": "This paper describes a rapid feasibility study of using GPT-4, a large\nlanguage model (LLM), to (semi)automate data extraction in systematic reviews.\nDespite the recent surge of interest in LLMs there is still a lack of\nunderstanding of how to design LLM-based automation tools and how to robustly\nevaluate their performance. During the 2023 Evidence Synthesis Hackathon we\nconducted two feasibility studies. Firstly, to automatically extract study\ncharacteristics from human clinical, animal, and social science domain studies.\nWe used two studies from each category for prompt-development; and ten for\nevaluation. Secondly, we used the LLM to predict Participants, Interventions,\nControls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP\ndataset. Overall, results indicated an accuracy of around 80%, with some\nvariability between domains (82% for human clinical, 80% for animal, and 72%\nfor studies of human social sciences). Causal inference methods and study\ndesign were the data extraction items with the most errors. In the PICO study,\nparticipants and intervention/control showed high accuracy (>80%), outcomes\nwere more challenging. Evaluation was done manually; scoring methods such as\nBLEU and ROUGE showed limited value. We observed variability in the LLMs\npredictions and changes in response quality. This paper presents a template for\nfuture evaluations of LLMs in the context of data extraction for systematic\nreview automation. Our results show that there might be value in using LLMs,\nfor example as second or third reviewers. However, caution is advised when\nintegrating models such as GPT-4 into tools. Further research on stability and\nreliability in practical settings is warranted for each type of data that is\nprocessed by the LLM.",
      "tldr_zh": "这篇论文通过一个快速可行性研究，探讨了使用 Large Language Model (LLM) 如 GPT-4 来半自动化系统综述中的数据提取过程，包括从人类临床、动物和社会科学领域提取研究特征，以及预测 PICO (Participants, Interventions, Controls, and Outcomes) 元素。研究结果显示，整体准确率约为 80%，不同领域有所差异（人类临床 82%、动物 80%、人类社会科学 72%），但因果推断方法和研究设计等项目出错较多。论文强调手动评估比 BLEU 和 ROUGE 等自动评分更可靠，并提供了一个评估 LLM 在数据提取中的模板，建议将其用作第二或第三审阅者，但需谨慎应用并进一步研究其稳定性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Conference proceedings, peer-reviewed and presented at the 3rd\n  Workshop on Augmented Intelligence for Technology-Assisted Reviews Systems,\n  Glasgow, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14445v2",
      "published_date": "2024-05-23 11:24:23 UTC",
      "updated_date": "2025-02-13 09:07:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:05:49.649806"
    },
    {
      "arxiv_id": "2405.14436v1",
      "title": "LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract Rules",
      "title_zh": "LARS-VSA：一种用于抽象规则学习的向量符号架构",
      "authors": [
        "Mohamed Mejri",
        "Chandramouli Amarnath",
        "Abhijit Chatterjee"
      ],
      "abstract": "Human cognition excels at symbolic reasoning, deducing abstract rules from\nlimited samples. This has been explained using symbolic and connectionist\napproaches, inspiring the development of a neuro-symbolic architecture that\ncombines both paradigms. In parallel, recent studies have proposed the use of a\n\"relational bottleneck\" that separates object-level features from abstract\nrules, allowing learning from limited amounts of data . While powerful, it is\nvulnerable to the curse of compositionality meaning that object representations\nwith similar features tend to interfere with each other. In this paper, we\nleverage hyperdimensional computing, which is inherently robust to such\ninterference to build a compositional architecture. We adapt the \"relational\nbottleneck\" strategy to a high-dimensional space, incorporating explicit vector\nbinding operations between symbols and relational representations.\nAdditionally, we design a novel high-dimensional attention mechanism that\nleverages this relational representation. Our system benefits from the low\noverhead of operations in hyperdimensional space, making it significantly more\nefficient than the state of the art when evaluated on a variety of test\ndatasets, while maintaining higher or equal accuracy.",
      "tldr_zh": "该论文提出LARS-VSA，一种基于Vector Symbolic Architecture (VSA)的神经符号架构，旨在提升机器学习抽象规则的能力，同时解决传统方法在compositionality方面的干扰问题。LARS-VSA通过将relational bottleneck策略适应到hyperdimensional computing的高维空间中，引入显式向量绑定操作和新型高维注意机制，实现符号与关系表示的结合，从而从有限数据中高效学习。实验结果显示，该系统在各种测试数据集上比现有方法更高效，同时保持相等或更高的准确率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14436v1",
      "published_date": "2024-05-23 11:05:42 UTC",
      "updated_date": "2024-05-23 11:05:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:05:59.614000"
    },
    {
      "arxiv_id": "2405.14431v1",
      "title": "RaFe: Ranking Feedback Improves Query Rewriting for RAG",
      "title_zh": "RaFe：排名反馈提升 RAG 的查询重写",
      "authors": [
        "Shengyu Mao",
        "Yong Jiang",
        "Boli Chen",
        "Xiao Li",
        "Peng Wang",
        "Xinyu Wang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG)\ntechniques have evolved, query rewriting has been widely incorporated into the\nRAG system for downstream tasks like open-domain QA. Many works have attempted\nto utilize small models with reinforcement learning rather than costly LLMs to\nimprove query rewriting. However, current methods require annotations (e.g.,\nlabeled relevant documents or downstream answers) or predesigned rewards for\nfeedback, which lack generalization, and fail to utilize signals tailored for\nquery rewriting. In this paper, we propose ours, a framework for training query\nrewriting models free of annotations. By leveraging a publicly available\nreranker, ours~provides feedback aligned well with the rewriting objectives.\nExperimental results demonstrate that ours~can obtain better performance than\nbaselines.",
      "tldr_zh": "该论文提出 RaFe 框架，利用排名反馈（Ranking Feedback）来提升 Retrieval Augmentation Generation (RAG) 中的查询重写（query rewriting），避免依赖标注数据或预设计奖励。RaFe 通过整合公开可用的 reranker 提供针对查询重写的特定反馈信号，实现了无需注解的模型训练。实验结果显示，RaFe 比现有基线方法表现出更好的性能，增强了查询重写的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.14431v1",
      "published_date": "2024-05-23 11:00:19 UTC",
      "updated_date": "2024-05-23 11:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:06:10.896887"
    },
    {
      "arxiv_id": "2405.14430v3",
      "title": "PipeFusion: Patch-level Pipeline Parallelism for Diffusion Transformers Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Fang",
        "Jinzhe Pan",
        "Jiannan Wang",
        "Aoyu Li",
        "Xibo Sun"
      ],
      "abstract": "This paper presents PipeFusion, an innovative parallel methodology to tackle\nthe high latency issues associated with generating high-resolution images using\ndiffusion transformers (DiTs) models. PipeFusion partitions images into patches\nand the model layers across multiple GPUs. It employs a patch-level pipeline\nparallel strategy to orchestrate communication and computation efficiently. By\ncapitalizing on the high similarity between inputs from successive diffusion\nsteps, PipeFusion reuses one-step stale feature maps to provide context for the\ncurrent pipeline step. This approach notably reduces communication costs\ncompared to existing DiTs inference parallelism, including tensor parallel,\nsequence parallel and DistriFusion. PipeFusion also exhibits superior memory\nefficiency, because it can distribute model parameters across multiple devices,\nmaking it more suitable for DiTs with large parameter sizes, such as Flux.1.\nExperimental results demonstrate that PipeFusion achieves state-of-the-art\nperformance on 8xL40 PCIe GPUs for Pixart, Stable-Diffusion 3 and Flux.1\nmodels.Our Source code is available at https://github.com/xdit-project/xDiT.",
      "tldr_zh": "本文提出 PipeFusion，一种针对扩散变压器 (DiTs) 模型的 patch-level pipeline parallel 方法，用于解决高分辨率图像生成中的高延迟问题。该方法将图像分成 patches，并将模型层分布到多个 GPU 上，通过重用连续扩散步骤的输入相似性来提供特征映射上下文，从而显著降低通信成本并提升内存效率。相比现有方法如 tensor parallel 和 DistriFusion，PipeFusion 在实验中显示出优越性能，在 8xL40 PCIe GPUs 上为 Pixart、Stable-Diffusion 3 和 Flux.1 模型实现了最先进的结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14430v3",
      "published_date": "2024-05-23 11:00:07 UTC",
      "updated_date": "2024-10-31 05:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:06:24.587553"
    },
    {
      "arxiv_id": "2405.14422v3",
      "title": "Unraveling overoptimism and publication bias in ML-driven science",
      "title_zh": "揭示机器学习驱动科学中的过度乐观和发表偏倚",
      "authors": [
        "Pouria Saidi",
        "Gautam Dasarathy",
        "Visar Berisha"
      ],
      "abstract": "Machine Learning (ML) is increasingly used across many disciplines with\nimpressive reported results. However, recent studies suggest published\nperformance of ML models are often overoptimistic. Validity concerns are\nunderscored by findings of an inverse relationship between sample size and\nreported accuracy in published ML models, contrasting with the theory of\nlearning curves where accuracy should improve or remain stable with increasing\nsample size. This paper investigates factors contributing to overoptimism in\nML-driven science, focusing on overfitting and publication bias. We introduce a\nnovel stochastic model for observed accuracy, integrating parametric learning\ncurves and the aforementioned biases. We construct an estimator that corrects\nfor these biases in observed data. Theoretical and empirical results show that\nour framework can estimate the underlying learning curve, providing realistic\nperformance assessments from published results. Applying the model to\nmeta-analyses of classifications of neurological conditions, we estimate the\ninherent limits of ML-based prediction in each domain.",
      "tldr_zh": "本研究探讨了机器学习（ML）在科学领域的过度乐观（overoptimism）和出版偏差（publication bias），这些因素导致已发表模型性能往往被高估，例如样本大小增加时准确率反而下降，与学习曲线理论相悖。论文引入了一个新颖的随机模型，整合参数学习曲线（parametric learning curves）、过拟合（overfitting）和出版偏差，并构建了一个校正这些偏差的估计器。理论和实证结果表明，该框架能从已发表数据中估计真实的底层学习曲线，提供更现实的性能评估；最终，将模型应用于神经学条件分类的元分析，揭示了ML预测的固有限制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 7 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.14422v3",
      "published_date": "2024-05-23 10:43:20 UTC",
      "updated_date": "2024-07-11 19:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:06:36.715951"
    },
    {
      "arxiv_id": "2405.14419v3",
      "title": "A motion-based compression algorithm for resource-constrained video camera traps",
      "title_zh": "一种基于运动的压缩算法，用于资源受限的视频相机陷阱",
      "authors": [
        "Malika Nisal Ratnayake",
        "Lex Gallon",
        "Adel N. Toosi",
        "Alan Dorin"
      ],
      "abstract": "Field-captured video facilitates detailed studies of spatio-temporal aspects\nof animal locomotion, decision-making and environmental interactions including\npredator-prey relationships and habitat utilisation. But even though data\ncapture is cheap with mass-produced hardware, storage, processing and\ntransmission overheads provide a hurdle to acquisition of high resolution video\nfrom field-situated edge computing devices. Efficient compression algorithms\nare therefore essential if monitoring is to be conducted on single-board\ncomputers in situations where such hurdles must be overcome. Animal motion\ntracking in the field has unique characteristics that necessitate the use of\nnovel video compression techniques, which may be underexplored or unsuitable in\nother contexts. In this article, we therefore introduce a new motion\nanalysis-based video compression algorithm specifically designed for camera\ntraps. We implemented and tested this algorithm using a case study of\ninsect-pollinator motion tracking on three popular edge computing platforms.\nThe algorithm identifies and stores only image regions depicting motion\nrelevant to pollination monitoring, reducing overall data size by an average of\n87% across diverse test datasets. Our experiments demonstrate the algorithm's\ncapability to preserve critical information for insect behaviour analysis\nthrough both manual observation and automatic analysis of the compressed\nfootage. The method presented in this paper enhances the applicability of\nlow-powered computer vision edge devices to remote, in situ animal motion\nmonitoring, and improves the efficiency of playback during behavioural\nanalyses. Our new software, EcoMotionZip, is available Open Access.",
      "tldr_zh": "这篇论文提出了一种基于运动分析的视频压缩算法，针对资源受限的视频相机陷阱，以解决野外动物监测中存储、处理和传输的挑战。算法通过识别并仅存储与动物运动相关的图像区域（如昆虫授粉行为），在三种流行边缘计算平台上进行了测试。结果显示，该算法平均减少数据大小87%，同时保留了关键信息，支持手动观察和自动分析。开源软件EcoMotionZip的发布，进一步提升了低功耗计算机视觉设备在远程动物运动监测中的适用性和行为分析效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.14419v3",
      "published_date": "2024-05-23 10:39:33 UTC",
      "updated_date": "2024-10-02 00:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:06:49.069155"
    },
    {
      "arxiv_id": "2405.14414v1",
      "title": "Proving Theorems Recursively",
      "title_zh": "递归证明定理",
      "authors": [
        "Haiming Wang",
        "Huajian Xin",
        "Zhengying Liu",
        "Wenda Li",
        "Yinya Huang",
        "Jianqiao Lu",
        "Zhicheng Yang",
        "Jing Tang",
        "Jian Yin",
        "Zhenguo Li",
        "Xiaodan Liang"
      ],
      "abstract": "Recent advances in automated theorem proving leverages language models to\nexplore expanded search spaces by step-by-step proof generation. However, such\napproaches are usually based on short-sighted heuristics (e.g., log probability\nor value function scores) that potentially lead to suboptimal or even\ndistracting subgoals, preventing us from finding longer proofs. To address this\nchallenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves\ntheorems in a recursive, level-by-level manner in the Isabelle theorem prover.\nUnlike previous step-by-step methods, POETRY searches for a verifiable sketch\nof the proof at each level and focuses on solving the current level's theorem\nor conjecture. Detailed proofs of intermediate conjectures within the sketch\nare temporarily replaced by a placeholder tactic called sorry, deferring their\nproofs to subsequent levels. This approach allows the theorem to be tackled\nincrementally by outlining the overall theorem at the first level and then\nsolving the intermediate conjectures at deeper levels. Experiments are\nconducted on the miniF2F and PISA datasets and significant performance gains\nare observed in our POETRY approach over state-of-the-art methods. POETRY on\nminiF2F achieves an average proving success rate improvement of 5.1%. Moreover,\nwe observe a substantial increase in the maximum proof length found by POETRY,\nfrom 10 to 26.",
      "tldr_zh": "该研究针对自动定理证明中依赖短视启发式（如 log probability 或价值函数分数）可能导致次优子目标的问题，提出 POETRY（PrOvE Theorems RecursivelY）框架，在 Isabelle theorem prover 中以递归逐级方式证明定理。POETRY 通过在每个级别搜索可验证的证明草图，并使用占位符 tactic \"sorry\" 暂代中间猜想的详细证明，从而实现逐步处理整体定理。实验在 miniF2F 和 PISA 数据集上显示，POETRY 比现有方法平均提高 5.1% 的证明成功率，并将最大证明长度从 10 增加到 26。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.14414v1",
      "published_date": "2024-05-23 10:35:08 UTC",
      "updated_date": "2024-05-23 10:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:07:02.300958"
    },
    {
      "arxiv_id": "2405.14411v2",
      "title": "Large Language Models for Explainable Decisions in Dynamic Digital Twins",
      "title_zh": "大型语言模型用于动态数字孪",
      "authors": [
        "Nan Zhang",
        "Christian Vergara-Marcillo",
        "Georgios Diamantopoulos",
        "Jingran Shen",
        "Nikos Tziritas",
        "Rami Bahsoon",
        "Georgios Theodoropoulos"
      ],
      "abstract": "Dynamic data-driven Digital Twins (DDTs) can enable informed decision-making\nand provide an optimisation platform for the underlying system. By leveraging\nprinciples of Dynamic Data-Driven Applications Systems (DDDAS), DDTs can\nformulate computational modalities for feedback loops, model updates and\ndecision-making, including autonomous ones. However, understanding autonomous\ndecision-making often requires technical and domain-specific knowledge. This\npaper explores using large language models (LLMs) to provide an explainability\nplatform for DDTs, generating natural language explanations of the system's\ndecision-making by leveraging domain-specific knowledge bases. A case study\nfrom smart agriculture is presented.",
      "tldr_zh": "本论文探讨了如何利用 Large Language Models (LLMs) 为 Dynamic Digital Twins (DDTs) 提供决策解释平台，以解决自主决策所需的复杂技术和领域知识问题。通过整合 Dynamic Data-Driven Applications Systems (DDDAS) 原则，LLMs 生成自然语言解释，并结合领域特定知识库，实现对系统决策过程的清晰阐述。论文以智能农业为例，展示了这一方法在优化决策和提升系统可解释性方面的实际效果。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures, accepted by DDDAS2024 -- the 5th International\n  Conference on Dynamic Data Driven Applications Systems",
      "pdf_url": "http://arxiv.org/pdf/2405.14411v2",
      "published_date": "2024-05-23 10:32:38 UTC",
      "updated_date": "2024-09-04 06:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:07:13.096938"
    },
    {
      "arxiv_id": "2405.14909v2",
      "title": "Interpretable Price Bounds Estimation with Shape Constraints in Price Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shunnosuke Ikeda",
        "Naoki Nishimura",
        "Shunji Umetani"
      ],
      "abstract": "This study addresses the interpretable estimation of price bounds in the\ncontext of price optimization. In recent years, price-optimization methods have\nbecome indispensable for maximizing revenue and profits. However, effective\napplication of these methods to real-world pricing operations remains a\nsignificant challenge. It is crucial for operators responsible for setting\nprices to utilize reasonable price bounds that are not only interpretable but\nalso acceptable. Despite this necessity, most studies assume that price bounds\nare given constant values, and few have explored reasonable determinations of\nthese bounds. Therefore, we propose a comprehensive framework for determining\nprice bounds that includes both the estimation and adjustment of these bounds.\nSpecifically, we first estimate price bounds using three distinct approaches\nbased on historical pricing data. Then, we adjust the estimated price bounds by\nsolving an optimization problem that incorporates shape constraints. This\nmethod allows the implementation of price optimization under practical and\nreasonable price bounds suitable for real-world applications. We report the\neffectiveness of our proposed method through numerical experiments using\nhistorical pricing data from actual services.",
      "tldr_zh": "这篇论文针对价格优化中的价格边界估计问题，提出一个全面框架，以确保边界的可解释性和实用性。该框架首先使用三种基于历史定价数据的不同方法来估计价格边界，然后通过解决一个包含形状约束的优化问题对边界进行调整，从而实现更合理的价格优化应用。通过实际服务的数值实验，证明了该方法的有效性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14909v2",
      "published_date": "2024-05-23 10:30:16 UTC",
      "updated_date": "2024-09-29 10:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:07:24.926496"
    },
    {
      "arxiv_id": "2407.11973v1",
      "title": "Preliminary Study of the Impact of AI-Based Interventions on Health and Behavioral Outcomes in Maternal Health Programs",
      "title_zh": "基于 AI 干预在孕产妇健康程序中对健康和行为结果影响的初步研究",
      "authors": [
        "Arpan Dasgupta",
        "Niclas Boehmer",
        "Neha Madhiwalla",
        "Aparna Hedge",
        "Bryan Wilder",
        "Milind Tambe",
        "Aparna Taneja"
      ],
      "abstract": "Automated voice calls are an effective method of delivering maternal and\nchild health information to mothers in underserved communities. One method to\nfight dwindling listenership is through an intervention in which health workers\nmake live service calls. Previous work has shown that we can use AI to identify\nbeneficiaries whose listenership gets the greatest boost from an intervention.\nIt has also been demonstrated that listening to the automated voice calls\nconsistently leads to improved health outcomes for the beneficiaries of the\nprogram. These two observations combined suggest the positive effect of\nAI-based intervention scheduling on behavioral and health outcomes. This study\nanalyzes the relationship between the two. Specifically, we are interested in\nmothers' health knowledge in the post-natal period, measured through survey\nquestions. We present evidence that improved listenership through AI-scheduled\ninterventions leads to a better understanding of key health issues during\npregnancy and infancy. This improved understanding has the potential to benefit\nthe health outcomes of mothers and their babies.",
      "tldr_zh": "本研究初步探讨了 AI-based interventions 在孕产妇健康计划中的影响，焦点在于使用 AI 算法识别受益者并优化干预（如健康工作者直播呼叫），以提升 underserved 社区母亲对自动语音呼叫的收听率。研究通过调查测量母亲在产后期的健康知识，发现 AI 调度干预显著改善了她们对孕期和婴儿期关键健康问题的理解。最终，证据表明这种提升的收听率和知识水平有潜力带来更好的 behavioral outcomes 和整体健康结果。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at Autonomous Agents for Social Good (AASG) workshop at\n  AAMAS'24",
      "pdf_url": "http://arxiv.org/pdf/2407.11973v1",
      "published_date": "2024-05-23 10:18:20 UTC",
      "updated_date": "2024-05-23 10:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:07:37.381118"
    },
    {
      "arxiv_id": "2405.14398v3",
      "title": "SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition with Jaccard Attentive Spiking Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Weiyu Guo",
        "Ying Sun",
        "Yijie Xu",
        "Ziyue Qiao",
        "Yongkui Yang",
        "Hui Xiong"
      ],
      "abstract": "Surface electromyography (sEMG) based gesture recognition offers a natural\nand intuitive interaction modality for wearable devices. Despite significant\nadvancements in sEMG-based gesture-recognition models, existing methods often\nsuffer from high computational latency and increased energy consumption.\nAdditionally, the inherent instability of sEMG signals, combined with their\nsensitivity to distribution shifts in real-world settings, compromises model\nrobustness. To tackle these challenges, we propose a novel SpGesture framework\nbased on Spiking Neural Networks, which possesses several unique merits\ncompared with existing methods: (1) Robustness: By utilizing membrane potential\nas a memory list, we pioneer the introduction of Source-Free Domain Adaptation\ninto SNN for the first time. This enables SpGesture to mitigate the accuracy\ndegradation caused by distribution shifts. (2) High Accuracy: With a novel\nSpiking Jaccard Attention, SpGesture enhances the SNNs' ability to represent\nsEMG features, leading to a notable rise in system accuracy. To validate\nSpGesture's performance, we collected a new sEMG gesture dataset which has\ndifferent forearm postures, where SpGesture achieved the highest accuracy among\nthe baselines ($89.26\\%$). Moreover, the actual deployment on the CPU\ndemonstrated a system latency below 100ms, well within real-time requirements.\nThis impressive performance showcases SpGesture's potential to enhance the\napplicability of sEMG in real-world scenarios. The code is available at\nhttps://github.com/guoweiyu/SpGesture/.",
      "tldr_zh": "本研究提出 SpGesture 框架，利用 Spiking Neural Networks (SNN) 进行基于 sEMG 的手势识别，旨在解决现有方法的高计算延迟、高能耗以及信号不稳定和分布偏移导致的鲁棒性问题。框架首次将 Source-Free Domain Adaptation 引入 SNN，通过膜电位作为记忆列表缓解分布偏移，并采用 Spiking Jaccard Attention 提升 sEMG 特征的表示能力，从而提高系统准确性。在新收集的 sEMG 数据集上，SpGesture 实现了 89.26% 的准确率，比基线模型表现更优，并在 CPU 部署中达到低于 100ms 的延迟，展示了其实时应用潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14398v3",
      "published_date": "2024-05-23 10:15:29 UTC",
      "updated_date": "2024-10-30 12:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:07:49.815672"
    },
    {
      "arxiv_id": "2405.14394v2",
      "title": "Instruction Tuning With Loss Over Instructions",
      "title_zh": "基于指令的损失函数指令调优",
      "authors": [
        "Zhengyan Shi",
        "Adam X. Yang",
        "Bin Wu",
        "Laurence Aitchison",
        "Emine Yilmaz",
        "Aldo Lipani"
      ],
      "abstract": "Instruction tuning plays a crucial role in shaping the outputs of language\nmodels (LMs) to desired styles. In this work, we propose a simple yet effective\nmethod, Instruction Modelling (IM), which trains LMs by applying a loss\nfunction to the instruction and prompt part rather than solely to the output\npart. Through experiments across 21 diverse benchmarks, we show that, in many\nscenarios, IM can effectively improve the LM performance on both NLP tasks\n(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks\n(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM\nboosts model performance on AlpacaEval 1.0 by over 100%. We identify two key\nfactors influencing the effectiveness of IM: (1) The ratio between instruction\nlength and output length in the training data; and (2) The number of training\nexamples. We observe that IM is especially beneficial when trained on datasets\nwith lengthy instructions paired with brief outputs, or under the Superficial\nAlignment Hypothesis (SAH) where a small amount of training examples are used\nfor instruction tuning. Further analysis substantiates our hypothesis that our\nimprovement can be attributed to reduced overfitting to instruction tuning\ndatasets. It is worth noting that we are not proposing \\ours as a replacement\nfor current fine-tuning processes. Instead, our work aims to provide practical\nguidance for instruction tuning LMs, especially in low-resource scenarios.",
      "tldr_zh": "本研究提出了一种简单有效的指令调优方法，Instruction Modelling (IM)，通过在指令和提示部分施加损失函数，而非仅限于输出部分，来提升语言模型 (LMs) 的性能。在21个多样化基准实验中，IM显著改善了LMs在NLP任务（如MMLU、TruthfulQA和HumanEval）以及开放生成任务（如MT-Bench和AlpacaEval）上的表现，其中AlpacaEval 1.0的性能在最佳情况下提升超过100%。影响IM有效性的关键因素包括训练数据中指令长度与输出长度的比例，以及训练示例的数量，尤其适用于指令较长、输出较短的数据集或Superficial Alignment Hypothesis (SAH)下的低资源场景。进一步分析表明，这种改进主要归因于减少了对指令调优数据集的过拟合，从而为低资源指令调优提供实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024. Code is available at\n  https://github.com/ZhengxiangShi/InstructionModelling",
      "pdf_url": "http://arxiv.org/pdf/2405.14394v2",
      "published_date": "2024-05-23 10:12:03 UTC",
      "updated_date": "2024-10-02 20:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:08:12.468831"
    },
    {
      "arxiv_id": "2405.14391v2",
      "title": "Explainable Few-shot Knowledge Tracing",
      "title_zh": "可解释的少样本知识追踪",
      "authors": [
        "Haoxuan Li",
        "Jifan Yu",
        "Yuanxin Ouyang",
        "Zhuang Liu",
        "Wenge Rong",
        "Juanzi Li",
        "Zhang Xiong"
      ],
      "abstract": "Knowledge tracing (KT), aiming to mine students' mastery of knowledge by\ntheir exercise records and predict their performance on future test questions,\nis a critical task in educational assessment. While researchers achieved\ntremendous success with the rapid development of deep learning techniques,\ncurrent knowledge tracing tasks fall into the cracks from real-world teaching\nscenarios. Relying heavily on extensive student data and solely predicting\nnumerical performances differs from the settings where teachers assess\nstudents' knowledge state from limited practices and provide explanatory\nfeedback. To fill this gap, we explore a new task formulation: Explainable\nFew-shot Knowledge Tracing. By leveraging the powerful reasoning and generation\nabilities of large language models (LLMs), we then propose a cognition-guided\nframework that can track the student knowledge from a few student records while\nproviding natural language explanations. Experimental results from three widely\nused datasets show that LLMs can perform comparable or superior to competitive\ndeep knowledge tracing methods. We also discuss potential directions and call\nfor future improvements in relevant topics.",
      "tldr_zh": "本文提出Explainable Few-shot Knowledge Tracing任务，旨在解决传统Knowledge Tracing（KT）依赖大量数据且无法提供解释反馈的问题，通过少量学生记录评估知识状态并生成自然语言解释。研究团队设计了一个基于大语言模型（LLMs）的认知引导框架，利用LLMs的推理和生成能力来追踪学生认知。实验结果显示，在三个常用数据集上，该框架的表现可与或优于现有深度KT方法，并呼吁未来在相关领域进行进一步改进。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14391v2",
      "published_date": "2024-05-23 10:07:21 UTC",
      "updated_date": "2024-05-26 03:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:08:14.341756"
    },
    {
      "arxiv_id": "2405.14389v1",
      "title": "stl2vec: Semantic and Interpretable Vector Representation of Temporal Logic",
      "title_zh": "stl2vec: 时序逻辑的语义和可解释向量表示",
      "authors": [
        "Gaia Saveri",
        "Laura Nenzi",
        "Luca Bortolussi",
        "Jan Křetínský"
      ],
      "abstract": "Integrating symbolic knowledge and data-driven learning algorithms is a\nlongstanding challenge in Artificial Intelligence. Despite the recognized\nimportance of this task, a notable gap exists due to the discreteness of\nsymbolic representations and the continuous nature of machine-learning\ncomputations. One of the desired bridges between these two worlds would be to\ndefine semantically grounded vector representation (feature embedding) of logic\nformulae, thus enabling to perform continuous learning and optimization in the\nsemantic space of formulae. We tackle this goal for knowledge expressed in\nSignal Temporal Logic (STL) and devise a method to compute continuous\nembeddings of formulae with several desirable properties: the embedding (i) is\nfinite-dimensional, (ii) faithfully reflects the semantics of the formulae,\n(iii) does not require any learning but instead is defined from basic\nprinciples, (iv) is interpretable. Another significant contribution lies in\ndemonstrating the efficacy of the approach in two tasks: learning model\nchecking, where we predict the probability of requirements being satisfied in\nstochastic processes; and integrating the embeddings into a neuro-symbolic\nframework, to constrain the output of a deep-learning generative model to\ncomply to a given logical specification.",
      "tldr_zh": "这篇论文解决了人工智能中符号知识与数据驱动学习整合的挑战，特别是符号表示的离散性和机器学习计算的连续性鸿沟。作者提出 stl2vec 方法，为 Signal Temporal Logic (STL) 公式计算连续 embeddings，这些 embeddings 具有有限维度、忠实反映语义、不需学习且可解释的特性。实验验证了该方法的效能，包括用于学习模型 checking（预测随机过程需求满足概率）和整合到 neuro-symbolic 框架中，以约束深度学习生成模型的输出符合给定逻辑规范。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14389v1",
      "published_date": "2024-05-23 10:04:56 UTC",
      "updated_date": "2024-05-23 10:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:08:25.447712"
    },
    {
      "arxiv_id": "2405.14385v1",
      "title": "Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Aline Étienne",
        "Delphine Battistelli",
        "Gwénolé Lecorvé"
      ],
      "abstract": "The objective of this paper is to predict (A) whether a sentence in a written\ntext expresses an emotion, (B) the mode(s) in which it is expressed, (C)\nwhether it is basic or complex, and (D) its emotional category.\n  One of our major contributions, through a dataset and a model, is to\nintegrate the fact that an emotion can be expressed in different modes: from a\ndirect mode, essentially lexicalized, to a more indirect mode, where emotions\nwill only be suggested, a mode that NLP approaches generally don't take into\naccount.\n  Another originality is that the scope is on written texts, as opposed usual\nwork focusing on conversational (often multi-modal) data. In this context,\nmodes of expression are seen as a factor towards the automatic analysis of\ncomplexity in texts.\n  Experiments on French texts show acceptable results compared to the human\nannotators' agreement, and outperforming results compared to using a large\nlanguage model with in-context learning (i.e. no fine-tuning).",
      "tldr_zh": "本论文旨在通过模型预测法语书面文本中句子的情绪表达情况，包括是否表达情绪（A）、表达模式（B）、是否为基本或复杂情绪（C）以及情绪类别（D）。主要贡献是构建数据集和模型，以整合情绪的多种表达模式，从直接的词汇化模式到间接的暗示模式，从而填补 NLP 领域对间接模式的忽略。论文强调将这些表达模式作为分析文本复杂性的因素，并聚焦于书面文本而非传统的对话或多模态数据。实验结果显示，在法语文本上，该模型与人类标注者的一致性良好，并优于使用 in-context learning 的巨型语言模型（无需微调）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 12 figures, submitted to ACL 2024 WASSA workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.14385v1",
      "published_date": "2024-05-23 10:02:13 UTC",
      "updated_date": "2024-05-23 10:02:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:08:37.376641"
    },
    {
      "arxiv_id": "2405.14384v1",
      "title": "Reliable Trajectory Prediction and Uncertainty Quantification with Conditioned Diffusion Models",
      "title_zh": "基于条件扩散模型的可靠轨迹预测与不确定性量化",
      "authors": [
        "Marion Neumeier",
        "Sebastian Dorn",
        "Michael Botsch",
        "Wolfgang Utschick"
      ],
      "abstract": "This work introduces the conditioned Vehicle Motion Diffusion (cVMD) model, a\nnovel network architecture for highway trajectory prediction using diffusion\nmodels. The proposed model ensures the drivability of the predicted trajectory\nby integrating non-holonomic motion constraints and physical constraints into\nthe generative prediction module. Central to the architecture of cVMD is its\ncapacity to perform uncertainty quantification, a feature that is crucial in\nsafety-critical applications. By integrating the quantified uncertainty into\nthe prediction process, the cVMD's trajectory prediction performance is\nimproved considerably. The model's performance was evaluated using the publicly\navailable highD dataset. Experiments show that the proposed architecture\nachieves competitive trajectory prediction accuracy compared to\nstate-of-the-art models, while providing guaranteed drivable trajectories and\nuncertainty quantification.",
      "tldr_zh": "本研究引入了conditioned Vehicle Motion Diffusion (cVMD) 模型，这是一种基于diffusion models的新型网络架构，用于高速公路轨迹预测，通过整合非-holonomic motion constraints和物理约束，确保预测轨迹的可驾驶性。cVMD的核心功能是进行uncertainty quantification，将其整合到预测过程中，从而显著提升轨迹预测的可靠性和性能。在使用highD数据集的实验中，该模型在准确性上与最先进模型相当，同时提供了可保证的驾驶轨迹和不确定性量化，为安全关键应用提供了重要支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE/CVF Computer Vision and Pattern Recognition\n  Conference Workshops (CVPRW) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14384v1",
      "published_date": "2024-05-23 10:01:39 UTC",
      "updated_date": "2024-05-23 10:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:08:48.539819"
    },
    {
      "arxiv_id": "2405.14383v1",
      "title": "Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihua Wen",
        "Zhiliang Tian",
        "Zexin Jian",
        "Zhen Huang",
        "Pei Ke",
        "Yifu Gao",
        "Minlie Huang",
        "Dongsheng Li"
      ],
      "abstract": "Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer\nfrom hallucinations. The knowledge boundary (KB) of an LLM limits its factual\nunderstanding, beyond which it may begin to hallucinate. Investigating the\nperception of LLMs' KB is crucial for detecting hallucinations and LLMs'\nreliable generation. Current studies perceive LLMs' KB on questions with a\nconcrete answer (close-ended questions) while paying limited attention to\nsemi-open-ended questions (SoeQ) that correspond to many potential answers.\nSome researchers achieve it by judging whether the question is answerable or\nnot. However, this paradigm is unsuitable for SoeQ, which are usually partially\nanswerable, containing both answerable and ambiguous (unanswerable) answers.\nAmbiguous answers are essential for knowledge-seeking, but they may go beyond\nthe KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by\ndiscovering more ambiguous answers. First, we apply an LLM-based approach to\nconstruct SoeQ and obtain answers from a target LLM. Unfortunately, the output\nprobabilities of mainstream black-box LLMs are inaccessible to sample for\nlow-probability ambiguous answers. Therefore, we apply an open-sourced\nauxiliary model to explore ambiguous answers for the target LLM. We calculate\nthe nearest semantic representation for existing answers to estimate their\nprobabilities, with which we reduce the generation probability of\nhigh-probability answers to achieve a more effective generation. Finally, we\ncompare the results from the RAG-based evaluation and LLM self-evaluation to\ncategorize four types of ambiguous answers that are beyond the KB of the target\nLLM. Following our method, we construct a dataset to perceive the KB for GPT-4.\nWe find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.\nBesides, our auxiliary model, LLaMA-2-13B, is effective in discovering more\nambiguous answers.",
      "tldr_zh": "该研究探讨了Large Language Models (LLMs) 的知识边界（KB），通过半开放式问题（SoeQ）来检测其幻觉问题，强调了SoeQ中模糊答案的重要性。方法包括使用LLM-based构建SoeQ，并借助开源辅助模型如LLaMA-2-13B通过语义表示和概率调整来探索更多模糊答案，然后通过RAG-based评价和LLM自评价分类四种超出KB的答案。实验构建了数据集应用于GPT-4，发现其在SoeQ上表现差劲，且无法自知其KB，这为提升LLMs的可靠生成提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14383v1",
      "published_date": "2024-05-23 10:00:14 UTC",
      "updated_date": "2024-05-23 10:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:09:03.773028"
    },
    {
      "arxiv_id": "2405.14379v1",
      "title": "Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?",
      "title_zh": "大型语言模型是否能为空间推理任务创建新知识？",
      "authors": [
        "Thomas Greatrix",
        "Roger Whitaker",
        "Liam Turner",
        "Walter Colombo"
      ],
      "abstract": "The potential for Large Language Models (LLMs) to generate new information\noffers a potential step change for research and innovation. This is challenging\nto assert as it can be difficult to determine what an LLM has previously seen\nduring training, making \"newness\" difficult to substantiate. In this paper we\nobserve that LLMs are able to perform sophisticated reasoning on problems with\na spatial dimension, that they are unlikely to have previously directly\nencountered. While not perfect, this points to a significant level of\nunderstanding that state-of-the-art LLMs can now achieve, supporting the\nproposition that LLMs are able to yield significant emergent properties. In\nparticular, Claude 3 is found to perform well in this regard.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能为空间推理任务生成新知识，通过观察 LLMs 在可能未直接遇到的复杂空间问题上进行高级推理。结果表明，尽管并非完美，LLMs 显示出显著的理解能力，支持其紧急属性 (emergent properties) 的存在。特别地，Claude 3 在这类任务中表现出色，为评估 LLMs 的创新潜力提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14379v1",
      "published_date": "2024-05-23 09:54:54 UTC",
      "updated_date": "2024-05-23 09:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:09:13.182802"
    },
    {
      "arxiv_id": "2405.14377v2",
      "title": "CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zi Yang",
        "Ziyue Liu",
        "Samridhi Choudhary",
        "Xinfeng Xie",
        "Cao Gao",
        "Siegfried Kunzmann",
        "Zheng Zhang"
      ],
      "abstract": "Training large AI models such as LLMs and DLRMs costs massive GPUs and\ncomputing time. The high training cost has become only affordable to big tech\ncompanies, meanwhile also causing increasing concerns about the environmental\nimpact. This paper presents CoMERA, a Computing- and Memory-Efficient training\nmethod via Rank-Adaptive tensor optimization. CoMERA achieves rank-adaptive\ntensor-compressed (pre)-training via a multi-objective optimization formulation\nand improves the training to provide both a high compression ratio and\nexcellent accuracy in the training process. Our optimized numerical computation\n(e.g., optimized tensorized embedding and tensor-network contractions) and GPU\nimplementation eliminate part of the run-time overhead in the tensorized\ntraining on GPU. This leads to, for the first time, $2-3\\times$ speedup per\ntraining epoch compared with standard training. CoMERA also outperforms the\nrecent GaLore in terms of both memory and computing efficiency. Specifically,\nCoMERA is $2\\times$ faster per training epoch and $9\\times$ more\nmemory-efficient than GaLore on a tested six-encoder transformer with\nsingle-batch training. Our method also shows $\\sim 2\\times$ speedup than\nstandard pre-training on a BERT-like code-generation LLM while achieving\n$4.23\\times$ compression ratio in pre-training. With further HPC optimization,\nCoMERA may reduce the pre-training cost of many other LLMs. An implementation\nof CoMERA is available at https://github.com/ziyangjoy/CoMERA.",
      "tldr_zh": "这篇论文提出了 CoMERA，一种通过秩自适应张量优化实现的计算和内存高效训练方法，旨在降低大型 AI 模型如 LLMs 和 DLRMs 的训练成本，并减少环境影响。CoMERA 通过多目标优化和优化后的数值计算（如张量化嵌入和张量网络收缩）实现高压缩比和准确性，同时在 GPU 上消除部分运行时开销，导致每训练周期比标准训练快 2-3 倍。实验结果显示，CoMERA 比 GaLore 快 2 倍、内存效率高 9 倍，并在 BERT-like 代码生成模型上实现约 2 倍加速和 4.23 倍压缩比，为高效 AI 训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14377v2",
      "published_date": "2024-05-23 09:52:15 UTC",
      "updated_date": "2024-12-02 09:48:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:09:26.674863"
    },
    {
      "arxiv_id": "2407.09493v1",
      "title": "Social AI and The Equation of Wittgenstein's Language User With Calvino's Literature Machine",
      "title_zh": "翻译失败",
      "authors": [
        "W. J. T. Mollema"
      ],
      "abstract": "Is it sensical to ascribe psychological predicates to AI systems like\nchatbots based on large language models (LLMs)? People have intuitively started\nascribing emotions or consciousness to social AI ('affective artificial\nagents'), with consequences that range from love to suicide. The philosophical\nquestion of whether such ascriptions are warranted is thus very relevant. This\npaper advances the argument that LLMs instantiate language users in Ludwig\nWittgenstein's sense but that ascribing psychological predicates to these\nsystems remains a functionalist temptation. Social AIs are not full-blown\nlanguage users, but rather more like Italo Calvino's literature machines. The\nideas of LLMs as Wittgensteinian language users and Calvino's\nliterature-producing writing machine are combined. This sheds light on the\nmisguided functionalist temptation inherent in moving from equating the two to\nthe ascription of psychological predicates to social AI. Finally, the framework\nof mortal computation is used to show that social AIs lack the basic\nautopoiesis needed for narrative fa\\c{c}ons de parler and their role in the\nsensemaking of human (inter)action. Such psychological predicate ascriptions\ncould make sense: the transition 'from quantity to quality' can take place, but\nits route lies somewhere between life and death, not between affective\nartifacts and emotion approximation by literature machines.",
      "tldr_zh": "本论文探讨了是否合理地将心理谓词（如情绪或意识）赋予基于大型语言模型（LLMs）的社交 AI 系统，强调这种归属可能导致从爱情到自杀的后果。作者论证 LLMs 类似于 Wittgenstein's language user，但更像 Calvino's literature machine，从而揭示了将两者等同的功能ist temptation 的误导性。最终，通过 mortal computation 框架，该研究指出社交 AI 缺乏基本的 autopoiesis，无法进行有效的叙事表达，因此心理谓词的归属需要从生命与死亡之间的过渡中寻求，而非简单地依赖情感模拟。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09493v1",
      "published_date": "2024-05-23 09:51:44 UTC",
      "updated_date": "2024-05-23 09:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:09:38.411903"
    },
    {
      "arxiv_id": "2405.14374v1",
      "title": "State-Constrained Offline Reinforcement Learning",
      "title_zh": "状态约束的离线强化学习",
      "authors": [
        "Charles A. Hepburn",
        "Yue Jin",
        "Giovanni Montana"
      ],
      "abstract": "Traditional offline reinforcement learning methods predominantly operate in a\nbatch-constrained setting. This confines the algorithms to a specific\nstate-action distribution present in the dataset, reducing the effects of\ndistributional shift but restricting the algorithm greatly. In this paper, we\nalleviate this limitation by introducing a novel framework named\n\\emph{state-constrained} offline reinforcement learning. By exclusively\nfocusing on the dataset's state distribution, our framework significantly\nenhances learning potential and reduces previous limitations. The proposed\nsetting not only broadens the learning horizon but also improves the ability to\ncombine different trajectories from the dataset effectively, a desirable\nproperty inherent in offline reinforcement learning. Our research is\nunderpinned by solid theoretical findings that pave the way for subsequent\nadvancements in this domain. Additionally, we introduce StaCQ, a deep learning\nalgorithm that is both performance-driven on the D4RL benchmark datasets and\nclosely aligned with our theoretical propositions. StaCQ establishes a strong\nbaseline for forthcoming explorations in state-constrained offline\nreinforcement learning.",
      "tldr_zh": "本文提出了一种名为 state-constrained offline reinforcement learning 的新框架，通过专注于数据集的状态分布，而不是传统的状态-动作分布，显著提升了学习潜力并缓解了分布偏移问题。该框架能够更有效地结合不同轨迹，提高离线强化学习的适用性，并得到坚实的理论支持。同时，作者引入了 StaCQ 算法，该算法在 D4RL 基准数据集上表现出色，建立了一个强有力的基线，为该领域的后续研究奠定基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14374v1",
      "published_date": "2024-05-23 09:50:04 UTC",
      "updated_date": "2024-05-23 09:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:09:48.985719"
    },
    {
      "arxiv_id": "2405.14908v4",
      "title": "BiMix: A Bivariate Data Mixing Law for Language Model Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Ce Ge",
        "Zhijian Ma",
        "Daoyuan Chen",
        "Yaliang Li",
        "Bolin Ding"
      ],
      "abstract": "Large language models have demonstrated remarkable capabilities across\nvarious tasks, primarily attributed to the utilization of diversely sourced\ndata. However, the impact of pretraining data composition on model performance\nremains poorly understood. This paper introduces $\\textbf{BiMix}$, a novel\nbivariate data mixing law that models the joint scaling behavior of domain\nproportions and data volume in LLM pretraining. $\\textbf{BiMix}$ provides a\nsystematic framework for understanding and optimizing data mixtures across\ndiverse domains. Through extensive experiments on two large-scale datasets, we\ndemonstrate $\\textbf{BiMix}$'s high accuracy in loss extrapolation (mean\nrelative error < 0.2%) and its generalization to unseen mixtures (R${}^{2}$ >\n0.97). Optimization of domain proportions yields superior model performance\ncompared to existing methods. Furthermore, we establish entropy-based measures\nas efficient proxies for data mixing, offering a computationally lightweight\nstrategy. Our work contributes both theoretical insights into data mixing\ndynamics and practical tools for enhancing LLM training efficiency, paving the\nway for more effective scaling strategies in language model development.",
      "tldr_zh": "本论文提出了一种名为 BiMix 的双变量数据混合法则，用于优化大型语言模型（LLM）的预训练过程。BiMix 模型化了领域比例和数据量的联合缩放行为，提供了一个系统框架来理解和调整数据混合策略。通过在两个大规模数据集上的广泛实验，BiMix 展示了在损失外推方面的极高准确性（平均相对误差 < 0.2%）以及对未见混合的强泛化能力（R² > 0.97），并通过优化领域比例实现了比现有方法更优的模型性能。此外，该研究引入了基于熵的度量作为高效代理工具，为LLM训练效率提供了理论洞见和实用策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Clarify details",
      "pdf_url": "http://arxiv.org/pdf/2405.14908v4",
      "published_date": "2024-05-23 09:44:02 UTC",
      "updated_date": "2025-01-27 11:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:10:02.342202"
    },
    {
      "arxiv_id": "2405.14366v2",
      "title": "MiniCache: KV Cache Compression in Depth Dimension for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Akide Liu",
        "Jing Liu",
        "Zizheng Pan",
        "Yefei He",
        "Gholamreza Haffari",
        "Bohan Zhuang"
      ],
      "abstract": "A critical approach for efficiently deploying computationally demanding large\nlanguage models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value\nstates of previously generated tokens, significantly reducing the need for\nrepetitive computations and thereby lowering latency in autoregressive\ngeneration. However, the size of the KV cache grows linearly with sequence\nlength, posing challenges for applications requiring long context input and\nextensive sequence generation. In this paper, we present a simple yet effective\napproach, called MiniCache, to compress the KV cache across layers from a novel\ndepth perspective, significantly reducing the memory footprint for LLM\ninference. Our approach is based on the observation that KV cache states\nexhibit high similarity between the adjacent layers in the middle-to-deep\nportion of LLMs. To facilitate merging, we propose disentangling the states\ninto the magnitude and direction components, interpolating the directions of\nthe state vectors while preserving their lengths unchanged. Furthermore, we\nintroduce a token retention strategy to keep highly distinct state pairs\nunmerged, thus preserving the information with minimal additional storage\noverhead. Our MiniCache is training-free and general, complementing existing KV\ncache compression strategies, such as quantization and sparsity. We conduct a\ncomprehensive evaluation of MiniCache utilizing various models including\nLLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,\ndemonstrating its exceptional performance in achieving superior compression\nratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit\nMiniCache achieves a remarkable compression ratio of up to 5.02x, enhances\ninference throughput by approximately 5x, and reduces the memory footprint by\n41% compared to the FP16 full cache baseline, all while maintaining\nnear-lossless performance.",
      "tldr_zh": "这篇论文提出了 MiniCache，一种针对 Large Language Models (LLMs) 的 KV Cache 压缩方法，通过从深度维度压缩缓存来解决序列长度增长导致的内存问题。MiniCache 基于 KV 状态在相邻层之间的高度相似性，将状态分解为 magnitude 和 direction 组件，对 direction 进行插值优化，同时引入 token retention 策略保留高度不同的状态，以最小化信息损失。该方法无需训练且通用，可与量化或稀疏策略结合；实验在 LLaMA-2、LLaMA-3 等模型上显示，MiniCache 实现了高达 5.02x 的压缩比、约 5x 的推理吞吐量提升，并将内存占用减少 41%，而性能几乎无损。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project is available at https://minicache.vmv.re",
      "pdf_url": "http://arxiv.org/pdf/2405.14366v2",
      "published_date": "2024-05-23 09:43:52 UTC",
      "updated_date": "2024-09-07 02:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:10:15.096622"
    },
    {
      "arxiv_id": "2405.14365v1",
      "title": "JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training Small Data Synthesis Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Zhou",
        "Beichen Zhang",
        "Jiapeng Wang",
        "Zhipeng Chen",
        "Wayne Xin Zhao",
        "Jing Sha",
        "Zhichao Sheng",
        "Shijin Wang",
        "Ji-Rong Wen"
      ],
      "abstract": "Mathematical reasoning is an important capability of large language\nmodels~(LLMs) for real-world applications. To enhance this capability, existing\nwork either collects large-scale math-related texts for pre-training, or relies\non stronger LLMs (\\eg GPT-4) to synthesize massive math problems. Both types of\nwork generally lead to large costs in training or synthesis. To reduce the\ncost, based on open-source available texts, we propose an efficient way that\ntrains a small LLM for math problem synthesis, to efficiently generate\nsufficient high-quality pre-training data. To achieve it, we create a dataset\nusing GPT-4 to distill its data synthesis capability into the small LLM.\nConcretely, we craft a set of prompts based on human education stages to guide\nGPT-4, to synthesize problems covering diverse math knowledge and difficulty\nlevels. Besides, we adopt the gradient-based influence estimation method to\nselect the most valuable math-related texts. The both are fed into GPT-4 for\ncreating the knowledge distillation dataset to train the small LLM. We leverage\nit to synthesize 6 million math problems for pre-training our JiuZhang3.0\nmodel, which only needs to invoke GPT-4 API 9.3k times and pre-train on 4.6B\ndata. Experimental results have shown that JiuZhang3.0 achieves\nstate-of-the-art performance on several mathematical reasoning datasets, under\nboth natural language reasoning and tool manipulation settings. Our code and\ndata will be publicly released in\n\\url{https://github.com/RUCAIBox/JiuZhang3.0}.",
      "tldr_zh": "该论文提出JiuZhang3.0，一种高效方法，通过训练小型数据合成模型来提升大型语言模型（LLMs）的数学推理能力，从而减少预训练成本。方法包括使用GPT-4蒸馏其合成能力，设计基于人类教育阶段的提示生成多样数学问题，并采用基于梯度的影响估计方法选择最有价值的文本，最终合成600万高质量问题。实验结果表明，JiuZhang3.0在多个数学推理数据集上实现了最先进性能，包括自然语言推理和工具操作场景。代码和数据已计划公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, SOTA math LLM using Well-trained Data Synthesis LLM",
      "pdf_url": "http://arxiv.org/pdf/2405.14365v1",
      "published_date": "2024-05-23 09:43:19 UTC",
      "updated_date": "2024-05-23 09:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:10:26.459874"
    },
    {
      "arxiv_id": "2405.14347v3",
      "title": "Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep Reinforcement Learning (CDRL) Approach",
      "title_zh": "双重动态 ISAC 预编码用于车辆网络：一种受限深度强化学习 (CDRL) 方法",
      "authors": [
        "Zonghui Yang",
        "Shijian Gao",
        "Xiang Cheng"
      ],
      "abstract": "Integrated sensing and communication (ISAC) technology is essential for\nsupporting vehicular networks. However, the communication channel in this\nscenario exhibits time variations, and the potential targets may move rapidly,\nresulting in double dynamics. This nature poses a challenge for real-time\nprecoder design. While optimization-based solutions are widely researched, they\nare complex and heavily rely on perfect channel-related information, which is\nimpractical in double dynamics. To address this challenge, we propose using\nconstrained deep reinforcement learning to facilitate dynamic updates to the\nISAC precoder. Additionally, the primal dual-deep deterministic policy gradient\nand Wolpertinger architecture are tailored to efficiently train the algorithm\nunder complex constraints and varying numbers of users. The proposed scheme not\nonly adapts to the dynamics based on observations but also leverages\nenvironmental information to enhance performance and reduce complexity. Its\nsuperiority over existing candidates has been validated through experiments.",
      "tldr_zh": "该论文针对车辆网络中 ISAC（Integrated Sensing and Communication）技术的双重动态挑战（如通信通道时间变化和目标快速移动），提出了一种基于受限深度强化学习（CDRL）的预编码方法，以实现实时动态更新。方法结合了 primal dual-deep deterministic policy gradient 和 Wolpertinger 架构，高效处理复杂约束和用户数量变化，同时利用环境信息提升性能并降低计算复杂性。实验验证显示，该方案在适应动态场景方面优于现有方法，为车辆网络的可靠ISAC应用提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by 2024 IEEE Global Communications Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.14347v3",
      "published_date": "2024-05-23 09:19:14 UTC",
      "updated_date": "2024-08-23 15:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:10:39.480248"
    },
    {
      "arxiv_id": "2405.14346v1",
      "title": "Mixture of Public and Private Distributions in Imperfect Information Games",
      "title_zh": "不完全信息游戏中的公共和私有分布混合",
      "authors": [
        "Jérôme Arjonilla",
        "Abdallah Saffidine",
        "Tristan Cazenave"
      ],
      "abstract": "In imperfect information games (e.g. Bridge, Skat, Poker), one of the\nfundamental considerations is to infer the missing information while at the\nsame time avoiding the disclosure of private information. Disregarding the\nissue of protecting private information can lead to a highly exploitable\nperformance. Yet, excessive attention to it leads to hesitations that are no\nlonger consistent with our private information. In our work, we show that to\nimprove performance, one must choose whether to use a player's private\ninformation. We extend our work by proposing a new belief distribution\ndepending on the amount of private and public information desired. We\nempirically demonstrate an increase in performance and, with the aim of further\nimproving performance, the new distribution should be used according to the\nposition in the game. Our experiments have been done on multiple benchmarks and\nin multiple determinization-based algorithms (PIMC and IS-MCTS).",
      "tldr_zh": "在不完全信息游戏（如 Bridge、Skat 和 Poker）中，论文探讨了如何平衡推断缺失信息与保护私人信息的问题，指出忽略私人信息保护会导致性能易被利用，而过度关注则可能导致决策不一致。研究提出了一种新的信念分布，通过混合公共和私人信息来根据游戏位置调整信息使用比例，以优化决策策略。在多个基准和算法（如 PIMC 和 IS-MCTS）上的实验显示，这种方法显著提高了性能，验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in CoG 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.14346v1",
      "published_date": "2024-05-23 09:18:25 UTC",
      "updated_date": "2024-05-23 09:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:10:51.291780"
    },
    {
      "arxiv_id": "2405.14333v1",
      "title": "DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Huajian Xin",
        "Daya Guo",
        "Zhihong Shao",
        "Zhizhou Ren",
        "Qihao Zhu",
        "Bo Liu",
        "Chong Ruan",
        "Wenda Li",
        "Xiaodan Liang"
      ],
      "abstract": "Proof assistants like Lean have revolutionized mathematical proof\nverification, ensuring high accuracy and reliability. Although large language\nmodels (LLMs) show promise in mathematical reasoning, their advancement in\nformal theorem proving is hindered by a lack of training data. To address this\nissue, we introduce an approach to generate extensive Lean 4 proof data derived\nfrom high-school and undergraduate-level mathematical competition problems.\nThis approach involves translating natural language problems into formal\nstatements, filtering out low-quality statements, and generating proofs to\ncreate synthetic data. After fine-tuning the DeepSeekMath 7B model on this\nsynthetic dataset, which comprises 8 million formal statements with proofs, our\nmodel achieved whole-proof generation accuracies of 46.3% with 64 samples and\n52% cumulatively on the Lean 4 miniF2F test, surpassing the baseline GPT-4 at\n23.0% with 64 samples and a tree search reinforcement learning method at 41.0%.\nAdditionally, our model successfully proved 5 out of 148 problems in the Lean 4\nFormalized International Mathematical Olympiad (FIMO) benchmark, while GPT-4\nfailed to prove any. These results demonstrate the potential of leveraging\nlarge-scale synthetic data to enhance theorem-proving capabilities in LLMs.\nBoth the synthetic dataset and the model will be made available to facilitate\nfurther research in this promising field.",
      "tldr_zh": "该论文提出 DeepSeek-Prover 方法，通过生成大规模合成数据来提升 LLMs 在定理证明中的能力，针对现有训练数据不足的问题。方法包括将高中和本科级数学竞赛问题转化为 Lean 4 正式语句、过滤低质量内容并生成证明，从而创建了包含 8 百万条语句和证明的合成数据集，并对 DeepSeekMath 7B 模型进行微调。实验结果显示，微调后的模型在 Lean 4 miniF2F 测试中实现 46.3% 的整体证明生成准确率（64 samples），累计达 52%，显著优于基线 GPT-4（23.0%）和树搜索强化学习方法（41.0%），并在 Lean 4 FIMO 基准上成功证明了 5/148 问题。这些成果证明了合成数据在增强 LLMs 证明能力的潜力，数据集和模型将公开以促进进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14333v1",
      "published_date": "2024-05-23 09:03:42 UTC",
      "updated_date": "2024-05-23 09:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:11:09.444065"
    },
    {
      "arxiv_id": "2405.14331v1",
      "title": "LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Mateusz Pach",
        "Dawid Rymarczyk",
        "Koryna Lewandowska",
        "Jacek Tabor",
        "Bartosz Zieliński"
      ],
      "abstract": "Prototypical parts networks combine the power of deep learning with the\nexplainability of case-based reasoning to make accurate, interpretable\ndecisions. They follow the this looks like that reasoning, representing each\nprototypical part with patches from training images. However, a single image\npatch comprises multiple visual features, such as color, shape, and texture,\nmaking it difficult for users to identify which feature is important to the\nmodel.\n  To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network\n(LucidPPN), a novel prototypical parts network that separates color prototypes\nfrom other visual features. Our method employs two reasoning branches: one for\nnon-color visual features, processing grayscale images, and another focusing\nsolely on color information. This separation allows us to clarify whether the\nmodel's decisions are based on color, shape, or texture. Additionally, LucidPPN\nidentifies prototypical parts corresponding to semantic parts of classified\nobjects, making comparisons between data classes more intuitive, e.g., when two\nbird species might differ primarily in belly color.\n  Our experiments demonstrate that the two branches are complementary and\ntogether achieve results comparable to baseline methods. More importantly,\nLucidPPN generates less ambiguous prototypical parts, enhancing user\nunderstanding.",
      "tldr_zh": "本研究提出LucidPPN，一种用户导向的解释性计算机视觉网络，旨在解决Prototypical Parts Networks在图像补丁中特征模糊的问题，例如难以区分颜色、形状和纹理的重要性。LucidPPN采用两个独立的推理分支：一个处理非颜色视觉特征（如形状和纹理）通过灰度图像，另一个专注于颜色信息，从而明确模型决策的依据，并识别出对应对象语义部分的prototypical parts，便于类间比较。实验结果显示，两个分支互补，性能与基线方法相当，同时显著降低了prototypical parts的模糊性，提升了用户理解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in the review process. The code will be available upon\n  acceptance",
      "pdf_url": "http://arxiv.org/pdf/2405.14331v1",
      "published_date": "2024-05-23 09:00:59 UTC",
      "updated_date": "2024-05-23 09:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:11:16.161026"
    },
    {
      "arxiv_id": "2405.17464v1",
      "title": "Data Valuation by Leveraging Global and Local Statistical Information",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoling Zhou",
        "Ou Wu",
        "Michael K. Ng",
        "Hao Jiang"
      ],
      "abstract": "Data valuation has garnered increasing attention in recent years, given the\ncritical role of high-quality data in various applications, particularly in\nmachine learning tasks. There are diverse technical avenues to quantify the\nvalue of data within a corpus. While Shapley value-based methods are among the\nmost widely used techniques in the literature due to their solid theoretical\nfoundation, the accurate calculation of Shapley values is often intractable,\nleading to the proposal of numerous approximated calculation methods. Despite\nsignificant progress, nearly all existing methods overlook the utilization of\ndistribution information of values within a data corpus. In this paper, we\ndemonstrate that both global and local statistical information of value\ndistributions hold significant potential for data valuation within the context\nof machine learning. Firstly, we explore the characteristics of both global and\nlocal value distributions across several simulated and real data corpora.\nUseful observations and clues are obtained. Secondly, we propose a new data\nvaluation method that estimates Shapley values by incorporating the explored\ndistribution characteristics into an existing method, AME. Thirdly, we present\na new path to address the dynamic data valuation problem by formulating an\noptimization problem that integrates information of both global and local value\ndistributions. Extensive experiments are conducted on Shapley value estimation,\nvalue-based data removal/adding, mislabeled data detection, and\nincremental/decremental data valuation. The results showcase the effectiveness\nand efficiency of our proposed methodologies, affirming the significant\npotential of global and local value distributions in data valuation.",
      "tldr_zh": "本文研究了数据估值的重要性，特别是在机器学习任务中，并指出现有Shapley value-based方法虽广泛使用，但计算复杂且忽略了数据语料中值分布的全局和局部统计信息。作者首先探索了这些分布特征，其次提出了一种新方法，将分布信息整合到现有AME方法中来估计Shapley值，并通过优化问题解决动态数据估值问题。实验结果显示，该方法在Shapley值估计、数据移除/添加、错误标记检测和增量/减量估值等方面表现出色，提高了有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2306.10577 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2405.17464v1",
      "published_date": "2024-05-23 08:58:08 UTC",
      "updated_date": "2024-05-23 08:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:11:27.629548"
    },
    {
      "arxiv_id": "2405.14327v5",
      "title": "Autoregressive Image Diffusion: Generation of Image Sequence and Application in MRI",
      "title_zh": "自回归图像扩散：图像序列的生成及其在 MRI 中的应用",
      "authors": [
        "Guanxiong Luo",
        "Shoujin Huang",
        "Martin Uecker"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a widely used non-invasive imaging\nmodality. However, a persistent challenge lies in balancing image quality with\nimaging speed. This trade-off is primarily constrained by k-space measurements,\nwhich traverse specific trajectories in the spatial Fourier domain (k-space).\nThese measurements are often undersampled to shorten acquisition times,\nresulting in image artifacts and compromised quality. Generative models learn\nimage distributions and can be used to reconstruct high-quality images from\nundersampled k-space data. In this work, we present the autoregressive image\ndiffusion (AID) model for image sequences and use it to sample the posterior\nfor accelerated MRI reconstruction. The algorithm incorporates both\nundersampled k-space and pre-existing information. Models trained with fastMRI\ndataset are evaluated comprehensively. The results show that the AID model can\nrobustly generate sequentially coherent image sequences. In MRI applications,\nthe AID can outperform the standard diffusion model and reduce hallucinations,\ndue to the learned inter-image dependencies. The project code is available at\nhttps://github.com/mrirecon/aid.",
      "tldr_zh": "这篇论文提出了 Autoregressive Image Diffusion (AID) 模型，用于生成图像序列，并应用于磁共振成像 (MRI) 的加速重建。AID 模型通过结合欠采样 k-space 数据和预存信息，学习图像间的依赖性，从而从欠采样测量中重建高质量图像序列，减少图像伪影和幻觉。实验在 fastMRI 数据集上评估表明，AID 模型在 MRI 应用中优于标准 diffusion model，提升了重建准确性和鲁棒性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14327v5",
      "published_date": "2024-05-23 08:57:10 UTC",
      "updated_date": "2025-01-06 18:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:11:40.827157"
    },
    {
      "arxiv_id": "2405.14314v2",
      "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhang",
        "Shixin Yang",
        "Chenjia Bai",
        "Fei Wu",
        "Xiu Li",
        "Zhen Wang",
        "Xuelong Li"
      ],
      "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied\ntasks is challenging due to the complexity of the physical world. Especially,\nLLM planning for multi-agent collaboration requires communication of agents or\ncredit assignment as the feedback to re-adjust the proposed plans and achieve\neffective coordination. However, existing methods that overly rely on physical\nverification or self-reflection suffer from excessive and inefficient querying\nof LLMs. In this paper, we propose a novel framework for multi-agent\ncollaboration that introduces Reinforced Advantage feedback (ReAd) for\nefficient self-refinement of plans. Specifically, we perform critic regression\nto learn a sequential advantage function from LLM-planned data, and then treat\nthe LLM planner as an optimizer to generate actions that maximize the advantage\nfunction. It endows the LLM with the foresight to discern whether the action\ncontributes to accomplishing the final task. We provide theoretical analysis by\nextending advantage-weighted regression in reinforcement learning to\nmulti-agent systems. Experiments on Overcooked-AI and a difficult variant of\nRoCoBench show that ReAd surpasses baselines in success rate, and also\nsignificantly decreases the interaction steps of agents and query rounds of\nLLMs, demonstrating its high efficiency for grounding LLMs. More results are\ngiven at https://read-llm.github.io/.",
      "tldr_zh": "该论文针对大型语言模型（LLM）在具身任务中的推理挑战，提出了一种高效的多智能体协作框架Reinforced Advantage feedback (ReAd)，以减少过度查询和低效问题。ReAd通过critic regression从LLM-planned数据中学习顺序优势函数，并将LLM planner作为优化器，生成最大化优势函数的动作，从而赋予LLM预见性来评估动作是否有助于任务完成。实验结果显示，在Overcooked-AI和RoCoBench基准上，ReAd比基线方法提高了成功率，同时显著减少了代理交互步骤和LLM查询轮次，证明了其在LLM grounding方面的效率和潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2405.14314v2",
      "published_date": "2024-05-23 08:33:19 UTC",
      "updated_date": "2024-05-26 02:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:11:53.272870"
    },
    {
      "arxiv_id": "2405.14307v1",
      "title": "AdaGMLP: AdaBoosting GNN-to-MLP Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Weigang Lu",
        "Ziyu Guan",
        "Wei Zhao",
        "Yaming Yang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have revolutionized graph-based machine\nlearning, but their heavy computational demands pose challenges for\nlatency-sensitive edge devices in practical industrial applications. In\nresponse, a new wave of methods, collectively known as GNN-to-MLP Knowledge\nDistillation, has emerged. They aim to transfer GNN-learned knowledge to a more\nefficient MLP student, which offers faster, resource-efficient inference while\nmaintaining competitive performance compared to GNNs. However, these methods\nface significant challenges in situations with insufficient training data and\nincomplete test data, limiting their applicability in real-world applications.\nTo address these challenges, we propose AdaGMLP, an AdaBoosting GNN-to-MLP\nKnowledge Distillation framework. It leverages an ensemble of diverse MLP\nstudents trained on different subsets of labeled nodes, addressing the issue of\ninsufficient training data. Additionally, it incorporates a Node Alignment\ntechnique for robust predictions on test data with missing or incomplete\nfeatures. Our experiments on seven benchmark datasets with different settings\ndemonstrate that AdaGMLP outperforms existing G2M methods, making it suitable\nfor a wide range of latency-sensitive real-world applications. We have\nsubmitted our code to the GitHub repository\n(https://github.com/WeigangLu/AdaGMLP-KDD24).",
      "tldr_zh": "该论文提出AdaGMLP框架，通过AdaBoosting技术优化GNN-to-MLP Knowledge Distillation，旨在解决Graph Neural Networks (GNNs)计算密集且不适合延迟敏感边缘设备的问题。AdaGMLP使用多个基于不同标记节点子集训练的MLP学生模型来处理训练数据不足问题，并引入Node Alignment技术以提升对缺失或不完整测试数据的鲁棒性。在七个基准数据集上的实验表明，AdaGMLP超越现有G2M方法，提供更高效的性能，适用于实时工业应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14307v1",
      "published_date": "2024-05-23 08:28:44 UTC",
      "updated_date": "2024-05-23 08:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:12:03.064748"
    },
    {
      "arxiv_id": "2407.12690v2",
      "title": "The Dual Imperative: Innovation and Regulation in the AI Era",
      "title_zh": "翻译失败",
      "authors": [
        "Paulo Carvão"
      ],
      "abstract": "This article addresses the societal costs associated with the lack of\nregulation in Artificial Intelligence and proposes a framework combining\ninnovation and regulation. Over fifty years of AI research, catalyzed by\ndeclining computing costs and the proliferation of data, have propelled AI into\nthe mainstream, promising significant economic benefits. Yet, this rapid\nadoption underscores risks, from bias amplification and labor disruptions to\nexistential threats posed by autonomous systems. The discourse is polarized\nbetween accelerationists, advocating for unfettered technological advancement,\nand doomers, calling for a slowdown to prevent dystopian outcomes. This piece\nadvocates for a middle path that leverages technical innovation and smart\nregulation to maximize the benefits of AI while minimizing its risks, offering\na pragmatic approach to the responsible progress of AI technology. Technical\ninvention beyond the most capable foundation models is needed to contain\ncatastrophic risks. Regulation is required to create incentives for this\nresearch while addressing current issues.",
      "tldr_zh": "这篇文章讨论了人工智能（AI）缺乏监管的社会成本，并提出一个结合创新与监管的框架，以平衡AI的快速发展。文章回顾了50年来AI研究的进展，强调了计算成本下降和数据泛滥带来的经济益处，同时指出了风险，如偏见放大（bias amplification）、劳动力中断和自主系统带来的生存威胁。作者主张一条中间路径，利用技术创新（如超越最先进基础模型的发明）和智能监管来最大化AI益处并最小化风险，从而为负责任的AI进步提供实用方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI",
        "K.4.1; K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "This is an original manuscript of an article published by\n  Inderscience in the International Journal of Technology Policy and Law Vol.\n  3, No. 3 on November 28, 2024, available online:\n  https://doi.org/10.1504/IJTPL.2024.142861",
      "pdf_url": "http://arxiv.org/pdf/2407.12690v2",
      "published_date": "2024-05-23 08:26:25 UTC",
      "updated_date": "2025-02-13 13:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:12:15.672221"
    },
    {
      "arxiv_id": "2405.14297v4",
      "title": "Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient Transformer Models",
      "title_zh": "动态混合专家：一种用于高效 Transformer 模型的自动调优方法",
      "authors": [
        "Yongxin Guo",
        "Zhenglin Cheng",
        "Xiaoying Tang",
        "Zhaopeng Tu",
        "Tao Lin"
      ],
      "abstract": "The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the\nefficiency of training and inference for Transformer-based foundational models,\nyielding promising results.However, the performance of SMoE heavily depends on\nthe choice of hyper-parameters, such as the number of experts and the number of\nexperts to be activated (referred to as top-k), resulting in significant\ncomputational overhead due to the extensive model training by searching over\nvarious hyper-parameter configurations. As a remedy, we introduce the Dynamic\nMixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating\nmethod that enables each token to automatically determine the number of experts\nto activate. (2) An adaptive process automatically adjusts the number of\nexperts during training. Extensive numerical results across Vision, Language,\nand Vision-Language tasks demonstrate the effectiveness of our approach to\nachieve competitive performance compared to GMoE for vision and language tasks,\nand MoE-LLaVA for vision-language tasks, while maintaining efficiency by\nactivating fewer parameters. Our code is available at\nhttps://github.com/LINs-lab/DynMoE.",
      "tldr_zh": "该研究针对 Sparse Mixture of Experts (SMoE) 在 Transformer 模型中依赖超参数（如专家数量和 top-k）导致的计算开销问题，提出了一种自动调优方法 Dynamic Mixture of Experts (DynMoE)。DynMoE 包括一个新颖的门控方法，让每个 token 自动决定激活的专家数量，以及一个自适应过程来在训练期间动态调整专家数量。在视觉、语言和视觉-语言任务的实验中，DynMoE 实现了与 GMoE 和 MoE-LLaVA 相当的性能，同时通过激活更少的参数提升了效率。该方法为高效 Transformer 模型提供了可扩展的优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.14297v4",
      "published_date": "2024-05-23 08:18:30 UTC",
      "updated_date": "2025-03-10 09:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:12:28.236137"
    },
    {
      "arxiv_id": "2405.14291v1",
      "title": "Variational Bayes for Federated Continual Learning",
      "title_zh": "变分贝叶斯用于联邦持续学习",
      "authors": [
        "Dezhong Yao",
        "Sanmu Li",
        "Yutong Dai",
        "Zhiqiang Xu",
        "Shengshan Hu",
        "Peilin Zhao",
        "Lichao Sun"
      ],
      "abstract": "Federated continual learning (FCL) has received increasing attention due to\nits potential in handling real-world streaming data, characterized by evolving\ndata distributions and varying client classes over time. The constraints of\nstorage limitations and privacy concerns confine local models to exclusively\naccess the present data within each learning cycle. Consequently, this\nrestriction induces performance degradation in model training on previous data,\ntermed \"catastrophic forgetting\". However, existing FCL approaches need to\nidentify or know changes in data distribution, which is difficult in the real\nworld. To release these limitations, this paper directs attention to a broader\ncontinuous framework. Within this framework, we introduce Federated Bayesian\nNeural Network (FedBNN), a versatile and efficacious framework employing a\nvariational Bayesian neural network across all clients. Our method continually\nintegrates knowledge from local and historical data distributions into a single\nmodel, adeptly learning from new data distributions while retaining performance\non historical distributions. We rigorously evaluate FedBNN's performance\nagainst prevalent methods in federated learning and continual learning using\nvarious metrics. Experimental analyses across diverse datasets demonstrate that\nFedBNN achieves state-of-the-art results in mitigating forgetting.",
      "tldr_zh": "该论文针对Federated Continual Learning (FCL)中的“catastrophic forgetting”问题，提出Federated Bayesian Neural Network (FedBNN)框架，利用Variational Bayes神经网络在客户端间整合本地和历史数据分布的知识。FedBNN能够适应不断演变的数据分布，同时保留对历史数据的性能，而无需预知分布变化。实验结果显示，在多种数据集上，FedBNN在缓解遗忘方面取得了最先进的效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14291v1",
      "published_date": "2024-05-23 08:09:21 UTC",
      "updated_date": "2024-05-23 08:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:12:40.928944"
    },
    {
      "arxiv_id": "2405.14286v2",
      "title": "Co-Representation Neural Hypergraph Diffusion for Edge-Dependent Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yijia Zheng",
        "Marcel Worring"
      ],
      "abstract": "Hypergraphs are widely employed to represent complex higher-order relations\nin real-world applications. Most hypergraph learning research focuses on\nnode-level or edge-level tasks. A practically relevant but more challenging\ntask, edge-dependent node classification (ENC), is only recently proposed. In\nENC, a node can have different labels across different hyperedges, which\nrequires the modeling of node-edge pairs instead of single nodes or hyperedges.\nExisting solutions for this task are based on message passing and model\ninteractions in within-edge and within-node structures as multi-input\nsingle-output functions. This brings three limitations: (1) non-adaptive\nrepresentation size, (2) non-adaptive messages, and (3) insufficient direct\ninteractions among nodes or edges. To tackle these limitations, we propose\nCoNHD, a new ENC solution that models both within-edge and within-node\ninteractions as multi-input multi-output functions. Specifically, we represent\nthese interactions as a hypergraph diffusion process on node-edge\nco-representations. We further develop a neural implementation for this\ndiffusion process, which can adapt to a specific ENC dataset. Extensive\nexperiments demonstrate the effectiveness and efficiency of the proposed CoNHD\nmethod.",
      "tldr_zh": "该论文提出CoNHD（Co-Representation Neural Hypergraph Diffusion）方法，用于解决超图（hypergraphs）中更具挑战性的边依赖节点分类（edge-dependent node classification, ENC）任务，其中节点标签因超边而异，需要建模节点-边对互动。现有基于消息 passing（message passing）的解决方案存在非自适应表示大小、非自适应消息以及节点或边间互动不足的局限，CoNHD通过将边内和节点内互动建模为多输入多输出函数，并采用在节点-边联合表示（node-edge co-representations）上的超图扩散过程（hypergraph diffusion process）来克服这些问题。实验结果显示，CoNHD在ENC任务上表现出色，具有较高的有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14286v2",
      "published_date": "2024-05-23 08:01:25 UTC",
      "updated_date": "2024-10-02 21:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:12:54.220562"
    },
    {
      "arxiv_id": "2405.14273v1",
      "title": "A fast algorithm to minimize prediction loss of the optimal solution in inverse optimization problem of MILP",
      "title_zh": "翻译失败",
      "authors": [
        "Akira Kitaoka"
      ],
      "abstract": "This paper tackles the problem of minimizing the prediction loss of the\noptimal solution (PLS) of the MILP with given data, which is one of the inverse\noptimization problems. While existing methods can approximately solve this\nproblem, their implementation in the high-dimensional case to minimize the PLS\nis computationally expensive because they are inefficient in reducing the\nprediction loss of weights (PLW). We propose a fast algorithm for minimizing\nthe PLS of MILP. To demonstrate this property, we attribute the problem of\nminimizing the PLS to that of minimizing the suboptimality loss (SL), which is\nconvex. If the PLS does not vanish, we can adapt the SL to have the estimated\nloss (SPO loss) with a positive lower bound, which enables us to evaluate the\nPLW. Consequently, we prove that the proposed algorithm can effectively reduce\nthe PLW and achieve the minimum value of PLS. Our numerical experiments\ndemonstrated that our algorithm successfully achieved the minimum PLS. Compared\nto existing methods, our algorithm exhibited a smaller dimensionality effect\nand minimized the PLS in less than 1/7 the number of iterations. Especially in\nhigh dimensions, our algorithm significantly improved the PLS by more than two\norders of magnitude compared to existing algorithms.",
      "tldr_zh": "该论文针对混合整数线性规划 (MILP) 的逆优化问题，提出了一种快速算法来最小化最优解的预测损失 (PLS)，以解决现有方法在高维数据下计算效率低的问题。算法将 PLS 问题归结为最小化子最优性损失 (SL)，后者为凸优化问题，并通过调整 SL 以包含带正下界的 SPO 损失，从而有效减少权重预测损失 (PLW)。实验结果表明，该算法在高维场景下比现有方法迭代次数少于1/7，且 PLS 改善超过两个数量级，显著提升了优化效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages; comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2405.14273v1",
      "published_date": "2024-05-23 07:51:05 UTC",
      "updated_date": "2024-05-23 07:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:13:06.043942"
    },
    {
      "arxiv_id": "2405.14270v1",
      "title": "Sparse $L^1$-Autoencoders for Scientific Data Compression",
      "title_zh": "用于科学数据压缩的稀疏 L^1-自动编码器",
      "authors": [
        "Matthias Chung",
        "Rick Archibald",
        "Paul Atzberger",
        "Jack Michael Solomon"
      ],
      "abstract": "Scientific datasets present unique challenges for machine learning-driven\ncompression methods, including more stringent requirements on accuracy and\nmitigation of potential invalidating artifacts. Drawing on results from\ncompressed sensing and rate-distortion theory, we introduce effective data\ncompression methods by developing autoencoders using high dimensional latent\nspaces that are $L^1$-regularized to obtain sparse low dimensional\nrepresentations. We show how these information-rich latent spaces can be used\nto mitigate blurring and other artifacts to obtain highly effective data\ncompression methods for scientific data. We demonstrate our methods for short\nangle scattering (SAS) datasets showing they can achieve compression ratios\naround two orders of magnitude and in some cases better. Our compression\nmethods show promise for use in addressing current bottlenecks in transmission,\nstorage, and analysis in high-performance distributed computing environments.\nThis is central to processing the large volume of SAS data being generated at\nshared experimental facilities around the world to support scientific\ninvestigations. Our approaches provide general ways for obtaining specialized\ncompression methods for targeted scientific datasets.",
      "tldr_zh": "这篇论文提出了 Sparse $L^1$-Autoencoders 的方法，用于科学数据压缩，以应对数据准确性和伪影（如模糊）等挑战。作者基于 compressed sensing 和 rate-distortion theory 开发了高维潜空间的自动编码器，通过 $L^1$ 正则化获得稀疏低维表示，从而减少伪影并提升压缩效率。在 short angle scattering (SAS) 数据集的实验中，该方法实现了约两个数量级的压缩比，有时甚至更高。该方法有助于解决高性能分布式计算环境中的数据传输、存储和分析瓶颈，并为针对特定科学数据集的压缩提供通用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14270v1",
      "published_date": "2024-05-23 07:48:00 UTC",
      "updated_date": "2024-05-23 07:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:13:18.327748"
    },
    {
      "arxiv_id": "2405.14268v1",
      "title": "Multi-Representation Genetic Programming: A Case Study on Tree-based and Linear Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixing Huang",
        "Yi Mei",
        "Fangfang Zhang",
        "Mengjie Zhang",
        "Wolfgang Banzhaf"
      ],
      "abstract": "Existing genetic programming (GP) methods are typically designed based on a\ncertain representation, such as tree-based or linear representations. These\nrepresentations show various pros and cons in different domains. However, due\nto the complicated relationships among representation and fitness landscapes of\nGP, it is hard to intuitively determine which GP representation is the most\nsuitable for solving a certain problem. Evolving programs (or models) with\nmultiple representations simultaneously can alternatively search on different\nfitness landscapes since representations are highly related to the search space\nthat essentially defines the fitness landscape. Fully using the latent\nsynergies among different GP individual representations might be helpful for GP\nto search for better solutions. However, existing GP literature rarely\ninvestigates the simultaneous effective use of evolving multiple\nrepresentations. To fill this gap, this paper proposes a multi-representation\nGP algorithm based on tree-based and linear representations, which are two\ncommonly used GP representations. In addition, we develop a new\ncross-representation crossover operator to harness the interplay between\ntree-based and linear representations. Empirical results show that navigating\nthe learned knowledge between basic tree-based and linear representations\nsuccessfully improves the effectiveness of GP with solely tree-based or linear\nrepresentation in solving symbolic regression and dynamic job shop scheduling\nproblems.",
      "tldr_zh": "这篇论文提出了一种多表示遗传编程(GP)算法，通过同时使用树状和线性表示来进化程序，从而探索不同的适应度景观并利用它们之间的协同作用，以解决单一表示在不同问题中的局限性。论文开发了一个新的跨表示交叉操作符，用于增强树状和线性表示之间的知识交互。实验结果表明，该算法在符号回归和动态作业车间调度问题上，比仅采用树状或线性表示的GP方法更有效。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14268v1",
      "published_date": "2024-05-23 07:47:06 UTC",
      "updated_date": "2024-05-23 07:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:13:28.986271"
    },
    {
      "arxiv_id": "2405.14267v2",
      "title": "A Gap in Time: The Challenge of Processing Heterogeneous IoT Data in Digitalized Buildings",
      "title_zh": "时间中的差距：处理异构物联网数据在数字化建筑中的挑战",
      "authors": [
        "Xiachong Lin",
        "Arian Prabowo",
        "Imran Razzak",
        "Hao Xue",
        "Matthew Amos",
        "Sam Behrens",
        "Flora D. Salim"
      ],
      "abstract": "The increasing demand for sustainable energy solutions has driven the\nintegration of digitalized buildings into the power grid, leveraging\nInternet-of-Things (IoT) technologies to enhance energy efficiency and\noperational performance. Despite their potential, effectively utilizing IoT\npoint data within deep-learning frameworks presents significant challenges,\nprimarily due to its inherent heterogeneity. This study investigates the\ndiverse dimensions of IoT data heterogeneity in both intra-building and\ninter-building contexts, examining their implications for predictive modeling.\nA benchmarking analysis of state-of-the-art time series models highlights their\nperformance on this complex dataset. The results emphasize the critical need\nfor multi-modal data integration, domain-informed modeling, and automated data\nengineering pipelines. Additionally, the study advocates for collaborative\nefforts to establish high-quality public datasets, which are essential for\nadvancing intelligent and sustainable energy management systems in digitalized\nbuildings.",
      "tldr_zh": "这篇论文探讨了在数字化建筑中处理异质 IoT 数据（heterogeneous IoT data）的挑战，这些数据异质性主要体现在建筑内部和建筑之间，导致深度学习框架在预测建模中面临困难。研究通过调查数据异质性的各种维度，并对最先进的时间序列模型（time series models）进行基准测试，突出了多模态数据整合（multi-modal data integration）、基于领域的建模（domain-informed modeling）和自动化数据工程管道（automated data engineering pipelines）的必要性。最终，论文强调了建立高质量公共数据集的紧迫性，以推动智能和可持续的能源管理系统的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 figures, 1 tables, 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.14267v2",
      "published_date": "2024-05-23 07:45:48 UTC",
      "updated_date": "2024-11-20 06:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:13:41.965821"
    },
    {
      "arxiv_id": "2405.14265v1",
      "title": "Deep Reinforcement Learning for 5*5 Multiplayer Go",
      "title_zh": "翻译失败",
      "authors": [
        "Brahim Driss",
        "Jérôme Arjonilla",
        "Hui Wang",
        "Abdallah Saffidine",
        "Tristan Cazenave"
      ],
      "abstract": "In recent years, much progress has been made in computer Go and most of the\nresults have been obtained thanks to search algorithms (Monte Carlo Tree\nSearch) and Deep Reinforcement Learning (DRL). In this paper, we propose to use\nand analyze the latest algorithms that use search and DRL (AlphaZero and\nDescent algorithms) to automatically learn to play an extended version of the\ngame of Go with more than two players. We show that using search and DRL we\nwere able to improve the level of play, even though there are more than two\nplayers.",
      "tldr_zh": "本论文探讨了深度强化学习(DRL)应用于5x5多玩家围棋的潜力，分析了搜索算法（如Monte Carlo Tree Search）和DRL算法（如AlphaZero和Descent算法）在多玩家游戏中的表现。作者通过这些算法自动训练AI学习扩展版围棋，结果显示AI的游戏水平得到显著提升，即使在超过两个玩家的复杂场景下。整体研究证明了DRL结合搜索技术的有效性，为多代理游戏AI的发展提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in EvoApps at Evostar2023",
      "pdf_url": "http://arxiv.org/pdf/2405.14265v1",
      "published_date": "2024-05-23 07:44:24 UTC",
      "updated_date": "2024-05-23 07:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:13:53.601126"
    },
    {
      "arxiv_id": "2405.14264v2",
      "title": "Reassessing Evaluation Functions in Algorithmic Recourse: An Empirical Study from a Human-Centered Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Tomu Tominaga",
        "Naomi Yamashita",
        "Takeshi Kurashima"
      ],
      "abstract": "In this study, we critically examine the foundational premise of algorithmic\nrecourse - a process of generating counterfactual action plans (i.e.,\nrecourses) assisting individuals to reverse adverse decisions made by AI\nsystems. The assumption underlying algorithmic recourse is that individuals\naccept and act on recourses that minimize the gap between their current and\ndesired states. This assumption, however, remains empirically unverified. To\naddress this issue, we conducted a user study with 362 participants and\nassessed whether minimizing the distance function, a metric of the gap between\nthe current and desired states, indeed prompts them to accept and act upon\nsuggested recourses. Our findings reveal a nuanced landscape: participants'\nacceptance of recourses did not correlate with the recourse distance. Moreover,\nparticipants' willingness to act upon recourses peaked at the minimal recourse\ndistance but was otherwise constant. These findings cast doubt on the\nprevailing assumption of algorithmic recourse research and signal the need to\nrethink the evaluation functions to pave the way for human-centered recourse\ngeneration.",
      "tldr_zh": "本研究重新评估了算法补救（algorithmic recourse）的评估函数，质疑其核心假设，即最小化当前状态与期望状态的距离函数（distance function）会促使人们接受和行动逆转AI决策的建议。研究者通过一项涉及362名参与者的用户研究，检验了这一假设的影响。结果发现，参与者的接受度与距离函数无关，而行动意愿仅在最小距离时达到峰值。这些发现强调了需要重新设计评估函数，以推动更注重人文视角的算法补救方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IJCAI 2024 (this is the extended version with\n  supplementary materials)",
      "pdf_url": "http://arxiv.org/pdf/2405.14264v2",
      "published_date": "2024-05-23 07:43:24 UTC",
      "updated_date": "2024-08-03 12:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:14:05.213792"
    },
    {
      "arxiv_id": "2405.14260v2",
      "title": "Graph Sparsification via Mixture of Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Guibin Zhang",
        "Xiangguo Sun",
        "Yanwei Yue",
        "Chonghe Jiang",
        "Kun Wang",
        "Tianlong Chen",
        "Shirui Pan"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated superior performance across\nvarious graph learning tasks but face significant computational challenges when\napplied to large-scale graphs. One effective approach to mitigate these\nchallenges is graph sparsification, which involves removing non-essential edges\nto reduce computational overhead. However, previous graph sparsification\nmethods often rely on a single global sparsity setting and uniform pruning\ncriteria, failing to provide customized sparsification schemes for each node's\ncomplex local context. In this paper, we introduce Mixture-of-Graphs (MoG),\nleveraging the concept of Mixture-of-Experts (MoE), to dynamically select\ntailored pruning solutions for each node. Specifically, MoG incorporates\nmultiple sparsifier experts, each characterized by unique sparsity levels and\npruning criteria, and selects the appropriate experts for each node.\nSubsequently, MoG performs a mixture of the sparse graphs produced by different\nexperts on the Grassmann manifold to derive an optimal sparse graph. One\nnotable property of MoG is its entirely local nature, as it depends on the\nspecific circumstances of each individual node. Extensive experiments on four\nlarge-scale OGB datasets and two superpixel datasets, equipped with five GNN\nbackbones, demonstrate that MoG (I) identifies subgraphs at higher sparsity\nlevels ($8.67\\%\\sim 50.85\\%$), with performance equal to or better than the\ndense graph, (II) achieves $1.47-2.62\\times$ speedup in GNN inference with\nnegligible performance drop, and (III) boosts ``top-student'' GNN performance\n($1.02\\%\\uparrow$ on RevGNN+\\textsc{ogbn-proteins} and $1.74\\%\\uparrow$ on\nDeeperGCN+\\textsc{ogbg-ppa}).",
      "tldr_zh": "本论文提出 Mixture-of-Graphs (MoG) 方法，借鉴 Mixture-of-Experts (MoE) 的概念，针对 Graph Neural Networks (GNNs) 在大规模图上的计算挑战，提供动态的节点级定制稀疏化方案。MoG 包含多个 sparsifier experts，每个具有独特的稀疏水平和修剪标准，通过在 Grassmann manifold 上混合不同 experts 生成的稀疏图，实现对每个节点的本地化优化。实验结果显示，MoG 在四个 OGB 数据集和两个 superpixel 数据集上，实现了高达 8.67%~50.85% 的稀疏水平，同时性能不逊于或优于稠密图，并为 GNN 推理带来 1.47-2.62 倍加速，同时提升了特定 GNN 模型的性能（如 RevGNN+ogbn-proteins 上提升 1.02%）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14260v2",
      "published_date": "2024-05-23 07:40:21 UTC",
      "updated_date": "2024-10-03 12:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:14:18.822159"
    },
    {
      "arxiv_id": "2405.14259v3",
      "title": "Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with LLMs for Multi-modal Text Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Chan-Jan Hsu",
        "Yi-Chang Chen",
        "Feng-Ting Liao",
        "Pei-Chen Ho",
        "Yu-Hsiang Wang",
        "Po-Chun Hsu",
        "Da-shan Shiu"
      ],
      "abstract": "We introduce \"Generative Fusion Decoding\" (GFD), a novel shallow fusion\nframework, utilized to integrate Large Language Models (LLMs) into multi-modal\ntext recognition systems such as automatic speech recognition (ASR) and optical\ncharacter recognition (OCR). We derive the formulas necessary to enable GFD to\noperate across mismatched token spaces of different models by mapping text\ntoken space to byte token space, enabling seamless fusion during the decoding\nprocess. The framework is plug-and-play, compatible with various\nauto-regressive models, and does not require re-training for feature alignment,\nthus overcoming limitations of previous fusion techniques. We highlight three\nmain advantages of GFD: First, by simplifying the complexity of aligning\ndifferent model sample spaces, GFD allows LLMs to correct errors in tandem with\nthe recognition model, reducing computation latencies. Second, the in-context\nlearning ability of LLMs is fully capitalized by GFD, increasing robustness in\nlong-form speech recognition and instruction aware speech recognition. Third,\nGFD enables fusing recognition models deficient in Chinese text recognition\nwith LLMs extensively trained on Chinese. Our evaluation demonstrates that GFD\nsignificantly improves performance in ASR and OCR tasks, with ASR reaching\nstate-of-the-art in the NTUML2021 benchmark. GFD provides a significant step\nforward in model integration, offering a unified solution that could be widely\napplicable to leveraging existing pre-trained models through step by step\nfusion.",
      "tldr_zh": "本研究提出了 Generative Fusion Decoding (GFD)，一种新型浅融合框架，用于将 Large Language Models (LLMs) 整合到多模态文本识别系统，如 automatic speech recognition (ASR) 和 optical character recognition (OCR) 中。\nGFD 通过映射文本标记空间到字节标记空间，实现不同模型的无缝融合，无需重新训练，从而简化对齐复杂性、允许 LLMs 实时纠正错误，并充分利用 LLMs 的 in-context 学习能力以提升长形式语音识别和中文文本处理。\n实验结果表明，GFD 在 ASR 和 OCR 任务上显著提升性能，在 NTUML2021 基准上达到最先进水平，为利用预训练模型的步进融合提供了一个统一的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14259v3",
      "published_date": "2024-05-23 07:39:42 UTC",
      "updated_date": "2024-06-02 16:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:14:29.904246"
    },
    {
      "arxiv_id": "2405.14256v1",
      "title": "ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Yefei He",
        "Luoming Zhang",
        "Weijia Wu",
        "Jing Liu",
        "Hong Zhou",
        "Bohan Zhuang"
      ],
      "abstract": "KV cache stores key and value states from previous tokens to avoid\nre-computation, yet it demands substantial storage space, especially for long\nsequences. Adaptive KV cache compression seeks to discern the saliency of\ntokens, preserving vital information while aggressively compressing those of\nless importance. However, previous methods of this approach exhibit significant\nperformance degradation at high compression ratios due to inaccuracies in\nidentifying salient tokens. In this paper, we present ZipCache, an accurate and\nefficient KV cache quantization method for LLMs. First, we construct a strong\nbaseline for quantizing KV cache. Through the proposed channel-separable\ntokenwise quantization scheme, the memory overhead of quantization parameters\nare substantially reduced compared to fine-grained groupwise quantization. To\nenhance the compression ratio, we propose normalized attention score as an\neffective metric for identifying salient tokens by considering the lower\ntriangle characteristics of the attention matrix. Moreover, we develop an\nefficient approximation method that decouples the saliency metric from full\nattention scores, enabling compatibility with fast attention implementations\nlike FlashAttention. Extensive experiments demonstrate that ZipCache achieves\nsuperior compression ratios, fast generation speed and minimal performance\nlosses compared with previous KV cache compression methods. For instance, when\nevaluating Mistral-7B model on GSM8k dataset, ZipCache is capable of\ncompressing the KV cache by $4.98\\times$, with only a $0.38\\%$ drop in\naccuracy. In terms of efficiency, ZipCache also showcases a $37.3\\%$ reduction\nin prefill-phase latency, a $56.9\\%$ reduction in decoding-phase latency, and a\n$19.8\\%$ reduction in GPU memory usage when evaluating LLaMA3-8B model with a\ninput length of $4096$.",
      "tldr_zh": "这篇论文提出了 ZipCache，一种针对大型语言模型 (LLMs) 的准确且高效 KV cache 量化方法，以解决现有压缩技术在高压缩率下因关键 token 识别不准而导致性能下降的问题。ZipCache 通过 channel-separable tokenwise quantization 方案显著减少量化参数的内存开销，并引入 normalized attention score 作为识别 salient tokens 的有效指标，同时开发了与 FlashAttention 兼容的 saliency metric 近似方法，以提升压缩效率。实验结果显示，ZipCache 在 Mistral-7B 模型上 GSM8k 数据集实现了 4.98 倍 KV cache 压缩，仅损失 0.38% 准确率；此外，在 LLaMA3-8B 模型上，它减少了 37.3% 预填充延迟、56.9% 解码延迟和 19.8% GPU 内存使用，展示了优越的性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.14256v1",
      "published_date": "2024-05-23 07:37:16 UTC",
      "updated_date": "2024-05-23 07:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:14:42.278016"
    },
    {
      "arxiv_id": "2405.14244v2",
      "title": "Tell me why: Training preferences-based RL with human preferences and step-level explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Karalus"
      ],
      "abstract": "Human-in-the-loop reinforcement learning allows the training of agents\nthrough various interfaces, even for non-expert humans. Recently,\npreference-based methods (PbRL), where the human has to give his preference\nover two trajectories, increased in popularity since they allow training in\ndomains where more direct feedback is hard to formulate. However, the current\nPBRL methods have limitations and do not provide humans with an expressive\ninterface for giving feedback. With this work, we propose a new\npreference-based learning method that provides humans with a more expressive\ninterface to provide their preference over trajectories and a factual\nexplanation (or annotation of why they have this preference). These\nexplanations allow the human to explain what parts of the trajectory are most\nrelevant for the preference. We allow the expression of the explanations over\nindividual trajectory steps. We evaluate our method in various simulations\nusing a simulated human oracle (with realistic restrictions), and our results\nshow that our extended feedback can improve the speed of learning.",
      "tldr_zh": "该研究提出了一种新的偏好-based reinforcement learning (PbRL) 方法，允许人类在训练过程中提供对轨迹的偏好选择以及步-level explanations，从而提升反馈的表达性和准确性。这种方法通过让人类标注偏好背后的具体步骤，帮助代理更好地理解关键决策因素。在模拟环境中进行的实验表明，该扩展反馈机制能显著加速学习过程，改善了传统 PbRL 的局限性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Workshop on Reinforcement Learning Beyond Rewards @ Reinforcement\n  Learning Conference (2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.14244v2",
      "published_date": "2024-05-23 07:23:33 UTC",
      "updated_date": "2024-08-05 12:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:14:53.370664"
    },
    {
      "arxiv_id": "2405.14241v1",
      "title": "NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation",
      "title_zh": "NeuroGauss4D-PCI：4D 神经场和高斯变形场用于点云插值",
      "authors": [
        "Chaokang Jiang",
        "Dalong Du",
        "Jiuming Liu",
        "Siting Zhu",
        "Zhenqiang Liu",
        "Zhuang Ma",
        "Zhujin Liang",
        "Jie Zhou"
      ],
      "abstract": "Point Cloud Interpolation confronts challenges from point sparsity, complex\nspatiotemporal dynamics, and the difficulty of deriving complete 3D point\nclouds from sparse temporal information. This paper presents NeuroGauss4D-PCI,\nwhich excels at modeling complex non-rigid deformations across varied dynamic\nscenes. The method begins with an iterative Gaussian cloud soft clustering\nmodule, offering structured temporal point cloud representations. The proposed\ntemporal radial basis function Gaussian residual utilizes Gaussian parameter\ninterpolation over time, enabling smooth parameter transitions and capturing\ntemporal residuals of Gaussian distributions. Additionally, a 4D Gaussian\ndeformation field tracks the evolution of these parameters, creating continuous\nspatiotemporal deformation fields. A 4D neural field transforms low-dimensional\nspatiotemporal coordinates ($x,y,z,t$) into a high-dimensional latent space.\nFinally, we adaptively and efficiently fuse the latent features from neural\nfields and the geometric features from Gaussian deformation fields.\nNeuroGauss4D-PCI outperforms existing methods in point cloud frame\ninterpolation, delivering leading performance on both object-level (DHB) and\nlarge-scale autonomous driving datasets (NL-Drive), with scalability to\nauto-labeling and point cloud densification tasks. The source code is released\nat https://github.com/jiangchaokang/NeuroGauss4D-PCI.",
      "tldr_zh": "本论文提出NeuroGauss4D-PCI方法，用于解决点云插值中的点稀疏、复杂时空动态和从稀疏信息获取完整3D点云的挑战。该方法结合迭代Gaussian云软聚类模块、临时径向基函数Gaussian残差、4D Gaussian变形场和4D神经场，来生成结构化的时间点云表示并实现平滑时空变形和特征融合。实验结果显示，NeuroGauss4D-PCI在DHB和NL-Drive数据集上超越现有方法，提供领先的点云帧插值性能，并扩展到自动标注和点云稠密化任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2405.14241v1",
      "published_date": "2024-05-23 07:21:01 UTC",
      "updated_date": "2024-05-23 07:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:15:06.585643"
    },
    {
      "arxiv_id": "2406.00019v3",
      "title": "EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively Exploring Electronic Health Records",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehee Ryu",
        "Seonhee Cho",
        "Gyubok Lee",
        "Edward Choi"
      ],
      "abstract": "In this paper, we introduce EHR-SeqSQL, a novel sequential text-to-SQL\ndataset for Electronic Health Record (EHR) databases. EHR-SeqSQL is designed to\naddress critical yet underexplored aspects in text-to-SQL parsing:\ninteractivity, compositionality, and efficiency. To the best of our knowledge,\nEHR-SeqSQL is not only the largest but also the first medical text-to-SQL\ndataset benchmark to include sequential and contextual questions. We provide a\ndata split and the new test set designed to assess compositional generalization\nability. Our experiments demonstrate the superiority of a multi-turn approach\nover a single-turn approach in learning compositionality. Additionally, our\ndataset integrates specially crafted tokens into SQL queries to improve\nexecution efficiency. With EHR-SeqSQL, we aim to bridge the gap between\npractical needs and academic research in the text-to-SQL domain. EHR-SeqSQL is\navailable at https://github.com/seonhee99/EHR-SeqSQL.",
      "tldr_zh": "本文提出EHR-SeqSQL，这是一个针对电子健康记录(EHR)数据库的顺序文本到SQL数据集，旨在解决文本-to-SQL解析中的互动性、组合性和效率问题。该数据集是目前最大的第一个包含顺序和上下文问题的医疗基准，并提供数据分割和测试集以评估组合泛化能力。实验结果显示，多轮方法在学习组合性方面优于单轮方法，同时通过整合特殊标记提升了SQL查询的执行效率。EHR-SeqSQL的目标是桥接实际应用与学术研究的差距，并已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2406.00019v3",
      "published_date": "2024-05-23 07:14:21 UTC",
      "updated_date": "2024-07-30 10:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:15:18.742109"
    },
    {
      "arxiv_id": "2405.14230v1",
      "title": "Boosting Medical Image-based Cancer Detection via Text-guided Supervision from Reports",
      "title_zh": "通过报告文本引导",
      "authors": [
        "Guangyu Guo",
        "Jiawen Yao",
        "Yingda Xia",
        "Tony C. W. Mok",
        "Zhilin Zheng",
        "Junwei Han",
        "Le Lu",
        "Dingwen Zhang",
        "Jian Zhou",
        "Ling Zhang"
      ],
      "abstract": "The absence of adequately sufficient expert-level tumor annotations hinders\nthe effectiveness of supervised learning based opportunistic cancer screening\non medical imaging. Clinical reports (that are rich in descriptive textual\ndetails) can offer a \"free lunch'' supervision information and provide tumor\nlocation as a type of weak label to cope with screening tasks, thus saving\nhuman labeling workloads, if properly leveraged. However, predicting cancer\nonly using such weak labels can be very changeling since tumors are usually\npresented in small anatomical regions compared to the whole 3D medical scans.\nWeakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level\ntumor annotations and incorporates alongside a substantial number of medical\nimages that have only off-the-shelf clinical reports, which may strike a good\nbalance between minimizing expert annotation workload and optimizing screening\nefficacy. In this paper, we propose a novel text-guided learning method to\nachieve highly accurate cancer detection results. Through integrating\ndiagnostic and tumor location text prompts into the text encoder of a\nvision-language model (VLM), optimization of weakly supervised learning can be\neffectively performed in the latent space of VLM, thereby enhancing the\nstability of training. Our approach can leverage clinical knowledge by\nlarge-scale pre-trained VLM to enhance generalization ability, and produce\nreliable pseudo tumor masks to improve cancer detection. Our extensive\nquantitative experimental results on a large-scale cancer dataset, including\n1,651 unique patients, validate that our approach can reduce human annotation\nefforts by at least 70% while maintaining comparable cancer detection accuracy\nto competing fully supervised methods (AUC value 0.961 versus 0.966).",
      "tldr_zh": "该研究针对医疗图像癌症检测中的标注不足问题，提出了一种基于临床报告的文本引导监督方法，利用报告中的描述性文本作为弱标签（weak labels），结合弱半监督学习（WSSL）来减少专家标注工作量。方法通过将诊断和肿瘤位置文本提示整合到视觉语言模型（VLM）的文本编码器中，在VLM的潜在空间优化训练，生成可靠的伪肿瘤掩码，并利用预训练VLM的临床知识提升泛化能力。实验结果显示，在包含1,651个患者的庞大数据集上，该方法减少了至少70%的标注努力，同时保持与全监督方法相当的检测准确性（AUC值0.961 vs 0.966）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14230v1",
      "published_date": "2024-05-23 07:03:38 UTC",
      "updated_date": "2024-05-23 07:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:15:30.910008"
    },
    {
      "arxiv_id": "2405.14226v2",
      "title": "Variational Delayed Policy Optimization",
      "title_zh": "变分延迟策略优化",
      "authors": [
        "Qingyuan Wu",
        "Simon Sinong Zhan",
        "Yixuan Wang",
        "Yuhui Wang",
        "Chung-Wei Lin",
        "Chen Lv",
        "Qi Zhu",
        "Chao Huang"
      ],
      "abstract": "In environments with delayed observation, state augmentation by including\nactions within the delay window is adopted to retrieve Markovian property to\nenable reinforcement learning (RL). However, state-of-the-art (SOTA) RL\ntechniques with Temporal-Difference (TD) learning frameworks often suffer from\nlearning inefficiency, due to the significant expansion of the augmented state\nspace with the delay. To improve learning efficiency without sacrificing\nperformance, this work introduces a novel framework called Variational Delayed\nPolicy Optimization (VDPO), which reformulates delayed RL as a variational\ninference problem. This problem is further modelled as a two-step iterative\noptimization problem, where the first step is TD learning in the delay-free\nenvironment with a small state space, and the second step is behaviour cloning\nwhich can be addressed much more efficiently than TD learning. We not only\nprovide a theoretical analysis of VDPO in terms of sample complexity and\nperformance, but also empirically demonstrate that VDPO can achieve consistent\nperformance with SOTA methods, with a significant enhancement of sample\nefficiency (approximately 50\\% less amount of samples) in the MuJoCo benchmark.",
      "tldr_zh": "本文提出Variational Delayed Policy Optimization (VDPO)，一种新型框架，用于解决延迟观察环境中强化学习 (RL) 的学习效率问题，将延迟RL重新表述为变分推理问题。VDPO 通过两步迭代优化实现：第一步在无延迟环境进行Temporal-Difference (TD) 学习，以处理小状态空间；第二步采用行为克隆方法，提升整体效率。实验结果显示，在MuJoCo benchmark上，VDPO 与SOTA 方法性能相当，但样本效率提高了约50%，并提供了理论分析支持其样本复杂度和性能优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2405.14226v2",
      "published_date": "2024-05-23 06:57:04 UTC",
      "updated_date": "2024-10-21 20:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:15:43.210875"
    },
    {
      "arxiv_id": "2405.14219v2",
      "title": "Understanding the Training and Generalization of Pretrained Transformer for Sequential Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhao Wang",
        "Yu Pan",
        "Fupeng Sun",
        "Shang Liu",
        "Kalyan Talluri",
        "Guanting Chen",
        "Xiaocheng Li"
      ],
      "abstract": "In this paper, we consider the supervised pre-trained transformer for a class\nof sequential decision-making problems. The class of considered problems is a\nsubset of the general formulation of reinforcement learning in that there is no\ntransition probability matrix; though seemingly restrictive, the subset class\nof problems covers bandits, dynamic pricing, and newsvendor problems as special\ncases. Such a structure enables the use of optimal actions/decisions in the\npre-training phase, and the usage also provides new insights for the training\nand generalization of the pre-trained transformer. We first note the training\nof the transformer model can be viewed as a performative prediction problem,\nand the existing methods and theories largely ignore or cannot resolve an\nout-of-distribution issue. We propose a natural solution that includes the\ntransformer-generated action sequences in the training procedure, and it enjoys\nbetter properties both numerically and theoretically. The availability of the\noptimal actions in the considered tasks also allows us to analyze the\nproperties of the pre-trained transformer as an algorithm and explains why it\nmay lack exploration and how this can be automatically resolved. Numerically,\nwe categorize the advantages of pre-trained transformers over the structured\nalgorithms such as UCB and Thompson sampling into three cases: (i) it better\nutilizes the prior knowledge in the pre-training data; (ii) it can elegantly\nhandle the misspecification issue suffered by the structured algorithms; (iii)\nfor short time horizon such as $T\\le50$, it behaves more greedy and enjoys much\nbetter regret than the structured algorithms designed for asymptotic\noptimality.",
      "tldr_zh": "本论文探讨了预训练 Transformer 在一类顺序决策问题（sequential decision making）中的训练和泛化，该类问题属于强化学习（reinforcement learning）的子集，没有转移概率矩阵，涵盖了 Bandits、Dynamic Pricing 和 Newsvendor 等特例。作者将 Transformer 的训练视为一个 performative prediction 问题，并指出现有方法忽略了 out-of-distribution 问题，因此提出了一种改进方案：在训练过程中纳入 Transformer 生成的动作序列，以提升数值和理论性能。利用这些任务中的最优动作，论文分析了预训练 Transformer 作为算法的属性，包括其缺乏探索性及其自动解决机制。实验结果显示，预训练 Transformer 相比结构化算法如 UCB 和 Thompson sampling，具有三大优势：更好地利用预训练数据中的先验知识、优雅处理错误指定（misspecification）问题，以及在短时间 horizon（如 T ≤ 50）时表现出更贪婪的行为并实现更低的 regret。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14219v2",
      "published_date": "2024-05-23 06:28:44 UTC",
      "updated_date": "2024-10-02 12:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:15:56.510968"
    },
    {
      "arxiv_id": "2405.14214v1",
      "title": "A Behavior-Aware Approach for Deep Reinforcement Learning in Non-stationary Environments without Known Change Points",
      "title_zh": "翻译失败",
      "authors": [
        "Zihe Liu",
        "Jie Lu",
        "Guangquan Zhang",
        "Junyu Xuan"
      ],
      "abstract": "Deep reinforcement learning is used in various domains, but usually under the\nassumption that the environment has stationary conditions like transitions and\nstate distributions. When this assumption is not met, performance suffers. For\nthis reason, tracking continuous environmental changes and adapting to\nunpredictable conditions is challenging yet crucial because it ensures that\nsystems remain reliable and flexible in practical scenarios. Our research\nintroduces Behavior-Aware Detection and Adaptation (BADA), an innovative\nframework that merges environmental change detection with behavior adaptation.\nThe key inspiration behind our method is that policies exhibit different global\nbehaviors in changing environments. Specifically, environmental changes are\nidentified by analyzing variations between behaviors using Wasserstein\ndistances without manually set thresholds. The model adapts to the new\nenvironment through behavior regularization based on the extent of changes. The\nresults of a series of experiments demonstrate better performance relative to\nseveral current algorithms. This research also indicates significant potential\nfor tackling this long-standing challenge.",
      "tldr_zh": "本研究针对深度强化学习（Deep Reinforcement Learning）在非平稳环境（Non-stationary Environments）中的性能下降问题，提出了一种无需已知变化点（without Known Change Points）的行为感知检测和适应框架（BADA）。该框架通过分析策略行为的全局变化，利用Wasserstein distances来检测环境变化，而不依赖手动阈值。随后，BADA基于变化程度进行行为正则化，以实现对新环境的快速适应。实验结果显示，该方法在多个测试场景中比现有算法表现出色，展示了其在处理这一长期挑战方面的显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14214v1",
      "published_date": "2024-05-23 06:17:26 UTC",
      "updated_date": "2024-05-23 06:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:16:16.044730"
    },
    {
      "arxiv_id": "2405.14205v4",
      "title": "Agent Planning with World Knowledge Model",
      "title_zh": "基于世界知识模型的智能体规划",
      "authors": [
        "Shuofei Qiao",
        "Runnan Fang",
        "Ningyu Zhang",
        "Yuqi Zhu",
        "Xiang Chen",
        "Shumin Deng",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen"
      ],
      "abstract": "Recent endeavors towards directly using large language models (LLMs) as agent\nmodels to execute interactive planning tasks have shown commendable results.\nDespite their achievements, however, they still struggle with brainless\ntrial-and-error in global planning and generating hallucinatory actions in\nlocal planning due to their poor understanding of the ``real'' physical world.\nImitating humans' mental world knowledge model which provides global prior\nknowledge before the task and maintains local dynamic knowledge during the\ntask, in this paper, we introduce parametric World Knowledge Model (WKM) to\nfacilitate agent planning. Concretely, we steer the agent model to\nself-synthesize knowledge from both expert and sampled trajectories. Then we\ndevelop WKM, providing prior task knowledge to guide the global planning and\ndynamic state knowledge to assist the local planning. Experimental results on\nthree complex real-world simulated datasets with three state-of-the-art\nopen-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our\nmethod can achieve superior performance compared to various strong baselines.\nBesides, we analyze to illustrate that our WKM can effectively alleviate the\nblind trial-and-error and hallucinatory action issues, providing strong support\nfor the agent's understanding of the world. Other interesting findings include:\n1) our instance-level task knowledge can generalize better to unseen tasks, 2)\nweak WKM can guide strong agent model planning, and 3) unified WKM training has\npromising potential for further development. The code is available at\nhttps://github.com/zjunlp/WKM.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在代理规划中存在的盲目试错 (brainless trial-and-error) 和幻觉动作 (hallucinatory actions) 问题，引入了参数化的 World Knowledge Model (WKM)，模仿人类心理模型提供全局先验知识和本地动态知识。WKM 通过代理模型从专家轨迹和采样轨迹中自我合成知识，从而指导全局规划和辅助本地规划。实验在三个复杂真实世界模拟数据集上，使用 Mistral-7B、Gemma-7B 和 Llama-3-8B 等开源 LLMs 进行测试，结果显示该方法优于多种强基线，并有效缓解了相关问题；此外，还发现 WKM 的实例级任务知识对未见任务有更好泛化潜力，以及弱 WKM 可指导强代理模型的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14205v4",
      "published_date": "2024-05-23 06:03:19 UTC",
      "updated_date": "2025-01-03 16:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:16:19.402669"
    },
    {
      "arxiv_id": "2405.14203v1",
      "title": "GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Thao Nguyen",
        "Tiara Torres-Flores",
        "Changhyun Hwang",
        "Carl Edwards",
        "Ying Diao",
        "Heng Ji"
      ],
      "abstract": "This paper presents a novel approach for predicting Power Conversion\nEfficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:\nsynergizing molecular Graphs and Language Descriptors for enhanced PCE\nprediction. Due to the lack of high-quality experimental data, we collect a\ndataset consisting of 500 pairs of OPV donor and acceptor molecules along with\ntheir corresponding PCE values, which we utilize as the training data for our\npredictive model. In this low-data regime, GLaD leverages properties learned\nfrom large language models (LLMs) pretrained on extensive scientific literature\nto enrich molecular structural representations, allowing for a multimodal\nrepresentation of molecules. GLaD achieves precise predictions of PCE, thereby\nfacilitating the synthesis of new OPV molecules with improved efficiency.\nFurthermore, GLaD showcases versatility, as it applies to a range of molecular\nproperty prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited to\nthose concerning OPV materials. Especially, GLaD proves valuable for tasks in\nlow-data regimes within the chemical space, as it enriches molecular\nrepresentations by incorporating molecular property descriptions learned from\nlarge-scale pretraining. This capability is significant in real-world\nscientific endeavors like drug and material discovery, where access to\ncomprehensive data is crucial for informed decision-making and efficient\nexploration of the chemical space.",
      "tldr_zh": "本研究提出了一种名为 GLaD 的新方法，通过整合分子 Graphs 和 Language Descriptors 来提升有机光伏（OPV）设备功率转换效率（PCE）的预测精度。面对数据不足的挑战，研究者收集了500对OPV供体和受体分子及其PCE值作为训练数据，并利用大型语言模型（LLMs）从科学文献中学习属性，以实现分子结构的 multimodal 表示，从而丰富预测模型。实验结果显示，GLaD 在低数据环境下实现了精确的PCE预测，并成功扩展到其他分子属性任务（如BBBP、BACE、ClinTox和SIDER），为药物和材料发现等领域的化学空间探索提供了高效工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "In progress",
      "pdf_url": "http://arxiv.org/pdf/2405.14203v1",
      "published_date": "2024-05-23 06:02:07 UTC",
      "updated_date": "2024-05-23 06:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:16:34.084254"
    },
    {
      "arxiv_id": "2405.14200v2",
      "title": "Awesome Multi-modal Object Tracking",
      "title_zh": "Awesome 多模态物体追踪",
      "authors": [
        "Chunhui Zhang",
        "Li Liu",
        "Hao Wen",
        "Xi Zhou",
        "Yanfeng Wang"
      ],
      "abstract": "Multi-modal object tracking (MMOT) is an emerging field that combines data\nfrom various modalities, \\eg vision (RGB), depth, thermal infrared, event,\nlanguage and audio, to estimate the state of an arbitrary object in a video\nsequence. It is of great significance for many applications such as autonomous\ndriving and intelligent surveillance. In recent years, MMOT has received more\nand more attention. However, existing MMOT algorithms mainly focus on two\nmodalities (\\eg RGB+depth, RGB+thermal infrared, and RGB+language). To leverage\nmore modalities, some recent efforts have been made to learn a unified visual\nobject tracking model for any modality. Additionally, some large-scale\nmulti-modal tracking benchmarks have been established by simultaneously\nproviding more than two modalities, such as vision-language-audio (\\eg\nWebUAV-3M) and vision-depth-language (\\eg UniMod1K). To track the latest\nprogress in MMOT, we conduct a comprehensive investigation in this report.\nSpecifically, we first divide existing MMOT tasks into five main categories,\n\\ie RGBL tracking, RGBE tracking, RGBD tracking, RGBT tracking, and\nmiscellaneous (RGB+X), where X can be any modality, such as language, depth,\nand event. Then, we analyze and summarize each MMOT task, focusing on widely\nused datasets and mainstream tracking algorithms based on their technical\nparadigms (\\eg self-supervised learning, prompt learning, knowledge\ndistillation, generative models, and state space models). Finally, we maintain\na continuously updated paper list for MMOT at\nhttps://github.com/983632847/Awesome-Multimodal-Object-Tracking.",
      "tldr_zh": "这篇论文对多模态对象跟踪 (Multi-modal object tracking, MMOT) 进行了全面调查，强调其通过结合多种模态（如 RGB、depth、thermal infrared、event、language 和 audio）来估计视频中对象状态的重要性，尤其在自动驾驶和智能监控等应用中。论文将 MMOT 任务分为五大类，包括 RGBL tracking、RGBE tracking、RGBD tracking、RGBT tracking 和其他 (RGB+X)，并分析了常用数据集和主流算法的技术范式，如 self-supervised learning、prompt learning、knowledge distillation、generative models 和 state space models。最终，论文总结了现有算法的局限性和最新进展，并维护了一个持续更新的论文列表（https://github.com/983632847/Awesome-Multimodal-Object-Tracking），以跟踪该领域的动态。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "A continuously updated project to track the latest progress in\n  multi-modal object tracking",
      "pdf_url": "http://arxiv.org/pdf/2405.14200v2",
      "published_date": "2024-05-23 05:58:10 UTC",
      "updated_date": "2024-05-31 11:09:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:16:45.400884"
    },
    {
      "arxiv_id": "2405.14195v1",
      "title": "Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation Learning",
      "title_zh": "通过自监督辅助深度估计学习增强的对象跟踪",
      "authors": [
        "Zhenyu Wei",
        "Yujie He",
        "Zhanchuan Cai"
      ],
      "abstract": "RGB-D tracking significantly improves the accuracy of object tracking.\nHowever, its dependency on real depth inputs and the complexity involved in\nmulti-modal fusion limit its applicability across various scenarios. The\nutilization of depth information in RGB-D tracking inspired us to propose a new\nmethod, named MDETrack, which trains a tracking network with an additional\ncapability to understand the depth of scenes, through supervised or\nself-supervised auxiliary Monocular Depth Estimation learning. The outputs of\nMDETrack's unified feature extractor are fed to the side-by-side tracking head\nand auxiliary depth estimation head, respectively. The auxiliary module will be\ndiscarded in inference, thus keeping the same inference speed. We evaluated our\nmodels with various training strategies on multiple datasets, and the results\nshow an improved tracking accuracy even without real depth. Through these\nfindings we highlight the potential of depth estimation in enhancing object\ntracking performance.",
      "tldr_zh": "本研究针对 RGB-D tracking 的依赖真实深度输入和多模态融合复杂性问题，提出了一种新方法 MDETrack，通过自监督或监督的辅助 Monocular Depth Estimation 学习来增强对象跟踪性能。MDETrack 采用统一的特征提取器，将输出分别输入到跟踪头和辅助深度估计头中，并在推理阶段丢弃辅助模块，从而保持相同的推理速度。在多个数据集上进行评估，结果显示即使没有真实深度输入，该方法也能显著提高跟踪准确性。这些发现突出了深度估计在提升对象跟踪效果方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14195v1",
      "published_date": "2024-05-23 05:43:38 UTC",
      "updated_date": "2024-05-23 05:43:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:16:57.633879"
    },
    {
      "arxiv_id": "2405.14194v1",
      "title": "Graphlets correct for the topological information missed by random walks",
      "title_zh": "Graphlets 修正随机游走遗漏的拓扑信息",
      "authors": [
        "Sam F. L. Windels",
        "Noel Malod-Dognin",
        "Natasa Przulj"
      ],
      "abstract": "Random walks are widely used for mining networks due to the computational\nefficiency of computing them. For instance, graph representation learning\nlearns a d-dimensional embedding space, so that the nodes that tend to co-occur\non random walks (a proxy of being in the same network neighborhood) are close\nin the embedding space. Specific local network topology (i.e., structure)\ninfluences the co-occurrence of nodes on random walks, so random walks of\nlimited length capture only partial topological information, hence diminishing\nthe performance of downstream methods. We explicitly capture all topological\nneighborhood information and improve performance by introducing orbit\nadjacencies that quantify the adjacencies of two nodes as co-occurring on a\ngiven pair of graphlet orbits, which are symmetric positions on graphlets\n(small, connected, non-isomorphic, induced subgraphs of a large network).\nImportantly, we mathematically prove that random walks on up to k nodes capture\nonly a subset of all the possible orbit adjacencies for up to k-node graphlets.\nFurthermore, we enable orbit adjacency-based analysis of networks by developing\nan efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively\ncomputes all 28 orbit adjacency matrices for up to four-node graphlets. Note\nthat four-node graphlets suffice, because real networks are usually\nsmall-world. In large networks on around 20,000 nodes,\nGRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we\ncompare the performance of node-label predictors obtained by using the network\nembeddings based on our orbit adjacencies to those based on random walks. We\nfind that orbit adjacencies, which include those unseen by random walks,\noutperform random walk-based adjacencies, demonstrating the importance of the\ninclusion of the topological neighborhood information that is unseen by random\nwalks.",
      "tldr_zh": "这篇论文指出，随机游走（random walks）在网络表示学习中仅捕获部分拓扑信息，导致下游任务性能下降，因为它们忽略了节点的完整邻域结构。作者引入了 orbit adjacencies 概念，通过量化节点在 graphlets（小连接非同构子图）上的对称位置（orbits）来全面捕获拓扑邻域信息，并数学证明随机游走无法覆盖所有这些邻接关系。论文开发了 GRADCO 工具，能高效计算所有 28 个 up to four-node graphlets 的 orbit adjacency 矩阵，并在六个真实网络上实验验证，结果显示基于 orbit adjacencies 的节点标签预测器显著优于 random walks 方法，突显了缺失拓扑信息的负面影响。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DS",
        "cs.LG",
        "68Uxx",
        "I.5"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14194v1",
      "published_date": "2024-05-23 05:42:38 UTC",
      "updated_date": "2024-05-23 05:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:17:11.006734"
    },
    {
      "arxiv_id": "2405.14176v1",
      "title": "Certified Robustness against Sparse Adversarial Perturbations via Data Localization",
      "title_zh": "通过数据本地化实现针对稀疏对抗",
      "authors": [
        "Ambar Pal",
        "René Vidal",
        "Jeremias Sulam"
      ],
      "abstract": "Recent work in adversarial robustness suggests that natural data\ndistributions are localized, i.e., they place high probability in small volume\nregions of the input space, and that this property can be utilized for\ndesigning classifiers with improved robustness guarantees for $\\ell_2$-bounded\nperturbations. Yet, it is still unclear if this observation holds true for more\ngeneral metrics. In this work, we extend this theory to $\\ell_0$-bounded\nadversarial perturbations, where the attacker can modify a few pixels of the\nimage but is unrestricted in the magnitude of perturbation, and we show\nnecessary and sufficient conditions for the existence of $\\ell_0$-robust\nclassifiers. Theoretical certification approaches in this regime essentially\nemploy voting over a large ensemble of classifiers. Such procedures are\ncombinatorial and expensive or require complicated certification techniques. In\ncontrast, a simple classifier emerges from our theory, dubbed Box-NN, which\nnaturally incorporates the geometry of the problem and improves upon the\ncurrent state-of-the-art in certified robustness against sparse attacks for the\nMNIST and Fashion-MNIST datasets.",
      "tldr_zh": "该论文扩展了数据局部性理论，将其应用于 $\\ell_0$-bounded 稀疏对抗扰动，证明了 $\\ell_0$ 鲁棒分类器的必要和充分条件，以应对攻击者对图像少量像素的无限制修改。不同于现有的复杂投票机制，该研究提出了一种简单分类器Box-NN，该方法自然整合了问题的几何特性，提升了鲁棒性设计。实验结果显示，Box-NN在MNIST和Fashion-MNIST数据集上超过了现有状态的认证鲁棒性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14176v1",
      "published_date": "2024-05-23 05:02:00 UTC",
      "updated_date": "2024-05-23 05:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:17:32.148937"
    },
    {
      "arxiv_id": "2405.14173v3",
      "title": "Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghui Chen",
        "Daniel Fried",
        "Ufuk Topcu"
      ],
      "abstract": "Developing autonomous agents that can strategize and cooperate with humans\nunder information asymmetry is challenging without effective communication in\nnatural language. We introduce a shared-control game, where two players\ncollectively control a token in alternating turns to achieve a common objective\nunder incomplete information. We formulate a policy synthesis problem for an\nautonomous agent in this game with a human as the other player. To solve this\nproblem, we propose a communication-based approach comprising a language module\nand a planning module. The language module translates natural language messages\ninto and from a finite set of flags, a compact representation defined to\ncapture player intents. The planning module leverages these flags to compute a\npolicy using an asymmetric information-set Monte Carlo tree search with flag\nexchange algorithm we present. We evaluate the effectiveness of this approach\nin a testbed based on Gnomes at Night, a search-and-find maze board game.\nResults of human subject experiments show that communication narrows the\ninformation gap between players and enhances human-agent cooperation efficiency\nwith fewer turns.",
      "tldr_zh": "该研究探讨了在信息不对称游戏中，通过自然 language communication 实现人类-代理合作的问题，提出了一种通信驱动的方法来提升策略合成。方法包括语言模块，将自然语言消息转化为一组有限的 flags 以捕捉玩家意图，以及规划模块，利用这些 flags 通过 asymmetric information-set Monte Carlo tree search with flag exchange 算法计算代理策略。在基于 Gnomes at Night 游戏的人类实验中，结果表明通信显著缩小了信息差距，提高了合作效率，并减少了游戏回合数。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "with appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.14173v3",
      "published_date": "2024-05-23 04:58:42 UTC",
      "updated_date": "2024-06-01 20:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:17:34.572196"
    },
    {
      "arxiv_id": "2405.14170v3",
      "title": "Large Language Models-guided Dynamic Adaptation for Temporal Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiapu Wang",
        "Kai Sun",
        "Linhao Luo",
        "Wei Wei",
        "Yongli Hu",
        "Alan Wee-Chung Liew",
        "Shirui Pan",
        "Baocai Yin"
      ],
      "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing\ntemporal information to capture complex relations within a Temporal Knowledge\nGraph (TKG) to infer new knowledge. Conventional methods in TKGR typically\ndepend on deep learning algorithms or temporal logical rules. However, deep\nlearning-based TKGRs often lack interpretability, whereas rule-based TKGRs\nstruggle to effectively learn temporal rules that capture temporal patterns.\nRecently, Large Language Models (LLMs) have demonstrated extensive knowledge\nand remarkable proficiency in temporal reasoning. Consequently, the employment\nof LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing\ninterest among researchers. Nonetheless, LLMs are known to function as black\nboxes, making it challenging to comprehend their reasoning process.\nAdditionally, due to the resource-intensive nature of fine-tuning, promptly\nupdating LLMs to integrate evolving knowledge within TKGs for reasoning is\nimpractical. To address these challenges, in this paper, we propose a Large\nLanguage Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on\nTKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze\nhistorical data and extract temporal logical rules. These rules unveil temporal\npatterns and facilitate interpretable reasoning. To account for the evolving\nnature of TKGs, a dynamic adaptation strategy is proposed to update the\nLLM-generated rules with the latest events. This ensures that the extracted\nrules always incorporate the most recent knowledge and better generalize to the\npredictions on future events. Experimental results show that without the need\nof fine-tuning, LLM-DA significantly improves the accuracy of reasoning over\nseveral common datasets, providing a robust framework for TKGR tasks.",
      "tldr_zh": "这篇论文针对 Temporal Knowledge Graph Reasoning (TKGR) 的挑战，提出了一种由 Large Language Models (LLMs) 引导的动态适应方法 (LLM-DA)，以解决传统深度学习方法缺乏可解释性和规则方法难以捕捉时间模式的问题。LLM-DA 利用 LLMs 分析历史数据并提取时间逻辑规则，实现可解释的推理过程。同时，该方法引入动态适应策略，实时更新规则以整合 TKGs 中的最新事件，从而提升对未来事件的预测泛化能力。实验结果表明，LLM-DA 在无需微调的情况下，在多个常见数据集上显著提高了推理准确率，为 TKGR 任务提供了稳健框架。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14170v3",
      "published_date": "2024-05-23 04:54:37 UTC",
      "updated_date": "2024-12-30 00:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:17:46.248020"
    },
    {
      "arxiv_id": "2405.17460v1",
      "title": "Investigation of Customized Medical Decision Algorithms Utilizing Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yafeng Yan",
        "Shuyao He",
        "Zhou Yu",
        "Jiajie Yuan",
        "Ziang Liu",
        "Yan Chen"
      ],
      "abstract": "Aiming at the limitations of traditional medical decision system in\nprocessing large-scale heterogeneous medical data and realizing highly\npersonalized recommendation, this paper introduces a personalized medical\ndecision algorithm utilizing graph neural network (GNN). This research\ninnovatively integrates graph neural network technology into the medical and\nhealth field, aiming to build a high-precision representation model of patient\nhealth status by mining the complex association between patients' clinical\ncharacteristics, genetic information, living habits. In this study, medical\ndata is preprocessed to transform it into a graph structure, where nodes\nrepresent different data entities (such as patients, diseases, genes, etc.) and\nedges represent interactions or relationships between entities. The core of the\nalgorithm is to design a novel multi-scale fusion mechanism, combining the\nhistorical medical records, physiological indicators and genetic\ncharacteristics of patients, to dynamically adjust the attention allocation\nstrategy of the graph neural network, so as to achieve highly customized\nanalysis of individual cases. In the experimental part, this study selected\nseveral publicly available medical data sets for validation, and the results\nshowed that compared with traditional machine learning methods and a single\ngraph neural network model, the proposed personalized medical decision\nalgorithm showed significantly superior performance in terms of disease\nprediction accuracy, treatment effect evaluation and patient risk\nstratification.",
      "tldr_zh": "本文针对传统医疗决策系统处理大规模异构数据和实现个性化推荐的局限性，提出了一种利用Graph Neural Networks (GNN)的个性化医疗决策算法。该算法通过将医疗数据预处理为图结构（节点表示患者、疾病、基因等，边表示实体间关系），并设计多尺度融合机制，结合患者历史医疗记录、生理指标和遗传特征，动态调整GNN的注意力分配策略，实现对个体病例的高精度定制化分析。实验验证显示，该算法在公开医疗数据集上，在疾病预测准确性、治疗效果评估和患者风险分层等方面，显著优于传统机器学习方法和单一GNN模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17460v1",
      "published_date": "2024-05-23 04:30:41 UTC",
      "updated_date": "2024-05-23 04:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:17:57.740251"
    },
    {
      "arxiv_id": "2405.14161v1",
      "title": "Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models",
      "title_zh": "Self-Taught Recognizer: 面向语音基础模型的无监督适应",
      "authors": [
        "Yuchen Hu",
        "Chen Chen",
        "Chao-Han Huck Yang",
        "Chengwei Qin",
        "Pin-Yu Chen",
        "Eng Siong Chng",
        "Chao Zhang"
      ],
      "abstract": "We propose an unsupervised adaptation framework, Self-TAught Recognizer\n(STAR), which leverages unlabeled data to enhance the robustness of automatic\nspeech recognition (ASR) systems in diverse target domains, such as noise and\naccents. STAR is developed for prevalent speech foundation models based on\nTransformer-related architecture with auto-regressive decoding (e.g., Whisper,\nCanary). Specifically, we propose a novel indicator that empirically integrates\nstep-wise information during decoding to assess the token-level quality of\npseudo labels without ground truth, thereby guiding model updates for effective\nunsupervised adaptation. Experimental results show that STAR achieves an\naverage of 13.5% relative reduction in word error rate across 14 target\ndomains, and it sometimes even approaches the upper-bound performance of\nsupervised adaptation. Surprisingly, we also observe that STAR prevents the\nadapted model from the common catastrophic forgetting problem without recalling\nsource-domain data. Furthermore, STAR exhibits high data efficiency that only\nrequires less than one-hour unlabeled data, and seamless generality to\nalternative large speech models and speech translation tasks. Our code aims to\nopen source to the research communities.",
      "tldr_zh": "我们提出 STAR（Self-Taught Recognizer），一种无监督适应框架，利用无标签数据增强自动语音识别（ASR）系统的鲁棒性，针对 Transformer 架构的语音基础模型如 Whisper 和 Canary。该框架引入一个新指标，通过整合解码过程中的逐步信息来评估伪标签的 token-level 质量，从而指导有效的模型更新。实验结果显示，STAR 在 14 个目标领域平均降低了 13.5% 的 word error rate，有时接近监督适应的性能上限，同时防止灾难性遗忘，并以高数据效率（如不到一小时的无标签数据）适用于其他语音模型和任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.14161v1",
      "published_date": "2024-05-23 04:27:11 UTC",
      "updated_date": "2024-05-23 04:27:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:18:10.810583"
    },
    {
      "arxiv_id": "2405.14159v2",
      "title": "Super Tiny Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Hillier",
        "Leon Guertler",
        "Cheston Tan",
        "Palaash Agrawal",
        "Chen Ruirui",
        "Bobby Cheng"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has led to significant\nimprovements in natural language processing but also poses challenges due to\ntheir high computational and energy demands. This paper introduces a series of\nresearch efforts focused on Super Tiny Language Models (STLMs), which aim to\ndeliver high performance with significantly reduced parameter counts. We\nexplore innovative techniques such as byte-level tokenization with a pooling\nmechanism, weight tying, and efficient training strategies. These methods aim\nto significantly reduce reduce the parameter count compared to traditional\nmodels -- in future works, we aim to build on these in a way that maintains and\nimproves upon the performance of base transformer models. This series of papers\nwill explore into various subproblems, including tokenizer-free models,\nself-play based training, and alternative training objectives. We will target\nmodels with 10M, 50M, and 100M parameters. Our ultimate goal is to make\nhigh-performance language models more accessible and practical for a wide range\nof applications.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）的快速发展带来的性能提升与高计算、能源需求挑战，提出Super Tiny Language Models (STLMs)系列研究，旨在实现高性能的同时显著减少参数数量。研究探索了创新技术，包括byte-level tokenization with a pooling mechanism、weight tying和高效训练策略，以维持或提升传统Transformer模型的性能。未来工作将针对10M、50M和100M参数的模型，深入探讨子问题如tokenizer-free models、self-play based training和替代训练目标，最终使高性能语言模型更易访问和实用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14159v2",
      "published_date": "2024-05-23 04:12:49 UTC",
      "updated_date": "2024-06-26 08:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:18:21.760583"
    },
    {
      "arxiv_id": "2405.14148v1",
      "title": "Real Time Deep Learning Weapon Detection Techniques for Mitigating Lone Wolf Attacks",
      "title_zh": "用于缓解独狼攻击的实时深度学习武器检测技术",
      "authors": [
        "Kambhatla Akhila",
        "Khaled R Ahmed"
      ],
      "abstract": "Firearm Shootings and stabbings attacks are intense and result in severe\ntrauma and threat to public safety. Technology is needed to prevent lone-wolf\nattacks without human supervision. Hence designing an automatic weapon\ndetection using deep learning, is an optimized solution to localize and detect\nthe presence of weapon objects using Neural Networks. This research focuses on\nboth unified and II-stage object detectors whose resultant model not only\ndetects the presence of weapons but also classifies with respective to its\nweapon classes, including handgun, knife, revolver, and rifle, along with\nperson detection. This research focuses on (You Look Only Once) family and\nFaster RCNN family for model validation and training. Pruning and Ensembling\ntechniques were applied to YOLOv5 to enhance their speed and performance.\nmodels achieve the highest score of 78% with an inference speed of 8.1ms.\nHowever, Faster R-CNN models achieve the highest AP 89%.",
      "tldr_zh": "这篇论文提出了一种实时深度学习武器检测技术，用于缓解独狼式攻击，通过神经网络自动定位和检测武器对象，包括 handgun、knife、revolver 和 rifle，以及人员检测。研究聚焦于 YOLO 家族（如 YOLOv5）和 Faster R-CNN 家族的模型，并通过 Pruning 和 Ensembling 技术优化 YOLOv5，以提高推理速度和性能。结果表明，优化后的 YOLO 模型达到 78% 的最高分数和 8.1ms 的推理速度，而 Faster R-CNN 模型则获得 89% 的 AP，展示了其在公共安全应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14148v1",
      "published_date": "2024-05-23 03:48:26 UTC",
      "updated_date": "2024-05-23 03:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:18:34.471782"
    },
    {
      "arxiv_id": "2405.14147v1",
      "title": "Minimum number of neurons in fully connected layers of a given neural network (the first approximation)",
      "title_zh": "给定神经网络的全连接层中神经元的最小数量（第一近似）",
      "authors": [
        "Oleg I. Berngardt"
      ],
      "abstract": "This paper presents an algorithm for searching for the minimum number of\nneurons in fully connected layers of an arbitrary network solving given\nproblem, which does not require multiple training of the network with different\nnumber of neurons. The algorithm is based at training the initial wide network\nusing the cross-validation method over at least two folds. Then by using\ntruncated singular value decomposition autoencoder inserted after the studied\nlayer of trained network we search the minimum number of neurons in inference\nonly mode of the network.\n  It is shown that the minimum number of neurons in a fully connected layer\ncould be interpreted not as network hyperparameter associated with the other\nhyperparameters of the network, but as internal (latent) property of the\nsolution, determined by the network architecture, the training dataset, layer\nposition, and the quality metric used. So the minimum number of neurons can be\nestimated for each hidden fully connected layer independently. The proposed\nalgorithm is the first approximation for estimating the minimum number of\nneurons in the layer, since, on the one hand, the algorithm does not guarantee\nthat a neural network with the found number of neurons can be trained to the\nrequired quality, and on the other hand, it searches for the minimum number of\nneurons in a limited class of possible solutions.\n  The solution was tested on several datasets in classification and regression\nproblems.",
      "tldr_zh": "本文提出了一种算法，用于估计给定神经网络中 fully connected layers 的最小神经元数量，而无需多次训练网络。该算法基于 cross-validation 方法训练初始宽网络，然后通过插入 truncated singular value decomposition autoencoder 在推理模式下搜索最小神经元。研究发现，最小神经元数量并非网络超参数，而是由网络架构、训练数据集、层位置和质量指标决定的内部属性，因此可独立估计每个隐藏层。该算法作为第一近似，已在分类和回归问题的多个数据集上进行测试，但不保证用找到的数量能训练到所需质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.14147v1",
      "published_date": "2024-05-23 03:46:07 UTC",
      "updated_date": "2024-05-23 03:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:18:46.497302"
    },
    {
      "arxiv_id": "2405.14142v2",
      "title": "Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Se-eun Yoon",
        "Hyunsik Jeon",
        "Julian McAuley"
      ],
      "abstract": "We introduce a multimodal dataset where users express preferences through\nimages. These images encompass a broad spectrum of visual expressions ranging\nfrom landscapes to artistic depictions. Users request recommendations for books\nor music that evoke similar feelings to those captured in the images, and\nrecommendations are endorsed by the community through upvotes. This dataset\nsupports two recommendation tasks: title generation and multiple-choice\nselection. Our experiments with large foundation models reveal their\nlimitations in these tasks. Particularly, vision-language models show no\nsignificant advantage over language-only counterparts that use descriptions,\nwhich we hypothesize is due to underutilized visual capabilities. To better\nharness these abilities, we propose the chain-of-imagery prompting, which\nresults in notable improvements. We release our code and datasets.",
      "tldr_zh": "本文引入了一个多模态数据集，允许用户通过图像（如景观或艺术描绘）表达偏好，并请求与图像类似感觉的书籍或音乐推荐，这些推荐通过社区 upvote 获得认可。该数据集支持标题生成和多选选择两个推荐任务。实验发现，大型基础模型在这些任务中表现有限，vision-language models 未显著优于语言-only 模型，可能是由于视觉能力的未充分利用；为此，提出 chain-of-imagery prompting 方法，显著提升了性能。最后，作者发布了代码和数据集以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14142v2",
      "published_date": "2024-05-23 03:36:31 UTC",
      "updated_date": "2025-04-16 02:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:08.936241"
    },
    {
      "arxiv_id": "2405.14135v3",
      "title": "Space-aware Socioeconomic Indicator Inference with Heterogeneous Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Xingchen Zou",
        "Jiani Huang",
        "Xixuan Hao",
        "Yuhao Yang",
        "Haomin Wen",
        "Yibo Yan",
        "Chao Huang",
        "Chao Chen",
        "Yuxuan Liang"
      ],
      "abstract": "Regional socioeconomic indicators are critical across various domains, yet\ntheir acquisition can be costly. Inferring global socioeconomic indicators from\na limited number of regional samples is essential for enhancing management and\nsustainability in urban areas and human settlements. Current inference methods\ntypically rely on spatial interpolation based on the assumption of spatial\ncontinuity, which does not adequately address the complex variations present\nwithin regional spaces. In this paper, we present GeoHG, the first space-aware\nsocioeconomic indicator inference method that utilizes a heterogeneous\ngraph-based structure to represent geospace for non-continuous inference.\nExtensive experiments demonstrate the effectiveness of GeoHG in comparison to\nexisting methods, achieving an $R^2$ score exceeding 0.8 under extreme data\nscarcity with a masked ratio of 95\\%.",
      "tldr_zh": "该论文针对社会经济指标（socioeconomic indicators）的获取成本高问题，提出了一种新型方法 GeoHG，用于从有限区域样本推断全球指标。GeoHG 利用异构图（heterogeneous graphs）结构表示地理空间（geospace），实现非连续推理，从而克服传统空间插值方法的假设局限性。实验结果表明，GeoHG 在极端数据稀缺条件下（95% 掩码比）取得 R² 分数超过 0.8，显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14135v3",
      "published_date": "2024-05-23 03:19:02 UTC",
      "updated_date": "2025-02-17 07:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:11.014864"
    },
    {
      "arxiv_id": "2405.14133v1",
      "title": "Automated Loss function Search for Class-imbalanced Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Guo",
        "Kai Wu",
        "Xiaoyu Zhang",
        "Jing Liu"
      ],
      "abstract": "Class-imbalanced node classification tasks are prevalent in real-world\nscenarios. Due to the uneven distribution of nodes across different classes,\nlearning high-quality node representations remains a challenging endeavor. The\nengineering of loss functions has shown promising potential in addressing this\nissue. It involves the meticulous design of loss functions, utilizing\ninformation about the quantities of nodes in different categories and the\nnetwork's topology to learn unbiased node representations. However, the design\nof these loss functions heavily relies on human expert knowledge and exhibits\nlimited adaptability to specific target tasks. In this paper, we introduce a\nhigh-performance, flexible, and generalizable automated loss function search\nframework to tackle this challenge. Across 15 combinations of graph neural\nnetworks and datasets, our framework achieves a significant improvement in\nperformance compared to state-of-the-art methods. Additionally, we observe that\nhomophily in graph-structured data significantly contributes to the\ntransferability of the proposed framework.",
      "tldr_zh": "本文针对类别不平衡的节点分类任务，提出了一种高性能、灵活且可泛化的自动损失函数搜索框架，以克服传统损失函数设计依赖人类专家和适应性有限的问题。该框架利用节点数量、网络拓扑等信息，显著提升了图神经网络(Graph Neural Networks)中节点表示的学习质量，并在15种数据集组合上比最先进方法实现性能显著改进。此外，研究发现，图结构数据中的homophily特性大大提升了框架的可转移性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14133v1",
      "published_date": "2024-05-23 03:12:49 UTC",
      "updated_date": "2024-05-23 03:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:23.162900"
    },
    {
      "arxiv_id": "2405.14129v2",
      "title": "AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Zhao",
        "Taotian Pang",
        "Chunhui Li",
        "Zhen Wu",
        "Junjie Guo",
        "Shangyu Xing",
        "Xinyu Dai"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) are widely regarded as crucial in\nthe exploration of Artificial General Intelligence (AGI). The core of MLLMs\nlies in their capability to achieve cross-modal alignment. To attain this goal,\ncurrent MLLMs typically follow a two-phase training paradigm: the pre-training\nphase and the instruction-tuning phase. Despite their success, there are\nshortcomings in the modeling of alignment capabilities within these models.\nFirstly, during the pre-training phase, the model usually assumes that all\nimage-text pairs are uniformly aligned, but in fact the degree of alignment\nbetween different image-text pairs is inconsistent. Secondly, the instructions\ncurrently used for finetuning incorporate a variety of tasks and different\ntasks usually require different levels of alignment capabilities, but previous\nMLLMs overlook these differentiated alignment needs. To tackle these issues, we\npropose a new multimodal large language model AlignGPT. In the pre-training\nstage, instead of treating all image-text pairs equally, we divide them into\ndifferent groups according to the degrees of alignment of them. Then, the model\nis trained to learn the representations of different alignment levels. In the\ninstruction-tuning phase, we adaptively combine these representations of\nalignment levels to meet the dynamic alignment needs of different tasks.\nExtensive experimental results show that our model achieves competitive\nperformance on 12 benchmarks.",
      "tldr_zh": "该研究针对 Multimodal Large Language Models (MLLMs) 在跨模态对齐能力建模上的不足，提出了 AlignGPT 模型，以提升其在 Artificial General Intelligence (AGI) 探索中的性能。具体而言，在预训练阶段，AlignGPT 根据图像-文本对的不同对齐程度进行分组，并训练模型学习各种对齐水平的表示；在指令-tuning 阶段，该模型自适应地组合这些表示，以满足不同任务的动态对齐需求。通过这种改进方法，AlignGPT 在 12 个基准测试中取得了竞争性的性能表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14129v2",
      "published_date": "2024-05-23 03:07:56 UTC",
      "updated_date": "2024-11-23 14:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:34.556805"
    },
    {
      "arxiv_id": "2405.14126v1",
      "title": "The Disappearance of Timestep Embedding in Modern Time-Dependent Neural Networks",
      "title_zh": "现代时间依赖神经网络中时间步嵌入的消失",
      "authors": [
        "Bum Jun Kim",
        "Yoshinobu Kawahara",
        "Sang Woo Kim"
      ],
      "abstract": "Dynamical systems are often time-varying, whose modeling requires a function\nthat evolves with respect to time. Recent studies such as the neural ordinary\ndifferential equation proposed a time-dependent neural network, which provides\na neural network varying with respect to time. However, we claim that the\narchitectural choice to build a time-dependent neural network significantly\naffects its time-awareness but still lacks sufficient validation in its current\nstates. In this study, we conduct an in-depth analysis of the architecture of\nmodern time-dependent neural networks. Here, we report a vulnerability of\nvanishing timestep embedding, which disables the time-awareness of a\ntime-dependent neural network. Furthermore, we find that this vulnerability can\nalso be observed in diffusion models because they employ a similar architecture\nthat incorporates timestep embedding to discriminate between different\ntimesteps during a diffusion process. Our analysis provides a detailed\ndescription of this phenomenon as well as several solutions to address the root\ncause. Through experiments on neural ordinary differential equations and\ndiffusion models, we observed that ensuring alive time-awareness via proposed\nsolutions boosted their performance, which implies that their current\nimplementations lack sufficient time-dependency.",
      "tldr_zh": "该论文分析了现代时间依赖神经网络（如神经常微分方程）的架构问题，指出timestep embedding消失会导致网络的时间感知能力丧失，从而影响动态系统建模。研究者发现这一漏洞同样存在于扩散模型中，因为它们采用类似架构来区分不同时间步。论文提供了详细描述和解决方案，通过实验验证，这些方法能显著提升神经常微分方程和扩散模型的性能，强调了当前实现中时间依赖性的不足。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14126v1",
      "published_date": "2024-05-23 02:58:23 UTC",
      "updated_date": "2024-05-23 02:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:46.284833"
    },
    {
      "arxiv_id": "2405.14125v3",
      "title": "ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingnan Zheng",
        "Han Wang",
        "An Zhang",
        "Tai D. Nguyen",
        "Jun Sun",
        "Tat-Seng Chua"
      ],
      "abstract": "Large Language Models (LLMs) can elicit unintended and even harmful content\nwhen misaligned with human values, posing severe risks to users and society. To\nmitigate these risks, current evaluation benchmarks predominantly employ\nexpert-designed contextual scenarios to assess how well LLMs align with human\nvalues. However, the labor-intensive nature of these benchmarks limits their\ntest scope, hindering their ability to generalize to the extensive variety of\nopen-world use cases and identify rare but crucial long-tail risks.\nAdditionally, these static tests fail to adapt to the rapid evolution of LLMs,\nmaking it hard to evaluate timely alignment issues. To address these\nchallenges, we propose ALI-Agent, an evaluation framework that leverages the\nautonomous abilities of LLM-powered agents to conduct in-depth and adaptive\nalignment assessments. ALI-Agent operates through two principal stages:\nEmulation and Refinement. During the Emulation stage, ALI-Agent automates the\ngeneration of realistic test scenarios. In the Refinement stage, it iteratively\nrefines the scenarios to probe long-tail risks. Specifically, ALI-Agent\nincorporates a memory module to guide test scenario generation, a tool-using\nmodule to reduce human labor in tasks such as evaluating feedback from target\nLLMs, and an action module to refine tests. Extensive experiments across three\naspects of human values--stereotypes, morality, and legality--demonstrate that\nALI-Agent, as a general evaluation framework, effectively identifies model\nmisalignment. Systematic analysis also validates that the generated test\nscenarios represent meaningful use cases, as well as integrate enhanced\nmeasures to probe long-tail risks. Our code is available at\nhttps://github.com/SophieZheng998/ALI-Agent.git",
      "tldr_zh": "该研究提出ALI-Agent框架，利用LLM驱动的代理进行动态评估，以评估大型语言模型(LLMs)是否与人类价值观对齐，解决现有基准的劳动密集型和适应性不足问题。框架包括Emulation阶段自动生成真实测试场景，以及Refinement阶段通过记忆模块(memory module)、工具使用模块(tool-using module)和行动模块(action module)迭代优化场景，以探测长尾风险。实验在刻板印象(stereotypes)、道德(morality)和合法性(legality)三个方面验证了ALI-Agent的有效性，能有效识别模型不对齐问题，并生成有意义的用例。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14125v3",
      "published_date": "2024-05-23 02:57:42 UTC",
      "updated_date": "2024-11-07 12:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:19:59.277848"
    },
    {
      "arxiv_id": "2405.14906v1",
      "title": "AutoCoder: Enhancing Code Large Language Model with \\textsc{AIEV-Instruct}",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Lei",
        "Yuchen Li",
        "Qiuwu Chen"
      ],
      "abstract": "We introduce AutoCoder, the first Large Language Model to surpass GPT-4 Turbo\n(April 2024) and GPT-4o in pass@1 on the Human Eval benchmark test\n($\\mathbf{90.9\\%}$ vs. $\\mathbf{90.2\\%}$). In addition, AutoCoder offers a more\nversatile code interpreter compared to GPT-4 Turbo and GPT-4o. It's code\ninterpreter can install external packages instead of limiting to built-in\npackages. AutoCoder's training data is a multi-turn dialogue dataset created by\na system combining agent interaction and external code execution verification,\na method we term \\textbf{\\textsc{AIEV-Instruct}} (Instruction Tuning with\nAgent-Interaction and Execution-Verified). Compared to previous large-scale\ncode dataset generation methods, \\textsc{AIEV-Instruct} reduces dependence on\nproprietary large models and provides execution-validated code dataset. The\ncode and the demo video is available in\n\\url{https://github.com/bin123apple/AutoCoder}.",
      "tldr_zh": "我们介绍了 AutoCoder，这是一个超越 GPT-4 Turbo 和 GPT-4o 的代码大语言模型，在 Human Eval 基准测试中实现了 90.9% 的 pass@1 准确率。AutoCoder 提供更通用的代码解释器，能够安装外部包，而非局限于内置包，从而提升了其实际应用灵活性。该模型的训练数据通过 \\textsc{AIEV-Instruct} 方法生成，该方法结合代理交互和外部代码执行验证，减少了对专有大模型的依赖，并确保数据集的执行有效性。代码和演示视频已在 GitHub 上开源。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14906v1",
      "published_date": "2024-05-23 02:53:25 UTC",
      "updated_date": "2024-05-23 02:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:20:10.605970"
    },
    {
      "arxiv_id": "2405.14117v2",
      "title": "Knowledge Localization: Mission Not Accomplished? Enter Query Localization!",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Chen",
        "Pengfei Cao",
        "Yubo Chen",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Large language models (LLMs) store extensive factual knowledge, but the\nmechanisms behind how they store and express this knowledge remain unclear. The\nKnowledge Neuron (KN) thesis is a prominent theory for explaining these\nmechanisms. This theory is based on the Knowledge Localization (KL) assumption,\nwhich suggests that a fact can be localized to a few knowledge storage units,\nnamely knowledge neurons.\n  However, this assumption has two limitations: first, it may be too rigid\nregarding knowledge storage, and second, it neglects the role of the attention\nmodule in knowledge expression.\n  In this paper, we first re-examine the KL assumption and demonstrate that its\nlimitations do indeed exist. To address these, we then present two new\nfindings, each targeting one of the limitations: one focusing on knowledge\nstorage and the other on knowledge expression. We summarize these findings as\n\\textbf{Query Localization} (QL) assumption and argue that the KL assumption\ncan be viewed as a simplification of the QL assumption. Based on QL assumption,\nwe further propose the Consistency-Aware KN modification method, which improves\nthe performance of knowledge modification, further validating our new\nassumption. We conduct 39 sets of experiments, along with additional\nvisualization experiments, to rigorously confirm our conclusions. Code is\navailable at https://github.com/heng840/KnowledgeLocalization.",
      "tldr_zh": "这篇论文质疑了 Large Language Models (LLMs) 中 Knowledge Localization (KL) 假设的局限性，认为它过于僵化且忽略了注意力模块在知识表达中的作用。作者提出 Query Localization (QL) 假设作为改进方案，并基于此开发了 Consistency-Aware KN 修改方法，以提升知识神经元(Knowledge Neuron, KN)的修改性能。通过 39 组实验和可视化分析，论文验证了 QL 假设的优越性，并证明了其对知识存储和表达机制的更全面解释。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2405.14117v2",
      "published_date": "2024-05-23 02:44:12 UTC",
      "updated_date": "2025-02-27 12:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:20:24.306906"
    },
    {
      "arxiv_id": "2405.14115v1",
      "title": "Configuring Data Augmentations to Reduce Variance Shift in Positional Embedding of Vision Transformers",
      "title_zh": "配置数据增强以减少视觉Transformer位置嵌入中的方差偏移",
      "authors": [
        "Bum Jun Kim",
        "Sang Woo Kim"
      ],
      "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance in a\nvariety of vision tasks. Despite their promising capabilities, training a ViT\nrequires a large amount of diverse data. Several studies empirically found that\nusing rich data augmentations, such as Mixup, Cutmix, and random erasing, is\ncritical to the successful training of ViTs. Now, the use of rich data\naugmentations has become a standard practice in the current state. However, we\nreport a vulnerability to this practice: Certain data augmentations such as\nMixup cause a variance shift in the positional embedding of ViT, which has been\na hidden factor that degrades the performance of ViT during the test phase. We\nclaim that achieving a stable effect from positional embedding requires a\nspecific condition on the image, which is often broken for the current data\naugmentation methods. We provide a detailed analysis of this problem as well as\nthe correct configuration for these data augmentations to remove the side\neffects of variance shift. Experiments showed that adopting our guidelines\nimproves the performance of ViTs compared with the current configuration of\ndata augmentations.",
      "tldr_zh": "该论文探讨了在训练 Vision Transformers (ViTs) 时，数据增强技术如 Mixup、Cutmix 和 random erasing 可能导致 positional embedding 中的 variance shift，从而降低测试性能的问题。作者通过详细分析发现，这种 variance shift 源于数据增强破坏了 positional embedding 所需的特定图像条件，并提供了正确的配置指导来消除这一副作用。实验结果表明，采用这些指导后，ViTs 的整体性能比当前标准配置有所提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14115v1",
      "published_date": "2024-05-23 02:42:32 UTC",
      "updated_date": "2024-05-23 02:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:20:35.749602"
    },
    {
      "arxiv_id": "2405.14114v2",
      "title": "Offline Reinforcement Learning from Datasets with Structured Non-Stationarity",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Ackermann",
        "Takayuki Osa",
        "Masashi Sugiyama"
      ],
      "abstract": "Current Reinforcement Learning (RL) is often limited by the large amount of\ndata needed to learn a successful policy. Offline RL aims to solve this issue\nby using transitions collected by a different behavior policy. We address a\nnovel Offline RL problem setting in which, while collecting the dataset, the\ntransition and reward functions gradually change between episodes but stay\nconstant within each episode. We propose a method based on Contrastive\nPredictive Coding that identifies this non-stationarity in the offline dataset,\naccounts for it when training a policy, and predicts it during evaluation. We\nanalyze our proposed method and show that it performs well in simple continuous\ncontrol tasks and challenging, high-dimensional locomotion tasks. We show that\nour method often achieves the oracle performance and performs better than\nbaselines.",
      "tldr_zh": "本文研究了离线强化学习（Offline RL）在具有结构化非平稳性（non-stationarity）的数据集上的应用，针对传统强化学习（RL）对大量数据的需求提出解决方案。作者提出了一种基于 Contrastive Predictive Coding 的方法，能够识别数据集中的非平稳性（即转移和奖励函数在 episodes 之间变化），并在训练策略时考虑这些变化，同时在评估时进行预测。该方法在简单连续控制任务和高维运动任务中表现出色，往往达到预言机性能（oracle performance），并优于现有基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Reinforcement Learning Conference (RLC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14114v2",
      "published_date": "2024-05-23 02:41:36 UTC",
      "updated_date": "2024-05-28 03:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:20:46.471725"
    },
    {
      "arxiv_id": "2405.14108v5",
      "title": "Deep Learning for Protein-Ligand Docking: Are We There Yet?",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Morehead",
        "Nabin Giri",
        "Jian Liu",
        "Pawan Neupane",
        "Jianlin Cheng"
      ],
      "abstract": "The effects of ligand binding on protein structures and their in vivo\nfunctions carry numerous implications for modern biomedical research and\nbiotechnology development efforts such as drug discovery. Although several deep\nlearning (DL) methods and benchmarks designed for protein-ligand docking have\nrecently been introduced, to date no prior works have systematically studied\nthe behavior of the latest docking and structure prediction methods within the\nbroadly applicable context of (1) using predicted (apo) protein structures for\ndocking (e.g., for applicability to new proteins); (2) binding multiple\n(cofactor) ligands concurrently to a given target protein (e.g., for enzyme\ndesign); and (3) having no prior knowledge of binding pockets (e.g., for\ngeneralization to unknown pockets). To enable a deeper understanding of docking\nmethods' real-world utility, we introduce PoseBench, the first comprehensive\nbenchmark for broadly applicable protein-ligand docking. PoseBench enables\nresearchers to rigorously and systematically evaluate DL methods for\napo-to-holo protein-ligand docking and protein-ligand structure prediction\nusing both primary ligand and multi-ligand benchmark datasets, the latter of\nwhich we introduce for the first time to the DL community. Empirically, using\nPoseBench, we find that (1) DL co-folding methods generally outperform\ncomparable conventional and DL docking baselines, yet popular methods such as\nAlphaFold 3 are still challenged by prediction targets with novel protein\nsequences; (2) certain DL co-folding methods are highly sensitive to their\ninput multiple sequence alignments, while others are not; and (3) DL methods\nstruggle to strike a balance between structural accuracy and chemical\nspecificity when predicting novel or multi-ligand protein targets. Code, data,\ntutorials, and benchmark results are available at\nhttps://github.com/BioinfoMachineLearning/PoseBench.",
      "tldr_zh": "本论文探讨了深度学习（Deep Learning）在蛋白质-配体对接（Protein-Ligand Docking）中的应用，并质疑其是否已达到实用水平。作者引入了首个全面基准PoseBench，用于系统评估对接方法在以下场景下的性能：使用预测的apo蛋白结构、多配体同时绑定，以及无先验结合口袋知识。实验结果显示，DL共同折叠方法通常优于传统和DL对接基线，但AlphaFold 3等模型在处理新蛋白序列时表现欠佳，且DL方法在结构准确性和化学特异性之间难以平衡，尤其在多配体或新颖目标的预测上。整体而言，PoseBench为未来蛋白质-配体对接研究提供了宝贵工具和见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.QM",
        "I.2.1; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "52 pages, 2 tables, 37 figures. Under review. Code, data, tutorials,\n  and benchmark results are available at\n  https://github.com/BioinfoMachineLearning/PoseBench",
      "pdf_url": "http://arxiv.org/pdf/2405.14108v5",
      "published_date": "2024-05-23 02:27:39 UTC",
      "updated_date": "2025-02-09 21:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:20:59.519287"
    },
    {
      "arxiv_id": "2405.17459v1",
      "title": "Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis",
      "title_zh": "使用多",
      "authors": [
        "Ziyan Yao",
        "Fei Lin",
        "Sheng Chai",
        "Weijie He",
        "Lu Dai",
        "Xinghui Fei"
      ],
      "abstract": "In this paper, an innovative multi-modal deep learning model is proposed to\ndeeply integrate heterogeneous information from medical images and clinical\nreports. First, for medical images, convolutional neural networks were used to\nextract high-dimensional features and capture key visual information such as\nfocal details, texture and spatial distribution. Secondly, for clinical report\ntext, a two-way long and short-term memory network combined with an attention\nmechanism is used for deep semantic understanding, and key statements related\nto the disease are accurately captured. The two features interact and integrate\neffectively through the designed multi-modal fusion layer to realize the joint\nrepresentation learning of image and text. In the empirical study, we selected\na large medical image database covering a variety of diseases, combined with\ncorresponding clinical reports for model training and validation. The proposed\nmultimodal deep learning model demonstrated substantial superiority in the\nrealms of disease classification, lesion localization, and clinical description\ngeneration, as evidenced by the experimental results.",
      "tldr_zh": "这篇论文提出了一种创新的多模态深度学习模型，用于整合医疗图像和临床报告的信息，以实现高级疾病分析。模型采用卷积神经网络（Convolutional Neural Networks, CNNs）提取图像的高维特征，如焦点细节、纹理和空间分布，并使用双向长短时记忆网络（Bidirectional Long Short-Term Memory, Bi-LSTM）结合注意力机制（Attention Mechanism）对临床报告文本进行深度语义理解。随后，通过多模态融合层（Multimodal Fusion Layer）实现图像和文本特征的联合表示学习。实验结果显示，该模型在大型医疗数据库上表现出色，在疾病分类、病变定位和临床描述生成方面显著优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17459v1",
      "published_date": "2024-05-23 02:22:10 UTC",
      "updated_date": "2024-05-23 02:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:21:12.199915"
    },
    {
      "arxiv_id": "2405.14105v5",
      "title": "Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Nadav Timor",
        "Jonathan Mamou",
        "Daniel Korat",
        "Moshe Berchansky",
        "Oren Pereg",
        "Moshe Wasserblat",
        "Tomer Galanti",
        "Michal Gordon",
        "David Harel"
      ],
      "abstract": "This paper introduces distributed speculative inference (DSI), a novel\ninference algorithm that is provably faster than speculative inference (SI)\n[leviathan2023, chen2023, miao2024, sun2025, timor2025] and standard\nautoregressive inference (non-SI). Like other SI algorithms, DSI operates on\nfrozen language models (LMs), requiring no training or architectural\nmodifications, and it preserves the target distribution. Prior studies on SI\nhave demonstrated empirical speedups over non-SI--but rely on sufficiently fast\nand accurate drafters, which are often unavailable in practice. We identify a\ngap where SI can be slower than non-SI if drafters are too slow or inaccurate.\nWe close this gap by proving that DSI is faster than both SI and non-SI--given\nany drafters. DSI is therefore not only faster than SI, but also unlocks the\nacceleration of LMs for which SI fails. DSI leverages speculation parallelism\n(SP), a novel type of task parallelism, to orchestrate target and drafter\ninstances that overlap in time, establishing a new foundational tradeoff\nbetween computational resources and latency. Our simulations show that DSI is\n1.29-1.92x faster than SI in single-node setups for various off-the-shelf LMs\nand tasks. We open-source all our code.",
      "tldr_zh": "这篇论文介绍了 Distributed Speculative Inference (DSI)，一种新型推理算法，能够证明性地比 Speculative Inference (SI) 和标准自回归推理更快，同时保持语言模型 (LMs) 的目标分布，且无需训练或架构修改。DSI 通过 Speculation Parallelism (SP) 这种新的任务并行性来协调目标和 drafter 实例，使它们在时间上重叠，从而解决 SI 在 drafters 缓慢或不准确时的性能问题。模拟实验显示，DSI 在单节点设置中对各种现成 LMs 和任务的加速效果为 1.29-1.92 倍，并开源了所有代码。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Published at ICLR 2025. (Link:\n  https://openreview.net/forum?id=cJd1BgZ9CS)",
      "pdf_url": "http://arxiv.org/pdf/2405.14105v5",
      "published_date": "2024-05-23 02:14:17 UTC",
      "updated_date": "2025-03-15 04:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:21:23.779137"
    },
    {
      "arxiv_id": "2405.14094v2",
      "title": "Attending to Topological Spaces: The Cellular Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Rubén Ballester",
        "Pablo Hernández-García",
        "Mathilde Papillon",
        "Claudio Battiloro",
        "Nina Miolane",
        "Tolga Birdal",
        "Carles Casacuberta",
        "Sergio Escalera",
        "Mustafa Hajij"
      ],
      "abstract": "Topological Deep Learning seeks to enhance the predictive performance of\nneural network models by harnessing topological structures in input data.\nTopological neural networks operate on spaces such as cell complexes and\nhypergraphs, that can be seen as generalizations of graphs. In this work, we\nintroduce the Cellular Transformer (CT), a novel architecture that generalizes\ngraph-based transformers to cell complexes. First, we propose a new formulation\nof the usual self- and cross-attention mechanisms, tailored to leverage\nincidence relations in cell complexes, e.g., edge-face and node-edge relations.\nAdditionally, we propose a set of topological positional encodings specifically\ndesigned for cell complexes. By transforming three graph datasets into cell\ncomplex datasets, our experiments reveal that CT not only achieves\nstate-of-the-art performance, but it does so without the need for more complex\nenhancements such as virtual nodes, in-domain structural encodings, or graph\nrewiring.",
      "tldr_zh": "本研究提出Cellular Transformer (CT)，一个将Transformer架构泛化到细胞复合体（cell complexes）和超图（hypergraphs）的创新模型，以提升拓扑深度学习（Topological Deep Learning）中神经网络的预测性能。CT 通过新的self- and cross-attention机制，利用细胞复合体的incidence relations（如edge-face和node-edge关系），并引入专为这些结构设计的拓扑positional encodings。实验结果显示，CT在将三个图数据集转换为细胞复合体数据集后，实现了state-of-the-art性能，且无需依赖额外的复杂增强如virtual nodes或graph rewiring。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "math.AT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14094v2",
      "published_date": "2024-05-23 01:48:32 UTC",
      "updated_date": "2024-05-26 23:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:21:39.486974"
    },
    {
      "arxiv_id": "2405.17458v2",
      "title": "Blood Glucose Control Via Pre-trained Counterfactual Invertible Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jingchi Jiang",
        "Rujia Shen",
        "Boran Wang",
        "Yi Guan"
      ],
      "abstract": "Type 1 diabetes mellitus (T1D) is characterized by insulin deficiency and\nblood glucose (BG) control issues. The state-of-the-art solution for continuous\nBG control is reinforcement learning (RL), where an agent can dynamically\nadjust exogenous insulin doses in time to maintain BG levels within the target\nrange. However, due to the lack of action guidance, the agent often needs to\nlearn from randomized trials to understand misleading correlations between\nexogenous insulin doses and BG levels, which can lead to instability and\nunsafety. To address these challenges, we propose an introspective RL based on\nCounterfactual Invertible Neural Networks (CINN). We use the pre-trained CINN\nas a frozen introspective block of the RL agent, which integrates forward\nprediction and counterfactual inference to guide the policy updates, promoting\nmore stable and safer BG control. Constructed based on interpretable causal\norder, CINN employs bidirectional encoders with affine coupling layers to\nensure invertibility while using orthogonal weight normalization to enhance the\ntrainability, thereby ensuring the bidirectional differentiability of network\nparameters. We experimentally validate the accuracy and generalization ability\nof the pre-trained CINN in BG prediction and counterfactual inference for\naction. Furthermore, our experimental results highlight the effectiveness of\npre-trained CINN in guiding RL policy updates for more accurate and safer BG\ncontrol.",
      "tldr_zh": "本研究针对1型糖尿病(T1D)的血糖(BG)控制问题，提出了一种基于预训练Counterfactual Invertible Neural Networks (CINN)的内省强化学习(RL)方法，以解决传统RL在学习胰岛素剂量与BG相关性时可能导致的不稳定性和不安全问题。CINN作为RL代理的冻结模块，整合前向预测和反事实推理来指导策略更新，并通过基于可解释因果顺序的双向编码器、仿射耦合层和正交权重归一化，确保网络的可逆性和训练性。实验结果验证了预训练CINN在BG预测和反事实推理中的准确性和泛化能力，并证明其能有效提升RL策略的准确性和安全性，从而实现更可靠的血糖控制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17458v2",
      "published_date": "2024-05-23 01:34:59 UTC",
      "updated_date": "2024-07-18 06:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:21:47.658047"
    },
    {
      "arxiv_id": "2405.14088v1",
      "title": "High-dimensional Learning with Noisy Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Aymane El Firdoussi",
        "Mohamed El Amine Seddik"
      ],
      "abstract": "This paper provides theoretical insights into high-dimensional binary\nclassification with class-conditional noisy labels. Specifically, we study the\nbehavior of a linear classifier with a label noisiness aware loss function,\nwhen both the dimension of data $p$ and the sample size $n$ are large and\ncomparable. Relying on random matrix theory by supposing a Gaussian mixture\ndata model, the performance of the linear classifier when $p,n\\to \\infty$ is\nshown to converge towards a limit, involving scalar statistics of the data.\nImportantly, our findings show that the low-dimensional intuitions to handle\nlabel noise do not hold in high-dimension, in the sense that the optimal\nclassifier in low-dimension dramatically fails in high-dimension. Based on our\nderivations, we design an optimized method that is shown to be provably more\nefficient in handling noisy labels in high dimensions. Our theoretical\nconclusions are further confirmed by experiments on real datasets, where we\nshow that our optimized approach outperforms the considered baselines.",
      "tldr_zh": "这篇论文探讨了高维二元 classification 中带有类别条件 noisy labels 的学习问题，使用随机 matrix theory 分析线性分类器的性能，假设数据遵循高斯混合模型。研究发现，当数据维度 p 和样本大小 n 都很大时，低维处理 noisy labels 的直觉在高维下不适用，导致低维最优分类器表现失败。作者据此设计了一个优化方法，能够更有效地处理高维 noisy labels，并在真实数据集实验中证明其优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14088v1",
      "published_date": "2024-05-23 01:32:25 UTC",
      "updated_date": "2024-05-23 01:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:21:59.830726"
    },
    {
      "arxiv_id": "2405.14905v1",
      "title": "Structural Entities Extraction and Patient Indications Incorporation for Chest X-ray Report Generation",
      "title_zh": "结构实体提取与患者指征整合用于胸部X光报告生成",
      "authors": [
        "Kang Liu",
        "Zhuoqi Ma",
        "Xiaolu Kang",
        "Zhusi Zhong",
        "Zhicheng Jiao",
        "Grayson Baird",
        "Harrison Bai",
        "Qiguang Miao"
      ],
      "abstract": "The automated generation of imaging reports proves invaluable in alleviating\nthe workload of radiologists. A clinically applicable reports generation\nalgorithm should demonstrate its effectiveness in producing reports that\naccurately describe radiology findings and attend to patient-specific\nindications. In this paper, we introduce a novel method, \\textbf{S}tructural\n\\textbf{E}ntities extraction and patient indications \\textbf{I}ncorporation\n(SEI) for chest X-ray report generation. Specifically, we employ a structural\nentities extraction (SEE) approach to eliminate presentation-style vocabulary\nin reports and improve the quality of factual entity sequences. This reduces\nthe noise in the following cross-modal alignment module by aligning X-ray\nimages with factual entity sequences in reports, thereby enhancing the\nprecision of cross-modal alignment and further aiding the model in\ngradient-free retrieval of similar historical cases. Subsequently, we propose a\ncross-modal fusion network to integrate information from X-ray images, similar\nhistorical cases, and patient-specific indications. This process allows the\ntext decoder to attend to discriminative features of X-ray images, assimilate\nhistorical diagnostic information from similar cases, and understand the\nexamination intention of patients. This, in turn, assists in triggering the\ntext decoder to produce high-quality reports. Experiments conducted on\nMIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on\nboth natural language generation and clinical efficacy metrics.",
      "tldr_zh": "本文提出一种名为SEI的方法，用于胸部X光报告的自动生成，旨在准确描述放射学发现并融入患者特定指示。具体地，SEI采用Structural Entities Extraction (SEE)来提取结构化实体、消除报告中的呈现风格词汇，并通过跨模态对齐模块提高图像与实体序列的精确匹配，同时利用跨模态融合网络整合X光图像、类似历史病例和患者指示信息，以辅助文本解码器生成高质量报告。在MIMIC-CXR数据集上的实验显示，SEI在自然语言生成和临床效能指标上优于最先进的方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.IV",
      "comment": "The code is available at https://github.com/mk-runner/SEI-Temp or\n  https://github.com/mk-runner/SEI",
      "pdf_url": "http://arxiv.org/pdf/2405.14905v1",
      "published_date": "2024-05-23 01:29:47 UTC",
      "updated_date": "2024-05-23 01:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:22:12.162776"
    },
    {
      "arxiv_id": "2406.00017v2",
      "title": "PTA: Enhancing Multimodal Sentiment Analysis through Pipelined Prediction and Translation-based Alignment",
      "title_zh": "PTA：通过管道式预测和基于翻译的对齐增强多模态情感分析",
      "authors": [
        "Shezheng Song",
        "Shasha Li",
        "Shan Zhao",
        "Chengyu Wang",
        "Xiaopeng Li",
        "Jie Yu",
        "Qian Wan",
        "Jun Ma",
        "Tianwei Yan",
        "Wentao Ma",
        "Xiaoguang Mao"
      ],
      "abstract": "Multimodal aspect-based sentiment analysis (MABSA) aims to understand\nopinions in a granular manner, advancing human-computer interaction and other\nfields. Traditionally, MABSA methods use a joint prediction approach to\nidentify aspects and sentiments simultaneously. However, we argue that joint\nmodels are not always superior. Our analysis shows that joint models struggle\nto align relevant text tokens with image patches, leading to misalignment and\nineffective image utilization.\n  In contrast, a pipeline framework first identifies aspects through MATE\n(Multimodal Aspect Term Extraction) and then aligns these aspects with image\npatches for sentiment classification (MASC: Multimodal Aspect-Oriented\nSentiment Classification). This method is better suited for multimodal\nscenarios where effective image use is crucial. We present three key\nobservations: (a) MATE and MASC have different feature requirements, with MATE\nfocusing on token-level features and MASC on sequence-level features; (b) the\naspect identified by MATE is crucial for effective image utilization; and (c)\nimages play a trivial role in previous MABSA methods due to high noise.\n  Based on these observations, we propose a pipeline framework that first\npredicts the aspect and then uses translation-based alignment (TBA) to enhance\nmultimodal semantic consistency for better image utilization. Our method\nachieves state-of-the-art (SOTA) performance on widely used MABSA datasets\nTwitter-15 and Twitter-17. This demonstrates the effectiveness of the pipeline\napproach and its potential to provide valuable insights for future MABSA\nresearch.\n  For reproducibility, the code and checkpoint will be released.",
      "tldr_zh": "本论文针对多模态方面级情感分析（MABSA）提出了一种管道框架PTA，以解决传统联合预测方法在文本标记和图像补丁对齐上的不足，从而提升图像利用效率。框架首先通过Multimodal Aspect Term Extraction (MATE)提取方面，然后采用Translation-based Alignment (TBA)增强多模态语义一致性，并进行Multimodal Aspect-Oriented Sentiment Classification (MASC)。关键观察包括MATE和MASC的特征需求差异，以及图像在先前方法中的次要作用。该方法在Twitter-15和Twitter-17数据集上实现了state-of-the-art (SOTA)性能，证明了管道方法的有效性和对未来MABSA研究的启发价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Code will be released upon publication",
      "pdf_url": "http://arxiv.org/pdf/2406.00017v2",
      "published_date": "2024-05-23 01:16:45 UTC",
      "updated_date": "2024-06-13 13:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:22:24.000980"
    },
    {
      "arxiv_id": "2405.17209v1",
      "title": "How Do Transformers \"Do\" Physics? Investigating the Simple Harmonic Oscillator",
      "title_zh": "翻译失败",
      "authors": [
        "Subhash Kantamneni",
        "Ziming Liu",
        "Max Tegmark"
      ],
      "abstract": "How do transformers model physics? Do transformers model systems with\ninterpretable analytical solutions, or do they create \"alien physics\" that are\ndifficult for humans to decipher? We take a step in demystifying this larger\npuzzle by investigating the simple harmonic oscillator (SHO), $\\ddot{x}+2\\gamma\n\\dot{x}+\\omega_0^2x=0$, one of the most fundamental systems in physics. Our\ngoal is to identify the methods transformers use to model the SHO, and to do so\nwe hypothesize and evaluate possible methods by analyzing the encoding of these\nmethods' intermediates. We develop four criteria for the use of a method within\nthe simple testbed of linear regression, where our method is $y = wx$ and our\nintermediate is $w$: (1) Can the intermediate be predicted from hidden states?\n(2) Is the intermediate's encoding quality correlated with model performance?\n(3) Can the majority of variance in hidden states be explained by the\nintermediate? (4) Can we intervene on hidden states to produce predictable\noutcomes? Armed with these two correlational (1,2), weak causal (3) and strong\ncausal (4) criteria, we determine that transformers use known numerical methods\nto model trajectories of the simple harmonic oscillator, specifically the\nmatrix exponential method. Our analysis framework can conveniently extend to\nhigh-dimensional linear systems and nonlinear systems, which we hope will help\nreveal the \"world model\" hidden in transformers.",
      "tldr_zh": "本研究探讨了Transformer如何建模物理系统，特别是简单谐振子(Simple Harmonic Oscillator, SHO)，以检验其是否使用可解释的分析方法而非难以理解的“alien physics”。研究者假设并评估了可能的建模方法，通过分析隐藏状态(hidden states)并应用四个标准（包括预测中间变量、编码质量与性能相关性、方差解释和干预效果）来验证这些方法。结果显示，Transformer使用已知的数值方法，特别是matrix exponential method，来模拟SHO的轨迹。该框架可扩展到高维线性系统和非线性系统，有助于揭示Transformer中的“world model”。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.17209v1",
      "published_date": "2024-05-23 01:14:22 UTC",
      "updated_date": "2024-05-23 01:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:22:35.391842"
    },
    {
      "arxiv_id": "2405.14082v2",
      "title": "Exclusively Penalized Q-learning for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junghyuk Yeom",
        "Yonghyeon Jo",
        "Jungmo Kim",
        "Sanghyeon Lee",
        "Seungyul Han"
      ],
      "abstract": "Constraint-based offline reinforcement learning (RL) involves policy\nconstraints or imposing penalties on the value function to mitigate\noverestimation errors caused by distributional shift. This paper focuses on a\nlimitation in existing offline RL methods with penalized value function,\nindicating the potential for underestimation bias due to unnecessary bias\nintroduced in the value function. To address this concern, we propose\nExclusively Penalized Q-learning (EPQ), which reduces estimation bias in the\nvalue function by selectively penalizing states that are prone to inducing\nestimation errors. Numerical results show that our method significantly reduces\nunderestimation bias and improves performance in various offline control tasks\ncompared to other offline RL methods",
      "tldr_zh": "本研究针对现有离线强化学习（offline RL）方法中，通过惩罚价值函数来缓解分布偏移引起的过估计错误，但可能引入低估偏差的问题。作者提出Exclusively Penalized Q-learning (EPQ)方法，该方法通过选择性地惩罚容易导致估计错误的states，从而减少价值函数中的不必要偏差。实验结果显示，EPQ显著降低了低估偏差，并在多种离线控制任务中比其他方法取得了更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 technical page followed by references and appendix. Accepted to\n  Neurips 2024 as spotlight paper",
      "pdf_url": "http://arxiv.org/pdf/2405.14082v2",
      "published_date": "2024-05-23 01:06:05 UTC",
      "updated_date": "2024-10-24 07:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:22:46.898724"
    },
    {
      "arxiv_id": "2405.14078v1",
      "title": "A finite time analysis of distributed Q-learning",
      "title_zh": "分布式 Q-learning 的有限时间分析",
      "authors": [
        "Han-Dong Lim",
        "Donghwan Lee"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in\ninterest, fueled by the empirical success achieved in applications of\nsingle-agent reinforcement learning (RL). In this study, we consider a\ndistributed Q-learning scenario, wherein a number of agents cooperatively solve\na sequential decision making problem without access to the central reward\nfunction which is an average of the local rewards. In particular, we study\nfinite-time analysis of a distributed Q-learning algorithm, and provide a new\nsample complexity result of $\\tilde{\\mathcal{O}}\\left(\n\\min\\left\\{\\frac{1}{\\epsilon^2}\\frac{t_{\\text{mix}}}{(1-\\gamma)^6 d_{\\min}^4 }\n,\\frac{1}{\\epsilon}\\frac{\\sqrt{|\\gS||\\gA|}}{(1-\\sigma_2(\\boldsymbol{W}))(1-\\gamma)^4\nd_{\\min}^3} \\right\\}\\right)$ under tabular lookup",
      "tldr_zh": "本研究分析了分布式 Q-learning 在多智能体强化学习（MARL）中的有限时间性能，针对多个代理合作解决顺序决策问题但无法访问中央奖励函数（仅使用本地奖励平均）的情况。研究提出了一种新的分布式 Q-learning 算法，并给出了其样本复杂度的有限时间分析。结果显示，样本复杂度为 \\(\\tilde{\\mathcal{O}}\\left( \\min\\left\\{ \\frac{1}{\\epsilon^2} \\frac{t_{\\text{mix}}}{(1-\\gamma)^6 d_{\\min}^4 }, \\frac{1}{\\epsilon} \\frac{\\sqrt{|\\gS||\\gA|}}{(1-\\sigma_2(\\boldsymbol{W}))(1-\\gamma)^4 d_{\\min}^3} \\right\\} \\right)\\)，为MARL 的理论基础提供了重要进展。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14078v1",
      "published_date": "2024-05-23 00:52:38 UTC",
      "updated_date": "2024-05-23 00:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:23:01.922099"
    },
    {
      "arxiv_id": "2405.14077v2",
      "title": "Learning to Transform Dynamically for Better Adversarial Transferability",
      "title_zh": "翻译失败",
      "authors": [
        "Rongyi Zhu",
        "Zeliang Zhang",
        "Susan Liang",
        "Zhuo Liu",
        "Chenliang Xu"
      ],
      "abstract": "Adversarial examples, crafted by adding perturbations imperceptible to\nhumans, can deceive neural networks. Recent studies identify the adversarial\ntransferability across various models, \\textit{i.e.}, the cross-model attack\nability of adversarial samples. To enhance such adversarial transferability,\nexisting input transformation-based methods diversify input data with\ntransformation augmentation. However, their effectiveness is limited by the\nfinite number of available transformations. In our study, we introduce a novel\napproach named Learning to Transform (L2T). L2T increases the diversity of\ntransformed images by selecting the optimal combination of operations from a\npool of candidates, consequently improving adversarial transferability. We\nconceptualize the selection of optimal transformation combinations as a\ntrajectory optimization problem and employ a reinforcement learning strategy to\neffectively solve the problem. Comprehensive experiments on the ImageNet\ndataset, as well as practical tests with Google Vision and GPT-4V, reveal that\nL2T surpasses current methodologies in enhancing adversarial transferability,\nthereby confirming its effectiveness and practical significance. The code is\navailable at https://github.com/RongyiZhu/L2T.",
      "tldr_zh": "该研究针对对抗样本(adversarial examples)的跨模型转移性(adversarial transferability)问题，提出了一种名为 Learning to Transform (L2T) 的新方法，以动态优化输入变换增强样本多样性。L2T 将变换组合选择视为轨迹优化问题，并采用强化学习(reinforcement learning)策略来高效解决这一问题，从而超越现有方法的局限性。在 ImageNet 数据集以及 Google Vision 和 GPT-4V 的实际测试中，L2T 显著提升了对抗转移性能，验证了其有效性和实用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted as a poster in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14077v2",
      "published_date": "2024-05-23 00:46:53 UTC",
      "updated_date": "2024-07-24 07:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:23:11.465600"
    },
    {
      "arxiv_id": "2405.14075v2",
      "title": "$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkun Cai",
        "Xu Zhao",
        "Yucheng Du",
        "Haoliang Liu",
        "Lei Li"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools in artificial\nintelligence, especially in complex decision-making scenarios, but their static\nproblem-solving strategies often limit their adaptability to dynamic\nenvironments. We explore the enhancement of reasoning capabilities in LLMs\nthrough Temperature Tree ($T^2$) prompting via a heuristic algorithm, termed as\n$T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing decision-making\nprocesses by dynamically adjusting search parameters, especially temperature,\nto improve accuracy without increasing computational demands. We empirically\nvalidate that our hybrid $T^2oT$ approach yields enhancements in,\nsingle-solution accuracy, multi-solution generation and text generation\nquality. Our findings suggest that while dynamic search depth adjustments based\non temperature can yield mixed results, a fixed search depth, when coupled with\nadaptive capabilities of $T^2oT$, provides a more reliable and versatile\nproblem-solving strategy. This work highlights the potential for future\nexplorations in optimizing algorithmic interactions with foundational language\nmodels, particularly illustrated by our development for the Game of 24 and\nCreative Writing tasks.",
      "tldr_zh": "本研究提出 $T^2$ of Thoughts ($T^2oT$) 算法，通过 Temperature Tree ($T^2$) 提示动态调整搜索参数（如温度），以增强大型语言模型 (LLMs) 在复杂决策场景中的推理能力，同时不增加计算需求。实验结果显示，$T^2oT$ 显著提高了单解决方案准确性、多解决方案生成以及文本生成质量，并在 Game of 24 和 Creative Writing 任务上进行了验证。总体发现表明，采用固定搜索深度结合 $T^2oT$ 的自适应策略，能提供更可靠的解决策略，为优化 LLMs 与算法互动提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14075v2",
      "published_date": "2024-05-23 00:40:43 UTC",
      "updated_date": "2025-02-16 13:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:23:23.638539"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 193,
  "processed_papers_count": 193,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T11:23:46.041865"
}