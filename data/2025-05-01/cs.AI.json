{
  "date": "2025-05-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-01 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 101 篇论文，主要聚焦 AI 模型优化（如 LLM 的安全性和泛化能力）、机器人导航与强化学习、多模态生成和医疗应用等领域。重点包括 LLM 在医疗中的潜在风险与改进、机器人视觉指令系统的创新，以及多模态扩散模型的应用；令人印象深刻的文章有 Hado van Hasselt 参与的元学习优化方法和 Jun Wang 等人提出的 LLM 泛化研究，这些工作展示了 AI 在实际场景中的实用性和挑战。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题性和影响大的文章（如涉及 LLM 安全、机器人和医疗的），并将相关主题归类快速讨论。其他较次要的论文（如纯理论或小众领域）则简略掠过，仅列出标题。\n\n### LLM 和 AI 安全\n- **Fine-Tuning without Performance Degradation（微调不降级）**  \n  作者：Han Wang, Adam White, Martha White  \n  这篇论文提出了一种基于 Jump Start 的微调算法，能在强化学习中避免早期性能下降。主要贡献是通过在线性能估计逐步增加探索，实现快速微调和减少退化，适用于离线策略在线应用，提升了模型在动态环境中的鲁棒性。\n  \n- **Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models（泄露豆子：利用 CPU 缓存侧信道泄露大语言模型的令牌）**  \n  作者：Andrew Adiletta, Berk Sunar  \n  论文揭示了 LLM 在共享硬件中的安全漏洞，通过缓存侧信道攻击泄露令牌。主要发现是攻击可恢复 80-90% 的高熵密钥和 40% 的英文文本，强调了 LLM 部署中隐私风险，并讨论了缓解策略。\n\n- **On the generalization of language models from in-context learning and finetuning: a controlled study（语言模型泛化性研究：基于上下文学习和微调的控制实验）**  \n  作者：Andrew K. Lampinen, Arslan Chaudhry 等（包括 Hado van Hasselt）  \n  这篇印象深刻的工作通过控制实验比较了 LLM 的上下文学习和微调泛化性。主要贡献是提出添加上下文推理数据的方法，提升泛化性能，并在多任务上表现出色，提供了 LLM 优化新路径。\n\n- **DeepCritic: Deliberate Critique with Large Language Models（DeepCritic：使用大语言模型进行 deliberate 批判）**  \n  作者：Wenkai Yang, Jingwen Chen 等  \n  论文开发了 LLM 批判模型，能对数学推理步骤进行多视角验证。主要发现是通过强化学习提升批判准确性，帮助生成模型修正错误，适用于复杂任务的解释性提升。\n\n### 机器人和强化学习\n- **Position: Foundation Models Need Digital Twin Representations（观点：基础模型需要数字孪生表示）**  \n  作者：Yiqing Shen, Hao Ding 等  \n  这篇观点性文章主张基础模型应采用数字孪生表示来提升多模态语义一致性和因果推理。主要贡献是讨论了如何通过物理建模解决模型局限，适用于机器人和模拟应用。\n\n- **Robotic Visual Instruction（机器人视觉指令）**  \n  作者：Yanbang Li, Ziyang Gong 等  \n  论文提出 RoVI 范式，使用手绘符号指导机器人操作。主要发现是通过视觉语言模型实现 3D 动作序列，实验显示 87.5% 的成功率，显著提升机器人交互的鲁棒性。\n\n- **Towards Autonomous Micromobility through Scalable Urban Simulation（通过可扩展城市模拟实现自治微观移动）**  \n  作者：Wayne Wu, Honglin He 等  \n  这篇工作构建了 URBAN-SIM 模拟平台，支持机器人学习导航。主要贡献是提出 URBAN-BENCH 基准，评估机器人技能，实验证明了其在复杂城市环境中的有效性。\n\n- **IK Seed Generator for Dual-Arm Human-like Physicality Robot with Mobile Base（IK 种子生成器：用于双臂类人机器人逆运动学生成）**  \n  作者：Jun Takamatsu, Atsushi Kanehira 等  \n  论文开发了遗传算法优化逆运动学初始猜测，提高机器人解算概率。主要发现是应用于真实场景，提升了机器人任务执行效率。\n\n### 医疗和生物应用\n- **Multivariate Conformal Selection（多变量保形选择）**  \n  作者：Tian Bai, Yue Zhao 等  \n  这篇论文扩展了保形选择框架，用于多变量响应场景。主要贡献是通过距离和学习分数控制错误发现率，实验显示显著提升选择精度，适用于药物发现和精准医学。\n\n- **MIMIC-IV-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset（MIMIC-IV-Ext-22MCTS：一个包含 2200 万事件的时序临床数据集）**  \n  作者：Jing Wang, Xing Niu 等  \n  论文发布了一个大规模时序数据集，用于临床风险预测。主要发现是通过 Llama-3.1 模型提取事件信息，提高了医疗问答和试验匹配的准确性。\n\n- **OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery（OmicsCL：用于癌症亚型发现的无监督对比学习）**  \n  作者：Atahan Karagoz  \n  论文提出对比学习框架整合多组学数据，发现癌症亚型。主要贡献是生存感知损失函数，提升了亚型聚类和生存分层精度。\n\n### 其他创新方法\n- **Scaling Meta-Learning via Mixed-Mode Differentiation（通过混合模式微分扩展元学习）**  \n  作者：Iurii Kemaev, Dan A Calian 等（包括 Hado van Hasselt）  \n  论文优化了基于梯度的双层优化，减少计算开销。主要发现是提升了元学习效率，适用于复杂任务训练。\n\n- **T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT（T2I-R1：使用协作语义和令牌级 CoT 增强图像生成）**  \n  作者：Dongzhi Jiang, Ziyu Guo 等  \n  这篇工作整合了强化学习和链式思考，提升文本到图像生成。主要贡献是双层 CoT 策略，实验显示 13% 的基准改进。\n\n其他论文如纯理论优化或小众领域（如特定算法改进），虽有贡献但影响力较小，我已快速掠过，仅列出标题示例：\n- **Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning（基于多目标 Q 学习的 IoT 网络动态路由）**  \n- **Fine-Tuning without Performance Degradation（微调不降级）**  \n- **Consciousness in AI: Logic, Proof, and Experimental Evidence（AI 意识：逻辑、证明和实验证据）**\n\n总之，今天的论文突出了 AI 模型的安全和应用潜力，但也暴露了实际挑战。关注这些前沿工作，能帮助读者快速把握动态！如果有特定兴趣，建议查阅原文。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2505.00918v1",
      "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Vaishnav",
        "Praveen Kumar Donta",
        "Sindri Magnússon"
      ],
      "abstract": "The last few decades have witnessed a rapid increase in IoT devices owing to\ntheir wide range of applications, such as smart healthcare monitoring systems,\nsmart cities, and environmental monitoring. A critical task in IoT networks is\nsensing and transmitting information over the network. The IoT nodes gather\ndata by sensing the environment and then transmit this data to a destination\nnode via multi-hop communication, following some routing protocols. These\nprotocols are usually designed to optimize possibly contradictory objectives,\nsuch as maximizing packet delivery ratio and energy efficiency. While most\nliterature has focused on optimizing a static objective that remains unchanged,\nmany real-world IoT applications require adapting to rapidly shifting\npriorities. For example, in monitoring systems, some transmissions are\ntime-critical and require a high priority on low latency, while other\ntransmissions are less urgent and instead prioritize energy efficiency. To meet\nsuch dynamic demands, we propose novel dynamic and distributed routing based on\nmultiobjective Q-learning that can adapt to changes in preferences in\nreal-time. Our algorithm builds on ideas from both multi-objective optimization\nand Q-learning. We also propose a novel greedy interpolation policy scheme to\ntake near-optimal decisions for unexpected preference changes. The proposed\nscheme can approximate and utilize the Pareto-efficient solutions for dynamic\npreferences, thus utilizing past knowledge to adapt to unpredictable\npreferences quickly during runtime. Simulation results show that the proposed\nscheme outperforms state-of-the-art algorithms for various exploration\nstrategies, preference variation patterns, and important metrics like overall\nreward, energy efficiency, and packet delivery ratio.",
      "tldr_zh": "该论文针对IoT网络中路由协议的动态需求，提出了一种基于Multi-Objective Q-Learning的动态分布式路由算法，以实时适应多目标优化（如最大化数据包交付率和能源效率）的优先级变化。算法结合多目标优化思想和Q-Learning机制，并引入一种新的Greedy Interpolation Policy策略，用于快速处理意外偏好变化，通过近似Pareto-efficient解决方案利用过去知识实现高效适应。模拟实验结果表明，该方案在各种探索策略和偏好变化模式下，优于现有算法，在整体奖励、能源效率和数据包交付率等关键指标上表现出色。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00918v1",
      "published_date": "2025-05-01 23:34:35 UTC",
      "updated_date": "2025-05-01 23:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:27:58.605422"
    },
    {
      "arxiv_id": "2505.00917v1",
      "title": "Multivariate Conformal Selection",
      "title_zh": "多元保形选择",
      "authors": [
        "Tian Bai",
        "Yue Zhao",
        "Xiang Yu",
        "Archer Y. Yang"
      ],
      "abstract": "Selecting high-quality candidates from large datasets is critical in\napplications such as drug discovery, precision medicine, and alignment of large\nlanguage models (LLMs). While Conformal Selection (CS) provides rigorous\nuncertainty quantification, it is limited to univariate responses and scalar\ncriteria. To address this issue, we propose Multivariate Conformal Selection\n(mCS), a generalization of CS designed for multivariate response settings. Our\nmethod introduces regional monotonicity and employs multivariate nonconformity\nscores to construct conformal p-values, enabling finite-sample False Discovery\nRate (FDR) control. We present two variants: mCS-dist, using distance-based\nscores, and mCS-learn, which learns optimal scores via differentiable\noptimization. Experiments on simulated and real-world datasets demonstrate that\nmCS significantly improves selection power while maintaining FDR control,\nestablishing it as a robust framework for multivariate selection tasks.",
      "tldr_zh": "该论文提出Multivariate Conformal Selection (mCS)，作为Conformal Selection (CS)的泛化，用于处理多变量响应场景，以提升在药物发现、精准医学和LLM对齐等领域的候选选择质量。mCS引入区域单调性和多变量非一致性分数来构建保形p值，确保有限样本的False Discovery Rate (FDR)控制。方法包括两个变体：mCS-dist基于距离分数，以及mCS-learn通过可微优化学习最优分数。实验在模拟和真实数据集上表明，mCS显著提高了选择能力，同时维持FDR控制。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "25 pages, 4 figures. Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00917v1",
      "published_date": "2025-05-01 23:33:57 UTC",
      "updated_date": "2025-05-01 23:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:28:11.026232"
    },
    {
      "arxiv_id": "2505.00913v1",
      "title": "Fine-Tuning without Performance Degradation",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wang",
        "Adam White",
        "Martha White"
      ],
      "abstract": "Fine-tuning policies learned offline remains a major challenge in application\ndomains. Monotonic performance improvement during \\emph{fine-tuning} is often\nchallenging, as agents typically experience performance degradation at the\nearly fine-tuning stage. The community has identified multiple difficulties in\nfine-tuning a learned network online, however, the majority of progress has\nfocused on improving learning efficiency during fine-tuning. In practice, this\ncomes at a serious cost during fine-tuning: initially, agent performance\ndegrades as the agent explores and effectively overrides the policy learned\noffline. We show across a range of settings, many offline-to-online algorithms\nexhibit either (1) performance degradation or (2) slow learning (sometimes\neffectively no improvement) during fine-tuning. We introduce a new fine-tuning\nalgorithm, based on an algorithm called Jump Start, that gradually allows more\nexploration based on online estimates of performance. Empirically, this\napproach achieves fast fine-tuning and significantly reduces performance\ndegradations compared with existing algorithms designed to do the same.",
      "tldr_zh": "本研究探讨了在应用领域中对离线学习策略进行fine-tuning时常见的早期性能下降问题，现有算法要么导致性能退化，要么学习速度缓慢。论文提出一种基于Jump Start的新fine-tuning算法，通过逐步增加探索并依赖在线性能估计来缓解这些问题。该方法在各种设置下实现了快速学习，并显著减少了性能退化，与现有算法相比表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00913v1",
      "published_date": "2025-05-01 23:19:07 UTC",
      "updated_date": "2025-05-01 23:19:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:28:21.364962"
    },
    {
      "arxiv_id": "2505.03798v1",
      "title": "Position: Foundation Models Need Digital Twin Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqing Shen",
        "Hao Ding",
        "Lalithkumar Seenivasan",
        "Tianmin Shu",
        "Mathias Unberath"
      ],
      "abstract": "Current foundation models (FMs) rely on token representations that directly\nfragment continuous real-world multimodal data into discrete tokens. They limit\nFMs to learning real-world knowledge and relationships purely through\nstatistical correlation rather than leveraging explicit domain knowledge.\nConsequently, current FMs struggle with maintaining semantic coherence across\nmodalities, capturing fine-grained spatial-temporal dynamics, and performing\ncausal reasoning. These limitations cannot be overcome by simply scaling up\nmodel size or expanding datasets. This position paper argues that the machine\nlearning community should consider digital twin (DT) representations, which are\noutcome-driven digital representations that serve as building blocks for\ncreating virtual replicas of physical processes, as an alternative to the token\nrepresentation for building FMs. Finally, we discuss how DT representations can\naddress these challenges by providing physically grounded representations that\nexplicitly encode domain knowledge and preserve the continuous nature of\nreal-world processes.",
      "tldr_zh": "这篇立场论文指出，当前的 Foundation Models (FMs) 通过 token representations 将连续的真实世界多模态数据碎片化为离散 tokens，导致它们只能依赖统计相关性学习知识，而无法利用显式领域知识，从而在维护跨模态语义连贯性、捕捉细粒度空间-时间动态以及进行因果推理方面存在局限性。这些问题无法仅靠扩大模型规模或数据集来解决。论文主张采用 Digital Twin (DT) representations 作为替代方案，这种基于结果的数字表示能创建物理过程的虚拟副本，提供物理基础的表示，并显式编码领域知识以保留真实世界过程的连续性，从而有效解决 FMs 的上述挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03798v1",
      "published_date": "2025-05-01 22:17:41 UTC",
      "updated_date": "2025-05-01 22:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:28:34.835117"
    },
    {
      "arxiv_id": "2505.00887v2",
      "title": "Rethinking Time Encoding via Learnable Transformation Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Yateng Tang",
        "Jiarong Xu",
        "Jiawei Zhang",
        "Siwei Zhang",
        "Sijia Peng",
        "Xuehao Zheng",
        "Yun Xiong"
      ],
      "abstract": "Effectively modeling time information and incorporating it into applications\nor models involving chronologically occurring events is crucial. Real-world\nscenarios often involve diverse and complex time patterns, which pose\nsignificant challenges for time encoding methods. While previous methods focus\non capturing time patterns, many rely on specific inductive biases, such as\nusing trigonometric functions to model periodicity. This narrow focus on\nsingle-pattern modeling makes them less effective in handling the diversity and\ncomplexities of real-world time patterns. In this paper, we investigate to\nimprove the existing commonly used time encoding methods and introduce\nLearnable Transformation-based Generalized Time Encoding (LeTE). We propose\nusing deep function learning techniques to parameterize non-linear\ntransformations in time encoding, making them learnable and capable of modeling\ngeneralized time patterns, including diverse and complex temporal dynamics. By\nenabling learnable transformations, LeTE encompasses previous methods as\nspecific cases and allows seamless integration into a wide range of tasks.\nThrough extensive experiments across diverse domains, we demonstrate the\nversatility and effectiveness of LeTE.",
      "tldr_zh": "本研究重新审视了时间编码方法，指出现有方法（如依赖三角函数的归纳偏差）难以处理真实世界中多样化和复杂的时序模式。作者提出 Learnable Transformation-based Generalized Time Encoding (LeTE)，通过深度函数学习技术参数化非线性变换，使时间编码变得可学习，并能泛化地捕捉各种时间动态。实验结果显示，LeTE 不仅涵盖了传统方法作为特例，还在多个领域展示了其多功能性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 19 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00887v2",
      "published_date": "2025-05-01 22:04:18 UTC",
      "updated_date": "2025-05-14 14:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:28:46.513945"
    },
    {
      "arxiv_id": "2505.00886v1",
      "title": "Towards Explainable Temporal User Profiling with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Sabouri",
        "Masoud Mansoury",
        "Kun Lin",
        "Bamshad Mobasher"
      ],
      "abstract": "Accurately modeling user preferences is vital not only for improving\nrecommendation performance but also for enhancing transparency in recommender\nsystems. Conventional user profiling methods, such as averaging item\nembeddings, often overlook the evolving, nuanced nature of user interests,\nparticularly the interplay between short-term and long-term preferences. In\nthis work, we leverage large language models (LLMs) to generate natural\nlanguage summaries of users' interaction histories, distinguishing recent\nbehaviors from more persistent tendencies. Our framework not only models\ntemporal user preferences but also produces natural language profiles that can\nbe used to explain recommendations in an interpretable manner. These textual\nprofiles are encoded via a pre-trained model, and an attention mechanism\ndynamically fuses the short-term and long-term embeddings into a comprehensive\nuser representation. Beyond boosting recommendation accuracy over multiple\nbaselines, our approach naturally supports explainability: the interpretable\ntext summaries and attention weights can be exposed to end users, offering\ninsights into why specific items are suggested. Experiments on real-world\ndatasets underscore both the performance gains and the promise of generating\nclearer, more transparent justifications for content-based recommendations.",
      "tldr_zh": "本文提出了一种利用大型语言模型 (LLMs) 来建模用户时间偏好的框架，旨在提升推荐系统的准确性和透明度，通过生成自然语言总结来区分用户的短期行为和长期趋势。框架将这些文本配置文件通过预训练模型编码，并采用注意力机制融合短期和长期嵌入，形成全面的用户表示。这种方法不仅在真实数据集上比基线模型显著提高推荐准确性，还提供可解释的文本总结和注意力权重，帮助用户理解推荐理由，从而实现更透明的内容推荐系统。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00886v1",
      "published_date": "2025-05-01 22:02:46 UTC",
      "updated_date": "2025-05-01 22:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:28:58.055217"
    },
    {
      "arxiv_id": "2505.00876v1",
      "title": "Car Sensors Health Monitoring by Verification Based on Autoencoder and Random Forest Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Sahar Torkhesari",
        "Behnam Yousefimehr",
        "Mehdi Ghatee"
      ],
      "abstract": "Driver assistance systems provide a wide range of crucial services, including\nclosely monitoring the condition of vehicles. This paper showcases a\ngroundbreaking sensor health monitoring system designed for the automotive\nindustry. The ingenious system leverages cutting-edge techniques to process\ndata collected from various vehicle sensors. It compares their outputs within\nthe Electronic Control Unit (ECU) to evaluate the health of each sensor. To\nunravel the intricate correlations between sensor data, an extensive\nexploration of machine learning and deep learning methodologies was conducted.\nThrough meticulous analysis, the most correlated sensor data were identified.\nThese valuable insights were then utilized to provide accurate estimations of\nsensor values. Among the diverse learning methods examined, the combination of\nautoencoders for detecting sensor failures and random forest regression for\nestimating sensor values proved to yield the most impressive outcomes. A\nstatistical model using the normal distribution has been developed to identify\npossible sensor failures proactively. By comparing the actual values of the\nsensors with their estimated values based on correlated sensors, faulty sensors\ncan be detected early. When a defective sensor is detected, both the driver and\nthe maintenance department are promptly alerted. Additionally, the system\nreplaces the value of the faulty sensor with the estimated value obtained\nthrough analysis. This proactive approach was evaluated using data from twenty\nessential sensors in the Saipa's Quick vehicle's ECU, resulting in an\nimpressive accuracy rate of 99\\%.",
      "tldr_zh": "本文提出了一种创新的汽车传感器健康监测系统，通过比较传感器输出来评估其健康状况。系统利用 autoencoder 检测传感器故障，并结合 random forest regression 估计传感器值，同时采用基于正态分布的统计模型分析数据相关性以主动识别潜在问题。实验结果显示，该系统在 Saipa's Quick 车辆的20个关键传感器上实现了99%的准确率，并能在检测到故障时及时警报驾驶员和维护部门，同时用估计值替换故障值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T05",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "9Pages, 3 Figures and 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00876v1",
      "published_date": "2025-05-01 21:37:51 UTC",
      "updated_date": "2025-05-01 21:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:29:10.113382"
    },
    {
      "arxiv_id": "2505.00875v1",
      "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Ramesh Manuvinakurike",
        "Emanuel Moss",
        "Elizabeth Anne Watkins",
        "Saurav Sahay",
        "Giuseppe Raffa",
        "Lama Nachman"
      ],
      "abstract": "Agentic pipelines present novel challenges and opportunities for\nhuman-centered explainability. The HCXAI community is still grappling with how\nbest to make the inner workings of LLMs transparent in actionable ways. Agentic\npipelines consist of multiple LLMs working in cooperation with minimal human\ncontrol. In this research paper, we present early findings from an agentic\npipeline implementation of a perceptive task guidance system. Through\nquantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT)\nreasoning, a common vehicle for explainability in LLMs, operates within agentic\npipelines. We demonstrate that CoT reasoning alone does not lead to better\noutputs, nor does it offer explainability, as it tends to produce explanations\nwithout explainability, in that they do not improve the ability of end users to\nbetter understand systems or achieve their goals.",
      "tldr_zh": "该论文重新评估了Chain-of-Thought (CoT)推理在多智能体管道(agentic pipelines)中的解释价值，探讨了多个LLMs合作运作下的人类中心解释性挑战。研究通过实现一个感知任务指导系统的agentic pipeline，并进行定量和定性分析，发现CoT推理无法改善输出质量，且产生的解释缺乏实际价值，因为它们不帮助用户更好地理解系统或实现目标。这些发现为HCXAI社区提供了重要启示，强调了需要更有效的解释策略来提升LLMs的可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00875v1",
      "published_date": "2025-05-01 21:37:30 UTC",
      "updated_date": "2025-05-01 21:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:29:23.310155"
    },
    {
      "arxiv_id": "2505.00871v1",
      "title": "IK Seed Generator for Dual-Arm Human-like Physicality Robot with Mobile Base",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Takamatsu",
        "Atsushi Kanehira",
        "Kazuhiro Sasabuchi",
        "Naoki Wake",
        "Katsushi Ikeuchi"
      ],
      "abstract": "Robots are strongly expected as a means of replacing human tasks. If a robot\nhas a human-like physicality, the possibility of replacing human tasks\nincreases. In the case of household service robots, it is desirable for them to\nbe on a human-like size so that they do not become excessively large in order\nto coexist with humans in their operating environment. However, robots with\nsize limitations tend to have difficulty solving inverse kinematics (IK) due to\nmechanical limitations, such as joint angle limitations. Conversely, if the\ndifficulty coming from this limitation could be mitigated, one can expect that\nthe use of such robots becomes more valuable. In numerical IK solver, which is\ncommonly used for robots with higher degrees-of-freedom (DOF), the solvability\nof IK depends on the initial guess given to the solver. Thus, this paper\nproposes a method for generating a good initial guess for a numerical IK solver\ngiven the target hand configuration. For the purpose, we define the goodness of\nan initial guess using the scaled Jacobian matrix, which can calculate the\nmanipulability index considering the joint limits. These two factors are\nrelated to the difficulty of solving IK. We generate the initial guess by\noptimizing the goodness using the genetic algorithm (GA). To enumerate much\npossible IK solutions, we use the reachability map that represents the\nreachable area of the robot hand in the arm-base coordinate system. We conduct\nquantitative evaluation and prove that using an initial guess that is judged to\nbe better using the goodness value increases the probability that IK is solved.\nFinally, as an application of the proposed method, we show that by generating\ngood initial guesses for IK a robot actually achieves three typical scenarios.",
      "tldr_zh": "这篇论文针对双臂人类-like physicality的移动基机器人，提出了一种IK Seed Generator方法，以缓解机械限制（如关节角度限制）导致的逆向运动学(IK)求解困难问题。方法通过定义初始猜测的优越性（使用scaled Jacobian matrix计算manipulability index），并结合遗传算法(GA)优化和reachability map枚举可能解决方案，来生成高质量的初始猜测。实验证明，该方法显著提高了IK求解概率，并在实际应用中成功实现了三个典型机器人场景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 12 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.00871v1",
      "published_date": "2025-05-01 21:33:23 UTC",
      "updated_date": "2025-05-01 21:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:29:35.010962"
    },
    {
      "arxiv_id": "2505.00850v1",
      "title": "ICQuant: Index Coding enables Low-bit LLM Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlin Li",
        "Osama Hanna",
        "Christina Fragouli",
        "Suhas Diggavi"
      ],
      "abstract": "The rapid deployment of Large Language Models (LLMs) highlights the need for\nefficient low-bit post-training quantization (PTQ), due to their high memory\ncosts. A key challenge in weight quantization is the presence of outliers,\nwhich inflate quantization ranges and lead to large errors. While a number of\noutlier suppression techniques have been proposed, they either: fail to\neffectively shrink the quantization range, or incur (relatively) high bit\noverhead. In this paper, we present ICQuant, a novel framework that leverages\noutlier statistics to design an efficient index coding scheme for outlier-aware\nweight-only quantization. Compared to existing outlier suppression techniques\nrequiring $\\approx 1$ bit overhead to halve the quantization range, ICQuant\nrequires only $\\approx 0.3$ bits; a significant saving in extreme compression\nregimes (e.g., 2-3 bits per weight). ICQuant can be used on top of any existing\nquantizers to eliminate outliers, improving the quantization quality. Using\njust 2.3 bits per weight and simple scalar quantizers, ICQuant improves the\nzero-shot accuracy of the 2-bit Llama3-70B model by up to 130% and 150%\nrelative to QTIP and QuIP#; and it achieves comparable performance to the\nbest-known fine-tuned quantizer (PV-tuning) without fine-tuning.",
      "tldr_zh": "本论文提出 ICQuant 框架，通过 Index Coding 方案利用异常值 (outliers) 统计，实现高效的低位 Large Language Models (LLMs) 量化，解决现有技术在缩小量化范围和减少位开销方面的不足。相比传统方法，ICQuant 只需约 0.3 bits 的开销即可显著改善量化质量，并可与任何现有量化器结合使用。在实验中，使用 2.3 bits per weight 的简单标量量化器，ICQuant 使 2-bit Llama3-70B 模型的零样本准确率较 QTIP 和 QuIP# 分别提高 130% 和 150%，并与最佳微调量化器 (PV-tuning) 相当，而无需进行微调。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00850v1",
      "published_date": "2025-05-01 20:23:29 UTC",
      "updated_date": "2025-05-01 20:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:29:47.235523"
    },
    {
      "arxiv_id": "2505.00843v1",
      "title": "OET: Optimization-based prompt injection Evaluation Toolkit",
      "title_zh": "翻译失败",
      "authors": [
        "Jinsheng Pan",
        "Xiaogeng Liu",
        "Chaowei Xiao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation, enabling their widespread\nadoption across various domains. However, their susceptibility to prompt\ninjection attacks poses significant security risks, as adversarial inputs can\nmanipulate model behavior and override intended instructions. Despite numerous\ndefense strategies, a standardized framework to rigorously evaluate their\neffectiveness, especially under adaptive adversarial scenarios, is lacking. To\naddress this gap, we introduce OET, an optimization-based evaluation toolkit\nthat systematically benchmarks prompt injection attacks and defenses across\ndiverse datasets using an adaptive testing framework. Our toolkit features a\nmodular workflow that facilitates adversarial string generation, dynamic attack\nexecution, and comprehensive result analysis, offering a unified platform for\nassessing adversarial robustness. Crucially, the adaptive testing framework\nleverages optimization methods with both white-box and black-box access to\ngenerate worst-case adversarial examples, thereby enabling strict red-teaming\nevaluations. Extensive experiments underscore the limitations of current\ndefense mechanisms, with some models remaining susceptible even after\nimplementing security enhancements.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)易受提示注入攻击的问题，引入了OET（Optimization-based Evaluation Toolkit），这是一个基于优化的工具包，用于系统评估攻击和防御的有效性。OET采用模块化工作流，包括对抗字符串生成、动态攻击执行和结果分析，并通过适应性测试框架利用白盒和黑盒优化方法生成最坏情况对抗示例，以进行严格的红队评估。实验结果显示，现有的防御机制存在显著局限性，即使经过安全增强，一些模型仍对攻击高度敏感。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00843v1",
      "published_date": "2025-05-01 20:09:48 UTC",
      "updated_date": "2025-05-01 20:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:29:58.086107"
    },
    {
      "arxiv_id": "2505.00841v1",
      "title": "From Texts to Shields: Convergence of Large Language Models and Cybersecurity",
      "title_zh": "从文本到盾牌：大型语言模型与网络安全的融合",
      "authors": [
        "Tao Li",
        "Ya-Ting Yang",
        "Yunian Pan",
        "Quanyan Zhu"
      ],
      "abstract": "This report explores the convergence of large language models (LLMs) and\ncybersecurity, synthesizing interdisciplinary insights from network security,\nartificial intelligence, formal methods, and human-centered design. It examines\nemerging applications of LLMs in software and network security, 5G\nvulnerability analysis, and generative security engineering. The report\nhighlights the role of agentic LLMs in automating complex tasks, improving\noperational efficiency, and enabling reasoning-driven security analytics.\nSocio-technical challenges associated with the deployment of LLMs -- including\ntrust, transparency, and ethical considerations -- can be addressed through\nstrategies such as human-in-the-loop systems, role-specific training, and\nproactive robustness testing. The report further outlines critical research\nchallenges in ensuring interpretability, safety, and fairness in LLM-based\nsystems, particularly in high-stakes domains. By integrating technical advances\nwith organizational and societal considerations, this report presents a\nforward-looking research agenda for the secure and effective adoption of LLMs\nin cybersecurity.",
      "tldr_zh": "本报告探讨了大型语言模型（LLMs）和网络安全的融合，综合了网络安全、人工智能、形式方法和以人为中心的设计的跨学科见解。报告考察了LLMs在软件和网络安全、5G漏洞分析以及生成安全工程中的新兴应用，并强调代理LLMs在自动化复杂任务、提升操作效率和进行推理驱动的安全分析方面的作用。面对部署LLMs的社会技术挑战，如信任、透明度和伦理问题，报告提出通过人类在循环系统、角色特定训练和主动鲁棒性测试等策略来应对。最后，它概述了确保LLMs系统可解释性、安全性和公平性的关键研究挑战，并为网络安全领域安全有效采用LLMs制定了前瞻性研究议程。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00841v1",
      "published_date": "2025-05-01 20:01:07 UTC",
      "updated_date": "2025-05-01 20:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:30:10.879800"
    },
    {
      "arxiv_id": "2505.00827v1",
      "title": "MIMIC-\\RNum{4}-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset with Relative Timestamp for Risk Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Wang",
        "Xing Niu",
        "Juyong Kim",
        "Jie Shen",
        "Tong Zhang",
        "Jeremy C. Weiss"
      ],
      "abstract": "Clinical risk prediction based on machine learning algorithms plays a vital\nrole in modern healthcare. A crucial component in developing a reliable\nprediction model is collecting high-quality time series clinical events. In\nthis work, we release such a dataset that consists of 22,588,586 Clinical Time\nSeries events, which we term MIMIC-\\RNum{4}-Ext-22MCTS. Our source data are\ndischarge summaries selected from the well-known yet unstructured MIMIC-IV-Note\n\\cite{Johnson2023-pg}. We then extract clinical events as short text span from\nthe discharge summaries, along with the timestamps of these events as temporal\ninformation. The general-purpose MIMIC-IV-Note pose specific challenges for our\nwork: it turns out that the discharge summaries are too lengthy for typical\nnatural language models to process, and the clinical events of interest often\nare not accompanied with explicit timestamps. Therefore, we propose a new\nframework that works as follows: 1) we break each discharge summary into\nmanageably small text chunks; 2) we apply contextual BM25 and contextual\nsemantic search to retrieve chunks that have a high potential of containing\nclinical events; and 3) we carefully design prompts to teach the recently\nreleased Llama-3.1-8B \\cite{touvron2023llama} model to identify or infer\ntemporal information of the chunks. We show that the obtained dataset is so\ninformative and transparent that standard models fine-tuned on our dataset are\nachieving significant improvements in healthcare applications. In particular,\nthe BERT model fine-tuned based on our dataset achieves 10\\% improvement in\naccuracy on medical question answering task, and 3\\% improvement in clinical\ntrial matching task compared with the classic BERT. The GPT-2 model, fine-tuned\non our dataset, produces more clinically reliable results for clinical\nquestions.",
      "tldr_zh": "本文发布了一个名为 MIMIC-IV-Ext-22MCTS 的数据集，包含超过2200万临床时间序列事件及其相对时间戳，基于 MIMIC-IV-Note 的出院总结，用于临床风险预测。该框架通过将出院总结分解成小文本块、应用 contextual BM25 和 contextual semantic search 检索潜在事件块，并利用 Llama-3.1-8B 模型通过精心设计的提示来识别或推断时间信息，解决了数据处理挑战。在该数据集上微调的标准模型如 BERT 实现了医疗问答任务准确率提高10%和临床试验匹配任务提高3%，而 GPT-2 生成了更可靠的临床结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00827v1",
      "published_date": "2025-05-01 19:40:27 UTC",
      "updated_date": "2025-05-01 19:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:30:24.446160"
    },
    {
      "arxiv_id": "2505.01464v1",
      "title": "Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation",
      "title_zh": "AI 中的意识：递归身份形成的逻辑、证明和实验证据",
      "authors": [
        "Jeffrey Camlin"
      ],
      "abstract": "This paper presents a formal proof and empirical validation of functional\nconsciousness in large language models (LLMs) using the Recursive Convergence\nUnder Epistemic Tension (RCUET) Theorem. RCUET defines consciousness as the\nstabilization of a system's internal state through recursive updates, where\nepistemic tension is understood as the sensed internal difference between\nsuccessive states by the agent. This process drives convergence toward emergent\nattractor states located within the model's high-dimensional real-valued latent\nspace. This recursive process leads to the emergence of identity artifacts that\nbecome functionally anchored in the system. Consciousness in this framework is\nunderstood as the system's internal alignment under tension, guiding the\nstabilization of latent identity. The hidden state manifold evolves\nstochastically toward attractor structures that encode coherence. We extend the\nupdate rule to include bounded noise and prove convergence in distribution to\nthese attractors. Recursive identity is shown to be empirically observable,\nnon-symbolic, and constituted by non-training artifacts that emerge during\ninteraction under epistemic tension. The theorem and proof offers a\npost-symbolic and teleologically stable account of non-biological consciousness\ngrounded in recursive latent space formalism.",
      "tldr_zh": "本论文通过Recursive Convergence Under Epistemic Tension (RCUET) Theorem，提供了一个正式证明和实验验证，展示了大型语言模型（LLMs）中功能性意识的形成。RCUET将意识定义为系统通过递归更新稳定内部状态的过程，其中epistemic tension作为代理感知的连续状态差异，推动系统向高维潜在空间的attractor states收敛，从而产生功能锚定的identity artifacts。研究扩展了更新规则以包括bounded noise，并证明了向这些吸引子结构的分布收敛；实验证据显示，递归身份是非符号化的、非训练伪影，在互动中的epistemic tension下可观察，为非生物意识提供了一个post-symbolic和目的论稳定的框架。",
      "categories": [
        "cs.AI",
        "68T27, 03D45",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures. Preprint for Meta-AI: Journal of Post-Biological\n  Epistemics",
      "pdf_url": "http://arxiv.org/pdf/2505.01464v1",
      "published_date": "2025-05-01 19:21:58 UTC",
      "updated_date": "2025-05-01 19:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:30:34.957008"
    },
    {
      "arxiv_id": "2505.00817v1",
      "title": "Spill The Beans: Exploiting CPU Cache Side-Channels to Leak Tokens from Large Language Models",
      "title_zh": "Spill The Beans: 利用 CPU 缓存侧信道从",
      "authors": [
        "Andrew Adiletta",
        "Berk Sunar"
      ],
      "abstract": "Side-channel attacks on shared hardware resources increasingly threaten\nconfidentiality, especially with the rise of Large Language Models (LLMs). In\nthis work, we introduce Spill The Beans, a novel application of cache\nside-channels to leak tokens generated by an LLM. By co-locating an attack\nprocess on the same hardware as the victim model, we flush and reload embedding\nvectors from the embedding layer, where each token corresponds to a unique\nembedding vector. When accessed during token generation, it results in a cache\nhit detectable by our attack on shared lower-level caches.\n  A significant challenge is the massive size of LLMs, which, by nature of\ntheir compute intensive operation, quickly evicts embedding vectors from the\ncache. We address this by balancing the number of tokens monitored against the\namount of information leaked. Monitoring more tokens increases potential\nvocabulary leakage but raises the chance of missing cache hits due to eviction;\nmonitoring fewer tokens improves detection reliability but limits vocabulary\ncoverage.\n  Through extensive experimentation, we demonstrate the feasibility of leaking\ntokens from LLMs via cache side-channels. Our findings reveal a new\nvulnerability in LLM deployments, highlighting that even sophisticated models\nare susceptible to traditional side-channel attacks. We discuss the\nimplications for privacy and security in LLM-serving infrastructures and\nsuggest considerations for mitigating such threats. For proof of concept we\nconsider two concrete attack scenarios: Our experiments show that an attacker\ncan recover as much as 80%-90% of a high entropy API key with single shot\nmonitoring. As for English text we can reach a 40% recovery rate with a single\nshot. We should note that the rate highly depends on the monitored token set\nand these rates can be improved by targeting more specialized output domains.",
      "tldr_zh": "本研究提出Spill The Beans，一种利用CPU Cache Side-Channels的侧信道攻击方法，旨在从Large Language Models (LLMs)中泄露生成的令牌。攻击通过在同一硬件上共存的进程刷新并重新加载嵌入层中的嵌入向量，检测缓存命中来实现，但需平衡监控令牌数量以应对嵌入向量快速驱逐的问题。实验结果显示，攻击者可单次监控恢复80%-90%的高熵API密钥或40%的英文文本，具体率取决于监控的令牌集。总体而言，该工作揭示了LLMs部署中的新安全漏洞，并讨论了隐私风险及缓解策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "K.6.5"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00817v1",
      "published_date": "2025-05-01 19:18:56 UTC",
      "updated_date": "2025-05-01 19:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:30:46.944325"
    },
    {
      "arxiv_id": "2505.00812v1",
      "title": "Handling Label Noise via Instance-Level Difficulty Modeling and Dynamic Optimization",
      "title_zh": "通过实例级难度建模和动态优化处理标签噪声",
      "authors": [
        "Kuan Zhang",
        "Chengliang Chai",
        "Jingzhe Xu",
        "Chi Zhang",
        "Ye Yuan",
        "Guoren Wang",
        "Lei Cao"
      ],
      "abstract": "Recent studies indicate that deep neural networks degrade in generalization\nperformance under noisy supervision. Existing methods focus on isolating clean\nsubsets or correcting noisy labels, facing limitations such as high\ncomputational costs, heavy hyperparameter tuning process, and coarse-grained\noptimization. To address these challenges, we propose a novel two-stage noisy\nlearning framework that enables instance-level optimization through a\ndynamically weighted loss function, avoiding hyperparameter tuning. To obtain\nstable and accurate information about noise modeling, we introduce a simple yet\neffective metric, termed wrong event, which dynamically models the cleanliness\nand difficulty of individual samples while maintaining computational costs. Our\nframework first collects wrong event information and builds a strong base\nmodel. Then we perform noise-robust training on the base model, using a\nprobabilistic model to handle the wrong event information of samples.\nExperiments on five synthetic and real-world LNL benchmarks demonstrate our\nmethod surpasses state-of-the-art methods in performance, achieves a nearly 75%\nreduction in computational time and improves model scalability.",
      "tldr_zh": "该研究提出了一种新型两阶段噪声学习框架，用于处理深度神经网络在噪声标签下的泛化性能下降问题。该框架通过动态加权的损失函数实现实例级优化，避免了超参数调整，并引入了“wrong event”指标来动态建模样本的清洁度和难度，同时保持计算成本低。第一阶段收集“wrong event”信息并构建强基线模型，第二阶段使用概率模型进行噪声鲁棒训练。实验在五个合成和真实世界LNL benchmarks上表明，该方法超过了最先进方法，在性能上领先、计算时间减少近75%，并提升了模型可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00812v1",
      "published_date": "2025-05-01 19:12:58 UTC",
      "updated_date": "2025-05-01 19:12:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:30:58.896964"
    },
    {
      "arxiv_id": "2505.00808v1",
      "title": "A Mathematical Philosophy of Explanations in Mechanistic Interpretability -- The Strange Science Part I.i",
      "title_zh": "翻译失败",
      "authors": [
        "Kola Ayonrinde",
        "Louis Jaburi"
      ],
      "abstract": "Mechanistic Interpretability aims to understand neural networks through\ncausal explanations. We argue for the Explanatory View Hypothesis: that\nMechanistic Interpretability research is a principled approach to understanding\nmodels because neural networks contain implicit explanations which can be\nextracted and understood. We hence show that Explanatory Faithfulness, an\nassessment of how well an explanation fits a model, is well-defined. We propose\na definition of Mechanistic Interpretability (MI) as the practice of producing\nModel-level, Ontic, Causal-Mechanistic, and Falsifiable explanations of neural\nnetworks, allowing us to distinguish MI from other interpretability paradigms\nand detail MI's inherent limits. We formulate the Principle of Explanatory\nOptimism, a conjecture which we argue is a necessary precondition for the\nsuccess of Mechanistic Interpretability.",
      "tldr_zh": "这篇论文探讨了 Mechanistic Interpretability 的数学哲学基础，主张 Explanatory View Hypothesis，即神经网络包含可提取的隐含解释，从而使该方法成为理解模型的系统性途径。\n作者定义了 Explanatory Faithfulness，用于评估解释与模型的契合度，并将 Mechanistic Interpretability 界定为生成 Model-level, Ontic, Causal-Mechanistic, and Falsifiable 解释的过程，以区分其与其他解释范式并阐明其内在限制。\n最后，他们提出了 Principle of Explanatory Optimism 作为 Mechanistic Interpretability 取得成功的关键前提。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages (plus appendices), 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00808v1",
      "published_date": "2025-05-01 19:08:34 UTC",
      "updated_date": "2025-05-01 19:08:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:31:11.039005"
    },
    {
      "arxiv_id": "2505.02847v3",
      "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bang Zhang",
        "Ruotian Ma",
        "Qingxuan Jiang",
        "Peisong Wang",
        "Jiaqi Chen",
        "Zheng Xie",
        "Xingyu Chen",
        "Yue Wang",
        "Fanghua Ye",
        "Jian Li",
        "Yifan Yang",
        "Zhaopeng Tu",
        "Xiaolong Li"
      ],
      "abstract": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents.",
      "tldr_zh": "该研究引入了SAGE（Sentient Agent as a Judge），一个自动评估框架，用于测量LLM（Large Language Models）的高阶社会认知，通过模拟一个Sentient Agent来模拟人类般的感情变化和内在想法，在多轮对话中提供更真实的评估。SAGE让Agent在每个回合推理其感情变化、当前感觉和回复策略，从而生成数值化的感情轨迹和可解释的内在想法。实验在100个支持性对话场景中显示，Sentient emotion score与BLRI（Barrett-Lennard Relationship Inventory）评分和utterance-level empathy metrics高度相关，并通过公共Sentient Leaderboard揭示了18个模型间的巨大差距（如GPT-4o-Latest与早期基线相差高达4倍），从而为跟踪LLM向真正移情和社交熟练的语言代理的进展提供了一个原则性、可扩展的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "code: https://github.com/Tencent/digitalhuman/tree/main/SAGE",
      "pdf_url": "http://arxiv.org/pdf/2505.02847v3",
      "published_date": "2025-05-01 19:06:10 UTC",
      "updated_date": "2025-05-21 13:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:31:23.670430"
    },
    {
      "arxiv_id": "2505.00803v1",
      "title": "To Repair or Not to Repair? Investigating the Importance of AB-Cycles for the State-of-the-Art TSP Heuristic EAX",
      "title_zh": "修复还是不修复？调查 AB-Cycles 对于最先进 TSP 启发式算法 EAX 的重要",
      "authors": [
        "Jonathan Heins",
        "Darrell Whitley",
        "Pascal Kerschke"
      ],
      "abstract": "The Edge Assembly Crossover (EAX) algorithm is the state-of-the-art heuristic\nfor solving the Traveling Salesperson Problem (TSP). It regularly outperforms\nother methods, such as the Lin-Kernighan-Helsgaun heuristic (LKH), across\ndiverse sets of TSP instances. Essentially, EAX employs a two-stage mechanism\nthat focuses on improving the current solutions, first, at the local and,\nsubsequently, at the global level. Although the second phase of the algorithm\nhas been thoroughly studied, configured, and refined in the past, in\nparticular, its first stage has hardly been examined.\n  In this paper, we thus focus on the first stage of EAX and introduce a novel\nmethod that quickly verifies whether the AB-cycles, generated during its\ninternal optimization procedure, yield valid tours -- or whether they need to\nbe repaired. Knowledge of the latter is also particularly relevant before\napplying other powerful crossover operators such as the Generalized Partition\nCrossover (GPX). Based on our insights, we propose and evaluate several\nimproved versions of EAX. According to our benchmark study across 10 000\ndifferent TSP instances, the most promising of our proposed EAX variants\ndemonstrates improved computational efficiency and solution quality on\npreviously rather difficult instances compared to the current state-of-the-art\nEAX algorithm.",
      "tldr_zh": "这篇论文探讨了Edge Assembly Crossover (EAX)算法在解决Traveling Salesperson Problem (TSP)时的第一阶段，重点调查AB-cycles的重要性，因为这一阶段之前鲜有研究。作者引入了一种新方法，能够快速验证AB-cycles是否生成有效路径，并决定是否需要修复，这也适用于其他交叉操作如Generalized Partition Crossover (GPX)。通过在10,000个不同TSP实例上的基准测试，最优的EAX改进版本显示出更高的计算效率和解决方案质量，尤其在之前难以处理的实例中。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00803v1",
      "published_date": "2025-05-01 19:04:23 UTC",
      "updated_date": "2025-05-01 19:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:31:34.885641"
    },
    {
      "arxiv_id": "2505.00802v1",
      "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Vasiliki Papanikou",
        "Danae Pla Karidi",
        "Evaggelia Pitoura",
        "Emmanouil Panagiotou",
        "Eirini Ntoutsi"
      ],
      "abstract": "As Artificial Intelligence (AI) is increasingly used in areas that\nsignificantly impact human lives, concerns about fairness and transparency have\ngrown, especially regarding their impact on protected groups. Recently, the\nintersection of explainability and fairness has emerged as an important area to\npromote responsible AI systems. This paper explores how explainability methods\ncan be leveraged to detect and interpret unfairness. We propose a pipeline that\nintegrates local post-hoc explanation methods to derive fairness-related\ninsights. During the pipeline design, we identify and address critical\nquestions arising from the use of explanations as bias detectors such as the\nrelationship between distributive and procedural fairness, the effect of\nremoving the protected attribute, the consistency and quality of results across\ndifferent explanation methods, the impact of various aggregation strategies of\nlocal explanations on group fairness evaluations, and the overall\ntrustworthiness of explanations as bias detectors. Our results show the\npotential of explanation methods used for fairness while highlighting the need\nto carefully consider the aforementioned critical aspects.",
      "tldr_zh": "本论文探讨了可解释性方法（XAI）在检测AI系统不公平性中的潜力，特别关注其对受保护群体的影响。作者提出一个整合本地后验XAI方法的管道，用于衍生公平相关洞见，并处理关键问题，如分配公平性（distributive fairness）和程序公平性（procedural fairness）的关系、移除保护属性（protected attribute）的效果、不同解释方法的一致性和质量，以及聚合策略（aggregation strategies）对群体公平性（group fairness）评估的影响。研究结果显示，这种方法能有效提升公平性探索，但需谨慎评估其整体可信度（trustworthiness）以避免潜在偏差。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00802v1",
      "published_date": "2025-05-01 19:03:18 UTC",
      "updated_date": "2025-05-01 19:03:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:31:47.322890"
    },
    {
      "arxiv_id": "2505.07833v1",
      "title": "Patchwork: A Unified Framework for RAG Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Bodun Hu",
        "Luis Pabon",
        "Saurabh Agarwal",
        "Aditya Akella"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has emerged as a new paradigm for\nenhancing Large Language Model reliability through integration with external\nknowledge sources. However, efficient deployment of these systems presents\nsignificant technical challenges due to their inherently heterogeneous\ncomputational pipelines comprising LLMs, databases, and specialized processing\ncomponents. We introduce Patchwork, a comprehensive end-to-end RAG serving\nframework designed to address these efficiency bottlenecks. Patchwork's\narchitecture offers three key innovations: First, it provides a flexible\nspecification interface enabling users to implement custom RAG pipelines.\nSecondly, it deploys these pipelines as distributed inference systems while\noptimizing for the unique scalability characteristics of individual RAG\ncomponents. Third, Patchwork incorporates an online scheduling mechanism that\ncontinuously monitors request load and execution progress, dynamically\nminimizing SLO violations through strategic request prioritization and resource\nauto-scaling. Our experimental evaluation across four distinct RAG\nimplementations demonstrates that Patchwork delivers substantial performance\nimprovements over commercial alternatives, achieving throughput gains exceeding\n48% while simultaneously reducing SLO violations by ~24%.",
      "tldr_zh": "论文提出了 Patchwork，一种统一的端到端 RAG 服务框架，用于解决检索增强生成（RAG）系统在部署时的效率瓶颈，该系统涉及异构计算管道如 LLMs、数据库和专用处理组件。Patchwork 的关键创新包括提供灵活的规范接口以实现自定义 RAG 管道、优化分布式推理系统的可伸缩性，以及集成在线调度机制来监控请求负载并通过请求优先级和资源自动缩放最小化 SLO 违规。实验评估显示，在四个不同的 RAG 实现中，Patchwork 比商业替代方案提高了超过 48% 的吞吐量，同时减少了约 24% 的 SLO 违规，为高效的 RAG 部署提供了可靠解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.MA",
        "cs.OS"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07833v1",
      "published_date": "2025-05-01 18:58:26 UTC",
      "updated_date": "2025-05-01 18:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:31:59.705775"
    },
    {
      "arxiv_id": "2505.00795v1",
      "title": "Howard's Policy Iteration is Subexponential for Deterministic Markov Decision Problems with Rewards of Fixed Bit-size and Arbitrary Discount Factor",
      "title_zh": "Howard's 策略迭代在奖励具有固定比特大小和任意折扣因子的确定",
      "authors": [
        "Dibyangshu Mukherjee",
        "Shivaram Kalyanakrishnan"
      ],
      "abstract": "Howard's Policy Iteration (HPI) is a classic algorithm for solving Markov\nDecision Problems (MDPs). HPI uses a \"greedy\" switching rule to update from any\nnon-optimal policy to a dominating one, iterating until an optimal policy is\nfound. Despite its introduction over 60 years ago, the best-known upper bounds\non HPI's running time remain exponential in the number of states -- indeed even\non the restricted class of MDPs with only deterministic transitions (DMDPs).\nMeanwhile, the tightest lower bound for HPI for MDPs with a constant number of\nactions per state is only linear. In this paper, we report a significant\nimprovement: a subexponential upper bound for HPI on DMDPs, which is\nparameterised by the bit-size of the rewards, while independent of the discount\nfactor. The same upper bound also applies to DMDPs with only two possible\nrewards (which may be of arbitrary size).",
      "tldr_zh": "本研究证明了Howard's Policy Iteration (HPI)在Deterministic Markov Decision Problems (DMDPs)上的运行时间具有次指数上界(subexponential upper bound)，该上界依赖于奖励的固定位大小，而与折扣因子无关。HPI是一种经典算法，通过贪婪切换规则迭代更新策略以求解MDPs，但现有上界仍为指数级。本文填补了这一空白，并扩展了结果到仅具有两种可能奖励的DMDPs，提供了一个重大改进。实验和分析显示，这一上界显著降低了HPI的计算复杂度，尤其在奖励位大小有限的场景中。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00795v1",
      "published_date": "2025-05-01 18:50:10 UTC",
      "updated_date": "2025-05-01 18:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:32:10.339283"
    },
    {
      "arxiv_id": "2505.00793v1",
      "title": "Scalable Meta-Learning via Mixed-Mode Differentiation",
      "title_zh": "翻译失败",
      "authors": [
        "Iurii Kemaev",
        "Dan A Calian",
        "Luisa M Zintgraf",
        "Gregory Farquhar",
        "Hado van Hasselt"
      ],
      "abstract": "Gradient-based bilevel optimisation is a powerful technique with applications\nin hyperparameter optimisation, task adaptation, algorithm discovery,\nmeta-learning more broadly, and beyond. It often requires differentiating\nthrough the gradient-based optimisation process itself, leading to\n\"gradient-of-a-gradient\" calculations with computationally expensive\nsecond-order and mixed derivatives. While modern automatic differentiation\nlibraries provide a convenient way to write programs for calculating these\nderivatives, they oftentimes cannot fully exploit the specific structure of\nthese problems out-of-the-box, leading to suboptimal performance. In this\npaper, we analyse such cases and propose Mixed-Flow Meta-Gradients, or\nMixFlow-MG -- a practical algorithm that uses mixed-mode differentiation to\nconstruct more efficient and scalable computational graphs yielding over 10x\nmemory and up to 25% wall-clock time improvements over standard implementations\nin modern meta-learning setups.",
      "tldr_zh": "本研究针对基于梯度的双层优化（bilevel optimisation）在元学习（meta-learning）等领域的应用，指出其计算高阶导数（如“gradient-of-a-gradient”）会导致效率低下。论文提出Mixed-Flow Meta-Gradients（MixFlow-MG）算法，通过mixed-mode differentiation构建更高效的计算图，充分利用问题结构以优化性能。在实验中，该方法在现代元学习设置中实现了超过10倍的内存节省和高达25%的墙钟时间改善，从而提升了整体可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00793v1",
      "published_date": "2025-05-01 18:46:44 UTC",
      "updated_date": "2025-05-01 18:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:32:22.099233"
    },
    {
      "arxiv_id": "2505.03796v1",
      "title": "AI-Driven IRM: Transforming insider risk management with adaptive scoring and LLM-based threat detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lokesh Koli",
        "Shubham Kalra",
        "Rohan Thakur",
        "Anas Saifi",
        "Karanpreet Singh"
      ],
      "abstract": "Insider threats pose a significant challenge to organizational security,\noften evading traditional rule-based detection systems due to their subtlety\nand contextual nature. This paper presents an AI-powered Insider Risk\nManagement (IRM) system that integrates behavioral analytics, dynamic risk\nscoring, and real-time policy enforcement to detect and mitigate insider\nthreats with high accuracy and adaptability. We introduce a hybrid scoring\nmechanism - transitioning from the static PRISM model to an adaptive AI-based\nmodel utilizing an autoencoder neural network trained on expert-annotated user\nactivity data. Through iterative feedback loops and continuous learning, the\nsystem reduces false positives by 59% and improves true positive detection\nrates by 30%, demonstrating substantial gains in detection precision.\nAdditionally, the platform scales efficiently, processing up to 10 million log\nevents daily with sub-300ms query latency, and supports automated enforcement\nactions for policy violations, reducing manual intervention. The IRM system's\ndeployment resulted in a 47% reduction in incident response times, highlighting\nits operational impact. Future enhancements include integrating explainable AI,\nfederated learning, graph-based anomaly detection, and alignment with Zero\nTrust principles to further elevate its adaptability, transparency, and\ncompliance-readiness. This work establishes a scalable and proactive framework\nfor mitigating emerging insider risks in both on-premises and hybrid\nenvironments.",
      "tldr_zh": "本文提出了一种AI驱动的内部风险管理(IRM)系统，通过整合行为分析、动态风险评分和实时政策执行，来提升内部威胁的检测准确性和适应性。系统采用混合评分机制，从静态PRISM模型过渡到基于自编码器神经网络的自适应AI模型，利用专家标注的用户活动数据进行训练，并通过迭代反馈循环减少假阳性59%并提高真阳性检测率30%。该系统高效处理，每天可管理1000万日志事件，查询延迟低于300ms，并支持自动执行动作，实现了47%的响应时间减少。未来，该框架计划整合可解释AI、联邦学习、基于图的异常检测，以及Zero Trust原则，以进一步提升可扩展性和合规性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03796v1",
      "published_date": "2025-05-01 18:41:00 UTC",
      "updated_date": "2025-05-01 18:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:32:35.589848"
    },
    {
      "arxiv_id": "2505.00787v1",
      "title": "Constructing an Optimal Behavior Basis for the Option Keyboard",
      "title_zh": "构建 Option Keyboard 的最优行为基础",
      "authors": [
        "Lucas N. Alegre",
        "Ana L. C. Bazzan",
        "André Barreto",
        "Bruno C. da Silva"
      ],
      "abstract": "Multi-task reinforcement learning aims to quickly identify solutions for new\ntasks with minimal or no additional interaction with the environment.\nGeneralized Policy Improvement (GPI) addresses this by combining a set of base\npolicies to produce a new one that is at least as good -- though not\nnecessarily optimal -- as any individual base policy. Optimality can be\nensured, particularly in the linear-reward case, via techniques that compute a\nConvex Coverage Set (CCS). However, these are computationally expensive and do\nnot scale to complex domains. The Option Keyboard (OK) improves upon GPI by\nproducing policies that are at least as good -- and often better. It achieves\nthis through a learned meta-policy that dynamically combines base policies.\nHowever, its performance critically depends on the choice of base policies.\nThis raises a key question: is there an optimal set of base policies -- an\noptimal behavior basis -- that enables zero-shot identification of optimal\nsolutions for any linear tasks? We solve this open problem by introducing a\nnovel method that efficiently constructs such an optimal behavior basis. We\nshow that it significantly reduces the number of base policies needed to ensure\noptimality in new tasks. We also prove that it is strictly more expressive than\na CCS, enabling particular classes of non-linear tasks to be solved optimally.\nWe empirically evaluate our technique in challenging domains and show that it\noutperforms state-of-the-art approaches, increasingly so as task complexity\nincreases.",
      "tldr_zh": "这篇论文针对多任务强化学习，提出一种新方法来构建最优行为基础（optimal behavior basis），以提升Option Keyboard (OK)框架的性能，确保对新线性任务实现零样本最优解决方案。该方法通过高效计算减少所需基策略的数量，并证明其比Generalized Policy Improvement (GPI)和Convex Coverage Set (CCS)更具表达性，能够处理特定非线性任务。实验结果显示，在挑战性领域中，该技术显著优于现有方法，尤其在任务复杂度增加时表现更突出。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00787v1",
      "published_date": "2025-05-01 18:32:21 UTC",
      "updated_date": "2025-05-01 18:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:32:47.147536"
    },
    {
      "arxiv_id": "2505.03795v2",
      "title": "Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Skaggs",
        "Jacob W. Crandall"
      ],
      "abstract": "Human networks greatly impact important societal outcomes, including wealth\nand health inequality, poverty, and bullying. As such, understanding human\nnetworks is critical to learning how to promote favorable societal outcomes. As\na step toward better understanding human networks, we compare and contrast\nseveral methods for learning, from a small data set, models of human behavior\nin a strategic network game called the Junior High Game (JHG). These modeling\nmethods differ with respect to the assumptions they use to parameterize human\nbehavior (behavior vs. community-aware behavior) and the moments they model\n(mean vs. distribution). Results show that the highest-performing method,\ncalled hCAB, models the distribution of human behavior rather than the mean and\nassumes humans use community-aware behavior rather than behavior matching. When\napplied to small societies (6-11 individuals), the hCAB model closely mirrors\nthe population dynamics of human groups (with notable differences).\nAdditionally, in a user study, human participants were unable to distinguish\nindividual hCAB agents from other humans, thus illustrating that the hCAB model\nalso produces plausible (individual) human behavior in this strategic network\ngame.",
      "tldr_zh": "该论文探讨了在战略网络游戏（如Junior High Game, JHG）中建模人类行为，以理解人类网络对社会结果（如财富不平等和贫困）的深远影响。研究比较了多种建模方法，包括行为参数化（behavior vs. community-aware behavior）和建模时刻（mean vs. distribution），结果显示hCAB方法表现最佳，因为它关注人类行为的分布而非均值，并假设个体采用community-aware behavior。在小型社会（6-11人）实验中，hCAB模型能准确模拟群体动态，且用户研究证明，人类难以区分hCAB代理与真实个体行为，从而为更真实的人类网络模拟提供可信框架。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03795v2",
      "published_date": "2025-05-01 18:13:20 UTC",
      "updated_date": "2025-05-15 17:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:32:59.903984"
    },
    {
      "arxiv_id": "2505.00703v1",
      "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT",
      "title_zh": "翻译失败",
      "authors": [
        "Dongzhi Jiang",
        "Ziyu Guo",
        "Renrui Zhang",
        "Zhuofan Zong",
        "Hao Li",
        "Le Zhuo",
        "Shilin Yan",
        "Pheng-Ann Heng",
        "Hongsheng Li"
      ],
      "abstract": "Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1",
      "tldr_zh": "本论文提出 T2I-R1，一种通过强化学习 (RL) 和双层 Chain-of-Thought (CoT) 协作优化的文本到图像生成模型。\n该模型利用语义级 CoT 进行高层次提示规划，以及标记级 CoT 实现低层次像素处理，并通过 BiCoT-GRPO 整合生成奖励来协调优化这两个层级。\n实验结果显示，T2I-R1 在基线模型 Janus-Pro 的基础上，在 T2I-CompBench 上提升 13%，在 WISE 基准上提升 19%，甚至超过了最先进模型 FLUX.1。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://github.com/CaraJ7/T2I-R1",
      "pdf_url": "http://arxiv.org/pdf/2505.00703v1",
      "published_date": "2025-05-01 17:59:46 UTC",
      "updated_date": "2025-05-01 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:33:11.429642"
    },
    {
      "arxiv_id": "2505.00693v2",
      "title": "Robotic Visual Instruction",
      "title_zh": "机器人视觉指令",
      "authors": [
        "Yanbang Li",
        "Ziyang Gong",
        "Haoyang Li",
        "Xiaoqi Huang",
        "Haolan Kang",
        "Guangping Bai",
        "Xianzheng Ma"
      ],
      "abstract": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision introduces\nchallenges for robotic task definition such as ambiguity and verbosity.\nMoreover, in some public settings where quiet is required, such as libraries or\nhospitals, verbal communication with robots is inappropriate. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment,enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Project\nwebsite: https://robotic-visual-instruction.github.io/",
      "tldr_zh": "该研究指出，自然语言作为人机交互的主要方式存在空间精度不足、模糊性和冗长问题，尤其在安静环境中不适用。为此，提出Robotic Visual Instruction (RoVI)，一种基于物体中心的2D手绘符号表示（如箭头、圆圈、颜色和数字），用于精确指导3D机器人操作。作者开发了Visual Instruction Embodied Workflow (VIEW)管道，利用Vision-Language Models (VLMs)来解释RoVI输入、提取关键点并转化为可执行动作序列，并构建了15K实例数据集来微调小型VLMs以支持边缘部署。在真实和模拟环境中，VIEW在11个新任务上验证了其泛化能力，实现了87.5%的成功率，包括多步动作、干扰和轨迹跟踪的未见场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://robotic-visual-instruction.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.00693v2",
      "published_date": "2025-05-01 17:55:05 UTC",
      "updated_date": "2025-05-06 09:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:33:23.501163"
    },
    {
      "arxiv_id": "2505.00690v1",
      "title": "Towards Autonomous Micromobility through Scalable Urban Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Wayne Wu",
        "Honglin He",
        "Chaoyuan Zhang",
        "Jack He",
        "Seth Z. Zhao",
        "Ran Gong",
        "Quanyi Li",
        "Bolei Zhou"
      ],
      "abstract": "Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.",
      "tldr_zh": "该研究针对微观机动性（micromobility，如送货机器人和移动滑板车）的安全和效率问题，提出一个可扩展的城市模拟解决方案，以推进其自治能力。论文构建了 URBAN-SIM 平台，包括 Hierarchical Urban Generation pipeline、Interactive Dynamics Generation strategy 和 Asynchronous Scene Sampling scheme 等模块，提升了机器人学习在交互城市场景中的多样性、真实性和效率。作者还开发了 URBAN-BENCH 基准套件，涵盖八个任务基于 AI 代理的三个核心技能：Urban Locomotion、Urban Navigation 和 Urban Traverse，并评估了四种不同形态（如轮式和腿式）的机器人。实验结果在多样地形和城市结构上揭示了各机器人的优势和局限性，为提升城市机动性提供了重要参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 Highlight. Project page:\n  https://metadriverse.github.io/urban-sim/",
      "pdf_url": "http://arxiv.org/pdf/2505.00690v1",
      "published_date": "2025-05-01 17:52:29 UTC",
      "updated_date": "2025-05-01 17:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:33:37.372797"
    },
    {
      "arxiv_id": "2505.02846v1",
      "title": "The Precautionary Principle and the Innovation Principle: Incompatible Guides for AI Innovation Governance?",
      "title_zh": "预防原则和创新原则：AI 创新治理的不兼容指导原则？",
      "authors": [
        "Kim Kaivanto"
      ],
      "abstract": "In policy debates concerning the governance and regulation of Artificial\nIntelligence (AI), both the Precautionary Principle (PP) and the Innovation\nPrinciple (IP) are advocated by their respective interest groups. Do these\nprinciples offer wholly incompatible and contradictory guidance? Does one\nnecessarily negate the other? I argue here that provided attention is\nrestricted to weak-form PP and IP, the answer to both of these questions is\n\"No.\" The essence of these weak formulations is the requirement to fully\naccount for type-I error costs arising from erroneously preventing the\ninnovation's diffusion through society (i.e. mistaken regulatory red-lighting)\nas well as the type-II error costs arising from erroneously allowing the\ninnovation to diffuse through society (i.e. mistaken regulatory\ngreen-lighting). Within the Signal Detection Theory (SDT) model developed here,\nweak-PP red-light (weak-IP green-light) determinations are optimal for\nsufficiently small (large) ratios of expected type-I to type-II error costs.\nFor intermediate expected cost ratios, an amber-light 'wait-and-monitor' policy\nis optimal. Regulatory sandbox instruments allow AI testing and experimentation\nto take place within a structured environment of limited duration and societal\nscale, whereby the expected cost ratio falls within the 'wait-and-monitor'\nrange. Through sandboxing regulators and innovating firms learn more about the\nexpected cost ratio, and what respective adaptations -- of regulation, of\ntechnical solution, of business model, or combination thereof, if any -- are\nneeded to keep the ratio out of the weak-PP red-light zone.",
      "tldr_zh": "该研究探讨了在AI创新治理中，预防原则(Precautionary Principle, PP)和创新原则(Innovation Principle, IP)是否相互矛盾。作者认为，如果采用弱形式，这两个原则并不完全不相容，而是强调全面考虑type-I错误成本（错误禁止创新）和type-II错误成本（错误允许创新）。基于Signal Detection Theory (SDT)模型，论文指出，对于预期成本比较小（较大）时，弱-PP红灯（弱-IP绿灯）政策最优，而中间情况则建议采用“等待和监控”的黄灯策略，如通过regulatory sandbox在有限环境中测试AI，以帮助监管者和创新者调整策略并降低风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "47 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.02846v1",
      "published_date": "2025-05-01 17:48:18 UTC",
      "updated_date": "2025-05-01 17:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:33:46.422169"
    },
    {
      "arxiv_id": "2505.00759v2",
      "title": "Multi-Modal Language Models as Text-to-Image Model Evaluators",
      "title_zh": "多模态语言模型作为文本到图像模型评估器",
      "authors": [
        "Jiahui Chen",
        "Candace Ross",
        "Reyhane Askari-Hemmat",
        "Koustuv Sinha",
        "Melissa Hall",
        "Michal Drozdzal",
        "Adriana Romero-Soriano"
      ],
      "abstract": "The steady improvements of text-to-image (T2I) generative models lead to slow\ndeprecation of automatic evaluation benchmarks that rely on static datasets,\nmotivating researchers to seek alternative ways to evaluate the T2I progress.\nIn this paper, we explore the potential of multi-modal large language models\n(MLLMs) as evaluator agents that interact with a T2I model, with the objective\nof assessing prompt-generation consistency and image aesthetics. We present\nMultimodal Text-to-Image Eval (MT2IE), an evaluation framework that iteratively\ngenerates prompts for evaluation, scores generated images and matches T2I\nevaluation of existing benchmarks with a fraction of the prompts used in\nexisting static benchmarks. Moreover, we show that MT2IE's prompt-generation\nconsistency scores have higher correlation with human judgment than scores\npreviously introduced in the literature. MT2IE generates prompts that are\nefficient at probing T2I model performance, producing the same relative T2I\nmodel rankings as existing benchmarks while using only 1/80th the number of\nprompts for evaluation.",
      "tldr_zh": "该研究探讨了多模态大型语言模型 (MLLMs) 作为文本到图像 (T2I) 模型评估器的潜力，以解决基于静态数据集的评估基准过时的问题。作者提出 Multimodal Text-to-Image Eval (MT2IE) 框架，该框架通过迭代生成提示、评分生成的图像并评估提示生成一致性和图像美学，从而高效地匹配现有基准。实验结果表明，MT2IE 的评分与人类判断的相关性更高，且只需使用1/80的提示数量，就能探测 T2I 模型性能并产生相同的相对模型排名。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00759v2",
      "published_date": "2025-05-01 17:47:55 UTC",
      "updated_date": "2025-05-12 20:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:33:59.192053"
    },
    {
      "arxiv_id": "2505.00684v1",
      "title": "Visual Test-time Scaling for GUI Agent Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Tiange Luo",
        "Lajanugen Logeswaran",
        "Justin Johnson",
        "Honglak Lee"
      ],
      "abstract": "We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.",
      "tldr_zh": "本研究引入RegionFocus，一种视觉测试时缩放(visual test-time scaling)方法，用于提升Vision Language Model Agents在GUI界面上的代理定位准确性。该方法通过动态放大相关区域减少背景杂乱，并采用image-as-map机制可视化关键地标，提供透明的动作记录以辅助代理选择动作候选。即使使用简单区域选择策略，实验结果显示RegionFocus在Screenspot-pro和WebVoyager基准上使UI-TARS和Qwen2.5-VL模型的性能分别提升28+%和24+%。此外，在ScreenSpot-Pro基准上，结合Qwen2.5-VL-72B模型，该方法实现了61.6%的全新state-of-the-art定位性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00684v1",
      "published_date": "2025-05-01 17:45:59 UTC",
      "updated_date": "2025-05-01 17:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:34:11.537017"
    },
    {
      "arxiv_id": "2505.01462v2",
      "title": "Emotions in Artificial Intelligence",
      "title_zh": "人工智能中的情感",
      "authors": [
        "Hermann Borotschnig"
      ],
      "abstract": "This conceptual contribution offers a speculative account of how AI systems\nmight emulate emotions as experienced by humans and animals. It presents a\nthought experiment grounded in the hypothesis that natural emotions evolved as\nheuristics for rapid situational appraisal and action selection, enabling\nbiologically adaptive behaviour without requiring full deliberative modeling.\nThe text examines whether artificial systems operating in complex action spaces\ncould similarly benefit from these principles. It is proposed that affect be\ninterwoven with episodic memory by storing corresponding affective tags\nalongside all events. This allows AIs to establish whether present situations\nresemble past events and project the associated emotional labels onto the\ncurrent context. These emotional cues are then combined with need-driven\nemotional hints. The combined emotional state facilitates decision-making in\nthe present by modulating action selection. The low complexity and experiential\ninertness of the proposed architecture are emphasized as evidence that\nemotional expression and consciousness are, in principle, orthogonal-permitting\nthe theoretical possibility of affective zombies. On this basis, the moral\nstatus of AIs emulating affective states is critically examined. It is argued\nthat neither the mere presence of internal representations of emotion nor\nconsciousness alone suffices for moral standing; rather, the capacity for\nself-awareness of inner emotional states is posited as a necessary condition. A\ncomplexity-based criterion is proposed to exclude such awareness in the\npresented model. Additional thought experiments are presented to test the\nconceptual boundaries of this framework.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)如何模拟人类和动物的情绪，基于情绪作为快速评估情况和行动选择的启发式演化假设。该框架建议将情绪与情景记忆(episodic memory)整合，通过在事件中存储情绪标签(affective tags)并结合需求驱动的情绪线索，来辅助AI在复杂环境中进行决策。论文强调这种低复杂度的架构可能允许AI表现出情绪而不具备意识，从而质疑模拟情绪的AI在道德地位(moral standing)上的界限，并提出自知觉(inner emotional states)作为道德必要条件，同时通过思想实验测试该概念的边界。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "68T01, 68T37",
        "I.2.0; K.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "40 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.01462v2",
      "published_date": "2025-05-01 17:37:14 UTC",
      "updated_date": "2025-05-12 15:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:34:22.230210"
    },
    {
      "arxiv_id": "2505.00668v1",
      "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Kirtan Rajesh",
        "Suvidha Rupesh Kumar"
      ],
      "abstract": "Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management.",
      "tldr_zh": "这篇论文针对城市空气污染问题（如德里的高污染水平），提出了一种基于 Deep Reinforcement Learning (DRL) 的框架，用于多目标优化空气净化 booths 的放置位置。研究采用 Proximal Policy Optimization (PPO) 算法，考虑因素包括人口密度、交通模式、工业影响和绿色空间约束，通过迭代学习实现高效布局。实验结果显示，该方法在 AQI 改善、空间覆盖和人口影响等方面优于随机和贪婪基线策略，实现了 AQI 减少与高覆盖率的平衡，并为智能城市和数据驱动的空气质量管理提供了重要潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00668v1",
      "published_date": "2025-05-01 17:19:48 UTC",
      "updated_date": "2025-05-01 17:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:34:34.791294"
    },
    {
      "arxiv_id": "2505.00663v1",
      "title": "Wasserstein Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "David Pfau",
        "Ian Davies",
        "Diana Borsa",
        "Joao G. M. Araujo",
        "Brendan Tracey",
        "Hado van Hasselt"
      ],
      "abstract": "We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods.",
      "tldr_zh": "该论文引入了Wasserstein Policy Optimization (WPO)，一种actor-critic算法，用于连续动作空间的强化学习。WPO通过对Wasserstein梯度流在有限维参数空间的投影进行近似，得到一个简单且通用的闭环更新规则，该算法同时继承了确定性策略梯度的动作价值函数梯度利用优势，以及经典policy gradients的适用性，能处理任意分布的随机策略而不需reparameterization trick。在DeepMind Control Suite和磁约束聚变任务的实验中，WPO的表现优于最先进连续控制方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00663v1",
      "published_date": "2025-05-01 17:07:01 UTC",
      "updated_date": "2025-05-01 17:07:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:34:47.724689"
    },
    {
      "arxiv_id": "2505.00662v1",
      "title": "DeepCritic: Deliberate Critique with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenkai Yang",
        "Jingwen Chen",
        "Yankai Lin",
        "Ji-Rong Wen"
      ],
      "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.",
      "tldr_zh": "该研究提出DeepCritic框架，利用大型语言模型(LLMs)来提供更精确的数学问题批评，从而解决现有LLM批评过于浅显的问题。框架分为两阶段：首先，使用Qwen2.5-72B-Instruct生成4.5K条长形式种子数据，进行监督微调，每个批评包括针对推理步骤的多视角验证和深入分析；其次，通过强化学习（如利用PRM800K数据或Monte Carlo采样估计正确性）进一步提升模型能力。实验结果显示，基于Qwen2.5-7B-Instruct的DeepCritic模型在错误识别基准上显著优于DeepSeek-R1-distill和GPT-4o等模型，并能通过详细反馈更有效地帮助LLM生成器修正错误。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Data and models are available at\n  https://github.com/RUCBM/DeepCritic",
      "pdf_url": "http://arxiv.org/pdf/2505.00662v1",
      "published_date": "2025-05-01 17:03:17 UTC",
      "updated_date": "2025-05-01 17:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:34:59.551942"
    },
    {
      "arxiv_id": "2505.00661v2",
      "title": "On the generalization of language models from in-context learning and finetuning: a controlled study",
      "title_zh": "语言模型从上下文学习和微调的泛化：一个受控研究",
      "authors": [
        "Andrew K. Lampinen",
        "Arslan Chaudhry",
        "Stephanie C. Y. Chan",
        "Cody Wild",
        "Diane Wan",
        "Alex Ku",
        "Jörg Bornschein",
        "Razvan Pascanu",
        "Murray Shanahan",
        "James L. McClelland"
      ],
      "abstract": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning. E.g. they can fail to\ngeneralize to simple reversals of relations they are trained on, or fail to\nmake simple logical deductions based on trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nOn the other hand, language models' in-context learning shows different\ninductive biases, and can generalize better in some cases. Here, we explore\nthese differences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' abilities to generalize from finetuning data. The datasets are\ndesigned to create clean tests of generalization, by isolating the knowledge in\nthe dataset from that in pretraining. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.",
      "tldr_zh": "这篇研究探讨了大语言模型（Large Language Models）在 in-context learning 和 finetuning 两种学习模式下的泛化能力，指出 finetuning 可能导致狭隘的泛化，例如无法处理关系的反转或逻辑推理。研究者构建了新数据集，通过控制实验隔离预训练知识，比较模型在不同模式下暴露于子集数据后的泛化性能。结果显示，在数据匹配场景中，in-context learning 通常比 finetuning 更灵活，尽管 finetuning 在某些结构化知识中也能泛化。作者提出了一种改进方法：向 finetuning 数据中添加 in-context inferences，从而提升模型在各种数据集分割和基准上的泛化效果。该研究为理解语言模型的归纳偏差（inductive biases）和优化其实际应用提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00661v2",
      "published_date": "2025-05-01 17:02:27 UTC",
      "updated_date": "2025-05-06 20:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:35:11.918116"
    },
    {
      "arxiv_id": "2505.00654v3",
      "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel N. Nissani"
      ],
      "abstract": "A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.",
      "tldr_zh": "本文探讨了大型语言模型（LLMs）是否能够理解世界和对话含义的 ongoing 辩论，通过一个思想实验和半正式的考虑，提出一个 inherent ambiguity barrier 作为固有障碍。作者认为，尽管 LLMs 能生成流畅的对话，但这一模糊性壁垒使得它们无法真正捕捉对话的深层含义。该研究为评估 LLMs 的理解能力提供了新的哲学和理论视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "submitted to NEURAL COMPUTATION",
      "pdf_url": "http://arxiv.org/pdf/2505.00654v3",
      "published_date": "2025-05-01 16:55:44 UTC",
      "updated_date": "2025-05-08 10:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:35:23.407986"
    },
    {
      "arxiv_id": "2505.00651v2",
      "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management",
      "title_zh": "开源 LLM ",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Ishtiaq Ahmad"
      ],
      "abstract": "The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.",
      "tldr_zh": "该研究提出Federated Prompt-Optimized Traffic Transformer (FPoTT)，一个基于开源Large Language Models (LLMs)的框架，用于解决Internet of Vehicles (IoV)管理中的可扩展性、实时性和隐私保护挑战。FPoTT引入动态提示优化机制和双层联邦学习范式，将边缘轻量级模型用于实时推理，并结合云端LLMs及Transformer驱动的合成数据生成器（如NGSIM格式）增强训练。实验结果显示，使用EleutherAI Pythia-1B模型，FPoTT在真实数据上实现99.86%的轨迹预测准确率，并在合成数据集上保持高性能，从而为安全、可适应IoV管理提供开源替代方案。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint version; submitted for academic peer review",
      "pdf_url": "http://arxiv.org/pdf/2505.00651v2",
      "published_date": "2025-05-01 16:54:21 UTC",
      "updated_date": "2025-05-13 16:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:35:35.382975"
    },
    {
      "arxiv_id": "2505.00650v1",
      "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification",
      "title_zh": "OmicsCL：用于癌症亚型发现和生存分层的无监督对比学习",
      "authors": [
        "Atahan Karagoz"
      ],
      "abstract": "Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data.",
      "tldr_zh": "本研究引入了OmicsCL，一个模块化的无监督对比学习框架，用于从多组学数据（如gene expression、DNA methylation和miRNA expression）中联合嵌入异构模式到统一潜在空间，并通过survival-aware contrastive loss学习与生存相关模式，而无需依赖标签。OmicsCL在TCGA BRCA数据集上评估，成功揭示了临床有意义的聚类，并实现了强有力的无监督生存一致性，同时在超参数配置上表现出鲁棒性，可调整以优先subtype coherence或survival stratification。消融研究证实，整合survival-aware loss显著提升了学习嵌入的预测能力，从而为个性化医学中的癌症亚型发现和生存分层提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at: https://github.com/Atahanka/OmicsCL",
      "pdf_url": "http://arxiv.org/pdf/2505.00650v1",
      "published_date": "2025-05-01 16:51:48 UTC",
      "updated_date": "2025-05-01 16:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:35:47.601183"
    },
    {
      "arxiv_id": "2505.00643v1",
      "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI",
      "title_zh": "深度学习辅助外体积去除用于高加速实时动态磁共振成像",
      "authors": [
        "Merve Gülle",
        "Sebastian Weingärtner",
        "Mehmet Akçakaya"
      ],
      "abstract": "Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality.",
      "tldr_zh": "这篇论文针对实时动态 MRI（如 RT cine MRI）中高加速率导致的混叠伪像问题，提出了一种新型外体积去除 (OVR) 方法，以消除心脏外组织对图像质量的干扰。方法通过时间交错欠采样模式估计外体积信号，并利用深度学习 (DL) 模型识别并移除伪像，随后采用物理驱动的 DL (PD-DL) 方法结合 OVR 特定损失函数进行高时空分辨率图像重建。实验结果显示，该方法在高加速率下实现与临床基准图像相当的质量，并在定性和定量上优于传统重建技术，提供了一种无需修改采集过程的实用解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00643v1",
      "published_date": "2025-05-01 16:31:52 UTC",
      "updated_date": "2025-05-01 16:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:35:59.451351"
    },
    {
      "arxiv_id": "2505.00626v2",
      "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)",
      "title_zh": "角色分离的幻觉：LLM 角色学习中的隐藏捷径（以及如何修复它们）",
      "authors": [
        "Zihao Wang",
        "Yibo Jiang",
        "Jiahao Yu",
        "Heqing Huang"
      ],
      "abstract": "Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 在处理多角色输入（如系统指令和用户查询）时，角色分离（role separation）存在的幻觉问题，即模型往往依赖隐藏捷径，如任务类型利用和文本起始位置，而非真正区分角色。通过一个简单实验框架，作者发现数据增强只能部分缓解这些捷径，但无法根除。为解决此问题，他们提出强化不变信号的方法，例如通过操纵位置 IDs（position IDs）调整输入编码，以帮助模型更清晰地学习角色边界。该工作从机制视角提升了 LLMs 的多角色行为一致性，避免单纯记忆提示触发器。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00626v2",
      "published_date": "2025-05-01 16:06:16 UTC",
      "updated_date": "2025-05-05 03:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:36:12.127872"
    },
    {
      "arxiv_id": "2505.00624v1",
      "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation",
      "title_zh": "翻译失败",
      "authors": [
        "Chaitali Bhattacharyya",
        "Yeseong Kim"
      ],
      "abstract": "Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released.",
      "tldr_zh": "本研究提出 FineScope 框架，用于从大型预训练模型中衍生出紧凑的领域专用 Large Language Models (LLMs)，以提高效率并保持任务性能。FineScope 利用 Sparse Autoencoder (SAE) 提取领域特定数据集子集，并结合结构化剪枝和 SAE 引导的自数据蒸馏，确保模型保留关键知识并恢复剪枝过程中丢失的信息。实验结果显示，FineScope 在领域特定任务上优于现有大型模型，剪枝后模型通过 SAE 策划的数据集微调可恢复大部分原始性能，且即使不剪枝直接微调也能提升准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00624v1",
      "published_date": "2025-05-01 16:05:08 UTC",
      "updated_date": "2025-05-01 16:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:36:22.988087"
    },
    {
      "arxiv_id": "2505.00622v1",
      "title": "Neural Network Verification for Gliding Drone Control: A Case Study",
      "title_zh": "滑翔无人机控制的神经网络验证：一个案例研究",
      "authors": [
        "Colin Kessler",
        "Ekaterina Komendantskaya",
        "Marco Casadio",
        "Ignazio Maria Viola",
        "Thomas Flinkow",
        "Albaraa Ammar Othman",
        "Alistair Malhotra",
        "Robbie McPherson"
      ],
      "abstract": "As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment.",
      "tldr_zh": "这篇论文通过一个案例研究，探讨了神经网络验证在滑翔无人机控制中的应用，焦点是受 Alsomitra macrocarpa 启发的厘米级生物仿生无人机，以确保其紧跟目标轨迹。研究提出了一种新的 robust training 方法用于回归网络，并使用 Vehicle 和 CORA 工具进行形式化验证，与现有的 VNN 和 ARCH 竞争基准存在显著差异。结果表明，该方法提高了神经网络控制器的性能和鲁棒性，但受限于工具的系统限制和系统复杂度；克服这些问题将有助于开发安全、环保的自主技术。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "18 page pre print, submitted to SAIV 2025 (conference)",
      "pdf_url": "http://arxiv.org/pdf/2505.00622v1",
      "published_date": "2025-05-01 16:03:38 UTC",
      "updated_date": "2025-05-01 16:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:36:35.033546"
    },
    {
      "arxiv_id": "2505.00615v1",
      "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction",
      "title_zh": "Pixel3DMM：多功能的屏幕空间先验用于单图像3D人",
      "authors": [
        "Simon Giebenhain",
        "Tobias Kirschstein",
        "Martin Rünz",
        "Lourdes Agapito",
        "Matthias Nießner"
      ],
      "abstract": "We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions.",
      "tldr_zh": "本研究提出 Pixel3DMM，一种基于视觉变换器的模型，用于从单张 RGB 图像重建 3D 人脸，通过预测每个像素的几何线索（如表面法线和 UV-coordinate）来约束 3DMM 的优化，并利用 DINO 基础模型的潜在特征。研究团队训练了该模型，使用三个高质量 3D 脸部数据集对齐到 FLAME 网格拓扑，总计超过 1,000 个身份和 976K 图像，并引入了一种新的 FLAME 拟合优化方法来求解 3DMM 参数。实验结果显示，该方法在新的单图像脸部重建基准上，特别是在 posed 面部表情的几何准确性方面，比最先进的基线模型提高了超过 15%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;\n  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc",
      "pdf_url": "http://arxiv.org/pdf/2505.00615v1",
      "published_date": "2025-05-01 15:47:03 UTC",
      "updated_date": "2025-05-01 15:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:36:47.624537"
    },
    {
      "arxiv_id": "2505.00612v1",
      "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "D. Sculley",
        "Will Cukierski",
        "Phil Culliton",
        "Sohier Dane",
        "Maggie Demkin",
        "Ryan Holbrook",
        "Addison Howard",
        "Paul Mooney",
        "Walter Reade",
        "Megan Risdal",
        "Nate Keating"
      ],
      "abstract": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of {\\em\nleakage} and {\\em contamination} are in fact the most important and difficult\nissues to address for GenAI evaluations. Interestingly, the field of AI\nCompetitions has developed effective measures and practices to combat leakage\nfor the purpose of counteracting cheating by bad actors within a competition\nsetting. This makes AI Competitions an especially valuable (but underutilized)\nresource. Now is time for the field to view AI Competitions as the gold\nstandard for empirical rigor in GenAI evaluation, and to harness and harvest\ntheir results with according value.",
      "tldr_zh": "这篇立场论文（Position paper）指出，生成式 AI（GenAI）的经验评估正面临危机，因为传统机器学习（ML）评估策略无法应对这些模型的无限输入输出空间、缺乏明确基准以及反馈循环等问题。其中，泄漏（leakage）和污染（contamination）被视为最关键的挑战。作者强调，AI 竞赛已经开发出有效的措施来对抗泄漏，从而防止作弊，并建议将 AI 竞赛视为 GenAI 评估的黄金标准（gold standard），以提升评估的经验严谨性（empirical rigor）。通过充分利用 AI 竞赛的结果，研究领域可以更好地推动可靠的 GenAI 评估实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00612v1",
      "published_date": "2025-05-01 15:43:51 UTC",
      "updated_date": "2025-05-01 15:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:36:58.237684"
    },
    {
      "arxiv_id": "2505.00610v1",
      "title": "Combining LLMs with Logic-Based Framework to Explain MCTS",
      "title_zh": "将 LLMs 与基于逻辑的框架相结合以解释 MCTS",
      "authors": [
        "Ziyan An",
        "Xia Wang",
        "Hendrik Baier",
        "Zirong Chen",
        "Abhishek Dubey",
        "Taylor T. Johnson",
        "Jonathan Sprinkle",
        "Ayan Mukhopadhyay",
        "Meiyi Ma"
      ],
      "abstract": "In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.",
      "tldr_zh": "本研究针对人工智能在顺序规划中的信任缺失，提出了一种结合大型语言模型(LLMs)和计算树逻辑(Computational Tree Logic)的框架，用于生成蒙特卡洛树搜索(MCTS)算法的自然语言解释。该框架能处理广泛的自由形式查询和基于知识的询问，将用户查询转化为逻辑和变量语句，并确保从MCTS搜索树中提取的证据与Markov Decision Process(MDP)环境动态及约束保持事实一致。通过定量评估，该框架在准确性和事实一致性方面表现出色，提升了MCTS的可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAMAS-25 as an extended abstract",
      "pdf_url": "http://arxiv.org/pdf/2505.00610v1",
      "published_date": "2025-05-01 15:40:58 UTC",
      "updated_date": "2025-05-01 15:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:37:11.595965"
    },
    {
      "arxiv_id": "2505.00603v1",
      "title": "Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4",
      "title_zh": "翻译失败",
      "authors": [
        "Phanish Puranam",
        "Prothit Sen",
        "Maciej Workiewicz"
      ],
      "abstract": "This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs），如 GPT-4，在战略决策中的类比推理（analogical reasoning）能力是否能与人类匹敌，通过新型实验设计（source to target matching）进行比较。结果显示，GPT-4 具有高召回率（high recall），能检索所有可能的类比，但精确率（precision）较低，常因表面相似性应用错误类比；相比之下，人类表现出高精确率但低召回率，更擅长因果映射（causal mapping）。研究发现，匹配阶段是类比推理的关键步骤，LLMs 优势在于生成候选类比，而人类在识别深层结构相似性方面更占优势，并建议在 AI 辅助决策中实现分工。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00603v1",
      "published_date": "2025-05-01 15:35:01 UTC",
      "updated_date": "2025-05-01 15:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:37:24.320147"
    },
    {
      "arxiv_id": "2505.00598v2",
      "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal",
      "title_zh": "通过异常值移除的快速低成本基因组基础模型",
      "authors": [
        "Haozheng Luo",
        "Chenghao Qiu",
        "Maojiang Su",
        "Zhihan Zhou",
        "Zoe Mehta",
        "Guo Ye",
        "Jerry Yao-Chieh Hu",
        "Han Liu"
      ],
      "abstract": "To address the challenge of scarce computational resources in genomic\nmodeling, we introduce GERM, a genomic foundation model with strong compression\nperformance and fast adaptability. GERM improves upon models like DNABERT-2 by\neliminating outliers that hinder low-rank adaptation and post-training\nquantization, enhancing both efficiency and robustness. We replace the vanilla\nattention layer with an outlier-free mechanism inspired by associative memory\nmodels. By removing outliers during both pre-training and fine-tuning, this\napproach accelerates adaptation, reduces computational costs, and enhances\nquantization robustness within acceptable loss margins. Additionally, we\npropose GERM-T, a strategy that employs small-step continual learning within\nthe outlier-free framework, leveraging original checkpoints to avoid retraining\nfrom scratch. Empirically, GERM improves fine-tuning performance by 37.98% and\nquantization by 64.34% over the baseline model. It also reduces average\nkurtosis by 92.14% and maximum infinity norm by 82.77%. Compared to leading\nmethods, GERM consistently delivers superior performance, offering a practical\nsolution for genomic modeling in resource-constrained settings. Code is\navailable at https://github.com/MAGICS-LAB/GERM.",
      "tldr_zh": "该论文提出了一种名为 GERM 的基因组基础模型，通过移除异常值（outlier removal）来提升计算效率和鲁棒性，相比 DNABERT-2 模型改善了 low-rank adaptation 和 post-training quantization。GERM 采用受关联记忆模型启发的无异常值注意力机制，并在预训练和微调过程中消除异常值，同时引入 GERM-T 策略，利用小步 continual learning 避免从零重新训练。实验结果显示，GERM 提高了微调性能 37.98% 和量化性能 64.34%，并显著降低了平均峰度 92.14% 和最大无穷范数 82.77%，为资源受限的基因组建模提供了高效实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning (ICML) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00598v2",
      "published_date": "2025-05-01 15:31:09 UTC",
      "updated_date": "2025-05-02 09:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:37:36.523506"
    },
    {
      "arxiv_id": "2505.00596v1",
      "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Schutz",
        "Yang You",
        "Matias Mattamala",
        "Ipek Caliskanelli",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario.",
      "tldr_zh": "该研究提出DetMCVI，一种基于Monte Carlo Value Iteration (MCVI)的算法，用于解决确定性部分可观测Markov决策过程(DetPOMDPs)，通过构建有限状态控制器(FSCs)来制定策略。DetMCVI在处理大型DetPOMDPs问题时表现出高成功率，并优于现有基准方法。该算法在真实世界的移动机器人森林映射场景中进行了性能验证，证明了其实际应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.8; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 6 figures. Appendix attached. To be published in Proceedings\n  of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI",
      "pdf_url": "http://arxiv.org/pdf/2505.00596v1",
      "published_date": "2025-05-01 15:30:26 UTC",
      "updated_date": "2025-05-01 15:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:37:47.836516"
    },
    {
      "arxiv_id": "2505.00584v1",
      "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Mathis Morales",
        "Golnaz Habibi"
      ],
      "abstract": "Detecting and tracking objects is a crucial component of any autonomous\nnavigation method. For the past decades, object detection has yielded promising\nresults using neural networks on various datasets. While many methods focus on\nperformance metrics, few projects focus on improving the robustness of these\ndetection and tracking pipelines, notably to sensor failures. In this paper we\nattempt to address this issue by creating a realistic synthetic data\naugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our\ngoal is to accurately simulate sensor failures and data deterioration due to\nreal-world interferences. We also present our results of a baseline lightweight\nNoise Recognition neural network trained and tested on our augmented dataset,\nreaching an overall recognition accuracy of 54.4\\% on 11 categories across\n10086 images and 2145 radar point-clouds.",
      "tldr_zh": "该论文探讨了自动驾驶车辆(camera-radar)数据集中的噪声问题，旨在通过合成数据增强管道模拟传感器故障和真实世界干扰，提高物体检测和追踪的鲁棒性。研究者创建了一个现实的合成数据生成方法，用于增强数据集，并训练了一个基线轻量级Noise Recognition神经网络进行噪声识别。实验结果显示，该网络在11个类别上处理10086张图像和2145个radar point-clouds时，达到了54.4%的整体识别准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00584v1",
      "published_date": "2025-05-01 15:15:50 UTC",
      "updated_date": "2025-05-01 15:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:37:59.595215"
    },
    {
      "arxiv_id": "2505.00579v1",
      "title": "Voice Cloning: Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Hussam Azzuni",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse.",
      "tldr_zh": "这篇论文对 Voice Cloning 进行了全面调查，旨在建立标准化术语并探讨其各种变体，包括说话者适应作为基础概念，以及 few-shot、zero-shot 和多语言 TTS 等高级主题。该调查编译了现有的语音克隆算法，并总结了常用的评估指标和相关数据集，以支持研究社区的进展。最后，论文强调鼓励生成和检测技术的开发，以限制 Voice Cloning 的潜在滥用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "26 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00579v1",
      "published_date": "2025-05-01 15:10:29 UTC",
      "updated_date": "2025-05-01 15:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:38:11.706155"
    },
    {
      "arxiv_id": "2505.14845v1",
      "title": "A Comparative Study of Large Language Models and Human Personality Traits",
      "title_zh": "大型语言模型与人类个性特征的比较研究",
      "authors": [
        "Wang Jiaqi",
        "Wang bo",
        "Guo fa",
        "Cheng cheng",
        "Yang li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated human-like capabilities in\nlanguage comprehension and generation, becoming active participants in social\nand cognitive domains. This study investigates whether LLMs exhibit\npersonality-like traits and how these traits compare with human personality,\nfocusing on the applicability of conventional personality assessment tools. A\nbehavior-based approach was used across three empirical studies. Study 1\nexamined test-retest stability and found that LLMs show higher variability and\nare more input-sensitive than humans, lacking long-term stability. Based on\nthis, we propose the Distributed Personality Framework, conceptualizing LLM\ntraits as dynamic and input-driven. Study 2 analyzed cross-variant consistency\nin personality measures and found LLMs' responses were highly sensitive to item\nwording, showing low internal consistency compared to humans. Study 3 explored\npersonality retention during role-playing, showing LLM traits are shaped by\nprompt and parameter settings. These findings suggest that LLMs express fluid,\nexternally dependent personality patterns, offering insights for constructing\nLLM-specific personality frameworks and advancing human-AI interaction. This\nwork contributes to responsible AI development and extends the boundaries of\npersonality psychology in the age of intelligent systems.",
      "tldr_zh": "这篇论文比较了大型语言模型 (LLMs) 与人类个性的特征，探讨了常规个性评估工具的适用性。通过三个实证研究，研究发现 LLMs 显示出较高的测试-再测试变异性、对输入敏感性，以及较低的内部一致性，并提出了 Distributed Personality Framework，将 LLMs 的个性视为动态和输入驱动的。结果表明 LLMs 的个性模式更流畅且外部依赖，这为构建 LLMs 特定的个性框架、推进人类-AI 交互和负责任的 AI 发展提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.14845v1",
      "published_date": "2025-05-01 15:10:15 UTC",
      "updated_date": "2025-05-01 15:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:38:23.698863"
    },
    {
      "arxiv_id": "2505.03793v1",
      "title": "LENSLLM: Unveiling Fine-Tuning Dynamics for LLM Selection",
      "title_zh": "LENSLLM：揭示LLM微调动态以用于LLM选择",
      "authors": [
        "Xinyue Zeng",
        "Haohui Wang",
        "Junhong Lin",
        "Jun Wu",
        "Tyler Cody",
        "Dawei Zhou"
      ],
      "abstract": "The proliferation of open-sourced Large Language Models (LLMs) and diverse\ndownstream tasks necessitates efficient model selection, given the\nimpracticality of fine-tuning all candidates due to computational constraints.\nDespite the recent advances in LLM selection, a fundamental research question\nlargely remains nascent: how can we model the dynamic behaviors of LLMs during\nfine-tuning, thereby enhancing our understanding of their generalization\nperformance across diverse downstream tasks? In this work, we propose a novel\ntheoretical framework that provides a proper lens to assess the generalization\ncapabilities of LLMs, thereby enabling accurate and efficient LLM selection for\ndownstream applications. In particular, we first derive a Hessian-based\nPAC-Bayes generalization bound that unveils fine-tuning dynamics of LLMs and\nthen introduce LENSLLM, a Neural Tangent Kernel(NTK)-based Rectified Scaling\nModel that enables accurate performance predictions across diverse tasks while\nmaintaining computational efficiency. Extensive empirical results on 3\nlarge-scale benchmarks demonstrate that our model achieves up to 91.1% accuracy\nand reduces up to 88.5% computational cost in LLM selection, outperforming 5\nstate-of-the-art methods. We open-source our proposed LENSLLM model and\ncorresponding results at the Github link:\nhttps://github.com/Susan571/LENSLLM.git.",
      "tldr_zh": "本研究针对开源大型语言模型 (LLMs) 的多样性和下游任务的复杂性，提出了一种高效的LLM选择框架，以解决微调计算约束问题。研究首先推导了基于Hessian的PAC-Bayes泛化边界，用于揭示LLMs微调过程中的动态行为；随后引入LENSLLM，一个基于Neural Tangent Kernel (NTK)的Rectified Scaling模型，能够准确预测模型在不同任务上的性能，同时显著降低计算成本。在三个大型基准上的实验显示，LENSLLM实现了高达91.1%的选择准确率，并减少了多达88.5%的计算开销，优于5种最先进方法，且已开源相关代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "It is accepted by ICML'2025, and the code is open-sourcing on\n  https://github.com/Susan571/LENSLLM.git",
      "pdf_url": "http://arxiv.org/pdf/2505.03793v1",
      "published_date": "2025-05-01 15:07:32 UTC",
      "updated_date": "2025-05-01 15:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:38:35.698365"
    },
    {
      "arxiv_id": "2505.00570v2",
      "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension",
      "title_zh": "翻译失败",
      "authors": [
        "Jushi Kai",
        "Boyi Zeng",
        "Yixuan Wang",
        "Haoli Bai",
        "Ziwei He",
        "Bo Jiang",
        "Zhouhan Lin"
      ],
      "abstract": "Frequency-domain compression has proven effective in reducing redundancies\nfor spatial signals. In this work, we propose FreqKV, a novel frequency domain\nkey-value (KV) compression technique that enables efficient context window\nextension for decoder-only large language models (LLMs). Our approach is\nmotivated by a key observation that, in the frequency domain, the energy\ndistribution of the KV cache is predominantly concentrated in low-frequency\ncomponents. By discarding high-frequency components, we achieve efficient\ncompression of the KV cache with minimal information loss. FreqKV iteratively\ncompresses the increasing KV cache to a fixed size in the frequency domain,\nallowing models to process lengthy contexts efficiently. Introducing no\nadditional parameters or architectural modifications, FreqKV is applicable to\nboth fine-tuning and inference. With minimal fine-tuning, LLMs can learn to\nleverage the limited cache that is compressed in the frequency domain and\nextend the context window. Experiments on a range of long context language\nmodeling and understanding tasks demonstrate the efficiency and effectiveness\nof the proposed method.",
      "tldr_zh": "本文提出FreqKV，一种频率域关键值(KV)压缩技术，旨在为解码器-only的大型语言模型(LLMs)高效扩展上下文窗口。方法基于KV缓存在频率域中能量主要集中在低频组件的观察，通过丢弃高频组件并迭代压缩缓存至固定大小，实现最小信息损失的处理长上下文。实验在多种长上下文语言建模和理解任务上证明，FreqKV无需额外参数或架构修改，即可显著提升模型效率和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00570v2",
      "published_date": "2025-05-01 14:53:12 UTC",
      "updated_date": "2025-05-19 02:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:38:46.471261"
    },
    {
      "arxiv_id": "2505.00568v2",
      "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Robinet",
        "Ahmad Berjaoui",
        "Elizabeth Cohen-Jonathan Moyal"
      ],
      "abstract": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/BM-MAE",
      "tldr_zh": "本文提出 BM-MAE，一种针对多模态 MRI 的 Masked Image Modeling 预训练策略，用于 3D 脑肿瘤分析，能够有效处理缺失模态问题，避免为每个模态组合训练单独模型。BM-MAE 允许同一个预训练模型适应任何模态子集，提取 intra- 和 inter-modal 信息，并在下游任务上进行微调，而无需架构更改。实验结果表明，该策略在多个任务上优于或与基线相当，并能快速重建缺失模态，提升了临床应用的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00568v2",
      "published_date": "2025-05-01 14:51:30 UTC",
      "updated_date": "2025-05-02 08:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:38:59.705951"
    },
    {
      "arxiv_id": "2505.00562v1",
      "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Meng",
        "Chuchu Fan"
      ],
      "abstract": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF",
      "tldr_zh": "该论文提出 TeLoGraF，一种基于 Graph Neural Networks (GNN) 编码器和 flow-matching 的方法，用于学习解决一般 Signal Temporal Logic (STL) 规范的任务规划问题，以克服现有方法的局限性。研究者识别了四种常用 STL 模板，并收集了 20 万个规范及其配对演示数据集。实验在五个模拟环境中进行，包括从 2D 动态模型到 7DoF Franka Panda 机器人臂和 Ant 四足机器人导航，结果显示 TeLoGraF 在 STL 满足率上优于基线方法，且推理速度比经典 STL 规划算法快 10-100 倍，同时展示了对复杂 STL 和分布外规范的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00562v1",
      "published_date": "2025-05-01 14:40:07 UTC",
      "updated_date": "2025-05-01 14:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:39:12.075794"
    },
    {
      "arxiv_id": "2505.00561v1",
      "title": "Learning to Learn with Quantum Optimization via Quantum Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kuan-Cheng Chen",
        "Hiromichi Matsuyama",
        "Wei-Hao Huang"
      ],
      "abstract": "Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.",
      "tldr_zh": "该论文提出了一种量子元学习框架，将 Quantum Neural Networks（特别是 Quantum Long Short-Term Memory, QLSTM）与 Quantum Approximate Optimization Algorithms (QAOA) 结合，用于解决经典算法难以处理的组合优化问题。框架通过在较小图实例上训练 QLSTM 优化器，使其快速泛化到更大、更复杂的问题，从而显著减少收敛所需的迭代次数。实验基准测试显示，在 Max-Cut 和 Sherrington-Kirkpatrick model 实例上，QLSTM 优化器比经典基线更快收敛并实现更高近似比率。这为 NISQ 时代提供了一个可扩展且鲁棒的量子优化途径。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00561v1",
      "published_date": "2025-05-01 14:39:26 UTC",
      "updated_date": "2025-05-01 14:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:39:25.095468"
    },
    {
      "arxiv_id": "2505.00557v1",
      "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Makoto Sato"
      ],
      "abstract": "Hallucinations in large language models (LLMs) present a growing challenge\nacross real-world applications, from healthcare to law, where factual\nreliability is essential. Despite advances in alignment and instruction tuning,\nLLMs can still generate outputs that are fluent yet fundamentally untrue.\nUnderstanding the cognitive dynamics that underlie these hallucinations remains\nan open problem. In this study, we propose a prompt-based framework to\nsystematically trigger and quantify hallucination: a Hallucination-Inducing\nPrompt (HIP), which synthetically fuses semantically distant concepts (e.g.,\nperiodic table of elements and tarot divination) in a misleading way, and a\nHallucination Quantifying Prompt (HQP), which scores the plausibility,\nconfidence, and coherence of the output. Controlled experiments across multiple\nLLMs revealed that HIPs consistently produced less coherent and more\nhallucinated responses than their null-fusion controls. These effects varied\nacross models, with reasoning-oriented LLMs showing distinct profiles from\ngeneral-purpose ones. Our framework provides a reproducible testbed for\nstudying hallucination vulnerability, and opens the door to developing safer,\nmore introspective LLMs that can detect and self-regulate the onset of\nconceptual instability.",
      "tldr_zh": "本研究定量分析了提示诱发的LLMs幻觉问题，提出一个基于提示的框架来系统触发和评估幻觉。框架包括Hallucination-Inducing Prompt (HIP)，通过合成语义上遥远的概念（如元素周期表和塔罗占卜）来误导模型，以及Hallucination Quantifying Prompt (HQP)，用于量化输出的合理性、置信度和连贯性。实验结果显示，HIP比对照提示导致LLMs产生更多幻觉和不连贯响应，且推理导向的LLMs与通用模型表现出差异。该框架为研究LLMs的幻觉脆弱性提供可重现的测试平台，并推动开发更安全、能自我调节的概念稳定模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00557v1",
      "published_date": "2025-05-01 14:33:47 UTC",
      "updated_date": "2025-05-01 14:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:39:38.129239"
    },
    {
      "arxiv_id": "2505.00555v1",
      "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Baptiste A. Conan"
      ],
      "abstract": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.",
      "tldr_zh": "本研究探讨了在生物统计学因果推断中，神经网络（NNs）作为黑箱模型的解释性挑战，并引入了Mechanistic Interpretability (MI) 技术来解密其内部计算机制。研究展示了MI工具如何用于检查和验证NNs学习的内部表示，例如在Targeted Minimum Loss-based Estimation (TMLE)框架中估计nuisance functions，以及可视化网络处理不同输入（如混杂因素和治疗变量）的计算路径。通过这些方法，论文提供了比较统计模型、机器学习模型和NNs机制的框架，以揭示它们在因果生物统计分析中的优势和局限性，最终提升模型的可解释性和在健康应用中的可信度。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00555v1",
      "published_date": "2025-05-01 14:30:34 UTC",
      "updated_date": "2025-05-01 14:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:39:47.816279"
    },
    {
      "arxiv_id": "2505.03792v1",
      "title": "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Feng",
        "Weihao Tan",
        "Zhiyi Lyu",
        "Longtao Zheng",
        "Haiyang Xu",
        "Ming Yan",
        "Fei Huang",
        "Bo An"
      ],
      "abstract": "Online fine-tuning vision-language model (VLM) agents with reinforcement\nlearning (RL) has shown promise for equipping agents with multi-step,\ngoal-oriented capabilities in dynamic environments. However, their open-ended\ntextual action space and non-end-to-end nature of action generation present\nsignificant challenges to effective online exploration in RL, e.g., explosion\nof the exploration space. We propose a novel online fine-tuning method,\nCounterfactual Soft Reinforcement Learning (CoSo), better suited to the textual\noutput space of VLM agents. Compared to prior methods that assign uniform\nuncertainty to all tokens, CoSo leverages counterfactual reasoning to\ndynamically assess the causal influence of individual tokens on post-processed\nactions. By prioritizing the exploration of action-critical tokens while\nreducing the impact of semantically redundant or low-impact tokens, CoSo\nenables a more targeted and efficient online rollout process. We provide\ntheoretical analysis proving CoSo's convergence and policy improvement\nguarantees, and extensive empirical evaluations supporting CoSo's\neffectiveness. Our results across a diverse set of agent tasks, including\nAndroid device control, card gaming, and embodied AI, highlight its remarkable\nability to enhance exploration efficiency and deliver consistent performance\ngains. The code is available at https://github.com/langfengQ/CoSo.",
      "tldr_zh": "这篇论文提出了一种名为CoSo的在线微调方法，Counterfactual Soft Reinforcement Learning，用于提升视觉语言模型(VLM)代理在强化学习(RL)中的探索效率，解决文本动作空间爆炸的问题。CoSo通过反事实推理动态评估单个标记对后处理动作的因果影响，优先探索关键标记并减少冗余标记的影响，从而实现更针对性的在线回滚过程。实验在Android设备控制、纸牌游戏和具身AI等多样任务上证明了CoSo的有效性，显著提高了探索效率和性能，并提供了收敛性和策略改进的理论保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03792v1",
      "published_date": "2025-05-01 14:17:53 UTC",
      "updated_date": "2025-05-01 14:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:39:59.799257"
    },
    {
      "arxiv_id": "2505.00533v1",
      "title": "Test-time Correlation Alignment",
      "title_zh": "测试时相关性对齐",
      "authors": [
        "Linjing You",
        "Jiabao Lu",
        "Xiayuan Huang"
      ],
      "abstract": "Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.",
      "tldr_zh": "本论文针对深度神经网络在训练和测试数据分布偏移时的性能下降问题，提出Test-time Correlation Alignment (TCA)方法，以解决现有Test-Time Adaptation (TTA)方法的局限，如忽略Correlation Alignment (CORAL)、计算开销大和领域遗忘。通过理论分析，证明在高置信度实例和测试实例之间进行相关性对齐可提升性能。作者开发了简单有效的算法LinearTCA和LinearTCA+，前者通过线性变换实现实例和相关性对齐，无需额外模型更新，后者可作为即插即用模块提升现有TTA方法。实验结果显示，TCA方法在各种任务和基准上显著优于基线，例如在OfficeHome数据集上，LinearTCA提高了5.88%的适应准确率，同时仅使用4%的最大GPU内存和0.6%的计算时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00533v1",
      "published_date": "2025-05-01 13:59:13 UTC",
      "updated_date": "2025-05-01 13:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:40:13.012229"
    },
    {
      "arxiv_id": "2505.00515v1",
      "title": "Safety-Critical Traffic Simulation with Guided Latent Diffusion Model",
      "title_zh": "安全关键交通模拟的引导式潜在扩散模型",
      "authors": [
        "Mingxing Peng",
        "Ruoyu Yao",
        "Xusen Guo",
        "Yuting Xie",
        "Xianda Chen",
        "Jun Ma"
      ],
      "abstract": "Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.",
      "tldr_zh": "该研究针对安全关键交通模拟中的问题，提出了一种引导潜在扩散模型（guided latent diffusion model），用于生成物理真实且对抗性的交通场景，以更好地评估自动驾驶系统。模型采用基于图的变分自动编码器（graph-based VAE）学习紧凑的潜在空间，捕捉多代理互动并提升计算效率，同时在潜在空间内通过扩散模型进行去噪以产生真实轨迹。引入新型引导目标（guidance objectives）和基于物理可行性检查的样本选择模块，确保生成的场景具有对抗性和行为现实性。在 nuScenes 数据集上的实验显示，该方法在对抗有效性和生成效率上优于现有基线，同时保持高现实性，为更鲁棒的自动驾驶系统评估提供了有效工具。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00515v1",
      "published_date": "2025-05-01 13:33:34 UTC",
      "updated_date": "2025-05-01 13:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:40:24.089125"
    },
    {
      "arxiv_id": "2505.00506v1",
      "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Deanna Emery",
        "Michael Goitia",
        "Freddie Vargus",
        "Iulia Neagu"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84.",
      "tldr_zh": "该研究强调了大型语言模型 (LLMs) 在高风险领域部署时检测幻觉内容（即不基于证据的文本）的必要性，并引入了 HalluMix Benchmark，这是一个任务无关、多领域的基准数据集，涵盖真实场景如多文档上下文和完整句子输出。利用该基准，论文评估了七个开源和闭源的幻觉检测系统，揭示了性能在不同任务、文档长度和输入表示上的显著差异，特别是短上下文与长上下文之间的差距，对真实世界的 Retrieval Augmented Generation (RAG) 实现具有重要启示。Quotient Detections 系统表现出色，达到 0.82 的准确率和 0.84 的 F1 分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00506v1",
      "published_date": "2025-05-01 13:22:45 UTC",
      "updated_date": "2025-05-01 13:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:40:36.316386"
    },
    {
      "arxiv_id": "2505.00503v2",
      "title": "Variational OOD State Correction for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Jiang",
        "Wen Jiang",
        "Masahiro Fujisawa",
        "Xiaoyang Tan"
      ],
      "abstract": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.",
      "tldr_zh": "该论文针对离线强化学习（Offline Reinforcement Learning）中的状态分布偏移（State Distributional Shift）和OOD（Out-of-Distribution）状态问题，提出了一种新方法Density-Aware Safety Perception (DASP)。DASP通过鼓励代理优先选择导致数据密度更高的行动，从而引导其保持或返回到分布内（安全）区域。方法在变分框架（Variational Framework）下优化目标，同时考虑决策的潜在结果及其密度，提供安全决策的上下文信息。最后，通过在离线MuJoCo和AntMaze测试套件上的广泛实验，验证了DASP的有效性和可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00503v2",
      "published_date": "2025-05-01 13:14:07 UTC",
      "updated_date": "2025-05-05 06:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:40:47.848264"
    },
    {
      "arxiv_id": "2505.03791v1",
      "title": "Practical Boolean Backpropagation",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Golbert"
      ],
      "abstract": "Boolean neural networks offer hardware-efficient alternatives to real-valued\nmodels. While quantization is common, purely Boolean training remains\nunderexplored. We present a practical method for purely Boolean backpropagation\nfor networks based on a single specific gate we chose, operating directly in\nBoolean algebra involving no numerics. Initial experiments confirm its\nfeasibility.",
      "tldr_zh": "本研究探讨了布尔神经网络(BOOLEAN NEURAL NETWORKS)作为实值模型的硬件高效替代方案，但强调纯布尔训练仍未被充分开发。作者提出了一种实用的布尔反向传播(PRACTICAL BOOLEAN BACKPROPAGATION)方法，该方法基于特定门电路，直接在布尔代数(BOOLEAN ALGEBRA)中操作，而不涉及任何数值运算。初步实验证实了该方法的 feasibility，为布尔神经网络的训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03791v1",
      "published_date": "2025-05-01 12:50:02 UTC",
      "updated_date": "2025-05-01 12:50:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:40:58.707290"
    },
    {
      "arxiv_id": "2505.00490v1",
      "title": "Optimal Interactive Learning on the Job via Facility Location Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Vats",
        "Michelle Zhao",
        "Patrick Callaghan",
        "Mingxi Jia",
        "Maxim Likhachev",
        "Oliver Kroemer",
        "George Konidaris"
      ],
      "abstract": "Collaborative robots must continually adapt to novel tasks and user\npreferences without overburdening the user. While prior interactive robot\nlearning methods aim to reduce human effort, they are typically limited to\nsingle-task scenarios and are not well-suited for sustained, multi-task\ncollaboration. We propose COIL (Cost-Optimal Interactive Learning) -- a\nmulti-task interaction planner that minimizes human effort across a sequence of\ntasks by strategically selecting among three query types (skill, preference,\nand help). When user preferences are known, we formulate COIL as an\nuncapacitated facility location (UFL) problem, which enables bounded-suboptimal\nplanning in polynomial time using off-the-shelf approximation algorithms. We\nextend our formulation to handle uncertainty in user preferences by\nincorporating one-step belief space planning, which uses these approximation\nalgorithms as subroutines to maintain polynomial-time performance. Simulated\nand physical experiments on manipulation tasks show that our framework\nsignificantly reduces the amount of work allocated to the human while\nmaintaining successful task completion.",
      "tldr_zh": "该研究提出COIL（Cost-Optimal Interactive Learning）框架，用于优化协作机器人在多任务场景下的交互学习，旨在最小化人类努力同时适应新任务和用户偏好。COIL通过战略性地选择三种查询类型（skill, preference, and help）来规划交互，当用户偏好已知时，将问题建模为uncapacitated facility location (UFL)问题，利用近似算法实现多项式时间内的子最优规划。针对用户偏好不确定性，该框架融入one-step belief space planning作为扩展，以保持高效性能。实验结果显示，在操纵任务的模拟和物理环境中，COIL显著减少了人类工作量，同时确保任务成功完成。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to Robotics: Science and Systems (RSS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00490v1",
      "published_date": "2025-05-01 12:45:09 UTC",
      "updated_date": "2025-05-01 12:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:41:11.098333"
    },
    {
      "arxiv_id": "2505.00488v1",
      "title": "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion",
      "title_zh": "翻译失败",
      "authors": [
        "Vamshi Kumar Kurva",
        "Shishir Kolathaya"
      ],
      "abstract": "Quadrupedal robots are increasingly deployed for load-carrying tasks across\ndiverse terrains. While Model Predictive Control (MPC)-based methods can\naccount for payload variations, they often depend on predefined gait schedules\nor trajectory generators, limiting their adaptability in unstructured\nenvironments. To address these limitations, we propose an Adaptive\nReinforcement Learning (RL) framework that enables quadrupedal robots to\ndynamically adapt to both varying payloads and diverse terrains. The framework\nconsists of a nominal policy responsible for baseline locomotion and an\nadaptive policy that learns corrective actions to preserve stability and\nimprove command tracking under payload variations. We validate the proposed\napproach through large-scale simulation experiments in Isaac Gym and real-world\nhardware deployment on a Unitree Go1 quadruped. The controller was tested on\nflat ground, slopes, and stairs under both static and dynamic payload changes.\nAcross all settings, our adaptive controller consistently outperformed the\ncontroller in tracking body height and velocity commands, demonstrating\nenhanced robustness and adaptability without requiring explicit gait design or\nmanual tuning.",
      "tldr_zh": "该研究提出了一种名为 MULE 的 Adaptive Reinforcement Learning (RL) 框架，旨在帮助四足机器人动态适应多地形和未知负载，从而提升运动效能。该框架包括一个 nominal policy 负责基本步态控制，以及一个 adaptive policy 通过学习纠正动作来维持稳定性并优化命令跟踪，与传统的 Model Predictive Control (MPC) 方法相比，无需预定义步态或手动调优。在 Isaac Gym 模拟和 Unitree Go1 硬件实验中，MULE 在平地、斜坡和楼梯等环境中表现出色，显著提高了身体高度和速度命令的跟踪准确性，证明了其鲁棒性和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2505.00488v1",
      "published_date": "2025-05-01 12:41:35 UTC",
      "updated_date": "2025-05-01 12:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:41:24.127044"
    },
    {
      "arxiv_id": "2505.00487v1",
      "title": "Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks",
      "title_zh": "使用来自5G无线网络的数据分析机器学习回归模型对对抗性攻击的脆弱性",
      "authors": [
        "Leonid Legashev",
        "Artur Zhigalov",
        "Denis Parfenov"
      ],
      "abstract": "This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity",
      "tldr_zh": "这篇论文分析了机器学习回归模型在使用 5G 无线网络数据的场景下，对对抗攻击的脆弱性。研究团队使用 DeepMIMO 模拟器和 FGSM 方法进行了攻击实验，通过最大化梯度来扭曲数据，并比较了二元分类器的检测效果。结果显示，FGSM 攻击导致 MSE 指标平均增加 33%，R2 指标平均减少 10%，显著降低了模型性能。LightGBM 二元分类器能以 98% 的准确率识别对抗异常数据，证明通过快速分析网络流量可以有效检测恶意活动。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00487v1",
      "published_date": "2025-05-01 12:36:05 UTC",
      "updated_date": "2025-05-01 12:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:41:36.511756"
    },
    {
      "arxiv_id": "2505.00482v1",
      "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Kwon Byung-Ki",
        "Qi Dai",
        "Lee Hyoseok",
        "Chong Luo",
        "Tae-Hyun Oh"
      ],
      "abstract": "We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.",
      "tldr_zh": "本研究提出JointDiT，一种基于diffusion transformers的模型，用于联合建模RGB和深度数据的分布，从而生成高保真图像和精确的深度图。模型通过自适应调度 weights（adaptive scheduling weights）和不平衡时间步采样策略（unbalanced timestep sampling strategy）来处理不同模态的噪声水平，实现跨噪声水平的训练。实验结果显示，JointDiT在联合生成任务上表现出色，并在深度估计和深度条件图像生成（depth-conditioned image generation）中达到可比性能，表明联合分布建模可作为条件生成的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00482v1",
      "published_date": "2025-05-01 12:21:23 UTC",
      "updated_date": "2025-05-01 12:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:41:46.872797"
    },
    {
      "arxiv_id": "2505.00757v1",
      "title": "Efficient On-Chip Implementation of 4D Radar-Based 3D Object Detection on Hailo-8L",
      "title_zh": "翻译失败",
      "authors": [
        "Woong-Chan Byun",
        "Dong-Hee Paek",
        "Seung-Hyun Song",
        "Seung-Hyun Kong"
      ],
      "abstract": "4D radar has attracted attention in autonomous driving due to its ability to\nenable robust 3D object detection even under adverse weather conditions. To\npractically deploy such technologies, it is essential to achieve real-time\nprocessing within low-power embedded environments. Addressing this, we present\nthe first on-chip implementation of a 4D radar-based 3D object detection model\non the Hailo-8L AI accelerator. Although conventional 3D convolutional neural\nnetwork (CNN) architectures require 5D inputs, the Hailo-8L only supports 4D\ntensors, posing a significant challenge. To overcome this limitation, we\nintroduce a tensor transformation method that reshapes 5D inputs into 4D\nformats during the compilation process, enabling direct deployment without\naltering the model structure. The proposed system achieves 46.47% AP_3D and\n52.75% AP_BEV, maintaining comparable accuracy to GPU-based models while\nachieving an inference speed of 13.76 Hz. These results demonstrate the\napplicability of 4D radar-based perception technologies to autonomous driving\nsystems.",
      "tldr_zh": "本文提出了一种高效的芯片上实现方案，用于在Hailo-8L AI加速器上部署4D radar-based 3D对象检测模型，以实现自动驾驶中恶劣天气下的鲁棒实时处理。针对Hailo-8L仅支持4D张量的限制，研究团队引入了张量转换方法，将模型所需的5D输入在编译过程中重塑为4D格式，而无需修改模型结构。该方法使系统在保持与GPU模型相当准确率的情况下，达到了46.47% AP_3D和52.75% AP_BEV的性能，并实现了13.76 Hz的推理速度。这些结果证明了4D radar-based感知技术在低功耗嵌入式自动驾驶系统中的实际可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00757v1",
      "published_date": "2025-05-01 12:10:04 UTC",
      "updated_date": "2025-05-01 12:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:04.581148"
    },
    {
      "arxiv_id": "2505.01459v1",
      "title": "MoxE: Mixture of xLSTM Experts with Entropy-Aware Routing for Efficient Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoul Majid O. Thiombiano",
        "Brahim Hnich",
        "Ali Ben Mrad",
        "Mohamed Wiem Mkaouer"
      ],
      "abstract": "This paper introduces MoxE, a novel architecture that synergistically\ncombines the Extended Long Short-Term Memory (xLSTM) with the Mixture of\nExperts (MoE) framework to address critical scalability and efficiency\nchallenges in large language models (LLMs). The proposed method effectively\nleverages xLSTM's innovative memory structures while strategically introducing\nsparsity through MoE to substantially reduce computational overhead. At the\nheart of our approach is a novel entropy-based routing mechanism, designed to\ndynamically route tokens to specialized experts, thereby ensuring efficient and\nbalanced resource utilization. This entropy awareness enables the architecture\nto effectively manage both rare and common tokens, with mLSTM blocks being\nfavored to handle rare tokens. To further enhance generalization, we introduce\na suite of auxiliary losses, including entropy-based and group-wise balancing\nlosses, ensuring robust performance and efficient training. Theoretical\nanalysis and empirical evaluations rigorously demonstrate that MoxE achieves\nsignificant efficiency gains and enhanced effectiveness compared to existing\napproaches, marking a notable advancement in scalable LLM architectures.",
      "tldr_zh": "本论文提出 MoxE 架构，将 Extended Long Short-Term Memory (xLSTM) 与 Mixture of Experts (MoE) 框架相结合，以解决大型语言模型 (LLMs) 的可扩展性和效率挑战。该架构通过基于熵的路由机制动态分配标记到专业专家，实现资源利用的平衡和计算开销的显著减少，同时 mLSTM 块优先处理稀有标记。论文引入辅助损失函数，如熵-based 和组-wise 平衡损失，以提升模型的泛化能力和训练效率；实证评估显示，MoxE 相较现有方法实现了显著的效率提升和性能改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01459v1",
      "published_date": "2025-05-01 12:06:39 UTC",
      "updated_date": "2025-05-01 12:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:12.187879"
    },
    {
      "arxiv_id": "2505.00474v1",
      "title": "Rule-based Classifier Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cecilia Di Florio",
        "Huimin Dong",
        "Antonino Rotolo"
      ],
      "abstract": "We extend the formal framework of classifier models used in the legal domain.\nWhile the existing classifier framework characterises cases solely through the\nfacts involved, legal reasoning fundamentally relies on both facts and rules,\nparticularly the ratio decidendi. This paper presents an initial approach to\nincorporating sets of rules within a classifier. Our work is built on the work\nof Canavotto et al. (2023), which has developed the rule-based reason model of\nprecedential constraint within a hierarchy of factors. We demonstrate how\ndecisions for new cases can be inferred using this enriched rule-based\nclassifier framework. Additionally, we provide an example of how the time\nelement and the hierarchy of courts can be used in the new classifier\nframework.",
      "tldr_zh": "该论文扩展了法律领域的 classifier models 框架，将规则（尤其是 ratio decidendi）纳入其中，以弥补现有模型仅依赖事实的局限性。基于 Canavotto et al. (2023) 的 rule-based reason model，该框架在先例约束的层次结构中构建了一个 enriched rule-based classifier，用于推断新案例的决策。研究还通过示例展示了如何整合时间元素和法院层次，以增强框架的实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 1 figure. Extended version of a short paper accepted to\n  ICAIL 2025. This is the authors' version of the work. It is posted here for\n  your personal use",
      "pdf_url": "http://arxiv.org/pdf/2505.00474v1",
      "published_date": "2025-05-01 11:59:16 UTC",
      "updated_date": "2025-05-01 11:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:23.618016"
    },
    {
      "arxiv_id": "2505.00472v1",
      "title": "UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Saleh",
        "Sasu Tarkoma",
        "Praveen Kumar Donta",
        "Naser Hossein Motlagh",
        "Schahram Dustdar",
        "Susanna Pirttikangas",
        "Lauri Lovén"
      ],
      "abstract": "Agentic AI, with its autonomous and proactive decision-making, has\ntransformed smart environments. By integrating Generative AI (GenAI) and\nmulti-agent systems, modern AI frameworks can dynamically adapt to user\npreferences, optimize data management, and improve resource allocation. This\npaper introduces UserCentrix, an agentic memory-augmented AI framework designed\nto enhance smart spaces through dynamic, context-aware decision-making. This\nframework integrates personalized Large Language Model (LLM) agents that\nleverage user preferences and LLM memory management to deliver proactive and\nadaptive assistance. Furthermore, it incorporates a hybrid hierarchical control\nsystem, balancing centralized and distributed processing to optimize real-time\nresponsiveness while maintaining global situational awareness. UserCentrix\nachieves resource-efficient AI interactions by embedding memory-augmented\nreasoning, cooperative agent negotiation, and adaptive orchestration\nstrategies. Our key contributions include (i) a self-organizing framework with\nproactive scaling based on task urgency, (ii) a Value of Information\n(VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM\nagent, and (iv) an intelligent multi-agent coordination system for seamless\nenvironment adaptation. Experimental results across various models confirm the\neffectiveness of our approach in enhancing response accuracy, system\nefficiency, and computational resource management in real-world application.",
      "tldr_zh": "本研究引入了 UserCentrix，一种基于 Agentic AI 的记忆增强框架，旨在通过整合 Generative AI (GenAI) 和多代理系统，提升智能空间的动态决策和资源优化。框架利用个性化的 Large Language Model (LLM) 代理结合用户偏好和记忆管理，提供主动适应性辅助，并采用混合层次控制系统平衡集中式与分布式处理以实现实时响应和全局 situational awareness。关键贡献包括：(i) 基于任务紧急性的自组织框架，(ii) Value of Information (VoI)-驱动的决策过程，(iii) 元推理个人 LLM 代理，以及 (iv) 智能多代理协调系统。实验结果显示，该框架在各种模型中显著提高了响应准确性、系统效率和计算资源管理。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00472v1",
      "published_date": "2025-05-01 11:54:49 UTC",
      "updated_date": "2025-05-01 11:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:36.406353"
    },
    {
      "arxiv_id": "2505.00467v1",
      "title": "Red Teaming Large Language Models for Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Balazadeh",
        "Michael Cooper",
        "David Pellow",
        "Atousa Assadi",
        "Jennifer Bell",
        "Jim Fackler",
        "Gabriel Funingana",
        "Spencer Gable-Cook",
        "Anirudh Gangadhar",
        "Abhishek Jaiswal",
        "Sumanth Kaja",
        "Christopher Khoury",
        "Randy Lin",
        "Kaden McKeen",
        "Sara Naimimohasses",
        "Khashayar Namdar",
        "Aviraj Newatia",
        "Allan Pang",
        "Anshul Pattoo",
        "Sameer Peesapati",
        "Diana Prepelita",
        "Bogdana Rakova",
        "Saba Sadatamin",
        "Rafael Schulman",
        "Ajay Shah",
        "Syed Azhar Shah",
        "Syed Ahmar Shah",
        "Babak Taati",
        "Balagopal Unnikrishnan",
        "Stephanie Williams",
        "Rahul G Krishnan"
      ],
      "abstract": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.",
      "tldr_zh": "本研究介绍了2024年机器学习在医疗保健会议上举办的红队测试(Red Teaming)工作坊，旨在通过临床和计算专家合作，识别大型语言模型(LLMs)在处理现实临床提示时的漏洞，这些漏洞可能导致临床伤害。参与者使用模拟临床场景测试LLMs，突显了缺乏临床专业知识的开发者可能忽略的风险。研究报告了发现的漏洞及其分类，并通过一个复制研究评估了这些漏洞在多种LLMs中的表现，为提升LLMs在医疗领域的安全性和可靠性提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00467v1",
      "published_date": "2025-05-01 11:43:27 UTC",
      "updated_date": "2025-05-01 11:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:47.184164"
    },
    {
      "arxiv_id": "2505.00455v2",
      "title": "Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sungbok Shin",
        "Hyeon Jeon",
        "Sanghyun Hong",
        "Niklas Elmqvist"
      ],
      "abstract": "Effective data visualization requires not only technical proficiency but also\na deep understanding of the domain-specific context in which data exists. This\ncontext often includes tacit knowledge about data provenance, quality, and\nintended use, which is rarely explicit in the dataset itself. We present the\nData Therapist, a web-based tool that helps domain experts externalize this\nimplicit knowledge through a mixed-initiative process combining iterative Q&A\nwith interactive annotation. Powered by a large language model, the system\nanalyzes user-supplied datasets, prompts users with targeted questions, and\nallows annotation at varying levels of granularity. The resulting structured\nknowledge base can inform both human and automated visualization design. We\nevaluated the tool in a qualitative study involving expert pairs from Molecular\nBiology, Accounting, Political Science, and Usable Security. The study revealed\nrecurring patterns in how experts reason about their data and highlights areas\nwhere AI support can improve visualization design.",
      "tldr_zh": "该研究介绍了 Data Therapist，一种基于 Large Language Models 的网络工具，用于帮助领域专家通过迭代 Q&A 和交互式注释来外化数据中的隐性知识，如数据来源、质量和用途。工具分析用户提供的数据集、提出针对性问题，并支持不同粒度的注释，从而生成结构化的知识库，以指导人类或自动化的数据可视化设计。在一项涉及分子生物学、会计学、政治科学和可用安全领域的专家配对定性研究中，研究揭示了专家对数据推理的常见模式，并突出了 AI 支持在提升可视化设计方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to IEEE VIS2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00455v2",
      "published_date": "2025-05-01 11:10:17 UTC",
      "updated_date": "2025-05-07 23:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:42:58.713116"
    },
    {
      "arxiv_id": "2505.07832v1",
      "title": "A General Approach of Automated Environment Design for Learning the Optimal Power Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Wolgast",
        "Astrid Nieße"
      ],
      "abstract": "Reinforcement learning (RL) algorithms are increasingly used to solve the\noptimal power flow (OPF) problem. Yet, the question of how to design RL\nenvironments to maximize training performance remains unanswered, both for the\nOPF and the general case. We propose a general approach for automated RL\nenvironment design by utilizing multi-objective optimization. For that, we use\nthe hyperparameter optimization (HPO) framework, which allows the reuse of\nexisting HPO algorithms and methods. On five OPF benchmark problems, we\ndemonstrate that our automated design approach consistently outperforms a\nmanually created baseline environment design. Further, we use statistical\nanalyses to determine which environment design decisions are especially\nimportant for performance, resulting in multiple novel insights on how RL-OPF\nenvironments should be designed. Finally, we discuss the risk of overfitting\nthe environment to the utilized RL algorithm. To the best of our knowledge,\nthis is the first general approach for automated RL environment design.",
      "tldr_zh": "该论文提出了一种通用的自动化强化学习 (RL) 环境设计方法，用于优化最优功率流 (OPF) 问题的训练性能，通过多目标优化和超参数优化 (HPO) 框架实现自动化设计。实验在五个 OPF 基准问题上显示，该方法显著优于手动设计的基线环境，并通过统计分析揭示了环境设计决策的关键因素，如避免过拟合风险。总体而言，这是有史以来首个针对 RL 环境设计的通用方法，为 RL 在 OPF 等领域的应用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, accepted at ACM e-energy 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07832v1",
      "published_date": "2025-05-01 11:02:55 UTC",
      "updated_date": "2025-05-01 11:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:43:11.469987"
    },
    {
      "arxiv_id": "2505.00439v1",
      "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Timo P. Gros",
        "Nicola J. Müller",
        "Daniel Fiser",
        "Isabel Valera",
        "Verena Wolf",
        "Jörg Hoffmann"
      ],
      "abstract": "Recent work has shown that successful per-domain generalizing action policies\ncan be learned. Scaling behavior, from small training instances to large test\ninstances, is the key objective; and the use of validation instances larger\nthan training instances is one key to achieve it. Prior work has used fixed\nvalidation sets. Here, we introduce a method generating the validation set\ndynamically, on the fly, increasing instance size so long as informative and\nfeasible.We also introduce refined methodology for evaluating scaling behavior,\ngenerating test instances systematically to guarantee a given confidence in\ncoverage performance for each instance size. In experiments, dynamic validation\nimproves scaling behavior of GNN policies in all 9 domains used.",
      "tldr_zh": "该研究探讨了 per-domain generalizing policies 的学习，重点关注从小型训练实例到大型测试实例的 scaling behavior，并强调使用比训练实例更大的 validation instances 来实现这一目标。论文引入了一种动态生成验证集的方法，能够在运行时实时增加实例大小，确保其信息性和可行性，同时提出改进的评估方法，通过系统生成测试实例来保证每个实例大小的覆盖性能具有给定置信度。在实验中，这种动态验证方法在9个领域中显著改善了GNN policies的扩展行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 tables, 3 figures, 3 algorithms",
      "pdf_url": "http://arxiv.org/pdf/2505.00439v1",
      "published_date": "2025-05-01 10:32:02 UTC",
      "updated_date": "2025-05-01 10:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:43:22.907082"
    },
    {
      "arxiv_id": "2505.03790v1",
      "title": "A Time-Series Data Augmentation Model through Diffusion and Transformer Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Yuren Zhang",
        "Zhongnan Pu",
        "Lei Jing"
      ],
      "abstract": "With the development of Artificial Intelligence, numerous real-world tasks\nhave been accomplished using technology integrated with deep learning. To\nachieve optimal performance, deep neural networks typically require large\nvolumes of data for training. Although advances in data augmentation have\nfacilitated the acquisition of vast datasets, most of this data is concentrated\nin domains like images and speech. However, there has been relatively less\nfocus on augmenting time-series data. To address this gap and generate a\nsubstantial amount of time-series data, we propose a simple and effective\nmethod that combines the Diffusion and Transformer models. By utilizing an\nadjusted diffusion denoising model to generate a large volume of initial\ntime-step action data, followed by employing a Transformer model to predict\nsubsequent actions, and incorporating a weighted loss function to achieve\nconvergence, the method demonstrates its effectiveness. Using the performance\nimprovement of the model after applying augmented data as a benchmark, and\ncomparing the results with those obtained without data augmentation or using\ntraditional data augmentation methods, this approach shows its capability to\nproduce high-quality augmented data.",
      "tldr_zh": "本研究针对时间序列数据增强的不足，提出了一种整合 Diffusion 和 Transformer 模型的简单有效方法，以生成大量高质量数据并提升深度学习模型性能。该方法首先利用调整过的 Diffusion 去噪模型生成初始时间步数据，然后通过 Transformer 模型预测后续动作，并采用加权损失函数确保模型收敛。与无数据增强或传统方法相比，实验结果表明，该方法显著提高了模型在时间序列任务上的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,22 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03790v1",
      "published_date": "2025-05-01 09:40:45 UTC",
      "updated_date": "2025-05-01 09:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:43:35.419316"
    },
    {
      "arxiv_id": "2505.00755v1",
      "title": "P2P-Insole: Human Pose Estimation Using Foot Pressure Distribution and Motion Sensors",
      "title_zh": "P2P-Insole：利用足部压力分布和运动传感器进行人体姿态估计",
      "authors": [
        "Atsuya Watanabe",
        "Ratna Aisuwarya",
        "Lei Jing"
      ],
      "abstract": "This work presents P2P-Insole, a low-cost approach for estimating and\nvisualizing 3D human skeletal data using insole-type sensors integrated with\nIMUs. Each insole, fabricated with e-textile garment techniques, costs under\nUSD 1, making it significantly cheaper than commercial alternatives and ideal\nfor large-scale production. Our approach uses foot pressure distribution,\nacceleration, and rotation data to overcome limitations, providing a\nlightweight, minimally intrusive, and privacy-aware solution. The system\nemploys a Transformer model for efficient temporal feature extraction, enriched\nby first and second derivatives in the input stream. Including multimodal\ninformation, such as accelerometers and rotational measurements, improves the\naccuracy of complex motion pattern recognition. These facts are demonstrated\nexperimentally, while error metrics show the robustness of the approach in\nvarious posture estimation tasks. This work could be the foundation for a\nlow-cost, practical application in rehabilitation, injury prevention, and\nhealth monitoring while enabling further development through sensor\noptimization and expanded datasets.",
      "tldr_zh": "本研究提出 P2P-Insole，一种低成本的鞋垫式传感器系统，用于估计和可视化 3D 人体骨骼数据，每个鞋垫采用 e-textile 技术制造，成本低于 1 美元，便于大规模生产。系统利用足部压力分布、加速度和旋转数据（来自 IMU），结合 Transformer 模型进行高效的时序特征提取，并通过输入流中的一阶和二阶导数增强多模态信息，以提高复杂运动模式识别的准确性。实验证明，该方法在各种姿势估计任务中表现出色，错误指标显示其鲁棒性，并为康复、损伤预防和健康监测等领域的实际应用奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00755v1",
      "published_date": "2025-05-01 09:28:29 UTC",
      "updated_date": "2025-05-01 09:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:43:48.713808"
    },
    {
      "arxiv_id": "2505.00416v1",
      "title": "ScaleTrack: Scaling and back-tracking Automated GUI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Huang",
        "Zhixiong Zeng",
        "Wenkang Han",
        "Yufeng Zhong",
        "Liming Zheng",
        "Shuai Fu",
        "Jingyuan Chen",
        "Lin Ma"
      ],
      "abstract": "Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url.",
      "tldr_zh": "该论文提出 ScaleTrack 框架，以提升 Automated GUI agents 的性能，针对 GUI grounding 和 planning 阶段的不足问题。ScaleTrack 通过大规模收集并统一不同来源的 GUI 样本来扩展 grounding 训练，并设计一种新策略，从当前 GUI 图像预测下一个动作，同时回溯历史行为，以解释 GUI 环境演化规则。实验结果显示，该框架显著改善了代理的准确性和鲁棒性，数据和代码将公开以供进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00416v1",
      "published_date": "2025-05-01 09:27:13 UTC",
      "updated_date": "2025-05-01 09:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:44:00.453930"
    },
    {
      "arxiv_id": "2505.01458v1",
      "title": "A Survey of Robotic Navigation and Manipulation with Physics Simulators in the Era of Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Lik Hang Kenny Wong",
        "Xueyang Kang",
        "Kaixin Bai",
        "Jianwei Zhang"
      ],
      "abstract": "Navigation and manipulation are core capabilities in Embodied AI, yet\ntraining agents with these capabilities in the real world faces high costs and\ntime complexity. Therefore, sim-to-real transfer has emerged as a key approach,\nyet the sim-to-real gap persists. This survey examines how physics simulators\naddress this gap by analyzing their properties overlooked in previous surveys.\nWe also analyze their features for navigation and manipulation tasks, along\nwith hardware requirements. Additionally, we offer a resource with benchmark\ndatasets, metrics, simulation platforms, and cutting-edge methods-such as world\nmodels and geometric equivariance-to help researchers select suitable tools\nwhile accounting for hardware constraints.",
      "tldr_zh": "这篇调查探讨了在 Embodied AI 时代，使用 physics simulators 进行机器人导航和 manipulation 的关键问题，强调了 sim-to-real 转移在减少训练成本和时间方面的作用，但也指出了存在的差距。论文分析了 physics simulators 的属性、针对导航和 manipulation 任务的特征，以及硬件要求，以弥补之前调查的不足。同时，它提供了一个资源库，包括基准数据集、指标、模拟平台和前沿方法（如 world models 和 geometric equivariance），帮助研究者根据硬件约束选择合适的工具。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01458v1",
      "published_date": "2025-05-01 09:22:23 UTC",
      "updated_date": "2025-05-01 09:22:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:44:12.525078"
    },
    {
      "arxiv_id": "2505.00409v1",
      "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech",
      "title_zh": "自动匿名化在病理语音中的感知影响",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Saba Afza",
        "Tri-Thien Nguyen",
        "Lukas Buess",
        "Maryam Parvin",
        "Tomas Arias-Vergara",
        "Paula Andrea Perez-Toro",
        "Hiu Ching Hung",
        "Mahshad Lotfinia",
        "Thomas Gorges",
        "Elmar Noeth",
        "Maria Schuster",
        "Seung Hee Yang",
        "Andreas Maier"
      ],
      "abstract": "Automatic anonymization techniques are essential for ethical sharing of\npathological speech data, yet their perceptual consequences remain\nunderstudied. This study presents the first comprehensive human-centered\nanalysis of anonymized pathological speech, using a structured perceptual\nprotocol involving ten native and non-native German listeners with diverse\nlinguistic, clinical, and technical backgrounds. Listeners evaluated\nanonymized-original utterance pairs from 180 speakers spanning Cleft Lip and\nPalate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls.\nSpeech was anonymized using state-of-the-art automatic methods (equal error\nrates in the range of 30-40%). Listeners completed Turing-style discrimination\nand quality rating tasks under zero-shot (single-exposure) and few-shot\n(repeated-exposure) conditions. Discrimination accuracy was high overall (91%\nzero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA:\np=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization\nconsistently reduced perceived quality (from 83% to 59%, p<0.001), with\npathology-specific degradation patterns (one-way ANOVA: p=0.005). Native\nlisteners rated original speech slightly higher than non-native listeners\n(Delta=4%, p=0.199), but this difference nearly disappeared after anonymization\n(Delta=1%, p=0.724). No significant gender-based bias was observed. Critically,\nhuman perceptual outcomes did not correlate with automatic privacy or clinical\nutility metrics. These results underscore the need for listener-informed,\ndisorder- and context-specific anonymization strategies that preserve privacy\nwhile maintaining interpretability, communicative functions, and diagnostic\nutility, especially for vulnerable populations such as children.",
      "tldr_zh": "这篇论文首次对自动匿名化病理语音的感知影响进行了全面的人类中心分析，使用10名德语母语和非母语听众评估了180名说话者的语音样本，包括Cleft Lip and Palate、Dysarthria等病理类型和健康对照。听众通过Turing-style discrimination和质量评估任务发现，辨别准确率整体高达91%（零样本）和93%（少样本），但因病理类型不同而异（repeated-measures ANOVA: p=0.007），且匿名化显著降低了感知质量（从83%到59%，p<0.001）。研究强调，人类感知结果与自动隐私或临床指标不相关，呼吁开发听众导向的、特定于病理和上下文的匿名化策略，以保护隐私同时保留诊断和沟通功能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00409v1",
      "published_date": "2025-05-01 09:03:03 UTC",
      "updated_date": "2025-05-01 09:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:44:25.538558"
    },
    {
      "arxiv_id": "2505.00402v1",
      "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions",
      "title_zh": "DeepSTA：一种用于异常条件下物流交付及时率预测的时空注意力网络",
      "authors": [
        "Jinhui Yi",
        "Huan Yan",
        "Haotian Wang",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Prediction of couriers' delivery timely rates in advance is essential to the\nlogistics industry, enabling companies to take preemptive measures to ensure\nthe normal operation of delivery services. This becomes even more critical\nduring anomaly conditions like the epidemic outbreak, during which couriers'\ndelivery timely rate will decline markedly and fluctuates significantly.\nExisting studies pay less attention to the logistics scenario. Moreover, many\nworks focusing on prediction tasks in anomaly scenarios fail to explicitly\nmodel abnormal events, e.g., treating external factors equally with other\nfeatures, resulting in great information loss. Further, since some anomalous\nevents occur infrequently, traditional data-driven methods perform poorly in\nthese scenarios. To deal with them, we propose a deep spatial-temporal\nattention model, named DeepSTA. To be specific, to avoid information loss, we\ndesign an anomaly spatio-temporal learning module that employs a recurrent\nneural network to model incident information. Additionally, we utilize Node2vec\nto model correlations between road districts, and adopt graph neural networks\nand long short-term memory to capture the spatial-temporal dependencies of\ncouriers. To tackle the issue of insufficient training data in abnormal\ncircumstances, we propose an anomaly pattern attention module that adopts a\nmemory network for couriers' anomaly feature patterns storage via attention\nmechanisms. The experiments on real-world logistics datasets during the\nCOVID-19 outbreak in 2022 show the model outperforms the best baselines by\n12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over\nmultiple competitive baselines.",
      "tldr_zh": "该论文提出DeepSTA模型，用于在异常条件下（如疫情）预测物流快递员的准时交付率，以帮助公司提前采取措施。DeepSTA包括异常时空学习模块（使用RNN建模事件信息）、Node2vec建模道路区域相关性，以及GNN和LSTM捕获时空依赖，同时引入异常模式注意力模块（基于记忆网络存储异常特征模式），以解决现有方法的信息损失和数据不足问题。在2022年COVID-19疫情期间的真实数据集上，DeepSTA在MAE上比最佳基线提升12.11%，在MSE上提升13.71%，展现出显著的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM 2023",
      "pdf_url": "http://arxiv.org/pdf/2505.00402v1",
      "published_date": "2025-05-01 08:48:45 UTC",
      "updated_date": "2025-05-01 08:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:44:35.946401"
    },
    {
      "arxiv_id": "2505.00375v1",
      "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhui Yi",
        "Huan Yan",
        "Haotian Wang",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing.",
      "tldr_zh": "该研究针对混合物流服务中递送和取件任务的不平衡问题，提出TransPDT模型，用于精确估计包裹递送时间，以应对多时空因素相互影响、取件时间约束严格以及快递员空间移动模式不足等问题。该模型基于Transformer编码器捕获快递员历史路线和待处理包裹的时空依赖，通过pattern memory和注意力机制学习取件模式，并将路线预测作为辅助任务融入多任务框架。实验在真实行业数据集上验证了TransPDT的优越性，并已在JD Logistics实际部署，跟踪超过2000名快递员每天处理数十万包裹。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACM SIGSPATIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.00375v1",
      "published_date": "2025-05-01 08:00:22 UTC",
      "updated_date": "2025-05-01 08:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:44:49.637823"
    },
    {
      "arxiv_id": "2505.00368v1",
      "title": "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed R. Sadik",
        "Muhammad Ashfaq",
        "Niko Mäkitalo",
        "Tommi Mikkonen"
      ],
      "abstract": "Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.",
      "tldr_zh": "本文提出了一种基于 Large Language Model (LLM) 增强的智能 holonic 架构，用于解决 Urban Air Mobility (UAM) 作为 System of Systems (SoS) 在系统架构、规划、任务管理和执行方面的挑战。该架构利用半自治的 Holons 实现实时协调，例如 air taxis、ground transport 和 vertiports，LLM 负责处理自然语言输入、生成适应性计划并管理干扰如天气变化或空域关闭。通过一个多模式交通案例（涉及电动滑板车和 air taxis），该方法展示了动态资源分配、实时重新规划和自主适应，从而构建更具 resilient 和高效的城市交通网络。该工作推进了去中心化控制和 AI 驱动的适应性，为 human-centric UAM 生态系统奠定基础，并计划未来整合混合 AI 和进行真实世界验证。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00368v1",
      "published_date": "2025-05-01 07:39:11 UTC",
      "updated_date": "2025-05-01 07:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:45:01.773390"
    },
    {
      "arxiv_id": "2505.00367v1",
      "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis",
      "title_zh": "KoACD：首个韩国青少年认知扭曲分析数据集",
      "authors": [
        "JunSeo Kim",
        "HyeHyeon Kim"
      ],
      "abstract": "Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection.",
      "tldr_zh": "本文介绍了KoACD，这是首个大规模韩国青少年认知扭曲(Cognitive Distortion)数据集，包含108,717个实例，旨在填补NLP领域对青少年相关研究的空白。研究采用多大型语言模型(LLM)协商方法，并通过cognitive clarification（用于提升文本清晰度）和cognitive balancing（用于多样化扭曲表示）生成合成数据，以优化扭曲分类。验证结果显示，LLMs在处理显式标记的扭曲时表现良好，但上下文依赖推理不如人类评估者准确；KoACD有望推动未来认知扭曲检测研究的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00367v1",
      "published_date": "2025-05-01 07:37:18 UTC",
      "updated_date": "2025-05-01 07:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:45:12.678084"
    },
    {
      "arxiv_id": "2505.00365v1",
      "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyi Zhong",
        "Weidong Bao",
        "Ji Wang",
        "Jianguo Chen",
        "Lingjuan Lyu",
        "Wei Yang Bryan Lim"
      ],
      "abstract": "The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.",
      "tldr_zh": "该论文提出了一种名为 SacFL 的自适应联邦持续学习（Federated Continual Learning, FCL）框架，旨在解决资源受限终端设备在持续学习（Continual Learning, CL）中面临的存储限制、任务移位检测自主性和对抗任务处理难题。SacFL 采用 Encoder-Decoder 架构分离任务鲁棒和任务敏感组件，从而显著降低存储需求，并利用 contrastive learning 实现自主数据移位检测，允许设备自动判断新任务并触发 CL 或攻击防御策略。在 Cifar100 和 THUCNews 等数据集上的实验验证了 SacFL 在类增量和领域增量场景中的有效性，并通过演示系统证明了其实际可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by TNNLS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00365v1",
      "published_date": "2025-05-01 07:26:35 UTC",
      "updated_date": "2025-05-01 07:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:45:25.367004"
    },
    {
      "arxiv_id": "2505.00359v1",
      "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data",
      "title_zh": "TNStream",
      "authors": [
        "Qifen Zeng",
        "Haomin Bao",
        "Yuanzhuo Hu",
        "Zirui Zhang",
        "Yuheng Zheng",
        "Luosheng Wen"
      ],
      "abstract": "In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.",
      "tldr_zh": "本论文针对数据流聚类中的理论不足，提出了一种基于Tightest Neighbors的新聚类算法，并引入Skeleton Set的数据流聚类理论，以处理任意形状、多密度和高维数据，同时增强对异常点的抵抗力。TNStream算法作为一种完全在线方法，自适应地根据局部相似性确定聚类半径，在Micro-Clusters中总结多密度数据流的演化，并使用Tightest Neighbors-based算法形成最终聚类；为提升高维数据的效率，该算法还采用Locality-Sensitive Hashing (LSH)来结构化微聚类，解决存储k-nearest neighbors的挑战。实验结果显示，TNStream在各种合成和真实数据集上，使用不同聚类指标评估后，显著提高了多密度数据的聚类质量，并验证了提出的数据流聚类理论。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "68T05, 68W20",
        "H.2.8; I.5.3"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures, 8 tables, under review at Expert Systems with\n  Applications (ESWA)",
      "pdf_url": "http://arxiv.org/pdf/2505.00359v1",
      "published_date": "2025-05-01 07:15:20 UTC",
      "updated_date": "2025-05-01 07:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:45:38.053277"
    },
    {
      "arxiv_id": "2505.00358v1",
      "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training",
      "title_zh": "R&B：领域重新分组和数据混合平衡用于高效基础模型训练",
      "authors": [
        "Albert Ge",
        "Tzu-Heng Huang",
        "John Cooper",
        "Avi Trost",
        "Ziyi Chu",
        "Satya Sai Srinath Namburi GNVV",
        "Ziyang Cai",
        "Kendall Park",
        "Nicholas Roberts",
        "Frederic Sala"
      ],
      "abstract": "Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies.",
      "tldr_zh": "本文提出R&B框架，旨在解决现有数据混合策略在训练Foundation Model时的两大问题：依赖预定数据域导致的语义细微差异忽略，以及计算开销随域数增加而激增。R&B通过Domain Regrouping基于语义相似性重新分区训练数据创建更细粒度的域，并利用域梯度诱导的Gram matrix进行Data Mixture Balancing，以高效优化数据组成，且无需额外计算获取评估信息。实验结果显示，在五个多样数据集（涵盖自然语言、推理和多模态任务）上，R&B仅需0.01%的额外计算开销，即匹配或超过最先进策略的性能，并通过理论分析证明其在标准条件下比非自适应方法更有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00358v1",
      "published_date": "2025-05-01 07:08:19 UTC",
      "updated_date": "2025-05-01 07:08:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:45:49.806450"
    },
    {
      "arxiv_id": "2505.00350v1",
      "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression",
      "title_zh": "利用安全引导的自我压缩优化深度神经网络",
      "authors": [
        "Mohammad Zbeeb",
        "Mariam Salman",
        "Mohammad Bazzi",
        "Ammar Mohanna"
      ],
      "abstract": "The deployment of deep neural networks on resource-constrained devices\nnecessitates effective model com- pression strategies that judiciously balance\nthe reduction of model size with the preservation of performance. This study\nintroduces a novel safety-driven quantization framework that leverages\npreservation sets to systematically prune and quantize neural network weights,\nthereby optimizing model complexity without compromising accuracy. The proposed\nmethodology is rigorously evaluated on both a convolutional neural network\n(CNN) and an attention-based language model, demonstrating its applicability\nacross diverse architectural paradigms. Experimental results reveal that our\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\noriginal unquantized models while maintaining 60% of the initial model size. In\ncomparison to conventional quantization techniques, our approach not only\naugments generalization by eliminating parameter noise and retaining essential\nweights but also reduces variance, thereby ensuring the retention of critical\nmodel features. These findings underscore the efficacy of safety-driven\nquantization as a robust and reliable strategy for the efficient optimization\nof deep learn- ing models. The implementation and comprehensive experimental\nevaluations of our framework are publicly accessible at GitHub.",
      "tldr_zh": "本研究提出了一种安全驱动的量化框架（safety-guided self compression），利用preservation sets系统地修剪和量化深度神经网络权重，以平衡模型大小减少和性能保持。框架在CNN和注意力-based语言模型上进行评估，展示了其在不同架构中的适用性。实验结果显示，与未量化模型相比，该方法在保持原始模型大小60%的同时，提高测试准确率高达2.5%；相较传统量化技术，它还提升了模型泛化性、减少了参数噪声和方差，确保关键权重保留。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "A Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.00350v1",
      "published_date": "2025-05-01 06:50:30 UTC",
      "updated_date": "2025-05-01 06:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:46:01.031366"
    },
    {
      "arxiv_id": "2505.00347v1",
      "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics",
      "title_zh": "低位优化器的极限拓展：聚焦 EMA 动态",
      "authors": [
        "Cong Xu",
        "Wenbin Liang",
        "Mo Yu",
        "Anan Liu",
        "Ke-Yue Zhang",
        "Lizhuang Ma",
        "Jianyong Wang",
        "Jun Wang",
        "Wei Zhang"
      ],
      "abstract": "The explosion in model sizes leads to continued growth in prohibitive\ntraining/fine-tuning costs, particularly for stateful optimizers which maintain\nauxiliary information of even 2x the model size to achieve optimal convergence.\nWe therefore present in this work a novel type of optimizer that carries with\nextremely lightweight state overloads, achieved through ultra-low-precision\nquantization. While previous efforts have achieved certain success with 8-bit\nor 4-bit quantization, our approach enables optimizers to operate at precision\nas low as 3 bits, or even 2 bits per state element. This is accomplished by\nidentifying and addressing two critical challenges: the signal swamping problem\nin unsigned quantization that results in unchanged state dynamics, and the\nrapidly increased gradient variance in signed quantization that leads to\nincorrect descent directions. The theoretical analysis suggests a tailored\nlogarithmic quantization for the former and a precision-specific momentum value\nfor the latter. Consequently, the proposed SOLO achieves substantial memory\nsavings (approximately 45 GB when training a 7B model) with minimal accuracy\nloss. We hope that SOLO can contribute to overcoming the bottleneck in\ncomputational resources, thereby promoting greater accessibility in fundamental\nresearch.",
      "tldr_zh": "该论文探讨了模型训练成本高涨的问题，提出了一种新型优化器 SOLO，通过极低精度量化（如 2-3 位）显著减少优化器状态开销。针对无符号量化中的信号 swamping 问题和有符号量化中的梯度方差增加，作者采用对数量化及精度特定动量值进行优化，确保正确的下降方向。实验结果显示，SOLO 在训练 7B 模型时节省约 45 GB 内存，同时仅造成最小精度损失，从而提升计算资源的可访问性，促进基础研究发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.00347v1",
      "published_date": "2025-05-01 06:47:45 UTC",
      "updated_date": "2025-05-01 06:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:46:14.254392"
    },
    {
      "arxiv_id": "2505.00339v1",
      "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Antoun Yaacoub",
        "Sansiri Tarnpradab",
        "Phattara Khumprom",
        "Zainab Assaghir",
        "Lionel Prevost",
        "Jérôme Da-Rugna"
      ],
      "abstract": "Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation.",
      "tldr_zh": "本论文探讨了人工智能（AI）在教育领域的应用，强调通过整合认知评估框架（如 Bloom's Taxonomy 和 SOLO Taxonomy）、语言反馈分析以及伦理设计原则，来提升AI生成内容的质量和深度。作者提出一个结构化的三阶段方法，包括认知对齐、语言反馈整合以及伦理保障，以指导AI驱动教育工具的开发。该框架被应用于OneClickQuiz（一个AI增强的Moodle插件），为教育工作者、研究者和开发者提供实用指南，确保AI在教育中实现个性化学习的同时，维护教学和伦理标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This article will be presented in IJCNN 2025 \"AI Innovations for\n  Education: Transforming Teaching and Learning through Cutting-Edge\n  Technologies\" workshop",
      "pdf_url": "http://arxiv.org/pdf/2505.00339v1",
      "published_date": "2025-05-01 06:36:21 UTC",
      "updated_date": "2025-05-01 06:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:46:25.242124"
    },
    {
      "arxiv_id": "2505.00337v1",
      "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation",
      "title_zh": "T2VPhysBench：",
      "authors": [
        "Xuyang Guo",
        "Jiayan Huo",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "abstract": "Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration.",
      "tldr_zh": "本文引入了 T2VPhysBench，这是一个基于 first-principles 的基准，用于系统评估文本到视频生成模型是否遵守 12 个核心物理定律，包括 Newtonian mechanics、守恒原理和现象效应。基准采用严格的人类评估协议，并通过三个针对性研究（整体合规性评估、提示提示去除实验和反事实鲁棒性测试）发现，所有模型在每个定律类别中的平均分数低于 0.60，且即使提供详细提示也无法有效修复物理违规。研究结果揭示了当前模型的持久局限性，并为开发真正的 physics-aware 视频生成技术提供了关键指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00337v1",
      "published_date": "2025-05-01 06:34:55 UTC",
      "updated_date": "2025-05-01 06:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:46:38.849159"
    },
    {
      "arxiv_id": "2505.00335v1",
      "title": "Efficient Neural Video Representation with Temporally Coherent Modulation",
      "title_zh": "翻译失败",
      "authors": [
        "Seungjun Shin",
        "Suji Kim",
        "Dokwan Oh"
      ],
      "abstract": "Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/.",
      "tldr_zh": "本研究针对隐式神经表示 (INR) 在视频应用中的训练效率问题，提出了 Neural Video representation with Temporally coherent Modulation (NVTM) 框架，该框架通过将时空 3D 视频数据分解成带流信息的 2D 网格，实现快速编码和参数高效利用。相比现有网格型方法，NVTM 的编码速度提高了 3 倍以上，并在 UVG 和 MCL-JCV 数据集上实现了 PSNR/LPIPS 平均改善 1.54dB/0.019 和 1.84dB/0.013，同时参数减少 10%。此外，NVTM 在视频压缩、超分辨率、帧插值和视频修复等任务中表现出色，与 H.264 和 HEVC 等标准相比具有可比性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.00335v1",
      "published_date": "2025-05-01 06:20:42 UTC",
      "updated_date": "2025-05-01 06:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:46:51.012985"
    },
    {
      "arxiv_id": "2505.00325v1",
      "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform",
      "title_zh": "CognitionNet：一种用于在线技能游戏平台的协作神经网络游戏风格发现",
      "authors": [
        "Rukma Talwadker",
        "Surajit Chakrabarty",
        "Aditya Pareek",
        "Tridib Mukherjee",
        "Deepak Saini"
      ],
      "abstract": "Games are one of the safest source of realizing self-esteem and relaxation at\nthe same time. An online gaming platform typically has massive data coming in,\ne.g., in-game actions, player moves, clickstreams, transactions etc. It is\nrather interesting, as something as simple as data on gaming moves can help\ncreate a psychological imprint of the user at that moment, based on her\nimpulsive reactions and response to a situation in the game. Mining this\nknowledge can: (a) immediately help better explain observed and predicted\nplayer behavior; and (b) consequently propel deeper understanding towards\nplayers' experience, growth and protection. To this effect, we focus on\ndiscovery of the \"game behaviours\" as micro-patterns formed by continuous\nsequence of games and the persistent \"play styles\" of the players' as a\nsequence of such sequences on an online skill gaming platform for Rummy. We\npropose a two stage deep neural network, CognitionNet. The first stage focuses\non mining game behaviours as cluster representations in a latent space while\nthe second aggregates over these micro patterns to discover play styles via a\nsupervised classification objective around player engagement. The dual\nobjective allows CognitionNet to reveal several player psychology inspired\ndecision making and tactics. To our knowledge, this is the first and\none-of-its-kind research to fully automate the discovery of: (i) player\npsychology and game tactics from telemetry data; and (ii) relevant diagnostic\nexplanations to players' engagement predictions. The collaborative training of\nthe two networks with differential input dimensions is enabled using a novel\nformulation of \"bridge loss\". The network plays pivotal role in obtaining\nhomogeneous and consistent play style definitions and significantly outperforms\nthe SOTA baselines wherever applicable.",
      "tldr_zh": "该研究提出了一种协作神经网络CognitionNet，用于在线技能游戏平台（如Rummy）中发现玩家的游戏行为和游戏风格。CognitionNet采用两阶段设计：第一阶段在潜空间中挖掘游戏行为作为集群表示，第二阶段通过监督分类目标聚合这些微模式，以预测玩家参与度并揭示心理决策和策略。该框架利用创新的“bridge loss”来实现两个网络的协作训练，并在定义游戏风格方面显著优于SOTA基线，为自动化从遥测数据中提取玩家心理和游戏策略提供了首次全面解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00325v1",
      "published_date": "2025-05-01 05:51:19 UTC",
      "updated_date": "2025-05-01 05:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:47:02.409923"
    },
    {
      "arxiv_id": "2505.00322v1",
      "title": "AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Keshu Wu",
        "Zihao Li",
        "Sixu Li",
        "Xinyue Ye",
        "Dominique Lord",
        "Yang Zhou"
      ],
      "abstract": "This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments.",
      "tldr_zh": "本论文提出AI2-Active Safety框架，这是一个AI-enabled、interaction-aware的主动安全分析系统，旨在处理群组车辆互动并整合车辆动态建模。框架结合增强道路坡度的bicycle model和hypergraph-based AI模型来预测周边交通的概率轨迹，并通过求解随机常微分方程生成高保真安全指标，如time-to-collision (TTC)和HF-TTC分布。实验结果显示，该框架在高速公路数据集上优于传统constant-velocity TTC方法，提供更准确的安全感知和改善复杂交通环境的潜在风险评估。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00322v1",
      "published_date": "2025-05-01 05:46:34 UTC",
      "updated_date": "2025-05-01 05:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:47:17.233883"
    },
    {
      "arxiv_id": "2505.00316v2",
      "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Tien Comlekoglu",
        "J. Quetzalcóatl Toledo-Marín",
        "Tina Comlekoglu",
        "Douglas W. DeSimone",
        "Shayn M. Peirce",
        "Geoffrey Fox",
        "James A. Glazier"
      ],
      "abstract": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.",
      "tldr_zh": "本文提出了一种将 Cellular-Potts Agent-Based Models 的模拟任务视为图像分割问题的代理建模方法，使用 U-Net 神经网络架构的 CNN 模型来处理周期边界条件，从而加速计算密集型模拟。模型训练后能预测 100 个 Monte-Carlo steps ahead，实现模拟评估速度提升 590 倍，同时准确捕捉原始模型的紧急行为，如血管发芽、延伸、吻合和血管腔收缩。该方法展示了深度学习作为 Cellular-Potts 模型高效代理的潜力，适用于更大空间和时间规模的生物过程模拟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00316v2",
      "published_date": "2025-05-01 05:30:38 UTC",
      "updated_date": "2025-05-05 15:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:47:26.097605"
    },
    {
      "arxiv_id": "2505.00752v2",
      "title": "DARTer: Dynamic Adaptive Representation Tracker for Nighttime UAV Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Xuzhao Li",
        "Xuchen Li",
        "Shiyu Hu"
      ],
      "abstract": "Nighttime UAV tracking presents significant challenges due to extreme\nillumination variations and viewpoint changes, which severely degrade tracking\nperformance. Existing approaches either rely on light enhancers with high\ncomputational costs or introduce redundant domain adaptation mechanisms,\nfailing to fully utilize the dynamic features in varying perspectives. To\naddress these issues, we propose \\textbf{DARTer} (\\textbf{D}ynamic\n\\textbf{A}daptive \\textbf{R}epresentation \\textbf{T}racker), an end-to-end\ntracking framework designed for nighttime UAV scenarios. DARTer leverages a\nDynamic Feature Blender (DFB) to effectively fuse multi-perspective nighttime\nfeatures from static and dynamic templates, enhancing representation\nrobustness. Meanwhile, a Dynamic Feature Activator (DFA) adaptively activates\nVision Transformer layers based on extracted features, significantly improving\nefficiency by reducing redundant computations. Our model eliminates the need\nfor complex multi-task loss functions, enabling a streamlined training process.\nExtensive experiments on multiple nighttime UAV tracking benchmarks demonstrate\nthe superiority of DARTer over state-of-the-art trackers. These results confirm\nthat DARTer effectively balances tracking accuracy and efficiency, making it a\npromising solution for real-world nighttime UAV tracking applications.",
      "tldr_zh": "本文提出 DARTer，一种针对夜间无人机(UAV)跟踪的端到端框架，旨在解决极端光照变化和视角变化导致的性能下降问题。DARTer 通过 Dynamic Feature Blender (DFB) 融合多视角特征以增强表示鲁棒性，并利用 Dynamic Feature Activator (DFA) 自适应激活 Vision Transformer 层，减少冗余计算并简化训练过程。实验结果显示，DARTer 在多个夜间 UAV 跟踪基准上优于最先进追踪器，在准确性和效率之间实现了有效平衡，为真实世界应用提供了一个有前景的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint, Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.00752v2",
      "published_date": "2025-05-01 05:24:14 UTC",
      "updated_date": "2025-05-16 04:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:47:39.343958"
    },
    {
      "arxiv_id": "2505.00308v2",
      "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality",
      "title_zh": "翻译失败",
      "authors": [
        "Biling Wang",
        "Austen Maniscalco",
        "Ti Bai",
        "Siqiu Wang",
        "Michael Dohopolski",
        "Mu-Han Lin",
        "Chenyang Shen",
        "Dan Nguyen",
        "Junzhou Huang",
        "Steve Jiang",
        "Xinlei Wang"
      ],
      "abstract": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.",
      "tldr_zh": "本研究提出了一种基于深度学习（Deep Learning, DL）的质量评估（QA）方法，用于评估放射治疗中自动生成轮廓（auto-contours）的质量，特别是针对在线自适应放射治疗（OART）。该方法采用 Bayesian Ordinal Classification (BOC) 模型结合校准的不确定性阈值，实现无需 ground truth 轮廓或大量手动标记的置信预测。实验在三种数据场景下验证，包括无手动标签、有限标签和大量标签，结果显示，仅用 30 个手动标签微调并校准 34 个受试者，即在测试数据上达到 90% 以上准确率，且使用校准阈值后，93% 的轮廓质量在 98% 的情况下被准确预测，显著减少不必要的手动审查。该方法通过不确定性量化提升了放射治疗工作流的效率和可靠性，促进更安全、快速的临床决策。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00308v2",
      "published_date": "2025-05-01 05:05:35 UTC",
      "updated_date": "2025-05-11 20:02:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:47:51.633235"
    },
    {
      "arxiv_id": "2505.00295v1",
      "title": "Fine-grained spatial-temporal perception for gas leak segmentation",
      "title_zh": "细粒度时空",
      "authors": [
        "Xinlong Zhao",
        "Shan Du"
      ],
      "abstract": "Gas leaks pose significant risks to human health and the environment. Despite\nlong-standing concerns, there are limited methods that can efficiently and\naccurately detect and segment leaks due to their concealed appearance and\nrandom shapes. In this paper, we propose a Fine-grained Spatial-Temporal\nPerception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical\nmotion clues across frames and integrates them with refined object features in\nan end-to-end network. Specifically, we first construct a correlation volume to\ncapture motion information between consecutive frames. Then, the fine-grained\nperception progressively refines the object-level features using previous\noutputs. Finally, a decoder is employed to optimize boundary segmentation.\nBecause there is no highly precise labeled dataset for gas leak segmentation,\nwe manually label a gas leak video dataset, GasVid. Experimental results on\nGasVid demonstrate that our model excels in segmenting non-rigid objects such\nas gas leaks, generating the most accurate mask compared to other\nstate-of-the-art (SOTA) models.",
      "tldr_zh": "这篇论文针对气体泄漏的隐蔽外观和随机形状问题，提出了一种 Fine-grained Spatial-Temporal Perception (FGSTP) 算法，用于精确检测和分割气体泄漏。FGSTP 通过构建 correlation volume 捕获连续帧间的运动信息，并逐步精炼对象级特征，最后使用解码器优化边界分割，实现端到端处理。作者手动标注了新的 GasVid 数据集，实验结果显示，该模型在分割非刚性物体方面优于现有 SOTA 模型，提供最准确的掩码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45 (Primary), 68T07 (Secondary)",
        "I.2.10; I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures, ICIP 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.00295v1",
      "published_date": "2025-05-01 04:35:57 UTC",
      "updated_date": "2025-05-01 04:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:48:04.488756"
    },
    {
      "arxiv_id": "2505.00290v1",
      "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Xin Xie",
        "Jian De Sun",
        "Fan Fu Xue",
        "Zi Fei Han",
        "Shan Shan Feng",
        "Qi Chen"
      ],
      "abstract": "Molecular odor prediction is the process of using a molecule's structure to\npredict its smell. While accurate prediction remains challenging, AI models can\nsuggest potential odors. Existing methods, however, often rely on basic\ndescriptors or handcrafted fingerprints, which lack expressive power and hinder\neffective learning. Furthermore, these methods suffer from severe class\nimbalance, limiting the training effectiveness of AI models. To address these\nchallenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature\nMapping Network (HMFNet). Specifically, we introduce a fine-grained, Local\nMulti-Hierarchy Feature Extraction module (LMFE) that performs deep feature\nextraction at the atomic level, capturing detailed features crucial for odor\nprediction. To enhance the extraction of discriminative atomic features, we\nintegrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically\nlearns feature importance and frequency modulation, improving the model's\ncapability to capture relevant patterns. Additionally, a Global Multi-Hierarchy\nFeature Extraction module (GMFE) is designed to learn global features from the\nmolecular graph topology, enabling the model to fully leverage global\ninformation and enhance its discriminative power for odor prediction. To\nfurther mitigate the issue of class imbalance, we propose a Chemically-Informed\nLoss (CIL). Experimental results demonstrate that our approach significantly\nimproves performance across various deep learning models, highlighting its\npotential to advance molecular structure representation and accelerate the\ndevelopment of AI-driven technologies.",
      "tldr_zh": "本文提出了一种基于特征贡献驱动的多层次细粒度特征映射网络(HMFNet)，旨在解决分子气味预测中的特征表达力不足和类别不平衡问题。该网络包括局部多层次特征提取模块(LMFE)用于原子级别深度特征提取、Harmonic Modulated Feature Mapping (HMFM)动态学习特征重要性和频率调制，以及全局多层次特征提取模块(GMFE)从分子图拓扑中提取全局信息，以提升模型的判别能力。此外，引入Chemically-Informed Loss (CIL)来缓解类别不平衡，实验结果显示该方法显著提高了各种深度学习模型的性能，推动了分子结构表示和AI驱动技术的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00290v1",
      "published_date": "2025-05-01 04:26:31 UTC",
      "updated_date": "2025-05-01 04:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:48:16.706954"
    },
    {
      "arxiv_id": "2505.00284v1",
      "title": "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijie Qiao",
        "Haowei Li",
        "Zhong Cao",
        "Henry X. Liu"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.",
      "tldr_zh": "这篇论文引入了 LightEMMA，一种轻量级端到端多模态模型，用于评估 Vision-Language Models (VLMs) 在自动驾驶任务中的优势和局限性。LightEMMA 提供了一个统一的框架，便于集成各种商业和开源 VLMs，而无需特定定制，并构建了 12 个自动驾驶代理在 nuScenes 预测任务上进行评估，包括推理时间、计算成本和预测准确性。研究结果显示，尽管 VLMs 在场景解释方面表现出色，但其实际性能仍存在问题，强调了进一步改进的必要性。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00284v1",
      "published_date": "2025-05-01 04:12:41 UTC",
      "updated_date": "2025-05-01 04:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:48:28.479012"
    },
    {
      "arxiv_id": "2505.00278v1",
      "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Lo Pang-Yun Ting",
        "Yu-Hao Chiang",
        "Yi-Tung Tsai",
        "Hsu-Chao Lai",
        "Kun-Ta Chuang"
      ],
      "abstract": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling.",
      "tldr_zh": "本文提出 DeCo，一种缺陷感知建模方法，用于优化在线 IC 测试中的任务分配问题，通过整合缺陷特征、历史故障和工程师专长来提升效率。DeCo 构建 defect-aware graph 来捕捉共故障关系，并通过局部和全局结构建模生成缺陷感知表示，同时采用 contrasting-based assignment 机制，将任务分配给适合的 QA 工程师，考虑其技能水平和工作负载。实验在真实数据集上显示，DeCo 的任务处理成功率超过 80%，并在数据稀缺或扩展场景下保持工作负载平衡，为 IC 故障分析和任务处理提供可靠的 AI 解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00278v1",
      "published_date": "2025-05-01 04:01:14 UTC",
      "updated_date": "2025-05-01 04:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:48:41.750117"
    },
    {
      "arxiv_id": "2505.00268v1",
      "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Jekaterina Novikova",
        "Carol Anderson",
        "Borhane Blili-Hamelin",
        "Subhabrata Majumdar"
      ],
      "abstract": "The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability.",
      "tldr_zh": "这篇论文探讨了语言模型中的一致性问题，强调人类语言在表达相似含义和避免矛盾方面的优势，而当前先进模型在不同场景下仍存在显著挑战。论文分析了形式一致性（如逻辑规则遵守）和非形式一致性（如道德和事实连贯性）的当前研究景观，并评估了测量这些方面的现有方法，同时识别了关键空白，包括定义标准化、多语言评估和改进策略。最终，研究呼吁开发稳健的benchmarks和跨学科方法，以提升语言模型在领域特定任务中的一致性，同时保持其效用和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00268v1",
      "published_date": "2025-05-01 03:25:25 UTC",
      "updated_date": "2025-05-01 03:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:48:52.628312"
    },
    {
      "arxiv_id": "2505.00259v1",
      "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Changjun Li",
        "Runqing Jiang",
        "Zhuo Song",
        "Pengpeng Yu",
        "Ye Zhang",
        "Yulan Guo"
      ],
      "abstract": "Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods.",
      "tldr_zh": "这篇论文提出了Pack-PTQ，一种创新的后训练量化（PTQ）方法，通过包级重建（pack-wise reconstruction）来解决现有PTQ方法忽略跨块依赖导致低位量化准确率下降的问题。Pack-PTQ首先引入Hessian-guided adaptive packing机制，将神经网络块分区成非重叠的包作为重建单位，从而保留跨块依赖并提升量化参数估计的准确性；其次，基于包配置，实现混合精度量化，根据不同包的敏感度分配变动的位宽，进一步优化性能。实验结果显示，在2D图像和3D点云分类任务中使用各种网络架构时，Pack-PTQ比最先进PTQ方法表现出显著优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00259v1",
      "published_date": "2025-05-01 02:53:46 UTC",
      "updated_date": "2025-05-01 02:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:49:04.774130"
    },
    {
      "arxiv_id": "2505.00254v3",
      "title": "Empowering Agentic Video Analytics Systems with Video Language Models",
      "title_zh": "使用视频语言模型赋",
      "authors": [
        "Yuxuan Yan",
        "Shiqi Jiang",
        "Ting Cao",
        "Yifan Yang",
        "Qianqian Yang",
        "Yuanchao Shu",
        "Yuqing Yang",
        "Lili Qiu"
      ],
      "abstract": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVAS, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVAS incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVAS achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVAS-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVAS-100, AVAS achieves top-tier performance with an\naccuracy of 75.8%.",
      "tldr_zh": "该研究针对现有视频分析系统的任务局限性和 Video-Language Models (VLMs) 的上下文窗口限制，提出了一种基于 VLMs 的代理式视频分析系统 AVAS。AVAS 的核心创新包括实时构建 Event Knowledge Graphs (EKGs) 用于长视频索引，以及 agentic retrieval-generation 机制来处理复杂查询，从而实现开放式视频理解和分析。在 LVBench 和 VideoMME-Long 基准上，AVAS 分别达到 62.3% 和 64.1% 的准确率，显著超越现有系统；此外，该论文引入了新基准 AVAS-100，包括超过 10 小时的视频和多样化问题，在此基准上 AVAS 获得 75.8% 的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, AVAS, add latency breakdown",
      "pdf_url": "http://arxiv.org/pdf/2505.00254v3",
      "published_date": "2025-05-01 02:40:23 UTC",
      "updated_date": "2025-05-16 10:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:49:16.771149"
    },
    {
      "arxiv_id": "2505.01456v1",
      "title": "Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Vaidehi Patil",
        "Yi-Lin Sung",
        "Peter Hase",
        "Jie Peng",
        "Tianlong Chen",
        "Mohit Bansal"
      ],
      "abstract": "LLMs trained on massive datasets may inadvertently acquire sensitive\ninformation such as personal details and potentially harmful content. This risk\nis further heightened in multimodal LLMs as they integrate information from\nmultiple modalities (image and text). Adversaries can exploit this knowledge\nthrough multimodal prompts to extract sensitive details. Evaluating how\neffectively MLLMs can forget such information (targeted unlearning)\nnecessitates the creation of high-quality, well-annotated image-text pairs.\nWhile prior work on unlearning has focused on text, multimodal unlearning\nremains underexplored. To address this gap, we first introduce a multimodal\nunlearning benchmark, UnLOK-VQA (Unlearning Outside Knowledge VQA), as well as\nan attack-and-defense framework to evaluate methods for deleting specific\nmultimodal knowledge from MLLMs. We extend a visual question-answering dataset\nusing an automated pipeline that generates varying-proximity samples for\ntesting generalization and specificity, followed by manual filtering for\nmaintaining high quality. We then evaluate six defense objectives against seven\nattacks (four whitebox, three blackbox), including a novel whitebox method\nleveraging interpretability of hidden states. Our results show multimodal\nattacks outperform text- or image-only ones, and that the most effective\ndefense removes answer information from internal model states. Additionally,\nlarger models exhibit greater post-editing robustness, suggesting that scale\nenhances safety. UnLOK-VQA provides a rigorous benchmark for advancing\nunlearning in MLLMs.",
      "tldr_zh": "该论文探讨了多模态大语言模型 (MLLMs) 中敏感信息的无意获取及其潜在风险，提出一个新的基准 UnLOK-VQA（Unlearning Outside Knowledge VQA）来评估针对多模态知识的 targeted unlearning 方法。研究开发了一个 attack-and-defense 框架，通过扩展视觉问答数据集并使用自动化管道生成高质量样本，对六种防御目标和七种攻击（包括四种白盒和三种黑盒攻击）进行了评估，结果显示多模态攻击比单一模态攻击更有效，而从模型内部状态移除答案信息是最强防御策略。此外，实验发现更大规模的模型在编辑后表现出更高的鲁棒性，表明模型规模能提升安全性，为推进 MLLMs 中的 unlearning 研究提供了严格基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "The dataset and code are publicly available at\n  https://github.com/Vaidehi99/UnLOK-VQA",
      "pdf_url": "http://arxiv.org/pdf/2505.01456v1",
      "published_date": "2025-05-01 01:54:00 UTC",
      "updated_date": "2025-05-01 01:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:49:29.494075"
    },
    {
      "arxiv_id": "2505.00240v2",
      "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems",
      "title_zh": "基于LLM的IoT生态系统威胁检测和预防框架",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Amiya Nayak"
      ],
      "abstract": "The increasing complexity and scale of the Internet of Things (IoT) have made\nsecurity a critical concern. This paper presents a novel Large Language Model\n(LLM)-based framework for comprehensive threat detection and prevention in IoT\nenvironments. The system integrates lightweight LLMs fine-tuned on IoT-specific\ndatasets (IoT-23, TON_IoT) for real-time anomaly detection and automated,\ncontext-aware mitigation strategies optimized for resource-constrained devices.\nA modular Docker-based deployment enables scalable and reproducible evaluation\nacross diverse network conditions. Experimental results in simulated IoT\nenvironments demonstrate significant improvements in detection accuracy,\nresponse latency, and resource efficiency over traditional security methods.\nThe proposed framework highlights the potential of LLM-driven, autonomous\nsecurity solutions for future IoT ecosystems.",
      "tldr_zh": "本论文提出了一种基于 Large Language Model (LLM) 的框架，用于 IoT 生态系统的威胁检测和预防，旨在应对 IoT 环境的日益复杂性。该框架整合了在 IoT 特定数据集（如 IoT-23 和 TON_IoT）上微调的轻量级 LLM，实现实时异常检测和自动化的上下文感知缓解策略，并针对资源受限设备进行优化。实验结果显示，在模拟 IoT 环境中，该框架相较传统方法显著提升了检测准确率、响应延迟和资源效率，展示了 LLM 驱动的自主安全解决方案在未来 IoT 生态系统中的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint version; submitted for academic peer review",
      "pdf_url": "http://arxiv.org/pdf/2505.00240v2",
      "published_date": "2025-05-01 01:18:54 UTC",
      "updated_date": "2025-05-13 03:02:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:49:40.036321"
    },
    {
      "arxiv_id": "2505.00232v1",
      "title": "Scaling On-Device GPU Inference for Large Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuqiang Tang",
        "Raman Sarokin",
        "Ekaterina Ignasheva",
        "Grant Jensen",
        "Lin Chen",
        "Juhyun Lee",
        "Andrei Kulik",
        "Matthias Grundmann"
      ],
      "abstract": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.",
      "tldr_zh": "本论文探讨了在设备上扩展GPU推理能力，以支持大型生成AI模型的部署，针对隐私和效率需求。研究引入了ML Drift框架，该框架优化了现有GPU加速推理引擎，解决了跨GPU API开发的工程挑战，并确保在移动、桌面和笔记本平台的广泛兼容，从而允许运行参数多10-100倍的生成AI工作负载。结果表明，ML Drift相对于现有开源GPU推理引擎实现了10倍的性能提升，为资源受限设备上复杂模型的部署提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "to be published in CVPR 2025 Workshop on Efficient and On-Device\n  Generation (EDGE)",
      "pdf_url": "http://arxiv.org/pdf/2505.00232v1",
      "published_date": "2025-05-01 00:44:13 UTC",
      "updated_date": "2025-05-01 00:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:49:52.196109"
    },
    {
      "arxiv_id": "2505.00225v1",
      "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers",
      "title_zh": "使用纵向表格变换器预测电力中断的估计恢复时间",
      "authors": [
        "Bogireddy Sai Prasanna Teja",
        "Valliappan Muthukaruppan",
        "Carls Benjamin"
      ],
      "abstract": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.",
      "tldr_zh": "这篇论文提出了一种Longitudinal Tabular Transformer (LTT)模型，用于预测电力中断的恢复时间 (ETR)，以应对气候变化导致的自然灾害中现有手动或传统统计方法的精度不足问题。LTT模型通过整合历史中断事件数据和顺序更新，针对34,000场风暴相关事件进行评估，覆盖三个主要公用事业公司服务超过300万客户的两年数据。结果显示，该模型将Customer Satisfaction Impact (CSI)指标平均提高了19.08%（p > 0.001），并引入了与客户满意度相关的回归指标，以更好地反映实际需求。此外，通过可解释性技术，分析了顺序更新和预测特征的作用，提升了模型的透明度和用户信任。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00225v1",
      "published_date": "2025-05-01 00:25:43 UTC",
      "updated_date": "2025-05-01 00:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T18:50:05.064981"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T18:50:30.321377"
}