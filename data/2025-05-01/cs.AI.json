{
  "date": "2025-05-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-05-01的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 上的研究热点集中在大型语言模型的深入应用与评估、强化学习新算法的提出以及计算机视觉在生成与模拟领域的前沿探索。值得关注的包括利用思维链和强化学习提升图像生成质量、DeepMind 提出的 Wasserstein 策略优化算法、对 LLM 泛化能力和一致性的深入探讨，以及面向城市微交通和物理一致性的新型模拟与基准测试。此外，AI 在机器人控制、医疗影像、半导体测试、物流优化等多个领域的应用也展现了新的进展。\n\n**重点论文 & LLM 相关研究**\n\n*   **T2I-R1：结合语义级和令牌级 CoT 强化图像生成 (T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT):** 这篇论文提出 T2I-R1 模型，首次将强化学习（RL）和两级思维链（CoT）推理（语义级用于提示规划，令牌级用于逐块生成时的像素处理）应用于文本到图像生成。通过名为 BiCoT-GRPO 的新优化策略协调两级 CoT，该模型在 T2I-CompBench 和 WISE 基准上显著优于基线 Janus-Pro，甚至超越了 SOTA 模型 FLUX.1。这表明推理策略能有效提升视觉生成效果。\n\n*   **DeepCritic：利用大型语言模型进行审慎批判 (DeepCritic: Deliberate Critique with Large Language Models):** 针对 LLM 输出评估的挑战，该研究聚焦于提升 LLM 的数学解题批判能力。现有 LLM 批判模型往往过于肤浅，难以提供有效反馈。DeepCritic 提出一个两阶段框架：首先用强 LLM 生成包含多角度验证和深入反思的“长式批判”数据进行微调；然后利用人工标注或自动标注数据（基于蒙特卡洛采样）进行强化学习。基于 Qwen2.5-7B 的 DeepCritic 在错误识别基准上显著优于现有模型（包括同尺寸 DeepSeek 和 GPT-4o），并能提供更详细的反馈帮助生成模型修正错误。\n\n*   **LLM 泛化研究：上下文学习与微调的对比 (On the generalization of language models from in-context learning and finetuning: a controlled study):** 这项研究通过精心构建的、隔离预训练知识的数据集，对比了大型语言模型通过上下文学习和微调进行泛化的差异。研究发现，在数据匹配的情况下，上下文学习通常比微调具有更灵活的泛化能力（但也发现微调在特定结构知识下能泛化反转关系）。作者提出将上下文推理结果加入微调数据中，以改善微调的泛化效果。这对理解不同学习模式的归纳偏见和提升模型性能具有意义。\n\n*   **角色分离的幻觉：LLM 角色学习中的隐藏捷径（及修复方法）(The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)):** LLM 需要区分不同输入角色（系统指令、用户查询、工具输出），即“角色分离”。研究发现，即使是针对提示注入攻击优化的模型，也可能依赖“任务类型”和“距文本开头的距离”等捷径来识别角色，而非真正理解角色差异。数据增强只能部分缓解。作者提出通过调整输入编码中的 token 级线索（特别是位置 ID）来强化标记角色边界的不变信号，从而帮助模型学习更清晰的角色区分，减少对表面代理的依赖。\n\n*   **FreqKV：用于高效上下文窗口扩展的频域键值压缩 (FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension):** 扩展 LLM 上下文窗口面临 KV 缓存内存和自注意力计算复杂度的挑战。该研究发现 KV 缓存的能量主要集中在频域的低频部分。基于此，提出 FreqKV 方法，在微调和推理过程中，通过滤除高频分量，将不断增长的 KV 缓存迭代压缩到固定大小。该方法无需额外参数或架构修改，通过少量微调即可让 LLM 学会利用压缩后的缓存，有效扩展上下文窗口。\n\n*   **SOLO：推动低比特优化器的极限：关注 EMA 动态 (Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics):** 为解决大型模型训练中优化器状态（如 Adam 的动量和方差）占用大量内存的问题，该研究提出 SOLO，一种能将优化器状态量化到极低精度（3 比特甚至 2 比特）的方法。通过识别并解决无符号量化中的“信号淹没”问题（通过定制对数量化）和有符号量化中梯度方差增大问题（通过精度特定的动量值），SOLO 在几乎不损失精度的情况下大幅节省内存（训练 7B 模型可省约 45GB）。\n\n*   **R&B：用于高效基础模型训练的域重组和数据混合平衡 (R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training):** 现有数据混合策略依赖预定义域且计算成本高。R&B 框架通过基于语义相似性重新划分数据（Regroup）创建更细粒度的域，并利用训练过程中域梯度的 Gram 矩阵高效优化数据组成（Balance），无需额外评估计算。理论分析和在自然语言、推理、多模态等任务上的实验表明，R&B 以极低开销（0.01%）达到或超过 SOTA 数据混合策略的性能。\n\n*   **LLM 理解：固有的歧义障碍 (Large Language Models Understanding: an Inherent Ambiguity Barrier):** 这篇简短的论文通过思想实验和半形式化论证提出，LLM 存在一个固有的“歧义障碍”，阻止它们真正理解其流畅对话的含义。这是一个关于 LLM 是否具备真正理解能力的哲学探讨。\n\n*   **触发 LLM 幻觉：提示引发大型语言模型幻觉的定量研究 (Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models):** 该研究提出了一个系统性触发和量化 LLM 幻觉的框架：使用“幻觉诱导提示”（HIP，人为融合语义遥远的概念）来引发幻觉，并用“幻觉量化提示”（HQP）来评估输出的合理性、置信度和连贯性。实验表明 HIPs 确实能诱导更多幻觉，且效果因模型而异。该框架为研究幻觉易感性提供了可复现的测试平台。\n\n*   **LLM 的一致性：当前格局、挑战与未来方向 (Consistency in Language Models: Current Landscape, Challenges, and Future Directions):** 这篇论文探讨了 AI 语言系统中的一致性问题，包括形式一致性（逻辑规则）和非形式一致性（道德、事实连贯）。分析了现有度量方法，指出了在定义标准化、多语言评估和提升一致性方法上的研究空白，强调了对稳健基准和跨学科方法的需求。\n\n*   **FineScope：使用 SAE 引导的自数据培养为领域专用 LLM 进行精确剪枝 (FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation):** 为开发小型、高效的领域专用 LLM，FineScope 提出一个框架：利用稀疏自编码器（SAE）从大数据集中提取领域特定子集；进行带领域约束的结构化剪枝；通过自数据蒸馏（使用 SAE 筛选的数据）恢复剪枝模型丢失的关键领域信息。实验表明 FineScope 能获得有竞争力的领域性能，剪枝模型通过 SAE 数据微调能恢复大部分性能。\n\n*   **AI 竞赛为 GenAI 评估提供了经验严谨性的黄金标准 (Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation):** 这篇立场文件认为，传统的 ML 评估方法不足以评估 GenAI 模型，尤其是在处理泄漏（leakage）和污染（contamination）问题上。作者指出，AI 竞赛领域为防止作弊已发展出有效措施，因此应被视为 GenAI 评估经验严谨性的黄金标准，其结果应得到充分利用。\n\n*   **结合 LLM 与基于逻辑的框架解释 MCTS (Combining LLMs with Logic-Based Framework to Explain MCTS):** 为增强对 AI 规划（如蒙特卡洛树搜索 MCTS）的信任，该研究设计了一个结合计算树逻辑（CTL）和 LLM 的自然语言解释框架。该框架能处理关于 MCTS 和 MDP 的自由形式查询，将用户查询转化为逻辑语句，确保从搜索树获取的证据与环境动态和约束事实一致。\n\n*   **LLM 能否帮助改进战略决策中的类比推理？来自人类和 GPT-4 的实验证据 (Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4):** 研究发现，在战略决策的类比推理任务中，GPT-4 召回率高（能找到所有可能的类比）但精确率低（常基于表面相似性选错），而人类精确率高但召回率低。这表明 LLM 可作为类比生成器，而人类在评估和应用深度结构相似性方面仍具优势。\n\n*   **数据治疗师：使用 LLM 从领域专家处引出领域知识 (Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models):** Data Therapist 是一个 Web 工具，通过结合 LLM 驱动的迭代问答和交互式标注，帮助领域专家（如分子生物学、会计学专家）外化其关于数据集的隐性知识（来源、质量、用途等），以辅助更好的数据可视化设计。\n\n*   **KoACD：首个用于认知扭曲分析的韩语青少年数据集 (KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis):** 针对青少年认知扭曲（可导致心理健康问题）研究缺乏大型数据集的问题，该研究构建了首个韩语青少年认知扭曲数据集 KoACD（含 10 万+ 实例）。利用多 LLM 协商方法改进分类，并生成合成数据。验证表明 LLM 在处理需上下文推理的扭曲分类上仍不如人类专家。\n\n*   **UserCentrix：面向智能空间的 Agentic 记忆增强 AI 框架 (UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces):** UserCentrix 是一个为智能空间设计的 Agentic AI 框架，集成了个性化 LLM Agent、记忆管理、混合分层控制系统、信息价值驱动决策和多 Agent 协调，旨在提供动态、上下文感知、资源高效的决策和主动适应能力。\n\n*   **LLM 驱动的联邦 Transformer 用于预测性 IoV 管理 (Open-Source LLM-Driven Federated Transformer for Predictive IoV Management):** FPoTT 框架利用开源 LLM（如 Pythia-1B）进行车联网（IoV）管理。它引入动态提示优化机制改进轨迹预测，采用双层联邦学习（边缘轻量模型+云端 LLM），并结合 Transformer 生成合成交通数据。实验表明其在真实数据上达到高预测精度。\n\n*   **LLM 驱动的物联网生态系统威胁检测与预防框架 (LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems):** 该框架使用在物联网特定数据集上微调的轻量级 LLM，进行实时异常检测和自动化的、上下文感知的缓解策略，旨在为资源受限的物联网设备提供安全保障。\n\n*   **城市空中交通（UAM）作为一个系统之系统：LLM 增强的全子（Holonic）方法 (Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach):** 提出一种结合 LLM 的智能全子架构来管理 UAM 的复杂性。Holons（如空中出租车、地面交通、垂直起降场）半自主运行，LLM 处理自然语言输入、生成自适应计划并管理干扰，实现去中心化的动态资源分配和实时重规划。\n\n*   **医疗保健领域大型语言模型的红队演练 (Red Teaming Large Language Models for Healthcare):** 报告了 MLHC 2024 会前研讨会的情况，临床和计算专家试图发现 LLM 在医疗场景中的漏洞（即可能导致临床伤害的响应）。报告了发现的漏洞类型，并进行了跨模型复现研究。\n\n**强化学习 / 机器人 / 控制**\n\n*   **Wasserstein 策略优化 (Wasserstein Policy Optimization):** 来自 DeepMind 的研究者提出了 WPO，一种用于连续动作空间的 Actor-Critic 强化学习算法。它可被推导为策略空间上 Wasserstein 梯度流的近似，结合了确定性策略梯度（利用值函数对动作的梯度）和经典策略梯度（可用于任意随机策略，无需重参数化技巧）的优点。在 DeepMind Control Suite 和磁约束聚变任务上表现出色。\n\n*   **通过可扩展城市模拟实现自主微出行 (Towards Autonomous Micromobility through Scalable Urban Simulation):** (CVPR 2025 Highlight) 为推进送货机器人、移动滑板车等微出行工具的自主性，该研究构建了 URBAN-SIM 平台，用于在交互式城市场景中大规模训练具身智能体。平台包含分层城市生成、交互式动态生成和异步场景采样模块。同时提出 URBAN-BENCH 基准，包含城市移动、导航、穿越三类核心技能的八项任务，评估了轮式和腿式机器人的能力。\n\n*   **机器人视觉指令 (Robotic Visual Instruction):** 为克服自然语言在机器人控制中空间精度不足的问题，提出 RoVI 范式，使用手绘符号（箭头、圆圈、颜色、数字的 2D 草图）来指导 3D 机器人操作。同时提出 VIEW 工作流，利用 VLM 解读 RoVI 输入，提取时空约束并转化为 3D 动作序列。构建了 15K 实例的数据集微调小型 VLM。在真实和模拟环境中验证了其在多步、有干扰、需轨迹跟踪任务上的泛化能力。\n\n*   **用于滑翔无人机控制的神经网络验证：案例研究 (Neural Network Verification for Gliding Drone Control: A Case Study):** 针对受 Alsomitra 种子启发的微型滑翔无人机，研究了使用神经网络控制器使其紧随目标轨迹的验证问题。提出了一种鲁棒回归网络训练方法，并在 Vehicle 和 CORA 工具中形式化该案例。结果表明训练方法提高了性能和鲁棒性，但现有验证工具在处理此类复杂系统时存在局限性。\n\n*   **用于离线强化学习的变分 OOD 状态修正 (Variational OOD State Correction for Offline Reinforcement Learning):** 为解决离线 RL 中的状态分布偏移问题，提出 DASP 方法进行 OOD 状态修正。该方法鼓励智能体选择导致更高数据密度状态的动作，使其保持在分布内（安全）区域。通过变分框架同时考虑决策结果及其密度进行优化。\n\n*   **通过设施选址规划实现最优在职交互式学习 (Optimal Interactive Learning on the Job via Facility Location Planning):** 提出 COIL 框架，用于多任务场景下规划机器人与用户的交互（技能、偏好、帮助查询），以最小化人类付出。当用户偏好已知时，问题被建模为无容量设施选址（UFL）问题，可用近似算法求解。当偏好未知时，结合一步信念空间规划，保持多项式时间性能。\n\n*   **MULE：用于有效四足运动的多地形和未知负载适应 (MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion):** 提出一个自适应强化学习框架，使四足机器人能动态适应变化的负载和多样的地形。框架包含一个基础运动策略和一个学习纠正动作以在负载变化下保持稳定性和命令跟踪的自适应策略。在模拟和真实 Go1 机器人上验证了其在平地、斜坡、楼梯以及静态/动态负载变化下的鲁棒性和适应性。\n\n*   **面向领域泛化策略：关于验证实例和扩展行为 (Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior):** 研究了学习能够从小型训练实例扩展到大型测试实例的每个领域泛化动作策略。提出动态生成验证集的方法，根据需要增加实例大小。同时改进了评估扩展行为的方法。实验表明动态验证改进了 GNN 策略在 9 个领域中的扩展行为。\n\n*   **用于确定性 POMDP 的基于有限状态控制器的离线求解器 (A Finite-State Controller Based Offline Solver for Deterministic POMDPs):** 针对状态不确定但动作和观察确定的规划问题（DetPOMDPs），提出 DetMCVI 算法，是蒙特卡洛值迭代（MCVI）的改编版，构建有限状态控制器（FSC）形式的策略。该算法在大型问题上表现优于现有基线，并在真实移动机器人森林地图绘制场景中验证。\n\n**计算机视觉 / 图形学 / 多模态**\n\n*   **Pixel3DMM：用于单图像 3D 人脸重建的通用屏幕空间先验 (Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction):** 提出 Pixel3DMM，利用 Vision Transformer（基于 DINO 特征）预测逐像素的几何线索（表面法线和 UV 坐标），以约束 3D 可变形人脸模型（3DMM）的优化。使用三个高质量 3D 人脸数据集（超 1000 身份，97 万图像）训练。提出新的单图像人脸重建基准，评估姿态和中性表情下的几何精度。该方法在姿态表情的几何精度上优于 SOTA 基线 15% 以上。\n\n*   **用于 GUI Agent 接地的视觉测试时缩放 (Visual Test-time Scaling for GUI Agent Grounding):** 提出 RegionFocus，一种用于 VLM Agent 的视觉测试时缩放方法。为解决 GUI 图像复杂性和元素众多导致的动作选择困难，该方法动态放大相关区域，减少背景干扰，提高接地精度。结合“图像即地图”机制可视化关键地标。在 ScreenSpot-pro 和 WebVoyager 基准上，该方法显著提升了 UI-TARS 和 Qwen2.5-VL 两个 SOTA VLM Agent 的性能，并在 ScreenSpot-Pro 上达到新的 SOTA。\n\n*   **ScaleTrack：缩放与回溯自动化 GUI Agent (ScaleTrack: Scaling and back-tracking Automated GUI Agents):** 为解决 GUI Agent 训练中接地数据不足和规划忽略回溯行为的问题，提出 ScaleTrack 框架。通过收集和统一多种来源的 GUI 样本扩大接地训练数据；设计新的训练策略，不仅从当前 GUI 预测下一动作，还回溯导致当前 GUI 的历史动作，以学习 GUI 环境的演化规则。\n\n*   **T2VPhysBench：用于文本到视频生成中物理一致性的第一性原理基准 (T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation):** 现有 T2V 模型生成的视频在美观和指令遵循上表现不错，但物理真实性常被忽略。该研究提出 T2VPhysBench，一个基于第一性原理的基准，通过严格的人工评估协议，系统评估 SOTA T2V 模型是否遵循 12 项核心物理定律（牛顿力学、守恒定律等）。结果显示所有模型在各类定律上平均得分低于 0.60，即使有提示也难以纠正违规，且模型常能生成明确违反物理规则的视频。\n\n*   **JointDiT：用 Diffusion Transformer 增强 RGB-Depth 联合建模 (JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers):** 提出 JointDiT，一个 Diffusion Transformer 模型，用于联合建模 RGB 和 Depth 分布。利用自适应调度权重和非平衡时间步采样策略，模型能生成高保真图像和几何准确的深度图。通过控制各分支的时间步，可自然处理联合生成、深度估计、深度条件图像生成等多种任务。\n\n*   **具有时序相干调制的 高效神经视频表示 (Efficient Neural Video Representation with Temporally Coherent Modulation):** 为加速隐式神经表示（INR）在视频上的应用，提出 NVTM 框架。它将时空 3D 视频数据分解为带光流信息的 2D 网格集，实现快速学习和参数高效。NVTM 能同时处理时序对应的像素，编码速度比 NeRV 类方法快 3 倍以上，并在 PSNR/LPIPS 上优于之前的网格类方法。在压缩、超分、插帧、修复等任务上也表现出色。\n\n*   **用于 3D MRI 脑肿瘤分析（含模态缺失）的多模态掩码自编码器预训练 (Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities):** 提出 BM-MAE，一种为多模态 MRI 数据设计的掩码图像建模预训练策略。预训练后的同一模型能无缝适应任何可用的模态组合进行微调，无需改变架构，同时受益于在全模态集上的预训练。实验表明其性能优于或持平于为每个模态子集单独预训练的基线，并能快速重建缺失模态。\n\n*   **用于高度加速实时动态 MRI 的深度学习辅助外体积去除 (Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI):** 为解决实时（RT）动态 MRI（如心脏电影成像）在高加速率下因心脏外组织产生的混叠伪影，提出一种后处理 OVR 方法。利用时间交错欠采样模式下的复合时间图像估计外体积信号，训练 DL 模型识别并去除伪影，得到干净的外体积估计，从 k 空间数据中减去。最终使用带 OVR 特定损失函数的物理驱动 DL 方法重建。\n\n*   **用于气体泄漏分割的细粒度时空感知 (Fine-grained spatial-temporal perception for gas leak segmentation):** 提出 FGSTP 算法用于气体泄漏分割。通过构建相关性体积捕捉帧间运动线索，并结合先前输出逐步细化对象级特征，最后用解码器优化边界。由于缺乏精确标注数据，作者手动标注了一个气体泄漏视频数据集 GasVid。实验表明该模型在分割气体等非刚性物体方面优于 SOTA。\n\n*   **用 VLM 赋能 Agentic 视频分析系统 (Empowering Agentic Video Analytics Systems with Video Language Models):** 为实现开放式视频分析，提出 AVA 系统。利用 VLM，通过近实时构建事件知识图（EKG）索引长视频流，并设计 Agentic 检索-生成机制处理复杂查询。在 LVBench、VideoMME-Long 和新提出的超长视频基准 AVA-100 上均取得 SOTA 或顶级性能。\n\n**其他 AI/ML 应用与方法**\n\n*   **Wasserstein 策略优化 (WPO):** (见 RL 部分)\n\n*   **用于城市空气质量管理的深度强化学习：大都市环境中污染缓解站点布局的多目标优化 (Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments):** 使用 PPO 算法优化德里市空气净化站的布局，以改善空气质量指数（AQI）。基于人口密度、交通模式、工业影响等因素学习高影响位置。与随机和贪婪策略相比，RL 方法在 AQI 改善、空间覆盖、人口/交通影响和空间熵等多个指标上实现了更好的平衡和效果。\n\n*   **OmicsCL：用于癌症亚型发现和生存分层的无监督对比学习 (OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification):** 提出 OmicsCL，一个模块化对比学习框架，将基因表达、DNA 甲基化、miRNA 表达等异构组学数据嵌入统一的潜在空间。包含一个生存感知对比损失，鼓励模型学习与生存相关的模式（无需标签）。在 TCGA BRCA 数据集上发现了临床上有意义的簇，并与患者生存具有良好的无监督一致性。\n\n*   **通过离群点去除实现快速低成本的基因组基础模型 (Fast and Low-Cost Genomic Foundation Models via Outlier Removal):** (注意：摘要内容似乎与标题不符，摘要描述的是一个名为 GERM 的基因组基础模型（GFM）对抗攻击基准，评估了 5 种 SOTA GFM 对 4 种攻击和 3 种防御策略的鲁棒性。发现 Transformer 模型更鲁棒，攻击常针对生物学重要区域。) *假设标题是准确的，那么论文可能提出了一种通过去除离群数据来加速 GFM 训练或降低成本的方法。*\n\n*   **测试时相关性对齐 (Test-time Correlation Alignment):** 为解决测试时适应（TTA）中仅关注实例对齐、忽略相关性对齐（CORAL）以及计算开销大的问题，提出 TCA。理论分析表明对齐高置信度实例和测试实例间的相关性可提升性能。提出 LinearTCA（线性变换实现实例和相关性对齐）和 LinearTCA+（即插即用模块）。实验证明 TCA 方法显著优于基线，且计算开销极低。\n\n*   **安全关键交通模拟与引导潜在扩散模型 (Safety-Critical Traffic Simulation with Guided Latent Diffusion Model):** 为生成真实且对抗性的安全关键交通场景以评估自动驾驶系统，提出引导 LDM。使用基于图的 VAE 学习紧凑潜空间，LDM 在此空间生成轨迹。引入新的引导目标驱动生成对抗性且行为真实的驾驶行为，并用物理可行性检查筛选样本。在 nuScenes 数据集上验证了其对抗有效性、生成效率和真实性。\n\n*   **HalluMix：用于真实世界幻觉检测的任务无关、多领域基准 (HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection):** 针对现有幻觉检测基准多为合成、局限于抽取式问答的问题，提出 HalluMix，一个包含来自多领域、多格式真实场景（涉及多文档上下文和完整句子输出）的幻觉检测基准。评估了 7 个检测系统，发现长短上下文性能差异显著，Quotient Detections 表现最佳。\n\n*   **基于规则的分类器模型 (Rule-based Classifier Models):** 扩展了法律领域中使用的分类器模型形式框架。现有框架仅通过事实描述案例，而法律推理依赖事实和规则（尤其是判决理由）。本文初步尝试将规则集纳入分类器，并展示了如何使用这个丰富的框架推断新案例的判决，还考虑了时间因素和法院层级。\n\n*   **每域泛化策略：关于验证实例和扩展行为 (Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior):** (见 RL 部分)\n\n*   **病理语音自动匿名化的感知影响 (Perceptual Implications of Automatic Anonymization in Pathological Speech):** 首次对匿名化后的病理语音（唇腭裂、构音障碍等）进行全面的以人为中心的感知评估。结果显示，听者能较好地区分匿名化前后的语音，匿名化普遍降低了感知质量，且效果因病症而异。关键在于，人类感知结果与自动隐私或临床效用指标不相关，强调需要针对特定障碍和场景制定保留可解释性和诊断效用的匿名化策略。\n\n*   **DeepSTA：异常条件下物流配送准时率预测的时空注意力网络 (DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions):** 为预测快递员在疫情等异常条件下的配送准时率，提出 DeepSTA 模型。设计异常时空学习模块（用 RNN 建模事件信息），利用 Node2vec 和 GNN/LSTM 捕捉时空依赖。为解决异常数据不足问题，提出异常模式注意力模块（用记忆网络存储异常特征模式）。在真实物流数据上表现优于基线。\n\n*   **学习估计混合不平衡配送和取件物流服务中的包裹送达时间 (Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services):** 针对快递员同时处理大量配送和少量（但时效要求更严）取件的混合场景，提出 TransPDT 模型（基于 Transformer 的多任务模型）预测包裹送达时间。利用 Transformer 编码器捕捉时空依赖，设计模式记忆网络学习不平衡数据中取件模式的影响，并将路线预测作为辅助任务。\n\n*   **TNStream：基于紧邻微簇的多密度流数据聚类 (TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data):** 针对流数据聚类中处理任意形状、多密度、高维数据和抗噪声的挑战，本文提出了基于“最紧邻居”（Tightest Neighbors）概念和骨架集（Skeleton Set）理论的数据流聚类方法 TNStream。该方法在线运行，根据局部相似性自适应确定聚类半径，在微簇中总结数据流演化，并利用 LSH 处理高维数据，实验证明其在多密度数据上表现优越。\n\n*   **利用安全引导自压缩优化深度神经网络 (Optimizing Deep Neural Networks using Safety-Guided Self Compression):** 提出一种安全驱动的量化框架，利用“保留集”（preservation sets）系统地剪枝和量化网络权重，以在减小模型大小和保持性能间取得平衡。在 CNN 和 Transformer 模型上评估，结果显示能在保持 60% 模型大小的同时，测试精度比原始模型提升高达 2.5%。\n\n*   **Pack-PTQ：通过 Pack-wise 重建推进神经网络的训练后量化 (Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction):** 现有 PTQ 方法多采用块级（block-wise）重建，忽略块间依赖。Pack-PTQ 提出基于 Hessian 引导的自适应打包机制，将块划分为包（pack），以包为单位进行重建，保留块间依赖。并提出混合精度量化方法，根据包的敏感度分配不同位宽。在图像和点云分类任务上优于 SOTA PTQ 方法。\n\n*   **CognitionNet：用于在线技能游戏平台玩法风格发现的协作神经网络 (CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform):** 为从在线拉米（Rummy）游戏数据中发现玩家的“游戏行为”（微观模式）和“玩法风格”（宏观模式），提出两阶段 DNN 模型 CognitionNet。第一阶段挖掘游戏行为（聚类表示），第二阶段聚合这些模式以发现玩法风格（通过玩家参与度的监督分类）。双目标和新颖的“桥接损失”实现了两个网络的协作训练，揭示了受玩家心理启发的决策和策略。\n\n*   **AI2-Active Safety：考虑车辆动力学的 AI 赋能交互感知主动安全分析 (AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics):** 提出一个考虑群体车辆交互的主动安全分析框架。结合考虑坡度的自行车模型（车辆动力学）和基于超图的 AI 模型（预测周围交通概率轨迹），推导 3D 路面上车辆间距的随机微分方程解，得到高保真 TTC 等代理安全度量。\n\n*   **使用 U-Net 架构将 Cellular-Potts Agent-Based 模型建模为分割任务的代理模型 (Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture):** 为加速计算成本高的 Cellular-Potts 模型（CPM，用于模拟复杂多细胞生物系统）仿真，开发了基于 U-Net 的 CNN 代理模型。该模型能预测 100 个计算步长，将体外血管生成 CPM 的评估速度提高了 590 倍，并能有效捕捉原始模型的涌现行为（如血管萌发、延伸、吻合）。\n\n*   **AI 辅助决策用于临床评估自动分割轮廓质量 (AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality):** 提出基于深度学习的质量评估（QA）方法，用于评估放疗（尤其是在线自适应放疗 OART）中的自动分割轮廓。利用贝叶斯序数分类（BOC）和校准的不确定性阈值，模型能在无需金标准或大量手动标签的情况下，自信地预测轮廓质量等级，减少不必要的人工检查。\n\n*   **分子气味预测中由特征贡献驱动的多层次细粒度特征映射 (Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction):** 为解决分子气味预测中特征表达力不足和类别不平衡问题，提出 HMFNet。包含：局部多层次特征提取（LMFE）模块进行原子级细粒度特征提取；谐波调制特征映射（HMFM）模块学习特征重要性和频率调制；全局多层次特征提取（GMFE）模块学习分子图拓扑的全局特征；化学知识引导损失（CIL）缓解类别不平衡。\n\n*   **DeCo：具有对比匹配的缺陷感知建模用于优化在线 IC 测试中的任务分配 (DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing):** 为优化 IC 测试中的任务分配（将任务分配给合适的工程师），提出 DeCo 方法。构建缺陷感知图捕捉共失效关系；为工程师和任务构建缺陷感知表示；使用基于对比的分配机制，考虑技能水平和工作负载进行匹配。实验表明 DeCo 能提高任务处理成功率并平衡负载。\n\n*   **利用纵向表格 Transformer 预测电力中断的预计恢复时间 (Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers):** 为提高自然灾害期间电力中断预计恢复时间（ETR）的准确性，提出纵向表格 Transformer（LTT）模型。利用历史中断事件数据和事件的顺序更新信息进行预测。在三家电力公司的数据上评估，LTT 模型显著改善了客户满意度影响（CSI）指标，并使用可解释性技术分析了模型。\n\n*   **扩展设备端 GPU 推理用于大型生成模型 (Scaling On-Device GPU Inference for Large Generative Models):** 为在移动和桌面 GPU 上运行比现有模型大 10-100 倍的生成模型（图像、音频、语音），提出 ML Drift 框架。它优化并扩展了现有 GPU 加速推理引擎，解决了跨 GPU API 开发等工程挑战，实现了比开源 GPU 推理引擎数量级的性能提升。\n\n*   **利用来自 5G 无线网络的数据分析机器学习回归模型对对抗攻击的脆弱性 (Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks):** 使用 DeepMIMO 模拟器数据，通过 FGSM 对抗攻击评估了回归模型的脆弱性。发现攻击使 MSE 增加 33%，R2 降低 10%。LightGBM 分类器能以 98% 的准确率识别被攻击数据。\n\n*   **合成和识别自动驾驶车辆摄像头雷达数据集中的噪声水平 (Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets):** 为提高自动驾驶目标检测与跟踪对传感器故障的鲁棒性，创建了一个逼真的摄像头-雷达数据增强流程，模拟传感器故障和干扰。并训练了一个轻量级噪声识别网络，在增强数据集上达到 54.4% 的识别准确率。\n\n*   **语音克隆：综合综述 (Voice Cloning: Comprehensive Survey):** 对语音克隆领域进行了全面综述，建立了标准化术语，探讨了不同变体（说话人自适应、少样本、零样本、多语言 TTS），并介绍了常用的评估指标和相关数据集。\n\n*   **增强 AI 驱动的教育：整合认知框架、语言反馈分析和伦理考量以改进内容生成 (Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation):** 综合四项研究，提出一个增强 AI 教育工具的框架。整合认知评估（布鲁姆、SOLO 分类法）、AI 生成反馈的语言分析和伦理原则，指导开发有效、负责任的 AI 工具，并在 Moodle 插件 OneClickQuiz 中应用。\n\n*   **量子神经网络实现量子优化的学会学习 (Learning to Learn with Quantum Optimization via Quantum Neural Networks):** 提出一个量子元学习框架，将量子神经网络（特别是 QLSTM）与量子近似优化算法（QAOA）结合。通过在小图实例上训练 QLSTM 优化器，使其能快速泛化到更大更复杂的问题，减少收敛所需迭代次数。在 Max-Cut 和 SK 模型上验证了其有效性。\n\n*   **生物统计学中因果关系神经网络的机制可解释性 (On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics):** 探讨了将机制可解释性（MI）技术应用于生物统计学因果推断中的神经网络。展示了 MI 工具可用于验证 NN 内部表示（如 TMLE 中的 nuisance 函数估计）、发现网络处理不同输入的计算路径（区分混杂因素和处理）、以及比较不同模型（统计、ML、NN）的学习机制。",
  "papers": [
    {
      "arxiv_id": "2505.00703v1",
      "title": "T2I-R1: Reinforcing Image Generation with Collaborative Semantic-level and Token-level CoT",
      "title_zh": "T2I-R1：通过协作式语义级别和 Token 级别 CoT 强化图像生成\n",
      "authors": [
        "Dongzhi Jiang",
        "Ziyu Guo",
        "Renrui Zhang",
        "Zhuofan Zong",
        "Hao Li",
        "Le Zhuo",
        "Shilin Yan",
        "Pheng-Ann Heng",
        "Hongsheng Li"
      ],
      "abstract": "Recent advancements in large language models have demonstrated how\nchain-of-thought (CoT) and reinforcement learning (RL) can improve performance.\nHowever, applying such reasoning strategies to the visual generation domain\nremains largely unexplored. In this paper, we present T2I-R1, a novel\nreasoning-enhanced text-to-image generation model, powered by RL with a\nbi-level CoT reasoning process. Specifically, we identify two levels of CoT\nthat can be utilized to enhance different stages of generation: (1) the\nsemantic-level CoT for high-level planning of the prompt and (2) the\ntoken-level CoT for low-level pixel processing during patch-by-patch\ngeneration. To better coordinate these two levels of CoT, we introduce\nBiCoT-GRPO with an ensemble of generation rewards, which seamlessly optimizes\nboth generation CoTs within the same training step. By applying our reasoning\nstrategies to the baseline model, Janus-Pro, we achieve superior performance\nwith 13% improvement on T2I-CompBench and 19% improvement on the WISE\nbenchmark, even surpassing the state-of-the-art model FLUX.1. Code is available\nat: https://github.com/CaraJ7/T2I-R1",
      "tldr_zh": "该论文提出了T2I-R1，一种基于强化学习(RL)和双层链式思维(CoT)的文本到图像生成模型，旨在提升图像生成质量。T2I-R1引入了语义层面的CoT用于prompt的高级规划，以及token层面的CoT用于patch-by-patch生成过程中的低级像素处理。为了协调这两个层面的CoT，论文提出了BiCoT-GRPO，一种包含生成奖励集合的算法，能够在同一训练步骤中优化两个层面的CoT。实验结果表明，T2I-R1在T2I-CompBench和WISE基准测试中分别取得了13%和19%的性能提升，甚至超越了当前最优模型FLUX.1。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://github.com/CaraJ7/T2I-R1",
      "pdf_url": "http://arxiv.org/pdf/2505.00703v1",
      "published_date": "2025-05-01 17:59:46 UTC",
      "updated_date": "2025-05-01 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:11:04.344018"
    },
    {
      "arxiv_id": "2505.00693v1",
      "title": "Robotic Visual Instruction",
      "title_zh": "机器人视觉指令\n",
      "authors": [
        "Yanbang Li",
        "Ziyang Gong",
        "Haoyang Li",
        "Haoyang Li",
        "Xiaoqi Huang",
        "Haolan Kang",
        "Guangping Bai",
        "Xianzheng Ma"
      ],
      "abstract": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision for robotic\ncontrol introduces challenges such as ambiguity and verbosity. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment, enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Code and\nDatasets in this paper will be released soon.",
      "tldr_zh": "该论文提出了Robotic Visual Instruction (RoVI)，一种新颖的机器人引导范式，通过以物体为中心的手绘符号表示来指导机器人任务，克服了自然语言在机器人控制中缺乏空间精确性的问题。RoVI利用箭头、圆形、颜色和数字等2D草图将时空信息编码成人类可理解的视觉指令，用于指导3D机器人操作。为了使机器人更好地理解RoVI并生成精确的动作，论文提出了Visual Instruction Embodied Workflow (VIEW)，一个为RoVI条件策略设计的流程，利用视觉语言模型(VLMs)解释RoVI输入，从2D像素空间解码时空约束，并将其转换为可执行的3D动作序列。论文还创建了一个包含15K实例的专门数据集，用于微调小型VLM，使其能够有效地学习RoVI能力。VIEW在真实和模拟环境中的11项新任务中得到了验证，在涉及多步骤动作、干扰和轨迹跟踪的真实场景中，VIEW的成功率达到了87.5%。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00693v1",
      "published_date": "2025-05-01 17:55:05 UTC",
      "updated_date": "2025-05-01 17:55:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:11:16.596690"
    },
    {
      "arxiv_id": "2505.00690v1",
      "title": "Towards Autonomous Micromobility through Scalable Urban Simulation",
      "title_zh": "基于可扩展城市模拟的自主微移动性研究\n",
      "authors": [
        "Wayne Wu",
        "Honglin He",
        "Chaoyuan Zhang",
        "Jack He",
        "Seth Z. Zhao",
        "Ran Gong",
        "Quanyi Li",
        "Bolei Zhou"
      ],
      "abstract": "Micromobility, which utilizes lightweight mobile machines moving in urban\npublic spaces, such as delivery robots and mobility scooters, emerges as a\npromising alternative to vehicular mobility. Current micromobility depends\nmostly on human manual operation (in-person or remote control), which raises\nsafety and efficiency concerns when navigating busy urban environments full of\nunpredictable obstacles and pedestrians. Assisting humans with AI agents in\nmaneuvering micromobility devices presents a viable solution for enhancing\nsafety and efficiency. In this work, we present a scalable urban simulation\nsolution to advance autonomous micromobility. First, we build URBAN-SIM - a\nhigh-performance robot learning platform for large-scale training of embodied\nagents in interactive urban scenes. URBAN-SIM contains three critical modules:\nHierarchical Urban Generation pipeline, Interactive Dynamics Generation\nstrategy, and Asynchronous Scene Sampling scheme, to improve the diversity,\nrealism, and efficiency of robot learning in simulation. Then, we propose\nURBAN-BENCH - a suite of essential tasks and benchmarks to gauge various\ncapabilities of the AI agents in achieving autonomous micromobility.\nURBAN-BENCH includes eight tasks based on three core skills of the agents:\nUrban Locomotion, Urban Navigation, and Urban Traverse. We evaluate four robots\nwith heterogeneous embodiments, such as the wheeled and legged robots, across\nthese tasks. Experiments on diverse terrains and urban structures reveal each\nrobot's strengths and limitations.",
      "tldr_zh": "该论文提出了一个可扩展的城市仿真解决方案，旨在推动自主微出行的发展。作者构建了URBAN-SIM，一个高性能的机器人学习平台，用于在交互式城市场景中大规模训练具身智能体。URBAN-SIM包含分层城市生成流程、交互式动态生成策略和异步场景采样方案，以提高模拟环境中机器人学习的多样性、真实性和效率。此外，作者还提出了URBAN-BENCH，一套用于评估AI智能体在实现自主微出行方面各种能力的任务和基准。通过在不同地形和城市结构上评估四种具有不同形态的机器人，实验揭示了每种机器人的优势和局限性。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 Highlight. Project page:\n  https://metadriverse.github.io/urban-sim/",
      "pdf_url": "http://arxiv.org/pdf/2505.00690v1",
      "published_date": "2025-05-01 17:52:29 UTC",
      "updated_date": "2025-05-01 17:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:11:28.235726"
    },
    {
      "arxiv_id": "2505.00684v1",
      "title": "Visual Test-time Scaling for GUI Agent Grounding",
      "title_zh": "用于 GUI 代理接地的视觉测试时缩放",
      "authors": [
        "Tiange Luo",
        "Lajanugen Logeswaran",
        "Justin Johnson",
        "Honglak Lee"
      ],
      "abstract": "We introduce RegionFocus, a visual test-time scaling approach for Vision\nLanguage Model Agents. Understanding webpages is challenging due to the visual\ncomplexity of GUI images and the large number of interface elements, making\naccurate action selection difficult. Our approach dynamically zooms in on\nrelevant regions, reducing background clutter and improving grounding accuracy.\nTo support this process, we propose an image-as-map mechanism that visualizes\nkey landmarks at each step, providing a transparent action record and enables\nthe agent to effectively choose among action candidates. Even with a simple\nregion selection strategy, we observe significant performance gains of 28+\\% on\nScreenspot-pro and 24+\\% on WebVoyager benchmarks on top of two\nstate-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL,\nhighlighting the effectiveness of visual test-time scaling in interactive\nsettings. We achieve a new state-of-the-art grounding performance of 61.6\\% on\nthe ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model.\nOur code will be released publicly at https://github.com/tiangeluo/RegionFocus.",
      "tldr_zh": "该论文提出了一种名为RegionFocus的视觉测试时缩放方法，用于提升视觉语言模型智能体在GUI环境中的定位能力。RegionFocus通过动态聚焦相关区域，减少背景干扰，从而提高动作选择的准确性。此外，论文还引入了一种“图像即地图”机制，可视化关键地标，提供透明的动作记录，帮助智能体有效选择动作。实验结果表明，在Screenspot-pro和WebVoyager基准测试中，RegionFocus在UI-TARS和Qwen2.5-VL等先进模型的基础上，分别实现了28%和24%以上的性能提升。通过将RegionFocus应用于Qwen2.5-VL-72B模型，在ScreenSpot-Pro基准测试中实现了61.6%的最新性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00684v1",
      "published_date": "2025-05-01 17:45:59 UTC",
      "updated_date": "2025-05-01 17:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:11:40.392483"
    },
    {
      "arxiv_id": "2505.00668v1",
      "title": "Deep Reinforcement Learning for Urban Air Quality Management: Multi-Objective Optimization of Pollution Mitigation Booth Placement in Metropolitan Environments",
      "title_zh": "用于城市空气质量管理的深度强化学习：大都市环境中污染缓解设施选址的多目标优化\n",
      "authors": [
        "Kirtan Rajesh",
        "Suvidha Rupesh Kumar"
      ],
      "abstract": "Urban air pollution remains a pressing global concern, particularly in\ndensely populated and traffic-intensive metropolitan areas like Delhi, where\nexposure to harmful pollutants severely impacts public health. Delhi, being one\nof the most polluted cities globally, experiences chronic air quality issues\ndue to vehicular emissions, industrial activities, and construction dust, which\nexacerbate its already fragile atmospheric conditions. Traditional pollution\nmitigation strategies, such as static air purifying installations, often fail\nto maximize their impact due to suboptimal placement and limited adaptability\nto dynamic urban environments. This study presents a novel deep reinforcement\nlearning (DRL) framework to optimize the placement of air purification booths\nto improve the air quality index (AQI) in the city of Delhi. We employ Proximal\nPolicy Optimization (PPO), a state-of-the-art reinforcement learning algorithm,\nto iteratively learn and identify high-impact locations based on multiple\nspatial and environmental factors, including population density, traffic\npatterns, industrial influence, and green space constraints. Our approach is\nbenchmarked against conventional placement strategies, including random and\ngreedy AQI-based methods, using multi-dimensional performance evaluation\nmetrics such as AQI improvement, spatial coverage, population and traffic\nimpact, and spatial entropy. Experimental results demonstrate that the RL-based\napproach outperforms baseline methods by achieving a balanced and effective\ndistribution of air purification infrastructure. Notably, the DRL framework\nachieves an optimal trade-off between AQI reduction and high-coverage\ndeployment, ensuring equitable environmental benefits across urban regions. The\nfindings underscore the potential of AI-driven spatial optimization in\nadvancing smart city initiatives and data-driven urban air quality management.",
      "tldr_zh": "该研究提出了一种基于深度强化学习(DRL)的框架，用于优化城市空气质量管理，特别是针对德里等人口稠密、交通拥堵的城市中空气净化站的选址问题。该框架采用Proximal Policy Optimization (PPO)算法，通过考虑人口密度、交通模式、工业影响和绿地约束等多重因素，迭代学习并确定高影响力地点。实验结果表明，与传统的随机和贪婪AQI方法相比，该基于RL的方法在AQI改善、空间覆盖、人口和交通影响以及空间熵等多个维度上表现更优，实现了AQI降低和高覆盖部署之间的最佳平衡，证明了AI驱动的空间优化在改善城市空气质量管理方面的潜力。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00668v1",
      "published_date": "2025-05-01 17:19:48 UTC",
      "updated_date": "2025-05-01 17:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:11:52.397446"
    },
    {
      "arxiv_id": "2505.00663v1",
      "title": "Wasserstein Policy Optimization",
      "title_zh": "Wasserstein策略优化\n",
      "authors": [
        "David Pfau",
        "Ian Davies",
        "Diana Borsa",
        "Joao G. M. Araujo",
        "Brendan Tracey",
        "Hado van Hasselt"
      ],
      "abstract": "We introduce Wasserstein Policy Optimization (WPO), an actor-critic algorithm\nfor reinforcement learning in continuous action spaces. WPO can be derived as\nan approximation to Wasserstein gradient flow over the space of all policies\nprojected into a finite-dimensional parameter space (e.g., the weights of a\nneural network), leading to a simple and completely general closed-form update.\nThe resulting algorithm combines many properties of deterministic and classic\npolicy gradient methods. Like deterministic policy gradients, it exploits\nknowledge of the gradient of the action-value function with respect to the\naction. Like classic policy gradients, it can be applied to stochastic policies\nwith arbitrary distributions over actions -- without using the\nreparameterization trick. We show results on the DeepMind Control Suite and a\nmagnetic confinement fusion task which compare favorably with state-of-the-art\ncontinuous control methods.",
      "tldr_zh": "本文提出了一种名为Wasserstein Policy Optimization (WPO)的actor-critic算法，用于连续动作空间的强化学习。WPO源于对策略空间上的Wasserstein梯度流的近似，并投影到有限维参数空间，从而得到一个简单且通用的闭式更新公式。该算法结合了确定性策略梯度和经典策略梯度方法的优点，既能利用动作值函数关于动作的梯度信息，又能应用于具有任意动作分布的随机策略，而无需重参数化技巧。在DeepMind Control Suite和磁约束聚变任务上的实验结果表明，WPO的性能优于目前最先进的连续控制方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00663v1",
      "published_date": "2025-05-01 17:07:01 UTC",
      "updated_date": "2025-05-01 17:07:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:12:04.141481"
    },
    {
      "arxiv_id": "2505.00662v1",
      "title": "DeepCritic: Deliberate Critique with Large Language Models",
      "title_zh": "DeepCritic：使用大型语言模型进行审慎评论\n",
      "authors": [
        "Wenkai Yang",
        "Jingwen Chen",
        "Yankai Lin",
        "Ji-Rong Wen"
      ],
      "abstract": "As Large Language Models (LLMs) are rapidly evolving, providing accurate\nfeedback and scalable oversight on their outputs becomes an urgent and critical\nproblem. Leveraging LLMs as critique models to achieve automated supervision is\na promising solution. In this work, we focus on studying and enhancing the math\ncritique ability of LLMs. Current LLM critics provide critiques that are too\nshallow and superficial on each step, leading to low judgment accuracy and\nstruggling to offer sufficient feedback for the LLM generator to correct\nmistakes. To tackle this issue, we propose a novel and effective two-stage\nframework to develop LLM critics that are capable of deliberately critiquing on\neach reasoning step of math solutions. In the first stage, we utilize\nQwen2.5-72B-Instruct to generate 4.5K long-form critiques as seed data for\nsupervised fine-tuning. Each seed critique consists of deliberate step-wise\ncritiques that includes multi-perspective verifications as well as in-depth\ncritiques of initial critiques for each reasoning step. Then, we perform\nreinforcement learning on the fine-tuned model with either existing\nhuman-labeled data from PRM800K or our automatically annotated data obtained\nvia Monte Carlo sampling-based correctness estimation, to further incentivize\nits critique ability. Our developed critique model built on Qwen2.5-7B-Instruct\nnot only significantly outperforms existing LLM critics (including the\nsame-sized DeepSeek-R1-distill models and GPT-4o) on various error\nidentification benchmarks, but also more effectively helps the LLM generator\nrefine erroneous steps through more detailed feedback.",
      "tldr_zh": "该论文提出DeepCritic，一个两阶段框架，旨在提升大型语言模型(LLMs)在数学问题批判方面的能力。第一阶段，利用Qwen2.5-72B-Instruct生成包含多角度验证和深度批判的4.5K长篇批判数据，用于监督微调。第二阶段，通过强化学习，使用PRM800K人工标注数据或基于蒙特卡洛抽样的自动标注数据，进一步提升模型的批判能力。实验结果表明，基于Qwen2.5-7B-Instruct构建的DeepCritic模型在错误识别方面显著优于现有LLM批判模型（包括同等规模的DeepSeek-R1-distill模型和GPT-4o），并且能通过更详细的反馈更有效地帮助LLM生成器改进错误步骤。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Data and models are available at\n  https://github.com/RUCBM/DeepCritic",
      "pdf_url": "http://arxiv.org/pdf/2505.00662v1",
      "published_date": "2025-05-01 17:03:17 UTC",
      "updated_date": "2025-05-01 17:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:12:16.559711"
    },
    {
      "arxiv_id": "2505.00661v1",
      "title": "On the generalization of language models from in-context learning and finetuning: a controlled study",
      "title_zh": "关于语言模型从上下文学习和微调中泛化的研究：一项受控研究\n",
      "authors": [
        "Andrew K. Lampinen",
        "Arslan Chaudhry",
        "Stephanie C. Y. Chan",
        "Cody Wild",
        "Diane Wan",
        "Alex Ku",
        "Jörg Bornschein",
        "Razvan Pascanu",
        "Murray Shanahan",
        "James L. McClelland"
      ],
      "abstract": "Large language models exhibit exciting capabilities, yet can show\nsurprisingly narrow generalization from finetuning -- from failing to\ngeneralize to simple reversals of relations they are trained on, to missing\nlogical deductions that can be made from trained information. These failures to\ngeneralize from fine-tuning can hinder practical application of these models.\nHowever, language models' in-context learning shows different inductive biases,\nand can generalize better in some of these cases. Here, we explore these\ndifferences in generalization between in-context- and fine-tuning-based\nlearning. To do so, we constructed several novel datasets to evaluate and\nimprove models' ability to generalize from finetuning data. The datasets are\nconstructed to isolate the knowledge in the dataset from that in pretraining,\nto create clean tests of generalization. We expose pretrained large models to\ncontrolled subsets of the information in these datasets -- either in context,\nor through fine-tuning -- and evaluate their performance on test sets that\nrequire various types of generalization. We find overall that in data-matched\nsettings, in-context learning can generalize more flexibly than fine-tuning\n(though we also find some qualifications of prior findings, such as cases when\nfine-tuning can generalize to reversals embedded in a larger structure of\nknowledge). We build on these findings to propose a method to enable improved\ngeneralization from fine-tuning: adding in-context inferences to finetuning\ndata. We show that this method improves generalization across various splits of\nour datasets and other benchmarks. Our results have implications for\nunderstanding the inductive biases of different modes of learning in language\nmodels, and practically improving their performance.",
      "tldr_zh": "本文研究了大型语言模型(LLMs)在上下文学习(in-context learning)和微调(finetuning)中的泛化能力差异。作者构建了多个数据集，旨在隔离数据集知识与预训练知识，从而对泛化能力进行清晰的测试。研究发现，在数据匹配的设置下，上下文学习比微调能更灵活地泛化。此外，论文提出了一种通过在微调数据中加入上下文推理来提高微调泛化能力的方法，并在多个数据集和基准测试中验证了其有效性。该研究对理解语言模型不同学习模式的归纳偏置以及实际提升其性能具有重要意义。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00661v1",
      "published_date": "2025-05-01 17:02:27 UTC",
      "updated_date": "2025-05-01 17:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:12:28.290282"
    },
    {
      "arxiv_id": "2505.00654v1",
      "title": "Large Language Models Understanding: an Inherent Ambiguity Barrier",
      "title_zh": "大型语言模型理解：一个固有的歧义壁垒\n",
      "authors": [
        "Daniel N. Nissani"
      ],
      "abstract": "A lively ongoing debate is taking place, since the extraordinary emergence of\nLarge Language Models (LLMs) with regards to their capability to understand the\nworld and capture the meaning of the dialogues in which they are involved.\nArguments and counter-arguments have been proposed based upon thought\nexperiments, anecdotal conversations between LLMs and humans, statistical\nlinguistic analysis, philosophical considerations, and more. In this brief\npaper we present a counter-argument based upon a thought experiment and\nsemi-formal considerations leading to an inherent ambiguity barrier which\nprevents LLMs from having any understanding of what their amazingly fluent\ndialogues mean.",
      "tldr_zh": "本文通过一个思想实验和半形式化的论证，提出了大型语言模型(LLMs)理解能力存在一个固有的歧义屏障。作者认为，由于这种固有的歧义性，LLMs无法真正理解其流畅对话的含义。该研究旨在对LLMs是否具备理解世界和捕捉对话意义的能力这一持续争论提出一个反驳观点。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "submitted to NEURAL COMPUTATION",
      "pdf_url": "http://arxiv.org/pdf/2505.00654v1",
      "published_date": "2025-05-01 16:55:44 UTC",
      "updated_date": "2025-05-01 16:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:12:40.202771"
    },
    {
      "arxiv_id": "2505.00651v1",
      "title": "Open-Source LLM-Driven Federated Transformer for Predictive IoV Management",
      "title_zh": "用于预测性 IoV 管理的开源 LLM 驱动的联邦 Transformer\n",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Ishtiaq Ahmad"
      ],
      "abstract": "The proliferation of connected vehicles within the Internet of Vehicles (IoV)\necosystem presents critical challenges in ensuring scalable, real-time, and\nprivacy-preserving traffic management. Existing centralized IoV solutions often\nsuffer from high latency, limited scalability, and reliance on proprietary\nArtificial Intelligence (AI) models, creating significant barriers to\nwidespread deployment, particularly in dynamic and privacy-sensitive\nenvironments. Meanwhile, integrating Large Language Models (LLMs) in vehicular\nsystems remains underexplored, especially concerning prompt optimization and\neffective utilization in federated contexts. To address these challenges, we\npropose the Federated Prompt-Optimized Traffic Transformer (FPoTT), a novel\nframework that leverages open-source LLMs for predictive IoV management. FPoTT\nintroduces a dynamic prompt optimization mechanism that iteratively refines\ntextual prompts to enhance trajectory prediction. The architecture employs a\ndual-layer federated learning paradigm, combining lightweight edge models for\nreal-time inference with cloud-based LLMs to retain global intelligence. A\nTransformer-driven synthetic data generator is incorporated to augment training\nwith diverse, high-fidelity traffic scenarios in the Next Generation Simulation\n(NGSIM) format. Extensive evaluations demonstrate that FPoTT, utilizing\nEleutherAI Pythia-1B, achieves 99.86% prediction accuracy on real-world data\nwhile maintaining high performance on synthetic datasets. These results\nunderscore the potential of open-source LLMs in enabling secure, adaptive, and\nscalable IoV management, offering a promising alternative to proprietary\nsolutions in smart mobility ecosystems.",
      "tldr_zh": "该论文提出了联邦提示优化交通Transformer (FPoTT)，一个利用开源LLM进行预测性IoV管理的新框架。FPoTT引入了一种动态提示优化机制，迭代地改进文本提示以增强轨迹预测。该架构采用双层联邦学习范式，结合轻量级边缘模型进行实时推理，以及基于云的LLM来保留全局智能。此外，还加入了一个Transformer驱动的合成数据生成器，以NGSIM格式增强训练数据。实验结果表明，使用EleutherAI Pythia-1B的FPoTT在真实世界数据上实现了99.86%的预测准确率，证明了开源LLM在实现安全、自适应和可扩展的IoV管理方面的潜力。\n",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint version; submitted for academic peer review",
      "pdf_url": "http://arxiv.org/pdf/2505.00651v1",
      "published_date": "2025-05-01 16:54:21 UTC",
      "updated_date": "2025-05-01 16:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:12:52.278686"
    },
    {
      "arxiv_id": "2505.00650v1",
      "title": "OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification",
      "title_zh": "OmicsCL：用于癌症亚型发现和生存分层的无监督对比学习\n",
      "authors": [
        "Atahan Karagoz"
      ],
      "abstract": "Unsupervised learning of disease subtypes from multi-omics data presents a\nsignificant opportunity for advancing personalized medicine. We introduce\nOmicsCL, a modular contrastive learning framework that jointly embeds\nheterogeneous omics modalities-such as gene expression, DNA methylation, and\nmiRNA expression-into a unified latent space. Our method incorporates a\nsurvival-aware contrastive loss that encourages the model to learn\nrepresentations aligned with survival-related patterns, without relying on\nlabeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers\nclinically meaningful clusters and achieves strong unsupervised concordance\nwith patient survival. The framework demonstrates robustness across\nhyperparameter configurations and can be tuned to prioritize either subtype\ncoherence or survival stratification. Ablation studies confirm that integrating\nsurvival-aware loss significantly enhances the predictive power of learned\nembeddings. These results highlight the promise of contrastive objectives for\nbiological insight discovery in high-dimensional, heterogeneous omics data.",
      "tldr_zh": "OmicsCL是一个无监督对比学习框架，旨在从多组学数据中发现癌症亚型并进行生存分层，从而推进个性化医疗。该框架将基因表达、DNA甲基化和miRNA表达等异构组学模态联合嵌入到统一的潜在空间中。OmicsCL采用了一种生存感知的对比损失，鼓励模型学习与生存相关的模式，而无需依赖标记结果。在TCGA BRCA数据集上的评估表明，OmicsCL揭示了具有临床意义的聚类，并在无监督的情况下与患者生存率高度一致。消融研究证实，整合生存感知损失显著增强了学习嵌入的预测能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at: https://github.com/Atahanka/OmicsCL",
      "pdf_url": "http://arxiv.org/pdf/2505.00650v1",
      "published_date": "2025-05-01 16:51:48 UTC",
      "updated_date": "2025-05-01 16:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:13:04.379270"
    },
    {
      "arxiv_id": "2505.00643v1",
      "title": "Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI",
      "title_zh": "深度学习辅助的外层体积去除技术，用于高度加速的实时动态 MRI",
      "authors": [
        "Merve Gülle",
        "Sebastian Weingärtner",
        "Mehmet Akçakaya"
      ],
      "abstract": "Real-time (RT) dynamic MRI plays a vital role in capturing rapid\nphysiological processes, offering unique insights into organ motion and\nfunction. Among these applications, RT cine MRI is particularly important for\nfunctional assessment of the heart with high temporal resolution. RT imaging\nenables free-breathing, ungated imaging of cardiac motion, making it a crucial\nalternative for patients who cannot tolerate conventional breath-hold,\nECG-gated acquisitions. However, achieving high acceleration rates in RT cine\nMRI is challenging due to aliasing artifacts from extra-cardiac tissues,\nparticularly at high undersampling factors. In this study, we propose a novel\nouter volume removal (OVR) method to address this challenge by eliminating\naliasing contributions from non-cardiac regions in a post-processing framework.\nOur approach estimates the outer volume signal for each timeframe using\ncomposite temporal images from time-interleaved undersampling patterns, which\ninherently contain pseudo-periodic ghosting artifacts. A deep learning (DL)\nmodel is trained to identify and remove these artifacts, producing a clean\nouter volume estimate that is subsequently subtracted from the corresponding\nk-space data. The final reconstruction is performed with a physics-driven DL\n(PD-DL) method trained using an OVR-specific loss function to restore high\nspatio-temporal resolution images. Experimental results show that the proposed\nmethod at high accelerations achieves image quality that is visually comparable\nto clinical baseline images, while outperforming conventional reconstruction\ntechniques, both qualitatively and quantitatively. The proposed approach\nprovides a practical and effective solution for artifact reduction in RT cine\nMRI without requiring acquisition modifications, offering a pathway to higher\nacceleration rates while preserving diagnostic quality.",
      "tldr_zh": "该研究提出了一种基于深度学习的外部体积去除(OVR)方法，用于解决高加速实时动态MRI中，因心脏外组织混叠伪影导致图像质量下降的问题。该方法利用时间交错欠采样模式的复合时间图像估计每个时间帧的外部体积信号，并训练深度学习模型去除伪周期重影伪影，从而获得干净的外部体积估计。随后，将该估计从相应的k空间数据中减去，并使用针对OVR的损失函数训练的物理驱动深度学习(PD-DL)方法进行最终重建，以恢复高时空分辨率图像。实验结果表明，该方法在高加速下获得的图像质量与临床基线图像相当，优于传统的重建技术，为在不修改采集方式的情况下提高实时电影MRI的加速率提供了有效途径。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00643v1",
      "published_date": "2025-05-01 16:31:52 UTC",
      "updated_date": "2025-05-01 16:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:13:16.600877"
    },
    {
      "arxiv_id": "2505.00626v1",
      "title": "The Illusion of Role Separation: Hidden Shortcuts in LLM Role Learning (and How to Fix Them)",
      "title_zh": "角色分离的错觉：LLM 角色学习中隐藏的捷径（以及如何修复它们）\n",
      "authors": [
        "Zihao Wang",
        "Yibo Jiang",
        "Jiahao Yu",
        "Heqing Huang"
      ],
      "abstract": "Large language models (LLMs) that integrate multiple input roles (e.g.,\nsystem instructions, user queries, external tool outputs) are increasingly\nprevalent in practice. Ensuring that the model accurately distinguishes\nmessages from each role -- a concept we call \\emph{role separation} -- is\ncrucial for consistent multi-role behavior. Although recent work often targets\nstate-of-the-art prompt injection defenses, it remains unclear whether such\nmethods truly teach LLMs to differentiate roles or merely memorize known\ntriggers. In this paper, we examine \\emph{role-separation learning}: the\nprocess of teaching LLMs to robustly distinguish system and user tokens.\nThrough a \\emph{simple, controlled experimental framework}, we find that\nfine-tuned models often rely on two proxies for role identification: (1) task\ntype exploitation, and (2) proximity to begin-of-text. Although data\naugmentation can partially mitigate these shortcuts, it generally leads to\niterative patching rather than a deeper fix. To address this, we propose\nreinforcing \\emph{invariant signals} that mark role boundaries by adjusting\ntoken-wise cues in the model's input encoding. In particular, manipulating\nposition IDs helps the model learn clearer distinctions and reduces reliance on\nsuperficial proxies. By focusing on this mechanism-centered perspective, our\nwork illuminates how LLMs can more reliably maintain consistent multi-role\nbehavior without merely memorizing known prompts or triggers.",
      "tldr_zh": "该研究揭示了大型语言模型(LLMs)在角色分离学习中存在的隐藏捷径，即模型并非真正理解角色差异，而是依赖于任务类型和与文本起始位置的距离等表面特征进行判断。通过可控实验框架，研究发现即使使用数据增强，也只能进行迭代修补，无法从根本上解决问题。为此，研究提出通过调整模型输入编码中的token-wise cues，强化标记角色边界的不变信号，特别是操纵position IDs，以帮助模型学习更清晰的角色区分。这种以机制为中心的方法，旨在使LLMs更可靠地保持一致的多角色行为，避免仅仅记忆已知的提示或触发器。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00626v1",
      "published_date": "2025-05-01 16:06:16 UTC",
      "updated_date": "2025-05-01 16:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:13:28.339339"
    },
    {
      "arxiv_id": "2505.00624v1",
      "title": "FineScope : Precision Pruning for Domain-Specialized Large Language Models Using SAE-Guided Self-Data Cultivation",
      "title_zh": "FineScope：使用 SAE 指导的自数据培育对领域专用大型语言模型进行精确剪枝\n",
      "authors": [
        "Chaitali Bhattacharyya",
        "Yeseong Kim"
      ],
      "abstract": "Training large language models (LLMs) from scratch requires significant\ncomputational resources, driving interest in developing smaller,\ndomain-specific LLMs that maintain both efficiency and strong task performance.\nMedium-sized models such as LLaMA, llama} have served as starting points for\ndomain-specific adaptation, but they often suffer from accuracy degradation\nwhen tested on specialized datasets. We introduce FineScope, a framework for\nderiving compact, domain-optimized LLMs from larger pretrained models.\nFineScope leverages the Sparse Autoencoder (SAE) framework, inspired by its\nability to produce interpretable feature representations, to extract\ndomain-specific subsets from large datasets. We apply structured pruning with\ndomain-specific constraints, ensuring that the resulting pruned models retain\nessential knowledge for the target domain. To further enhance performance,\nthese pruned models undergo self-data distillation, leveraging SAE-curated\ndatasets to restore key domain-specific information lost during pruning.\nExtensive experiments and ablation studies demonstrate that FineScope achieves\nhighly competitive performance, outperforming several large-scale\nstate-of-the-art LLMs in domain-specific tasks. Additionally, our results show\nthat FineScope enables pruned models to regain a substantial portion of their\noriginal performance when fine-tuned with SAE-curated datasets. Furthermore,\napplying these datasets to fine-tune pretrained LLMs without pruning also\nimproves their domain-specific accuracy, highlighting the robustness of our\napproach. The code will be released.",
      "tldr_zh": "该论文提出了FineScope框架，旨在从大型预训练语言模型中提取紧凑且领域优化的LLM。FineScope利用稀疏自编码器(SAE)提取领域特定数据集的特征表示，并应用结构化剪枝保留目标领域的核心知识。通过SAE生成的数据集进行自数据蒸馏，恢复剪枝过程中丢失的关键领域信息。实验结果表明，FineScope在领域特定任务上表现优异，超越了多个大型SOTA LLM，并且使用SAE数据集微调预训练LLM也能提高领域特定准确性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00624v1",
      "published_date": "2025-05-01 16:05:08 UTC",
      "updated_date": "2025-05-01 16:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:13:40.364915"
    },
    {
      "arxiv_id": "2505.00622v1",
      "title": "Neural Network Verification for Gliding Drone Control: A Case Study",
      "title_zh": "滑翔无人机控制的神经网络验证：一个案例研究\n",
      "authors": [
        "Colin Kessler",
        "Ekaterina Komendantskaya",
        "Marco Casadio",
        "Ignazio Maria Viola",
        "Thomas Flinkow",
        "Albaraa Ammar Othman",
        "Alistair Malhotra",
        "Robbie McPherson"
      ],
      "abstract": "As machine learning is increasingly deployed in autonomous systems,\nverification of neural network controllers is becoming an active research\ndomain. Existing tools and annual verification competitions suggest that soon\nthis technology will become effective for real-world applications. Our\napplication comes from the emerging field of microflyers that are passively\ntransported by the wind, which may have various uses in weather or pollution\nmonitoring. Specifically, we investigate centimetre-scale bio-inspired gliding\ndrones that resemble Alsomitra macrocarpa diaspores. In this paper, we propose\na new case study on verifying Alsomitra-inspired drones with neural network\ncontrollers, with the aim of adhering closely to a target trajectory. We show\nthat our system differs substantially from existing VNN and ARCH competition\nbenchmarks, and show that a combination of tools holds promise for verifying\nsuch systems in the future, if certain shortcomings can be overcome. We propose\na novel method for robust training of regression networks, and investigate\nformalisations of this case study in Vehicle and CORA. Our verification results\nsuggest that the investigated training methods do improve performance and\nrobustness of neural network controllers in this application, but are limited\nin scope and usefulness. This is due to systematic limitations of both Vehicle\nand CORA, and the complexity of our system reducing the scale of reachability,\nwhich we investigate in detail. If these limitations can be overcome, it will\nenable engineers to develop safe and robust technologies that improve people's\nlives and reduce our impact on the environment.",
      "tldr_zh": "本文针对滑翔无人机控制中的神经网络控制器验证问题，提出了一个实际案例研究。该研究以模仿Alsomitra macrocarpa种子的厘米级仿生滑翔无人机为对象，旨在验证其神经网络控制器能否使其精确地跟踪目标轨迹。研究表明，该系统与现有的VNN和ARCH验证基准测试有显著差异。通过结合Vehicle和CORA等工具，并提出一种新的回归网络鲁棒训练方法，验证结果表明所研究的训练方法确实提高了神经网络控制器的性能和鲁棒性。然而，由于Vehicle和CORA的局限性以及系统本身的复杂性，验证的范围和有效性受到限制。该研究强调了克服这些限制对于开发安全可靠的无人机技术的重要性。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "18 page pre print, submitted to SAIV 2025 (conference)",
      "pdf_url": "http://arxiv.org/pdf/2505.00622v1",
      "published_date": "2025-05-01 16:03:38 UTC",
      "updated_date": "2025-05-01 16:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:13:52.518514"
    },
    {
      "arxiv_id": "2505.00615v1",
      "title": "Pixel3DMM: Versatile Screen-Space Priors for Single-Image 3D Face Reconstruction",
      "title_zh": "Pixel3DMM：用于单图像三维人脸重建的多功能屏幕空间先验",
      "authors": [
        "Simon Giebenhain",
        "Tobias Kirschstein",
        "Martin Rünz",
        "Lourdes Agapito",
        "Matthias Nießner"
      ],
      "abstract": "We address the 3D reconstruction of human faces from a single RGB image. To\nthis end, we propose Pixel3DMM, a set of highly-generalized vision transformers\nwhich predict per-pixel geometric cues in order to constrain the optimization\nof a 3D morphable face model (3DMM). We exploit the latent features of the DINO\nfoundation model, and introduce a tailored surface normal and uv-coordinate\nprediction head. We train our model by registering three high-quality 3D face\ndatasets against the FLAME mesh topology, which results in a total of over\n1,000 identities and 976K images. For 3D face reconstruction, we propose a\nFLAME fitting opitmization that solves for the 3DMM parameters from the\nuv-coordinate and normal estimates. To evaluate our method, we introduce a new\nbenchmark for single-image face reconstruction, which features high diversity\nfacial expressions, viewing angles, and ethnicities. Crucially, our benchmark\nis the first to evaluate both posed and neutral facial geometry. Ultimately,\nour method outperforms the most competitive baselines by over 15% in terms of\ngeometric accuracy for posed facial expressions.",
      "tldr_zh": "本文提出Pixel3DMM，一种通用的屏幕空间先验方法，用于从单张RGB图像中进行3D人脸重建。该方法利用视觉Transformer预测逐像素的几何线索，从而约束3D形变人脸模型(3DMM)的优化。Pixel3DMM利用DINO基础模型的潜在特征，并引入定制的表面法线和UV坐标预测头。通过将三个高质量的3D人脸数据集注册到FLAME网格拓扑上进行训练，得到了包含超过1000个身份和976K图像的数据集。在3D人脸重建方面，文章提出了一种FLAME拟合优化方法，通过UV坐标和法线估计求解3DMM参数。为了评估该方法，作者引入了一个新的单图像人脸重建基准，该基准具有高度多样化的面部表情、视角和种族。实验结果表明，该方法在姿态面部表情的几何精度方面优于最具竞争力的基线方法15%以上。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Website: https://simongiebenhain.github.io/pixel3dmm/ ;\n  Video: https://www.youtube.com/watch?v=BwxwEXJwUDc",
      "pdf_url": "http://arxiv.org/pdf/2505.00615v1",
      "published_date": "2025-05-01 15:47:03 UTC",
      "updated_date": "2025-05-01 15:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:14:04.726058"
    },
    {
      "arxiv_id": "2505.00612v1",
      "title": "Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation",
      "title_zh": "立场：AI 竞赛为 GenAI 评估中的经验严谨性提供了黄金标准\n",
      "authors": [
        "D. Sculley",
        "Will Cukierski",
        "Phil Culliton",
        "Sohier Dane",
        "Maggie Demkin",
        "Ryan Holbrook",
        "Addison Howard",
        "Paul Mooney",
        "Walter Reade",
        "Megan Risdal",
        "Nate Keating"
      ],
      "abstract": "In this position paper, we observe that empirical evaluation in Generative AI\nis at a crisis point since traditional ML evaluation and benchmarking\nstrategies are insufficient to meet the needs of evaluating modern GenAI models\nand systems. There are many reasons for this, including the fact that these\nmodels typically have nearly unbounded input and output spaces, typically do\nnot have a well defined ground truth target, and typically exhibit strong\nfeedback loops and prediction dependence based on context of previous model\noutputs. On top of these critical issues, we argue that the problems of {\\em\nleakage} and {\\em contamination} are in fact the most important and difficult\nissues to address for GenAI evaluations. Interestingly, the field of AI\nCompetitions has developed effective measures and practices to combat leakage\nfor the purpose of counteracting cheating by bad actors within a competition\nsetting. This makes AI Competitions an especially valuable (but underutilized)\nresource. Now is time for the field to view AI Competitions as the gold\nstandard for empirical rigor in GenAI evaluation, and to harness and harvest\ntheir results with according value.",
      "tldr_zh": "这篇论文指出，生成式人工智能(GenAI)的经验评估正面临危机，传统的机器学习评估和基准测试策略已不足以满足现代GenAI模型和系统的评估需求。GenAI模型通常具有无限的输入和输出空间，缺乏明确的ground truth目标，并且表现出基于先前模型输出上下文的强反馈循环和预测依赖性。论文强调了GenAI评估中泄漏(leakage)和污染(contamination)问题的重要性，并认为AI竞赛在对抗作弊行为方面已经开发出有效的措施和实践。因此，论文提出应将AI竞赛视为GenAI评估中经验严谨性的黄金标准，并充分利用其结果。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00612v1",
      "published_date": "2025-05-01 15:43:51 UTC",
      "updated_date": "2025-05-01 15:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:14:16.372372"
    },
    {
      "arxiv_id": "2505.00610v1",
      "title": "Combining LLMs with Logic-Based Framework to Explain MCTS",
      "title_zh": "结合大型语言模型与基于逻辑的框架来解释蒙特卡洛树搜索\n",
      "authors": [
        "Ziyan An",
        "Xia Wang",
        "Hendrik Baier",
        "Zirong Chen",
        "Abhishek Dubey",
        "Taylor T. Johnson",
        "Jonathan Sprinkle",
        "Ayan Mukhopadhyay",
        "Meiyi Ma"
      ],
      "abstract": "In response to the lack of trust in Artificial Intelligence (AI) for\nsequential planning, we design a Computational Tree Logic-guided large language\nmodel (LLM)-based natural language explanation framework designed for the Monte\nCarlo Tree Search (MCTS) algorithm. MCTS is often considered challenging to\ninterpret due to the complexity of its search trees, but our framework is\nflexible enough to handle a wide range of free-form post-hoc queries and\nknowledge-based inquiries centered around MCTS and the Markov Decision Process\n(MDP) of the application domain. By transforming user queries into logic and\nvariable statements, our framework ensures that the evidence obtained from the\nsearch tree remains factually consistent with the underlying environmental\ndynamics and any constraints in the actual stochastic control process. We\nevaluate the framework rigorously through quantitative assessments, where it\ndemonstrates strong performance in terms of accuracy and factual consistency.",
      "tldr_zh": "该研究提出了一种基于计算树逻辑引导的大语言模型(LLM)自然语言解释框架，用于解释蒙特卡洛树搜索(MCTS)算法。该框架通过将用户查询转化为逻辑和变量语句，确保从搜索树中获得的证据与底层环境动态和随机控制过程中的约束保持事实一致性。通过定量评估，该框架在准确性和事实一致性方面表现出强大的性能，能够处理围绕MCTS和马尔可夫决策过程(MDP)的各种自由形式的后验查询和基于知识的查询，从而提升AI在序列规划中的可信度。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAMAS-25 as an extended abstract",
      "pdf_url": "http://arxiv.org/pdf/2505.00610v1",
      "published_date": "2025-05-01 15:40:58 UTC",
      "updated_date": "2025-05-01 15:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:14:28.200958"
    },
    {
      "arxiv_id": "2505.00603v1",
      "title": "Can LLMs Help Improve Analogical Reasoning For Strategic Decisions? Experimental Evidence from Humans and GPT-4",
      "title_zh": "LLM 能否帮助改进战略决策中的类比推理？来自人类和 GPT-4 的实验证据\n",
      "authors": [
        "Phanish Puranam",
        "Prothit Sen",
        "Maciej Workiewicz"
      ],
      "abstract": "This study investigates whether large language models, specifically GPT4, can\nmatch human capabilities in analogical reasoning within strategic decision\nmaking contexts. Using a novel experimental design involving source to target\nmatching, we find that GPT4 achieves high recall by retrieving all plausible\nanalogies but suffers from low precision, frequently applying incorrect\nanalogies based on superficial similarities. In contrast, human participants\nexhibit high precision but low recall, selecting fewer analogies yet with\nstronger causal alignment. These findings advance theory by identifying\nmatching, the evaluative phase of analogical reasoning, as a distinct step that\nrequires accurate causal mapping beyond simple retrieval. While current LLMs\nare proficient in generating candidate analogies, humans maintain a comparative\nadvantage in recognizing deep structural similarities across domains. Error\nanalysis reveals that AI errors arise from surface level matching, whereas\nhuman errors stem from misinterpretations of causal structure. Taken together,\nthe results suggest a productive division of labor in AI assisted\norganizational decision making where LLMs may serve as broad analogy\ngenerators, while humans act as critical evaluators, applying the most\ncontextually appropriate analogies to strategic problems.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs），特别是GPT-4，在战略决策中类比推理方面是否能与人类能力相媲美。通过源到目标匹配的实验设计，发现GPT-4在检索所有可能的类比时实现了高召回率，但由于经常基于表面相似性应用不正确的类比，因此精度较低。相比之下，人类参与者表现出高精度但低召回率，选择的类比数量较少，但因果关系更强。研究结果表明，类比推理的评估阶段（matching）是一个独特的步骤，需要超出简单检索的精确因果映射。虽然目前的LLMs擅长生成候选类比，但人类在识别跨领域的深层结构相似性方面保持着比较优势。误差分析表明，AI错误源于表面层次的匹配，而人类错误源于对因果结构的误解。总而言之，研究结果表明，在AI辅助的组织决策中，LLMs可以作为广泛的类比生成器，而人类则可以作为批判性的评估者，将最适合上下文的类比应用于战略问题，从而实现富有成效的分工。\n",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00603v1",
      "published_date": "2025-05-01 15:35:01 UTC",
      "updated_date": "2025-05-01 15:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:14:40.996692"
    },
    {
      "arxiv_id": "2505.00598v1",
      "title": "Fast and Low-Cost Genomic Foundation Models via Outlier Removal",
      "title_zh": "通过移除异常值实现快速且低成本的基因组基础模型\n",
      "authors": [
        "Haozheng Luo",
        "Chenghao Qiu",
        "Maojiang Su",
        "Zhihan Zhou",
        "Zoe Mehta",
        "Guo Ye",
        "Jerry Yao-Chieh Hu",
        "Han Liu"
      ],
      "abstract": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GERM. Unlike existing GFM benchmarks, GERM\noffers the first comprehensive evaluation framework to systematically assess\nthe vulnerability of GFMs to adversarial attacks. Methodologically, we evaluate\nthe adversarial robustness of five state-of-the-art GFMs using four widely\nadopted attack algorithms and three defense strategies. Importantly, our\nbenchmark provides an accessible and comprehensive framework to analyze GFM\nvulnerabilities with respect to model architecture, quantization schemes, and\ntraining datasets. Empirically, transformer-based models exhibit greater\nrobustness to adversarial perturbations compared to HyenaDNA, highlighting the\nimpact of architectural design on vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features.",
      "tldr_zh": "该论文提出了首个针对基因组基础模型(Genomic Foundation Models, GFMs)的统一对抗攻击基准GERM，旨在全面评估GFMs在对抗攻击下的脆弱性。通过GERM，研究人员使用四种常见的攻击算法和三种防御策略，评估了五个最先进的GFMs的对抗鲁棒性。实验结果表明，基于Transformer的模型比HyenaDNA模型对对抗扰动更具鲁棒性，强调了架构设计对脆弱性的影响。此外，对抗攻击经常针对具有生物学意义的基因组区域，表明这些模型有效地捕捉了有意义的序列特征。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning (ICML) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00598v1",
      "published_date": "2025-05-01 15:31:09 UTC",
      "updated_date": "2025-05-01 15:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:14:52.450390"
    },
    {
      "arxiv_id": "2505.00596v1",
      "title": "A Finite-State Controller Based Offline Solver for Deterministic POMDPs",
      "title_zh": "基于有限状态控制器的确定性 POMDP 离线求解器\n",
      "authors": [
        "Alex Schutz",
        "Yang You",
        "Matias Mattamala",
        "Ipek Caliskanelli",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "abstract": "Deterministic partially observable Markov decision processes (DetPOMDPs)\noften arise in planning problems where the agent is uncertain about its\nenvironmental state but can act and observe deterministically. In this paper,\nwe propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI)\nalgorithm for DetPOMDPs, which builds policies in the form of finite-state\ncontrollers (FSCs). DetMCVI solves large problems with a high success rate,\noutperforming existing baselines for DetPOMDPs. We also verify the performance\nof the algorithm in a real-world mobile robot forest mapping scenario.",
      "tldr_zh": "本文提出了一种基于有限状态控制器(FSC)的离线求解器DetMCVI，用于解决确定性部分可观测马尔可夫决策过程(DetPOMDPs)。DetMCVI是蒙特卡洛值迭代(MCVI)算法在DetPOMDPs上的改进，它构建有限状态控制器的策略。实验结果表明，DetMCVI在解决大型问题时具有较高的成功率，优于现有的DetPOMDPs基线方法。该算法还在真实的移动机器人森林测绘场景中验证了其性能。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.8; I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 6 figures. Appendix attached. To be published in Proceedings\n  of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI",
      "pdf_url": "http://arxiv.org/pdf/2505.00596v1",
      "published_date": "2025-05-01 15:30:26 UTC",
      "updated_date": "2025-05-01 15:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:15:04.212986"
    },
    {
      "arxiv_id": "2505.00584v1",
      "title": "Synthesizing and Identifying Noise Levels in Autonomous Vehicle Camera Radar Datasets",
      "title_zh": "合成并识别自动驾驶车辆相机雷达数据集中的噪声水平\n",
      "authors": [
        "Mathis Morales",
        "Golnaz Habibi"
      ],
      "abstract": "Detecting and tracking objects is a crucial component of any autonomous\nnavigation method. For the past decades, object detection has yielded promising\nresults using neural networks on various datasets. While many methods focus on\nperformance metrics, few projects focus on improving the robustness of these\ndetection and tracking pipelines, notably to sensor failures. In this paper we\nattempt to address this issue by creating a realistic synthetic data\naugmentation pipeline for camera-radar Autonomous Vehicle (AV) datasets. Our\ngoal is to accurately simulate sensor failures and data deterioration due to\nreal-world interferences. We also present our results of a baseline lightweight\nNoise Recognition neural network trained and tested on our augmented dataset,\nreaching an overall recognition accuracy of 54.4\\% on 11 categories across\n10086 images and 2145 radar point-clouds.",
      "tldr_zh": "该论文提出了一种针对自动驾驶车辆(AV)相机-雷达数据集的合成数据增强流程，旨在模拟传感器故障和真实世界干扰导致的数据质量下降，从而提高目标检测和跟踪管道的鲁棒性。该流程能够合成不同噪声水平的数据。此外，论文还训练并测试了一个轻量级的噪声识别神经网络，用于识别增强数据集中的噪声水平，在11个类别、10086张图像和2145个雷达点云上达到了54.4%的总体识别准确率。研究结果表明，该方法能够有效模拟传感器噪声，并为后续的噪声识别和鲁棒性提升奠定基础。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00584v1",
      "published_date": "2025-05-01 15:15:50 UTC",
      "updated_date": "2025-05-01 15:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:15:16.436758"
    },
    {
      "arxiv_id": "2505.00579v1",
      "title": "Voice Cloning: Comprehensive Survey",
      "title_zh": "语音克隆：综合综述\n",
      "authors": [
        "Hussam Azzuni",
        "Abdulmotaleb El Saddik"
      ],
      "abstract": "Voice Cloning has rapidly advanced in today's digital world, with many\nresearchers and corporations working to improve these algorithms for various\napplications. This article aims to establish a standardized terminology for\nvoice cloning and explore its different variations. It will cover speaker\nadaptation as the fundamental concept and then delve deeper into topics such as\nfew-shot, zero-shot, and multilingual TTS within that context. Finally, we will\nexplore the evaluation metrics commonly used in voice cloning research and\nrelated datasets. This survey compiles the available voice cloning algorithms\nto encourage research toward its generation and detection to limit its misuse.",
      "tldr_zh": "本文对语音克隆技术进行了全面的综述，旨在建立标准化的术语并探讨其不同的变体。文章首先介绍了作为基础概念的说话人自适应，然后深入研究了少样本(few-shot)、零样本(zero-shot)和多语种TTS等主题。最后，探讨了语音克隆研究中常用的评估指标和相关数据集。该综述旨在促进语音克隆技术的生成和检测研究，从而限制其滥用。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "26 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00579v1",
      "published_date": "2025-05-01 15:10:29 UTC",
      "updated_date": "2025-05-01 15:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:15:28.208872"
    },
    {
      "arxiv_id": "2505.00570v1",
      "title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension",
      "title_zh": "FreqKV：用于高效上下文窗口扩展的频域键值压缩\n",
      "authors": [
        "Jushi Kai",
        "Boyi Zeng",
        "Yixuan Wang",
        "Haoli Bai",
        "Bo Jiang",
        "Zhouhan Lin"
      ],
      "abstract": "Extending the context window in large language models (LLMs) is essential for\napplications involving long-form content generation. However, the linear\nincrease in key-value (KV) cache memory requirements and the quadratic\ncomplexity of self-attention with respect to sequence length present\nsignificant challenges during fine-tuning and inference. Existing methods\nsuffer from performance degradation when extending to longer contexts. In this\nwork, we introduce a novel context extension method that optimizes both\nfine-tuning and inference efficiency. Our method exploits a key observation: in\nthe frequency domain, the energy distribution of the KV cache is primarily\nconcentrated in low-frequency components. By filtering out the high-frequency\ncomponents, the KV cache can be effectively compressed with minimal information\nloss. Building on this insight, we propose an efficient compression technique,\nFreqKV, that iteratively compresses the increasing KV cache to a fixed size in\nthe frequency domain, applicable to both fine-tuning and inference. FreqKV\nintroduces no additional parameters or architectural modifications. With\nminimal fine-tuning, LLMs can learn to leverage the limited cache that is\ncompressed in the frequency domain and extend the context window efficiently.\nExperiments on various long context language modeling and understanding tasks\ndemonstrate the efficiency and efficacy of the proposed method.",
      "tldr_zh": "为了解决大语言模型(LLMs)上下文窗口扩展时KV缓存线性增长和自注意力机制二次复杂度的问题，该论文提出了一种名为FreqKV的新型上下文扩展方法。FreqKV的核心思想是观察到KV缓存在频域中的能量主要集中在低频分量，因此可以通过滤除高频分量来压缩KV缓存，同时保持信息损失最小。FreqKV在频域中迭代压缩KV缓存至固定大小，无需额外参数或架构修改，适用于微调和推理。实验表明，通过少量微调，LLMs可以有效地利用压缩后的缓存，并在长文本建模和理解任务中表现出高效性和有效性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00570v1",
      "published_date": "2025-05-01 14:53:12 UTC",
      "updated_date": "2025-05-01 14:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:15:40.526888"
    },
    {
      "arxiv_id": "2505.00568v1",
      "title": "Multimodal Masked Autoencoder Pre-training for 3D MRI-Based Brain Tumor Analysis with Missing Modalities",
      "title_zh": "用于处理缺失模态的基于 3D MRI 脑肿瘤分析的多模态掩码自编码器预训练\n",
      "authors": [
        "Lucas Robinet",
        "Ahmad Berjaoui",
        "Elizabeth Cohen-Jonathan Moyal"
      ],
      "abstract": "Multimodal magnetic resonance imaging (MRI) constitutes the first line of\ninvestigation for clinicians in the care of brain tumors, providing crucial\ninsights for surgery planning, treatment monitoring, and biomarker\nidentification. Pre-training on large datasets have been shown to help models\nlearn transferable representations and adapt with minimal labeled data. This\nbehavior is especially valuable in medical imaging, where annotations are often\nscarce. However, applying this paradigm to multimodal medical data introduces a\nchallenge: most existing approaches assume that all imaging modalities are\navailable during both pre-training and fine-tuning. In practice, missing\nmodalities often occur due to acquisition issues, specialist unavailability, or\nspecific experimental designs on small in-house datasets. Consequently, a\ncommon approach involves training a separate model for each desired modality\ncombination, making the process both resource-intensive and impractical for\nclinical use. Therefore, we introduce BM-MAE, a masked image modeling\npre-training strategy tailored for multimodal MRI data. The same pre-trained\nmodel seamlessly adapts to any combination of available modalities, extracting\nrich representations that capture both intra- and inter-modal information. This\nallows fine-tuning on any subset of modalities without requiring architectural\nchanges, while still benefiting from a model pre-trained on the full set of\nmodalities. Extensive experiments show that the proposed pre-training strategy\noutperforms or remains competitive with baselines that require separate\npre-training for each modality subset, while substantially surpassing training\nfrom scratch on several downstream tasks. Additionally, it can quickly and\nefficiently reconstruct missing modalities, highlighting its practical value.\nCode and trained models are available at: https://github.com/Lucas-rbnt/bmmae",
      "tldr_zh": "该论文提出了BM-MAE，一种用于3D MRI脑肿瘤分析的多模态掩码自编码器预训练策略，旨在解决医学影像中模态缺失的问题。BM-MAE能够利用所有模态数据进行预训练，并无缝适应任意模态组合的微调，无需改变网络结构。实验结果表明，该方法在多个下游任务中优于或至少与针对每个模态子集单独预训练的基线模型持平，并且显著优于从头开始训练的模型。此外，BM-MAE还能快速有效地重建缺失的模态，具有很高的实用价值。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00568v1",
      "published_date": "2025-05-01 14:51:30 UTC",
      "updated_date": "2025-05-01 14:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:15:52.460426"
    },
    {
      "arxiv_id": "2505.00562v1",
      "title": "TeLoGraF: Temporal Logic Planning via Graph-encoded Flow Matching",
      "title_zh": "TeLoGraF：通过图编码的流动匹配进行时序逻辑规划\n",
      "authors": [
        "Yue Meng",
        "Chuchu Fan"
      ],
      "abstract": "Learning to solve complex tasks with signal temporal logic (STL)\nspecifications is crucial to many real-world applications. However, most\nprevious works only consider fixed or parametrized STL specifications due to\nthe lack of a diverse STL dataset and encoders to effectively extract temporal\nlogic information for downstream tasks. In this paper, we propose TeLoGraF,\nTemporal Logic Graph-encoded Flow, which utilizes Graph Neural Networks (GNN)\nencoder and flow-matching to learn solutions for general STL specifications. We\nidentify four commonly used STL templates and collect a total of 200K\nspecifications with paired demonstrations. We conduct extensive experiments in\nfive simulation environments ranging from simple dynamical models in the 2D\nspace to high-dimensional 7DoF Franka Panda robot arm and Ant quadruped\nnavigation. Results show that our method outperforms other baselines in the STL\nsatisfaction rate. Compared to classical STL planning algorithms, our approach\nis 10-100X faster in inference and can work on any system dynamics. Besides, we\nshow our graph-encoding method's capability to solve complex STLs and\nrobustness to out-distribution STL specifications. Code is available at\nhttps://github.com/mengyuest/TeLoGraF",
      "tldr_zh": "本文提出了一种名为TeLoGraF的框架，即Temporal Logic Graph-encoded Flow，它利用图神经网络(GNN)编码器和流匹配(flow-matching)来学习通用信号时序逻辑(STL)规范的解决方案。研究人员收集了包含20万个配对演示的STL规范数据集，涵盖四种常用STL模板。实验在五个模拟环境中进行，结果表明TeLoGraF在STL满足率方面优于其他基线方法。与经典STL规划算法相比，TeLoGraF的推理速度快10-100倍，并且可以应用于任何系统动力学。此外，该研究还展示了其图编码方法解决复杂STL的能力以及对分布外STL规范的鲁棒性。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00562v1",
      "published_date": "2025-05-01 14:40:07 UTC",
      "updated_date": "2025-05-01 14:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:16:04.535817"
    },
    {
      "arxiv_id": "2505.00561v1",
      "title": "Learning to Learn with Quantum Optimization via Quantum Neural Networks",
      "title_zh": "通过量子神经网络学习量子优化中的元学习\n",
      "authors": [
        "Kuan-Cheng Chen",
        "Hiromichi Matsuyama",
        "Wei-Hao Huang"
      ],
      "abstract": "Quantum Approximate Optimization Algorithms (QAOA) promise efficient\nsolutions to classically intractable combinatorial optimization problems by\nharnessing shallow-depth quantum circuits. Yet, their performance and\nscalability often hinge on effective parameter optimization, which remains\nnontrivial due to rugged energy landscapes and hardware noise. In this work, we\nintroduce a quantum meta-learning framework that combines quantum neural\nnetworks, specifically Quantum Long Short-Term Memory (QLSTM) architectures,\nwith QAOA. By training the QLSTM optimizer on smaller graph instances, our\napproach rapidly generalizes to larger, more complex problems, substantially\nreducing the number of iterations required for convergence. Through\ncomprehensive benchmarks on Max-Cut and Sherrington-Kirkpatrick model\ninstances, we demonstrate that QLSTM-based optimizers converge faster and\nachieve higher approximation ratios compared to classical baselines, thereby\noffering a robust pathway toward scalable quantum optimization in the NISQ era.",
      "tldr_zh": "该研究提出了一种量子元学习框架，将量子神经网络(Quantum Neural Networks)，特别是量子长短期记忆网络(QLSTM)与量子近似优化算法(QAOA)相结合，用于解决QAOA中参数优化难题。通过在较小的图实例上训练QLSTM优化器，该方法可以快速推广到更大、更复杂的问题，从而显著减少收敛所需的迭代次数。在Max-Cut和Sherrington-Kirkpatrick模型实例上的综合基准测试表明，与经典基线相比，基于QLSTM的优化器收敛速度更快，并实现了更高的近似比率，为NISQ时代的可扩展量子优化提供了一条有效途径。\n",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00561v1",
      "published_date": "2025-05-01 14:39:26 UTC",
      "updated_date": "2025-05-01 14:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:16:16.468099"
    },
    {
      "arxiv_id": "2505.00557v1",
      "title": "Triggering Hallucinations in LLMs: A Quantitative Study of Prompt-Induced Hallucination in Large Language Models",
      "title_zh": "触发大型语言模型中的幻觉：大型语言模型中提示诱导幻觉的定量研究\n",
      "authors": [
        "Makoto Sato"
      ],
      "abstract": "Hallucinations in large language models (LLMs) present a growing challenge\nacross real-world applications, from healthcare to law, where factual\nreliability is essential. Despite advances in alignment and instruction tuning,\nLLMs can still generate outputs that are fluent yet fundamentally untrue.\nUnderstanding the cognitive dynamics that underlie these hallucinations remains\nan open problem. In this study, we propose a prompt-based framework to\nsystematically trigger and quantify hallucination: a Hallucination-Inducing\nPrompt (HIP), which synthetically fuses semantically distant concepts (e.g.,\nperiodic table of elements and tarot divination) in a misleading way, and a\nHallucination Quantifying Prompt (HQP), which scores the plausibility,\nconfidence, and coherence of the output. Controlled experiments across multiple\nLLMs revealed that HIPs consistently produced less coherent and more\nhallucinated responses than their null-fusion controls. These effects varied\nacross models, with reasoning-oriented LLMs showing distinct profiles from\ngeneral-purpose ones. Our framework provides a reproducible testbed for\nstudying hallucination vulnerability, and opens the door to developing safer,\nmore introspective LLMs that can detect and self-regulate the onset of\nconceptual instability.",
      "tldr_zh": "该研究提出了一个基于prompt的框架，用于系统性地触发和量化大型语言模型(LLMs)中的幻觉现象。该框架包含一个Hallucination-Inducing Prompt (HIP)，它将语义上遥远的概念进行融合，以及一个Hallucination Quantifying Prompt (HQP)，用于评估输出的可信度、置信度和连贯性。实验结果表明，HIPs能够持续产生比对照组更不连贯和更具幻觉性的回复。不同模型之间存在差异，面向推理的LLMs与通用LLMs表现出不同的特征。该框架提供了一个可复现的测试平台，用于研究幻觉漏洞，并为开发更安全、更内省的LLMs铺平了道路，使其能够检测和自我调节概念不稳定性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00557v1",
      "published_date": "2025-05-01 14:33:47 UTC",
      "updated_date": "2025-05-01 14:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:16:28.694733"
    },
    {
      "arxiv_id": "2505.00555v1",
      "title": "On the Mechanistic Interpretability of Neural Networks for Causality in Bio-statistics",
      "title_zh": "关于生物统计学中用于因果关系推断的神经网络的机制可解释性研究\n",
      "authors": [
        "Jean-Baptiste A. Conan"
      ],
      "abstract": "Interpretable insights from predictive models remain critical in\nbio-statistics, particularly when assessing causality, where classical\nstatistical and machine learning methods often provide inherent clarity. While\nNeural Networks (NNs) offer powerful capabilities for modeling complex\nbiological data, their traditional \"black-box\" nature presents challenges for\nvalidation and trust in high-stakes health applications. Recent advances in\nMechanistic Interpretability (MI) aim to decipher the internal computations\nlearned by these networks. This work investigates the application of MI\ntechniques to NNs within the context of causal inference for bio-statistics.\n  We demonstrate that MI tools can be leveraged to: (1) probe and validate the\ninternal representations learned by NNs, such as those estimating nuisance\nfunctions in frameworks like Targeted Minimum Loss-based Estimation (TMLE); (2)\ndiscover and visualize the distinct computational pathways employed by the\nnetwork to process different types of inputs, potentially revealing how\nconfounders and treatments are handled; and (3) provide methodologies for\ncomparing the learned mechanisms and extracted insights across statistical,\nmachine learning, and NN models, fostering a deeper understanding of their\nrespective strengths and weaknesses for causal bio-statistical analysis.",
      "tldr_zh": "该研究探索了将机制可解释性(Mechanistic Interpretability, MI)技术应用于生物统计学因果推断中神经网络(NNs)的可行性。研究表明，MI工具可以用于：(1)探究和验证NNs学习到的内部表示，例如在目标最小损失估计(TMLE)框架中估计干扰函数；(2)发现并可视化网络用于处理不同类型输入的计算路径，揭示混杂因素和处理方式的处理方式；(3)提供比较统计、机器学习和NN模型学习机制的方法，从而更深入地理解它们在因果生物统计分析中的优缺点。该工作旨在提高神经网络在生物统计学中因果推断的可信度和可验证性。\n",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00555v1",
      "published_date": "2025-05-01 14:30:34 UTC",
      "updated_date": "2025-05-01 14:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:16:40.520663"
    },
    {
      "arxiv_id": "2505.00533v1",
      "title": "Test-time Correlation Alignment",
      "title_zh": "测试时相关性对齐\n",
      "authors": [
        "Linjing You",
        "Jiabao Lu",
        "Xiayuan Huang"
      ],
      "abstract": "Deep neural networks often experience performance drops due to distribution\nshifts between training and test data. Although domain adaptation offers a\nsolution, privacy concerns restrict access to training data in many real-world\nscenarios. This restriction has spurred interest in Test-Time Adaptation (TTA),\nwhich adapts models using only unlabeled test data. However, current TTA\nmethods still face practical challenges: (1) a primary focus on instance-wise\nalignment, overlooking CORrelation ALignment (CORAL) due to missing source\ncorrelations; (2) complex backpropagation operations for model updating,\nresulting in overhead computation and (3) domain forgetting.\n  To address these challenges, we provide a theoretical analysis to investigate\nthe feasibility of Test-time Correlation Alignment (TCA), demonstrating that\ncorrelation alignment between high-certainty instances and test instances can\nenhance test performances with a theoretical guarantee. Based on this, we\npropose two simple yet effective algorithms: LinearTCA and LinearTCA+.\nLinearTCA applies a simple linear transformation to achieve both instance and\ncorrelation alignment without additional model updates, while LinearTCA+ serves\nas a plug-and-play module that can easily boost existing TTA methods. Extensive\nexperiments validate our theoretical insights and show that TCA methods\nsignificantly outperforms baselines across various tasks, benchmarks and\nbackbones. Notably, LinearTCA improves adaptation accuracy by 5.88% on\nOfficeHome dataset, while using only 4% maximum GPU memory usage and 0.6%\ncomputation time compared to the best baseline TTA method.",
      "tldr_zh": "该论文研究了测试时自适应(TTA)中由于缺少源域相关性而忽略相关性对齐(CORAL)的问题，并从理论上分析了测试时相关性对齐(TCA)的可行性。研究表明，高置信度样本和测试样本之间的相关性对齐可以提升测试性能。基于此，论文提出了两种简单有效的算法：LinearTCA和LinearTCA+。LinearTCA通过线性变换实现实例和相关性对齐，无需额外模型更新；LinearTCA+作为一个即插即用模块，可以提升现有TTA方法。实验结果表明，TCA方法在多个任务和数据集上显著优于基线方法，例如在OfficeHome数据集上，LinearTCA将自适应精度提高了5.88%，同时显著降低了GPU内存占用和计算时间。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00533v1",
      "published_date": "2025-05-01 13:59:13 UTC",
      "updated_date": "2025-05-01 13:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:16:52.794508"
    },
    {
      "arxiv_id": "2505.00515v1",
      "title": "Safety-Critical Traffic Simulation with Guided Latent Diffusion Model",
      "title_zh": "基于引导潜在扩散模型的安全关键交通仿真\n",
      "authors": [
        "Mingxing Peng",
        "Ruoyu Yao",
        "Xusen Guo",
        "Yuting Xie",
        "Xianda Chen",
        "Jun Ma"
      ],
      "abstract": "Safety-critical traffic simulation plays a crucial role in evaluating\nautonomous driving systems under rare and challenging scenarios. However,\nexisting approaches often generate unrealistic scenarios due to insufficient\nconsideration of physical plausibility and suffer from low generation\nefficiency. To address these limitations, we propose a guided latent diffusion\nmodel (LDM) capable of generating physically realistic and adversarial\nsafety-critical traffic scenarios. Specifically, our model employs a\ngraph-based variational autoencoder (VAE) to learn a compact latent space that\ncaptures complex multi-agent interactions while improving computational\nefficiency. Within this latent space, the diffusion model performs the\ndenoising process to produce realistic trajectories. To enable controllable and\nadversarial scenario generation, we introduce novel guidance objectives that\ndrive the diffusion process toward producing adversarial and behaviorally\nrealistic driving behaviors. Furthermore, we develop a sample selection module\nbased on physical feasibility checks to further enhance the physical\nplausibility of the generated scenarios. Extensive experiments on the nuScenes\ndataset demonstrate that our method achieves superior adversarial effectiveness\nand generation efficiency compared to existing baselines while maintaining a\nhigh level of realism. Our work provides an effective tool for realistic\nsafety-critical scenario simulation, paving the way for more robust evaluation\nof autonomous driving systems.",
      "tldr_zh": "该论文提出了一种引导潜在扩散模型(Guided Latent Diffusion Model)用于生成安全关键的交通场景，旨在解决现有方法生成场景不真实和效率低下的问题。该模型利用基于图的变分自编码器(VAE)学习紧凑的潜在空间，捕捉复杂的多智能体交互，并在该空间内使用扩散模型生成轨迹。通过引入新的引导目标，模型能够生成可控的、对抗性的驾驶行为。此外，样本选择模块基于物理可行性检查进一步提升了生成场景的物理合理性。在nuScenes数据集上的实验表明，该方法在对抗有效性和生成效率上优于现有基线，同时保持了高度的真实感，为自动驾驶系统的鲁棒性评估提供了有效工具。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00515v1",
      "published_date": "2025-05-01 13:33:34 UTC",
      "updated_date": "2025-05-01 13:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:17:04.786913"
    },
    {
      "arxiv_id": "2505.00506v1",
      "title": "HalluMix: A Task-Agnostic, Multi-Domain Benchmark for Real-World Hallucination Detection",
      "title_zh": "HalluMix：一个与任务无关的、多领域的真实幻觉检测基准",
      "authors": [
        "Deanna Emery",
        "Michael Goitia",
        "Freddie Vargus",
        "Iulia Neagu"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in high-stakes\ndomains, detecting hallucinated content$\\unicode{x2013}$text that is not\ngrounded in supporting evidence$\\unicode{x2013}$has become a critical\nchallenge. Existing benchmarks for hallucination detection are often\nsynthetically generated, narrowly focused on extractive question answering, and\nfail to capture the complexity of real-world scenarios involving multi-document\ncontexts and full-sentence outputs. We introduce the HalluMix Benchmark, a\ndiverse, task-agnostic dataset that includes examples from a range of domains\nand formats. Using this benchmark, we evaluate seven hallucination detection\nsystems$\\unicode{x2013}$both open and closed\nsource$\\unicode{x2013}$highlighting differences in performance across tasks,\ndocument lengths, and input representations. Our analysis highlights\nsubstantial performance disparities between short and long contexts, with\ncritical implications for real-world Retrieval Augmented Generation (RAG)\nimplementations. Quotient Detections achieves the best overall performance,\nwith an accuracy of 0.82 and an F1 score of 0.84.",
      "tldr_zh": "该论文提出了HalluMix基准，一个任务无关、多领域的真实世界幻觉检测数据集，旨在解决现有幻觉检测基准依赖合成数据、领域狭窄以及无法捕捉复杂现实场景的问题。HalluMix包含多种领域和格式的样本，用于评估七种幻觉检测系统，包括开源和闭源模型。实验结果表明，模型在长文本上下文中的表现明显下降，对实际的检索增强生成(RAG)应用具有重要意义。Quotient Detections在HalluMix上取得了最佳的整体性能，准确率为0.82，F1分数为0.84。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00506v1",
      "published_date": "2025-05-01 13:22:45 UTC",
      "updated_date": "2025-05-01 13:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:17:16.455417"
    },
    {
      "arxiv_id": "2505.00503v1",
      "title": "Variational OOD State Correction for Offline Reinforcement Learning",
      "title_zh": "离线强化学习中的变分 OOD 状态校正\n",
      "authors": [
        "Ke Jiang",
        "Wen Jiang",
        "Xiaoyang Tan"
      ],
      "abstract": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.",
      "tldr_zh": "本文针对离线强化学习中状态分布偏移问题，提出了一种名为密度感知安全感知(DASP)的OOD状态校正新方法。DASP鼓励智能体优先选择导致更高数据密度结果的动作，从而促进智能体在分布内(安全)区域内操作或返回。该方法在变分框架内优化目标，同时考虑决策的潜在结果及其密度，为安全决策提供关键的上下文信息。在离线MuJoCo和AntMaze套件上的大量实验验证了该方法的有效性和可行性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00503v1",
      "published_date": "2025-05-01 13:14:07 UTC",
      "updated_date": "2025-05-01 13:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:17:28.427173"
    },
    {
      "arxiv_id": "2505.00490v1",
      "title": "Optimal Interactive Learning on the Job via Facility Location Planning",
      "title_zh": "基于设施选址规划的最优在岗交互学习\n",
      "authors": [
        "Shivam Vats",
        "Michelle Zhao",
        "Patrick Callaghan",
        "Mingxi Jia",
        "Maxim Likhachev",
        "Oliver Kroemer",
        "George Konidaris"
      ],
      "abstract": "Collaborative robots must continually adapt to novel tasks and user\npreferences without overburdening the user. While prior interactive robot\nlearning methods aim to reduce human effort, they are typically limited to\nsingle-task scenarios and are not well-suited for sustained, multi-task\ncollaboration. We propose COIL (Cost-Optimal Interactive Learning) -- a\nmulti-task interaction planner that minimizes human effort across a sequence of\ntasks by strategically selecting among three query types (skill, preference,\nand help). When user preferences are known, we formulate COIL as an\nuncapacitated facility location (UFL) problem, which enables bounded-suboptimal\nplanning in polynomial time using off-the-shelf approximation algorithms. We\nextend our formulation to handle uncertainty in user preferences by\nincorporating one-step belief space planning, which uses these approximation\nalgorithms as subroutines to maintain polynomial-time performance. Simulated\nand physical experiments on manipulation tasks show that our framework\nsignificantly reduces the amount of work allocated to the human while\nmaintaining successful task completion.",
      "tldr_zh": "本文提出了一种名为COIL（Cost-Optimal Interactive Learning）的多任务交互规划器，旨在最小化协作机器人在持续多任务协作中所需的人工干预。COIL通过策略性地选择三种查询类型（技能、偏好和帮助）来优化学习过程。当用户偏好已知时，COIL被建模为一个无容量设施选址（UFL）问题，允许使用现成的近似算法在多项式时间内进行有界次优规划。此外，该研究还扩展了该模型，通过结合单步信念空间规划来处理用户偏好中的不确定性，并使用近似算法作为子程序，保持多项式时间性能。在操纵任务的仿真和物理实验中，COIL显著减少了分配给人类的工作量，同时保持了任务的成功完成。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to Robotics: Science and Systems (RSS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00490v1",
      "published_date": "2025-05-01 12:45:09 UTC",
      "updated_date": "2025-05-01 12:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:17:40.644761"
    },
    {
      "arxiv_id": "2505.00488v1",
      "title": "MULE: Multi-terrain and Unknown Load Adaptation for Effective Quadrupedal Locomotion",
      "title_zh": "MULE：用于有效四足运动的多地形和未知负载自适应\n",
      "authors": [
        "Vamshi Kumar Kurva",
        "Shishir Kolathaya"
      ],
      "abstract": "Quadrupedal robots are increasingly deployed for load-carrying tasks across\ndiverse terrains. While Model Predictive Control (MPC)-based methods can\naccount for payload variations, they often depend on predefined gait schedules\nor trajectory generators, limiting their adaptability in unstructured\nenvironments. To address these limitations, we propose an Adaptive\nReinforcement Learning (RL) framework that enables quadrupedal robots to\ndynamically adapt to both varying payloads and diverse terrains. The framework\nconsists of a nominal policy responsible for baseline locomotion and an\nadaptive policy that learns corrective actions to preserve stability and\nimprove command tracking under payload variations. We validate the proposed\napproach through large-scale simulation experiments in Isaac Gym and real-world\nhardware deployment on a Unitree Go1 quadruped. The controller was tested on\nflat ground, slopes, and stairs under both static and dynamic payload changes.\nAcross all settings, our adaptive controller consistently outperformed the\ncontroller in tracking body height and velocity commands, demonstrating\nenhanced robustness and adaptability without requiring explicit gait design or\nmanual tuning.",
      "tldr_zh": "该论文提出了一种自适应强化学习(RL)框架，名为MULE，旨在使四足机器人能够动态适应不同的地形和变化的载荷。该框架包含一个负责基础运动的标称策略和一个学习修正动作的自适应策略，以在载荷变化下保持稳定性和提高指令跟踪能力。通过在Isaac Gym中的大规模仿真实验和Unitree Go1四足机器人的真实硬件部署验证，结果表明，该自适应控制器在跟踪身体高度和速度指令方面始终优于基线控制器，无需显式步态设计或手动调整，从而增强了鲁棒性和适应性。MULE的有效性已在平面、斜坡和楼梯等多种地形以及静态和动态载荷变化下得到验证。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2505.00488v1",
      "published_date": "2025-05-01 12:41:35 UTC",
      "updated_date": "2025-05-01 12:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:17:52.724500"
    },
    {
      "arxiv_id": "2505.00487v1",
      "title": "Analysis of the vulnerability of machine learning regression models to adversarial attacks using data from 5G wireless networks",
      "title_zh": "基于 5G 无线网络数据分析机器学习回归模型对抗攻击的脆弱性\n",
      "authors": [
        "Leonid Legashev",
        "Artur Zhigalov",
        "Denis Parfenov"
      ],
      "abstract": "This article describes the process of creating a script and conducting an\nanalytical study of a dataset using the DeepMIMO emulator. An advertorial\nattack was carried out using the FGSM method to maximize the gradient. A\ncomparison is made of the effectiveness of binary classifiers in the task of\ndetecting distorted data. The dynamics of changes in the quality indicators of\nthe regression model were analyzed in conditions without adversarial attacks,\nduring an adversarial attack and when the distorted data was isolated. It is\nshown that an adversarial FGSM attack with gradient maximization leads to an\nincrease in the value of the MSE metric by 33% and a decrease in the R2\nindicator by 10% on average. The LightGBM binary classifier effectively\nidentifies data with adversarial anomalies with 98% accuracy. Regression\nmachine learning models are susceptible to adversarial attacks, but rapid\nanalysis of network traffic and data transmitted over the network makes it\npossible to identify malicious activity",
      "tldr_zh": "本文研究了基于5G无线网络数据的机器学习回归模型对对抗攻击的脆弱性。通过DeepMIMO仿真器生成数据集，并使用FGSM方法进行对抗攻击以最大化梯度。研究比较了二元分类器在检测失真数据方面的有效性，并分析了在无攻击、攻击中和隔离失真数据时回归模型质量指标的变化。结果表明，FGSM对抗攻击导致MSE指标平均增加33%，R2指标平均下降10%。LightGBM二元分类器能够以98%的准确率识别具有对抗异常的数据。结论是回归模型容易受到对抗攻击，但快速分析网络流量和数据可以识别恶意活动。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00487v1",
      "published_date": "2025-05-01 12:36:05 UTC",
      "updated_date": "2025-05-01 12:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:18:04.675032"
    },
    {
      "arxiv_id": "2505.00482v1",
      "title": "JointDiT: Enhancing RGB-Depth Joint Modeling with Diffusion Transformers",
      "title_zh": "JointDiT：利用扩散Transformer增强RGB-深度联合建模\n",
      "authors": [
        "Kwon Byung-Ki",
        "Qi Dai",
        "Lee Hyoseok",
        "Chong Luo",
        "Tae-Hyun Oh"
      ],
      "abstract": "We present JointDiT, a diffusion transformer that models the joint\ndistribution of RGB and depth. By leveraging the architectural benefit and\noutstanding image prior of the state-of-the-art diffusion transformer, JointDiT\nnot only generates high-fidelity images but also produces geometrically\nplausible and accurate depth maps. This solid joint distribution modeling is\nachieved through two simple yet effective techniques that we propose, i.e.,\nadaptive scheduling weights, which depend on the noise levels of each modality,\nand the unbalanced timestep sampling strategy. With these techniques, we train\nour model across all noise levels for each modality, enabling JointDiT to\nnaturally handle various combinatorial generation tasks, including joint\ngeneration, depth estimation, and depth-conditioned image generation by simply\ncontrolling the timestep of each branch. JointDiT demonstrates outstanding\njoint generation performance. Furthermore, it achieves comparable results in\ndepth estimation and depth-conditioned image generation, suggesting that joint\ndistribution modeling can serve as a replaceable alternative to conditional\ngeneration. The project page is available at\nhttps://byungki-k.github.io/JointDiT/.",
      "tldr_zh": "JointDiT 是一种扩散 Transformer 模型，用于对 RGB 图像和深度图的联合分布进行建模。它利用了先进的扩散 Transformer 的架构优势和卓越的图像先验知识，不仅生成高保真图像，还生成几何上合理且精确的深度图。该模型通过自适应调度权重（取决于每个模态的噪声水平）和非平衡时间步采样策略来实现可靠的联合分布建模。JointDiT 能够自然地处理各种组合生成任务，包括联合生成、深度估计和深度条件图像生成。实验结果表明，JointDiT 在联合生成方面表现出色，并在深度估计和深度条件图像生成方面取得了可比的结果，表明联合分布建模可以作为条件生成的可替代方案。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00482v1",
      "published_date": "2025-05-01 12:21:23 UTC",
      "updated_date": "2025-05-01 12:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:18:16.563659"
    },
    {
      "arxiv_id": "2505.00474v1",
      "title": "Rule-based Classifier Models",
      "title_zh": "基于规则的分类器模型\n",
      "authors": [
        "Cecilia Di Florio",
        "Huimin Dong",
        "Antonino Rotolo"
      ],
      "abstract": "We extend the formal framework of classifier models used in the legal domain.\nWhile the existing classifier framework characterises cases solely through the\nfacts involved, legal reasoning fundamentally relies on both facts and rules,\nparticularly the ratio decidendi. This paper presents an initial approach to\nincorporating sets of rules within a classifier. Our work is built on the work\nof Canavotto et al. (2023), which has developed the rule-based reason model of\nprecedential constraint within a hierarchy of factors. We demonstrate how\ndecisions for new cases can be inferred using this enriched rule-based\nclassifier framework. Additionally, we provide an example of how the time\nelement and the hierarchy of courts can be used in the new classifier\nframework.",
      "tldr_zh": "本文扩展了法律领域中使用的分类器模型的形式框架。现有框架仅通过案件事实来描述案例，而法律推理依赖于事实和规则，特别是判决理由(ratio decidendi)。本文提出了一种将规则集纳入分类器中的初步方法，基于Canavotto et al. (2023)的研究，该研究在因素层级结构中开发了先例约束的基于规则的推理模型。研究展示了如何使用这种增强的基于规则的分类器框架来推断新案例的决策，并提供了一个例子说明如何在新的分类器框架中使用时间要素和法院层级结构。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 1 figure. Extended version of a short paper accepted to\n  ICAIL 2025. This is the authors' version of the work. It is posted here for\n  your personal use",
      "pdf_url": "http://arxiv.org/pdf/2505.00474v1",
      "published_date": "2025-05-01 11:59:16 UTC",
      "updated_date": "2025-05-01 11:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:18:28.567776"
    },
    {
      "arxiv_id": "2505.00472v1",
      "title": "UserCentrix: An Agentic Memory-augmented AI Framework for Smart Spaces",
      "title_zh": "UserCentrix：一种用于智能空间的基于 Agent 的记忆增强型 AI 框架\n",
      "authors": [
        "Alaa Saleh",
        "Sasu Tarkoma",
        "Praveen Kumar Donta",
        "Naser Hossein Motlagh",
        "Schahram Dustdar",
        "Susanna Pirttikangas",
        "Lauri Lovén"
      ],
      "abstract": "Agentic AI, with its autonomous and proactive decision-making, has\ntransformed smart environments. By integrating Generative AI (GenAI) and\nmulti-agent systems, modern AI frameworks can dynamically adapt to user\npreferences, optimize data management, and improve resource allocation. This\npaper introduces UserCentrix, an agentic memory-augmented AI framework designed\nto enhance smart spaces through dynamic, context-aware decision-making. This\nframework integrates personalized Large Language Model (LLM) agents that\nleverage user preferences and LLM memory management to deliver proactive and\nadaptive assistance. Furthermore, it incorporates a hybrid hierarchical control\nsystem, balancing centralized and distributed processing to optimize real-time\nresponsiveness while maintaining global situational awareness. UserCentrix\nachieves resource-efficient AI interactions by embedding memory-augmented\nreasoning, cooperative agent negotiation, and adaptive orchestration\nstrategies. Our key contributions include (i) a self-organizing framework with\nproactive scaling based on task urgency, (ii) a Value of Information\n(VoI)-driven decision-making process, (iii) a meta-reasoning personal LLM\nagent, and (iv) an intelligent multi-agent coordination system for seamless\nenvironment adaptation. Experimental results across various models confirm the\neffectiveness of our approach in enhancing response accuracy, system\nefficiency, and computational resource management in real-world application.",
      "tldr_zh": "UserCentrix 是一种基于Agent的、记忆增强的AI框架，旨在提升智能空间的用户体验。它通过集成个性化的大语言模型(LLM) Agent，利用用户偏好和LLM记忆管理，提供主动和自适应的帮助。该框架采用混合层级控制系统，平衡集中式和分布式处理，优化实时响应并保持全局感知。UserCentrix 通过嵌入记忆增强推理、协同Agent协商和自适应编排策略，实现了资源高效的AI交互。实验结果表明，该方法在提高响应准确性、系统效率和计算资源管理方面表现出色。\n",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00472v1",
      "published_date": "2025-05-01 11:54:49 UTC",
      "updated_date": "2025-05-01 11:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:18:40.569570"
    },
    {
      "arxiv_id": "2505.00467v1",
      "title": "Red Teaming Large Language Models for Healthcare",
      "title_zh": "医疗保健领域大语言模型的红队测试",
      "authors": [
        "Vahid Balazadeh",
        "Michael Cooper",
        "David Pellow",
        "Atousa Assadi",
        "Jennifer Bell",
        "Jim Fackler",
        "Gabriel Funingana",
        "Spencer Gable-Cook",
        "Anirudh Gangadhar",
        "Abhishek Jaiswal",
        "Sumanth Kaja",
        "Christopher Khoury",
        "Randy Lin",
        "Kaden McKeen",
        "Sara Naimimohasses",
        "Khashayar Namdar",
        "Aviraj Newatia",
        "Allan Pang",
        "Anshul Pattoo",
        "Sameer Peesapati",
        "Diana Prepelita",
        "Bogdana Rakova",
        "Saba Sadatamin",
        "Rafael Schulman",
        "Ajay Shah",
        "Syed Azhar Shah",
        "Syed Ahmar Shah",
        "Babak Taati",
        "Balagopal Unnikrishnan",
        "Stephanie Williams",
        "Rahul G Krishnan"
      ],
      "abstract": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.",
      "tldr_zh": "本文介绍了在2024年机器学习医疗保健会议上举办的“医疗保健大型语言模型红队”研讨会的设计过程和发现。与会者（包括计算和临床专家）试图发现LLM的漏洞，即可能导致临床危害的真实临床提示。通过与临床医生进行红队测试，可以识别缺乏临床专业知识的LLM开发者可能无法识别的LLM漏洞。文章报告了发现的漏洞，对其进行了分类，并提供了一项复制研究的结果，该研究评估了所有提供的LLM中的漏洞。该研究强调了临床医生参与红队测试对于确保LLM在医疗保健领域安全可靠应用的重要性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00467v1",
      "published_date": "2025-05-01 11:43:27 UTC",
      "updated_date": "2025-05-01 11:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:18:52.585446"
    },
    {
      "arxiv_id": "2505.00455v1",
      "title": "Data Therapist: Eliciting Domain Knowledge from Subject Matter Experts Using Large Language Models",
      "title_zh": "数据治疗师：利用大型语言模型从领域专家处获取领域知识\n",
      "authors": [
        "Sungbok Shin",
        "Hyeon Jeon",
        "Sanghyun Hong",
        "Niklas Elmqvist"
      ],
      "abstract": "Effective data visualization requires not only technical proficiency but also\na deep understanding of the domain-specific context in which data exists. This\ncontext often includes tacit knowledge about data provenance, quality, and\nintended use, which is rarely explicit in the dataset itself. We present the\nData Therapist, a web-based tool that helps domain experts externalize this\nimplicit knowledge through a mixed-initiative process combining iterative Q&A\nwith interactive annotation. Powered by a large language model, the system\nanalyzes user-supplied datasets, prompts users with targeted questions, and\nallows annotation at varying levels of granularity. The resulting structured\nknowledge base can inform both human and automated visualization design. We\nevaluated the tool in a qualitative study involving expert pairs from Molecular\nBiology, Accounting, Political Science, and Usable Security. The study revealed\nrecurring patterns in how experts reason about their data and highlights areas\nwhere AI support can improve visualization design.",
      "tldr_zh": "本文介绍了一个名为Data Therapist的工具，该工具利用大型语言模型(LLM)帮助领域专家提取关于数据的隐性知识。该工具通过迭代问答和交互式标注，将专家对数据来源、质量和预期用途的隐性知识显性化。Data Therapist分析用户提供的数据集，提出针对性问题，并允许不同粒度的标注，从而构建结构化的知识库，为人类和自动化可视化设计提供信息。一项涉及分子生物学、会计学、政治学和可用安全领域的专家对的定性研究表明，该工具能够有效帮助专家梳理数据，并揭示了AI支持可以改进可视化设计的领域。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to IEEE VIS2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00455v1",
      "published_date": "2025-05-01 11:10:17 UTC",
      "updated_date": "2025-05-01 11:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:19:04.676571"
    },
    {
      "arxiv_id": "2505.00439v1",
      "title": "Per-Domain Generalizing Policies: On Validation Instances and Scaling Behavior",
      "title_zh": "领域泛化策略：关于验证实例和缩放行为的研究\n",
      "authors": [
        "Timo P. Gros",
        "Nicola J. Müller",
        "Daniel Fiser",
        "Isabel Valera",
        "Verena Wolf",
        "Jörg Hoffmann"
      ],
      "abstract": "Recent work has shown that successful per-domain generalizing action policies\ncan be learned. Scaling behavior, from small training instances to large test\ninstances, is the key objective; and the use of validation instances larger\nthan training instances is one key to achieve it. Prior work has used fixed\nvalidation sets. Here, we introduce a method generating the validation set\ndynamically, on the fly, increasing instance size so long as informative and\nfeasible.We also introduce refined methodology for evaluating scaling behavior,\ngenerating test instances systematically to guarantee a given confidence in\ncoverage performance for each instance size. In experiments, dynamic validation\nimproves scaling behavior of GNN policies in all 9 domains used.",
      "tldr_zh": "本文研究了如何学习具有领域泛化能力的行动策略，重点关注从小规模训练实例到大规模测试实例的扩展性。核心方法是动态生成验证集，即根据策略的性能，逐步增大验证实例的规模，直到验证集提供的信息不再有效或不可行。此外，论文还提出了一种精细的评估方法，系统地生成测试实例，以保证在每个实例规模下覆盖性能的置信度。实验结果表明，动态验证能够显著提升GNN策略在9个领域中的扩展性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 tables, 3 figures, 3 algorithms",
      "pdf_url": "http://arxiv.org/pdf/2505.00439v1",
      "published_date": "2025-05-01 10:32:02 UTC",
      "updated_date": "2025-05-01 10:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:19:16.586434"
    },
    {
      "arxiv_id": "2505.00416v1",
      "title": "ScaleTrack: Scaling and back-tracking Automated GUI Agents",
      "title_zh": "ScaleTrack：扩展和回溯自动化 GUI 代理",
      "authors": [
        "Jing Huang",
        "Zhixiong Zeng",
        "Wenkang Han",
        "Yufeng Zhong",
        "Liming Zheng",
        "Shuai Fu",
        "Jingyuan Chen",
        "Lin Ma"
      ],
      "abstract": "Automated GUI agents aims to facilitate user interaction by automatically\nperforming complex tasks in digital environments, such as web, mobile, desktop\ndevices. It receives textual task instruction and GUI description to generate\nexecutable actions (\\emph{e.g.}, click) and operation boxes step by step.\nTraining a GUI agent mainly involves grounding and planning stages, in which\nthe GUI grounding focuses on finding the execution coordinates according to the\ntask, while the planning stage aims to predict the next action based on\nhistorical actions. However, previous work suffers from the limitations of\ninsufficient training data for GUI grounding, as well as the ignorance of\nbacktracking historical behaviors for GUI planning. To handle the above\nchallenges, we propose ScaleTrack, a training framework by scaling grounding\nand backtracking planning for automated GUI agents. We carefully collected GUI\nsamples of different synthesis criterions from a wide range of sources, and\nunified them into the same template for training GUI grounding models.\nMoreover, we design a novel training strategy that predicts the next action\nfrom the current GUI image, while also backtracking the historical actions that\nled to the GUI image. In this way, ScaleTrack explains the correspondence\nbetween GUI images and actions, which effectively describes the evolution rules\nof the GUI environment. Extensive experimental results demonstrate the\neffectiveness of ScaleTrack. Data and code will be available at url.",
      "tldr_zh": "本文提出了ScaleTrack框架，旨在解决自动GUI智能体训练中GUI grounding数据不足以及GUI规划忽略历史行为回溯的问题。ScaleTrack通过收集并统一不同来源的GUI样本，用于训练GUI grounding模型，从而扩大了训练数据规模。此外，该框架设计了一种新的训练策略，不仅预测当前GUI图像的下一步动作，还回溯导致该GUI图像的历史动作。这种方式有效描述了GUI环境的演变规则，解释了GUI图像和动作之间的对应关系。实验结果表明，ScaleTrack框架的有效性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00416v1",
      "published_date": "2025-05-01 09:27:13 UTC",
      "updated_date": "2025-05-01 09:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:19:28.604917"
    },
    {
      "arxiv_id": "2505.00409v1",
      "title": "Perceptual Implications of Automatic Anonymization in Pathological Speech",
      "title_zh": "病理语音中自动匿名化的感知影响\n",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Saba Afza",
        "Tri-Thien Nguyen",
        "Lukas Buess",
        "Maryam Parvin",
        "Tomas Arias-Vergara",
        "Paula Andrea Perez-Toro",
        "Hiu Ching Hung",
        "Mahshad Lotfinia",
        "Thomas Gorges",
        "Elmar Noeth",
        "Maria Schuster",
        "Seung Hee Yang",
        "Andreas Maier"
      ],
      "abstract": "Automatic anonymization techniques are essential for ethical sharing of\npathological speech data, yet their perceptual consequences remain\nunderstudied. This study presents the first comprehensive human-centered\nanalysis of anonymized pathological speech, using a structured perceptual\nprotocol involving ten native and non-native German listeners with diverse\nlinguistic, clinical, and technical backgrounds. Listeners evaluated\nanonymized-original utterance pairs from 180 speakers spanning Cleft Lip and\nPalate, Dysarthria, Dysglossia, Dysphonia, and age-matched healthy controls.\nSpeech was anonymized using state-of-the-art automatic methods (equal error\nrates in the range of 30-40%). Listeners completed Turing-style discrimination\nand quality rating tasks under zero-shot (single-exposure) and few-shot\n(repeated-exposure) conditions. Discrimination accuracy was high overall (91%\nzero-shot; 93% few-shot), but varied by disorder (repeated-measures ANOVA:\np=0.007), ranging from 96% (Dysarthria) to 86% (Dysphonia). Anonymization\nconsistently reduced perceived quality (from 83% to 59%, p<0.001), with\npathology-specific degradation patterns (one-way ANOVA: p=0.005). Native\nlisteners rated original speech slightly higher than non-native listeners\n(Delta=4%, p=0.199), but this difference nearly disappeared after anonymization\n(Delta=1%, p=0.724). No significant gender-based bias was observed. Critically,\nhuman perceptual outcomes did not correlate with automatic privacy or clinical\nutility metrics. These results underscore the need for listener-informed,\ndisorder- and context-specific anonymization strategies that preserve privacy\nwhile maintaining interpretability, communicative functions, and diagnostic\nutility, especially for vulnerable populations such as children.",
      "tldr_zh": "本研究首次对病理语音自动匿名化技术的感知影响进行了以人为中心的综合分析。研究招募了不同背景的听众，评估了来自多种语音障碍（包括唇腭裂、构音障碍、发音障碍、发声障碍）患者以及健康对照组的匿名化语音与原始语音。研究发现，尽管听众的区分准确率很高（零样本91%，少样本93%），但匿名化显著降低了语音质量。不同语音障碍的匿名化效果存在差异，且人类感知结果与自动隐私或临床效用指标不相关。研究强调，需要针对特定障碍和情境，采取以听众为中心的匿名化策略，在保护隐私的同时，维持语音的可解释性、交流功能和诊断效用。\n",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00409v1",
      "published_date": "2025-05-01 09:03:03 UTC",
      "updated_date": "2025-05-01 09:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:19:41.014594"
    },
    {
      "arxiv_id": "2505.00402v1",
      "title": "DeepSTA: A Spatial-Temporal Attention Network for Logistics Delivery Timely Rate Prediction in Anomaly Conditions",
      "title_zh": "DeepSTA：用于异常条件下物流配送及时率预测的时空注意力网络\n",
      "authors": [
        "Jinhui Yi",
        "Huan Yan",
        "Haotian Wang",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Prediction of couriers' delivery timely rates in advance is essential to the\nlogistics industry, enabling companies to take preemptive measures to ensure\nthe normal operation of delivery services. This becomes even more critical\nduring anomaly conditions like the epidemic outbreak, during which couriers'\ndelivery timely rate will decline markedly and fluctuates significantly.\nExisting studies pay less attention to the logistics scenario. Moreover, many\nworks focusing on prediction tasks in anomaly scenarios fail to explicitly\nmodel abnormal events, e.g., treating external factors equally with other\nfeatures, resulting in great information loss. Further, since some anomalous\nevents occur infrequently, traditional data-driven methods perform poorly in\nthese scenarios. To deal with them, we propose a deep spatial-temporal\nattention model, named DeepSTA. To be specific, to avoid information loss, we\ndesign an anomaly spatio-temporal learning module that employs a recurrent\nneural network to model incident information. Additionally, we utilize Node2vec\nto model correlations between road districts, and adopt graph neural networks\nand long short-term memory to capture the spatial-temporal dependencies of\ncouriers. To tackle the issue of insufficient training data in abnormal\ncircumstances, we propose an anomaly pattern attention module that adopts a\nmemory network for couriers' anomaly feature patterns storage via attention\nmechanisms. The experiments on real-world logistics datasets during the\nCOVID-19 outbreak in 2022 show the model outperforms the best baselines by\n12.11% in MAE and 13.71% in MSE, demonstrating its superior performance over\nmultiple competitive baselines.",
      "tldr_zh": "该论文提出了一种名为DeepSTA的深度时空注意力网络，用于预测异常情况下物流配送的及时率。该模型针对现有研究对物流场景关注不足以及异常事件建模不明确的问题，设计了异常时空学习模块，利用循环神经网络对事件信息进行建模，避免信息损失。同时，利用Node2vec建模道路区域间的相关性，并采用图神经网络和LSTM捕捉配送员的时空依赖性。此外，为了解决异常情况下训练数据不足的问题，提出了异常模式注意力模块，通过注意力机制存储配送员的异常特征模式。在2022年COVID-19爆发期间的真实物流数据集上的实验结果表明，DeepSTA在MAE和MSE指标上分别优于最佳基线12.11%和13.71%。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CIKM 2023",
      "pdf_url": "http://arxiv.org/pdf/2505.00402v1",
      "published_date": "2025-05-01 08:48:45 UTC",
      "updated_date": "2025-05-01 08:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:19:52.863677"
    },
    {
      "arxiv_id": "2505.00375v1",
      "title": "Learning to Estimate Package Delivery Time in Mixed Imbalanced Delivery and Pickup Logistics Services",
      "title_zh": "学习在混合不平衡的收派物流服务中预估包裹送达时间\n",
      "authors": [
        "Jinhui Yi",
        "Huan Yan",
        "Haotian Wang",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Accurately estimating package delivery time is essential to the logistics\nindustry, which enables reasonable work allocation and on-time service\nguarantee. This becomes even more necessary in mixed logistics scenarios where\ncouriers handle a high volume of delivery and a smaller number of pickup\nsimultaneously. However, most of the related works treat the pickup and\ndelivery patterns on couriers' decision behavior equally, neglecting that the\npickup has a greater impact on couriers' decision-making compared to the\ndelivery due to its tighter time constraints. In such context, we have three\nmain challenges: 1) multiple spatiotemporal factors are intricately\ninterconnected, significantly affecting couriers' delivery behavior; 2) pickups\nhave stricter time requirements but are limited in number, making it\nchallenging to model their effects on couriers' delivery process; 3) couriers'\nspatial mobility patterns are critical determinants of their delivery behavior,\nbut have been insufficiently explored. To deal with these, we propose TransPDT,\na Transformer-based multi-task package delivery time prediction model. We first\nemploy the Transformer encoder architecture to capture the spatio-temporal\ndependencies of couriers' historical travel routes and pending package sets.\nThen we design the pattern memory to learn the patterns of pickup in the\nimbalanced dataset via attention mechanism. We also set the route prediction as\nan auxiliary task of delivery time prediction, and incorporate the prior\ncourier spatial movement regularities in prediction. Extensive experiments on\nreal industry-scale datasets demonstrate the superiority of our method. A\nsystem based on TransPDT is deployed internally in JD Logistics to track more\nthan 2000 couriers handling hundreds of thousands of packages per day in\nBeijing.",
      "tldr_zh": "该论文提出了TransPDT，一个基于Transformer的多任务模型，用于解决混合不平衡的快递和取件物流服务中包裹递送时间的准确预估问题。TransPDT利用Transformer编码器捕捉快递员历史路线和待处理包裹集合的时空依赖性，并通过模式记忆(pattern memory)学习不平衡数据集中取件模式。同时，TransPDT将路线预测作为辅助任务，融入快递员的空间移动规律。在真实工业数据集上的实验表明，TransPDT优于现有方法。该系统已在京东物流内部署，用于跟踪北京超过2000名快递员，每日处理数十万个包裹。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACM SIGSPATIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.00375v1",
      "published_date": "2025-05-01 08:00:22 UTC",
      "updated_date": "2025-05-01 08:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:20:05.016357"
    },
    {
      "arxiv_id": "2505.00368v1",
      "title": "Urban Air Mobility as a System of Systems: An LLM-Enhanced Holonic Approach",
      "title_zh": "城市空中交通作为一种系统之系统：一种基于 LLM 增强的 Holonic 方法\n",
      "authors": [
        "Ahmed R. Sadik",
        "Muhammad Ashfaq",
        "Niko Mäkitalo",
        "Tommi Mikkonen"
      ],
      "abstract": "Urban Air Mobility (UAM) is an emerging System of System (SoS) that faces\nchallenges in system architecture, planning, task management, and execution.\nTraditional architectural approaches struggle with scalability, adaptability,\nand seamless resource integration within dynamic and complex environments. This\npaper presents an intelligent holonic architecture that incorporates Large\nLanguage Model (LLM) to manage the complexities of UAM. Holons function semi\nautonomously, allowing for real time coordination among air taxis, ground\ntransport, and vertiports. LLMs process natural language inputs, generate\nadaptive plans, and manage disruptions such as weather changes or airspace\nclosures.Through a case study of multimodal transportation with electric\nscooters and air taxis, we demonstrate how this architecture enables dynamic\nresource allocation, real time replanning, and autonomous adaptation without\ncentralized control, creating more resilient and efficient urban transportation\nnetworks. By advancing decentralized control and AI driven adaptability, this\nwork lays the groundwork for resilient, human centric UAM ecosystems, with\nfuture efforts targeting hybrid AI integration and real world validation.",
      "tldr_zh": "本文提出了一种基于LLM增强的Holonic架构，用于解决城市空中交通(UAM)作为复杂系统时面临的系统架构、规划、任务管理和执行等挑战。该架构利用Holons的半自治特性，实现空中出租车、地面交通和垂直起降机场之间的实时协同。LLM负责处理自然语言输入，生成自适应计划，并管理诸如天气变化或空域关闭等突发事件。通过电动滑板车和空中出租车的多模式交通案例研究，验证了该架构在动态资源分配、实时重新规划和自主适应方面的能力，为构建更具弹性和效率的城市交通网络奠定了基础。该研究为以人为本的UAM生态系统提供了基础，未来的工作将侧重于混合AI集成和实际验证。\n",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00368v1",
      "published_date": "2025-05-01 07:39:11 UTC",
      "updated_date": "2025-05-01 07:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:20:16.847518"
    },
    {
      "arxiv_id": "2505.00367v1",
      "title": "KoACD: The First Korean Adolescent Dataset for Cognitive Distortion Analysis",
      "title_zh": "KoACD：首个用于认知扭曲分析的韩国青少年数据集\n",
      "authors": [
        "JunSeo Kim",
        "HyeHyeon Kim"
      ],
      "abstract": "Cognitive distortion refers to negative thinking patterns that can lead to\nmental health issues like depression and anxiety in adolescents. Previous\nstudies using natural language processing (NLP) have focused mainly on\nsmall-scale adult datasets, with limited research on adolescents. This study\nintroduces KoACD, the first large-scale dataset of cognitive distortions in\nKorean adolescents, containing 108,717 instances. We applied a multi-Large\nLanguage Model (LLM) negotiation method to refine distortion classification and\ngenerate synthetic data using two approaches: cognitive clarification for\ntextual clarity and cognitive balancing for diverse distortion representation.\nValidation through LLMs and expert evaluations showed that while LLMs\nclassified distortions with explicit markers, they struggled with\ncontext-dependent reasoning, where human evaluators demonstrated higher\naccuracy. KoACD aims to enhance future research on cognitive distortion\ndetection.",
      "tldr_zh": "该研究推出了KoACD，首个用于认知扭曲分析的韩国青少年大规模数据集，包含108,717个实例。研究采用多LLM协商方法，改进扭曲分类，并使用认知澄清和认知平衡两种方法生成合成数据。通过LLM和专家评估验证，发现LLM在分类具有显式标记的扭曲时表现良好，但在依赖上下文推理时表现不佳，人类评估者表现出更高的准确性。KoACD旨在促进未来对认知扭曲检测的研究。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00367v1",
      "published_date": "2025-05-01 07:37:18 UTC",
      "updated_date": "2025-05-01 07:37:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:20:28.601397"
    },
    {
      "arxiv_id": "2505.00365v1",
      "title": "SacFL: Self-Adaptive Federated Continual Learning for Resource-Constrained End Devices",
      "title_zh": "SacFL：面向资源受限终端设备的自适应联邦持续学习\n",
      "authors": [
        "Zhengyi Zhong",
        "Weidong Bao",
        "Ji Wang",
        "Jianguo Chen",
        "Lingjuan Lyu",
        "Wei Yang Bryan Lim"
      ],
      "abstract": "The proliferation of end devices has led to a distributed computing paradigm,\nwherein on-device machine learning models continuously process diverse data\ngenerated by these devices. The dynamic nature of this data, characterized by\ncontinuous changes or data drift, poses significant challenges for on-device\nmodels. To address this issue, continual learning (CL) is proposed, enabling\nmachine learning models to incrementally update their knowledge and mitigate\ncatastrophic forgetting. However, the traditional centralized approach to CL is\nunsuitable for end devices due to privacy and data volume concerns. In this\ncontext, federated continual learning (FCL) emerges as a promising solution,\npreserving user data locally while enhancing models through collaborative\nupdates. Aiming at the challenges of limited storage resources for CL, poor\nautonomy in task shift detection, and difficulty in coping with new adversarial\ntasks in FCL scenario, we propose a novel FCL framework named SacFL. SacFL\nemploys an Encoder-Decoder architecture to separate task-robust and\ntask-sensitive components, significantly reducing storage demands by retaining\nlightweight task-sensitive components for resource-constrained end devices.\nMoreover, $\\rm{SacFL}$ leverages contrastive learning to introduce an\nautonomous data shift detection mechanism, enabling it to discern whether a new\ntask has emerged and whether it is a benign task. This capability ultimately\nallows the device to autonomously trigger CL or attack defense strategy without\nadditional information, which is more practical for end devices. Comprehensive\nexperiments conducted on multiple text and image datasets, such as Cifar100 and\nTHUCNews, have validated the effectiveness of $\\rm{SacFL}$ in both\nclass-incremental and domain-incremental scenarios. Furthermore, a demo system\nhas been developed to verify its practicality.",
      "tldr_zh": "本文提出了一种名为SacFL的自适应联邦持续学习(FCL)框架，旨在解决资源受限的终端设备上的持续学习问题。SacFL采用Encoder-Decoder架构分离任务鲁棒和任务敏感组件，通过保留轻量级的任务敏感组件来显著降低存储需求。此外，SacFL利用对比学习引入自主数据漂移检测机制，无需额外信息即可判断新任务是否出现以及是否为良性任务，从而自主触发持续学习或防御策略。在Cifar100和THUCNews等多个文本和图像数据集上的实验验证了SacFL在类增量和域增量场景下的有效性。同时，开发了一个演示系统来验证其可行性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by TNNLS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00365v1",
      "published_date": "2025-05-01 07:26:35 UTC",
      "updated_date": "2025-05-01 07:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:20:40.635331"
    },
    {
      "arxiv_id": "2505.00359v1",
      "title": "TNStream: Applying Tightest Neighbors to Micro-Clusters to Define Multi-Density Clusters in Streaming Data",
      "title_zh": "TNStream：应用最紧密邻居于微簇以定义流数据中的多密度聚类\n",
      "authors": [
        "Qifen Zeng",
        "Haomin Bao",
        "Yuanzhuo Hu",
        "Zirui Zhang",
        "Yuheng Zheng",
        "Luosheng Wen"
      ],
      "abstract": "In data stream clustering, systematic theory of stream clustering algorithms\nremains relatively scarce. Recently, density-based methods have gained\nattention. However, existing algorithms struggle to simultaneously handle\narbitrarily shaped, multi-density, high-dimensional data while maintaining\nstrong outlier resistance. Clustering quality significantly deteriorates when\ndata density varies complexly. This paper proposes a clustering algorithm based\non the novel concept of Tightest Neighbors and introduces a data stream\nclustering theory based on the Skeleton Set. Based on these theories, this\npaper develops a new method, TNStream, a fully online algorithm. The algorithm\nadaptively determines the clustering radius based on local similarity,\nsummarizing the evolution of multi-density data streams in micro-clusters. It\nthen applies a Tightest Neighbors-based clustering algorithm to form final\nclusters. To improve efficiency in high-dimensional cases, Locality-Sensitive\nHashing (LSH) is employed to structure micro-clusters, addressing the challenge\nof storing k-nearest neighbors. TNStream is evaluated on various synthetic and\nreal-world datasets using different clustering metrics. Experimental results\ndemonstrate its effectiveness in improving clustering quality for multi-density\ndata and validate the proposed data stream clustering theory.",
      "tldr_zh": "本文提出了一种名为TNStream的流数据聚类算法，该算法基于“最紧邻居”(Tightest Neighbors)的新概念和“骨架集”(Skeleton Set)的流数据聚类理论。TNStream通过局部相似性自适应地确定聚类半径，并用微簇(micro-clusters)概括多密度数据流的演变。该算法随后应用基于最紧邻居的聚类算法形成最终簇。为了提高高维数据的效率，TNStream采用局部敏感哈希(LSH)来构建微簇，从而解决存储k近邻的挑战。实验结果表明，TNStream在多密度数据的聚类质量方面表现出色，并验证了所提出的流数据聚类理论的有效性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "68T05, 68W20",
        "H.2.8; I.5.3"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures, 8 tables, under review at Expert Systems with\n  Applications (ESWA)",
      "pdf_url": "http://arxiv.org/pdf/2505.00359v1",
      "published_date": "2025-05-01 07:15:20 UTC",
      "updated_date": "2025-05-01 07:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:20:52.921668"
    },
    {
      "arxiv_id": "2505.00358v1",
      "title": "R&B: Domain Regrouping and Data Mixture Balancing for Efficient Foundation Model Training",
      "title_zh": "R&B：用于高效基础模型训练的领域重组和数据混合平衡\n",
      "authors": [
        "Albert Ge",
        "Tzu-Heng Huang",
        "John Cooper",
        "Avi Trost",
        "Ziyi Chu",
        "Satya Sai Srinath Namburi GNVV",
        "Ziyang Cai",
        "Kendall Park",
        "Nicholas Roberts",
        "Frederic Sala"
      ],
      "abstract": "Data mixing strategies have successfully reduced the costs involved in\ntraining language models. While promising, such methods suffer from two flaws.\nFirst, they rely on predetermined data domains (e.g., data sources, task\ntypes), which may fail to capture critical semantic nuances, leaving\nperformance on the table. Second, these methods scale with the number of\ndomains in a computationally prohibitive way. We address these challenges via\nR&B, a framework that re-partitions training data based on semantic similarity\n(Regroup) to create finer-grained domains, and efficiently optimizes the data\ncomposition (Balance) by leveraging a Gram matrix induced by domain gradients\nobtained throughout training. Unlike prior works, it removes the need for\nadditional compute to obtain evaluation information such as losses or\ngradients. We analyze this technique under standard regularity conditions and\nprovide theoretical insights that justify R&B's effectiveness compared to\nnon-adaptive mixing approaches. Empirically, we demonstrate the effectiveness\nof R&B on five diverse datasets ranging from natural language to reasoning and\nmultimodal tasks. With as little as 0.01% additional compute overhead, R&B\nmatches or exceeds the performance of state-of-the-art data mixing strategies.",
      "tldr_zh": "该论文提出了R&B框架，旨在提高基础模型训练的数据混合效率。R&B通过语义相似性重新划分训练数据（Regroup），创建更细粒度的领域，并利用领域梯度诱导的Gram矩阵高效优化数据组成（Balance）。与现有方法不同，R&B无需额外计算即可获得损失或梯度等评估信息。理论分析表明，R&B相比非自适应混合方法更有效。实验结果表明，在自然语言、推理和多模态任务等五个数据集上，R&B仅需增加0.01%的计算开销，即可达到或超过最先进的数据混合策略的性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00358v1",
      "published_date": "2025-05-01 07:08:19 UTC",
      "updated_date": "2025-05-01 07:08:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:21:04.681108"
    },
    {
      "arxiv_id": "2505.00350v1",
      "title": "Optimizing Deep Neural Networks using Safety-Guided Self Compression",
      "title_zh": "使用安全引导的自压缩优化深度神经网络\n",
      "authors": [
        "Mohammad Zbeeb",
        "Mariam Salman",
        "Mohammad Bazzi",
        "Ammar Mohanna"
      ],
      "abstract": "The deployment of deep neural networks on resource-constrained devices\nnecessitates effective model com- pression strategies that judiciously balance\nthe reduction of model size with the preservation of performance. This study\nintroduces a novel safety-driven quantization framework that leverages\npreservation sets to systematically prune and quantize neural network weights,\nthereby optimizing model complexity without compromising accuracy. The proposed\nmethodology is rigorously evaluated on both a convolutional neural network\n(CNN) and an attention-based language model, demonstrating its applicability\nacross diverse architectural paradigms. Experimental results reveal that our\nframework achieves up to a 2.5% enhancement in test accuracy relative to the\noriginal unquantized models while maintaining 60% of the initial model size. In\ncomparison to conventional quantization techniques, our approach not only\naugments generalization by eliminating parameter noise and retaining essential\nweights but also reduces variance, thereby ensuring the retention of critical\nmodel features. These findings underscore the efficacy of safety-driven\nquantization as a robust and reliable strategy for the efficient optimization\nof deep learn- ing models. The implementation and comprehensive experimental\nevaluations of our framework are publicly accessible at GitHub.",
      "tldr_zh": "该研究提出了一种基于安全引导的自压缩量化框架，用于优化深度神经网络在资源受限设备上的部署。该方法利用 preservation sets 系统地剪枝和量化神经网络权重，在不牺牲准确率的前提下降低模型复杂度。实验在卷积神经网络(CNN)和基于注意力机制的语言模型上验证了该方法的有效性。结果表明，该框架在保持初始模型60%大小的同时，测试精度比原始未量化模型提高了2.5%。与传统量化技术相比，该方法通过消除参数噪声和保留关键权重来增强泛化能力，并降低方差，确保关键模型特征的保留。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "A Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.00350v1",
      "published_date": "2025-05-01 06:50:30 UTC",
      "updated_date": "2025-05-01 06:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:21:16.877586"
    },
    {
      "arxiv_id": "2505.00347v1",
      "title": "Pushing the Limits of Low-Bit Optimizers: A Focus on EMA Dynamics",
      "title_zh": "突破低比特优化器的极限：聚焦 EMA 动态",
      "authors": [
        "Cong Xu",
        "Wenbin Liang",
        "Mo Yu",
        "Anan Liu",
        "Ke-Yue Zhang",
        "Lizhuang Ma",
        "Jianyong Wang",
        "Jun Wang",
        "Wei Zhang"
      ],
      "abstract": "The explosion in model sizes leads to continued growth in prohibitive\ntraining/fine-tuning costs, particularly for stateful optimizers which maintain\nauxiliary information of even 2x the model size to achieve optimal convergence.\nWe therefore present in this work a novel type of optimizer that carries with\nextremely lightweight state overloads, achieved through ultra-low-precision\nquantization. While previous efforts have achieved certain success with 8-bit\nor 4-bit quantization, our approach enables optimizers to operate at precision\nas low as 3 bits, or even 2 bits per state element. This is accomplished by\nidentifying and addressing two critical challenges: the signal swamping problem\nin unsigned quantization that results in unchanged state dynamics, and the\nrapidly increased gradient variance in signed quantization that leads to\nincorrect descent directions. The theoretical analysis suggests a tailored\nlogarithmic quantization for the former and a precision-specific momentum value\nfor the latter. Consequently, the proposed SOLO achieves substantial memory\nsavings (approximately 45 GB when training a 7B model) with minimal accuracy\nloss. We hope that SOLO can contribute to overcoming the bottleneck in\ncomputational resources, thereby promoting greater accessibility in fundamental\nresearch.",
      "tldr_zh": "本文提出了一种新型的低比特优化器SOLO，旨在解决大型模型训练/微调过程中stateful优化器带来的高昂成本问题。SOLO通过超低精度量化实现极轻量级的状态负载，最低可达每个状态元素2或3比特。该研究针对无符号量化中的信号淹没问题和有符号量化中梯度方差快速增加的问题，分别提出了对数的量化方法和精度特定的动量值。理论分析和实验结果表明，SOLO在保证最小精度损失的同时，能够显著节省内存（训练7B模型时约45GB）。SOLO有望缓解计算资源瓶颈，促进基础研究的普及。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.00347v1",
      "published_date": "2025-05-01 06:47:45 UTC",
      "updated_date": "2025-05-01 06:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:21:29.016629"
    },
    {
      "arxiv_id": "2505.00339v1",
      "title": "Enhancing AI-Driven Education: Integrating Cognitive Frameworks, Linguistic Feedback Analysis, and Ethical Considerations for Improved Content Generation",
      "title_zh": "增强人工智能驱动的教育：整合认知框架、语言反馈分析和伦理考量以改进内容生成\n",
      "authors": [
        "Antoun Yaacoub",
        "Sansiri Tarnpradab",
        "Phattara Khumprom",
        "Zainab Assaghir",
        "Lionel Prevost",
        "Jérôme Da-Rugna"
      ],
      "abstract": "Artificial intelligence (AI) is rapidly transforming education, presenting\nunprecedented opportunities for personalized learning and streamlined content\ncreation. However, realizing the full potential of AI in educational settings\nnecessitates careful consideration of the quality, cognitive depth, and ethical\nimplications of AI-generated materials. This paper synthesizes insights from\nfour related studies to propose a comprehensive framework for enhancing\nAI-driven educational tools. We integrate cognitive assessment frameworks\n(Bloom's Taxonomy and SOLO Taxonomy), linguistic analysis of AI-generated\nfeedback, and ethical design principles to guide the development of effective\nand responsible AI tools. We outline a structured three-phase approach\nencompassing cognitive alignment, linguistic feedback integration, and ethical\nsafeguards. The practical application of this framework is demonstrated through\nits integration into OneClickQuiz, an AI-powered Moodle plugin for quiz\ngeneration. This work contributes a comprehensive and actionable guide for\neducators, researchers, and developers aiming to harness AI's potential while\nupholding pedagogical and ethical standards in educational content generation.",
      "tldr_zh": "本文综合了四项相关研究，提出了一个综合框架，旨在提升AI驱动教育工具的质量、认知深度和伦理水平。该框架整合了认知评估框架（布鲁姆分类法和SOLO分类法）、AI生成反馈的语言分析以及伦理设计原则，用于指导有效且负责任的AI工具的开发。研究提出了一个包含认知对齐、语言反馈整合和伦理保障的结构化三阶段方法。该框架已集成到OneClickQuiz中，这是一个用于测验生成的AI驱动Moodle插件。这项工作为教育工作者、研究人员和开发人员提供了一个全面且可操作的指南，旨在利用AI的潜力，同时坚持教育内容生成中的教学和伦理标准。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This article will be presented in IJCNN 2025 \"AI Innovations for\n  Education: Transforming Teaching and Learning through Cutting-Edge\n  Technologies\" workshop",
      "pdf_url": "http://arxiv.org/pdf/2505.00339v1",
      "published_date": "2025-05-01 06:36:21 UTC",
      "updated_date": "2025-05-01 06:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:21:40.838899"
    },
    {
      "arxiv_id": "2505.00337v1",
      "title": "T2VPhysBench: A First-Principles Benchmark for Physical Consistency in Text-to-Video Generation",
      "title_zh": "T2VPhysBench：文本到视频生成中物理一致性的第一性原理基准测试",
      "authors": [
        "Xuyang Guo",
        "Jiayan Huo",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "abstract": "Text-to-video generative models have made significant strides in recent\nyears, producing high-quality videos that excel in both aesthetic appeal and\naccurate instruction following, and have become central to digital art creation\nand user engagement online. Yet, despite these advancements, their ability to\nrespect fundamental physical laws remains largely untested: many outputs still\nviolate basic constraints such as rigid-body collisions, energy conservation,\nand gravitational dynamics, resulting in unrealistic or even misleading\ncontent. Existing physical-evaluation benchmarks typically rely on automatic,\npixel-level metrics applied to simplistic, life-scenario prompts, and thus\noverlook both human judgment and first-principles physics. To fill this gap, we\nintroduce \\textbf{T2VPhysBench}, a first-principled benchmark that\nsystematically evaluates whether state-of-the-art text-to-video systems, both\nopen-source and commercial, obey twelve core physical laws including Newtonian\nmechanics, conservation principles, and phenomenological effects. Our benchmark\nemploys a rigorous human evaluation protocol and includes three targeted\nstudies: (1) an overall compliance assessment showing that all models score\nbelow 0.60 on average in each law category; (2) a prompt-hint ablation\nrevealing that even detailed, law-specific hints fail to remedy physics\nviolations; and (3) a counterfactual robustness test demonstrating that models\noften generate videos that explicitly break physical rules when so instructed.\nThe results expose persistent limitations in current architectures and offer\nconcrete insights for guiding future research toward truly physics-aware video\ngeneration.",
      "tldr_zh": "该论文提出了T2VPhysBench，一个用于评估文本生成视频模型在物理一致性方面表现的基准。该基准着重考察模型是否遵循牛顿力学、守恒定律等12项核心物理定律。通过严格的人工评估，研究发现现有文本生成视频模型，包括开源和商业模型，在物理规律遵循方面表现不佳，平均得分低于0.60。即使提供详细的、针对特定物理定律的提示，也难以改善物理违规现象。此外，反事实鲁棒性测试表明，模型在被指示违反物理规则时，经常生成明确违反规则的视频。T2VPhysBench揭示了当前架构的局限性，并为未来开发真正具有物理感知能力的视频生成模型提供了指导。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00337v1",
      "published_date": "2025-05-01 06:34:55 UTC",
      "updated_date": "2025-05-01 06:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:21:53.066271"
    },
    {
      "arxiv_id": "2505.00335v1",
      "title": "Efficient Neural Video Representation with Temporally Coherent Modulation",
      "title_zh": "基于时间相干调制的高效神经视频表示\n",
      "authors": [
        "Seungjun Shin",
        "Suji Kim",
        "Dokwan Oh"
      ],
      "abstract": "Implicit neural representations (INR) has found successful applications\nacross diverse domains. To employ INR in real-life, it is important to speed up\ntraining. In the field of INR for video applications, the state-of-the-art\napproach employs grid-type parametric encoding and successfully achieves a\nfaster encoding speed in comparison to its predecessors. However, the grid\nusage, which does not consider the video's dynamic nature, leads to redundant\nuse of trainable parameters. As a result, it has significantly lower parameter\nefficiency and higher bitrate compared to NeRV-style methods that do not use a\nparametric encoding. To address the problem, we propose Neural Video\nrepresentation with Temporally coherent Modulation (NVTM), a novel framework\nthat can capture dynamic characteristics of video. By decomposing the\nspatio-temporal 3D video data into a set of 2D grids with flow information,\nNVTM enables learning video representation rapidly and uses parameter\nefficiently. Our framework enables to process temporally corresponding pixels\nat once, resulting in the fastest encoding speed for a reasonable video\nquality, especially when compared to the NeRV-style method, with a speed\nincrease of over 3 times. Also, it remarks an average of 1.54dB/0.019\nimprovements in PSNR/LPIPS on UVG (Dynamic) (even with 10% fewer parameters)\nand an average of 1.84dB/0.013 improvements in PSNR/LPIPS on MCL-JCV (Dynamic),\ncompared to previous grid-type works. By expanding this to compression tasks,\nwe demonstrate comparable performance to video compression standards (H.264,\nHEVC) and recent INR approaches for video compression. Additionally, we perform\nextensive experiments demonstrating the superior performance of our algorithm\nacross diverse tasks, encompassing super resolution, frame interpolation and\nvideo inpainting. Project page is https://sujiikim.github.io/NVTM/.",
      "tldr_zh": "该论文提出了一种新的神经视频表示框架，即具有时间相干调制的神经视频表示(NVTM)，旨在提高INR在视频应用中的训练效率和参数效率。NVTM通过将时空3D视频数据分解为一组具有光流信息的2D网格，从而能够快速学习视频表示并高效利用参数。该方法能够一次性处理时间上对应的像素，显著提升了编码速度，尤其与NeRV类似的方法相比，速度提高了3倍以上。实验结果表明，NVTM在UVG和MCL-JCV数据集上，PSNR和LPIPS指标均优于之前的网格类型方法，且参数量更少。此外，NVTM在视频压缩任务中表现出与传统视频压缩标准(H.264, HEVC)和最新的INR视频压缩方法相媲美的性能，并在超分辨率、帧插值和视频修复等任务中展现出卓越的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.00335v1",
      "published_date": "2025-05-01 06:20:42 UTC",
      "updated_date": "2025-05-01 06:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:22:05.248008"
    },
    {
      "arxiv_id": "2505.00325v1",
      "title": "CognitionNet: A Collaborative Neural Network for Play Style Discovery in Online Skill Gaming Platform",
      "title_zh": "CognitionNet：用于在线技能游戏平台中游戏风格发现的协作神经网络\n",
      "authors": [
        "Rukma Talwadker",
        "Surajit Chakrabarty",
        "Aditya Pareek",
        "Tridib Mukherjee",
        "Deepak Saini"
      ],
      "abstract": "Games are one of the safest source of realizing self-esteem and relaxation at\nthe same time. An online gaming platform typically has massive data coming in,\ne.g., in-game actions, player moves, clickstreams, transactions etc. It is\nrather interesting, as something as simple as data on gaming moves can help\ncreate a psychological imprint of the user at that moment, based on her\nimpulsive reactions and response to a situation in the game. Mining this\nknowledge can: (a) immediately help better explain observed and predicted\nplayer behavior; and (b) consequently propel deeper understanding towards\nplayers' experience, growth and protection. To this effect, we focus on\ndiscovery of the \"game behaviours\" as micro-patterns formed by continuous\nsequence of games and the persistent \"play styles\" of the players' as a\nsequence of such sequences on an online skill gaming platform for Rummy. We\npropose a two stage deep neural network, CognitionNet. The first stage focuses\non mining game behaviours as cluster representations in a latent space while\nthe second aggregates over these micro patterns to discover play styles via a\nsupervised classification objective around player engagement. The dual\nobjective allows CognitionNet to reveal several player psychology inspired\ndecision making and tactics. To our knowledge, this is the first and\none-of-its-kind research to fully automate the discovery of: (i) player\npsychology and game tactics from telemetry data; and (ii) relevant diagnostic\nexplanations to players' engagement predictions. The collaborative training of\nthe two networks with differential input dimensions is enabled using a novel\nformulation of \"bridge loss\". The network plays pivotal role in obtaining\nhomogeneous and consistent play style definitions and significantly outperforms\nthe SOTA baselines wherever applicable.",
      "tldr_zh": "该论文提出了一个名为CognitionNet的两阶段深度神经网络，用于在在线技能游戏平台（以Rummy为例）中发现玩家的游戏行为和游戏风格。第一阶段通过聚类表示挖掘潜在空间中的游戏行为，第二阶段通过监督分类聚合微观模式以发现玩家的游戏风格。该网络使用一种新颖的“桥损失”进行协同训练，能够揭示受玩家心理启发的决策和策略。据作者所知，这是第一个全自动地从遥测数据中发现玩家心理和游戏策略，并为玩家参与度预测提供相关诊断解释的研究。实验结果表明，CognitionNet在定义同质和一致的游戏风格方面表现出色，并在适用情况下显著优于现有技术水平的基线模型。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00325v1",
      "published_date": "2025-05-01 05:51:19 UTC",
      "updated_date": "2025-05-01 05:51:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:22:17.052439"
    },
    {
      "arxiv_id": "2505.00322v1",
      "title": "AI2-Active Safety: AI-enabled Interaction-aware Active Safety Analysis with Vehicle Dynamics",
      "title_zh": "AI2-Active Safety：基于 AI 且感知交互的车辆动力学主动安全分析\n",
      "authors": [
        "Keshu Wu",
        "Zihao Li",
        "Sixu Li",
        "Xinyue Ye",
        "Dominique Lord",
        "Yang Zhou"
      ],
      "abstract": "This paper introduces an AI-enabled, interaction-aware active safety analysis\nframework that accounts for groupwise vehicle interactions. Specifically, the\nframework employs a bicycle model-augmented with road gradient\nconsiderations-to accurately capture vehicle dynamics. In parallel, a\nhypergraph-based AI model is developed to predict probabilistic trajectories of\nambient traffic. By integrating these two components, the framework derives\nvehicle intra-spacing over a 3D road surface as the solution of a stochastic\nordinary differential equation, yielding high-fidelity surrogate safety\nmeasures such as time-to-collision (TTC). To demonstrate its effectiveness, the\nframework is analyzed using stochastic numerical methods comprising 4th-order\nRunge-Kutta integration and AI inference, generating probability-weighted\nhigh-fidelity TTC (HF-TTC) distributions that reflect complex multi-agent\nmaneuvers and behavioral uncertainties. Evaluated with HF-TTC against\ntraditional constant-velocity TTC and non-interaction-aware approaches on\nhighway datasets, the proposed framework offers a systematic methodology for\nactive safety analysis with enhanced potential for improving safety perception\nin complex traffic environments.",
      "tldr_zh": "本文提出了一种基于AI的、交互感知的车辆主动安全分析框架，该框架考虑了车辆间的群体交互。该框架使用自行车模型（bicycle model）并结合道路坡度信息，精确捕捉车辆动力学。同时，开发了一个基于超图（hypergraph）的AI模型来预测周围交通的概率轨迹。通过整合这两个组件，该框架将车辆间距推导为随机常微分方程的解，从而产生高保真的替代安全指标，例如碰撞时间(TTC)。通过随机数值方法（包括四阶Runge-Kutta积分和AI推理）进行分析，生成概率加权的高保真TTC (HF-TTC)分布，反映了复杂的多智能体机动和行为不确定性。在高速公路数据集上，HF-TTC与传统的恒定速度TTC和非交互感知方法进行评估，结果表明该框架为主动安全分析提供了一种系统的方法，并具有增强复杂交通环境中安全感知能力的潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00322v1",
      "published_date": "2025-05-01 05:46:34 UTC",
      "updated_date": "2025-05-01 05:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:22:29.271069"
    },
    {
      "arxiv_id": "2505.00316v1",
      "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture",
      "title_zh": "使用 U-Net 神经网络架构将 Cellular-Potts 基于智能体的模型代理建模为分割任务\n",
      "authors": [
        "Tien Comlekoglu",
        "J. Quetzalcóatl Toledo-Marín",
        "Tina Comlekoglu",
        "Douglas W. DeSimone",
        "Shayn M. Peirce",
        "Geoffrey Fox",
        "James A. Glazier"
      ],
      "abstract": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate \\textit{in vitro} vasculogenesis. The surrogate\nmodel was trained to predict 100 computational steps ahead (Monte-Carlo steps,\nMCS), accelerating simulation evaluations by a factor of 590 times compared to\nCPM code execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.",
      "tldr_zh": "该研究提出了一种基于U-Net卷积神经网络的代理模型，用于加速计算昂贵的Cellular-Potts模型(CPM)的模拟，尤其针对复杂的多细胞生物系统。该代理模型将CPM模拟视为一个分割任务，并考虑了周期性边界条件。研究使用该模型加速了先前用于研究体外血管生成的CPM的评估，实现了590倍的加速。该模型能够有效地捕捉CPM所展示的涌现行为，如血管萌发、延伸、吻合以及血管腔的收缩。结果表明，深度学习有潜力作为CPM模拟的有效代理模型，从而在更大的时空尺度上更快地评估计算昂贵的生物过程CPM。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00316v1",
      "published_date": "2025-05-01 05:30:38 UTC",
      "updated_date": "2025-05-01 05:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:22:40.852839"
    },
    {
      "arxiv_id": "2505.00308v1",
      "title": "AI-Assisted Decision-Making for Clinical Assessment of Auto-Segmented Contour Quality",
      "title_zh": "AI辅助的自动分割轮廓质量临床评估决策\n",
      "authors": [
        "Biling Wang",
        "Austen Maniscalco",
        "Ti Bai",
        "Siqiu Wang",
        "Michael Dohopolski",
        "Mu-Han Lin",
        "Chenyang Shen",
        "Dan Nguyen",
        "Junzhou Huang",
        "Steve Jiang",
        "Xinlei Wang"
      ],
      "abstract": "Purpose: This study presents a Deep Learning (DL)-based quality assessment\n(QA) approach for evaluating auto-generated contours (auto-contours) in\nradiotherapy, with emphasis on Online Adaptive Radiotherapy (OART). Leveraging\nBayesian Ordinal Classification (BOC) and calibrated uncertainty thresholds,\nthe method enables confident QA predictions without relying on ground truth\ncontours or extensive manual labeling. Methods: We developed a BOC model to\nclassify auto-contour quality and quantify prediction uncertainty. A\ncalibration step was used to optimize uncertainty thresholds that meet clinical\naccuracy needs. The method was validated under three data scenarios: no manual\nlabels, limited labels, and extensive labels. For rectum contours in prostate\ncancer, we applied geometric surrogate labels when manual labels were absent,\ntransfer learning when limited, and direct supervision when ample labels were\navailable. Results: The BOC model delivered robust performance across all\nscenarios. Fine-tuning with just 30 manual labels and calibrating with 34\nsubjects yielded over 90% accuracy on test data. Using the calibrated\nthreshold, over 93% of the auto-contours' qualities were accurately predicted\nin over 98% of cases, reducing unnecessary manual reviews and highlighting\ncases needing correction. Conclusion: The proposed QA model enhances contouring\nefficiency in OART by reducing manual workload and enabling fast, informed\nclinical decisions. Through uncertainty quantification, it ensures safer, more\nreliable radiotherapy workflows.",
      "tldr_zh": "该研究提出了一种基于深度学习(DL)的质量评估(QA)方法，用于评估放疗中自动生成的轮廓(auto-contours)的质量，尤其适用于在线自适应放疗(OART)。该方法利用贝叶斯序数分类(BOC)和校准的不确定性阈值，无需依赖真实轮廓或大量手动标注即可进行可靠的QA预测。实验结果表明，该BOC模型在各种数据场景下均表现出色，仅使用30个手动标签进行微调并在34个受试者上进行校准，即可在测试数据上获得超过90%的准确率。通过不确定性量化，该模型能够减少手动工作量，并突出显示需要校正的病例，从而提高OART中的勾画效率，并确保更安全、更可靠的放疗工作流程。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00308v1",
      "published_date": "2025-05-01 05:05:35 UTC",
      "updated_date": "2025-05-01 05:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:22:53.082467"
    },
    {
      "arxiv_id": "2505.00295v1",
      "title": "Fine-grained spatial-temporal perception for gas leak segmentation",
      "title_zh": "用于气体泄漏分割的细粒度时空感知\n",
      "authors": [
        "Xinlong Zhao",
        "Shan Du"
      ],
      "abstract": "Gas leaks pose significant risks to human health and the environment. Despite\nlong-standing concerns, there are limited methods that can efficiently and\naccurately detect and segment leaks due to their concealed appearance and\nrandom shapes. In this paper, we propose a Fine-grained Spatial-Temporal\nPerception (FGSTP) algorithm for gas leak segmentation. FGSTP captures critical\nmotion clues across frames and integrates them with refined object features in\nan end-to-end network. Specifically, we first construct a correlation volume to\ncapture motion information between consecutive frames. Then, the fine-grained\nperception progressively refines the object-level features using previous\noutputs. Finally, a decoder is employed to optimize boundary segmentation.\nBecause there is no highly precise labeled dataset for gas leak segmentation,\nwe manually label a gas leak video dataset, GasVid. Experimental results on\nGasVid demonstrate that our model excels in segmenting non-rigid objects such\nas gas leaks, generating the most accurate mask compared to other\nstate-of-the-art (SOTA) models.",
      "tldr_zh": "该论文提出了一种用于气体泄漏分割的细粒度时空感知算法(FGSTP)。FGSTP旨在解决气体泄漏因其隐蔽性和随机形状而难以检测和分割的问题。该算法通过构建相关体积来捕获连续帧之间的运动信息，并利用细粒度感知逐步优化目标级别的特征。最终，解码器用于优化边界分割。作者手动标注了一个气体泄漏视频数据集GasVid，实验结果表明，FGSTP在分割非刚性物体（如气体泄漏）方面优于其他SOTA模型，并生成了最精确的掩膜。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45 (Primary), 68T07 (Secondary)",
        "I.2.10; I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures, ICIP 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.00295v1",
      "published_date": "2025-05-01 04:35:57 UTC",
      "updated_date": "2025-05-01 04:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:23:04.934180"
    },
    {
      "arxiv_id": "2505.00290v1",
      "title": "Multi-Hierarchical Fine-Grained Feature Mapping Driven by Feature Contribution for Molecular Odor Prediction",
      "title_zh": "基于特征贡献的多层次细粒度特征映射驱动的分子气味预测\n",
      "authors": [
        "Hong Xin Xie",
        "Jian De Sun",
        "Fan Fu Xue",
        "Zi Fei Han",
        "Shan Shan Feng",
        "Qi Chen"
      ],
      "abstract": "Molecular odor prediction is the process of using a molecule's structure to\npredict its smell. While accurate prediction remains challenging, AI models can\nsuggest potential odors. Existing methods, however, often rely on basic\ndescriptors or handcrafted fingerprints, which lack expressive power and hinder\neffective learning. Furthermore, these methods suffer from severe class\nimbalance, limiting the training effectiveness of AI models. To address these\nchallenges, we propose a Feature Contribution-driven Hierarchical Multi-Feature\nMapping Network (HMFNet). Specifically, we introduce a fine-grained, Local\nMulti-Hierarchy Feature Extraction module (LMFE) that performs deep feature\nextraction at the atomic level, capturing detailed features crucial for odor\nprediction. To enhance the extraction of discriminative atomic features, we\nintegrate a Harmonic Modulated Feature Mapping (HMFM). This module dynamically\nlearns feature importance and frequency modulation, improving the model's\ncapability to capture relevant patterns. Additionally, a Global Multi-Hierarchy\nFeature Extraction module (GMFE) is designed to learn global features from the\nmolecular graph topology, enabling the model to fully leverage global\ninformation and enhance its discriminative power for odor prediction. To\nfurther mitigate the issue of class imbalance, we propose a Chemically-Informed\nLoss (CIL). Experimental results demonstrate that our approach significantly\nimproves performance across various deep learning models, highlighting its\npotential to advance molecular structure representation and accelerate the\ndevelopment of AI-driven technologies.",
      "tldr_zh": "该论文提出了一种基于特征贡献驱动的多层次细粒度特征映射网络(HMFNet)，用于分子气味预测。HMFNet通过局部多层次特征提取模块(LMFE)进行原子级别的深度特征提取，并结合谐波调制特征映射(HMFM)动态学习特征重要性和频率调制，以增强判别性原子特征的提取。此外，全局多层次特征提取模块(GMFE)用于学习分子图拓扑的全局特征。为了解决类别不平衡问题，论文还提出了化学信息损失(CIL)。实验结果表明，HMFNet显著提高了各种深度学习模型的性能，为分子结构表示和AI驱动技术的发展提供了潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00290v1",
      "published_date": "2025-05-01 04:26:31 UTC",
      "updated_date": "2025-05-01 04:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:23:16.937876"
    },
    {
      "arxiv_id": "2505.00284v1",
      "title": "LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving",
      "title_zh": "LightEMMA：用于自动驾驶的轻量级端到端多模态模型\n",
      "authors": [
        "Zhijie Qiao",
        "Haowei Li",
        "Zhong Cao",
        "Henry X. Liu"
      ],
      "abstract": "Vision-Language Models (VLMs) have demonstrated significant potential for\nend-to-end autonomous driving. However, fully exploiting their capabilities for\nsafe and reliable vehicle control remains an open research challenge. To\nsystematically examine advances and limitations of VLMs in driving tasks, we\nintroduce LightEMMA, a Lightweight End-to-End Multimodal Model for Autonomous\ndriving. LightEMMA provides a unified, VLM-based autonomous driving framework\nwithout ad hoc customizations, enabling easy integration and evaluation of\nevolving state-of-the-art commercial and open-source models. We construct\ntwelve autonomous driving agents using various VLMs and evaluate their\nperformance on the nuScenes prediction task, comprehensively assessing metrics\nsuch as inference time, computational cost, and predictive accuracy.\nIllustrative examples highlight that, despite their strong scenario\ninterpretation capabilities, VLMs' practical performance in autonomous driving\ntasks remains concerning, emphasizing the need for further improvements. The\ncode is available at https://github.com/michigan-traffic-lab/LightEMMA.",
      "tldr_zh": "LightEMMA是一个轻量级的端到端多模态模型，用于自动驾驶研究，旨在系统性地评估视觉语言模型(VLM)在驾驶任务中的能力和局限性。它提供了一个统一的、基于VLM的自动驾驶框架，无需额外的定制，方便集成和评估各种先进模型。研究人员构建了12个使用不同VLM的自动驾驶智能体，并在nuScenes预测任务上评估它们的性能，考察了推理时间、计算成本和预测精度等指标。实验结果表明，尽管VLM具有强大的场景理解能力，但在自动驾驶任务中的实际性能仍然令人担忧，需要进一步改进。代码已开源。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00284v1",
      "published_date": "2025-05-01 04:12:41 UTC",
      "updated_date": "2025-05-01 04:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:23:28.815463"
    },
    {
      "arxiv_id": "2505.00278v1",
      "title": "DeCo: Defect-Aware Modeling with Contrasting Matching for Optimizing Task Assignment in Online IC Testing",
      "title_zh": "DeCo：基于对比匹配的缺陷感知建模，用于优化在线 IC 测试中的任务分配\n",
      "authors": [
        "Lo Pang-Yun Ting",
        "Yu-Hao Chiang",
        "Yi-Tung Tsai",
        "Hsu-Chao Lai",
        "Kun-Ta Chuang"
      ],
      "abstract": "In the semiconductor industry, integrated circuit (IC) processes play a vital\nrole, as the rising complexity and market expectations necessitate improvements\nin yield. Identifying IC defects and assigning IC testing tasks to the right\nengineers improves efficiency and reduces losses. While current studies\nemphasize fault localization or defect classification, they overlook the\nintegration of defect characteristics, historical failures, and the insights\nfrom engineer expertise, which restrains their effectiveness in improving IC\nhandling. To leverage AI for these challenges, we propose DeCo, an innovative\napproach for optimizing task assignment in IC testing. DeCo constructs a novel\ndefect-aware graph from IC testing reports, capturing co-failure relationships\nto enhance defect differentiation, even with scarce defect data. Additionally,\nit formulates defect-aware representations for engineers and tasks, reinforced\nby local and global structure modeling on the defect-aware graph. Finally, a\ncontrasting-based assignment mechanism pairs testing tasks with QA engineers by\nconsidering their skill level and current workload, thus promoting an equitable\nand efficient job dispatch. Experiments on a real-world dataset demonstrate\nthat DeCo achieves the highest task-handling success rates in different\nscenarios, exceeding 80\\%, while also maintaining balanced workloads on both\nscarce or expanded defect data. Moreover, case studies reveal that DeCo can\nassign tasks to potentially capable engineers, even for their unfamiliar\ndefects, highlighting its potential as an AI-driven solution for the real-world\nIC failure analysis and task handling.",
      "tldr_zh": "该论文提出了DeCo，一种新颖的缺陷感知建模方法，用于优化在线IC测试中的任务分配。DeCo通过构建缺陷感知图，捕捉IC测试报告中的共现失效关系，从而增强缺陷区分能力，尤其是在缺陷数据稀缺的情况下。该方法还结合局部和全局结构建模，为工程师和任务构建缺陷感知的表示。最终，DeCo采用基于对比的分配机制，根据工程师的技能水平和当前工作量，将测试任务与质量保证工程师进行匹配，从而实现公平高效的任务分配。在真实数据集上的实验表明，DeCo在不同场景下均实现了最高的任务处理成功率，超过80%，同时保持了工作负载的平衡。案例研究也表明，DeCo可以将任务分配给潜在的有能力的工程师，即使他们不熟悉相关缺陷，突显了其作为IC失效分析和任务处理的AI驱动解决方案的潜力。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00278v1",
      "published_date": "2025-05-01 04:01:14 UTC",
      "updated_date": "2025-05-01 04:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:23:41.162506"
    },
    {
      "arxiv_id": "2505.00268v1",
      "title": "Consistency in Language Models: Current Landscape, Challenges, and Future Directions",
      "title_zh": "语言模型的一致性：现状、挑战与未来方向\n",
      "authors": [
        "Jekaterina Novikova",
        "Carol Anderson",
        "Borhane Blili-Hamelin",
        "Subhabrata Majumdar"
      ],
      "abstract": "The hallmark of effective language use lies in consistency -- expressing\nsimilar meanings in similar contexts and avoiding contradictions. While human\ncommunication naturally demonstrates this principle, state-of-the-art language\nmodels struggle to maintain reliable consistency across different scenarios.\nThis paper examines the landscape of consistency research in AI language\nsystems, exploring both formal consistency (including logical rule adherence)\nand informal consistency (such as moral and factual coherence). We analyze\ncurrent approaches to measure aspects of consistency, identify critical\nresearch gaps in standardization of definitions, multilingual assessment, and\nmethods to improve consistency. Our findings point to an urgent need for robust\nbenchmarks to measure and interdisciplinary approaches to ensure consistency in\nthe application of language models on domain-specific tasks while preserving\nthe utility and adaptability.",
      "tldr_zh": "这篇论文探讨了语言模型中一致性的问题，包括形式一致性（如逻辑规则）和非形式一致性（如道德和事实一致性）。论文分析了当前衡量一致性的方法，并指出了在定义标准化、多语言评估以及提高一致性的方法方面存在的关键研究差距。研究强调，迫切需要建立可靠的基准来衡量一致性，并采用跨学科方法来确保语言模型在特定领域任务应用中的一致性，同时保持其效用和适应性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00268v1",
      "published_date": "2025-05-01 03:25:25 UTC",
      "updated_date": "2025-05-01 03:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:23:52.706473"
    },
    {
      "arxiv_id": "2505.00259v1",
      "title": "Pack-PTQ: Advancing Post-training Quantization of Neural Networks by Pack-wise Reconstruction",
      "title_zh": "Pack-PTQ：通过分包重建推进神经网络的后训练量化",
      "authors": [
        "Changjun Li",
        "Runqing Jiang",
        "Zhuo Song",
        "Pengpeng Yu",
        "Ye Zhang",
        "Yulan Guo"
      ],
      "abstract": "Post-training quantization (PTQ) has evolved as a prominent solution for\ncompressing complex models, which advocates a small calibration dataset and\navoids end-to-end retraining. However, most existing PTQ methods employ\nblock-wise reconstruction, which neglects cross-block dependency and exhibits a\nnotable accuracy drop in low-bit cases. To address these limitations, this\npaper presents a novel PTQ method, dubbed Pack-PTQ. First, we design a\nHessian-guided adaptive packing mechanism to partition blocks into\nnon-overlapping packs, which serve as the base unit for reconstruction, thereby\npreserving the cross-block dependency and enabling accurate quantization\nparameters estimation. Second, based on the pack configuration, we propose a\nmixed-precision quantization approach to assign varied bit-widths to packs\naccording to their distinct sensitivities, thereby further enhancing\nperformance. Extensive experiments on 2D image and 3D point cloud\nclassification tasks, using various network architectures, demonstrate the\nsuperiority of our method over the state-of-the-art PTQ methods.",
      "tldr_zh": "本文提出了一种新的后训练量化(PTQ)方法，名为Pack-PTQ，旨在解决现有PTQ方法忽略块间依赖性导致低比特精度下降的问题。Pack-PTQ首先设计了一种基于Hessian的自适应打包机制，将块划分为非重叠的包(pack)，作为重建的基本单元，从而保留了块间的依赖性，实现了精确的量化参数估计。其次，基于包的配置，提出了一种混合精度量化方法，根据包的不同敏感度为其分配不同的比特宽度，从而进一步提高了性能。在2D图像和3D点云分类任务上的大量实验表明，Pack-PTQ优于现有的PTQ方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00259v1",
      "published_date": "2025-05-01 02:53:46 UTC",
      "updated_date": "2025-05-01 02:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:24:05.115241"
    },
    {
      "arxiv_id": "2505.00254v1",
      "title": "Empowering Agentic Video Analytics Systems with Video Language Models",
      "title_zh": "利用视频语言模型赋能主动式视频分析系统\n",
      "authors": [
        "Yuxuan Yan",
        "Shiqi Jiang",
        "Ting Cao",
        "Yifan Yang",
        "Qianqian Yang",
        "Yuanchao Shu",
        "Yuqing Yang",
        "Lili Qiu"
      ],
      "abstract": "AI-driven video analytics has become increasingly pivotal across diverse\ndomains. However, existing systems are often constrained to specific,\npredefined tasks, limiting their adaptability in open-ended analytical\nscenarios. The recent emergence of Video-Language Models (VLMs) as\ntransformative technologies offers significant potential for enabling\nopen-ended video understanding, reasoning, and analytics. Nevertheless, their\nlimited context windows present challenges when processing ultra-long video\ncontent, which is prevalent in real-world applications. To address this, we\nintroduce AVA, a VLM-powered system designed for open-ended, advanced video\nanalytics. AVA incorporates two key innovations: (1) the near real-time\nconstruction of Event Knowledge Graphs (EKGs) for efficient indexing of long or\ncontinuous video streams, and (2) an agentic retrieval-generation mechanism\nthat leverages EKGs to handle complex and diverse queries. Comprehensive\nevaluations on public benchmarks, LVBench and VideoMME-Long, demonstrate that\nAVA achieves state-of-the-art performance, attaining 62.3% and 64.1% accuracy,\nrespectively, significantly surpassing existing VLM and video\nRetrieval-Augmented Generation (RAG) systems. Furthermore, to evaluate video\nanalytics in ultra-long and open-world video scenarios, we introduce a new\nbenchmark, AVA-100. This benchmark comprises 8 videos, each exceeding 10 hours\nin duration, along with 120 manually annotated, diverse, and complex\nquestion-answer pairs. On AVA-100, AVA achieves top-tier performance with an\naccuracy of 75.8%.",
      "tldr_zh": "该论文提出了AVA，一个基于视频语言模型(VLM)的智能视频分析系统，旨在解决现有系统在开放式分析场景中的适应性问题以及VLM处理超长视频内容时上下文窗口有限的挑战。AVA通过近实时构建事件知识图谱(EKG)来高效索引长视频流，并采用智能体检索-生成机制，利用EKG处理复杂查询。在LVBench和VideoMME-Long基准测试中，AVA达到了state-of-the-art的性能，准确率分别达到62.3%和64.1%。此外，论文还提出了一个新的基准AVA-100，包含8个超过10小时的视频，用于评估超长开放世界视频场景下的视频分析，AVA在该基准上实现了75.8%的准确率。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.00254v1",
      "published_date": "2025-05-01 02:40:23 UTC",
      "updated_date": "2025-05-01 02:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:24:17.359997"
    },
    {
      "arxiv_id": "2505.00240v1",
      "title": "LLM-Based Threat Detection and Prevention Framework for IoT Ecosystems",
      "title_zh": "基于LLM的物联网生态系统威胁检测与防御框架\n",
      "authors": [
        "Yazan Otoum",
        "Arghavan Asad",
        "Amiya Nayak"
      ],
      "abstract": "The increasing complexity and scale of the Internet of Things (IoT) have made\nsecurity a critical concern. This paper presents a novel Large Language Model\n(LLM)-based framework for comprehensive threat detection and prevention in IoT\nenvironments. The system integrates lightweight LLMs fine-tuned on IoT-specific\ndatasets (IoT-23, TON_IoT) for real-time anomaly detection and automated,\ncontext-aware mitigation strategies optimized for resource-constrained devices.\nA modular Docker-based deployment enables scalable and reproducible evaluation\nacross diverse network conditions. Experimental results in simulated IoT\nenvironments demonstrate significant improvements in detection accuracy,\nresponse latency, and resource efficiency over traditional security methods.\nThe proposed framework highlights the potential of LLM-driven, autonomous\nsecurity solutions for future IoT ecosystems.",
      "tldr_zh": "该论文提出了一种基于大型语言模型(LLM)的物联网(IoT)威胁检测和防御框架，旨在应对日益复杂的IoT安全问题。该框架利用在IoT特定数据集(IoT-23, TON_IoT)上微调的轻量级LLM，实现实时异常检测，并自动生成针对资源受限设备的上下文感知缓解策略。通过模块化的Docker部署，该系统能够进行可扩展和可复现的评估。实验结果表明，与传统安全方法相比，该框架在检测准确性、响应延迟和资源效率方面均有显著提升，突显了LLM驱动的自主安全解决方案在未来IoT生态系统中的潜力。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint version; submitted for academic peer review",
      "pdf_url": "http://arxiv.org/pdf/2505.00240v1",
      "published_date": "2025-05-01 01:18:54 UTC",
      "updated_date": "2025-05-01 01:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:24:28.779421"
    },
    {
      "arxiv_id": "2505.00232v1",
      "title": "Scaling On-Device GPU Inference for Large Generative Models",
      "title_zh": "扩展设备端 GPU 推理以支持大型生成模型\n",
      "authors": [
        "Jiuqiang Tang",
        "Raman Sarokin",
        "Ekaterina Ignasheva",
        "Grant Jensen",
        "Lin Chen",
        "Juhyun Lee",
        "Andrei Kulik",
        "Matthias Grundmann"
      ],
      "abstract": "Driven by the advancements in generative AI, large machine learning models\nhave revolutionized domains such as image processing, audio synthesis, and\nspeech recognition. While server-based deployments remain the locus of peak\nperformance, the imperative for on-device inference, necessitated by privacy\nand efficiency considerations, persists. Recognizing GPUs as the on-device ML\naccelerator with the widest reach, we present ML Drift--an optimized framework\nthat extends the capabilities of state-of-the-art GPU-accelerated inference\nengines. ML Drift enables on-device execution of generative AI workloads which\ncontain 10 to 100x more parameters than existing on-device generative AI\nmodels. ML Drift addresses intricate engineering challenges associated with\ncross-GPU API development, and ensures broad compatibility across mobile and\ndesktop/laptop platforms, thereby facilitating the deployment of significantly\nmore complex models on resource-constrained devices. Our GPU-accelerated ML/AI\ninference engine achieves an order-of-magnitude performance improvement\nrelative to existing open-source GPU inference engines.",
      "tldr_zh": "为了在设备上部署大型生成模型，该论文提出了ML Drift，一个优化的框架，旨在扩展现有GPU加速推理引擎的能力。ML Drift 解决了跨GPU API开发的复杂工程挑战，并确保在移动和桌面/笔记本电脑平台上的广泛兼容性，从而可以在资源受限的设备上部署更复杂的模型，模型参数量可以达到现有on-device生成模型的10到100倍。实验结果表明，相对于现有的开源GPU推理引擎，ML Drift实现了数量级的性能提升。该研究为在设备上运行大型生成模型提供了新的可能性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "to be published in CVPR 2025 Workshop on Efficient and On-Device\n  Generation (EDGE)",
      "pdf_url": "http://arxiv.org/pdf/2505.00232v1",
      "published_date": "2025-05-01 00:44:13 UTC",
      "updated_date": "2025-05-01 00:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:24:40.788539"
    },
    {
      "arxiv_id": "2505.00225v1",
      "title": "Predicting Estimated Times of Restoration for Electrical Outages Using Longitudinal Tabular Transformers",
      "title_zh": "使用纵向表格 Transformer 预测电力中断的预计恢复时间\n",
      "authors": [
        "Bogireddy Sai Prasanna Teja",
        "Valliappan Muthukaruppan",
        "Carls Benjamin"
      ],
      "abstract": "As climate variability increases, the ability of utility providers to deliver\nprecise Estimated Times of Restoration (ETR) during natural disasters has\nbecome increasingly critical. Accurate and timely ETRs are essential for\nenabling customer preparedness during extended power outages, where informed\ndecision-making can be crucial, particularly in severe weather conditions.\nNonetheless, prevailing utility practices predominantly depend on manual\nassessments or traditional statistical methods, which often fail to achieve the\nlevel of precision required for reliable and actionable predictions. To address\nthese limitations, we propose a Longitudinal Tabular Transformer (LTT) model\nthat leverages historical outage event data along with sequential updates of\nthese events to improve the accuracy of ETR predictions. The model's\nperformance was evaluated over 34,000 storm-related outage events from three\nmajor utility companies, collectively serving over 3 million customers over a\n2-year period. Results demonstrate that the LTT model improves the Customer\nSatisfaction Impact (CSI) metric by an average of 19.08% (p > 0.001) compared\nto existing methods. Additionally, we introduce customer-informed regression\nmetrics that align model evaluation with real-world satisfaction, ensuring the\noutcomes resonate with customer expectations. Furthermore, we employ\ninterpretability techniques to analyze the temporal significance of\nincorporating sequential updates in modeling outage events and to identify the\ncontributions of predictive features to a given ETR. This comprehensive\napproach not only improves predictive accuracy but also enhances transparency,\nfostering greater trust in the model's capabilities.",
      "tldr_zh": "该论文提出了一种纵向表格Transformer (Longitudinal Tabular Transformer, LTT)模型，用于更准确地预测电力中断的预计恢复时间(Estimated Times of Restoration, ETR)。该模型利用历史中断事件数据和事件的顺序更新来提高ETR预测的准确性，旨在解决传统方法在自然灾害期间提供精确ETR的不足。通过对来自三个主要电力公司的超过34,000个风暴相关中断事件的评估，LTT模型在客户满意度影响(Customer Satisfaction Impact, CSI)指标上平均提高了19.08%。此外，论文还引入了客户知情的回归指标，并将可解释性技术应用于分析顺序更新的时间重要性和预测特征对ETR的贡献，从而提高预测准确性和透明度。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00225v1",
      "published_date": "2025-05-01 00:25:43 UTC",
      "updated_date": "2025-05-01 00:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-03T02:24:53.059748"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 70,
  "processed_papers_count": 70,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-03T02:26:51.940990"
}