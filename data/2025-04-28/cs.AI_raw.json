[
  {
    "arxiv_id": "2504.20314v1",
    "title": "Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training",
    "authors": [
      "Qitao Tan",
      "Sung-En Chang",
      "Rui Xia",
      "Huidong Ji",
      "Chence Yang",
      "Ci Zhang",
      "Jun Liu",
      "Zheng Zhan",
      "Zhou Zou",
      "Yanzhi Wang",
      "Jin Lu",
      "Geng Yuan"
    ],
    "abstract": "Zeroth-order (ZO) optimization is an emerging deep neural network (DNN)\ntraining paradigm that offers computational simplicity and memory savings.\nHowever, this seemingly promising approach faces a significant and long-ignored\nchallenge. ZO requires generating a substantial number of Gaussian random\nnumbers, which poses significant difficulties and even makes it infeasible for\nhardware platforms, such as FPGAs and ASICs. In this paper, we identify this\ncritical issue, which arises from the mismatch between algorithm and hardware\ndesigners. To address this issue, we proposed PeZO, a perturbation-efficient ZO\nframework. Specifically, we design random number reuse strategies to\nsignificantly reduce the demand for random number generation and introduce a\nhardware-friendly adaptive scaling method to replace the costly Gaussian\ndistribution with a uniform distribution. Our experiments show that PeZO\nreduces the required LUTs and FFs for random number generation by 48.6\\% and\n12.7\\%, and saves at maximum 86\\% power consumption, all without compromising\ntraining performance, making ZO optimization feasible for on-device training.\nTo the best of our knowledge, we are the first to explore the potential of\non-device ZO optimization, providing valuable insights for future research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20314v1",
    "published_date": "2025-04-28 23:58:07 UTC",
    "updated_date": "2025-04-28 23:58:07 UTC"
  },
  {
    "arxiv_id": "2504.20310v1",
    "title": "A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning",
    "authors": [
      "Greg Gluch",
      "Shafi Goldwasser"
    ],
    "abstract": "In this paper, we initiate a cryptographically inspired theoretical study of\ndetection versus mitigation of adversarial inputs produced by attackers of\nMachine Learning algorithms during inference time.\n  We formally define defense by detection (DbD) and defense by mitigation\n(DbM). Our definitions come in the form of a 3-round protocol between two\nresource-bounded parties: a trainer/defender and an attacker. The attacker aims\nto produce inference-time inputs that fool the training algorithm. We define\ncorrectness, completeness, and soundness properties to capture successful\ndefense at inference time while not degrading (too much) the performance of the\nalgorithm on inputs from the training distribution.\n  We first show that achieving DbD and achieving DbM are equivalent for ML\nclassification tasks. Surprisingly, this is not the case for ML generative\nlearning tasks, where there are many possible correct outputs that can be\ngenerated for each input. We show a separation between DbD and DbM by\nexhibiting a generative learning task for which is possible to defend by\nmitigation but is provably impossible to defend by detection under the\nassumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE),\npublicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of\nKnowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation\nphase uses significantly fewer samples than the initial training algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.20310v1",
    "published_date": "2025-04-28 23:46:45 UTC",
    "updated_date": "2025-04-28 23:46:45 UTC"
  },
  {
    "arxiv_id": "2504.20304v2",
    "title": "UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions",
    "authors": [
      "Xiulin Yang",
      "Zhuoxuan Ju",
      "Lanni Bu",
      "Zoey Liu",
      "Nathan Schneider"
    ],
    "abstract": "CHILDES is a widely used resource of transcribed child and child-directed\nspeech. This paper introduces UD-English-CHILDES, the first officially released\nUniversal Dependencies (UD) treebank derived from previously\ndependency-annotated CHILDES data with consistent and unified annotation\nguidelines. Our corpus harmonizes annotations from 11 children and their\ncaregivers, totaling over 48k sentences. We validate existing gold-standard\nannotations under the UD v2 framework and provide an additional 1M\nsilver-standard sentences, offering a consistent resource for computational and\nlinguistic research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20304v2",
    "published_date": "2025-04-28 23:20:36 UTC",
    "updated_date": "2025-05-04 13:35:09 UTC"
  },
  {
    "arxiv_id": "2504.20295v1",
    "title": "The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting",
    "authors": [
      "Mohammadhossein Homaei",
      "Victor Gonzalez Morales",
      "Oscar Mogollon-Gutierrez",
      "Andres Caro"
    ],
    "abstract": "Digital twins (DTs) are improving water distribution systems by using\nreal-time data, analytics, and prediction models to optimize operations. This\npaper presents a DT platform designed for a Spanish water supply network,\nutilizing Long Short-Term Memory (LSTM) networks to predict water consumption.\nHowever, machine learning models are vulnerable to adversarial attacks, such as\nthe Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD).\nThese attacks manipulate critical model parameters, injecting subtle\ndistortions that degrade forecasting accuracy. To further exploit these\nvulnerabilities, we introduce a Learning Automata (LA) and Random LA-based\napproach that dynamically adjusts perturbations, making adversarial attacks\nmore difficult to detect. Experimental results show that this approach\nsignificantly impacts prediction reliability, causing the Mean Absolute\nPercentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack\nstrategies amplify this effect, highlighting cybersecurity risks in AI-driven\nDTs. These findings emphasize the urgent need for robust defenses, including\nadversarial training, anomaly detection, and secure data pipelines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "7 Pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.20295v1",
    "published_date": "2025-04-28 22:34:11 UTC",
    "updated_date": "2025-04-28 22:34:11 UTC"
  },
  {
    "arxiv_id": "2504.20294v1",
    "title": "mrCAD: Multimodal Refinement of Computer-aided Designs",
    "authors": [
      "William P. McCarthy",
      "Saujas Vaduguru",
      "Karl D. D. Willis",
      "Justin Matejka",
      "Judith E. Fan",
      "Daniel Fried",
      "Yewen Pu"
    ],
    "abstract": "A key feature of human collaboration is the ability to iteratively refine the\nconcepts we have communicated. In contrast, while generative AI excels at the\n\\textit{generation} of content, it often struggles to make specific\nlanguage-guided \\textit{modifications} of its prior outputs. To bridge the gap\nbetween how humans and machines perform edits, we present mrCAD, a dataset of\nmultimodal instructions in a communication game. In each game, players created\ncomputer aided designs (CADs) and refined them over several rounds to match\nspecific target designs. Only one player, the Designer, could see the target,\nand they must instruct the other player, the Maker, using text, drawing, or a\ncombination of modalities. mrCAD consists of 6,082 communication games, 15,163\ninstruction-execution rounds, played between 1,092 pairs of human players. We\nanalyze the dataset and find that generation and refinement instructions differ\nin their composition of drawing and text. Using the mrCAD task as a benchmark,\nwe find that state-of-the-art VLMs are better at following generation\ninstructions than refinement instructions. These results lay a foundation for\nanalyzing and modeling a multimodal language of refinement that is not\nrepresented in previous datasets.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "the first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2504.20294v1",
    "published_date": "2025-04-28 22:32:57 UTC",
    "updated_date": "2025-04-28 22:32:57 UTC"
  },
  {
    "arxiv_id": "2504.20278v1",
    "title": "Deep Physics Prior for First Order Inverse Optimization",
    "authors": [
      "Haoyu Yang",
      "Kamyar Azizzadenesheli",
      "Haoxing Ren"
    ],
    "abstract": "Inverse design optimization aims to infer system parameters from observed\nsolutions, posing critical challenges across domains such as semiconductor\nmanufacturing, structural engineering, materials science, and fluid dynamics.\nThe lack of explicit mathematical representations in many systems complicates\nthis process and makes the first order optimization impossible. Mainstream\napproaches, including generative AI and Bayesian optimization, address these\nchallenges but have limitations. Generative AI is computationally expensive,\nwhile Bayesian optimization, relying on surrogate models, suffers from\nscalability, sensitivity to priors, and noise issues, often leading to\nsuboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel\nmethod enabling first-order gradient-based inverse optimization with surrogate\nmachine learning models. By leveraging pretrained auxiliary Neural Operators,\nDPP enforces prior distribution constraints to ensure robust and meaningful\nsolutions. This approach is particularly effective when prior data and\nobservation distributions are unknown.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figure. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.20278v1",
    "published_date": "2025-04-28 21:48:19 UTC",
    "updated_date": "2025-04-28 21:48:19 UTC"
  },
  {
    "arxiv_id": "2504.20275v1",
    "title": "Smart Water Security with AI and Blockchain-Enhanced Digital Twins",
    "authors": [
      "Mohammadhossein Homaei",
      "Victor Gonzalez Morales",
      "Oscar Mogollon Gutierrez",
      "Ruben Molano Gomez",
      "Andres Caro"
    ],
    "abstract": "Water distribution systems in rural areas face serious challenges such as a\nlack of real-time monitoring, vulnerability to cyberattacks, and unreliable\ndata handling. This paper presents an integrated framework that combines\nLoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection\nSystem (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure\nand transparent water management. The IDS filters anomalous or spoofed data\nusing a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before\nvalidated data is logged via smart contracts on a private Ethereum blockchain\nusing Proof of Authority (PoA) consensus. The verified data feeds into a\nreal-time DT model supporting leak detection, consumption forecasting, and\npredictive maintenance. Experimental results demonstrate that the system\nachieves over 80 transactions per second (TPS) with under 2 seconds of latency\nwhile remaining cost-effective and scalable for up to 1,000 smart meters. This\nwork demonstrates a practical and secure architecture for decentralized water\ninfrastructure in under-connected rural environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "8 Pages, 9 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.20275v1",
    "published_date": "2025-04-28 21:41:23 UTC",
    "updated_date": "2025-04-28 21:41:23 UTC"
  },
  {
    "arxiv_id": "2504.20251v1",
    "title": "A Platform for Generating Educational Activities to Teach English as a Second Language",
    "authors": [
      "Aiala Rosá",
      "Santiago Góngora",
      "Juan Pablo Filevich",
      "Ignacio Sastre",
      "Laura Musto",
      "Brian Carpenter",
      "Luis Chiruzzo"
    ],
    "abstract": "We present a platform for the generation of educational activities oriented\nto teaching English as a foreign language. The different activities -- games\nand language practice exercises -- are strongly based on Natural Language\nProcessing techniques. The platform offers the possibility of playing\nout-of-the-box games, generated from resources created semi-automatically and\nthen manually curated. It can also generate games or exercises of greater\ncomplexity from texts entered by teachers, providing a stage of review and\nedition of the generated content before use. As a way of expanding the variety\nof activities in the platform, we are currently experimenting with image and\ntext generation. In order to integrate them and improve the performance of\nother neural tools already integrated, we are working on migrating the platform\nto a more powerful server. In this paper we describe the development of our\nplatform and its deployment for end users, discussing the challenges faced and\nhow we overcame them, and also detail our future work plans.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Unpublished report written in 2023",
    "pdf_url": "http://arxiv.org/pdf/2504.20251v1",
    "published_date": "2025-04-28 20:43:40 UTC",
    "updated_date": "2025-04-28 20:43:40 UTC"
  },
  {
    "arxiv_id": "2505.06246v1",
    "title": "United States Road Accident Prediction using Random Forest Predictor",
    "authors": [
      "Dominic Parosh Yamarthi",
      "Haripriya Raman",
      "Shamsad Parvin"
    ],
    "abstract": "Road accidents significantly threaten public safety and require in-depth\nanalysis for effective prevention and mitigation strategies. This paper focuses\non predicting accidents through the examination of a comprehensive traffic\ndataset covering 49 states in the United States. The dataset integrates\ninformation from diverse sources, including transportation departments, law\nenforcement, and traffic sensors. This paper specifically emphasizes predicting\nthe number of accidents, utilizing advanced machine learning models such as\nregression analysis and time series analysis. The inclusion of various factors,\nranging from environmental conditions to human behavior and infrastructure,\nensures a holistic understanding of the dynamics influencing road safety.\nTemporal and spatial analysis further allows for the identification of trends,\nseasonal variations, and high-risk areas. The implications of this research\nextend to proactive decision-making for policymakers and transportation\nauthorities. By providing accurate predictions and quantifiable insights into\nexpected accident rates under different conditions, the paper aims to empower\nauthorities to allocate resources efficiently and implement targeted\ninterventions. The goal is to contribute to the development of informed\npolicies and interventions that enhance road safety, creating a safer\nenvironment for all road users. Keywords: Machine Learning, Random Forest,\nAccident Prediction, AutoML, LSTM.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "5 Pages, 8 Figures",
    "pdf_url": "http://arxiv.org/pdf/2505.06246v1",
    "published_date": "2025-04-28 20:31:40 UTC",
    "updated_date": "2025-04-28 20:31:40 UTC"
  },
  {
    "arxiv_id": "2504.20213v1",
    "title": "Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework",
    "authors": [
      "Yuan Xia",
      "Akanksha Atrey",
      "Fadoua Khmaissia",
      "Kedar S. Namjoshi"
    ],
    "abstract": "This paper investigates the logical reasoning capabilities of large language\nmodels (LLMs). For a precisely defined yet tractable formulation, we choose the\nconceptually simple but technically complex task of constructing proofs in\nBoolean logic. A trained LLM receives as input a set of assumptions and a goal,\nand produces as output a proof that formally derives the goal from the\nassumptions. Incorrect proofs are caught by an automated proof checker. A\ncritical obstacle for training is the scarcity of real-world proofs. We propose\nan efficient, randomized procedure for synthesizing valid proofs and introduce\nTemplate Transformation, a data augmentation technique that enhances the\nmodel's ability to handle complex logical expressions. The central evaluation\nquestion is whether an LLM has indeed learned to reason. We propose tests to\nmeasure the reasoning ability of a black-box LLM. By these measures,\nexperiments demonstrate strong reasoning capabilities for assertions with short\nproofs, which decline with proof complexity. Notably, template transformation\nimproves accuracy even for smaller models, suggesting its effectiveness across\nmodel scales.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20213v1",
    "published_date": "2025-04-28 19:25:29 UTC",
    "updated_date": "2025-04-28 19:25:29 UTC"
  },
  {
    "arxiv_id": "2504.20199v1",
    "title": "Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains",
    "authors": [
      "Juntian Zhang",
      "Chuanqi cheng",
      "Yuhan Liu",
      "Wei Liu",
      "Jian Luan",
      "Rui Yan"
    ],
    "abstract": "Vision-language models (VLMs) achieve remarkable success in single-image\ntasks. However, real-world scenarios often involve intricate multi-image\ninputs, leading to a notable performance decline as models struggle to\ndisentangle critical information scattered across complex visual features. In\nthis work, we propose Focus-Centric Visual Chain, a novel paradigm that\nenhances VLMs'perception, comprehension, and reasoning abilities in multi-image\nscenarios. To facilitate this paradigm, we propose Focus-Centric Data\nSynthesis, a scalable bottom-up approach for synthesizing high-quality data\nwith elaborate reasoning paths. Through this approach, We construct VISC-150K,\na large-scale dataset with reasoning data in the form of Focus-Centric Visual\nChain, specifically designed for multi-image tasks. Experimental results on\nseven multi-image benchmarks demonstrate that our method achieves average\nperformance gains of 3.16% and 2.24% across two distinct model architectures,\nwithout compromising the general vision-language capabilities. our study\nrepresents a significant step toward more robust and capable vision-language\nsystems that can handle complex visual scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20199v1",
    "published_date": "2025-04-28 19:02:18 UTC",
    "updated_date": "2025-04-28 19:02:18 UTC"
  },
  {
    "arxiv_id": "2504.20197v1",
    "title": "Representation Learning on a Random Lattice",
    "authors": [
      "Aryeh Brill"
    ],
    "abstract": "Decomposing a deep neural network's learned representations into\ninterpretable features could greatly enhance its safety and reliability. To\nbetter understand features, we adopt a geometric perspective, viewing them as a\nlearned coordinate system for mapping an embedded data distribution. We\nmotivate a model of a generic data distribution as a random lattice and analyze\nits properties using percolation theory. Learned features are categorized into\ncontext, component, and surface features. The model is qualitatively consistent\nwith recent findings in mechanistic interpretability and suggests directions\nfor future research.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Proceedings of ILIAD (2024),\n  https://www.iliadconference.com/proceedings",
    "pdf_url": "http://arxiv.org/pdf/2504.20197v1",
    "published_date": "2025-04-28 19:01:36 UTC",
    "updated_date": "2025-04-28 19:01:36 UTC"
  },
  {
    "arxiv_id": "2504.20196v1",
    "title": "Prompting LLMs for Code Editing: Struggles and Remedies",
    "authors": [
      "Daye Nam",
      "Ahmed Omran",
      "Ambar Murillo",
      "Saksham Thakur",
      "Abner Araujo",
      "Marcel Blistein",
      "Alexander Frömmgen",
      "Vincent Hellendoorn",
      "Satish Chandra"
    ],
    "abstract": "Large Language Models (LLMs) are rapidly transforming software engineering,\nwith coding assistants embedded in an IDE becoming increasingly prevalent.\nWhile research has focused on improving the tools and understanding developer\nperceptions, a critical gap exists in understanding how developers actually use\nthese tools in their daily workflows, and, crucially, where they struggle. This\npaper addresses part of this gap through a multi-phased investigation of\ndeveloper interactions with an LLM-powered code editing and transformation\nfeature, Transform Code, in an IDE widely used at Google. First, we analyze\ntelemetry logs of the feature usage, revealing that frequent re-prompting can\nbe an indicator of developer struggles with using Transform Code. Second, we\nconduct a qualitative analysis of unsatisfactory requests, identifying five key\ncategories of information often missing from developer prompts. Finally, based\non these findings, we propose and evaluate a tool, AutoPrompter, for\nautomatically improving prompts by inferring missing information from the\nsurrounding code context, leading to a 27% improvement in edit correctness on\nour test set.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20196v1",
    "published_date": "2025-04-28 18:59:28 UTC",
    "updated_date": "2025-04-28 18:59:28 UTC"
  },
  {
    "arxiv_id": "2504.20187v1",
    "title": "AI Recommendation Systems for Lane-Changing Using Adherence-Aware Reinforcement Learning",
    "authors": [
      "Weihao Sun",
      "Heeseung Bang",
      "Andreas A. Malikopoulos"
    ],
    "abstract": "In this paper, we present an adherence-aware reinforcement learning (RL)\napproach aimed at seeking optimal lane-changing recommendations within a\nsemi-autonomous driving environment to enhance a single vehicle's travel\nefficiency. The problem is framed within a Markov decision process setting and\nis addressed through an adherence-aware deep Q network, which takes into\naccount the partial compliance of human drivers with the recommended actions.\nThis approach is evaluated within CARLA's driving environment under realistic\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2504.20187v1",
    "published_date": "2025-04-28 18:38:39 UTC",
    "updated_date": "2025-04-28 18:38:39 UTC"
  },
  {
    "arxiv_id": "2504.20183v1",
    "title": "BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics",
    "authors": [
      "Niki van Stein",
      "Anna V. Kononova",
      "Haoran Yin",
      "Thomas Bäck"
    ],
    "abstract": "The application of Large Language Models (LLMs) for Automated Algorithm\nDiscovery (AAD), particularly for optimisation heuristics, is an emerging field\nof research. This emergence necessitates robust, standardised benchmarking\npractices to rigorously evaluate the capabilities and limitations of LLM-driven\nAAD methods and the resulting generated algorithms, especially given the\nopacity of their design process and known issues with existing benchmarks. To\naddress this need, we introduce BLADE (Benchmark suite for LLM-driven Automated\nDesign and Evolution), a modular and extensible framework specifically designed\nfor benchmarking LLM-driven AAD methods in a continuous black-box optimisation\ncontext. BLADE integrates collections of benchmark problems (including MA-BBOB\nand SBOX-COST among others) with instance generators and textual descriptions\naimed at capability-focused testing, such as generalisation, specialisation and\ninformation exploitation. It offers flexible experimental setup options,\nstandardised logging for reproducibility and fair comparison, incorporates\nmethods for analysing the AAD process (e.g., Code Evolution Graphs and various\nvisualisation approaches) and facilitates comparison against human-designed\nbaselines through integration with established tools like IOHanalyser and\nIOHexplainer. BLADE provides an `out-of-the-box' solution to systematically\nevaluate LLM-driven AAD approaches. The framework is demonstrated through two\ndistinct use cases exploring mutation prompt strategies and function\nspecialisation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages, accepted at GECCO Workshop 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20183v1",
    "published_date": "2025-04-28 18:34:09 UTC",
    "updated_date": "2025-04-28 18:34:09 UTC"
  },
  {
    "arxiv_id": "2504.20179v1",
    "title": "Integration Flow Models",
    "authors": [
      "Jingjing Wang",
      "Dan Zhang",
      "Joshua Luo",
      "Yin Yang",
      "Feng Luo"
    ],
    "abstract": "Ordinary differential equation (ODE) based generative models have emerged as\na powerful approach for producing high-quality samples in many applications.\nHowever, the ODE-based methods either suffer the discretization error of\nnumerical solvers of ODE, which restricts the quality of samples when only a\nfew NFEs are used, or struggle with training instability. In this paper, we\nproposed Integration Flow, which directly learns the integral of ODE-based\ntrajectory paths without solving the ODE functions. Moreover, Integration Flow\nexplicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in\nguiding the reverse-time dynamics. We have theoretically proven this can\ncontribute to both stability and accuracy. To the best of our knowledge,\nIntegration Flow is the first model with a unified structure to estimate\nODE-based generative models and the first to show the exact straightness of\n1-Rectified Flow without reflow. Through theoretical analysis and empirical\nevaluations, we show that Integration Flows achieve improved performance when\nit is applied to existing ODE-based models, such as diffusion models, Rectified\nFlows, and PFGM++. Specifically, Integration Flow achieves one-step generation\non CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model,\n3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet\nwith FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without\nreflow and 4.15 for PFGM++.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20179v1",
    "published_date": "2025-04-28 18:29:15 UTC",
    "updated_date": "2025-04-28 18:29:15 UTC"
  },
  {
    "arxiv_id": "2504.20172v1",
    "title": "Causal Identification in Time Series Models",
    "authors": [
      "Erik Jahn",
      "Karthik Karnik",
      "Leonard J. Schulman"
    ],
    "abstract": "In this paper, we analyze the applicability of the Causal Identification\nalgorithm to causal time series graphs with latent confounders. Since these\ngraphs extend over infinitely many time steps, deciding whether causal effects\nacross arbitrary time intervals are identifiable appears to require computation\non graph segments of unbounded size. Even for deciding the identifiability of\nintervention effects on variables that are close in time, no bound is known on\nhow many time steps in the past need to be considered. We give a first bound of\nthis kind that only depends on the number of variables per time step and the\nmaximum time lag of any direct or latent causal effect. More generally, we show\nthat applying the Causal Identification algorithm to a constant-size segment of\nthe time series graph is sufficient to decide identifiability of causal\neffects, even across unbounded time intervals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20172v1",
    "published_date": "2025-04-28 18:10:39 UTC",
    "updated_date": "2025-04-28 18:10:39 UTC"
  },
  {
    "arxiv_id": "2504.20168v1",
    "title": "MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools",
    "authors": [
      "Nishant Subramani",
      "Jason Eisner",
      "Justin Svegliato",
      "Benjamin Van Durme",
      "Yu Su",
      "Sam Thomson"
    ],
    "abstract": "Tool-using agents that act in the world need to be both useful and safe.\nWell-calibrated model confidences can be used to weigh the risk versus reward\nof potential actions, but prior work shows that many models are poorly\ncalibrated. Inspired by interpretability literature exploring the internals of\nmodels, we propose a novel class of model-internal confidence estimators (MICE)\nto better assess confidence when calling tools. MICE first decodes from each\nintermediate layer of the language model using logitLens and then computes\nsimilarity scores between each layer's generation and the final output. These\nfeatures are fed into a learned probabilistic classifier to assess confidence\nin the decoded output. On the simulated trial and error (STE) tool-calling\ndataset using Llama3 models, we find that MICE beats or matches the baselines\non smoothed expected calibration error. Using MICE confidences to determine\nwhether to call a tool significantly improves over strong baselines on a new\nmetric, expected tool-calling utility. Further experiments show that MICE is\nsample-efficient, can generalize zero-shot to unseen APIs, and results in\nhigher tool-calling utility in scenarios with varying risk levels. Our code is\nopen source, available at https://github.com/microsoft/mice_for_cats.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025. Code:\n  https://github.com/microsoft/mice_for_cats",
    "pdf_url": "http://arxiv.org/pdf/2504.20168v1",
    "published_date": "2025-04-28 18:06:38 UTC",
    "updated_date": "2025-04-28 18:06:38 UTC"
  },
  {
    "arxiv_id": "2504.20131v1",
    "title": "LZ Penalty: An information-theoretic repetition penalty for autoregressive language models",
    "authors": [
      "Antonio A. Ginart",
      "Naveen Kodali",
      "Jason Lee",
      "Caiming Xiong",
      "Silvio Savarese",
      "John R. Emmons"
    ],
    "abstract": "We introduce the LZ penalty, a penalty specialized for reducing degenerate\nrepetitions in autoregressive language models without loss of capability. The\npenalty is based on the codelengths in the LZ77 universal lossless compression\nalgorithm. Through the lens of the prediction-compression duality, decoding the\nLZ penalty has the interpretation of sampling from the residual distribution\nafter removing the information that is highly compressible. We demonstrate the\nLZ penalty enables state-of-the-art open-source reasoning models to operate\nwith greedy (temperature zero) decoding without loss of capability and without\ninstances of degenerate repetition. Both the industry-standard frequency\npenalty and repetition penalty are ineffective, incurring degenerate repetition\nrates of up to 4%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint (draft)",
    "pdf_url": "http://arxiv.org/pdf/2504.20131v1",
    "published_date": "2025-04-28 17:58:28 UTC",
    "updated_date": "2025-04-28 17:58:28 UTC"
  },
  {
    "arxiv_id": "2504.20026v1",
    "title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields",
    "authors": [
      "Zhengqin Li",
      "Dilin Wang",
      "Ka Chen",
      "Zhaoyang Lv",
      "Thu Nguyen-Phuoc",
      "Milim Lee",
      "Jia-Bin Huang",
      "Lei Xiao",
      "Cheng Zhang",
      "Yufeng Zhu",
      "Carl S. Marshall",
      "Yufeng Ren",
      "Richard Newcombe",
      "Zhao Dong"
    ],
    "abstract": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20026v1",
    "published_date": "2025-04-28 17:48:58 UTC",
    "updated_date": "2025-04-28 17:48:58 UTC"
  },
  {
    "arxiv_id": "2504.20020v1",
    "title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models",
    "authors": [
      "Xin Wang",
      "Haoyang Li",
      "Zeyang Zhang",
      "Haibo Chen",
      "Wenwu Zhu"
    ],
    "abstract": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.20020v1",
    "published_date": "2025-04-28 17:42:02 UTC",
    "updated_date": "2025-04-28 17:42:02 UTC"
  },
  {
    "arxiv_id": "2504.20019v1",
    "title": "Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control",
    "authors": [
      "Abdelhakim Amer",
      "David Felsager",
      "Yury Brodskiy",
      "Andriy Sarabakha"
    ],
    "abstract": "Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2025. The final version consists\n  of 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.20019v1",
    "published_date": "2025-04-28 17:38:57 UTC",
    "updated_date": "2025-04-28 17:38:57 UTC"
  },
  {
    "arxiv_id": "2504.20018v1",
    "title": "MINT: Multi-Vector Search Index Tuning",
    "authors": [
      "Jiongli Zhu",
      "Yue Wang",
      "Bailu Ding",
      "Philip A. Bernstein",
      "Vivek Narasayya",
      "Surajit Chaudhuri"
    ],
    "abstract": "Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20018v1",
    "published_date": "2025-04-28 17:36:06 UTC",
    "updated_date": "2025-04-28 17:36:06 UTC"
  },
  {
    "arxiv_id": "2504.20010v1",
    "title": "Towards Automated Scoping of AI for Social Good Projects",
    "authors": [
      "Jacob Emmerson",
      "Rayid Ghani",
      "Zheyuan Ryan Shi"
    ],
    "abstract": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20010v1",
    "published_date": "2025-04-28 17:29:51 UTC",
    "updated_date": "2025-04-28 17:29:51 UTC"
  },
  {
    "arxiv_id": "2504.20007v2",
    "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
    "authors": [
      "Anita Srbinovska",
      "Angela Srbinovska",
      "Vivek Senthil",
      "Adrian Martin",
      "John McCluskey",
      "Jonathan Bateman",
      "Ernest Fokoué"
    ],
    "abstract": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.20007v2",
    "published_date": "2025-04-28 17:25:23 UTC",
    "updated_date": "2025-05-09 14:29:05 UTC"
  },
  {
    "arxiv_id": "2504.19997v1",
    "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration",
    "authors": [
      "Ivo Brett"
    ],
    "abstract": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19997v1",
    "published_date": "2025-04-28 17:17:42 UTC",
    "updated_date": "2025-04-28 17:17:42 UTC"
  },
  {
    "arxiv_id": "2504.19996v1",
    "title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery",
    "authors": [
      "Andreas Kalogeras",
      "Dimitrios Bormpoudakis",
      "Iason Tsardanidis",
      "Dimitra A. Loka",
      "Charalampos Kontoes"
    ],
    "abstract": "The widespread use of Exogenous Organic Matter in agriculture necessitates\nmonitoring to assess its effects on soil and crop health. This study evaluates\noptical Sentinel-2 satellite imagery for detecting digestate application, a\npractice that enhances soil fertility but poses environmental risks like\nmicroplastic contamination and nitrogen losses. In the first instance,\nSentinel-2 satellite image time series (SITS) analysis of specific indices\n(EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after\napplication on the soils of four different crop types in Thessaly, Greece.\nFurthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient\nBoosting and a Feed-Forward Neural Network), were used to investigate digestate\npresence detection, achieving F1-scores up to 0.85. The findings highlight the\npotential of combining remote sensing and ML for scalable and cost-effective\nmonitoring of EOM applications, supporting precision agriculture and\nsustainability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19996v1",
    "published_date": "2025-04-28 17:16:40 UTC",
    "updated_date": "2025-04-28 17:16:40 UTC"
  },
  {
    "arxiv_id": "2504.19990v1",
    "title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and Directions",
    "authors": [
      "Salem Lahlou"
    ],
    "abstract": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19990v1",
    "published_date": "2025-04-28 17:06:30 UTC",
    "updated_date": "2025-04-28 17:06:30 UTC"
  },
  {
    "arxiv_id": "2505.03770v1",
    "title": "Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind",
    "authors": [
      "Mouad Abrini",
      "Omri Abend",
      "Dina Acklin",
      "Henny Admoni",
      "Gregor Aichinger",
      "Nitay Alon",
      "Zahra Ashktorab",
      "Ashish Atreja",
      "Moises Auron",
      "Alexander Aufreiter",
      "Raghav Awasthi",
      "Soumya Banerjee",
      "Joe M. Barnby",
      "Rhea Basappa",
      "Severin Bergsmann",
      "Djallel Bouneffouf",
      "Patrick Callaghan",
      "Marc Cavazza",
      "Thierry Chaminade",
      "Sonia Chernova",
      "Mohamed Chetouan",
      "Moumita Choudhury",
      "Axel Cleeremans",
      "Jacek B. Cywinski",
      "Fabio Cuzzolin",
      "Hokin Deng",
      "N'yoma Diamond",
      "Camilla Di Pasquasio",
      "Guillaume Dumas",
      "Max van Duijn",
      "Mahapatra Dwarikanath",
      "Qingying Gao",
      "Ashok Goel",
      "Rebecca Goldstein",
      "Matthew Gombolay",
      "Gabriel Enrique Gonzalez",
      "Amar Halilovic",
      "Tobias Halmdienst",
      "Mahimul Islam",
      "Julian Jara-Ettinger",
      "Natalie Kastel",
      "Renana Keydar",
      "Ashish K. Khanna",
      "Mahdi Khoramshahi",
      "JiHyun Kim",
      "MiHyeon Kim",
      "YoungBin Kim",
      "Senka Krivic",
      "Nikita Krasnytskyi",
      "Arun Kumar",
      "JuneHyoung Kwon",
      "Eunju Lee",
      "Shane Lee",
      "Peter R. Lewis",
      "Xue Li",
      "Yijiang Li",
      "Michal Lewandowski",
      "Nathan Lloyd",
      "Matthew B. Luebbers",
      "Dezhi Luo",
      "Haiyun Lyu",
      "Dwarikanath Mahapatra",
      "Kamal Maheshwari",
      "Mallika Mainali",
      "Piyush Mathur",
      "Patrick Mederitsch",
      "Shuwa Miura",
      "Manuel Preston de Miranda",
      "Reuth Mirsky",
      "Shreya Mishra",
      "Nina Moorman",
      "Katelyn Morrison",
      "John Muchovej",
      "Bernhard Nessler",
      "Felix Nessler",
      "Hieu Minh Jord Nguyen",
      "Abby Ortego",
      "Francis A. Papay",
      "Antoine Pasquali",
      "Hamed Rahimi",
      "Charumathi Raghu",
      "Amanda Royka",
      "Stefan Sarkadi",
      "Jaelle Scheuerman",
      "Simon Schmid",
      "Paul Schrater",
      "Anik Sen",
      "Zahra Sheikhbahaee",
      "Ke Shi",
      "Reid Simmons",
      "Nishant Singh",
      "Mason O. Smith",
      "Ramira van der Meulen",
      "Anthia Solaki",
      "Haoran Sun",
      "Viktor Szolga",
      "Matthew E. Taylor",
      "Travis Taylor",
      "Sanne Van Waveren",
      "Juan David Vargas",
      "Rineke Verbrugge",
      "Eitan Wagner",
      "Justin D. Weisz",
      "Ximing Wen",
      "William Yeoh",
      "Wenlong Zhang",
      "Michelle Zhao",
      "Shlomo Zilberstein"
    ],
    "abstract": "This volume includes a selection of papers presented at the Workshop on\nAdvancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in\nPhiladelphia US on 3rd March 2025. The purpose of this volume is to provide an\nopen access and curated anthology for the ToM and AI research community.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "workshop proceedings",
    "pdf_url": "http://arxiv.org/pdf/2505.03770v1",
    "published_date": "2025-04-28 17:06:14 UTC",
    "updated_date": "2025-04-28 17:06:14 UTC"
  },
  {
    "arxiv_id": "2504.19985v1",
    "title": "Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao Robot: A Closed-Loop Approach",
    "authors": [
      "Keyhan Rayati",
      "Amirhossein Feizi",
      "Alireza Beigy",
      "Pourya Shahverdi",
      "Mehdi Tale Masouleh",
      "Ahmad Kalhor"
    ],
    "abstract": "This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19985v1",
    "published_date": "2025-04-28 17:01:54 UTC",
    "updated_date": "2025-04-28 17:01:54 UTC"
  },
  {
    "arxiv_id": "2504.19982v1",
    "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons",
    "authors": [
      "Emre Can Acikgoz",
      "Carl Guo",
      "Suvodip Dey",
      "Akul Datta",
      "Takyoung Kim",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19982v1",
    "published_date": "2025-04-28 16:57:17 UTC",
    "updated_date": "2025-04-28 16:57:17 UTC"
  },
  {
    "arxiv_id": "2504.19968v1",
    "title": "How Group Lives Go Well",
    "authors": [
      "John Beverley",
      "Regina Hurley"
    ],
    "abstract": "This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19968v1",
    "published_date": "2025-04-28 16:40:06 UTC",
    "updated_date": "2025-04-28 16:40:06 UTC"
  },
  {
    "arxiv_id": "2504.19967v1",
    "title": "Enhancing short-term traffic prediction by integrating trends and fluctuations with attention mechanism",
    "authors": [
      "Adway Das",
      "Agnimitra Sengupta",
      "S. Ilgin Guler"
    ],
    "abstract": "Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19967v1",
    "published_date": "2025-04-28 16:38:46 UTC",
    "updated_date": "2025-04-28 16:38:46 UTC"
  },
  {
    "arxiv_id": "2504.19956v2",
    "title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents",
    "authors": [
      "Vineeth Sai Narajala",
      "Om Narayan"
    ],
    "abstract": "As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 2 figures, 1 table, typos corrected, references added",
    "pdf_url": "http://arxiv.org/pdf/2504.19956v2",
    "published_date": "2025-04-28 16:29:24 UTC",
    "updated_date": "2025-05-02 18:42:42 UTC"
  },
  {
    "arxiv_id": "2504.19951v1",
    "title": "Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach",
    "authors": [
      "Vineeth Sai Narajala",
      "Ken Huang",
      "Idan Habler"
    ],
    "abstract": "The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.19951v1",
    "published_date": "2025-04-28 16:22:21 UTC",
    "updated_date": "2025-04-28 16:22:21 UTC"
  },
  {
    "arxiv_id": "2504.19949v1",
    "title": "Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving Intelligent System",
    "authors": [
      "Aydoğan Soylu",
      "Tufan Kumbasar"
    ],
    "abstract": "Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "in International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.19949v1",
    "published_date": "2025-04-28 16:21:20 UTC",
    "updated_date": "2025-04-28 16:21:20 UTC"
  },
  {
    "arxiv_id": "2504.19944v1",
    "title": "Probabilistic and Causal Satisfiability: Constraining the Model",
    "authors": [
      "Markus Bläser",
      "Julian Dörfler",
      "Maciej Liśkiewicz",
      "Benito van der Zander"
    ],
    "abstract": "We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CC",
    "comment": "accepted at ICALP 25",
    "pdf_url": "http://arxiv.org/pdf/2504.19944v1",
    "published_date": "2025-04-28 16:14:06 UTC",
    "updated_date": "2025-04-28 16:14:06 UTC"
  },
  {
    "arxiv_id": "2504.19933v1",
    "title": "Automated decision-making for dynamic task assignment at scale",
    "authors": [
      "Riccardo Lo Bianco",
      "Willem van Jaarsveld",
      "Jeroen Middelhuis",
      "Luca Begnardi",
      "Remco Dijkman"
    ],
    "abstract": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19933v1",
    "published_date": "2025-04-28 16:08:35 UTC",
    "updated_date": "2025-04-28 16:08:35 UTC"
  },
  {
    "arxiv_id": "2504.19918v1",
    "title": "Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI",
    "authors": [
      "Hugo Georgenthum",
      "Cristian Cosentino",
      "Fabrizio Marozzo",
      "Pietro Liò"
    ],
    "abstract": "The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19918v1",
    "published_date": "2025-04-28 15:46:02 UTC",
    "updated_date": "2025-04-28 15:46:02 UTC"
  },
  {
    "arxiv_id": "2504.19912v1",
    "title": "Can AI Agents Design and Implement Drug Discovery Pipelines?",
    "authors": [
      "Khachik Smbatyan",
      "Tsolak Ghukasyan",
      "Tigran Aghajanyan",
      "Hovhannes Dabaghyan",
      "Sergey Adamyan",
      "Aram Bughdaryan",
      "Vahagn Altunyan",
      "Gagik Navasardyan",
      "Aram Davtyan",
      "Anush Hakobyan",
      "Aram Gharibyan",
      "Arman Fahradyan",
      "Artur Hakobyan",
      "Hasmik Mnatsakanyan",
      "Narek Ginoyan",
      "Garik Petrosyan"
    ],
    "abstract": "The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19912v1",
    "published_date": "2025-04-28 15:41:28 UTC",
    "updated_date": "2025-04-28 15:41:28 UTC"
  },
  {
    "arxiv_id": "2504.19901v1",
    "title": "Attention Mechanism, Max-Affine Partition, and Universal Approximation",
    "authors": [
      "Hude Liu",
      "Jerry Yao-Chieh Hu",
      "Zhao Song",
      "Han Liu"
    ],
    "abstract": "We establish the universal approximation capability of single-layer,\nsingle-head self- and cross-attention mechanisms with minimal attached\nstructures. Our key insight is to interpret single-head attention as an input\ndomain-partition mechanism that assigns distinct values to subregions. This\nallows us to engineer the attention weights such that this assignment imitates\nthe target function. Building on this, we prove that a single self-attention\nlayer, preceded by sum-of-linear transformations, is capable of approximating\nany continuous function on a compact domain under the $L_\\infty$-norm.\nFurthermore, we extend this construction to approximate any Lebesgue integrable\nfunction under $L_p$-norm for $1\\leq p <\\infty$. Lastly, we also extend our\ntechniques and show that, for the first time, single-head cross-attention\nachieves the same universal approximation guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19901v1",
    "published_date": "2025-04-28 15:31:45 UTC",
    "updated_date": "2025-04-28 15:31:45 UTC"
  },
  {
    "arxiv_id": "2504.19900v1",
    "title": "Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning",
    "authors": [
      "Han Chen",
      "Anne L. Martel"
    ],
    "abstract": "Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19900v1",
    "published_date": "2025-04-28 15:31:08 UTC",
    "updated_date": "2025-04-28 15:31:08 UTC"
  },
  {
    "arxiv_id": "2504.21045v1",
    "title": "Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection",
    "authors": [
      "Dennis Miczek",
      "Divyesh Gabbireddy",
      "Suman Saha"
    ],
    "abstract": "According to the Open Web Application Security Project (OWASP), Cross-Site\nScripting (XSS) is a critical security vulnerability. Despite decades of\nresearch, XSS remains among the top 10 security vulnerabilities. Researchers\nhave proposed various techniques to protect systems from XSS attacks, with\nmachine learning (ML) being one of the most widely used methods. An ML model is\ntrained on a dataset to identify potential XSS threats, making its\neffectiveness highly dependent on the size and diversity of the training data.\nA variation of XSS is obfuscated XSS, where attackers apply obfuscation\ntechniques to alter the code's structure, making it challenging for security\nsystems to detect its malicious intent. Our study's random forest model was\ntrained on traditional (non-obfuscated) XSS data achieved 99.8% accuracy.\nHowever, when tested against obfuscated XSS samples, accuracy dropped to 81.9%,\nunderscoring the importance of training ML models with obfuscated data to\nimprove their effectiveness in detecting XSS attacks. A significant challenge\nis to generate highly complex obfuscated code despite the availability of\nseveral public tools. These tools can only produce obfuscation up to certain\nlevels of complexity.\n  In our proposed system, we fine-tune a Large Language Model (LLM) to generate\ncomplex obfuscated XSS payloads automatically. By transforming original XSS\nsamples into diverse obfuscated variants, we create challenging training data\nfor ML model evaluation. Our approach achieved a 99.5% accuracy rate with the\nobfuscated dataset. We also found that the obfuscated samples generated by the\nLLMs were 28.1% more complex than those created by other tools, significantly\nimproving the model's ability to handle advanced XSS attacks and making it more\neffective for real-world application security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This work has been accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.21045v1",
    "published_date": "2025-04-28 15:22:31 UTC",
    "updated_date": "2025-04-28 15:22:31 UTC"
  },
  {
    "arxiv_id": "2504.19874v1",
    "title": "TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate",
    "authors": [
      "Amir Zandieh",
      "Majid Daliri",
      "Majid Hadian",
      "Vahab Mirrokni"
    ],
    "abstract": "Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19874v1",
    "published_date": "2025-04-28 15:05:35 UTC",
    "updated_date": "2025-04-28 15:05:35 UTC"
  },
  {
    "arxiv_id": "2504.19863v1",
    "title": "Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer",
    "authors": [
      "Daniel Kienzle",
      "Robin Schön",
      "Rainer Lienhart",
      "Shin'Ichi Satoh"
    ],
    "abstract": "Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in 2025 IEEE/CVF International Conference on Computer\n  Vision and Pattern Recognition Workshops (CVPRW)",
    "pdf_url": "http://arxiv.org/pdf/2504.19863v1",
    "published_date": "2025-04-28 14:55:12 UTC",
    "updated_date": "2025-04-28 14:55:12 UTC"
  },
  {
    "arxiv_id": "2504.21044v1",
    "title": "AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection",
    "authors": [
      "Jianbo Gao",
      "Keke Gai",
      "Jing Yu",
      "Liehuang Zhu",
      "Qi Wu"
    ],
    "abstract": "Recent advancement in large-scale Artificial Intelligence (AI) models\noffering multimodal services have become foundational in AI systems, making\nthem prime targets for model theft. Existing methods select Out-of-Distribution\n(OoD) data as backdoor watermarks and retrain the original model for copyright\nprotection. However, existing methods are susceptible to malicious detection\nand forgery by adversaries, resulting in watermark evasion. In this work, we\npropose Model-\\underline{ag}nostic Black-box Backdoor W\\underline{ate}rmarking\nFramework (AGATE) to address stealthiness and robustness challenges in\nmultimodal model copyright protection. Specifically, we propose an adversarial\ntrigger generation method to generate stealthy adversarial triggers from\nordinary dataset, providing visual fidelity while inducing semantic shifts. To\nalleviate the issue of anomaly detection among model outputs, we propose a\npost-transform module to correct the model output by narrowing the distance\nbetween adversarial trigger image embedding and text embedding. Subsequently, a\ntwo-phase watermark verification is proposed to judge whether the current model\ninfringes by comparing the two results with and without the transform module.\nConsequently, we consistently outperform state-of-the-art methods across five\ndatasets in the downstream tasks of multimodal image-text retrieval and image\nclassification. Additionally, we validated the robustness of AGATE under two\nadversarial attack scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21044v1",
    "published_date": "2025-04-28 14:52:01 UTC",
    "updated_date": "2025-04-28 14:52:01 UTC"
  },
  {
    "arxiv_id": "2504.19854v1",
    "title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks",
    "authors": [
      "Chia-Yu Hung",
      "Qi Sun",
      "Pengfei Hong",
      "Amir Zadeh",
      "Chuan Li",
      "U-Xuan Tan",
      "Navonil Majumder",
      "Soujanya Poria"
    ],
    "abstract": "Existing Visual-Language-Action (VLA) models have shown promising performance\nin zero-shot scenarios, demonstrating impressive task execution and reasoning\ncapabilities. However, a significant challenge arises from the limitations of\nvisual encoding, which can result in failures during tasks such as object\ngrasping. Moreover, these models typically suffer from high computational\noverhead due to their large sizes, often exceeding 7B parameters. While these\nmodels excel in reasoning and task planning, the substantial computational\noverhead they incur makes them impractical for real-time robotic environments,\nwhere speed and efficiency are paramount. To address the limitations of\nexisting VLA models, we propose NORA, a 3B-parameter model designed to reduce\ncomputational overhead while maintaining strong task performance. NORA adopts\nthe Qwen-2.5-VL-3B multimodal model as its backbone, leveraging its superior\nvisual-semantic understanding to enhance visual reasoning and action grounding.\nAdditionally, our \\model{} is trained on 970k real-world robot demonstrations\nand equipped with the FAST+ tokenizer for efficient action sequence generation.\nExperimental results demonstrate that NORA outperforms existing large-scale VLA\nmodels, achieving better task performance with significantly reduced\ncomputational overhead, making it a more practical solution for real-time\nrobotic autonomy.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19854v1",
    "published_date": "2025-04-28 14:47:34 UTC",
    "updated_date": "2025-04-28 14:47:34 UTC"
  },
  {
    "arxiv_id": "2504.19848v1",
    "title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study",
    "authors": [
      "Simona Casini",
      "Pietro Ducange",
      "Francesco Marcelloni",
      "Lorenzo Pollini"
    ],
    "abstract": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "International Joint Conference on Neural Network 2025 - Accepted",
    "pdf_url": "http://arxiv.org/pdf/2504.19848v1",
    "published_date": "2025-04-28 14:45:48 UTC",
    "updated_date": "2025-04-28 14:45:48 UTC"
  },
  {
    "arxiv_id": "2504.19847v1",
    "title": "Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration",
    "authors": [
      "Juhan Park",
      "Kyungjae Lee",
      "Hyung Jin Chang",
      "Jungchan Cho"
    ],
    "abstract": "In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19847v1",
    "published_date": "2025-04-28 14:45:26 UTC",
    "updated_date": "2025-04-28 14:45:26 UTC"
  },
  {
    "arxiv_id": "2504.19822v1",
    "title": "Mjölnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density",
    "authors": [
      "Minjong Cheon"
    ],
    "abstract": "Recent advances in AI-based weather forecasting models, such as FourCastNet,\nPangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep\nlearning to emulate complex atmospheric dynamics. Building on this momentum, we\npropose Mj\\\"olnir, a novel deep learning-based framework for global lightning\nflash density parameterization. Trained on ERA5 atmospheric predictors and\nWorld Wide Lightning Location Network (WWLLN) observations at a daily temporal\nresolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear\nmapping between large-scale environmental conditions and lightning activity.\nThe model architecture is based on the InceptionNeXt backbone with SENet, and a\nmulti-task learning strategy to simultaneously predict lightning occurrence and\nmagnitude. Extensive evaluations yield that Mollnir accurately reproduces the\nglobal distribution, seasonal variability, and regional characteristics of\nlightning activity, achieving a global Pearson correlation coefficient of 0.96\nfor annual mean fields. These results suggest that Mj\\\"olnir serves not only as\nan effective data-driven global lightning parameterization but also as a\npromising AI-based scheme for next-generation Earth system models (AI-ESMs).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19822v1",
    "published_date": "2025-04-28 14:22:59 UTC",
    "updated_date": "2025-04-28 14:22:59 UTC"
  },
  {
    "arxiv_id": "2504.19818v1",
    "title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping",
    "authors": [
      "Feng Chen",
      "Ilias Stogiannidis",
      "Andrew Wood",
      "Danilo Bueno",
      "Dominic Williams",
      "Fraser Macfarlane",
      "Bruce Grieve",
      "Darren Wells",
      "Jonathan A. Atkinson",
      "Malcolm J. Hawkesford",
      "Stephen A. Rolfe",
      "Tracy Lawson",
      "Tony Pridmore",
      "Mario Valerio Giuffrida",
      "Sotirios A. Tsaftaris"
    ],
    "abstract": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19818v1",
    "published_date": "2025-04-28 14:20:30 UTC",
    "updated_date": "2025-04-28 14:20:30 UTC"
  },
  {
    "arxiv_id": "2504.21043v2",
    "title": "CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain",
    "authors": [
      "Lingxiang Wang",
      "Hainan Zhang",
      "Qinnan Zhang",
      "Ziwei Wang",
      "Hongwei Zheng",
      "Jin Dong",
      "Zhiming Zheng"
    ],
    "abstract": "Large language models (LLMs) excel at generating code from natural language\ninstructions, yet they often lack an understanding of security vulnerabilities.\nThis limitation makes it difficult for LLMs to avoid security risks in\ngenerated code, particularly in high-security programming tasks such as smart\ncontract development for blockchain. Researchers have attempted to enhance the\nvulnerability awareness of these models by training them to differentiate\nbetween vulnerable and fixed code snippets. However, this approach relies\nheavily on manually labeled vulnerability data, which is only available for\npopular languages like Python and C++. For low-resource languages like\nSolidity, used in smart contracts, large-scale annotated datasets are scarce\nand difficult to obtain. To address this challenge, we introduce CodeBC, a code\ngeneration model specifically designed for generating secure smart contracts in\nblockchain. CodeBC employs a three-stage fine-tuning approach based on\nCodeLlama, distinguishing itself from previous methods by not relying on\npairwise vulnerability location annotations. Instead, it leverages\nvulnerability and security tags to teach the model the differences between\nvulnerable and secure code. During the inference phase, the model leverages\nsecurity tags to generate secure and robust code. Experimental results\ndemonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU,\nand compilation pass rates, while significantly reducing vulnerability rates.\nThese findings validate the effectiveness and cost-efficiency of our\nthree-stage fine-tuning strategy, making CodeBC a promising solution for\ngenerating secure smart contract code.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21043v2",
    "published_date": "2025-04-28 14:14:16 UTC",
    "updated_date": "2025-05-07 02:31:34 UTC"
  },
  {
    "arxiv_id": "2504.19792v1",
    "title": "Contextures: The Mechanism of Representation Learning",
    "authors": [
      "Runtian Zhai"
    ],
    "abstract": "This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2504.19792v1",
    "published_date": "2025-04-28 13:36:28 UTC",
    "updated_date": "2025-04-28 13:36:28 UTC"
  },
  {
    "arxiv_id": "2504.20125v1",
    "title": "Towards Large Language Models for Lunar Mission Planning and In Situ Resource Utilization",
    "authors": [
      "Michael Pekala",
      "Gregory Canal",
      "Samuel Barham",
      "Milena B. Graziano",
      "Morgan Trexler",
      "Leslie Hamilton",
      "Elizabeth Reilly",
      "Christopher D. Stiles"
    ],
    "abstract": "A key factor for lunar mission planning is the ability to assess the local\navailability of raw materials. However, many potentially relevant measurements\nare scattered across a variety of scientific publications. In this paper we\nconsider the viability of obtaining lunar composition data by leveraging LLMs\nto rapidly process a corpus of scientific publications. While leveraging LLMs\nto obtain knowledge from scientific documents is not new, this particular\napplication presents interesting challenges due to the heterogeneity of lunar\nsamples and the nuances involved in their characterization. Accuracy and\nuncertainty quantification are particularly crucial since many materials\nproperties can be sensitive to small variations in composition. Our findings\nindicate that off-the-shelf LLMs are generally effective at extracting data\nfrom tables commonly found in these documents. However, there remains\nopportunity to further refine the data we extract in this initial approach; in\nparticular, to capture fine-grained mineralogy information and to improve\nperformance on more subtle/complex pieces of information.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20125v1",
    "published_date": "2025-04-28 13:33:37 UTC",
    "updated_date": "2025-04-28 13:33:37 UTC"
  },
  {
    "arxiv_id": "2504.21042v2",
    "title": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift",
    "authors": [
      "Jiamin Chang",
      "Haoyang Li",
      "Hammond Pearce",
      "Ruoxi Sun",
      "Bo Li",
      "Minhui Xue"
    ],
    "abstract": "The growing adoption of artificial intelligence (AI) has amplified concerns\nabout trustworthiness, including integrity, privacy, robustness, and bias. To\nassess and attribute these threats, we propose ConceptLens, a generic framework\nthat leverages pre-trained multimodal models to identify the root causes of\nintegrity threats by analyzing Concept Shift in probing samples. ConceptLens\ndemonstrates strong detection performance for vanilla data poisoning attacks\nand uncovers vulnerabilities to bias injection, such as the generation of\ncovert advertisements through malicious concept shifts. It identifies privacy\nrisks in unaltered but high-risk samples, filters them before training, and\nprovides insights into model weaknesses arising from incomplete or imbalanced\ntraining data. Additionally, at the model level, it attributes concepts that\nthe target model is overly dependent on, identifies misleading concepts, and\nexplains how disrupting key concepts negatively impacts the model. Furthermore,\nit uncovers sociological biases in generative content, revealing disparities\nacross sociological contexts. Strikingly, ConceptLens reveals how safe training\nand inference data can be unintentionally and easily exploited, potentially\nundermining safety alignment. Our study informs actionable insights to breed\ntrust in AI systems, thereby speeding adoption and driving greater innovation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to The ACM Conference on Computer and Communications\n  Security (CCS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.21042v2",
    "published_date": "2025-04-28 13:30:48 UTC",
    "updated_date": "2025-05-17 04:44:18 UTC"
  },
  {
    "arxiv_id": "2505.05486v1",
    "title": "FedAvgen: Metadata for Model Aggregation In Communication Systems",
    "authors": [
      "Anthony Kiggundu",
      "Dennis Krummacker",
      "Hans D. Schotten"
    ],
    "abstract": "To improve business efficiency and minimize costs, Artificial Intelligence\n(AI) practitioners have adopted a shift from formulating models from scratch\ntowards sharing pretrained models. The pretrained models are then aggregated\ninto a global model with higher generalization capabilities, which is\nafterwards distributed to the client devices. This approach is known as\nfederated learning and inherently utilizes different techniques to select the\ncandidate client models averaged to obtain the global model. This approach, in\nthe case of communication systems, faces challenges arising from the\nexistential diversity in device profiles. The multiplicity in profiles\nmotivates our conceptual assessment of a metaheuristic algorithm (FedAvgen),\nwhich relates each pretrained model with its weight space as metadata, to a\nphenotype and genotype, respectively. This parent-child genetic evolution\ncharacterizes the global averaging step in federated learning. We then compare\nthe results of our approach to two widely adopted baseline federated learning\nalgorithms like Federated Averaging (FedAvg) and Federated Stochastic Gradient\nDescent (FedSGD).",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted in IEEE NetSoft 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.05486v1",
    "published_date": "2025-04-28 13:11:32 UTC",
    "updated_date": "2025-04-28 13:11:32 UTC"
  },
  {
    "arxiv_id": "2504.19755v1",
    "title": "Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment",
    "authors": [
      "Kapil Kashyap",
      "Sean Fargose",
      "Chrisil Dabre",
      "Fatema Dolaria",
      "Nilesh Patil",
      "Aniket Kore"
    ],
    "abstract": "Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19755v1",
    "published_date": "2025-04-28 12:54:51 UTC",
    "updated_date": "2025-04-28 12:54:51 UTC"
  },
  {
    "arxiv_id": "2504.20124v1",
    "title": "Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier",
    "authors": [
      "Abul Ehtesham",
      "Saket Kumar",
      "Aditi Singh",
      "Tala Talaei Khoei"
    ],
    "abstract": "Early detection of asthma in children is crucial to prevent long-term\nrespiratory complications and reduce emergency interventions. This work\npresents an AI-powered diagnostic pipeline that leverages Googles Health\nAcoustic Representations (HeAR) model to detect early signs of asthma from\npediatric respiratory sounds. The SPRSound dataset, the first open-access\ncollection of annotated respiratory sounds in children aged 1 month to 18\nyears, is used to extract 2-second audio segments labeled as wheeze, crackle,\nrhonchi, stridor, or normal. Each segment is embedded into a 512-dimensional\nrepresentation using HeAR, a foundation model pretrained on 300 million\nhealth-related audio clips, including 100 million cough sounds. Multiple\nclassifiers, including SVM, Random Forest, and MLP, are trained on these\nembeddings to distinguish between asthma-indicative and normal sounds. The\nsystem achieves over 91\\% accuracy, with strong performance on precision-recall\nmetrics for positive cases. In addition to classification, learned embeddings\nare visualized using PCA, misclassifications are analyzed through waveform\nplayback, and ROC and confusion matrix insights are provided. This method\ndemonstrates that short, low-resource pediatric recordings, when powered by\nfoundation audio models, can enable fast, noninvasive asthma screening. The\napproach is especially promising for digital diagnostics in remote or\nunderserved healthcare settings.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20124v1",
    "published_date": "2025-04-28 12:52:17 UTC",
    "updated_date": "2025-04-28 12:52:17 UTC"
  },
  {
    "arxiv_id": "2504.19754v1",
    "title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation",
    "authors": [
      "Carlo Merola",
      "Jaspinder Singh"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages, 2 figures, Second Workshop on Knowledge-Enhanced\n  Information Retrieval, ECIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.19754v1",
    "published_date": "2025-04-28 12:52:05 UTC",
    "updated_date": "2025-04-28 12:52:05 UTC"
  },
  {
    "arxiv_id": "2504.19738v1",
    "title": "Learning Efficiency Meets Symmetry Breaking",
    "authors": [
      "Yingbin Bai",
      "Sylvie Thiebaux",
      "Felipe Trevizan"
    ],
    "abstract": "Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19738v1",
    "published_date": "2025-04-28 12:33:39 UTC",
    "updated_date": "2025-04-28 12:33:39 UTC"
  },
  {
    "arxiv_id": "2504.19720v1",
    "title": "Taming the Titans: A Survey of Efficient LLM Inference Serving",
    "authors": [
      "Ranran Zhen",
      "Juntao Li",
      "Yixin Ji",
      "Zhenlin Yang",
      "Tong Liu",
      "Qingrong Xia",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) for Generative AI have achieved remarkable\nprogress, evolving into sophisticated and versatile tools widely adopted across\nvarious domains and applications. However, the substantial memory overhead\ncaused by their vast number of parameters, combined with the high computational\ndemands of the attention mechanism, poses significant challenges in achieving\nlow latency and high throughput for LLM inference services. Recent\nadvancements, driven by groundbreaking research, have significantly accelerated\nprogress in this field. This paper provides a comprehensive survey of these\nmethods, covering fundamental instance-level approaches, in-depth cluster-level\nstrategies, emerging scenario directions, and other miscellaneous but important\nareas. At the instance level, we review model placement, request scheduling,\ndecoding length prediction, storage management, and the disaggregation\nparadigm. At the cluster level, we explore GPU cluster deployment,\nmulti-instance load balancing, and cloud service solutions. For emerging\nscenarios, we organize the discussion around specific tasks, modules, and\nauxiliary methods. To ensure a holistic overview, we also highlight several\nniche yet critical areas. Finally, we outline potential research directions to\nfurther advance the field of LLM inference serving.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress;11 pages of main paper with 7 main figures, overall\n  20 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19720v1",
    "published_date": "2025-04-28 12:14:02 UTC",
    "updated_date": "2025-04-28 12:14:02 UTC"
  },
  {
    "arxiv_id": "2504.19715v1",
    "title": "Model-based controller assisted domain randomization in deep reinforcement learning: application to nonlinear powertrain control",
    "authors": [
      "Heisei Yonezawa",
      "Ansei Yonezawa",
      "Itsuro Kajiwara"
    ],
    "abstract": "Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19715v1",
    "published_date": "2025-04-28 12:09:07 UTC",
    "updated_date": "2025-04-28 12:09:07 UTC"
  },
  {
    "arxiv_id": "2504.19678v1",
    "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review",
    "authors": [
      "Mohamed Amine Ferrag",
      "Norbert Tihanyi",
      "Merouane Debbah"
    ],
    "abstract": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19678v1",
    "published_date": "2025-04-28 11:08:22 UTC",
    "updated_date": "2025-04-28 11:08:22 UTC"
  },
  {
    "arxiv_id": "2504.19675v1",
    "title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs",
    "authors": [
      "Osma Suominen",
      "Juho Inkinen",
      "Mona Lehtinen"
    ],
    "abstract": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects",
    "pdf_url": "http://arxiv.org/pdf/2504.19675v1",
    "published_date": "2025-04-28 11:04:23 UTC",
    "updated_date": "2025-04-28 11:04:23 UTC"
  },
  {
    "arxiv_id": "2504.19674v1",
    "title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation",
    "authors": [
      "Madhur Jindal",
      "Hari Shrawgi",
      "Parag Agrawal",
      "Sandipan Dandapat"
    ],
    "abstract": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 9 main pages excluding references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.19674v1",
    "published_date": "2025-04-28 11:01:08 UTC",
    "updated_date": "2025-04-28 11:01:08 UTC"
  },
  {
    "arxiv_id": "2504.19673v1",
    "title": "Generative AI in Education: Student Skills and Lecturer Roles",
    "authors": [
      "Stefanie Krause",
      "Ashish Dalvi",
      "Syed Khubaib Zaidi"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19673v1",
    "published_date": "2025-04-28 10:58:30 UTC",
    "updated_date": "2025-04-28 10:58:30 UTC"
  },
  {
    "arxiv_id": "2504.19667v1",
    "title": "A Tripartite Perspective on GraphRAG",
    "authors": [
      "Michael Banf",
      "Johannes Kuhn"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19667v1",
    "published_date": "2025-04-28 10:43:35 UTC",
    "updated_date": "2025-04-28 10:43:35 UTC"
  },
  {
    "arxiv_id": "2505.01441v1",
    "title": "Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning",
    "authors": [
      "Joykirat Singh",
      "Raghav Magazine",
      "Yash Pandya",
      "Akshay Nambi"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable progress in complex\nreasoning tasks, yet they remain fundamentally limited by their reliance on\nstatic internal knowledge and text-only reasoning. Real-world problem solving\noften demands dynamic, multi-step reasoning, adaptive decision making, and the\nability to interact with external tools and environments. In this work, we\nintroduce ARTIST (Agentic Reasoning and Tool Integration in Self-improving\nTransformers), a unified framework that tightly couples agentic reasoning,\nreinforcement learning, and tool integration for LLMs. ARTIST enables models to\nautonomously decide when, how, and which tools to invoke within multi-turn\nreasoning chains, leveraging outcome-based RL to learn robust strategies for\ntool use and environment interaction without requiring step-level supervision.\nExtensive experiments on mathematical reasoning and multi-turn function calling\nbenchmarks show that ARTIST consistently outperforms state-of-the-art\nbaselines, with up to 22% absolute improvement over base models and strong\ngains on the most challenging tasks. Detailed studies and metric analyses\nreveal that agentic RL training leads to deeper reasoning, more effective tool\nuse, and higher-quality solutions. Our results establish agentic RL with tool\nintegration as a powerful new frontier for robust, interpretable, and\ngeneralizable problem-solving in LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01441v1",
    "published_date": "2025-04-28 10:42:49 UTC",
    "updated_date": "2025-04-28 10:42:49 UTC"
  },
  {
    "arxiv_id": "2504.19659v1",
    "title": "Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs",
    "authors": [
      "Muhammad Sabih",
      "Abrarul Karim",
      "Jakob Wittmann",
      "Frank Hannig",
      "Jürgen Teich"
    ],
    "abstract": "The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19659v1",
    "published_date": "2025-04-28 10:19:39 UTC",
    "updated_date": "2025-04-28 10:19:39 UTC"
  },
  {
    "arxiv_id": "2504.19654v1",
    "title": "Transformation & Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM",
    "authors": [
      "Leon Davies",
      "Baihua Li",
      "Mohamad Saada",
      "Simon Sølvsten",
      "Qinggang Meng"
    ],
    "abstract": "SLAM (Simultaneous Localisation and Mapping) is a crucial component for\nrobotic systems, providing a map of an environment, the current location and\nprevious trajectory of a robot. While 3D LiDAR SLAM has received notable\nimprovements in recent years, 2D SLAM lags behind. Gradual drifts in odometry\nand pose estimation inaccuracies hinder modern 2D LiDAR-odometry algorithms in\nlarge complex environments. Dynamic robotic motion coupled with inherent\nestimation based SLAM processes introduce noise and errors, degrading map\nquality. Occupancy Grid Mapping (OGM) produces results that are often noisy and\nunclear. This is due to the fact that evidence based mapping represents maps\naccording to uncertain observations. This is why OGMs are so popular in\nexploration or navigation tasks. However, this also limits OGMs' effectiveness\nfor specific mapping based tasks such as floor plan creation in complex scenes.\nTo address this, we propose our novel Transformation and Translation Occupancy\nGrid Mapping (TT-OGM). We adapt and enable accurate and robust pose estimation\ntechniques from 3D SLAM to the world of 2D and mitigate errors to improve map\nquality using Generative Adversarial Networks (GANs). We introduce a novel data\ngeneration method via deep reinforcement learning (DRL) to build datasets large\nenough for training a GAN for SLAM error correction. We demonstrate our SLAM in\nreal-time on data collected at Loughborough University. We also prove its\ngeneralisability on a variety of large complex environments on a collection of\nlarge scale well-known 2D occupancy maps. Our novel approach enables the\ncreation of high quality OGMs in complex scenes, far surpassing the\ncapabilities of current SLAM algorithms in terms of quality, accuracy and\nreliability.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, preprint, submitted to Robotics And Autonomous Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.19654v1",
    "published_date": "2025-04-28 10:13:47 UTC",
    "updated_date": "2025-04-28 10:13:47 UTC"
  },
  {
    "arxiv_id": "2504.19653v1",
    "title": "GAN-SLAM: Real-Time GAN Aided Floor Plan Creation Through SLAM",
    "authors": [
      "Leon Davies",
      "Baihua Li",
      "Mohamad Saada",
      "Simon Sølvsten",
      "Qinggang Meng"
    ],
    "abstract": "SLAM is a fundamental component of modern autonomous systems, providing\nrobots and their operators with a deeper understanding of their environment.\nSLAM systems often encounter challenges due to the dynamic nature of robotic\nmotion, leading to inaccuracies in mapping quality, particularly in 2D\nrepresentations such as Occupancy Grid Maps. These errors can significantly\ndegrade map quality, hindering the effectiveness of specific downstream tasks\nsuch as floor plan creation. To address this challenge, we introduce our novel\n'GAN-SLAM', a new SLAM approach that leverages Generative Adversarial Networks\nto clean and complete occupancy grids during the SLAM process, reducing the\nimpact of noise and inaccuracies introduced on the output map. We adapt and\nintegrate accurate pose estimation techniques typically used for 3D SLAM into a\n2D form. This enables the quality improvement 3D LiDAR-odometry has seen in\nrecent years to be effective for 2D representations. Our results demonstrate\nsubstantial improvements in map fidelity and quality, with minimal noise and\nerrors, affirming the effectiveness of GAN-SLAM for real-world mapping\napplications within large-scale complex environments. We validate our approach\non real-world data operating in real-time, and on famous examples of 2D maps.\nThe improved quality of the output map enables new downstream tasks, such as\nfloor plan drafting, further enhancing the capabilities of autonomous systems.\nOur novel approach to SLAM offers a significant step forward in the field,\nimproving the usability for SLAM in mapping-based tasks, and offers insight\ninto the usage of GANs for OGM error correction.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, preprint conference submission",
    "pdf_url": "http://arxiv.org/pdf/2504.19653v1",
    "published_date": "2025-04-28 10:13:38 UTC",
    "updated_date": "2025-04-28 10:13:38 UTC"
  },
  {
    "arxiv_id": "2504.19645v1",
    "title": "A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks",
    "authors": [
      "Shadan Shukr Sabr",
      "Nazira Sabr Mustafa",
      "Talar Sabah Omar",
      "Salah Hwayyiz Rasool",
      "Nawzad Anwer Omer",
      "Darya Sabir Hamad",
      "Hemin Abdulhameed Shams",
      "Omer Mahmood Kareem",
      "Rozhan Noori Abdullah",
      "Khabat Atar Abdullah",
      "Mahabad Azad Mohammad",
      "Haneen Al-Raghefy",
      "Safar M. Asaad",
      "Sara Jamal Mohammed",
      "Twana Saeed Ali",
      "Fazil Shawrow",
      "Halgurd S. Maghdid"
    ],
    "abstract": "- The field of natural language processing (NLP) has dramatically expanded\nwithin the last decade. Many human-being applications are conducted daily via\nNLP tasks, starting from machine translation, speech recognition, text\ngeneration and recommendations, Part-of-Speech tagging (POS), and Named-Entity\nRecognition (NER). However, low-resourced languages, such as the\nCentral-Kurdish language (CKL), mainly remain unexamined due to shortage of\nnecessary resources to support their development. The POS tagging task is the\nbase of other NLP tasks; for example, the POS tag set has been used to\nstandardized languages to provide the relationship between words among the\nsentences, followed by machine translation and text recommendation.\nSpecifically, for the CKL, most of the utilized or provided POS tagsets are\nneither standardized nor comprehensive. To this end, this study presented an\naccurate and comprehensive POS tagset for the CKL to provide better performance\nof the Kurdish NLP tasks. The article also collected most of the POS tags from\ndifferent studies as well as from Kurdish linguistic experts to standardized\npart-of-speech tags. The proposed POS tagset is designed to annotate a large\nCKL corpus and support Kurdish NLP tasks. The initial investigations of this\nstudy via comparison with the Universal Dependencies framework for standard\nlanguages, show that the proposed POS tagset can streamline or correct\nsentences more accurately for Kurdish NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "K.5; K.7; J.7"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.19645v1",
    "published_date": "2025-04-28 10:02:11 UTC",
    "updated_date": "2025-04-28 10:02:11 UTC"
  },
  {
    "arxiv_id": "2504.19636v2",
    "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search",
    "authors": [
      "Fei Liu",
      "Qingfu Zhang",
      "Xialiang Tong",
      "Kun Mao",
      "Mingxuan Yuan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19636v2",
    "published_date": "2025-04-28 09:52:41 UTC",
    "updated_date": "2025-05-01 08:33:32 UTC"
  },
  {
    "arxiv_id": "2504.19627v2",
    "title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning",
    "authors": [
      "Run Luo",
      "Renke Shan",
      "Longze Chen",
      "Ziqiang Liu",
      "Lu Wang",
      "Min Yang",
      "Xiaobo Xia"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like\nembodied intelligence due to their strong vision-language reasoning abilities.\nHowever, current LVLMs process entire images at the token level, which is\ninefficient compared to humans who analyze information and generate content at\nthe conceptual level, extracting relevant visual concepts with minimal effort.\nThis inefficiency, stemming from the lack of a visual concept model, limits\nLVLMs' usability in real-world applications. To address this, we propose VCM,\nan end-to-end self-supervised visual concept modeling framework. VCM leverages\nimplicit contrastive learning across multiple sampled instances and\nvision-language fine-tuning to construct a visual concept model without\nrequiring costly concept-level annotations. Our results show that VCM\nsignificantly reduces computational costs (e.g., 85\\% fewer FLOPs for\nLLaVA-1.5-7B) while maintaining strong performance across diverse image\nunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities in\nclassic visual concept perception tasks. Extensive quantitative and qualitative\nexperiments validate the effectiveness and efficiency of VCM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "VCM",
    "pdf_url": "http://arxiv.org/pdf/2504.19627v2",
    "published_date": "2025-04-28 09:39:07 UTC",
    "updated_date": "2025-05-19 13:44:04 UTC"
  },
  {
    "arxiv_id": "2505.02843v1",
    "title": "Physical foundations for trustworthy medical imaging: a review for artificial intelligence researchers",
    "authors": [
      "Miriam Cobo",
      "David Corral Fontecha",
      "Wilson Silva",
      "Lara Lloret Iglesias"
    ],
    "abstract": "Artificial intelligence in medical imaging has seen unprecedented growth in\nthe last years, due to rapid advances in deep learning and computing resources.\nApplications cover the full range of existing medical imaging modalities, with\nunique characteristics driven by the physics of each technique. Yet, artificial\nintelligence professionals entering the field, and even experienced developers,\noften lack a comprehensive understanding of the physical principles underlying\nmedical image acquisition, which hinders their ability to fully leverage its\npotential. The integration of physics knowledge into artificial intelligence\nalgorithms enhances their trustworthiness and robustness in medical imaging,\nespecially in scenarios with limited data availability. In this work, we review\nthe fundamentals of physics in medical images and their impact on the latest\nadvances in artificial intelligence, particularly, in generative models and\nreconstruction algorithms. Finally, we explore the integration of physics\nknowledge into physics-inspired machine learning models, which leverage\nphysics-based constraints to enhance the learning of medical imaging features.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "17 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02843v1",
    "published_date": "2025-04-28 09:35:00 UTC",
    "updated_date": "2025-04-28 09:35:00 UTC"
  },
  {
    "arxiv_id": "2504.19622v1",
    "title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models",
    "authors": [
      "Minsu Kim",
      "Sangryul Kim",
      "James Thorne"
    ],
    "abstract": "This paper investigates the knowledge of language models from the perspective\nof Bayesian epistemology. We explore how language models adjust their\nconfidence and responses when presented with evidence with varying levels of\ninformativeness and reliability. To study these properties, we create a dataset\nwith various types of evidence and analyze language models' responses and\nconfidence using verbalized confidence, token probability, and sampling. We\nobserved that language models do not consistently follow Bayesian epistemology:\nlanguage models follow the Bayesian confirmation assumption well with true\nevidence but fail to adhere to other Bayesian assumptions when encountering\ndifferent evidence types. Also, we demonstrated that language models can\nexhibit high confidence when given strong evidence, but this does not always\nguarantee high accuracy. Our analysis also reveals that language models are\nbiased toward golden evidence and show varying performance depending on the\ndegree of irrelevance, helping explain why they deviate from Bayesian\nassumptions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19622v1",
    "published_date": "2025-04-28 09:28:42 UTC",
    "updated_date": "2025-04-28 09:28:42 UTC"
  },
  {
    "arxiv_id": "2504.19600v1",
    "title": "Image Generation Method Based on Heat Diffusion Models",
    "authors": [
      "Pengfei Zhang",
      "Shouqing Jia"
    ],
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image\ngeneration without adversarial training, but they process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM is a model that incorporates pixel-level\noperations while maintaining the same training process as DDPM. In HDM, the\ndiscrete form of the two-dimensional heat equation is integrated into the\ndiffusion and generation formulas of DDPM, enabling the model to compute\nrelationships between neighboring pixels during image processing. Our\nexperiments demonstrate that HDM can generate higher-quality samples compared\nto models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion\nModels (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19600v1",
    "published_date": "2025-04-28 09:03:33 UTC",
    "updated_date": "2025-04-28 09:03:33 UTC"
  },
  {
    "arxiv_id": "2504.19599v2",
    "title": "GVPO: Group Variance Policy Optimization for Large Language Model Post-Training",
    "authors": [
      "Kaichen Zhang",
      "Yuzhong Hong",
      "Junwei Bao",
      "Hongfei Jiang",
      "Yang Song",
      "Dingqian Hong",
      "Hui Xiong"
    ],
    "abstract": "Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19599v2",
    "published_date": "2025-04-28 09:02:24 UTC",
    "updated_date": "2025-05-19 06:40:29 UTC"
  },
  {
    "arxiv_id": "2504.19598v1",
    "title": "Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection",
    "authors": [
      "Dou Quan",
      "Rufan Zhou",
      "Shuang Wang",
      "Ning Huyan",
      "Dong Zhao",
      "Yunan Li",
      "Licheng Jiao"
    ],
    "abstract": "Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19598v1",
    "published_date": "2025-04-28 09:01:56 UTC",
    "updated_date": "2025-04-28 09:01:56 UTC"
  },
  {
    "arxiv_id": "2504.19595v2",
    "title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution",
    "authors": [
      "Pietro Bongini",
      "Sara Mandelli",
      "Andrea Montibeller",
      "Mirko Casu",
      "Orazio Pontorno",
      "Claudio Vittorio Ragaglia",
      "Luca Zanchetta",
      "Mattia Aquilina",
      "Taiba Majid Wani",
      "Luca Guarnera",
      "Benedetta Tondi",
      "Giulia Boato",
      "Paolo Bestagini",
      "Irene Amerini",
      "Francesco De Natale",
      "Sebastiano Battiato",
      "Mauro Barni"
    ],
    "abstract": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19595v2",
    "published_date": "2025-04-28 08:58:34 UTC",
    "updated_date": "2025-04-29 09:01:26 UTC"
  },
  {
    "arxiv_id": "2504.19594v2",
    "title": "Mapping the Italian Telegram Ecosystem: Communities, Toxicity, and Hate Speech",
    "authors": [
      "Lorenzo Alvisi",
      "Serena Tardelli",
      "Maurizio Tesconi"
    ],
    "abstract": "Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19594v2",
    "published_date": "2025-04-28 08:58:18 UTC",
    "updated_date": "2025-05-05 09:35:11 UTC"
  },
  {
    "arxiv_id": "2504.19592v1",
    "title": "Neural network task specialization via domain constraining",
    "authors": [
      "Roman Malashin",
      "Daniil Ilyukhin"
    ],
    "abstract": "This paper introduces a concept of neural network specialization via\ntask-specific domain constraining, aimed at enhancing network performance on\ndata subspace in which the network operates. The study presents experiments on\ntraining specialists for image classification and object detection tasks. The\nresults demonstrate that specialization can enhance a generalist's accuracy\neven without additional data or changing training regimes: solely by\nconstraining class label space in which the network performs. Theoretical and\nexperimental analyses indicate that effective specialization requires modifying\ntraditional fine-tuning methods and constraining data space to semantically\ncoherent subsets. The specialist extraction phase before tuning the network is\nproposed for maximal performance gains. We also provide analysis of the\nevolution of the feature space during specialization. This study paves way to\nfuture research for developing more advanced dynamically configurable image\nanalysis systems, where computations depend on the specific input.\nAdditionally, the proposed methods can help improve system performance in\nscenarios where certain data domains should be excluded from consideration of\nthe generalist network.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19592v1",
    "published_date": "2025-04-28 08:57:01 UTC",
    "updated_date": "2025-04-28 08:57:01 UTC"
  },
  {
    "arxiv_id": "2505.00032v1",
    "title": "MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis",
    "authors": [
      "Yuyang Sha",
      "Hongxin Pan",
      "Wei Xu",
      "Weiyu Meng",
      "Gang Luo",
      "Xinyu Du",
      "Xiaobing Zhai",
      "Henry H. Y. Tong",
      "Caijuan Shi",
      "Kefeng Li"
    ],
    "abstract": "Major depressive disorder (MDD) impacts more than 300 million people\nworldwide, highlighting a significant public health issue. However, the uneven\ndistribution of medical resources and the complexity of diagnostic methods have\nresulted in inadequate attention to this disorder in numerous countries and\nregions. This paper introduces a high-performance MDD diagnosis tool named\nMDD-LLM, an AI-driven framework that utilizes fine-tuned large language models\n(LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis.\nTherefore, we select 274,348 individual information from the UK Biobank cohort\nto train and evaluate the proposed method. Specifically, we select 274,348\nindividual records from the UK Biobank cohort and design a tabular data\ntransformation method to create a large corpus for training and evaluating the\nproposed approach. To illustrate the advantages of MDD-LLM, we perform\ncomprehensive experiments and provide several comparative analyses against\nexisting model-based solutions across multiple evaluation metrics. Experimental\nresults show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of\n0.8919 (95% CI: 0.8799 - 0.9040), significantly outperforming existing machine\nlearning and deep learning frameworks for MDD diagnosis. Given the limited\nexploration of LLMs in MDD diagnosis, we examine numerous factors that may\ninfluence the performance of our proposed method, such as tabular data\ntransformation techniques and different fine-tuning strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00032v1",
    "published_date": "2025-04-28 08:53:55 UTC",
    "updated_date": "2025-04-28 08:53:55 UTC"
  },
  {
    "arxiv_id": "2504.19590v1",
    "title": "Arabic Metaphor Sentiment Classification Using Semantic Information",
    "authors": [
      "Israa Alsiyat"
    ],
    "abstract": "In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19590v1",
    "published_date": "2025-04-28 08:53:28 UTC",
    "updated_date": "2025-04-28 08:53:28 UTC"
  },
  {
    "arxiv_id": "2504.21039v1",
    "title": "Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report",
    "authors": [
      "Paul Kassianik",
      "Baturay Saglam",
      "Alexander Chen",
      "Blaine Nelson",
      "Anu Vellore",
      "Massimo Aufiero",
      "Fraser Burch",
      "Dhruv Kedia",
      "Avi Zohary",
      "Sajana Weerawardhena",
      "Aman Priyanshu",
      "Adam Swanda",
      "Amy Chang",
      "Hyrum Anderson",
      "Kojin Oshiba",
      "Omar Santos",
      "Yaron Singer",
      "Amin Karbasi"
    ],
    "abstract": "As transformer-based large language models (LLMs) increasingly permeate\nsociety, they have revolutionized domains such as software engineering,\ncreative writing, and digital arts. However, their adoption in cybersecurity\nremains limited due to challenges like scarcity of specialized training data\nand complexity of representing cybersecurity-specific knowledge. To address\nthese gaps, we present Foundation-Sec-8B, a cybersecurity-focused LLM built on\nthe Llama 3.1 architecture and enhanced through continued pretraining on a\ncarefully curated cybersecurity corpus. We evaluate Foundation-Sec-8B across\nboth established and new cybersecurity benchmarks, showing that it matches\nLlama 3.1-70B and GPT-4o-mini in certain cybersecurity-specific tasks. By\nreleasing our model to the public, we aim to accelerate progress and adoption\nof AI-driven tools in both public and private cybersecurity contexts.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21039v1",
    "published_date": "2025-04-28 08:41:12 UTC",
    "updated_date": "2025-04-28 08:41:12 UTC"
  },
  {
    "arxiv_id": "2504.20119v2",
    "title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets",
    "authors": [
      "Lorenz Brehme",
      "Thomas Ströhle",
      "Ruth Breu"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "8 Pages. This paper has been accepted for presentation at the IEEE\n  Swiss Conference on Data Science (SDS25)",
    "pdf_url": "http://arxiv.org/pdf/2504.20119v2",
    "published_date": "2025-04-28 08:22:19 UTC",
    "updated_date": "2025-05-01 13:03:37 UTC"
  },
  {
    "arxiv_id": "2504.19565v1",
    "title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
    "authors": [
      "Meng Xiao",
      "Xunxin Cai",
      "Chengrui Wang",
      "Yuanchun Zhou"
    ],
    "abstract": "The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, Large Language Model, Agentic AI, Dataset Distillation,\n  Multi-agent Collaboration",
    "pdf_url": "http://arxiv.org/pdf/2504.19565v1",
    "published_date": "2025-04-28 08:18:24 UTC",
    "updated_date": "2025-04-28 08:18:24 UTC"
  },
  {
    "arxiv_id": "2504.20118v1",
    "title": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis",
    "authors": [
      "Jinglin He",
      "Yunqi Guo",
      "Lai Kwan Lam",
      "Waikei Leung",
      "Lixing He",
      "Yuanan Jiang",
      "Chi Chiu Wang",
      "Guoliang Xing",
      "Hongkai Chen"
    ],
    "abstract": "Traditional Chinese Medicine (TCM) represents a rich repository of ancient\nmedical knowledge that continues to play an important role in modern\nhealthcare. Due to the complexity and breadth of the TCM literature, the\nintegration of AI technologies is critical for its modernization and broader\naccessibility. However, this integration poses considerable challenges,\nincluding the interpretation of obscure classical Chinese texts and the\nmodeling of intricate semantic relationships among TCM concepts. In this paper,\nwe develop OpenTCM, an LLM-based system that combines a domain-specific TCM\nknowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG).\nFirst, we extract more than 3.73 million classical Chinese characters from 68\ngynecological books in the Chinese Medical Classics Database, with the help of\nTCM and gynecology experts. Second, we construct a comprehensive\nmulti-relational knowledge graph comprising more than 48,000 entities and\n152,000 interrelationships, using customized prompts and Chinese-oriented LLMs\nsuch as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last,\nwe integrate OpenTCM with this knowledge graph, enabling high-fidelity\ningredient knowledge retrieval and diagnostic question-answering without model\nfine-tuning. Experimental evaluations demonstrate that our prompt design and\nmodel selection significantly improve knowledge graph quality, achieving a\nprecision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves\nmean expert scores of 4.5 in ingredient information retrieval and 3.8 in\ndiagnostic question-answering tasks, outperforming state-of-the-art solutions\nin real-world TCM use cases.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.20118v1",
    "published_date": "2025-04-28 08:04:44 UTC",
    "updated_date": "2025-04-28 08:04:44 UTC"
  },
  {
    "arxiv_id": "2504.19545v1",
    "title": "Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction",
    "authors": [
      "Zezeng Li",
      "Zhihui Qi",
      "Weimin Wang",
      "Ziliang Wang",
      "Junyi Duan",
      "Na Lei"
    ],
    "abstract": "Quad meshes are essential in geometric modeling and computational mechanics.\nAlthough learning-based methods for triangle mesh demonstrate considerable\nadvancements, quad mesh generation remains less explored due to the challenge\nof ensuring coplanarity, convexity, and quad-only meshes. In this paper, we\npresent Point2Quad, the first learning-based method for quad-only mesh\ngeneration from point clouds. The key idea is learning to identify quad mesh\nwith fused pointwise and facewise features. Specifically, Point2Quad begins\nwith a k-NN-based candidate generation considering the coplanarity and\nsquareness. Then, two encoders are followed to extract geometric and\ntopological features that address the challenge of quad-related constraints,\nespecially by combining in-depth quadrilaterals-specific characteristics.\nSubsequently, the extracted features are fused to train the classifier with a\ndesigned compound loss. The final results are derived after the refinement by a\nquad-specific post-processing. Extensive experiments on both clear and noise\ndata demonstrate the effectiveness and superiority of Point2Quad, compared to\nbaseline methods under comprehensive metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19545v1",
    "published_date": "2025-04-28 07:48:17 UTC",
    "updated_date": "2025-04-28 07:48:17 UTC"
  },
  {
    "arxiv_id": "2504.21038v1",
    "title": "Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary",
    "authors": [
      "Yakai Li",
      "Jiekang Hu",
      "Weiduan Sang",
      "Luping Ma",
      "Jing Xie",
      "Weijuan Zhang",
      "Aimin Yu",
      "Shijie Zhao",
      "Qingjia Huang",
      "Qihang Zhou"
    ],
    "abstract": "Large Language Models (LLMs) are designed to generate helpful and safe\ncontent. However, adversarial attacks, commonly referred to as jailbreak, can\nbypass their safety protocols, prompting LLMs to generate harmful content or\nreveal sensitive data. Consequently, investigating jailbreak methodologies is\ncrucial for exposing systemic vulnerabilities within LLMs, ultimately guiding\nthe continuous implementation of security enhancements by developers. In this\npaper, we introduce a novel jailbreak attack method that leverages the\nprefilling feature of LLMs, a feature designed to enhance model output\nconstraints. Unlike traditional jailbreak methods, the proposed attack\ncircumvents LLMs' safety mechanisms by directly manipulating the probability\ndistribution of subsequent tokens, thereby exerting control over the model's\noutput. We propose two attack variants: Static Prefilling (SP), which employs a\nuniversal prefill text, and Optimized Prefilling (OP), which iteratively\noptimizes the prefill text to maximize the attack success rate. Experiments on\nsix state-of-the-art LLMs using the AdvBench benchmark validate the\neffectiveness of our method and demonstrate its capability to substantially\nenhance attack success rates when combined with existing jailbreak approaches.\nThe OP method achieved attack success rates of up to 99.82% on certain models,\nsignificantly outperforming baseline methods. This work introduces a new\njailbreak attack method in LLMs, emphasizing the need for robust content\nvalidation mechanisms to mitigate the adversarial exploitation of prefilling\nfeatures. All code and data used in this paper are publicly available.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21038v1",
    "published_date": "2025-04-28 07:38:43 UTC",
    "updated_date": "2025-04-28 07:38:43 UTC"
  },
  {
    "arxiv_id": "2504.20117v2",
    "title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies",
    "authors": [
      "Shubham Gandhi",
      "Dhruv Shah",
      "Manasi Patwardhan",
      "Lovekesh Vig",
      "Gautam Shroff"
    ],
    "abstract": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20117v2",
    "published_date": "2025-04-28 07:18:45 UTC",
    "updated_date": "2025-05-03 16:45:38 UTC"
  },
  {
    "arxiv_id": "2505.00031v1",
    "title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving",
    "authors": [
      "Jin Zhang",
      "Flood Sung",
      "Zhilin Yang",
      "Yang Gao",
      "Chongjie Zhang"
    ],
    "abstract": "In the field of large language model (LLM) post-training, the effectiveness\nof utilizing synthetic data generated by the LLM itself has been\nwell-presented. However, a key question remains unaddressed: what essential\ninformation should such self-generated data encapsulate? Existing approaches\nonly produce step-by-step problem solutions, and fail to capture the abstract\nmeta-knowledge necessary for generalization across similar problems. Drawing\ninsights from cognitive science, where humans employ high-level abstraction to\nsimplify complex problems before delving into specifics, we introduce a novel\nself-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains\nthe LLM to formulate anticipatory plans, which serve as abstract meta-knowledge\nfor problem-solving, before engaging with the intricacies of problems. This\napproach not only outlines the solution generation path but also shields the\nLLM from the distraction of irrelevant details. During data generation, LEPA\nfirst crafts an anticipatory plan based on the problem, and then generates a\nsolution that aligns with both the plan and the problem. LEPA refines the plan\nthrough self-reflection, aiming to acquire plans that are instrumental in\nyielding correct solutions. During model optimization, the LLM is trained to\npredict both the refined plans and the corresponding solutions. By efficiently\nextracting and utilizing the anticipatory plans, LEPA demonstrates remarkable\nsuperiority over conventional algorithms on various challenging natural\nlanguage reasoning benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00031v1",
    "published_date": "2025-04-28 06:32:58 UTC",
    "updated_date": "2025-04-28 06:32:58 UTC"
  },
  {
    "arxiv_id": "2504.21037v1",
    "title": "Security Bug Report Prediction Within and Across Projects: A Comparative Study of BERT and Random Forest",
    "authors": [
      "Farnaz Soltaniani",
      "Mohammad Ghafari",
      "Mohammed Sayagh"
    ],
    "abstract": "Early detection of security bug reports (SBRs) is crucial for preventing\nvulnerabilities and ensuring system reliability. While machine learning models\nhave been developed for SBR prediction, their predictive performance still has\nroom for improvement. In this study, we conduct a comprehensive comparison\nbetween BERT and Random Forest (RF), a competitive baseline for predicting\nSBRs. The results show that RF outperforms BERT with a 34% higher average\nG-measure for within-project predictions. Adding only SBRs from various\nprojects improves both models' average performance. However, including both\nsecurity and nonsecurity bug reports significantly reduces RF's average\nperformance to 46%, while boosts BERT to its best average performance of 66%,\nsurpassing RF. In cross-project SBR prediction, BERT achieves a remarkable 62%\nG-measure, which is substantially higher than RF.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21037v1",
    "published_date": "2025-04-28 06:09:01 UTC",
    "updated_date": "2025-04-28 06:09:01 UTC"
  },
  {
    "arxiv_id": "2504.20115v1",
    "title": "AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers",
    "authors": [
      "Zijie Lin",
      "Yiqing Shen",
      "Qilin Cai",
      "He Sun",
      "Jinrui Zhou",
      "Mingjun Xiao"
    ],
    "abstract": "Machine Learning (ML) research is spread through academic papers featuring\nrich multimodal content, including text, diagrams, and tabular results.\nHowever, translating these multimodal elements into executable code remains a\nchallenging and time-consuming process that requires substantial ML expertise.\nWe introduce ``Paper-to-Code'' (P2C), a novel task that transforms the\nmultimodal content of scientific publications into fully executable code\nrepositories, which extends beyond the existing formulation of code generation\nthat merely converts textual descriptions into isolated code snippets. To\nautomate the P2C process, we propose AutoP2C, a multi-agent framework based on\nlarge language models that processes both textual and visual content from\nresearch papers to generate complete code repositories. Specifically, AutoP2C\ncontains four stages: (1) repository blueprint extraction from established\ncodebases, (2) multimodal content parsing that integrates information from\ntext, equations, and figures, (3) hierarchical task decomposition for\nstructured code generation, and (4) iterative feedback-driven debugging to\nensure functionality and performance. Evaluation on a benchmark of eight\nresearch papers demonstrates the effectiveness of AutoP2C, which can\nsuccessfully generate executable code repositories for all eight papers, while\nOpenAI-o1 or DeepSeek-R1 can only produce runnable code for one paper. The code\nis available at https://github.com/shoushouyu/Automated-Paper-to-Code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20115v1",
    "published_date": "2025-04-28 05:47:37 UTC",
    "updated_date": "2025-04-28 05:47:37 UTC"
  },
  {
    "arxiv_id": "2504.19499v1",
    "title": "Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks",
    "authors": [
      "Omid Semiari",
      "Hosein Nikopour",
      "Shilpa Talwar"
    ],
    "abstract": "Next-generation wireless cellular networks are expected to provide\nunparalleled Quality-of-Service (QoS) for emerging wireless applications,\nnecessitating strict performance guarantees, e.g., in terms of link-level data\nrates. A critical challenge in meeting these QoS requirements is the prevention\nof cell congestion, which involves balancing the load to ensure sufficient\nradio resources are available for each cell to serve its designated User\nEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approach\nis developed to optimize the performance of Guaranteed Bit Rate (GBR) and Best\nEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoS\nand resource constraints. The proposed solution builds on Graph Reinforcement\nLearning (GRL), a powerful framework at the intersection of Graph Neural\nNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,\nwith states represented as graphs. QoS consideration are integrated into both\nstate representations and reward signal design. The LB agent is then trained\nusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-based\narchitecture. This design ensures the LB policy is invariant to the ordering of\nnodes (UE or cell), flexible in handling various network sizes, and capable of\naccounting for spatial node dependencies in LB decisions. Performance of the\nGRL-based solution is compared with two baseline methods. Results show\nsubstantial performance gains, including a $53\\%$ reduction in QoS violations\nand a fourfold increase in the 5th percentile rate for BE traffic.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.NI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in the proceedings of the 2025 IEEE International\n  Conference on Communications (ICC), Seventh Workshop on Data Driven\n  Intelligence for Networks and Systems (DDINS)",
    "pdf_url": "http://arxiv.org/pdf/2504.19499v1",
    "published_date": "2025-04-28 05:41:31 UTC",
    "updated_date": "2025-04-28 05:41:31 UTC"
  },
  {
    "arxiv_id": "2504.19496v1",
    "title": "DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction",
    "authors": [
      "Rudy Morel",
      "Jiequn Han",
      "Edouard Oyallon"
    ],
    "abstract": "We address the problem of predicting the next state of a dynamical system\ngoverned by unknown temporal partial differential equations (PDEs) using only a\nshort trajectory. While standard transformers provide a natural black-box\nsolution to this task, the presence of a well-structured evolution operator in\nthe data suggests a more tailored and efficient approach. Specifically, when\nthe PDE is fully known, classical numerical solvers can evolve the state\naccurately with only a few parameters. Building on this observation, we\nintroduce DISCO, a model that uses a large hypernetwork to process a short\ntrajectory and generate the parameters of a much smaller operator network,\nwhich then predicts the next state through time integration. Our framework\ndecouples dynamics estimation (i.e., DISCovering an evolution operator from a\nshort trajectory) from state prediction (i.e., evolving this operator).\nExperiments show that pretraining our model on diverse physics datasets\nachieves state-of-the-art performance while requiring significantly fewer\nepochs. Moreover, it generalizes well and remains competitive when fine-tuned\non downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19496v1",
    "published_date": "2025-04-28 05:36:52 UTC",
    "updated_date": "2025-04-28 05:36:52 UTC"
  },
  {
    "arxiv_id": "2504.21036v2",
    "title": "Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?",
    "authors": [
      "Hao Du",
      "Shang Liu",
      "Yang Cao"
    ],
    "abstract": "Fine-tuning large language models (LLMs) has become an essential strategy for\nadapting them to specialized tasks; however, this process introduces\nsignificant privacy challenges, as sensitive training data may be inadvertently\nmemorized and exposed. Although differential privacy (DP) offers strong\ntheoretical guarantees against such leakage, its empirical privacy\neffectiveness on LLMs remains unclear, especially under different fine-tuning\nmethods. In this paper, we systematically investigate the impact of DP across\nfine-tuning methods and privacy budgets, using both data extraction and\nmembership inference attacks to assess empirical privacy risks. Our main\nfindings are as follows: (1) Differential privacy reduces model utility, but\nits impact varies significantly across different fine-tuning methods. (2)\nWithout DP, the privacy risks of models fine-tuned with different approaches\ndiffer considerably. (3) When DP is applied, even a relatively high privacy\nbudget can substantially lower privacy risk. (4) The privacy-utility trade-off\nunder DP training differs greatly among fine-tuning methods, with some methods\nbeing unsuitable for DP due to severe utility degradation. Our results provide\npractical guidance for privacy-conscious deployment of LLMs and pave the way\nfor future research on optimizing the privacy-utility trade-off in fine-tuning\nmethodologies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "accepted by DBSec25",
    "pdf_url": "http://arxiv.org/pdf/2504.21036v2",
    "published_date": "2025-04-28 05:34:53 UTC",
    "updated_date": "2025-05-01 10:10:01 UTC"
  },
  {
    "arxiv_id": "2505.01440v1",
    "title": "Interactive Double Deep Q-network: Integrating Human Interventions and Evaluative Predictions in Reinforcement Learning of Autonomous Driving",
    "authors": [
      "Alkis Sygkounas",
      "Ioannis Athanasiadis",
      "Andreas Persson",
      "Michael Felsberg",
      "Amy Loutfi"
    ],
    "abstract": "Integrating human expertise with machine learning is crucial for applications\ndemanding high accuracy and safety, such as autonomous driving. This study\nintroduces Interactive Double Deep Q-network (iDDQN), a Human-in-the-Loop\n(HITL) approach that enhances Reinforcement Learning (RL) by merging human\ninsights directly into the RL training process, improving model performance.\nOur proposed iDDQN method modifies the Q-value update equation to integrate\nhuman and agent actions, establishing a collaborative approach for policy\ndevelopment. Additionally, we present an offline evaluative framework that\nsimulates the agent's trajectory as if no human intervention had occurred, to\nassess the effectiveness of human interventions. Empirical results in simulated\nautonomous driving scenarios demonstrate that iDDQN outperforms established\napproaches, including Behavioral Cloning (BC), HG-DAgger, Deep Q-Learning from\nDemonstrations (DQfD), and vanilla DRL in leveraging human expertise for\nimproving performance and adaptability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2025, 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.01440v1",
    "published_date": "2025-04-28 05:25:18 UTC",
    "updated_date": "2025-04-28 05:25:18 UTC"
  },
  {
    "arxiv_id": "2504.19483v1",
    "title": "Improving Reasoning Performance in Large Language Models via Representation Engineering",
    "authors": [
      "Bertram Højer",
      "Oliver Jarvis",
      "Stefan Heinrich"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Has been accepted at \"The Thirteenth International Conference on\n  Learning Representations (ICLR 2025)\" Link to publication:\n  https://openreview.net/forum?id=IssPhpUsKt",
    "pdf_url": "http://arxiv.org/pdf/2504.19483v1",
    "published_date": "2025-04-28 04:58:43 UTC",
    "updated_date": "2025-04-28 04:58:43 UTC"
  },
  {
    "arxiv_id": "2504.19480v1",
    "title": "An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination",
    "authors": [
      "Dixiao Wei",
      "Peng Yi",
      "Jinlong Lei",
      "Yiguang Hong",
      "Yuchuan Du"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19480v1",
    "published_date": "2025-04-28 04:41:15 UTC",
    "updated_date": "2025-04-28 04:41:15 UTC"
  },
  {
    "arxiv_id": "2504.19475v1",
    "title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video",
    "authors": [
      "Sonia Joseph",
      "Praneet Suresh",
      "Lorenz Hufe",
      "Edward Stevinson",
      "Robert Graham",
      "Yash Vadi",
      "Danilo Bzdok",
      "Sebastian Lapuschkin",
      "Lee Sharkey",
      "Blake Aaron Richards"
    ],
    "abstract": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 3 figures, 9 tables. Oral and Tutorial at the CVPR\n  Mechanistic Interpretability for Vision (MIV) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.19475v1",
    "published_date": "2025-04-28 04:31:24 UTC",
    "updated_date": "2025-04-28 04:31:24 UTC"
  },
  {
    "arxiv_id": "2504.19467v2",
    "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text",
    "authors": [
      "Jiageng Wu",
      "Bowen Gu",
      "Ren Zhou",
      "Kevin Xie",
      "Doug Snyder",
      "Yixing Jiang",
      "Valentina Carducci",
      "Richard Wyss",
      "Rishi J Desai",
      "Emily Alsentzer",
      "Leo Anthony Celi",
      "Adam Rodman",
      "Sebastian Schneeweiss",
      "Jonathan H. Chen",
      "Santiago Romero-Brufau",
      "Kueiyu Joshua Lin",
      "Jie Yang"
    ],
    "abstract": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19467v2",
    "published_date": "2025-04-28 04:13:18 UTC",
    "updated_date": "2025-05-01 02:21:09 UTC"
  },
  {
    "arxiv_id": "2504.19460v1",
    "title": "A Real-Time Gesture-Based Control Framework",
    "authors": [
      "Mahya Khazaei",
      "Ali Bahrani",
      "George Tzanetakis"
    ],
    "abstract": "We introduce a real-time, human-in-the-loop gesture control framework that\ncan dynamically adapt audio and music based on human movement by analyzing live\nvideo input. By creating a responsive connection between visual and auditory\nstimuli, this system enables dancers and performers to not only respond to\nmusic but also influence it through their movements. Designed for live\nperformances, interactive installations, and personal use, it offers an\nimmersive experience where users can shape the music in real time.\n  The framework integrates computer vision and machine learning techniques to\ntrack and interpret motion, allowing users to manipulate audio elements such as\ntempo, pitch, effects, and playback sequence. With ongoing training, it\nachieves user-independent functionality, requiring as few as 50 to 80 samples\nto label simple gestures. This framework combines gesture training, cue\nmapping, and audio manipulation to create a dynamic, interactive experience.\nGestures are interpreted as input signals, mapped to sound control commands,\nand used to naturally adjust music elements, showcasing the seamless interplay\nbetween human interaction and machine response.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 4 figures, 2025 International Computer Music Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.19460v1",
    "published_date": "2025-04-28 03:57:28 UTC",
    "updated_date": "2025-04-28 03:57:28 UTC"
  },
  {
    "arxiv_id": "2504.19457v1",
    "title": "Towards Long Context Hallucination Detection",
    "authors": [
      "Siyi Liu",
      "Kishaloy Halder",
      "Zheng Qi",
      "Wei Xiao",
      "Nikolaos Pappas",
      "Phu Mon Htut",
      "Neha Anna John",
      "Yassine Benajiba",
      "Dan Roth"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. However, they are prone to contextual hallucination, generating\ninformation that is either unsubstantiated or contradictory to the given\ncontext. Although many studies have investigated contextual hallucinations in\nLLMs, addressing them in long-context inputs remains an open problem. In this\nwork, we take an initial step toward solving this problem by constructing a\ndataset specifically designed for long-context hallucination detection.\nFurthermore, we propose a novel architecture that enables pre-trained encoder\nmodels, such as BERT, to process long contexts and effectively detect\ncontextual hallucinations through a decomposition and aggregation mechanism.\nOur experimental results show that the proposed architecture significantly\noutperforms previous models of similar size as well as LLM-based models across\nvarious metrics, while providing substantially faster inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19457v1",
    "published_date": "2025-04-28 03:47:05 UTC",
    "updated_date": "2025-04-28 03:47:05 UTC"
  },
  {
    "arxiv_id": "2504.19443v1",
    "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions",
    "authors": [
      "Yejin Jeong",
      "Donghun Lee"
    ],
    "abstract": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.19443v1",
    "published_date": "2025-04-28 03:10:24 UTC",
    "updated_date": "2025-04-28 03:10:24 UTC"
  },
  {
    "arxiv_id": "2504.19432v1",
    "title": "EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation",
    "authors": [
      "Zhe Dong",
      "Yuzhe Sun",
      "Tianzhu Liu",
      "Wangmeng Zuo",
      "Yanfeng Gu"
    ],
    "abstract": "Satellite imagery and maps, as two fundamental data modalities in remote\nsensing, offer direct observations of the Earth's surface and\nhuman-interpretable geographic abstractions, respectively. The task of\nbidirectional translation between satellite images and maps (BSMT) holds\nsignificant potential for applications in urban planning and disaster response.\nHowever, this task presents two major challenges: first, the absence of precise\npixel-wise alignment between the two modalities substantially complicates the\ntranslation process; second, it requires achieving both high-level abstraction\nof geographic features and high-quality visual synthesis, which further\nelevates the technical complexity. To address these limitations, we introduce\nEarthMapper, a novel autoregressive framework for controllable bidirectional\nsatellite-map translation. EarthMapper employs geographic coordinate embeddings\nto anchor generation, ensuring region-specific adaptability, and leverages\nmulti-scale feature alignment within a geo-conditioned joint scale\nautoregression (GJSA) process to unify bidirectional translation in a single\ntraining cycle. A semantic infusion (SI) mechanism is introduced to enhance\nfeature-level consistency, while a key point adaptive guidance (KPAG) mechanism\nis proposed to dynamically balance diversity and precision during inference. We\nfurther contribute CNSatMap, a large-scale dataset comprising 302,132 precisely\naligned satellite-map pairs across 38 Chinese cities, enabling robust\nbenchmarking. Extensive experiments on CNSatMap and the New York dataset\ndemonstrate EarthMapper's superior performance, achieving significant\nimprovements in visual realism, semantic consistency, and structural fidelity\nover state-of-the-art methods. Additionally, EarthMapper excels in zero-shot\ntasks like in-painting, out-painting and coordinate-conditional generation,\nunderscoring its versatility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19432v1",
    "published_date": "2025-04-28 02:41:12 UTC",
    "updated_date": "2025-04-28 02:41:12 UTC"
  },
  {
    "arxiv_id": "2504.19426v1",
    "title": "Sharp higher order convergence rates for the Adam optimizer",
    "authors": [
      "Steffen Dereich",
      "Arnulf Jentzen",
      "Adrian Riekert"
    ],
    "abstract": "Gradient descent based optimization methods are the methods of choice to\ntrain deep neural networks in machine learning. Beyond the standard gradient\ndescent method, also suitable modified variants of standard gradient descent\ninvolving acceleration techniques such as the momentum method and/or adaptivity\ntechniques such as the RMSprop method are frequently considered optimization\nmethods. These days the most popular of such sophisticated optimization schemes\nis presumably the Adam optimizer that has been proposed in 2014 by Kingma and\nBa. A highly relevant topic of research is to investigate the speed of\nconvergence of such optimization methods. In particular, in 1964 Polyak showed\nthat the standard gradient descent method converges in a neighborhood of a\nstrict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves\nthe (optimal) strictly faster convergence rate (\\sqrt{x} - 1)(\\sqrt{x} +\n1)^{-1} where x \\in (1,\\infty) is the condition number (the ratio of the\nlargest and the smallest eigenvalue) of the Hessian of the objective function\nat the local minimizer. It is the key contribution of this work to reveal that\nAdam also converges with the strictly faster convergence rate (\\sqrt{x} -\n1)(\\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x\n- 1)(x + 1)^{-1}.",
    "categories": [
      "math.OC",
      "cs.AI",
      "68T05, 65K05, 90C25",
      "I.2.0"
    ],
    "primary_category": "math.OC",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19426v1",
    "published_date": "2025-04-28 02:17:50 UTC",
    "updated_date": "2025-04-28 02:17:50 UTC"
  },
  {
    "arxiv_id": "2504.20114v2",
    "title": "TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering",
    "authors": [
      "Zhonghao Li",
      "Kunpeng Zhang",
      "Jinghuai Ou",
      "Shuliang Liu",
      "Xuming Hu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) systems face significant challenges in\nmulti-hop question answering (MHQA), where complex queries require synthesizing\ninformation across multiple document chunks. Existing approaches typically rely\non iterative LLM-based query rewriting and routing, resulting in high\ncomputational costs due to repeated LLM invocations and multi-stage processes.\nTo address these limitations, we propose TreeHop, an embedding-level framework\nwithout the need for LLMs in query refinement. TreeHop dynamically updates\nquery embeddings by fusing semantic information from prior queries and\nretrieved documents, enabling iterative retrieval through embedding-space\noperations alone. This method replaces the traditional\n\"Retrieve-Rewrite-Vectorize-Retrieve\" cycle with a streamlined\n\"Retrieve-Embed-Retrieve\" loop, significantly reducing computational overhead.\nMoreover, a rule-based stop criterion is introduced to further prune redundant\nretrievals, balancing efficiency and recall rate. Experimental results show\nthat TreeHop rivals advanced RAG methods across three open-domain MHQA\ndatasets, achieving comparable performance with only 5\\%-0.4\\% of the model\nparameter size and reducing the query latency by approximately 99\\% compared to\nconcurrent approaches. This makes TreeHop a faster and more cost-effective\nsolution for deployment in a range of knowledge-intensive applications. For\nreproducibility purposes, codes and data are available here:\nhttps://github.com/allen-li1231/TreeHop-RAG.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.20114v2",
    "published_date": "2025-04-28 01:56:31 UTC",
    "updated_date": "2025-04-30 13:15:49 UTC"
  },
  {
    "arxiv_id": "2504.19413v1",
    "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
    "authors": [
      "Prateek Chhikara",
      "Dev Khant",
      "Saket Aryan",
      "Taranjeet Singh",
      "Deshraj Yadav"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable prowess in\ngenerating contextually coherent responses, yet their fixed context windows\npose fundamental challenges for maintaining consistency over prolonged\nmulti-session dialogues. We introduce Mem0, a scalable memory-centric\narchitecture that addresses this issue by dynamically extracting,\nconsolidating, and retrieving salient information from ongoing conversations.\nBuilding on this foundation, we further propose an enhanced variant that\nleverages graph-based memory representations to capture complex relational\nstructures among conversational elements. Through comprehensive evaluations on\nLOCOMO benchmark, we systematically compare our approaches against six baseline\ncategories: (i) established memory-augmented systems, (ii) retrieval-augmented\ngeneration (RAG) with varying chunk sizes and k-values, (iii) a full-context\napproach that processes the entire conversation history, (iv) an open-source\nmemory solution, (v) a proprietary model system, and (vi) a dedicated memory\nmanagement platform. Empirical results show that our methods consistently\noutperform all existing memory systems across four question categories:\nsingle-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26%\nrelative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with\ngraph memory achieves around 2% higher overall score than the base\nconfiguration. Beyond accuracy gains, we also markedly reduce computational\noverhead compared to full-context method. In particular, Mem0 attains a 91%\nlower p95 latency and saves more than 90% token cost, offering a compelling\nbalance between advanced reasoning capabilities and practical deployment\nconstraints. Our findings highlight critical role of structured, persistent\nmemory mechanisms for long-term conversational coherence, paving the way for\nmore reliable and efficient LLM-driven AI agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19413v1",
    "published_date": "2025-04-28 01:46:35 UTC",
    "updated_date": "2025-04-28 01:46:35 UTC"
  },
  {
    "arxiv_id": "2504.19409v2",
    "title": "GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field",
    "authors": [
      "Zuxing Lu",
      "Xin Yuan",
      "Shaowen Yang",
      "Jingyu Liu",
      "Changyin Sun"
    ],
    "abstract": "Semantic-aware 3D scene reconstruction is essential for autonomous robots to\nperform complex interactions. Semantic SLAM, an online approach, integrates\npose tracking, geometric reconstruction, and semantic mapping into a unified\nframework, shows significant potential. However, existing systems, which rely\non 2D ground truth priors for supervision, are often limited by the sparsity\nand noise of these signals in real-world environments. To address this\nchallenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D\nGaussian Splatting that leverages feature fields to achieve joint rendering of\nappearance, geometry, and N-dimensional semantic features. By independently\noptimizing feature gradients, our method supports semantic reconstruction using\nvarious forms of 2D priors, particularly sparse and noisy signals. Experimental\nresults demonstrate that our approach outperforms previous methods in both\ntracking accuracy and photorealistic rendering quality. When utilizing 2D\nground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation\nperformance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with\nonly marginal performance degradation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19409v2",
    "published_date": "2025-04-28 01:21:35 UTC",
    "updated_date": "2025-05-16 23:51:06 UTC"
  },
  {
    "arxiv_id": "2504.20113v1",
    "title": "Transforming Evidence Synthesis: A Systematic Review of the Evolution of Automated Meta-Analysis in the Age of AI",
    "authors": [
      "Lingbo Li",
      "Anuradha Mathrani",
      "Teo Susnjak"
    ],
    "abstract": "Exponential growth in scientific literature has heightened the demand for\nefficient evidence-based synthesis, driving the rise of the field of Automated\nMeta-analysis (AMA) powered by natural language processing and machine\nlearning. This PRISMA systematic review introduces a structured framework for\nassessing the current state of AMA, based on screening 978 papers from 2006 to\n2024, and analyzing 54 studies across diverse domains. Findings reveal a\npredominant focus on automating data processing (57%), such as extraction and\nstatistical modeling, while only 17% address advanced synthesis stages. Just\none study (2%) explored preliminary full-process automation, highlighting a\ncritical gap that limits AMA's capacity for comprehensive synthesis. Despite\nrecent breakthroughs in large language models (LLMs) and advanced AI, their\nintegration into statistical modeling and higher-order synthesis, such as\nheterogeneity assessment and bias evaluation, remains underdeveloped. This has\nconstrained AMA's potential for fully autonomous meta-analysis. From our\ndataset spanning medical (67%) and non-medical (33%) applications, we found\nthat AMA has exhibited distinct implementation patterns and varying degrees of\neffectiveness in actually improving efficiency, scalability, and\nreproducibility. While automation has enhanced specific meta-analytic tasks,\nachieving seamless, end-to-end automation remains an open challenge. As AI\nsystems advance in reasoning and contextual understanding, addressing these\ngaps is now imperative. Future efforts must focus on bridging automation across\nall meta-analysis stages, refining interpretability, and ensuring\nmethodological robustness to fully realize AMA's potential for scalable,\ndomain-agnostic synthesis.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20113v1",
    "published_date": "2025-04-28 00:40:17 UTC",
    "updated_date": "2025-04-28 00:40:17 UTC"
  }
]