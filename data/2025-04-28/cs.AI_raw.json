[
  {
    "arxiv_id": "2504.20026v1",
    "title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields",
    "authors": [
      "Zhengqin Li",
      "Dilin Wang",
      "Ka Chen",
      "Zhaoyang Lv",
      "Thu Nguyen-Phuoc",
      "Milim Lee",
      "Jia-Bin Huang",
      "Lei Xiao",
      "Cheng Zhang",
      "Yufeng Zhu",
      "Carl S. Marshall",
      "Yufeng Ren",
      "Richard Newcombe",
      "Zhao Dong"
    ],
    "abstract": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20026v1",
    "published_date": "2025-04-28 17:48:58 UTC",
    "updated_date": "2025-04-28 17:48:58 UTC"
  },
  {
    "arxiv_id": "2504.20020v1",
    "title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models",
    "authors": [
      "Xin Wang",
      "Haoyang Li",
      "Zeyang Zhang",
      "Haibo Chen",
      "Wenwu Zhu"
    ],
    "abstract": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.20020v1",
    "published_date": "2025-04-28 17:42:02 UTC",
    "updated_date": "2025-04-28 17:42:02 UTC"
  },
  {
    "arxiv_id": "2504.20019v1",
    "title": "Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control",
    "authors": [
      "Abdelhakim Amer",
      "David Felsager",
      "Yury Brodskiy",
      "Andriy Sarabakha"
    ],
    "abstract": "Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2025. The final version consists\n  of 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.20019v1",
    "published_date": "2025-04-28 17:38:57 UTC",
    "updated_date": "2025-04-28 17:38:57 UTC"
  },
  {
    "arxiv_id": "2504.20018v1",
    "title": "MINT: Multi-Vector Search Index Tuning",
    "authors": [
      "Jiongli Zhu",
      "Yue Wang",
      "Bailu Ding",
      "Philip A. Bernstein",
      "Vivek Narasayya",
      "Surajit Chaudhuri"
    ],
    "abstract": "Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20018v1",
    "published_date": "2025-04-28 17:36:06 UTC",
    "updated_date": "2025-04-28 17:36:06 UTC"
  },
  {
    "arxiv_id": "2504.20010v1",
    "title": "Towards Automated Scoping of AI for Social Good Projects",
    "authors": [
      "Jacob Emmerson",
      "Rayid Ghani",
      "Zheyuan Ryan Shi"
    ],
    "abstract": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20010v1",
    "published_date": "2025-04-28 17:29:51 UTC",
    "updated_date": "2025-04-28 17:29:51 UTC"
  },
  {
    "arxiv_id": "2504.20007v1",
    "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
    "authors": [
      "Anita Srbinovska",
      "Angela Srbinovska",
      "Vivek Senthil",
      "Adrian Martin",
      "John McCluskey",
      "Ernest Fokou√©"
    ],
    "abstract": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures, and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.20007v1",
    "published_date": "2025-04-28 17:25:23 UTC",
    "updated_date": "2025-04-28 17:25:23 UTC"
  },
  {
    "arxiv_id": "2504.19997v1",
    "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration",
    "authors": [
      "Ivo Brett"
    ],
    "abstract": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19997v1",
    "published_date": "2025-04-28 17:17:42 UTC",
    "updated_date": "2025-04-28 17:17:42 UTC"
  },
  {
    "arxiv_id": "2504.19996v1",
    "title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery",
    "authors": [
      "Andreas Kalogeras",
      "Dimitrios Bormpoudakis",
      "Iason Tsardanidis",
      "Dimitra A. Loka",
      "Charalampos Kontoes"
    ],
    "abstract": "The widespread use of Exogenous Organic Matter in agriculture necessitates\nmonitoring to assess its effects on soil and crop health. This study evaluates\noptical Sentinel-2 satellite imagery for detecting digestate application, a\npractice that enhances soil fertility but poses environmental risks like\nmicroplastic contamination and nitrogen losses. In the first instance,\nSentinel-2 satellite image time series (SITS) analysis of specific indices\n(EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after\napplication on the soils of four different crop types in Thessaly, Greece.\nFurthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient\nBoosting and a Feed-Forward Neural Network), were used to investigate digestate\npresence detection, achieving F1-scores up to 0.85. The findings highlight the\npotential of combining remote sensing and ML for scalable and cost-effective\nmonitoring of EOM applications, supporting precision agriculture and\nsustainability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19996v1",
    "published_date": "2025-04-28 17:16:40 UTC",
    "updated_date": "2025-04-28 17:16:40 UTC"
  },
  {
    "arxiv_id": "2504.19990v1",
    "title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and Directions",
    "authors": [
      "Salem Lahlou"
    ],
    "abstract": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19990v1",
    "published_date": "2025-04-28 17:06:30 UTC",
    "updated_date": "2025-04-28 17:06:30 UTC"
  },
  {
    "arxiv_id": "2504.19985v1",
    "title": "Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao Robot: A Closed-Loop Approach",
    "authors": [
      "Keyhan Rayati",
      "Amirhossein Feizi",
      "Alireza Beigy",
      "Pourya Shahverdi",
      "Mehdi Tale Masouleh",
      "Ahmad Kalhor"
    ],
    "abstract": "This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19985v1",
    "published_date": "2025-04-28 17:01:54 UTC",
    "updated_date": "2025-04-28 17:01:54 UTC"
  },
  {
    "arxiv_id": "2504.19982v1",
    "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons",
    "authors": [
      "Emre Can Acikgoz",
      "Carl Guo",
      "Suvodip Dey",
      "Akul Datta",
      "Takyoung Kim",
      "Gokhan Tur",
      "Dilek Hakkani-T√ºr"
    ],
    "abstract": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19982v1",
    "published_date": "2025-04-28 16:57:17 UTC",
    "updated_date": "2025-04-28 16:57:17 UTC"
  },
  {
    "arxiv_id": "2504.19968v1",
    "title": "How Group Lives Go Well",
    "authors": [
      "John Beverley",
      "Regina Hurley"
    ],
    "abstract": "This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19968v1",
    "published_date": "2025-04-28 16:40:06 UTC",
    "updated_date": "2025-04-28 16:40:06 UTC"
  },
  {
    "arxiv_id": "2504.19967v1",
    "title": "Enhancing short-term traffic prediction by integrating trends and fluctuations with attention mechanism",
    "authors": [
      "Adway Das",
      "Agnimitra Sengupta",
      "S. Ilgin Guler"
    ],
    "abstract": "Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19967v1",
    "published_date": "2025-04-28 16:38:46 UTC",
    "updated_date": "2025-04-28 16:38:46 UTC"
  },
  {
    "arxiv_id": "2504.19956v1",
    "title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents",
    "authors": [
      "Vineeth Sai Narajala",
      "Om Narayan"
    ],
    "abstract": "As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 2 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.19956v1",
    "published_date": "2025-04-28 16:29:24 UTC",
    "updated_date": "2025-04-28 16:29:24 UTC"
  },
  {
    "arxiv_id": "2504.19951v1",
    "title": "Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach",
    "authors": [
      "Vineeth Sai Narajala",
      "Ken Huang",
      "Idan Habler"
    ],
    "abstract": "The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 4 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.19951v1",
    "published_date": "2025-04-28 16:22:21 UTC",
    "updated_date": "2025-04-28 16:22:21 UTC"
  },
  {
    "arxiv_id": "2504.19949v1",
    "title": "Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving Intelligent System",
    "authors": [
      "Aydoƒüan Soylu",
      "Tufan Kumbasar"
    ],
    "abstract": "Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "in International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.19949v1",
    "published_date": "2025-04-28 16:21:20 UTC",
    "updated_date": "2025-04-28 16:21:20 UTC"
  },
  {
    "arxiv_id": "2504.19944v1",
    "title": "Probabilistic and Causal Satisfiability: Constraining the Model",
    "authors": [
      "Markus Bl√§ser",
      "Julian D√∂rfler",
      "Maciej Li≈õkiewicz",
      "Benito van der Zander"
    ],
    "abstract": "We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CC",
    "comment": "accepted at ICALP 25",
    "pdf_url": "http://arxiv.org/pdf/2504.19944v1",
    "published_date": "2025-04-28 16:14:06 UTC",
    "updated_date": "2025-04-28 16:14:06 UTC"
  },
  {
    "arxiv_id": "2504.19933v1",
    "title": "Automated decision-making for dynamic task assignment at scale",
    "authors": [
      "Riccardo Lo Bianco",
      "Willem van Jaarsveld",
      "Jeroen Middelhuis",
      "Luca Begnardi",
      "Remco Dijkman"
    ],
    "abstract": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19933v1",
    "published_date": "2025-04-28 16:08:35 UTC",
    "updated_date": "2025-04-28 16:08:35 UTC"
  },
  {
    "arxiv_id": "2504.19918v1",
    "title": "Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI",
    "authors": [
      "Hugo Georgenthum",
      "Cristian Cosentino",
      "Fabrizio Marozzo",
      "Pietro Li√≤"
    ],
    "abstract": "The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19918v1",
    "published_date": "2025-04-28 15:46:02 UTC",
    "updated_date": "2025-04-28 15:46:02 UTC"
  },
  {
    "arxiv_id": "2504.19912v1",
    "title": "Can AI Agents Design and Implement Drug Discovery Pipelines?",
    "authors": [
      "Khachik Smbatyan",
      "Tsolak Ghukasyan",
      "Tigran Aghajanyan",
      "Hovhannes Dabaghyan",
      "Sergey Adamyan",
      "Aram Bughdaryan",
      "Vahagn Altunyan",
      "Gagik Navasardyan",
      "Aram Davtyan",
      "Anush Hakobyan",
      "Aram Gharibyan",
      "Arman Fahradyan",
      "Artur Hakobyan",
      "Hasmik Mnatsakanyan",
      "Narek Ginoyan",
      "Garik Petrosyan"
    ],
    "abstract": "The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19912v1",
    "published_date": "2025-04-28 15:41:28 UTC",
    "updated_date": "2025-04-28 15:41:28 UTC"
  },
  {
    "arxiv_id": "2504.19901v1",
    "title": "Attention Mechanism, Max-Affine Partition, and Universal Approximation",
    "authors": [
      "Hude Liu",
      "Jerry Yao-Chieh Hu",
      "Zhao Song",
      "Han Liu"
    ],
    "abstract": "We establish the universal approximation capability of single-layer,\nsingle-head self- and cross-attention mechanisms with minimal attached\nstructures. Our key insight is to interpret single-head attention as an input\ndomain-partition mechanism that assigns distinct values to subregions. This\nallows us to engineer the attention weights such that this assignment imitates\nthe target function. Building on this, we prove that a single self-attention\nlayer, preceded by sum-of-linear transformations, is capable of approximating\nany continuous function on a compact domain under the $L_\\infty$-norm.\nFurthermore, we extend this construction to approximate any Lebesgue integrable\nfunction under $L_p$-norm for $1\\leq p <\\infty$. Lastly, we also extend our\ntechniques and show that, for the first time, single-head cross-attention\nachieves the same universal approximation guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19901v1",
    "published_date": "2025-04-28 15:31:45 UTC",
    "updated_date": "2025-04-28 15:31:45 UTC"
  },
  {
    "arxiv_id": "2504.19900v1",
    "title": "Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning",
    "authors": [
      "Han Chen",
      "Anne L. Martel"
    ],
    "abstract": "Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19900v1",
    "published_date": "2025-04-28 15:31:08 UTC",
    "updated_date": "2025-04-28 15:31:08 UTC"
  },
  {
    "arxiv_id": "2504.19874v1",
    "title": "TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate",
    "authors": [
      "Amir Zandieh",
      "Majid Daliri",
      "Majid Hadian",
      "Vahab Mirrokni"
    ],
    "abstract": "Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19874v1",
    "published_date": "2025-04-28 15:05:35 UTC",
    "updated_date": "2025-04-28 15:05:35 UTC"
  },
  {
    "arxiv_id": "2504.19863v1",
    "title": "Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer",
    "authors": [
      "Daniel Kienzle",
      "Robin Sch√∂n",
      "Rainer Lienhart",
      "Shin'Ichi Satoh"
    ],
    "abstract": "Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in 2025 IEEE/CVF International Conference on Computer\n  Vision and Pattern Recognition Workshops (CVPRW)",
    "pdf_url": "http://arxiv.org/pdf/2504.19863v1",
    "published_date": "2025-04-28 14:55:12 UTC",
    "updated_date": "2025-04-28 14:55:12 UTC"
  },
  {
    "arxiv_id": "2504.19854v1",
    "title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks",
    "authors": [
      "Chia-Yu Hung",
      "Qi Sun",
      "Pengfei Hong",
      "Amir Zadeh",
      "Chuan Li",
      "U-Xuan Tan",
      "Navonil Majumder",
      "Soujanya Poria"
    ],
    "abstract": "Existing Visual-Language-Action (VLA) models have shown promising performance\nin zero-shot scenarios, demonstrating impressive task execution and reasoning\ncapabilities. However, a significant challenge arises from the limitations of\nvisual encoding, which can result in failures during tasks such as object\ngrasping. Moreover, these models typically suffer from high computational\noverhead due to their large sizes, often exceeding 7B parameters. While these\nmodels excel in reasoning and task planning, the substantial computational\noverhead they incur makes them impractical for real-time robotic environments,\nwhere speed and efficiency are paramount. To address the limitations of\nexisting VLA models, we propose NORA, a 3B-parameter model designed to reduce\ncomputational overhead while maintaining strong task performance. NORA adopts\nthe Qwen-2.5-VL-3B multimodal model as its backbone, leveraging its superior\nvisual-semantic understanding to enhance visual reasoning and action grounding.\nAdditionally, our \\model{} is trained on 970k real-world robot demonstrations\nand equipped with the FAST+ tokenizer for efficient action sequence generation.\nExperimental results demonstrate that NORA outperforms existing large-scale VLA\nmodels, achieving better task performance with significantly reduced\ncomputational overhead, making it a more practical solution for real-time\nrobotic autonomy.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19854v1",
    "published_date": "2025-04-28 14:47:34 UTC",
    "updated_date": "2025-04-28 14:47:34 UTC"
  },
  {
    "arxiv_id": "2504.19848v1",
    "title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study",
    "authors": [
      "Simona Casini",
      "Pietro Ducange",
      "Francesco Marcelloni",
      "Lorenzo Pollini"
    ],
    "abstract": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "International Joint Conference on Neural Network 2025 - Accepted",
    "pdf_url": "http://arxiv.org/pdf/2504.19848v1",
    "published_date": "2025-04-28 14:45:48 UTC",
    "updated_date": "2025-04-28 14:45:48 UTC"
  },
  {
    "arxiv_id": "2504.19847v1",
    "title": "Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration",
    "authors": [
      "Juhan Park",
      "Kyungjae Lee",
      "Hyung Jin Chang",
      "Jungchan Cho"
    ],
    "abstract": "In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19847v1",
    "published_date": "2025-04-28 14:45:26 UTC",
    "updated_date": "2025-04-28 14:45:26 UTC"
  },
  {
    "arxiv_id": "2504.19822v1",
    "title": "Mj√∂lnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density",
    "authors": [
      "Minjong Cheon"
    ],
    "abstract": "Recent advances in AI-based weather forecasting models, such as FourCastNet,\nPangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep\nlearning to emulate complex atmospheric dynamics. Building on this momentum, we\npropose Mj\\\"olnir, a novel deep learning-based framework for global lightning\nflash density parameterization. Trained on ERA5 atmospheric predictors and\nWorld Wide Lightning Location Network (WWLLN) observations at a daily temporal\nresolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear\nmapping between large-scale environmental conditions and lightning activity.\nThe model architecture is based on the InceptionNeXt backbone with SENet, and a\nmulti-task learning strategy to simultaneously predict lightning occurrence and\nmagnitude. Extensive evaluations yield that Mollnir accurately reproduces the\nglobal distribution, seasonal variability, and regional characteristics of\nlightning activity, achieving a global Pearson correlation coefficient of 0.96\nfor annual mean fields. These results suggest that Mj\\\"olnir serves not only as\nan effective data-driven global lightning parameterization but also as a\npromising AI-based scheme for next-generation Earth system models (AI-ESMs).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19822v1",
    "published_date": "2025-04-28 14:22:59 UTC",
    "updated_date": "2025-04-28 14:22:59 UTC"
  },
  {
    "arxiv_id": "2504.19818v1",
    "title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping",
    "authors": [
      "Feng Chen",
      "Ilias Stogiannidis",
      "Andrew Wood",
      "Danilo Bueno",
      "Dominic Williams",
      "Fraser Macfarlane",
      "Bruce Grieve",
      "Darren Wells",
      "Jonathan A. Atkinson",
      "Malcolm J. Hawkesford",
      "Stephen A. Rolfe",
      "Tracy Lawson",
      "Tony Pridmore",
      "Mario Valerio Giuffrida",
      "Sotirios A. Tsaftaris"
    ],
    "abstract": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19818v1",
    "published_date": "2025-04-28 14:20:30 UTC",
    "updated_date": "2025-04-28 14:20:30 UTC"
  },
  {
    "arxiv_id": "2504.19792v1",
    "title": "Contextures: The Mechanism of Representation Learning",
    "authors": [
      "Runtian Zhai"
    ],
    "abstract": "This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "PhD Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2504.19792v1",
    "published_date": "2025-04-28 13:36:28 UTC",
    "updated_date": "2025-04-28 13:36:28 UTC"
  },
  {
    "arxiv_id": "2504.19755v1",
    "title": "Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment",
    "authors": [
      "Kapil Kashyap",
      "Sean Fargose",
      "Chrisil Dabre",
      "Fatema Dolaria",
      "Nilesh Patil",
      "Aniket Kore"
    ],
    "abstract": "Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19755v1",
    "published_date": "2025-04-28 12:54:51 UTC",
    "updated_date": "2025-04-28 12:54:51 UTC"
  },
  {
    "arxiv_id": "2504.19754v1",
    "title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation",
    "authors": [
      "Carlo Merola",
      "Jaspinder Singh"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages, 2 figures, Second Workshop on Knowledge-Enhanced\n  Information Retrieval, ECIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.19754v1",
    "published_date": "2025-04-28 12:52:05 UTC",
    "updated_date": "2025-04-28 12:52:05 UTC"
  },
  {
    "arxiv_id": "2504.19738v1",
    "title": "Learning Efficiency Meets Symmetry Breaking",
    "authors": [
      "Yingbin Bai",
      "Sylvie Thiebaux",
      "Felipe Trevizan"
    ],
    "abstract": "Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19738v1",
    "published_date": "2025-04-28 12:33:39 UTC",
    "updated_date": "2025-04-28 12:33:39 UTC"
  },
  {
    "arxiv_id": "2504.19720v1",
    "title": "Taming the Titans: A Survey of Efficient LLM Inference Serving",
    "authors": [
      "Ranran Zhen",
      "Juntao Li",
      "Yixin Ji",
      "Zhenlin Yang",
      "Tong Liu",
      "Qingrong Xia",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) for Generative AI have achieved remarkable\nprogress, evolving into sophisticated and versatile tools widely adopted across\nvarious domains and applications. However, the substantial memory overhead\ncaused by their vast number of parameters, combined with the high computational\ndemands of the attention mechanism, poses significant challenges in achieving\nlow latency and high throughput for LLM inference services. Recent\nadvancements, driven by groundbreaking research, have significantly accelerated\nprogress in this field. This paper provides a comprehensive survey of these\nmethods, covering fundamental instance-level approaches, in-depth cluster-level\nstrategies, emerging scenario directions, and other miscellaneous but important\nareas. At the instance level, we review model placement, request scheduling,\ndecoding length prediction, storage management, and the disaggregation\nparadigm. At the cluster level, we explore GPU cluster deployment,\nmulti-instance load balancing, and cloud service solutions. For emerging\nscenarios, we organize the discussion around specific tasks, modules, and\nauxiliary methods. To ensure a holistic overview, we also highlight several\nniche yet critical areas. Finally, we outline potential research directions to\nfurther advance the field of LLM inference serving.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress;11 pages of main paper with 7 main figures, overall\n  20 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19720v1",
    "published_date": "2025-04-28 12:14:02 UTC",
    "updated_date": "2025-04-28 12:14:02 UTC"
  },
  {
    "arxiv_id": "2504.19715v1",
    "title": "Model-based controller assisted domain randomization in deep reinforcement learning: application to nonlinear powertrain control",
    "authors": [
      "Heisei Yonezawa",
      "Ansei Yonezawa",
      "Itsuro Kajiwara"
    ],
    "abstract": "Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19715v1",
    "published_date": "2025-04-28 12:09:07 UTC",
    "updated_date": "2025-04-28 12:09:07 UTC"
  },
  {
    "arxiv_id": "2504.19678v1",
    "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review",
    "authors": [
      "Mohamed Amine Ferrag",
      "Norbert Tihanyi",
      "Merouane Debbah"
    ],
    "abstract": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19678v1",
    "published_date": "2025-04-28 11:08:22 UTC",
    "updated_date": "2025-04-28 11:08:22 UTC"
  },
  {
    "arxiv_id": "2504.19675v1",
    "title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs",
    "authors": [
      "Osma Suominen",
      "Juho Inkinen",
      "Mona Lehtinen"
    ],
    "abstract": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects",
    "pdf_url": "http://arxiv.org/pdf/2504.19675v1",
    "published_date": "2025-04-28 11:04:23 UTC",
    "updated_date": "2025-04-28 11:04:23 UTC"
  },
  {
    "arxiv_id": "2504.19674v1",
    "title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation",
    "authors": [
      "Madhur Jindal",
      "Hari Shrawgi",
      "Parag Agrawal",
      "Sandipan Dandapat"
    ],
    "abstract": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 9 main pages excluding references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.19674v1",
    "published_date": "2025-04-28 11:01:08 UTC",
    "updated_date": "2025-04-28 11:01:08 UTC"
  },
  {
    "arxiv_id": "2504.19673v1",
    "title": "Generative AI in Education: Student Skills and Lecturer Roles",
    "authors": [
      "Stefanie Krause",
      "Ashish Dalvi",
      "Syed Khubaib Zaidi"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19673v1",
    "published_date": "2025-04-28 10:58:30 UTC",
    "updated_date": "2025-04-28 10:58:30 UTC"
  },
  {
    "arxiv_id": "2504.19667v1",
    "title": "A Tripartite Perspective on GraphRAG",
    "authors": [
      "Michael Banf",
      "Johannes Kuhn"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19667v1",
    "published_date": "2025-04-28 10:43:35 UTC",
    "updated_date": "2025-04-28 10:43:35 UTC"
  },
  {
    "arxiv_id": "2504.19659v1",
    "title": "Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs",
    "authors": [
      "Muhammad Sabih",
      "Abrarul Karim",
      "Jakob Wittmann",
      "Frank Hannig",
      "J√ºrgen Teich"
    ],
    "abstract": "The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19659v1",
    "published_date": "2025-04-28 10:19:39 UTC",
    "updated_date": "2025-04-28 10:19:39 UTC"
  },
  {
    "arxiv_id": "2504.19654v1",
    "title": "Transformation & Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM",
    "authors": [
      "Leon Davies",
      "Baihua Li",
      "Mohamad Saada",
      "Simon S√∏lvsten",
      "Qinggang Meng"
    ],
    "abstract": "SLAM (Simultaneous Localisation and Mapping) is a crucial component for\nrobotic systems, providing a map of an environment, the current location and\nprevious trajectory of a robot. While 3D LiDAR SLAM has received notable\nimprovements in recent years, 2D SLAM lags behind. Gradual drifts in odometry\nand pose estimation inaccuracies hinder modern 2D LiDAR-odometry algorithms in\nlarge complex environments. Dynamic robotic motion coupled with inherent\nestimation based SLAM processes introduce noise and errors, degrading map\nquality. Occupancy Grid Mapping (OGM) produces results that are often noisy and\nunclear. This is due to the fact that evidence based mapping represents maps\naccording to uncertain observations. This is why OGMs are so popular in\nexploration or navigation tasks. However, this also limits OGMs' effectiveness\nfor specific mapping based tasks such as floor plan creation in complex scenes.\nTo address this, we propose our novel Transformation and Translation Occupancy\nGrid Mapping (TT-OGM). We adapt and enable accurate and robust pose estimation\ntechniques from 3D SLAM to the world of 2D and mitigate errors to improve map\nquality using Generative Adversarial Networks (GANs). We introduce a novel data\ngeneration method via deep reinforcement learning (DRL) to build datasets large\nenough for training a GAN for SLAM error correction. We demonstrate our SLAM in\nreal-time on data collected at Loughborough University. We also prove its\ngeneralisability on a variety of large complex environments on a collection of\nlarge scale well-known 2D occupancy maps. Our novel approach enables the\ncreation of high quality OGMs in complex scenes, far surpassing the\ncapabilities of current SLAM algorithms in terms of quality, accuracy and\nreliability.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, preprint, submitted to Robotics And Autonomous Systems",
    "pdf_url": "http://arxiv.org/pdf/2504.19654v1",
    "published_date": "2025-04-28 10:13:47 UTC",
    "updated_date": "2025-04-28 10:13:47 UTC"
  },
  {
    "arxiv_id": "2504.19653v1",
    "title": "GAN-SLAM: Real-Time GAN Aided Floor Plan Creation Through SLAM",
    "authors": [
      "Leon Davies",
      "Baihua Li",
      "Mohamad Saada",
      "Simon S√∏lvsten",
      "Qinggang Meng"
    ],
    "abstract": "SLAM is a fundamental component of modern autonomous systems, providing\nrobots and their operators with a deeper understanding of their environment.\nSLAM systems often encounter challenges due to the dynamic nature of robotic\nmotion, leading to inaccuracies in mapping quality, particularly in 2D\nrepresentations such as Occupancy Grid Maps. These errors can significantly\ndegrade map quality, hindering the effectiveness of specific downstream tasks\nsuch as floor plan creation. To address this challenge, we introduce our novel\n'GAN-SLAM', a new SLAM approach that leverages Generative Adversarial Networks\nto clean and complete occupancy grids during the SLAM process, reducing the\nimpact of noise and inaccuracies introduced on the output map. We adapt and\nintegrate accurate pose estimation techniques typically used for 3D SLAM into a\n2D form. This enables the quality improvement 3D LiDAR-odometry has seen in\nrecent years to be effective for 2D representations. Our results demonstrate\nsubstantial improvements in map fidelity and quality, with minimal noise and\nerrors, affirming the effectiveness of GAN-SLAM for real-world mapping\napplications within large-scale complex environments. We validate our approach\non real-world data operating in real-time, and on famous examples of 2D maps.\nThe improved quality of the output map enables new downstream tasks, such as\nfloor plan drafting, further enhancing the capabilities of autonomous systems.\nOur novel approach to SLAM offers a significant step forward in the field,\nimproving the usability for SLAM in mapping-based tasks, and offers insight\ninto the usage of GANs for OGM error correction.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, preprint conference submission",
    "pdf_url": "http://arxiv.org/pdf/2504.19653v1",
    "published_date": "2025-04-28 10:13:38 UTC",
    "updated_date": "2025-04-28 10:13:38 UTC"
  },
  {
    "arxiv_id": "2504.19645v1",
    "title": "A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks",
    "authors": [
      "Shadan Shukr Sabr",
      "Nazira Sabr Mustafa",
      "Talar Sabah Omar",
      "Salah Hwayyiz Rasool",
      "Nawzad Anwer Omer",
      "Darya Sabir Hamad",
      "Hemin Abdulhameed Shams",
      "Omer Mahmood Kareem",
      "Rozhan Noori Abdullah",
      "Khabat Atar Abdullah",
      "Mahabad Azad Mohammad",
      "Haneen Al-Raghefy",
      "Safar M. Asaad",
      "Sara Jamal Mohammed",
      "Twana Saeed Ali",
      "Fazil Shawrow",
      "Halgurd S. Maghdid"
    ],
    "abstract": "- The field of natural language processing (NLP) has dramatically expanded\nwithin the last decade. Many human-being applications are conducted daily via\nNLP tasks, starting from machine translation, speech recognition, text\ngeneration and recommendations, Part-of-Speech tagging (POS), and Named-Entity\nRecognition (NER). However, low-resourced languages, such as the\nCentral-Kurdish language (CKL), mainly remain unexamined due to shortage of\nnecessary resources to support their development. The POS tagging task is the\nbase of other NLP tasks; for example, the POS tag set has been used to\nstandardized languages to provide the relationship between words among the\nsentences, followed by machine translation and text recommendation.\nSpecifically, for the CKL, most of the utilized or provided POS tagsets are\nneither standardized nor comprehensive. To this end, this study presented an\naccurate and comprehensive POS tagset for the CKL to provide better performance\nof the Kurdish NLP tasks. The article also collected most of the POS tags from\ndifferent studies as well as from Kurdish linguistic experts to standardized\npart-of-speech tags. The proposed POS tagset is designed to annotate a large\nCKL corpus and support Kurdish NLP tasks. The initial investigations of this\nstudy via comparison with the Universal Dependencies framework for standard\nlanguages, show that the proposed POS tagset can streamline or correct\nsentences more accurately for Kurdish NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "K.5; K.7; J.7"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.19645v1",
    "published_date": "2025-04-28 10:02:11 UTC",
    "updated_date": "2025-04-28 10:02:11 UTC"
  },
  {
    "arxiv_id": "2504.19636v1",
    "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search",
    "authors": [
      "Fei Liu",
      "Qingfu Zhang",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Kun Mao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19636v1",
    "published_date": "2025-04-28 09:52:41 UTC",
    "updated_date": "2025-04-28 09:52:41 UTC"
  },
  {
    "arxiv_id": "2504.19627v1",
    "title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning",
    "authors": [
      "Run Luo",
      "Renke Shan",
      "Longze Chen",
      "Ziqiang Liu",
      "Lu Wang",
      "Min Yang",
      "Xiaobo Xia"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like\nembodied intelligence due to their strong vision-language reasoning abilities.\nHowever, current LVLMs process entire images at the token level, which is\ninefficient compared to humans who analyze information and generate content at\nthe conceptual level, extracting relevant visual concepts with minimal effort.\nThis inefficiency, stemming from the lack of a visual concept model, limits\nLVLMs' usability in real-world applications. To address this, we propose VCM,\nan end-to-end self-supervised visual concept modeling framework. VCM leverages\nimplicit contrastive learning across multiple sampled instances and\nvision-language fine-tuning to construct a visual concept model without\nrequiring costly concept-level annotations. Our results show that VCM\nsignificantly reduces computational costs (e.g., 85\\% fewer FLOPs for\nLLaVA-1.5-7B) while maintaining strong performance across diverse image\nunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities in\nclassic visual concept perception tasks. Extensive quantitative and qualitative\nexperiments validate the effectiveness and efficiency of VCM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "VCM",
    "pdf_url": "http://arxiv.org/pdf/2504.19627v1",
    "published_date": "2025-04-28 09:39:07 UTC",
    "updated_date": "2025-04-28 09:39:07 UTC"
  },
  {
    "arxiv_id": "2504.19622v1",
    "title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models",
    "authors": [
      "Minsu Kim",
      "Sangryul Kim",
      "James Thorne"
    ],
    "abstract": "This paper investigates the knowledge of language models from the perspective\nof Bayesian epistemology. We explore how language models adjust their\nconfidence and responses when presented with evidence with varying levels of\ninformativeness and reliability. To study these properties, we create a dataset\nwith various types of evidence and analyze language models' responses and\nconfidence using verbalized confidence, token probability, and sampling. We\nobserved that language models do not consistently follow Bayesian epistemology:\nlanguage models follow the Bayesian confirmation assumption well with true\nevidence but fail to adhere to other Bayesian assumptions when encountering\ndifferent evidence types. Also, we demonstrated that language models can\nexhibit high confidence when given strong evidence, but this does not always\nguarantee high accuracy. Our analysis also reveals that language models are\nbiased toward golden evidence and show varying performance depending on the\ndegree of irrelevance, helping explain why they deviate from Bayesian\nassumptions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19622v1",
    "published_date": "2025-04-28 09:28:42 UTC",
    "updated_date": "2025-04-28 09:28:42 UTC"
  },
  {
    "arxiv_id": "2504.19600v1",
    "title": "Image Generation Method Based on Heat Diffusion Models",
    "authors": [
      "Pengfei Zhang",
      "Shouqing Jia"
    ],
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image\ngeneration without adversarial training, but they process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM is a model that incorporates pixel-level\noperations while maintaining the same training process as DDPM. In HDM, the\ndiscrete form of the two-dimensional heat equation is integrated into the\ndiffusion and generation formulas of DDPM, enabling the model to compute\nrelationships between neighboring pixels during image processing. Our\nexperiments demonstrate that HDM can generate higher-quality samples compared\nto models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion\nModels (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19600v1",
    "published_date": "2025-04-28 09:03:33 UTC",
    "updated_date": "2025-04-28 09:03:33 UTC"
  },
  {
    "arxiv_id": "2504.19599v1",
    "title": "GVPO: Group Variance Policy Optimization for Large Language Model Post-Training",
    "authors": [
      "Kaichen Zhang",
      "Yuzhong Hong",
      "Junwei Bao",
      "Hongfei Jiang",
      "Yang Song",
      "Dingqian Hong",
      "Hui Xiong"
    ],
    "abstract": "Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19599v1",
    "published_date": "2025-04-28 09:02:24 UTC",
    "updated_date": "2025-04-28 09:02:24 UTC"
  },
  {
    "arxiv_id": "2504.19598v1",
    "title": "Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection",
    "authors": [
      "Dou Quan",
      "Rufan Zhou",
      "Shuang Wang",
      "Ning Huyan",
      "Dong Zhao",
      "Yunan Li",
      "Licheng Jiao"
    ],
    "abstract": "Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19598v1",
    "published_date": "2025-04-28 09:01:56 UTC",
    "updated_date": "2025-04-28 09:01:56 UTC"
  },
  {
    "arxiv_id": "2504.19595v2",
    "title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution",
    "authors": [
      "Pietro Bongini",
      "Sara Mandelli",
      "Andrea Montibeller",
      "Mirko Casu",
      "Orazio Pontorno",
      "Claudio Vittorio Ragaglia",
      "Luca Zanchetta",
      "Mattia Aquilina",
      "Taiba Majid Wani",
      "Luca Guarnera",
      "Benedetta Tondi",
      "Giulia Boato",
      "Paolo Bestagini",
      "Irene Amerini",
      "Francesco De Natale",
      "Sebastiano Battiato",
      "Mauro Barni"
    ],
    "abstract": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19595v2",
    "published_date": "2025-04-28 08:58:34 UTC",
    "updated_date": "2025-04-29 09:01:26 UTC"
  },
  {
    "arxiv_id": "2504.19594v1",
    "title": "Mapping the Italian Telegram Ecosystem",
    "authors": [
      "Lorenzo Alvisi",
      "Serena Tardelli",
      "Maurizio Tesconi"
    ],
    "abstract": "Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19594v1",
    "published_date": "2025-04-28 08:58:18 UTC",
    "updated_date": "2025-04-28 08:58:18 UTC"
  },
  {
    "arxiv_id": "2504.19592v1",
    "title": "Neural network task specialization via domain constraining",
    "authors": [
      "Roman Malashin",
      "Daniil Ilyukhin"
    ],
    "abstract": "This paper introduces a concept of neural network specialization via\ntask-specific domain constraining, aimed at enhancing network performance on\ndata subspace in which the network operates. The study presents experiments on\ntraining specialists for image classification and object detection tasks. The\nresults demonstrate that specialization can enhance a generalist's accuracy\neven without additional data or changing training regimes: solely by\nconstraining class label space in which the network performs. Theoretical and\nexperimental analyses indicate that effective specialization requires modifying\ntraditional fine-tuning methods and constraining data space to semantically\ncoherent subsets. The specialist extraction phase before tuning the network is\nproposed for maximal performance gains. We also provide analysis of the\nevolution of the feature space during specialization. This study paves way to\nfuture research for developing more advanced dynamically configurable image\nanalysis systems, where computations depend on the specific input.\nAdditionally, the proposed methods can help improve system performance in\nscenarios where certain data domains should be excluded from consideration of\nthe generalist network.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19592v1",
    "published_date": "2025-04-28 08:57:01 UTC",
    "updated_date": "2025-04-28 08:57:01 UTC"
  },
  {
    "arxiv_id": "2504.19590v1",
    "title": "Arabic Metaphor Sentiment Classification Using Semantic Information",
    "authors": [
      "Israa Alsiyat"
    ],
    "abstract": "In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19590v1",
    "published_date": "2025-04-28 08:53:28 UTC",
    "updated_date": "2025-04-28 08:53:28 UTC"
  },
  {
    "arxiv_id": "2504.19565v1",
    "title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
    "authors": [
      "Meng Xiao",
      "Xunxin Cai",
      "Chengrui Wang",
      "Yuanchun Zhou"
    ],
    "abstract": "The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, Large Language Model, Agentic AI, Dataset Distillation,\n  Multi-agent Collaboration",
    "pdf_url": "http://arxiv.org/pdf/2504.19565v1",
    "published_date": "2025-04-28 08:18:24 UTC",
    "updated_date": "2025-04-28 08:18:24 UTC"
  },
  {
    "arxiv_id": "2504.19545v1",
    "title": "Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction",
    "authors": [
      "Zezeng Li",
      "Zhihui Qi",
      "Weimin Wang",
      "Ziliang Wang",
      "Junyi Duan",
      "Na Lei"
    ],
    "abstract": "Quad meshes are essential in geometric modeling and computational mechanics.\nAlthough learning-based methods for triangle mesh demonstrate considerable\nadvancements, quad mesh generation remains less explored due to the challenge\nof ensuring coplanarity, convexity, and quad-only meshes. In this paper, we\npresent Point2Quad, the first learning-based method for quad-only mesh\ngeneration from point clouds. The key idea is learning to identify quad mesh\nwith fused pointwise and facewise features. Specifically, Point2Quad begins\nwith a k-NN-based candidate generation considering the coplanarity and\nsquareness. Then, two encoders are followed to extract geometric and\ntopological features that address the challenge of quad-related constraints,\nespecially by combining in-depth quadrilaterals-specific characteristics.\nSubsequently, the extracted features are fused to train the classifier with a\ndesigned compound loss. The final results are derived after the refinement by a\nquad-specific post-processing. Extensive experiments on both clear and noise\ndata demonstrate the effectiveness and superiority of Point2Quad, compared to\nbaseline methods under comprehensive metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19545v1",
    "published_date": "2025-04-28 07:48:17 UTC",
    "updated_date": "2025-04-28 07:48:17 UTC"
  },
  {
    "arxiv_id": "2504.19499v1",
    "title": "Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks",
    "authors": [
      "Omid Semiari",
      "Hosein Nikopour",
      "Shilpa Talwar"
    ],
    "abstract": "Next-generation wireless cellular networks are expected to provide\nunparalleled Quality-of-Service (QoS) for emerging wireless applications,\nnecessitating strict performance guarantees, e.g., in terms of link-level data\nrates. A critical challenge in meeting these QoS requirements is the prevention\nof cell congestion, which involves balancing the load to ensure sufficient\nradio resources are available for each cell to serve its designated User\nEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approach\nis developed to optimize the performance of Guaranteed Bit Rate (GBR) and Best\nEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoS\nand resource constraints. The proposed solution builds on Graph Reinforcement\nLearning (GRL), a powerful framework at the intersection of Graph Neural\nNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,\nwith states represented as graphs. QoS consideration are integrated into both\nstate representations and reward signal design. The LB agent is then trained\nusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-based\narchitecture. This design ensures the LB policy is invariant to the ordering of\nnodes (UE or cell), flexible in handling various network sizes, and capable of\naccounting for spatial node dependencies in LB decisions. Performance of the\nGRL-based solution is compared with two baseline methods. Results show\nsubstantial performance gains, including a $53\\%$ reduction in QoS violations\nand a fourfold increase in the 5th percentile rate for BE traffic.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.NI",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in the proceedings of the 2025 IEEE International\n  Conference on Communications (ICC), Seventh Workshop on Data Driven\n  Intelligence for Networks and Systems (DDINS)",
    "pdf_url": "http://arxiv.org/pdf/2504.19499v1",
    "published_date": "2025-04-28 05:41:31 UTC",
    "updated_date": "2025-04-28 05:41:31 UTC"
  },
  {
    "arxiv_id": "2504.19496v1",
    "title": "DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction",
    "authors": [
      "Rudy Morel",
      "Jiequn Han",
      "Edouard Oyallon"
    ],
    "abstract": "We address the problem of predicting the next state of a dynamical system\ngoverned by unknown temporal partial differential equations (PDEs) using only a\nshort trajectory. While standard transformers provide a natural black-box\nsolution to this task, the presence of a well-structured evolution operator in\nthe data suggests a more tailored and efficient approach. Specifically, when\nthe PDE is fully known, classical numerical solvers can evolve the state\naccurately with only a few parameters. Building on this observation, we\nintroduce DISCO, a model that uses a large hypernetwork to process a short\ntrajectory and generate the parameters of a much smaller operator network,\nwhich then predicts the next state through time integration. Our framework\ndecouples dynamics estimation (i.e., DISCovering an evolution operator from a\nshort trajectory) from state prediction (i.e., evolving this operator).\nExperiments show that pretraining our model on diverse physics datasets\nachieves state-of-the-art performance while requiring significantly fewer\nepochs. Moreover, it generalizes well and remains competitive when fine-tuned\non downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19496v1",
    "published_date": "2025-04-28 05:36:52 UTC",
    "updated_date": "2025-04-28 05:36:52 UTC"
  },
  {
    "arxiv_id": "2504.19483v1",
    "title": "Improving Reasoning Performance in Large Language Models via Representation Engineering",
    "authors": [
      "Bertram H√∏jer",
      "Oliver Jarvis",
      "Stefan Heinrich"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Has been accepted at \"The Thirteenth International Conference on\n  Learning Representations (ICLR 2025)\" Link to publication:\n  https://openreview.net/forum?id=IssPhpUsKt",
    "pdf_url": "http://arxiv.org/pdf/2504.19483v1",
    "published_date": "2025-04-28 04:58:43 UTC",
    "updated_date": "2025-04-28 04:58:43 UTC"
  },
  {
    "arxiv_id": "2504.19480v1",
    "title": "An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination",
    "authors": [
      "Dixiao Wei",
      "Peng Yi",
      "Jinlong Lei",
      "Yiguang Hong",
      "Yuchuan Du"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19480v1",
    "published_date": "2025-04-28 04:41:15 UTC",
    "updated_date": "2025-04-28 04:41:15 UTC"
  },
  {
    "arxiv_id": "2504.19475v1",
    "title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video",
    "authors": [
      "Sonia Joseph",
      "Praneet Suresh",
      "Lorenz Hufe",
      "Edward Stevinson",
      "Robert Graham",
      "Yash Vadi",
      "Danilo Bzdok",
      "Sebastian Lapuschkin",
      "Lee Sharkey",
      "Blake Aaron Richards"
    ],
    "abstract": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 3 figures, 9 tables. Oral and Tutorial at the CVPR\n  Mechanistic Interpretability for Vision (MIV) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.19475v1",
    "published_date": "2025-04-28 04:31:24 UTC",
    "updated_date": "2025-04-28 04:31:24 UTC"
  },
  {
    "arxiv_id": "2504.19467v1",
    "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text",
    "authors": [
      "Jiageng Wu",
      "Bowen Gu",
      "Ren Zhou",
      "Kevin Xie",
      "Doug Snyder",
      "Yixing Jiang",
      "Valentina Carducci",
      "Richard Wyss",
      "Rishi J Desai",
      "Emily Alsentzer",
      "Leo Anthony Celi",
      "Adam Rodman",
      "Sebastian Schneeweiss",
      "Jonathan H. Chen",
      "Santiago Romero-Brufau",
      "Kueiyu Joshua Lin",
      "Jie Yang"
    ],
    "abstract": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19467v1",
    "published_date": "2025-04-28 04:13:18 UTC",
    "updated_date": "2025-04-28 04:13:18 UTC"
  },
  {
    "arxiv_id": "2504.19460v1",
    "title": "A Real-Time Gesture-Based Control Framework",
    "authors": [
      "Mahya Khazaei",
      "Ali Bahrani",
      "George Tzanetakis"
    ],
    "abstract": "We introduce a real-time, human-in-the-loop gesture control framework that\ncan dynamically adapt audio and music based on human movement by analyzing live\nvideo input. By creating a responsive connection between visual and auditory\nstimuli, this system enables dancers and performers to not only respond to\nmusic but also influence it through their movements. Designed for live\nperformances, interactive installations, and personal use, it offers an\nimmersive experience where users can shape the music in real time.\n  The framework integrates computer vision and machine learning techniques to\ntrack and interpret motion, allowing users to manipulate audio elements such as\ntempo, pitch, effects, and playback sequence. With ongoing training, it\nachieves user-independent functionality, requiring as few as 50 to 80 samples\nto label simple gestures. This framework combines gesture training, cue\nmapping, and audio manipulation to create a dynamic, interactive experience.\nGestures are interpreted as input signals, mapped to sound control commands,\nand used to naturally adjust music elements, showcasing the seamless interplay\nbetween human interaction and machine response.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages, 4 figures, 2025 International Computer Music Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.19460v1",
    "published_date": "2025-04-28 03:57:28 UTC",
    "updated_date": "2025-04-28 03:57:28 UTC"
  },
  {
    "arxiv_id": "2504.19457v1",
    "title": "Towards Long Context Hallucination Detection",
    "authors": [
      "Siyi Liu",
      "Kishaloy Halder",
      "Zheng Qi",
      "Wei Xiao",
      "Nikolaos Pappas",
      "Phu Mon Htut",
      "Neha Anna John",
      "Yassine Benajiba",
      "Dan Roth"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. However, they are prone to contextual hallucination, generating\ninformation that is either unsubstantiated or contradictory to the given\ncontext. Although many studies have investigated contextual hallucinations in\nLLMs, addressing them in long-context inputs remains an open problem. In this\nwork, we take an initial step toward solving this problem by constructing a\ndataset specifically designed for long-context hallucination detection.\nFurthermore, we propose a novel architecture that enables pre-trained encoder\nmodels, such as BERT, to process long contexts and effectively detect\ncontextual hallucinations through a decomposition and aggregation mechanism.\nOur experimental results show that the proposed architecture significantly\noutperforms previous models of similar size as well as LLM-based models across\nvarious metrics, while providing substantially faster inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19457v1",
    "published_date": "2025-04-28 03:47:05 UTC",
    "updated_date": "2025-04-28 03:47:05 UTC"
  },
  {
    "arxiv_id": "2504.19443v1",
    "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions",
    "authors": [
      "Yejin Jeong",
      "Donghun Lee"
    ],
    "abstract": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.19443v1",
    "published_date": "2025-04-28 03:10:24 UTC",
    "updated_date": "2025-04-28 03:10:24 UTC"
  },
  {
    "arxiv_id": "2504.19432v1",
    "title": "EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation",
    "authors": [
      "Zhe Dong",
      "Yuzhe Sun",
      "Tianzhu Liu",
      "Wangmeng Zuo",
      "Yanfeng Gu"
    ],
    "abstract": "Satellite imagery and maps, as two fundamental data modalities in remote\nsensing, offer direct observations of the Earth's surface and\nhuman-interpretable geographic abstractions, respectively. The task of\nbidirectional translation between satellite images and maps (BSMT) holds\nsignificant potential for applications in urban planning and disaster response.\nHowever, this task presents two major challenges: first, the absence of precise\npixel-wise alignment between the two modalities substantially complicates the\ntranslation process; second, it requires achieving both high-level abstraction\nof geographic features and high-quality visual synthesis, which further\nelevates the technical complexity. To address these limitations, we introduce\nEarthMapper, a novel autoregressive framework for controllable bidirectional\nsatellite-map translation. EarthMapper employs geographic coordinate embeddings\nto anchor generation, ensuring region-specific adaptability, and leverages\nmulti-scale feature alignment within a geo-conditioned joint scale\nautoregression (GJSA) process to unify bidirectional translation in a single\ntraining cycle. A semantic infusion (SI) mechanism is introduced to enhance\nfeature-level consistency, while a key point adaptive guidance (KPAG) mechanism\nis proposed to dynamically balance diversity and precision during inference. We\nfurther contribute CNSatMap, a large-scale dataset comprising 302,132 precisely\naligned satellite-map pairs across 38 Chinese cities, enabling robust\nbenchmarking. Extensive experiments on CNSatMap and the New York dataset\ndemonstrate EarthMapper's superior performance, achieving significant\nimprovements in visual realism, semantic consistency, and structural fidelity\nover state-of-the-art methods. Additionally, EarthMapper excels in zero-shot\ntasks like in-painting, out-painting and coordinate-conditional generation,\nunderscoring its versatility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19432v1",
    "published_date": "2025-04-28 02:41:12 UTC",
    "updated_date": "2025-04-28 02:41:12 UTC"
  },
  {
    "arxiv_id": "2504.19426v1",
    "title": "Sharp higher order convergence rates for the Adam optimizer",
    "authors": [
      "Steffen Dereich",
      "Arnulf Jentzen",
      "Adrian Riekert"
    ],
    "abstract": "Gradient descent based optimization methods are the methods of choice to\ntrain deep neural networks in machine learning. Beyond the standard gradient\ndescent method, also suitable modified variants of standard gradient descent\ninvolving acceleration techniques such as the momentum method and/or adaptivity\ntechniques such as the RMSprop method are frequently considered optimization\nmethods. These days the most popular of such sophisticated optimization schemes\nis presumably the Adam optimizer that has been proposed in 2014 by Kingma and\nBa. A highly relevant topic of research is to investigate the speed of\nconvergence of such optimization methods. In particular, in 1964 Polyak showed\nthat the standard gradient descent method converges in a neighborhood of a\nstrict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves\nthe (optimal) strictly faster convergence rate (\\sqrt{x} - 1)(\\sqrt{x} +\n1)^{-1} where x \\in (1,\\infty) is the condition number (the ratio of the\nlargest and the smallest eigenvalue) of the Hessian of the objective function\nat the local minimizer. It is the key contribution of this work to reveal that\nAdam also converges with the strictly faster convergence rate (\\sqrt{x} -\n1)(\\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x\n- 1)(x + 1)^{-1}.",
    "categories": [
      "math.OC",
      "cs.AI",
      "68T05, 65K05, 90C25",
      "I.2.0"
    ],
    "primary_category": "math.OC",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.19426v1",
    "published_date": "2025-04-28 02:17:50 UTC",
    "updated_date": "2025-04-28 02:17:50 UTC"
  },
  {
    "arxiv_id": "2504.19413v1",
    "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
    "authors": [
      "Prateek Chhikara",
      "Dev Khant",
      "Saket Aryan",
      "Taranjeet Singh",
      "Deshraj Yadav"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable prowess in\ngenerating contextually coherent responses, yet their fixed context windows\npose fundamental challenges for maintaining consistency over prolonged\nmulti-session dialogues. We introduce Mem0, a scalable memory-centric\narchitecture that addresses this issue by dynamically extracting,\nconsolidating, and retrieving salient information from ongoing conversations.\nBuilding on this foundation, we further propose an enhanced variant that\nleverages graph-based memory representations to capture complex relational\nstructures among conversational elements. Through comprehensive evaluations on\nLOCOMO benchmark, we systematically compare our approaches against six baseline\ncategories: (i) established memory-augmented systems, (ii) retrieval-augmented\ngeneration (RAG) with varying chunk sizes and k-values, (iii) a full-context\napproach that processes the entire conversation history, (iv) an open-source\nmemory solution, (v) a proprietary model system, and (vi) a dedicated memory\nmanagement platform. Empirical results show that our methods consistently\noutperform all existing memory systems across four question categories:\nsingle-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26%\nrelative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with\ngraph memory achieves around 2% higher overall score than the base\nconfiguration. Beyond accuracy gains, we also markedly reduce computational\noverhead compared to full-context method. In particular, Mem0 attains a 91%\nlower p95 latency and saves more than 90% token cost, offering a compelling\nbalance between advanced reasoning capabilities and practical deployment\nconstraints. Our findings highlight critical role of structured, persistent\nmemory mechanisms for long-term conversational coherence, paving the way for\nmore reliable and efficient LLM-driven AI agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19413v1",
    "published_date": "2025-04-28 01:46:35 UTC",
    "updated_date": "2025-04-28 01:46:35 UTC"
  },
  {
    "arxiv_id": "2504.19409v1",
    "title": "GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field",
    "authors": [
      "Zuxing Lu",
      "Xin Yuan",
      "Shaowen Yang",
      "Jingyu Liu",
      "Jiawei Wang",
      "Changyin Sun"
    ],
    "abstract": "Semantic-aware 3D scene reconstruction is essential for autonomous robots to\nperform complex interactions. Semantic SLAM, an online approach, integrates\npose tracking, geometric reconstruction, and semantic mapping into a unified\nframework, shows significant potential. However, existing systems, which rely\non 2D ground truth priors for supervision, are often limited by the sparsity\nand noise of these signals in real-world environments. To address this\nchallenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D\nGaussian Splatting that leverages feature fields to achieve joint rendering of\nappearance, geometry, and N-dimensional semantic features. By independently\noptimizing feature gradients, our method supports semantic reconstruction using\nvarious forms of 2D priors, particularly sparse and noisy signals. Experimental\nresults demonstrate that our approach outperforms previous methods in both\ntracking accuracy and photorealistic rendering quality. When utilizing 2D\nground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation\nperformance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with\nonly marginal performance degradation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.19409v1",
    "published_date": "2025-04-28 01:21:35 UTC",
    "updated_date": "2025-04-28 01:21:35 UTC"
  }
]