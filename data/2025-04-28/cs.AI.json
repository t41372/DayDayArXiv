{
  "date": "2025-04-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-28 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 110 篇论文，主要聚焦 AI 优化、LLM 安全与应用、医疗 AI 以及机器人领域，亮点包括 Shafi Goldwasser 等知名学者的机器学习攻击研究，以及多个 LLM 增强框架如 GraphRAG 和多代理系统，这些创新可能推动 AI 安全与实际应用话题。\n\n以下是今日值得关注的论文，我优先选取了重要、创新性和话题度高的内容（如 LLM 相关、AI 安全和医疗应用），并将相关论文归类讨论。其他较常规或次要论文（如某些优化算法或小规模实验）则简略掠过，以控制篇幅。\n\n### AI 安全与 LLM 应用\n这些论文探讨了 LLM 的安全机制、推理优化和代理系统，体现了 LLM 在实际场景中的潜力。\n\n- **Prompting LLMs for Code Editing: Struggles and Remedies（针对 LLM 的代码编辑提示：挑战与解决方案）**  \n  作者包括 Vincent Hellendoorn 和 Satish Chandra。这篇论文的主要贡献是分析开发者在使用 LLM 进行代码编辑时的困难，并提出 AutoPrompter 工具，通过自动推断上下文信息改善提示，实验显示编辑正确率提升 27%，为 LLM 在软件工程中的应用提供实用改进。\n\n- **A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning（机器学习中缓解 vs. 检测的加密视角）**  \n  作者：Greg Gluch 和 Shafi Goldwasser（知名密码学专家）。论文定义了防御机制（DbD 和 DbM），证明在生成任务中缓解优于检测，利用同态加密和零知识证明，展示了首个缓解策略，强调 AI 安全的关键洞见。\n\n- **Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework（大型语言模型能否学习形式逻辑？数据驱动的训练与评估框架）**  \n  论文提出随机证明合成和模板转换技术，训练 LLM 处理布尔逻辑证明，实验显示短证明准确率高，但随复杂度下降，揭示 LLM 推理能力的局限性。\n\n- **Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains（跨图像编织上下文：通过焦点中心视觉链提升视觉-语言模型）**  \n  论文引入焦点中心视觉链和数据合成方法，构建 VISC-150K 数据集，实验在多图像基准上平均提升 3.16%，增强 LLM 在复杂视觉场景中的感知和推理。\n\n- **Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning（通过强化学习实现 LLM 的代理推理与工具整合）**  \n  提出 ARTIST 框架，将强化学习与工具整合，实验显示在数学和函数调用任务上比基线提升 22%，为 LLM 代理系统提供高效决策方法。\n\n- **Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models（模块化机器学习：通往新一代大型语言模型的必经之路）**  \n  作者包括 Hongfei Jiang 和 Hui Xiong。论文定义模块化框架，强调模块表示和推理，提升 LLM 的逆事实推理和公平性，潜在应用包括更可靠的 AI 系统。\n\n### 医疗 AI 与生物应用\n这些论文展示了 AI 在医疗中的创新，特别是在诊断和资源利用上，关注实际影响。\n\n- **Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage（迈向 AI 驱动的警务：从警用随身摄像机中发现跨学科知识）**  \n  论文构建多模态框架，使用 LSTM 和 NLP 分析警用视频，检测行为模式如升级和降级，F1 分数达 0.85，促进 AI 在公共安全中的应用。\n\n- **Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning（使用视觉提示微调的多视图乳腺癌筛查乳腺 X 光检测）**  \n  提出 MVPT-NET 框架，结合多视图图像和提示微调，AUROC 达 0.852，提升乳腺癌检测准确性。\n\n- **MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis（MDD-LLM：面向抑郁症诊断的精确大型语言模型）**  \n  构建 LLM 框架处理抑郁症数据，准确率达 0.8378，超过基线模型，推动 AI 在心理健康诊断中的应用。\n\n- **PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping（PhenoAssistant：用于自动化植物表型分析的对话式多代理 AI 系统）**  \n  开发多代理系统自动化植物表型提取，实验显示显著提升分析效率，适用于农业 AI。\n\n### 机器人与优化技术\n这些论文聚焦 SLAM 和优化，强调实际部署。\n\n- **Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training（硬件友好型设备训练的扰动高效零阶优化）**  \n  提出 PeZO 框架，减少随机数生成需求，实验显示降低功耗 86%，适用于边缘设备训练。\n\n- **Deep Physics Prior for First Order Inverse Optimization（用于一阶逆优化的深度物理先验）**  \n  引入 DPP 方法，利用神经算子进行逆优化，适用于半导体和流体力学领域。\n\n其他论文如某些数学优化或小规模数据集实验（如第9、12、14等），虽有贡献但话题度较低，故仅简要提及：它们探讨了交通预测或表示学习，但未带来重大突破。\n\n总之，今天的论文突显 AI 领域的快速迭代，Shafi Goldwasser 的工作和 LLM 代理框架尤其值得关注，期待这些创新加速 AI 安全与应用的落地。明天见！",
  "papers": [
    {
      "arxiv_id": "2504.20314v1",
      "title": "Perturbation-efficient Zeroth-order Optimization for Hardware-friendly On-device Training",
      "title_zh": "翻译失败",
      "authors": [
        "Qitao Tan",
        "Sung-En Chang",
        "Rui Xia",
        "Huidong Ji",
        "Chence Yang",
        "Ci Zhang",
        "Jun Liu",
        "Zheng Zhan",
        "Zhou Zou",
        "Yanzhi Wang",
        "Jin Lu",
        "Geng Yuan"
      ],
      "abstract": "Zeroth-order (ZO) optimization is an emerging deep neural network (DNN)\ntraining paradigm that offers computational simplicity and memory savings.\nHowever, this seemingly promising approach faces a significant and long-ignored\nchallenge. ZO requires generating a substantial number of Gaussian random\nnumbers, which poses significant difficulties and even makes it infeasible for\nhardware platforms, such as FPGAs and ASICs. In this paper, we identify this\ncritical issue, which arises from the mismatch between algorithm and hardware\ndesigners. To address this issue, we proposed PeZO, a perturbation-efficient ZO\nframework. Specifically, we design random number reuse strategies to\nsignificantly reduce the demand for random number generation and introduce a\nhardware-friendly adaptive scaling method to replace the costly Gaussian\ndistribution with a uniform distribution. Our experiments show that PeZO\nreduces the required LUTs and FFs for random number generation by 48.6\\% and\n12.7\\%, and saves at maximum 86\\% power consumption, all without compromising\ntraining performance, making ZO optimization feasible for on-device training.\nTo the best of our knowledge, we are the first to explore the potential of\non-device ZO optimization, providing valuable insights for future research.",
      "tldr_zh": "这篇论文针对 Zeroth-order (ZO) 优化在深度神经网络 (DNN) 训练中的硬件挑战，提出 PeZO 框架，以解决生成大量 Gaussian 随机数导致的资源消耗问题。PeZO 通过设计随机数重用策略和硬件友好的自适应缩放方法，将 Gaussian 分布替换为均匀分布，从而显著减少随机数生成需求。实验结果显示，该框架减少了 48.6% 的 LUTs 和 12.7% 的 FFs 使用量，并节省最多 86% 的功率消耗，同时不影响训练性能。作为首次探索 on-device ZO 优化的工作，这为未来硬件友好型训练提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20314v1",
      "published_date": "2025-04-28 23:58:07 UTC",
      "updated_date": "2025-04-28 23:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:16:31.569337"
    },
    {
      "arxiv_id": "2504.20310v1",
      "title": "A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Greg Gluch",
        "Shafi Goldwasser"
      ],
      "abstract": "In this paper, we initiate a cryptographically inspired theoretical study of\ndetection versus mitigation of adversarial inputs produced by attackers of\nMachine Learning algorithms during inference time.\n  We formally define defense by detection (DbD) and defense by mitigation\n(DbM). Our definitions come in the form of a 3-round protocol between two\nresource-bounded parties: a trainer/defender and an attacker. The attacker aims\nto produce inference-time inputs that fool the training algorithm. We define\ncorrectness, completeness, and soundness properties to capture successful\ndefense at inference time while not degrading (too much) the performance of the\nalgorithm on inputs from the training distribution.\n  We first show that achieving DbD and achieving DbM are equivalent for ML\nclassification tasks. Surprisingly, this is not the case for ML generative\nlearning tasks, where there are many possible correct outputs that can be\ngenerated for each input. We show a separation between DbD and DbM by\nexhibiting a generative learning task for which is possible to defend by\nmitigation but is provably impossible to defend by detection under the\nassumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE),\npublicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of\nKnowledge (zk-SNARK) and Strongly Unforgeable Signatures exist. The mitigation\nphase uses significantly fewer samples than the initial training algorithm.",
      "tldr_zh": "这篇论文从加密学的角度，探讨机器学习中对抗输入的检测(DbD)和缓解(DbM)，通过一个三轮协议形式化定义了这些防御机制，包括正确性、完整性和可靠性属性，以确保推理时成功防御而不显著影响算法性能。作者证明，在分类任务中DbD和DbM是等价的，但对于生成学习任务，二者存在分离：在某些加密假设下（如Identity-Based Fully Homomorphic Encryption (IB-FHE)、zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK)和强不可伪造签名存在），某些任务可以实现DbM但无法实现DbD，且DbM阶段只需较少的样本。整体研究为机器学习的安全性提供了新的理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20310v1",
      "published_date": "2025-04-28 23:46:45 UTC",
      "updated_date": "2025-04-28 23:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:16:42.690977"
    },
    {
      "arxiv_id": "2504.20304v2",
      "title": "UD-English-CHILDES: A Collected Resource of Gold and Silver Universal Dependencies Trees for Child Language Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Xiulin Yang",
        "Zhuoxuan Ju",
        "Lanni Bu",
        "Zoey Liu",
        "Nathan Schneider"
      ],
      "abstract": "CHILDES is a widely used resource of transcribed child and child-directed\nspeech. This paper introduces UD-English-CHILDES, the first officially released\nUniversal Dependencies (UD) treebank derived from previously\ndependency-annotated CHILDES data with consistent and unified annotation\nguidelines. Our corpus harmonizes annotations from 11 children and their\ncaregivers, totaling over 48k sentences. We validate existing gold-standard\nannotations under the UD v2 framework and provide an additional 1M\nsilver-standard sentences, offering a consistent resource for computational and\nlinguistic research.",
      "tldr_zh": "这篇论文介绍了 UD-English-CHILDES，这是一个从 CHILDES 数据派生的官方 Universal Dependencies (UD) 树库，使用一致的注释指南统一了 11 个儿童及其护理者的超过 48k 句子注释。研究团队在 UD v2 框架下验证了这些 gold-standard 注释的质量，并提供了额外的 1M silver-standard 句子，作为统一的资源支持计算和语言学研究。该树库有助于深入分析儿童语言互动，提供更可靠的数据基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20304v2",
      "published_date": "2025-04-28 23:20:36 UTC",
      "updated_date": "2025-05-04 13:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:16:55.739382"
    },
    {
      "arxiv_id": "2504.20295v1",
      "title": "The Dark Side of Digital Twins: Adversarial Attacks on AI-Driven Water Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadhossein Homaei",
        "Victor Gonzalez Morales",
        "Oscar Mogollon-Gutierrez",
        "Andres Caro"
      ],
      "abstract": "Digital twins (DTs) are improving water distribution systems by using\nreal-time data, analytics, and prediction models to optimize operations. This\npaper presents a DT platform designed for a Spanish water supply network,\nutilizing Long Short-Term Memory (LSTM) networks to predict water consumption.\nHowever, machine learning models are vulnerable to adversarial attacks, such as\nthe Fast Gradient Sign Method (FGSM) and Projected Gradient Descent (PGD).\nThese attacks manipulate critical model parameters, injecting subtle\ndistortions that degrade forecasting accuracy. To further exploit these\nvulnerabilities, we introduce a Learning Automata (LA) and Random LA-based\napproach that dynamically adjusts perturbations, making adversarial attacks\nmore difficult to detect. Experimental results show that this approach\nsignificantly impacts prediction reliability, causing the Mean Absolute\nPercentage Error (MAPE) to rise from 26% to over 35%. Moreover, adaptive attack\nstrategies amplify this effect, highlighting cybersecurity risks in AI-driven\nDTs. These findings emphasize the urgent need for robust defenses, including\nadversarial training, anomaly detection, and secure data pipelines.",
      "tldr_zh": "本研究探讨了数字孪生（DTs）在AI驱动水预测中的安全风险，特别针对一个基于Long Short-Term Memory (LSTM)网络的西班牙水供应网络平台。论文引入Fast Gradient Sign Method (FGSM)和Projected Gradient Descent (PGD)攻击，以及一种新颖的Learning Automata (LA)和Random LA-based方法，来动态调整扰动以降低预测准确性。实验结果显示，这种攻击导致Mean Absolute Percentage Error (MAPE)从26%上升到超过35%，显著放大预测可靠性问题。总体而言，该工作突显了AI驱动DTs的网络安全隐患，并呼吁采用对抗训练、异常检测和安全数据管道等防御措施。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "7 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20295v1",
      "published_date": "2025-04-28 22:34:11 UTC",
      "updated_date": "2025-04-28 22:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:17:06.636068"
    },
    {
      "arxiv_id": "2504.20294v1",
      "title": "mrCAD: Multimodal Refinement of Computer-aided Designs",
      "title_zh": "翻译失败",
      "authors": [
        "William P. McCarthy",
        "Saujas Vaduguru",
        "Karl D. D. Willis",
        "Justin Matejka",
        "Judith E. Fan",
        "Daniel Fried",
        "Yewen Pu"
      ],
      "abstract": "A key feature of human collaboration is the ability to iteratively refine the\nconcepts we have communicated. In contrast, while generative AI excels at the\n\\textit{generation} of content, it often struggles to make specific\nlanguage-guided \\textit{modifications} of its prior outputs. To bridge the gap\nbetween how humans and machines perform edits, we present mrCAD, a dataset of\nmultimodal instructions in a communication game. In each game, players created\ncomputer aided designs (CADs) and refined them over several rounds to match\nspecific target designs. Only one player, the Designer, could see the target,\nand they must instruct the other player, the Maker, using text, drawing, or a\ncombination of modalities. mrCAD consists of 6,082 communication games, 15,163\ninstruction-execution rounds, played between 1,092 pairs of human players. We\nanalyze the dataset and find that generation and refinement instructions differ\nin their composition of drawing and text. Using the mrCAD task as a benchmark,\nwe find that state-of-the-art VLMs are better at following generation\ninstructions than refinement instructions. These results lay a foundation for\nanalyzing and modeling a multimodal language of refinement that is not\nrepresented in previous datasets.",
      "tldr_zh": "这篇论文介绍了mrCAD数据集，一个用于多模态指令精炼计算机辅助设计(CAD)的通信游戏基准。数据集通过人类玩家互动生成，包括6,082个游戏和15,163个指令执行轮次，其中Designer使用文本、绘图或两者结合指导Maker迭代修改CAD设计。分析发现，生成指令和精炼指令在文本与绘图组成上存在差异，且state-of-the-art VLMs在遵循生成指令上表现优于精炼指令。该数据集为分析和建模多模态精炼语言提供了新基础，桥接了人类协作与AI编辑的差距。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "the first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2504.20294v1",
      "published_date": "2025-04-28 22:32:57 UTC",
      "updated_date": "2025-04-28 22:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:17:18.793065"
    },
    {
      "arxiv_id": "2504.20278v1",
      "title": "Deep Physics Prior for First Order Inverse Optimization",
      "title_zh": "深度物理先验用于第一阶逆优化",
      "authors": [
        "Haoyu Yang",
        "Kamyar Azizzadenesheli",
        "Haoxing Ren"
      ],
      "abstract": "Inverse design optimization aims to infer system parameters from observed\nsolutions, posing critical challenges across domains such as semiconductor\nmanufacturing, structural engineering, materials science, and fluid dynamics.\nThe lack of explicit mathematical representations in many systems complicates\nthis process and makes the first order optimization impossible. Mainstream\napproaches, including generative AI and Bayesian optimization, address these\nchallenges but have limitations. Generative AI is computationally expensive,\nwhile Bayesian optimization, relying on surrogate models, suffers from\nscalability, sensitivity to priors, and noise issues, often leading to\nsuboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel\nmethod enabling first-order gradient-based inverse optimization with surrogate\nmachine learning models. By leveraging pretrained auxiliary Neural Operators,\nDPP enforces prior distribution constraints to ensure robust and meaningful\nsolutions. This approach is particularly effective when prior data and\nobservation distributions are unknown.",
      "tldr_zh": "本研究针对逆设计优化（inverse design optimization）的挑战，探讨了从观察到的解决方案推断系统参数的难题，该问题在半导体制造、结构工程、材料科学和流体动力学等领域普遍存在，且由于缺乏显式数学表示，一阶优化（first order optimization）难以实现。现有方法如生成式 AI 计算开销巨大，而 Bayesian optimization 则受限于可伸缩性、对先验的敏感性和噪声问题，常导致次优解决方案。为解决这些问题，本文提出 Deep Physics Prior (DPP)，一种创新方法，利用预训练的辅助 Neural Operators 强制先验分布约束，从而实现基于一阶梯度的逆优化，确保解决方案的鲁棒性和可靠性。该方法特别适用于先验数据和观察分布未知的场景，提供了一种高效、可扩展的优化框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figure. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.20278v1",
      "published_date": "2025-04-28 21:48:19 UTC",
      "updated_date": "2025-04-28 21:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:17:30.065784"
    },
    {
      "arxiv_id": "2504.20275v1",
      "title": "Smart Water Security with AI and Blockchain-Enhanced Digital Twins",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadhossein Homaei",
        "Victor Gonzalez Morales",
        "Oscar Mogollon Gutierrez",
        "Ruben Molano Gomez",
        "Andres Caro"
      ],
      "abstract": "Water distribution systems in rural areas face serious challenges such as a\nlack of real-time monitoring, vulnerability to cyberattacks, and unreliable\ndata handling. This paper presents an integrated framework that combines\nLoRaWAN-based data acquisition, a machine learning-driven Intrusion Detection\nSystem (IDS), and a blockchain-enabled Digital Twin (BC-DT) platform for secure\nand transparent water management. The IDS filters anomalous or spoofed data\nusing a Long Short-Term Memory (LSTM) Autoencoder and Isolation Forest before\nvalidated data is logged via smart contracts on a private Ethereum blockchain\nusing Proof of Authority (PoA) consensus. The verified data feeds into a\nreal-time DT model supporting leak detection, consumption forecasting, and\npredictive maintenance. Experimental results demonstrate that the system\nachieves over 80 transactions per second (TPS) with under 2 seconds of latency\nwhile remaining cost-effective and scalable for up to 1,000 smart meters. This\nwork demonstrates a practical and secure architecture for decentralized water\ninfrastructure in under-connected rural environments.",
      "tldr_zh": "这篇论文提出了一种集成框架，用于解决农村水分配系统的实时监控缺失、网络攻击风险和数据处理不可靠问题，通过结合LoRaWAN-based数据采集、机器学习驱动的入侵检测系统(IDS)和区块链启用数字孪生(BC-DT)平台，实现安全的透明水管理。IDS利用Long Short-Term Memory (LSTM) Autoencoder和Isolation Forest过滤异常数据，并通过智能合约在私有Ethereum区块链上使用Proof of Authority (PoA)共识机制记录验证数据，这些数据随后feeding到实时数字孪生模型，支持漏水检测、消费预测和预测性维护。实验结果显示，该系统实现超过80笔交易每秒(TPS)、延迟低于2秒，且成本有效、可扩展至1,000个智能仪表，为农村去中心化水基础设施提供了实用、安全的架构。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8 Pages, 9 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20275v1",
      "published_date": "2025-04-28 21:41:23 UTC",
      "updated_date": "2025-04-28 21:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:17:42.839980"
    },
    {
      "arxiv_id": "2504.20251v1",
      "title": "A Platform for Generating Educational Activities to Teach English as a Second Language",
      "title_zh": "翻译失败",
      "authors": [
        "Aiala Rosá",
        "Santiago Góngora",
        "Juan Pablo Filevich",
        "Ignacio Sastre",
        "Laura Musto",
        "Brian Carpenter",
        "Luis Chiruzzo"
      ],
      "abstract": "We present a platform for the generation of educational activities oriented\nto teaching English as a foreign language. The different activities -- games\nand language practice exercises -- are strongly based on Natural Language\nProcessing techniques. The platform offers the possibility of playing\nout-of-the-box games, generated from resources created semi-automatically and\nthen manually curated. It can also generate games or exercises of greater\ncomplexity from texts entered by teachers, providing a stage of review and\nedition of the generated content before use. As a way of expanding the variety\nof activities in the platform, we are currently experimenting with image and\ntext generation. In order to integrate them and improve the performance of\nother neural tools already integrated, we are working on migrating the platform\nto a more powerful server. In this paper we describe the development of our\nplatform and its deployment for end users, discussing the challenges faced and\nhow we overcame them, and also detail our future work plans.",
      "tldr_zh": "我们提出一个平台，用于基于 Natural Language Processing (NLP) 技术生成英语作为第二语言的教学活动，包括游戏和语言练习。该平台支持从半自动创建并手动校对的资源生成现成游戏，还能从教师输入的文本创建更复杂的活动，并提供内容审查和编辑阶段。为扩展活动多样性，我们正在实验图像和文本生成，并计划迁移到更强大的服务器以提升整体性能和工具整合。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Unpublished report written in 2023",
      "pdf_url": "http://arxiv.org/pdf/2504.20251v1",
      "published_date": "2025-04-28 20:43:40 UTC",
      "updated_date": "2025-04-28 20:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:17:54.367949"
    },
    {
      "arxiv_id": "2505.06246v1",
      "title": "United States Road Accident Prediction using Random Forest Predictor",
      "title_zh": "翻译失败",
      "authors": [
        "Dominic Parosh Yamarthi",
        "Haripriya Raman",
        "Shamsad Parvin"
      ],
      "abstract": "Road accidents significantly threaten public safety and require in-depth\nanalysis for effective prevention and mitigation strategies. This paper focuses\non predicting accidents through the examination of a comprehensive traffic\ndataset covering 49 states in the United States. The dataset integrates\ninformation from diverse sources, including transportation departments, law\nenforcement, and traffic sensors. This paper specifically emphasizes predicting\nthe number of accidents, utilizing advanced machine learning models such as\nregression analysis and time series analysis. The inclusion of various factors,\nranging from environmental conditions to human behavior and infrastructure,\nensures a holistic understanding of the dynamics influencing road safety.\nTemporal and spatial analysis further allows for the identification of trends,\nseasonal variations, and high-risk areas. The implications of this research\nextend to proactive decision-making for policymakers and transportation\nauthorities. By providing accurate predictions and quantifiable insights into\nexpected accident rates under different conditions, the paper aims to empower\nauthorities to allocate resources efficiently and implement targeted\ninterventions. The goal is to contribute to the development of informed\npolicies and interventions that enhance road safety, creating a safer\nenvironment for all road users. Keywords: Machine Learning, Random Forest,\nAccident Prediction, AutoML, LSTM.",
      "tldr_zh": "本研究利用美国49个州的交通数据集，预测道路事故数量，整合了交通部门、执法机构和传感器等来源的数据。研究采用Random Forest等机器学习模型，包括回归分析和时间序列分析（如LSTM），并考虑环境条件、人为行为和基础设施等因素进行全面分析。通过时间和空间分析，识别了事故趋势、季节变化和高风险区域。该方法提高了事故预测准确性，为决策者提供量化洞见，支持资源优化和针对性干预，从而提升道路安全政策。关键词：Machine Learning, Random Forest, Accident Prediction, AutoML, LSTM。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "5 Pages, 8 Figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06246v1",
      "published_date": "2025-04-28 20:31:40 UTC",
      "updated_date": "2025-04-28 20:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:18:05.747817"
    },
    {
      "arxiv_id": "2504.20213v1",
      "title": "Can Large Language Models Learn Formal Logic? A Data-Driven Training and Evaluation Framework",
      "title_zh": "大型语言模型能学习形式逻辑吗？一个数据驱动的训练与评估框架",
      "authors": [
        "Yuan Xia",
        "Akanksha Atrey",
        "Fadoua Khmaissia",
        "Kedar S. Namjoshi"
      ],
      "abstract": "This paper investigates the logical reasoning capabilities of large language\nmodels (LLMs). For a precisely defined yet tractable formulation, we choose the\nconceptually simple but technically complex task of constructing proofs in\nBoolean logic. A trained LLM receives as input a set of assumptions and a goal,\nand produces as output a proof that formally derives the goal from the\nassumptions. Incorrect proofs are caught by an automated proof checker. A\ncritical obstacle for training is the scarcity of real-world proofs. We propose\nan efficient, randomized procedure for synthesizing valid proofs and introduce\nTemplate Transformation, a data augmentation technique that enhances the\nmodel's ability to handle complex logical expressions. The central evaluation\nquestion is whether an LLM has indeed learned to reason. We propose tests to\nmeasure the reasoning ability of a black-box LLM. By these measures,\nexperiments demonstrate strong reasoning capabilities for assertions with short\nproofs, which decline with proof complexity. Notably, template transformation\nimproves accuracy even for smaller models, suggesting its effectiveness across\nmodel scales.",
      "tldr_zh": "本论文探讨大型语言模型 (LLMs) 是否能学习形式逻辑，特别通过布尔逻辑证明任务来评估其推理能力。作者提出一个数据驱动框架，包括高效的随机化证明合成过程和 Template Transformation 数据增强技术，以解决训练数据稀缺问题并提升模型处理复杂逻辑表达式的能力。实验结果表明，LLMs 在短证明任务上表现出强推理能力，但随着证明复杂性增加，性能下降；此外，Template Transformation 技术能显著改善小型模型的准确性，显示其在不同模型规模上的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20213v1",
      "published_date": "2025-04-28 19:25:29 UTC",
      "updated_date": "2025-04-28 19:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:18:19.471178"
    },
    {
      "arxiv_id": "2504.20199v1",
      "title": "Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains",
      "title_zh": "翻译失败",
      "authors": [
        "Juntian Zhang",
        "Chuanqi cheng",
        "Yuhan Liu",
        "Wei Liu",
        "Jian Luan",
        "Rui Yan"
      ],
      "abstract": "Vision-language models (VLMs) achieve remarkable success in single-image\ntasks. However, real-world scenarios often involve intricate multi-image\ninputs, leading to a notable performance decline as models struggle to\ndisentangle critical information scattered across complex visual features. In\nthis work, we propose Focus-Centric Visual Chain, a novel paradigm that\nenhances VLMs'perception, comprehension, and reasoning abilities in multi-image\nscenarios. To facilitate this paradigm, we propose Focus-Centric Data\nSynthesis, a scalable bottom-up approach for synthesizing high-quality data\nwith elaborate reasoning paths. Through this approach, We construct VISC-150K,\na large-scale dataset with reasoning data in the form of Focus-Centric Visual\nChain, specifically designed for multi-image tasks. Experimental results on\nseven multi-image benchmarks demonstrate that our method achieves average\nperformance gains of 3.16% and 2.24% across two distinct model architectures,\nwithout compromising the general vision-language capabilities. our study\nrepresents a significant step toward more robust and capable vision-language\nsystems that can handle complex visual scenarios.",
      "tldr_zh": "该研究针对视觉语言模型(VLMs)在多图像任务中的性能下降问题，提出Focus-Centric Visual Chain这一新范式，以提升模型在复杂视觉场景中的感知、理解和推理能力。研究引入Focus-Centric Data Synthesis方法，通过可扩展的从下至上合成方式，创建了大规模数据集VISC-150K，该数据集包含详细的推理路径，专门针对多图像任务。实验结果显示，该方法在七个多图像基准测试中，使两个不同模型架构的平均性能分别提升3.16%和2.24%，同时保持了模型的一般视觉语言能力，从而推动了更鲁棒的视觉语言系统的开发。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20199v1",
      "published_date": "2025-04-28 19:02:18 UTC",
      "updated_date": "2025-04-28 19:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:18:31.679081"
    },
    {
      "arxiv_id": "2504.20197v1",
      "title": "Representation Learning on a Random Lattice",
      "title_zh": "翻译失败",
      "authors": [
        "Aryeh Brill"
      ],
      "abstract": "Decomposing a deep neural network's learned representations into\ninterpretable features could greatly enhance its safety and reliability. To\nbetter understand features, we adopt a geometric perspective, viewing them as a\nlearned coordinate system for mapping an embedded data distribution. We\nmotivate a model of a generic data distribution as a random lattice and analyze\nits properties using percolation theory. Learned features are categorized into\ncontext, component, and surface features. The model is qualitatively consistent\nwith recent findings in mechanistic interpretability and suggests directions\nfor future research.",
      "tldr_zh": "这篇论文从几何视角探讨深度神经网络的表示学习（Representation Learning），将特征视为嵌入数据分布的坐标系统，以提升模型的安全性和可靠性。作者假设数据分布为随机格子（Random Lattice），并使用渗流理论（Percolation Theory）分析其属性，将特征分类为上下文特征（Context Features）、组件特征（Component Features）和表面特征（Surface Features）。该模型与机械解释性（Mechanistic Interpretability）中的最新发现相符，并为未来研究方向提供了有益建议。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Proceedings of ILIAD (2024),\n  https://www.iliadconference.com/proceedings",
      "pdf_url": "http://arxiv.org/pdf/2504.20197v1",
      "published_date": "2025-04-28 19:01:36 UTC",
      "updated_date": "2025-04-28 19:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:18:44.372186"
    },
    {
      "arxiv_id": "2504.20196v1",
      "title": "Prompting LLMs for Code Editing: Struggles and Remedies",
      "title_zh": "翻译失败",
      "authors": [
        "Daye Nam",
        "Ahmed Omran",
        "Ambar Murillo",
        "Saksham Thakur",
        "Abner Araujo",
        "Marcel Blistein",
        "Alexander Frömmgen",
        "Vincent Hellendoorn",
        "Satish Chandra"
      ],
      "abstract": "Large Language Models (LLMs) are rapidly transforming software engineering,\nwith coding assistants embedded in an IDE becoming increasingly prevalent.\nWhile research has focused on improving the tools and understanding developer\nperceptions, a critical gap exists in understanding how developers actually use\nthese tools in their daily workflows, and, crucially, where they struggle. This\npaper addresses part of this gap through a multi-phased investigation of\ndeveloper interactions with an LLM-powered code editing and transformation\nfeature, Transform Code, in an IDE widely used at Google. First, we analyze\ntelemetry logs of the feature usage, revealing that frequent re-prompting can\nbe an indicator of developer struggles with using Transform Code. Second, we\nconduct a qualitative analysis of unsatisfactory requests, identifying five key\ncategories of information often missing from developer prompts. Finally, based\non these findings, we propose and evaluate a tool, AutoPrompter, for\nautomatically improving prompts by inferring missing information from the\nsurrounding code context, leading to a 27% improvement in edit correctness on\nour test set.",
      "tldr_zh": "这篇论文探讨了开发者在使用大型语言模型 (LLMs) 进行代码编辑时的挑战，通过分析 Google IDE 中 Transform Code 功能的遥测日志，发现频繁 re-prompting 是开发者挣扎的常见指标。研究进一步通过定性分析识别了五类常见提示缺失信息，包括上下文细节和任务规格。最终，论文提出并评估了 AutoPrompter 工具，该工具能自动从周围代码上下文中推断缺失信息，从而将编辑正确性提高了 27%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20196v1",
      "published_date": "2025-04-28 18:59:28 UTC",
      "updated_date": "2025-04-28 18:59:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:18:56.508309"
    },
    {
      "arxiv_id": "2504.20187v1",
      "title": "AI Recommendation Systems for Lane-Changing Using Adherence-Aware Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Sun",
        "Heeseung Bang",
        "Andreas A. Malikopoulos"
      ],
      "abstract": "In this paper, we present an adherence-aware reinforcement learning (RL)\napproach aimed at seeking optimal lane-changing recommendations within a\nsemi-autonomous driving environment to enhance a single vehicle's travel\nefficiency. The problem is framed within a Markov decision process setting and\nis addressed through an adherence-aware deep Q network, which takes into\naccount the partial compliance of human drivers with the recommended actions.\nThis approach is evaluated within CARLA's driving environment under realistic\nscenarios.",
      "tldr_zh": "本文提出了一种adherence-aware reinforcement learning (RL) 方法，用于优化半自动驾驶环境中的换道推荐系统，以提升单一车辆的旅行效率。该方法将问题建模为Markov decision process (MDP)，并采用adherence-aware deep Q network来考虑人类驾驶员对推荐动作的部分遵守行为。通过在CARLA模拟环境中进行现实场景评估，该方法展示了在处理驾驶员遵守性问题上潜在的改进潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 5 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2504.20187v1",
      "published_date": "2025-04-28 18:38:39 UTC",
      "updated_date": "2025-04-28 18:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:19:06.919367"
    },
    {
      "arxiv_id": "2504.20183v1",
      "title": "BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics",
      "title_zh": "翻译失败",
      "authors": [
        "Niki van Stein",
        "Anna V. Kononova",
        "Haoran Yin",
        "Thomas Bäck"
      ],
      "abstract": "The application of Large Language Models (LLMs) for Automated Algorithm\nDiscovery (AAD), particularly for optimisation heuristics, is an emerging field\nof research. This emergence necessitates robust, standardised benchmarking\npractices to rigorously evaluate the capabilities and limitations of LLM-driven\nAAD methods and the resulting generated algorithms, especially given the\nopacity of their design process and known issues with existing benchmarks. To\naddress this need, we introduce BLADE (Benchmark suite for LLM-driven Automated\nDesign and Evolution), a modular and extensible framework specifically designed\nfor benchmarking LLM-driven AAD methods in a continuous black-box optimisation\ncontext. BLADE integrates collections of benchmark problems (including MA-BBOB\nand SBOX-COST among others) with instance generators and textual descriptions\naimed at capability-focused testing, such as generalisation, specialisation and\ninformation exploitation. It offers flexible experimental setup options,\nstandardised logging for reproducibility and fair comparison, incorporates\nmethods for analysing the AAD process (e.g., Code Evolution Graphs and various\nvisualisation approaches) and facilitates comparison against human-designed\nbaselines through integration with established tools like IOHanalyser and\nIOHexplainer. BLADE provides an `out-of-the-box' solution to systematically\nevaluate LLM-driven AAD approaches. The framework is demonstrated through two\ndistinct use cases exploring mutation prompt strategies and function\nspecialisation.",
      "tldr_zh": "该研究引入了 BLADE，这是一个模块化且可扩展的基准测试套件，用于评估大型语言模型 (LLMs) 在自动算法发现 (AAD) 领域的性能，特别是针对迭代优化启发式方法。BLADE 集成了多种基准问题（如 MA-BBOB 和 SBOX-COST）、实例生成器和文本描述，专注于测试能力如泛化、特化和信息利用，并提供灵活实验设置、标准化日志以及分析工具（如 Code Evolution Graphs）。通过与现有工具集成和两个用例的演示，BLADE 便于系统地比较 LLM 驱动 AAD 方法与人类设计基准，促进了该领域的可靠评估和优化。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages, accepted at GECCO Workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20183v1",
      "published_date": "2025-04-28 18:34:09 UTC",
      "updated_date": "2025-04-28 18:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:19:19.805320"
    },
    {
      "arxiv_id": "2504.20179v1",
      "title": "Integration Flow Models",
      "title_zh": "积分流模型",
      "authors": [
        "Jingjing Wang",
        "Dan Zhang",
        "Joshua Luo",
        "Yin Yang",
        "Feng Luo"
      ],
      "abstract": "Ordinary differential equation (ODE) based generative models have emerged as\na powerful approach for producing high-quality samples in many applications.\nHowever, the ODE-based methods either suffer the discretization error of\nnumerical solvers of ODE, which restricts the quality of samples when only a\nfew NFEs are used, or struggle with training instability. In this paper, we\nproposed Integration Flow, which directly learns the integral of ODE-based\ntrajectory paths without solving the ODE functions. Moreover, Integration Flow\nexplicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in\nguiding the reverse-time dynamics. We have theoretically proven this can\ncontribute to both stability and accuracy. To the best of our knowledge,\nIntegration Flow is the first model with a unified structure to estimate\nODE-based generative models and the first to show the exact straightness of\n1-Rectified Flow without reflow. Through theoretical analysis and empirical\nevaluations, we show that Integration Flows achieve improved performance when\nit is applied to existing ODE-based models, such as diffusion models, Rectified\nFlows, and PFGM++. Specifically, Integration Flow achieves one-step generation\non CIFAR10 with FIDs of 2.86 for the Variance Exploding (VE) diffusion model,\n3.36 for rectified flow without reflow, and 2.91 for PFGM++; and on ImageNet\nwith FIDs of 4.09 for VE diffusion model, 4.35 for rectified flow without\nreflow and 4.15 for PFGM++.",
      "tldr_zh": "本论文提出 Integration Flow 模型，通过直接学习 ODE-based 轨迹路径的积分来生成高质量样本，避免了传统 ODE 方法的离散化错误和训练不稳定性。该方法创新地将目标状态 \\(\\mathbf{x}_0\\) 作为锚点指导反向时间动态，并理论证明这提升了模型的稳定性和准确性，同时首次实现统一结构估计 ODE-based 模型并证明 1-Rectified Flow 的精确直线性。实验结果显示，Integration Flow 应用于 VE 扩散模型、Rectified Flows 和 PFGM++ 等模型后，在 CIFAR10 上实现单步生成 FID 分别为 2.86、3.36 和 2.91，在 ImageNet 上分别为 4.09、4.35 和 4.15，显著提高了生成性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20179v1",
      "published_date": "2025-04-28 18:29:15 UTC",
      "updated_date": "2025-04-28 18:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:19:32.971170"
    },
    {
      "arxiv_id": "2504.20172v1",
      "title": "Causal Identification in Time Series Models",
      "title_zh": "时间序列模型中的因果识别",
      "authors": [
        "Erik Jahn",
        "Karthik Karnik",
        "Leonard J. Schulman"
      ],
      "abstract": "In this paper, we analyze the applicability of the Causal Identification\nalgorithm to causal time series graphs with latent confounders. Since these\ngraphs extend over infinitely many time steps, deciding whether causal effects\nacross arbitrary time intervals are identifiable appears to require computation\non graph segments of unbounded size. Even for deciding the identifiability of\nintervention effects on variables that are close in time, no bound is known on\nhow many time steps in the past need to be considered. We give a first bound of\nthis kind that only depends on the number of variables per time step and the\nmaximum time lag of any direct or latent causal effect. More generally, we show\nthat applying the Causal Identification algorithm to a constant-size segment of\nthe time series graph is sufficient to decide identifiability of causal\neffects, even across unbounded time intervals.",
      "tldr_zh": "这篇论文分析了Causal Identification algorithm在带有latent confounders的因果时间序列图中的适用性，针对无限时间步的图结构，探讨了跨任意时间间隔的因果效应是否可识别。论文提出一个新的边界，仅依赖于每个时间步的变量数量和最大时间滞后，从而避免了对无限图段的计算。总体上，它证明了只需在时间序列图的固定大小段上应用该算法，就能决定包括跨越无限间隔的intervention effects在内的因果效应的可识别性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20172v1",
      "published_date": "2025-04-28 18:10:39 UTC",
      "updated_date": "2025-04-28 18:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:19:43.903967"
    },
    {
      "arxiv_id": "2504.20168v1",
      "title": "MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools",
      "title_zh": "翻译失败",
      "authors": [
        "Nishant Subramani",
        "Jason Eisner",
        "Justin Svegliato",
        "Benjamin Van Durme",
        "Yu Su",
        "Sam Thomson"
      ],
      "abstract": "Tool-using agents that act in the world need to be both useful and safe.\nWell-calibrated model confidences can be used to weigh the risk versus reward\nof potential actions, but prior work shows that many models are poorly\ncalibrated. Inspired by interpretability literature exploring the internals of\nmodels, we propose a novel class of model-internal confidence estimators (MICE)\nto better assess confidence when calling tools. MICE first decodes from each\nintermediate layer of the language model using logitLens and then computes\nsimilarity scores between each layer's generation and the final output. These\nfeatures are fed into a learned probabilistic classifier to assess confidence\nin the decoded output. On the simulated trial and error (STE) tool-calling\ndataset using Llama3 models, we find that MICE beats or matches the baselines\non smoothed expected calibration error. Using MICE confidences to determine\nwhether to call a tool significantly improves over strong baselines on a new\nmetric, expected tool-calling utility. Further experiments show that MICE is\nsample-efficient, can generalize zero-shot to unseen APIs, and results in\nhigher tool-calling utility in scenarios with varying risk levels. Our code is\nopen source, available at https://github.com/microsoft/mice_for_cats.",
      "tldr_zh": "这篇论文提出 MICE（Model-Internal Confidence Estimation），一种新型模型内部信心估计器，用于校准使用工具的代理模型，以平衡行动的风险和回报。MICE 方法通过从语言模型的每个中间层使用 logitLens 解码，并计算生成与最终输出的相似度分数，然后输入学习概率分类器来评估信心。在 STE 数据集上实验显示，MICE 优于基线模型，提高了预期工具调用效用（expected tool-calling utility），并展示出样本效率高、零样本泛化到未见 API 的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025. Code:\n  https://github.com/microsoft/mice_for_cats",
      "pdf_url": "http://arxiv.org/pdf/2504.20168v1",
      "published_date": "2025-04-28 18:06:38 UTC",
      "updated_date": "2025-04-28 18:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:19:55.897448"
    },
    {
      "arxiv_id": "2504.20131v1",
      "title": "LZ Penalty: An information-theoretic repetition penalty for autoregressive language models",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio A. Ginart",
        "Naveen Kodali",
        "Jason Lee",
        "Caiming Xiong",
        "Silvio Savarese",
        "John R. Emmons"
      ],
      "abstract": "We introduce the LZ penalty, a penalty specialized for reducing degenerate\nrepetitions in autoregressive language models without loss of capability. The\npenalty is based on the codelengths in the LZ77 universal lossless compression\nalgorithm. Through the lens of the prediction-compression duality, decoding the\nLZ penalty has the interpretation of sampling from the residual distribution\nafter removing the information that is highly compressible. We demonstrate the\nLZ penalty enables state-of-the-art open-source reasoning models to operate\nwith greedy (temperature zero) decoding without loss of capability and without\ninstances of degenerate repetition. Both the industry-standard frequency\npenalty and repetition penalty are ineffective, incurring degenerate repetition\nrates of up to 4%.",
      "tldr_zh": "本研究引入了LZ Penalty，一种基于信息理论的惩罚机制，旨在减少自回归语言模型中的退化重复，同时不影响模型能力。该惩罚利用LZ77无损压缩算法的码长，通过预测-压缩二元性视角，将解码解释为从去除高压缩信息后的残差分布中采样。实验结果显示，LZ Penalty使开源推理模型能够在贪婪解码（温度为零）条件下运行，而不会出现退化重复，且优于标准频率惩罚和重复惩罚，后者可能导致高达4%的退化重复率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint (draft)",
      "pdf_url": "http://arxiv.org/pdf/2504.20131v1",
      "published_date": "2025-04-28 17:58:28 UTC",
      "updated_date": "2025-04-28 17:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:20:07.329425"
    },
    {
      "arxiv_id": "2504.20026v1",
      "title": "LIRM: Large Inverse Rendering Model for Progressive Reconstruction of Shape, Materials and View-dependent Radiance Fields",
      "title_zh": "LIRM：针对形状、材料和视点相关辐射场的渐进式重建的大型逆渲染模型",
      "authors": [
        "Zhengqin Li",
        "Dilin Wang",
        "Ka Chen",
        "Zhaoyang Lv",
        "Thu Nguyen-Phuoc",
        "Milim Lee",
        "Jia-Bin Huang",
        "Lei Xiao",
        "Cheng Zhang",
        "Yufeng Zhu",
        "Carl S. Marshall",
        "Yufeng Ren",
        "Richard Newcombe",
        "Zhao Dong"
      ],
      "abstract": "We present Large Inverse Rendering Model (LIRM), a transformer architecture\nthat jointly reconstructs high-quality shape, materials, and radiance fields\nwith view-dependent effects in less than a second. Our model builds upon the\nrecent Large Reconstruction Models (LRMs) that achieve state-of-the-art\nsparse-view reconstruction quality. However, existing LRMs struggle to\nreconstruct unseen parts accurately and cannot recover glossy appearance or\ngenerate relightable 3D contents that can be consumed by standard Graphics\nengines. To address these limitations, we make three key technical\ncontributions to build a more practical multi-view 3D reconstruction framework.\nFirst, we introduce an update model that allows us to progressively add more\ninput views to improve our reconstruction. Second, we propose a hexa-plane\nneural SDF representation to better recover detailed textures, geometry and\nmaterial parameters. Third, we develop a novel neural directional-embedding\nmechanism to handle view-dependent effects. Trained on a large-scale shape and\nmaterial dataset with a tailored coarse-to-fine training scheme, our model\nachieves compelling results. It compares favorably to optimization-based\ndense-view inverse rendering methods in terms of geometry and relighting\naccuracy, while requiring only a fraction of the inference time.",
      "tldr_zh": "本文提出 Large Inverse Rendering Model (LIRM)，一个基于 transformer 的架构，能够在不到一秒内联合重建高品质的形状、材料和视点依赖辐射场，从而提升多视图 3D 重建的实用性。LIRM 通过三个关键创新来解决现有 Large Reconstruction Models (LRMs) 的不足：引入更新模型以逐步添加输入视图改善重建、采用 hexa-plane neural SDF 表示以精确恢复细节纹理和几何参数，以及开发神经方向嵌入机制处理视点依赖效果。训练于大规模形状和材料数据集上采用粗到细方案后，LIRM 在几何和重光准确性上优于基于优化的密集视图逆渲染方法，同时推理时间仅为其一小部分。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20026v1",
      "published_date": "2025-04-28 17:48:58 UTC",
      "updated_date": "2025-04-28 17:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:20:20.764216"
    },
    {
      "arxiv_id": "2504.20020v1",
      "title": "Modular Machine Learning: An Indispensable Path towards New-Generation Large Language Models",
      "title_zh": "模块化机器学习：通往新一代大型语言模型的不可或缺路径",
      "authors": [
        "Xin Wang",
        "Haoyang Li",
        "Zeyang Zhang",
        "Haibo Chen",
        "Wenwu Zhu"
      ],
      "abstract": "Large language models (LLMs) have dramatically advanced machine learning\nresearch including natural language processing, computer vision, data mining,\netc., yet they still exhibit critical limitations in reasoning, factual\nconsistency, and interpretability. In this paper, we introduce a novel learning\nparadigm -- Modular Machine Learning (MML) -- as an essential approach toward\nnew-generation LLMs. MML decomposes the complex structure of LLMs into three\ninterdependent components: modular representation, modular model, and modular\nreasoning, aiming to enhance LLMs' capability of counterfactual reasoning,\nmitigating hallucinations, as well as promoting fairness, safety, and\ntransparency. Specifically, the proposed MML paradigm can: i) clarify the\ninternal working mechanism of LLMs through the disentanglement of semantic\ncomponents; ii) allow for flexible and task-adaptive model design; iii) enable\ninterpretable and logic-driven decision-making process. We present a feasible\nimplementation of MML-based LLMs via leveraging advanced techniques such as\ndisentangled representation learning, neural architecture search and\nneuro-symbolic learning. We critically identify key challenges, such as the\nintegration of continuous neural and discrete symbolic processes, joint\noptimization, and computational scalability, present promising future research\ndirections that deserve further exploration. Ultimately, the integration of the\nMML paradigm with LLMs has the potential to bridge the gap between statistical\n(deep) learning and formal (logical) reasoning, thereby paving the way for\nrobust, adaptable, and trustworthy AI systems across a wide range of real-world\napplications.",
      "tldr_zh": "这篇论文引入了 Modular Machine Learning (MML) 作为通往新一代 Large Language Models (LLMs) 的关键范式，旨在解决 LLMs 在推理、一致性和可解释性方面的局限性。MML 将 LLMs 结构分解为三个相互依赖的组件——modular representation、modular model 和 modular reasoning，从而提升 counterfactual reasoning 能力、减少 hallucinations，并促进公平、安全和透明。论文通过 disentangled representation learning、neural architecture search 和 neuro-symbolic learning 等技术实现 MML，并指出了整合挑战如神经与符号过程的联合优化和计算可扩展性，同时展望了桥接统计学习与形式推理的未来方向，以构建更鲁棒、可适应的 AI 系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20020v1",
      "published_date": "2025-04-28 17:42:02 UTC",
      "updated_date": "2025-04-28 17:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:20:33.779106"
    },
    {
      "arxiv_id": "2504.20019v1",
      "title": "Modelling of Underwater Vehicles using Physics-Informed Neural Networks with Control",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelhakim Amer",
        "David Felsager",
        "Yury Brodskiy",
        "Andriy Sarabakha"
      ],
      "abstract": "Physics-informed neural networks (PINNs) integrate physical laws with\ndata-driven models to improve generalization and sample efficiency. This work\nintroduces an open-source implementation of the Physics-Informed Neural Network\nwith Control (PINC) framework, designed to model the dynamics of an underwater\nvehicle. Using initial states, control actions, and time inputs, PINC extends\nPINNs to enable physically consistent transitions beyond the training domain.\nVarious PINC configurations are tested, including differing loss functions,\ngradient-weighting schemes, and hyperparameters. Validation on a simulated\nunderwater vehicle demonstrates more accurate long-horizon predictions compared\nto a non-physics-informed baseline",
      "tldr_zh": "这篇论文介绍了 Physics-Informed Neural Network with Control (PINC) 框架，一个开源实现，用于模拟水下车辆的动力学。PINC 基于 Physics-Informed Neural Networks (PINNs)，通过整合物理定律、初始状态、控制动作和时间输入，实现超出训练域的物理一致性过渡，并测试了各种损失函数、梯度加权方案和超参数。实验结果显示，在模拟水下车辆环境中，PINC 比非物理信息基线模型提供了更准确的长horizon预测。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2025. The final version consists\n  of 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20019v1",
      "published_date": "2025-04-28 17:38:57 UTC",
      "updated_date": "2025-04-28 17:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:20:44.672379"
    },
    {
      "arxiv_id": "2504.20018v1",
      "title": "MINT: Multi-Vector Search Index Tuning",
      "title_zh": "MINT: 多向量搜索索引调优",
      "authors": [
        "Jiongli Zhu",
        "Yue Wang",
        "Bailu Ding",
        "Philip A. Bernstein",
        "Vivek Narasayya",
        "Surajit Chaudhuri"
      ],
      "abstract": "Vector search plays a crucial role in many real-world applications. In\naddition to single-vector search, multi-vector search becomes important for\nmulti-modal and multi-feature scenarios today. In a multi-vector database, each\nrow is an item, each column represents a feature of items, and each cell is a\nhigh-dimensional vector. In multi-vector databases, the choice of indexes can\nhave a significant impact on performance. Although index tuning for relational\ndatabases has been extensively studied, index tuning for multi-vector search\nremains unclear and challenging. In this paper, we define multi-vector search\nindex tuning and propose a framework to solve it. Specifically, given a\nmulti-vector search workload, we develop algorithms to find indexes that\nminimize latency and meet storage and recall constraints. Compared to the\nbaseline, our latency achieves 2.1X to 8.3X speedup.",
      "tldr_zh": "这篇论文介绍了MINT框架，用于优化多向量搜索（Multi-Vector Search）数据库的索引调整，以提升多模态和多特征场景下的搜索性能。论文定义了多向量搜索索引调整问题，并提出算法来针对给定工作负载选择索引，从而最小化查询延迟，同时满足存储和召回约束。与基线方法相比，实验结果显示延迟提升了2.1X到8.3X，为实际应用中的高效向量搜索提供了有效解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20018v1",
      "published_date": "2025-04-28 17:36:06 UTC",
      "updated_date": "2025-04-28 17:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:20:56.074500"
    },
    {
      "arxiv_id": "2504.20010v1",
      "title": "Towards Automated Scoping of AI for Social Good Projects",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Emmerson",
        "Rayid Ghani",
        "Zheyuan Ryan Shi"
      ],
      "abstract": "Artificial Intelligence for Social Good (AI4SG) is an emerging effort that\naims to address complex societal challenges with the powerful capabilities of\nAI systems. These challenges range from local issues with transit networks to\nglobal wildlife preservation. However, regardless of scale, a critical\nbottleneck for many AI4SG initiatives is the laborious process of problem\nscoping -- a complex and resource-intensive task -- due to a scarcity of\nprofessionals with both technical and domain expertise. Given the remarkable\napplications of large language models (LLM), we propose a Problem Scoping Agent\n(PSA) that uses an LLM to generate comprehensive project proposals grounded in\nscientific literature and real-world knowledge. We demonstrate that our PSA\nframework generates proposals comparable to those written by experts through a\nblind review and AI evaluations. Finally, we document the challenges of\nreal-world problem scoping and note several areas for future work.",
      "tldr_zh": "该研究针对 AI for Social Good (AI4SG) 项目中问题范围界定（problem scoping）的资源密集挑战，提出了一种 Problem Scoping Agent (PSA) 框架，利用 large language models (LLM) 生成基于科学文献和现实知识的全面项目提案。PSA 通过盲审和 AI 评估，证明其生成的提案质量可与专家水平媲美，有效缓解了专业知识短缺的问题。论文还讨论了实际问题范围界定的挑战，并指出未来工作方向，如进一步优化模型适应性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20010v1",
      "published_date": "2025-04-28 17:29:51 UTC",
      "updated_date": "2025-04-28 17:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:21:07.966325"
    },
    {
      "arxiv_id": "2504.20007v2",
      "title": "Towards AI-Driven Policing: Interdisciplinary Knowledge Discovery from Police Body-Worn Camera Footage",
      "title_zh": "翻译失败",
      "authors": [
        "Anita Srbinovska",
        "Angela Srbinovska",
        "Vivek Senthil",
        "Adrian Martin",
        "John McCluskey",
        "Jonathan Bateman",
        "Ernest Fokoué"
      ],
      "abstract": "This paper proposes a novel interdisciplinary framework for analyzing police\nbody-worn camera (BWC) footage from the Rochester Police Department (RPD) using\nadvanced artificial intelligence (AI) and statistical machine learning (ML)\ntechniques. Our goal is to detect, classify, and analyze patterns of\ninteraction between police officers and civilians to identify key behavioral\ndynamics, such as respect, disrespect, escalation, and de-escalation. We apply\nmultimodal data analysis by integrating video, audio, and natural language\nprocessing (NLP) techniques to extract meaningful insights from BWC footage. We\npresent our methodology, computational techniques, and findings, outlining a\npractical approach for law enforcement while advancing the frontiers of\nknowledge discovery from police BWC data.",
      "tldr_zh": "本论文提出一个新型跨学科框架，利用AI和统计机器学习(ML)技术分析罗切斯特警察局(RPD)的随身摄像头(BWC)视频，旨在检测、分类和分析警察与平民互动模式，如尊重、不尊重、升级和降级行为。框架采用多模态数据分析方法，整合视频、音频和自然语言处理(NLP)技术，从BWC数据中提取关键洞见。研究展示了具体方法、计算技术和发现，为执法部门提供实用策略，并推动警察BWC数据知识发现领域的创新进展。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures, and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.20007v2",
      "published_date": "2025-04-28 17:25:23 UTC",
      "updated_date": "2025-05-09 14:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:21:19.765093"
    },
    {
      "arxiv_id": "2504.19997v1",
      "title": "Simplified and Secure MCP Gateways for Enterprise AI Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Ivo Brett"
      ],
      "abstract": "The increased adoption of the Model Context Protocol (MCP) for AI Agents\nnecessitates robust security for Enterprise integrations. This paper introduces\nthe MCP Gateway to simplify self-hosted MCP server integration. The proposed\narchitecture integrates security principles, authentication, intrusion\ndetection, and secure tunneling, enabling secure self-hosting without exposing\ninfrastructure. Key contributions include a reference architecture, threat\nmodel mapping, simplified integration strategies, and open-source\nimplementation recommendations. This work focuses on the unique challenges of\nenterprise-centric, self-hosted AI integrations, unlike existing public MCP\nserver solutions.",
      "tldr_zh": "该论文针对AI Agents采用Model Context Protocol (MCP)时企业集成的安全需求，提出了一种简化的MCP Gateway架构，以简化自托管MCP服务器的集成。该架构整合了安全原则、认证、入侵检测和安全隧道，确保自托管环境不暴露基础设施。关键贡献包括参考架构、威胁模型映射、简化集成策略以及开源实现推荐，该工作专注于企业中心自托管AI集成的独特挑战，与现有公共MCP服务器解决方案形成鲜明对比。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19997v1",
      "published_date": "2025-04-28 17:17:42 UTC",
      "updated_date": "2025-04-28 17:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:21:31.496298"
    },
    {
      "arxiv_id": "2504.19996v1",
      "title": "Monitoring digestate application on agricultural crops using Sentinel-2 Satellite imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Kalogeras",
        "Dimitrios Bormpoudakis",
        "Iason Tsardanidis",
        "Dimitra A. Loka",
        "Charalampos Kontoes"
      ],
      "abstract": "The widespread use of Exogenous Organic Matter in agriculture necessitates\nmonitoring to assess its effects on soil and crop health. This study evaluates\noptical Sentinel-2 satellite imagery for detecting digestate application, a\npractice that enhances soil fertility but poses environmental risks like\nmicroplastic contamination and nitrogen losses. In the first instance,\nSentinel-2 satellite image time series (SITS) analysis of specific indices\n(EOMI, NDVI, EVI) was used to characterize EOM's spectral behavior after\napplication on the soils of four different crop types in Thessaly, Greece.\nFurthermore, Machine Learning (ML) models (namely Random Forest, k-NN, Gradient\nBoosting and a Feed-Forward Neural Network), were used to investigate digestate\npresence detection, achieving F1-scores up to 0.85. The findings highlight the\npotential of combining remote sensing and ML for scalable and cost-effective\nmonitoring of EOM applications, supporting precision agriculture and\nsustainability.",
      "tldr_zh": "本研究评估了使用 Sentinel-2 卫星图像监测外源有机物（Exogenous Organic Matter, EOM）应用对农业作物的影响，特别是消化物（digestate）的施用，以平衡土壤肥力和环境风险如微塑料污染和氮损失。通过分析 Sentinel-2 图像时间序列（SITS）和特定指数（EOMI, NDVI, EVI），研究表征了四种作物类型在希腊 Thessaly 土壤上的光谱行为。采用机器学习模型（包括 Random Forest, k-NN, Gradient Boosting 和 Feed-Forward Neural Network），检测消化物存在的准确率最高达到 F1-score 0.85。这些结果突出了遥感和机器学习相结合的潜力，支持可扩展、成本有效的精准农业和可持续发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19996v1",
      "published_date": "2025-04-28 17:16:40 UTC",
      "updated_date": "2025-04-28 17:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:21:45.872844"
    },
    {
      "arxiv_id": "2504.19990v1",
      "title": "Mitigating Societal Cognitive Overload in the Age of AI: Challenges and Directions",
      "title_zh": "在 AI 时代缓解社会认知超载：挑战和方向",
      "authors": [
        "Salem Lahlou"
      ],
      "abstract": "Societal cognitive overload, driven by the deluge of information and\ncomplexity in the AI age, poses a critical challenge to human well-being and\nsocietal resilience. This paper argues that mitigating cognitive overload is\nnot only essential for improving present-day life but also a crucial\nprerequisite for navigating the potential risks of advanced AI, including\nexistential threats. We examine how AI exacerbates cognitive overload through\nvarious mechanisms, including information proliferation, algorithmic\nmanipulation, automation anxieties, deregulation, and the erosion of meaning.\nThe paper reframes the AI safety debate to center on cognitive overload,\nhighlighting its role as a bridge between near-term harms and long-term risks.\nIt concludes by discussing potential institutional adaptations, research\ndirections, and policy considerations that arise from adopting an\noverload-resilient perspective on human-AI alignment, suggesting pathways for\nfuture exploration rather than prescribing definitive solutions.",
      "tldr_zh": "这篇论文探讨了AI时代的社会认知过载(societal cognitive overload)对人类福祉和社会韧性的挑战，认为缓解这一问题不仅是改善当前生活的关键，还能防范高级AI的风险，包括存在威胁。论文分析了AI通过信息泛滥、算法操纵、自动化焦虑、放松管制和意义侵蚀等机制加剧认知过载，并将其重新框架为连接短期危害和长期风险的桥梁。最终，它建议从过载弹性视角出发，探讨机构适应、研究方向和政策考虑，以推动人类-AI对齐(human-AI alignment)的未来探索。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19990v1",
      "published_date": "2025-04-28 17:06:30 UTC",
      "updated_date": "2025-04-28 17:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:21:56.992182"
    },
    {
      "arxiv_id": "2505.03770v1",
      "title": "Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Mouad Abrini",
        "Omri Abend",
        "Dina Acklin",
        "Henny Admoni",
        "Gregor Aichinger",
        "Nitay Alon",
        "Zahra Ashktorab",
        "Ashish Atreja",
        "Moises Auron",
        "Alexander Aufreiter",
        "Raghav Awasthi",
        "Soumya Banerjee",
        "Joe M. Barnby",
        "Rhea Basappa",
        "Severin Bergsmann",
        "Djallel Bouneffouf",
        "Patrick Callaghan",
        "Marc Cavazza",
        "Thierry Chaminade",
        "Sonia Chernova",
        "Mohamed Chetouan",
        "Moumita Choudhury",
        "Axel Cleeremans",
        "Jacek B. Cywinski",
        "Fabio Cuzzolin",
        "Hokin Deng",
        "N'yoma Diamond",
        "Camilla Di Pasquasio",
        "Guillaume Dumas",
        "Max van Duijn",
        "Mahapatra Dwarikanath",
        "Qingying Gao",
        "Ashok Goel",
        "Rebecca Goldstein",
        "Matthew Gombolay",
        "Gabriel Enrique Gonzalez",
        "Amar Halilovic",
        "Tobias Halmdienst",
        "Mahimul Islam",
        "Julian Jara-Ettinger",
        "Natalie Kastel",
        "Renana Keydar",
        "Ashish K. Khanna",
        "Mahdi Khoramshahi",
        "JiHyun Kim",
        "MiHyeon Kim",
        "YoungBin Kim",
        "Senka Krivic",
        "Nikita Krasnytskyi",
        "Arun Kumar",
        "JuneHyoung Kwon",
        "Eunju Lee",
        "Shane Lee",
        "Peter R. Lewis",
        "Xue Li",
        "Yijiang Li",
        "Michal Lewandowski",
        "Nathan Lloyd",
        "Matthew B. Luebbers",
        "Dezhi Luo",
        "Haiyun Lyu",
        "Dwarikanath Mahapatra",
        "Kamal Maheshwari",
        "Mallika Mainali",
        "Piyush Mathur",
        "Patrick Mederitsch",
        "Shuwa Miura",
        "Manuel Preston de Miranda",
        "Reuth Mirsky",
        "Shreya Mishra",
        "Nina Moorman",
        "Katelyn Morrison",
        "John Muchovej",
        "Bernhard Nessler",
        "Felix Nessler",
        "Hieu Minh Jord Nguyen",
        "Abby Ortego",
        "Francis A. Papay",
        "Antoine Pasquali",
        "Hamed Rahimi",
        "Charumathi Raghu",
        "Amanda Royka",
        "Stefan Sarkadi",
        "Jaelle Scheuerman",
        "Simon Schmid",
        "Paul Schrater",
        "Anik Sen",
        "Zahra Sheikhbahaee",
        "Ke Shi",
        "Reid Simmons",
        "Nishant Singh",
        "Mason O. Smith",
        "Ramira van der Meulen",
        "Anthia Solaki",
        "Haoran Sun",
        "Viktor Szolga",
        "Matthew E. Taylor",
        "Travis Taylor",
        "Sanne Van Waveren",
        "Juan David Vargas",
        "Rineke Verbrugge",
        "Eitan Wagner",
        "Justin D. Weisz",
        "Ximing Wen",
        "William Yeoh",
        "Wenlong Zhang",
        "Michelle Zhao",
        "Shlomo Zilberstein"
      ],
      "abstract": "This volume includes a selection of papers presented at the Workshop on\nAdvancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in\nPhiladelphia US on 3rd March 2025. The purpose of this volume is to provide an\nopen access and curated anthology for the ToM and AI research community.",
      "tldr_zh": "这本论文集收录了在2025年3月3日于美国费城AAAI 2025会议上举办的第一届“Advancing Artificial Intelligence through Theory of Mind”研讨会的选定论文。目的是为Theory of Mind (ToM)和人工智能(AI)研究社区提供一个开放访问的、经过精选的学术资源，促进相关领域的创新和交流。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "workshop proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.03770v1",
      "published_date": "2025-04-28 17:06:14 UTC",
      "updated_date": "2025-04-28 17:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:22:08.516387"
    },
    {
      "arxiv_id": "2504.19985v1",
      "title": "Real-Time Imitation of Human Head Motions, Blinks and Emotions by Nao Robot: A Closed-Loop Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Keyhan Rayati",
        "Amirhossein Feizi",
        "Alireza Beigy",
        "Pourya Shahverdi",
        "Mehdi Tale Masouleh",
        "Ahmad Kalhor"
      ],
      "abstract": "This paper introduces a novel approach for enabling real-time imitation of\nhuman head motion by a Nao robot, with a primary focus on elevating human-robot\ninteractions. By using the robust capabilities of the MediaPipe as a computer\nvision library and the DeepFace as an emotion recognition library, this\nresearch endeavors to capture the subtleties of human head motion, including\nblink actions and emotional expressions, and seamlessly incorporate these\nindicators into the robot's responses. The result is a comprehensive framework\nwhich facilitates precise head imitation within human-robot interactions,\nutilizing a closed-loop approach that involves gathering real-time feedback\nfrom the robot's imitation performance. This feedback loop ensures a high\ndegree of accuracy in modeling head motion, as evidenced by an impressive R2\nscore of 96.3 for pitch and 98.9 for yaw. Notably, the proposed approach holds\npromise in improving communication for children with autism, offering them a\nvaluable tool for more effective interaction. In essence, proposed work\nexplores the integration of real-time head imitation and real-time emotion\nrecognition to enhance human-robot interactions, with potential benefits for\nindividuals with unique communication needs.",
      "tldr_zh": "本研究提出了一种闭环方法，让 Nao robot 实时模仿人类的头部动作、眨眼和情感表达，以提升人机互动质量。方法利用 MediaPipe 作为计算机视觉库和 DeepFace 作为情感识别库，捕捉人类动作细微差别，并通过实时反馈循环确保模仿准确性。实验结果显示，pitch 的 R2 score 为 96.3，yaw 为 98.9，证明了框架的高效性。该方法特别有望改善自闭症儿童的沟通，提供更有效的互动工具。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19985v1",
      "published_date": "2025-04-28 17:01:54 UTC",
      "updated_date": "2025-04-28 17:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:22:20.058220"
    },
    {
      "arxiv_id": "2504.19982v1",
      "title": "TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons",
      "title_zh": "翻译失败",
      "authors": [
        "Emre Can Acikgoz",
        "Carl Guo",
        "Suvodip Dey",
        "Akul Datta",
        "Takyoung Kim",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Task-oriented dialogue (TOD) systems are experiencing a revolution driven by\nLarge Language Models (LLMs), yet the evaluation methodologies for these\nsystems remain insufficient for their growing sophistication. While traditional\nautomatic metrics effectively assessed earlier modular systems, they focus\nsolely on the dialogue level and cannot detect critical intermediate errors\nthat can arise during user-agent interactions. In this paper, we introduce\nTD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework\nthat unifies fine-grained turn-level analysis with holistic dialogue-level\ncomparisons. At turn level, we evaluate each response along three TOD-specific\ndimensions: conversation cohesion, backend knowledge consistency, and policy\ncompliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons\nto provide a measure of dialogue-level quality. Through experiments on MultiWOZ\n2.4 and {\\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the\nconversational errors that conventional metrics miss. Furthermore, TD-EVAL\nexhibits better alignment with human judgments than traditional and LLM-based\nmetrics. These findings demonstrate that TD-EVAL introduces a new paradigm for\nTOD system evaluation, efficiently assessing both turn and system levels with a\nplug-and-play framework for future research.",
      "tldr_zh": "该论文重新审视任务导向对话 (TOD) 系统的评估问题，提出 TD-EVAL 框架，该框架结合回合级别精确分析（包括对话连贯性、后端知识一致性和策略遵守三个维度）和对话级别配对比较（通过 TOD Agent Arena 进行）。实验在 MultiWOZ 2.4 和 τ-Bench 数据集上显示，TD-EVAL 能识别传统指标忽略的关键错误，并与人类判断更紧密对齐。总体上，这为 TOD 系统评估引入了一个即插即用的新范式，提升了评估的全面性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19982v1",
      "published_date": "2025-04-28 16:57:17 UTC",
      "updated_date": "2025-04-28 16:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:22:32.981606"
    },
    {
      "arxiv_id": "2504.19968v1",
      "title": "How Group Lives Go Well",
      "title_zh": "翻译失败",
      "authors": [
        "John Beverley",
        "Regina Hurley"
      ],
      "abstract": "This paper explores the ontological space of group well being, proposing a\nframework for representing collective welfare, group functions, and long term\ncontributions within an ontology engineering context. Traditional well being\ntheories focus on individual states, often relying on hedonistic, desire\nsatisfaction, or objective list models. Such approaches struggle to account for\ncases where individual sacrifices contribute to broader social progress, a\ncritical challenge in modeling group flourishing. To address this, the paper\nrefines and extends the Counterfactual Account (CT) of well being, which\nevaluates goodness of an event by comparing an individual's actual well being\nwith a hypothetical counterpart in a nearby possible world. While useful, this\nframework is insufficient for group level ontologies, where well being depends\non functional persistence, institutional roles, and historical impact rather\nthan immediate individual outcomes. Drawing on Basic Formal Ontology (BFO), the\npaper introduces a model in which group flourishing is evaluated in terms of\ngroup functional, where members bear roles and exhibit persistence conditions\nakin to biological systems or designed artifacts. This approach enables\nsemantic interoperability for modeling longitudinal social contributions,\nallowing for structured reasoning about group welfare, social institutions, and\ngroup flourishing over time.",
      "tldr_zh": "这篇论文探讨了群体福祉的本体空间（ontological space of group well being），提出一个框架来表示集体福祉、群体功能和长期贡献，以解决传统福祉理论（如享乐主义、欲望满足或客观列表模型）过度关注个体状态的局限性。论文改进并扩展了Counterfactual Account (CT) of well being，通过比较实际与假设世界的福祉来评估事件，但发现其不足以处理群体层面的问题，如功能持续性、机构角色和历史影响。借鉴Basic Formal Ontology (BFO)，论文引入一个新模型，将群体繁荣评估为群体功能，类似于生物系统或设计制品，从而实现语义互操作性，并支持对长期社会贡献、群体福祉和社会机构的结构化推理。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19968v1",
      "published_date": "2025-04-28 16:40:06 UTC",
      "updated_date": "2025-04-28 16:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:22:44.665083"
    },
    {
      "arxiv_id": "2504.19967v1",
      "title": "Enhancing short-term traffic prediction by integrating trends and fluctuations with attention mechanism",
      "title_zh": "通过整合趋势和波动以及注意力机制增强短期交通预测",
      "authors": [
        "Adway Das",
        "Agnimitra Sengupta",
        "S. Ilgin Guler"
      ],
      "abstract": "Traffic flow prediction is a critical component of intelligent transportation\nsystems, yet accurately forecasting traffic remains challenging due to the\ninteraction between long-term trends and short-term fluctuations. Standard deep\nlearning models often struggle with these challenges because their\narchitectures inherently smooth over fine-grained fluctuations while focusing\non general trends. This limitation arises from low-pass filtering effects, gate\nbiases favoring stability, and memory update mechanisms that prioritize\nlong-term information retention. To address these shortcomings, this study\nintroduces a hybrid deep learning framework that integrates both long-term\ntrend and short-term fluctuation information using two input features processed\nin parallel, designed to capture complementary aspects of traffic flow\ndynamics. Further, our approach leverages attention mechanisms, specifically\nBahdanau attention, to selectively focus on critical time steps within traffic\ndata, enhancing the model's ability to predict congestion and other transient\nphenomena. Experimental results demonstrate that features learned from both\nbranches are complementary, significantly improving the goodness-of-fit\nstatistics across multiple prediction horizons compared to a baseline model.\nNotably, the attention mechanism enhances short-term forecast accuracy by\ndirectly targeting immediate fluctuations, though challenges remain in fully\nintegrating long-term trends. This framework can contribute to more effective\ncongestion mitigation and urban mobility planning by advancing the robustness\nand precision of traffic prediction models.",
      "tldr_zh": "这篇论文针对交通流量预测的挑战，提出一个混合深度学习框架，通过并行处理长期趋势和短期波动信息来提升预测准确性。框架利用 Bahdanau attention mechanism 选择性地关注关键时间步骤，从而更好地捕捉瞬时现象如拥堵。实验结果表明，该方法比基线模型显著提高了预测性能，尤其在短期预测中，特征学习的分支显示出互补性。整体框架有助于增强交通预测的鲁棒性和精确性，支持更有效的拥堵缓解和城市交通规划。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19967v1",
      "published_date": "2025-04-28 16:38:46 UTC",
      "updated_date": "2025-04-28 16:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:22:56.087174"
    },
    {
      "arxiv_id": "2504.19956v2",
      "title": "Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Vineeth Sai Narajala",
        "Om Narayan"
      ],
      "abstract": "As generative AI (GenAI) agents become more common in enterprise settings,\nthey introduce security challenges that differ significantly from those posed\nby traditional systems. These agents are not just LLMs; they reason, remember,\nand act, often with minimal human oversight. This paper introduces a\ncomprehensive threat model tailored specifically for GenAI agents, focusing on\nhow their autonomy, persistent memory access, complex reasoning, and tool\nintegration create novel risks. This research work identifies 9 primary threats\nand organizes them across five key domains: cognitive architecture\nvulnerabilities, temporal persistence threats, operational execution\nvulnerabilities, trust boundary violations, and governance circumvention. These\nthreats are not just theoretical they bring practical challenges such as\ndelayed exploitability, cross-system propagation, cross system lateral\nmovement, and subtle goal misalignments that are hard to detect with existing\nframeworks and standard approaches. To help address this, the research work\npresent two complementary frameworks: ATFAA - Advanced Threat Framework for\nAutonomous AI Agents, which organizes agent-specific risks, and SHIELD, a\nframework proposing practical mitigation strategies designed to reduce\nenterprise exposure. While this work builds on existing work in LLM and AI\nsecurity, the focus is squarely on what makes agents different and why those\ndifferences matter. Ultimately, this research argues that GenAI agents require\na new lens for security. If we fail to adapt our threat models and defenses to\naccount for their unique architecture and behavior, we risk turning a powerful\nnew tool into a serious enterprise liability.",
      "tldr_zh": "这篇论文针对生成式 AI (GenAI) 代理在企业环境中的安全挑战，引入了一个全面威胁模型，聚焦于其自治性、持久内存访问、复杂推理和工具集成带来的新风险。研究识别了 9 个主要威胁，并将其组织在五个关键领域：认知架构漏洞、时间持久性威胁、操作执行漏洞、信任边界违反和治理规避，这些威胁可能导致延迟利用、跨系统传播和目标失调等问题。论文提出了两个框架：ATFAA (Advanced Threat Framework for Autonomous AI Agents)，用于系统化代理特定风险，以及 SHIELD，用于提供实际缓解策略以降低企业暴露。最终，研究强调，GenAI 代理需要全新的安全视角，否则可能将这些强大工具转化为潜在责任。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 2 figures, 1 table, typos corrected, references added",
      "pdf_url": "http://arxiv.org/pdf/2504.19956v2",
      "published_date": "2025-04-28 16:29:24 UTC",
      "updated_date": "2025-05-02 18:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:23:09.912723"
    },
    {
      "arxiv_id": "2504.19951v1",
      "title": "Securing GenAI Multi-Agent Systems Against Tool Squatting: A Zero Trust Registry-Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Vineeth Sai Narajala",
        "Ken Huang",
        "Idan Habler"
      ],
      "abstract": "The rise of generative AI (GenAI) multi-agent systems (MAS) necessitates\nstandardized protocols enabling agents to discover and interact with external\ntools. However, these protocols introduce new security challenges,\nparticularly; tool squatting; the deceptive registration or representation of\ntools. This paper analyzes tool squatting threats within the context of\nemerging interoperability standards, such as Model Context Protocol (MCP) or\nseamless communication between agents protocols. It introduces a comprehensive\nTool Registry system designed to mitigate these risks. We propose a\nsecurity-focused architecture featuring admin-controlled registration,\ncentralized tool discovery, fine grained access policies enforced via dedicated\nAgent and Tool Registry services, a dynamic trust scoring mechanism based on\ntool versioning and known vulnerabilities, and just in time credential\nprovisioning. Based on its design principles, the proposed registry framework\naims to effectively prevent common tool squatting vectors while preserving the\nflexibility and power of multi-agent systems. This work addresses a critical\nsecurity gap in the rapidly evolving GenAI ecosystem and provides a foundation\nfor secure tool integration in production environments.",
      "tldr_zh": "这篇论文针对生成式 AI (GenAI) 多智能体系统 (MAS) 中的工具篡改 (tool squatting) 威胁进行分析，该威胁通过欺骗性工具注册在标准协议如 Model Context Protocol (MCP) 中出现，导致安全风险。论文提出一个基于 Zero Trust 的工具注册系统，包括管理员控制注册、中央化工具发现、细粒度访问策略、动态信任评分机制（基于工具版本和已知漏洞）以及及时凭证提供，以有效缓解这些攻击。总体上，该框架不仅防止常见工具篡改向量，还维护了多智能体系统的灵活性，并为生产环境中的安全工具集成奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.19951v1",
      "published_date": "2025-04-28 16:22:21 UTC",
      "updated_date": "2025-04-28 16:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:23:21.223791"
    },
    {
      "arxiv_id": "2504.19949v1",
      "title": "Capturing Aerodynamic Characteristics of ATTAS Aircraft with Evolving Intelligent System",
      "title_zh": "通过演化智能系统捕获 ATTAS 飞机的空气",
      "authors": [
        "Aydoğan Soylu",
        "Tufan Kumbasar"
      ],
      "abstract": "Accurate modeling of aerodynamic coefficients is crucial for understanding\nand optimizing the performance of modern aircraft systems. This paper presents\nthe novel deployment of an Evolving Type-2 Quantum Fuzzy Neural Network\n(eT2QFNN) for modeling the aerodynamic coefficients of the ATTAS aircraft to\nexpress the aerodynamic characteristics. eT2QFNN can represent the nonlinear\naircraft model by creating multiple linear submodels with its rule-based\nstructure through an incremental learning strategy rather than a traditional\nbatch learning approach. Moreover, it enhances robustness to uncertainties and\ndata noise through its quantum membership functions, as well as its automatic\nrule-learning and parameter-tuning capabilities. During the estimation of the\naerodynamic coefficients via the flight data of the ATTAS, two different\nstudies are conducted in the training phase: one with a large amount of data\nand the other with a limited amount of data. The results show that the modeling\nperformance of the eT2QFNN is superior in comparison to baseline counterparts.\nFurthermore, eT2QFNN estimated the aerodynamic model with fewer rules compared\nto Type-1 fuzzy counterparts. In addition, by applying the Delta method to the\nproposed approach, the stability and control derivatives of the aircraft are\nanalyzed. The results prove the superiority of the proposed eT2QFNN in\nrepresenting aerodynamic coefficients.",
      "tldr_zh": "本论文提出了一种新型的 Evolving Type-2 Quantum Fuzzy Neural Network (eT2QFNN) 方法，用于精确建模 ATTAS 飞机的空气动力学系数，从而更好地理解和优化飞机性能。eT2QFNN 通过增量学习策略创建多个线性子模型，并利用量子成员函数增强对不确定性和数据噪声的鲁棒性，同时实现自动规则学习和参数调整。实验结果表明，该方法在 ATTAS 飞行数据上的建模性能优于基线模型，使用更少的规则，并通过 Delta 方法成功分析了飞机的稳定性和控制导数，证明了其整体优越性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "in International Congress on Human-Computer Interaction, Optimization\n  and Robotic Applications, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19949v1",
      "published_date": "2025-04-28 16:21:20 UTC",
      "updated_date": "2025-04-28 16:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:23:32.526390"
    },
    {
      "arxiv_id": "2504.19944v1",
      "title": "Probabilistic and Causal Satisfiability: Constraining the Model",
      "title_zh": "概率和因果可满足性：约束",
      "authors": [
        "Markus Bläser",
        "Julian Dörfler",
        "Maciej Liśkiewicz",
        "Benito van der Zander"
      ],
      "abstract": "We study the complexity of satisfiability problems in probabilistic and\ncausal reasoning. Given random variables $X_1, X_2,\\ldots$ over finite domains,\nthe basic terms are probabilities of propositional formulas over atomic events\n$X_i = x_i$, such as $P(X_1 = x_1)$ or $P(X_1 = x_1 \\vee X_2 = x_2)$. The basic\nterms can be combined using addition (yielding linear terms) or multiplication\n(polynomial terms). The probabilistic satisfiability problem asks whether a\njoint probability distribution satisfies a Boolean combination of\n(in)equalities over such terms. Fagin et al. (1990) showed that for basic and\nlinear terms, this problem is NP-complete, making it no harder than Boolean\nsatisfiability, while Moss\\'e et al. (2022) proved that for polynomial terms,\nit is complete for the existential theory of the reals.\n  Pearl's Causal Hierarchy (PCH) extends the probabilistic setting with\ninterventional and counterfactual reasoning, enriching the expressiveness of\nlanguages. However, Moss\\'e et al. (2022) found that satisfiability complexity\nremains unchanged. Van der Zander et al. (2023) showed that introducing a\nmarginalization operator to languages induces a significant increase in\ncomplexity.\n  We extend this line of work by adding two new dimensions to the problem by\nconstraining the models. First, we fix the graph structure of the underlying\nstructural causal model, motivated by settings like Pearl's do-calculus, and\ngive a nearly complete landscape across different arithmetics and PCH levels.\nSecond, we study small models. While earlier work showed that satisfiable\ninstances admit polynomial-size models, this is no longer guaranteed with\ncompact marginalization. We characterize the complexities of satisfiability\nunder small-model constraints across different settings.",
      "tldr_zh": "本论文探讨了概率和因果推理中可满足性问题的复杂性，针对随机变量的概率术语（如基本、线性或多项式术语）及其布尔组合。作者扩展了现有工作，通过固定底层结构因果模型的图结构（如Pearl's Causal Hierarchy (PCH)），提供了不同算术运算和PCH水平的几乎完整复杂性景观。研究还分析了小模型约束下的可满足性，发现引入紧凑边缘化后，可满足实例不再保证具有多项式大小的模型，从而表征了各种设置下的复杂性（例如NP-complete或existential theory of the reals）。这为概率和因果推理领域提供了更精确的约束分析框架。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CC",
      "comment": "accepted at ICALP 25",
      "pdf_url": "http://arxiv.org/pdf/2504.19944v1",
      "published_date": "2025-04-28 16:14:06 UTC",
      "updated_date": "2025-04-28 16:14:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:23:46.103680"
    },
    {
      "arxiv_id": "2504.19933v1",
      "title": "Automated decision-making for dynamic task assignment at scale",
      "title_zh": "大规模动态任务分配的自动化决策系统",
      "authors": [
        "Riccardo Lo Bianco",
        "Willem van Jaarsveld",
        "Jeroen Middelhuis",
        "Luca Begnardi",
        "Remco Dijkman"
      ],
      "abstract": "The Dynamic Task Assignment Problem (DTAP) concerns matching resources to\ntasks in real time while minimizing some objectives, like resource costs or\ntask cycle time. In this work, we consider a DTAP variant where every task is a\ncase composed of a stochastic sequence of activities. The DTAP, in this case,\ninvolves the decision of which employee to assign to which activity to process\nrequests as quickly as possible. In recent years, Deep Reinforcement Learning\n(DRL) has emerged as a promising tool for tackling this DTAP variant, but most\nresearch is limited to solving small-scale, synthetic problems, neglecting the\nchallenges posed by real-world use cases. To bridge this gap, this work\nproposes a DRL-based Decision Support System (DSS) for real-world scale DTAPS.\nTo this end, we introduce a DRL agent with two novel elements: a graph\nstructure for observations and actions that can effectively represent any DTAP\nand a reward function that is provably equivalent to the objective of\nminimizing the average cycle time of tasks. The combination of these two\nnovelties allows the agent to learn effective and generalizable assignment\npolicies for real-world scale DTAPs. The proposed DSS is evaluated on five DTAP\ninstances whose parameters are extracted from real-world logs through process\nmining. The experimental evaluation shows how the proposed DRL agent matches or\noutperforms the best baseline in all DTAP instances and generalizes on\ndifferent time horizons and across instances.",
      "tldr_zh": "这篇论文针对动态任务分配问题 (DTAP)，提出了一种基于深度强化学习 (DRL) 的决策支持系统 (DSS)，用于实时匹配员工到随机序列的任务活动，以最小化平均任务周期时间。系统创新性地引入图结构来表示观察和行动，以及一个证明等价于优化目标的奖励函数 (reward function)，使代理能够学习高效且可泛化的分配策略。在五个从真实日志提取的DTAP实例上进行实验，该DRL代理的表现匹配或优于最佳基线，并在不同时间范围和实例间实现了良好泛化。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19933v1",
      "published_date": "2025-04-28 16:08:35 UTC",
      "updated_date": "2025-04-28 16:08:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:23:56.364355"
    },
    {
      "arxiv_id": "2504.19918v1",
      "title": "Enhancing Surgical Documentation through Multimodal Visual-Temporal Transformers and Generative AI",
      "title_zh": "通过多模态视觉-时间 Transformer 和生成式人工智能增强手术文档",
      "authors": [
        "Hugo Georgenthum",
        "Cristian Cosentino",
        "Fabrizio Marozzo",
        "Pietro Liò"
      ],
      "abstract": "The automatic summarization of surgical videos is essential for enhancing\nprocedural documentation, supporting surgical training, and facilitating\npost-operative analysis. This paper presents a novel method at the intersection\nof artificial intelligence and medicine, aiming to develop machine learning\nmodels with direct real-world applications in surgical contexts. We propose a\nmulti-modal framework that leverages recent advancements in computer vision and\nlarge language models to generate comprehensive video summaries. % The approach\nis structured in three key stages. First, surgical videos are divided into\nclips, and visual features are extracted at the frame level using visual\ntransformers. This step focuses on detecting tools, tissues, organs, and\nsurgical actions. Second, the extracted features are transformed into\nframe-level captions via large language models. These are then combined with\ntemporal features, captured using a ViViT-based encoder, to produce clip-level\nsummaries that reflect the broader context of each video segment. Finally, the\nclip-level descriptions are aggregated into a full surgical report using a\ndedicated LLM tailored for the summarization task. % We evaluate our method on\nthe CholecT50 dataset, using instrument and action annotations from 50\nlaparoscopic videos. The results show strong performance, achieving 96\\%\nprecision in tool detection and a BERT score of 0.74 for temporal context\nsummarization. This work contributes to the advancement of AI-assisted tools\nfor surgical reporting, offering a step toward more intelligent and reliable\nclinical documentation.",
      "tldr_zh": "该论文提出了一种多模态框架，利用 Multimodal Visual-Temporal Transformers 和 Generative AI 来自动总结手术视频，从而提升手术文档记录、训练和术后分析。方法分为三阶段：首先，使用视觉变换器提取视频帧级的视觉特征（如工具、组织和手术动作）；其次，将这些特征转化为帧级标题，并结合 ViViT-based 编码器的时间特征生成片段级摘要；最后，聚合这些描述使用专用的大型语言模型（LLMs）生成完整手术报告。在 CholecT50 数据集的评估中，该框架实现了96%的工具检测精度和0.74的BERT分数，展示了其在推进 AI 辅助临床文档方面的显著贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19918v1",
      "published_date": "2025-04-28 15:46:02 UTC",
      "updated_date": "2025-04-28 15:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:24:09.217083"
    },
    {
      "arxiv_id": "2504.19912v1",
      "title": "Can AI Agents Design and Implement Drug Discovery Pipelines?",
      "title_zh": "AI 代理能设计和实施药物发现管道吗？",
      "authors": [
        "Khachik Smbatyan",
        "Tsolak Ghukasyan",
        "Tigran Aghajanyan",
        "Hovhannes Dabaghyan",
        "Sergey Adamyan",
        "Aram Bughdaryan",
        "Vahagn Altunyan",
        "Gagik Navasardyan",
        "Aram Davtyan",
        "Anush Hakobyan",
        "Aram Gharibyan",
        "Arman Fahradyan",
        "Artur Hakobyan",
        "Hasmik Mnatsakanyan",
        "Narek Ginoyan",
        "Garik Petrosyan"
      ],
      "abstract": "The rapid advancement of artificial intelligence, particularly autonomous\nagentic systems based on Large Language Models (LLMs), presents new\nopportunities to accelerate drug discovery by improving in-silico modeling and\nreducing dependence on costly experimental trials. Current AI agent-based\nsystems demonstrate proficiency in solving programming challenges and\nconducting research, indicating an emerging potential to develop software\ncapable of addressing complex problems such as pharmaceutical design and drug\ndiscovery. This paper introduces DO Challenge, a benchmark designed to evaluate\nthe decision-making abilities of AI agents in a single, complex problem\nresembling virtual screening scenarios. The benchmark challenges systems to\nindependently develop, implement, and execute efficient strategies for\nidentifying promising molecular structures from extensive datasets, while\nnavigating chemical space, selecting models, and managing limited resources in\na multi-objective context. We also discuss insights from the DO Challenge 2025,\na competition based on the proposed benchmark, which showcased diverse\nstrategies explored by human participants. Furthermore, we present the Deep\nThought multi-agent system, which demonstrated strong performance on the\nbenchmark, outperforming most human teams. Among the language models tested,\nClaude 3.7 Sonnet, Gemini 2.5 Pro and o3 performed best in primary agent roles,\nand GPT-4o, Gemini 2.0 Flash were effective in auxiliary roles. While\npromising, the system's performance still fell short of expert-designed\nsolutions and showed high instability, highlighting both the potential and\ncurrent limitations of AI-driven methodologies in transforming drug discovery\nand broader scientific research.",
      "tldr_zh": "这篇论文探讨了基于 Large Language Models (LLMs) 的 AI 代理是否能设计和实施药物发现管道，以加速 in-silico 建模并减少昂贵实验依赖。论文提出 DO Challenge 基准，用于评估 AI 代理在复杂虚拟筛选场景中的决策能力，包括从大量数据集识别有前景分子结构、管理化学空间和资源。研究介绍了 Deep Thought 多代理系统，该系统在基准测试中超过了大多数人类团队，但性能仍低于专家方案，并表现出高不稳定性。最终，论文突显了 AI 代理在药物发现领域的潜力，同时强调了当前局限性，如模型稳定性问题。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19912v1",
      "published_date": "2025-04-28 15:41:28 UTC",
      "updated_date": "2025-04-28 15:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:24:21.841222"
    },
    {
      "arxiv_id": "2504.19901v1",
      "title": "Attention Mechanism, Max-Affine Partition, and Universal Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Hude Liu",
        "Jerry Yao-Chieh Hu",
        "Zhao Song",
        "Han Liu"
      ],
      "abstract": "We establish the universal approximation capability of single-layer,\nsingle-head self- and cross-attention mechanisms with minimal attached\nstructures. Our key insight is to interpret single-head attention as an input\ndomain-partition mechanism that assigns distinct values to subregions. This\nallows us to engineer the attention weights such that this assignment imitates\nthe target function. Building on this, we prove that a single self-attention\nlayer, preceded by sum-of-linear transformations, is capable of approximating\nany continuous function on a compact domain under the $L_\\infty$-norm.\nFurthermore, we extend this construction to approximate any Lebesgue integrable\nfunction under $L_p$-norm for $1\\leq p <\\infty$. Lastly, we also extend our\ntechniques and show that, for the first time, single-head cross-attention\nachieves the same universal approximation guarantees.",
      "tldr_zh": "本文研究了 attention mechanism 的通用逼近能力，证明单层单头 self-attention 和 cross-attention 机制，通过最小附加结构（如线性变换的求和），能够逼近任意函数。关键方法是将单头 attention 视为一种输入域分区机制（Max-Affine Partition），通过设计注意力权重来模拟目标函数，从而在紧致域上以 L∞-norm 逼近任何连续函数，并扩展到以 Lp-norm（1 ≤ p < ∞）逼近任何 Lebesgue integrable 函数。该工作首次展示了单头 cross-attention 也能实现相同的通用逼近保证，为深度学习模型的设计提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19901v1",
      "published_date": "2025-04-28 15:31:45 UTC",
      "updated_date": "2025-04-28 15:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:24:33.766507"
    },
    {
      "arxiv_id": "2504.19900v1",
      "title": "Breast Cancer Detection from Multi-View Screening Mammograms with Visual Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Han Chen",
        "Anne L. Martel"
      ],
      "abstract": "Accurate detection of breast cancer from high-resolution mammograms is\ncrucial for early diagnosis and effective treatment planning. Previous studies\nhave shown the potential of using single-view mammograms for breast cancer\ndetection. However, incorporating multi-view data can provide more\ncomprehensive insights. Multi-view classification, especially in medical\nimaging, presents unique challenges, particularly when dealing with\nlarge-scale, high-resolution data. In this work, we propose a novel Multi-view\nVisual Prompt Tuning Network (MVPT-NET) for analyzing multiple screening\nmammograms. We first pretrain a robust single-view classification model on\nhigh-resolution mammograms and then innovatively adapt multi-view feature\nlearning into a task-specific prompt tuning process. This technique selectively\ntunes a minimal set of trainable parameters (7\\%) while retaining the\nrobustness of the pre-trained single-view model, enabling efficient integration\nof multi-view data without the need for aggressive downsampling. Our approach\noffers an efficient alternative to traditional feature fusion methods,\nproviding a more robust, scalable, and efficient solution for high-resolution\nmammogram analysis. Experimental results on a large multi-institution dataset\ndemonstrate that our method outperforms conventional approaches while\nmaintaining detection efficiency, achieving an AUROC of 0.852 for\ndistinguishing between Benign, DCIS, and Invasive classes. This work highlights\nthe potential of MVPT-NET for medical imaging tasks and provides a scalable\nsolution for integrating multi-view data in breast cancer detection.",
      "tldr_zh": "本研究针对乳腺癌检测，提出了一种基于 Visual Prompt Tuning 的多视图筛查乳腺X光照片分析方法，以提升早期诊断的准确性。论文引入 MVPT-NET 模型，首先在高分辨率单视图乳腺X光照片上预训练分类模型，然后通过任务特定的提示调整过程整合多视图特征，仅调整少量参数（7%），从而避免传统特征融合的激进下采样并保持模型鲁棒性。该方法在大型多机构数据集上实验表明，其性能优于传统方法，AUROC 达到 0.852，用于区分良性、DCIS 和侵袭性癌症类别，并为医疗成像任务提供高效、可扩展的多视图数据整合解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19900v1",
      "published_date": "2025-04-28 15:31:08 UTC",
      "updated_date": "2025-04-28 15:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:24:45.208502"
    },
    {
      "arxiv_id": "2504.21045v1",
      "title": "Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection",
      "title_zh": "利用 LLM 加强基于机器学习的跨站脚本攻击检测",
      "authors": [
        "Dennis Miczek",
        "Divyesh Gabbireddy",
        "Suman Saha"
      ],
      "abstract": "According to the Open Web Application Security Project (OWASP), Cross-Site\nScripting (XSS) is a critical security vulnerability. Despite decades of\nresearch, XSS remains among the top 10 security vulnerabilities. Researchers\nhave proposed various techniques to protect systems from XSS attacks, with\nmachine learning (ML) being one of the most widely used methods. An ML model is\ntrained on a dataset to identify potential XSS threats, making its\neffectiveness highly dependent on the size and diversity of the training data.\nA variation of XSS is obfuscated XSS, where attackers apply obfuscation\ntechniques to alter the code's structure, making it challenging for security\nsystems to detect its malicious intent. Our study's random forest model was\ntrained on traditional (non-obfuscated) XSS data achieved 99.8% accuracy.\nHowever, when tested against obfuscated XSS samples, accuracy dropped to 81.9%,\nunderscoring the importance of training ML models with obfuscated data to\nimprove their effectiveness in detecting XSS attacks. A significant challenge\nis to generate highly complex obfuscated code despite the availability of\nseveral public tools. These tools can only produce obfuscation up to certain\nlevels of complexity.\n  In our proposed system, we fine-tune a Large Language Model (LLM) to generate\ncomplex obfuscated XSS payloads automatically. By transforming original XSS\nsamples into diverse obfuscated variants, we create challenging training data\nfor ML model evaluation. Our approach achieved a 99.5% accuracy rate with the\nobfuscated dataset. We also found that the obfuscated samples generated by the\nLLMs were 28.1% more complex than those created by other tools, significantly\nimproving the model's ability to handle advanced XSS attacks and making it more\neffective for real-world application security.",
      "tldr_zh": "本文研究了如何利用大型语言模型(LLM)来提升基于机器学习(ML)的跨站脚本攻击(Cross-Site Scripting, XSS)检测能力，特别是针对混淆XSS攻击的挑战。作者微调LLM自动生成复杂混淆XSS有效载荷，从而创建多样化的训练数据集，用于改进ML模型的训练。实验结果显示，使用这些数据训练的随机森林模型在混淆数据集上达到99.5%准确率，比传统方法提升约17.6%，并使生成的样本复杂度比其他工具高28.1%，显著增强了模型在真实世界应用中的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.21045v1",
      "published_date": "2025-04-28 15:22:31 UTC",
      "updated_date": "2025-04-28 15:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:24:58.019239"
    },
    {
      "arxiv_id": "2504.19874v1",
      "title": "TurboQuant: Online Vector Quantization with Near-optimal Distortion Rate",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Zandieh",
        "Majid Daliri",
        "Majid Hadian",
        "Vahab Mirrokni"
      ],
      "abstract": "Vector quantization, a problem rooted in Shannon's source coding theory, aims\nto quantize high-dimensional Euclidean vectors while minimizing distortion in\ntheir geometric structure. We propose TurboQuant to address both mean-squared\nerror (MSE) and inner product distortion, overcoming limitations of existing\nmethods that fail to achieve optimal distortion rates. Our data-oblivious\nalgorithms, suitable for online applications, achieve near-optimal distortion\nrates (within a small constant factor) across all bit-widths and dimensions.\nTurboQuant achieves this by randomly rotating input vectors, inducing a\nconcentrated Beta distribution on coordinates, and leveraging the\nnear-independence property of distinct coordinates in high dimensions to simply\napply optimal scalar quantizers per each coordinate. Recognizing that\nMSE-optimal quantizers introduce bias in inner product estimation, we propose a\ntwo-stage approach: applying an MSE quantizer followed by a 1-bit Quantized JL\n(QJL) transform on the residual, resulting in an unbiased inner product\nquantizer. We also provide a formal proof of the information-theoretic lower\nbounds on best achievable distortion rate by any vector quantizer,\ndemonstrating that TurboQuant closely matches these bounds, differing only by a\nsmall constant ($\\approx 2.7$) factor. Experimental results validate our\ntheoretical findings, showing that for KV cache quantization, we achieve\nabsolute quality neutrality with 3.5 bits per channel and marginal quality\ndegradation with 2.5 bits per channel. Furthermore, in nearest neighbor search\ntasks, our method outperforms existing product quantization techniques in\nrecall while reducing indexing time to virtually zero.",
      "tldr_zh": "该论文提出 TurboQuant，一种在线矢量量化（Vector Quantization）算法，旨在最小化高维欧式矢量的均方误差（MSE）和内积失真，同时实现近优化的失真率（仅差一个约2.7的常数因子）。TurboQuant 通过随机旋转输入矢量以诱导 Beta 分布，然后对每个坐标应用最优标量量化器，并采用两阶段方法（MSE 量化器加 1-bit Quantized JL (QJL) 变换）来消除内积估计偏差。实验结果显示，在 KV cache 量化任务中，TurboQuant 以 3.5 bits per channel 实现绝对质量中性，而 2.5 bits per channel 仅造成轻微退化；在最近邻搜索中，它超越现有产品量化技术，提高召回率并几乎消除索引时间。总的来说，该方法证明了其理论优越性，并为高效在线量化应用提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.19874v1",
      "published_date": "2025-04-28 15:05:35 UTC",
      "updated_date": "2025-04-28 15:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:25:10.826290"
    },
    {
      "arxiv_id": "2504.19863v1",
      "title": "Towards Ball Spin and Trajectory Analysis in Table Tennis Broadcast Videos via Physically Grounded Synthetic-to-Real Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Kienzle",
        "Robin Schön",
        "Rainer Lienhart",
        "Shin'Ichi Satoh"
      ],
      "abstract": "Analyzing a player's technique in table tennis requires knowledge of the\nball's 3D trajectory and spin. While, the spin is not directly observable in\nstandard broadcasting videos, we show that it can be inferred from the ball's\ntrajectory in the video. We present a novel method to infer the initial spin\nand 3D trajectory from the corresponding 2D trajectory in a video. Without\nground truth labels for broadcast videos, we train a neural network solely on\nsynthetic data. Due to the choice of our input data representation, physically\ncorrect synthetic training data, and using targeted augmentations, the network\nnaturally generalizes to real data. Notably, these simple techniques are\nsufficient to achieve generalization. No real data at all is required for\ntraining. To the best of our knowledge, we are the first to present a method\nfor spin and trajectory prediction in simple monocular broadcast videos,\nachieving an accuracy of 92.0% in spin classification and a 2D reprojection\nerror of 0.19% of the image diagonal.",
      "tldr_zh": "本论文提出了一种基于Physically Grounded Synthetic-to-Real Transfer的方法，用于从乒乓球广播视频中推断球的初始旋转和3D轨迹，该方法通过分析视频中的2D轨迹来间接获取旋转信息。研究者仅使用合成数据训练神经网络，并通过物理正确的输入表示和针对性增强，实现模型在真实数据上的自然泛化，而无需任何真实标签。实验结果显示，该方法在单目视频中实现了92.0%的旋转分类准确率和2D重投影错误的0.19%（图像对角线百分比），为乒乓球技术分析提供了高效工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in 2025 IEEE/CVF International Conference on Computer\n  Vision and Pattern Recognition Workshops (CVPRW)",
      "pdf_url": "http://arxiv.org/pdf/2504.19863v1",
      "published_date": "2025-04-28 14:55:12 UTC",
      "updated_date": "2025-04-28 14:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:25:22.833325"
    },
    {
      "arxiv_id": "2504.21044v1",
      "title": "AGATE: Stealthy Black-box Watermarking for Multimodal Model Copyright Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Jianbo Gao",
        "Keke Gai",
        "Jing Yu",
        "Liehuang Zhu",
        "Qi Wu"
      ],
      "abstract": "Recent advancement in large-scale Artificial Intelligence (AI) models\noffering multimodal services have become foundational in AI systems, making\nthem prime targets for model theft. Existing methods select Out-of-Distribution\n(OoD) data as backdoor watermarks and retrain the original model for copyright\nprotection. However, existing methods are susceptible to malicious detection\nand forgery by adversaries, resulting in watermark evasion. In this work, we\npropose Model-\\underline{ag}nostic Black-box Backdoor W\\underline{ate}rmarking\nFramework (AGATE) to address stealthiness and robustness challenges in\nmultimodal model copyright protection. Specifically, we propose an adversarial\ntrigger generation method to generate stealthy adversarial triggers from\nordinary dataset, providing visual fidelity while inducing semantic shifts. To\nalleviate the issue of anomaly detection among model outputs, we propose a\npost-transform module to correct the model output by narrowing the distance\nbetween adversarial trigger image embedding and text embedding. Subsequently, a\ntwo-phase watermark verification is proposed to judge whether the current model\ninfringes by comparing the two results with and without the transform module.\nConsequently, we consistently outperform state-of-the-art methods across five\ndatasets in the downstream tasks of multimodal image-text retrieval and image\nclassification. Additionally, we validated the robustness of AGATE under two\nadversarial attack scenarios.",
      "tldr_zh": "该研究提出AGATE，一种模型无关的黑盒后门水印框架，用于保护多模态模型的版权，解决现有方法易被检测和伪造的问题。具体而言，AGATE通过对抗触发器生成方法从普通数据集创建隐蔽的触发器，确保视觉保真度并诱导语义偏移，并引入后置转换模块（post-transform module）来修正模型输出，缩小图像嵌入和文本嵌入的距离，同时采用两阶段水印验证来判断侵权。实验结果显示，AGATE在五个数据集上的多模态图像-文本检索和图像分类任务中，优于最先进方法，并在两种对抗攻击场景下证明了其鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21044v1",
      "published_date": "2025-04-28 14:52:01 UTC",
      "updated_date": "2025-04-28 14:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:25:33.297221"
    },
    {
      "arxiv_id": "2504.19854v1",
      "title": "NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Chia-Yu Hung",
        "Qi Sun",
        "Pengfei Hong",
        "Amir Zadeh",
        "Chuan Li",
        "U-Xuan Tan",
        "Navonil Majumder",
        "Soujanya Poria"
      ],
      "abstract": "Existing Visual-Language-Action (VLA) models have shown promising performance\nin zero-shot scenarios, demonstrating impressive task execution and reasoning\ncapabilities. However, a significant challenge arises from the limitations of\nvisual encoding, which can result in failures during tasks such as object\ngrasping. Moreover, these models typically suffer from high computational\noverhead due to their large sizes, often exceeding 7B parameters. While these\nmodels excel in reasoning and task planning, the substantial computational\noverhead they incur makes them impractical for real-time robotic environments,\nwhere speed and efficiency are paramount. To address the limitations of\nexisting VLA models, we propose NORA, a 3B-parameter model designed to reduce\ncomputational overhead while maintaining strong task performance. NORA adopts\nthe Qwen-2.5-VL-3B multimodal model as its backbone, leveraging its superior\nvisual-semantic understanding to enhance visual reasoning and action grounding.\nAdditionally, our \\model{} is trained on 970k real-world robot demonstrations\nand equipped with the FAST+ tokenizer for efficient action sequence generation.\nExperimental results demonstrate that NORA outperforms existing large-scale VLA\nmodels, achieving better task performance with significantly reduced\ncomputational overhead, making it a more practical solution for real-time\nrobotic autonomy.",
      "tldr_zh": "该研究针对现有 Visual-Language-Action (VLA) 模型在零样本任务中存在的视觉编码缺陷和高计算开销问题，提出了一种小型开源通用模型 NORA，仅有 3B 参数。NORA 以 Qwen-2.5-VL-3B 多模态模型为基础，结合 97 万真实机器人演示数据训练，并采用 FAST+ tokenizer 来优化动作序列生成效率，从而提升视觉推理和任务执行性能。实验结果表明，NORA 在任务表现上超越了大型 VLA 模型，同时显著降低了计算开销，使其更适用于实时机器人自治场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19854v1",
      "published_date": "2025-04-28 14:47:34 UTC",
      "updated_date": "2025-04-28 14:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:25:46.736337"
    },
    {
      "arxiv_id": "2504.19848v1",
      "title": "Human-Centered AI and Autonomy in Robotics: Insights from a Bibliometric Study",
      "title_zh": "以人为中心的人工智能和机器人自治：来自计量文献学研究的洞见",
      "authors": [
        "Simona Casini",
        "Pietro Ducange",
        "Francesco Marcelloni",
        "Lorenzo Pollini"
      ],
      "abstract": "The development of autonomous robotic systems offers significant potential\nfor performing complex tasks with precision and consistency. Recent advances in\nArtificial Intelligence (AI) have enabled more capable intelligent automation\nsystems, addressing increasingly complex challenges. However, this progress\nraises questions about human roles in such systems. Human-Centered AI (HCAI)\naims to balance human control and automation, ensuring performance enhancement\nwhile maintaining creativity, mastery, and responsibility. For real-world\napplications, autonomous robots must balance task performance with reliability,\nsafety, and trustworthiness. Integrating HCAI principles enhances human-robot\ncollaboration and ensures responsible operation.\n  This paper presents a bibliometric analysis of intelligent autonomous robotic\nsystems, utilizing SciMAT and VOSViewer to examine data from the Scopus\ndatabase. The findings highlight academic trends, emerging topics, and AI's\nrole in self-adaptive robotic behaviour, with an emphasis on HCAI architecture.\nThese insights are then projected onto the IBM MAPE-K architecture, with the\ngoal of identifying how these research results map into actual robotic\nautonomous systems development efforts for real-world scenarios.",
      "tldr_zh": "这篇论文通过文献计量分析探讨了以人为中心的 AI (HCAI) 在机器人自治系统中的作用，强调了平衡人类控制与自动化以提升任务性能、可靠性和安全性的重要性。研究利用 SciMAT 和 VOSViewer 工具分析了 Scopus 数据库的数据，揭示了学术趋势、AI 在自适应机器人行为中的关键作用，以及对 HCAI 架构的关注。最终，将这些发现映射到 IBM MAPE-K 架构中，为真实场景下的机器人开发提供指导，促进负责任的人机协作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "International Joint Conference on Neural Network 2025 - Accepted",
      "pdf_url": "http://arxiv.org/pdf/2504.19848v1",
      "published_date": "2025-04-28 14:45:48 UTC",
      "updated_date": "2025-04-28 14:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:25:57.633545"
    },
    {
      "arxiv_id": "2504.19847v1",
      "title": "Foundation Model-Driven Framework for Human-Object Interaction Prediction with Segmentation Mask Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Juhan Park",
        "Kyungjae Lee",
        "Hyung Jin Chang",
        "Jungchan Cho"
      ],
      "abstract": "In this work, we introduce Segmentation to Human-Object Interaction\n(\\textit{\\textbf{Seg2HOI}}) approach, a novel framework that integrates\nsegmentation-based vision foundation models with the human-object interaction\ntask, distinguished from traditional detection-based Human-Object Interaction\n(HOI) methods. Our approach enhances HOI detection by not only predicting the\nstandard triplets but also introducing quadruplets, which extend HOI triplets\nby including segmentation masks for human-object pairs. More specifically,\nSeg2HOI inherits the properties of the vision foundation model (e.g.,\npromptable and interactive mechanisms) and incorporates a decoder that applies\nthese attributes to HOI task. Despite training only for HOI, without additional\ntraining mechanisms for these properties, the framework demonstrates that such\nfeatures still operate efficiently. Extensive experiments on two public\nbenchmark datasets demonstrate that Seg2HOI achieves performance comparable to\nstate-of-the-art methods, even in zero-shot scenarios. Lastly, we propose that\nSeg2HOI can generate HOI quadruplets and interactive HOI segmentation from\nnovel text and visual prompts that were not used during training, making it\nversatile for a wide range of applications by leveraging this flexibility.",
      "tldr_zh": "本研究提出了一种基于基础模型的框架Seg2HOI，用于人类-物体交互（HOI）预测，通过整合分割掩码，将传统的检测-based HOI方法扩展为预测标准三元组（triplets）及新引入的四元组（quadruplets），后者包括人类-物体对的分割信息。Seg2HOI继承了视觉基础模型的promptable和interactive机制，并通过一个解码器将其应用到HOI任务中，尽管仅针对HOI训练，这些属性仍能高效运行。在两个公共基准数据集上的广泛实验显示，该框架的性能与最先进方法相当，甚至在zero-shot场景中表现出色。最后，Seg2HOI能从训练中未见的新文本和视觉prompts生成HOI quadruplets和交互HOI segmentation，提升了其在各种应用中的灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19847v1",
      "published_date": "2025-04-28 14:45:26 UTC",
      "updated_date": "2025-04-28 14:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:26:11.602204"
    },
    {
      "arxiv_id": "2504.19822v1",
      "title": "Mjölnir: A Deep Learning Parametrization Framework for Global Lightning Flash Density",
      "title_zh": "翻译失败",
      "authors": [
        "Minjong Cheon"
      ],
      "abstract": "Recent advances in AI-based weather forecasting models, such as FourCastNet,\nPangu-Weather, and GraphCast, have demonstrated the remarkable ability of deep\nlearning to emulate complex atmospheric dynamics. Building on this momentum, we\npropose Mj\\\"olnir, a novel deep learning-based framework for global lightning\nflash density parameterization. Trained on ERA5 atmospheric predictors and\nWorld Wide Lightning Location Network (WWLLN) observations at a daily temporal\nresolution and 1 degree spatial resolution, Mj\\\"olnir captures the nonlinear\nmapping between large-scale environmental conditions and lightning activity.\nThe model architecture is based on the InceptionNeXt backbone with SENet, and a\nmulti-task learning strategy to simultaneously predict lightning occurrence and\nmagnitude. Extensive evaluations yield that Mollnir accurately reproduces the\nglobal distribution, seasonal variability, and regional characteristics of\nlightning activity, achieving a global Pearson correlation coefficient of 0.96\nfor annual mean fields. These results suggest that Mj\\\"olnir serves not only as\nan effective data-driven global lightning parameterization but also as a\npromising AI-based scheme for next-generation Earth system models (AI-ESMs).",
      "tldr_zh": "该研究提出Mjölnir，一个基于深度学习的框架，用于全球闪电闪密度参数化，旨在利用AI模拟复杂大气动态。模型采用InceptionNeXt主干网络和SENet相结合的多任务学习策略，训练于ERA5大气预测数据和WWLLN观测数据，以每日时间分辨率和1度空间分辨率捕捉环境条件与闪电活动间的非线性关系。评估结果显示，Mjölnir准确再现了全球闪电分布、季节变异性和区域特征，年度平均字段的Pearson相关系数达0.96，并为下一代地球系统模型(AI-ESMs)提供了一个有前景的数据驱动方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19822v1",
      "published_date": "2025-04-28 14:22:59 UTC",
      "updated_date": "2025-04-28 14:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:26:21.708561"
    },
    {
      "arxiv_id": "2504.19818v1",
      "title": "PhenoAssistant: A Conversational Multi-Agent AI System for Automated Plant Phenotyping",
      "title_zh": "PhenoAssistant: 用于自动植物表型分析的对话式多智能体 AI 系统",
      "authors": [
        "Feng Chen",
        "Ilias Stogiannidis",
        "Andrew Wood",
        "Danilo Bueno",
        "Dominic Williams",
        "Fraser Macfarlane",
        "Bruce Grieve",
        "Darren Wells",
        "Jonathan A. Atkinson",
        "Malcolm J. Hawkesford",
        "Stephen A. Rolfe",
        "Tracy Lawson",
        "Tony Pridmore",
        "Mario Valerio Giuffrida",
        "Sotirios A. Tsaftaris"
      ],
      "abstract": "Plant phenotyping increasingly relies on (semi-)automated image-based\nanalysis workflows to improve its accuracy and scalability. However, many\nexisting solutions remain overly complex, difficult to reimplement and\nmaintain, and pose high barriers for users without substantial computational\nexpertise. To address these challenges, we introduce PhenoAssistant: a\npioneering AI-driven system that streamlines plant phenotyping via intuitive\nnatural language interaction. PhenoAssistant leverages a large language model\nto orchestrate a curated toolkit supporting tasks including automated phenotype\nextraction, data visualisation and automated model training. We validate\nPhenoAssistant through several representative case studies and a set of\nevaluation tasks. By significantly lowering technical hurdles, PhenoAssistant\nunderscores the promise of AI-driven methodologies to democratising AI adoption\nin plant biology.",
      "tldr_zh": "该研究介绍了PhenoAssistant，一种基于对话式多智能体AI系统的创新解决方案，旨在简化植物表型分析（Plant phenotyping）的自动化流程。系统利用大型语言模型（Large Language Model）协调工具包，支持通过直观的自然语言交互进行自动表型提取、数据可视化和模型训练，从而降低了对计算专业知识的要求。通过案例研究和评估任务验证，PhenoAssistant显著降低了技术障碍，推动AI在植物生物学中的普及和民主化。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19818v1",
      "published_date": "2025-04-28 14:20:30 UTC",
      "updated_date": "2025-04-28 14:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:26:32.657063"
    },
    {
      "arxiv_id": "2504.21043v2",
      "title": "CodeBC: A More Secure Large Language Model for Smart Contract Code Generation in Blockchain",
      "title_zh": "翻译失败",
      "authors": [
        "Lingxiang Wang",
        "Hainan Zhang",
        "Qinnan Zhang",
        "Ziwei Wang",
        "Hongwei Zheng",
        "Jin Dong",
        "Zhiming Zheng"
      ],
      "abstract": "Large language models (LLMs) excel at generating code from natural language\ninstructions, yet they often lack an understanding of security vulnerabilities.\nThis limitation makes it difficult for LLMs to avoid security risks in\ngenerated code, particularly in high-security programming tasks such as smart\ncontract development for blockchain. Researchers have attempted to enhance the\nvulnerability awareness of these models by training them to differentiate\nbetween vulnerable and fixed code snippets. However, this approach relies\nheavily on manually labeled vulnerability data, which is only available for\npopular languages like Python and C++. For low-resource languages like\nSolidity, used in smart contracts, large-scale annotated datasets are scarce\nand difficult to obtain. To address this challenge, we introduce CodeBC, a code\ngeneration model specifically designed for generating secure smart contracts in\nblockchain. CodeBC employs a three-stage fine-tuning approach based on\nCodeLlama, distinguishing itself from previous methods by not relying on\npairwise vulnerability location annotations. Instead, it leverages\nvulnerability and security tags to teach the model the differences between\nvulnerable and secure code. During the inference phase, the model leverages\nsecurity tags to generate secure and robust code. Experimental results\ndemonstrate that CodeBC outperforms baseline models in terms of BLEU, CodeBLEU,\nand compilation pass rates, while significantly reducing vulnerability rates.\nThese findings validate the effectiveness and cost-efficiency of our\nthree-stage fine-tuning strategy, making CodeBC a promising solution for\ngenerating secure smart contract code.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在生成智能合约代码时存在的安全漏洞问题，提出了一种新型模型CodeBC，专注于区块链领域的安全代码生成。CodeBC基于CodeLlama的三阶段微调方法，使用漏洞和安全标签来区分不安全与安全代码，从而避免依赖手动标注数据，尤其适用于低资源语言如Solidity。实验结果显示，CodeBC在BLEU、CodeBLEU和编译通过率指标上优于基线模型，并显著降低了漏洞率，验证了该策略的有效性和成本效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21043v2",
      "published_date": "2025-04-28 14:14:16 UTC",
      "updated_date": "2025-05-07 02:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:26:46.282815"
    },
    {
      "arxiv_id": "2504.19792v1",
      "title": "Contextures: The Mechanism of Representation Learning",
      "title_zh": "Contextures: 表示学习的机制",
      "authors": [
        "Runtian Zhai"
      ],
      "abstract": "This dissertation establishes the contexture theory to mathematically\ncharacterize the mechanism of representation learning, or pretraining. Despite\nthe remarkable empirical success of foundation models, it is not very clear\nwhat representations they learn, and why these representations are useful for\nvarious downstream tasks. A scientific understanding of representation learning\nis critical, especially at this point when scaling up the model size is\nproducing diminishing returns, and designing new pretraining methods is\nimperative for further progress.\n  Prior work treated different representation learning methods quite\ndifferently, whereas the contexture theory provides a unified framework for\nanalyzing these methods. The central argument is that a representation is\nlearned from the association between the input X and a context variable A. We\nprove that if an encoder captures the maximum information of this association,\nin which case we say that the encoder learns the contexture, then it will be\noptimal on the class of tasks that are compatible with the context. We also\nshow that a context is the most useful when the association between X and A is\nneither too strong nor too weak. The important implication of the contexture\ntheory is that increasing the model size alone will achieve diminishing\nreturns, and further advancements require better contexts.\n  We demonstrate that many pretraining objectives can learn the contexture,\nincluding supervised learning, self-supervised learning, generative models,\netc. Then, we introduce two general objectives -- SVME and KISE, for learning\nthe contexture. We also show how to mix multiple contexts together, an\neffortless way to create better contexts from existing ones. Then, we prove\nstatistical learning bounds for representation learning. Finally, we discuss\nthe effect of the data distribution shift from pretraining to the downstream\ntask.",
      "tldr_zh": "该论文提出contexture理论，以数学方式阐释表示学习（representation learning）或预训练（pretraining）的机制，旨在统一分析各种学习方法并解释为什么这些表示对下游任务有益。核心观点是，表示学习源于输入X与上下文变量A的关联，当编码器最大化捕获此关联（即学习contexture）时，它将在兼容任务上达到最优，且上下文关联强度适中时效果最佳。论文证明单纯增加模型规模将导致收益递减，并引入通用目标SVME和KISE，以及上下文混合方法，以提升表示学习；同时，提供统计学习边界并讨论数据分布转移的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "PhD Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2504.19792v1",
      "published_date": "2025-04-28 13:36:28 UTC",
      "updated_date": "2025-04-28 13:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:26:58.529315"
    },
    {
      "arxiv_id": "2504.20125v1",
      "title": "Towards Large Language Models for Lunar Mission Planning and In Situ Resource Utilization",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pekala",
        "Gregory Canal",
        "Samuel Barham",
        "Milena B. Graziano",
        "Morgan Trexler",
        "Leslie Hamilton",
        "Elizabeth Reilly",
        "Christopher D. Stiles"
      ],
      "abstract": "A key factor for lunar mission planning is the ability to assess the local\navailability of raw materials. However, many potentially relevant measurements\nare scattered across a variety of scientific publications. In this paper we\nconsider the viability of obtaining lunar composition data by leveraging LLMs\nto rapidly process a corpus of scientific publications. While leveraging LLMs\nto obtain knowledge from scientific documents is not new, this particular\napplication presents interesting challenges due to the heterogeneity of lunar\nsamples and the nuances involved in their characterization. Accuracy and\nuncertainty quantification are particularly crucial since many materials\nproperties can be sensitive to small variations in composition. Our findings\nindicate that off-the-shelf LLMs are generally effective at extracting data\nfrom tables commonly found in these documents. However, there remains\nopportunity to further refine the data we extract in this initial approach; in\nparticular, to capture fine-grained mineralogy information and to improve\nperformance on more subtle/complex pieces of information.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型(LLMs)来处理科学出版物，从而快速获取月球成分数据，以支持月球任务规划和原地资源利用(In Situ Resource Utilization)。研究强调了月球样本的异质性及其特征化细微差别带来的挑战，特别是对准确性和不确定性量化的需求，因为材料属性对微小组成变化高度敏感。结果显示，现成的LLMs在从这些文档的表格中提取数据方面表现出色，但仍需改进以更好地捕获细粒度的矿物学信息和处理更微妙复杂的细节。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20125v1",
      "published_date": "2025-04-28 13:33:37 UTC",
      "updated_date": "2025-04-28 13:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:27:09.797221"
    },
    {
      "arxiv_id": "2504.21042v2",
      "title": "What's Pulling the Strings? Evaluating Integrity and Attribution in AI Training and Inference through Concept Shift",
      "title_zh": "翻译失败",
      "authors": [
        "Jiamin Chang",
        "Haoyang Li",
        "Hammond Pearce",
        "Ruoxi Sun",
        "Bo Li",
        "Minhui Xue"
      ],
      "abstract": "The growing adoption of artificial intelligence (AI) has amplified concerns\nabout trustworthiness, including integrity, privacy, robustness, and bias. To\nassess and attribute these threats, we propose ConceptLens, a generic framework\nthat leverages pre-trained multimodal models to identify the root causes of\nintegrity threats by analyzing Concept Shift in probing samples. ConceptLens\ndemonstrates strong detection performance for vanilla data poisoning attacks\nand uncovers vulnerabilities to bias injection, such as the generation of\ncovert advertisements through malicious concept shifts. It identifies privacy\nrisks in unaltered but high-risk samples, filters them before training, and\nprovides insights into model weaknesses arising from incomplete or imbalanced\ntraining data. Additionally, at the model level, it attributes concepts that\nthe target model is overly dependent on, identifies misleading concepts, and\nexplains how disrupting key concepts negatively impacts the model. Furthermore,\nit uncovers sociological biases in generative content, revealing disparities\nacross sociological contexts. Strikingly, ConceptLens reveals how safe training\nand inference data can be unintentionally and easily exploited, potentially\nundermining safety alignment. Our study informs actionable insights to breed\ntrust in AI systems, thereby speeding adoption and driving greater innovation.",
      "tldr_zh": "该研究提出ConceptLens框架，利用预训练多模态模型分析Concept Shift，以评估AI系统在训练和推理过程中的完整性、隐私、鲁棒性和偏见问题。框架通过识别概念偏移的根因，能有效检测数据中毒攻击、偏见注入（如生成隐蔽广告）和隐私风险，并过滤高风险样本，同时揭示模型对特定概念的过度依赖和社会偏见。实验结果显示，ConceptLens显著提升了AI系统的可信度，提供可操作见解，帮助防范潜在威胁并推动AI创新和采用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to The ACM Conference on Computer and Communications\n  Security (CCS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21042v2",
      "published_date": "2025-04-28 13:30:48 UTC",
      "updated_date": "2025-05-17 04:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:27:20.963421"
    },
    {
      "arxiv_id": "2505.05486v1",
      "title": "FedAvgen: Metadata for Model Aggregation In Communication Systems",
      "title_zh": "FedAvgen：通信系统中的模型聚合元数据",
      "authors": [
        "Anthony Kiggundu",
        "Dennis Krummacker",
        "Hans D. Schotten"
      ],
      "abstract": "To improve business efficiency and minimize costs, Artificial Intelligence\n(AI) practitioners have adopted a shift from formulating models from scratch\ntowards sharing pretrained models. The pretrained models are then aggregated\ninto a global model with higher generalization capabilities, which is\nafterwards distributed to the client devices. This approach is known as\nfederated learning and inherently utilizes different techniques to select the\ncandidate client models averaged to obtain the global model. This approach, in\nthe case of communication systems, faces challenges arising from the\nexistential diversity in device profiles. The multiplicity in profiles\nmotivates our conceptual assessment of a metaheuristic algorithm (FedAvgen),\nwhich relates each pretrained model with its weight space as metadata, to a\nphenotype and genotype, respectively. This parent-child genetic evolution\ncharacterizes the global averaging step in federated learning. We then compare\nthe results of our approach to two widely adopted baseline federated learning\nalgorithms like Federated Averaging (FedAvg) and Federated Stochastic Gradient\nDescent (FedSGD).",
      "tldr_zh": "该研究针对通信系统中联邦学习（Federated Learning）面临的设备配置文件多样性挑战，提出了一种元启发式算法（Metaheuristic Algorithm）FedAvgen，用于模型聚合。FedAvgen 将每个预训练模型的权重空间（Weight Space）作为元数据，与 phenotype 和 genotype 关联，模拟父子遗传演化过程来优化全局模型。实验结果显示，该方法与传统算法 Federated Averaging (FedAvg) 和 Federated Stochastic Gradient Descent (FedSGD) 相比，在提高模型泛化能力方面表现出潜在优势。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted in IEEE NetSoft 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05486v1",
      "published_date": "2025-04-28 13:11:32 UTC",
      "updated_date": "2025-04-28 13:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:27:33.366124"
    },
    {
      "arxiv_id": "2504.19755v1",
      "title": "Hybrid Approach Combining Ultrasound and Blood Test Analysis with a Voting Classifier for Accurate Liver Fibrosis and Cirrhosis Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Kapil Kashyap",
        "Sean Fargose",
        "Chrisil Dabre",
        "Fatema Dolaria",
        "Nilesh Patil",
        "Aniket Kore"
      ],
      "abstract": "Liver cirrhosis is an insidious condition involving the substitution of\nnormal liver tissue with fibrous scar tissue and causing major health\ncomplications. The conventional method of diagnosis using liver biopsy is\ninvasive and, therefore, inconvenient for use in regular screening. In this\npaper,we present a hybrid model that combines machine learning techniques with\nclinical data and ultrasoundscans to improve liver fibrosis and cirrhosis\ndetection accuracy is presented. The model integrates fixed blood test\nprobabilities with deep learning model predictions (DenseNet-201) for\nultrasonic images. The combined hybrid model achieved an accuracy of 92.5%. The\nfindings establish the viability of the combined model in enhancing diagnosis\naccuracy and supporting early intervention in liver disease care.",
      "tldr_zh": "这篇论文提出了一种混合方法，用于准确评估肝纤维化(Liver Fibrosis)和肝硬化(Cirrhosis)，通过结合超声扫描(Ultrasound)和血检分析(Blood Test)。该方法整合了固定血检概率与DenseNet-201深度学习模型对超声图像的预测，并采用投票分类器(Voting Classifier)进行决策融合。实验结果显示，该模型的准确率达到92.5%，证明了其在提升诊断准确性和支持肝病早期干预方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19755v1",
      "published_date": "2025-04-28 12:54:51 UTC",
      "updated_date": "2025-04-28 12:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:27:45.629340"
    },
    {
      "arxiv_id": "2504.20124v1",
      "title": "Pediatric Asthma Detection with Googles HeAR Model: An AI-Driven Respiratory Sound Classifier",
      "title_zh": "使用 Google 的 HeAR 模型的儿科哮喘检测：一个 AI ",
      "authors": [
        "Abul Ehtesham",
        "Saket Kumar",
        "Aditi Singh",
        "Tala Talaei Khoei"
      ],
      "abstract": "Early detection of asthma in children is crucial to prevent long-term\nrespiratory complications and reduce emergency interventions. This work\npresents an AI-powered diagnostic pipeline that leverages Googles Health\nAcoustic Representations (HeAR) model to detect early signs of asthma from\npediatric respiratory sounds. The SPRSound dataset, the first open-access\ncollection of annotated respiratory sounds in children aged 1 month to 18\nyears, is used to extract 2-second audio segments labeled as wheeze, crackle,\nrhonchi, stridor, or normal. Each segment is embedded into a 512-dimensional\nrepresentation using HeAR, a foundation model pretrained on 300 million\nhealth-related audio clips, including 100 million cough sounds. Multiple\nclassifiers, including SVM, Random Forest, and MLP, are trained on these\nembeddings to distinguish between asthma-indicative and normal sounds. The\nsystem achieves over 91\\% accuracy, with strong performance on precision-recall\nmetrics for positive cases. In addition to classification, learned embeddings\nare visualized using PCA, misclassifications are analyzed through waveform\nplayback, and ROC and confusion matrix insights are provided. This method\ndemonstrates that short, low-resource pediatric recordings, when powered by\nfoundation audio models, can enable fast, noninvasive asthma screening. The\napproach is especially promising for digital diagnostics in remote or\nunderserved healthcare settings.",
      "tldr_zh": "本文提出了一种基于 Google HeAR 模型的 AI 驱动系统，用于从儿童呼吸音中检测哮喘早期迹象，旨在预防长期呼吸并发症。该系统利用 SPRSound 数据集（首个公开的儿童呼吸音集合）提取 2 秒音频段，并通过 HeAR（预训练于 3 亿健康音频）的 512 维嵌入，训练 SVM、Random Forest 和 MLP 等分类器，实现对 wheeze、crackle、rhonchi、stridor 和 normal 声音的区分。实验结果显示，系统准确率超过 91%，并在精确率-召回率指标上表现出色，通过 PCA 可视化、ROC 分析和混淆矩阵进一步验证了其可靠性。此方法证明了短音频结合基础模型的可行性，为偏远或 underserved 地区的快速、非侵入性哮喘筛查提供新途径。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20124v1",
      "published_date": "2025-04-28 12:52:17 UTC",
      "updated_date": "2025-04-28 12:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:27:58.297608"
    },
    {
      "arxiv_id": "2504.19754v1",
      "title": "Reconstructing Context: Evaluating Advanced Chunking Strategies for Retrieval-Augmented Generation",
      "title_zh": "重建上下文：评估检索增强生成的高级分块策略",
      "authors": [
        "Carlo Merola",
        "Jaspinder Singh"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has become a transformative approach for\nenhancing large language models (LLMs) by grounding their outputs in external\nknowledge sources. Yet, a critical question persists: how can vast volumes of\nexternal knowledge be managed effectively within the input constraints of LLMs?\nTraditional methods address this by chunking external documents into smaller,\nfixed-size segments. While this approach alleviates input limitations, it often\nfragments context, resulting in incomplete retrieval and diminished coherence\nin generation. To overcome these shortcomings, two advanced techniques, late\nchunking and contextual retrieval, have been introduced, both aiming to\npreserve global context. Despite their potential, their comparative strengths\nand limitations remain unclear. This study presents a rigorous analysis of late\nchunking and contextual retrieval, evaluating their effectiveness and\nefficiency in optimizing RAG systems. Our results indicate that contextual\nretrieval preserves semantic coherence more effectively but requires greater\ncomputational resources. In contrast, late chunking offers higher efficiency\nbut tends to sacrifice relevance and completeness.",
      "tldr_zh": "这篇论文评估了先进的 chunking 策略，以优化 Retrieval-Augmented Generation (RAG) 系统在处理大型语言模型 (LLMs) 输入限制时的外部知识管理。研究重点比较了 late chunking 和 contextual retrieval 两种技术，前者通过后期分块提高效率，但可能导致上下文相关性和完整性降低。结果表明，contextual retrieval 更有效地保留语义连贯性，尽管它需要更多计算资源，从而为 RAG 系统的改进提供了重要见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages, 2 figures, Second Workshop on Knowledge-Enhanced\n  Information Retrieval, ECIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19754v1",
      "published_date": "2025-04-28 12:52:05 UTC",
      "updated_date": "2025-04-28 12:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:28:10.129478"
    },
    {
      "arxiv_id": "2504.19738v1",
      "title": "Learning Efficiency Meets Symmetry Breaking",
      "title_zh": "翻译失败",
      "authors": [
        "Yingbin Bai",
        "Sylvie Thiebaux",
        "Felipe Trevizan"
      ],
      "abstract": "Learning-based planners leveraging Graph Neural Networks can learn search\nguidance applicable to large search spaces, yet their potential to address\nsymmetries remains largely unexplored. In this paper, we introduce a graph\nrepresentation of planning problems allying learning efficiency with the\nability to detect symmetries, along with two pruning methods, action pruning\nand state pruning, designed to manage symmetries during search. The integration\nof these techniques into Fast Downward achieves a first-time success over LAMA\non the latest IPC learning track dataset. Code is released at:\nhttps://github.com/bybeye/Distincter.",
      "tldr_zh": "这篇论文引入了一种图表示方法，将 Graph Neural Networks (GNNs) 的学习效率与对称性检测相结合，用于处理规划问题中的搜索空间。论文提出两种修剪技术——action pruning 和 state pruning，以在搜索过程中有效管理对称性。这些方法整合到 Fast Downward 系统后，在 IPC learning track 数据集上首次超过了 LAMA 基准的性能。代码已开源，地址为 https://github.com/bybeye/Distincter。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19738v1",
      "published_date": "2025-04-28 12:33:39 UTC",
      "updated_date": "2025-04-28 12:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:28:20.706974"
    },
    {
      "arxiv_id": "2504.19720v1",
      "title": "Taming the Titans: A Survey of Efficient LLM Inference Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Ranran Zhen",
        "Juntao Li",
        "Yixin Ji",
        "Zhenlin Yang",
        "Tong Liu",
        "Qingrong Xia",
        "Xinyu Duan",
        "Zhefeng Wang",
        "Baoxing Huai",
        "Min Zhang"
      ],
      "abstract": "Large Language Models (LLMs) for Generative AI have achieved remarkable\nprogress, evolving into sophisticated and versatile tools widely adopted across\nvarious domains and applications. However, the substantial memory overhead\ncaused by their vast number of parameters, combined with the high computational\ndemands of the attention mechanism, poses significant challenges in achieving\nlow latency and high throughput for LLM inference services. Recent\nadvancements, driven by groundbreaking research, have significantly accelerated\nprogress in this field. This paper provides a comprehensive survey of these\nmethods, covering fundamental instance-level approaches, in-depth cluster-level\nstrategies, emerging scenario directions, and other miscellaneous but important\nareas. At the instance level, we review model placement, request scheduling,\ndecoding length prediction, storage management, and the disaggregation\nparadigm. At the cluster level, we explore GPU cluster deployment,\nmulti-instance load balancing, and cloud service solutions. For emerging\nscenarios, we organize the discussion around specific tasks, modules, and\nauxiliary methods. To ensure a holistic overview, we also highlight several\nniche yet critical areas. Finally, we outline potential research directions to\nfurther advance the field of LLM inference serving.",
      "tldr_zh": "这篇论文对高效的大型语言模型(LLMs)推理服务的优化方法进行了全面调查，旨在解决LLMs的巨大参数内存开销和注意力机制计算需求带来的延迟和吞吐量挑战。调查涵盖了实例级策略（如模型放置、请求调度、解码长度预测和存储管理）、集群级方法（如GPU集群部署、多实例负载平衡和云服务解决方案），以及新兴场景和辅助领域。最终，该研究总结了这些进展的显著效果，并提出了未来LLM推理服务的潜在研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress;11 pages of main paper with 7 main figures, overall\n  20 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.19720v1",
      "published_date": "2025-04-28 12:14:02 UTC",
      "updated_date": "2025-04-28 12:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:28:33.776225"
    },
    {
      "arxiv_id": "2504.19715v1",
      "title": "Model-based controller assisted domain randomization in deep reinforcement learning: application to nonlinear powertrain control",
      "title_zh": "基于模型控制器辅助的域随机化在深度强化学习中：应用于非",
      "authors": [
        "Heisei Yonezawa",
        "Ansei Yonezawa",
        "Itsuro Kajiwara"
      ],
      "abstract": "Complex mechanical systems such as vehicle powertrains are inherently subject\nto multiple nonlinearities and uncertainties arising from parametric\nvariations. Modeling and calibration errors are therefore unavoidable, making\nthe transfer of control systems from simulation to real-world systems a\ncritical challenge. Traditional robust controls have limitations in handling\ncertain types of nonlinearities and uncertainties, requiring a more practical\napproach capable of comprehensively compensating for these various constraints.\nThis study proposes a new robust control approach using the framework of deep\nreinforcement learning (DRL). The key strategy lies in the synergy among domain\nrandomization-based DRL, long short-term memory (LSTM)-based actor and critic\nnetworks, and model-based control (MBC). The problem setup is modeled via the\nlatent Markov decision process (LMDP), a set of vanilla MDPs, for a controlled\nsystem subject to uncertainties and nonlinearities. In LMDP, the dynamics of an\nenvironment simulator is randomized during training to improve the robustness\nof the control system to real testing environments. The randomization increases\ntraining difficulties as well as conservativeness of the resultant control\nsystem; therefore, progress is assisted by concurrent use of a model-based\ncontroller based on a nominal system model. Compared to traditional DRL-based\ncontrols, the proposed controller design is smarter in that we can achieve a\nhigh level of generalization ability with a more compact neural network\narchitecture and a smaller amount of training data. The proposed approach is\nverified via practical application to active damping for a complex powertrain\nsystem with nonlinearities and parametric variations. Comparative tests\ndemonstrate the high robustness of the proposed approach.",
      "tldr_zh": "本研究针对车辆动力系统等复杂机械系统的非线性性和不确定性，提出了一种结合 domain randomization-based deep reinforcement learning (DRL) 和 model-based control (MBC) 的鲁棒控制方法。\n该方法通过 latent Markov decision process (LMDP) 框架和 LSTM-based actor 与 critic 网络，在训练中随机化环境模拟器以提升控制系统的泛化能力，同时利用 MBC 辅助减少训练难度和保守性。\n相比传统 DRL 控制，新方法使用更紧凑的神经网络架构和更少的数据，实现了更高的鲁棒性。\n实验在复杂动力系统的主动阻尼控制应用中验证了其有效性，展示了显著的鲁棒性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19715v1",
      "published_date": "2025-04-28 12:09:07 UTC",
      "updated_date": "2025-04-28 12:09:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:28:47.462363"
    },
    {
      "arxiv_id": "2504.19678v1",
      "title": "From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review",
      "title_zh": "从 LLM 推理到自主 AI 代理：一个全面综述",
      "authors": [
        "Mohamed Amine Ferrag",
        "Norbert Tihanyi",
        "Merouane Debbah"
      ],
      "abstract": "Large language models and autonomous AI agents have evolved rapidly,\nresulting in a diverse array of evaluation benchmarks, frameworks, and\ncollaboration protocols. However, the landscape remains fragmented and lacks a\nunified taxonomy or comprehensive survey. Therefore, we present a side-by-side\ncomparison of benchmarks developed between 2019 and 2025 that evaluate these\nmodels and agents across multiple domains. In addition, we propose a taxonomy\nof approximately 60 benchmarks that cover general and academic knowledge\nreasoning, mathematical problem-solving, code generation and software\nengineering, factual grounding and retrieval, domain-specific evaluations,\nmultimodal and embodied tasks, task orchestration, and interactive assessments.\nFurthermore, we review AI-agent frameworks introduced between 2023 and 2025\nthat integrate large language models with modular toolkits to enable autonomous\ndecision-making and multi-step reasoning. Moreover, we present real-world\napplications of autonomous AI agents in materials science, biomedical research,\nacademic ideation, software engineering, synthetic data generation, chemical\nreasoning, mathematical problem-solving, geographic information systems,\nmultimedia, healthcare, and finance. We then survey key agent-to-agent\ncollaboration protocols, namely the Agent Communication Protocol (ACP), the\nModel Context Protocol (MCP), and the Agent-to-Agent Protocol (A2A). Finally,\nwe discuss recommendations for future research, focusing on advanced reasoning\nstrategies, failure modes in multi-agent LLM systems, automated scientific\ndiscovery, dynamic tool integration via reinforcement learning, integrated\nsearch capabilities, and security vulnerabilities in agent protocols.",
      "tldr_zh": "这篇论文对大型语言模型(LLM)推理到自主 AI 代理的发展进行全面综述，填补了现有基准和框架的碎片化问题。作者比较了2019-2025年间约60个评估基准，并提出一个分类体系，涵盖一般知识推理、数学问题解决、代码生成、多模态任务等领域。论文审阅了2023-2025年的AI代理框架，这些框架通过整合LLM和模块化工具包实现自主决策和多步推理，并展示了其在材料科学、生物医学、金融等领域的实际应用。最终，它调查了代理间协作协议如Agent Communication Protocol(ACP)和Agent-to-Agent Protocol(A2A)，并推荐未来研究重点，包括高级推理策略、多代理系统失败模式和安全漏洞。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19678v1",
      "published_date": "2025-04-28 11:08:22 UTC",
      "updated_date": "2025-04-28 11:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:28:58.290792"
    },
    {
      "arxiv_id": "2504.19675v1",
      "title": "Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Osma Suominen",
        "Juho Inkinen",
        "Mona Lehtinen"
      ],
      "abstract": "This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects),\nwhich focussed on subject indexing using large language models (LLMs). The task\nrequired creating subject predictions for bibliographic records from the\nbilingual TIBKAT database using the GND subject vocabulary. Our approach\ncombines traditional natural language processing and machine learning\ntechniques implemented in the Annif toolkit with innovative LLM-based methods\nfor translation and synthetic data generation, and merging predictions from\nmonolingual models. The system ranked first in the all-subjects category and\nsecond in the tib-core-subjects category in the quantitative evaluation, and\nfourth in qualitative evaluations. These findings demonstrate the potential of\ncombining traditional XMTC algorithms with modern LLM techniques to improve the\naccuracy and efficiency of subject indexing in multilingual contexts.",
      "tldr_zh": "本论文介绍了 Annif 系统在 SemEval-2025 Task 5 中的表现，该任务聚焦于使用 LLMs 进行主题索引，针对双语 TIBKAT 数据库的书目记录生成 GND 主题词汇预测。系统结合了传统自然语言处理和机器学习技术（包括 XMTC 算法）与创新的 LLM-based 方法，如翻译、合成数据生成以及单语模型预测合并。实验结果显示，Annif 在 all-subjects 类别排名第一，在 tib-core-subjects 类别排名第二，并在定性评估中排名第四。这些发现证明了传统 XMTC 与现代 LLMs 技术的融合，能够显著提高多语境主题索引的准确性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures, submitted to SemEval-2025 workshop Task 5:\n  LLMs4Subjects",
      "pdf_url": "http://arxiv.org/pdf/2504.19675v1",
      "published_date": "2025-04-28 11:04:23 UTC",
      "updated_date": "2025-04-28 11:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:29:10.946972"
    },
    {
      "arxiv_id": "2504.19674v1",
      "title": "$\\texttt{SAGE}$: A Generic Framework for LLM Safety Evaluation",
      "title_zh": "SAGE：大语言模型安全评估的通用框架",
      "authors": [
        "Madhur Jindal",
        "Hari Shrawgi",
        "Parag Agrawal",
        "Sandipan Dandapat"
      ],
      "abstract": "Safety evaluation of Large Language Models (LLMs) has made progress and\nattracted academic interest, but it remains challenging to keep pace with the\nrapid integration of LLMs across diverse applications. Different applications\nexpose users to various harms, necessitating application-specific safety\nevaluations with tailored harms and policies. Another major gap is the lack of\nfocus on the dynamic and conversational nature of LLM systems. Such potential\noversights can lead to harms that go unnoticed in standard safety benchmarks.\nThis paper identifies the above as key requirements for robust LLM safety\nevaluation and recognizing that current evaluation methodologies do not satisfy\nthese, we introduce the $\\texttt{SAGE}$ (Safety AI Generic Evaluation)\nframework. $\\texttt{SAGE}$ is an automated modular framework designed for\ncustomized and dynamic harm evaluations. It utilizes adversarial user models\nthat are system-aware and have unique personalities, enabling a holistic\nred-teaming evaluation. We demonstrate $\\texttt{SAGE}$'s effectiveness by\nevaluating seven state-of-the-art LLMs across three applications and harm\npolicies. Our experiments with multi-turn conversational evaluations revealed a\nconcerning finding that harm steadily increases with conversation length.\nFurthermore, we observe significant disparities in model behavior when exposed\nto different user personalities and scenarios. Our findings also reveal that\nsome models minimize harmful outputs by employing severe refusal tactics that\ncan hinder their usefulness. These insights highlight the necessity of adaptive\nand context-specific testing to ensure better safety alignment and safer\ndeployment of LLMs in real-world scenarios.",
      "tldr_zh": "本论文提出$\\texttt{SAGE}$框架，这是一个通用的自动化模块化工具，用于评估大型语言模型(LLMs)的安全问题，特别针对应用特定的危害和动态对话场景。$\\texttt{SAGE}$通过引入系统感知的对抗性用户模型（具有独特个性）进行整体红队(red-teaming)评估，实现定制化和动态的危害测试。实验结果显示，在评估七个最先进LLMs时，多轮对话中危害随对话长度增加，且模型对不同用户个性与场景表现出显著差异，一些模型通过过度拒绝策略减少危害但降低了实用性。这些发现强调了进行适应性、上下文特定的测试，以提升LLMs的安全性和实际部署效果。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 9 main pages excluding references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2504.19674v1",
      "published_date": "2025-04-28 11:01:08 UTC",
      "updated_date": "2025-04-28 11:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:29:21.327252"
    },
    {
      "arxiv_id": "2504.19673v1",
      "title": "Generative AI in Education: Student Skills and Lecturer Roles",
      "title_zh": "生成式 AI 在教育中：学生技能与讲师角色",
      "authors": [
        "Stefanie Krause",
        "Ashish Dalvi",
        "Syed Khubaib Zaidi"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) tools such as ChatGPT are emerging\nas a revolutionary tool in education that brings both positive aspects and\nchallenges for educators and students, reshaping how learning and teaching are\napproached. This study aims to identify and evaluate the key competencies\nstudents need to effectively engage with GenAI in education and to provide\nstrategies for lecturers to integrate GenAI into teaching practices. The study\napplied a mixed method approach with a combination of a literature review and a\nquantitative survey involving 130 students from South Asia and Europe to obtain\nits findings. The literature review identified 14 essential student skills for\nGenAI engagement, with AI literacy, critical thinking, and ethical AI practices\nemerging as the most critical. The student survey revealed gaps in prompt\nengineering, bias awareness, and AI output management. In our study of lecturer\nstrategies, we identified six key areas, with GenAI Integration and Curriculum\nDesign being the most emphasised. Our findings highlight the importance of\nincorporating GenAI into education. While literature prioritized ethics and\npolicy development, students favour hands-on, project-based learning and\npractical AI applications. To foster inclusive and responsible GenAI adoption,\ninstitutions should ensure equitable access to GenAI tools, establish clear\nacademic integrity policies, and advocate for global GenAI research\ninitiatives.",
      "tldr_zh": "这篇论文探讨了 Generative AI (GenAI) 在教育中的应用，识别了学生有效使用 GenAI 的关键技能和讲师的整合策略。研究采用混合方法，包括文献综述和对 130 名南亚和欧洲学生的定量调查，发现 14 种核心学生技能（如 AI literacy、critical thinking 和 ethical AI practices）最为重要，但学生在 prompt engineering、bias awareness 和 AI output management 方面存在显著差距。论文强调讲师应优先考虑 GenAI Integration 和 Curriculum Design，并建议教育机构确保 GenAI 工具的公平访问、制定学术诚信政策，并推动全球研究倡议，以促进负责任的 GenAI 采用。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19673v1",
      "published_date": "2025-04-28 10:58:30 UTC",
      "updated_date": "2025-04-28 10:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:29:34.326018"
    },
    {
      "arxiv_id": "2504.19667v1",
      "title": "A Tripartite Perspective on GraphRAG",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Banf",
        "Johannes Kuhn"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities across\nvarious domains, yet they struggle with knowledge-intensive tasks in areas that\ndemand factual accuracy, e.g. industrial automation and healthcare. Key\nlimitations include their tendency to hallucinate, lack of source traceability\n(provenance), and challenges in timely knowledge updates. Combining language\nmodels with knowledge graphs (GraphRAG) offers promising avenues for overcoming\nthese deficits. However, a major challenge lies in creating such a knowledge\ngraph in the first place. Here, we propose a novel approach that combines LLMs\nwith a tripartite knowledge graph representation, which is constructed by\nconnecting complex, domain-specific objects via a curated ontology of\ncorresponding, domain-specific concepts to relevant sections within chunks of\ntext through a concept-anchored pre-analysis of source documents starting from\nan initial lexical graph. As a consequence, our Tripartite-GraphRAG approach\nimplements: i) a concept-specific, information-preserving pre-compression of\ntextual chunks; ii) allows for the formation of a concept-specific relevance\nestimation of embedding similarities grounded in statistics; and iii) avoids\ncommon challenges w.r.t. continuous extendability, such as the need for entity\nresolution and deduplication. By applying a transformation to the knowledge\ngraph, we formulate LLM prompt creation as an unsupervised node classification\nproblem, drawing on ideas from Markov Random Fields. We evaluate our approach\non a healthcare use case, involving multi-faceted analyses of patient anamneses\ngiven a set of medical concepts as well as clinical literature. Experiments\nindicate that it can optimize information density, coverage, and arrangement of\nLLM prompts while reducing their lengths, which may lead to reduced costs and\nmore consistent and reliable LLM outputs.",
      "tldr_zh": "该论文探讨了 Large Language Models (LLMs) 在知识密集型任务中的局限性，如幻觉、来源可追溯性缺失和知识更新挑战，并提出 Tripartite-GraphRAG 框架作为解决方案。该框架采用三元组知识图谱（tripartite knowledge graph）来连接领域特定对象、对应概念和文本块，通过概念锚定的预分析从初始词汇图构建图谱，从而实现文本预压缩和基于统计的相关性估计，同时避免实体解析和去重难题。论文将 LLM 提示创建转化为无监督节点分类问题，利用 Markov Random Fields 的思想进行优化。在医疗用例实验中，该方法显著提高了信息密度、覆盖率和提示安排效率，减少了提示长度，进而降低了成本并提升了 LLM 输出的可靠性和一致性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19667v1",
      "published_date": "2025-04-28 10:43:35 UTC",
      "updated_date": "2025-04-28 10:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:29:46.815041"
    },
    {
      "arxiv_id": "2505.01441v1",
      "title": "Agentic Reasoning and Tool Integration for LLMs via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Joykirat Singh",
        "Raghav Magazine",
        "Yash Pandya",
        "Akshay Nambi"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress in complex\nreasoning tasks, yet they remain fundamentally limited by their reliance on\nstatic internal knowledge and text-only reasoning. Real-world problem solving\noften demands dynamic, multi-step reasoning, adaptive decision making, and the\nability to interact with external tools and environments. In this work, we\nintroduce ARTIST (Agentic Reasoning and Tool Integration in Self-improving\nTransformers), a unified framework that tightly couples agentic reasoning,\nreinforcement learning, and tool integration for LLMs. ARTIST enables models to\nautonomously decide when, how, and which tools to invoke within multi-turn\nreasoning chains, leveraging outcome-based RL to learn robust strategies for\ntool use and environment interaction without requiring step-level supervision.\nExtensive experiments on mathematical reasoning and multi-turn function calling\nbenchmarks show that ARTIST consistently outperforms state-of-the-art\nbaselines, with up to 22% absolute improvement over base models and strong\ngains on the most challenging tasks. Detailed studies and metric analyses\nreveal that agentic RL training leads to deeper reasoning, more effective tool\nuse, and higher-quality solutions. Our results establish agentic RL with tool\nintegration as a powerful new frontier for robust, interpretable, and\ngeneralizable problem-solving in LLMs.",
      "tldr_zh": "该研究提出 ARTIST 框架，通过结合 agentic reasoning（智能体推理）、reinforcement learning（强化学习）和 tool integration（工具集成），帮助 LLMs 实现动态、多步推理和外部环境交互，克服其静态知识的局限性。ARTIST 让模型在多轮推理链中自主决定何时及如何使用工具，并利用基于结果的 RL 训练策略，而无需步级监督。实验结果显示，该框架在数学推理和多轮函数调用基准上比最先进基线提升高达22%，并显著改善推理深度、工具使用效率和解决方案质量。这些发现确立了 agentic RL 与工具集成作为 LLMs 问题解决的强大新方向，提供更鲁棒、可解释的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01441v1",
      "published_date": "2025-04-28 10:42:49 UTC",
      "updated_date": "2025-04-28 10:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:29:58.996245"
    },
    {
      "arxiv_id": "2504.19659v1",
      "title": "Hardware/Software Co-Design of RISC-V Extensions for Accelerating Sparse DNNs on FPGAs",
      "title_zh": "RISC-V 扩展的硬件/软件协同设计，用于在",
      "authors": [
        "Muhammad Sabih",
        "Abrarul Karim",
        "Jakob Wittmann",
        "Frank Hannig",
        "Jürgen Teich"
      ],
      "abstract": "The customizability of RISC-V makes it an attractive choice for accelerating\ndeep neural networks (DNNs). It can be achieved through instruction set\nextensions and corresponding custom functional units. Yet, efficiently\nexploiting these opportunities requires a hardware/software co-design approach\nin which the DNN model, software, and hardware are designed together. In this\npaper, we propose novel RISC-V extensions for accelerating DNN models\ncontaining semi-structured and unstructured sparsity. While the idea of\naccelerating structured and unstructured pruning is not new, our novel design\noffers various advantages over other designs. To exploit semi-structured\nsparsity, we take advantage of the fine-grained (bit-level) configurability of\nFPGAs and suggest reserving a few bits in a block of DNN weights to encode the\ninformation about sparsity in the succeeding blocks. The proposed custom\nfunctional unit utilizes this information to skip computations. To exploit\nunstructured sparsity, we propose a variable cycle sequential\nmultiply-and-accumulate unit that performs only as many multiplications as the\nnon-zero weights. Our implementation of unstructured and semi-structured\npruning accelerators can provide speedups of up to a factor of 3 and 4,\nrespectively. We then propose a combined design that can accelerate both types\nof sparsities, providing speedups of up to a factor of 5. Our designs consume a\nsmall amount of additional FPGA resources such that the resulting co-designs\nenable the acceleration of DNNs even on small FPGAs. We benchmark our designs\non standard TinyML applications such as keyword spotting, image classification,\nand person detection.",
      "tldr_zh": "本文提出了一种硬件/软件联合设计方法，通过扩展 RISC-V 指令集来加速稀疏 DNNs 在 FPGAs 上的执行，针对半结构化和非结构化稀疏性进行优化。针对半结构化稀疏，该设计利用 FPGAs 的细粒度位级配置，在权重块中保留位来编码稀疏信息，从而启用自定义功能单元跳过不必要的计算；针对非结构化稀疏，则采用可变周期的顺序乘-累加单元，仅对非零权重进行运算。实验结果显示，该方法可分别提供高达 4 倍和 3 倍的速度提升，结合设计则达 5 倍，且在小型 FPGAs 上资源消耗低，并在 TinyML 应用如关键词检测、图像分类和人员检测上进行了基准测试。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19659v1",
      "published_date": "2025-04-28 10:19:39 UTC",
      "updated_date": "2025-04-28 10:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:30:11.285393"
    },
    {
      "arxiv_id": "2504.19654v1",
      "title": "Transformation & Translation Occupancy Grid Mapping: 2-Dimensional Deep Learning Refined SLAM",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Davies",
        "Baihua Li",
        "Mohamad Saada",
        "Simon Sølvsten",
        "Qinggang Meng"
      ],
      "abstract": "SLAM (Simultaneous Localisation and Mapping) is a crucial component for\nrobotic systems, providing a map of an environment, the current location and\nprevious trajectory of a robot. While 3D LiDAR SLAM has received notable\nimprovements in recent years, 2D SLAM lags behind. Gradual drifts in odometry\nand pose estimation inaccuracies hinder modern 2D LiDAR-odometry algorithms in\nlarge complex environments. Dynamic robotic motion coupled with inherent\nestimation based SLAM processes introduce noise and errors, degrading map\nquality. Occupancy Grid Mapping (OGM) produces results that are often noisy and\nunclear. This is due to the fact that evidence based mapping represents maps\naccording to uncertain observations. This is why OGMs are so popular in\nexploration or navigation tasks. However, this also limits OGMs' effectiveness\nfor specific mapping based tasks such as floor plan creation in complex scenes.\nTo address this, we propose our novel Transformation and Translation Occupancy\nGrid Mapping (TT-OGM). We adapt and enable accurate and robust pose estimation\ntechniques from 3D SLAM to the world of 2D and mitigate errors to improve map\nquality using Generative Adversarial Networks (GANs). We introduce a novel data\ngeneration method via deep reinforcement learning (DRL) to build datasets large\nenough for training a GAN for SLAM error correction. We demonstrate our SLAM in\nreal-time on data collected at Loughborough University. We also prove its\ngeneralisability on a variety of large complex environments on a collection of\nlarge scale well-known 2D occupancy maps. Our novel approach enables the\ncreation of high quality OGMs in complex scenes, far surpassing the\ncapabilities of current SLAM algorithms in terms of quality, accuracy and\nreliability.",
      "tldr_zh": "该论文针对2D SLAM（Simultaneous Localisation and Mapping）中的渐进漂移、位姿估计不准确和Occupancy Grid Mapping（OGM）噪声等问题，提出了一种新型框架Transformation and Translation OGM（TT-OGM）。该方法将3D SLAM的位姿估计技术移植到2D领域，并利用Generative Adversarial Networks（GANs）结合基于深度强化学习（DRL）的创新数据生成方法，来减少错误并提升地图质量。实验在Loughborough University的实时数据上验证，并证明了TT-OGM在各种大型复杂环境中具有优越的泛化性，显著超越现有SLAM算法，在地图质量、准确性和可靠性方面实现了重大改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, preprint, submitted to Robotics And Autonomous Systems",
      "pdf_url": "http://arxiv.org/pdf/2504.19654v1",
      "published_date": "2025-04-28 10:13:47 UTC",
      "updated_date": "2025-04-28 10:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:30:22.758328"
    },
    {
      "arxiv_id": "2504.19653v1",
      "title": "GAN-SLAM: Real-Time GAN Aided Floor Plan Creation Through SLAM",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Davies",
        "Baihua Li",
        "Mohamad Saada",
        "Simon Sølvsten",
        "Qinggang Meng"
      ],
      "abstract": "SLAM is a fundamental component of modern autonomous systems, providing\nrobots and their operators with a deeper understanding of their environment.\nSLAM systems often encounter challenges due to the dynamic nature of robotic\nmotion, leading to inaccuracies in mapping quality, particularly in 2D\nrepresentations such as Occupancy Grid Maps. These errors can significantly\ndegrade map quality, hindering the effectiveness of specific downstream tasks\nsuch as floor plan creation. To address this challenge, we introduce our novel\n'GAN-SLAM', a new SLAM approach that leverages Generative Adversarial Networks\nto clean and complete occupancy grids during the SLAM process, reducing the\nimpact of noise and inaccuracies introduced on the output map. We adapt and\nintegrate accurate pose estimation techniques typically used for 3D SLAM into a\n2D form. This enables the quality improvement 3D LiDAR-odometry has seen in\nrecent years to be effective for 2D representations. Our results demonstrate\nsubstantial improvements in map fidelity and quality, with minimal noise and\nerrors, affirming the effectiveness of GAN-SLAM for real-world mapping\napplications within large-scale complex environments. We validate our approach\non real-world data operating in real-time, and on famous examples of 2D maps.\nThe improved quality of the output map enables new downstream tasks, such as\nfloor plan drafting, further enhancing the capabilities of autonomous systems.\nOur novel approach to SLAM offers a significant step forward in the field,\nimproving the usability for SLAM in mapping-based tasks, and offers insight\ninto the usage of GANs for OGM error correction.",
      "tldr_zh": "该研究针对 SLAM 系统在动态机器人运动中导致的 2D 地图不准确问题（如 Occupancy Grid Maps 中的噪声），提出了一种新型 GAN-SLAM 方法，利用 Generative Adversarial Networks (GAN) 在 SLAM 过程中实时清理和完成地图，以减少错误并整合 3D SLAM 的精确姿态估计技术到 2D 形式。实验结果显示，GAN-SLAM 显著提高了地图的保真度和质量，在真实世界数据和著名 2D 地图示例上验证其实时有效性。该方法不仅提升了 SLAM 在大规模复杂环境中的可用性，还为下游任务如 floor plan 创建提供了新支持。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, preprint conference submission",
      "pdf_url": "http://arxiv.org/pdf/2504.19653v1",
      "published_date": "2025-04-28 10:13:38 UTC",
      "updated_date": "2025-04-28 10:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:30:35.265965"
    },
    {
      "arxiv_id": "2504.19645v1",
      "title": "A Comprehensive Part-of-Speech Tagging to Standardize Central-Kurdish Language: A Research Guide for Kurdish Natural Language Processing Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Shadan Shukr Sabr",
        "Nazira Sabr Mustafa",
        "Talar Sabah Omar",
        "Salah Hwayyiz Rasool",
        "Nawzad Anwer Omer",
        "Darya Sabir Hamad",
        "Hemin Abdulhameed Shams",
        "Omer Mahmood Kareem",
        "Rozhan Noori Abdullah",
        "Khabat Atar Abdullah",
        "Mahabad Azad Mohammad",
        "Haneen Al-Raghefy",
        "Safar M. Asaad",
        "Sara Jamal Mohammed",
        "Twana Saeed Ali",
        "Fazil Shawrow",
        "Halgurd S. Maghdid"
      ],
      "abstract": "- The field of natural language processing (NLP) has dramatically expanded\nwithin the last decade. Many human-being applications are conducted daily via\nNLP tasks, starting from machine translation, speech recognition, text\ngeneration and recommendations, Part-of-Speech tagging (POS), and Named-Entity\nRecognition (NER). However, low-resourced languages, such as the\nCentral-Kurdish language (CKL), mainly remain unexamined due to shortage of\nnecessary resources to support their development. The POS tagging task is the\nbase of other NLP tasks; for example, the POS tag set has been used to\nstandardized languages to provide the relationship between words among the\nsentences, followed by machine translation and text recommendation.\nSpecifically, for the CKL, most of the utilized or provided POS tagsets are\nneither standardized nor comprehensive. To this end, this study presented an\naccurate and comprehensive POS tagset for the CKL to provide better performance\nof the Kurdish NLP tasks. The article also collected most of the POS tags from\ndifferent studies as well as from Kurdish linguistic experts to standardized\npart-of-speech tags. The proposed POS tagset is designed to annotate a large\nCKL corpus and support Kurdish NLP tasks. The initial investigations of this\nstudy via comparison with the Universal Dependencies framework for standard\nlanguages, show that the proposed POS tagset can streamline or correct\nsentences more accurately for Kurdish NLP tasks.",
      "tldr_zh": "本研究针对低资源语言Central-Kurdish Language (CKL)，提出了一种全面的Part-of-Speech Tagging (POS)标记集，以标准化CKL并指导Kurdish Natural Language Processing (NLP)任务。作者通过收集不同研究和Kurdish语言专家的POS标签，设计了一个准确、全面的标记集，用于标注大型CKL语料库并提升后续NLP任务如机器翻译和Named-Entity Recognition (NER)的性能。初步比较显示，该标记集与Universal Dependencies框架相比，能更精确地处理CKL句子，从而改善Kurdish NLP任务的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "K.5; K.7; J.7"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.19645v1",
      "published_date": "2025-04-28 10:02:11 UTC",
      "updated_date": "2025-04-28 10:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:30:45.986068"
    },
    {
      "arxiv_id": "2504.19636v2",
      "title": "Fitness Landscape of Large Language Model-Assisted Automated Algorithm Search",
      "title_zh": "大型语言模型辅助的自动算法搜索的适应度景观",
      "authors": [
        "Fei Liu",
        "Qingfu Zhang",
        "Xialiang Tong",
        "Kun Mao",
        "Mingxuan Yuan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in\nalgorithm design. However, when integrated into search frameworks for iterative\nalgorithm search, the underlying fitness landscape--critical for understanding\nsearch behaviou--remains underexplored. In this paper, we illustrate and\nanalyze the fitness landscape of LLM-assisted Algorithm Search (LAS) using a\ngraph-based approach, where nodes represent algorithms and edges denote\ntransitions between them. We conduct extensive evaluations across six algorithm\ndesign tasks and six commonly used LLMs. Our findings reveal that LAS\nlandscapes are highly multimodal and rugged, particularly in combinatorial\noptimization tasks, with distinct structural variations across tasks and LLMs.\nFor instance, heuristic design tasks exhibit dense clusters of high-performing\nalgorithms, while symbolic regression tasks show sparse, scattered\ndistributions. Additionally, we demonstrate how population size influences\nexploration-exploitation trade-offs and the evolving trajectory of elite\nalgorithms. These insights not only advance our understanding of LAS landscapes\nbut also provide practical guidance for designing more effective LAS methods.",
      "tldr_zh": "本文探讨了 Large Language Models (LLMs) 在算法搜索中的适应度景观（fitness landscape），使用图-based 方法将算法表示为节点和过渡边，分析 LLM-assisted Algorithm Search (LAS) 的搜索行为。研究通过评估六种算法设计任务和六种常用 LLMs，发现 LAS 景观高度多模态和崎岖，尤其在组合优化任务中存在显著结构差异，例如启发式设计任务显示密集高性能算法集群，而符号回归任务则呈现稀疏散布。最终，这些发现揭示了种群大小对探索-利用权衡和精英算法演化轨迹的影响，并为设计更有效的 LAS 方法提供了实用指导。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19636v2",
      "published_date": "2025-04-28 09:52:41 UTC",
      "updated_date": "2025-05-01 08:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:30:59.099397"
    },
    {
      "arxiv_id": "2504.19627v2",
      "title": "VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning",
      "title_zh": "VCM：基于隐式对比学习的视觉概念建模与视觉-语言指令微调",
      "authors": [
        "Run Luo",
        "Renke Shan",
        "Longze Chen",
        "Ziqiang Liu",
        "Lu Wang",
        "Min Yang",
        "Xiaobo Xia"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) are pivotal for real-world AI tasks like\nembodied intelligence due to their strong vision-language reasoning abilities.\nHowever, current LVLMs process entire images at the token level, which is\ninefficient compared to humans who analyze information and generate content at\nthe conceptual level, extracting relevant visual concepts with minimal effort.\nThis inefficiency, stemming from the lack of a visual concept model, limits\nLVLMs' usability in real-world applications. To address this, we propose VCM,\nan end-to-end self-supervised visual concept modeling framework. VCM leverages\nimplicit contrastive learning across multiple sampled instances and\nvision-language fine-tuning to construct a visual concept model without\nrequiring costly concept-level annotations. Our results show that VCM\nsignificantly reduces computational costs (e.g., 85\\% fewer FLOPs for\nLLaVA-1.5-7B) while maintaining strong performance across diverse image\nunderstanding tasks. Moreover, VCM enhances visual encoders' capabilities in\nclassic visual concept perception tasks. Extensive quantitative and qualitative\nexperiments validate the effectiveness and efficiency of VCM.",
      "tldr_zh": "该研究指出，大型视觉语言模型 (LVLMs) 在处理图像时以 token 级别操作，效率低下，无法像人类那样在概念级别提取视觉信息，从而限制了其在现实应用中的可用性。为解决此问题，提出 VCM 框架，这是一个端到端的自监督视觉概念建模方法，利用 implicit contrastive learning 和 vision-language instruction fine-tuning 来构建视觉概念模型，而无需昂贵的概念级标注。VCM 显著降低了计算成本，例如为 LLaVA-1.5-7B 减少 85% 的 FLOPs，同时在各种图像理解任务中保持强劲性能，并提升了视觉编码器的概念感知能力。通过广泛的定量和定性实验，证明了 VCM 的有效性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "VCM",
      "pdf_url": "http://arxiv.org/pdf/2504.19627v2",
      "published_date": "2025-04-28 09:39:07 UTC",
      "updated_date": "2025-05-19 13:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:31:11.342931"
    },
    {
      "arxiv_id": "2505.02843v1",
      "title": "Physical foundations for trustworthy medical imaging: a review for artificial intelligence researchers",
      "title_zh": "可信赖医学成像的物理基础：面向人工智能研究者的综述",
      "authors": [
        "Miriam Cobo",
        "David Corral Fontecha",
        "Wilson Silva",
        "Lara Lloret Iglesias"
      ],
      "abstract": "Artificial intelligence in medical imaging has seen unprecedented growth in\nthe last years, due to rapid advances in deep learning and computing resources.\nApplications cover the full range of existing medical imaging modalities, with\nunique characteristics driven by the physics of each technique. Yet, artificial\nintelligence professionals entering the field, and even experienced developers,\noften lack a comprehensive understanding of the physical principles underlying\nmedical image acquisition, which hinders their ability to fully leverage its\npotential. The integration of physics knowledge into artificial intelligence\nalgorithms enhances their trustworthiness and robustness in medical imaging,\nespecially in scenarios with limited data availability. In this work, we review\nthe fundamentals of physics in medical images and their impact on the latest\nadvances in artificial intelligence, particularly, in generative models and\nreconstruction algorithms. Finally, we explore the integration of physics\nknowledge into physics-inspired machine learning models, which leverage\nphysics-based constraints to enhance the learning of medical imaging features.",
      "tldr_zh": "这篇评论文章针对 artificial intelligence 研究者，回顾了医疗成像的物理基础及其对 AI 发展的关键影响，强调了理解这些原理对于提升算法可信度和鲁棒性的重要性，尤其在数据有限的场景中。论文讨论了物理知识如何整合到深度学习模型中，特别是在 generative models 和 reconstruction algorithms 的最新进展中，以增强医疗图像特征的学习。最终，它探索了基于物理约束的 machine learning models，旨在帮助 AI 专业人士更有效地利用物理原理来开发更可靠的医疗成像技术。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "17 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.02843v1",
      "published_date": "2025-04-28 09:35:00 UTC",
      "updated_date": "2025-04-28 09:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:31:23.161037"
    },
    {
      "arxiv_id": "2504.19622v1",
      "title": "From Evidence to Belief: A Bayesian Epistemology Approach to Language Models",
      "title_zh": "从证据到信念：一种贝叶斯认识",
      "authors": [
        "Minsu Kim",
        "Sangryul Kim",
        "James Thorne"
      ],
      "abstract": "This paper investigates the knowledge of language models from the perspective\nof Bayesian epistemology. We explore how language models adjust their\nconfidence and responses when presented with evidence with varying levels of\ninformativeness and reliability. To study these properties, we create a dataset\nwith various types of evidence and analyze language models' responses and\nconfidence using verbalized confidence, token probability, and sampling. We\nobserved that language models do not consistently follow Bayesian epistemology:\nlanguage models follow the Bayesian confirmation assumption well with true\nevidence but fail to adhere to other Bayesian assumptions when encountering\ndifferent evidence types. Also, we demonstrated that language models can\nexhibit high confidence when given strong evidence, but this does not always\nguarantee high accuracy. Our analysis also reveals that language models are\nbiased toward golden evidence and show varying performance depending on the\ndegree of irrelevance, helping explain why they deviate from Bayesian\nassumptions.",
      "tldr_zh": "这篇论文从Bayesian Epistemology的角度探讨语言模型如何根据不同信息量和可靠性的证据调整其信心和响应。研究者创建了一个数据集，并通过verbalized confidence、token probability和sampling分析语言模型的表现，发现这些模型在面对真实证据时能遵循Bayesian confirmation assumption，但对其他证据类型则未能遵守贝叶斯原则。结果显示，语言模型偏向golden evidence，并在证据相关度变化时表现出偏差，导致高信心并不总是对应高准确性。该研究揭示了语言模型偏离Bayesian假设的潜在原因，为改进模型的可靠性和决策提供见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19622v1",
      "published_date": "2025-04-28 09:28:42 UTC",
      "updated_date": "2025-04-28 09:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:31:35.012756"
    },
    {
      "arxiv_id": "2504.19600v1",
      "title": "Image Generation Method Based on Heat Diffusion Models",
      "title_zh": "基于热扩散模型的图像生成方法",
      "authors": [
        "Pengfei Zhang",
        "Shouqing Jia"
      ],
      "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) achieve high-quality image\ngeneration without adversarial training, but they process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM is a model that incorporates pixel-level\noperations while maintaining the same training process as DDPM. In HDM, the\ndiscrete form of the two-dimensional heat equation is integrated into the\ndiffusion and generation formulas of DDPM, enabling the model to compute\nrelationships between neighboring pixels during image processing. Our\nexperiments demonstrate that HDM can generate higher-quality samples compared\nto models such as DDPM, Consistency Diffusion Models (CDM), Latent Diffusion\nModels (LDM), and Vector Quantized Generative Adversarial Networks (VQGAN).",
      "tldr_zh": "这篇论文提出了一种基于热扩散模型(HDM)的图像生成方法，以解决传统 DDPMs 在处理图像整体时忽略相邻像素关系的问题，从而更好地保留图像细节并生成更真实的样本。HDM 保留了 DDPMs 的训练过程，但通过整合二维热方程的离散形式，实现了像素级操作以计算相邻像素之间的关系。实验结果表明，HDM 生成的样本质量超过了 DDPM、CDM、LDM 和 VQGAN 等模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19600v1",
      "published_date": "2025-04-28 09:03:33 UTC",
      "updated_date": "2025-04-28 09:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:31:46.244817"
    },
    {
      "arxiv_id": "2504.19599v2",
      "title": "GVPO: Group Variance Policy Optimization for Large Language Model Post-Training",
      "title_zh": "GVPO",
      "authors": [
        "Kaichen Zhang",
        "Yuzhong Hong",
        "Junwei Bao",
        "Hongfei Jiang",
        "Yang Song",
        "Dingqian Hong",
        "Hui Xiong"
      ],
      "abstract": "Post-training plays a crucial role in refining and aligning large language\nmodels to meet specific tasks and human preferences. While recent advancements\nin post-training techniques, such as Group Relative Policy Optimization (GRPO),\nleverage increased sampling with relative reward scoring to achieve superior\nperformance, these methods often suffer from training instability that limits\ntheir practical adoption. To address this challenge, we present Group Variance\nPolicy Optimization (GVPO). GVPO incorporates the analytical solution to\nKL-constrained reward maximization directly into its gradient weights, ensuring\nalignment with the optimal policy. The method provides intuitive physical\ninterpretations: its gradient mirrors the mean squared error between the\ncentral distance of implicit rewards and that of actual rewards. GVPO offers\ntwo key advantages: (1) it guarantees a unique optimal solution, exactly the\nKL-constrained reward maximization objective, (2) it supports flexible sampling\ndistributions that avoids on-policy and importance sampling limitations. By\nunifying theoretical guarantees with practical adaptability, GVPO establishes a\nnew paradigm for reliable and versatile LLM post-training.",
      "tldr_zh": "这篇论文针对大语言模型(LLMs)后训练中的训练不稳定性问题，提出了Group Variance Policy Optimization (GVPO)方法，以改进现有技术如Group Relative Policy Optimization (GRPO)。GVPO将KL-constrained reward maximization的解析解直接整合到梯度权重中，确保策略与最优解对齐，并通过均方误差解释隐式奖励和实际奖励的中心距离。相比传统方法，该方法提供独特优势：保证唯一的最优解，并支持灵活采样分布，避免on-policy和importance sampling的限制，从而为可靠且多功能的LLM后训练建立新范式。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19599v2",
      "published_date": "2025-04-28 09:02:24 UTC",
      "updated_date": "2025-05-19 06:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:31:58.795180"
    },
    {
      "arxiv_id": "2504.19598v1",
      "title": "Lightweight Adapter Learning for More Generalized Remote Sensing Change Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Dou Quan",
        "Rufan Zhou",
        "Shuang Wang",
        "Ning Huyan",
        "Dong Zhao",
        "Yunan Li",
        "Licheng Jiao"
      ],
      "abstract": "Deep learning methods have shown promising performances in remote sensing\nimage change detection (CD). However, existing methods usually train a\ndataset-specific deep network for each dataset. Due to the significant\ndifferences in the data distribution and labeling between various datasets, the\ntrained dataset-specific deep network has poor generalization performances on\nother datasets. To solve this problem, this paper proposes a change adapter\nnetwork (CANet) for a more universal and generalized CD. CANet contains\ndataset-shared and dataset-specific learning modules. The former explores the\ndiscriminative features of images, and the latter designs a lightweight adapter\nmodel, to deal with the characteristics of different datasets in data\ndistribution and labeling. The lightweight adapter can quickly generalize the\ndeep network for new CD tasks with a small computation cost. Specifically, this\npaper proposes an interesting change region mask (ICM) in the adapter, which\ncan adaptively focus on interested change objects and decrease the influence of\nlabeling differences in various datasets. Moreover, CANet adopts a unique batch\nnormalization layer for each dataset to deal with data distribution\ndifferences. Compared with existing deep learning methods, CANet can achieve\nsatisfactory CD performances on various datasets simultaneously. Experimental\nresults on several public datasets have verified the effectiveness and\nadvantages of the proposed CANet on CD. CANet has a stronger generalization\nability, smaller training costs (merely updating 4.1%-7.7% parameters), and\nbetter performances under limited training datasets than other deep learning\nmethods, which also can be flexibly inserted with existing deep models.",
      "tldr_zh": "这篇论文提出了一种轻量级适配器学习方法，名为 Change Adapter Network (CANet)，旨在解决现有深度学习模型在遥感图像变化检测 (CD) 中的泛化问题，通过数据集共享模块提取判别特征，以及数据集特定模块的轻量级适配器处理数据分布和标签差异。CANet 引入了 Interesting Change Region Mask (ICM) 来自适应关注变化对象并减少标签影响，同时为每个数据集采用独特的 Batch Normalization 层以应对分布差异。与传统方法相比，实验在多个公共数据集上验证了 CANet 的有效性，它具有更强的泛化能力、较低的训练成本（仅更新 4.1%-7.7% 参数），并可灵活插入现有模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19598v1",
      "published_date": "2025-04-28 09:01:56 UTC",
      "updated_date": "2025-04-28 09:01:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:32:12.234538"
    },
    {
      "arxiv_id": "2504.19595v2",
      "title": "WILD: a new in-the-Wild Image Linkage Dataset for synthetic image attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Pietro Bongini",
        "Sara Mandelli",
        "Andrea Montibeller",
        "Mirko Casu",
        "Orazio Pontorno",
        "Claudio Vittorio Ragaglia",
        "Luca Zanchetta",
        "Mattia Aquilina",
        "Taiba Majid Wani",
        "Luca Guarnera",
        "Benedetta Tondi",
        "Giulia Boato",
        "Paolo Bestagini",
        "Irene Amerini",
        "Francesco De Natale",
        "Sebastiano Battiato",
        "Mauro Barni"
      ],
      "abstract": "Synthetic image source attribution is an open challenge, with an increasing\nnumber of image generators being released yearly. The complexity and the sheer\nnumber of available generative techniques, as well as the scarcity of\nhigh-quality open source datasets of diverse nature for this task, make\ntraining and benchmarking synthetic image source attribution models very\nchallenging. WILD is a new in-the-Wild Image Linkage Dataset designed to\nprovide a powerful training and benchmarking tool for synthetic image\nattribution models. The dataset is built out of a closed set of 10 popular\ncommercial generators, which constitutes the training base of attribution\nmodels, and an open set of 10 additional generators, simulating a real-world\nin-the-wild scenario. Each generator is represented by 1,000 images, for a\ntotal of 10,000 images in the closed set and 10,000 images in the open set.\nHalf of the images are post-processed with a wide range of operators. WILD\nallows benchmarking attribution models in a wide range of tasks, including\nclosed and open set identification and verification, and robust attribution\nwith respect to post-processing and adversarial attacks. Models trained on WILD\nare expected to benefit from the challenging scenario represented by the\ndataset itself. Moreover, an assessment of seven baseline methodologies on\nclosed and open set attribution is presented, including robustness tests with\nrespect to post-processing.",
      "tldr_zh": "本论文引入了WILD数据集，这是一个新的in-the-Wild Image Linkage Dataset，用于synthetic image attribution，以解决图像生成器多样性和数据集稀缺性带来的挑战。数据集包括封闭集（10个流行商业生成器，每种1000张图像，共10000张）和开放集（10个额外生成器，共10000张图像），其中半数图像经过各种后处理操作，模拟真实场景。WILD支持多种任务的训练和基准测试，如closed set和open set识别、验证，以及对post-processing和adversarial attacks的鲁棒归因。论文评估了七种基线方法，结果显示在这些任务上模型表现出色，为合成图像来源归因提供了强大的工具。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19595v2",
      "published_date": "2025-04-28 08:58:34 UTC",
      "updated_date": "2025-04-29 09:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:32:24.466819"
    },
    {
      "arxiv_id": "2504.19594v2",
      "title": "Mapping the Italian Telegram Ecosystem: Communities, Toxicity, and Hate Speech",
      "title_zh": "映射意大利Telegram生态系统：社区、毒性和仇恨言论",
      "authors": [
        "Lorenzo Alvisi",
        "Serena Tardelli",
        "Maurizio Tesconi"
      ],
      "abstract": "Telegram has become a major space for political discourse and alternative\nmedia. However, its lack of moderation allows misinformation, extremism, and\ntoxicity to spread. While prior research focused on these particular phenomena\nor topics, these have mostly been examined separately, and a broader\nunderstanding of the Telegram ecosystem is still missing. In this work, we fill\nthis gap by conducting a large-scale analysis of the Italian Telegram sphere,\nleveraging a dataset of 186 million messages from 13,151 chats collected in\n2023. Using network analysis, Large Language Models, and toxicity detection\ntools, we examine how different thematic communities form, align ideologically,\nand engage in harmful discourse within the Italian cultural context. Results\nshow strong thematic and ideological homophily. We also identify mixed\nideological communities where far-left and far-right rhetoric coexist on\nparticular geopolitical issues. Beyond political analysis, we find that\ntoxicity, rather than being isolated in a few extreme chats, appears widely\nnormalized within highly toxic communities. Moreover, we find that Italian\ndiscourse primarily targets Black people, Jews, and gay individuals\nindependently of the topic. Finally, we uncover common trend of intra-national\nhostility, where Italians often attack other Italians, reflecting regional and\nintra-regional cultural conflicts that can be traced back to old historical\ndivisions. This study provides the first large-scale mapping of the Italian\nTelegram ecosystem, offering insights into ideological interactions, toxicity,\nand identity-targets of hate and contributing to research on online toxicity\nacross different cultural and linguistic contexts on Telegram.",
      "tldr_zh": "本研究通过分析意大利 Telegram 生态系统中的 1.86 亿条消息，运用 network analysis、Large Language Models 和 toxicity detection tools，考察了社区形成、意识形态同质性和有害言论的传播。结果显示，存在强烈的 thematic 和 ideological homophily，导致社区内部高度一致，同时某些混合社区中 far-left 和 far-right 意识形态在特定地缘政治问题上共存。毒性言论并非局限于极端聊天，而是广泛正常化于多个社区，主要针对 Black people、Jews 和 gay individuals，且意大利内部常出现 intra-national hostility，反映历史文化冲突。该研究首次提供意大利 Telegram 生态的大规模映射，为跨文化在线 toxicity 研究贡献了重要洞见。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19594v2",
      "published_date": "2025-04-28 08:58:18 UTC",
      "updated_date": "2025-05-05 09:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:32:37.696314"
    },
    {
      "arxiv_id": "2504.19592v1",
      "title": "Neural network task specialization via domain constraining",
      "title_zh": "通过领域约束的神经网络任务专业化",
      "authors": [
        "Roman Malashin",
        "Daniil Ilyukhin"
      ],
      "abstract": "This paper introduces a concept of neural network specialization via\ntask-specific domain constraining, aimed at enhancing network performance on\ndata subspace in which the network operates. The study presents experiments on\ntraining specialists for image classification and object detection tasks. The\nresults demonstrate that specialization can enhance a generalist's accuracy\neven without additional data or changing training regimes: solely by\nconstraining class label space in which the network performs. Theoretical and\nexperimental analyses indicate that effective specialization requires modifying\ntraditional fine-tuning methods and constraining data space to semantically\ncoherent subsets. The specialist extraction phase before tuning the network is\nproposed for maximal performance gains. We also provide analysis of the\nevolution of the feature space during specialization. This study paves way to\nfuture research for developing more advanced dynamically configurable image\nanalysis systems, where computations depend on the specific input.\nAdditionally, the proposed methods can help improve system performance in\nscenarios where certain data domains should be excluded from consideration of\nthe generalist network.",
      "tldr_zh": "这篇论文提出了神经网络任务专业化（neural network task specialization）的新概念，通过任务特定领域约束（domain constraining）来提升网络在数据子空间的性能，而无需额外数据或改变训练方式。研究通过图像分类和物体检测任务的实验证明，仅约束类标签空间即可提高通用模型的准确率。作者建议修改传统fine-tuning方法，并在tuning前进行专家提取阶段，以确保数据空间限于语义上连贯的子集，并分析了特征空间（feature space）在专业化过程中的演变。该方法为开发动态可配置的图像分析系统铺平道路，尤其适用于排除特定数据域的场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19592v1",
      "published_date": "2025-04-28 08:57:01 UTC",
      "updated_date": "2025-04-28 08:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:32:47.686016"
    },
    {
      "arxiv_id": "2505.00032v1",
      "title": "MDD-LLM: Towards Accuracy Large Language Models for Major Depressive Disorder Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Yuyang Sha",
        "Hongxin Pan",
        "Wei Xu",
        "Weiyu Meng",
        "Gang Luo",
        "Xinyu Du",
        "Xiaobing Zhai",
        "Henry H. Y. Tong",
        "Caijuan Shi",
        "Kefeng Li"
      ],
      "abstract": "Major depressive disorder (MDD) impacts more than 300 million people\nworldwide, highlighting a significant public health issue. However, the uneven\ndistribution of medical resources and the complexity of diagnostic methods have\nresulted in inadequate attention to this disorder in numerous countries and\nregions. This paper introduces a high-performance MDD diagnosis tool named\nMDD-LLM, an AI-driven framework that utilizes fine-tuned large language models\n(LLMs) and extensive real-world samples to tackle challenges in MDD diagnosis.\nTherefore, we select 274,348 individual information from the UK Biobank cohort\nto train and evaluate the proposed method. Specifically, we select 274,348\nindividual records from the UK Biobank cohort and design a tabular data\ntransformation method to create a large corpus for training and evaluating the\nproposed approach. To illustrate the advantages of MDD-LLM, we perform\ncomprehensive experiments and provide several comparative analyses against\nexisting model-based solutions across multiple evaluation metrics. Experimental\nresults show that MDD-LLM (70B) achieves an accuracy of 0.8378 and an AUC of\n0.8919 (95% CI: 0.8799 - 0.9040), significantly outperforming existing machine\nlearning and deep learning frameworks for MDD diagnosis. Given the limited\nexploration of LLMs in MDD diagnosis, we examine numerous factors that may\ninfluence the performance of our proposed method, such as tabular data\ntransformation techniques and different fine-tuning strategies.",
      "tldr_zh": "本研究针对Major Depressive Disorder (MDD) 的全球影响和诊断挑战，提出了一种高性能AI框架MDD-LLM，利用fine-tuned Large Language Models (LLMs) 和UK Biobank的274,348个真实样本进行诊断。研究设计了tabular data transformation方法，将表格数据转化为大型训练语料，以提升模型在MDD识别中的准确性。实验结果显示，MDD-LLM (70B) 模型在多项评估指标中表现出色，准确率达0.8378、AUC为0.8919（95% CI: 0.8799 - 0.9040），显著优于现有机器学习和深度学习框架。此外，论文探讨了影响性能的因素，如数据转换技术和fine-tuning策略，为MDD诊断提供了更可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00032v1",
      "published_date": "2025-04-28 08:53:55 UTC",
      "updated_date": "2025-04-28 08:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:33:00.251079"
    },
    {
      "arxiv_id": "2504.19590v1",
      "title": "Arabic Metaphor Sentiment Classification Using Semantic Information",
      "title_zh": "翻译失败",
      "authors": [
        "Israa Alsiyat"
      ],
      "abstract": "In this paper, I discuss the testing of the Arabic Metaphor Corpus (AMC) [1]\nusing newly designed automatic tools for sentiment classification for AMC based\non semantic tags. The tool incorporates semantic emotional tags for sentiment\nclassification. I evaluate the tool using standard methods, which are F-score,\nrecall, and precision. The method is to show the impact of Arabic online\nmetaphors on sentiment through the newly designed tools. To the best of our\nknowledge, this is the first approach to conduct sentiment classification for\nArabic metaphors using semantic tags to find the impact of the metaphor.",
      "tldr_zh": "本研究首次使用语义标签对Arabic Metaphor Corpus (AMC) 进行情感分类，开发了基于语义情感标签的自动工具，以评估阿拉伯在线隐喻对情感的影响。方法涉及测试这些工具，并采用F-score、recall和precision等标准指标进行评估。结果展示了语义标签在处理阿拉伯隐喻情感分类中的有效性，为相关领域提供了新颖的分析框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19590v1",
      "published_date": "2025-04-28 08:53:28 UTC",
      "updated_date": "2025-04-28 08:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:33:10.623423"
    },
    {
      "arxiv_id": "2504.21039v1",
      "title": "Llama-3.1-FoundationAI-SecurityLLM-Base-8B Technical Report",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Kassianik",
        "Baturay Saglam",
        "Alexander Chen",
        "Blaine Nelson",
        "Anu Vellore",
        "Massimo Aufiero",
        "Fraser Burch",
        "Dhruv Kedia",
        "Avi Zohary",
        "Sajana Weerawardhena",
        "Aman Priyanshu",
        "Adam Swanda",
        "Amy Chang",
        "Hyrum Anderson",
        "Kojin Oshiba",
        "Omar Santos",
        "Yaron Singer",
        "Amin Karbasi"
      ],
      "abstract": "As transformer-based large language models (LLMs) increasingly permeate\nsociety, they have revolutionized domains such as software engineering,\ncreative writing, and digital arts. However, their adoption in cybersecurity\nremains limited due to challenges like scarcity of specialized training data\nand complexity of representing cybersecurity-specific knowledge. To address\nthese gaps, we present Foundation-Sec-8B, a cybersecurity-focused LLM built on\nthe Llama 3.1 architecture and enhanced through continued pretraining on a\ncarefully curated cybersecurity corpus. We evaluate Foundation-Sec-8B across\nboth established and new cybersecurity benchmarks, showing that it matches\nLlama 3.1-70B and GPT-4o-mini in certain cybersecurity-specific tasks. By\nreleasing our model to the public, we aim to accelerate progress and adoption\nof AI-driven tools in both public and private cybersecurity contexts.",
      "tldr_zh": "本论文介绍了Foundation-Sec-8B，一款基于Llama 3.1架构的网络安全焦点LLM，通过在精心策划的网络安全语料库上进行持续预训练，解决了LLMs在网络安全领域的数据稀缺和知识表示复杂等问题。该模型在各种网络安全基准测试中表现出色，与Llama 3.1-70B和GPT-4o-mini在特定任务中相当。通过公开发布Foundation-Sec-8B，研究团队旨在加速AI驱动工具在公共和私有网络安全环境中的采用和发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21039v1",
      "published_date": "2025-04-28 08:41:12 UTC",
      "updated_date": "2025-04-28 08:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:33:24.560761"
    },
    {
      "arxiv_id": "2504.20119v2",
      "title": "Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and Datasets",
      "title_zh": "LLMs 在评估 RAG 系统方面能被信任吗？方法和数据集的调查",
      "authors": [
        "Lorenz Brehme",
        "Thomas Ströhle",
        "Ruth Breu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has advanced significantly in recent\nyears. The complexity of RAG systems, which involve multiple components-such as\nindexing, retrieval, and generation-along with numerous other parameters, poses\nsubstantial challenges for systematic evaluation and quality enhancement.\nPrevious research highlights that evaluating RAG systems is essential for\ndocumenting advancements, comparing configurations, and identifying effective\napproaches for domain-specific applications. This study systematically reviews\n63 academic articles to provide a comprehensive overview of state-of-the-art\nRAG evaluation methodologies, focusing on four key areas: datasets, retrievers,\nindexing and databases, and the generator component. We observe the feasibility\nof an automated evaluation approach for each component of a RAG system,\nleveraging an LLM capable of both generating evaluation datasets and conducting\nevaluations. In addition, we found that further practical research is essential\nto provide companies with clear guidance on the do's and don'ts of implementing\nand evaluating RAG systems. By synthesizing evaluation approaches for key RAG\ncomponents and emphasizing the creation and adaptation of domain-specific\ndatasets for benchmarking, we contribute to the advancement of systematic\nevaluation methods and the improvement of evaluation rigor for RAG systems.\nFurthermore, by examining the interplay between automated approaches leveraging\nLLMs and human judgment, we contribute to the ongoing discourse on balancing\nautomation and human input, clarifying their respective contributions,\nlimitations, and challenges in achieving robust and reliable evaluations.",
      "tldr_zh": "这篇论文通过调查63篇学术文章，对Retrieval-Augmented Generation (RAG) 系统的评估方法进行了系统回顾，聚焦于数据集、retrievers、indexing 和 databases 以及 generator 组件。研究发现，Large Language Models (LLMs) 可用于自动化生成评估数据集和进行组件评估，但存在可信度挑战，需要结合人类判断以实现更可靠的结果。论文强调了创建领域特定数据集的重要性，并为RAG系统的实施提供实用指导，从而推进系统评估方法的改进和整体质量提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 Pages. This paper has been accepted for presentation at the IEEE\n  Swiss Conference on Data Science (SDS25)",
      "pdf_url": "http://arxiv.org/pdf/2504.20119v2",
      "published_date": "2025-04-28 08:22:19 UTC",
      "updated_date": "2025-05-01 13:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:33:39.164975"
    },
    {
      "arxiv_id": "2504.19565v1",
      "title": "m-KAILIN: Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
      "title_zh": "m-KAILIN：知识驱动的代理式科学语料库蒸馏框架，用于生物医学大语言模型训练",
      "authors": [
        "Meng Xiao",
        "Xunxin Cai",
        "Chengrui Wang",
        "Yuanchun Zhou"
      ],
      "abstract": "The rapid progress of large language models (LLMs) in biomedical research has\nunderscored the limitations of existing open-source annotated scientific\ncorpora, which are often insufficient in quantity and quality. Addressing the\nchallenge posed by the complex hierarchy of biomedical knowledge, we propose a\nknowledge-driven, multi-agent framework for scientific corpus distillation\ntailored for LLM training in the biomedical domain. Central to our approach is\na collaborative multi-agent architecture, where specialized agents, each guided\nby the Medical Subject Headings (MeSH) hierarchy, work in concert to\nautonomously extract, synthesize, and self-evaluate high-quality textual data\nfrom vast scientific literature. These agents collectively generate and refine\ndomain-specific question-answer pairs, ensuring comprehensive coverage and\nconsistency with biomedical ontologies while minimizing manual involvement.\nExtensive experimental results show that language models trained on our\nmulti-agent distilled datasets achieve notable improvements in biomedical\nquestion-answering tasks, outperforming both strong life sciences LLM baselines\nand advanced proprietary models. Notably, our AI-Ready dataset enables\nLlama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger\nscale. Detailed ablation studies and case analyses further validate the\neffectiveness and synergy of each agent within the framework, highlighting the\npotential of multi-agent collaboration in biomedical LLM training.",
      "tldr_zh": "该研究提出 m-KAILIN 框架，这是一个知识驱动的多智能体系统，用于从海量科学文献中提炼高质量生物医学语料库，以支持 Large Language Models (LLMs) 的训练。框架中，各智能体由 Medical Subject Headings (MeSH) 层次结构指导，协作提取、合成和自我评估领域特定问答对，确保覆盖全面、一致性并减少手动干预。实验结果显示，使用该框架提炼的数据集训练的模型在生物医学问答任务中显著优于基线，如 Llama3-70B 超过了 GPT-4 with MedPrompt 和 Med-PaLM-2；此外，消融研究证实了多智能体协同的效能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, Large Language Model, Agentic AI, Dataset Distillation,\n  Multi-agent Collaboration",
      "pdf_url": "http://arxiv.org/pdf/2504.19565v1",
      "published_date": "2025-04-28 08:18:24 UTC",
      "updated_date": "2025-04-28 08:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:33:49.051117"
    },
    {
      "arxiv_id": "2504.20118v1",
      "title": "OpenTCM: A GraphRAG-Empowered LLM-based System for Traditional Chinese Medicine Knowledge Retrieval and Diagnosis",
      "title_zh": "OpenTCM：一个基于GraphRAG的LLM",
      "authors": [
        "Jinglin He",
        "Yunqi Guo",
        "Lai Kwan Lam",
        "Waikei Leung",
        "Lixing He",
        "Yuanan Jiang",
        "Chi Chiu Wang",
        "Guoliang Xing",
        "Hongkai Chen"
      ],
      "abstract": "Traditional Chinese Medicine (TCM) represents a rich repository of ancient\nmedical knowledge that continues to play an important role in modern\nhealthcare. Due to the complexity and breadth of the TCM literature, the\nintegration of AI technologies is critical for its modernization and broader\naccessibility. However, this integration poses considerable challenges,\nincluding the interpretation of obscure classical Chinese texts and the\nmodeling of intricate semantic relationships among TCM concepts. In this paper,\nwe develop OpenTCM, an LLM-based system that combines a domain-specific TCM\nknowledge graph and Graph-based Retrieval-Augmented Generation (GraphRAG).\nFirst, we extract more than 3.73 million classical Chinese characters from 68\ngynecological books in the Chinese Medical Classics Database, with the help of\nTCM and gynecology experts. Second, we construct a comprehensive\nmulti-relational knowledge graph comprising more than 48,000 entities and\n152,000 interrelationships, using customized prompts and Chinese-oriented LLMs\nsuch as DeepSeek and Kimi to ensure high-fidelity semantic understanding. Last,\nwe integrate OpenTCM with this knowledge graph, enabling high-fidelity\ningredient knowledge retrieval and diagnostic question-answering without model\nfine-tuning. Experimental evaluations demonstrate that our prompt design and\nmodel selection significantly improve knowledge graph quality, achieving a\nprecision of 98. 55% and an F1 score of 99. 55%. In addition, OpenTCM achieves\nmean expert scores of 4.5 in ingredient information retrieval and 3.8 in\ndiagnostic question-answering tasks, outperforming state-of-the-art solutions\nin real-world TCM use cases.",
      "tldr_zh": "本研究开发了OpenTCM系统，这是一个基于LLM的平台，结合了特定领域的TCM知识图谱和GraphRAG技术，以提升传统中医知识检索和诊断的准确性。研究团队从68本妇科书籍中提取超过373万字符，构建了一个包含48,000实体和152,000关系的多关系知识图谱，并利用定制提示和中文LLM（如DeepSeek和Kimi）确保语义理解的精确性。无需模型微调，OpenTCM实现了高效的成分知识检索和诊断问答，实验结果显示知识图谱精确率达98.55%、F1分数99.55%，并在实际TCM应用中超越现有解决方案，平均专家评分分别为4.5和3.8。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20118v1",
      "published_date": "2025-04-28 08:04:44 UTC",
      "updated_date": "2025-04-28 08:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:34:00.061216"
    },
    {
      "arxiv_id": "2504.19545v1",
      "title": "Point2Quad: Generating Quad Meshes from Point Clouds via Face Prediction",
      "title_zh": "Point2Quad：通过面预测从点云生成四边形网格",
      "authors": [
        "Zezeng Li",
        "Zhihui Qi",
        "Weimin Wang",
        "Ziliang Wang",
        "Junyi Duan",
        "Na Lei"
      ],
      "abstract": "Quad meshes are essential in geometric modeling and computational mechanics.\nAlthough learning-based methods for triangle mesh demonstrate considerable\nadvancements, quad mesh generation remains less explored due to the challenge\nof ensuring coplanarity, convexity, and quad-only meshes. In this paper, we\npresent Point2Quad, the first learning-based method for quad-only mesh\ngeneration from point clouds. The key idea is learning to identify quad mesh\nwith fused pointwise and facewise features. Specifically, Point2Quad begins\nwith a k-NN-based candidate generation considering the coplanarity and\nsquareness. Then, two encoders are followed to extract geometric and\ntopological features that address the challenge of quad-related constraints,\nespecially by combining in-depth quadrilaterals-specific characteristics.\nSubsequently, the extracted features are fused to train the classifier with a\ndesigned compound loss. The final results are derived after the refinement by a\nquad-specific post-processing. Extensive experiments on both clear and noise\ndata demonstrate the effectiveness and superiority of Point2Quad, compared to\nbaseline methods under comprehensive metrics.",
      "tldr_zh": "该论文提出Point2Quad，一种从点云生成四边形网格（Quad Meshes）的首个学习-based方法，通过面预测技术解决共面性、凸性和仅四边形约束的挑战。核心思路是融合点级和面级特征，首先利用k-NN-based候选生成确保共面性和正方形性，然后通过两个编码器提取几何和拓扑特征，并结合四边形特定特性进行特征融合和分类器训练。实验结果显示，Point2Quad在清晰和噪声数据上表现出色，在综合指标下优于基线方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19545v1",
      "published_date": "2025-04-28 07:48:17 UTC",
      "updated_date": "2025-04-28 07:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:34:11.998821"
    },
    {
      "arxiv_id": "2504.21038v1",
      "title": "Prefill-Based Jailbreak: A Novel Approach of Bypassing LLM Safety Boundary",
      "title_zh": "翻译失败",
      "authors": [
        "Yakai Li",
        "Jiekang Hu",
        "Weiduan Sang",
        "Luping Ma",
        "Jing Xie",
        "Weijuan Zhang",
        "Aimin Yu",
        "Shijie Zhao",
        "Qingjia Huang",
        "Qihang Zhou"
      ],
      "abstract": "Large Language Models (LLMs) are designed to generate helpful and safe\ncontent. However, adversarial attacks, commonly referred to as jailbreak, can\nbypass their safety protocols, prompting LLMs to generate harmful content or\nreveal sensitive data. Consequently, investigating jailbreak methodologies is\ncrucial for exposing systemic vulnerabilities within LLMs, ultimately guiding\nthe continuous implementation of security enhancements by developers. In this\npaper, we introduce a novel jailbreak attack method that leverages the\nprefilling feature of LLMs, a feature designed to enhance model output\nconstraints. Unlike traditional jailbreak methods, the proposed attack\ncircumvents LLMs' safety mechanisms by directly manipulating the probability\ndistribution of subsequent tokens, thereby exerting control over the model's\noutput. We propose two attack variants: Static Prefilling (SP), which employs a\nuniversal prefill text, and Optimized Prefilling (OP), which iteratively\noptimizes the prefill text to maximize the attack success rate. Experiments on\nsix state-of-the-art LLMs using the AdvBench benchmark validate the\neffectiveness of our method and demonstrate its capability to substantially\nenhance attack success rates when combined with existing jailbreak approaches.\nThe OP method achieved attack success rates of up to 99.82% on certain models,\nsignificantly outperforming baseline methods. This work introduces a new\njailbreak attack method in LLMs, emphasizing the need for robust content\nvalidation mechanisms to mitigate the adversarial exploitation of prefilling\nfeatures. All code and data used in this paper are publicly available.",
      "tldr_zh": "本研究提出了一种名为 Prefill-Based Jailbreak 的新颖攻击方法，用于绕过 Large Language Models (LLMs) 的安全边界，通过操纵预填充 (prefilling) 功能来直接影响后续 token 的概率分布。方法包括两种变体：Static Prefilling (SP)，使用通用预填充文本，以及 Optimized Prefilling (OP)，通过迭代优化预填充文本以最大化攻击成功率。在六种最先进 LLMs 上使用 AdvBench 基准测试，OP 方法的攻击成功率高达 99.82%，显著优于基线方法，并证明其可与其他越狱方法结合以提升效果。该工作揭示了 LLMs 系统漏洞的潜在风险，呼吁开发者加强内容验证机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21038v1",
      "published_date": "2025-04-28 07:38:43 UTC",
      "updated_date": "2025-04-28 07:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:34:27.603132"
    },
    {
      "arxiv_id": "2504.20117v2",
      "title": "ResearchCodeAgent: An LLM Multi-Agent System for Automated Codification of Research Methodologies",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Gandhi",
        "Dhruv Shah",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Gautam Shroff"
      ],
      "abstract": "In this paper we introduce ResearchCodeAgent, a novel multi-agent system\nleveraging large language models (LLMs) agents to automate the codification of\nresearch methodologies described in machine learning literature. The system\nbridges the gap between high-level research concepts and their practical\nimplementation, allowing researchers auto-generating code of existing research\npapers for benchmarking or building on top-of existing methods specified in the\nliterature with availability of partial or complete starter code.\nResearchCodeAgent employs a flexible agent architecture with a comprehensive\naction suite, enabling context-aware interactions with the research\nenvironment. The system incorporates a dynamic planning mechanism, utilizing\nboth short and long-term memory to adapt its approach iteratively. We evaluate\nResearchCodeAgent on three distinct machine learning tasks with distinct task\ncomplexity and representing different parts of the ML pipeline: data\naugmentation, optimization, and data batching. Our results demonstrate the\nsystem's effectiveness and generalizability, with 46.9% of generated code being\nhigh-quality and error-free, and 25% showing performance improvements over\nbaseline implementations. Empirical analysis shows an average reduction of\n57.9% in coding time compared to manual implementation. We observe higher gains\nfor more complex tasks. ResearchCodeAgent represents a significant step towards\nautomating the research implementation process, potentially accelerating the\npace of machine learning research.",
      "tldr_zh": "本文介绍了 ResearchCodeAgent，一种基于 LLM 的多智能体系统，旨在自动将机器学习文献中的研究方法转化为代码，从而桥接高层次概念与实际实现。系统采用灵活的智能体架构、动态规划机制以及短/长期记忆功能，支持上下文感知交互和迭代适应。在数据增强、优化和数据批处理等任务的评估中，ResearchCodeAgent 生成的代码中有 46.9% 为高质量无错误，25% 性能优于基线，并平均减少 57.9% 编码时间，尤其在复杂任务上表现突出，这有助于加速机器学习研究进程。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20117v2",
      "published_date": "2025-04-28 07:18:45 UTC",
      "updated_date": "2025-05-03 16:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:32.828778"
    },
    {
      "arxiv_id": "2505.00031v1",
      "title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Zhang",
        "Flood Sung",
        "Zhilin Yang",
        "Yang Gao",
        "Chongjie Zhang"
      ],
      "abstract": "In the field of large language model (LLM) post-training, the effectiveness\nof utilizing synthetic data generated by the LLM itself has been\nwell-presented. However, a key question remains unaddressed: what essential\ninformation should such self-generated data encapsulate? Existing approaches\nonly produce step-by-step problem solutions, and fail to capture the abstract\nmeta-knowledge necessary for generalization across similar problems. Drawing\ninsights from cognitive science, where humans employ high-level abstraction to\nsimplify complex problems before delving into specifics, we introduce a novel\nself-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains\nthe LLM to formulate anticipatory plans, which serve as abstract meta-knowledge\nfor problem-solving, before engaging with the intricacies of problems. This\napproach not only outlines the solution generation path but also shields the\nLLM from the distraction of irrelevant details. During data generation, LEPA\nfirst crafts an anticipatory plan based on the problem, and then generates a\nsolution that aligns with both the plan and the problem. LEPA refines the plan\nthrough self-reflection, aiming to acquire plans that are instrumental in\nyielding correct solutions. During model optimization, the LLM is trained to\npredict both the refined plans and the corresponding solutions. By efficiently\nextracting and utilizing the anticipatory plans, LEPA demonstrates remarkable\nsuperiority over conventional algorithms on various challenging natural\nlanguage reasoning benchmarks.",
      "tldr_zh": "这篇论文提出了一种名为 LEPA 的自训练算法，旨在训练大型语言模型 (LLM) 在解决问题前学习抽象计划，以提升问题解决的泛化能力。LEPA 借鉴认知科学原理，先基于问题生成预见性计划作为抽象元知识，然后创建与计划一致的解决方案，并通过自反省优化计划。训练过程中，LLM 被优化以预测这些精炼计划和对应解决方案，最终在各种自然语言推理基准上表现出显著优势，优于传统算法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00031v1",
      "published_date": "2025-04-28 06:32:58 UTC",
      "updated_date": "2025-04-28 06:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:34:51.419152"
    },
    {
      "arxiv_id": "2504.21037v1",
      "title": "Security Bug Report Prediction Within and Across Projects: A Comparative Study of BERT and Random Forest",
      "title_zh": "项目内和项目间安全漏洞报告预测：BERT 与 Random Forest 的比较研究",
      "authors": [
        "Farnaz Soltaniani",
        "Mohammad Ghafari",
        "Mohammed Sayagh"
      ],
      "abstract": "Early detection of security bug reports (SBRs) is crucial for preventing\nvulnerabilities and ensuring system reliability. While machine learning models\nhave been developed for SBR prediction, their predictive performance still has\nroom for improvement. In this study, we conduct a comprehensive comparison\nbetween BERT and Random Forest (RF), a competitive baseline for predicting\nSBRs. The results show that RF outperforms BERT with a 34% higher average\nG-measure for within-project predictions. Adding only SBRs from various\nprojects improves both models' average performance. However, including both\nsecurity and nonsecurity bug reports significantly reduces RF's average\nperformance to 46%, while boosts BERT to its best average performance of 66%,\nsurpassing RF. In cross-project SBR prediction, BERT achieves a remarkable 62%\nG-measure, which is substantially higher than RF.",
      "tldr_zh": "该研究比较了BERT和Random Forest (RF)模型在安全漏洞报告(SBRs)预测中的性能，旨在改善早期漏洞检测。结果显示，在项目内预测中，RF的平均G-measure比BERT高出34%；添加其他项目的SBRs可提升两者的性能，但包含安全和非安全报告时，BERT的表现提升至66%，超过RF的46%。在跨项目预测中，BERT达到62%的G-measure，显著优于RF，这为选择合适模型提供重要指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21037v1",
      "published_date": "2025-04-28 06:09:01 UTC",
      "updated_date": "2025-04-28 06:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:02.518539"
    },
    {
      "arxiv_id": "2504.20115v1",
      "title": "AutoP2C: An LLM-Based Agent Framework for Code Repository Generation from Multimodal Content in Academic Papers",
      "title_zh": "AutoP2C：基于LLM的代理框架，用于从学术论文中的多模态内容生成代码仓库",
      "authors": [
        "Zijie Lin",
        "Yiqing Shen",
        "Qilin Cai",
        "He Sun",
        "Jinrui Zhou",
        "Mingjun Xiao"
      ],
      "abstract": "Machine Learning (ML) research is spread through academic papers featuring\nrich multimodal content, including text, diagrams, and tabular results.\nHowever, translating these multimodal elements into executable code remains a\nchallenging and time-consuming process that requires substantial ML expertise.\nWe introduce ``Paper-to-Code'' (P2C), a novel task that transforms the\nmultimodal content of scientific publications into fully executable code\nrepositories, which extends beyond the existing formulation of code generation\nthat merely converts textual descriptions into isolated code snippets. To\nautomate the P2C process, we propose AutoP2C, a multi-agent framework based on\nlarge language models that processes both textual and visual content from\nresearch papers to generate complete code repositories. Specifically, AutoP2C\ncontains four stages: (1) repository blueprint extraction from established\ncodebases, (2) multimodal content parsing that integrates information from\ntext, equations, and figures, (3) hierarchical task decomposition for\nstructured code generation, and (4) iterative feedback-driven debugging to\nensure functionality and performance. Evaluation on a benchmark of eight\nresearch papers demonstrates the effectiveness of AutoP2C, which can\nsuccessfully generate executable code repositories for all eight papers, while\nOpenAI-o1 or DeepSeek-R1 can only produce runnable code for one paper. The code\nis available at https://github.com/shoushouyu/Automated-Paper-to-Code.",
      "tldr_zh": "该研究引入了“Paper-to-Code (P2C)”任务，旨在将学术论文的多模态内容（如文本、图表和表格）转化为完整的可执行代码仓库，以解决手动转换的挑战。AutoP2C 是一个基于大型语言模型 (LLM) 的多智能体框架，包括四个阶段：从现有代码库提取仓库蓝图、多模态内容解析、层次化任务分解生成结构化代码，以及迭代反馈驱动调试以确保性能。实验在八篇论文的基准上显示，AutoP2C 成功为所有论文生成可执行代码，而基线模型如 OpenAI-o1 或 DeepSeek-R1 仅成功一份，证明了其有效性。代码已在 GitHub 上公开。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20115v1",
      "published_date": "2025-04-28 05:47:37 UTC",
      "updated_date": "2025-04-28 05:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:15.667122"
    },
    {
      "arxiv_id": "2504.19499v1",
      "title": "Graph Reinforcement Learning for QoS-Aware Load Balancing in Open Radio Access Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Omid Semiari",
        "Hosein Nikopour",
        "Shilpa Talwar"
      ],
      "abstract": "Next-generation wireless cellular networks are expected to provide\nunparalleled Quality-of-Service (QoS) for emerging wireless applications,\nnecessitating strict performance guarantees, e.g., in terms of link-level data\nrates. A critical challenge in meeting these QoS requirements is the prevention\nof cell congestion, which involves balancing the load to ensure sufficient\nradio resources are available for each cell to serve its designated User\nEquipments (UEs). In this work, a novel QoS-aware Load Balancing (LB) approach\nis developed to optimize the performance of Guaranteed Bit Rate (GBR) and Best\nEffort (BE) traffic in a multi-band Open Radio Access Network (O-RAN) under QoS\nand resource constraints. The proposed solution builds on Graph Reinforcement\nLearning (GRL), a powerful framework at the intersection of Graph Neural\nNetwork (GNN) and RL. The QoS-aware LB is modeled as a Markov Decision Process,\nwith states represented as graphs. QoS consideration are integrated into both\nstate representations and reward signal design. The LB agent is then trained\nusing an off-policy dueling Deep Q Network (DQN) that leverages a GNN-based\narchitecture. This design ensures the LB policy is invariant to the ordering of\nnodes (UE or cell), flexible in handling various network sizes, and capable of\naccounting for spatial node dependencies in LB decisions. Performance of the\nGRL-based solution is compared with two baseline methods. Results show\nsubstantial performance gains, including a $53\\%$ reduction in QoS violations\nand a fourfold increase in the 5th percentile rate for BE traffic.",
      "tldr_zh": "该论文提出了一种基于 Graph Reinforcement Learning (GRL) 的 QoS 感知负载平衡方法，针对 Open Radio Access Networks (O-RAN) 中 Guaranteed Bit Rate (GBR) 和 Best Effort (BE) 流量的优化，以防止蜂窝拥塞并满足严格的性能要求。方法将负载平衡建模为 Markov Decision Process (MDP)，使用 GNN 架构的 off-policy dueling Deep Q Network (DQN) 进行训练，集成 QoS 到状态表示和奖励设计中，确保对节点顺序不变并处理空间依赖。实验结果显示，与基线方法相比，该方案减少了 53% 的 QoS 违规，并将 BE 流量的 5th percentile 速率提高了四倍。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.NI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in the proceedings of the 2025 IEEE International\n  Conference on Communications (ICC), Seventh Workshop on Data Driven\n  Intelligence for Networks and Systems (DDINS)",
      "pdf_url": "http://arxiv.org/pdf/2504.19499v1",
      "published_date": "2025-04-28 05:41:31 UTC",
      "updated_date": "2025-04-28 05:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:28.765852"
    },
    {
      "arxiv_id": "2504.19496v1",
      "title": "DISCO: learning to DISCover an evolution Operator for multi-physics-agnostic prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Rudy Morel",
        "Jiequn Han",
        "Edouard Oyallon"
      ],
      "abstract": "We address the problem of predicting the next state of a dynamical system\ngoverned by unknown temporal partial differential equations (PDEs) using only a\nshort trajectory. While standard transformers provide a natural black-box\nsolution to this task, the presence of a well-structured evolution operator in\nthe data suggests a more tailored and efficient approach. Specifically, when\nthe PDE is fully known, classical numerical solvers can evolve the state\naccurately with only a few parameters. Building on this observation, we\nintroduce DISCO, a model that uses a large hypernetwork to process a short\ntrajectory and generate the parameters of a much smaller operator network,\nwhich then predicts the next state through time integration. Our framework\ndecouples dynamics estimation (i.e., DISCovering an evolution operator from a\nshort trajectory) from state prediction (i.e., evolving this operator).\nExperiments show that pretraining our model on diverse physics datasets\nachieves state-of-the-art performance while requiring significantly fewer\nepochs. Moreover, it generalizes well and remains competitive when fine-tuned\non downstream tasks.",
      "tldr_zh": "本篇论文针对未知时间偏微分方程（PDEs）控制的动态系统，提出DISCO模型，通过短轨迹学习一个多物理无关的演化算子，用于高效预测系统下一个状态。DISCO框架使用一个大型hypernetwork处理轨迹，生成小型operator network的参数，然后通过时间积分实现状态预测，从而解耦动态估计和状态演化过程。实验结果表明，该模型在多样物理数据集上预训练后，达到最先进性能，仅需更少训练周期，并在下游任务微调时保持出色泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19496v1",
      "published_date": "2025-04-28 05:36:52 UTC",
      "updated_date": "2025-04-28 05:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:46.991181"
    },
    {
      "arxiv_id": "2504.21036v2",
      "title": "Can Differentially Private Fine-tuning LLMs Protect Against Privacy Attacks?",
      "title_zh": "差分隐私微调大语言模型是否能防范隐私攻击？",
      "authors": [
        "Hao Du",
        "Shang Liu",
        "Yang Cao"
      ],
      "abstract": "Fine-tuning large language models (LLMs) has become an essential strategy for\nadapting them to specialized tasks; however, this process introduces\nsignificant privacy challenges, as sensitive training data may be inadvertently\nmemorized and exposed. Although differential privacy (DP) offers strong\ntheoretical guarantees against such leakage, its empirical privacy\neffectiveness on LLMs remains unclear, especially under different fine-tuning\nmethods. In this paper, we systematically investigate the impact of DP across\nfine-tuning methods and privacy budgets, using both data extraction and\nmembership inference attacks to assess empirical privacy risks. Our main\nfindings are as follows: (1) Differential privacy reduces model utility, but\nits impact varies significantly across different fine-tuning methods. (2)\nWithout DP, the privacy risks of models fine-tuned with different approaches\ndiffer considerably. (3) When DP is applied, even a relatively high privacy\nbudget can substantially lower privacy risk. (4) The privacy-utility trade-off\nunder DP training differs greatly among fine-tuning methods, with some methods\nbeing unsuitable for DP due to severe utility degradation. Our results provide\npractical guidance for privacy-conscious deployment of LLMs and pave the way\nfor future research on optimizing the privacy-utility trade-off in fine-tuning\nmethodologies.",
      "tldr_zh": "本研究探讨了差分隐私(DP)是否能有效保护微调大型语言模型(LLMs)免受隐私攻击，如数据提取和成员推理攻击。研究系统评估了DP在不同微调方法和隐私预算下的影响，发现DP虽然会降低模型效用，但其影响因微调方法而异，且即使较高隐私预算也能显著减少隐私风险。结果显示，没有DP时各微调方法的隐私风险差异大，而DP下的隐私-效用权衡因方法不同而悬殊，有些方法因效用严重下降而不适合使用。该工作为隐私意识强的LLMs部署提供实用指导，并为优化隐私-效用权衡的未来研究奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "accepted by DBSec25",
      "pdf_url": "http://arxiv.org/pdf/2504.21036v2",
      "published_date": "2025-04-28 05:34:53 UTC",
      "updated_date": "2025-05-01 10:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:35:57.336220"
    },
    {
      "arxiv_id": "2505.01440v1",
      "title": "Interactive Double Deep Q-network: Integrating Human Interventions and Evaluative Predictions in Reinforcement Learning of Autonomous Driving",
      "title_zh": "交互式双深度 Q 网络：整合人类干预和评估预测于自动驾驶强化学习",
      "authors": [
        "Alkis Sygkounas",
        "Ioannis Athanasiadis",
        "Andreas Persson",
        "Michael Felsberg",
        "Amy Loutfi"
      ],
      "abstract": "Integrating human expertise with machine learning is crucial for applications\ndemanding high accuracy and safety, such as autonomous driving. This study\nintroduces Interactive Double Deep Q-network (iDDQN), a Human-in-the-Loop\n(HITL) approach that enhances Reinforcement Learning (RL) by merging human\ninsights directly into the RL training process, improving model performance.\nOur proposed iDDQN method modifies the Q-value update equation to integrate\nhuman and agent actions, establishing a collaborative approach for policy\ndevelopment. Additionally, we present an offline evaluative framework that\nsimulates the agent's trajectory as if no human intervention had occurred, to\nassess the effectiveness of human interventions. Empirical results in simulated\nautonomous driving scenarios demonstrate that iDDQN outperforms established\napproaches, including Behavioral Cloning (BC), HG-DAgger, Deep Q-Learning from\nDemonstrations (DQfD), and vanilla DRL in leveraging human expertise for\nimproving performance and adaptability.",
      "tldr_zh": "这篇论文提出了 Interactive Double Deep Q-network (iDDQN)，一种 Human-in-the-Loop (HITL) 方法，将人类专家见解直接整合到 Reinforcement Learning (RL) 的自动驾驶训练中，以提升模型性能和安全性。iDDQN 通过修改 Q-value 更新方程来结合人类和代理动作，形成协作策略，并引入一个离线评估框架来模拟无干预轨迹，从而评估人类干预的有效性。在模拟自动驾驶场景的实验中，iDDQN 优于 Behavioral Cloning (BC)、HG-DAgger、Deep Q-Learning from Demonstrations (DQfD) 和传统 DRL 方法，显著提高了性能和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2025, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.01440v1",
      "published_date": "2025-04-28 05:25:18 UTC",
      "updated_date": "2025-04-28 05:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:36:10.152418"
    },
    {
      "arxiv_id": "2504.19483v1",
      "title": "Improving Reasoning Performance in Large Language Models via Representation Engineering",
      "title_zh": "通过表示工程改善大型语言模型的推理性能",
      "authors": [
        "Bertram Højer",
        "Oliver Jarvis",
        "Stefan Heinrich"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have resulted in\nincreasingly anthropomorphic language concerning the ability of LLMs to reason.\nWhether reasoning in LLMs should be understood to be inherently different is,\nhowever, widely debated. We propose utilizing a representation engineering\napproach wherein model activations are read from the residual stream of an LLM\nwhen processing a reasoning task. The activations are used to derive a control\nvector that is applied to the model as an inference-time intervention,\nmodulating the representational space of the model, to improve performance on\nthe specified task. We publish the code for deriving control vectors and\nanalyzing model representations. The method allows us to improve performance on\nreasoning benchmarks and assess how control vectors influence the final logit\ndistribution of a model via metrics such as KL divergence and entropy. We apply\ncontrol vectors to Mistral-7B-Instruct and a range of Pythia models on an\ninductive, a deductive and mathematical reasoning task. We show that an LLM\ncan, to a certain degree, be controlled to improve its perceived reasoning\nability by modulating activations. The intervention is dependent upon the\nability to reliably extract the model's typical state when correctly solving a\ntask. Our results suggest that reasoning performance can be modulated in the\nsame manner as other information-processing tasks performed by LLMs and\ndemonstrate that we are capable of improving performance on specific tasks via\na simple intervention on the residual stream with no additional training.",
      "tldr_zh": "这篇论文提出了一种representation engineering方法，通过读取大型语言模型(LLMs)的residual stream中的激活来派生控制向量，并作为推理时的干预，以调整模型的表示空间，从而提升其在推理任务上的性能。该方法无需额外训练，仅通过对激活进行调制，即可改善LLMs在归纳、演绎和数学推理基准上的表现，例如在Mistral-7B-Instruct和Pythia模型中观察到显著提升。实验结果显示，这种干预能有效降低KL divergence和entropy，证明推理能力可像其他信息处理任务一样被调控，并提供了相关代码以供分析模型表示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Has been accepted at \"The Thirteenth International Conference on\n  Learning Representations (ICLR 2025)\" Link to publication:\n  https://openreview.net/forum?id=IssPhpUsKt",
      "pdf_url": "http://arxiv.org/pdf/2504.19483v1",
      "published_date": "2025-04-28 04:58:43 UTC",
      "updated_date": "2025-04-28 04:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:36:21.990307"
    },
    {
      "arxiv_id": "2504.19480v1",
      "title": "An Automated Reinforcement Learning Reward Design Framework with Large Language Model for Cooperative Platoon Coordination",
      "title_zh": "翻译失败",
      "authors": [
        "Dixiao Wei",
        "Peng Yi",
        "Jinlong Lei",
        "Yiguang Hong",
        "Yuchuan Du"
      ],
      "abstract": "Reinforcement Learning (RL) has demonstrated excellent decision-making\npotential in platoon coordination problems. However, due to the variability of\ncoordination goals, the complexity of the decision problem, and the\ntime-consumption of trial-and-error in manual design, finding a well\nperformance reward function to guide RL training to solve complex platoon\ncoordination problems remains challenging. In this paper, we formally define\nthe Platoon Coordination Reward Design Problem (PCRDP), extending the RL-based\ncooperative platoon coordination problem to incorporate automated reward\nfunction generation. To address PCRDP, we propose a Large Language Model\n(LLM)-based Platoon coordination Reward Design (PCRD) framework, which\nsystematically automates reward function discovery through LLM-driven\ninitialization and iterative optimization. In this method, LLM first\ninitializes reward functions based on environment code and task requirements\nwith an Analysis and Initial Reward (AIR) module, and then iteratively\noptimizes them based on training feedback with an evolutionary module. The AIR\nmodule guides LLM to deepen their understanding of code and tasks through a\nchain of thought, effectively mitigating hallucination risks in code\ngeneration. The evolutionary module fine-tunes and reconstructs the reward\nfunction, achieving a balance between exploration diversity and convergence\nstability for training. To validate our approach, we establish six challenging\ncoordination scenarios with varying complexity levels within the Yangtze River\nDelta transportation network simulation. Comparative experimental results\ndemonstrate that RL agents utilizing PCRD-generated reward functions\nconsistently outperform human-engineered reward functions, achieving an average\nof 10\\% higher performance metrics in all scenarios.",
      "tldr_zh": "本文定义了 Platoon Coordination Reward Design Problem (PCRDP)，旨在解决强化学习 (RL) 在车队协调中的奖励函数设计挑战，通过自动化生成适应复杂目标的奖励函数。提出 Large Language Model (LLM)-based PCRD 框架，包括 Analysis and Initial Reward (AIR) 模块用于基于环境代码和任务需求初始化奖励函数，以及进化模块通过训练反馈迭代优化，以平衡探索多样性和收敛稳定性。实验在长江三角洲交通网络的六种复杂场景中验证，RL 代理使用 PCRD 生成的奖励函数比人工设计高出平均 10% 的性能指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19480v1",
      "published_date": "2025-04-28 04:41:15 UTC",
      "updated_date": "2025-04-28 04:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:36:34.080191"
    },
    {
      "arxiv_id": "2504.19475v1",
      "title": "Prisma: An Open Source Toolkit for Mechanistic Interpretability in Vision and Video",
      "title_zh": "翻译失败",
      "authors": [
        "Sonia Joseph",
        "Praneet Suresh",
        "Lorenz Hufe",
        "Edward Stevinson",
        "Robert Graham",
        "Yash Vadi",
        "Danilo Bzdok",
        "Sebastian Lapuschkin",
        "Lee Sharkey",
        "Blake Aaron Richards"
      ],
      "abstract": "Robust tooling and publicly available pre-trained models have helped drive\nrecent advances in mechanistic interpretability for language models. However,\nsimilar progress in vision mechanistic interpretability has been hindered by\nthe lack of accessible frameworks and pre-trained weights. We present Prisma\n(Access the codebase here: https://github.com/Prisma-Multimodal/ViT-Prisma), an\nopen-source framework designed to accelerate vision mechanistic\ninterpretability research, providing a unified toolkit for accessing 75+ vision\nand video transformers; support for sparse autoencoder (SAE), transcoder, and\ncrosscoder training; a suite of 80+ pre-trained SAE weights; activation\ncaching, circuit analysis tools, and visualization tools; and educational\nresources. Our analysis reveals surprising findings, including that effective\nvision SAEs can exhibit substantially lower sparsity patterns than language\nSAEs, and that in some instances, SAE reconstructions can decrease model loss.\nPrisma enables new research directions for understanding vision model internals\nwhile lowering barriers to entry in this emerging field.",
      "tldr_zh": "该研究介绍了Prisma，一个开源工具包，旨在加速视觉和视频领域的机制解释性(Mechanistic Interpretability)研究，以弥补语言模型领域进步的差距。Prisma提供对75+视觉和视频变压器的访问，支持Sparse Autoencoder (SAE)、Transcoder和Crosscoder的训练，并包括80+预训练SAE权重、激活缓存、电路分析工具、可视化工具和教育资源。研究发现，有效的视觉SAE显示出比语言SAE更低的稀疏性模式，并在某些情况下降低模型损失，从而为理解视觉模型内部机制和推动新研究方向提供了便利。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 3 figures, 9 tables. Oral and Tutorial at the CVPR\n  Mechanistic Interpretability for Vision (MIV) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.19475v1",
      "published_date": "2025-04-28 04:31:24 UTC",
      "updated_date": "2025-04-28 04:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:36:45.495206"
    },
    {
      "arxiv_id": "2504.19467v2",
      "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text",
      "title_zh": "BRIDGE：大语言模型理解真实世界临床实践文本的基准测试",
      "authors": [
        "Jiageng Wu",
        "Bowen Gu",
        "Ren Zhou",
        "Kevin Xie",
        "Doug Snyder",
        "Yixing Jiang",
        "Valentina Carducci",
        "Richard Wyss",
        "Rishi J Desai",
        "Emily Alsentzer",
        "Leo Anthony Celi",
        "Adam Rodman",
        "Sebastian Schneeweiss",
        "Jonathan H. Chen",
        "Santiago Romero-Brufau",
        "Kueiyu Joshua Lin",
        "Jie Yang"
      ],
      "abstract": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, current evaluations of LLMs in clinical contexts remain limited. Most\nexisting benchmarks rely on medical exam-style questions or PubMed-derived\ntext, failing to capture the complexity of real-world electronic health record\n(EHR) data. Others focus narrowly on specific application scenarios, limiting\ntheir generalizability across broader clinical use. To address this gap, we\npresent BRIDGE, a comprehensive multilingual benchmark comprising 87 tasks\nsourced from real-world clinical data sources across nine languages. We\nsystematically evaluated 52 state-of-the-art LLMs (including DeepSeek-R1,\nGPT-4o, Gemini, and Llama 4) under various inference strategies. With a total\nof 13,572 experiments, our results reveal substantial performance variation\nacross model sizes, languages, natural language processing tasks, and clinical\nspecialties. Notably, we demonstrate that open-source LLMs can achieve\nperformance comparable to proprietary models, while medically fine-tuned LLMs\nbased on older architectures often underperform versus updated general-purpose\nmodels. The BRIDGE and its corresponding leaderboard serve as a foundational\nresource and a unique reference for the development and evaluation of new LLMs\nin real-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard",
      "tldr_zh": "本研究引入了 BRIDGE，这是一个全面的多语言基准，用于评估大型语言模型 (LLMs) 在理解真实临床实践文本方面的性能，以填补现有评估的局限性，如依赖医疗考试问题或 PubMed 文本而忽略电子健康记录 (EHR) 数据的复杂性。BRIDGE 包含 87 个任务，源自真实临床数据并覆盖九种语言，系统评估了 52 个最先进 LLMs（如 DeepSeek-R1、GPT-4o、Gemini 和 Llama 4）共 13,572 次实验。结果显示，模型性能在大小、语言、自然语言处理 (NLP) 任务和临床专业领域间存在显著差异，开源 LLMs 可与专有模型匹敌，而基于旧架构的医疗微调 LLMs 往往不如更新的通用模型。BRIDGE 及其排行榜（https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard）作为关键资源，支持未来 LLMs 在临床文本理解领域的开发和评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19467v2",
      "published_date": "2025-04-28 04:13:18 UTC",
      "updated_date": "2025-05-01 02:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:36:59.885321"
    },
    {
      "arxiv_id": "2504.19460v1",
      "title": "A Real-Time Gesture-Based Control Framework",
      "title_zh": "实时手势控制框架",
      "authors": [
        "Mahya Khazaei",
        "Ali Bahrani",
        "George Tzanetakis"
      ],
      "abstract": "We introduce a real-time, human-in-the-loop gesture control framework that\ncan dynamically adapt audio and music based on human movement by analyzing live\nvideo input. By creating a responsive connection between visual and auditory\nstimuli, this system enables dancers and performers to not only respond to\nmusic but also influence it through their movements. Designed for live\nperformances, interactive installations, and personal use, it offers an\nimmersive experience where users can shape the music in real time.\n  The framework integrates computer vision and machine learning techniques to\ntrack and interpret motion, allowing users to manipulate audio elements such as\ntempo, pitch, effects, and playback sequence. With ongoing training, it\nachieves user-independent functionality, requiring as few as 50 to 80 samples\nto label simple gestures. This framework combines gesture training, cue\nmapping, and audio manipulation to create a dynamic, interactive experience.\nGestures are interpreted as input signals, mapped to sound control commands,\nand used to naturally adjust music elements, showcasing the seamless interplay\nbetween human interaction and machine response.",
      "tldr_zh": "这篇论文提出了一种实时手势控制框架，通过分析实时视频输入，利用computer vision和machine learning技术来跟踪并解释人类动作，从而动态调整音频元素如tempo、pitch、效果和播放序列。框架允许用户（如舞者和表演者）不仅响应音乐，还能通过手势实时影响它，实现沉浸式互动体验。实验结果显示，该系统只需50到80个样本即可训练简单手势，并实现用户无关的功能，适用于现场表演、互动装置和个人使用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 4 figures, 2025 International Computer Music Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.19460v1",
      "published_date": "2025-04-28 03:57:28 UTC",
      "updated_date": "2025-04-28 03:57:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:37:09.561320"
    },
    {
      "arxiv_id": "2504.19457v1",
      "title": "Towards Long Context Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Siyi Liu",
        "Kishaloy Halder",
        "Zheng Qi",
        "Wei Xiao",
        "Nikolaos Pappas",
        "Phu Mon Htut",
        "Neha Anna John",
        "Yassine Benajiba",
        "Dan Roth"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. However, they are prone to contextual hallucination, generating\ninformation that is either unsubstantiated or contradictory to the given\ncontext. Although many studies have investigated contextual hallucinations in\nLLMs, addressing them in long-context inputs remains an open problem. In this\nwork, we take an initial step toward solving this problem by constructing a\ndataset specifically designed for long-context hallucination detection.\nFurthermore, we propose a novel architecture that enables pre-trained encoder\nmodels, such as BERT, to process long contexts and effectively detect\ncontextual hallucinations through a decomposition and aggregation mechanism.\nOur experimental results show that the proposed architecture significantly\noutperforms previous models of similar size as well as LLM-based models across\nvarious metrics, while providing substantially faster inference.",
      "tldr_zh": "大语言模型 (LLMs) 容易在长上下文输入中产生幻觉 (hallucination)，即生成与给定上下文不符的信息，但针对长上下文的检测问题仍未解决。  \n本文构建了一个专门设计的长上下文幻觉检测数据集，并提出了一种新架构，利用预训练编码器模型如 BERT 通过分解和聚合机制处理长上下文并有效检测幻觉。  \n实验结果表明，该架构在各种指标上显著优于类似大小的先前模型和基于 LLM 的模型，同时提供更快的推理速度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19457v1",
      "published_date": "2025-04-28 03:47:05 UTC",
      "updated_date": "2025-04-28 03:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:37:21.696162"
    },
    {
      "arxiv_id": "2504.19443v1",
      "title": "CLIP-KOA: Enhancing Knee Osteoarthritis Diagnosis with Multi-Modal Learning and Symmetry-Aware Loss Functions",
      "title_zh": "CLIP-KOA：利用多模态学习和对称感知损失函数增强膝关节骨关节炎诊断",
      "authors": [
        "Yejin Jeong",
        "Donghun Lee"
      ],
      "abstract": "Knee osteoarthritis (KOA) is a universal chronic musculoskeletal disorders\nworldwide, making early diagnosis crucial. Currently, the Kellgren and Lawrence\n(KL) grading system is widely used to assess KOA severity. However, its high\ninter-observer variability and subjectivity hinder diagnostic consistency. To\naddress these limitations, automated diagnostic techniques using deep learning\nhave been actively explored in recent years. In this study, we propose a\nCLIP-based framework (CLIP-KOA) to enhance the consistency and reliability of\nKOA grade prediction. To achieve this, we introduce a learning approach that\nintegrates image and text information and incorporate Symmetry Loss and\nConsistency Loss to ensure prediction consistency between the original and\nflipped images. CLIP-KOA achieves state-of-the-art accuracy of 71.86\\% on KOA\nseverity prediction task, and ablation studies show that CLIP-KOA has 2.36\\%\nimprovement in accuracy over the standard CLIP model due to our contribution.\nThis study shows a novel direction for data-driven medical prediction not only\nto improve reliability of fine-grained diagnosis and but also to explore\nmultimodal methods for medical image analysis. Our code is available at\nhttps://github.com/anonymized-link.",
      "tldr_zh": "本研究针对膝关节骨关节炎（KOA）的诊断问题，提出CLIP-KOA框架，该框架利用多模态学习整合图像和文本信息，并引入Symmetry Loss和Consistency Loss函数，以确保预测结果在原始和翻转图像间的consistency和可靠性。相比标准CLIP模型，CLIP-KOA在KOA严重程度预测任务上实现了71.86%的state-of-the-art准确率，并提升了2.36%的性能。该方法不仅提高了细粒度诊断的可靠性，还为多模态医疗图像分析开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19443v1",
      "published_date": "2025-04-28 03:10:24 UTC",
      "updated_date": "2025-04-28 03:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:37:33.547205"
    },
    {
      "arxiv_id": "2504.19432v1",
      "title": "EarthMapper: Visual Autoregressive Models for Controllable Bidirectional Satellite-Map Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Dong",
        "Yuzhe Sun",
        "Tianzhu Liu",
        "Wangmeng Zuo",
        "Yanfeng Gu"
      ],
      "abstract": "Satellite imagery and maps, as two fundamental data modalities in remote\nsensing, offer direct observations of the Earth's surface and\nhuman-interpretable geographic abstractions, respectively. The task of\nbidirectional translation between satellite images and maps (BSMT) holds\nsignificant potential for applications in urban planning and disaster response.\nHowever, this task presents two major challenges: first, the absence of precise\npixel-wise alignment between the two modalities substantially complicates the\ntranslation process; second, it requires achieving both high-level abstraction\nof geographic features and high-quality visual synthesis, which further\nelevates the technical complexity. To address these limitations, we introduce\nEarthMapper, a novel autoregressive framework for controllable bidirectional\nsatellite-map translation. EarthMapper employs geographic coordinate embeddings\nto anchor generation, ensuring region-specific adaptability, and leverages\nmulti-scale feature alignment within a geo-conditioned joint scale\nautoregression (GJSA) process to unify bidirectional translation in a single\ntraining cycle. A semantic infusion (SI) mechanism is introduced to enhance\nfeature-level consistency, while a key point adaptive guidance (KPAG) mechanism\nis proposed to dynamically balance diversity and precision during inference. We\nfurther contribute CNSatMap, a large-scale dataset comprising 302,132 precisely\naligned satellite-map pairs across 38 Chinese cities, enabling robust\nbenchmarking. Extensive experiments on CNSatMap and the New York dataset\ndemonstrate EarthMapper's superior performance, achieving significant\nimprovements in visual realism, semantic consistency, and structural fidelity\nover state-of-the-art methods. Additionally, EarthMapper excels in zero-shot\ntasks like in-painting, out-painting and coordinate-conditional generation,\nunderscoring its versatility.",
      "tldr_zh": "本文提出 EarthMapper，一种视觉自回归模型，用于可控双向卫星-地图翻译（Bidirectional Satellite-Map Translation），旨在解决模式之间缺乏像素级对齐和需要高水平地理特征抽象的挑战。EarthMapper 通过地理坐标嵌入（geographic coordinate embeddings）和地理条件联合尺度自回归（GJSA）机制统一双向翻译过程，并引入语义注入（SI）和关键点自适应指导（KPAG）来增强特征一致性和生成平衡。研究者贡献了 CNSatMap 数据集，包含 302,132 对精确对齐的卫星-地图图像，覆盖 38 个中国城市。实验结果显示，EarthMapper 在 CNSatMap 和 New York 数据集上显著提升视觉真实性、语义一致性和结构保真度，并在零样本任务如 in-painting 和 out-painting 中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19432v1",
      "published_date": "2025-04-28 02:41:12 UTC",
      "updated_date": "2025-04-28 02:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:37:48.217152"
    },
    {
      "arxiv_id": "2504.19426v1",
      "title": "Sharp higher order convergence rates for the Adam optimizer",
      "title_zh": "翻译失败",
      "authors": [
        "Steffen Dereich",
        "Arnulf Jentzen",
        "Adrian Riekert"
      ],
      "abstract": "Gradient descent based optimization methods are the methods of choice to\ntrain deep neural networks in machine learning. Beyond the standard gradient\ndescent method, also suitable modified variants of standard gradient descent\ninvolving acceleration techniques such as the momentum method and/or adaptivity\ntechniques such as the RMSprop method are frequently considered optimization\nmethods. These days the most popular of such sophisticated optimization schemes\nis presumably the Adam optimizer that has been proposed in 2014 by Kingma and\nBa. A highly relevant topic of research is to investigate the speed of\nconvergence of such optimization methods. In particular, in 1964 Polyak showed\nthat the standard gradient descent method converges in a neighborhood of a\nstrict local minimizer with rate (x - 1)(x + 1)^{-1} while momentum achieves\nthe (optimal) strictly faster convergence rate (\\sqrt{x} - 1)(\\sqrt{x} +\n1)^{-1} where x \\in (1,\\infty) is the condition number (the ratio of the\nlargest and the smallest eigenvalue) of the Hessian of the objective function\nat the local minimizer. It is the key contribution of this work to reveal that\nAdam also converges with the strictly faster convergence rate (\\sqrt{x} -\n1)(\\sqrt{x} + 1)^{-1} while RMSprop only converges with the convergence rate (x\n- 1)(x + 1)^{-1}.",
      "tldr_zh": "这篇论文分析了Adam优化器的收敛率，证明其在严格局部最小点附近具有更快的更高阶收敛速度，具体为(\\sqrt{x} - 1)(\\sqrt{x} + 1)^{-1}，其中x是目标函数Hessian的条件数。相比之下，标准gradient descent的收敛率为(x - 1)(x + 1)^{-1}，而RMSprop仅达到相同的收敛率。研究通过比较这些优化方法，为训练深度神经网络提供了更精确的收敛率分析和优化指导。",
      "categories": [
        "math.OC",
        "cs.AI",
        "68T05, 65K05, 90C25",
        "I.2.0"
      ],
      "primary_category": "math.OC",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.19426v1",
      "published_date": "2025-04-28 02:17:50 UTC",
      "updated_date": "2025-04-28 02:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:37:59.830319"
    },
    {
      "arxiv_id": "2504.20114v2",
      "title": "TreeHop: Generate and Filter Next Query Embeddings Efficiently for Multi-hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghao Li",
        "Kunpeng Zhang",
        "Jinghuai Ou",
        "Shuliang Liu",
        "Xuming Hu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems face significant challenges in\nmulti-hop question answering (MHQA), where complex queries require synthesizing\ninformation across multiple document chunks. Existing approaches typically rely\non iterative LLM-based query rewriting and routing, resulting in high\ncomputational costs due to repeated LLM invocations and multi-stage processes.\nTo address these limitations, we propose TreeHop, an embedding-level framework\nwithout the need for LLMs in query refinement. TreeHop dynamically updates\nquery embeddings by fusing semantic information from prior queries and\nretrieved documents, enabling iterative retrieval through embedding-space\noperations alone. This method replaces the traditional\n\"Retrieve-Rewrite-Vectorize-Retrieve\" cycle with a streamlined\n\"Retrieve-Embed-Retrieve\" loop, significantly reducing computational overhead.\nMoreover, a rule-based stop criterion is introduced to further prune redundant\nretrievals, balancing efficiency and recall rate. Experimental results show\nthat TreeHop rivals advanced RAG methods across three open-domain MHQA\ndatasets, achieving comparable performance with only 5\\%-0.4\\% of the model\nparameter size and reducing the query latency by approximately 99\\% compared to\nconcurrent approaches. This makes TreeHop a faster and more cost-effective\nsolution for deployment in a range of knowledge-intensive applications. For\nreproducibility purposes, codes and data are available here:\nhttps://github.com/allen-li1231/TreeHop-RAG.",
      "tldr_zh": "本研究提出TreeHop，一种高效的嵌入级框架，用于解决Retrieval-augmented generation (RAG)系统在多跳问答(MHQA)中的高计算成本问题，该框架无需LLM参与，直接通过融合先前的查询和检索文档的语义信息来动态更新查询嵌入。TreeHop将传统的“Retrieve-Rewrite-Vectorize-Retrieve”循环简化为“Retrieve-Embed-Retrieve”流程，并引入基于规则的停止标准以减少冗余检索，从而显著提升效率。实验结果显示，TreeHop在三个开放域MHQA数据集上与先进RAG方法性能相当，但模型参数大小仅为其5%-0.4%，查询延迟降低约99%，使其成为知识密集型应用的更快、更具成本效益的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20114v2",
      "published_date": "2025-04-28 01:56:31 UTC",
      "updated_date": "2025-04-30 13:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:38:09.949194"
    },
    {
      "arxiv_id": "2504.19413v1",
      "title": "Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Chhikara",
        "Dev Khant",
        "Saket Aryan",
        "Taranjeet Singh",
        "Deshraj Yadav"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable prowess in\ngenerating contextually coherent responses, yet their fixed context windows\npose fundamental challenges for maintaining consistency over prolonged\nmulti-session dialogues. We introduce Mem0, a scalable memory-centric\narchitecture that addresses this issue by dynamically extracting,\nconsolidating, and retrieving salient information from ongoing conversations.\nBuilding on this foundation, we further propose an enhanced variant that\nleverages graph-based memory representations to capture complex relational\nstructures among conversational elements. Through comprehensive evaluations on\nLOCOMO benchmark, we systematically compare our approaches against six baseline\ncategories: (i) established memory-augmented systems, (ii) retrieval-augmented\ngeneration (RAG) with varying chunk sizes and k-values, (iii) a full-context\napproach that processes the entire conversation history, (iv) an open-source\nmemory solution, (v) a proprietary model system, and (vi) a dedicated memory\nmanagement platform. Empirical results show that our methods consistently\noutperform all existing memory systems across four question categories:\nsingle-hop, temporal, multi-hop, and open-domain. Notably, Mem0 achieves 26%\nrelative improvements in the LLM-as-a-Judge metric over OpenAI, while Mem0 with\ngraph memory achieves around 2% higher overall score than the base\nconfiguration. Beyond accuracy gains, we also markedly reduce computational\noverhead compared to full-context method. In particular, Mem0 attains a 91%\nlower p95 latency and saves more than 90% token cost, offering a compelling\nbalance between advanced reasoning capabilities and practical deployment\nconstraints. Our findings highlight critical role of structured, persistent\nmemory mechanisms for long-term conversational coherence, paving the way for\nmore reliable and efficient LLM-driven AI agents.",
      "tldr_zh": "本文提出 Mem0，一种可扩展的内存中心架构，旨在解决 Large Language Models (LLMs) 在长期对话中因固定上下文窗口而导致的一致性问题，通过动态提取、整合和检索关键信息来提升多会话对话的连贯性。Mem0 的增强版本引入基于图的内存表示，以捕捉对话元素间的复杂关系。在 LOCOMO 基准测试中，Mem0 相较于六类基线（如 RAG 系统和全上下文方法）在单跳、时间、多跳及开放域问题上表现优异，实现 26% 的 LLM-as-a-Judge 指标相对提升，并将计算开销降低 91% 的 p95 延迟和 90% 的令牌成本。该框架为构建可靠、高效的 LLM 驱动 AI 代理提供了实用基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19413v1",
      "published_date": "2025-04-28 01:46:35 UTC",
      "updated_date": "2025-04-28 01:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:38:22.426815"
    },
    {
      "arxiv_id": "2504.19409v2",
      "title": "GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field",
      "title_zh": "GSFF-SLAM：基于特征",
      "authors": [
        "Zuxing Lu",
        "Xin Yuan",
        "Shaowen Yang",
        "Jingyu Liu",
        "Changyin Sun"
      ],
      "abstract": "Semantic-aware 3D scene reconstruction is essential for autonomous robots to\nperform complex interactions. Semantic SLAM, an online approach, integrates\npose tracking, geometric reconstruction, and semantic mapping into a unified\nframework, shows significant potential. However, existing systems, which rely\non 2D ground truth priors for supervision, are often limited by the sparsity\nand noise of these signals in real-world environments. To address this\nchallenge, we propose GSFF-SLAM, a novel dense semantic SLAM system based on 3D\nGaussian Splatting that leverages feature fields to achieve joint rendering of\nappearance, geometry, and N-dimensional semantic features. By independently\noptimizing feature gradients, our method supports semantic reconstruction using\nvarious forms of 2D priors, particularly sparse and noisy signals. Experimental\nresults demonstrate that our approach outperforms previous methods in both\ntracking accuracy and photorealistic rendering quality. When utilizing 2D\nground truth priors, GSFF-SLAM achieves state-of-the-art semantic segmentation\nperformance with 95.03\\% mIoU, while achieving up to 2.9$\\times$ speedup with\nonly marginal performance degradation.",
      "tldr_zh": "该研究提出GSFF-SLAM，一种基于3D Gaussian Splatting的密集语义SLAM系统，利用feature fields实现外观、几何和N维语义特征的联合渲染，以解决现有系统依赖稀疏嘈杂的2D先验信号的问题。  \n通过独立优化特征梯度，该方法支持各种形式的2D先验，提升了语义重建的鲁棒性和效率。  \n实验结果表明，GSFF-SLAM在跟踪准确性和逼真渲染质量上优于先前方法，使用2D地面实况先验时达到95.03% mIoU的语义分割性能，并实现高达2.9倍的速度提升，同时性能下降很小。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19409v2",
      "published_date": "2025-04-28 01:21:35 UTC",
      "updated_date": "2025-05-16 23:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:38:34.524675"
    },
    {
      "arxiv_id": "2504.20113v1",
      "title": "Transforming Evidence Synthesis: A Systematic Review of the Evolution of Automated Meta-Analysis in the Age of AI",
      "title_zh": "转变证据合成：AI 时代自动化元分析演变的系统综述",
      "authors": [
        "Lingbo Li",
        "Anuradha Mathrani",
        "Teo Susnjak"
      ],
      "abstract": "Exponential growth in scientific literature has heightened the demand for\nefficient evidence-based synthesis, driving the rise of the field of Automated\nMeta-analysis (AMA) powered by natural language processing and machine\nlearning. This PRISMA systematic review introduces a structured framework for\nassessing the current state of AMA, based on screening 978 papers from 2006 to\n2024, and analyzing 54 studies across diverse domains. Findings reveal a\npredominant focus on automating data processing (57%), such as extraction and\nstatistical modeling, while only 17% address advanced synthesis stages. Just\none study (2%) explored preliminary full-process automation, highlighting a\ncritical gap that limits AMA's capacity for comprehensive synthesis. Despite\nrecent breakthroughs in large language models (LLMs) and advanced AI, their\nintegration into statistical modeling and higher-order synthesis, such as\nheterogeneity assessment and bias evaluation, remains underdeveloped. This has\nconstrained AMA's potential for fully autonomous meta-analysis. From our\ndataset spanning medical (67%) and non-medical (33%) applications, we found\nthat AMA has exhibited distinct implementation patterns and varying degrees of\neffectiveness in actually improving efficiency, scalability, and\nreproducibility. While automation has enhanced specific meta-analytic tasks,\nachieving seamless, end-to-end automation remains an open challenge. As AI\nsystems advance in reasoning and contextual understanding, addressing these\ngaps is now imperative. Future efforts must focus on bridging automation across\nall meta-analysis stages, refining interpretability, and ensuring\nmethodological robustness to fully realize AMA's potential for scalable,\ndomain-agnostic synthesis.",
      "tldr_zh": "这篇论文通过 PRISMA 系统综述，评估了 2006-2024 年 Automated Meta-Analysis (AMA) 的演变，筛选了 978 篇论文并分析了 54 篇跨领域研究。结果显示，AMA 主要聚焦于数据处理（如提取和统计建模），占 57%，而高级综合阶段（如异质性评估和偏差评估）仅占 17%，且仅有 2% 的研究探索了全过程自动化，暴露了关键空白。Large Language Models (LLMs) 和 AI 技术的整合仍不充分，限制了 AMA 在效率、可扩展性和可重复性方面的潜力。尽管在医疗（67%）和非医疗（33%）应用中显示出不同效果，实现端到端自动化仍是挑战，未来需加强跨阶段桥接和方法学稳健性以实现可扩展的证据综合。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20113v1",
      "published_date": "2025-04-28 00:40:17 UTC",
      "updated_date": "2025-04-28 00:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:38:48.032192"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 111,
  "processed_papers_count": 111,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T17:39:07.488482"
}