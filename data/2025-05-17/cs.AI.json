{
  "date": "2025-05-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-17 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 领域的创新，特别是大型语言模型（LLMs）的推理优化、多代理系统和视频生成技术，强调高效计算和鲁棒性。其中，令人印象深刻的文章包括“LLM-BABYBENCH”对 LLM 基础智能的基准测试，以及“ARC-AGI-2”对前沿 AI 推理系统的挑战；知名学者如 Marta Kwiatkowska 在强化学习和概率逻辑方面的论文也值得关注，这些工作推动了 AI 在实际应用中的潜力。\n\n下面，我将挑选并讨论部分关键论文，先从热门主题如 LLM 代理和视频生成入手，再简要概述其他相关工作。对于篇幅有限的论文，我会快速掠过，只突出核心贡献。\n\n### LLM 推理和代理系统\n- **LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs**（英文原题：LLM-BABYBENCH）  \n  这篇论文引入了一个新基准测试套件，评估 LLMs 在交互环境中进行规划和推理的能力，包括预测、规划和分解任务。贡献在于构建了基于文本网格世界的数据集，并提供标准化评估框架，实验显示现有 LLMs 在这些任务中面临挑战，促进了 LLM 代理的开发。\n\n- **SAINT: Attention-Based Modeling of Sub-Action Dependencies in Multi-Action Policies**（英文原题：SAINT）  \n  作者提出了一种基于 Transformer 的策略架构，用于处理多子动作的依赖关系。关键发现是 SAINT 在 15 个组合环境（包括近 1700 万动作）中超越基线，提升了强化学习的样本效率和鲁棒性。\n\n- **Learning Probabilistic Temporal Logic Specifications for Stochastic Systems**（英文原题：Learning Probabilistic Temporal Logic Specifications for Stochastic Systems）  \n  Marta Kwiatkowska 等学者的工作聚焦于从马尔科夫链中推断概率 LTL 公式。贡献包括一个新算法，用于强化学习和形式验证中的规范学习，实验证明其在处理随机系统时高效且简洁。\n\n- **Improving Fairness in LLMs Through Testing-Time Adversaries**（英文原题：Improving Fairness in LLMs Through Testing-Time Adversaries）  \n  这篇论文提出了一种测试时攻击方法来提升 LLM 的公平性，通过修改句子属性检测偏差。发现能在不需训练的情况下显著减少种族歧视，Llama3 的公平指标提升达 27%。\n\n其他 LLM 相关论文如“ABoN: Adaptive Best-of-N Alignment”和“RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework”也探索了自适应优化，但核心在于提升推理效率，我这里快速掠过：它们分别通过强化学习优化提示和规划路径，提高了 LLM 在复杂任务中的性能。\n\n### 视频生成和处理\n- **SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds**（英文原题：SoftPQ）  \n  作者改进实例分割评估指标，引入软匹配和可调阈值，解决了传统 IoU 的二元局限。贡献在于新指标 SoftPQ 更能捕捉细微错误，提供平滑反馈，实验显示其在鲁棒性和模型迭代中优于传统方法。\n\n- **EarthSynth: Generating Informative Earth Observation with Diffusion Models**（英文原题：EarthSynth）  \n  这篇论文首次探索遥感图像的多任务生成，使用扩散模型合成多类别遥感数据。关键发现是通过 Counterfactual Composition 策略提升数据多样性，并在分类、检测和分割任务中实现 SOTA 性能。\n\n- **VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption**（英文原题：VFRTok）  \n  作者提出一个可变帧率视频标记器，基于时长比例信息假设优化编码。贡献包括 Partial Rotary Position Embeddings，提升视频生成效率，实验显示其在视频重建和生成中仅用 1/8 标记器即可达到竞争性能。\n\n视频领域的其他论文如“Diffmv”和“DraftAttention”则聚焦扩散模型的鲁棒性，我快速掠过：它们通过噪声处理和注意力指导加速视频生成，但整体影响不如上述几篇显著。\n\n### 其他 AI 应用和优化\n- **HARDMath2: A Benchmark for Applied Mathematics Built by Students as Part of a Graduate Class**（英文原题：HARDMath2）  \n  这篇论文构建了一个新数学基准，由学生参与设计，覆盖非线性 PDE 和渐近分析。贡献在于提供更精细的评估框架，实验显示前沿模型在实际数学问题上仍落后人类。\n\n- **GeoMaNO: Geometric Mamba Neural Operator for Partial Differential Equations**（英文原题：GeoMaNO）  \n  作者提出基于 Mamba 的神经算子框架，用于 PDE 求解。发现其在几何约束下提升了准确性，实验在多个基准上超越基线达 58.9%。\n\n其余论文如“TDFormer”和“SepPrune”涉及时间序列和剪枝优化，我快速掠过：它们分别在交通预测和语音分离中提升效率，但主题较窄，不如 LLM 和视频生成那样有广泛话题度。\n\n总体而言，今天的 arXiv 论文展示了 AI 领域的多样创新，LLM 代理和视频生成是亮点，强调了高效推理和实际应用潜力。未来几天，关注这些方向的进展将更有价值！",
  "papers": [
    {
      "arxiv_id": "2505.13522v1",
      "title": "A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Nathalie Sanghikian",
        "Rafael Meirelles",
        "Rafael Martinelli",
        "Anand Subramanian"
      ],
      "abstract": "Maritime Inventory Routing Problem (MIRP) plays a crucial role in the\nintegration of global maritime commerce levels. However, there are still no\nwell-established methodologies capable of efficiently solving large MIRP\ninstances or their variants due to the high complexity of the problem. The\nadoption of exact methods, typically based on Mixed Integer Programming (MIP),\nfor daily operations is nearly impractical due to the CPU time required, as\nplanning must be executed multiple times while ensuring high-quality results\nwithin acceptable time limits. Non-MIP-based heuristics are less frequently\napplied due to the highly constrained nature of the problem, which makes even\nthe construction of an effective initial solution challenging. Papageorgiou et\nal. (2014) introduced a single-product MIRP as the foundation for MIRPLib,\naiming to provide a collection of publicly available benchmark instances.\nHowever, only a few studies that propose new methodologies have been published\nsince then. To encourage the use of MIRPLib and facilitate result comparisons,\nthis study presents a heuristic approach that does not rely on mathematical\noptimization techniques to solve a deterministic, finite-horizon,\nsingle-product MIRP. The proposed heuristic combines a variation of a Beam\nSearch algorithm with an Iterated Local Search procedure. Among the 72\ninstances tested, the developed methodology can improve the best-known solution\nfor ten instances within an acceptable CPU time.",
      "tldr_zh": "本研究针对Maritime Inventory Routing Problem (MIRP) 的高复杂度问题，提出了一种不依赖数学优化技术的启发式算法，以解决现有方法如Mixed Integer Programming (MIP) 在日常操作中耗时过长的问题。该算法结合了Beam Search 的变体和Iterated Local Search 程序，能够高效构建初始解并优化结果。在72个测试实例中，该方法在可接受的CPU 时间内改进了10个实例的最佳已知解，从而促进MIRPLib 的使用和结果比较。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13522v1",
      "published_date": "2025-05-17 22:40:36 UTC",
      "updated_date": "2025-05-17 22:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:16:12.155014"
    },
    {
      "arxiv_id": "2505.12155v1",
      "title": "SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds",
      "title_zh": "SoftPQ：通过软匹配和可调阈值的鲁棒实例分割评估",
      "authors": [
        "Ranit Karmakar",
        "Simon F. Nørrelykke"
      ],
      "abstract": "Segmentation evaluation metrics traditionally rely on binary decision logic:\npredictions are either correct or incorrect, based on rigid IoU thresholds.\nDetection--based metrics such as F1 and mAP determine correctness at the object\nlevel using fixed overlap cutoffs, while overlap--based metrics like\nIntersection over Union (IoU) and Dice operate at the pixel level, often\noverlooking instance--level structure. Panoptic Quality (PQ) attempts to unify\ndetection and segmentation assessment, but it remains dependent on\nhard-threshold matching--treating predictions below the threshold as entirely\nincorrect. This binary framing obscures important distinctions between\nqualitatively different errors and fails to reward gradual model improvements.\nWe propose SoftPQ, a flexible and interpretable instance segmentation metric\nthat redefines evaluation as a graded continuum rather than a binary\nclassification. SoftPQ introduces tunable upper and lower IoU thresholds to\ndefine a partial matching region and applies a sublinear penalty function to\nambiguous or fragmented predictions. These extensions allow SoftPQ to exhibit\nsmoother score behavior, greater robustness to structural segmentation errors,\nand more informative feedback for model development and evaluation. Through\ncontrolled perturbation experiments, we show that SoftPQ captures meaningful\ndifferences in segmentation quality that existing metrics overlook, making it a\npractical and principled alternative for both benchmarking and iterative model\nrefinement.",
      "tldr_zh": "本论文指出了传统实例分割评估指标（如F1、mAP和IoU）的局限性，它们依赖于二元决策和固定IoU阈值，导致忽略实例级结构和细微错误。作者提出SoftPQ，一种灵活的评估指标，通过引入可调的上限下限IoU阈值和次线性惩罚函数，将评估转变为渐进式连续体，从而提供更平滑的评分、更强的鲁棒性以及更具信息性的反馈。实验结果显示，SoftPQ在控制扰动实验中捕捉到了现有指标忽略的分割质量差异，有助于模型开发和基准测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12155v1",
      "published_date": "2025-05-17 22:08:33 UTC",
      "updated_date": "2025-05-17 22:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:16:24.795089"
    },
    {
      "arxiv_id": "2505.12151v1",
      "title": "Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Heyman",
        "Joel Zylberberg"
      ],
      "abstract": "Large language models have recently made great strides in reasoning task\nperformance through chain-of-thought (CoT) strategies trained via reinforcement\nlearning; however, these \"reasoning large language models\" (RLLMs) remain\nimperfect reasoners, and understanding the frequencies and causes of their\nfailure modes is important for both users and developers. We test o1-mini,\no3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, and Grok 3\nMini Beta on graph coloring as a variable-complexity constraint-satisfaction\nlogic problem, and find evidence from both error rate comparisons and\nCoT/explanation text analysis that RLLMs are prone to hallucinate edges not\nspecified in the prompt's description of the graph. This phenomenon persists\nacross multiple problem complexity levels and semantic frames, and it appears\nto account for a significant fraction of the incorrect answers from every\ntested model, and the vast majority of them for some models. Our results\nindicate that RLLMs may possess broader issues with misrepresentation of\nproblem specifics, and we offer suggestions for design choices to mitigate this\nweakness.",
      "tldr_zh": "这篇论文探讨了推理型大语言模型（RLLMs）的错误原因，发现这些模型在处理复杂问题时，常因幻觉（hallucinating）关键问题特征（如图着色问题中的额外边）而导致失败。研究者通过测试多个模型（包括 o1-mini、o3-mini 和 Gemini 2.5 Pro Preview）在变量复杂度的约束满足逻辑问题上，并分析 Chain-of-Thought (CoT) 文本，证明了这种现象在不同问题复杂度和语义框架中广泛存在。结果显示，幻觉错误占模型错误答案的显著比例，论文据此提出设计建议，以改善 RLLMs 对问题细节的准确表示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages (9 excluding references and appendices); 7 figures (6\n  excluding appendices)",
      "pdf_url": "http://arxiv.org/pdf/2505.12151v1",
      "published_date": "2025-05-17 21:55:12 UTC",
      "updated_date": "2025-05-17 21:55:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:16:36.935610"
    },
    {
      "arxiv_id": "2505.12143v1",
      "title": "Structured Representation",
      "title_zh": "结构化表示",
      "authors": [
        "Arun Kumar",
        "Paul Schrater"
      ],
      "abstract": "Invariant representations are core to representation learning, yet a central\nchallenge remains: uncovering invariants that are stable and transferable\nwithout suppressing task-relevant signals. This raises fundamental questions,\nrequiring further inquiry, about the appropriate level of abstraction at which\nsuch invariants should be defined, and which aspects of a system they should\ncharacterize. Interpretation of the environment relies on abstract knowledge\nstructures to make sense of the current state, which leads to interactions,\nessential drivers of learning and knowledge acquisition. We posit that\ninterpretation operates at the level of higher-order relational knowledge;\nhence, invariant structures must be where knowledge resides, specifically, as\npartitions defined by the closure of relational paths within an abstract\nknowledge space. These partitions serve as the core invariant representations,\nforming the structural substrate where knowledge is stored and learning occurs.\nOn the other hand, inter-partition connectors enable the deployment of these\nknowledge partitions encoding task-relevant transitions. Thus, invariant\npartitions provide the foundational primitives of structured representation. We\nformalize the computational foundations for structured representation of the\ninvariant partitions based on closed semiring, a relational algebraic\nstructure.",
      "tldr_zh": "该论文探讨了不变表示（invariant representations）的核心挑战，即如何创建稳定且可转移的表示，同时不抑制任务相关信号。作者提出，不变结构应在更高阶的关系知识中定义，具体表现为抽象知识空间中关系路径闭包的分区，这些分区作为知识存储和学习的结构基础。论文进一步基于闭合半环（closed semiring）这一关系代数结构形式化这些不变分区，并通过分区间的连接器来处理任务相关转换，从而为结构化表示提供计算基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12143v1",
      "published_date": "2025-05-17 21:26:05 UTC",
      "updated_date": "2025-05-17 21:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:16:48.231143"
    },
    {
      "arxiv_id": "2505.12136v1",
      "title": "Lightweight Spatio-Temporal Attention Network with Graph Embedding and Rotational Position Encoding for Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Wang",
        "Shun-Ren Yang"
      ],
      "abstract": "Traffic forecasting is a key task in the field of Intelligent Transportation\nSystems. Recent research on traffic forecasting has mainly focused on combining\ngraph neural networks (GNNs) with other models. However, GNNs only consider\nshort-range spatial information. In this study, we present a novel model termed\nLSTAN-GERPE (Lightweight Spatio-Temporal Attention Network with Graph Embedding\nand Rotational Position Encoding). This model leverages both Temporal and\nSpatial Attention mechanisms to effectively capture long-range traffic\ndynamics. Additionally, the optimal frequency for rotational position encoding\nis determined through a grid search approach in both the spatial and temporal\nattention mechanisms. This systematic optimization enables the model to\neffectively capture complex traffic patterns. The model also enhances feature\nrepresentation by incorporating geographical location maps into the\nspatio-temporal embeddings. Without extensive feature engineering, the proposed\nmethod in this paper achieves advanced accuracy on the real-world traffic\nforecasting datasets PeMS04 and PeMS08.",
      "tldr_zh": "这篇论文提出了一种轻量级时空注意力网络 LSTAN-GERPE，用于智能交通系统的交通预测问题，以克服图神经网络 (GNNs) 只关注短程空间信息的局限。模型通过结合 Temporal 和 Spatial Attention 机制，捕捉长程交通动态，并采用网格搜索方法优化 Rotational Position Encoding 的频率，以增强时空嵌入的特征表示。还整合了地理位置地图，进一步提升模型的表现。该方法在真实数据集 PeMS04 和 PeMS08 上实现了先进的准确率，而无需进行大量特征工程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12136v1",
      "published_date": "2025-05-17 20:36:20 UTC",
      "updated_date": "2025-05-17 20:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:17:00.409475"
    },
    {
      "arxiv_id": "2505.12135v1",
      "title": "LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Choukrani",
        "Idriss Malek",
        "Daniil Orel",
        "Zhuohan Xie",
        "Zangir Iklassov",
        "Martin Takáč",
        "Salem Lahlou"
      ],
      "abstract": "Assessing the capacity of Large Language Models (LLMs) to plan and reason\nwithin the constraints of interactive environments is crucial for developing\ncapable AI agents. We introduce $\\textbf{LLM-BabyBench}$, a new benchmark suite\ndesigned specifically for this purpose. Built upon a textual adaptation of the\nprocedurally generated BabyAI grid world, this suite evaluates LLMs on three\nfundamental aspects of grounded intelligence: (1) predicting the consequences\nof actions on the environment state ($\\textbf{Predict}$ task), (2) generating\nsequences of low-level actions to achieve specified objectives ($\\textbf{Plan}$\ntask), and (3) decomposing high-level instructions into coherent subgoal\nsequences ($\\textbf{Decompose}$ task). We detail the methodology for generating\nthe three corresponding datasets ($\\texttt{LLM-BabyBench-Predict}$,\n$\\texttt{-Plan}$, $\\texttt{-Decompose}$) by extracting structured information\nfrom an expert agent operating within the text-based environment. Furthermore,\nwe provide a standardized evaluation harness and metrics, including environment\ninteraction for validating generated plans, to facilitate reproducible\nassessment of diverse LLMs. Initial baseline results highlight the challenges\nposed by these grounded reasoning tasks. The benchmark suite, datasets, data\ngeneration code, and evaluation code are made publicly available\n($\\href{https://github.com/choukrani/llm-babybench}{\\text{GitHub}}$,\n$\\href{https://huggingface.co/datasets/salem-mbzuai/LLM-BabyBench}{\\text{HuggingFace}}$).",
      "tldr_zh": "本研究引入了LLM-BabyBench，这是一个新的基准测试套件，用于评估大型语言模型(LLMs)在交互环境中的规划和推理能力。基于BabyAI网格世界的文本适应版本，该套件评估三个核心方面：(1)预测动作对环境状态的影响(Predict任务)，(2)生成低级动作序列以实现指定目标(Plan任务)，以及(3)将高层指令分解成子目标序列(Decompose任务)。研究团队通过从专家代理的操作中提取结构化信息，生成对应的数据集，并提供标准化评估工具和指标，包括环境交互验证，以确保结果的可重复性。初步基准结果突出了这些任务的挑战性，并公开了相关资源（如代码和数据集）。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12135v1",
      "published_date": "2025-05-17 20:23:17 UTC",
      "updated_date": "2025-05-17 20:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:17:12.552017"
    },
    {
      "arxiv_id": "2505.12130v1",
      "title": "Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Niaz Ahmad",
        "Jawad Khan",
        "Kang G. Shin",
        "Youngmoon Lee",
        "Guanghui Wang"
      ],
      "abstract": "The dynamic movement of the human body presents a fundamental challenge for\nhuman pose estimation and body segmentation. State-of-the-art approaches\nprimarily rely on combining keypoint heatmaps with segmentation masks but often\nstruggle in scenarios involving overlapping joints or rapidly changing poses\nduring instance-level segmentation. To address these limitations, we propose\nKeypoints as Dynamic Centroid (KDC), a new centroid-based representation for\nunified human pose estimation and instance-level segmentation. KDC adopts a\nbottom-up paradigm to generate keypoint heatmaps for both easily\ndistinguishable and complex keypoints and improves keypoint detection and\nconfidence scores by introducing KeyCentroids using a keypoint disk. It\nleverages high-confidence keypoints as dynamic centroids in the embedding space\nto generate MaskCentroids, allowing for swift clustering of pixels to specific\nhuman instances during rapid body movements in live environments. Our\nexperimental evaluations on the CrowdPose, OCHuman, and COCO benchmarks\ndemonstrate KDC's effectiveness and generalizability in challenging scenarios\nin terms of both accuracy and runtime performance. The implementation is\navailable at: https://sites.google.com/view/niazahmad/projects/kdc.",
      "tldr_zh": "本文提出 KDC（Keypoints as Dynamic Centroid）方法，用于统一人体姿势估计和实例级分割，解决动态人体运动中重叠关节和快速变化姿势的挑战。KDC 采用自下而上的范式生成关键点热图，并通过引入 KeyCentroids 来提升关键点检测和置信度，同时利用高置信度关键点作为动态质心生成 MaskCentroids，实现快速像素聚类以处理实时环境中的人体实例。实验结果显示，在 CrowdPose、OCHuman 和 COCO 基准上，KDC 在准确性和运行时性能方面表现出色，并证明了其有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12130v1",
      "published_date": "2025-05-17 20:05:34 UTC",
      "updated_date": "2025-05-17 20:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:17:25.791170"
    },
    {
      "arxiv_id": "2505.12109v1",
      "title": "SAINT: Attention-Based Modeling of Sub-Action Dependencies in Multi-Action Policies",
      "title_zh": "SAINT：",
      "authors": [
        "Matthew Landers",
        "Taylor W. Killian",
        "Thomas Hartvigsen",
        "Afsaneh Doryab"
      ],
      "abstract": "The combinatorial structure of many real-world action spaces leads to\nexponential growth in the number of possible actions, limiting the\neffectiveness of conventional reinforcement learning algorithms. Recent\napproaches for combinatorial action spaces impose factorized or sequential\nstructures over sub-actions, failing to capture complex joint behavior. We\nintroduce the Sub-Action Interaction Network using Transformers (SAINT), a\nnovel policy architecture that represents multi-component actions as unordered\nsets and models their dependencies via self-attention conditioned on the global\nstate. SAINT is permutation-invariant, sample-efficient, and compatible with\nstandard policy optimization algorithms. In 15 distinct combinatorial\nenvironments across three task domains, including environments with nearly 17\nmillion joint actions, SAINT consistently outperforms strong baselines.",
      "tldr_zh": "该论文针对真实世界动作空间的组合结构导致动作数量指数级增长的问题，提出了 SAINT 框架，一种基于 Transformers 的新型策略架构。\nSAINT 将多组件动作表示为无序集合，并通过基于全局状态的 self-attention 机制建模子动作间的依赖关系，实现置换不变（permutation-invariant）、样本高效（sample-efficient）的特性，并兼容标准策略优化算法。\n在 15 个不同组合环境中的实验中，包括近 1700 万联合动作的环境，SAINT  consistently outperforms 强基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12109v1",
      "published_date": "2025-05-17 18:34:31 UTC",
      "updated_date": "2025-05-17 18:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:17:37.834072"
    },
    {
      "arxiv_id": "2505.12108v1",
      "title": "EarthSynth: Generating Informative Earth Observation with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiancheng Pan",
        "Shiye Lei",
        "Yuqian Fu",
        "Jiahao Li",
        "Yanxing Liu",
        "Yuze Sun",
        "Xiao He",
        "Long Peng",
        "Xiaomeng Huang",
        "Bo Zhao"
      ],
      "abstract": "Remote sensing image (RSI) interpretation typically faces challenges due to\nthe scarcity of labeled data, which limits the performance of RSI\ninterpretation tasks. To tackle this challenge, we propose EarthSynth, a\ndiffusion-based generative foundation model that enables synthesizing\nmulti-category, cross-satellite labeled Earth observation for downstream RSI\ninterpretation tasks. To the best of our knowledge, EarthSynth is the first to\nexplore multi-task generation for remote sensing. EarthSynth, trained on the\nEarthSynth-180K dataset, employs the Counterfactual Composition training\nstrategy to improve training data diversity and enhance category control.\nFurthermore, a rule-based method of R-Filter is proposed to filter more\ninformative synthetic data for downstream tasks. We evaluate our EarthSynth on\nscene classification, object detection, and semantic segmentation in open-world\nscenarios, offering a practical solution for advancing RSI interpretation.",
      "tldr_zh": "该研究提出 EarthSynth，一种基于 diffusion models 的生成基础模型，用于合成多类别、跨卫星的标注地球观测数据，以解决遥感图像 (RSI) 解释任务中标注数据稀缺的挑战。EarthSynth 首次探索遥感领域的多任务生成，通过 EarthSynth-180K 数据集和 Counterfactual Composition 训练策略提升数据多样性及类别控制，同时引入 R-Filter 规则方法筛选更具信息性的合成数据。实验结果显示，EarthSynth 在开放世界场景下的场景分类、物体检测和语义分割任务中表现出色，提供了一个实际有效的 RSI 解释解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12108v1",
      "published_date": "2025-05-17 18:27:15 UTC",
      "updated_date": "2025-05-17 18:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:17:47.442448"
    },
    {
      "arxiv_id": "2505.12107v1",
      "title": "Learning Probabilistic Temporal Logic Specifications for Stochastic Systems",
      "title_zh": "针对随机系统的概率时序逻辑规范学习",
      "authors": [
        "Rajarshi Roy",
        "Yash Pote",
        "David Parker",
        "Marta Kwiatkowska"
      ],
      "abstract": "There has been substantial progress in the inference of formal behavioural\nspecifications from sample trajectories, for example, using Linear Temporal\nLogic (LTL). However, these techniques cannot handle specifications that\ncorrectly characterise systems with stochastic behaviour, which occur commonly\nin reinforcement learning and formal verification. We consider the passive\nlearning problem of inferring a Boolean combination of probabilistic LTL (PLTL)\nformulas from a set of Markov chains, classified as either positive or\nnegative. We propose a novel learning algorithm that infers concise PLTL\nspecifications, leveraging grammar-based enumeration, search heuristics,\nprobabilistic model checking and Boolean set-cover procedures. We demonstrate\nthe effectiveness of our algorithm in two use cases: learning from policies\ninduced by RL algorithms and learning from variants of a probabilistic model.\nIn both cases, our method automatically and efficiently extracts PLTL\nspecifications that succinctly characterise the temporal differences between\nthe policies or model variants.",
      "tldr_zh": "本论文解决了从样本轨迹中推断随机系统行为规范的问题，因为传统Linear Temporal Logic (LTL)方法无法处理强化学习和正式验证中的随机行为。研究提出了一种新算法，通过语法-based枚举、搜索启发式、probabilistic model checking和Boolean set-cover程序，从一组分类的Markov chains中被动学习简洁的Probabilistic LTL (PLTL)公式。实验在强化学习诱导的政策和概率模型变体上验证了该算法的有效性，能够自动高效地提取PLTL规范，以简洁方式描述政策或模型之间的时间差异。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.LO",
      "comment": "Full version of the paper that appears in IJCAI'25",
      "pdf_url": "http://arxiv.org/pdf/2505.12107v1",
      "published_date": "2025-05-17 18:19:35 UTC",
      "updated_date": "2025-05-17 18:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:18:00.505192"
    },
    {
      "arxiv_id": "2505.12100v1",
      "title": "Improving Fairness in LLMs Through Testing-Time Adversaries",
      "title_zh": "通过测试时对抗者改善LLMs中的公平性",
      "authors": [
        "Isabela Pereira Gregio",
        "Ian Pons",
        "Anna Helena Reali Costa",
        "Artur Jordão"
      ],
      "abstract": "Large Language Models (LLMs) push the bound-aries in natural language\nprocessing and generative AI, driving progress across various aspects of modern\nsociety. Unfortunately, the pervasive issue of bias in LLMs responses (i.e.,\npredictions) poses a significant and open challenge, hindering their\napplication in tasks involving ethical sensitivity and responsible\ndecision-making. In this work, we propose a straightforward, user-friendly and\npractical method to mitigate such biases, enhancing the reliability and\ntrustworthiness of LLMs. Our method creates multiple variations of a given\nsentence by modifying specific attributes and evaluates the corresponding\nprediction behavior compared to the original, unaltered, prediction/sentence.\nThe idea behind this process is that critical ethical predictions often exhibit\nnotable inconsistencies, indicating the presence of bias. Unlike previous\napproaches, our method relies solely on forward passes (i.e., testing-time\nadversaries), eliminating the need for training, fine-tuning, or prior\nknowledge of the training data distribution. Through extensive experiments on\nthe popular Llama family, we demonstrate the effectiveness of our method in\nimproving various fairness metrics, focusing on the reduction of disparities in\nhow the model treats individuals from different racial groups. Specifically,\nusing standard metrics, we improve the fairness in Llama3 in up to 27\npercentage points. Overall, our approach significantly enhances fairness,\nequity, and reliability in LLM-generated results without parameter tuning or\ntraining data modifications, confirming its effectiveness in practical\nscenarios. We believe our work establishes an important step toward enabling\nthe use of LLMs in tasks that require ethical considerations and responsible\ndecision-making.",
      "tldr_zh": "这篇论文提出了一种通过测试时对抗样本（testing-time adversaries）来改善大型语言模型（LLMs）公平性的简单方法，该方法通过创建句子的多个变体并比较预测行为，以检测和缓解模型偏见，而无需训练、微调或依赖训练数据。核心思路是识别关键预测中的不一致性，以减少种族群体间的差异。实验在 Llama 系列模型上进行，结果显示该方法将 Llama3 的公平性指标提高了高达 27 个百分点。总体上，这一方法增强了 LLMs 的可靠性和可信度，促进其在道德敏感任务中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12100v1",
      "published_date": "2025-05-17 17:56:53 UTC",
      "updated_date": "2025-05-17 17:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:18:12.465138"
    },
    {
      "arxiv_id": "2505.12096v1",
      "title": "When the Left Foot Leads to the Right Path: Bridging Initial Prejudice and Trainability",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Bassi",
        "Carlo Albert",
        "Aurelien Lucchi",
        "Marco Baity-Jesi",
        "Emanuele Francazi"
      ],
      "abstract": "Understanding the statistical properties of deep neural networks (DNNs) at\ninitialization is crucial for elucidating both their trainability and the\nintrinsic architectural biases they encode prior to data exposure. Mean-field\n(MF) analyses have demonstrated that the parameter distribution in randomly\ninitialized networks dictates whether gradients vanish or explode.\nConcurrently, untrained DNNs were found to exhibit an initial-guessing bias\n(IGB), in which large regions of the input space are assigned to a single\nclass. In this work, we derive a theoretical proof establishing the\ncorrespondence between IGB and previous MF theories, thereby connecting a\nnetwork prejudice toward specific classes with the conditions for fast and\naccurate learning. This connection yields the counter-intuitive conclusion: the\ninitialization that optimizes trainability is necessarily biased, rather than\nneutral. Furthermore, we extend the MF/IGB framework to multi-node activation\nfunctions, offering practical guidelines for designing initialization schemes\nthat ensure stable optimization in architectures employing max- and\naverage-pooling layers.",
      "tldr_zh": "本研究探讨了深度神经网络（DNNs）在初始化时的统计特性如何影响其可训练性和固有偏见（Initial-Guessing Bias, IGB）。论文通过理论证明将 IGB 与 Mean-field (MF) 分析联系起来，揭示网络对特定类的偏见实际上是优化训练速度和准确性的关键条件，而不是中性初始化。最终，该框架扩展到多节点激活函数，并提供实用指导，帮助设计初始化方案以确保在包含 max- 和 average-pooling 层的架构中实现稳定的优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12096v1",
      "published_date": "2025-05-17 17:31:56 UTC",
      "updated_date": "2025-05-17 17:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:18:25.317981"
    },
    {
      "arxiv_id": "2505.12094v1",
      "title": "Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks",
      "title_zh": "翻译失败",
      "authors": [
        "M Ruhul Amin"
      ],
      "abstract": "This paper introduces Attribution Projection Calculus (AP-Calculus), a novel\nmathematical framework for determining causal relationships in structured\nBayesian networks. We investigate a specific network architecture with source\nnodes connected to destination nodes through intermediate nodes, where each\ninput maps to a single label with maximum marginal probability. We prove that\nfor each label, exactly one intermediate node acts as a deconfounder while\nothers serve as confounders, enabling optimal attribution of features to their\ncorresponding labels. The framework formalizes the dual nature of intermediate\nnodes as both confounders and deconfounders depending on the context, and\nestablishes separation functions that maximize distinctions between\nintermediate representations. We demonstrate that the proposed network\narchitecture is optimal for causal inference compared to alternative\nstructures, including those based on Pearl's causal framework. AP-Calculus\nprovides a comprehensive mathematical foundation for analyzing feature-label\nattributions, managing spurious correlations, quantifying information gain,\nensuring fairness, and evaluating uncertainty in prediction models, including\nlarge language models. Theoretical verification shows that AP-Calculus not only\nextends but can also subsume traditional do-calculus for many practical\napplications, offering a more direct approach to causal inference in supervised\nlearning contexts.",
      "tldr_zh": "本论文引入了Attribution Projection Calculus (AP-Calculus)，一个新的数学框架，用于在Bayesian Networks中进行因果推理。该框架针对一种特定网络架构（源节点通过中间节点连接到目标节点），证明每个标签对应一个中间节点作为deconfounder，而其他节点作为confounders，从而实现特征到标签的最佳归因，并通过分离函数最大化中间表示的区别。相比传统结构如Pearl's causal framework，AP-Calculus更优，能有效管理虚假相关、量化信息增益、确保公平性和评估不确定性，并在监督学习和大型语言模型中提供更直接的因果推理方法。理论验证表明，该框架不仅扩展了do-calculus，还能在许多实际应用中取代它。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML",
        "60E10, 62R07, 68Q32, 68T07, 94A16",
        "F.2.2; G.3; I.1.2; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "*AI was used to improve Text and collecting Citations",
      "pdf_url": "http://arxiv.org/pdf/2505.12094v1",
      "published_date": "2025-05-17 17:29:13 UTC",
      "updated_date": "2025-05-17 17:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:18:37.074084"
    },
    {
      "arxiv_id": "2505.12090v1",
      "title": "Personalized Author Obfuscation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Shokri",
        "Sarah Ita Levitan",
        "Rivka Levitan"
      ],
      "abstract": "In this paper, we investigate the efficacy of large language models (LLMs) in\nobfuscating authorship by paraphrasing and altering writing styles. Rather than\nadopting a holistic approach that evaluates performance across the entire\ndataset, we focus on user-wise performance to analyze how obfuscation\neffectiveness varies across individual authors. While LLMs are generally\neffective, we observe a bimodal distribution of efficacy, with performance\nvarying significantly across users. To address this, we propose a personalized\nprompting method that outperforms standard prompting techniques and partially\nmitigates the bimodality issue.",
      "tldr_zh": "本研究考察大型语言模型 (LLMs) 通过改写和改变写作风格来隐藏作者身份的有效性，重点分析用户级别的性能，而不是整体数据集表现。结果显示，LLMs 总体有效，但效果存在双峰分布 (bimodal distribution)，即在不同作者间差异显著。为此，研究提出了一种个性化提示方法 (personalized prompting)，它优于标准提示技术，并部分缓解了这一双峰问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12090v1",
      "published_date": "2025-05-17 17:10:25 UTC",
      "updated_date": "2025-05-17 17:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:18:48.426979"
    },
    {
      "arxiv_id": "2505.12089v1",
      "title": "NTIRE 2025 Challenge on Efficient Burst HDR and Restoration: Datasets, Methods, and Results",
      "title_zh": "翻译失败",
      "authors": [
        "Sangmin Lee",
        "Eunpil Park",
        "Angel Canelo",
        "Hyunhee Park",
        "Youngjo Kim",
        "Hyung-Ju Chun",
        "Xin Jin",
        "Chongyi Li",
        "Chun-Le Guo",
        "Radu Timofte",
        "Qi Wu",
        "Tianheng Qiu",
        "Yuchun Dong",
        "Shenglin Ding",
        "Guanghua Pan",
        "Weiyu Zhou",
        "Tao Hu",
        "Yixu Feng",
        "Duwei Dai",
        "Yu Cao",
        "Peng Wu",
        "Wei Dong",
        "Yanning Zhang",
        "Qingsen Yan",
        "Simon J. Larsen",
        "Ruixuan Jiang",
        "Senyan Xu",
        "Xingbo Wang",
        "Xin Lu",
        "Marcos V. Conde",
        "Javier Abad-Hernandez",
        "Alvaro Garcıa-Lara",
        "Daniel Feijoo",
        "Alvaro Garcıa",
        "Zeyu Xiao",
        "Zhuoyuan Li"
      ],
      "abstract": "This paper reviews the NTIRE 2025 Efficient Burst HDR and Restoration\nChallenge, which aims to advance efficient multi-frame high dynamic range (HDR)\nand restoration techniques. The challenge is based on a novel RAW multi-frame\nfusion dataset, comprising nine noisy and misaligned RAW frames with various\nexposure levels per scene. Participants were tasked with developing solutions\ncapable of effectively fusing these frames while adhering to strict efficiency\nconstraints: fewer than 30 million model parameters and a computational budget\nunder 4.0 trillion FLOPs. A total of 217 participants registered, with six\nteams finally submitting valid solutions. The top-performing approach achieved\na PSNR of 43.22 dB, showcasing the potential of novel methods in this domain.\nThis paper provides a comprehensive overview of the challenge, compares the\nproposed solutions, and serves as a valuable reference for researchers and\npractitioners in efficient burst HDR and restoration.",
      "tldr_zh": "这篇论文回顾了 NTIRE 2025 高效 Burst HDR 和修复挑战赛，旨在推进多帧高动态范围 (HDR) 技术和修复方法。挑战赛基于一个新颖的 RAW 多帧融合数据集，每个场景包含九帧嘈杂和不对齐的 RAW 帧，参与者需开发高效融合解决方案，同时遵守参数少于 30 百万和 FLOPs 少于 4.0 万亿的计算约束。共有 217 名参与者注册，六队提交有效方案，其中最佳方法达到 PSNR 43.22 dB，展示了该领域新方法的潜力。该论文全面概述了挑战赛、比较了提出的解决方案，并为高效 Burst HDR 和修复的研究提供宝贵参考。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12089v1",
      "published_date": "2025-05-17 17:10:22 UTC",
      "updated_date": "2025-05-17 17:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:19:01.560354"
    },
    {
      "arxiv_id": "2505.12079v1",
      "title": "SepPrune: Structured Pruning for Efficient Deep Speech Separation",
      "title_zh": "SepPrune：用于高效深度语音分离的结构化剪枝",
      "authors": [
        "Yuqi Li",
        "Kai Li",
        "Xin Yin",
        "Zhifei Yang",
        "Junhao Dong",
        "Zeyu Dong",
        "Chuanguang Yang",
        "Yingli Tian",
        "Yao Lu"
      ],
      "abstract": "Although deep learning has substantially advanced speech separation in recent\nyears, most existing studies continue to prioritize separation quality while\noverlooking computational efficiency, an essential factor for low-latency\nspeech processing in real-time applications. In this paper, we propose\nSepPrune, the first structured pruning framework specifically designed to\ncompress deep speech separation models and reduce their computational cost.\nSepPrune begins by analyzing the computational structure of a given model to\nidentify layers with the highest computational burden. It then introduces a\ndifferentiable masking strategy to enable gradient-driven channel selection.\nBased on the learned masks, SepPrune prunes redundant channels and fine-tunes\nthe remaining parameters to recover performance. Extensive experiments\ndemonstrate that this learnable pruning paradigm yields substantial advantages\nfor channel pruning in speech separation models, outperforming existing\nmethods. Notably, a model pruned with SepPrune can recover 85% of the\nperformance of a pre-trained model (trained over hundreds of epochs) with only\none epoch of fine-tuning, and achieves convergence 36$\\times$ faster than\ntraining from scratch. Code is available at\nhttps://github.com/itsnotacie/SepPrune.",
      "tldr_zh": "本论文提出 SepPrune，一种专门针对深度语音分离模型的结构化剪枝框架，旨在提升计算效率以适应实时应用。该框架首先分析模型计算结构，识别高负载层，然后使用可微掩码策略进行梯度驱动的通道选择，并剪枝冗余通道后微调剩余参数。实验结果显示，SepPrune 优于现有方法，能在仅一轮微调中恢复预训练模型85%的性能，并使模型收敛速度比从零开始训练快36倍。开源代码可从 https://github.com/itsnotacie/SepPrune 获取。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12079v1",
      "published_date": "2025-05-17 16:44:38 UTC",
      "updated_date": "2025-05-17 16:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:19:12.374631"
    },
    {
      "arxiv_id": "2505.12069v1",
      "title": "MT-CYP-Net: Multi-Task Network for Pixel-Level Crop Yield Prediction Under Very Few Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Shenzhou Liu",
        "Di Wang",
        "Haonan Guo",
        "Chengxi Han",
        "Wenzhi Zeng"
      ],
      "abstract": "Accurate and fine-grained crop yield prediction plays a crucial role in\nadvancing global agriculture. However, the accuracy of pixel-level yield\nestimation based on satellite remote sensing data has been constrained by the\nscarcity of ground truth data. To address this challenge, we propose a novel\napproach called the Multi-Task Crop Yield Prediction Network (MT-CYP-Net). This\nframework introduces an effective multi-task feature-sharing strategy, where\nfeatures extracted from a shared backbone network are simultaneously utilized\nby both crop yield prediction decoders and crop classification decoders with\nthe ability to fuse information between them. This design allows MT-CYP-Net to\nbe trained with extremely sparse crop yield point labels and crop type labels,\nwhile still generating detailed pixel-level crop yield maps. Concretely, we\ncollected 1,859 yield point labels along with corresponding crop type labels\nand satellite images from eight farms in Heilongjiang Province, China, in 2023,\ncovering soybean, maize, and rice crops, and constructed a sparse crop yield\nlabel dataset. MT-CYP-Net is compared with three classical machine learning and\ndeep learning benchmark methods in this dataset. Experimental results not only\nindicate the superiority of MT-CYP-Net compared to previous methods on multiple\ntypes of crops but also demonstrate the potential of deep networks on precise\npixel-level crop yield prediction, especially with limited data labels.",
      "tldr_zh": "本研究针对卫星遥感数据中地面真实数据稀缺的问题，提出了一种多任务网络MT-CYP-Net，用于在极少样本下进行像素级作物产量预测。该框架采用多任务特征共享策略，通过共享骨干网络提取特征，同时服务于作物产量预测解码器和作物分类解码器，并实现信息融合，从而生成详细的像素级作物产量地图。研究者收集了来自中国黑龙江省8个农场的1859个产量点标签、作物类型标签和卫星图像，覆盖大豆、玉米和水稻作物。与经典机器学习和深度学习基准方法比较，实验结果显示MT-CYP-Net在多种作物上表现出色，证明了深度网络在数据有限条件下的像素级预测潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12069v1",
      "published_date": "2025-05-17 16:20:44 UTC",
      "updated_date": "2025-05-17 16:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:19:24.822078"
    },
    {
      "arxiv_id": "2505.12065v1",
      "title": "Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tiannuo Yang",
        "Zebin Yao",
        "Bowen Jin",
        "Lixiao Cui",
        "Yusen Li",
        "Gang Wang",
        "Xiaoguang Liu"
      ],
      "abstract": "Large Language Model (LLM)-based search agents have shown remarkable\ncapabilities in solving complex tasks by dynamically decomposing problems and\naddressing them through interleaved reasoning and retrieval. However, this\ninterleaved paradigm introduces substantial efficiency bottlenecks. First, we\nobserve that both highly accurate and overly approximate retrieval methods\ndegrade system efficiency: exact search incurs significant retrieval overhead,\nwhile coarse retrieval requires additional reasoning steps during generation.\nSecond, we identify inefficiencies in system design, including improper\nscheduling and frequent retrieval stalls, which lead to cascading latency --\nwhere even minor delays in retrieval amplify end-to-end inference time. To\naddress these challenges, we introduce SearchAgent-X, a high-efficiency\ninference framework for LLM-based search agents. SearchAgent-X leverages\nhigh-recall approximate retrieval and incorporates two key techniques:\npriority-aware scheduling and non-stall retrieval. Extensive experiments\ndemonstrate that SearchAgent-X consistently outperforms state-of-the-art\nsystems such as vLLM and HNSW-based retrieval across diverse tasks, achieving\nup to 3.4$\\times$ higher throughput and 5$\\times$ lower latency, without\ncompromising generation quality. SearchAgent-X is available at\nhttps://github.com/tiannuo-yang/SearchAgent-X.",
      "tldr_zh": "该研究揭示了Large Language Model (LLM)-based search agents在交错推理和检索过程中存在的效率瓶颈，包括精确检索的开销过大和粗略检索需额外步骤，以及系统设计中的不当调度和检索暂停导致的级联延迟。为解决这些问题，研究提出SearchAgent-X框架，利用高召回率近似检索、priority-aware scheduling和non-stall retrieval技术优化系统。实验结果显示，SearchAgent-X相较于vLLM和HNSW-based retrieval等基准系统，实现了高达3.4倍的吞吐量提升和5倍的延迟降低，同时保持了生成质量不变。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12065v1",
      "published_date": "2025-05-17 16:07:01 UTC",
      "updated_date": "2025-05-17 16:07:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:19:36.413412"
    },
    {
      "arxiv_id": "2505.15840v1",
      "title": "TDFormer: A Top-Down Attention-Controlled Spiking Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Zizheng Zhu",
        "Yingchao Yu",
        "Zeqi Zheng",
        "Zhaofei Yu",
        "Yaochu Jin"
      ],
      "abstract": "Traditional spiking neural networks (SNNs) can be viewed as a combination of\nmultiple subnetworks with each running for one time step, where the parameters\nare shared, and the membrane potential serves as the only information link\nbetween them. However, the implicit nature of the membrane potential limits its\nability to effectively represent temporal information. As a result, each time\nstep cannot fully leverage information from previous time steps, seriously\nlimiting the model's performance. Inspired by the top-down mechanism in the\nbrain, we introduce TDFormer, a novel model with a top-down feedback structure\nthat functions hierarchically and leverages high-order representations from\nearlier time steps to modulate the processing of low-order information at later\nstages. The feedback structure plays a role from two perspectives: 1) During\nforward propagation, our model increases the mutual information across time\nsteps, indicating that richer temporal information is being transmitted and\nintegrated in different time steps. 2) During backward propagation, we\ntheoretically prove that the feedback structure alleviates the problem of\nvanishing gradients along the time dimension. We find that these mechanisms\ntogether significantly and consistently improve the model performance on\nmultiple datasets. In particular, our model achieves state-of-the-art\nperformance on ImageNet with an accuracy of 86.83%.",
      "tldr_zh": "该论文提出 TDFormer，一种自上而下注意力控制的脉冲 Transformer 模型，旨在解决传统 SNNs 在时间信息表示上的局限性，通过反馈结构层次化地利用早期时间步的高阶表示来调节后续处理。反馈机制在正向传播中增强时间步之间的互信息，并在反向传播中理论证明缓解梯度消失问题，从而显著提升模型性能。实验结果显示，TDFormer 在多个数据集上表现出色，尤其在 ImageNet 上达到 86.83% 的准确率，实现了 state-of-the-art 水平。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.15840v1",
      "published_date": "2025-05-17 15:55:32 UTC",
      "updated_date": "2025-05-17 15:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:19:47.906151"
    },
    {
      "arxiv_id": "2505.12058v1",
      "title": "Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Koc"
      ],
      "abstract": "Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual\nsmoke-test suite designed to give large-language-model (LLM) pipelines a\nunit-test style safety net dataset that runs in seconds with minimal cost. Born\nout of the tight feedback-loop demands building the Comet Opik\nprompt-optimization SDK, where waiting on heavyweight benchmarks breaks\ndeveloper flow. TQB++ couples a 52-item English gold set (less than 20 kB) with\na tiny synthetic-data generator pypi package built on provider-agnostic\nLiteLLM. The generator lets practitioners mint their own tiny packs in any\nlanguage, domain, or difficulty, while ten ready-made packs already cover\nArabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian,\nSpanish, and Turkish. Every dataset ships with Croissant metadata and\nplug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so\nteams can drop deterministic micro-benchmarks directly into pull-request gates,\nprompt-engineering loops, and production dashboards without touching GPU\nbudgets. A complete TQB++ run adds only a few seconds to pipeline latency yet\nreliably flags prompt-template errors, tokenizer drift, and fine-tuning\nside-effects long before full-scale suites like MMLU or BIG-Bench would finish\nconfiguring. The entire framework is released to accelerate continuous,\nresource-efficient quality assurance across the generative-AI ecosystem.",
      "tldr_zh": "Tiny QA Benchmark++ (TQB++) 是一个超轻量级、多语言的合成数据集生成工具和烟雾测试套件，旨在为大型语言模型 (LLM) 管道提供快速、单元测试式的安全网，以加速开发流程。框架包括一个52项英语黄金数据集（小于20 kB）和基于 LiteLLM 的合成数据生成器，用户可轻松创建自定义语言、领域或难度的微基准，并附带10个现成包覆盖阿拉伯语、中文、法语等语言。TQB++ 通过 Croissant 元数据和即插即用文件，兼容 OpenAI-Evals、LangChain 和 CI 工具，实现无 GPU 预算的直接集成，能在几秒内检测提示模板错误、标记器漂移和微调副作用。该开源框架促进生成式 AI 生态中的资源高效、持续质量保证。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.6; H.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 7 figures, 3 tables. Includes expanded appendix & full\n  score matrices. Dataset & code: HF Hub + GitHub + Pypi links in abstract.\n  Core data and code Apache-2.0; synthetic packs eval-only",
      "pdf_url": "http://arxiv.org/pdf/2505.12058v1",
      "published_date": "2025-05-17 15:40:03 UTC",
      "updated_date": "2025-05-17 15:40:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:20:03.631290"
    },
    {
      "arxiv_id": "2505.12057v1",
      "title": "CorBenchX: Large-Scale Chest X-Ray Error Dataset and Vision-Language Model Benchmark for Report Error Correction",
      "title_zh": "CorBenchX：",
      "authors": [
        "Jing Zou",
        "Qingqiu Li",
        "Chenyu Lian",
        "Lihao Liu",
        "Xiaohan Yan",
        "Shujun Wang",
        "Jing Qin"
      ],
      "abstract": "AI-driven models have shown great promise in detecting errors in radiology\nreports, yet the field lacks a unified benchmark for rigorous evaluation of\nerror detection and further correction. To address this gap, we introduce\nCorBenchX, a comprehensive suite for automated error detection and correction\nin chest X-ray reports, designed to advance AI-assisted quality control in\nclinical practice. We first synthesize a large-scale dataset of 26,326 chest\nX-ray error reports by injecting clinically common errors via prompting\nDeepSeek-R1, with each corrupted report paired with its original text, error\ntype, and human-readable description. Leveraging this dataset, we benchmark\nboth open- and closed-source vision-language models,(e.g., InternVL, Qwen-VL,\nGPT-4o, o4-mini, and Claude-3.7) for error detection and correction under\nzero-shot prompting. Among these models, o4-mini achieves the best performance,\nwith 50.6 % detection accuracy and correction scores of BLEU 0.853, ROUGE\n0.924, BERTScore 0.981, SembScore 0.865, and CheXbertF1 0.954, remaining below\nclinical-level accuracy, highlighting the challenge of precise report\ncorrection. To advance the state of the art, we propose a multi-step\nreinforcement learning (MSRL) framework that optimizes a multi-objective reward\ncombining format compliance, error-type accuracy, and BLEU similarity. We apply\nMSRL to QwenVL2.5-7B, the top open-source model in our benchmark, achieving an\nimprovement of 38.3% in single-error detection precision and 5.2% in\nsingle-error correction over the zero-shot baseline.",
      "tldr_zh": "本研究引入 CorBenchX，这是一个大规模胸部 X 光报告错误数据集（包含 26,326 条通过提示 DeepSeek-R1 注入临床常见错误的报告），并提供了一个统一的基准，用于评估 vision-language models 在报告错误检测和纠正方面的性能。在零-shot prompting 下，o4-mini 模型表现出色，达到 50.6% 的检测准确率和多项纠正指标（如 BLEU 0.853、ROUGE 0.924），但仍未达到临床水平。为了提升性能，论文提出多步强化学习 (MSRL) 框架，优化多目标奖励（如格式合规、错误类型准确性和 BLEU 相似度），应用于 QwenVL2.5-7B 模型后，单错误检测精度提高 38.3%，纠正精度提高 5.2%。这项工作突出了 AI 在临床质量控制中的潜力，并为未来改进奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12057v1",
      "published_date": "2025-05-17 15:39:39 UTC",
      "updated_date": "2025-05-17 15:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:20:17.940170"
    },
    {
      "arxiv_id": "2505.12053v1",
      "title": "VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxiong Zhong",
        "Xingye Tian",
        "Boyuan Jiang",
        "Xuebo Wang",
        "Xin Tao",
        "Pengfei Wan",
        "Zhiwei Zhang"
      ],
      "abstract": "Modern video generation frameworks based on Latent Diffusion Models suffer\nfrom inefficiencies in tokenization due to the Frame-Proportional Information\nAssumption. Existing tokenizers provide fixed temporal compression rates,\ncausing the computational cost of the diffusion model to scale linearly with\nthe frame rate. The paper proposes the Duration-Proportional Information\nAssumption: the upper bound on the information capacity of a video is\nproportional to the duration rather than the number of frames. Based on this\ninsight, the paper introduces VFRTok, a Transformer-based video tokenizer, that\nenables variable frame rate encoding and decoding through asymmetric frame rate\ntraining between the encoder and decoder. Furthermore, the paper proposes\nPartial Rotary Position Embeddings (RoPE) to decouple position and content\nmodeling, which groups correlated patches into unified tokens. The Partial RoPE\neffectively improves content-awareness, enhancing the video generation\ncapability. Benefiting from the compact and continuous spatio-temporal\nrepresentation, VFRTok achieves competitive reconstruction quality and\nstate-of-the-art generation fidelity while using only 1/8 tokens compared to\nexisting tokenizers.",
      "tldr_zh": "这篇论文针对基于 Latent Diffusion Models 的视频生成框架中，Frame-Proportional Information Assumption 导致的 tokenization 效率问题，提出了 Duration-Proportional Information Assumption，即视频信息容量上限与时长成正比。基于此，作者开发了 VFRTok，一种 Transformer-based 视频 tokenizer，通过编码器和解码器之间的不对称帧率训练，实现可变帧率编码和解码，并引入 Partial Rotary Position Embeddings (RoPE) 来解耦位置和内容建模，提升内容感知能力。实验结果显示，VFRTok 仅使用现有 tokenizer 的 1/8 令牌，就实现了竞争性的重建质量和最先进的生成保真度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.12053v1",
      "published_date": "2025-05-17 15:32:54 UTC",
      "updated_date": "2025-05-17 15:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:20:29.592838"
    },
    {
      "arxiv_id": "2505.12050v1",
      "title": "ABoN: Adaptive Best-of-N Alignment",
      "title_zh": "ABoN：自适应 Best-of-N 对齐",
      "authors": [
        "Vinod Raman",
        "Hilal Asi",
        "Satyen Kale"
      ],
      "abstract": "Recent advances in test-time alignment methods, such as Best-of-N sampling,\noffer a simple and effective way to steer language models (LMs) toward\npreferred behaviors using reward models (RM). However, these approaches can be\ncomputationally expensive, especially when applied uniformly across prompts\nwithout accounting for differences in alignment difficulty. In this work, we\npropose a prompt-adaptive strategy for Best-of-N alignment that allocates\ninference-time compute more efficiently. Motivated by latency concerns, we\ndevelop a two-stage algorithm: an initial exploratory phase estimates the\nreward distribution for each prompt using a small exploration budget, and a\nsecond stage adaptively allocates the remaining budget using these estimates.\nOur method is simple, practical, and compatible with any LM/RM combination.\nEmpirical results on the AlpacaEval dataset for 12 LM/RM pairs and 50 different\nbatches of prompts show that our adaptive strategy consistently outperforms the\nuniform allocation with the same inference budget. Moreover, our experiments\nshow that our adaptive strategy remains competitive against uniform allocations\nwith 20% larger inference budgets and even improves in performance as the batch\nsize grows.",
      "tldr_zh": "论文提出ABoN，一种自适应Best-of-N对齐策略，旨在更高效地引导语言模型(LMs)使用奖励模型(RM)，解决传统方法在计算开销和提示差异上的问题。该策略采用两阶段算法：首先通过小预算探索估计算法每个提示的奖励分布，其次基于这些估计自适应分配剩余推理预算。实验结果显示，在AlpacaEval数据集上测试12对LM/RM和50批提示时，ABoN在相同预算下 consistently 优于统一分配策略，甚至能与预算高20%的统一方法竞争，并在批量大小增加时进一步提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12050v1",
      "published_date": "2025-05-17 15:24:48 UTC",
      "updated_date": "2025-05-17 15:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:20:39.780673"
    },
    {
      "arxiv_id": "2505.12051v1",
      "title": "Enhanced Multimodal Hate Video Detection via Channel-wise and Modality-wise Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yinghui Zhang",
        "Tailin Chen",
        "Yuchen Zhang",
        "Zeyu Fu"
      ],
      "abstract": "The rapid rise of video content on platforms such as TikTok and YouTube has\ntransformed information dissemination, but it has also facilitated the spread\nof harmful content, particularly hate videos. Despite significant efforts to\ncombat hate speech, detecting these videos remains challenging due to their\noften implicit nature. Current detection methods primarily rely on unimodal\napproaches, which inadequately capture the complementary features across\ndifferent modalities. While multimodal techniques offer a broader perspective,\nmany fail to effectively integrate temporal dynamics and modality-wise\ninteractions essential for identifying nuanced hate content. In this paper, we\npresent CMFusion, an enhanced multimodal hate video detection model utilizing a\nnovel Channel-wise and Modality-wise Fusion Mechanism. CMFusion first extracts\nfeatures from text, audio, and video modalities using pre-trained models and\nthen incorporates a temporal cross-attention mechanism to capture dependencies\nbetween video and audio streams. The learned features are then processed by\nchannel-wise and modality-wise fusion modules to obtain informative\nrepresentations of videos. Our extensive experiments on a real-world dataset\ndemonstrate that CMFusion significantly outperforms five widely used baselines\nin terms of accuracy, precision, recall, and F1 score. Comprehensive ablation\nstudies and parameter analyses further validate our design choices,\nhighlighting the model's effectiveness in detecting hate videos. The source\ncodes will be made publicly available at https://github.com/EvelynZ10/cmfusion.",
      "tldr_zh": "该研究针对视频平台上隐性仇恨视频的检测难题，提出了一种增强的多模态模型 CMFusion，利用 Channel-wise and Modality-wise Fusion Mechanism 来整合文本、音频和视频特征。模型首先通过预训练模型提取模态特征，并采用 temporal cross-attention 机制捕捉视频和音频间的时序依赖，然后通过 channel-wise 和 modality-wise 融合模块生成更具信息性的视频表示。实验结果显示，CMFusion 在真实数据集上显著优于五个基线模型，在准确率、精确率、召回率和 F1 分数方面表现出色，并通过消融实验验证了其设计有效性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "ICDMW 2024, Github: https://github.com/EvelynZ10/cmfusion",
      "pdf_url": "http://arxiv.org/pdf/2505.12051v1",
      "published_date": "2025-05-17 15:24:48 UTC",
      "updated_date": "2025-05-17 15:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:20:51.066264"
    },
    {
      "arxiv_id": "2505.12049v1",
      "title": "Beyond Scalar Rewards: An Axiomatic Framework for Lexicographic MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Mehran Shakerinava",
        "Siamak Ravanbakhsh",
        "Adam Oberman"
      ],
      "abstract": "Recent work has formalized the reward hypothesis through the lens of expected\nutility theory, by interpreting reward as utility. Hausner's foundational work\nshowed that dropping the continuity axiom leads to a generalization of expected\nutility theory where utilities are lexicographically ordered vectors of\narbitrary dimension. In this paper, we extend this result by identifying a\nsimple and practical condition under which preferences cannot be represented by\nscalar rewards, necessitating a 2-dimensional reward function. We provide a\nfull characterization of such reward functions, as well as the general\nd-dimensional case, in Markov Decision Processes (MDPs) under a memorylessness\nassumption on preferences. Furthermore, we show that optimal policies in this\nsetting retain many desirable properties of their scalar-reward counterparts,\nwhile in the Constrained MDP (CMDP) setting -- another common multiobjective\nsetting -- they do not.",
      "tldr_zh": "该论文扩展了奖励假设（reward hypothesis），通过放弃连续性公理，将效用视为词典序向量，从而构建了一个适用于词典序Markov Decision Processes (MDPs)的公理框架。研究者识别出一个简单实用的条件，即偏好无法用标量奖励表示时，需要采用二维奖励函数，并对这种二维及一般d维奖励函数在MDPs下的无记忆偏好条件下进行了完整表征。主要发现是，在这种多维设置下，最优策略保留了标量奖励策略的许多理想特性，但在Constrained MDP (CMDP)环境中则不具备这些特性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12049v1",
      "published_date": "2025-05-17 15:23:58 UTC",
      "updated_date": "2025-05-17 15:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:21:03.247331"
    },
    {
      "arxiv_id": "2505.12039v1",
      "title": "AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research",
      "title_zh": "AI驱动的自动化可以成为下一时代科学学研究的基础",
      "authors": [
        "Renqi Chen",
        "Haoyang Su",
        "Shixiang Tang",
        "Zhenfei Yin",
        "Qi Wu",
        "Hui Li",
        "Ye Sun",
        "Nanqing Dong",
        "Wanli Ouyang",
        "Philip Torr"
      ],
      "abstract": "The Science of Science (SoS) explores the mechanisms underlying scientific\ndiscovery, and offers valuable insights for enhancing scientific efficiency and\nfostering innovation. Traditional approaches often rely on simplistic\nassumptions and basic statistical tools, such as linear regression and\nrule-based simulations, which struggle to capture the complexity and scale of\nmodern research ecosystems. The advent of artificial intelligence (AI) presents\na transformative opportunity for the next generation of SoS, enabling the\nautomation of large-scale pattern discovery and uncovering insights previously\nunattainable. This paper offers a forward-looking perspective on the\nintegration of Science of Science with AI for automated research pattern\ndiscovery and highlights key open challenges that could greatly benefit from\nAI. We outline the advantages of AI over traditional methods, discuss potential\nlimitations, and propose pathways to overcome them. Additionally, we present a\npreliminary multi-agent system as an illustrative example to simulate research\nsocieties, showcasing AI's ability to replicate real-world research patterns\nand accelerate progress in Science of Science research.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)如何成为下一代科学科学(SoS)研究的基础，通过自动化大规模模式发现来解决传统方法（如线性回归和规则模拟）的局限性，从而更好地捕捉现代研究生态的复杂性。论文强调AI的优势在于提升科学效率和创新潜力，并分析了潜在挑战及其克服路径，如整合AI进行自动化研究模式发现。最终，论文通过一个初步的多智能体系统示例，展示了AI模拟真实研究社会的能力，并加速SoS领域的进展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12039v1",
      "published_date": "2025-05-17 15:01:33 UTC",
      "updated_date": "2025-05-17 15:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:21:15.706860"
    },
    {
      "arxiv_id": "2505.12038v1",
      "title": "Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Lu",
        "Shengcai Liu",
        "Jiahao Wu",
        "Weiyu Chen",
        "Zhirui Zhang",
        "Yew-Soon Ong",
        "Qi Wang",
        "Ke Tang"
      ],
      "abstract": "Large language models (LLMs) have shown great potential as general-purpose AI\nassistants across various domains. To fully leverage this potential in specific\napplications, many companies provide fine-tuning API services, enabling users\nto upload their own data for LLM customization. However, fine-tuning services\nintroduce a new safety threat: user-uploaded data, whether harmful or benign,\ncan break the model's alignment, leading to unsafe outputs. Moreover, existing\ndefense methods struggle to address the diversity of fine-tuning datasets\n(e.g., varying sizes, tasks), often sacrificing utility for safety or vice\nversa. To address this issue, we propose Safe Delta, a safety-aware\npost-training defense method that adjusts the delta parameters (i.e., the\nparameter change before and after fine-tuning). Specifically, Safe Delta\nestimates the safety degradation, selects delta parameters to maximize utility\nwhile limiting overall safety loss, and applies a safety compensation vector to\nmitigate residual safety loss. Through extensive experiments on four diverse\ndatasets with varying settings, our approach consistently preserves safety\nwhile ensuring that the utility gain from benign datasets remains unaffected.",
      "tldr_zh": "该论文针对微调大型语言模型（LLMs）时，用户上传的数据可能破坏模型安全性的问题，提出Safe Delta，一种安全感知的后训练防御方法。Safe Delta通过调整delta parameters，包括估计安全退化、选择参数以最大化实用性并应用安全补偿向量，从而在多样数据集上平衡安全性和性能。实验在四个不同数据集上验证，该方法 consistently 保持了模型的安全性，同时确保良性数据的实用性收益不受影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2505.12038v1",
      "published_date": "2025-05-17 15:01:07 UTC",
      "updated_date": "2025-05-17 15:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:21:27.167477"
    },
    {
      "arxiv_id": "2505.12031v1",
      "title": "LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Lai",
        "Jiakun Zhang",
        "Shuo Xu",
        "Taolue Chen",
        "Zihang Wang",
        "Yao Yang",
        "Jiarui Zhang",
        "Chun Cao",
        "Jingwei Xu"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have sparked considerable\ninterest in automated theorem proving and a prominent line of research\nintegrates stepwise LLM-based provers into tree search. In this paper, we\nintroduce a novel proof-state exploration approach for training data synthesis,\ndesigned to produce diverse tactics across a wide range of intermediate proof\nstates, thereby facilitating effective one-shot fine-tuning of LLM as the\npolicy model. We also propose an adaptive beam size strategy, which effectively\ntakes advantage of our data synthesis method and achieves a trade-off between\nexploration and exploitation during tree search. Evaluations on the MiniF2F and\nProofNet benchmarks demonstrate that our method outperforms strong baselines\nunder the stringent Pass@1 metric, attaining an average pass rate of $60.74\\%$\non MiniF2F and $21.18\\%$ on ProofNet. These results underscore the impact of\nlarge-scale synthetic data in advancing automated theorem proving.",
      "tldr_zh": "该论文探讨了基于LLM（Large Language Models）的自动定理证明（Automated Theorem Proving），强调了可扩展的合成数据生成在其中的关键作用。研究引入了一种新型proof-state exploration方法，用于合成多样化的训练数据，从而支持LLM作为policy model的有效one-shot fine-tuning，并提出adaptive beam size strategy来在tree search中平衡exploration和exploitation。实验结果显示，该方法在MiniF2F和ProofNet基准测试中以Pass@1指标超过了强baseline，平均通过率为60.74%和21.18%，证明了大规模synthetic data对提升自动定理证明性能的显著影响。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.12031v1",
      "published_date": "2025-05-17 14:47:36 UTC",
      "updated_date": "2025-05-17 14:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:21:40.608599"
    },
    {
      "arxiv_id": "2505.12020v1",
      "title": "GeoMaNO: Geometric Mamba Neural Operator for Partial Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Han",
        "Jingwei Zhang",
        "Dimitris Samaras",
        "Fei Hou",
        "Hong Qin"
      ],
      "abstract": "The neural operator (NO) framework has emerged as a powerful tool for solving\npartial differential equations (PDEs). Recent NOs are dominated by the\nTransformer architecture, which offers NOs the capability to capture long-range\ndependencies in PDE dynamics. However, existing Transformer-based NOs suffer\nfrom quadratic complexity, lack geometric rigor, and thus suffer from\nsub-optimal performance on regular grids. As a remedy, we propose the Geometric\nMamba Neural Operator (GeoMaNO) framework, which empowers NOs with Mamba's\nmodeling capability, linear complexity, plus geometric rigor. We evaluate\nGeoMaNO's performance on multiple standard and popularly employed PDE\nbenchmarks, spanning from Darcy flow problems to Navier-Stokes problems.\nGeoMaNO improves existing baselines in solution operator approximation by as\nmuch as 58.9%.",
      "tldr_zh": "该研究针对神经算子（NO）框架在解决偏微分方程（PDEs）时存在的二次复杂度、缺乏几何严谨性及在规则网格上性能不佳等问题，提出Geometric Mamba Neural Operator (GeoMaNO)框架。GeoMaNO结合Mamba的建模能力、线性复杂度以及几何严谨性，旨在提升NO的整体效能。在多个标准PDE基准测试中，包括Darcy flow和Navier-Stokes问题，GeoMaNO在解算子逼近方面比现有基线提高了多达58.9%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12020v1",
      "published_date": "2025-05-17 14:20:57 UTC",
      "updated_date": "2025-05-17 14:20:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:21:51.816555"
    },
    {
      "arxiv_id": "2505.12012v1",
      "title": "Empowering Sustainable Finance with Artificial Intelligence: A Framework for Responsible Implementation",
      "title_zh": "用人工智能赋能可持续金融：负责任实施的框架",
      "authors": [
        "Georgios Pavlidis"
      ],
      "abstract": "This chapter explores the convergence of two major developments: the rise of\nenvironmental, social, and governance (ESG) investing and the exponential\ngrowth of artificial intelligence (AI) technology. The increased demand for\ndiverse ESG instruments, such as green and ESG-linked loans, will be aligned\nwith the rapid growth of the global AI market, which is expected to be worth\n$1,394.30 billion by 2029. AI can assist in identifying and pricing climate\nrisks, setting more ambitious ESG goals, and advancing sustainable finance\ndecisions. However, delegating sustainable finance decisions to AI poses\nserious risks, and new principles and rules for AI and ESG investing are\nnecessary to mitigate these risks. This chapter highlights the challenges\nassociated with norm-setting initiatives and stresses the need for the\nfine-tuning of the principles of legitimacy, oversight and verification,\ntransparency, and explainability. Finally, the chapter contends that\nintegrating AI into ESG non-financial reporting necessitates a heightened sense\nof responsibility and the establishment of fundamental guiding principles\nwithin the spheres of AI and ESG investing.",
      "tldr_zh": "本论文探讨了人工智能（AI）与环境、社会和治理（ESG）投资的融合，提出一个负责任实施框架，以推动可持续金融发展。AI 可用于识别和定价气候风险、设定更雄心勃勃的 ESG 目标，并提升可持续金融决策效率，同时预计全球 AI 市场到 2029 年将达 1,394.30 亿美元。论文强调，将决策委托给 AI 会带来严重风险，因此需要制定新的原则和规则，包括合法性、监督和验证、透明度和可解释性，以缓解这些挑战。最后，该框架主张在 AI 和 ESG 投资领域加强责任感和基本指导原则，以促进非财务报告的整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12012v1",
      "published_date": "2025-05-17 14:05:39 UTC",
      "updated_date": "2025-05-17 14:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:22:04.920020"
    },
    {
      "arxiv_id": "2505.12006v1",
      "title": "SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuncheng Hua",
        "Ji Miao",
        "Mehdi Jafari",
        "Jianxiang Xie",
        "Hao Xue",
        "Flora D. Salim"
      ],
      "abstract": "This paper introduces SOCIA (Simulation Orchestration for\nCyber-physical-social Intelligence and Agents), a novel end-to-end framework\nleveraging Large Language Model (LLM)-based multi-agent systems to automate the\ngeneration of high-fidelity Cyber-Physical-Social (CPS) simulators. Addressing\nthe challenges of labor-intensive manual simulator development and complex data\ncalibration, SOCIA integrates a centralized orchestration manager that\ncoordinates specialized agents for tasks including data comprehension, code\ngeneration, simulation execution, and iterative evaluation-feedback loops.\nThrough empirical evaluations across diverse CPS tasks, such as mask adoption\nbehavior simulation (social), personal mobility generation (physical), and user\nmodeling (cyber), SOCIA demonstrates its ability to produce high-fidelity,\nscalable simulations with reduced human intervention. These results highlight\nSOCIA's potential to offer a scalable solution for studying complex CPS\nphenomena",
      "tldr_zh": "这篇论文介绍了 SOCIA，一种基于 Large Language Model (LLM) 的端到端多智能体框架，用于自动化生成高保真 Cyber-Physical-Social (CPS) 模拟器，以解决手动开发和数据校准的劳动密集型挑战。SOCIA 通过集中的协调管理器协调专门的智能体，处理数据理解、代码生成、模拟执行以及迭代评估反馈循环，确保模拟过程高效且可扩展。在各种 CPS 任务（如口罩采用行为模拟、社会层面；个人移动生成、物理层面；和用户建模、cyber层面）的实证评估中，SOCIA 显著减少了人为干预，并展示了其在研究复杂 CPS 现象方面的潜力。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 3 figures, 2 tables. The paper is under review",
      "pdf_url": "http://arxiv.org/pdf/2505.12006v1",
      "published_date": "2025-05-17 13:47:31 UTC",
      "updated_date": "2025-05-17 13:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:22:18.202945"
    },
    {
      "arxiv_id": "2505.12005v1",
      "title": "CHRIS: Clothed Human Reconstruction with Side View Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Liu",
        "Yifan Yang",
        "Zixiong Huang",
        "Yuxin Gao",
        "Mingkui Tan"
      ],
      "abstract": "Creating a realistic clothed human from a single-view RGB image is crucial\nfor applications like mixed reality and filmmaking. Despite some progress in\nrecent years, mainstream methods often fail to fully utilize side-view\ninformation, as the input single-view image contains front-view information\nonly. This leads to globally unrealistic topology and local surface\ninconsistency in side views. To address these, we introduce Clothed Human\nReconstruction with Side View Consistency, namely CHRIS, which consists of 1) A\nSide-View Normal Discriminator that enhances global visual reasonability by\ndistinguishing the generated side-view normals from the ground truth ones; 2) A\nMulti-to-One Gradient Computation (M2O) that ensures local surface consistency.\nM2O calculates the gradient of a sampling point by integrating the gradients of\nthe nearby points, effectively acting as a smooth operation. Experimental\nresults demonstrate that CHRIS achieves state-of-the-art performance on public\nbenchmarks and outperforms the prior work.",
      "tldr_zh": "该研究提出 CHRIS 框架，用于从单视图 RGB 图像重建真实衣着人体模型，旨在解决现有方法未充分利用侧视图信息导致的全局拓扑不真实和局部表面不一致问题。\nCHRIS 包括 Side-View Normal Discriminator 来区分生成的侧视图法线与真实法线，从而提升全局视觉合理性，以及 Multi-to-One Gradient Computation (M2O) 通过整合附近点的梯度进行平滑操作，确保局部表面一致性。\n实验结果显示，CHRIS 在公共基准上达到最先进性能，并优于先前工作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.12005v1",
      "published_date": "2025-05-17 13:41:46 UTC",
      "updated_date": "2025-05-17 13:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:22:29.179257"
    },
    {
      "arxiv_id": "2505.12001v1",
      "title": "Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework",
      "title_zh": "LLM 多智能体系统中的互动公平：一个评估框架",
      "authors": [
        "Ruta Binkyte"
      ],
      "abstract": "As large language models (LLMs) are increasingly used in multi-agent systems,\nquestions of fairness should extend beyond resource distribution and procedural\ndesign to include the fairness of how agents communicate. Drawing from\norganizational psychology, we introduce a novel framework for evaluating\nInteractional fairness encompassing Interpersonal fairness (IF) and\nInformational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We\nextend the theoretical grounding of Interactional Fairness to non-sentient\nagents, reframing fairness as a socially interpretable signal rather than a\nsubjective experience. We then adapt established tools from organizational\njustice research, including Colquitt's Organizational Justice Scale and the\nCritical Incident Technique, to measure fairness as a behavioral property of\nagent interaction. We validate our framework through a pilot study using\ncontrolled simulations of a resource negotiation task. We systematically\nmanipulate tone, explanation quality, outcome inequality, and task framing\n(collaborative vs. competitive) to assess how IF influences agent behavior.\nResults show that tone and justification quality significantly affect\nacceptance decisions even when objective outcomes are held constant. In\naddition, the influence of IF vs. InfF varies with context. This work lays the\nfoundation for fairness auditing and norm-sensitive alignment in LLM-MAS.",
      "tldr_zh": "本研究引入了一个评估框架，用于评估大型语言模型 (LLMs) 多智能体系统 (LLM-MAS) 中的交互公平性，包括人际公平 (Interpersonal fairness, IF) 和信息公平 (Informational fairness, InfF)。框架将交互公平理论扩展到非感性代理，将公平性视为一种可社会解释的信号，并适应组织公正研究的工具，如 Colquitt's Organizational Justice Scale 和 Critical Incident Technique，来测量代理互动的行为属性。通过一个试点研究，使用受控模拟的资源谈判任务，系统操纵语气、解释质量、结果不平等和任务框架（合作 vs. 竞争），结果显示语气和理由质量显著影响代理的接受决策，即使客观结果不变。整体而言，此框架为 LLM-MAS 中的公平审计和规范敏感对齐奠定基础。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.12001v1",
      "published_date": "2025-05-17 13:24:13 UTC",
      "updated_date": "2025-05-17 13:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:22:41.816169"
    },
    {
      "arxiv_id": "2505.13520v1",
      "title": "Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering",
      "title_zh": "超越检索",
      "authors": [
        "Hessa Alawwad",
        "Usman Naseem",
        "Areej Alhothali",
        "Ali Alkhathlan",
        "Amani Jamal"
      ],
      "abstract": "Textbook question answering (TQA) is a complex task, requiring the\ninterpretation of complex multimodal context. Although recent advances have\nimproved overall performance, they often encounter difficulties in educational\nsettings where accurate semantic alignment and task-specific document retrieval\nare essential. In this paper, we propose a novel approach to multimodal\ntextbook question answering by introducing a mechanism for enhancing semantic\nrepresentations through multi-objective joint training. Our model, Joint\nEmbedding Training With Ranking Supervision for Textbook Question Answering\n(JETRTQA), is a multimodal learning framework built on a retriever--generator\narchitecture that uses a retrieval-augmented generation setup, in which a\nmultimodal large language model generates answers. JETRTQA is designed to\nimprove the relevance of retrieved documents in complex educational contexts.\nUnlike traditional direct scoring approaches, JETRTQA learns to refine the\nsemantic representations of questions and documents through a supervised signal\nthat combines pairwise ranking and implicit supervision derived from answers.\nWe evaluate our method on the CK12-QA dataset and demonstrate that it\nsignificantly improves the discrimination between informative and irrelevant\ndocuments, even when they are long, complex, and multimodal. JETRTQA\noutperforms the previous state of the art, achieving a 2.4\\% gain in accuracy\non the validation set and 11.1\\% on the test set.",
      "tldr_zh": "该论文针对教科书问答(TQA)任务提出了一种超越传统检索的方法，强调多模态文档排名的联合监督，以处理复杂教育场景中的语义对齐和文档检索挑战。作者引入了JETRTQA框架，这是一个基于检索-生成架构的多模态学习模型，通过多目标联合训练结合配对排名和从答案派生的隐式监督，来优化问题和文档的语义表示，从而提升检索文档的相关性。在CK12-QA数据集上的实验显示，JETRTQA比现有最佳方法提高了2.4%的验证集准确率和11.1%的测试集准确率，显著改善了对长、复杂多模态文档的区分能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 16 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.13520v1",
      "published_date": "2025-05-17 13:23:54 UTC",
      "updated_date": "2025-05-17 13:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:22:52.541424"
    },
    {
      "arxiv_id": "2505.11999v1",
      "title": "MRGRP: Empowering Courier Route Prediction in Food Delivery Service with Multi-Relational Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Liu",
        "Huan Yan",
        "Hongjie Sui",
        "Haomin Wen",
        "Yuan Yuan",
        "Yuyang Han",
        "Hongsen Liao",
        "Xuetao Ding",
        "Jinghua Hao",
        "Yong Li"
      ],
      "abstract": "Instant food delivery has become one of the most popular web services\nworldwide due to its convenience in daily life. A fundamental challenge is\naccurately predicting courier routes to optimize task dispatch and improve\ndelivery efficiency. This enhances satisfaction for couriers and users and\nincreases platform profitability. The current heuristic prediction method uses\nonly limited human-selected task features and ignores couriers preferences,\ncausing suboptimal results. Additionally, existing learning-based methods do\nnot fully capture the diverse factors influencing courier decisions or the\ncomplex relationships among them. To address this, we propose a\nMulti-Relational Graph-based Route Prediction (MRGRP) method that models\nfine-grained correlations among tasks affecting courier decisions for accurate\nprediction. We encode spatial and temporal proximity, along with\npickup-delivery relationships, into a multi-relational graph and design a\nGraphFormer architecture to capture these complex connections. We also\nintroduce a route decoder that leverages courier information and dynamic\ndistance and time contexts for prediction, using existing route solutions as\nreferences to improve outcomes. Experiments show our model achieves\nstate-of-the-art route prediction on offline data from cities of various sizes.\nDeployed on the Meituan Turing platform, it surpasses the current heuristic\nalgorithm, reaching a high route prediction accuracy of 0.819, essential for\ncourier and user satisfaction in instant food delivery.",
      "tldr_zh": "即时食品配送服务中，准确预测快递员路线是优化任务分配和提高效率的关键挑战，但现有启发式方法仅依赖有限特征且忽略快递员偏好，而学习方法未能充分捕捉相关因素间的复杂关系。论文提出 MRGRP 方法，通过构建 Multi-Relational Graph 来编码任务间的空间、时间接近度和取货-送货关系，并设计 GraphFormer 架构和路线解码器，利用快递员信息及动态上下文进行预测。实验结果显示，MRGRP 在多城市离线数据上实现最先进性能，部署于 Meituan Turing 平台后准确率达 0.819，显著超越传统算法，提升了快递员和用户满意度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11999v1",
      "published_date": "2025-05-17 13:19:34 UTC",
      "updated_date": "2025-05-17 13:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:23:06.156240"
    },
    {
      "arxiv_id": "2505.13519v1",
      "title": "Continuous Domain Generalization",
      "title_zh": "连续领域泛化",
      "authors": [
        "Zekun Cai",
        "Yiheng Yao",
        "Guangji Bai",
        "Renhe Jiang",
        "Xuan Song",
        "Ryosuke Shibasaki",
        "Liang Zhao"
      ],
      "abstract": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic context. However, existing\ndomain generalization approaches typically treat domains as discrete or\nevolving along a single axis (e.g., time), which fails to capture the complex,\nmulti-dimensional nature of real-world variation. This paper introduces the\ntask of Continuous Domain Generalization (CDG), which aims to generalize\npredictive models to unseen domains defined by arbitrary combinations of\ncontinuous variation descriptors. We present a principled framework grounded in\ngeometric and algebraic theory, showing that optimal model parameters across\ndomains lie on a low-dimensional manifold. To model this structure, we propose\na Neural Lie Transport Operator (NeuralLTO), which enables structured parameter\ntransitions by enforcing geometric continuity and algebraic consistency. To\nhandle noisy or incomplete domain descriptors, we introduce a gating mechanism\nto suppress irrelevant dimensions and a local chart-based strategy for robust\ngeneralization. Extensive experiments on synthetic and real-world\ndatasets-including remote sensing, scientific documents, and traffic\nforecasting-demonstrate that our method significantly outperforms existing\nbaselines in generalization accuracy and robustness under descriptor\nimperfections.",
      "tldr_zh": "本论文引入 Continuous Domain Generalization (CDG) 任务，旨在让预测模型泛化到由多维连续变化描述符（如时间和地理）任意组合定义的未见领域，解决现有方法忽略复杂多维变化的局限。作者提出一个基于几何和代数理论的框架，表明最优模型参数位于低维流形上，并开发 Neural Lie Transport Operator (NeuralLTO) 来实现结构化参数过渡，同时通过门控机制抑制无关维度和局部图策略处理噪声或不完整描述符。在合成及真实数据集（如遥感、科学文档和交通预测）上的实验表明，该方法在泛化准确性和鲁棒性上显著优于基线模型。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "22 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13519v1",
      "published_date": "2025-05-17 12:39:45 UTC",
      "updated_date": "2025-05-17 12:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:23:18.496971"
    },
    {
      "arxiv_id": "2505.11983v2",
      "title": "Online Iterative Self-Alignment for Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ting Xiao",
        "Lei Shi",
        "Yang Zhang",
        "HaoFeng Yang",
        "Zhe Wang",
        "Chenjia Bai"
      ],
      "abstract": "Radiology Report Generation (RRG) is an important research topic for\nrelieving radiologist' heavy workload. Existing RRG models mainly rely on\nsupervised fine-tuning (SFT) based on different model architectures using data\npairs of radiological images and corresponding radiologist-annotated reports.\nRecent research has shifted focus to post-training improvements, aligning RRG\nmodel outputs with human preferences using reinforcement learning (RL).\nHowever, the limited data coverage of high-quality annotated data poses risks\nof overfitting and generalization. This paper proposes a novel Online Iterative\nSelf-Alignment (OISA) method for RRG that consists of four stages:\nself-generation of diverse data, self-evaluation for multi-objective preference\ndata,self-alignment for multi-objective optimization and self-iteration for\nfurther improvement. Our approach allows for generating varied reports tailored\nto specific clinical objectives, enhancing the overall performance of the RRG\nmodel iteratively. Unlike existing methods, our frame-work significantly\nincreases data quality and optimizes performance through iterative\nmulti-objective optimization. Experimental results demonstrate that our method\nsurpasses previous approaches, achieving state-of-the-art performance across\nmultiple evaluation metrics.",
      "tldr_zh": "这篇论文针对放射学报告生成（RRG）的问题，提出了一种新型 Online Iterative Self-Alignment (OISA) 方法，以缓解现有模型依赖监督微调（SFT）和强化学习（RL）所带来的数据覆盖不足、过拟合和泛化风险。OISA 包括四个阶段：自我生成多样数据、自我评估多目标偏好数据、自我对齐多目标优化以及自我迭代进一步改进，从而实现针对特定临床目标的报告生成和性能提升。实验结果显示，该方法在多个评估指标上超越了现有方法，达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2505.11983v2",
      "published_date": "2025-05-17 12:31:12 UTC",
      "updated_date": "2025-05-20 14:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:23:30.516835"
    },
    {
      "arxiv_id": "2505.11980v1",
      "title": "AoP-SAM: Automation of Prompts for Efficient Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Chen",
        "Mu-Young Son",
        "Chuanbo Hua",
        "Joo-Young Kim"
      ],
      "abstract": "The Segment Anything Model (SAM) is a powerful foundation model for image\nsegmentation, showing robust zero-shot generalization through prompt\nengineering. However, relying on manual prompts is impractical for real-world\napplications, particularly in scenarios where rapid prompt provision and\nresource efficiency are crucial. In this paper, we propose the Automation of\nPrompts for SAM (AoP-SAM), a novel approach that learns to generate essential\nprompts in optimal locations automatically. AoP-SAM enhances SAM's efficiency\nand usability by eliminating manual input, making it better suited for\nreal-world tasks. Our approach employs a lightweight yet efficient Prompt\nPredictor model that detects key entities across images and identifies the\noptimal regions for placing prompt candidates. This method leverages SAM's\nimage embeddings, preserving its zero-shot generalization capabilities without\nrequiring fine-tuning. Additionally, we introduce a test-time instance-level\nAdaptive Sampling and Filtering mechanism that generates prompts in a\ncoarse-to-fine manner. This notably enhances both prompt and mask generation\nefficiency by reducing computational overhead and minimizing redundant mask\nrefinements. Evaluations of three datasets demonstrate that AoP-SAM\nsubstantially improves both prompt generation efficiency and mask generation\naccuracy, making SAM more effective for automated segmentation tasks.",
      "tldr_zh": "本文提出 AoP-SAM，一种自动生成提示的方法，旨在提升 Segment Anything Model (SAM) 在图像分割中的效率，解决手动提示依赖的问题。AoP-SAM 采用轻量级的 Prompt Predictor 模型，利用 SAM 的图像嵌入来检测关键实体并选择最佳提示位置，同时引入测试时的实例级 Adaptive Sampling and Filtering 机制，实现从粗到细的提示生成，减少计算开销。实验在三个数据集上证明，该方法显著提高了提示生成效率和掩码生成准确性，使 SAM 更适用于真实世界的自动化分割任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11980v1",
      "published_date": "2025-05-17 12:27:36 UTC",
      "updated_date": "2025-05-17 12:27:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:23:40.429224"
    },
    {
      "arxiv_id": "2505.11979v1",
      "title": "Introduction to Analytical Software Engineering Design Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Tarik Houichime",
        "Younes El Amrani"
      ],
      "abstract": "As modern software systems expand in scale and complexity, the challenges\nassociated with their modeling and formulation grow increasingly intricate.\nTraditional approaches often fall short in effectively addressing these\ncomplexities, particularly in tasks such as design pattern detection for\nmaintenance and assessment, as well as code refactoring for optimization and\nlong-term sustainability. This growing inadequacy underscores the need for a\nparadigm shift in how such challenges are approached and resolved. This paper\npresents Analytical Software Engineering (ASE), a novel design paradigm aimed\nat balancing abstraction, tool accessibility, compatibility, and scalability.\nASE enables effective modeling and resolution of complex software engineering\nproblems. The paradigm is evaluated through two frameworks\nBehavioral-Structural Sequences (BSS) and Optimized Design Refactoring (ODR),\nboth developed in accordance with ASE principles. BSS offers a compact,\nlanguage-agnostic representation of codebases to facilitate precise design\npattern detection. ODR unifies artifact and solution representations to\noptimize code refactoring via heuristic algorithms while eliminating iterative\ncomputational overhead. By providing a structured approach to software design\nchallenges, ASE lays the groundwork for future research in encoding and\nanalyzing complex software metrics.",
      "tldr_zh": "本论文介绍了Analytical Software Engineering (ASE) 范式，以应对现代软件系统规模和复杂性带来的挑战，如设计模式检测和代码重构的不足。ASE 强调平衡抽象性、工具可访问性、兼容性和可扩展性，从而有效建模和解决复杂软件工程问题。该范式通过Behavioral-Structural Sequences (BSS) 框架实现紧凑的语言无关代码表示以精确检测设计模式，以及Optimized Design Refactoring (ODR) 框架统一表示并使用启发式算法优化重构，消除迭代计算开销。最终，ASE 为编码和分析复杂软件指标的未来研究奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.MS",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "The Conference's autorization to submit a preprint was granted",
      "pdf_url": "http://arxiv.org/pdf/2505.11979v1",
      "published_date": "2025-05-17 12:23:55 UTC",
      "updated_date": "2025-05-17 12:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:23:52.931948"
    },
    {
      "arxiv_id": "2505.13518v1",
      "title": "Data Balancing Strategies: A Survey of Resampling and Augmentation Methods",
      "title_zh": "数据平衡策略：重采样和",
      "authors": [
        "Behnam Yousefimehr",
        "Mehdi Ghatee",
        "Mohammad Amin Seifi",
        "Javad Fazli",
        "Sajed Tavakoli",
        "Zahra Rafei",
        "Shervin Ghaffari",
        "Abolfazl Nikahd",
        "Mahdi Razi Gandomani",
        "Alireza Orouji",
        "Ramtin Mahmoudi Kashani",
        "Sarina Heshmati",
        "Negin Sadat Mousavi"
      ],
      "abstract": "Imbalanced data poses a significant obstacle in machine learning, as an\nunequal distribution of class labels often results in skewed predictions and\ndiminished model accuracy. To mitigate this problem, various resampling\nstrategies have been developed, encompassing both oversampling and\nundersampling techniques aimed at modifying class proportions. Conventional\noversampling approaches like SMOTE enhance the representation of the minority\nclass, whereas undersampling methods focus on trimming down the majority class.\nAdvances in deep learning have facilitated the creation of more complex\nsolutions, such as Generative Adversarial Networks (GANs) and Variational\nAutoencoders (VAEs), which are capable of producing high-quality synthetic\nexamples. This paper reviews a broad spectrum of data balancing methods,\nclassifying them into categories including synthetic oversampling, adaptive\ntechniques, generative models, ensemble-based strategies, hybrid approaches,\nundersampling, and neighbor-based methods. Furthermore, it highlights current\ndevelopments in resampling techniques and discusses practical implementations\nand case studies that validate their effectiveness. The paper concludes by\noffering perspectives on potential directions for future exploration in this\ndomain.",
      "tldr_zh": "该论文调查了机器学习中数据不平衡问题如何导致预测偏差和模型准确性下降，并总结了各种重采样和数据增强策略来缓解这一问题。方法包括传统过采样技术如 SMOTE、欠采样方法，以及先进生成模型如 GANs 和 VAEs，这些被分类为合成过采样、适应性技术、生成模型、集成策略、混合方法、欠采样和基于邻居的方法。论文通过讨论实际实现、案例研究和当前发展，展示了这些策略的有效性，并为未来数据平衡研究提供了潜在方向。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13518v1",
      "published_date": "2025-05-17 12:15:28 UTC",
      "updated_date": "2025-05-17 12:15:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:24:04.922032"
    },
    {
      "arxiv_id": "2505.11966v1",
      "title": "Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier",
      "title_zh": "翻译失败",
      "authors": [
        "Jianyuan Zhong",
        "Zeju Li",
        "Zhijian Xu",
        "Xiangyu Wen",
        "Kezhi Li",
        "Qiang Xu"
      ],
      "abstract": "Large Language Model (LLM) reasoning for complex tasks inherently involves a\ntrade-off between solution accuracy and computational efficiency. The\nsubsequent step of verification, while intended to improve performance, further\ncomplicates this landscape by introducing its own challenging trade-off:\nsophisticated Generative Reward Models (GenRMs) can be computationally\nprohibitive if naively integrated with LLMs at test-time, while simpler, faster\nmethods may lack reliability. To overcome these challenges, we introduce\nFlexiVe, a novel generative verifier that flexibly balances computational\nresources between rapid, reliable fast thinking and meticulous slow thinking\nusing a Flexible Allocation of Verification Budget strategy. We further propose\nthe Solve-Detect-Verify pipeline, an efficient inference-time scaling framework\nthat intelligently integrates FlexiVe, proactively identifying solution\ncompletion points to trigger targeted verification and provide focused solver\nfeedback. Experiments show FlexiVe achieves superior accuracy in pinpointing\nerrors within reasoning traces on ProcessBench. Furthermore, on challenging\nmathematical reasoning benchmarks (AIME 2024, AIME 2025, and CNMO), our full\napproach outperforms baselines like self-consistency in reasoning accuracy and\ninference efficiency. Our system offers a scalable and effective solution to\nenhance LLM reasoning at test time.",
      "tldr_zh": "这篇论文针对大型语言模型 (LLM) 在复杂任务推理中准确性和计算效率的权衡问题，引入了 Flexible Generative Verifier (FlexiVe)，一种灵活的生成式验证器，通过 Flexible Allocation of Verification Budget 策略平衡快速可靠的快速思考和 meticulous 慢速思考。论文提出 Solve-Detect-Verify 管道，这是一个高效的推理时缩放框架，能够智能整合 FlexiVe，主动识别解决方案完成点并提供针对性反馈，以提升整体性能。实验结果显示，FlexiVe 在 ProcessBench 上精确识别推理痕迹中的错误，而在 AIME 2024、AIME 2025 和 CNMO 等数学推理基准上，该方法在推理准确性和推理效率上均优于基线如 self-consistency，提供了一个可扩展的 LLM 推理增强方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11966v1",
      "published_date": "2025-05-17 11:41:44 UTC",
      "updated_date": "2025-05-17 11:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:24:19.241127"
    },
    {
      "arxiv_id": "2505.11963v1",
      "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Collini",
        "Baleegh Ahmad",
        "Joey Ah-kiow",
        "Ramesh Karri"
      ],
      "abstract": "Hardware security verification is a challenging and time-consuming task. For\nthis purpose, design engineers may utilize tools such as formal verification,\nlinters, and functional simulation tests, coupled with analysis and a deep\nunderstanding of the hardware design being inspected. Large Language Models\n(LLMs) have been used to assist during this task, either directly or in\nconjunction with existing tools. We improve the state of the art by proposing\nMARVEL, a multi-agent LLM framework for a unified approach to decision-making,\ntool use, and reasoning. MARVEL mimics the cognitive process of a designer\nlooking for security vulnerabilities in RTL code. It consists of a supervisor\nagent that devises the security policy of the system-on-chips (SoCs) using its\nsecurity documentation. It delegates tasks to validate the security policy to\nindividual executor agents. Each executor agent carries out its assigned task\nusing a particular strategy. Each executor agent may use one or more tools to\nidentify potential security bugs in the design and send the results back to the\nsupervisor agent for further analysis and confirmation. MARVEL includes\nexecutor agents that leverage formal tools, linters, simulation tests,\nLLM-based detection schemes, and static analysis-based checks. We test our\napproach on a known buggy SoC based on OpenTitan from the Hack@DATE\ncompetition. We find that 20 of the 48 issues reported by MARVEL pose security\nvulnerabilities.",
      "tldr_zh": "论文提出 MARVEL，一种基于 Large Language Models (LLMs) 的多智能体框架，用于统一决策、工具使用和推理，以提升 RTL 代码的安全漏洞提取效率。该框架模仿设计师的认知过程，包括一个监督者代理负责制定 SoC 的安全策略，并分配任务给多个执行者代理，这些代理采用特定策略并利用正式工具、linters、模拟测试、LLM-based 检测和静态分析进行漏洞识别。在对 OpenTitan SoC 的测试中，MARVEL 报告了 48 个问题，其中 20 个被确认是安全漏洞，展示了其在硬件安全验证中的潜在优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted for Peer Review",
      "pdf_url": "http://arxiv.org/pdf/2505.11963v1",
      "published_date": "2025-05-17 11:31:24 UTC",
      "updated_date": "2025-05-17 11:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:24:29.237588"
    },
    {
      "arxiv_id": "2505.11962v1",
      "title": "CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World",
      "title_zh": "翻译失败",
      "authors": [
        "Zoya Volovikova",
        "Gregory Gorbov",
        "Petr Kuderov",
        "Aleksandr I. Panov",
        "Alexey Skrynnik"
      ],
      "abstract": "Following instructions in real-world conditions requires the ability to adapt\nto the world's volatility and entanglement: the environment is dynamic and\nunpredictable, instructions can be linguistically complex with diverse\nvocabulary, and the number of possible goals an agent may encounter is vast.\nDespite extensive research in this area, most studies are conducted in static\nenvironments with simple instructions and a limited vocabulary, making it\ndifficult to assess agent performance in more diverse and challenging settings.\nTo address this gap, we introduce CrafText, a benchmark for evaluating\ninstruction following in a multimodal environment with diverse instructions and\ndynamic interactions. CrafText includes 3,924 instructions with 3,423 unique\nwords, covering Localization, Conditional, Building, and Achievement tasks.\nAdditionally, we propose an evaluation protocol that measures an agent's\nability to generalize to novel instruction formulations and dynamically\nevolving task configurations, providing a rigorous test of both linguistic\nunderstanding and adaptive decision-making.",
      "tldr_zh": "该论文引入 CrafText benchmark，以评估代理在复杂多模态开放世界中的指令跟随能力，解决现有研究在静态环境和简单指令下的局限性。CrafText 包括 3,924 条指令和 3,423 个独特词汇，涵盖 Localization, Conditional, Building 和 Achievement 任务，支持动态互动和词汇多样性。同时，论文提出一个评估协议，测试代理对新指令表述和动态任务配置的泛化能力，从而提升语言理解和适应决策的表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11962v1",
      "published_date": "2025-05-17 11:25:46 UTC",
      "updated_date": "2025-05-17 11:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:24:40.897369"
    },
    {
      "arxiv_id": "2505.11953v1",
      "title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning",
      "title_zh": "探索损失重新加权的标准以增强LLM遗忘",
      "authors": [
        "Puning Yang",
        "Qizhou Wang",
        "Zhuo Huang",
        "Tongliang Liu",
        "Chengqi Zhang",
        "Bo Han"
      ],
      "abstract": "Loss reweighting has shown significant benefits for machine unlearning with\nlarge language models (LLMs). However, their exact functionalities are left\nunclear and the optimal strategy remains an open question, thus impeding the\nunderstanding and improvement of existing methodologies. In this paper, we\nidentify two distinct goals of loss reweighting, namely, Saturation and\nImportance -- the former indicates that those insufficiently optimized data\nshould be emphasized, while the latter stresses some critical data that are\nmost influential for loss minimization. To study their usefulness, we design\nspecific reweighting strategies for each goal and evaluate their respective\neffects on unlearning. We conduct extensive empirical analyses on\nwell-established benchmarks, and summarize some important observations as\nfollows: (i) Saturation enhances efficacy more than importance-based\nreweighting, and their combination can yield additional improvements. (ii)\nSaturation typically allocates lower weights to data with lower likelihoods,\nwhereas importance-based reweighting does the opposite. (iii) The efficacy of\nunlearning is also largely influenced by the smoothness and granularity of the\nweight distributions. Based on these findings, we propose SatImp, a simple\nreweighting method that combines the advantages of both saturation and\nimportance. Empirical results on extensive datasets validate the efficacy of\nour method, potentially bridging existing research gaps and indicating\ndirections for future research. Our code is available at\nhttps://github.com/Puning97/SatImp-for-LLM-Unlearning.",
      "tldr_zh": "本文探讨了 loss reweighting 在提升大型语言模型(LLMs) unlearning 效果中的标准，识别了两个关键目标：Saturation（强调优化不足的数据）和 Importance（突出对损失最小化最有影响的数据）。研究设计了针对每个目标的具体 reweighting 策略，并通过广泛实证分析发现，Saturation 比 Importance 更能提升 unlearning 效能，二者结合可进一步优化，且权重分布的平滑性和粒度对效果至关重要。最终，作者提出了 SatImp 方法，结合上述优势，并在多个数据集上验证了其有效性，为未来 LLM unlearning 研究提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11953v1",
      "published_date": "2025-05-17 10:41:22 UTC",
      "updated_date": "2025-05-17 10:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:24:53.041872"
    },
    {
      "arxiv_id": "2505.11946v1",
      "title": "Let's have a chat with the EU AI Act",
      "title_zh": "来和欧盟 AI Act 聊聊",
      "authors": [
        "Adam Kovari",
        "Yasin Ghafourian",
        "Csaba Hegedus",
        "Belal Abu Naim",
        "Kitti Mezei",
        "Pal Varga",
        "Markus Tauber"
      ],
      "abstract": "As artificial intelligence (AI) regulations evolve and the regulatory\nlandscape develops and becomes more complex, ensuring compliance with ethical\nguidelines and legal frameworks remains a challenge for AI developers. This\npaper introduces an AI-driven self-assessment chatbot designed to assist users\nin navigating the European Union AI Act and related standards. Leveraging a\nRetrieval-Augmented Generation (RAG) framework, the chatbot enables real-time,\ncontext-aware compliance verification by retrieving relevant regulatory texts\nand providing tailored guidance. By integrating both public and proprietary\nstandards, it streamlines regulatory adherence, reduces complexity, and fosters\nresponsible AI development. The paper explores the chatbot's architecture,\ncomparing naive and graph-based RAG models, and discusses its potential impact\non AI governance.",
      "tldr_zh": "这篇论文引入了一个基于人工智能的自评估聊天机器人，旨在帮助用户导航欧盟 AI Act（EU AI Act）及其相关标准，确保合规性。该机器人采用 Retrieval-Augmented Generation (RAG) 框架，提供实时、上下文相关的监管文本检索和定制指导，通过整合公共和专有标准简化了遵守过程。论文比较了 naive 和 graph-based RAG 模型的架构设计，并讨论了该工具在促进负责任 AI 开发和提升 AI 治理方面的潜在影响。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11946v1",
      "published_date": "2025-05-17 10:24:08 UTC",
      "updated_date": "2025-05-17 10:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:25:05.232688"
    },
    {
      "arxiv_id": "2505.11942v1",
      "title": "LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners",
      "title_zh": "LifelongAgentBench：评估 LLM 代理作为终生学习者",
      "authors": [
        "Junhao Zheng",
        "Xidi Cai",
        "Qiuke Li",
        "Duzhen Zhang",
        "ZhongZhi Li",
        "Yingying Zhang",
        "Le Song",
        "Qianli Ma"
      ],
      "abstract": "Lifelong learning is essential for intelligent agents operating in dynamic\nenvironments. Current large language model (LLM)-based agents, however, remain\nstateless and unable to accumulate or transfer knowledge over time. Existing\nbenchmarks treat agents as static systems and fail to evaluate lifelong\nlearning capabilities. We present LifelongAgentBench, the first unified\nbenchmark designed to systematically assess the lifelong learning ability of\nLLM agents. It provides skill-grounded, interdependent tasks across three\ninteractive environments, Database, Operating System, and Knowledge Graph, with\nautomatic label verification, reproducibility, and modular extensibility.\nExtensive experiments reveal that conventional experience replay has limited\neffectiveness for LLM agents due to irrelevant information and context length\nconstraints. We further introduce a group self-consistency mechanism that\nsignificantly improves lifelong learning performance. We hope\nLifelongAgentBench will advance the development of adaptive, memory-capable LLM\nagents.",
      "tldr_zh": "该论文提出了 LifelongAgentBench，这是首个统一基准，用于系统评估大语言模型 (LLM) 代理的终身学习能力，以解决现有代理无法积累知识的局限性。该基准包括基于技能的相互依赖任务，分布在 Database、Operating System 和 Knowledge Graph 等三个交互环境，并支持自动标签验证、可重复性和模块化扩展。实验结果显示，传统经验回放 (experience replay) 对 LLM 代理效果有限，主要是由于无关信息和上下文长度限制；作者引入了群组自一致性机制 (group self-consistency mechanism)，显著提升了终身学习性能。该基准有望推动开发更具适应性和记忆能力的 LLM 代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11942v1",
      "published_date": "2025-05-17 10:09:11 UTC",
      "updated_date": "2025-05-17 10:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:25:17.613739"
    },
    {
      "arxiv_id": "2505.11939v1",
      "title": "Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Haitao Li",
        "Che Liu",
        "Zhengyao Ding",
        "Ziyi Liu",
        "Zhengxing Huang"
      ],
      "abstract": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular\ndiseases. While previous ECG-text contrastive learning methods have shown\npromising results, they often overlook the incompleteness of the reports. Given\nan ECG, the report is generated by first identifying key waveform features and\nthen inferring the final diagnosis through these features. Despite their\nimportance, these waveform features are often not recorded in the report as\nintermediate results. Aligning ECGs with such incomplete reports impedes the\nmodel's ability to capture the ECG's waveform features and limits its\nunderstanding of diagnostic reasoning based on those features. To address this,\nwe propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which\naims to recover these waveform features from incomplete reports with the help\nof large language models (LLMs), under the challenges of hallucinations and the\nnon-bijective relationship between waveform features and diagnoses.\nAdditionally, considering the frequent false negatives due to the prevalence of\ncommon diagnoses in ECGs, we introduce a semantic similarity matrix to guide\ncontrastive learning. Furthermore, we adopt a sigmoid-based loss function to\naccommodate the multi-label nature of ECG-related tasks. Experiments on six\ndatasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both\nzero-shot prediction and linear probing across these datasets.",
      "tldr_zh": "该论文针对心电图(ECG)报告的不完整性问题，提出了一种细粒度对比学习方法FG-CLEP，通过增强波形理解来改善ECG-文本对齐。FG-CLEP利用大型语言模型(LLMs)从不完整的报告中恢复关键波形特征，同时处理幻觉和非双射关系的挑战，并引入语义相似性矩阵和基于sigmoid的损失函数来优化多标签对比学习。实验结果显示，该方法在六个数据集上，在零样本预测和线性探测任务中均优于现有最先进方法，显著提升了ECG诊断的准确性和鲁棒性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11939v1",
      "published_date": "2025-05-17 10:03:06 UTC",
      "updated_date": "2025-05-17 10:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:25:30.062368"
    },
    {
      "arxiv_id": "2505.11936v1",
      "title": "How can Diffusion Models Evolve into Continual Generators?",
      "title_zh": "扩散模型如何演化成持续生成器？",
      "authors": [
        "Jingren Liu",
        "Zhong Ji",
        "Xiangyu Chen"
      ],
      "abstract": "While diffusion models have achieved remarkable success in static data\ngeneration, their deployment in streaming or continual learning (CL) scenarios\nfaces a major challenge: catastrophic forgetting (CF), where newly acquired\ngenerative capabilities overwrite previously learned ones. To systematically\naddress this, we introduce a formal Continual Diffusion Generation (CDG)\nparadigm that characterizes and redefines CL in the context of generative\ndiffusion models. Prior efforts often adapt heuristic strategies from continual\nclassification tasks but lack alignment with the underlying diffusion process.\nIn this work, we develop the first theoretical framework for CDG by analyzing\ncross-task dynamics in diffusion-based generative modeling. Our analysis\nreveals that the retention and stability of generative knowledge across tasks\nare governed by three key consistency criteria: inter-task knowledge\nconsistency (IKC), unconditional knowledge consistency (UKC), and label\nknowledge consistency (LKC). Building on these insights, we propose Continual\nConsistency Diffusion (CCD), a principled framework that integrates these\nconsistency objectives into training via hierarchical loss terms\n$\\mathcal{L}_{IKC}$, $\\mathcal{L}_{UKC}$, and $\\mathcal{L}_{LKC}$. This\npromotes effective knowledge retention while enabling the assimilation of new\ngenerative capabilities. Extensive experiments on four benchmark datasets\ndemonstrate that CCD achieves state-of-the-art performance under continual\nsettings, with substantial gains in Mean Fidelity (MF) and Incremental Mean\nFidelity (IMF), particularly in tasks with rich cross-task knowledge overlap.",
      "tldr_zh": "扩散模型（diffusion models）在持续学习（continual learning, CL）场景中面临灾难性遗忘（catastrophic forgetting）问题，导致新生成能力覆盖旧知识，本文引入了正式的 Continual Diffusion Generation (CDG) 范式，并开发了第一个理论框架来分析扩散模型中的跨任务动态。框架揭示了三个关键一致性标准：inter-task knowledge consistency (IKC)、unconditional knowledge consistency (UKC) 和 label knowledge consistency (LKC)。为此，作者提出 Continual Consistency Diffusion (CCD) 框架，通过分层损失函数（$\\mathcal{L}_{IKC}$、$\\mathcal{L}_{UKC}$ 和 $\\mathcal{L}_{LKC}$）整合这些标准，以实现知识保留和新生成能力的融合。实验在四个基准数据集上证明，CCD 在 Mean Fidelity (MF) 和 Incremental Mean Fidelity (IMF) 上实现了最先进性能，尤其在跨任务知识重叠丰富的任务中取得显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11936v1",
      "published_date": "2025-05-17 09:49:25 UTC",
      "updated_date": "2025-05-17 09:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:25:43.376461"
    },
    {
      "arxiv_id": "2505.11933v1",
      "title": "Conversational Recommendation System using NLP and Sentiment Analysis",
      "title_zh": "基于 NLP 和情感分析的对话式推荐系统",
      "authors": [
        "Piyush Talegaonkar",
        "Siddhant Hole",
        "Shrinesh Kamble",
        "Prashil Gulechha",
        "Deepali Salapurkar"
      ],
      "abstract": "In today's digitally-driven world, the demand for personalized and\ncontext-aware recommendations has never been greater. Traditional recommender\nsystems have made significant strides in this direction, but they often lack\nthe ability to tap into the richness of conversational data. This paper\nrepresents a novel approach to recommendation systems by integrating\nconversational insights into the recommendation process. The Conversational\nRecommender System integrates cutting-edge technologies such as deep learning,\nleveraging machine learning algorithms like Apriori for Association Rule\nMining, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN),\nand Long Short-Term Memory (LTSM). Furthermore, sophisticated voice recognition\ntechnologies, including Hidden Markov Models (HMMs) and Dynamic Time Warping\n(DTW) algorithms, play a crucial role in accurate speech-to-text conversion,\nensuring robust performance in diverse environments. The methodology\nincorporates a fusion of content-based and collaborative recommendation\napproaches, enhancing them with NLP techniques. This innovative integration\nensures a more personalized and context-aware recommendation experience,\nparticularly in marketing applications.",
      "tldr_zh": "这篇论文提出了一种整合自然语言处理(NLP)和情感分析(Sentiment Analysis)的对话推荐系统，以利用对话数据提升推荐的个性化与上下文感知性。系统采用机器学习算法如Apriori、卷积神经网络(CNN)、循环神经网络(RNN)和长短时记忆网络(LSTM)，并结合隐马尔可夫模型(HMM)和动态时间弯曲(DTW)进行语音识别，从而融合内容-based和协作推荐方法。实验结果表明，该系统在营销应用中显著提高了推荐的准确性和相关性，提供更高效的用户体验。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented in ISETE conference (International Conference on Artificial\n  Intelligence, Machine Learning and Big Data Engineering 2024)",
      "pdf_url": "http://arxiv.org/pdf/2505.11933v1",
      "published_date": "2025-05-17 09:36:05 UTC",
      "updated_date": "2025-05-17 09:36:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:25:52.842072"
    },
    {
      "arxiv_id": "2505.11930v1",
      "title": "The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Sälzer",
        "Przemysław Andrzej Wałęga",
        "Martin Lange"
      ],
      "abstract": "In recent years, the expressive power of various neural architectures --\nincluding graph neural networks (GNNs), transformers, and recurrent neural\nnetworks -- has been characterised using tools from logic and formal language\ntheory. As the capabilities of basic architectures are becoming well\nunderstood, increasing attention is turning to models that combine multiple\narchitectural paradigms. Among them particularly important, and challenging to\nanalyse, are temporal extensions of GNNs, which integrate both spatial\n(graph-structure) and temporal (evolution over time) dimensions. In this paper,\nwe initiate the study of logical characterisation of temporal GNNs by\nconnecting them to two-dimensional product logics. We show that the expressive\npower of temporal GNNs depends on how graph and temporal components are\ncombined. In particular, temporal GNNs that apply static GNNs recursively over\ntime can capture all properties definable in the product logic of (past)\npropositional temporal logic PTL and the modal logic K. In contrast,\narchitectures such as graph-and-time TGNNs and global TGNNs can only express\nrestricted fragments of this logic, where the interaction between temporal and\nspatial operators is syntactically constrained. These results yield the first\nlogical characterisations of temporal GNNs and establish new relative\nexpressiveness results for temporal GNNs.",
      "tldr_zh": "本研究使用二维乘积逻辑（two-dimensional product logics）对时间图神经网络（temporal GNNs）的逻辑表达能力进行表征，探讨了这些网络在整合空间（图结构）和时间（演化）维度时的表现。研究发现，递归应用静态 GNNs 的 temporal GNNs 可以捕捉 PTL（过去命题时态逻辑）和 K（模态逻辑）的乘积逻辑中定义的所有属性，而 TGNNs 和 global TGNNs 仅能表达该逻辑的受限片段，其中时空操作符的交互受到语法约束。这些结果提供了 temporal GNNs 的首次逻辑表征，并确立了不同 temporal GNNs 之间的新相对表达能力比较。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11930v1",
      "published_date": "2025-05-17 09:34:57 UTC",
      "updated_date": "2025-05-17 09:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:26:06.417015"
    },
    {
      "arxiv_id": "2505.11926v1",
      "title": "SafeVid: Toward Safety Aligned Video Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yixu Wang",
        "Jiaxin Song",
        "Yifeng Gao",
        "Xin Wang",
        "Yang Yao",
        "Yan Teng",
        "Xingjun Ma",
        "Yingchun Wang",
        "Yu-Gang Jiang"
      ],
      "abstract": "As Video Large Multimodal Models (VLMMs) rapidly advance, their inherent\ncomplexity introduces significant safety challenges, particularly the issue of\nmismatched generalization where static safety alignments fail to transfer to\ndynamic video contexts. We introduce SafeVid, a framework designed to instill\nvideo-specific safety principles in VLMMs. SafeVid uniquely transfers robust\ntextual safety alignment capabilities to the video domain by employing detailed\ntextual video descriptions as an interpretive bridge, facilitating LLM-based\nrule-driven safety reasoning. This is achieved through a closed-loop system\ncomprising: 1) generation of SafeVid-350K, a novel 350,000-pair video-specific\nsafety preference dataset; 2) targeted alignment of VLMMs using Direct\nPreference Optimization (DPO); and 3) comprehensive evaluation via our new\nSafeVidBench benchmark. Alignment with SafeVid-350K significantly enhances VLMM\nsafety, with models like LLaVA-NeXT-Video demonstrating substantial\nimprovements (e.g., up to 42.39%) on SafeVidBench. SafeVid provides critical\nresources and a structured approach, demonstrating that leveraging textual\ndescriptions as a conduit for safety reasoning markedly improves the safety\nalignment of VLMMs. We have made SafeVid-350K dataset\n(https://huggingface.co/datasets/yxwang/SafeVid-350K) publicly available.",
      "tldr_zh": "该论文提出 SafeVid 框架，旨在解决 Video Large Multimodal Models (VLMMs) 在动态视频上下文中的安全对齐问题，特别是静态对齐无法有效转移的问题。SafeVid 通过使用详细的文本视频描述作为桥梁，将文本安全对齐能力转移到视频领域，并采用 LLM-based 规则驱动的安全推理，形成一个闭环系统，包括生成 35 万对的 SafeVid-350K 安全偏好数据集、使用 Direct Preference Optimization (DPO) 进行针对性对齐，以及通过 SafeVidBench 基准进行全面评估。实验结果显示，与 SafeVid-350K 对齐后，模型如 LLaVA-NeXT-Video 在安全性能上提升高达 42.39%。这一方法证明，利用文本描述作为安全推理的管道，能显著提升 VLMMs 的安全性和可靠性，并已公开 SafeVid-350K 数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11926v1",
      "published_date": "2025-05-17 09:21:33 UTC",
      "updated_date": "2025-05-17 09:21:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:26:19.956207"
    },
    {
      "arxiv_id": "2505.11924v1",
      "title": "An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Ting Lee",
        "Hui-Ying Shih",
        "Fu-Chieh Chang",
        "Pei-Yuan Wu"
      ],
      "abstract": "We provide an explanation for the performance gains of intrinsic\nself-correction, a process where a language model iteratively refines its\noutputs without external feedback. More precisely, we investigate how prompting\ninduces interpretable changes in hidden states and thus affects the output\ndistributions. We hypothesize that each prompt-induced shift lies in a linear\nspan of some linear representation vectors, naturally separating tokens based\non individual concept alignment. Building around this idea, we give a\nmathematical formulation of self-correction and derive a concentration result\nfor output tokens based on alignment magnitudes. Our experiments on text\ndetoxification with zephyr-7b-sft reveal a substantial gap in the inner\nproducts of the prompt-induced shifts and the unembeddings of the top-100 most\ntoxic tokens vs. those of the unembeddings of the bottom-100 least toxic\ntokens, under toxic instructions. This suggests that self-correction prompts\nenhance a language model's capability of latent concept recognition. Our\nanalysis offers insights into the underlying mechanism of self-correction by\ncharacterizing how prompting works explainably. For reproducibility, our code\nis available.",
      "tldr_zh": "该论文解释了内在自校正（intrinsic self-correction）的性能提升机制，重点探讨提示（prompting）如何通过线性表示（linear representations）和潜在概念（latent concepts）诱导隐藏状态的可解释变化，从而影响输出分布。研究者假设每个提示诱导的移位位于某些线性表示向量的张量中，并推导了基于概念对齐大小的输出标记集中结果的数学公式。在zephyr-7b-sft模型的文本净化实验中，结果显示自校正提示显著增强了语言模型对潜在概念的识别能力，为可解释的提示机制提供了新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11924v1",
      "published_date": "2025-05-17 09:18:37 UTC",
      "updated_date": "2025-05-17 09:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:26:32.233148"
    },
    {
      "arxiv_id": "2505.11912v1",
      "title": "Modèles de Substitution pour les Modèles à base d'Agents : Enjeux, Méthodes et Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Saves",
        "Nicolas Verstaevel",
        "Benoît Gaudou"
      ],
      "abstract": "Multi-agent simulations enables the modeling and analyses of the dynamic\nbehaviors and interactions of autonomous entities evolving in complex\nenvironments. Agent-based models (ABM) are widely used to study emergent\nphenomena arising from local interactions. However, their high computational\ncost poses a significant challenge, particularly for large-scale simulations\nrequiring extensive parameter exploration, optimization, or uncertainty\nquantification. The increasing complexity of ABM limits their feasibility for\nreal-time decision-making and large-scale scenario analysis. To address these\nlimitations, surrogate models offer an efficient alternative by learning\napproximations from sparse simulation data. These models provide\ncheap-to-evaluate predictions, significantly reducing computational costs while\nmaintaining accuracy. Various machine learning techniques, including regression\nmodels, neural networks, random forests and Gaussian processes, have been\napplied to construct robust surrogates. Moreover, uncertainty quantification\nand sensitivity analysis play a crucial role in enhancing model reliability and\ninterpretability.\n  This article explores the motivations, methods, and applications of surrogate\nmodeling for ABM, emphasizing the trade-offs between accuracy, computational\nefficiency, and interpretability. Through a case study on a segregation model,\nwe highlight the challenges associated with building and validating surrogate\nmodels, comparing different approaches and evaluating their performance.\nFinally, we discuss future perspectives on integrating surrogate models within\nABM to improve scalability, explainability, and real-time decision support\nacross various fields such as ecology, urban planning and economics.",
      "tldr_zh": "本研究探讨了代理模型（surrogate models）在基于智能体模型（Agent-based models, ABM）中的应用，以解决多智能体模拟（multi-agent simulations）的高计算成本问题，从而支持大规模参数探索、优化和不确定性量化（uncertainty quantification）。作者评估了多种机器学习技术，如回归模型（regression models）、神经网络（neural networks）、随机森林（random forests）和高斯过程（Gaussian processes），用于构建高效的代理模型，这些模型在保持准确性的同时显著降低了计算开销。论文通过一个隔离模型（segregation model）的案例研究，比较了不同方法的性能，并突出了在准确性、计算效率和可解释性（interpretability）之间的权衡。最后，讨论了将代理模型整合到 ABM 中的未来前景，以提升可扩展性（scalability）和实时决策支持，适用于生态学、城市规划和经济学等领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, in French language. Les 33\\`emes Journ\\'ees Francophones\n  sur les Syst\\`emes Multi-Agents (JFSMA 2025). 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11912v1",
      "published_date": "2025-05-17 08:55:33 UTC",
      "updated_date": "2025-05-17 08:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:26:43.410390"
    },
    {
      "arxiv_id": "2505.11904v1",
      "title": "K*-Means: A Parameter-free Clustering Algorithm",
      "title_zh": "K*-Means：一种无参数聚类算法",
      "authors": [
        "Louis Mahon",
        "Mirella Lapata"
      ],
      "abstract": "Clustering is a widely used and powerful machine learning technique, but its\neffectiveness is often limited by the need to specify the number of clusters,\nk, or by relying on thresholds that implicitly determine k. We introduce\nk*-means, a novel clustering algorithm that eliminates the need to set k or any\nother parameters. Instead, it uses the minimum description length principle to\nautomatically determine the optimal number of clusters, k*, by splitting and\nmerging clusters while also optimising the standard k-means objective. We prove\nthat k*-means is guaranteed to converge and demonstrate experimentally that it\nsignificantly outperforms existing methods in scenarios where k is unknown. We\nalso show that it is accurate in estimating k, and that empirically its runtime\nis competitive with existing methods, and scales well with dataset size.",
      "tldr_zh": "该论文提出了一种参数-free 聚类算法 k*-means，用于解决传统聚类方法需指定聚类数 k 或依赖阈值的局限性。算法利用 minimum description length principle 自动确定最优聚类数 k*，通过分裂和合并集群的同时优化标准 k-means 目标，并证明了其收敛性。实验结果显示，k*-means 在 k 未知的场景下显著优于现有方法，能够准确估计 k，且其运行时间与现有算法相当，并随数据集规模良好扩展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11904v1",
      "published_date": "2025-05-17 08:41:07 UTC",
      "updated_date": "2025-05-17 08:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:26:55.291379"
    },
    {
      "arxiv_id": "2505.11899v1",
      "title": "From Recall to Reasoning: Automated Question Generation for Deeper Math Learning through Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yongan Yu",
        "Alexandre Krantz",
        "Nikki G. Lobczowski"
      ],
      "abstract": "Educators have started to turn to Generative AI (GenAI) to help create new\ncourse content, but little is known about how they should do so. In this\nproject, we investigated the first steps for optimizing content creation for\nadvanced math. In particular, we looked at the ability of GenAI to produce\nhigh-quality practice problems that are relevant to the course content. We\nconducted two studies to: (1) explore the capabilities of current versions of\npublicly available GenAI and (2) develop an improved framework to address the\nlimitations we found. Our results showed that GenAI can create math problems at\nvarious levels of quality with minimal support, but that providing examples and\nrelevant content results in better quality outputs. This research can help\neducators decide the ideal way to adopt GenAI in their workflows, to create\nmore effective educational experiences for students.",
      "tldr_zh": "这篇论文探讨了如何利用 Generative AI (GenAI) 和 Large Language Models 自动生成数学练习问题，以从记忆式学习转向更深层的推理式学习。研究者通过两个实验评估了当前 GenAI 的能力，包括生成各种质量的数学问题，并开发了一个改进框架，通过提供例子和相关内容来克服其局限性。结果显示，GenAI 在最小支持下即可创建高质量问题，但添加示例能显著提升输出质量。该框架为教育者提供了实用指导，帮助他们在工作流程中优化 GenAI 的应用，以创建更有效的数学教育体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, accepted by AIED conference",
      "pdf_url": "http://arxiv.org/pdf/2505.11899v1",
      "published_date": "2025-05-17 08:30:10 UTC",
      "updated_date": "2025-05-17 08:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:27:06.953018"
    },
    {
      "arxiv_id": "2505.11896v1",
      "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenwei Lou",
        "Zewei Sun",
        "Xinnian Liang",
        "Meng Qu",
        "Wei Shen",
        "Wenqi Wang",
        "Yuntao Li",
        "Qingping Yang",
        "Shuangzhi Wu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but\noften face challenges with tasks requiring sophisticated reasoning. While\nChain-of-Thought (CoT) prompting significantly enhances reasoning, it\nindiscriminately generates lengthy reasoning steps for all queries, leading to\nsubstantial computational costs and inefficiency, especially for simpler\ninputs. To address this critical issue, we introduce AdaCoT (Adaptive\nChain-of-Thought), a novel framework enabling LLMs to adaptively decide when to\ninvoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem\nthat seeks to balance model performance with the costs associated with CoT\ninvocation (both frequency and computational overhead). We propose a\nreinforcement learning (RL) based method, specifically utilizing Proximal\nPolicy Optimization (PPO), to dynamically control the CoT triggering decision\nboundary by adjusting penalty coefficients, thereby allowing the model to\ndetermine CoT necessity based on implicit query complexity. A key technical\ncontribution is Selective Loss Masking (SLM), designed to counteract decision\nboundary collapse during multi-stage RL training, ensuring robust and stable\nadaptive triggering. Experimental results demonstrate that AdaCoT successfully\nnavigates the Pareto frontier, achieving substantial reductions in CoT usage\nfor queries not requiring elaborate reasoning. For instance, on our production\ntraffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and\ndecreased average response tokens by 69.06%, while maintaining high performance\non complex tasks.",
      "tldr_zh": "该论文提出 AdaCoT 框架，利用强化学习（Reinforcement Learning）来实现 Pareto-Optimal 的自适应 Chain-of-Thought (CoT) 触发，旨在解决大型语言模型 (LLMs) 在简单查询上因过度生成推理步骤而导致的计算开销问题。框架将自适应推理视为 Pareto 优化问题，通过 Proximal Policy Optimization (PPO) 动态调整 CoT 触发的决策边界，根据查询复杂度决定是否调用 CoT。论文的关键贡献包括 Selective Loss Masking (SLM) 技术，用于防止 RL 训练中的决策边界崩溃；实验结果显示，AdaCoT 在生产流量测试集上将 CoT 触发率降至 3.18%，响应令牌减少 69.06%，同时保持复杂任务的高性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11896v1",
      "published_date": "2025-05-17 08:27:00 UTC",
      "updated_date": "2025-05-17 08:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:27:20.826838"
    },
    {
      "arxiv_id": "2505.11893v1",
      "title": "RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Zepeng Ding",
        "Dixuan Wang",
        "Ziqin Luo",
        "Guochao Jiang",
        "Deqing Yang",
        "Jiaqing Liang"
      ],
      "abstract": "Multi-step planning has been widely employed to enhance the performance of\nlarge language models (LLMs) on downstream natural language processing (NLP)\ntasks, which decomposes the original task into multiple subtasks and guide LLMs\nto solve them sequentially without additional training. When addressing task\ninstances, existing methods either preset the order of steps or attempt\nmultiple paths at each step. However, these methods overlook instances'\nlinguistic features and rely on the intrinsic planning capabilities of LLMs to\nevaluate intermediate feedback and then select subtasks, resulting in\nsuboptimal outcomes. To better solve multi-step NLP tasks with LLMs, in this\npaper we propose a Reinforcement Learning enhanced Adaptive Planning framework\n(RLAP). In our framework, we model an NLP task as a Markov decision process\n(MDP) and employ an LLM directly into the environment. In particular, a\nlightweight Actor model is trained to estimate Q-values for natural language\nsequences consisting of states and actions through reinforcement learning.\nTherefore, during sequential planning, the linguistic features of each sequence\nin the MDP can be taken into account, and the Actor model interacts with the\nLLM to determine the optimal order of subtasks for each task instance. We apply\nRLAP on three different types of NLP tasks and conduct extensive experiments on\nmultiple datasets to verify RLAP's effectiveness and robustness.",
      "tldr_zh": "该论文提出RLAP框架，即Reinforcement Learning增强的自适应规划框架，用于提升大型语言模型(LLMs)在多步自然语言处理(NLP)任务中的性能。RLAP将NLP任务建模为Markov决策过程(MDP)，并训练一个轻量级的Actor模型通过强化学习估计状态和动作序列的Q值，从而在规划过程中考虑实例的语言特征，与LLM交互动态优化子任务顺序。与现有方法相比，该框架避免了预设步骤或盲目尝试路径的局限性。在三个不同类型NLP任务的多数据集实验中，RLAP展示了显著的有效性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11893v1",
      "published_date": "2025-05-17 08:06:14 UTC",
      "updated_date": "2025-05-17 08:06:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:27:30.870713"
    },
    {
      "arxiv_id": "2505.11891v1",
      "title": "Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Weikai Xu",
        "Zhizheng Jiang",
        "Yuxuan Liu",
        "Wei Liu",
        "Jian Luan",
        "Yuanchun Li",
        "Yunxin Liu",
        "Bin Wang",
        "Bo An"
      ],
      "abstract": "VLM-based mobile agents are increasingly popular due to their capabilities to\ninteract with smartphone GUIs and XML-structured texts and to complete daily\ntasks. However, existing online benchmarks struggle with obtaining stable\nreward signals due to dynamic environmental changes. Offline benchmarks\nevaluate the agents through single-path trajectories, which stands in contrast\nto the inherently multi-solution characteristics of GUI tasks. Additionally,\nboth types of benchmarks fail to assess whether mobile agents can handle noise\nor engage in proactive interactions due to a lack of noisy apps or overly full\ninstructions during the evaluation process. To address these limitations, we\nuse a slot-based instruction generation method to construct a more realistic\nand comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a\ncommon task split, with offline multi-path evaluation to assess the agent's\nability to obtain step rewards during task execution. It contains a noisy split\nbased on pop-ups and ads apps, and a contaminated split named AITZ-Noise to\nformulate a real noisy environment. Furthermore, an ambiguous instruction split\nwith preset Q\\&A interactions is released to evaluate the agent's proactive\ninteraction capabilities. We conduct evaluations on these splits using the\nsingle-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2,\nas well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are\navailable at https://huggingface.co/datasets/xwk123/MobileBench-v2.",
      "tldr_zh": "该论文介绍了 Mobile-Bench-v2，一种更真实且全面的基准，用于评估基于视觉语言模型(VLM-based mobile agents)的移动代理，以解决现有在线基准的动态环境不稳定性以及离线基准的单路径评估局限性。Mobile-Bench-v2 通过 slot-based instruction generation 方法构建，包括常见任务拆分（支持离线多路径评估）、noisy split（基于弹出窗口和广告应用）、contaminated split（如 AITZ-Noise 模拟真实噪声环境），以及 ambiguous instruction split（通过预设 Q&A 互动评估代理的主动能力）。作者在这些拆分上评估了多种代理如 AppAgent-v1 和 Mobile-Agent-v2，并提供了代码和数据以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11891v1",
      "published_date": "2025-05-17 07:58:34 UTC",
      "updated_date": "2025-05-17 07:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:27:45.060033"
    },
    {
      "arxiv_id": "2505.11889v1",
      "title": "Exploring the Potential of SSL Models for Sound Event Detection",
      "title_zh": "探索 SSL 模型在声音事件检测中的潜力",
      "authors": [
        "Hanfang Cui",
        "Longfei Song",
        "Li Li",
        "Dongxing Xu",
        "Yanhua Long"
      ],
      "abstract": "Self-supervised learning (SSL) models offer powerful representations for\nsound event detection (SED), yet their synergistic potential remains\nunderexplored. This study systematically evaluates state-of-the-art SSL models\nto guide optimal model selection and integration for SED. We propose a\nframework that combines heterogeneous SSL representations (e.g., BEATs, HuBERT,\nWavLM) through three fusion strategies: individual SSL embedding integration,\ndual-modal fusion, and full aggregation. Experiments on the DCASE 2023 Task 4\nChallenge reveal that dual-modal fusion (e.g., CRNN+BEATs+WavLM) achieves\ncomplementary performance gains, while CRNN+BEATs alone delivers the best\nresults among individual SSL models. We further introduce normalized sound\nevent bounding boxes (nSEBBs), an adaptive post-processing method that\ndynamically adjusts event boundary predictions, improving PSDS1 by up to 4% for\nstandalone SSL models. These findings highlight the compatibility and\ncomplementarity of SSL architectures, providing guidance for task-specific\nfusion and robust SED system design.",
      "tldr_zh": "本研究探索了自监督学习 (SSL) 模型在声音事件检测 (SED) 中的潜力，通过系统评估最先进的 SSL 模型（如 BEATs、HuBERT 和 WavLM），以指导模型选择和整合。研究提出一个框架，利用三种融合策略（单个 SSL 嵌入整合、双模态融合和全聚合）结合异构 SSL 表示，例如 CRNN+BEATs+WavLM 的双模态融合，实现了互补性能提升。实验在 DCASE 2023 Task 4 Challenge 上显示，CRNN+BEATs 组合表现最佳，而引入的归一化声音事件边界框 (nSEBBs) 后处理方法可将 PSDS1 指标提高高达 4%。这些发现突出了 SSL 架构的兼容性和互补性，为任务特定融合和鲁棒 SED 系统设计提供了指导。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "I.5.4; I.2.10; H.5.5"
      ],
      "primary_category": "eess.AS",
      "comment": "27 pages, 5 figures, submitted to the Journal of King Saud University\n  - Computer and Information Sciences (under review)",
      "pdf_url": "http://arxiv.org/pdf/2505.11889v1",
      "published_date": "2025-05-17 07:54:31 UTC",
      "updated_date": "2025-05-17 07:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:27:56.226020"
    },
    {
      "arxiv_id": "2505.11881v1",
      "title": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks",
      "title_zh": "重新审视残差连接：正交更新用于稳定和高效的深度网络",
      "authors": [
        "Giyeong Oh",
        "Woohyun Cho",
        "Siyeol Kim",
        "Suhwan Choi",
        "Younjae Yu"
      ],
      "abstract": "Residual connections are pivotal for deep neural networks, enabling greater\ndepth by mitigating vanishing gradients. However, in standard residual updates,\nthe module's output is directly added to the input stream. This can lead to\nupdates that predominantly reinforce or modulate the existing stream direction,\npotentially underutilizing the module's capacity for learning entirely novel\nfeatures. In this work, we introduce Orthogonal Residual Update: we decompose\nthe module's output relative to the input stream and add only the component\northogonal to this stream. This design aims to guide modules to contribute\nprimarily new representational directions, fostering richer feature learning\nwhile promoting more efficient training. We demonstrate that our orthogonal\nupdate strategy improves generalization accuracy and training stability across\ndiverse architectures (ResNetV2, Vision Transformers) and datasets (CIFARs,\nTinyImageNet, ImageNet-1k), achieving, for instance, a +4.3\\%p top-1 accuracy\ngain for ViT-B on ImageNet-1k.",
      "tldr_zh": "本文重新审视了Residual Connections在深度神经网络中的作用，提出Orthogonal Residual Update方法，通过分解模块输出并仅添加与输入流正交的部分，促进模块学习新的表示方向，从而提升网络的泛化准确性和训练稳定性。相比标准残差更新，该方法在ResNetV2和Vision Transformers等架构上表现突出，并在CIFARs、TinyImageNet和ImageNet-1k数据集上实现了显著改进，例如ViT-B在ImageNet-1k上的top-1准确率提升了4.3%。这项创新有助于构建更高效的深度网络。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, WIP",
      "pdf_url": "http://arxiv.org/pdf/2505.11881v1",
      "published_date": "2025-05-17 07:16:11 UTC",
      "updated_date": "2025-05-17 07:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:28:08.397321"
    },
    {
      "arxiv_id": "2505.11878v1",
      "title": "AdaptMol: Adaptive Fusion from Sequence String to Topological Structure for Few-shot Drug Discovery",
      "title_zh": "AdaptMol：从序列字符串到拓扑",
      "authors": [
        "Yifan Dai",
        "Xuanbai Ren",
        "Tengfei Ma",
        "Qipeng Yan",
        "Yiping Liu",
        "Yuansheng Liu",
        "Xiangxiang Zeng"
      ],
      "abstract": "Accurate molecular property prediction (MPP) is a critical step in modern\ndrug development. However, the scarcity of experimental validation data poses a\nsignificant challenge to AI-driven research paradigms. Under few-shot learning\nscenarios, the quality of molecular representations directly dictates the\ntheoretical upper limit of model performance. We present AdaptMol, a\nprototypical network integrating Adaptive multimodal fusion for Molecular\nrepresentation. This framework employs a dual-level attention mechanism to\ndynamically integrate global and local molecular features derived from two\nmodalities: SMILES sequences and molecular graphs. (1) At the local level,\nstructural features such as atomic interactions and substructures are extracted\nfrom molecular graphs, emphasizing fine-grained topological information; (2) At\nthe global level, the SMILES sequence provides a holistic representation of the\nmolecule. To validate the necessity of multimodal adaptive fusion, we propose\nan interpretable approach based on identifying molecular active substructures\nto demonstrate that multimodal adaptive fusion can efficiently represent\nmolecules. Extensive experiments on three commonly used benchmarks under 5-shot\nand 10-shot settings demonstrate that AdaptMol achieves state-of-the-art\nperformance in most cases. The rationale-extracted method guides the fusion of\ntwo modalities and highlights the importance of both modalities.",
      "tldr_zh": "该论文针对分子属性预测（MPP）在药物开发中的数据稀缺问题，提出AdaptMol框架，这是一种集成了自适应多模态融合的原型网络，用于少样本学习场景。AdaptMol采用双层注意力机制，融合SMILES sequences的全局分子表示和molecular graphs的局部特征（如原子互动和子结构），从而动态提取精确的分子表示。实验在三个基准数据集上的5-shot和10-shot设置中显示，AdaptMol实现了state-of-the-art性能，并通过可解释方法（如识别分子活性子结构）证明了多模态融合的效率和必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN",
        "J.3; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11878v1",
      "published_date": "2025-05-17 07:12:12 UTC",
      "updated_date": "2025-05-17 07:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:28:21.087821"
    },
    {
      "arxiv_id": "2505.14711v1",
      "title": "Space evaluation at the starting point of soccer transitions",
      "title_zh": "足球转化的起始点的空间评估",
      "authors": [
        "Yohei Ogawa",
        "Rikuhei Umemoto",
        "Keisuke Fujii"
      ],
      "abstract": "Soccer is a sport played on a pitch where effective use of space is crucial.\nDecision-making during transitions, when possession switches between teams, has\nbeen increasingly important, but research on space evaluation in these moments\nhas been limited. Recent space evaluation methods such as OBSO (Off-Ball\nScoring Opportunity) use scoring probability, so it is not well-suited for\nassessing areas far from the goal, where transitions typically occur. In this\npaper, we propose OBPV (Off-Ball Positioning Value) to evaluate space across\nthe pitch, including the starting points of transitions. OBPV extends OBSO by\nintroducing the field value model, which evaluates the entire pitch, and by\nemploying the transition kernel model, which reflects positional specificity\nthrough kernel density estimation of pass distributions. Experiments using La\nLiga 2023/24 season tracking and event data show that OBPV highlights effective\nspace utilization during counter-attacks and reveals team-specific\ncharacteristics in how the teams utilize space after positive and negative\ntransitions.",
      "tldr_zh": "足球比赛中，转换阶段（transitions）的空间评估至关重要，但现有方法如 OBSO（Off-Ball Scoring Opportunity）主要基于得分概率，无法有效评估远离球门的区域。论文提出 OBPV（Off-Ball Positioning Value），通过引入 field value model（评估整个球场）和 transition kernel model（利用核密度估计反映传球分布的 positional specificity），来扩展空间评估范围。实验基于 La Liga 2023/24 赛季的跟踪和事件数据，显示 OBPV 突出了反击中的有效空间利用，并揭示了球队在正负转换后的特定特性。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "23 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.14711v1",
      "published_date": "2025-05-17 06:28:06 UTC",
      "updated_date": "2025-05-17 06:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:28:33.415107"
    },
    {
      "arxiv_id": "2505.11866v1",
      "title": "Position Paper: Bounded Alignment: What (Not) To Expect From AGI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ali A. Minai"
      ],
      "abstract": "The issues of AI risk and AI safety are becoming critical as the prospect of\nartificial general intelligence (AGI) looms larger. The emergence of extremely\nlarge and capable generative models has led to alarming predictions and created\na stir from boardrooms to legislatures. As a result, AI alignment has emerged\nas one of the most important areas in AI research. The goal of this position\npaper is to argue that the currently dominant vision of AGI in the AI and\nmachine learning (AI/ML) community needs to evolve, and that expectations and\nmetrics for its safety must be informed much more by our understanding of the\nonly existing instance of general intelligence, i.e., the intelligence found in\nanimals, and especially in humans. This change in perspective will lead to a\nmore realistic view of the technology, and allow for better policy decisions.",
      "tldr_zh": "这篇立场论文（Position Paper）探讨了AGI（Artificial General Intelligence）代理的边界对齐（Bounded Alignment），强调在AI风险和安全日益重要的背景下，需要重新审视AI社区对AGI的当前愿景。作者主张，AI alignment的期望和指标应更多借鉴人类和动物智能的实际理解，以避免不切实际的预测。最终，这种视角转变有助于形成更现实的技术评估和政策决策。",
      "categories": [
        "cs.AI",
        "I.2.0; I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted for the 2025 IEEE/INNS International Joint Conference\n  on Neural Networks, Rome, Italy, June 30 - July 5, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11866v1",
      "published_date": "2025-05-17 06:17:57 UTC",
      "updated_date": "2025-05-17 06:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:28:43.668480"
    },
    {
      "arxiv_id": "2505.11864v1",
      "title": "Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning",
      "title_zh": "从有噪声偏",
      "authors": [
        "Kalyan Cherukuri",
        "Aarav Lala"
      ],
      "abstract": "As generative agents become increasingly capable, alignment of their behavior\nwith complex human values remains a fundamental challenge. Existing approaches\noften simplify human intent through reduction to a scalar reward, overlooking\nthe multi-faceted nature of human feedback. In this work, we introduce a\ntheoretical framework for preference-based Multi-Objective Inverse\nReinforcement Learning (MO-IRL), where human preferences are modeled as latent\nvector-valued reward functions. We formalize the problem of recovering a\nPareto-optimal reward representation from noisy preference queries and\nestablish conditions for identifying the underlying multi-objective structure.\nWe derive tight sample complexity bounds for recovering\n$\\epsilon$-approximations of the Pareto front and introduce a regret\nformulation to quantify suboptimality in this multi-objective setting.\nFurthermore, we propose a provably convergent algorithm for policy optimization\nusing preference-inferred reward cones. Our results bridge the gap between\npractical alignment techniques and theoretical guarantees, providing a\nprincipled foundation for learning aligned behaviors in a high-dimension and\nvalue-pluralistic environment.",
      "tldr_zh": "这篇论文提出一个理论框架，用于基于偏好的多目标逆强化学习（Multi-Objective Inverse Reinforcement Learning, MO-IRL），旨在从噪声偏好查询中学习Pareto最优奖励表示，以更好地对齐生成代理的行为与复杂人类价值观。框架形式化了恢复Pareto前沿的ε近似值问题，建立了识别多目标结构的条件，并导出了紧密的样本复杂度边界，同时引入了遗憾（regret）公式来量化多目标设置中的次优性。作者还提出了一种可收敛的算法，利用偏好推断的奖励锥进行策略优化，为在高维和价值多元环境中实现可靠的行为对齐提供了理论基础和实践指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11864v1",
      "published_date": "2025-05-17 06:09:13 UTC",
      "updated_date": "2025-05-17 06:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:28:57.144630"
    },
    {
      "arxiv_id": "2505.11862v1",
      "title": "Q-Policy: Quantum-Enhanced Policy Evaluation for Scalable Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kalyan Cherukuri",
        "Aarav Lala",
        "Yash Yardi"
      ],
      "abstract": "We propose Q-Policy, a hybrid quantum-classical reinforcement learning (RL)\nframework that mathematically accelerates policy evaluation and optimization by\nexploiting quantum computing primitives. Q-Policy encodes value functions in\nquantum superposition, enabling simultaneous evaluation of multiple\nstate-action pairs via amplitude encoding and quantum parallelism. We introduce\na quantum-enhanced policy iteration algorithm with provable polynomial\nreductions in sample complexity for the evaluation step, under standard\nassumptions. To demonstrate the technical feasibility and theoretical soundness\nof our approach, we validate Q-Policy on classical emulations of small discrete\ncontrol tasks. Due to current hardware and simulation limitations, our\nexperiments focus on showcasing proof-of-concept behavior rather than\nlarge-scale empirical evaluation. Our results support the potential of Q-Policy\nas a theoretical foundation for scalable RL on future quantum devices,\naddressing RL scalability challenges beyond classical approaches.",
      "tldr_zh": "该研究提出 Q-Policy，一种混合量子-经典强化学习（RL）框架，通过利用量子计算原语（如量子叠加和振幅编码）来加速策略评估和优化，实现多个状态-动作对的并行评估。框架引入量子增强的策略迭代算法，在标准假设下证明了评估步骤的样本复杂度多项式减少。实验在小离散控制任务的经典模拟中验证了其概念可行性，并为未来量子设备上的可扩展 RL 提供了理论基础，解决经典方法无法应对的扩展性挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11862v1",
      "published_date": "2025-05-17 06:03:32 UTC",
      "updated_date": "2025-05-17 06:03:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:29:07.688038"
    },
    {
      "arxiv_id": "2505.11861v1",
      "title": "Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhou",
        "Jie Zhang",
        "Dongxia Wang",
        "Qiang Liu",
        "Tianlin Li",
        "Jin Song Dong",
        "Wenhai Wang",
        "Qing Guo"
      ],
      "abstract": "Human preference plays a crucial role in the refinement of large language\nmodels (LLMs). However, collecting human preference feedback is costly and most\nexisting datasets neglect the correlation between personalization and\npreferences. To address this issue, we introduce Fair-PP, a synthetic dataset\nof personalized preferences targeting social equity, derived from real-world\nsocial survey data, which includes 28 social groups, 98 equity topics, and 5\npersonal preference dimensions. Leveraging GPT-4o-mini, we engage in\nrole-playing based on seven representative persona portrayals guided by\nexisting social survey data, yielding a total of 238,623 preference records.\nThrough Fair-PP, we also contribute (i) An automated framework for generating\npreference data, along with a more fine-grained dataset of personalized\npreferences; (ii) analysis of the positioning of the existing mainstream LLMs\nacross five major global regions within the personalized preference space; and\n(iii) a sample reweighting method for personalized preference alignment,\nenabling alignment with a target persona while maximizing the divergence from\nother personas. Empirical experiments show our method outperforms the\nbaselines.",
      "tldr_zh": "这篇论文引入了 Fair-PP，这是一个合成数据集，旨在帮助大型语言模型（LLMs）与社会公平相关的个性化偏好对齐，基于真实社会调查数据包括28个社会群体、98个公平主题和5个个人偏好维度。利用GPT-4o-mini通过角色扮演生成238,623条偏好记录，构建了一个自动框架来高效创建细粒度个性化偏好数据。论文还分析了主流LLMs在五个全球区域的偏好空间定位，并提出了一种样本再加权方法，使模型与目标人物偏好对齐，同时最大化与其他人物的差异。实验结果表明，该方法在个性化偏好对齐方面优于基线模型。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "91C99",
        "I.2.7; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2505.11861v1",
      "published_date": "2025-05-17 06:02:00 UTC",
      "updated_date": "2025-05-17 06:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:29:20.716802"
    },
    {
      "arxiv_id": "2505.11854v1",
      "title": "Evaluating the Logical Reasoning Abilities of Large Reasoning Models",
      "title_zh": "评估大型推理模型的逻辑推理能力",
      "authors": [
        "Hanmeng Liu",
        "Yiran Ding",
        "Zhizhang Fu",
        "Chaoli Zhang",
        "Xiaozhang Liu",
        "Yue Zhang"
      ],
      "abstract": "Large reasoning models, often post-trained on long chain-of-thought (long\nCoT) data with reinforcement learning, achieve state-of-the-art performance on\nmathematical, coding, and domain-specific reasoning benchmarks. However, their\nlogical reasoning capabilities - fundamental to human cognition and independent\nof domain knowledge - remain understudied. To address this gap, we introduce\nLogiEval, a holistic benchmark for evaluating logical reasoning in large\nreasoning models. LogiEval spans diverse reasoning types (deductive, inductive,\nanalogical, and abductive) and task formats (e.g., logical sequence, argument\nanalysis), sourced from high-quality human examinations (e.g., LSAT, GMAT). Our\nexperiments demonstrate that modern reasoning models excel at 4-choice argument\nanalysis problems and analogical reasoning, surpassing human performance, yet\nexhibit uneven capabilities across reasoning types and formats, highlighting\nlimitations in their generalization. Our analysis reveals that human\nperformance does not mirror model failure distributions. To foster further\nresearch, we curate LogiEval-Hard, a challenging subset identified through a\nnovel screening paradigm where small-model failures (Qwen3-30B-A3B) reliably\npredict difficulties for larger models. Modern models show striking, consistent\nfailures on LogiEval-Hard. This demonstrates that fundamental reasoning\nbottlenecks persist across model scales, and establishes LogiEval-Hard as both\na diagnostic tool and a rigorous testbed for advancing logical reasoning in\nLLMs.",
      "tldr_zh": "本文评估了大型推理模型的逻辑推理能力，引入了 LogiEval 基准，该基准涵盖演绎（deductive）、归纳（inductive）、类比（analogical）和溯因（abductive）推理等多种类型，并基于高质量人类考试（如 LSAT、GMAT）设计任务格式。实验结果显示，现代模型在 4 选一的论证分析和类比推理上超过了人类表现，但整体能力不均衡，且泛化有限；同时，人类失败模式与模型分布不一致。作者进一步创建了 LogiEval-Hard 子集，通过小模型失败筛选机制识别挑战性任务，揭示模型规模间存在的根本推理瓶颈，并将其确立为诊断工具和推进 LLM 逻辑推理的研究测试平台。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11854v1",
      "published_date": "2025-05-17 05:36:14 UTC",
      "updated_date": "2025-05-17 05:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:29:33.508131"
    },
    {
      "arxiv_id": "2505.11849v1",
      "title": "VeriReason: Reinforcement Learning with Testbench Feedback for Reasoning-Enhanced Verilog Generation",
      "title_zh": "VeriReason：利用测试bench反馈的强化学习，用于增强推理的Verilog生成",
      "authors": [
        "Yiting Wang",
        "Guoheng Sun",
        "Wanghao Ye",
        "Gang Qu",
        "Ang Li"
      ],
      "abstract": "Automating Register Transfer Level (RTL) code generation using Large Language\nModels (LLMs) offers substantial promise for streamlining digital circuit\ndesign and reducing human effort. However, current LLM-based approaches face\nsignificant challenges with training data scarcity, poor specification-code\nalignment, lack of verification mechanisms, and balancing generalization with\nspecialization. Inspired by DeepSeek-R1, we introduce VeriReason, a framework\nintegrating supervised fine-tuning with Guided Reward Proximal Optimization\n(GRPO) reinforcement learning for RTL generation. Using curated training\nexamples and a feedback-driven reward model, VeriReason combines testbench\nevaluations with structural heuristics while embedding self-checking\ncapabilities for autonomous error correction. On the VerilogEval Benchmark,\nVeriReason delivers significant improvements: achieving 83.1% functional\ncorrectness on the VerilogEval Machine benchmark, substantially outperforming\nboth comparable-sized models and much larger commercial systems like GPT-4\nTurbo. Additionally, our approach demonstrates up to a 2.8X increase in\nfirst-attempt functional correctness compared to baseline methods and exhibits\nrobust generalization to unseen designs. To our knowledge, VeriReason\nrepresents the first system to successfully integrate explicit reasoning\ncapabilities with reinforcement learning for Verilog generation, establishing a\nnew state-of-the-art for automated RTL synthesis. The models and datasets are\navailable at: https://huggingface.co/collections/AI4EDA-CASE Code is Available\nat: https://github.com/NellyW8/VeriReason",
      "tldr_zh": "本文提出 VeriReason 框架，利用 Reinforcement Learning 与 Testbench Feedback 相结合的强化学习方法，针对 Large Language Models (LLMs) 在 Register Transfer Level (RTL) 代码生成中的问题，如数据稀缺和规范-代码不对齐，提供增强推理能力的 Verilog 生成解决方案。框架整合了监督微调（Supervised Fine-Tuning）和 Guided Reward Proximal Optimization (GRPO)，通过精选训练示例、反馈驱动奖励模型以及自检机制，实现错误修正和结构启发式评估。在 VerilogEval Benchmark 上，VeriReason 实现了 83.1% 的功能正确率，比基线模型和 GPT-4 Turbo 显著提升，并将第一尝试正确率提高高达 2.8 倍，同时展示了对未见设计的鲁棒泛化。该方法首次成功整合显式推理与 Reinforcement Learning，为自动化 RTL 合成树立了新标准。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11849v1",
      "published_date": "2025-05-17 05:25:01 UTC",
      "updated_date": "2025-05-17 05:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:29:45.911672"
    },
    {
      "arxiv_id": "2505.14709v1",
      "title": "FastCar: Cache Attentive Replay for Fast Auto-Regressive Video Generation on the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Shen",
        "Weize Ma",
        "Yufa Zhou",
        "Enhao Tang",
        "Yanyue Xie",
        "Zhengang Li",
        "Yifan Gong",
        "Quanyi Wang",
        "Henghui Ding",
        "Yiwei Wang",
        "Yanzhi Wang",
        "Pu Zhao",
        "Jun Lin",
        "Jiuxiang Gu"
      ],
      "abstract": "Auto-regressive (AR) models, initially successful in language generation,\nhave recently shown promise in visual generation tasks due to their superior\nsampling efficiency. Unlike image generation, video generation requires a\nsubstantially larger number of tokens to produce coherent temporal frames,\nresulting in significant overhead during the decoding phase. Our key\nobservations are: (i) MLP modules in the decode phase dominate the inference\nlatency, and (ii) there exists high temporal redundancy in MLP outputs of\nadjacent frames. In this paper, we propose the \\textbf{FastCar} framework to\naccelerate the decode phase for the AR video generation by exploring the\ntemporal redundancy. The Temporal Attention Score (TAS) is proposed to\ndetermine whether to apply the replay strategy (\\textit{i.e.}, reusing cached\nMLP outputs from the previous frame to reduce redundant computations) with\ndetailed theoretical analysis and justification. Also, we develop a hardware\naccelerator on FPGA with Dynamic Resource Scheduling (DRS) based on TAS to\nenable better resource utilization and faster inference. Experimental results\ndemonstrate the effectiveness of our method, which outperforms traditional\nsparse attention approaches with more than 2.1x decoding speedup and higher\nenergy efficiency on the edge. Furthermore, by combining FastCar and sparse\nattention, FastCar can boost the performance of sparse attention with\nalleviated drifting, demonstrating our unique advantages for high-resolution\nand long-duration video generation. Code:\nhttps://github.com/shawnricecake/fast-car",
      "tldr_zh": "这篇论文提出 FastCar 框架，用于加速 Auto-Regressive (AR) 模型在边缘设备上的视频生成，通过利用相邻帧的 MLP 输出时间冗余来减少解码阶段的计算开销。框架引入 Temporal Attention Score (TAS) 来判断是否应用缓存重放策略（重用前一帧的 MLP 输出），并结合 FPGA 上的硬件加速器和 Dynamic Resource Scheduling (DRS) 优化资源利用。实验结果显示，FastCar 比传统稀疏注意力方法提速 2.1 倍以上，同时提升能量效率，并在结合稀疏注意力时缓解 drifting 问题，支持高分辨率和长视频生成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint Version",
      "pdf_url": "http://arxiv.org/pdf/2505.14709v1",
      "published_date": "2025-05-17 05:00:39 UTC",
      "updated_date": "2025-05-17 05:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:29:56.534404"
    },
    {
      "arxiv_id": "2505.11839v1",
      "title": "On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Yang",
        "Qi Yang",
        "Luoxi Tang",
        "Jeremy Blackburn",
        "Zhaohan Xi"
      ],
      "abstract": "Counterfactual reasoning has emerged as a crucial technique for generalizing\nthe reasoning capabilities of large language models (LLMs). By generating and\nanalyzing counterfactual scenarios, researchers can assess the adaptability and\nreliability of model decision-making. Although prior work has shown that LLMs\noften struggle with counterfactual reasoning, it remains unclear which factors\nmost significantly impede their performance across different tasks and\nmodalities. In this paper, we propose a decompositional strategy that breaks\ndown the counterfactual generation from causality construction to the reasoning\nover counterfactual interventions. To support decompositional analysis, we\ninvestigate 11 datasets spanning diverse tasks, including natural language\nunderstanding, mathematics, programming, and vision-language tasks. Through\nextensive evaluations, we characterize LLM behavior across each decompositional\nstage and identify how modality type and intermediate reasoning influence\nperformance. By establishing a structured framework for analyzing\ncounterfactual reasoning, this work contributes to the development of more\nreliable LLM-based reasoning systems and informs future elicitation strategies.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在反事实推理（Counterfactual reasoning）中的适用性，通过提出一种分解策略（decompositional strategy）将反事实生成过程分解为因果构建和对反事实干预的推理阶段。研究者评估了11个数据集，涵盖自然语言理解、数学、编程和视觉语言任务，以分析LLMs在每个阶段的行为，并考察模式类型和中间推理对性能的影响。结果显示，该框架有助于识别影响因素，提升LLMs的可靠性和适应性，为开发更先进的LLM推理系统提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11839v1",
      "published_date": "2025-05-17 04:59:32 UTC",
      "updated_date": "2025-05-17 04:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:30:08.348700"
    },
    {
      "arxiv_id": "2505.11837v1",
      "title": "On Membership Inference Attacks in Knowledge Distillation",
      "title_zh": "关于知识蒸馏中的成员推理攻击",
      "authors": [
        "Ziyao Cui",
        "Minxing Zhang",
        "Jian Pei"
      ],
      "abstract": "Nowadays, Large Language Models (LLMs) are trained on huge datasets, some\nincluding sensitive information. This poses a serious privacy concern because\nprivacy attacks such as Membership Inference Attacks (MIAs) may detect this\nsensitive information. While knowledge distillation compresses LLMs into\nefficient, smaller student models, its impact on privacy remains underexplored.\nIn this paper, we investigate how knowledge distillation affects model\nrobustness against MIA. We focus on two questions. First, how is private data\nprotected in teacher and student models? Second, how can we strengthen privacy\npreservation against MIAs in knowledge distillation? Through comprehensive\nexperiments, we show that while teacher and student models achieve similar\noverall MIA accuracy, teacher models better protect member data, the primary\ntarget of MIA, whereas student models better protect non-member data. To\naddress this vulnerability in student models, we propose 5 privacy-preserving\ndistillation methods and demonstrate that they successfully reduce student\nmodels' vulnerability to MIA, with ensembling further stabilizing the\nrobustness, offering a reliable approach for distilling more secure and\nefficient student models. Our implementation source code is available at\nhttps://github.com/richardcui18/MIA_in_KD.",
      "tldr_zh": "本研究探讨了知识蒸馏（knowledge distillation）对 Membership Inference Attacks (MIAs) 的影响，关注大型语言模型（LLMs）中私有数据的隐私保护问题。实验结果显示，教师模型更有效地保护成员数据（member data），而学生模型更擅长保护非成员数据（non-member data）。为了缓解学生模型的易受攻击性，研究提出5种隐私保护的蒸馏方法，这些方法显著降低了学生模型对MIAs的脆弱性，并通过集成（ensembling）技术进一步增强鲁棒性，提供了一种构建更安全、高效学生模型的可靠途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11837v1",
      "published_date": "2025-05-17 04:54:26 UTC",
      "updated_date": "2025-05-17 04:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:30:20.169562"
    },
    {
      "arxiv_id": "2505.11836v1",
      "title": "SplInterp: Improving our Understanding and Training of Sparse Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Budd",
        "Javier Ideami",
        "Benjamin Macdowall Rynne",
        "Keith Duggar",
        "Randall Balestriero"
      ],
      "abstract": "Sparse autoencoders (SAEs) have received considerable recent attention as\ntools for mechanistic interpretability, showing success at extracting\ninterpretable features even from very large LLMs. However, this research has\nbeen largely empirical, and there have been recent doubts about the true\nutility of SAEs. In this work, we seek to enhance the theoretical understanding\nof SAEs, using the spline theory of deep learning. By situating SAEs in this\nframework: we discover that SAEs generalise ``$k$-means autoencoders'' to be\npiecewise affine, but sacrifice accuracy for interpretability vs. the optimal\n``$k$-means-esque plus local principal component analysis (PCA)'' piecewise\naffine autoencoder. We characterise the underlying geometry of (TopK) SAEs\nusing power diagrams. And we develop a novel proximal alternating method SGD\n(PAM-SGD) algorithm for training SAEs, with both solid theoretical foundations\nand promising empirical results in MNIST and LLM experiments, particularly in\nsample efficiency and (in the LLM setting) improved sparsity of codes. All code\nis available at: https://github.com/splInterp2025/splInterp",
      "tldr_zh": "本文提出 SplInterp 方法，以提升对稀疏自编码器（SAEs）的理论理解和训练效率，通过 spline 理论框架分析 SAEs 的特性。研究发现，SAEs 将 k-means 自编码器推广为分段仿射（piecewise affine）形式，但相比最优的 k-means 加上局部主成分分析（PCA）的自编码器，在准确性和可解释性之间做出了权衡。作者使用 power diagrams 描述了 TopK SAEs 的底层几何结构，并开发了 proximal alternating method SGD (PAM-SGD) 算法，该算法在 MNIST 和 LLMs 实验中显示出更高的样本效率和代码稀疏性。所有代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 65D07"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages, 38 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2505.11836v1",
      "published_date": "2025-05-17 04:51:26 UTC",
      "updated_date": "2025-05-17 04:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:30:33.077640"
    },
    {
      "arxiv_id": "2505.11835v1",
      "title": "Multilingual Collaborative Defense for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliang Li",
        "Jinan Xu",
        "Gengping Cui",
        "Changhao Guan",
        "Fengran Mo",
        "Kaiyu Huang"
      ],
      "abstract": "The robustness and security of large language models (LLMs) has become a\nprominent research area. One notable vulnerability is the ability to bypass LLM\nsafeguards by translating harmful queries into rare or underrepresented\nlanguages, a simple yet effective method of \"jailbreaking\" these models.\nDespite the growing concern, there has been limited research addressing the\nsafeguarding of LLMs in multilingual scenarios, highlighting an urgent need to\nenhance multilingual safety. In this work, we investigate the correlation\nbetween various attack features across different languages and propose\nMultilingual Collaborative Defense (MCD), a novel learning method that\noptimizes a continuous, soft safety prompt automatically to facilitate\nmultilingual safeguarding of LLMs. The MCD approach offers three advantages:\nFirst, it effectively improves safeguarding performance across multiple\nlanguages. Second, MCD maintains strong generalization capabilities while\nminimizing false refusal rates. Third, MCD mitigates the language safety\nmisalignment caused by imbalances in LLM training corpora. To evaluate the\neffectiveness of MCD, we manually construct multilingual versions of commonly\nused jailbreak benchmarks, such as MaliciousInstruct and AdvBench, to assess\nvarious safeguarding methods. Additionally, we introduce these datasets in\nunderrepresented (zero-shot) languages to verify the language transferability\nof MCD. The results demonstrate that MCD outperforms existing approaches in\nsafeguarding against multilingual jailbreak attempts while also exhibiting\nstrong language transfer capabilities. Our code is available at\nhttps://github.com/HLiang-Lee/MCD.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在多语言场景下的安全漏洞，特别是通过翻译有害查询进行越狱 (jailbreaking) 的攻击，并提出 Multilingual Collaborative Defense (MCD)，一种通过优化连续软安全提示的学习方法来提升多语言安全。MCD 的优势包括提高跨语言防护性能、保持强泛化能力同时减少错误拒绝率，以及缓解 LLM 训练语料不平衡导致的安全失调问题。为了评估其有效性，研究者构建了多语言版本的基准数据集（如 MaliciousInstruct 和 AdvBench），实验结果显示 MCD 在对抗多语言攻击时优于现有方法，并展现出优秀的语言转移能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 4figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11835v1",
      "published_date": "2025-05-17 04:47:16 UTC",
      "updated_date": "2025-05-17 04:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:30:44.702199"
    },
    {
      "arxiv_id": "2505.11833v1",
      "title": "ToLeaP: Rethinking Development of Tool Learning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Chen",
        "Zijun Song",
        "Boye Niu",
        "Ke Zhang",
        "Litu Ou",
        "Yaxi Lu",
        "Zhong Zhang",
        "Xin Cong",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Tool learning, which enables large language models (LLMs) to utilize external\ntools effectively, has garnered increasing attention for its potential to\nrevolutionize productivity across industries. Despite rapid development in tool\nlearning, key challenges and opportunities remain understudied, limiting deeper\ninsights and future advancements. In this paper, we investigate the tool\nlearning ability of 41 prevalent LLMs by reproducing 33 benchmarks and enabling\none-click evaluation for seven of them, forming a Tool Learning Platform named\nToLeaP. We also collect 21 out of 33 potential training datasets to facilitate\nfuture exploration. After analyzing over 3,000 bad cases of 41 LLMs based on\nToLeaP, we identify four main critical challenges: (1) benchmark limitations\ninduce both the neglect and lack of (2) autonomous learning, (3)\ngeneralization, and (4) long-horizon task-solving capabilities of LLMs. To aid\nfuture advancements, we take a step further toward exploring potential\ndirections, namely (1) real-world benchmark construction, (2)\ncompatibility-aware autonomous learning, (3) rationale learning by thinking,\nand (4) identifying and recalling key clues. The preliminary experiments\ndemonstrate their effectiveness, highlighting the need for further research and\nexploration.",
      "tldr_zh": "本文重新审视了大型语言模型（LLMs）的工具学习（tool learning）发展，提出 ToLeaP 平台，通过复现 33 个基准并评估 41 个流行 LLMs 的表现，收集 21 个潜在训练数据集。研究分析了超过 3,000 个坏案例，识别了四个关键挑战：基准局限性导致 LLMs 缺乏自主学习、一般化能力以及长-horizon 任务解决能力。为了推动进展，论文探索了四个潜在方向，包括构建真实世界基准、兼容性-aware 自主学习、通过思考进行 rationale learning，以及识别和回想关键线索。初步实验验证了这些方向的有效性，强调了未来研究的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11833v1",
      "published_date": "2025-05-17 04:39:47 UTC",
      "updated_date": "2025-05-17 04:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:30:57.815999"
    },
    {
      "arxiv_id": "2505.11831v1",
      "title": "ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems",
      "title_zh": "ARC-AGI-2：前沿AI推理系统的全新挑战",
      "authors": [
        "Francois Chollet",
        "Mike Knoop",
        "Gregory Kamradt",
        "Bryan Landers",
        "Henry Pinkard"
      ],
      "abstract": "The Abstraction and Reasoning Corpus for Artificial General Intelligence\n(ARC-AGI), introduced in 2019, established a challenging benchmark for\nevaluating the general fluid intelligence of artificial systems via a set of\nunique, novel tasks only requiring minimal prior knowledge. While ARC-AGI has\nspurred significant research activity over the past five years, recent AI\nprogress calls for benchmarks capable of finer-grained evaluation at higher\nlevels of cognitive complexity. We introduce ARC-AGI-2, an upgraded version of\nthe benchmark. ARC-AGI-2 preserves the input-output pair task format of its\npredecessor, ensuring continuity for researchers. It incorporates a newly\ncurated and expanded set of tasks specifically designed to provide a more\ngranular signal to assess abstract reasoning and problem-solving abilities at\nhigher levels of fluid intelligence. To contextualize the difficulty and\ncharacteristics of ARC-AGI-2, we present extensive results from human testing,\nproviding a robust baseline that highlights the benchmark's accessibility to\nhuman intelligence, yet difficulty for current AI systems. ARC-AGI-2 aims to\nserve as a next-generation tool for rigorously measuring progress towards more\ngeneral and human-like AI capabilities.",
      "tldr_zh": "该研究引入了ARC-AGI-2基准，作为2019年ARC-AGI的升级版，旨在通过更精细的任务设计评估AI系统的更高水平抽象推理和问题解决能力。ARC-AGI-2保留了原有输入-输出对任务格式，同时新增了精心策划的扩展任务集，仅需最小先验知识，以提供更颗粒化的认知复杂度评估。研究通过广泛的人类测试建立了稳健基准，结果显示该基准对人类智能可访问，但对当前AI系统仍具挑战性。总体而言，ARC-AGI-2作为下一代工具，将有助于精确测量AI向更通用和类人能力的进展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11831v1",
      "published_date": "2025-05-17 04:34:48 UTC",
      "updated_date": "2025-05-17 04:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:31:08.114084"
    },
    {
      "arxiv_id": "2505.14708v1",
      "title": "DraftAttention: Fast Video Diffusion via Low-Resolution Attention Guidance",
      "title_zh": "DraftAttention：通过低分辨率注意力指导的快速视频扩散",
      "authors": [
        "Xuan Shen",
        "Chenxia Han",
        "Yufa Zhou",
        "Yanyue Xie",
        "Yifan Gong",
        "Quanyi Wang",
        "Yiwei Wang",
        "Yanzhi Wang",
        "Pu Zhao",
        "Jiuxiang Gu"
      ],
      "abstract": "Diffusion transformer-based video generation models (DiTs) have recently\nattracted widespread attention for their excellent generation quality. However,\ntheir computational cost remains a major bottleneck-attention alone accounts\nfor over 80% of total latency, and generating just 8 seconds of 720p video\ntakes tens of minutes-posing serious challenges to practical application and\nscalability. To address this, we propose the DraftAttention, a training-free\nframework for the acceleration of video diffusion transformers with dynamic\nsparse attention on GPUs. We apply down-sampling to each feature map across\nframes in the compressed latent space, enabling a higher-level receptive field\nover the latent composed of hundreds of thousands of tokens. The low-resolution\ndraft attention map, derived from draft query and key, exposes redundancy both\nspatially within each feature map and temporally across frames. We reorder the\nquery, key, and value based on the draft attention map to guide the sparse\nattention computation in full resolution, and subsequently restore their\noriginal order after the attention computation. This reordering enables\nstructured sparsity that aligns with hardware-optimized execution. Our\ntheoretical analysis demonstrates that the low-resolution draft attention\nclosely approximates the full attention, providing reliable guidance for\nconstructing accurate sparse attention. Experimental results show that our\nmethod outperforms existing sparse attention approaches in video generation\nquality and achieves up to 1.75x end-to-end speedup on GPUs. Code:\nhttps://github.com/shawnricecake/draft-attention",
      "tldr_zh": "该研究针对 Diffusion transformer-based video generation models (DiTs) 在视频生成中的高计算成本问题（如注意力机制占80%的延迟），提出了一种无需训练的框架DraftAttention，用于加速视频扩散变换器。框架通过对特征图进行降采样，在压缩的潜在空间中创建更高的感受野，并利用低分辨率草案注意力图识别空间和时间冗余，从而指导全分辨率的稀疏注意力计算。实验结果显示，DraftAttention在视频生成质量上优于现有稀疏注意力方法，并在GPU上实现高达1.75倍的端到端加速。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint Version",
      "pdf_url": "http://arxiv.org/pdf/2505.14708v1",
      "published_date": "2025-05-17 04:34:34 UTC",
      "updated_date": "2025-05-17 04:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:31:19.945496"
    },
    {
      "arxiv_id": "2505.11830v1",
      "title": "CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongbo Jin",
        "Ruyang Liu",
        "Wenhao Zhang",
        "Guibo Luo",
        "Ge Li"
      ],
      "abstract": "System2 reasoning is developing rapidly these days with the emergence of\nDeep- Thinking Models and chain-of-thought technology, which has become a\ncentralized discussion point in the AI community. However, there is a relative\ngap in the research on complex video reasoning at present. In this work, we\npropose CoT-Vid, a novel training-free paradigm for the video domain with a\nmultistage complex reasoning design. Distinguishing from existing video LLMs,\nwhich rely heavily on perceptual abilities, it achieved surprising performance\ngain with explicit reasoning mechanism. The paradigm consists of three main\ncomponents: dynamic inference path routing, problem decoupling strategy, and\nvideo self-consistency verification. In addition, we propose a new standard for\ncategorization of video questions. CoT- Vid showed outstanding results on a\nwide range of benchmarks, and outperforms its base model by 9.3% on Egochema\nand 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary\nmodels, such as GPT-4V, GPT-4o and Gemini-1.5-flash. Our codebase will be\npublicly available soon.",
      "tldr_zh": "本文提出 CoT-Vid，一种无需训练的视频推理范式，采用动态 Chain-of-Thought 路由、问题解耦策略和视频自一致性验证机制，旨在提升复杂视频推理性能。不同于依赖感知能力的现有视频 LLM，该方法通过显式推理设计实现了显著改进，并引入了新的视频问题分类标准。在基准测试中，CoT-Vid 比基础模型在 Egochema 上提升 9.3%、在 VideoEspresso 上提升 5.6%，甚至超过了 GPT-4V、GPT-4o 和 Gemini-1.5-flash 等大型模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11830v1",
      "published_date": "2025-05-17 04:34:32 UTC",
      "updated_date": "2025-05-17 04:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:31:32.402130"
    },
    {
      "arxiv_id": "2505.11827v1",
      "title": "Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning",
      "title_zh": "并非所有思考都同样重要：通过多轮强化学习实现高效的LLM推理",
      "authors": [
        "Yansong Ning",
        "Wei Li",
        "Jun Fang",
        "Naiqiang Tan",
        "Hao Liu"
      ],
      "abstract": "Compressing long chain-of-thought (CoT) from large language models (LLMs) is\nan emerging strategy to improve the reasoning efficiency of LLMs. Despite its\npromising benefits, existing studies equally compress all thoughts within a\nlong CoT, hindering more concise and effective reasoning. To this end, we first\ninvestigate the importance of different thoughts by examining their\neffectiveness and efficiency in contributing to reasoning through automatic\nlong CoT chunking and Monte Carlo rollouts. Building upon the insights, we\npropose a theoretically bounded metric to jointly measure the effectiveness and\nefficiency of different thoughts. We then propose Long$\\otimes$Short, an\nefficient reasoning framework that enables two LLMs to collaboratively solve\nthe problem: a long-thought LLM for more effectively generating important\nthoughts, while a short-thought LLM for efficiently generating remaining\nthoughts. Specifically, we begin by synthesizing a small amount of cold-start\ndata to fine-tune LLMs for long-thought and short-thought reasoning styles,\nrespectively. Furthermore, we propose a synergizing-oriented multi-turn\nreinforcement learning, focusing on the model self-evolution and collaboration\nbetween long-thought and short-thought LLMs. Experimental results show that our\nmethod enables Qwen2.5-7B and Llama3.1-8B to achieve comparable performance\ncompared to DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B, while\nreducing token length by over 80% across the MATH500, AIME24/25, AMC23, and\nGPQA Diamond benchmarks. Our data and code are available at\nhttps://github.com/yasNing/Long-otimes-Short/.",
      "tldr_zh": "该论文指出，现有的 Chain-of-Thought (CoT) 压缩方法未能区分不同想法的重要性，因此通过自动长 CoT 分块和 Monte Carlo rollouts 评估想法的有效性和效率，并提出一个联合度量标准。\n作者引入 Long⊗Short 框架，使用两个 LLMs 协作：long-thought LLM 专注于生成重要想法，short-thought LLM 处理剩余想法，并通过多轮 Reinforcement Learning 优化模型的自演化和协同。\n实验结果显示，该方法使 Qwen2.5-7B 和 Llama3.1-8B 在 MATH500、AIME24/25、AMC23 和 GPQA Diamond 等基准上性能与基线模型相当，但令牌长度减少超过 80%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In progress",
      "pdf_url": "http://arxiv.org/pdf/2505.11827v1",
      "published_date": "2025-05-17 04:26:39 UTC",
      "updated_date": "2025-05-17 04:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:31:45.312704"
    },
    {
      "arxiv_id": "2505.11825v1",
      "title": "Bootstrapping Diffusion: Diffusion Model Training Leveraging Partial and Corrupted Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Ma"
      ],
      "abstract": "Training diffusion models requires large datasets. However, acquiring large\nvolumes of high-quality data can be challenging, for example, collecting large\nnumbers of high-resolution images and long videos. On the other hand, there are\nmany complementary data that are usually considered corrupted or partial, such\nas low-resolution images and short videos. Other examples of corrupted data\ninclude videos that contain subtitles, watermarks, and logos. In this study, we\ninvestigate the theoretical problem of whether the above partial data can be\nutilized to train conventional diffusion models. Motivated by our theoretical\nanalysis in this study, we propose a straightforward approach of training\ndiffusion models utilizing partial data views, where we consider each form of\ncomplementary data as a view of conventional data. Our proposed approach first\ntrains one separate diffusion model for each individual view, and then trains a\nmodel for predicting the residual score function. We prove generalization error\nbounds, which show that the proposed diffusion model training approach can\nachieve lower generalization errors if proper regularizations are adopted in\nthe residual score function training. In particular, we prove that the\ndifficulty in training the residual score function scales proportionally with\nthe signal correlations not captured by partial data views. Consequently, the\nproposed approach achieves near first-order optimal data efficiency.",
      "tldr_zh": "本文研究了如何利用部分和损坏数据（如低分辨率图像和短视频）训练 diffusion models，以解决高质量数据获取的挑战。提出了一种简单方法：先为每个数据视图训练单独的 diffusion model，然后训练一个预测 residual score function 的模型，并通过适当的正则化来优化训练过程。理论分析证明了该方法的泛化误差边界较低，且数据效率接近第一阶最优，因为训练难度与部分数据视图未捕获的信号相关性成正比。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.11825v1",
      "published_date": "2025-05-17 04:17:48 UTC",
      "updated_date": "2025-05-17 04:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:31:56.245102"
    },
    {
      "arxiv_id": "2505.11824v1",
      "title": "Search-Based Correction of Reasoning Chains for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Kim",
        "Jean-Pierre Falet",
        "Oliver E. Richardson",
        "Xiaoyin Chen",
        "Moksh Jain",
        "Sungjin Ahn",
        "Sungsoo Ahn",
        "Yoshua Bengio"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning has advanced the capabilities and\ntransparency of language models (LMs); however, reasoning chains can contain\ninaccurate statements that reduce performance and trustworthiness. To address\nthis, we introduce a new self-correction framework that augments each reasoning\nstep in a CoT with a latent variable indicating its veracity, enabling modeling\nof all possible truth assignments rather than assuming correctness throughout.\nTo efficiently explore this expanded space, we introduce Search Corrector, a\ndiscrete search algorithm over boolean-valued veracity assignments. It\nefficiently performs otherwise intractable inference in the posterior\ndistribution over veracity assignments by leveraging the LM's joint likelihood\nover veracity and the final answer as a proxy reward. This efficient\ninference-time correction method facilitates supervised fine-tuning of an\nAmortized Corrector by providing pseudo-labels for veracity. The Amortized\nCorrector generalizes self-correction, enabling accurate zero-shot veracity\ninference in novel contexts. Empirical results demonstrate that Search\nCorrector reliably identifies errors in logical (ProntoQA) and mathematical\nreasoning (GSM8K) benchmarks. The Amortized Corrector achieves comparable\nzero-shot accuracy and improves final answer accuracy by up to 25%.",
      "tldr_zh": "这篇论文针对语言模型的 Chain-of-Thought (CoT) 推理中存在的错误问题，提出了一种自校正框架，通过为每个推理步骤添加表示真实性的潜在变量来建模所有可能的真实性分配。框架的核心是 Search Corrector，一种基于离散搜索的算法，利用语言模型的联合似然作为代理奖励，高效探索并纠正错误，从而为 Amortized Corrector 提供监督微调的伪标签。实验结果显示，Amortized Corrector 在 ProntoQA 和 GSM8K 等基准上实现了可比的零样本准确率，并将最终答案准确率提高高达 25%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11824v1",
      "published_date": "2025-05-17 04:16:36 UTC",
      "updated_date": "2025-05-17 04:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:32:08.618257"
    },
    {
      "arxiv_id": "2505.13516v1",
      "title": "HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems",
      "title_zh": "HALO：面向多智能体LLM系统的层次化自治逻辑导向编排",
      "authors": [
        "Zhipeng Hou",
        "Junyi Tang",
        "Yipeng Wang"
      ],
      "abstract": "Recent advancements in Multi-Agent Systems (MAS) powered by Large Language\nModels (LLMs) have demonstrated tremendous potential in diverse task scenarios.\nNonetheless, existing agentic systems typically rely on predefined agent-role\ndesign spaces and static communication structures, limiting their adaptability\nas well as flexibility in complex interaction environments and leading to\nsubpar performance on highly specialized and expert-level tasks. To address\nthese issues, we introduce HALO, a multi-agent collaboration framework based on\na hierarchical reasoning architecture. Specifically, we incorporate a\nhigh-level planning agent for task decomposition, mid-level role-design agents\nfor subtask-specific agent instantiation, and low-level inference agents for\nsubtask execution. Particularly, subtask execution is reformulated as a\nstructured workflow search problem, where Monte Carlo Tree Search (MCTS)\nsystematically explores the agentic action space to construct optimal reasoning\ntrajectories. Additionally, as the majority of users lack expertise in prompt\nengineering, we leverage an Adaptive Prompt Refinement module to transform raw\nqueries into task-specific prompts. Empirical evaluations on Code Generation\n(HumanEval), General Reasoning (MMLU), and Arithmetic Reasoning (MATH)\nbenchmark datasets highlight the effectiveness of HALO, yielding a 14.4%\naverage improvement over state-of-the-art baselines. Notably, HALO achieves up\nto 13.3% performance gain on the Moral Scenarios subject in the MMLU benchmark\nand up to 19.6% performance gain on the Algebra subarea in the MATH benchmark,\nindicating its advanced proficiency in tackling highly specialized and\nexpert-level tasks. The code repository is available at\nhttps://github.com/23japhone/HALO.",
      "tldr_zh": "该论文提出 HALO，一种基于分层推理架构的自治逻辑导向框架，用于提升 Multi-Agent LLM Systems 的适应性和灵活性，解决现有系统依赖预定义角色和静态通信结构的问题。HALO 包括高层规划智能体进行任务分解、中层角色设计智能体实例化子任务特定智能体，以及底层推理智能体通过 Monte Carlo Tree Search (MCTS) 探索行动空间以构建最优推理轨迹。框架还引入 Adaptive Prompt Refinement 模块，将原始查询转化为任务特定提示，以辅助非专业用户。实验结果显示，HALO 在 HumanEval、MMLU 和 MATH 基准上平均比最先进基线提高了 14.4%，特别是在 MMLU 的 Moral Scenarios 和 MATH 的 Algebra 子领域分别提升了 13.3% 和 19.6%，证明其在高度专业任务中的优越性能。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "The code repository is available at https://github.com/23japhone/HALO",
      "pdf_url": "http://arxiv.org/pdf/2505.13516v1",
      "published_date": "2025-05-17 04:14:03 UTC",
      "updated_date": "2025-05-17 04:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:32:23.131847"
    },
    {
      "arxiv_id": "2505.13515v1",
      "title": "LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades",
      "title_zh": "翻译失败",
      "authors": [
        "Yanan Li",
        "Fanxu Meng",
        "Muhan Zhang",
        "Shiai Zhu",
        "Shangguang Wang",
        "Mengwei Xu"
      ],
      "abstract": "As Large Language Models (LLMs) are frequently updated, LoRA weights trained\non earlier versions quickly become obsolete. The conventional practice of\nretraining LoRA weights from scratch on the latest model is costly,\ntime-consuming, and environmentally detrimental, particularly as the diversity\nof LLMs and downstream tasks expands. This motivates a critical question: \"How\ncan we efficiently leverage existing LoRA weights to adapt to newer model\nversions?\" To address this, we propose LoRASuite, a modular approach tailored\nspecifically to various types of LLM updates. First, we compute a transfer\nmatrix utilizing known parameters from both old and new LLMs. Next, we allocate\ncorresponding layers and attention heads based on centered kernel alignment and\ncosine similarity metrics, respectively. A subsequent small-scale, skillful\nfine-tuning step ensures numerical stability. Experimental evaluations\ndemonstrate that LoRASuite consistently surpasses small-scale vanilla LoRA\nmethods. Notably, on backbone LLMs such as MiniCPM and Qwen, LoRASuite even\nexceeds the performance of full-scale LoRA retraining, with average\nimprovements of +1.4 and +6.6 points on math tasks, respectively. Additionally,\nLoRASuite significantly reduces memory consumption by 5.5 GB and computational\ntime by 78.23%.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)频繁更新导致 LoRA 权重过时的问题，提出 LoRASuite，一种模块化框架，用于高效适应不同类型 LLM 更新。\nLoRASuite 通过计算转移矩阵、基于 centered kernel alignment 和 cosine similarity 分配层和注意力头，并进行小规模微调，确保了权重的有效转移。\n实验结果显示，LoRASuite 在 MiniCPM 和 Qwen 等模型上超过了全规模 LoRA 重训，数学任务平均提升 1.4 和 6.6 分，同时减少了 5.5 GB 内存消耗和 78.23% 计算时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13515v1",
      "published_date": "2025-05-17 04:11:17 UTC",
      "updated_date": "2025-05-17 04:11:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:32:32.606448"
    },
    {
      "arxiv_id": "2505.11814v1",
      "title": "ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Hector Munoz-Avila",
        "David W. Aha",
        "Paola Rizzo"
      ],
      "abstract": "We introduce ChatHTN, a Hierarchical Task Network (HTN) planner that combines\nsymbolic HTN planning techniques with queries to ChatGPT to approximate\nsolutions in the form of task decompositions. The resulting hierarchies\ninterleave task decompositions generated by symbolic HTN planning with those\ngenerated by ChatGPT. Despite the approximate nature of the results generates\nby ChatGPT, ChatHTN is provably sound; any plan it generates correctly achieves\nthe input tasks. We demonstrate this property with an open-source\nimplementation of our system.",
      "tldr_zh": "该论文引入了 ChatHTN，一种 Hierarchical Task Network (HTN) 规划器，将符号 HTN 规划技术与 ChatGPT 查询相结合，来近似生成任务分解。ChatHTN 通过交织符号规划生成的分解与 LLM (Large Language Model) 生成的分解，确保规划过程的灵活性。尽管 ChatGPT 的结果是近似的，该系统被证明是 provably sound 的，即生成的任何计划都能正确实现输入任务。最后，研究提供了一个开源实现，以验证其可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2nd International Conference on Neuro-symbolic Systems (NeuS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11814v1",
      "published_date": "2025-05-17 03:53:08 UTC",
      "updated_date": "2025-05-17 03:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:32:44.289363"
    },
    {
      "arxiv_id": "2505.11813v1",
      "title": "SGD-Mix: Enhancing Domain-Specific Image Classification with Label-Preserving Data Augmentation",
      "title_zh": "SGD-Mix：通过保留标签的数据增强提升领域特定图像分类",
      "authors": [
        "Yixuan Dong",
        "Fang-Yi Su",
        "Jung-Hsien Chiang"
      ],
      "abstract": "Data augmentation for domain-specific image classification tasks often\nstruggles to simultaneously address diversity, faithfulness, and label clarity\nof generated data, leading to suboptimal performance in downstream tasks. While\nexisting generative diffusion model-based methods aim to enhance augmentation,\nthey fail to cohesively tackle these three critical aspects and often overlook\nintrinsic challenges of diffusion models, such as sensitivity to model\ncharacteristics and stochasticity under strong transformations. In this paper,\nwe propose a novel framework that explicitly integrates diversity,\nfaithfulness, and label clarity into the augmentation process. Our approach\nemploys saliency-guided mixing and a fine-tuned diffusion model to preserve\nforeground semantics, enrich background diversity, and ensure label\nconsistency, while mitigating diffusion model limitations. Extensive\nexperiments across fine-grained, long-tail, few-shot, and background robustness\ntasks demonstrate our method's superior performance over state-of-the-art\napproaches.",
      "tldr_zh": "本文提出SGD-Mix框架，用于提升领域特定图像分类任务的数据增强效果。该框架通过显式整合多样性、忠实性和标签清晰度，使用saliency-guided mixing和fine-tuned diffusion model来保留前景语义、丰富背景多样性，并确保标签一致性，同时缓解diffusion model的固有挑战，如对模型特性的敏感性和随机性。实验结果显示，在细粒度、长尾分布、少样本和背景鲁棒性任务上，SGD-Mix优于现有最先进方法，显著提高了下游任务的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 6 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.11813v1",
      "published_date": "2025-05-17 03:51:18 UTC",
      "updated_date": "2025-05-17 03:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:32:56.821840"
    },
    {
      "arxiv_id": "2505.11807v1",
      "title": "Retrospex: Language Agent Meets Offline Reinforcement Learning Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Xiang",
        "Yiqun Shen",
        "Yeqin Zhang",
        "Cam-Tu Nguyen"
      ],
      "abstract": "Large Language Models (LLMs) possess extensive knowledge and commonsense\nreasoning capabilities, making them valuable for creating powerful agents.\nHowever, existing LLM agent frameworks have not fully utilized past experiences\nfor improvement. This work introduces a new LLM-based agent framework called\nRetrospex, which addresses this challenge by analyzing past experiences in\ndepth. Unlike previous approaches, Retrospex does not directly integrate\nexperiences into the LLM's context. Instead, it combines the LLM's action\nlikelihood with action values estimated by a Reinforcement Learning (RL)\nCritic, which is trained on past experiences through an offline\n''retrospection'' process. Additionally, Retrospex employs a dynamic action\nrescoring mechanism that increases the importance of experience-based values\nfor tasks that require more interaction with the environment. We evaluate\nRetrospex in ScienceWorld, ALFWorld and Webshop environments, demonstrating its\nadvantages over strong, contemporary baselines.",
      "tldr_zh": "该研究提出Retrospex框架，将大型语言模型(LLMs)的知识和推理能力与离线强化学习(RL) Critic相结合，以更好地利用过去经验提升代理性能。不同于直接整合经验，Retrospex通过离线\"retrospection\"过程训练RL Critic来估计行动值，并将其与LLMs的行动可能性融合，同时引入动态行动重新评分机制，以针对高交互任务增强经验权重。在ScienceWorld、ALFWorld和Webshop等环境中，Retrospex表现出色，优于现有基线，证明了其在代理决策中的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11807v1",
      "published_date": "2025-05-17 03:28:24 UTC",
      "updated_date": "2025-05-17 03:28:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:33:07.437754"
    },
    {
      "arxiv_id": "2505.11804v1",
      "title": "Are vision language models robust to uncertain inputs?",
      "title_zh": "视觉语言模型对不确定输入是否鲁棒？",
      "authors": [
        "Xi Wang",
        "Eric Nalisnick"
      ],
      "abstract": "Robustness against uncertain and ambiguous inputs is a critical challenge for\ndeep learning models. While recent advancements in large scale vision language\nmodels (VLMs, e.g. GPT4o) might suggest that increasing model and training\ndataset size would mitigate this issue, our empirical evaluation shows a more\ncomplicated picture. Testing models using two classic uncertainty\nquantification tasks, anomaly detection and classification under inherently\nambiguous conditions, we find that newer and larger VLMs indeed exhibit\nimproved robustness compared to earlier models, but still suffer from a\ntendency to strictly follow instructions, often causing them to hallucinate\nconfident responses even when faced with unclear or anomalous inputs.\nRemarkably, for natural images such as ImageNet, this limitation can be\novercome without pipeline modifications: simply prompting models to abstain\nfrom uncertain predictions enables significant reliability gains, achieving\nnear-perfect robustness in several settings. However, for domain-specific tasks\nsuch as galaxy morphology classification, a lack of specialized knowledge\nprevents reliable uncertainty estimation. Finally, we propose a novel mechanism\nbased on caption diversity to reveal a model's internal uncertainty, enabling\npractitioners to predict when models will successfully abstain without relying\non labeled data.",
      "tldr_zh": "本研究评估了视觉语言模型（VLMs）对不确定输入的鲁棒性，发现尽管更大规模的VLMs（如GPT4o）比早期模型更具改善，但它们仍倾向于严格遵循指令，导致在异常检测和模糊分类任务中出现幻觉和自信错误回应。通过简单提示模型在不确定时避免预测，该问题在自然图像（如ImageNet）任务中可显著缓解，实现近乎完美的鲁棒性。然而，在领域特定任务如星系形态分类中，模型缺乏专业知识导致可靠性不足。最后，研究提出一种基于标题多样性（caption diversity）的创新机制，能揭示模型内部不确定性，帮助预测何时成功避免预测，而无需标注数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11804v1",
      "published_date": "2025-05-17 03:16:49 UTC",
      "updated_date": "2025-05-17 03:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:33:19.654907"
    },
    {
      "arxiv_id": "2505.11803v1",
      "title": "VITA: Versatile Time Representation Learning for Temporal Hyper-Relational Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "ChongIn Un",
        "Yuhuan Lu",
        "Tianyue Yang",
        "Dingqi Yang"
      ],
      "abstract": "Knowledge graphs (KGs) have become an effective paradigm for managing\nreal-world facts, which are not only complex but also dynamically evolve over\ntime. The temporal validity of facts often serves as a strong clue in\ndownstream link prediction tasks, which predicts a missing element in a fact.\nTraditional link prediction techniques on temporal KGs either consider a\nsequence of temporal snapshots of KGs with an ad-hoc defined time interval or\nexpand a temporal fact over its validity period under a predefined time\ngranularity; these approaches not only suffer from the sensitivity of the\nselection of time interval/granularity, but also face the computational\nchallenges when handling facts with long (even infinite) validity. Although the\nrecent hyper-relational KGs represent the temporal validity of a fact as\nqualifiers describing the fact, it is still suboptimal due to its ignorance of\nthe infinite validity of some facts and the insufficient information encoded\nfrom the qualifiers about the temporal validity. Against this background, we\npropose VITA, a $\\underline{V}$ersatile t$\\underline{I}$me\nrepresen$\\underline{TA}$tion learning method for temporal hyper-relational\nknowledge graphs. We first propose a versatile time representation that can\nflexibly accommodate all four types of temporal validity of facts (i.e., since,\nuntil, period, time-invariant), and then design VITA to effectively learn the\ntime information in both aspects of time value and timespan to boost the link\nprediction performance. We conduct a thorough evaluation of VITA compared to a\nsizable collection of baselines on real-world KG datasets. Results show that\nVITA outperforms the best-performing baselines in various link prediction tasks\n(predicting missing entities, relations, time, and other numeric literals) by\nup to 75.3%. Ablation studies and a case study also support our key design\nchoices.",
      "tldr_zh": "本研究提出VITA，一种多功能的时代表现学习方法，用于处理temporal hyper-relational knowledge graphs中的动态事实问题。VITA通过灵活的时代表现适应四种时间有效性类型（包括since、until、period和time-invariant），并学习时间值和时跨度信息，以提升链接预测任务的性能。实验结果显示，VITA在真实数据集上比基线模型在预测缺失实体、关系、时间和其他数值时改善高达75.3%，并通过消融研究和案例分析验证了其关键设计选择。",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11803v1",
      "published_date": "2025-05-17 03:16:13 UTC",
      "updated_date": "2025-05-17 03:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:33:31.841063"
    },
    {
      "arxiv_id": "2505.11802v1",
      "title": "Diffmv: A Unified Diffusion Framework for Healthcare Predictions with Random Missing Views and View Laziness",
      "title_zh": "翻译失败",
      "authors": [
        "Chuang Zhao",
        "Hui Tang",
        "Hongke Zhao",
        "Xiaomeng Li"
      ],
      "abstract": "Advanced healthcare predictions offer significant improvements in patient\noutcomes by leveraging predictive analytics. Existing works primarily utilize\nvarious views of Electronic Health Record (EHR) data, such as diagnoses, lab\ntests, or clinical notes, for model training. These methods typically assume\nthe availability of complete EHR views and that the designed model could fully\nleverage the potential of each view. However, in practice, random missing views\nand view laziness present two significant challenges that hinder further\nimprovements in multi-view utilization. To address these challenges, we\nintroduce Diffmv, an innovative diffusion-based generative framework designed\nto advance the exploitation of multiple views of EHR data. Specifically, to\naddress random missing views, we integrate various views of EHR data into a\nunified diffusion-denoising framework, enriched with diverse contextual\nconditions to facilitate progressive alignment and view transformation. To\nmitigate view laziness, we propose a novel reweighting strategy that assesses\nthe relative advantages of each view, promoting a balanced utilization of\nvarious data views within the model. Our proposed strategy achieves superior\nperformance across multiple health prediction tasks derived from three popular\ndatasets, including multi-view and multi-modality scenarios.",
      "tldr_zh": "该研究提出Diffmv，一种统一的扩散框架，用于处理医疗预测中的随机缺失视图和视图懒惰问题，旨在更好地利用电子健康记录(EHR)数据的多视图信息。框架通过将各种EHR视图整合到扩散去噪模型中，并使用多样化的上下文条件实现渐进对齐和视图转换，从而解决随机缺失视图；同时，引入一种新型再加权策略来评估每个视图的相对优势，促进模型的平衡利用。实验结果显示，Diffmv在多个健康预测任务上表现出色，在三个流行数据集的多视图和多模态场景中，实现了比现有方法更优的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SIGKDD2025, accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.11802v1",
      "published_date": "2025-05-17 03:15:55 UTC",
      "updated_date": "2025-05-17 03:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:33:43.874325"
    },
    {
      "arxiv_id": "2505.13514v1",
      "title": "Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuxun Wang",
        "Qingyu Yin",
        "Chak Tou Leong",
        "Qiang Zhang",
        "Linyi Yang"
      ],
      "abstract": "Repetition curse is a phenomenon where Large Language Models (LLMs) generate\nrepetitive sequences of tokens or cyclic sequences. While the repetition curse\nhas been widely observed, its underlying mechanisms remain poorly understood.\nIn this work, we investigate the role of induction heads--a specific type of\nattention head known for their ability to perform in-context learning--in\ndriving this repetitive behavior. Specifically, we focus on the \"toxicity\" of\ninduction heads, which we define as their tendency to dominate the model's\noutput logits during repetition, effectively excluding other attention heads\nfrom contributing to the generation process. Our findings have important\nimplications for the design and training of LLMs. By identifying induction\nheads as a key driver of the repetition curse, we provide a mechanistic\nexplanation for this phenomenon and suggest potential avenues for mitigation.\nWe also propose a technique with attention head regularization that could be\nemployed to reduce the dominance of induction heads during generation, thereby\npromoting more diverse and coherent outputs.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)中常见的repetition curse现象，即模型生成重复或循环序列的原因，并发现induction heads（一种用于in-context learning的注意力头）是其主要驱动因素。研究定义了induction heads的“toxicity”，即它们在重复过程中主导输出logits，从而排斥其他注意力头的贡献，提供了一个机制性解释。最终，该工作提出attention head regularization技术作为潜在解决方案，以减少induction heads的支配性，促进模型生成更多样和连贯的输出。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13514v1",
      "published_date": "2025-05-17 03:09:33 UTC",
      "updated_date": "2025-05-17 03:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:33:56.044004"
    },
    {
      "arxiv_id": "2505.11793v1",
      "title": "CL-CaGAN: Capsule differential adversarial continuous learning for cross-domain hyperspectral anomaly detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Wang",
        "Siying Guo",
        "Zheng Hua",
        "Runhu Huang",
        "Jinyu Hu",
        "Maoguo Gong"
      ],
      "abstract": "Anomaly detection (AD) has attracted remarkable attention in hyperspectral\nimage (HSI) processing fields, and most existing deep learning (DL)-based\nalgorithms indicate dramatic potential for detecting anomaly samples through\nspecific training process under current scenario. However, the limited prior\ninformation and the catastrophic forgetting problem indicate crucial challenges\nfor existing DL structure in open scenarios cross-domain detection. In order to\nimprove the detection performance, a novel continual learning-based capsule\ndifferential generative adversarial network (CL-CaGAN) is proposed to elevate\nthe cross-scenario learning performance for facilitating the real application\nof DL-based structure in hyperspectral AD (HAD) task. First, a modified capsule\nstructure with adversarial learning network is constructed to estimate the\nbackground distribution for surmounting the deficiency of prior information. To\nmitigate the catastrophic forgetting phenomenon, clustering-based sample replay\nstrategy and a designed extra self-distillation regularization are integrated\nfor merging the history and future knowledge in continual AD task, while the\ndiscriminative learning ability from previous detection scenario to current\nscenario is retained by the elaborately designed structure with continual\nlearning (CL) strategy. In addition, the differentiable enhancement is enforced\nto augment the generation performance of the training data. This further\nstabilizes the training process with better convergence and efficiently\nconsolidates the reconstruction ability of background samples. To verify the\neffectiveness of our proposed CL-CaGAN, we conduct experiments on several real\nHSIs, and the results indicate that the proposed CL-CaGAN demonstrates higher\ndetection performance and continuous learning capacity for mitigating the\ncatastrophic forgetting under cross-domain scenarios.",
      "tldr_zh": "该论文提出 CL-CaGAN，一种基于持续学习（continual learning）的胶囊差分生成对抗网络（capsule differential adversarial network），旨在解决高光谱图像（HSI）跨域异常检测（AD）中的先验信息不足和灾难性遗忘问题。该方法通过修改后的胶囊结构与对抗学习网络估计背景分布，并整合集群-based样本重放策略、自蒸馏正则化和可微增强技术，以保留历史知识并提升训练稳定性。实验结果表明，CL-CaGAN 在真实 HSI 数据集上实现了更高的检测性能和持续学习能力，显著缓解了跨域场景下的灾难性遗忘现象。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11793v1",
      "published_date": "2025-05-17 02:32:41 UTC",
      "updated_date": "2025-05-17 02:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:34:08.845145"
    },
    {
      "arxiv_id": "2505.11792v1",
      "title": "Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yitian Chen",
        "Jingfan Xia",
        "Siyu Shao",
        "Dongdong Ge",
        "Yinyu Ye"
      ],
      "abstract": "Optimization modeling is fundamental to decision-making across diverse\ndomains.Despite progress in automating optimization formulation from natural\nlanguage descriptions, Large Language Models (LLMs) often struggle to generate\nformally correct and usable models due to hallucinations, posing a challenge\nfor reliable automation. Inspired by the success of Reinforcement Learning (RL)\nin enhancing Large Reasoning Models, we present Solver-Informed Reinforcement\nLearning (SIRL).This novel framework leverages external optimization solvers as\nverifiable reward mechanisms to significantly improve the authenticity of LLMs\nfor optimization modeling.Acting as precise verifiers, these solvers\nautomatically assess the executable code and the instance-level mathematical\nmodel represented by the associated LP file, yielding precise and comprehensive\nfeedback signals -- including syntax, feasibility, and solution quality that\ndirectly inform the RL process. This automated verification process, powered by\nclassic optimization solvers, also underpins our instance-enhanced\nself-consistency method to synthesize high-quality training data. Extensive\nexperiments on diverse public benchmarks demonstrate that SIRL achieves\nstate-of-the-art performance, substantially outperforming existing methods in\ngenerating accurate and executable optimization models.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 在优化建模中存在的幻觉问题，提出了一种名为 Solver-Informed Reinforcement Learning (SIRL) 的框架，以提升模型生成正式正确和可执行优化模型的真实性。SIRL 通过外部优化求解器作为奖励机制，提供精确反馈，包括语法、feasibility 和解决方案质量，从而指导 Reinforcement Learning (RL) 过程，并支持实例增强的自一致性方法来合成高质量训练数据。实验结果显示，该框架在多样公共基准上显著优于现有方法，实现了最先进性能，为可靠的优化建模自动化奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11792v1",
      "published_date": "2025-05-17 02:32:03 UTC",
      "updated_date": "2025-05-17 02:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:34:21.432905"
    },
    {
      "arxiv_id": "2505.11785v1",
      "title": "Improving Coverage in Combined Prediction Sets with Weighted p-values",
      "title_zh": "翻译失败",
      "authors": [
        "Gina Wong",
        "Drew Prinster",
        "Suchi Saria",
        "Rama Chellappa",
        "Anqi Liu"
      ],
      "abstract": "Conformal prediction quantifies the uncertainty of machine learning models by\naugmenting point predictions with valid prediction sets, assuming\nexchangeability. For complex scenarios involving multiple trials, models, or\ndata sources, conformal prediction sets can be aggregated to create a\nprediction set that captures the overall uncertainty, often improving\nprecision. However, aggregating multiple prediction sets with individual\n$1-\\alpha$ coverage inevitably weakens the overall guarantee, typically\nresulting in $1-2\\alpha$ worst-case coverage. In this work, we propose a\nframework for the weighted aggregation of prediction sets, where weights are\nassigned to each prediction set based on their contribution. Our framework\noffers flexible control over how the sets are aggregated, achieving tighter\ncoverage bounds that interpolate between the $1-2\\alpha$ guarantee of the\ncombined models and the $1-\\alpha$ guarantee of an individual model depending\non the distribution of weights. We extend our framework to data-dependent\nweights, and we derive a general procedure for data-dependent weight\naggregation that maintains finite-sample validity. We demonstrate the\neffectiveness of our methods through experiments on synthetic and real data in\nthe mixture-of-experts setting, and we show that aggregation with\ndata-dependent weights provides a form of adaptive coverage.",
      "tldr_zh": "本文提出了一种基于加权 p-values 的框架，用于改善 Conformal Prediction 在聚合多个预测集时的覆盖率问题。该框架通过为每个预测集分配基于贡献的权重，实现更灵活的聚合控制，从而获得介于 1-2α 和 1-α 之间的更紧凑覆盖率边界，并扩展到数据相关的权重以保持有限样本有效性。在混合专家设置的合成和真实数据实验中，该方法展示了显著的自适应覆盖性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11785v1",
      "published_date": "2025-05-17 01:51:28 UTC",
      "updated_date": "2025-05-17 01:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:34:32.852972"
    },
    {
      "arxiv_id": "2505.11780v1",
      "title": "A Review and Analysis of a Parallel Approach for Decision Tree Learning from Large Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Zeinab Shiralizadeh"
      ],
      "abstract": "This work studies one of the parallel decision tree learning algorithms,\npdsCART, designed for scalable and efficient data analysis. The method\nincorporates three core capabilities. First, it supports real-time learning\nfrom data streams, allowing trees to be constructed incrementally. Second, it\nenables parallel processing of high-volume streaming data, making it\nwell-suited for large-scale applications. Third, the algorithm integrates\nseamlessly into the MapReduce framework, ensuring compatibility with\ndistributed computing environments. In what follows, we present the algorithm's\nkey components along with results highlighting its performance and scalability.",
      "tldr_zh": "这篇论文审查和分析了 pdsCART 算法，这是一种用于从大型数据流学习决策树(Decision Tree)的并行方法，旨在实现可扩展和高效的数据分析。该算法具备三个核心能力：支持从数据流实时学习并逐步构建树、启用高体积流数据的并行处理，以及与 MapReduce 框架无缝集成。论文详细介绍了算法的关键组件，并展示了其性能和可扩展性的实验结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11780v1",
      "published_date": "2025-05-17 01:07:25 UTC",
      "updated_date": "2025-05-17 01:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:34:45.037835"
    },
    {
      "arxiv_id": "2505.11776v1",
      "title": "Generative and Contrastive Graph Representation Learning",
      "title_zh": "生成式与对比式图表示学习",
      "authors": [
        "Jiali Chen",
        "Avijit Mukherjee"
      ],
      "abstract": "Self-supervised learning (SSL) on graphs generates node and graph\nrepresentations (i.e., embeddings) that can be used for downstream tasks such\nas node classification, node clustering, and link prediction. Graph SSL is\nparticularly useful in scenarios with limited or no labeled data. Existing SSL\nmethods predominantly follow contrastive or generative paradigms, each\nexcelling in different tasks: contrastive methods typically perform well on\nclassification tasks, while generative methods often excel in link prediction.\nIn this paper, we present a novel architecture for graph SSL that integrates\nthe strengths of both approaches. Our framework introduces community-aware\nnode-level contrastive learning, providing more robust and effective positive\nand negative node pairs generation, alongside graph-level contrastive learning\nto capture global semantic information. Additionally, we employ a comprehensive\naugmentation strategy that combines feature masking, node perturbation, and\nedge perturbation, enabling robust and diverse representation learning. By\nincorporating these enhancements, our model achieves superior performance\nacross multiple tasks, including node classification, clustering, and link\nprediction. Evaluations on open benchmark datasets demonstrate that our model\noutperforms state-of-the-art methods, achieving a performance lift of\n0.23%-2.01% depending on the task and dataset.",
      "tldr_zh": "这篇论文提出了一种新型的自监督学习（SSL）框架，用于图表示学习，该框架融合了生成和对比学习方法，以提升节点分类、聚类和链接预测等下游任务的性能。框架的关键创新包括社区感知的节点级对比学习（生成更鲁棒的正负样本对）、图级对比学习（捕捉全局语义信息），以及综合增强策略（如特征掩码、节点扰动和边扰动）。在公开基准数据集上的实验表明，该模型比现有最先进方法提高了0.23%-2.01%的性能，展示了其在标签数据有限场景下的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.4, I2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11776v1",
      "published_date": "2025-05-17 01:02:22 UTC",
      "updated_date": "2025-05-17 01:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:34:56.485019"
    },
    {
      "arxiv_id": "2505.11774v1",
      "title": "HARDMath2: A Benchmark for Applied Mathematics Built by Students as Part of a Graduate Class",
      "title_zh": "HARDMath2：学生作为研究生课程一部分构建的应用数学基准",
      "authors": [
        "James V. Roggeveen",
        "Erik Y. Wang",
        "Will Flintoft",
        "Peter Donets",
        "Lucy S. Nathwani",
        "Nickholas Gutierrez",
        "David Ettel",
        "Anton Marius Graf",
        "Siddharth Dandavate",
        "Arjun Nageswaran",
        "Raglan Ward",
        "Ava Williamson",
        "Anne Mykland",
        "Kacper K. Migacz",
        "Yijun Wang",
        "Egemen Bostan",
        "Duy Thuc Nguyen",
        "Zhe He",
        "Marc L. Descoteaux",
        "Felix Yeung",
        "Shida Liu",
        "Jorge García Ponce",
        "Luke Zhu",
        "Yuyang Chen",
        "Ekaterina S. Ivshina",
        "Miguel Fernandez",
        "Minjae Kim",
        "Kennan Gumbs",
        "Matthew Scott Tan",
        "Russell Yang",
        "Mai Hoang",
        "David Brown",
        "Isabella A. Silveira",
        "Lavon Sykes",
        "Ahmed Roman",
        "William Fredenberg",
        "Yiming Chen",
        "Lucas Martin",
        "Yixing Tang",
        "Kelly Werker Smith",
        "Hongyu Liao",
        "Logan G. Wilson",
        "Alexander Dazhen Cai",
        "Andrea Elizabeth Biju",
        "Michael P. Brenner"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable progress in mathematical\nproblem-solving, but evaluation has largely focused on problems that have exact\nanalytical solutions or involve formal proofs, often overlooking\napproximation-based problems ubiquitous in applied science and engineering. To\nfill this gap, we build on prior work and present HARDMath2, a dataset of 211\noriginal problems covering the core topics in an introductory graduate applied\nmath class, including boundary-layer analysis, WKB methods, asymptotic\nsolutions of nonlinear partial differential equations, and the asymptotics of\noscillatory integrals. This dataset was designed and verified by the students\nand instructors of a core graduate applied mathematics course at Harvard. We\nbuild the dataset through a novel collaborative environment that challenges\nstudents to write and refine difficult problems consistent with the class\nsyllabus, peer-validate solutions, test different models, and automatically\ncheck LLM-generated solutions against their own answers and numerical ground\ntruths. Evaluation results show that leading frontier models still struggle\nwith many of the problems in the dataset, highlighting a gap in the\nmathematical reasoning skills of current LLMs. Importantly, students identified\nstrategies to create increasingly difficult problems by interacting with the\nmodels and exploiting common failure modes. This back-and-forth with the models\nnot only resulted in a richer and more challenging benchmark but also led to\nqualitative improvements in the students' understanding of the course material,\nwhich is increasingly important as we enter an age where state-of-the-art\nlanguage models can solve many challenging problems across a wide domain of\nfields.",
      "tldr_zh": "这篇论文介绍了 HARDMath2 数据集，一个由哈佛研究生课程学生和讲师构建的基准，包含 211 个原创问题，聚焦于应用数学中的近似问题，如 boundary-layer analysis、WKB methods、非线性偏微分方程的渐近解，以及振荡积分的渐近。数据集通过一种新型协作环境构建，学生参与编写、验证问题、测试不同 LLMs，并自动检查模型生成的解决方案与数值真实值。评估结果显示，领先的 LLMs 在许多问题上仍表现出色不足，突显了其数学推理技能的差距；同时，这种互动过程帮助学生创建更具挑战性的问题，并提升了对课程材料的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11774v1",
      "published_date": "2025-05-17 00:52:49 UTC",
      "updated_date": "2025-05-17 00:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:35:09.217774"
    },
    {
      "arxiv_id": "2505.11771v1",
      "title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Xu",
        "Ryumei Nakada",
        "Linjun Zhang",
        "Lexin Li"
      ],
      "abstract": "Transfer learning typically leverages representations learned from a source\ndomain to improve performance on a target task. A common approach is to extract\nfeatures from a pre-trained model and directly apply them for target\nprediction. However, this strategy is prone to negative transfer where the\nsource representation fails to align with the target distribution. In this\narticle, we propose Residual Feature Integration (REFINE), a simple yet\neffective method designed to mitigate negative transfer. Our approach combines\na fixed source-side representation with a trainable target-side encoder and\nfits a shallow neural network on the resulting joint representation, which\nadapts to the target domain while preserving transferable knowledge from the\nsource domain. Theoretically, we prove that REFINE is sufficient to prevent\nnegative transfer under mild conditions, and derive the generalization bound\ndemonstrating its theoretical benefit. Empirically, we show that REFINE\nconsistently enhances performance across diverse application and data\nmodalities including vision, text, and tabular data, and outperforms numerous\nalternative solutions. Our method is lightweight, architecture-agnostic, and\nrobust, making it a valuable addition to the existing transfer learning\ntoolbox.",
      "tldr_zh": "本文提出 Residual Feature Integration (REFINE) 方法，以解决转移学习（transfer learning）中 Negative Transfer 的问题，即源域表示与目标域分布不匹配导致的性能下降。REFINE 通过结合固定源域表示、可训练目标域编码器和浅层神经网络，适应目标域的同时保留可转移知识。理论上，该方法在温和条件下被证明足以防止 Negative Transfer，并提供了 Generalization Bound 以展示其优势。实验结果显示，REFINE 在视觉、文本和表格数据等多种模态上显著提升性能，且比其他方法更轻量级、架构无关和鲁棒。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11771v1",
      "published_date": "2025-05-17 00:36:59 UTC",
      "updated_date": "2025-05-17 00:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:35:20.613264"
    },
    {
      "arxiv_id": "2505.11770v1",
      "title": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors",
      "title_zh": "内部因果机制稳健预测语言模型分布外行为",
      "authors": [
        "Jing Huang",
        "Junyi Tao",
        "Thomas Icard",
        "Diyi Yang",
        "Christopher Potts"
      ],
      "abstract": "Interpretability research now offers a variety of techniques for identifying\nabstract internal mechanisms in neural networks. Can such techniques be used to\npredict how models will behave on out-of-distribution examples? In this work,\nwe provide a positive answer to this question. Through a diverse set of\nlanguage modeling tasks--including symbol manipulation, knowledge retrieval,\nand instruction following--we show that the most robust features for\ncorrectness prediction are those that play a distinctive causal role in the\nmodel's behavior. Specifically, we propose two methods that leverage causal\nmechanisms to predict the correctness of model outputs: counterfactual\nsimulation (checking whether key causal variables are realized) and value\nprobing (using the values of those variables to make predictions). Both achieve\nhigh AUC-ROC in distribution and outperform methods that rely on\ncausal-agnostic features in out-of-distribution settings, where predicting\nmodel behaviors is more crucial. Our work thus highlights a novel and\nsignificant application for internal causal analysis of language models.",
      "tldr_zh": "本文研究了神经网络内部因果机制是否能预测语言模型在out-of-distribution场景下的行为，并通过符号操作、知识检索和指令遵循等任务证明了其有效性。作者提出两种方法：counterfactual simulation（检查关键因果变量是否实现）和value probing（使用这些变量的值进行预测），这些方法依赖于模型行为中的独特因果特征。实验结果显示，这些方法在分布内和分布外均实现高AUC-ROC性能，并在out-of-distribution设置中优于非因果特征方法。该工作突出了内部因果分析在语言模型中的新应用前景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11770v1",
      "published_date": "2025-05-17 00:31:39 UTC",
      "updated_date": "2025-05-17 00:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:35:32.492278"
    },
    {
      "arxiv_id": "2505.11766v1",
      "title": "Redefining Neural Operators in $d+1$ Dimensions",
      "title_zh": "在 $d+1$ 维度中重新定义神经算子",
      "authors": [
        "Haoze Song",
        "Zhihao Li",
        "Xiaobo Zhang",
        "Zecheng Gan",
        "Zhilu Lai",
        "Wei Wang"
      ],
      "abstract": "Neural Operators have emerged as powerful tools for learning mappings between\nfunction spaces. Among them, the kernel integral operator has been widely\nvalidated on universally approximating various operators. Although recent\nadvancements following this definition have developed effective modules to\nbetter approximate the kernel function defined on the original domain (with $d$\ndimensions, $d=1, 2, 3...$), the unclarified evolving mechanism in the\nembedding spaces blocks our view to design neural operators that can fully\ncapture the target system evolution.\n  Drawing on recent breakthroughs in quantum simulation of partial differential\nequations (PDEs), we elucidate the linear evolution process in neural\noperators. Based on that, we redefine neural operators on a new $d+1$\ndimensional domain. Within this framework, we implement our proposed\nSchr\\\"odingerised Kernel Neural Operator (SKNO) aligning better with the $d+1$\ndimensional evolution. In experiments, our $d+1$ dimensional evolving linear\nblock performs far better than others. Also, we test SKNO's SOTA performance on\nvarious benchmark tests and also the zero-shot super-resolution task. In\naddition, we analyse the impact of different lifting and recovering operators\non the prediction within the redefined NO framework, reflecting the alignment\nbetween our model and the underlying $d+1$ dimensional evolution.",
      "tldr_zh": "该论文重新定义了Neural Operators，将其扩展到$d+1$维域，以更好地捕捉目标系统的演化过程。作者基于量子模拟PDEs的突破，阐明了Neural Operators中的线性演化机制，并提出Schrödingerised Kernel Neural Operator (SKNO)，通过$d+1$维框架提升核函数的近似精度。实验结果显示，SKNO在各种基准测试和零样本超分辨率任务中表现出SOTA性能，且分析了lifting和recovering operators对预测的影响，进一步验证了模型与$d+1$维演化的对齐。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11766v1",
      "published_date": "2025-05-17 00:15:00 UTC",
      "updated_date": "2025-05-17 00:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:35:44.623120"
    },
    {
      "arxiv_id": "2505.11765v2",
      "title": "OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Shijun Li",
        "Hilaf Hasson",
        "Joydeep Ghosh"
      ],
      "abstract": "Agents powered by advanced large language models (LLMs) have demonstrated\nimpressive capabilities across diverse complex applications. Recently,\nMulti-Agent Systems (MAS), wherein multiple agents collaborate and communicate\nwith each other, have exhibited enhanced capabilities in complex tasks, such as\nhigh-quality code generation and arithmetic reasoning. However, the development\nof such systems often relies on handcrafted methods, and the literature on\nsystematic design and optimization of LLM-based MAS remains limited.\n  In this work, we introduce OMAC, a general framework designed for holistic\noptimization of LLM-based MAS. Specifically, we identify five key optimization\ndimensions for MAS, encompassing both agent functionality and collaboration\nstructure. Building upon these dimensions, we first propose a general\nalgorithm, utilizing two actors termed the Semantic Initializer and the\nContrastive Comparator, to optimize any single dimension. Then, we present an\nalgorithm for joint optimization across multiple dimensions. Extensive\nexperiments demonstrate the superior performance of OMAC on code generation,\narithmetic reasoning, and general reasoning tasks against state-of-the-art\napproaches.",
      "tldr_zh": "本文提出 OMAC 框架，用于全面优化基于 LLM 的多代理系统（Multi-Agent Systems, MAS），以提升代理功能和协作结构等五个关键维度。框架包括一个通用算法，利用 Semantic Initializer 和 Contrastive Comparator 来优化单个维度，并提供多维度联合优化算法。实验结果表明，OMAC 在代码生成、算术推理和一般推理任务上，表现优于现有先进方法。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11765v2",
      "published_date": "2025-05-17 00:13:46 UTC",
      "updated_date": "2025-05-21 21:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:35:56.004550"
    },
    {
      "arxiv_id": "2505.11764v1",
      "title": "Towards Universal Semantics With Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Raymond Baartmans",
        "Matthew Raffel",
        "Rahul Vikram",
        "Aiden Deringer",
        "Lizhong Chen"
      ],
      "abstract": "The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a\nuniversal set of semantic primes: simple, primitive word-meanings that have\nbeen shown to exist in most, if not all, languages of the world. According to\nthis framework, any word, regardless of complexity, can be paraphrased using\nthese primes, revealing a clear and universally translatable meaning. These\nparaphrases, known as explications, can offer valuable applications for many\nnatural language processing (NLP) tasks, but producing them has traditionally\nbeen a slow, manual process. In this work, we present the first study of using\nlarge language models (LLMs) to generate NSM explications. We introduce\nautomatic evaluation methods, a tailored dataset for training and evaluation,\nand fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in\nproducing accurate, cross-translatable explications, marking a significant step\ntoward universal semantic representation with LLMs and opening up new\npossibilities for applications in semantic analysis, translation, and beyond.",
      "tldr_zh": "这篇论文探讨了使用 Large Language Models (LLMs) 生成 Natural Semantic Metalanguage (NSM) 的 explications，以实现基于通用语义原语的跨语言语义表示。研究者首次引入自动评估方法、定制数据集，并对模型进行微调，使其能够高效生成准确且可翻译的 explications。结果显示，他们的 1B 和 8B 模型在性能上超过了 GPT-4o，为自然语言处理 (NLP) 任务如语义分析和翻译打开了新应用前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11764v1",
      "published_date": "2025-05-17 00:11:58 UTC",
      "updated_date": "2025-05-17 00:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:36:09.073019"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 100,
  "processed_papers_count": 100,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T00:36:27.627362"
}