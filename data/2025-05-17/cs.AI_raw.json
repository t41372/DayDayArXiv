[
  {
    "arxiv_id": "2505.13522v1",
    "title": "A Heuristic Algorithm Based on Beam Search and Iterated Local Search for the Maritime Inventory Routing Problem",
    "authors": [
      "Nathalie Sanghikian",
      "Rafael Meirelles",
      "Rafael Martinelli",
      "Anand Subramanian"
    ],
    "abstract": "Maritime Inventory Routing Problem (MIRP) plays a crucial role in the\nintegration of global maritime commerce levels. However, there are still no\nwell-established methodologies capable of efficiently solving large MIRP\ninstances or their variants due to the high complexity of the problem. The\nadoption of exact methods, typically based on Mixed Integer Programming (MIP),\nfor daily operations is nearly impractical due to the CPU time required, as\nplanning must be executed multiple times while ensuring high-quality results\nwithin acceptable time limits. Non-MIP-based heuristics are less frequently\napplied due to the highly constrained nature of the problem, which makes even\nthe construction of an effective initial solution challenging. Papageorgiou et\nal. (2014) introduced a single-product MIRP as the foundation for MIRPLib,\naiming to provide a collection of publicly available benchmark instances.\nHowever, only a few studies that propose new methodologies have been published\nsince then. To encourage the use of MIRPLib and facilitate result comparisons,\nthis study presents a heuristic approach that does not rely on mathematical\noptimization techniques to solve a deterministic, finite-horizon,\nsingle-product MIRP. The proposed heuristic combines a variation of a Beam\nSearch algorithm with an Iterated Local Search procedure. Among the 72\ninstances tested, the developed methodology can improve the best-known solution\nfor ten instances within an acceptable CPU time.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13522v1",
    "published_date": "2025-05-17 22:40:36 UTC",
    "updated_date": "2025-05-17 22:40:36 UTC"
  },
  {
    "arxiv_id": "2505.12155v1",
    "title": "SoftPQ: Robust Instance Segmentation Evaluation via Soft Matching and Tunable Thresholds",
    "authors": [
      "Ranit Karmakar",
      "Simon F. Nørrelykke"
    ],
    "abstract": "Segmentation evaluation metrics traditionally rely on binary decision logic:\npredictions are either correct or incorrect, based on rigid IoU thresholds.\nDetection--based metrics such as F1 and mAP determine correctness at the object\nlevel using fixed overlap cutoffs, while overlap--based metrics like\nIntersection over Union (IoU) and Dice operate at the pixel level, often\noverlooking instance--level structure. Panoptic Quality (PQ) attempts to unify\ndetection and segmentation assessment, but it remains dependent on\nhard-threshold matching--treating predictions below the threshold as entirely\nincorrect. This binary framing obscures important distinctions between\nqualitatively different errors and fails to reward gradual model improvements.\nWe propose SoftPQ, a flexible and interpretable instance segmentation metric\nthat redefines evaluation as a graded continuum rather than a binary\nclassification. SoftPQ introduces tunable upper and lower IoU thresholds to\ndefine a partial matching region and applies a sublinear penalty function to\nambiguous or fragmented predictions. These extensions allow SoftPQ to exhibit\nsmoother score behavior, greater robustness to structural segmentation errors,\nand more informative feedback for model development and evaluation. Through\ncontrolled perturbation experiments, we show that SoftPQ captures meaningful\ndifferences in segmentation quality that existing metrics overlook, making it a\npractical and principled alternative for both benchmarking and iterative model\nrefinement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12155v1",
    "published_date": "2025-05-17 22:08:33 UTC",
    "updated_date": "2025-05-17 22:08:33 UTC"
  },
  {
    "arxiv_id": "2505.12151v1",
    "title": "Reasoning Large Language Model Errors Arise from Hallucinating Critical Problem Features",
    "authors": [
      "Alex Heyman",
      "Joel Zylberberg"
    ],
    "abstract": "Large language models have recently made great strides in reasoning task\nperformance through chain-of-thought (CoT) strategies trained via reinforcement\nlearning; however, these \"reasoning large language models\" (RLLMs) remain\nimperfect reasoners, and understanding the frequencies and causes of their\nfailure modes is important for both users and developers. We test o1-mini,\no3-mini, DeepSeek-R1, Claude 3.7 Sonnet, Gemini 2.5 Pro Preview, and Grok 3\nMini Beta on graph coloring as a variable-complexity constraint-satisfaction\nlogic problem, and find evidence from both error rate comparisons and\nCoT/explanation text analysis that RLLMs are prone to hallucinate edges not\nspecified in the prompt's description of the graph. This phenomenon persists\nacross multiple problem complexity levels and semantic frames, and it appears\nto account for a significant fraction of the incorrect answers from every\ntested model, and the vast majority of them for some models. Our results\nindicate that RLLMs may possess broader issues with misrepresentation of\nproblem specifics, and we offer suggestions for design choices to mitigate this\nweakness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages (9 excluding references and appendices); 7 figures (6\n  excluding appendices)",
    "pdf_url": "http://arxiv.org/pdf/2505.12151v1",
    "published_date": "2025-05-17 21:55:12 UTC",
    "updated_date": "2025-05-17 21:55:12 UTC"
  },
  {
    "arxiv_id": "2505.12143v1",
    "title": "Structured Representation",
    "authors": [
      "Arun Kumar",
      "Paul Schrater"
    ],
    "abstract": "Invariant representations are core to representation learning, yet a central\nchallenge remains: uncovering invariants that are stable and transferable\nwithout suppressing task-relevant signals. This raises fundamental questions,\nrequiring further inquiry, about the appropriate level of abstraction at which\nsuch invariants should be defined, and which aspects of a system they should\ncharacterize. Interpretation of the environment relies on abstract knowledge\nstructures to make sense of the current state, which leads to interactions,\nessential drivers of learning and knowledge acquisition. We posit that\ninterpretation operates at the level of higher-order relational knowledge;\nhence, invariant structures must be where knowledge resides, specifically, as\npartitions defined by the closure of relational paths within an abstract\nknowledge space. These partitions serve as the core invariant representations,\nforming the structural substrate where knowledge is stored and learning occurs.\nOn the other hand, inter-partition connectors enable the deployment of these\nknowledge partitions encoding task-relevant transitions. Thus, invariant\npartitions provide the foundational primitives of structured representation. We\nformalize the computational foundations for structured representation of the\ninvariant partitions based on closed semiring, a relational algebraic\nstructure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12143v1",
    "published_date": "2025-05-17 21:26:05 UTC",
    "updated_date": "2025-05-17 21:26:05 UTC"
  },
  {
    "arxiv_id": "2505.12136v1",
    "title": "Lightweight Spatio-Temporal Attention Network with Graph Embedding and Rotational Position Encoding for Traffic Forecasting",
    "authors": [
      "Xiao Wang",
      "Shun-Ren Yang"
    ],
    "abstract": "Traffic forecasting is a key task in the field of Intelligent Transportation\nSystems. Recent research on traffic forecasting has mainly focused on combining\ngraph neural networks (GNNs) with other models. However, GNNs only consider\nshort-range spatial information. In this study, we present a novel model termed\nLSTAN-GERPE (Lightweight Spatio-Temporal Attention Network with Graph Embedding\nand Rotational Position Encoding). This model leverages both Temporal and\nSpatial Attention mechanisms to effectively capture long-range traffic\ndynamics. Additionally, the optimal frequency for rotational position encoding\nis determined through a grid search approach in both the spatial and temporal\nattention mechanisms. This systematic optimization enables the model to\neffectively capture complex traffic patterns. The model also enhances feature\nrepresentation by incorporating geographical location maps into the\nspatio-temporal embeddings. Without extensive feature engineering, the proposed\nmethod in this paper achieves advanced accuracy on the real-world traffic\nforecasting datasets PeMS04 and PeMS08.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12136v1",
    "published_date": "2025-05-17 20:36:20 UTC",
    "updated_date": "2025-05-17 20:36:20 UTC"
  },
  {
    "arxiv_id": "2505.12135v1",
    "title": "LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs",
    "authors": [
      "Omar Choukrani",
      "Idriss Malek",
      "Daniil Orel",
      "Zhuohan Xie",
      "Zangir Iklassov",
      "Martin Takáč",
      "Salem Lahlou"
    ],
    "abstract": "Assessing the capacity of Large Language Models (LLMs) to plan and reason\nwithin the constraints of interactive environments is crucial for developing\ncapable AI agents. We introduce $\\textbf{LLM-BabyBench}$, a new benchmark suite\ndesigned specifically for this purpose. Built upon a textual adaptation of the\nprocedurally generated BabyAI grid world, this suite evaluates LLMs on three\nfundamental aspects of grounded intelligence: (1) predicting the consequences\nof actions on the environment state ($\\textbf{Predict}$ task), (2) generating\nsequences of low-level actions to achieve specified objectives ($\\textbf{Plan}$\ntask), and (3) decomposing high-level instructions into coherent subgoal\nsequences ($\\textbf{Decompose}$ task). We detail the methodology for generating\nthe three corresponding datasets ($\\texttt{LLM-BabyBench-Predict}$,\n$\\texttt{-Plan}$, $\\texttt{-Decompose}$) by extracting structured information\nfrom an expert agent operating within the text-based environment. Furthermore,\nwe provide a standardized evaluation harness and metrics, including environment\ninteraction for validating generated plans, to facilitate reproducible\nassessment of diverse LLMs. Initial baseline results highlight the challenges\nposed by these grounded reasoning tasks. The benchmark suite, datasets, data\ngeneration code, and evaluation code are made publicly available\n($\\href{https://github.com/choukrani/llm-babybench}{\\text{GitHub}}$,\n$\\href{https://huggingface.co/datasets/salem-mbzuai/LLM-BabyBench}{\\text{HuggingFace}}$).",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12135v1",
    "published_date": "2025-05-17 20:23:17 UTC",
    "updated_date": "2025-05-17 20:23:17 UTC"
  },
  {
    "arxiv_id": "2505.12130v1",
    "title": "Keypoints as Dynamic Centroids for Unified Human Pose and Segmentation",
    "authors": [
      "Niaz Ahmad",
      "Jawad Khan",
      "Kang G. Shin",
      "Youngmoon Lee",
      "Guanghui Wang"
    ],
    "abstract": "The dynamic movement of the human body presents a fundamental challenge for\nhuman pose estimation and body segmentation. State-of-the-art approaches\nprimarily rely on combining keypoint heatmaps with segmentation masks but often\nstruggle in scenarios involving overlapping joints or rapidly changing poses\nduring instance-level segmentation. To address these limitations, we propose\nKeypoints as Dynamic Centroid (KDC), a new centroid-based representation for\nunified human pose estimation and instance-level segmentation. KDC adopts a\nbottom-up paradigm to generate keypoint heatmaps for both easily\ndistinguishable and complex keypoints and improves keypoint detection and\nconfidence scores by introducing KeyCentroids using a keypoint disk. It\nleverages high-confidence keypoints as dynamic centroids in the embedding space\nto generate MaskCentroids, allowing for swift clustering of pixels to specific\nhuman instances during rapid body movements in live environments. Our\nexperimental evaluations on the CrowdPose, OCHuman, and COCO benchmarks\ndemonstrate KDC's effectiveness and generalizability in challenging scenarios\nin terms of both accuracy and runtime performance. The implementation is\navailable at: https://sites.google.com/view/niazahmad/projects/kdc.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12130v1",
    "published_date": "2025-05-17 20:05:34 UTC",
    "updated_date": "2025-05-17 20:05:34 UTC"
  },
  {
    "arxiv_id": "2505.12109v1",
    "title": "SAINT: Attention-Based Modeling of Sub-Action Dependencies in Multi-Action Policies",
    "authors": [
      "Matthew Landers",
      "Taylor W. Killian",
      "Thomas Hartvigsen",
      "Afsaneh Doryab"
    ],
    "abstract": "The combinatorial structure of many real-world action spaces leads to\nexponential growth in the number of possible actions, limiting the\neffectiveness of conventional reinforcement learning algorithms. Recent\napproaches for combinatorial action spaces impose factorized or sequential\nstructures over sub-actions, failing to capture complex joint behavior. We\nintroduce the Sub-Action Interaction Network using Transformers (SAINT), a\nnovel policy architecture that represents multi-component actions as unordered\nsets and models their dependencies via self-attention conditioned on the global\nstate. SAINT is permutation-invariant, sample-efficient, and compatible with\nstandard policy optimization algorithms. In 15 distinct combinatorial\nenvironments across three task domains, including environments with nearly 17\nmillion joint actions, SAINT consistently outperforms strong baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12109v1",
    "published_date": "2025-05-17 18:34:31 UTC",
    "updated_date": "2025-05-17 18:34:31 UTC"
  },
  {
    "arxiv_id": "2505.12108v1",
    "title": "EarthSynth: Generating Informative Earth Observation with Diffusion Models",
    "authors": [
      "Jiancheng Pan",
      "Shiye Lei",
      "Yuqian Fu",
      "Jiahao Li",
      "Yanxing Liu",
      "Yuze Sun",
      "Xiao He",
      "Long Peng",
      "Xiaomeng Huang",
      "Bo Zhao"
    ],
    "abstract": "Remote sensing image (RSI) interpretation typically faces challenges due to\nthe scarcity of labeled data, which limits the performance of RSI\ninterpretation tasks. To tackle this challenge, we propose EarthSynth, a\ndiffusion-based generative foundation model that enables synthesizing\nmulti-category, cross-satellite labeled Earth observation for downstream RSI\ninterpretation tasks. To the best of our knowledge, EarthSynth is the first to\nexplore multi-task generation for remote sensing. EarthSynth, trained on the\nEarthSynth-180K dataset, employs the Counterfactual Composition training\nstrategy to improve training data diversity and enhance category control.\nFurthermore, a rule-based method of R-Filter is proposed to filter more\ninformative synthetic data for downstream tasks. We evaluate our EarthSynth on\nscene classification, object detection, and semantic segmentation in open-world\nscenarios, offering a practical solution for advancing RSI interpretation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12108v1",
    "published_date": "2025-05-17 18:27:15 UTC",
    "updated_date": "2025-05-17 18:27:15 UTC"
  },
  {
    "arxiv_id": "2505.12107v1",
    "title": "Learning Probabilistic Temporal Logic Specifications for Stochastic Systems",
    "authors": [
      "Rajarshi Roy",
      "Yash Pote",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "abstract": "There has been substantial progress in the inference of formal behavioural\nspecifications from sample trajectories, for example, using Linear Temporal\nLogic (LTL). However, these techniques cannot handle specifications that\ncorrectly characterise systems with stochastic behaviour, which occur commonly\nin reinforcement learning and formal verification. We consider the passive\nlearning problem of inferring a Boolean combination of probabilistic LTL (PLTL)\nformulas from a set of Markov chains, classified as either positive or\nnegative. We propose a novel learning algorithm that infers concise PLTL\nspecifications, leveraging grammar-based enumeration, search heuristics,\nprobabilistic model checking and Boolean set-cover procedures. We demonstrate\nthe effectiveness of our algorithm in two use cases: learning from policies\ninduced by RL algorithms and learning from variants of a probabilistic model.\nIn both cases, our method automatically and efficiently extracts PLTL\nspecifications that succinctly characterise the temporal differences between\nthe policies or model variants.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.LO",
    "comment": "Full version of the paper that appears in IJCAI'25",
    "pdf_url": "http://arxiv.org/pdf/2505.12107v1",
    "published_date": "2025-05-17 18:19:35 UTC",
    "updated_date": "2025-05-17 18:19:35 UTC"
  },
  {
    "arxiv_id": "2505.12100v1",
    "title": "Improving Fairness in LLMs Through Testing-Time Adversaries",
    "authors": [
      "Isabela Pereira Gregio",
      "Ian Pons",
      "Anna Helena Reali Costa",
      "Artur Jordão"
    ],
    "abstract": "Large Language Models (LLMs) push the bound-aries in natural language\nprocessing and generative AI, driving progress across various aspects of modern\nsociety. Unfortunately, the pervasive issue of bias in LLMs responses (i.e.,\npredictions) poses a significant and open challenge, hindering their\napplication in tasks involving ethical sensitivity and responsible\ndecision-making. In this work, we propose a straightforward, user-friendly and\npractical method to mitigate such biases, enhancing the reliability and\ntrustworthiness of LLMs. Our method creates multiple variations of a given\nsentence by modifying specific attributes and evaluates the corresponding\nprediction behavior compared to the original, unaltered, prediction/sentence.\nThe idea behind this process is that critical ethical predictions often exhibit\nnotable inconsistencies, indicating the presence of bias. Unlike previous\napproaches, our method relies solely on forward passes (i.e., testing-time\nadversaries), eliminating the need for training, fine-tuning, or prior\nknowledge of the training data distribution. Through extensive experiments on\nthe popular Llama family, we demonstrate the effectiveness of our method in\nimproving various fairness metrics, focusing on the reduction of disparities in\nhow the model treats individuals from different racial groups. Specifically,\nusing standard metrics, we improve the fairness in Llama3 in up to 27\npercentage points. Overall, our approach significantly enhances fairness,\nequity, and reliability in LLM-generated results without parameter tuning or\ntraining data modifications, confirming its effectiveness in practical\nscenarios. We believe our work establishes an important step toward enabling\nthe use of LLMs in tasks that require ethical considerations and responsible\ndecision-making.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12100v1",
    "published_date": "2025-05-17 17:56:53 UTC",
    "updated_date": "2025-05-17 17:56:53 UTC"
  },
  {
    "arxiv_id": "2505.12096v1",
    "title": "When the Left Foot Leads to the Right Path: Bridging Initial Prejudice and Trainability",
    "authors": [
      "Alberto Bassi",
      "Carlo Albert",
      "Aurelien Lucchi",
      "Marco Baity-Jesi",
      "Emanuele Francazi"
    ],
    "abstract": "Understanding the statistical properties of deep neural networks (DNNs) at\ninitialization is crucial for elucidating both their trainability and the\nintrinsic architectural biases they encode prior to data exposure. Mean-field\n(MF) analyses have demonstrated that the parameter distribution in randomly\ninitialized networks dictates whether gradients vanish or explode.\nConcurrently, untrained DNNs were found to exhibit an initial-guessing bias\n(IGB), in which large regions of the input space are assigned to a single\nclass. In this work, we derive a theoretical proof establishing the\ncorrespondence between IGB and previous MF theories, thereby connecting a\nnetwork prejudice toward specific classes with the conditions for fast and\naccurate learning. This connection yields the counter-intuitive conclusion: the\ninitialization that optimizes trainability is necessarily biased, rather than\nneutral. Furthermore, we extend the MF/IGB framework to multi-node activation\nfunctions, offering practical guidelines for designing initialization schemes\nthat ensure stable optimization in architectures employing max- and\naverage-pooling layers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12096v1",
    "published_date": "2025-05-17 17:31:56 UTC",
    "updated_date": "2025-05-17 17:31:56 UTC"
  },
  {
    "arxiv_id": "2505.12094v1",
    "title": "Attribution Projection Calculus: A Novel Framework for Causal Inference in Bayesian Networks",
    "authors": [
      "M Ruhul Amin"
    ],
    "abstract": "This paper introduces Attribution Projection Calculus (AP-Calculus), a novel\nmathematical framework for determining causal relationships in structured\nBayesian networks. We investigate a specific network architecture with source\nnodes connected to destination nodes through intermediate nodes, where each\ninput maps to a single label with maximum marginal probability. We prove that\nfor each label, exactly one intermediate node acts as a deconfounder while\nothers serve as confounders, enabling optimal attribution of features to their\ncorresponding labels. The framework formalizes the dual nature of intermediate\nnodes as both confounders and deconfounders depending on the context, and\nestablishes separation functions that maximize distinctions between\nintermediate representations. We demonstrate that the proposed network\narchitecture is optimal for causal inference compared to alternative\nstructures, including those based on Pearl's causal framework. AP-Calculus\nprovides a comprehensive mathematical foundation for analyzing feature-label\nattributions, managing spurious correlations, quantifying information gain,\nensuring fairness, and evaluating uncertainty in prediction models, including\nlarge language models. Theoretical verification shows that AP-Calculus not only\nextends but can also subsume traditional do-calculus for many practical\napplications, offering a more direct approach to causal inference in supervised\nlearning contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML",
      "60E10, 62R07, 68Q32, 68T07, 94A16",
      "F.2.2; G.3; I.1.2; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "*AI was used to improve Text and collecting Citations",
    "pdf_url": "http://arxiv.org/pdf/2505.12094v1",
    "published_date": "2025-05-17 17:29:13 UTC",
    "updated_date": "2025-05-17 17:29:13 UTC"
  },
  {
    "arxiv_id": "2505.12090v1",
    "title": "Personalized Author Obfuscation with Large Language Models",
    "authors": [
      "Mohammad Shokri",
      "Sarah Ita Levitan",
      "Rivka Levitan"
    ],
    "abstract": "In this paper, we investigate the efficacy of large language models (LLMs) in\nobfuscating authorship by paraphrasing and altering writing styles. Rather than\nadopting a holistic approach that evaluates performance across the entire\ndataset, we focus on user-wise performance to analyze how obfuscation\neffectiveness varies across individual authors. While LLMs are generally\neffective, we observe a bimodal distribution of efficacy, with performance\nvarying significantly across users. To address this, we propose a personalized\nprompting method that outperforms standard prompting techniques and partially\nmitigates the bimodality issue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12090v1",
    "published_date": "2025-05-17 17:10:25 UTC",
    "updated_date": "2025-05-17 17:10:25 UTC"
  },
  {
    "arxiv_id": "2505.12089v1",
    "title": "NTIRE 2025 Challenge on Efficient Burst HDR and Restoration: Datasets, Methods, and Results",
    "authors": [
      "Sangmin Lee",
      "Eunpil Park",
      "Angel Canelo",
      "Hyunhee Park",
      "Youngjo Kim",
      "Hyung-Ju Chun",
      "Xin Jin",
      "Chongyi Li",
      "Chun-Le Guo",
      "Radu Timofte",
      "Qi Wu",
      "Tianheng Qiu",
      "Yuchun Dong",
      "Shenglin Ding",
      "Guanghua Pan",
      "Weiyu Zhou",
      "Tao Hu",
      "Yixu Feng",
      "Duwei Dai",
      "Yu Cao",
      "Peng Wu",
      "Wei Dong",
      "Yanning Zhang",
      "Qingsen Yan",
      "Simon J. Larsen",
      "Ruixuan Jiang",
      "Senyan Xu",
      "Xingbo Wang",
      "Xin Lu",
      "Marcos V. Conde",
      "Javier Abad-Hernandez",
      "Alvaro Garcıa-Lara",
      "Daniel Feijoo",
      "Alvaro Garcıa",
      "Zeyu Xiao",
      "Zhuoyuan Li"
    ],
    "abstract": "This paper reviews the NTIRE 2025 Efficient Burst HDR and Restoration\nChallenge, which aims to advance efficient multi-frame high dynamic range (HDR)\nand restoration techniques. The challenge is based on a novel RAW multi-frame\nfusion dataset, comprising nine noisy and misaligned RAW frames with various\nexposure levels per scene. Participants were tasked with developing solutions\ncapable of effectively fusing these frames while adhering to strict efficiency\nconstraints: fewer than 30 million model parameters and a computational budget\nunder 4.0 trillion FLOPs. A total of 217 participants registered, with six\nteams finally submitting valid solutions. The top-performing approach achieved\na PSNR of 43.22 dB, showcasing the potential of novel methods in this domain.\nThis paper provides a comprehensive overview of the challenge, compares the\nproposed solutions, and serves as a valuable reference for researchers and\npractitioners in efficient burst HDR and restoration.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12089v1",
    "published_date": "2025-05-17 17:10:22 UTC",
    "updated_date": "2025-05-17 17:10:22 UTC"
  },
  {
    "arxiv_id": "2505.12079v1",
    "title": "SepPrune: Structured Pruning for Efficient Deep Speech Separation",
    "authors": [
      "Yuqi Li",
      "Kai Li",
      "Xin Yin",
      "Zhifei Yang",
      "Junhao Dong",
      "Zeyu Dong",
      "Chuanguang Yang",
      "Yingli Tian",
      "Yao Lu"
    ],
    "abstract": "Although deep learning has substantially advanced speech separation in recent\nyears, most existing studies continue to prioritize separation quality while\noverlooking computational efficiency, an essential factor for low-latency\nspeech processing in real-time applications. In this paper, we propose\nSepPrune, the first structured pruning framework specifically designed to\ncompress deep speech separation models and reduce their computational cost.\nSepPrune begins by analyzing the computational structure of a given model to\nidentify layers with the highest computational burden. It then introduces a\ndifferentiable masking strategy to enable gradient-driven channel selection.\nBased on the learned masks, SepPrune prunes redundant channels and fine-tunes\nthe remaining parameters to recover performance. Extensive experiments\ndemonstrate that this learnable pruning paradigm yields substantial advantages\nfor channel pruning in speech separation models, outperforming existing\nmethods. Notably, a model pruned with SepPrune can recover 85% of the\nperformance of a pre-trained model (trained over hundreds of epochs) with only\none epoch of fine-tuning, and achieves convergence 36$\\times$ faster than\ntraining from scratch. Code is available at\nhttps://github.com/itsnotacie/SepPrune.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12079v1",
    "published_date": "2025-05-17 16:44:38 UTC",
    "updated_date": "2025-05-17 16:44:38 UTC"
  },
  {
    "arxiv_id": "2505.12069v1",
    "title": "MT-CYP-Net: Multi-Task Network for Pixel-Level Crop Yield Prediction Under Very Few Samples",
    "authors": [
      "Shenzhou Liu",
      "Di Wang",
      "Haonan Guo",
      "Chengxi Han",
      "Wenzhi Zeng"
    ],
    "abstract": "Accurate and fine-grained crop yield prediction plays a crucial role in\nadvancing global agriculture. However, the accuracy of pixel-level yield\nestimation based on satellite remote sensing data has been constrained by the\nscarcity of ground truth data. To address this challenge, we propose a novel\napproach called the Multi-Task Crop Yield Prediction Network (MT-CYP-Net). This\nframework introduces an effective multi-task feature-sharing strategy, where\nfeatures extracted from a shared backbone network are simultaneously utilized\nby both crop yield prediction decoders and crop classification decoders with\nthe ability to fuse information between them. This design allows MT-CYP-Net to\nbe trained with extremely sparse crop yield point labels and crop type labels,\nwhile still generating detailed pixel-level crop yield maps. Concretely, we\ncollected 1,859 yield point labels along with corresponding crop type labels\nand satellite images from eight farms in Heilongjiang Province, China, in 2023,\ncovering soybean, maize, and rice crops, and constructed a sparse crop yield\nlabel dataset. MT-CYP-Net is compared with three classical machine learning and\ndeep learning benchmark methods in this dataset. Experimental results not only\nindicate the superiority of MT-CYP-Net compared to previous methods on multiple\ntypes of crops but also demonstrate the potential of deep networks on precise\npixel-level crop yield prediction, especially with limited data labels.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12069v1",
    "published_date": "2025-05-17 16:20:44 UTC",
    "updated_date": "2025-05-17 16:20:44 UTC"
  },
  {
    "arxiv_id": "2505.12065v1",
    "title": "Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents",
    "authors": [
      "Tiannuo Yang",
      "Zebin Yao",
      "Bowen Jin",
      "Lixiao Cui",
      "Yusen Li",
      "Gang Wang",
      "Xiaoguang Liu"
    ],
    "abstract": "Large Language Model (LLM)-based search agents have shown remarkable\ncapabilities in solving complex tasks by dynamically decomposing problems and\naddressing them through interleaved reasoning and retrieval. However, this\ninterleaved paradigm introduces substantial efficiency bottlenecks. First, we\nobserve that both highly accurate and overly approximate retrieval methods\ndegrade system efficiency: exact search incurs significant retrieval overhead,\nwhile coarse retrieval requires additional reasoning steps during generation.\nSecond, we identify inefficiencies in system design, including improper\nscheduling and frequent retrieval stalls, which lead to cascading latency --\nwhere even minor delays in retrieval amplify end-to-end inference time. To\naddress these challenges, we introduce SearchAgent-X, a high-efficiency\ninference framework for LLM-based search agents. SearchAgent-X leverages\nhigh-recall approximate retrieval and incorporates two key techniques:\npriority-aware scheduling and non-stall retrieval. Extensive experiments\ndemonstrate that SearchAgent-X consistently outperforms state-of-the-art\nsystems such as vLLM and HNSW-based retrieval across diverse tasks, achieving\nup to 3.4$\\times$ higher throughput and 5$\\times$ lower latency, without\ncompromising generation quality. SearchAgent-X is available at\nhttps://github.com/tiannuo-yang/SearchAgent-X.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12065v1",
    "published_date": "2025-05-17 16:07:01 UTC",
    "updated_date": "2025-05-17 16:07:01 UTC"
  },
  {
    "arxiv_id": "2505.15840v1",
    "title": "TDFormer: A Top-Down Attention-Controlled Spiking Transformer",
    "authors": [
      "Zizheng Zhu",
      "Yingchao Yu",
      "Zeqi Zheng",
      "Zhaofei Yu",
      "Yaochu Jin"
    ],
    "abstract": "Traditional spiking neural networks (SNNs) can be viewed as a combination of\nmultiple subnetworks with each running for one time step, where the parameters\nare shared, and the membrane potential serves as the only information link\nbetween them. However, the implicit nature of the membrane potential limits its\nability to effectively represent temporal information. As a result, each time\nstep cannot fully leverage information from previous time steps, seriously\nlimiting the model's performance. Inspired by the top-down mechanism in the\nbrain, we introduce TDFormer, a novel model with a top-down feedback structure\nthat functions hierarchically and leverages high-order representations from\nearlier time steps to modulate the processing of low-order information at later\nstages. The feedback structure plays a role from two perspectives: 1) During\nforward propagation, our model increases the mutual information across time\nsteps, indicating that richer temporal information is being transmitted and\nintegrated in different time steps. 2) During backward propagation, we\ntheoretically prove that the feedback structure alleviates the problem of\nvanishing gradients along the time dimension. We find that these mechanisms\ntogether significantly and consistently improve the model performance on\nmultiple datasets. In particular, our model achieves state-of-the-art\nperformance on ImageNet with an accuracy of 86.83%.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.15840v1",
    "published_date": "2025-05-17 15:55:32 UTC",
    "updated_date": "2025-05-17 15:55:32 UTC"
  },
  {
    "arxiv_id": "2505.12058v1",
    "title": "Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation",
    "authors": [
      "Vincent Koc"
    ],
    "abstract": "Tiny QA Benchmark++ (TQB++) presents an ultra-lightweight, multilingual\nsmoke-test suite designed to give large-language-model (LLM) pipelines a\nunit-test style safety net dataset that runs in seconds with minimal cost. Born\nout of the tight feedback-loop demands building the Comet Opik\nprompt-optimization SDK, where waiting on heavyweight benchmarks breaks\ndeveloper flow. TQB++ couples a 52-item English gold set (less than 20 kB) with\na tiny synthetic-data generator pypi package built on provider-agnostic\nLiteLLM. The generator lets practitioners mint their own tiny packs in any\nlanguage, domain, or difficulty, while ten ready-made packs already cover\nArabic, Chinese, French, German, Japanese, Korean, Portuguese, Russian,\nSpanish, and Turkish. Every dataset ships with Croissant metadata and\nplug-and-play files for OpenAI-Evals, LangChain, and standard CI tools, so\nteams can drop deterministic micro-benchmarks directly into pull-request gates,\nprompt-engineering loops, and production dashboards without touching GPU\nbudgets. A complete TQB++ run adds only a few seconds to pipeline latency yet\nreliably flags prompt-template errors, tokenizer drift, and fine-tuning\nside-effects long before full-scale suites like MMLU or BIG-Bench would finish\nconfiguring. The entire framework is released to accelerate continuous,\nresource-efficient quality assurance across the generative-AI ecosystem.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.6; H.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 7 figures, 3 tables. Includes expanded appendix & full\n  score matrices. Dataset & code: HF Hub + GitHub + Pypi links in abstract.\n  Core data and code Apache-2.0; synthetic packs eval-only",
    "pdf_url": "http://arxiv.org/pdf/2505.12058v1",
    "published_date": "2025-05-17 15:40:03 UTC",
    "updated_date": "2025-05-17 15:40:03 UTC"
  },
  {
    "arxiv_id": "2505.12057v1",
    "title": "CorBenchX: Large-Scale Chest X-Ray Error Dataset and Vision-Language Model Benchmark for Report Error Correction",
    "authors": [
      "Jing Zou",
      "Qingqiu Li",
      "Chenyu Lian",
      "Lihao Liu",
      "Xiaohan Yan",
      "Shujun Wang",
      "Jing Qin"
    ],
    "abstract": "AI-driven models have shown great promise in detecting errors in radiology\nreports, yet the field lacks a unified benchmark for rigorous evaluation of\nerror detection and further correction. To address this gap, we introduce\nCorBenchX, a comprehensive suite for automated error detection and correction\nin chest X-ray reports, designed to advance AI-assisted quality control in\nclinical practice. We first synthesize a large-scale dataset of 26,326 chest\nX-ray error reports by injecting clinically common errors via prompting\nDeepSeek-R1, with each corrupted report paired with its original text, error\ntype, and human-readable description. Leveraging this dataset, we benchmark\nboth open- and closed-source vision-language models,(e.g., InternVL, Qwen-VL,\nGPT-4o, o4-mini, and Claude-3.7) for error detection and correction under\nzero-shot prompting. Among these models, o4-mini achieves the best performance,\nwith 50.6 % detection accuracy and correction scores of BLEU 0.853, ROUGE\n0.924, BERTScore 0.981, SembScore 0.865, and CheXbertF1 0.954, remaining below\nclinical-level accuracy, highlighting the challenge of precise report\ncorrection. To advance the state of the art, we propose a multi-step\nreinforcement learning (MSRL) framework that optimizes a multi-objective reward\ncombining format compliance, error-type accuracy, and BLEU similarity. We apply\nMSRL to QwenVL2.5-7B, the top open-source model in our benchmark, achieving an\nimprovement of 38.3% in single-error detection precision and 5.2% in\nsingle-error correction over the zero-shot baseline.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12057v1",
    "published_date": "2025-05-17 15:39:39 UTC",
    "updated_date": "2025-05-17 15:39:39 UTC"
  },
  {
    "arxiv_id": "2505.12053v1",
    "title": "VFRTok: Variable Frame Rates Video Tokenizer with Duration-Proportional Information Assumption",
    "authors": [
      "Tianxiong Zhong",
      "Xingye Tian",
      "Boyuan Jiang",
      "Xuebo Wang",
      "Xin Tao",
      "Pengfei Wan",
      "Zhiwei Zhang"
    ],
    "abstract": "Modern video generation frameworks based on Latent Diffusion Models suffer\nfrom inefficiencies in tokenization due to the Frame-Proportional Information\nAssumption. Existing tokenizers provide fixed temporal compression rates,\ncausing the computational cost of the diffusion model to scale linearly with\nthe frame rate. The paper proposes the Duration-Proportional Information\nAssumption: the upper bound on the information capacity of a video is\nproportional to the duration rather than the number of frames. Based on this\ninsight, the paper introduces VFRTok, a Transformer-based video tokenizer, that\nenables variable frame rate encoding and decoding through asymmetric frame rate\ntraining between the encoder and decoder. Furthermore, the paper proposes\nPartial Rotary Position Embeddings (RoPE) to decouple position and content\nmodeling, which groups correlated patches into unified tokens. The Partial RoPE\neffectively improves content-awareness, enhancing the video generation\ncapability. Benefiting from the compact and continuous spatio-temporal\nrepresentation, VFRTok achieves competitive reconstruction quality and\nstate-of-the-art generation fidelity while using only 1/8 tokens compared to\nexisting tokenizers.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.12053v1",
    "published_date": "2025-05-17 15:32:54 UTC",
    "updated_date": "2025-05-17 15:32:54 UTC"
  },
  {
    "arxiv_id": "2505.12050v1",
    "title": "ABoN: Adaptive Best-of-N Alignment",
    "authors": [
      "Vinod Raman",
      "Hilal Asi",
      "Satyen Kale"
    ],
    "abstract": "Recent advances in test-time alignment methods, such as Best-of-N sampling,\noffer a simple and effective way to steer language models (LMs) toward\npreferred behaviors using reward models (RM). However, these approaches can be\ncomputationally expensive, especially when applied uniformly across prompts\nwithout accounting for differences in alignment difficulty. In this work, we\npropose a prompt-adaptive strategy for Best-of-N alignment that allocates\ninference-time compute more efficiently. Motivated by latency concerns, we\ndevelop a two-stage algorithm: an initial exploratory phase estimates the\nreward distribution for each prompt using a small exploration budget, and a\nsecond stage adaptively allocates the remaining budget using these estimates.\nOur method is simple, practical, and compatible with any LM/RM combination.\nEmpirical results on the AlpacaEval dataset for 12 LM/RM pairs and 50 different\nbatches of prompts show that our adaptive strategy consistently outperforms the\nuniform allocation with the same inference budget. Moreover, our experiments\nshow that our adaptive strategy remains competitive against uniform allocations\nwith 20% larger inference budgets and even improves in performance as the batch\nsize grows.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12050v1",
    "published_date": "2025-05-17 15:24:48 UTC",
    "updated_date": "2025-05-17 15:24:48 UTC"
  },
  {
    "arxiv_id": "2505.12051v1",
    "title": "Enhanced Multimodal Hate Video Detection via Channel-wise and Modality-wise Fusion",
    "authors": [
      "Yinghui Zhang",
      "Tailin Chen",
      "Yuchen Zhang",
      "Zeyu Fu"
    ],
    "abstract": "The rapid rise of video content on platforms such as TikTok and YouTube has\ntransformed information dissemination, but it has also facilitated the spread\nof harmful content, particularly hate videos. Despite significant efforts to\ncombat hate speech, detecting these videos remains challenging due to their\noften implicit nature. Current detection methods primarily rely on unimodal\napproaches, which inadequately capture the complementary features across\ndifferent modalities. While multimodal techniques offer a broader perspective,\nmany fail to effectively integrate temporal dynamics and modality-wise\ninteractions essential for identifying nuanced hate content. In this paper, we\npresent CMFusion, an enhanced multimodal hate video detection model utilizing a\nnovel Channel-wise and Modality-wise Fusion Mechanism. CMFusion first extracts\nfeatures from text, audio, and video modalities using pre-trained models and\nthen incorporates a temporal cross-attention mechanism to capture dependencies\nbetween video and audio streams. The learned features are then processed by\nchannel-wise and modality-wise fusion modules to obtain informative\nrepresentations of videos. Our extensive experiments on a real-world dataset\ndemonstrate that CMFusion significantly outperforms five widely used baselines\nin terms of accuracy, precision, recall, and F1 score. Comprehensive ablation\nstudies and parameter analyses further validate our design choices,\nhighlighting the model's effectiveness in detecting hate videos. The source\ncodes will be made publicly available at https://github.com/EvelynZ10/cmfusion.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "ICDMW 2024, Github: https://github.com/EvelynZ10/cmfusion",
    "pdf_url": "http://arxiv.org/pdf/2505.12051v1",
    "published_date": "2025-05-17 15:24:48 UTC",
    "updated_date": "2025-05-17 15:24:48 UTC"
  },
  {
    "arxiv_id": "2505.12049v1",
    "title": "Beyond Scalar Rewards: An Axiomatic Framework for Lexicographic MDPs",
    "authors": [
      "Mehran Shakerinava",
      "Siamak Ravanbakhsh",
      "Adam Oberman"
    ],
    "abstract": "Recent work has formalized the reward hypothesis through the lens of expected\nutility theory, by interpreting reward as utility. Hausner's foundational work\nshowed that dropping the continuity axiom leads to a generalization of expected\nutility theory where utilities are lexicographically ordered vectors of\narbitrary dimension. In this paper, we extend this result by identifying a\nsimple and practical condition under which preferences cannot be represented by\nscalar rewards, necessitating a 2-dimensional reward function. We provide a\nfull characterization of such reward functions, as well as the general\nd-dimensional case, in Markov Decision Processes (MDPs) under a memorylessness\nassumption on preferences. Furthermore, we show that optimal policies in this\nsetting retain many desirable properties of their scalar-reward counterparts,\nwhile in the Constrained MDP (CMDP) setting -- another common multiobjective\nsetting -- they do not.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12049v1",
    "published_date": "2025-05-17 15:23:58 UTC",
    "updated_date": "2025-05-17 15:23:58 UTC"
  },
  {
    "arxiv_id": "2505.12039v1",
    "title": "AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research",
    "authors": [
      "Renqi Chen",
      "Haoyang Su",
      "Shixiang Tang",
      "Zhenfei Yin",
      "Qi Wu",
      "Hui Li",
      "Ye Sun",
      "Nanqing Dong",
      "Wanli Ouyang",
      "Philip Torr"
    ],
    "abstract": "The Science of Science (SoS) explores the mechanisms underlying scientific\ndiscovery, and offers valuable insights for enhancing scientific efficiency and\nfostering innovation. Traditional approaches often rely on simplistic\nassumptions and basic statistical tools, such as linear regression and\nrule-based simulations, which struggle to capture the complexity and scale of\nmodern research ecosystems. The advent of artificial intelligence (AI) presents\na transformative opportunity for the next generation of SoS, enabling the\nautomation of large-scale pattern discovery and uncovering insights previously\nunattainable. This paper offers a forward-looking perspective on the\nintegration of Science of Science with AI for automated research pattern\ndiscovery and highlights key open challenges that could greatly benefit from\nAI. We outline the advantages of AI over traditional methods, discuss potential\nlimitations, and propose pathways to overcome them. Additionally, we present a\npreliminary multi-agent system as an illustrative example to simulate research\nsocieties, showcasing AI's ability to replicate real-world research patterns\nand accelerate progress in Science of Science research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12039v1",
    "published_date": "2025-05-17 15:01:33 UTC",
    "updated_date": "2025-05-17 15:01:33 UTC"
  },
  {
    "arxiv_id": "2505.12038v1",
    "title": "Safe Delta: Consistently Preserving Safety when Fine-Tuning LLMs on Diverse Datasets",
    "authors": [
      "Ning Lu",
      "Shengcai Liu",
      "Jiahao Wu",
      "Weiyu Chen",
      "Zhirui Zhang",
      "Yew-Soon Ong",
      "Qi Wang",
      "Ke Tang"
    ],
    "abstract": "Large language models (LLMs) have shown great potential as general-purpose AI\nassistants across various domains. To fully leverage this potential in specific\napplications, many companies provide fine-tuning API services, enabling users\nto upload their own data for LLM customization. However, fine-tuning services\nintroduce a new safety threat: user-uploaded data, whether harmful or benign,\ncan break the model's alignment, leading to unsafe outputs. Moreover, existing\ndefense methods struggle to address the diversity of fine-tuning datasets\n(e.g., varying sizes, tasks), often sacrificing utility for safety or vice\nversa. To address this issue, we propose Safe Delta, a safety-aware\npost-training defense method that adjusts the delta parameters (i.e., the\nparameter change before and after fine-tuning). Specifically, Safe Delta\nestimates the safety degradation, selects delta parameters to maximize utility\nwhile limiting overall safety loss, and applies a safety compensation vector to\nmitigate residual safety loss. Through extensive experiments on four diverse\ndatasets with varying settings, our approach consistently preserves safety\nwhile ensuring that the utility gain from benign datasets remains unaffected.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2505.12038v1",
    "published_date": "2025-05-17 15:01:07 UTC",
    "updated_date": "2025-05-17 15:01:07 UTC"
  },
  {
    "arxiv_id": "2505.12031v1",
    "title": "LLM-based Automated Theorem Proving Hinges on Scalable Synthetic Data Generation",
    "authors": [
      "Junyu Lai",
      "Jiakun Zhang",
      "Shuo Xu",
      "Taolue Chen",
      "Zihang Wang",
      "Yao Yang",
      "Jiarui Zhang",
      "Chun Cao",
      "Jingwei Xu"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have sparked considerable\ninterest in automated theorem proving and a prominent line of research\nintegrates stepwise LLM-based provers into tree search. In this paper, we\nintroduce a novel proof-state exploration approach for training data synthesis,\ndesigned to produce diverse tactics across a wide range of intermediate proof\nstates, thereby facilitating effective one-shot fine-tuning of LLM as the\npolicy model. We also propose an adaptive beam size strategy, which effectively\ntakes advantage of our data synthesis method and achieves a trade-off between\nexploration and exploitation during tree search. Evaluations on the MiniF2F and\nProofNet benchmarks demonstrate that our method outperforms strong baselines\nunder the stringent Pass@1 metric, attaining an average pass rate of $60.74\\%$\non MiniF2F and $21.18\\%$ on ProofNet. These results underscore the impact of\nlarge-scale synthetic data in advancing automated theorem proving.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.12031v1",
    "published_date": "2025-05-17 14:47:36 UTC",
    "updated_date": "2025-05-17 14:47:36 UTC"
  },
  {
    "arxiv_id": "2505.12020v1",
    "title": "GeoMaNO: Geometric Mamba Neural Operator for Partial Differential Equations",
    "authors": [
      "Xi Han",
      "Jingwei Zhang",
      "Dimitris Samaras",
      "Fei Hou",
      "Hong Qin"
    ],
    "abstract": "The neural operator (NO) framework has emerged as a powerful tool for solving\npartial differential equations (PDEs). Recent NOs are dominated by the\nTransformer architecture, which offers NOs the capability to capture long-range\ndependencies in PDE dynamics. However, existing Transformer-based NOs suffer\nfrom quadratic complexity, lack geometric rigor, and thus suffer from\nsub-optimal performance on regular grids. As a remedy, we propose the Geometric\nMamba Neural Operator (GeoMaNO) framework, which empowers NOs with Mamba's\nmodeling capability, linear complexity, plus geometric rigor. We evaluate\nGeoMaNO's performance on multiple standard and popularly employed PDE\nbenchmarks, spanning from Darcy flow problems to Navier-Stokes problems.\nGeoMaNO improves existing baselines in solution operator approximation by as\nmuch as 58.9%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12020v1",
    "published_date": "2025-05-17 14:20:57 UTC",
    "updated_date": "2025-05-17 14:20:57 UTC"
  },
  {
    "arxiv_id": "2505.12012v1",
    "title": "Empowering Sustainable Finance with Artificial Intelligence: A Framework for Responsible Implementation",
    "authors": [
      "Georgios Pavlidis"
    ],
    "abstract": "This chapter explores the convergence of two major developments: the rise of\nenvironmental, social, and governance (ESG) investing and the exponential\ngrowth of artificial intelligence (AI) technology. The increased demand for\ndiverse ESG instruments, such as green and ESG-linked loans, will be aligned\nwith the rapid growth of the global AI market, which is expected to be worth\n$1,394.30 billion by 2029. AI can assist in identifying and pricing climate\nrisks, setting more ambitious ESG goals, and advancing sustainable finance\ndecisions. However, delegating sustainable finance decisions to AI poses\nserious risks, and new principles and rules for AI and ESG investing are\nnecessary to mitigate these risks. This chapter highlights the challenges\nassociated with norm-setting initiatives and stresses the need for the\nfine-tuning of the principles of legitimacy, oversight and verification,\ntransparency, and explainability. Finally, the chapter contends that\nintegrating AI into ESG non-financial reporting necessitates a heightened sense\nof responsibility and the establishment of fundamental guiding principles\nwithin the spheres of AI and ESG investing.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12012v1",
    "published_date": "2025-05-17 14:05:39 UTC",
    "updated_date": "2025-05-17 14:05:39 UTC"
  },
  {
    "arxiv_id": "2505.12006v1",
    "title": "SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation",
    "authors": [
      "Yuncheng Hua",
      "Ji Miao",
      "Mehdi Jafari",
      "Jianxiang Xie",
      "Hao Xue",
      "Flora D. Salim"
    ],
    "abstract": "This paper introduces SOCIA (Simulation Orchestration for\nCyber-physical-social Intelligence and Agents), a novel end-to-end framework\nleveraging Large Language Model (LLM)-based multi-agent systems to automate the\ngeneration of high-fidelity Cyber-Physical-Social (CPS) simulators. Addressing\nthe challenges of labor-intensive manual simulator development and complex data\ncalibration, SOCIA integrates a centralized orchestration manager that\ncoordinates specialized agents for tasks including data comprehension, code\ngeneration, simulation execution, and iterative evaluation-feedback loops.\nThrough empirical evaluations across diverse CPS tasks, such as mask adoption\nbehavior simulation (social), personal mobility generation (physical), and user\nmodeling (cyber), SOCIA demonstrates its ability to produce high-fidelity,\nscalable simulations with reduced human intervention. These results highlight\nSOCIA's potential to offer a scalable solution for studying complex CPS\nphenomena",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 3 figures, 2 tables. The paper is under review",
    "pdf_url": "http://arxiv.org/pdf/2505.12006v1",
    "published_date": "2025-05-17 13:47:31 UTC",
    "updated_date": "2025-05-17 13:47:31 UTC"
  },
  {
    "arxiv_id": "2505.12005v1",
    "title": "CHRIS: Clothed Human Reconstruction with Side View Consistency",
    "authors": [
      "Dong Liu",
      "Yifan Yang",
      "Zixiong Huang",
      "Yuxin Gao",
      "Mingkui Tan"
    ],
    "abstract": "Creating a realistic clothed human from a single-view RGB image is crucial\nfor applications like mixed reality and filmmaking. Despite some progress in\nrecent years, mainstream methods often fail to fully utilize side-view\ninformation, as the input single-view image contains front-view information\nonly. This leads to globally unrealistic topology and local surface\ninconsistency in side views. To address these, we introduce Clothed Human\nReconstruction with Side View Consistency, namely CHRIS, which consists of 1) A\nSide-View Normal Discriminator that enhances global visual reasonability by\ndistinguishing the generated side-view normals from the ground truth ones; 2) A\nMulti-to-One Gradient Computation (M2O) that ensures local surface consistency.\nM2O calculates the gradient of a sampling point by integrating the gradients of\nthe nearby points, effectively acting as a smooth operation. Experimental\nresults demonstrate that CHRIS achieves state-of-the-art performance on public\nbenchmarks and outperforms the prior work.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.12005v1",
    "published_date": "2025-05-17 13:41:46 UTC",
    "updated_date": "2025-05-17 13:41:46 UTC"
  },
  {
    "arxiv_id": "2505.12001v1",
    "title": "Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework",
    "authors": [
      "Ruta Binkyte"
    ],
    "abstract": "As large language models (LLMs) are increasingly used in multi-agent systems,\nquestions of fairness should extend beyond resource distribution and procedural\ndesign to include the fairness of how agents communicate. Drawing from\norganizational psychology, we introduce a novel framework for evaluating\nInteractional fairness encompassing Interpersonal fairness (IF) and\nInformational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We\nextend the theoretical grounding of Interactional Fairness to non-sentient\nagents, reframing fairness as a socially interpretable signal rather than a\nsubjective experience. We then adapt established tools from organizational\njustice research, including Colquitt's Organizational Justice Scale and the\nCritical Incident Technique, to measure fairness as a behavioral property of\nagent interaction. We validate our framework through a pilot study using\ncontrolled simulations of a resource negotiation task. We systematically\nmanipulate tone, explanation quality, outcome inequality, and task framing\n(collaborative vs. competitive) to assess how IF influences agent behavior.\nResults show that tone and justification quality significantly affect\nacceptance decisions even when objective outcomes are held constant. In\naddition, the influence of IF vs. InfF varies with context. This work lays the\nfoundation for fairness auditing and norm-sensitive alignment in LLM-MAS.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.12001v1",
    "published_date": "2025-05-17 13:24:13 UTC",
    "updated_date": "2025-05-17 13:24:13 UTC"
  },
  {
    "arxiv_id": "2505.13520v1",
    "title": "Beyond Retrieval: Joint Supervision and Multimodal Document Ranking for Textbook Question Answering",
    "authors": [
      "Hessa Alawwad",
      "Usman Naseem",
      "Areej Alhothali",
      "Ali Alkhathlan",
      "Amani Jamal"
    ],
    "abstract": "Textbook question answering (TQA) is a complex task, requiring the\ninterpretation of complex multimodal context. Although recent advances have\nimproved overall performance, they often encounter difficulties in educational\nsettings where accurate semantic alignment and task-specific document retrieval\nare essential. In this paper, we propose a novel approach to multimodal\ntextbook question answering by introducing a mechanism for enhancing semantic\nrepresentations through multi-objective joint training. Our model, Joint\nEmbedding Training With Ranking Supervision for Textbook Question Answering\n(JETRTQA), is a multimodal learning framework built on a retriever--generator\narchitecture that uses a retrieval-augmented generation setup, in which a\nmultimodal large language model generates answers. JETRTQA is designed to\nimprove the relevance of retrieved documents in complex educational contexts.\nUnlike traditional direct scoring approaches, JETRTQA learns to refine the\nsemantic representations of questions and documents through a supervised signal\nthat combines pairwise ranking and implicit supervision derived from answers.\nWe evaluate our method on the CK12-QA dataset and demonstrate that it\nsignificantly improves the discrimination between informative and irrelevant\ndocuments, even when they are long, complex, and multimodal. JETRTQA\noutperforms the previous state of the art, achieving a 2.4\\% gain in accuracy\non the validation set and 11.1\\% on the test set.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages, 16 figure",
    "pdf_url": "http://arxiv.org/pdf/2505.13520v1",
    "published_date": "2025-05-17 13:23:54 UTC",
    "updated_date": "2025-05-17 13:23:54 UTC"
  },
  {
    "arxiv_id": "2505.11999v1",
    "title": "MRGRP: Empowering Courier Route Prediction in Food Delivery Service with Multi-Relational Graph",
    "authors": [
      "Chang Liu",
      "Huan Yan",
      "Hongjie Sui",
      "Haomin Wen",
      "Yuan Yuan",
      "Yuyang Han",
      "Hongsen Liao",
      "Xuetao Ding",
      "Jinghua Hao",
      "Yong Li"
    ],
    "abstract": "Instant food delivery has become one of the most popular web services\nworldwide due to its convenience in daily life. A fundamental challenge is\naccurately predicting courier routes to optimize task dispatch and improve\ndelivery efficiency. This enhances satisfaction for couriers and users and\nincreases platform profitability. The current heuristic prediction method uses\nonly limited human-selected task features and ignores couriers preferences,\ncausing suboptimal results. Additionally, existing learning-based methods do\nnot fully capture the diverse factors influencing courier decisions or the\ncomplex relationships among them. To address this, we propose a\nMulti-Relational Graph-based Route Prediction (MRGRP) method that models\nfine-grained correlations among tasks affecting courier decisions for accurate\nprediction. We encode spatial and temporal proximity, along with\npickup-delivery relationships, into a multi-relational graph and design a\nGraphFormer architecture to capture these complex connections. We also\nintroduce a route decoder that leverages courier information and dynamic\ndistance and time contexts for prediction, using existing route solutions as\nreferences to improve outcomes. Experiments show our model achieves\nstate-of-the-art route prediction on offline data from cities of various sizes.\nDeployed on the Meituan Turing platform, it surpasses the current heuristic\nalgorithm, reaching a high route prediction accuracy of 0.819, essential for\ncourier and user satisfaction in instant food delivery.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11999v1",
    "published_date": "2025-05-17 13:19:34 UTC",
    "updated_date": "2025-05-17 13:19:34 UTC"
  },
  {
    "arxiv_id": "2505.13519v1",
    "title": "Continuous Domain Generalization",
    "authors": [
      "Zekun Cai",
      "Yiheng Yao",
      "Guangji Bai",
      "Renhe Jiang",
      "Xuan Song",
      "Ryosuke Shibasaki",
      "Liang Zhao"
    ],
    "abstract": "Real-world data distributions often shift continuously across multiple latent\nfactors such as time, geography, and socioeconomic context. However, existing\ndomain generalization approaches typically treat domains as discrete or\nevolving along a single axis (e.g., time), which fails to capture the complex,\nmulti-dimensional nature of real-world variation. This paper introduces the\ntask of Continuous Domain Generalization (CDG), which aims to generalize\npredictive models to unseen domains defined by arbitrary combinations of\ncontinuous variation descriptors. We present a principled framework grounded in\ngeometric and algebraic theory, showing that optimal model parameters across\ndomains lie on a low-dimensional manifold. To model this structure, we propose\na Neural Lie Transport Operator (NeuralLTO), which enables structured parameter\ntransitions by enforcing geometric continuity and algebraic consistency. To\nhandle noisy or incomplete domain descriptors, we introduce a gating mechanism\nto suppress irrelevant dimensions and a local chart-based strategy for robust\ngeneralization. Extensive experiments on synthetic and real-world\ndatasets-including remote sensing, scientific documents, and traffic\nforecasting-demonstrate that our method significantly outperforms existing\nbaselines in generalization accuracy and robustness under descriptor\nimperfections.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.13519v1",
    "published_date": "2025-05-17 12:39:45 UTC",
    "updated_date": "2025-05-17 12:39:45 UTC"
  },
  {
    "arxiv_id": "2505.11983v2",
    "title": "Online Iterative Self-Alignment for Radiology Report Generation",
    "authors": [
      "Ting Xiao",
      "Lei Shi",
      "Yang Zhang",
      "HaoFeng Yang",
      "Zhe Wang",
      "Chenjia Bai"
    ],
    "abstract": "Radiology Report Generation (RRG) is an important research topic for\nrelieving radiologist' heavy workload. Existing RRG models mainly rely on\nsupervised fine-tuning (SFT) based on different model architectures using data\npairs of radiological images and corresponding radiologist-annotated reports.\nRecent research has shifted focus to post-training improvements, aligning RRG\nmodel outputs with human preferences using reinforcement learning (RL).\nHowever, the limited data coverage of high-quality annotated data poses risks\nof overfitting and generalization. This paper proposes a novel Online Iterative\nSelf-Alignment (OISA) method for RRG that consists of four stages:\nself-generation of diverse data, self-evaluation for multi-objective preference\ndata,self-alignment for multi-objective optimization and self-iteration for\nfurther improvement. Our approach allows for generating varied reports tailored\nto specific clinical objectives, enhancing the overall performance of the RRG\nmodel iteratively. Unlike existing methods, our frame-work significantly\nincreases data quality and optimizes performance through iterative\nmulti-objective optimization. Experimental results demonstrate that our method\nsurpasses previous approaches, achieving state-of-the-art performance across\nmultiple evaluation metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2505.11983v2",
    "published_date": "2025-05-17 12:31:12 UTC",
    "updated_date": "2025-05-20 14:49:41 UTC"
  },
  {
    "arxiv_id": "2505.11980v1",
    "title": "AoP-SAM: Automation of Prompts for Efficient Segmentation",
    "authors": [
      "Yi Chen",
      "Mu-Young Son",
      "Chuanbo Hua",
      "Joo-Young Kim"
    ],
    "abstract": "The Segment Anything Model (SAM) is a powerful foundation model for image\nsegmentation, showing robust zero-shot generalization through prompt\nengineering. However, relying on manual prompts is impractical for real-world\napplications, particularly in scenarios where rapid prompt provision and\nresource efficiency are crucial. In this paper, we propose the Automation of\nPrompts for SAM (AoP-SAM), a novel approach that learns to generate essential\nprompts in optimal locations automatically. AoP-SAM enhances SAM's efficiency\nand usability by eliminating manual input, making it better suited for\nreal-world tasks. Our approach employs a lightweight yet efficient Prompt\nPredictor model that detects key entities across images and identifies the\noptimal regions for placing prompt candidates. This method leverages SAM's\nimage embeddings, preserving its zero-shot generalization capabilities without\nrequiring fine-tuning. Additionally, we introduce a test-time instance-level\nAdaptive Sampling and Filtering mechanism that generates prompts in a\ncoarse-to-fine manner. This notably enhances both prompt and mask generation\nefficiency by reducing computational overhead and minimizing redundant mask\nrefinements. Evaluations of three datasets demonstrate that AoP-SAM\nsubstantially improves both prompt generation efficiency and mask generation\naccuracy, making SAM more effective for automated segmentation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.11980v1",
    "published_date": "2025-05-17 12:27:36 UTC",
    "updated_date": "2025-05-17 12:27:36 UTC"
  },
  {
    "arxiv_id": "2505.11979v1",
    "title": "Introduction to Analytical Software Engineering Design Paradigm",
    "authors": [
      "Tarik Houichime",
      "Younes El Amrani"
    ],
    "abstract": "As modern software systems expand in scale and complexity, the challenges\nassociated with their modeling and formulation grow increasingly intricate.\nTraditional approaches often fall short in effectively addressing these\ncomplexities, particularly in tasks such as design pattern detection for\nmaintenance and assessment, as well as code refactoring for optimization and\nlong-term sustainability. This growing inadequacy underscores the need for a\nparadigm shift in how such challenges are approached and resolved. This paper\npresents Analytical Software Engineering (ASE), a novel design paradigm aimed\nat balancing abstraction, tool accessibility, compatibility, and scalability.\nASE enables effective modeling and resolution of complex software engineering\nproblems. The paradigm is evaluated through two frameworks\nBehavioral-Structural Sequences (BSS) and Optimized Design Refactoring (ODR),\nboth developed in accordance with ASE principles. BSS offers a compact,\nlanguage-agnostic representation of codebases to facilitate precise design\npattern detection. ODR unifies artifact and solution representations to\noptimize code refactoring via heuristic algorithms while eliminating iterative\ncomputational overhead. By providing a structured approach to software design\nchallenges, ASE lays the groundwork for future research in encoding and\nanalyzing complex software metrics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.MS",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "The Conference's autorization to submit a preprint was granted",
    "pdf_url": "http://arxiv.org/pdf/2505.11979v1",
    "published_date": "2025-05-17 12:23:55 UTC",
    "updated_date": "2025-05-17 12:23:55 UTC"
  },
  {
    "arxiv_id": "2505.13518v1",
    "title": "Data Balancing Strategies: A Survey of Resampling and Augmentation Methods",
    "authors": [
      "Behnam Yousefimehr",
      "Mehdi Ghatee",
      "Mohammad Amin Seifi",
      "Javad Fazli",
      "Sajed Tavakoli",
      "Zahra Rafei",
      "Shervin Ghaffari",
      "Abolfazl Nikahd",
      "Mahdi Razi Gandomani",
      "Alireza Orouji",
      "Ramtin Mahmoudi Kashani",
      "Sarina Heshmati",
      "Negin Sadat Mousavi"
    ],
    "abstract": "Imbalanced data poses a significant obstacle in machine learning, as an\nunequal distribution of class labels often results in skewed predictions and\ndiminished model accuracy. To mitigate this problem, various resampling\nstrategies have been developed, encompassing both oversampling and\nundersampling techniques aimed at modifying class proportions. Conventional\noversampling approaches like SMOTE enhance the representation of the minority\nclass, whereas undersampling methods focus on trimming down the majority class.\nAdvances in deep learning have facilitated the creation of more complex\nsolutions, such as Generative Adversarial Networks (GANs) and Variational\nAutoencoders (VAEs), which are capable of producing high-quality synthetic\nexamples. This paper reviews a broad spectrum of data balancing methods,\nclassifying them into categories including synthetic oversampling, adaptive\ntechniques, generative models, ensemble-based strategies, hybrid approaches,\nundersampling, and neighbor-based methods. Furthermore, it highlights current\ndevelopments in resampling techniques and discusses practical implementations\nand case studies that validate their effectiveness. The paper concludes by\noffering perspectives on potential directions for future exploration in this\ndomain.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13518v1",
    "published_date": "2025-05-17 12:15:28 UTC",
    "updated_date": "2025-05-17 12:15:28 UTC"
  },
  {
    "arxiv_id": "2505.11966v1",
    "title": "Solve-Detect-Verify: Inference-Time Scaling with Flexible Generative Verifier",
    "authors": [
      "Jianyuan Zhong",
      "Zeju Li",
      "Zhijian Xu",
      "Xiangyu Wen",
      "Kezhi Li",
      "Qiang Xu"
    ],
    "abstract": "Large Language Model (LLM) reasoning for complex tasks inherently involves a\ntrade-off between solution accuracy and computational efficiency. The\nsubsequent step of verification, while intended to improve performance, further\ncomplicates this landscape by introducing its own challenging trade-off:\nsophisticated Generative Reward Models (GenRMs) can be computationally\nprohibitive if naively integrated with LLMs at test-time, while simpler, faster\nmethods may lack reliability. To overcome these challenges, we introduce\nFlexiVe, a novel generative verifier that flexibly balances computational\nresources between rapid, reliable fast thinking and meticulous slow thinking\nusing a Flexible Allocation of Verification Budget strategy. We further propose\nthe Solve-Detect-Verify pipeline, an efficient inference-time scaling framework\nthat intelligently integrates FlexiVe, proactively identifying solution\ncompletion points to trigger targeted verification and provide focused solver\nfeedback. Experiments show FlexiVe achieves superior accuracy in pinpointing\nerrors within reasoning traces on ProcessBench. Furthermore, on challenging\nmathematical reasoning benchmarks (AIME 2024, AIME 2025, and CNMO), our full\napproach outperforms baselines like self-consistency in reasoning accuracy and\ninference efficiency. Our system offers a scalable and effective solution to\nenhance LLM reasoning at test time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11966v1",
    "published_date": "2025-05-17 11:41:44 UTC",
    "updated_date": "2025-05-17 11:41:44 UTC"
  },
  {
    "arxiv_id": "2505.11963v1",
    "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models",
    "authors": [
      "Luca Collini",
      "Baleegh Ahmad",
      "Joey Ah-kiow",
      "Ramesh Karri"
    ],
    "abstract": "Hardware security verification is a challenging and time-consuming task. For\nthis purpose, design engineers may utilize tools such as formal verification,\nlinters, and functional simulation tests, coupled with analysis and a deep\nunderstanding of the hardware design being inspected. Large Language Models\n(LLMs) have been used to assist during this task, either directly or in\nconjunction with existing tools. We improve the state of the art by proposing\nMARVEL, a multi-agent LLM framework for a unified approach to decision-making,\ntool use, and reasoning. MARVEL mimics the cognitive process of a designer\nlooking for security vulnerabilities in RTL code. It consists of a supervisor\nagent that devises the security policy of the system-on-chips (SoCs) using its\nsecurity documentation. It delegates tasks to validate the security policy to\nindividual executor agents. Each executor agent carries out its assigned task\nusing a particular strategy. Each executor agent may use one or more tools to\nidentify potential security bugs in the design and send the results back to the\nsupervisor agent for further analysis and confirmation. MARVEL includes\nexecutor agents that leverage formal tools, linters, simulation tests,\nLLM-based detection schemes, and static analysis-based checks. We test our\napproach on a known buggy SoC based on OpenTitan from the Hack@DATE\ncompetition. We find that 20 of the 48 issues reported by MARVEL pose security\nvulnerabilities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted for Peer Review",
    "pdf_url": "http://arxiv.org/pdf/2505.11963v1",
    "published_date": "2025-05-17 11:31:24 UTC",
    "updated_date": "2025-05-17 11:31:24 UTC"
  },
  {
    "arxiv_id": "2505.11962v1",
    "title": "CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World",
    "authors": [
      "Zoya Volovikova",
      "Gregory Gorbov",
      "Petr Kuderov",
      "Aleksandr I. Panov",
      "Alexey Skrynnik"
    ],
    "abstract": "Following instructions in real-world conditions requires the ability to adapt\nto the world's volatility and entanglement: the environment is dynamic and\nunpredictable, instructions can be linguistically complex with diverse\nvocabulary, and the number of possible goals an agent may encounter is vast.\nDespite extensive research in this area, most studies are conducted in static\nenvironments with simple instructions and a limited vocabulary, making it\ndifficult to assess agent performance in more diverse and challenging settings.\nTo address this gap, we introduce CrafText, a benchmark for evaluating\ninstruction following in a multimodal environment with diverse instructions and\ndynamic interactions. CrafText includes 3,924 instructions with 3,423 unique\nwords, covering Localization, Conditional, Building, and Achievement tasks.\nAdditionally, we propose an evaluation protocol that measures an agent's\nability to generalize to novel instruction formulations and dynamically\nevolving task configurations, providing a rigorous test of both linguistic\nunderstanding and adaptive decision-making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11962v1",
    "published_date": "2025-05-17 11:25:46 UTC",
    "updated_date": "2025-05-17 11:25:46 UTC"
  },
  {
    "arxiv_id": "2505.11953v1",
    "title": "Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning",
    "authors": [
      "Puning Yang",
      "Qizhou Wang",
      "Zhuo Huang",
      "Tongliang Liu",
      "Chengqi Zhang",
      "Bo Han"
    ],
    "abstract": "Loss reweighting has shown significant benefits for machine unlearning with\nlarge language models (LLMs). However, their exact functionalities are left\nunclear and the optimal strategy remains an open question, thus impeding the\nunderstanding and improvement of existing methodologies. In this paper, we\nidentify two distinct goals of loss reweighting, namely, Saturation and\nImportance -- the former indicates that those insufficiently optimized data\nshould be emphasized, while the latter stresses some critical data that are\nmost influential for loss minimization. To study their usefulness, we design\nspecific reweighting strategies for each goal and evaluate their respective\neffects on unlearning. We conduct extensive empirical analyses on\nwell-established benchmarks, and summarize some important observations as\nfollows: (i) Saturation enhances efficacy more than importance-based\nreweighting, and their combination can yield additional improvements. (ii)\nSaturation typically allocates lower weights to data with lower likelihoods,\nwhereas importance-based reweighting does the opposite. (iii) The efficacy of\nunlearning is also largely influenced by the smoothness and granularity of the\nweight distributions. Based on these findings, we propose SatImp, a simple\nreweighting method that combines the advantages of both saturation and\nimportance. Empirical results on extensive datasets validate the efficacy of\nour method, potentially bridging existing research gaps and indicating\ndirections for future research. Our code is available at\nhttps://github.com/Puning97/SatImp-for-LLM-Unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11953v1",
    "published_date": "2025-05-17 10:41:22 UTC",
    "updated_date": "2025-05-17 10:41:22 UTC"
  },
  {
    "arxiv_id": "2505.11946v1",
    "title": "Let's have a chat with the EU AI Act",
    "authors": [
      "Adam Kovari",
      "Yasin Ghafourian",
      "Csaba Hegedus",
      "Belal Abu Naim",
      "Kitti Mezei",
      "Pal Varga",
      "Markus Tauber"
    ],
    "abstract": "As artificial intelligence (AI) regulations evolve and the regulatory\nlandscape develops and becomes more complex, ensuring compliance with ethical\nguidelines and legal frameworks remains a challenge for AI developers. This\npaper introduces an AI-driven self-assessment chatbot designed to assist users\nin navigating the European Union AI Act and related standards. Leveraging a\nRetrieval-Augmented Generation (RAG) framework, the chatbot enables real-time,\ncontext-aware compliance verification by retrieving relevant regulatory texts\nand providing tailored guidance. By integrating both public and proprietary\nstandards, it streamlines regulatory adherence, reduces complexity, and fosters\nresponsible AI development. The paper explores the chatbot's architecture,\ncomparing naive and graph-based RAG models, and discusses its potential impact\non AI governance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11946v1",
    "published_date": "2025-05-17 10:24:08 UTC",
    "updated_date": "2025-05-17 10:24:08 UTC"
  },
  {
    "arxiv_id": "2505.11942v1",
    "title": "LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners",
    "authors": [
      "Junhao Zheng",
      "Xidi Cai",
      "Qiuke Li",
      "Duzhen Zhang",
      "ZhongZhi Li",
      "Yingying Zhang",
      "Le Song",
      "Qianli Ma"
    ],
    "abstract": "Lifelong learning is essential for intelligent agents operating in dynamic\nenvironments. Current large language model (LLM)-based agents, however, remain\nstateless and unable to accumulate or transfer knowledge over time. Existing\nbenchmarks treat agents as static systems and fail to evaluate lifelong\nlearning capabilities. We present LifelongAgentBench, the first unified\nbenchmark designed to systematically assess the lifelong learning ability of\nLLM agents. It provides skill-grounded, interdependent tasks across three\ninteractive environments, Database, Operating System, and Knowledge Graph, with\nautomatic label verification, reproducibility, and modular extensibility.\nExtensive experiments reveal that conventional experience replay has limited\neffectiveness for LLM agents due to irrelevant information and context length\nconstraints. We further introduce a group self-consistency mechanism that\nsignificantly improves lifelong learning performance. We hope\nLifelongAgentBench will advance the development of adaptive, memory-capable LLM\nagents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11942v1",
    "published_date": "2025-05-17 10:09:11 UTC",
    "updated_date": "2025-05-17 10:09:11 UTC"
  },
  {
    "arxiv_id": "2505.11939v1",
    "title": "Fine-Grained ECG-Text Contrastive Learning via Waveform Understanding Enhancement",
    "authors": [
      "Haitao Li",
      "Che Liu",
      "Zhengyao Ding",
      "Ziyi Liu",
      "Zhengxing Huang"
    ],
    "abstract": "Electrocardiograms (ECGs) are essential for diagnosing cardiovascular\ndiseases. While previous ECG-text contrastive learning methods have shown\npromising results, they often overlook the incompleteness of the reports. Given\nan ECG, the report is generated by first identifying key waveform features and\nthen inferring the final diagnosis through these features. Despite their\nimportance, these waveform features are often not recorded in the report as\nintermediate results. Aligning ECGs with such incomplete reports impedes the\nmodel's ability to capture the ECG's waveform features and limits its\nunderstanding of diagnostic reasoning based on those features. To address this,\nwe propose FG-CLEP (Fine-Grained Contrastive Language ECG Pre-training), which\naims to recover these waveform features from incomplete reports with the help\nof large language models (LLMs), under the challenges of hallucinations and the\nnon-bijective relationship between waveform features and diagnoses.\nAdditionally, considering the frequent false negatives due to the prevalence of\ncommon diagnoses in ECGs, we introduce a semantic similarity matrix to guide\ncontrastive learning. Furthermore, we adopt a sigmoid-based loss function to\naccommodate the multi-label nature of ECG-related tasks. Experiments on six\ndatasets demonstrate that FG-CLEP outperforms state-of-the-art methods in both\nzero-shot prediction and linear probing across these datasets.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11939v1",
    "published_date": "2025-05-17 10:03:06 UTC",
    "updated_date": "2025-05-17 10:03:06 UTC"
  },
  {
    "arxiv_id": "2505.11936v1",
    "title": "How can Diffusion Models Evolve into Continual Generators?",
    "authors": [
      "Jingren Liu",
      "Zhong Ji",
      "Xiangyu Chen"
    ],
    "abstract": "While diffusion models have achieved remarkable success in static data\ngeneration, their deployment in streaming or continual learning (CL) scenarios\nfaces a major challenge: catastrophic forgetting (CF), where newly acquired\ngenerative capabilities overwrite previously learned ones. To systematically\naddress this, we introduce a formal Continual Diffusion Generation (CDG)\nparadigm that characterizes and redefines CL in the context of generative\ndiffusion models. Prior efforts often adapt heuristic strategies from continual\nclassification tasks but lack alignment with the underlying diffusion process.\nIn this work, we develop the first theoretical framework for CDG by analyzing\ncross-task dynamics in diffusion-based generative modeling. Our analysis\nreveals that the retention and stability of generative knowledge across tasks\nare governed by three key consistency criteria: inter-task knowledge\nconsistency (IKC), unconditional knowledge consistency (UKC), and label\nknowledge consistency (LKC). Building on these insights, we propose Continual\nConsistency Diffusion (CCD), a principled framework that integrates these\nconsistency objectives into training via hierarchical loss terms\n$\\mathcal{L}_{IKC}$, $\\mathcal{L}_{UKC}$, and $\\mathcal{L}_{LKC}$. This\npromotes effective knowledge retention while enabling the assimilation of new\ngenerative capabilities. Extensive experiments on four benchmark datasets\ndemonstrate that CCD achieves state-of-the-art performance under continual\nsettings, with substantial gains in Mean Fidelity (MF) and Incremental Mean\nFidelity (IMF), particularly in tasks with rich cross-task knowledge overlap.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11936v1",
    "published_date": "2025-05-17 09:49:25 UTC",
    "updated_date": "2025-05-17 09:49:25 UTC"
  },
  {
    "arxiv_id": "2505.11933v1",
    "title": "Conversational Recommendation System using NLP and Sentiment Analysis",
    "authors": [
      "Piyush Talegaonkar",
      "Siddhant Hole",
      "Shrinesh Kamble",
      "Prashil Gulechha",
      "Deepali Salapurkar"
    ],
    "abstract": "In today's digitally-driven world, the demand for personalized and\ncontext-aware recommendations has never been greater. Traditional recommender\nsystems have made significant strides in this direction, but they often lack\nthe ability to tap into the richness of conversational data. This paper\nrepresents a novel approach to recommendation systems by integrating\nconversational insights into the recommendation process. The Conversational\nRecommender System integrates cutting-edge technologies such as deep learning,\nleveraging machine learning algorithms like Apriori for Association Rule\nMining, Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN),\nand Long Short-Term Memory (LTSM). Furthermore, sophisticated voice recognition\ntechnologies, including Hidden Markov Models (HMMs) and Dynamic Time Warping\n(DTW) algorithms, play a crucial role in accurate speech-to-text conversion,\nensuring robust performance in diverse environments. The methodology\nincorporates a fusion of content-based and collaborative recommendation\napproaches, enhancing them with NLP techniques. This innovative integration\nensures a more personalized and context-aware recommendation experience,\nparticularly in marketing applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Presented in ISETE conference (International Conference on Artificial\n  Intelligence, Machine Learning and Big Data Engineering 2024)",
    "pdf_url": "http://arxiv.org/pdf/2505.11933v1",
    "published_date": "2025-05-17 09:36:05 UTC",
    "updated_date": "2025-05-17 09:36:05 UTC"
  },
  {
    "arxiv_id": "2505.11930v1",
    "title": "The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics",
    "authors": [
      "Marco Sälzer",
      "Przemysław Andrzej Wałęga",
      "Martin Lange"
    ],
    "abstract": "In recent years, the expressive power of various neural architectures --\nincluding graph neural networks (GNNs), transformers, and recurrent neural\nnetworks -- has been characterised using tools from logic and formal language\ntheory. As the capabilities of basic architectures are becoming well\nunderstood, increasing attention is turning to models that combine multiple\narchitectural paradigms. Among them particularly important, and challenging to\nanalyse, are temporal extensions of GNNs, which integrate both spatial\n(graph-structure) and temporal (evolution over time) dimensions. In this paper,\nwe initiate the study of logical characterisation of temporal GNNs by\nconnecting them to two-dimensional product logics. We show that the expressive\npower of temporal GNNs depends on how graph and temporal components are\ncombined. In particular, temporal GNNs that apply static GNNs recursively over\ntime can capture all properties definable in the product logic of (past)\npropositional temporal logic PTL and the modal logic K. In contrast,\narchitectures such as graph-and-time TGNNs and global TGNNs can only express\nrestricted fragments of this logic, where the interaction between temporal and\nspatial operators is syntactically constrained. These results yield the first\nlogical characterisations of temporal GNNs and establish new relative\nexpressiveness results for temporal GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11930v1",
    "published_date": "2025-05-17 09:34:57 UTC",
    "updated_date": "2025-05-17 09:34:57 UTC"
  },
  {
    "arxiv_id": "2505.11926v1",
    "title": "SafeVid: Toward Safety Aligned Video Large Multimodal Models",
    "authors": [
      "Yixu Wang",
      "Jiaxin Song",
      "Yifeng Gao",
      "Xin Wang",
      "Yang Yao",
      "Yan Teng",
      "Xingjun Ma",
      "Yingchun Wang",
      "Yu-Gang Jiang"
    ],
    "abstract": "As Video Large Multimodal Models (VLMMs) rapidly advance, their inherent\ncomplexity introduces significant safety challenges, particularly the issue of\nmismatched generalization where static safety alignments fail to transfer to\ndynamic video contexts. We introduce SafeVid, a framework designed to instill\nvideo-specific safety principles in VLMMs. SafeVid uniquely transfers robust\ntextual safety alignment capabilities to the video domain by employing detailed\ntextual video descriptions as an interpretive bridge, facilitating LLM-based\nrule-driven safety reasoning. This is achieved through a closed-loop system\ncomprising: 1) generation of SafeVid-350K, a novel 350,000-pair video-specific\nsafety preference dataset; 2) targeted alignment of VLMMs using Direct\nPreference Optimization (DPO); and 3) comprehensive evaluation via our new\nSafeVidBench benchmark. Alignment with SafeVid-350K significantly enhances VLMM\nsafety, with models like LLaVA-NeXT-Video demonstrating substantial\nimprovements (e.g., up to 42.39%) on SafeVidBench. SafeVid provides critical\nresources and a structured approach, demonstrating that leveraging textual\ndescriptions as a conduit for safety reasoning markedly improves the safety\nalignment of VLMMs. We have made SafeVid-350K dataset\n(https://huggingface.co/datasets/yxwang/SafeVid-350K) publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11926v1",
    "published_date": "2025-05-17 09:21:33 UTC",
    "updated_date": "2025-05-17 09:21:33 UTC"
  },
  {
    "arxiv_id": "2505.11924v1",
    "title": "An Explanation of Intrinsic Self-Correction via Linear Representations and Latent Concepts",
    "authors": [
      "Yu-Ting Lee",
      "Hui-Ying Shih",
      "Fu-Chieh Chang",
      "Pei-Yuan Wu"
    ],
    "abstract": "We provide an explanation for the performance gains of intrinsic\nself-correction, a process where a language model iteratively refines its\noutputs without external feedback. More precisely, we investigate how prompting\ninduces interpretable changes in hidden states and thus affects the output\ndistributions. We hypothesize that each prompt-induced shift lies in a linear\nspan of some linear representation vectors, naturally separating tokens based\non individual concept alignment. Building around this idea, we give a\nmathematical formulation of self-correction and derive a concentration result\nfor output tokens based on alignment magnitudes. Our experiments on text\ndetoxification with zephyr-7b-sft reveal a substantial gap in the inner\nproducts of the prompt-induced shifts and the unembeddings of the top-100 most\ntoxic tokens vs. those of the unembeddings of the bottom-100 least toxic\ntokens, under toxic instructions. This suggests that self-correction prompts\nenhance a language model's capability of latent concept recognition. Our\nanalysis offers insights into the underlying mechanism of self-correction by\ncharacterizing how prompting works explainably. For reproducibility, our code\nis available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11924v1",
    "published_date": "2025-05-17 09:18:37 UTC",
    "updated_date": "2025-05-17 09:18:37 UTC"
  },
  {
    "arxiv_id": "2505.11912v1",
    "title": "Modèles de Substitution pour les Modèles à base d'Agents : Enjeux, Méthodes et Applications",
    "authors": [
      "Paul Saves",
      "Nicolas Verstaevel",
      "Benoît Gaudou"
    ],
    "abstract": "Multi-agent simulations enables the modeling and analyses of the dynamic\nbehaviors and interactions of autonomous entities evolving in complex\nenvironments. Agent-based models (ABM) are widely used to study emergent\nphenomena arising from local interactions. However, their high computational\ncost poses a significant challenge, particularly for large-scale simulations\nrequiring extensive parameter exploration, optimization, or uncertainty\nquantification. The increasing complexity of ABM limits their feasibility for\nreal-time decision-making and large-scale scenario analysis. To address these\nlimitations, surrogate models offer an efficient alternative by learning\napproximations from sparse simulation data. These models provide\ncheap-to-evaluate predictions, significantly reducing computational costs while\nmaintaining accuracy. Various machine learning techniques, including regression\nmodels, neural networks, random forests and Gaussian processes, have been\napplied to construct robust surrogates. Moreover, uncertainty quantification\nand sensitivity analysis play a crucial role in enhancing model reliability and\ninterpretability.\n  This article explores the motivations, methods, and applications of surrogate\nmodeling for ABM, emphasizing the trade-offs between accuracy, computational\nefficiency, and interpretability. Through a case study on a segregation model,\nwe highlight the challenges associated with building and validating surrogate\nmodels, comparing different approaches and evaluating their performance.\nFinally, we discuss future perspectives on integrating surrogate models within\nABM to improve scalability, explainability, and real-time decision support\nacross various fields such as ecology, urban planning and economics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, in French language. Les 33\\`emes Journ\\'ees Francophones\n  sur les Syst\\`emes Multi-Agents (JFSMA 2025). 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.11912v1",
    "published_date": "2025-05-17 08:55:33 UTC",
    "updated_date": "2025-05-17 08:55:33 UTC"
  },
  {
    "arxiv_id": "2505.11904v1",
    "title": "K*-Means: A Parameter-free Clustering Algorithm",
    "authors": [
      "Louis Mahon",
      "Mirella Lapata"
    ],
    "abstract": "Clustering is a widely used and powerful machine learning technique, but its\neffectiveness is often limited by the need to specify the number of clusters,\nk, or by relying on thresholds that implicitly determine k. We introduce\nk*-means, a novel clustering algorithm that eliminates the need to set k or any\nother parameters. Instead, it uses the minimum description length principle to\nautomatically determine the optimal number of clusters, k*, by splitting and\nmerging clusters while also optimising the standard k-means objective. We prove\nthat k*-means is guaranteed to converge and demonstrate experimentally that it\nsignificantly outperforms existing methods in scenarios where k is unknown. We\nalso show that it is accurate in estimating k, and that empirically its runtime\nis competitive with existing methods, and scales well with dataset size.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11904v1",
    "published_date": "2025-05-17 08:41:07 UTC",
    "updated_date": "2025-05-17 08:41:07 UTC"
  },
  {
    "arxiv_id": "2505.11899v1",
    "title": "From Recall to Reasoning: Automated Question Generation for Deeper Math Learning through Large Language Models",
    "authors": [
      "Yongan Yu",
      "Alexandre Krantz",
      "Nikki G. Lobczowski"
    ],
    "abstract": "Educators have started to turn to Generative AI (GenAI) to help create new\ncourse content, but little is known about how they should do so. In this\nproject, we investigated the first steps for optimizing content creation for\nadvanced math. In particular, we looked at the ability of GenAI to produce\nhigh-quality practice problems that are relevant to the course content. We\nconducted two studies to: (1) explore the capabilities of current versions of\npublicly available GenAI and (2) develop an improved framework to address the\nlimitations we found. Our results showed that GenAI can create math problems at\nvarious levels of quality with minimal support, but that providing examples and\nrelevant content results in better quality outputs. This research can help\neducators decide the ideal way to adopt GenAI in their workflows, to create\nmore effective educational experiences for students.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures, accepted by AIED conference",
    "pdf_url": "http://arxiv.org/pdf/2505.11899v1",
    "published_date": "2025-05-17 08:30:10 UTC",
    "updated_date": "2025-05-17 08:30:10 UTC"
  },
  {
    "arxiv_id": "2505.11896v1",
    "title": "AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning",
    "authors": [
      "Chenwei Lou",
      "Zewei Sun",
      "Xinnian Liang",
      "Meng Qu",
      "Wei Shen",
      "Wenqi Wang",
      "Yuntao Li",
      "Qingping Yang",
      "Shuangzhi Wu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities but\noften face challenges with tasks requiring sophisticated reasoning. While\nChain-of-Thought (CoT) prompting significantly enhances reasoning, it\nindiscriminately generates lengthy reasoning steps for all queries, leading to\nsubstantial computational costs and inefficiency, especially for simpler\ninputs. To address this critical issue, we introduce AdaCoT (Adaptive\nChain-of-Thought), a novel framework enabling LLMs to adaptively decide when to\ninvoke CoT. AdaCoT framed adaptive reasoning as a Pareto optimization problem\nthat seeks to balance model performance with the costs associated with CoT\ninvocation (both frequency and computational overhead). We propose a\nreinforcement learning (RL) based method, specifically utilizing Proximal\nPolicy Optimization (PPO), to dynamically control the CoT triggering decision\nboundary by adjusting penalty coefficients, thereby allowing the model to\ndetermine CoT necessity based on implicit query complexity. A key technical\ncontribution is Selective Loss Masking (SLM), designed to counteract decision\nboundary collapse during multi-stage RL training, ensuring robust and stable\nadaptive triggering. Experimental results demonstrate that AdaCoT successfully\nnavigates the Pareto frontier, achieving substantial reductions in CoT usage\nfor queries not requiring elaborate reasoning. For instance, on our production\ntraffic testset, AdaCoT reduced CoT triggering rates to as low as 3.18\\% and\ndecreased average response tokens by 69.06%, while maintaining high performance\non complex tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11896v1",
    "published_date": "2025-05-17 08:27:00 UTC",
    "updated_date": "2025-05-17 08:27:00 UTC"
  },
  {
    "arxiv_id": "2505.11893v1",
    "title": "RLAP: A Reinforcement Learning Enhanced Adaptive Planning Framework for Multi-step NLP Task Solving",
    "authors": [
      "Zepeng Ding",
      "Dixuan Wang",
      "Ziqin Luo",
      "Guochao Jiang",
      "Deqing Yang",
      "Jiaqing Liang"
    ],
    "abstract": "Multi-step planning has been widely employed to enhance the performance of\nlarge language models (LLMs) on downstream natural language processing (NLP)\ntasks, which decomposes the original task into multiple subtasks and guide LLMs\nto solve them sequentially without additional training. When addressing task\ninstances, existing methods either preset the order of steps or attempt\nmultiple paths at each step. However, these methods overlook instances'\nlinguistic features and rely on the intrinsic planning capabilities of LLMs to\nevaluate intermediate feedback and then select subtasks, resulting in\nsuboptimal outcomes. To better solve multi-step NLP tasks with LLMs, in this\npaper we propose a Reinforcement Learning enhanced Adaptive Planning framework\n(RLAP). In our framework, we model an NLP task as a Markov decision process\n(MDP) and employ an LLM directly into the environment. In particular, a\nlightweight Actor model is trained to estimate Q-values for natural language\nsequences consisting of states and actions through reinforcement learning.\nTherefore, during sequential planning, the linguistic features of each sequence\nin the MDP can be taken into account, and the Actor model interacts with the\nLLM to determine the optimal order of subtasks for each task instance. We apply\nRLAP on three different types of NLP tasks and conduct extensive experiments on\nmultiple datasets to verify RLAP's effectiveness and robustness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11893v1",
    "published_date": "2025-05-17 08:06:14 UTC",
    "updated_date": "2025-05-17 08:06:14 UTC"
  },
  {
    "arxiv_id": "2505.11891v1",
    "title": "Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents",
    "authors": [
      "Weikai Xu",
      "Zhizheng Jiang",
      "Yuxuan Liu",
      "Wei Liu",
      "Jian Luan",
      "Yuanchun Li",
      "Yunxin Liu",
      "Bin Wang",
      "Bo An"
    ],
    "abstract": "VLM-based mobile agents are increasingly popular due to their capabilities to\ninteract with smartphone GUIs and XML-structured texts and to complete daily\ntasks. However, existing online benchmarks struggle with obtaining stable\nreward signals due to dynamic environmental changes. Offline benchmarks\nevaluate the agents through single-path trajectories, which stands in contrast\nto the inherently multi-solution characteristics of GUI tasks. Additionally,\nboth types of benchmarks fail to assess whether mobile agents can handle noise\nor engage in proactive interactions due to a lack of noisy apps or overly full\ninstructions during the evaluation process. To address these limitations, we\nuse a slot-based instruction generation method to construct a more realistic\nand comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a\ncommon task split, with offline multi-path evaluation to assess the agent's\nability to obtain step rewards during task execution. It contains a noisy split\nbased on pop-ups and ads apps, and a contaminated split named AITZ-Noise to\nformulate a real noisy environment. Furthermore, an ambiguous instruction split\nwith preset Q\\&A interactions is released to evaluate the agent's proactive\ninteraction capabilities. We conduct evaluations on these splits using the\nsingle-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2,\nas well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are\navailable at https://huggingface.co/datasets/xwk123/MobileBench-v2.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11891v1",
    "published_date": "2025-05-17 07:58:34 UTC",
    "updated_date": "2025-05-17 07:58:34 UTC"
  },
  {
    "arxiv_id": "2505.11889v1",
    "title": "Exploring the Potential of SSL Models for Sound Event Detection",
    "authors": [
      "Hanfang Cui",
      "Longfei Song",
      "Li Li",
      "Dongxing Xu",
      "Yanhua Long"
    ],
    "abstract": "Self-supervised learning (SSL) models offer powerful representations for\nsound event detection (SED), yet their synergistic potential remains\nunderexplored. This study systematically evaluates state-of-the-art SSL models\nto guide optimal model selection and integration for SED. We propose a\nframework that combines heterogeneous SSL representations (e.g., BEATs, HuBERT,\nWavLM) through three fusion strategies: individual SSL embedding integration,\ndual-modal fusion, and full aggregation. Experiments on the DCASE 2023 Task 4\nChallenge reveal that dual-modal fusion (e.g., CRNN+BEATs+WavLM) achieves\ncomplementary performance gains, while CRNN+BEATs alone delivers the best\nresults among individual SSL models. We further introduce normalized sound\nevent bounding boxes (nSEBBs), an adaptive post-processing method that\ndynamically adjusts event boundary predictions, improving PSDS1 by up to 4% for\nstandalone SSL models. These findings highlight the compatibility and\ncomplementarity of SSL architectures, providing guidance for task-specific\nfusion and robust SED system design.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "I.5.4; I.2.10; H.5.5"
    ],
    "primary_category": "eess.AS",
    "comment": "27 pages, 5 figures, submitted to the Journal of King Saud University\n  - Computer and Information Sciences (under review)",
    "pdf_url": "http://arxiv.org/pdf/2505.11889v1",
    "published_date": "2025-05-17 07:54:31 UTC",
    "updated_date": "2025-05-17 07:54:31 UTC"
  },
  {
    "arxiv_id": "2505.11881v1",
    "title": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks",
    "authors": [
      "Giyeong Oh",
      "Woohyun Cho",
      "Siyeol Kim",
      "Suhwan Choi",
      "Younjae Yu"
    ],
    "abstract": "Residual connections are pivotal for deep neural networks, enabling greater\ndepth by mitigating vanishing gradients. However, in standard residual updates,\nthe module's output is directly added to the input stream. This can lead to\nupdates that predominantly reinforce or modulate the existing stream direction,\npotentially underutilizing the module's capacity for learning entirely novel\nfeatures. In this work, we introduce Orthogonal Residual Update: we decompose\nthe module's output relative to the input stream and add only the component\northogonal to this stream. This design aims to guide modules to contribute\nprimarily new representational directions, fostering richer feature learning\nwhile promoting more efficient training. We demonstrate that our orthogonal\nupdate strategy improves generalization accuracy and training stability across\ndiverse architectures (ResNetV2, Vision Transformers) and datasets (CIFARs,\nTinyImageNet, ImageNet-1k), achieving, for instance, a +4.3\\%p top-1 accuracy\ngain for ViT-B on ImageNet-1k.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, WIP",
    "pdf_url": "http://arxiv.org/pdf/2505.11881v1",
    "published_date": "2025-05-17 07:16:11 UTC",
    "updated_date": "2025-05-17 07:16:11 UTC"
  },
  {
    "arxiv_id": "2505.11878v1",
    "title": "AdaptMol: Adaptive Fusion from Sequence String to Topological Structure for Few-shot Drug Discovery",
    "authors": [
      "Yifan Dai",
      "Xuanbai Ren",
      "Tengfei Ma",
      "Qipeng Yan",
      "Yiping Liu",
      "Yuansheng Liu",
      "Xiangxiang Zeng"
    ],
    "abstract": "Accurate molecular property prediction (MPP) is a critical step in modern\ndrug development. However, the scarcity of experimental validation data poses a\nsignificant challenge to AI-driven research paradigms. Under few-shot learning\nscenarios, the quality of molecular representations directly dictates the\ntheoretical upper limit of model performance. We present AdaptMol, a\nprototypical network integrating Adaptive multimodal fusion for Molecular\nrepresentation. This framework employs a dual-level attention mechanism to\ndynamically integrate global and local molecular features derived from two\nmodalities: SMILES sequences and molecular graphs. (1) At the local level,\nstructural features such as atomic interactions and substructures are extracted\nfrom molecular graphs, emphasizing fine-grained topological information; (2) At\nthe global level, the SMILES sequence provides a holistic representation of the\nmolecule. To validate the necessity of multimodal adaptive fusion, we propose\nan interpretable approach based on identifying molecular active substructures\nto demonstrate that multimodal adaptive fusion can efficiently represent\nmolecules. Extensive experiments on three commonly used benchmarks under 5-shot\nand 10-shot settings demonstrate that AdaptMol achieves state-of-the-art\nperformance in most cases. The rationale-extracted method guides the fusion of\ntwo modalities and highlights the importance of both modalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN",
      "J.3; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.11878v1",
    "published_date": "2025-05-17 07:12:12 UTC",
    "updated_date": "2025-05-17 07:12:12 UTC"
  },
  {
    "arxiv_id": "2505.14711v1",
    "title": "Space evaluation at the starting point of soccer transitions",
    "authors": [
      "Yohei Ogawa",
      "Rikuhei Umemoto",
      "Keisuke Fujii"
    ],
    "abstract": "Soccer is a sport played on a pitch where effective use of space is crucial.\nDecision-making during transitions, when possession switches between teams, has\nbeen increasingly important, but research on space evaluation in these moments\nhas been limited. Recent space evaluation methods such as OBSO (Off-Ball\nScoring Opportunity) use scoring probability, so it is not well-suited for\nassessing areas far from the goal, where transitions typically occur. In this\npaper, we propose OBPV (Off-Ball Positioning Value) to evaluate space across\nthe pitch, including the starting points of transitions. OBPV extends OBSO by\nintroducing the field value model, which evaluates the entire pitch, and by\nemploying the transition kernel model, which reflects positional specificity\nthrough kernel density estimation of pass distributions. Experiments using La\nLiga 2023/24 season tracking and event data show that OBPV highlights effective\nspace utilization during counter-attacks and reveals team-specific\ncharacteristics in how the teams utilize space after positive and negative\ntransitions.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "23 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.14711v1",
    "published_date": "2025-05-17 06:28:06 UTC",
    "updated_date": "2025-05-17 06:28:06 UTC"
  },
  {
    "arxiv_id": "2505.11866v1",
    "title": "Position Paper: Bounded Alignment: What (Not) To Expect From AGI Agents",
    "authors": [
      "Ali A. Minai"
    ],
    "abstract": "The issues of AI risk and AI safety are becoming critical as the prospect of\nartificial general intelligence (AGI) looms larger. The emergence of extremely\nlarge and capable generative models has led to alarming predictions and created\na stir from boardrooms to legislatures. As a result, AI alignment has emerged\nas one of the most important areas in AI research. The goal of this position\npaper is to argue that the currently dominant vision of AGI in the AI and\nmachine learning (AI/ML) community needs to evolve, and that expectations and\nmetrics for its safety must be informed much more by our understanding of the\nonly existing instance of general intelligence, i.e., the intelligence found in\nanimals, and especially in humans. This change in perspective will lead to a\nmore realistic view of the technology, and allow for better policy decisions.",
    "categories": [
      "cs.AI",
      "I.2.0; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper accepted for the 2025 IEEE/INNS International Joint Conference\n  on Neural Networks, Rome, Italy, June 30 - July 5, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.11866v1",
    "published_date": "2025-05-17 06:17:57 UTC",
    "updated_date": "2025-05-17 06:17:57 UTC"
  },
  {
    "arxiv_id": "2505.11864v1",
    "title": "Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning",
    "authors": [
      "Kalyan Cherukuri",
      "Aarav Lala"
    ],
    "abstract": "As generative agents become increasingly capable, alignment of their behavior\nwith complex human values remains a fundamental challenge. Existing approaches\noften simplify human intent through reduction to a scalar reward, overlooking\nthe multi-faceted nature of human feedback. In this work, we introduce a\ntheoretical framework for preference-based Multi-Objective Inverse\nReinforcement Learning (MO-IRL), where human preferences are modeled as latent\nvector-valued reward functions. We formalize the problem of recovering a\nPareto-optimal reward representation from noisy preference queries and\nestablish conditions for identifying the underlying multi-objective structure.\nWe derive tight sample complexity bounds for recovering\n$\\epsilon$-approximations of the Pareto front and introduce a regret\nformulation to quantify suboptimality in this multi-objective setting.\nFurthermore, we propose a provably convergent algorithm for policy optimization\nusing preference-inferred reward cones. Our results bridge the gap between\npractical alignment techniques and theoretical guarantees, providing a\nprincipled foundation for learning aligned behaviors in a high-dimension and\nvalue-pluralistic environment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11864v1",
    "published_date": "2025-05-17 06:09:13 UTC",
    "updated_date": "2025-05-17 06:09:13 UTC"
  },
  {
    "arxiv_id": "2505.11862v1",
    "title": "Q-Policy: Quantum-Enhanced Policy Evaluation for Scalable Reinforcement Learning",
    "authors": [
      "Kalyan Cherukuri",
      "Aarav Lala",
      "Yash Yardi"
    ],
    "abstract": "We propose Q-Policy, a hybrid quantum-classical reinforcement learning (RL)\nframework that mathematically accelerates policy evaluation and optimization by\nexploiting quantum computing primitives. Q-Policy encodes value functions in\nquantum superposition, enabling simultaneous evaluation of multiple\nstate-action pairs via amplitude encoding and quantum parallelism. We introduce\na quantum-enhanced policy iteration algorithm with provable polynomial\nreductions in sample complexity for the evaluation step, under standard\nassumptions. To demonstrate the technical feasibility and theoretical soundness\nof our approach, we validate Q-Policy on classical emulations of small discrete\ncontrol tasks. Due to current hardware and simulation limitations, our\nexperiments focus on showcasing proof-of-concept behavior rather than\nlarge-scale empirical evaluation. Our results support the potential of Q-Policy\nas a theoretical foundation for scalable RL on future quantum devices,\naddressing RL scalability challenges beyond classical approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11862v1",
    "published_date": "2025-05-17 06:03:32 UTC",
    "updated_date": "2025-05-17 06:03:32 UTC"
  },
  {
    "arxiv_id": "2505.11861v1",
    "title": "Fair-PP: A Synthetic Dataset for Aligning LLM with Personalized Preferences of Social Equity",
    "authors": [
      "Qi Zhou",
      "Jie Zhang",
      "Dongxia Wang",
      "Qiang Liu",
      "Tianlin Li",
      "Jin Song Dong",
      "Wenhai Wang",
      "Qing Guo"
    ],
    "abstract": "Human preference plays a crucial role in the refinement of large language\nmodels (LLMs). However, collecting human preference feedback is costly and most\nexisting datasets neglect the correlation between personalization and\npreferences. To address this issue, we introduce Fair-PP, a synthetic dataset\nof personalized preferences targeting social equity, derived from real-world\nsocial survey data, which includes 28 social groups, 98 equity topics, and 5\npersonal preference dimensions. Leveraging GPT-4o-mini, we engage in\nrole-playing based on seven representative persona portrayals guided by\nexisting social survey data, yielding a total of 238,623 preference records.\nThrough Fair-PP, we also contribute (i) An automated framework for generating\npreference data, along with a more fine-grained dataset of personalized\npreferences; (ii) analysis of the positioning of the existing mainstream LLMs\nacross five major global regions within the personalized preference space; and\n(iii) a sample reweighting method for personalized preference alignment,\nenabling alignment with a target persona while maximizing the divergence from\nother personas. Empirical experiments show our method outperforms the\nbaselines.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "91C99",
      "I.2.7; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2505.11861v1",
    "published_date": "2025-05-17 06:02:00 UTC",
    "updated_date": "2025-05-17 06:02:00 UTC"
  },
  {
    "arxiv_id": "2505.11854v1",
    "title": "Evaluating the Logical Reasoning Abilities of Large Reasoning Models",
    "authors": [
      "Hanmeng Liu",
      "Yiran Ding",
      "Zhizhang Fu",
      "Chaoli Zhang",
      "Xiaozhang Liu",
      "Yue Zhang"
    ],
    "abstract": "Large reasoning models, often post-trained on long chain-of-thought (long\nCoT) data with reinforcement learning, achieve state-of-the-art performance on\nmathematical, coding, and domain-specific reasoning benchmarks. However, their\nlogical reasoning capabilities - fundamental to human cognition and independent\nof domain knowledge - remain understudied. To address this gap, we introduce\nLogiEval, a holistic benchmark for evaluating logical reasoning in large\nreasoning models. LogiEval spans diverse reasoning types (deductive, inductive,\nanalogical, and abductive) and task formats (e.g., logical sequence, argument\nanalysis), sourced from high-quality human examinations (e.g., LSAT, GMAT). Our\nexperiments demonstrate that modern reasoning models excel at 4-choice argument\nanalysis problems and analogical reasoning, surpassing human performance, yet\nexhibit uneven capabilities across reasoning types and formats, highlighting\nlimitations in their generalization. Our analysis reveals that human\nperformance does not mirror model failure distributions. To foster further\nresearch, we curate LogiEval-Hard, a challenging subset identified through a\nnovel screening paradigm where small-model failures (Qwen3-30B-A3B) reliably\npredict difficulties for larger models. Modern models show striking, consistent\nfailures on LogiEval-Hard. This demonstrates that fundamental reasoning\nbottlenecks persist across model scales, and establishes LogiEval-Hard as both\na diagnostic tool and a rigorous testbed for advancing logical reasoning in\nLLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11854v1",
    "published_date": "2025-05-17 05:36:14 UTC",
    "updated_date": "2025-05-17 05:36:14 UTC"
  },
  {
    "arxiv_id": "2505.11849v1",
    "title": "VeriReason: Reinforcement Learning with Testbench Feedback for Reasoning-Enhanced Verilog Generation",
    "authors": [
      "Yiting Wang",
      "Guoheng Sun",
      "Wanghao Ye",
      "Gang Qu",
      "Ang Li"
    ],
    "abstract": "Automating Register Transfer Level (RTL) code generation using Large Language\nModels (LLMs) offers substantial promise for streamlining digital circuit\ndesign and reducing human effort. However, current LLM-based approaches face\nsignificant challenges with training data scarcity, poor specification-code\nalignment, lack of verification mechanisms, and balancing generalization with\nspecialization. Inspired by DeepSeek-R1, we introduce VeriReason, a framework\nintegrating supervised fine-tuning with Guided Reward Proximal Optimization\n(GRPO) reinforcement learning for RTL generation. Using curated training\nexamples and a feedback-driven reward model, VeriReason combines testbench\nevaluations with structural heuristics while embedding self-checking\ncapabilities for autonomous error correction. On the VerilogEval Benchmark,\nVeriReason delivers significant improvements: achieving 83.1% functional\ncorrectness on the VerilogEval Machine benchmark, substantially outperforming\nboth comparable-sized models and much larger commercial systems like GPT-4\nTurbo. Additionally, our approach demonstrates up to a 2.8X increase in\nfirst-attempt functional correctness compared to baseline methods and exhibits\nrobust generalization to unseen designs. To our knowledge, VeriReason\nrepresents the first system to successfully integrate explicit reasoning\ncapabilities with reinforcement learning for Verilog generation, establishing a\nnew state-of-the-art for automated RTL synthesis. The models and datasets are\navailable at: https://huggingface.co/collections/AI4EDA-CASE Code is Available\nat: https://github.com/NellyW8/VeriReason",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.11849v1",
    "published_date": "2025-05-17 05:25:01 UTC",
    "updated_date": "2025-05-17 05:25:01 UTC"
  },
  {
    "arxiv_id": "2505.14709v1",
    "title": "FastCar: Cache Attentive Replay for Fast Auto-Regressive Video Generation on the Edge",
    "authors": [
      "Xuan Shen",
      "Weize Ma",
      "Yufa Zhou",
      "Enhao Tang",
      "Yanyue Xie",
      "Zhengang Li",
      "Yifan Gong",
      "Quanyi Wang",
      "Henghui Ding",
      "Yiwei Wang",
      "Yanzhi Wang",
      "Pu Zhao",
      "Jun Lin",
      "Jiuxiang Gu"
    ],
    "abstract": "Auto-regressive (AR) models, initially successful in language generation,\nhave recently shown promise in visual generation tasks due to their superior\nsampling efficiency. Unlike image generation, video generation requires a\nsubstantially larger number of tokens to produce coherent temporal frames,\nresulting in significant overhead during the decoding phase. Our key\nobservations are: (i) MLP modules in the decode phase dominate the inference\nlatency, and (ii) there exists high temporal redundancy in MLP outputs of\nadjacent frames. In this paper, we propose the \\textbf{FastCar} framework to\naccelerate the decode phase for the AR video generation by exploring the\ntemporal redundancy. The Temporal Attention Score (TAS) is proposed to\ndetermine whether to apply the replay strategy (\\textit{i.e.}, reusing cached\nMLP outputs from the previous frame to reduce redundant computations) with\ndetailed theoretical analysis and justification. Also, we develop a hardware\naccelerator on FPGA with Dynamic Resource Scheduling (DRS) based on TAS to\nenable better resource utilization and faster inference. Experimental results\ndemonstrate the effectiveness of our method, which outperforms traditional\nsparse attention approaches with more than 2.1x decoding speedup and higher\nenergy efficiency on the edge. Furthermore, by combining FastCar and sparse\nattention, FastCar can boost the performance of sparse attention with\nalleviated drifting, demonstrating our unique advantages for high-resolution\nand long-duration video generation. Code:\nhttps://github.com/shawnricecake/fast-car",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint Version",
    "pdf_url": "http://arxiv.org/pdf/2505.14709v1",
    "published_date": "2025-05-17 05:00:39 UTC",
    "updated_date": "2025-05-17 05:00:39 UTC"
  },
  {
    "arxiv_id": "2505.11839v1",
    "title": "On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study",
    "authors": [
      "Shuai Yang",
      "Qi Yang",
      "Luoxi Tang",
      "Jeremy Blackburn",
      "Zhaohan Xi"
    ],
    "abstract": "Counterfactual reasoning has emerged as a crucial technique for generalizing\nthe reasoning capabilities of large language models (LLMs). By generating and\nanalyzing counterfactual scenarios, researchers can assess the adaptability and\nreliability of model decision-making. Although prior work has shown that LLMs\noften struggle with counterfactual reasoning, it remains unclear which factors\nmost significantly impede their performance across different tasks and\nmodalities. In this paper, we propose a decompositional strategy that breaks\ndown the counterfactual generation from causality construction to the reasoning\nover counterfactual interventions. To support decompositional analysis, we\ninvestigate 11 datasets spanning diverse tasks, including natural language\nunderstanding, mathematics, programming, and vision-language tasks. Through\nextensive evaluations, we characterize LLM behavior across each decompositional\nstage and identify how modality type and intermediate reasoning influence\nperformance. By establishing a structured framework for analyzing\ncounterfactual reasoning, this work contributes to the development of more\nreliable LLM-based reasoning systems and informs future elicitation strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11839v1",
    "published_date": "2025-05-17 04:59:32 UTC",
    "updated_date": "2025-05-17 04:59:32 UTC"
  },
  {
    "arxiv_id": "2505.11837v1",
    "title": "On Membership Inference Attacks in Knowledge Distillation",
    "authors": [
      "Ziyao Cui",
      "Minxing Zhang",
      "Jian Pei"
    ],
    "abstract": "Nowadays, Large Language Models (LLMs) are trained on huge datasets, some\nincluding sensitive information. This poses a serious privacy concern because\nprivacy attacks such as Membership Inference Attacks (MIAs) may detect this\nsensitive information. While knowledge distillation compresses LLMs into\nefficient, smaller student models, its impact on privacy remains underexplored.\nIn this paper, we investigate how knowledge distillation affects model\nrobustness against MIA. We focus on two questions. First, how is private data\nprotected in teacher and student models? Second, how can we strengthen privacy\npreservation against MIAs in knowledge distillation? Through comprehensive\nexperiments, we show that while teacher and student models achieve similar\noverall MIA accuracy, teacher models better protect member data, the primary\ntarget of MIA, whereas student models better protect non-member data. To\naddress this vulnerability in student models, we propose 5 privacy-preserving\ndistillation methods and demonstrate that they successfully reduce student\nmodels' vulnerability to MIA, with ensembling further stabilizing the\nrobustness, offering a reliable approach for distilling more secure and\nefficient student models. Our implementation source code is available at\nhttps://github.com/richardcui18/MIA_in_KD.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11837v1",
    "published_date": "2025-05-17 04:54:26 UTC",
    "updated_date": "2025-05-17 04:54:26 UTC"
  },
  {
    "arxiv_id": "2505.11836v1",
    "title": "SplInterp: Improving our Understanding and Training of Sparse Autoencoders",
    "authors": [
      "Jeremy Budd",
      "Javier Ideami",
      "Benjamin Macdowall Rynne",
      "Keith Duggar",
      "Randall Balestriero"
    ],
    "abstract": "Sparse autoencoders (SAEs) have received considerable recent attention as\ntools for mechanistic interpretability, showing success at extracting\ninterpretable features even from very large LLMs. However, this research has\nbeen largely empirical, and there have been recent doubts about the true\nutility of SAEs. In this work, we seek to enhance the theoretical understanding\nof SAEs, using the spline theory of deep learning. By situating SAEs in this\nframework: we discover that SAEs generalise ``$k$-means autoencoders'' to be\npiecewise affine, but sacrifice accuracy for interpretability vs. the optimal\n``$k$-means-esque plus local principal component analysis (PCA)'' piecewise\naffine autoencoder. We characterise the underlying geometry of (TopK) SAEs\nusing power diagrams. And we develop a novel proximal alternating method SGD\n(PAM-SGD) algorithm for training SAEs, with both solid theoretical foundations\nand promising empirical results in MNIST and LLM experiments, particularly in\nsample efficiency and (in the LLM setting) improved sparsity of codes. All code\nis available at: https://github.com/splInterp2025/splInterp",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 65D07"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages, 38 figures, under review",
    "pdf_url": "http://arxiv.org/pdf/2505.11836v1",
    "published_date": "2025-05-17 04:51:26 UTC",
    "updated_date": "2025-05-17 04:51:26 UTC"
  },
  {
    "arxiv_id": "2505.11835v1",
    "title": "Multilingual Collaborative Defense for Large Language Models",
    "authors": [
      "Hongliang Li",
      "Jinan Xu",
      "Gengping Cui",
      "Changhao Guan",
      "Fengran Mo",
      "Kaiyu Huang"
    ],
    "abstract": "The robustness and security of large language models (LLMs) has become a\nprominent research area. One notable vulnerability is the ability to bypass LLM\nsafeguards by translating harmful queries into rare or underrepresented\nlanguages, a simple yet effective method of \"jailbreaking\" these models.\nDespite the growing concern, there has been limited research addressing the\nsafeguarding of LLMs in multilingual scenarios, highlighting an urgent need to\nenhance multilingual safety. In this work, we investigate the correlation\nbetween various attack features across different languages and propose\nMultilingual Collaborative Defense (MCD), a novel learning method that\noptimizes a continuous, soft safety prompt automatically to facilitate\nmultilingual safeguarding of LLMs. The MCD approach offers three advantages:\nFirst, it effectively improves safeguarding performance across multiple\nlanguages. Second, MCD maintains strong generalization capabilities while\nminimizing false refusal rates. Third, MCD mitigates the language safety\nmisalignment caused by imbalances in LLM training corpora. To evaluate the\neffectiveness of MCD, we manually construct multilingual versions of commonly\nused jailbreak benchmarks, such as MaliciousInstruct and AdvBench, to assess\nvarious safeguarding methods. Additionally, we introduce these datasets in\nunderrepresented (zero-shot) languages to verify the language transferability\nof MCD. The results demonstrate that MCD outperforms existing approaches in\nsafeguarding against multilingual jailbreak attempts while also exhibiting\nstrong language transfer capabilities. Our code is available at\nhttps://github.com/HLiang-Lee/MCD.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 4figures",
    "pdf_url": "http://arxiv.org/pdf/2505.11835v1",
    "published_date": "2025-05-17 04:47:16 UTC",
    "updated_date": "2025-05-17 04:47:16 UTC"
  },
  {
    "arxiv_id": "2505.11833v1",
    "title": "ToLeaP: Rethinking Development of Tool Learning with Large Language Models",
    "authors": [
      "Haotian Chen",
      "Zijun Song",
      "Boye Niu",
      "Ke Zhang",
      "Litu Ou",
      "Yaxi Lu",
      "Zhong Zhang",
      "Xin Cong",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Tool learning, which enables large language models (LLMs) to utilize external\ntools effectively, has garnered increasing attention for its potential to\nrevolutionize productivity across industries. Despite rapid development in tool\nlearning, key challenges and opportunities remain understudied, limiting deeper\ninsights and future advancements. In this paper, we investigate the tool\nlearning ability of 41 prevalent LLMs by reproducing 33 benchmarks and enabling\none-click evaluation for seven of them, forming a Tool Learning Platform named\nToLeaP. We also collect 21 out of 33 potential training datasets to facilitate\nfuture exploration. After analyzing over 3,000 bad cases of 41 LLMs based on\nToLeaP, we identify four main critical challenges: (1) benchmark limitations\ninduce both the neglect and lack of (2) autonomous learning, (3)\ngeneralization, and (4) long-horizon task-solving capabilities of LLMs. To aid\nfuture advancements, we take a step further toward exploring potential\ndirections, namely (1) real-world benchmark construction, (2)\ncompatibility-aware autonomous learning, (3) rationale learning by thinking,\nand (4) identifying and recalling key clues. The preliminary experiments\ndemonstrate their effectiveness, highlighting the need for further research and\nexploration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11833v1",
    "published_date": "2025-05-17 04:39:47 UTC",
    "updated_date": "2025-05-17 04:39:47 UTC"
  },
  {
    "arxiv_id": "2505.11831v1",
    "title": "ARC-AGI-2: A New Challenge for Frontier AI Reasoning Systems",
    "authors": [
      "Francois Chollet",
      "Mike Knoop",
      "Gregory Kamradt",
      "Bryan Landers",
      "Henry Pinkard"
    ],
    "abstract": "The Abstraction and Reasoning Corpus for Artificial General Intelligence\n(ARC-AGI), introduced in 2019, established a challenging benchmark for\nevaluating the general fluid intelligence of artificial systems via a set of\nunique, novel tasks only requiring minimal prior knowledge. While ARC-AGI has\nspurred significant research activity over the past five years, recent AI\nprogress calls for benchmarks capable of finer-grained evaluation at higher\nlevels of cognitive complexity. We introduce ARC-AGI-2, an upgraded version of\nthe benchmark. ARC-AGI-2 preserves the input-output pair task format of its\npredecessor, ensuring continuity for researchers. It incorporates a newly\ncurated and expanded set of tasks specifically designed to provide a more\ngranular signal to assess abstract reasoning and problem-solving abilities at\nhigher levels of fluid intelligence. To contextualize the difficulty and\ncharacteristics of ARC-AGI-2, we present extensive results from human testing,\nproviding a robust baseline that highlights the benchmark's accessibility to\nhuman intelligence, yet difficulty for current AI systems. ARC-AGI-2 aims to\nserve as a next-generation tool for rigorously measuring progress towards more\ngeneral and human-like AI capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11831v1",
    "published_date": "2025-05-17 04:34:48 UTC",
    "updated_date": "2025-05-17 04:34:48 UTC"
  },
  {
    "arxiv_id": "2505.14708v1",
    "title": "DraftAttention: Fast Video Diffusion via Low-Resolution Attention Guidance",
    "authors": [
      "Xuan Shen",
      "Chenxia Han",
      "Yufa Zhou",
      "Yanyue Xie",
      "Yifan Gong",
      "Quanyi Wang",
      "Yiwei Wang",
      "Yanzhi Wang",
      "Pu Zhao",
      "Jiuxiang Gu"
    ],
    "abstract": "Diffusion transformer-based video generation models (DiTs) have recently\nattracted widespread attention for their excellent generation quality. However,\ntheir computational cost remains a major bottleneck-attention alone accounts\nfor over 80% of total latency, and generating just 8 seconds of 720p video\ntakes tens of minutes-posing serious challenges to practical application and\nscalability. To address this, we propose the DraftAttention, a training-free\nframework for the acceleration of video diffusion transformers with dynamic\nsparse attention on GPUs. We apply down-sampling to each feature map across\nframes in the compressed latent space, enabling a higher-level receptive field\nover the latent composed of hundreds of thousands of tokens. The low-resolution\ndraft attention map, derived from draft query and key, exposes redundancy both\nspatially within each feature map and temporally across frames. We reorder the\nquery, key, and value based on the draft attention map to guide the sparse\nattention computation in full resolution, and subsequently restore their\noriginal order after the attention computation. This reordering enables\nstructured sparsity that aligns with hardware-optimized execution. Our\ntheoretical analysis demonstrates that the low-resolution draft attention\nclosely approximates the full attention, providing reliable guidance for\nconstructing accurate sparse attention. Experimental results show that our\nmethod outperforms existing sparse attention approaches in video generation\nquality and achieves up to 1.75x end-to-end speedup on GPUs. Code:\nhttps://github.com/shawnricecake/draft-attention",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint Version",
    "pdf_url": "http://arxiv.org/pdf/2505.14708v1",
    "published_date": "2025-05-17 04:34:34 UTC",
    "updated_date": "2025-05-17 04:34:34 UTC"
  },
  {
    "arxiv_id": "2505.11830v1",
    "title": "CoT-Vid: Dynamic Chain-of-Thought Routing with Self Verification for Training-Free Video Reasoning",
    "authors": [
      "Hongbo Jin",
      "Ruyang Liu",
      "Wenhao Zhang",
      "Guibo Luo",
      "Ge Li"
    ],
    "abstract": "System2 reasoning is developing rapidly these days with the emergence of\nDeep- Thinking Models and chain-of-thought technology, which has become a\ncentralized discussion point in the AI community. However, there is a relative\ngap in the research on complex video reasoning at present. In this work, we\npropose CoT-Vid, a novel training-free paradigm for the video domain with a\nmultistage complex reasoning design. Distinguishing from existing video LLMs,\nwhich rely heavily on perceptual abilities, it achieved surprising performance\ngain with explicit reasoning mechanism. The paradigm consists of three main\ncomponents: dynamic inference path routing, problem decoupling strategy, and\nvideo self-consistency verification. In addition, we propose a new standard for\ncategorization of video questions. CoT- Vid showed outstanding results on a\nwide range of benchmarks, and outperforms its base model by 9.3% on Egochema\nand 5.6% on VideoEspresso, rivalling or even surpassing larger and proprietary\nmodels, such as GPT-4V, GPT-4o and Gemini-1.5-flash. Our codebase will be\npublicly available soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.11830v1",
    "published_date": "2025-05-17 04:34:32 UTC",
    "updated_date": "2025-05-17 04:34:32 UTC"
  },
  {
    "arxiv_id": "2505.11827v1",
    "title": "Not All Thoughts are Generated Equal: Efficient LLM Reasoning via Multi-Turn Reinforcement Learning",
    "authors": [
      "Yansong Ning",
      "Wei Li",
      "Jun Fang",
      "Naiqiang Tan",
      "Hao Liu"
    ],
    "abstract": "Compressing long chain-of-thought (CoT) from large language models (LLMs) is\nan emerging strategy to improve the reasoning efficiency of LLMs. Despite its\npromising benefits, existing studies equally compress all thoughts within a\nlong CoT, hindering more concise and effective reasoning. To this end, we first\ninvestigate the importance of different thoughts by examining their\neffectiveness and efficiency in contributing to reasoning through automatic\nlong CoT chunking and Monte Carlo rollouts. Building upon the insights, we\npropose a theoretically bounded metric to jointly measure the effectiveness and\nefficiency of different thoughts. We then propose Long$\\otimes$Short, an\nefficient reasoning framework that enables two LLMs to collaboratively solve\nthe problem: a long-thought LLM for more effectively generating important\nthoughts, while a short-thought LLM for efficiently generating remaining\nthoughts. Specifically, we begin by synthesizing a small amount of cold-start\ndata to fine-tune LLMs for long-thought and short-thought reasoning styles,\nrespectively. Furthermore, we propose a synergizing-oriented multi-turn\nreinforcement learning, focusing on the model self-evolution and collaboration\nbetween long-thought and short-thought LLMs. Experimental results show that our\nmethod enables Qwen2.5-7B and Llama3.1-8B to achieve comparable performance\ncompared to DeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B, while\nreducing token length by over 80% across the MATH500, AIME24/25, AMC23, and\nGPQA Diamond benchmarks. Our data and code are available at\nhttps://github.com/yasNing/Long-otimes-Short/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "In progress",
    "pdf_url": "http://arxiv.org/pdf/2505.11827v1",
    "published_date": "2025-05-17 04:26:39 UTC",
    "updated_date": "2025-05-17 04:26:39 UTC"
  },
  {
    "arxiv_id": "2505.11825v1",
    "title": "Bootstrapping Diffusion: Diffusion Model Training Leveraging Partial and Corrupted Data",
    "authors": [
      "Xudong Ma"
    ],
    "abstract": "Training diffusion models requires large datasets. However, acquiring large\nvolumes of high-quality data can be challenging, for example, collecting large\nnumbers of high-resolution images and long videos. On the other hand, there are\nmany complementary data that are usually considered corrupted or partial, such\nas low-resolution images and short videos. Other examples of corrupted data\ninclude videos that contain subtitles, watermarks, and logos. In this study, we\ninvestigate the theoretical problem of whether the above partial data can be\nutilized to train conventional diffusion models. Motivated by our theoretical\nanalysis in this study, we propose a straightforward approach of training\ndiffusion models utilizing partial data views, where we consider each form of\ncomplementary data as a view of conventional data. Our proposed approach first\ntrains one separate diffusion model for each individual view, and then trains a\nmodel for predicting the residual score function. We prove generalization error\nbounds, which show that the proposed diffusion model training approach can\nachieve lower generalization errors if proper regularizations are adopted in\nthe residual score function training. In particular, we prove that the\ndifficulty in training the residual score function scales proportionally with\nthe signal correlations not captured by partial data views. Consequently, the\nproposed approach achieves near first-order optimal data efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2505.11825v1",
    "published_date": "2025-05-17 04:17:48 UTC",
    "updated_date": "2025-05-17 04:17:48 UTC"
  },
  {
    "arxiv_id": "2505.11824v1",
    "title": "Search-Based Correction of Reasoning Chains for Language Models",
    "authors": [
      "Minsu Kim",
      "Jean-Pierre Falet",
      "Oliver E. Richardson",
      "Xiaoyin Chen",
      "Moksh Jain",
      "Sungjin Ahn",
      "Sungsoo Ahn",
      "Yoshua Bengio"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning has advanced the capabilities and\ntransparency of language models (LMs); however, reasoning chains can contain\ninaccurate statements that reduce performance and trustworthiness. To address\nthis, we introduce a new self-correction framework that augments each reasoning\nstep in a CoT with a latent variable indicating its veracity, enabling modeling\nof all possible truth assignments rather than assuming correctness throughout.\nTo efficiently explore this expanded space, we introduce Search Corrector, a\ndiscrete search algorithm over boolean-valued veracity assignments. It\nefficiently performs otherwise intractable inference in the posterior\ndistribution over veracity assignments by leveraging the LM's joint likelihood\nover veracity and the final answer as a proxy reward. This efficient\ninference-time correction method facilitates supervised fine-tuning of an\nAmortized Corrector by providing pseudo-labels for veracity. The Amortized\nCorrector generalizes self-correction, enabling accurate zero-shot veracity\ninference in novel contexts. Empirical results demonstrate that Search\nCorrector reliably identifies errors in logical (ProntoQA) and mathematical\nreasoning (GSM8K) benchmarks. The Amortized Corrector achieves comparable\nzero-shot accuracy and improves final answer accuracy by up to 25%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11824v1",
    "published_date": "2025-05-17 04:16:36 UTC",
    "updated_date": "2025-05-17 04:16:36 UTC"
  },
  {
    "arxiv_id": "2505.13516v1",
    "title": "HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems",
    "authors": [
      "Zhipeng Hou",
      "Junyi Tang",
      "Yipeng Wang"
    ],
    "abstract": "Recent advancements in Multi-Agent Systems (MAS) powered by Large Language\nModels (LLMs) have demonstrated tremendous potential in diverse task scenarios.\nNonetheless, existing agentic systems typically rely on predefined agent-role\ndesign spaces and static communication structures, limiting their adaptability\nas well as flexibility in complex interaction environments and leading to\nsubpar performance on highly specialized and expert-level tasks. To address\nthese issues, we introduce HALO, a multi-agent collaboration framework based on\na hierarchical reasoning architecture. Specifically, we incorporate a\nhigh-level planning agent for task decomposition, mid-level role-design agents\nfor subtask-specific agent instantiation, and low-level inference agents for\nsubtask execution. Particularly, subtask execution is reformulated as a\nstructured workflow search problem, where Monte Carlo Tree Search (MCTS)\nsystematically explores the agentic action space to construct optimal reasoning\ntrajectories. Additionally, as the majority of users lack expertise in prompt\nengineering, we leverage an Adaptive Prompt Refinement module to transform raw\nqueries into task-specific prompts. Empirical evaluations on Code Generation\n(HumanEval), General Reasoning (MMLU), and Arithmetic Reasoning (MATH)\nbenchmark datasets highlight the effectiveness of HALO, yielding a 14.4%\naverage improvement over state-of-the-art baselines. Notably, HALO achieves up\nto 13.3% performance gain on the Moral Scenarios subject in the MMLU benchmark\nand up to 19.6% performance gain on the Algebra subarea in the MATH benchmark,\nindicating its advanced proficiency in tackling highly specialized and\nexpert-level tasks. The code repository is available at\nhttps://github.com/23japhone/HALO.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "The code repository is available at https://github.com/23japhone/HALO",
    "pdf_url": "http://arxiv.org/pdf/2505.13516v1",
    "published_date": "2025-05-17 04:14:03 UTC",
    "updated_date": "2025-05-17 04:14:03 UTC"
  },
  {
    "arxiv_id": "2505.13515v1",
    "title": "LoRASuite: Efficient LoRA Adaptation Across Large Language Model Upgrades",
    "authors": [
      "Yanan Li",
      "Fanxu Meng",
      "Muhan Zhang",
      "Shiai Zhu",
      "Shangguang Wang",
      "Mengwei Xu"
    ],
    "abstract": "As Large Language Models (LLMs) are frequently updated, LoRA weights trained\non earlier versions quickly become obsolete. The conventional practice of\nretraining LoRA weights from scratch on the latest model is costly,\ntime-consuming, and environmentally detrimental, particularly as the diversity\nof LLMs and downstream tasks expands. This motivates a critical question: \"How\ncan we efficiently leverage existing LoRA weights to adapt to newer model\nversions?\" To address this, we propose LoRASuite, a modular approach tailored\nspecifically to various types of LLM updates. First, we compute a transfer\nmatrix utilizing known parameters from both old and new LLMs. Next, we allocate\ncorresponding layers and attention heads based on centered kernel alignment and\ncosine similarity metrics, respectively. A subsequent small-scale, skillful\nfine-tuning step ensures numerical stability. Experimental evaluations\ndemonstrate that LoRASuite consistently surpasses small-scale vanilla LoRA\nmethods. Notably, on backbone LLMs such as MiniCPM and Qwen, LoRASuite even\nexceeds the performance of full-scale LoRA retraining, with average\nimprovements of +1.4 and +6.6 points on math tasks, respectively. Additionally,\nLoRASuite significantly reduces memory consumption by 5.5 GB and computational\ntime by 78.23%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13515v1",
    "published_date": "2025-05-17 04:11:17 UTC",
    "updated_date": "2025-05-17 04:11:17 UTC"
  },
  {
    "arxiv_id": "2505.11814v1",
    "title": "ChatHTN: Interleaving Approximate (LLM) and Symbolic HTN Planning",
    "authors": [
      "Hector Munoz-Avila",
      "David W. Aha",
      "Paola Rizzo"
    ],
    "abstract": "We introduce ChatHTN, a Hierarchical Task Network (HTN) planner that combines\nsymbolic HTN planning techniques with queries to ChatGPT to approximate\nsolutions in the form of task decompositions. The resulting hierarchies\ninterleave task decompositions generated by symbolic HTN planning with those\ngenerated by ChatGPT. Despite the approximate nature of the results generates\nby ChatGPT, ChatHTN is provably sound; any plan it generates correctly achieves\nthe input tasks. We demonstrate this property with an open-source\nimplementation of our system.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2nd International Conference on Neuro-symbolic Systems (NeuS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.11814v1",
    "published_date": "2025-05-17 03:53:08 UTC",
    "updated_date": "2025-05-17 03:53:08 UTC"
  },
  {
    "arxiv_id": "2505.11813v1",
    "title": "SGD-Mix: Enhancing Domain-Specific Image Classification with Label-Preserving Data Augmentation",
    "authors": [
      "Yixuan Dong",
      "Fang-Yi Su",
      "Jung-Hsien Chiang"
    ],
    "abstract": "Data augmentation for domain-specific image classification tasks often\nstruggles to simultaneously address diversity, faithfulness, and label clarity\nof generated data, leading to suboptimal performance in downstream tasks. While\nexisting generative diffusion model-based methods aim to enhance augmentation,\nthey fail to cohesively tackle these three critical aspects and often overlook\nintrinsic challenges of diffusion models, such as sensitivity to model\ncharacteristics and stochasticity under strong transformations. In this paper,\nwe propose a novel framework that explicitly integrates diversity,\nfaithfulness, and label clarity into the augmentation process. Our approach\nemploys saliency-guided mixing and a fine-tuned diffusion model to preserve\nforeground semantics, enrich background diversity, and ensure label\nconsistency, while mitigating diffusion model limitations. Extensive\nexperiments across fine-grained, long-tail, few-shot, and background robustness\ntasks demonstrate our method's superior performance over state-of-the-art\napproaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.11813v1",
    "published_date": "2025-05-17 03:51:18 UTC",
    "updated_date": "2025-05-17 03:51:18 UTC"
  },
  {
    "arxiv_id": "2505.11807v1",
    "title": "Retrospex: Language Agent Meets Offline Reinforcement Learning Critic",
    "authors": [
      "Yufei Xiang",
      "Yiqun Shen",
      "Yeqin Zhang",
      "Cam-Tu Nguyen"
    ],
    "abstract": "Large Language Models (LLMs) possess extensive knowledge and commonsense\nreasoning capabilities, making them valuable for creating powerful agents.\nHowever, existing LLM agent frameworks have not fully utilized past experiences\nfor improvement. This work introduces a new LLM-based agent framework called\nRetrospex, which addresses this challenge by analyzing past experiences in\ndepth. Unlike previous approaches, Retrospex does not directly integrate\nexperiences into the LLM's context. Instead, it combines the LLM's action\nlikelihood with action values estimated by a Reinforcement Learning (RL)\nCritic, which is trained on past experiences through an offline\n''retrospection'' process. Additionally, Retrospex employs a dynamic action\nrescoring mechanism that increases the importance of experience-based values\nfor tasks that require more interaction with the environment. We evaluate\nRetrospex in ScienceWorld, ALFWorld and Webshop environments, demonstrating its\nadvantages over strong, contemporary baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.11807v1",
    "published_date": "2025-05-17 03:28:24 UTC",
    "updated_date": "2025-05-17 03:28:24 UTC"
  },
  {
    "arxiv_id": "2505.11804v1",
    "title": "Are vision language models robust to uncertain inputs?",
    "authors": [
      "Xi Wang",
      "Eric Nalisnick"
    ],
    "abstract": "Robustness against uncertain and ambiguous inputs is a critical challenge for\ndeep learning models. While recent advancements in large scale vision language\nmodels (VLMs, e.g. GPT4o) might suggest that increasing model and training\ndataset size would mitigate this issue, our empirical evaluation shows a more\ncomplicated picture. Testing models using two classic uncertainty\nquantification tasks, anomaly detection and classification under inherently\nambiguous conditions, we find that newer and larger VLMs indeed exhibit\nimproved robustness compared to earlier models, but still suffer from a\ntendency to strictly follow instructions, often causing them to hallucinate\nconfident responses even when faced with unclear or anomalous inputs.\nRemarkably, for natural images such as ImageNet, this limitation can be\novercome without pipeline modifications: simply prompting models to abstain\nfrom uncertain predictions enables significant reliability gains, achieving\nnear-perfect robustness in several settings. However, for domain-specific tasks\nsuch as galaxy morphology classification, a lack of specialized knowledge\nprevents reliable uncertainty estimation. Finally, we propose a novel mechanism\nbased on caption diversity to reveal a model's internal uncertainty, enabling\npractitioners to predict when models will successfully abstain without relying\non labeled data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11804v1",
    "published_date": "2025-05-17 03:16:49 UTC",
    "updated_date": "2025-05-17 03:16:49 UTC"
  },
  {
    "arxiv_id": "2505.11803v1",
    "title": "VITA: Versatile Time Representation Learning for Temporal Hyper-Relational Knowledge Graphs",
    "authors": [
      "ChongIn Un",
      "Yuhuan Lu",
      "Tianyue Yang",
      "Dingqi Yang"
    ],
    "abstract": "Knowledge graphs (KGs) have become an effective paradigm for managing\nreal-world facts, which are not only complex but also dynamically evolve over\ntime. The temporal validity of facts often serves as a strong clue in\ndownstream link prediction tasks, which predicts a missing element in a fact.\nTraditional link prediction techniques on temporal KGs either consider a\nsequence of temporal snapshots of KGs with an ad-hoc defined time interval or\nexpand a temporal fact over its validity period under a predefined time\ngranularity; these approaches not only suffer from the sensitivity of the\nselection of time interval/granularity, but also face the computational\nchallenges when handling facts with long (even infinite) validity. Although the\nrecent hyper-relational KGs represent the temporal validity of a fact as\nqualifiers describing the fact, it is still suboptimal due to its ignorance of\nthe infinite validity of some facts and the insufficient information encoded\nfrom the qualifiers about the temporal validity. Against this background, we\npropose VITA, a $\\underline{V}$ersatile t$\\underline{I}$me\nrepresen$\\underline{TA}$tion learning method for temporal hyper-relational\nknowledge graphs. We first propose a versatile time representation that can\nflexibly accommodate all four types of temporal validity of facts (i.e., since,\nuntil, period, time-invariant), and then design VITA to effectively learn the\ntime information in both aspects of time value and timespan to boost the link\nprediction performance. We conduct a thorough evaluation of VITA compared to a\nsizable collection of baselines on real-world KG datasets. Results show that\nVITA outperforms the best-performing baselines in various link prediction tasks\n(predicting missing entities, relations, time, and other numeric literals) by\nup to 75.3%. Ablation studies and a case study also support our key design\nchoices.",
    "categories": [
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11803v1",
    "published_date": "2025-05-17 03:16:13 UTC",
    "updated_date": "2025-05-17 03:16:13 UTC"
  },
  {
    "arxiv_id": "2505.11802v1",
    "title": "Diffmv: A Unified Diffusion Framework for Healthcare Predictions with Random Missing Views and View Laziness",
    "authors": [
      "Chuang Zhao",
      "Hui Tang",
      "Hongke Zhao",
      "Xiaomeng Li"
    ],
    "abstract": "Advanced healthcare predictions offer significant improvements in patient\noutcomes by leveraging predictive analytics. Existing works primarily utilize\nvarious views of Electronic Health Record (EHR) data, such as diagnoses, lab\ntests, or clinical notes, for model training. These methods typically assume\nthe availability of complete EHR views and that the designed model could fully\nleverage the potential of each view. However, in practice, random missing views\nand view laziness present two significant challenges that hinder further\nimprovements in multi-view utilization. To address these challenges, we\nintroduce Diffmv, an innovative diffusion-based generative framework designed\nto advance the exploitation of multiple views of EHR data. Specifically, to\naddress random missing views, we integrate various views of EHR data into a\nunified diffusion-denoising framework, enriched with diverse contextual\nconditions to facilitate progressive alignment and view transformation. To\nmitigate view laziness, we propose a novel reweighting strategy that assesses\nthe relative advantages of each view, promoting a balanced utilization of\nvarious data views within the model. Our proposed strategy achieves superior\nperformance across multiple health prediction tasks derived from three popular\ndatasets, including multi-view and multi-modality scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "SIGKDD2025, accepted",
    "pdf_url": "http://arxiv.org/pdf/2505.11802v1",
    "published_date": "2025-05-17 03:15:55 UTC",
    "updated_date": "2025-05-17 03:15:55 UTC"
  },
  {
    "arxiv_id": "2505.13514v1",
    "title": "Induction Head Toxicity Mechanistically Explains Repetition Curse in Large Language Models",
    "authors": [
      "Shuxun Wang",
      "Qingyu Yin",
      "Chak Tou Leong",
      "Qiang Zhang",
      "Linyi Yang"
    ],
    "abstract": "Repetition curse is a phenomenon where Large Language Models (LLMs) generate\nrepetitive sequences of tokens or cyclic sequences. While the repetition curse\nhas been widely observed, its underlying mechanisms remain poorly understood.\nIn this work, we investigate the role of induction heads--a specific type of\nattention head known for their ability to perform in-context learning--in\ndriving this repetitive behavior. Specifically, we focus on the \"toxicity\" of\ninduction heads, which we define as their tendency to dominate the model's\noutput logits during repetition, effectively excluding other attention heads\nfrom contributing to the generation process. Our findings have important\nimplications for the design and training of LLMs. By identifying induction\nheads as a key driver of the repetition curse, we provide a mechanistic\nexplanation for this phenomenon and suggest potential avenues for mitigation.\nWe also propose a technique with attention head regularization that could be\nemployed to reduce the dominance of induction heads during generation, thereby\npromoting more diverse and coherent outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.13514v1",
    "published_date": "2025-05-17 03:09:33 UTC",
    "updated_date": "2025-05-17 03:09:33 UTC"
  },
  {
    "arxiv_id": "2505.11793v1",
    "title": "CL-CaGAN: Capsule differential adversarial continuous learning for cross-domain hyperspectral anomaly detection",
    "authors": [
      "Jianing Wang",
      "Siying Guo",
      "Zheng Hua",
      "Runhu Huang",
      "Jinyu Hu",
      "Maoguo Gong"
    ],
    "abstract": "Anomaly detection (AD) has attracted remarkable attention in hyperspectral\nimage (HSI) processing fields, and most existing deep learning (DL)-based\nalgorithms indicate dramatic potential for detecting anomaly samples through\nspecific training process under current scenario. However, the limited prior\ninformation and the catastrophic forgetting problem indicate crucial challenges\nfor existing DL structure in open scenarios cross-domain detection. In order to\nimprove the detection performance, a novel continual learning-based capsule\ndifferential generative adversarial network (CL-CaGAN) is proposed to elevate\nthe cross-scenario learning performance for facilitating the real application\nof DL-based structure in hyperspectral AD (HAD) task. First, a modified capsule\nstructure with adversarial learning network is constructed to estimate the\nbackground distribution for surmounting the deficiency of prior information. To\nmitigate the catastrophic forgetting phenomenon, clustering-based sample replay\nstrategy and a designed extra self-distillation regularization are integrated\nfor merging the history and future knowledge in continual AD task, while the\ndiscriminative learning ability from previous detection scenario to current\nscenario is retained by the elaborately designed structure with continual\nlearning (CL) strategy. In addition, the differentiable enhancement is enforced\nto augment the generation performance of the training data. This further\nstabilizes the training process with better convergence and efficiently\nconsolidates the reconstruction ability of background samples. To verify the\neffectiveness of our proposed CL-CaGAN, we conduct experiments on several real\nHSIs, and the results indicate that the proposed CL-CaGAN demonstrates higher\ndetection performance and continuous learning capacity for mitigating the\ncatastrophic forgetting under cross-domain scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11793v1",
    "published_date": "2025-05-17 02:32:41 UTC",
    "updated_date": "2025-05-17 02:32:41 UTC"
  },
  {
    "arxiv_id": "2505.11792v1",
    "title": "Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling",
    "authors": [
      "Yitian Chen",
      "Jingfan Xia",
      "Siyu Shao",
      "Dongdong Ge",
      "Yinyu Ye"
    ],
    "abstract": "Optimization modeling is fundamental to decision-making across diverse\ndomains.Despite progress in automating optimization formulation from natural\nlanguage descriptions, Large Language Models (LLMs) often struggle to generate\nformally correct and usable models due to hallucinations, posing a challenge\nfor reliable automation. Inspired by the success of Reinforcement Learning (RL)\nin enhancing Large Reasoning Models, we present Solver-Informed Reinforcement\nLearning (SIRL).This novel framework leverages external optimization solvers as\nverifiable reward mechanisms to significantly improve the authenticity of LLMs\nfor optimization modeling.Acting as precise verifiers, these solvers\nautomatically assess the executable code and the instance-level mathematical\nmodel represented by the associated LP file, yielding precise and comprehensive\nfeedback signals -- including syntax, feasibility, and solution quality that\ndirectly inform the RL process. This automated verification process, powered by\nclassic optimization solvers, also underpins our instance-enhanced\nself-consistency method to synthesize high-quality training data. Extensive\nexperiments on diverse public benchmarks demonstrate that SIRL achieves\nstate-of-the-art performance, substantially outperforming existing methods in\ngenerating accurate and executable optimization models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11792v1",
    "published_date": "2025-05-17 02:32:03 UTC",
    "updated_date": "2025-05-17 02:32:03 UTC"
  },
  {
    "arxiv_id": "2505.11785v1",
    "title": "Improving Coverage in Combined Prediction Sets with Weighted p-values",
    "authors": [
      "Gina Wong",
      "Drew Prinster",
      "Suchi Saria",
      "Rama Chellappa",
      "Anqi Liu"
    ],
    "abstract": "Conformal prediction quantifies the uncertainty of machine learning models by\naugmenting point predictions with valid prediction sets, assuming\nexchangeability. For complex scenarios involving multiple trials, models, or\ndata sources, conformal prediction sets can be aggregated to create a\nprediction set that captures the overall uncertainty, often improving\nprecision. However, aggregating multiple prediction sets with individual\n$1-\\alpha$ coverage inevitably weakens the overall guarantee, typically\nresulting in $1-2\\alpha$ worst-case coverage. In this work, we propose a\nframework for the weighted aggregation of prediction sets, where weights are\nassigned to each prediction set based on their contribution. Our framework\noffers flexible control over how the sets are aggregated, achieving tighter\ncoverage bounds that interpolate between the $1-2\\alpha$ guarantee of the\ncombined models and the $1-\\alpha$ guarantee of an individual model depending\non the distribution of weights. We extend our framework to data-dependent\nweights, and we derive a general procedure for data-dependent weight\naggregation that maintains finite-sample validity. We demonstrate the\neffectiveness of our methods through experiments on synthetic and real data in\nthe mixture-of-experts setting, and we show that aggregation with\ndata-dependent weights provides a form of adaptive coverage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11785v1",
    "published_date": "2025-05-17 01:51:28 UTC",
    "updated_date": "2025-05-17 01:51:28 UTC"
  },
  {
    "arxiv_id": "2505.11780v1",
    "title": "A Review and Analysis of a Parallel Approach for Decision Tree Learning from Large Data Streams",
    "authors": [
      "Zeinab Shiralizadeh"
    ],
    "abstract": "This work studies one of the parallel decision tree learning algorithms,\npdsCART, designed for scalable and efficient data analysis. The method\nincorporates three core capabilities. First, it supports real-time learning\nfrom data streams, allowing trees to be constructed incrementally. Second, it\nenables parallel processing of high-volume streaming data, making it\nwell-suited for large-scale applications. Third, the algorithm integrates\nseamlessly into the MapReduce framework, ensuring compatibility with\ndistributed computing environments. In what follows, we present the algorithm's\nkey components along with results highlighting its performance and scalability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11780v1",
    "published_date": "2025-05-17 01:07:25 UTC",
    "updated_date": "2025-05-17 01:07:25 UTC"
  },
  {
    "arxiv_id": "2505.11776v1",
    "title": "Generative and Contrastive Graph Representation Learning",
    "authors": [
      "Jiali Chen",
      "Avijit Mukherjee"
    ],
    "abstract": "Self-supervised learning (SSL) on graphs generates node and graph\nrepresentations (i.e., embeddings) that can be used for downstream tasks such\nas node classification, node clustering, and link prediction. Graph SSL is\nparticularly useful in scenarios with limited or no labeled data. Existing SSL\nmethods predominantly follow contrastive or generative paradigms, each\nexcelling in different tasks: contrastive methods typically perform well on\nclassification tasks, while generative methods often excel in link prediction.\nIn this paper, we present a novel architecture for graph SSL that integrates\nthe strengths of both approaches. Our framework introduces community-aware\nnode-level contrastive learning, providing more robust and effective positive\nand negative node pairs generation, alongside graph-level contrastive learning\nto capture global semantic information. Additionally, we employ a comprehensive\naugmentation strategy that combines feature masking, node perturbation, and\nedge perturbation, enabling robust and diverse representation learning. By\nincorporating these enhancements, our model achieves superior performance\nacross multiple tasks, including node classification, clustering, and link\nprediction. Evaluations on open benchmark datasets demonstrate that our model\noutperforms state-of-the-art methods, achieving a performance lift of\n0.23%-2.01% depending on the task and dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.4, I2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.11776v1",
    "published_date": "2025-05-17 01:02:22 UTC",
    "updated_date": "2025-05-17 01:02:22 UTC"
  },
  {
    "arxiv_id": "2505.11774v1",
    "title": "HARDMath2: A Benchmark for Applied Mathematics Built by Students as Part of a Graduate Class",
    "authors": [
      "James V. Roggeveen",
      "Erik Y. Wang",
      "Will Flintoft",
      "Peter Donets",
      "Lucy S. Nathwani",
      "Nickholas Gutierrez",
      "David Ettel",
      "Anton Marius Graf",
      "Siddharth Dandavate",
      "Arjun Nageswaran",
      "Raglan Ward",
      "Ava Williamson",
      "Anne Mykland",
      "Kacper K. Migacz",
      "Yijun Wang",
      "Egemen Bostan",
      "Duy Thuc Nguyen",
      "Zhe He",
      "Marc L. Descoteaux",
      "Felix Yeung",
      "Shida Liu",
      "Jorge García Ponce",
      "Luke Zhu",
      "Yuyang Chen",
      "Ekaterina S. Ivshina",
      "Miguel Fernandez",
      "Minjae Kim",
      "Kennan Gumbs",
      "Matthew Scott Tan",
      "Russell Yang",
      "Mai Hoang",
      "David Brown",
      "Isabella A. Silveira",
      "Lavon Sykes",
      "Ahmed Roman",
      "William Fredenberg",
      "Yiming Chen",
      "Lucas Martin",
      "Yixing Tang",
      "Kelly Werker Smith",
      "Hongyu Liao",
      "Logan G. Wilson",
      "Alexander Dazhen Cai",
      "Andrea Elizabeth Biju",
      "Michael P. Brenner"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable progress in mathematical\nproblem-solving, but evaluation has largely focused on problems that have exact\nanalytical solutions or involve formal proofs, often overlooking\napproximation-based problems ubiquitous in applied science and engineering. To\nfill this gap, we build on prior work and present HARDMath2, a dataset of 211\noriginal problems covering the core topics in an introductory graduate applied\nmath class, including boundary-layer analysis, WKB methods, asymptotic\nsolutions of nonlinear partial differential equations, and the asymptotics of\noscillatory integrals. This dataset was designed and verified by the students\nand instructors of a core graduate applied mathematics course at Harvard. We\nbuild the dataset through a novel collaborative environment that challenges\nstudents to write and refine difficult problems consistent with the class\nsyllabus, peer-validate solutions, test different models, and automatically\ncheck LLM-generated solutions against their own answers and numerical ground\ntruths. Evaluation results show that leading frontier models still struggle\nwith many of the problems in the dataset, highlighting a gap in the\nmathematical reasoning skills of current LLMs. Importantly, students identified\nstrategies to create increasingly difficult problems by interacting with the\nmodels and exploiting common failure modes. This back-and-forth with the models\nnot only resulted in a richer and more challenging benchmark but also led to\nqualitative improvements in the students' understanding of the course material,\nwhich is increasingly important as we enter an age where state-of-the-art\nlanguage models can solve many challenging problems across a wide domain of\nfields.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11774v1",
    "published_date": "2025-05-17 00:52:49 UTC",
    "updated_date": "2025-05-17 00:52:49 UTC"
  },
  {
    "arxiv_id": "2505.11771v1",
    "title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer",
    "authors": [
      "Yichen Xu",
      "Ryumei Nakada",
      "Linjun Zhang",
      "Lexin Li"
    ],
    "abstract": "Transfer learning typically leverages representations learned from a source\ndomain to improve performance on a target task. A common approach is to extract\nfeatures from a pre-trained model and directly apply them for target\nprediction. However, this strategy is prone to negative transfer where the\nsource representation fails to align with the target distribution. In this\narticle, we propose Residual Feature Integration (REFINE), a simple yet\neffective method designed to mitigate negative transfer. Our approach combines\na fixed source-side representation with a trainable target-side encoder and\nfits a shallow neural network on the resulting joint representation, which\nadapts to the target domain while preserving transferable knowledge from the\nsource domain. Theoretically, we prove that REFINE is sufficient to prevent\nnegative transfer under mild conditions, and derive the generalization bound\ndemonstrating its theoretical benefit. Empirically, we show that REFINE\nconsistently enhances performance across diverse application and data\nmodalities including vision, text, and tabular data, and outperforms numerous\nalternative solutions. Our method is lightweight, architecture-agnostic, and\nrobust, making it a valuable addition to the existing transfer learning\ntoolbox.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11771v1",
    "published_date": "2025-05-17 00:36:59 UTC",
    "updated_date": "2025-05-17 00:36:59 UTC"
  },
  {
    "arxiv_id": "2505.11770v1",
    "title": "Internal Causal Mechanisms Robustly Predict Language Model Out-of-Distribution Behaviors",
    "authors": [
      "Jing Huang",
      "Junyi Tao",
      "Thomas Icard",
      "Diyi Yang",
      "Christopher Potts"
    ],
    "abstract": "Interpretability research now offers a variety of techniques for identifying\nabstract internal mechanisms in neural networks. Can such techniques be used to\npredict how models will behave on out-of-distribution examples? In this work,\nwe provide a positive answer to this question. Through a diverse set of\nlanguage modeling tasks--including symbol manipulation, knowledge retrieval,\nand instruction following--we show that the most robust features for\ncorrectness prediction are those that play a distinctive causal role in the\nmodel's behavior. Specifically, we propose two methods that leverage causal\nmechanisms to predict the correctness of model outputs: counterfactual\nsimulation (checking whether key causal variables are realized) and value\nprobing (using the values of those variables to make predictions). Both achieve\nhigh AUC-ROC in distribution and outperform methods that rely on\ncausal-agnostic features in out-of-distribution settings, where predicting\nmodel behaviors is more crucial. Our work thus highlights a novel and\nsignificant application for internal causal analysis of language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.11770v1",
    "published_date": "2025-05-17 00:31:39 UTC",
    "updated_date": "2025-05-17 00:31:39 UTC"
  },
  {
    "arxiv_id": "2505.11766v1",
    "title": "Redefining Neural Operators in $d+1$ Dimensions",
    "authors": [
      "Haoze Song",
      "Zhihao Li",
      "Xiaobo Zhang",
      "Zecheng Gan",
      "Zhilu Lai",
      "Wei Wang"
    ],
    "abstract": "Neural Operators have emerged as powerful tools for learning mappings between\nfunction spaces. Among them, the kernel integral operator has been widely\nvalidated on universally approximating various operators. Although recent\nadvancements following this definition have developed effective modules to\nbetter approximate the kernel function defined on the original domain (with $d$\ndimensions, $d=1, 2, 3...$), the unclarified evolving mechanism in the\nembedding spaces blocks our view to design neural operators that can fully\ncapture the target system evolution.\n  Drawing on recent breakthroughs in quantum simulation of partial differential\nequations (PDEs), we elucidate the linear evolution process in neural\noperators. Based on that, we redefine neural operators on a new $d+1$\ndimensional domain. Within this framework, we implement our proposed\nSchr\\\"odingerised Kernel Neural Operator (SKNO) aligning better with the $d+1$\ndimensional evolution. In experiments, our $d+1$ dimensional evolving linear\nblock performs far better than others. Also, we test SKNO's SOTA performance on\nvarious benchmark tests and also the zero-shot super-resolution task. In\naddition, we analyse the impact of different lifting and recovering operators\non the prediction within the redefined NO framework, reflecting the alignment\nbetween our model and the underlying $d+1$ dimensional evolution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11766v1",
    "published_date": "2025-05-17 00:15:00 UTC",
    "updated_date": "2025-05-17 00:15:00 UTC"
  },
  {
    "arxiv_id": "2505.11765v2",
    "title": "OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration",
    "authors": [
      "Shijun Li",
      "Hilaf Hasson",
      "Joydeep Ghosh"
    ],
    "abstract": "Agents powered by advanced large language models (LLMs) have demonstrated\nimpressive capabilities across diverse complex applications. Recently,\nMulti-Agent Systems (MAS), wherein multiple agents collaborate and communicate\nwith each other, have exhibited enhanced capabilities in complex tasks, such as\nhigh-quality code generation and arithmetic reasoning. However, the development\nof such systems often relies on handcrafted methods, and the literature on\nsystematic design and optimization of LLM-based MAS remains limited.\n  In this work, we introduce OMAC, a general framework designed for holistic\noptimization of LLM-based MAS. Specifically, we identify five key optimization\ndimensions for MAS, encompassing both agent functionality and collaboration\nstructure. Building upon these dimensions, we first propose a general\nalgorithm, utilizing two actors termed the Semantic Initializer and the\nContrastive Comparator, to optimize any single dimension. Then, we present an\nalgorithm for joint optimization across multiple dimensions. Extensive\nexperiments demonstrate the superior performance of OMAC on code generation,\narithmetic reasoning, and general reasoning tasks against state-of-the-art\napproaches.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11765v2",
    "published_date": "2025-05-17 00:13:46 UTC",
    "updated_date": "2025-05-21 21:38:23 UTC"
  },
  {
    "arxiv_id": "2505.11764v1",
    "title": "Towards Universal Semantics With Large Language Models",
    "authors": [
      "Raymond Baartmans",
      "Matthew Raffel",
      "Rahul Vikram",
      "Aiden Deringer",
      "Lizhong Chen"
    ],
    "abstract": "The Natural Semantic Metalanguage (NSM) is a linguistic theory based on a\nuniversal set of semantic primes: simple, primitive word-meanings that have\nbeen shown to exist in most, if not all, languages of the world. According to\nthis framework, any word, regardless of complexity, can be paraphrased using\nthese primes, revealing a clear and universally translatable meaning. These\nparaphrases, known as explications, can offer valuable applications for many\nnatural language processing (NLP) tasks, but producing them has traditionally\nbeen a slow, manual process. In this work, we present the first study of using\nlarge language models (LLMs) to generate NSM explications. We introduce\nautomatic evaluation methods, a tailored dataset for training and evaluation,\nand fine-tuned models for this task. Our 1B and 8B models outperform GPT-4o in\nproducing accurate, cross-translatable explications, marking a significant step\ntoward universal semantic representation with LLMs and opening up new\npossibilities for applications in semantic analysis, translation, and beyond.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.11764v1",
    "published_date": "2025-05-17 00:11:58 UTC",
    "updated_date": "2025-05-17 00:11:58 UTC"
  }
]