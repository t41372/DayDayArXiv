[
  {
    "arxiv_id": "2411.10895v1",
    "title": "Evolution of IVR building techniques: from code writing to AI-powered automation",
    "authors": [
      "Khushbu Mehboob Shaikh",
      "Georgios Giannakopoulos"
    ],
    "abstract": "Interactive Voice Response (IVR) systems have undergone significant\ntransformation in recent years, moving from traditional code-based development\nto more user-friendly approaches leveraging widgets and, most recently,\nharnessing the power of Artificial Intelligence (AI) for automated IVR flow\ncreation. This paper explores the evolution of IVR building techniques,\nhighlighting the industry's revolution and shaping the future of IVR systems.\nThe authors delve into the historical context, current trends, and future\nprospects of IVR development, elucidating the impact of AI on simplifying IVR\ncreation processes and enhancing customer experiences.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.10895v1",
    "published_date": "2024-11-16 21:47:10 UTC",
    "updated_date": "2024-11-16 21:47:10 UTC"
  },
  {
    "arxiv_id": "2411.10888v1",
    "title": "MpoxVLM: A Vision-Language Model for Diagnosing Skin Lesions from Mpox Virus Infection",
    "authors": [
      "Xu Cao",
      "Wenqian Ye",
      "Kenny Moise",
      "Megan Coffee"
    ],
    "abstract": "In the aftermath of the COVID-19 pandemic and amid accelerating climate\nchange, emerging infectious diseases, particularly those arising from zoonotic\nspillover, remain a global threat. Mpox (caused by the monkeypox virus) is a\nnotable example of a zoonotic infection that often goes undiagnosed, especially\nas its rash progresses through stages, complicating detection across diverse\npopulations with different presentations. In August 2024, the WHO\nDirector-General declared the mpox outbreak a public health emergency of\ninternational concern for a second time. Despite the deployment of deep\nlearning techniques for detecting diseases from skin lesion images, a robust\nand publicly accessible foundation model for mpox diagnosis is still lacking\ndue to the unavailability of open-source mpox skin lesion images, multimodal\nclinical data, and specialized training pipelines. To address this gap, we\npropose MpoxVLM, a vision-language model (VLM) designed to detect mpox by\nanalyzing both skin lesion images and patient clinical information. MpoxVLM\nintegrates the CLIP visual encoder, an enhanced Vision Transformer (ViT)\nclassifier for skin lesions, and LLaMA-2-7B models, pre-trained and fine-tuned\non visual instruction-following question-answer pairs from our newly released\nmpox skin lesion dataset. Our work achieves 90.38% accuracy for mpox detection,\noffering a promising pathway to improve early diagnostic accuracy in combating\nmpox.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by ML4H 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.10888v1",
    "published_date": "2024-11-16 21:09:04 UTC",
    "updated_date": "2024-11-16 21:09:04 UTC"
  },
  {
    "arxiv_id": "2411.10886v2",
    "title": "MetricGold: Leveraging Text-To-Image Latent Diffusion Models for Metric Depth Estimation",
    "authors": [
      "Ansh Shah",
      "K Madhava Krishna"
    ],
    "abstract": "Recovering metric depth from a single image remains a fundamental challenge\nin computer vision, requiring both scene understanding and accurate scaling.\nWhile deep learning has advanced monocular depth estimation, current models\noften struggle with unfamiliar scenes and layouts, particularly in zero-shot\nscenarios and when predicting scale-ergodic metric depth. We present\nMetricGold, a novel approach that harnesses generative diffusion model's rich\npriors to improve metric depth estimation. Building upon recent advances in\nMariGold, DDVM and Depth Anything V2 respectively, our method combines latent\ndiffusion, log-scaled metric depth representation, and synthetic data training.\nMetricGold achieves efficient training on a single RTX 3090 within two days\nusing photo-realistic synthetic data from HyperSIM, VirtualKitti, and\nTartanAir. Our experiments demonstrate robust generalization across diverse\ndatasets, producing sharper and higher quality metric depth estimates compared\nto existing approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10886v2",
    "published_date": "2024-11-16 20:59:01 UTC",
    "updated_date": "2024-12-05 14:51:55 UTC"
  },
  {
    "arxiv_id": "2411.10879v1",
    "title": "BanglaDialecto: An End-to-End AI-Powered Regional Speech Standardization",
    "authors": [
      "Md. Nazmus Sadat Samin",
      "Jawad Ibn Ahad",
      "Tanjila Ahmed Medha",
      "Fuad Rahman",
      "Mohammad Ruhul Amin",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ],
    "abstract": "This study focuses on recognizing Bangladeshi dialects and converting diverse\nBengali accents into standardized formal Bengali speech. Dialects, often\nreferred to as regional languages, are distinctive variations of a language\nspoken in a particular location and are identified by their phonetics,\npronunciations, and lexicon. Subtle changes in pronunciation and intonation are\nalso influenced by geographic location, educational attainment, and\nsocioeconomic status. Dialect standardization is needed to ensure effective\ncommunication, educational consistency, access to technology, economic\nopportunities, and the preservation of linguistic resources while respecting\ncultural diversity. Being the fifth most spoken language with around 55\ndistinct dialects spoken by 160 million people, addressing Bangla dialects is\ncrucial for developing inclusive communication tools. However, limited research\nexists due to a lack of comprehensive datasets and the challenges of handling\ndiverse dialects. With the advancement in multilingual Large Language Models\n(mLLMs), emerging possibilities have been created to address the challenges of\ndialectal Automated Speech Recognition (ASR) and Machine Translation (MT). This\nstudy presents an end-to-end pipeline for converting dialectal Noakhali speech\nto standard Bangla speech. This investigation includes constructing a\nlarge-scale diverse dataset with dialectal speech signals that tailored the\nfine-tuning process in ASR and LLM for transcribing the dialect speech to\ndialect text and translating the dialect text to standard Bangla text. Our\nexperiments demonstrated that fine-tuning the Whisper ASR model achieved a CER\nof 0.8% and WER of 1.5%, while the BanglaT5 model attained a BLEU score of\n41.6% for dialect-to-standard text translation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE\n  BigData)",
    "pdf_url": "http://arxiv.org/pdf/2411.10879v1",
    "published_date": "2024-11-16 20:20:15 UTC",
    "updated_date": "2024-11-16 20:20:15 UTC"
  },
  {
    "arxiv_id": "2411.10878v1",
    "title": "Empowering Meta-Analysis: Leveraging Large Language Models for Scientific Synthesis",
    "authors": [
      "Jawad Ibn Ahad",
      "Rafeed Mohammad Sultan",
      "Abraham Kaikobad",
      "Fuad Rahman",
      "Mohammad Ruhul Amin",
      "Nabeel Mohammed",
      "Shafin Rahman"
    ],
    "abstract": "This study investigates the automation of meta-analysis in scientific\ndocuments using large language models (LLMs). Meta-analysis is a robust\nstatistical method that synthesizes the findings of multiple studies support\narticles to provide a comprehensive understanding. We know that a meta-article\nprovides a structured analysis of several articles. However, conducting\nmeta-analysis by hand is labor-intensive, time-consuming, and susceptible to\nhuman error, highlighting the need for automated pipelines to streamline the\nprocess. Our research introduces a novel approach that fine-tunes the LLM on\nextensive scientific datasets to address challenges in big data handling and\nstructured data extraction. We automate and optimize the meta-analysis process\nby integrating Retrieval Augmented Generation (RAG). Tailored through prompt\nengineering and a new loss metric, Inverse Cosine Distance (ICD), designed for\nfine-tuning on large contextual datasets, LLMs efficiently generate structured\nmeta-analysis content. Human evaluation then assesses relevance and provides\ninformation on model performance in key metrics. This research demonstrates\nthat fine-tuned models outperform non-fine-tuned models, with fine-tuned LLMs\ngenerating 87.6% relevant meta-analysis abstracts. The relevance of the\ncontext, based on human evaluation, shows a reduction in irrelevancy from 4.56%\nto 1.9%. These experiments were conducted in a low-resource environment,\nhighlighting the study's contribution to enhancing the efficiency and\nreliability of meta-analysis automation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE\n  BigData)",
    "pdf_url": "http://arxiv.org/pdf/2411.10878v1",
    "published_date": "2024-11-16 20:18:57 UTC",
    "updated_date": "2024-11-16 20:18:57 UTC"
  },
  {
    "arxiv_id": "2411.10877v3",
    "title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative AI for Software Development",
    "authors": [
      "Trevor Stalnaker",
      "Nathan Wintersgill",
      "Oscar Chaparro",
      "Laura A. Heymann",
      "Massimiliano Di Penta",
      "Daniel M German",
      "Denys Poshyvanyk"
    ],
    "abstract": "Despite the utility that Generative AI (GenAI) tools provide for tasks such\nas writing code, the use of these tools raises important legal questions and\npotential risks, particularly those associated with copyright law. As lawmakers\nand regulators engage with those questions, the views of users can provide\nrelevant perspectives. In this paper, we provide: (1) a survey of 574\ndevelopers on the licensing and copyright aspects of GenAI for coding, as well\nas follow-up interviews; (2) a snapshot of developers' views at a time when\nGenAI and perceptions of it are rapidly evolving; and (3) an analysis of\ndevelopers' views, yielding insights and recommendations that can inform future\nregulatory decisions in this evolving field. Our results show the benefits\ndevelopers derive from GenAI, how they view the use of AI-generated code as\nsimilar to using other existing code, the varied opinions they have on who\nshould own or be compensated for such code, that they are concerned about data\nleakage via GenAI, and much more, providing organizations and policymakers with\nvaluable insights into how the technology is being used and what concerns\nstakeholders would like to see addressed.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10877v3",
    "published_date": "2024-11-16 20:06:21 UTC",
    "updated_date": "2025-03-19 17:50:30 UTC"
  },
  {
    "arxiv_id": "2411.10867v2",
    "title": "ViBe: A Text-to-Video Benchmark for Evaluating Hallucination in Large Multimodal Models",
    "authors": [
      "Vipula Rawte",
      "Sarthak Jain",
      "Aarush Sinha",
      "Garv Kaushik",
      "Aman Bansal",
      "Prathiksha Rumale Vishwanath",
      "Samyak Rajesh Jain",
      "Aishwarya Naresh Reganti",
      "Vinija Jain",
      "Aman Chadha",
      "Amit P. Sheth",
      "Amitava Das"
    ],
    "abstract": "Recent advances in Large Multimodal Models (LMMs) have expanded their\ncapabilities to video understanding, with Text-to-Video (T2V) models excelling\nin generating videos from textual prompts. However, they still frequently\nproduce hallucinated content, revealing AI-generated inconsistencies. We\nintroduce ViBe (https://vibe-t2v-bench.github.io/): a large-scale dataset of\nhallucinated videos from open-source T2V models. We identify five major\nhallucination types: Vanishing Subject, Omission Error, Numeric Variability,\nSubject Dysmorphia, and Visual Incongruity. Using ten T2V models, we generated\nand manually annotated 3,782 videos from 837 diverse MS COCO captions. Our\nproposed benchmark includes a dataset of hallucinated videos and a\nclassification framework using video embeddings. ViBe serves as a critical\nresource for evaluating T2V reliability and advancing hallucination detection.\nWe establish classification as a baseline, with the TimeSFormer + CNN ensemble\nachieving the best performance (0.345 accuracy, 0.342 F1 score). While initial\nbaselines proposed achieve modest accuracy, this highlights the difficulty of\nautomated hallucination detection and the need for improved methods. Our\nresearch aims to drive the development of more robust T2V models and evaluate\ntheir outputs based on user preferences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10867v2",
    "published_date": "2024-11-16 19:23:12 UTC",
    "updated_date": "2025-03-19 18:53:09 UTC"
  },
  {
    "arxiv_id": "2411.12763v1",
    "title": "Education in the Era of Neurosymbolic AI",
    "authors": [
      "Chris Davis Jaldi",
      "Eleni Ilkou",
      "Noah Schroeder",
      "Cogan Shimizu"
    ],
    "abstract": "Education is poised for a transformative shift with the advent of\nneurosymbolic artificial intelligence (NAI), which will redefine how we support\ndeeply adaptive and personalized learning experiences. NAI-powered education\nsystems will be capable of interpreting complex human concepts and contexts\nwhile employing advanced problem-solving strategies, all grounded in\nestablished pedagogical frameworks. This will enable a level of personalization\nin learning systems that to date has been largely unattainable at scale,\nproviding finely tailored curricula that adapt to an individual's learning pace\nand accessibility needs, including the diagnosis of student understanding of\nsubjects at a fine-grained level, identifying gaps in foundational knowledge,\nand adjusting instruction accordingly. In this paper, we propose a system that\nleverages the unique affordances of pedagogical agents -- embodied characters\ndesigned to enhance learning -- as critical components of a hybrid NAI\narchitecture. To do so, these agents can thus simulate nuanced discussions,\ndebates, and problem-solving exercises that push learners beyond rote\nmemorization toward deep comprehension. We discuss the rationale for our system\ndesign and the preliminary findings of our work. We conclude that education in\nthe era of NAI will make learning more accessible, equitable, and aligned with\nreal-world skills. This is an era that will explore a new depth of\nunderstanding in educational tools.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12763v1",
    "published_date": "2024-11-16 19:18:39 UTC",
    "updated_date": "2024-11-16 19:18:39 UTC"
  },
  {
    "arxiv_id": "2411.10861v1",
    "title": "See-Saw Generative Mechanism for Scalable Recursive Code Generation with Generative AI",
    "authors": [
      "Ruslan Idelfonso Magaña Vsevolodovna"
    ],
    "abstract": "The generation of complex, large-scale code projects using generative AI\nmodels presents challenges due to token limitations, dependency management, and\niterative refinement requirements. This paper introduces the See-Saw generative\nmechanism, a novel methodology for dynamic and recursive code generation. The\nproposed approach alternates between main code updates and dependency\ngeneration to ensure alignment and functionality. By dynamically optimizing\ntoken usage and incorporating key elements of the main code into the generation\nof dependencies, the method enables efficient and scalable code generation for\nprojects requiring hundreds of interdependent files. The mechanism ensures that\nall code components are synchronized and functional, enabling scalable and\nefficient project generation. Experimental validation demonstrates the method's\ncapability to manage dependencies effectively while maintaining coherence and\nminimizing computational overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE",
      "68T05 (Primary) 68T50, 68N99(Secondary)",
      "I.2.6; I.2.7; D.2.2"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.10861v1",
    "published_date": "2024-11-16 18:54:56 UTC",
    "updated_date": "2024-11-16 18:54:56 UTC"
  },
  {
    "arxiv_id": "2411.11908v1",
    "title": "LLM4DS: Evaluating Large Language Models for Data Science Code Generation",
    "authors": [
      "Nathalia Nascimento",
      "Everton Guimaraes",
      "Sai Sanjna Chintakunta",
      "Santhosh Anitha Boominathan"
    ],
    "abstract": "The adoption of Large Language Models (LLMs) for code generation in data\nscience offers substantial potential for enhancing tasks such as data\nmanipulation, statistical analysis, and visualization. However, the\neffectiveness of these models in the data science domain remains underexplored.\nThis paper presents a controlled experiment that empirically assesses the\nperformance of four leading LLM-based AI assistants-Microsoft Copilot (GPT-4\nTurbo), ChatGPT (o1-preview), Claude (3.5 Sonnet), and Perplexity Labs\n(Llama-3.1-70b-instruct)-on a diverse set of data science coding challenges\nsourced from the Stratacratch platform. Using the Goal-Question-Metric (GQM)\napproach, we evaluated each model's effectiveness across task types\n(Analytical, Algorithm, Visualization) and varying difficulty levels. Our\nfindings reveal that all models exceeded a 50% baseline success rate,\nconfirming their capability beyond random chance. Notably, only ChatGPT and\nClaude achieved success rates significantly above a 60% baseline, though none\nof the models reached a 70% threshold, indicating limitations in higher\nstandards. ChatGPT demonstrated consistent performance across varying\ndifficulty levels, while Claude's success rate fluctuated with task complexity.\nHypothesis testing indicates that task type does not significantly impact\nsuccess rate overall. For analytical tasks, efficiency analysis shows no\nsignificant differences in execution times, though ChatGPT tended to be slower\nand less predictable despite high success rates. This study provides a\nstructured, empirical evaluation of LLMs in data science, delivering insights\nthat support informed model selection tailored to specific task demands. Our\nfindings establish a framework for future AI assessments, emphasizing the value\nof rigorous evaluation beyond basic accuracy measures.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.11908v1",
    "published_date": "2024-11-16 18:43:26 UTC",
    "updated_date": "2024-11-16 18:43:26 UTC"
  },
  {
    "arxiv_id": "2411.14461v1",
    "title": "Towards Next-Generation Medical Agent: How o1 is Reshaping Decision-Making in Medical Scenarios",
    "authors": [
      "Shaochen Xu",
      "Yifan Zhou",
      "Zhengliang Liu",
      "Zihao Wu",
      "Tianyang Zhong",
      "Huaqin Zhao",
      "Yiwei Li",
      "Hanqi Jiang",
      "Yi Pan",
      "Junhao Chen",
      "Jin Lu",
      "Wei Zhang",
      "Tuo Zhang",
      "Lu Zhang",
      "Dajiang Zhu",
      "Xiang Li",
      "Wei Liu",
      "Quanzheng Li",
      "Andrea Sikora",
      "Xiaoming Zhai",
      "Zhen Xiang",
      "Tianming Liu"
    ],
    "abstract": "Artificial Intelligence (AI) has become essential in modern healthcare, with\nlarge language models (LLMs) offering promising advances in clinical\ndecision-making. Traditional model-based approaches, including those leveraging\nin-context demonstrations and those with specialized medical fine-tuning, have\ndemonstrated strong performance in medical language processing but struggle\nwith real-time adaptability, multi-step reasoning, and handling complex medical\ntasks. Agent-based AI systems address these limitations by incorporating\nreasoning traces, tool selection based on context, knowledge retrieval, and\nboth short- and long-term memory. These additional features enable the medical\nAI agent to handle complex medical scenarios where decision-making should be\nbuilt on real-time interaction with the environment. Therefore, unlike\nconventional model-based approaches that treat medical queries as isolated\nquestions, medical AI agents approach them as complex tasks and behave more\nlike human doctors. In this paper, we study the choice of the backbone LLM for\nmedical AI agents, which is the foundation for the agent's overall reasoning\nand action generation. In particular, we consider the emergent o1 model and\nexamine its impact on agents' reasoning, tool-use adaptability, and real-time\ninformation retrieval across diverse clinical scenarios, including high-stakes\nsettings such as intensive care units (ICUs). Our findings demonstrate o1's\nability to enhance diagnostic accuracy and consistency, paving the way for\nsmarter, more responsive AI tools that support better patient outcomes and\ndecision-making efficacy in clinical practice.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14461v1",
    "published_date": "2024-11-16 18:19:53 UTC",
    "updated_date": "2024-11-16 18:19:53 UTC"
  },
  {
    "arxiv_id": "2411.10843v2",
    "title": "A Novel Adaptive Hybrid Focal-Entropy Loss for Enhancing Diabetic Retinopathy Detection Using Convolutional Neural Networks",
    "authors": [
      "Santhosh Malarvannan",
      "Pandiyaraju V",
      "Shravan Venkatraman",
      "Abeshek A",
      "Priyadarshini B",
      "Kannan A"
    ],
    "abstract": "Diabetic retinopathy is a leading cause of blindness around the world and\ndemands precise AI-based diagnostic tools. Traditional loss functions in\nmulti-class classification, such as Categorical Cross-Entropy (CCE), are very\ncommon but break down with class imbalance, especially in cases with inherently\nchallenging or overlapping classes, which leads to biased and less sensitive\nmodels. Since a heavy imbalance exists in the number of examples for higher\nseverity stage 4 diabetic retinopathy, etc., classes compared to those very\nearly stages like class 0, achieving class balance is key. For this purpose, we\npropose the Adaptive Hybrid Focal-Entropy Loss which combines the ideas of\nfocal loss and entropy loss with adaptive weighting in order to focus on\nminority classes and highlight the challenging samples. The state-of-the art\nmodels applied for diabetic retinopathy detection with AHFE revealed good\nperformance improvements, indicating the top performances of ResNet50 at\n99.79%, DenseNet121 at 98.86%, Xception at 98.92%, MobileNetV2 at 97.84%, and\nInceptionV3 at 93.62% accuracy. This sheds light into how AHFE promotes\nenhancement in AI-driven diagnostics for complex and imbalanced medical\ndatasets.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "68T07, 92C55, 68U10",
      "I.2.10; I.5.1; J.3"
    ],
    "primary_category": "eess.IV",
    "comment": "7 pages,7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.10843v2",
    "published_date": "2024-11-16 17:07:53 UTC",
    "updated_date": "2025-04-23 16:24:31 UTC"
  },
  {
    "arxiv_id": "2411.10842v1",
    "title": "CODECLEANER: Elevating Standards with A Robust Data Contamination Mitigation Toolkit",
    "authors": [
      "Jialun Cao",
      "Songqiang Chen",
      "Wuqi Zhang",
      "Hau Ching Lo",
      "Shing-Chi Cheung"
    ],
    "abstract": "Data contamination presents a critical barrier preventing widespread\nindustrial adoption of advanced software engineering techniques that leverage\ncode language models (CLMs). This phenomenon occurs when evaluation data\ninadvertently overlaps with the public code repositories used to train CLMs,\nseverely undermining the credibility of performance evaluations. For software\ncompanies considering the integration of CLM-based techniques into their\ndevelopment pipeline, this uncertainty about true performance metrics poses an\nunacceptable business risk. Code refactoring, which comprises code\nrestructuring and variable renaming, has emerged as a promising measure to\nmitigate data contamination. It provides a practical alternative to the\nresource-intensive process of building contamination-free evaluation datasets,\nwhich would require companies to collect, clean, and label code created after\nthe CLMs' training cutoff dates. However, the lack of automated code\nrefactoring tools and scientifically validated refactoring techniques has\nhampered widespread industrial implementation. To bridge the gap, this paper\npresents the first systematic study to examine the efficacy of code refactoring\noperators at multiple scales (method-level, class-level, and cross-class level)\nand in different programming languages. In particular, we develop an\nopen-sourced toolkit, CODECLEANER, which includes 11 operators for Python, with\nnine method-level, one class-level, and one cross-class-level operator. A drop\nof 65% overlap ratio is found when applying all operators in CODECLEANER,\ndemonstrating their effectiveness in addressing data contamination.\nAdditionally, we migrate four operators to Java, showing their generalizability\nto another language. We make CODECLEANER online available to facilitate further\nstudies on mitigating CLM data contamination.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10842v1",
    "published_date": "2024-11-16 17:06:21 UTC",
    "updated_date": "2024-11-16 17:06:21 UTC"
  },
  {
    "arxiv_id": "2411.10841v1",
    "title": "Adaptive Learning of Design Strategies over Non-Hierarchical Multi-Fidelity Models via Policy Alignment",
    "authors": [
      "Akash Agrawal",
      "Christopher McComb"
    ],
    "abstract": "Multi-fidelity Reinforcement Learning (RL) frameworks significantly enhance\nthe efficiency of engineering design by leveraging analysis models with varying\nlevels of accuracy and computational costs. The prevailing methodologies,\ncharacterized by transfer learning, human-inspired strategies, control variate\ntechniques, and adaptive sampling, predominantly depend on a structured\nhierarchy of models. However, this reliance on a model hierarchy overlooks the\nheterogeneous error distributions of models across the design space, extending\nbeyond mere fidelity levels. This work proposes ALPHA (Adaptively Learned\nPolicy with Heterogeneous Analyses), a novel multi-fidelity RL framework to\nefficiently learn a high-fidelity policy by adaptively leveraging an arbitrary\nset of non-hierarchical, heterogeneous, low-fidelity models alongside a\nhigh-fidelity model. Specifically, low-fidelity policies and their experience\ndata are dynamically used for efficient targeted learning, guided by their\nalignment with the high-fidelity policy. The effectiveness of ALPHA is\ndemonstrated in analytical test optimization and octocopter design problems,\nutilizing two low-fidelity models alongside a high-fidelity one. The results\nhighlight ALPHA's adaptive capability to dynamically utilize models across time\nand design space, eliminating the need for scheduling models as required in a\nhierarchical framework. Furthermore, the adaptive agents find more direct paths\nto high-performance solutions, showing superior convergence behavior compared\nto hierarchical agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "48 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.10841v1",
    "published_date": "2024-11-16 16:54:33 UTC",
    "updated_date": "2024-11-16 16:54:33 UTC"
  },
  {
    "arxiv_id": "2411.10830v1",
    "title": "One-Layer Transformer Provably Learns One-Nearest Neighbor In Context",
    "authors": [
      "Zihao Li",
      "Yuan Cao",
      "Cheng Gao",
      "Yihan He",
      "Han Liu",
      "Jason M. Klusowski",
      "Jianqing Fan",
      "Mengdi Wang"
    ],
    "abstract": "Transformers have achieved great success in recent years. Interestingly,\ntransformers have shown particularly strong in-context learning capability --\neven without fine-tuning, they are still able to solve unseen tasks well purely\nbased on task-specific prompts. In this paper, we study the capability of\none-layer transformers in learning one of the most classical nonparametric\nestimators, the one-nearest neighbor prediction rule. Under a theoretical\nframework where the prompt contains a sequence of labeled training data and\nunlabeled test data, we show that, although the loss function is nonconvex when\ntrained with gradient descent, a single softmax attention layer can\nsuccessfully learn to behave like a one-nearest neighbor classifier. Our result\ngives a concrete example of how transformers can be trained to implement\nnonparametric machine learning algorithms, and sheds light on the role of\nsoftmax attention in transformer models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10830v1",
    "published_date": "2024-11-16 16:12:42 UTC",
    "updated_date": "2024-11-16 16:12:42 UTC"
  },
  {
    "arxiv_id": "2412.12103v1",
    "title": "Empathic Coupling of Homeostatic States for Intrinsic Prosociality",
    "authors": [
      "Naoto Yoshida",
      "Kingson Man"
    ],
    "abstract": "When regarding the suffering of others, we often experience personal distress\nand feel compelled to help. Inspired by living systems, we investigate the\nemergence of prosocial behavior among autonomous agents that are motivated by\nhomeostatic self-regulation. We perform multi-agent reinforcement learning,\ntreating each agent as a vulnerable homeostat charged with maintaining its own\nwell-being. We introduce an empathy-like mechanism to share homeostatic states\nbetween agents: an agent can either \\emph{observe} their partner's internal\nstate (cognitive empathy) or the agent's internal state can be \\emph{directly\ncoupled} to that of their partner's (affective empathy). In three simple\nmulti-agent environments, we show that prosocial behavior arises only under\nhomeostatic coupling - when the distress of a partner can affect one's own\nwell-being. Our findings specify the type and role of empathy in artificial\nagents capable of prosocial behavior.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12103v1",
    "published_date": "2024-11-16 13:30:01 UTC",
    "updated_date": "2024-11-16 13:30:01 UTC"
  },
  {
    "arxiv_id": "2411.13583v1",
    "title": "Enhanced FIWARE-Based Architecture for Cyberphysical Systems With Tiny Machine Learning and Machine Learning Operations: A Case Study on Urban Mobility Systems",
    "authors": [
      "Javier Conde",
      "Andrés Munoz-Arcentales",
      "Álvaro Alonso",
      "Joaquín Salvachúa",
      "Gabriel Huecas"
    ],
    "abstract": "The rise of AI and the Internet of Things is accelerating the digital\ntransformation of society. Mobility computing presents specific barriers due to\nits real-time requirements, decentralization, and connectivity through wireless\nnetworks. New research on edge computing and tiny machine learning (tinyML)\nexplores the execution of AI models on low-performance devices to address these\nissues. However, there are not many studies proposing agnostic architectures\nthat manage the entire lifecycle of intelligent cyberphysical systems. This\narticle extends a previous architecture based on FIWARE software components to\nimplement the machine learning operations flow, enabling the management of the\nentire tinyML lifecycle in cyberphysical systems. We also provide a use case to\nshowcase how to implement the FIWARE architecture through a complete example of\na smart traffic system. We conclude that the FIWARE ecosystem constitutes a\nreal reference option for developing tinyML and edge computing in cyberphysical\nsystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13583v1",
    "published_date": "2024-11-16 13:14:29 UTC",
    "updated_date": "2024-11-16 13:14:29 UTC"
  },
  {
    "arxiv_id": "2411.12762v2",
    "title": "Playing Language Game with LLMs Leads to Jailbreaking",
    "authors": [
      "Yu Peng",
      "Zewen Long",
      "Fangming Dong",
      "Congyi Li",
      "Shu Wu",
      "Kai Chen"
    ],
    "abstract": "The advent of large language models (LLMs) has spurred the development of\nnumerous jailbreak techniques aimed at circumventing their security defenses\nagainst malicious attacks. An effective jailbreak approach is to identify a\ndomain where safety generalization fails, a phenomenon known as mismatched\ngeneralization. In this paper, we introduce two novel jailbreak methods based\non mismatched generalization: natural language games and custom language games,\nboth of which effectively bypass the safety mechanisms of LLMs, with various\nkinds and different variants, making them hard to defend and leading to high\nattack rates. Natural language games involve the use of synthetic linguistic\nconstructs and the actions intertwined with these constructs, such as the Ubbi\nDubbi language. Building on this phenomenon, we propose the custom language\ngames method: by engaging with LLMs using a variety of custom rules, we\nsuccessfully execute jailbreak attacks across multiple LLM platforms. Extensive\nexperiments demonstrate the effectiveness of our methods, achieving success\nrates of 93% on GPT-4o, 89% on GPT-4o-mini and 83% on Claude-3.5-Sonnet.\nFurthermore, to investigate the generalizability of safety alignments, we\nfine-tuned Llama-3.1-70B with the custom language games to achieve safety\nalignment within our datasets and found that when interacting through other\nlanguage games, the fine-tuned models still failed to identify harmful content.\nThis finding indicates that the safety alignment knowledge embedded in LLMs\nfails to generalize across different linguistic formats, thus opening new\navenues for future research in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12762v2",
    "published_date": "2024-11-16 13:07:13 UTC",
    "updated_date": "2024-11-27 07:41:35 UTC"
  },
  {
    "arxiv_id": "2411.15173v1",
    "title": "Decentralizing Test-time Adaptation under Heterogeneous Data Streams",
    "authors": [
      "Zixian Su",
      "Jingwei Guo",
      "Xi Yang",
      "Qiufeng Wang",
      "Kaizhu Huang"
    ],
    "abstract": "While Test-Time Adaptation (TTA) has shown promise in addressing distribution\nshifts between training and testing data, its effectiveness diminishes with\nheterogeneous data streams due to uniform target estimation. As previous\nattempts merely stabilize model fine-tuning over time to handle continually\nchanging environments, they fundamentally assume a homogeneous target domain at\nany moment, leaving the intrinsic real-world data heterogeneity unresolved.\nThis paper delves into TTA under heterogeneous data streams, moving beyond\ncurrent model-centric limitations. By revisiting TTA from a data-centric\nperspective, we discover that decomposing samples into Fourier space\nfacilitates an accurate data separation across different frequency levels.\nDrawing from this insight, we propose a novel Frequency-based Decentralized\nAdaptation (FreDA) framework, which transitions data from globally\nheterogeneous to locally homogeneous in Fourier space and employs decentralized\nadaptation to manage diverse distribution shifts.Interestingly, we devise a\nnovel Fourier-based augmentation strategy to assist in decentralizing\nadaptation, which individually enhances sample quality for capturing each type\nof distribution shifts. Extensive experiments across various settings\n(corrupted, natural, and medical environments) demonstrate the superiority of\nour proposed framework over the state-of-the-arts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15173v1",
    "published_date": "2024-11-16 12:29:59 UTC",
    "updated_date": "2024-11-16 12:29:59 UTC"
  },
  {
    "arxiv_id": "2411.14460v2",
    "title": "LLaSA: Large Language and Structured Data Assistant",
    "authors": [
      "Yao Xu",
      "Shizhu He",
      "Jiabei Chen",
      "Zeng Xiangrong",
      "Bingning Wang",
      "Guang Liu",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Structured data, such as tables, graphs, and databases, play a critical role\nin plentiful NLP tasks such as question answering and dialogue system.\nRecently, inspired by Vision-Language Models, Graph Neutral Networks (GNNs)\nhave been introduced as an additional modality into the input of Large Language\nModels (LLMs) to improve their performance on Structured Knowledge Grounding\n(SKG) tasks. However, those GNN-enhanced LLMs have the following limitations:\n(1) They employ diverse GNNs to model varying types of structured data,\nrendering them unable to uniformly process various forms of structured data.\n(2) The pretraining of GNNs is coupled with specific LLMs, which prevents GNNs\nfrom fully aligning with the textual space and limits their adaptability to\nother LLMs. To address these issues, we propose \\textbf{L}arge\n\\textbf{L}anguage and \\textbf{S}tructured Data \\textbf{A}ssistant (LLaSA), a\ngeneral framework for enhancing LLMs' ability to handle structured data.\nSpecifically, we represent various types of structured data in a unified\nhypergraph format, and use self-supervised learning to pretrain a hypergraph\nencoder, and a G-Former compressing encoded hypergraph representations with\ncross-attention. The compressed hypergraph representations are appended to the\nserialized inputs during training and inference stages of LLMs. Experimental\nresults on multiple SKG tasks show that our pretrained hypergraph encoder can\nadapt to various LLMs and enhance their ability to process different types of\nstructured data. Besides, LLaSA, with LoRA fine-tuning, outperforms previous\nSOTA method using full parameters tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2411.14460v2",
    "published_date": "2024-11-16 12:27:14 UTC",
    "updated_date": "2025-02-09 17:13:10 UTC"
  },
  {
    "arxiv_id": "2411.14459v1",
    "title": "Unveiling User Preferences: A Knowledge Graph and LLM-Driven Approach for Conversational Recommendation",
    "authors": [
      "Zhangchi Qiu",
      "Linhao Luo",
      "Shirui Pan",
      "Alan Wee-Chung Liew"
    ],
    "abstract": "Conversational Recommender Systems (CRSs) aim to provide personalized\nrecommendations through dynamically capturing user preferences in interactive\nconversations. Conventional CRSs often extract user preferences as hidden\nrepresentations, which are criticized for their lack of interpretability. This\ndiminishes the transparency and trustworthiness of the recommendation process.\nRecent works have explored combining the impressive capabilities of Large\nLanguage Models (LLMs) with the domain-specific knowledge of Knowledge Graphs\n(KGs) to generate human-understandable recommendation explanations. Despite\nthese efforts, the integration of LLMs and KGs for CRSs remains challenging due\nto the modality gap between unstructured dialogues and structured KGs.\nMoreover, LLMs pre-trained on large-scale corpora may not be well-suited for\nanalyzing user preferences, which require domain-specific knowledge. In this\npaper, we propose COMPASS, a plug-and-play framework that synergizes LLMs and\nKGs to unveil user preferences, enhancing the performance and explainability of\nexisting CRSs. To address integration challenges, COMPASS employs a two-stage\ntraining approach: first, it bridges the gap between the structured KG and\nnatural language through an innovative graph entity captioning pre-training\nmechanism. This enables the LLM to transform KG entities into concise natural\nlanguage descriptions, allowing them to comprehend domain-specific knowledge.\nFollowing, COMPASS optimizes user preference modeling via knowledge-aware\ninstruction fine-tuning, where the LLM learns to reason and summarize user\npreferences from both dialogue histories and KG-augmented context. This enables\nCOMPASS to perform knowledge-aware reasoning and generate comprehensive and\ninterpretable user preferences that can seamlessly integrate with existing CRS\nmodels for improving recommendation performance and explainability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14459v1",
    "published_date": "2024-11-16 11:47:21 UTC",
    "updated_date": "2024-11-16 11:47:21 UTC"
  },
  {
    "arxiv_id": "2412.00020v1",
    "title": "Partitioning Message Passing for Graph Fraud Detection",
    "authors": [
      "Wei Zhuo",
      "Zemin Liu",
      "Bryan Hooi",
      "Bingsheng He",
      "Guang Tan",
      "Rizal Fathony",
      "Jia Chen"
    ],
    "abstract": "Label imbalance and homophily-heterophily mixture are the fundamental\nproblems encountered when applying Graph Neural Networks (GNNs) to Graph Fraud\nDetection (GFD) tasks. Existing GNN-based GFD models are designed to augment\ngraph structure to accommodate the inductive bias of GNNs towards homophily, by\nexcluding heterophilic neighbors during message passing. In our work, we argue\nthat the key to applying GNNs for GFD is not to exclude but to {\\em\ndistinguish} neighbors with different labels. Grounded in this perspective, we\nintroduce Partitioning Message Passing (PMP), an intuitive yet effective\nmessage passing paradigm expressly crafted for GFD. Specifically, in the\nneighbor aggregation stage of PMP, neighbors with different classes are\naggregated with distinct node-specific aggregation functions. By this means,\nthe center node can adaptively adjust the information aggregated from its\nheterophilic and homophilic neighbors, thus avoiding the model gradient being\ndominated by benign nodes which occupy the majority of the population. We\ntheoretically establish a connection between the spatial formulation of PMP and\nspectral analysis to characterize that PMP operates an adaptive node-specific\nspectral graph filter, which demonstrates the capability of PMP to handle\nheterophily-homophily mixed graphs. Extensive experimental results show that\nPMP can significantly boost the performance on GFD tasks.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00020v1",
    "published_date": "2024-11-16 11:30:53 UTC",
    "updated_date": "2024-11-16 11:30:53 UTC"
  },
  {
    "arxiv_id": "2411.12761v1",
    "title": "AI-Empowered Human Research Integrating Brain Science and Social Sciences Insights",
    "authors": [
      "Feng Xiong",
      "Xinguo Yu",
      "Hon Wai Leong"
    ],
    "abstract": "This paper explores the transformative role of artificial intelligence (AI)\nin enhancing scientific research, particularly in the fields of brain science\nand social sciences. We analyze the fundamental aspects of human research and\nargue that it is high time for researchers to transition to human-AI joint\nresearch. Building upon this foundation, we propose two innovative research\nparadigms of human-AI joint research: \"AI-Brain Science Research Paradigm\" and\n\"AI-Social Sciences Research Paradigm\". In these paradigms, we introduce three\nhuman-AI collaboration models: AI as a research tool (ART), AI as a research\nassistant (ARA), and AI as a research participant (ARP). Furthermore, we\noutline the methods for conducting human-AI joint research. This paper seeks to\nredefine the collaborative interactions between human researchers and AI\nsystem, setting the stage for future research directions and sparking\ninnovation in this interdisciplinary field.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to IEIR 2024, 10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.12761v1",
    "published_date": "2024-11-16 11:13:23 UTC",
    "updated_date": "2024-11-16 11:13:23 UTC"
  },
  {
    "arxiv_id": "2411.10772v1",
    "title": "MRI Parameter Mapping via Gaussian Mixture VAE: Breaking the Assumption of Independent Pixels",
    "authors": [
      "Moucheng Xu",
      "Yukun Zhou",
      "Tobias Goodwin-Allcock",
      "Kimia Firoozabadi",
      "Joseph Jacob",
      "Daniel C. Alexander",
      "Paddy J. Slator"
    ],
    "abstract": "We introduce and demonstrate a new paradigm for quantitative parameter\nmapping in MRI. Parameter mapping techniques, such as diffusion MRI and\nquantitative MRI, have the potential to robustly and repeatably measure\nbiologically-relevant tissue maps that strongly relate to underlying\nmicrostructure. Quantitative maps are calculated by fitting a model to multiple\nimages, e.g. with least-squares or machine learning. However, the overwhelming\nmajority of model fitting techniques assume that each voxel is independent,\nignoring any co-dependencies in the data. This makes model fitting sensitive to\nvoxelwise measurement noise, hampering reliability and repeatability. We\npropose a self-supervised deep variational approach that breaks the assumption\nof independent pixels, leveraging redundancies in the data to effectively\nperform data-driven regularisation of quantitative maps. We demonstrate that\nour approach outperforms current model fitting techniques in dMRI simulations\nand real data. Especially with a Gaussian mixture prior, our model enables\nsharper quantitative maps, revealing finer anatomical details that are not\npresented in the baselines. Our approach can hence support the clinical\nadoption of parameter mapping methods such as dMRI and qMRI.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.IV",
    "comment": "NeurIPS 2024 Workshop in Machine Learning and the Physical Sciences",
    "pdf_url": "http://arxiv.org/pdf/2411.10772v1",
    "published_date": "2024-11-16 11:11:36 UTC",
    "updated_date": "2024-11-16 11:11:36 UTC"
  },
  {
    "arxiv_id": "2412.12102v1",
    "title": "Distributed Collaborative Inference System in Next-Generation Networks and Communication",
    "authors": [
      "Chuan Zhang",
      "Xixi Zheng",
      "Xiaolong Tao",
      "Chenfei Hu",
      "Weiting Zhang",
      "Liehuang Zhu"
    ],
    "abstract": "With the rapid advancement of artificial intelligence, generative artificial\nintelligence (GAI) has taken a leading role in transforming data processing\nmethods. However, the high computational demands of GAI present challenges for\ndevices with limited resources. As we move towards the sixth generation of\nmobile networks (6G), the higher data rates and improved energy efficiency of\n6G create a need for more efficient data processing in GAI. Traditional GAI,\nhowever, shows its limitations in meeting these demands. To address these\nchallenges, we introduce a multi-level collaborative inference system designed\nfor next-generation networks and communication. Our proposed system features a\ndeployment strategy that assigns models of varying sizes to devices at\ndifferent network layers. Then, we design a task offloading strategy to\noptimise both efficiency and latency. Furthermore, a modified early exit\nmechanism is implemented to enhance the inference process for single models.\nExperimental results demonstrate that our system effectively reduces inference\nlatency while maintaining high-quality output. Specifically, compared to\nexisting work, our system can reduce inference time by up to 17% without\nsacrificing the inference accuracy.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12102v1",
    "published_date": "2024-11-16 10:48:12 UTC",
    "updated_date": "2024-11-16 10:48:12 UTC"
  },
  {
    "arxiv_id": "2411.14458v1",
    "title": "Improving training time and GPU utilization in geo-distributed language model training",
    "authors": [
      "Palak",
      "Rohan Gandhi",
      "Karan Tandon",
      "Debopam Bhattacherjee",
      "Venkata N. Padmanabhan"
    ],
    "abstract": "The widespread adoption of language models (LMs) across multiple industries\nhas caused huge surge in demand for GPUs. Training LMs requires tens of\nthousands of GPUs and housing them in the same datacenter (DCs) is becoming\nchallenging. We focus on training such models across multiple DCs connected via\nWide-Area-Network (WAN). We build ATLAS that speeds up such training time using\nnovel temporal bandwidth sharing and many other design choices. While ATLAS\nimproves the training time, it does not eliminate the bubbles (idle GPU\ncycles). We built BUBBLETEA that runs prefill-as-a-service (part of LM\ninference) during the bubbles that improves the GPU utilization substantially\nwithout any impact of training. Together, ATLAS and BUBBLETEA improve training\ntime by up to 17X and achieve GPU utilization of up to 94%.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14458v1",
    "published_date": "2024-11-16 10:15:01 UTC",
    "updated_date": "2024-11-16 10:15:01 UTC"
  },
  {
    "arxiv_id": "2411.10754v1",
    "title": "Integrated Machine Learning and Survival Analysis Modeling for Enhanced Chronic Kidney Disease Risk Stratification",
    "authors": [
      "Zachary Dana",
      "Ahmed Ammar Naseer",
      "Botros Toro",
      "Sumanth Swaminathan"
    ],
    "abstract": "Chronic kidney disease (CKD) is a significant public health challenge, often\nprogressing to end-stage renal disease (ESRD) if not detected and managed\nearly. Early intervention, warranted by silent disease progression, can\nsignificantly reduce associated morbidity, mortality, and financial burden. In\nthis study, we propose a novel approach to modeling CKD progression using a\ncombination of machine learning techniques and classical statistical models.\nBuilding on the work of Liu et al. (2023), we evaluate linear models,\ntree-based methods, and deep learning models to extract novel predictors for\nCKD progression, with feature importance assessed using Shapley values. These\nnewly identified predictors, integrated with established clinical features from\nthe Kidney Failure Risk Equation, are then applied within the framework of Cox\nproportional hazards models to predict CKD progression.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 19 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.10754v1",
    "published_date": "2024-11-16 09:22:06 UTC",
    "updated_date": "2024-11-16 09:22:06 UTC"
  },
  {
    "arxiv_id": "2411.10753v1",
    "title": "Chain-of-Programming (CoP) : Empowering Large Language Models for Geospatial Code Generation",
    "authors": [
      "Shuyang Hou",
      "Haoyue Jiao",
      "Zhangxiao Shen",
      "Jianyuan Liang",
      "Anqi Zhao",
      "Xiaopu Zhang",
      "Jianxun Wang",
      "Huayi Wu"
    ],
    "abstract": "With the rapid growth of interdisciplinary demands for geospatial modeling\nand the rise of large language models (LLMs), geospatial code generation\ntechnology has seen significant advancements. However, existing LLMs often face\nchallenges in the geospatial code generation process due to incomplete or\nunclear user requirements and insufficient knowledge of specific platform\nsyntax rules, leading to the generation of non-executable code, a phenomenon\nknown as \"code hallucination.\" To address this issue, this paper proposes a\nChain of Programming (CoP) framework, which decomposes the code generation\nprocess into five steps: requirement analysis, algorithm design, code\nimplementation, code debugging, and code annotation. The framework incorporates\na shared information pool, knowledge base retrieval, and user feedback\nmechanisms, forming an end-to-end code generation flow from requirements to\ncode without the need for model fine-tuning. Based on a geospatial problem\nclassification framework and evaluation benchmarks, the CoP strategy\nsignificantly improves the logical clarity, syntactical correctness, and\nexecutability of the generated code, with improvements ranging from 3.0% to\n48.8%. Comparative and ablation experiments further validate the superiority of\nthe CoP strategy over other optimization approaches and confirm the rationality\nand necessity of its key components. Through case studies on building data\nvisualization and fire data analysis, this paper demonstrates the application\nand effectiveness of CoP in various geospatial scenarios. The CoP framework\noffers a systematic, step-by-step approach to LLM-based geospatial code\ngeneration tasks, significantly enhancing code generation performance in\ngeospatial tasks and providing valuable insights for code generation in other\nvertical domains.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10753v1",
    "published_date": "2024-11-16 09:20:35 UTC",
    "updated_date": "2024-11-16 09:20:35 UTC"
  },
  {
    "arxiv_id": "2411.10746v1",
    "title": "LTCXNet: Advancing Chest X-Ray Analysis with Solutions for Long-Tailed Multi-Label Classification and Fairness Challenges",
    "authors": [
      "Chin-Wei Huang",
      "Mu-Yi Shen",
      "Kuan-Chang Shih",
      "Shih-Chih Lin",
      "Chi-Yu Chen",
      "Po-Chih Kuo"
    ],
    "abstract": "Chest X-rays (CXRs) often display various diseases with disparate class\nfrequencies, leading to a long-tailed, multi-label data distribution. In\nresponse to this challenge, we explore the Pruned MIMIC-CXR-LT dataset, a\ncurated collection derived from the MIMIC-CXR dataset, specifically designed to\nrepresent a long-tailed and multi-label data scenario. We introduce LTCXNet, a\nnovel framework that integrates the ConvNeXt model, ML-Decoder, and strategic\ndata augmentation, further enhanced by an ensemble approach. We demonstrate\nthat LTCXNet improves the performance of CXR interpretation across all classes,\nespecially enhancing detection in rarer classes like `Pneumoperitoneum' and\n`Pneumomediastinum' by 79\\% and 48\\%, respectively. Beyond performance metrics,\nour research extends into evaluating fairness, highlighting that some methods,\nwhile improving model accuracy, could inadvertently affect fairness across\ndifferent demographic groups negatively. This work contributes to advancing the\nunderstanding and management of long-tailed, multi-label data distributions in\nmedical imaging, paving the way for more equitable and effective diagnostic\ntools.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.10746v1",
    "published_date": "2024-11-16 08:59:20 UTC",
    "updated_date": "2024-11-16 08:59:20 UTC"
  },
  {
    "arxiv_id": "2411.10744v1",
    "title": "Digital-Analog Quantum Machine Learning",
    "authors": [
      "Lucas Lamata"
    ],
    "abstract": "Machine Learning algorithms are extensively used in an increasing number of\nsystems, applications, technologies, and products, both in industry and in\nsociety as a whole. They enable computing devices to learn from previous\nexperience and therefore improve their performance in a certain context or\nenvironment. In this way, many useful possibilities have been made accessible.\nHowever, dealing with an increasing amount of data poses difficulties for\nclassical devices. Quantum systems may offer a way forward, possibly enabling\nto scale up machine learning calculations in certain contexts. On the other\nhand, quantum systems themselves are also hard to scale up, due to decoherence\nand the fragility of quantum superpositions. In the short and mid term, it has\nbeen evidenced that a quantum paradigm that combines evolution under large\nanalog blocks with discrete quantum gates, may be fruitful to achieve new\nknowledge of classical and quantum systems with no need of having a\nfault-tolerant quantum computer. In this Perspective, we review some recent\nworks that employ this digital-analog quantum paradigm to carry out efficient\nmachine learning calculations with current quantum devices.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "Invited Perspective for Advanced Intelligent Discovery",
    "pdf_url": "http://arxiv.org/pdf/2411.10744v1",
    "published_date": "2024-11-16 08:54:52 UTC",
    "updated_date": "2024-11-16 08:54:52 UTC"
  },
  {
    "arxiv_id": "2411.10741v1",
    "title": "MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map",
    "authors": [
      "Yuhong Chou",
      "Man Yao",
      "Kexin Wang",
      "Yuqi Pan",
      "Ruijie Zhu",
      "Yiran Zhong",
      "Yu Qiao",
      "Jibin Wu",
      "Bo Xu",
      "Guoqi Li"
    ],
    "abstract": "Various linear complexity models, such as Linear Transformer (LinFormer),\nState Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace\nthe conventional softmax attention in Transformer structures. However, the\noptimal design of these linear models is still an open question. In this work,\nwe attempt to answer this question by finding the best linear approximation to\nsoftmax attention from a theoretical perspective. We start by unifying existing\nlinear complexity models as the linear attention form and then identify three\nconditions for the optimal linear attention design: 1) Dynamic memory ability;\n2) Static approximation ability; 3) Least parameter approximation. We find that\nnone of the current linear models meet all three conditions, resulting in\nsuboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a\nsolution that satisfies these conditions. Our experiments on Multi-Query\nAssociative Recall (MQAR) task, language modeling, image classification, and\nLong-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than\nthe existing linear models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10741v1",
    "published_date": "2024-11-16 08:47:32 UTC",
    "updated_date": "2024-11-16 08:47:32 UTC"
  },
  {
    "arxiv_id": "2412.02702v1",
    "title": "Fine Tuning Swimming Locomotion Learned from Mosquito Larvae",
    "authors": [
      "Pranav Rajbhandari",
      "Karthick Dhileep",
      "Sridhar Ravi",
      "Donald Sofge"
    ],
    "abstract": "In prior research, we analyzed the backwards swimming motion of mosquito\nlarvae, parameterized it, and replicated it in a Computational Fluid Dynamics\n(CFD) model. Since the parameterized swimming motion is copied from observed\nlarvae, it is not necessarily the most efficient locomotion for the model of\nthe swimmer. In this project, we further optimize this copied solution for the\nswimmer model. We utilize Reinforcement Learning to guide local parameter\nupdates. Since the majority of the computation cost arises from the CFD model,\nwe additionally train a deep learning model to replicate the forces acting on\nthe swimmer model. We find that this method is effective at performing local\nsearch to improve the parameterized swimming locomotion.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.02702v1",
    "published_date": "2024-11-16 06:54:43 UTC",
    "updated_date": "2024-11-16 06:54:43 UTC"
  },
  {
    "arxiv_id": "2411.10696v1",
    "title": "HELENE: Hessian Layer-wise Clipping and Gradient Annealing for Accelerating Fine-tuning LLM with Zeroth-order Optimization",
    "authors": [
      "Huaqin Zhao",
      "Jiaxi Li",
      "Yi Pan",
      "Shizhe Liang",
      "Xiaofeng Yang",
      "Wei Liu",
      "Xiang Li",
      "Fei Dou",
      "Tianming Liu",
      "Jin Lu"
    ],
    "abstract": "Fine-tuning large language models (LLMs) poses significant memory challenges,\nas the back-propagation process demands extensive resources, especially with\ngrowing model sizes. Recent work, MeZO, addresses this issue using a\nzeroth-order (ZO) optimization method, which reduces memory consumption by\nmatching the usage to the inference phase. However, MeZO experiences slow\nconvergence due to varying curvatures across model parameters. To overcome this\nlimitation, we introduce HELENE, a novel scalable and memory-efficient\noptimizer that integrates annealed A-GNB gradients with a diagonal Hessian\nestimation and layer-wise clipping, serving as a second-order pre-conditioner.\nThis combination allows for faster and more stable convergence. Our theoretical\nanalysis demonstrates that HELENE improves convergence rates, particularly for\nmodels with heterogeneous layer dimensions, by reducing the dependency on the\ntotal parameter space dimension. Instead, the method scales with the largest\nlayer dimension, making it highly suitable for modern LLM architectures.\nExperimental results on RoBERTa-large and OPT-1.3B across multiple tasks show\nthat HELENE achieves up to a 20x speedup compared to MeZO, with average\naccuracy improvements of 1.5%. Furthermore, HELENE remains compatible with both\nfull parameter tuning and parameter-efficient fine-tuning (PEFT), outperforming\nseveral state-of-the-art optimizers. The codes will be released after\nreviewing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10696v1",
    "published_date": "2024-11-16 04:27:22 UTC",
    "updated_date": "2024-11-16 04:27:22 UTC"
  },
  {
    "arxiv_id": "2411.10692v1",
    "title": "DEBUG-HD: Debugging TinyML models on-device using Hyper-Dimensional computing",
    "authors": [
      "Nikhil P Ghanathe",
      "Steven J E Wilton"
    ],
    "abstract": "TinyML models often operate in remote, dynamic environments without cloud\nconnectivity, making them prone to failures. Ensuring reliability in such\nscenarios requires not only detecting model failures but also identifying their\nroot causes. However, transient failures, privacy concerns, and the\nsafety-critical nature of many applications-where systems cannot be interrupted\nfor debugging-complicate the use of raw sensor data for offline analysis. We\npropose DEBUG-HD, a novel, resource-efficient on-device debugging approach\noptimized for KB-sized tinyML devices that utilizes hyper-dimensional computing\n(HDC). Our method introduces a new HDC encoding technique that leverages\nconventional neural networks, allowing DEBUG-HD to outperform prior binary HDC\nmethods by 27% on average in detecting input corruptions across various image\nand audio datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the Machine Learning for Systems Workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.10692v1",
    "published_date": "2024-11-16 04:03:22 UTC",
    "updated_date": "2024-11-16 04:03:22 UTC"
  },
  {
    "arxiv_id": "2411.12759v1",
    "title": "A Novel Approach to Eliminating Hallucinations in Large Language Model-Assisted Causal Discovery",
    "authors": [
      "Grace Sng",
      "Yanming Zhang",
      "Klaus Mueller"
    ],
    "abstract": "The increasing use of large language models (LLMs) in causal discovery as a\nsubstitute for human domain experts highlights the need for optimal model\nselection. This paper presents the first hallucination survey of popular LLMs\nfor causal discovery. We show that hallucinations exist when using LLMs in\ncausal discovery so the choice of LLM is important. We propose using Retrieval\nAugmented Generation (RAG) to reduce hallucinations when quality data is\navailable. Additionally, we introduce a novel method employing multiple LLMs\nwith an arbiter in a debate to audit edges in causal graphs, achieving a\ncomparable reduction in hallucinations to RAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.12759v1",
    "published_date": "2024-11-16 03:06:39 UTC",
    "updated_date": "2024-11-16 03:06:39 UTC"
  },
  {
    "arxiv_id": "2411.10676v2",
    "title": "Exploring Feature-based Knowledge Distillation for Recommender System: A Frequency Perspective",
    "authors": [
      "Zhangchi Zhu",
      "Wei Zhang"
    ],
    "abstract": "In this paper, we analyze the feature-based knowledge distillation for\nrecommendation from the frequency perspective. By defining knowledge as\ndifferent frequency components of the features, we theoretically demonstrate\nthat regular feature-based knowledge distillation is equivalent to equally\nminimizing losses on all knowledge and further analyze how this equal loss\nweight allocation method leads to important knowledge being overlooked. In\nlight of this, we propose to emphasize important knowledge by redistributing\nknowledge weights. Furthermore, we propose FreqD, a lightweight knowledge\nreweighting method, to avoid the computational cost of calculating losses on\neach knowledge. Extensive experiments demonstrate that FreqD consistently and\nsignificantly outperforms state-of-the-art knowledge distillation methods for\nrecommender systems. Our code is available at https://github.com/woriazzc/KDs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "ACM KDD 2025 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2411.10676v2",
    "published_date": "2024-11-16 02:41:12 UTC",
    "updated_date": "2025-01-13 09:10:18 UTC"
  },
  {
    "arxiv_id": "2411.10666v3",
    "title": "SAM Decoding: Speculative Decoding via Suffix Automaton",
    "authors": [
      "Yuxuan Hu",
      "Ke Wang",
      "Xiaokang Zhang",
      "Fanjin Zhang",
      "Cuiping Li",
      "Hong Chen",
      "Jing Zhang"
    ],
    "abstract": "Speculative decoding (SD) has been demonstrated as an effective technique for\nlossless LLM inference acceleration. Retrieval-based SD methods, one kind of\nmodel-free method, have yielded promising speedup, but they often rely on\nincomplete retrieval resources, inefficient retrieval methods, and are\nconstrained to certain domains. This paper presents a novel retrieval-based\nspeculative decoding method that adapts suffix automaton (SAM) for efficient\nand accurate draft generation by utilizing common text corpus and dynamic text\nsequence. Unlike existing $n$-gram matching methods, SAM-Decoding finds the\nexact longest suffix match, achieving an average time complexity of O(1) per\ngeneration step of SAM update and suffix retrieval. It can also integrate with\nexisting methods, adaptively selecting a draft generation strategy based on\nmatch length to generalize to broader domains. Extensive experiments on\nSpec-Bench show that our method is $18\\%+$ faster than other retrieval-based SD\nmethods. Additionally, when combined with advanced EAGLE-2, it provides an\nadditional speedup of $3.28\\%$ -- $11.13\\%$ across various-sized LLM backbones.\nOur code is available at our\n\\href{https://github.com/hyx1999/SAM-Decoding}{repository}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 9 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.10666v3",
    "published_date": "2024-11-16 02:02:49 UTC",
    "updated_date": "2024-12-16 10:48:28 UTC"
  },
  {
    "arxiv_id": "2411.10654v1",
    "title": "Pluralistic Alignment Over Time",
    "authors": [
      "Toryn Q. Klassen",
      "Parand A. Alamdari",
      "Sheila A. McIlraith"
    ],
    "abstract": "If an AI system makes decisions over time, how should we evaluate how aligned\nit is with a group of stakeholders (who may have conflicting values and\npreferences)? In this position paper, we advocate for consideration of temporal\naspects including stakeholders' changing levels of satisfaction and their\npossibly temporally extended preferences. We suggest how a recent approach to\nevaluating fairness over time could be applied to a new form of pluralistic\nalignment: temporal pluralism, where the AI system reflects different\nstakeholders' values at different times.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Pluralistic Alignment Workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.10654v1",
    "published_date": "2024-11-16 01:23:25 UTC",
    "updated_date": "2024-11-16 01:23:25 UTC"
  },
  {
    "arxiv_id": "2411.10651v1",
    "title": "Understanding Learning with Sliced-Wasserstein Requires Rethinking Informative Slices",
    "authors": [
      "Huy Tran",
      "Yikun Bai",
      "Ashkan Shahbazi",
      "John R. Hershey",
      "Soheil Kolouri"
    ],
    "abstract": "The practical applications of Wasserstein distances (WDs) are constrained by\ntheir sample and computational complexities. Sliced-Wasserstein distances\n(SWDs) provide a workaround by projecting distributions onto one-dimensional\nsubspaces, leveraging the more efficient, closed-form WDs for one-dimensional\ndistributions. However, in high dimensions, most random projections become\nuninformative due to the concentration of measure phenomenon. Although several\nSWD variants have been proposed to focus on \\textit{informative} slices, they\noften introduce additional complexity, numerical instability, and compromise\ndesirable theoretical (metric) properties of SWD. Amidst the growing literature\nthat focuses on directly modifying the slicing distribution, which often face\nchallenges, we revisit the classical Sliced-Wasserstein and propose instead to\nrescale the 1D Wasserstein to make all slices equally informative. Importantly,\nwe show that with an appropriate data assumption and notion of \\textit{slice\ninformativeness}, rescaling for all individual slices simplifies to \\textbf{a\nsingle global scaling factor} on the SWD. This, in turn, translates to the\nstandard learning rate search for gradient-based learning in common machine\nlearning workflows. We perform extensive experiments across various machine\nlearning tasks showing that the classical SWD, when properly configured, can\noften match or surpass the performance of more complex variants. We then answer\nthe following question: \"Is Sliced-Wasserstein all you need for common learning\ntasks?\"",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.AP",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10651v1",
    "published_date": "2024-11-16 01:18:27 UTC",
    "updated_date": "2024-11-16 01:18:27 UTC"
  },
  {
    "arxiv_id": "2411.10639v2",
    "title": "MTA: Multimodal Task Alignment for BEV Perception and Captioning",
    "authors": [
      "Yunsheng Ma",
      "Burhaneddin Yaman",
      "Xin Ye",
      "Jingru Luo",
      "Feng Tao",
      "Abhirup Mallik",
      "Ziran Wang",
      "Liu Ren"
    ],
    "abstract": "Bird's eye view (BEV)-based 3D perception plays a crucial role in autonomous\ndriving applications. The rise of large language models has spurred interest in\nBEV-based captioning to understand object behavior in the surrounding\nenvironment. However, existing approaches treat perception and captioning as\nseparate tasks, focusing on the performance of only one task and overlooking\nthe potential benefits of multimodal alignment. To bridge this gap between\nmodalities, we introduce MTA, a novel multimodal task alignment framework that\nboosts both BEV perception and captioning. MTA consists of two key components:\n(1) BEV-Language Alignment (BLA), a contextual learning mechanism that aligns\nthe BEV scene representations with ground-truth language representations, and\n(2) Detection-Captioning Alignment (DCA), a cross-modal prompting mechanism\nthat aligns detection and captioning outputs. MTA seamlessly integrates into\nstate-of-the-art baselines during training, adding no extra computational\ncomplexity at runtime. Extensive experiments on the nuScenes and TOD3Cap\ndatasets show that MTA significantly outperforms state-of-the-art baselines in\nboth tasks, achieving a 10.7% improvement in challenging rare perception\nscenarios and a 9.2% improvement in captioning. These results underscore the\neffectiveness of unified alignment in reconciling BEV-based perception and\ncaptioning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.10639v2",
    "published_date": "2024-11-16 00:14:13 UTC",
    "updated_date": "2025-03-10 20:59:22 UTC"
  },
  {
    "arxiv_id": "2411.10636v1",
    "title": "Gender Bias Mitigation for Bangla Classification Tasks",
    "authors": [
      "Sajib Kumar Saha Joy",
      "Arman Hassan Mahy",
      "Meherin Sultana",
      "Azizah Mamun Abha",
      "MD Piyal Ahmmed",
      "Yue Dong",
      "G M Shahariar"
    ],
    "abstract": "In this study, we investigate gender bias in Bangla pretrained language\nmodels, a largely under explored area in low-resource languages. To assess this\nbias, we applied gender-name swapping techniques to existing datasets, creating\nfour manually annotated, task-specific datasets for sentiment analysis,\ntoxicity detection, hate speech detection, and sarcasm detection. By altering\nnames and gender-specific terms, we ensured these datasets were suitable for\ndetecting and mitigating gender bias. We then proposed a joint loss\noptimization technique to mitigate gender bias across task-specific pretrained\nmodels. Our approach was evaluated against existing bias mitigation methods,\nwith results showing that our technique not only effectively reduces bias but\nalso maintains competitive accuracy compared to other baseline approaches. To\npromote further research, we have made both our implementation and datasets\npublicly available\nhttps://github.com/sajib-kumar/Gender-Bias-Mitigation-From-Bangla-PLM",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10636v1",
    "published_date": "2024-11-16 00:04:45 UTC",
    "updated_date": "2024-11-16 00:04:45 UTC"
  }
]