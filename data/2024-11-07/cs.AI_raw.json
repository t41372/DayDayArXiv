[
  {
    "arxiv_id": "2411.05875v1",
    "title": "Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization",
    "authors": [
      "Zhuotong Chen",
      "Fang Liu",
      "Jennifer Zhu",
      "Wanyu Du",
      "Yanjun Qi"
    ],
    "abstract": "Direct Preference Optimization (DPO) and its variants have become the de\nfacto standards for aligning large language models (LLMs) with human\npreferences or specific goals. However, DPO requires high-quality preference\ndata and suffers from unstable preference optimization. In this work, we aim to\nimprove the preference optimization pipeline by taking a closer look at\npreference data generation and training regularization techniques. For\npreference data generation, we demonstrate that existing scoring-based reward\nmodels produce unsatisfactory preference data and perform poorly on\nout-of-distribution tasks. This significantly impacts the LLM alignment\nperformance when using these data for preference tuning. To ensure high-quality\npreference data generation, we propose an iterative pairwise ranking mechanism\nthat derives preference ranking of completions using pairwise comparison\nsignals. For training regularization, we observe that preference optimization\ntends to achieve better convergence when the LLM predicted likelihood of\npreferred samples gets slightly reduced. However, the widely used supervised\nnext-word prediction regularization strictly prevents any likelihood reduction\nof preferred samples. This observation motivates our design of a\nbudget-controlled regularization formulation. Empirically we show that\ncombining the two designs leads to aligned models that surpass existing SOTA\nacross two popular benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.05875v1",
    "published_date": "2024-11-07 23:03:11 UTC",
    "updated_date": "2024-11-07 23:03:11 UTC"
  },
  {
    "arxiv_id": "2411.05232v1",
    "title": "Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities",
    "authors": [
      "Shengzhi Li",
      "Kittipat Kampa",
      "Rongyu Lin",
      "Bohang Li",
      "Shichao Pei"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance across various\ntasks, yet their ability to handle long-context reading remains challenging.\nThis study explores the effectiveness of leveraging high-quality academic peer\nreview data for fine-tuning LLMs to enhance their long-context capabilities. We\ncompare the Direct Preference Optimization (DPO) method with the Supervised\nFine-Tuning (SFT) method, demonstrating DPO's superiority and data efficiency.\nOur experiments show that the fine-tuned model achieves a 4.04-point\nimprovement over phi-3 and a 2.6\\% increase on the Qasper benchmark using only\n2000 samples. Despite facing limitations in data scale and processing costs,\nthis study underscores the potential of DPO and high-quality data in advancing\nLLM performance.\n  Additionally, the zero-shot benchmark results indicate that aggregated\nhigh-quality human reviews are overwhelmingly preferred over LLM-generated\nresponses, even for the most capable models like GPT-4o. This suggests that\nhigh-quality human reviews are extremely rich in information, reasoning, and\nlong-context retrieval, capabilities that even the most advanced models have\nnot fully captured. These findings highlight the high utility of leveraging\nhuman reviews to further advance the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "We share our latest dataset on\n  https://github.com/findalexli/Abstract2Appendix",
    "pdf_url": "http://arxiv.org/pdf/2411.05232v1",
    "published_date": "2024-11-07 22:57:02 UTC",
    "updated_date": "2024-11-07 22:57:02 UTC"
  },
  {
    "arxiv_id": "2411.05874v2",
    "title": "Interplay between Federated Learning and Explainable Artificial Intelligence: a Scoping Review",
    "authors": [
      "Luis M. Lopez-Ramos",
      "Florian Leiser",
      "Aditya Rastogi",
      "Steven Hicks",
      "Inga Strümke",
      "Vince I. Madai",
      "Tobias Budig",
      "Ali Sunyaev",
      "Adam Hilbert"
    ],
    "abstract": "The joint implementation of federated learning (FL) and explainable\nartificial intelligence (XAI) could allow training models from distributed data\nand explaining their inner workings while preserving essential aspects of\nprivacy. Toward establishing the benefits and tensions associated with their\ninterplay, this scoping review maps the publications that jointly deal with FL\nand XAI, focusing on publications that reported an interplay between FL and\nmodel interpretability or post-hoc explanations. Out of the 37 studies meeting\nour criteria, only one explicitly and quantitatively analyzed the influence of\nFL on model explanations, revealing a significant research gap. The aggregation\nof interpretability metrics across FL nodes created generalized global insights\nat the expense of node-specific patterns being diluted. Several studies\nproposed FL algorithms incorporating explanation methods to safeguard the\nlearning process against defaulting or malicious nodes. Studies using\nestablished FL libraries or following reporting guidelines are a minority. More\nquantitative research and structured, transparent practices are needed to fully\nunderstand their mutual impact and under which conditions it happens.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 10 figures, submitted in IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2411.05874v2",
    "published_date": "2024-11-07 22:44:35 UTC",
    "updated_date": "2025-04-10 10:21:56 UTC"
  },
  {
    "arxiv_id": "2411.05209v1",
    "title": "Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs",
    "authors": [
      "Yide Ran",
      "Zhaozhuo Xu",
      "Yuhang Yao",
      "Zijian Hu",
      "Shanshan Han",
      "Han Jin",
      "Alay Dilipbhai Shah",
      "Jipeng Zhang",
      "Dimitris Stripelis",
      "Tong Zhang",
      "Salman Avestimehr",
      "Chaoyang He"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has led to their\nincreased integration into mobile devices for personalized assistance, which\nenables LLMs to call external API functions to enhance their performance.\nHowever, challenges such as data scarcity, ineffective question formatting, and\ncatastrophic forgetting hinder the development of on-device LLM agents. To\ntackle these issues, we propose Alopex, a framework that enables precise\non-device function calls using the Fox LLM. Alopex introduces a logic-based\nmethod for generating high-quality training data and a novel\n``description-question-output'' format for fine-tuning, reducing risks of\nfunction information leakage. Additionally, a data mixing strategy is used to\nmitigate catastrophic forgetting, combining function call data with textbook\ndatasets to enhance performance in various tasks. Experimental results show\nthat Alopex improves function call accuracy and significantly reduces\ncatastrophic forgetting, providing a robust solution for integrating function\ncall capabilities into LLMs without manual intervention.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05209v1",
    "published_date": "2024-11-07 22:15:17 UTC",
    "updated_date": "2024-11-07 22:15:17 UTC"
  },
  {
    "arxiv_id": "2411.05205v1",
    "title": "Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions",
    "authors": [
      "Bowei Li",
      "Yang Xu",
      "Ran Zhang",
      "Jiang",
      "Xie",
      "Miao Wang"
    ],
    "abstract": "Deep reinforcement learning (DRL) has been extensively applied to\nMulti-Unmanned Aerial Vehicle (UAV) network (MUN) to effectively enable\nreal-time adaptation to complex, time-varying environments. Nevertheless, most\nof the existing works assume a stationary user distribution (UD) or a dynamic\none with predicted patterns. Such considerations may make the UD-specific\nstrategies insufficient when a MUN is deployed in unknown environments. To this\nend, this paper investigates distributed user connectivity maximization problem\nin a MUN with generalization to arbitrary UDs. Specifically, the problem is\nfirst formulated into a time-coupled combinatorial nonlinear non-convex\noptimization with arbitrary underlying UDs. To make the optimization tractable,\na multi-agent CNN-enhanced deep Q learning (MA-CDQL) algorithm is proposed. The\nalgorithm integrates a ResNet-based CNN to the policy network to analyze the\ninput UD in real time and obtain optimal decisions based on the extracted\nhigh-level UD features. To improve the learning efficiency and avoid local\noptimums, a heatmap algorithm is developed to transform the raw UD to a\ncontinuous density map. The map will be part of the true input to the policy\nnetwork. Simulations are conducted to demonstrate the efficacy of UD heatmaps\nand the proposed algorithm in maximizing user connectivity as compared to\nK-means methods.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.NI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05205v1",
    "published_date": "2024-11-07 22:10:54 UTC",
    "updated_date": "2024-11-07 22:10:54 UTC"
  },
  {
    "arxiv_id": "2411.05196v2",
    "title": "Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method",
    "authors": [
      "Turker Berk Donmez"
    ],
    "abstract": "In democratic societies, electoral systems play a crucial role in translating\npublic preferences into political representation. Among these, the D'Hondt\nmethod is widely used to ensure proportional representation, balancing fair\nrepresentation with governmental stability. Recently, there has been a growing\ninterest in applying similar principles of proportional representation to\nenhance interpretability in machine learning, specifically in Explainable AI\n(XAI). This study investigates the integration of D'Hondt-based voting\nprinciples in the DhondtXAI method, which leverages resource allocation\nconcepts to interpret feature importance within AI models. Through a comparison\nof SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their\neffectiveness in feature attribution within CatBoost and XGBoost models for\nbreast cancer and diabetes prediction, respectively. The DhondtXAI approach\nallows for alliance formation and thresholding to enhance interpretability,\nrepresenting feature importance as seats in a parliamentary view. Statistical\ncorrelation analyses between SHAP values and DhondtXAI allocations support the\nconsistency of interpretations, demonstrating DhondtXAI's potential as a\ncomplementary tool for understanding feature importance in AI models. The\nresults highlight that integrating electoral principles, such as proportional\nrepresentation and alliances, into AI explainability can improve user\nunderstanding, especially in high-stakes fields like healthcare.",
    "categories": [
      "cs.AI",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05196v2",
    "published_date": "2024-11-07 21:43:29 UTC",
    "updated_date": "2024-11-13 18:58:46 UTC"
  },
  {
    "arxiv_id": "2411.05194v1",
    "title": "Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations",
    "authors": [
      "Joey Hong",
      "Jessica Lin",
      "Anca Dragan",
      "Sergey Levine"
    ],
    "abstract": "Recent progress on large language models (LLMs) has enabled dialogue agents\nto generate highly naturalistic and plausible text. However, current LLM\nlanguage generation focuses on responding accurately to questions and requests\nwith a single effective response. In reality, many real dialogues are\ninteractive, meaning an agent's utterances will influence their conversational\npartner, elicit information, or change their opinion. Accounting for how an\nagent can effectively steer a conversation is a crucial ability in many\ndialogue tasks, from healthcare to preference elicitation. Existing methods for\nfine-tuning dialogue agents to accomplish such tasks would rely on curating\nsome amount of expert data. However, doing so often requires understanding the\nunderlying cognitive processes of the conversational partner, which is a skill\nneither humans nor LLMs trained on human data can reliably do. Our key insight\nis that while LLMs may not be adept at identifying effective strategies for\nsteering conversations a priori, or in the middle of an ongoing conversation,\nthey can do so post-hoc, or in hindsight, after seeing how their conversational\npartner responds. We use this fact to rewrite and augment existing suboptimal\ndata, and train via offline reinforcement learning (RL) an agent that\noutperforms both prompting and learning from unaltered human demonstrations. We\napply our approach to two domains that require understanding human mental\nstate, intelligent interaction, and persuasion: mental health support, and\nsoliciting charitable donations. Our results in a user study with real humans\nshow that our approach greatly outperforms existing state-of-the-art dialogue\nagents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05194v1",
    "published_date": "2024-11-07 21:37:51 UTC",
    "updated_date": "2024-11-07 21:37:51 UTC"
  },
  {
    "arxiv_id": "2411.05193v2",
    "title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning",
    "authors": [
      "Joey Hong",
      "Anca Dragan",
      "Sergey Levine"
    ],
    "abstract": "Value-based reinforcement learning (RL) can in principle learn effective\npolicies for a wide range of multi-turn problems, from games to dialogue to\nrobotic control, including via offline RL from static previously collected\ndatasets. However, despite the widespread use of policy gradient methods to\ntrain large language models for single turn tasks (e.g., question answering),\nvalue-based methods for multi-turn RL in an off-policy or offline setting have\nproven particularly challenging to scale to the setting of large language\nmodels. This setting requires effectively leveraging pretraining, scaling to\nlarge architectures with billions of parameters, and training on large\ndatasets, all of which represent major challenges for current value-based RL\nmethods. In this work, we propose a novel offline RL algorithm that addresses\nthese drawbacks, casting Q-learning as a modified supervised fine-tuning (SFT)\nproblem where the probabilities of tokens directly translate to Q-values. In\nthis way we obtain an algorithm that smoothly transitions from maximizing the\nlikelihood of the data during pretraining to learning a near-optimal Q-function\nduring finetuning. Our algorithm has strong theoretical foundations, enjoying\nperformance bounds similar to state-of-the-art Q-learning methods, while in\npractice utilizing an objective that closely resembles SFT. Because of this,\nour approach can enjoy the full benefits of the pretraining of language models,\nwithout the need to reinitialize any weights before RL finetuning, and without\nthe need to initialize new heads for predicting values or advantages.\nEmpirically, we evaluate our method on both pretrained LLMs and VLMs, on a\nvariety of tasks including both natural language dialogue and robotic\nmanipulation and navigation from images.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05193v2",
    "published_date": "2024-11-07 21:36:52 UTC",
    "updated_date": "2024-11-27 00:05:44 UTC"
  },
  {
    "arxiv_id": "2411.05192v1",
    "title": "Explaining Mixtures of Sources in News Articles",
    "authors": [
      "Alexander Spangher",
      "James Youn",
      "Matt DeButts",
      "Nanyun Peng",
      "Emilio Ferrara",
      "Jonathan May"
    ],
    "abstract": "Human writers plan, then write. For large language models (LLMs) to play a\nrole in longer-form article generation, we must understand the planning steps\nhumans make before writing. We explore one kind of planning, source-selection\nin news, as a case-study for evaluating plans in long-form generation. We ask:\nwhy do specific stories call for specific kinds of sources? We imagine a\ngenerative process for story writing where a source-selection schema is first\nselected by a journalist, and then sources are chosen based on categories in\nthat schema. Learning the article's plan means predicting the schema initially\nchosen by the journalist. Working with professional journalists, we adapt five\nexisting schemata and introduce three new ones to describe journalistic plans\nfor the inclusion of sources in documents. Then, inspired by Bayesian\nlatent-variable modeling, we develop metrics to select the most likely plan, or\nschema, underlying a story, which we use to compare schemata. We find that two\nschemata: stance and social affiliation best explain source plans in most\ndocuments. However, other schemata like textual entailment explain source plans\nin factually rich topics like \"Science\". Finally, we find we can predict the\nmost suitable schema given just the article's headline with reasonable\naccuracy. We see this as an important case-study for human planning, and\nprovides a framework and approach for evaluating other kinds of plans. We\nrelease a corpora, NewsSources, with annotations for 4M articles.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.05192v1",
    "published_date": "2024-11-07 21:34:05 UTC",
    "updated_date": "2024-11-07 21:34:05 UTC"
  },
  {
    "arxiv_id": "2411.11894v1",
    "title": "ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction",
    "authors": [
      "Yoga Suhas Kuruba Manjunath",
      "Mathew Szymanowski",
      "Austin Wissborn",
      "Mushu Li",
      "Lian Zhao",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Our work proposes a comprehensive solution for predicting Metaverse network\ntraffic, addressing the growing demand for intelligent resource management in\neXtended Reality (XR) services. We first introduce a state-of-the-art testbed\ncapturing a real-world dataset of virtual reality (VR), augmented reality (AR),\nand mixed reality (MR) traffic, made openly available for further research. To\nenhance prediction accuracy, we then propose a novel view-frame (VF) algorithm\nthat accurately identifies video frames from traffic while ensuring privacy\ncompliance, and we develop a Transformer-based progressive error-learning\nalgorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn\nsignificantly improves time-series predictions by using fully connected neural\nnetworks to reduce errors, particularly during peak traffic, outperforming\nprior work by 99%. Our contributions offer Internet service providers (ISPs)\nrobust tools for real-time network management to satisfy Quality of Service\n(QoS) and enhance user experience in the Metaverse.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11894v1",
    "published_date": "2024-11-07 21:11:24 UTC",
    "updated_date": "2024-11-07 21:11:24 UTC"
  },
  {
    "arxiv_id": "2411.05184v1",
    "title": "Discern-XR: An Online Classifier for Metaverse Network Traffic",
    "authors": [
      "Yoga Suhas Kuruba Manjunath",
      "Austin Wissborn",
      "Mathew Szymanowski",
      "Mushu Li",
      "Lian Zhao",
      "Xiao-Ping Zhang"
    ],
    "abstract": "In this paper, we design an exclusive Metaverse network traffic classifier,\nnamed Discern-XR, to help Internet service providers (ISP) and router\nmanufacturers enhance the quality of Metaverse services. Leveraging segmented\nlearning, the Frame Vector Representation (FVR) algorithm and Frame\nIdentification Algorithm (FIA) are proposed to extract critical frame-related\nstatistics from raw network data having only four application-level features. A\nnovel Augmentation, Aggregation, and Retention Online Training (A2R-OT)\nalgorithm is proposed to find an accurate classification model through online\ntraining methodology. In addition, we contribute to the real-world Metaverse\ndataset comprising virtual reality (VR) games, VR video, VR chat, augmented\nreality (AR), and mixed reality (MR) traffic, providing a comprehensive\nbenchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while\nimproving training efficiency and reducing false-negative rates. Our work\nadvances Metaverse network traffic classification by standing as the\nstate-of-the-art solution.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05184v1",
    "published_date": "2024-11-07 21:07:49 UTC",
    "updated_date": "2024-11-07 21:07:49 UTC"
  },
  {
    "arxiv_id": "2411.05174v1",
    "title": "Inverse Transition Learning: Learning Dynamics from Demonstrations",
    "authors": [
      "Leo Benac",
      "Abhishek Sharma",
      "Sonali Parbhoo",
      "Finale Doshi-Velez"
    ],
    "abstract": "We consider the problem of estimating the transition dynamics $T^*$ from\nnear-optimal expert trajectories in the context of offline model-based\nreinforcement learning. We develop a novel constraint-based method, Inverse\nTransition Learning, that treats the limited coverage of the expert\ntrajectories as a \\emph{feature}: we use the fact that the expert is\nnear-optimal to inform our estimate of $T^*$. We integrate our constraints into\na Bayesian approach. Across both synthetic environments and real healthcare\nscenarios like Intensive Care Unit (ICU) patient management in hypotension, we\ndemonstrate not only significant improvements in decision-making, but that our\nposterior can inform when transfer will be successful.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05174v1",
    "published_date": "2024-11-07 20:27:29 UTC",
    "updated_date": "2024-11-07 20:27:29 UTC"
  },
  {
    "arxiv_id": "2411.05085v1",
    "title": "PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation",
    "authors": [
      "Daniel C. Castro",
      "Aurelia Bustos",
      "Shruthi Bannur",
      "Stephanie L. Hyland",
      "Kenza Bouzid",
      "Maria Teodora Wetscherek",
      "Maria Dolores Sánchez-Valverde",
      "Lara Jaques-Pérez",
      "Lourdes Pérez-Rodríguez",
      "Kenji Takeda",
      "José María Salinas",
      "Javier Alvarez-Valle",
      "Joaquín Galant Herrero",
      "Antonio Pertusa"
    ],
    "abstract": "Radiology report generation (RRG) aims to create free-text radiology reports\nfrom clinical imaging. Grounded radiology report generation (GRRG) extends RRG\nby including the localisation of individual findings on the image. Currently,\nthere are no manually annotated chest X-ray (CXR) datasets to train GRRG\nmodels. In this work, we present a dataset called PadChest-GR\n(Grounded-Reporting) derived from PadChest aimed at training GRRG models for\nCXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with\ngrounded reports (3,099 abnormal and 1,456 normal), each containing complete\nlists of sentences describing individual present (positive) and absent\n(negative) findings in English and Spanish. In total, PadChest-GR contains\n7,037 positive and 3,422 negative finding sentences. Every positive finding\nsentence is associated with up to two independent sets of bounding boxes\nlabelled by different readers and has categorical labels for finding type,\nlocations, and progression. To the best of our knowledge, PadChest-GR is the\nfirst manually curated dataset designed to train GRRG models for understanding\nand interpreting radiological images and generated text. By including detailed\nlocalization and comprehensive annotations of all clinically relevant findings,\nit provides a valuable resource for developing and evaluating GRRG models from\nCXR images. PadChest-GR can be downloaded under request from\nhttps://bimcv.cipf.es/bimcv-projects/padchest-gr/",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05085v1",
    "published_date": "2024-11-07 19:06:17 UTC",
    "updated_date": "2024-11-07 19:06:17 UTC"
  },
  {
    "arxiv_id": "2411.05003v1",
    "title": "ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning",
    "authors": [
      "David Junhao Zhang",
      "Roni Paiss",
      "Shiran Zada",
      "Nikhil Karnad",
      "David E. Jacobs",
      "Yael Pritch",
      "Inbar Mosseri",
      "Mike Zheng Shou",
      "Neal Wadhwa",
      "Nataniel Ruiz"
    ],
    "abstract": "Recently, breakthroughs in video modeling have allowed for controllable\ncamera trajectories in generated videos. However, these methods cannot be\ndirectly applied to user-provided videos that are not generated by a video\nmodel. In this paper, we present ReCapture, a method for generating new videos\nwith novel camera trajectories from a single user-provided video. Our method\nallows us to re-generate the reference video, with all its existing scene\nmotion, from vastly different angles and with cinematic camera motion. Notably,\nusing our method we can also plausibly hallucinate parts of the scene that were\nnot observable in the reference video. Our method works by (1) generating a\nnoisy anchor video with a new camera trajectory using multiview diffusion\nmodels or depth-based point cloud rendering and then (2) regenerating the\nanchor video into a clean and temporally consistent reangled video using our\nproposed masked video fine-tuning technique.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "project page: https://generative-video-camera-controls.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.05003v1",
    "published_date": "2024-11-07 18:59:45 UTC",
    "updated_date": "2024-11-07 18:59:45 UTC"
  },
  {
    "arxiv_id": "2411.05001v1",
    "title": "Analyzing The Language of Visual Tokens",
    "authors": [
      "David M. Chan",
      "Rodolfo Corona",
      "Joonyong Park",
      "Cheol Jun Cho",
      "Yutong Bai",
      "Trevor Darrell"
    ],
    "abstract": "With the introduction of transformer-based models for vision and language\ntasks, such as LLaVA and Chameleon, there has been renewed interest in the\ndiscrete tokenized representation of images. These models often treat image\npatches as discrete tokens, analogous to words in natural language, learning\njoint alignments between visual and human languages. However, little is known\nabout the statistical behavior of these visual languages - whether they follow\nsimilar frequency distributions, grammatical structures, or topologies as\nnatural languages. In this paper, we take a natural-language-centric approach\nto analyzing discrete visual languages and uncover striking similarities and\nfundamental differences. We demonstrate that, although visual languages adhere\nto Zipfian distributions, higher token innovation drives greater entropy and\nlower compression, with tokens predominantly representing object parts,\nindicating intermediate granularity. We also show that visual languages lack\ncohesive grammatical structures, leading to higher perplexity and weaker\nhierarchical organization compared to natural languages. Finally, we\ndemonstrate that, while vision models align more closely with natural languages\nthan other models, this alignment remains significantly weaker than the\ncohesion found within natural languages. Through these experiments, we\ndemonstrate how understanding the statistical properties of discrete visual\nlanguages can inform the design of more effective computer vision models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05001v1",
    "published_date": "2024-11-07 18:59:28 UTC",
    "updated_date": "2024-11-07 18:59:28 UTC"
  },
  {
    "arxiv_id": "2411.04998v1",
    "title": "HourVideo: 1-Hour Video-Language Understanding",
    "authors": [
      "Keshigeyan Chandrasegaran",
      "Agrim Gupta",
      "Lea M. Hadzic",
      "Taran Kota",
      "Jimming He",
      "Cristóbal Eyzaguirre",
      "Zane Durante",
      "Manling Li",
      "Jiajun Wu",
      "Li Fei-Fei"
    ],
    "abstract": "We present HourVideo, a benchmark dataset for hour-long video-language\nunderstanding. Our dataset consists of a novel task suite comprising\nsummarization, perception (recall, tracking), visual reasoning (spatial,\ntemporal, predictive, causal, counterfactual), and navigation (room-to-room,\nobject retrieval) tasks. HourVideo includes 500 manually curated egocentric\nvideos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and\nfeatures 12,976 high-quality, five-way multiple-choice questions. Benchmarking\nresults reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve\nmarginal improvements over random chance. In stark contrast, human experts\nsignificantly outperform the state-of-the-art long-context multimodal model,\nGemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal\ncapabilities. Our benchmark, evaluation toolkit, prompts, and documentation are\navailable at https://hourvideo.stanford.edu",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Datasets and Benchmarks Track; 28 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.04998v1",
    "published_date": "2024-11-07 18:59:16 UTC",
    "updated_date": "2024-11-07 18:59:16 UTC"
  },
  {
    "arxiv_id": "2411.04994v3",
    "title": "Legacy Procurement Practices Shape How U.S. Cities Govern AI: Understanding Government Employees' Practices, Challenges, and Needs",
    "authors": [
      "Nari Johnson",
      "Elise Silva",
      "Harrison Leon",
      "Motahhare Eslami",
      "Beth Schwanke",
      "Ravit Dotan",
      "Hoda Heidari"
    ],
    "abstract": "Most AI tools adopted by governments are not developed internally, but\ninstead are acquired from third-party vendors in a process called public\nprocurement. In this paper, we conduct the first empirical study of how United\nStates cities' procurement practices shape critical decisions surrounding\npublic sector AI. We conduct semi-structured interviews with 19 city employees\nwho oversee AI procurement across 7 U.S. cities. We found that cities' legacy\nprocurement practices, which are shaped by decades-old laws and norms,\nestablish infrastructure that determines which AI is purchased, and which\nactors hold decision-making power over procured AI. We characterize the\nemerging actions cities have taken to adapt their purchasing practices to\naddress algorithmic harms. From employees' reflections on real-world AI\nprocurements, we identify three key challenges that motivate but are not fully\naddressed by existing AI procurement reform initiatives. Based on these\nfindings, we discuss implications and opportunities for the FAccT community to\nsupport cities in foreseeing and preventing AI harms throughout the public\nprocurement processes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 2 column format. In proceedings of ACM FAccT 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.04994v3",
    "published_date": "2024-11-07 18:58:16 UTC",
    "updated_date": "2025-05-13 01:13:45 UTC"
  },
  {
    "arxiv_id": "2411.04991v2",
    "title": "Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives",
    "authors": [
      "Hao Sun",
      "Yunyi Shen",
      "Jean-Francois Ton"
    ],
    "abstract": "The Bradley-Terry (BT) model is a common and successful practice in reward\nmodeling for Large Language Model (LLM) alignment. However, it remains unclear\nwhy this model -- originally developed for multi-player stochastic game\nmatching -- can be adopted to convert pairwise response comparisons to reward\nvalues and make predictions. Especially given the fact that only a limited\nnumber of prompt-response pairs are sparsely compared with others. In this\npaper, we first revisit the foundations of using BT models in reward modeling,\nand establish the convergence rate of BT reward models based on deep neural\nnetworks using embeddings, providing a theoretical foundation for their use.\nDespite theoretically sound, we argue that the BT model is not a necessary\nchoice from the perspective of downstream optimization. This is because a\nreward model only needs to preserve the correct ranking predictions through a\nmonotonic transformation of the true reward. We highlight the critical concept\nof order consistency in reward modeling and demonstrate that the BT model\npossesses this property. Consequently, we propose a simple and straightforward\nupper-bound algorithm, compatible with off-the-shelf binary classifiers, as an\nalternative order-consistent reward modeling objective. To offer practical\ninsights, we empirically evaluate the performance of these different reward\nmodeling approaches across more than 12,000 experimental setups, using $6$ base\nLLMs, $2$ datasets, and diverse annotation designs that vary in quantity,\nquality, and pairing choices in preference annotations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04991v2",
    "published_date": "2024-11-07 18:57:03 UTC",
    "updated_date": "2025-01-26 00:46:36 UTC"
  },
  {
    "arxiv_id": "2411.04990v2",
    "title": "Clustering in Causal Attention Masking",
    "authors": [
      "Nikita Karagodin",
      "Yury Polyanskiy",
      "Philippe Rigollet"
    ],
    "abstract": "This work presents a modification of the self-attention dynamics proposed by\nGeshkovski et al. (arXiv:2312.10794) to better reflect the practically\nrelevant, causally masked attention used in transformer architectures for\ngenerative AI. This modification translates into an interacting particle system\nthat cannot be interpreted as a mean-field gradient flow. Despite this loss of\nstructure, we significantly strengthen the results of Geshkovski et al.\n(arXiv:2312.10794) in this context: While previous rigorous results focused on\ncases where all three matrices (Key, Query, and Value) were scaled identities,\nwe prove asymptotic convergence to a single cluster for arbitrary key-query\nmatrices and a value matrix equal to the identity. Additionally, we establish a\nconnection to the classical R\\'enyi parking problem from combinatorial geometry\nto make initial theoretical steps towards demonstrating the existence of\nmeta-stable states.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "math.DS",
      "68T07, 35Q68, 37N99, 82C22"
    ],
    "primary_category": "cs.LG",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024), 22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04990v2",
    "published_date": "2024-11-07 18:56:37 UTC",
    "updated_date": "2024-11-10 17:07:45 UTC"
  },
  {
    "arxiv_id": "2411.04987v2",
    "title": "Few-Shot Task Learning through Inverse Generative Modeling",
    "authors": [
      "Aviv Netanyahu",
      "Yilun Du",
      "Antonia Bronars",
      "Jyothish Pari",
      "Joshua Tenenbaum",
      "Tianmin Shu",
      "Pulkit Agrawal"
    ],
    "abstract": "Learning the intents of an agent, defined by its goals or motion style, is\noften extremely challenging from just a few examples. We refer to this problem\nas task concept learning and present our approach, Few-Shot Task Learning\nthrough Inverse Generative Modeling (FTL-IGM), which learns new task concepts\nby leveraging invertible neural generative models. The core idea is to pretrain\na generative model on a set of basic concepts and their demonstrations. Then,\ngiven a few demonstrations of a new concept (such as a new goal or a new\naction), our method learns the underlying concepts through backpropagation\nwithout updating the model weights, thanks to the invertibility of the\ngenerative model. We evaluate our method in five domains -- object\nrearrangement, goal-oriented navigation, motion caption of human actions,\nautonomous driving, and real-world table-top manipulation. Our experimental\nresults demonstrate that via the pretrained generative model, we successfully\nlearn novel concepts and generate agent plans or motion corresponding to these\nconcepts in (1) unseen environments and (2) in composition with training\nconcepts.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Added acknowledgment",
    "pdf_url": "http://arxiv.org/pdf/2411.04987v2",
    "published_date": "2024-11-07 18:55:10 UTC",
    "updated_date": "2025-01-13 18:24:22 UTC"
  },
  {
    "arxiv_id": "2411.04983v2",
    "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
    "authors": [
      "Gaoyue Zhou",
      "Hengkai Pan",
      "Yann LeCun",
      "Lerrel Pinto"
    ],
    "abstract": "The ability to predict future outcomes given control actions is fundamental\nfor physical reasoning. However, such predictive models, often called world\nmodels, remains challenging to learn and are typically developed for\ntask-specific solutions with online policy learning. To unlock world models'\ntrue potential, we argue that they should 1) be trainable on offline,\npre-collected trajectories, 2) support test-time behavior optimization, and 3)\nfacilitate task-agnostic reasoning. To this end, we present DINO World Model\n(DINO-WM), a new method to model visual dynamics without reconstructing the\nvisual world. DINO-WM leverages spatial patch features pre-trained with DINOv2,\nenabling it to learn from offline behavioral trajectories by predicting future\npatch features. This allows DINO-WM to achieve observational goals through\naction sequence optimization, facilitating task-agnostic planning by treating\ngoal features as prediction targets. We demonstrate that DINO-WM achieves\nzero-shot behavioral solutions at test time on six environments without expert\ndemonstrations, reward modeling, or pre-learned inverse models, outperforming\nprior state-of-the-art work across diverse task families such as arbitrarily\nconfigured mazes, push manipulation with varied object shapes, and\nmulti-particle scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04983v2",
    "published_date": "2024-11-07 18:54:37 UTC",
    "updated_date": "2025-02-01 02:40:49 UTC"
  },
  {
    "arxiv_id": "2411.04981v1",
    "title": "Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries",
    "authors": [
      "Dylan Manuel",
      "Nafis Tanveer Islam",
      "Joseph Khoury",
      "Ana Nunez",
      "Elias Bou-Harb",
      "Peyman Najafirad"
    ],
    "abstract": "Security experts reverse engineer (decompile) binary code to identify\ncritical security vulnerabilities. The limited access to source code in vital\nsystems - such as firmware, drivers, and proprietary software used in Critical\nInfrastructures (CI) - makes this analysis even more crucial on the binary\nlevel. Even with available source code, a semantic gap persists after\ncompilation between the source and the binary code executed by the processor.\nThis gap may hinder the detection of vulnerabilities in source code. That being\nsaid, current research on Large Language Models (LLMs) overlooks the\nsignificance of decompiled binaries in this area by focusing solely on source\ncode. In this work, we are the first to empirically uncover the substantial\nsemantic limitations of state-of-the-art LLMs when it comes to analyzing\nvulnerabilities in decompiled binaries, largely due to the absence of relevant\ndatasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary\ncode vulnerability dataset. Our dataset is multi-architecture and\nmulti-optimization, focusing on C/C++ due to their wide usage in CI and\nassociation with numerous vulnerabilities. Specifically, we curate 150,872\nsamples of vulnerable and non-vulnerable decompiled binary code for the task of\n(i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv)\nrecovering function names in the domain of decompiled binaries. Subsequently,\nwe fine-tune state-of-the-art LLMs using DeBinVul and report on a performance\nincrease of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and\nCodeGen2 respectively, in detecting binary code vulnerabilities. Additionally,\nusing DeBinVul, we report a high performance of 80-90% on the vulnerability\nclassification task. Furthermore, we report improved performance in function\nname recovery and vulnerability description tasks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04981v1",
    "published_date": "2024-11-07 18:54:31 UTC",
    "updated_date": "2024-11-07 18:54:31 UTC"
  },
  {
    "arxiv_id": "2411.04975v1",
    "title": "SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference",
    "authors": [
      "Gabriele Oliaro",
      "Zhihao Jia",
      "Daniel Campos",
      "Aurick Qiao"
    ],
    "abstract": "We present SuffixDecoding, a novel model-free approach to accelerating large\nlanguage model (LLM) inference through speculative decoding. Unlike existing\nmethods that rely on draft models or specialized decoding heads, SuffixDecoding\nleverages suffix trees built from previously generated outputs to efficiently\npredict candidate token sequences. Our approach enables flexible\ntree-structured speculation without the overhead of maintaining and\norchestrating additional models. SuffixDecoding builds and dynamically updates\nsuffix trees to capture patterns in the generated text, using them to construct\nspeculation trees through a principled scoring mechanism based on empirical\ntoken frequencies. SuffixDecoding requires only CPU memory which is plentiful\nand underutilized on typical LLM serving nodes. We demonstrate that\nSuffixDecoding achieves competitive speedups compared to model-based approaches\nacross diverse workloads including open-domain chat, code generation, and\ntext-to-SQL tasks. For open-ended chat and code generation tasks,\nSuffixDecoding achieves up to $1.4\\times$ higher output throughput than\nSpecInfer and up to $1.1\\times$ lower time-per-token (TPOT) latency. For a\nproprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to\n$2.9\\times$ higher output throughput and $3\\times$ lower latency than\nspeculative decoding. Our evaluation shows that SuffixDecoding maintains high\nacceptance rates even with small reference corpora of 256 examples, while\ncontinuing to improve performance as more historical outputs are incorporated.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04975v1",
    "published_date": "2024-11-07 18:49:33 UTC",
    "updated_date": "2024-11-07 18:49:33 UTC"
  },
  {
    "arxiv_id": "2411.04962v1",
    "title": "Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability",
    "authors": [
      "Yanjun Gao",
      "Skatje Myers",
      "Shan Chen",
      "Dmitriy Dligach",
      "Timothy A Miller",
      "Danielle Bitterman",
      "Guanhua Chen",
      "Anoop Mayampurath",
      "Matthew Churpek",
      "Majid Afshar"
    ],
    "abstract": "Large language models (LLMs) are being explored for diagnostic decision\nsupport, yet their ability to estimate pre-test probabilities, vital for\nclinical decision-making, remains limited. This study evaluates two LLMs,\nMistral-7B and Llama3-70B, using structured electronic health record data on\nthree diagnosis tasks. We examined three current methods of extracting LLM\nprobability estimations and revealed their limitations. We aim to highlight the\nneed for improved techniques in LLM confidence estimation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to GenAI4Health Workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04962v1",
    "published_date": "2024-11-07 18:39:04 UTC",
    "updated_date": "2024-11-07 18:39:04 UTC"
  },
  {
    "arxiv_id": "2411.04956v2",
    "title": "Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification",
    "authors": [
      "Mischa Dombrowski",
      "Hadrien Reynaud",
      "Bernhard Kainz"
    ],
    "abstract": "Latent Video Diffusion Models can easily deceive casual observers and domain\nexperts alike thanks to the produced image quality and temporal consistency.\nBeyond entertainment, this creates opportunities around safe data sharing of\nfully synthetic datasets, which are crucial in healthcare, as well as other\ndomains relying on sensitive personal information. However, privacy concerns\nwith this approach have not fully been addressed yet, and models trained on\nsynthetic data for specific downstream tasks still perform worse than those\ntrained on real data. This discrepancy may be partly due to the sampling space\nbeing a subspace of the training videos, effectively reducing the training data\nsize for downstream models. Additionally, the reduced temporal consistency when\ngenerating long videos could be a contributing factor.\n  In this paper, we first show that training privacy-preserving models in\nlatent space is computationally more efficient and generalize better.\nFurthermore, to investigate downstream degradation factors, we propose to use a\nre-identification model, previously employed as a privacy preservation filter.\nWe demonstrate that it is sufficient to train this model on the latent space of\nthe video generator. Subsequently, we use these models to evaluate the subspace\ncovered by synthetic video datasets and thus introduce a new way to measure the\nfaithfulness of generative machine learning models. We focus on a specific\napplication in healthcare echocardiography to illustrate the effectiveness of\nour novel methods. Our findings indicate that only up to 30.8% of the training\nvideos are learned in latent video diffusion models, which could explain the\nlack of performance when training downstream tasks on synthetic data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 tables, 6 figures; v2 Acknowledgements added",
    "pdf_url": "http://arxiv.org/pdf/2411.04956v2",
    "published_date": "2024-11-07 18:32:00 UTC",
    "updated_date": "2024-12-12 10:10:19 UTC"
  },
  {
    "arxiv_id": "2411.04952v1",
    "title": "M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding",
    "authors": [
      "Jaemin Cho",
      "Debanjan Mahata",
      "Ozan Irsoy",
      "Yujie He",
      "Mohit Bansal"
    ],
    "abstract": "Document visual question answering (DocVQA) pipelines that answer questions\nfrom documents have broad applications. Existing methods focus on handling\nsingle-page documents with multi-modal language models (MLMs), or rely on\ntext-based retrieval-augmented generation (RAG) that uses text extraction tools\nsuch as optical character recognition (OCR). However, there are difficulties in\napplying these methods in real-world scenarios: (a) questions often require\ninformation across different pages or documents, where MLMs cannot handle many\nlong documents; (b) documents often have important information in visual\nelements such as figures, but text extraction tools ignore them. We introduce\nM3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various\ndocument contexts (closed-domain and open-domain), question hops (single-hop\nand multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG\nfinds relevant documents and answers questions using a multi-modal retriever\nand an MLM, so that it can efficiently handle single or many documents while\npreserving visual information. Since previous DocVQA datasets ask questions in\nthe context of a specific document, we also present M3DocVQA, a new benchmark\nfor evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.\nIn three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results\nshow that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance\nthan many strong baselines, including state-of-the-art performance in\nMP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and\nretrieval models. Lastly, we qualitatively show that M3DocRAG can successfully\nhandle various scenarios, such as when relevant information exists across\nmultiple pages and when answer evidence only exists in images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Project webpage: https://m3docrag.github.io",
    "pdf_url": "http://arxiv.org/pdf/2411.04952v1",
    "published_date": "2024-11-07 18:29:38 UTC",
    "updated_date": "2024-11-07 18:29:38 UTC"
  },
  {
    "arxiv_id": "2411.04946v1",
    "title": "SPGD: Steepest Perturbed Gradient Descent Optimization",
    "authors": [
      "Amir M. Vahedi",
      "Horea T. Ilies"
    ],
    "abstract": "Optimization algorithms are pivotal in advancing various scientific and\nindustrial fields but often encounter obstacles such as trapping in local\nminima, saddle points, and plateaus (flat regions), which makes the convergence\nto reasonable or near-optimal solutions particularly challenging. This paper\npresents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that\ninnovatively combines the principles of the gradient descent method with\nperiodic uniform perturbation sampling to effectively circumvent these\nimpediments and lead to better solutions whenever possible. SPGD is\ndistinctively designed to generate a set of candidate solutions and select the\none exhibiting the steepest loss difference relative to the current solution.\nIt enhances the traditional gradient descent approach by integrating a\nstrategic exploration mechanism that significantly increases the likelihood of\nescaping sub-optimal local minima and navigating complex optimization\nlandscapes effectively. Our approach not only retains the directed efficiency\nof gradient descent but also leverages the exploratory benefits of stochastic\nperturbations, thus enabling a more comprehensive search for global optima\nacross diverse problem spaces. We demonstrate the efficacy of SPGD in solving\nthe 3D component packing problem, an NP-hard challenge. Preliminary results\nshow a substantial improvement over four established methods, particularly on\nresponse surfaces with complex topographies and in multidimensional non-convex\ncontinuous optimization problems. Comparative analyses with established 2D\nbenchmark functions highlight SPGD's superior performance, showcasing its\nability to navigate complex optimization landscapes. These results emphasize\nSPGD's potential as a versatile tool for a wide range of optimization problems.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "math-ph",
      "math.MP"
    ],
    "primary_category": "math.OC",
    "comment": "28 pages, 26 figures, submitted to Journal of Mechanical Design",
    "pdf_url": "http://arxiv.org/pdf/2411.04946v1",
    "published_date": "2024-11-07 18:23:30 UTC",
    "updated_date": "2024-11-07 18:23:30 UTC"
  },
  {
    "arxiv_id": "2411.05059v2",
    "title": "FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?",
    "authors": [
      "Eric Wu",
      "Kevin Wu",
      "James Zou"
    ],
    "abstract": "There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05059v2",
    "published_date": "2024-11-07 18:22:14 UTC",
    "updated_date": "2024-11-11 21:48:52 UTC"
  },
  {
    "arxiv_id": "2411.04928v1",
    "title": "DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion",
    "authors": [
      "Wenqiang Sun",
      "Shuo Chen",
      "Fangfu Liu",
      "Zilong Chen",
      "Yueqi Duan",
      "Jun Zhang",
      "Yikai Wang"
    ],
    "abstract": "In this paper, we introduce \\textbf{DimensionX}, a framework designed to\ngenerate photorealistic 3D and 4D scenes from just a single image with video\ndiffusion. Our approach begins with the insight that both the spatial structure\nof a 3D scene and the temporal evolution of a 4D scene can be effectively\nrepresented through sequences of video frames. While recent video diffusion\nmodels have shown remarkable success in producing vivid visuals, they face\nlimitations in directly recovering 3D/4D scenes due to limited spatial and\ntemporal controllability during generation. To overcome this, we propose\nST-Director, which decouples spatial and temporal factors in video diffusion by\nlearning dimension-aware LoRAs from dimension-variant data. This controllable\nvideo diffusion approach enables precise manipulation of spatial structure and\ntemporal dynamics, allowing us to reconstruct both 3D and 4D representations\nfrom sequential frames with the combination of spatial and temporal dimensions.\nAdditionally, to bridge the gap between generated videos and real-world scenes,\nwe introduce a trajectory-aware mechanism for 3D generation and an\nidentity-preserving denoising strategy for 4D generation. Extensive experiments\non various real-world and synthetic datasets demonstrate that DimensionX\nachieves superior results in controllable video generation, as well as in 3D\nand 4D scene generation, compared with previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://chenshuo20.github.io/DimensionX/",
    "pdf_url": "http://arxiv.org/pdf/2411.04928v1",
    "published_date": "2024-11-07 18:07:31 UTC",
    "updated_date": "2024-11-07 18:07:31 UTC"
  },
  {
    "arxiv_id": "2411.04925v2",
    "title": "StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration",
    "authors": [
      "Panwen Hu",
      "Jin Jiang",
      "Jianqi Chen",
      "Mingfei Han",
      "Shengcai Liao",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ],
    "abstract": "The advent of AI-Generated Content (AIGC) has spurred research into automated\nvideo generation to streamline conventional processes. However, automating\nstorytelling video production, particularly for customized narratives, remains\nchallenging due to the complexity of maintaining subject consistency across\nshots. While existing approaches like Mora and AesopAgent integrate multiple\nagents for Story-to-Video (S2V) generation, they fall short in preserving\nprotagonist consistency and supporting Customized Storytelling Video Generation\n(CSVG). To address these limitations, we propose StoryAgent, a multi-agent\nframework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks\nassigned to specialized agents, mirroring the professional production process.\nNotably, our framework includes agents for story design, storyboard generation,\nvideo creation, agent coordination, and result evaluation. Leveraging the\nstrengths of different models, StoryAgent enhances control over the generation\nprocess, significantly improving character consistency. Specifically, we\nintroduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance\nintra-shot temporal consistency, while a novel storyboard generation pipeline\nis proposed to maintain subject consistency across shots. Extensive experiments\ndemonstrate the effectiveness of our approach in synthesizing highly consistent\nstorytelling videos, outperforming state-of-the-art methods. Our contributions\ninclude the introduction of StoryAgent, a versatile framework for video\ngeneration tasks, and novel techniques for preserving protagonist consistency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04925v2",
    "published_date": "2024-11-07 18:00:33 UTC",
    "updated_date": "2024-11-11 13:24:18 UTC"
  },
  {
    "arxiv_id": "2411.04920v3",
    "title": "GPTKB: Comprehensively Materializing Factual LLM Knowledge",
    "authors": [
      "Yujia Hu",
      "Tuan-Phong Nguyen",
      "Shrestha Ghosh",
      "Simon Razniewski"
    ],
    "abstract": "LLMs have majorly advanced NLP and AI, and next to their ability to perform a\nwide range of procedural tasks, a major success factor is their internalized\nfactual knowledge. Since (Petroni et al., 2019), analyzing this knowledge has\ngained attention. However, most approaches investigate one question at a time\nvia modest-sized pre-defined samples, introducing an availability bias (Tversky\nand Kahnemann, 1973) that prevents the discovery of knowledge (or beliefs) of\nLLMs beyond the experimenter's predisposition.\n  To address this challenge, we propose a novel methodology to comprehensively\nmaterializing an LLM's factual knowledge through recursive querying and result\nconsolidation.\n  As a prototype, we employ GPT-4o-mini to construct GPTKB, a large-scale\nknowledge base (KB) comprising 105 million triples for over 2.9 million\nentities - achieved at 1% of the cost of previous KB projects. This work marks\na milestone in two areas: For LLM research, for the first time, it provides\nconstructive insights into the scope and structure of LLMs' knowledge (or\nbeliefs). For KB construction, it pioneers new pathways for the long-standing\nchallenge of general-domain KB construction. GPTKB is accessible at\nhttps://gptkb.org.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 4 tables, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04920v3",
    "published_date": "2024-11-07 17:57:03 UTC",
    "updated_date": "2024-12-16 14:05:03 UTC"
  },
  {
    "arxiv_id": "2411.04915v1",
    "title": "Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping",
    "authors": [
      "Bavo Lesy",
      "Ali Anwar",
      "Siegfried Mercelis"
    ],
    "abstract": "Recently, there has been growing interest in autonomous shipping due to its\npotential to improve maritime efficiency and safety. The use of advanced\ntechnologies, such as artificial intelligence, can address the current\nnavigational and operational challenges in autonomous shipping. In particular,\ninland waterway transport (IWT) presents a unique set of challenges, such as\ncrowded waterways and variable environmental conditions. In such dynamic\nsettings, the reliability and robustness of autonomous shipping solutions are\ncritical factors for ensuring safe operations. This paper examines the\nrobustness of benchmark deep reinforcement learning (RL) algorithms,\nimplemented for IWT within an autonomous shipping simulator, and their ability\nto generate effective motion planning policies. We demonstrate that a\nmodel-free approach can achieve an adequate policy in the simulator,\nsuccessfully navigating port environments never encountered during training. We\nfocus particularly on Soft-Actor Critic (SAC), which we show to be inherently\nmore robust to environmental disturbances compared to MuZero, a\nstate-of-the-art model-based RL algorithm. In this paper, we take a significant\nstep towards developing robust, applied RL frameworks that can be generalized\nto various vessel types and navigate complex port- and inland environments and\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 4 figures. Will be presented at IEEE RAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04915v1",
    "published_date": "2024-11-07 17:55:07 UTC",
    "updated_date": "2024-11-07 17:55:07 UTC"
  },
  {
    "arxiv_id": "2411.04890v2",
    "title": "GUI Agents with Foundation Models: A Comprehensive Survey",
    "authors": [
      "Shuai Wang",
      "Weiwen Liu",
      "Jingxuan Chen",
      "Yuqi Zhou",
      "Weinan Gan",
      "Xingshan Zeng",
      "Yuhan Che",
      "Shuai Yu",
      "Xinlong Hao",
      "Kun Shao",
      "Bin Wang",
      "Chuhan Wu",
      "Yasheng Wang",
      "Ruiming Tang",
      "Jianye Hao"
    ],
    "abstract": "Recent advances in foundation models, particularly Large Language Models\n(LLMs) and Multimodal Large Language Models (MLLMs), have facilitated the\ndevelopment of intelligent agents capable of performing complex tasks. By\nleveraging the ability of (M)LLMs to process and interpret Graphical User\nInterfaces (GUIs), these agents can autonomously execute user instructions,\nsimulating human-like interactions such as clicking and typing. This survey\nconsolidates recent research on (M)LLM-based GUI agents, highlighting key\ninnovations in data resources, frameworks, and applications. We begin by\nreviewing representative datasets and benchmarks, followed by an overview of a\ngeneralized, unified framework that encapsulates the essential components of\nprior studies, supported by a detailed taxonomy. Additionally, we explore\nrelevant commercial applications. Drawing insights from existing work, we\nidentify key challenges and propose future research directions. We hope this\nsurvey will inspire further advancements in the field of (M)LLM-based GUI\nagents.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04890v2",
    "published_date": "2024-11-07 17:28:10 UTC",
    "updated_date": "2025-02-13 10:09:37 UTC"
  },
  {
    "arxiv_id": "2411.04872v5",
    "title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI",
    "authors": [
      "Elliot Glazer",
      "Ege Erdil",
      "Tamay Besiroglu",
      "Diego Chicharro",
      "Evan Chen",
      "Alex Gunning",
      "Caroline Falkman Olsson",
      "Jean-Stanislas Denain",
      "Anson Ho",
      "Emily de Oliveira Santos",
      "Olli Järviniemi",
      "Matthew Barnett",
      "Robert Sandler",
      "Matej Vrzala",
      "Jaime Sevilla",
      "Qiuyu Ren",
      "Elizabeth Pratt",
      "Lionel Levine",
      "Grant Barkley",
      "Natalie Stewart",
      "Bogdan Grechuk",
      "Tetiana Grechuk",
      "Shreepranav Varma Enugandla",
      "Mark Wildon"
    ],
    "abstract": "We introduce FrontierMath, a benchmark of hundreds of original, exceptionally\nchallenging mathematics problems crafted and vetted by expert mathematicians.\nThe questions cover most major branches of modern mathematics -- from\ncomputationally intensive problems in number theory and real analysis to\nabstract questions in algebraic geometry and category theory. Solving a typical\nproblem requires multiple hours of effort from a researcher in the relevant\nbranch of mathematics, and for the upper end questions, multiple days.\nFrontierMath uses new, unpublished problems and automated verification to\nreliably evaluate models while minimizing risk of data contamination. Current\nstate-of-the-art AI models solve under 2% of problems, revealing a vast gap\nbetween AI capabilities and the prowess of the mathematical community. As AI\nsystems advance toward expert-level mathematical abilities, FrontierMath offers\na rigorous testbed that quantifies their progress.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04872v5",
    "published_date": "2024-11-07 17:07:35 UTC",
    "updated_date": "2024-12-20 03:27:06 UTC"
  },
  {
    "arxiv_id": "2411.04867v2",
    "title": "Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning",
    "authors": [
      "Satchit Chatterji",
      "Erman Acar"
    ],
    "abstract": "Safe reinforcement learning (RL) is crucial for real-world applications, and\nmulti-agent interactions introduce additional safety challenges. While\nProbabilistic Logic Shields (PLS) has been a powerful proposal to enforce\nsafety in single-agent RL, their generalizability to multi-agent settings\nremains unexplored. In this paper, we address this gap by conducting extensive\nanalyses of PLS within decentralized, multi-agent environments, and in doing\nso, propose Shielded Multi-Agent Reinforcement Learning (SMARL) as a general\nframework for steering MARL towards norm-compliant outcomes. Our key\ncontributions are: (1) a novel Probabilistic Logic Temporal Difference (PLTD)\nupdate for shielded, independent Q-learning, which incorporates probabilistic\nconstraints directly into the value update process; (2) a probabilistic logic\npolicy gradient method for shielded PPO with formal safety guarantees for MARL;\nand (3) comprehensive evaluation across symmetric and asymmetrically shielded\n$n$-player game-theoretic benchmarks, demonstrating fewer constraint violations\nand significantly better cooperation under normative constraints. These results\nposition SMARL as an effective mechanism for equilibrium selection, paving the\nway toward safer, socially aligned multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 16 figures, Earlier title: \"Analyzing Probabilistic Logic\n  Driven Safety in Multi-Agent Reinforcement Learning\" (changed for specificity\n  and clarity)",
    "pdf_url": "http://arxiv.org/pdf/2411.04867v2",
    "published_date": "2024-11-07 16:59:32 UTC",
    "updated_date": "2025-05-14 13:30:31 UTC"
  },
  {
    "arxiv_id": "2411.04865v4",
    "title": "ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset",
    "authors": [
      "Olaf Wysocki",
      "Yue Tan",
      "Thomas Froech",
      "Yan Xia",
      "Magdalena Wysocki",
      "Ludwig Hoegner",
      "Daniel Cremers",
      "Christoph Holst"
    ],
    "abstract": "Facade semantic segmentation is a long-standing challenge in photogrammetry\nand computer vision. Although the last decades have witnessed the influx of\nfacade segmentation methods, there is a lack of comprehensive facade classes\nand data covering the architectural variability. In ZAHA, we introduce Level of\nFacade Generalization (LoFG), novel hierarchical facade classes designed based\non international urban modeling standards, ensuring compatibility with\nreal-world challenging classes and uniform methods' comparison. Realizing the\nLoFG, we present to date the largest semantic 3D facade segmentation dataset,\nproviding 601 million annotated points at five and 15 classes of LoFG2 and\nLoFG3, respectively. Moreover, we analyze the performance of baseline semantic\nsegmentation methods on our introduced LoFG classes and data, complementing it\nwith a discussion on the unresolved challenges for facade segmentation. We\nfirmly believe that ZAHA shall facilitate further development of 3D facade\nsemantic segmentation methods, enabling robust segmentation indispensable in\ncreating urban digital twins.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV))",
    "pdf_url": "http://arxiv.org/pdf/2411.04865v4",
    "published_date": "2024-11-07 16:58:18 UTC",
    "updated_date": "2024-12-19 13:45:39 UTC"
  },
  {
    "arxiv_id": "2411.04859v1",
    "title": "A multi-purpose automatic editing system based on lecture semantics for remote education",
    "authors": [
      "Panwen Hu",
      "Rui Huang"
    ],
    "abstract": "Remote teaching has become popular recently due to its convenience and\nsafety, especially under extreme circumstances like a pandemic. However, online\nstudents usually have a poor experience since the information acquired from the\nviews provided by the broadcast platforms is limited. One potential solution is\nto show more camera views simultaneously, but it is technically challenging and\ndistracting for the viewers. Therefore, an automatic multi-camera\ndirecting/editing system, which aims at selecting the most concerned view at\neach time instance to guide the attention of online students, is in urgent\ndemand. However, existing systems mostly make simple assumptions and focus on\ntracking the position of the speaker instead of the real lecture semantics, and\ntherefore have limited capacities to deliver optimal information flow. To this\nend, this paper proposes an automatic multi-purpose editing system based on the\nlecture semantics, which can both direct the multiple video streams for\nreal-time broadcasting and edit the optimal video offline for review purposes.\nOur system directs the views by semantically analyzing the class events while\nfollowing the professional directing rules, mimicking a human director to\ncapture the regions of interest from the viewpoint of the onsite students. We\nconduct both qualitative and quantitative analyses to verify the effectiveness\nof the proposed system and its components.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04859v1",
    "published_date": "2024-11-07 16:49:25 UTC",
    "updated_date": "2024-11-07 16:49:25 UTC"
  },
  {
    "arxiv_id": "2411.04838v1",
    "title": "Machine learning and optimization-based approaches to duality in statistical physics",
    "authors": [
      "Andrea E. V. Ferrari",
      "Prateek Gupta",
      "Nabil Iqbal"
    ],
    "abstract": "The notion of duality -- that a given physical system can have two different\nmathematical descriptions -- is a key idea in modern theoretical physics.\nEstablishing a duality in lattice statistical mechanics models requires the\nconstruction of a dual Hamiltonian and a map from the original to the dual\nobservables. By using simple neural networks to parameterize these maps and\nintroducing a loss function that penalises the difference between correlation\nfunctions in original and dual models, we formulate the process of duality\ndiscovery as an optimization problem. We numerically solve this problem and\nshow that our framework can rediscover the celebrated Kramers-Wannier duality\nfor the 2d Ising model, reconstructing the known mapping of temperatures. We\nalso discuss an alternative approach which uses known features of the mapping\nof topological lines to reduce the problem to optimizing the couplings in a\ndual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d\nIsing duality. We discuss future directions and prospects for discovering new\ndualities within this framework.",
    "categories": [
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "hep-th"
    ],
    "primary_category": "cond-mat.stat-mech",
    "comment": "27 pages + appendices, lots of plots",
    "pdf_url": "http://arxiv.org/pdf/2411.04838v1",
    "published_date": "2024-11-07 16:29:03 UTC",
    "updated_date": "2024-11-07 16:29:03 UTC"
  },
  {
    "arxiv_id": "2411.05056v1",
    "title": "Seeing is Deceiving: Exploitation of Visual Pathways in Multi-Modal Language Models",
    "authors": [
      "Pete Janowczyk",
      "Linda Laurier",
      "Ave Giulietta",
      "Arlo Octavia",
      "Meade Cleti"
    ],
    "abstract": "Multi-Modal Language Models (MLLMs) have transformed artificial intelligence\nby combining visual and text data, making applications like image captioning,\nvisual question answering, and multi-modal content creation possible. This\nability to understand and work with complex information has made MLLMs useful\nin areas such as healthcare, autonomous systems, and digital content. However,\nintegrating multiple types of data also creates security risks. Attackers can\nmanipulate either the visual or text inputs, or both, to make the model produce\nunintended or even harmful responses. This paper reviews how visual inputs in\nMLLMs can be exploited by various attack strategies. We break down these\nattacks into categories: simple visual tweaks and cross-modal manipulations, as\nwell as advanced strategies like VLATTACK, HADES, and Collaborative Multimodal\nAdversarial Attack (Co-Attack). These attacks can mislead even the most robust\nmodels while looking nearly identical to the original visuals, making them hard\nto detect. We also discuss the broader security risks, including threats to\nprivacy and safety in important applications. To counter these risks, we review\ncurrent defense methods like the SmoothVLM framework, pixel-wise randomization,\nand MirrorCheck, looking at their strengths and limitations. We also discuss\nnew methods to make MLLMs more secure, including adaptive defenses, better\nevaluation tools, and security approaches that protect both visual and text\ndata. By bringing together recent developments and identifying key areas for\nimprovement, this review aims to support the creation of more secure and\nreliable multi-modal AI systems for real-world use.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05056v1",
    "published_date": "2024-11-07 16:21:18 UTC",
    "updated_date": "2024-11-07 16:21:18 UTC"
  },
  {
    "arxiv_id": "2411.08054v1",
    "title": "GREI Data Repository AI Taxonomy",
    "authors": [
      "John Chodacki",
      "Mark Hanhel",
      "Stefano Iacus",
      "Ryan Scherle",
      "Eric Olson",
      "Nici Pfeiffer",
      "Kristi Holmes",
      "Mohammad Hosseini"
    ],
    "abstract": "The Generalist Repository Ecosystem Initiative (GREI), funded by the NIH,\ndeveloped an AI taxonomy tailored to data repository roles to guide AI\nintegration across repository management. It categorizes the roles into stages,\nincluding acquisition, validation, organization, enhancement, analysis,\nsharing, and user support, providing a structured framework for implementing AI\nin repository workflows.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08054v1",
    "published_date": "2024-11-07 16:14:58 UTC",
    "updated_date": "2024-11-07 16:14:58 UTC"
  },
  {
    "arxiv_id": "2411.04832v2",
    "title": "Plasticity Loss in Deep Reinforcement Learning: A Survey",
    "authors": [
      "Timo Klein",
      "Lukas Miklautz",
      "Kevin Sidak",
      "Claudia Plant",
      "Sebastian Tschiatschek"
    ],
    "abstract": "Akin to neuroplasticity in human brains, the plasticity of deep neural\nnetworks enables their quick adaption to new data. This makes plasticity\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\nplasticity is lost, an agent's performance will inevitably plateau because it\ncannot improve its policy to account for changes in the data distribution,\nwhich are a necessary consequence of its learning process. Thus, developing\nwell-performing and sample-efficient agents hinges on their ability to remain\nplastic during training. Furthermore, the loss of plasticity can be connected\nto many other issues plaguing deep RL, such as training instabilities, scaling\nfailures, overestimation bias, and insufficient exploration. With this survey,\nwe aim to provide an overview of the emerging research on plasticity loss for\nacademics and practitioners of deep reinforcement learning. First, we propose a\nunified definition of plasticity loss based on recent works, relate it to\ndefinitions from the literature, and discuss metrics for measuring plasticity\nloss. Then, we categorize and discuss numerous possible causes of plasticity\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\nthe first systematic overview of the current state of the field. Lastly, we\ndiscuss prevalent issues within the literature, such as a necessity for broader\nevaluation, and provide recommendations for future research, like gaining a\nbetter understanding of an agent's neural activity and behavior.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04832v2",
    "published_date": "2024-11-07 16:13:54 UTC",
    "updated_date": "2024-11-08 10:19:15 UTC"
  },
  {
    "arxiv_id": "2411.04826v1",
    "title": "D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes",
    "authors": [
      "Siyu Chen",
      "Hong Liu",
      "Wenhao Li",
      "Ying Zhu",
      "Guoquan Wang",
      "Jianbing Wu"
    ],
    "abstract": "Depth estimation is a crucial technology in robotics. Recently,\nself-supervised depth estimation methods have demonstrated great potential as\nthey can efficiently leverage large amounts of unlabelled real-world data.\nHowever, most existing methods are designed under the assumption of static\nscenes, which hinders their adaptability in dynamic environments. To address\nthis issue, we present D$^3$epth, a novel method for self-supervised depth\nestimation in dynamic scenes. It tackles the challenge of dynamic objects from\ntwo key perspectives. First, within the self-supervised framework, we design a\nreprojection constraint to identify regions likely to contain dynamic objects,\nallowing the construction of a dynamic mask that mitigates their impact at the\nloss level. Second, for multi-frame depth estimation, we introduce a cost\nvolume auto-masking strategy that leverages adjacent frames to identify regions\nassociated with dynamic objects and generate corresponding masks. This provides\nguidance for subsequent processes. Furthermore, we propose a spectral entropy\nuncertainty module that incorporates spectral entropy to guide uncertainty\nestimation during depth fusion, effectively addressing issues arising from cost\nvolume computation in dynamic environments. Extensive experiments on KITTI and\nCityscapes datasets demonstrate that the proposed method consistently\noutperforms existing self-supervised monocular depth estimation baselines. Code\nis available at \\url{https://github.com/Csyunling/D3epth}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Open sourced",
    "pdf_url": "http://arxiv.org/pdf/2411.04826v1",
    "published_date": "2024-11-07 16:07:00 UTC",
    "updated_date": "2024-11-07 16:07:00 UTC"
  },
  {
    "arxiv_id": "2411.11892v1",
    "title": "Green My LLM: Studying the key factors affecting the energy consumption of code assistants",
    "authors": [
      "Tristan Coignion",
      "Clément Quinton",
      "Romain Rouvoy"
    ],
    "abstract": "In recent years,Large Language Models (LLMs) have significantly improved in\ngenerating high-quality code, enabling their integration into developers'\nIntegrated Development Environments (IDEs) as code assistants. These\nassistants, such as GitHub Copilot, deliver real-time code suggestions and can\ngreatly enhance developers' productivity. However, the environmental impact of\nthese tools, in particular their energy consumption, remains a key concern.\nThis paper investigates the energy consumption of LLM-based code assistants by\nsimulating developer interactions with GitHub Copilot and analyzing various\nconfiguration factors. We collected a dataset of development traces from 20\ndevelopers and conducted extensive software project development simulations to\nmeasure energy usage under different scenarios. Our findings reveal that the\nenergy consumption and performance of code assistants are influenced by various\nfactors, such as the number of concurrent developers, model size, quantization\nmethods, and the use of streaming. Notably, a substantial portion of generation\nrequests made by GitHub Copilot is either canceled or rejected by developers,\nindicating a potential area for reducing wasted computations. Based on these\nfindings, we share actionable insights into optimizing configurations for\ndifferent use cases, demonstrating that careful adjustments can lead to\nsignificant energy savings.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Submitted to JSS",
    "pdf_url": "http://arxiv.org/pdf/2411.11892v1",
    "published_date": "2024-11-07 16:00:29 UTC",
    "updated_date": "2024-11-07 16:00:29 UTC"
  },
  {
    "arxiv_id": "2411.04811v1",
    "title": "Defending Deep Regression Models against Backdoor Attacks",
    "authors": [
      "Lingyu Du",
      "Yupei Liu",
      "Jinyuan Jia",
      "Guohao Lan"
    ],
    "abstract": "Deep regression models are used in a wide variety of safety-critical\napplications, but are vulnerable to backdoor attacks. Although many defenses\nhave been proposed for classification models, they are ineffective as they do\nnot consider the uniqueness of regression models. First, the outputs of\nregression models are continuous values instead of discretized labels. Thus,\nthe potential infected target of a backdoored regression model has infinite\npossibilities, which makes it impossible to be determined by existing defenses.\nSecond, the backdoor behavior of backdoored deep regression models is triggered\nby the activation values of all the neurons in the feature space, which makes\nit difficult to be detected and mitigated using existing defenses. To resolve\nthese problems, we propose DRMGuard, the first defense to identify if a deep\nregression model in the image domain is backdoored or not. DRMGuard formulates\nthe optimization problem for reverse engineering based on the unique\noutput-space and feature-space characteristics of backdoored deep regression\nmodels. We conduct extensive evaluations on two regression tasks and four\ndatasets. The results show that DRMGuard can consistently defend against\nvarious backdoor attacks. We also generalize four state-of-the-art defenses\ndesigned for classifiers to regression models, and compare DRMGuard with them.\nThe results show that DRMGuard significantly outperforms all those defenses.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04811v1",
    "published_date": "2024-11-07 15:49:03 UTC",
    "updated_date": "2024-11-07 15:49:03 UTC"
  },
  {
    "arxiv_id": "2411.04799v2",
    "title": "Kwai-STaR: Transform LLMs into State-Transition Reasoners",
    "authors": [
      "Xingyu Lu",
      "Yuhang Hu",
      "Changyi Liu",
      "Tianke Zhang",
      "Zhenyu Yang",
      "Zhixiang Ding",
      "Shengsheng Qian",
      "Meng Du",
      "Ruiwen Kang",
      "Kaiyu Tang",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang",
      "Hai-Tao Zheng",
      "Bin Wen"
    ],
    "abstract": "Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04799v2",
    "published_date": "2024-11-07 15:38:25 UTC",
    "updated_date": "2024-11-12 12:57:58 UTC"
  },
  {
    "arxiv_id": "2411.04796v1",
    "title": "MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation",
    "authors": [
      "Sayan Paul",
      "Ruddra dev Roychoudhury",
      "Brojeshwar Bhowmick"
    ],
    "abstract": "Visual odometry (VO) is essential for enabling accurate point-goal navigation\nof embodied agents in indoor environments where GPS and compass sensors are\nunreliable and inaccurate. However, traditional VO methods face challenges in\nwide-baseline scenarios, where fast robot motions and low frames per second\n(FPS) during inference hinder their performance, leading to drift and\ncatastrophic failures in point-goal navigation. Recent deep-learned VO methods\nshow robust performance but suffer from sample inefficiency during training;\nhence, they require huge datasets and compute resources. So, we propose a\nrobust and sample-efficient VO pipeline based on motion priors available while\nan agent is navigating an environment. It consists of a training-free\naction-prior based geometric VO module that estimates a coarse relative pose\nwhich is further consumed as a motion prior by a deep-learned VO model, which\nfinally produces a fine relative pose to be used by the navigation policy. This\nstrategy helps our pipeline achieve up to 2x sample efficiency during training\nand demonstrates superior accuracy and robustness in point-goal navigation\ntasks compared to state-of-the-art VO method(s). Realistic indoor environments\nof the Gibson dataset is used in the AI-Habitat simulator to evaluate the\nproposed approach using navigation metrics (like success/SPL) and pose metrics\n(like RPE/ATE). We hope this method further opens a direction of work where\nmotion priors from various sources can be utilized to improve VO estimates and\nachieve better results in embodied navigation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in 50SFM Workshop of the 18th European Conference on\n  Computer Vision (ECCV) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04796v1",
    "published_date": "2024-11-07 15:36:49 UTC",
    "updated_date": "2024-11-07 15:36:49 UTC"
  },
  {
    "arxiv_id": "2411.04794v2",
    "title": "KnowCoder-X: Boosting Multilingual Information Extraction via Code",
    "authors": [
      "Yuxin Zuo",
      "Wenxuan Jiang",
      "Wenxuan Liu",
      "Zixuan Li",
      "Long Bai",
      "Hanbin Wang",
      "Yutao Zeng",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "Empirical evidence indicates that LLMs exhibit spontaneous cross-lingual\nalignment. However, although LLMs show promising cross-lingual alignment in IE,\na significant imbalance across languages persists, highlighting an underlying\ndeficiency. To address this, we propose KnowCoder-X, a powerful code LLM with\nadvanced cross-lingual and multilingual capabilities for universal information\nextraction. Firstly, it standardizes the representation of multilingual schemas\nusing Python classes, ensuring a consistent ontology across different\nlanguages. Then, IE across languages is formulated as a unified code generation\ntask. Secondly, we enhance the model's cross-lingual transferability through IE\ncross-lingual alignment instruction tuning on a translated instance prediction\ntask we proposed. During this phase, we also construct a high-quality and\ndiverse bilingual IE parallel dataset with 257k samples, called ParallelNER,\nsynthesized by our proposed robust three-stage pipeline, with manual annotation\nto ensure quality. Although without training in 29 unseen languages,\nKnowCoder-X surpasses ChatGPT by $30.17\\%$ and SoTA by $20.03\\%$, thereby\ndemonstrating superior cross-lingual IE capabilities. Comprehensive evaluations\non 64 IE benchmarks in Chinese and English under various settings demonstrate\nthat KnowCoder-X significantly enhances cross-lingual IE transfer through\nboosting the IE alignment. Our code and dataset are available at:\nhttps://github.com/ICT-GoKnow/KnowCoder",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04794v2",
    "published_date": "2024-11-07 15:36:05 UTC",
    "updated_date": "2025-04-08 16:16:30 UTC"
  },
  {
    "arxiv_id": "2411.13562v1",
    "title": "The Role of AI in Financial Forecasting: ChatGPT's Potential and Challenges",
    "authors": [
      "Shuochen Bi",
      "Tingting Deng",
      "Jue Xiao"
    ],
    "abstract": "The outlook for the future of artificial intelligence (AI) in the financial\nsector, especially in financial forecasting, the challenges and implications.\nThe dynamics of AI technology, including deep learning, reinforcement learning,\nand integration with blockchAIn and the Internet of Things, also highlight the\ncontinued improvement in data processing capabilities. Explore how AI is\nreshaping financial services with precisely tAIlored services that can more\nprecisely meet the diverse needs of individual investors. The integration of AI\nchallenges regulatory and ethical issues in the financial sector, as well as\nthe implications for data privacy protection. Analyze the limitations of\ncurrent AI technology in financial forecasting and its potential impact on the\nfuture financial industry landscape, including changes in the job market, the\nemergence of new financial institutions, and user interface innovations.\nEmphasizing the importance of increasing investor understanding and awareness\nof AI and looking ahead to future trends in AI tools for user experience to\ndrive wider adoption of AI in financial decision making. The huge potential,\nchallenges, and future directions of AI in the financial sector highlight the\ncritical role of AI technology in driving transformation and innovation in the\nfinancial sector",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "q-fin.ST",
    "comment": "7 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.13562v1",
    "published_date": "2024-11-07 15:35:16 UTC",
    "updated_date": "2024-11-07 15:35:16 UTC"
  },
  {
    "arxiv_id": "2411.04788v1",
    "title": "Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research",
    "authors": [
      "Xuewen Han",
      "Neng Wang",
      "Shangkun Che",
      "Hongyang Yang",
      "Kunpeng Zhang",
      "Sean Xin Xu"
    ],
    "abstract": "In recent years, the application of generative artificial intelligence\n(GenAI) in financial analysis and investment decision-making has gained\nsignificant attention. However, most existing approaches rely on single-agent\nsystems, which fail to fully utilize the collaborative potential of multiple AI\nagents. In this paper, we propose a novel multi-agent collaboration system\ndesigned to enhance decision-making in financial investment research. The\nsystem incorporates agent groups with both configurable group sizes and\ncollaboration structures to leverage the strengths of each agent group type. By\nutilizing a sub-optimal combination strategy, the system dynamically adapts to\nvarying market conditions and investment scenarios, optimizing performance\nacross different tasks. We focus on three sub-tasks: fundamentals, market\nsentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30\ncompanies listed on the Dow Jones Index. Our findings reveal significant\nperformance variations based on the configurations of AI agents for different\ntasks. The results demonstrate that our multi-agent collaboration system\noutperforms traditional single-agent models, offering improved accuracy,\nefficiency, and adaptability in complex financial environments. This study\nhighlights the potential of multi-agent systems in transforming financial\nanalysis and investment decision-making by integrating diverse analytical\nperspectives.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "q-fin.ST",
      "q-fin.TR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04788v1",
    "published_date": "2024-11-07 15:28:20 UTC",
    "updated_date": "2024-11-07 15:28:20 UTC"
  },
  {
    "arxiv_id": "2411.04784v1",
    "title": "Navigating Trade-offs: Policy Summarization for Multi-Objective Reinforcement Learning",
    "authors": [
      "Zuzanna Osika",
      "Jazmin Zatarain-Salazar",
      "Frans A. Oliehoek",
      "Pradeep K. Murukannaiah"
    ],
    "abstract": "Multi-objective reinforcement learning (MORL) is used to solve problems\ninvolving multiple objectives. An MORL agent must make decisions based on the\ndiverse signals provided by distinct reward functions. Training an MORL agent\nyields a set of solutions (policies), each presenting distinct trade-offs among\nthe objectives (expected returns). MORL enhances explainability by enabling\nfine-grained comparisons of policies in the solution set based on their\ntrade-offs as opposed to having a single policy. However, the solution set is\ntypically large and multi-dimensional, where each policy (e.g., a neural\nnetwork) is represented by its objective values.\n  We propose an approach for clustering the solution set generated by MORL. By\nconsidering both policy behavior and objective values, our clustering method\ncan reveal the relationship between policy behaviors and regions in the\nobjective space. This approach can enable decision makers (DMs) to identify\noverarching trends and insights in the solution set rather than examining each\npolicy individually. We tested our method in four multi-objective environments\nand found it outperformed traditional k-medoids clustering. Additionally, we\ninclude a case study that demonstrates its real-world application.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04784v1",
    "published_date": "2024-11-07 15:26:38 UTC",
    "updated_date": "2024-11-07 15:26:38 UTC"
  },
  {
    "arxiv_id": "2411.04772v1",
    "title": "Attention Masks Help Adversarial Attacks to Bypass Safety Detectors",
    "authors": [
      "Yunfan Shi"
    ],
    "abstract": "Despite recent research advancements in adversarial attack methods, current\napproaches against XAI monitors are still discoverable and slower. In this\npaper, we present an adaptive framework for attention mask generation to enable\nstealthy, explainable and efficient PGD image classification adversarial attack\nunder XAI monitors. Specifically, we utilize mutation XAI mixture and multitask\nself-supervised X-UNet for attention mask generation to guide PGD attack.\nExperiments on MNIST (MLP), CIFAR-10 (AlexNet) have shown that our system can\noutperform benchmark PGD, Sparsefool and SOTA SINIFGSM in balancing among\nstealth, efficiency and explainability which is crucial for effectively fooling\nSOTA defense protected classifiers.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04772v1",
    "published_date": "2024-11-07 15:13:50 UTC",
    "updated_date": "2024-11-07 15:13:50 UTC"
  },
  {
    "arxiv_id": "2411.05867v2",
    "title": "Modeling Nonlinear Oscillator Networks Using Physics-Informed Hybrid Reservoir Computing",
    "authors": [
      "Andrew Shannon",
      "Conor Houghton",
      "David Barton",
      "Martin Homer"
    ],
    "abstract": "Surrogate modeling of non-linear oscillator networks remains challenging due\nto discrepancies between simplified analytical models and real-world\ncomplexity. To bridge this gap, we investigate hybrid reservoir computing,\ncombining reservoir computing with \"expert\" analytical models. Simulating the\nabsence of an exact model, we first test the surrogate models with parameter\nerrors in their expert model. Second, in a residual physics task, we assess\ntheir performance when their expert model lacks key non-linear coupling terms\npresent in an extended ground-truth model. We focus on short-term forecasting\nacross diverse dynamical regimes, evaluating the use of these surrogates for\ncontrol applications. We show that hybrid reservoir computers generally\noutperform standard reservoir computers and exhibit greater robustness to\nparameter tuning. This advantage is less pronounced in the residual physics\ntask. Notably, unlike standard reservoir computers, the performance of the\nhybrid does not degrade when crossing an observed spectral radius threshold.\nFurthermore, there is good performance for dynamical regimes not accessible to\nthe expert model, demonstrating the contribution of the reservoir.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "I.6.3; I.6.5; I.2.6; J.2"
    ],
    "primary_category": "eess.SY",
    "comment": "32 pages, 10 figures, 21 supplementary figures. Updated in response\n  to review. Code at https://github.com/AJS50/Hybrid_RC_for_NLONS_paper_code",
    "pdf_url": "http://arxiv.org/pdf/2411.05867v2",
    "published_date": "2024-11-07 15:09:23 UTC",
    "updated_date": "2025-05-19 10:33:44 UTC"
  },
  {
    "arxiv_id": "2411.04747v1",
    "title": "Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations",
    "authors": [
      "Zachary Schwehr"
    ],
    "abstract": "Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "8 pages, 1 figure, Presented at IEEE CIBCB",
    "pdf_url": "http://arxiv.org/pdf/2411.04747v1",
    "published_date": "2024-11-07 14:29:05 UTC",
    "updated_date": "2024-11-07 14:29:05 UTC"
  },
  {
    "arxiv_id": "2411.11891v1",
    "title": "Survey on Semantic Interpretation of Tabular Data: Challenges and Directions",
    "authors": [
      "Marco Cremaschi",
      "Blerina Spahiu",
      "Matteo Palmonari",
      "Ernesto Jimenez-Ruiz"
    ],
    "abstract": "Tabular data plays a pivotal role in various fields, making it a popular\nformat for data manipulation and exchange, particularly on the web. The\ninterpretation, extraction, and processing of tabular information are\ninvaluable for knowledge-intensive applications. Notably, significant efforts\nhave been invested in annotating tabular data with ontologies and entities from\nbackground knowledge graphs, a process known as Semantic Table Interpretation\n(STI). STI automation aids in building knowledge graphs, enriching data, and\nenhancing web-based question answering. This survey aims to provide a\ncomprehensive overview of the STI landscape. It starts by categorizing\napproaches using a taxonomy of 31 attributes, allowing for comparisons and\nevaluations. It also examines available tools, assessing them based on 12\ncriteria. Furthermore, the survey offers an in-depth analysis of the Gold\nStandards used for evaluating STI approaches. Finally, it provides practical\nguidance to help end-users choose the most suitable approach for their specific\ntasks while also discussing unresolved issues and suggesting potential future\nresearch directions.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.11891v1",
    "published_date": "2024-11-07 14:28:56 UTC",
    "updated_date": "2024-11-07 14:28:56 UTC"
  },
  {
    "arxiv_id": "2411.04710v1",
    "title": "Differential Privacy Overview and Fundamental Techniques",
    "authors": [
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck",
      "Juba Ziani"
    ],
    "abstract": "This chapter is meant to be part of the book \"Differential Privacy in\nArtificial Intelligence: From Theory to Practice\" and provides an introduction\nto Differential Privacy. It starts by illustrating various attempts to protect\ndata privacy, emphasizing where and why they failed, and providing the key\ndesiderata of a robust privacy definition. It then defines the key actors,\ntasks, and scopes that make up the domain of privacy-preserving data analysis.\nFollowing that, it formalizes the definition of Differential Privacy and its\ninherent properties, including composition, post-processing immunity, and group\nprivacy. The chapter also reviews the basic techniques and mechanisms commonly\nused to implement Differential Privacy in its pure and approximate forms.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Chapter 1 of book: \"Differential Privacy in Artificial Intelligence:\n  From Theory to Practice\"",
    "pdf_url": "http://arxiv.org/pdf/2411.04710v1",
    "published_date": "2024-11-07 13:52:11 UTC",
    "updated_date": "2024-11-07 13:52:11 UTC"
  },
  {
    "arxiv_id": "2411.05055v1",
    "title": "Integrating Large Language Models for Genetic Variant Classification",
    "authors": [
      "Youssef Boulaimen",
      "Gabriele Fossi",
      "Leila Outemzabet",
      "Nathalie Jeanray",
      "Oleksandr Levenets",
      "Stephane Gerart",
      "Sebastien Vachenc",
      "Salvatore Raieli",
      "Joanna Giemza"
    ],
    "abstract": "The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG",
      "68T07 (Primary) 92D20, 92C40 (Secondary)",
      "I.2.7; J.3"
    ],
    "primary_category": "q-bio.GN",
    "comment": "21 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05055v1",
    "published_date": "2024-11-07 13:45:56 UTC",
    "updated_date": "2024-11-07 13:45:56 UTC"
  },
  {
    "arxiv_id": "2411.04700v1",
    "title": "Field Assessment of Force Torque Sensors for Planetary Rover Navigation",
    "authors": [
      "Levin Gerdes",
      "Carlos Pérez del Pulgar",
      "Raúl Castilla Arquillo",
      "Martin Azkarate"
    ],
    "abstract": "Proprioceptive sensors on planetary rovers serve for state estimation and for\nunderstanding terrain and locomotion performance. While inertial measurement\nunits (IMUs) are widely used to this effect, force-torque sensors are less\nexplored for planetary navigation despite their potential to directly measure\ninteraction forces and provide insights into traction performance. This paper\npresents an evaluation of the performance and use cases of force-torque sensors\nbased on data collected from a six-wheeled rover during tests over varying\nterrains, speeds, and slopes. We discuss challenges, such as sensor signal\nreliability and terrain response accuracy, and identify opportunities regarding\nthe use of these sensors. The data is openly accessible and includes\nforce-torque measurements from each of the six-wheel assemblies as well as IMU\ndata from within the rover chassis. This paper aims to inform the design of\nfuture studies and rover upgrades, particularly in sensor integration and\ncontrol algorithms, to improve navigation capabilities.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04700v1",
    "published_date": "2024-11-07 13:34:37 UTC",
    "updated_date": "2024-11-07 13:34:37 UTC"
  },
  {
    "arxiv_id": "2411.04696v3",
    "title": "The Multiple Dimensions of Spuriousness in Machine Learning",
    "authors": [
      "Samuel J. Bell",
      "Skyler Wang"
    ],
    "abstract": "Learning correlations from data forms the foundation of today's machine\nlearning (ML) and artificial intelligence (AI) research. While such an approach\nenables the automatic discovery of patterned relationships within big data\ncorpora, it is susceptible to failure modes when unintended correlations are\ncaptured. This vulnerability has expanded interest in interrogating\nspuriousness, often critiqued as an impediment to model performance, fairness,\nand robustness. In this article, we trace deviations from the conventional\ndefinition of statistical spuriousness-which denotes a non-causal observation\narising from either coincidence or confounding variables-to articulate how ML\nresearchers make sense of spuriousness in practice. Drawing on a broad survey\nof ML literature, we conceptualize the \"multiple dimensions of spuriousness,\"\nencompassing: relevance (\"Models should only use correlations that are relevant\nto the task.\"), generalizability (\"Models should only use correlations that\ngeneralize to unseen data\"), human-likeness (\"Models should only use\ncorrelations that a human would use to perform the same task\"), and harmfulness\n(\"Models should only use correlations that are not harmful\"). These dimensions\ndemonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy\nand that the disparate interpretative paths researchers choose could\nmeaningfully influence the trajectory of ML development. By underscoring how a\nfundamental problem in ML is contingently negotiated in research contexts, we\ncontribute to ongoing debates about responsible practices in AI development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04696v3",
    "published_date": "2024-11-07 13:29:32 UTC",
    "updated_date": "2024-11-28 12:00:41 UTC"
  },
  {
    "arxiv_id": "2411.15151v1",
    "title": "Memory-Driven Metaheuristics: Improving Optimization Performance",
    "authors": [
      "Salar Farahmand-Tabar"
    ],
    "abstract": "Metaheuristics are stochastic optimization algorithms that mimic natural\nprocesses to find optimal solutions to complex problems. The success of\nmetaheuristics largely depends on the ability to effectively explore and\nexploit the search space. Memory mechanisms have been introduced in several\npopular metaheuristic algorithms to enhance their performance. This chapter\nexplores the significance of memory in metaheuristic algorithms and provides\ninsights from well-known algorithms. The chapter begins by introducing the\nconcept of memory, and its role in metaheuristic algorithms. The key factors\ninfluencing the effectiveness of memory mechanisms are discussed, such as the\nsize of the memory, the information stored in memory, and the rate of\ninformation decay. A comprehensive analysis of how memory mechanisms are\nincorporated into popular metaheuristic algorithms is presented and concludes\nby highlighting the importance of memory in metaheuristic performance and\nproviding future research directions for improving memory mechanisms. The key\ntakeaways are that memory mechanisms can significantly enhance the performance\nof metaheuristics by enabling them to explore and exploit the search space\neffectively and efficiently, and that the choice of memory mechanism should be\ntailored to the problem domain and the characteristics of the search space.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "25 pages, 5 figures, book chapter, Springer",
    "pdf_url": "http://arxiv.org/pdf/2411.15151v1",
    "published_date": "2024-11-07 13:27:03 UTC",
    "updated_date": "2024-11-07 13:27:03 UTC"
  },
  {
    "arxiv_id": "2411.04693v2",
    "title": "Electromagnetic Scattering Kernel Guided Reciprocal Point Learning for SAR Open-Set Recognition",
    "authors": [
      "Xiayang Xiao",
      "Zhuoxuan Li",
      "Ruyi Zhang",
      "Jiacheng Chen",
      "Haipeng Wang"
    ],
    "abstract": "The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target\nRecognition (ATR) methods lie in their confinement by the closed-environment\nassumption, hindering their effective and robust handling of unknown target\ncategories in open environments. Open Set Recognition (OSR), a pivotal facet\nfor algorithmic practicality, intends to categorize known classes while\ndenoting unknown ones as \"unknown.\" The chief challenge in OSR involves\nconcurrently mitigating risks associated with generalizing features from a\nrestricted set of known classes to numerous unknown samples and the open space\nexposure to potential unknown data. To enhance open-set SAR classification, a\nmethod called scattering kernel with reciprocal learning network is proposed.\nInitially, a feature learning framework is constructed based on reciprocal\npoint learning (RPL), establishing a bounded space for potential unknown\nclasses. This approach indirectly introduces unknown information into a learner\nconfined to known classes, thereby acquiring more concise and discriminative\nrepresentations. Subsequently, considering the variability in the imaging of\ntargets at different angles and the discreteness of components in SAR images, a\nproposal is made to design convolutional kernels based on large-sized attribute\nscattering center models. This enhances the ability to extract intrinsic\nnon-linear features and specific scattering characteristics in SAR images,\nthereby improving the discriminative features of the model and mitigating the\nimpact of imaging variations on classification performance. Experiments on the\nMSTAR datasets substantiate the superior performance of the proposed approach\ncalled ASC-RPL over mainstream methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04693v2",
    "published_date": "2024-11-07 13:26:20 UTC",
    "updated_date": "2024-12-06 01:31:56 UTC"
  },
  {
    "arxiv_id": "2411.04692v1",
    "title": "Personalized Federated Learning for Cross-view Geo-localization",
    "authors": [
      "Christos Anagnostopoulos",
      "Alexandros Gkillas",
      "Nikos Piperigkos",
      "Aris S. Lalos"
    ],
    "abstract": "In this paper we propose a methodology combining Federated Learning (FL) with\nCross-view Image Geo-localization (CVGL) techniques. We address the challenges\nof data privacy and heterogeneity in autonomous vehicle environments by\nproposing a personalized Federated Learning scenario that allows selective\nsharing of model parameters. Our method implements a coarse-to-fine approach,\nwhere clients share only the coarse feature extractors while keeping\nfine-grained features specific to local environments. We evaluate our approach\nagainst traditional centralized and single-client training schemes using the\nKITTI dataset combined with satellite imagery. Results demonstrate that our\nfederated CVGL method achieves performance close to centralized training while\nmaintaining data privacy. The proposed partial model sharing strategy shows\ncomparable or slightly better performance than classical FL, offering\nsignificant reduced communication overhead without sacrificing accuracy. Our\nwork contributes to more robust and privacy-preserving localization systems for\nautonomous vehicles operating in diverse environments",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 2 figures, Preprint submitted to the IEEE 26th International\n  Workshop on Multimedia Signal Processing (MMSP)",
    "pdf_url": "http://arxiv.org/pdf/2411.04692v1",
    "published_date": "2024-11-07 13:25:52 UTC",
    "updated_date": "2024-11-07 13:25:52 UTC"
  },
  {
    "arxiv_id": "2411.04691v1",
    "title": "AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data",
    "authors": [
      "Tianyi Zhang",
      "Miu Kojima",
      "Simon D'Alfonso"
    ],
    "abstract": "Smartphones, equipped with an array of sensors, have become valuable tools\nfor personal sensing. Particularly in digital health, smartphones facilitate\nthe tracking of health-related behaviors and contexts, contributing\nsignificantly to digital phenotyping, a process where data from digital\ninteractions is analyzed to infer behaviors and assess mental health.\nTraditional methods process raw sensor data into information features for\nstatistical and machine learning analyses. In this paper, we introduce a novel\napproach that systematically converts smartphone-collected data into\nstructured, chronological narratives. The AWARE Narrator translates\nquantitative smartphone sensing data into English language descriptions,\nforming comprehensive narratives of an individual's activities. We apply the\nframework to the data collected from university students over a week,\ndemonstrating the potential of utilizing the narratives to summarize individual\nbehavior, and analyzing psychological states by leveraging large language\nmodels.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04691v1",
    "published_date": "2024-11-07 13:23:57 UTC",
    "updated_date": "2024-11-07 13:23:57 UTC"
  },
  {
    "arxiv_id": "2411.04685v5",
    "title": "Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model",
    "authors": [
      "Md. Kutub Uddin",
      "Md. Saiful Islam",
      "Md Abrar Jahin",
      "Md. Saiful Islam Seam",
      "M. F. Mridha"
    ],
    "abstract": "This paper focuses on the generalized grouping problem in the context of\ncellular manufacturing systems (CMS), where parts may have more than one\nprocess route. A process route lists the machines corresponding to each part of\nthe operation. Inspired by the extensive and widespread use of network flow\nalgorithms, this research formulates the process route family formation for\ngeneralized grouping as a unit capacity minimum cost network flow model. The\nobjective is to minimize dissimilarity (based on the machines required) among\nthe process routes within a family. The proposed model optimally solves the\nprocess route family formation problem without pre-specifying the number of\npart families to be formed. The process route of family formation is the first\nstage in a hierarchical procedure. For the second stage (machine cell\nformation), two procedures, a quadratic assignment programming (QAP)\nformulation, and a heuristic procedure, are proposed. The QAP simultaneously\nassigns process route families and machines to a pre-specified number of cells\nin such a way that total machine utilization is maximized. The heuristic\nprocedure for machine cell formation is hierarchical in nature. Computational\nresults for some test problems show that the QAP and the heuristic procedure\nyield the same results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04685v5",
    "published_date": "2024-11-07 13:14:52 UTC",
    "updated_date": "2024-12-04 20:56:11 UTC"
  },
  {
    "arxiv_id": "2411.05054v1",
    "title": "FMEA Builder: Expert Guided Text Generation for Equipment Maintenance",
    "authors": [
      "Karol Lynch",
      "Fabio Lorenzi",
      "John Sheehan",
      "Duygu Kabakci-Zorlu",
      "Bradley Eck"
    ],
    "abstract": "Foundation models show great promise for generative tasks in many domains.\nHere we discuss the use of foundation models to generate structured documents\nrelated to critical assets. A Failure Mode and Effects Analysis (FMEA) captures\nthe composition of an asset or piece of equipment, the ways it may fail and the\nconsequences thereof. Our system uses large language models to enable fast and\nexpert supervised generation of new FMEA documents. Empirical analysis shows\nthat foundation models can correctly generate over half of an FMEA's key\ncontent. Results from polling audiences of reliability professionals show a\npositive outlook on using generative AI to create these documents for critical\nassets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, 2 figures. AI for Critical Infrastructure Workshop @ IJCAI\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2411.05054v1",
    "published_date": "2024-11-07 13:11:03 UTC",
    "updated_date": "2024-11-07 13:11:03 UTC"
  },
  {
    "arxiv_id": "2411.04679v2",
    "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation",
    "authors": [
      "Jie Liu",
      "Pan Zhou",
      "Yingjun Du",
      "Ah-Hwee Tan",
      "Cees G. M. Snoek",
      "Jan-Jakob Sonke",
      "Efstratios Gavves"
    ],
    "abstract": "In this work, we address the cooperation problem among large language model\n(LLM) based embodied agents, where agents must cooperate to achieve a common\ngoal. Previous methods often execute actions extemporaneously and incoherently,\nwithout long-term strategic and cooperative planning, leading to redundant\nsteps, failures, and even serious repercussions in complex tasks like\nsearch-and-rescue missions where discussion and cooperative plan are crucial.\nTo solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance\nthe cooperation efficiency of LLM-based embodied agents. Inspired by human\ncooperation schemes, CaPo improves cooperation efficiency with two phases: 1)\nmeta-plan generation, and 2) progress-adaptive meta-plan and execution. In the\nfirst phase, all agents analyze the task, discuss, and cooperatively create a\nmeta-plan that decomposes the task into subtasks with detailed steps, ensuring\na long-term strategic and coherent plan for efficient coordination. In the\nsecond phase, agents execute tasks according to the meta-plan and dynamically\nadjust it based on their latest progress (e.g., discovering a target object)\nthrough multi-turn discussions. This progress-based adaptation eliminates\nredundant actions, improving the overall cooperation efficiency of agents.\nExperimental results on the ThreeDworld Multi-Agent Transport and Communicative\nWatch-And-Help tasks demonstrate that CaPo achieves much higher task completion\nrate and efficiency compared with state-of-the-arts.The code is released at\nhttps://github.com/jliu4ai/CaPo.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2411.04679v2",
    "published_date": "2024-11-07 13:08:04 UTC",
    "updated_date": "2025-03-01 09:00:30 UTC"
  },
  {
    "arxiv_id": "2411.05865v1",
    "title": "Bilinear Fuzzy Genetic Algorithm and Its Application on the Optimum Design of Steel Structures with Semi-rigid Connections",
    "authors": [
      "Salar Farahmand-Tabar",
      "Payam Ashtari"
    ],
    "abstract": "An improved bilinear fuzzy genetic algorithm (BFGA) is introduced in this\nchapter for the design optimization of steel structures with semi-rigid\nconnections. Semi-rigid connections provide a compromise between the stiffness\nof fully rigid connections and the flexibility of fully pinned connections.\nHowever, designing such structures is challenging due to the nonlinear behavior\nof semi-rigid connections. The BFGA is a robust optimization method that\ncombines the strengths of fuzzy logic and genetic algorithm to handle the\ncomplexity and uncertainties of structural design problems. The BFGA, compared\nto standard GA, demonstrated to generate high-quality solutions in a reasonable\ntime. The application of the BFGA is demonstrated through the optimization of\nsteel structures with semirigid connections, considering the weight and\nperformance criteria. The results show that the proposed BFGA is capable of\nfinding optimal designs that satisfy all the design requirements and\nconstraints. The proposed approach provides a promising solution for the\noptimization of complex structures with nonlinear behavior.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "19 pages, 12 figures, book chapter, Springer",
    "pdf_url": "http://arxiv.org/pdf/2411.05865v1",
    "published_date": "2024-11-07 13:07:16 UTC",
    "updated_date": "2024-11-07 13:07:16 UTC"
  },
  {
    "arxiv_id": "2411.05864v1",
    "title": "Boosting the Efficiency of Metaheuristics Through Opposition-Based Learning in Optimum Locating of Control Systems in Tall Buildings",
    "authors": [
      "Salar Farahmand-Tabar",
      "Sina Shirgir"
    ],
    "abstract": "Opposition-based learning (OBL) is an effective approach to improve the\nperformance of metaheuristic optimization algorithms, which are commonly used\nfor solving complex engineering problems. This chapter provides a comprehensive\nreview of the literature on the use of opposition strategies in metaheuristic\noptimization algorithms, discussing the benefits and limitations of this\napproach. An overview of the opposition strategy concept, its various\nimplementations, and its impact on the performance of metaheuristic algorithms\nare presented. Furthermore, case studies on the application of opposition\nstrategies in engineering problems are provided, including the optimum locating\nof control systems in tall building. A shear frame with Magnetorheological (MR)\nfluid damper is considered as a case study. The results demonstrate that the\nincorporation of opposition strategies in metaheuristic algorithms\nsignificantly enhances the quality and speed of the optimization process. This\nchapter aims to provide a clear understanding of the opposition strategy in\nmetaheuristic optimization algorithms and its engineering applications, with\nthe ultimate goal of facilitating its adoption in real-world engineering\nproblems.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NE",
    "comment": "17 pages, 4 figures, book chapter, Springer",
    "pdf_url": "http://arxiv.org/pdf/2411.05864v1",
    "published_date": "2024-11-07 13:05:40 UTC",
    "updated_date": "2024-11-07 13:05:40 UTC"
  },
  {
    "arxiv_id": "2411.04671v3",
    "title": "CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR",
    "authors": [
      "Kadir Burak Buldu",
      "Süleyman Özdel",
      "Ka Hei Carrie Lau",
      "Mengdi Wang",
      "Daniel Saad",
      "Sofie Schönborn",
      "Auxane Boch",
      "Enkelejda Kasneci",
      "Efe Bozkir"
    ],
    "abstract": "Recent developments in computer graphics, machine learning, and sensor\ntechnologies enable numerous opportunities for extended reality (XR) setups for\neveryday life, from skills training to entertainment. With large corporations\noffering affordable consumer-grade head-mounted displays (HMDs), XR will likely\nbecome pervasive, and HMDs will develop as personal devices like smartphones\nand tablets. However, having intelligent spaces and naturalistic interactions\nin XR is as important as technological advances so that users grow their\nengagement in virtual and augmented spaces. To this end, large language model\n(LLM)--powered non-player characters (NPCs) with speech-to-text (STT) and\ntext-to-speech (TTS) models bring significant advantages over conventional or\npre-scripted NPCs for facilitating more natural conversational user interfaces\n(CUIs) in XR. This paper provides the community with an open-source,\ncustomizable, extendable, and privacy-aware Unity package, CUIfy, that\nfacilitates speech-based NPC-user interaction with widely used LLMs, STT, and\nTTS models. Our package also supports multiple LLM-powered NPCs per environment\nand minimizes latency between different computational models through streaming\nto achieve usable interactions between users and NPCs. We publish our source\ncode in the following repository: https://gitlab.lrz.de/hctl/cuify",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7th IEEE International Conference on Artificial Intelligence &\n  eXtended and Virtual Reality (IEEE AIxVR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.04671v3",
    "published_date": "2024-11-07 12:55:17 UTC",
    "updated_date": "2025-03-03 13:41:33 UTC"
  },
  {
    "arxiv_id": "2411.04669v1",
    "title": "EffiCANet: Efficient Time Series Forecasting with Convolutional Attention",
    "authors": [
      "Xinxing Zhou",
      "Jiaqi Ye",
      "Shubao Zhao",
      "Ming Jin",
      "Chengyi Yang",
      "Yanlong Wen",
      "Xiaojie Yuan"
    ],
    "abstract": "The exponential growth of multivariate time series data from sensor networks\nin domains like industrial monitoring and smart cities requires efficient and\naccurate forecasting models. Current deep learning methods often fail to\nadequately capture long-range dependencies and complex inter-variable\nrelationships, especially under real-time processing constraints. These\nlimitations arise as many models are optimized for either short-term\nforecasting with limited receptive fields or long-term accuracy at the cost of\nefficiency. Additionally, dynamic and intricate interactions between variables\nin real-world data further complicate modeling efforts. To address these\nlimitations, we propose EffiCANet, an Efficient Convolutional Attention Network\ndesigned to enhance forecasting accuracy while maintaining computational\nefficiency. EffiCANet integrates three key components: (1) a Temporal\nLarge-kernel Decomposed Convolution (TLDC) module that captures long-term\ntemporal dependencies while reducing computational overhead; (2) an\nInter-Variable Group Convolution (IVGC) module that captures complex and\nevolving relationships among variables; and (3) a Global Temporal-Variable\nAttention (GTVA) mechanism that prioritizes critical temporal and\ninter-variable features. Extensive evaluations across nine benchmark datasets\nshow that EffiCANet achieves the maximum reduction of 10.02% in MAE over\nstate-of-the-art models, while cutting computational costs by 26.2% relative to\nconventional large-kernel convolution methods, thanks to its efficient\ndecomposition strategy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04669v1",
    "published_date": "2024-11-07 12:54:42 UTC",
    "updated_date": "2024-11-07 12:54:42 UTC"
  },
  {
    "arxiv_id": "2411.04649v1",
    "title": "DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models",
    "authors": [
      "Zijian Zhang",
      "Vinay Setty",
      "Yumeng Wang",
      "Avishek Anand"
    ],
    "abstract": "With the rapid advancement of neural language models, the deployment of\nover-parameterized models has surged, increasing the need for interpretable\nexplanations comprehensible to human inspectors. Existing post-hoc\ninterpretability methods, which often focus on unigram features of single input\ntextual instances, fail to capture the models' decision-making process fully.\nAdditionally, many methods do not differentiate between decisions based on\nspurious correlations and those based on a holistic understanding of the input.\nOur paper introduces DISCO, a novel method for discovering global, rule-based\nexplanations by identifying causal n-gram associations with model predictions.\nThis method employs a scalable sequence mining technique to extract relevant\ntext spans from training data, associate them with model predictions, and\nconduct causality checks to distill robust rules that elucidate model behavior.\nThese rules expose potential overfitting and provide insights into misleading\nfeature combinations. We validate DISCO through extensive testing,\ndemonstrating its superiority over existing methods in offering comprehensive\ninsights into complex model behaviors. Our approach successfully identifies all\nshortcuts manually introduced into the training data (100% detection rate on\nthe MultiRC dataset), resulting in an 18.8% regression in model performance --\na capability unmatched by any other method. Furthermore, DISCO supports\ninteractive explanations, enabling human inspectors to distinguish spurious\ncauses in the rule-based output. This alleviates the burden of abundant\ninstance-wise explanations and helps assess the model's risk when encountering\nout-of-distribution (OOD) data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.3; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04649v1",
    "published_date": "2024-11-07 12:12:44 UTC",
    "updated_date": "2024-11-07 12:12:44 UTC"
  },
  {
    "arxiv_id": "2411.04644v1",
    "title": "wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals",
    "authors": [
      "Jonathan F. Carter",
      "Lionel Tarassenko"
    ],
    "abstract": "Accurate classification of sleep stages from less obtrusive sensor\nmeasurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)\ncould enable important applications in sleep medicine. Existing approaches to\nthis problem have typically used deep learning models designed and trained to\noperate on one or more specific input signals. However, the datasets used to\ndevelop these models often do not contain the same sets of input signals. Some\nsignals, particularly PPG, are much less prevalent than others, and this has\npreviously been addressed with techniques such as transfer learning.\nAdditionally, only training on one or more fixed modalities precludes\ncross-modal information transfer from other sources, which has proved valuable\nin other problem domains. To address this, we introduce wav2sleep, a unified\nmodel designed to operate on variable sets of input signals during training and\ninference. After jointly training on over 10,000 overnight recordings from six\npublicly available polysomnography datasets, including SHHS and MESA, wav2sleep\noutperforms existing sleep stage classification models across test-time input\ncombinations including ECG, PPG, and respiratory signals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to Machine Learning for Health (ML4H) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04644v1",
    "published_date": "2024-11-07 12:01:36 UTC",
    "updated_date": "2024-11-07 12:01:36 UTC"
  },
  {
    "arxiv_id": "2411.15149v1",
    "title": "The Fundamental Rights Impact Assessment (FRIA) in the AI Act: Roots, legal obligations and key elements for a model template",
    "authors": [
      "Alessandro Mantelero"
    ],
    "abstract": "What is the context which gave rise to the obligation to carry out a\nFundamental Rights Impact Assessment (FRIA) in the AI Act? How has assessment\nof the impact on fundamental rights been framed by the EU legislator in the AI\nAct? What methodological criteria should be followed in developing the FRIA?\nThese are the three main research questions that this article aims to address,\nthrough both legal analysis of the relevant provisions of the AI Act and\ndiscussion of various possible models for assessment of the impact of AI on\nfundamental rights. The overall objective of this article is to fill existing\ngaps in the theoretical and methodological elaboration of the FRIA, as outlined\nin the AI Act. In order to facilitate the future work of EU and national bodies\nand AI operators in placing this key tool for human-centric and trustworthy AI\nat the heart of the EU approach to AI design and development, this article\noutlines the main building blocks of a model template for the FRIA. While this\nproposal is consistent with the rationale and scope of the AI Act, it is also\napplicable beyond the cases listed in Article 27 and can serve as a blueprint\nfor other national and international regulatory initiatives to ensure that AI\nis fully consistent with human rights.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15149v1",
    "published_date": "2024-11-07 11:55:55 UTC",
    "updated_date": "2024-11-07 11:55:55 UTC"
  },
  {
    "arxiv_id": "2411.04642v1",
    "title": "TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models",
    "authors": [
      "Jonathan Fhima",
      "Elad Ben Avraham",
      "Oren Nuriel",
      "Yair Kittenplon",
      "Roy Ganz",
      "Aviad Aberdam",
      "Ron Litman"
    ],
    "abstract": "Vision-Language (VL) models have garnered considerable research interest;\nhowever, they still face challenges in effectively handling text within images.\nTo address this limitation, researchers have developed two approaches. The\nfirst method involves utilizing external Optical Character Recognition (OCR)\ntools to extract textual information from images, which is then prepended to\nother textual inputs. The second strategy focuses on employing extremely\nhigh-resolution images to improve text recognition capabilities. In this paper,\nwe focus on enhancing the first strategy by introducing a novel method, named\nTAP-VL, which treats OCR information as a distinct modality and seamlessly\nintegrates it into any VL model. TAP-VL employs a lightweight transformer-based\nOCR module to receive OCR with layout information, compressing it into a short\nfixed-length sequence for input into the LLM. Initially, we conduct\nmodel-agnostic pretraining of the OCR module on unlabeled documents, followed\nby its integration into any VL architecture through brief fine-tuning.\nExtensive experiments demonstrate consistent performance improvements when\napplying TAP-VL to top-performing VL models, across scene-text and\ndocument-based VL benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04642v1",
    "published_date": "2024-11-07 11:54:01 UTC",
    "updated_date": "2024-11-07 11:54:01 UTC"
  },
  {
    "arxiv_id": "2411.04594v2",
    "title": "Verification of Neural Networks against Convolutional Perturbations via Parameterised Kernels",
    "authors": [
      "Benedikt Brückner",
      "Alessio Lomuscio"
    ],
    "abstract": "We develop a method for the efficient verification of neural networks against\nconvolutional perturbations such as blurring or sharpening. To define input\nperturbations we use well-known camera shake, box blur and sharpen kernels. We\ndemonstrate that these kernels can be linearly parameterised in a way that\nallows for a variation of the perturbation strength while preserving desired\nkernel properties. To facilitate their use in neural network verification, we\ndevelop an efficient way of convolving a given input with these parameterised\nkernels. The result of this convolution can be used to encode the perturbation\nin a verification setting by prepending a linear layer to a given network. This\nleads to tight bounds and a high effectiveness in the resulting verification\nstep. We add further precision by employing input splitting as a branch and\nbound strategy. We demonstrate that we are able to verify robustness on a\nnumber of standard benchmarks where the baseline is unable to provide any\nsafety certificates. To the best of our knowledge, this is the first solution\nfor verifying robustness against specific convolutional perturbations such as\ncamera shake.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.04594v2",
    "published_date": "2024-11-07 10:25:20 UTC",
    "updated_date": "2025-02-17 19:37:58 UTC"
  },
  {
    "arxiv_id": "2411.04588v1",
    "title": "Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction",
    "authors": [
      "Ahlam Alrehili",
      "Areej Alhothali"
    ],
    "abstract": "Natural language processing (NLP) utilizes text data augmentation to overcome\nsample size constraints. Increasing the sample size is a natural and widely\nused strategy for alleviating these challenges. In this study, we chose Arabic\nto increase the sample size and correct grammatical errors. Arabic is\nconsidered one of the languages with limited resources for grammatical error\ncorrection (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used\nin most Arabic grammatical error correction research, with approximately 20,500\nparallel examples, which is considered low compared with other languages.\nTherefore, this study aims to develop an Arabic corpus called \"Tibyan\" for\ngrammatical error correction using ChatGPT. ChatGPT is used as a data augmenter\ntool based on a pair of Arabic sentences containing grammatical errors matched\nwith a sentence free of errors extracted from Arabic books, called guide\nsentences. Multiple steps were involved in establishing our corpus, including\nthe collection and pre-processing of a pair of Arabic texts from various\nsources, such as books and open-access corpora. We then used ChatGPT to\ngenerate a parallel corpus based on the text collected previously, as a guide\nfor generating sentences with multiple types of errors. By engaging linguistic\nexperts to review and validate the automatically generated sentences, we\nensured that they were correct and error-free. The corpus was validated and\nrefined iteratively based on feedback provided by linguistic experts to improve\nits accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to\nanalyze the types of errors in the Tibyan corpus. Our corpus contained 49 of\nerrors, including seven types: orthography, morphology, syntax, semantics,\npunctuation, merge, and split. The Tibyan corpus contains approximately 600 K\ntokens.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.04588v1",
    "published_date": "2024-11-07 10:17:40 UTC",
    "updated_date": "2024-11-07 10:17:40 UTC"
  },
  {
    "arxiv_id": "2411.04586v2",
    "title": "On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data",
    "authors": [
      "Aitor Martinez-Seras",
      "Javier Del Ser",
      "Aitzol Olivares-Rad",
      "Alain Andres",
      "Pablo Garcia-Bringas"
    ],
    "abstract": "Robustness is a fundamental aspect for developing safe and trustworthy\nmodels, particularly when they are deployed in the open world. In this work we\nanalyze the inherent capability of one-stage object detectors to robustly\noperate in the presence of out-of-distribution (OoD) data. Specifically, we\npropose a novel detection algorithm for detecting unknown objects in image\ndata, which leverages the features extracted by the model from each sample.\nDifferently from other recent approaches in the literature, our proposal does\nnot require retraining the object detector, thereby allowing for the use of\npretrained models. Our proposed OoD detector exploits the application of\nsupervised dimensionality reduction techniques to mitigate the effects of the\ncurse of dimensionality on the features extracted by the model. Furthermore, it\nutilizes high-resolution feature maps to identify potential unknown objects in\nan unsupervised fashion. Our experiments analyze the Pareto trade-off between\nthe performance detecting known and unknown objects resulting from different\nalgorithmic configurations and inference confidence thresholds. We also compare\nthe performance of our proposed algorithm to that of logits-based post-hoc OoD\nmethods, as well as possible fusion strategies. Finally, we discuss on the\ncompetitiveness of all tested methods against state-of-the-art OoD approaches\nfor object detection models over the recently published Unknown Object\nDetection benchmark. The obtained results verify that the performance of\navant-garde post-hoc OoD detectors can be further improved when combined with\nour proposed algorithm.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T45, 68T07",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "13 figures, 4 tables, under review",
    "pdf_url": "http://arxiv.org/pdf/2411.04586v2",
    "published_date": "2024-11-07 10:15:25 UTC",
    "updated_date": "2025-02-04 20:20:36 UTC"
  },
  {
    "arxiv_id": "2411.04580v1",
    "title": "Interpreting the Learned Model in MuZero Planning",
    "authors": [
      "Hung Guei",
      "Yan-Ru Ju",
      "Wei-Yu Chen",
      "Ti-Rong Wu"
    ],
    "abstract": "MuZero has achieved superhuman performance in various games by using a\ndynamics network to predict environment dynamics for planning, without relying\non simulators. However, the latent states learned by the dynamics network make\nits planning process opaque. This paper aims to demystify MuZero's model by\ninterpreting the learned latent states. We incorporate observation\nreconstruction and state consistency into MuZero training and conduct an\nin-depth analysis to evaluate latent states across two board games: 9x9 Go and\nOuter-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our\nfindings reveal that while the dynamics network becomes less accurate over\nlonger simulations, MuZero still performs effectively by using planning to\ncorrect errors. Our experiments also show that the dynamics network learns\nbetter latent states in board games than in Atari games. These insights\ncontribute to a better understanding of MuZero and offer directions for future\nresearch to improve the playing performance, robustness, and interpretability\nof the MuZero algorithm.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 29th International Conference on Technologies and\n  Applications of Artificial Intelligence (TAAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.04580v1",
    "published_date": "2024-11-07 10:06:23 UTC",
    "updated_date": "2024-11-07 10:06:23 UTC"
  },
  {
    "arxiv_id": "2411.04578v1",
    "title": "Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions",
    "authors": [
      "Tianqi Song",
      "Yugin Tan",
      "Zicheng Zhu",
      "Yibin Feng",
      "Yi-Chieh Lee"
    ],
    "abstract": "Multi-agent systems - systems with multiple independent AI agents working\ntogether to achieve a common goal - are becoming increasingly prevalent in\ndaily life. Drawing inspiration from the phenomenon of human group social\ninfluence, we investigate whether a group of AI agents can create social\npressure on users to agree with them, potentially changing their stance on a\ntopic. We conducted a study in which participants discussed social issues with\neither a single or multiple AI agents, and where the agents either agreed or\ndisagreed with the user's stance on the topic. We found that conversing with\nmultiple agents (holding conversation content constant) increased the social\npressure felt by participants, and caused a greater shift in opinion towards\nthe agents' stances on each topic. Our study shows the potential advantages of\nmulti-agent systems over single-agent platforms in causing opinion change. We\ndiscuss design implications for possible multi-agent systems that promote\nsocial good, as well as the potential for malicious actors to use these systems\nto manipulate public opinion.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04578v1",
    "published_date": "2024-11-07 10:00:46 UTC",
    "updated_date": "2024-11-07 10:00:46 UTC"
  },
  {
    "arxiv_id": "2411.04573v1",
    "title": "Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages",
    "authors": [
      "Leena G Pillai",
      "Kavya Manohar",
      "Basil K Raju",
      "Elizabeth Sherly"
    ],
    "abstract": "This paper presents a novel multistage fine-tuning strategy designed to\nenhance automatic speech recognition (ASR) performance in low-resource\nlanguages using OpenAI's Whisper model. In this approach we aim to build ASR\nmodel for languages with limited digital resources by sequentially adapting the\nmodel across linguistically similar languages. We experimented this on the\nMalasar language, a Dravidian language spoken by approximately ten thousand\npeople in the Western Ghats of South India. Malasar language faces critical\nchallenges for technological intervention due to its lack of a native script\nand absence of digital or spoken data resources. Working in collaboration with\nWycliffe India and Malasar community members, we created a spoken Malasar\ncorpus paired with transcription in Tamil script, a closely related major\nlanguage. In our approach to build ASR model for Malasar, we first build an\nintermediate Tamil ASR, leveraging higher data availability for Tamil annotated\nspeech. This intermediate model is subsequently fine-tuned on Malasar data,\nallowing for more effective ASR adaptation despite limited resources. The\nmultistage fine-tuning strategy demonstrated significant improvements over\ndirect fine-tuning on Malasar data alone, achieving a word error rate (WER) of\n51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning\nmethod. Further a WER reduction to 47.3% was achieved through punctuation\nremoval in post-processing, which addresses formatting inconsistencies that\nimpact evaluation. Our results underscore the effectiveness of sequential\nmultistage fine-tuning combined with targeted post-processing as a scalable\nstrategy for ASR system development in low-resource languages, especially where\nlinguistic similarities can be leveraged to bridge gaps in training data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04573v1",
    "published_date": "2024-11-07 09:57:57 UTC",
    "updated_date": "2024-11-07 09:57:57 UTC"
  },
  {
    "arxiv_id": "2411.04569v1",
    "title": "Impact of Label Noise on Learning Complex Features",
    "authors": [
      "Rahul Vashisht",
      "P. Krishna Kumar",
      "Harsha Vardhan Govind",
      "Harish G. Ramaswamy"
    ],
    "abstract": "Neural networks trained with stochastic gradient descent exhibit an inductive\nbias towards simpler decision boundaries, typically converging to a narrow\nfamily of functions, and often fail to capture more complex features. This\nphenomenon raises concerns about the capacity of deep models to adequately\nlearn and represent real-world datasets. Traditional approaches such as\nexplicit regularization, data augmentation, architectural modifications, etc.,\nhave largely proven ineffective in encouraging the models to learn diverse\nfeatures. In this work, we investigate the impact of pre-training models with\nnoisy labels on the dynamics of SGD across various architectures and datasets.\nWe show that pretraining promotes learning complex functions and diverse\nfeatures in the presence of noise. Our experiments demonstrate that\npre-training with noisy labels encourages gradient descent to find alternate\nminima that do not solely depend upon simple features, rather learns more\ncomplex and broader set of features, without hurting performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Workshop on Scientific Methods for Understanding Deep\n  Learning, NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04569v1",
    "published_date": "2024-11-07 09:47:18 UTC",
    "updated_date": "2024-11-07 09:47:18 UTC"
  },
  {
    "arxiv_id": "2411.04564v1",
    "title": "A Generalisation of Voter Model: Influential Nodes and Convergence Properties",
    "authors": [
      "Abhiram Manohara",
      "Ahad N. Zehmakan"
    ],
    "abstract": "Consider an undirected graph G, representing a social network, where each\nnode is blue or red, corresponding to positive or negative opinion on a topic.\nIn the voter model, in discrete time rounds, each node picks a neighbour\nuniformly at random and adopts its colour. Despite its significant popularity,\nthis model does not capture some fundamental real-world characteristics such as\nthe difference in the strengths of individuals connections, individuals with\nneutral opinion on a topic, and individuals who are reluctant to update their\nopinion. To address these issues, we introduce and study a generalisation of\nthe voter model. Motivating by campaigning strategies, we study the problem of\nselecting a set of seeds blue nodes to maximise the expected number of blue\nnodes after some rounds. We prove that the problem is NP- hard and provide a\npolynomial time approximation algorithm with the best possible approximation\nguarantee. Our experiments on real-world and synthetic graph data demonstrate\nthat the proposed algorithm outperforms other algorithms. We also investigate\nthe convergence properties of the model. We prove that the process could take\nan exponential number of rounds to converge. However, if we limit ourselves to\nstrongly connected graphs, the convergence time is polynomial and the period\n(the number of states in convergence) divides the length of all cycles in the\ngraph.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04564v1",
    "published_date": "2024-11-07 09:38:42 UTC",
    "updated_date": "2024-11-07 09:38:42 UTC"
  },
  {
    "arxiv_id": "2411.04562v2",
    "title": "Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning",
    "authors": [
      "Marvin Alles",
      "Philip Becker-Ehmck",
      "Patrick van der Smagt",
      "Maximilian Karl"
    ],
    "abstract": "In offline reinforcement learning, a policy is learned using a static dataset\nin the absence of costly feedback from the environment. In contrast to the\nonline setting, only using static datasets poses additional challenges, such as\npolicies generating out-of-distribution samples. Model-based offline\nreinforcement learning methods try to overcome these by learning a model of the\nunderlying dynamics of the environment and using it to guide policy search. It\nis beneficial but, with limited datasets, errors in the model and the issue of\nvalue overestimation among out-of-distribution states can worsen performance.\nCurrent model-based methods apply some notion of conservatism to the Bellman\nupdate, often implemented using uncertainty estimation derived from model\nensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP)\nwhich learns a generative model of the joint distribution of observations and\nactions. We cast policy learning as a constrained objective to always stay\nwithin the support of the latent action distribution, and use the generative\ncapabilities of the model to impose an implicit constraint on the generated\nactions. Thereby eliminating the need to use additional uncertainty penalties\non the Bellman update and significantly decreasing the number of gradient steps\nrequired to learn a policy. We empirically evaluate C-LAP on the D4RL and\nV-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art\nmethods, especially outperforming on datasets with visual observations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.04562v2",
    "published_date": "2024-11-07 09:35:22 UTC",
    "updated_date": "2025-01-15 13:24:49 UTC"
  },
  {
    "arxiv_id": "2411.04555v2",
    "title": "An Axiomatic Study of the Evaluation of Enthymeme Decoding in Weighted Structured Argumentation",
    "authors": [
      "Jonathan Ben-Naim",
      "Victor David",
      "Anthony Hunter"
    ],
    "abstract": "An argument can be seen as a pair consisting of a set of premises and a claim\nsupported by them. Arguments used by humans are often enthymemes, i.e., some\npremises are implicit. To better understand, evaluate, and compare enthymemes,\nit is essential to decode them, i.e., to find the missing premisses. Many\nenthymeme decodings are possible. We need to distinguish between reasonable\ndecodings and unreasonable ones. However, there is currently no research in the\nliterature on \"How to evaluate decodings?\". To pave the way and achieve this\ngoal, we introduce seven criteria related to decoding, based on different\nresearch areas. Then, we introduce the notion of criterion measure, the\nobjective of which is to evaluate a decoding with regard to a certain\ncriterion. Since such measures need to be validated, we introduce several\ndesirable properties for them, called axioms. Another main contribution of the\npaper is the construction of certain criterion measures that are validated by\nour axioms. Such measures can be used to identify the best enthymemes\ndecodings.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.04555v2",
    "published_date": "2024-11-07 09:26:54 UTC",
    "updated_date": "2024-11-13 09:44:33 UTC"
  },
  {
    "arxiv_id": "2411.04549v1",
    "title": "Vision Language Models are In-Context Value Learners",
    "authors": [
      "Yecheng Jason Ma",
      "Joey Hejna",
      "Ayzaan Wahid",
      "Chuyuan Fu",
      "Dhruv Shah",
      "Jacky Liang",
      "Zhuo Xu",
      "Sean Kirmani",
      "Peng Xu",
      "Danny Driess",
      "Ted Xiao",
      "Jonathan Tompson",
      "Osbert Bastani",
      "Dinesh Jayaraman",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Dorsa Sadigh",
      "Fei Xia"
    ],
    "abstract": "Predicting temporal progress from visual trajectories is important for\nintelligent robots that can learn, adapt, and improve. However, learning such\nprogress estimator, or temporal value function, across different tasks and\ndomains requires both a large amount of diverse data and methods which can\nscale and generalize. To address these challenges, we present Generative Value\nLearning (\\GVL), a universal value function estimator that leverages the world\nknowledge embedded in vision-language models (VLMs) to predict task progress.\nNaively asking a VLM to predict values for a video sequence performs poorly due\nto the strong temporal correlation between successive frames. Instead, GVL\nposes value estimation as a temporal ordering problem over shuffled video\nframes; this seemingly more challenging task encourages VLMs to more fully\nexploit their underlying semantic and temporal grounding capabilities to\ndifferentiate frames based on their perceived task progress, consequently\nproducing significantly better value predictions. Without any robot or task\nspecific training, GVL can in-context zero-shot and few-shot predict effective\nvalues for more than 300 distinct real-world tasks across diverse robot\nplatforms, including challenging bimanual manipulation tasks. Furthermore, we\ndemonstrate that GVL permits flexible multi-modal in-context learning via\nexamples from heterogeneous tasks and embodiments, such as human videos. The\ngenerality of GVL enables various downstream applications pertinent to\nvisuomotor policy learning, including dataset filtering, success detection, and\nadvantage-weighted regression -- all without any model training or finetuning.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website and demo:\n  https://generative-value-learning.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.04549v1",
    "published_date": "2024-11-07 09:17:50 UTC",
    "updated_date": "2024-11-07 09:17:50 UTC"
  },
  {
    "arxiv_id": "2411.05862v1",
    "title": "From Electrode to Global Brain: Integrating Multi- and Cross-Scale Brain Connections and Interactions Under Cross-Subject and Within-Subject Scenarios",
    "authors": [
      "Chen Zhige",
      "Qin Chengxuan"
    ],
    "abstract": "The individual variabilities of electroencephalogram signals pose great\nchallenges to cross-subject motor imagery (MI) classification, especially for\nthe data-scarce single-source to single-target (STS) scenario. The multi-scale\nspatial data distribution differences can not be fully eliminated in MI\nexperiments for the topological structure and connection are the inherent\nproperties of the human brain. Overall, no literature investigates the\nmulti-scale spatial data distribution problem in STS cross-subject MI\nclassification task, neither intra-subject nor inter-subject scenarios. In this\npaper, a novel multi-scale spatial domain adaptation network (MSSDAN) consists\nof both multi-scale spatial feature extractor (MSSFE) and deep domain\nadaptation method called multi-scale spatial domain adaptation (MSSDA) is\nproposed and verified, our goal is to integrate the principles of multi-scale\nbrain topological structures in order to solve the multi-scale spatial data\ndistribution difference problem.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05862v1",
    "published_date": "2024-11-07 09:12:13 UTC",
    "updated_date": "2024-11-07 09:12:13 UTC"
  },
  {
    "arxiv_id": "2411.04547v1",
    "title": "Dynamic Detection of Relevant Objectives and Adaptation to Preference Drifts in Interactive Evolutionary Multi-Objective Optimization",
    "authors": [
      "Seyed Mahdi Shavarani",
      "Mahmoud Golabi",
      "Richard Allmendinger",
      "Lhassane Idoumghar"
    ],
    "abstract": "Evolutionary Multi-Objective Optimization Algorithms (EMOAs) are widely\nemployed to tackle problems with multiple conflicting objectives. Recent\nresearch indicates that not all objectives are equally important to the\ndecision-maker (DM). In the context of interactive EMOAs, preference\ninformation elicited from the DM during the optimization process can be\nleveraged to identify and discard irrelevant objectives, a crucial step when\nobjective evaluations are computationally expensive. However, much of the\nexisting literature fails to account for the dynamic nature of DM preferences,\nwhich can evolve throughout the decision-making process and affect the\nrelevance of objectives. This study addresses this limitation by simulating\ndynamic shifts in DM preferences within a ranking-based interactive algorithm.\nAdditionally, we propose methods to discard outdated or conflicting preferences\nwhen such shifts occur. Building on prior research, we also introduce a\nmechanism to safeguard relevant objectives that may become trapped in local or\nglobal optima due to the diminished correlation with the DM-provided rankings.\nOur experimental results demonstrate that the proposed methods effectively\nmanage evolving preferences and significantly enhance the quality and\ndesirability of the solutions produced by the algorithm.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04547v1",
    "published_date": "2024-11-07 09:09:06 UTC",
    "updated_date": "2024-11-07 09:09:06 UTC"
  },
  {
    "arxiv_id": "2411.05051v1",
    "title": "Intellectual Property Protection for Deep Learning Model and Dataset Intelligence",
    "authors": [
      "Yongqi Jiang",
      "Yansong Gao",
      "Chunyi Zhou",
      "Hongsheng Hu",
      "Anmin Fu",
      "Willy Susilo"
    ],
    "abstract": "With the growing applications of Deep Learning (DL), especially recent\nspectacular achievements of Large Language Models (LLMs) such as ChatGPT and\nLLaMA, the commercial significance of these remarkable models has soared.\nHowever, acquiring well-trained models is costly and resource-intensive. It\nrequires a considerable high-quality dataset, substantial investment in\ndedicated architecture design, expensive computational resources, and efforts\nto develop technical expertise. Consequently, safeguarding the Intellectual\nProperty (IP) of well-trained models is attracting increasing attention. In\ncontrast to existing surveys overwhelmingly focusing on model IPP mainly, this\nsurvey not only encompasses the protection on model level intelligence but also\nvaluable dataset intelligence. Firstly, according to the requirements for\neffective IPP design, this work systematically summarizes the general and\nscheme-specific performance evaluation metrics. Secondly, from proactive IP\ninfringement prevention and reactive IP ownership verification perspectives, it\ncomprehensively investigates and analyzes the existing IPP methods for both\ndataset and model intelligence. Additionally, from the standpoint of training\nsettings, it delves into the unique challenges that distributed settings pose\nto IPP compared to centralized settings. Furthermore, this work examines\nvarious attacks faced by deep IPP techniques. Finally, we outline prospects for\npromising future directions that may act as a guide for innovative research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05051v1",
    "published_date": "2024-11-07 09:02:41 UTC",
    "updated_date": "2024-11-07 09:02:41 UTC"
  },
  {
    "arxiv_id": "2411.04535v2",
    "title": "Meta-Reasoning Improves Tool Use in Large Language Models",
    "authors": [
      "Lisa Alazraki",
      "Marek Rei"
    ],
    "abstract": "External tools help large language models succeed at tasks where they would\notherwise typically fail. In existing frameworks, choosing tools at test time\nrelies on naive greedy decoding, regardless of whether the model has been\nfine-tuned on tool-annotated data or prompted with in-context examples. In\ncontrast, we find that gathering and choosing among a suitable set of candidate\ntools has greater potential to lead to an optimal selection. We present Tool\nselECTion via meta-reasONing (TECTON), a two-phase system that first reasons\nover a task and outputs candidate tools using a custom fine-tuned language\nmodelling head. Then, with the custom head disabled, it meta-reasons (i.e., it\nreasons over the previous reasoning process) to make a final choice. We show\nthat TECTON results in substantial gains--both in-distribution and\nout-of-distribution--on a range of math reasoning datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2411.04535v2",
    "published_date": "2024-11-07 08:48:33 UTC",
    "updated_date": "2025-02-08 18:26:05 UTC"
  },
  {
    "arxiv_id": "2411.04525v1",
    "title": "GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints",
    "authors": [
      "Pavel Sulimov",
      "Claude Lehmann",
      "Kurt Stockinger"
    ],
    "abstract": "Query optimization has become a research area where classical algorithms are\nbeing challenged by machine learning algorithms. At the same time, recent\ntrends in learned query optimizers have shown that it is prudent to take\nadvantage of decades of database research and augment classical query\noptimizers by shrinking the plan search space through different types of hints\n(e.g. by specifying the join type, scan type or the order of joins) rather than\ncompletely replacing the classical query optimizer with machine learning\nmodels. It is especially relevant for cases when classical optimizers cannot\nfully enumerate all logical and physical plans and, as an alternative, need to\nrely on less robust approaches like genetic algorithms. However, even\nsymbiotically learned query optimizers are hampered by the need for vast\namounts of training data, slow plan generation during inference and unstable\nresults across various workload conditions. In this paper, we present GenJoin -\na novel learned query optimizer that considers the query optimization problem\nas a generative task and is capable of learning from a random set of subplan\nhints to produce query plans that outperform the classical optimizer. GenJoin\nis the first learned query optimizer that significantly and consistently\noutperforms PostgreSQL as well as state-of-the-art methods on two well-known\nreal-world benchmarks across a variety of workloads using rigorous machine\nlearning evaluations.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04525v1",
    "published_date": "2024-11-07 08:31:01 UTC",
    "updated_date": "2024-11-07 08:31:01 UTC"
  },
  {
    "arxiv_id": "2411.04517v1",
    "title": "Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic",
    "authors": [
      "Sharvani Srivastava",
      "Sudhakar Singh",
      "Pooja",
      "Shiv Prakash"
    ],
    "abstract": "Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 4 figures, Wireless Pers Commun",
    "pdf_url": "http://arxiv.org/pdf/2411.04517v1",
    "published_date": "2024-11-07 08:19:39 UTC",
    "updated_date": "2024-11-07 08:19:39 UTC"
  },
  {
    "arxiv_id": "2411.04509v1",
    "title": "FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation",
    "authors": [
      "Liangrui Pan",
      "Mao Huang",
      "Lian Wang",
      "Pinle Qin",
      "Shaoliang Peng"
    ],
    "abstract": "Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is\nconsidered the gold standard for pathologists and medical practitioners for\ntumor diagnosis, surgical planning, and post-operative assessment. With the\nrapid advancement of deep learning technologies, the development of numerous\nmodels based on convolutional neural networks and transformer-based models has\nbeen applied to the precise segmentation of WSIs. However, due to privacy\nregulations and the need to protect patient confidentiality, centralized\nstorage and processing of image data are impractical. Training a centralized\nmodel directly is challenging to implement in medical settings due to these\nprivacy concerns.This paper addresses the dispersed nature and privacy\nsensitivity of medical image data by employing a federated learning framework,\nallowing medical institutions to collaboratively learn while protecting patient\nprivacy. Additionally, to address the issue of original data reconstruction\nthrough gradient inversion during the federated learning training process,\ndifferential privacy introduces noise into the model updates, preventing\nattackers from inferring the contributions of individual samples, thereby\nprotecting the privacy of the training data.Experimental results show that the\nproposed method, FedDP, minimally impacts model accuracy while effectively\nsafeguarding the privacy of cancer pathology image data, with only a slight\ndecrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,\nrespectively. This approach facilitates cross-institutional collaboration and\nknowledge sharing while protecting sensitive data privacy, providing a viable\nsolution for further research and application in the medical field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in BIBM2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04509v1",
    "published_date": "2024-11-07 08:02:58 UTC",
    "updated_date": "2024-11-07 08:02:58 UTC"
  },
  {
    "arxiv_id": "2411.04491v1",
    "title": "Series-to-Series Diffusion Bridge Model",
    "authors": [
      "Hao Yang",
      "Zhanbo Feng",
      "Feng Zhou",
      "Robert C Qiu",
      "Zenan Ling"
    ],
    "abstract": "Diffusion models have risen to prominence in time series forecasting,\nshowcasing their robust capability to model complex data distributions.\nHowever, their effectiveness in deterministic predictions is often constrained\nby instability arising from their inherent stochasticity. In this paper, we\nrevisit time series diffusion models and present a comprehensive framework that\nencompasses most existing diffusion-based methods. Building on this theoretical\nfoundation, we propose a novel diffusion-based time series forecasting model,\nthe Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$), which\nleverages the Brownian Bridge process to reduce randomness in reverse\nestimations and improves accuracy by incorporating informative priors and\nconditions derived from historical time series data. Experimental results\ndemonstrate that $\\mathrm{S^2DBM}$ delivers superior performance in\npoint-to-point forecasting and competes effectively with other diffusion-based\nmodels in probabilistic forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04491v1",
    "published_date": "2024-11-07 07:37:34 UTC",
    "updated_date": "2024-11-07 07:37:34 UTC"
  },
  {
    "arxiv_id": "2411.05050v1",
    "title": "Selecting Between BERT and GPT for Text Classification in Political Science Research",
    "authors": [
      "Yu Wang",
      "Wen Qu",
      "Xin Ye"
    ],
    "abstract": "Political scientists often grapple with data scarcity in text classification.\nRecently, fine-tuned BERT models and their variants have gained traction as\neffective solutions to address this issue. In this study, we investigate the\npotential of GPT-based models combined with prompt engineering as a viable\nalternative. We conduct a series of experiments across various classification\ntasks, differing in the number of classes and complexity, to evaluate the\neffectiveness of BERT-based versus GPT-based models in low-data scenarios. Our\nfindings indicate that while zero-shot and few-shot learning with GPT models\nprovide reasonable performance and are well-suited for early-stage research\nexploration, they generally fall short - or, at best, match - the performance\nof BERT fine-tuning, particularly as the training set reaches a substantial\nsize (e.g., 1,000 samples). We conclude by comparing these approaches in terms\nof performance, ease of use, and cost, providing practical guidance for\nresearchers facing data limitations. Our results are particularly relevant for\nthose engaged in quantitative text analysis in low-resource settings or with\nlimited labeled data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 5 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.05050v1",
    "published_date": "2024-11-07 07:29:39 UTC",
    "updated_date": "2024-11-07 07:29:39 UTC"
  },
  {
    "arxiv_id": "2411.05860v1",
    "title": "Conditional Diffusion Model for Longitudinal Medical Image Generation",
    "authors": [
      "Duy-Phuong Dao",
      "Hyung-Jeong Yang",
      "Jahae Kim"
    ],
    "abstract": "Alzheimers disease progresses slowly and involves complex interaction between\nvarious biological factors. Longitudinal medical imaging data can capture this\nprogression over time. However, longitudinal data frequently encounter issues\nsuch as missing data due to patient dropouts, irregular follow-up intervals,\nand varying lengths of observation periods. To address these issues, we\ndesigned a diffusion-based model for 3D longitudinal medical imaging generation\nusing single magnetic resonance imaging (MRI). This involves the injection of a\nconditioning MRI and time-visit encoding to the model, enabling control in\nchange between source and target images. The experimental results indicate that\nthe proposed method generates higher-quality images compared to other competing\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2411.05860v1",
    "published_date": "2024-11-07 06:44:47 UTC",
    "updated_date": "2024-11-07 06:44:47 UTC"
  },
  {
    "arxiv_id": "2411.04468v1",
    "title": "Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks",
    "authors": [
      "Adam Fourney",
      "Gagan Bansal",
      "Hussein Mozannar",
      "Cheng Tan",
      "Eduardo Salinas",
      "Erkang",
      "Zhu",
      "Friederike Niedtner",
      "Grace Proebsting",
      "Griffin Bassman",
      "Jack Gerrits",
      "Jacob Alber",
      "Peter Chang",
      "Ricky Loynd",
      "Robert West",
      "Victor Dibia",
      "Ahmed Awadallah",
      "Ece Kamar",
      "Rafah Hosn",
      "Saleema Amershi"
    ],
    "abstract": "Modern AI agents, driven by advances in large foundation models, promise to\nenhance our productivity and transform our lives by augmenting our knowledge\nand capabilities. To achieve this vision, AI agents must effectively plan,\nperform multi-step reasoning and actions, respond to novel observations, and\nrecover from errors, to successfully complete complex tasks across a wide range\nof scenarios. In this work, we introduce Magentic-One, a high-performing\nopen-source agentic system for solving such tasks. Magentic-One uses a\nmulti-agent architecture where a lead agent, the Orchestrator, plans, tracks\nprogress, and re-plans to recover from errors. Throughout task execution, the\nOrchestrator directs other specialized agents to perform tasks as needed, such\nas operating a web browser, navigating local files, or writing and executing\nPython code. We show that Magentic-One achieves statistically competitive\nperformance to the state-of-the-art on three diverse and challenging agentic\nbenchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves these\nresults without modification to core agent capabilities or to how they\ncollaborate, demonstrating progress towards generalist agentic systems.\nMoreover, Magentic-One's modular design allows agents to be added or removed\nfrom the team without additional prompt tuning or training, easing development\nand making it extensible to future scenarios. We provide an open-source\nimplementation of Magentic-One, and we include AutoGenBench, a standalone tool\nfor agentic evaluation. AutoGenBench provides built-in controls for repetition\nand isolation to run agentic benchmarks in a rigorous and contained manner --\nwhich is important when agents' actions have side-effects. Magentic-One,\nAutoGenBench and detailed empirical performance evaluations of Magentic-One,\nincluding ablations and error analysis are available at\nhttps://aka.ms/magentic-one",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04468v1",
    "published_date": "2024-11-07 06:36:19 UTC",
    "updated_date": "2024-11-07 06:36:19 UTC"
  },
  {
    "arxiv_id": "2411.04466v1",
    "title": "Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity",
    "authors": [
      "Robby Costales",
      "Stefanos Nikolaidis"
    ],
    "abstract": "The wider application of end-to-end learning methods to embodied\ndecision-making domains remains bottlenecked by their reliance on a\nsuperabundance of training data representative of the target domain.\nMeta-reinforcement learning (meta-RL) approaches abandon the aim of zero-shot\ngeneralization--the goal of standard reinforcement learning (RL)--in favor of\nfew-shot adaptation, and thus hold promise for bridging larger generalization\ngaps. While learning this meta-level adaptive behavior still requires\nsubstantial data, efficient environment simulators approaching real-world\ncomplexity are growing in prevalence. Even so, hand-designing sufficiently\ndiverse and numerous simulated training tasks for these complex domains is\nprohibitively labor-intensive. Domain randomization (DR) and procedural\ngeneration (PG), offered as solutions to this problem, require simulators to\npossess carefully-defined parameters which directly translate to meaningful\ntask diversity--a similarly prohibitive assumption. In this work, we present\nDIVA, an evolutionary approach for generating diverse training tasks in such\ncomplex, open-ended simulators. Like unsupervised environment design (UED)\nmethods, DIVA can be applied to arbitrary parameterizations, but can\nadditionally incorporate realistically-available domain knowledge--thus\ninheriting the flexibility and generality of UED, and the supervised structure\nembedded in well-designed simulators exploited by DR and PG. Our empirical\nresults showcase DIVA's unique ability to overcome complex parameterizations\nand successfully train adaptive agent behavior, far outperforming competitive\nbaselines from prior literature. These findings highlight the potential of such\nsemi-supervised environment design (SSED) approaches, of which DIVA is the\nfirst humble constituent, to enable training in realistic simulated domains,\nand produce more robust and capable adaptive agents.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04466v1",
    "published_date": "2024-11-07 06:27:12 UTC",
    "updated_date": "2024-11-07 06:27:12 UTC"
  },
  {
    "arxiv_id": "2411.04462v2",
    "title": "Can CDT rationalise the ex ante optimal policy via modified anthropics?",
    "authors": [
      "Emery Cooper",
      "Caspar Oesterheld",
      "Vincent Conitzer"
    ],
    "abstract": "In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and\nthus comes apart from evidential decision theory (EDT) and ex ante policy\noptimisation (which prescribe one-boxing). However, in Newcomb's problem, you\nshould perhaps believe that with some probability you are in a simulation run\nby the predictor to determine whether to put a million dollars into the opaque\nbox. If so, then causal decision theory might recommend one-boxing in order to\ncause the predictor to fill the opaque box. In this paper, we study\ngeneralisations of this approach. That is, we consider general Newcomblike\nproblems and try to form reasonable self-locating beliefs under which CDT's\nrecommendations align with an EDT-like notion of ex ante policy optimisation.\nWe consider approaches in which we model the world as running simulations of\nthe agent, and an approach not based on such models (which we call 'Generalised\nGeneralised Thirding', or GGT). For each approach, we characterise the\nresulting CDT policies, and prove that under certain conditions, these include\nthe ex ante optimal policies.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04462v2",
    "published_date": "2024-11-07 06:23:38 UTC",
    "updated_date": "2024-11-20 19:39:49 UTC"
  },
  {
    "arxiv_id": "2411.05859v1",
    "title": "Enhancing Financial Fraud Detection with Human-in-the-Loop Feedback and Feedback Propagation",
    "authors": [
      "Prashank Kadam"
    ],
    "abstract": "Human-in-the-loop (HITL) feedback mechanisms can significantly enhance\nmachine learning models, particularly in financial fraud detection, where fraud\npatterns change rapidly, and fraudulent nodes are sparse. Even small amounts of\nfeedback from Subject Matter Experts (SMEs) can notably boost model\nperformance. This paper examines the impact of HITL feedback on both\ntraditional and advanced techniques using proprietary and publicly available\ndatasets. Our results show that HITL feedback improves model accuracy, with\ngraph-based techniques benefiting the most. We also introduce a novel feedback\npropagation method that extends feedback across the dataset, further enhancing\ndetection accuracy. By leveraging human expertise, this approach addresses\nchallenges related to evolving fraud patterns, data sparsity, and model\ninterpretability, ultimately improving model robustness and streamlining the\nannotation process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "J.1"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning and Applications 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.05859v1",
    "published_date": "2024-11-07 05:22:36 UTC",
    "updated_date": "2024-11-07 05:22:36 UTC"
  },
  {
    "arxiv_id": "2411.04434v2",
    "title": "Scaling Laws for Pre-training Agents and World Models",
    "authors": [
      "Tim Pearce",
      "Tabish Rashid",
      "Dave Bignell",
      "Raluca Georgescu",
      "Sam Devlin",
      "Katja Hofmann"
    ],
    "abstract": "The performance of embodied agents has been shown to improve by increasing\nmodel parameters, dataset size, and compute. This has been demonstrated in\ndomains from robotics to video games, when generative learning objectives on\noffline datasets (pre-training) are used to model an agent's behavior\n(imitation learning) or their environment (world modeling). This paper\ncharacterizes the role of scale in these tasks more precisely. Going beyond the\nsimple intuition that `bigger is better', we show that the same types of power\nlaws found in language modeling also arise in world modeling and imitation\nlearning (e.g. between loss and optimal model size). However, the coefficients\nof these laws are heavily influenced by the tokenizer, task \\& architecture --\nthis has important implications on the optimal sizing of models and data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04434v2",
    "published_date": "2024-11-07 04:57:40 UTC",
    "updated_date": "2024-12-18 07:54:33 UTC"
  },
  {
    "arxiv_id": "2411.04424v1",
    "title": "Bayesian Calibration of Win Rate Estimation with LLM Evaluators",
    "authors": [
      "Yicheng Gao",
      "Gonghan Xu",
      "Zhe Wang",
      "Arman Cohan"
    ],
    "abstract": "Recent advances in large language models (LLMs) show the potential of using\nLLMs as evaluators for assessing the quality of text generations from LLMs.\nHowever, applying LLM evaluators naively to compare or judge between different\nsystems can lead to unreliable results due to the intrinsic win rate estimation\nbias of LLM evaluators. In order to mitigate this problem, we propose two\ncalibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian\nDawid-Skene, both of which leverage Bayesian inference to more accurately infer\nthe true win rate of generative language models. We empirically validate our\nmethods on six datasets covering story generation, summarization, and\ninstruction following tasks. We show that both our methods are effective in\nimproving the accuracy of win rate estimation using LLMs as evaluators,\noffering a promising direction for reliable automatic text quality evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.04424v1",
    "published_date": "2024-11-07 04:32:40 UTC",
    "updated_date": "2024-11-07 04:32:40 UTC"
  },
  {
    "arxiv_id": "2411.04421v2",
    "title": "Variational Low-Rank Adaptation Using IVON",
    "authors": [
      "Bai Cong",
      "Nico Daheim",
      "Yuesong Shen",
      "Daniel Cremers",
      "Rio Yokota",
      "Mohammad Emtiyaz Khan",
      "Thomas Möllenhoff"
    ],
    "abstract": "We show that variational learning can significantly improve the accuracy and\ncalibration of Low-Rank Adaptation (LoRA) without a substantial increase in the\ncost. We replace AdamW by the Improved Variational Online Newton (IVON)\nalgorithm to finetune large language models. For Llama-2 with 7 billion\nparameters, IVON improves the accuracy over AdamW by 2.8% and expected\ncalibration error by 4.6%. The accuracy is also better than the other Bayesian\nalternatives, yet the cost is lower and the implementation is easier. Our work\nprovides additional evidence for the effectiveness of IVON for large language\nmodels. The code is available at\nhttps://github.com/team-approx-bayes/ivon-lora.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at 38th Workshop on Fine-Tuning in Machine Learning\n  (NeurIPS 2024). Code available at\n  https://github.com/team-approx-bayes/ivon-lora. In version 2 we fixed a typo\n  in the equation of prior in section 2",
    "pdf_url": "http://arxiv.org/pdf/2411.04421v2",
    "published_date": "2024-11-07 04:17:30 UTC",
    "updated_date": "2024-11-09 12:30:06 UTC"
  },
  {
    "arxiv_id": "2411.05048v1",
    "title": "Leveraging LLMs to Enable Natural Language Search on Go-to-market Platforms",
    "authors": [
      "Jesse Yao",
      "Saurav Acharya",
      "Priyaranjan Parida",
      "Srinivas Attipalli",
      "Ali Dasdan"
    ],
    "abstract": "Enterprise searches require users to have complex knowledge of queries,\nconfigurations, and metadata, rendering it difficult for them to access\ninformation as needed. Most go-to-market (GTM) platforms utilize advanced\nsearch, an interface that enables users to filter queries by various fields\nusing categories or keywords, which, historically, however, has proven to be\nexceedingly cumbersome, as users are faced with seemingly hundreds of options,\nfields, and buttons. Consequently, querying with natural language has long been\nideal, a notion further empowered by Large Language Models (LLMs).\n  In this paper, we implement and evaluate a solution for the Zoominfo product\nfor sellers, which prompts the LLM with natural language, producing search\nfields through entity extraction that are then converted into a search query.\nThe intermediary search fields offer numerous advantages for each query,\nincluding the elimination of syntax errors, simpler ground truths, and an\nintuitive format for the LLM to interpret.\n  We paired this pipeline with many advanced prompt engineering strategies,\nfeaturing an intricate system message, few-shot prompting, chain-of-thought\n(CoT) reasoning, and execution refinement. Furthermore, we manually created the\nground truth for 500+ natural language queries, enabling the supervised\nfine-tuning of Llama-3-8B-Instruct and the introduction of sophisticated\nnumerical metrics.\n  Comprehensive experiments with closed, open source, and fine-tuned LLM models\nwere conducted through exact, Jaccard, cosine, and semantic similarity on\nindividual search entities to demonstrate the efficacy of our approach.\nOverall, the most accurate closed model had an average accuracy of 97% per\nquery, with only one field performing under 90%, with comparable results\nobserved from the fine-tuned models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG",
      "I.2.7; H.3.3; H.3.4"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05048v1",
    "published_date": "2024-11-07 03:58:38 UTC",
    "updated_date": "2024-11-07 03:58:38 UTC"
  },
  {
    "arxiv_id": "2411.04403v1",
    "title": "Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers",
    "authors": [
      "Zhichao Geng",
      "Dongyu Ru",
      "Yang Yang"
    ],
    "abstract": "Learned sparse retrieval, which can efficiently perform retrieval through\nmature inverted-index engines, has garnered growing attention in recent years.\nParticularly, the inference-free sparse retrievers are attractive as they\neliminate online model inference in the retrieval phase thereby avoids huge\ncomputational cost, offering reasonable throughput and latency. However, even\nthe state-of-the-art (SOTA) inference-free sparse models lag far behind in\nterms of search relevance when compared to both sparse and dense siamese\nmodels. Towards competitive search relevance for inference-free sparse\nretrievers, we argue that they deserve dedicated training methods other than\nusing same ones with siamese encoders. In this paper, we propose two different\napproaches for performance improvement. First, we introduce the IDF-aware FLOPS\nloss, which introduces Inverted Document Frequency (IDF) to the sparsification\nof representations. We find that it mitigates the negative impact of the FLOPS\nregularization on search relevance, allowing the model to achieve a better\nbalance between accuracy and efficiency. Moreover, we propose a heterogeneous\nensemble knowledge distillation framework that combines siamese dense and\nsparse retrievers to generate supervisory signals during the pre-training\nphase. The ensemble framework of dense and sparse retriever capitalizes on\ntheir strengths respectively, providing a strong upper bound for knowledge\ndistillation. To concur the diverse feedback from heterogeneous supervisors, we\nnormalize and then aggregate the outputs of the teacher models to eliminate\nscore scale differences. On the BEIR benchmark, our model outperforms existing\nSOTA inference-free sparse model by \\textbf{3.3 NDCG@10 score}. It exhibits\nsearch relevance comparable to siamese sparse retrievers and client-side\nlatency only \\textbf{1.1x that of BM25}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04403v1",
    "published_date": "2024-11-07 03:46:43 UTC",
    "updated_date": "2024-11-07 03:46:43 UTC"
  },
  {
    "arxiv_id": "2411.04397v1",
    "title": "A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior",
    "authors": [
      "Yiwei Dong",
      "Shaoxin Ye",
      "Yuwen Cao",
      "Qiyu Han",
      "Hongteng Xu",
      "Hanfang Yang"
    ],
    "abstract": "Asynchronous event sequence clustering aims to group similar event sequences\nin an unsupervised manner. Mixture models of temporal point processes have been\nproposed to solve this problem, but they often suffer from overfitting, leading\nto excessive cluster generation with a lack of diversity. To overcome these\nlimitations, we propose a Bayesian mixture model of Temporal Point Processes\nwith Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an\nefficient posterior inference algorithm based on conditional Gibbs sampling.\nOur work provides a flexible learning framework for event sequence clustering,\nenabling automatic identification of the potential number of clusters and\naccurate grouping of sequences with similar features. It is applicable to a\nwide range of parametric temporal point processes, including neural\nnetwork-based models. Experimental results on both synthetic and real-world\ndata suggest that our framework could produce moderately fewer yet more diverse\nmixture components, and achieve outstanding results across multiple evaluation\nmetrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04397v1",
    "published_date": "2024-11-07 03:21:30 UTC",
    "updated_date": "2024-11-07 03:21:30 UTC"
  },
  {
    "arxiv_id": "2411.04393v1",
    "title": "Bridging the Gap: Representation Spaces in Neuro-Symbolic AI",
    "authors": [
      "Xin Zhang",
      "Victor S. Sheng"
    ],
    "abstract": "Neuro-symbolic AI is an effective method for improving the overall\nperformance of AI models by combining the advantages of neural networks and\nsymbolic learning. However, there are differences between the two in terms of\nhow they process data, primarily because they often use different data\nrepresentation methods, which is often an important factor limiting the overall\nperformance of the two. From this perspective, we analyzed 191 studies from\n2013 by constructing a four-level classification framework. The first level\ndefines five types of representation spaces, and the second level focuses on\nfive types of information modalities that the representation space can\nrepresent. Then, the third level describes four symbolic logic methods.\nFinally, the fourth-level categories propose three collaboration strategies\nbetween neural networks and symbolic learning. Furthermore, we conducted a\ndetailed analysis of 46 research based on their representation space.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04393v1",
    "published_date": "2024-11-07 03:10:44 UTC",
    "updated_date": "2024-11-07 03:10:44 UTC"
  },
  {
    "arxiv_id": "2411.04383v1",
    "title": "Neuro-Symbolic AI: Explainability, Challenges, and Future Trends",
    "authors": [
      "Xin Zhang",
      "Victor S. Sheng"
    ],
    "abstract": "Explainability is an essential reason limiting the application of neural\nnetworks in many vital fields. Although neuro-symbolic AI hopes to enhance the\noverall explainability by leveraging the transparency of symbolic learning, the\nresults are less evident than imagined. This article proposes a classification\nfor explainability by considering both model design and behavior of 191 studies\nfrom 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want\nto understand the explainability of neuro-symbolic AI. Precisely, we classify\nthem into five categories by considering whether the form of bridging the\nrepresentation differences is readable as their design factor, if there are\nrepresentation differences between neural networks and symbolic logic learning,\nand whether a model decision or prediction process is understandable as their\nbehavior factor: implicit intermediate representations and implicit prediction,\npartially explicit intermediate representations and partially explicit\nprediction, explicit intermediate representations or explicit prediction,\nexplicit intermediate representation and explicit prediction, unified\nrepresentation and explicit prediction. We also analyzed the research trends\nand three significant challenges: unified representations, explainability and\ntransparency, and sufficient cooperation from neural networks and symbolic\nlearning. Finally, we put forward suggestions for future research in three\naspects: unified representations, enhancing model explainability, ethical\nconsiderations, and social impact.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04383v1",
    "published_date": "2024-11-07 02:54:35 UTC",
    "updated_date": "2024-11-07 02:54:35 UTC"
  },
  {
    "arxiv_id": "2411.13560v1",
    "title": "AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG",
    "authors": [
      "Yichen Shi",
      "Zhuofu Tao",
      "Yuhao Gao",
      "Tianjia Zhou",
      "Cheng Chang",
      "Yaxing Wang",
      "Bingyu Chen",
      "Genhao Zhang",
      "Alvin Liu",
      "Zhiping Yu",
      "Ting-Jung Lin",
      "Lei He"
    ],
    "abstract": "High-performance analog and mixed-signal (AMS) circuits are mainly\nfull-custom designed, which is time-consuming and labor-intensive. A\nsignificant portion of the effort is experience-driven, which makes the\nautomation of AMS circuit design a formidable challenge. Large language models\n(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)\napplications, fostering advancements in the automatic design process for\nlarge-scale AMS circuits. However, the absence of high-quality datasets has led\nto issues such as model hallucination, which undermines the robustness of\nautomatically generated circuit designs. To address this issue, this paper\nintroduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and\nnetlists. We construct a knowledge graph with annotations on detailed\nfunctional and performance characteristics. Facilitated by AMSnet-KG, we\npropose an automated AMS circuit generation framework that utilizes the\ncomprehensive knowledge embedded in LLMs. We first formulate a design strategy\n(e.g., circuit architecture using a number of circuit components) based on\nrequired specifications. Next, matched circuit components are retrieved and\nassembled into a complete topology, and transistor sizing is obtained through\nBayesian optimization. Simulation results of the netlist are fed back to the\nLLM for further topology refinement, ensuring the circuit design specifications\nare met. We perform case studies of operational amplifier and comparator design\nto verify the automatic design flow from specifications to netlists with\nminimal human effort. The dataset used in this paper will be open-sourced upon\npublishing of this paper.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.ET",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13560v1",
    "published_date": "2024-11-07 02:49:53 UTC",
    "updated_date": "2024-11-07 02:49:53 UTC"
  },
  {
    "arxiv_id": "2411.05046v1",
    "title": "PhoneLM:an Efficient and Capable Small Language Model Family through Principled Pre-training",
    "authors": [
      "Rongjie Yi",
      "Xiang Li",
      "Weikai Xie",
      "Zhenyan Lu",
      "Chenghua Wang",
      "Ao Zhou",
      "Shangguang Wang",
      "Xiwen Zhang",
      "Mengwei Xu"
    ],
    "abstract": "The interest in developing small language models (SLM) for on-device\ndeployment is fast growing. However, the existing SLM design hardly considers\nthe device hardware characteristics. Instead, this work presents a simple yet\neffective principle for SLM design: architecture searching for (near-)optimal\nruntime efficiency before pre-training. Guided by this principle, we develop\nPhoneLM SLM family (currently with 0.5B and 1.5B versions), that acheive the\nstate-of-the-art capability-efficiency tradeoff among those with similar\nparameter size. We fully open-source the code, weights, and training datasets\nof PhoneLM for reproducibility and transparency, including both base and\ninstructed versions. We also release a finetuned version of PhoneLM capable of\naccurate Android Intent invocation, and an end-to-end Android demo. All\nmaterials are available at https://github.com/UbiquitousLearning/PhoneLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05046v1",
    "published_date": "2024-11-07 02:19:00 UTC",
    "updated_date": "2024-11-07 02:19:00 UTC"
  },
  {
    "arxiv_id": "2411.04372v1",
    "title": "Benchmarking Large Language Models with Integer Sequence Generation Tasks",
    "authors": [
      "Daniel O'Malley",
      "Manish Bhattarai",
      "Javier Santos"
    ],
    "abstract": "This paper presents a novel benchmark where the large language model (LLM)\nmust write code that computes integer sequences from the Online Encyclopedia of\nInteger Sequences (OEIS), a widely-used resource for mathematical sequences.\nThe benchmark is designed to evaluate both the correctness of the generated\ncode and its computational efficiency. Our benchmark reveals that the o1 series\nof models outperform other frontier models from OpenAI, Anthropic, Meta, and\nGoogle in accuracy and cheating rates across both easy and hard integer\nsequences. In order to ensure models do not exploit memorized sequence values,\nwe introduce an automated cheating detection mechanism that flags the use of\nlookup tables and validated this automation against human cheating evaluations.\nThis benchmark provides a meaningful challenge for current LLMs, offering\ninsights into their mathematical reasoning and code writing capabilities, which\ncan guide future research directions and model development in mathematical\nreasoning and code synthesis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04372v1",
    "published_date": "2024-11-07 02:05:43 UTC",
    "updated_date": "2024-11-07 02:05:43 UTC"
  },
  {
    "arxiv_id": "2411.04371v2",
    "title": "ComFairGNN: Community Fair Graph Neural Network",
    "authors": [
      "Yonas Sium",
      "Qi Li"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become the leading approach for addressing\ngraph analytical problems in various real-world scenarios. However, GNNs may\nproduce biased predictions against certain demographic subgroups due to node\nattributes and neighbors surrounding a node. Most current research on GNN\nfairness focuses predominantly on debiasing GNNs using oversimplified fairness\nevaluation metrics, which can give a misleading impression of fairness.\nUnderstanding the potential evaluation paradoxes due to the complicated nature\nof the graph structure is crucial for developing effective GNN debiasing\nmechanisms. In this paper, we examine the effectiveness of current GNN\ndebiasing methods in terms of unfairness evaluation. Specifically, we introduce\na community-level strategy to measure bias in GNNs and evaluate debiasing\nmethods at this level. Further, We introduce ComFairGNN, a novel framework\ndesigned to mitigate community-level bias in GNNs. Our approach employs a\nlearnable coreset-based debiasing function that addresses bias arising from\ndiverse local neighborhood distributions during GNNs neighborhood aggregation.\nComprehensive evaluations on three benchmark datasets demonstrate our model's\neffectiveness in both accuracy and fairness metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at PAKDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.04371v2",
    "published_date": "2024-11-07 02:04:34 UTC",
    "updated_date": "2025-04-01 21:14:17 UTC"
  },
  {
    "arxiv_id": "2411.05856v1",
    "title": "Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry",
    "authors": [
      "Soaad Hossain",
      "James Rasalingam",
      "Arhum Waheed",
      "Fatah Awil",
      "Rachel Kandiah",
      "Syed Ishtiaque Ahmed"
    ],
    "abstract": "With the growing interest in using AI and machine learning (ML) in medicine,\nthere is an increasing number of literature covering the application and ethics\nof using AI and ML in areas of medicine such as clinical psychiatry. The\nproblem is that there is little literature covering the economic aspects\nassociated with using ML in clinical psychiatry. This study addresses this gap\nby specifically studying the economic implications of using ML in clinical\npsychiatry. In this paper, we evaluate the economic implications of using ML in\nclinical psychiatry through using three problem-oriented case studies,\nliterature on economics, socioeconomic and medical AI, and two types of health\neconomic evaluations. In addition, we provide details on fairness, legal,\nethics and other considerations for ML in clinical psychiatry.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.LG",
      "68T01",
      "I.2; J.4; I.2.1; K.4.3"
    ],
    "primary_category": "cs.CY",
    "comment": "11 pages, submitted to Machine Learning for Health (ML4H) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.05856v1",
    "published_date": "2024-11-07 01:57:06 UTC",
    "updated_date": "2024-11-07 01:57:06 UTC"
  },
  {
    "arxiv_id": "2411.04356v1",
    "title": "GaGSL: Global-augmented Graph Structure Learning via Graph Information Bottleneck",
    "authors": [
      "Shuangjie Li",
      "Jiangqing Song",
      "Baoming Zhang",
      "Gaoli Ruan",
      "Junyuan Xie",
      "Chongjun Wang"
    ],
    "abstract": "Graph neural networks (GNNs) are prominent for their effectiveness in\nprocessing graph data for semi-supervised node classification tasks. Most works\nof GNNs assume that the observed structure accurately represents the underlying\nnode relationships. However, the graph structure is inevitably noisy or\nincomplete in reality, which can degrade the quality of graph representations.\nTherefore, it is imperative to learn a clean graph structure that balances\nperformance and robustness. In this paper, we propose a novel method named\n\\textit{Global-augmented Graph Structure Learning} (GaGSL), guided by the Graph\nInformation Bottleneck (GIB) principle. The key idea behind GaGSL is to learn a\ncompact and informative graph structure for node classification tasks.\nSpecifically, to mitigate the bias caused by relying solely on the original\nstructure, we first obtain augmented features and augmented structure through\nglobal feature augmentation and global structure augmentation. We then input\nthe augmented features and augmented structure into a structure estimator with\ndifferent parameters for optimization and re-definition of the graph structure,\nrespectively. The redefined structures are combined to form the final graph\nstructure. Finally, we employ GIB based on mutual information to guide the\noptimization of the graph structure to obtain the minimum sufficient graph\nstructure. Comprehensive evaluations across a range of datasets reveal the\noutstanding performance and robustness of GaGSL compared with the\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04356v1",
    "published_date": "2024-11-07 01:23:48 UTC",
    "updated_date": "2024-11-07 01:23:48 UTC"
  },
  {
    "arxiv_id": "2411.04337v1",
    "title": "Model and Deep learning based Dynamic Range Compression Inversion",
    "authors": [
      "Haoran Sun",
      "Dominique Fourer",
      "Hichem Maaref"
    ],
    "abstract": "Dynamic Range Compression (DRC) is a popular audio effect used to control the\ndynamic range of a signal. Inverting DRC can also help to restore the original\ndynamics to produce new mixes and/or to improve the overall quality of the\naudio signal. Since, state-of-the-art DRC inversion techniques either ignore\nparameters or require precise parameters that are difficult to estimate, we\nfill the gap by combining a model-based approach with neural networks for DRC\ninversion. To this end, depending on the scenario, we use different neural\nnetworks to estimate DRC parameters. Then, a model-based inversion is completed\nto restore the original audio signal. Our experimental results show the\neffectiveness and robustness of the proposed method in comparison to several\nstate-of-the-art methods, when applied on two music datasets.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04337v1",
    "published_date": "2024-11-07 00:33:07 UTC",
    "updated_date": "2024-11-07 00:33:07 UTC"
  },
  {
    "arxiv_id": "2411.05044v1",
    "title": "Deep Heuristic Learning for Real-Time Urban Pathfinding",
    "authors": [
      "Mohamed Hussein Abo El-Ela",
      "Ali Hamdi Fergany"
    ],
    "abstract": "This paper introduces a novel approach to urban pathfinding by transforming\ntraditional heuristic-based algorithms into deep learning models that leverage\nreal-time contextual data, such as traffic and weather conditions. We propose\ntwo methods: an enhanced A* algorithm that dynamically adjusts routes based on\ncurrent environmental conditions, and a neural network model that predicts the\nnext optimal path segment using historical and live data. An extensive\nbenchmark was conducted to compare the performance of different deep learning\nmodels, including MLP, GRU, LSTM, Autoencoders, and Transformers. Both methods\nwere evaluated in a simulated urban environment in Berlin, with the neural\nnetwork model outperforming traditional methods, reducing travel times by up to\n40%, while the enhanced A* algorithm achieved a 34% improvement. These results\ndemonstrate the potential of deep learning to optimize urban navigation in real\ntime, providing more adaptable and efficient routing solutions.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05044v1",
    "published_date": "2024-11-07 00:22:04 UTC",
    "updated_date": "2024-11-07 00:22:04 UTC"
  },
  {
    "arxiv_id": "2411.05043v1",
    "title": "Multi-language Video Subtitle Dataset for Image-based Text Recognition",
    "authors": [
      "Thanadol Singkhornart",
      "Olarik Surinta"
    ],
    "abstract": "The Multi-language Video Subtitle Dataset is a comprehensive collection\ndesigned to support research in text recognition across multiple languages.\nThis dataset includes 4,224 subtitle images extracted from 24 videos sourced\nfrom online platforms. It features a wide variety of characters, including Thai\nconsonants, vowels, tone marks, punctuation marks, numerals, Roman characters,\nand Arabic numerals. With 157 unique characters, the dataset provides a\nresource for addressing challenges in text recognition within complex\nbackgrounds. It addresses the growing need for high-quality, multilingual text\nrecognition data, particularly as videos with embedded subtitles become\nincreasingly dominant on platforms like YouTube and Facebook. The variability\nin text length, font, and placement within these images adds complexity,\noffering a valuable resource for developing and evaluating deep learning\nmodels. The dataset facilitates accurate text transcription from video content\nwhile providing a foundation for improving computational efficiency in text\nrecognition systems. As a result, it holds significant potential to drive\nadvancements in research and innovation across various computer science\ndisciplines, including artificial intelligence, deep learning, computer vision,\nand pattern recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.05043v1",
    "published_date": "2024-11-07 00:06:53 UTC",
    "updated_date": "2024-11-07 00:06:53 UTC"
  }
]