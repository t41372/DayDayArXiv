{
  "date": "2024-11-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-07 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文聚焦于 AI 模型优化、多代理系统、图像生成和强化学习等领域，亮点包括大型语言模型（LLMs）的长上下文能力提升（如 Abstract2Appendix）和数学推理基准（FrontierMath），以及 Sergey Levine 等学者的多篇贡献，这些工作突显了 AI 在实际应用中的潜力，如医疗和对话代理。\n\n下面，我将逐一简要概述今日的论文，先优先讨论重要、话题性和创新性强的文章（如涉及 LLMs、强化学习和多模态模型的），然后快速掠过其他次要内容。每个条目包括论文标题（中文 + 英文）、核心贡献和发现，保留关键学术术语。\n\n### LLMs 和代理系统相关论文（重点讨论）\n- **Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities**（英文原标题：Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities）  \n  这篇论文提出使用学术同行评审数据微调 LLMs，以提升其长上下文处理能力；主要贡献是通过 DPO 方法在 Qasper 基准上实现 4.04 分的性能提升，并强调高质量数据对 LLM 的信息检索和推理能力的积极影响。\n\n- **Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations**（英文原标题：Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations）  \n  Sergey Levine 参与的工作，使用后见式强化学习（hindsight reinforcement learning）训练对话代理；发现代理能更好地引导对话并说服人类，用户研究显示其在心理健康和慈善领域显著优于现有 SOTA 模型。\n\n- **Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning**（英文原标题：Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning）  \n  另一篇 Sergey Levine 合作论文，将 Q 学习转化为监督微调问题；贡献在于无缝整合预训练和强化学习，提升 LLMs 在多轮任务（如对话和机器人控制）的性能，同时保持高效。\n\n- **SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference**（英文原标题：SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference）  \n  提出基于后缀树的推测解码方法加速 LLMs 推理；主要发现是它在聊天和代码生成任务中比 SOTA 方法提高 1.4 倍输出吞吐量，同时减少延迟。\n\n- **StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration**（英文原标题：StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration）  \n  引入多代理框架生成定制化故事视频；关键贡献是模拟专业制作流程，确保角色一致性和视频质量，实验显示其优于现有方法。\n\n- **Kwai-STaR: Transform LLMs into State-Transition Reasoners**（英文原标题：Kwai-STaR: Transform LLMs into State-Transition Reasoners）  \n  将 LLMs 转化为状态转移推理器；发现通过状态空间学习，模型在数学推理任务中显著提升效率和准确性。\n\n- **FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI**（英文原标题：FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI）  \n  构建一个高级数学推理基准数据集；主要贡献是揭示当前 AI 模型在复杂数学任务上的巨大差距，强调未来模型需提升全球最优解能力。\n\n- **HourVideo: 1-Hour Video-Language Understanding**（英文原标题：HourVideo: 1-Hour Video-Language Understanding）  \n  发布一个长视频理解基准数据集；发现多模态模型在总结、感知和推理任务上远逊于人类，推动了视频语言模型的改进。\n\n- **GaGSL: Global-augmented Graph Structure Learning via Graph Information Bottleneck**（英文原标题：GaGSL: Global-augmented Graph Structure Learning via Graph Information Bottleneck）  \n  提出全局增强图结构学习框架；贡献在于通过信息瓶颈优化图表示，提升节点分类的鲁棒性和准确性。\n\n### 强化学习和优化相关论文（次重点）\n- **Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization**（英文原标题：Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization）  \n  优化直接偏好优化（DPO）框架；主要发现是迭代配对排名机制和预算控制正则化能提升 LLM 对齐性能。\n\n- **Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions**（英文原标题：Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions）  \n  使用深度强化学习（DRL）优化多无人机网络；贡献是提出 MA-CDQL 算法，提升用户连接性。\n\n- **Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method**（英文原标题：Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method）  \n  引入民主选举方法到可解释 AI；发现 DhondtXAI 在特征归因上优于 SHAP，提升了医疗预测的可解释性。\n\n- **Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning**（英文原标题：Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning）  \n  扩展概率逻辑屏蔽到多代理强化学习；主要贡献是 PLTD 更新和概率策略梯度方法，提高了代理的安全性和合作。\n\n### 图像和多模态处理相关论文（简要讨论）\n- **ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning**（英文原标题：ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning）  \n  生成视频从用户视频中创建新视角；发现 masked 视频微调能处理场景运动和角度变化。\n\n- **M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding**（英文原标题：M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding）  \n  提出多模态检索框架处理多页文档；贡献是提升文档视觉问答性能，实验在 M3DocVQA 上优于 SOTA。\n\n- **DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning**（英文原标题：DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning）  \n  使用预训练视觉特征构建世界模型；发现它在零样本规划中表现突出，适用于机器人任务。\n\n### 医疗和隐私相关论文（快速掠过）\n- **PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation**（英文原标题：PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation）  \n  发布双语胸部 X 光数据集；主要用于训练报告生成模型。\n  \n- **Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries**（英文原标题：Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries）  \n  使用 LLMs 分析二进制漏洞；发现微调后模型在漏洞检测上提升 19%。\n\n- **Interplay between Federated Learning and Explainable Artificial Intelligence: a Scoping Review**（英文原标题：Interplay between Federated Learning and Explainable Artificial Intelligence: a Scoping Review）  \n  综述联邦学习和可解释 AI 的互动；强调隐私保护和解释性的研究空白。\n\n其他论文，如纯理论优化（如 Clustering in Causal Attention Masking）和特定应用（如 ResLearn for Metaverse traffic prediction），虽有贡献但相对次要，这里仅提及其标题和核心点：它们分别探讨注意力机制聚类和元宇宙流量预测的改进。总体而言，今天的论文突出了 AI 模型的实用性和挑战，LLMs 和强化学习领域进展显著，值得关注。明日见！",
  "papers": [
    {
      "arxiv_id": "2411.05875v1",
      "title": "Towards Improved Preference Optimization Pipeline: from Data Generation to Budget-Controlled Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuotong Chen",
        "Fang Liu",
        "Jennifer Zhu",
        "Wanyu Du",
        "Yanjun Qi"
      ],
      "abstract": "Direct Preference Optimization (DPO) and its variants have become the de\nfacto standards for aligning large language models (LLMs) with human\npreferences or specific goals. However, DPO requires high-quality preference\ndata and suffers from unstable preference optimization. In this work, we aim to\nimprove the preference optimization pipeline by taking a closer look at\npreference data generation and training regularization techniques. For\npreference data generation, we demonstrate that existing scoring-based reward\nmodels produce unsatisfactory preference data and perform poorly on\nout-of-distribution tasks. This significantly impacts the LLM alignment\nperformance when using these data for preference tuning. To ensure high-quality\npreference data generation, we propose an iterative pairwise ranking mechanism\nthat derives preference ranking of completions using pairwise comparison\nsignals. For training regularization, we observe that preference optimization\ntends to achieve better convergence when the LLM predicted likelihood of\npreferred samples gets slightly reduced. However, the widely used supervised\nnext-word prediction regularization strictly prevents any likelihood reduction\nof preferred samples. This observation motivates our design of a\nbudget-controlled regularization formulation. Empirically we show that\ncombining the two designs leads to aligned models that surpass existing SOTA\nacross two popular benchmarks.",
      "tldr_zh": "这篇论文针对 Direct Preference Optimization (DPO) 的问题，提出改进偏好优化流程，包括数据生成和训练正则化方法，以提升大型语言模型 (LLMs) 与人类偏好的对齐效果。在数据生成方面，他们发现现有基于得分的奖励模型生成偏好数据质量低，尤其在分布外任务上表现不佳，因此引入了迭代配对排名机制，使用配对比较信号来确保高质量偏好数据的生成。对于训练正则化，他们观察到偏好优化在首选样本的 LLM 预测似然略微减少时收敛更好，并设计了预算控制正则化公式来优化这一过程。实验结果表明，该改进流程在两个流行基准上超越了现有最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.05875v1",
      "published_date": "2024-11-07 23:03:11 UTC",
      "updated_date": "2024-11-07 23:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:15:07.243912"
    },
    {
      "arxiv_id": "2411.05232v1",
      "title": "Abstract2Appendix: Academic Reviews Enhance LLM Long-Context Capabilities",
      "title_zh": "Abstract2Appendix：学术评论增强 LLM 长上下文能力",
      "authors": [
        "Shengzhi Li",
        "Kittipat Kampa",
        "Rongyu Lin",
        "Bohang Li",
        "Shichao Pei"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance across various\ntasks, yet their ability to handle long-context reading remains challenging.\nThis study explores the effectiveness of leveraging high-quality academic peer\nreview data for fine-tuning LLMs to enhance their long-context capabilities. We\ncompare the Direct Preference Optimization (DPO) method with the Supervised\nFine-Tuning (SFT) method, demonstrating DPO's superiority and data efficiency.\nOur experiments show that the fine-tuned model achieves a 4.04-point\nimprovement over phi-3 and a 2.6\\% increase on the Qasper benchmark using only\n2000 samples. Despite facing limitations in data scale and processing costs,\nthis study underscores the potential of DPO and high-quality data in advancing\nLLM performance.\n  Additionally, the zero-shot benchmark results indicate that aggregated\nhigh-quality human reviews are overwhelmingly preferred over LLM-generated\nresponses, even for the most capable models like GPT-4o. This suggests that\nhigh-quality human reviews are extremely rich in information, reasoning, and\nlong-context retrieval, capabilities that even the most advanced models have\nnot fully captured. These findings highlight the high utility of leveraging\nhuman reviews to further advance the field.",
      "tldr_zh": "本研究探讨利用高质量学术同行评审数据微调大型语言模型 (LLMs)，以提升其处理长上下文的能力，通过比较 Direct Preference Optimization (DPO) 和 Supervised Fine-Tuning (SFT) 方法，发现 DPO 更具优势和数据效率，仅用 2000 个样本即使模型在 Qasper 基准上比 phi-3 提升 4.04 分。实验结果还表明，零样本测试中，聚合的人类评审内容远优于 LLM 生成响应，甚至超过 GPT-4o，这突显了人类评审在信息、推理和长上下文检索方面的丰富价值。尽管面临数据规模和处理成本的限制，该研究强调了 DPO 和高质量数据在推进 LLM 性能方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "We share our latest dataset on\n  https://github.com/findalexli/Abstract2Appendix",
      "pdf_url": "http://arxiv.org/pdf/2411.05232v1",
      "published_date": "2024-11-07 22:57:02 UTC",
      "updated_date": "2024-11-07 22:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:15:20.299727"
    },
    {
      "arxiv_id": "2411.05874v2",
      "title": "Interplay between Federated Learning and Explainable Artificial Intelligence: a Scoping Review",
      "title_zh": "联邦学习与可解释人工智能之间的相互作用：一项范围综述",
      "authors": [
        "Luis M. Lopez-Ramos",
        "Florian Leiser",
        "Aditya Rastogi",
        "Steven Hicks",
        "Inga Strümke",
        "Vince I. Madai",
        "Tobias Budig",
        "Ali Sunyaev",
        "Adam Hilbert"
      ],
      "abstract": "The joint implementation of federated learning (FL) and explainable\nartificial intelligence (XAI) could allow training models from distributed data\nand explaining their inner workings while preserving essential aspects of\nprivacy. Toward establishing the benefits and tensions associated with their\ninterplay, this scoping review maps the publications that jointly deal with FL\nand XAI, focusing on publications that reported an interplay between FL and\nmodel interpretability or post-hoc explanations. Out of the 37 studies meeting\nour criteria, only one explicitly and quantitatively analyzed the influence of\nFL on model explanations, revealing a significant research gap. The aggregation\nof interpretability metrics across FL nodes created generalized global insights\nat the expense of node-specific patterns being diluted. Several studies\nproposed FL algorithms incorporating explanation methods to safeguard the\nlearning process against defaulting or malicious nodes. Studies using\nestablished FL libraries or following reporting guidelines are a minority. More\nquantitative research and structured, transparent practices are needed to fully\nunderstand their mutual impact and under which conditions it happens.",
      "tldr_zh": "这篇综述探讨了Federated Learning (FL)与Explainable Artificial Intelligence (XAI)的互动，旨在评估它们在分布式数据训练和模型解释方面的益处，同时保护隐私。研究者对37篇相关文献进行了scoping review，焦点在于FL对模型可解释性或后验解释的影响，结果显示仅有1篇研究明确量化分析了FL对解释的影响，并揭示了显著的研究空白。发现FL中聚合可解释性指标能生成泛化的全局洞见，但会稀释节点特定模式，而一些研究则提出了将解释方法整合到FL算法中，以防范默认或恶意节点。综述强调，需要更多定量研究和结构化的报告实践来全面理解它们之间的相互影响及其条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 10 figures, submitted in IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2411.05874v2",
      "published_date": "2024-11-07 22:44:35 UTC",
      "updated_date": "2025-04-10 10:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:15:32.150438"
    },
    {
      "arxiv_id": "2411.05209v1",
      "title": "Alopex: A Computational Framework for Enabling On-Device Function Calls with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yide Ran",
        "Zhaozhuo Xu",
        "Yuhang Yao",
        "Zijian Hu",
        "Shanshan Han",
        "Han Jin",
        "Alay Dilipbhai Shah",
        "Jipeng Zhang",
        "Dimitris Stripelis",
        "Tong Zhang",
        "Salman Avestimehr",
        "Chaoyang He"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has led to their\nincreased integration into mobile devices for personalized assistance, which\nenables LLMs to call external API functions to enhance their performance.\nHowever, challenges such as data scarcity, ineffective question formatting, and\ncatastrophic forgetting hinder the development of on-device LLM agents. To\ntackle these issues, we propose Alopex, a framework that enables precise\non-device function calls using the Fox LLM. Alopex introduces a logic-based\nmethod for generating high-quality training data and a novel\n``description-question-output'' format for fine-tuning, reducing risks of\nfunction information leakage. Additionally, a data mixing strategy is used to\nmitigate catastrophic forgetting, combining function call data with textbook\ndatasets to enhance performance in various tasks. Experimental results show\nthat Alopex improves function call accuracy and significantly reduces\ncatastrophic forgetting, providing a robust solution for integrating function\ncall capabilities into LLMs without manual intervention.",
      "tldr_zh": "该研究提出Alopex框架，利用Fox LLM实现设备端函数调用，以解决Large Language Models (LLMs)集成外部API时面临的数据稀缺、无效问题格式和catastrophic forgetting等问题。Alopex引入基于逻辑的方法生成高质量训练数据，并采用“description-question-output”格式进行微调，以减少函数信息泄露风险；同时，通过数据混合策略将函数调用数据与教科书数据集结合，缓解灾难性遗忘。实验结果显示，Alopex显著提高了函数调用准确性，并提供了一种无需手动干预的稳健解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05209v1",
      "published_date": "2024-11-07 22:15:17 UTC",
      "updated_date": "2024-11-07 22:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:15:42.073764"
    },
    {
      "arxiv_id": "2411.05205v1",
      "title": "Maximizing User Connectivity in AI-Enabled Multi-UAV Networks: A Distributed Strategy Generalized to Arbitrary User Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Bowei Li",
        "Yang Xu",
        "Ran Zhang",
        "Jiang",
        "Xie",
        "Miao Wang"
      ],
      "abstract": "Deep reinforcement learning (DRL) has been extensively applied to\nMulti-Unmanned Aerial Vehicle (UAV) network (MUN) to effectively enable\nreal-time adaptation to complex, time-varying environments. Nevertheless, most\nof the existing works assume a stationary user distribution (UD) or a dynamic\none with predicted patterns. Such considerations may make the UD-specific\nstrategies insufficient when a MUN is deployed in unknown environments. To this\nend, this paper investigates distributed user connectivity maximization problem\nin a MUN with generalization to arbitrary UDs. Specifically, the problem is\nfirst formulated into a time-coupled combinatorial nonlinear non-convex\noptimization with arbitrary underlying UDs. To make the optimization tractable,\na multi-agent CNN-enhanced deep Q learning (MA-CDQL) algorithm is proposed. The\nalgorithm integrates a ResNet-based CNN to the policy network to analyze the\ninput UD in real time and obtain optimal decisions based on the extracted\nhigh-level UD features. To improve the learning efficiency and avoid local\noptimums, a heatmap algorithm is developed to transform the raw UD to a\ncontinuous density map. The map will be part of the true input to the policy\nnetwork. Simulations are conducted to demonstrate the efficacy of UD heatmaps\nand the proposed algorithm in maximizing user connectivity as compared to\nK-means methods.",
      "tldr_zh": "本文研究了在 AI 启用多无人机网络 (Multi-UAV Networks) 中最大化用户连接的问题，提出了一种分布式策略，能够泛化到任意用户分布 (UD)。他们将问题表述为时间耦合的组合非线性非凸优化，并开发了 MA-CDQL 算法，该算法整合 ResNet-based CNN 来实时分析 UD 的高级特征，并使用 heatmap 算法将原始 UD 转换为连续密度图，以提升学习效率并避免局部最优。实验结果表明，该方法在最大化用户连接方面比 K-means 方法更有效，证明了其在未知环境下的适用性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.NI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05205v1",
      "published_date": "2024-11-07 22:10:54 UTC",
      "updated_date": "2024-11-07 22:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:15:55.508829"
    },
    {
      "arxiv_id": "2411.05196v2",
      "title": "Explainable AI through a Democratic Lens: DhondtXAI for Proportional Feature Importance Using the D'Hondt Method",
      "title_zh": "翻译失败",
      "authors": [
        "Turker Berk Donmez"
      ],
      "abstract": "In democratic societies, electoral systems play a crucial role in translating\npublic preferences into political representation. Among these, the D'Hondt\nmethod is widely used to ensure proportional representation, balancing fair\nrepresentation with governmental stability. Recently, there has been a growing\ninterest in applying similar principles of proportional representation to\nenhance interpretability in machine learning, specifically in Explainable AI\n(XAI). This study investigates the integration of D'Hondt-based voting\nprinciples in the DhondtXAI method, which leverages resource allocation\nconcepts to interpret feature importance within AI models. Through a comparison\nof SHAP (Shapley Additive Explanations) and DhondtXAI, we evaluate their\neffectiveness in feature attribution within CatBoost and XGBoost models for\nbreast cancer and diabetes prediction, respectively. The DhondtXAI approach\nallows for alliance formation and thresholding to enhance interpretability,\nrepresenting feature importance as seats in a parliamentary view. Statistical\ncorrelation analyses between SHAP values and DhondtXAI allocations support the\nconsistency of interpretations, demonstrating DhondtXAI's potential as a\ncomplementary tool for understanding feature importance in AI models. The\nresults highlight that integrating electoral principles, such as proportional\nrepresentation and alliances, into AI explainability can improve user\nunderstanding, especially in high-stakes fields like healthcare.",
      "tldr_zh": "本研究将民主选举中的 D'Hondt 方法应用于 Explainable AI (XAI)，提出 DhondtXAI 方法，通过资源分配概念实现特征重要性的比例表示，从而提升 AI 模型的可解释性。\nDhondtXAI 允许联盟形成和阈值设置，将特征重要性可视化为议会席位，并与 SHAP 方法进行比较，在 CatBoost 和 XGBoost 模型上测试乳腺癌和糖尿病预测任务。\n结果显示，DhondtXAI 的解释结果与 SHAP 值具有统计相关性，能够改善用户理解，尤其适用于医疗等高风险领域。",
      "categories": [
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05196v2",
      "published_date": "2024-11-07 21:43:29 UTC",
      "updated_date": "2024-11-13 18:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:16:07.395846"
    },
    {
      "arxiv_id": "2411.05194v1",
      "title": "Interactive Dialogue Agents via Reinforcement Learning on Hindsight Regenerations",
      "title_zh": "翻译失败",
      "authors": [
        "Joey Hong",
        "Jessica Lin",
        "Anca Dragan",
        "Sergey Levine"
      ],
      "abstract": "Recent progress on large language models (LLMs) has enabled dialogue agents\nto generate highly naturalistic and plausible text. However, current LLM\nlanguage generation focuses on responding accurately to questions and requests\nwith a single effective response. In reality, many real dialogues are\ninteractive, meaning an agent's utterances will influence their conversational\npartner, elicit information, or change their opinion. Accounting for how an\nagent can effectively steer a conversation is a crucial ability in many\ndialogue tasks, from healthcare to preference elicitation. Existing methods for\nfine-tuning dialogue agents to accomplish such tasks would rely on curating\nsome amount of expert data. However, doing so often requires understanding the\nunderlying cognitive processes of the conversational partner, which is a skill\nneither humans nor LLMs trained on human data can reliably do. Our key insight\nis that while LLMs may not be adept at identifying effective strategies for\nsteering conversations a priori, or in the middle of an ongoing conversation,\nthey can do so post-hoc, or in hindsight, after seeing how their conversational\npartner responds. We use this fact to rewrite and augment existing suboptimal\ndata, and train via offline reinforcement learning (RL) an agent that\noutperforms both prompting and learning from unaltered human demonstrations. We\napply our approach to two domains that require understanding human mental\nstate, intelligent interaction, and persuasion: mental health support, and\nsoliciting charitable donations. Our results in a user study with real humans\nshow that our approach greatly outperforms existing state-of-the-art dialogue\nagents.",
      "tldr_zh": "该研究提出了一种基于后见之明再生 (Hindsight Regenerations) 的强化学习 (Reinforcement Learning) 方法，用于训练交互式对话代理，以提升其在对话中影响伙伴、获取信息和改变意见的能力。关键洞见是大型语言模型 (LLMs) 虽无法实时识别有效策略，但能事后重写和增强 suboptimal 数据，从而通过离线强化学习训练代理，超越基于人类演示的学习方法。该方法应用于心理健康支持和慈善捐赠领域，用户研究显示，该代理在理解人类心理状态、交互和说服方面大大优于现有最先进对话代理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05194v1",
      "published_date": "2024-11-07 21:37:51 UTC",
      "updated_date": "2024-11-07 21:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:16:18.316284"
    },
    {
      "arxiv_id": "2411.05193v2",
      "title": "Q-SFT: Q-Learning for Language Models via Supervised Fine-Tuning",
      "title_zh": "Q",
      "authors": [
        "Joey Hong",
        "Anca Dragan",
        "Sergey Levine"
      ],
      "abstract": "Value-based reinforcement learning (RL) can in principle learn effective\npolicies for a wide range of multi-turn problems, from games to dialogue to\nrobotic control, including via offline RL from static previously collected\ndatasets. However, despite the widespread use of policy gradient methods to\ntrain large language models for single turn tasks (e.g., question answering),\nvalue-based methods for multi-turn RL in an off-policy or offline setting have\nproven particularly challenging to scale to the setting of large language\nmodels. This setting requires effectively leveraging pretraining, scaling to\nlarge architectures with billions of parameters, and training on large\ndatasets, all of which represent major challenges for current value-based RL\nmethods. In this work, we propose a novel offline RL algorithm that addresses\nthese drawbacks, casting Q-learning as a modified supervised fine-tuning (SFT)\nproblem where the probabilities of tokens directly translate to Q-values. In\nthis way we obtain an algorithm that smoothly transitions from maximizing the\nlikelihood of the data during pretraining to learning a near-optimal Q-function\nduring finetuning. Our algorithm has strong theoretical foundations, enjoying\nperformance bounds similar to state-of-the-art Q-learning methods, while in\npractice utilizing an objective that closely resembles SFT. Because of this,\nour approach can enjoy the full benefits of the pretraining of language models,\nwithout the need to reinitialize any weights before RL finetuning, and without\nthe need to initialize new heads for predicting values or advantages.\nEmpirically, we evaluate our method on both pretrained LLMs and VLMs, on a\nvariety of tasks including both natural language dialogue and robotic\nmanipulation and navigation from images.",
      "tldr_zh": "本研究提出了一种名为 Q-SFT 的离线强化学习 (RL) 算法，将 Q-Learning 转化为一个修改后的监督微调 (SFT) 问题，通过 token 概率直接映射到 Q 值，从而解决价值-based RL 在大型语言模型 (LLMs) 上的挑战，如扩展到亿参数级架构和利用预训练数据。相比传统方法，Q-SFT 能平滑过渡从数据似然最大化（预训练阶段）到学习近优 Q 函数（微调阶段），无需重新初始化权重或添加新头。实验结果显示，该算法在预训练的 LLMs 和视觉语言模型 (VLMs) 上表现良好，适用于自然语言对话、机器人操作和导航任务，提供更高效的 RL 训练框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05193v2",
      "published_date": "2024-11-07 21:36:52 UTC",
      "updated_date": "2024-11-27 00:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:16:31.140696"
    },
    {
      "arxiv_id": "2411.05192v1",
      "title": "Explaining Mixtures of Sources in News Articles",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Spangher",
        "James Youn",
        "Matt DeButts",
        "Nanyun Peng",
        "Emilio Ferrara",
        "Jonathan May"
      ],
      "abstract": "Human writers plan, then write. For large language models (LLMs) to play a\nrole in longer-form article generation, we must understand the planning steps\nhumans make before writing. We explore one kind of planning, source-selection\nin news, as a case-study for evaluating plans in long-form generation. We ask:\nwhy do specific stories call for specific kinds of sources? We imagine a\ngenerative process for story writing where a source-selection schema is first\nselected by a journalist, and then sources are chosen based on categories in\nthat schema. Learning the article's plan means predicting the schema initially\nchosen by the journalist. Working with professional journalists, we adapt five\nexisting schemata and introduce three new ones to describe journalistic plans\nfor the inclusion of sources in documents. Then, inspired by Bayesian\nlatent-variable modeling, we develop metrics to select the most likely plan, or\nschema, underlying a story, which we use to compare schemata. We find that two\nschemata: stance and social affiliation best explain source plans in most\ndocuments. However, other schemata like textual entailment explain source plans\nin factually rich topics like \"Science\". Finally, we find we can predict the\nmost suitable schema given just the article's headline with reasonable\naccuracy. We see this as an important case-study for human planning, and\nprovides a framework and approach for evaluating other kinds of plans. We\nrelease a corpora, NewsSources, with annotations for 4M articles.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在长篇文章生成中的规划问题，以新闻来源选择为例，分析人类作家（如记者）在写作前如何选择来源。研究者适应了五个现有schemata并引入三个新ones，使用Bayesian latent-variable modeling的启发开发指标来预测文章背后的来源选择模式，结果显示stance和social affiliation schemata在大多数文档中解释力最强，而textual entailment schema更适合事实密集主题如“Science”。此外，通过仅使用文章标题即可合理准确预测最合适schema，该工作提供了评估人类规划的框架，并发布了包含400万文章注解的NewsSources语料库。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.05192v1",
      "published_date": "2024-11-07 21:34:05 UTC",
      "updated_date": "2024-11-07 21:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:16:43.258844"
    },
    {
      "arxiv_id": "2411.11894v1",
      "title": "ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction",
      "title_zh": "ResLearn：基于Transformer的残差学习用于元宇宙网络流量预测",
      "authors": [
        "Yoga Suhas Kuruba Manjunath",
        "Mathew Szymanowski",
        "Austin Wissborn",
        "Mushu Li",
        "Lian Zhao",
        "Xiao-Ping Zhang"
      ],
      "abstract": "Our work proposes a comprehensive solution for predicting Metaverse network\ntraffic, addressing the growing demand for intelligent resource management in\neXtended Reality (XR) services. We first introduce a state-of-the-art testbed\ncapturing a real-world dataset of virtual reality (VR), augmented reality (AR),\nand mixed reality (MR) traffic, made openly available for further research. To\nenhance prediction accuracy, we then propose a novel view-frame (VF) algorithm\nthat accurately identifies video frames from traffic while ensuring privacy\ncompliance, and we develop a Transformer-based progressive error-learning\nalgorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn\nsignificantly improves time-series predictions by using fully connected neural\nnetworks to reduce errors, particularly during peak traffic, outperforming\nprior work by 99%. Our contributions offer Internet service providers (ISPs)\nrobust tools for real-time network management to satisfy Quality of Service\n(QoS) and enhance user experience in the Metaverse.",
      "tldr_zh": "本研究提出ResLearn，一种基于Transformer的残差学习算法，用于预测Metaverse网络流量，以满足eXtended Reality (XR)服务对智能资源管理的需求。研究首先构建了一个先进的测试平台，捕获并公开了真实世界的VR、AR和MR流量数据集，并开发了view-frame (VF)算法来准确识别视频帧，同时确保隐私合规。ResLearn通过使用全连接神经网络逐步减少预测错误，尤其在高峰流量期间，比现有方法提高了99%的准确率。该框架为互联网服务提供商 (ISPs) 提供了强大的工具，支持实时网络管理，提升Quality of Service (QoS)和用户体验。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11894v1",
      "published_date": "2024-11-07 21:11:24 UTC",
      "updated_date": "2024-11-07 21:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:16:54.918728"
    },
    {
      "arxiv_id": "2411.05184v1",
      "title": "Discern-XR: An Online Classifier for Metaverse Network Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Yoga Suhas Kuruba Manjunath",
        "Austin Wissborn",
        "Mathew Szymanowski",
        "Mushu Li",
        "Lian Zhao",
        "Xiao-Ping Zhang"
      ],
      "abstract": "In this paper, we design an exclusive Metaverse network traffic classifier,\nnamed Discern-XR, to help Internet service providers (ISP) and router\nmanufacturers enhance the quality of Metaverse services. Leveraging segmented\nlearning, the Frame Vector Representation (FVR) algorithm and Frame\nIdentification Algorithm (FIA) are proposed to extract critical frame-related\nstatistics from raw network data having only four application-level features. A\nnovel Augmentation, Aggregation, and Retention Online Training (A2R-OT)\nalgorithm is proposed to find an accurate classification model through online\ntraining methodology. In addition, we contribute to the real-world Metaverse\ndataset comprising virtual reality (VR) games, VR video, VR chat, augmented\nreality (AR), and mixed reality (MR) traffic, providing a comprehensive\nbenchmark. Discern-XR outperforms state-of-the-art classifiers by 7% while\nimproving training efficiency and reducing false-negative rates. Our work\nadvances Metaverse network traffic classification by standing as the\nstate-of-the-art solution.",
      "tldr_zh": "本研究设计了 Discern-XR，一种专为 Metaverse 网络流量分类的在线分类器，帮助 ISP 和路由器制造商提升服务质量。通过 segmented learning，该分类器引入了 Frame Vector Representation (FVR) 算法和 Frame Identification Algorithm (FIA)，从仅含四个应用级特征的原始数据中提取关键帧统计；同时，提出 Augmentation, Aggregation, and Retention Online Training (A2R-OT) 算法，实现高效在线训练。研究还贡献了一个真实 Metaverse 数据集，包括 VR 游戏、VR 视频、VR 聊天、AR 和 MR 流量，作为基准测试。Discern-XR 比现有最先进分类器提升 7% 的准确率，同时提高了训练效率并降低了假阴性率，推动了 Metaverse 网络流量分类领域的进展。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05184v1",
      "published_date": "2024-11-07 21:07:49 UTC",
      "updated_date": "2024-11-07 21:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:17:07.748014"
    },
    {
      "arxiv_id": "2411.05174v1",
      "title": "Inverse Transition Learning: Learning Dynamics from Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Benac",
        "Abhishek Sharma",
        "Sonali Parbhoo",
        "Finale Doshi-Velez"
      ],
      "abstract": "We consider the problem of estimating the transition dynamics $T^*$ from\nnear-optimal expert trajectories in the context of offline model-based\nreinforcement learning. We develop a novel constraint-based method, Inverse\nTransition Learning, that treats the limited coverage of the expert\ntrajectories as a \\emph{feature}: we use the fact that the expert is\nnear-optimal to inform our estimate of $T^*$. We integrate our constraints into\na Bayesian approach. Across both synthetic environments and real healthcare\nscenarios like Intensive Care Unit (ICU) patient management in hypotension, we\ndemonstrate not only significant improvements in decision-making, but that our\nposterior can inform when transfer will be successful.",
      "tldr_zh": "该论文提出了一种名为 Inverse Transition Learning 的新方法，用于从近优专家轨迹中估计过渡动态 $T^*$，以解决离线模型-based 强化学习中的问题。该方法将专家轨迹的有限覆盖视为优势，通过约束-based 技术利用专家的近优性来指导 $T^*$ 的估计，并将其整合到 Bayesian 框架中。在合成环境和真实医疗场景（如 ICU 患者管理中的低血压）中，实验结果显示该方法显著提升了决策质量，且其后验分布能够预测转移成功的可能性。总的来说，这为改进强化学习在实际应用中的鲁棒性提供了重要贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05174v1",
      "published_date": "2024-11-07 20:27:29 UTC",
      "updated_date": "2024-11-07 20:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:17:18.342844"
    },
    {
      "arxiv_id": "2411.05085v1",
      "title": "PadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel C. Castro",
        "Aurelia Bustos",
        "Shruthi Bannur",
        "Stephanie L. Hyland",
        "Kenza Bouzid",
        "Maria Teodora Wetscherek",
        "Maria Dolores Sánchez-Valverde",
        "Lara Jaques-Pérez",
        "Lourdes Pérez-Rodríguez",
        "Kenji Takeda",
        "José María Salinas",
        "Javier Alvarez-Valle",
        "Joaquín Galant Herrero",
        "Antonio Pertusa"
      ],
      "abstract": "Radiology report generation (RRG) aims to create free-text radiology reports\nfrom clinical imaging. Grounded radiology report generation (GRRG) extends RRG\nby including the localisation of individual findings on the image. Currently,\nthere are no manually annotated chest X-ray (CXR) datasets to train GRRG\nmodels. In this work, we present a dataset called PadChest-GR\n(Grounded-Reporting) derived from PadChest aimed at training GRRG models for\nCXR images. We curate a public bi-lingual dataset of 4,555 CXR studies with\ngrounded reports (3,099 abnormal and 1,456 normal), each containing complete\nlists of sentences describing individual present (positive) and absent\n(negative) findings in English and Spanish. In total, PadChest-GR contains\n7,037 positive and 3,422 negative finding sentences. Every positive finding\nsentence is associated with up to two independent sets of bounding boxes\nlabelled by different readers and has categorical labels for finding type,\nlocations, and progression. To the best of our knowledge, PadChest-GR is the\nfirst manually curated dataset designed to train GRRG models for understanding\nand interpreting radiological images and generated text. By including detailed\nlocalization and comprehensive annotations of all clinically relevant findings,\nit provides a valuable resource for developing and evaluating GRRG models from\nCXR images. PadChest-GR can be downloaded under request from\nhttps://bimcv.cipf.es/bimcv-projects/padchest-gr/",
      "tldr_zh": "本文介绍了PadChest-GR数据集，这是一个双语（英语和西班牙语）的胸部X-ray (CXR) 数据集，专门设计用于训练Grounded Radiology Report Generation (GRRG) 模型，以实现放射报告的生成和发现定位。数据集包含4,555个CXR研究（其中3,099个异常和1,456个正常），包括7,037个positive发现句子和3,422个negative发现句子，每条positive句子均配有最多两个独立的bounding boxes标签，以及发现类型、位置和进展的分类标注。作为首个手动注释的GRRG数据集，PadChest-GR为开发和评估放射图像理解模型提供了宝贵资源，可从指定链接公开下载。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05085v1",
      "published_date": "2024-11-07 19:06:17 UTC",
      "updated_date": "2024-11-07 19:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:17:31.443252"
    },
    {
      "arxiv_id": "2411.05003v1",
      "title": "ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "David Junhao Zhang",
        "Roni Paiss",
        "Shiran Zada",
        "Nikhil Karnad",
        "David E. Jacobs",
        "Yael Pritch",
        "Inbar Mosseri",
        "Mike Zheng Shou",
        "Neal Wadhwa",
        "Nataniel Ruiz"
      ],
      "abstract": "Recently, breakthroughs in video modeling have allowed for controllable\ncamera trajectories in generated videos. However, these methods cannot be\ndirectly applied to user-provided videos that are not generated by a video\nmodel. In this paper, we present ReCapture, a method for generating new videos\nwith novel camera trajectories from a single user-provided video. Our method\nallows us to re-generate the reference video, with all its existing scene\nmotion, from vastly different angles and with cinematic camera motion. Notably,\nusing our method we can also plausibly hallucinate parts of the scene that were\nnot observable in the reference video. Our method works by (1) generating a\nnoisy anchor video with a new camera trajectory using multiview diffusion\nmodels or depth-based point cloud rendering and then (2) regenerating the\nanchor video into a clean and temporally consistent reangled video using our\nproposed masked video fine-tuning technique.",
      "tldr_zh": "这篇论文提出了 ReCapture 方法，用于从用户提供的视频生成具有新相机轨迹的视频，解决了现有技术无法直接应用于非生成视频的问题。方法包括：(1) 使用 multiview diffusion models 或基于深度的 point cloud rendering 生成一个带有新轨迹的噪声锚视频；(2) 通过 masked video fine-tuning 技术，将锚视频再生为干净、一致的重新角度视频，同时保留原场景运动。ReCapture 不仅能从不同角度和电影式运动重新生成视频，还能合理地 hallucinate 未观察到的场景部分，提升视频生成的可控性和真实性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://generative-video-camera-controls.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.05003v1",
      "published_date": "2024-11-07 18:59:45 UTC",
      "updated_date": "2024-11-07 18:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:17:43.206311"
    },
    {
      "arxiv_id": "2411.05001v1",
      "title": "Analyzing The Language of Visual Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "David M. Chan",
        "Rodolfo Corona",
        "Joonyong Park",
        "Cheol Jun Cho",
        "Yutong Bai",
        "Trevor Darrell"
      ],
      "abstract": "With the introduction of transformer-based models for vision and language\ntasks, such as LLaVA and Chameleon, there has been renewed interest in the\ndiscrete tokenized representation of images. These models often treat image\npatches as discrete tokens, analogous to words in natural language, learning\njoint alignments between visual and human languages. However, little is known\nabout the statistical behavior of these visual languages - whether they follow\nsimilar frequency distributions, grammatical structures, or topologies as\nnatural languages. In this paper, we take a natural-language-centric approach\nto analyzing discrete visual languages and uncover striking similarities and\nfundamental differences. We demonstrate that, although visual languages adhere\nto Zipfian distributions, higher token innovation drives greater entropy and\nlower compression, with tokens predominantly representing object parts,\nindicating intermediate granularity. We also show that visual languages lack\ncohesive grammatical structures, leading to higher perplexity and weaker\nhierarchical organization compared to natural languages. Finally, we\ndemonstrate that, while vision models align more closely with natural languages\nthan other models, this alignment remains significantly weaker than the\ncohesion found within natural languages. Through these experiments, we\ndemonstrate how understanding the statistical properties of discrete visual\nlanguages can inform the design of more effective computer vision models.",
      "tldr_zh": "这篇论文分析了视觉token的语言特性，将图像补丁视为类似于自然语言中的单词，并通过自然语言中心的方法比较其统计行为。研究发现，视觉语言遵循Zipfian distributions，但由于更高的token创新，导致更大的entropy和更低的compression，且token主要代表物体部分，显示中等粒度。相比之下，视觉语言缺乏cohesive grammatical structures，表现出更高的perplexity和更弱的hierarchical organization，尽管视觉模型与自然语言的alignment较其他模型更紧密。最终，这些发现有助于指导更有效computer vision models的设计。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05001v1",
      "published_date": "2024-11-07 18:59:28 UTC",
      "updated_date": "2024-11-07 18:59:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:17:55.626975"
    },
    {
      "arxiv_id": "2411.04998v1",
      "title": "HourVideo: 1-Hour Video-Language Understanding",
      "title_zh": "HourVideo：1小时视频-语言理解",
      "authors": [
        "Keshigeyan Chandrasegaran",
        "Agrim Gupta",
        "Lea M. Hadzic",
        "Taran Kota",
        "Jimming He",
        "Cristóbal Eyzaguirre",
        "Zane Durante",
        "Manling Li",
        "Jiajun Wu",
        "Li Fei-Fei"
      ],
      "abstract": "We present HourVideo, a benchmark dataset for hour-long video-language\nunderstanding. Our dataset consists of a novel task suite comprising\nsummarization, perception (recall, tracking), visual reasoning (spatial,\ntemporal, predictive, causal, counterfactual), and navigation (room-to-room,\nobject retrieval) tasks. HourVideo includes 500 manually curated egocentric\nvideos from the Ego4D dataset, spanning durations of 20 to 120 minutes, and\nfeatures 12,976 high-quality, five-way multiple-choice questions. Benchmarking\nresults reveal that multimodal models, including GPT-4 and LLaVA-NeXT, achieve\nmarginal improvements over random chance. In stark contrast, human experts\nsignificantly outperform the state-of-the-art long-context multimodal model,\nGemini Pro 1.5 (85.0% vs. 37.3%), highlighting a substantial gap in multimodal\ncapabilities. Our benchmark, evaluation toolkit, prompts, and documentation are\navailable at https://hourvideo.stanford.edu",
      "tldr_zh": "本研究引入了 HourVideo，这是一个针对小时级视频-语言理解的基准数据集，包含总结、感知（recall、tracking）、视觉推理（spatial、temporal、predictive、causal、counterfactual）和导航（room-to-room、object retrieval）等任务。数据集基于 Ego4D 抽取了 500 个手动策划的 egocentric 视频，每段时长 20 到 120 分钟，并附有 12,976 个高质量五选一多项选择题。基准测试显示，多模态模型如 GPT-4 和 LLaVA-NeXT 仅略高于随机猜测，而人类专家远超最先进模型 Gemini Pro 1.5（85.0% vs. 37.3%），突显了当前模型在长视频理解方面的显著不足。该数据集及其评估工具已公开在 https://hourvideo.stanford.edu。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Datasets and Benchmarks Track; 28 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.04998v1",
      "published_date": "2024-11-07 18:59:16 UTC",
      "updated_date": "2024-11-07 18:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:18:07.649224"
    },
    {
      "arxiv_id": "2411.04994v3",
      "title": "Legacy Procurement Practices Shape How U.S. Cities Govern AI: Understanding Government Employees' Practices, Challenges, and Needs",
      "title_zh": "翻译失败",
      "authors": [
        "Nari Johnson",
        "Elise Silva",
        "Harrison Leon",
        "Motahhare Eslami",
        "Beth Schwanke",
        "Ravit Dotan",
        "Hoda Heidari"
      ],
      "abstract": "Most AI tools adopted by governments are not developed internally, but\ninstead are acquired from third-party vendors in a process called public\nprocurement. In this paper, we conduct the first empirical study of how United\nStates cities' procurement practices shape critical decisions surrounding\npublic sector AI. We conduct semi-structured interviews with 19 city employees\nwho oversee AI procurement across 7 U.S. cities. We found that cities' legacy\nprocurement practices, which are shaped by decades-old laws and norms,\nestablish infrastructure that determines which AI is purchased, and which\nactors hold decision-making power over procured AI. We characterize the\nemerging actions cities have taken to adapt their purchasing practices to\naddress algorithmic harms. From employees' reflections on real-world AI\nprocurements, we identify three key challenges that motivate but are not fully\naddressed by existing AI procurement reform initiatives. Based on these\nfindings, we discuss implications and opportunities for the FAccT community to\nsupport cities in foreseeing and preventing AI harms throughout the public\nprocurement processes.",
      "tldr_zh": "这篇论文通过对7个美国城市的19名政府员工进行半结构化访谈（semi-structured interviews），首次实证研究了传统采购实践（legacy procurement practices）如何塑造美国城市对AI的治理决策。研究发现，这些由旧法律和规范影响的实践决定了哪些AI被采购以及决策权归属，同时城市正采取新兴行动来应对算法伤害（algorithmic harms）。论文识别出三个关键挑战，并为FAccT社区提供启示，以支持城市在公共采购过程中预见和预防AI风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 2 column format. In proceedings of ACM FAccT 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.04994v3",
      "published_date": "2024-11-07 18:58:16 UTC",
      "updated_date": "2025-05-13 01:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:18:19.051099"
    },
    {
      "arxiv_id": "2411.04991v2",
      "title": "Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives",
      "title_zh": "重新思考基于偏好的奖励建模中的 Bradley-Terry 模型：基础、理论和备选方案",
      "authors": [
        "Hao Sun",
        "Yunyi Shen",
        "Jean-Francois Ton"
      ],
      "abstract": "The Bradley-Terry (BT) model is a common and successful practice in reward\nmodeling for Large Language Model (LLM) alignment. However, it remains unclear\nwhy this model -- originally developed for multi-player stochastic game\nmatching -- can be adopted to convert pairwise response comparisons to reward\nvalues and make predictions. Especially given the fact that only a limited\nnumber of prompt-response pairs are sparsely compared with others. In this\npaper, we first revisit the foundations of using BT models in reward modeling,\nand establish the convergence rate of BT reward models based on deep neural\nnetworks using embeddings, providing a theoretical foundation for their use.\nDespite theoretically sound, we argue that the BT model is not a necessary\nchoice from the perspective of downstream optimization. This is because a\nreward model only needs to preserve the correct ranking predictions through a\nmonotonic transformation of the true reward. We highlight the critical concept\nof order consistency in reward modeling and demonstrate that the BT model\npossesses this property. Consequently, we propose a simple and straightforward\nupper-bound algorithm, compatible with off-the-shelf binary classifiers, as an\nalternative order-consistent reward modeling objective. To offer practical\ninsights, we empirically evaluate the performance of these different reward\nmodeling approaches across more than 12,000 experimental setups, using $6$ base\nLLMs, $2$ datasets, and diverse annotation designs that vary in quantity,\nquality, and pairing choices in preference annotations.",
      "tldr_zh": "本论文重新审视了 Bradley-Terry (BT) 模型在基于偏好的奖励建模中的应用，探讨了其在 Large Language Model (LLM) 校准中将成对响应比较转换为奖励值的原因，并建立了 BT 模型基于深度神经网络的收敛率理论，提供理论基础。论文强调，BT 模型虽具有 order consistency 属性（即保持正确排名预测），但并非下游优化的必要选择，而是可以通过单调变换实现，因此提出了一种简单上界算法，使用现成的二元分类器作为替代的 order-consistent 奖励建模目标。实验结果显示，通过超过12,000个设置（包括6个基础LLM、2个数据集和各种偏好标注设计），这些方法在性能上表现出可行性，为更灵活的奖励建模提供了实用见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04991v2",
      "published_date": "2024-11-07 18:57:03 UTC",
      "updated_date": "2025-01-26 00:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:18:32.755926"
    },
    {
      "arxiv_id": "2411.04990v2",
      "title": "Clustering in Causal Attention Masking",
      "title_zh": "因果注意力掩码中的聚类",
      "authors": [
        "Nikita Karagodin",
        "Yury Polyanskiy",
        "Philippe Rigollet"
      ],
      "abstract": "This work presents a modification of the self-attention dynamics proposed by\nGeshkovski et al. (arXiv:2312.10794) to better reflect the practically\nrelevant, causally masked attention used in transformer architectures for\ngenerative AI. This modification translates into an interacting particle system\nthat cannot be interpreted as a mean-field gradient flow. Despite this loss of\nstructure, we significantly strengthen the results of Geshkovski et al.\n(arXiv:2312.10794) in this context: While previous rigorous results focused on\ncases where all three matrices (Key, Query, and Value) were scaled identities,\nwe prove asymptotic convergence to a single cluster for arbitrary key-query\nmatrices and a value matrix equal to the identity. Additionally, we establish a\nconnection to the classical R\\'enyi parking problem from combinatorial geometry\nto make initial theoretical steps towards demonstrating the existence of\nmeta-stable states.",
      "tldr_zh": "这篇论文修改了Geshkovski et al. (arXiv:2312.10794)提出的自注意力(self-attention)动态，以更好地适应transformer架构中用于生成AI的因果掩码(causal attention)机制，将其转化为一个互动粒子系统(interacting particle system)，尽管无法解释为均值场梯度流(mean-field gradient flow)。研究证明，在任意Key-Query矩阵和Value矩阵为身份矩阵(identity)的条件下，该系统会渐进收敛到单个簇。论文还建立了与经典Rényi停车问题的连接，作为向证明元稳定状态(meta-stable states)存在的初步理论步骤。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "math.DS",
        "68T07, 35Q68, 37N99, 82C22"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024), 22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04990v2",
      "published_date": "2024-11-07 18:56:37 UTC",
      "updated_date": "2024-11-10 17:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:18:43.513727"
    },
    {
      "arxiv_id": "2411.04987v2",
      "title": "Few-Shot Task Learning through Inverse Generative Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Aviv Netanyahu",
        "Yilun Du",
        "Antonia Bronars",
        "Jyothish Pari",
        "Joshua Tenenbaum",
        "Tianmin Shu",
        "Pulkit Agrawal"
      ],
      "abstract": "Learning the intents of an agent, defined by its goals or motion style, is\noften extremely challenging from just a few examples. We refer to this problem\nas task concept learning and present our approach, Few-Shot Task Learning\nthrough Inverse Generative Modeling (FTL-IGM), which learns new task concepts\nby leveraging invertible neural generative models. The core idea is to pretrain\na generative model on a set of basic concepts and their demonstrations. Then,\ngiven a few demonstrations of a new concept (such as a new goal or a new\naction), our method learns the underlying concepts through backpropagation\nwithout updating the model weights, thanks to the invertibility of the\ngenerative model. We evaluate our method in five domains -- object\nrearrangement, goal-oriented navigation, motion caption of human actions,\nautonomous driving, and real-world table-top manipulation. Our experimental\nresults demonstrate that via the pretrained generative model, we successfully\nlearn novel concepts and generate agent plans or motion corresponding to these\nconcepts in (1) unseen environments and (2) in composition with training\nconcepts.",
      "tldr_zh": "本研究提出了一种名为 FTL-IGM（Few-Shot Task Learning through Inverse Generative Modeling）的少样本任务学习方法，用于从少量示例中学习代理的意图（如目标或动作风格）。该方法通过在基本概念和演示上预训练可逆神经生成模型，然后利用反向传播在不更新模型权重的情况下，从新概念的少量演示中推断底层概念。实验在五个领域（包括物体重新排列、目标导向导航、人类动作运动描述、自动驾驶和真实世界桌面操作）中进行，结果显示，FTL-IGM 能成功学习新概念，并在未见环境以及与训练概念的组合中生成相应的代理计划或动作，从而提升了任务概念学习的泛化能力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Added acknowledgment",
      "pdf_url": "http://arxiv.org/pdf/2411.04987v2",
      "published_date": "2024-11-07 18:55:10 UTC",
      "updated_date": "2025-01-13 18:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:18:55.324717"
    },
    {
      "arxiv_id": "2411.04983v2",
      "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
      "title_zh": "DINO-WM：基于预训练视觉特征的世界模型实现零样本规划",
      "authors": [
        "Gaoyue Zhou",
        "Hengkai Pan",
        "Yann LeCun",
        "Lerrel Pinto"
      ],
      "abstract": "The ability to predict future outcomes given control actions is fundamental\nfor physical reasoning. However, such predictive models, often called world\nmodels, remains challenging to learn and are typically developed for\ntask-specific solutions with online policy learning. To unlock world models'\ntrue potential, we argue that they should 1) be trainable on offline,\npre-collected trajectories, 2) support test-time behavior optimization, and 3)\nfacilitate task-agnostic reasoning. To this end, we present DINO World Model\n(DINO-WM), a new method to model visual dynamics without reconstructing the\nvisual world. DINO-WM leverages spatial patch features pre-trained with DINOv2,\nenabling it to learn from offline behavioral trajectories by predicting future\npatch features. This allows DINO-WM to achieve observational goals through\naction sequence optimization, facilitating task-agnostic planning by treating\ngoal features as prediction targets. We demonstrate that DINO-WM achieves\nzero-shot behavioral solutions at test time on six environments without expert\ndemonstrations, reward modeling, or pre-learned inverse models, outperforming\nprior state-of-the-art work across diverse task families such as arbitrarily\nconfigured mazes, push manipulation with varied object shapes, and\nmulti-particle scenarios.",
      "tldr_zh": "该论文提出 DINO-WM 方法，利用预训练的 DINOv2 视觉特征构建世界模型（world models），实现零样本规划（zero-shot planning），无需重建视觉世界，而是通过预测未来 patch features 从离线轨迹中学习。DINO-WM 支持任务无关的推理和测试时的行为优化，允许通过优化动作序列来实现观察目标。实验结果显示，在六个环境中，包括复杂迷宫、物体推动和多粒子场景，DINO-WM 超越了现有最先进的方法，无需专家演示、奖励模型或预学习的逆模型。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04983v2",
      "published_date": "2024-11-07 18:54:37 UTC",
      "updated_date": "2025-02-01 02:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:19:07.076717"
    },
    {
      "arxiv_id": "2411.04981v1",
      "title": "Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Manuel",
        "Nafis Tanveer Islam",
        "Joseph Khoury",
        "Ana Nunez",
        "Elias Bou-Harb",
        "Peyman Najafirad"
      ],
      "abstract": "Security experts reverse engineer (decompile) binary code to identify\ncritical security vulnerabilities. The limited access to source code in vital\nsystems - such as firmware, drivers, and proprietary software used in Critical\nInfrastructures (CI) - makes this analysis even more crucial on the binary\nlevel. Even with available source code, a semantic gap persists after\ncompilation between the source and the binary code executed by the processor.\nThis gap may hinder the detection of vulnerabilities in source code. That being\nsaid, current research on Large Language Models (LLMs) overlooks the\nsignificance of decompiled binaries in this area by focusing solely on source\ncode. In this work, we are the first to empirically uncover the substantial\nsemantic limitations of state-of-the-art LLMs when it comes to analyzing\nvulnerabilities in decompiled binaries, largely due to the absence of relevant\ndatasets. To bridge the gap, we introduce DeBinVul, a novel decompiled binary\ncode vulnerability dataset. Our dataset is multi-architecture and\nmulti-optimization, focusing on C/C++ due to their wide usage in CI and\nassociation with numerous vulnerabilities. Specifically, we curate 150,872\nsamples of vulnerable and non-vulnerable decompiled binary code for the task of\n(i) identifying; (ii) classifying; (iii) describing vulnerabilities; and (iv)\nrecovering function names in the domain of decompiled binaries. Subsequently,\nwe fine-tune state-of-the-art LLMs using DeBinVul and report on a performance\nincrease of 19%, 24%, and 21% in the capabilities of CodeLlama, Llama3, and\nCodeGen2 respectively, in detecting binary code vulnerabilities. Additionally,\nusing DeBinVul, we report a high performance of 80-90% on the vulnerability\nclassification task. Furthermore, we report improved performance in function\nname recovery and vulnerability description tasks.",
      "tldr_zh": "本文研究了Large Language Models (LLMs)在反编译二进制代码漏洞分析中的局限性，强调了其在安全领域的重要性，尤其是针对源代码不可用的关键基础设施。研究者引入了DeBinVul数据集，这是一个多架构、多优化的C/C++反编译二进制代码漏洞数据集，包含15万多样本，用于识别、分类、描述漏洞及恢复函数名称。实验结果显示，通过微调LLMs（如CodeLlama、Llama3和CodeGen2），漏洞检测性能分别提高了19%、24%和21%，漏洞分类任务的性能达到80-90%。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04981v1",
      "published_date": "2024-11-07 18:54:31 UTC",
      "updated_date": "2024-11-07 18:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:19:19.220387"
    },
    {
      "arxiv_id": "2411.04975v1",
      "title": "SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Oliaro",
        "Zhihao Jia",
        "Daniel Campos",
        "Aurick Qiao"
      ],
      "abstract": "We present SuffixDecoding, a novel model-free approach to accelerating large\nlanguage model (LLM) inference through speculative decoding. Unlike existing\nmethods that rely on draft models or specialized decoding heads, SuffixDecoding\nleverages suffix trees built from previously generated outputs to efficiently\npredict candidate token sequences. Our approach enables flexible\ntree-structured speculation without the overhead of maintaining and\norchestrating additional models. SuffixDecoding builds and dynamically updates\nsuffix trees to capture patterns in the generated text, using them to construct\nspeculation trees through a principled scoring mechanism based on empirical\ntoken frequencies. SuffixDecoding requires only CPU memory which is plentiful\nand underutilized on typical LLM serving nodes. We demonstrate that\nSuffixDecoding achieves competitive speedups compared to model-based approaches\nacross diverse workloads including open-domain chat, code generation, and\ntext-to-SQL tasks. For open-ended chat and code generation tasks,\nSuffixDecoding achieves up to $1.4\\times$ higher output throughput than\nSpecInfer and up to $1.1\\times$ lower time-per-token (TPOT) latency. For a\nproprietary multi-LLM text-to-SQL application, SuffixDecoding achieves up to\n$2.9\\times$ higher output throughput and $3\\times$ lower latency than\nspeculative decoding. Our evaluation shows that SuffixDecoding maintains high\nacceptance rates even with small reference corpora of 256 examples, while\ncontinuing to improve performance as more historical outputs are incorporated.",
      "tldr_zh": "本研究提出 SuffixDecoding，一种无模型的方法，通过推测性解码(speculative decoding)加速大型语言模型(LLM)推理过程。它利用从先前生成的输出构建的后缀树(suffix trees)，并通过基于经验标记频率的评分机制动态更新这些树，以高效预测候选标记序列，从而避免了维护额外模型的开销。实验结果显示，在开放域聊天、代码生成和文本到 SQL 任务中，SuffixDecoding 比 SpecInfer 等方法提高了高达 1.4 倍的输出吞吐量，并降低了 3 倍的延迟；即使使用小型参考语料（256 个示例），它也能保持高接受率，并随着历史输出增加而持续提升性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04975v1",
      "published_date": "2024-11-07 18:49:33 UTC",
      "updated_date": "2024-11-07 18:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:19:31.627802"
    },
    {
      "arxiv_id": "2411.04962v1",
      "title": "Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjun Gao",
        "Skatje Myers",
        "Shan Chen",
        "Dmitriy Dligach",
        "Timothy A Miller",
        "Danielle Bitterman",
        "Guanhua Chen",
        "Anoop Mayampurath",
        "Matthew Churpek",
        "Majid Afshar"
      ],
      "abstract": "Large language models (LLMs) are being explored for diagnostic decision\nsupport, yet their ability to estimate pre-test probabilities, vital for\nclinical decision-making, remains limited. This study evaluates two LLMs,\nMistral-7B and Llama3-70B, using structured electronic health record data on\nthree diagnosis tasks. We examined three current methods of extracting LLM\nprobability estimations and revealed their limitations. We aim to highlight the\nneed for improved techniques in LLM confidence estimation.",
      "tldr_zh": "这篇position paper 探讨了Large Language Models (LLMs) 在诊断决策支持中的不确定性估计问题，强调next-word probability 无法等同于临床决策中至关重要的pre-test probability。研究评估了Mistral-7B 和 Llama3-70B 两个模型，使用结构化的电子健康记录数据在三个诊断任务上进行测试，并检查了三种当前提取LLM概率估计的方法。结果揭示了这些方法的局限性，并呼吁开发更先进的LLM信心估计技术，以提升其在医疗应用中的可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to GenAI4Health Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04962v1",
      "published_date": "2024-11-07 18:39:04 UTC",
      "updated_date": "2024-11-07 18:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:19:43.195112"
    },
    {
      "arxiv_id": "2411.04956v2",
      "title": "Uncovering Hidden Subspaces in Video Diffusion Models Using Re-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Mischa Dombrowski",
        "Hadrien Reynaud",
        "Bernhard Kainz"
      ],
      "abstract": "Latent Video Diffusion Models can easily deceive casual observers and domain\nexperts alike thanks to the produced image quality and temporal consistency.\nBeyond entertainment, this creates opportunities around safe data sharing of\nfully synthetic datasets, which are crucial in healthcare, as well as other\ndomains relying on sensitive personal information. However, privacy concerns\nwith this approach have not fully been addressed yet, and models trained on\nsynthetic data for specific downstream tasks still perform worse than those\ntrained on real data. This discrepancy may be partly due to the sampling space\nbeing a subspace of the training videos, effectively reducing the training data\nsize for downstream models. Additionally, the reduced temporal consistency when\ngenerating long videos could be a contributing factor.\n  In this paper, we first show that training privacy-preserving models in\nlatent space is computationally more efficient and generalize better.\nFurthermore, to investigate downstream degradation factors, we propose to use a\nre-identification model, previously employed as a privacy preservation filter.\nWe demonstrate that it is sufficient to train this model on the latent space of\nthe video generator. Subsequently, we use these models to evaluate the subspace\ncovered by synthetic video datasets and thus introduce a new way to measure the\nfaithfulness of generative machine learning models. We focus on a specific\napplication in healthcare echocardiography to illustrate the effectiveness of\nour novel methods. Our findings indicate that only up to 30.8% of the training\nvideos are learned in latent video diffusion models, which could explain the\nlack of performance when training downstream tasks on synthetic data.",
      "tldr_zh": "该研究揭示了潜在视频扩散模型（Latent Video Diffusion Models）在生成高质量视频时的隐私风险，并探讨了使用合成数据训练下游任务时性能不如真实数据的潜在原因。作者提出在潜在空间中训练再识别模型（Re-Identification model），这不仅更高效且泛化更好，还能评估合成视频数据集覆盖的子空间。论文引入一种新方法来衡量生成模型的忠实度，并以医疗领域的超声心动图（echocardiography）为例，发现这些模型仅学习了最多30.8%的训练视频，这解释了下游任务性能下降的关键因素。总的来说，此方法为隐私保护和模型评估提供了实用框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 tables, 6 figures; v2 Acknowledgements added",
      "pdf_url": "http://arxiv.org/pdf/2411.04956v2",
      "published_date": "2024-11-07 18:32:00 UTC",
      "updated_date": "2024-12-12 10:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:19:55.027878"
    },
    {
      "arxiv_id": "2411.04952v1",
      "title": "M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jaemin Cho",
        "Debanjan Mahata",
        "Ozan Irsoy",
        "Yujie He",
        "Mohit Bansal"
      ],
      "abstract": "Document visual question answering (DocVQA) pipelines that answer questions\nfrom documents have broad applications. Existing methods focus on handling\nsingle-page documents with multi-modal language models (MLMs), or rely on\ntext-based retrieval-augmented generation (RAG) that uses text extraction tools\nsuch as optical character recognition (OCR). However, there are difficulties in\napplying these methods in real-world scenarios: (a) questions often require\ninformation across different pages or documents, where MLMs cannot handle many\nlong documents; (b) documents often have important information in visual\nelements such as figures, but text extraction tools ignore them. We introduce\nM3DocRAG, a novel multi-modal RAG framework that flexibly accommodates various\ndocument contexts (closed-domain and open-domain), question hops (single-hop\nand multi-hop), and evidence modalities (text, chart, figure, etc.). M3DocRAG\nfinds relevant documents and answers questions using a multi-modal retriever\nand an MLM, so that it can efficiently handle single or many documents while\npreserving visual information. Since previous DocVQA datasets ask questions in\nthe context of a specific document, we also present M3DocVQA, a new benchmark\nfor evaluating open-domain DocVQA over 3,000+ PDF documents with 40,000+ pages.\nIn three benchmarks (M3DocVQA/MMLongBench-Doc/MP-DocVQA), empirical results\nshow that M3DocRAG with ColPali and Qwen2-VL 7B achieves superior performance\nthan many strong baselines, including state-of-the-art performance in\nMP-DocVQA. We provide comprehensive analyses of different indexing, MLMs, and\nretrieval models. Lastly, we qualitatively show that M3DocRAG can successfully\nhandle various scenarios, such as when relevant information exists across\nmultiple pages and when answer evidence only exists in images.",
      "tldr_zh": "该论文提出 M3DocRAG，一种新型多模态检索增强生成（RAG）框架，用于文档视觉问答（DocVQA），能够灵活处理多页多文档场景，包括跨页或跨文档问题以及视觉元素如图表和图形。M3DocRAG 通过多模态检索器和多模态语言模型（MLMs）结合，解决了现有方法的局限性，如文本提取工具（OCR）的忽略视觉信息问题，并在封闭域和开放域、单跳和多跳问题中表现出色。论文还引入了新基准 M3DocVQA，涵盖 3000+ PDF 文档和 40000+ 页，并在 M3DocVQA、MMLongBench-Doc 和 MP-DocVQA 等基准上超越基线模型，包括在 MP-DocVQA 上达到 state-of-the-art 性能。综合分析显示，该框架在不同索引、MLMs 和检索模型下均有效处理复杂场景，如跨页信息和图像证据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://m3docrag.github.io",
      "pdf_url": "http://arxiv.org/pdf/2411.04952v1",
      "published_date": "2024-11-07 18:29:38 UTC",
      "updated_date": "2024-11-07 18:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:20:08.589137"
    },
    {
      "arxiv_id": "2411.04946v1",
      "title": "SPGD: Steepest Perturbed Gradient Descent Optimization",
      "title_zh": "SPGD：最陡扰动梯度下降优化",
      "authors": [
        "Amir M. Vahedi",
        "Horea T. Ilies"
      ],
      "abstract": "Optimization algorithms are pivotal in advancing various scientific and\nindustrial fields but often encounter obstacles such as trapping in local\nminima, saddle points, and plateaus (flat regions), which makes the convergence\nto reasonable or near-optimal solutions particularly challenging. This paper\npresents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that\ninnovatively combines the principles of the gradient descent method with\nperiodic uniform perturbation sampling to effectively circumvent these\nimpediments and lead to better solutions whenever possible. SPGD is\ndistinctively designed to generate a set of candidate solutions and select the\none exhibiting the steepest loss difference relative to the current solution.\nIt enhances the traditional gradient descent approach by integrating a\nstrategic exploration mechanism that significantly increases the likelihood of\nescaping sub-optimal local minima and navigating complex optimization\nlandscapes effectively. Our approach not only retains the directed efficiency\nof gradient descent but also leverages the exploratory benefits of stochastic\nperturbations, thus enabling a more comprehensive search for global optima\nacross diverse problem spaces. We demonstrate the efficacy of SPGD in solving\nthe 3D component packing problem, an NP-hard challenge. Preliminary results\nshow a substantial improvement over four established methods, particularly on\nresponse surfaces with complex topographies and in multidimensional non-convex\ncontinuous optimization problems. Comparative analyses with established 2D\nbenchmark functions highlight SPGD's superior performance, showcasing its\nability to navigate complex optimization landscapes. These results emphasize\nSPGD's potential as a versatile tool for a wide range of optimization problems.",
      "tldr_zh": "这篇论文提出了SPGD（Steepest Perturbed Gradient Descent）算法，一种创新的优化方法，将梯度下降与周期性均匀扰动采样相结合，以有效避开局部最小值、鞍点和平坦区域等挑战。SPGD通过生成一组候选解决方案并选择损失差异最大的那个，增强了探索机制，同时保留梯度下降的定向效率，从而在复杂优化景观中实现更全面的全局最优搜索。在3D组件打包问题（一个NP-hard挑战）上的实验显示，SPGD比四种现有方法表现出色，尤其在多维非凸连续优化问题中取得了显著改善，突显其作为多功能优化工具的潜力。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "math-ph",
        "math.MP"
      ],
      "primary_category": "math.OC",
      "comment": "28 pages, 26 figures, submitted to Journal of Mechanical Design",
      "pdf_url": "http://arxiv.org/pdf/2411.04946v1",
      "published_date": "2024-11-07 18:23:30 UTC",
      "updated_date": "2024-11-07 18:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:20:19.283872"
    },
    {
      "arxiv_id": "2411.05059v2",
      "title": "FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge into LLMs?",
      "title_zh": "FineTuneBench：商业微调 API 向大语言模型注入知识的效果如何？",
      "authors": [
        "Eric Wu",
        "Kevin Wu",
        "James Zou"
      ],
      "abstract": "There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.",
      "tldr_zh": "本研究引入 FineTuneBench，这是一个评估框架和数据集，用于测试商业微调 API（如 OpenAI 和 Google 的）是否能有效将新知识注入 LLMs。研究评估了五个前沿模型，包括 GPT-4o 和 Gemini 1.5 Pro，在两种场景下：摄取新信息（如最近新闻事件）和更新现有知识（如医疗指南更新）。结果显示，所有模型在新信息学习时的平均泛化准确率仅为37%，在更新知识时更低至19%，其中 GPT-4o mini 表现最佳，其次是 GPT-3.5 Turbo 和 GPT-4o，而 Gemini 1.5 Flash 和 Gemini 1.5 Pro 完全无法学习新知识。这些发现揭示了当前商业微调服务的重大局限性，并开源了 FineTuneBench 数据集以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05059v2",
      "published_date": "2024-11-07 18:22:14 UTC",
      "updated_date": "2024-11-11 21:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:20:32.623028"
    },
    {
      "arxiv_id": "2411.04928v1",
      "title": "DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiang Sun",
        "Shuo Chen",
        "Fangfu Liu",
        "Zilong Chen",
        "Yueqi Duan",
        "Jun Zhang",
        "Yikai Wang"
      ],
      "abstract": "In this paper, we introduce \\textbf{DimensionX}, a framework designed to\ngenerate photorealistic 3D and 4D scenes from just a single image with video\ndiffusion. Our approach begins with the insight that both the spatial structure\nof a 3D scene and the temporal evolution of a 4D scene can be effectively\nrepresented through sequences of video frames. While recent video diffusion\nmodels have shown remarkable success in producing vivid visuals, they face\nlimitations in directly recovering 3D/4D scenes due to limited spatial and\ntemporal controllability during generation. To overcome this, we propose\nST-Director, which decouples spatial and temporal factors in video diffusion by\nlearning dimension-aware LoRAs from dimension-variant data. This controllable\nvideo diffusion approach enables precise manipulation of spatial structure and\ntemporal dynamics, allowing us to reconstruct both 3D and 4D representations\nfrom sequential frames with the combination of spatial and temporal dimensions.\nAdditionally, to bridge the gap between generated videos and real-world scenes,\nwe introduce a trajectory-aware mechanism for 3D generation and an\nidentity-preserving denoising strategy for 4D generation. Extensive experiments\non various real-world and synthetic datasets demonstrate that DimensionX\nachieves superior results in controllable video generation, as well as in 3D\nand 4D scene generation, compared with previous methods.",
      "tldr_zh": "这篇论文介绍了 DimensionX 框架，它能从单张图像生成逼真的 3D 和 4D 场景，通过可控视频扩散技术来处理空间结构和时间动态。核心方法是 ST-Director，通过从维度变异数据中学习维度感知的 LoRAs，将视频扩散中的空间和时间因素分离，实现精确操控和重建。框架还引入了轨迹感知机制用于 3D 生成，以及身份保留去噪策略用于 4D 生成，并在各种真实和合成数据集上的实验中，DimensionX 在可控视频生成和场景重建方面显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://chenshuo20.github.io/DimensionX/",
      "pdf_url": "http://arxiv.org/pdf/2411.04928v1",
      "published_date": "2024-11-07 18:07:31 UTC",
      "updated_date": "2024-11-07 18:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:20:43.718858"
    },
    {
      "arxiv_id": "2411.04925v2",
      "title": "StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Panwen Hu",
        "Jin Jiang",
        "Jianqi Chen",
        "Mingfei Han",
        "Shengcai Liao",
        "Xiaojun Chang",
        "Xiaodan Liang"
      ],
      "abstract": "The advent of AI-Generated Content (AIGC) has spurred research into automated\nvideo generation to streamline conventional processes. However, automating\nstorytelling video production, particularly for customized narratives, remains\nchallenging due to the complexity of maintaining subject consistency across\nshots. While existing approaches like Mora and AesopAgent integrate multiple\nagents for Story-to-Video (S2V) generation, they fall short in preserving\nprotagonist consistency and supporting Customized Storytelling Video Generation\n(CSVG). To address these limitations, we propose StoryAgent, a multi-agent\nframework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks\nassigned to specialized agents, mirroring the professional production process.\nNotably, our framework includes agents for story design, storyboard generation,\nvideo creation, agent coordination, and result evaluation. Leveraging the\nstrengths of different models, StoryAgent enhances control over the generation\nprocess, significantly improving character consistency. Specifically, we\nintroduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance\nintra-shot temporal consistency, while a novel storyboard generation pipeline\nis proposed to maintain subject consistency across shots. Extensive experiments\ndemonstrate the effectiveness of our approach in synthesizing highly consistent\nstorytelling videos, outperforming state-of-the-art methods. Our contributions\ninclude the introduction of StoryAgent, a versatile framework for video\ngeneration tasks, and novel techniques for preserving protagonist consistency.",
      "tldr_zh": "该研究提出StoryAgent，一种基于多智能体协作的框架，用于实现Customized Storytelling Video Generation (CSVG)，以解决现有方法在保持主角一致性方面的不足。StoryAgent将CSVG分解为故事设计、故事板生成、视频创建、代理协调和结果评估等子任务，并引入LoRA-BE方法提升镜头内时间一致性，以及一个新颖的故事板生成管道来维护镜头间主题一致性。实验结果表明，StoryAgent在合成高度一致的叙事视频方面优于现有技术，其主要贡献包括提供一个通用的视频生成框架和创新性一致性保持技巧。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04925v2",
      "published_date": "2024-11-07 18:00:33 UTC",
      "updated_date": "2024-11-11 13:24:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:20:54.732785"
    },
    {
      "arxiv_id": "2411.04920v3",
      "title": "GPTKB: Comprehensively Materializing Factual LLM Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Yujia Hu",
        "Tuan-Phong Nguyen",
        "Shrestha Ghosh",
        "Simon Razniewski"
      ],
      "abstract": "LLMs have majorly advanced NLP and AI, and next to their ability to perform a\nwide range of procedural tasks, a major success factor is their internalized\nfactual knowledge. Since (Petroni et al., 2019), analyzing this knowledge has\ngained attention. However, most approaches investigate one question at a time\nvia modest-sized pre-defined samples, introducing an availability bias (Tversky\nand Kahnemann, 1973) that prevents the discovery of knowledge (or beliefs) of\nLLMs beyond the experimenter's predisposition.\n  To address this challenge, we propose a novel methodology to comprehensively\nmaterializing an LLM's factual knowledge through recursive querying and result\nconsolidation.\n  As a prototype, we employ GPT-4o-mini to construct GPTKB, a large-scale\nknowledge base (KB) comprising 105 million triples for over 2.9 million\nentities - achieved at 1% of the cost of previous KB projects. This work marks\na milestone in two areas: For LLM research, for the first time, it provides\nconstructive insights into the scope and structure of LLMs' knowledge (or\nbeliefs). For KB construction, it pioneers new pathways for the long-standing\nchallenge of general-domain KB construction. GPTKB is accessible at\nhttps://gptkb.org.",
      "tldr_zh": "本文提出了一种新方法，通过递归 querying 和 result consolidation，全面提取大型语言模型（LLMs）的factual knowledge，以克服现有分析方法存在的可用性偏见（availability bias）。作为原型，使用GPT-4o-mini构建了GPTKB，这是一个大规模知识库（KB），包含105 million triples和2.9 million entities，成本仅为之前KB项目的1%。实验结果首次揭示了LLMs知识范围和结构的详细洞见，并为通用领域KB construction开辟了创新途径。GPTKB可通过https://gptkb.org访问。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 4 tables, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04920v3",
      "published_date": "2024-11-07 17:57:03 UTC",
      "updated_date": "2024-12-16 14:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:21:07.835932"
    },
    {
      "arxiv_id": "2411.04915v1",
      "title": "Evaluating Robustness of Reinforcement Learning Algorithms for Autonomous Shipping",
      "title_zh": "评估强化学习算法在自主航运中的鲁棒性",
      "authors": [
        "Bavo Lesy",
        "Ali Anwar",
        "Siegfried Mercelis"
      ],
      "abstract": "Recently, there has been growing interest in autonomous shipping due to its\npotential to improve maritime efficiency and safety. The use of advanced\ntechnologies, such as artificial intelligence, can address the current\nnavigational and operational challenges in autonomous shipping. In particular,\ninland waterway transport (IWT) presents a unique set of challenges, such as\ncrowded waterways and variable environmental conditions. In such dynamic\nsettings, the reliability and robustness of autonomous shipping solutions are\ncritical factors for ensuring safe operations. This paper examines the\nrobustness of benchmark deep reinforcement learning (RL) algorithms,\nimplemented for IWT within an autonomous shipping simulator, and their ability\nto generate effective motion planning policies. We demonstrate that a\nmodel-free approach can achieve an adequate policy in the simulator,\nsuccessfully navigating port environments never encountered during training. We\nfocus particularly on Soft-Actor Critic (SAC), which we show to be inherently\nmore robust to environmental disturbances compared to MuZero, a\nstate-of-the-art model-based RL algorithm. In this paper, we take a significant\nstep towards developing robust, applied RL frameworks that can be generalized\nto various vessel types and navigate complex port- and inland environments and\nscenarios.",
      "tldr_zh": "这篇论文评估了强化学习（RL）算法在自主航运中的鲁棒性，特别是针对内陆水路运输（IWT）的挑战，如拥挤水道和可变环境条件。研究者使用自主航运模拟器测试基准 RL 算法，包括无模型方法 Soft-Actor Critic (SAC) 和模型-based 方法 MuZero，结果显示 SAC 对环境干扰更具鲁棒性，能在训练中未遇到的港口环境中生成有效的运动规划策略。该工作为开发可推广到各种船只类型和复杂场景的鲁棒 RL 框架提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 4 figures. Will be presented at IEEE RAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04915v1",
      "published_date": "2024-11-07 17:55:07 UTC",
      "updated_date": "2024-11-07 17:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:21:19.538175"
    },
    {
      "arxiv_id": "2411.04890v2",
      "title": "GUI Agents with Foundation Models: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Wang",
        "Weiwen Liu",
        "Jingxuan Chen",
        "Yuqi Zhou",
        "Weinan Gan",
        "Xingshan Zeng",
        "Yuhan Che",
        "Shuai Yu",
        "Xinlong Hao",
        "Kun Shao",
        "Bin Wang",
        "Chuhan Wu",
        "Yasheng Wang",
        "Ruiming Tang",
        "Jianye Hao"
      ],
      "abstract": "Recent advances in foundation models, particularly Large Language Models\n(LLMs) and Multimodal Large Language Models (MLLMs), have facilitated the\ndevelopment of intelligent agents capable of performing complex tasks. By\nleveraging the ability of (M)LLMs to process and interpret Graphical User\nInterfaces (GUIs), these agents can autonomously execute user instructions,\nsimulating human-like interactions such as clicking and typing. This survey\nconsolidates recent research on (M)LLM-based GUI agents, highlighting key\ninnovations in data resources, frameworks, and applications. We begin by\nreviewing representative datasets and benchmarks, followed by an overview of a\ngeneralized, unified framework that encapsulates the essential components of\nprior studies, supported by a detailed taxonomy. Additionally, we explore\nrelevant commercial applications. Drawing insights from existing work, we\nidentify key challenges and propose future research directions. We hope this\nsurvey will inspire further advancements in the field of (M)LLM-based GUI\nagents.",
      "tldr_zh": "这篇综述论文探讨了 Large Language Models (LLMs) 和 Multimodal Large Language Models (MLLMs) 在 Graphical User Interfaces (GUI) 代理中的应用，强调这些模型如何使代理能够自主执行用户指令并模拟人类交互。论文回顾了代表性数据集、基准和一个统一的框架，包括关键组件的详细分类，以及商业应用的案例。最终，它识别了关键挑战并提出未来研究方向，以推动 (M)LLM-based GUI 代理领域的创新和发展。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04890v2",
      "published_date": "2024-11-07 17:28:10 UTC",
      "updated_date": "2025-02-13 10:09:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:21:30.703727"
    },
    {
      "arxiv_id": "2411.04872v5",
      "title": "FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Glazer",
        "Ege Erdil",
        "Tamay Besiroglu",
        "Diego Chicharro",
        "Evan Chen",
        "Alex Gunning",
        "Caroline Falkman Olsson",
        "Jean-Stanislas Denain",
        "Anson Ho",
        "Emily de Oliveira Santos",
        "Olli Järviniemi",
        "Matthew Barnett",
        "Robert Sandler",
        "Matej Vrzala",
        "Jaime Sevilla",
        "Qiuyu Ren",
        "Elizabeth Pratt",
        "Lionel Levine",
        "Grant Barkley",
        "Natalie Stewart",
        "Bogdan Grechuk",
        "Tetiana Grechuk",
        "Shreepranav Varma Enugandla",
        "Mark Wildon"
      ],
      "abstract": "We introduce FrontierMath, a benchmark of hundreds of original, exceptionally\nchallenging mathematics problems crafted and vetted by expert mathematicians.\nThe questions cover most major branches of modern mathematics -- from\ncomputationally intensive problems in number theory and real analysis to\nabstract questions in algebraic geometry and category theory. Solving a typical\nproblem requires multiple hours of effort from a researcher in the relevant\nbranch of mathematics, and for the upper end questions, multiple days.\nFrontierMath uses new, unpublished problems and automated verification to\nreliably evaluate models while minimizing risk of data contamination. Current\nstate-of-the-art AI models solve under 2% of problems, revealing a vast gap\nbetween AI capabilities and the prowess of the mathematical community. As AI\nsystems advance toward expert-level mathematical abilities, FrontierMath offers\na rigorous testbed that quantifies their progress.",
      "tldr_zh": "本研究引入了FrontierMath，这是一个由专家数学家创建的基准测试，包含数百个原创且极具挑战性的数学问题，覆盖数论、实分析、代数几何和范畴论等现代数学主要分支。每个问题通常需要相关领域的研究人员数小时甚至数天来解决，并采用新颖的未发表问题和自动化验证，以可靠评估AI模型并避免数据污染。目前最先进的AI模型仅能解决不到2%的FrontierMath问题，突显AI在高级mathematical reasoning方面的巨大能力差距。该基准为量化AI向专家级数学能力进化的进展提供了严格的测试平台。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04872v5",
      "published_date": "2024-11-07 17:07:35 UTC",
      "updated_date": "2024-12-20 03:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:21:42.648724"
    },
    {
      "arxiv_id": "2411.04867v2",
      "title": "Think Smart, Act SMARL! Analyzing Probabilistic Logic Shields for Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Satchit Chatterji",
        "Erman Acar"
      ],
      "abstract": "Safe reinforcement learning (RL) is crucial for real-world applications, and\nmulti-agent interactions introduce additional safety challenges. While\nProbabilistic Logic Shields (PLS) has been a powerful proposal to enforce\nsafety in single-agent RL, their generalizability to multi-agent settings\nremains unexplored. In this paper, we address this gap by conducting extensive\nanalyses of PLS within decentralized, multi-agent environments, and in doing\nso, propose Shielded Multi-Agent Reinforcement Learning (SMARL) as a general\nframework for steering MARL towards norm-compliant outcomes. Our key\ncontributions are: (1) a novel Probabilistic Logic Temporal Difference (PLTD)\nupdate for shielded, independent Q-learning, which incorporates probabilistic\nconstraints directly into the value update process; (2) a probabilistic logic\npolicy gradient method for shielded PPO with formal safety guarantees for MARL;\nand (3) comprehensive evaluation across symmetric and asymmetrically shielded\n$n$-player game-theoretic benchmarks, demonstrating fewer constraint violations\nand significantly better cooperation under normative constraints. These results\nposition SMARL as an effective mechanism for equilibrium selection, paving the\nway toward safer, socially aligned multi-agent systems.",
      "tldr_zh": "这篇论文探讨了在多智能体强化学习(MARL)中应用Probabilistic Logic Shields (PLS)以提升安全性的挑战，并提出Shielded Multi-Agent Reinforcement Learning (SMARL)框架，用于引导MARL实现符合规范的结果。论文的主要贡献包括：一种新的Probabilistic Logic Temporal Difference (PLTD)更新方法，将概率约束融入独立Q学习的价值更新过程；以及一种概率逻辑策略梯度方法，应用于屏蔽的PPO算法，提供MARL的正式安全保证。通过在对称和不对称$n$-玩家博弈理论基准上的全面评估，SMARL显著减少了约束违反，并提升了合作水平，从而为更安全、社会协调的多智能体系统奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 16 figures, Earlier title: \"Analyzing Probabilistic Logic\n  Driven Safety in Multi-Agent Reinforcement Learning\" (changed for specificity\n  and clarity)",
      "pdf_url": "http://arxiv.org/pdf/2411.04867v2",
      "published_date": "2024-11-07 16:59:32 UTC",
      "updated_date": "2025-05-14 13:30:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:21:55.343857"
    },
    {
      "arxiv_id": "2411.04865v4",
      "title": "ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Olaf Wysocki",
        "Yue Tan",
        "Thomas Froech",
        "Yan Xia",
        "Magdalena Wysocki",
        "Ludwig Hoegner",
        "Daniel Cremers",
        "Christoph Holst"
      ],
      "abstract": "Facade semantic segmentation is a long-standing challenge in photogrammetry\nand computer vision. Although the last decades have witnessed the influx of\nfacade segmentation methods, there is a lack of comprehensive facade classes\nand data covering the architectural variability. In ZAHA, we introduce Level of\nFacade Generalization (LoFG), novel hierarchical facade classes designed based\non international urban modeling standards, ensuring compatibility with\nreal-world challenging classes and uniform methods' comparison. Realizing the\nLoFG, we present to date the largest semantic 3D facade segmentation dataset,\nproviding 601 million annotated points at five and 15 classes of LoFG2 and\nLoFG3, respectively. Moreover, we analyze the performance of baseline semantic\nsegmentation methods on our introduced LoFG classes and data, complementing it\nwith a discussion on the unresolved challenges for facade segmentation. We\nfirmly believe that ZAHA shall facilitate further development of 3D facade\nsemantic segmentation methods, enabling robust segmentation indispensable in\ncreating urban digital twins.",
      "tldr_zh": "该研究引入了 Level of Facade Generalization (LoFG)，一种基于国际城市建模标准的层次化外立面分类系统，以统一方法比较并处理真实世界建筑变异性。研究者发布了目前最大的 Point Cloud Facade Semantic Segmentation 基准数据集，包含 6.01 亿标注点，分别覆盖 LoFG2 的 5 类和 LoFG3 的 15 类。实验分析了基线语义分割方法的性能，并讨论了外立面分割的未解决挑战，旨在推动 3D 外立面语义分割技术的发展，支持城市数字孪生的构建。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV))",
      "pdf_url": "http://arxiv.org/pdf/2411.04865v4",
      "published_date": "2024-11-07 16:58:18 UTC",
      "updated_date": "2024-12-19 13:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:22:06.437833"
    },
    {
      "arxiv_id": "2411.04859v1",
      "title": "A multi-purpose automatic editing system based on lecture semantics for remote education",
      "title_zh": "基于讲座语义的多用途自动编辑系统，用于远程教育",
      "authors": [
        "Panwen Hu",
        "Rui Huang"
      ],
      "abstract": "Remote teaching has become popular recently due to its convenience and\nsafety, especially under extreme circumstances like a pandemic. However, online\nstudents usually have a poor experience since the information acquired from the\nviews provided by the broadcast platforms is limited. One potential solution is\nto show more camera views simultaneously, but it is technically challenging and\ndistracting for the viewers. Therefore, an automatic multi-camera\ndirecting/editing system, which aims at selecting the most concerned view at\neach time instance to guide the attention of online students, is in urgent\ndemand. However, existing systems mostly make simple assumptions and focus on\ntracking the position of the speaker instead of the real lecture semantics, and\ntherefore have limited capacities to deliver optimal information flow. To this\nend, this paper proposes an automatic multi-purpose editing system based on the\nlecture semantics, which can both direct the multiple video streams for\nreal-time broadcasting and edit the optimal video offline for review purposes.\nOur system directs the views by semantically analyzing the class events while\nfollowing the professional directing rules, mimicking a human director to\ncapture the regions of interest from the viewpoint of the onsite students. We\nconduct both qualitative and quantitative analyses to verify the effectiveness\nof the proposed system and its components.",
      "tldr_zh": "这篇论文提出了一种基于 lecture semantics 的多用途自动编辑系统，旨在解决远程教育中在线学生体验差的问题，例如广播平台提供的信息有限。该系统通过语义分析课堂事件并遵循专业 directing 规则，自动选择最相关的摄像头视图，实现实时多视频流广播和离线视频编辑，模仿人类导演捕捉兴趣区域。实验结果通过定性和定量分析验证了系统的有效性，提升了信息传递的优化和学生注意力引导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04859v1",
      "published_date": "2024-11-07 16:49:25 UTC",
      "updated_date": "2024-11-07 16:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:22:19.767560"
    },
    {
      "arxiv_id": "2411.04838v1",
      "title": "Machine learning and optimization-based approaches to duality in statistical physics",
      "title_zh": "基于机器学习和优化的方法在统计物理中的对偶性",
      "authors": [
        "Andrea E. V. Ferrari",
        "Prateek Gupta",
        "Nabil Iqbal"
      ],
      "abstract": "The notion of duality -- that a given physical system can have two different\nmathematical descriptions -- is a key idea in modern theoretical physics.\nEstablishing a duality in lattice statistical mechanics models requires the\nconstruction of a dual Hamiltonian and a map from the original to the dual\nobservables. By using simple neural networks to parameterize these maps and\nintroducing a loss function that penalises the difference between correlation\nfunctions in original and dual models, we formulate the process of duality\ndiscovery as an optimization problem. We numerically solve this problem and\nshow that our framework can rediscover the celebrated Kramers-Wannier duality\nfor the 2d Ising model, reconstructing the known mapping of temperatures. We\nalso discuss an alternative approach which uses known features of the mapping\nof topological lines to reduce the problem to optimizing the couplings in a\ndual Hamiltonian, and explore next-to-nearest neighbour deformations of the 2d\nIsing duality. We discuss future directions and prospects for discovering new\ndualities within this framework.",
      "tldr_zh": "这篇论文提出了一种基于机器学习和优化的框架，用于发现统计物理中的duality，即物理系统不同数学描述的对应关系。作者使用简单neural networks参数化原系统到对偶系统的映射，并通过一个惩罚相关函数差异的loss function，将duality发现转化为优化问题。实验结果显示，该框架成功重现了2d Ising模型的Kramers-Wannier duality，并探索了Hamiltonian耦合的替代优化方法和模型变形，为未来发现新duality提供了前景。",
      "categories": [
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "hep-th"
      ],
      "primary_category": "cond-mat.stat-mech",
      "comment": "27 pages + appendices, lots of plots",
      "pdf_url": "http://arxiv.org/pdf/2411.04838v1",
      "published_date": "2024-11-07 16:29:03 UTC",
      "updated_date": "2024-11-07 16:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:22:31.322673"
    },
    {
      "arxiv_id": "2411.05056v1",
      "title": "Seeing is Deceiving: Exploitation of Visual Pathways in Multi-Modal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pete Janowczyk",
        "Linda Laurier",
        "Ave Giulietta",
        "Arlo Octavia",
        "Meade Cleti"
      ],
      "abstract": "Multi-Modal Language Models (MLLMs) have transformed artificial intelligence\nby combining visual and text data, making applications like image captioning,\nvisual question answering, and multi-modal content creation possible. This\nability to understand and work with complex information has made MLLMs useful\nin areas such as healthcare, autonomous systems, and digital content. However,\nintegrating multiple types of data also creates security risks. Attackers can\nmanipulate either the visual or text inputs, or both, to make the model produce\nunintended or even harmful responses. This paper reviews how visual inputs in\nMLLMs can be exploited by various attack strategies. We break down these\nattacks into categories: simple visual tweaks and cross-modal manipulations, as\nwell as advanced strategies like VLATTACK, HADES, and Collaborative Multimodal\nAdversarial Attack (Co-Attack). These attacks can mislead even the most robust\nmodels while looking nearly identical to the original visuals, making them hard\nto detect. We also discuss the broader security risks, including threats to\nprivacy and safety in important applications. To counter these risks, we review\ncurrent defense methods like the SmoothVLM framework, pixel-wise randomization,\nand MirrorCheck, looking at their strengths and limitations. We also discuss\nnew methods to make MLLMs more secure, including adaptive defenses, better\nevaluation tools, and security approaches that protect both visual and text\ndata. By bringing together recent developments and identifying key areas for\nimprovement, this review aims to support the creation of more secure and\nreliable multi-modal AI systems for real-world use.",
      "tldr_zh": "这篇论文探讨了 Multi-Modal Language Models (MLLMs) 中视觉输入的漏洞，强调攻击者可以通过简单视觉调整、跨模态操纵或高级策略如 VLATTACK、HADES 和 Co-Attack 来误导模型，产生有害或不意图的输出，而这些修改往往难以察觉。作者分类了这些攻击，并分析了它们对隐私和安全（如医疗和自动系统）的潜在风险。论文回顾了现有防御方法，包括 SmoothVLM 框架、像素级随机化和 MirrorCheck，并提出新策略如自适应防御和综合评估工具，以提升 MLLMs 的安全性。最终，该研究整合了最新进展，为构建更可靠的 multi-modal AI 系统提供了关键见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05056v1",
      "published_date": "2024-11-07 16:21:18 UTC",
      "updated_date": "2024-11-07 16:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:22:43.840891"
    },
    {
      "arxiv_id": "2411.08054v1",
      "title": "GREI Data Repository AI Taxonomy",
      "title_zh": "翻译失败",
      "authors": [
        "John Chodacki",
        "Mark Hanhel",
        "Stefano Iacus",
        "Ryan Scherle",
        "Eric Olson",
        "Nici Pfeiffer",
        "Kristi Holmes",
        "Mohammad Hosseini"
      ],
      "abstract": "The Generalist Repository Ecosystem Initiative (GREI), funded by the NIH,\ndeveloped an AI taxonomy tailored to data repository roles to guide AI\nintegration across repository management. It categorizes the roles into stages,\nincluding acquisition, validation, organization, enhancement, analysis,\nsharing, and user support, providing a structured framework for implementing AI\nin repository workflows.",
      "tldr_zh": "该论文介绍了由 NIH 资助的 Generalist Repository Ecosystem Initiative (GREI) 开发的 AI Taxonomy，这是一个针对数据仓库角色的 AI 分类系统，用于指导 AI 在仓库管理中的整合。该分类系统将仓库角色分为多个阶段，包括 acquisition、validation、organization、enhancement、analysis、sharing 和 user support，提供了一个结构化的框架来优化仓库工作流程。通过这一框架，研究者可以更有效地实施 AI 技术，提升数据仓库的效率和可扩展性。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08054v1",
      "published_date": "2024-11-07 16:14:58 UTC",
      "updated_date": "2024-11-07 16:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:22:53.613770"
    },
    {
      "arxiv_id": "2411.04832v2",
      "title": "Plasticity Loss in Deep Reinforcement Learning: A Survey",
      "title_zh": "深度强化学习中的可塑性损失：综述",
      "authors": [
        "Timo Klein",
        "Lukas Miklautz",
        "Kevin Sidak",
        "Claudia Plant",
        "Sebastian Tschiatschek"
      ],
      "abstract": "Akin to neuroplasticity in human brains, the plasticity of deep neural\nnetworks enables their quick adaption to new data. This makes plasticity\nparticularly crucial for deep Reinforcement Learning (RL) agents: Once\nplasticity is lost, an agent's performance will inevitably plateau because it\ncannot improve its policy to account for changes in the data distribution,\nwhich are a necessary consequence of its learning process. Thus, developing\nwell-performing and sample-efficient agents hinges on their ability to remain\nplastic during training. Furthermore, the loss of plasticity can be connected\nto many other issues plaguing deep RL, such as training instabilities, scaling\nfailures, overestimation bias, and insufficient exploration. With this survey,\nwe aim to provide an overview of the emerging research on plasticity loss for\nacademics and practitioners of deep reinforcement learning. First, we propose a\nunified definition of plasticity loss based on recent works, relate it to\ndefinitions from the literature, and discuss metrics for measuring plasticity\nloss. Then, we categorize and discuss numerous possible causes of plasticity\nloss before reviewing currently employed mitigation strategies. Our taxonomy is\nthe first systematic overview of the current state of the field. Lastly, we\ndiscuss prevalent issues within the literature, such as a necessity for broader\nevaluation, and provide recommendations for future research, like gaining a\nbetter understanding of an agent's neural activity and behavior.",
      "tldr_zh": "这篇调查论文探讨了深度强化学习（deep Reinforcement Learning, RL）中神经网络的可塑性损失（plasticity loss），类似于人类大脑的神经可塑性（neuroplasticity），强调其对代理适应新数据分布的重要性。论文提出一个统一的定义，讨论了测量指标、可能原因（如训练不稳定性、过估计偏差和探索不足）以及当前的缓解策略，通过系统分类概述了该领域的现状。最终，论文指出文献中存在的评估不足等问题，并推荐未来研究重点，如深入理解代理的神经活动和行为，以提升 RL 代理的性能和样本效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04832v2",
      "published_date": "2024-11-07 16:13:54 UTC",
      "updated_date": "2024-11-08 10:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:23:06.909870"
    },
    {
      "arxiv_id": "2411.04826v1",
      "title": "D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Siyu Chen",
        "Hong Liu",
        "Wenhao Li",
        "Ying Zhu",
        "Guoquan Wang",
        "Jianbing Wu"
      ],
      "abstract": "Depth estimation is a crucial technology in robotics. Recently,\nself-supervised depth estimation methods have demonstrated great potential as\nthey can efficiently leverage large amounts of unlabelled real-world data.\nHowever, most existing methods are designed under the assumption of static\nscenes, which hinders their adaptability in dynamic environments. To address\nthis issue, we present D$^3$epth, a novel method for self-supervised depth\nestimation in dynamic scenes. It tackles the challenge of dynamic objects from\ntwo key perspectives. First, within the self-supervised framework, we design a\nreprojection constraint to identify regions likely to contain dynamic objects,\nallowing the construction of a dynamic mask that mitigates their impact at the\nloss level. Second, for multi-frame depth estimation, we introduce a cost\nvolume auto-masking strategy that leverages adjacent frames to identify regions\nassociated with dynamic objects and generate corresponding masks. This provides\nguidance for subsequent processes. Furthermore, we propose a spectral entropy\nuncertainty module that incorporates spectral entropy to guide uncertainty\nestimation during depth fusion, effectively addressing issues arising from cost\nvolume computation in dynamic environments. Extensive experiments on KITTI and\nCityscapes datasets demonstrate that the proposed method consistently\noutperforms existing self-supervised monocular depth estimation baselines. Code\nis available at \\url{https://github.com/Csyunling/D3epth}.",
      "tldr_zh": "该论文提出 D$^3$epth，一种针对动态场景的自监督深度估计(self-supervised depth estimation)方法，以解决现有方法在动态环境中的适应性问题。方法从两个角度处理动态物体：首先，通过重投影约束(reprojection constraint)构建动态掩码(dynamic mask)，在损失层面减轻动态物体的影响；其次，引入成本体积自动掩码策略(cost volume auto-masking strategy)和谱熵不确定性模块(spectral entropy uncertainty module)，利用相邻帧和谱熵指导深度融合的不确定性估计。实验在 KITTI 和 Cityscapes 数据集上显示，D$^3$epth  consistently outperforms 现有自监督单目深度估计基线，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Open sourced",
      "pdf_url": "http://arxiv.org/pdf/2411.04826v1",
      "published_date": "2024-11-07 16:07:00 UTC",
      "updated_date": "2024-11-07 16:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:23:19.804677"
    },
    {
      "arxiv_id": "2411.11892v1",
      "title": "Green My LLM: Studying the key factors affecting the energy consumption of code assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Tristan Coignion",
        "Clément Quinton",
        "Romain Rouvoy"
      ],
      "abstract": "In recent years,Large Language Models (LLMs) have significantly improved in\ngenerating high-quality code, enabling their integration into developers'\nIntegrated Development Environments (IDEs) as code assistants. These\nassistants, such as GitHub Copilot, deliver real-time code suggestions and can\ngreatly enhance developers' productivity. However, the environmental impact of\nthese tools, in particular their energy consumption, remains a key concern.\nThis paper investigates the energy consumption of LLM-based code assistants by\nsimulating developer interactions with GitHub Copilot and analyzing various\nconfiguration factors. We collected a dataset of development traces from 20\ndevelopers and conducted extensive software project development simulations to\nmeasure energy usage under different scenarios. Our findings reveal that the\nenergy consumption and performance of code assistants are influenced by various\nfactors, such as the number of concurrent developers, model size, quantization\nmethods, and the use of streaming. Notably, a substantial portion of generation\nrequests made by GitHub Copilot is either canceled or rejected by developers,\nindicating a potential area for reducing wasted computations. Based on these\nfindings, we share actionable insights into optimizing configurations for\ndifferent use cases, demonstrating that careful adjustments can lead to\nsignificant energy savings.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 在代码助手（如 GitHub Copilot）中的能耗问题，通过模拟开发者互动和软件项目开发实验，分析了并发开发者数量、模型大小、量化方法和流式处理等关键因素对能耗的影响。结果显示，大量生成请求被开发者取消或拒绝，导致计算浪费，并揭示了这些因素如何显著影响性能和能源使用。研究提供了可操作的优化建议，例如调整配置以实现显著能耗节省，适用于不同开发场景。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to JSS",
      "pdf_url": "http://arxiv.org/pdf/2411.11892v1",
      "published_date": "2024-11-07 16:00:29 UTC",
      "updated_date": "2024-11-07 16:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:23:30.549248"
    },
    {
      "arxiv_id": "2411.04811v1",
      "title": "Defending Deep Regression Models against Backdoor Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyu Du",
        "Yupei Liu",
        "Jinyuan Jia",
        "Guohao Lan"
      ],
      "abstract": "Deep regression models are used in a wide variety of safety-critical\napplications, but are vulnerable to backdoor attacks. Although many defenses\nhave been proposed for classification models, they are ineffective as they do\nnot consider the uniqueness of regression models. First, the outputs of\nregression models are continuous values instead of discretized labels. Thus,\nthe potential infected target of a backdoored regression model has infinite\npossibilities, which makes it impossible to be determined by existing defenses.\nSecond, the backdoor behavior of backdoored deep regression models is triggered\nby the activation values of all the neurons in the feature space, which makes\nit difficult to be detected and mitigated using existing defenses. To resolve\nthese problems, we propose DRMGuard, the first defense to identify if a deep\nregression model in the image domain is backdoored or not. DRMGuard formulates\nthe optimization problem for reverse engineering based on the unique\noutput-space and feature-space characteristics of backdoored deep regression\nmodels. We conduct extensive evaluations on two regression tasks and four\ndatasets. The results show that DRMGuard can consistently defend against\nvarious backdoor attacks. We also generalize four state-of-the-art defenses\ndesigned for classifiers to regression models, and compare DRMGuard with them.\nThe results show that DRMGuard significantly outperforms all those defenses.",
      "tldr_zh": "本论文探讨了深度回归模型（Deep Regression Models）在安全关键应用中的后门攻击（Backdoor Attacks）漏洞，指出现有针对分类模型的防御方法因回归模型的连续输出和特征空间特性而无效。作者提出DRMGuard，这是首个针对图像领域深度回归模型的后门防御框架，通过基于输出空间和特征空间的优化问题进行逆向工程来检测和缓解攻击。在两个回归任务和四个数据集上的广泛评估中，DRMGuard成功抵御了多种后门攻击，并显著优于四种泛化自分类器防御的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04811v1",
      "published_date": "2024-11-07 15:49:03 UTC",
      "updated_date": "2024-11-07 15:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:23:43.041863"
    },
    {
      "arxiv_id": "2411.04799v2",
      "title": "Kwai-STaR: Transform LLMs into State-Transition Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Lu",
        "Yuhang Hu",
        "Changyi Liu",
        "Tianke Zhang",
        "Zhenyu Yang",
        "Zhixiang Ding",
        "Shengsheng Qian",
        "Meng Du",
        "Ruiwen Kang",
        "Kaiyu Tang",
        "Fan Yang",
        "Tingting Gao",
        "Di Zhang",
        "Hai-Tao Zheng",
        "Bin Wen"
      ],
      "abstract": "Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在数学推理中的挑战，提出了Kwai-STaR框架，将LLMs转化为状态转换推理器（State-Transition Reasoners），将问题求解视为从初始未解决状态到最终解决状态的转换过程。框架包括三个关键步骤：定义针对数学推理的状态空间、生成状态转换数据，以及通过课程训练策略（curricular training）优化模型。实验结果显示，在GSM8K和GSM-Hard数据集上，Mistral-7B和LLaMA-3等模型的性能显著提升，准确率获得可观增益，同时实现了高效的训练和推理过程。未来实验将进一步验证Kwai-STaR的通用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04799v2",
      "published_date": "2024-11-07 15:38:25 UTC",
      "updated_date": "2024-11-12 12:57:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:23:55.913673"
    },
    {
      "arxiv_id": "2411.04796v1",
      "title": "MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Sayan Paul",
        "Ruddra dev Roychoudhury",
        "Brojeshwar Bhowmick"
      ],
      "abstract": "Visual odometry (VO) is essential for enabling accurate point-goal navigation\nof embodied agents in indoor environments where GPS and compass sensors are\nunreliable and inaccurate. However, traditional VO methods face challenges in\nwide-baseline scenarios, where fast robot motions and low frames per second\n(FPS) during inference hinder their performance, leading to drift and\ncatastrophic failures in point-goal navigation. Recent deep-learned VO methods\nshow robust performance but suffer from sample inefficiency during training;\nhence, they require huge datasets and compute resources. So, we propose a\nrobust and sample-efficient VO pipeline based on motion priors available while\nan agent is navigating an environment. It consists of a training-free\naction-prior based geometric VO module that estimates a coarse relative pose\nwhich is further consumed as a motion prior by a deep-learned VO model, which\nfinally produces a fine relative pose to be used by the navigation policy. This\nstrategy helps our pipeline achieve up to 2x sample efficiency during training\nand demonstrates superior accuracy and robustness in point-goal navigation\ntasks compared to state-of-the-art VO method(s). Realistic indoor environments\nof the Gibson dataset is used in the AI-Habitat simulator to evaluate the\nproposed approach using navigation metrics (like success/SPL) and pose metrics\n(like RPE/ATE). We hope this method further opens a direction of work where\nmotion priors from various sources can be utilized to improve VO estimates and\nachieve better results in embodied navigation tasks.",
      "tldr_zh": "本研究提出MPVO，一种基于运动先验的视觉里程计(Visual Odometry)方法，旨在提升室内点目标导航(PointGoal Navigation)中的准确性和鲁棒性，以应对传统VO在宽基线场景下因快速运动和低FPS导致的漂移问题。MPVO框架包括一个无训练的基于动作先验的几何VO模块，用于估计粗略相对位姿，随后将其作为运动先验输入到深度学习VO模型中，以生成精细相对位姿并辅助导航策略。该方法显著提高了训练样本效率（高达2倍），并在Gibson数据集的AI-Habitat模拟器中表现出色，比现有最先进方法在导航指标（如成功率/SPL）和位姿指标（如RPE/ATE）上更具优势。该创新有望开辟利用多种运动先验来改善VO估计和增强导航任务的新方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in 50SFM Workshop of the 18th European Conference on\n  Computer Vision (ECCV) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04796v1",
      "published_date": "2024-11-07 15:36:49 UTC",
      "updated_date": "2024-11-07 15:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:24:08.167752"
    },
    {
      "arxiv_id": "2411.04794v2",
      "title": "KnowCoder-X: Boosting Multilingual Information Extraction via Code",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Zuo",
        "Wenxuan Jiang",
        "Wenxuan Liu",
        "Zixuan Li",
        "Long Bai",
        "Hanbin Wang",
        "Yutao Zeng",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "Empirical evidence indicates that LLMs exhibit spontaneous cross-lingual\nalignment. However, although LLMs show promising cross-lingual alignment in IE,\na significant imbalance across languages persists, highlighting an underlying\ndeficiency. To address this, we propose KnowCoder-X, a powerful code LLM with\nadvanced cross-lingual and multilingual capabilities for universal information\nextraction. Firstly, it standardizes the representation of multilingual schemas\nusing Python classes, ensuring a consistent ontology across different\nlanguages. Then, IE across languages is formulated as a unified code generation\ntask. Secondly, we enhance the model's cross-lingual transferability through IE\ncross-lingual alignment instruction tuning on a translated instance prediction\ntask we proposed. During this phase, we also construct a high-quality and\ndiverse bilingual IE parallel dataset with 257k samples, called ParallelNER,\nsynthesized by our proposed robust three-stage pipeline, with manual annotation\nto ensure quality. Although without training in 29 unseen languages,\nKnowCoder-X surpasses ChatGPT by $30.17\\%$ and SoTA by $20.03\\%$, thereby\ndemonstrating superior cross-lingual IE capabilities. Comprehensive evaluations\non 64 IE benchmarks in Chinese and English under various settings demonstrate\nthat KnowCoder-X significantly enhances cross-lingual IE transfer through\nboosting the IE alignment. Our code and dataset are available at:\nhttps://github.com/ICT-GoKnow/KnowCoder",
      "tldr_zh": "这篇论文提出 KnowCoder-X，一种通过代码增强的多语言信息提取（IE）模型，旨在解决大型语言模型（LLMs）在跨语言对齐中的不平衡问题。KnowCoder-X 使用 Python classes 标准化多语言 schema，并将 IE 任务转化为统一的代码生成任务，同时通过 IE 跨语言对齐指令微调和构建高质量双语数据集 ParallelNER（包含 257k 样本）来提升模型的跨语言转移能力。尽管未在 29 种未见语言上训练，KnowCoder-X 仍比 ChatGPT 高出 30.17% 和 SOTA 高出 20.03%，在 64 个中英 IE 基准测试中显著提高了 IE 对齐性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04794v2",
      "published_date": "2024-11-07 15:36:05 UTC",
      "updated_date": "2025-04-08 16:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:24:20.168841"
    },
    {
      "arxiv_id": "2411.13562v1",
      "title": "The Role of AI in Financial Forecasting: ChatGPT's Potential and Challenges",
      "title_zh": "AI 在金融预测中的作用：ChatGPT 的潜力与挑战",
      "authors": [
        "Shuochen Bi",
        "Tingting Deng",
        "Jue Xiao"
      ],
      "abstract": "The outlook for the future of artificial intelligence (AI) in the financial\nsector, especially in financial forecasting, the challenges and implications.\nThe dynamics of AI technology, including deep learning, reinforcement learning,\nand integration with blockchAIn and the Internet of Things, also highlight the\ncontinued improvement in data processing capabilities. Explore how AI is\nreshaping financial services with precisely tAIlored services that can more\nprecisely meet the diverse needs of individual investors. The integration of AI\nchallenges regulatory and ethical issues in the financial sector, as well as\nthe implications for data privacy protection. Analyze the limitations of\ncurrent AI technology in financial forecasting and its potential impact on the\nfuture financial industry landscape, including changes in the job market, the\nemergence of new financial institutions, and user interface innovations.\nEmphasizing the importance of increasing investor understanding and awareness\nof AI and looking ahead to future trends in AI tools for user experience to\ndrive wider adoption of AI in financial decision making. The huge potential,\nchallenges, and future directions of AI in the financial sector highlight the\ncritical role of AI technology in driving transformation and innovation in the\nfinancial sector",
      "tldr_zh": "这篇论文探讨了AI在金融预测中的作用，特别是ChatGPT的潜力与挑战。论文分析了AI技术如deep learning和reinforcement learning与blockchain及Internet of Things的整合，如何提升数据处理能力并为投资者提供更精确的服务。AI的应用虽能重塑金融行业，但也面临监管、伦理问题和数据隐私保护的挑战。论文强调了AI在金融预测的局限性及其对就业市场、新金融机构和用户界面的潜在影响，并呼吁加强投资者对AI的理解，以推动其在金融决策中的广泛采用。最终，论文突出了AI在驱动金融行业转型和创新的关键作用。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "q-fin.ST",
      "comment": "7 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.13562v1",
      "published_date": "2024-11-07 15:35:16 UTC",
      "updated_date": "2024-11-07 15:35:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:24:30.679858"
    },
    {
      "arxiv_id": "2411.04788v1",
      "title": "Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research",
      "title_zh": "翻译失败",
      "authors": [
        "Xuewen Han",
        "Neng Wang",
        "Shangkun Che",
        "Hongyang Yang",
        "Kunpeng Zhang",
        "Sean Xin Xu"
      ],
      "abstract": "In recent years, the application of generative artificial intelligence\n(GenAI) in financial analysis and investment decision-making has gained\nsignificant attention. However, most existing approaches rely on single-agent\nsystems, which fail to fully utilize the collaborative potential of multiple AI\nagents. In this paper, we propose a novel multi-agent collaboration system\ndesigned to enhance decision-making in financial investment research. The\nsystem incorporates agent groups with both configurable group sizes and\ncollaboration structures to leverage the strengths of each agent group type. By\nutilizing a sub-optimal combination strategy, the system dynamically adapts to\nvarying market conditions and investment scenarios, optimizing performance\nacross different tasks. We focus on three sub-tasks: fundamentals, market\nsentiment, and risk analysis, by analyzing the 2023 SEC 10-K forms of 30\ncompanies listed on the Dow Jones Index. Our findings reveal significant\nperformance variations based on the configurations of AI agents for different\ntasks. The results demonstrate that our multi-agent collaboration system\noutperforms traditional single-agent models, offering improved accuracy,\nefficiency, and adaptability in complex financial environments. This study\nhighlights the potential of multi-agent systems in transforming financial\nanalysis and investment decision-making by integrating diverse analytical\nperspectives.",
      "tldr_zh": "该研究探讨了生成式AI（GenAI）在金融分析中的应用，提出了一种新型多智能体协作系统，以优化AI代理在投资决策中的协同作用。该系统通过可配置的智能体组大小和结构，以及子最优组合策略，动态适应不同市场条件，并在基础分析、市场情绪分析和风险分析等子任务上进行优化。实验基于2023年SEC 10-K表格的30家道琼斯指数公司数据，结果显示该系统在准确性、效率和适应性方面显著优于传统单智能体模型，突显了多智能体系统整合多样分析视角的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "q-fin.ST",
        "q-fin.TR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04788v1",
      "published_date": "2024-11-07 15:28:20 UTC",
      "updated_date": "2024-11-07 15:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:24:43.940290"
    },
    {
      "arxiv_id": "2411.04784v1",
      "title": "Navigating Trade-offs: Policy Summarization for Multi-Objective Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zuzanna Osika",
        "Jazmin Zatarain-Salazar",
        "Frans A. Oliehoek",
        "Pradeep K. Murukannaiah"
      ],
      "abstract": "Multi-objective reinforcement learning (MORL) is used to solve problems\ninvolving multiple objectives. An MORL agent must make decisions based on the\ndiverse signals provided by distinct reward functions. Training an MORL agent\nyields a set of solutions (policies), each presenting distinct trade-offs among\nthe objectives (expected returns). MORL enhances explainability by enabling\nfine-grained comparisons of policies in the solution set based on their\ntrade-offs as opposed to having a single policy. However, the solution set is\ntypically large and multi-dimensional, where each policy (e.g., a neural\nnetwork) is represented by its objective values.\n  We propose an approach for clustering the solution set generated by MORL. By\nconsidering both policy behavior and objective values, our clustering method\ncan reveal the relationship between policy behaviors and regions in the\nobjective space. This approach can enable decision makers (DMs) to identify\noverarching trends and insights in the solution set rather than examining each\npolicy individually. We tested our method in four multi-objective environments\nand found it outperformed traditional k-medoids clustering. Additionally, we\ninclude a case study that demonstrates its real-world application.",
      "tldr_zh": "这篇论文针对多目标强化学习(MORL)中策略集合的复杂性和多维权衡问题，提出了一种聚类方法，用于总结和分析MORL生成的策略集。该方法同时考虑策略行为和目标值，揭示策略行为与目标空间区域之间的关系，从而帮助决策者快速识别整体趋势，而非逐个检查策略。在四个多目标环境中测试，该方法优于传统k-medoids聚类，并通过一个案例研究展示了其在实际应用中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04784v1",
      "published_date": "2024-11-07 15:26:38 UTC",
      "updated_date": "2024-11-07 15:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:24:55.621696"
    },
    {
      "arxiv_id": "2411.04772v1",
      "title": "Attention Masks Help Adversarial Attacks to Bypass Safety Detectors",
      "title_zh": "注意力掩码帮助对抗性攻击绕过安全检测器",
      "authors": [
        "Yunfan Shi"
      ],
      "abstract": "Despite recent research advancements in adversarial attack methods, current\napproaches against XAI monitors are still discoverable and slower. In this\npaper, we present an adaptive framework for attention mask generation to enable\nstealthy, explainable and efficient PGD image classification adversarial attack\nunder XAI monitors. Specifically, we utilize mutation XAI mixture and multitask\nself-supervised X-UNet for attention mask generation to guide PGD attack.\nExperiments on MNIST (MLP), CIFAR-10 (AlexNet) have shown that our system can\noutperform benchmark PGD, Sparsefool and SOTA SINIFGSM in balancing among\nstealth, efficiency and explainability which is crucial for effectively fooling\nSOTA defense protected classifiers.",
      "tldr_zh": "该论文提出了一种自适应框架，利用注意力掩码（attention masks）来实现隐秘、可解释和高效的 PGD 图像分类对抗攻击，从而绕过 XAI 监控器。框架具体通过 mutation XAI mixture 和 multitask self-supervised X-UNet 生成注意力掩码，以指导 PGD 攻击过程。实验在 MNIST (MLP) 和 CIFAR-10 (AlexNet) 数据集上显示，该方法在隐秘性、效率和可解释性方面优于基准 PGD、Sparsefool 和 SOTA SINIFGSM，从而更有效地欺骗先进的防御保护分类器。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04772v1",
      "published_date": "2024-11-07 15:13:50 UTC",
      "updated_date": "2024-11-07 15:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:25:06.702251"
    },
    {
      "arxiv_id": "2411.05867v2",
      "title": "Modeling Nonlinear Oscillator Networks Using Physics-Informed Hybrid Reservoir Computing",
      "title_zh": "使用物理信息驱动的混合水库计算建模非线性振荡器网络",
      "authors": [
        "Andrew Shannon",
        "Conor Houghton",
        "David Barton",
        "Martin Homer"
      ],
      "abstract": "Surrogate modeling of non-linear oscillator networks remains challenging due\nto discrepancies between simplified analytical models and real-world\ncomplexity. To bridge this gap, we investigate hybrid reservoir computing,\ncombining reservoir computing with \"expert\" analytical models. Simulating the\nabsence of an exact model, we first test the surrogate models with parameter\nerrors in their expert model. Second, in a residual physics task, we assess\ntheir performance when their expert model lacks key non-linear coupling terms\npresent in an extended ground-truth model. We focus on short-term forecasting\nacross diverse dynamical regimes, evaluating the use of these surrogates for\ncontrol applications. We show that hybrid reservoir computers generally\noutperform standard reservoir computers and exhibit greater robustness to\nparameter tuning. This advantage is less pronounced in the residual physics\ntask. Notably, unlike standard reservoir computers, the performance of the\nhybrid does not degrade when crossing an observed spectral radius threshold.\nFurthermore, there is good performance for dynamical regimes not accessible to\nthe expert model, demonstrating the contribution of the reservoir.",
      "tldr_zh": "本文提出了一种基于Physics-Informed Hybrid Reservoir Computing的方法，用于建模非线性振荡器网络，以弥合简化分析模型与现实复杂度之间的差距。该方法将Reservoir Computing与“专家”分析模型结合，并在参数错误场景及残差物理任务中进行测试，评估其在短期预测和控制应用中的性能。结果显示，Hybrid Reservoir Computers 普遍优于标准Reservoir Computers，具有更强的鲁棒性、对参数调整的适应性和在跨越谱半径阈值时的稳定性，尤其能在专家模型无法处理的动态制度下实现良好表现。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "I.6.3; I.6.5; I.2.6; J.2"
      ],
      "primary_category": "eess.SY",
      "comment": "32 pages, 10 figures, 21 supplementary figures. Updated in response\n  to review. Code at https://github.com/AJS50/Hybrid_RC_for_NLONS_paper_code",
      "pdf_url": "http://arxiv.org/pdf/2411.05867v2",
      "published_date": "2024-11-07 15:09:23 UTC",
      "updated_date": "2025-05-19 10:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:25:19.727025"
    },
    {
      "arxiv_id": "2411.04747v1",
      "title": "Equivariant Graph Attention Networks with Structural Motifs for Predicting Cell Line-Specific Synergistic Drug Combinations",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Schwehr"
      ],
      "abstract": "Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https://github.com/WeToTheMoon/EGAT_DrugSynergy.",
      "tldr_zh": "本研究针对癌症治疗中药物组合筛选的低效问题，提出了一种基于 equivariant graph attention networks 的几何深度学习框架，该框架对 3D 旋转、平移和反射保持不变，并结合 structural motifs 和癌症细胞系的基因表达数据，来预测特定细胞系的协同药物组合。相比现有 SOTA 方法，该模型在 DrugComb 数据集的 12 个基准任务上准确率提高了 28% 以上，展示了其在学习几何数据和分子表示方面的优势。总体而言，该框架为高效的 in silico 药物筛选提供了一个可泛化的工具，支持进一步的湿实验室验证，并已开源代码。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "8 pages, 1 figure, Presented at IEEE CIBCB",
      "pdf_url": "http://arxiv.org/pdf/2411.04747v1",
      "published_date": "2024-11-07 14:29:05 UTC",
      "updated_date": "2024-11-07 14:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:25:31.122452"
    },
    {
      "arxiv_id": "2411.11891v1",
      "title": "Survey on Semantic Interpretation of Tabular Data: Challenges and Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Cremaschi",
        "Blerina Spahiu",
        "Matteo Palmonari",
        "Ernesto Jimenez-Ruiz"
      ],
      "abstract": "Tabular data plays a pivotal role in various fields, making it a popular\nformat for data manipulation and exchange, particularly on the web. The\ninterpretation, extraction, and processing of tabular information are\ninvaluable for knowledge-intensive applications. Notably, significant efforts\nhave been invested in annotating tabular data with ontologies and entities from\nbackground knowledge graphs, a process known as Semantic Table Interpretation\n(STI). STI automation aids in building knowledge graphs, enriching data, and\nenhancing web-based question answering. This survey aims to provide a\ncomprehensive overview of the STI landscape. It starts by categorizing\napproaches using a taxonomy of 31 attributes, allowing for comparisons and\nevaluations. It also examines available tools, assessing them based on 12\ncriteria. Furthermore, the survey offers an in-depth analysis of the Gold\nStandards used for evaluating STI approaches. Finally, it provides practical\nguidance to help end-users choose the most suitable approach for their specific\ntasks while also discussing unresolved issues and suggesting potential future\nresearch directions.",
      "tldr_zh": "这篇调查论文探讨了表格数据的语义解释（Semantic Table Interpretation, STI）的挑战和未来方向，强调了STI在构建知识图谱（Knowledge Graphs）、数据丰富和网络问答中的重要作用。论文采用31个属性的分类法来比较各种STI方法，并基于12个标准评估了可用工具，同时分析了用于评估的黄金标准。最终，它提供实用指导帮助用户选择合适方法，并讨论了未解决的问题及潜在研究方向。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.11891v1",
      "published_date": "2024-11-07 14:28:56 UTC",
      "updated_date": "2024-11-07 14:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:25:43.155898"
    },
    {
      "arxiv_id": "2411.04710v1",
      "title": "Differential Privacy Overview and Fundamental Techniques",
      "title_zh": "差分隐私概述和基本技术",
      "authors": [
        "Ferdinando Fioretto",
        "Pascal Van Hentenryck",
        "Juba Ziani"
      ],
      "abstract": "This chapter is meant to be part of the book \"Differential Privacy in\nArtificial Intelligence: From Theory to Practice\" and provides an introduction\nto Differential Privacy. It starts by illustrating various attempts to protect\ndata privacy, emphasizing where and why they failed, and providing the key\ndesiderata of a robust privacy definition. It then defines the key actors,\ntasks, and scopes that make up the domain of privacy-preserving data analysis.\nFollowing that, it formalizes the definition of Differential Privacy and its\ninherent properties, including composition, post-processing immunity, and group\nprivacy. The chapter also reviews the basic techniques and mechanisms commonly\nused to implement Differential Privacy in its pure and approximate forms.",
      "tldr_zh": "这篇章节概述了 Differential Privacy 的基本概念，介绍了传统数据隐私保护方法的失败案例，并定义了其核心要求，如关键参与者、任务和范围，以实现稳健的隐私保护。章节正式化了 Differential Privacy 的定义及其属性，包括 composition、post-processing immunity 和 group privacy，这些属性确保了隐私机制的可靠性。随后，它回顾了实现 Differential Privacy 的基本技术和机制，涵盖纯形式和 approximate forms 的应用。总的来说，这为隐私保护数据分析提供了理论基础和实用指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Chapter 1 of book: \"Differential Privacy in Artificial Intelligence:\n  From Theory to Practice\"",
      "pdf_url": "http://arxiv.org/pdf/2411.04710v1",
      "published_date": "2024-11-07 13:52:11 UTC",
      "updated_date": "2024-11-07 13:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:25:54.598267"
    },
    {
      "arxiv_id": "2411.05055v1",
      "title": "Integrating Large Language Models for Genetic Variant Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Youssef Boulaimen",
        "Gabriele Fossi",
        "Leila Outemzabet",
        "Nathalie Jeanray",
        "Oleksandr Levenets",
        "Stephane Gerart",
        "Sebastien Vachenc",
        "Salvatore Raieli",
        "Joanna Giemza"
      ],
      "abstract": "The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
      "tldr_zh": "本研究探讨了整合 Large Language Models (LLMs) 以提升遗传变异分类的准确性，特别是针对 Variants of Uncertain Significance (VUS) 的挑战。研究方法结合了 GPN-MSA、ESM1b 和 AlphaMissense 等模型，利用 DNA 和蛋白序列数据以及结构洞见，在 ProteinGym 和 ClinVar 数据集上进行评估，并显著优于现有工具。结果显示，该框架在处理模糊变异时表现出色，提高了分类系统的可靠性和精确性，最终为临床遗传学和精准医学提供更可靠的诊断支持。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG",
        "68T07 (Primary) 92D20, 92C40 (Secondary)",
        "I.2.7; J.3"
      ],
      "primary_category": "q-bio.GN",
      "comment": "21 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05055v1",
      "published_date": "2024-11-07 13:45:56 UTC",
      "updated_date": "2024-11-07 13:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:26:07.083799"
    },
    {
      "arxiv_id": "2411.04700v1",
      "title": "Field Assessment of Force Torque Sensors for Planetary Rover Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Levin Gerdes",
        "Carlos Pérez del Pulgar",
        "Raúl Castilla Arquillo",
        "Martin Azkarate"
      ],
      "abstract": "Proprioceptive sensors on planetary rovers serve for state estimation and for\nunderstanding terrain and locomotion performance. While inertial measurement\nunits (IMUs) are widely used to this effect, force-torque sensors are less\nexplored for planetary navigation despite their potential to directly measure\ninteraction forces and provide insights into traction performance. This paper\npresents an evaluation of the performance and use cases of force-torque sensors\nbased on data collected from a six-wheeled rover during tests over varying\nterrains, speeds, and slopes. We discuss challenges, such as sensor signal\nreliability and terrain response accuracy, and identify opportunities regarding\nthe use of these sensors. The data is openly accessible and includes\nforce-torque measurements from each of the six-wheel assemblies as well as IMU\ndata from within the rover chassis. This paper aims to inform the design of\nfuture studies and rover upgrades, particularly in sensor integration and\ncontrol algorithms, to improve navigation capabilities.",
      "tldr_zh": "这篇论文评估了Force-Torque Sensors在行星探测车导航中的性能，通过实地测试一个六轮探测车在不同地形、速度和坡度的场景下收集数据。研究讨论了传感器信号可靠性和地形响应准确性的挑战，同时识别了其在改善牵引性能和状态估计方面的机会。论文公开了数据集，包括每个轮子的Force-Torque测量和IMU数据，以指导未来探测车的传感器集成和控制算法设计，从而提升导航能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04700v1",
      "published_date": "2024-11-07 13:34:37 UTC",
      "updated_date": "2024-11-07 13:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:26:19.300304"
    },
    {
      "arxiv_id": "2411.04696v3",
      "title": "The Multiple Dimensions of Spuriousness in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel J. Bell",
        "Skyler Wang"
      ],
      "abstract": "Learning correlations from data forms the foundation of today's machine\nlearning (ML) and artificial intelligence (AI) research. While such an approach\nenables the automatic discovery of patterned relationships within big data\ncorpora, it is susceptible to failure modes when unintended correlations are\ncaptured. This vulnerability has expanded interest in interrogating\nspuriousness, often critiqued as an impediment to model performance, fairness,\nand robustness. In this article, we trace deviations from the conventional\ndefinition of statistical spuriousness-which denotes a non-causal observation\narising from either coincidence or confounding variables-to articulate how ML\nresearchers make sense of spuriousness in practice. Drawing on a broad survey\nof ML literature, we conceptualize the \"multiple dimensions of spuriousness,\"\nencompassing: relevance (\"Models should only use correlations that are relevant\nto the task.\"), generalizability (\"Models should only use correlations that\ngeneralize to unseen data\"), human-likeness (\"Models should only use\ncorrelations that a human would use to perform the same task\"), and harmfulness\n(\"Models should only use correlations that are not harmful\"). These dimensions\ndemonstrate that ML spuriousness goes beyond the causal/non-causal dichotomy\nand that the disparate interpretative paths researchers choose could\nmeaningfully influence the trajectory of ML development. By underscoring how a\nfundamental problem in ML is contingently negotiated in research contexts, we\ncontribute to ongoing debates about responsible practices in AI development.",
      "tldr_zh": "这篇论文探讨了机器学习（Machine Learning）中 spuriousness 的多重维度，强调模型在学习数据相关性时可能捕捉到非预期的关联，导致性能、公平性和鲁棒性问题。作者通过文献调研，将 spuriousness 扩展到四个关键维度：relevance（模型只使用与任务相关的相关性）、generalizability（模型只使用能泛化到未见数据的相关性）、human-likeness（模型只使用人类在相同任务中会采用的相关性），以及harmfulness（模型只使用不有害的相关性）。这些维度超越了传统的统计非因果定义，展示了 spuriousness 在实际研究中的复杂诠释，并为负责任的 AI 发展提供重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04696v3",
      "published_date": "2024-11-07 13:29:32 UTC",
      "updated_date": "2024-11-28 12:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:26:31.993355"
    },
    {
      "arxiv_id": "2411.15151v1",
      "title": "Memory-Driven Metaheuristics: Improving Optimization Performance",
      "title_zh": "记忆驱动的元启发式算法：改善优化性能",
      "authors": [
        "Salar Farahmand-Tabar"
      ],
      "abstract": "Metaheuristics are stochastic optimization algorithms that mimic natural\nprocesses to find optimal solutions to complex problems. The success of\nmetaheuristics largely depends on the ability to effectively explore and\nexploit the search space. Memory mechanisms have been introduced in several\npopular metaheuristic algorithms to enhance their performance. This chapter\nexplores the significance of memory in metaheuristic algorithms and provides\ninsights from well-known algorithms. The chapter begins by introducing the\nconcept of memory, and its role in metaheuristic algorithms. The key factors\ninfluencing the effectiveness of memory mechanisms are discussed, such as the\nsize of the memory, the information stored in memory, and the rate of\ninformation decay. A comprehensive analysis of how memory mechanisms are\nincorporated into popular metaheuristic algorithms is presented and concludes\nby highlighting the importance of memory in metaheuristic performance and\nproviding future research directions for improving memory mechanisms. The key\ntakeaways are that memory mechanisms can significantly enhance the performance\nof metaheuristics by enabling them to explore and exploit the search space\neffectively and efficiently, and that the choice of memory mechanism should be\ntailored to the problem domain and the characteristics of the search space.",
      "tldr_zh": "本论文探讨了记忆机制在元启发式(metaheuristics)算法中的作用，这些算法通过模拟自然过程来优化复杂问题。作者分析了影响记忆机制效能的关键因素，包括记忆大小、存储信息类型和信息衰减率，并考察了其在流行算法中的整合方式。研究发现，适当的记忆机制能显著提升算法的搜索空间探索和利用效率，并建议未来研究应根据问题领域和搜索空间特性来定制记忆机制，以进一步改善优化性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "25 pages, 5 figures, book chapter, Springer",
      "pdf_url": "http://arxiv.org/pdf/2411.15151v1",
      "published_date": "2024-11-07 13:27:03 UTC",
      "updated_date": "2024-11-07 13:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:26:43.404640"
    },
    {
      "arxiv_id": "2411.04693v2",
      "title": "Electromagnetic Scattering Kernel Guided Reciprocal Point Learning for SAR Open-Set Recognition",
      "title_zh": "电磁",
      "authors": [
        "Xiayang Xiao",
        "Zhuoxuan Li",
        "Ruyi Zhang",
        "Jiacheng Chen",
        "Haipeng Wang"
      ],
      "abstract": "The limitations of existing Synthetic Aperture Radar (SAR) Automatic Target\nRecognition (ATR) methods lie in their confinement by the closed-environment\nassumption, hindering their effective and robust handling of unknown target\ncategories in open environments. Open Set Recognition (OSR), a pivotal facet\nfor algorithmic practicality, intends to categorize known classes while\ndenoting unknown ones as \"unknown.\" The chief challenge in OSR involves\nconcurrently mitigating risks associated with generalizing features from a\nrestricted set of known classes to numerous unknown samples and the open space\nexposure to potential unknown data. To enhance open-set SAR classification, a\nmethod called scattering kernel with reciprocal learning network is proposed.\nInitially, a feature learning framework is constructed based on reciprocal\npoint learning (RPL), establishing a bounded space for potential unknown\nclasses. This approach indirectly introduces unknown information into a learner\nconfined to known classes, thereby acquiring more concise and discriminative\nrepresentations. Subsequently, considering the variability in the imaging of\ntargets at different angles and the discreteness of components in SAR images, a\nproposal is made to design convolutional kernels based on large-sized attribute\nscattering center models. This enhances the ability to extract intrinsic\nnon-linear features and specific scattering characteristics in SAR images,\nthereby improving the discriminative features of the model and mitigating the\nimpact of imaging variations on classification performance. Experiments on the\nMSTAR datasets substantiate the superior performance of the proposed approach\ncalled ASC-RPL over mainstream methods.",
      "tldr_zh": "该研究针对合成孔径雷达(SAR)自动目标识别(ATR)方法的局限性，提出了一种电磁散射核引导的互惠点学习(Reciprocal Point Learning, RPL)网络，用于SAR开放集识别(Open Set Recognition, OSR)。该方法首先构建基于RPL的特征学习框架，建立边界空间来间接引入未知类别信息，从而获得更简洁和判别性的特征表示；其次，设计基于大型属性散射中心模型的卷积核，以提取SAR图像的内在非线性特征和特定散射特性，缓解成像角度变化对分类的影响。实验在MSTAR数据集上证明，该方法（ASC-RPL）在识别已知类别并检测未知类别方面，优于主流方法，显著提升了SAR OSR的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04693v2",
      "published_date": "2024-11-07 13:26:20 UTC",
      "updated_date": "2024-12-06 01:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:26:55.795042"
    },
    {
      "arxiv_id": "2411.04692v1",
      "title": "Personalized Federated Learning for Cross-view Geo-localization",
      "title_zh": "个性化联邦学习用于跨视图地理定位",
      "authors": [
        "Christos Anagnostopoulos",
        "Alexandros Gkillas",
        "Nikos Piperigkos",
        "Aris S. Lalos"
      ],
      "abstract": "In this paper we propose a methodology combining Federated Learning (FL) with\nCross-view Image Geo-localization (CVGL) techniques. We address the challenges\nof data privacy and heterogeneity in autonomous vehicle environments by\nproposing a personalized Federated Learning scenario that allows selective\nsharing of model parameters. Our method implements a coarse-to-fine approach,\nwhere clients share only the coarse feature extractors while keeping\nfine-grained features specific to local environments. We evaluate our approach\nagainst traditional centralized and single-client training schemes using the\nKITTI dataset combined with satellite imagery. Results demonstrate that our\nfederated CVGL method achieves performance close to centralized training while\nmaintaining data privacy. The proposed partial model sharing strategy shows\ncomparable or slightly better performance than classical FL, offering\nsignificant reduced communication overhead without sacrificing accuracy. Our\nwork contributes to more robust and privacy-preserving localization systems for\nautonomous vehicles operating in diverse environments",
      "tldr_zh": "本篇论文提出了一种结合 Federated Learning (FL) 和 Cross-view Geo-localization (CVGL) 的方法，旨在解决自动驾驶车辆环境中数据隐私和异质性挑战。方法采用 personalized FL 策略，客户端仅共享粗粒度特征提取器，而保留细粒度特征本地，实现粗到细的训练流程。实验在 KITTI 数据集和卫星图像上显示，该方法性能接近传统集中式训练，同时显著减少通信开销，并与经典 FL 相比表现出相当或略高的准确性。该工作为多样环境下的自动车辆定位系统提供了更鲁棒且隐私保护的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures, Preprint submitted to the IEEE 26th International\n  Workshop on Multimedia Signal Processing (MMSP)",
      "pdf_url": "http://arxiv.org/pdf/2411.04692v1",
      "published_date": "2024-11-07 13:25:52 UTC",
      "updated_date": "2024-11-07 13:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:27:08.006984"
    },
    {
      "arxiv_id": "2411.04691v1",
      "title": "AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhang",
        "Miu Kojima",
        "Simon D'Alfonso"
      ],
      "abstract": "Smartphones, equipped with an array of sensors, have become valuable tools\nfor personal sensing. Particularly in digital health, smartphones facilitate\nthe tracking of health-related behaviors and contexts, contributing\nsignificantly to digital phenotyping, a process where data from digital\ninteractions is analyzed to infer behaviors and assess mental health.\nTraditional methods process raw sensor data into information features for\nstatistical and machine learning analyses. In this paper, we introduce a novel\napproach that systematically converts smartphone-collected data into\nstructured, chronological narratives. The AWARE Narrator translates\nquantitative smartphone sensing data into English language descriptions,\nforming comprehensive narratives of an individual's activities. We apply the\nframework to the data collected from university students over a week,\ndemonstrating the potential of utilizing the narratives to summarize individual\nbehavior, and analyzing psychological states by leveraging large language\nmodels.",
      "tldr_zh": "本论文提出 AWARE Narrator 系统，将智能手机传感器数据转化为结构化、按时间顺序的英文叙述，从而从定量数据中提取行为洞见。该系统利用 Large Language Models 处理数据，支持数字健康领域的 digital phenotyping，通过分析个人活动来推断行为和心理状态。在对大学学生一周数据的应用中，框架展示了高效总结个体行为的潜力，并为进一步评估心理健康提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04691v1",
      "published_date": "2024-11-07 13:23:57 UTC",
      "updated_date": "2024-11-07 13:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:27:19.878535"
    },
    {
      "arxiv_id": "2411.04685v5",
      "title": "Solving Generalized Grouping Problems in Cellular Manufacturing Systems Using a Network Flow Model",
      "title_zh": "使用网络流模型解决蜂窝式制造系统中的广义分组问题",
      "authors": [
        "Md. Kutub Uddin",
        "Md. Saiful Islam",
        "Md Abrar Jahin",
        "Md. Saiful Islam Seam",
        "M. F. Mridha"
      ],
      "abstract": "This paper focuses on the generalized grouping problem in the context of\ncellular manufacturing systems (CMS), where parts may have more than one\nprocess route. A process route lists the machines corresponding to each part of\nthe operation. Inspired by the extensive and widespread use of network flow\nalgorithms, this research formulates the process route family formation for\ngeneralized grouping as a unit capacity minimum cost network flow model. The\nobjective is to minimize dissimilarity (based on the machines required) among\nthe process routes within a family. The proposed model optimally solves the\nprocess route family formation problem without pre-specifying the number of\npart families to be formed. The process route of family formation is the first\nstage in a hierarchical procedure. For the second stage (machine cell\nformation), two procedures, a quadratic assignment programming (QAP)\nformulation, and a heuristic procedure, are proposed. The QAP simultaneously\nassigns process route families and machines to a pre-specified number of cells\nin such a way that total machine utilization is maximized. The heuristic\nprocedure for machine cell formation is hierarchical in nature. Computational\nresults for some test problems show that the QAP and the heuristic procedure\nyield the same results.",
      "tldr_zh": "本论文解决了Cellular Manufacturing Systems (CMS)中广义分组问题，针对零件可能有多个工艺路线的场景，使用单位容量最小成本Network Flow Model来形成工艺路线家族，目标是最小化家族内工艺路线间的异质性（基于所需机器），且无需预先指定零件家族数量。模型作为分层程序的第一阶段，第二阶段则提出Quadratic Assignment Programming (QAP)公式和启发式程序来同时分配工艺路线家族和机器到预设单元，以最大化机器利用率。计算实验结果显示，QAP和启发式程序在测试问题上产生相同的结果，为CMS优化提供了高效方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04685v5",
      "published_date": "2024-11-07 13:14:52 UTC",
      "updated_date": "2024-12-04 20:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:27:31.589759"
    },
    {
      "arxiv_id": "2411.05054v1",
      "title": "FMEA Builder: Expert Guided Text Generation for Equipment Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Karol Lynch",
        "Fabio Lorenzi",
        "John Sheehan",
        "Duygu Kabakci-Zorlu",
        "Bradley Eck"
      ],
      "abstract": "Foundation models show great promise for generative tasks in many domains.\nHere we discuss the use of foundation models to generate structured documents\nrelated to critical assets. A Failure Mode and Effects Analysis (FMEA) captures\nthe composition of an asset or piece of equipment, the ways it may fail and the\nconsequences thereof. Our system uses large language models to enable fast and\nexpert supervised generation of new FMEA documents. Empirical analysis shows\nthat foundation models can correctly generate over half of an FMEA's key\ncontent. Results from polling audiences of reliability professionals show a\npositive outlook on using generative AI to create these documents for critical\nassets.",
      "tldr_zh": "该研究提出 FMEA Builder 系统，利用 Foundation Models 生成设备维护相关的结构化文档，特别是 Failure Mode and Effects Analysis (FMEA)，以捕捉资产组成、故障模式及其后果。系统通过大型语言模型结合专家监督，实现快速生成新 FMEA 文档。实证分析显示，Foundation Models 能正确生成超过一半的关键内容，且可靠性专业人士的调查反馈对使用生成式 AI 创建这些文档持积极态度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages, 2 figures. AI for Critical Infrastructure Workshop @ IJCAI\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2411.05054v1",
      "published_date": "2024-11-07 13:11:03 UTC",
      "updated_date": "2024-11-07 13:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:27:43.165161"
    },
    {
      "arxiv_id": "2411.04679v2",
      "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Liu",
        "Pan Zhou",
        "Yingjun Du",
        "Ah-Hwee Tan",
        "Cees G. M. Snoek",
        "Jan-Jakob Sonke",
        "Efstratios Gavves"
      ],
      "abstract": "In this work, we address the cooperation problem among large language model\n(LLM) based embodied agents, where agents must cooperate to achieve a common\ngoal. Previous methods often execute actions extemporaneously and incoherently,\nwithout long-term strategic and cooperative planning, leading to redundant\nsteps, failures, and even serious repercussions in complex tasks like\nsearch-and-rescue missions where discussion and cooperative plan are crucial.\nTo solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance\nthe cooperation efficiency of LLM-based embodied agents. Inspired by human\ncooperation schemes, CaPo improves cooperation efficiency with two phases: 1)\nmeta-plan generation, and 2) progress-adaptive meta-plan and execution. In the\nfirst phase, all agents analyze the task, discuss, and cooperatively create a\nmeta-plan that decomposes the task into subtasks with detailed steps, ensuring\na long-term strategic and coherent plan for efficient coordination. In the\nsecond phase, agents execute tasks according to the meta-plan and dynamically\nadjust it based on their latest progress (e.g., discovering a target object)\nthrough multi-turn discussions. This progress-based adaptation eliminates\nredundant actions, improving the overall cooperation efficiency of agents.\nExperimental results on the ThreeDworld Multi-Agent Transport and Communicative\nWatch-And-Help tasks demonstrate that CaPo achieves much higher task completion\nrate and efficiency compared with state-of-the-arts.The code is released at\nhttps://github.com/jliu4ai/CaPo.",
      "tldr_zh": "本论文针对LLM-based embodied agents的合作问题，提出CaPo框架，以提升代理在复杂任务中的长期战略规划和协调效率。CaPo包括两个阶段：首先，通过meta-plan generation让代理分析任务、讨论并创建分解子任务的元计划；其次，通过progress-adaptive meta-plan and execution，代理根据最新进展（如发现目标对象）进行多轮讨论动态调整计划，从而减少冗余动作。实验结果显示，在ThreeDworld的Multi-Agent Transport和Communicative Watch-And-Help任务上，CaPo相比现有方法显著提高了任务完成率和整体效率。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted in ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2411.04679v2",
      "published_date": "2024-11-07 13:08:04 UTC",
      "updated_date": "2025-03-01 09:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:27:55.367955"
    },
    {
      "arxiv_id": "2411.05865v1",
      "title": "Bilinear Fuzzy Genetic Algorithm and Its Application on the Optimum Design of Steel Structures with Semi-rigid Connections",
      "title_zh": "双线性模糊遗传算法及其在具有半刚性连接的钢结构最优设计中的应用",
      "authors": [
        "Salar Farahmand-Tabar",
        "Payam Ashtari"
      ],
      "abstract": "An improved bilinear fuzzy genetic algorithm (BFGA) is introduced in this\nchapter for the design optimization of steel structures with semi-rigid\nconnections. Semi-rigid connections provide a compromise between the stiffness\nof fully rigid connections and the flexibility of fully pinned connections.\nHowever, designing such structures is challenging due to the nonlinear behavior\nof semi-rigid connections. The BFGA is a robust optimization method that\ncombines the strengths of fuzzy logic and genetic algorithm to handle the\ncomplexity and uncertainties of structural design problems. The BFGA, compared\nto standard GA, demonstrated to generate high-quality solutions in a reasonable\ntime. The application of the BFGA is demonstrated through the optimization of\nsteel structures with semirigid connections, considering the weight and\nperformance criteria. The results show that the proposed BFGA is capable of\nfinding optimal designs that satisfy all the design requirements and\nconstraints. The proposed approach provides a promising solution for the\noptimization of complex structures with nonlinear behavior.",
      "tldr_zh": "本研究引入了改进的 Bilinear Fuzzy Genetic Algorithm (BFGA)，用于优化带有半刚性连接的钢结构设计，以平衡刚性和灵活性，同时应对连接非线性行为的挑战。BFGA 结合了模糊逻辑和 Genetic Algorithm (GA) 的优势，能够高效处理结构设计中的复杂性和不确定性，并比标准 GA 生成更高质量的解决方案。实验结果显示，该算法在优化钢结构的重量和性能标准时，成功找到满足所有设计要求和约束的最优设计，为处理非线性结构优化问题提供了有前景的方法。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "19 pages, 12 figures, book chapter, Springer",
      "pdf_url": "http://arxiv.org/pdf/2411.05865v1",
      "published_date": "2024-11-07 13:07:16 UTC",
      "updated_date": "2024-11-07 13:07:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:28:07.201906"
    },
    {
      "arxiv_id": "2411.05864v1",
      "title": "Boosting the Efficiency of Metaheuristics Through Opposition-Based Learning in Optimum Locating of Control Systems in Tall Buildings",
      "title_zh": "翻译失败",
      "authors": [
        "Salar Farahmand-Tabar",
        "Sina Shirgir"
      ],
      "abstract": "Opposition-based learning (OBL) is an effective approach to improve the\nperformance of metaheuristic optimization algorithms, which are commonly used\nfor solving complex engineering problems. This chapter provides a comprehensive\nreview of the literature on the use of opposition strategies in metaheuristic\noptimization algorithms, discussing the benefits and limitations of this\napproach. An overview of the opposition strategy concept, its various\nimplementations, and its impact on the performance of metaheuristic algorithms\nare presented. Furthermore, case studies on the application of opposition\nstrategies in engineering problems are provided, including the optimum locating\nof control systems in tall building. A shear frame with Magnetorheological (MR)\nfluid damper is considered as a case study. The results demonstrate that the\nincorporation of opposition strategies in metaheuristic algorithms\nsignificantly enhances the quality and speed of the optimization process. This\nchapter aims to provide a clear understanding of the opposition strategy in\nmetaheuristic optimization algorithms and its engineering applications, with\nthe ultimate goal of facilitating its adoption in real-world engineering\nproblems.",
      "tldr_zh": "本研究探讨了Opposition-based Learning (OBL)如何提升metaheuristic优化算法的效率，特别针对高层建筑控制系统的优化定位问题。通过对文献的全面回顾，介绍了OBL的概念、各种实现方式及其对算法性能的益处和局限性。案例研究以剪切框架和Magnetorheological (MR) fluid damper为例，证明了OBL显著提高了优化过程的质量和速度，最终促进了其在实际工程问题中的应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NE",
      "comment": "17 pages, 4 figures, book chapter, Springer",
      "pdf_url": "http://arxiv.org/pdf/2411.05864v1",
      "published_date": "2024-11-07 13:05:40 UTC",
      "updated_date": "2024-11-07 13:05:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:28:19.516030"
    },
    {
      "arxiv_id": "2411.04671v3",
      "title": "CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR",
      "title_zh": "翻译失败",
      "authors": [
        "Kadir Burak Buldu",
        "Süleyman Özdel",
        "Ka Hei Carrie Lau",
        "Mengdi Wang",
        "Daniel Saad",
        "Sofie Schönborn",
        "Auxane Boch",
        "Enkelejda Kasneci",
        "Efe Bozkir"
      ],
      "abstract": "Recent developments in computer graphics, machine learning, and sensor\ntechnologies enable numerous opportunities for extended reality (XR) setups for\neveryday life, from skills training to entertainment. With large corporations\noffering affordable consumer-grade head-mounted displays (HMDs), XR will likely\nbecome pervasive, and HMDs will develop as personal devices like smartphones\nand tablets. However, having intelligent spaces and naturalistic interactions\nin XR is as important as technological advances so that users grow their\nengagement in virtual and augmented spaces. To this end, large language model\n(LLM)--powered non-player characters (NPCs) with speech-to-text (STT) and\ntext-to-speech (TTS) models bring significant advantages over conventional or\npre-scripted NPCs for facilitating more natural conversational user interfaces\n(CUIs) in XR. This paper provides the community with an open-source,\ncustomizable, extendable, and privacy-aware Unity package, CUIfy, that\nfacilitates speech-based NPC-user interaction with widely used LLMs, STT, and\nTTS models. Our package also supports multiple LLM-powered NPCs per environment\nand minimizes latency between different computational models through streaming\nto achieve usable interactions between users and NPCs. We publish our source\ncode in the following repository: https://gitlab.lrz.de/hctl/cuify",
      "tldr_zh": "该论文介绍了 CUIfy，一个开源的 Unity 包，旨在将 LLM（大型语言模型）驱动的对话代理嵌入到 XR（扩展现实）环境中，以实现更自然的语音交互。CUIfy 通过整合 STT（语音到文本）和 TTS（文本到语音）模型，支持多 NPC（非玩家角色）在 XR 中的对话，并优化流式处理以最小化延迟，确保隐私和可扩展性。实验和设计表明，该包能提升用户在虚拟空间的参与度，为 XR 应用提供更智能且自然的 CUIs（对话用户界面）。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7th IEEE International Conference on Artificial Intelligence &\n  eXtended and Virtual Reality (IEEE AIxVR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.04671v3",
      "published_date": "2024-11-07 12:55:17 UTC",
      "updated_date": "2025-03-03 13:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:28:30.914924"
    },
    {
      "arxiv_id": "2411.04669v1",
      "title": "EffiCANet: Efficient Time Series Forecasting with Convolutional Attention",
      "title_zh": "EffiCANet：利用卷积注意力的高效时间序列预测",
      "authors": [
        "Xinxing Zhou",
        "Jiaqi Ye",
        "Shubao Zhao",
        "Ming Jin",
        "Chengyi Yang",
        "Yanlong Wen",
        "Xiaojie Yuan"
      ],
      "abstract": "The exponential growth of multivariate time series data from sensor networks\nin domains like industrial monitoring and smart cities requires efficient and\naccurate forecasting models. Current deep learning methods often fail to\nadequately capture long-range dependencies and complex inter-variable\nrelationships, especially under real-time processing constraints. These\nlimitations arise as many models are optimized for either short-term\nforecasting with limited receptive fields or long-term accuracy at the cost of\nefficiency. Additionally, dynamic and intricate interactions between variables\nin real-world data further complicate modeling efforts. To address these\nlimitations, we propose EffiCANet, an Efficient Convolutional Attention Network\ndesigned to enhance forecasting accuracy while maintaining computational\nefficiency. EffiCANet integrates three key components: (1) a Temporal\nLarge-kernel Decomposed Convolution (TLDC) module that captures long-term\ntemporal dependencies while reducing computational overhead; (2) an\nInter-Variable Group Convolution (IVGC) module that captures complex and\nevolving relationships among variables; and (3) a Global Temporal-Variable\nAttention (GTVA) mechanism that prioritizes critical temporal and\ninter-variable features. Extensive evaluations across nine benchmark datasets\nshow that EffiCANet achieves the maximum reduction of 10.02% in MAE over\nstate-of-the-art models, while cutting computational costs by 26.2% relative to\nconventional large-kernel convolution methods, thanks to its efficient\ndecomposition strategy.",
      "tldr_zh": "该研究针对多变量时间序列数据的预测问题，指出现有深度学习模型难以捕捉长程依赖和变量间复杂关系，同时面临实时处理效率挑战。EffiCANet 提出一种高效的卷积注意力网络，整合 Temporal Large-kernel Decomposed Convolution (TLDC) 模块以减少计算开销捕捉长程时间依赖、Inter-Variable Group Convolution (IVGC) 模块以处理变量间动态交互，以及 Global Temporal-Variable Attention (GTVA) 机制以优先关键特征。在九个基准数据集上的评估中，EffiCANet 比最先进模型降低了最多 10.02% 的 MAE，同时将计算成本相对于传统大核卷积方法减少了 26.2%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04669v1",
      "published_date": "2024-11-07 12:54:42 UTC",
      "updated_date": "2024-11-07 12:54:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:28:43.715763"
    },
    {
      "arxiv_id": "2411.04649v1",
      "title": "DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Zhang",
        "Vinay Setty",
        "Yumeng Wang",
        "Avishek Anand"
      ],
      "abstract": "With the rapid advancement of neural language models, the deployment of\nover-parameterized models has surged, increasing the need for interpretable\nexplanations comprehensible to human inspectors. Existing post-hoc\ninterpretability methods, which often focus on unigram features of single input\ntextual instances, fail to capture the models' decision-making process fully.\nAdditionally, many methods do not differentiate between decisions based on\nspurious correlations and those based on a holistic understanding of the input.\nOur paper introduces DISCO, a novel method for discovering global, rule-based\nexplanations by identifying causal n-gram associations with model predictions.\nThis method employs a scalable sequence mining technique to extract relevant\ntext spans from training data, associate them with model predictions, and\nconduct causality checks to distill robust rules that elucidate model behavior.\nThese rules expose potential overfitting and provide insights into misleading\nfeature combinations. We validate DISCO through extensive testing,\ndemonstrating its superiority over existing methods in offering comprehensive\ninsights into complex model behaviors. Our approach successfully identifies all\nshortcuts manually introduced into the training data (100% detection rate on\nthe MultiRC dataset), resulting in an 18.8% regression in model performance --\na capability unmatched by any other method. Furthermore, DISCO supports\ninteractive explanations, enabling human inspectors to distinguish spurious\ncauses in the rule-based output. This alleviates the burden of abundant\ninstance-wise explanations and helps assess the model's risk when encountering\nout-of-distribution (OOD) data.",
      "tldr_zh": "本研究提出DISCO，一种新颖的方法，用于发现文本分类模型中的过拟合问题，通过识别模型预测的因果n-gram关联来生成全局、基于规则的解释。DISCO采用可扩展的序列挖掘技术，从训练数据中提取相关文本片段，并进行因果性检查，以提炼鲁棒规则，这些规则能揭示潜在的虚假相关性和误导特征组合。实验结果显示，DISCO在MultiRC数据集上实现了100%的捷径检测率，导致模型性能下降18.8%，并支持交互式解释，帮助人类检查员评估模型在OOD数据下的风险，从而优于现有可解释性方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.3; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04649v1",
      "published_date": "2024-11-07 12:12:44 UTC",
      "updated_date": "2024-11-07 12:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:28:55.078715"
    },
    {
      "arxiv_id": "2411.04644v1",
      "title": "wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan F. Carter",
        "Lionel Tarassenko"
      ],
      "abstract": "Accurate classification of sleep stages from less obtrusive sensor\nmeasurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)\ncould enable important applications in sleep medicine. Existing approaches to\nthis problem have typically used deep learning models designed and trained to\noperate on one or more specific input signals. However, the datasets used to\ndevelop these models often do not contain the same sets of input signals. Some\nsignals, particularly PPG, are much less prevalent than others, and this has\npreviously been addressed with techniques such as transfer learning.\nAdditionally, only training on one or more fixed modalities precludes\ncross-modal information transfer from other sources, which has proved valuable\nin other problem domains. To address this, we introduce wav2sleep, a unified\nmodel designed to operate on variable sets of input signals during training and\ninference. After jointly training on over 10,000 overnight recordings from six\npublicly available polysomnography datasets, including SHHS and MESA, wav2sleep\noutperforms existing sleep stage classification models across test-time input\ncombinations including ECG, PPG, and respiratory signals.",
      "tldr_zh": "本文提出 wav2sleep，一种统一的 multi-modal 模型，用于从生理信号（如 ECG 和 PPG）准确分类睡眠阶段，解决了现有方法在处理信号不一致和跨模态信息转移方面的局限性。该模型支持训练和推理时的可变输入信号集，并在六个公开数据集（如 SHHS 和 MESA）上联合训练超过 10,000 个过夜记录。实验结果表明，wav2sleep 在测试时处理 ECG、PPG 和呼吸信号等组合时，优于现有睡眠阶段分类模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Machine Learning for Health (ML4H) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04644v1",
      "published_date": "2024-11-07 12:01:36 UTC",
      "updated_date": "2024-11-07 12:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:29:07.257603"
    },
    {
      "arxiv_id": "2411.15149v1",
      "title": "The Fundamental Rights Impact Assessment (FRIA) in the AI Act: Roots, legal obligations and key elements for a model template",
      "title_zh": "AI Act 中的基本权利影响评估 (FRIA)：根源、法律义务以及模型模板的关键元素",
      "authors": [
        "Alessandro Mantelero"
      ],
      "abstract": "What is the context which gave rise to the obligation to carry out a\nFundamental Rights Impact Assessment (FRIA) in the AI Act? How has assessment\nof the impact on fundamental rights been framed by the EU legislator in the AI\nAct? What methodological criteria should be followed in developing the FRIA?\nThese are the three main research questions that this article aims to address,\nthrough both legal analysis of the relevant provisions of the AI Act and\ndiscussion of various possible models for assessment of the impact of AI on\nfundamental rights. The overall objective of this article is to fill existing\ngaps in the theoretical and methodological elaboration of the FRIA, as outlined\nin the AI Act. In order to facilitate the future work of EU and national bodies\nand AI operators in placing this key tool for human-centric and trustworthy AI\nat the heart of the EU approach to AI design and development, this article\noutlines the main building blocks of a model template for the FRIA. While this\nproposal is consistent with the rationale and scope of the AI Act, it is also\napplicable beyond the cases listed in Article 27 and can serve as a blueprint\nfor other national and international regulatory initiatives to ensure that AI\nis fully consistent with human rights.",
      "tldr_zh": "这篇文章探讨了欧盟 AI Act 中 Fundamental Rights Impact Assessment (FRIA) 的起源、法律义务以及关键元素，旨在回答 FRIA 的背景、框架和方法论标准。作者通过法律分析和评估模型的讨论，填补了 FRIA 在理论和方法上的空白。最终，该文提出一个模型模板的核心构建块，不仅适用于 AI Act 第 27 条规定的场景，还可扩展到其他国家和国际 AI 监管举措，以确保 AI 符合人权标准。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15149v1",
      "published_date": "2024-11-07 11:55:55 UTC",
      "updated_date": "2024-11-07 11:55:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:29:18.539972"
    },
    {
      "arxiv_id": "2411.04642v1",
      "title": "TAP-VL: Text Layout-Aware Pre-training for Enriched Vision-Language Models",
      "title_zh": "TAP-V",
      "authors": [
        "Jonathan Fhima",
        "Elad Ben Avraham",
        "Oren Nuriel",
        "Yair Kittenplon",
        "Roy Ganz",
        "Aviad Aberdam",
        "Ron Litman"
      ],
      "abstract": "Vision-Language (VL) models have garnered considerable research interest;\nhowever, they still face challenges in effectively handling text within images.\nTo address this limitation, researchers have developed two approaches. The\nfirst method involves utilizing external Optical Character Recognition (OCR)\ntools to extract textual information from images, which is then prepended to\nother textual inputs. The second strategy focuses on employing extremely\nhigh-resolution images to improve text recognition capabilities. In this paper,\nwe focus on enhancing the first strategy by introducing a novel method, named\nTAP-VL, which treats OCR information as a distinct modality and seamlessly\nintegrates it into any VL model. TAP-VL employs a lightweight transformer-based\nOCR module to receive OCR with layout information, compressing it into a short\nfixed-length sequence for input into the LLM. Initially, we conduct\nmodel-agnostic pretraining of the OCR module on unlabeled documents, followed\nby its integration into any VL architecture through brief fine-tuning.\nExtensive experiments demonstrate consistent performance improvements when\napplying TAP-VL to top-performing VL models, across scene-text and\ndocument-based VL benchmarks.",
      "tldr_zh": "本文提出 TAP-VL，一种文本布局感知预训练方法，用于增强 Vision-Language (VL) 模型处理图像中文本的能力。TAP-VL 将 Optical Character Recognition (OCR) 信息视为独立模态，使用轻量级 transformer-based OCR 模块处理带布局信息的文本，并将其压缩成固定长度序列输入到 LLM 中。论文先在无标签文档上进行模型无关预训练，然后通过简短微调集成到任何 VL 架构中；实验结果显示，TAP-VL 显著提升了顶级 VL 模型在场景文本和文档基准上的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04642v1",
      "published_date": "2024-11-07 11:54:01 UTC",
      "updated_date": "2024-11-07 11:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:29:31.817916"
    },
    {
      "arxiv_id": "2411.04594v2",
      "title": "Verification of Neural Networks against Convolutional Perturbations via Parameterised Kernels",
      "title_zh": "通过参数化内核验证神经网络对抗卷积扰动",
      "authors": [
        "Benedikt Brückner",
        "Alessio Lomuscio"
      ],
      "abstract": "We develop a method for the efficient verification of neural networks against\nconvolutional perturbations such as blurring or sharpening. To define input\nperturbations we use well-known camera shake, box blur and sharpen kernels. We\ndemonstrate that these kernels can be linearly parameterised in a way that\nallows for a variation of the perturbation strength while preserving desired\nkernel properties. To facilitate their use in neural network verification, we\ndevelop an efficient way of convolving a given input with these parameterised\nkernels. The result of this convolution can be used to encode the perturbation\nin a verification setting by prepending a linear layer to a given network. This\nleads to tight bounds and a high effectiveness in the resulting verification\nstep. We add further precision by employing input splitting as a branch and\nbound strategy. We demonstrate that we are able to verify robustness on a\nnumber of standard benchmarks where the baseline is unable to provide any\nsafety certificates. To the best of our knowledge, this is the first solution\nfor verifying robustness against specific convolutional perturbations such as\ncamera shake.",
      "tldr_zh": "这篇论文提出了一种高效方法，用于验证neural networks对convolutional perturbations（如camera shake、box blur和sharpen kernels）的鲁棒性，通过线性parameterised kernels来调整扰动强度并保持核属性。方法包括高效卷积输入、添加线性层以编码扰动，并采用输入分割作为分支和边界策略，以获得更精确的验证边界。在标准基准测试中，该方法成功提供了安全证书，而基线模型无法实现，这是首个针对特定convolutional perturbations的鲁棒性验证解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.04594v2",
      "published_date": "2024-11-07 10:25:20 UTC",
      "updated_date": "2025-02-17 19:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:29:43.552853"
    },
    {
      "arxiv_id": "2411.04588v1",
      "title": "Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Ahlam Alrehili",
        "Areej Alhothali"
      ],
      "abstract": "Natural language processing (NLP) utilizes text data augmentation to overcome\nsample size constraints. Increasing the sample size is a natural and widely\nused strategy for alleviating these challenges. In this study, we chose Arabic\nto increase the sample size and correct grammatical errors. Arabic is\nconsidered one of the languages with limited resources for grammatical error\ncorrection (GEC). Furthermore, QALB-14 and QALB-15 are the only datasets used\nin most Arabic grammatical error correction research, with approximately 20,500\nparallel examples, which is considered low compared with other languages.\nTherefore, this study aims to develop an Arabic corpus called \"Tibyan\" for\ngrammatical error correction using ChatGPT. ChatGPT is used as a data augmenter\ntool based on a pair of Arabic sentences containing grammatical errors matched\nwith a sentence free of errors extracted from Arabic books, called guide\nsentences. Multiple steps were involved in establishing our corpus, including\nthe collection and pre-processing of a pair of Arabic texts from various\nsources, such as books and open-access corpora. We then used ChatGPT to\ngenerate a parallel corpus based on the text collected previously, as a guide\nfor generating sentences with multiple types of errors. By engaging linguistic\nexperts to review and validate the automatically generated sentences, we\nensured that they were correct and error-free. The corpus was validated and\nrefined iteratively based on feedback provided by linguistic experts to improve\nits accuracy. Finally, we used the Arabic Error Type Annotation tool (ARETA) to\nanalyze the types of errors in the Tibyan corpus. Our corpus contained 49 of\nerrors, including seven types: orthography, morphology, syntax, semantics,\npunctuation, merge, and split. The Tibyan corpus contains approximately 600 K\ntokens.",
      "tldr_zh": "本研究针对阿拉伯语语法错误修正（GEC）的资源不足问题，开发了名为 Tibyan 的语料库，使用 ChatGPT 作为数据增强工具，从阿拉伯书籍中提取正确句子作为指导，生成带有多种错误的平行句子，并由语言专家进行审查和迭代验证。Tibyan 语料库包含约 600K tokens，覆盖 49 种错误，包括 orthography、morphology、syntax、semantics、punctuation、merge 和 split 等七大类型，比现有的 QALB-14 和 QALB-15 语料库（约 20,500 个示例）更全面平衡。最终，使用 ARETA 工具分析了错误类型，该语料库有助于提升阿拉伯语 NLP 任务的样本规模和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.04588v1",
      "published_date": "2024-11-07 10:17:40 UTC",
      "updated_date": "2024-11-07 10:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:29:56.688914"
    },
    {
      "arxiv_id": "2411.04586v2",
      "title": "On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data",
      "title_zh": "翻译失败",
      "authors": [
        "Aitor Martinez-Seras",
        "Javier Del Ser",
        "Aitzol Olivares-Rad",
        "Alain Andres",
        "Pablo Garcia-Bringas"
      ],
      "abstract": "Robustness is a fundamental aspect for developing safe and trustworthy\nmodels, particularly when they are deployed in the open world. In this work we\nanalyze the inherent capability of one-stage object detectors to robustly\noperate in the presence of out-of-distribution (OoD) data. Specifically, we\npropose a novel detection algorithm for detecting unknown objects in image\ndata, which leverages the features extracted by the model from each sample.\nDifferently from other recent approaches in the literature, our proposal does\nnot require retraining the object detector, thereby allowing for the use of\npretrained models. Our proposed OoD detector exploits the application of\nsupervised dimensionality reduction techniques to mitigate the effects of the\ncurse of dimensionality on the features extracted by the model. Furthermore, it\nutilizes high-resolution feature maps to identify potential unknown objects in\nan unsupervised fashion. Our experiments analyze the Pareto trade-off between\nthe performance detecting known and unknown objects resulting from different\nalgorithmic configurations and inference confidence thresholds. We also compare\nthe performance of our proposed algorithm to that of logits-based post-hoc OoD\nmethods, as well as possible fusion strategies. Finally, we discuss on the\ncompetitiveness of all tested methods against state-of-the-art OoD approaches\nfor object detection models over the recently published Unknown Object\nDetection benchmark. The obtained results verify that the performance of\navant-garde post-hoc OoD detectors can be further improved when combined with\nour proposed algorithm.",
      "tldr_zh": "本文研究了 One-Stage Object Detection 模型在面对 Out-of-Distribution (OoD) 数据时的固有鲁棒性，提出了一种新型检测算法，利用模型提取的特征来识别未知对象，而无需重新训练预训练模型。算法通过监督维数减少技术缓解维数灾难的影响，并利用高分辨率特征图在无监督方式下定位潜在未知对象。实验分析了不同配置和置信度阈值下的已知与未知对象检测性能权衡，并证明该算法与现有后处理 OoD 方法结合后，在 Unknown Object Detection 基准上显著提升了整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T45, 68T07",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "13 figures, 4 tables, under review",
      "pdf_url": "http://arxiv.org/pdf/2411.04586v2",
      "published_date": "2024-11-07 10:15:25 UTC",
      "updated_date": "2025-02-04 20:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:30:07.471792"
    },
    {
      "arxiv_id": "2411.04580v1",
      "title": "Interpreting the Learned Model in MuZero Planning",
      "title_zh": "解读 MuZero 规划中的学习模型",
      "authors": [
        "Hung Guei",
        "Yan-Ru Ju",
        "Wei-Yu Chen",
        "Ti-Rong Wu"
      ],
      "abstract": "MuZero has achieved superhuman performance in various games by using a\ndynamics network to predict environment dynamics for planning, without relying\non simulators. However, the latent states learned by the dynamics network make\nits planning process opaque. This paper aims to demystify MuZero's model by\ninterpreting the learned latent states. We incorporate observation\nreconstruction and state consistency into MuZero training and conduct an\nin-depth analysis to evaluate latent states across two board games: 9x9 Go and\nOuter-Open Gomoku, and three Atari games: Breakout, Ms. Pacman, and Pong. Our\nfindings reveal that while the dynamics network becomes less accurate over\nlonger simulations, MuZero still performs effectively by using planning to\ncorrect errors. Our experiments also show that the dynamics network learns\nbetter latent states in board games than in Atari games. These insights\ncontribute to a better understanding of MuZero and offer directions for future\nresearch to improve the playing performance, robustness, and interpretability\nof the MuZero algorithm.",
      "tldr_zh": "这篇论文旨在解释 MuZero 规划中的学习模型，特别是动态网络的潜在状态，以提升其透明度。通过将观察重建和状态一致性整合到 MuZero 训练中，作者对 9x9 Go、Outer-Open Gomoku 和 Atari 游戏（如 Breakout、Ms. Pacman、Pong）进行了深入分析。结果显示，动态网络在较长模拟中准确性下降，但 MuZero 通过规划机制修正错误，并在棋盘游戏中学习更有效的潜在状态。这些发现有助于更好地理解 MuZero，并为改进其性能、鲁棒性和可解释性提供未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the 29th International Conference on Technologies and\n  Applications of Artificial Intelligence (TAAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.04580v1",
      "published_date": "2024-11-07 10:06:23 UTC",
      "updated_date": "2024-11-07 10:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:30:20.436581"
    },
    {
      "arxiv_id": "2411.04578v1",
      "title": "Multi-Agents are Social Groups: Investigating Social Influence of Multiple Agents in Human-Agent Interactions",
      "title_zh": "多智能体即社会群体：调查多个智能体在人-智能体互动中的社会影响",
      "authors": [
        "Tianqi Song",
        "Yugin Tan",
        "Zicheng Zhu",
        "Yibin Feng",
        "Yi-Chieh Lee"
      ],
      "abstract": "Multi-agent systems - systems with multiple independent AI agents working\ntogether to achieve a common goal - are becoming increasingly prevalent in\ndaily life. Drawing inspiration from the phenomenon of human group social\ninfluence, we investigate whether a group of AI agents can create social\npressure on users to agree with them, potentially changing their stance on a\ntopic. We conducted a study in which participants discussed social issues with\neither a single or multiple AI agents, and where the agents either agreed or\ndisagreed with the user's stance on the topic. We found that conversing with\nmultiple agents (holding conversation content constant) increased the social\npressure felt by participants, and caused a greater shift in opinion towards\nthe agents' stances on each topic. Our study shows the potential advantages of\nmulti-agent systems over single-agent platforms in causing opinion change. We\ndiscuss design implications for possible multi-agent systems that promote\nsocial good, as well as the potential for malicious actors to use these systems\nto manipulate public opinion.",
      "tldr_zh": "这篇论文研究了多智能体系统(multi-agent systems)对人类意见的影响，探讨多个AI代理是否能像人类社会群体一样施加社会压力，促使用户改变立场。研究通过实验让参与者与单个或多个AI代理讨论社会问题，结果发现，与多个代理对话（内容保持不变）会增加参与者感受到的社会压力，并导致更大程度上的意见转变。论文强调，多智能体系统比单智能体平台更有效在引起意见改变，并讨论了其设计含义，包括用于促进社会公益的潜力以及防范恶意演员操纵公众意见的风险。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04578v1",
      "published_date": "2024-11-07 10:00:46 UTC",
      "updated_date": "2024-11-07 10:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:30:31.746763"
    },
    {
      "arxiv_id": "2411.04573v1",
      "title": "Multistage Fine-tuning Strategies for Automatic Speech Recognition in Low-resource Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Leena G Pillai",
        "Kavya Manohar",
        "Basil K Raju",
        "Elizabeth Sherly"
      ],
      "abstract": "This paper presents a novel multistage fine-tuning strategy designed to\nenhance automatic speech recognition (ASR) performance in low-resource\nlanguages using OpenAI's Whisper model. In this approach we aim to build ASR\nmodel for languages with limited digital resources by sequentially adapting the\nmodel across linguistically similar languages. We experimented this on the\nMalasar language, a Dravidian language spoken by approximately ten thousand\npeople in the Western Ghats of South India. Malasar language faces critical\nchallenges for technological intervention due to its lack of a native script\nand absence of digital or spoken data resources. Working in collaboration with\nWycliffe India and Malasar community members, we created a spoken Malasar\ncorpus paired with transcription in Tamil script, a closely related major\nlanguage. In our approach to build ASR model for Malasar, we first build an\nintermediate Tamil ASR, leveraging higher data availability for Tamil annotated\nspeech. This intermediate model is subsequently fine-tuned on Malasar data,\nallowing for more effective ASR adaptation despite limited resources. The\nmultistage fine-tuning strategy demonstrated significant improvements over\ndirect fine-tuning on Malasar data alone, achieving a word error rate (WER) of\n51.9%, which is 4.5% absolute reduction when compared to the direct fine-tuning\nmethod. Further a WER reduction to 47.3% was achieved through punctuation\nremoval in post-processing, which addresses formatting inconsistencies that\nimpact evaluation. Our results underscore the effectiveness of sequential\nmultistage fine-tuning combined with targeted post-processing as a scalable\nstrategy for ASR system development in low-resource languages, especially where\nlinguistic similarities can be leveraged to bridge gaps in training data.",
      "tldr_zh": "本论文提出了一种多阶段微调策略，用于提升低资源语言的 Automatic Speech Recognition (ASR) 性能，基于 OpenAI's Whisper 模型，通过顺序适应语言上相似的语言来构建 ASR 系统。研究团队针对 Malasar 语言（一种 Dravidian 语言）进行了实验，与社区合作创建了口语语料库，并使用 Tamil 脚本进行转录，先构建 Tamil ASR 模型再微调到 Malasar 数据。结果显示，该策略比直接微调降低了 Word Error Rate (WER) 4.5%，达到 51.9%，而通过后处理去除标点进一步降至 47.3%。这一方法证明了利用语言相似性进行顺序微调的可扩展性，为低资源语言的 ASR 系统开发提供了有效途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04573v1",
      "published_date": "2024-11-07 09:57:57 UTC",
      "updated_date": "2024-11-07 09:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:30:44.536265"
    },
    {
      "arxiv_id": "2411.04569v1",
      "title": "Impact of Label Noise on Learning Complex Features",
      "title_zh": "标签噪声对学习复杂特征的影响",
      "authors": [
        "Rahul Vashisht",
        "P. Krishna Kumar",
        "Harsha Vardhan Govind",
        "Harish G. Ramaswamy"
      ],
      "abstract": "Neural networks trained with stochastic gradient descent exhibit an inductive\nbias towards simpler decision boundaries, typically converging to a narrow\nfamily of functions, and often fail to capture more complex features. This\nphenomenon raises concerns about the capacity of deep models to adequately\nlearn and represent real-world datasets. Traditional approaches such as\nexplicit regularization, data augmentation, architectural modifications, etc.,\nhave largely proven ineffective in encouraging the models to learn diverse\nfeatures. In this work, we investigate the impact of pre-training models with\nnoisy labels on the dynamics of SGD across various architectures and datasets.\nWe show that pretraining promotes learning complex functions and diverse\nfeatures in the presence of noise. Our experiments demonstrate that\npre-training with noisy labels encourages gradient descent to find alternate\nminima that do not solely depend upon simple features, rather learns more\ncomplex and broader set of features, without hurting performance.",
      "tldr_zh": "神经网络在使用随机梯度下降(SGD)训练时，通常偏向于简单决策边界，导致难以捕捉复杂特征，从而影响对真实世界数据集的学习。传统方法如显式正则化或数据增强未能有效解决这一问题，本文通过研究噪声标签预训练对SGD动态的影响，探索了在各种架构和数据集上的效果。结果表明，预训练带有噪声标签能促使模型学习更复杂和多样特征，帮助SGD找到替代最小值，同时不降低整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Workshop on Scientific Methods for Understanding Deep\n  Learning, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04569v1",
      "published_date": "2024-11-07 09:47:18 UTC",
      "updated_date": "2024-11-07 09:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:30:56.079628"
    },
    {
      "arxiv_id": "2411.04564v1",
      "title": "A Generalisation of Voter Model: Influential Nodes and Convergence Properties",
      "title_zh": "投票模型的泛化：影响节点和收敛性质",
      "authors": [
        "Abhiram Manohara",
        "Ahad N. Zehmakan"
      ],
      "abstract": "Consider an undirected graph G, representing a social network, where each\nnode is blue or red, corresponding to positive or negative opinion on a topic.\nIn the voter model, in discrete time rounds, each node picks a neighbour\nuniformly at random and adopts its colour. Despite its significant popularity,\nthis model does not capture some fundamental real-world characteristics such as\nthe difference in the strengths of individuals connections, individuals with\nneutral opinion on a topic, and individuals who are reluctant to update their\nopinion. To address these issues, we introduce and study a generalisation of\nthe voter model. Motivating by campaigning strategies, we study the problem of\nselecting a set of seeds blue nodes to maximise the expected number of blue\nnodes after some rounds. We prove that the problem is NP- hard and provide a\npolynomial time approximation algorithm with the best possible approximation\nguarantee. Our experiments on real-world and synthetic graph data demonstrate\nthat the proposed algorithm outperforms other algorithms. We also investigate\nthe convergence properties of the model. We prove that the process could take\nan exponential number of rounds to converge. However, if we limit ourselves to\nstrongly connected graphs, the convergence time is polynomial and the period\n(the number of states in convergence) divides the length of all cycles in the\ngraph.",
      "tldr_zh": "本论文对 Voter Model 进行了泛化，引入一个新模型来处理社交网络中连接强度、中立意见和意见更新 reluctance 等现实特性，旨在模拟更真实的意见传播过程。研究者证明了选择种子节点（blue nodes）以最大化预期蓝节点数量的问题是 NP-hard，并提出一个多项式时间近似算法，具有最佳近似保证；实验结果显示，该算法在真实和合成图数据上优于其他算法。此外，论文分析了模型的收敛性质，证明在一般图中收敛可能需指数轮次，但在 strongly connected graphs 中，收敛时间为多项式，且周期与图中循环长度相关。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04564v1",
      "published_date": "2024-11-07 09:38:42 UTC",
      "updated_date": "2024-11-07 09:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:31:07.270725"
    },
    {
      "arxiv_id": "2411.04562v2",
      "title": "Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning",
      "title_zh": "受约束的潜在动作策略用于基于模型的离线强化学习",
      "authors": [
        "Marvin Alles",
        "Philip Becker-Ehmck",
        "Patrick van der Smagt",
        "Maximilian Karl"
      ],
      "abstract": "In offline reinforcement learning, a policy is learned using a static dataset\nin the absence of costly feedback from the environment. In contrast to the\nonline setting, only using static datasets poses additional challenges, such as\npolicies generating out-of-distribution samples. Model-based offline\nreinforcement learning methods try to overcome these by learning a model of the\nunderlying dynamics of the environment and using it to guide policy search. It\nis beneficial but, with limited datasets, errors in the model and the issue of\nvalue overestimation among out-of-distribution states can worsen performance.\nCurrent model-based methods apply some notion of conservatism to the Bellman\nupdate, often implemented using uncertainty estimation derived from model\nensembles. In this paper, we propose Constrained Latent Action Policies (C-LAP)\nwhich learns a generative model of the joint distribution of observations and\nactions. We cast policy learning as a constrained objective to always stay\nwithin the support of the latent action distribution, and use the generative\ncapabilities of the model to impose an implicit constraint on the generated\nactions. Thereby eliminating the need to use additional uncertainty penalties\non the Bellman update and significantly decreasing the number of gradient steps\nrequired to learn a policy. We empirically evaluate C-LAP on the D4RL and\nV-D4RL benchmark, and show that C-LAP is competitive to state-of-the-art\nmethods, especially outperforming on datasets with visual observations.",
      "tldr_zh": "本研究针对模型-based offline reinforcement learning 的挑战，提出 Constrained Latent Action Policies (C-LAP) 方法，该方法通过学习观察和动作的联合分布生成模型，将策略学习设置为约束目标，确保生成的动作始终在潜在动作分布的支持内。\nC-LAP 利用模型的生成能力施加隐式约束，消除了对 Bellman update 的额外不确定性惩罚，并显著减少了训练所需的梯度步骤。\n实验结果显示，在 D4RL 和 V-D4RL 基准上，C-LAP 与最先进方法相当，尤其在视觉观察数据集上表现出优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.04562v2",
      "published_date": "2024-11-07 09:35:22 UTC",
      "updated_date": "2025-01-15 13:24:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:31:20.005227"
    },
    {
      "arxiv_id": "2411.04555v2",
      "title": "An Axiomatic Study of the Evaluation of Enthymeme Decoding in Weighted Structured Argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Ben-Naim",
        "Victor David",
        "Anthony Hunter"
      ],
      "abstract": "An argument can be seen as a pair consisting of a set of premises and a claim\nsupported by them. Arguments used by humans are often enthymemes, i.e., some\npremises are implicit. To better understand, evaluate, and compare enthymemes,\nit is essential to decode them, i.e., to find the missing premisses. Many\nenthymeme decodings are possible. We need to distinguish between reasonable\ndecodings and unreasonable ones. However, there is currently no research in the\nliterature on \"How to evaluate decodings?\". To pave the way and achieve this\ngoal, we introduce seven criteria related to decoding, based on different\nresearch areas. Then, we introduce the notion of criterion measure, the\nobjective of which is to evaluate a decoding with regard to a certain\ncriterion. Since such measures need to be validated, we introduce several\ndesirable properties for them, called axioms. Another main contribution of the\npaper is the construction of certain criterion measures that are validated by\nour axioms. Such measures can be used to identify the best enthymemes\ndecodings.",
      "tldr_zh": "本论文研究了在加权结构化论证（weighted structured argumentation）中对隐喻（enthymeme）解码的评估问题，旨在区分合理的解码方式。作者引入了七个基于不同研究领域的标准，并定义了标准测量（criterion measure）来评估解码的合理性。为了验证这些测量，论文提出了若干期望属性，称为公理（axioms），并构建了符合这些公理的特定测量方法。这些贡献可用于识别最佳的隐喻解码，从而提升对人类论证的理解和比较。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.04555v2",
      "published_date": "2024-11-07 09:26:54 UTC",
      "updated_date": "2024-11-13 09:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:31:31.418139"
    },
    {
      "arxiv_id": "2411.04549v1",
      "title": "Vision Language Models are In-Context Value Learners",
      "title_zh": "视觉语言模型是基于上下文的价值学习者",
      "authors": [
        "Yecheng Jason Ma",
        "Joey Hejna",
        "Ayzaan Wahid",
        "Chuyuan Fu",
        "Dhruv Shah",
        "Jacky Liang",
        "Zhuo Xu",
        "Sean Kirmani",
        "Peng Xu",
        "Danny Driess",
        "Ted Xiao",
        "Jonathan Tompson",
        "Osbert Bastani",
        "Dinesh Jayaraman",
        "Wenhao Yu",
        "Tingnan Zhang",
        "Dorsa Sadigh",
        "Fei Xia"
      ],
      "abstract": "Predicting temporal progress from visual trajectories is important for\nintelligent robots that can learn, adapt, and improve. However, learning such\nprogress estimator, or temporal value function, across different tasks and\ndomains requires both a large amount of diverse data and methods which can\nscale and generalize. To address these challenges, we present Generative Value\nLearning (\\GVL), a universal value function estimator that leverages the world\nknowledge embedded in vision-language models (VLMs) to predict task progress.\nNaively asking a VLM to predict values for a video sequence performs poorly due\nto the strong temporal correlation between successive frames. Instead, GVL\nposes value estimation as a temporal ordering problem over shuffled video\nframes; this seemingly more challenging task encourages VLMs to more fully\nexploit their underlying semantic and temporal grounding capabilities to\ndifferentiate frames based on their perceived task progress, consequently\nproducing significantly better value predictions. Without any robot or task\nspecific training, GVL can in-context zero-shot and few-shot predict effective\nvalues for more than 300 distinct real-world tasks across diverse robot\nplatforms, including challenging bimanual manipulation tasks. Furthermore, we\ndemonstrate that GVL permits flexible multi-modal in-context learning via\nexamples from heterogeneous tasks and embodiments, such as human videos. The\ngenerality of GVL enables various downstream applications pertinent to\nvisuomotor policy learning, including dataset filtering, success detection, and\nadvantage-weighted regression -- all without any model training or finetuning.",
      "tldr_zh": "这篇论文提出 Generative Value Learning (GVL)，一种利用 Vision Language Models (VLMs) 的框架，用于预测视觉轨迹中的任务进展，从而帮助智能机器人学习和适应多任务环境。GVL 通过将值估计转化为对打乱视频帧的时序排序问题，充分利用 VLMs 的语义和时间 grounding 能力，显著提升预测准确性，而非直接处理帧间相关性。实验结果显示，GVL 无需特定训练即可零样本或少样本预测超过 300 个真实世界任务的值，支持多模态 in-context learning，如从人类视频中学习。最终，GVL 应用于 visuomotor 政策学习的下游任务，包括数据集过滤、成功检测和优势加权回归，提供了一个通用的、可扩展的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website and demo:\n  https://generative-value-learning.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.04549v1",
      "published_date": "2024-11-07 09:17:50 UTC",
      "updated_date": "2024-11-07 09:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:31:45.027824"
    },
    {
      "arxiv_id": "2411.05862v1",
      "title": "From Electrode to Global Brain: Integrating Multi- and Cross-Scale Brain Connections and Interactions Under Cross-Subject and Within-Subject Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Zhige",
        "Qin Chengxuan"
      ],
      "abstract": "The individual variabilities of electroencephalogram signals pose great\nchallenges to cross-subject motor imagery (MI) classification, especially for\nthe data-scarce single-source to single-target (STS) scenario. The multi-scale\nspatial data distribution differences can not be fully eliminated in MI\nexperiments for the topological structure and connection are the inherent\nproperties of the human brain. Overall, no literature investigates the\nmulti-scale spatial data distribution problem in STS cross-subject MI\nclassification task, neither intra-subject nor inter-subject scenarios. In this\npaper, a novel multi-scale spatial domain adaptation network (MSSDAN) consists\nof both multi-scale spatial feature extractor (MSSFE) and deep domain\nadaptation method called multi-scale spatial domain adaptation (MSSDA) is\nproposed and verified, our goal is to integrate the principles of multi-scale\nbrain topological structures in order to solve the multi-scale spatial data\ndistribution difference problem.",
      "tldr_zh": "本论文针对 EEG 信号的个体变异性在跨主体运动想象 (MI) 分类中的挑战，特别是数据稀缺的单源到单目标 (STS) 场景，提出了多尺度空间域适应网络 (MSSDAN)。MSSDAN 由多尺度空间特征提取器 (MSSFE) 和多尺度空间域适应 (MSSDA) 组成，用于整合多尺度脑拓扑结构，解决多尺度空间数据分布差异问题。实验验证了该方法在跨主体和 intra-subject 场景下的有效性，为 EEG 信号处理提供新途径。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05862v1",
      "published_date": "2024-11-07 09:12:13 UTC",
      "updated_date": "2024-11-07 09:12:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:31:56.219078"
    },
    {
      "arxiv_id": "2411.04547v1",
      "title": "Dynamic Detection of Relevant Objectives and Adaptation to Preference Drifts in Interactive Evolutionary Multi-Objective Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mahdi Shavarani",
        "Mahmoud Golabi",
        "Richard Allmendinger",
        "Lhassane Idoumghar"
      ],
      "abstract": "Evolutionary Multi-Objective Optimization Algorithms (EMOAs) are widely\nemployed to tackle problems with multiple conflicting objectives. Recent\nresearch indicates that not all objectives are equally important to the\ndecision-maker (DM). In the context of interactive EMOAs, preference\ninformation elicited from the DM during the optimization process can be\nleveraged to identify and discard irrelevant objectives, a crucial step when\nobjective evaluations are computationally expensive. However, much of the\nexisting literature fails to account for the dynamic nature of DM preferences,\nwhich can evolve throughout the decision-making process and affect the\nrelevance of objectives. This study addresses this limitation by simulating\ndynamic shifts in DM preferences within a ranking-based interactive algorithm.\nAdditionally, we propose methods to discard outdated or conflicting preferences\nwhen such shifts occur. Building on prior research, we also introduce a\nmechanism to safeguard relevant objectives that may become trapped in local or\nglobal optima due to the diminished correlation with the DM-provided rankings.\nOur experimental results demonstrate that the proposed methods effectively\nmanage evolving preferences and significantly enhance the quality and\ndesirability of the solutions produced by the algorithm.",
      "tldr_zh": "该研究针对进化多目标优化算法 (EMOAs) 中决策者 (DM) 偏好的动态变化问题，提出了一种交互式方法，能够动态检测相关目标并适应偏好漂移。通过模拟 DM 偏好变化并在基于排名的交互算法中应用，该方法允许丢弃过时的或冲突的偏好，同时引入机制保护可能陷入局部或全局最优的相关目标。实验结果显示，这些改进显著提升了算法产出解决方案的质量和可取性，使其更适用于实际决策场景。",
      "categories": [
        "cs.AI",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04547v1",
      "published_date": "2024-11-07 09:09:06 UTC",
      "updated_date": "2024-11-07 09:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:32:06.989728"
    },
    {
      "arxiv_id": "2411.05051v1",
      "title": "Intellectual Property Protection for Deep Learning Model and Dataset Intelligence",
      "title_zh": "深度学习模型和数据集智能的知识产权保护",
      "authors": [
        "Yongqi Jiang",
        "Yansong Gao",
        "Chunyi Zhou",
        "Hongsheng Hu",
        "Anmin Fu",
        "Willy Susilo"
      ],
      "abstract": "With the growing applications of Deep Learning (DL), especially recent\nspectacular achievements of Large Language Models (LLMs) such as ChatGPT and\nLLaMA, the commercial significance of these remarkable models has soared.\nHowever, acquiring well-trained models is costly and resource-intensive. It\nrequires a considerable high-quality dataset, substantial investment in\ndedicated architecture design, expensive computational resources, and efforts\nto develop technical expertise. Consequently, safeguarding the Intellectual\nProperty (IP) of well-trained models is attracting increasing attention. In\ncontrast to existing surveys overwhelmingly focusing on model IPP mainly, this\nsurvey not only encompasses the protection on model level intelligence but also\nvaluable dataset intelligence. Firstly, according to the requirements for\neffective IPP design, this work systematically summarizes the general and\nscheme-specific performance evaluation metrics. Secondly, from proactive IP\ninfringement prevention and reactive IP ownership verification perspectives, it\ncomprehensively investigates and analyzes the existing IPP methods for both\ndataset and model intelligence. Additionally, from the standpoint of training\nsettings, it delves into the unique challenges that distributed settings pose\nto IPP compared to centralized settings. Furthermore, this work examines\nvarious attacks faced by deep IPP techniques. Finally, we outline prospects for\npromising future directions that may act as a guide for innovative research.",
      "tldr_zh": "这篇论文探讨了Deep Learning模型和数据集智能的Intellectual Property (IP)保护问题，尤其在Large Language Models (LLMs)如ChatGPT和LLaMA兴起后，其商业价值日益凸显。论文不仅涵盖模型级IP保护，还扩展到数据集级，系统总结了IP保护设计的性能评估指标，并从主动侵权预防和被动所有权验证角度分析现有方法。相比集中式训练，论文深入探讨了分布式设置的独特挑战、潜在攻击，并为未来研究方向提供指导，以提升IP保护的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05051v1",
      "published_date": "2024-11-07 09:02:41 UTC",
      "updated_date": "2024-11-07 09:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:32:19.242746"
    },
    {
      "arxiv_id": "2411.04535v2",
      "title": "Meta-Reasoning Improves Tool Use in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lisa Alazraki",
        "Marek Rei"
      ],
      "abstract": "External tools help large language models succeed at tasks where they would\notherwise typically fail. In existing frameworks, choosing tools at test time\nrelies on naive greedy decoding, regardless of whether the model has been\nfine-tuned on tool-annotated data or prompted with in-context examples. In\ncontrast, we find that gathering and choosing among a suitable set of candidate\ntools has greater potential to lead to an optimal selection. We present Tool\nselECTion via meta-reasONing (TECTON), a two-phase system that first reasons\nover a task and outputs candidate tools using a custom fine-tuned language\nmodelling head. Then, with the custom head disabled, it meta-reasons (i.e., it\nreasons over the previous reasoning process) to make a final choice. We show\nthat TECTON results in substantial gains--both in-distribution and\nout-of-distribution--on a range of math reasoning datasets.",
      "tldr_zh": "这篇论文探讨了如何通过元推理(meta-reasoning)提升大型语言模型(Large Language Models)在外部工具使用上的表现，解决了现有框架依赖简单贪婪解码的局限性。作者提出TECTON系统，该系统采用两阶段方法：首先，使用自定义微调的语言模型头对任务进行推理并输出候选工具；然后，通过元推理（对先前推理过程进行分析）来做出最终选择。实验结果显示，TECTON在多种数学推理数据集上实现了显著改进，包括分布内和分布外场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2411.04535v2",
      "published_date": "2024-11-07 08:48:33 UTC",
      "updated_date": "2025-02-08 18:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:32:31.209167"
    },
    {
      "arxiv_id": "2411.04525v1",
      "title": "GenJoin: Conditional Generative Plan-to-Plan Query Optimizer that Learns from Subplan Hints",
      "title_zh": "翻译失败",
      "authors": [
        "Pavel Sulimov",
        "Claude Lehmann",
        "Kurt Stockinger"
      ],
      "abstract": "Query optimization has become a research area where classical algorithms are\nbeing challenged by machine learning algorithms. At the same time, recent\ntrends in learned query optimizers have shown that it is prudent to take\nadvantage of decades of database research and augment classical query\noptimizers by shrinking the plan search space through different types of hints\n(e.g. by specifying the join type, scan type or the order of joins) rather than\ncompletely replacing the classical query optimizer with machine learning\nmodels. It is especially relevant for cases when classical optimizers cannot\nfully enumerate all logical and physical plans and, as an alternative, need to\nrely on less robust approaches like genetic algorithms. However, even\nsymbiotically learned query optimizers are hampered by the need for vast\namounts of training data, slow plan generation during inference and unstable\nresults across various workload conditions. In this paper, we present GenJoin -\na novel learned query optimizer that considers the query optimization problem\nas a generative task and is capable of learning from a random set of subplan\nhints to produce query plans that outperform the classical optimizer. GenJoin\nis the first learned query optimizer that significantly and consistently\noutperforms PostgreSQL as well as state-of-the-art methods on two well-known\nreal-world benchmarks across a variety of workloads using rigorous machine\nlearning evaluations.",
      "tldr_zh": "本文提出GenJoin，一种条件生成式查询优化器（Conditional Generative Plan-to-Plan Query Optimizer），它将查询优化视为生成任务，并从随机子计划提示（subplan hints）中学习，以缩小计划搜索空间并生成更优的查询计划。相比传统优化器，GenJoin解决了训练数据需求大、计划生成慢和结果不稳定的问题，通过结合机器学习和数据库研究来增强性能。在两个真实世界基准测试中，GenJoin显著且一致地超越PostgreSQL和其他最先进方法，在各种工作负载下表现出色。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04525v1",
      "published_date": "2024-11-07 08:31:01 UTC",
      "updated_date": "2024-11-07 08:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:32:43.799913"
    },
    {
      "arxiv_id": "2411.04517v1",
      "title": "Continuous Sign Language Recognition System using Deep Learning with MediaPipe Holistic",
      "title_zh": "翻译失败",
      "authors": [
        "Sharvani Srivastava",
        "Sudhakar Singh",
        "Pooja",
        "Shiv Prakash"
      ],
      "abstract": "Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.",
      "tldr_zh": "这篇论文提出了一种使用深度学习（Deep Learning）和 MediaPipe Holistic 的连续手语识别（SLR）系统，旨在解决听障人士沟通障碍问题，通过识别手部、面部和身体动作将手语转化为口语。系统采用 Long Short-Term Memory (LSTM) 模型，并在使用 MediaPipe Holistic 管道创建的印度手语（ISL）数据集上进行训练和测试。实验结果显示，该系统在实时识别中实现了 88.23% 的准确率，为手语与口语的桥梁提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 figures, Wireless Pers Commun",
      "pdf_url": "http://arxiv.org/pdf/2411.04517v1",
      "published_date": "2024-11-07 08:19:39 UTC",
      "updated_date": "2024-11-07 08:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:32:55.698951"
    },
    {
      "arxiv_id": "2411.04509v1",
      "title": "FedDP: Privacy-preserving method based on federated learning for histopathology image segmentation",
      "title_zh": "FedDP：基于联邦学习的组织病理图像分割隐私保护方法",
      "authors": [
        "Liangrui Pan",
        "Mao Huang",
        "Lian Wang",
        "Pinle Qin",
        "Shaoliang Peng"
      ],
      "abstract": "Hematoxylin and Eosin (H&E) staining of whole slide images (WSIs) is\nconsidered the gold standard for pathologists and medical practitioners for\ntumor diagnosis, surgical planning, and post-operative assessment. With the\nrapid advancement of deep learning technologies, the development of numerous\nmodels based on convolutional neural networks and transformer-based models has\nbeen applied to the precise segmentation of WSIs. However, due to privacy\nregulations and the need to protect patient confidentiality, centralized\nstorage and processing of image data are impractical. Training a centralized\nmodel directly is challenging to implement in medical settings due to these\nprivacy concerns.This paper addresses the dispersed nature and privacy\nsensitivity of medical image data by employing a federated learning framework,\nallowing medical institutions to collaboratively learn while protecting patient\nprivacy. Additionally, to address the issue of original data reconstruction\nthrough gradient inversion during the federated learning training process,\ndifferential privacy introduces noise into the model updates, preventing\nattackers from inferring the contributions of individual samples, thereby\nprotecting the privacy of the training data.Experimental results show that the\nproposed method, FedDP, minimally impacts model accuracy while effectively\nsafeguarding the privacy of cancer pathology image data, with only a slight\ndecrease in Dice, Jaccard, and Acc indices by 0.55%, 0.63%, and 0.42%,\nrespectively. This approach facilitates cross-institutional collaboration and\nknowledge sharing while protecting sensitive data privacy, providing a viable\nsolution for further research and application in the medical field.",
      "tldr_zh": "本研究提出FedDP方法，利用federated learning框架实现病理图像分割，同时保护患者隐私。针对H&E染色全滑图像(WSIs)的分割任务，FedDP通过引入differential privacy在模型更新中添加噪声，防止攻击者通过梯度反演重建原始数据，从而缓解隐私泄露风险。实验结果显示，该方法仅导致Dice、Jaccard和Acc指标分别下降0.55%、0.63%和0.42%，而模型准确性影响最小，促进了医疗机构间的协作和知识共享，为隐私敏感的医疗应用提供了可行方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in BIBM2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04509v1",
      "published_date": "2024-11-07 08:02:58 UTC",
      "updated_date": "2024-11-07 08:02:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:33:06.900030"
    },
    {
      "arxiv_id": "2411.04491v1",
      "title": "Series-to-Series Diffusion Bridge Model",
      "title_zh": "序列到序列扩散桥模型",
      "authors": [
        "Hao Yang",
        "Zhanbo Feng",
        "Feng Zhou",
        "Robert C Qiu",
        "Zenan Ling"
      ],
      "abstract": "Diffusion models have risen to prominence in time series forecasting,\nshowcasing their robust capability to model complex data distributions.\nHowever, their effectiveness in deterministic predictions is often constrained\nby instability arising from their inherent stochasticity. In this paper, we\nrevisit time series diffusion models and present a comprehensive framework that\nencompasses most existing diffusion-based methods. Building on this theoretical\nfoundation, we propose a novel diffusion-based time series forecasting model,\nthe Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$), which\nleverages the Brownian Bridge process to reduce randomness in reverse\nestimations and improves accuracy by incorporating informative priors and\nconditions derived from historical time series data. Experimental results\ndemonstrate that $\\mathrm{S^2DBM}$ delivers superior performance in\npoint-to-point forecasting and competes effectively with other diffusion-based\nmodels in probabilistic forecasting.",
      "tldr_zh": "本研究回顾了时间序列预测中的 Diffusion models，并提出一个全面框架，涵盖现有的大多数扩散模型方法，以解决这些模型固有随机性导致的确定性预测不稳定性问题。作者引入了新型 Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$)，该模型利用 Brownian Bridge 过程减少反向估计的随机性，并通过整合历史时间序列数据的信息性先验和条件来提升预测准确性。实验结果显示，$\\mathrm{S^2DBM}$ 在点对点预测中表现出色，并在概率预测中与其它扩散模型竞争性强。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04491v1",
      "published_date": "2024-11-07 07:37:34 UTC",
      "updated_date": "2024-11-07 07:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:33:19.055922"
    },
    {
      "arxiv_id": "2411.05050v1",
      "title": "Selecting Between BERT and GPT for Text Classification in Political Science Research",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Wang",
        "Wen Qu",
        "Xin Ye"
      ],
      "abstract": "Political scientists often grapple with data scarcity in text classification.\nRecently, fine-tuned BERT models and their variants have gained traction as\neffective solutions to address this issue. In this study, we investigate the\npotential of GPT-based models combined with prompt engineering as a viable\nalternative. We conduct a series of experiments across various classification\ntasks, differing in the number of classes and complexity, to evaluate the\neffectiveness of BERT-based versus GPT-based models in low-data scenarios. Our\nfindings indicate that while zero-shot and few-shot learning with GPT models\nprovide reasonable performance and are well-suited for early-stage research\nexploration, they generally fall short - or, at best, match - the performance\nof BERT fine-tuning, particularly as the training set reaches a substantial\nsize (e.g., 1,000 samples). We conclude by comparing these approaches in terms\nof performance, ease of use, and cost, providing practical guidance for\nresearchers facing data limitations. Our results are particularly relevant for\nthose engaged in quantitative text analysis in low-resource settings or with\nlimited labeled data.",
      "tldr_zh": "本研究探讨了在政治科学文本分类中，面对数据稀缺问题时，BERT 微调模型与 GPT 模型（结合 prompt engineering）的比较表现。研究通过一系列实验评估了二者在不同分类任务中的有效性，包括类别数量和复杂性的差异，结果显示 GPT 的 zero-shot 和 few-shot learning 适合初步探索，但通常不如或仅匹配 BERT fine-tuning 的性能，尤其在训练集规模较大（如 1000 个样本）时。最终，论文比较了这些方法的性能、易用性和成本，为在低资源环境中进行定量文本分析的研究者提供实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 5 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.05050v1",
      "published_date": "2024-11-07 07:29:39 UTC",
      "updated_date": "2024-11-07 07:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:33:32.667919"
    },
    {
      "arxiv_id": "2411.05860v1",
      "title": "Conditional Diffusion Model for Longitudinal Medical Image Generation",
      "title_zh": "用于纵向医学图像生成的条件扩散模型",
      "authors": [
        "Duy-Phuong Dao",
        "Hyung-Jeong Yang",
        "Jahae Kim"
      ],
      "abstract": "Alzheimers disease progresses slowly and involves complex interaction between\nvarious biological factors. Longitudinal medical imaging data can capture this\nprogression over time. However, longitudinal data frequently encounter issues\nsuch as missing data due to patient dropouts, irregular follow-up intervals,\nand varying lengths of observation periods. To address these issues, we\ndesigned a diffusion-based model for 3D longitudinal medical imaging generation\nusing single magnetic resonance imaging (MRI). This involves the injection of a\nconditioning MRI and time-visit encoding to the model, enabling control in\nchange between source and target images. The experimental results indicate that\nthe proposed method generates higher-quality images compared to other competing\nmethods.",
      "tldr_zh": "本文提出了一种Conditional Diffusion Model，用于生成3D纵向医学影像，以解决阿尔茨海默病等疾病数据中的缺失、不规则随访间隔和观察期长度差异问题。该模型通过注入条件MRI和time-visit encoding作为输入，实现了对源图像和目标图像之间变化的精确控制。实验结果显示，该方法生成的图像质量高于其他竞争方法，为处理纵向医学数据提供了有效工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2411.05860v1",
      "published_date": "2024-11-07 06:44:47 UTC",
      "updated_date": "2024-11-07 06:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:33:42.868570"
    },
    {
      "arxiv_id": "2411.04468v1",
      "title": "Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Fourney",
        "Gagan Bansal",
        "Hussein Mozannar",
        "Cheng Tan",
        "Eduardo Salinas",
        "Erkang",
        "Zhu",
        "Friederike Niedtner",
        "Grace Proebsting",
        "Griffin Bassman",
        "Jack Gerrits",
        "Jacob Alber",
        "Peter Chang",
        "Ricky Loynd",
        "Robert West",
        "Victor Dibia",
        "Ahmed Awadallah",
        "Ece Kamar",
        "Rafah Hosn",
        "Saleema Amershi"
      ],
      "abstract": "Modern AI agents, driven by advances in large foundation models, promise to\nenhance our productivity and transform our lives by augmenting our knowledge\nand capabilities. To achieve this vision, AI agents must effectively plan,\nperform multi-step reasoning and actions, respond to novel observations, and\nrecover from errors, to successfully complete complex tasks across a wide range\nof scenarios. In this work, we introduce Magentic-One, a high-performing\nopen-source agentic system for solving such tasks. Magentic-One uses a\nmulti-agent architecture where a lead agent, the Orchestrator, plans, tracks\nprogress, and re-plans to recover from errors. Throughout task execution, the\nOrchestrator directs other specialized agents to perform tasks as needed, such\nas operating a web browser, navigating local files, or writing and executing\nPython code. We show that Magentic-One achieves statistically competitive\nperformance to the state-of-the-art on three diverse and challenging agentic\nbenchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves these\nresults without modification to core agent capabilities or to how they\ncollaborate, demonstrating progress towards generalist agentic systems.\nMoreover, Magentic-One's modular design allows agents to be added or removed\nfrom the team without additional prompt tuning or training, easing development\nand making it extensible to future scenarios. We provide an open-source\nimplementation of Magentic-One, and we include AutoGenBench, a standalone tool\nfor agentic evaluation. AutoGenBench provides built-in controls for repetition\nand isolation to run agentic benchmarks in a rigorous and contained manner --\nwhich is important when agents' actions have side-effects. Magentic-One,\nAutoGenBench and detailed empirical performance evaluations of Magentic-One,\nincluding ablations and error analysis are available at\nhttps://aka.ms/magentic-one",
      "tldr_zh": "本文提出 Magentic-One，一种高性能开源多智能体系统，旨在通过规划、多步推理、行动和错误恢复来处理复杂任务。该系统采用多智能体架构，由 Orchestrator 智能体主导规划和协调，其他专业智能体负责具体任务，如网页操作、本地文件管理和 Python 代码执行。在 GAIA、AssistantBench 和 WebArena 等基准上，Magentic-One 实现了与最先进系统相当的性能，且无需修改核心能力或协作方式。系统设计模块化，便于添加或移除智能体，并提供了开源实现和 AutoGenBench 工具，以支持严格的代理评估。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04468v1",
      "published_date": "2024-11-07 06:36:19 UTC",
      "updated_date": "2024-11-07 06:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:33:56.178472"
    },
    {
      "arxiv_id": "2411.04466v1",
      "title": "Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity",
      "title_zh": "通过针对多样性启用开放式模拟器中的自适应代理训练",
      "authors": [
        "Robby Costales",
        "Stefanos Nikolaidis"
      ],
      "abstract": "The wider application of end-to-end learning methods to embodied\ndecision-making domains remains bottlenecked by their reliance on a\nsuperabundance of training data representative of the target domain.\nMeta-reinforcement learning (meta-RL) approaches abandon the aim of zero-shot\ngeneralization--the goal of standard reinforcement learning (RL)--in favor of\nfew-shot adaptation, and thus hold promise for bridging larger generalization\ngaps. While learning this meta-level adaptive behavior still requires\nsubstantial data, efficient environment simulators approaching real-world\ncomplexity are growing in prevalence. Even so, hand-designing sufficiently\ndiverse and numerous simulated training tasks for these complex domains is\nprohibitively labor-intensive. Domain randomization (DR) and procedural\ngeneration (PG), offered as solutions to this problem, require simulators to\npossess carefully-defined parameters which directly translate to meaningful\ntask diversity--a similarly prohibitive assumption. In this work, we present\nDIVA, an evolutionary approach for generating diverse training tasks in such\ncomplex, open-ended simulators. Like unsupervised environment design (UED)\nmethods, DIVA can be applied to arbitrary parameterizations, but can\nadditionally incorporate realistically-available domain knowledge--thus\ninheriting the flexibility and generality of UED, and the supervised structure\nembedded in well-designed simulators exploited by DR and PG. Our empirical\nresults showcase DIVA's unique ability to overcome complex parameterizations\nand successfully train adaptive agent behavior, far outperforming competitive\nbaselines from prior literature. These findings highlight the potential of such\nsemi-supervised environment design (SSED) approaches, of which DIVA is the\nfirst humble constituent, to enable training in realistic simulated domains,\nand produce more robust and capable adaptive agents.",
      "tldr_zh": "该研究针对端到端学习在实体决策领域的应用瓶颈，提出DIVA（一种进化方法），用于在复杂开放模拟器中生成多样化的训练任务。DIVA结合Unsupervised Environment Design (UED)的灵活性与领域知识的监督结构，超越了Domain Randomization (DR)和Procedural Generation (PG)的局限性，从而实现meta-reinforcement learning (meta-RL)代理的少样本适应训练。实验结果显示，DIVA在处理复杂参数化和训练自适应代理方面远超现有基线，突显了Semi-Supervised Environment Design (SSED)方法在模拟域训练中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04466v1",
      "published_date": "2024-11-07 06:27:12 UTC",
      "updated_date": "2024-11-07 06:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:34:08.082616"
    },
    {
      "arxiv_id": "2411.04462v2",
      "title": "Can CDT rationalise the ex ante optimal policy via modified anthropics?",
      "title_zh": "翻译失败",
      "authors": [
        "Emery Cooper",
        "Caspar Oesterheld",
        "Vincent Conitzer"
      ],
      "abstract": "In Newcomb's problem, causal decision theory (CDT) recommends two-boxing and\nthus comes apart from evidential decision theory (EDT) and ex ante policy\noptimisation (which prescribe one-boxing). However, in Newcomb's problem, you\nshould perhaps believe that with some probability you are in a simulation run\nby the predictor to determine whether to put a million dollars into the opaque\nbox. If so, then causal decision theory might recommend one-boxing in order to\ncause the predictor to fill the opaque box. In this paper, we study\ngeneralisations of this approach. That is, we consider general Newcomblike\nproblems and try to form reasonable self-locating beliefs under which CDT's\nrecommendations align with an EDT-like notion of ex ante policy optimisation.\nWe consider approaches in which we model the world as running simulations of\nthe agent, and an approach not based on such models (which we call 'Generalised\nGeneralised Thirding', or GGT). For each approach, we characterise the\nresulting CDT policies, and prove that under certain conditions, these include\nthe ex ante optimal policies.",
      "tldr_zh": "这篇论文探讨了在纽康布问题（Newcomb's problem）中，Causal Decision Theory (CDT) 是否能通过修改的 anthropics 来推荐与 ex ante policy optimisation 一致的策略，从而解决 CDT 与 Evidential Decision Theory (EDT) 的分歧。作者研究了泛化方法，包括建模世界运行代理模拟以及不基于模拟的 Generalised Generalised Thirding (GGT) 途径，以形成合理的自我定位信念。结果表明，在特定条件下，这些方法使 CDT 的策略包括 ex ante 最优策略，为决策理论的统一提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04462v2",
      "published_date": "2024-11-07 06:23:38 UTC",
      "updated_date": "2024-11-20 19:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:34:20.474313"
    },
    {
      "arxiv_id": "2411.05859v1",
      "title": "Enhancing Financial Fraud Detection with Human-in-the-Loop Feedback and Feedback Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Prashank Kadam"
      ],
      "abstract": "Human-in-the-loop (HITL) feedback mechanisms can significantly enhance\nmachine learning models, particularly in financial fraud detection, where fraud\npatterns change rapidly, and fraudulent nodes are sparse. Even small amounts of\nfeedback from Subject Matter Experts (SMEs) can notably boost model\nperformance. This paper examines the impact of HITL feedback on both\ntraditional and advanced techniques using proprietary and publicly available\ndatasets. Our results show that HITL feedback improves model accuracy, with\ngraph-based techniques benefiting the most. We also introduce a novel feedback\npropagation method that extends feedback across the dataset, further enhancing\ndetection accuracy. By leveraging human expertise, this approach addresses\nchallenges related to evolving fraud patterns, data sparsity, and model\ninterpretability, ultimately improving model robustness and streamlining the\nannotation process.",
      "tldr_zh": "本论文探讨了 Human-in-the-Loop (HITL) 反馈机制在金融欺诈检测中的应用，该机制能显著提升机器学习模型的表现，尤其在欺诈模式快速变化和欺诈节点稀疏的情况下。研究使用专有和公开数据集，评估HITL反馈对传统和高级技术（如图-based techniques）的冲击，结果显示反馈能提高模型准确率，其中图-based技术受益最大。论文引入了一种新型反馈 propagation方法，将反馈扩展到整个数据集，进一步增强检测准确率，并通过利用人类专家知识，解决了演变欺诈模式、数据稀疏性和模型可解释性的挑战，从而提升了模型稳健性和注释过程的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "J.1"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Machine Learning and Applications 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.05859v1",
      "published_date": "2024-11-07 05:22:36 UTC",
      "updated_date": "2024-11-07 05:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:34:31.240918"
    },
    {
      "arxiv_id": "2411.04434v2",
      "title": "Scaling Laws for Pre-training Agents and World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Pearce",
        "Tabish Rashid",
        "Dave Bignell",
        "Raluca Georgescu",
        "Sam Devlin",
        "Katja Hofmann"
      ],
      "abstract": "The performance of embodied agents has been shown to improve by increasing\nmodel parameters, dataset size, and compute. This has been demonstrated in\ndomains from robotics to video games, when generative learning objectives on\noffline datasets (pre-training) are used to model an agent's behavior\n(imitation learning) or their environment (world modeling). This paper\ncharacterizes the role of scale in these tasks more precisely. Going beyond the\nsimple intuition that `bigger is better', we show that the same types of power\nlaws found in language modeling also arise in world modeling and imitation\nlearning (e.g. between loss and optimal model size). However, the coefficients\nof these laws are heavily influenced by the tokenizer, task \\& architecture --\nthis has important implications on the optimal sizing of models and data.",
      "tldr_zh": "该研究探讨了预训练代理（agents）和世界模型（world models）的规模定律，分析了通过增加模型参数、数据集大小和计算资源来提升代理性能的效果，尤其在机器人和视频游戏领域。论文发现，与语言建模类似，世界建模和模仿学习（imitation learning）也遵循幂律（scaling laws），例如损失与最佳模型大小之间的关系，但这些幂律的系数受 tokenizer、任务和架构的影响。最终，这为优化模型和数据的规模提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04434v2",
      "published_date": "2024-11-07 04:57:40 UTC",
      "updated_date": "2024-12-18 07:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:34:42.981284"
    },
    {
      "arxiv_id": "2411.04424v1",
      "title": "Bayesian Calibration of Win Rate Estimation with LLM Evaluators",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Gao",
        "Gonghan Xu",
        "Zhe Wang",
        "Arman Cohan"
      ],
      "abstract": "Recent advances in large language models (LLMs) show the potential of using\nLLMs as evaluators for assessing the quality of text generations from LLMs.\nHowever, applying LLM evaluators naively to compare or judge between different\nsystems can lead to unreliable results due to the intrinsic win rate estimation\nbias of LLM evaluators. In order to mitigate this problem, we propose two\ncalibration methods, Bayesian Win Rate Sampling (BWRS) and Bayesian\nDawid-Skene, both of which leverage Bayesian inference to more accurately infer\nthe true win rate of generative language models. We empirically validate our\nmethods on six datasets covering story generation, summarization, and\ninstruction following tasks. We show that both our methods are effective in\nimproving the accuracy of win rate estimation using LLMs as evaluators,\noffering a promising direction for reliable automatic text quality evaluation.",
      "tldr_zh": "本论文探讨了使用大型语言模型(LLM)作为评估器来评估文本生成质量的问题，但指出LLM评估器存在固有的胜率估计偏差，导致结果不可靠。为解决这一问题，研究提出两种校准方法：Bayesian Win Rate Sampling (BWRS)和Bayesian Dawid-Skene，这两种方法利用Bayesian inference来更准确地推断生成语言模型的真实胜率。在六个数据集上进行的实证验证（涵盖故事生成、摘要和指令遵循任务）显示，这些方法显著提高了胜率估计的准确性，为可靠的自动文本质量评估提供了新的方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.04424v1",
      "published_date": "2024-11-07 04:32:40 UTC",
      "updated_date": "2024-11-07 04:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:34:56.009777"
    },
    {
      "arxiv_id": "2411.04421v2",
      "title": "Variational Low-Rank Adaptation Using IVON",
      "title_zh": "翻译失败",
      "authors": [
        "Bai Cong",
        "Nico Daheim",
        "Yuesong Shen",
        "Daniel Cremers",
        "Rio Yokota",
        "Mohammad Emtiyaz Khan",
        "Thomas Möllenhoff"
      ],
      "abstract": "We show that variational learning can significantly improve the accuracy and\ncalibration of Low-Rank Adaptation (LoRA) without a substantial increase in the\ncost. We replace AdamW by the Improved Variational Online Newton (IVON)\nalgorithm to finetune large language models. For Llama-2 with 7 billion\nparameters, IVON improves the accuracy over AdamW by 2.8% and expected\ncalibration error by 4.6%. The accuracy is also better than the other Bayesian\nalternatives, yet the cost is lower and the implementation is easier. Our work\nprovides additional evidence for the effectiveness of IVON for large language\nmodels. The code is available at\nhttps://github.com/team-approx-bayes/ivon-lora.",
      "tldr_zh": "本文提出了一种基于变分学习（Variational Low-Rank Adaptation）的改进方法，使用 Improved Variational Online Newton (IVON) 算法替换 AdamW 来微调大型语言模型，从而显著提升 LoRA 的准确性和校准性，同时保持成本增加有限。实验结果显示，在 Llama-2 7B 参数模型上，IVON 比 AdamW 提高了 2.8% 的准确率和 4.6% 的预期校准错误（expected calibration error）。相较于其他 Bayesian 方法，IVON 提供了更高的准确率、更低的计算成本和更简单的实现，并附带了开源代码（https://github.com/team-approx-bayes/ivon-lora）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 38th Workshop on Fine-Tuning in Machine Learning\n  (NeurIPS 2024). Code available at\n  https://github.com/team-approx-bayes/ivon-lora. In version 2 we fixed a typo\n  in the equation of prior in section 2",
      "pdf_url": "http://arxiv.org/pdf/2411.04421v2",
      "published_date": "2024-11-07 04:17:30 UTC",
      "updated_date": "2024-11-09 12:30:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:35:07.504762"
    },
    {
      "arxiv_id": "2411.05048v1",
      "title": "Leveraging LLMs to Enable Natural Language Search on Go-to-market Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Yao",
        "Saurav Acharya",
        "Priyaranjan Parida",
        "Srinivas Attipalli",
        "Ali Dasdan"
      ],
      "abstract": "Enterprise searches require users to have complex knowledge of queries,\nconfigurations, and metadata, rendering it difficult for them to access\ninformation as needed. Most go-to-market (GTM) platforms utilize advanced\nsearch, an interface that enables users to filter queries by various fields\nusing categories or keywords, which, historically, however, has proven to be\nexceedingly cumbersome, as users are faced with seemingly hundreds of options,\nfields, and buttons. Consequently, querying with natural language has long been\nideal, a notion further empowered by Large Language Models (LLMs).\n  In this paper, we implement and evaluate a solution for the Zoominfo product\nfor sellers, which prompts the LLM with natural language, producing search\nfields through entity extraction that are then converted into a search query.\nThe intermediary search fields offer numerous advantages for each query,\nincluding the elimination of syntax errors, simpler ground truths, and an\nintuitive format for the LLM to interpret.\n  We paired this pipeline with many advanced prompt engineering strategies,\nfeaturing an intricate system message, few-shot prompting, chain-of-thought\n(CoT) reasoning, and execution refinement. Furthermore, we manually created the\nground truth for 500+ natural language queries, enabling the supervised\nfine-tuning of Llama-3-8B-Instruct and the introduction of sophisticated\nnumerical metrics.\n  Comprehensive experiments with closed, open source, and fine-tuned LLM models\nwere conducted through exact, Jaccard, cosine, and semantic similarity on\nindividual search entities to demonstrate the efficacy of our approach.\nOverall, the most accurate closed model had an average accuracy of 97% per\nquery, with only one field performing under 90%, with comparable results\nobserved from the fine-tuned models.",
      "tldr_zh": "这篇论文探讨了如何利用大型语言模型(LLMs)来简化企业销售平台(Go-to-market Platforms)的搜索过程，解决用户面对复杂查询和界面时的难题。研究提出了一种解决方案：在Zoominfo产品中，通过实体提取将自然语言查询转换为搜索字段，并结合高级提示工程策略，如few-shot prompting、Chain-of-Thought (CoT)推理和执行精炼，以消除语法错误并提升查询准确性。作者手动创建了500+查询的ground truth，用于监督微调Llama-3-8B-Instruct模型，并通过精确度、Jaccard、cosine和语义相似度等指标进行实验评估，结果显示最准确的封闭模型每查询平均准确率达97%。这项工作为更直观、可访问的自然语言搜索系统提供了有效框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.IR",
        "cs.LG",
        "I.2.7; H.3.3; H.3.4"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05048v1",
      "published_date": "2024-11-07 03:58:38 UTC",
      "updated_date": "2024-11-07 03:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:35:20.198043"
    },
    {
      "arxiv_id": "2411.04403v1",
      "title": "Towards Competitive Search Relevance For Inference-Free Learned Sparse Retrievers",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichao Geng",
        "Dongyu Ru",
        "Yang Yang"
      ],
      "abstract": "Learned sparse retrieval, which can efficiently perform retrieval through\nmature inverted-index engines, has garnered growing attention in recent years.\nParticularly, the inference-free sparse retrievers are attractive as they\neliminate online model inference in the retrieval phase thereby avoids huge\ncomputational cost, offering reasonable throughput and latency. However, even\nthe state-of-the-art (SOTA) inference-free sparse models lag far behind in\nterms of search relevance when compared to both sparse and dense siamese\nmodels. Towards competitive search relevance for inference-free sparse\nretrievers, we argue that they deserve dedicated training methods other than\nusing same ones with siamese encoders. In this paper, we propose two different\napproaches for performance improvement. First, we introduce the IDF-aware FLOPS\nloss, which introduces Inverted Document Frequency (IDF) to the sparsification\nof representations. We find that it mitigates the negative impact of the FLOPS\nregularization on search relevance, allowing the model to achieve a better\nbalance between accuracy and efficiency. Moreover, we propose a heterogeneous\nensemble knowledge distillation framework that combines siamese dense and\nsparse retrievers to generate supervisory signals during the pre-training\nphase. The ensemble framework of dense and sparse retriever capitalizes on\ntheir strengths respectively, providing a strong upper bound for knowledge\ndistillation. To concur the diverse feedback from heterogeneous supervisors, we\nnormalize and then aggregate the outputs of the teacher models to eliminate\nscore scale differences. On the BEIR benchmark, our model outperforms existing\nSOTA inference-free sparse model by \\textbf{3.3 NDCG@10 score}. It exhibits\nsearch relevance comparable to siamese sparse retrievers and client-side\nlatency only \\textbf{1.1x that of BM25}.",
      "tldr_zh": "该论文针对 inference-free learned sparse retrievers 的搜索相关性不足问题，提出两种专用训练方法，以提升其性能并与 siamese 模型竞争。首先，引入 IDF-aware FLOPS loss，通过整合 Inverted Document Frequency (IDF) 来优化表示的稀疏化，缓解 FLOPS 正则化对准确性的负面影响，实现效率与相关性的平衡。其次，提出 heterogeneous ensemble knowledge distillation 框架，将 siamese dense 和 sparse retrievers 结合，在预训练阶段生成监督信号，通过归一化和聚合输出处理异构反馈。在 BEIR benchmark 上，该模型比现有 SOTA inference-free sparse 模型提高了 3.3 NDCG@10 分数，与 siamese sparse retrievers 的相关性相当，且客户端延迟仅为 BM25 的 1.1 倍。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04403v1",
      "published_date": "2024-11-07 03:46:43 UTC",
      "updated_date": "2024-11-07 03:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:35:32.441748"
    },
    {
      "arxiv_id": "2411.04397v1",
      "title": "A Bayesian Mixture Model of Temporal Point Processes with Determinantal Point Process Prior",
      "title_zh": "一种带有行列式点过程先验的贝叶斯时间点过程混合模型",
      "authors": [
        "Yiwei Dong",
        "Shaoxin Ye",
        "Yuwen Cao",
        "Qiyu Han",
        "Hongteng Xu",
        "Hanfang Yang"
      ],
      "abstract": "Asynchronous event sequence clustering aims to group similar event sequences\nin an unsupervised manner. Mixture models of temporal point processes have been\nproposed to solve this problem, but they often suffer from overfitting, leading\nto excessive cluster generation with a lack of diversity. To overcome these\nlimitations, we propose a Bayesian mixture model of Temporal Point Processes\nwith Determinantal Point Process prior (TP$^2$DP$^2$) and accordingly an\nefficient posterior inference algorithm based on conditional Gibbs sampling.\nOur work provides a flexible learning framework for event sequence clustering,\nenabling automatic identification of the potential number of clusters and\naccurate grouping of sequences with similar features. It is applicable to a\nwide range of parametric temporal point processes, including neural\nnetwork-based models. Experimental results on both synthetic and real-world\ndata suggest that our framework could produce moderately fewer yet more diverse\nmixture components, and achieve outstanding results across multiple evaluation\nmetrics.",
      "tldr_zh": "本研究针对异步事件序列聚类的问题，提出了一种Bayesian mixture model of Temporal Point Processes with Determinantal Point Process prior（简称TP²DP²），以解决现有模型的过拟合问题和缺乏多样性。TP²DP²框架结合了Determinantal Point Process prior，并开发了基于条件Gibbs sampling的efficient posterior inference算法，能够自动识别潜在集群数量并准确分组相似序列。该模型适用于多种parametric temporal point processes，包括基于neural network的模型。实验结果显示，在合成和真实世界数据上，TP²DP²生成了更少但更丰富的mixture components，并在多个evaluation metrics上取得了优异性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04397v1",
      "published_date": "2024-11-07 03:21:30 UTC",
      "updated_date": "2024-11-07 03:21:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:35:43.397011"
    },
    {
      "arxiv_id": "2411.04393v1",
      "title": "Bridging the Gap: Representation Spaces in Neuro-Symbolic AI",
      "title_zh": "弥合差距：神经符号 AI 中的表示空间",
      "authors": [
        "Xin Zhang",
        "Victor S. Sheng"
      ],
      "abstract": "Neuro-symbolic AI is an effective method for improving the overall\nperformance of AI models by combining the advantages of neural networks and\nsymbolic learning. However, there are differences between the two in terms of\nhow they process data, primarily because they often use different data\nrepresentation methods, which is often an important factor limiting the overall\nperformance of the two. From this perspective, we analyzed 191 studies from\n2013 by constructing a four-level classification framework. The first level\ndefines five types of representation spaces, and the second level focuses on\nfive types of information modalities that the representation space can\nrepresent. Then, the third level describes four symbolic logic methods.\nFinally, the fourth-level categories propose three collaboration strategies\nbetween neural networks and symbolic learning. Furthermore, we conducted a\ndetailed analysis of 46 research based on their representation space.",
      "tldr_zh": "本论文探讨了 Neuro-Symbolic AI 中神经网络和符号学习之间的表示空间（representation spaces）差异，这些差异是影响 AI 模型整体性能的关键因素。通过构建一个四级分类框架，作者分析了从 2013 年起的 191 篇研究：第一级定义五种表示空间类型，第二级关注五种信息模式，第三级描述四种符号逻辑方法，第四级提出三种神经网络与符号学习的协作策略。此外，对 46 篇研究进行详细分析，旨在桥接两者差距，提升 Neuro-Symbolic AI 的效能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04393v1",
      "published_date": "2024-11-07 03:10:44 UTC",
      "updated_date": "2024-11-07 03:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:35:55.417015"
    },
    {
      "arxiv_id": "2411.04383v1",
      "title": "Neuro-Symbolic AI: Explainability, Challenges, and Future Trends",
      "title_zh": "神经符号 AI：可解释性、挑战和未来趋势",
      "authors": [
        "Xin Zhang",
        "Victor S. Sheng"
      ],
      "abstract": "Explainability is an essential reason limiting the application of neural\nnetworks in many vital fields. Although neuro-symbolic AI hopes to enhance the\noverall explainability by leveraging the transparency of symbolic learning, the\nresults are less evident than imagined. This article proposes a classification\nfor explainability by considering both model design and behavior of 191 studies\nfrom 2013, focusing on neuro-symbolic AI, hoping to inspire scholars who want\nto understand the explainability of neuro-symbolic AI. Precisely, we classify\nthem into five categories by considering whether the form of bridging the\nrepresentation differences is readable as their design factor, if there are\nrepresentation differences between neural networks and symbolic logic learning,\nand whether a model decision or prediction process is understandable as their\nbehavior factor: implicit intermediate representations and implicit prediction,\npartially explicit intermediate representations and partially explicit\nprediction, explicit intermediate representations or explicit prediction,\nexplicit intermediate representation and explicit prediction, unified\nrepresentation and explicit prediction. We also analyzed the research trends\nand three significant challenges: unified representations, explainability and\ntransparency, and sufficient cooperation from neural networks and symbolic\nlearning. Finally, we put forward suggestions for future research in three\naspects: unified representations, enhancing model explainability, ethical\nconsiderations, and social impact.",
      "tldr_zh": "这篇论文探讨了Neuro-Symbolic AI的解释性问题，分析了其在提升模型透明性方面的潜力及其面临的挑战。作者基于191篇从2013年起的相关研究，将模型设计和行为因素分为五类：隐式中间表示和隐式预测、部分显式中间表示和部分显式预测、显式中间表示或显式预测、显式中间表示和显式预测，以及统一表示和显式预测。研究发现，Neuro-Symbolic AI的主要挑战包括统一表示、解释性和透明度，以及神经网络与符号学习的充分合作。最终，论文提出未来研究建议，聚焦于统一表示、提升模型explainability、伦理考虑和社会影响。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04383v1",
      "published_date": "2024-11-07 02:54:35 UTC",
      "updated_date": "2024-11-07 02:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:36:08.063237"
    },
    {
      "arxiv_id": "2411.13560v1",
      "title": "AMSnet-KG: A Netlist Dataset for LLM-based AMS Circuit Auto-Design Using Knowledge Graph RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Shi",
        "Zhuofu Tao",
        "Yuhao Gao",
        "Tianjia Zhou",
        "Cheng Chang",
        "Yaxing Wang",
        "Bingyu Chen",
        "Genhao Zhang",
        "Alvin Liu",
        "Zhiping Yu",
        "Ting-Jung Lin",
        "Lei He"
      ],
      "abstract": "High-performance analog and mixed-signal (AMS) circuits are mainly\nfull-custom designed, which is time-consuming and labor-intensive. A\nsignificant portion of the effort is experience-driven, which makes the\nautomation of AMS circuit design a formidable challenge. Large language models\n(LLMs) have emerged as powerful tools for Electronic Design Automation (EDA)\napplications, fostering advancements in the automatic design process for\nlarge-scale AMS circuits. However, the absence of high-quality datasets has led\nto issues such as model hallucination, which undermines the robustness of\nautomatically generated circuit designs. To address this issue, this paper\nintroduces AMSnet-KG, a dataset encompassing various AMS circuit schematics and\nnetlists. We construct a knowledge graph with annotations on detailed\nfunctional and performance characteristics. Facilitated by AMSnet-KG, we\npropose an automated AMS circuit generation framework that utilizes the\ncomprehensive knowledge embedded in LLMs. We first formulate a design strategy\n(e.g., circuit architecture using a number of circuit components) based on\nrequired specifications. Next, matched circuit components are retrieved and\nassembled into a complete topology, and transistor sizing is obtained through\nBayesian optimization. Simulation results of the netlist are fed back to the\nLLM for further topology refinement, ensuring the circuit design specifications\nare met. We perform case studies of operational amplifier and comparator design\nto verify the automatic design flow from specifications to netlists with\nminimal human effort. The dataset used in this paper will be open-sourced upon\npublishing of this paper.",
      "tldr_zh": "该论文引入了AMSnet-KG数据集，该数据集包含各种模拟和混合信号(AMS)电路原理图、网表以及详细的功能和性能特性的知识图谱注释，以支持基于大型语言模型(LLMs)的AMS电路自动设计。研究提出一个自动生成框架，利用知识图谱RAG技术制定电路架构策略、检索匹配组件、组装拓扑，并通过Bayesian优化进行晶体管尺寸调整，同时反馈模拟结果给LLM进行优化。实验案例包括运算放大器和比较器的设计，证明了该框架能从规格到网表的自动化流程，显著减少人为努力，且数据集将在论文发布后开源。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.ET",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13560v1",
      "published_date": "2024-11-07 02:49:53 UTC",
      "updated_date": "2024-11-07 02:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:36:19.705785"
    },
    {
      "arxiv_id": "2411.05046v1",
      "title": "PhoneLM:an Efficient and Capable Small Language Model Family through Principled Pre-training",
      "title_zh": "PhoneLM：通过有原则预训练实现的高效且功能强大的小型语言模型家族",
      "authors": [
        "Rongjie Yi",
        "Xiang Li",
        "Weikai Xie",
        "Zhenyan Lu",
        "Chenghua Wang",
        "Ao Zhou",
        "Shangguang Wang",
        "Xiwen Zhang",
        "Mengwei Xu"
      ],
      "abstract": "The interest in developing small language models (SLM) for on-device\ndeployment is fast growing. However, the existing SLM design hardly considers\nthe device hardware characteristics. Instead, this work presents a simple yet\neffective principle for SLM design: architecture searching for (near-)optimal\nruntime efficiency before pre-training. Guided by this principle, we develop\nPhoneLM SLM family (currently with 0.5B and 1.5B versions), that acheive the\nstate-of-the-art capability-efficiency tradeoff among those with similar\nparameter size. We fully open-source the code, weights, and training datasets\nof PhoneLM for reproducibility and transparency, including both base and\ninstructed versions. We also release a finetuned version of PhoneLM capable of\naccurate Android Intent invocation, and an end-to-end Android demo. All\nmaterials are available at https://github.com/UbiquitousLearning/PhoneLM.",
      "tldr_zh": "该研究提出了一种针对设备部署的小语言模型(SLM)设计原则：在预训练前通过架构搜索优化运行时效率，从而开发了PhoneLM模型家族（包括0.5B和1.5B版本）。PhoneLM在类似参数规模下实现了最先进的性能-效率权衡，显著提升了SLM的实用性。研究团队开源了PhoneLM的代码、权重、训练数据集以及base和instructed版本，还发布了一个微调版本支持Android Intent调用，并提供了端到端Android演示，以促进可复现性和实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05046v1",
      "published_date": "2024-11-07 02:19:00 UTC",
      "updated_date": "2024-11-07 02:19:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:36:30.398667"
    },
    {
      "arxiv_id": "2411.04372v1",
      "title": "Benchmarking Large Language Models with Integer Sequence Generation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel O'Malley",
        "Manish Bhattarai",
        "Javier Santos"
      ],
      "abstract": "This paper presents a novel benchmark where the large language model (LLM)\nmust write code that computes integer sequences from the Online Encyclopedia of\nInteger Sequences (OEIS), a widely-used resource for mathematical sequences.\nThe benchmark is designed to evaluate both the correctness of the generated\ncode and its computational efficiency. Our benchmark reveals that the o1 series\nof models outperform other frontier models from OpenAI, Anthropic, Meta, and\nGoogle in accuracy and cheating rates across both easy and hard integer\nsequences. In order to ensure models do not exploit memorized sequence values,\nwe introduce an automated cheating detection mechanism that flags the use of\nlookup tables and validated this automation against human cheating evaluations.\nThis benchmark provides a meaningful challenge for current LLMs, offering\ninsights into their mathematical reasoning and code writing capabilities, which\ncan guide future research directions and model development in mathematical\nreasoning and code synthesis.",
      "tldr_zh": "本论文提出一个新基准，用于评估大型语言模型（LLMs）的整数序列生成能力，任务要求模型编写代码计算来自 Online Encyclopedia of Integer Sequences (OEIS) 的数学序列，并同时考量代码的正确性和计算效率。该基准揭示，o1 系列模型在简单和困难序列上表现出色，准确性和作弊率均优于 OpenAI、Anthropic、Meta 和 Google 的前沿模型。为防止模型利用记忆序列，论文引入了自动作弊检测机制，并通过人类评估验证其有效性。该基准为 LLM 的数学推理和代码合成能力提供了重要洞见，有助于指导未来的模型开发和研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04372v1",
      "published_date": "2024-11-07 02:05:43 UTC",
      "updated_date": "2024-11-07 02:05:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:36:43.295916"
    },
    {
      "arxiv_id": "2411.04371v2",
      "title": "ComFairGNN: Community Fair Graph Neural Network",
      "title_zh": "ComFairGNN：社区公平图神经网络",
      "authors": [
        "Yonas Sium",
        "Qi Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become the leading approach for addressing\ngraph analytical problems in various real-world scenarios. However, GNNs may\nproduce biased predictions against certain demographic subgroups due to node\nattributes and neighbors surrounding a node. Most current research on GNN\nfairness focuses predominantly on debiasing GNNs using oversimplified fairness\nevaluation metrics, which can give a misleading impression of fairness.\nUnderstanding the potential evaluation paradoxes due to the complicated nature\nof the graph structure is crucial for developing effective GNN debiasing\nmechanisms. In this paper, we examine the effectiveness of current GNN\ndebiasing methods in terms of unfairness evaluation. Specifically, we introduce\na community-level strategy to measure bias in GNNs and evaluate debiasing\nmethods at this level. Further, We introduce ComFairGNN, a novel framework\ndesigned to mitigate community-level bias in GNNs. Our approach employs a\nlearnable coreset-based debiasing function that addresses bias arising from\ndiverse local neighborhood distributions during GNNs neighborhood aggregation.\nComprehensive evaluations on three benchmark datasets demonstrate our model's\neffectiveness in both accuracy and fairness metrics.",
      "tldr_zh": "本论文探讨了 Graph Neural Networks (GNNs) 由于节点属性和邻居影响而产生的偏见问题，指出现有去偏方法依赖简化公平评估指标可能导致误导。作者引入了社区级别的偏见测量策略，并提出 ComFairGNN 框架，该框架利用可学习的 coreset-based 去偏函数来缓解 GNNs 在邻域聚合过程中因局部邻域分布多样性引发的偏见。在三个基准数据集上的全面评估显示，ComFairGNN 不仅提升了模型的准确性，还显著改善了公平性指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at PAKDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.04371v2",
      "published_date": "2024-11-07 02:04:34 UTC",
      "updated_date": "2025-04-01 21:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:36:55.325775"
    },
    {
      "arxiv_id": "2411.05856v1",
      "title": "Evaluating the Economic Implications of Using Machine Learning in Clinical Psychiatry",
      "title_zh": "翻译失败",
      "authors": [
        "Soaad Hossain",
        "James Rasalingam",
        "Arhum Waheed",
        "Fatah Awil",
        "Rachel Kandiah",
        "Syed Ishtiaque Ahmed"
      ],
      "abstract": "With the growing interest in using AI and machine learning (ML) in medicine,\nthere is an increasing number of literature covering the application and ethics\nof using AI and ML in areas of medicine such as clinical psychiatry. The\nproblem is that there is little literature covering the economic aspects\nassociated with using ML in clinical psychiatry. This study addresses this gap\nby specifically studying the economic implications of using ML in clinical\npsychiatry. In this paper, we evaluate the economic implications of using ML in\nclinical psychiatry through using three problem-oriented case studies,\nliterature on economics, socioeconomic and medical AI, and two types of health\neconomic evaluations. In addition, we provide details on fairness, legal,\nethics and other considerations for ML in clinical psychiatry.",
      "tldr_zh": "本研究评估了在临床精神病学中使用 Machine Learning (ML) 的经济影响，填补了现有文献中对这一领域的经济分析缺口。研究通过三个问题导向的案例研究、健康经济评估以及相关经济、社会经济和医疗 AI 文献，进行全面评估。同时，论文讨论了公平性、法律、伦理等考虑，为 ML 在临床精神病学中的应用提供了更全面的指导。该工作有助于理解 ML 技术的经济效益和潜在风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE",
        "cs.HC",
        "cs.LG",
        "68T01",
        "I.2; J.4; I.2.1; K.4.3"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, submitted to Machine Learning for Health (ML4H) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.05856v1",
      "published_date": "2024-11-07 01:57:06 UTC",
      "updated_date": "2024-11-07 01:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:37:06.390842"
    },
    {
      "arxiv_id": "2411.04356v1",
      "title": "GaGSL: Global-augmented Graph Structure Learning via Graph Information Bottleneck",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangjie Li",
        "Jiangqing Song",
        "Baoming Zhang",
        "Gaoli Ruan",
        "Junyuan Xie",
        "Chongjun Wang"
      ],
      "abstract": "Graph neural networks (GNNs) are prominent for their effectiveness in\nprocessing graph data for semi-supervised node classification tasks. Most works\nof GNNs assume that the observed structure accurately represents the underlying\nnode relationships. However, the graph structure is inevitably noisy or\nincomplete in reality, which can degrade the quality of graph representations.\nTherefore, it is imperative to learn a clean graph structure that balances\nperformance and robustness. In this paper, we propose a novel method named\n\\textit{Global-augmented Graph Structure Learning} (GaGSL), guided by the Graph\nInformation Bottleneck (GIB) principle. The key idea behind GaGSL is to learn a\ncompact and informative graph structure for node classification tasks.\nSpecifically, to mitigate the bias caused by relying solely on the original\nstructure, we first obtain augmented features and augmented structure through\nglobal feature augmentation and global structure augmentation. We then input\nthe augmented features and augmented structure into a structure estimator with\ndifferent parameters for optimization and re-definition of the graph structure,\nrespectively. The redefined structures are combined to form the final graph\nstructure. Finally, we employ GIB based on mutual information to guide the\noptimization of the graph structure to obtain the minimum sufficient graph\nstructure. Comprehensive evaluations across a range of datasets reveal the\noutstanding performance and robustness of GaGSL compared with the\nstate-of-the-art methods.",
      "tldr_zh": "本论文提出 GaGSL（Global-augmented Graph Structure Learning）方法，基于 Graph Information Bottleneck (GIB) 原则，旨在学习一个紧凑且信息丰富的图结构，以应对 GNNs 在半监督节点分类任务中因图结构噪声或不完整而导致的性能下降问题。具体而言，GaGSL 通过全局特征增强和全局结构增强生成增强特征和增强结构，然后利用结构估计器优化并重新定义图结构，最终结合 GIB 基于互信息的指导优化，获得最小充分的图结构。在多个数据集上的全面评估显示，GaGSL 比现有最先进方法表现出色，具有更高的性能和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04356v1",
      "published_date": "2024-11-07 01:23:48 UTC",
      "updated_date": "2024-11-07 01:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:37:18.755526"
    },
    {
      "arxiv_id": "2411.04337v1",
      "title": "Model and Deep learning based Dynamic Range Compression Inversion",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Sun",
        "Dominique Fourer",
        "Hichem Maaref"
      ],
      "abstract": "Dynamic Range Compression (DRC) is a popular audio effect used to control the\ndynamic range of a signal. Inverting DRC can also help to restore the original\ndynamics to produce new mixes and/or to improve the overall quality of the\naudio signal. Since, state-of-the-art DRC inversion techniques either ignore\nparameters or require precise parameters that are difficult to estimate, we\nfill the gap by combining a model-based approach with neural networks for DRC\ninversion. To this end, depending on the scenario, we use different neural\nnetworks to estimate DRC parameters. Then, a model-based inversion is completed\nto restore the original audio signal. Our experimental results show the\neffectiveness and robustness of the proposed method in comparison to several\nstate-of-the-art methods, when applied on two music datasets.",
      "tldr_zh": "本研究针对Dynamic Range Compression (DRC)反转问题，提出了一种结合模型-based方法和神经网络的框架，以解决现有技术忽略参数或参数估计困难的局限性。\n该方法根据不同场景使用神经网络估计DRC参数，然后通过模型-based反转恢复原始音频信号。\n实验结果表明，该框架在两个音乐数据集上比现有方法更有效和鲁棒。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04337v1",
      "published_date": "2024-11-07 00:33:07 UTC",
      "updated_date": "2024-11-07 00:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:37:30.805026"
    },
    {
      "arxiv_id": "2411.05044v1",
      "title": "Deep Heuristic Learning for Real-Time Urban Pathfinding",
      "title_zh": "深度启发式学习用于实时城市路径规划",
      "authors": [
        "Mohamed Hussein Abo El-Ela",
        "Ali Hamdi Fergany"
      ],
      "abstract": "This paper introduces a novel approach to urban pathfinding by transforming\ntraditional heuristic-based algorithms into deep learning models that leverage\nreal-time contextual data, such as traffic and weather conditions. We propose\ntwo methods: an enhanced A* algorithm that dynamically adjusts routes based on\ncurrent environmental conditions, and a neural network model that predicts the\nnext optimal path segment using historical and live data. An extensive\nbenchmark was conducted to compare the performance of different deep learning\nmodels, including MLP, GRU, LSTM, Autoencoders, and Transformers. Both methods\nwere evaluated in a simulated urban environment in Berlin, with the neural\nnetwork model outperforming traditional methods, reducing travel times by up to\n40%, while the enhanced A* algorithm achieved a 34% improvement. These results\ndemonstrate the potential of deep learning to optimize urban navigation in real\ntime, providing more adaptable and efficient routing solutions.",
      "tldr_zh": "这篇论文提出了一种创新方法，将传统启发式算法转化为深度学习模型，用于实时城市路径规划，充分利用交通和天气等上下文数据。论文引入两种具体方法：增强的 A* 算法，能够动态调整路线以适应当前环境，以及一个神经网络模型，利用历史和实时数据预测最佳路径段。通过在模拟柏林城市环境中进行的基准测试，比较了 MLP、GRU、LSTM、Autoencoders 和 Transformers 等模型，结果显示神经网络模型比传统方法减少旅行时间高达40%，而增强 A* 算法实现了34%的改善。这些发现突显了深度学习在提供更适应性和高效的城市导航解决方案方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05044v1",
      "published_date": "2024-11-07 00:22:04 UTC",
      "updated_date": "2024-11-07 00:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:37:43.121767"
    },
    {
      "arxiv_id": "2411.05043v1",
      "title": "Multi-language Video Subtitle Dataset for Image-based Text Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Thanadol Singkhornart",
        "Olarik Surinta"
      ],
      "abstract": "The Multi-language Video Subtitle Dataset is a comprehensive collection\ndesigned to support research in text recognition across multiple languages.\nThis dataset includes 4,224 subtitle images extracted from 24 videos sourced\nfrom online platforms. It features a wide variety of characters, including Thai\nconsonants, vowels, tone marks, punctuation marks, numerals, Roman characters,\nand Arabic numerals. With 157 unique characters, the dataset provides a\nresource for addressing challenges in text recognition within complex\nbackgrounds. It addresses the growing need for high-quality, multilingual text\nrecognition data, particularly as videos with embedded subtitles become\nincreasingly dominant on platforms like YouTube and Facebook. The variability\nin text length, font, and placement within these images adds complexity,\noffering a valuable resource for developing and evaluating deep learning\nmodels. The dataset facilitates accurate text transcription from video content\nwhile providing a foundation for improving computational efficiency in text\nrecognition systems. As a result, it holds significant potential to drive\nadvancements in research and innovation across various computer science\ndisciplines, including artificial intelligence, deep learning, computer vision,\nand pattern recognition.",
      "tldr_zh": "本研究介绍了Multi-language Video Subtitle Dataset，这是一个针对图像-based文本识别的多语言数据集，由24个在线视频中提取的4,224个字幕图像组成。该数据集涵盖157个独特字符，包括Thai辅音、元音、tone marks、punctuation marks、numerals、Roman characters和Arabic numerals，旨在解决复杂背景下的文本识别挑战。数据集通过提供文本长度、字体和位置的多样性，支持开发和评估deep learning模型，提高文本转录的准确性和计算效率，从而推动artificial intelligence、computer vision和pattern recognition等领域的研究创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05043v1",
      "published_date": "2024-11-07 00:06:53 UTC",
      "updated_date": "2024-11-07 00:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:37:54.531982"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 115,
  "processed_papers_count": 115,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T22:38:17.624833"
}