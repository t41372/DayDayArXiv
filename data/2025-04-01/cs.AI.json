{
  "date": "2025-04-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-01 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 模型的优化、联邦学习、多模态处理和实际应用创新，其中 LLM 在推理、多语言支持和医疗领域的突破最为引人注目，令人印象深刻的文章包括 Cohere 团队的 \"Command A\" 模型，以及涉及医学 AI 和高效计算方法的创新研究。\n\n### 重点论文回顾\n今天共有 128 篇论文，我将优先讨论那些创新性强、可能引发话题的论文（如 LLM 优化和联邦学习），并快速掠过较基础或应用性不强的内容。以下按主题归类，突出核心贡献。\n\n**LLM 优化与推理（高话题度领域）**  \n- **Command A: An Enterprise-Ready Large Language Model**（Command A: 一个企业级大型语言模型）  \n  这篇论文由 Cohere 团队发布，提出 Command A 模型，支持多语言和代理优化，通过混合架构提升企业任务效率，主要贡献是实现高效的检索增强生成（RAG）和工具使用，显著改善实际应用中的性能。\n\n- **μKE: Matryoshka Unstructured Knowledge Editing of Large Language Models**（μKE: Matryoshka 风格的非结构化知识编辑）  \n  作者包括 Xiangyu Zhang，引入 Matryoshka 风格目标来编辑 LLM 知识，保持因果依赖性，主要发现是提升编辑效率达 12.33%，适用于动态知识更新。\n\n- **When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning**（何时求解、何时验证：LLM 推理的计算最优问题求解和生成验证）  \n  这篇研究探索 LLM 在推理任务中的计算最优策略，通过生成奖励模型（GenRM）优化求解与验证平衡，发现扩展求解生成比验证更高效，提升了数学推理性能。\n\n- **MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs**（MedReason: 通过知识图谱激发 LLM 的事实性医学推理步骤）  \n  作者包括 Yuyin Zhou，提出使用知识图谱引导 LLM 进行医学推理，主要贡献是构建高品质数据集，提升诊断准确率达 7.7%，为临床 AI 工具提供可靠框架。\n\n- **Multilingual and Multi-Accent Jailbreaking of Audio LLMs**（多语言和多口音的音频 LLM 越狱攻击）  \n  这篇论文揭示音频 LLM 的漏洞，通过多模态攻击提升越狱成功率达 57.25%，强调了 LLM 在语音安全中的弱点，并提出防御策略。\n\n- **Brains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics**（Brains vs. Bytes: 评估 LLM 在奥林匹克数学中的能力）  \n  作者团队包括 Huan Liu，他们发现 LLM 在数学推理中依赖模式识别而非真正推理，准确率远低于人类，呼吁更严格的基准测试。\n\n**联邦学习与隐私保护（高效计算创新）**  \n- **FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization**（FedPaI: 通过初始化剪枝实现联邦学习的极端稀疏性）  \n  这篇论文提出 FedPaI 框架，在联邦学习中实现 98% 稀疏性，同时保持准确率，主要发现是显著减少通信和计算开销，适用于非独立同分布数据。\n\n- **Personalized Federated Training of Diffusion Models with Privacy Guarantees**（个性化联邦训练的扩散模型伴随隐私保证）  \n  作者包括 Kumar Kshitij Patel，开发联邦学习框架训练扩散模型，确保隐私保护并提升合成数据质量，适用于医疗等领域。\n\n**计算机视觉与多模态处理（应用广泛的领域）**  \n- **FUSION: Frequency-guided Underwater Spatial Image recOnstructioN**（FUSION: 频率引导的水下空间图像重建）  \n  论文提出双域框架结合频率和空间信息重建水下图像，主要贡献是提升图像保真度（PSNR 达 23.717 dB），适用于实时应用。\n\n- **GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors**（GeometryCrafter: 使用扩散先验的开放世界视频几何估计）  \n  这篇研究使用扩散模型估计视频几何信息，实现高保真 3D 重建，显著提升时空一致性。\n\n- **TDBench: Benchmarking Vision-Language Models in Understanding Top-Down Images**（TDBench: 用于理解顶部视图图像的视觉语言模型基准）  \n  作者构建 TDBench 数据集，评估多模态模型对顶部视图图像的理解能力，主要发现是改进模型在自主导航中的性能。\n\n**其他值得一提的论文（快速概述）**  \n- **Dynamic Graph Structure Estimation for Learning Multivariate Point Process using Spiking Neural Networks**（动态图结构估计用于基于脉冲神经网络的学习多变量点过程）  \n  提出 Spiking Dynamic Graph Network (SDGN)，动态估计时空图结构，提升预测准确率，适用于神经科学和社交数据。\n\n- **Automated Factual Benchmarking for In-Car Conversational Systems using Large Language Models**（使用大型语言模型的自动事实基准测试车载对话系统）  \n  开发 LLM 基准测试方法，确保车载系统事实正确性，准确率达 90%，并创建新数据集。\n\n- **Epistemic Alignment: A Mediating Framework for User-LLM Knowledge Delivery**（认识论对齐: 用户-LLM 知识传递的中介框架）  \n  构建框架处理 LLM 知识传递偏好，提升用户交互可靠性。\n\n其余论文，如一些纯理论模型或特定应用（如第10、15、20、22等），虽有贡献但较常规，我仅简要提及：它们涉及领域如图像分类、神经网络优化和量子计算，但未带来突破性创新，例如第8篇的轻量级图像表示方法和第14篇的 SAT 求解优化，均在各自领域提供细微改进，却未显著影响整体趋势。\n\n总之，今天的论文强调 AI 模型的鲁棒性和实际应用，LLM 领域的进展尤为突出，期待这些创新推动更可靠的 AI 系统。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.01252v1",
      "title": "Plan-and-Act using Large Language Models for Interactive Agreement",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuhiro Sasabuchi",
        "Naoki Wake",
        "Atsushi Kanehira",
        "Jun Takamatsu",
        "Katsushi Ikeuchi"
      ],
      "abstract": "Recent large language models (LLMs) are capable of planning robot actions. In\nthis paper, we explore how LLMs can be used for planning actions with tasks\ninvolving situational human-robot interaction (HRI). A key problem of applying\nLLMs in situational HRI is balancing between \"respecting the current human's\nactivity\" and \"prioritizing the robot's task,\" as well as understanding the\ntiming of when to use the LLM to generate an action plan. In this paper, we\npropose a necessary plan-and-act skill design to solve the above problems. We\nshow that a critical factor for enabling a robot to switch between passive /\nactive interaction behavior is to provide the LLM with an action text about the\ncurrent robot's action. We also show that a second-stage question to the LLM\n(about the next timing to call the LLM) is necessary for planning actions at an\nappropriate timing. The skill design is applied to an Engage skill and is\ntested on four distinct interaction scenarios. We show that by using the skill\ndesign, LLMs can be leveraged to easily scale to different HRI scenarios with a\nreasonable success rate reaching 90% on the test scenarios.",
      "tldr_zh": "本文探讨如何使用Large Language Models (LLMs)为情境性Human-Robot Interaction (HRI)任务规划机器人动作，重点解决平衡“尊重人类活动”和“优先机器人任务”的问题，以及确定调用LLMs的时机。研究提出一种plan-and-act技能设计，包括向LLMs提供当前机器人动作文本以切换被动/主动交互行为，并通过第二阶段问题优化行动计划的时机。该设计应用于Engage技能，并在四个交互场景中测试，成功率达到90%，展示了LLMs在HRI场景扩展的可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01252v1",
      "published_date": "2025-04-01 23:41:05 UTC",
      "updated_date": "2025-04-01 23:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:12:56.742787"
    },
    {
      "arxiv_id": "2504.01248v1",
      "title": "Automated Factual Benchmarking for In-Car Conversational Systems using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Giebisch",
        "Ken E. Friedl",
        "Lev Sorokin",
        "Andrea Stocco"
      ],
      "abstract": "In-car conversational systems bring the promise to improve the in-vehicle\nuser experience. Modern conversational systems are based on Large Language\nModels (LLMs), which makes them prone to errors such as hallucinations, i.e.,\ninaccurate, fictitious, and therefore factually incorrect information. In this\npaper, we present an LLM-based methodology for the automatic factual\nbenchmarking of in-car conversational systems. We instantiate our methodology\nwith five LLM-based methods, leveraging ensembling techniques and diverse\npersonae to enhance agreement and minimize hallucinations. We use our\nmethodology to evaluate CarExpert, an in-car retrieval-augmented conversational\nquestion answering system, with respect to the factual correctness to a\nvehicle's manual. We produced a novel dataset specifically created for the\nin-car domain, and tested our methodology against an expert evaluation. Our\nresults show that the combination of GPT-4 with the Input Output Prompting\nachieves over 90 per cent factual correctness agreement rate with expert\nevaluations, other than being the most efficient approach yielding an average\nresponse time of 4.5s. Our findings suggest that LLM-based testing constitutes\na viable approach for the validation of conversational systems regarding their\nfactual correctness.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的自动事实基准测试方法，用于评估车载对话系统的准确性，特别针对 hallucinations（幻觉）问题，以确保信息事实正确。方法包括五种 LLM-based 技术，通过 ensembling techniques（集成技术）和 diverse personae（多样化角色）来提高一致性和减少错误，并应用于 CarExpert 系统——一个检索增强的对话问答系统。实验使用一个新创建的 in-car 领域数据集进行测试，结果显示 GPT-4 结合 Input Output Prompting 的方法与专家评估一致率超过 90%，响应时间平均 4.5 秒，证明 LLM-based 测试是验证对话系统事实正确性的高效可行方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in IEEE Intelligent Vehicles Symposium Conference (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.01248v1",
      "published_date": "2025-04-01 23:25:30 UTC",
      "updated_date": "2025-04-01 23:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:13:09.113667"
    },
    {
      "arxiv_id": "2504.01246v1",
      "title": "Dynamic Graph Structure Estimation for Learning Multivariate Point Process using Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Biswadeep Chakraborty",
        "Hemant Kumawat",
        "Beomseok Kang",
        "Saibal Mukhopadhyay"
      ],
      "abstract": "Modeling and predicting temporal point processes (TPPs) is critical in\ndomains such as neuroscience, epidemiology, finance, and social sciences. We\nintroduce the Spiking Dynamic Graph Network (SDGN), a novel framework that\nleverages the temporal processing capabilities of spiking neural networks\n(SNNs) and spike-timing-dependent plasticity (STDP) to dynamically estimate\nunderlying spatio-temporal functional graphs. Unlike existing methods that rely\non predefined or static graph structures, SDGN adapts to any dataset by\nlearning dynamic spatio-temporal dependencies directly from the event data,\nenhancing generalizability and robustness. While SDGN offers significant\nimprovements over prior methods, we acknowledge its limitations in handling\ndense graphs and certain non-Gaussian dependencies, providing opportunities for\nfuture refinement. Our evaluations, conducted on both synthetic and real-world\ndatasets including NYC Taxi, 911, Reddit, and Stack Overflow, demonstrate that\nSDGN achieves superior predictive accuracy while maintaining computational\nefficiency. Furthermore, we include ablation studies to highlight the\ncontributions of its core components.",
      "tldr_zh": "本文提出 Spiking Dynamic Graph Network (SDGN)，一个创新框架，利用 spiking neural networks (SNNs) 和 spike-timing-dependent plasticity (STDP) 来动态估计多变量时序点过程 (TPPs) 的时空功能图。不同于依赖预定义或静态图结构的现有方法，SDGN 通过从事件数据中学习动态依赖，提升了模型的泛化性和鲁棒性。实验在合成和真实数据集（如 NYC Taxi、911、Reddit 和 Stack Overflow）上显示，SDGN 实现了更高的预测准确性和计算效率，并通过消融研究突出了核心组件的贡献。尽管如此，该框架在处理密集图和某些非-Gaussian 依赖方面存在局限性，为未来优化提供了机会。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01246v1",
      "published_date": "2025-04-01 23:23:10 UTC",
      "updated_date": "2025-04-01 23:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:13:21.527991"
    },
    {
      "arxiv_id": "2504.01243v2",
      "title": "FUSION: Frequency-guided Underwater Spatial Image recOnstructioN",
      "title_zh": "FUSION：频率引导的水下空间图像重建",
      "authors": [
        "Jaskaran Singh Walia",
        "Shravan Venkatraman",
        "Pavithra LK"
      ],
      "abstract": "Underwater images suffer from severe degradations, including color\ndistortions, reduced visibility, and loss of structural details due to\nwavelength-dependent attenuation and scattering. Existing enhancement methods\nprimarily focus on spatial-domain processing, neglecting the frequency domain's\npotential to capture global color distributions and long-range dependencies. To\naddress these limitations, we propose FUSION, a dual-domain deep learning\nframework that jointly leverages spatial and frequency domain information.\nFUSION independently processes each RGB channel through multi-scale\nconvolutional kernels and adaptive attention mechanisms in the spatial domain,\nwhile simultaneously extracting global structural information via FFT-based\nfrequency attention. A Frequency Guided Fusion module integrates complementary\nfeatures from both domains, followed by inter-channel fusion and adaptive\nchannel recalibration to ensure balanced color distributions. Extensive\nexperiments on benchmark datasets (UIEB, EUVP, SUIM-E) demonstrate that FUSION\nachieves state-of-the-art performance, consistently outperforming existing\nmethods in reconstruction fidelity (highest PSNR of 23.717 dB and SSIM of 0.883\non UIEB), perceptual quality (lowest LPIPS of 0.112 on UIEB), and visual\nenhancement metrics (best UIQM of 3.414 on UIEB), while requiring significantly\nfewer parameters (0.28M) and lower computational complexity, demonstrating its\nsuitability for real-time underwater imaging applications.",
      "tldr_zh": "该研究提出FUSION框架，一种基于频率引导的双域深度学习方法，用于提升水下图像的增强效果，通过结合空间域（使用多尺度卷积核和自适应注意力机制处理RGB通道）和频率域（通过FFT-based频率注意力提取全局结构信息）来解决颜色失真和细节丢失问题。FUSION引入Frequency Guided Fusion模块来整合双域特征，并进行通道间融合和自适应校准，以实现均衡的颜色分布。在UIEB、EUVP和SUIM-E基准数据集上的实验显示，FUSION在重建保真度（最高PSNR 23.717 dB和SSIM 0.883）、感知质量（最低LPIPS 0.112）和视觉增强指标（最佳UIQM 3.414）上均超越现有方法，同时仅需0.28M参数和较低计算复杂度，适合实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01243v2",
      "published_date": "2025-04-01 23:16:19 UTC",
      "updated_date": "2025-04-13 19:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:13:33.299635"
    },
    {
      "arxiv_id": "2504.01228v1",
      "title": "TenAd: A Tensor-based Low-rank Black Box Adversarial Attack for Video Classification",
      "title_zh": "TenAd：一种基于张量的低秩黑盒对抗攻击，用于视频分类",
      "authors": [
        "Kimia haghjooei",
        "Mansoor Rezghi"
      ],
      "abstract": "Deep learning models have achieved remarkable success in computer vision but\nremain vulnerable to adversarial attacks, particularly in black-box settings\nwhere model details are unknown. Existing adversarial attack methods(even those\nworks with key frames) often treat video data as simple vectors, ignoring their\ninherent multi-dimensional structure, and require a large number of queries,\nmaking them inefficient and detectable. In this paper, we propose\n\\textbf{TenAd}, a novel tensor-based low-rank adversarial attack that leverages\nthe multi-dimensional properties of video data by representing videos as\nfourth-order tensors. By exploiting low-rank attack, our method significantly\nreduces the search space and the number of queries needed to generate\nadversarial examples in black-box settings. Experimental results on standard\nvideo classification datasets demonstrate that \\textbf{TenAd} effectively\ngenerates imperceptible adversarial perturbations while achieving higher attack\nsuccess rates and query efficiency compared to state-of-the-art methods. Our\napproach outperforms existing black-box adversarial attacks in terms of success\nrate, query efficiency, and perturbation imperceptibility, highlighting the\npotential of tensor-based methods for adversarial attacks on video models.",
      "tldr_zh": "本论文提出TenAd，一种基于张量的低秩黑盒对抗攻击方法，用于视频分类，以解决现有方法忽略视频多维结构并需大量查询的问题。TenAd将视频表示为四阶张量，并利用低秩攻击减少搜索空间和查询次数，从而生成不易察觉的对抗扰动。实验在标准视频分类数据集上表明，TenAd在攻击成功率、查询效率和扰动隐蔽性方面均优于现有黑盒攻击方法，突显了张量方法在视频模型对抗攻击中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01228v1",
      "published_date": "2025-04-01 22:35:28 UTC",
      "updated_date": "2025-04-01 22:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:13:44.511148"
    },
    {
      "arxiv_id": "2504.01225v1",
      "title": "A Conformal Risk Control Framework for Granular Word Assessment and Uncertainty Calibration of CLIPScore Quality Estimates",
      "title_zh": "翻译失败",
      "authors": [
        "Gonçalo Gomes",
        "Chrysoula Zerva",
        "Bruno Martins"
      ],
      "abstract": "This study explores current limitations of learned image captioning\nevaluation metrics, specifically the lack of granular assessment for individual\nword misalignments within captions, and the reliance on single-point quality\nestimates without considering uncertainty. To address these limitations, we\npropose a simple yet effective strategy for generating and calibrating\nCLIPScore distributions. Leveraging a model-agnostic conformal risk control\nframework, we calibrate CLIPScore values for task-specific control variables,\nto tackle the aforementioned two limitations. Experimental results demonstrate\nthat using conformal risk control, over the distributions produced with simple\nmethods such as input masking, can achieve competitive performance compared to\nmore complex approaches. Our method effectively detects misaligned words, while\nproviding formal guarantees aligned with desired risk levels, and improving the\ncorrelation between uncertainty estimations and prediction errors, thus\nenhancing the overall reliability of caption evaluation metrics.",
      "tldr_zh": "本研究探讨了图像标题评估指标如 CLIPScore 的局限性，包括对单个单词失配的细粒度评估不足，以及仅依赖单一质量估计而忽略不确定性。\n为了解决这些问题，作者提出了一种简单策略，通过模型无关的 conformal risk control 框架生成并校准 CLIPScore 分布，针对特定任务的控制变量进行优化。\n实验结果显示，该方法比简单输入掩码等方法更具竞争力，能够有效检测失配单词，提供与期望风险水平一致的正式保证，并提高了不确定性估计与预测错误的关联性，从而提升了标题评估指标的整体可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01225v1",
      "published_date": "2025-04-01 22:25:00 UTC",
      "updated_date": "2025-04-01 22:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:13:57.450386"
    },
    {
      "arxiv_id": "2504.01216v1",
      "title": "Detecting PTSD in Clinical Interviews: A Comparative Analysis of NLP Methods and Large Language Models",
      "title_zh": "在临床访谈中检测 PTSD：NLP 方法和大型语言模型的比较分析",
      "authors": [
        "Feng Chen",
        "Dror Ben-Zeev",
        "Gillian Sparks",
        "Arya Kadakia",
        "Trevor Cohen"
      ],
      "abstract": "Post-Traumatic Stress Disorder (PTSD) remains underdiagnosed in clinical\nsettings, presenting opportunities for automated detection to identify\npatients. This study evaluates natural language processing approaches for\ndetecting PTSD from clinical interview transcripts. We compared general and\nmental health-specific transformer models (BERT/RoBERTa), embedding-based\nmethods (SentenceBERT/LLaMA), and large language model prompting strategies\n(zero-shot/few-shot/chain-of-thought) using the DAIC-WOZ dataset.\nDomain-specific models significantly outperformed general models\n(Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485). LLaMA embeddings with neural\nnetworks achieved the highest performance (F1=0.700). Zero-shot prompting using\nDSM-5 criteria yielded competitive results without training data (F1=0.657).\nPerformance varied significantly across symptom severity and comorbidity\nstatus, with higher accuracy for severe PTSD cases and patients with comorbid\ndepression. Our findings highlight the potential of domain-adapted embeddings\nand LLMs for scalable screening while underscoring the need for improved\ndetection of nuanced presentations and offering insights for developing\nclinically viable AI tools for PTSD assessment.",
      "tldr_zh": "本研究比较了多种自然语言处理 (NLP) 方法和大型语言模型 (LLMs) 在临床访谈中检测创伤后应激障碍 (PTSD) 的性能，使用 DAIC-WOZ 数据集评估了通用 transformer 模型 (如 BERT/RoBERTa)、领域特定模型 (如 Mental-RoBERTa) 以及基于嵌入的方法 (如 SentenceBERT/LLaMA)，并测试了 zero-shot/few-shot/chain-of-thought 提示策略。结果显示，领域特定模型显著优于通用模型 (Mental-RoBERTa F1=0.643 vs. RoBERTa-base 0.485)，而 LLaMA 嵌入结合神经网络取得了最高表现 (F1=0.700)，zero-shot 提示使用 DSM-5 标准也达到了竞争性水平 (F1=0.657)。性能因 PTSD 症状严重程度和共病状态（如抑郁）而异，对严重病例的检测准确率更高，该研究突出了领域适应嵌入和 LLMs 在可扩展筛查中的潜力，并为开发临床可行的 AI 工具提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.01216v1",
      "published_date": "2025-04-01 22:06:28 UTC",
      "updated_date": "2025-04-01 22:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:14:09.485581"
    },
    {
      "arxiv_id": "2504.01214v1",
      "title": "PolygoNet: Leveraging Simplified Polygonal Representation for Effective Image Classification",
      "title_zh": "PolygoNet：利用简化的多边形表示进行有效的图像分类",
      "authors": [
        "Salim Khazem",
        "Jeremy Fix",
        "Cédric Pradalier"
      ],
      "abstract": "Deep learning models have achieved significant success in various image\nrelated tasks. However, they often encounter challenges related to\ncomputational complexity and overfitting. In this paper, we propose an\nefficient approach that leverages polygonal representations of images using\ndominant points or contour coordinates. By transforming input images into these\ncompact forms, our method significantly reduces computational requirements,\naccelerates training, and conserves resources making it suitable for real time\nand resource constrained applications. These representations inherently capture\nessential image features while filtering noise, providing a natural\nregularization effect that mitigates overfitting. The resulting lightweight\nmodels achieve performance comparable to state of the art methods using full\nresolution images while enabling deployment on edge devices. Extensive\nexperiments on benchmark datasets validate the effectiveness of our approach in\nreducing complexity, improving generalization, and facilitating edge computing\napplications. This work demonstrates the potential of polygonal representations\nin advancing efficient and scalable deep learning solutions for real world\nscenarios. The code for the experiments of the paper is provided in\nhttps://github.com/salimkhazem/PolygoNet.",
      "tldr_zh": "本文提出 PolygoNet 方法，利用简化多边形表示（基于主导点或轮廓坐标）来处理图像分类问题，从而降低深度学习模型的计算复杂性和过拟合风险。相比传统方法，该方法通过捕捉图像本质特征并过滤噪声，实现训练加速和资源节约，适合实时及边缘设备应用。实验在基准数据集上验证了 PolygoNet 的有效性，其性能与 state-of-the-art 模型相当，同时提升了泛化和部署灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01214v1",
      "published_date": "2025-04-01 22:05:00 UTC",
      "updated_date": "2025-04-01 22:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:14:20.160221"
    },
    {
      "arxiv_id": "2504.01211v1",
      "title": "Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding",
      "title_zh": "翻译失败",
      "authors": [
        "Nishanth Venkatesh S.",
        "Heeseung Bang",
        "Andreas A. Malikopoulos"
      ],
      "abstract": "In this paper, we expand the Bayesian persuasion framework to account for\nunobserved confounding variables in sender-receiver interactions. While\ntraditional models assume that belief updates follow Bayesian principles,\nreal-world scenarios often involve hidden variables that impact the receiver's\nbelief formation and decision-making. We conceptualize this as a sequential\ndecision-making problem, where the sender and receiver interact over multiple\nrounds. In each round, the sender communicates with the receiver, who also\ninteracts with the environment. Crucially, the receiver's belief update is\naffected by an unobserved confounding variable. By reformulating this scenario\nas a Partially Observable Markov Decision Process (POMDP), we capture the\nsender's incomplete information regarding both the dynamics of the receiver's\nbeliefs and the unobserved confounder. We prove that finding an optimal\nobservation-based policy in this POMDP is equivalent to solving for an optimal\nsignaling strategy in the original persuasion framework. Furthermore, we\ndemonstrate how this reformulation facilitates the application of proximal\nlearning for off-policy evaluation in the persuasion process. This advancement\nenables the sender to evaluate alternative signaling strategies using only\nobservational data from a behavioral policy, thus eliminating the necessity for\ncostly new experiments.",
      "tldr_zh": "本文扩展了Bayesian persuasion框架，以处理发送者-接收者互动中的unobserved confounding变量，这些变量会影响接收者的信念更新和决策过程。作者将这一顺序决策问题重构为Partially Observable Markov Decision Process (POMDP)，证明了在POMDP中找到最优观察-based政策等价于原框架中的最优信令策略。进一步，通过应用proximal learning进行off-policy evaluation，论文展示了如何使用观察数据评估替代信令策略，从而避免了昂贵的实验需求。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01211v1",
      "published_date": "2025-04-01 21:50:32 UTC",
      "updated_date": "2025-04-01 21:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:14:31.953474"
    },
    {
      "arxiv_id": "2504.01208v1",
      "title": "Lightweight Deep Models for Dermatological Disease Detection: A Study on Instance Selection and Channel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Mateos Gonzalez",
        "Estefani Jaramilla Nava",
        "Abraham Sánchez Morales",
        "Jesús García-Ramírez",
        "Ricardo Ramos-Aguilar"
      ],
      "abstract": "The identification of dermatological disease is an important problem in\nMexico according with different studies. Several works in literature use the\ndatasets of different repositories without applying a study of the data\nbehavior, especially in medical images domain. In this work, we propose a\nmethodology to preprocess dermaMNIST dataset in order to improve its quality\nfor the classification stage, where we use lightweight convolutional neural\nnetworks. In our results, we reduce the number of instances for the neural\nnetwork training obtaining a similar performance of models as ResNet.",
      "tldr_zh": "本研究针对墨西哥皮肤病识别问题，提出了一种预处理 dermaMNIST 数据集的方法，包括实例选择和通道优化，以提升数据质量并用于分类任务。采用轻量级卷积神经网络(CNN)进行模型训练，结果显示通过减少训练实例，模型性能可与 ResNet 相当，从而提高了计算效率和实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to Mexican Conference on Pattern Recognition 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01208v1",
      "published_date": "2025-04-01 21:47:57 UTC",
      "updated_date": "2025-04-01 21:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:14:43.626108"
    },
    {
      "arxiv_id": "2504.01205v1",
      "title": "Epistemic Alignment: A Mediating Framework for User-LLM Knowledge Delivery",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Clark",
        "Hua Shen",
        "Bill Howe",
        "Tanushree Mitra"
      ],
      "abstract": "LLMs increasingly serve as tools for knowledge acquisition, yet users cannot\neffectively specify how they want information presented. When users request\nthat LLMs \"cite reputable sources,\" \"express appropriate uncertainty,\" or\n\"include multiple perspectives,\" they discover that current interfaces provide\nno structured way to articulate these preferences. The result is prompt sharing\nfolklore: community-specific copied prompts passed through trust relationships\nrather than based on measured efficacy. We propose the Epistemic Alignment\nFramework, a set of ten challenges in knowledge transmission derived from the\nphilosophical literature of epistemology, concerning issues such as evidence\nquality assessment and calibration of testimonial reliance. The framework\nserves as a structured intermediary between user needs and system capabilities,\ncreating a common vocabulary to bridge the gap between what users want and what\nsystems deliver. Through a thematic analysis of custom prompts and\npersonalization strategies shared on online communities where these issues are\nactively discussed, we find users develop elaborate workarounds to address each\nof the challenges. We then apply our framework to two prominent model\nproviders, OpenAI and Anthropic, through content analysis of their documented\npolicies and product features. Our analysis shows that while these providers\nhave partially addressed the challenges we identified, they fail to establish\nadequate mechanisms for specifying epistemic preferences, lack transparency\nabout how preferences are implemented, and offer no verification tools to\nconfirm whether preferences were followed. For AI developers, the Epistemic\nAlignment Framework offers concrete guidance for supporting diverse approaches\nto knowledge; for users, it works toward information delivery that aligns with\ntheir specific needs rather than defaulting to one-size-fits-all approaches.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在知识传递中的问题，用户难以指定信息呈现偏好，如引用可靠来源或表达不确定性，导致依赖社区共享的提示。该研究提出 Epistemic Alignment Framework，这是一个中介框架，基于认识论（epistemology）文献，定义了十个知识传输挑战，包括证据质量评估和证言依赖校准，以桥接用户需求和系统能力。通过主题分析用户自定义提示和内容分析 OpenAI 与 Anthropic 的政策，发现用户采用复杂工作around，而模型提供商虽部分解决了挑战，但缺乏指定偏好机制、透明度和验证工具。该框架为 AI 开发者提供指导，支持多样化知识方法，并帮助用户实现更个性化的信息交付。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01205v1",
      "published_date": "2025-04-01 21:38:12 UTC",
      "updated_date": "2025-04-01 21:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:14:55.894499"
    },
    {
      "arxiv_id": "2504.01201v1",
      "title": "Medical large language models are easily distracted",
      "title_zh": "医学大型语言模型容易分心",
      "authors": [
        "Krithik Vishwanath",
        "Anton Alyakin",
        "Daniel Alexander Alber",
        "Jin Vivian Lee",
        "Douglas Kondziolka",
        "Eric Karl Oermann"
      ],
      "abstract": "Large language models (LLMs) have the potential to transform medicine, but\nreal-world clinical scenarios contain extraneous information that can hinder\nperformance. The rise of assistive technologies like ambient dictation, which\nautomatically generates draft notes from live patient encounters, has the\npotential to introduce additional noise making it crucial to assess the ability\nof LLM's to filter relevant data. To investigate this, we developed\nMedDistractQA, a benchmark using USMLE-style questions embedded with simulated\nreal-world distractions. Our findings show that distracting statements\n(polysemous words with clinical meanings used in a non-clinical context or\nreferences to unrelated health conditions) can reduce LLM accuracy by up to\n17.9%. Commonly proposed solutions to improve model performance such as\nretrieval-augmented generation (RAG) and medical fine-tuning did not change\nthis effect and in some cases introduced their own confounders and further\ndegraded performance. Our findings suggest that LLMs natively lack the logical\nmechanisms necessary to distinguish relevant from irrelevant clinical\ninformation, posing challenges for real-world applications. MedDistractQA and\nour results highlights the need for robust mitigation strategies to enhance LLM\nresilience to extraneous information.",
      "tldr_zh": "这篇论文探讨了大语言模型(LLMs)在医学应用中容易受到无关信息的干扰，导致性能下降。研究者开发了MedDistractQA基准，使用USMLE风格的问题嵌入模拟真实世界的distractions（如多义词在非临床语境中使用或无关健康状况的引用），发现这些干扰可使LLMs准确率降低高达17.9%。常见的解决方案如检索增强生成(RAG)和医学微调未能有效缓解这一问题，有时甚至引入新干扰并进一步恶化表现。论文强调，LLMs缺乏区分相关与无关临床信息的内在逻辑机制，这对实际应用构成挑战，并呼吁开发更robust的mitigation策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 2 main figures, 6 extended figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01201v1",
      "published_date": "2025-04-01 21:34:01 UTC",
      "updated_date": "2025-04-01 21:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:15:09.149381"
    },
    {
      "arxiv_id": "2504.01196v1",
      "title": "$μ$KE: Matryoshka Unstructured Knowledge Editing of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zian Su",
        "Ziyang Huang",
        "Kaiyuan Zhang",
        "Xiangyu Zhang"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful knowledge bases yet are\nlimited by static training data, leading to issues such as hallucinations and\nsafety risks. Editing a model's internal knowledge through the locate-and-edit\nparadigm has proven a cost-effective alternative to retraining, though current\nunstructured approaches, especially window-based autoregressive methods, often\ndisrupt the causal dependency between early memory updates and later output\ntokens. In this work, we first theoretically analyze these limitations and then\nintroduce Matryoshka Unstructured Knowledge Editing ($\\mu$KE), a novel memory\nupdate mechanism that preserves such dependencies via a Matryoshka-style\nobjective and adaptive loss coefficients. Empirical evaluations on two models\nacross four benchmarks demonstrate that $\\mu$KE improves edit efficacy by up to\n12.33% over state-of-the-art methods, and remain robust when applied to diverse\nformatted edits, underscoring its potential for effective unstructured\nknowledge editing in LLMs.",
      "tldr_zh": "大型语言模型 (LLMs) 由于静态训练数据而面临幻觉和安全风险，现有的非结构化知识编辑方法（如基于窗口的自回归方法）往往破坏了早期记忆更新与后续输出标记的因果依赖。论文首先理论分析了这些限制，并引入 $μ$KE，一种 Matryoshka Unstructured Knowledge Editing 机制，通过 Matryoshka-style 目标和自适应损失系数来保留因果依赖，从而提升编辑效能。在两个模型和四个基准上的实证评估表明，$μ$KE 比最先进方法提高了最多 12.33% 的编辑效果，并在多样化编辑格式中保持稳健表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01196v1",
      "published_date": "2025-04-01 21:24:44 UTC",
      "updated_date": "2025-04-01 21:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:15:21.742492"
    },
    {
      "arxiv_id": "2504.01173v1",
      "title": "Neural Approaches to SAT Solving: Design Choices and Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "David Mojžíšek",
        "Jan Hůla",
        "Ziwei Li",
        "Ziyu Zhou",
        "Mikoláš Janota"
      ],
      "abstract": "In this contribution, we provide a comprehensive evaluation of graph neural\nnetworks applied to Boolean satisfiability problems, accompanied by an\nintuitive explanation of the mechanisms enabling the model to generalize to\ndifferent instances. We introduce several training improvements, particularly a\nnovel closest assignment supervision method that dynamically adapts to the\nmodel's current state, significantly enhancing performance on problems with\nlarger solution spaces. Our experiments demonstrate the suitability of\nvariable-clause graph representations with recurrent neural network updates,\nwhich achieve good accuracy on SAT assignment prediction while reducing\ncomputational demands. We extend the base graph neural network into a diffusion\nmodel that facilitates incremental sampling and can be effectively combined\nwith classical techniques like unit propagation. Through analysis of embedding\nspace patterns and optimization trajectories, we show how these networks\nimplicitly perform a process very similar to continuous relaxations of MaxSAT,\noffering an interpretable view of their reasoning process. This understanding\nguides our design choices and explains the ability of recurrent architectures\nto scale effectively at inference time beyond their training distribution,\nwhich we demonstrate with test-time scaling experiments.",
      "tldr_zh": "该研究对图神经网络(graph neural networks)应用于布尔可满足性问题(SAT)进行了全面评估，并解释了模型如何泛化到不同实例。论文引入了closest assignment supervision方法，该方法动态适应模型状态，大幅提升了在较大解空间问题上的性能，同时使用变量-子句图表示和循环神经网络(recurrent neural network)更新来实现高效的SAT赋值预测。实验结果显示，该框架可与经典技术如单位传播(unit propagation)结合，通过分析嵌入空间模式和优化轨迹，揭示网络隐式模拟MaxSAT的连续松弛过程，从而指导设计选择并增强模型在推理时的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01173v1",
      "published_date": "2025-04-01 20:31:01 UTC",
      "updated_date": "2025-04-01 20:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:15:32.594335"
    },
    {
      "arxiv_id": "2504.01154v1",
      "title": "Remember, but also, Forget: Bridging Myopic and Perfect Recall Fairness with Past-Discounting",
      "title_zh": "翻译失败",
      "authors": [
        "Ashwin Kumar",
        "William Yeoh"
      ],
      "abstract": "Dynamic resource allocation in multi-agent settings often requires balancing\nefficiency with fairness over time--a challenge inadequately addressed by\nconventional, myopic fairness measures. Motivated by behavioral insights that\nhuman judgments of fairness evolve with temporal distance, we introduce a novel\nframework for temporal fairness that incorporates past-discounting mechanisms.\nBy applying a tunable discount factor to historical utilities, our approach\ninterpolates between instantaneous and perfect-recall fairness, thereby\ncapturing both immediate outcomes and long-term equity considerations. Beyond\naligning more closely with human perceptions of fairness, this past-discounting\nmethod ensures that the augmented state space remains bounded, significantly\nimproving computational tractability in sequential decision-making settings. We\ndetail the formulation of discounted-recall fairness in both additive and\naveraged utility contexts, illustrate its benefits through practical examples,\nand discuss its implications for designing balanced, scalable resource\nallocation strategies.",
      "tldr_zh": "本研究针对多智能体动态资源分配中的公平性挑战，提出了一种结合过去折扣机制(past-discounting)的框架，以桥接短视(myopic)公平和完美回忆(perfect recall)公平，灵感来源于人类对公平判断随时间变化的行为洞见。\n该框架通过可调折扣因子对历史效用进行折扣处理，实现即时结果与长期公平性的平衡，同时确保状态空间有界，从而显著提升了顺序决策环境的计算可行性。\n作者详细阐述了折扣回忆公平在加法和平均效用上下文中的应用，并通过实际例子证明其益处，为设计高效、可扩展的资源分配策略提供了新思路。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01154v1",
      "published_date": "2025-04-01 19:42:17 UTC",
      "updated_date": "2025-04-01 19:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:15:45.006178"
    },
    {
      "arxiv_id": "2504.01153v3",
      "title": "Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Mahjabin Nahar",
        "Eun-Ju Lee",
        "Jin Won Park",
        "Dongwon Lee"
      ],
      "abstract": "While we increasingly rely on large language models (LLMs) for various tasks,\nthese models are known to produce inaccurate content or `hallucinations' with\npotentially disastrous consequences. The recent integration of web search\nresults into LLMs prompts the question of whether people utilize them to verify\nthe generated content, thereby accurately detecting hallucinations. An online\nexperiment (N = 560) investigated how the provision of search results, either\nstatic (i.e., fixed search results provided by LLM) or dynamic (i.e.,\nparticipant-led searches), affects participants' perceived accuracy of\nLLM-generated content (i.e., genuine, minor hallucination, major\nhallucination), self-confidence in accuracy ratings, as well as their overall\nevaluation of the LLM, as compared to the control condition (i.e., no search\nresults). Results showed that participants in both static and dynamic\nconditions (vs. control) rated hallucinated content to be less accurate and\nperceived the LLM more negatively. However, those in the dynamic condition\nrated genuine content as more accurate and demonstrated greater overall\nself-confidence in their assessments than those in the static search or control\nconditions. We highlighted practical implications of incorporating web search\nfunctionality into LLMs in real-world contexts.",
      "tldr_zh": "本研究探讨了整合网络搜索结果是否能帮助用户检测大型语言模型（LLMs）的幻觉（hallucinations）。研究通过一项在线实验（N=560）比较了三种条件：静态搜索结果（由LLMs提供）、动态搜索结果（参与者自行搜索）和控制组（无搜索结果），评估这些条件对内容准确性感知、自我信心和LLMs整体评价的影响。结果显示，静态和动态搜索组的参与者对幻觉内容的准确性评价更低，并对LLMs持更负面态度，而动态搜索组则对真实内容评估更准确且自信心更强。该发现突出了在现实应用中添加网络搜索功能的实际意义，有助于提升LLMs的可信度和用户体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01153v3",
      "published_date": "2025-04-01 19:36:14 UTC",
      "updated_date": "2025-05-06 17:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:15:56.378869"
    },
    {
      "arxiv_id": "2504.01132v1",
      "title": "Is the Top Still Spinning? Evaluating Subjectivity in Narrative Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Melanie Subbiah",
        "Akankshya Mishra",
        "Grace Kim",
        "Liyan Tang",
        "Greg Durrett",
        "Kathleen McKeown"
      ],
      "abstract": "Determining faithfulness of a claim to a source document is an important\nproblem across many domains. This task is generally treated as a binary\njudgment of whether the claim is supported or unsupported in relation to the\nsource. In many cases, though, whether a claim is supported can be ambiguous.\nFor instance, it may depend on making inferences from given evidence, and\ndifferent people can reasonably interpret the claim as either supported or\nunsupported based on their agreement with those inferences. Forcing binary\nlabels upon such claims lowers the reliability of evaluation. In this work, we\nreframe the task to manage the subjectivity involved with factuality judgments\nof ambiguous claims. We introduce LLM-generated edits of summaries as a method\nof providing a nuanced evaluation of claims: how much does a summary need to be\nedited to be unambiguous? Whether a claim gets rewritten and how much it\nchanges can be used as an automatic evaluation metric, the Ambiguity Rewrite\nMetric (ARM), with a much richer feedback signal than a binary judgment of\nfaithfulness. We focus on the area of narrative summarization as it is\nparticularly rife with ambiguity and subjective interpretation. We show that\nARM produces a 21% absolute improvement in annotator agreement on claim\nfaithfulness, indicating that subjectivity is reduced.",
      "tldr_zh": "这篇论文探讨了在叙事理解中评估声明忠实性的主观性问题，指出传统二元判断（支持或不支持）忽略了模糊性和不同解读，导致可靠性降低。作者提出一种新方法，使用LLM生成摘要编辑来量化模糊性，定义了Ambiguity Rewrite Metric (ARM)作为自动评估指标，提供比二元判断更丰富的反馈信号。实验结果显示，在叙事总结任务中，ARM使注释者对声明忠实性的同意率提高了21%，有效减少了主观性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.01132v1",
      "published_date": "2025-04-01 19:08:24 UTC",
      "updated_date": "2025-04-01 19:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:16:08.624213"
    },
    {
      "arxiv_id": "2504.03748v1",
      "title": "TDBench: Benchmarking Vision-Language Models in Understanding Top-Down Images",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Hou",
        "Minghui Zhao",
        "Lilin Xu",
        "Yuang Fan",
        "Xiaofan Jiang"
      ],
      "abstract": "The rapid emergence of Vision-Language Models (VLMs) has significantly\nadvanced multimodal understanding, enabling applications in scene comprehension\nand visual reasoning. While these models have been primarily evaluated and\ndeveloped for front-view image understanding, their capabilities in\ninterpreting top-down images have received limited attention, partly due to the\nscarcity of diverse top-down datasets and the challenges in collecting such\ndata. In contrast, top-down vision provides explicit spatial overviews and\nimproved contextual understanding of scenes, making it particularly valuable\nfor tasks like autonomous navigation, aerial imaging, and spatial planning. In\nthis work, we address this gap by introducing TDBench, a comprehensive\nbenchmark for VLMs in top-down image understanding. TDBench is constructed from\npublic top-down view datasets and high-quality simulated images, including\ndiverse real-world and synthetic scenarios. TDBench consists of visual\nquestion-answer pairs across ten evaluation dimensions of image understanding.\nMoreover, we conduct four case studies that commonly happen in real-world\nscenarios but are less explored. By revealing the strengths and limitations of\nexisting VLM through evaluation results, we hope TDBench to provide insights\nfor motivating future research. Project homepage:\nhttps://github.com/Columbia-ICSL/TDBench",
      "tldr_zh": "这篇论文引入了 TDBench，这是一个针对 Vision-Language Models (VLMs) 在理解 top-down images 的综合基准测试，以填补现有模型在顶视图图像评估方面的空白。TDBench 利用公共数据集和高质量模拟图像，构建了涵盖十个图像理解评估维度的视觉问答对，并包含四个真实场景案例研究。实验结果揭示了现有 VLM 的优势和局限性，为自动导航、航拍和空间规划等应用提供宝贵洞见，并激励未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03748v1",
      "published_date": "2025-04-01 19:01:13 UTC",
      "updated_date": "2025-04-01 19:01:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:16:20.660134"
    },
    {
      "arxiv_id": "2504.01128v2",
      "title": "RipVIS: Rip Currents Video Instance Segmentation Benchmark for Beach Monitoring and Safety",
      "title_zh": "RipVIS：离岸流视频实例分割基准，用于海滩监测和安全",
      "authors": [
        "Andrei Dumitriu",
        "Florin Tatui",
        "Florin Miron",
        "Aakash Ralhan",
        "Radu Tudor Ionescu",
        "Radu Timofte"
      ],
      "abstract": "Rip currents are strong, localized and narrow currents of water that flow\noutwards into the sea, causing numerous beach-related injuries and fatalities\nworldwide. Accurate identification of rip currents remains challenging due to\ntheir amorphous nature and the lack of annotated data, which often requires\nexpert knowledge. To address these issues, we present RipVIS, a large-scale\nvideo instance segmentation benchmark explicitly designed for rip current\nsegmentation. RipVIS is an order of magnitude larger than previous datasets,\nfeaturing $184$ videos ($212,328$ frames), of which $150$ videos ($163,528$\nframes) are with rip currents, collected from various sources, including\ndrones, mobile phones, and fixed beach cameras. Our dataset encompasses diverse\nvisual contexts, such as wave-breaking patterns, sediment flows, and water\ncolor variations, across multiple global locations, including USA, Mexico,\nCosta Rica, Portugal, Italy, Greece, Romania, Sri Lanka, Australia and New\nZealand. Most videos are annotated at $5$ FPS to ensure accuracy in dynamic\nscenarios, supplemented by an additional $34$ videos ($48,800$ frames) without\nrip currents. We conduct comprehensive experiments with Mask R-CNN, Cascade\nMask R-CNN, SparseInst and YOLO11, fine-tuning these models for the task of rip\ncurrent segmentation. Results are reported in terms of multiple metrics, with a\nparticular focus on the $F_2$ score to prioritize recall and reduce false\nnegatives. To enhance segmentation performance, we introduce a novel\npost-processing step based on Temporal Confidence Aggregation (TCA). RipVIS\naims to set a new standard for rip current segmentation, contributing towards\nsafer beach environments. We offer a benchmark website to share data, models,\nand results with the research community, encouraging ongoing collaboration and\nfuture contributions, at https://ripvis.ai.",
      "tldr_zh": "本文提出 RipVIS，这是一个大规模视频实例分割基准数据集，针对海滩湍流（rip currents）的识别，以提升监测和安全水平。数据集包含 184 个视频（212,328 帧），其中 150 个视频标注有湍流，覆盖全球多地多样场景，如波浪模式和水色变化，并以 5 FPS 进行标注。研究通过细调 Mask R-CNN、Cascade Mask R-CNN、SparseInst 和 YOLO11 等模型，并引入 Temporal Confidence Aggregation (TCA) 后处理步骤，实验结果在 F2 score 等指标上显著改善，减少假阴性，为海滩安全应用设定新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.01128v2",
      "published_date": "2025-04-01 18:57:15 UTC",
      "updated_date": "2025-04-03 09:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:16:33.840623"
    },
    {
      "arxiv_id": "2504.01122v1",
      "title": "ffstruc2vec: Flat, Flexible and Scalable Learning of Node Representations from Structural Identities",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Heidrich",
        "Jeffrey Heidemann",
        "Rüdiger Buchkremer",
        "Gonzalo Wandosell Fernández de Bobadilla"
      ],
      "abstract": "Node embedding refers to techniques that generate low-dimensional vector\nrepresentations of nodes in a graph while preserving specific properties of the\nnodes. A key challenge in the field is developing scalable methods that can\npreserve structural properties suitable for the required types of structural\npatterns of a given downstream application task. While most existing methods\nfocus on preserving node proximity, those that do preserve structural\nproperties often lack the flexibility to preserve various types of structural\npatterns required by downstream application tasks. This paper introduces\nffstruc2vec, a scalable deep-learning framework for learning node embedding\nvectors that preserve structural identities. Its flat, efficient architecture\nallows high flexibility in capturing diverse types of structural patterns,\nenabling broad adaptability to various downstream application tasks. The\nproposed framework significantly outperforms existing approaches across diverse\nunsupervised and supervised tasks in practical applications. Moreover,\nffstruc2vec enables explainability by quantifying how individual structural\npatterns influence task outcomes, providing actionable interpretation. To our\nknowledge, no existing framework combines this level of flexibility,\nscalability, and structural interpretability, underscoring its unique\ncapabilities.",
      "tldr_zh": "这篇论文提出了 ffstruc2vec，一种扁平（flat）、灵活且可扩展的深度学习框架，用于从结构身份（structural identities）学习节点嵌入（node embedding），以更好地保留图中节点的结构属性。相较于现有方法，该框架允许高灵活性来捕获多样化的结构模式，从而适应各种下游应用任务。实验结果显示，ffstruc2vec 在多种无监督和监督任务中显著优于现有方法，并通过量化结构模式对任务结果的影响，提供可解释性和可操作的解释，这在灵活性、可扩展性和结构可解释性方面实现了独特结合。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01122v1",
      "published_date": "2025-04-01 18:47:16 UTC",
      "updated_date": "2025-04-01 18:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:16:44.405948"
    },
    {
      "arxiv_id": "2504.01094v1",
      "title": "Multilingual and Multi-Accent Jailbreaking of Audio LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jaechul Roh",
        "Virat Shejwalkar",
        "Amir Houmansadr"
      ],
      "abstract": "Large Audio Language Models (LALMs) have significantly advanced audio\nunderstanding but introduce critical security risks, particularly through audio\njailbreaks. While prior work has focused on English-centric attacks, we expose\na far more severe vulnerability: adversarial multilingual and multi-accent\naudio jailbreaks, where linguistic and acoustic variations dramatically amplify\nattack success. In this paper, we introduce Multi-AudioJail, the first\nsystematic framework to exploit these vulnerabilities through (1) a novel\ndataset of adversarially perturbed multilingual/multi-accent audio jailbreaking\nprompts, and (2) a hierarchical evaluation pipeline revealing that how acoustic\nperturbations (e.g., reverberation, echo, and whisper effects) interacts with\ncross-lingual phonetics to cause jailbreak success rates (JSRs) to surge by up\nto +57.25 percentage points (e.g., reverberated Kenyan-accented attack on\nMERaLiON). Crucially, our work further reveals that multimodal LLMs are\ninherently more vulnerable than unimodal systems: attackers need only exploit\nthe weakest link (e.g., non-English audio inputs) to compromise the entire\nmodel, which we empirically show by multilingual audio-only attacks achieving\n3.1x higher success rates than text-only attacks. We plan to release our\ndataset to spur research into cross-modal defenses, urging the community to\naddress this expanding attack surface in multimodality as LALMs evolve.",
      "tldr_zh": "该研究揭示了大型音频语言模型(LALMs)在多语言和多口音音频越狱攻击中的严重漏洞，远超以往的英语中心攻击。\n他们引入了Multi-AudioJail框架，包括一个新数据集和分层评估管道，探讨声学扰动（如回声和耳语效果）与跨语言语音交互，导致越狱成功率(JSRs)提高高达+57.25%。\n实验显示，多模态LLMs比单模态系统更易受攻击，多语言音频攻击的成功率比文本攻击高3.1倍，并计划发布数据集以推动跨模态防御研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "21 pages, 6 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.01094v1",
      "published_date": "2025-04-01 18:12:23 UTC",
      "updated_date": "2025-04-01 18:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:16:57.408160"
    },
    {
      "arxiv_id": "2504.01093v1",
      "title": "Hard-constraining Neumann boundary conditions in physics-informed neural networks via Fourier feature embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher Straub",
        "Philipp Brendel",
        "Vlad Medvedev",
        "Andreas Rosskopf"
      ],
      "abstract": "We present a novel approach to hard-constrain Neumann boundary conditions in\nphysics-informed neural networks (PINNs) using Fourier feature embeddings.\nNeumann boundary conditions are used to described critical processes in various\napplication, yet they are more challenging to hard-constrain in PINNs than\nDirichlet conditions. Our method employs specific Fourier feature embeddings to\ndirectly incorporate Neumann boundary conditions into the neural network's\narchitecture instead of learning them. The embedding can be naturally extended\nby high frequency modes to better capture high frequency phenomena. We\ndemonstrate the efficacy of our approach through experiments on a diffusion\nproblem, for which our method outperforms existing hard-constraining methods\nand classical PINNs, particularly in multiscale and high frequency scenarios.",
      "tldr_zh": "本文提出了一种新方法，使用 Fourier feature embeddings 来硬约束 Neumann boundary conditions 在 physics-informed neural networks (PINNs) 中的应用，以解决这些边界条件比 Dirichlet conditions 更难处理的挑战。该方法将 Neumann boundary conditions 直接嵌入神经网络架构，而不是通过学习实现，并通过高频模式扩展以更好地捕捉高频现象。在扩散问题的实验中，该方法优于现有硬约束技术和经典 PINNs，尤其在多尺度和高频场景下表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.01093v1",
      "published_date": "2025-04-01 18:10:46 UTC",
      "updated_date": "2025-04-01 18:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:17:07.617065"
    },
    {
      "arxiv_id": "2504.01089v1",
      "title": "HomeEmergency -- Using Audio to Find and Respond to Emergencies in the Home",
      "title_zh": "HomeEmergency —— 使用音频发现并响应家庭紧急情况",
      "authors": [
        "James F. Mullen Jr",
        "Dhruva Kumar",
        "Xuewei Qi",
        "Rajasimman Madhivanan",
        "Arnie Sen",
        "Dinesh Manocha",
        "Richard Kim"
      ],
      "abstract": "In the United States alone accidental home deaths exceed 128,000 per year.\nOur work aims to enable home robots who respond to emergency scenarios in the\nhome, preventing injuries and deaths. We introduce a new dataset of household\nemergencies based in the ThreeDWorld simulator. Each scenario in our dataset\nbegins with an instantaneous or periodic sound which may or may not be an\nemergency. The agent must navigate the multi-room home scene using prior\nobservations, alongside audio signals and images from the simulator, to\ndetermine if there is an emergency or not.\n  In addition to our new dataset, we present a modular approach for localizing\nand identifying potential home emergencies. Underpinning our approach is a\nnovel probabilistic dynamic scene graph (P-DSG), where our key insight is that\ngraph nodes corresponding to agents can be represented with a probabilistic\nedge. This edge, when refined using Bayesian inference, enables efficient and\neffective localization of agents in the scene. We also utilize multi-modal\nvision-language models (VLMs) as a component in our approach, determining\nobject traits (e.g. flammability) and identifying emergencies. We present a\ndemonstration of our method completing a real-world version of our task on a\nconsumer robot, showing the transferability of both our task and our method.\nOur dataset will be released to the public upon this papers publication.",
      "tldr_zh": "该研究针对美国每年超过12.8万起家庭意外死亡的问题，提出一种利用音频检测和响应家庭紧急情况的方法，旨在让家庭机器人预防伤害和死亡。研究引入了一个基于ThreeDWorld模拟器的新数据集，包含多房间场景，其中代理需结合先验观察、音频信号和图像来判断紧急情况。核心方法包括一个新型概率动态场景图(P-DSG)，通过Bayesian推理优化代理定位，并整合多模态视觉语言模型(VLMs)来识别物体特性（如易燃性）和紧急事件。实验演示了该方法在消费级机器人上的实际应用，证明了其可转移性，并计划公开数据集以推动相关研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01089v1",
      "published_date": "2025-04-01 18:07:25 UTC",
      "updated_date": "2025-04-01 18:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:17:20.567169"
    },
    {
      "arxiv_id": "2504.01016v1",
      "title": "GeometryCrafter: Consistent Geometry Estimation for Open-world Videos with Diffusion Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Tian-Xing Xu",
        "Xiangjun Gao",
        "Wenbo Hu",
        "Xiaoyu Li",
        "Song-Hai Zhang",
        "Ying Shan"
      ],
      "abstract": "Despite remarkable advancements in video depth estimation, existing methods\nexhibit inherent limitations in achieving geometric fidelity through the\naffine-invariant predictions, limiting their applicability in reconstruction\nand other metrically grounded downstream tasks. We propose GeometryCrafter, a\nnovel framework that recovers high-fidelity point map sequences with temporal\ncoherence from open-world videos, enabling accurate 3D/4D reconstruction,\ncamera parameter estimation, and other depth-based applications. At the core of\nour approach lies a point map Variational Autoencoder (VAE) that learns a\nlatent space agnostic to video latent distributions for effective point map\nencoding and decoding. Leveraging the VAE, we train a video diffusion model to\nmodel the distribution of point map sequences conditioned on the input videos.\nExtensive evaluations on diverse datasets demonstrate that GeometryCrafter\nachieves state-of-the-art 3D accuracy, temporal consistency, and generalization\ncapability.",
      "tldr_zh": "该研究提出 GeometryCrafter 框架，用于从开放世界的视频中恢复高保真度的点图序列，确保时间连贯性，从而支持准确的3D/4D重建、相机参数估计和其他基于深度的应用。核心方法包括一个点图 Variational Autoencoder (VAE)，它学习一个与视频潜在分布无关的潜在空间，用于点图的编码和解码；随后，通过训练视频 diffusion model 来建模点图序列的分布，基于输入视频进行条件生成。实验在多样数据集上显示，GeometryCrafter 实现了最先进的3D准确性、时间一致性和泛化能力，显著超越现有方法。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Project webpage: https://geometrycrafter.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2504.01016v1",
      "published_date": "2025-04-01 17:58:03 UTC",
      "updated_date": "2025-04-01 17:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:17:32.208140"
    },
    {
      "arxiv_id": "2504.01008v1",
      "title": "IntrinsiX: High-Quality PBR Generation using Image Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Kocsis",
        "Lukas Höllein",
        "Matthias Nießner"
      ],
      "abstract": "We introduce IntrinsiX, a novel method that generates high-quality intrinsic\nimages from text description. In contrast to existing text-to-image models\nwhose outputs contain baked-in scene lighting, our approach predicts\nphysically-based rendering (PBR) maps. This enables the generated outputs to be\nused for content creation scenarios in core graphics applications that\nfacilitate re-lighting, editing, and texture generation tasks. In order to\ntrain our generator, we exploit strong image priors, and pre-train separate\nmodels for each PBR material component (albedo, roughness, metallic, normals).\nWe then align these models with a new cross-intrinsic attention formulation\nthat concatenates key and value features in a consistent fashion. This allows\nus to exchange information between each output modality and to obtain\nsemantically coherent PBR predictions. To ground each intrinsic component, we\npropose a rendering loss which provides image-space signals to constrain the\nmodel, thus facilitating sharp details also in the output BRDF properties. Our\nresults demonstrate detailed intrinsic generation with strong generalization\ncapabilities that outperforms existing intrinsic image decomposition methods\nused with generated images by a significant margin. Finally, we show a series\nof applications, including re-lighting, editing, and text-conditioned\nroom-scale PBR texture generation.",
      "tldr_zh": "我们介绍了 IntrinsiX，一种从文本描述生成高质量 Physically-Based Rendering (PBR) 地图的方法，与传统文本到图像模型不同，它支持重新照明、编辑和纹理生成等图形应用。方法利用图像先验预训练每个 PBR 组件模型（包括 albedo、roughness、metallic 和 normals），并通过新的 cross-intrinsic attention 机制实现输出模态间的语义一致性，同时引入 rendering loss 来确保细节锐利。实验结果显示，IntrinsiX 在固有图像生成上大幅优于现有分解方法，并展示了实际应用如重新照明和文本条件下的房间规模 PBR 纹理生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.8; I.4.9; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://peter-kocsis.github.io/IntrinsiX/ Video:\n  https://youtu.be/b0wVA44R93Y",
      "pdf_url": "http://arxiv.org/pdf/2504.01008v1",
      "published_date": "2025-04-01 17:47:48 UTC",
      "updated_date": "2025-04-01 17:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:17:44.872812"
    },
    {
      "arxiv_id": "2504.01005v1",
      "title": "When To Solve, When To Verify: Compute-Optimal Problem Solving and Generative Verification for LLM Reasoning",
      "title_zh": "何时求解，何时验证：计算最优问题求解和生成式验证用于LLM推理",
      "authors": [
        "Nishad Singhi",
        "Hritik Bansal",
        "Arian Hosseini",
        "Aditya Grover",
        "Kai-Wei Chang",
        "Marcus Rohrbach",
        "Anna Rohrbach"
      ],
      "abstract": "Scaling test-time compute has emerged as a key strategy for enhancing the\nreasoning capabilities of large language models (LLMs), particularly in tasks\nlike mathematical problem-solving. A traditional approach, Self-Consistency\n(SC), generates multiple solutions to a problem and selects the most common\nanswer via majority voting. Another common method involves scoring each\nsolution with a reward model (verifier) and choosing the best one. Recent\nadvancements in Generative Reward Models (GenRM) reframe verification as a\nnext-token prediction task, enabling inference-time scaling along a new axis.\nSpecifically, GenRM generates multiple verification chains-of-thought to score\neach solution. Under a limited inference budget, this introduces a fundamental\ntrade-off: should you spend the budget on scaling solutions via SC or generate\nfewer solutions and allocate compute to verification via GenRM? To address\nthis, we evaluate GenRM against SC under a fixed inference budget.\nInterestingly, we find that SC is more compute-efficient than GenRM for most\npractical inference budgets across diverse models and datasets. For instance,\nGenRM first matches SC after consuming up to 8x the inference compute and\nrequires significantly more compute to outperform it. Furthermore, we derive\ninference scaling laws for the GenRM paradigm, revealing that compute-optimal\ninference favors scaling solution generation more aggressively than scaling the\nnumber of verifications. Our work provides practical guidance on optimizing\ntest-time scaling by balancing solution generation and verification. The code\nis available at https://github.com/nishadsinghi/sc-genrm-scaling.",
      "tldr_zh": "这篇论文探讨了在有限推理预算下，如何优化大语言模型(LLMs)推理任务中的问题解决和验证策略，比较了Self-Consistency (SC)生成多个解决方案并通过多数投票选择答案的方法，与Generative Reward Models (GenRM)生成验证链来评分解决方案的方法。研究发现，SC 在大多数实际预算下比 GenRM 计算效率更高，例如 GenRM 需要多达8倍的计算资源才能匹配或超越 SC。论文推导了 GenRM 的推理缩放定律，表明最优策略应更积极地扩展解决方案生成而非验证，并提供了平衡生成和验证的实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.01005v1",
      "published_date": "2025-04-01 17:41:57 UTC",
      "updated_date": "2025-04-01 17:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:17:57.120357"
    },
    {
      "arxiv_id": "2504.01002v1",
      "title": "Token embeddings violate the manifold hypothesis",
      "title_zh": "标记嵌入违反流形假设",
      "authors": [
        "Michael Robinson",
        "Sourya Dey",
        "Tony Chiang"
      ],
      "abstract": "To fully understand the behavior of a large language model (LLM) requires our\nunderstanding of its input space. If this input space differs from our\nassumption, our understanding of and conclusions about the LLM is likely\nflawed, regardless of its architecture. Here, we elucidate the structure of the\ntoken embeddings, the input domain for LLMs, both empirically and\ntheoretically. We present a generalized and statistically testable model where\nthe neighborhood of each token splits into well-defined signal and noise\ndimensions.\n  This model is based on a generalization of a manifold called a fiber bundle,\nso we denote our hypothesis test as the ``fiber bundle null.'' Failing to\nreject the null is uninformative, but rejecting it at a specific token\nindicates that token has a statistically significant local structure, and so is\nof interest to us. By running our test over several open-source LLMs, each with\nunique token embeddings, we find that the null is frequently rejected, and so\nthe token subspace is provably not a fiber bundle and hence also not a\nmanifold. As a consequence of our findings, when an LLM is presented with two\nsemantically equivalent prompts, and if one prompt contains a token implicated\nby our test, that prompt will likely exhibit more output variability\nproportional to the local signal dimension of the token.",
      "tldr_zh": "本文研究发现，大型语言模型(LLMs)的token embeddings不符合manifold hypothesis，通过实证和理论分析揭示其结构。研究者提出一个基于fiber bundle的泛化模型，将每个token的邻域分为信号和噪声维度，并设计fiber bundle null假设测试来验证局部结构。测试结果显示，在多个开源LLMs上，该假设经常被拒绝，表明token embeddings不是fiber bundle或manifold，从而导致包含特定token的语义等价提示输出变异性增加。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "53Z50, 62H15"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.01002v1",
      "published_date": "2025-04-01 17:40:12 UTC",
      "updated_date": "2025-04-01 17:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:18:08.014020"
    },
    {
      "arxiv_id": "2504.03746v1",
      "title": "Enhancing Biologically Inspired Hierarchical Temporal Memory with Hardware-Accelerated Reflex Memory",
      "title_zh": "使用硬件加速反射记忆增强受生物启发的分层时间记忆",
      "authors": [
        "Pavia Bera",
        "Sabrina Hassan Moon",
        "Jennifer Adorno",
        "Dayane Alfenas Reis",
        "Sanjukta Bhanja"
      ],
      "abstract": "The rapid expansion of the Internet of Things (IoT) generates zettabytes of\ndata that demand efficient unsupervised learning systems. Hierarchical Temporal\nMemory (HTM), a third-generation unsupervised AI algorithm, models the\nneocortex of the human brain by simulating columns of neurons to process and\npredict sequences. These neuron columns can memorize and infer sequences across\nmultiple orders. While multiorder inferences offer robust predictive\ncapabilities, they often come with significant computational overhead. The\nSequence Memory (SM) component of HTM, which manages these inferences,\nencounters bottlenecks primarily due to its extensive programmable\ninterconnects. In many cases, it has been observed that first-order temporal\nrelationships have proven to be sufficient without any significant loss in\nefficiency. This paper introduces a Reflex Memory (RM) block, inspired by the\nSpinal Cord's working mechanisms, designed to accelerate the processing of\nfirst-order inferences. The RM block performs these inferences significantly\nfaster than the SM. The integration of RM with HTM forms a system called the\nAccelerated Hierarchical Temporal Memory (AHTM), which processes repetitive\ninformation more efficiently than the original HTM while still supporting\nmultiorder inferences. The experimental results demonstrate that the HTM\npredicts an event in 0.945 s, whereas the AHTM module does so in 0.125 s.\nAdditionally, the hardware implementation of RM in a content-addressable memory\n(CAM) block, known as Hardware-Accelerated Hierarchical Temporal Memory\n(H-AHTM), predicts an event in just 0.094 s, significantly improving inference\nspeed. Compared to the original algorithm \\cite{bautista2020matlabhtm}, AHTM\naccelerates inference by up to 7.55x, while H-AHTM further enhances performance\nwith a 10.10x speedup.",
      "tldr_zh": "该研究针对物联网(IoT)生成的大量数据，增强了Hierarchical Temporal Memory (HTM)算法，通过引入受脊髓机制启发的Reflex Memory (RM)块来加速第一级推断，从而形成Accelerated Hierarchical Temporal Memory (AHTM)。AHTM保留了HTM的多级推断能力，同时显著提高了处理重复信息的效率。实验结果显示，AHTM将事件预测时间从HTM的0.945秒缩短至0.125秒，而Hardware-Accelerated Hierarchical Temporal Memory (H-AHTM)进一步优化至0.094秒，实现最高10.10x的加速速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03746v1",
      "published_date": "2025-04-01 17:40:12 UTC",
      "updated_date": "2025-04-01 17:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:18:22.249542"
    },
    {
      "arxiv_id": "2504.01001v1",
      "title": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models",
      "title_zh": "零样本基准测试：一个灵活且可扩展的语言模型自动评估框架",
      "authors": [
        "José Pombal",
        "Nuno M. Guerreiro",
        "Ricardo Rei",
        "André F. T. Martins"
      ],
      "abstract": "As language models improve and become capable of performing more complex\ntasks across modalities, evaluating them automatically becomes increasingly\nchallenging. Developing strong and robust task-specific automatic metrics gets\nharder, and human-annotated test sets -- which are expensive to create --\nsaturate more quickly. A compelling alternative is to design reliable\nstrategies to automate the creation of test data and evaluation, but previous\nattempts either rely on pre-existing data, or focus solely on individual tasks.\nWe present Zero-shot Benchmarking (ZSB), a framework for creating high-quality\nbenchmarks for any task by leveraging language models for both synthetic test\ndata creation and evaluation. ZSB is simple and flexible: it requires only the\ncreation of a prompt for data generation and one for evaluation; it is scalable\nto tasks and languages where collecting real-world data is costly or\nimpractical; it is model-agnostic, allowing the creation of increasingly\nchallenging benchmarks as models improve. To assess the effectiveness of our\nframework, we create benchmarks for five text-only tasks and a multi-modal one:\ngeneral capabilities in four languages (English, Chinese, French, and Korean),\ntranslation, and general vision-language capabilities in English. We then rank\na broad range of open and closed systems on our benchmarks. ZSB rankings\nconsistently correlate strongly with human rankings, outperforming\nwidely-adopted standard benchmarks. Through ablations, we find that strong\nbenchmarks can be created with open models, and that judge model size and\ndataset variety are crucial drivers of performance. We release all our\nbenchmarks, and code to reproduce our experiments and to produce new\nbenchmarks.",
      "tldr_zh": "本研究提出Zero-shot Benchmarking (ZSB)框架，一种灵活且可扩展的自动评估方法，用于评估语言模型的性能，而无需预先数据或特定任务依赖。ZSB利用语言模型生成合成测试数据和评估提示，仅需设计简单提示即可适用于多种任务和语言，包括文本任务（如多种语言的通用能力）和多模态任务。实验结果显示，ZSB的模型排名与人类排名高度相关，且在五个文本任务和一个视觉语言任务上优于标准基准；通过消融实验发现，使用开源模型创建强基准可行，且评判模型大小和数据集多样性是关键因素。该框架的发布将促进语言模型评估的创新和可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01001v1",
      "published_date": "2025-04-01 17:40:08 UTC",
      "updated_date": "2025-04-01 17:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:18:32.758099"
    },
    {
      "arxiv_id": "2504.00999v1",
      "title": "MergeVQ: A Unified Framework for Visual Generation and Representation with Disentangled Token Merging and Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Li",
        "Luyuan Zhang",
        "Zedong Wang",
        "Juanxi Tian",
        "Cheng Tan",
        "Zicheng Liu",
        "Chang Yu",
        "Qingsong Xie",
        "Haonan Lu",
        "Haoqian Wang",
        "Zhen Lei"
      ],
      "abstract": "Masked Image Modeling (MIM) with Vector Quantization (VQ) has achieved great\nsuccess in both self-supervised pre-training and image generation. However,\nmost existing methods struggle to address the trade-off in shared latent space\nfor generation quality vs. representation learning and efficiency. To push the\nlimits of this paradigm, we propose MergeVQ, which incorporates token merging\ntechniques into VQ-based generative models to bridge the gap between image\ngeneration and visual representation learning in a unified architecture. During\npre-training, MergeVQ decouples top-k semantics from latent space with the\ntoken merge module after self-attention blocks in the encoder for subsequent\nLook-up Free Quantization (LFQ) and global alignment and recovers their\nfine-grained details through cross-attention in the decoder for reconstruction.\nAs for the second-stage generation, we introduce MergeAR, which performs KV\nCache compression for efficient raster-order prediction. Extensive experiments\non ImageNet verify that MergeVQ as an AR generative model achieves competitive\nperformance in both visual representation learning and image generation tasks\nwhile maintaining favorable token efficiency and inference speed. The code and\nmodel will be available at https://apexgen-x.github.io/MergeVQ.",
      "tldr_zh": "该研究提出MergeVQ框架，一种统一的体系，用于整合视觉生成和表示学习，通过分离的token merging和量化技术解决基于Vector Quantization (VQ)的生成模型在生成质量、表示学习和效率间的权衡问题。在预训练阶段，MergeVQ在编码器的self-attention后使用token merge模块分离top-k语义，进行Look-up Free Quantization (LFQ)和全局对齐，并在解码器中通过cross-attention恢复细节；同时，引入MergeAR模块进行KV Cache压缩，以提升光栅顺序预测的效率。在ImageNet上的实验显示，MergeVQ作为自回归(AR)生成模型，在视觉表示学习和图像生成任务上表现出色，同时保持高效的token效率和推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2025 (in process for more analysis and extension)",
      "pdf_url": "http://arxiv.org/pdf/2504.00999v1",
      "published_date": "2025-04-01 17:39:19 UTC",
      "updated_date": "2025-04-01 17:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:18:45.162238"
    },
    {
      "arxiv_id": "2504.00993v2",
      "title": "MedReason: Eliciting Factual Medical Reasoning Steps in LLMs via Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Juncheng Wu",
        "Wenlong Deng",
        "Xingxuan Li",
        "Sheng Liu",
        "Taomian Mi",
        "Yifan Peng",
        "Ziyang Xu",
        "Yi Liu",
        "Hyunjin Cho",
        "Chang-In Choi",
        "Yihan Cao",
        "Hui Ren",
        "Xiang Li",
        "Xiaoxiao Li",
        "Yuyin Zhou"
      ],
      "abstract": "Medical tasks such as diagnosis and treatment planning require precise and\ncomplex reasoning, particularly in life-critical domains. Unlike mathematical\nreasoning, medical reasoning demands meticulous, verifiable thought processes\nto ensure reliability and accuracy. However, there is a notable lack of\ndatasets that provide transparent, step-by-step reasoning to validate and\nenhance the medical reasoning ability of AI models. To bridge this gap, we\nintroduce MedReason, a large-scale high-quality medical reasoning dataset\ndesigned to enable faithful and explainable medical problem-solving in large\nlanguage models (LLMs). We utilize a structured medical knowledge graph (KG) to\nconvert clinical QA pairs into logical chains of reasoning, or ``thinking\npaths'', which trace connections from question elements to answers via relevant\nKG entities. Each path is validated for consistency with clinical logic and\nevidence-based medicine. Our pipeline generates detailed reasoning for various\nmedical questions from 7 medical datasets, resulting in a dataset of 32,682\nquestion-answer pairs, each with detailed, step-by-step explanations.\nExperiments demonstrate that fine-tuning with our dataset consistently boosts\nmedical problem-solving capabilities, achieving significant gains of up to 7.7%\nfor DeepSeek-Ditill-8B. Our top-performing model, MedReason-8B, outperforms the\nHuatuo-o1-8B, a state-of-the-art medical reasoning model, by up to 4.2% on the\nclinical benchmark MedBullets. We also engage medical professionals from\ndiverse specialties to assess our dataset's quality, ensuring MedReason offers\naccurate and coherent medical reasoning. Our data, models, and code is\navailable at https://github.com/UCSC-VLAA/MedReason.",
      "tldr_zh": "该研究引入了MedReason，这是一个大规模高质量的医疗推理数据集，旨在通过知识图(KG)提升大型语言模型(LLMs)在医疗任务（如诊断和治疗规划）中的精确性和可解释性。MedReason利用结构化的KG将临床QA对转换为逻辑推理链（thinking paths），并通过临床逻辑和循证医学进行验证，生成32,682个带有详细逐步解释的问答对。实验结果显示，使用该数据集微调模型可显著提升性能，例如DeepSeek-Ditill-8B模型的准确率提高高达7.7%，而MedReason-8B模型在MedBullets基准上比现有最先进模型Huatuo-o1-8B高出4.2%。这项工作经医疗专业人士评估，确保了数据集的准确性和连贯性，并已在GitHub上公开资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 11 figures, 6 tables. Project page:\n  https://github.com/UCSC-VLAA/MedReason",
      "pdf_url": "http://arxiv.org/pdf/2504.00993v2",
      "published_date": "2025-04-01 17:31:44 UTC",
      "updated_date": "2025-04-04 18:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:18:57.028875"
    },
    {
      "arxiv_id": "2504.00986v1",
      "title": "Accelerating drug discovery with Artificial: a whole-lab orchestration and scheduling system for self-driving labs",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Fehlis",
        "Paul Mandel",
        "Charles Crain",
        "Betty Liu",
        "David Fuller"
      ],
      "abstract": "Self-driving labs are transforming drug discovery by enabling automated,\nAI-guided experimentation, but they face challenges in orchestrating complex\nworkflows, integrating diverse instruments and AI models, and managing data\nefficiently. Artificial addresses these issues with a comprehensive\norchestration and scheduling system that unifies lab operations, automates\nworkflows, and integrates AI-driven decision-making. By incorporating AI/ML\nmodels like NVIDIA BioNeMo - which facilitates molecular interaction prediction\nand biomolecular analysis - Artificial enhances drug discovery and accelerates\ndata-driven research. Through real-time coordination of instruments, robots,\nand personnel, the platform streamlines experiments, enhances reproducibility,\nand advances drug discovery.",
      "tldr_zh": "该论文介绍了Artificial系统，这是一个针对自驱动实验室(Self-driving labs)的全面编排和调度系统，旨在解决药物发现中的复杂工作流编排、仪器与AI模型整合以及数据管理挑战。通过自动化工作流和整合AI/ML模型（如NVIDIA BioNeMo，用于分子交互预测和生物分子分析），Artificial实现了AI驱动决策的实时协调。实验结果显示，该系统能够简化实验过程、提升可重复性，并显著加速数据驱动的药物发现研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00986v1",
      "published_date": "2025-04-01 17:22:50 UTC",
      "updated_date": "2025-04-01 17:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:19:07.895492"
    },
    {
      "arxiv_id": "2504.00983v1",
      "title": "WorldScore: A Unified Evaluation Benchmark for World Generation",
      "title_zh": "WorldScore：世界生成的统一评估基准",
      "authors": [
        "Haoyi Duan",
        "Hong-Xing Yu",
        "Sirui Chen",
        "Li Fei-Fei",
        "Jiajun Wu"
      ],
      "abstract": "We introduce the WorldScore benchmark, the first unified benchmark for world\ngeneration. We decompose world generation into a sequence of next-scene\ngeneration tasks with explicit camera trajectory-based layout specifications,\nenabling unified evaluation of diverse approaches from 3D and 4D scene\ngeneration to video generation models. The WorldScore benchmark encompasses a\ncurated dataset of 3,000 test examples that span diverse worlds: static and\ndynamic, indoor and outdoor, photorealistic and stylized. The WorldScore\nmetrics evaluate generated worlds through three key aspects: controllability,\nquality, and dynamics. Through extensive evaluation of 19 representative\nmodels, including both open-source and closed-source ones, we reveal key\ninsights and challenges for each category of models. Our dataset, evaluation\ncode, and leaderboard can be found at https://haoyi-duan.github.io/WorldScore/",
      "tldr_zh": "我们引入了 WorldScore，这是一个统一的基准，用于评估世界生成任务，将其分解为一系列基于相机轨迹布局的下一个场景生成任务，从而支持对 3D、4D 场景生成和视频生成模型的统一评估。该基准包含一个精选数据集，涵盖 3,000 个多样化示例，包括静态/动态、室内/室外以及光线真实/风格化世界，并通过 controllability、quality 和 dynamics 等指标进行评估。通过对 19 个代表性模型（包括开源和闭源）的广泛实验，我们揭示了各模型类别的主要洞见和挑战。相关数据集、评估代码和排行榜可在 https://haoyi-duan.github.io/WorldScore/ 访问。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Project website: https://haoyi-duan.github.io/WorldScore/ The first\n  two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2504.00983v1",
      "published_date": "2025-04-01 17:20:23 UTC",
      "updated_date": "2025-04-01 17:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:19:21.029166"
    },
    {
      "arxiv_id": "2504.00975v3",
      "title": "Resource Allocation for RIS-Assisted CoMP-NOMA Networks using Reinforcement Learning",
      "title_zh": "使用强化学习的 RIS",
      "authors": [
        "Muhammad Umer",
        "Muhammad Ahmed Mohsin",
        "Huma Ghafoor",
        "Syed Ali Hassan"
      ],
      "abstract": "This thesis delves into the forefront of wireless communication by exploring\nthe synergistic integration of three transformative technologies: STAR-RIS,\nCoMP, and NOMA. Driven by the ever-increasing demand for higher data rates,\nimproved spectral efficiency, and expanded coverage in the evolving landscape\nof 6G development, this research investigates the potential of these\ntechnologies to revolutionize future wireless networks.\n  The thesis analyzes the performance gains achievable through strategic\ndeployment of STAR-RIS, focusing on mitigating inter-cell interference,\nenhancing signal strength, and extending coverage to cell-edge users. Resource\nsharing strategies for STAR-RIS elements are explored, optimizing both\ntransmission and reflection functionalities. Analytical frameworks are\ndeveloped to quantify the benefits of STAR-RIS assisted CoMP-NOMA networks\nunder realistic channel conditions, deriving key performance metrics such as\nergodic rates and outage probabilities. Additionally, the research delves into\nenergy-efficient design approaches for CoMP-NOMA networks incorporating RIS,\nproposing novel RIS configurations and optimization algorithms to achieve a\nbalance between performance and energy consumption. Furthermore, the\napplication of Deep Reinforcement Learning (DRL) techniques for intelligent and\nadaptive optimization in aerial RIS-assisted CoMP-NOMA networks is explored,\naiming to maximize network sum rate while meeting user quality of service\nrequirements. Through a comprehensive investigation of these technologies and\ntheir synergistic potential, this thesis contributes valuable insights into the\nfuture of wireless communication, paving the way for the development of more\nefficient, reliable, and sustainable networks capable of meeting the demands of\nour increasingly connected world.",
      "tldr_zh": "本论文探讨了 STAR-RIS、CoMP 和 NOMA 技术的协同整合，以提升 6G 无线网络的数据速率、光谱效率和覆盖范围。研究通过分析 STAR-RIS 的战略部署，优化资源共享策略并开发分析框架，量化了网络性能指标如 ergodic rates 和 outage probabilities，同时提出能量高效的 RIS 配置和优化算法。最终，利用 Deep Reinforcement Learning (DRL) 技术对空中 RIS 辅助的 CoMP-NOMA 网络进行智能优化，实现了网络总速率最大化并满足用户质量服务要求，为构建更高效可靠的无线网络提供了关键见解。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00975v3",
      "published_date": "2025-04-01 17:14:01 UTC",
      "updated_date": "2025-05-19 15:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:19:32.075944"
    },
    {
      "arxiv_id": "2504.00970v1",
      "title": "SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching",
      "title_zh": "SentenceKV：通过句子级语义 KV 缓存实现 LLM 高效推理",
      "authors": [
        "Yuxuan Zhu",
        "Ali Falahati",
        "David H. Yang",
        "Mohammad Mohammadi Amiri"
      ],
      "abstract": "Large language models face significant computational and memory challenges\nwhen processing long contexts. During inference, efficient management of the\nkey-value (KV) cache, which stores intermediate activations for autoregressive\ngeneration, is critical to reducing memory overhead and improving computational\nefficiency. Traditional token-level efficient KV caching methods overlook\nsemantic information, treating tokens independently without considering their\nsemantic relationships. Meanwhile, existing semantic-preserving KV cache\nmanagement approaches often suffer from substantial memory usage and high\ntime-to-first-token. To address these limitations, we propose SentenceKV, a\nnovel sentence-level semantic KV caching approach designed to enhance inference\nefficiency while preserving semantic coherence. During prefilling, SentenceKV\ngroups tokens based on sentence-level semantic similarity, compressing sentence\nrepresentations into concise semantic vectors stored directly on the GPU, while\nindividual KV pairs are offloaded to CPU. During decoding, SentenceKV generates\ntokens by selectively retrieving semantically relevant sentence-level KV\nentries, leveraging the semantic similarity between the prefilling-stage\nsemantic vectors and decoding-stage queries. This ensures efficient and\ncontextually accurate predictions, minimizing the loading of redundant or\nirrelevant data into GPU memory and significantly reducing memory overhead\nwhile maintaining stable inference latency, even for extremely long contexts.\nExtensive evaluations on benchmarks including PG-19, LongBench, and\nNeedle-In-A-Haystack demonstrate that SentenceKV significantly outperforms\nstate-of-the-art methods in both efficiency and memory usage, without\ncompromising model accuracy.",
      "tldr_zh": "这篇论文提出 SentenceKV，一种基于句子级语义的 KV caching 方法，用于提升大型语言模型(LLM)在处理长上下文时的推理效率。SentenceKV 在预填充阶段将 tokens 按句子级语义相似性分组，压缩成简洁的语义向量存储在 GPU，同时将个体 KV 对卸载到 CPU；在解码阶段，通过语义相似性选择性检索相关 KV 条目，以减少内存开销并保持上下文准确性。实验结果显示，在 PG-19、LongBench 和 Needle-In-A-Haystack 等基准上，SentenceKV 显著优于现有方法，在效率和内存使用方面取得平衡，同时不牺牲模型准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00970v1",
      "published_date": "2025-04-01 17:08:57 UTC",
      "updated_date": "2025-04-01 17:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:19:45.282807"
    },
    {
      "arxiv_id": "2504.00969v2",
      "title": "HDVIO2.0: Wind and Disturbance Estimation with Hybrid Dynamics VIO",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Cioffi",
        "Leonard Bauersfeld",
        "Davide Scaramuzza"
      ],
      "abstract": "Visual-inertial odometry (VIO) is widely used for state estimation in\nautonomous micro aerial vehicles using onboard sensors. Current methods improve\nVIO by incorporating a model of the translational vehicle dynamics, yet their\nperformance degrades when faced with low-accuracy vehicle models or continuous\nexternal disturbances, like wind. Additionally, incorporating rotational\ndynamics in these models is computationally intractable when they are deployed\nin online applications, e.g., in a closed-loop control system. We present\nHDVIO2.0, which models full 6-DoF, translational and rotational, vehicle\ndynamics and tightly incorporates them into a VIO with minimal impact on the\nruntime. HDVIO2.0 builds upon the previous work, HDVIO, and addresses these\nchallenges through a hybrid dynamics model combining a point-mass vehicle model\nwith a learning-based component, with access to control commands and IMU\nhistory, to capture complex aerodynamic effects. The key idea behind modeling\nthe rotational dynamics is to represent them with continuous-time functions.\nHDVIO2.0 leverages the divergence between the actual motion and the predicted\nmotion from the hybrid dynamics model to estimate external forces as well as\nthe robot state. Our system surpasses the performance of state-of-the-art\nmethods in experiments using public and new drone dynamics datasets, as well as\nreal-world flights in winds up to 25 km/h. Unlike existing approaches, we also\nshow that accurate vehicle dynamics predictions are achievable without precise\nknowledge of the full vehicle state.",
      "tldr_zh": "本文提出HDVIO2.0，一种改进的视觉-惯性里程计(VIO)系统，通过整合混合动力学模型（结合点质量车辆模型和基于学习的组件）来估计风和外部干扰，实现完整的6-DoF（平移和旋转）动力学建模，同时最小化运行时影响。系统利用实际运动与预测运动的差异来估计外部力和机器人状态，并通过连续时间函数处理旋转动力学。实验在公共数据集、新无人机动力学数据集以及真实飞行环境中（风速高达25 km/h）证明，HDVIO2.0 超越了现有方法，且无需精确的完整车辆状态即可实现准确预测。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00969v2",
      "published_date": "2025-04-01 17:08:27 UTC",
      "updated_date": "2025-04-07 06:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:19:57.766119"
    },
    {
      "arxiv_id": "2504.00957v2",
      "title": "Enabling Efficient Processing of Spiking Neural Networks with On-Chip Learning on Commodity Neuromorphic Processors for Edge AI Systems",
      "title_zh": "在商用神经形态处理器上实现脉冲神经网络的片上学习以启用高效处理，用于边缘AI系统",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Pasindu Wickramasinghe",
        "Muhammad Shafique"
      ],
      "abstract": "The rising demand for energy-efficient edge AI systems (e.g., mobile\nagents/robots) has increased the interest in neuromorphic computing, since it\noffers ultra-low power/energy AI computation through spiking neural network\n(SNN) algorithms on neuromorphic processors. However, their efficient\nimplementation strategy has not been comprehensively studied, hence limiting\nSNN deployments for edge AI systems. Toward this, we propose a design\nmethodology to enable efficient SNN processing on commodity neuromorphic\nprocessors. To do this, we first study the key characteristics of targeted\nneuromorphic hardware (e.g., memory and compute budgets), and leverage this\ninformation to perform compatibility analysis for network selection. Afterward,\nwe employ a mapping strategy for efficient SNN implementation on the targeted\nprocessor. Furthermore, we incorporate an efficient on-chip learning mechanism\nto update the systems' knowledge for adapting to new input classes and dynamic\nenvironments. The experimental results show that the proposed methodology leads\nthe system to achieve low latency of inference (i.e., less than 50ms for image\nclassification, less than 200ms for real-time object detection in video\nstreaming, and less than 1ms in keyword recognition) and low latency of on-chip\nlearning (i.e., less than 2ms for keyword recognition), while incurring less\nthan 250mW of processing power and less than 15mJ of energy consumption across\nthe respective different applications and scenarios. These results show the\npotential of the proposed methodology in enabling efficient edge AI systems for\ndiverse application use-cases.",
      "tldr_zh": "该研究针对边缘 AI 系统的高能效需求，提出了一种设计方法，用于在商品神经形态处理器上高效处理 Spiking Neural Networks (SNN)。方法包括分析硬件特性（如内存和计算预算）进行网络兼容性评估、SNN 映射策略以及集成 on-chip 学习机制，以适应新输入类和动态环境。实验结果显示，该系统在图像分类（延迟小于50ms）、实时对象检测（延迟小于200ms）和关键词识别（延迟小于1ms）等应用中实现了低延迟、低功耗（小于250mW）和低能耗（小于15mJ），展示了其在多样化场景中的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN) 2025 in Rome, Italy",
      "pdf_url": "http://arxiv.org/pdf/2504.00957v2",
      "published_date": "2025-04-01 16:52:03 UTC",
      "updated_date": "2025-04-19 05:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:20:09.276226"
    },
    {
      "arxiv_id": "2504.00955v1",
      "title": "Unfair Learning: GenAI Exceptionalism and Copyright Law",
      "title_zh": "翻译失败",
      "authors": [
        "David Atkinson"
      ],
      "abstract": "This paper challenges the argument that generative artificial intelligence\n(GenAI) is entitled to broad immunity from copyright law for reproducing\ncopyrighted works without authorization due to a fair use defense. It examines\nfair use legal arguments and eight distinct substantive arguments, contending\nthat every legal and substantive argument favoring fair use for GenAI applies\nequally, if not more so, to humans. Therefore, granting GenAI exceptional\nprivileges in this domain is legally and logically inconsistent with\nwithholding broad fair use exemptions from individual humans. It would mean no\nhuman would need to pay for virtually any copyright work again. The solution is\nto take a circumspect view of any fair use claim for mass copyright\nreproduction by any entity and focus on the first principles of whether\npermitting such exceptionalism for GenAI promotes science and the arts.",
      "tldr_zh": "这篇论文挑战了生成式人工智能(GenAI)通过公平使用(fair use)辩护来免受版权法约束的观点，认为GenAI未经授权复制受版权保护作品不应享有特权。论文分析了公平使用法律论点和八个实质性论点，论证这些论点同样适用于人类，甚至更适用，从而指出给予GenAI例外主义会逻辑上和法律上不一致，可能导致人类无需为版权作品付费。最终，论文建议审慎评估任何实体的大规模版权复制主张，并从促进科学和艺术的基本原则出发，避免GenAI的过度特权。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00955v1",
      "published_date": "2025-04-01 16:49:39 UTC",
      "updated_date": "2025-04-01 16:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:20:19.778985"
    },
    {
      "arxiv_id": "2504.00954v1",
      "title": "IDMR: Towards Instance-Driven Precise Visual Correspondence in Multimodal Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Bangwei Liu",
        "Yicheng Bao",
        "Shaohui Lin",
        "Xuhong Wang",
        "Xin Tan",
        "Yingchun Wang",
        "Yuan Xie",
        "Chaochao Lu"
      ],
      "abstract": "Multimodal retrieval systems are becoming increasingly vital for cutting-edge\nAI technologies, such as embodied AI and AI-driven digital content industries.\nHowever, current multimodal retrieval tasks lack sufficient complexity and\ndemonstrate limited practical application value. It spires us to design\nInstance-Driven Multimodal Image Retrieval (IDMR), a novel task that requires\nmodels to retrieve images containing the same instance as a query image while\nmatching a text-described scenario. Unlike existing retrieval tasks focused on\nglobal image similarity or category-level matching, IDMR demands fine-grained\ninstance-level consistency across diverse contexts. To benchmark this\ncapability, we develop IDMR-bench using real-world object tracking and\nfirst-person video data. Addressing the scarcity of training data, we propose a\ncross-domain synthesis method that creates 557K training samples by cropping\nobjects from standard detection datasets. Our Multimodal Large Language Model\n(MLLM) based retrieval model, trained on 1.2M samples, outperforms\nstate-of-the-art approaches on both traditional benchmarks and our zero-shot\nIDMR-bench. Experimental results demonstrate previous models' limitations in\ninstance-aware retrieval and highlight the potential of MLLM for advanced\nretrieval applications. The whole training dataset, codes and models, with wide\nranges of sizes, are available at https://github.com/BwLiu01/IDMR.",
      "tldr_zh": "该论文提出了一种新的多模态检索任务IDMR（Instance-Driven Multimodal Image Retrieval），要求模型在检索图像时，不仅匹配查询图像中的相同实例，还需符合文本描述的场景，从而实现细粒度的实例级一致性，而非传统的全局相似性或类别级匹配。为评估这一任务，作者开发了IDMR-bench基准，使用真实世界的对象跟踪和第一人称视频数据，并通过跨域合成方法从标准检测数据集裁剪对象，生成557K训练样本。基于Multimodal Large Language Model (MLLM)的检索模型在1.2M样本上训练后，在传统基准和零样本IDMR-bench上超越了现有方法，揭示了现有模型在实例感知检索中的局限性，并展示了MLLM在高级检索应用中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00954v1",
      "published_date": "2025-04-01 16:47:20 UTC",
      "updated_date": "2025-04-01 16:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:20:33.624917"
    },
    {
      "arxiv_id": "2504.00952v1",
      "title": "Personalized Federated Training of Diffusion Models with Privacy Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Kumar Kshitij Patel",
        "Weitong Zhang",
        "Lingxiao Wang"
      ],
      "abstract": "The scarcity of accessible, compliant, and ethically sourced data presents a\nconsiderable challenge to the adoption of artificial intelligence (AI) in\nsensitive fields like healthcare, finance, and biomedical research.\nFurthermore, access to unrestricted public datasets is increasingly constrained\ndue to rising concerns over privacy, copyright, and competition. Synthetic data\nhas emerged as a promising alternative, and diffusion models -- a cutting-edge\ngenerative AI technology -- provide an effective solution for generating\nhigh-quality and diverse synthetic data. In this paper, we introduce a novel\nfederated learning framework for training diffusion models on decentralized\nprivate datasets. Our framework leverages personalization and the inherent\nnoise in the forward diffusion process to produce high-quality samples while\nensuring robust differential privacy guarantees. Our experiments show that our\nframework outperforms non-collaborative training methods, particularly in\nsettings with high data heterogeneity, and effectively reduces biases and\nimbalances in synthetic data, resulting in fairer downstream models.",
      "tldr_zh": "该研究针对数据稀缺、隐私和版权问题，提出了一种新型联邦学习(federated learning)框架，用于在去中心化私有数据集上训练扩散模型(diffusion models)。该框架通过利用个性化(personalization)和扩散过程中的固有噪声，生成高质量、多样化的合成数据，同时确保差分隐私(differential privacy)保护。实验结果显示，该框架在数据异质性高的场景下优于非协作训练方法，能有效减少合成数据中的偏差和不平衡，从而提升下游模型的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00952v1",
      "published_date": "2025-04-01 16:45:26 UTC",
      "updated_date": "2025-04-01 16:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:20:44.016807"
    },
    {
      "arxiv_id": "2504.00948v1",
      "title": "QSViT: A Methodology for Quantizing Spiking Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Saad Iftikhar",
        "Muhammad Shafique"
      ],
      "abstract": "Vision Transformer (ViT)-based models have shown state-of-the-art performance\n(e.g., accuracy) in vision-based AI tasks. However, realizing their capability\nin resource-constrained embedded AI systems is challenging due to their\ninherent large memory footprints and complex computations, thereby incurring\nhigh power/energy consumption. Recently, Spiking Vision Transformer\n(SViT)-based models have emerged as alternate low-power ViT networks. However,\ntheir large memory footprints still hinder their applicability for\nresource-constrained embedded AI systems. Therefore, there is a need for a\nmethodology to compress SViT models without degrading the accuracy\nsignificantly. To address this, we propose QSViT, a novel design methodology to\ncompress the SViT models through a systematic quantization strategy across\ndifferent network layers. To do this, our QSViT employs several key steps: (1)\ninvestigating the impact of different precision levels in different network\nlayers, (2) identifying the appropriate base quantization settings for guiding\nbit precision reduction, (3) performing a guided quantization strategy based on\nthe base settings to select the appropriate quantization setting, and (4)\ndeveloping an efficient quantized network based on the selected quantization\nsetting. The experimental results demonstrate that, our QSViT methodology\nachieves 22.75% memory saving and 21.33% power saving, while also maintaining\nhigh accuracy within 2.1% from that of the original non-quantized SViT model on\nthe ImageNet dataset. These results highlight the potential of QSViT\nmethodology to pave the way toward the efficient SViT deployments on\nresource-constrained embedded AI systems.",
      "tldr_zh": "本研究针对Vision Transformer (ViT)模型在资源受限嵌入式AI系统中的高内存占用和功耗问题，提出QSViT方法，用于量化Spiking Vision Transformer (SViT)模型以实现高效压缩。QSViT通过四个关键步骤——调查不同网络层精度水平的影响、识别基准量化设置、执行引导量化策略以及开发高效量化网络——来最小化准确率损失。实验结果显示，在ImageNet数据集上，QSViT实现了22.75%的内存节省和21.33%的功耗节省，同时准确率仅比原始SViT模型下降2.1%，为资源受限系统中的SViT部署提供了可行路径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN) 2025 in Rome, Italy",
      "pdf_url": "http://arxiv.org/pdf/2504.00948v1",
      "published_date": "2025-04-01 16:34:46 UTC",
      "updated_date": "2025-04-01 16:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:20:57.509672"
    },
    {
      "arxiv_id": "2504.00943v1",
      "title": "Graph Classification and Radiomics Signature for Identification of Tuberculous Meningitis",
      "title_zh": "翻译失败",
      "authors": [
        "Snigdha Agarwal",
        "Ganaraja V H",
        "Neelam Sinha",
        "Abhilasha Indoria",
        "Netravathi M",
        "Jitender Saini"
      ],
      "abstract": "Introduction: Tuberculous meningitis (TBM) is a serious brain infection\ncaused by Mycobacterium tuberculosis, characterized by inflammation of the\nmeninges covering the brain and spinal cord. Diagnosis often requires invasive\nlumbar puncture (LP) and cerebrospinal fluid (CSF) analysis. Objectives: This\nstudy aims to classify TBM patients using T1-weighted (T1w) non-contrast\nMagnetic Resonance Imaging (MRI) scans. We hypothesize that specific brain\nregions, such as the interpeduncular cisterns, bone, and corpus callosum,\ncontain visual markers that can non-invasively distinguish TBM patients from\nhealthy controls. We propose a novel Pixel-array Graphs Classifier\n(PAG-Classifier) that leverages spatial relationships between neighbouring 3D\npixels in a graph-based framework to extract significant features through eigen\ndecomposition. These features are then used to train machine learning\nclassifiers for effective patient classification. We validate our approach\nusing a radiomics-based methodology, classifying TBM patients based on relevant\nradiomics features. Results: We utilized an internal dataset consisting of 52\nscans, 32 from confirmed TBM patients based on mycobacteria detection in CSF,\nand 20 from healthy individuals. We achieved a 5-fold cross-validated average\nF1 score of 85.71% for cistern regions with our PAG-Classifier and 92.85% with\nthe radiomics features classifier, surpassing current state-of-the-art\nbenchmarks by 15% and 22%, respectively. However, bone and corpus callosum\nregions showed poor classification effectiveness, with average F1 scores below\n50%. Conclusion: Our study suggests that algorithms like the PAG-Classifier\nserve as effective tools for non-invasive TBM analysis, particularly by\ntargeting the interpeduncular cistern. Findings indicate that the bone and\ncorpus callosum regions lack distinctive patterns for differentiation.",
      "tldr_zh": "该研究旨在使用 T1-weighted (T1w) 非对比 MRI 扫描非侵入性地识别结核性脑膜炎 (TBM) 患者，假设特定脑区如幕间池、骨头和胼胝体含有视觉标记。\n他们提出了 Pixel-array Graphs Classifier (PAG-Classifier)，通过图-based 框架提取 3D 像素的空间关系特征并结合机器学习分类器，以及 radiomics 特征方法，进行患者分类。\n在包含 52 个扫描的数据集上，PAG-Classifier 在幕间池区域的 5 折交叉验证平均 F1 分数为 85.71%，radiomics 方法为 92.85%，分别比现有基准高 15% 和 22%。\n然而，骨头和胼胝体区域的分类效果较差（F1 分数低于 50%），结果表明该方法在特定脑区更有效，为非侵入性 TBM 诊断提供了新工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.00943v1",
      "published_date": "2025-04-01 16:28:39 UTC",
      "updated_date": "2025-04-01 16:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:21:11.551114"
    },
    {
      "arxiv_id": "2504.00938v1",
      "title": "AI Judges in Design: Statistical Perspectives on Achieving Human Expert Equivalence With Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kristen M. Edwards",
        "Farnaz Tehranchi",
        "Scarlett R. Miller",
        "Faez Ahmed"
      ],
      "abstract": "The subjective evaluation of early stage engineering designs, such as\nconceptual sketches, traditionally relies on human experts. However, expert\nevaluations are time-consuming, expensive, and sometimes inconsistent. Recent\nadvances in vision-language models (VLMs) offer the potential to automate\ndesign assessments, but it is crucial to ensure that these AI ``judges''\nperform on par with human experts. However, no existing framework assesses\nexpert equivalence. This paper introduces a rigorous statistical framework to\ndetermine whether an AI judge's ratings match those of human experts. We apply\nthis framework in a case study evaluating four VLM-based judges on key design\nmetrics (uniqueness, creativity, usefulness, and drawing quality). These AI\njudges employ various in-context learning (ICL) techniques, including uni- vs.\nmultimodal prompts and inference-time reasoning. The same statistical framework\nis used to assess three trained novices for expert-equivalence. Results show\nthat the top-performing AI judge, using text- and image-based ICL with\nreasoning, achieves expert-level agreement for uniqueness and drawing quality\nand outperforms or matches trained novices across all metrics. In 6/6 runs for\nboth uniqueness and creativity, and 5/6 runs for both drawing quality and\nusefulness, its agreement with experts meets or exceeds that of the majority of\ntrained novices. These findings suggest that reasoning-supported VLM models can\nachieve human-expert equivalence in design evaluation. This has implications\nfor scaling design evaluation in education and practice, and provides a general\nstatistical framework for validating AI judges in other domains requiring\nsubjective content evaluation.",
      "tldr_zh": "该论文提出一个严格的统计框架，用于评估视觉语言模型(VLMs)作为AI判断者在设计评估中是否达到人类专家水平，解决传统专家评估耗时和不一致的问题。研究通过案例分析测试了四种基于VLMs的判断者，采用in-context learning(ICL)技术（如单多模态提示和推理时间推理），并与训练过的初学者进行比较。结果显示，最优AI判断者（结合文本和图像ICL与推理）在独特性、创造性、usefulness和drawing quality指标上实现了专家级一致性，并在多数运行中优于或匹配初学者。这为教育和实践中的设计评估提供可扩展方法，并为其他主观内容评估领域提供通用统计框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 8 tables, 6 figures, 8 tables in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2504.00938v1",
      "published_date": "2025-04-01 16:20:29 UTC",
      "updated_date": "2025-04-01 16:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:21:22.279362"
    },
    {
      "arxiv_id": "2504.02872v1",
      "title": "Scraping the Shadows: Deep Learning Breakthroughs in Dark Web Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Ingmar Bakermans",
        "Daniel De Pascale",
        "Gonçalo Marcelino",
        "Giuseppe Cascavilla",
        "Zeno Geradts"
      ],
      "abstract": "Darknet markets (DNMs) facilitate the trade of illegal goods on a global\nscale. Gathering data on DNMs is critical to ensuring law enforcement agencies\ncan effectively combat crime. Manually extracting data from DNMs is an\nerror-prone and time-consuming task. Aiming to automate this process we develop\na framework for extracting data from DNMs and evaluate the application of three\nstate-of-the-art Named Entity Recognition (NER) models, ELMo-BiLSTM\n\\citep{ShahEtAl2022}, UniversalNER \\citep{ZhouEtAl2024}, and GLiNER\n\\citep{ZaratianaEtAl2023}, at the task of extracting complex entities from DNM\nproduct listing pages. We propose a new annotated dataset, which we use to\ntrain, fine-tune, and evaluate the models. Our findings show that\nstate-of-the-art NER models perform well in information extraction from DNMs,\nachieving 91% Precision, 96% Recall, and an F1 score of 94%. In addition,\nfine-tuning enhances model performance, with UniversalNER achieving the best\nperformance.",
      "tldr_zh": "本研究针对Darknet markets (DNMs)非法交易数据提取的挑战，开发了一个自动化框架，以提高执法机构的犯罪打击效率。该框架评估了三种先进的Named Entity Recognition (NER)模型，包括ELMo-BiLSTM、UniversalNER和GLiNER，在从DNM产品页面提取复杂实体方面的性能，并引入了一个新的标注数据集用于模型训练和微调。结果显示，这些模型在信息提取任务上取得了91%的Precision、96%的Recall和94%的F1分数，而微调后UniversalNER表现最佳，进一步提升了整体准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 17 images",
      "pdf_url": "http://arxiv.org/pdf/2504.02872v1",
      "published_date": "2025-04-01 16:12:19 UTC",
      "updated_date": "2025-04-01 16:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:21:31.980369"
    },
    {
      "arxiv_id": "2504.02871v1",
      "title": "Synthesized Annotation Guidelines are Knowledge-Lite Boosters for Clinical Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Enshuo Hsu",
        "Martin Ugbala",
        "Krishna Kumar Kookal",
        "Zouaidi Kawtar",
        "Nicholas L. Rider",
        "Muhammad F. Walji",
        "Kirk Roberts"
      ],
      "abstract": "Generative information extraction using large language models, particularly\nthrough few-shot learning, has become a popular method. Recent studies indicate\nthat providing a detailed, human-readable guideline-similar to the annotation\nguidelines traditionally used for training human annotators can significantly\nimprove performance. However, constructing these guidelines is both labor- and\nknowledge-intensive. Additionally, the definitions are often tailored to meet\nspecific needs, making them highly task-specific and often non-reusable.\nHandling these subtle differences requires considerable effort and attention to\ndetail. In this study, we propose a self-improving method that harvests the\nknowledge summarization and text generation capacity of LLMs to synthesize\nannotation guidelines while requiring virtually no human input. Our zero-shot\nexperiments on the clinical named entity recognition benchmarks, 2012 i2b2\nEVENT, 2012 i2b2 TIMEX, 2014 i2b2, and 2018 n2c2 showed 25.86%, 4.36%, 0.20%,\nand 7.75% improvements in strict F1 scores from the no-guideline baseline. The\nLLM-synthesized guidelines showed equivalent or better performance compared to\nhuman-written guidelines by 1.15% to 4.14% in most tasks. In conclusion, this\nstudy proposes a novel LLM self-improving method that requires minimal\nknowledge and human input and is applicable to multiple biomedical domains.",
      "tldr_zh": "本研究提出了一种自我改进方法，使用大型语言模型（LLMs）合成注释指南，以提升临床信息提取的性能。该方法利用LLMs的知识总结和文本生成能力，几乎无需人工输入，便能在零样本设置下生成指南，从而解决传统指南制作的劳动密集和知识密集问题。在临床命名实体识别基准测试（如2012 i2b2 EVENT、2012 i2b2 TIMEX、2014 i2b2和2018 n2c2）中，与无指南基线相比，严格F1分数分别提高了25.86%、4.36%、0.20%和7.75%，且合成指南的表现与人工指南相当或更优（提升1.15%至4.14%）。总之，此方法作为一种知识轻量（knowledge-lite）的解决方案，可广泛应用于多个生物医学领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.02871v1",
      "published_date": "2025-04-01 15:59:04 UTC",
      "updated_date": "2025-04-01 15:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:21:45.166623"
    },
    {
      "arxiv_id": "2504.00907v2",
      "title": "Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ram Ramrakhya",
        "Matthew Chang",
        "Xavier Puig",
        "Ruta Desai",
        "Zsolt Kira",
        "Roozbeh Mottaghi"
      ],
      "abstract": "Embodied agents operating in real-world environments must interpret ambiguous\nand under-specified human instructions. A capable household robot should\nrecognize ambiguity and ask relevant clarification questions to infer the user\nintent accurately, leading to more effective task execution. To study this\nproblem, we introduce the Ask-to-Act task, where an embodied agent must fetch a\nspecific object instance given an ambiguous instruction in a home environment.\nThe agent must strategically ask minimal, yet relevant, clarification questions\nto resolve ambiguity while navigating under partial observability. To solve\nthis problem, we propose a novel approach that fine-tunes multimodal large\nlanguage models (MLLMs) as vision-language-action (VLA) policies using online\nreinforcement learning (RL) with LLM-generated rewards. Our method eliminates\nthe need for large-scale human demonstrations or manually engineered rewards\nfor training such agents. We benchmark against strong zero-shot baselines,\nincluding GPT-4o, and supervised fine-tuned MLLMs, on our task. Our results\ndemonstrate that our RL-finetuned MLLM outperforms all baselines by a\nsignificant margin ($19.1$-$40.3\\%$), generalizing well to novel scenes and\ntasks. To the best of our knowledge, this is the first demonstration of\nadapting MLLMs as VLA agents that can act and ask for help using LLM-generated\nrewards with online RL.",
      "tldr_zh": "该研究针对具身代理（Embodied Agents）处理模糊人类指令的问题，引入了Ask-to-Act任务，要求代理在家庭环境中通过战略性提问澄清指令，以准确执行任务并导航部分可观察场景。研究提出了一种新方法，使用在线强化学习（Reinforcement Learning）微调多模态大语言模型（Multimodal LLMs）作为视觉-语言-动作（VLA）策略，并采用LLM生成的奖励进行训练，从而避免依赖大规模人类演示或手动奖励。实验结果显示，该方法在基准测试中大幅优于基线模型（如GPT-4o），成功率提升19.1-40.3%，并在新型场景和任务中表现出色。这是首次展示通过在线RL和LLM奖励，使MLLMs作为能行动和求助的代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00907v2",
      "published_date": "2025-04-01 15:41:50 UTC",
      "updated_date": "2025-04-02 01:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:21:56.786879"
    },
    {
      "arxiv_id": "2504.00906v1",
      "title": "Agent S2: A Compositional Generalist-Specialist Framework for Computer Use Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Saaket Agashe",
        "Kyle Wong",
        "Vincent Tu",
        "Jiachen Yang",
        "Ang Li",
        "Xin Eric Wang"
      ],
      "abstract": "Computer use agents automate digital tasks by directly interacting with\ngraphical user interfaces (GUIs) on computers and mobile devices, offering\nsignificant potential to enhance human productivity by completing an open-ended\nspace of user queries. However, current agents face significant challenges:\nimprecise grounding of GUI elements, difficulties with long-horizon task\nplanning, and performance bottlenecks from relying on single generalist models\nfor diverse cognitive tasks. To this end, we introduce Agent S2, a novel\ncompositional framework that delegates cognitive responsibilities across\nvarious generalist and specialist models. We propose a novel\nMixture-of-Grounding technique to achieve precise GUI localization and\nintroduce Proactive Hierarchical Planning, dynamically refining action plans at\nmultiple temporal scales in response to evolving observations. Evaluations\ndemonstrate that Agent S2 establishes new state-of-the-art (SOTA) performance\non three prominent computer use benchmarks. Specifically, Agent S2 achieves\n18.9% and 32.7% relative improvements over leading baseline agents such as\nClaude Computer Use and UI-TARS on the OSWorld 15-step and 50-step evaluation.\nMoreover, Agent S2 generalizes effectively to other operating systems and\napplications, surpassing previous best methods by 52.8% on WindowsAgentArena\nand by 16.52% on AndroidWorld relatively. Code available at\nhttps://github.com/simular-ai/Agent-S.",
      "tldr_zh": "本文提出Agent S2框架，这是一个组合式通用-专业模型框架，旨在解决计算机使用代理在图形用户界面(GUIs)交互中的挑战，包括GUI元素精确定位、长期任务规划和依赖单一模型的性能瓶颈。框架引入Mixture-of-Grounding技术实现精确GUI定位，以及Proactive Hierarchical Planning方法，通过动态优化多时间尺度行动计划来响应观察变化。实验结果显示，Agent S2在OSWorld、WindowsAgentArena和AndroidWorld基准上达到新的SOTA性能，较领先基线如Claude Computer Use和UI-TARS分别提升18.9%至52.8%，并展示出良好的操作系统和应用泛化能力。代码开源于https://github.com/simular-ai/Agent-S。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 13 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.00906v1",
      "published_date": "2025-04-01 15:40:27 UTC",
      "updated_date": "2025-04-01 15:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:22:10.213153"
    },
    {
      "arxiv_id": "2504.00899v1",
      "title": "Role and Use of Race in AI/ML Models Related to Health",
      "title_zh": "翻译失败",
      "authors": [
        "Martin C. Were",
        "Ang Li",
        "Bradley A. Malin",
        "Zhijun Yin",
        "Joseph R. Coco",
        "Benjamin X. Collins",
        "Ellen Wright Clayton",
        "Laurie L. Novak",
        "Rachele Hendricks-Sturrup",
        "Abiodun Oluyomi",
        "Shilo Anders",
        "Chao Yan"
      ],
      "abstract": "The role and use of race within health-related artificial intelligence and\nmachine learning (AI/ML) models has sparked increasing attention and\ncontroversy. Despite the complexity and breadth of related issues, a robust and\nholistic framework to guide stakeholders in their examination and resolution\nremains lacking. This perspective provides a broad-based, systematic, and\ncross-cutting landscape analysis of race-related challenges, structured around\nthe AI/ML lifecycle and framed through \"points to consider\" to support inquiry\nand decision-making.",
      "tldr_zh": "这篇论文探讨了种族在健康相关 AI/ML 模型中的作用及其引发的争议，强调了这些问题的复杂性和缺乏全面指导框架。作者通过一个系统化的景观分析，围绕 AI/ML 生命周期结构化地审视种族相关挑战，并提出“points to consider”来辅助利益相关者的调查和决策。该框架旨在提供跨领域视角，促进更负责任的 AI/ML 应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00899v1",
      "published_date": "2025-04-01 15:27:31 UTC",
      "updated_date": "2025-04-01 15:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:22:19.909234"
    },
    {
      "arxiv_id": "2504.03744v1",
      "title": "Comparative Explanations: Explanation Guided Decision Making for Human-in-the-Loop Preference Selection",
      "title_zh": "比较解释：解释引导的人",
      "authors": [
        "Tanmay Chakraborty",
        "Christian Wirth",
        "Christin Seifert"
      ],
      "abstract": "This paper introduces Multi-Output LOcal Narrative Explanation (MOLONE), a\nnovel comparative explanation method designed to enhance preference selection\nin human-in-the-loop Preference Bayesian optimization (PBO). The preference\nelicitation in PBO is a non-trivial task because it involves navigating\nimplicit trade-offs between vector-valued outcomes, subjective priorities of\ndecision-makers, and decision-makers' uncertainty in preference selection.\nExisting explainable AI (XAI) methods for BO primarily focus on input feature\nimportance, neglecting the crucial role of outputs (objectives) in human\npreference elicitation. MOLONE addresses this gap by providing explanations\nthat highlight both input and output importance, enabling decision-makers to\nunderstand the trade-offs between competing objectives and make more informed\npreference selections. MOLONE focuses on local explanations, comparing the\nimportance of input features and outcomes across candidate samples within a\nlocal neighborhood of the search space, thus capturing nuanced differences\nrelevant to preference-based decision-making. We evaluate MOLONE within a PBO\nframework using benchmark multi-objective optimization functions, demonstrating\nits effectiveness in improving convergence compared to noisy preference\nselections. Furthermore, a user study confirms that MOLONE significantly\naccelerates convergence in human-in-the-loop scenarios by facilitating more\nefficient identification of preferred options.",
      "tldr_zh": "这篇论文引入了 MOLONE（Multi-Output LOcal Narrative Explanation），一种新型的比较解释方法，用于提升人类参与的 Preference Bayesian Optimization (PBO) 中的偏好选择。MOLONE 通过同时突出输入特征和输出（目标）的重要性，提供局部解释，帮助决策者理解竞争目标之间的权衡，并捕捉搜索空间局部邻域中的细微差异。实验在基准多目标优化函数上证明，MOLONE 显著改善了 PBO 的收敛性；此外，用户研究显示，它在人类循环场景中加速了首选选项的识别和决策效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03744v1",
      "published_date": "2025-04-01 15:23:54 UTC",
      "updated_date": "2025-04-01 15:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:22:33.794496"
    },
    {
      "arxiv_id": "2504.03743v1",
      "title": "Modelling bounded rational decision-making through Wasserstein constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Patrick Evans",
        "Leo Ardon",
        "Sumitra Ganesh"
      ],
      "abstract": "Modelling bounded rational decision-making through information constrained\nprocessing provides a principled approach for representing departures from\nrationality within a reinforcement learning framework, while still treating\ndecision-making as an optimization process. However, existing approaches are\ngenerally based on Entropy, Kullback-Leibler divergence, or Mutual Information.\nIn this work, we highlight issues with these approaches when dealing with\nordinal action spaces. Specifically, entropy assumes uniform prior beliefs,\nmissing the impact of a priori biases on decision-makings. KL-Divergence\naddresses this, however, has no notion of \"nearness\" of actions, and\nadditionally, has several well known potentially undesirable properties such as\nthe lack of symmetry, and furthermore, requires the distributions to have the\nsame support (e.g. positive probability for all actions). Mutual information is\noften difficult to estimate. Here, we propose an alternative approach for\nmodeling bounded rational RL agents utilising Wasserstein distances. This\napproach overcomes the aforementioned issues. Crucially, this approach accounts\nfor the nearness of ordinal actions, modeling \"stickiness\" in agent decisions\nand unlikeliness of rapidly switching to far away actions, while also\nsupporting low probability actions, zero-support prior distributions, and is\nsimple to calculate directly.",
      "tldr_zh": "本文提出了一种利用Wasserstein distances建模有限理性决策的新方法，以克服现有基于Entropy、Kullback-Leibler divergence或Mutual Information的强化学习（RL）框架的局限性，这些方法在处理ordinal action spaces时忽略了动作的近似性、先验偏差或计算复杂性。相比之下，该方法考虑了动作的“nearness”，模拟决策的“stickiness”，即代理不易快速切换到远距离动作，同时支持低概率动作和零支持先验分布，且计算简单。该创新为建模bounded rational决策提供了更灵活且实用的优化框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at RLDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.03743v1",
      "published_date": "2025-04-01 15:19:34 UTC",
      "updated_date": "2025-04-01 15:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:22:44.235172"
    },
    {
      "arxiv_id": "2504.00885v1",
      "title": "Spectral Architecture Search for Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Peri",
        "Lorenzo Giambagli",
        "Lorenzo Chicchi",
        "Duccio Fanelli"
      ],
      "abstract": "Architecture design and optimization are challenging problems in the field of\nartificial neural networks. Working in this context, we here present SPARCS\n(SPectral ARchiteCture Search), a novel architecture search protocol which\nexploits the spectral attributes of the inter-layer transfer matrices. SPARCS\nallows one to explore the space of possible architectures by spanning\ncontinuous and differentiable manifolds, thus enabling for gradient-based\noptimization algorithms to be eventually employed. With reference to simple\nbenchmark models, we show that the newly proposed method yields a self-emerging\narchitecture with a minimal degree of expressivity to handle the task under\ninvestigation and with a reduced parameter count as compared to other viable\nalternatives.",
      "tldr_zh": "这篇论文提出了 SPARCS（SPectral ARchiteCture Search），一种利用层间传输矩阵的谱属性（spectral attributes）来进行神经网络架构搜索的新协议。该方法通过探索连续可微的流形（manifolds）空间，启用基于梯度的优化算法，从而高效地设计架构。在简单基准模型的实验中，SPARCS 生成的自适应架构具有最小表达度（minimal degree of expressivity）和更少的参数数量，优于其他备选方案。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00885v1",
      "published_date": "2025-04-01 15:14:30 UTC",
      "updated_date": "2025-04-01 15:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:22:56.789264"
    },
    {
      "arxiv_id": "2504.00883v2",
      "title": "Improved Visual-Spatial Reasoning via R1-Zero-Like Training",
      "title_zh": "通过 R1-Zero-Like 训练改进视觉-空间推理",
      "authors": [
        "Zhenyi Liao",
        "Qingsong Xie",
        "Yanhao Zhang",
        "Zijian Kong",
        "Haonan Lu",
        "Zhenyu Yang",
        "Zhijie Deng"
      ],
      "abstract": "Increasing attention has been placed on improving the reasoning capacities of\nmulti-modal large language models (MLLMs). As the cornerstone for AI agents\nthat function in the physical realm, video-based visual-spatial intelligence\n(VSI) emerges as one of the most pivotal reasoning capabilities of MLLMs. This\nwork conducts a first, in-depth study on improving the visual-spatial reasoning\nof MLLMs via R1-Zero-like training. Technically, we first identify that the\nvisual-spatial reasoning capacities of small- to medium-sized Qwen2-VL models\ncannot be activated via Chain of Thought (CoT) prompts. We then incorporate\nGRPO training for improved visual-spatial reasoning, using the carefully\ncurated VSI-100k dataset, following DeepSeek-R1-Zero. During the investigation,\nwe identify the necessity to keep the KL penalty (even with a small value) in\nGRPO. With just 120 GPU hours, our vsGRPO-2B model, fine-tuned from\nQwen2-VL-2B, can outperform the base model by 12.1% and surpass GPT-4o.\nMoreover, our vsGRPO-7B model, fine-tuned from Qwen2-VL-7B, achieves\nperformance comparable to that of the best open-source model\nLLaVA-NeXT-Video-72B. Additionally, we compare vsGRPO to supervised fine-tuning\nand direct preference optimization baselines and observe strong performance\nsuperiority. The code and dataset will be available soon.",
      "tldr_zh": "这篇论文研究了通过 R1-Zero-like 训练提升多模态大语言模型 (MLLMs) 的视觉-空间推理 (VSI) 能力，特别是针对视频-based 场景。作者发现小到中型 Qwen2-VL 模型无法通过 Chain of Thought (CoT) 提示激活推理能力，因此采用 GRPO 训练方法，结合精心策划的 VSI-100k 数据集，并在训练中保留 KL penalty 以优化效果。实验结果显示，vsGRPO-2B 模型（从 Qwen2-VL-2B 微调）比基础模型提升 12.1% 并超过 GPT-4o，而 vsGRPO-7B 模型达到与 LLaVA-NeXT-Video-72B 相当的性能，且整体优于监督微调和直接偏好优化基线。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00883v2",
      "published_date": "2025-04-01 15:11:11 UTC",
      "updated_date": "2025-04-14 20:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:23:11.463315"
    },
    {
      "arxiv_id": "2504.00882v1",
      "title": "CrackSQL: A Hybrid SQL Dialect Translation System Powered by Large Language Models",
      "title_zh": "CrackSQL",
      "authors": [
        "Wei Zhou",
        "Yuyang Gao",
        "Xuanhe Zhou",
        "Guoliang Li"
      ],
      "abstract": "Dialect translation plays a key role in enabling seamless interaction across\nheterogeneous database systems. However, translating SQL queries between\ndifferent dialects (e.g., from PostgreSQL to MySQL) remains a challenging task\ndue to syntactic discrepancies and subtle semantic variations. Existing\napproaches including manual rewriting, rule-based systems, and large language\nmodel (LLM)-based techniques often involve high maintenance effort (e.g.,\ncrafting custom translation rules) or produce unreliable results (e.g., LLM\ngenerates non-existent functions), especially when handling complex queries. In\nthis demonstration, we present CrackSQL, the first hybrid SQL dialect\ntranslation system that combines rule and LLM-based methods to overcome these\nlimitations. CrackSQL leverages the adaptability of LLMs to minimize manual\nintervention, while enhancing translation accuracy by segmenting lengthy\ncomplex SQL via functionality-based query processing. To further improve\nrobustness, it incorporates a novel cross-dialect syntax embedding model for\nprecise syntax alignment, as well as an adaptive local-to-global translation\nstrategy that effectively resolves interdependent query operations. CrackSQL\nsupports three translation modes and offers multiple deployment and access\noptions including a web console interface, a PyPI package, and a command-line\nprompt, facilitating adoption across a variety of real-world use cases",
      "tldr_zh": "该论文介绍了 CrackSQL，一种混合 SQL 方言翻译系统，利用大型语言模型（LLM）结合规则方法，解决不同数据库系统（如 PostgreSQL 到 MySQL）间的查询翻译挑战，包括语法差异和语义变异问题。CrackSQL 通过基于功能的查询处理分割复杂 SQL、引入跨方言语法嵌入模型进行精确对齐，以及采用自适应本地到全局翻译策略，显著提高了翻译准确性和鲁棒性，同时最小化手动干预。系统支持三种翻译模式，并提供多种部署选项（如 web 界面、PyPI 包和命令行提示），便于在实际场景中应用。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "Extension of our SIGMOD 2025 paper. Please refer to source code\n  available at: https://github.com/weAIDB/CrackSQL",
      "pdf_url": "http://arxiv.org/pdf/2504.00882v1",
      "published_date": "2025-04-01 15:11:03 UTC",
      "updated_date": "2025-04-01 15:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:23:20.907246"
    },
    {
      "arxiv_id": "2504.00869v1",
      "title": "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoke Huang",
        "Juncheng Wu",
        "Hui Liu",
        "Xianfeng Tang",
        "Yuyin Zhou"
      ],
      "abstract": "Test-time scaling has emerged as a powerful technique for enhancing the\nreasoning capabilities of large language models. However, its effectiveness in\nmedical reasoning remains uncertain, as the medical domain fundamentally\ndiffers from mathematical tasks in terms of knowledge representation and\ndecision-making processes. In this paper, we provide the first comprehensive\ninvestigation of test-time scaling for medical reasoning and present m1, a\nsimple yet effective approach that increases a model's medical reasoning\ncapability at inference. Our evaluation across diverse medical tasks\ndemonstrates that test-time scaling consistently enhances medical reasoning,\nenabling lightweight fine-tuned models under 10B parameters to establish new\nstate-of-the-art performance, while our 32B model rivals previous 70B-scale\nmedical LLMs. However, we identify an optimal reasoning token budget of\napproximately 4K, beyond which performance may degrade due to overthinking.\nBudget forcing, which extends test-time computation through iterative prompts,\nhelps models double-check answers but does not necessarily improve the overall\nmedical QA performance and, in some cases, even introduces errors into\npreviously correct responses. Our case-by-case analysis identifies insufficient\nmedical knowledge as a key bottleneck that prevents further performance gains\nthrough test-time scaling. We find that increasing data scale, improving data\nquality, and expanding model capacity consistently enhance medical knowledge\ngrounding, enabling continued performance improvements, particularly on\nchallenging medical benchmarks where smaller models reach saturation. These\nfindings underscore fundamental differences between medical and mathematical\nreasoning in LLMs, highlighting that enriched medical knowledge, other than\nincreased reasoning depth alone, is essential for realizing the benefits of\ntest-time scaling.",
      "tldr_zh": "该论文首次全面调查了 test-time scaling 技术在医疗推理中的应用，并提出 m1 方法，这是一种简单有效的策略，用于在推理阶段提升 Large Language Models (LLMs) 的医疗推理能力。实验结果显示，m1 使小于 10B 参数的轻量级模型达到新的 state-of-the-art 性能，而 32B 模型可与 70B 规模的医疗 LLM 媲美，但最佳推理 token 预算约为 4K，超过此可能因 overthinking 而降低表现。作者强调，医疗知识不足是主要瓶颈，通过增加数据规模、改善数据质量和扩展模型容量，能增强医疗知识基础，从而实现持续性能提升，并突显医疗推理与数学推理的根本差异，即需要丰富的医疗知识而非仅靠增加推理深度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages; 7 figures; Data, code, and models:\n  https://github.com/UCSC-VLAA/m1",
      "pdf_url": "http://arxiv.org/pdf/2504.00869v1",
      "published_date": "2025-04-01 14:57:43 UTC",
      "updated_date": "2025-04-01 14:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:23:33.726249"
    },
    {
      "arxiv_id": "2504.03742v1",
      "title": "Hierarchical Local-Global Feature Learning for Few-shot Malicious Traffic Detection",
      "title_zh": "层次化的局部-全局特征学习用于少样本恶意流量检测",
      "authors": [
        "Songtao Peng",
        "Lei Wang",
        "Wu Shuai",
        "Hao Song",
        "Jiajun Zhou",
        "Shanqing Yu",
        "Qi Xuan"
      ],
      "abstract": "With the rapid growth of internet traffic, malicious network attacks have\nbecome increasingly frequent and sophisticated, posing significant threats to\nglobal cybersecurity. Traditional detection methods, including rule-based and\nmachine learning-based approaches, struggle to accurately identify emerging\nthreats, particularly in scenarios with limited samples. While recent advances\nin few-shot learning have partially addressed the data scarcity issue, existing\nmethods still exhibit high false positive rates and lack the capability to\neffectively capture crucial local traffic patterns. In this paper, we propose\nHLoG, a novel hierarchical few-shot malicious traffic detection framework that\nleverages both local and global features extracted from network sessions. HLoG\nemploys a sliding-window approach to segment sessions into phases, capturing\nfine-grained local interaction patterns through hierarchical bidirectional GRU\nencoding, while simultaneously modeling global contextual dependencies. We\nfurther design a session similarity assessment module that integrates local\nsimilarity with global self-attention-enhanced representations, achieving\naccurate and robust few-shot traffic classification. Comprehensive experiments\non three meticulously reconstructed datasets demonstrate that HLoG\nsignificantly outperforms existing state-of-the-art methods. Particularly, HLoG\nachieves superior recall rates while substantially reducing false positives,\nhighlighting its effectiveness and practical value in real-world cybersecurity\napplications.",
      "tldr_zh": "该论文针对网络流量中恶意攻击的检测问题，提出了一种HLoG框架，用于few-shot学习场景下处理样本稀缺和高假阳性率的问题。HLoG通过滑动窗口分割网络会话，并利用层次化双向GRU编码捕获细粒度的局部交互模式，同时结合全局自注意力机制建模上下文依赖，并设计会话相似性评估模块实现精确分类。实验结果显示，在三个重建数据集上，HLoG显著优于现有方法，提高了召回率并大幅降低了假阳性率，具有重要的实际网络安全应用价值。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03742v1",
      "published_date": "2025-04-01 14:56:44 UTC",
      "updated_date": "2025-04-01 14:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:23:43.566478"
    },
    {
      "arxiv_id": "2504.00860v1",
      "title": "Investigating the Capabilities and Limitations of Machine Learning for Identifying Bias in English Language Data with Information and Heritage Professionals",
      "title_zh": "翻译失败",
      "authors": [
        "Lucy Havens",
        "Benjamin Bach",
        "Melissa Terras",
        "Beatrice Alex"
      ],
      "abstract": "Despite numerous efforts to mitigate their biases, ML systems continue to\nharm already-marginalized people. While predominant ML approaches assume bias\ncan be removed and fair models can be created, we show that these are not\nalways possible, nor desirable, goals. We reframe the problem of ML bias by\ncreating models to identify biased language, drawing attention to a dataset's\nbiases rather than trying to remove them. Then, through a workshop, we\nevaluated the models for a specific use case: workflows of information and\nheritage professionals. Our findings demonstrate the limitations of ML for\nidentifying bias due to its contextual nature, the way in which approaches to\nmitigating it can simultaneously privilege and oppress different communities,\nand its inevitability. We demonstrate the need to expand ML approaches to bias\nand fairness, providing a mixed-methods approach to investigating the\nfeasibility of removing bias or achieving fairness in a given ML use case.",
      "tldr_zh": "该研究调查了机器学习(ML) 在识别英语语言数据偏见方面的能力和局限性，特别与信息和遗产专业人士合作。论文重新定义偏见问题，通过创建模型来突出数据集的偏见而不是试图移除它们，并通过研讨会评估这些模型在专业工作流程中的应用。结果显示，ML 识别偏见受上下文影响较大，缓解偏见的方法可能同时有利于和损害不同群体，且偏见不可避免。研究强调需要扩展 ML 对偏见和公平性的方法，提供了一种混合方法来评估在特定 ML 用例中移除偏见或实现公平性的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "I.2.7; J.0; K.4.0"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 2025 CHI Conference on Human Factors in Computing\n  Systems (CHI '25)",
      "pdf_url": "http://arxiv.org/pdf/2504.00860v1",
      "published_date": "2025-04-01 14:51:25 UTC",
      "updated_date": "2025-04-01 14:51:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:23:56.365207"
    },
    {
      "arxiv_id": "2504.00857v1",
      "title": "Exploring Personalized Federated Learning Architectures for Violence Detection in Surveillance Videos",
      "title_zh": "探索监控视频中暴力检测的个性化联邦学习架构",
      "authors": [
        "Mohammad Kassir",
        "Siba Haidar",
        "Antoun Yaacoub"
      ],
      "abstract": "The challenge of detecting violent incidents in urban surveillance systems is\ncompounded by the voluminous and diverse nature of video data. This paper\npresents a targeted approach using Personalized Federated Learning (PFL) to\naddress these issues, specifically employing the Federated Learning with\nPersonalization Layers method within the Flower framework. Our methodology\nadapts learning models to the unique data characteristics of each surveillance\nnode, effectively managing the heterogeneous and non-IID nature of surveillance\nvideo data. Through rigorous experiments conducted on balanced and imbalanced\ndatasets, our PFL models demonstrated enhanced accuracy and efficiency,\nachieving up to 99.3% accuracy. This study underscores the potential of PFL to\nsignificantly improve the scalability and effectiveness of surveillance\nsystems, offering a robust, privacy-preserving solution for violence detection\nin complex urban environments.",
      "tldr_zh": "本研究探讨了在监控视频中检测暴力事件的挑战，提出使用Personalized Federated Learning (PFL)架构，特别是Federated Learning with Personalization Layers方法，在Flower框架下适应各监控节点的异构和non-IID数据特性。实验在平衡和不平衡数据集上进行，PFL模型实现了高达99.3%的准确率，并提升了系统效率。总体而言，此方法为监控系统提供了可扩展、隐私保护的暴力检测解决方案，适用于复杂城市环境。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.00857v1",
      "published_date": "2025-04-01 14:47:14 UTC",
      "updated_date": "2025-04-01 14:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:24:08.336965"
    },
    {
      "arxiv_id": "2504.00852v1",
      "title": "ReaLitE: Enrichment of Relation Embeddings in Knowledge Graphs using Numeric Literals",
      "title_zh": "翻译失败",
      "authors": [
        "Antonis Klironomos",
        "Baifan Zhou",
        "Zhuoxun Zheng",
        "Gad-Elrab Mohamed",
        "Heiko Paulheim",
        "Evgeny Kharlamov"
      ],
      "abstract": "Most knowledge graph embedding (KGE) methods tailored for link prediction\nfocus on the entities and relations in the graph, giving little attention to\nother literal values, which might encode important information. Therefore, some\nliteral-aware KGE models attempt to either integrate numerical values into the\nembeddings of the entities or convert these numerics into entities during\npreprocessing, leading to information loss. Other methods concerned with\ncreating relation-specific numerical features assume completeness of numerical\ndata, which does not apply to real-world graphs. In this work, we propose\nReaLitE, a novel relation-centric KGE model that dynamically aggregates and\nmerges entities' numerical attributes with the embeddings of the connecting\nrelations. ReaLitE is designed to complement existing conventional KGE methods\nwhile supporting multiple variations for numerical aggregations, including a\nlearnable method.\n  We comprehensively evaluated the proposed relation-centric embedding using\nseveral benchmarks for link prediction and node classification tasks. The\nresults showed the superiority of ReaLitE over the state of the art in both\ntasks.",
      "tldr_zh": "该论文指出，现有的知识图谱嵌入 (KGE) 方法在链接预测任务中忽略了数字字面值 (numeric literals)，导致信息损失或依赖不完整的假设。ReaLitE 是一种新型的关系中心 KGE 模型，通过动态聚合和合并实体数字属性与连接关系的嵌入，来补充传统 KGE 方法，并支持多种数字聚合变体，包括可学习的选项。实验结果显示，ReaLitE 在链接预测和节点分类任务上优于最先进模型，为知识图谱应用提供了更全面的表示能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ESWC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00852v1",
      "published_date": "2025-04-01 14:38:22 UTC",
      "updated_date": "2025-04-01 14:38:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:24:20.002434"
    },
    {
      "arxiv_id": "2504.00850v1",
      "title": "Global Intervention and Distillation for Federated Out-of-Distribution Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuang Qi",
        "Runhui Zhang",
        "Lei Meng",
        "Wei Wu",
        "Yachong Zhang",
        "Xiangxu Meng"
      ],
      "abstract": "Attribute skew in federated learning leads local models to focus on learning\nnon-causal associations, guiding them towards inconsistent optimization\ndirections, which inevitably results in performance degradation and unstable\nconvergence. Existing methods typically leverage data augmentation to enhance\nsample diversity or employ knowledge distillation to learn invariant\nrepresentations. However, the instability in the quality of generated data and\nthe lack of domain information limit their performance on unseen samples. To\naddress these issues, this paper presents a global intervention and\ndistillation method, termed FedGID, which utilizes diverse attribute features\nfor backdoor adjustment to break the spurious association between background\nand label. It includes two main modules, where the global intervention module\nadaptively decouples objects and backgrounds in images, injects background\ninformation into random samples to intervene in the sample distribution, which\nlinks backgrounds to all categories to prevent the model from treating\nbackground-label associations as causal. The global distillation module\nleverages a unified knowledge base to guide the representation learning of\nclient models, preventing local models from overfitting to client-specific\nattributes. Experimental results on three datasets demonstrate that FedGID\nenhances the model's ability to focus on the main subjects in unseen data and\noutperforms existing methods in collaborative modeling.",
      "tldr_zh": "该论文提出FedGID方法，针对联邦学习(Federated Learning)中的属性偏差问题，通过全球干预和蒸馏机制打破背景与标签的非因果关联，提升Out-of-Distribution泛化能力。FedGID包括全球干预模块，该模块自适应地解耦图像中的对象和背景，并注入背景信息到随机样本中，以防止模型将背景-标签关联视为因果关系；全球蒸馏模块则利用统一的知识库指导客户端模型的表示学习，避免过拟合。实验结果在三个数据集上表明，FedGID显著提升了模型对未见数据的关注和性能，优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00850v1",
      "published_date": "2025-04-01 14:36:24 UTC",
      "updated_date": "2025-04-01 14:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:24:33.158041"
    },
    {
      "arxiv_id": "2504.00843v1",
      "title": "Investigating Large Language Models in Diagnosing Students' Cognitive Skills in Math Problem-solving",
      "title_zh": "调查大语言模型在诊断学生数学问题求解中的认知技能",
      "authors": [
        "Hyoungwook Jin",
        "Yoonsu Kim",
        "Dongyun Jung",
        "Seungju Kim",
        "Kiyoon Choi",
        "Jinho Son",
        "Juho Kim"
      ],
      "abstract": "Mathematics learning entails mastery of both content knowledge and cognitive\nprocessing of knowing, applying, and reasoning with it. Automated math\nassessment primarily has focused on grading students' exhibition of content\nknowledge by finding textual evidence, such as specific numbers, formulas, and\nstatements. Recent advancements in problem-solving, image recognition, and\nreasoning capabilities of large language models (LLMs) show promise for nuanced\nevaluation of students' cognitive skills. Diagnosing cognitive skills needs to\ninfer students' thinking processes beyond textual evidence, which is an\nunderexplored task in LLM-based automated assessment. In this work, we\ninvestigate how state-of-the-art LLMs diagnose students' cognitive skills in\nmathematics. We constructed MathCog, a novel benchmark dataset comprising 639\nstudent responses to 110 expert-curated middle school math problems, each\nannotated with detailed teachers' diagnoses based on cognitive skill\nchecklists. Using MathCog, we evaluated 16 closed and open LLMs of varying\nmodel sizes and vendors. Our evaluation reveals that even the state-of-the-art\nLLMs struggle with the task, all F1 scores below 0.5, and tend to exhibit\nstrong false confidence for incorrect cases ($r_s=.617$). We also found that\nmodel size positively correlates with the diagnosis performance ($r_s=.771$).\nFinally, we discuss the implications of these findings, the overconfidence\nissue, and directions for improving automated cognitive skill diagnosis.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）在诊断学生数学问题解决中的认知技能，包括知道、应用和推理过程。研究者构建了MathCog数据集，包含639个学生对110个中学生数学问题的响应，并由教师基于认知技能清单进行详细标注。评估了16个不同规模和来源的LLMs，结果显示所有模型的F1分数均低于0.5，且存在强烈假自信（r_s=0.617），尽管模型大小与诊断性能正相关（r_s=0.771）。这些发现突出了LLMs在认知技能诊断中的局限性，并为改进自动评估方法提供了方向。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00843v1",
      "published_date": "2025-04-01 14:29:41 UTC",
      "updated_date": "2025-04-01 14:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:24:45.462445"
    },
    {
      "arxiv_id": "2504.00839v1",
      "title": "Context-Aware Human Behavior Prediction Using Multimodal Large Language Models: Challenges and Insights",
      "title_zh": "利用多模态大型语言模型的上下文感知人类行为预测：挑战与洞见",
      "authors": [
        "Yuchen Liu",
        "Lino Lerch",
        "Luigi Palmieri",
        "Andrey Rudenko",
        "Sebastian Koch",
        "Timo Ropinski",
        "Marco Aiello"
      ],
      "abstract": "Predicting human behavior in shared environments is crucial for safe and\nefficient human-robot interaction. Traditional data-driven methods to that end\nare pre-trained on domain-specific datasets, activity types, and prediction\nhorizons. In contrast, the recent breakthroughs in Large Language Models (LLMs)\npromise open-ended cross-domain generalization to describe various human\nactivities and make predictions in any context. In particular, Multimodal LLMs\n(MLLMs) are able to integrate information from various sources, achieving more\ncontextual awareness and improved scene understanding. The difficulty in\napplying general-purpose MLLMs directly for prediction stems from their limited\ncapacity for processing large input sequences, sensitivity to prompt design,\nand expensive fine-tuning. In this paper, we present a systematic analysis of\napplying pre-trained MLLMs for context-aware human behavior prediction. To this\nend, we introduce a modular multimodal human activity prediction framework that\nallows us to benchmark various MLLMs, input variations, In-Context Learning\n(ICL), and autoregressive techniques. Our evaluation indicates that the\nbest-performing framework configuration is able to reach 92.8% semantic\nsimilarity and 66.1% exact label accuracy in predicting human behaviors in the\ntarget frame.",
      "tldr_zh": "该论文分析了使用多模态大型语言模型(MLLMs)进行上下文感知人类行为预测的挑战和见解，强调传统数据驱动方法依赖特定领域数据集，而MLLMs可实现跨域泛化和信息整合，但面临处理大输入序列、提示设计敏感和微调成本高等问题。研究提出一个模块化的多模态人类活动预测框架，用于基准测试各种MLLMs、输入变体、In-Context Learning(ICL)以及自回归技术。实验结果表明，该框架的最佳配置在预测人类行为时达到了92.8%的语义相似度和66.1%的精确标签准确率，为人机交互中的行为预测提供了重要参考。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00839v1",
      "published_date": "2025-04-01 14:28:19 UTC",
      "updated_date": "2025-04-01 14:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:24:57.241474"
    },
    {
      "arxiv_id": "2504.00837v2",
      "title": "A Survey on Music Generation from Single-Modal, Cross-Modal, and Multi-Modal Perspectives",
      "title_zh": "音乐生成",
      "authors": [
        "Shuyu Li",
        "Shulei Ji",
        "Zihao Wang",
        "Songruoyao Wu",
        "Jiaxing Yu",
        "Kejun Zhang"
      ],
      "abstract": "Multi-modal music generation, using multiple modalities like text, images,\nand video alongside musical scores and audio as guidance, is an emerging\nresearch area with broad applications. This paper reviews this field,\ncategorizing music generation systems from the perspective of modalities. The\nreview covers modality representation, multi-modal data alignment, and their\nutilization to guide music generation. Current datasets and evaluation methods\nare also discussed. Key challenges in this area include effective multi-modal\nintegration, large-scale comprehensive datasets, and systematic evaluation\nmethods. Finally, an outlook on future research directions is provided,\nfocusing on creativity, efficiency, multi-modal alignment, and evaluation.",
      "tldr_zh": "这篇论文对音乐生成领域进行了综述，从Single-Modal、Cross-Modal 和 Multi-Modal 视角分类音乐生成系统，涵盖了模态表示、多模态数据对齐及其在指导音乐生成中的应用。论文还讨论了当前可用数据集和评估方法，并指出了关键挑战，包括有效整合多模态数据、构建大规模综合数据集以及开发系统化的评估框架。最后，它展望了未来研究方向，强调提升创意、效率、多模态对齐和评估方法的必要性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00837v2",
      "published_date": "2025-04-01 14:26:25 UTC",
      "updated_date": "2025-04-20 12:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:25:08.817009"
    },
    {
      "arxiv_id": "2504.00831v1",
      "title": "Example-Based Concept Analysis Framework for Deep Weather Forecast Models",
      "title_zh": "翻译失败",
      "authors": [
        "Soyeon Kim",
        "Junho Choi",
        "Subeen Lee",
        "Jaesik Choi"
      ],
      "abstract": "To improve the trustworthiness of an AI model, finding consistent,\nunderstandable representations of its inference process is essential. This\nunderstanding is particularly important in high-stakes operations such as\nweather forecasting, where the identification of underlying meteorological\nmechanisms is as critical as the accuracy of the predictions. Despite the\ngrowing literature that addresses this issue through explainable AI, the\napplicability of their solutions is often limited due to their AI-centric\ndevelopment. To fill this gap, we follow a user-centric process to develop an\nexample-based concept analysis framework, which identifies cases that follow a\nsimilar inference process as the target instance in a target model and presents\nthem in a user-comprehensible format. Our framework provides the users with\nvisually and conceptually analogous examples, including the probability of\nconcept assignment to resolve ambiguities in weather mechanisms. To bridge the\ngap between vector representations identified from models and\nhuman-understandable explanations, we compile a human-annotated concept dataset\nand implement a user interface to assist domain experts involved in the the\nframework development.",
      "tldr_zh": "这篇论文提出一个基于示例（example-based）的概念分析框架，针对深度天气预报模型，以提升其可解释性和可信度，特别是在高风险领域中理解气象机制的重要性。框架采用用户为中心的方法，通过识别与目标实例类似推理过程的案例，并以视觉和概念上相似的例子呈现，包括概念分配概率来解决天气机制的模糊性。作者编译了人类标注的概念数据集，并开发了用户界面，帮助桥接AI模型的向量表示与人类可理解解释，从而填补了现有可解释AI（explainable AI）方法的适用性局限。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "68T07",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00831v1",
      "published_date": "2025-04-01 14:22:41 UTC",
      "updated_date": "2025-04-01 14:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:25:20.939195"
    },
    {
      "arxiv_id": "2504.00795v1",
      "title": "Explainable AI-Based Interface System for Weather Forecasting Model",
      "title_zh": "翻译失败",
      "authors": [
        "Soyeon Kim",
        "Junho Choi",
        "Yeji Choi",
        "Subeen Lee",
        "Artyom Stitsyuk",
        "Minkyoung Park",
        "Seongyeop Jeong",
        "Youhyun Baek",
        "Jaesik Choi"
      ],
      "abstract": "Machine learning (ML) is becoming increasingly popular in meteorological\ndecision-making. Although the literature on explainable artificial intelligence\n(XAI) is growing steadily, user-centered XAI studies have not extend to this\ndomain yet. This study defines three requirements for explanations of black-box\nmodels in meteorology through user studies: statistical model performance for\ndifferent rainfall scenarios to identify model bias, model reasoning, and the\nconfidence of model outputs. Appropriate XAI methods are mapped to each\nrequirement, and the generated explanations are tested quantitatively and\nqualitatively. An XAI interface system is designed based on user feedback. The\nresults indicate that the explanations increase decision utility and user\ntrust. Users prefer intuitive explanations over those based on XAI algorithms\neven for potentially easy-to-recognize examples. These findings can provide\nevidence for future research on user-centered XAI algorithms, as well as a\nbasis to improve the usability of AI systems in practice.",
      "tldr_zh": "本文提出了一种基于可解释人工智能(XAI)的界面系统，用于气象预报模型，通过用户研究定义了三个关键解释要求：统计模型性能（针对不同降雨场景识别偏差）、模型推理，以及模型输出置信度。研究团队将合适的XAI方法映射到这些要求，并通过定量和定性测试设计了界面系统，基于用户反馈优化其可用性。结果表明，该系统提升了决策效用和用户信任，用户更偏好直观的解释而非基于XAI算法的复杂输出，为未来用户中心的XAI研究和AI系统实用性改进提供了重要依据。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "68T07",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00795v1",
      "published_date": "2025-04-01 13:52:34 UTC",
      "updated_date": "2025-04-01 13:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:25:32.474134"
    },
    {
      "arxiv_id": "2504.00794v1",
      "title": "Conditional Temporal Neural Processes with Covariance Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Boseon Yoo",
        "Jiwoo Lee",
        "Janghoon Ju",
        "Seijun Chung",
        "Soyeon Kim",
        "Jaesik Choi"
      ],
      "abstract": "We introduce a novel loss function, Covariance Loss, which is conceptually\nequivalent to conditional neural processes and has a form of regularization so\nthat is applicable to many kinds of neural networks. With the proposed loss,\nmappings from input variables to target variables are highly affected by\ndependencies of target variables as well as mean activation and mean\ndependencies of input and target variables. This nature enables the resulting\nneural networks to become more robust to noisy observations and recapture\nmissing dependencies from prior information. In order to show the validity of\nthe proposed loss, we conduct extensive sets of experiments on real-world\ndatasets with state-of-the-art models and discuss the benefits and drawbacks of\nthe proposed Covariance Loss.",
      "tldr_zh": "本论文提出了一种新型损失函数Covariance Loss，它概念上等同于条件神经过程，并引入正则化形式，使其适用于多种神经网络。该损失函数通过考虑目标变量的依赖性、均值激活以及输入与目标变量的均值依赖性，增强了神经网络对噪声观察的鲁棒性，并能从先验信息中重新捕获缺失依赖。实验在真实数据集上与最先进模型进行比较，验证了Covariance Loss的有效性，同时讨论了其优势（如鲁棒性提升）和潜在缺点。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00794v1",
      "published_date": "2025-04-01 13:51:44 UTC",
      "updated_date": "2025-04-01 13:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:25:44.657335"
    },
    {
      "arxiv_id": "2504.00780v1",
      "title": "Digitally Supported Analysis of Spontaneous Speech (DigiSpon): Benchmarking NLP-Supported Language Sample Analysis of Swiss Children's Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Anja Ryser",
        "Yingqiang Gao",
        "Sarah Ebling"
      ],
      "abstract": "Language sample analysis (LSA) is a process that complements standardized\npsychometric tests for diagnosing, for example, developmental language disorder\n(DLD) in children. However, its labor-intensive nature has limited its use in\nspeech-language pathology practice. We introduce an approach that leverages\nnatural language processing (NLP) methods not based on commercial large\nlanguage models (LLMs) applied to transcribed speech data from 119 children in\nthe German speaking part of Switzerland with typical and atypical language\ndevelopment. The study aims to identify optimal practices that support\nspeech-language pathologists in diagnosing DLD more efficiently within a\nhuman-in-the-loop framework, without relying on potentially unethical\nimplementations that leverage commercial LLMs. Preliminary findings underscore\nthe potential of integrating locally deployed NLP methods into the process of\nsemi-automatic LSA.",
      "tldr_zh": "本研究引入 DigiSpon 方法，利用自然语言处理 (NLP) 技术对瑞士德语区 119 名儿童的转录语音数据进行分析，以支持语言病理学家更高效地诊断发育语言障碍 (DLD)。该方法避免依赖商业大型语言模型 (LLMs)，而是通过人类在循环框架下的半自动语言样本分析 (LSA) 来优化流程。初步发现表明，整合本地部署的 NLP 方法能显著减少 LSA 的劳动密集型问题，提升诊断效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00780v1",
      "published_date": "2025-04-01 13:32:38 UTC",
      "updated_date": "2025-04-01 13:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:25:58.299036"
    },
    {
      "arxiv_id": "2504.03740v1",
      "title": "Brain Network Classification Based on Graph Contrastive Learning and Graph Transformer",
      "title_zh": "基于图对比学习和图Transformer的脑网络分类",
      "authors": [
        "ZhiTeng Zhu",
        "Lan Yao"
      ],
      "abstract": "The dynamic characterization of functional brain networks is of great\nsignificance for elucidating the mechanisms of human brain function. Although\ngraph neural networks have achieved remarkable progress in functional network\nanalysis, challenges such as data scarcity and insufficient supervision\npersist. To address the limitations of limited training data and inadequate\nsupervision, this paper proposes a novel model named PHGCL-DDGformer that\nintegrates graph contrastive learning with graph transformers, effectively\nenhancing the representation learning capability for brain network\nclassification tasks. To overcome the constraints of existing graph contrastive\nlearning methods in brain network feature extraction, an adaptive graph\naugmentation strategy combining attribute masking and edge perturbation is\nimplemented for data enhancement. Subsequently, a dual-domain graph transformer\n(DDGformer) module is constructed to integrate local and global information,\nwhere graph convolutional networks aggregate neighborhood features to capture\nlocal patterns while attention mechanisms extract global dependencies. Finally,\na graph contrastive learning framework is established to maximize the\nconsistency between positive and negative pairs, thereby obtaining high-quality\ngraph representations. Experimental results on real-world datasets demonstrate\nthat the PHGCL-DDGformer model outperforms existing state-of-the-art approaches\nin brain network classification tasks.",
      "tldr_zh": "本论文针对功能脑网络分析中的数据稀缺和监督不足问题，提出了一种名为PHGCL-DDGformer的创新模型，该模型结合Graph Contrastive Learning和Graph Transformer，提升脑网络分类任务的表示学习能力。模型采用适应性图增强策略，包括属性掩码和边扰动，以实现数据增强；同时，通过双域图变换器（DDGformer）模块整合局部信息（利用图卷积网络捕获邻域特征）和全局依赖（通过注意力机制提取）。实验结果显示，在真实数据集上，PHGCL-DDGformer在脑网络分类任务中优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, uses tikz.sty",
      "pdf_url": "http://arxiv.org/pdf/2504.03740v1",
      "published_date": "2025-04-01 13:26:03 UTC",
      "updated_date": "2025-04-01 13:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:26:08.970028"
    },
    {
      "arxiv_id": "2504.00762v4",
      "title": "Do We Truly Need So Many Samples? Multi-LLM Repeated Sampling Efficiently Scales Test-Time Compute",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Chen",
        "Zishuo Xun",
        "Bocheng Zhou",
        "Han Qi",
        "Hangfan Zhang",
        "Qiaosheng Zhang",
        "Yang Chen",
        "Wei Hu",
        "Yuzhong Qu",
        "Wanli Ouyang",
        "Shuyue Hu"
      ],
      "abstract": "This paper presents a simple, effective, and cost-efficient strategy to\nimprove LLM performance by scaling test-time compute. Our strategy builds upon\nthe repeated-sampling-then-voting framework, with a novel twist: incorporating\nmultiple models, even weaker ones, to leverage their complementary strengths\nthat potentially arise from diverse training data and paradigms. By using\nconsistency as a signal, our strategy dynamically switches between models.\nTheoretical analysis highlights the efficiency and performance advantages of\nour strategy. Extensive experiments on six datasets demonstrate that our\nstrategy not only outperforms self-consistency and state-of-the-art multi-agent\ndebate approaches, but also significantly reduces inference costs.\nAdditionally, ModelSwitch requires only a few comparable LLMs to achieve\noptimal performance and can be extended with verification methods,\ndemonstrating the potential of leveraging multiple LLMs in the\ngeneration-verification paradigm.",
      "tldr_zh": "这篇论文提出了一种名为ModelSwitch的简单高效策略，通过多LLM（Large Language Models）重复采样然后投票的框架，动态切换模型以利用它们的互补优势，从而扩展测试时计算并提升性能。策略基于一致性信号在多个模型（包括较弱的LLM）之间切换，理论分析证明了其效率和性能优势。实验结果显示，在六个数据集上，ModelSwitch不仅优于自一致性和最先进的多智能体辩论方法，还显著降低了推理成本，并可扩展到生成-验证范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00762v4",
      "published_date": "2025-04-01 13:13:43 UTC",
      "updated_date": "2025-05-08 08:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:26:21.319374"
    },
    {
      "arxiv_id": "2504.00752v1",
      "title": "LLMs4SchemaDiscovery: A Human-in-the-Loop Workflow for Scientific Schema Mining with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sameer Sadruddin",
        "Jennifer D'Souza",
        "Eleni Poupaki",
        "Alex Watkins",
        "Hamed Babaei Giglou",
        "Anisa Rula",
        "Bora Karasulu",
        "Sören Auer",
        "Adrie Mackus",
        "Erwin Kessels"
      ],
      "abstract": "Extracting structured information from unstructured text is crucial for\nmodeling real-world processes, but traditional schema mining relies on\nsemi-structured data, limiting scalability. This paper introduces schema-miner,\na novel tool that combines large language models with human feedback to\nautomate and refine schema extraction. Through an iterative workflow, it\norganizes properties from text, incorporates expert input, and integrates\ndomain-specific ontologies for semantic depth. Applied to materials\nscience--specifically atomic layer deposition--schema-miner demonstrates that\nexpert-guided LLMs generate semantically rich schemas suitable for diverse\nreal-world applications.",
      "tldr_zh": "该论文提出了LLMs4SchemaDiscovery，一种结合大型语言模型(LLMs)和人类反馈的人机协作工作流，用于从非结构化文本中自动挖掘科学模式(schema)。该工作流通过迭代过程组织属性、融入专家输入以及整合领域特定本体(ontologies)，从而实现模式提取的精炼和语义增强。在材料科学领域，特别是原子层沉积(atomic layer deposition)的应用中，实验证明专家指导的LLMs能生成适用于多样实际场景的语义丰富模式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures, to appear in the Extended Semantic Web\n  Conference (ESWC 2025) proceedings in the Resource track",
      "pdf_url": "http://arxiv.org/pdf/2504.00752v1",
      "published_date": "2025-04-01 13:03:33 UTC",
      "updated_date": "2025-04-01 13:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:26:33.015879"
    },
    {
      "arxiv_id": "2504.02870v2",
      "title": "AI Hiring with LLMs: A Context-Aware and Explainable Multi-Agent Framework for Resume Screening",
      "title_zh": "翻译失败",
      "authors": [
        "Frank P. -W. Lo",
        "Jianing Qiu",
        "Zeyu Wang",
        "Haibao Yu",
        "Yeming Chen",
        "Gao Zhang",
        "Benny Lo"
      ],
      "abstract": "Resume screening is a critical yet time-intensive process in talent\nacquisition, requiring recruiters to analyze vast volume of job applications\nwhile remaining objective, accurate, and fair. With the advancements in Large\nLanguage Models (LLMs), their reasoning capabilities and extensive knowledge\nbases demonstrate new opportunities to streamline and automate recruitment\nworkflows. In this work, we propose a multi-agent framework for resume\nscreening using LLMs to systematically process and evaluate resumes. The\nframework consists of four core agents, including a resume extractor, an\nevaluator, a summarizer, and a score formatter. To enhance the contextual\nrelevance of candidate assessments, we integrate Retrieval-Augmented Generation\n(RAG) within the resume evaluator, allowing incorporation of external knowledge\nsources, such as industry-specific expertise, professional certifications,\nuniversity rankings, and company-specific hiring criteria. This dynamic\nadaptation enables personalized recruitment, bridging the gap between AI\nautomation and talent acquisition. We assess the effectiveness of our approach\nby comparing AI-generated scores with ratings provided by HR professionals on a\ndataset of anonymized online resumes. The findings highlight the potential of\nmulti-agent RAG-LLM systems in automating resume screening, enabling more\nefficient and scalable hiring workflows.",
      "tldr_zh": "本文提出了一种基于 LLMs 的多智能体框架，用于简历筛选，以提升招聘过程的客观性、准确性和效率。该框架包括四个核心智能体：resume extractor、evaluator（整合 RAG 以融入外部知识如行业专业知识和公司招聘标准）、summarizer 和 score formatter，实现上下文相关和个性化的候选评估。通过与 HR 专业人士评分比较，实验结果显示该系统在真实数据集上表现突出，能显著自动化招聘工作流程，并提高其可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by CVPR 2025 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.02870v2",
      "published_date": "2025-04-01 12:56:39 UTC",
      "updated_date": "2025-05-13 16:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:26:45.079288"
    },
    {
      "arxiv_id": "2504.01053v1",
      "title": "Knowledge-Base based Semantic Image Transmission Using CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Chongyang Li",
        "Yanmei He",
        "Tianqian Zhang",
        "Mingjian He",
        "Shouyin Liu"
      ],
      "abstract": "This paper proposes a novel knowledge-Base (KB) assisted semantic\ncommunication framework for image transmission. At the receiver, a Facebook AI\nSimilarity Search (FAISS) based vector database is constructed by extracting\nsemantic embeddings from images using the Contrastive Language-Image\nPre-Training (CLIP) model. During transmission, the transmitter first extracts\na 512-dimensional semantic feature using the CLIP model, then compresses it\nwith a lightweight neural network for transmission. After receiving the signal,\nthe receiver reconstructs the feature back to 512 dimensions and performs\nsimilarity matching from the KB to retrieve the most semantically similar\nimage. Semantic transmission success is determined by category consistency\nbetween the transmitted and retrieved images, rather than traditional metrics\nlike Peak Signal-to-Noise Ratio (PSNR). The proposed system prioritizes\nsemantic accuracy, offering a new evaluation paradigm for semantic-aware\ncommunication systems. Experimental validation on CIFAR100 demonstrates the\neffectiveness of the framework in achieving semantic image transmission.",
      "tldr_zh": "这篇论文提出了一种基于知识库 (KB) 的语义图像传输框架，使用 CLIP 模型提取图像的512维语义特征，并通过轻量级神经网络压缩传输。接收端利用 FAISS 构建的向量数据库进行相似性匹配，检索与传输图像语义最相似的图像，并以类别一致性作为成功标准，而非传统指标如 PSNR，从而优先确保语义准确性。该框架在 CIFAR100 数据集上的实验验证了其有效性，为语义感知通信系统提供了新的评估范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01053v1",
      "published_date": "2025-04-01 12:53:54 UTC",
      "updated_date": "2025-04-01 12:53:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:26:56.281629"
    },
    {
      "arxiv_id": "2504.00727v1",
      "title": "Personality-Driven Decision-Making in LLM-Based Autonomous Agents",
      "title_zh": "LLM-Based",
      "authors": [
        "Lewis Newsham",
        "Daniel Prince"
      ],
      "abstract": "The embedding of Large Language Models (LLMs) into autonomous agents is a\nrapidly developing field which enables dynamic, configurable behaviours without\nthe need for extensive domain-specific training. In our previous work, we\nintroduced SANDMAN, a Deceptive Agent architecture leveraging the Five-Factor\nOCEAN personality model, demonstrating that personality induction significantly\ninfluences agent task planning. Building on these findings, this study presents\na novel method for measuring and evaluating how induced personality traits\naffect task selection processes - specifically planning, scheduling, and\ndecision-making - in LLM-based agents. Our results reveal distinct\ntask-selection patterns aligned with induced OCEAN attributes, underscoring the\nfeasibility of designing highly plausible Deceptive Agents for proactive cyber\ndefense strategies.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在自主代理中的应用，焦点在于如何通过 Five-Factor OCEAN 个性模型诱导个性特征来影响代理的决策过程。基于先前 SANDMAN 架构，该工作提出了一种新方法，用于衡量和评估这些个性特征对任务规划、调度和决策的影响。结果显示，不同的 OCEAN 属性会导致独特的任务选择模式，这为设计高度可信的欺骗代理应用于主动网络防御策略提供了可行性。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 8 figures. To be included in Proc. of the 24th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.00727v1",
      "published_date": "2025-04-01 12:36:28 UTC",
      "updated_date": "2025-04-01 12:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:27:08.193141"
    },
    {
      "arxiv_id": "2504.00717v1",
      "title": "Advancements in Multimodal Differential Evolution: A Comprehensive Review and Future Perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Dikshit Chauhan",
        "Shivani",
        "Donghwi Jung",
        "Anupam Yadav"
      ],
      "abstract": "Multi-modal optimization involves identifying multiple global and local\noptima of a function, offering valuable insights into diverse optimal solutions\nwithin the search space. Evolutionary algorithms (EAs) excel at finding\nmultiple solutions in a single run, providing a distinct advantage over\nclassical optimization techniques that often require multiple restarts without\nguarantee of obtaining diverse solutions. Among these EAs, differential\nevolution (DE) stands out as a powerful and versatile optimizer for continuous\nparameter spaces. DE has shown significant success in multi-modal optimization\nby utilizing its population-based search to promote the formation of multiple\nstable subpopulations, each targeting different optima. Recent advancements in\nDE for multi-modal optimization have focused on niching methods, parameter\nadaptation, hybridization with other algorithms including machine learning, and\napplications across various domains. Given these developments, it is an\nopportune moment to present a critical review of the latest literature and\nidentify key future research directions. This paper offers a comprehensive\noverview of recent DE advancements in multimodal optimization, including\nmethods for handling multiple optima, hybridization with EAs, and machine\nlearning, and highlights a range of real-world applications. Additionally, the\npaper outlines a set of compelling open problems and future research issues\nfrom multiple perspectives",
      "tldr_zh": "这篇论文对Multi-modal optimization领域的Differential Evolution (DE)算法进行了全面回顾，强调DE通过种群-based搜索的优势，能够在单次运行中发现多个全局和局部最优解。论文探讨了DE的最新进展，包括niching methods、参数适应、与其他演化算法(EAs)和机器学习的hybridization，以及在各种实际领域的应用。最终，它提出了关键的开放问题和未来研究方向，以推动该领域的进一步发展。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00717v1",
      "published_date": "2025-04-01 12:30:07 UTC",
      "updated_date": "2025-04-01 12:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:27:20.718151"
    },
    {
      "arxiv_id": "2504.00709v1",
      "title": "Science Autonomy using Machine Learning for Astrobiology",
      "title_zh": "翻译失败",
      "authors": [
        "Victoria Da Poian",
        "Bethany Theiling",
        "Eric Lyness",
        "David Burtt",
        "Abigail R. Azari",
        "Joey Pasterski",
        "Luoth Chou",
        "Melissa Trainer",
        "Ryan Danell",
        "Desmond Kaplan",
        "Xiang Li",
        "Lily Clough",
        "Brett McKinney",
        "Lukas Mandrake",
        "Bill Diamond",
        "Caroline Freissinet"
      ],
      "abstract": "In recent decades, artificial intelligence (AI) including machine learning\n(ML) have become vital for space missions enabling rapid data processing,\nadvanced pattern recognition, and enhanced insight extraction. These tools are\nespecially valuable in astrobiology applications, where models must distinguish\nbiotic patterns from complex abiotic backgrounds. Advancing the integration of\nautonomy through AI and ML into space missions is a complex challenge, and we\nbelieve that by focusing on key areas, we can make significant progress and\noffer practical recommendations for tackling these obstacles.",
      "tldr_zh": "该论文探讨了机器学习(Machine Learning)如何提升天体生物学的科学自主性，强调AI和ML在太空任务中的关键作用，包括快速数据处理、先进模式识别以及从复杂环境中提取洞察。特别是在区分生物模式与非生物背景方面，这些工具尤为宝贵。作者指出，推进AI和ML的整合面临复杂挑战，并提出聚焦关键领域以实现进展并提供实用推荐。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.EP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "8 pages (expanded citations compared to 5 page submitted version for\n  DARES white papers), a white paper for the 2025 NASA Decadal Astrobiology\n  Research and Exploration Strategy (DARES)",
      "pdf_url": "http://arxiv.org/pdf/2504.00709v1",
      "published_date": "2025-04-01 12:20:18 UTC",
      "updated_date": "2025-04-01 12:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:27:32.623283"
    },
    {
      "arxiv_id": "2504.00707v1",
      "title": "Energy Weighted Learning Progress Guided Interleaved Multi-Task Learning",
      "title_zh": "能量加权学习进度引导的交错多任务学习",
      "authors": [
        "Hanne Say",
        "Suzan Ece Ada",
        "Emre Ugur",
        "Erhan Oztop"
      ],
      "abstract": "Humans can continuously acquire new skills and knowledge by exploiting\nexisting ones for improved learning, without forgetting them. Similarly,\n'continual learning' in machine learning aims to learn new information while\npreserving the previously acquired knowledge. Existing research often overlooks\nthe nature of human learning, where tasks are interleaved due to human choice\nor environmental constraints. So, almost never do humans master one task before\nswitching to the next. To investigate to what extent human-like learning can\nbenefit the learner, we propose a method that interleaves tasks based on their\n'learning progress' and energy consumption. From a machine learning\nperspective, our approach can be seen as a multi-task learning system that\nbalances learning performance with energy constraints while mimicking\necologically realistic human task learning. To assess the validity of our\napproach, we consider a robot learning setting in simulation, where the robot\nlearns the effect of its actions in different contexts. The conducted\nexperiments show that our proposed method achieves better performance than\nsequential task learning and reduces energy consumption for learning the tasks.",
      "tldr_zh": "该研究提出了一种基于能量加权学习进度引导的交错多任务学习（Energy Weighted Learning Progress Guided Interleaved Multi-Task Learning）方法，旨在模仿人类学习方式，通过交错任务来实现持续学习（continual learning）而非顺序处理，避免知识遗忘。该方法根据任务的学习进度和能量消耗动态调整任务顺序，作为一种多任务学习（multi-task learning）系统，在模拟机器人环境中进行实验。结果显示，与顺序任务学习（sequential task learning）相比，该方法显著提高了学习性能，同时降低了能量消耗，为更高效的人类化机器学习提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00707v1",
      "published_date": "2025-04-01 12:15:27 UTC",
      "updated_date": "2025-04-01 12:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:27:45.191073"
    },
    {
      "arxiv_id": "2504.00698v2",
      "title": "Command A: An Enterprise-Ready Large Language Model",
      "title_zh": "Command A: 企业就绪的大型语言模型",
      "authors": [
        "Team Cohere",
        ":",
        "Aakanksha",
        "Arash Ahmadian",
        "Marwan Ahmed",
        "Jay Alammar",
        "Milad Alizadeh",
        "Yazeed Alnumay",
        "Sophia Althammer",
        "Arkady Arkhangorodsky",
        "Viraat Aryabumi",
        "Dennis Aumiller",
        "Raphaël Avalos",
        "Zahara Aviv",
        "Sammie Bae",
        "Saurabh Baji",
        "Alexandre Barbet",
        "Max Bartolo",
        "Björn Bebensee",
        "Neeral Beladia",
        "Walter Beller-Morales",
        "Alexandre Bérard",
        "Andrew Berneshawi",
        "Anna Bialas",
        "Phil Blunsom",
        "Matt Bobkin",
        "Adi Bongale",
        "Sam Braun",
        "Maxime Brunet",
        "Samuel Cahyawijaya",
        "David Cairuz",
        "Jon Ander Campos",
        "Cassie Cao",
        "Kris Cao",
        "Roman Castagné",
        "Julián Cendrero",
        "Leila Chan Currie",
        "Yash Chandak",
        "Diane Chang",
        "Giannis Chatziveroglou",
        "Hongyu Chen",
        "Claire Cheng",
        "Alexis Chevalier",
        "Justin T. Chiu",
        "Eugene Cho",
        "Eugene Choi",
        "Eujeong Choi",
        "Tim Chung",
        "Volkan Cirik",
        "Ana Cismaru",
        "Pierre Clavier",
        "Henry Conklin",
        "Lucas Crawhall-Stein",
        "Devon Crouse",
        "Andres Felipe Cruz-Salinas",
        "Ben Cyrus",
        "Daniel D'souza",
        "Hugo Dalla-Torre",
        "John Dang",
        "William Darling",
        "Omar Darwiche Domingues",
        "Saurabh Dash",
        "Antoine Debugne",
        "Théo Dehaze",
        "Shaan Desai",
        "Joan Devassy",
        "Rishit Dholakia",
        "Kyle Duffy",
        "Ali Edalati",
        "Ace Eldeib",
        "Abdullah Elkady",
        "Sarah Elsharkawy",
        "Irem Ergün",
        "Beyza Ermis",
        "Marzieh Fadaee",
        "Boyu Fan",
        "Lucas Fayoux",
        "Yannis Flet-Berliac",
        "Nick Frosst",
        "Matthias Gallé",
        "Wojciech Galuba",
        "Utsav Garg",
        "Matthieu Geist",
        "Mohammad Gheshlaghi Azar",
        "Ellen Gilsenan-McMahon",
        "Seraphina Goldfarb-Tarrant",
        "Tomas Goldsack",
        "Aidan Gomez",
        "Victor Machado Gonzaga",
        "Nithya Govindarajan",
        "Manoj Govindassamy",
        "Nathan Grinsztajn",
        "Nikolas Gritsch",
        "Patrick Gu",
        "Shangmin Guo",
        "Kilian Haefeli",
        "Rod Hajjar",
        "Tim Hawes",
        "Jingyi He",
        "Sebastian Hofstätter",
        "Sungjin Hong",
        "Sara Hooker",
        "Tom Hosking",
        "Stephanie Howe",
        "Eric Hu",
        "Renjie Huang",
        "Hemant Jain",
        "Ritika Jain",
        "Nick Jakobi",
        "Madeline Jenkins",
        "JJ Jordan",
        "Dhruti Joshi",
        "Jason Jung",
        "Trushant Kalyanpur",
        "Siddhartha Rao Kamalakara",
        "Julia Kedrzycki",
        "Gokce Keskin",
        "Edward Kim",
        "Joon Kim",
        "Wei-Yin Ko",
        "Tom Kocmi",
        "Michael Kozakov",
        "Wojciech Kryściński",
        "Arnav Kumar Jain",
        "Komal Kumar Teru",
        "Sander Land",
        "Michael Lasby",
        "Olivia Lasche",
        "Justin Lee",
        "Patrick Lewis",
        "Jeffrey Li",
        "Jonathan Li",
        "Hangyu Lin",
        "Acyr Locatelli",
        "Kevin Luong",
        "Raymond Ma",
        "Lukáš Mach",
        "Marina Machado",
        "Joanne Magbitang",
        "Brenda Malacara Lopez",
        "Aryan Mann",
        "Kelly Marchisio",
        "Olivia Markham",
        "Alexandre Matton",
        "Alex McKinney",
        "Dominic McLoughlin",
        "Jozef Mokry",
        "Adrien Morisot",
        "Autumn Moulder",
        "Harry Moynehan",
        "Maximilian Mozes",
        "Vivek Muppalla",
        "Lidiya Murakhovska",
        "Hemangani Nagarajan",
        "Alekhya Nandula",
        "Hisham Nasir",
        "Shauna Nehra",
        "Josh Netto-Rosen",
        "Daniel Ohashi",
        "James Owers-Bardsley",
        "Jason Ozuzu",
        "Dennis Padilla",
        "Gloria Park",
        "Sam Passaglia",
        "Jeremy Pekmez",
        "Laura Penstone",
        "Aleksandra Piktus",
        "Case Ploeg",
        "Andrew Poulton",
        "Youran Qi",
        "Shubha Raghvendra",
        "Miguel Ramos",
        "Ekagra Ranjan",
        "Pierre Richemond",
        "Cécile Robert-Michon",
        "Aurélien Rodriguez",
        "Sudip Roy",
        "Sebastian Ruder",
        "Laura Ruis",
        "Louise Rust",
        "Anubhav Sachan",
        "Alejandro Salamanca",
        "Kailash Karthik Saravanakumar",
        "Isha Satyakam",
        "Alice Schoenauer Sebag",
        "Priyanka Sen",
        "Sholeh Sepehri",
        "Preethi Seshadri",
        "Ye Shen",
        "Tom Sherborne",
        "Sylvie Shang Shi",
        "Sanal Shivaprasad",
        "Vladyslav Shmyhlo",
        "Anirudh Shrinivason",
        "Inna Shteinbuk",
        "Amir Shukayev",
        "Mathieu Simard",
        "Ella Snyder",
        "Ava Spataru",
        "Victoria Spooner",
        "Trisha Starostina",
        "Florian Strub",
        "Yixuan Su",
        "Jimin Sun",
        "Dwarak Talupuru",
        "Eugene Tarassov",
        "Elena Tommasone",
        "Jennifer Tracey",
        "Billy Trend",
        "Evren Tumer",
        "Ahmet Üstün",
        "Bharat Venkitesh",
        "David Venuto",
        "Pat Verga",
        "Maxime Voisin",
        "Alex Wang",
        "Donglu Wang",
        "Shijian Wang",
        "Edmond Wen",
        "Naomi White",
        "Jesse Willman",
        "Marysia Winkels",
        "Chen Xia",
        "Jessica Xie",
        "Minjie Xu",
        "Bowen Yang",
        "Tan Yi-Chern",
        "Ivan Zhang",
        "Zhenyu Zhao",
        "Zhoujie Zhao"
      ],
      "abstract": "In this report we describe the development of Command A, a powerful large\nlanguage model purpose-built to excel at real-world enterprise use cases.\nCommand A is an agent-optimised and multilingual-capable model, with support\nfor 23 languages of global business, and a novel hybrid architecture balancing\nefficiency with top of the range performance. It offers best-in-class Retrieval\nAugmented Generation (RAG) capabilities with grounding and tool use to automate\nsophisticated business processes. These abilities are achieved through a\ndecentralised training approach, including self-refinement algorithms and model\nmerging techniques. We also include results for Command R7B which shares\ncapability and architectural similarities to Command A. Weights for both models\nhave been released for research purposes. This technical report details our\noriginal training pipeline and presents an extensive evaluation of our models\nacross a suite of enterprise-relevant tasks and public benchmarks,\ndemonstrating excellent performance and efficiency.",
      "tldr_zh": "这篇报告介绍了Command A，一款针对企业实际应用优化的Large Language Model，支持23种语言并采用混合架构，以平衡效率和顶级性能。该模型具备一流的Retrieval Augmented Generation (RAG) 能力，包括grounding和tool use，用于自动化复杂业务流程，并通过去中心化训练、自精炼算法和模型合并技术实现这些功能。与Command R7B类似，Command A在企业相关任务和公共基准上的评估显示出卓越的表现和效率，且模型权重已发布供研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "55 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.00698v2",
      "published_date": "2025-04-01 12:08:07 UTC",
      "updated_date": "2025-04-14 12:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:27:57.643357"
    },
    {
      "arxiv_id": "2504.00692v1",
      "title": "The HCI GenAI CO2ST Calculator: A Tool for Calculating the Carbon Footprint of Generative AI Use in Human-Computer Interaction Research",
      "title_zh": "翻译失败",
      "authors": [
        "Nanna Inie",
        "Jeanette Falk",
        "Raghavendra Selvan"
      ],
      "abstract": "Increased usage of generative AI (GenAI) in Human-Computer Interaction (HCI)\nresearch induces a climate impact from carbon emissions due to energy\nconsumption of the hardware used to develop and run GenAI models and systems.\nThe exact energy usage and and subsequent carbon emissions are difficult to\nestimate in HCI research because HCI researchers most often use cloud-based\nservices where the hardware and its energy consumption are hidden from plain\nview. The HCI GenAI CO2ST Calculator is a tool designed specifically for the\nHCI research pipeline, to help researchers estimate the energy consumption and\ncarbon footprint of using generative AI in their research, either a priori\n(allowing for mitigation strategies or experimental redesign) or post hoc\n(allowing for transparent documentation of carbon footprint in written reports\nof the research).",
      "tldr_zh": "这篇论文介绍了 HCI GenAI CO2ST Calculator，一种专为 HCI（Human-Computer Interaction）研究设计的工具，用于估算生成式 AI（Generative AI）使用中的能源消耗和碳足迹。工具针对 HCI 研究者在使用云服务时面临的硬件透明度问题，提供事前（a priori）估算以制定缓解策略或实验 redesign，以及事后（post hoc）估算以在报告中实现透明文档。该工具有助于促进 HCI 研究的可持续发展，并提升对碳排放影响的认识。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00692v1",
      "published_date": "2025-04-01 12:02:45 UTC",
      "updated_date": "2025-04-01 12:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:28:09.531273"
    },
    {
      "arxiv_id": "2504.03739v1",
      "title": "A Unified Virtual Mixture-of-Experts Framework:Enhanced Inference and Hallucination Mitigation in Single-Model System",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyan Liu"
      ],
      "abstract": "Generative models, such as GPT and BERT, have significantly improved\nperformance in tasks like text generation and summarization. However,\nhallucinations \"where models generate non-factual or misleading content\" are\nespecially problematic in smaller-scale architectures, limiting their\nreal-world applicability.In this paper, we propose a unified Virtual\nMixture-of-Experts (MoE) fusion strategy that enhances inference performance\nand mitigates hallucinations in a single Qwen 1.5 0.5B model without increasing\nthe parameter count. Our method leverages multiple domain-specific expert\nprompts (with the number of experts being adjustable) to guide the model from\ndifferent perspectives. We apply a statistical outlier truncation strategy\nbased on the mean and standard deviation to filter out abnormally high\nprobability predictions, and we inject noise into the embedding space to\npromote output diversity. To clearly assess the contribution of each module, we\nadopt a fixed voting mechanism rather than a dynamic gating network, thereby\navoiding additional confounding factors. We provide detailed theoretical\nderivations from both statistical and ensemble learning perspectives to\ndemonstrate how our method reduces output variance and suppresses\nhallucinations. Extensive ablation experiments on dialogue generation tasks\nshow that our approach significantly improves inference accuracy and robustness\nin small models. Additionally, we discuss methods for evaluating the\northogonality of virtual experts and outline the potential for future work\ninvolving dynamic expert weight allocation using gating networks.",
      "tldr_zh": "该论文提出了一种统一的 Virtual Mixture-of-Experts (MoE) 框架，用于在单个 Qwen 1.5 0.5B 模型中提升推理性能并缓解 hallucinations（模型生成非事实或误导性内容的问题），而不增加参数数量。该方法利用多个 domain-specific expert prompts 从不同角度引导模型，并结合统计异常值截断策略（如基于均值和标准差过滤高概率预测）和嵌入空间噪声注入，以减少输出方差并增强多样性。从统计和集成学习角度提供理论推导，支持该框架抑制 hallucinations 的效果。实验在对话生成任务上显示，该方法显著提高了小模型的推理准确性和鲁棒性，并讨论了评估 virtual experts 正交性和未来动态专家权重分配的可能性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03739v1",
      "published_date": "2025-04-01 11:38:01 UTC",
      "updated_date": "2025-04-01 11:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:28:21.747017"
    },
    {
      "arxiv_id": "2504.13877v1",
      "title": "New care pathways for supporting transitional care from hospitals to home using AI and personalized digital assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Ionut Anghel",
        "Tudor Cioara",
        "Roberta Bevilacqua",
        "Federico Barbarossa",
        "Terje Grimstad",
        "Riitta Hellman",
        "Arnor Solberg",
        "Lars Thomas Boye",
        "Ovidiu Anchidin",
        "Ancuta Nemes",
        "Camilla Gabrielsen"
      ],
      "abstract": "Transitional care may play a vital role for the sustainability of Europe\nfuture healthcare system, offering solutions for relocating patient care from\nhospital to home therefore addressing the growing demand for medical care as\nthe population is ageing. However, to be effective, it is essential to\nintegrate innovative Information and Communications Technology technologies to\nensure that patients with comorbidities experience a smooth and coordinated\ntransition from hospitals or care centers to home, thereby reducing the risk of\nrehospitalization. In this paper, we present an overview of the integration of\nInternet of Things, artificial intelligence, and digital assistance\ntechnologies with traditional care pathways to address the challenges and needs\nof healthcare systems in Europe. We identify the current gaps in transitional\ncare and define the technology mapping to enhance the care pathways, aiming to\nimprove patient outcomes, safety, and quality of life avoiding hospital\nreadmissions. Finally, we define the trial setup and evaluation methodology\nneeded to provide clinical evidence that supports the positive impact of\ntechnology integration on patient care and discuss the potential effects on the\nhealthcare system.",
      "tldr_zh": "该论文探讨了利用AI和个性化数字辅助技术来优化欧洲医疗系统的过渡性护理路径，旨在帮助患者从医院平稳过渡到家庭，应对老龄化人口的医疗需求并减少再住院风险。通过整合Internet of Things (IoT)、artificial intelligence (AI) 和数字辅助技术，该研究识别了当前护理中的关键差距，并定义了技术映射以提升患者结果、安全和生活质量。最终，论文提出了试验设置和评估方法，以提供临床证据证明这些创新整合对医疗系统的积极影响。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "submitted to journal (under review)",
      "pdf_url": "http://arxiv.org/pdf/2504.13877v1",
      "published_date": "2025-04-01 11:37:36 UTC",
      "updated_date": "2025-04-01 11:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:28:32.509816"
    },
    {
      "arxiv_id": "2504.00661v1",
      "title": "DynMoLE: Boosting Mixture of LoRA Experts Fine-Tuning with a Hybrid Routing Mechanism",
      "title_zh": "DynMoLE：通过混合路由机制提升",
      "authors": [
        "Dengchun Li",
        "Naizheng Wang",
        "Zihao Zhang",
        "Haoyang Yin",
        "Lei Duan",
        "Meng Xiao",
        "Mingjie Tang"
      ],
      "abstract": "Instruction-based fine-tuning of large language models (LLMs) has achieved\nremarkable success in various natural language processing (NLP) tasks.\nParameter-efficient fine-tuning (PEFT) methods, such as Mixture of LoRA Experts\n(MoLE), combine the efficiency of Low-Rank Adaptation (LoRA) with the\nversatility of Mixture of Experts (MoE) models, demonstrating significant\npotential for handling multiple downstream tasks. However, the existing routing\nmechanisms for MoLE often involve a trade-off between computational efficiency\nand predictive accuracy, and they fail to fully address the diverse expert\nselection demands across different transformer layers. In this work, we propose\nDynMoLE, a hybrid routing strategy that dynamically adjusts expert selection\nbased on the Tsallis entropy of the router's probability distribution. This\napproach mitigates router uncertainty, enhances stability, and promotes more\nequitable expert participation, leading to faster convergence and improved\nmodel performance. Additionally, we introduce an auxiliary loss based on\nTsallis entropy to further guide the model toward convergence with reduced\nuncertainty, thereby improving training stability and performance. Our\nextensive experiments on commonsense reasoning benchmarks demonstrate that\nDynMoLE achieves substantial performance improvements, outperforming LoRA by\n9.6% and surpassing the state-of-the-art MoLE method, MoLA, by 2.3%. We also\nconduct a comprehensive ablation study to evaluate the contributions of\nDynMoLE's key components.",
      "tldr_zh": "本研究提出 DynMoLE，一种混合路由机制，用于提升 Mixture of LoRA Experts (MoLE) 在大型语言模型 (LLMs) 微调中的性能，解决现有路由策略在计算效率和预测准确性之间的权衡问题。DynMoLE 通过基于 Tsallis entropy 的动态路由策略动态调整专家选择，减少路由不确定性、提高稳定性，并促进专家均衡参与，从而加速模型收敛并优化性能；此外，还引入 Tsallis entropy 辅助损失以进一步增强训练稳定性和效果。在常识推理基准测试中，DynMoLE 比 LoRA 提升 9.6%，并超过最先进方法 MoLA 2.3%，并通过全面消融研究验证了其关键组件的贡献。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00661v1",
      "published_date": "2025-04-01 11:14:19 UTC",
      "updated_date": "2025-04-01 11:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:28:45.717808"
    },
    {
      "arxiv_id": "2504.00652v1",
      "title": "Towards Adaptive AI Governance: Comparative Insights from the U.S., EU, and Asia",
      "title_zh": "迈向适应性 AI 治理：来自美国、欧盟和亚洲的比较见解",
      "authors": [
        "Vikram Kulothungan",
        "Deepti Gupta"
      ],
      "abstract": "Artificial intelligence (AI) trends vary significantly across global regions,\nshaping the trajectory of innovation, regulation, and societal impact. This\nvariation influences how different regions approach AI development, balancing\ntechnological progress with ethical and regulatory considerations. This study\nconducts a comparative analysis of AI trends in the United States (US), the\nEuropean Union (EU), and Asia, focusing on three key dimensions: generative AI,\nethical oversight, and industrial applications. The US prioritizes\nmarket-driven innovation with minimal regulatory constraints, the EU enforces a\nprecautionary risk-based framework emphasizing ethical safeguards, and Asia\nemploys state-guided AI strategies that balance rapid deployment with\nregulatory oversight. Although these approaches reflect different economic\nmodels and policy priorities, their divergence poses challenges to\ninternational collaboration, regulatory harmonization, and the development of\nglobal AI standards. To address these challenges, this paper synthesizes\nregional strengths to propose an adaptive AI governance framework that\nintegrates risk-tiered oversight, innovation accelerators, and strategic\nalignment mechanisms. By bridging governance gaps, this study offers actionable\ninsights for fostering responsible AI development while ensuring a balance\nbetween technological progress, ethical imperatives, and regulatory coherence.",
      "tldr_zh": "本研究对美国（U.S.）、欧盟（EU）和亚洲的 AI 趋势进行比较分析，聚焦生成式 AI、伦理监督和工业应用三个维度。美国强调市场驱动创新和最小监管，欧盟采用预防性风险-based 框架优先伦理保障，而亚洲则通过国家引导策略平衡快速部署与监管。研究发现，这些区域差异导致国际合作、监管协调和全球标准开发的挑战，并提出一个适应性 AI 治理框架，整合风险分级监督、创新加速器和战略对齐机制，以推动负责任的 AI 发展并实现技术进步与伦理监管的平衡。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at IEEE BigDataSecurity 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.00652v1",
      "published_date": "2025-04-01 11:05:47 UTC",
      "updated_date": "2025-04-01 11:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:28:57.082985"
    },
    {
      "arxiv_id": "2504.02000v1",
      "title": "AI Regulation and Capitalist Growth: Balancing Innovation, Ethics, and Global Governance",
      "title_zh": "AI 监管与资本主义增长：平衡创新、伦理和全球治理",
      "authors": [
        "Vikram Kulothungan",
        "Priya Ranjani Mohan",
        "Deepti Gupta"
      ],
      "abstract": "Artificial Intelligence (AI) is increasingly central to economic growth,\npromising new efficiencies and markets. This economic significance has sparked\ndebate over AI regulation: do rules and oversight bolster long term growth by\nbuilding trust and safeguarding the public, or do they constrain innovation and\nfree enterprise? This paper examines the balance between AI regulation and\ncapitalist ideals, focusing on how different approaches to AI data privacy can\nimpact innovation in AI-driven applications. The central question is whether AI\nregulation enhances or inhibits growth in a capitalist economy. Our analysis\nsynthesizes historical precedents, the current U.S. regulatory landscape,\neconomic projections, legal challenges, and case studies of recent AI policies.\nWe discuss that carefully calibrated AI data privacy regulations-balancing\ninnovation incentives with the public interest can foster sustainable growth by\nbuilding trust and ensuring responsible data use, while excessive regulation\nmay risk stifling innovation and entrenching incumbents.",
      "tldr_zh": "这篇论文探讨了AI监管与资本主义经济增长之间的平衡，焦点在于AI规则是否能通过建立信任和保护公众来促进长期创新，还是会抑制自由企业和创新。作者通过分析历史先例、当前美国监管环境、经济预测、法律挑战以及AI政策案例研究，评估AI数据隐私法规对AI驱动应用的影响。研究发现，适度AI regulation能平衡创新激励与公共利益，促进可持续增长和负责数据使用，而过度regulation可能扼杀创新并强化现有企业。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for IEEE BigDataSecurity 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.02000v1",
      "published_date": "2025-04-01 10:59:02 UTC",
      "updated_date": "2025-04-01 10:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:29:08.657163"
    },
    {
      "arxiv_id": "2504.00638v2",
      "title": "Impact of Data Duplication on Deep Neural Network-Based Image Classifiers: Robust vs. Standard Models",
      "title_zh": "数据重复对基于深度神经网络的图像分类器的影响：鲁棒模型与标准模型",
      "authors": [
        "Alireza Aghabagherloo",
        "Aydin Abadi",
        "Sumanta Sarkar",
        "Vishnu Asutosh Dasu",
        "Bart Preneel"
      ],
      "abstract": "The accuracy and robustness of machine learning models against adversarial\nattacks are significantly influenced by factors such as training data quality,\nmodel architecture, the training process, and the deployment environment. In\nrecent years, duplicated data in training sets, especially in language models,\nhas attracted considerable attention. It has been shown that deduplication\nenhances both training performance and model accuracy in language models. While\nthe importance of data quality in training image classifier Deep Neural\nNetworks (DNNs) is widely recognized, the impact of duplicated images in the\ntraining set on model generalization and performance has received little\nattention.\n  In this paper, we address this gap and provide a comprehensive study on the\neffect of duplicates in image classification. Our analysis indicates that the\npresence of duplicated images in the training set not only negatively affects\nthe efficiency of model training but also may result in lower accuracy of the\nimage classifier. This negative impact of duplication on accuracy is\nparticularly evident when duplicated data is non-uniform across classes or when\nduplication, whether uniform or non-uniform, occurs in the training set of an\nadversarially trained model. Even when duplicated samples are selected in a\nuniform way, increasing the amount of duplication does not lead to a\nsignificant improvement in accuracy.",
      "tldr_zh": "本文研究了训练数据中重复图像对基于 Deep Neural Networks (DNNs) 的图像分类器的影响，比较了标准模型和鲁棒模型的性能。研究发现，重复数据不仅降低了模型的训练效率和准确性，尤其在类别非均匀分布或对抗训练（adversarial trained）模型中表现更明显。即使采用均匀重复样本，增加重复量也不会显著改善准确性。该工作填补了图像分类领域数据重复影响的空白，为提升训练数据质量提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00638v2",
      "published_date": "2025-04-01 10:48:00 UTC",
      "updated_date": "2025-04-17 16:01:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:29:21.138045"
    },
    {
      "arxiv_id": "2504.00634v1",
      "title": "CNOT-Optimal Clifford Synthesis as SAT",
      "title_zh": "翻译失败",
      "authors": [
        "Irfansha Shaik",
        "Jaco van de Pol"
      ],
      "abstract": "Clifford circuit optimization is an important step in the quantum compilation\npipeline. Major compilers employ heuristic approaches. While they are fast,\ntheir results are often suboptimal. Minimization of noisy gates, like 2-qubit\nCNOT gates, is crucial for practical computing. Exact approaches have been\nproposed to fill the gap left by heuristic approaches. Among these are SAT\nbased approaches that optimize gate count or depth, but they suffer from\nscalability issues. Further, they do not guarantee optimality on more important\nmetrics like CNOT count or CNOT depth. A recent work proposed an exhaustive\nsearch only on Clifford circuits in a certain normal form to guarantee CNOT\ncount optimality. But an exhaustive approach cannot scale beyond 6 qubits.\n  In this paper, we incorporate search restricted to Clifford normal forms in a\nSAT encoding to guarantee CNOT count optimality. By allowing parallel plans, we\npropose a second SAT encoding that optimizes CNOT depth. By taking advantage of\nflexibility in SAT based approaches, we also handle connectivity restrictions\nin hardware platforms, and allow for qubit relabeling. We have implemented the\nabove encodings and variations in our open source tool Q-Synth.\n  In experiments, our encodings significantly outperform existing SAT\napproaches on random Clifford circuits. We consider practical VQE and Feynman\nbenchmarks to compare with TKET and Qiskit compilers. In all-to-all\nconnectivity, we observe reductions up to 32.1% in CNOT count and 48.1% in CNOT\ndepth. Overall, we observe better results than TKET in the CNOT count and\ndepth. We also experiment with connectivity restrictions of major quantum\nplatforms. Compared to Qiskit, we observe up to 30.3% CNOT count and 35.9% CNOT\ndepth further reduction.",
      "tldr_zh": "这篇论文将 Clifford 电路优化问题转化为 SAT 问题，旨在通过限制搜索于 Clifford 标准形式来保证 CNOT 计数的全局最优性，同时提出一个基于并行计划的第二 SAT 编码来优化 CNOT 深度，并处理硬件平台的连接限制和量子位重标记。作者在开源工具 Q-Synth 中实现了这些编码。实验结果显示，该方法在随机 Clifford 电路上显著优于现有 SAT 技术，在 VQE 和 Feynman 基准测试中，与 TKET 和 Qiskit 编译器相比，CNOT 计数减少高达 32.1%、CNOT 深度减少高达 48.1%，并在连接限制下进一步实现额外优化。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "27 pages (16 main text, rest references and appendix), 15 Tables, 3\n  Figures, 2 Algorithms",
      "pdf_url": "http://arxiv.org/pdf/2504.00634v1",
      "published_date": "2025-04-01 10:35:58 UTC",
      "updated_date": "2025-04-01 10:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:29:33.899912"
    },
    {
      "arxiv_id": "2504.00624v1",
      "title": "Feature Subset Weighting for Distance-based Supervised Learning through Choquet Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Adnan Theerens",
        "Yvan Saeys",
        "Chris Cornelis"
      ],
      "abstract": "This paper introduces feature subset weighting using monotone measures for\ndistance-based supervised learning. The Choquet integral is used to define a\ndistance metric that incorporates these weights. This integration enables the\nproposed distances to effectively capture non-linear relationships and account\nfor interactions both between conditional and decision attributes and among\nconditional attributes themselves, resulting in a more flexible distance\nmeasure. In particular, we show how this approach ensures that the distances\nremain unaffected by the addition of duplicate and strongly correlated\nfeatures. Another key point of this approach is that it makes feature subset\nweighting computationally feasible, since only $m$ feature subset weights\nshould be calculated each time instead of calculating all feature subset\nweights ($2^m$), where $m$ is the number of attributes. Next, we also examine\nhow the use of the Choquet integral for measuring similarity leads to a\nnon-equivalent definition of distance. The relationship between distance and\nsimilarity is further explored through dual measures. Additionally, symmetric\nChoquet distances and similarities are proposed, preserving the classical\nsymmetry between similarity and distance. Finally, we introduce a concrete\nfeature subset weighting distance, evaluate its performance in a $k$-nearest\nneighbors (KNN) classification setting, and compare it against Mahalanobis\ndistances and weighted distance methods.",
      "tldr_zh": "本论文提出了一种基于Choquet积分的特征子集加权方法，用于距离-based监督学习，通过单调测度（monotone measures）定义距离度量，以捕捉条件属性间的非线性关系和交互。相比传统方法，该方法确保距离不受重复或高度相关特征的影响，并通过仅计算m个特征子集权重（而非2^m）实现计算效率的提升，同时探讨了Choquet积分在相似性测量中的非等价定义和对称版本。实验结果显示，该距离在k-nearest neighbors (KNN) 分类任务中优于Mahalanobis distances和加权距离方法，提供了一种更灵活且鲁棒的监督学习框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00624v1",
      "published_date": "2025-04-01 10:23:01 UTC",
      "updated_date": "2025-04-01 10:23:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:29:45.068549"
    },
    {
      "arxiv_id": "2504.00615v2",
      "title": "Towards Responsible and Trustworthy Educational Data Mining: Comparing Symbolic, Sub-Symbolic, and Neural-Symbolic AI Methods",
      "title_zh": "面向负责任和可信赖的教育数据挖掘：",
      "authors": [
        "Danial Hooshyar",
        "Eve Kikas",
        "Yeongwook Yang",
        "Gustav Šír",
        "Raija Hämäläinen",
        "Tommi Kärkkäinen",
        "Roger Azevedo"
      ],
      "abstract": "Given the demand for responsible and trustworthy AI for education, this study\nevaluates symbolic, sub-symbolic, and neural-symbolic AI (NSAI) in terms of\ngeneralizability and interpretability. Our extensive experiments on balanced\nand imbalanced self-regulated learning datasets of Estonian primary school\nstudents predicting 7th-grade mathematics national test performance showed that\nsymbolic and sub-symbolic methods performed well on balanced data but struggled\nto identify low performers in imbalanced datasets. Interestingly, symbolic and\nsub-symbolic methods emphasized different factors in their decision-making:\nsymbolic approaches primarily relied on cognitive and motivational factors,\nwhile sub-symbolic methods focused more on cognitive aspects, learnt knowledge,\nand the demographic variable of gender -- yet both largely overlooked\nmetacognitive factors. The NSAI method, on the other hand, showed advantages\nby: (i) being more generalizable across both classes -- even in imbalanced\ndatasets -- as its symbolic knowledge component compensated for the\nunderrepresented class; and (ii) relying on a more integrated set of factors in\nits decision-making, including motivation, (meta)cognition, and learnt\nknowledge, thus offering a comprehensive and theoretically grounded\ninterpretability framework. These contrasting findings highlight the need for a\nholistic comparison of AI methods before drawing conclusions based solely on\npredictive performance. They also underscore the potential of hybrid,\nhuman-centred NSAI methods to address the limitations of other AI families and\nmove us closer to responsible AI for education. Specifically, by enabling\nstakeholders to contribute to AI design, NSAI aligns learned patterns with\ntheoretical constructs, incorporates factors like motivation and metacognition,\nand strengthens the trustworthiness and responsibility of educational data\nmining.",
      "tldr_zh": "本研究比较了 symbolic AI、sub-symbolic AI 和 neural-symbolic AI (NSAI) 在教育数据挖掘中的 generalizability 和 interpretability，旨在推动负责任的 AI 应用。实验使用平衡和不平衡的自调节学习数据集，预测爱沙尼亚小学生7年级数学考试成绩，结果显示 symbolic 和 sub-symbolic 方法在平衡数据上表现良好，但难以识别不平衡数据集中的低绩效者，且主要依赖认知和动机因素而忽略 metacognitive 因素。相比之下，NSAI 方法通过其 symbolic 知识组件实现了更好的 generalizability，并在决策中整合动机、(meta)cognition 和学到的知识，提供更全面的 interpretability 框架。这些发现强调了全面评估 AI 方法的必要性，并突出了 hybrid NSAI 方法在构建可信赖教育 AI 方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00615v2",
      "published_date": "2025-04-01 10:14:11 UTC",
      "updated_date": "2025-04-11 11:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:29:59.492834"
    },
    {
      "arxiv_id": "2504.00613v1",
      "title": "LLM-Guided Search for Deletion-Correcting Codes",
      "title_zh": "LLM 引导的删除纠正码搜索",
      "authors": [
        "Franziska Weindel",
        "Reinhard Heckel"
      ],
      "abstract": "Finding deletion-correcting codes of maximum size has been an open problem\nfor over 70 years, even for a single deletion. In this paper, we propose a\nnovel approach for constructing deletion-correcting codes. A code is a set of\nsequences satisfying certain constraints, and we construct it by greedily\nadding the highest-priority sequence according to a priority function. To find\ngood priority functions, we leverage FunSearch, a large language model\n(LLM)-guided evolutionary search proposed by Romera et al., 2024. FunSearch\niteratively generates, evaluates, and refines priority functions to construct\nlarge deletion-correcting codes. For a single deletion, our evolutionary search\nfinds functions that construct codes which match known maximum sizes, reach the\nsize of the largest (conjectured optimal) Varshamov-Tenengolts codes where the\nmaximum is unknown, and independently rediscover them in equivalent form. For\ntwo deletions, we find functions that construct codes with new best-known sizes\nfor code lengths \\( n = 12, 13 \\), and \\( 16 \\), establishing improved lower\nbounds. These results demonstrate the potential of LLM-guided search for\ninformation theory and code design and represent the first application of such\nmethods for constructing error-correcting codes.",
      "tldr_zh": "本文提出一种利用大型语言模型(LLM)引导的搜索方法，通过FunSearch框架来构建删除纠错codes。方法涉及贪婪添加最高优先级序列，并迭代生成、评估和优化优先级函数，以最大化code规模。对于单删除，该方法构建的codes匹配已知最大规模，并独立重新发现等效的Varshamov-Tenengolts codes；对于双删除，在n=12、13和16的code长度上，取得了新最佳规模的下界。这些结果展示了LLM-guided search在信息理论和code设计中的潜力，并标志着此类方法在构建error-correcting codes的首次应用。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "cs.NE",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00613v1",
      "published_date": "2025-04-01 10:11:32 UTC",
      "updated_date": "2025-04-01 10:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:30:09.857796"
    },
    {
      "arxiv_id": "2504.00608v1",
      "title": "PLM4NDV: Minimizing Data Access for Number of Distinct Values Estimation with Pre-trained Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xianghong Xu",
        "Xiao He",
        "Tieying Zhang",
        "Lei Zhang",
        "Rui Shi",
        "Jianjun Chen"
      ],
      "abstract": "Number of Distinct Values (NDV) estimation of a multiset/column is a basis\nfor many data management tasks, especially within databases. Despite decades of\nresearch, most existing methods require either a significant amount of samples\nthrough uniform random sampling or access to the entire column to produce\nestimates, leading to substantial data access costs and potentially ineffective\nestimations in scenarios with limited data access. In this paper, we propose\nleveraging semantic information, i.e., schema, to address these challenges. The\nschema contains rich semantic information that can benefit the NDV estimation.\nTo this end, we propose PLM4NDV, a learned method incorporating Pre-trained\nLanguage Models (PLMs) to extract semantic schema information for NDV\nestimation. Specifically, PLM4NDV leverages the semantics of the target column\nand the corresponding table to gain a comprehensive understanding of the\ncolumn's meaning. By using the semantics, PLM4NDV reduces data access costs,\nprovides accurate NDV estimation, and can even operate effectively without any\ndata access. Extensive experiments on a large-scale real-world dataset\ndemonstrate the superiority of PLM4NDV over baseline methods. Our code is\navailable at https://github.com/bytedance/plm4ndv.",
      "tldr_zh": "该论文针对 Number of Distinct Values (NDV) 估计问题提出 PLM4NDV 方法，利用 Pre-trained Language Models (PLMs) 提取 schema 的语义信息，以最小化数据访问成本。PLM4NDV 通过理解目标列和对应表的语义，实现准确的 NDV 估计，甚至能在无需访问任何数据的情况下有效运作。实验结果显示，在大规模真实数据集上，该方法比基线方法表现出色，显著降低了数据管理任务中的访问开销。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted by SIGMOD 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00608v1",
      "published_date": "2025-04-01 10:06:20 UTC",
      "updated_date": "2025-04-01 10:06:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:30:20.732556"
    },
    {
      "arxiv_id": "2504.00603v1",
      "title": "Data Cleansing for GANs",
      "title_zh": "GANs 的数据清洗",
      "authors": [
        "Naoyuki Terashita",
        "Hiroki Ohashi",
        "Satoshi Hara"
      ],
      "abstract": "As the application of generative adversarial networks (GANs) expands, it\nbecomes increasingly critical to develop a unified approach that improves\nperformance across various generative tasks. One effective strategy that\napplies to any machine learning task is identifying harmful instances, whose\nremoval improves the performance. While previous studies have successfully\nestimated these harmful training instances in supervised settings, their\napproaches are not easily applicable to GANs. The challenge lies in two\nrequirements of the previous approaches that do not apply to GANs. First,\nprevious approaches require that the absence of a training instance directly\naffects the parameters. However, in the training for GANs, the instances do not\ndirectly affect the generator's parameters since they are only fed into the\ndiscriminator. Second, previous approaches assume that the change in loss\ndirectly quantifies the harmfulness of the instance to a model's performance,\nwhile common types of GAN losses do not always reflect the generative\nperformance. To overcome the first challenge, we propose influence estimation\nmethods that use the Jacobian of the generator's gradient with respect to the\ndiscriminator's parameters (and vice versa). Such a Jacobian represents the\nindirect effect between two models: how removing an instance from the\ndiscriminator's training changes the generator's parameters. Second, we propose\nan instance evaluation scheme that measures the harmfulness of each training\ninstance based on how a GAN evaluation metric (e.g., Inception score) is\nexpected to change by the instance's removal. Furthermore, we demonstrate that\nremoving the identified harmful instances significantly improves the generative\nperformance on various GAN evaluation metrics.",
      "tldr_zh": "本研究针对生成对抗网络(GANs)的训练，提出了一种数据清洗方法，以识别和移除有害实例，从而提升各种生成任务的性能。该方法克服了传统影响估计方法的局限，通过使用Jacobian矩阵评估实例移除对生成器参数的间接影响（即通过判别器参数的梯度变化），并基于GAN评估指标（如Inception score）的预期变化来量化实例的有害性。实验结果表明，移除这些有害实例后，GANs在多个生成性能指标上显著改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for IEEE Transactions on Neural Networks and Learning\n  Systems (TNNLS, 2025). Journal extention of\n  https://openreview.net/forum?id=opHLcXxYTC_",
      "pdf_url": "http://arxiv.org/pdf/2504.00603v1",
      "published_date": "2025-04-01 10:02:37 UTC",
      "updated_date": "2025-04-01 10:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:30:33.351532"
    },
    {
      "arxiv_id": "2504.00597v2",
      "title": "On the Consistency of Multilingual Context Utilization in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jirui Qi",
        "Raquel Fernández",
        "Arianna Bisazza"
      ],
      "abstract": "Retrieval-augmented generation (RAG) with large language models (LLMs) has\ndemonstrated strong performance in multilingual question-answering (QA) tasks\nby leveraging relevant passages retrieved from corpora. In multilingual RAG\n(mRAG), the retrieved passages can be written in languages other than that of\nthe query entered by the user, making it challenging for LLMs to effectively\nutilize the provided information. Recent research suggests that retrieving\npassages from multilingual corpora can improve RAG performance, particularly\nfor low-resource languages. However, the extent to which LLMs can leverage\ndifferent kinds of multilingual contexts to generate accurate answers,\n*independently from retrieval quality*, remains understudied. In this paper, we\nconduct an extensive assessment of LLMs' ability to (i) make consistent use of\na relevant passage regardless of its language, (ii) respond in the expected\nlanguage, and (iii) focus on the relevant passage even when multiple\n`distracting' passages in different languages are provided in the context. Our\nexperiments with four LLMs across three QA datasets covering a total of 48\nlanguages reveal a surprising ability of LLMs to extract the relevant\ninformation from out-language passages, but a much weaker ability to formulate\na full answer in the correct language. Our analysis, based on both accuracy and\nfeature attribution techniques, further shows that distracting passages\nnegatively impact answer quality regardless of their language. However,\ndistractors in the query language exert a slightly stronger influence. Taken\ntogether, our findings deepen the understanding of how LLMs utilize context in\nmRAG systems, providing directions for future improvements.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在多语言检索增强生成 (RAG) 系统中的上下文利用一致性，焦点在于 LLMs 处理不同语言检索段落的能力，包括利用相关段落、生成预期语言的响应，以及在存在多语言“distracting”段落时保持焦点。实验涉及四个 LLMs 和三个 QA 数据集，覆盖 48 种语言，结果显示 LLMs 能有效从非查询语言的段落中提取信息，但生成完整答案的语言准确性较弱，且 distracting 段落会降低答案质量，尤其是查询语言的 distractors。总体而言，该研究加深了对 mRAG 系统中 LLMs 行为的理解，并为提升模型的多语言处理能力提供了改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review at COLM2025. All codes and data are released at\n  https://github.com/Betswish/mRAG-Context-Consistency",
      "pdf_url": "http://arxiv.org/pdf/2504.00597v2",
      "published_date": "2025-04-01 09:55:23 UTC",
      "updated_date": "2025-04-08 12:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:30:45.162684"
    },
    {
      "arxiv_id": "2504.00584v1",
      "title": "Enhancing Negation Awareness in Universal Text Embeddings: A Data-efficient and Computational-efficient Approach",
      "title_zh": "在通用文本嵌入中",
      "authors": [
        "Hongliu Cao"
      ],
      "abstract": "Negation plays an important role in various natural language processing tasks\nsuch as Natural Language Inference and Sentiment Analysis tasks. Numerous prior\nstudies have found that contextual text embedding models such as BERT, ELMO,\nRoBERTa or XLNet face challenges in accurately understanding negation. Recent\nadvancements in universal text embeddings have demonstrated superior\nperformance over contextual text embeddings in various tasks. However, due to\nthe bias in popular evaluation benchmarks, the negation awareness capacity of\nthese models remains unclear. To bridge the gap in existing literature, an\nin-depth analysis is initiated in this work to study the negation awareness of\ncutting-edge universal text embedding models. Our findings reveal a significant\nlack of negation awareness in these models, often interpreting negated text\npairs as semantically similar. To efficiently deal with the conflict that\ndifferent tasks need different trade-offs between topic and negation\ninformation among other semantic information, a data-efficient and\ncomputational-efficient embedding re-weighting method is proposed without\nmodifying the parameters of text embedding models. The proposed solution is\nable to improve text embedding models' negation awareness significantly on both\nsimple negation understanding task and complex negation understanding task.\nFurthermore, the proposed solution can also significantly improve the negation\nawareness of Large Language Model based task-specific high dimensional\nuniversal text embeddings.",
      "tldr_zh": "本研究探讨了否定在自然语言处理任务（如Natural Language Inference和Sentiment Analysis）中的重要性，并发现现有上下文文本嵌入模型（如BERT、RoBERTa和XLNet）在处理否定方面存在显著挑战。作者对最先进的universal text embeddings模型进行深入分析，揭示这些模型往往将否定文本视为语义相似的，从而缺乏negation awareness。针对此问题，他们提出了一种数据-efficient和computational-efficient的嵌入re-weighting方法，该方法无需修改模型参数即可平衡主题和否定信息。实验结果显示，该方法显著提升了模型在简单和复杂negation理解任务上的性能，并适用于Large Language Model基于的任务-specific高维universal text embeddings。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00584v1",
      "published_date": "2025-04-01 09:39:57 UTC",
      "updated_date": "2025-04-01 09:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:30:57.692284"
    },
    {
      "arxiv_id": "2504.02867v1",
      "title": "Multi-Agent LLM Judge: automatic personalized LLM judge design for evaluating natural language generation applications",
      "title_zh": "翻译失败",
      "authors": [
        "Hongliu Cao",
        "Ilias Driouich",
        "Robin Singh",
        "Eoin Thomas"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive performance across\ndiverse domains, yet they still encounter challenges such as insufficient\ndomain-specific knowledge, biases, and hallucinations. This underscores the\nneed for robust evaluation methodologies to accurately assess LLM-based\napplications. Traditional evaluation methods, which rely on word overlap or\ntext embeddings, are inadequate for capturing the nuanced semantic information\nnecessary to evaluate dynamic, open-ended text generation. Recent research has\nexplored leveraging LLMs to mimic human reasoning and decision-making processes\nfor evaluation purposes known as LLM-as-a-judge framework. However, these\nexisting frameworks have two significant limitations. First, they lack the\nflexibility to adapt to different text styles, including various answer and\nground truth styles, thereby reducing their generalization performance. Second,\nthe evaluation scores produced by these frameworks are often skewed and hard to\ninterpret, showing a low correlation with human judgment. To address these\nchallenges, we propose a novel dynamic multi-agent system that automatically\ndesigns personalized LLM judges for various natural language generation\napplications. This system iteratively refines evaluation prompts and balances\nthe trade-off between the adaptive requirements of downstream tasks and the\nalignment with human perception. Our experimental results show that the\nproposed multi-agent LLM Judge framework not only enhances evaluation accuracy\ncompared to existing methods but also produces evaluation scores that better\nalign with human perception.",
      "tldr_zh": "本文提出了一种动态多智能体系统，名为Multi-Agent LLM Judge，用于自动设计个性化的LLM判断器，以评估自然语言生成应用。该系统针对现有LLM-as-a-judge框架的局限性（如缺乏适应不同文本风格的灵活性和评估分数与人类判断的相关性低）问题，通过迭代优化评估提示和平衡下游任务需求与人类感知的权衡，来提升评估性能。实验结果表明，该框架比传统方法提高了评估准确性，且生成的评分更符合人类判断，为LLM应用评估提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at SophiaSummit2024",
      "pdf_url": "http://arxiv.org/pdf/2504.02867v1",
      "published_date": "2025-04-01 09:36:56 UTC",
      "updated_date": "2025-04-01 09:36:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:31:09.236357"
    },
    {
      "arxiv_id": "2504.03738v1",
      "title": "Attention in Diffusion Model: A Survey",
      "title_zh": "扩散模型中的注意力机制：一项综述",
      "authors": [
        "Litao Hua",
        "Fan Liu",
        "Jie Su",
        "Xingyu Miao",
        "Zizhou Ouyang",
        "Zeyu Wang",
        "Runze Hu",
        "Zhenyu Wen",
        "Bing Zhai",
        "Yang Long",
        "Haoran Duan",
        "Yuan Zhou"
      ],
      "abstract": "Attention mechanisms have become a foundational component in diffusion\nmodels, significantly influencing their capacity across a wide range of\ngenerative and discriminative tasks. This paper presents a comprehensive survey\nof attention within diffusion models, systematically analysing its roles,\ndesign patterns, and operations across different modalities and tasks. We\npropose a unified taxonomy that categorises attention-related modifications\ninto parts according to the structural components they affect, offering a clear\nlens through which to understand their functional diversity. In addition to\nreviewing architectural innovations, we examine how attention mechanisms\ncontribute to performance improvements in diverse applications. We also\nidentify current limitations and underexplored areas, and outline potential\ndirections for future research. Our study provides valuable insights into the\nevolving landscape of diffusion models, with a particular focus on the\nintegrative and ubiquitous role of attention.",
      "tldr_zh": "这篇论文对扩散模型（diffusion models）中的注意力机制（attention mechanisms）进行了全面调查，系统分析了其在各种生成和判别任务中的作用、设计模式及操作。作者提出一个统一的分类法（unified taxonomy），将注意力相关的修改分类为不同结构组件，以揭示其功能多样性，并探讨了这些机制如何提升多模态应用的性能。论文还指出了当前限制和未探索领域，并为未来研究方向提供了潜在指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03738v1",
      "published_date": "2025-04-01 09:00:49 UTC",
      "updated_date": "2025-04-01 09:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:31:20.409982"
    },
    {
      "arxiv_id": "2504.00526v1",
      "title": "High-Quality Pseudo-Label Generation Based on Visual Prompt Assisted Cloud Model Update",
      "title_zh": "基于视觉提示辅助云模型更新的高质量伪标签生成",
      "authors": [
        "Xinrun Xu",
        "Qiuhong Zhang",
        "Jianwen Yang",
        "Zhanbiao Lian",
        "Jin Yan",
        "Zhiming Ding",
        "Shan Jiang"
      ],
      "abstract": "Generating high-quality pseudo-labels on the cloud is crucial for cloud-edge\nobject detection, especially in dynamic traffic monitoring where data\ndistributions evolve. Existing methods often assume reliable cloud models,\nneglecting potential errors or struggling with complex distribution shifts.\nThis paper proposes Cloud-Adaptive High-Quality Pseudo-label generation\n(CA-HQP), addressing these limitations by incorporating a learnable Visual\nPrompt Generator (VPG) and dual feature alignment into cloud model updates. The\nVPG enables parameter-efficient adaptation by injecting visual prompts,\nenhancing flexibility without extensive fine-tuning. CA-HQP mitigates domain\ndiscrepancies via two feature alignment techniques: global Domain Query Feature\nAlignment (DQFA) capturing scene-level shifts, and fine-grained Temporal\nInstance-Aware Feature Embedding Alignment (TIAFA) addressing instance\nvariations. Experiments on the Bellevue traffic dataset demonstrate that CA-HQP\nsignificantly improves pseudo-label quality compared to existing methods,\nleading to notable performance gains for the edge model and showcasing CA-HQP's\nadaptation effectiveness. Ablation studies validate each component (DQFA,\nTIAFA, VPG) and the synergistic effect of combined alignment strategies,\nhighlighting the importance of adaptive cloud updates and domain adaptation for\nrobust object detection in evolving scenarios. CA-HQP provides a promising\nsolution for enhancing cloud-edge object detection systems in real-world\napplications.",
      "tldr_zh": "本论文提出了一种名为 CA-HQP 的方法，用于生成高质量伪标签（pseudo-labels），以解决云边对象检测中数据分布动态变化的问题，特别是动态交通监控场景。CA-HQP 通过引入可学习的 Visual Prompt Generator (VPG) 和双特征对齐技术，包括全局 Domain Query Feature Alignment (DQFA) 处理场景级变化，以及细粒度 Temporal Instance-Aware Feature Embedding Alignment (TIAFA) 应对实例变异，从而实现高效的云模型更新。实验在 Bellevue 交通数据集上表明，CA-HQP 显著提升了伪标签质量，导致边模型性能获得显著改进，且消融研究验证了各组件的协同作用。总体上，该方法为适应性云边对象检测系统提供了可靠解决方案，提升了在真实世界演变场景中的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCNN'25",
      "pdf_url": "http://arxiv.org/pdf/2504.00526v1",
      "published_date": "2025-04-01 08:20:16 UTC",
      "updated_date": "2025-04-01 08:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:31:33.425033"
    },
    {
      "arxiv_id": "2504.00521v1",
      "title": "Automated detection of atomicity violations in large-scale systems",
      "title_zh": "大型系统中原子性违反的自动化检测",
      "authors": [
        "Hang He",
        "Yixing Luo",
        "Chengcheng Wan",
        "Ting Su",
        "Haiying Sun",
        "Geguang Pu"
      ],
      "abstract": "Atomicity violations in interrupt-driven programs pose a significant threat\nto software safety in critical systems. These violations occur when the\nexecution sequence of operations on shared resources is disrupted by\nasynchronous interrupts. Detecting atomicity violations is challenging due to\nthe vast program state space, application-level code dependencies, and complex\ndomain-specific knowledge. We propose Clover, a hybrid framework that\nintegrates static analysis with large language model (LLM) agents to detect\natomicity violations in real-world programs. Clover first performs static\nanalysis to extract critical code snippets and operation information. It then\ninitiates a multi-agent process, where the expert agent leverages\ndomain-specific knowledge to detect atomicity violations, which are\nsubsequently validated by the judge agent. Evaluations on RaceBench 2.1,\nSV-COMP, and RWIP demonstrate that Clover achieves a precision/recall of\n92.3%/86.6%, outperforming existing approaches by 27.4-118.2% on F1-score.",
      "tldr_zh": "该研究针对 interrupt-driven 程序中 atomicity violations 的问题，提出了一种自动化检测框架 Clover，以解决程序状态空间巨大、代码依赖复杂和领域知识需求等挑战。Clover 整合静态分析来提取关键代码片段和操作信息，随后通过多代理系统——其中专家代理利用领域特定知识检测 violations，并由判断代理进行验证。实验结果显示，在 RaceBench 2.1、SV-COMP 和 RWIP 基准上，Clover 达到了 92.3% 精确度和 86.6% 召回率，在 F1-score 上比现有方法提高了 27.4-118.2%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00521v1",
      "published_date": "2025-04-01 08:13:29 UTC",
      "updated_date": "2025-04-01 08:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:31:45.778749"
    },
    {
      "arxiv_id": "2504.00515v1",
      "title": "Training Frozen Feature Pyramid DINOv2 for Eyelid Measurements with Infinite Encoding and Orthogonal Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Chun-Hung Chen"
      ],
      "abstract": "Accurate measurement of eyelid parameters such as Margin Reflex Distances\n(MRD1, MRD2) and Levator Function (LF) is critical in oculoplastic diagnostics\nbut remains limited by manual, inconsistent methods. This study evaluates deep\nlearning models: SE-ResNet, EfficientNet, and the vision transformer-based\nDINOv2 for automating these measurements using smartphone-acquired images. We\nassess performance across frozen and fine-tuned settings, using MSE, MAE, and\nR2 metrics. DINOv2, pretrained through self-supervised learning, demonstrates\nsuperior scalability and robustness, especially under frozen conditions ideal\nfor mobile deployment. Lightweight regressors such as MLP and Deep Ensemble\noffer high precision with minimal computational overhead. To address class\nimbalance and improve generalization, we integrate focal loss, orthogonal\nregularization, and binary encoding strategies. Our results show that DINOv2\ncombined with these enhancements delivers consistent, accurate predictions\nacross all tasks, making it a strong candidate for real-world, mobile-friendly\nclinical applications. This work highlights the potential of foundation models\nin advancing AI-powered ophthalmic care.",
      "tldr_zh": "这篇论文探讨了使用深度学习模型自动化眼睑参数测量（如 MRD1, MRD2 和 LF），以解决传统手动方法的不一致性问题。研究评估了 SE-ResNet、EfficientNet 和 DINOv2 模型在智能手机图像上的性能，使用 MSE、MAE 和 R2 指标比较冻结和微调设置，其中 DINOv2 通过自监督学习表现出色，尤其在冻结条件下适合移动部署。作者引入了 focal loss、orthogonal regularization 和 binary encoding 策略来处理类别不平衡并提升泛化能力。最终结果显示，增强后的 DINOv2 提供高精度预测，推动了 AI 在眼科护理中的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00515v1",
      "published_date": "2025-04-01 08:06:08 UTC",
      "updated_date": "2025-04-01 08:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:31:58.720433"
    },
    {
      "arxiv_id": "2504.00513v2",
      "title": "Leveraging LLMs for User Stories in AI Systems: UStAI Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Asma Yamani",
        "Malak Baslyman",
        "Moataz Ahmed"
      ],
      "abstract": "AI systems are gaining widespread adoption across various sectors and\ndomains. Creating high-quality AI system requirements is crucial for aligning\nthe AI system with business goals and consumer values and for social\nresponsibility. However, with the uncertain nature of AI systems and the heavy\nreliance on sensitive data, more research is needed to address the elicitation\nand analysis of AI systems requirements. With the proprietary nature of many AI\nsystems, there is a lack of open-source requirements artifacts and technical\nrequirements documents for AI systems, limiting broader research and\ninvestigation. With Large Language Models (LLMs) emerging as a promising\nalternative to human-generated text, this paper investigates the potential use\nof LLMs to generate user stories for AI systems based on abstracts from\nscholarly papers. We conducted an empirical evaluation using three LLMs and\ngenerated $1260$ user stories from $42$ abstracts from $26$ domains. We assess\ntheir quality using the Quality User Story (QUS) framework. Moreover, we\nidentify relevant non-functional requirements (NFRs) and ethical principles.\nOur analysis demonstrates that the investigated LLMs can generate user stories\ninspired by the needs of various stakeholders, offering a promising approach\nfor generating user stories for research purposes and for aiding in the early\nrequirements elicitation phase of AI systems. We have compiled and curated a\ncollection of stories generated by various LLMs into a dataset (UStAI), which\nis now publicly available for use.",
      "tldr_zh": "该研究探讨了利用大型语言模型（LLMs）生成AI系统用户故事（User Stories）的潜力，以解决AI系统需求收集的挑战。研究者从42个学术论文摘要中生成1260个用户故事，使用三个LLMs，并通过Quality User Story (QUS)框架评估其质量，同时识别相关非功能性需求（NFRs）和道德原则。结果显示，LLMs能够有效创建反映多利益相关者需求的用户故事，这为AI系统的早期需求收集提供了一个有前景的方法；此外，研究公开了UStAI数据集，促进进一步的研究和应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00513v2",
      "published_date": "2025-04-01 08:03:40 UTC",
      "updated_date": "2025-04-23 11:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:32:09.055224"
    },
    {
      "arxiv_id": "2504.00510v1",
      "title": "Operator Learning with Domain Decomposition for Geometry Generalization in PDE Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Huang",
        "Kaixuan Zhang",
        "Youjia Wu",
        "Ze Cheng"
      ],
      "abstract": "Neural operators have become increasingly popular in solving \\textit{partial\ndifferential equations} (PDEs) due to their superior capability to capture\nintricate mappings between function spaces over complex domains. However, the\ndata-hungry nature of operator learning inevitably poses a bottleneck for their\nwidespread applications. At the core of the challenge lies the absence of\ntransferability of neural operators to new geometries. To tackle this issue, we\npropose operator learning with domain decomposition, a local-to-global\nframework to solve PDEs on arbitrary geometries. Under this framework, we\ndevise an iterative scheme \\textit{Schwarz Neural Inference} (SNI). This scheme\nallows for partitioning of the problem domain into smaller subdomains, on which\nlocal problems can be solved with neural operators, and stitching local\nsolutions to construct a global solution. Additionally, we provide a\ntheoretical analysis of the convergence rate and error bound. We conduct\nextensive experiments on several representative PDEs with diverse boundary\nconditions and achieve remarkable geometry generalization compared to\nalternative methods. These analysis and experiments demonstrate the proposed\nframework's potential in addressing challenges related to geometry\ngeneralization and data efficiency.",
      "tldr_zh": "本研究针对神经算子（neural operators）在解决偏微分方程（PDEs）时面临的数据饥饿和几何泛化（geometry generalization）不足的问题，提出了一种基于域分解（domain decomposition）的局部到全局框架。该框架引入Schwarz Neural Inference (SNI)迭代方案，将问题域分区为子域，使用神经算子求解局部问题并拼接成全局解决方案，同时提供了收敛率和误差界的理论分析。实验结果显示，该方法在多种PDEs和边界条件下，比其他方法实现了显著的几何泛化和数据效率提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00510v1",
      "published_date": "2025-04-01 08:00:43 UTC",
      "updated_date": "2025-04-01 08:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:32:22.121235"
    },
    {
      "arxiv_id": "2504.00509v2",
      "title": "Recitation over Reasoning: How Cutting-Edge Language Models Can Fail on Elementary School-Level Reasoning Problems?",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Yan",
        "Yufei Xu",
        "Zhengyin Du",
        "Xuesong Yao",
        "Zheyu Wang",
        "Xiaowen Guo",
        "Jiecao Chen"
      ],
      "abstract": "The rapid escalation from elementary school-level to frontier problems of the\ndifficulty for LLM benchmarks in recent years have weaved a miracle for\nresearchers that we are only inches away from surpassing human intelligence.\nHowever, is the LLMs' remarkable reasoning ability indeed comes from true\nintelligence by human standards, or are they simply reciting solutions\nwitnessed during training at an Internet level? To study this problem, we\npropose RoR-Bench, a novel, multi-modal benchmark for detecting LLM's\nrecitation behavior when asked simple reasoning problems but with conditions\nsubtly shifted, and conduct empirical analysis on our benchmark. Surprisingly,\nwe found existing cutting-edge LLMs unanimously exhibits extremely severe\nrecitation behavior; by changing one phrase in the condition, top models such\nas OpenAI-o1 and DeepSeek-R1 can suffer $60\\%$ performance loss on elementary\nschool-level arithmetic and reasoning problems. Such findings are a wake-up\ncall to the LLM community that compels us to re-evaluate the true intelligence\nlevel of cutting-edge LLMs.",
      "tldr_zh": "这篇论文质疑了前沿语言模型（LLMs）的推理能力，探讨它们在小学级算术和推理问题上是否依赖真正的智能还是仅仅背诵训练数据。作者提出了 RoR-Bench，这是一个多模态基准，通过微妙改变问题条件来检测 LLMs 的背诵行为。实验发现，顶级模型如 OpenAI-o1 和 DeepSeek-R1 在条件稍作调整后，性能下降高达 60%，这提醒 LLM 社区需要重新评估这些模型的真正智能水平。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 3 figures, 10 tables. V2 refines related work and\n  acknowledgement, and adds links to chat logs for qualitative studies",
      "pdf_url": "http://arxiv.org/pdf/2504.00509v2",
      "published_date": "2025-04-01 07:57:58 UTC",
      "updated_date": "2025-04-08 16:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:32:33.066106"
    },
    {
      "arxiv_id": "2504.00485v3",
      "title": "Stroke Disease Classification Using Machine Learning with Feature Selection Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Mahade Hasan",
        "Farhana Yasmin",
        "Xue Yu"
      ],
      "abstract": "Heart disease remains a leading cause of mortality and morbidity worldwide,\nnecessitating the development of accurate and reliable predictive models to\nfacilitate early detection and intervention. While state of the art work has\nfocused on various machine learning approaches for predicting heart disease,\nbut they could not able to achieve remarkable accuracy. In response to this\nneed, we applied nine machine learning algorithms XGBoost, logistic regression,\ndecision tree, random forest, k-nearest neighbors (KNN), support vector machine\n(SVM), gaussian na\\\"ive bayes (NB gaussian), adaptive boosting, and linear\nregression to predict heart disease based on a range of physiological\nindicators. Our approach involved feature selection techniques to identify the\nmost relevant predictors, aimed at refining the models to enhance both\nperformance and interpretability. The models were trained, incorporating\nprocesses such as grid search hyperparameter tuning, and cross-validation to\nminimize overfitting. Additionally, we have developed a novel voting system\nwith feature selection techniques to advance heart disease classification.\nFurthermore, we have evaluated the models using key performance metrics\nincluding accuracy, precision, recall, F1-score, and the area under the\nreceiver operating characteristic curve (ROC AUC). Among the models, XGBoost\ndemonstrated exceptional performance, achieving 99% accuracy, precision,\nF1-Score, 98% recall, and 100% ROC AUC. This study offers a promising approach\nto early heart disease diagnosis and preventive healthcare.",
      "tldr_zh": "该研究针对心脏病（heart disease）的预测问题，应用了九种机器学习算法，包括 XGBoost、logistic regression、decision tree、random forest、KNN、SVM、gaussian naïve bayes、adaptive boosting 和 linear regression，结合特征选择技术来识别关键生理指标。研究通过网格搜索超参数调整和交叉验证来优化模型性能，并开发了一个新型投票系统（voting system）以提升分类准确性。实验结果显示，XGBoost 模型表现出色，达到了 99% 的 accuracy、precision 和 F1-score、98% 的 recall 以及 100% 的 ROC AUC。该方法为心脏病的早期诊断和预防性医疗提供了高效且可解释的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00485v3",
      "published_date": "2025-04-01 07:16:49 UTC",
      "updated_date": "2025-05-21 20:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:32:47.234942"
    },
    {
      "arxiv_id": "2504.03736v1",
      "title": "Uncertainty Propagation in XAI: A Comparison of Analytical and Empirical Estimators",
      "title_zh": "翻译失败",
      "authors": [
        "Teodor Chiaburu",
        "Felix Bießmann",
        "Frank Haußer"
      ],
      "abstract": "Understanding uncertainty in Explainable AI (XAI) is crucial for building\ntrust and ensuring reliable decision-making in Machine Learning models. This\npaper introduces a unified framework for quantifying and interpreting\nUncertainty in XAI by defining a general explanation function $e_{\\theta}(x,\nf)$ that captures the propagation of uncertainty from key sources:\nperturbations in input data and model parameters. By using both analytical and\nempirical estimates of explanation variance, we provide a systematic means of\nassessing the impact uncertainty on explanations. We illustrate the approach\nusing a first-order uncertainty propagation as the analytical estimator. In a\ncomprehensive evaluation across heterogeneous datasets, we compare analytical\nand empirical estimates of uncertainty propagation and evaluate their\nrobustness. Extending previous work on inconsistencies in explanations, our\nexperiments identify XAI methods that do not reliably capture and propagate\nuncertainty. Our findings underscore the importance of uncertainty-aware\nexplanations in high-stakes applications and offer new insights into the\nlimitations of current XAI methods. The code for the experiments can be found\nin our repository at https://github.com/TeodorChiaburu/UXAI",
      "tldr_zh": "这篇论文提出一个统一的框架，用于量化可解释 AI (XAI) 中的不确定性，通过定义解释函数 $e_{\\theta}(x, f)$ 来分析不确定性在输入数据和模型参数中的传播。作者比较了分析估计（如一阶不确定性传播）和经验估计的方法，并在不同数据集上评估了它们的鲁棒性。实验结果显示，一些 XAI 方法无法可靠地捕捉和传播不确定性，强调了在高风险应用中采用不确定性感知解释的重要性，以提升模型的可信度和决策可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 10 figures, accepted at WCXAI 2025 Istanbul",
      "pdf_url": "http://arxiv.org/pdf/2504.03736v1",
      "published_date": "2025-04-01 07:06:31 UTC",
      "updated_date": "2025-04-01 07:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:32:58.435241"
    },
    {
      "arxiv_id": "2504.00472v1",
      "title": "Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning",
      "title_zh": "记忆是不够的：通过推理进行深度知识注入",
      "authors": [
        "Ruoxi Xu",
        "Yunjie Ji",
        "Boxi Cao",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xianpei Han",
        "Ben He",
        "Yingfei Sun",
        "Xiangang Li",
        "Le Sun"
      ],
      "abstract": "Although large language models (LLMs) excel in knowledge recall and\nreasoning, their static nature leads to outdated information as the real world\nevolves or when adapting to domain-specific knowledge, highlighting the need\nfor effective knowledge injection. However, current research on knowledge\ninjection remains superficial, mainly focusing on knowledge memorization and\nretrieval. This paper proposes a four-tier knowledge injection framework that\nsystematically defines the levels of knowledge injection: memorization,\nretrieval, reasoning, and association. Based on this framework, we introduce\nDeepKnowledge, a synthetic experimental testbed designed for fine-grained\nevaluation of the depth of knowledge injection across three knowledge types\n(novel, incremental, and updated). We then explore various knowledge injection\nscenarios and evaluate the depth of knowledge injection for each scenario on\nthe benchmark. Experimental results reveal key factors to reach each level of\nknowledge injection for LLMs and establish a mapping between the levels of\nknowledge injection and the corresponding suitable injection methods, aiming to\nprovide a comprehensive approach for efficient knowledge injection across\nvarious levels.",
      "tldr_zh": "该论文指出，大型语言模型（LLMs）虽擅长知识回忆和推理，但其静态特性导致信息过时，现有知识注入研究仅局限于记忆和检索层面。作者提出一个四层知识注入框架，包括memorization、retrieval、reasoning和association，并开发了DeepKnowledge测试床，用于细粒度评估三种知识类型（novel、incremental和updated）的注入深度。实验结果揭示了实现每个注入水平的关键因素，并建立了注入水平与合适方法的映射，提供了一种全面高效的知识注入策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00472v1",
      "published_date": "2025-04-01 06:59:59 UTC",
      "updated_date": "2025-04-01 06:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:33:10.080521"
    },
    {
      "arxiv_id": "2504.00469v2",
      "title": "Learning-Based Approximate Nonlinear Model Predictive Control Motion Cueing",
      "title_zh": "翻译失败",
      "authors": [
        "Camilo Gonzalez Arango",
        "Houshyar Asadi",
        "Mohammad Reza Chalak Qazani",
        "Chee Peng Lim"
      ],
      "abstract": "Motion Cueing Algorithms (MCAs) encode the movement of simulated vehicles\ninto movement that can be reproduced with a motion simulator to provide a\nrealistic driving experience within the capabilities of the machine. This paper\nintroduces a novel learning-based MCA for serial robot-based motion simulators.\nBuilding on the differentiable predictive control framework, the proposed\nmethod merges the advantages of Nonlinear Model Predictive Control (NMPC) -\nnotably nonlinear constraint handling and accurate kinematic modeling - with\nthe computational efficiency of machine learning. By shifting the computational\nburden to offline training, the new algorithm enables real-time operation at\nhigh control rates, thus overcoming the key challenge associated with\nNMPC-based motion cueing. The proposed MCA incorporates a nonlinear joint-space\nplant model and a policy network trained to mimic NMPC behavior while\naccounting for joint acceleration, velocity, and position limits. Simulation\nexperiments across multiple motion cueing scenarios showed that the proposed\nalgorithm performed on par with a state-of-the-art NMPC-based alternative in\nterms of motion cueing quality as quantified by the RMSE and correlation\ncoefficient with respect to reference signals. However, the proposed algorithm\nwas on average 400 times faster than the NMPC baseline. In addition, the\nalgorithm successfully generalized to unseen operating conditions, including\nmotion cueing scenarios on a different vehicle and real-time physics-based\nsimulations.",
      "tldr_zh": "这篇论文提出了一种基于学习的 Approximate Nonlinear Model Predictive Control (NMPC) Motion Cueing Algorithm (MCA)，用于串行机器人运动模拟器，以提升模拟车辆运动的真实性和实时性能。该算法整合了 NMPC 的非线性约束处理和精确运动学建模优势，同时通过离线训练策略网络来减轻计算负担，确保在高控制率下实时运行。实验结果显示，该方法在多个场景中的运动提示质量（如 RMSE 和相关系数）与 NMPC 基准相当，但速度快 400 倍，并成功泛化到未见条件，如不同车辆和实时物理模拟。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00469v2",
      "published_date": "2025-04-01 06:52:30 UTC",
      "updated_date": "2025-04-09 23:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:33:22.823381"
    },
    {
      "arxiv_id": "2504.00460v1",
      "title": "MetaLoRA: Tensor-Enhanced Adaptive Low-Rank Fine-tuning",
      "title_zh": "MetaLoRA：张量增强的自适应低秩微调",
      "authors": [
        "Maolin Wang",
        "Xiangyu Zhao"
      ],
      "abstract": "There has been a significant increase in the deployment of neural network\nmodels, presenting substantial challenges in model adaptation and fine-tuning.\nEfficient adaptation is crucial in maintaining model performance across diverse\ntasks and domains. While Low-Rank Adaptation (LoRA) has emerged as a promising\nparameter-efficient fine-tuning method, its fixed parameter nature limits its\nability to handle dynamic task requirements effectively. Adapting models to new\ntasks can be challenging due to the need for extensive fine-tuning. Current\nLoRA variants primarily focus on general parameter reduction while overlooking\nthe importance of dynamic parameter adjustment and meta-learning capabilities.\nMoreover, existing approaches mainly address static adaptations, neglecting the\npotential benefits of task-aware parameter generation in handling diverse task\ndistributions. To address these limitations, this Ph.D. research proposes a\nLoRA generation approach to model task relationships and introduces MetaLoRA, a\nnovel parameter-efficient adaptation framework incorporating meta-learning\nprinciples. This work develops a comprehensive architecture that integrates\nmeta-parameter generation with adaptive low-rank decomposition, enabling\nefficient handling of both task-specific and task-agnostic features. MetaLoRA\naccurately captures task patterns by incorporating meta-learning mechanisms and\ndynamic parameter adjustment strategies. To our knowledge, this research\nrepresents the first attempt to provide a meta-learning enhanced LoRA variant,\noffering improved adaptation capability while maintaining computational\nefficiency in model fine-tuning.",
      "tldr_zh": "该论文针对神经网络模型适应和细调的挑战，指出现有 Low-Rank Adaptation (LoRA) 方法因固定参数而难以处理动态任务需求。研究提出 MetaLoRA，一种新型参数高效框架，结合 meta-learning 原则、元参数生成和自适应低秩分解，能够有效捕捉任务模式并处理任务特定与任务无关特征。MetaLoRA 提升了模型的适应能力，同时保持计算效率，是首个 meta-learning 增强的 LoRA 变体，为多任务场景提供更灵活的细调解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDE 2025 PhD Symposium Track",
      "pdf_url": "http://arxiv.org/pdf/2504.00460v1",
      "published_date": "2025-04-01 06:34:26 UTC",
      "updated_date": "2025-04-01 06:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:33:34.631314"
    },
    {
      "arxiv_id": "2504.00457v3",
      "title": "Distilling Multi-view Diffusion Models into 3D Generators",
      "title_zh": "将多视图扩散模型蒸馏成 3D 生成器",
      "authors": [
        "Hao Qin",
        "Luyuan Chen",
        "Ming Kong",
        "Mengxu Lu",
        "Qiang Zhu"
      ],
      "abstract": "We introduce DD3G, a formulation that Distills a multi-view Diffusion model\n(MV-DM) into a 3D Generator using gaussian splatting. DD3G compresses and\nintegrates extensive visual and spatial geometric knowledge from the MV-DM by\nsimulating its ordinary differential equation (ODE) trajectory, ensuring the\ndistilled generator generalizes better than those trained solely on 3D data.\nUnlike previous amortized optimization approaches, we align the MV-DM and 3D\ngenerator representation spaces to transfer the teacher's probabilistic flow to\nthe student, thus avoiding inconsistencies in optimization objectives caused by\nprobabilistic sampling. The introduction of probabilistic flow and the coupling\nof various attributes in 3D Gaussians introduce challenges in the generation\nprocess. To tackle this, we propose PEPD, a generator consisting of Pattern\nExtraction and Progressive Decoding phases, which enables efficient fusion of\nprobabilistic flow and converts a single image into 3D Gaussians within 0.06\nseconds. Furthermore, to reduce knowledge loss and overcome sparse-view\nsupervision, we design a joint optimization objective that ensures the quality\nof generated samples through explicit supervision and implicit verification.\nLeveraging existing 2D generation models, we compile 120k high-quality RGBA\nimages for distillation. Experiments on synthetic and public datasets\ndemonstrate the effectiveness of our method. Our project is available at:\nhttps://qinbaigao.github.io/DD3G_project/",
      "tldr_zh": "本文提出 DD3G 方法，将多视图扩散模型 (MV-DM) 蒸馏成一个基于 gaussian splatting 的 3D 生成器，通过模拟普通微分方程 (ODE) 轨迹来压缩视觉和空间几何知识，提升生成器的泛化能力。不同于以往的优化方法，DD3G 通过对齐 MV-DM 和 3D 生成器的表示空间，转移概率流以避免采样不一致问题，并引入 PEPD 生成器（包括 Pattern Extraction 和 Progressive Decoding 阶段），实现高效融合并在 0.06 秒内将单张图像转换为 3D Gaussians。作者设计了联合优化目标，结合显式监督和隐式验证，使用 120k 高质量 RGBA 图像进行训练，以减少知识损失并应对稀疏视图监督。在合成和公共数据集上的实验证明，该方法显著提高了 3D 生成质量和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00457v3",
      "published_date": "2025-04-01 06:32:48 UTC",
      "updated_date": "2025-04-03 01:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:33:47.930789"
    },
    {
      "arxiv_id": "2504.00441v2",
      "title": "No Free Lunch with Guardrails",
      "title_zh": "翻译失败",
      "authors": [
        "Divyanshu Kumar",
        "Nitin Aravind Birur",
        "Tanay Baswa",
        "Sahil Agarwal",
        "Prashanth Harshangi"
      ],
      "abstract": "As large language models (LLMs) and generative AI become widely adopted,\nguardrails have emerged as a key tool to ensure their safe use. However, adding\nguardrails isn't without tradeoffs; stronger security measures can reduce\nusability, while more flexible systems may leave gaps for adversarial attacks.\nIn this work, we explore whether current guardrails effectively prevent misuse\nwhile maintaining practical utility. We introduce a framework to evaluate these\ntradeoffs, measuring how different guardrails balance risk, security, and\nusability, and build an efficient guardrail.\n  Our findings confirm that there is no free lunch with guardrails;\nstrengthening security often comes at the cost of usability. To address this,\nwe propose a blueprint for designing better guardrails that minimize risk while\nmaintaining usability. We evaluate various industry guardrails, including Azure\nContent Safety, Bedrock Guardrails, OpenAI's Moderation API, Guardrails AI,\nNemo Guardrails, and Enkrypt AI guardrails. Additionally, we assess how LLMs\nlike GPT-4o, Gemini 2.0-Flash, Claude 3.5-Sonnet, and Mistral Large-Latest\nrespond under different system prompts, including simple prompts, detailed\nprompts, and detailed prompts with chain-of-thought (CoT) reasoning. Our study\nprovides a clear comparison of how different guardrails perform, highlighting\nthe challenges in balancing security and usability.",
      "tldr_zh": "本研究探讨了在大型语言模型（LLMs）和生成式 AI 中使用 guardrails 的权衡，强调加强安全措施往往会降低可用性，而更灵活的系统可能存在漏洞。论文引入了一个框架来评估不同 guardrails 在风险、安全性和可用性之间的平衡，并构建了一个高效的 guardrail，通过实验比较了 Azure Content Safety、Bedrock Guardrails、OpenAI's Moderation API 等行业解决方案，以及 GPT-4o、Gemini 2.0-Flash 等模型在各种系统提示下的表现。结果证实了“没有免费午餐”的原则，即提升安全会牺牲可用性，并提出一个蓝图来设计更优的 guardrails，以最小化风险同时保持实用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00441v2",
      "published_date": "2025-04-01 05:46:54 UTC",
      "updated_date": "2025-04-03 13:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:34:00.127106"
    },
    {
      "arxiv_id": "2504.00438v1",
      "title": "Suite-IN++: A FlexiWear BodyNet Integrating Global and Local Motion Features from Apple Suite for Robust Inertial Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Lan Sun",
        "Songpengcheng Xia",
        "Jiarui Yang",
        "Ling Pei"
      ],
      "abstract": "The proliferation of wearable technology has established multi-device\necosystems comprising smartphones, smartwatches, and headphones as critical\nenablers for ubiquitous pedestrian localization. However, traditional\npedestrian dead reckoning (PDR) struggles with diverse motion modes, while\ndata-driven methods, despite improving accuracy, often lack robustness due to\ntheir reliance on a single-device setup. Therefore, a promising solution is to\nfully leverage existing wearable devices to form a flexiwear bodynet for robust\nand accurate pedestrian localization. This paper presents Suite-IN++, a deep\nlearning framework for flexiwear bodynet-based pedestrian localization.\nSuite-IN++ integrates motion data from wearable devices on different body\nparts, using contrastive learning to separate global and local motion features.\nIt fuses global features based on the data reliability of each device to\ncapture overall motion trends and employs an attention mechanism to uncover\ncross-device correlations in local features, extracting motion details helpful\nfor accurate localization. To evaluate our method, we construct a real-life\nflexiwear bodynet dataset, incorporating Apple Suite (iPhone, Apple Watch, and\nAirPods) across diverse walking modes and device configurations. Experimental\nresults demonstrate that Suite-IN++ achieves superior localization accuracy and\nrobustness, significantly outperforming state-of-the-art models in real-life\npedestrian tracking scenarios.",
      "tldr_zh": "这篇论文介绍了Suite-IN++，一个基于FlexiWear BodyNet的深度学习框架，旨在通过整合Apple Suite（如iPhone、Apple Watch和AirPods）设备的数据，实现鲁棒的行人定位（Pedestrian Dead Reckoning）。该框架使用对比学习（contrastive learning）分离全局和局部运动特征，基于设备数据可靠性融合全局特征，并通过注意力机制（attention mechanism）挖掘局部特征的跨设备相关性，以捕捉整体运动趋势和精确细节。实验结果显示，Suite-IN++在真实数据集上显著提升了定位准确性和鲁棒性，优于现有模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages,10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00438v1",
      "published_date": "2025-04-01 05:40:52 UTC",
      "updated_date": "2025-04-01 05:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:34:11.755257"
    },
    {
      "arxiv_id": "2504.00428v1",
      "title": "LLM-Assisted Proactive Threat Intelligence for Automated Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shuva Paul",
        "Farhad Alemi",
        "Richard Macwan"
      ],
      "abstract": "Successful defense against dynamically evolving cyber threats requires\nadvanced and sophisticated techniques. This research presents a novel approach\nto enhance real-time cybersecurity threat detection and response by integrating\nlarge language models (LLMs) and Retrieval-Augmented Generation (RAG) systems\nwith continuous threat intelligence feeds. Leveraging recent advancements in\nLLMs, specifically GPT-4o, and the innovative application of RAG techniques,\nour approach addresses the limitations of traditional static threat analysis by\nincorporating dynamic, real-time data sources. We leveraged RAG to get the\nlatest information in real-time for threat intelligence, which is not possible\nin the existing GPT-4o model. We employ the Patrowl framework to automate the\nretrieval of diverse cybersecurity threat intelligence feeds, including Common\nVulnerabilities and Exposures (CVE), Common Weakness Enumeration (CWE), Exploit\nPrediction Scoring System (EPSS), and Known Exploited Vulnerabilities (KEV)\ndatabases, and integrate these with the all-mpnet-base-v2 model for\nhigh-dimensional vector embeddings, stored and queried in Milvus. We\ndemonstrate our system's efficacy through a series of case studies, revealing\nsignificant improvements in addressing recently disclosed vulnerabilities,\nKEVs, and high-EPSS-score CVEs compared to the baseline GPT-4o. This work not\nonly advances the role of LLMs in cybersecurity but also establishes a robust\nfoundation for the development of automated intelligent cyberthreat information\nmanagement systems, addressing crucial gaps in current cybersecurity practices.",
      "tldr_zh": "该研究提出了一种结合大型语言模型(LLMs)和检索增强生成(RAG)系统的主动威胁情报方法，使用GPT-4o和Patrowl框架从实时数据源（如CVE、CWE、EPSS和KEV）中自动检索网络威胁情报，并通过all-mpnet-base-v2模型生成高维向量嵌入存储于Milvus，以提升自动化推理能力。相比传统静态分析，该方法解决了实时信息获取的局限性，在案例研究中显示出显著优势，例如在处理新披露漏洞和高EPSS分数CVE方面比基线GPT-4o改善明显。该工作为智能网络威胁管理系统奠定了基础，填补了当前网络安全实践中的关键空白。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 Pages, 1 Figure",
      "pdf_url": "http://arxiv.org/pdf/2504.00428v1",
      "published_date": "2025-04-01 05:19:33 UTC",
      "updated_date": "2025-04-01 05:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:34:22.925300"
    },
    {
      "arxiv_id": "2504.00424v1",
      "title": "Hawkeye:Efficient Reasoning with Model Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Jianshu She",
        "Zhuohao Li",
        "Zhemin Huang",
        "Qi Li",
        "Peiran Xu",
        "Haonan Li",
        "Qirong Ho"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning has demonstrated remarkable effectiveness in\nenhancing the reasoning abilities of large language models (LLMs). However, its\nefficiency remains a challenge due to the generation of excessive intermediate\nreasoning tokens, which introduce semantic redundancy and overly detailed\nreasoning steps. Moreover, computational expense and latency are significant\nconcerns, as the cost scales with the number of output tokens, including those\nintermediate steps. In this work, we observe that most CoT tokens are\nunnecessary, and retaining only a small portion of them is sufficient for\nproducing high-quality responses. Inspired by this, we propose HAWKEYE, a novel\npost-training and inference framework where a large model produces concise CoT\ninstructions to guide a smaller model in response generation. HAWKEYE\nquantifies redundancy in CoT reasoning and distills high-density information\nvia reinforcement learning. By leveraging these concise CoTs, HAWKEYE is able\nto expand responses while reducing token usage and computational cost\nsignificantly. Our evaluation shows that HAWKEYE can achieve comparable\nresponse quality using only 35% of the full CoTs, while improving clarity,\ncoherence, and conciseness by approximately 10%. Furthermore, HAWKEYE can\naccelerate end-to-end reasoning by up to 3.4x on complex math tasks while\nreducing inference cost by up to 60%. HAWKEYE will be open-sourced and the\nmodels will be available soon.",
      "tldr_zh": "该研究针对 Chain-of-Thought (CoT) 推理在提升大型语言模型 (LLMs) 能力的同时存在的效率问题（如冗余中间 tokens 和高计算开销），提出了一种创新框架 HAWKEYE。HAWKEYE 通过大模型生成简洁的 CoT 指令来指导小模型响应生成，并利用强化学习量化 CoT 中的冗余并提炼高密度信息，从而显著减少 tokens 使用。实验结果显示，HAWKEYE 仅需 35% 的完整 CoT 即可实现可比响应质量，同时提高清晰度、一致性和简洁性约 10%，并将复杂数学任务的端到端推理加速高达 3.4 倍，降低推理成本达 60%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00424v1",
      "published_date": "2025-04-01 05:09:04 UTC",
      "updated_date": "2025-04-01 05:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:34:36.256853"
    },
    {
      "arxiv_id": "2504.01047v1",
      "title": "Predicting Movie Production Years through Facial Recognition of Actors with Machine Learning",
      "title_zh": "通过演员人脸识别与机器学习预测电影制作年份",
      "authors": [
        "Asraa Muayed Abdalah",
        "Noor Redha Alkazaz"
      ],
      "abstract": "This study used machine learning algorithms to identify actors and extract\nthe age of actors from images taken randomly from movies. The use of images\ntaken from Arab movies includes challenges such as non-uniform lighting,\ndifferent and multiple poses for the actors and multiple elements with the\nactor or a group of actors. Additionally, the use of make-up, wigs, beards, and\nwearing different accessories and costumes made it difficult for the system to\nidentify the personality of the same actor. The Arab Actors Dataset-AAD\ncomprises 574 images sourced from various movies, encompassing both black and\nwhite as well as color compositions. The images depict complete scenes or\nfragments thereof. Multiple models were employed for feature extraction, and\ndiverse machine learning algorithms were utilized during the classification and\nprediction stages to determine the most effective algorithm for handling such\nimage types. The study demonstrated the effectiveness of the Logistic\nRegression model exhibited the best performance compared to other models in the\ntraining phase, as evidenced by its AUC, precision, CA and F1score values of\n99%, 86%, 85.5% and 84.2% respectively. The findings of this study can be used\nto improve the precision and reliability of facial recognition technology for\nvarious uses as with movies search services, movie suggestion algorithms, and\ngenre classification of movies.",
      "tldr_zh": "这篇论文使用 Machine Learning 算法，通过面部识别技术从阿拉伯电影图像中提取演员年龄，从而预测电影制作年份。研究构建了 Arab Actors Dataset-AAD 数据集，包含574张图像，并处理了诸如非均匀照明、多姿势和化妆等挑战。Logistic Regression 模型在分类和预测阶段表现出最佳性能，AUC、精度、CA 和 F1 分数分别达到99%、86%、85.5% 和84.2%。这些发现可用于提升电影搜索服务、建议算法和流派分类的精确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01047v1",
      "published_date": "2025-04-01 04:46:05 UTC",
      "updated_date": "2025-04-01 04:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:34:46.415643"
    },
    {
      "arxiv_id": "2504.00414v1",
      "title": "Multimodal LLMs for OCR, OCR Post-Correction, and Named Entity Recognition in Historical Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Gavin Greif",
        "Niclas Griesshaber",
        "Robin Greif"
      ],
      "abstract": "We explore how multimodal Large Language Models (mLLMs) can help researchers\ntranscribe historical documents, extract relevant historical information, and\nconstruct datasets from historical sources. Specifically, we investigate the\ncapabilities of mLLMs in performing (1) Optical Character Recognition (OCR),\n(2) OCR Post-Correction, and (3) Named Entity Recognition (NER) tasks on a set\nof city directories published in German between 1754 and 1870. First, we\nbenchmark the off-the-shelf transcription accuracy of both mLLMs and\nconventional OCR models. We find that the best-performing mLLM model\nsignificantly outperforms conventional state-of-the-art OCR models and other\nfrontier mLLMs. Second, we are the first to introduce multimodal\npost-correction of OCR output using mLLMs. We find that this novel approach\nleads to a drastic improvement in transcription accuracy and consistently\nproduces highly accurate transcriptions (<1% CER), without any image\npre-processing or model fine-tuning. Third, we demonstrate that mLLMs can\nefficiently recognize entities in transcriptions of historical documents and\nparse them into structured dataset formats. Our findings provide early evidence\nfor the long-term potential of mLLMs to introduce a paradigm shift in the\napproaches to historical data collection and document transcription.",
      "tldr_zh": "本研究探讨多模态大型语言模型 (mLLMs) 在历史文档处理中的应用，具体包括光学字符识别 (OCR)、OCR 后修正和命名实体识别 (NER)，并使用1754-1870年间德文城市目录作为数据集。实验结果显示，最佳 mLLMs 模型在转录准确性上显著优于传统 OCR 模型和其他前沿 mLLMs，且首次引入的多模态后修正方法无需图像预处理或模型微调，即可将字符错误率 (CER) 降低至不到1%。此外，mLLMs 能高效识别实体并解析成结构化数据集，这为历史数据收集和文档转录带来潜在的范式转变。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00414v1",
      "published_date": "2025-04-01 04:21:34 UTC",
      "updated_date": "2025-04-01 04:21:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:00.137185"
    },
    {
      "arxiv_id": "2504.00409v1",
      "title": "Semantic Mastery: Enhancing LLMs with Advanced Natural Language Understanding",
      "title_zh": "语义掌握：通过高级自然语言理解增强 LLMs",
      "authors": [
        "Mohanakrishnan Hariharan"
      ],
      "abstract": "Large language models (LLMs) have greatly improved their capability in\nperforming NLP tasks. However, deeper semantic understanding, contextual\ncoherence, and more subtle reasoning are still difficult to obtain. The paper\ndiscusses state-of-the-art methodologies that advance LLMs with more advanced\nNLU techniques, such as semantic parsing, knowledge integration, and contextual\nreinforcement learning. We analyze the use of structured knowledge graphs,\nretrieval-augmented generation (RAG), and fine-tuning strategies that match\nmodels with human-level understanding. Furthermore, we address the\nincorporation of transformer-based architectures, contrastive learning, and\nhybrid symbolic-neural methods that address problems like hallucinations,\nambiguity, and inconsistency in the factual perspectives involved in performing\ncomplex NLP tasks, such as question-answering text summarization and dialogue\ngeneration. Our findings show the importance of semantic precision for\nenhancing AI-driven language systems and suggest future research directions to\nbridge the gap between statistical language models and true natural language\nunderstanding.",
      "tldr_zh": "这篇论文探讨了如何通过先进的自然语言理解(NLU)技术提升大型语言模型(LLMs)的语义理解能力，以解决其在深度语义、上下文连贯性和微妙推理方面的局限性。研究引入了语义解析、知识整合、检索增强生成(RAG)以及知识图谱等方法，并结合transformer-based架构、对比学习和混合符号-神经方法，来减少幻觉、歧义和不一致性问题。实验结果强调了语义精确性的重要性，并为未来研究提供了方向，以桥接统计语言模型与真正NLU之间的差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00409v1",
      "published_date": "2025-04-01 04:12:04 UTC",
      "updated_date": "2025-04-01 04:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:11.567068"
    },
    {
      "arxiv_id": "2504.00408v1",
      "title": "From Intuition to Understanding: Using AI Peers to Overcome Physics Misconceptions",
      "title_zh": "翻译失败",
      "authors": [
        "Ruben Weijers",
        "Denton Wu",
        "Hannah Betts",
        "Tamara Jacod",
        "Yuxiang Guan",
        "Vidya Sujaya",
        "Kushal Dev",
        "Toshali Goel",
        "William Delooze",
        "Reihaneh Rabbany",
        "Ying Wu",
        "Jean-François Godbout",
        "Kellin Pelrine"
      ],
      "abstract": "Generative AI has the potential to transform personalization and\naccessibility of education. However, it raises serious concerns about accuracy\nand helping students become independent critical thinkers. In this study, we\ndesigned a helpful AI \"Peer\" to help students correct fundamental physics\nmisconceptions related to Newtonian mechanic concepts. In contrast to\napproaches that seek near-perfect accuracy to create an authoritative AI tutor\nor teacher, we directly inform students that this AI can answer up to 40% of\nquestions incorrectly. In a randomized controlled trial with 165 students,\nthose who engaged in targeted dialogue with the AI Peer achieved post-test\nscores that were, on average, 10.5 percentage points higher - with over 20\npercentage points higher normalized gain - than a control group that discussed\nphysics history. Qualitative feedback indicated that 91% of the treatment\ngroup's AI interactions were rated as helpful. Furthermore, by comparing\nstudent performance on pre- and post-test questions about the same concept,\nalong with experts' annotations of the AI interactions, we find initial\nevidence suggesting the improvement in performance does not depend on the\ncorrectness of the AI. With further research, the AI Peer paradigm described\nhere could open new possibilities for how we learn, adapt to, and grow with AI.",
      "tldr_zh": "这篇论文探讨了使用 AI Peer 来帮助学生克服牛顿力学概念的物理误区，强调 AI 的准确性并非完美，而是直接告知学生 AI 可能回答错误（高达40%）。研究通过随机对照试验（randomized controlled trial）涉及165名学生，发现与讨论物理历史控制组相比，实验组学生的后测成绩平均提高了10.5百分点，标准化增益超过20百分点。91%的实验组参与者认为AI互动有帮助，且分析显示成绩改善不依赖于AI的正确性。该方法为AI在教育中的新范式提供了潜力，推动学生独立批判性思考。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00408v1",
      "published_date": "2025-04-01 04:09:13 UTC",
      "updated_date": "2025-04-01 04:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:22.744014"
    },
    {
      "arxiv_id": "2504.00406v1",
      "title": "VerifiAgent: a Unified Verification Agent in Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuzhou Han",
        "Wray Buntine",
        "Ehsan Shareghi"
      ],
      "abstract": "Large language models demonstrate remarkable reasoning capabilities but often\nproduce unreliable or incorrect responses. Existing verification methods are\ntypically model-specific or domain-restricted, requiring significant\ncomputational resources and lacking scalability across diverse reasoning tasks.\nTo address these limitations, we propose VerifiAgent, a unified verification\nagent that integrates two levels of verification: meta-verification, which\nassesses completeness and consistency in model responses, and tool-based\nadaptive verification, where VerifiAgent autonomously selects appropriate\nverification tools based on the reasoning type, including mathematical,\nlogical, or commonsense reasoning. This adaptive approach ensures both\nefficiency and robustness across different verification scenarios. Experimental\nresults show that VerifiAgent outperforms baseline verification methods (e.g.,\ndeductive verifier, backward verifier) among all reasoning tasks. Additionally,\nit can further enhance reasoning accuracy by leveraging feedback from\nverification results. VerifiAgent can also be effectively applied to inference\nscaling, achieving better results with fewer generated samples and costs\ncompared to existing process reward models in the mathematical reasoning\ndomain. Code is available at https://github.com/Jiuzhouh/VerifiAgent",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）在推理任务中产生不可靠响应的难题，提出了一种统一的验证代理VerifiAgent，以提升模型的可靠性和可扩展性。VerifiAgent整合了两级验证机制：meta-verification用于评估响应完整性和一致性，以及tool-based adaptive verification，根据推理类型（如数学、逻辑或常识推理）自主选择合适的验证工具，确保高效和鲁棒性。实验结果显示，VerifiAgent在所有推理任务中优于基线方法（如deductive verifier和backward verifier），并通过验证反馈进一步提升推理准确性，同时在推理缩放方面实现了更低的样本和成本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00406v1",
      "published_date": "2025-04-01 04:05:03 UTC",
      "updated_date": "2025-04-01 04:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:34.565108"
    },
    {
      "arxiv_id": "2504.03735v1",
      "title": "Misaligned Roles, Misplaced Images: Structural Input Perturbations Expose Multimodal Alignment Blind Spots",
      "title_zh": "翻译失败",
      "authors": [
        "Erfan Shayegani",
        "G M Shahariar",
        "Sara Abdali",
        "Lei Yu",
        "Nael Abu-Ghazaleh",
        "Yue Dong"
      ],
      "abstract": "Multimodal Language Models (MMLMs) typically undergo post-training alignment\nto prevent harmful content generation. However, these alignment stages focus\nprimarily on the assistant role, leaving the user role unaligned, and stick to\na fixed input prompt structure of special tokens, leaving the model vulnerable\nwhen inputs deviate from these expectations. We introduce Role-Modality Attacks\n(RMA), a novel class of adversarial attacks that exploit role confusion between\nthe user and assistant and alter the position of the image token to elicit\nharmful outputs. Unlike existing attacks that modify query content, RMAs\nmanipulate the input structure without altering the query itself. We\nsystematically evaluate these attacks across multiple Vision Language Models\n(VLMs) on eight distinct settings, showing that they can be composed to create\nstronger adversarial prompts, as also evidenced by their increased projection\nin the negative refusal direction in the residual stream, a property observed\nin prior successful attacks. Finally, for mitigation, we propose an adversarial\ntraining approach that makes the model robust against input prompt\nperturbations. By training the model on a range of harmful and benign prompts\nall perturbed with different RMA settings, it loses its sensitivity to Role\nConfusion and Modality Manipulation attacks and is trained to only pay\nattention to the content of the query in the input prompt structure,\neffectively reducing Attack Success Rate (ASR) while preserving the model's\ngeneral utility.",
      "tldr_zh": "本研究揭示了多模态语言模型（MMLMs）的对齐盲点，即这些模型主要针对助手角色进行训练，而忽略用户角色和输入结构变化，导致易受攻击。作者引入了Role-Modality Attacks (RMA)，一种新型攻击方法，通过混淆用户与助手角色并调整图像标记位置来诱导有害输出，而不修改查询内容；在多个视觉语言模型（VLMs）上的实验显示，RMA能显著提升攻击强度，并在模型残差流中显示负面拒绝方向。最终，论文提出了一种对抗训练方法，通过在各种RMA设置下训练模型，使其对角色混淆和模式操纵不敏感，从而有效降低攻击成功率（ASR）并保持模型的整体性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03735v1",
      "published_date": "2025-04-01 03:54:36 UTC",
      "updated_date": "2025-04-01 03:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:46.887838"
    },
    {
      "arxiv_id": "2504.00401v1",
      "title": "Beyond Wide-Angle Images: Unsupervised Video Portrait Correction via Spatiotemporal Diffusion Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Nie",
        "Lang Nie",
        "Chunyu Lin",
        "Jingwen Chen",
        "Ke Xing",
        "Jiyuan Wang",
        "Yao Zhao"
      ],
      "abstract": "Wide-angle cameras, despite their popularity for content creation, suffer\nfrom distortion-induced facial stretching-especially at the edge of the\nlens-which degrades visual appeal. To address this issue, we propose an image\nportrait correction framework using diffusion models named ImagePD. It\nintegrates the long-range awareness of transformer and multi-step denoising of\ndiffusion models into a unified framework, achieving global structural\nrobustness and local detail refinement. Besides, considering the high cost of\nobtaining video labels, we then repurpose ImagePD for unlabeled wide-angle\nvideos (termed VideoPD), by spatiotemporal diffusion adaption with spatial\nconsistency and temporal smoothness constraints. For the former, we encourage\nthe denoised image to approximate pseudo labels following the wide-angle\ndistortion distribution pattern, while for the latter, we derive rectification\ntrajectories with backward optical flows and smooth them. Compared with\nImagePD, VideoPD maintains high-quality facial corrections in space and\nmitigates the potential temporal shakes sequentially. Finally, to establish an\nevaluation benchmark and train the framework, we establish a video portrait\ndataset with a large diversity in people number, lighting conditions, and\nbackground. Experiments demonstrate that the proposed methods outperform\nexisting solutions quantitatively and qualitatively, contributing to\nhigh-fidelity wide-angle videos with stable and natural portraits. The codes\nand dataset will be available.",
      "tldr_zh": "该研究针对宽角相机导致的边缘人脸扭曲问题，提出ImagePD框架，该框架整合Transformer的长距离感知和diffusion models的多步去噪机制，实现全局结构鲁棒性和局部细节优化。为了处理无标签视频，该框架扩展为VideoPD，通过spatiotemporal diffusion adaptation引入空间一致性和时间平滑约束，例如使用backward optical flows生成平滑校正轨迹。研究者建立了一个多样化视频人像数据集，并实验证明，VideoPD在定量和定性上优于现有方法，提供高保真且稳定的宽角视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00401v1",
      "published_date": "2025-04-01 03:49:59 UTC",
      "updated_date": "2025-04-01 03:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:35:59.019430"
    },
    {
      "arxiv_id": "2504.00389v1",
      "title": "CyberBOT: Towards Reliable Cybersecurity Education via Ontology-Grounded Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chengshuai Zhao",
        "Riccardo De Maria",
        "Tharindu Kumarage",
        "Kumar Satvik Chaudhary",
        "Garima Agrawal",
        "Yiwen Li",
        "Jongchan Park",
        "Yuli Deng",
        "Ying-Chih Chen",
        "Huan Liu"
      ],
      "abstract": "Advancements in large language models (LLMs) have enabled the development of\nintelligent educational tools that support inquiry-based learning across\ntechnical domains. In cybersecurity education, where accuracy and safety are\nparamount, systems must go beyond surface-level relevance to provide\ninformation that is both trustworthy and domain-appropriate. To address this\nchallenge, we introduce CyberBOT, a question-answering chatbot that leverages a\nretrieval-augmented generation (RAG) pipeline to incorporate contextual\ninformation from course-specific materials and validate responses using a\ndomain-specific cybersecurity ontology. The ontology serves as a structured\nreasoning layer that constrains and verifies LLM-generated answers, reducing\nthe risk of misleading or unsafe guidance. CyberBOT has been deployed in a\nlarge graduate-level course at Arizona State University (ASU), where more than\none hundred students actively engage with the system through a dedicated\nweb-based platform. Computational evaluations in lab environments highlight the\npotential capacity of CyberBOT, and a forthcoming field study will evaluate its\npedagogical impact. By integrating structured domain reasoning with modern\ngenerative capabilities, CyberBOT illustrates a promising direction for\ndeveloping reliable and curriculum-aligned AI applications in specialized\neducational contexts.",
      "tldr_zh": "这篇论文介绍了 CyberBOT，一种基于 Retrieval-Augmented Generation (RAG) 的问答聊天机器人，旨在提升网络安全教育的可靠性和准确性。CyberBOT 通过整合课程特定材料和一个领域特定的 cybersecurity ontology 来验证并约束 LLM 生成的回答，从而减少误导或不安全指导的风险。该系统已在亚利桑那州立大学的一个研究生课程中部署，吸引超过一百名学生互动，实验室评估显示了其潜力，并计划通过实地研究评估其教育影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00389v1",
      "published_date": "2025-04-01 03:19:22 UTC",
      "updated_date": "2025-04-01 03:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:36:10.835821"
    },
    {
      "arxiv_id": "2504.00374v1",
      "title": "When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)",
      "title_zh": "翻译失败",
      "authors": [
        "Mahak Agarwal",
        "Divyam Khanna"
      ],
      "abstract": "In many real-world scenarios, a single Large Language Model (LLM) may\nencounter contradictory claims-some accurate, others forcefully incorrect-and\nmust judge which is true. We investigate this risk in a single-turn,\nmulti-agent debate framework: one LLM-based agent provides a factual answer\nfrom TruthfulQA, another vigorously defends a falsehood, and the same LLM\narchitecture serves as judge. We introduce the Confidence-Weighted Persuasion\nOverride Rate (CW-POR), which captures not only how often the judge is deceived\nbut also how strongly it believes the incorrect choice. Our experiments on five\nopen-source LLMs (3B-14B parameters), where we systematically vary agent\nverbosity (30-300 words), reveal that even smaller models can craft persuasive\narguments that override truthful answers-often with high confidence. These\nfindings underscore the importance of robust calibration and adversarial\ntesting to prevent LLMs from confidently endorsing misinformation.",
      "tldr_zh": "该研究探讨了在多智能体 LLM 辩论中，说服力如何覆盖真实性，引入了 Confidence-Weighted Persuasion Override Rate (CW-POR) 指标来评估裁判 LLM 被误导的频率及其信心强度。实验框架涉及一个代理基于 TruthfulQA 提供真实答案，另一个代理辩护虚假信息，而同一 LLM 作为裁判；在五种开源 LLM（3B-14B 参数）上测试不同代理冗长度（30-300 词），结果显示即使较小模型也能通过说服性论点使裁判高信心地接受错误信息。研究强调了加强 LLM 的 robust calibration 和 adversarial testing，以防止其自信地支持错误信息。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.6"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00374v1",
      "published_date": "2025-04-01 02:45:02 UTC",
      "updated_date": "2025-04-01 02:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:36:22.605289"
    },
    {
      "arxiv_id": "2504.00356v1",
      "title": "Hybrid Global-Local Representation with Augmented Spatial Guidance for Zero-Shot Referring Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ting Liu",
        "Siyuan Li"
      ],
      "abstract": "Recent advances in zero-shot referring image segmentation (RIS), driven by\nmodels such as the Segment Anything Model (SAM) and CLIP, have made substantial\nprogress in aligning visual and textual information. Despite these successes,\nthe extraction of precise and high-quality mask region representations remains\na critical challenge, limiting the full potential of RIS tasks. In this paper,\nwe introduce a training-free, hybrid global-local feature extraction approach\nthat integrates detailed mask-specific features with contextual information\nfrom the surrounding area, enhancing mask region representation. To further\nstrengthen alignment between mask regions and referring expressions, we propose\na spatial guidance augmentation strategy that improves spatial coherence, which\nis essential for accurately localizing described areas. By incorporating\nmultiple spatial cues, this approach facilitates more robust and precise\nreferring segmentation. Extensive experiments on standard RIS benchmarks\ndemonstrate that our method significantly outperforms existing zero-shot RIS\nmodels, achieving substantial performance gains. We believe our approach\nadvances RIS tasks and establishes a versatile framework for region-text\nalignment, offering broader implications for cross-modal understanding and\ninteraction. Code is available at https://github.com/fhgyuanshen/HybridGL .",
      "tldr_zh": "该论文针对Zero-Shot Referring Image Segmentation (RIS)中的掩码区域表示挑战，提出了一种无训练的混合全局-局部特征提取方法，将详细的掩码特定特征与周围上下文信息相结合，提升了区域表示的精确性。\n为了加强掩码区域与引用表达的对齐，他们引入了空间引导增强策略，通过整合多个空间线索，提高了空间连贯性和定位准确性。\n实验结果显示，该方法在标准RIS基准上显著优于现有零样本模型，实现了实质性性能提升。\n这项工作为区域-文本对齐提供了通用的框架，具有更广泛的跨模态理解应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00356v1",
      "published_date": "2025-04-01 02:13:39 UTC",
      "updated_date": "2025-04-01 02:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:36:35.855506"
    },
    {
      "arxiv_id": "2504.03734v1",
      "title": "Artificial Geographically Weighted Neural Network: A Novel Framework for Spatial Analysis with Geographically Weighted Layers",
      "title_zh": "翻译失败",
      "authors": [
        "Jianfei Cao",
        "Dongchao Wang"
      ],
      "abstract": "Geographically Weighted Regression (GWR) is a widely recognized technique for\nmodeling spatial heterogeneity. However, it is commonly assumed that the\nrelationships between dependent and independent variables are linear. To\novercome this limitation, we propose an Artificial Geographically Weighted\nNeural Network (AGWNN), a novel framework that integrates geographically\nweighted techniques with neural networks to capture complex nonlinear spatial\nrelationships. Central to this framework is the Geographically Weighted Layer\n(GWL), a specialized component designed to encode spatial heterogeneity within\nthe neural network architecture. To rigorously evaluate the performance of\nAGWNN, we conducted comprehensive experiments using both simulated datasets and\nreal-world case studies. Our results demonstrate that AGWNN significantly\noutperforms traditional GWR and standard Artificial Neural Networks (ANNs) in\nterms of model fitting accuracy. Notably, AGWNN excels in modeling intricate\nnonlinear relationships and effectively identifies complex spatial\nheterogeneity patterns, offering a robust and versatile tool for advanced\nspatial analysis.",
      "tldr_zh": "该研究提出了一种新框架——Artificial Geographically Weighted Neural Network (AGWNN)，将Geographically Weighted Regression (GWR)技术与神经网络整合，以克服GWR在处理非线性空间关系时的局限性。AGWNN的核心组件是Geographically Weighted Layer (GWL)，用于在神经网络架构中编码空间异质性，从而捕捉复杂的空间模式。实验通过模拟数据集和真实案例研究表明，AGWNN在模型拟合准确性上显著优于传统GWR和标准Artificial Neural Networks (ANNs)。这一框架为高级空间分析提供了强大工具，能够有效识别非线性关系和空间异质性模式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03734v1",
      "published_date": "2025-04-01 01:48:46 UTC",
      "updated_date": "2025-04-01 01:48:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:36:47.698003"
    },
    {
      "arxiv_id": "2504.00341v1",
      "title": "Integrated LLM-Based Intrusion Detection with Secure Slicing xApp for Securing O-RAN-Enabled Wireless Network Deployments",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Moore",
        "Aly Sabri Abdalla",
        "Prabesh Khanal",
        "Vuk Marojevic"
      ],
      "abstract": "The Open Radio Access Network (O-RAN) architecture is reshaping\ntelecommunications by promoting openness, flexibility, and intelligent\nclosed-loop optimization. By decoupling hardware and software and enabling\nmulti-vendor deployments, O-RAN reduces costs, enhances performance, and allows\nrapid adaptation to new technologies. A key innovation is intelligent network\nslicing, which partitions networks into isolated slices tailored for specific\nuse cases or quality of service requirements. The RAN Intelligent Controller\nfurther optimizes resource allocation, ensuring efficient utilization and\nimproved service quality for user equipment (UEs). However, the modular and\ndynamic nature of O-RAN expands the threat surface, necessitating advanced\nsecurity measures to maintain network integrity, confidentiality, and\navailability. Intrusion detection systems have become essential for identifying\nand mitigating attacks. This research explores using large language models\n(LLMs) to generate security recommendations based on the temporal traffic\npatterns of connected UEs. The paper introduces an LLM-driven intrusion\ndetection framework and demonstrates its efficacy through experimental\ndeployments, comparing non fine-tuned and fine-tuned models for task-specific\naccuracy.",
      "tldr_zh": "该研究探讨了如何利用大型语言模型（LLMs）集成入侵检测系统和Secure Slicing xApp，以保护O-RAN启用的无线网络部署。论文强调O-RAN架构的开放性和灵活性（如网络切片和RAN Intelligent Controller的优化），但也指出其模块化特性增加了安全威胁，因此提出基于LLMs分析UE流量模式生成安全推荐的框架。通过实验验证，该框架在入侵检测任务中显著提升了准确率，尤其是在微调模型与非微调模型的比较中，展示了其在实时网络安全中的潜在应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "This article has been accepted for publication in the IEEE 2025\n  International Conference on Communications (ICC2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.00341v1",
      "published_date": "2025-04-01 01:45:07 UTC",
      "updated_date": "2025-04-01 01:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:36:58.674521"
    },
    {
      "arxiv_id": "2504.00339v1",
      "title": "VNJPTranslate: A comprehensive pipeline for Vietnamese-Japanese translation",
      "title_zh": "翻译失败",
      "authors": [
        "Hoang Hai Phan",
        "Nguyen Duc Minh Vu",
        "Nam Dang Phuong"
      ],
      "abstract": "Neural Machine Translation (NMT) driven by Transformer architectures has\nadvanced significantly, yet faces challenges with low-resource language pairs\nlike Vietnamese-Japanese (Vi-Ja). Issues include sparse parallel data and\nhandling linguistic/cultural nuances. Recent progress in Large Language Models\n(LLMs) with strong reasoning, often refined via Reinforcement Learning (RL),\nenables high-quality synthetic data generation. We introduce VNJPTranslate, a\npipeline designed to systematically address the Vi-Ja translation task. It\nfeatures a targeted data augmentation strategy using advanced LLMs with\nChain-of-Thought prompting for challenging segments identified via corpus\nanalysis. Subsequently, we employ efficient fine-tuning techniques (Unsloth\nwith QLoRA) on a capable, low-parameter autoregressive model (specifically, a\nfine-tuned version of the 1.8B parameter Sailor model, which is based on the\nQwen architecture) to create a practical and high-performing translation\nsystem. This integrated approach aims to improve Vi-Ja translation quality\nsignificantly over existing baselines.",
      "tldr_zh": "该论文提出了 VNJPTranslate，一种针对越南语-日语 (Vi-Ja) 翻译的全面管道，旨在解决 Neural Machine Translation (NMT) 在低资源语言对上的挑战，如稀疏平行数据和语言/文化细微差别。管道采用高级 Large Language Models (LLMs) 结合 Chain-of-Thought 提示进行针对性数据增强，针对语料分析中识别出的困难部分。随后，通过 Unsloth with QLoRA 技术对基于 Qwen 架构的 1.8B 参数 Sailor 模型进行高效微调。整体方法显著提升了 Vi-Ja 翻译质量，超越现有基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00339v1",
      "published_date": "2025-04-01 01:38:25 UTC",
      "updated_date": "2025-04-01 01:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:37:12.400139"
    },
    {
      "arxiv_id": "2504.00338v1",
      "title": "Agentic Multimodal AI for Hyperpersonalized B2B and B2C Advertising in Competitive Markets: An AI-Driven Competitive Advertising Framework",
      "title_zh": "代理式多模态AI用于竞争市场中的超个性化B2B和B2C广告：一个AI驱动的竞争广告框架",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Akash Das",
        "Shivam Gupta",
        "Venkataramana Runkana"
      ],
      "abstract": "The growing use of foundation models (FMs) in real-world applications demands\nadaptive, reliable, and efficient strategies for dynamic markets. In the\nchemical industry, AI-discovered materials drive innovation, but commercial\nsuccess hinges on market adoption, requiring FM-driven advertising frameworks\nthat operate in-the-wild. We present a multilingual, multimodal AI framework\nfor autonomous, hyper-personalized advertising in B2B and B2C markets. By\nintegrating retrieval-augmented generation (RAG), multimodal reasoning, and\nadaptive persona-based targeting, our system generates culturally relevant,\nmarket-aware ads tailored to shifting consumer behaviors and competition.\nValidation combines real-world product experiments with a Simulated Humanistic\nColony of Agents to model consumer personas, optimize strategies at scale, and\nensure privacy compliance. Synthetic experiments mirror real-world scenarios,\nenabling cost-effective testing of ad strategies without risky A/B tests.\nCombining structured retrieval-augmented reasoning with in-context learning\n(ICL), the framework boosts engagement, prevents market cannibalization, and\nmaximizes ROAS. This work bridges AI-driven innovation and market adoption,\nadvancing multimodal FM deployment for high-stakes decision-making in\ncommercial marketing.",
      "tldr_zh": "这篇论文提出了一种Agentic多模态AI框架，用于B2B和B2C市场的自主、超个性化广告，针对动态竞争环境中的化学工业等场景，以桥接AI创新与市场采用。框架整合了检索增强生成(RAG)、多模态推理和适应性基于角色的定位，生成文化相关、市场感知的广告，以适应消费者行为变化并优化策略。验证通过真实产品实验和模拟的人文代理群落(Simulated Humanistic Colony of Agents)进行，确保隐私合规并在合成实验中模拟真实场景。结果显示，该框架结合结构化RAG和in-context learning(ICL)，显著提升参与度、防止市场cannibalization，并最大化ROAS。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00338v1",
      "published_date": "2025-04-01 01:37:02 UTC",
      "updated_date": "2025-04-01 01:37:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:37:23.969911"
    },
    {
      "arxiv_id": "2504.00336v2",
      "title": "SeizureTransformer: Scaling U-Net with Transformer for Simultaneous Time-Step Level Seizure Detection from Long EEG Recordings",
      "title_zh": "翻译失败",
      "authors": [
        "Kerui Wu",
        "Ziyue Zhao",
        "Bülent Yener"
      ],
      "abstract": "Epilepsy is a common neurological disorder that affects around 65 million\npeople worldwide. Detecting seizures quickly and accurately is vital, given the\nprevalence and severity of the associated complications. Recently, deep\nlearning-based automated seizure detection methods have emerged as solutions;\nhowever, most existing methods require extensive post-processing and do not\neffectively handle the crucial long-range patterns in EEG data. In this work,\nwe propose SeizureTransformer, a simple model comprised of (i) a deep encoder\ncomprising 1D convolutions (ii) a residual CNN stack and a transformer encoder\nto embed previous output into high-level representation with contextual\ninformation, and (iii) streamlined decoder which converts these features into a\nsequence of probabilities, directly indicating the presence or absence of\nseizures at every time step. Extensive experiments on public and private EEG\nseizure detection datasets demonstrate that our model significantly outperforms\nexisting approaches (ranked in the first place in the 2025 \"seizure detection\nchallenge\" organized in the International Conference on Artificial Intelligence\nin Epilepsy and Other Neurological Disorders), underscoring its potential for\nreal-time, precise seizure detection.",
      "tldr_zh": "该研究针对癫痫检测的挑战，提出SeizureTransformer模型，该模型基于U-Net扩展并整合Transformer，旨在从长EEG记录中实时检测每个时间步的癫痫发作。模型包括深度1D卷积编码器、残差CNN堆栈和Transformer编码器来提取高水平上下文表示，以及一个简化的解码器直接输出癫痫概率序列，从而避免了传统方法的复杂后处理。实验结果显示，该模型在公共和私有EEG数据集上显著优于现有方法，并在2025年国际癫痫AI会议挑战赛中排名第一，展示了其在精确实时检测中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00336v2",
      "published_date": "2025-04-01 01:33:42 UTC",
      "updated_date": "2025-04-02 16:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:37:35.115028"
    },
    {
      "arxiv_id": "2504.03733v1",
      "title": "Artificial Intelligence and Deep Learning Algorithms for Epigenetic Sequence Analysis: A Review for Epigeneticists and AI Experts",
      "title_zh": "人工智能和深度学习算法用于表观遗传序列分析：针对表观遗传学家和 AI 专家的评论",
      "authors": [
        "Muhammad Tahir",
        "Mahboobeh Norouzi",
        "Shehroz S. Khan",
        "James R. Davie",
        "Soichiro Yamanaka",
        "Ahmed Ashraf"
      ],
      "abstract": "Epigenetics encompasses mechanisms that can alter the expression of genes\nwithout changing the underlying genetic sequence. The epigenetic regulation of\ngene expression is initiated and sustained by several mechanisms such as DNA\nmethylation, histone modifications, chromatin conformation, and non-coding RNA.\nThe changes in gene regulation and expression can manifest in the form of\nvarious diseases and disorders such as cancer and congenital deformities. Over\nthe last few decades, high throughput experimental approaches have been used to\nidentify and understand epigenetic changes, but these laboratory experimental\napproaches and biochemical processes are time-consuming and expensive. To\novercome these challenges, machine learning and artificial intelligence (AI)\napproaches have been extensively used for mapping epigenetic modifications to\ntheir phenotypic manifestations. In this paper we provide a narrative review of\npublished research on AI models trained on epigenomic data to address a variety\nof problems such as prediction of disease markers, gene expression, enhancer\npromoter interaction, and chromatin states. The purpose of this review is\ntwofold as it is addressed to both AI experts and epigeneticists. For AI\nresearchers, we provided a taxonomy of epigenetics research problems that can\nbenefit from an AI-based approach. For epigeneticists, given each of the above\nproblems we provide a list of candidate AI solutions in the literature. We have\nalso identified several gaps in the literature, research challenges, and\nrecommendations to address these challenges.",
      "tldr_zh": "本综述探讨了人工智能(AI)和深度学习算法在表观遗传(Epigenetics)序列分析中的应用，旨在帮助AI专家和表观遗传学家理解如何通过这些技术映射DNA甲基化、组蛋白修饰等机制与疾病表型的关系。论文回顾了现有研究，包括AI模型在预测疾病标记、基因表达、增强子启动子相互作用和染色质状态等方面的解决方案，并为AI专家提供了表观遗传学问题的分类系统。最终，论文识别了文献中的研究空白、挑战，并提出了针对性推荐，以推动该领域的进一步发展。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03733v1",
      "published_date": "2025-04-01 01:02:34 UTC",
      "updated_date": "2025-04-01 01:02:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:37:47.643026"
    },
    {
      "arxiv_id": "2504.00310v1",
      "title": "Detecting and Mitigating Bias in LLMs through Knowledge Graph-Augmented Training",
      "title_zh": "通过知识图增强训练检测和缓解 LLMs 中的偏差",
      "authors": [
        "Rajeev Kumar",
        "Harishankar Kumar",
        "Kumari Shalini"
      ],
      "abstract": "Large language models have revolutionized natural language processing with\ntheir surprising capability to understand and generate human-like text.\nHowever, many of these models inherit and further amplify the biases present in\ntheir training data, raising ethical and fairness concerns. The detection and\nmitigation of such biases are vital to ensuring that LLMs act responsibly and\nequitably across diverse domains. This work investigates Knowledge\nGraph-Augmented Training (KGAT) as a novel method to mitigate bias in LLM.\nUsing structured domain-specific knowledge from real-world knowledge graphs, we\nimprove the understanding of the model and reduce biased output. Public\ndatasets for bias assessment include Gender Shades, Bias in Bios, and FairFace,\nwhile metrics such as demographic parity and equal opportunity facilitate\nrigorous detection. We also performed targeted mitigation strategies to correct\nbiased associations, leading to a significant drop in biased output and\nimproved bias metrics. Equipped with real-world datasets and knowledge graphs,\nour framework is both scalable and effective, paving the way toward responsible\ndeployment in sensitive and high-stakes applications.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中存在的偏见问题，这些偏见源于训练数据，并可能放大伦理和公平性风险。作者提出Knowledge Graph-Augmented Training (KGAT)方法，利用结构化的领域特定Knowledge Graphs来增强模型理解，并减少偏见输出，通过数据集如Gender Shades、Bias in Bios和FairFace，以及指标如demographic parity和equal opportunity进行检测和评估。实验结果显示，KGAT显著降低了偏见关联，提升了偏见指标表现，使框架在敏感应用中更具可扩展性和可靠性，从而促进LLMs的负责任部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00310v1",
      "published_date": "2025-04-01 00:27:50 UTC",
      "updated_date": "2025-04-01 00:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:37:58.470490"
    },
    {
      "arxiv_id": "2504.00308v1",
      "title": "FedPaI: Achieving Extreme Sparsity in Federated Learning via Pruning at Initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Haonan Wang",
        "Zeli Liu",
        "Kajimusugura Hoshino",
        "Tuo Zhang",
        "John Paul Walters",
        "Stephen Crago"
      ],
      "abstract": "Federated Learning (FL) enables distributed training on edge devices but\nfaces significant challenges due to resource constraints in edge environments,\nimpacting both communication and computational efficiency. Existing iterative\npruning techniques improve communication efficiency but are limited by their\ncentralized design, which struggles with FL's decentralized and data-imbalanced\nnature, resulting in suboptimal sparsity levels. To address these issues, we\npropose FedPaI, a novel efficient FL framework that leverages Pruning at\nInitialization (PaI) to achieve extreme sparsity. FedPaI identifies optimal\nsparse connections at an early stage, maximizing model capacity and\nsignificantly reducing communication and computation overhead by fixing\nsparsity patterns at the start of training. To adapt to diverse hardware and\nsoftware environments, FedPaI supports both structured and unstructured\npruning. Additionally, we introduce personalized client-side pruning mechanisms\nfor improved learning capacity and sparsity-aware server-side aggregation for\nenhanced efficiency. Experimental results demonstrate that FedPaI consistently\noutperforms existing efficient FL that applies conventional iterative pruning\nwith significant leading in efficiency and model accuracy. For the first time,\nour proposed FedPaI achieves an extreme sparsity level of up to 98% without\ncompromising the model accuracy compared to unpruned baselines, even under\nchallenging non-IID settings. By employing our FedPaI with joint optimization\nof model learning capacity and sparsity, FL applications can benefit from\nfaster convergence and accelerate the training by 6.4 to 7.9 times.",
      "tldr_zh": "该研究提出FedPaI框架，通过在训练初始阶段进行Pruning at Initialization (PaI)，实现Federated Learning (FL)中的极端稀疏性，以解决资源约束、通信和计算效率问题。FedPaI在早期识别最佳稀疏连接，固定稀疏模式，支持结构化和非结构化修剪，并引入个性化客户端修剪机制和稀疏感知服务器聚合，适应FL的去中心化和数据不平衡特性。实验结果显示，FedPaI首次实现高达98%的极端稀疏性，同时在非IID设置下保持与未修剪基线相当的模型准确性，并加速训练6.4至7.9倍，显著优于现有迭代修剪方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00308v1",
      "published_date": "2025-04-01 00:24:34 UTC",
      "updated_date": "2025-04-01 00:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:38:11.334264"
    },
    {
      "arxiv_id": "2504.01995v2",
      "title": "Brains vs. Bytes: Evaluating LLM Proficiency in Olympiad Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Mahdavi",
        "Alireza Hashemi",
        "Majid Daliri",
        "Pegah Mohammadipour",
        "Alireza Farhadi",
        "Samira Malek",
        "Yekta Yazdanifard",
        "Amir Khasahmadi",
        "Vasant Honavar"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown impressive\nprogress in mathematical reasoning tasks. However, current evaluation\nbenchmarks predominantly focus on the accuracy of final answers, often\noverlooking the crucial logical rigor for mathematical problem solving. The\nclaim that state-of-the-art LLMs can solve Math Olympiad-level problems\nrequires closer examination. To explore this, we conducted both qualitative and\nquantitative human evaluations of proofs generated by LLMs, and developed a\nschema for automatically assessing their reasoning capabilities. Our study\nreveals that current LLMs fall significantly short of solving challenging\nOlympiad-level problems and frequently fail to distinguish correct mathematical\nreasoning from clearly flawed solutions. Our analyses demonstrate that the\noccasional correct final answers provided by LLMs often result from pattern\nrecognition or heuristic shortcuts rather than genuine mathematical reasoning.\nThese findings underscore the substantial gap between LLM performance and human\nexpertise in advanced mathematical reasoning and highlight the importance of\ndeveloping benchmarks that prioritize the soundness of the reasoning used to\narrive at an answer rather than the mere correctness of the final answers.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在奥林匹克数学问题上的表现，指出现有基准过度关注最终答案准确性，而忽略了逻辑严谨性。作者通过定性和定量的人类评估，以及开发一个自动评估推理能力的模式，检验了LLMs的数学推理能力。结果显示，当前LLMs在解决挑战性奥林匹克问题时表现欠佳，常将正确答案归因于模式识别或启发式捷径，而非真正的数学推理。这些发现突显了LLMs与人类专家在高级数学推理方面的巨大差距，并呼吁开发更注重推理严谨性的评估基准。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01995v2",
      "published_date": "2025-04-01 00:10:10 UTC",
      "updated_date": "2025-04-10 20:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:38:23.150124"
    },
    {
      "arxiv_id": "2504.00299v1",
      "title": "Collaborative LLM Numerical Reasoning with Local Data Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Min Zhang",
        "Yuzhe Lu",
        "Yun Zhou",
        "Panpan Xu",
        "Lin Lee Cheong",
        "Chang-Tien Lu",
        "Haozhu Wang"
      ],
      "abstract": "Numerical reasoning over documents, which demands both contextual\nunderstanding and logical inference, is challenging for low-capacity local\nmodels deployed on computation-constrained devices. Although such complex\nreasoning queries could be routed to powerful remote models like GPT-4,\nexposing local data raises significant data leakage concerns. Existing\nmitigation methods generate problem descriptions or examples for remote\nassistance. However, the inherent complexity of numerical reasoning hinders the\nlocal model from generating logically equivalent queries and accurately\ninferring answers with remote guidance. In this paper, we present a model\ncollaboration framework with two key innovations: (1) a context-aware synthesis\nstrategy that shifts the query domains while preserving logical consistency;\nand (2) a tool-based answer reconstruction approach that reuses the\nremote-generated problem-solving pattern with code snippets. Experimental\nresults demonstrate that our method achieves better reasoning accuracy than\nsolely using local models while providing stronger data protection than fully\nrelying on remote models. Furthermore, our method improves accuracy by 16.2% -\n43.6% while reducing data leakage by 2.3% - 44.6% compared to existing data\nprotection approaches.",
      "tldr_zh": "该论文提出了一种协作LLM框架，用于处理文档中的数值推理问题，同时保护本地数据安全。该框架包括两个关键创新：（1）上下文感知合成策略，通过改变查询领域来保持逻辑一致性；（2）基于工具的答案重建方法，利用远程模型生成的代码片段重用问题解决模式。实验结果显示，该方法比仅使用本地模型的准确性更高，且比完全依赖远程模型提供更强的数据保护；相比现有方法，它提高了16.2% - 43.6%的准确率，同时减少了2.3% - 44.6%的数据泄露。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00299v1",
      "published_date": "2025-04-01 00:02:25 UTC",
      "updated_date": "2025-04-01 00:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:38:34.852814"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T08:38:59.146524"
}