[
  {
    "arxiv_id": "2408.06527v2",
    "title": "Rethinking the Alignment of Psychotherapy Dialogue Generation with Motivational Interviewing Strategies",
    "authors": [
      "Xin Sun",
      "Xiao Tang",
      "Abdallah El Ali",
      "Zhuying Li",
      "Pengjie Ren",
      "Jan de Wit",
      "Jiahuan Pei",
      "Jos A. Bosch"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have shown promise in\ngenerating psychotherapeutic dialogues, particularly in the context of\nmotivational interviewing (MI). However, the inherent lack of transparency in\nLLM outputs presents significant challenges given the sensitive nature of\npsychotherapy. Applying MI strategies, a set of MI skills, to generate more\ncontrollable therapeutic-adherent conversations with explainability provides a\npossible solution. In this work, we explore the alignment of LLMs with MI\nstrategies by first prompting the LLMs to predict the appropriate strategies as\nreasoning and then utilizing these strategies to guide the subsequent dialogue\ngeneration. We seek to investigate whether such alignment leads to more\ncontrollable and explainable generations. Multiple experiments including\nautomatic and human evaluations are conducted to validate the effectiveness of\nMI strategies in aligning psychotherapy dialogue generation. Our findings\ndemonstrate the potential of LLMs in producing strategically aligned dialogues\nand suggest directions for practical applications in psychotherapeutic\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06527v2",
    "published_date": "2024-08-12 23:19:02 UTC",
    "updated_date": "2024-12-17 16:44:16 UTC"
  },
  {
    "arxiv_id": "2408.06512v1",
    "title": "Learned Ranking Function: From Short-term Behavior Predictions to Long-term User Satisfaction",
    "authors": [
      "Yi Wu",
      "Daryl Chang",
      "Jennifer She",
      "Zhe Zhao",
      "Li Wei",
      "Lukasz Heldt"
    ],
    "abstract": "We present the Learned Ranking Function (LRF), a system that takes short-term\nuser-item behavior predictions as input and outputs a slate of recommendations\nthat directly optimizes for long-term user satisfaction. Most previous work is\nbased on optimizing the hyperparameters of a heuristic function. We propose to\nmodel the problem directly as a slate optimization problem with the objective\nof maximizing long-term user satisfaction. We also develop a novel constraint\noptimization algorithm that stabilizes objective trade-offs for multi-objective\noptimization. We evaluate our approach with live experiments and describe its\ndeployment on YouTube.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "RecSys 24",
    "pdf_url": "http://arxiv.org/pdf/2408.06512v1",
    "published_date": "2024-08-12 22:02:39 UTC",
    "updated_date": "2024-08-12 22:02:39 UTC"
  },
  {
    "arxiv_id": "2408.06509v1",
    "title": "Fooling SHAP with Output Shuffling Attacks",
    "authors": [
      "Jun Yuan",
      "Aritra Dasgupta"
    ],
    "abstract": "Explainable AI~(XAI) methods such as SHAP can help discover feature\nattributions in black-box models. If the method reveals a significant\nattribution from a ``protected feature'' (e.g., gender, race) on the model\noutput, the model is considered unfair. However, adversarial attacks can\nsubvert the detection of XAI methods. Previous approaches to constructing such\nan adversarial model require access to underlying data distribution, which may\nnot be possible in many practical scenarios. We relax this constraint and\npropose a novel family of attacks, called shuffling attacks, that are\ndata-agnostic. The proposed attack strategies can adapt any trained machine\nlearning model to fool Shapley value-based explanations. We prove that Shapley\nvalues cannot detect shuffling attacks. However, algorithms that estimate\nShapley values, such as linear SHAP and SHAP, can detect these attacks with\nvarying degrees of effectiveness. We demonstrate the efficacy of the attack\nstrategies by comparing the performance of linear SHAP and SHAP using\nreal-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06509v1",
    "published_date": "2024-08-12 21:57:18 UTC",
    "updated_date": "2024-08-12 21:57:18 UTC"
  },
  {
    "arxiv_id": "2408.06507v1",
    "title": "Benchmarking tree species classification from proximally-sensed laser scanning data: introducing the FOR-species20K dataset",
    "authors": [
      "Stefano Puliti",
      "Emily R. Lines",
      "Jana Müllerová",
      "Julian Frey",
      "Zoe Schindler",
      "Adrian Straker",
      "Matthew J. Allen",
      "Lukas Winiwarter",
      "Nataliia Rehush",
      "Hristina Hristova",
      "Brent Murray",
      "Kim Calders",
      "Louise Terryn",
      "Nicholas Coops",
      "Bernhard Höfle",
      "Samuli Junttila",
      "Martin Krůček",
      "Grzegorz Krok",
      "Kamil Král",
      "Shaun R. Levick",
      "Linda Luck",
      "Azim Missarov",
      "Martin Mokroš",
      "Harry J. F. Owen",
      "Krzysztof Stereńczak",
      "Timo P. Pitkänen",
      "Nicola Puletti",
      "Ninni Saarinen",
      "Chris Hopkinson",
      "Chiara Torresan",
      "Enrico Tomelleri",
      "Hannah Weiser",
      "Rasmus Astrup"
    ],
    "abstract": "Proximally-sensed laser scanning offers significant potential for automated\nforest data capture, but challenges remain in automatically identifying tree\nspecies without additional ground data. Deep learning (DL) shows promise for\nautomation, yet progress is slowed by the lack of large, diverse, openly\navailable labeled datasets of single tree point clouds. This has impacted the\nrobustness of DL models and the ability to establish best practices for species\nclassification.\n  To overcome these challenges, the FOR-species20K benchmark dataset was\ncreated, comprising over 20,000 tree point clouds from 33 species, captured\nusing terrestrial (TLS), mobile (MLS), and drone laser scanning (ULS) across\nvarious European forests, with some data from other regions. This dataset\nenables the benchmarking of DL models for tree species classification,\nincluding both point cloud-based (PointNet++, MinkNet, MLP-Mixer, DGCNNs) and\nmulti-view image-based methods (SimpleView, DetailView, YOLOv5).\n  2D image-based models generally performed better (average OA = 0.77) than 3D\npoint cloud-based models (average OA = 0.72), with consistent results across\ndifferent scanning platforms and sensors. The top model, DetailView, was\nparticularly robust, handling data imbalances well and generalizing effectively\nacross tree sizes.\n  The FOR-species20K dataset, available at https://zenodo.org/records/13255198,\nis a key resource for developing and benchmarking DL models for tree species\nclassification using laser scanning data, providing a foundation for future\nadvancements in the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06507v1",
    "published_date": "2024-08-12 21:47:15 UTC",
    "updated_date": "2024-08-12 21:47:15 UTC"
  },
  {
    "arxiv_id": "2408.06503v2",
    "title": "Enhancing Heterogeneous Multi-Agent Cooperation in Decentralized MARL via GNN-driven Intrinsic Rewards",
    "authors": [
      "Jahir Sadik Monon",
      "Deeparghya Dutta Barua",
      "Md. Mosaddek Khan"
    ],
    "abstract": "Multi-agent Reinforcement Learning (MARL) is emerging as a key framework for\nvarious sequential decision-making and control tasks. Unlike their single-agent\ncounterparts, multi-agent systems necessitate successful cooperation among the\nagents. The deployment of these systems in real-world scenarios often requires\ndecentralized training, a diverse set of agents, and learning from infrequent\nenvironmental reward signals. These challenges become more pronounced under\npartial observability and the lack of prior knowledge about agent\nheterogeneity. While notable studies use intrinsic motivation (IM) to address\nreward sparsity or cooperation in decentralized settings, those dealing with\nheterogeneity typically assume centralized training, parameter sharing, and\nagent indexing. To overcome these limitations, we propose the CoHet algorithm,\nwhich utilizes a novel Graph Neural Network (GNN) based intrinsic motivation to\nfacilitate the learning of heterogeneous agent policies in decentralized\nsettings, under the challenges of partial observability and reward sparsity.\nEvaluation of CoHet in the Multi-agent Particle Environment (MPE) and\nVectorized Multi-Agent Simulator (VMAS) benchmarks demonstrates superior\nperformance compared to the state-of-the-art in a range of cooperative\nmulti-agent scenarios. Our research is supplemented by an analysis of the\nimpact of the agent dynamics model on the intrinsic motivation module, insights\ninto the performance of different CoHet variants, and its robustness to an\nincreasing number of heterogeneous agents.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO",
      "I.2.6; I.2.9; I.2.11"
    ],
    "primary_category": "cs.MA",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.06503v2",
    "published_date": "2024-08-12 21:38:40 UTC",
    "updated_date": "2024-10-15 02:18:35 UTC"
  },
  {
    "arxiv_id": "2408.06484v1",
    "title": "Cross-Lingual Conversational Speech Summarization with Large Language Models",
    "authors": [
      "Max Nelson",
      "Shannon Wotherspoon",
      "Francis Keith",
      "William Hartmann",
      "Matthew Snover"
    ],
    "abstract": "Cross-lingual conversational speech summarization is an important problem,\nbut suffers from a dearth of resources. While transcriptions exist for a number\nof languages, translated conversational speech is rare and datasets containing\nsummaries are non-existent. We build upon the existing Fisher and Callhome\nSpanish-English Speech Translation corpus by supplementing the translations\nwith summaries. The summaries are generated using GPT-4 from the reference\ntranslations and are treated as ground truth. The task is to generate similar\nsummaries in the presence of transcription and translation errors. We build a\nbaseline cascade-based system using open-source speech recognition and machine\ntranslation models. We test a range of LLMs for summarization and analyze the\nimpact of transcription and translation errors. Adapting the Mistral-7B model\nfor this task performs significantly better than off-the-shelf models and\nmatches the performance of GPT-4.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06484v1",
    "published_date": "2024-08-12 20:40:46 UTC",
    "updated_date": "2024-08-12 20:40:46 UTC"
  },
  {
    "arxiv_id": "2408.06458v2",
    "title": "Towards Autonomous Agents: Adaptive-planning, Reasoning, and Acting in Language Models",
    "authors": [
      "Abhishek Dutta",
      "Yen-Che Hsiao"
    ],
    "abstract": "We propose a novel in-context learning algorithm for building autonomous\ndecision-making language agents. The language agent continuously attempts to\nsolve the same task by self-correcting each time the task fails. Our selected\nlanguage agent demonstrates the ability to solve tasks in a text-based game\nenvironment. Our results show that the gemma-2-9b-it language model, using our\nproposed method, can successfully complete two of six tasks that failed in the\nfirst attempt. This highlights the effectiveness of our approach in enhancing\nthe problem-solving capabilities of a single language model through\nself-correction, paving the way for more advanced autonomous agents. The code\nis publicly available at\nhttps://github.com/YenCheHsiao/AutonomousLLMAgentwithAdaptingPlanning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06458v2",
    "published_date": "2024-08-12 19:18:05 UTC",
    "updated_date": "2024-11-04 21:04:31 UTC"
  },
  {
    "arxiv_id": "2408.06445v1",
    "title": "Multi-View Neural Differential Equations for Continuous-Time Stream Data in Long-Term Traffic Forecasting",
    "authors": [
      "Zibo Liu",
      "Zhe Jiang",
      "Shigang Chen"
    ],
    "abstract": "Long-term traffic flow forecasting plays a crucial role in intelligent\ntransportation as it allows traffic managers to adjust their decisions in\nadvance. However, the problem is challenging due to spatio-temporal\ncorrelations and complex dynamic patterns in continuous-time stream data.\nNeural Differential Equations (NDEs) are among the state-of-the-art methods for\nlearning continuous-time traffic dynamics. However, the traditional NDE models\nface issues in long-term traffic forecasting due to failures in capturing\ndelayed traffic patterns, dynamic edge (location-to-location correlation)\npatterns, and abrupt trend patterns. To fill this gap, we propose a new NDE\narchitecture called Multi-View Neural Differential Equations. Our model\ncaptures current states, delayed states, and trends in different state\nvariables (views) by learning latent multiple representations within Neural\nDifferential Equations. Extensive experiments conducted on several real-world\ntraffic datasets demonstrate that our proposed method outperforms the\nstate-of-the-art and achieves superior prediction accuracy for long-term\nforecasting and robustness with noisy or missing inputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06445v1",
    "published_date": "2024-08-12 18:49:02 UTC",
    "updated_date": "2024-08-12 18:49:02 UTC"
  },
  {
    "arxiv_id": "2408.06423v3",
    "title": "Evaluating LLMs on Entity Disambiguation in Tables",
    "authors": [
      "Federico Belotti",
      "Fabio Dadda",
      "Marco Cremaschi",
      "Roberto Avogadro",
      "Matteo Palmonari"
    ],
    "abstract": "Tables are crucial containers of information, but understanding their meaning\nmay be challenging. Over the years, there has been a surge in interest in\ndata-driven approaches based on deep learning that have increasingly been\ncombined with heuristic-based ones. In the last period, the advent of\n\\acf{llms} has led to a new category of approaches for table annotation.\nHowever, these approaches have not been consistently evaluated on a common\nground, making evaluation and comparison difficult. This work proposes an\nextensive evaluation of four STI SOTA approaches: Alligator (formerly s-elbat),\nDagobah, TURL, and TableLlama; the first two belong to the family of\nheuristic-based algorithms, while the others are respectively encoder-only and\ndecoder-only Large Language Models (LLMs). We also include in the evaluation\nboth GPT-4o and GPT-4o-mini, since they excel in various public benchmarks. The\nprimary objective is to measure the ability of these approaches to solve the\nentity disambiguation task with respect to both the performance achieved on a\ncommon-ground evaluation setting and the computational and cost requirements\ninvolved, with the ultimate aim of charting new research paths in the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 6 figures; fixed avg. accuracy-over-price plot for GPT\n  families, fixed typos in table referencing, added evaluation and inference\n  subsubsection",
    "pdf_url": "http://arxiv.org/pdf/2408.06423v3",
    "published_date": "2024-08-12 18:01:50 UTC",
    "updated_date": "2024-10-31 18:43:01 UTC"
  },
  {
    "arxiv_id": "2408.06335v1",
    "title": "LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification",
    "authors": [
      "Tanisha Khurana",
      "Kaushik Pillalamarri",
      "Vikram Pande",
      "Munindar Singh"
    ],
    "abstract": "This paper explores humor detection through a linguistic lens, prioritizing\nsyntactic, semantic, and contextual features over computational methods in\nNatural Language Processing. We categorize features into syntactic, semantic,\nand contextual dimensions, including lexicons, structural statistics, Word2Vec,\nWordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT\nembeddings and parallel hidden layers to capture sentence congruity. By\ncombining syntactic, semantic, and contextual features, we train Colbert for\nhumor detection. Feature engineering examines essential syntactic and semantic\nfeatures alongside BERT embeddings. SHAP interpretations and decision trees\nidentify influential features, revealing that a holistic approach improves\nhumor detection accuracy on unseen data. Integrating linguistic cues from\ndifferent dimensions enhances the model's ability to understand humor\ncomplexity beyond traditional computational methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06335v1",
    "published_date": "2024-08-12 17:52:11 UTC",
    "updated_date": "2024-08-12 17:52:11 UTC"
  },
  {
    "arxiv_id": "2408.06327v1",
    "title": "VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents",
    "authors": [
      "Xiao Liu",
      "Tianjie Zhang",
      "Yu Gu",
      "Iat Long Iong",
      "Yifan Xu",
      "Xixuan Song",
      "Shudan Zhang",
      "Hanyu Lai",
      "Xinyi Liu",
      "Hanlin Zhao",
      "Jiadai Sun",
      "Xinyue Yang",
      "Yu Yang",
      "Zehan Qi",
      "Shuntian Yao",
      "Xueqiao Sun",
      "Siyi Cheng",
      "Qinkai Zheng",
      "Hao Yu",
      "Hanchen Zhang",
      "Wenyi Hong",
      "Ming Ding",
      "Lihang Pan",
      "Xiaotao Gu",
      "Aohan Zeng",
      "Zhengxiao Du",
      "Chan Hee Song",
      "Yu Su",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "abstract": "Large Multimodal Models (LMMs) have ushered in a new era in artificial\nintelligence, merging capabilities in both language and vision to form highly\ncapable Visual Foundation Agents. These agents are postulated to excel across a\nmyriad of tasks, potentially approaching general artificial intelligence.\nHowever, existing benchmarks fail to sufficiently challenge or showcase the\nfull potential of LMMs in complex, real-world environments. To address this\ngap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering\nbenchmark specifically designed to train and evaluate LMMs as visual foundation\nagents across diverse scenarios, including Embodied, Graphical User Interface,\nand Visual Design, with tasks formulated to probe the depth of LMMs'\nunderstanding and interaction capabilities. Through rigorous testing across\nnine proprietary LMM APIs and eight open models, we demonstrate the\nconsiderable yet still developing agent capabilities of these models.\nAdditionally, VAB constructs a trajectory training set constructed through\nhybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and\nHuman Demonstrations, promoting substantial performance improvements in LMMs\nthrough behavior cloning. Our work not only aims to benchmark existing models\nbut also provides a solid foundation for future development into visual\nfoundation agents. Code, train \\& test data, and part of fine-tuned open LMMs\nare available at \\url{https://github.com/THUDM/VisualAgentBench}.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06327v1",
    "published_date": "2024-08-12 17:44:17 UTC",
    "updated_date": "2024-08-12 17:44:17 UTC"
  },
  {
    "arxiv_id": "2408.06318v1",
    "title": "Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example",
    "authors": [
      "Yanan Chen",
      "Ali Pesaranghader",
      "Tanmana Sadhu",
      "Dong Hoon Yi"
    ],
    "abstract": "Large language models (LLMs) have brought autonomous agents closer to\nartificial general intelligence (AGI) due to their promising generalization and\nemergent capabilities. There is, however, a lack of studies on how LLM-based\nagents behave, why they could potentially fail, and how to improve them,\nparticularly in demanding real-world planning tasks. In this paper, as an\neffort to fill the gap, we present our study using a realistic benchmark,\nTravelPlanner, where an agent must meet multiple constraints to generate\naccurate plans. We leverage this benchmark to address four key research\nquestions: (1) are LLM agents robust enough to lengthy and noisy contexts when\nit comes to reasoning and planning? (2) can few-shot prompting adversely impact\nthe performance of LLM agents in scenarios with long context? (3) can we rely\non refinement to improve plans, and (4) can fine-tuning LLMs with both positive\nand negative feedback lead to further improvement? Our comprehensive\nexperiments indicate that, firstly, LLMs often fail to attend to crucial parts\nof a long context, despite their ability to handle extensive reference\ninformation and few-shot examples; secondly, they still struggle with analyzing\nthe long plans and cannot provide accurate feedback for refinement; thirdly, we\npropose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and\nnegative feedback, resulting in substantial gains over Supervised Fine-Tuning\n(SFT). Our findings offer in-depth insights to the community on various aspects\nrelated to real-world planning applications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.06318v1",
    "published_date": "2024-08-12 17:39:01 UTC",
    "updated_date": "2024-08-12 17:39:01 UTC"
  },
  {
    "arxiv_id": "2408.06316v1",
    "title": "Body Transformer: Leveraging Robot Embodiment for Policy Learning",
    "authors": [
      "Carmelo Sferrazza",
      "Dun-Ming Huang",
      "Fangchen Liu",
      "Jongmin Lee",
      "Pieter Abbeel"
    ],
    "abstract": "In recent years, the transformer architecture has become the de facto\nstandard for machine learning algorithms applied to natural language processing\nand computer vision. Despite notable evidence of successful deployment of this\narchitecture in the context of robot learning, we claim that vanilla\ntransformers do not fully exploit the structure of the robot learning problem.\nTherefore, we propose Body Transformer (BoT), an architecture that leverages\nthe robot embodiment by providing an inductive bias that guides the learning\nprocess. We represent the robot body as a graph of sensors and actuators, and\nrely on masked attention to pool information throughout the architecture. The\nresulting architecture outperforms the vanilla transformer, as well as the\nclassical multilayer perceptron, in terms of task completion, scaling\nproperties, and computational efficiency when representing either imitation or\nreinforcement learning policies. Additional material including the open-source\ncode is available at https://sferrazza.cc/bot_site.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06316v1",
    "published_date": "2024-08-12 17:31:28 UTC",
    "updated_date": "2024-08-12 17:31:28 UTC"
  },
  {
    "arxiv_id": "2408.06310v2",
    "title": "OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment",
    "authors": [
      "Sevinj Teymurova",
      "Ernesto Jiménez-Ruiz",
      "Tillman Weyde",
      "Jiaoyan Chen"
    ],
    "abstract": "Ontology alignment is integral to achieving semantic interoperability as the\nnumber of available ontologies covering intersecting domains is increasing.\nThis paper proposes OWL2Vec4OA, an extension of the ontology embedding system\nOWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontology\nembedding, it currently lacks a mechanism to tailor the embedding to the\nontology alignment task. OWL2Vec4OA incorporates edge confidence values from\nseed mappings to guide the random walk strategy. We present the theoretical\nfoundations, implementation details, and experimental evaluation of our\nproposed extension, demonstrating its potential effectiveness for ontology\nalignment tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 6th Knowledge Graph and Semantic Web Conference",
    "pdf_url": "http://arxiv.org/pdf/2408.06310v2",
    "published_date": "2024-08-12 17:24:19 UTC",
    "updated_date": "2024-10-23 09:59:15 UTC"
  },
  {
    "arxiv_id": "2408.06292v3",
    "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
    "authors": [
      "Chris Lu",
      "Cong Lu",
      "Robert Tjarko Lange",
      "Jakob Foerster",
      "Jeff Clune",
      "David Ha"
    ],
    "abstract": "One of the grand challenges of artificial general intelligence is developing\nagents capable of conducting scientific research and discovering new knowledge.\nWhile frontier models have already been used as aides to human scientists, e.g.\nfor brainstorming ideas, writing code, or prediction tasks, they still conduct\nonly a small part of the scientific process. This paper presents the first\ncomprehensive framework for fully automatic scientific discovery, enabling\nfrontier large language models to perform research independently and\ncommunicate their findings. We introduce The AI Scientist, which generates\nnovel research ideas, writes code, executes experiments, visualizes results,\ndescribes its findings by writing a full scientific paper, and then runs a\nsimulated review process for evaluation. In principle, this process can be\nrepeated to iteratively develop ideas in an open-ended fashion, acting like the\nhuman scientific community. We demonstrate its versatility by applying it to\nthree distinct subfields of machine learning: diffusion modeling,\ntransformer-based language modeling, and learning dynamics. Each idea is\nimplemented and developed into a full paper at a cost of less than $15 per\npaper. To evaluate the generated papers, we design and validate an automated\nreviewer, which we show achieves near-human performance in evaluating paper\nscores. The AI Scientist can produce papers that exceed the acceptance\nthreshold at a top machine learning conference as judged by our automated\nreviewer. This approach signifies the beginning of a new era in scientific\ndiscovery in machine learning: bringing the transformative benefits of AI\nagents to the entire research process of AI itself, and taking us closer to a\nworld where endless affordable creativity and innovation can be unleashed on\nthe world's most challenging problems. Our code is open-sourced at\nhttps://github.com/SakanaAI/AI-Scientist",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06292v3",
    "published_date": "2024-08-12 16:58:11 UTC",
    "updated_date": "2024-09-01 00:41:18 UTC"
  },
  {
    "arxiv_id": "2408.06285v1",
    "title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM",
    "authors": [
      "Trisha Das",
      "Dina Albassam",
      "Jimeng Sun"
    ],
    "abstract": "Medical dialogue systems (MDS) enhance patient-physician communication,\nimprove healthcare accessibility, and reduce costs. However, acquiring suitable\ndata to train these systems poses significant challenges. Privacy concerns\nprevent the use of real conversations, necessitating synthetic alternatives.\nSynthetic dialogue generation from publicly available clinical notes offers a\npromising solution to this issue, providing realistic data while safeguarding\nprivacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot\nprompting and a feedback loop to generate and refine high-quality synthetic\ndialogues. The feedback consists of weighted evaluation scores for similarity\nand extractiveness. The iterative process ensures dialogues meet predefined\nthresholds, achieving superior extractiveness as a result of the feedback loop.\nAdditionally, evaluation shows that the generated dialogues excel in factuality\nmetric compared to the baselines and has comparable diversity scores with GPT4.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06285v1",
    "published_date": "2024-08-12 16:49:22 UTC",
    "updated_date": "2024-08-12 16:49:22 UTC"
  },
  {
    "arxiv_id": "2408.06281v1",
    "title": "MovieSum: An Abstractive Summarization Dataset for Movie Screenplays",
    "authors": [
      "Rohit Saxena",
      "Frank Keller"
    ],
    "abstract": "Movie screenplay summarization is challenging, as it requires an\nunderstanding of long input contexts and various elements unique to movies.\nLarge language models have shown significant advancements in document\nsummarization, but they often struggle with processing long input contexts.\nFurthermore, while television transcripts have received attention in recent\nstudies, movie screenplay summarization remains underexplored. To stimulate\nresearch in this area, we present a new dataset, MovieSum, for abstractive\nsummarization of movie screenplays. This dataset comprises 2200 movie\nscreenplays accompanied by their Wikipedia plot summaries. We manually\nformatted the movie screenplays to represent their structural elements.\nCompared to existing datasets, MovieSum possesses several distinctive features:\n(1) It includes movie screenplays, which are longer than scripts of TV\nepisodes. (2) It is twice the size of previous movie screenplay datasets. (3)\nIt provides metadata with IMDb IDs to facilitate access to additional external\nknowledge. We also show the results of recently released large language models\napplied to summarization on our dataset to provide a detailed baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2408.06281v1",
    "published_date": "2024-08-12 16:43:09 UTC",
    "updated_date": "2024-08-12 16:43:09 UTC"
  },
  {
    "arxiv_id": "2408.06266v5",
    "title": "Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment",
    "authors": [
      "Karel D'Oosterlinck",
      "Winnie Xu",
      "Chris Develder",
      "Thomas Demeester",
      "Amanpreet Singh",
      "Christopher Potts",
      "Douwe Kiela",
      "Shikib Mehri"
    ],
    "abstract": "Large Language Models (LLMs) are often aligned using contrastive alignment\nobjectives and preference pair datasets. The interaction between model, paired\ndata, and objective makes alignment a complicated procedure, sometimes\nproducing subpar results. We study this and find that (i) preference data gives\na better learning signal when the underlying responses are contrastive, and\n(ii) alignment objectives lead to better performance when they specify more\ncontrol over the model during training. Based on these insights, we introduce\nContrastive Learning from AI Revisions (CLAIR), a data-creation method which\nleads to more contrastive preference pairs, and Anchored Preference\nOptimization (APO), a controllable and more stable alignment objective. We\nalign Llama-3-8B-Instruct using various comparable datasets and alignment\nobjectives and measure MixEval-Hard scores, which correlate highly with human\njudgments. The CLAIR preferences lead to the strongest performance out of all\ndatasets, and APO consistently outperforms less controllable objectives. Our\nbest model, trained on 32K CLAIR preferences with APO, improves\nLlama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code\nis available at https://github.com/ContextualAI/CLAIR_and_APO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06266v5",
    "published_date": "2024-08-12 16:24:51 UTC",
    "updated_date": "2024-09-14 23:09:07 UTC"
  },
  {
    "arxiv_id": "2408.06264v1",
    "title": "Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance",
    "authors": [
      "Manuel Milling",
      "Shuo Liu",
      "Andreas Triantafyllopoulos",
      "Ilhan Aslan",
      "Björn W. Schuller"
    ],
    "abstract": "Neural network models for audio tasks, such as automatic speech recognition\n(ASR) and acoustic scene classification (ASC), are susceptible to noise\ncontamination for real-life applications. To improve audio quality, an\nenhancement module, which can be developed independently, is explicitly used at\nthe front-end of the target audio applications. In this paper, we present an\nend-to-end learning solution to jointly optimise the models for audio\nenhancement (AE) and the subsequent applications. To guide the optimisation of\nthe AE module towards a target application, and especially to overcome\ndifficult samples, we make use of the sample-wise performance measure as an\nindication of sample importance. In experiments, we consider four\nrepresentative applications to evaluate our training paradigm, i.e., ASR,\nspeech command recognition (SCR), speech emotion recognition (SER), and ASC.\nThese applications are associated with speech and non-speech tasks concerning\nsemantic and non-semantic features, transient and global information, and the\nexperimental results indicate that our proposed approach can considerably boost\nthe noise robustness of the models, especially at low signal-to-noise ratios\n(SNRs), for a wide range of computer audition tasks in everyday-life noisy\nenvironments.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06264v1",
    "published_date": "2024-08-12 16:23:58 UTC",
    "updated_date": "2024-08-12 16:23:58 UTC"
  },
  {
    "arxiv_id": "2408.06261v3",
    "title": "Open-Source Molecular Processing Pipeline for Generating Molecules",
    "authors": [
      "V Shreyas",
      "Jose Siguenza",
      "Karan Bania",
      "Bharath Ramsundar"
    ],
    "abstract": "Generative models for molecules have shown considerable promise for use in\ncomputational chemistry, but remain difficult to use for non-experts. For this\nreason, we introduce open-source infrastructure for easily building generative\nmolecular models into the widely used DeepChem [Ramsundar et al., 2019] library\nwith the aim of creating a robust and reusable molecular generation pipeline.\nIn particular, we add high quality PyTorch [Paszke et al., 2019]\nimplementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao\nand Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our\nimplementations show strong performance comparable with past work [Kuznetsov\nand Polykovskiy, 2021, Cao and Kipf, 2022].",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the Molecular Machine Learning Conference 2024 (MoML\n  2024), BayLearn 2024 and the Machine Learning and Physical Sciences (ML4PS)\n  Workshop at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06261v3",
    "published_date": "2024-08-12 16:21:29 UTC",
    "updated_date": "2024-11-28 20:40:53 UTC"
  },
  {
    "arxiv_id": "2408.06257v3",
    "title": "Reciprocal Learning",
    "authors": [
      "Julian Rodemann",
      "Christoph Jansen",
      "Georg Schollmeyer"
    ],
    "abstract": "We demonstrate that a wide array of machine learning algorithms are specific\ninstances of one single paradigm: reciprocal learning. These instances range\nfrom active learning over multi-armed bandits to self-training. We show that\nall these algorithms do not only learn parameters from data but also vice\nversa: They iteratively alter training data in a way that depends on the\ncurrent model fit. We introduce reciprocal learning as a generalization of\nthese algorithms using the language of decision theory. This allows us to study\nunder what conditions they converge. The key is to guarantee that reciprocal\nlearning contracts such that the Banach fixed-point theorem applies. In this\nway, we find that reciprocal learning algorithms converge at linear rates to an\napproximately optimal model under relatively mild assumptions on the loss\nfunction, if their predictions are probabilistic and the sample adaption is\nboth non-greedy and either randomized or regularized. We interpret these\nfindings and provide corollaries that relate them to specific active learning,\nself-training, and bandit algorithms.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T37, 68T05, 68W25"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted at NeurIPS 2024. v2: fixed typos, added future work. v3:\n  changed def. 4 and proof of thm. 4, added illustrations",
    "pdf_url": "http://arxiv.org/pdf/2408.06257v3",
    "published_date": "2024-08-12 16:14:52 UTC",
    "updated_date": "2024-11-01 20:48:15 UTC"
  },
  {
    "arxiv_id": "2408.06240v4",
    "title": "Decentralized Health Intelligence Network (DHIN)",
    "authors": [
      "Abraham Nash"
    ],
    "abstract": "Decentralized Health Intelligence Network (DHIN) extends the Decentralized\nIntelligence Network (DIN) framework to address challenges in healthcare data\nsovereignty and AI utilization. Building upon DIN's core principles, DHIN\nintroduces healthcare-specific components to tackle data fragmentation across\nproviders and institutions, establishing a sovereign architecture for\nhealthcare provision. It facilitates effective AI utilization by overcoming\nbarriers to accessing diverse health data sources. This comprehensive framework\nleverages: 1) self-sovereign identity architecture coupled with a personal\nhealth record (PHR), extending DIN's personal data stores concept to ensure\nhealth data sovereignty; 2) a scalable federated learning (FL) protocol\nimplemented on a public blockchain for decentralized AI training in healthcare,\ntailored for medical data; and 3) a scalable, trustless rewards mechanism\nadapted from DIN to incentivize participation in healthcare AI development.\nDHIN operates on a public blockchain with an immutable record, ensuring that no\nentity can control access to health data or determine financial benefits. It\nsupports effective AI training while allowing patients to maintain control over\ntheir health data, benefit financially, and contribute to a decentralized\necosystem. Unique to DHIN, patients receive rewards in digital wallets as an\nincentive to opt into the FL protocol, with a long-term roadmap to fund\ndecentralized insurance solutions. This approach introduces a novel,\nself-financed healthcare model that adapts to individual needs, complements\nexisting systems, and redefines universal coverage, showcasing how DIN\nprinciples can transform healthcare data management and AI utilization while\nempowering patients.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.06240v4",
    "published_date": "2024-08-12 15:47:26 UTC",
    "updated_date": "2024-09-04 17:57:39 UTC"
  },
  {
    "arxiv_id": "2408.06227v1",
    "title": "FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks",
    "authors": [
      "Min Ma",
      "Yuma Koizumi",
      "Shigeki Karita",
      "Heiga Zen",
      "Jason Riesa",
      "Haruko Ishikawa",
      "Michiel Bacchiani"
    ],
    "abstract": "This paper introduces FLEURS-R, a speech restoration applied version of the\nFew-shot Learning Evaluation of Universal Representations of Speech (FLEURS)\ncorpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages as\nFLEURS, with improved audio quality and fidelity by applying the speech\nrestoration model Miipher. The aim of FLEURS-R is to advance speech technology\nin more languages and catalyze research including text-to-speech (TTS) and\nother speech generation tasks in low-resource languages. Comprehensive\nevaluations with the restored speech and TTS baseline models trained from the\nnew corpus show that the new corpus obtained significantly improved speech\nquality while maintaining the semantic contents of the speech. The corpus is\npublicly released via Hugging Face.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06227v1",
    "published_date": "2024-08-12 15:28:51 UTC",
    "updated_date": "2024-08-12 15:28:51 UTC"
  },
  {
    "arxiv_id": "2408.06226v2",
    "title": "A Large-Scale Study of Model Integration in ML-Enabled Software Systems",
    "authors": [
      "Yorick Sens",
      "Henriette Knopp",
      "Sven Peldszus",
      "Thorsten Berger"
    ],
    "abstract": "The rise of machine learning (ML) and its integration into software systems\nhas drastically changed development practices. While software engineering\ntraditionally focused on manually created code artifacts with dedicated\nprocesses and architectures, ML-enabled systems require additional data-science\nmethods and tools to create ML artifacts -- especially ML models and training\ndata. However, integrating models into systems, and managing the many different\nartifacts involved, is far from trivial. ML-enabled systems can easily have\nmultiple ML models that interact with each other and with traditional code in\nintricate ways. Unfortunately, while challenges and practices of building\nML-enabled systems have been studied, little is known about the characteristics\nof real-world ML-enabled systems beyond isolated examples. Improving\nengineering processes and architectures for ML-enabled systems requires\nimproving the empirical understanding of these systems. We present a\nlarge-scale study of 2,928 open-source ML-enabled software systems. We\nclassified and analyzed them to determine system characteristics, model and\ncode reuse practices, and architectural aspects of integrating ML models. Our\nfindings show that these systems still mainly consist of traditional source\ncode, and that ML model reuse through code duplication or pre-trained models is\ncommon. We also identified different ML integration patterns and related\nimplementation practices. We hope that our results help improve practices for\nintegrating ML models, bringing data science and software engineering closer\ntogether.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at International Conference on Software Engineering (ICSE)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2408.06226v2",
    "published_date": "2024-08-12 15:28:40 UTC",
    "updated_date": "2025-02-24 15:02:27 UTC"
  },
  {
    "arxiv_id": "2408.06223v3",
    "title": "On Effects of Steering Latent Representation for Large Language Model Unlearning",
    "authors": [
      "Dang Huu-Tien",
      "Trung-Tin Pham",
      "Hoang Thanh-Tung",
      "Naoya Inoue"
    ],
    "abstract": "Representation Misdirection for Unlearning (RMU), which steers model\nrepresentation in the intermediate layer to a target random representation, is\nan effective method for large language model (LLM) unlearning. Despite its high\nperformance, the underlying cause and explanation remain underexplored. In this\npaper, we theoretically demonstrate that steering forget representations in the\nintermediate layer reduces token confidence, causing LLMs to generate wrong or\nnonsense responses. We investigate how the coefficient influences the alignment\nof forget-sample representations with the random direction and hint at the\noptimal coefficient values for effective unlearning across different network\nlayers. We show that RMU unlearned models are robust against adversarial\njailbreak attacks. Furthermore, our empirical analysis shows that RMU is less\neffective when applied to the middle and later layers in LLMs. To resolve this\ndrawback, we propose Adaptive RMU--a simple yet effective alternative method\nthat makes unlearning effective with most layers. Extensive experiments\ndemonstrate that Adaptive RMU significantly improves the unlearning performance\ncompared to prior art while incurring no additional computational cost.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AAAI-25 Main Technical Track",
    "pdf_url": "http://arxiv.org/pdf/2408.06223v3",
    "published_date": "2024-08-12 15:24:50 UTC",
    "updated_date": "2025-02-06 02:25:18 UTC"
  },
  {
    "arxiv_id": "2408.07100v1",
    "title": "Pattern-Matching Dynamic Memory Network for Dual-Mode Traffic Prediction",
    "authors": [
      "Wenchao Weng",
      "Mei Wu",
      "Hanyu Jiang",
      "Wanzeng Kong",
      "Xiangjie Kong",
      "Feng Xia"
    ],
    "abstract": "In recent years, deep learning has increasingly gained attention in the field\nof traffic prediction. Existing traffic prediction models often rely on GCNs or\nattention mechanisms with O(N^2) complexity to dynamically extract traffic node\nfeatures, which lack efficiency and are not lightweight. Additionally, these\nmodels typically only utilize historical data for prediction, without\nconsidering the impact of the target information on the prediction. To address\nthese issues, we propose a Pattern-Matching Dynamic Memory Network (PM-DMNet).\nPM-DMNet employs a novel dynamic memory network to capture traffic pattern\nfeatures with only O(N) complexity, significantly reducing computational\noverhead while achieving excellent performance. The PM-DMNet also introduces\ntwo prediction methods: Recursive Multi-step Prediction (RMP) and Parallel\nMulti-step Prediction (PMP), which leverage the time features of the prediction\ntargets to assist in the forecasting process. Furthermore, a transfer attention\nmechanism is integrated into PMP, transforming historical data features to\nbetter align with the predicted target states, thereby capturing trend changes\nmore accurately and reducing errors. Extensive experiments demonstrate the\nsuperiority of the proposed model over existing benchmarks. The source codes\nare available at: https://github.com/wengwenchao123/PM-DMNet.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07100v1",
    "published_date": "2024-08-12 15:12:30 UTC",
    "updated_date": "2024-08-12 15:12:30 UTC"
  },
  {
    "arxiv_id": "2408.06202v2",
    "title": "Strategy Game-Playing with Size-Constrained State Abstraction",
    "authors": [
      "Linjie Xu",
      "Diego Perez-Liebana",
      "Alexander Dockhorn"
    ],
    "abstract": "Playing strategy games is a challenging problem for artificial intelligence\n(AI). One of the major challenges is the large search space due to a diverse\nset of game components. In recent works, state abstraction has been applied to\nsearch-based game AI and has brought significant performance improvements.\nState abstraction techniques rely on reducing the search space, e.g., by\naggregating similar states. However, the application of these abstractions is\nhindered because the quality of an abstraction is difficult to evaluate.\nPrevious works hence abandon the abstraction in the middle of the search to not\nbias the search to a local optimum. This mechanism introduces a hyper-parameter\nto decide the time to abandon the current state abstraction. In this work, we\npropose a size-constrained state abstraction (SCSA), an approach that limits\nthe maximum number of nodes being grouped together. We found that with SCSA,\nthe abstraction is not required to be abandoned. Our empirical results on $3$\nstrategy games show that the SCSA agent outperforms the previous methods and\nyields robust performance over different games. Codes are open-sourced at\nhttps://github.com/GAIGResearch/Stratega.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, published in Proceedings of the Conference on Games 2024,\n  codes are open-sourced at https://github.com/GAIGResearch/Stratega",
    "pdf_url": "http://arxiv.org/pdf/2408.06202v2",
    "published_date": "2024-08-12 14:50:18 UTC",
    "updated_date": "2025-02-15 11:10:48 UTC"
  },
  {
    "arxiv_id": "2408.06199v1",
    "title": "Dynamic Blocked Clause Elimination for Projected Model Counting",
    "authors": [
      "Jean-Marie Lagniez",
      "Pierre Marquis",
      "Armin Biere"
    ],
    "abstract": "In this paper, we explore the application of blocked clause elimination for\nprojected model counting. This is the problem of determining the number of\nmodels ||\\exists X.{\\Sigma}|| of a propositional formula {\\Sigma} after\neliminating a given set X of variables existentially. Although blocked clause\nelimination is a well-known technique for SAT solving, its direct application\nto model counting is challenging as in general it changes the number of models.\nHowever, we demonstrate, by focusing on projected variables during the blocked\nclause search, that blocked clause elimination can be leveraged while\npreserving the correct model count. To take advantage of blocked clause\nelimination in an efficient way during model counting, a novel data structure\nand associated algorithms are introduced. Our proposed approach is implemented\nin the model counter d4. Our experiments demonstrate the computational benefits\nof our new method of blocked clause elimination for projected model counting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "LIPIcs, Volume 305, SAT 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06199v1",
    "published_date": "2024-08-12 14:49:12 UTC",
    "updated_date": "2024-08-12 14:49:12 UTC"
  },
  {
    "arxiv_id": "2408.15268v3",
    "title": "Anomaly Detection in Time Series of EDFA Pump Currents to Monitor Degeneration Processes using Fuzzy Clustering",
    "authors": [
      "Dominic Schneider",
      "Lutz Rapp",
      "Christoph Ament"
    ],
    "abstract": "This article proposes a novel fuzzy clustering based anomaly detection method\nfor pump current time series of EDFA systems. The proposed change detection\nframework (CDF) strategically combines the advantages of entropy analysis (EA)\nand principle component analysis (PCA) with fuzzy clustering procedures. In the\nframework, EA is applied for dynamic selection of features for reduction of the\nfeature space and increase of computational performance. Furthermore, PCA is\nutilized to extract features from the raw feature space to enable\ngeneralization capability of the subsequent fuzzy clustering procedures. Three\ndifferent fuzzy clustering methods, more precisely the fuzzy clustering\nalgorithm, a probabilistic clustering algorithm and a possibilistic clustering\nalgorithm are evaluated for performance and generalization. Hence, the proposed\nframework has the innovative feature to detect changes in pump current time\nseries at an early stage for arbitrary points of operation, compared to\nstate-of-the-art predefined alarms in commercially used EDFAs. Moreover, the\napproach is implemented and tested using experimental data. In addition, the\nproposed framework enables further approaches of applying decentralized\npredictive maintenance for optical fiber networks.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.15268v3",
    "published_date": "2024-08-12 14:23:42 UTC",
    "updated_date": "2025-04-29 12:14:08 UTC"
  },
  {
    "arxiv_id": "2408.08328v1",
    "title": "Unleash The Power of Pre-Trained Language Models for Irregularly Sampled Time Series",
    "authors": [
      "Weijia Zhang",
      "Chenlong Yin",
      "Hao Liu",
      "Hui Xiong"
    ],
    "abstract": "Pre-trained Language Models (PLMs), such as ChatGPT, have significantly\nadvanced the field of natural language processing. This progress has inspired a\nseries of innovative studies that explore the adaptation of PLMs to time series\nanalysis, intending to create a unified foundation model that addresses various\ntime series analytical tasks. However, these efforts predominantly focus on\nRegularly Sampled Time Series (RSTS), neglecting the unique challenges posed by\nIrregularly Sampled Time Series (ISTS), which are characterized by non-uniform\nsampling intervals and prevalent missing data. To bridge this gap, this work\nexplores the potential of PLMs for ISTS analysis. We begin by investigating the\neffect of various methods for representing ISTS, aiming to maximize the\nefficacy of PLMs in this under-explored area. Furthermore, we present a unified\nPLM-based framework, ISTS-PLM, which integrates time-aware and variable-aware\nPLMs tailored for comprehensive intra and inter-time series modeling and\nincludes a learnable input embedding layer and a task-specific output layer to\ntackle diverse ISTS analytical tasks. Extensive experiments on a comprehensive\nbenchmark demonstrate that the ISTS-PLM, utilizing a simple yet effective\nseries-based representation for ISTS, consistently achieves state-of-the-art\nperformance across various analytical tasks, such as classification,\ninterpolation, and extrapolation, as well as few-shot and zero-shot learning\nscenarios, spanning scientific domains like healthcare and biomechanics.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08328v1",
    "published_date": "2024-08-12 14:22:14 UTC",
    "updated_date": "2024-08-12 14:22:14 UTC"
  },
  {
    "arxiv_id": "2408.06163v1",
    "title": "ACCELERATION: Sequentially-scanning DECT Imaging Using High Temporal Resolution Image Reconstruction And Temporal Extrapolation",
    "authors": [
      "Qiaoxin Li",
      "Dong Liang",
      "Yinsheng Li"
    ],
    "abstract": "Dual-energy computed tomography (DECT) has been widely used to obtain\nquantitative elemental composition of imaged subjects for personalized and\nprecise medical diagnosis. Compared with existing high-end DECT leveraging\nadvanced X-ray source and/or detector technologies, the use of the\nsequentially-scanning data acquisition scheme to implement DECT may make\nbroader impact on clinical practice because this scheme requires no specialized\nhardware designs. However, since the concentration of iodinated contrast agent\nin the imaged subject varies over time, sequentially-scanned data sets acquired\nat two tube potentials are temporally inconsistent. As existing material\ndecomposition approaches for DECT assume that the data sets acquired at two\ntube potentials are temporally consistent, the violation of this assumption\nresults in inaccurate quantification accuracy of iodine concentration. In this\nwork, we developed a technique to achieve sequentially-scanning DECT imaging\nusing high temporal resolution image reconstruction and temporal extrapolation,\nACCELERATION in short, to address the technical challenge induced by temporal\ninconsistency of sequentially-scanned data sets and improve iodine\nquantification accuracy in sequentially-scanning DECT. ACCELERATION has been\nvalidated and evaluated using numerical simulation data sets generated from\nclinical human subject exams. Results demonstrated the improvement of iodine\nquantification accuracy using ACCELERATION.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CV",
      "physics.ins-det"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06163v1",
    "published_date": "2024-08-12 14:03:17 UTC",
    "updated_date": "2024-08-12 14:03:17 UTC"
  },
  {
    "arxiv_id": "2408.06152v2",
    "title": "Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming",
    "authors": [
      "Xinqi Jin",
      "Zhui Zhu",
      "Xikai Sun",
      "Fan Dang",
      "Jiangchuan Liu",
      "Jingao Xu",
      "Kebin Liu",
      "Xinlei Chen",
      "Yunhao Liu"
    ],
    "abstract": "Neural enhancement through super-resolution (SR) deep neural networks (DNNs)\nopens up new possibilities for ultra-high-definition (UHD) live streaming over\nexisting encoding and networking infrastructure. Yet, the heavy SR DNN\ninference overhead leads to severe deployment challenges. To reduce the\noverhead, existing systems propose to apply DNN-based SR only on carefully\nselected anchor frames while upscaling non-anchor frames via the lightweight\nreusing-based SR approach. However, frame-level scheduling is coarse-grained\nand fails to deliver optimal efficiency. In this work, we propose Palantir, the\nfirst neural-enhanced UHD live streaming system with fine-grained patch-level\nscheduling. Two novel techniques are incorporated into Palantir to select the\nmost beneficial anchor patches and support latency-sensitive UHD live streaming\napplications. Firstly, under the guidance of our pioneering and theoretical\nanalysis, Palantir constructs a directed acyclic graph (DAG) for lightweight\nyet accurate SR quality estimation under any possible anchor patch set.\nSecondly, to further optimize the scheduling latency, Palantir improves\nparallelizability by refactoring the computation subprocedure of the estimation\nprocess into a sparse matrix-matrix multiplication operation.\n  The evaluation results suggest that Palantir incurs a negligible scheduling\nlatency accounting for less than 5.7% of the end-to-end latency requirement.\nWhen compared to the naive method of applying DNN-based SR on all the frames,\nPalantir can reduce the SR DNN inference overhead by 20 times (or 60 times)\nwhile preserving 54.0-82.6% (or 32.8-64.0%) of the quality gain. When compared\nto the state-of-the-art real-time frame-level scheduling strategy, Palantir can\nreduce the SR DNN inference overhead by 80.1% at most (and 38.4% on average)\nwithout sacrificing the video quality.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.NI"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06152v2",
    "published_date": "2024-08-12 13:48:06 UTC",
    "updated_date": "2024-08-31 12:32:50 UTC"
  },
  {
    "arxiv_id": "2408.06142v1",
    "title": "Med42-v2: A Suite of Clinical LLMs",
    "authors": [
      "Clément Christophe",
      "Praveen K Kanithi",
      "Tathagata Raha",
      "Shadab Khan",
      "Marco AF Pimentel"
    ],
    "abstract": "Med42-v2 introduces a suite of clinical large language models (LLMs) designed\nto address the limitations of generic models in healthcare settings. These\nmodels are built on Llama3 architecture and fine-tuned using specialized\nclinical data. They underwent multi-stage preference alignment to effectively\nrespond to natural prompts. While generic models are often preference-aligned\nto avoid answering clinical queries as a precaution, Med42-v2 is specifically\ntrained to overcome this limitation, enabling its use in clinical settings.\nMed42-v2 models demonstrate superior performance compared to the original\nLlama3 models in both 8B and 70B parameter configurations and GPT-4 across\nvarious medical benchmarks. These LLMs are developed to understand clinical\nqueries, perform reasoning tasks, and provide valuable assistance in clinical\nenvironments. The models are now publicly available at\n\\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06142v1",
    "published_date": "2024-08-12 13:37:31 UTC",
    "updated_date": "2024-08-12 13:37:31 UTC"
  },
  {
    "arxiv_id": "2408.06121v3",
    "title": "A Methodological Report on Anomaly Detection on Dynamic Knowledge Graphs",
    "authors": [
      "Xiaohua Lu",
      "Leshanshui Yang"
    ],
    "abstract": "In this paper, we explore different approaches to anomaly detection on\ndynamic knowledge graphs, specifically in a Micro-services environment for\nKubernetes applications. Our approach explores three dynamic knowledge graph\nrepresentations: sequential data, hierarchical data and inter-service\ndependency data, with each representation incorporating increasingly complex\nstructural information of dynamic knowledge graph. Different machine learning\nand deep learning models are tested on these representations. We empirically\nanalyse their performance and propose an approach based on ensemble learning of\nthese models. Our approach significantly outperforms the baseline on the ISWC\n2024 Dynamic Knowledge Graph Anomaly Detection dataset, providing a robust\nsolution for anomaly detection in dynamic complex data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06121v3",
    "published_date": "2024-08-12 13:03:34 UTC",
    "updated_date": "2024-11-11 01:49:19 UTC"
  },
  {
    "arxiv_id": "2408.06402v2",
    "title": "PhaGO: Protein function annotation for bacteriophages by integrating the genomic context",
    "authors": [
      "Jiaojiao Guan",
      "Yongxin Ji",
      "Cheng Peng",
      "Wei Zou",
      "Xubo Tang",
      "Jiayu Shang",
      "Yanni Sun"
    ],
    "abstract": "Bacteriophages are viruses that target bacteria, playing a crucial role in\nmicrobial ecology. Phage proteins are important in understanding phage biology,\nsuch as virus infection, replication, and evolution. Although a large number of\nnew phages have been identified via metagenomic sequencing, many of them have\nlimited protein function annotation. Accurate function annotation of phage\nproteins presents several challenges, including their inherent diversity and\nthe scarcity of annotated ones. Existing tools have yet to fully leverage the\nunique properties of phages in annotating protein functions. In this work, we\npropose a new protein function annotation tool for phages by leveraging the\nmodular genomic structure of phage genomes. By employing embeddings from the\nlatest protein foundation models and Transformer to capture contextual\ninformation between proteins in phage genomes, PhaGO surpasses state-of-the-art\nmethods in annotating diverged proteins and proteins with uncommon functions by\n6.78% and 13.05% improvement, respectively. PhaGO can annotate proteins lacking\nhomology search results, which is critical for characterizing the rapidly\naccumulating phage genomes. We demonstrate the utility of PhaGO by identifying\n688 potential holins in phages, which exhibit high structural conservation with\nknown holins. The results show the potential of PhaGO to extend our\nunderstanding of newly discovered phages.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "17 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.06402v2",
    "published_date": "2024-08-12 13:02:38 UTC",
    "updated_date": "2024-08-17 13:46:36 UTC"
  },
  {
    "arxiv_id": "2408.06101v1",
    "title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics",
    "authors": [
      "Robin Schmöcker",
      "Alexander Henkes",
      "Julian Roth",
      "Thomas Wick"
    ],
    "abstract": "This works investigates the generalization capabilities of MeshGraphNets\n(MGN) [Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. ICML\n2021] to unseen geometries for fluid dynamics, e.g. predicting the flow around\na new obstacle that was not part of the training data. For this purpose, we\ncreate a new benchmark dataset for data-driven computational fluid dynamics\n(CFD) which extends DeepMind's flow around a cylinder dataset by including\ndifferent shapes and multiple objects. We then use this new dataset to extend\nthe generalization experiments conducted by DeepMind on MGNs by testing how\nwell an MGN can generalize to different shapes. In our numerical tests, we show\nthat MGNs can sometimes generalize well to various shapes by training on a\ndataset of one obstacle shape and testing on a dataset of another obstacle\nshape.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06101v1",
    "published_date": "2024-08-12 12:32:15 UTC",
    "updated_date": "2024-08-12 12:32:15 UTC"
  },
  {
    "arxiv_id": "2408.07099v1",
    "title": "Bearing Fault Diagnosis using Graph Sampling and Aggregation Network",
    "authors": [
      "Jiaying Chen",
      "Xusheng Du",
      "Yurong Qian",
      "Gwanggil Jeon"
    ],
    "abstract": "Bearing fault diagnosis technology has a wide range of practical applications\nin industrial production, energy and other fields. Timely and accurate\ndetection of bearing faults plays an important role in preventing catastrophic\naccidents and ensuring product quality. Traditional signal analysis techniques\nand deep learning-based fault detection algorithms do not take into account the\nintricate correlation between signals, making it difficult to further improve\ndetection accuracy. To address this problem, we introduced Graph Sampling and\nAggregation (GraphSAGE) network and proposed GraphSAGE-based Bearing fault\nDiagnosis (GSABFD) algorithm. The original vibration signal is firstly sliced\nthrough a fixed size non-overlapping sliding window, and the sliced data is\nfeature transformed using signal analysis methods; then correlations are\nconstructed for the transformed vibration signal and further transformed into\nvertices in the graph; then the GraphSAGE network is used for training; finally\nthe fault level of the object is calculated in the output layer of the network.\nThe proposed algorithm is compared with five advanced algorithms in a\nreal-world public dataset for experiments, and the results show that the GSABFD\nalgorithm improves the AUC value by 5% compared with the next best algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07099v1",
    "published_date": "2024-08-12 12:32:03 UTC",
    "updated_date": "2024-08-12 12:32:03 UTC"
  },
  {
    "arxiv_id": "2408.07098v1",
    "title": "QTypeMix: Enhancing Multi-Agent Cooperative Strategies through Heterogeneous and Homogeneous Value Decomposition",
    "authors": [
      "Songchen Fu",
      "Shaojing Zhao",
      "Ta Li",
      "YongHong Yan"
    ],
    "abstract": "In multi-agent cooperative tasks, the presence of heterogeneous agents is\nfamiliar. Compared to cooperation among homogeneous agents, collaboration\nrequires considering the best-suited sub-tasks for each agent. However, the\noperation of multi-agent systems often involves a large amount of complex\ninteraction information, making it more challenging to learn heterogeneous\nstrategies. Related multi-agent reinforcement learning methods sometimes use\ngrouping mechanisms to form smaller cooperative groups or leverage prior domain\nknowledge to learn strategies for different roles. In contrast, agents should\nlearn deeper role features without relying on additional information.\nTherefore, we propose QTypeMix, which divides the value decomposition process\ninto homogeneous and heterogeneous stages. QTypeMix learns to extract type\nfeatures from local historical observations through the TE loss. In addition,\nwe introduce advanced network structures containing attention mechanisms and\nhypernets to enhance the representation capability and achieve the value\ndecomposition process. The results of testing the proposed method on 14 maps\nfrom SMAC and SMACv2 show that QTypeMix achieves state-of-the-art performance\nin tasks of varying difficulty.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.MA",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07098v1",
    "published_date": "2024-08-12 12:27:58 UTC",
    "updated_date": "2024-08-12 12:27:58 UTC"
  },
  {
    "arxiv_id": "2408.06087v1",
    "title": "Building Decision Making Models Through Language Model Regime",
    "authors": [
      "Yu Zhang",
      "Haoxiang Liu",
      "Feijun Jiang",
      "Weihua Luo",
      "Kaifu Zhang"
    ],
    "abstract": "We propose a novel approach for decision making problems leveraging the\ngeneralization capabilities of large language models (LLMs). Traditional\nmethods such as expert systems, planning algorithms, and reinforcement learning\noften exhibit limited generalization, typically requiring the training of new\nmodels for each unique task. In contrast, LLMs demonstrate remarkable success\nin generalizing across varied language tasks, inspiring a new strategy for\ntraining decision making models. Our approach, referred to as \"Learning then\nUsing\" (LTU), entails a two-stage process. Initially, the \\textit{learning}\nphase develops a robust foundational decision making model by integrating\ndiverse knowledge from various domains and decision making contexts. The\nsubsequent \\textit{using} phase refines this foundation model for specific\ndecision making scenarios. Distinct from other studies that employ LLMs for\ndecision making through supervised learning, our LTU method embraces a\nversatile training methodology that combines broad pre-training with targeted\nfine-tuning. Experiments in e-commerce domains such as advertising and search\noptimization have shown that LTU approach outperforms traditional supervised\nlearning regimes in decision making capabilities and generalization. The LTU\napproach is the first practical training architecture for both single-step and\nmulti-step decision making tasks combined with LLMs, which can be applied\nbeyond game and robot domains. It provides a robust and adaptable framework for\ndecision making, enhances the effectiveness and flexibility of various systems\nin tackling various challenges.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06087v1",
    "published_date": "2024-08-12 12:04:14 UTC",
    "updated_date": "2024-08-12 12:04:14 UTC"
  },
  {
    "arxiv_id": "2408.06069v1",
    "title": "Fully Bayesian Differential Gaussian Processes through Stochastic Differential Equations",
    "authors": [
      "Jian Xu",
      "Zhiqi Lin",
      "Min Chen",
      "Junmei Yang",
      "Delu Zeng",
      "John Paisley"
    ],
    "abstract": "Traditional deep Gaussian processes model the data evolution using a discrete\nhierarchy, whereas differential Gaussian processes (DIFFGPs) represent the\nevolution as an infinitely deep Gaussian process. However, prior DIFFGP methods\noften overlook the uncertainty of kernel hyperparameters and assume them to be\nfixed and time-invariant, failing to leverage the unique synergy between\ncontinuous-time models and approximate inference. In this work, we propose a\nfully Bayesian approach that treats the kernel hyperparameters as random\nvariables and constructs coupled stochastic differential equations (SDEs) to\nlearn their posterior distribution and that of inducing points. By\nincorporating estimation uncertainty on hyperparameters, our method enhances\nthe model's flexibility and adaptability to complex dynamics. Additionally, our\napproach provides a time-varying, comprehensive, and realistic posterior\napproximation through coupling variables using SDE methods. Experimental\nresults demonstrate the advantages of our method over traditional approaches,\nshowcasing its superior performance in terms of flexibility, accuracy, and\nother metrics. Our work opens up exciting research avenues for advancing\nBayesian inference and offers a powerful modeling tool for continuous-time\nGaussian processes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06069v1",
    "published_date": "2024-08-12 11:41:07 UTC",
    "updated_date": "2024-08-12 11:41:07 UTC"
  },
  {
    "arxiv_id": "2408.06068v1",
    "title": "Online Optimization of Curriculum Learning Schedules using Evolutionary Optimization",
    "authors": [
      "Mohit Jiwatode",
      "Leon Schlecht",
      "Alexander Dockhorn"
    ],
    "abstract": "We propose RHEA CL, which combines Curriculum Learning (CL) with Rolling\nHorizon Evolutionary Algorithms (RHEA) to automatically produce effective\ncurricula during the training of a reinforcement learning agent. RHEA CL\noptimizes a population of curricula, using an evolutionary algorithm, and\nselects the best-performing curriculum as the starting point for the next\ntraining epoch. Performance evaluations are conducted after every curriculum\nstep in all environments. We evaluate the algorithm on the \\textit{DoorKey} and\n\\textit{DynamicObstacles} environments within the Minigrid framework. It\ndemonstrates adaptability and consistent improvement, particularly in the early\nstages, while reaching a stable performance later that is capable of\noutperforming other curriculum learners. In comparison to other curriculum\nschedules, RHEA CL has been shown to yield performance improvements for the\nfinal Reinforcement learning (RL) agent at the cost of additional evaluation\nduring training.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages including abstract, to be published in the Proceedings of the\n  IEEE Conference on Games 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06068v1",
    "published_date": "2024-08-12 11:39:50 UTC",
    "updated_date": "2024-08-12 11:39:50 UTC"
  },
  {
    "arxiv_id": "2408.08902v1",
    "title": "Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection",
    "authors": [
      "Chengyu Song",
      "Linru Ma",
      "Jianming Zheng",
      "Jinzhi Liao",
      "Hongyu Kuang",
      "Lin Yang"
    ],
    "abstract": "Log-based insider threat detection (ITD) detects malicious user activities by\nauditing log entries. Recently, large language models (LLMs) with strong common\nsense knowledge have emerged in the domain of ITD. Nevertheless, diverse\nactivity types and overlong log files pose a significant challenge for LLMs in\ndirectly discerning malicious ones within myriads of normal activities.\nFurthermore, the faithfulness hallucination issue from LLMs aggravates its\napplication difficulty in ITD, as the generated conclusion may not align with\nuser commands and activity context. In response to these challenges, we\nintroduce Audit-LLM, a multi-agent log-based insider threat detection framework\ncomprising three collaborative agents: (i) the Decomposer agent, breaking down\nthe complex ITD task into manageable sub-tasks using Chain-of-Thought (COT)\nreasoning;(ii) the Tool Builder agent, creating reusable tools for sub-tasks to\novercome context length limitations in LLMs; and (iii) the Executor agent,\ngenerating the final detection conclusion by invoking constructed tools. To\nenhance conclusion accuracy, we propose a pair-wise Evidence-based Multi-agent\nDebate (EMAD) mechanism, where two independent Executors iteratively refine\ntheir conclusions through reasoning exchange to reach a consensus.\nComprehensive experiments conducted on three publicly available ITD\ndatasets-CERT r4.2, CERT r5.2, and PicoDomain-demonstrate the superiority of\nour method over existing baselines and show that the proposed EMAD\nsignificantly improves the faithfulness of explanations generated by LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.08902v1",
    "published_date": "2024-08-12 11:33:45 UTC",
    "updated_date": "2024-08-12 11:33:45 UTC"
  },
  {
    "arxiv_id": "2408.06065v1",
    "title": "An Investigation Into Explainable Audio Hate Speech Detection",
    "authors": [
      "Jinmyeong An",
      "Wonjun Lee",
      "Yejin Jeon",
      "Jungseul Ok",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "abstract": "Research on hate speech has predominantly revolved around detection and\ninterpretation from textual inputs, leaving verbal content largely unexplored.\nWhile there has been limited exploration into hate speech detection within\nverbal acoustic speech inputs, the aspect of interpretability has been\noverlooked. Therefore, we introduce a new task of explainable audio hate speech\ndetection. Specifically, we aim to identify the precise time intervals,\nreferred to as audio frame-level rationales, which serve as evidence for hate\nspeech classification. Towards this end, we propose two different approaches:\ncascading and End-to-End (E2E). The cascading approach initially converts audio\nto transcripts, identifies hate speech within these transcripts, and\nsubsequently locates the corresponding audio time frames. Conversely, the E2E\napproach processes audio utterances directly, which allows it to pinpoint hate\nspeech within specific time frames. Additionally, due to the lack of\nexplainable audio hate speech datasets that include audio frame-level\nrationales, we curated a synthetic audio dataset to train our models. We\nfurther validated these models on actual human speech utterances and found that\nthe E2E approach outperforms the cascading method in terms of the audio frame\nIntersection over Union (IoU) metric. Furthermore, we observed that including\nframe-level rationales significantly enhances hate speech detection accuracy\nfor the E2E approach.\n  \\textbf{Disclaimer} The reader may encounter content of an offensive or\nhateful nature. However, given the nature of the work, this cannot be avoided.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to SIGDIAL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06065v1",
    "published_date": "2024-08-12 11:32:34 UTC",
    "updated_date": "2024-08-12 11:32:34 UTC"
  },
  {
    "arxiv_id": "2408.06051v2",
    "title": "Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games",
    "authors": [
      "Chiu-Chou Lin",
      "Wei-Chen Chiu",
      "I-Chen Wu"
    ],
    "abstract": "Defining and measuring decision-making styles, also known as playstyles, is\ncrucial in gaming, where these styles reflect a broad spectrum of individuality\nand diversity. However, finding a universally applicable measure for these\nstyles poses a challenge. Building on Playstyle Distance, the first\nunsupervised metric to measure playstyle similarity based on game screens and\nraw actions, we introduce three enhancements to increase accuracy: multiscale\nanalysis with varied state granularity, a perceptual kernel rooted in\npsychology, and the utilization of the intersection-over-union method for\nefficient evaluation. These innovations not only advance measurement precision\nbut also offer insights into human cognition of similarity. Across two racing\ngames and seven Atari games, our techniques significantly improve the precision\nof zero-shot playstyle classification, achieving an accuracy exceeding 90\npercent with fewer than 512 observation-action pairs, which is less than half\nan episode of these games. Furthermore, our experiments with 2048 and Go\ndemonstrate the potential of discrete playstyle measures in puzzle and board\ngames. We also develop an algorithm for assessing decision-making diversity\nusing these measures. Our findings improve the measurement of end-to-end game\nanalysis and the evolution of artificial intelligence for diverse playstyles.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "TMLR 08/2024 https://openreview.net/forum?id=30C9AWBW49",
    "pdf_url": "http://arxiv.org/pdf/2408.06051v2",
    "published_date": "2024-08-12 10:55:42 UTC",
    "updated_date": "2024-08-30 03:19:26 UTC"
  },
  {
    "arxiv_id": "2408.06042v1",
    "title": "Understanding Byzantine Robustness in Federated Learning with A Black-box Server",
    "authors": [
      "Fangyuan Zhao",
      "Yuexiang Xie",
      "Xuebin Ren",
      "Bolin Ding",
      "Shusen Yang",
      "Yaliang Li"
    ],
    "abstract": "Federated learning (FL) becomes vulnerable to Byzantine attacks where some of\nparticipators tend to damage the utility or discourage the convergence of the\nlearned model via sending their malicious model updates. Previous works propose\nto apply robust rules to aggregate updates from participators against different\ntypes of Byzantine attacks, while at the same time, attackers can further\ndesign advanced Byzantine attack algorithms targeting specific aggregation rule\nwhen it is known. In practice, FL systems can involve a black-box server that\nmakes the adopted aggregation rule inaccessible to participants, which can\nnaturally defend or weaken some Byzantine attacks. In this paper, we provide an\nin-depth understanding on the Byzantine robustness of the FL system with a\nblack-box server. Our investigation demonstrates the improved Byzantine\nrobustness of a black-box server employing a dynamic defense strategy. We\nprovide both empirical evidence and theoretical analysis to reveal that the\nblack-box server can mitigate the worst-case attack impact from a maximum level\nto an expectation level, which is attributed to the inherent inaccessibility\nand randomness offered by a black-box server.The source code is available at\nhttps://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense to\npromote further research in the community.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "We have released code on\n  https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense",
    "pdf_url": "http://arxiv.org/pdf/2408.06042v1",
    "published_date": "2024-08-12 10:18:24 UTC",
    "updated_date": "2024-08-12 10:18:24 UTC"
  },
  {
    "arxiv_id": "2408.06039v1",
    "title": "Spacetime $E(n)$-Transformer: Equivariant Attention for Spatio-temporal Graphs",
    "authors": [
      "Sergio G. Charles"
    ],
    "abstract": "We introduce an $E(n)$-equivariant Transformer architecture for\nspatio-temporal graph data. By imposing rotation, translation, and permutation\nequivariance inductive biases in both space and time, we show that the\nSpacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal\nmodels without symmetry-preserving properties. We benchmark SET against said\nmodels on the charged $N$-body problem, a simple physical system with complex\ndynamics. While existing spatio-temporal graph neural networks focus on\nsequential modeling, we empirically demonstrate that leveraging underlying\ndomain symmetries yields considerable improvements for modeling dynamical\nsystems on graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.06039v1",
    "published_date": "2024-08-12 10:13:45 UTC",
    "updated_date": "2024-08-12 10:13:45 UTC"
  },
  {
    "arxiv_id": "2408.06036v1",
    "title": "Peaking into the Black-box: Prediction Intervals Give Insight into Data-driven Quadrotor Model Reliability",
    "authors": [
      "Jasper van Beers",
      "Coen de Visser"
    ],
    "abstract": "Ensuring the reliability and validity of data-driven quadrotor model\npredictions is essential for their accepted and practical use. This is\nespecially true for grey- and black-box models wherein the mapping of inputs to\npredictions is not transparent and subsequent reliability notoriously difficult\nto ascertain. Nonetheless, such techniques are frequently and successfully used\nto identify quadrotor models. Prediction intervals (PIs) may be employed to\nprovide insight into the consistency and accuracy of model predictions. This\npaper estimates such PIs for polynomial and Artificial Neural Network (ANN)\nquadrotor aerodynamic models. Two existing ANN PI estimation techniques - the\nbootstrap method and the quality driven method - are validated numerically for\nquadrotor aerodynamic models using an existing high-fidelity quadrotor\nsimulation. Quadrotor aerodynamic models are then identified on real quadrotor\nflight data to demonstrate their utility and explore their sensitivity to model\ninterpolation and extrapolation. It is found that the ANN-based PIs widen\nconsiderably when extrapolating and remain constant, or shrink, when\ninterpolating. While this behaviour also occurs for the polynomial PIs, it is\nof lower magnitude. The estimated PIs establish probabilistic bounds within\nwhich the quadrotor model outputs will likely lie, subject to modelling and\nmeasurement uncertainties that are reflected through the PI widths.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Presented at AIAA SciTech Forum 2023 in National Harbor, MD, USA",
    "pdf_url": "http://arxiv.org/pdf/2408.06036v1",
    "published_date": "2024-08-12 09:57:00 UTC",
    "updated_date": "2024-08-12 09:57:00 UTC"
  },
  {
    "arxiv_id": "2408.06022v1",
    "title": "Controlling Surprisal in Music Generation via Information Content Curve Matching",
    "authors": [
      "Mathias Rose Bjare",
      "Stefan Lattner",
      "Gerhard Widmer"
    ],
    "abstract": "In recent years, the quality and public interest in music generation systems\nhave grown, encouraging research into various ways to control these systems. We\npropose a novel method for controlling surprisal in music generation using\nsequence models. To achieve this goal, we define a metric called Instantaneous\nInformation Content (IIC). The IIC serves as a proxy function for the perceived\nmusical surprisal (as estimated from a probabilistic model) and can be\ncalculated at any point within a music piece. This enables the comparison of\nsurprisal across different musical content even if the musical events occur in\nirregular time intervals. We use beam search to generate musical material whose\nIIC curve closely approximates a given target IIC. We experimentally show that\nthe IIC correlates with harmonic and rhythmic complexity and note density. The\ncorrelation decreases with the length of the musical context used for\nestimating the IIC. Finally, we conduct a qualitative user study to test if\nhuman listeners can identify the IIC curves that have been used as targets when\ngenerating the respective musical material. We provide code for creating IIC\ninterpolations and IIC visualizations on https://github.com/muthissar/iic.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 4 figures, 2 tables, accepted at the 25th Int. Society for\n  Music Information Retrieval Conf., San Francisco, USA, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06022v1",
    "published_date": "2024-08-12 09:21:41 UTC",
    "updated_date": "2024-08-12 09:21:41 UTC"
  },
  {
    "arxiv_id": "2408.06018v1",
    "title": "Uncertainty-Informed Volume Visualization using Implicit Neural Representation",
    "authors": [
      "Shanu Saklani",
      "Chitwan Goel",
      "Shrey Bansal",
      "Zhe Wang",
      "Soumya Dutta",
      "Tushar M. Athawale",
      "David Pugmire",
      "Christopher R. Johnson"
    ],
    "abstract": "The increasing adoption of Deep Neural Networks (DNNs) has led to their\napplication in many challenging scientific visualization tasks. While advanced\nDNNs offer impressive generalization capabilities, understanding factors such\nas model prediction quality, robustness, and uncertainty is crucial. These\ninsights can enable domain scientists to make informed decisions about their\ndata. However, DNNs inherently lack ability to estimate prediction uncertainty,\nnecessitating new research to construct robust uncertainty-aware visualization\ntechniques tailored for various visualization tasks. In this work, we propose\nuncertainty-aware implicit neural representations to model scalar field data\nsets effectively and comprehensively study the efficacy and benefits of\nestimated uncertainty information for volume visualization tasks. We evaluate\nthe effectiveness of two principled deep uncertainty estimation techniques: (1)\nDeep Ensemble and (2) Monte Carlo Dropout (MCDropout). These techniques enable\nuncertainty-informed volume visualization in scalar field data sets. Our\nextensive exploration across multiple data sets demonstrates that\nuncertainty-aware models produce informative volume visualization results.\nMoreover, integrating prediction uncertainty enhances the trustworthiness of\nour DNN model, making it suitable for robustly analyzing and visualizing\nreal-world scientific volumetric data sets.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.GR",
    "comment": "To appear in IEEE Workshop on Uncertainty Visualization in\n  conjunction with IEEE VIS 2024, Florida, USA",
    "pdf_url": "http://arxiv.org/pdf/2408.06018v1",
    "published_date": "2024-08-12 09:14:23 UTC",
    "updated_date": "2024-08-12 09:14:23 UTC"
  },
  {
    "arxiv_id": "2408.05992v2",
    "title": "Transfer learning of state-based potential games for process optimization in decentralized manufacturing systems",
    "authors": [
      "Steve Yuwono",
      "Dorothea Schwung",
      "Andreas Schwung"
    ],
    "abstract": "This paper presents a novel transfer learning approach in state-based\npotential games (TL-SbPGs) for enhancing distributed self-optimization in\nmanufacturing systems. The approach focuses on the practical relevant\nindustrial setting where sharing and transferring gained knowledge among\nsimilar-behaved players improves the self-learning mechanism in large-scale\nsystems. With TL-SbPGs, the gained knowledge can be reused by other players to\noptimize their policies, thereby improving the learning outcomes of the players\nand accelerating the learning process. To accomplish this goal, we develop\ntransfer learning concepts and similarity criteria for players, which offer two\ndistinct settings: (a) predefined similarities between players and (b)\ndynamically inferred similarities between players during training. We formally\nprove the applicability of the SbPG framework in transfer learning.\nAdditionally, we introduce an efficient method to determine the optimal timing\nand weighting of the transfer learning procedure during the training phase.\nThrough experiments on a laboratory-scale testbed, we demonstrate that TL-SbPGs\nsignificantly boost production efficiency while reducing power consumption of\nthe production schedules while also outperforming native SbPGs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "This revised pre-print was submitted to Computers in Industry on\n  October 11, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05992v2",
    "published_date": "2024-08-12 08:40:20 UTC",
    "updated_date": "2024-10-11 09:41:40 UTC"
  },
  {
    "arxiv_id": "2408.06397v1",
    "title": "Distributed Stackelberg Strategies in State-based Potential Games for Autonomous Decentralized Learning Manufacturing Systems",
    "authors": [
      "Steve Yuwono",
      "Dorothea Schwung",
      "Andreas Schwung"
    ],
    "abstract": "This article describes a novel game structure for autonomously optimizing\ndecentralized manufacturing systems with multi-objective optimization\nchallenges, namely Distributed Stackelberg Strategies in State-Based Potential\nGames (DS2-SbPG). DS2-SbPG integrates potential games and Stackelberg games,\nwhich improves the cooperative trade-off capabilities of potential games and\nthe multi-objective optimization handling by Stackelberg games. Notably, all\ntraining procedures remain conducted in a fully distributed manner. DS2-SbPG\noffers a promising solution to finding optimal trade-offs between objectives by\neliminating the complexities of setting up combined objective optimization\nfunctions for individual players in self-learning domains, particularly in\nreal-world industrial settings with diverse and numerous objectives between the\nsub-systems. We further prove that DS2-SbPG constitutes a dynamic potential\ngame that results in corresponding converge guarantees. Experimental validation\nconducted on a laboratory-scale testbed highlights the efficacy of DS2-SbPG and\nits two variants, such as DS2-SbPG for single-leader-follower and Stack\nDS2-SbPG for multi-leader-follower. The results show significant reductions in\npower consumption and improvements in overall performance, which signals the\npotential of DS2-SbPG in real-world applications.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "This pre-print was submitted to IEEE Transactions on Systems, Man,\n  and Cybernetics: Systems on July 31, 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06397v1",
    "published_date": "2024-08-12 08:24:54 UTC",
    "updated_date": "2024-08-12 08:24:54 UTC"
  },
  {
    "arxiv_id": "2408.07097v1",
    "title": "Attention Please: What Transformer Models Really Learn for Process Prediction",
    "authors": [
      "Martin Käppel",
      "Lars Ackermann",
      "Stefan Jablonski",
      "Simon Härtl"
    ],
    "abstract": "Predictive process monitoring aims to support the execution of a process\nduring runtime with various predictions about the further evolution of a\nprocess instance. In the last years a plethora of deep learning architectures\nhave been established as state-of-the-art for different prediction targets,\namong others the transformer architecture. The transformer architecture is\nequipped with a powerful attention mechanism, assigning attention scores to\neach input part that allows to prioritize most relevant information leading to\nmore accurate and contextual output. However, deep learning models largely\nrepresent a black box, i.e., their reasoning or decision-making process cannot\nbe understood in detail. This paper examines whether the attention scores of a\ntransformer based next-activity prediction model can serve as an explanation\nfor its decision-making. We find that attention scores in next-activity\nprediction models can serve as explainers and exploit this fact in two proposed\ngraph-based explanation approaches. The gained insights could inspire future\nwork on the improvement of predictive business process models as well as\nenabling a neural network based mining of process models from event logs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 68T01, 68U35",
      "H.4.2; I.2.1; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07097v1",
    "published_date": "2024-08-12 08:20:38 UTC",
    "updated_date": "2024-08-12 08:20:38 UTC"
  },
  {
    "arxiv_id": "2408.06396v1",
    "title": "Design Proteins Using Large Language Models: Enhancements and Comparative Analyses",
    "authors": [
      "Kamyar Zeinalipour",
      "Neda Jamshidi",
      "Monica Bianchini",
      "Marco Maggini",
      "Marco Gori"
    ],
    "abstract": "Pre-trained LLMs have demonstrated substantial capabilities across a range of\nconventional natural language processing (NLP) tasks, such as summarization and\nentity recognition. In this paper, we explore the application of LLMs in the\ngeneration of high-quality protein sequences. Specifically, we adopt a suite of\npre-trained LLMs, including Mistral-7B1, Llama-2-7B2, Llama-3-8B3, and\ngemma-7B4, to produce valid protein sequences. All of these models are publicly\navailable.5 Unlike previous work in this field, our approach utilizes a\nrelatively small dataset comprising 42,000 distinct human protein sequences. We\nretrain these models to process protein-related data, ensuring the generation\nof biologically feasible protein structures. Our findings demonstrate that even\nwith limited data, the adapted models exhibit efficiency comparable to\nestablished protein-focused models such as ProGen varieties, ProtGPT2, and\nProLLaMA, which were trained on millions of protein sequences. To validate and\nquantify the performance of our models, we conduct comparative analyses\nemploying standard metrics such as pLDDT, RMSD, TM-score, and REU. Furthermore,\nwe commit to making the trained versions of all four models publicly available,\nfostering greater transparency and collaboration in the field of computational\nbiology.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "This paper has been accepted for presentation at Language and\n  Molecules ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.06396v1",
    "published_date": "2024-08-12 08:17:27 UTC",
    "updated_date": "2024-08-12 08:17:27 UTC"
  },
  {
    "arxiv_id": "2408.05982v2",
    "title": "Exploring and Learning Structure: Active Inference Approach in Navigational Agents",
    "authors": [
      "Daria de Tinguy",
      "Tim Verbelen",
      "Bart Dhoedt"
    ],
    "abstract": "Drawing inspiration from animal navigation strategies, we introduce a novel\ncomputational model for navigation and mapping, rooted in biologically inspired\nprinciples. Animals exhibit remarkable navigation abilities by efficiently\nusing memory, imagination, and strategic decision-making to navigate complex\nand aliased environments. Building on these insights, we integrate traditional\ncognitive mapping approaches with an Active Inference Framework (AIF) to learn\nan environment structure in a few steps. Through the incorporation of\ntopological mapping for long-term memory and AIF for navigation planning and\nstructure learning, our model can dynamically apprehend environmental\nstructures and expand its internal map with predicted beliefs during\nexploration. Comparative experiments with the Clone-Structured Graph (CSCG)\nmodel highlight our model's ability to rapidly learn environmental structures\nin a single episode, with minimal navigation overlap. this is achieved without\nprior knowledge of the dimensions of the environment or the type of\nobservations, showcasing its robustness and effectiveness in navigating\nambiguous environments.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "IWAI workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05982v2",
    "published_date": "2024-08-12 08:17:14 UTC",
    "updated_date": "2024-09-02 08:48:12 UTC"
  },
  {
    "arxiv_id": "2408.05966v2",
    "title": "Freehand Sketch Generation from Mechanical Components",
    "authors": [
      "Zhichao Liao",
      "Di Huang",
      "Heming Fang",
      "Yue Ma",
      "Fengyuan Piao",
      "Xinghui Li",
      "Long Zeng",
      "Pingfa Feng"
    ],
    "abstract": "Drawing freehand sketches of mechanical components on multimedia devices for\nAI-based engineering modeling has become a new trend. However, its development\nis being impeded because existing works cannot produce suitable sketches for\ndata-driven research. These works either generate sketches lacking a freehand\nstyle or utilize generative models not originally designed for this task\nresulting in poor effectiveness. To address this issue, we design a two-stage\ngenerative framework mimicking the human sketching behavior pattern, called\nMSFormer, which is the first time to produce humanoid freehand sketches\ntailored for mechanical components. The first stage employs Open CASCADE\ntechnology to obtain multi-view contour sketches from mechanical components,\nfiltering perturbing signals for the ensuing generation process. Meanwhile, we\ndesign a view selector to simulate viewpoint selection tasks during human\nsketching for picking out information-rich sketches. The second stage\ntranslates contour sketches into freehand sketches by a transformer-based\ngenerator. To retain essential modeling features as much as possible and\nrationalize stroke distribution, we introduce a novel edge-constraint stroke\ninitialization. Furthermore, we utilize a CLIP vision encoder and a new loss\nfunction incorporating the Hausdorff distance to enhance the generalizability\nand robustness of the model. Extensive experiments demonstrate that our\napproach achieves state-of-the-art performance for generating freehand sketches\nin the mechanical domain. Project page: https://mcfreeskegen.github.io .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at ACM Multimedia (ACM MM) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05966v2",
    "published_date": "2024-08-12 07:44:19 UTC",
    "updated_date": "2024-08-21 10:28:18 UTC"
  },
  {
    "arxiv_id": "2408.05960v1",
    "title": "Match Point AI: A Novel AI Framework for Evaluating Data-Driven Tennis Strategies",
    "authors": [
      "Carlo Nübel",
      "Alexander Dockhorn",
      "Sanaz Mostaghim"
    ],
    "abstract": "Many works in the domain of artificial intelligence in games focus on board\nor video games due to the ease of reimplementing their mechanics.\nDecision-making problems in real-world sports share many similarities to such\ndomains. Nevertheless, not many frameworks on sports games exist. In this\npaper, we present the tennis match simulation environment \\textit{Match Point\nAI}, in which different agents can compete against real-world data-driven bot\nstrategies. Next to presenting the framework, we highlight its capabilities by\nillustrating, how MCTS can be used in Match Point AI to optimize the shot\ndirection selection problem in tennis. While the framework will be extended in\nthe future, first experiments already reveal that generated shot-by-shot data\nof simulated tennis matches show realistic characteristics when compared to\nreal-world data. At the same time, reasonable shot placement strategies emerge,\nwhich share similarities to the ones found in real-world tennis matches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 1 page abstract, short paper, to be published in Proceedings\n  of the IEEE Conference on Games 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05960v1",
    "published_date": "2024-08-12 07:22:46 UTC",
    "updated_date": "2024-08-12 07:22:46 UTC"
  },
  {
    "arxiv_id": "2408.05959v1",
    "title": "Markov Senior -- Learning Markov Junior Grammars to Generate User-specified Content",
    "authors": [
      "Mehmet Kayra Oğuz",
      "Alexander Dockhorn"
    ],
    "abstract": "Markov Junior is a probabilistic programming language used for procedural\ncontent generation across various domains. However, its reliance on manually\ncrafted and tuned probabilistic rule sets, also called grammars, presents a\nsignificant bottleneck, diverging from approaches that allow rule learning from\nexamples. In this paper, we propose a novel solution to this challenge by\nintroducing a genetic programming-based optimization framework for learning\nhierarchical rule sets automatically. Our proposed method ``Markov Senior''\nfocuses on extracting positional and distance relations from single input\nsamples to construct probabilistic rules to be used by Markov Junior. Using a\nKullback-Leibler divergence-based fitness measure, we search for grammars to\ngenerate content that is coherent with the given sample. To enhance\nscalability, we introduce a divide-and-conquer strategy that enables the\nefficient generation of large-scale content. We validate our approach through\nexperiments in generating image-based content and Super Mario levels,\ndemonstrating its flexibility and effectiveness. In this way, ``Markov Senior''\nallows for the wider application of Markov Junior for tasks in which an example\nmay be available, but the design of a generative rule set is infeasible.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, to be published in the Proceedings of the IEEE Conference on\n  Games 2024, demo implementation can be found here:\n  https://github.com/ADockhorn/MarkovSenior",
    "pdf_url": "http://arxiv.org/pdf/2408.05959v1",
    "published_date": "2024-08-12 07:22:33 UTC",
    "updated_date": "2024-08-12 07:22:33 UTC"
  },
  {
    "arxiv_id": "2408.05950v2",
    "title": "Robust online reconstruction of continuous-time signals from a lean spike train ensemble code",
    "authors": [
      "Anik Chattopadhyay",
      "Arunava Banerjee"
    ],
    "abstract": "Sensory stimuli in animals are encoded into spike trains by neurons, offering\nadvantages such as sparsity, energy efficiency, and high temporal resolution.\nThis paper presents a signal processing framework that deterministically\nencodes continuous-time signals into biologically feasible spike trains, and\naddresses the questions about representable signal classes and reconstruction\nbounds. The framework considers encoding of a signal through spike trains\ngenerated by an ensemble of neurons using a convolve-then-threshold mechanism\nwith various convolution kernels. A closed-form solution to the inverse\nproblem, from spike trains to signal reconstruction, is derived in the Hilbert\nspace of shifted kernel functions, ensuring sparse representation of a\ngeneralized Finite Rate of Innovation (FRI) class of signals. Additionally,\ninspired by real-time processing in biological systems, an efficient iterative\nversion of the optimal reconstruction is formulated that considers only a\nfinite window of past spikes, ensuring robustness of the technique to\nill-conditioned encoding; convergence guarantees of the windowed reconstruction\nto the optimal solution are then provided. Experiments on a large audio dataset\ndemonstrate excellent reconstruction accuracy at spike rates as low as\none-fifth of the Nyquist rate, while showing clear competitive advantage in\ncomparison to state-of-the-art sparse coding techniques in the low spike rate\nregime.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.NE",
    "comment": "22 pages, including a 9-page appendix, 8 figures. A GitHub link to\n  the project implementation is embedded in the paper",
    "pdf_url": "http://arxiv.org/pdf/2408.05950v2",
    "published_date": "2024-08-12 06:55:51 UTC",
    "updated_date": "2024-08-14 16:43:36 UTC"
  },
  {
    "arxiv_id": "2408.05941v1",
    "title": "Multimodal Large Language Models for Phishing Webpage Detection and Identification",
    "authors": [
      "Jehyun Lee",
      "Peiyuan Lim",
      "Bryan Hooi",
      "Dinil Mon Divakaran"
    ],
    "abstract": "To address the challenging problem of detecting phishing webpages,\nresearchers have developed numerous solutions, in particular those based on\nmachine learning (ML) algorithms. Among these, brand-based phishing detection\nthat uses models from Computer Vision to detect if a given webpage is imitating\na well-known brand has received widespread attention. However, such models are\ncostly and difficult to maintain, as they need to be retrained with labeled\ndataset that has to be regularly and continuously collected. Besides, they also\nneed to maintain a good reference list of well-known websites and related\nmeta-data for effective performance.\n  In this work, we take steps to study the efficacy of large language models\n(LLMs), in particular the multimodal LLMs, in detecting phishing webpages.\nGiven that the LLMs are pretrained on a large corpus of data, we aim to make\nuse of their understanding of different aspects of a webpage (logo, theme,\nfavicon, etc.) to identify the brand of a given webpage and compare the\nidentified brand with the domain name in the URL to detect a phishing attack.\nWe propose a two-phase system employing LLMs in both phases: the first phase\nfocuses on brand identification, while the second verifies the domain. We carry\nout comprehensive evaluations on a newly collected dataset. Our experiments\nshow that the LLM-based system achieves a high detection rate at high\nprecision; importantly, it also provides interpretable evidence for the\ndecisions. Our system also performs significantly better than a\nstate-of-the-art brand-based phishing detection system while demonstrating\nrobustness against two known adversarial attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear in eCrime 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05941v1",
    "published_date": "2024-08-12 06:36:08 UTC",
    "updated_date": "2024-08-12 06:36:08 UTC"
  },
  {
    "arxiv_id": "2408.05940v2",
    "title": "Spb3DTracker: A Robust LiDAR-Based Person Tracker for Noisy Environment",
    "authors": [
      "Eunsoo Im",
      "Changhyun Jee",
      "Jung Kwon Lee"
    ],
    "abstract": "Person detection and tracking (PDT) has seen significant advancements with 2D\ncamera-based systems in the autonomous vehicle field, leading to widespread\nadoption of these algorithms. However, growing privacy concerns have recently\nemerged as a major issue, prompting a shift towards LiDAR-based PDT as a viable\nalternative. Within this domain, \"Tracking-by-Detection\" (TBD) has become a\nprominent methodology. Despite its effectiveness, LiDAR-based PDT has not yet\nachieved the same level of performance as camera-based PDT. This paper examines\nkey components of the LiDAR-based PDT framework, including detection\npost-processing, data association, motion modeling, and lifecycle management.\nBuilding upon these insights, we introduce SpbTrack, a robust person tracker\ndesigned for diverse environments. Our method achieves superior performance on\nnoisy datasets and state-of-the-art results on KITTI Dataset benchmarks and\ncustom office indoor dataset among LiDAR-based trackers.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.05940v2",
    "published_date": "2024-08-12 06:33:38 UTC",
    "updated_date": "2024-08-13 05:18:42 UTC"
  },
  {
    "arxiv_id": "2408.05933v1",
    "title": "Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models",
    "authors": [
      "Fei Liu",
      "Zejun Kang",
      "Xing Han"
    ],
    "abstract": "With the growing demand for offline PDF chatbots in automotive industrial\nproduction environments, optimizing the deployment of large language models\n(LLMs) in local, low-performance settings has become increasingly important.\nThis study focuses on enhancing Retrieval-Augmented Generation (RAG) techniques\nfor processing complex automotive industry documents using locally deployed\nOllama models. Based on the Langchain framework, we propose a multi-dimensional\noptimization approach for Ollama's local RAG implementation. Our method\naddresses key challenges in automotive document processing, including\nmulti-column layouts and technical specifications. We introduce improvements in\nPDF processing, retrieval mechanisms, and context compression, tailored to the\nunique characteristics of automotive industry documents. Additionally, we\ndesign custom classes supporting embedding pipelines and an agent supporting\nself-RAG based on LangGraph best practices. To evaluate our approach, we\nconstructed a proprietary dataset comprising typical automotive industry\ndocuments, including technical reports and corporate regulations. We compared\nour optimized RAG model and self-RAG agent against a naive RAG baseline across\nthree datasets: our automotive industry dataset, QReCC, and CoQA. Results\ndemonstrate significant improvements in context precision, context recall,\nanswer relevancy, and faithfulness, with particularly notable performance on\nthe automotive industry dataset. Our optimization scheme provides an effective\nsolution for deploying local RAG systems in the automotive sector, addressing\nthe specific needs of PDF chatbots in industrial production environments. This\nresearch has important implications for advancing information processing and\nintelligent production in the automotive industry.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05933v1",
    "published_date": "2024-08-12 06:16:37 UTC",
    "updated_date": "2024-08-12 06:16:37 UTC"
  },
  {
    "arxiv_id": "2408.05926v1",
    "title": "BI-MDRG: Bridging Image History in Multimodal Dialogue Response Generation",
    "authors": [
      "Hee Suk Yoon",
      "Eunseop Yoon",
      "Joshua Tian Jin Tee",
      "Kang Zhang",
      "Yu-Jung Heo",
      "Du-Seong Chang",
      "Chang D. Yoo"
    ],
    "abstract": "Multimodal Dialogue Response Generation (MDRG) is a recently proposed task\nwhere the model needs to generate responses in texts, images, or a blend of\nboth based on the dialogue context. Due to the lack of a large-scale dataset\nspecifically for this task and the benefits of leveraging powerful pre-trained\nmodels, previous work relies on the text modality as an intermediary step for\nboth the image input and output of the model rather than adopting an end-to-end\napproach. However, this approach can overlook crucial information about the\nimage, hindering 1) image-grounded text response and 2) consistency of objects\nin the image response. In this paper, we propose BI-MDRG that bridges the\nresponse generation path such that the image history information is utilized\nfor enhanced relevance of text responses to the image content and the\nconsistency of objects in sequential image responses. Through extensive\nexperiments on the multimodal dialogue benchmark dataset, we show that BI-MDRG\ncan effectively increase the quality of multimodal dialogue. Additionally,\nrecognizing the gap in benchmark datasets for evaluating the image consistency\nin multimodal dialogue, we have created a curated set of 300 dialogues\nannotated to track object consistency across conversations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05926v1",
    "published_date": "2024-08-12 05:22:42 UTC",
    "updated_date": "2024-08-12 05:22:42 UTC"
  },
  {
    "arxiv_id": "2408.10255v2",
    "title": "Large Investment Model",
    "authors": [
      "Jian Guo",
      "Heung-Yeung Shum"
    ],
    "abstract": "Traditional quantitative investment research is encountering diminishing\nreturns alongside rising labor and time costs. To overcome these challenges, we\nintroduce the Large Investment Model (LIM), a novel research paradigm designed\nto enhance both performance and efficiency at scale. LIM employs end-to-end\nlearning and universal modeling to create an upstream foundation model capable\nof autonomously learning comprehensive signal patterns from diverse financial\ndata spanning multiple exchanges, instruments, and frequencies. These \"global\npatterns\" are subsequently transferred to downstream strategy modeling,\noptimizing performance for specific tasks. We detail the system architecture\ndesign of LIM, address the technical challenges inherent in this approach, and\noutline potential directions for future research. The advantages of LIM are\ndemonstrated through a series of numerical experiments on cross-instrument\nprediction for commodity futures trading, leveraging insights from stock\nmarkets.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.ST",
    "comment": "20 pages, 10 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.10255v2",
    "published_date": "2024-08-12 05:15:13 UTC",
    "updated_date": "2024-08-22 07:57:42 UTC"
  },
  {
    "arxiv_id": "2408.05924v2",
    "title": "Space-LLaVA: a Vision-Language Model Adapted to Extraterrestrial Applications",
    "authors": [
      "Matthew Foutter",
      "Daniele Gammelli",
      "Justin Kruger",
      "Ethan Foss",
      "Praneet Bhoj",
      "Tommaso Guffanti",
      "Simone D'Amico",
      "Marco Pavone"
    ],
    "abstract": "Foundation Models (FMs), e.g., large language models, possess attributes of\nintelligence which offer promise to endow a robot with the contextual\nunderstanding necessary to navigate complex, unstructured tasks in the wild. We\nsee three core challenges in the future of space robotics that motivate\nbuilding an FM for the space robotics community: 1) Scalability of\nground-in-the-loop operations; 2) Generalizing prior knowledge to novel\nenvironments; and 3) Multi-modality in tasks and sensor data. As a first-step\ntowards a space foundation model, we programmatically augment three\nextraterrestrial databases with fine-grained language annotations inspired by\nthe sensory reasoning necessary to e.g., identify a site of scientific interest\non Mars, building a synthetic dataset of visual-question-answer and visual\ninstruction-following tuples. We fine-tune a pre-trained LLaVA 13B checkpoint\non our augmented dataset to adapt a Vision-Language Model (VLM) to the visual\nsemantic features in an extraterrestrial environment, demonstrating FMs as a\ntool for specialization and enhancing a VLM's zero-shot performance on unseen\ntask types in comparison to state-of-the-art VLMs. Ablation studies show that\nfine-tuning the language backbone and vision-language adapter in concert is key\nto facilitate adaption while a small percentage, e.g., 20%, of the pre-training\ndata can be used to safeguard against catastrophic forgetting.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IEEE Aerospace Conference, 23 pages, 18 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.05924v2",
    "published_date": "2024-08-12 05:07:24 UTC",
    "updated_date": "2025-01-18 19:33:02 UTC"
  },
  {
    "arxiv_id": "2408.05920v3",
    "title": "Urban Region Pre-training and Prompting: A Graph-based Approach",
    "authors": [
      "Jiahui Jin",
      "Yifan Song",
      "Dong Kan",
      "Haojia Zhu",
      "Xiangguo Sun",
      "Zhicheng Li",
      "Xigang Sun",
      "Jinghui Zhang"
    ],
    "abstract": "Urban region representation is crucial for various urban downstream tasks.\nHowever, despite the proliferation of methods and their success, acquiring\ngeneral urban region knowledge and adapting to different tasks remains\nchallenging. Previous work often neglects the spatial structures and functional\nlayouts between entities, limiting their ability to capture transferable\nknowledge across regions. Further, these methods struggle to adapt effectively\nto specific downstream tasks, as they do not adequately address the unique\nfeatures and relationships required for different downstream tasks. In this\npaper, we propose a $\\textbf{G}$raph-based $\\textbf{U}$rban $\\textbf{R}$egion\n$\\textbf{P}$re-training and $\\textbf{P}$rompting framework ($\\textbf{GURPP}$)\nfor region representation learning. Specifically, we first construct an urban\nregion graph that integrates detailed spatial entity data for more effective\nurban region representation. Then, we develop a subgraph-centric urban region\npre-training model to capture the heterogeneous and transferable patterns of\ninteractions among entities. To further enhance the adaptability of these\nembeddings to different tasks, we design two graph-based prompting methods to\nincorporate explicit/hidden task knowledge. Extensive experiments on various\nurban region prediction tasks and different cities demonstrate the superior\nperformance of our GURPP framework.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05920v3",
    "published_date": "2024-08-12 05:00:23 UTC",
    "updated_date": "2024-08-26 11:41:28 UTC"
  },
  {
    "arxiv_id": "2408.05917v1",
    "title": "Inverse design of Non-parameterized Ventilated Acoustic Resonator via Variational Autoencoder with Acoustic Response-encoded Latent Space",
    "authors": [
      "Min Woo Cho",
      "Seok Hyeon Hwang",
      "Jun-Young Jang",
      "Jin Yeong Song",
      "Sun-kwang Hwang",
      "Kyoung Je Cha",
      "Dong Yong Park",
      "Kyungjun Song",
      "Sang Min Park"
    ],
    "abstract": "Ventilated acoustic resonator(VAR), a type of acoustic metamaterial, emerge\nas an alternative for sound attenuation in environments that require\nventilation, owing to its excellent low-frequency attenuation performance and\nflexible shape adaptability. However, due to the non-linear acoustic responses\nof VARs, the VAR designs are generally obtained within a limited parametrized\ndesign space, and the design relies on the iteration of the numerical\nsimulation which consumes a considerable amount of computational time and\nresources. This paper proposes an acoustic response-encoded variational\nautoencoder (AR-VAE), a novel variational autoencoder-based generative design\nmodel for the efficient and accurate inverse design of VAR even with\nnon-parametrized designs. The AR-VAE matches the high-dimensional acoustic\nresponse with the VAR cross-section image in the dimension-reduced latent\nspace, which enables the AR-VAE to generate various non-parametrized VAR\ncross-section images with the target acoustic response. AR-VAE generates\nnon-parameterized VARs from target acoustic responses, which show a 25-fold\nreduction in mean squared error compared to conventional deep learning-based\nparameter searching methods while exhibiting lower average mean squared error\nand peak frequency variance. By combining the inverse-designed VARs by AR-VAE,\nmulti-cavity VAR was devised for broadband and multitarget peak frequency\nattenuation. The proposed design method presents a new approach for structural\ninverse-design with a high-dimensional non-linear physical response.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05917v1",
    "published_date": "2024-08-12 04:43:40 UTC",
    "updated_date": "2024-08-12 04:43:40 UTC"
  },
  {
    "arxiv_id": "2408.05911v1",
    "title": "A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning",
    "authors": [
      "Chih-Wei Song",
      "Yu-Kai Lee",
      "Yin-Te Tsai"
    ],
    "abstract": "With the rapid development of large language models in recent years, there\nhas been an increasing demand for domain-specific Agents that can cater to the\nunique needs of enterprises and organizations. Unlike general models, which\nstrive for broad coverage, these specialized Agents rely on focused datasets\ntailored to their intended applications. This research proposes a pipeline that\nleverages the power of LLMs and the Retrieval-Augmented Generation related\nframework to construct high-quality instruction datasets for fine-tuning on\nspecific domains using custom document collections. By ingesting\ndomain-specific documents, the pipeline generates relevant and contextually\nappropriate instructions, thus effectively creating a comprehensive dataset for\nfine-tuning LLMs on the target domain. This approach overcomes the limitations\nof traditional dataset creation methods, which often rely on manual curation or\nweb-scraping techniques that may introduce noise and irrelevant data. Notably,\nour pipeline offers a dynamic solution that can quickly adapt to updates or\nmodifications in the domain-specific document collection, eliminating the need\nfor complete retraining. Additionally, it addresses the challenge of data\nscarcity by enabling the generation of instruction datasets from a limited set\nof initial documents, rendering it suitable for unpopular or specialized\ndomains where comprehensive datasets are scarce. As a case study, we apply this\napproach to the domain of psychiatry, a field requiring specialized knowledge\nand sensitive handling of patient information. The resulting fine-tuned LLM\ndemonstrates showcases the viability of the proposed approach and underscores\nits potential for widespread adoption across various industries and domains\nwhere tailored, accurate, and contextually relevant language models are\nindispensable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, SCA 2024: The 7th IEEE International Workshop on Smart\n  Computing & Applications",
    "pdf_url": "http://arxiv.org/pdf/2408.05911v1",
    "published_date": "2024-08-12 03:52:11 UTC",
    "updated_date": "2024-08-12 03:52:11 UTC"
  },
  {
    "arxiv_id": "2408.05905v2",
    "title": "Weakly Supervised Video Anomaly Detection and Localization with Spatio-Temporal Prompts",
    "authors": [
      "Peng Wu",
      "Xuerong Zhou",
      "Guansong Pang",
      "Zhiwei Yang",
      "Qingsen Yan",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "abstract": "Current weakly supervised video anomaly detection (WSVAD) task aims to\nachieve frame-level anomalous event detection with only coarse video-level\nannotations available. Existing works typically involve extracting global\nfeatures from full-resolution video frames and training frame-level classifiers\nto detect anomalies in the temporal dimension. However, most anomalous events\ntend to occur in localized spatial regions rather than the entire video frames,\nwhich implies existing frame-level feature based works may be misled by the\ndominant background information and lack the interpretation of the detected\nanomalies. To address this dilemma, this paper introduces a novel method called\nSTPrompt that learns spatio-temporal prompt embeddings for weakly supervised\nvideo anomaly detection and localization (WSVADL) based on pre-trained\nvision-language models (VLMs). Our proposed method employs a two-stream network\nstructure, with one stream focusing on the temporal dimension and the other\nprimarily on the spatial dimension. By leveraging the learned knowledge from\npre-trained VLMs and incorporating natural motion priors from raw videos, our\nmodel learns prompt embeddings that are aligned with spatio-temporal regions of\nvideos (e.g., patches of individual frames) for identify specific local regions\nof anomalies, enabling accurate video anomaly detection while mitigating the\ninfluence of background information. Without relying on detailed\nspatio-temporal annotations or auxiliary object detection/tracking, our method\nachieves state-of-the-art performance on three public benchmarks for the WSVADL\ntask.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACMMM2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05905v2",
    "published_date": "2024-08-12 03:31:29 UTC",
    "updated_date": "2024-08-13 13:55:03 UTC"
  },
  {
    "arxiv_id": "2408.13122v1",
    "title": "Semantic Variational Bayes Based on a Semantic Information Theory for Solving Latent Variables",
    "authors": [
      "Chenguang Lu"
    ],
    "abstract": "The Variational Bayesian method (VB) is used to solve the probability\ndistributions of latent variables with the minimum free energy criterion. This\ncriterion is not easy to understand, and the computation is complex. For these\nreasons, this paper proposes the Semantic Variational Bayes' method (SVB). The\nSemantic Information Theory the author previously proposed extends the\nrate-distortion function R(D) to the rate-fidelity function R(G), where R is\nthe minimum mutual information for given semantic mutual information G. SVB\ncame from the parameter solution of R(G), where the variational and iterative\nmethods originated from Shannon et al.'s research on the rate-distortion\nfunction. The constraint functions SVB uses include likelihood, truth,\nmembership, similarity, and distortion functions. SVB uses the maximum\ninformation efficiency (G/R) criterion, including the maximum semantic\ninformation criterion for optimizing model parameters and the minimum mutual\ninformation criterion for optimizing the Shannon channel. For the same tasks,\nSVB is computationally simpler than VB. The computational experiments in the\npaper include 1) using a mixture model as an example to show that the mixture\nmodel converges as G/R increases; 2) demonstrating the application of SVB in\ndata compression with a group of error ranges as the constraint; 3)\nillustrating how the semantic information measure and SVB can be used for\nmaximum entropy control and reinforcement learning in control tasks with given\nrange constraints, providing numerical evidence for balancing control's\npurposiveness and efficiency. Further research is needed to apply SVB to neural\nnetworks and deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "94A17, 94A15, 68T05, 62F15, 68P30, 68T27, 68T50, 30B42",
      "H.1.1; I.1.2; I.2.6; I.2.8; I.2.4; E.4; G.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 7 figures, 39 references",
    "pdf_url": "http://arxiv.org/pdf/2408.13122v1",
    "published_date": "2024-08-12 03:23:53 UTC",
    "updated_date": "2024-08-12 03:23:53 UTC"
  },
  {
    "arxiv_id": "2408.05899v1",
    "title": "Quantum Gradient Class Activation Map for Model Interpretability",
    "authors": [
      "Hsin-Yi Lin",
      "Huan-Hsin Tseng",
      "Samuel Yen-Chi Chen",
      "Shinjae Yoo"
    ],
    "abstract": "Quantum machine learning (QML) has recently made significant advancements in\nvarious topics. Despite the successes, the safety and interpretability of QML\napplications have not been thoroughly investigated. This work proposes using\nVariational Quantum Circuits (VQCs) for activation mapping to enhance model\ntransparency, introducing the Quantum Gradient Class Activation Map\n(QGrad-CAM). This hybrid quantum-classical computing framework leverages both\nquantum and classical strengths and gives access to the derivation of an\nexplicit formula of feature map importance. Experimental results demonstrate\nsignificant, fine-grained, class-discriminative visual explanations generated\nacross both image and speech datasets.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Submitted to IEEE SiPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.05899v1",
    "published_date": "2024-08-12 02:45:58 UTC",
    "updated_date": "2024-08-12 02:45:58 UTC"
  },
  {
    "arxiv_id": "2408.05888v1",
    "title": "Integrative Approaches in Cybersecurity and AI",
    "authors": [
      "Marwan Omar"
    ],
    "abstract": "In recent years, the convergence of cybersecurity, artificial intelligence\n(AI), and data management has emerged as a critical area of research, driven by\nthe increasing complexity and interdependence of modern technological\necosystems. This paper provides a comprehensive review and analysis of\nintegrative approaches that harness AI techniques to enhance cybersecurity\nframeworks and optimize data management practices. By exploring the synergies\nbetween these domains, we identify key trends, challenges, and future\ndirections that hold the potential to revolutionize the way organizations\nprotect, analyze, and leverage their data. Our findings highlight the necessity\nof cross-disciplinary strategies that incorporate AI-driven automation,\nreal-time threat detection, and advanced data analytics to build more resilient\nand adaptive security architectures.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.05888v1",
    "published_date": "2024-08-12 01:37:06 UTC",
    "updated_date": "2024-08-12 01:37:06 UTC"
  }
]