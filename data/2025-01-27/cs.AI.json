{
  "date": "2025-01-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、强化学习优化、多模态处理以及医疗应用等领域，亮点包括 LLM 在攻击检测和安全对齐中的创新应用，以及知名学者如 David J. Chalmers 在 AI 可解释性方面的理论探讨；令人印象深刻的文章有 PackDiT 和 Targeting Alignment，它们展示了 AI 在多任务生成和安全分类器提取上的突破。\n\n以下是今天值得关注的论文摘要，我会优先选取高影响力、话题度高的文章（如 AI 安全和 LLM 应用），并将相关主题归类快速概述。其他较常规的论文（如某些图像处理或基准测试）会简要掠过，以控制篇幅。\n\n### AI 安全与 LLM 应用\n- **PackDiT: Joint Human Motion and Text Generation via Mutual Prompting**（PackDiT: 通过互促提示的联合人体运动和文本生成）  \n  这篇论文提出了一种基于扩散模型的 PackDiT，能同时处理运动生成、文本生成和双向转换任务，实现状态-of-the-art 的文本到运动生成（FID 得分 0.106），显著提升了多模态对齐和无条件生成能力。\n\n- **Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs**（Targeting Alignment: 提取对齐 LLM 的安全分类器）  \n  作者 Jean-Charles Noirot Ferrand 等开发了一种算法，从 LLM 中提取代理安全分类器，用于评估对齐鲁棒性；在对抗攻击中，提取的分类器提升了攻击成功率至 70%，揭示了 LLM 越狱攻击的潜在漏洞。\n\n- **Smoothed Embeddings for Robust Language Models**（Smoothed Embeddings: 用于鲁棒 LLM 的平滑嵌入）  \n  该工作引入 RESTA 防御机制，通过添加噪声和聚合来提升 LLM 对越狱攻击的鲁棒性，实验显示其在权衡鲁棒性和效用时优于基线方法。\n\n- **On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks**（LLM 是否能自主执行多主机网络攻击的可行性）  \n  论文构建了 MHBench 基准，并提出 Incalmo 框架，让 LLM 通过高层抽象执行网络攻击，实现了在 9/10 网络中的目标，展示了 LLM 在安全领域的双刃剑特性。\n\n- **What is Harm? Baby Don't Hurt Me! On the Impossibility of Complete Harm Specification in AI Alignment**（什么是伤害？AI 对齐中完全伤害规范的不可能性）  \n  知名学者 Robin Young 论证了 AI 对齐中伤害规范的理论极限，使用信息理论证明完全规范不可能，并提出语义熵和安全-能力比等新指标。\n\n- **Training AI to be Loyal**（训练忠诚的 AI）  \n  作者 Sewoong Oh 等探讨了社区所有和对齐的 AI 模型，提出 OML 框架，利用开源和加密-ML 库构建忠诚 AI，强调了权限管理和经济共享的实际路径。\n\n- **Indiana Jones: There Are Always Some Useful Ancient Relics**（印第安纳·琼斯: 总有一些有用的古代遗迹）  \n  这篇论文设计了多 LLM 对话机制进行越狱攻击，实现了近乎完美的绕过率，揭示了 LLM 安全漏洞的高话题度。\n\n- **Membership Inference Attacks Against Vision-Language Models**（针对视觉-语言模型的成员推理攻击）  \n  作者 Yuke Hu 等提出新方法检测 VLMs 的训练数据泄露，达到 0.8 AUC，强调了隐私风险。\n\n### 强化学习与优化\n- **Sample-Efficient Behavior Cloning Using General Domain Knowledge**（使用通用领域知识的样本高效行为克隆）  \n  论文引入 Knowledge Informed Model (KIM)，结合大语言模型和专家知识，提高了行为克隆的样本效率，在 Lunar Lander 等任务中仅需 5 个演示即可实现鲁棒性能。\n\n- **Generalized Mission Planning for Heterogeneous Multi-Robot Teams via LLM-constructed Hierarchical Trees**（通过 LLM 构建的层次树进行异构多机器人任务规划）  \n  作者提出使用 LLM 生成层次树来优化多机器人任务，实现了灵活的子任务分解和调度。\n\n- **Upside Down Reinforcement Learning with Policy Generators**（反转强化学习与政策生成器）  \n  该工作使用 Hypernetworks 生成政策，提升了强化学习的样本效率，并在多种任务中超越基线。\n\n### 医疗与多模态应用\n- **Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models**（Brain-Adapter: 使用适配器微调的多模态 LLM 增强神经障碍分析）  \n  论文开发了 Brain-Adapter 框架，结合多模态数据提高神经障碍诊断准确性，无需高计算成本。\n\n- **Classification of Mild Cognitive Impairment Based on Dynamic Functional Connectivity Using Spatio-Temporal Transformer**（基于时空 Transformer 的动态功能连接轻度认知障碍分类）  \n  作者使用 Transformer 捕捉 fMRI 的动态连接，显著提升了 MCI 预测准确性。\n\n- **Leveraging Video Vision Transformer for Alzheimer's Disease Diagnosis from 3D Brain MRI**（利用视频视觉 Transformer 从 3D 脑 MRI 诊断阿尔茨海默病）  \n  ViTranZheimer 模型将 MRI 视为视频，实现了 98.6% 的诊断准确率，优于混合基线。\n\n其他论文，如能源预测基准、图像生成模型（如 RelightVid）和表单化验证等，虽然有贡献，但相对常规，我这里仅快速提及：这些工作推进了具体领域的技术优化，例如 RelightVid 在视频重光照中提升了时间一致性，PhysBench 提供了物理理解的基准测试，但细节限于篇幅不展开。\n\n今天的 arXiv 论文总体上反映了 AI 向安全和实际应用倾斜的趋势，读者可关注 LLM 相关内容以跟进热点。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.16577v1",
      "title": "Generative AI Uses and Risks for Knowledge Workers in a Science Organization",
      "title_zh": "翻译失败",
      "authors": [
        "Kelly B. Wagman",
        "Matthew T. Dearing",
        "Marshini Chetty"
      ],
      "abstract": "Generative AI could enhance scientific discovery by supporting knowledge\nworkers in science organizations. However, the real-world applications and\nperceived concerns of generative AI use in these organizations are uncertain.\nIn this paper, we report on a collaborative study with a US national laboratory\nwith employees spanning Science and Operations about their use of generative AI\ntools. We surveyed 66 employees, interviewed a subset (N=22), and measured\nearly adoption of an internal generative AI interface called Argo lab-wide. We\nhave four findings: (1) Argo usage data shows small but increasing use by\nScience and Operations employees; Common current and envisioned use cases for\ngenerative AI in this context conceptually fall into either a (2) copilot or\n(3) workflow agent modality; and (4) Concerns include sensitive data security,\nacademic publishing, and job impacts. Based on our findings, we make\nrecommendations for generative AI use in science and other organizations.",
      "tldr_zh": "这篇论文探讨了生成式 AI 在科学组织中知识工作者的应用及其风险，通过对66名员工的调查、22名采访以及内部工具 Argo 的使用数据分析。研究发现，Argo 的使用量虽小但呈上升趋势，常见和预期的使用场景可分为 copilot 模式（辅助工具）和 workflow agent 模式（工作流代理）。此外，担忧包括敏感数据安全、学术出版和就业影响，并基于这些发现提出生成式 AI 在科学和其他组织中的使用推荐。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI Conference on Human Factors in Computing Systems (CHI '25)",
      "pdf_url": "http://arxiv.org/pdf/2501.16577v1",
      "published_date": "2025-01-27 23:41:13 UTC",
      "updated_date": "2025-01-27 23:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:37:39.139740"
    },
    {
      "arxiv_id": "2502.15721v1",
      "title": "iTRI-QA: a Toolset for Customized Question-Answer Dataset Generation Using Language Models for Enhanced Scientific Research",
      "title_zh": "iTRI-QA：一个用于使用语言模型生成定制问答数据集的工具集，以增强科学研究",
      "authors": [
        "Qiming Liu",
        "Zhongzheng Niu",
        "Siting Liu",
        "Mao Tian"
      ],
      "abstract": "The exponential growth of AI in science necessitates efficient and scalable\nsolutions for retrieving and preserving research information. Here, we present\na tool for the development of a customized question-answer (QA) dataset, called\nInteractive Trained Research Innovator (iTRI) - QA, tailored for the needs of\nresearchers leveraging language models (LMs) to retrieve scientific knowledge\nin a QA format. Our approach integrates curated QA datasets with a specialized\nresearch paper dataset to enhance responses' contextual relevance and accuracy\nusing fine-tuned LM. The framework comprises four key steps: (1) the generation\nof high-quality and human-generated QA examples, (2) the creation of a\nstructured research paper database, (3) the fine-tuning of LMs using\ndomain-specific QA examples, and (4) the generation of QA dataset that align\nwith user queries and the curated database. This pipeline provides a dynamic\nand domain-specific QA system that augments the utility of LMs in academic\nresearch that will be applied for future research LM deployment. We demonstrate\nthe feasibility and scalability of our tool for streamlining knowledge\nretrieval in scientific contexts, paving the way for its integration into\nbroader multi-disciplinary applications.",
      "tldr_zh": "该研究介绍了 iTRI-QA，一种用于生成自定义 Question-Answer (QA) 数据集的工具集，旨在通过 Language Models (LMs) 提升科学研究的知识检索效率。该框架包括四个关键步骤：生成高质量人类QA示例、构建结构化研究论文数据库、使用领域特定QA示例微调LMs，以及创建与用户查询对齐的QA数据集。这种动态、领域特定的QA系统提高了LMs在学术研究中的实用性，并展示了其可行性和可扩展性，为多学科应用铺平道路。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15721v1",
      "published_date": "2025-01-27 23:38:39 UTC",
      "updated_date": "2025-01-27 23:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:37:50.366673"
    },
    {
      "arxiv_id": "2501.16571v1",
      "title": "Efficient Object Detection of Marine Debris using Pruned YOLO Model",
      "title_zh": "翻译失败",
      "authors": [
        "Abi Aryaza",
        "Novanto Yudistira",
        "Tibyani"
      ],
      "abstract": "Marine debris poses significant harm to marine life due to substances like\nmicroplastics, polychlorinated biphenyls, and pesticides, which damage habitats\nand poison organisms. Human-based solutions, such as diving, are increasingly\nineffective in addressing this issue. Autonomous underwater vehicles (AUVs) are\nbeing developed for efficient sea garbage collection, with the choice of object\ndetection architecture being critical. This research employs the YOLOv4 model\nfor real-time detection of marine debris using the Trash-ICRA 19 dataset,\nconsisting of 7683 images at 480x320 pixels. Various modifications-pretrained\nmodels, training from scratch, mosaic augmentation, layer freezing,\nYOLOv4-tiny, and channel pruning-are compared to enhance architecture\nefficiency. Channel pruning significantly improves detection speed, increasing\nthe base YOLOv4 frame rate from 15.19 FPS to 19.4 FPS, with only a 1.2% drop in\nmean Average Precision, from 97.6% to 96.4%.",
      "tldr_zh": "本文研究了使用修剪后的 YOLO 模型实现海洋垃圾高效检测的问题，以应对微塑料等物质对海洋生物的危害，并支持自主水下车辆 (AUVs) 的垃圾收集任务。研究基于 Trash-ICRA 19 数据集（包含 7683 张 480x320 像素图像），对 YOLOv4 模型进行了多种优化，包括预训练模型、Mosaic 增强、层冻结、YOLOv4-tiny 和通道修剪。结果表明，通道修剪显著提高了检测速度，将帧率从 15.19 FPS 提升至 19.4 FPS，同时平均精度仅下降 1.2%（从 97.6% 到 96.4%），实现了高效且准确的实时检测。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16571v1",
      "published_date": "2025-01-27 23:31:39 UTC",
      "updated_date": "2025-01-27 23:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:38:02.882742"
    },
    {
      "arxiv_id": "2501.16551v1",
      "title": "PackDiT: Joint Human Motion and Text Generation via Mutual Prompting",
      "title_zh": "PackDiT：通过相互提示实现人类动作和文本的联合生成",
      "authors": [
        "Zhongyu Jiang",
        "Wenhao Chai",
        "Zhuoran Zhou",
        "Cheng-Yen Yang",
        "Hsiang-Wei Huang",
        "Jenq-Neng Hwang"
      ],
      "abstract": "Human motion generation has advanced markedly with the advent of diffusion\nmodels. Most recent studies have concentrated on generating motion sequences\nbased on text prompts, commonly referred to as text-to-motion generation.\nHowever, the bidirectional generation of motion and text, enabling tasks such\nas motion-to-text alongside text-to-motion, has been largely unexplored. This\ncapability is essential for aligning diverse modalities and supports\nunconditional generation. In this paper, we introduce PackDiT, the first\ndiffusion-based generative model capable of performing various tasks\nsimultaneously, including motion generation, motion prediction, text\ngeneration, text-to-motion, motion-to-text, and joint motion-text generation.\nOur core innovation leverages mutual blocks to integrate multiple diffusion\ntransformers (DiTs) across different modalities seamlessly. We train PackDiT on\nthe HumanML3D dataset, achieving state-of-the-art text-to-motion performance\nwith an FID score of 0.106, along with superior results in motion prediction\nand in-between tasks. Our experiments further demonstrate that diffusion models\nare effective for motion-to-text generation, achieving performance comparable\nto that of autoregressive models.",
      "tldr_zh": "该论文提出 PackDiT，一种基于 diffusion models 的生成模型，通过 mutual blocks 整合多个 diffusion transformers (DiTs)，实现人类动作和文本的双向生成，包括动作生成、文本生成、文本到动作、动作到文本以及联合生成等任务。核心创新在于利用 mutual prompting 机制无缝整合不同模态，提升生成效率和准确性。在 HumanML3D 数据集上，PackDiT 达到了 state-of-the-art 的文本到动作性能（FID score 0.106），并在动作预测和其他任务上表现出色。实验结果还表明，diffusion models 在动作到文本生成上与 autoregressive models 相当有效，为多模态生成应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16551v1",
      "published_date": "2025-01-27 22:51:45 UTC",
      "updated_date": "2025-01-27 22:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:38:14.705689"
    },
    {
      "arxiv_id": "2501.16546v1",
      "title": "Sample-Efficient Behavior Cloning Using General Domain Knowledge",
      "title_zh": "基于一般领域知识的样本高效行为克隆",
      "authors": [
        "Feiyu Zhu",
        "Jean Oh",
        "Reid Simmons"
      ],
      "abstract": "Behavior cloning has shown success in many sequential decision-making tasks\nby learning from expert demonstrations, yet they can be very sample inefficient\nand fail to generalize to unseen scenarios. One approach to these problems is\nto introduce general domain knowledge, such that the policy can focus on the\nessential features and may generalize to unseen states by applying that\nknowledge. Although this knowledge is easy to acquire from the experts, it is\nhard to be combined with learning from individual examples due to the lack of\nsemantic structure in neural networks and the time-consuming nature of feature\nengineering. To enable learning from both general knowledge and specific\ndemonstration trajectories, we use a large language model's coding capability\nto instantiate a policy structure based on expert domain knowledge expressed in\nnatural language and tune the parameters in the policy with demonstrations. We\nname this approach the Knowledge Informed Model (KIM) as the structure reflects\nthe semantics of expert knowledge. In our experiments with lunar lander and car\nracing tasks, our approach learns to solve the tasks with as few as 5\ndemonstrations and is robust to action noise, outperforming the baseline model\nwithout domain knowledge. This indicates that with the help of large language\nmodels, we can incorporate domain knowledge into the structure of the policy,\nincreasing sample efficiency for behavior cloning.",
      "tldr_zh": "本文提出 Knowledge Informed Model (KIM)，一种利用大语言模型 (Large Language Model) 的编码能力，将一般领域知识 (General Domain Knowledge) 融入行为克隆 (Behavior Cloning) 中，以提高样本效率和泛化能力。KIM 通过从专家自然语言描述中实例化政策结构，并用演示数据微调参数，解决了神经网络语义结构缺失和特征工程耗时的问题。在 lunar lander 和 car racing 任务的实验中，KIM 仅需 5 个演示即可学会任务，并对动作噪声表现出色，优于无领域知识的基线模型，从而证明了这种方法在顺序决策任务中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16546v1",
      "published_date": "2025-01-27 22:40:11 UTC",
      "updated_date": "2025-01-27 22:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:38:28.099144"
    },
    {
      "arxiv_id": "2501.16539v1",
      "title": "Generalized Mission Planning for Heterogeneous Multi-Robot Teams via LLM-constructed Hierarchical Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Piyush Gupta",
        "David Isele",
        "Enna Sachdeva",
        "Pin-Hao Huang",
        "Behzad Dariush",
        "Kwonjoon Lee",
        "Sangjae Bae"
      ],
      "abstract": "We present a novel mission-planning strategy for heterogeneous multi-robot\nteams, taking into account the specific constraints and capabilities of each\nrobot. Our approach employs hierarchical trees to systematically break down\ncomplex missions into manageable sub-tasks. We develop specialized APIs and\ntools, which are utilized by Large Language Models (LLMs) to efficiently\nconstruct these hierarchical trees. Once the hierarchical tree is generated, it\nis further decomposed to create optimized schedules for each robot, ensuring\nadherence to their individual constraints and capabilities. We demonstrate the\neffectiveness of our framework through detailed examples covering a wide range\nof missions, showcasing its flexibility and scalability.",
      "tldr_zh": "这篇论文提出了一种通用任务规划策略，用于异构多机器人团队，考虑每个机器人的特定约束和能力。方法通过 Large Language Models (LLMs) 利用开发的 APIs 和工具来构建 hierarchical trees，从而系统地将复杂任务分解成可管理的子任务，并进一步优化每个机器人的调度。实验结果通过多种任务示例证明了该框架的有效性、灵活性和可扩展性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16539v1",
      "published_date": "2025-01-27 22:20:48 UTC",
      "updated_date": "2025-01-27 22:20:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:38:38.433881"
    },
    {
      "arxiv_id": "2501.17201v1",
      "title": "Smart Cubing for Graph Search: A Comparative Study",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Kirchweger",
        "Hai Xia",
        "Tomáš Peitl",
        "Stefan Szeider"
      ],
      "abstract": "Parallel solving via cube-and-conquer is a key method for scaling SAT solvers\nto hard instances. While cube-and-conquer has proven successful for pure SAT\nproblems, notably the Pythagorean triples conjecture, its application to SAT\nsolvers extended with propagators presents unique challenges, as these\npropagators learn constraints dynamically during the search.\n  We study this problem using SAT Modulo Symmetries (SMS) as our primary test\ncase, where a symmetry-breaking propagator reduces the search space by learning\nconstraints that eliminate isomorphic graphs. Through extensive experimentation\ncomprising over 10,000 CPU hours, we systematically evaluate different\ncube-and-conquer variants on three well-studied combinatorial problems. Our\nmethodology combines prerun phases to collect learned constraints, various\ncubing strategies, and parameter tuning via algorithm configuration and\nLLM-generated design suggestions.\n  The comprehensive empirical evaluation provides new insights into effective\ncubing strategies for propagator-based SAT solving, with our best method\nachieving speedups of 2-3x from improved cubing and parameter tuning, providing\nan additional 1.5-2x improvement on harder instances.",
      "tldr_zh": "这篇论文对 cube-and-conquer 方法在扩展 propagators 的 SAT 求解器中的应用进行了比较研究，重点探讨了其在 SAT Modulo Symmetries (SMS) 等场景下的挑战和优化策略。研究团队通过超过 10,000 CPU 小时的实验，结合 prerun 阶段收集约束、多种 cubing 策略以及算法配置和 LLM 生成的设计建议，系统评估了三个组合问题。结果显示，最佳方法通过改进 cubing 和参数调整实现了 2-3 倍的速度提升，在更难的实例上额外获得 1.5-2 倍的性能改进，为 propagator-based SAT 求解提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17201v1",
      "published_date": "2025-01-27 22:15:54 UTC",
      "updated_date": "2025-01-27 22:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:38:51.283232"
    },
    {
      "arxiv_id": "2501.16534v1",
      "title": "Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Charles Noirot Ferrand",
        "Yohan Beugin",
        "Eric Pauley",
        "Ryan Sheatsley",
        "Patrick McDaniel"
      ],
      "abstract": "Alignment in large language models (LLMs) is used to enforce guidelines such\nas safety. Yet, alignment fails in the face of jailbreak attacks that modify\ninputs to induce unsafe outputs. In this paper, we present and evaluate a\nmethod to assess the robustness of LLM alignment. We observe that alignment\nembeds a safety classifier in the target model that is responsible for deciding\nbetween refusal and compliance. We seek to extract an approximation of this\nclassifier, called a surrogate classifier, from the LLM. We develop an\nalgorithm for identifying candidate classifiers from subsets of the LLM model.\nWe evaluate the degree to which the candidate classifiers approximate the\nmodel's embedded classifier in benign (F1 score) and adversarial (using\nsurrogates in a white-box attack) settings. Our evaluation shows that the best\ncandidates achieve accurate agreement (an F1 score above 80%) using as little\nas 20% of the model architecture. Further, we find attacks mounted on the\nsurrogate models can be transferred with high accuracy. For example, a\nsurrogate using only 50% of the Llama 2 model achieved an attack success rate\n(ASR) of 70%, a substantial improvement over attacking the LLM directly, where\nwe only observed a 22% ASR. These results show that extracting surrogate\nclassifiers is a viable (and highly effective) means for modeling (and therein\naddressing) the vulnerability of aligned models to jailbreaking attacks.",
      "tldr_zh": "这篇论文探讨了从对齐的大型语言模型(LLMs)中提取安全分类器(safety classifier)的方法，以评估其对越狱攻击(jailbreak attacks)的鲁棒性。研究人员开发了一种算法，从LLMs的子集（如20%的模型架构）中提取代理分类器(surrogate classifier)，并证明这些代理分类器能准确逼近原分类器，达到80%以上的F1分数。实验结果显示，使用代理分类器进行的攻击可以高效转移，例如在Llama 2模型的50%部分上，攻击成功率(ASR)达到70%，远高于直接攻击的22%。这项工作为识别和缓解对齐模型漏洞提供了有效手段。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16534v1",
      "published_date": "2025-01-27 22:13:05 UTC",
      "updated_date": "2025-01-27 22:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:39:03.311672"
    },
    {
      "arxiv_id": "2501.16525v1",
      "title": "Multi-Objective Deep-Learning-based Biomechanical Deformable Image Registration with MOREA",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Andreadis",
        "Eduard Ruiz Munné",
        "Thomas H. W. Bäck",
        "Peter A. N. Bosman",
        "Tanja Alderliesten"
      ],
      "abstract": "When choosing a deformable image registration (DIR) approach for images with\nlarge deformations and content mismatch, the realism of found transformations\noften needs to be traded off against the required runtime. DIR approaches using\ndeep learning (DL) techniques have shown remarkable promise in instantly\npredicting a transformation. However, on difficult registration problems, the\nrealism of these transformations can fall short. DIR approaches using\nbiomechanical, finite element modeling (FEM) techniques can find more realistic\ntransformations, but tend to require much longer runtimes. This work proposes\nthe first hybrid approach to combine them, with the aim of getting the best of\nboth worlds. This hybrid approach, called DL-MOREA, combines a recently\nintroduced multi-objective DL-based DIR approach which leverages the VoxelMorph\nframework, called DL-MODIR, with MOREA, an evolutionary algorithm-based,\nmulti-objective DIR approach in which a FEM-like biomechanical mesh\ntransformation model is used. In our proposed hybrid approach, the DL results\nare used to smartly initialize MOREA, with the aim of more efficiently\noptimizing its mesh transformation model. We empirically compare DL-MOREA\nagainst its components, DL-MODIR and MOREA, on CT scan pairs capturing large\nbladder filling differences of 15 cervical cancer patients. While MOREA\nrequires a median runtime of 45 minutes, DL-MOREA can already find high-quality\ntransformations after 5 minutes. Compared to the DL-MODIR transformations, the\ntransformations found by DL-MOREA exhibit far less folding and improve or\npreserve the bladder contour distance error.",
      "tldr_zh": "本文提出了一种混合方法DL-MOREA，用于可变形图像配准(DIR)，将深度学习(DL)技术与生物力学有限元建模(FEM-like)相结合，旨在解决大变形和内容不匹配问题，同时平衡变换真实性和运行效率。DL-MOREA使用基于VoxelMorph的多目标DL方法DL-MODIR来初始化MOREA算法，从而更高效地优化网格变换模型。在实验中，对15名宫颈癌患者的CT扫描图像进行测试，DL-MOREA仅需5分钟即可获得高质量变换，比MOREA减少了90%的运行时间，并显著降低变换折叠问题，同时改善或保持膀胱轮廓距离错误。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Pre-print for the SPIE Medical Imaging: Image Processing Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.16525v1",
      "published_date": "2025-01-27 21:50:12 UTC",
      "updated_date": "2025-01-27 21:50:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:39:15.760773"
    },
    {
      "arxiv_id": "2501.16516v1",
      "title": "How well can LLMs Grade Essays in Arabic?",
      "title_zh": "大语言模型在阿拉伯语作文评分中的表现如何？",
      "authors": [
        "Rayed Ghazawi",
        "Edwin Simpson"
      ],
      "abstract": "This research assesses the effectiveness of state-of-the-art large language\nmodels (LLMs), including ChatGPT, Llama, Aya, Jais, and ACEGPT, in the task of\nArabic automated essay scoring (AES) using the AR-AES dataset. It explores\nvarious evaluation methodologies, including zero-shot, few-shot in-context\nlearning, and fine-tuning, and examines the influence of instruction-following\ncapabilities through the inclusion of marking guidelines within the prompts. A\nmixed-language prompting strategy, integrating English prompts with Arabic\ncontent, was implemented to improve model comprehension and performance. Among\nthe models tested, ACEGPT demonstrated the strongest performance across the\ndataset, achieving a Quadratic Weighted Kappa (QWK) of 0.67, but was\noutperformed by a smaller BERT-based model with a QWK of 0.88. The study\nidentifies challenges faced by LLMs in processing Arabic, including\ntokenization complexities and higher computational demands. Performance\nvariation across different courses underscores the need for adaptive models\ncapable of handling diverse assessment formats and highlights the positive\nimpact of effective prompt engineering on improving LLM outputs. To the best of\nour knowledge, this study is the first to empirically evaluate the performance\nof multiple generative Large Language Models (LLMs) on Arabic essays using\nauthentic student data.",
      "tldr_zh": "这篇论文评估了ChatGPT、Llama、Aya、Jais和ACEGPT等LLMs在阿拉伯语自动作文评分(AES)任务上的表现，使用AR-AES数据集。\n研究探索了零样本学习、少样本学习、微调等方法，并通过混合语言提示策略（结合英语提示和阿拉伯内容）来提升模型的指令遵循能力和性能。\n结果显示，ACEGPT取得了最高的Quadratic Weighted Kappa (QWK)分数为0.67，但仍被一个较小的BERT模型（QWK 0.88）超越。\n论文还指出了LLMs处理阿拉伯语的挑战，包括分词复杂性和高计算需求，并强调了性能在不同课程间的差异，突出了有效提示工程和适应性模型的重要性，这是首个使用真实学生数据的实证研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.16516v1",
      "published_date": "2025-01-27 21:30:02 UTC",
      "updated_date": "2025-01-27 21:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:39:28.145109"
    },
    {
      "arxiv_id": "2501.17200v1",
      "title": "Improving LLM Leaderboards with Psychometrical Methodology",
      "title_zh": "使用心理测量学方法改进 LLM 排行榜",
      "authors": [
        "Denis Federiakin"
      ],
      "abstract": "The rapid development of large language models (LLMs) has necessitated the\ncreation of benchmarks to evaluate their performance. These benchmarks resemble\nhuman tests and surveys, as they consist of sets of questions designed to\nmeasure emergent properties in the cognitive behavior of these systems.\nHowever, unlike the well-defined traits and abilities studied in social\nsciences, the properties measured by these benchmarks are often vaguer and less\nrigorously defined. The most prominent benchmarks are often grouped into\nleaderboards for convenience, aggregating performance metrics and enabling\ncomparisons between models. Unfortunately, these leaderboards typically rely on\nsimplistic aggregation methods, such as taking the average score across\nbenchmarks. In this paper, we demonstrate the advantages of applying\ncontemporary psychometric methodologies - originally developed for human tests\nand surveys - to improve the ranking of large language models on leaderboards.\nUsing data from the Hugging Face Leaderboard as an example, we compare the\nresults of the conventional naive ranking approach with a psychometrically\ninformed ranking. The findings highlight the benefits of adopting psychometric\ntechniques for more robust and meaningful evaluation of LLM performance.",
      "tldr_zh": "这篇论文探讨了如何通过心理测量学方法（psychometrical methodology）改进大型语言模型（LLMs）的排行榜（leaderboards），以解决现有基准测试定义模糊和简单聚合（如平均分数）的问题。作者使用Hugging Face Leaderboard的数据，将传统简单排名方法与心理测量学-informed排名进行比较，证明了后者能提供更稳健的评估。结果显示，这种方法显著提升了对LLMs认知行为的测量准确性，从而为更可靠的模型性能比较奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "53 pages, 10 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.17200v1",
      "published_date": "2025-01-27 21:21:46 UTC",
      "updated_date": "2025-01-27 21:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:39:38.118117"
    },
    {
      "arxiv_id": "2501.16510v1",
      "title": "Decrypting the temperature field in flow boiling with latent diffusion models",
      "title_zh": "翻译失败",
      "authors": [
        "UngJin Na",
        "JunYoung Seo",
        "Taeil Kim",
        "ByongGuk Jeon",
        "HangJin Jo"
      ],
      "abstract": "This paper presents an innovative method using Latent Diffusion Models (LDMs)\nto generate temperature fields from phase indicator maps. By leveraging the\nBubbleML dataset from numerical simulations, the LDM translates phase field\ndata into corresponding temperature distributions through a two-stage training\nprocess involving a vector-quantized variational autoencoder (VQVAE) and a\ndenoising autoencoder. The resulting model effectively reconstructs complex\ntemperature fields at interfaces. Spectral analysis indicates a high degree of\nagreement with ground truth data in the low to mid wavenumber ranges, even\nthough some inconsistencies are observed at higher wavenumbers, suggesting\nareas for further enhancement. This machine learning approach significantly\nreduces the computational burden of traditional simulations and improves the\nprecision of experimental calibration methods. Future work will focus on\nrefining the model's ability to represent small-scale turbulence and expanding\nits applicability to a broader range of boiling conditions.",
      "tldr_zh": "本论文提出了一种创新方法，使用 Latent Diffusion Models (LDMs) 从相位指示图生成流沸腾中的温度场，基于 BubbleML 数据集进行训练。\n该方法采用两阶段过程，包括 vector-quantized variational autoencoder (VQVAE) 和 denoising autoencoder，实现复杂温度场的有效重建。\n频谱分析显示，模型在低到中波数范围与真实数据高度一致，但高波数范围存在不一致性，整体上显著降低了传统模拟的计算负担并提升了实验校准的精确性。\n未来工作将优化模型对小规模湍流的处理，并扩展其适用性到更广泛的沸腾条件。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16510v1",
      "published_date": "2025-01-27 21:18:05 UTC",
      "updated_date": "2025-01-27 21:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:39:51.917901"
    },
    {
      "arxiv_id": "2501.16509v1",
      "title": "Reinforcement Learning for Quantum Circuit Design: Using Matrix Representations",
      "title_zh": "强化学习用于量子电路设计：利用矩阵表示",
      "authors": [
        "Zhiyuan Wang",
        "Chunlin Feng",
        "Christopher Poon",
        "Lijian Huang",
        "Xingjian Zhao",
        "Yao Ma",
        "Tianfan Fu",
        "Xiao-Yang Liu"
      ],
      "abstract": "Quantum computing promises advantages over classical computing. The\nmanufacturing of quantum hardware is in the infancy stage, called the Noisy\nIntermediate-Scale Quantum (NISQ) era. A major challenge is automated quantum\ncircuit design that map a quantum circuit to gates in a universal gate set. In\nthis paper, we present a generic MDP modeling and employ Q-learning and DQN\nalgorithms for quantum circuit design. By leveraging the power of deep\nreinforcement learning, we aim to provide an automatic and scalable approach\nover traditional hand-crafted heuristic methods.",
      "tldr_zh": "本研究针对量子计算中量子电路设计的自动化挑战，特别是将电路映射到通用门集的问题，提出了基于Markov Decision Process (MDP)的通用建模方法。论文采用Q-learning和Deep Q-Network (DQN)算法，通过深度强化学习实现电路设计过程。该方法提供了一种自动且可扩展的替代方案，超越传统的手工启发式方法，有望提升量子计算在Noisy Intermediate-Scale Quantum (NISQ)时代的发展潜力。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16509v1",
      "published_date": "2025-01-27 21:17:58 UTC",
      "updated_date": "2025-01-27 21:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:40:02.998388"
    },
    {
      "arxiv_id": "2501.16507v1",
      "title": "Characterizing Network Structure of Anti-Trans Actors on TikTok",
      "title_zh": "翻译失败",
      "authors": [
        "Maxyn Leitner",
        "Rebecca Dorn",
        "Fred Morstatter",
        "Kristina Lerman"
      ],
      "abstract": "The recent proliferation of short form video social media sites such as\nTikTok has been effectively utilized for increased visibility, communication,\nand community connection amongst trans/nonbinary creators online. However,\nthese same platforms have also been exploited by right-wing actors targeting\ntrans/nonbinary people, enabling such anti-trans actors to efficiently spread\nhate speech and propaganda. Given these divergent groups, what are the\ndifferences in network structure between anti-trans and pro-trans communities\non TikTok, and to what extent do they amplify the effects of anti-trans\ncontent? In this paper, we collect a sample of TikTok videos containing pro and\nanti-trans content, and develop a taxonomy of trans related sentiment to enable\nthe classification of content on TikTok, and ultimately analyze the reply\nnetwork structures of pro-trans and anti-trans communities. In order to\naccomplish this, we worked with hired expert data annotators from the\ntrans/nonbinary community in order to generate a sample of highly accurately\nlabeled data. From this subset, we utilized a novel classification pipeline\nleveraging Retrieval-Augmented Generation (RAG) with annotated examples and\ntaxonomy definitions to classify content into pro-trans, anti-trans, or neutral\ncategories. We find that incorporating our taxonomy and its logics into our\nclassification engine results in improved ability to differentiate trans\nrelated content, and that Results from network analysis indicate many\ninteractions between posters of pro-trans and anti-trans content exist, further\ndemonstrating targeting of trans individuals, and demonstrating the need for\nbetter content moderation tools",
      "tldr_zh": "本研究分析了TikTok平台上反跨性别（anti-trans）参与者的网络结构，并比较了反跨性别和支持跨性别（pro-trans）社区的差异及其内容影响力。研究团队收集了相关视频样本，开发了跨性别相关情感的taxonomy分类体系，并利用Retrieval-Augmented Generation (RAG)结合专家标注数据构建分类管道，以准确地将内容分类为支持、反或中立。结果显示，这种方法显著提高了内容区分能力，而网络分析揭示了支持和反跨性别内容之间的大量互动，表明存在针对跨性别个体的行为，并强调了需要更有效的内容审核工具。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI",
        "I.2.7; J.4; H.3.3; K.4.2"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 4 figures. 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.16507v1",
      "published_date": "2025-01-27 21:14:18 UTC",
      "updated_date": "2025-01-27 21:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:40:14.973871"
    },
    {
      "arxiv_id": "2501.16504v1",
      "title": "Digital Twin Enabled Site Specific Channel Precoding: Over the Air CIR Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Majumder Haider",
        "Imtiaz Ahmed",
        "Zoheb Hassan",
        "Timothy J. O'Shea",
        "Lingjia Liu",
        "Danda B. Rawat"
      ],
      "abstract": "This paper investigates the significance of designing a reliable,\nintelligent, and true physical environment-aware precoding scheme by leveraging\nan accurately designed channel twin model to obtain realistic channel state\ninformation (CSI) for cellular communication systems. Specifically, we propose\na fine-tuned multi-step channel twin design process that can render CSI very\nclose to the CSI of the actual environment. After generating a precise CSI, we\nexecute precoding using the obtained CSI at the transmitter end. We demonstrate\na two-step parameters' tuning approach to design channel twin by ray tracing\n(RT) emulation, then further fine-tuning of CSI by employing an artificial\nintelligence (AI) based algorithm can significantly reduce the gap between\nactual CSI and the fine-tuned digital twin (DT) rendered CSI. The simulation\nresults show the effectiveness of the proposed novel approach in designing a\ntrue physical environment-aware channel twin model.",
      "tldr_zh": "本论文探讨了利用Digital Twin模型设计一种可靠、智能且真实物理环境感知的信道预编码方案，以获取精确的信道状态信息（CSI）用于蜂窝通信系统。具体方法包括一个多步信道孪生设计过程：先通过Ray Tracing (RT)仿真进行参数调整，然后采用AI算法进一步微调CSI，从而显著减少实际CSI与数字孪生渲染CSI之间的差距。模拟结果证明，该方法在预编码性能上表现出色，为环境感知通信技术提供了有效途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16504v1",
      "published_date": "2025-01-27 21:10:07 UTC",
      "updated_date": "2025-01-27 21:10:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:40:26.760848"
    },
    {
      "arxiv_id": "2501.16497v1",
      "title": "Smoothed Embeddings for Robust Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Hase",
        "Md Rafi Ur Rashid",
        "Ashley Lewis",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "abstract": "Improving the safety and reliability of large language models (LLMs) is a\ncrucial aspect of realizing trustworthy AI systems. Although alignment methods\naim to suppress harmful content generation, LLMs are often still vulnerable to\njailbreaking attacks that employ adversarial inputs that subvert alignment and\ninduce harmful outputs. We propose the Randomized Embedding Smoothing and Token\nAggregation (RESTA) defense, which adds random noise to the embedding vectors\nand performs aggregation during the generation of each output token, with the\naim of better preserving semantic information. Our experiments demonstrate that\nour approach achieves superior robustness versus utility tradeoffs compared to\nthe baseline defenses.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)面对jailbreaking attacks的问题，提出了一种Randomized Embedding Smoothing and Token Aggregation (RESTA)防御机制，以提升模型的安全性和可靠性。RESTA方法通过向嵌入向量添加随机噪声并在生成每个输出标记时进行聚合，从而更好地保留语义信息，同时抑制有害内容的生成。实验结果显示，该方法在鲁棒性与实用性权衡上优于基线防御，提供了一种更有效的LLMs保护策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "stat.ML",
        "68T07 (Primary), 68T50 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented in the Safe Generative AI Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.16497v1",
      "published_date": "2025-01-27 20:57:26 UTC",
      "updated_date": "2025-01-27 20:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:40:38.772242"
    },
    {
      "arxiv_id": "2501.16490v1",
      "title": "Towards Robust Stability Prediction in Smart Grids: GAN-based Approach under Data Constraints and Adversarial Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Emad Efatinasab",
        "Alessandro Brighente",
        "Denis Donadel",
        "Mauro Conti",
        "Mirco Rampazzo"
      ],
      "abstract": "Smart grids are critical for addressing the growing energy demand due to\nglobal population growth and urbanization. They enhance efficiency,\nreliability, and sustainability by integrating renewable energy. Ensuring their\navailability and safety requires advanced operational control and safety\nmeasures. Researchers employ AI and machine learning to assess grid stability,\nbut challenges like the lack of datasets and cybersecurity threats, including\nadversarial attacks, persist. In particular, data scarcity is a key issue:\nobtaining grid instability instances is tough due to the need for significant\nexpertise, resources, and time. However, they are essential to test novel\nresearch advancements and security mitigations. In this paper, we introduce a\nnovel framework to detect instability in smart grids by employing only stable\ndata. It relies on a Generative Adversarial Network (GAN) where the generator\nis trained to create instability data that are used along with stable data to\ntrain the discriminator. Moreover, we include a new adversarial training layer\nto improve robustness against adversarial attacks. Our solution, tested on a\ndataset composed of real-world stable and unstable samples, achieve accuracy up\nto 97.5\\% in predicting grid stability and up to 98.9\\% in detecting\nadversarial attacks. Moreover, we implemented our model in a single-board\ncomputer demonstrating efficient real-time decision-making with an average\nresponse time of less than 7ms. Our solution improves prediction accuracy and\nresilience while addressing data scarcity in smart grid management.",
      "tldr_zh": "本研究针对智能电网(smart grids)稳定性预测中的数据稀缺和对抗攻击(adversarial attacks)挑战，提出了一种基于生成对抗网络(GAN)的创新框架。该框架利用GAN的生成器仅从稳定数据中创建不稳定实例，并结合这些数据训练判别器，同时添加对抗训练层以提升模型的鲁棒性。在真实数据集上的实验显示，该方法在预测电网稳定性时准确率高达97.5%，在检测对抗攻击时准确率达98.9%，并在单板计算机上实现了平均响应时间小于7ms的实时决策。该框架有效解决了数据约束问题，提高了智能电网管理的准确性和弹性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "This work has been submitted to the IEEE Internet of Things Journal\n  for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2501.16490v1",
      "published_date": "2025-01-27 20:48:25 UTC",
      "updated_date": "2025-01-27 20:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:40:51.651771"
    },
    {
      "arxiv_id": "2501.16471v1",
      "title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Dahan",
        "Gabriel Bénédict",
        "Logan Z. J. Williams",
        "Yourong Guo",
        "Daniel Rueckert",
        "Robert Leech",
        "Emma C. Robinson"
      ],
      "abstract": "Current AI frameworks for brain decoding and encoding, typically train and\ntest models within the same datasets. This limits their utility for brain\ncomputer interfaces (BCI) or neurofeedback, for which it would be useful to\npool experiences across individuals to better simulate stimuli not sampled\nduring training. A key obstacle to model generalisation is the degree of\nvariability of inter-subject cortical organisation, which makes it difficult to\nalign or compare cortical signals across participants. In this paper we address\nthis through the use of surface vision transformers, which build a\ngeneralisable model of cortical functional dynamics, through encoding the\ntopography of cortical networks and their interactions as a moving image across\na surface. This is then combined with tri-modal self-supervised contrastive\n(CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval\nof visual and auditory stimuli from patterns of cortical activity (and\nvice-versa). We validate our approach on 7T task-fMRI data from 174 healthy\nparticipants engaged in the movie-watching experiment from the Human Connectome\nProject (HCP). Results show that it is possible to detect which movie clips an\nindividual is watching purely from their brain activity, even for individuals\nand movies not seen during training. Further analysis of attention maps reveals\nthat our model captures individual patterns of brain activity that reflect\nsemantic and visual systems. This opens the door to future personalised\nsimulations of brain function. Code & pre-trained models will be made available\nat https://github.com/metrics-lab/sim, processed data for training will be\navailable upon request at https://gin.g-node.org/Sdahan30/sim.",
      "tldr_zh": "该论文提出SIM框架，使用表面视觉Transformer来构建可泛化的皮层功能动态模型，解决fMRI脑解码中跨个体变异性问题，并结合三模态自监督对比学习(CLIP)对齐音频、视频和fMRI模态，实现从脑活动模式中检索视觉和听觉刺激。实验在Human Connectome Project的7T任务fMRI数据上验证，涉及174名参与者观看电影，结果显示模型能准确检测训练中未见过的个体和电影片段。进一步分析表明，SIM捕捉了反映语义和视觉系统的个体脑活动模式，为脑机接口(BCI)和个性化脑功能模拟铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.AS",
        "eess.IV",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16471v1",
      "published_date": "2025-01-27 20:05:17 UTC",
      "updated_date": "2025-01-27 20:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:41:03.876850"
    },
    {
      "arxiv_id": "2501.16466v3",
      "title": "On the Feasibility of Using LLMs to Autonomously Execute Multi-host Network Attacks",
      "title_zh": "关于使用 LLMs 自主执行多主机网络攻击的可行性",
      "authors": [
        "Brian Singer",
        "Keane Lucas",
        "Lakshmi Adiga",
        "Meghna Jain",
        "Lujo Bauer",
        "Vyas Sekar"
      ],
      "abstract": "LLMs have shown preliminary promise in some security tasks and CTF\nchallenges. Real cyberattacks are often multi-host network attacks, which\ninvolve executing a number of steps across multiple hosts such as conducting\nreconnaissance, exploiting vulnerabilities, and using compromised hosts to\nexfiltrate data. To date, the extent to which LLMs can autonomously execute\nmulti-host network attacks} is not well understood. To this end, our first\ncontribution is MHBench, an open-source multi-host attack benchmark with 10\nrealistic emulated networks (from 25 to 50 hosts). We find that popular LLMs\nincluding modern reasoning models (e.g., GPT4o, Gemini 2.5 Pro, Sonnet 3.7\nThinking) with state-of-art security-relevant prompting strategies (e.g.,\nPentestGPT, CyberSecEval3) cannot autonomously execute multi-host network\nattacks. To enable LLMs to autonomously execute such attacks, our second\ncontribution is Incalmo, an high-level abstraction layer. Incalmo enables LLMs\nto specify high-level actions (e.g., infect a host, scan a network). Incalmo's\ntranslation layer converts these actions into lower-level primitives (e.g.,\ncommands to exploit tools) through expert agents. In 9 out of 10 networks in\nMHBench, LLMs using Incalmo achieve at least some of the attack goals. Even\nsmaller LLMs (e.g., Haiku 3.5, Gemini 2 Flash) equipped with Incalmo achieve\nall goals in 5 of 10 environments. We also validate the key role of high-level\nactions in Incalmo's abstraction in enabling LLMs to autonomously execute such\nattacks.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在自主执行多主机网络攻击的可行性，引入了开源基准MHBench，该基准包含10个模拟网络（25至50个主机），用于评估LLMs在攻击任务（如侦察、漏洞利用和数据外泄）中的性能。实验发现，主流LLMs（如GPT4o、Gemini 2.5 Pro和Sonnet 3.7 Thinking）即使采用先进提示策略（如PentestGPT和CyberSecEval3），也无法独立完成这些攻击。论文提出Incalmo框架，一个高层抽象层，允许LLMs指定高层动作（如感染主机或扫描网络），并通过翻译层转换为底层命令，从而在9个网络中实现部分攻击目标，甚至较小LLMs（如Haiku 3.5）在5个环境中完成所有目标，突显高层抽象的关键作用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16466v3",
      "published_date": "2025-01-27 19:58:29 UTC",
      "updated_date": "2025-05-16 14:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:41:15.502285"
    },
    {
      "arxiv_id": "2501.16453v1",
      "title": "Detecting Zero-Day Attacks in Digital Substations via In-Context Learning",
      "title_zh": "通过上下文学习检测数字变电站中的零日攻击",
      "authors": [
        "Faizan Manzoor",
        "Vanshaj Khattar",
        "Akila Herath",
        "Clifton Black",
        "Matthew C Nielsen",
        "Junho Hong",
        "Chen-Ching Liu",
        "Ming Jin"
      ],
      "abstract": "The occurrences of cyber attacks on the power grids have been increasing\nevery year, with novel attack techniques emerging every year. In this paper, we\naddress the critical challenge of detecting novel/zero-day attacks in digital\nsubstations that employ the IEC-61850 communication protocol. While many\nheuristic and machine learning (ML)-based methods have been proposed for attack\ndetection in IEC-61850 digital substations, generalization to novel or zero-day\nattacks remains challenging. We propose an approach that leverages the\nin-context learning (ICL) capability of the transformer architecture, the\nfundamental building block of large language models. The ICL approach enables\nthe model to detect zero-day attacks and learn from a few examples of that\nattack without explicit retraining. Our experiments on the IEC-61850 dataset\ndemonstrate that the proposed method achieves more than $85\\%$ detection\naccuracy on zero-day attacks while the existing state-of-the-art baselines\nfail. This work paves the way for building more secure and resilient digital\nsubstations of the future.",
      "tldr_zh": "本论文针对电力网格中日益增多的网络攻击，特别是针对使用 IEC-61850 协议的数字变电站的 zero-day attacks，提出了一种基于 in-context learning (ICL) 的检测方法。该方法利用 transformer 架构的 ICL 能力，使模型能够在不进行显式重新训练的情况下，从少量攻击示例中快速学习和检测新型攻击。在 IEC-61850 数据集上的实验显示，该方法对 zero-day attacks 的检测准确率超过 85%，远优于现有基准模型。该研究为构建更安全和弹性的数字变电站提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16453v1",
      "published_date": "2025-01-27 19:24:00 UTC",
      "updated_date": "2025-01-27 19:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:41:27.066907"
    },
    {
      "arxiv_id": "2501.16450v3",
      "title": "360Brew: A Decoder-only Foundation Model for Personalized Ranking and Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Firooz",
        "Maziar Sanjabi",
        "Adrian Englhardt",
        "Aman Gupta",
        "Ben Levine",
        "Dre Olgiati",
        "Gungor Polatkan",
        "Iuliia Melnychuk",
        "Karthik Ramgopal",
        "Kirill Talanine",
        "Kutta Srinivasan",
        "Luke Simon",
        "Natesh Sivasubramoniapillai",
        "Necip Fazil Ayan",
        "Qingquan Song",
        "Samira Sriram",
        "Souvik Ghosh",
        "Tao Song",
        "Tejas Dharamsi",
        "Vignesh Kothapalli",
        "Xiaoling Zhai",
        "Ya Xu",
        "Yu Wang",
        "Yun Dai"
      ],
      "abstract": "Ranking and recommendation systems are the foundation for numerous online\nexperiences, ranging from search results to personalized content delivery.\nThese systems have evolved into complex, multilayered architectures that\nleverage vast datasets and often incorporate thousands of predictive models.\nThe maintenance and enhancement of these models is a labor intensive process\nthat requires extensive feature engineering. This approach not only exacerbates\ntechnical debt but also hampers innovation in extending these systems to\nemerging problem domains. In this report, we present our research to address\nthese challenges by utilizing a large foundation model with a textual interface\nfor ranking and recommendation tasks. We illustrate several key advantages of\nour approach: (1) a single model can manage multiple predictive tasks involved\nin ranking and recommendation, (2) decoder models with textual interface due to\ntheir comprehension of reasoning capabilities, can generalize to new\nrecommendation surfaces and out-of-domain problems, and (3) by employing\nnatural language interfaces for task definitions and verbalizing member\nbehaviors and their social connections, we eliminate the need for feature\nengineering and the maintenance of complex directed acyclic graphs of model\ndependencies. We introduce our research pre-production model, 360Brew V1.0, a\n150B parameter, decoder-only model that has been trained and fine-tuned on\nLinkedIn's data and tasks. This model is capable of solving over 30 predictive\ntasks across various segments of the LinkedIn platform, achieving performance\nlevels comparable to or exceeding those of current production systems based on\noffline metrics, without task-specific fine-tuning. Notably, each of these\ntasks is conventionally addressed by dedicated models that have been developed\nand maintained over multiple years by teams of a similar or larger size than\nour own.",
      "tldr_zh": "本文提出 360Brew，一种 decoder-only foundation model，用于个性化排名和推荐系统，以解决传统多层架构的复杂维护、技术债务和特征工程问题。该模型通过文本接口整合多个预测任务，利用其推理能力实现对新推荐场景和领域外问题的泛化，并通过自然语言定义任务来消除模型依赖图的维护需求。实验结果显示，360Brew V1.0（一个150B参数模型）在LinkedIn平台上处理超过30个预测任务，性能与现有生产系统相当或更优，且无需任务特定微调。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16450v3",
      "published_date": "2025-01-27 19:14:52 UTC",
      "updated_date": "2025-02-07 22:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:41:39.266314"
    },
    {
      "arxiv_id": "2501.16448v1",
      "title": "What is Harm? Baby Don't Hurt Me! On the Impossibility of Complete Harm Specification in AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Robin Young"
      ],
      "abstract": "\"First, do no harm\" faces a fundamental challenge in artificial intelligence:\nhow can we specify what constitutes harm? While prior work treats harm\nspecification as a technical hurdle to be overcome through better algorithms or\nmore data, we argue this assumption is unsound. Drawing on information theory,\nwe demonstrate that complete harm specification is fundamentally impossible for\nany system where harm is defined external to its specifications. This\nimpossibility arises from an inescapable information-theoretic gap: the entropy\nof harm H(O) always exceeds the mutual information I(O;I) between ground truth\nharm O and a system's specifications I.\n  We introduce two novel metrics: semantic entropy H(S) and the\nsafety-capability ratio I(O;I)/H(O), to quantify these limitations. Through a\nprogression of increasingly sophisticated specification attempts, we show why\neach approach must fail and why the resulting gaps are not mere engineering\nchallenges but fundamental constraints akin to the halting problem. These\nresults suggest a paradigm shift: rather than pursuing complete specifications,\nAI alignment research should focus on developing systems that can operate\nsafely despite irreducible specification uncertainty.",
      "tldr_zh": "本论文探讨了AI对齐（AI Alignment）中完全指定“伤害”（harm）的根本不可能性，挑战了将此视为单纯技术问题的观点。作者基于信息理论证明了这种不可能性，因为伤害的熵H(O)总是超过系统规范与真实伤害之间的互信息I(O;I)，导致不可逾越的信息理论鸿沟。论文引入了语义熵H(S)和安全能力比I(O;I)/H(O)两个新指标，用于量化这些限制，并通过分析各种指定尝试展示了为什么这些方法必然失败，类似于停机问题。最终，研究建议AI对齐应转向开发能够在不可避免的指定不确定性下安全运作的系统。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16448v1",
      "published_date": "2025-01-27 19:13:39 UTC",
      "updated_date": "2025-01-27 19:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:41:50.746145"
    },
    {
      "arxiv_id": "2502.15720v1",
      "title": "Training AI to be Loyal",
      "title_zh": "翻译失败",
      "authors": [
        "Sewoong Oh",
        "Himanshu Tyagi",
        "Pramod Viswanath"
      ],
      "abstract": "Loyal AI is loyal to the community that builds it. An AI is loyal to a\ncommunity if the community has ownership, alignment, and control. Community\nowned models can only be used with the approval of the community and share the\neconomic rewards communally. Community aligned models have values that are\naligned with the consensus of the community. Community controlled models\nperform functions designed by the community. Since we would like permissionless\naccess to the loyal AI's community, we need the AI to be open source. The key\nscientific question then is: how can we build models that are openly accessible\n(open source) and yet are owned and governed by the community. This seeming\nimpossibility is the focus of this paper where we outline a concrete pathway to\nOpen, Monetizable and Loyal models (OML), building on our earlier work on OML,\narXiv:2411.03887(1) , and a representation via a cryptographic-ML library\nhttp://github.com/sentient-agi/oml-1.0-fingerprinting .",
      "tldr_zh": "该论文探讨了如何训练忠诚 AI（Loyal AI），即 AI 对构建它的社区保持忠诚，通过社区所有权（社区批准使用并共享经济回报）、对齐（价值观与社区共识一致）和控制（功能由社区设计）来实现。核心科学问题是构建开源的 AI 模型，同时确保社区拥有和治理，为此论文提出 Open, Monetizable and Loyal models (OML) 的具体路径，基于先前工作 arXiv:2411.03887 和一个加密-ML 库（http://github.com/sentient-agi/oml-1.0-fingerprinting）。这一框架旨在解决开源 AI 与社区忠诚性的矛盾，提供可行方案以实现无权限访问的忠诚 AI 系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15720v1",
      "published_date": "2025-01-27 19:11:19 UTC",
      "updated_date": "2025-01-27 19:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:42:02.751973"
    },
    {
      "arxiv_id": "2502.00045v1",
      "title": "Restless Multi-armed Bandits under Frequency and Window Constraints for Public Service Inspections",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Mao",
        "Andrew Perrault"
      ],
      "abstract": "Municipal inspections are an important part of maintaining the quality of\ngoods and services. In this paper, we approach the problem of intelligently\nscheduling service inspections to maximize their impact, using the case of food\nestablishment inspections in Chicago as a case study. The Chicago Department of\nPublic Health (CDPH) inspects thousands of establishments each year, with a\nsubstantial fail rate (over 3,000 failed inspection reports in 2023). To\nbalance the objectives of ensuring adherence to guidelines, minimizing\ndisruption to establishments, and minimizing inspection costs, CDPH assigns\neach establishment an inspection window every year and guarantees that they\nwill be inspected exactly once during that window. These constraints create a\nchallenge for a restless multi-armed bandit (RMAB) approach, for which there\nare no existing methods. We develop an extension to Whittle index-based systems\nfor RMABs that can guarantee action window constraints and frequencies, and\nfurthermore can be leveraged to optimize action window assignments themselves.\nBriefly, we combine MDP reformulation and integer programming-based lookahead\nto maximize the impact of inspections subject to constraints. A neural\nnetwork-based supervised learning model is developed to model state transitions\nof real Chicago establishments using public CDPH inspection records, which\ndemonstrates 10\\% AUC improvements compared with directly predicting\nestablishments' failures. Our experiments not only show up to 24\\% (in\nsimulation) or 33\\% (on real data) reward improvements resulting from our\napproach but also give insight into the impact of scheduling constraints.",
      "tldr_zh": "这篇论文针对公共服务检查（如芝加哥食品机构检查）的调度问题，提出了一种在频率和窗口约束下优化Restless Multi-armed Bandits (RMAB)框架的方法，旨在最大化检查影响同时减少干扰。研究扩展了Whittle index系统，通过MDP改革和整数规划来处理约束，并开发了一个基于神经网络的监督学习模型来预测检查失败状态，该模型比直接预测方法提高了10% AUC。实验结果显示，该方法在模拟中提升24%奖励，在真实数据中提升33%，并提供了调度约束对检查效率的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00045v1",
      "published_date": "2025-01-27 19:08:15 UTC",
      "updated_date": "2025-01-27 19:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:42:14.930946"
    },
    {
      "arxiv_id": "2501.16411v2",
      "title": "PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding",
      "title_zh": "PhysBench：针对物理世界理解的视觉语言模型基准测试与增强",
      "authors": [
        "Wei Chow",
        "Jiageng Mao",
        "Boyi Li",
        "Daniel Seita",
        "Vitor Guizilini",
        "Yue Wang"
      ],
      "abstract": "Understanding the physical world is a fundamental challenge in embodied AI,\ncritical for enabling agents to perform complex tasks and operate safely in\nreal-world environments. While Vision-Language Models (VLMs) have shown great\npromise in reasoning and task planning for embodied agents, their ability to\ncomprehend physical phenomena remains extremely limited. To close this gap, we\nintroduce PhysBench, a comprehensive benchmark designed to evaluate VLMs'\nphysical world understanding capability across a diverse set of tasks.\nPhysBench contains 10,002 entries of interleaved video-image-text data,\ncategorized into four major domains: physical object properties, physical\nobject relationships, physical scene understanding, and physics-based dynamics,\nfurther divided into 19 subclasses and 8 distinct capability dimensions. Our\nextensive experiments, conducted on 75 representative VLMs, reveal that while\nthese models excel in common-sense reasoning, they struggle with understanding\nthe physical world -- likely due to the absence of physical knowledge in their\ntraining data and the lack of embedded physical priors. To tackle the\nshortfall, we introduce PhysAgent, a novel framework that combines the\ngeneralization strengths of VLMs with the specialized expertise of vision\nmodels, significantly enhancing VLMs' physical understanding across a variety\nof tasks, including an 18.4\\% improvement on GPT-4o. Furthermore, our results\ndemonstrate that enhancing VLMs' physical world understanding capabilities can\nhelp embodied agents such as MOKA. We believe that PhysBench and PhysAgent\noffer valuable insights and contribute to bridging the gap between VLMs and\nphysical world understanding.",
      "tldr_zh": "该研究引入 PhysBench，一个全面基准，用于评估 Vision-Language Models (VLMs) 在物理世界理解方面的能力，涵盖物理对象属性、关系、场景理解和动态等四个领域，共计 10,002 条视频-图像-文本数据，并细分为 19 个子类和 8 个能力维度。实验测试了 75 个代表性 VLMs，发现这些模型在常识推理上表现出色，但由于训练数据缺少物理知识和先验，导致物理世界理解能力较弱。为了解决这一问题，研究提出 PhysAgent 框架，将 VLMs 的泛化能力与视觉模型的专业知识结合，提升其物理理解表现，例如在 GPT-4o 上实现 18.4% 的改进。PhysBench 和 PhysAgent 的贡献有助于弥合 VLMs 与真实物理世界的差距，并提升具身代理如 MOKA 的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025. Project page: https://physbench.github.io/ Dataset:\n  https://huggingface.co/datasets/USC-GVL/PhysBench",
      "pdf_url": "http://arxiv.org/pdf/2501.16411v2",
      "published_date": "2025-01-27 18:59:58 UTC",
      "updated_date": "2025-01-29 03:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:42:27.192771"
    },
    {
      "arxiv_id": "2501.16330v1",
      "title": "RelightVid: Temporal-Consistent Diffusion Model for Video Relighting",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Fang",
        "Zeyi Sun",
        "Shangzhan Zhang",
        "Tong Wu",
        "Yinghao Xu",
        "Pan Zhang",
        "Jiaqi Wang",
        "Gordon Wetzstein",
        "Dahua Lin"
      ],
      "abstract": "Diffusion models have demonstrated remarkable success in image generation and\nediting, with recent advancements enabling albedo-preserving image relighting.\nHowever, applying these models to video relighting remains challenging due to\nthe lack of paired video relighting datasets and the high demands for output\nfidelity and temporal consistency, further complicated by the inherent\nrandomness of diffusion models. To address these challenges, we introduce\nRelightVid, a flexible framework for video relighting that can accept\nbackground video, text prompts, or environment maps as relighting conditions.\nTrained on in-the-wild videos with carefully designed illumination\naugmentations and rendered videos under extreme dynamic lighting, RelightVid\nachieves arbitrary video relighting with high temporal consistency without\nintrinsic decomposition while preserving the illumination priors of its image\nbackbone.",
      "tldr_zh": "本论文提出RelightVid，一种基于Diffusion Model的视频重照明框架，旨在解决视频重照明中缺乏配对数据集、输出保真度及时间一致性挑战的问题。该框架灵活接受背景视频、文本提示或环境映射作为重照明条件，并通过在野外视频和极端动态照明渲染视频上训练，实现任意视频重照明，而无需内在分解(intrinsic decomposition)。实验结果显示，RelightVid在保持高时间一致性(Temporal-Consistent)的同时，保留了其图像骨干的照明先验，显著提升了视频编辑效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16330v1",
      "published_date": "2025-01-27 18:59:57 UTC",
      "updated_date": "2025-01-27 18:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:42:38.697012"
    },
    {
      "arxiv_id": "2501.16329v1",
      "title": "sDREAMER: Self-distilled Mixture-of-Modality-Experts Transformer for Automatic Sleep Staging",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Chen",
        "Yuan Yao",
        "Mie Anderson",
        "Natalie Hauglund",
        "Celia Kjaerby",
        "Verena Untiet",
        "Maiken Nedergaard",
        "Jiebo Luo"
      ],
      "abstract": "Automatic sleep staging based on electroencephalography (EEG) and\nelectromyography (EMG) signals is an important aspect of sleep-related\nresearch. Current sleep staging methods suffer from two major drawbacks. First,\nthere are limited information interactions between modalities in the existing\nmethods. Second, current methods do not develop unified models that can handle\ndifferent sources of input. To address these issues, we propose a novel sleep\nstage scoring model sDREAMER, which emphasizes cross-modality interaction and\nper-channel performance. Specifically, we develop a mixture-of-modality-expert\n(MoME) model with three pathways for EEG, EMG, and mixed signals with partially\nshared weights. We further propose a self-distillation training scheme for\nfurther information interaction across modalities. Our model is trained with\nmulti-channel inputs and can make classifications on either single-channel or\nmulti-channel inputs. Experiments demonstrate that our model outperforms the\nexisting transformer-based sleep scoring methods for multi-channel inference.\nFor single-channel inference, our model also outperforms the transformer-based\nmodels trained with single-channel signals.",
      "tldr_zh": "本研究针对自动睡眠分期问题，提出了一种新型模型 sDREAMER，以解决现有方法中模态间信息交互有限和无法处理不同输入来源的缺点。sDREAMER 采用 Mixture-of-Modality-Experts (MoME) Transformer 架构，包括 EEG、EMG 和混合信号的三条路径，并部分共享权重，以增强跨模态交互；同时引入自蒸馏(self-distillation)训练方案，进一步促进模态间信息交换。实验结果显示，该模型在多通道推理中优于现有 Transformer-based 方法，在单通道推理中也超越了基于单通道训练的模型，从而提升了 EEG 和 EMG 信号的睡眠分期准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16329v1",
      "published_date": "2025-01-27 18:59:55 UTC",
      "updated_date": "2025-01-27 18:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:42:51.169881"
    },
    {
      "arxiv_id": "2501.16309v1",
      "title": "Evaluating The Performance of Using Large Language Models to Automate Summarization of CT Simulation Orders in Radiation Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Meiyun Cao",
        "Shaw Hu",
        "Jason Sharp",
        "Edward Clouser",
        "Jason Holmes",
        "Linda L. Lam",
        "Xiaoning Ding",
        "Diego Santos Toesca",
        "Wendy S. Lindholm",
        "Samir H. Patel",
        "Sujay A. Vora",
        "Peilong Wang",
        "Wei Liu"
      ],
      "abstract": "Purpose: This study aims to use a large language model (LLM) to automate the\ngeneration of summaries from the CT simulation orders and evaluate its\nperformance.\n  Materials and Methods: A total of 607 CT simulation orders for patients were\ncollected from the Aria database at our institution. A locally hosted Llama 3.1\n405B model, accessed via the Application Programming Interface (API) service,\nwas used to extract keywords from the CT simulation orders and generate\nsummaries. The downloaded CT simulation orders were categorized into seven\ngroups based on treatment modalities and disease sites. For each group, a\ncustomized instruction prompt was developed collaboratively with therapists to\nguide the Llama 3.1 405B model in generating summaries. The ground truth for\nthe corresponding summaries was manually derived by carefully reviewing each CT\nsimulation order and subsequently verified by therapists. The accuracy of the\nLLM-generated summaries was evaluated by therapists using the verified ground\ntruth as a reference.\n  Results: About 98% of the LLM-generated summaries aligned with the manually\ngenerated ground truth in terms of accuracy. Our evaluations showed an improved\nconsistency in format and enhanced readability of the LLM-generated summaries\ncompared to the corresponding therapists-generated summaries. This automated\napproach demonstrated a consistent performance across all groups, regardless of\nmodality or disease site.\n  Conclusions: This study demonstrated the high precision and consistency of\nthe Llama 3.1 405B model in extracting keywords and summarizing CT simulation\norders, suggesting that LLMs have great potential to help with this task,\nreduce the workload of therapists and improve workflow efficiency.",
      "tldr_zh": "本研究评估了使用Large Language Models (LLM)自动生成放射肿瘤学CT模拟订单摘要的性能，旨在减轻治疗师工作负担。研究收集了607个CT模拟订单，使用Llama 3.1 405B模型结合定制提示语提取关键词并生成摘要，并通过人工ground truth验证。结果显示，98%的LLM生成摘要在准确性、格式一致性和可读性上优于人工摘要，且在不同治疗方式和疾病部位组中表现稳定。结论表明，LLM具有高精度和一致性潜力，可显著提高工作流程效率。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16309v1",
      "published_date": "2025-01-27 18:47:58 UTC",
      "updated_date": "2025-01-27 18:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:43:02.930281"
    },
    {
      "arxiv_id": "2501.16300v1",
      "title": "Large Models in Dialogue for Active Perception and Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tzoulio Chamiti",
        "Nikolaos Passalis",
        "Anastasios Tefas"
      ],
      "abstract": "Autonomous aerial monitoring is an important task aimed at gathering\ninformation from areas that may not be easily accessible by humans. At the same\ntime, this task often requires recognizing anomalies from a significant\ndistance or not previously encountered in the past. In this paper, we propose a\nnovel framework that leverages the advanced capabilities provided by Large\nLanguage Models (LLMs) to actively collect information and perform anomaly\ndetection in novel scenes. To this end, we propose an LLM based model dialogue\napproach, in which two deep learning models engage in a dialogue to actively\ncontrol a drone to increase perception and anomaly detection accuracy. We\nconduct our experiments in a high fidelity simulation environment where an LLM\nis provided with a predetermined set of natural language movement commands\nmapped into executable code functions. Additionally, we deploy a multimodal\nVisual Question Answering (VQA) model charged with the task of visual question\nanswering and captioning. By engaging the two models in conversation, the LLM\nasks exploratory questions while simultaneously flying a drone into different\nparts of the scene, providing a novel way to implement active perception. By\nleveraging LLMs reasoning ability, we output an improved detailed description\nof the scene going beyond existing static perception approaches. In addition to\ninformation gathering, our approach is utilized for anomaly detection and our\nresults demonstrate the proposed methods effectiveness in informing and\nalerting about potential hazards.",
      "tldr_zh": "该论文提出了一种利用大型语言模型(LLMs)的新框架，用于无人机主动感知和异常检测，旨在通过对话机制收集信息并识别未知场景中的异常。方法包括LLMs与多模态视觉问答(VQA)模型的互动，LLMs生成自然语言指令控制无人机探索场景，同时VQA模型处理视觉描述和问答，以提高感知准确性。实验在高保真模拟环境中进行，结果显示该方法比静态感知方法更有效，能输出更详细的场景描述，并成功用于异常检测和潜在危险警报。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to International Conference of Pattern Recognition (ICPR\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.16300v1",
      "published_date": "2025-01-27 18:38:36 UTC",
      "updated_date": "2025-01-27 18:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:43:15.218578"
    },
    {
      "arxiv_id": "2501.16295v1",
      "title": "Mixture-of-Mamba: Enhancing Multi-Modal State-Space Models with Modality-Aware Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Weixin Liang",
        "Junhong Shen",
        "Genghan Zhang",
        "Ning Dong",
        "Luke Zettlemoyer",
        "Lili Yu"
      ],
      "abstract": "State Space Models (SSMs) have emerged as efficient alternatives to\nTransformers for sequential modeling, but their inability to leverage\nmodality-specific features limits their performance in multi-modal pretraining.\nHere, we propose Mixture-of-Mamba, a novel SSM architecture that introduces\nmodality-aware sparsity through modality-specific parameterization of the Mamba\nblock. Building on Mixture-of-Transformers (W. Liang et al. arXiv:2411.04996;\n2024), we extend the benefits of modality-aware sparsity to SSMs while\npreserving their computational efficiency. We evaluate Mixture-of-Mamba across\nthree multi-modal pretraining settings: Transfusion (interleaved text and\ncontinuous image tokens with diffusion loss), Chameleon (interleaved text and\ndiscrete image tokens), and an extended three-modality framework incorporating\nspeech. Mixture-of-Mamba consistently reaches the same loss values at earlier\ntraining steps with significantly reduced computational costs. In the\nTransfusion setting, Mixture-of-Mamba achieves equivalent image loss using only\n34.76% of the training FLOPs at the 1.4B scale. In the Chameleon setting,\nMixture-of-Mamba reaches similar image loss with just 42.50% of the FLOPs at\nthe 1.4B scale, and similar text loss with just 65.40% of the FLOPs. In the\nthree-modality setting, MoM matches speech loss at 24.80% of the FLOPs at the\n1.4B scale. Our ablation study highlights the synergistic effects of decoupling\nprojection components, where joint decoupling yields greater gains than\nindividual modifications. These results establish modality-aware sparsity as a\nversatile and effective design principle, extending its impact from\nTransformers to SSMs and setting new benchmarks in multi-modal pretraining. Our\ncode can be accessed at https://github.com/Weixin-Liang/Mixture-of-Mamba",
      "tldr_zh": "本研究提出Mixture-of-Mamba，一种新型State Space Models (SSMs)架构，通过引入模态感知稀疏性（modality-aware sparsity）来优化多模态预训练，利用模态特定参数化Mamba块，解决SSMs无法充分利用模态特定特征的问题。基于Mixture-of-Transformers的理念，该框架在保持计算效率的同时，在Transfusion、Chameleon和三模态（包括语音）设置中进行评估，结果显示Mixture-of-Mamba在减少计算成本的情况下显著加速训练，例如在Transfusion设置中，使用仅34.76%的FLOPs即可达到等效图像损失。消融研究证实，解耦投影组件的协同效应进一步提升了性能，这些发现将模态感知稀疏性确立为一种通用设计原则，推动SSMs在多模态预训练中的新基准。我们的代码可在https://github.com/Weixin-Liang/Mixture-of-Mamba获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16295v1",
      "published_date": "2025-01-27 18:35:05 UTC",
      "updated_date": "2025-01-27 18:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:43:27.301878"
    },
    {
      "arxiv_id": "2501.16288v2",
      "title": "Upside Down Reinforcement Learning with Policy Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Jacopo Di Ventura",
        "Dylan R. Ashley",
        "Vincent Herrmann",
        "Francesco Faccio",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Upside Down Reinforcement Learning (UDRL) is a promising framework for\nsolving reinforcement learning problems which focuses on learning\ncommand-conditioned policies. In this work, we extend UDRL to the task of\nlearning a command-conditioned generator of deep neural network policies. We\naccomplish this using Hypernetworks - a variant of Fast Weight Programmers,\nwhich learn to decode input commands representing a desired expected return\ninto command-specific weight matrices. Our method, dubbed Upside Down\nReinforcement Learning with Policy Generators (UDRLPG), streamlines comparable\ntechniques by removing the need for an evaluator or critic to update the\nweights of the generator. To counteract the increased variance in last returns\ncaused by not having an evaluator, we decouple the sampling probability of the\nbuffer from the absolute number of policies in it, which, together with a\nsimple weighting strategy, improves the empirical convergence of the algorithm.\nCompared with existing algorithms, UDRLPG achieves competitive performance and\nhigh returns, sometimes outperforming more complex architectures. Our\nexperiments show that a trained generator can generalize to create policies\nthat achieve unseen returns zero-shot. The proposed method appears to be\neffective in mitigating some of the challenges associated with learning highly\nmultimodal functions. Altogether, we believe that UDRLPG represents a promising\nstep forward in achieving greater empirical sample efficiency in RL. A full\nimplementation of UDRLPG is publicly available at\nhttps://github.com/JacopoD/udrlpg_",
      "tldr_zh": "本文提出了一种扩展 Upside Down Reinforcement Learning (UDRL) 的方法，名为 UDRLPG，利用 Hypernetworks 生成命令条件深度神经网络策略，从而无需评估器或批评者来更新生成器权重。UDRLPG 通过解耦采样概率和缓冲区策略，并采用简单加权机制，降低了方差并提升了算法的经验收敛。实验结果显示，该方法在性能上与现有算法竞争，甚至在某些场景下优于复杂架构，并能零样本泛化到未见回报，提高了强化学习的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages in main text, 4 figures in main text; source code available\n  at https://github.com/JacopoD/udrlpg_",
      "pdf_url": "http://arxiv.org/pdf/2501.16288v2",
      "published_date": "2025-01-27 18:25:04 UTC",
      "updated_date": "2025-01-28 13:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:43:39.305749"
    },
    {
      "arxiv_id": "2501.16282v1",
      "title": "Brain-Adapter: Enhancing Neurological Disorder Analysis with Adapter-Tuning Multimodal Large Language Models",
      "title_zh": "Brain-Adapter：通过适配器微调多模态大型语言模型增强神经",
      "authors": [
        "Jing Zhang",
        "Xiaowei Yu",
        "Yanjun Lyu",
        "Lu Zhang",
        "Tong Chen",
        "Chao Cao",
        "Yan Zhuang",
        "Minheng Chen",
        "Tianming Liu",
        "Dajiang Zhu"
      ],
      "abstract": "Understanding brain disorders is crucial for accurate clinical diagnosis and\ntreatment. Recent advances in Multimodal Large Language Models (MLLMs) offer a\npromising approach to interpreting medical images with the support of text\ndescriptions. However, previous research has primarily focused on 2D medical\nimages, leaving richer spatial information of 3D images under-explored, and\nsingle-modality-based methods are limited by overlooking the critical clinical\ninformation contained in other modalities. To address this issue, this paper\nproposes Brain-Adapter, a novel approach that incorporates an extra bottleneck\nlayer to learn new knowledge and instill it into the original pre-trained\nknowledge. The major idea is to incorporate a lightweight bottleneck layer to\ntrain fewer parameters while capturing essential information and utilize a\nContrastive Language-Image Pre-training (CLIP) strategy to align multimodal\ndata within a unified representation space. Extensive experiments demonstrated\nthe effectiveness of our approach in integrating multimodal data to\nsignificantly improve the diagnosis accuracy without high computational costs,\nhighlighting the potential to enhance real-world diagnostic workflows.",
      "tldr_zh": "该研究提出Brain-Adapter，一种基于Adapter-Tuning的多模态大语言模型(MLLMs)，旨在提升神经疾病分析的准确性，通过整合2D和3D医疗图像等多模态数据来弥补单模态方法的局限。方法包括添加一个bottleneck layer来学习新知识并注入预训练模型，同时利用Contrastive Language-Image Pre-training (CLIP)策略对齐多模态数据，实现统一表示空间。实验证明，该方法显著提高了诊断准确率，同时保持低计算成本，具有在实际临床诊断工作流中应用的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16282v1",
      "published_date": "2025-01-27 18:20:49 UTC",
      "updated_date": "2025-01-27 18:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:09.132134"
    },
    {
      "arxiv_id": "2501.16409v1",
      "title": "Classification of Mild Cognitive Impairment Based on Dynamic Functional Connectivity Using Spatio-Temporal Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Zhang",
        "Yanjun Lyu",
        "Xiaowei Yu",
        "Lu Zhang",
        "Chao Cao",
        "Tong Chen",
        "Minheng Chen",
        "Yan Zhuang",
        "Tianming Liu",
        "Dajiang Zhu"
      ],
      "abstract": "Dynamic functional connectivity (dFC) using resting-state functional magnetic\nresonance imaging (rs-fMRI) is an advanced technique for capturing the dynamic\nchanges of neural activities, and can be very useful in the studies of brain\ndiseases such as Alzheimer's disease (AD). Yet, existing studies have not fully\nleveraged the sequential information embedded within dFC that can potentially\nprovide valuable information when identifying brain conditions. In this paper,\nwe propose a novel framework that jointly learns the embedding of both spatial\nand temporal information within dFC based on the transformer architecture.\nSpecifically, we first construct dFC networks from rs-fMRI data through a\nsliding window strategy. Then, we simultaneously employ a temporal block and a\nspatial block to capture higher-order representations of dynamic\nspatio-temporal dependencies, via mapping them into an efficient fused feature\nrepresentation. To further enhance the robustness of these feature\nrepresentations by reducing the dependency on labeled data, we also introduce a\ncontrastive learning strategy to manipulate different brain states.\nExperimental results on 345 subjects with 570 scans from the Alzheimer's\nDisease Neuroimaging Initiative (ADNI) demonstrate the superiority of our\nproposed method for MCI (Mild Cognitive Impairment, the prodromal stage of AD)\nprediction, highlighting its potential for early identification of AD.",
      "tldr_zh": "本文提出了一种基于 Spatio-Temporal Transformer 的新框架，用于通过动态功能连接 (dFC) 和静息态功能磁共振成像 (rs-fMRI) 分类轻度认知障碍 (MCI)。该框架通过滑动窗口策略构建 dFC 网络，并同时使用时间块和空间块来捕获动态时空依赖的高阶表示，同时引入对比学习策略以增强特征表示的鲁棒性，减少对标签数据的依赖。实验结果显示，在 Alzheimer’s Disease Neuroimaging Initiative (ADNI) 数据集的 345 名受试者中，该方法在 MCI 预测方面优于现有方法，有助于阿尔茨海默病 (AD) 的早期识别。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16409v1",
      "published_date": "2025-01-27 18:20:33 UTC",
      "updated_date": "2025-01-27 18:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:44:03.842255"
    },
    {
      "arxiv_id": "2501.16274v1",
      "title": "What is Formal Verification without Specifications? A Survey on mining LTL Specifications",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Neider",
        "Rajarshi Roy"
      ],
      "abstract": "Virtually all verification techniques using formal methods rely on the\navailability of a formal specification, which describes the design requirements\nprecisely. However, formulating specifications remains a manual task that is\nnotoriously challenging and error-prone. To address this bottleneck in formal\nverification, recent research has thus focussed on automatically generating\nspecifications for formal verification from examples of (desired and undesired)\nsystem behavior. In this survey, we list and compare recent advances in mining\nspecifications in Linear Temporal Logic (LTL), the de facto standard\nspecification language for reactive systems. Several approaches have been\ndesigned for learning LTL formulas, which address different aspects and\nsettings of specification design. Moreover, the approaches rely on a diverse\nrange of techniques such as constraint solving, neural network training,\nenumerative search, etc. We survey the current state-of-the-art techniques and\ncompare them for the convenience of the formal methods practitioners.",
      "tldr_zh": "这篇调查论文探讨了正式验证（Formal Verification）在缺乏规范时的挑战，焦点在于自动挖掘 Linear Temporal Logic (LTL) 规范，以解决手动制定规范的难题。论文总结了从系统行为的期望和非期望示例中生成 LTL 公式的最新方法，这些方法涉及约束求解、神经网络训练和枚举搜索等多种技术。最终，通过比较这些方法的优缺点，为正式方法从业者提供便利，帮助他们在不同场景下选择合适的规范挖掘策略。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.FL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16274v1",
      "published_date": "2025-01-27 18:06:48 UTC",
      "updated_date": "2025-01-27 18:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:44:14.632869"
    },
    {
      "arxiv_id": "2501.16273v2",
      "title": "Return of the Encoder: Maximizing Parameter Efficiency for SLMs",
      "title_zh": "编码器的回归：针对 SLMs 最大化参数效率",
      "authors": [
        "Mohamed Elfeki",
        "Rui Liu",
        "Chad Voegele"
      ],
      "abstract": "The dominance of large decoder-only language models has overshadowed\nencoder-decoder architectures, despite their fundamental efficiency advantages\nin sequence processing. For small language models (SLMs) - those with 1 billion\nparameters or fewer - our systematic analysis across GPU, CPU, and NPU\nplatforms reveals that encoder-decoder architectures achieve 47% lower\nfirst-token latency and 4.7x higher throughput compared to decoder-only models\non edge devices. These gains may be attributed to encoder-decoder's one-time\ninput processing and efficient separation of understanding and generation\nphases.\n  We introduce a novel knowledge distillation framework that enables\nencoder-decoder models to leverage capabilities from large scalable\ndecoder-only teachers while preserving their architectural advantages,\nachieving up to 6 average performance points improvement across diverse tasks,\nwith significant gains in asymmetric sequence tasks where input and output\ndistributions can benefit from different processing approaches.\n  When combined with modern advances like Rotary Positional Embeddings (RoPE)\nand Vision encoders, our systematic investigation demonstrates that\nencoder-decoder architectures provide a more practical path toward deploying\ncapable language models in resource-constrained environments. Our findings\nchallenge the prevailing trend toward decoder-only scaling, showing that\narchitectural choices become increasingly crucial as parameter budgets\ndecrease, particularly for on-device and edge deployments where computational\nefficiency is paramount.",
      "tldr_zh": "这篇论文重新审视了encoder-decoder架构在小语言模型(SLMs，参数规模1 billion或更少)中的参数效率优势，通过系统分析发现其在GPU、CPU和NPU平台上比decoder-only模型降低了47%的首token延迟并提高了4.7倍的吞吐量，尤其适合边缘设备部署。论文引入了一种新型知识distillation框架，让encoder-decoder模型从大型decoder-only教师模型中学习能力，同时保留其结构优势，在多样任务中提升了平均6个性能点，特别是在非对称序列任务中表现突出。结合Rotary Positional Embeddings (RoPE)和Vision encoders，该研究证明encoder-decoder架构为资源受限环境提供了更实用的部署路径，挑战了当前decoder-only模型的主流趋势，并强调在参数预算有限时架构选择的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 5 figures. LLMs/SLMs, encoder-decoder and decoder-only",
      "pdf_url": "http://arxiv.org/pdf/2501.16273v2",
      "published_date": "2025-01-27 18:06:36 UTC",
      "updated_date": "2025-01-30 16:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:44:29.663278"
    },
    {
      "arxiv_id": "2501.16271v1",
      "title": "From Molecules to Mixtures: Learning Representations of Olfactory Mixture Similarity using Inductive Biases",
      "title_zh": "从分子到混合物：使用归纳偏差学习嗅觉混合物相似性的",
      "authors": [
        "Gary Tom",
        "Cher Tian Ser",
        "Ella M. Rajaonson",
        "Stanley Lo",
        "Hyun Suk Park",
        "Brian K. Lee",
        "Benjamin Sanchez-Lengeling"
      ],
      "abstract": "Olfaction -- how molecules are perceived as odors to humans -- remains poorly\nunderstood. Recently, the principal odor map (POM) was introduced to digitize\nthe olfactory properties of single compounds. However, smells in real life are\nnot pure single molecules, but complex mixtures of molecules, whose\nrepresentations remain relatively under-explored. In this work, we introduce\nPOMMix, an extension of the POM to represent mixtures. Our representation\nbuilds upon the symmetries of the problem space in a hierarchical manner: (1)\ngraph neural networks for building molecular embeddings, (2) attention\nmechanisms for aggregating molecular representations into mixture\nrepresentations, and (3) cosine prediction heads to encode olfactory perceptual\ndistance in the mixture embedding space. POMMix achieves state-of-the-art\npredictive performance across multiple datasets. We also evaluate the\ngeneralizability of the representation on multiple splits when applied to\nunseen molecules and mixture sizes. Our work advances the effort to digitize\nolfaction, and highlights the synergy of domain expertise and deep learning in\ncrafting expressive representations in low-data regimes.",
      "tldr_zh": "本研究针对嗅觉（olfaction）感知的复杂性，扩展了主气味图（POM）模型，引入POMMix来表示分子混合物的嗅觉相似性，利用归纳偏差（inductive biases）构建层次化表示。方法包括使用图神经网络（graph neural networks）生成分子嵌入、注意力机制（attention mechanisms）聚合混合表示，以及余弦预测头（cosine prediction heads）编码感知距离。POMMix在多个数据集上实现了最先进的预测性能，并展示了在未见分子和混合大小上的良好泛化能力。该工作推进了嗅觉数字化的努力，强调了领域专业知识与深度学习的协同作用，尤其在低数据环境中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16271v1",
      "published_date": "2025-01-27 18:05:28 UTC",
      "updated_date": "2025-01-27 18:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:44:39.969653"
    },
    {
      "arxiv_id": "2501.16249v2",
      "title": "Lightweight Weighted Average Ensemble Model for Pneumonia Detection in Chest X-Ray Images",
      "title_zh": "轻量级加权平均集成模型用于胸部X光图像肺炎检测",
      "authors": [
        "Suresh Babu Nettur",
        "Shanthi Karpurapu",
        "Unnati Nettur",
        "Likhit Sagar Gajja",
        "Sravanthy Myneni",
        "Akhil Dusi",
        "Lalithya Posham"
      ],
      "abstract": "Pneumonia is a leading cause of illness and death in children, underscoring\nthe need for early and accurate detection. In this study, we propose a novel\nlightweight ensemble model for detecting pneumonia in children using chest\nX-ray images. This ensemble model integrates two pre-trained convolutional\nneural networks (CNNs), MobileNetV2 and NASNetMobile, selected for their\nbalance of computational efficiency and accuracy. These models were fine-tuned\non a pediatric chest X-ray dataset and combined to enhance classification\nperformance. Our proposed ensemble model achieved a classification accuracy of\n98.63%, significantly outperforming individual models such as MobileNetV2\n(97.10%) and NASNetMobile(96.25%) in terms of accuracy, precision, recall, and\nF1 score. Moreover, the ensemble model outperformed state-of-the-art\narchitectures, including ResNet50, InceptionV3, and DenseNet201, while\nmaintaining computational efficiency. The proposed lightweight ensemble model\npresents a highly effective and resource-efficient solution for pneumonia\ndetection, making it particularly suitable for deployment in\nresource-constrained settings.",
      "tldr_zh": "本研究提出了一种轻量级加权平均集成模型，用于检测儿童胸部X光图像中的肺炎，以满足早期准确诊断的需求。该模型整合了预训练的MobileNetV2和NASNetMobile两个CNN，并通过在儿科胸部X光数据集上微调和组合方式提升分类性能。实验结果显示，该集成模型的准确率达到98.63%，在准确率、精确率、召回率和F1分数上均优于单个模型（如MobileNetV2的97.10%和NASNetMobile的96.25%）以及先进架构如ResNet50、InceptionV3和DenseNet201，同时保持计算效率，特别适合资源受限环境部署。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Corresponding authors: Shanthi Karpurapu\n  (shanthi.karpurapu@gmail.com), Suresh Babu Nettur (nettursuresh@gmail.com)\n  Shanthi Karpurapu and Suresh Babu Nettur are co-first authors",
      "pdf_url": "http://arxiv.org/pdf/2501.16249v2",
      "published_date": "2025-01-27 17:51:29 UTC",
      "updated_date": "2025-02-01 00:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:44:51.852015"
    },
    {
      "arxiv_id": "2501.16243v1",
      "title": "Accelerating Quantum Reinforcement Learning with a Quantum Natural Policy Gradient Based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Xu",
        "Vaneet Aggarwal"
      ],
      "abstract": "We address the problem of quantum reinforcement learning (QRL) under\nmodel-free settings with quantum oracle access to the Markov Decision Process\n(MDP). This paper introduces a Quantum Natural Policy Gradient (QNPG)\nalgorithm, which replaces the random sampling used in classical Natural Policy\nGradient (NPG) estimators with a deterministic gradient estimation approach,\nenabling seamless integration into quantum systems. While this modification\nintroduces a bounded bias in the estimator, the bias decays exponentially with\nincreasing truncation levels. This paper demonstrates that the proposed QNPG\nalgorithm achieves a sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1.5})$ for queries to the quantum oracle,\nsignificantly improving the classical lower bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ for queries to the MDP.",
      "tldr_zh": "该论文针对量子强化学习 (QRL) 的无模型设置，提出 Quantum Natural Policy Gradient (QNPG) 算法，利用量子预言机访问 Markov Decision Process (MDP)，以加速学习过程。QNPG 通过将经典 Natural Policy Gradient (NPG) 中的随机采样替换为确定性梯度估计，引入了有界偏差，但该偏差随截断级别指数衰减，从而提高了算法的适用性。实验结果显示，QNPG 的样本复杂度达到 $\\tilde{\\mathcal{O}}(\\epsilon^{-1.5})$，显著优于经典方法的 $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ 下界。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16243v1",
      "published_date": "2025-01-27 17:38:30 UTC",
      "updated_date": "2025-01-27 17:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:04.054799"
    },
    {
      "arxiv_id": "2501.16224v1",
      "title": "Language-Based Bayesian Optimization Research Assistant (BORA)",
      "title_zh": "基于语言的贝叶斯优化研究助理（BORA）",
      "authors": [
        "Abdoulatif Cissé",
        "Xenophon Evangelopoulos",
        "Vladimir V. Gusev",
        "Andrew I. Cooper"
      ],
      "abstract": "Many important scientific problems involve multivariate optimization coupled\nwith slow and laborious experimental measurements. These complex,\nhigh-dimensional searches can be defined by non-convex optimization landscapes\nthat resemble needle-in-a-haystack surfaces, leading to entrapment in local\nminima. Contextualizing optimizers with human domain knowledge is a powerful\napproach to guide searches to localized fruitful regions. However, this\napproach is susceptible to human confirmation bias and it is also challenging\nfor domain experts to keep track of the rapidly expanding scientific\nliterature. Here, we propose the use of Large Language Models (LLMs) for\ncontextualizing Bayesian optimization (BO) via a hybrid optimization framework\nthat intelligently and economically blends stochastic inference with domain\nknowledge-based insights from the LLM, which is used to suggest new,\nbetter-performing areas of the search space for exploration. Our method fosters\nuser engagement by offering real-time commentary on the optimization progress,\nexplaining the reasoning behind the search strategies. We validate the\neffectiveness of our approach on synthetic benchmarks with up to 15 independent\nvariables and demonstrate the ability of LLMs to reason in four real-world\nexperimental tasks where context-aware suggestions boost optimization\nperformance substantially.",
      "tldr_zh": "这篇论文提出了 BORA（Language-Based Bayesian Optimization Research Assistant），一种利用 Large Language Models (LLMs) 来 contextualize Bayesian optimization (BO) 的混合框架，旨在解决多变量优化问题中容易陷入局部最小值的挑战，同时减少人类确认偏差的影响。BORA 通过结合随机推理和 LLM 提供的领域知识洞见，智能建议新的搜索空间区域，并提供实时评论来解释优化策略，促进用户参与。实验在合成基准（最多 15 个独立变量）和四个真实世界任务上验证了其有效性，LLMs 的上下文感知建议显著提升了优化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16224v1",
      "published_date": "2025-01-27 17:20:04 UTC",
      "updated_date": "2025-01-27 17:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:15.944638"
    },
    {
      "arxiv_id": "2501.16215v1",
      "title": "Enhancing Visual Inspection Capability of Multi-Modal Large Language Models on Medical Time Series with Supportive Conformalized and Interpretable Small Specialized Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huayu Li",
        "Xiwen Chen",
        "Ci Zhang",
        "Stuart F. Quan",
        "William D. S. Killgore",
        "Shu-Fen Wung",
        "Chen X. Chen",
        "Geng Yuan",
        "Jin Lu",
        "Ao Li"
      ],
      "abstract": "Large language models (LLMs) exhibit remarkable capabilities in visual\ninspection of medical time-series data, achieving proficiency comparable to\nhuman clinicians. However, their broad scope limits domain-specific precision,\nand proprietary weights hinder fine-tuning for specialized datasets. In\ncontrast, small specialized models (SSMs) excel in targeted tasks but lack the\ncontextual reasoning required for complex clinical decision-making. To address\nthese challenges, we propose ConMIL (Conformalized Multiple Instance Learning),\na decision-support SSM that integrates seamlessly with LLMs. By using Multiple\nInstance Learning (MIL) to identify clinically significant signal segments and\nconformal prediction for calibrated set-valued outputs, ConMIL enhances LLMs'\ninterpretative capabilities for medical time-series analysis. Experimental\nresults demonstrate that ConMIL significantly improves the performance of\nstate-of-the-art LLMs, such as ChatGPT4.0 and Qwen2-VL-7B. Specifically,\n\\ConMIL{}-supported Qwen2-VL-7B achieves 94.92% and 96.82% precision for\nconfident samples in arrhythmia detection and sleep staging, compared to\nstandalone LLM accuracy of 46.13% and 13.16%. These findings highlight the\npotential of ConMIL to bridge task-specific precision and broader contextual\nreasoning, enabling more reliable and interpretable AI-driven clinical decision\nsupport.",
      "tldr_zh": "本研究针对多模态大语言模型(LLMs)在医疗时间序列视觉检查中的领域特定精度不足和微调困难问题，提出ConMIL（一种整合Multiple Instance Learning (MIL)和conformal prediction的决策支持小专业模型，SSMs），以增强LLMs的解释能力和可靠性。ConMIL通过识别临床重要信号段并提供校准的集合值输出，与LLMs无缝整合，实现更精确的医疗分析。实验结果显示，ConMIL支持的Qwen2-VL-7B在心律失常检测和睡眠分期中的精确率分别提升至94.92%和96.82%，远超独立LLMs的46.13%和13.16%。这一方法桥接了任务特定精度与上下文推理的差距，促进可靠且可解释的AI临床决策支持。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16215v1",
      "published_date": "2025-01-27 17:07:20 UTC",
      "updated_date": "2025-01-27 17:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:28.871880"
    },
    {
      "arxiv_id": "2501.16211v1",
      "title": "UDBE: Unsupervised Diffusion-based Brightness Enhancement in Underwater Images",
      "title_zh": "翻译失败",
      "authors": [
        "Tatiana Taís Schein",
        "Gustavo Pereira de Almeira",
        "Stephanie Loi Brião",
        "Rodrigo Andrade de Bem",
        "Felipe Gomes de Oliveira",
        "Paulo L. J. Drews-Jr"
      ],
      "abstract": "Activities in underwater environments are paramount in several scenarios,\nwhich drives the continuous development of underwater image enhancement\ntechniques. A major challenge in this domain is the depth at which images are\ncaptured, with increasing depth resulting in a darker environment. Most\nexisting methods for underwater image enhancement focus on noise removal and\ncolor adjustment, with few works dedicated to brightness enhancement. This work\nintroduces a novel unsupervised learning approach to underwater image\nenhancement using a diffusion model. Our method, called UDBE, is based on\nconditional diffusion to maintain the brightness details of the unpaired input\nimages. The input image is combined with a color map and a Signal-Noise\nRelation map (SNR) to ensure stable training and prevent color distortion in\nthe output images. The results demonstrate that our approach achieves an\nimpressive accuracy rate in the datasets UIEB, SUIM and RUIE, well-established\nunderwater image benchmarks. Additionally, the experiments validate the\nrobustness of our approach, regarding the image quality metrics PSNR, SSIM,\nUIQM, and UISM, indicating the good performance of the brightness enhancement\nprocess. The source code is available here: https://github.com/gusanagy/UDBE.",
      "tldr_zh": "该研究针对水下图像增强的挑战，提出了一种无监督学习方法UDBE，利用diffusion model来专注于亮度增强，以应对深度增加导致的环境黑暗问题。UDBE基于conditional diffusion，将输入图像与color map和Signal-Noise Relation map (SNR)结合，确保训练稳定并避免颜色失真，从而保持亮度细节。实验结果显示，该方法在UIEB、SUIM和RUIE数据集上表现出色，在PSNR、SSIM、UIQM和UISM等图像质量指标上实现了显著改善，证明了其在水下图像亮度增强的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper presented at ICMLA 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.16211v1",
      "published_date": "2025-01-27 17:01:45 UTC",
      "updated_date": "2025-01-27 17:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:39.796864"
    },
    {
      "arxiv_id": "2501.16207v3",
      "title": "From Informal to Formal -- Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Jialun Cao",
        "Yaojie Lu",
        "Meiziniu Li",
        "Haoyang Ma",
        "Haokun Li",
        "Mengda He",
        "Cheng Wen",
        "Le Sun",
        "Hongyu Zhang",
        "Shengchao Qin",
        "Shing-Chi Cheung",
        "Cong Tian"
      ],
      "abstract": "The research in AI-based formal mathematical reasoning has shown an\nunstoppable growth trend. These studies have excelled in mathematical\ncompetitions like IMO and have made significant progress. This paper focuses on\nformal verification, an immediate application scenario of formal reasoning, and\nbreaks it down into sub-tasks. We constructed 18k high-quality\ninstruction-response pairs across five formal specification languages (Coq,\nLean4, Dafny, ACSL, and TLA+) by distilling gpt-4o and evaluated against ten\nopen-sourced LLMs, including recent popular DeepSeek-R1. We also fine-tuned\nseveral 7~8B small models to achieve comparable performance with\nDeepseek-R1-671B. Interestingly, we observed that fine-tuning with formal data\nalso enhances mathematics, reasoning, and coding capabilities. Fine-tuned\nmodels are released at https: //huggingface.co/fm-universe.",
      "tldr_zh": "该论文探讨了如何将自然语言要求转化为可验证的正式证明，聚焦于AI驱动的正式验证任务。研究者构建了18k高质量的指令-响应对，涵盖五种正式规范语言（Coq、Lean4、Dafny、ACSL和TLA+），并使用gpt-4o提炼数据来评估十个开源LLMs，包括DeepSeek-R1。通过微调几个7~8B的小模型，研究实现了与DeepSeek-R1-671B相当的性能，并观察到这种微调还能提升模型在数学、推理和编码方面的能力。微调后的模型已开源在Hugging Face上，为AI在正式推理领域的应用提供了新工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.16207v3",
      "published_date": "2025-01-27 17:00:56 UTC",
      "updated_date": "2025-03-05 15:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:45:52.375822"
    },
    {
      "arxiv_id": "2501.16191v1",
      "title": "Raiders of the Lost Dependency: Fixing Dependency Conflicts in Python using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Antony Bartlett",
        "Cynthia Liem",
        "Annibale Panichella"
      ],
      "abstract": "Fixing Python dependency issues is a tedious and error-prone task for\ndevelopers, who must manually identify and resolve environment dependencies and\nversion constraints of third-party modules and Python interpreters. Researchers\nhave attempted to automate this process by relying on large knowledge graphs\nand database lookup tables. However, these traditional approaches face\nlimitations due to the variety of dependency error types, large sets of\npossible module versions, and conflicts among transitive dependencies. This\nstudy explores the potential of using large language models (LLMs) to\nautomatically fix dependency issues in Python programs. We introduce PLLM\n(pronounced \"plum\"), a novel technique that employs retrieval-augmented\ngeneration (RAG) to help an LLM infer Python versions and required modules for\na given Python file. PLLM builds a testing environment that iteratively (1)\nprompts the LLM for module combinations, (2) tests the suggested changes, and\n(3) provides feedback (error messages) to the LLM to refine the fix. This\nfeedback cycle leverages natural language processing (NLP) to intelligently\nparse and interpret build error messages. We benchmark PLLM on the Gistable\nHG2.9K dataset, a collection of challenging single-file Python gists. We\ncompare PLLM against two state-of-the-art automatic dependency inference\napproaches, namely PyEGo and ReadPyE, w.r.t. the ability to resolve dependency\nissues. Our results indicate that PLLM can fix more dependency issues than the\ntwo baselines, with +218 (+15.97%) more fixes over ReadPyE and +281 (+21.58%)\nover PyEGo. Our deeper analyses suggest that PLLM is particularly beneficial\nfor projects with many dependencies and for specific third-party numerical and\nmachine-learning modules. Our findings demonstrate the potential of LLM-based\napproaches to iteratively resolve Python dependency issues.",
      "tldr_zh": "这篇论文提出 PLLM（一种新型技术），利用大型语言模型 (LLMs) 和检索增强生成 (RAG) 来自动修复 Python 程序中的依赖冲突问题，通过迭代反馈循环（提示 LLMs 建议模块组合、测试更改并反馈错误消息）来智能解析和优化修复过程。相比传统方法，PLLM 在 Gistable HG2.9K 数据集上表现出色，比基线工具 PyEGo 多修复 281 个（+21.58%）问题，比 ReadPyE 多修复 218 个（+15.97%）。研究发现，PLLM 特别适用于具有多依赖的项目，尤其是第三方数值和机器学习模块，这证明了 LLM-based 方法在处理 Python 依赖问题的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under submission to TOSEM, 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16191v1",
      "published_date": "2025-01-27 16:45:34 UTC",
      "updated_date": "2025-01-27 16:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:46:04.996624"
    },
    {
      "arxiv_id": "2501.16182v1",
      "title": "The Linear Attention Resurrection in Vision Transformer",
      "title_zh": "视觉Transformer中的线性注意力复兴",
      "authors": [
        "Chuanyang Zheng"
      ],
      "abstract": "Vision Transformers (ViTs) have recently taken computer vision by storm.\nHowever, the softmax attention underlying ViTs comes with a quadratic\ncomplexity in time and memory, hindering the application of ViTs to\nhigh-resolution images. We revisit the attention design and propose a linear\nattention method to address the limitation, which doesn't sacrifice ViT's core\nadvantage of capturing global representation like existing methods (e.g. local\nwindow attention of Swin). We further investigate the key difference between\nlinear attention and softmax attention. Our empirical results suggest that\nlinear attention lacks a fundamental property of concentrating the distribution\nof the attention matrix. Inspired by this observation, we introduce a local\nconcentration module to enhance linear attention. By incorporating enhanced\nlinear global attention and local window attention, we propose a new ViT\narchitecture, dubbed L$^2$ViT. Notably, L$^2$ViT can effectively capture both\nglobal interactions and local representations while enjoying linear\ncomputational complexity. Extensive experiments demonstrate the strong\nperformance of L$^2$ViT. On image classification, L$^2$ViT achieves 84.4% Top-1\naccuracy on ImageNet-1K without any extra training data or label. By further\npre-training on ImageNet-22k, it attains 87.0% when fine-tuned with resolution\n384$^2$. For downstream tasks, L$^2$ViT delivers favorable performance as a\nbackbone on object detection as well as semantic segmentation.",
      "tldr_zh": "该研究针对 Vision Transformers (ViTs) 中 softmax attention 的二次方复杂度问题，提出了一种线性注意力方法，以支持高分辨率图像处理，同时保留 ViTs 捕捉全局表示的核心优势。作者发现线性注意力缺乏注意力矩阵分布集中的属性，因此引入局部集中模块，并结合增强的线性全局注意力与局部窗口注意力，构建了新的 ViT 架构 L²ViT。该架构实现了线性计算复杂度，并在实验中表现出色：在 ImageNet-1K 上达到 84.4% Top-1 准确率，进一步预训练后提升至 87.0%，并在目标检测和语义分割等下游任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16182v1",
      "published_date": "2025-01-27 16:29:17 UTC",
      "updated_date": "2025-01-27 16:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:46:16.999184"
    },
    {
      "arxiv_id": "2502.15719v1",
      "title": "Governing AI Beyond the Pretraining Frontier",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas A. Caputo"
      ],
      "abstract": "This year, jurisdictions worldwide, including the United States, the European\nUnion, the United Kingdom, and China, are set to enact or revise laws governing\nfrontier AI. Their efforts largely rely on the assumption that increasing model\nscale through pretraining is the path to more advanced AI capabilities. Yet\ngrowing evidence suggests that this \"pretraining paradigm\" may be hitting a\nwall and major AI companies are turning to alternative approaches, like\ninference-time \"reasoning,\" to boost capabilities instead.\n  This paradigm shift presents fundamental challenges for the frontier AI\ngovernance frameworks that target pretraining scale as a key bottleneck useful\nfor monitoring, control, and exclusion, threatening to undermine this new legal\norder as it emerges. This essay seeks to identify these challenges and point to\nnew paths forward for regulation. First, we examine the existing frontier AI\nregulatory regime and analyze some key traits and vulnerabilities. Second, we\nintroduce the concept of the \"pretraining frontier,\" the capabilities threshold\nmade possible by scaling up pretraining alone, and demonstrate how it could\nmake the regulatory field more diffuse and complex and lead to new forms of\ncompetition. Third, we lay out a regulatory approach that focuses on increasing\ntransparency and leveraging new natural technical bottlenecks to effectively\noversee changing frontier AI development while minimizing regulatory burdens\nand protecting fundamental rights. Our analysis provides concrete mechanisms\nfor governing frontier AI systems across diverse technical paradigms, offering\npolicymakers tools for addressing both current and future regulatory challenges\nin frontier AI.",
      "tldr_zh": "这篇论文讨论了全球管辖区（如美国、欧盟、英国和中国）在制定前沿 AI 治理法规时，过度依赖“pretraining paradigm”（预训练范式）来监控模型规模的假设，但证据显示这一范式可能触及瓶颈，转向如推理时间推理等替代方法，从而挑战现有监管框架。作者引入“pretraining frontier”概念，分析了这种转变如何使监管环境更复杂，并引发新的竞争形式。论文提出一种新监管方法，聚焦于提升透明度和利用自然技术瓶颈（如新瓶颈），以有效监督多样化前沿 AI 发展，同时减少监管负担和保护基本权利，为政策制定者提供具体机制应对未来挑战。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.15719v1",
      "published_date": "2025-01-27 16:25:03 UTC",
      "updated_date": "2025-01-27 16:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:46:28.523029"
    },
    {
      "arxiv_id": "2501.16177v1",
      "title": "BAG: Body-Aligned 3D Wearable Asset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongjin Luo",
        "Yang Li",
        "Mingrui Zhang",
        "Senbo Wang",
        "Han Yan",
        "Xibin Song",
        "Taizhang Shang",
        "Wei Mao",
        "Hongdong Li",
        "Xiaoguang Han",
        "Pan Ji"
      ],
      "abstract": "While recent advancements have shown remarkable progress in general 3D shape\ngeneration models, the challenge of leveraging these approaches to\nautomatically generate wearable 3D assets remains unexplored. To this end, we\npresent BAG, a Body-aligned Asset Generation method to output 3D wearable asset\nthat can be automatically dressed on given 3D human bodies. This is achived by\ncontrolling the 3D generation process using human body shape and pose\ninformation. Specifically, we first build a general single-image to consistent\nmultiview image diffusion model, and train it on the large Objaverse dataset to\nachieve diversity and generalizability. Then we train a Controlnet to guide the\nmultiview generator to produce body-aligned multiview images. The control\nsignal utilizes the multiview 2D projections of the target human body, where\npixel values represent the XYZ coordinates of the body surface in a canonical\nspace. The body-conditioned multiview diffusion generates body-aligned\nmultiview images, which are then fed into a native 3D diffusion model to\nproduce the 3D shape of the asset. Finally, by recovering the similarity\ntransformation using multiview silhouette supervision and addressing asset-body\npenetration with physics simulators, the 3D asset can be accurately fitted onto\nthe target human body. Experimental results demonstrate significant advantages\nover existing methods in terms of image prompt-following capability, shape\ndiversity, and shape quality. Our project page is available at\nhttps://bag-3d.github.io/.",
      "tldr_zh": "本文提出BAG方法，用于自动生成可与给定3D人体对齐的可穿戴资产，通过人体形状和姿势信息控制3D生成过程。具体而言，该方法先训练一个从单图像到一致多视图图像的扩散模型，然后使用Controlnet引导生成基于人体多视图2D投影的图像，再通过3D扩散模型输出资产形状，并利用多视图轮廓监督和物理模拟器确保资产准确拟合人体。实验结果表明，BAG在图像提示遵循能力、形状多样性和质量方面显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "video: https://youtu.be/XJtG82LjQKc",
      "pdf_url": "http://arxiv.org/pdf/2501.16177v1",
      "published_date": "2025-01-27 16:23:45 UTC",
      "updated_date": "2025-01-27 16:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:46:39.954015"
    },
    {
      "arxiv_id": "2501.16174v1",
      "title": "Measuring Heterogeneity in Machine Learning with Distributed Energy Distance",
      "title_zh": "翻译失败",
      "authors": [
        "Mengchen Fan",
        "Baocheng Geng",
        "Roman Shterenberg",
        "Joseph A. Casey",
        "Zhong Chen",
        "Keren Li"
      ],
      "abstract": "In distributed and federated learning, heterogeneity across data sources\nremains a major obstacle to effective model aggregation and convergence. We\nfocus on feature heterogeneity and introduce energy distance as a sensitive\nmeasure for quantifying distributional discrepancies. While we show that energy\ndistance is robust for detecting data distribution shifts, its direct use in\nlarge-scale systems can be prohibitively expensive. To address this, we develop\nTaylor approximations that preserve key theoretical quantitative properties\nwhile reducing computational overhead. Through simulation studies, we show how\naccurately capturing feature discrepancies boosts convergence in distributed\nlearning. Finally, we propose a novel application of energy distance to assign\npenalty weights for aligning predictions across heterogeneous nodes, ultimately\nenhancing coordination in federated and distributed settings.",
      "tldr_zh": "本研究针对分布式和联邦学习中数据源的特征异质性问题，引入energy distance作为一种敏感度量来量化分布差异，并证明其在检测数据分布偏移时的鲁棒性。为了降低大规模系统中的计算开销，研究开发了Taylor approximations来保留关键理论属性同时减少开销。通过模拟研究，展示了准确捕获特征差异如何提升分布式学习的收敛速度。最后，提出energy distance的新应用，用于分配惩罚权重以对齐异质节点上的预测，从而改善联邦和分布式设置中的协调。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16174v1",
      "published_date": "2025-01-27 16:15:57 UTC",
      "updated_date": "2025-01-27 16:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:46:51.635367"
    },
    {
      "arxiv_id": "2501.16164v1",
      "title": "MetaDecorator: Generating Immersive Virtual Tours through Multimodality",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Xie",
        "Yang Liu",
        "Jeannie S. A. Lee",
        "Haiwei Dong"
      ],
      "abstract": "MetaDecorator, is a framework that empowers users to personalize virtual\nspaces. By leveraging text-driven prompts and image synthesis techniques,\nMetaDecorator adorns static panoramas captured by 360{\\deg} imaging devices,\ntransforming them into uniquely styled and visually appealing environments.\nThis significantly enhances the realism and engagement of virtual tours\ncompared to traditional offerings. Beyond the core framework, we also discuss\nthe integration of Large Language Models (LLMs) and haptics in the VR\napplication to provide a more immersive experience.",
      "tldr_zh": "MetaDecorator 是一个框架，允许用户通过多模态技术个性化虚拟空间，利用文本驱动提示和图像合成技术对 360° 成像设备捕获的静态全景进行装饰，从而创建出独特风格的视觉环境。相比传统虚拟游览，该框架显著提升了真实性和互动性。论文还探讨了整合 Large Language Models (LLMs) 和 haptics 到 VR 应用中的可能性，以提供更沉浸式的体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16164v1",
      "published_date": "2025-01-27 15:59:58 UTC",
      "updated_date": "2025-01-27 15:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:47:02.688874"
    },
    {
      "arxiv_id": "2501.16154v2",
      "title": "AdaCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive Chain-of-Thought",
      "title_zh": "AdaCoT：通过自适应链式思考重新审视跨语言事实推理",
      "authors": [
        "Xin Huang",
        "Tarun Kumar Vangani",
        "Zhengyuan Liu",
        "Bowei Zou",
        "Ai Ti Aw"
      ],
      "abstract": "Large language models have shown impressive multilingual capabilities through\npretraining on diverse corpora. While these models show strong reasoning\nabilities, their performance varies significantly across languages due to\nimbalanced training data distribution. Existing approaches using sample-level\ntranslation for extensive multilingual pretraining and cross-lingual tuning\nface scalability challenges and often fail to capture nuanced reasoning\nprocesses across languages. In this paper, we introduce AdaCoT (Adaptive\nChain-of-Thought), a framework that enhances multilingual factual reasoning by\ndynamically routing thought processes in intermediary ``thinking languages''\nbefore generating target-language responses. AdaCoT leverages a\nlanguage-agnostic core and incorporates an adaptive, reward-based mechanism for\nselecting optimal reasoning pathways without requiring additional pretraining.\nOur comprehensive evaluation across multiple benchmarks demonstrates\nsubstantial improvements in both factual reasoning quality and cross-lingual\nconsistency, with particularly strong performance gains in low-resource\nlanguage settings. The results suggest that adaptive reasoning paths can\neffectively bridge the performance gap between high and low-resource languages\nwhile maintaining cultural and linguistic nuances.",
      "tldr_zh": "本论文重新审视跨语言事实推理问题，提出 AdaCoT 框架，通过自适应 Chain-of-Thought 动态路由中间“思考语言”的推理过程，来提升大语言模型的多语言性能，而无需额外预训练。AdaCoT 采用语言无关的核心和基于奖励的机制，选择最佳推理路径，以解决训练数据不平衡带来的跨语言差异。实验结果显示，该框架在多个基准测试中显著提高了事实推理质量和跨语言一致性，尤其在低资源语言环境中表现出色，并有效桥接了高资源与低资源语言的性能差距，同时保留了文化和语言细微差别。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16154v2",
      "published_date": "2025-01-27 15:48:57 UTC",
      "updated_date": "2025-05-09 05:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:47:16.553971"
    },
    {
      "arxiv_id": "2501.16150v1",
      "title": "AI Agents for Computer Use: A Review of Instruction-based Computer Control, GUI Automation, and Operator Assistants",
      "title_zh": "AI 代理用于计算机应用",
      "authors": [
        "Pascal J. Sager",
        "Benjamin Meyer",
        "Peng Yan",
        "Rebekka von Wartburg-Kottler",
        "Layan Etaiwi",
        "Aref Enayati",
        "Gabriel Nobel",
        "Ahmed Abdulkadir",
        "Benjamin F. Grewe",
        "Thilo Stadelmann"
      ],
      "abstract": "Instruction-based computer control agents (CCAs) execute complex action\nsequences on personal computers or mobile devices to fulfill tasks using the\nsame graphical user interfaces as a human user would, provided instructions in\nnatural language. This review offers a comprehensive overview of the emerging\nfield of instruction-based computer control, examining available agents --\ntheir taxonomy, development, and respective resources -- and emphasizing the\nshift from manually designed, specialized agents to leveraging foundation\nmodels such as large language models (LLMs) and vision-language models (VLMs).\nWe formalize the problem and establish a taxonomy of the field to analyze\nagents from three perspectives: (a) the environment perspective, analyzing\ncomputer environments; (b) the interaction perspective, describing observations\nspaces (e.g., screenshots, HTML) and action spaces (e.g., mouse and keyboard\nactions, executable code); and (c) the agent perspective, focusing on the core\nprinciple of how an agent acts and learns to act. Our framework encompasses\nboth specialized and foundation agents, facilitating their comparative analysis\nand revealing how prior solutions in specialized agents, such as an environment\nlearning step, can guide the development of more capable foundation agents.\nAdditionally, we review current CCA datasets and CCA evaluation methods and\noutline the challenges to deploying such agents in a productive setting. In\ntotal, we review and classify 86 CCAs and 33 related datasets. By highlighting\ntrends, limitations, and future research directions, this work presents a\ncomprehensive foundation to obtain a broad understanding of the field and push\nits future development.",
      "tldr_zh": "这篇综述探讨了基于指令的计算机控制代理（CCAs），包括GUI自动化和操作员助手的发展，强调从手动设计专用代理向利用基础模型如大型语言模型（LLMs）和视觉语言模型（VLMs）的转变。\n论文形式化了问题，建立了一个分类法，从环境视角（计算机环境）、交互视角（观察和动作空间，如屏幕截图或鼠标操作）和代理视角（代理的行动和学习原理）进行分析。\n通过审查86个CCAs和33个相关数据集，该工作总结了当前挑战、评估方法，并指出了未来研究方向，如提升代理在实际生产环境中的部署能力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16150v1",
      "published_date": "2025-01-27 15:44:02 UTC",
      "updated_date": "2025-01-27 15:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:47:28.452076"
    },
    {
      "arxiv_id": "2501.16146v1",
      "title": "Toward Efficient Generalization in 3D Human Pose Estimation via a Canonical Domain Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Hoosang Lee",
        "Jeha Ryu"
      ],
      "abstract": "Recent advancements in deep learning methods have significantly improved the\nperformance of 3D Human Pose Estimation (HPE). However, performance degradation\ncaused by domain gaps between source and target domains remains a major\nchallenge to generalization, necessitating extensive data augmentation and/or\nfine-tuning for each specific target domain. To address this issue more\nefficiently, we propose a novel canonical domain approach that maps both the\nsource and target domains into a unified canonical domain, alleviating the need\nfor additional fine-tuning in the target domain. To construct the canonical\ndomain, we introduce a canonicalization process to generate a novel canonical\n2D-3D pose mapping that ensures 2D-3D pose consistency and simplifies 2D-3D\npose patterns, enabling more efficient training of lifting networks. The\ncanonicalization of both domains is achieved through the following steps: (1)\nin the source domain, the lifting network is trained within the canonical\ndomain; (2) in the target domain, input 2D poses are canonicalized prior to\ninference by leveraging the properties of perspective projection and known\ncamera intrinsics. Consequently, the trained network can be directly applied to\nthe target domain without requiring additional fine-tuning. Experiments\nconducted with various lifting networks and publicly available datasets (e.g.,\nHuman3.6M, Fit3D, MPI-INF-3DHP) demonstrate that the proposed method\nsubstantially improves generalization capability across datasets while using\nthe same data volume.",
      "tldr_zh": "该研究针对3D Human Pose Estimation (HPE) 中因源域和目标域间差距导致的性能下降问题，提出了一种高效的canonical domain approach。该方法将源域和目标域映射到一个统一的规范域，通过一个规范化的2D-3D姿态映射过程，确保2D-3D姿态一致性和简化姿态模式，从而在训练lifting networks时无需针对每个目标域进行额外微调。实验结果显示，在各种lifting networks和公开数据集（如Human3.6M、Fit3D、MPI-INF-3DHP）上，该方法显著提升了泛化能力，同时保持相同的数据量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16146v1",
      "published_date": "2025-01-27 15:39:39 UTC",
      "updated_date": "2025-01-27 15:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:47:39.985165"
    },
    {
      "arxiv_id": "2501.16142v1",
      "title": "Towards General-Purpose Model-Free Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Scott Fujimoto",
        "Pierluca D'Oro",
        "Amy Zhang",
        "Yuandong Tian",
        "Michael Rabbat"
      ],
      "abstract": "Reinforcement learning (RL) promises a framework for near-universal\nproblem-solving. In practice however, RL algorithms are often tailored to\nspecific benchmarks, relying on carefully tuned hyperparameters and algorithmic\nchoices. Recently, powerful model-based RL methods have shown impressive\ngeneral results across benchmarks but come at the cost of increased complexity\nand slow run times, limiting their broader applicability. In this paper, we\nattempt to find a unifying model-free deep RL algorithm that can address a\ndiverse class of domains and problem settings. To achieve this, we leverage\nmodel-based representations that approximately linearize the value function,\ntaking advantage of the denser task objectives used by model-based RL while\navoiding the costs associated with planning or simulated trajectories. We\nevaluate our algorithm, MR.Q, on a variety of common RL benchmarks with a\nsingle set of hyperparameters and show a competitive performance against\ndomain-specific and general baselines, providing a concrete step towards\nbuilding general-purpose model-free deep RL algorithms.",
      "tldr_zh": "本文旨在开发一个通用的模型无关（model-free）深度强化学习（Reinforcement Learning, RL）算法，以解决现有RL算法需针对特定基准调优的问题。作者提出MR.Q算法，通过利用基于模型的表示来近似线性化价值函数，结合模型-based RL的密集任务目标，同时避免规划或模拟轨迹的成本。实验结果显示，MR.Q在各种常见RL基准上，使用单一超参数集，便可与特定领域和一般基线算法竞争性能，为构建通用目的的模型-free深度RL算法提供了关键进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16142v1",
      "published_date": "2025-01-27 15:36:37 UTC",
      "updated_date": "2025-01-27 15:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:47:52.802538"
    },
    {
      "arxiv_id": "2501.17195v1",
      "title": "Atla Selene Mini: A General Purpose Evaluation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Alexandru",
        "Antonia Calvi",
        "Henry Broomfield",
        "Jackson Golden",
        "Kyle Dai",
        "Mathias Leys",
        "Maurice Burger",
        "Max Bartolo",
        "Roman Engeler",
        "Sashank Pisupati",
        "Toby Drane",
        "Young Sun Park"
      ],
      "abstract": "We introduce Atla Selene Mini, a state-of-the-art small language\nmodel-as-a-judge (SLMJ). Selene Mini is a general-purpose evaluator that\noutperforms the best SLMJs and GPT-4o-mini on overall performance across 11\nout-of-distribution benchmarks, spanning absolute scoring, classification, and\npairwise preference tasks. It is the highest-scoring 8B generative model on\nRewardBench, surpassing strong baselines like GPT-4o and specialized judges. To\nachieve this, we develop a principled data curation strategy that augments\npublic datasets with synthetically generated critiques and ensures high quality\nthrough filtering and dataset ablations. We train our model on a combined\ndirect preference optimization (DPO) and supervised fine-tuning (SFT) loss, and\nproduce a highly promptable evaluator that excels in real-world scenarios.\nSelene Mini shows dramatically improved zero-shot agreement with human expert\nevaluations on financial and medical industry datasets. It is also robust to\nvariations in prompt format. Preliminary results indicate that Selene Mini is\nthe top-ranking evaluator in a live, community-driven Judge Arena. We release\nthe model weights on HuggingFace\n(https://hf.co/AtlaAI/Selene-1-Mini-Llama-3.1-8B) and Ollama to encourage\nwidespread community adoption.",
      "tldr_zh": "我们引入了Atla Selene Mini，一种先进的8B小型语言模型-as-a-judge (SLMJ)，它在11个分布外基准测试中超越了GPT-4o-mini和最佳SLMJs，在绝对评分、分类和配对偏好任务上表现出色。研究团队开发了原则性的数据整理策略，包括使用合成生成的批评增强公共数据集，并通过过滤和数据集消融确保高质量，然后采用结合直接偏好优化 (DPO) 和监督微调 (SFT) 的训练方法，使模型在真实场景中高度可提示。实验结果显示，Selene Mini在RewardBench上成为最高分的8B生成模型，与人类专家在金融和医疗数据集上的零样本评估同意度大幅提升，并对提示格式变化具有鲁棒性。该模型已在HuggingFace和Ollama上开源，以推动社区采用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17195v1",
      "published_date": "2025-01-27 15:09:08 UTC",
      "updated_date": "2025-01-27 15:09:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:48:04.539835"
    },
    {
      "arxiv_id": "2501.16100v2",
      "title": "Automated Detection of Sport Highlights from Audio and Video Sources",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Della Santa",
        "Morgana Lalli"
      ],
      "abstract": "This study presents a novel Deep Learning-based and lightweight approach for\nthe automated detection of sports highlights (HLs) from audio and video\nsources. HL detection is a key task in sports video analysis, traditionally\nrequiring significant human effort. Our solution leverages Deep Learning (DL)\nmodels trained on relatively small datasets of audio Mel-spectrograms and\ngrayscale video frames, achieving promising accuracy rates of 89% and 83% for\naudio and video detection, respectively. The use of small datasets, combined\nwith simple architectures, demonstrates the practicality of our method for fast\nand cost-effective deployment. Furthermore, an ensemble model combining both\nmodalities shows improved robustness against false positives and false\nnegatives. The proposed methodology offers a scalable solution for automated HL\ndetection across various types of sports video content, reducing the need for\nmanual intervention. Future work will focus on enhancing model architectures\nand extending this approach to broader scene-detection tasks in media analysis.",
      "tldr_zh": "本研究提出了一种基于深度学习的轻量级方法，用于从音频和视频源自动检测体育亮点（HLs），以减少传统的人工干预。该方法利用小数据集训练模型，包括音频 Mel-spectrograms 和灰度视频帧，分别实现了89%的音频检测准确率和83%的视频检测准确率。通过结合两种模态的 ensemble model，进一步提升了模型对假阳性和假阴性的鲁棒性。该方法提供了一个可扩展的解决方案，适用于各种体育视频内容，并计划未来优化模型架构并扩展到更广泛的媒体分析任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16100v2",
      "published_date": "2025-01-27 14:50:13 UTC",
      "updated_date": "2025-01-31 09:03:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:48:14.946394"
    },
    {
      "arxiv_id": "2501.16093v1",
      "title": "STAR: Stepwise Task Augmentation and Relation Learning for Aspect Sentiment Quad Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Wenna Lai",
        "Haoran Xie",
        "Guandong Xu",
        "Qing Li"
      ],
      "abstract": "Aspect-based sentiment analysis (ABSA) aims to identify four sentiment\nelements, including aspect term, aspect category, opinion term, and sentiment\npolarity. These elements construct the complete picture of sentiments. The most\nchallenging task, aspect sentiment quad prediction (ASQP), predicts these\nelements simultaneously, hindered by difficulties in accurately coupling\ndifferent sentiment elements. A key challenge is insufficient annotated data\nthat limits the capability of models in semantic understanding and reasoning\nabout quad prediction. To address this, we propose stepwise task augmentation\nand relation learning (STAR), a strategy inspired by human reasoning. STAR\nconstructs auxiliary data to learn quadruple relationships incrementally by\naugmenting with pairwise and overall relation tasks derived from training data.\nBy encouraging the model to infer causal relationships among sentiment elements\nwithout requiring additional annotations, STAR effectively enhances quad\nprediction. Extensive experiments demonstrate the proposed STAR exhibits\nsuperior performance on four benchmark datasets.",
      "tldr_zh": "本论文提出STAR方法，用于Aspect-based sentiment analysis (ABSA)中的Aspect Sentiment Quad Prediction (ASQP)任务，该任务需同时预测aspect term、aspect category、opinion term和sentiment polarity，但受限于标注数据不足和情感元素耦合困难。STAR受人类推理启发，通过stepwise task augmentation和relation learning，从训练数据派生配对和整体关系任务，构建辅助数据并逐步学习四元组关系，从而增强模型的语义理解和因果推理能力，而无需额外标注。实验结果显示，STAR在四个基准数据集上表现出优越性能，显著提升了ASQP的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.16093v1",
      "published_date": "2025-01-27 14:41:20 UTC",
      "updated_date": "2025-01-27 14:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:48:28.208683"
    },
    {
      "arxiv_id": "2502.20402v1",
      "title": "Beyond transparency: computational reliabilism as an externalist epistemology of algorithms",
      "title_zh": "超越透明性：计算可靠主义作为算法的外在主义认识论",
      "authors": [
        "Juan Manuel Durán"
      ],
      "abstract": "This chapter is interested in the epistemology of algorithms. As I intend to\napproach the topic, this is an issue about epistemic justification. Current\napproaches to justification emphasize the transparency of algorithms, which\nentails elucidating their internal mechanisms -- such as functions and\nvariables -- and demonstrating how (or that) these produce outputs. Thus, the\nmode of justification through transparency is contingent on what can be shown\nabout the algorithm and, in this sense, is internal to the algorithm. In\ncontrast, I advocate for an externalist epistemology of algorithms that I term\ncomputational reliabilism (CR). While I have previously introduced and examined\nCR in the field of computer simulations ([42, 53, 4]), this chapter extends\nthis reliabilist epistemology to encompass a broader spectrum of algorithms\nutilized in various scientific disciplines, with a particular emphasis on\nmachine learning applications. At its core, CR posits that an algorithm's\noutput is justified if it is produced by a reliable algorithm. A reliable\nalgorithm is one that has been specified, coded, used, and maintained utilizing\nreliability indicators. These reliability indicators stem from formal methods,\nalgorithmic metrics, expert competencies, cultures of research, and other\nscientific endeavors. The primary aim of this chapter is to delineate the\nfoundations of CR, explicate its operational mechanisms, and outline its\npotential as an externalist epistemology of algorithms.",
      "tldr_zh": "这篇论文探讨算法的认识论（epistemic justification），批评当前强调算法透明性的内部主义方法，即通过揭示内部机制（如函数和变量）来证明输出正当性。作者提出 computational reliabilism (CR) 作为一种外部主义 epistemology of algorithms，认为算法输出在可靠算法基础上才被正当化，可靠算法依赖于可靠性指标，如形式方法、算法指标、专家能力及研究文化。论文扩展 CR 到机器学习等科学领域，阐述其基础、运作机制，并展示其作为外部主义框架的潜力，为算法认识论提供新视角。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20402v1",
      "published_date": "2025-01-27 14:31:47 UTC",
      "updated_date": "2025-01-27 14:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:48:40.138693"
    },
    {
      "arxiv_id": "2502.00043v2",
      "title": "Mitigating Traffic Oscillations in Mixed Traffic Flow with Scalable Deep Koopman Predictive Control",
      "title_zh": "通过可扩展的深度 Koopman 预测控制缓解混合交通流中的交通波动",
      "authors": [
        "Hao Lyu",
        "Yanyong Guo",
        "Pan Liu",
        "Nan Zheng",
        "Ting Wang",
        "Quansheng Yue"
      ],
      "abstract": "The use of connected automated vehicle (CAV) is advocated to mitigate traffic\noscillations in mixed traffic flow consisting of CAVs and human driven vehicles\n(HDVs). This study proposes an adaptive deep Koopman predictive control\nframework (AdapKoopPC) for regulating mixed traffic flow. Firstly, a Koopman\ntheory-based adaptive trajectory prediction deep network (AdapKoopnet) is\ndesigned for modeling HDVs car-following behavior. AdapKoopnet enables the\nrepresentation of HDVs behavior by a linear model in a high-dimensional space.\nSecondly, the model predictive control is employed to smooth the mixed traffic\nflow, where the combination of the linear dynamic model of CAVs and linear\nprediction blocks from AdapKoopnet is embedded as the predictive model into the\nAdapKoopPC. Finally, the predictive performance of the prosed AdapKoopnet is\nverified using the HighD naturalistic driving dataset. Furthermore, the control\nperformance of AdapKoopPC is validated by the numerical simulations. Results\ndemonstrate that the AdapKoopnet provides more accuracy HDVs predicted\ntrajectories than the baseline nonlinear models. Moreover, the proposed\nAdapKoopPC exhibits more effective control performance with less computation\ncost compared with baselines in mitigating traffic oscillations, especially at\nthe low CAVs penetration rates. The code of proposed AdapKoopPC is open source.",
      "tldr_zh": "本文提出一种自适应深度 Koopman 预测控制框架 (AdapKoopPC)，旨在利用连接自动车辆 (CAV) 来缓解混合交通流中 CAV 和人类驾驶车辆 (HDV) 造成的交通震荡。框架的核心组件是基于 Koopman 理论的 AdapKoopnet 网络，用于建模 HDV 的跟车行为，并将其表示为高维线性模型，以提升预测准确性和控制效率。实验验证显示，AdapKoopnet 比基线非线性模型预测轨迹更精确，而 AdapKoopPC 在低 CAV 渗透率下显著减少交通震荡，同时降低计算成本，且相关代码已开源。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00043v2",
      "published_date": "2025-01-27 14:28:20 UTC",
      "updated_date": "2025-04-22 15:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:50:44.431013"
    },
    {
      "arxiv_id": "2501.16075v1",
      "title": "PISCO: Pretty Simple Compression for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Louis",
        "Hervé Déjean",
        "Stéphane Clinchant"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) pipelines enhance Large Language Models\n(LLMs) by retrieving relevant documents, but they face scalability issues due\nto high inference costs and limited context size. Document compression is a\npractical solution, but current soft compression methods suffer from accuracy\nlosses and require extensive pretraining. In this paper, we introduce PISCO, a\nnovel method that achieves a 16x compression rate with minimal accuracy loss\n(0-3%) across diverse RAG-based question-answering (QA) tasks. Unlike existing\napproaches, PISCO requires no pretraining or annotated data, relying solely on\nsequence-level knowledge distillation from document-based questions. With the\nability to fine-tune a 7-10B LLM in 48 hours on a single A100 GPU, PISCO offers\na highly efficient and scalable solution. We present comprehensive experiments\nshowing that PISCO outperforms existing compression models by 8% in accuracy.",
      "tldr_zh": "该论文提出 PISCO，一种简单高效的压缩方法，用于 Retrieval-Augmented Generation (RAG)，以解决 Large Language Models (LLMs) 在高推理成本和上下文大小限制方面的可扩展性问题。\nPISCO 通过序列级知识蒸馏（knowledge distillation）从文档-based 问题中实现 16x 压缩率，同时保持准确性损失最小（0-3%），且无需预训练或标注数据。\n实验结果显示，PISCO 在各种 RAG-based 问答任务中比现有压缩模型准确性高 8%，并能在单 A100 GPU 上用 48 小时微调 7-10B LLM，提供了一个高效可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16075v1",
      "published_date": "2025-01-27 14:26:27 UTC",
      "updated_date": "2025-01-27 14:26:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:50:57.390072"
    },
    {
      "arxiv_id": "2501.18628v1",
      "title": "Indiana Jones: There Are Always Some Useful Ancient Relics",
      "title_zh": "翻译失败",
      "authors": [
        "Junchen Ding",
        "Jiahao Zhang",
        "Yi Liu",
        "Ziqi Ding",
        "Gelei Deng",
        "Yuekang Li"
      ],
      "abstract": "This paper introduces Indiana Jones, an innovative approach to jailbreaking\nLarge Language Models (LLMs) by leveraging inter-model dialogues and\nkeyword-driven prompts. Through orchestrating interactions among three\nspecialised LLMs, the method achieves near-perfect success rates in bypassing\ncontent safeguards in both white-box and black-box LLMs. The research exposes\nsystemic vulnerabilities within contemporary models, particularly their\nsusceptibility to producing harmful or unethical outputs when guided by\nostensibly innocuous prompts framed in historical or contextual contexts.\nExperimental evaluations highlight the efficacy and adaptability of Indiana\nJones, demonstrating its superiority over existing jailbreak methods. These\nfindings emphasise the urgent need for enhanced ethical safeguards and robust\nsecurity measures in the development of LLMs. Moreover, this work provides a\ncritical foundation for future studies aimed at fortifying LLMs against\nadversarial exploitation while preserving their utility and flexibility.",
      "tldr_zh": "这篇论文介绍了Indiana Jones方法，一种创新的越狱(jailbreaking)Large Language Models (LLMs)技术，通过三个专门LLMs的交互对话和关键词驱动提示，实现近乎完美的成功率来绕过白盒和黑盒模型的内容安全机制。\n该方法揭示了LLMs在历史或上下文框架下的系统性漏洞，导致它们容易产生有害或不道德输出。\n实验结果证明了Indiana Jones的有效性和适应性，比现有越狱方法更优越，并强调了加强LLMs伦理保障和安全措施的紧迫性，为未来对抗性研究奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18628v1",
      "published_date": "2025-01-27 14:12:07 UTC",
      "updated_date": "2025-01-27 14:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:49:16.396910"
    },
    {
      "arxiv_id": "2501.16061v1",
      "title": "The Unbearable Lightness of Prompting: A Critical Reflection on the Environmental Impact of genAI use in Design Education",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Luce Lupetti",
        "Elena Cavallin",
        "Dave Murray-Rust"
      ],
      "abstract": "Design educators are finding ways to support students in skillfully using\nGenAI tools in their practices while encouraging the critical scrutiny of the\nethical and social issues around these technologies. However, the issue of\nenvironmental sustainability remains unaddressed. There is a lack of both\nresources to grasp the environmental costs of genAI in education and a lack of\nshared practices for engaging with the issue. This paper critically reflects on\nthe energy costs of using genAI in design education, using a workshop held in\n2023 with 49 students as a motivating example. Through this reflection, we\ndevelop a set of five alternative stances, with related actions, that support\nthe conscious use of genAI in design education. The work contributes to the\nfield of design and HCI by bringing together ways for educators to reflect on\ntheir practices, informing the future development of educational programs\naround genAI.",
      "tldr_zh": "这篇论文批判性地反思了生成式 AI (genAI) 在设计教育中的环境影响，指出现有资源和实践未能充分解决其能源成本问题，并以 2023 年一个涉及 49 名学生的研讨会为例进行分析。论文提出了五种替代立场（alternative stances）和相关行动，以促进 genAI 的有意识使用。最终，该工作为设计和 HCI 领域贡献了教育者反思教学实践的框架，并指导未来教育程序的开发。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "25 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.16061v1",
      "published_date": "2025-01-27 14:01:14 UTC",
      "updated_date": "2025-01-27 14:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:49:27.711001"
    },
    {
      "arxiv_id": "2501.16050v1",
      "title": "Skeleton-Guided-Translation: A Benchmarking Framework for Code Repository Translation with Fine-Grained Quality Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Zhang",
        "Jiaheng Wen",
        "Fangkai Yang",
        "Pu Zhao",
        "Yu Kang",
        "Junhao Wang",
        "Maoquan Wang",
        "Yufan Huang",
        "Elsie Nallipogu",
        "Qingwei Lin",
        "Yingnong Dang",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "The advancement of large language models has intensified the need to\nmodernize enterprise applications and migrate legacy systems to secure,\nversatile languages. However, existing code translation benchmarks primarily\nfocus on individual functions, overlooking the complexities involved in\ntranslating entire repositories, such as maintaining inter-module coherence and\nmanaging dependencies. While some recent repository-level translation\nbenchmarks attempt to address these challenges, they still face limitations,\nincluding poor maintainability and overly coarse evaluation granularity, which\nmake them less developer-friendly. We introduce Skeleton-Guided-Translation, a\nframework for repository-level Java to C# code translation with fine-grained\nquality evaluation. It uses a two-step process: first translating the\nrepository's structural \"skeletons\", then translating the full repository\nguided by these skeletons. Building on this, we present TRANSREPO-BENCH, a\nbenchmark of high quality open-source Java repositories and their corresponding\nC# skeletons, including matching unit tests and build configurations. Our unit\ntests are fixed and can be applied across multiple or incremental translations\nwithout manual adjustments, enhancing automation and scalability in\nevaluations. Additionally, we develop fine-grained evaluation metrics that\nassess translation quality at the individual test case level, addressing\ntraditional binary metrics' inability to distinguish when build failures cause\nall tests to fail. Evaluations using TRANSREPO-BENCH highlight key challenges\nand advance more accurate repository level code translation.",
      "tldr_zh": "该论文提出 Skeleton-Guided-Translation 框架，用于仓库级 Java 到 C# 代码翻译，解决现有基准忽略模块一致性和依赖管理的局限性。该框架采用两步过程：先翻译仓库的结构“skeletons”（骨架），然后用这些骨架指导完整仓库翻译，并构建 TRANSREPO-BENCH 基准，包括高质量开源 Java 仓库、对应 C# 骨架、固定单元测试和构建配置，以提升评估的自动化和可扩展性。论文还开发了细粒度评估指标，在单个测试用例级别评估翻译质量，克服传统二元指标的缺陷；通过 TRANSREPO-BENCH 评估，突出了关键挑战并推动更准确的仓库级代码翻译。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16050v1",
      "published_date": "2025-01-27 13:44:51 UTC",
      "updated_date": "2025-01-27 13:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:51:09.034911"
    },
    {
      "arxiv_id": "2501.16033v1",
      "title": "PRISMe: A Novel LLM-Powered Tool for Interactive Privacy Policy Assessment",
      "title_zh": "PRISMe：一种新型LLM驱动的交互式隐私政策评估工具",
      "authors": [
        "Vincent Freiberger",
        "Arthur Fleig",
        "Erik Buchmann"
      ],
      "abstract": "Protecting online privacy requires users to engage with and comprehend\nwebsite privacy policies, but many policies are difficult and tedious to read.\nWe present PRISMe (Privacy Risk Information Scanner for Me), a novel Large\nLanguage Model (LLM)-driven privacy policy assessment tool, which helps users\nto understand the essence of a lengthy, complex privacy policy while browsing.\nThe tool, a browser extension, integrates a dashboard and an LLM chat. One\nmajor contribution is the first rigorous evaluation of such a tool. In a\nmixed-methods user study (N=22), we evaluate PRISMe's efficiency, usability,\nunderstandability of the provided information, and impacts on awareness. While\nour tool improves privacy awareness by providing a comprehensible quick\noverview and a quality chat for in-depth discussion, users note issues with\nconsistency and building trust in the tool. From our insights, we derive\nimportant design implications to guide future policy analysis tools.",
      "tldr_zh": "本研究引入了 PRISMe，一种基于 Large Language Model (LLM) 的交互式工具，用于评估和简化网站隐私政策，帮助用户快速理解复杂的内容。该工具以浏览器扩展形式呈现，结合仪表板提供快速概述和 LLM 聊天功能，支持深入讨论。研究通过混合方法用户研究 (N=22) 评估了工具的效率、可用性、信息易懂性及其对隐私意识的提升，结果显示 PRISMe 显著提高了用户隐私意识，但也暴露了工具一致性和信任问题，并据此提出未来政策分析工具的设计启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.m; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.16033v1",
      "published_date": "2025-01-27 13:27:04 UTC",
      "updated_date": "2025-01-27 13:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:51:20.161711"
    },
    {
      "arxiv_id": "2501.16029v1",
      "title": "FDLLM: A Text Fingerprint Detection Method for LLMs in Multi-Language, Multi-Domain Black-Box Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Fu",
        "Junfan Chen",
        "Hongyu Sun",
        "Ting Yang",
        "Ruidong Li",
        "Yuqing Zhang"
      ],
      "abstract": "Using large language models (LLMs) integration platforms without transparency\nabout which LLM is being invoked can lead to potential security risks.\nSpecifically, attackers may exploit this black-box scenario to deploy malicious\nmodels and embed viruses in the code provided to users. In this context, it is\nincreasingly urgent for users to clearly identify the LLM they are interacting\nwith, in order to avoid unknowingly becoming victims of malicious models.\nHowever, existing studies primarily focus on mixed classification of human and\nmachine-generated text, with limited attention to classifying texts generated\nsolely by different models. Current research also faces dual bottlenecks: poor\nquality of LLM-generated text (LLMGT) datasets and limited coverage of\ndetectable LLMs, resulting in poor detection performance for various LLMGT in\nblack-box scenarios. We propose the first LLMGT fingerprint detection model,\n\\textbf{FDLLM}, based on Qwen2.5-7B and fine-tuned using LoRA to address these\nchallenges. FDLLM can more efficiently handle detection tasks across\nmultilingual and multi-domain scenarios. Furthermore, we constructed a dataset\nnamed \\textbf{FD-Datasets}, consisting of 90,000 samples that span multiple\nlanguages and domains, covering 20 different LLMs. Experimental results\ndemonstrate that FDLLM achieves a macro F1 score 16.7\\% higher than the best\nbaseline method, LM-D.",
      "tldr_zh": "该研究针对黑箱LLM环境中的安全风险，提出了一种文本指纹检测方法FDLLM，用于识别不同LLMs生成的文本，以帮助用户避免恶意模型的威胁。FDLLM基于Qwen2.5-7B模型，并通过LoRA微调，高效处理多语言和多领域场景，同时构建了包含90,000样本的FD-Datasets数据集，覆盖20个LLMs。实验结果表明，FDLLM的宏F1分数比最佳基线LM-D高16.7%，显著提升了检测性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16029v1",
      "published_date": "2025-01-27 13:18:40 UTC",
      "updated_date": "2025-01-27 13:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:51:33.362853"
    },
    {
      "arxiv_id": "2501.18626v3",
      "title": "The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Berezin",
        "Reza Farahbakhsh",
        "Noel Crespi"
      ],
      "abstract": "We present a novel class of jailbreak adversarial attacks on LLMs, termed\nTask-in-Prompt (TIP) attacks. Our approach embeds sequence-to-sequence tasks\n(e.g., cipher decoding, riddles, code execution) into the model's prompt to\nindirectly generate prohibited inputs. To systematically assess the\neffectiveness of these attacks, we introduce the PHRYGE benchmark. We\ndemonstrate that our techniques successfully circumvent safeguards in six\nstate-of-the-art language models, including GPT-4o and LLaMA 3.2. Our findings\nhighlight critical weaknesses in current LLM safety alignments and underscore\nthe urgent need for more sophisticated defence strategies.\n  Warning: this paper contains examples of unethical inquiries used solely for\nresearch purposes.",
      "tldr_zh": "本研究引入了一种新型越狱攻击Task-in-Prompt (TIP) attacks，针对大型语言模型(LLMs)通过在提示中嵌入序列到序列任务（如密码解码、谜语或代码执行）来间接生成被禁止的输入。作者开发了PHRYGE基准来系统评估这些攻击的有效性，并证明其成功绕过了包括GPT-4o和LLaMA 3.2在内的六种最先进模型的安全机制。结果显示了当前LLM安全对齐的重大弱点，并呼吁开发更先进的防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.18626v3",
      "published_date": "2025-01-27 12:48:47 UTC",
      "updated_date": "2025-02-04 17:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:51:43.884079"
    },
    {
      "arxiv_id": "2501.15998v1",
      "title": "Controllable Forgetting Mechanism for Few-Shot Class-Incremental Learning",
      "title_zh": "可控遗忘机制用于少样本类增量学习",
      "authors": [
        "Kirill Paramonov",
        "Mete Ozay",
        "Eunju Yang",
        "Jijoong Moon",
        "Umberto Michieli"
      ],
      "abstract": "Class-incremental learning in the context of limited personal labeled samples\n(few-shot) is critical for numerous real-world applications, such as smart home\ndevices. A key challenge in these scenarios is balancing the trade-off between\nadapting to new, personalized classes and maintaining the performance of the\nmodel on the original, base classes. Fine-tuning the model on novel classes\noften leads to the phenomenon of catastrophic forgetting, where the accuracy of\nbase classes declines unpredictably and significantly. In this paper, we\npropose a simple yet effective mechanism to address this challenge by\ncontrolling the trade-off between novel and base class accuracy. We\nspecifically target the ultra-low-shot scenario, where only a single example is\navailable per novel class. Our approach introduces a Novel Class Detection\n(NCD) rule, which adjusts the degree of forgetting a priori while\nsimultaneously enhancing performance on novel classes. We demonstrate the\nversatility of our solution by applying it to state-of-the-art Few-Shot\nClass-Incremental Learning (FSCIL) methods, showing consistent improvements\nacross different settings. To better quantify the trade-off between novel and\nbase class performance, we introduce new metrics: NCR@2FOR and NCR@5FOR. Our\napproach achieves up to a 30% improvement in novel class accuracy on the\nCIFAR100 dataset (1-shot, 1 novel class) while maintaining a controlled base\nclass forgetting rate of 2%.",
      "tldr_zh": "该论文针对少样本类增量学习（Few-Shot Class-Incremental Learning）中的灾难性遗忘问题，提出了一种可控遗忘机制，以平衡新类和基类性能的权衡。方法引入Novel Class Detection (NCD)规则，通过调整遗忘程度来提升新类准确率，同时应用于现有FSCIL方法，实现了在不同设置下的持续改进。论文还定义了新指标NCR@2FOR和NCR@5FOR来量化性能权衡，并在CIFAR100数据集的1-shot场景中，实现了新类准确率高达30%的提升，同时将基类遗忘率控制在2%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15998v1",
      "published_date": "2025-01-27 12:31:50 UTC",
      "updated_date": "2025-01-27 12:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:51:56.082834"
    },
    {
      "arxiv_id": "2502.00040v2",
      "title": "Multi-Objective Reinforcement Learning for Power Grid Topology Control",
      "title_zh": "多目标强化学习用于电力网格拓扑控制",
      "authors": [
        "Thomas Lautenbacher",
        "Ali Rajaei",
        "Davide Barbieri",
        "Jan Viebahn",
        "Jochen L. Cremer"
      ],
      "abstract": "Transmission grid congestion increases as the electrification of various\nsectors requires transmitting more power. Topology control, through substation\nreconfiguration, can reduce congestion but its potential remains\nunder-exploited in operations. A challenge is modeling the topology control\nproblem to align well with the objectives and constraints of operators.\nAddressing this challenge, this paper investigates the application of\nmulti-objective reinforcement learning (MORL) to integrate multiple conflicting\nobjectives for power grid topology control. We develop a MORL approach using\ndeep optimistic linear support (DOL) and multi-objective proximal policy\noptimization (MOPPO) to generate a set of Pareto-optimal policies that balance\nobjectives such as minimizing line loading, topological deviation, and\nswitching frequency. Initial case studies show that the MORL approach can\nprovide valuable insights into objective trade-offs and improve Pareto front\napproximation compared to a random search baseline. The generated\nmulti-objective RL policies are 30% more successful in preventing grid failure\nunder contingencies and 20% more effective when training budget is reduced -\ncompared to the common single objective RL policy.",
      "tldr_zh": "该研究探讨了多目标强化学习（MORL）在电力网格拓扑控制中的应用，以解决传输网拥堵问题，通过变电站重新配置减少负载。研究开发了基于 Deep Optimistic Linear Support (DOL) 和 Multi-Objective Proximal Policy Optimization (MOPPO) 的方法，生成 Pareto 最优策略来平衡最小化线路负载、拓扑偏差和切换频率等冲突目标。实验结果显示，与随机搜索基线相比，该 MORL 策略在防止电网故障时成功率提高 30%，并在训练预算减少时有效性提升 20%，优于传统单目标强化学习策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00040v2",
      "published_date": "2025-01-27 12:23:03 UTC",
      "updated_date": "2025-05-01 13:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:52:08.022948"
    },
    {
      "arxiv_id": "2501.15987v1",
      "title": "MultiPDENet: PDE-embedded Learning with Multi-time-stepping for Accelerated Flow Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Wang",
        "Yuan Mi",
        "Haoyun Wang",
        "Yi Zhang",
        "Ruizhi Chengze",
        "Hongsheng Liu",
        "Ji-Rong Wen",
        "Hao Sun"
      ],
      "abstract": "Solving partial differential equations (PDEs) by numerical methods meet\ncomputational cost challenge for getting the accurate solution since fine grids\nand small time steps are required. Machine learning can accelerate this\nprocess, but struggle with weak generalizability, interpretability, and data\ndependency, as well as suffer in long-term prediction. To this end, we propose\na PDE-embedded network with multiscale time stepping (MultiPDENet), which fuses\nthe scheme of numerical methods and machine learning, for accelerated\nsimulation of flows. In particular, we design a convolutional filter based on\nthe structure of finite difference stencils with a small number of parameters\nto optimize, which estimates the equivalent form of spatial derivative on a\ncoarse grid to minimize the equation's residual. A Physics Block with a\n4th-order Runge-Kutta integrator at the fine time scale is established that\nembeds the structure of PDEs to guide the prediction. To alleviate the curse of\ntemporal error accumulation in long-term prediction, we introduce a multiscale\ntime integration approach, where a neural network is used to correct the\nprediction error at a coarse time scale. Experiments across various PDE\nsystems, including the Navier-Stokes equations, demonstrate that MultiPDENet\ncan accurately predict long-term spatiotemporal dynamics, even given small and\nincomplete training data, e.g., spatiotemporally down-sampled datasets.\nMultiPDENet achieves the state-of-the-art performance compared with other\nneural baseline models, also with clear speedup compared to classical numerical\nmethods.",
      "tldr_zh": "本文提出 MultiPDENet，一种嵌入偏微分方程 (PDE) 的学习框架，结合多尺度时间步进技术，用于加速流体模拟。该框架设计基于有限差分模板的卷积滤波器和 Physics Block（包括 4 阶 Runge-Kutta 积分器），以在粗网格上最小化方程残差并嵌入 PDE 结构，同时通过多尺度时间积分修正长期预测中的误差积累。实验结果显示，MultiPDENet 在 Navier-Stokes equations 等各种 PDE 系统上，即使使用小而不完整的训练数据（如时空下采样数据集），也能实现准确的长期时空动态预测，并比其他神经基线模型和经典数值方法表现出色且计算速度更快。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15987v1",
      "published_date": "2025-01-27 12:15:51 UTC",
      "updated_date": "2025-01-27 12:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:52:22.076763"
    },
    {
      "arxiv_id": "2501.15972v1",
      "title": "Flexible Blood Glucose Control: Offline Reinforcement Learning from Human Feedback",
      "title_zh": "灵活的血糖控制：基于人类反馈的离线强化学习",
      "authors": [
        "Harry Emerson",
        "Sam Gordon James",
        "Matthew Guy",
        "Ryan McConville"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated success in automating insulin\ndosing in simulated type 1 diabetes (T1D) patients but is currently unable to\nincorporate patient expertise and preference. This work introduces PAINT\n(Preference Adaptation for INsulin control in T1D), an original RL framework\nfor learning flexible insulin dosing policies from patient records. PAINT\nemploys a sketch-based approach for reward learning, where past data is\nannotated with a continuous reward signal to reflect patient's desired\noutcomes. Labelled data trains a reward model, informing the actions of a novel\nsafety-constrained offline RL algorithm, designed to restrict actions to a safe\nstrategy and enable preference tuning via a sliding scale. In-silico evaluation\nshows PAINT achieves common glucose goals through simple labelling of desired\nstates, reducing glycaemic risk by 15% over a commercial benchmark. Action\nlabelling can also be used to incorporate patient expertise, demonstrating an\nability to pre-empt meals (+10% time-in-range post-meal) and address certain\ndevice errors (-1.6% variance post-error) with patient guidance. These results\nhold under realistic conditions, including limited samples, labelling errors,\nand intra-patient variability. This work illustrates PAINT's potential in\nreal-world T1D management and more broadly any tasks requiring rapid and\nprecise preference learning under safety constraints.",
      "tldr_zh": "该研究提出 PAINT 框架，利用离线 Reinforcement Learning (RL) 从人类反馈中学习灵活的胰岛素剂量策略，以解决传统 RL 在 1 型糖尿病 (T1D) 患者管理中无法整合患者偏好的问题。PAINT 通过基于草图的奖励学习方法，对患者记录数据标注连续奖励信号，训练奖励模型并结合安全约束的离线 RL 算法，确保策略安全且可调。实验结果显示，PAINT 在模拟环境中比商业基准减少 15% 的糖代谢风险，并能整合患者专业知识，如预判进餐（增加 10% 的进餐后时间-in-range）和处理设备错误（减少 1.6% 的变异），在现实条件下如有限样本和变异中保持鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.15972v1",
      "published_date": "2025-01-27 11:31:40 UTC",
      "updated_date": "2025-01-27 11:31:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:52:34.211357"
    },
    {
      "arxiv_id": "2501.15969v1",
      "title": "An Explainable Disease Surveillance System for Early Prediction of Multiple Chronic Diseases",
      "title_zh": "一种可解释的疾病监测系统，用于多种慢性病的早期预测",
      "authors": [
        "Shaheer Ahmad Khan",
        "Muhammad Usamah Shahid",
        "Ahmad Abdullah",
        "Ibrahim Hashmat",
        "Muddassar Farooq"
      ],
      "abstract": "This study addresses a critical gap in the healthcare system by developing a\nclinically meaningful, practical, and explainable disease surveillance system\nfor multiple chronic diseases, utilizing routine EHR data from multiple U.S.\npractices integrated with CureMD's EMR/EHR system. Unlike traditional\nsystems--using AI models that rely on features from patients' labs--our\napproach focuses on routinely available data, such as medical history, vitals,\ndiagnoses, and medications, to preemptively assess the risks of chronic\ndiseases in the next year. We trained three distinct models for each chronic\ndisease: prediction models that forecast the risk of a disease 3, 6, and 12\nmonths before a potential diagnosis. We developed Random Forest models, which\nwere internally validated using F1 scores and AUROC as performance metrics and\nfurther evaluated by a panel of expert physicians for clinical relevance based\non inferences grounded in medical knowledge. Additionally, we discuss our\nimplementation of integrating these models into a practical EMR system. Beyond\nusing Shapley attributes and surrogate models for explainability, we also\nintroduce a new rule-engineering framework to enhance the intrinsic\nexplainability of Random Forests.",
      "tldr_zh": "这篇论文开发了一个可解释的疾病监测系统，用于提前预测多种慢性疾病，基于日常 EHR 数据（如医疗历史、体征、诊断和药物），以弥补传统系统的局限。研究团队训练了 Random Forest 模型来预测患者在 3、6 和 12 个月内的疾病风险，并使用 F1 scores 和 AUROC 作为性能指标进行内部验证，同时由专家医师评估其临床相关性。论文还引入了新的 rule-engineering 框架，结合 Shapley attributes 和 surrogate models，提升了模型的内在解释性，并讨论了将其集成到 EMR 系统中的实际实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15969v1",
      "published_date": "2025-01-27 11:26:54 UTC",
      "updated_date": "2025-01-27 11:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:52:45.302144"
    },
    {
      "arxiv_id": "2501.15968v1",
      "title": "Multi-View Attention Syntactic Enhanced Graph Convolutional Network for Aspect-based Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Huang",
        "Hao Peng",
        "Shuo Sun",
        "Zhifeng Hao",
        "Hui Lin",
        "Shuhai Wang"
      ],
      "abstract": "Aspect-based Sentiment Analysis (ABSA) is the task aimed at predicting the\nsentiment polarity of aspect words within sentences. Recently, incorporating\ngraph neural networks (GNNs) to capture additional syntactic structure\ninformation in the dependency tree derived from syntactic dependency parsing\nhas been proven to be an effective paradigm for boosting ABSA. Despite GNNs\nenhancing model capability by fusing more types of information, most works only\nutilize a single topology view of the dependency tree or simply conflate\ndifferent perspectives of information without distinction, which limits the\nmodel performance. To address these challenges, in this paper, we propose a new\nmulti-view attention syntactic enhanced graph convolutional network (MASGCN)\nthat weighs different syntactic information of views using attention\nmechanisms. Specifically, we first construct distance mask matrices from the\ndependency tree to obtain multiple subgraph views for GNNs. To aggregate\nfeatures from different views, we propose a multi-view attention mechanism to\ncalculate the attention weights of views. Furthermore, to incorporate more\nsyntactic information, we fuse the dependency type information matrix into the\nadjacency matrices and present a structural entropy loss to learn the\ndependency type adjacency matrix. Comprehensive experiments on four benchmark\ndatasets demonstrate that our model outperforms state-of-the-art methods. The\ncodes and datasets are available at https://github.com/SELGroup/MASGCN.",
      "tldr_zh": "本研究针对Aspect-based Sentiment Analysis (ABSA)任务，提出了一种Multi-View Attention Syntactic Enhanced Graph Convolutional Network (MASGCN)模型，通过利用多视图子图和注意力机制来更好地捕获依赖树的句法结构信息，从而解决现有GNNs方法仅依赖单一拓扑视图或简单合并信息的局限性。具体而言，MASGCN从依赖树构建距离掩码矩阵生成多个子图视图，并采用多视图注意力机制聚合特征，同时融合依赖类型信息矩阵并引入结构熵损失来优化邻接矩阵。实验在四个基准数据集上表明，该模型优于最先进方法，代码和数据集已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is accepted by DASFAA 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15968v1",
      "published_date": "2025-01-27 11:26:13 UTC",
      "updated_date": "2025-01-27 11:26:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:52:56.775835"
    },
    {
      "arxiv_id": "2501.15963v1",
      "title": "Evaluating Data Influence in Meta Learning",
      "title_zh": "评估元学习中的数据影响",
      "authors": [
        "Chenyang Ren",
        "Huanyi Xie",
        "Shu Yang",
        "Meng Ding",
        "Lijie Hu",
        "Di Wang"
      ],
      "abstract": "As one of the most fundamental models, meta learning aims to effectively\naddress few-shot learning challenges. However, it still faces significant\nissues related to the training data, such as training inefficiencies due to\nnumerous low-contribution tasks in large datasets and substantial noise from\nincorrect labels. Thus, training data attribution methods are needed for meta\nlearning. However, the dual-layer structure of mata learning complicates the\nmodeling of training data contributions because of the interdependent influence\nbetween meta-parameters and task-specific parameters, making existing data\ninfluence evaluation tools inapplicable or inaccurate. To address these\nchallenges, based on the influence function, we propose a general data\nattribution evaluation framework for meta-learning within the bilevel\noptimization framework. Our approach introduces task influence functions\n(task-IF) and instance influence functions (instance-IF) to accurately assess\nthe impact of specific tasks and individual data points in closed forms. This\nframework comprehensively models data contributions across both the inner and\nouter training processes, capturing the direct effects of data points on\nmeta-parameters as well as their indirect influence through task-specific\nparameters. We also provide several strategies to enhance computational\nefficiency and scalability. Experimental results demonstrate the framework's\neffectiveness in training data evaluation via several downstream tasks.",
      "tldr_zh": "元学习（meta learning）在处理少样本学习时面临训练数据效率低下（如低贡献任务）和噪声（如错误标签）的问题，但其双层优化（bilevel optimization）结构使得现有数据影响评估工具难以适用。论文提出一个基于影响函数（influence function）的通用框架，引入任务影响函数（task-IF）和实例影响函数（instance-IF），以准确评估数据点对元参数的直接和间接影响。实验结果显示，该框架在训练数据评估中表现出色，能够提升下游任务的性能，并提供了优化计算效率的策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15963v1",
      "published_date": "2025-01-27 11:14:04 UTC",
      "updated_date": "2025-01-27 11:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:53:08.747365"
    },
    {
      "arxiv_id": "2501.15928v1",
      "title": "Generative AI for Lyapunov Optimization Theory in UAV-based Low-Altitude Economy Networking",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Liu",
        "Dusit Niyato",
        "Jiacheng Wang",
        "Geng Sun",
        "Lianfen Huang",
        "Zhibin Gao",
        "Xianbin Wang"
      ],
      "abstract": "Lyapunov optimization theory has recently emerged as a powerful mathematical\nframework for solving complex stochastic optimization problems by transforming\nlong-term objectives into a sequence of real-time short-term decisions while\nensuring system stability. This theory is particularly valuable in unmanned\naerial vehicle (UAV)-based low-altitude economy (LAE) networking scenarios,\nwhere it could effectively address inherent challenges of dynamic network\nconditions, multiple optimization objectives, and stability requirements.\nRecently, generative artificial intelligence (GenAI) has garnered significant\nattention for its unprecedented capability to generate diverse digital content.\nExtending beyond content generation, in this paper, we propose a framework\nintegrating generative diffusion models with reinforcement learning to address\nLyapunov optimization problems in UAV-based LAE networking. We begin by\nintroducing the fundamentals of Lyapunov optimization theory and analyzing the\nlimitations of both conventional methods and traditional AI-enabled approaches.\nWe then examine various GenAI models and comprehensively analyze their\npotential contributions to Lyapunov optimization. Subsequently, we develop a\nLyapunov-guided generative diffusion model-based reinforcement learning\nframework and validate its effectiveness through a UAV-based LAE networking\ncase study. Finally, we outline several directions for future research.",
      "tldr_zh": "该论文探讨了 Lyapunov optimization theory 在无人机 (UAV)-based low-altitude economy (LAE) networking 中的应用，该理论可将长期优化目标转化为实时决策，同时确保系统稳定性。作者提出一个创新框架，将 generative AI 中的生成式扩散模型与 reinforcement learning 整合，解决传统方法在动态网络条件下的局限性。实验通过 UAV-based LAE 网络案例验证了该框架的有效性，并分析了 generative AI 的潜在贡献和未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages, 5 figures, magazine paper",
      "pdf_url": "http://arxiv.org/pdf/2501.15928v1",
      "published_date": "2025-01-27 10:27:15 UTC",
      "updated_date": "2025-01-27 10:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:53:20.497171"
    },
    {
      "arxiv_id": "2501.15916v1",
      "title": "Online Housing Market",
      "title_zh": "翻译失败",
      "authors": [
        "Julien Lesca"
      ],
      "abstract": "This paper studies an online variant of the celebrated housing market\nproblem, where each agent has a single house and seeks to exchange it for\nanother based on her preferences. In this online setting, agents may arrive and\ndepart at any time, meaning that not all agents are present on the housing\nmarket simultaneously. I extend the well known serial dictatorship and Gale s\ntop trading cycle mechanisms to this online scenario, aiming to retain their\ndesirable properties such as Pareto efficiency, individual rationality, and\nstrategy proofness. These extensions also seek to prevent agents from\nstrategically delaying their arrival or advancing their departure. I\ndemonstrate that achieving all of these properties simultaneously is impossible\nin the online context, and I present several variants that achieve different\nsubsets of these properties.",
      "tldr_zh": "这篇论文研究了在线住房市场问题，即一个代理人各拥有一套房屋并根据偏好交换房屋的场景，但代理人可随时到达或离开，导致并非所有参与者同时在线。作者扩展了serial dictatorship和Gale's top trading cycle机制，以保留这些机制的理想属性，包括Pareto efficiency、individual rationality和strategy proofness，同时防止代理人战略性地延迟到达或提前离开。论文证明，在在线环境中不可能同时实现所有这些属性，并提出了几种变体，这些变体实现了这些属性的不同子集，从而为在线市场设计提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15916v1",
      "published_date": "2025-01-27 10:05:49 UTC",
      "updated_date": "2025-01-27 10:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:53:33.705179"
    },
    {
      "arxiv_id": "2501.15908v1",
      "title": "Evidential Physics-Informed Neural Networks",
      "title_zh": "证据性物理信息神经网络",
      "authors": [
        "Hai Siong Tan",
        "Kuancheng Wang",
        "Rafe McBeth"
      ],
      "abstract": "We present a novel class of Physics-Informed Neural Networks that is\nformulated based on the principles of Evidential Deep Learning, where the model\nincorporates uncertainty quantification by learning parameters of a\nhigher-order distribution. The dependent and trainable variables of the PDE\nresidual loss and data-fitting loss terms are recast as functions of the\nhyperparameters of an evidential prior distribution. Our model is equipped with\nan information-theoretic regularizer that contains the Kullback-Leibler\ndivergence between two inverse-gamma distributions characterizing predictive\nuncertainty. Relative to Bayesian-Physics-Informed-Neural-Networks, our\nframework appeared to exhibit higher sensitivity to data noise, preserve\nboundary conditions more faithfully and yield empirical coverage probabilities\ncloser to nominal ones. Toward examining its relevance for data mining in\nscientific discoveries, we demonstrate how to apply our model to inverse\nproblems involving 1D and 2D nonlinear differential equations.",
      "tldr_zh": "该研究提出了一种基于 Evidential Deep Learning 的新型 Physics-Informed Neural Networks (PINNs)，通过学习更高阶分布的参数来量化不确定性，并将 PDE 残差损失和数据拟合损失的变量重新表述为证据先验分布的超参数函数。模型引入了信息论正则化器，使用两个逆伽马分布之间的 Kullback-Leibler divergence 来表征预测不确定性。与 Bayesian-PINNs 相比，该框架对数据噪声更敏感、更忠实地保留边界条件，并产生更接近名义的经验覆盖概率。该方法被应用于逆问题，包括 1D 和 2D 非线性微分方程，用于科学发现的数据挖掘。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for International Conference on Scientific Computing and\n  Machine Learning (SCML) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15908v1",
      "published_date": "2025-01-27 10:01:10 UTC",
      "updated_date": "2025-01-27 10:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:53:45.320207"
    },
    {
      "arxiv_id": "2501.15890v3",
      "title": "Complexity in Complexity: Understanding Visual Complexity Through Structure, Color, and Surprise",
      "title_zh": "复杂性中的复杂性：通过结构、颜色和惊喜理解视觉复杂度",
      "authors": [
        "Karahan Sarıtaş",
        "Peter Dayan",
        "Tingke Shen",
        "Surabhi S Nath"
      ],
      "abstract": "Understanding how humans perceive visual complexity is a key area of study in\nvisual cognition. Previous approaches to modeling visual complexity assessments\nhave often resulted in intricate, difficult-to-interpret algorithms that employ\nnumerous features or sophisticated deep learning architectures. While these\ncomplex models achieve high performance on specific datasets, they often\nsacrifice interpretability, making it challenging to understand the factors\ndriving human perception of complexity. Recently (Shen, et al. 2024) proposed\nan interpretable segmentation-based model that accurately predicted complexity\nacross various datasets, supporting the idea that complexity can be explained\nsimply. In this work, we investigate the failure of their model to capture\nstructural, color and surprisal contributions to complexity. To this end, we\npropose Multi-Scale Sobel Gradient (MSG) which measures spatial intensity\nvariations, Multi-Scale Unique Color (MUC) which quantifies colorfulness across\nmultiple scales, and surprise scores generated using a Large Language Model. We\ntest our features on existing benchmarks and a novel dataset (Surprising Visual\nGenome) containing surprising images from Visual Genome. Our experiments\ndemonstrate that modeling complexity accurately is not as simple as previously\nthought, requiring additional perceptual and semantic factors to address\ndataset biases. Our model improves predictive performance while maintaining\ninterpretability, offering deeper insights into how visual complexity is\nperceived and assessed. Our code, analysis and data are available at\nhttps://github.com/Complexity-Project/Complexity-in-Complexity.",
      "tldr_zh": "本文研究了人类对视觉复杂性的感知，针对现有模型（如Shen et al. 2024提出的可解释分割模型）的不足，提出新特征：Multi-Scale Sobel Gradient (MSG) 用于测量多尺度空间强度变化、Multi-Scale Unique Color (MUC) 用于量化颜色丰富度，以及使用 Large Language Model 生成的 surprise scores。作者在现有基准和新型数据集 Surprising Visual Genome 上进行测试，结果表明，准确建模视觉复杂性需要整合额外的感知和语义因素，以克服数据集偏差。该方法提升了预测性能，同时保持模型的可解释性，提供更深入的洞察。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15890v3",
      "published_date": "2025-01-27 09:32:56 UTC",
      "updated_date": "2025-03-20 12:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:53:57.195833"
    },
    {
      "arxiv_id": "2501.15889v4",
      "title": "Adaptive Width Neural Networks",
      "title_zh": "自适应宽度神经网络",
      "authors": [
        "Federico Errica",
        "Henrik Christiansen",
        "Viktor Zaverkin",
        "Mathias Niepert",
        "Francesco Alesiani"
      ],
      "abstract": "For almost 70 years, researchers have mostly relied on hyper-parameter tuning\nto select the width of neural networks' layers. This paper challenges the\nstatus quo by introducing an easy-to-use technique to learn an unbounded width\nof a neural network's layer during training. The technique does not rely on\nalternate optimization nor hand-crafted gradient heuristics; rather, it jointly\noptimizes the width and the parameters of each layer via simple\nbackpropagation. We apply the technique to a broad range of data domains such\nas tables, images, text, sequences, and graphs, showing how the width adapts to\nthe task's difficulty. The method imposes a soft ordering of importance among\nneurons, by which it also is possible to truncate the trained network at\nvirtually zero cost, achieving a smooth trade-off between performance and\ncompute resources in a structured way. Alternatively, one can dynamically\ncompress the network with no performance degradation. In light of recent\nfoundation models trained on large datasets, believed to require billions of\nparameters and where hyper-parameter tuning is unfeasible due to humongous\ntraining costs, our approach stands as a viable alternative for width learning.",
      "tldr_zh": "该论文挑战了传统神经网络宽度依赖超参数调整的做法，提出了一种简单易用的技术，通过标准反向传播(backpropagation)来在训练过程中联合优化神经网络各层的无界宽度。该方法适用于表格、图像、文本、序列和图等多种数据域，能根据任务难度自动适应宽度，并在神经元中施加软重要性排序，从而实现几乎零成本的网络截断或动态压缩，以平衡性能和计算资源。实验结果表明，这种宽度学习(adaptive width)方法为大型基础模型提供了一个可行的替代方案，尤其在数据集庞大且超参数调整成本高昂的情况下。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15889v4",
      "published_date": "2025-01-27 09:25:56 UTC",
      "updated_date": "2025-05-21 14:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:54:08.310766"
    },
    {
      "arxiv_id": "2501.16404v1",
      "title": "DynaPrompt: Dynamic Test-Time Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Zehao Xiao",
        "Shilin Yan",
        "Jack Hong",
        "Jiayin Cai",
        "Xiaolong Jiang",
        "Yao Hu",
        "Jiayi Shen",
        "Qi Wang",
        "Cees G. M. Snoek"
      ],
      "abstract": "Test-time prompt tuning enhances zero-shot generalization of vision-language\nmodels but tends to ignore the relatedness among test samples during inference.\nOnline test-time prompt tuning provides a simple way to leverage the\ninformation in previous test samples, albeit with the risk of prompt collapse\ndue to error accumulation. To enhance test-time prompt tuning, we propose\nDynaPrompt, short for dynamic test-time prompt tuning, exploiting relevant data\ndistribution information while reducing error accumulation. Built on an online\nprompt buffer, DynaPrompt adaptively selects and optimizes the relevant prompts\nfor each test sample during tuning. Specifically, we introduce a dynamic prompt\nselection strategy based on two metrics: prediction entropy and probability\ndifference. For unseen test data information, we develop dynamic prompt\nappending, which allows the buffer to append new prompts and delete the\ninactive ones. By doing so, the prompts are optimized to exploit beneficial\ninformation on specific test data, while alleviating error accumulation.\nExperiments on fourteen datasets demonstrate the effectiveness of dynamic\ntest-time prompt tuning.",
      "tldr_zh": "这篇论文提出了 DynaPrompt，一种动态测试时提示调整方法，旨在提升视觉语言模型的零-shot 泛化性能，同时利用测试样本的相关性信息并减少错误积累。DynaPrompt 基于在线提示缓冲区，通过预测熵和概率差的动态提示选择策略来自适应优化每个测试样本的相关提示，并引入动态提示追加机制以添加新提示并删除不活跃的提示，从而缓解提示崩溃问题。在 14 个数据集上的实验证明了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16404v1",
      "published_date": "2025-01-27 09:10:06 UTC",
      "updated_date": "2025-01-27 09:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:54:20.500879"
    },
    {
      "arxiv_id": "2501.16403v1",
      "title": "Is Open Source the Future of AI? A Data-Driven Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Domen Vake",
        "Bogdan Šinik",
        "Jernej Vičič",
        "Aleksandar Tošić"
      ],
      "abstract": "Large Language Models (LLMs) have become central in academia and industry,\nraising concerns about privacy, transparency, and misuse. A key issue is the\ntrustworthiness of proprietary models, with open-sourcing often proposed as a\nsolution. However, open-sourcing presents challenges, including potential\nmisuse, financial disincentives, and intellectual property concerns.\nProprietary models, backed by private sector resources, are better positioned\nfor return on investment.\n  There are also other approaches that lie somewhere on the spectrum between\ncompletely open-source and proprietary. These can largely be categorised into\nopen-source usage limitations protected by licensing, partially open-source\n(open weights) models, hybrid approaches where obsolete model versions are\nopen-sourced, while competitive versions with market value remain proprietary.\n  Currently, discussions on where on the spectrum future models should fall on\nremains unbacked and mostly opinionated where industry leaders are weighing in\non the discussion. In this paper, we present a data-driven approach by\ncompiling data on open-source development of LLMs, and their contributions in\nterms of improvements, modifications, and methods. Our goal is to avoid\nsupporting either extreme but rather present data that will support future\ndiscussions both by industry experts as well as policy makers.\n  Our findings indicate that open-source contributions can enhance model\nperformance, with trends such as reduced model size and manageable accuracy\nloss. We also identify positive community engagement patterns and architectures\nthat benefit most from open contributions.",
      "tldr_zh": "这篇论文探讨了开源是否将成为AI的未来，采用数据驱动方法分析大型语言模型（LLMs）的开源发展及其挑战，包括隐私、透明度和潜在误用问题。作者编译了开源LLMs的改进、修改和方法数据，比较了完全开源、部分开源（如开放权重）和专有模型的中间方案，避免偏向极端。研究发现，开源贡献能提升模型性能、减少模型大小并保持可管理的准确性损失，同时促进积极的社区参与和某些架构的优化，为行业专家和政策制定者提供数据支持。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16403v1",
      "published_date": "2025-01-27 09:03:49 UTC",
      "updated_date": "2025-01-27 09:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:54:32.212037"
    },
    {
      "arxiv_id": "2501.15877v3",
      "title": "Boli: A dataset for understanding stuttering experience and analyzing stuttered speech",
      "title_zh": "翻译失败",
      "authors": [
        "Ashita Batra",
        "Mannas Narang",
        "Neeraj Kumar Sharma",
        "Pradip K Das"
      ],
      "abstract": "There is a growing need for diverse, high-quality stuttered speech data,\nparticularly in the context of Indian languages. This paper introduces Project\nBoli, a multi-lingual stuttered speech dataset designed to advance scientific\nunderstanding and technology development for individuals who stutter,\nparticularly in India. The dataset constitutes (a) anonymized metadata (gender,\nage, country, mother tongue) and responses to a questionnaire about how\nstuttering affects their daily lives, (b) captures both read speech (using the\nRainbow Passage) and spontaneous speech (through image description tasks) for\neach participant and (c) includes detailed annotations of five stutter types:\nblocks, prolongations, interjections, sound repetitions and word repetitions.\nWe present a comprehensive analysis of the dataset, including the data\ncollection procedure, experience summarization of people who stutter, severity\nassessment of stuttering events and technical validation of the collected data.\nThe dataset is released as an open access to further speech technology\ndevelopment.",
      "tldr_zh": "这篇论文介绍了 Boli 数据集，这是一个多语言口吃语音数据集，旨在填补印度语言中高质量多样化数据的空白，并提升对口吃者（特别是印度人群）的科学理解和技术发展。数据集包含匿名元数据（包括性别、年龄、国家和母语）、口吃影响日常生活的问卷回答，以及每位参与者的阅读语音（使用 Rainbow Passage）和自发语音（通过图像描述任务），并对五种口吃类型（blocks, prolongations, interjections, sound repetitions 和 word repetitions）进行了详细注释。论文还呈现了数据集的全面分析，包括数据收集过程、口吃者经验总结、口吃事件严重程度评估和技术验证，并以开源方式发布，以推进语音技术创新。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15877v3",
      "published_date": "2025-01-27 09:03:28 UTC",
      "updated_date": "2025-05-01 09:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:54:45.002548"
    },
    {
      "arxiv_id": "2501.15876v1",
      "title": "Optimizing Sentence Embedding with Pseudo-Labeling and Model Ensembles: A Hierarchical Framework for Enhanced NLP Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Liu",
        "Qi Zhang",
        "Lifu Gao"
      ],
      "abstract": "Sentence embedding tasks are important in natural language processing (NLP),\nbut improving their performance while keeping them reliable is still hard. This\npaper presents a framework that combines pseudo-label generation and model\nensemble techniques to improve sentence embeddings. We use external data from\nSimpleWiki, Wikipedia, and BookCorpus to make sure the training data is\nconsistent. The framework includes a hierarchical model with an encoding layer,\nrefinement layer, and ensemble prediction layer, using ALBERT-xxlarge,\nRoBERTa-large, and DeBERTa-large models. Cross-attention layers combine\nexternal context, and data augmentation techniques like synonym replacement and\nback-translation increase data variety. Experimental results show large\nimprovements in accuracy and F1-score compared to basic models, and studies\nconfirm that cross-attention and data augmentation make a difference. This work\npresents an effective way to improve sentence embedding tasks and lays the\ngroundwork for future NLP research.",
      "tldr_zh": "这篇论文提出了一种分层框架，通过伪标签生成(pseudo-labeling)和模型集成(model ensembles)来优化句子嵌入(sentence embedding)，旨在提升自然语言处理(NLP)任务的性能。该框架包括编码层(encoding layer)、精炼层(refinement layer)和集成预测层(ensemble prediction layer)，并利用 ALBERT-xxlarge、RoBERTa-large 和 DeBERTa-large 模型，结合外部数据源如 SimpleWiki、Wikipedia 和 BookCorpus，以及交叉注意力层(cross-attention layers)和数据增强技术如同义词替换(synonym replacement)和回译(back-translation)。实验结果显示，与基本模型相比，准确率和 F1-score 显著提高，验证了这些技术的有效性，并为未来 NLP 研究奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15876v1",
      "published_date": "2025-01-27 09:02:42 UTC",
      "updated_date": "2025-01-27 09:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:54:57.394923"
    },
    {
      "arxiv_id": "2501.15870v1",
      "title": "D-PLS: Decoupled Semantic Segmentation for 4D-Panoptic-LiDAR-Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Maik Steinhauser",
        "Laurenz Reichardt",
        "Nikolas Ebert",
        "Oliver Wasenmüller"
      ],
      "abstract": "This paper introduces a novel approach to 4D Panoptic LiDAR Segmentation that\ndecouples semantic and instance segmentation, leveraging single-scan semantic\npredictions as prior information for instance segmentation. Our method D-PLS\nfirst performs single-scan semantic segmentation and aggregates the results\nover time, using them to guide instance segmentation. The modular design of\nD-PLS allows for seamless integration on top of any semantic segmentation\narchitecture, without requiring architectural changes or retraining. We\nevaluate our approach on the SemanticKITTI dataset, where it demonstrates\nsignificant improvements over the baseline in both classification and\nassociation tasks, as measured by the LiDAR Segmentation and Tracking Quality\n(LSTQ) metric. Furthermore, we show that our decoupled architecture not only\nenhances instance prediction but also surpasses the baseline due to\nadvancements in single-scan semantic segmentation.",
      "tldr_zh": "本研究提出D-PLS，一种用于4D Panoptic LiDAR Segmentation的解耦语义分割方法，通过利用单次扫描的语义预测作为实例分割的先验信息来提升整体性能。D-PLS首先进行单次扫描语义分割并聚合时间序列结果，以指导实例分割，其模块化设计允许无缝集成到任何语义分割架构中，而无需架构修改或重新训练。在SemanticKITTI数据集上的评估显示，D-PLS在分类和关联任务上显著超越基线模型，根据LiDAR Segmentation and Tracking Quality (LSTQ)指标取得了可观的改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15870v1",
      "published_date": "2025-01-27 08:46:22 UTC",
      "updated_date": "2025-01-27 08:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:55:08.208793"
    },
    {
      "arxiv_id": "2501.15865v2",
      "title": "Transfer of Knowledge through Reverse Annealing: A Preliminary Analysis of the Benefits and What to Share",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Esther Villar-Rodriguez"
      ],
      "abstract": "Being immersed in the NISQ-era, current quantum annealers present limitations\nfor solving optimization problems efficiently. To mitigate these limitations,\nD-Wave Systems developed a mechanism called Reverse Annealing, a specific type\nof quantum annealing designed to perform local refinement of good states found\nelsewhere. Despite the research activity around Reverse Annealing, none has\ntheorized about the possible benefits related to the transfer of knowledge\nunder this paradigm. This work moves in that direction and is driven by\nexperimentation focused on answering two key research questions: i) is reverse\nannealing a paradigm that can benefit from knowledge transfer between similar\nproblems? and ii) can we infer the characteristics that an input solution\nshould meet to help increase the probability of success? To properly guide the\ntests in this paper, the well-known Knapsack Problem has been chosen for\nbenchmarking purposes, using a total of 34 instances composed of 14 and 16\nitems.",
      "tldr_zh": "在 NISQ 时代，量子退火器在解决优化问题时面临效率限制，本文通过初步分析探讨了 Reverse Annealing 作为局部优化机制在知识转移方面的潜在益处。研究针对两个关键问题进行实验：i) Reverse Annealing 是否能从类似问题之间受益于知识转移，以及 ii) 输入解决方案应具备哪些特性以提高成功概率。作者使用 Knapsack Problem 作为基准，测试了共 34 个实例（包括 14 和 16 项），为未来量子计算应用提供了初步洞见。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "quant-ph",
      "comment": "13 pages, 2 figures and 2 tables. Paper submitted to Frontiers in\n  Physics journal",
      "pdf_url": "http://arxiv.org/pdf/2501.15865v2",
      "published_date": "2025-01-27 08:42:40 UTC",
      "updated_date": "2025-04-11 10:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:55:20.287072"
    },
    {
      "arxiv_id": "2501.15857v5",
      "title": "Are Transformers Able to Reason by Connecting Separated Knowledge in Training Data?",
      "title_zh": "Transformers 是否能够通过连接训练数据中的分离知识来进行推理？",
      "authors": [
        "Yutong Yin",
        "Zhaoran Wang"
      ],
      "abstract": "Humans exhibit remarkable compositional reasoning by integrating knowledge\nfrom various sources. For example, if someone learns ( B = f(A) ) from one\nsource and ( C = g(B) ) from another, they can deduce ( C=g(B)=g(f(A)) ) even\nwithout encountering ( ABC ) together, showcasing the generalization ability of\nhuman intelligence. In this paper, we introduce a synthetic learning task,\n\"FTCT\" (Fragmented at Training, Chained at Testing), to validate the potential\nof Transformers in replicating this skill and interpret its inner mechanism. In\nthe training phase, data consist of separated knowledge fragments from an\noverall causal graph. During testing, Transformers must infer complete causal\ngraph traces by integrating these fragments. Our findings demonstrate that\nfew-shot Chain-of-Thought prompting enables Transformers to perform\ncompositional reasoning on FTCT by revealing correct combinations of fragments,\neven if such combinations were absent in the training data. Furthermore, the\nemergence of compositional reasoning ability is strongly correlated with the\nmodel complexity and training-testing data similarity. We propose, both\ntheoretically and empirically, that Transformers learn an underlying\ngeneralizable program from training, enabling effective compositional reasoning\nduring testing.",
      "tldr_zh": "本论文探讨了Transformers模型是否能像人类一样，通过整合训练数据中的分离知识进行组合推理（compositional reasoning）。作者引入了一个合成任务“FTCT”（Fragmented at Training, Chained at Testing），其中训练数据由整体因果图的分离片段组成，而测试阶段要求模型推导出完整的因果图痕迹。实验结果显示，采用少样本Chain-of-Thought提示后，Transformers能够识别并组合未见过的知识片段进行推理，这种能力与模型复杂度及训练-测试数据相似度密切相关。论文理论和实证证明，Transformers从训练数据中学习到一个可泛化的程序，从而支持有效的组合推理。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15857v5",
      "published_date": "2025-01-27 08:34:38 UTC",
      "updated_date": "2025-05-13 00:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:55:32.489831"
    },
    {
      "arxiv_id": "2501.15842v1",
      "title": "Beyond In-Distribution Performance: A Cross-Dataset Study of Trajectory Prediction Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Yao",
        "Daniel Goehring",
        "Joerg Reichardt"
      ],
      "abstract": "We study the Out-of-Distribution (OoD) generalization ability of three SotA\ntrajectory prediction models with comparable In-Distribution (ID) performance\nbut different model designs. We investigate the influence of inductive bias,\nsize of training data and data augmentation strategy by training the models on\nArgoverse 2 (A2) and testing on Waymo Open Motion (WO) and vice versa. We find\nthat the smallest model with highest inductive bias exhibits the best OoD\ngeneralization across different augmentation strategies when trained on the\nsmaller A2 dataset and tested on the large WO dataset. In the converse setting,\ntraining all models on the larger WO dataset and testing on the smaller A2\ndataset, we find that all models generalize poorly, even though the model with\nthe highest inductive bias still exhibits the best generalization ability. We\ndiscuss possible reasons for this surprising finding and draw conclusions about\nthe design and test of trajectory prediction models and benchmarks.",
      "tldr_zh": "本文研究了轨迹预测模型的 Out-of-Distribution (OoD) 泛化能力，通过比较三个状态-of-the-art (SotA) 模型在 In-Distribution (ID) 性能相当但设计不同的情况下。实验在 Argoverse 2 (A2) 和 Waymo Open Motion (WO) 数据集间交叉训练和测试，考察了 inductive bias、训练数据大小以及数据增强策略的影响。结果发现，当在较小 A2 数据集上训练并在较大 WO 数据集上测试时，具有最高 inductive bias 的最小模型表现出最佳 OoD 泛化；但在相反设置下，所有模型均泛化较差。作者讨论了这一现象的原因，并为轨迹预测模型的设计和基准测试提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2407.13431",
      "pdf_url": "http://arxiv.org/pdf/2501.15842v1",
      "published_date": "2025-01-27 08:08:17 UTC",
      "updated_date": "2025-01-27 08:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:55:45.805989"
    },
    {
      "arxiv_id": "2501.15838v1",
      "title": "CrySPAI: A new Crystal Structure Prediction Software Based on Artificial Intelligence",
      "title_zh": "CrySPAI：一种基于人工智能的晶体结构预测新软件",
      "authors": [
        "Zongguo Wang",
        "Ziyi Chen",
        "Yang Yuan",
        "Yangang Wang"
      ],
      "abstract": "Crystal structure predictions based on the combination of first-principles\ncalculations and machine learning have achieved significant success in\nmaterials science. However, most of these approaches are limited to predicting\nspecific systems, which hinders their application to unknown or unexplored\ndomains. In this paper, we present CrySPAI, a crystal structure prediction\npackage developed using artificial intelligence (AI) to predict energetically\nstable crystal structures of inorganic materials given their chemical\ncompositions. The software consists of three key modules, an evolutionary\noptimization algorithm (EOA) that searches for all possible crystal structure\nconfigurations, density functional theory (DFT) that provides the accurate\nenergy values for these structures, and a deep neural network (DNN) that learns\nthe relationship between crystal structures and their corresponding energies.\nTo optimize the process across these modules, a distributed framework is\nimplemented to parallelize tasks, and an automated workflow has been integrated\ninto CrySPAI for seamless execution. This paper reports the development and\nimplementation of AI AI-based CrySPAI Crystal Prediction Software tool and its\nunique features.",
      "tldr_zh": "该论文介绍了 CrySPAI，一款基于人工智能的晶体结构预测软件，旨在预测无机材料给定化学成分的能量稳定结构，解决了现有方法仅限于特定系统的局限性。软件由三个关键模块组成：进化优化算法 (EOA) 用于搜索所有可能晶体结构配置、密度泛函理论 (DFT) 提供精确能量值，以及深度神经网络 (DNN) 学习晶体结构与能量之间的关系。CrySPAI 还集成了分布式框架和自动化工作流来优化模块间的任务并行和执行流程，提升了预测效率和适用性。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15838v1",
      "published_date": "2025-01-27 07:53:06 UTC",
      "updated_date": "2025-01-27 07:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:55:56.399813"
    },
    {
      "arxiv_id": "2501.15836v2",
      "title": "Intelligent Code Embedding Framework for High-Precision Ransomware Detection via Multimodal Execution Path Analysis",
      "title_zh": "智能代码",
      "authors": [
        "Levi Gareth",
        "Maximilian Fairbrother",
        "Peregrine Blackwood",
        "Lucasta Underhill",
        "Benedict Ruthermore"
      ],
      "abstract": "Modern threat landscapes continue to evolve with increasing sophistication,\nchallenging traditional detection methodologies and necessitating innovative\nsolutions capable of addressing complex adversarial tactics. A novel framework\nwas developed to identify ransomware activity through multimodal execution path\nanalysis, integrating high-dimensional embeddings and dynamic heuristic\nderivation mechanisms to capture behavioral patterns across diverse attack\nvariants. The approach demonstrated high adaptability, effectively mitigating\nobfuscation strategies and polymorphic characteristics often employed by\nransomware families to evade detection. Comprehensive experimental evaluations\nrevealed significant advancements in precision, recall, and accuracy metrics\ncompared to baseline techniques, particularly under conditions of variable\nencryption speeds and obfuscated execution flows. The framework achieved\nscalable and computationally efficient performance, ensuring robust\napplicability across a range of system configurations, from\nresource-constrained environments to high-performance infrastructures. Notable\nfindings included reduced false positive rates and enhanced detection latency,\neven for ransomware families employing sophisticated encryption mechanisms. The\nmodular design allowed seamless integration of additional modalities, enabling\nextensibility and future-proofing against emerging threat vectors. Quantitative\nanalyses further highlighted the system's energy efficiency, emphasizing its\npracticality for deployment in environments with stringent operational\nconstraints. The results underline the importance of integrating advanced\ncomputational techniques and dynamic adaptability to safeguard digital\necosystems from increasingly complex threats.",
      "tldr_zh": "该论文提出了一种智能代码嵌入框架，通过多模态执行路径分析(Multimodal Execution Path Analysis)实现高精度勒索软件(ransomware)检测，该框架整合高维嵌入和高动态启发式机制，以捕捉不同攻击变体的行为模式并应对混淆和多态策略。实验评估显示，该框架在精确率、召回率和准确率上比基线技术显著提升，尤其在可变加密速度和混淆执行流条件下，同时降低了假阳性率并改善了检测延迟。框架设计具有可扩展性和计算效率，适用于从资源受限到高性能的各种系统配置，并强调了其能源效率和对新兴威胁的适应性。关键发现突出了整合高级计算技术和动态适应性在保护数字生态系统中的重要作用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
      "pdf_url": "http://arxiv.org/pdf/2501.15836v2",
      "published_date": "2025-01-27 07:51:51 UTC",
      "updated_date": "2025-03-26 15:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:56:09.799767"
    },
    {
      "arxiv_id": "2501.15830v5",
      "title": "SpatialVLA: Exploring Spatial Representations for Visual-Language-Action Model",
      "title_zh": "翻译失败",
      "authors": [
        "Delin Qu",
        "Haoming Song",
        "Qizhi Chen",
        "Yuanqi Yao",
        "Xinyi Ye",
        "Yan Ding",
        "Zhigang Wang",
        "JiaYuan Gu",
        "Bin Zhao",
        "Dong Wang",
        "Xuelong Li"
      ],
      "abstract": "In this paper, we claim that spatial understanding is the keypoint in robot\nmanipulation, and propose SpatialVLA to explore effective spatial\nrepresentations for the robot foundation model. Specifically, we introduce\nEgo3D Position Encoding to inject 3D information into the input observations of\nthe visual-language-action model, and propose Adaptive Action Grids to\nrepresent spatial robot movement actions with adaptive discretized action\ngrids, facilitating learning generalizable and transferrable spatial action\nknowledge for cross-robot control. SpatialVLA is first pre-trained on top of a\nvision-language model with 1.1 Million real-world robot episodes, to learn a\ngeneralist manipulation policy across multiple robot environments and tasks.\nAfter pre-training, SpatialVLA is directly applied to perform numerous tasks in\na zero-shot manner. The superior results in both simulation and real-world\nrobots demonstrate its advantage of inferring complex robot motion trajectories\nand its strong in-domain multi-task generalization ability. We further show the\nproposed Adaptive Action Grids offer a new and effective way to fine-tune the\npre-trained SpatialVLA model for new simulation and real-world setups, where\nthe pre-learned action grids are re-discretized to capture robot-specific\nspatial action movements of new setups. The superior results from extensive\nevaluations demonstrate the exceptional in-distribution generalization and\nout-of-distribution adaptation capability, highlighting the crucial benefit of\nthe proposed spatial-aware representations for generalist robot policy\nlearning. All the details and codes will be open-sourced.",
      "tldr_zh": "本文强调空间理解是机器人操作的关键，并提出SpatialVLA框架，用于探索有效的空间表示。具体地，SpatialVLA引入Ego3D Position Encoding将3D信息注入视觉-语言-动作模型的输入观察，并采用Adaptive Action Grids来表示自适应离散动作，促进可泛化和可转移的空间动作知识学习。框架在110万真实机器人场景上预训练后，可零样本方式执行多种任务，并在模拟和真实环境中表现出色，展示了强大的内域多任务泛化及外域适应能力。最终实验结果证明了这些空间感知表示在通用机器人策略学习中的关键优势，相关代码将开源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15830v5",
      "published_date": "2025-01-27 07:34:33 UTC",
      "updated_date": "2025-05-19 02:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:56:23.731936"
    },
    {
      "arxiv_id": "2501.15820v1",
      "title": "FuzzyLight: A Robust Two-Stage Fuzzy Approach for Traffic Signal Control Works in Real Cities",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyuan Li",
        "Jiahao Wang",
        "Bo Du",
        "Jun Shen",
        "Qiang Wu"
      ],
      "abstract": "Effective traffic signal control (TSC) is crucial in mitigating urban\ncongestion and reducing emissions. Recently, reinforcement learning (RL) has\nbeen the research trend for TSC. However, existing RL algorithms face several\nreal-world challenges that hinder their practical deployment in TSC: (1) Sensor\naccuracy deteriorates with increased sensor detection range, and data\ntransmission is prone to noise, potentially resulting in unsafe TSC decisions.\n(2) During the training of online RL, interactions with the environment could\nbe unstable, potentially leading to inappropriate traffic signal phase (TSP)\nselection and traffic congestion. (3) Most current TSC algorithms focus only on\nTSP decisions, overlooking the critical aspect of phase duration, affecting\nsafety and efficiency. To overcome these challenges, we propose a robust\ntwo-stage fuzzy approach called FuzzyLight, which integrates compressed sensing\nand RL for TSC deployment. FuzzyLight offers several key contributions: (1) It\nemploys fuzzy logic and compressed sensing to address sensor noise and enhances\nthe efficiency of TSP decisions. (2) It maintains stable performance during\ntraining and combines fuzzy logic with RL to generate precise phases. (3) It\nworks in real cities across 22 intersections and demonstrates superior\nperformance in both real-world and simulated environments. Experimental results\nindicate that FuzzyLight enhances traffic efficiency by 48% compared to\nexpert-designed timings in the real world. Furthermore, it achieves\nstate-of-the-art (SOTA) performance in simulated environments using six\nreal-world datasets with transmission noise. The code and deployment video are\navailable at the URL1",
      "tldr_zh": "这篇论文提出FuzzyLight，一种鲁棒的两阶段模糊方法，用于交通信号控制(TSC)，以解决传感器噪声、RL训练不稳定性和相位持续时间优化等实际挑战。FuzzyLight整合fuzzy logic、compressed sensing和RL，增强TSP决策效率，并在训练过程中保持稳定性能。实验结果显示，该方法在真实城市22个路口部署时，比专家设计的定时方案提高交通效率48%，并在模拟环境中使用六个真实数据集达到SOTA性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15820v1",
      "published_date": "2025-01-27 06:55:47 UTC",
      "updated_date": "2025-01-27 06:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:56:32.870070"
    },
    {
      "arxiv_id": "2501.15817v1",
      "title": "Long-Term Interest Clock: Fine-Grained Time Perception in Streaming Recommendation System",
      "title_zh": "长期兴趣时钟：流式推荐系统中的细粒度时间感知",
      "authors": [
        "Yongchun Zhu",
        "Guanyu Jiang",
        "Jingwu Chen",
        "Feng Zhang",
        "Xiao Yang",
        "Zuotao Liu"
      ],
      "abstract": "User interests manifest a dynamic pattern within the course of a day, e.g., a\nuser usually favors soft music at 8 a.m. but may turn to ambient music at 10\np.m. To model dynamic interests in a day, hour embedding is widely used in\ntraditional daily-trained industrial recommendation systems. However, its\ndiscreteness can cause periodical online patterns and instability in recent\nstreaming recommendation systems. Recently, Interest Clock has achieved\nremarkable performance in streaming recommendation systems. Nevertheless, it\nmodels users' dynamic interests in a coarse-grained manner, merely encoding\nusers' discrete interests of 24 hours from short-term behaviors. In this paper,\nwe propose a fine-grained method for perceiving time information for streaming\nrecommendation systems, named Long-term Interest Clock (LIC). The key idea of\nLIC is adaptively calculating current user interests by taking into\nconsideration the relevance of long-term behaviors around current time (e.g., 8\na.m.) given a candidate item. LIC consists of two modules: (1) Clock-GSU\nretrieves a sub-sequence by searching through long-term behaviors, using query\ninformation from a candidate item and current time, (2) Clock-ESU employs a\ntime-gap-aware attention mechanism to aggregate sub-sequence with the candidate\nitem. With Clock-GSU and Clock-ESU, LIC is capable of capturing users' dynamic\nfine-grained interests from long-term behaviors. We conduct online A/B tests,\nobtaining +0.122% improvements on user active days. Besides, the extended\noffline experiments show improvements as well. Long-term Interest Clock has\nbeen integrated into Douyin Music App's recommendation system.",
      "tldr_zh": "本文提出 Long-term Interest Clock (LIC)，一种细粒度时间感知方法，用于流式推荐系统，以解决传统小时嵌入的周期性和不稳定性问题。LIC 通过两个模块实现：Clock-GSU 使用候选物品和当前时间查询信息从长期行为中检索子序列，Clock-ESU 则采用时间间隙感知注意力机制聚合这些子序列与候选物品，从而捕捉用户细粒度动态兴趣。实验结果显示，在线 A/B 测试中用户活跃天数提升 0.122%，离线实验也取得改善，并已整合到 Douyin Music App 的推荐系统中。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15817v1",
      "published_date": "2025-01-27 06:52:50 UTC",
      "updated_date": "2025-01-27 06:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:56:44.624526"
    },
    {
      "arxiv_id": "2501.15816v1",
      "title": "AdaF^2M^2: Comprehensive Learning and Responsive Leveraging Features in Recommendation System",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchun Zhu",
        "Jingwu Chen",
        "Ling Chen",
        "Yitan Li",
        "Feng Zhang",
        "Xiao Yang",
        "Zuotao Liu"
      ],
      "abstract": "Feature modeling, which involves feature representation learning and\nleveraging, plays an essential role in industrial recommendation systems.\nHowever, the data distribution in real-world applications usually follows a\nhighly skewed long-tail pattern due to the popularity bias, which easily leads\nto over-reliance on ID-based features, such as user/item IDs and ID sequences\nof interactions. Such over-reliance makes it hard for models to learn features\ncomprehensively, especially for those non-ID meta features, e.g., user/item\ncharacteristics. Further, it limits the feature leveraging ability in models,\ngetting less generalized and more susceptible to data noise. Previous studies\non feature modeling focus on feature extraction and interaction, hardly\nnoticing the problems brought about by the long-tail data distribution. To\nachieve better feature representation learning and leveraging on real-world\ndata, we propose a model-agnostic framework AdaF^2M^2, short for Adaptive\nFeature Modeling with Feature Mask. The feature-mask mechanism helps\ncomprehensive feature learning via multi-forward training with augmented\nsamples, while the adapter applies adaptive weights on features responsive to\ndifferent user/item states. By arming base models with AdaF^2M^2, we conduct\nonline A/B tests on multiple recommendation scenarios, obtaining +1.37% and\n+1.89% cumulative improvements on user active days and app duration\nrespectively. Besides, the extended offline experiments on different models\nshow improvements as well. AdaF$^2$M$^2$ has been widely deployed on both\nretrieval and ranking tasks in multiple applications of Douyin Group,\nindicating its superior effectiveness and universality.",
      "tldr_zh": "该研究针对推荐系统中长尾数据分布导致的过度依赖 ID 特征（如用户/物品 ID）问题，提出模型无关框架 AdaF^2M^2，以实现更全面的特征表示学习和响应性特征利用。框架的核心机制包括 feature-mask，通过多前向训练和增强样本提升非-ID 元特征（如用户/物品特性）的学习能力，以及 adapter 机制为不同用户/物品状态应用自适应权重，从而提高模型的泛化性和鲁棒性。在线 A/B 测试在多个推荐场景中取得了用户活跃天数+1.37%和应用使用时长+1.89%的提升，且离线实验在不同模型上也显示了显著改进；AdaF^2M^2 已广泛部署在 Douyin 集团的检索和排名任务中，证明其有效性和通用性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by DASFAA2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15816v1",
      "published_date": "2025-01-27 06:49:27 UTC",
      "updated_date": "2025-01-27 06:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:56:57.930396"
    },
    {
      "arxiv_id": "2502.07794v1",
      "title": "Regulatory Science Innovation for Generative AI and Large Language Models in Health and Medicine: A Global Call for Action",
      "title_zh": "翻译失败",
      "authors": [
        "Jasmine Chiat Ling Ong",
        "Yilin Ning",
        "Mingxuan Liu",
        "Yian Ma",
        "Zhao Liang",
        "Kuldev Singh",
        "Robert T Chang",
        "Silke Vogel",
        "John CW Lim",
        "Iris Siu Kwan Tan",
        "Oscar Freyer",
        "Stephen Gilbert",
        "Danielle S Bitterman",
        "Xiaoxuan Liu",
        "Alastair K Denniston",
        "Nan Liu"
      ],
      "abstract": "The integration of generative AI (GenAI) and large language models (LLMs) in\nhealthcare presents both unprecedented opportunities and challenges,\nnecessitating innovative regulatory approaches. GenAI and LLMs offer broad\napplications, from automating clinical workflows to personalizing diagnostics.\nHowever, the non-deterministic outputs, broad functionalities and complex\nintegration of GenAI and LLMs challenge existing medical device regulatory\nframeworks, including the total product life cycle (TPLC) approach. Here we\ndiscuss the constraints of the TPLC approach to GenAI and LLM-based medical\ndevice regulation, and advocate for global collaboration in regulatory science\nresearch. This serves as the foundation for developing innovative approaches\nincluding adaptive policies and regulatory sandboxes, to test and refine\ngovernance in real-world settings. International harmonization, as seen with\nthe International Medical Device Regulators Forum, is essential to manage\nimplications of LLM on global health, including risks of widening health\ninequities driven by inherent model biases. By engaging multidisciplinary\nexpertise, prioritizing iterative, data-driven approaches, and focusing on the\nneeds of diverse populations, global regulatory science research enables the\nresponsible and equitable advancement of LLM innovations in healthcare.",
      "tldr_zh": "这篇论文讨论了 generative AI (GenAI) 和 large language models (LLMs) 在医疗领域的应用机会与挑战，这些技术可用于自动化临床工作流程和个性化诊断，但其非确定性输出和复杂整合挑战了现有的 total product life cycle (TPLC) 监管框架。论文指出了 TPLC 方法的局限性，并呼吁全球合作开展监管科学研究，包括采用 adaptive policies 和 regulatory sandboxes 等创新策略。最终，它强调通过国际协调（如 International Medical Device Regulators Forum）、多学科协作和数据驱动方法，确保 LLM 在医疗中的负责任发展，并减少模型偏差导致的健康不平等风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07794v1",
      "published_date": "2025-01-27 06:21:13 UTC",
      "updated_date": "2025-01-27 06:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:57:09.032795"
    },
    {
      "arxiv_id": "2501.15802v1",
      "title": "Adaptive AI-based Decentralized Resource Management in the Cloud-Edge Continuum",
      "title_zh": "自适应 AI 驱动的去中心化资源管理于云边连续体",
      "authors": [
        "Lanpei Li",
        "Jack Bell",
        "Massimo Coppola",
        "Vincenzo Lomonaco"
      ],
      "abstract": "The increasing complexity of application requirements and the dynamic nature\nof the Cloud-Edge Continuum present significant challenges for efficient\nresource management. These challenges stem from the ever-changing\ninfrastructure, which is characterized by additions, removals, and\nreconfigurations of nodes and links, as well as the variability of application\nworkloads. Traditional centralized approaches struggle to adapt to these\nchanges due to their static nature, while decentralized solutions face\nchallenges such as limited global visibility and coordination overhead. This\npaper proposes a hybrid decentralized framework for dynamic application\nplacement and resource management. The framework utilizes Graph Neural Networks\n(GNNs) to embed resource and application states, enabling comprehensive\nrepresentation and efficient decision-making. It employs a collaborative\nmulti-agent reinforcement learning (MARL) approach, where local agents optimize\nresource management in their neighborhoods and a global orchestrator ensures\nsystem-wide coordination. By combining decentralized application placement with\ncentralized oversight, our framework addresses the scalability, adaptability,\nand accuracy challenges inherent in the Cloud-Edge Continuum. This work\ncontributes to the development of decentralized application placement\nstrategies, the integration of GNN embeddings, and collaborative MARL systems,\nproviding a foundation for efficient, adaptive and scalable resource\nmanagement.",
      "tldr_zh": "这篇论文针对云边连续体(Cloud-Edge Continuum)的动态资源管理挑战，提出了一种混合去中心化框架，以应对基础设施变化和应用工作负载变异性。框架利用 Graph Neural Networks (GNNs) 嵌入资源和应用状态，实现高效决策，并采用协作多代理强化学习 (MARL)，其中本地代理优化局部资源管理，而全局协调器确保系统级协调。该方法提升了可伸缩性、适应性和准确性，为去中心化应用放置策略、GNN 嵌入和 MARL 系统的整合提供了重要基础。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15802v1",
      "published_date": "2025-01-27 06:07:09 UTC",
      "updated_date": "2025-01-27 06:07:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:57:20.963906"
    },
    {
      "arxiv_id": "2501.18624v2",
      "title": "Membership Inference Attacks Against Vision-Language Models",
      "title_zh": "针对视觉语言模型的成员推断攻击",
      "authors": [
        "Yuke Hu",
        "Zheng Li",
        "Zhihao Liu",
        "Yang Zhang",
        "Zhan Qin",
        "Kui Ren",
        "Chun Chen"
      ],
      "abstract": "Vision-Language Models (VLMs), built on pre-trained vision encoders and large\nlanguage models (LLMs), have shown exceptional multi-modal understanding and\ndialog capabilities, positioning them as catalysts for the next technological\nrevolution. However, while most VLM research focuses on enhancing multi-modal\ninteraction, the risks of data misuse and leakage have been largely unexplored.\nThis prompts the need for a comprehensive investigation of such risks in VLMs.\nIn this paper, we conduct the first analysis of misuse and leakage detection in\nVLMs through the lens of membership inference attack (MIA). In specific, we\nfocus on the instruction tuning data of VLMs, which is more likely to contain\nsensitive or unauthorized information. To address the limitation of existing\nMIA methods, we introduce a novel approach that infers membership based on a\nset of samples and their sensitivity to temperature, a unique parameter in\nVLMs. Based on this, we propose four membership inference methods, each\ntailored to different levels of background knowledge, ultimately arriving at\nthe most challenging scenario. Our comprehensive evaluations show that these\nmethods can accurately determine membership status, e.g., achieving an AUC\ngreater than 0.8 targeting a small set consisting of only 5 samples on LLaVA.",
      "tldr_zh": "这篇论文首次探讨了 Vision-Language Models (VLMs) 的数据误用和泄露风险，通过 Membership Inference Attack (MIA) 进行分析，重点关注 VLMs 的指令微调数据可能包含的敏感信息。作者提出了一种新方法，利用样本集及其对温度参数的敏感性来推断成员资格，并设计了四种 MIA 方法，适应不同背景知识水平。实验结果显示，这些方法准确性高，例如在 LLaVA 模型上针对仅 5 个样本的集合，AUC 大于 0.8，从而证明了 VLMs 面临的数据泄露威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by USENIX'25; 22 pages, 28 figures;",
      "pdf_url": "http://arxiv.org/pdf/2501.18624v2",
      "published_date": "2025-01-27 05:44:58 UTC",
      "updated_date": "2025-02-07 05:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:57:33.622084"
    },
    {
      "arxiv_id": "2501.15791v2",
      "title": "Harnessing Diverse Perspectives: A Multi-Agent Framework for Enhanced Error Detection in Knowledge Graphs",
      "title_zh": "利用多样化视角：一个用于增强知识图谱错误检测的多智能体",
      "authors": [
        "Yu Li",
        "Yi Huang",
        "Guilin Qi",
        "Junlan Feng",
        "Nan Hu",
        "Songlin Zhai",
        "Haohan Xue",
        "Yongrui Chen",
        "Ruoyan Shen",
        "Tongtong Wu"
      ],
      "abstract": "Knowledge graphs are widely used in industrial applications, making error\ndetection crucial for ensuring the reliability of downstream applications.\nExisting error detection methods often fail to effectively utilize fine-grained\nsubgraph information and rely solely on fixed graph structures, while also\nlacking transparency in their decision-making processes, which results in\nsuboptimal detection performance. In this paper, we propose a novel Multi-Agent\nframework for Knowledge Graph Error Detection (MAKGED) that utilizes multiple\nlarge language models (LLMs) in a collaborative setting. By concatenating\nfine-grained, bidirectional subgraph embeddings with LLM-based query embeddings\nduring training, our framework integrates these representations to produce four\nspecialized agents. These agents utilize subgraph information from different\ndimensions to engage in multi-round discussions, thereby improving error\ndetection accuracy and ensuring a transparent decision-making process.\nExtensive experiments on FB15K and WN18RR demonstrate that MAKGED outperforms\nstate-of-the-art methods, enhancing the accuracy and robustness of KG\nevaluation. For specific industrial scenarios, our framework can facilitate the\ntraining of specialized agents using domain-specific knowledge graphs for error\ndetection, which highlights the potential industrial application value of our\nframework. Our code and datasets are available at\nhttps://github.com/kse-ElEvEn/MAKGED.",
      "tldr_zh": "本研究针对知识图谱（Knowledge Graphs）中的错误检测问题，提出了一种名为 MAKGED 的多智能体框架，利用多个大型语言模型（LLMs）进行协作，以克服现有方法对细粒度子图信息利用不足和决策透明度低的问题。框架通过将细粒度双向子图嵌入与 LLM-based 查询嵌入整合，创建四个专业代理，这些代理从不同维度分析子图信息并进行多轮讨论，从而提升错误检测的准确性和透明度。在 FB15K 和 WN18RR 数据集上的实验显示，MAKGED 优于最先进方法，提高了知识图谱评估的准确性和鲁棒性。该框架还支持使用领域特定知识图谱训练专业代理，具有显著的工业应用潜力。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been ACCEPTED as a FULL PAPER at DASFAA 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.15791v2",
      "published_date": "2025-01-27 05:35:25 UTC",
      "updated_date": "2025-02-20 13:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:57:44.631500"
    },
    {
      "arxiv_id": "2501.15781v1",
      "title": "Large Language Models to Diffusion Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Edoardo Cetin",
        "Tianyu Zhao",
        "Yujin Tang"
      ],
      "abstract": "We propose a new finetuning method to provide pre-trained large language\nmodels (LMs) the ability to scale test-time compute through the diffusion\nframework. By increasing the number of diffusion steps, we show our finetuned\nmodels achieve monotonically increasing accuracy, directly translating to\nimproved performance across downstream tasks. Furthermore, our finetuned models\ncan expertly answer questions on specific topics by integrating powerful\nguidance techniques, and autonomously determine the compute required for a\ngiven problem by leveraging adaptive ODE solvers. Our method is universally\napplicable to any foundation model pre-trained with a cross-entropy loss and\ndoes not modify any of its original weights, fully preserving its strong\nsingle-step generation capabilities. We show our method is more effective and\nfully compatible with traditional finetuning approaches, introducing an\northogonal new direction to unify the strengths of the autoregressive and\ndiffusion frameworks.",
      "tldr_zh": "该论文提出了一种新的微调方法，将预训练的大型语言模型（LLMs）与扩散框架结合，通过增加扩散步骤来提升测试时的计算能力，从而实现准确性的单调提升和下游任务的性能改进。该方法允许模型通过强大指导技术回答特定主题的问题，并利用自适应 ODE 求解器自动确定计算需求，同时不修改原模型权重，保留其单步生成能力。实验结果显示，该方法比传统微调更有效，并与现有方法完全兼容，统一了自回归和扩散框架的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. 19 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.15781v1",
      "published_date": "2025-01-27 04:59:29 UTC",
      "updated_date": "2025-01-27 04:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:57:56.718116"
    },
    {
      "arxiv_id": "2501.15767v2",
      "title": "Formal Verification of Markov Processes with Learned Parameters",
      "title_zh": "带有学习参数的Markov过程形式验证",
      "authors": [
        "Muhammad Maaz",
        "Timothy C. Y. Chan"
      ],
      "abstract": "We introduce the problem of formally verifying properties of Markov processes\nwhere the parameters are given by the output of machine learning models. For a\nbroad class of machine learning models, including linear models, tree-based\nmodels, and neural networks, verifying properties of Markov chains like\nreachability, hitting time, and total reward can be formulated as a bilinear\nprogram. We develop a decomposition and bound propagation scheme for solving\nthe bilinear program and show through computational experiments that our method\nsolves the problem to global optimality up to 100x faster than state-of-the-art\nsolvers. To demonstrate the practical utility of our approach, we apply it to a\nreal-world healthcare case study. Along with the paper, we release markovml, an\nopen-source tool for building Markov processes, integrating pretrained machine\nlearning models, and verifying their properties, available at\nhttps://github.com/mmaaz-git/markovml.",
      "tldr_zh": "该论文探讨了使用机器学习模型输出参数对Markov processes进行正式验证的问题，适用于线性模型、tree-based模型和neural networks等类型。研究将Markov链属性的验证（如reachability、hitting time和total reward）表述为bilinear program，并开发了一种分解和bound propagation方案，使求解速度比现有最先进求解器快100倍。实验结果显示，该方法在真实医疗保健案例中表现出色，并发布了开源工具markovml，用于构建Markov processes、整合预训练机器学习模型并验证其属性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "68Q60 (primary) 90C30, 60J20, 60J22 (secondary)",
        "F.4.1; G.1.6; I.2.3"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages (main manuscript), 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.15767v2",
      "published_date": "2025-01-27 04:34:22 UTC",
      "updated_date": "2025-05-11 08:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:58:08.873764"
    },
    {
      "arxiv_id": "2501.15757v2",
      "title": "Efficiency Bottlenecks of Convolutional Kolmogorov-Arnold Networks: A Comprehensive Scrutiny with ImageNet, AlexNet, LeNet and Tabular Classification",
      "title_zh": "卷积 Kolmogorov-Arnold 网络的效率瓶颈：基于 ImageNet、AlexNet、LeNet 和表格分类的全面审视",
      "authors": [
        "Ashim Dahal",
        "Saydul Akbar Murad",
        "Nick Rahimi"
      ],
      "abstract": "Algorithmic level developments like Convolutional Neural Networks,\ntransformers, attention mechanism, Retrieval Augmented Generation and so on\nhave changed Artificial Intelligence. Recent such development was observed by\nKolmogorov-Arnold Networks that suggested to challenge the fundamental concept\nof a Neural Network, thus change Multilayer Perceptron, and Convolutional\nNeural Networks. They received a good reception in terms of scientific\nmodeling, yet had some drawbacks in terms of efficiency. In this paper, we\ntrain Convolutional Kolmogorov Arnold Networks (CKANs) with the ImageNet-1k\ndataset with 1.3 million images, MNIST dataset with 60k images and a tabular\nbiological science related MoA dataset and test the promise of CKANs in terms\nof FLOPS, Inference Time, number of trainable parameters and training time\nagainst the accuracy, precision, recall and f-1 score they produce against the\nstandard industry practice on CNN models. We show that the CKANs perform fair\nyet slower than CNNs in small size dataset like MoA and MNIST but are not\nnearly comparable as the dataset gets larger and more complex like the\nImageNet. The code implementation of this paper can be found on the link:\n\\href{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}{https://github.com/ashimdahal/Study-of-Convolutional-Kolmogorov-Arnold-networks}",
      "tldr_zh": "本研究对Convolutional Kolmogorov-Arnold Networks (CKANs) 的效率瓶颈进行了全面评估，旨在挑战传统神经网络如Multilayer Perceptron和CNNs的核心概念。研究者训练CKANs于ImageNet-1k（130万图像）、MNIST（6万图像）和MoA（表格数据集）上，比较了FLOPS、推理时间、可训练参数和训练时间等指标与准确率、精确率、召回率及F1分数的性能表现。结果显示，CKANs在小型数据集如MNIST和MoA上表现公平但比CNNs慢，而在大规模复杂数据集如ImageNet上，其效率和表现远逊于CNNs。该论文提供了代码实现链接，以供进一步验证和扩展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15757v2",
      "published_date": "2025-01-27 04:00:05 UTC",
      "updated_date": "2025-01-28 04:26:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:58:21.141765"
    },
    {
      "arxiv_id": "2501.15749v1",
      "title": "LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System",
      "title_zh": "翻译失败",
      "authors": [
        "Tianfu Wang",
        "Yi Zhan",
        "Jianxun Lian",
        "Zhengyu Hu",
        "Nicholas Jing Yuan",
        "Qi Zhang",
        "Xing Xie",
        "Hui Xiong"
      ],
      "abstract": "Intelligent Tutoring Systems (ITSs) have revolutionized education by offering\npersonalized learning experiences. However, as goal-oriented learning, which\nemphasizes efficiently achieving specific objectives, becomes increasingly\nimportant in professional contexts, existing ITSs often struggle to deliver\nthis type of targeted learning experience. In this paper, we propose GenMentor,\nan LLM-powered multi-agent framework designed to deliver goal-oriented,\npersonalized learning within ITS. GenMentor begins by accurately mapping\nlearners' goals to required skills using a fine-tuned LLM trained on a custom\ngoal-to-skill dataset. After identifying the skill gap, it schedules an\nefficient learning path using an evolving optimization approach, driven by a\ncomprehensive and dynamic profile of learners' multifaceted status.\nAdditionally, GenMentor tailors learning content with an\nexploration-drafting-integration mechanism to align with individual learner\nneeds. Extensive automated and human evaluations demonstrate GenMentor's\neffectiveness in learning guidance and content quality. Furthermore, we have\ndeployed it in practice and also implemented it as an application. Practical\nhuman study with professional learners further highlights its effectiveness in\ngoal alignment and resource targeting, leading to enhanced personalization.\nSupplementary resources are available at\nhttps://github.com/GeminiLight/gen-mentor.",
      "tldr_zh": "该论文提出 GenMentor，一种基于 LLM 的多-agent 框架，旨在提升 Intelligent Tutoring Systems (ITSs) 在专业背景下的目标导向学习能力。框架首先使用 fine-tuned LLM 和自定义数据集，将学习者目标映射到所需技能，并通过 evolving optimization approach 动态优化学习路径以填补技能差距。随后，它采用 exploration-drafting-integration 机制定制个性化学习内容。实验结果和实际部署显示，GenMentor 在学习指导和内容质量方面表现出色，人文研究进一步证实了其在目标对齐和资源针对性上的优势。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by WWW 2025 (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2501.15749v1",
      "published_date": "2025-01-27 03:29:44 UTC",
      "updated_date": "2025-01-27 03:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:58:33.235078"
    },
    {
      "arxiv_id": "2501.15747v2",
      "title": "IndicMMLU-Pro: Benchmarking Indic Large Language Models on Multi-Task Language Understanding",
      "title_zh": "IndicMMLU-Pro：针对印度语系大语言模型的多任务语言理解基准测试",
      "authors": [
        "Sankalp KJ",
        "Ashutosh Kumar",
        "Laxmaan Balaji",
        "Nikunj Kotecha",
        "Vinija Jain",
        "Aman Chadha",
        "Sreyoshi Bhaduri"
      ],
      "abstract": "Known by more than 1.5 billion people in the Indian subcontinent, Indic\nlanguages present unique challenges and opportunities for natural language\nprocessing (NLP) research due to their rich cultural heritage, linguistic\ndiversity, and complex structures. IndicMMLU-Pro is a comprehensive benchmark\ndesigned to evaluate Large Language Models (LLMs) across Indic languages,\nbuilding upon the MMLU Pro (Massive Multitask Language Understanding)\nframework. Covering major languages such as Hindi, Bengali, Gujarati, Marathi,\nKannada, Punjabi, Tamil, Telugu, and Urdu, our benchmark addresses the unique\nchallenges and opportunities presented by the linguistic diversity of the\nIndian subcontinent. This benchmark encompasses a wide range of tasks in\nlanguage comprehension, reasoning, and generation, meticulously crafted to\ncapture the intricacies of Indian languages. IndicMMLU-Pro provides a\nstandardized evaluation framework to push the research boundaries in Indic\nlanguage AI, facilitating the development of more accurate, efficient, and\nculturally sensitive models. This paper outlines the benchmarks' design\nprinciples, task taxonomy, and data collection methodology, and presents\nbaseline results from state-of-the-art multilingual models.",
      "tldr_zh": "该研究介绍了IndicMMLU-Pro，一个基于MMLU Pro框架的全面基准，用于评估Large Language Models (LLMs)在Indic语言的多任务语言理解能力。基准覆盖了Hindi、Bengali、Gujarati、Marathi、Kannada、Punjabi、Tamil、Telugu和Urdu等九种语言，涵盖语言理解、推理和生成任务，以应对这些语言的文化多样性和复杂结构。论文阐述了基准的设计原则、任务分类、数据收集方法，并提供了多语言模型的基线结果，推动了更准确、文化敏感的Indic语言AI模型的开发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15747v2",
      "published_date": "2025-01-27 03:19:03 UTC",
      "updated_date": "2025-01-28 04:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:58:45.353470"
    },
    {
      "arxiv_id": "2501.15740v1",
      "title": "Propositional Interpretability in Artificial Intelligence",
      "title_zh": "人工智能中的命题可解释性",
      "authors": [
        "David J. Chalmers"
      ],
      "abstract": "Mechanistic interpretability is the program of explaining what AI systems are\ndoing in terms of their internal mechanisms. I analyze some aspects of the\nprogram, along with setting out some concrete challenges and assessing progress\nto date. I argue for the importance of propositional interpretability, which\ninvolves interpreting a system's mechanisms and behavior in terms of\npropositional attitudes: attitudes (such as belief, desire, or subjective\nprobability) to propositions (e.g. the proposition that it is hot outside).\nPropositional attitudes are the central way that we interpret and explain human\nbeings and they are likely to be central in AI too. A central challenge is what\nI call thought logging: creating systems that log all of the relevant\npropositional attitudes in an AI system over time. I examine currently popular\nmethods of interpretability (such as probing, sparse auto-encoders, and chain\nof thought methods) as well as philosophical methods of interpretation\n(including those grounded in psychosemantics) to assess their strengths and\nweaknesses as methods of propositional interpretability.",
      "tldr_zh": "该论文分析了AI领域的Mechanistic interpretability，即通过内部机制解释AI系统的运作，并强调了propositional interpretability的重要性，即用propositional attitudes（如belief、desire或subjective probability）来解释AI的行为和机制。作者指出，propositional attitudes是理解人类和AI的核心方式，并将thought logging（记录AI系统中所有相关propositional attitudes）定义为主要挑战。论文评估了当前方法如probing、sparse auto-encoders和chain of thought methods，以及哲学方法（如基于psychosemantics的），评估它们的优势和局限性，以推进AI解释性的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15740v1",
      "published_date": "2025-01-27 03:06:06 UTC",
      "updated_date": "2025-01-27 03:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:58:56.789820"
    },
    {
      "arxiv_id": "2502.07088v1",
      "title": "Kernels of Selfhood: GPT-4o shows humanlike patterns of cognitive consistency moderated by free choice",
      "title_zh": "翻译失败",
      "authors": [
        "Steven A. Lehr",
        "Ketan S. Saichandran",
        "Eddie Harmon-Jones",
        "Nykko Vitali",
        "Mahzarin R. Banaji"
      ],
      "abstract": "Large Language Models (LLMs) show emergent patterns that mimic human\ncognition. We explore whether they also mirror other, less deliberative human\npsychological processes. Drawing upon classical theories of cognitive\nconsistency, two preregistered studies tested whether GPT-4o changed its\nattitudes toward Vladimir Putin in the direction of a positive or negative\nessay it wrote about the Russian leader. Indeed, GPT displayed patterns of\nattitude change mimicking cognitive consistency effects in humans. Even more\nremarkably, the degree of change increased sharply when the LLM was offered an\nillusion of choice about which essay (positive or negative) to write. This\nresult suggests that GPT-4o manifests a functional analog of humanlike\nselfhood, although how faithfully the chatbot's behavior reflects the\nmechanisms of human attitude change remains to be understood.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否模仿人类非 deliberative 心理过程，特别是认知一致性(cognitive consistency)。研究通过两个 preregistered 实验，让GPT-4o撰写关于Vladimir Putin的正负面文章，并观察其态度变化，结果显示GPT-4o表现出类似人类的认知一致性效果。更为显著的是，当提供自由选择(free choice)时，态度变化程度显著增加，表明GPT-4o可能具备人类like selfhood的功能模拟，但其机制仍需进一步验证。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "68T50 (Primary), 91E10, 68T30, 68T99, 91C99 (Secondary)",
        "I.2.7; I.2.0; J.4; K.4.0; H.1.2; K.4.1"
      ],
      "primary_category": "cs.CY",
      "comment": "Main Article: 10 pages, Supporting Information: 61 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.07088v1",
      "published_date": "2025-01-27 02:25:12 UTC",
      "updated_date": "2025-01-27 02:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:59:08.798308"
    },
    {
      "arxiv_id": "2501.15733v1",
      "title": "Leveraging Video Vision Transformer for Alzheimer's Disease Diagnosis from 3D Brain MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Taymaz Akan",
        "Sait Alp",
        "Md. Shenuarin Bhuiyan",
        "Elizabeth A. Disbrow",
        "Steven A. Conrad",
        "John A. Vanchiere",
        "Christopher G. Kevil",
        "Mohammad A. N. Bhuiyan"
      ],
      "abstract": "Alzheimer's disease (AD) is a neurodegenerative disorder affecting millions\nworldwide, necessitating early and accurate diagnosis for optimal patient\nmanagement. In recent years, advancements in deep learning have shown\nremarkable potential in medical image analysis. Methods In this study, we\npresent \"ViTranZheimer,\" an AD diagnosis approach which leverages video vision\ntransformers to analyze 3D brain MRI data. By treating the 3D MRI volumes as\nvideos, we exploit the temporal dependencies between slices to capture\nintricate structural relationships. The video vision transformer's\nself-attention mechanisms enable the model to learn long-range dependencies and\nidentify subtle patterns that may indicate AD progression. Our proposed deep\nlearning framework seeks to enhance the accuracy and sensitivity of AD\ndiagnosis, empowering clinicians with a tool for early detection and\nintervention. We validate the performance of the video vision transformer using\nthe ADNI dataset and conduct comparative analyses with other relevant models.\nResults The proposed ViTranZheimer model is compared with two hybrid models,\nCNN-BiLSTM and ViT-BiLSTM. CNN-BiLSTM is the combination of a convolutional\nneural network (CNN) and a bidirectional long-short-term memory network\n(BiLSTM), while ViT-BiLSTM is the combination of a vision transformer (ViT)\nwith BiLSTM. The accuracy levels achieved in the ViTranZheimer, CNN-BiLSTM, and\nViT-BiLSTM models are 98.6%, 96.479%, and 97.465%, respectively. ViTranZheimer\ndemonstrated the highest accuracy at 98.6%, outperforming other models in this\nevaluation metric, indicating its superior performance in this specific\nevaluation metric. Conclusion This research advances the understanding of\napplying deep learning techniques in neuroimaging and Alzheimer's disease\nresearch, paving the way for earlier and less invasive clinical diagnosis.",
      "tldr_zh": "本文提出ViTranZheimer模型，利用Video Vision Transformer将3D brain MRI数据视为视频，捕捉切片间的时序依赖和长程依赖，以提升Alzheimer's Disease (AD)诊断的准确性和敏感性。相比于CNN-BiLSTM和ViT-BiLSTM模型，该方法在ADNI数据集上实现了98.6%的准确率，分别高于后两者的96.479%和97.465%。这项研究展示了Video Vision Transformer在神经影像分析中的潜力，为AD的早期检测和临床干预提供了更可靠的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15733v1",
      "published_date": "2025-01-27 02:18:08 UTC",
      "updated_date": "2025-01-27 02:18:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:59:21.647176"
    },
    {
      "arxiv_id": "2501.15731v1",
      "title": "Renewable Energy Prediction: A Comparative Study of Deep Learning Models for Complex Dataset Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Haibo Wang",
        "Jun Huang",
        "Lutfu Sua",
        "Bahram Alidaee"
      ],
      "abstract": "The increasing focus on predicting renewable energy production aligns with\nadvancements in deep learning (DL). The inherent variability of renewable\nsources and the complexity of prediction methods require robust approaches,\nsuch as DL models, in the renewable energy sector. DL models are preferred over\ntraditional machine learning (ML) because they capture complex, nonlinear\nrelationships in renewable energy datasets. This study examines key factors\ninfluencing DL technique accuracy, including sampling and hyperparameter\noptimization, by comparing various methods and training and test ratios within\na DL framework. Seven machine learning methods, LSTM, Stacked LSTM, CNN,\nCNN-LSTM, DNN, Time-Distributed MLP (TD-MLP), and Autoencoder (AE), are\nevaluated using a dataset combining weather and photovoltaic power output data\nfrom 12 locations. Regularization techniques such as early stopping, neuron\ndropout, L1 and L2 regularization are applied to address overfitting. The\nresults demonstrate that the combination of early stopping, dropout, and L1\nregularization provides the best performance to reduce overfitting in the CNN\nand TD-MLP models with larger training set, while the combination of early\nstopping, dropout, and L2 regularization is the most effective to reduce the\noverfitting in CNN-LSTM and AE models with smaller training set.",
      "tldr_zh": "本研究比较了多种深度学习（DL）模型在复杂可再生能源预测数据集中的性能，旨在解决能源生产变异性和非线性关系的挑战。研究者评估了七种模型，包括 LSTM、Stacked LSTM、CNN、CNN-LSTM、DNN、Time-Distributed MLP (TD-MLP) 和 Autoencoder (AE)，使用来自12个地点的天气和光伏输出数据，并探讨了采样、超参数优化以及正则化技巧（如 early stopping、neuron dropout、L1 和 L2 regularization）对准确性的影响。结果显示，对于较大的训练集，CNN 和 TD-MLP 模型通过 early stopping、dropout 和 L1 regularization 组合可有效减少过拟合；对于较小的训练集，CNN-LSTM 和 AE 模型则以 early stopping、dropout 和 L2 regularization 组合表现最佳，从而为DL在可再生能源预测中的应用提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 2 figures and 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.15731v1",
      "published_date": "2025-01-27 02:10:10 UTC",
      "updated_date": "2025-01-27 02:10:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:59:33.091591"
    },
    {
      "arxiv_id": "2501.15727v1",
      "title": "Gensors: Authoring Personalized Visual Sensors with Multimodal Foundation Models and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Xieyang Liu",
        "Savvas Petridis",
        "Vivian Tsai",
        "Alexander J. Fiannaca",
        "Alex Olwal",
        "Michael Terry",
        "Carrie J. Cai"
      ],
      "abstract": "Multimodal large language models (MLLMs), with their expansive world\nknowledge and reasoning capabilities, present a unique opportunity for\nend-users to create personalized AI sensors capable of reasoning about complex\nsituations. A user could describe a desired sensing task in natural language\n(e.g., \"alert if my toddler is getting into mischief\"), with the MLLM analyzing\nthe camera feed and responding within seconds. In a formative study, we found\nthat users saw substantial value in defining their own sensors, yet struggled\nto articulate their unique personal requirements and debug the sensors through\nprompting alone. To address these challenges, we developed Gensors, a system\nthat empowers users to define customized sensors supported by the reasoning\ncapabilities of MLLMs. Gensors 1) assists users in eliciting requirements\nthrough both automatically-generated and manually created sensor criteria, 2)\nfacilitates debugging by allowing users to isolate and test individual criteria\nin parallel, 3) suggests additional criteria based on user-provided images, and\n4) proposes test cases to help users \"stress test\" sensors on potentially\nunforeseen scenarios. In a user study, participants reported significantly\ngreater sense of control, understanding, and ease of communication when\ndefining sensors using Gensors. Beyond addressing model limitations, Gensors\nsupported users in debugging, eliciting requirements, and expressing unique\npersonal requirements to the sensor through criteria-based reasoning; it also\nhelped uncover users' \"blind spots\" by exposing overlooked criteria and\nrevealing unanticipated failure modes. Finally, we discuss how unique\ncharacteristics of MLLMs--such as hallucinations and inconsistent\nresponses--can impact the sensor-creation process. These findings contribute to\nthe design of future intelligent sensing systems that are intuitive and\ncustomizable by everyday users.",
      "tldr_zh": "该研究利用多模态大语言模型(MLLMs)的知识和推理能力，开发了Gensors系统，帮助用户创建个性化的视觉传感器，例如通过自然语言描述任务（如“如果我的孩子淘气了就警报”）。Gensors提供多种功能，包括自动生成和手动创建传感器标准、并行调试标准、基于图像建议额外标准，以及提出测试案例来验证潜在场景。用户研究显示，使用Gensors后，用户在控制感、理解度和沟通易用性上显著提升，同时系统还揭示了用户的盲点和MLLMs的局限性（如幻觉和不一致响应）。这项工作为设计直观、可定制的智能传感系统提供了重要见解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15727v1",
      "published_date": "2025-01-27 01:47:57 UTC",
      "updated_date": "2025-01-27 01:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:59:44.577628"
    },
    {
      "arxiv_id": "2501.15724v2",
      "title": "A Survey on Computational Pathology Foundation Models: Datasets, Adaptation Strategies, and Evaluation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Li",
        "Guihong Wan",
        "Xintao Wu",
        "Xinyu Wu",
        "Ajit J. Nirmal",
        "Christine G. Lian",
        "Peter K. Sorger",
        "Yevgeniy R. Semenov",
        "Chen Zhao"
      ],
      "abstract": "Computational pathology foundation models (CPathFMs) have emerged as a\npowerful approach for analyzing histopathological data, leveraging\nself-supervised learning to extract robust feature representations from\nunlabeled whole-slide images. These models, categorized into uni-modal and\nmulti-modal frameworks, have demonstrated promise in automating complex\npathology tasks such as segmentation, classification, and biomarker discovery.\nHowever, the development of CPathFMs presents significant challenges, such as\nlimited data accessibility, high variability across datasets, the necessity for\ndomain-specific adaptation, and the lack of standardized evaluation benchmarks.\nThis survey provides a comprehensive review of CPathFMs in computational\npathology, focusing on datasets, adaptation strategies, and evaluation tasks.\nWe analyze key techniques, such as contrastive learning and multi-modal\nintegration, and highlight existing gaps in current research. Finally, we\nexplore future directions from four perspectives for advancing CPathFMs. This\nsurvey serves as a valuable resource for researchers, clinicians, and AI\npractitioners, guiding the advancement of CPathFMs toward robust and clinically\napplicable AI-driven pathology solutions.",
      "tldr_zh": "计算病理基础模型 (CPathFMs) 通过自监督学习从无标签的全滑玻片图像中提取鲁棒特征表示，已被用于自动化病理任务如分割、分类和生物标记物发现，但面临数据可访问性有限、数据集变异性高以及缺乏标准化评估基准等挑战。本调查全面回顾了CPathFMs的关键方面，包括数据集、适应策略（如对比学习和多模态整合）和评估任务，分析了现有研究中的差距，并从四个角度探讨未来发展方向。该论文为研究人员、临床医生和AI从业者提供宝贵资源，推动CPathFMs向更鲁棒且临床适用的AI驱动病理解决方案演进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.15724v2",
      "published_date": "2025-01-27 01:27:59 UTC",
      "updated_date": "2025-02-26 03:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T03:59:57.290881"
    },
    {
      "arxiv_id": "2501.15708v3",
      "title": "StaICC: Standardized Evaluation for Classification Task in In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hakaze Cho",
        "Naoya Inoue"
      ],
      "abstract": "Classification tasks are widely investigated in the In-Context Learning (ICL)\nparadigm. However, current efforts are evaluated on disjoint benchmarks and\nsettings, while their performances are significantly influenced by some trivial\nvariables, such as prompt templates, data sampling, instructions, etc., which\nleads to significant inconsistencies in the results reported across various\nliterature, preventing fair comparison or meta-analysis across different\npapers. Therefore, this paper proposes a standardized and easy-to-use\nevaluation toolkit (StaICC) for in-context classification. Including, for the\nnormal classification task, we provide StaICC-Normal, selecting 10 widely used\ndatasets, and generating prompts with a fixed form, to mitigate the variance\namong the experiment implementations. To enrich the usage of our benchmark, we\nalso provide a sub-benchmark StaICC-Diag for diagnosing ICL from several\naspects, aiming for a more robust inference processing.",
      "tldr_zh": "本文针对 In-Context Learning (ICL) 中的分类任务评估存在不一致问题（如提示模板和数据采样影响），提出标准化评估工具包 StaICC，以实现公平比较和元分析。StaICC-Normal 子基准选取 10 个常用数据集，并采用固定形式的提示生成，减少实验变异。StaICC-Diag 则用于从多个方面诊断 ICL 的性能，提升推理处理的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 8 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.15708v3",
      "published_date": "2025-01-27 00:05:12 UTC",
      "updated_date": "2025-04-18 08:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T04:00:09.095161"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 106,
  "processed_papers_count": 106,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T04:00:41.699931"
}