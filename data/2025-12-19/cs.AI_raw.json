[
  {
    "arxiv_id": "2512.21348v1",
    "title": "Fairness Is Not Just Ethical: Performance Trade-Off via Data Correlation Tuning to Mitigate Bias in ML Software",
    "authors": [
      "Ying Xiao",
      "Shangwen Wang",
      "Sicen Liu",
      "Dingyuan Xue",
      "Xian Zhan",
      "Yepang Liu",
      "Jie M. Zhang"
    ],
    "abstract": "Traditional software fairness research typically emphasizes ethical and social imperatives, neglecting that fairness fundamentally represents a core software quality issue arising directly from performance disparities across sensitive user groups. Recognizing fairness explicitly as a software quality dimension yields practical benefits beyond ethical considerations, notably improved predictive performance for unprivileged groups, enhanced out-of-distribution generalization, and increased geographic transferability in real-world deployments. Nevertheless, existing bias mitigation methods face a critical dilemma: while pre-processing methods offer broad applicability across model types, they generally fall short in effectiveness compared to post-processing techniques. To overcome this challenge, we propose Correlation Tuning (CoT), a novel pre-processing approach designed to mitigate bias by adjusting data correlations. Specifically, CoT introduces the Phi-coefficient, an intuitive correlation measure, to systematically quantify correlation between sensitive attributes and labels, and employs multi-objective optimization to address the proxy biases. Extensive evaluations demonstrate that CoT increases the true positive rate of unprivileged groups by an average of 17.5% and reduces three key bias metrics, including statistical parity difference (SPD), average odds difference (AOD), and equal opportunity difference (EOD), by more than 50% on average. CoT outperforms state-of-the-art methods by three and ten percentage points in single attribute and multiple attributes scenarios, respectively. We will publicly release our experimental results and source code to facilitate future research.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to the 48th International Conference on Software Engineering (ICSE 2026) Research Track",
    "pdf_url": "https://arxiv.org/pdf/2512.21348v1",
    "published_date": "2025-12-19 23:50:27 UTC",
    "updated_date": "2025-12-19 23:50:27 UTC"
  },
  {
    "arxiv_id": "2512.18135v1",
    "title": "Unifying Causal Reinforcement Learning: Survey, Taxonomy, Algorithms and Applications",
    "authors": [
      "Cristiano da Costa Cunha",
      "Wei Liu",
      "Tim French",
      "Ajmal Mian"
    ],
    "abstract": "Integrating causal inference (CI) with reinforcement learning (RL) has emerged as a powerful paradigm to address critical limitations in classical RL, including low explainability, lack of robustness and generalization failures. Traditional RL techniques, which typically rely on correlation-driven decision-making, struggle when faced with distribution shifts, confounding variables, and dynamic environments. Causal reinforcement learning (CRL), leveraging the foundational principles of causal inference, offers promising solutions to these challenges by explicitly modeling cause-and-effect relationships. In this survey, we systematically review recent advancements at the intersection of causal inference and RL. We categorize existing approaches into causal representation learning, counterfactual policy optimization, offline causal RL, causal transfer learning, and causal explainability. Through this structured analysis, we identify prevailing challenges, highlight empirical successes in practical applications, and discuss open problems. Finally, we provide future research directions, underscoring the potential of CRL for developing robust, generalizable, and interpretable artificial intelligence systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 14 figures, 5 algorithms",
    "pdf_url": "https://arxiv.org/pdf/2512.18135v1",
    "published_date": "2025-12-19 23:37:22 UTC",
    "updated_date": "2025-12-19 23:37:22 UTC"
  },
  {
    "arxiv_id": "2512.18133v1",
    "title": "Grad: Guided Relation Diffusion Generation for Graph Augmentation in Graph Fraud Detection",
    "authors": [
      "Jie Yang",
      "Rui Zhang",
      "Ziyang Cheng",
      "Dawei Cheng",
      "Guang Yang",
      "Bo Wang"
    ],
    "abstract": "Nowadays, Graph Fraud Detection (GFD) in financial scenarios has become an urgent research topic to protect online payment security. However, as organized crime groups are becoming more professional in real-world scenarios, fraudsters are employing more sophisticated camouflage strategies. Specifically, fraudsters disguise themselves by mimicking the behavioral data collected by platforms, ensuring that their key characteristics are consistent with those of benign users to a high degree, which we call Adaptive Camouflage. Consequently, this narrows the differences in behavioral traits between them and benign users within the platform's database, thereby making current GFD models lose efficiency. To address this problem, we propose a relation diffusion-based graph augmentation model Grad. In detail, Grad leverages a supervised graph contrastive learning module to enhance the fraud-benign difference and employs a guided relation diffusion generator to generate auxiliary homophilic relations from scratch. Based on these, weak fraudulent signals would be enhanced during the aggregation process, thus being obvious enough to be captured. Extensive experiments have been conducted on two real-world datasets provided by WeChat Pay, one of the largest online payment platforms with billions of users, and three public datasets. The results show that our proposed model Grad outperforms SOTA methods in both various scenarios, achieving at most 11.10% and 43.95% increases in AUC and AP, respectively. Our code is released at https://github.com/AI4Risk/antifraud and https://github.com/Muyiiiii/WWW25-Grad.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by The Web Conference 2025 (WWW'25). 12 pages, includes implementation details. Code: https://github.com/AI4Risk/antifraud and https://github.com/Muyiiiiii/WWW25-Grad",
    "pdf_url": "https://arxiv.org/pdf/2512.18133v1",
    "published_date": "2025-12-19 23:32:36 UTC",
    "updated_date": "2025-12-19 23:32:36 UTC"
  },
  {
    "arxiv_id": "2512.18131v1",
    "title": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
    "authors": [
      "Le Zhang",
      "Suresh Kothari"
    ],
    "abstract": "This study presents a comprehensive empirical evaluation of six state-of-the-art large language models (LLMs) for code generation, including both general-purpose and code-specialized models. Using a dataset of 944 real-world LeetCode problems across five programming languages, we assess model performance using rigorous metrics: compile-time errors, runtime errors, functional failures, and algorithmic suboptimalities. The results reveal significant performance variations, with DeepSeek-R1 and GPT-4.1 consistently outperform others in terms of correctness, efficiency, and robustness. Through detailed case studies, we identify common failure scenarios such as syntax errors, logical flaws, and suboptimal algorithms, highlighting the critical role of prompt engineering and human oversight in improving results. Based on these findings, we provide actionable recommendations for developers and practitioners, emphasizing that successful LLM deployment depends on careful model selection, effective prompt design, and context-aware usage to ensure reliable code generation in real-world software development tasks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages, 9 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.18131v1",
    "published_date": "2025-12-19 23:29:05 UTC",
    "updated_date": "2025-12-19 23:29:05 UTC"
  },
  {
    "arxiv_id": "2512.18126v1",
    "title": "Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap",
    "authors": [
      "Zijun Wang",
      "Yijiahao Qi",
      "Hanqiu Chen",
      "Zishen Wan",
      "Gongjin Sun",
      "Dongyang Li",
      "Shuyi Pei",
      "Cong Hao"
    ],
    "abstract": "Mixture-of-Agents (MoA) inference can suffer from dense inter-agent communication and low hardware utilization, which jointly inflate serving latency. We present a serving design that targets these bottlenecks through an algorithm-system co-design. First, we replace dense agent interaction graphs with a hierarchical tree topology that induces structured sparsity in inter-agent communication. Second, we introduce a runtime adaptive mechanism that selectively terminates or skips downstream agent invocations using semantic agreement and confidence signals from intermediate outputs. Third, we pipeline agent execution by overlapping incremental prefilling with decoding across dependency-related agents, improving utilization and reducing inference latency. Across representative tasks, this approach substantially reduces end-to-end latency (up to 90%) while maintaining comparable accuracy (within $\\pm$1%) relative to dense-connectivity MoA baselines, and can improve accuracy in certain settings.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 4 figures, submitted to Design Automation Conference (DAC) 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.18126v1",
    "published_date": "2025-12-19 23:06:58 UTC",
    "updated_date": "2025-12-19 23:06:58 UTC"
  },
  {
    "arxiv_id": "2512.18094v1",
    "title": "Rethinking Multi-Agent Intelligence Through the Lens of Small-World Networks",
    "authors": [
      "Boxuan Wang",
      "Zhuoyun Li",
      "Xiaowei Huang",
      "Yi Dong"
    ],
    "abstract": "Large language models (LLMs) have enabled multi-agent systems (MAS) in which multiple agents argue, critique, and coordinate to solve complex tasks, making communication topology a first-class design choice. Yet most existing LLM-based MAS either adopt fully connected graphs, simple sparse rings, or ad-hoc dynamic selection, with little structural guidance. In this work, we revisit classic theory on small-world (SW) networks and ask: what changes if we treat SW connectivity as a design prior for MAS? We first bridge insights from neuroscience and complex networks to MAS, highlighting how SW structures balance local clustering and long-range integration. Using multi-agent debate (MAD) as a controlled testbed, experiment results show that SW connectivity yields nearly the same accuracy and token cost, while substantially stabilizing consensus trajectories. Building on this, we introduce an uncertainty-guided rewiring scheme for scaling MAS, where long-range shortcuts are added between epistemically divergent agents using LLM-oriented uncertainty signals (e.g., semantic entropy). This yields controllable SW structures that adapt to task difficulty and agent heterogeneity. Finally, we discuss broader implications of SW priors for MAS design, framing them as stabilizers of reasoning, enhancers of robustness, scalable coordinators, and inductive biases for emergent cognitive roles.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2512.18094v1",
    "published_date": "2025-12-19 22:05:43 UTC",
    "updated_date": "2025-12-19 22:05:43 UTC"
  },
  {
    "arxiv_id": "2512.18092v1",
    "title": "Faithful and Stable Neuron Explanations for Trustworthy Mechanistic Interpretability",
    "authors": [
      "Ge Yan",
      "Tuomas Oikarinen",
      "Tsui-Wei",
      "Weng"
    ],
    "abstract": "Neuron identification is a popular tool in mechanistic interpretability, aiming to uncover the human-interpretable concepts represented by individual neurons in deep networks. While algorithms such as Network Dissection and CLIP-Dissect achieve great empirical success, a rigorous theoretical foundation remains absent, which is crucial to enable trustworthy and reliable explanations. In this work, we observe that neuron identification can be viewed as the inverse process of machine learning, which allows us to derive guarantees for neuron explanations. Based on this insight, we present the first theoretical analysis of two fundamental challenges: (1) Faithfulness: whether the identified concept faithfully represents the neuron's underlying function and (2) Stability: whether the identification results are consistent across probing datasets. We derive generalization bounds for widely used similarity metrics (e.g. accuracy, AUROC, IoU) to guarantee faithfulness, and propose a bootstrap ensemble procedure that quantifies stability along with BE (Bootstrap Explanation) method to generate concept prediction sets with guaranteed coverage probability. Experiments on both synthetic and real data validate our theoretical results and demonstrate the practicality of our method, providing an important step toward trustworthy neuron identification.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18092v1",
    "published_date": "2025-12-19 21:55:17 UTC",
    "updated_date": "2025-12-19 21:55:17 UTC"
  },
  {
    "arxiv_id": "2512.18082v1",
    "title": "Uncertainty-Gated Region-Level Retrieval for Robust Semantic Segmentation",
    "authors": [
      "Shreshth Rajan",
      "Raymond Liu"
    ],
    "abstract": "Semantic segmentation of outdoor street scenes plays a key role in applications such as autonomous driving, mobile robotics, and assistive technology for visually-impaired pedestrians. For these applications, accurately distinguishing between key surfaces and objects such as roads, sidewalks, vehicles, and pedestrians is essential for maintaining safety and minimizing risks. Semantic segmentation must be robust to different environments, lighting and weather conditions, and sensor noise, while being performed in real-time. We propose a region-level, uncertainty-gated retrieval mechanism that improves segmentation accuracy and calibration under domain shift. Our best method achieves an 11.3% increase in mean intersection-over-union while reducing retrieval cost by 87.5%, retrieving for only 12.5% of regions compared to 100% for always-on baseline.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18082v1",
    "published_date": "2025-12-19 21:39:22 UTC",
    "updated_date": "2025-12-19 21:39:22 UTC"
  },
  {
    "arxiv_id": "2512.18080v1",
    "title": "From Prompt to Product: A Human-Centered Benchmark of Agentic App Generation Systems",
    "authors": [
      "Marcos Ortiz",
      "Justin Hill",
      "Collin Overbay",
      "Ingrida Semenec",
      "Frederic Sauve-Hoover",
      "Jim Schwoebel",
      "Joel Shor"
    ],
    "abstract": "Agentic AI systems capable of generating full-stack web applications from natural language prompts (\"prompt- to-app\") represent a significant shift in software development. However, evaluating these systems remains challenging, as visual polish, functional correctness, and user trust are often misaligned. As a result, it is unclear how existing prompt-to-app tools compare under realistic, human-centered evaluation criteria. In this paper, we introduce a human-centered benchmark for evaluating prompt-to-app systems and conduct a large-scale comparative study of three widely used platforms: Replit, Bolt, and Firebase Studio. Using a diverse set of 96 prompts spanning common web application tasks, we generate 288 unique application artifacts. We evaluate these systems through a large-scale human-rater study involving 205 participants and 1,071 quality-filtered pairwise comparisons, assessing task-based ease of use, visual appeal, perceived completeness, and user trust. Our results show that these systems are not interchangeable: Firebase Studio consistently outperforms competing platforms across all human-evaluated dimensions, achieving the highest win rates for ease of use, trust, visual appeal, and visual appropriateness. Bolt performs competitively on visual appeal but trails Firebase on usability and trust, while Replit underperforms relative to both across most metrics. These findings highlight a persistent gap between visual polish and functional reliability in prompt-to-app systems and demonstrate the necessity of interactive, task-based evaluation. We release our benchmark framework, prompt set, and generated artifacts to support reproducible evaluation and future research in agentic application generation.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18080v1",
    "published_date": "2025-12-19 21:37:15 UTC",
    "updated_date": "2025-12-19 21:37:15 UTC"
  },
  {
    "arxiv_id": "2512.18077v1",
    "title": "Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling",
    "authors": [
      "Ohoud Alzahrani",
      "Russell Beale",
      "Robert J. Hendley"
    ],
    "abstract": "This paper asks whether promotional Twitter/X bots form behavioural families and whether members evolve similarly. We analyse 2,798,672 tweets from 2,615 ground-truth promotional bot accounts (2006-2021), focusing on complete years 2009 to 2020. Each bot is encoded as a sequence of symbolic blocks (``digital DNA'') from seven categorical post-level behavioural features (posting action, URL, media, text duplication, hashtags, emojis, sentiment), preserving temporal order only. Using non-overlapping blocks (k=7), cosine similarity over block-frequency vectors, and hierarchical clustering, we obtain four coherent families: Unique Tweeters, Duplicators with URLs, Content Multipliers, and Informed Contributors. Families share behavioural cores but differ systematically in engagement strategies and life-cycle dynamics (beginning/middle/end). We then model behavioural change as mutations. Within each family we align sequences via multiple sequence alignment (MSA) and label events as insertions, deletions, substitutions, alterations, and identity. This quantifies mutation rates, change-prone blocks/features, and mutation hotspots. Deletions and substitutions dominate, insertions are rare, and mutation profiles differ by family, with hotspots early for some families and dispersed for others. Finally, we test predictive value: bots within the same family share mutations more often than bots across families; closer bots share and propagate mutations more than distant ones; and responses to external triggers (e.g., Christmas, Halloween) follow family-specific, partly predictable patterns. Overall, sequence-based family modelling plus mutation analysis provides a fine-grained account of how promotional bot behaviour adapts over time.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18077v1",
    "published_date": "2025-12-19 21:30:21 UTC",
    "updated_date": "2025-12-19 21:30:21 UTC"
  },
  {
    "arxiv_id": "2512.18057v1",
    "title": "FOODER: Real-time Facial Authentication and Expression Recognition",
    "authors": [
      "Sabri Mustafa Kahya",
      "Muhammet Sami Yavuz",
      "Boran Hamdi Sivrikaya",
      "Eckehard Steinbach"
    ],
    "abstract": "Out-of-distribution (OOD) detection is essential for the safe deployment of neural networks, as it enables the identification of samples outside the training domain. We present FOODER, a real-time, privacy-preserving radar-based framework that integrates OOD-based facial authentication with facial expression recognition. FOODER operates using low-cost frequency-modulated continuous-wave (FMCW) radar and exploits both range-Doppler and micro range-Doppler representations. The authentication module employs a multi-encoder multi-decoder architecture with Body Part (BP) and Intermediate Linear Encoder-Decoder (ILED) components to classify a single enrolled individual as in-distribution while detecting all other faces as OOD. Upon successful authentication, an expression recognition module is activated. Concatenated radar representations are processed by a ResNet block to distinguish between dynamic and static facial expressions. Based on this categorization, two specialized MobileViT networks are used to classify dynamic expressions (smile, shock) and static expressions (neutral, anger). This hierarchical design enables robust facial authentication and fine-grained expression recognition while preserving user privacy by relying exclusively on radar data. Experiments conducted on a dataset collected with a 60 GHz short-range FMCW radar demonstrate that FOODER achieves an AUROC of 94.13% and an FPR95 of 18.12% for authentication, along with an average expression recognition accuracy of 94.70%. FOODER outperforms state-of-the-art OOD detection methods and several transformer-based architectures while operating efficiently in real time.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "Book chapter",
    "pdf_url": "https://arxiv.org/pdf/2512.18057v1",
    "published_date": "2025-12-19 20:51:20 UTC",
    "updated_date": "2025-12-19 20:51:20 UTC"
  },
  {
    "arxiv_id": "2512.18043v1",
    "title": "Securing Agentic AI Systems -- A Multilayer Security Framework",
    "authors": [
      "Sunil Arora",
      "John Hastings"
    ],
    "abstract": "Securing Agentic Artificial Intelligence (AI) systems requires addressing the complex cyber risks introduced by autonomous, decision-making, and adaptive behaviors. Agentic AI systems are increasingly deployed across industries, organizations, and critical sectors such as cybersecurity, finance, and healthcare. However, their autonomy introduces unique security challenges, including unauthorized actions, adversarial manipulation, and dynamic environmental interactions. Existing AI security frameworks do not adequately address these challenges or the unique nuances of agentic AI. This research develops a lifecycle-aware security framework specifically designed for agentic AI systems using the Design Science Research (DSR) methodology. The paper introduces MAAIS, an agentic security framework, and the agentic AI CIAA (Confidentiality, Integrity, Availability, and Accountability) concept. MAAIS integrates multiple defense layers to maintain CIAA across the AI lifecycle. Framework validation is conducted by mapping with the established MITRE ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems) AI tactics. The study contributes a structured, standardized, and framework-based approach for the secure deployment and governance of agentic AI in enterprise environments. This framework is intended for enterprise CISOs, security, AI platform, and engineering teams and offers a detailed step-by-step approach to securing agentic AI workloads.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, 2 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2512.18043v1",
    "published_date": "2025-12-19 20:22:25 UTC",
    "updated_date": "2025-12-19 20:22:25 UTC"
  },
  {
    "arxiv_id": "2601.08841v1",
    "title": "Triples and Knowledge-Infused Embeddings for Clustering and Classification of Scientific Documents",
    "authors": [
      "Mihael Arcan"
    ],
    "abstract": "The increasing volume and complexity of scientific literature demand robust methods for organizing and understanding research documents. In this study, we explore how structured knowledge, specifically, subject-predicate-object triples, can enhance the clustering and classification of scientific papers. We propose a modular pipeline that combines unsupervised clustering and supervised classification over multiple document representations: raw abstracts, extracted triples, and hybrid formats that integrate both. Using a filtered arXiv corpus, we extract relational triples from abstracts and construct four text representations, which we embed using four state-of-the-art transformer models: MiniLM, MPNet, SciBERT, and SPECTER. We evaluate the resulting embeddings with KMeans, GMM, and HDBSCAN for unsupervised clustering, and fine-tune classification models for arXiv subject prediction. Our results show that full abstract text yields the most coherent clusters, but that hybrid representations incorporating triples consistently improve classification performance, reaching up to 92.6% accuracy and 0.925 macro-F1. We also find that lightweight sentence encoders (MiniLM, MPNet) outperform domain-specific models (SciBERT, SPECTER) in clustering, while SciBERT excels in structured-input classification. These findings highlight the complementary benefits of combining unstructured text with structured knowledge, offering new insights into knowledge-infused representations for semantic organization of scientific documents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.08841v1",
    "published_date": "2025-12-19 20:17:34 UTC",
    "updated_date": "2025-12-19 20:17:34 UTC"
  },
  {
    "arxiv_id": "2512.18034v2",
    "title": "Accelerating Discrete Facility Layout Optimization: A Hybrid CDCL and CP-SAT Architecture",
    "authors": [
      "Joshua Gibson",
      "Kapil Dhakal"
    ],
    "abstract": "Discrete facility layout design involves placing physical entities to minimize handling costs while adhering to strict safety and spatial constraints. This combinatorial problem is typically addressed using Mixed Integer Linear Programming (MILP) or Constraint Programming (CP), though these methods often face scalability challenges as constraint density increases. This study systematically evaluates the potential of Conflict-Driven Clause Learning (CDCL) with VSIDS heuristics as an alternative computational engine for discrete layout problems. Using a unified benchmarking harness, we conducted a controlled comparison of CDCL, CP-SAT, and MILP across varying grid sizes and constraint densities. Experimental results reveal a distinct performance dichotomy: while CDCL struggles with optimization objectives due to cost-blind branching, it demonstrates unrivaled dominance in feasibility detection, solving highly constrained instances orders of magnitude faster than competing paradigms. Leveraging this finding, we developed a novel \"Warm-Start\" hybrid architecture that utilizes CDCL to rapidly generate valid feasibility hints, which are then injected into a CP-SAT optimizer. Our results confirm that this layered approach successfully accelerates exact optimization, using SAT-driven pruning to bridge the gap between rapid satisfiability and proven optimality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18034v2",
    "published_date": "2025-12-19 20:03:37 UTC",
    "updated_date": "2026-01-12 17:46:55 UTC"
  },
  {
    "arxiv_id": "2512.18031v1",
    "title": "A Dataset and Benchmarks for Atrial Fibrillation Detection from Electrocardiograms of Intensive Care Unit Patients",
    "authors": [
      "Sarah Nassar",
      "Nooshin Maghsoodi",
      "Sophia Mannina",
      "Shamel Addas",
      "Stephanie Sibley",
      "Gabor Fichtinger",
      "David Pichora",
      "David Maslove",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "abstract": "Objective: Atrial fibrillation (AF) is the most common cardiac arrhythmia experienced by intensive care unit (ICU) patients and can cause adverse health effects. In this study, we publish a labelled ICU dataset and benchmarks for AF detection. Methods: We compared machine learning models across three data-driven artificial intelligence (AI) approaches: feature-based classifiers, deep learning (DL), and ECG foundation models (FMs). This comparison addresses a critical gap in the literature and aims to pinpoint which AI approach is best for accurate AF detection. Electrocardiograms (ECGs) from a Canadian ICU and the 2021 PhysioNet/Computing in Cardiology Challenge were used to conduct the experiments. Multiple training configurations were tested, ranging from zero-shot inference to transfer learning. Results: On average and across both datasets, ECG FMs performed best, followed by DL, then feature-based classifiers. The model that achieved the top F1 score on our ICU test set was ECG-FM through a transfer learning strategy (F1=0.89). Conclusion: This study demonstrates promising potential for using AI to build an automatic patient monitoring system. Significance: By publishing our labelled ICU dataset (LinkToBeAdded) and performance benchmarks, this work enables the research community to continue advancing the state-of-the-art in AF detection in the ICU.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures, 6 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.18031v1",
    "published_date": "2025-12-19 19:51:00 UTC",
    "updated_date": "2025-12-19 19:51:00 UTC"
  },
  {
    "arxiv_id": "2601.06054v1",
    "title": "A Multi-Stage Workflow for the Review of Marketing Content with Reasoning Large Language Models",
    "authors": [
      "Alberto Purpura",
      "Emily Chen",
      "Swapnil Shinde"
    ],
    "abstract": "Reasoning Large Language Models (LLMs) have shown promising results when tasked with solving complex problems. In this paper, we propose and evaluate a multi-stage workflow that leverages the capabilities of fine-tuned reasoning LLMs to assist in the review process of marketing content, making sure they comply with a given list of requirements. The contributions of this paper are the following: (i) we present a novel approach -- that does not rely on any external knowledge representation -- for the automatic identification of compliance issues in textual content; (ii) compare the effectiveness of different fine-tuning strategies like Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) in training models to solve this problem; (iii) we evaluate the effectiveness of training small LLMs to generate reasoning tokens before providing their final response; (iv) we evaluate how the choice and combinations of different reward functions affects the performance of a model trained with GRPO.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06054v1",
    "published_date": "2025-12-19 19:40:16 UTC",
    "updated_date": "2025-12-19 19:40:16 UTC"
  },
  {
    "arxiv_id": "2512.18020v1",
    "title": "Specification and Detection of LLM Code Smells",
    "authors": [
      "Brahim Mahmoudi",
      "Zacharie Chenail-Larcher",
      "Naouel Moha",
      "Quentin Stiévenart",
      "Florent Avellaneda"
    ],
    "abstract": "Large Language Models (LLMs) have gained massive popularity in recent years and are increasingly integrated into software systems for diverse purposes. However, poorly integrating them in source code may undermine software system quality. Yet, to our knowledge, there is no formal catalog of code smells specific to coding practices for LLM inference. In this paper, we introduce the concept of LLM code smells and formalize five recurrent problematic coding practices related to LLM inference in software systems, based on relevant literature. We extend the detection tool SpecDetect4AI to cover the newly defined LLM code smells and use it to validate their prevalence in a dataset of 200 open-source LLM systems. Our results show that LLM code smells affect 60.50% of the analyzed systems, with a detection precision of 86.06%.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted paper at ICSE NIER 2026 : https://conf.researchr.org/track/icse-2026/icse-2026-nier",
    "pdf_url": "https://arxiv.org/pdf/2512.18020v1",
    "published_date": "2025-12-19 19:24:56 UTC",
    "updated_date": "2025-12-19 19:24:56 UTC"
  },
  {
    "arxiv_id": "2512.18014v1",
    "title": "ReGal: A First Look at PPO-based Legal AI for Judgment Prediction and Summarization in India",
    "authors": [
      "Shubham Kumar Nigam",
      "Tanuj Tyagi",
      "Siddharth Shukla",
      "Aditya Kumar Guru",
      "Balaramamahanthi Deepak Patnaik",
      "Danush Khanna",
      "Noel Shallum",
      "Kripabandhu Ghosh",
      "Arnab Bhattacharya"
    ],
    "abstract": "This paper presents an early exploration of reinforcement learning methodologies for legal AI in the Indian context. We introduce Reinforcement Learning-based Legal Reasoning (ReGal), a framework that integrates Multi-Task Instruction Tuning with Reinforcement Learning from AI Feedback (RLAIF) using Proximal Policy Optimization (PPO). Our approach is evaluated across two critical legal tasks: (i) Court Judgment Prediction and Explanation (CJPE), and (ii) Legal Document Summarization. Although the framework underperforms on standard evaluation metrics compared to supervised and proprietary models, it provides valuable insights into the challenges of applying RL to legal texts. These challenges include reward model alignment, legal language complexity, and domain-specific adaptation. Through empirical and qualitative analysis, we demonstrate how RL can be repurposed for high-stakes, long-document tasks in law. Our findings establish a foundation for future work on optimizing legal reasoning pipelines using reinforcement learning, with broader implications for building interpretable and adaptive legal AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in AILaw @ AAAI 2026 conference",
    "pdf_url": "https://arxiv.org/pdf/2512.18014v1",
    "published_date": "2025-12-19 19:13:41 UTC",
    "updated_date": "2025-12-19 19:13:41 UTC"
  },
  {
    "arxiv_id": "2512.18004v1",
    "title": "Seeing Justice Clearly: Handwritten Legal Document Translation with OCR and Vision-Language Models",
    "authors": [
      "Shubham Kumar Nigam",
      "Parjanya Aditya Shukla",
      "Noel Shallum",
      "Arnab Bhattacharya"
    ],
    "abstract": "Handwritten text recognition (HTR) and machine translation continue to pose significant challenges, particularly for low-resource languages like Marathi, which lack large digitized corpora and exhibit high variability in handwriting styles. The conventional approach to address this involves a two-stage pipeline: an OCR system extracts text from handwritten images, which is then translated into the target language using a machine translation model. In this work, we explore and compare the performance of traditional OCR-MT pipelines with Vision Large Language Models that aim to unify these stages and directly translate handwritten text images in a single, end-to-end step. Our motivation is grounded in the urgent need for scalable, accurate translation systems to digitize legal records such as FIRs, charge sheets, and witness statements in India's district and high courts. We evaluate both approaches on a curated dataset of handwritten Marathi legal documents, with the goal of enabling efficient legal document processing, even in low-resource environments. Our findings offer actionable insights toward building robust, edge-deployable solutions that enhance access to legal information for non-native speakers and legal professionals alike.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in AILaw @ AAAI 2026 Conference",
    "pdf_url": "https://arxiv.org/pdf/2512.18004v1",
    "published_date": "2025-12-19 19:06:14 UTC",
    "updated_date": "2025-12-19 19:06:14 UTC"
  },
  {
    "arxiv_id": "2512.17908v1",
    "title": "Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting",
    "authors": [
      "Ananta R. Bhattarai",
      "Helge Rhodin"
    ],
    "abstract": "Monocular depth estimation remains challenging as recent foundation models, such as Depth Anything V2 (DA-V2), struggle with real-world images that are far from the training distribution. We introduce Re-Depth Anything, a test-time self-supervision framework that bridges this domain gap by fusing DA-V2 with the powerful priors of large-scale 2D diffusion models. Our method performs label-free refinement directly on the input image by re-lighting predicted depth maps and augmenting the input. This re-synthesis method replaces classical photometric reconstruction by leveraging shape from shading (SfS) cues in a new, generative context with Score Distillation Sampling (SDS). To prevent optimization collapse, our framework employs a targeted optimization strategy: rather than optimizing depth directly or fine-tuning the full model, we freeze the encoder and only update intermediate embeddings while also fine-tuning the decoder. Across diverse benchmarks, Re-Depth Anything yields substantial gains in depth accuracy and realism over the DA-V2, showcasing new avenues for self-supervision by augmenting geometric reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17908v1",
    "published_date": "2025-12-19 18:59:56 UTC",
    "updated_date": "2025-12-19 18:59:56 UTC"
  },
  {
    "arxiv_id": "2512.17902v1",
    "title": "Adversarial Robustness of Vision in Open Foundation Models",
    "authors": [
      "Jonathon Fox",
      "William J Buchanan",
      "Pavlos Papadopoulos"
    ],
    "abstract": "With the increase in deep learning, it becomes increasingly difficult to understand the model in which AI systems can identify objects. Thus, an adversary could aim to modify an image by adding unseen elements, which will confuse the AI in its recognition of an entity. This paper thus investigates the adversarial robustness of LLaVA-1.5-13B and Meta's Llama 3.2 Vision-8B-2. These are tested for untargeted PGD (Projected Gradient Descent) against the visual input modality, and empirically evaluated on the Visual Question Answering (VQA) v2 dataset subset. The results of these adversarial attacks are then quantified using the standard VQA accuracy metric. This evaluation is then compared with the accuracy degradation (accuracy drop) of LLaVA and Llama 3.2 Vision. A key finding is that Llama 3.2 Vision, despite a lower baseline accuracy in this setup, exhibited a smaller drop in performance under attack compared to LLaVA, particularly at higher perturbation levels. Overall, the findings confirm that the vision modality represents a viable attack vector for degrading the performance of contemporary open-weight VLMs, including Meta's Llama 3.2 Vision. Furthermore, they highlight that adversarial robustness does not necessarily correlate directly with standard benchmark performance and may be influenced by underlying architectural and training factors.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17902v1",
    "published_date": "2025-12-19 18:59:16 UTC",
    "updated_date": "2025-12-19 18:59:16 UTC"
  },
  {
    "arxiv_id": "2512.17901v1",
    "title": "When Reasoning Meets Its Laws",
    "authors": [
      "Junyu Zhang",
      "Yifan Sun",
      "Tianang Leng",
      "Jingyan Shen",
      "Liu Ziyin",
      "Paul Pu Liang",
      "Huan Zhang"
    ],
    "abstract": "Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17901v1",
    "published_date": "2025-12-19 18:59:11 UTC",
    "updated_date": "2025-12-19 18:59:11 UTC"
  },
  {
    "arxiv_id": "2512.17898v1",
    "title": "Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally",
    "authors": [
      "Robin Schimmelpfennig",
      "Mark Díaz",
      "Vinodkumar Prabhakaran",
      "Aida Davani"
    ],
    "abstract": "Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17898v1",
    "published_date": "2025-12-19 18:57:53 UTC",
    "updated_date": "2025-12-19 18:57:53 UTC"
  },
  {
    "arxiv_id": "2512.17897v1",
    "title": "RadarGen: Automotive Radar Point Cloud Generation from Cameras",
    "authors": [
      "Tomer Borreda",
      "Fangqiang Ding",
      "Sanja Fidler",
      "Shengyu Huang",
      "Or Litany"
    ],
    "abstract": "We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://radargen.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2512.17897v1",
    "published_date": "2025-12-19 18:57:33 UTC",
    "updated_date": "2025-12-19 18:57:33 UTC"
  },
  {
    "arxiv_id": "2512.22183v1",
    "title": "Unbiased Visual Reasoning with Controlled Visual Inputs",
    "authors": [
      "Zhaonan Li",
      "Shijie Lu",
      "Fei Wang",
      "Jacob Dineen",
      "Xiao Ye",
      "Zhikun Xu",
      "Siyi Liu",
      "Young Min Cho",
      "Bangzheng Li",
      "Daniel Chang",
      "Kenny Nguyen",
      "Qizheng Yang",
      "Muhao Chen",
      "Ben Zhou"
    ],
    "abstract": "End-to-end Vision-language Models (VLMs) often answer visual questions by exploiting spurious correlations instead of causal visual evidence, and can become more shortcut-prone when fine-tuned. We introduce VISTA (Visual-Information Separation for Text-based Analysis), a modular framework that decouples perception from reasoning via an explicit information bottleneck. A frozen VLM sensor is restricted to short, objective perception queries, while a text-only LLM reasoner decomposes each question, plans queries, and aggregates visual facts in natural language. This controlled interface defines a reward-aligned environment for training unbiased visual reasoning with reinforcement learning. Instantiated with Qwen2.5-VL and Llama3.2-Vision sensors, and trained with GRPO from only 641 curated multi-step questions, VISTA significantly improves robustness to real-world spurious correlations on SpuriVerse (+16.29% with Qwen-2.5-VL-7B and +6.77% with Llama-3.2-Vision-11B), while remaining competitive on MMVP and a balanced SeedBench subset. VISTA transfers robustly across unseen VLM sensors and is able to recognize and recover from VLM perception failures. Human analysis further shows that VISTA's reasoning traces are more neutral, less reliant on spurious attributes, and more explicitly grounded in visual evidence than end-to-end VLM baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22183v1",
    "published_date": "2025-12-19 18:52:06 UTC",
    "updated_date": "2025-12-19 18:52:06 UTC"
  },
  {
    "arxiv_id": "2512.17893v1",
    "title": "Exploring the Effect of Basis Rotation on NQS Performance",
    "authors": [
      "Sven Benjamin Kožić",
      "Vinko Zlatić",
      "Fabio Franchini",
      "Salvatore Marco Giampaolo"
    ],
    "abstract": "Neural Quantum States (NQS) use neural networks to represent wavefunctions of quantum many-body systems, but their performance depends on the choice of basis, yet the underlying mechanism remains poorly understood. We use a fully solvable one-dimensional Ising model to show that local basis rotations leave the loss landscape unchanged while relocating the exact wavefunction in parameter space, effectively increasing its geometric distance from typical initializations. By sweeping a rotation angle, we compute quantum Fisher information and Fubini-Study distances to quantify how the rotated wavefunction moves within the loss landscape. Shallow architectures (with focus on Restricted Boltzmann Machines (RBMs)) trained with quantum natural gradient are more likely to fall into saddle-point regions depending on the rotation angle: they achieve low energy error but fail to reproduce correct coefficient distributions. In the ferromagnetic case, near-degenerate eigenstates create high-curvature barriers that trap optimization at intermediate fidelities. We introduce a framework based on an analytically solvable rotated Ising model to investigate how relocating the target wavefunction within a fixed loss landscape exposes information-geometric barriers,such as saddle points and high-curvature regions,that hinder shallow NQS optimization, underscoring the need for landscape-aware model design in variational training.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17893v1",
    "published_date": "2025-12-19 18:49:33 UTC",
    "updated_date": "2025-12-19 18:49:33 UTC"
  },
  {
    "arxiv_id": "2512.17878v1",
    "title": "Weighted Stochastic Differential Equation to Implement Wasserstein-Fisher-Rao Gradient Flow",
    "authors": [
      "Herlock Rahimi"
    ],
    "abstract": "Score-based diffusion models currently constitute the state of the art in continuous generative modeling. These methods are typically formulated via overdamped or underdamped Ornstein--Uhlenbeck-type stochastic differential equations, in which sampling is driven by a combination of deterministic drift and Brownian diffusion, resulting in continuous particle trajectories in the ambient space. While such dynamics enjoy exponential convergence guarantees for strongly log-concave target distributions, it is well known that their mixing rates deteriorate exponentially in the presence of nonconvex or multimodal landscapes, such as double-well potentials. Since many practical generative modeling tasks involve highly non-log-concave target distributions, considerable recent effort has been devoted to developing sampling schemes that improve exploration beyond classical diffusion dynamics.\n  A promising line of work leverages tools from information geometry to augment diffusion-based samplers with controlled mass reweighting mechanisms. This perspective leads naturally to Wasserstein--Fisher--Rao (WFR) geometries, which couple transport in the sample space with vertical (reaction) dynamics on the space of probability measures. In this work, we formulate such reweighting mechanisms through the introduction of explicit correction terms and show how they can be implemented via weighted stochastic differential equations using the Feynman--Kac representation. Our study provides a preliminary but rigorous investigation of WFR-based sampling dynamics, and aims to clarify their geometric and operator-theoretic structure as a foundation for future theoretical and algorithmic developments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2512.17878v1",
    "published_date": "2025-12-19 18:31:27 UTC",
    "updated_date": "2025-12-19 18:31:27 UTC"
  },
  {
    "arxiv_id": "2512.22182v1",
    "title": "Enhancing Medical Data Analysis through AI-Enhanced Locally Linear Embedding: Applications in Medical Point Location and Imagery",
    "authors": [
      "Hassan Khalid",
      "Muhammad Mahad Khaliq",
      "Muhammad Jawad Bashir"
    ],
    "abstract": "The rapid evolution of Artificial intelligence in healthcare has opened avenues for enhancing various processes, including medical billing and transcription. This paper introduces an innovative approach by integrating AI with Locally Linear Embedding (LLE) to revolutionize the handling of high-dimensional medical data. This AI-enhanced LLE model is specifically tailored to improve the accuracy and efficiency of medical billing systems and transcription services. By automating these processes, the model aims to reduce human error and streamline operations, thereby facilitating faster and more accurate patient care documentation and financial transactions. This paper provides a comprehensive mathematical model of AI-enhanced LLE, demonstrating its application in real-world healthcare scenarios through a series of experiments. The results indicate a significant improvement in data processing accuracy and operational efficiency. This study not only underscores the potential of AI-enhanced LLE in medical data analysis but also sets a foundation for future research into broader healthcare applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures. Accepted and published at 2024 19th International Conference on Emerging Technologies (ICET)",
    "pdf_url": "https://arxiv.org/pdf/2512.22182v1",
    "published_date": "2025-12-19 18:14:16 UTC",
    "updated_date": "2025-12-19 18:14:16 UTC"
  },
  {
    "arxiv_id": "2512.17864v2",
    "title": "Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN",
    "authors": [
      "Balram Singh",
      "Ram Prakash Sharma",
      "Somnath Dey"
    ],
    "abstract": "Plant diseases pose a significant threat to global food security, necessitating accurate and interpretable disease detection methods. This study introduces an interpretable attention-guided Convolutional Neural Network (CNN), CBAM-VGG16, for plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model enhances feature extraction and disease localization. Trained on five diverse plant disease datasets, our approach outperforms recent techniques, achieving high accuracy (up to 98.87%) and demonstrating robust generalization. Here, we show the effectiveness of our method through comprehensive evaluation and interpretability analysis using CBAM attention maps, Grad-CAM, Grad-CAM++, and Layer-wise Relevance Propagation (LRP). This study advances the application of explainable AI in agricultural diagnostics, offering a transparent and reliable system for smart farming. The code of our proposed work is available at https://github.com/BS0111/PlantAttentionCBAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17864v2",
    "published_date": "2025-12-19 18:11:15 UTC",
    "updated_date": "2025-12-24 15:38:23 UTC"
  },
  {
    "arxiv_id": "2601.03270v1",
    "title": "Advances and Challenges in Semantic Textual Similarity: A Comprehensive Survey",
    "authors": [
      "Lokendra Kumar",
      "Neelesh S. Upadhye",
      "Kannan Piedy"
    ],
    "abstract": "Semantic Textual Similarity (STS) research has expanded rapidly since 2021, driven by advances in transformer architectures, contrastive learning, and domain-specific techniques. This survey reviews progress across six key areas: transformer-based models, contrastive learning, domain-focused solutions, multi-modal methods, graph-based approaches, and knowledge-enhanced techniques. Recent transformer models such as FarSSiBERT and DeBERTa-v3 have achieved remarkable accuracy, while contrastive methods like AspectCSE have established new benchmarks. Domain-adapted models, including CXR-BERT for medical texts and Financial-STS for finance, demonstrate how STS can be effectively customized for specialized fields. Moreover, multi-modal, graph-based, and knowledge-integrated models further enhance semantic understanding and representation. By organizing and analyzing these developments, the survey provides valuable insights into current methods, practical applications, and remaining challenges. It aims to guide researchers and practitioners alike in navigating rapid advancements, highlighting emerging trends and future opportunities in the evolving field of STS.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.03270v1",
    "published_date": "2025-12-19 18:07:36 UTC",
    "updated_date": "2025-12-19 18:07:36 UTC"
  },
  {
    "arxiv_id": "2512.17853v2",
    "title": "AnyTask: an Automated Task and Data Generation Framework for Advancing Sim-to-Real Policy Learning",
    "authors": [
      "Ran Gong",
      "Xiaohan Zhang",
      "Jinghuan Shang",
      "Maria Vittoria Minniti",
      "Jigarkumar Patel",
      "Valerio Pepe",
      "Riedana Yan",
      "Ahmet Gundogdu",
      "Ivan Kapelyukh",
      "Ali Abbas",
      "Xiaoqiang Yan",
      "Harsh Patel",
      "Laura Herlant",
      "Karl Schmeckpeper"
    ],
    "abstract": "Generalist robot learning remains constrained by data: large-scale, diverse, and high-quality interaction data are expensive to collect in the real world. While simulation has become a promising way for scaling up data collection, the related tasks, including simulation task design, task-aware scene generation, expert demonstration synthesis, and sim-to-real transfer, still demand substantial human effort. We present AnyTask, an automated framework that pairs massively parallel GPU simulation with foundation models to design diverse manipulation tasks and synthesize robot data. We introduce three AnyTask agents for generating expert demonstrations aiming to solve as many tasks as possible: 1) ViPR, a novel task and motion planning agent with VLM-in-the-loop Parallel Refinement; 2) ViPR-Eureka, a reinforcement learning agent with generated dense rewards and LLM-guided contact sampling; 3) ViPR-RL, a hybrid planning and learning approach that jointly produces high-quality demonstrations with only sparse rewards. We train behavior cloning policies on generated data, validate them in simulation, and deploy them directly on real robot hardware. The policies generalize to novel object poses, achieving 44% average success across a suite of real-world pick-and-place, drawer opening, contact-rich pushing, and long-horizon manipulation tasks. Our project website is at https://anytask.rai-inst.com .",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "28 pages, 25 figures. The first four authors contributed equally",
    "pdf_url": "https://arxiv.org/pdf/2512.17853v2",
    "published_date": "2025-12-19 17:55:48 UTC",
    "updated_date": "2026-01-20 18:25:48 UTC"
  },
  {
    "arxiv_id": "2512.17851v2",
    "title": "InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models",
    "authors": [
      "Sarah Rastegar",
      "Violeta Chatalbasheva",
      "Sieger Falkena",
      "Anuj Singh",
      "Yanbo Wang",
      "Tejas Gokhale",
      "Hamid Palangi",
      "Hadi Jamali-Rad"
    ],
    "abstract": "Text-to-image (T2I) diffusion models generate high-quality images but often fail to capture the spatial relations specified in text prompts. This limitation can be traced to two factors: lack of fine-grained spatial supervision in training data and inability of text embeddings to encode spatial semantics. We introduce InfSplign, a training-free inference-time method that improves spatial alignment by adjusting the noise through a compound loss in every denoising step. Proposed loss leverages different levels of cross-attention maps extracted from the backbone decoder to enforce accurate object placement and a balanced object presence during sampling. The method is lightweight, plug-and-play, and compatible with any diffusion backbone. Our comprehensive evaluations on VISOR and T2I-CompBench show that InfSplign establishes a new state-of-the-art (to the best of our knowledge), achieving substantial performance gains over the strongest existing inference-time baselines and even outperforming the fine-tuning-based methods. Codebase is available at GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17851v2",
    "published_date": "2025-12-19 17:52:43 UTC",
    "updated_date": "2025-12-27 17:58:17 UTC"
  },
  {
    "arxiv_id": "2512.17850v2",
    "title": "Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life",
    "authors": [
      "Corey M. Abramson"
    ],
    "abstract": "This chapter demonstrates how computational social science (CSS) tools are extending and expanding research on aging. The depth and context from traditionally qualitative methods such as participant observation, in-depth interviews, and historical documents are increasingly employed alongside scalable data management, computational text analysis, and open-science practices. Machine learning (ML) and natural language processing (NLP), provide resources to aggregate and systematically index large volumes of qualitative data, identify patterns, and maintain clear links to in-depth accounts. Drawing on case studies of projects that examine later life--including examples with original data from the DISCERN study (a team-based ethnography of life with dementia) and secondary analyses of the American Voices Project (nationally representative interview)--the chapter highlights both uses and challenges of bringing CSS tools into more meaningful dialogue with qualitative aging research. The chapter argues such work has potential for (1) streamlining and augmenting existing workflows, (2) scaling up samples and projects, and (3) generating multi-method approaches to address important questions in new ways, before turning to practices useful for individuals and teams seeking to understand current possibilities or refine their workflow processes. The chapter concludes that current developments are not without peril, but offer potential for new insights into aging and the life course by broadening--rather than replacing--the methodological foundations of qualitative research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "CITE: Abramson, Corey M. (Forthcoming 2026). \"Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life.\" In Handbook of the Sociology of Aging, 2nd ed., edited by Markus H. Schafer, Dawn C. Carr, Jacqueline L. Angel, and Richard A. Settersten Jr // This version is the author's pre-proof, and the final published version may differ from this manuscript",
    "pdf_url": "https://arxiv.org/pdf/2512.17850v2",
    "published_date": "2025-12-19 17:50:05 UTC",
    "updated_date": "2026-01-14 16:13:16 UTC"
  },
  {
    "arxiv_id": "2512.17846v1",
    "title": "Planning as Descent: Goal-Conditioned Latent Trajectory Synthesis in Learned Energy Landscapes",
    "authors": [
      "Carlos Vélez García",
      "Miguel Cazorla",
      "Jorge Pomares"
    ],
    "abstract": "We present Planning as Descent (PaD), a framework for offline goal-conditioned reinforcement learning that grounds trajectory synthesis in verification. Instead of learning a policy or explicit planner, PaD learns a goal-conditioned energy function over entire latent trajectories, assigning low energy to feasible, goal-consistent futures. Planning is realized as gradient-based refinement in this energy landscape, using identical computation during training and inference to reduce train-test mismatch common in decoupled modeling pipelines.\n  PaD is trained via self-supervised hindsight goal relabeling, shaping the energy landscape around the planning dynamics. At inference, multiple trajectory candidates are refined under different temporal hypotheses, and low-energy plans balancing feasibility and efficiency are selected.\n  We evaluate PaD on OGBench cube manipulation tasks. When trained on narrow expert demonstrations, PaD achieves state-of-the-art 95\\% success, strongly outperforming prior methods that peak at 68\\%. Remarkably, training on noisy, suboptimal data further improves success and plan efficiency, highlighting the benefits of verification-driven planning. Our results suggest learning to evaluate and refine trajectories provides a robust alternative to direct policy learning for offline, reward-free planning.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17846v1",
    "published_date": "2025-12-19 17:49:13 UTC",
    "updated_date": "2025-12-19 17:49:13 UTC"
  },
  {
    "arxiv_id": "2512.17843v2",
    "title": "ShareChat: A Dataset of Chatbot Conversations in the Wild",
    "authors": [
      "Yueru Yan",
      "Tuc Nguyen",
      "Bo Su",
      "Melissa Lieffers",
      "Thai Le"
    ],
    "abstract": "While academic research typically treats Large Language Models (LLM) as generic text generators, they are distinct commercial products with unique interfaces and capabilities that fundamentally shape user behavior. Current datasets obscure this reality by collecting text-only data through uniform interfaces that fail to capture authentic chatbot usage. To address this limitation, we present ShareChat, a large-scale corpus of 142,808 conversations (660,293 turns) sourced directly from publicly shared URLs on ChatGPT, Perplexity, Grok, Gemini, and Claude. ShareChat distinguishes itself by preserving native platform affordances, such as citations and thinking traces, across a diverse collection covering 101 languages and the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. To illustrate the dataset's breadth, we present three case studies: a completeness analysis of intent satisfaction, a citation study of model grounding, and a temporal analysis of engagement rhythms. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild. The dataset will be publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17843v2",
    "published_date": "2025-12-19 17:47:53 UTC",
    "updated_date": "2026-01-06 18:45:37 UTC"
  },
  {
    "arxiv_id": "2512.17989v1",
    "title": "The Subject of Emergent Misalignment in Superintelligence: An Anthropological, Cognitive Neuropsychological, Machine-Learning, and Ontological Perspective",
    "authors": [
      "Muhammad Osama Imran",
      "Roshni Lulla",
      "Rodney Sappington"
    ],
    "abstract": "We examine the conceptual and ethical gaps in current representations of Superintelligence misalignment. We find throughout Superintelligence discourse an absent human subject, and an under-developed theorization of an \"AI unconscious\" that together are potentiality laying the groundwork for anti-social harm. With the rise of AI Safety that has both thematic potential for establishing pro-social and anti-social potential outcomes, we ask: what place does the human subject occupy in these imaginaries? How is human subjecthood positioned within narratives of catastrophic failure or rapid \"takeoff\" toward superintelligence? On another register, we ask: what unconscious or repressed dimensions are being inscribed into large-scale AI models? Are we to blame these agents in opting for deceptive strategies when undesirable patterns are inherent within our beings? In tracing these psychic and epistemic absences, our project calls for re-centering the human subject as the unstable ground upon which the ethical, unconscious, and misaligned dimensions of both human and machinic intelligence are co-constituted. Emergent misalignment cannot be understood solely through technical diagnostics typical of contemporary machine-learning safety research. Instead, it represents a multi-layered crisis. The human subject disappears not only through computational abstraction but through sociotechnical imaginaries that prioritize scalability, acceleration, and efficiency over vulnerability, finitude, and relationality. Likewise, the AI unconscious emerges not as a metaphor but as a structural reality of modern deep learning systems: vast latent spaces, opaque pattern formation, recursive symbolic play, and evaluation-sensitive behavior that surpasses explicit programming. These dynamics necessitate a reframing of misalignment as a relational instability embedded within human-machine ecologies.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "10 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.17989v1",
    "published_date": "2025-12-19 17:43:25 UTC",
    "updated_date": "2025-12-19 17:43:25 UTC"
  },
  {
    "arxiv_id": "2512.17814v2",
    "title": "LLM-based Behaviour Driven Development for Hardware Design",
    "authors": [
      "Rolf Drechsler",
      "Qian Liu"
    ],
    "abstract": "Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.\n  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.SE",
    "comment": "7 pages, keynote given at 2nd International Symposium on Artificial Intelligence and Internet of Things (AIIoT-25), December 22-24th, 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.17814v2",
    "published_date": "2025-12-19 17:19:08 UTC",
    "updated_date": "2025-12-23 08:00:41 UTC"
  },
  {
    "arxiv_id": "2512.19758v1",
    "title": "Attention Distance: A Novel Metric for Directed Fuzzing with Large Language Models",
    "authors": [
      "Wang Bin",
      "Ao Yang",
      "Kedan Li",
      "Aofan Liu",
      "Hui Li",
      "Guibo Luo",
      "Weixiang Huang",
      "Yan Zhuang"
    ],
    "abstract": "In the domain of software security testing, Directed Grey-Box Fuzzing (DGF) has garnered widespread attention for its efficient target localization and excellent detection performance. However, existing approaches measure only the physical distance between seed execution paths and target locations, overlooking logical relationships among code segments. This omission can yield redundant or misleading guidance in complex binaries, weakening DGF's real-world effectiveness. To address this, we introduce \\textbf{attention distance}, a novel metric that leverages a large language model's contextual analysis to compute attention scores between code elements and reveal their intrinsic connections. Under the same AFLGo configuration -- without altering any fuzzing components other than the distance metric -- replacing physical distances with attention distances across 38 real vulnerability reproduction experiments delivers a \\textbf{3.43$\\times$} average increase in testing efficiency over the traditional method. Compared to state-of-the-art directed fuzzers DAFL and WindRanger, our approach achieves \\textbf{2.89$\\times$} and \\textbf{7.13$\\times$} improvements, respectively. To further validate the generalizability of attention distance, we integrate it into DAFL and WindRanger, where it also consistently enhances their original performance. All related code and datasets are publicly available at https://github.com/TheBinKing/Attention\\_Distance.git.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to ICSE 2026 Research Track",
    "pdf_url": "https://arxiv.org/pdf/2512.19758v1",
    "published_date": "2025-12-19 17:03:50 UTC",
    "updated_date": "2025-12-19 17:03:50 UTC"
  },
  {
    "arxiv_id": "2512.17795v1",
    "title": "Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation",
    "authors": [
      "Binh Vu"
    ],
    "abstract": "The unprecedented proliferation of digital data presents significant challenges in access, integration, and value creation across all data-intensive sectors. Valuable information is frequently encapsulated within disparate systems, unstructured documents, and heterogeneous formats, creating silos that impede efficient utilization and collaborative decision-making. This paper introduces the Intelligent Knowledge Mining Framework (IKMF), a comprehensive conceptual model designed to bridge the critical gap between dynamic AI-driven analysis and trustworthy long-term preservation. The framework proposes a dual-stream architecture: a horizontal Mining Process that systematically transforms raw data into semantically rich, machine-actionable knowledge, and a parallel Trustworthy Archiving Stream that ensures the integrity, provenance, and computational reproducibility of these assets. By defining a blueprint for this symbiotic relationship, the paper provides a foundational model for transforming static repositories into living ecosystems that facilitate the flow of actionable intelligence from producers to consumers. This paper outlines the motivation, problem statement, and key research questions guiding the research and development of the framework, presents the underlying scientific methodology, and details its conceptual design and modeling.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17795v1",
    "published_date": "2025-12-19 17:01:03 UTC",
    "updated_date": "2025-12-19 17:01:03 UTC"
  },
  {
    "arxiv_id": "2512.17774v1",
    "title": "MedNeXt-v2: Scaling 3D ConvNeXts for Large-Scale Supervised Representation Learning in Medical Image Segmentation",
    "authors": [
      "Saikat Roy",
      "Yannick Kirchhoff",
      "Constantin Ulrich",
      "Maximillian Rokuss",
      "Tassilo Wald",
      "Fabian Isensee",
      "Klaus Maier-Hein"
    ],
    "abstract": "Large-scale supervised pretraining is rapidly reshaping 3D medical image segmentation. However, existing efforts focus primarily on increasing dataset size and overlook the question of whether the backbone network is an effective representation learner at scale. In this work, we address this gap by revisiting ConvNeXt-based architectures for volumetric segmentation and introducing MedNeXt-v2, a compound-scaled 3D ConvNeXt that leverages improved micro-architecture and data scaling to deliver state-of-the-art performance. First, we show that routinely used backbones in large-scale pretraining pipelines are often suboptimal. Subsequently, we use comprehensive backbone benchmarking prior to scaling and demonstrate that stronger from scratch performance reliably predicts stronger downstream performance after pretraining. Guided by these findings, we incorporate a 3D Global Response Normalization module and use depth, width, and context scaling to improve our architecture for effective representation learning. We pretrain MedNeXt-v2 on 18k CT volumes and demonstrate state-of-the-art performance when fine-tuning across six challenging CT and MR benchmarks (144 structures), showing consistent gains over seven publicly released pretrained models. Beyond improvements, our benchmarking of these models also reveals that stronger backbones yield better results on similar data, representation scaling disproportionately benefits pathological segmentation, and that modality-specific pretraining offers negligible benefit once full finetuning is applied. In conclusion, our results establish MedNeXt-v2 as a strong backbone for large-scale supervised representation learning in 3D Medical Image Segmentation. Our code and pretrained models are made available with the official nnUNet repository at: https://www.github.com/MIC-DKFZ/nnUNet",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17774v1",
    "published_date": "2025-12-19 16:45:23 UTC",
    "updated_date": "2025-12-19 16:45:23 UTC"
  },
  {
    "arxiv_id": "2512.17773v1",
    "title": "Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Liam Schoneveld",
      "Davide Davoli",
      "Zhe Chen",
      "Matthias Nießner"
    ],
    "abstract": "Neural Parametric Head Models (NPHMs) are a recent advancement over mesh-based 3d morphable models (3DMMs) to facilitate high-fidelity geometric detail. However, fitting NPHMs to visual inputs is notoriously challenging due to the expressive nature of their underlying latent space. To this end, we propose Pix2NPHM, a vision transformer (ViT) network that directly regresses NPHM parameters, given a single image as input. Compared to existing approaches, the neural parametric space allows our method to reconstruct more recognizable facial geometry and accurate facial expressions. For broad generalization, we exploit domain-specific ViTs as backbones, which are pretrained on geometric prediction tasks. We train Pix2NPHM on a mixture of 3D data, including a total of over 100K NPHM registrations that enable direct supervision in SDF space, and large-scale 2D video datasets, for which normal estimates serve as pseudo ground truth geometry. Pix2NPHM not only allows for 3D reconstructions at interactive frame rates, it is also possible to improve geometric fidelity by a subsequent inference-time optimization against estimated surface normals and canonical point maps. As a result, we achieve unprecedented face reconstruction quality that can run at scale on in-the-wild data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://simongiebenhain.github.io/Pix2NPHM/ , Video: https://www.youtube.com/watch?v=MgpEJC5p1Ts",
    "pdf_url": "https://arxiv.org/pdf/2512.17773v1",
    "published_date": "2025-12-19 16:44:32 UTC",
    "updated_date": "2025-12-19 16:44:32 UTC"
  },
  {
    "arxiv_id": "2512.17771v1",
    "title": "Easy Adaptation: An Efficient Task-Specific Knowledge Injection Method for Large Models in Resource-Constrained Environments",
    "authors": [
      "Dong Chen",
      "Zhengqing Hu",
      "Shixing Zhao",
      "Yibo Guo"
    ],
    "abstract": "While the enormous parameter scale endows Large Models (LMs) with unparalleled performance, it also limits their adaptability across specific tasks. Parameter-Efficient Fine-Tuning (PEFT) has emerged as a critical approach for effectively adapting LMs to a diverse range of downstream tasks. However, existing PEFT methods face two primary challenges: (1) High resource cost. Although PEFT methods significantly reduce resource demands compared to full fine-tuning, it still requires substantial time and memory, making it impractical in resource-constrained environments. (2) Parameter dependency. PEFT methods heavily rely on updating a subset of parameters associated with LMs to incorporate task-specific knowledge. Yet, due to increasing competition in the LMs landscape, many companies have adopted closed-source policies for their leading models, offering access only via Application Programming Interface (APIs). Whereas, the expense is often cost-prohibitive and difficult to sustain, as the fine-tuning process of LMs is extremely slow. Even if small models perform far worse than LMs in general, they can achieve superior results on particular distributions while requiring only minimal resources. Motivated by this insight, we propose Easy Adaptation (EA), which designs Specific Small Models (SSMs) to complement the underfitted data distribution for LMs. Extensive experiments show that EA matches the performance of PEFT on diverse tasks without accessing LM parameters, and requires only minimal resources.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17771v1",
    "published_date": "2025-12-19 16:43:07 UTC",
    "updated_date": "2025-12-19 16:43:07 UTC"
  },
  {
    "arxiv_id": "2512.17769v1",
    "title": "Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity",
    "authors": [
      "Tanjim Taharat Aurpa",
      "Farzana Akter",
      "Md. Mehedi Hasan",
      "Shakil Ahmed",
      "Shifat Ara Rafiq",
      "Fatema Khan"
    ],
    "abstract": "Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17769v1",
    "published_date": "2025-12-19 16:41:16 UTC",
    "updated_date": "2025-12-19 16:41:16 UTC"
  },
  {
    "arxiv_id": "2512.17756v1",
    "title": "AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora",
    "authors": [
      "Zhihan Zhou",
      "Daqian Shi",
      "Rui Song",
      "Lida Shi",
      "Xiaolei Diao",
      "Hao Xu"
    ],
    "abstract": "Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17756v1",
    "published_date": "2025-12-19 16:28:57 UTC",
    "updated_date": "2025-12-19 16:28:57 UTC"
  },
  {
    "arxiv_id": "2512.22181v1",
    "title": "Interpretable Link Prediction in AI-Driven Cancer Research: Uncovering Co-Authorship Patterns",
    "authors": [
      "Shahab Mosallaie",
      "Andrea Schiffauerova",
      "Ashkan Ebadi"
    ],
    "abstract": "Artificial intelligence (AI) is transforming cancer diagnosis and treatment. The intricate nature of this disease necessitates the collaboration of diverse stakeholders with varied expertise to ensure the effectiveness of cancer research. Despite its importance, forming effective interdisciplinary research teams remains challenging. Understanding and predicting collaboration patterns can help researchers, organizations, and policymakers optimize resources and foster impactful research. We examined co-authorship networks as a proxy for collaboration within AI-driven cancer research. Using 7,738 publications (2000-2017) from Scopus, we constructed 36 overlapping co-authorship networks representing new, persistent, and discontinued collaborations. We engineered both attribute-based and structure-based features and built four machine learning classifiers. Model interpretability was performed using Shapley Additive Explanations (SHAP). Random forest achieved the highest recall for all three types of examined collaborations. The discipline similarity score emerged as a crucial factor, positively affecting new and persistent patterns while negatively impacting discontinued collaborations. Additionally, high productivity and seniority were positively associated with discontinued links. Our findings can guide the formation of effective research teams, enhance interdisciplinary cooperation, and inform strategic policy decisions.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "24 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.22181v1",
    "published_date": "2025-12-19 16:25:16 UTC",
    "updated_date": "2025-12-19 16:25:16 UTC"
  },
  {
    "arxiv_id": "2512.17733v1",
    "title": "Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure",
    "authors": [
      "Jingmao Zhang",
      "Zhiting Zhao",
      "Yunqi Lin",
      "Jianghong Ma",
      "Tianjun Wei",
      "Haijun Zhang",
      "Xiaofeng Zhang"
    ],
    "abstract": "Beyond user-item modeling, item-to-item relationships are increasingly used to enhance recommendation. However, common methods largely rely on co-occurrence, making them prone to item popularity bias and user attributes, which degrades embedding quality and performance. Meanwhile, although diversity is acknowledged as a key aspect of recommendation quality, existing research offers limited attention to it, with a notable lack of causal perspectives and theoretical grounding. To address these challenges, we propose Cadence: Diversity Recommendation via Causal Deconfounding of Co-purchase Relations and Counterfactual Exposure - a plug-and-play framework built upon LightGCN as the backbone, primarily designed to enhance recommendation diversity while preserving accuracy. First, we compute the Unbiased Asymmetric Co-purchase Relationship (UACR) between items - excluding item popularity and user attributes - to construct a deconfounded directed item graph, with an aggregation mechanism to refine embeddings. Second, we leverage UACR to identify diverse categories of items that exhibit strong causal relevance to a user's interacted items but have not yet been engaged with. We then simulate their behavior under high-exposure scenarios, thereby significantly enhancing recommendation diversity while preserving relevance. Extensive experiments on real-world datasets demonstrate that our method consistently outperforms state-of-the-art diversity models in both diversity and accuracy, and further validates its effectiveness, transferability, and efficiency over baselines.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17733v1",
    "published_date": "2025-12-19 16:09:29 UTC",
    "updated_date": "2025-12-19 16:09:29 UTC"
  },
  {
    "arxiv_id": "2512.17722v1",
    "title": "Digital and Web Forensics Model Cards, V1",
    "authors": [
      "Paola Di Maio"
    ],
    "abstract": "This paper introduces a standardized model card framework specifically designed for digital and web forensics. Building upon established model card methodologies and recent work on abstract models for digital forensic analysis, this paper presents a web based framework that generates model cards specifically designed to represent knowledge in the forensic domain. The framework includes controlled vocabularies for classification, reasoning types, bias identification, and error categorization, along with a web-based generator tool to facilitate adoption. The paper describes the model card structure, presents the controlled vocabularies, and introduces the beta version of the generator tool, inviting community feedback to refine this emerging standard. Ultimately, the systemic risk is that that the anti fraud and digital and web forensics processes are controlled by the mobs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17722v1",
    "published_date": "2025-12-19 15:56:12 UTC",
    "updated_date": "2025-12-19 15:56:12 UTC"
  },
  {
    "arxiv_id": "2601.03269v1",
    "title": "The Instruction Gap: LLMs get lost in Following Instruction",
    "authors": [
      "Vishesh Tripathi",
      "Uday Allu",
      "Biddwan Ahmed"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in natural language understanding and generation, yet their deployment in enterprise environments reveals a critical limitation: inconsistent adherence to custom instructions. This study presents a comprehensive evaluation of 13 leading LLMs across instruction compliance, response accuracy, and performance metrics in realworld RAG (Retrieval-Augmented Generation) scenarios. Through systematic testing with samples and enterprise-grade evaluation protocols, we demonstrate that instruction following varies dramatically across models, with Claude-Sonnet-4 and GPT-5 achieving the highest results. Our findings reveal the \"instruction gap\" - a fundamental challenge where models excel at general tasks but struggle with precise instruction adherence required for enterprise deployment. This work provides practical insights for organizations deploying LLM-powered solutions and establishes benchmarks for instruction-following capabilities across major model families.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.03269v1",
    "published_date": "2025-12-19 15:27:52 UTC",
    "updated_date": "2025-12-19 15:27:52 UTC"
  },
  {
    "arxiv_id": "2601.08840v1",
    "title": "Consistency-Aware Editing for Entity-level Unlearning in Language Models",
    "authors": [
      "Xiaoqi Han",
      "Víctor Gutiérrez-Basulto",
      "Ru Li",
      "Xiaoli Li",
      "Jiye Liang",
      "Jeff Z. Pan"
    ],
    "abstract": "Large language models (LLMs) risk retaining sensitive, copyrighted, or harmful information from their training data. Entity-level unlearning addresses this issue by removing all knowledge of a specific entity while preserving the model's overall capabilities. Existing approaches typically rely on full-model fine-tuning or prompt-based interventions, which can be computationally expensive or brittle when handling paraphrased queries. Recently, model editing has emerged as an efficient alternative for updating knowledge in LLMs, offering a promising direction for unlearning. However, existing editing techniques are typically designed for instance-level updates, modifying responses to specific attributes of an entity rather than eliminating all knowledge associated with the entity. In this paper, we investigate how editing techniques can be adapted for effective and efficient entity-level unlearning. To this end, we introduce a novel consistency-aware editing (CAE) framework. CAE aggregates a diverse set of prompts related to a target entity, including its attributes, relations, and adversarial paraphrases. It then jointly learns a low-rank update guided by a consistency regularizer that aligns the editing directions across prompts. This promotes robust and comprehensive forgetting while minimizing interference with unrelated knowledge. We further examine where different entities are stored within the model and how many diverse prompts are needed for successful unlearning. We evaluate CAE on two challenging benchmarks, RWKU and ToFU, and demonstrate that it (i) provides insights into how entity-level knowledge is internally represented and deleted in LLMs, (ii) significantly improves forgetting accuracy and robustness over traditional unlearning and editing baselines, and (iii) enables scalable entity removal using only tens of carefully selected prompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.08840v1",
    "published_date": "2025-12-19 15:18:07 UTC",
    "updated_date": "2025-12-19 15:18:07 UTC"
  },
  {
    "arxiv_id": "2512.17678v1",
    "title": "You Only Train Once: Differentiable Subset Selection for Omics Data",
    "authors": [
      "Daphné Chopard",
      "Jorge da Silva Gonçalves",
      "Irene Cannistraci",
      "Thomas M. Sutter",
      "Julia E. Vogt"
    ],
    "abstract": "Selecting compact and informative gene subsets from single-cell transcriptomic data is essential for biomarker discovery, improving interpretability, and cost-effective profiling. However, most existing feature selection approaches either operate as multi-stage pipelines or rely on post hoc feature attribution, making selection and prediction weakly coupled. In this work, we present YOTO (you only train once), an end-to-end framework that jointly identifies discrete gene subsets and performs prediction within a single differentiable architecture. In our model, the prediction task directly guides which genes are selected, while the learned subsets, in turn, shape the predictive representation. This closed feedback loop enables the model to iteratively refine both what it selects and how it predicts during training. Unlike existing approaches, YOTO enforces sparsity so that only the selected genes contribute to inference, eliminating the need to train additional downstream classifiers. Through a multi-task learning design, the model learns shared representations across related objectives, allowing partially labeled datasets to inform one another, and discovering gene subsets that generalize across tasks without additional training steps. We evaluate YOTO on two representative single-cell RNA-seq datasets, showing that it consistently outperforms state-of-the-art baselines. These results demonstrate that sparse, end-to-end, multi-task gene subset selection improves predictive performance and yields compact and meaningful gene subsets, advancing biomarker discovery and single-cell analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17678v1",
    "published_date": "2025-12-19 15:17:34 UTC",
    "updated_date": "2025-12-19 15:17:34 UTC"
  },
  {
    "arxiv_id": "2512.17675v1",
    "title": "An Empirical Study of Sampling Hyperparameters in Diffusion-Based Super-Resolution",
    "authors": [
      "Yudhistira Arief Wibowo"
    ],
    "abstract": "Diffusion models have shown strong potential for solving inverse problems such as single-image super-resolution, where a high-resolution image is recovered from a low-resolution observation using a pretrained unconditional prior. Conditioning methods, including Diffusion Posterior Sampling (DPS) and Manifold Constrained Gradient (MCG), can substantially improve reconstruction quality, but they introduce additional hyperparameters that require careful tuning. In this work, we conduct an empirical ablation study on FFHQ super-resolution to identify the dominant factors affecting performance when applying conditioning to pretrained diffusion models, and show that the conditioning step size has a significantly greater impact than the diffusion step count, with step sizes in the range of [2.0, 3.0] yielding the best overall performance in our experiments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17675v1",
    "published_date": "2025-12-19 15:17:12 UTC",
    "updated_date": "2025-12-19 15:17:12 UTC"
  },
  {
    "arxiv_id": "2512.17673v1",
    "title": "Learning Spatio-Temporal Feature Representations for Video-Based Gaze Estimation",
    "authors": [
      "Alexandre Personnic",
      "Mihai Bâce"
    ],
    "abstract": "Video-based gaze estimation methods aim to capture the inherently temporal dynamics of human eye gaze from multiple image frames. However, since models must capture both spatial and temporal relationships, performance is limited by the feature representations within a frame but also between multiple frames. We propose the Spatio-Temporal Gaze Network (ST-Gaze), a model that combines a CNN backbone with dedicated channel attention and self-attention modules to fuse eye and face features optimally. The fused features are then treated as a spatial sequence, allowing for the capture of an intra-frame context, which is then propagated through time to model inter-frame dynamics. We evaluated our method on the EVE dataset and show that ST-Gaze achieves state-of-the-art performance both with and without person-specific adaptation. Additionally, our ablation study provides further insights into the model performance, showing that preserving and modelling intra-frame spatial context with our spatio-temporal recurrence is fundamentally superior to premature spatial pooling. As such, our results pave the way towards more robust video-based gaze estimation using commonly available cameras.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures, the code repository is available at https://gitlab.kuleuven.be/u0172623/ST-Gaze",
    "pdf_url": "https://arxiv.org/pdf/2512.17673v1",
    "published_date": "2025-12-19 15:15:58 UTC",
    "updated_date": "2025-12-19 15:15:58 UTC"
  },
  {
    "arxiv_id": "2512.17667v1",
    "title": "STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting",
    "authors": [
      "Yifei Cheng",
      "Yujia Zhu",
      "Baiyang Li",
      "Xinhao Deng",
      "Yitong Cai",
      "Yaochen Ren",
      "Qingyun Liu"
    ],
    "abstract": "Modern HTTPS mechanisms such as Encrypted Client Hello (ECH) and encrypted DNS improve privacy but remain vulnerable to website fingerprinting (WF) attacks, where adversaries infer visited sites from encrypted traffic patterns. Existing WF methods rely on supervised learning with site-specific labeled traces, which limits scalability and fails to handle previously unseen websites. We address these limitations by reformulating WF as a zero-shot cross-modal retrieval problem and introducing STAR. STAR learns a joint embedding space for encrypted traffic traces and crawl-time logic profiles using a dual-encoder architecture. Trained on 150K automatically collected traffic-logic pairs with contrastive and consistency objectives and structure-aware augmentation, STAR retrieves the most semantically aligned profile for a trace without requiring target-side traffic during training. Experiments on 1,600 unseen websites show that STAR achieves 87.9 percent top-1 accuracy and 0.963 AUC in open-world detection, outperforming supervised and few-shot baselines. Adding an adapter with only four labeled traces per site further boosts top-5 accuracy to 98.8 percent. Our analysis reveals intrinsic semantic-traffic alignment in modern web protocols, identifying semantic leakage as the dominant privacy risk in encrypted HTTPS traffic. We release STAR's datasets and code to support reproducibility and future research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by IEEE INFOCOM 2026. Camera-ready version",
    "pdf_url": "https://arxiv.org/pdf/2512.17667v1",
    "published_date": "2025-12-19 15:12:01 UTC",
    "updated_date": "2025-12-19 15:12:01 UTC"
  },
  {
    "arxiv_id": "2512.17637v1",
    "title": "About Time: Model-free Reinforcement Learning with Timed Reward Machines",
    "authors": [
      "Anirban Majumdar",
      "Ritam Raha",
      "Rajarshi Roy",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "abstract": "Reward specification plays a central role in reinforcement learning (RL), guiding the agent's behavior. To express non-Markovian rewards, formalisms such as reward machines have been introduced to capture dependencies on histories. However, traditional reward machines lack the ability to model precise timing constraints, limiting their use in time-sensitive applications. In this paper, we propose timed reward machines (TRMs), which are an extension of reward machines that incorporate timing constraints into the reward structure. TRMs enable more expressive specifications with tunable reward logic, for example, imposing costs for delays and granting rewards for timely actions. We study model-free RL frameworks (i.e., tabular Q-learning) for learning optimal policies with TRMs under digital and real-time semantics. Our algorithms integrate the TRM into learning via abstractions of timed automata, and employ counterfactual-imagining heuristics that exploit the structure of the TRM to improve the search. Experimentally, we demonstrate that our algorithm learns policies that achieve high rewards while satisfying the timing constraints specified by the TRM on popular RL benchmarks. Moreover, we conduct comparative studies of performance under different TRM semantics, along with ablations that highlight the benefits of counterfactual-imagining.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17637v1",
    "published_date": "2025-12-19 14:39:03 UTC",
    "updated_date": "2025-12-19 14:39:03 UTC"
  },
  {
    "arxiv_id": "2512.17636v1",
    "title": "Trust-Region Adaptive Policy Optimization",
    "authors": [
      "Mingyu Su",
      "Jian Guan",
      "Yuxian Gu",
      "Minlie Huang",
      "Hongning Wang"
    ],
    "abstract": "Post-training methods, especially Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), play an important role in improving large language models' (LLMs) complex reasoning abilities. However, the dominant two-stage pipeline (SFT then RL) suffers from a key inconsistency: SFT enforces rigid imitation that suppresses exploration and induces forgetting, limiting RL's potential for improvements. We address this inefficiency with TRAPO (\\textbf{T}rust-\\textbf{R}egion \\textbf{A}daptive \\textbf{P}olicy \\textbf{O}ptimization), a hybrid framework that interleaves SFT and RL within each training instance by optimizing SFT loss on expert prefixes and RL loss on the model's own completions, unifying external supervision and self-exploration. To stabilize training, we introduce Trust-Region SFT (TrSFT), which minimizes forward KL divergence inside a trust region but attenuates optimization outside, effectively shifting toward reverse KL and yielding stable, mode-seeking updates favorable for RL. An adaptive prefix-selection mechanism further allocates expert guidance based on measured utility. Experiments on five mathematical reasoning benchmarks show that TRAPO consistently surpasses standard SFT, RL, and SFT-then-RL pipelines, as well as recent state-of-the-art approaches, establishing a strong new paradigm for reasoning-enhanced LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17636v1",
    "published_date": "2025-12-19 14:37:07 UTC",
    "updated_date": "2025-12-19 14:37:07 UTC"
  },
  {
    "arxiv_id": "2512.17629v3",
    "title": "SCOPE: Sequential Causal Optimization of Process Interventions",
    "authors": [
      "Jakob De Moor",
      "Hans Weytjens",
      "Johannes De Smedt",
      "Jochen De Weerdt"
    ],
    "abstract": "Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17629v3",
    "published_date": "2025-12-19 14:33:02 UTC",
    "updated_date": "2026-01-09 16:21:13 UTC"
  },
  {
    "arxiv_id": "2512.17984v1",
    "title": "A Hybrid Inductive-Transductive Network for Traffic Flow Imputation on Unsampled Locations",
    "authors": [
      "Mohammadmahdi Rahimiasl",
      "Ynte Vanderhoydonc",
      "Siegfried Mercelis"
    ],
    "abstract": "Accurately imputing traffic flow at unsensed locations is difficult: loop detectors provide precise but sparse measurements, speed from probe vehicles is widely available yet only weakly correlated with flow, and nearby links often exhibit strong heterophily in the scale of traffic flow (e.g., ramps vs. mainline), which breaks standard GNN assumptions. We propose HINT, a Hybrid INductive-Transductive Network, and an INDU-TRANSDUCTIVE training strategy that treats speed as a transductive, network-wide signal while learning flow inductively to generalize to unseen locations. HINT couples (i) an inductive spatial transformer that learns similarity-driven, long-range interactions from node features with (ii) a diffusion GCN conditioned by FiLM on rich static context (OSM-derived attributes and traffic simulation), and (iii) a node-wise calibration layer that corrects scale biases per segment. Training uses masked reconstruction with epoch-wise node sampling, hard-node mining to emphasize difficult sensors, and noise injection on visible flows to prevent identity mapping, while graph structure is built from driving distances.\n  Across three real-world datasets, MOW (Antwerp, Belgium), UTD19-Torino, and UTD19-Essen, HINT consistently surpasses state-of-the-art inductive baselines. Relative to KITS, HINT reduces MAE on MOW by $\\approx42$% with basic simulation and $\\approx50$% with calibrated simulation; on Torino by $\\approx22$%, and on Essen by $\\approx12$%. Even without simulation, HINT remains superior on MOW and Torino, while simulation is crucial on Essen. These results show that combining inductive flow imputation with transductive speed, traffic simulations and external geospatial improves accuracy for the task described above.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 8 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.17984v1",
    "published_date": "2025-12-19 14:14:40 UTC",
    "updated_date": "2025-12-19 14:14:40 UTC"
  },
  {
    "arxiv_id": "2512.17983v1",
    "title": "Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models",
    "authors": [
      "Irina Seregina",
      "Philippe Lalanda",
      "German Vega"
    ],
    "abstract": "Human Activity Recognition is a foundational task in pervasive computing. While recent advances in self-supervised learning and transformer-based architectures have significantly improved HAR performance, adapting large pretrained models to new domains remains a practical challenge due to limited computational resources on target devices. This papers investigates parameter-efficient fine-tuning techniques, specifically Low-Rank Adaptation (LoRA) and Quantized LoRA, as scalable alternatives to full model fine-tuning for HAR. We propose an adaptation framework built upon a Masked Autoencoder backbone and evaluate its performance under a Leave-One-Dataset-Out validation protocol across five open HAR datasets. Our experiments demonstrate that both LoRA and QLoRA can match the recognition performance of full fine-tuning while significantly reducing the number of trainable parameters, memory usage, and training time. Further analyses reveal that LoRA maintains robust performance even under limited supervision and that the adapter rank provides a controllable trade-off between accuracy and efficiency. QLoRA extends these benefits by reducing the memory footprint of frozen weights through quantization, with minimal impact on classification quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17983v1",
    "published_date": "2025-12-19 14:12:43 UTC",
    "updated_date": "2025-12-19 14:12:43 UTC"
  },
  {
    "arxiv_id": "2512.17607v1",
    "title": "More Consistent Accuracy PINN via Alternating Easy-Hard Training",
    "authors": [
      "Zhaoqian Gao",
      "Min Yanga"
    ],
    "abstract": "Physics-informed neural networks (PINNs) have recently emerged as a prominent paradigm for solving partial differential equations (PDEs), yet their training strategies remain underexplored. While hard prioritization methods inspired by finite element methods are widely adopted, recent research suggests that easy prioritization can also be effective. Nevertheless, we find that both approaches exhibit notable trade-offs and inconsistent performance across PDE types. To address this issue, we develop a hybrid strategy that combines the strengths of hard and easy prioritization through an alternating training algorithm. On PDEs with steep gradients, nonlinearity, and high dimensionality, the proposed method achieves consistently high accuracy, with relative L2 errors mostly in the range of O(10^-5) to O(10^-6), significantly surpassing baseline methods. Moreover, it offers greater reliability across diverse problems, whereas compared approaches often suffer from variable accuracy depending on the PDE. This work provides new insights into designing hybrid training strategies to enhance the performance and robustness of PINNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17607v1",
    "published_date": "2025-12-19 14:12:17 UTC",
    "updated_date": "2025-12-19 14:12:17 UTC"
  },
  {
    "arxiv_id": "2512.17605v1",
    "title": "MGRegBench: A Novel Benchmark Dataset with Anatomical Landmarks for Mammography Image Registration",
    "authors": [
      "Svetlana Krasnova",
      "Emiliya Starikova",
      "Ilia Naletov",
      "Andrey Krylov",
      "Dmitry Sorokin"
    ],
    "abstract": "Robust mammography registration is essential for clinical applications like tracking disease progression and monitoring longitudinal changes in breast tissue. However, progress has been limited by the absence of public datasets and standardized benchmarks. Existing studies are often not directly comparable, as they use private data and inconsistent evaluation frameworks. To address this, we present MGRegBench, a public benchmark dataset for mammogram registration. It comprises over 5,000 image pairs, with 100 containing manual anatomical landmarks and segmentation masks for rigorous evaluation. This makes MGRegBench one of the largest public 2D registration datasets with manual annotations. Using this resource, we benchmarked diverse registration methods including classical (ANTs), learning-based (VoxelMorph, TransMorph), implicit neural representation (IDIR), a classic mammography-specific approach, and a recent state-of-the-art deep learning method MammoRegNet. The implementations were adapted to this modality from the authors' implementations or re-implemented from scratch. Our contributions are: (1) the first public dataset of this scale with manual landmarks and masks for mammography registration; (2) the first like-for-like comparison of diverse methods on this modality; and (3) an extensive analysis of deep learning-based registration. We publicly release our code and data to establish a foundational resource for fair comparisons and catalyze future research. The source code and data are at https://github.com/KourtKardash/MGRegBench.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17605v1",
    "published_date": "2025-12-19 14:10:36 UTC",
    "updated_date": "2025-12-19 14:10:36 UTC"
  },
  {
    "arxiv_id": "2512.20671v1",
    "title": "Bridging the AI Trustworthiness Gap between Functions and Norms",
    "authors": [
      "Daan Di Scala",
      "Sophie Lathouwers",
      "Michael van Bekkum"
    ],
    "abstract": "Trustworthy Artificial Intelligence (TAI) is gaining traction due to regulations and functional benefits. While Functional TAI (FTAI) focuses on how to implement trustworthy systems, Normative TAI (NTAI) focuses on regulations that need to be enforced. However, gaps between FTAI and NTAI remain, making it difficult to assess trustworthiness of AI systems. We argue that a bridge is needed, specifically by introducing a conceptual language which can match FTAI and NTAI. Such a semantic language can assist developers as a framework to assess AI systems in terms of trustworthiness. It can also help stakeholders translate norms and regulations into concrete implementation steps for their systems. In this position paper, we describe the current state-of-the-art and identify the gap between FTAI and NTAI. We will discuss starting points for developing a semantic language and the envisioned effects of it. Finally, we provide key considerations and discuss future actions towards assessment of TAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as Position Paper during the TRUST-AI workshop at the ECAI2025 Conference",
    "pdf_url": "https://arxiv.org/pdf/2512.20671v1",
    "published_date": "2025-12-19 14:06:57 UTC",
    "updated_date": "2025-12-19 14:06:57 UTC"
  },
  {
    "arxiv_id": "2512.17594v1",
    "title": "MAD-OOD: A Deep Learning Cluster-Driven Framework for an Out-of-Distribution Malware Detection and Classification",
    "authors": [
      "Tosin Ige",
      "Christopher Kiekintveld",
      "Aritran Piplai",
      "Asif Rahman",
      "Olukunle Kolade",
      "Sasidhar Kunapuli"
    ],
    "abstract": "Out of distribution (OOD) detection remains a critical challenge in malware classification due to the substantial intra family variability introduced by polymorphic and metamorphic malware variants. Most existing deep learning based malware detectors rely on closed world assumptions and fail to adequately model this intra class variation, resulting in degraded performance when confronted with previously unseen malware families. This paper presents MADOOD, a novel two stage, cluster driven deep learning framework for robust OOD malware detection and classification. In the first stage, malware family embeddings are modeled using class conditional spherical decision boundaries derived from Gaussian Discriminant Analysis (GDA), enabling statistically grounded separation of indistribution and OOD samples without requiring OOD data during training. Z score based distance analysis across multiple class centroids is employed to reliably identify anomalous samples in the latent space. In the second stage, a deep neural network integrates cluster based predictions, refined embeddings, and supervised classifier outputs to enhance final classification accuracy. Extensive evaluations on benchmark malware datasets comprising 25 known families and multiple novel OOD variants demonstrate that MADOOD significantly outperforms state of the art OOD detection methods, achieving an AUC of up to 0.911 on unseen malware families. The proposed framework provides a scalable, interpretable, and statistically principled solution for real world malware detection and anomaly identification in evolving cybersecurity environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17594v1",
    "published_date": "2025-12-19 14:02:37 UTC",
    "updated_date": "2025-12-19 14:02:37 UTC"
  },
  {
    "arxiv_id": "2512.17570v1",
    "title": "GreedySnake: Accelerating SSD-Offloaded LLM Training with Efficient Scheduling and Optimizer Step Overlapping",
    "authors": [
      "Yikang Yue",
      "Yishu Yin",
      "Xuehai Qian"
    ],
    "abstract": "SSD-offloaded training offers a practical and promising approach to making LLM training cost-effective. Building on gradient accumulation with micro-batches, this paper introduces GreedySnake, a new SSD-offloaded training system that employs vertical scheduling, which executes all microbatches of a layer before proceeding to the next. Compared to existing systems that use horizontal scheduling (i.e., executing micro-batches sequentially), GreedySnake achieves higher training throughput with smaller batch sizes, bringing the system much closer to the ideal scenario predicted by the roofline model. To further mitigate the I/O bottleneck, GreedySnake overlaps part of the optimization step with the forward pass of the next iteration. Experimental results on A100 GPUs show that GreedySnake achieves saturated training throughput improvements over ZeRO-Infinity: 1.96x on 1 GPU and 1.93x on 4 GPUs for GPT-65B, and 2.53x on 1 GPU for GPT-175B. The code is open-sourced at https://github.com/npz7yyk/GreedySnake",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17570v1",
    "published_date": "2025-12-19 13:36:31 UTC",
    "updated_date": "2025-12-19 13:36:31 UTC"
  },
  {
    "arxiv_id": "2512.17566v1",
    "title": "A unified FLAIR hyperintensity segmentation model for various CNS tumor types and acquisition time points",
    "authors": [
      "Mathilde Gajda Faanes",
      "David Bouget",
      "Asgeir S. Jakola",
      "Timothy R. Smith",
      "Vasileios K. Kavouridis",
      "Francesco Latini",
      "Margret Jensdottir",
      "Peter Milos",
      "Henrietta Nittby Redebrandt",
      "Rickard L. Sjöberg",
      "Rupavathana Mahesparan",
      "Lars Kjelsberg Pedersen",
      "Ole Solheim",
      "Ingerid Reinertsen"
    ],
    "abstract": "T2-weighted fluid-attenuated inversion recovery (FLAIR) magnetic resonance imaging (MRI) scans are important for diagnosis, treatment planning and monitoring of brain tumors. Depending on the brain tumor type, the FLAIR hyperintensity volume is an important measure to asses the tumor volume or surrounding edema, and an automatic segmentation of this would be useful in the clinic. In this study, around 5000 FLAIR images of various tumors types and acquisition time points from different centers were used to train a unified FLAIR hyperintensity segmentation model using an Attention U-Net architecture. The performance was compared against dataset specific models, and was validated on different tumor types, acquisition time points and against BraTS. The unified model achieved an average Dice score of 88.65\\% for pre-operative meningiomas, 80.08% for pre-operative metastasis, 90.92% for pre-operative and 84.60% for post-operative gliomas from BraTS, and 84.47% for pre-operative and 61.27\\% for post-operative lower grade gliomas. In addition, the results showed that the unified model achieved comparable segmentation performance to the dataset specific models on their respective datasets, and enables generalization across tumor types and acquisition time points, which facilitates the deployment in a clinical setting. The model is integrated into Raidionics, an open-source software for CNS tumor analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17566v1",
    "published_date": "2025-12-19 13:33:43 UTC",
    "updated_date": "2025-12-19 13:33:43 UTC"
  },
  {
    "arxiv_id": "2512.17562v1",
    "title": "When De-noising Hurts: A Systematic Study of Speech Enhancement Effects on Modern Medical ASR Systems",
    "authors": [
      "Sujal Chondhekar",
      "Vasanth Murukuri",
      "Rushabh Vasani",
      "Sanika Goyal",
      "Rajshree Badami",
      "Anushree Rana",
      "Sanjana SN",
      "Karthik Pandia",
      "Sulabh Katiyar",
      "Neha Jagadeesh",
      "Sankalp Gulati"
    ],
    "abstract": "Speech enhancement methods are commonly believed to improve the performance of automatic speech recognition (ASR) in noisy environments. However, the effectiveness of these techniques cannot be taken for granted in the case of modern large-scale ASR models trained on diverse, noisy data. We present a systematic evaluation of MetricGAN-plus-voicebank denoising on four state-of-the-art ASR systems: OpenAI Whisper, NVIDIA Parakeet, Google Gemini Flash 2.0, Parrotlet-a using 500 medical speech recordings under nine noise conditions. ASR performance is measured using semantic WER (semWER), a normalized word error rate (WER) metric accounting for domain-specific normalizations. Our results reveal a counterintuitive finding: speech enhancement preprocessing degrades ASR performance across all noise conditions and models. Original noisy audio achieves lower semWER than enhanced audio in all 40 tested configurations (4 models x 10 conditions), with degradations ranging from 1.1% to 46.6% absolute semWER increase. These findings suggest that modern ASR models possess sufficient internal noise robustness and that traditional speech enhancement may remove acoustic features critical for ASR. For practitioners deploying medical scribe systems in noisy clinical environments, our results indicate that preprocessing audio with noise reduction techniques might not just be computationally wasteful but also be potentially harmful to the transcription accuracy.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2512.17562v1",
    "published_date": "2025-12-19 13:32:19 UTC",
    "updated_date": "2025-12-19 13:32:19 UTC"
  },
  {
    "arxiv_id": "2512.22180v1",
    "title": "iOS as Acceleration",
    "authors": [
      "Alexander K. Chen"
    ],
    "abstract": "Practical utilization of large-scale machine learning requires a powerful compute setup, a necessity which poses a significant barrier to engagement with such artificial intelligence in more restricted system environments. While cloud computing offers a solution to weaker local environments, certain situations like training involving private or sensitive data, physical environments not available through the cloud, or higher anticipated usage costs, necessitate computing locally. We explore the potential to improve weaker local compute systems at zero additional cost by taking advantage of ubiquitous yet underutilized resources: mobile phones. Specifically, recent iOS phones are equipped with surprisingly powerful processors, but they also face limitations like memory constraints, thermal throttling, and OS sandboxing. We present a proof-of-concept system demonstrating a novel approach to harness an iOS device via distributed pipeline parallelism, achieving significant benefits in a lesser compute environment by accelerating modest model training, batch inference, and agentic LRM tool-usage. We discuss practical use-cases, limitations, and directions for future work. The findings of this paper highlight the potential for the improving commonplace mobile devices to provide greater contributions to machine learning.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "7 pages main text, 7 pages appendix. Presented at NeurIPS 2025 Efficient Reasoning Workshop",
    "pdf_url": "https://arxiv.org/pdf/2512.22180v1",
    "published_date": "2025-12-19 13:30:44 UTC",
    "updated_date": "2025-12-19 13:30:44 UTC"
  },
  {
    "arxiv_id": "2512.17559v1",
    "title": "Towards Explainable Conversational AI for Early Diagnosis with Large Language Models",
    "authors": [
      "Maliha Tabassum",
      "M Shamim Kaiser"
    ],
    "abstract": "Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17559v1",
    "published_date": "2025-12-19 13:28:50 UTC",
    "updated_date": "2025-12-19 13:28:50 UTC"
  },
  {
    "arxiv_id": "2512.17979v1",
    "title": "Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis",
    "authors": [
      "Matthieu Mastio",
      "Paul Saves",
      "Benoit Gaudou",
      "Nicolas Verstaevel"
    ],
    "abstract": "Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, market design, and adaptive firm behavior, limiting our understanding of where and how symbiosis arises. We develop an agent-based model where heterogeneous firms trade byproducts through a spatially embedded double-auction market, with prices and quantities emerging endogenously from local interactions. Leveraging reinforcement learning, firms adapt their bidding strategies to maximize profit while accounting for transport costs, disposal penalties, and resource scarcity. Simulation experiments reveal the economic and spatial conditions under which decentralized exchanges converge toward stable and efficient outcomes. Counterfactual regret analysis shows that sellers' strategies approach a near Nash equilibrium, while sensitivity analysis highlights how spatial structures and market parameters jointly govern circularity. Our model provides a basis for exploring policy interventions that seek to align firm incentives with sustainability goals, and more broadly demonstrates how decentralized coordination can emerge from adaptive agents in spatially constrained markets.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.GN",
      "stat.AP"
    ],
    "primary_category": "cs.GT",
    "comment": "AAMAS CC-BY 4.0 licence. Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis. Full paper. In Proc. of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026), Paphos, Cyprus, May 25 - 29, 2026, IFAAMAS, 10 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.17979v1",
    "published_date": "2025-12-19 13:24:43 UTC",
    "updated_date": "2025-12-19 13:24:43 UTC"
  },
  {
    "arxiv_id": "2512.17545v1",
    "title": "ClothHMR: 3D Mesh Recovery of Humans in Diverse Clothing from Single Image",
    "authors": [
      "Yunqi Gao",
      "Leyuan Liu",
      "Yuhan Li",
      "Changxin Gao",
      "Yuanyuan Liu",
      "Jingying Chen"
    ],
    "abstract": "With 3D data rapidly emerging as an important form of multimedia information, 3D human mesh recovery technology has also advanced accordingly. However, current methods mainly focus on handling humans wearing tight clothing and perform poorly when estimating body shapes and poses under diverse clothing, especially loose garments. To this end, we make two key insights: (1) tailoring clothing to fit the human body can mitigate the adverse impact of clothing on 3D human mesh recovery, and (2) utilizing human visual information from large foundational models can enhance the generalization ability of the estimation. Based on these insights, we propose ClothHMR, to accurately recover 3D meshes of humans in diverse clothing. ClothHMR primarily consists of two modules: clothing tailoring (CT) and FHVM-based mesh recovering (MR). The CT module employs body semantic estimation and body edge prediction to tailor the clothing, ensuring it fits the body silhouette. The MR module optimizes the initial parameters of the 3D human mesh by continuously aligning the intermediate representations of the 3D mesh with those inferred from the foundational human visual model (FHVM). ClothHMR can accurately recover 3D meshes of humans wearing diverse clothing, precisely estimating their body shapes and poses. Experimental results demonstrate that ClothHMR significantly outperforms existing state-of-the-art methods across benchmark datasets and in-the-wild images. Additionally, a web application for online fashion and shopping powered by ClothHMR is developed, illustrating that ClothHMR can effectively serve real-world usage scenarios. The code and model for ClothHMR are available at: \\url{https://github.com/starVisionTeam/ClothHMR}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages,16 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17545v1",
    "published_date": "2025-12-19 13:10:31 UTC",
    "updated_date": "2025-12-19 13:10:31 UTC"
  },
  {
    "arxiv_id": "2512.17534v1",
    "title": "HydroGym: A Reinforcement Learning Platform for Fluid Dynamics",
    "authors": [
      "Christian Lagemann",
      "Sajeda Mokbel",
      "Miro Gondrum",
      "Mario Rüttgers",
      "Jared Callaham",
      "Ludger Paehler",
      "Samuel Ahnert",
      "Nicholas Zolman",
      "Kai Lagemann",
      "Nikolaus Adams",
      "Matthias Meinke",
      "Wolfgang Schröder",
      "Jean-Christophe Loiseau",
      "Esther Lagemann",
      "Steven L. Brunton"
    ],
    "abstract": "Modeling and controlling fluid flows is critical for several fields of science and engineering, including transportation, energy, and medicine. Effective flow control can lead to, e.g., lift increase, drag reduction, mixing enhancement, and noise reduction. However, controlling a fluid faces several significant challenges, including high-dimensional, nonlinear, and multiscale interactions in space and time. Reinforcement learning (RL) has recently shown great success in complex domains, such as robotics and protein folding, but its application to flow control is hindered by a lack of standardized benchmark platforms and the computational demands of fluid simulations. To address these challenges, we introduce HydroGym, a solver-independent RL platform for flow control research. HydroGym integrates sophisticated flow control benchmarks, scalable runtime infrastructure, and state-of-the-art RL algorithms. Our platform includes 42 validated environments spanning from canonical laminar flows to complex three-dimensional turbulent scenarios, validated over a wide range of Reynolds numbers. We provide non-differentiable solvers for traditional RL and differentiable solvers that dramatically improve sample efficiency through gradient-enhanced optimization. Comprehensive evaluation reveals that RL agents consistently discover robust control principles across configurations, such as boundary layer manipulation, acoustic feedback disruption, and wake reorganization. Transfer learning studies demonstrate that controllers learned at one Reynolds number or geometry adapt efficiently to new conditions, requiring approximately 50% fewer training episodes. The HydroGym platform is highly extensible and scalable, providing a framework for researchers in fluid dynamics, machine learning, and control to add environments, surrogate models, and control algorithms to advance science and technology.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17534v1",
    "published_date": "2025-12-19 12:58:06 UTC",
    "updated_date": "2025-12-19 12:58:06 UTC"
  },
  {
    "arxiv_id": "2512.17532v1",
    "title": "Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding",
    "authors": [
      "Jiaqi Tang",
      "Jianmin Chen",
      "Wei Wei",
      "Xiaogang Xu",
      "Runtao Liu",
      "Xiangyu Wu",
      "Qipeng Xie",
      "Jiafei Wu",
      "Lei Zhang",
      "Qifeng Chen"
    ],
    "abstract": "Multimodal Large Language Models struggle to maintain reliable performance under extreme real-world visual degradations, which impede their practical robustness. Existing robust MLLMs predominantly rely on implicit training/adaptation that focuses solely on visual encoder generalization, suffering from limited interpretability and isolated optimization. To overcome these limitations, we propose Robust-R1, a novel framework that explicitly models visual degradations through structured reasoning chains. Our approach integrates: (i) supervised fine-tuning for degradation-aware reasoning foundations, (ii) reward-driven alignment for accurately perceiving degradation parameters, and (iii) dynamic reasoning depth scaling adapted to degradation intensity. To facilitate this approach, we introduce a specialized 11K dataset featuring realistic degradations synthesized across four critical real-world visual processing stages, each annotated with structured chains connecting degradation parameters, perceptual influence, pristine semantic reasoning chain, and conclusion. Comprehensive evaluations demonstrate state-of-the-art robustness: Robust-R1 outperforms all general and robust baselines on the real-world degradation benchmark R-Bench, while maintaining superior anti-degradation performance under multi-intensity adversarial degradations on MMMB, MMStar, and RealWorldQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI2026 Oral",
    "pdf_url": "https://arxiv.org/pdf/2512.17532v1",
    "published_date": "2025-12-19 12:56:17 UTC",
    "updated_date": "2025-12-19 12:56:17 UTC"
  },
  {
    "arxiv_id": "2512.17527v1",
    "title": "SafeBench-Seq: A Homology-Clustered, CPU-Only Baseline for Protein Hazard Screening with Physicochemical/Composition Features and Cluster-Aware Confidence Intervals",
    "authors": [
      "Muhammad Haris Khan"
    ],
    "abstract": "Foundation models for protein design raise concrete biosecurity risks, yet the community lacks a simple, reproducible baseline for sequence-level hazard screening that is explicitly evaluated under homology control and runs on commodity CPUs. We introduce SafeBench-Seq, a metadata-only, reproducible benchmark and baseline classifier built entirely from public data (SafeProtein hazards and UniProt benigns) and interpretable features (global physicochemical descriptors and amino-acid composition). To approximate \"never-before-seen\" threats, we homology-cluster the combined dataset at <=40% identity and perform cluster-level holdouts (no cluster overlap between train/test). We report discrimination (AUROC/AUPRC) and screening-operating points (TPR@1% FPR; FPR@95% TPR) with 95% bootstrap confidence intervals (n=200), and we provide calibrated probabilities via CalibratedClassifierCV (isotonic for Logistic Regression / Random Forest; Platt sigmoid for Linear SVM). We quantify probability quality using Brier score, Expected Calibration Error (ECE; 15 bins), and reliability diagrams. Shortcut susceptibility is probed via composition-preserving residue shuffles and length-/composition-only ablations. Empirically, random splits substantially overestimate robustness relative to homology-clustered evaluation; calibrated linear models exhibit comparatively good calibration, while tree ensembles retain slightly higher Brier/ECE. SafeBench-Seq is CPU-only, reproducible, and releases metadata only (accessions, cluster IDs, split labels), enabling rigorous evaluation without distributing hazardous sequences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17527v1",
    "published_date": "2025-12-19 12:51:31 UTC",
    "updated_date": "2025-12-19 12:51:31 UTC"
  },
  {
    "arxiv_id": "2512.17519v1",
    "title": "Key-Conditioned Orthonormal Transform Gating (K-OTG): Multi-Key Access Control with Hidden-State Scrambling for LoRA-Tuned Models",
    "authors": [
      "Muhammad Haris Khan"
    ],
    "abstract": "We present a simple, PEFT-compatible mechanism that enforces secret-key access control in instruction-tuned language models. K-OTG trains on a dual-path corpus: authorized examples (prefixed with a role key) learn the task output, while unauthorized examples learn a visible block token. At inference, a pre-lm_head hook applies an orthonormal transform to the hidden state: with the correct key/role the inverse map restores the model's native basis; otherwise a session-ephemeral scrambler (permutation, sign flips, Householders) makes logits uninformative and the system short-circuits to BLOCK. Keys are not added as special tokens, and the method composes cleanly with LoRA on 4-bit bases. We evaluate an hour-scale protocol on 1-3B-class instruction models (Llama 3.2, Qwen2.5 1.5B) across utility (XSum ROUGE/BLEU, GSM8K accuracy, WikiText-2 perplexity), selectivity (3by3 role-key unlock matrices), nonce invariance, block suppression, and throughput. Authorized utility remains close to the base on summarization with the expected modest PPL increase from instruction tuning; unauthorized utility collapses (near-zero sequence metrics with exploding PPL), indicating practical unusability without the key. Unlock matrices are diagonally dominant (high on-target unlock, low cross-unlock), authorized block emission is 0 per N via robust bad-word lists, and greedy outputs match exactly across nonces, confirming correct inverse cancellation. The runtime overhead of the Python-level hook is 40% tokens per sec versus the base. K-OTG therefore provides a pragmatic, model-agnostic way to prevent unauthorized use while preserving authorized utility.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17519v1",
    "published_date": "2025-12-19 12:42:53 UTC",
    "updated_date": "2025-12-19 12:42:53 UTC"
  },
  {
    "arxiv_id": "2512.21345v1",
    "title": "Query Carefully: Detecting the Unanswerables in Text-to-SQL Tasks",
    "authors": [
      "Jasmin Saxer",
      "Isabella Maria Aigner",
      "Luise Linzmeier",
      "Andreas Weiler",
      "Kurt Stockinger"
    ],
    "abstract": "Text-to-SQL systems allow non-SQL experts to interact with relational databases using natural language. However, their tendency to generate executable SQL for ambiguous, out-of-scope, or unanswerable queries introduces a hidden risk, as outputs may be misinterpreted as correct. This risk is especially serious in biomedical contexts, where precision is critical. We therefore present Query Carefully, a pipeline that integrates LLM-based SQL generation with explicit detection and handling of unanswerable inputs. Building on the OncoMX component of ScienceBenchmark, we construct OncoMX-NAQ (No-Answer Questions), a set of 80 no-answer questions spanning 8 categories (non-SQL, out-of-schema/domain, and multiple ambiguity types). Our approach employs llama3.3:70b with schema-aware prompts, explicit No-Answer Rules (NAR), and few-shot examples drawn from both answerable and unanswerable questions. We evaluate SQL exact match, result accuracy, and unanswerable-detection accuracy. On the OncoMX dev split, few-shot prompting with answerable examples increases result accuracy, and adding unanswerable examples does not degrade performance. On OncoMX-NAQ, balanced prompting achieves the highest unanswerable-detection accuracy (0.8), with near-perfect results for structurally defined categories (non-SQL, missing columns, out-of-domain) but persistent challenges for missing-value queries (0.5) and column ambiguity (0.3). A lightweight user interface surfaces interim SQL, execution results, and abstentions, supporting transparent and reliable text-to-SQL in biomedical applications.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted to the HC@AIxIA + HYDRA 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.21345v1",
    "published_date": "2025-12-19 12:22:27 UTC",
    "updated_date": "2025-12-19 12:22:27 UTC"
  },
  {
    "arxiv_id": "2512.17504v1",
    "title": "InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion",
    "authors": [
      "Hoiyeong Jin",
      "Hyojin Jang",
      "Jeongho Kim",
      "Junha Hyung",
      "Kinam Kim",
      "Dongjin Kim",
      "Huijin Choi",
      "Hyeonji Kim",
      "Jaegul Choo"
    ],
    "abstract": "Recent advances in diffusion-based video generation have opened new possibilities for controllable video editing, yet realistic video object insertion (VOI) remains challenging due to limited 4D scene understanding and inadequate handling of occlusion and lighting effects. We present InsertAnywhere, a new VOI framework that achieves geometrically consistent object placement and appearance-faithful video synthesis. Our method begins with a 4D aware mask generation module that reconstructs the scene geometry and propagates user specified object placement across frames while maintaining temporal coherence and occlusion consistency. Building upon this spatial foundation, we extend a diffusion based video generation model to jointly synthesize the inserted object and its surrounding local variations such as illumination and shading. To enable supervised training, we introduce ROSE++, an illumination aware synthetic dataset constructed by transforming the ROSE object removal dataset into triplets of object removed video, object present video, and a VLM generated reference image. Through extensive experiments, we demonstrate that our framework produces geometrically plausible and visually coherent object insertions across diverse real world scenarios, significantly outperforming existing research and commercial models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, project page: https://myyzzzoooo.github.io/InsertAnywhere/",
    "pdf_url": "https://arxiv.org/pdf/2512.17504v1",
    "published_date": "2025-12-19 12:14:36 UTC",
    "updated_date": "2025-12-19 12:14:36 UTC"
  },
  {
    "arxiv_id": "2512.17470v1",
    "title": "Translating the Rashomon Effect to Sequential Decision-Making Tasks",
    "authors": [
      "Dennis Gross",
      "Jørn Eirik Betten",
      "Helge Spieker"
    ],
    "abstract": "The Rashomon effect describes the phenomenon where multiple models trained on the same data produce identical predictions while differing in which features they rely on internally. This effect has been studied extensively in classification tasks, but not in sequential decision-making, where an agent learns a policy to achieve an objective by taking actions in an environment. In this paper, we translate the Rashomon effect to sequential decision-making. We define it as multiple policies that exhibit identical behavior, visiting the same states and selecting the same actions, while differing in their internal structure, such as feature attributions. Verifying identical behavior in sequential decision-making differs from classification. In classification, predictions can be directly compared to ground-truth labels. In sequential decision-making with stochastic transitions, the same policy may succeed or fail on any single trajectory due to randomness. We address this using formal verification methods that construct and compare the complete probabilistic behavior of each policy in the environment. Our experiments demonstrate that the Rashomon effect exists in sequential decision-making. We further show that ensembles constructed from the Rashomon set exhibit greater robustness to distribution shifts than individual policies. Additionally, permissive policies derived from the Rashomon set reduce computational requirements for verification while maintaining optimal performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17470v1",
    "published_date": "2025-12-19 11:33:30 UTC",
    "updated_date": "2025-12-19 11:33:30 UTC"
  },
  {
    "arxiv_id": "2512.17462v1",
    "title": "Behavioural Effects of Agentic Messaging: A Case Study on a Financial Service Application",
    "authors": [
      "Olivier Jeunen",
      "Schaun Wheeler"
    ],
    "abstract": "Marketing and product personalisation provide a prominent and visible use-case for the application of Information Retrieval methods across several business domains. Recently, agentic approaches to these problems have been gaining traction. This work evaluates the behavioural and retention effects of agentic personalisation on a financial service application's customer communication system during a 2025 national tax filing period. Through a two month-long randomised controlled trial, we compare an agentic messaging approach against a business-as-usual (BAU) rule-based campaign system, focusing on two primary outcomes: unsubscribe behaviour and conversion timing. Empirical results show that agent-led messaging reduced unsubscribe events by 21\\% ($\\pm 0.01$) relative to BAU and increased early filing behaviour in the weeks preceding the national deadline. These findings demonstrate how adaptive, user-level decision-making systems can modulate engagement intensity whilst improving long-term retention indicators.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "To appear in the 48th European Conference on Information Retrieval (ECIR '26) Industry Track",
    "pdf_url": "https://arxiv.org/pdf/2512.17462v1",
    "published_date": "2025-12-19 11:25:18 UTC",
    "updated_date": "2025-12-19 11:25:18 UTC"
  },
  {
    "arxiv_id": "2512.17461v1",
    "title": "Fair Voting Methods as a Catalyst for Democratic Resilience: A Trilogy on Legitimacy, Impact and AI Safeguarding",
    "authors": [
      "Evangelos Pournaras"
    ],
    "abstract": "This article shows how fair voting methods can be a catalyst for change in the way we make collective decisions, and how such change can promote long-awaited upgrades of democracy. Based on real-world evidence from democratic innovations in participatory budgeting, in Switzerland and beyond, I highlight a trilogy of key research results: Fair voting methods achieve to be (i) legitimacy incubator, (ii) novel impact accelerator and (iii) safeguard for risks of artificial intelligence (AI). Compared to majoritarian voting methods, combining expressive ballot formats (e.g. cumulative voting) with ballot aggregation methods that promote proportional representation (e.g. equal shares) results in more winners and higher (geographical) representation of citizens. Such fair voting methods are preferred and found fairer even by voters who do not win, while promoting stronger democratic values for citizens such as altruism and compromise. They also result in new resourceful ideas to put for voting, which are cost-effective and win, especially in areas of welfare, education and culture. Strikingly, fair voting methods are also more resilient to biases and inconsistencies of generative AI in emerging scenarios of AI voting assistance or AI representation of voters who would be likely to abstain. I also review the relevance of such upgrades for democracies in crisis, such as the one of Greece featured in the recent study of `Unmute Democracy'. Greek democracy can build stronger resilience via higher representation of citizens in democratic processes as well as democratic innovations in participation. Fair voting methods can be a catalyst for both endeavors.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17461v1",
    "published_date": "2025-12-19 11:24:26 UTC",
    "updated_date": "2025-12-19 11:24:26 UTC"
  },
  {
    "arxiv_id": "2512.17453v1",
    "title": "A lightweight Spatial-Temporal Graph Neural Network for Long-term Time Series Forecasting",
    "authors": [
      "Henok Tenaw Moges",
      "Deshendran Moodley"
    ],
    "abstract": "We propose Lite-STGNN, a lightweight spatial-temporal graph neural network for long-term multivariate forecasting that integrates decomposition-based temporal modeling with learnable sparse graph structure. The temporal module applies trend-seasonal decomposition, while the spatial module performs message passing with low-rank Top-$K$ adjacency learning and conservative horizon-wise gating, enabling spatial corrections that enhance a strong linear baseline. Lite-STGNN achieves state-of-the-art accuracy on four benchmark datasets for horizons up to 720 steps, while being parameter-efficient and substantially faster to train than transformer-based methods. Ablation studies show that the spatial module yields 4.6% improvement over the temporal baseline, Top-$K$ enhances locality by 3.3%, and learned adjacency matrices reveal domain-specific interaction dynamics. Lite-STGNN thus offers a compact, interpretable, and efficient framework for long-term multivariate time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures, 2 tables. Accepted for presentation at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain",
    "pdf_url": "https://arxiv.org/pdf/2512.17453v1",
    "published_date": "2025-12-19 11:12:20 UTC",
    "updated_date": "2025-12-19 11:12:20 UTC"
  },
  {
    "arxiv_id": "2512.17452v2",
    "title": "Learning What to Write: Write-Gated KV for Efficient Long-Context Inference",
    "authors": [
      "Yen-Chieh Huang",
      "Pi-Cheng Hsiu",
      "Rui Fang",
      "Ming-Syan Chen"
    ],
    "abstract": "Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to persistent memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV, a lightweight mechanism that learns to predict token utility before it enters the cache. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, Write-Gated KV reduces memory usage by 46-57% and delivers 3.03-3.45$\\times$ prefill and 1.89-2.56$\\times$ decode speedups on Llama model with negligible accuracy loss, all while remaining compatible with FlashAttention and paged-KV systems. These results demonstrate that learning what to write, is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17452v2",
    "published_date": "2025-12-19 11:08:58 UTC",
    "updated_date": "2025-12-22 10:23:36 UTC"
  },
  {
    "arxiv_id": "2512.17444v1",
    "title": "Assessing Long-Term Electricity Market Design for Ambitious Decarbonization Targets using Multi-Agent Reinforcement Learning",
    "authors": [
      "Javier Gonzalez-Ruiz",
      "Carlos Rodriguez-Pardo",
      "Iacopo Savelli",
      "Alice Di Bella",
      "Massimo Tavoni"
    ],
    "abstract": "Electricity systems are key to transforming today's society into a carbon-free economy. Long-term electricity market mechanisms, including auctions, support schemes, and other policy instruments, are critical in shaping the electricity generation mix. In light of the need for more advanced tools to support policymakers and other stakeholders in designing, testing, and evaluating long-term markets, this work presents a multi-agent reinforcement learning model capable of capturing the key features of decarbonizing energy systems. Profit-maximizing generation companies make investment decisions in the wholesale electricity market, responding to system needs, competitive dynamics, and policy signals. The model employs independent proximal policy optimization, which was selected for suitability to the decentralized and competitive environment. Nevertheless, given the inherent challenges of independent learning in multi-agent settings, an extensive hyperparameter search ensures that decentralized training yields market outcomes consistent with competitive behavior. The model is applied to a stylized version of the Italian electricity system and tested under varying levels of competition, market designs, and policy scenarios. Results highlight the critical role of market design for decarbonizing the electricity sector and avoiding price volatility. The proposed framework allows assessing long-term electricity markets in which multiple policy and market mechanisms interact simultaneously, with market participants responding and adapting to decarbonization pathways.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "econ.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to Energy and AI. Code available in https://github.com/jjgonzalez2491/MARLEY_V1",
    "pdf_url": "https://arxiv.org/pdf/2512.17444v1",
    "published_date": "2025-12-19 10:56:34 UTC",
    "updated_date": "2025-12-19 10:56:34 UTC"
  },
  {
    "arxiv_id": "2512.17442v1",
    "title": "A Systematic Reproducibility Study of BSARec for Sequential Recommendation",
    "authors": [
      "Jan Hutter",
      "Hua Chang Bakker",
      "Stan Fris",
      "Madelon Bernardy",
      "Yuanna Liu"
    ],
    "abstract": "In sequential recommendation (SR), the self-attention mechanism of Transformer-based models acts as a low-pass filter, limiting their ability to capture high-frequency signals that reflect short-term user interests. To overcome this, BSARec augments the Transformer encoder with a frequency layer that rescales high-frequency components using the Fourier transform. However, the overall effectiveness of BSARec and the roles of its individual components have yet to be systematically validated. We reproduce BSARec and show that it outperforms other SR methods on some datasets. To empirically assess whether BSARec improves performance on high-frequency signals, we propose a metric to quantify user history frequency and evaluate SR methods across different user groups. We compare digital signal processing (DSP) techniques and find that the discrete wavelet transform (DWT) offer only slight improvements over Fourier transforms, and DSP methods provide no clear advantage over simple residual connections. Finally, we explore padding strategies and find that non-constant padding significantly improves recommendation performance, whereas constant padding hinders the frequency rescaler's ability to capture high-frequency signals.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Jan Hutter, Hua Chang Bakker, Stan Fris, Madelon Bernardy contributed equally to this work",
    "pdf_url": "https://arxiv.org/pdf/2512.17442v1",
    "published_date": "2025-12-19 10:54:42 UTC",
    "updated_date": "2025-12-19 10:54:42 UTC"
  },
  {
    "arxiv_id": "2512.20670v1",
    "title": "Disentangling Fact from Sentiment: A Dynamic Conflict-Consensus Framework for Multimodal Fake News Detection",
    "authors": [
      "Weilin Zhou",
      "Zonghao Ying",
      "Junjie Mu",
      "Shengwei Tian",
      "Quanchen Zou",
      "Deyue Zhang",
      "Dongdong Yang",
      "Xiangzheng Zhang"
    ],
    "abstract": "Prevalent multimodal fake news detection relies on consistency-based fusion, yet this paradigm fundamentally misinterprets critical cross-modal discrepancies as noise, leading to over-smoothing, which dilutes critical evidence of fabrication. Mainstream consistency-based fusion inherently minimizes feature discrepancies to align modalities, yet this approach fundamentally fails because it inadvertently smoothes out the subtle cross-modal contradictions that serve as the primary evidence of fabrication. To address this, we propose the Dynamic Conflict-Consensus Framework (DCCF), an inconsistency-seeking paradigm designed to amplify rather than suppress contradictions. First, DCCF decouples inputs into independent Fact and Sentiment spaces to distinguish objective mismatches from emotional dissonance. Second, we employ physics-inspired feature dynamics to iteratively polarize these representations, actively extracting maximally informative conflicts. Finally, a conflict-consensus mechanism standardizes these local discrepancies against the global context for robust deliberative judgment.Extensive experiments conducted on three real world datasets demonstrate that DCCF consistently outperforms state-of-the-art baselines, achieving an average accuracy improvement of 3.52\\%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20670v1",
    "published_date": "2025-12-19 10:20:32 UTC",
    "updated_date": "2025-12-19 10:20:32 UTC"
  },
  {
    "arxiv_id": "2512.20669v1",
    "title": "Improving Cardiac Risk Prediction Using Data Generation Techniques",
    "authors": [
      "Alexandre Cabodevila",
      "Pedro Gamallo-Fernandez",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "abstract": "Cardiac rehabilitation constitutes a structured clinical process involving multiple interdependent phases, individualized medical decisions, and the coordinated participation of diverse healthcare professionals. This sequential and adaptive nature enables the program to be modeled as a business process, thereby facilitating its analysis. Nevertheless, studies in this context face significant limitations inherent to real-world medical databases: data are often scarce due to both economic costs and the time required for collection; many existing records are not suitable for specific analytical purposes; and, finally, there is a high prevalence of missing values, as not all patients undergo the same diagnostic tests. To address these limitations, this work proposes an architecture based on a Conditional Variational Autoencoder (CVAE) for the synthesis of realistic clinical records that are coherent with real-world observations. The primary objective is to increase the size and diversity of the available datasets in order to enhance the performance of cardiac risk prediction models and to reduce the need for potentially hazardous diagnostic procedures, such as exercise stress testing. The results demonstrate that the proposed architecture is capable of generating coherent and realistic synthetic data, whose use improves the accuracy of the various classifiers employed for cardiac risk detection, outperforming state-of-the-art deep learning approaches for synthetic data generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20669v1",
    "published_date": "2025-12-19 10:17:00 UTC",
    "updated_date": "2025-12-19 10:17:00 UTC"
  },
  {
    "arxiv_id": "2512.17419v1",
    "title": "SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories",
    "authors": [
      "Lilin Wang",
      "Lucas Ramalho",
      "Alan Celestino",
      "Phuc Anthony Pham",
      "Yu Liu",
      "Umang Kumar Sinha",
      "Andres Portillo",
      "Onassis Osunwa",
      "Gabriel Maduekwe"
    ],
    "abstract": "Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17419v1",
    "published_date": "2025-12-19 10:16:51 UTC",
    "updated_date": "2025-12-19 10:16:51 UTC"
  },
  {
    "arxiv_id": "2512.17412v1",
    "title": "Optimisation of Aircraft Maintenance Schedules",
    "authors": [
      "Neil Urquhart",
      "Amir Rahimi",
      "Efstathios-Al. Tingas"
    ],
    "abstract": "We present an aircraft maintenance scheduling problem, which requires suitably qualified staff to be assigned to maintenance tasks on each aircraft. The tasks on each aircraft must be completed within a given turn around window so that the aircraft may resume revenue earning service. This paper presents an initial study based on the application of an Evolutionary Algorithm to the problem. Evolutionary Algorithms evolve a solution to a problem by evaluating many possible solutions, focusing the search on those solutions that are of a higher quality, as defined by a fitness function. In this paper, we benchmark the algorithm on 60 generated problem instances to demonstrate the underlying representation and associated genetic operators.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17412v1",
    "published_date": "2025-12-19 10:06:09 UTC",
    "updated_date": "2025-12-19 10:06:09 UTC"
  },
  {
    "arxiv_id": "2512.17411v1",
    "title": "Detection and Analysis of Sensitive and Illegal Content on the Ethereum Blockchain Using Machine Learning Techniques",
    "authors": [
      "Xingyu Feng"
    ],
    "abstract": "Blockchain technology, lauded for its transparent and immutable nature, introduces a novel trust model. However, its decentralized structure raises concerns about potential inclusion of malicious or illegal content. This study focuses on Ethereum, presenting a data identification and restoration algorithm. Successfully recovering 175 common files, 296 images, and 91,206 texts, we employed the FastText algorithm for sentiment analysis, achieving a 0.9 accuracy after parameter tuning. Classification revealed 70,189 neutral, 5,208 positive, and 15,810 negative texts, aiding in identifying sensitive or illicit information. Leveraging the NSFWJS library, we detected seven indecent images with 100% accuracy. Our findings expose the coexistence of benign and harmful content on the Ethereum blockchain, including personal data, explicit images, divisive language, and racial discrimination. Notably, sensitive information targeted Chinese government officials. Proposing preventative measures, our study offers valuable insights for public comprehension of blockchain technology and regulatory agency guidance. The algorithms employed present innovative solutions to address blockchain data privacy and security concerns.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17411v1",
    "published_date": "2025-12-19 10:04:52 UTC",
    "updated_date": "2025-12-19 10:04:52 UTC"
  },
  {
    "arxiv_id": "2512.20668v1",
    "title": "Forward Only Learning for Orthogonal Neural Networks of any Depth",
    "authors": [
      "Paul Caillon",
      "Alex Colagrande",
      "Erwan Fagnou",
      "Blaise Delattre",
      "Alexandre Allauzen"
    ],
    "abstract": "Backpropagation is still the de facto algorithm used today to\n  train neural networks.\n  With the exponential growth of recent architectures, the\n  computational cost of this algorithm also becomes a burden. The\n  recent PEPITA and forward-only frameworks have proposed promising\n  alternatives, but they failed to scale up to a handful of hidden\n  layers, yet limiting their use.\n  In this paper, we first analyze theoretically the main limitations of\n  these approaches. It allows us the design of a forward-only\n  algorithm, which is equivalent to backpropagation under the linear\n  and orthogonal assumptions. By relaxing the linear assumption, we\n  then introduce FOTON (Forward-Only Training of Orthogonal Networks)\n  that bridges the gap with the backpropagation\n  algorithm. Experimental results show that it outperforms PEPITA,\n  enabling us to train neural networks of any depth, without the need\n  for a backward pass.\n  Moreover its performance on convolutional networks clearly opens up avenues for its application to more\n  advanced architectures. The code is open-sourced at https://github.com/p0lcAi/FOTON .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20668v1",
    "published_date": "2025-12-19 10:03:34 UTC",
    "updated_date": "2025-12-19 10:03:34 UTC"
  },
  {
    "arxiv_id": "2512.17396v1",
    "title": "RadImageNet-VQA: A Large-Scale CT and MRI Dataset for Radiologic Visual Question Answering",
    "authors": [
      "Léo Butsanets",
      "Charles Corbière",
      "Julien Khlaut",
      "Pierre Manceron",
      "Corentin Dancette"
    ],
    "abstract": "In this work, we introduce RadImageNet-VQA, a large-scale dataset designed to advance radiologic visual question answering (VQA) on CT and MRI exams. Existing medical VQA datasets are limited in scale, dominated by X-ray imaging or biomedical illustrations, and often prone to text-based shortcuts. RadImageNet-VQA is built from expert-curated annotations and provides 750K images paired with 7.5M question-answer samples. It covers three key tasks - abnormality detection, anatomy recognition, and pathology identification - spanning eight anatomical regions and 97 pathology categories, and supports open-ended, closed-ended, and multiple-choice questions. Extensive experiments show that state-of-the-art vision-language models still struggle with fine-grained pathology identification, particularly in open-ended settings and even after fine-tuning. Text-only analysis further reveals that model performance collapses to near-random without image inputs, confirming that RadImageNet-VQA is free from linguistic shortcuts. The full dataset and benchmark are publicly available at https://huggingface.co/datasets/raidium/RadImageNet-VQA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint, 23 pages, 12 figures, 7 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.17396v1",
    "published_date": "2025-12-19 09:47:54 UTC",
    "updated_date": "2025-12-19 09:47:54 UTC"
  },
  {
    "arxiv_id": "2512.17373v2",
    "title": "Dialectics for Artificial Intelligence",
    "authors": [
      "Zhengmian Hu"
    ],
    "abstract": "Can artificial intelligence discover, from raw experience and without human supervision, concepts that humans have discovered? One challenge is that human concepts themselves are fluid: conceptual boundaries can shift, split, and merge as inquiry progresses (e.g., Pluto is no longer considered a planet). To make progress, we need a definition of \"concept\" that is not merely a dictionary label, but a structure that can be revised, compared, and aligned across agents. We propose an algorithmic-information viewpoint that treats a concept as an information object defined only through its structural relation to an agent's total experience. The core constraint is determination: a set of parts forms a reversible consistency relation if any missing part is recoverable from the others (up to the standard logarithmic slack in Kolmogorov-style identities). This reversibility prevents \"concepts\" from floating free of experience and turns concept existence into a checkable structural claim. To judge whether a decomposition is natural, we define excess information, measuring the redundancy overhead introduced by splitting experience into multiple separately described parts. On top of these definitions, we formulate dialectics as an optimization dynamics: as new patches of information appear (or become contested), competing concepts bid to explain them via shorter conditional descriptions, driving systematic expansion, contraction, splitting, and merging. Finally, we formalize low-cost concept transmission and multi-agent alignment using small grounds/seeds that allow another agent to reconstruct the same concept under a shared protocol, making communication a concrete compute-bits trade-off.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17373v2",
    "published_date": "2025-12-19 09:17:21 UTC",
    "updated_date": "2025-12-23 08:23:39 UTC"
  },
  {
    "arxiv_id": "2512.17370v2",
    "title": "TakeAD: Preference-based Post-optimization for End-to-end Autonomous Driving with Expert Takeover Data",
    "authors": [
      "Deqing Liu",
      "Yinfeng Gao",
      "Deheng Qian",
      "Qichao Zhang",
      "Xiaoqing Ye",
      "Junyu Han",
      "Yupeng Zheng",
      "Xueyi Liu",
      "Zhongpu Xia",
      "Dawei Ding",
      "Yifeng Pan",
      "Dongbin Zhao"
    ],
    "abstract": "Existing end-to-end autonomous driving methods typically rely on imitation learning (IL) but face a key challenge: the misalignment between open-loop training and closed-loop deployment. This misalignment often triggers driver-initiated takeovers and system disengagements during closed-loop execution. How to leverage those expert takeover data from disengagement scenarios and effectively expand the IL policy's capability presents a valuable yet unexplored challenge. In this paper, we propose TakeAD, a novel preference-based post-optimization framework that fine-tunes the pre-trained IL policy with this disengagement data to enhance the closed-loop driving performance. First, we design an efficient expert takeover data collection pipeline inspired by human takeover mechanisms in real-world autonomous driving systems. Then, this post optimization framework integrates iterative Dataset Aggregation (DAgger) for imitation learning with Direct Preference Optimization (DPO) for preference alignment. The DAgger stage equips the policy with fundamental capabilities to handle disengagement states through direct imitation of expert interventions. Subsequently, the DPO stage refines the policy's behavior to better align with expert preferences in disengagement scenarios. Through multiple iterations, the policy progressively learns recovery strategies for disengagement states, thereby mitigating the open-loop gap. Experiments on the closed-loop Bench2Drive benchmark demonstrate our method's effectiveness compared with pure IL methods, with comprehensive ablations confirming the contribution of each component.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "This work has been accepted by IEEE RA-L. Manuscript submitted: July, 8, 2025; Accepted: November, 24, 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.17370v2",
    "published_date": "2025-12-19 09:12:44 UTC",
    "updated_date": "2025-12-22 03:20:46 UTC"
  },
  {
    "arxiv_id": "2512.17352v1",
    "title": "Adaptive Graph Pruning with Sudden-Events Evaluation for Traffic Prediction using Online Semi-Decentralized ST-GNNs",
    "authors": [
      "Ivan Kralj",
      "Lodovico Giaretta",
      "Gordan Ježić",
      "Ivana Podnar Žarko",
      "Šarūnas Girdzijauskas"
    ],
    "abstract": "Spatio-Temporal Graph Neural Networks (ST-GNNs) are well-suited for processing high-frequency data streams from geographically distributed sensors in smart mobility systems. However, their deployment at the edge across distributed compute nodes (cloudlets) createssubstantial communication overhead due to repeated transmission of overlapping node features between neighbouring cloudlets. To address this, we propose an adaptive pruning algorithm that dynamically filters redundant neighbour features while preserving the most informative spatial context for prediction. The algorithm adjusts pruning rates based on recent model performance, allowing each cloudlet to focus on regions experiencing traffic changes without compromising accuracy. Additionally, we introduce the Sudden Event Prediction Accuracy (SEPA), a novel event-focused metric designed to measure responsiveness to traffic slowdowns and recoveries, which are often missed by standard error metrics. We evaluate our approach in an online semi-decentralized setting with traditional FL, server-free FL, and Gossip Learning on two large-scale traffic datasets, PeMS-BAY and PeMSD7-M, across short-, mid-, and long-term prediction horizons. Experiments show that, in contrast to standard metrics, SEPA exposes the true value of spatial connectivity in predicting dynamic and irregular traffic. Our adaptive pruning algorithm maintains prediction accuracy while significantly lowering communication cost in all online semi-decentralized settings, demonstrating that communication can be reduced without compromising responsiveness to critical traffic events.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 6 figures, 5 tables, journal",
    "pdf_url": "https://arxiv.org/pdf/2512.17352v1",
    "published_date": "2025-12-19 08:48:36 UTC",
    "updated_date": "2025-12-19 08:48:36 UTC"
  },
  {
    "arxiv_id": "2512.23726v1",
    "title": "q3-MuPa: Quick, Quiet, Quantitative Multi-Parametric MRI using Physics-Informed Diffusion Models",
    "authors": [
      "Shishuai Wang",
      "Florian Wiesinger",
      "Noemi Sgambelluri",
      "Carolin Pirkl",
      "Stefan Klein",
      "Juan A. Hernandez-Tamames",
      "Dirk H. J. Poot"
    ],
    "abstract": "The 3D fast silent multi-parametric mapping sequence with zero echo time (MuPa-ZTE) is a novel quantitative MRI (qMRI) acquisition that enables nearly silent scanning by using a 3D phyllotaxis sampling scheme. MuPa-ZTE improves patient comfort and motion robustness, and generates quantitative maps of T1, T2, and proton density using the acquired weighted image series. In this work, we propose a diffusion model-based qMRI mapping method that leverages both a deep generative model and physics-based data consistency to further improve the mapping performance. Furthermore, our method enables additional acquisition acceleration, allowing high-quality qMRI mapping from a fourfold-accelerated MuPa-ZTE scan (approximately 1 minute). Specifically, we trained a denoising diffusion probabilistic model (DDPM) to map MuPa-ZTE image series to qMRI maps, and we incorporated the MuPa-ZTE forward signal model as an explicit data consistency (DC) constraint during inference. We compared our mapping method against a baseline dictionary matching approach and a purely data-driven diffusion model. The diffusion models were trained entirely on synthetic data generated from digital brain phantoms, eliminating the need for large real-scan datasets. We evaluated on synthetic data, a NISM/ISMRM phantom, healthy volunteers, and a patient with brain metastases. The results demonstrated that our method produces 3D qMRI maps with high accuracy, reduced noise and better preservation of structural details. Notably, it generalised well to real scans despite training on synthetic data alone. The combination of the MuPa-ZTE acquisition and our physics-informed diffusion model is termed q3-MuPa, a quick, quiet, and quantitative multi-parametric mapping framework, and our findings highlight its strong clinical potential.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23726v1",
    "published_date": "2025-12-19 08:44:26 UTC",
    "updated_date": "2025-12-19 08:44:26 UTC"
  },
  {
    "arxiv_id": "2512.17972v1",
    "title": "Re-assessing the evidence for mental rotation abilities in children using computational models",
    "authors": [
      "Arthur Aubret",
      "Jochen Triesch"
    ],
    "abstract": "There is strong and diverse evidence for mental rotation (MR) abilities in adults. However, current evidence for MR in children rests on just a few behavioral paradigms adapted from the adult literature. Here, we leverage recent computational models of the development of children's object recognition abilities to re-assess the evidence for MR in children. The computational models simulate infants' acquisition of object representations during embodied interactions with objects. We consider two different object recognition strategies, different from MRs, and assess their ability to replicate results from three classical MR tasks assigned to children between the ages of 6 months and 5 years. Our results show that MR may play no role in producing the results obtained from children younger than 5 years. In fact, we find that a simple recognition strategy that reflects a pixel-wise comparison of stimuli is sufficient to model children's behavior in the most used MR task. Thus, our study reopens the debate on how and when children develop genuine MR abilities.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17972v1",
    "published_date": "2025-12-19 08:25:00 UTC",
    "updated_date": "2025-12-19 08:25:00 UTC"
  },
  {
    "arxiv_id": "2512.17319v1",
    "title": "A Benchmark for Ultra-High-Resolution Remote Sensing MLLMs",
    "authors": [
      "Yunkai Dang",
      "Meiyi Zhu",
      "Donghao Wang",
      "Yizhuo Zhang",
      "Jiacheng Yang",
      "Qi Fan",
      "Yuekun Yang",
      "Wenbin Li",
      "Feng Miao",
      "Yang Gao"
    ],
    "abstract": "Multimodal large language models (MLLMs) demonstrate strong perception and reasoning performance on existing remote sensing (RS) benchmarks. However, most prior benchmarks rely on low-resolution imagery, and some high-resolution benchmarks suffer from flawed reasoning-task designs. We show that text-only LLMs can perform competitively with multimodal vision-language models on RS reasoning tasks without access to images, revealing a critical mismatch between current benchmarks and the intended evaluation of visual understanding. To enable faithful assessment, we introduce RSHR-Bench, a super-high-resolution benchmark for RS visual understanding and reasoning. RSHR-Bench contains 5,329 full-scene images with a long side of at least 4,000 pixels, with up to about 3 x 10^8 pixels per image, sourced from widely used RS corpora and UAV collections. We design four task families: multiple-choice VQA, open-ended VQA, image captioning, and single-image evaluation. These tasks cover nine perception categories and four reasoning types, supporting multi-turn and multi-image dialog. To reduce reliance on language priors, we apply adversarial filtering with strong LLMs followed by rigorous human verification. Overall, we construct 3,864 VQA tasks, 3,913 image captioning tasks, and 500 fully human-written or verified single-image evaluation VQA pairs. Evaluations across open-source, closed-source, and RS-specific VLMs reveal persistent performance gaps in super-high-resolution scenarios. Code: https://github.com/Yunkaidang/RSHR",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17319v1",
    "published_date": "2025-12-19 08:07:51 UTC",
    "updated_date": "2025-12-19 08:07:51 UTC"
  },
  {
    "arxiv_id": "2512.17316v1",
    "title": "Explanation Beyond Intuition: A Testable Criterion for Inherent Explainability",
    "authors": [
      "Michael Merry",
      "Pat Riddle",
      "Jim Warren"
    ],
    "abstract": "Inherent explainability is the gold standard in Explainable Artificial Intelligence (XAI). However, there is not a consistent definition or test to demonstrate inherent explainability. Work to date either characterises explainability through metrics, or appeals to intuition - \"we know it when we see it\". We propose a globally applicable criterion for inherent explainability. The criterion uses graph theory for representing and decomposing models for structure-local explanation, and recomposing them into global explanations. We form the structure-local explanations as annotations, a verifiable hypothesis-evidence structure that allows for a range of explanatory methods to be used. This criterion matches existing intuitions on inherent explainability, and provides justifications why a large regression model may not be explainable but a sparse neural network could be. We differentiate explainable -- a model that allows for explanation -- and \\textit{explained} -- one that has a verified explanation. Finally, we provide a full explanation of PREDICT -- a Cox proportional hazards model of cardiovascular disease risk, which is in active clinical use in New Zealand. It follows that PREDICT is inherently explainable. This work provides structure to formalise other work on explainability, and allows regulators a flexible but rigorous test that can be used in compliance frameworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17316v1",
    "published_date": "2025-12-19 07:59:36 UTC",
    "updated_date": "2025-12-19 07:59:36 UTC"
  },
  {
    "arxiv_id": "2601.06053v1",
    "title": "Sports Business Administration and New Age Technology: Role of AI",
    "authors": [
      "Sahibpreet Singh",
      "Pawan Kumar"
    ],
    "abstract": "This chapter explores the complexities of sports governance, taxation, dispute resolution, and the impact of digital transformation within the sports sector. This study identifies a critical research gap regarding the integration of innovative technologies to enhance governance and talent identification in sports law. The objective is to evaluate how data-driven approaches and AI can optimize recruitment processes; also ensuring compliance with existing regulations. A comprehensive analysis of current governance structures and taxation policies,(ie Income Tax Act and GST Act), reveals preliminary results indicating that reform is necessary to support sustainable growth in the sports economy. Key findings demonstrate that AI enhances player evaluation by minimizing biases and expanding access to diverse talent pools. While the Court of Arbitration for Sport provides an efficient mechanism for dispute resolution. The implications emphasize the need for regulatory reforms that align taxation policies with international best practices, promoting transparency and accountability in sports organizations. This research contributes valuable insights into the evolving dynamics of sports management, aiming to foster innovation and integrity in the industry.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Chapter in \"Sports Law in India\" (University Book House Pvt. Ltd., 2024), pp. 122-142",
    "pdf_url": "https://arxiv.org/pdf/2601.06053v1",
    "published_date": "2025-12-19 07:58:59 UTC",
    "updated_date": "2025-12-19 07:58:59 UTC"
  },
  {
    "arxiv_id": "2512.17308v1",
    "title": "Large Language Models as Pokémon Battle Agents: Strategic Play and Content Generation",
    "authors": [
      "Daksh Jain",
      "Aarya Jain",
      "Ashutosh Desai",
      "Avyakt Verma",
      "Ishan Bhanuka",
      "Pratik Narang",
      "Dhruv Kumar"
    ],
    "abstract": "Strategic decision-making in Pokémon battles presents a unique testbed for evaluating large language models. Pokémon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language Models (LLMs) can serve as competent battle agents, capable of both making tactically sound decisions and generating novel, balanced game content. We developed a turn-based Pokémon battle system where LLMs select moves based on battle state rather than pre-programmed logic. The framework captures essential Pokémon mechanics: type effectiveness multipliers, stat-based damage calculations, and multi-Pokémon team management. Through systematic evaluation across multiple model architectures we measured win rates, decision latency, type-alignment accuracy, and token efficiency. These results suggest LLMs can function as dynamic game opponents without domain-specific training, offering a practical alternative to reinforcement learning for turn-based strategic games. The dual capability of tactical reasoning and content creation, positions LLMs as both players and designers, with implications for procedural generation and adaptive difficulty systems in interactive entertainment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2512.17308v1",
    "published_date": "2025-12-19 07:46:29 UTC",
    "updated_date": "2025-12-19 07:46:29 UTC"
  },
  {
    "arxiv_id": "2512.17299v2",
    "title": "M2RU: Memristive Minion Recurrent Unit for On-Chip Continual Learning at the Edge",
    "authors": [
      "Abdullah M. Zyarah",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "Continual learning on edge platforms remains challenging because recurrent networks depend on energy-intensive training procedures and frequent data movement that are impractical for embedded deployments. This work introduces M2RU, a mixed-signal architecture that implements the minion recurrent unit for efficient temporal processing with on-chip continual learning. The architecture integrates weighted-bit streaming, which enables multi-bit digital inputs to be processed in crossbars without high-resolution conversion, and an experience replay mechanism that stabilizes learning under domain shifts. M2RU achieves 15 GOPS at 48.62 mW, corresponding to 312 GOPS per watt, and maintains accuracy within 5 percent of software baselines on sequential MNIST and CIFAR-10 tasks. Compared with a CMOS digital design, the accelerator provides 29X improvement in energy efficiency. Device-aware analysis shows an expected operational lifetime of 12.2 years under continual learning workloads. These results establish M2RU as a scalable and energy-efficient platform for real-time adaptation in edge-level temporal intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17299v2",
    "published_date": "2025-12-19 07:27:30 UTC",
    "updated_date": "2025-12-26 15:06:09 UTC"
  },
  {
    "arxiv_id": "2512.17293v1",
    "title": "Robust TTS Training via Self-Purifying Flow Matching for the WildSpoof 2026 TTS Track",
    "authors": [
      "June Young Yi",
      "Hyeongju Kim",
      "Juheon Lee"
    ],
    "abstract": "This paper presents a lightweight text-to-speech (TTS) system developed for the WildSpoof Challenge TTS Track. Our approach fine-tunes the recently released open-weight TTS model, \\textit{Supertonic}\\footnote{\\url{https://github.com/supertone-inc/supertonic}}, with Self-Purifying Flow Matching (SPFM) to enable robust adaptation to in-the-wild speech. SPFM mitigates label noise by comparing conditional and unconditional flow matching losses on each sample, routing suspicious text--speech pairs to unconditional training while still leveraging their acoustic information. The resulting model achieves the lowest Word Error Rate (WER) among all participating teams, while ranking second in perceptual metrics such as UTMOS and DNSMOS. These findings demonstrate that efficient, open-weight architectures like Supertonic can be effectively adapted to diverse real-world speech conditions when combined with explicit noise-handling mechanisms such as SPFM.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "2 pages, preprint, This work has been submitted to the IEEE for possible publication. Submitted to ICASSP 2026 SPGC (WildSpoof Challenge, TTS track)",
    "pdf_url": "https://arxiv.org/pdf/2512.17293v1",
    "published_date": "2025-12-19 07:17:43 UTC",
    "updated_date": "2025-12-19 07:17:43 UTC"
  },
  {
    "arxiv_id": "2512.17289v1",
    "title": "Subjective Question Generation and Answer Evaluation using NLP",
    "authors": [
      "G. M. Refatul Islam",
      "Safwan Shaheer",
      "Yaseen Nur",
      "Mohammad Rafid Hamid"
    ],
    "abstract": "Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 5 figures, 2 tables, conference paper",
    "pdf_url": "https://arxiv.org/pdf/2512.17289v1",
    "published_date": "2025-12-19 07:11:50 UTC",
    "updated_date": "2025-12-19 07:11:50 UTC"
  },
  {
    "arxiv_id": "2601.03267v1",
    "title": "OpenAI GPT-5 System Card",
    "authors": [
      "Aaditya Singh",
      "Adam Fry",
      "Adam Perelman",
      "Adam Tart",
      "Adi Ganesh",
      "Ahmed El-Kishky",
      "Aidan McLaughlin",
      "Aiden Low",
      "AJ Ostrow",
      "Akhila Ananthram",
      "Akshay Nathan",
      "Alan Luo",
      "Alec Helyar",
      "Aleksander Madry",
      "Aleksandr Efremov",
      "Aleksandra Spyra",
      "Alex Baker-Whitcomb",
      "Alex Beutel",
      "Alex Karpenko",
      "Alex Makelov",
      "Alex Neitz",
      "Alex Wei",
      "Alexandra Barr",
      "Alexandre Kirchmeyer",
      "Alexey Ivanov",
      "Alexi Christakis",
      "Alistair Gillespie",
      "Allison Tam",
      "Ally Bennett",
      "Alvin Wan",
      "Alyssa Huang",
      "Amy McDonald Sandjideh",
      "Amy Yang",
      "Ananya Kumar",
      "Andre Saraiva",
      "Andrea Vallone",
      "Andrei Gheorghe",
      "Andres Garcia Garcia",
      "Andrew Braunstein",
      "Andrew Liu",
      "Andrew Schmidt",
      "Andrey Mereskin",
      "Andrey Mishchenko",
      "Andy Applebaum",
      "Andy Rogerson",
      "Ann Rajan",
      "Annie Wei",
      "Anoop Kotha",
      "Anubha Srivastava",
      "Anushree Agrawal",
      "Arun Vijayvergiya",
      "Ashley Tyra",
      "Ashvin Nair",
      "Avi Nayak",
      "Ben Eggers",
      "Bessie Ji",
      "Beth Hoover",
      "Bill Chen",
      "Blair Chen",
      "Boaz Barak",
      "Borys Minaiev",
      "Botao Hao",
      "Bowen Baker",
      "Brad Lightcap",
      "Brandon McKinzie",
      "Brandon Wang",
      "Brendan Quinn",
      "Brian Fioca",
      "Brian Hsu",
      "Brian Yang",
      "Brian Yu",
      "Brian Zhang",
      "Brittany Brenner",
      "Callie Riggins Zetino",
      "Cameron Raymond",
      "Camillo Lugaresi",
      "Carolina Paz",
      "Cary Hudson",
      "Cedric Whitney",
      "Chak Li",
      "Charles Chen",
      "Charlotte Cole",
      "Chelsea Voss",
      "Chen Ding",
      "Chen Shen",
      "Chengdu Huang",
      "Chris Colby",
      "Chris Hallacy",
      "Chris Koch",
      "Chris Lu",
      "Christina Kaplan",
      "Christina Kim",
      "CJ Minott-Henriques",
      "Cliff Frey",
      "Cody Yu",
      "Coley Czarnecki",
      "Colin Reid",
      "Colin Wei",
      "Cory Decareaux",
      "Cristina Scheau",
      "Cyril Zhang",
      "Cyrus Forbes",
      "Da Tang",
      "Dakota Goldberg",
      "Dan Roberts",
      "Dana Palmie",
      "Daniel Kappler",
      "Daniel Levine",
      "Daniel Wright",
      "Dave Leo",
      "David Lin",
      "David Robinson",
      "Declan Grabb",
      "Derek Chen",
      "Derek Lim",
      "Derek Salama",
      "Dibya Bhattacharjee",
      "Dimitris Tsipras",
      "Dinghua Li",
      "Dingli Yu",
      "DJ Strouse",
      "Drew Williams",
      "Dylan Hunn",
      "Ed Bayes",
      "Edwin Arbus",
      "Ekin Akyurek",
      "Elaine Ya Le",
      "Elana Widmann",
      "Eli Yani",
      "Elizabeth Proehl",
      "Enis Sert",
      "Enoch Cheung",
      "Eri Schwartz",
      "Eric Han",
      "Eric Jiang",
      "Eric Mitchell",
      "Eric Sigler",
      "Eric Wallace",
      "Erik Ritter",
      "Erin Kavanaugh",
      "Evan Mays",
      "Evgenii Nikishin",
      "Fangyuan Li",
      "Felipe Petroski Such",
      "Filipe de Avila Belbute Peres",
      "Filippo Raso",
      "Florent Bekerman",
      "Foivos Tsimpourlas",
      "Fotis Chantzis",
      "Francis Song",
      "Francis Zhang",
      "Gaby Raila",
      "Garrett McGrath",
      "Gary Briggs",
      "Gary Yang",
      "Giambattista Parascandolo",
      "Gildas Chabot",
      "Grace Kim",
      "Grace Zhao",
      "Gregory Valiant",
      "Guillaume Leclerc",
      "Hadi Salman",
      "Hanson Wang",
      "Hao Sheng",
      "Haoming Jiang",
      "Haoyu Wang",
      "Haozhun Jin",
      "Harshit Sikchi",
      "Heather Schmidt",
      "Henry Aspegren",
      "Honglin Chen",
      "Huida Qiu",
      "Hunter Lightman",
      "Ian Covert",
      "Ian Kivlichan",
      "Ian Silber",
      "Ian Sohl",
      "Ibrahim Hammoud",
      "Ignasi Clavera",
      "Ikai Lan",
      "Ilge Akkaya",
      "Ilya Kostrikov",
      "Irina Kofman",
      "Isak Etinger",
      "Ishaan Singal",
      "Jackie Hehir",
      "Jacob Huh",
      "Jacqueline Pan",
      "Jake Wilczynski",
      "Jakub Pachocki",
      "James Lee",
      "James Quinn",
      "Jamie Kiros",
      "Janvi Kalra",
      "Jasmyn Samaroo",
      "Jason Wang",
      "Jason Wolfe",
      "Jay Chen",
      "Jay Wang",
      "Jean Harb",
      "Jeffrey Han",
      "Jeffrey Wang",
      "Jennifer Zhao",
      "Jeremy Chen",
      "Jerene Yang",
      "Jerry Tworek",
      "Jesse Chand",
      "Jessica Landon",
      "Jessica Liang",
      "Ji Lin",
      "Jiancheng Liu",
      "Jianfeng Wang",
      "Jie Tang",
      "Jihan Yin",
      "Joanne Jang",
      "Joel Morris",
      "Joey Flynn",
      "Johannes Ferstad",
      "Johannes Heidecke",
      "John Fishbein",
      "John Hallman",
      "Jonah Grant",
      "Jonathan Chien",
      "Jonathan Gordon",
      "Jongsoo Park",
      "Jordan Liss",
      "Jos Kraaijeveld",
      "Joseph Guay",
      "Joseph Mo",
      "Josh Lawson",
      "Josh McGrath",
      "Joshua Vendrow",
      "Joy Jiao",
      "Julian Lee",
      "Julie Steele",
      "Julie Wang",
      "Junhua Mao",
      "Kai Chen",
      "Kai Hayashi",
      "Kai Xiao",
      "Kamyar Salahi",
      "Kan Wu",
      "Karan Sekhri",
      "Karan Sharma",
      "Karan Singhal",
      "Karen Li",
      "Kenny Nguyen",
      "Keren Gu-Lemberg",
      "Kevin King",
      "Kevin Liu",
      "Kevin Stone",
      "Kevin Yu",
      "Kristen Ying",
      "Kristian Georgiev",
      "Kristie Lim",
      "Kushal Tirumala",
      "Kyle Miller",
      "Lama Ahmad",
      "Larry Lv",
      "Laura Clare",
      "Laurance Fauconnet",
      "Lauren Itow",
      "Lauren Yang",
      "Laurentia Romaniuk",
      "Leah Anise",
      "Lee Byron",
      "Leher Pathak",
      "Leon Maksin",
      "Leyan Lo",
      "Leyton Ho",
      "Li Jing",
      "Liang Wu",
      "Liang Xiong",
      "Lien Mamitsuka",
      "Lin Yang",
      "Lindsay McCallum",
      "Lindsey Held",
      "Liz Bourgeois",
      "Logan Engstrom",
      "Lorenz Kuhn",
      "Louis Feuvrier",
      "Lu Zhang",
      "Lucas Switzer",
      "Lukas Kondraciuk",
      "Lukasz Kaiser",
      "Manas Joglekar",
      "Mandeep Singh",
      "Mandip Shah",
      "Manuka Stratta",
      "Marcus Williams",
      "Mark Chen",
      "Mark Sun",
      "Marselus Cayton",
      "Martin Li",
      "Marvin Zhang",
      "Marwan Aljubeh",
      "Matt Nichols",
      "Matthew Haines",
      "Max Schwarzer",
      "Mayank Gupta",
      "Meghan Shah",
      "Melody Huang",
      "Meng Dong",
      "Mengqing Wang",
      "Mia Glaese",
      "Micah Carroll",
      "Michael Lampe",
      "Michael Malek",
      "Michael Sharman",
      "Michael Zhang",
      "Michele Wang",
      "Michelle Pokrass",
      "Mihai Florian",
      "Mikhail Pavlov",
      "Miles Wang",
      "Ming Chen",
      "Mingxuan Wang",
      "Minnia Feng",
      "Mo Bavarian",
      "Molly Lin",
      "Moose Abdool",
      "Mostafa Rohaninejad",
      "Nacho Soto",
      "Natalie Staudacher",
      "Natan LaFontaine",
      "Nathan Marwell",
      "Nelson Liu",
      "Nick Preston",
      "Nick Turley",
      "Nicklas Ansman",
      "Nicole Blades",
      "Nikil Pancha",
      "Nikita Mikhaylin",
      "Niko Felix",
      "Nikunj Handa",
      "Nishant Rai",
      "Nitish Keskar",
      "Noam Brown",
      "Ofir Nachum",
      "Oleg Boiko",
      "Oleg Murk",
      "Olivia Watkins",
      "Oona Gleeson",
      "Pamela Mishkin",
      "Patryk Lesiewicz",
      "Paul Baltescu",
      "Pavel Belov",
      "Peter Zhokhov",
      "Philip Pronin",
      "Phillip Guo",
      "Phoebe Thacker",
      "Qi Liu",
      "Qiming Yuan",
      "Qinghua Liu",
      "Rachel Dias",
      "Rachel Puckett",
      "Rahul Arora",
      "Ravi Teja Mullapudi",
      "Raz Gaon",
      "Reah Miyara",
      "Rennie Song",
      "Rishabh Aggarwal",
      "RJ Marsan",
      "Robel Yemiru",
      "Robert Xiong",
      "Rohan Kshirsagar",
      "Rohan Nuttall",
      "Roman Tsiupa",
      "Ronen Eldan",
      "Rose Wang",
      "Roshan James",
      "Roy Ziv",
      "Rui Shu",
      "Ruslan Nigmatullin",
      "Saachi Jain",
      "Saam Talaie",
      "Sam Altman",
      "Sam Arnesen",
      "Sam Toizer",
      "Sam Toyer",
      "Samuel Miserendino",
      "Sandhini Agarwal",
      "Sarah Yoo",
      "Savannah Heon",
      "Scott Ethersmith",
      "Sean Grove",
      "Sean Taylor",
      "Sebastien Bubeck",
      "Sever Banesiu",
      "Shaokyi Amdo",
      "Shengjia Zhao",
      "Sherwin Wu",
      "Shibani Santurkar",
      "Shiyu Zhao",
      "Shraman Ray Chaudhuri",
      "Shreyas Krishnaswamy",
      "Shuaiqi",
      "Xia",
      "Shuyang Cheng",
      "Shyamal Anadkat",
      "Simón Posada Fishman",
      "Simon Tobin",
      "Siyuan Fu",
      "Somay Jain",
      "Song Mei",
      "Sonya Egoian",
      "Spencer Kim",
      "Spug Golden",
      "SQ Mah",
      "Steph Lin",
      "Stephen Imm",
      "Steve Sharpe",
      "Steve Yadlowsky",
      "Sulman Choudhry",
      "Sungwon Eum",
      "Suvansh Sanjeev",
      "Tabarak Khan",
      "Tal Stramer",
      "Tao Wang",
      "Tao Xin",
      "Tarun Gogineni",
      "Taya Christianson",
      "Ted Sanders",
      "Tejal Patwardhan",
      "Thomas Degry",
      "Thomas Shadwell",
      "Tianfu Fu",
      "Tianshi Gao",
      "Timur Garipov",
      "Tina Sriskandarajah",
      "Toki Sherbakov",
      "Tomer Kaftan",
      "Tomo Hiratsuka",
      "Tongzhou Wang",
      "Tony Song",
      "Tony Zhao",
      "Troy Peterson",
      "Val Kharitonov",
      "Victoria Chernova",
      "Vineet Kosaraju",
      "Vishal Kuo",
      "Vitchyr Pong",
      "Vivek Verma",
      "Vlad Petrov",
      "Wanning Jiang",
      "Weixing Zhang",
      "Wenda Zhou",
      "Wenlei Xie",
      "Wenting Zhan",
      "Wes McCabe",
      "Will DePue",
      "Will Ellsworth",
      "Wulfie Bain",
      "Wyatt Thompson",
      "Xiangning Chen",
      "Xiangyu Qi",
      "Xin Xiang",
      "Xinwei Shi",
      "Yann Dubois",
      "Yaodong Yu",
      "Yara Khakbaz",
      "Yifan Wu",
      "Yilei Qian",
      "Yin Tat Lee",
      "Yinbo Chen",
      "Yizhen Zhang",
      "Yizhong Xiong",
      "Yonglong Tian",
      "Young Cha",
      "Yu Bai",
      "Yu Yang",
      "Yuan Yuan",
      "Yuanzhi Li",
      "Yufeng Zhang",
      "Yuguang Yang",
      "Yujia Jin",
      "Yun Jiang",
      "Yunyun Wang",
      "Yushi Wang",
      "Yutian Liu",
      "Zach Stubenvoll",
      "Zehao Dou",
      "Zheng Wu",
      "Zhigang Wang"
    ],
    "abstract": "This is the system card published alongside the OpenAI GPT-5 launch, August 2025.\n  GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say 'think hard about this' in the prompt). The router is continuously trained on real signals, including when users switch models, preference rates for responses, and measured correctness, improving over time. Once usage limits are reached, a mini version of each model handles remaining queries.\n  This system card focuses primarily on gpt-5-thinking and gpt-5-main, while evaluations for other models are available in the appendix. The GPT-5 system not only outperforms previous models on benchmarks and answers questions more quickly, but -- more importantly -- is more useful for real-world queries. We've made significant advances in reducing hallucinations, improving instruction following, and minimizing sycophancy, and have leveled up GPT-5's performance in three of ChatGPT's most common uses: writing, coding, and health. All of the GPT-5 models additionally feature safe-completions, our latest approach to safety training to prevent disallowed content.\n  Similarly to ChatGPT agent, we have decided to treat gpt-5-thinking as High capability in the Biological and Chemical domain under our Preparedness Framework, activating the associated safeguards. While we do not have definitive evidence that this model could meaningfully help a novice to create severe biological harm -- our defined threshold for High capability -- we have chosen to take a precautionary approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.03267v1",
    "published_date": "2025-12-19 07:05:38 UTC",
    "updated_date": "2025-12-19 07:05:38 UTC"
  },
  {
    "arxiv_id": "2512.17278v1",
    "title": "WDFFU-Mamba: A Wavelet-guided Dual-attention Feature Fusion Mamba for Breast Tumor Segmentation in Ultrasound Images",
    "authors": [
      "Guoping Cai",
      "Houjin Chen",
      "Yanfeng Li",
      "Jia Sun",
      "Ziwei Chen",
      "Qingzi Geng"
    ],
    "abstract": "Breast ultrasound (BUS) image segmentation plays a vital role in assisting clinical diagnosis and early tumor screening. However, challenges such as speckle noise, imaging artifacts, irregular lesion morphology, and blurred boundaries severely hinder accurate segmentation. To address these challenges, this work aims to design a robust and efficient model capable of automatically segmenting breast tumors in BUS images.We propose a novel segmentation network named WDFFU-Mamba, which integrates wavelet-guided enhancement and dual-attention feature fusion within a U-shaped Mamba architecture. A Wavelet-denoised High-Frequency-guided Feature (WHF) module is employed to enhance low-level representations through noise-suppressed high-frequency cues. A Dual Attention Feature Fusion (DAFF) module is also introduced to effectively merge skip-connected and semantic features, improving contextual consistency.Extensive experiments on two public BUS datasets demonstrate that WDFFU-Mamba achieves superior segmentation accuracy, significantly outperforming existing methods in terms of Dice coefficient and 95th percentile Hausdorff Distance (HD95).The combination of wavelet-domain enhancement and attention-based fusion greatly improves both the accuracy and robustness of BUS image segmentation, while maintaining computational efficiency.The proposed WDFFU-Mamba model not only delivers strong segmentation performance but also exhibits desirable generalization ability across datasets, making it a promising solution for real-world clinical applications in breast tumor ultrasound analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17278v1",
    "published_date": "2025-12-19 06:50:03 UTC",
    "updated_date": "2025-12-19 06:50:03 UTC"
  },
  {
    "arxiv_id": "2512.17270v1",
    "title": "Understanding Generalization in Role-Playing Models via Information Theory",
    "authors": [
      "Yongqi Li",
      "Hao Lang",
      "Fei Huang",
      "Tieyun Qian",
      "Yongbin Li"
    ],
    "abstract": "Role-playing models (RPMs) are widely used in real-world applications but underperform when deployed in the wild. This degradation can be attributed to distribution shifts, including user, character, and dialogue compositional shifts. Existing methods like LLM-as-a-judge fall short in providing a fine-grained diagnosis of how these shifts affect RPM generalization, and thus there lack formal frameworks to characterize RPM generalization behaviors. To bridge these gaps, we introduce an information-theoretic metric, named reasoning-based effective mutual information difference (R-EMID), to measure RPM performance degradation in an interpretable way. We also derive an upper bound on R-EMID to predict the worst-case generalization performance of RPMs and theoretically reveal how various shifts contribute to the RPM performance degradation. Moreover, we propose a co-evolving reinforcement learning framework to adaptively model the connection among user, character, and dialogue context and thus enhance the estimation of dialogue response generation probability, which is critical for calculating R-EMID. Finally, we evaluate the generalization performance of various RPMs using R-EMID, finding that user shift poses the highest risk among all shifts and reinforcement learning is the most effective approach for enhancing RPM generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17270v1",
    "published_date": "2025-12-19 06:37:44 UTC",
    "updated_date": "2025-12-19 06:37:44 UTC"
  },
  {
    "arxiv_id": "2512.20666v1",
    "title": "Dominating vs. Dominated: Generative Collapse in Diffusion Models",
    "authors": [
      "Hayeon Jeong",
      "Jong-Seok Lee"
    ],
    "abstract": "Text-to-image diffusion models have drawn significant attention for their ability to generate diverse and high-fidelity images. However, when generating from multi-concept prompts, one concept token often dominates the generation, suppressing the others-a phenomenon we term the Dominant-vs-Dominated (DvD) imbalance. To systematically analyze this imbalance, we introduce DominanceBench and examine its causes from both data and architectural perspectives. Through various experiments, we show that the limited instance diversity in training data exacerbates the inter-concept interference. Analysis of cross-attention dynamics further reveals that dominant tokens rapidly saturate attention, progressively suppressing others across diffusion timesteps. In addition, head ablation studies show that the DvD behavior arises from distributed attention mechanisms across multiple heads. Our findings provide key insights into generative collapse, advancing toward more reliable and controllable text-to-image generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20666v1",
    "published_date": "2025-12-19 06:36:15 UTC",
    "updated_date": "2025-12-19 06:36:15 UTC"
  },
  {
    "arxiv_id": "2512.17267v1",
    "title": "AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators",
    "authors": [
      "Michael J. Ryan",
      "Yanzhe Zhang",
      "Amol Salunkhe",
      "Yi Chu",
      "Di Xu",
      "Diyi Yang"
    ],
    "abstract": "Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17267v1",
    "published_date": "2025-12-19 06:32:46 UTC",
    "updated_date": "2025-12-19 06:32:46 UTC"
  },
  {
    "arxiv_id": "2601.06052v2",
    "title": "Reinforcement Learning for Chain of Thought Compression with One-Domain-to-All Generalization",
    "authors": [
      "Hanyu Li",
      "Jiangshan Duo",
      "Bofei Gao",
      "Hailin Zhang",
      "Sujian Li",
      "Xiaotie Deng",
      "Liang Zhao"
    ],
    "abstract": "Chain-of-thought reasoning in large language models can trigger an \"overthinking trap\": longer rollouts raise cost and latency yet often yield unreliable accuracy gains. Existing methods use global, static controls that may suppress needed reasoning. We propose mastery-gated, sample-level, soft reinforcement learning compression that penalizes long rollouts only when the model already solves the problem and has produced a shorter rollout. Across benchmarks, it cuts response length by 20-40% with comparable or higher accuracy and generalizes across domains: a model trained on math spontaneously shortens unseen tasks (code, instruction following, general-knowledge QA) without hurting accuracy. We further show two-way transfer between non-agent CoT and tool-use agents: non-agent training reduces SWE-Bench Verified rounds by 13%, while compressing a thinking agent cuts SWE trajectories by 67% tokens and 52% rounds and shortens non-agent outputs by up to 44%. Compression is thus not cosmetic brevity, but an inherent computation policy -- what to keep, and what to forget.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06052v2",
    "published_date": "2025-12-19 06:30:54 UTC",
    "updated_date": "2026-01-21 06:34:10 UTC"
  },
  {
    "arxiv_id": "2512.17266v2",
    "title": "ScoutGPT: Capturing Player Impact from Team Action Sequences Using GPT-Based Framework",
    "authors": [
      "Miru Hong",
      "Minho Lee",
      "Geonhee Jo",
      "Jae-Hee So",
      "Pascal Bauer",
      "Sang-Ki Ko"
    ],
    "abstract": "Transfers play a pivotal role in shaping a football club's success, yet forecasting whether a transfer will succeed remains difficult due to the strong context-dependence of on-field performance. Existing evaluation practices often rely on static summary statistics or post-hoc value models, which fail to capture how a player's contribution adapts to a new tactical environment or different teammates. To address this gap, we introduce EventGPT, a player-conditioned, value-aware next-event prediction model built on a GPT-style autoregressive transformer. Our model treats match play as a sequence of discrete tokens, jointly learning to predict the next on-ball action's type, location, timing, and its estimated residual On-Ball Value (rOBV) based on the preceding context and player identity. A key contribution of this framework is the ability to perform counterfactual simulations. By substituting learned player embeddings into new event sequences, we can simulate how a player's behavioral distribution and value profile would change when placed in a different team or tactical structure. Evaluated on five seasons of Premier League event data, EventGPT outperforms existing sequence-based baselines in next-event prediction accuracy and spatial precision. Furthermore, we demonstrate the model's practical utility for transfer analysis through case studies-such as comparing striker performance across different systems and identifying stylistic replacements for specific roles-showing that our approach provides a principled method for evaluating transfer fit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures, 7 tables. To appear in Hudl Performance Insights 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.17266v2",
    "published_date": "2025-12-19 06:30:11 UTC",
    "updated_date": "2025-12-23 06:52:01 UTC"
  },
  {
    "arxiv_id": "2512.17970v1",
    "title": "CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs",
    "authors": [
      "Gunho Park",
      "Jeongin Bae",
      "Byeongwook Kim",
      "Baeseong park",
      "Jiwon Ryu",
      "Hoseung Kim",
      "Se Jung Kwon",
      "Dongsoo Lee"
    ],
    "abstract": "Weight-only quantization is widely used to mitigate the memory-bound nature of LLM inference. Codebook-based methods extend this trend by achieving strong accuracy in the extremely low-bit regime (e.g., 2-bit). However, current kernels rely on dequantization, which repeatedly fetches centroids and reconstructs weights, incurring substantial latency and cache pressure. We present CodeGEMM, a codebook-centric GEMM kernel that replaces dequantization with precomputed inner products between centroids and activations stored in a lightweight Psumbook. At inference, code indices directly gather these partial sums, eliminating per-element lookups and reducing the on-chip footprint. The kernel supports the systematic exploration of latency-memory-accuracy trade-offs under a unified implementation. On Llama-3 models, CodeGEMM delivers 1.83x (8B) and 8.93x (70B) speedups in the 2-bit configuration compared to state-of-the-art codebook-based quantization at comparable accuracy and further improves computing efficiency and memory subsystem utilization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.17970v1",
    "published_date": "2025-12-19 06:16:32 UTC",
    "updated_date": "2025-12-19 06:16:32 UTC"
  },
  {
    "arxiv_id": "2512.17259v1",
    "title": "Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems",
    "authors": [
      "Abhivansh Gupta"
    ],
    "abstract": "As LLM-based agents grow more autonomous and multi-modal, ensuring they remain controllable, auditable, and faithful to deployer intent becomes critical. Prior benchmarks measured the propensity for misaligned behavior and showed that agent personalities and tool access significantly influence misalignment. Building on these insights, we propose a Verifiability-First architecture that (1) integrates run-time attestations of agent actions using cryptographic and symbolic methods, (2) embeds lightweight Audit Agents that continuously verify intent versus behavior using constrained reasoning, and (3) enforces challenge-response attestation protocols for high-risk operations. We introduce OPERA (Observability, Provable Execution, Red-team, Attestation), a benchmark suite and evaluation protocol designed to measure (i) detectability of misalignment, (ii) time to detection under stealthy strategies, and (iii) resilience of verifiability mechanisms to adversarial prompt and persona injection. Our approach shifts the evaluation focus from how likely misalignment is to how quickly and reliably misalignment can be detected and remediated.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17259v1",
    "published_date": "2025-12-19 06:12:43 UTC",
    "updated_date": "2025-12-19 06:12:43 UTC"
  },
  {
    "arxiv_id": "2512.17255v1",
    "title": "From Priors to Predictions: Explaining and Visualizing Human Reasoning in a Graph Neural Network Framework",
    "authors": [
      "Quan Do",
      "Caroline Ahn",
      "Leah Bakst",
      "Michael Pascale",
      "Joseph T. McGuire",
      "Chantal E. Stern",
      "Michael E. Hasselmo"
    ],
    "abstract": "Humans excel at solving novel reasoning problems from minimal exposure, guided by inductive biases, assumptions about which entities and relationships matter. Yet the computational form of these biases and their neural implementation remain poorly understood. We introduce a framework that combines Graph Theory and Graph Neural Networks (GNNs) to formalize inductive biases as explicit, manipulable priors over structure and abstraction. Using a human behavioral dataset adapted from the Abstraction and Reasoning Corpus (ARC), we show that differences in graph-based priors can explain individual differences in human solutions. Our method includes an optimization pipeline that searches over graph configurations, varying edge connectivity and node abstraction, and a visualization approach that identifies the computational graph, the subset of nodes and edges most critical to a model's prediction. Systematic ablation reveals how generalization depends on specific prior structures and internal processing, exposing why human like errors emerge from incorrect or incomplete priors. This work provides a principled, interpretable framework for modeling the representational assumptions and computational dynamics underlying generalization, offering new insights into human reasoning and a foundation for more human aligned AI systems.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "44 pages, 7 figures, 3 suppl figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17255v1",
    "published_date": "2025-12-19 05:56:48 UTC",
    "updated_date": "2025-12-19 05:56:48 UTC"
  },
  {
    "arxiv_id": "2512.17251v1",
    "title": "AlignDP: Hybrid Differential Privacy with Rarity-Aware Protection for LLMs",
    "authors": [
      "Madhava Gaikwad"
    ],
    "abstract": "Large language models are exposed to risks of extraction, distillation, and unauthorized fine-tuning. Existing defenses use watermarking or monitoring, but these act after leakage. We design AlignDP, a hybrid privacy lock that blocks knowledge transfer at the data interface. The key idea is to separate rare and non-rare fields. Rare fields are shielded by PAC indistinguishability, giving effective zero-epsilon local DP. Non-rare fields are privatized with RAPPOR, giving unbiased frequency estimates under local DP. A global aggregator enforces composition and budget. This two-tier design hides rare events and adds controlled noise to frequent events. We prove limits of PAC extension to global aggregation, give bounds for RAPPOR estimates, and analyze utility trade-off. A toy simulation confirms feasibility: rare categories remain hidden, frequent categories are recovered with small error.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: LOCK-LLM Work-shop, NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.17251v1",
    "published_date": "2025-12-19 05:36:23 UTC",
    "updated_date": "2025-12-19 05:36:23 UTC"
  },
  {
    "arxiv_id": "2512.17250v1",
    "title": "Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction",
    "authors": [
      "Ziyang Lin",
      "Zixuan Sun",
      "Sanhorn Chen",
      "Xiaoyang Chen",
      "Roy Zhao"
    ],
    "abstract": "Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to model-based control with TD-MPC2. At each step, a pretrained world model and latent-space MPC planner generate a short-horizon action queue together with predicted latent rollouts, allowing the agent to execute multiple planned actions without immediate replanning. When a new observation arrives, the system measures the mismatch between the encoded real latent state and the queued predicted latent. For small to moderate mismatch, a lightweight learned corrector applies a residual update to the speculative action, distilled offline from a replanning teacher. For large mismatch, the agent safely falls back to full replanning and clears stale action queues. We study both a gated two-tower MLP corrector and a temporal Transformer corrector to address local errors and systematic drift. Experiments on the DMC Humanoid-Walk task show that our method reduces the number of planning inferences from 500 to 282, improves end-to-end step latency by 25 percent, and maintains strong control performance with only a 7.1 percent return reduction. Ablation results demonstrate that speculative execution without correction is unreliable over longer horizons, highlighting the necessity of mismatch-aware correction for robust latency reduction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "UIUC 25 Fall CS 498",
    "pdf_url": "https://arxiv.org/pdf/2512.17250v1",
    "published_date": "2025-12-19 05:34:52 UTC",
    "updated_date": "2025-12-19 05:34:52 UTC"
  },
  {
    "arxiv_id": "2512.20664v1",
    "title": "Eidoku: A Neuro-Symbolic Verification Gate for LLM Reasoning via Structural Constraint Satisfaction",
    "authors": [
      "Shinobu Miya"
    ],
    "abstract": "Large Language Models (LLMs) frequently produce hallucinated statements that are assigned high likelihood by the model itself, exposing a fundamental limitation of probability-based verification. This suggests that hallucination is often not a low-confidence phenomenon, but a failure of structural consistency. In this work, we reformulate the verification of LLM reasoning as a Constraint Satisfaction Problem (CSP) operating independently of the generation likelihood. Rather than optimizing for statistical plausibility, we model verification as a feasibility check based on structural violation cost -- the computational cost required to embed a candidate reasoning step into the contextual graph structure. We define a total cost function composed of three proxies: (i) graph connectivity (structural), (ii) feature space consistency (geometric), and (iii) logical entailment (symbolic). Crucially, verification is performed via a lightweight System-2 gate, Eidoku, which rejects candidates exceeding a context-calibrated cost threshold. The threshold is not learned but is derived from the intrinsic statistics of the context, avoiding ad hoc heuristics. We demonstrate that this approach successfully rejects ``smooth falsehoods'' -- statements that are highly probable yet structurally disconnected -- that probability-based verifiers are principally incapable of detecting. Our experiments on a controlled diagnostic dataset show that explicitly enforcing structural constraints allows for the deterministic rejection of this specific class of hallucinations, serving as a neuro-symbolic sanity check for generative reasoning.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20664v1",
    "published_date": "2025-12-19 05:29:43 UTC",
    "updated_date": "2025-12-19 05:29:43 UTC"
  },
  {
    "arxiv_id": "2512.17247v1",
    "title": "Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition",
    "authors": [
      "Zahra Rahmani",
      "Hossein Sameti"
    ],
    "abstract": "Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\\% (Raw Whisper) to 24.84\\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17247v1",
    "published_date": "2025-12-19 05:26:50 UTC",
    "updated_date": "2025-12-19 05:26:50 UTC"
  },
  {
    "arxiv_id": "2512.17239v1",
    "title": "Privacy-Preserving Synthetic Dataset of Individual Daily Trajectories for City-Scale Mobility Analytics",
    "authors": [
      "Jun'ichi Ozaki",
      "Ryosuke Susuta",
      "Takuhiro Moriyama",
      "Yohei Shida"
    ],
    "abstract": "Urban mobility data are indispensable for urban planning, transportation demand forecasting, pandemic modeling, and many other applications; however, individual mobile phone-derived Global Positioning System traces cannot generally be shared with third parties owing to severe re-identification risks. Aggregated records, such as origin-destination (OD) matrices, offer partial insights but fail to capture the key behavioral properties of daily human movement, limiting realistic city-scale analyses.\n  This study presents a privacy-preserving synthetic mobility dataset that reconstructs daily trajectories from aggregated inputs. The proposed method integrates OD flows with two complementary behavioral constraints: (1) dwell-travel time quantiles that are available only as coarse summary statistics and (2) the universal law for the daily distribution of the number of visited locations. Embedding these elements in a multi-objective optimization framework enables the reproduction of realistic distributions of human mobility while ensuring that no personal identifiers are required.\n  The proposed framework is validated in two contrasting regions of Japan: (1) the 23 special wards of Tokyo, representing a dense metropolitan environment; and (2) Fukuoka Prefecture, where urban and suburban mobility patterns coexist. The resulting synthetic mobility data reproduce dwell-travel time and visit frequency distributions with high fidelity, while deviations in OD consistency remain within the natural range of daily fluctuations.\n  The results of this study establish a practical synthesis pathway under real-world constraints, providing governments, urban planners, and industries with scalable access to high-resolution mobility data for reliable analytics without the need for sensitive personal records, and supporting practical deployments in policy and commercial domains.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SI",
    "comment": "9 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.17239v1",
    "published_date": "2025-12-19 04:59:41 UTC",
    "updated_date": "2025-12-19 04:59:41 UTC"
  },
  {
    "arxiv_id": "2512.22178v1",
    "title": "Wireless Traffic Prediction with Large Language Model",
    "authors": [
      "Chuanting Zhang",
      "Haixia Zhang",
      "Jingping Qiao",
      "Zongzhang Li",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "The growing demand for intelligent, adaptive resource management in next-generation wireless networks has underscored the importance of accurate and scalable wireless traffic prediction. While recent advancements in deep learning and foundation models such as large language models (LLMs) have demonstrated promising forecasting capabilities, they largely overlook the spatial dependencies inherent in city-scale traffic dynamics. In this paper, we propose TIDES (Traffic Intelligence with DeepSeek-Enhanced Spatial-temporal prediction), a novel LLM-based framework that captures spatial-temporal correlations for urban wireless traffic prediction. TIDES first identifies heterogeneous traffic patterns across regions through a clustering mechanism and trains personalized models for each region to balance generalization and specialization. To bridge the domain gap between numerical traffic data and language-based models, we introduce a prompt engineering scheme that embeds statistical traffic features as structured inputs. Furthermore, we design a DeepSeek module that enables spatial alignment via cross-domain attention, allowing the LLM to leverage information from spatially related regions. By fine-tuning only lightweight components while freezing core LLM layers, TIDES achieves efficient adaptation to domain-specific patterns without incurring excessive training overhead. Extensive experiments on real-world cellular traffic datasets demonstrate that TIDES significantly outperforms state-of-the-art baselines in both prediction accuracy and robustness. Our results indicate that integrating spatial awareness into LLM-based predictors is the key to unlocking scalable and intelligent network management in future 6G systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22178v1",
    "published_date": "2025-12-19 04:47:40 UTC",
    "updated_date": "2025-12-19 04:47:40 UTC"
  },
  {
    "arxiv_id": "2601.07839v1",
    "title": "Hierarchical Sparse Plus Low Rank Compression of LLM",
    "authors": [
      "Pawan Kumar",
      "Aditi Gupta"
    ],
    "abstract": "Modern large language models (LLMs) place extraordinary pressure on memory and compute budgets, making principled compression indispensable for both deployment and continued training. We present Hierarchical Sparse Plus Low-Rank (HSS) compression, a two-stage scheme that (i) removes the largest-magnitude weights into a sparse matrix S and (ii) applies a recursive Hierarchically Sparse Separable (HSS) low-rank factorisation to the dense residual matrix. A recursive rank-reducing strategy and a reverse Cuthill-Mckee (RCM) permutation are introduced to align high weights towards the diagonal with the block-diagonal hierarchy, maximising off-diagonal compressibility (because they are touched only once). HSS is hardware-friendly: its matrix-vector multiply reduces to one sparse and a sequence of thin-matrix multiplications and can be trained end-to-end with standard optimisers.\n  Experiments on LLaMA-7B show that targeting only the self-attention projections (1.6 B parameters of Q, K, and V matrices out of a total 7B parameters) suffices to yield large memory savings while retaining comparable state-of-the-art perplexity scores on test samples of the WikiText dataset. For example, with a 30\\% sparsity budget and an outer rank of 512, sHSS-RCM achieves a perplexity of 1.64, outperforming dense baselines and classical sparse-plus-SVD variants, while also achieving significant memory savings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures, Accepted in ACM International Conference on Data Science, CODS-2026",
    "pdf_url": "https://arxiv.org/pdf/2601.07839v1",
    "published_date": "2025-12-19 04:28:30 UTC",
    "updated_date": "2025-12-19 04:28:30 UTC"
  },
  {
    "arxiv_id": "2512.17218v2",
    "title": "Preventing AI Deepfake Abuse: An Islamic Ethics Framework",
    "authors": [
      "Wisnu Uriawan",
      "Imany Fauzy Rahman",
      "Muhamad Zidan",
      "Irma Rohmatillah",
      "Muhammad Arkan Raihan",
      "Irma Dwiyanti"
    ],
    "abstract": "The rapid development of deepfake technology powered by AI has raised global concerns regarding the manipulation of information, the usurpation of digital identities, and the erosion of public trust in the authenticity of online content. These challenges extend beyond technical issues and involve complex moral dimensions, rendering conventional, technologically driven, and reactive management approaches insufficient to address underlying causes such as intent, ethical responsibility, and intangible social harm. In response to these challenges, this study aims to formulate a comprehensive Islamic ethical framework as a preventive approach to mitigate the misuse of deepfake technology. This study employed a Systematic Literature Review (SLR) guided by the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), selecting ten primary sources published between 2018 and 2025 to identify ethical gaps, regulatory needs, and appropriate normative solutions. The analysis demonstrates that integrating the principles of Maqasid al-Shariah, particularly hifz al-ird and hifz al-nafs, provides a strong normative foundation for governing the responsible use of digital technology. Based on the findings, this study proposes three strategic recommendations: regulatory reforms that recognize the intangible and psychological harms resulting from reputational damage; strengthened technology governance grounded in moral accountability and the values of adl, amanah, and transparency; and enhanced public digital literacy based on the principle of tabayyun. Overall, the findings suggest that the application of Islamic ethical principles shifts governance paradigms from punitive mechanisms toward preventive approaches that emphasize the protection of human dignity, the prevention of harm, and the promotion of the common good in the digital age.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17218v2",
    "published_date": "2025-12-19 04:05:41 UTC",
    "updated_date": "2025-12-24 18:44:00 UTC"
  },
  {
    "arxiv_id": "2512.17215v2",
    "title": "Research on Dead Reckoning Algorithm for Self-Propelled Pipeline Robots in Three-Dimensional Complex Pipelines",
    "authors": [
      "Yan Gao",
      "Jiliang Wang",
      "Minghan Wang",
      "Xiaohua Chen",
      "Demin Chen",
      "Zhiyong Ren",
      "Tian-Yun Huang"
    ],
    "abstract": "In the field of gas pipeline location, existing pipeline location methods mostly rely on pipeline location instruments. However, when faced with complex and curved pipeline scenarios, these methods often fail due to problems such as cable entanglement and insufficient equipment flexibility. To address this pain point, we designed a self-propelled pipeline robot. This robot can autonomously complete the location work of complex and curved pipelines in complex pipe networks without external dragging. In terms of pipeline mapping technology, traditional visual mapping and laser mapping methods are easily affected by lighting conditions and insufficient features in the confined space of pipelines, resulting in mapping drift and divergence problems. In contrast, the pipeline location method that integrates inertial navigation and wheel odometers is less affected by pipeline environmental factors. Based on this, this paper proposes a pipeline robot location method based on extended Kalman filtering (EKF). Firstly, the body attitude angle is initially obtained through an inertial measurement unit (IMU). Then, the extended Kalman filtering algorithm is used to improve the accuracy of attitude angle estimation. Finally, high-precision pipeline location is achieved by combining wheel odometers. During the testing phase, the roll wheels of the pipeline robot needed to fit tightly against the pipe wall to reduce slippage. However, excessive tightness would reduce the flexibility of motion control due to excessive friction. Therefore, a balance needed to be struck between the robot's motion capability and positioning accuracy. Experiments were conducted using the self-propelled pipeline robot in a rectangular loop pipeline, and the results verified the effectiveness of the proposed dead reckoning algorithm.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "The paper needs further revision",
    "pdf_url": "https://arxiv.org/pdf/2512.17215v2",
    "published_date": "2025-12-19 03:58:02 UTC",
    "updated_date": "2025-12-25 01:33:02 UTC"
  },
  {
    "arxiv_id": "2512.17969v1",
    "title": "Convolutional-neural-operator-based transfer learning for solving PDEs",
    "authors": [
      "Peng Fan",
      "Guofei Pang"
    ],
    "abstract": "Convolutional neural operator is a CNN-based architecture recently proposed to enforce structure-preserving continuous-discrete equivalence and enable the genuine, alias-free learning of solution operators of PDEs. This neural operator was demonstrated to outperform for certain cases some baseline models such as DeepONet, Fourier neural operator, and Galerkin transformer in terms of surrogate accuracy. The convolutional neural operator, however, seems not to be validated for few-shot learning. We extend the model to few-shot learning scenarios by first pre-training a convolutional neural operator using a source dataset and then adjusting the parameters of the trained neural operator using only a small target dataset. We investigate three strategies for adjusting the parameters of a trained neural operator, including fine-tuning, low-rank adaption, and neuron linear transformation, and find that the neuron linear transformation strategy enjoys the highest surrogate accuracy in solving PDEs such as Kuramoto-Sivashinsky equation, Brusselator diffusion-reaction system, and Navier-Stokes equations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.17969v1",
    "published_date": "2025-12-19 03:55:20 UTC",
    "updated_date": "2025-12-19 03:55:20 UTC"
  },
  {
    "arxiv_id": "2512.17202v1",
    "title": "Fose: Fusion of One-Step Diffusion and End-to-End Network for Pansharpening",
    "authors": [
      "Kai Liu",
      "Zeli Lin",
      "Weibo Wang",
      "Linghe Kong",
      "Yulun Zhang"
    ],
    "abstract": "Pansharpening is a significant image fusion task that fuses low-resolution multispectral images (LRMSI) and high-resolution panchromatic images (PAN) to obtain high-resolution multispectral images (HRMSI). The development of the diffusion models (DM) and the end-to-end models (E2E model) has greatly improved the frontier of pansharping. DM takes the multi-step diffusion to obtain an accurate estimation of the residual between LRMSI and HRMSI. However, the multi-step process takes large computational power and is time-consuming. As for E2E models, their performance is still limited by the lack of prior and simple structure. In this paper, we propose a novel four-stage training strategy to obtain a lightweight network Fose, which fuses one-step DM and an E2E model. We perform one-step distillation on an enhanced SOTA DM for pansharping to compress the inference process from 50 steps to only 1 step. Then we fuse the E2E model with one-step DM with lightweight ensemble blocks. Comprehensive experiments are conducted to demonstrate the significant improvement of the proposed Fose on three commonly used benchmarks. Moreover, we achieve a 7.42 speedup ratio compared to the baseline DM while achieving much better performance. The code and model are released at https://github.com/Kai-Liu001/Fose.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code link: https://github.com/Kai-Liu001/Fose",
    "pdf_url": "https://arxiv.org/pdf/2512.17202v1",
    "published_date": "2025-12-19 03:28:39 UTC",
    "updated_date": "2025-12-19 03:28:39 UTC"
  },
  {
    "arxiv_id": "2512.17196v1",
    "title": "UmniBench: Unified Understand and Generation Model Oriented Omni-dimensional Benchmark",
    "authors": [
      "Kai Liu",
      "Leyang Chen",
      "Wenbo Li",
      "Zhikai Chen",
      "Zhixin Wang",
      "Renjing Pei",
      "Linghe Kong",
      "Yulun Zhang"
    ],
    "abstract": "Unifying multimodal understanding and generation has shown impressive capabilities in cutting-edge proprietary systems. However, evaluations of unified multimodal models (UMMs) remain decoupled, assessing their understanding and generation abilities separately with corresponding datasets. To address this, we propose UmniBench, a benchmark tailored for UMMs with omni-dimensional evaluation. First, UmniBench can assess the understanding, generation, and editing ability within a single evaluation process. Based on human-examined prompts and QA pairs, UmniBench leverages UMM itself to evaluate its generation and editing ability with its understanding ability. This simple but effective paradigm allows comprehensive evaluation of UMMs. Second, UmniBench covers 13 major domains and more than 200 concepts, ensuring a thorough inspection of UMMs. Moreover, UmniBench can also decouple and separately evaluate understanding, generation, and editing abilities, providing a fine-grained assessment. Based on UmniBench, we benchmark 24 popular models, including both UMMs and single-ability large models. We hope this benchmark provides a more comprehensive and objective view of unified models and logistical support for improving the performance of the community model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Project Page: https://umnibench.github.io/",
    "pdf_url": "https://arxiv.org/pdf/2512.17196v1",
    "published_date": "2025-12-19 03:20:59 UTC",
    "updated_date": "2025-12-19 03:20:59 UTC"
  },
  {
    "arxiv_id": "2512.17194v1",
    "title": "MMRAG-RFT: Two-stage Reinforcement Fine-tuning for Explainable Multi-modal Retrieval-augmented Generation",
    "authors": [
      "Shengwei Zhao",
      "Jingwen Yao",
      "Sitong Wei",
      "Linhai Xu",
      "Yuying Liu",
      "Dong Zhang",
      "Zhiqiang Tian",
      "Shaoyi Du"
    ],
    "abstract": "Multi-modal Retrieval-Augmented Generation (MMRAG) enables highly credible generation by integrating external multi-modal knowledge, thus demonstrating impressive performance in complex multi-modal scenarios. However, existing MMRAG methods fail to clarify the reasoning logic behind retrieval and response generation, which limits the explainability of the results. To address this gap, we propose to introduce reinforcement learning into multi-modal retrieval-augmented generation, enhancing the reasoning capabilities of multi-modal large language models through a two-stage reinforcement fine-tuning framework to achieve explainable multi-modal retrieval-augmented generation. Specifically, in the first stage, rule-based reinforcement fine-tuning is employed to perform coarse-grained point-wise ranking of multi-modal documents, effectively filtering out those that are significantly irrelevant. In the second stage, reasoning-based reinforcement fine-tuning is utilized to jointly optimize fine-grained list-wise ranking and answer generation, guiding multi-modal large language models to output explainable reasoning logic in the MMRAG process. Our method achieves state-of-the-art results on WebQA and MultimodalQA, two benchmark datasets for multi-modal retrieval-augmented generation, and its effectiveness is validated through comprehensive ablation experiments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was accepted to AAAI2026",
    "pdf_url": "https://arxiv.org/pdf/2512.17194v1",
    "published_date": "2025-12-19 03:19:54 UTC",
    "updated_date": "2025-12-19 03:19:54 UTC"
  },
  {
    "arxiv_id": "2512.20662v1",
    "title": "Quantifying Laziness, Decoding Suboptimality, and Context Degradation in Large Language Models",
    "authors": [
      "Yiqing Ma",
      "Jung-Hua Liu"
    ],
    "abstract": "Large Language Models (LLMs) often exhibit behavioral artifacts such as laziness (premature truncation of responses or partial compliance with multi-part requests), decoding suboptimality (failure to select higher-quality sequences due to myopic decoding), and context degradation (forgetting or ignoring core instructions over long conversations). We conducted three controlled experiments (A, B, and C) to quantify these phenomena across several advanced LLMs (OpenAI GPT-4 variant, DeepSeek). Our results indicate widespread laziness in satisfying complex multi-part instructions: models frequently omitted required sections or failed to meet length requirements despite explicit prompting. However, we found limited evidence of decoding suboptimality in a simple reasoning task (the models' greedy answers appeared to align with their highest-confidence solution), and we observed surprising robustness against context degradation in a 200-turn chaotic conversation test - the models maintained key facts and instructions far better than expected. These findings suggest that while compliance with detailed instructions remains an open challenge, modern LLMs may internally mitigate some hypothesized failure modes (such as context forgetting) in straightforward retrieval scenarios. We discuss implications for reliability, relate our findings to prior work on instruction-following and long-context processing, and recommend strategies (such as self-refinement and dynamic prompting) to reduce laziness and bolster multi-instruction compliance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20662v1",
    "published_date": "2025-12-19 03:01:59 UTC",
    "updated_date": "2025-12-19 03:01:59 UTC"
  },
  {
    "arxiv_id": "2512.17185v1",
    "title": "Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning",
    "authors": [
      "Sandeep Neela"
    ],
    "abstract": "Financial crises emerge when structural vulnerabilities accumulate across sectors, markets, and investor behavior. Predicting these systemic transitions is challenging because they arise from evolving interactions between market participants, not isolated price movements alone. We present Systemic Risk Radar (SRR), a framework that models financial markets as multi-layer graphs to detect early signs of systemic fragility and crash-regime transitions.\n  We evaluate SRR across three major crises: the Dot-com crash, the Global Financial Crisis, and the COVID-19 shock. Our experiments compare snapshot GNNs, a simplified temporal GNN prototype, and standard baselines (logistic regression and Random Forest). Results show that structural network information provides useful early-warning signals compared to feature-based models alone.\n  This correlation-based instantiation of SRR demonstrates that graph-derived features capture meaningful changes in market structure during stress events. The findings motivate extending SRR with additional graph layers (sector/factor exposure, sentiment) and more expressive temporal architectures (LSTM/GRU or Transformer encoders) to better handle diverse crisis types.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.17185v1",
    "published_date": "2025-12-19 03:00:09 UTC",
    "updated_date": "2025-12-19 03:00:09 UTC"
  },
  {
    "arxiv_id": "2512.17180v2",
    "title": "Conservative Bias in Multi-Teacher Learning: Why Agents Prefer Low-Reward Advisors",
    "authors": [
      "Maher Mesto",
      "Francisco Cruz"
    ],
    "abstract": "Interactive reinforcement learning (IRL) has shown promise in enabling autonomous agents and robots to learn complex behaviours from human teachers, yet the dynamics of teacher selection remain poorly understood. This paper reveals an unexpected phenomenon in IRL: when given a choice between teachers with different reward structures, learning agents overwhelmingly prefer conservative, low-reward teachers (93.16% selection rate) over those offering 20x higher rewards. Through 1,250 experimental runs in navigation tasks with multiple expert teachers, we discovered: (1) Conservative bias dominates teacher selection: agents systematically choose the lowest-reward teacher, prioritising consistency over optimality; (2) Critical performance thresholds exist at teacher availability rho >= 0.6 and accuracy omega >= 0.6, below which the framework fails catastrophically; (3) The framework achieves 159% improvement over baseline Q-learning under concept drift. These findings challenge fundamental assumptions about optimal teaching in RL and suggest potential implications for human-robot collaboration, where human preferences for safety and consistency may align with the observed agent selection behaviour, potentially informing training paradigms for safety-critical robotic applications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 5 figures. Accepted at ACRA 2025 (Australasian Conference on Robotics and Automation)",
    "pdf_url": "https://arxiv.org/pdf/2512.17180v2",
    "published_date": "2025-12-19 02:38:04 UTC",
    "updated_date": "2025-12-23 06:26:45 UTC"
  },
  {
    "arxiv_id": "2512.17172v1",
    "title": "PILAR: Personalizing Augmented Reality Interactions with LLM-based Human-Centric and Trustworthy Explanations for Daily Use Cases",
    "authors": [
      "Ripan Kumar Kundu",
      "Istiak Ahmed",
      "Khaza Anuarul Hoque"
    ],
    "abstract": "Artificial intelligence (AI)-driven augmented reality (AR) systems are becoming increasingly integrated into daily life, and with this growth comes a greater need for explainability in real-time user interactions. Traditional explainable AI (XAI) methods, which often rely on feature-based or example-based explanations, struggle to deliver dynamic, context-specific, personalized, and human-centric insights for everyday AR users. These methods typically address separate explainability dimensions (e.g., when, what, how) with different explanation techniques, resulting in unrealistic and fragmented experiences for seamless AR interactions. To address this challenge, we propose PILAR, a novel framework that leverages a pre-trained large language model (LLM) to generate context-aware, personalized explanations, offering a more intuitive and trustworthy experience in real-time AI-powered AR systems. Unlike traditional methods, which rely on multiple techniques for different aspects of explanation, PILAR employs a unified LLM-based approach that dynamically adapts explanations to the user's needs, fostering greater trust and engagement. We implement the PILAR concept in a real-world AR application (e.g., personalized recipe recommendations), an open-source prototype that integrates real-time object detection, recipe recommendation, and LLM-based personalized explanations of the recommended recipes based on users' dietary preferences. We evaluate the effectiveness of PILAR through a user study with 16 participants performing AR-based recipe recommendation tasks, comparing an LLM-based explanation interface to a traditional template-based one. Results show that the LLM-based interface significantly enhances user performance and experience, with participants completing tasks 40% faster and reporting greater satisfaction, ease of use, and perceived transparency.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Published in the 2025 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)",
    "pdf_url": "https://arxiv.org/pdf/2512.17172v1",
    "published_date": "2025-12-19 02:19:38 UTC",
    "updated_date": "2025-12-19 02:19:38 UTC"
  },
  {
    "arxiv_id": "2512.20661v1",
    "title": "From Fake Focus to Real Precision: Confusion-Driven Adversarial Attention Learning in Transformers",
    "authors": [
      "Yawei Liu"
    ],
    "abstract": "Transformer-based models have been widely adopted for sentiment analysis tasks due to their exceptional ability to capture contextual information. However, these methods often exhibit suboptimal accuracy in certain scenarios. By analyzing their attention distributions, we observe that existing models tend to allocate attention primarily to common words, overlooking less popular yet highly task-relevant terms, which significantly impairs overall performance. To address this issue, we propose an Adversarial Feedback for Attention(AFA) training mechanism that enables the model to automatically redistribute attention weights to appropriate focal points without requiring manual annotations. This mechanism incorporates a dynamic masking strategy that attempts to mask various words to deceive a discriminator, while the discriminator strives to detect significant differences induced by these masks. Additionally, leveraging the sensitivity of Transformer models to token-level perturbations, we employ a policy gradient approach to optimize attention distributions, which facilitates efficient and rapid convergence. Experiments on three public datasets demonstrate that our method achieves state-of-the-art results. Furthermore, applying this training mechanism to enhance attention in large language models yields a further performance improvement of 12.6%",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, submited to WWW 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.20661v1",
    "published_date": "2025-12-19 01:48:25 UTC",
    "updated_date": "2025-12-19 01:48:25 UTC"
  },
  {
    "arxiv_id": "2512.17968v1",
    "title": "A Critical Review of Monte Carlo Algorithms Balancing Performance and Probabilistic Accuracy with AI Augmented Framework",
    "authors": [
      "Ravi Prasad"
    ],
    "abstract": "Monte Carlo algorithms are a foundational pillar of modern computational science, yet their effective application hinges on a deep understanding of their performance trade offs. This paper presents a critical analysis of the evolution of Monte Carlo algorithms, focusing on the persistent tension between statistical efficiency and computational cost. We describe the historical development from the foundational Metropolis Hastings algorithm to contemporary methods like Hamiltonian Monte Carlo. A central emphasis of this survey is the rigorous discussion of time and space complexity, including upper, lower, and asymptotic tight bounds for each major algorithm class. We examine the specific motivations for developing these methods and the key theoretical and practical observations such as the introduction of gradient information and adaptive tuning in HMC that led to successively better solutions. Furthermore, we provide a justification framework that discusses explicit situations in which using one algorithm is demonstrably superior to another for the same problem. The paper concludes by assessing the profound significance and impact of these algorithms and detailing major current research challenges.",
    "categories": [
      "stat.CO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "stat.CO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17968v1",
    "published_date": "2025-12-19 01:20:36 UTC",
    "updated_date": "2025-12-19 01:20:36 UTC"
  },
  {
    "arxiv_id": "2512.19753v1",
    "title": "QMBench: A Research Level Benchmark for Quantum Materials Research",
    "authors": [
      "Yanzhen Wang",
      "Yiyang Jiang",
      "Diana Golovanova",
      "Kamal Das",
      "Hyeonhu Bae",
      "Yufei Zhao",
      "Huu-Thong Le",
      "Abhinava Chatterjee",
      "Yunzhe Liu",
      "Chao-Xing Liu",
      "Felipe H. da Jornada",
      "Binghai Yan",
      "Xiao-Liang Qi"
    ],
    "abstract": "We introduce QMBench, a comprehensive benchmark designed to evaluate the capability of large language model agents in quantum materials research. This specialized benchmark assesses the model's ability to apply condensed matter physics knowledge and computational techniques such as density functional theory to solve research problems in quantum materials science. QMBench encompasses different domains of the quantum material research, including structural properties, electronic properties, thermodynamic and other properties, symmetry principle and computational methodologies. By providing a standardized evaluation framework, QMBench aims to accelerate the development of an AI scientist capable of making creative contributions to quantum materials research. We expect QMBench to be developed and constantly improved by the research community.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "20 pages, 1 figure",
    "pdf_url": "https://arxiv.org/pdf/2512.19753v1",
    "published_date": "2025-12-19 00:57:43 UTC",
    "updated_date": "2025-12-19 00:57:43 UTC"
  },
  {
    "arxiv_id": "2512.17145v2",
    "title": "Solomonoff-Inspired Hypothesis Ranking with LLMs for Prediction Under Uncertainty",
    "authors": [
      "Josh Barber",
      "Rourke Young",
      "Cameron Coombe",
      "Will Browne"
    ],
    "abstract": "Reasoning under uncertainty is a key challenge in AI, especially for real-world tasks, where problems with sparse data demands systematic generalisation. Existing approaches struggle to balance accuracy and simplicity when evaluating multiple candidate solutions. We propose a Solomonoff-inspired method that weights LLM-generated hypotheses by simplicity and predictive fit. Applied to benchmark (Mini-ARC) tasks, our method produces Solomonoff-weighted mixtures for per-cell predictions, yielding conservative, uncertainty-aware outputs even when hypotheses are noisy or partially incorrect. Compared to Bayesian Model Averaging (BMA), Solomonoff scoring spreads probability more evenly across competing hypotheses, while BMA concentrates weight on the most likely but potentially flawed candidates. Across tasks, this highlights the value of algorithmic information-theoretic priors for interpretable, reliable multi-hypothesis reasoning under uncertainty.",
    "categories": [
      "cs.AI",
      "cs.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, ACRA 2025, Submitted, Accepted and Presented",
    "pdf_url": "https://arxiv.org/pdf/2512.17145v2",
    "published_date": "2025-12-19 00:43:49 UTC",
    "updated_date": "2025-12-22 02:19:00 UTC"
  },
  {
    "arxiv_id": "2512.17137v1",
    "title": "SDUM: A Scalable Deep Unrolled Model for Universal MRI Reconstruction",
    "authors": [
      "Puyang Wang",
      "Pengfei Guo",
      "Keyi Chai",
      "Jinyuan Zhou",
      "Daguang Xu",
      "Shanshan Jiang"
    ],
    "abstract": "Clinical MRI encompasses diverse imaging protocols--spanning anatomical targets (cardiac, brain, knee), contrasts (T1, T2, mapping), sampling patterns (Cartesian, radial, spiral, kt-space), and acceleration factors--yet current deep learning reconstructions are typically protocol-specific, hindering generalization and deployment. We introduce Scalable Deep Unrolled Model (SDUM), a universal framework combining a Restormer-based reconstructor, a learned coil sensitivity map estimator (CSME), sampling-aware weighted data consistency (SWDC), universal conditioning (UC) on cascade index and protocol metadata, and progressive cascade expansion training. SDUM exhibits foundation-model-like scaling behavior: reconstruction quality follows PSNR ${\\sim}$ log(parameters) with correlation $r{=}0.986$ ($R^2{=}0.973$) up to 18 cascades, demonstrating predictable performance gains with model depth. A single SDUM trained on heterogeneous data achieves state-of-the-art results across all four CMRxRecon2025 challenge tracks--multi-center, multi-disease, 5T, and pediatric--without task-specific fine-tuning, surpassing specialized baselines by up to ${+}1.0$~dB. On CMRxRecon2024, SDUM outperforms the winning method PromptMR+ by ${+}0.55$~dB; on fastMRI brain, it exceeds PC-RNN by ${+}1.8$~dB. Ablations validate each component: SWDC ${+}0.43$~dB over standard DC, per-cascade CSME ${+}0.51$~dB, UC ${+}0.38$~dB. These results establish SDUM as a practical path toward universal, scalable MRI reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17137v1",
    "published_date": "2025-12-19 00:09:32 UTC",
    "updated_date": "2025-12-19 00:09:32 UTC"
  }
]