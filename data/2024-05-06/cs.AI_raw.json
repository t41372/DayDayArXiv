[
  {
    "arxiv_id": "2405.03903v1",
    "title": "Unified Locational Differential Privacy Framework",
    "authors": [
      "Aman Priyanshu",
      "Yash Maurya",
      "Suriya Ganesh",
      "Vy Tran"
    ],
    "abstract": "Aggregating statistics over geographical regions is important for many\napplications, such as analyzing income, election results, and disease spread.\nHowever, the sensitive nature of this data necessitates strong privacy\nprotections to safeguard individuals. In this work, we present a unified\nlocational differential privacy (DP) framework to enable private aggregation of\nvarious data types, including one-hot encoded, boolean, float, and integer\narrays, over geographical regions. Our framework employs local DP mechanisms\nsuch as randomized response, the exponential mechanism, and the Gaussian\nmechanism. We evaluate our approach on four datasets representing significant\nlocation data aggregation scenarios. Results demonstrate the utility of our\nframework in providing formal DP guarantees while enabling geographical data\nanalysis.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03903v1",
    "published_date": "2024-05-06 23:33:52 UTC",
    "updated_date": "2024-05-06 23:33:52 UTC"
  },
  {
    "arxiv_id": "2405.03901v1",
    "title": "OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs",
    "authors": [
      "Jiahao Nick Li",
      "Yan Xu",
      "Tovi Grossman",
      "Stephanie Santosa",
      "Michelle Li"
    ],
    "abstract": "The progression to \"Pervasive Augmented Reality\" envisions easy access to\nmultimodal information continuously. However, in many everyday scenarios, users\nare occupied physically, cognitively or socially. This may increase the\nfriction to act upon the multimodal information that users encounter in the\nworld. To reduce such friction, future interactive interfaces should\nintelligently provide quick access to digital actions based on users' context.\nTo explore the range of possible digital actions, we conducted a diary study\nthat required participants to capture and share the media that they intended to\nperform actions on (e.g., images or audio), along with their desired actions\nand other contextual information. Using this data, we generated a holistic\ndesign space of digital follow-up actions that could be performed in response\nto different types of multimodal sensory inputs. We then designed OmniActions,\na pipeline powered by large language models (LLMs) that processes multimodal\nsensory inputs and predicts follow-up actions on the target information\ngrounded in the derived design space. Using the empirical data collected in the\ndiary study, we performed quantitative evaluations on three variations of LLM\ntechniques (intent classification, in-context learning and finetuning) and\nidentified the most effective technique for our task. Additionally, as an\ninstantiation of the pipeline, we developed an interactive prototype and\nreported preliminary user feedback about how people perceive and react to the\naction predictions and its errors.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted to the 2024 CHI Conference on Human Factors in\n  Computing Systems (CHI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.03901v1",
    "published_date": "2024-05-06 23:11:00 UTC",
    "updated_date": "2024-05-06 23:11:00 UTC"
  },
  {
    "arxiv_id": "2405.03892v1",
    "title": "Out-of-Distribution Adaptation in Offline RL: Counterfactual Reasoning via Causal Normalizing Flows",
    "authors": [
      "Minjae Cho",
      "Jonathan P. How",
      "Chuangchuang Sun"
    ],
    "abstract": "Despite notable successes of Reinforcement Learning (RL), the prevalent use\nof an online learning paradigm prevents its widespread adoption, especially in\nhazardous or costly scenarios. Offline RL has emerged as an alternative\nsolution, learning from pre-collected static datasets. However, this offline\nlearning introduces a new challenge known as distributional shift, degrading\nthe performance when the policy is evaluated on scenarios that are\nOut-Of-Distribution (OOD) from the training dataset. Most existing offline RL\nresolves this issue by regularizing policy learning within the information\nsupported by the given dataset. However, such regularization overlooks the\npotential for high-reward regions that may exist beyond the dataset. This\nmotivates exploring novel offline learning techniques that can make\nimprovements beyond the data support without compromising policy performance,\npotentially by learning causation (cause-and-effect) instead of correlation\nfrom the dataset. In this paper, we propose the MOOD-CRL (Model-based Offline\nOOD-Adapting Causal RL) algorithm, which aims to address the challenge of\nextrapolation for offline policy training through causal inference instead of\npolicy-regularizing methods. Specifically, Causal Normalizing Flow (CNF) is\ndeveloped to learn the transition and reward functions for data generation and\naugmentation in offline policy evaluation and training. Based on the\ndata-invariant, physics-based qualitative causal graph and the observational\ndata, we develop a novel learning scheme for CNF to learn the quantitative\nstructural causal model. As a result, CNF gains predictive and counterfactual\nreasoning capabilities for sequential decision-making tasks, revealing a high\npotential for OOD adaptation. Our CNF-based offline RL approach is validated\nthrough empirical evaluations, outperforming model-free and model-based methods\nby a significant margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted for review at IEEE: Neural Networks and Learning Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.03892v1",
    "published_date": "2024-05-06 22:44:32 UTC",
    "updated_date": "2024-05-06 22:44:32 UTC"
  },
  {
    "arxiv_id": "2405.03891v1",
    "title": "Enhancing O-RAN Security: Evasion Attacks and Robust Defenses for Graph Reinforcement Learning-based Connection Management",
    "authors": [
      "Ravikumar Balakrishnan",
      "Marius Arvinte",
      "Nageen Himayat",
      "Hosein Nikopour",
      "Hassnaa Moustafa"
    ],
    "abstract": "Adversarial machine learning, focused on studying various attacks and\ndefenses on machine learning (ML) models, is rapidly gaining importance as ML\nis increasingly being adopted for optimizing wireless systems such as Open\nRadio Access Networks (O-RAN). A comprehensive modeling of the security threats\nand the demonstration of adversarial attacks and defenses on practical AI based\nO-RAN systems is still in its nascent stages. We begin by conducting threat\nmodeling to pinpoint attack surfaces in O-RAN using an ML-based Connection\nmanagement application (xApp) as an example. The xApp uses a Graph Neural\nNetwork trained using Deep Reinforcement Learning and achieves on average 54%\nimprovement in the coverage rate measured as the 5th percentile user data\nrates. We then formulate and demonstrate evasion attacks that degrade the\ncoverage rates by as much as 50% through injecting bounded noise at different\nthreat surfaces including the open wireless medium itself. Crucially, we also\ncompare and contrast the effectiveness of such attacks on the ML-based xApp and\na non-ML based heuristic. We finally develop and demonstrate robust\ntraining-based defenses against the challenging physical/jamming-based attacks\nand show a 15% improvement in the coverage rates when compared to employing no\ndefense over a range of noise budgets",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.03891v1",
    "published_date": "2024-05-06 22:27:24 UTC",
    "updated_date": "2024-05-06 22:27:24 UTC"
  },
  {
    "arxiv_id": "2405.03885v2",
    "title": "Playing Games with your PET: Extending the Partial Exploration Tool to Stochastic Games",
    "authors": [
      "Tobias Meggendorfer",
      "Maximilian Weininger"
    ],
    "abstract": "We present version 2.0 of the Partial Exploration Tool (PET), a tool for\nverification of probabilistic systems. We extend the previous version by adding\nsupport for stochastic games, based on a recent unified framework for sound\nvalue iteration algorithms. Thereby, PET2 is the first tool implementing a\nsound and efficient approach for solving stochastic games with objectives of\nthe type reachability/safety and mean payoff. We complement this approach by\ndeveloping and implementing a partial-exploration based variant for all three\nobjectives. Our experimental evaluation shows that PET2 offers the most\nefficient partial-exploration based algorithm and is the most viable tool on\nSGs, even outperforming unsound tools.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.GT",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03885v2",
    "published_date": "2024-05-06 22:07:26 UTC",
    "updated_date": "2024-05-13 07:41:41 UTC"
  },
  {
    "arxiv_id": "2405.03882v3",
    "title": "Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer",
    "authors": [
      "Huihong Shi",
      "Haikuo Shao",
      "Wendong Mao",
      "Zhongfeng Wang"
    ],
    "abstract": "Motivated by the huge success of Transformers in the field of natural\nlanguage processing (NLP), Vision Transformers (ViTs) have been rapidly\ndeveloped and achieved remarkable performance in various computer vision tasks.\nHowever, their huge model sizes and intensive computations hinder ViTs'\ndeployment on embedded devices, calling for effective model compression\nmethods, such as quantization. Unfortunately, due to the existence of\nhardware-unfriendly and quantization-sensitive non-linear operations,\nparticularly {Softmax}, it is non-trivial to completely quantize all operations\nin ViTs, yielding either significant accuracy drops or non-negligible hardware\ncosts. In response to challenges associated with \\textit{standard ViTs}, we\nfocus our attention towards the quantization and acceleration for\n\\textit{efficient ViTs}, which not only eliminate the troublesome Softmax but\nalso integrate linear attention with low computational complexity, and propose\nTrio-ViT accordingly. Specifically, at the algorithm level, we develop a\n{tailored post-training quantization engine} taking the unique activation\ndistributions of Softmax-free efficient ViTs into full consideration, aiming to\nboost quantization accuracy. Furthermore, at the hardware level, we build an\naccelerator dedicated to the specific Convolution-Transformer hybrid\narchitecture of efficient ViTs, thereby enhancing hardware efficiency.\nExtensive experimental results consistently prove the effectiveness of our\nTrio-ViT framework. {Particularly, we can gain up to\n$\\uparrow$$\\mathbf{3.6}\\times$, $\\uparrow$$\\mathbf{5.0}\\times$, and\n$\\uparrow$$\\mathbf{7.3}\\times$ FPS under comparable accuracy over\nstate-of-the-art ViT accelerators, as well as $\\uparrow$$\\mathbf{6.0}\\times$,\n$\\uparrow$$\\mathbf{1.5}\\times$, and $\\uparrow$$\\mathbf{2.1}\\times$ DSP\nefficiency.} Codes are available at\n\\url{https://github.com/shihuihong214/Trio-ViT}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03882v3",
    "published_date": "2024-05-06 21:57:35 UTC",
    "updated_date": "2024-09-30 07:01:57 UTC"
  },
  {
    "arxiv_id": "2405.03878v2",
    "title": "Sequence Compression Speeds Up Credit Assignment in Reinforcement Learning",
    "authors": [
      "Aditya A. Ramesh",
      "Kenny Young",
      "Louis Kirsch",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Temporal credit assignment in reinforcement learning is challenging due to\ndelayed and stochastic outcomes. Monte Carlo targets can bridge long delays\nbetween action and consequence but lead to high-variance targets due to\nstochasticity. Temporal difference (TD) learning uses bootstrapping to overcome\nvariance but introduces a bias that can only be corrected through many\niterations. TD($\\lambda$) provides a mechanism to navigate this bias-variance\ntradeoff smoothly. Appropriately selecting $\\lambda$ can significantly improve\nperformance. Here, we propose Chunked-TD, which uses predicted probabilities of\ntransitions from a model for computing $\\lambda$-return targets. Unlike other\nmodel-based solutions to credit assignment, Chunked-TD is less vulnerable to\nmodel inaccuracies. Our approach is motivated by the principle of history\ncompression and 'chunks' trajectories for conventional TD learning. Chunking\nwith learned world models compresses near-deterministic regions of the\nenvironment-policy interaction to speed up credit assignment while still\nbootstrapping when necessary. We propose algorithms that can be implemented\nonline and show that they solve some problems much faster than conventional\nTD($\\lambda$).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 version",
    "pdf_url": "http://arxiv.org/pdf/2405.03878v2",
    "published_date": "2024-05-06 21:49:29 UTC",
    "updated_date": "2024-06-04 05:28:56 UTC"
  },
  {
    "arxiv_id": "2405.03873v1",
    "title": "Investigating Personalized Driving Behaviors in Dilemma Zones: Analysis and Prediction of Stop-or-Go Decisions",
    "authors": [
      "Ziye Qin",
      "Siyan Li",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han"
    ],
    "abstract": "Dilemma zones at signalized intersections present a commonly occurring but\nunsolved challenge for both drivers and traffic operators. Onsets of the yellow\nlights prompt varied responses from different drivers: some may brake abruptly,\ncompromising the ride comfort, while others may accelerate, increasing the risk\nof red-light violations and potential safety hazards. Such diversity in\ndrivers' stop-or-go decisions may result from not only surrounding traffic\nconditions, but also personalized driving behaviors. To this end, identifying\npersonalized driving behaviors and integrating them into advanced driver\nassistance systems (ADAS) to mitigate the dilemma zone problem presents an\nintriguing scientific question. In this study, we employ a game engine-based\n(i.e., CARLA-enabled) driving simulator to collect high-resolution vehicle\ntrajectories, incoming traffic signal phase and timing information, and\nstop-or-go decisions from four subject drivers in various scenarios. This\napproach allows us to analyze personalized driving behaviors in dilemma zones\nand develop a Personalized Transformer Encoder to predict individual drivers'\nstop-or-go decisions. The results show that the Personalized Transformer\nEncoder improves the accuracy of predicting driver decision-making in the\ndilemma zone by 3.7% to 12.6% compared to the Generic Transformer Encoder, and\nby 16.8% to 21.6% over the binary logistic regression model.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03873v1",
    "published_date": "2024-05-06 21:39:25 UTC",
    "updated_date": "2024-05-06 21:39:25 UTC"
  },
  {
    "arxiv_id": "2405.03870v1",
    "title": "AI-Driven Frameworks for Enhancing Data Quality in Big Data Ecosystems: Error_Detection, Correction, and Metadata Integration",
    "authors": [
      "Widad Elouataoui"
    ],
    "abstract": "The widespread adoption of big data has ushered in a new era of data-driven\ndecision-making, transforming numerous industries and sectors. However, the\nefficacy of these decisions hinges on the quality of the underlying data. Poor\ndata quality can result in inaccurate analyses and deceptive conclusions.\nManaging the vast volume, velocity, and variety of data sources presents\nsignificant challenges, heightening the importance of addressing big data\nquality issues. While there has been increased attention from both academia and\nindustry, current approaches often lack comprehensiveness and universality.\nThey tend to focus on limited metrics, neglecting other dimensions of data\nquality. Moreover, existing methods are often context-specific, limiting their\napplicability across different domains. There is a clear need for intelligent,\nautomated approaches leveraging artificial intelligence (AI) for advanced data\nquality corrections.\n  To bridge these gaps, this Ph.D. thesis proposes a novel set of\ninterconnected frameworks aimed at enhancing big data quality comprehensively.\nFirstly, we introduce new quality metrics and a weighted scoring system for\nprecise data quality assessment. Secondly, we present a generic framework for\ndetecting various quality anomalies using AI models. Thirdly, we propose an\ninnovative framework for correcting detected anomalies through predictive\nmodeling. Additionally, we address metadata quality enhancement within big data\necosystems. These frameworks are rigorously tested on diverse datasets,\ndemonstrating their efficacy in improving big data quality. Finally, the thesis\nconcludes with insights and suggestions for future research directions.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Doctoral thesis",
    "pdf_url": "http://arxiv.org/pdf/2405.03870v1",
    "published_date": "2024-05-06 21:36:45 UTC",
    "updated_date": "2024-05-06 21:36:45 UTC"
  },
  {
    "arxiv_id": "2405.03869v5",
    "title": "Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models",
    "authors": [
      "Anshuman Chhabra",
      "Bo Li",
      "Jian Chen",
      "Prasant Mohapatra",
      "Hongfu Liu"
    ],
    "abstract": "A core data-centric learning challenge is the identification of training\nsamples that are detrimental to model performance. Influence functions serve as\na prominent tool for this task and offer a robust framework for assessing\ntraining data influence on model predictions. Despite their widespread use,\ntheir high computational cost associated with calculating the inverse of the\nHessian matrix pose constraints, particularly when analyzing large-sized deep\nmodels. In this paper, we establish a bridge between identifying detrimental\ntraining samples via influence functions and outlier gradient detection. This\ntransformation not only presents a straightforward and Hessian-free formulation\nbut also provides insights into the role of the gradient in sample impact.\nThrough systematic empirical evaluations, we first validate the hypothesis of\nour proposed outlier gradient analysis approach on synthetic datasets. We then\ndemonstrate its effectiveness in detecting mislabeled samples in vision models\nand selecting data samples for improving performance of natural language\nprocessing transformer models. We also extend its use to influential sample\nidentification for fine-tuning Large Language Models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.03869v5",
    "published_date": "2024-05-06 21:34:46 UTC",
    "updated_date": "2025-05-03 14:54:17 UTC"
  },
  {
    "arxiv_id": "2405.03865v1",
    "title": "Information-driven Affordance Discovery for Efficient Robotic Manipulation",
    "authors": [
      "Pietro Mazzaglia",
      "Taco Cohen",
      "Daniel Dijkman"
    ],
    "abstract": "Robotic affordances, providing information about what actions can be taken in\na given situation, can aid robotic manipulation. However, learning about\naffordances requires expensive large annotated datasets of interactions or\ndemonstrations. In this work, we argue that well-directed interactions with the\nenvironment can mitigate this problem and propose an information-based measure\nto augment the agent's objective and accelerate the affordance discovery\nprocess. We provide a theoretical justification of our approach and we\nempirically validate the approach both in simulation and real-world tasks. Our\nmethod, which we dub IDA, enables the efficient discovery of visual affordances\nfor several action primitives, such as grasping, stacking objects, or opening\ndrawers, strongly improving data efficiency in simulation, and it allows us to\nlearn grasping affordances in a small number of interactions, on a real-world\nsetup with a UFACTORY XArm 6 robot arm.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2308.14915",
    "pdf_url": "http://arxiv.org/pdf/2405.03865v1",
    "published_date": "2024-05-06 21:25:51 UTC",
    "updated_date": "2024-05-06 21:25:51 UTC"
  },
  {
    "arxiv_id": "2405.03864v1",
    "title": "Learning Planning Abstractions from Language",
    "authors": [
      "Weiyu Liu",
      "Geng Chen",
      "Joy Hsu",
      "Jiayuan Mao",
      "Jiajun Wu"
    ],
    "abstract": "This paper presents a framework for learning state and action abstractions in\nsequential decision-making domains. Our framework, planning abstraction from\nlanguage (PARL), utilizes language-annotated demonstrations to automatically\ndiscover a symbolic and abstract action space and induce a latent state\nabstraction based on it. PARL consists of three stages: 1) recovering\nobject-level and action concepts, 2) learning state abstractions, abstract\naction feasibility, and transition models, and 3) applying low-level policies\nfor abstract actions. During inference, given the task description, PARL first\nmakes abstract action plans using the latent transition and feasibility\nfunctions, then refines the high-level plan using low-level policies. PARL\ngeneralizes across scenarios involving novel object instances and environments,\nunseen concept compositions, and tasks that require longer planning horizons\nthan settings it is trained on.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "The first two authors contributed equally. The last two authors\n  provide equal advising. Project website: https://parl2024.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.03864v1",
    "published_date": "2024-05-06 21:24:22 UTC",
    "updated_date": "2024-05-06 21:24:22 UTC"
  },
  {
    "arxiv_id": "2405.03862v3",
    "title": "Persona Inconstancy in Multi-Agent LLM Collaboration: Conformity, Confabulation, and Impersonation",
    "authors": [
      "Razan Baltaji",
      "Babak Hemmatian",
      "Lav R. Varshney"
    ],
    "abstract": "Multi-agent AI systems can be used for simulating collective decision-making\nin scientific and practical applications. They can also be used to introduce a\ndiverse group discussion step in chatbot pipelines, enhancing the cultural\nsensitivity of the chatbot's responses. These applications, however, are\npredicated on the ability of AI agents to reliably adopt assigned personas and\nmimic human interactions. To see whether LLM agents satisfy these requirements,\nwe examine AI agent ensembles engaged in cross-national collaboration and\ndebate by analyzing their private responses and chat transcripts. Our findings\nsuggest that multi-agent discussions can support collective AI decisions that\nmore often reflect diverse perspectives, yet this effect is tempered by the\nagents' susceptibility to conformity due to perceived peer pressure and\noccasional challenges in maintaining consistent personas and opinions.\nInstructions that encourage debate in support of one's opinions rather than\ncollaboration increase the rate of inconstancy. Without addressing the factors\nwe identify, the full potential of multi-agent frameworks for producing more\nculturally diverse AI outputs or more realistic simulations of group\ndecision-making may remain untapped.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.03862v3",
    "published_date": "2024-05-06 21:20:35 UTC",
    "updated_date": "2024-08-14 18:01:13 UTC"
  },
  {
    "arxiv_id": "2405.03852v1",
    "title": "VSA4VQA: Scaling a Vector Symbolic Architecture to Visual Question Answering on Natural Images",
    "authors": [
      "Anna Penzkofer",
      "Lei Shi",
      "Andreas Bulling"
    ],
    "abstract": "While Vector Symbolic Architectures (VSAs) are promising for modelling\nspatial cognition, their application is currently limited to artificially\ngenerated images and simple spatial queries. We propose VSA4VQA - a novel 4D\nimplementation of VSAs that implements a mental representation of natural\nimages for the challenging task of Visual Question Answering (VQA). VSA4VQA is\nthe first model to scale a VSA to complex spatial queries. Our method is based\non the Semantic Pointer Architecture (SPA) to encode objects in a\nhyperdimensional vector space. To encode natural images, we extend the SPA to\ninclude dimensions for object's width and height in addition to their spatial\nlocation. To perform spatial queries we further introduce learned spatial query\nmasks and integrate a pre-trained vision-language model for answering\nattribute-related questions. We evaluate our method on the GQA benchmark\ndataset and show that it can effectively encode natural images, achieving\ncompetitive performance to state-of-the-art deep learning methods for zero-shot\nVQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in the Proceedings of the Annual Meeting of the\n  Cognitive Science Society (CogSci'24)",
    "pdf_url": "http://arxiv.org/pdf/2405.03852v1",
    "published_date": "2024-05-06 20:59:45 UTC",
    "updated_date": "2024-05-06 20:59:45 UTC"
  },
  {
    "arxiv_id": "2405.03845v1",
    "title": "Self-Improving Customer Review Response Generation Based on LLMs",
    "authors": [
      "Guy Azov",
      "Tatiana Pelc",
      "Adi Fledel Alon",
      "Gila Kamhi"
    ],
    "abstract": "Previous studies have demonstrated that proactive interaction with user\nreviews has a positive impact on the perception of app users and encourages\nthem to submit revised ratings. Nevertheless, developers encounter challenges\nin managing a high volume of reviews, particularly in the case of popular apps\nwith a substantial influx of daily reviews. Consequently, there is a demand for\nautomated solutions aimed at streamlining the process of responding to user\nreviews. To address this, we have developed a new system for generating\nautomatic responses by leveraging user-contributed documents with the help of\nretrieval-augmented generation (RAG) and advanced Large Language Models (LLMs).\nOur solution, named SCRABLE, represents an adaptive customer review response\nautomation that enhances itself with self-optimizing prompts and a judging\nmechanism based on LLMs. Additionally, we introduce an automatic scoring\nmechanism that mimics the role of a human evaluator to assess the quality of\nresponses generated in customer review domains. Extensive experiments and\nanalyses conducted on real-world datasets reveal that our method is effective\nin producing high-quality responses, yielding improvement of more than 8.5%\ncompared to the baseline. Further validation through manual examination of the\ngenerated responses underscores the efficacy our proposed system.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 4 figure, 8 figures in Appendix, accepted to LREC-COLING\n  2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2405.03845v1",
    "published_date": "2024-05-06 20:50:17 UTC",
    "updated_date": "2024-05-06 20:50:17 UTC"
  },
  {
    "arxiv_id": "2405.03842v1",
    "title": "A Novel Cross-band CSI Prediction Scheme for Multi-band Fingerprint based Localization",
    "authors": [
      "Yuan Ruihao",
      "Huang Kaixuan",
      "Zhang Shunqing"
    ],
    "abstract": "Because of the advantages of computation complexity compared with traditional\nlocalization algorithms, fingerprint based localization is getting increasing\ndemand. Expanding the fingerprint database from the frequency domain by channel\nreconstruction can improve localization accuracy. However, in a mobility\nenvironment, the channel reconstruction accuracy is limited by the time-varying\nparameters. In this paper, we proposed a system to extract the time-varying\nparameters based on space-alternating generalized expectation maximization\n(SAGE) algorithm, then used variational auto-encoder (VAE) to reconstruct the\nchannel state information on another channel. The proposed scheme is tested on\nthe data generated by the deep-MIMO channel model. Mathematical analysis for\nthe viability of our system is also shown in this paper.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03842v1",
    "published_date": "2024-05-06 20:44:58 UTC",
    "updated_date": "2024-05-06 20:44:58 UTC"
  },
  {
    "arxiv_id": "2405.03832v3",
    "title": "Guylingo: The Republic of Guyana Creole Corpora",
    "authors": [
      "Christopher Clarke",
      "Roland Daynauth",
      "Charlene Wilkinson",
      "Hubert Devonish",
      "Jason Mars"
    ],
    "abstract": "While major languages often enjoy substantial attention and resources, the\nlinguistic diversity across the globe encompasses a multitude of smaller,\nindigenous, and regional languages that lack the same level of computational\nsupport. One such region is the Caribbean. While commonly labeled as \"English\nspeaking\", the ex-British Caribbean region consists of a myriad of Creole\nlanguages thriving alongside English. In this paper, we present Guylingo: a\ncomprehensive corpus designed for advancing NLP research in the domain of\nCreolese (Guyanese English-lexicon Creole), the most widely spoken language in\nthe culturally rich nation of Guyana. We first outline our framework for\ngathering and digitizing this diverse corpus, inclusive of colloquial\nexpressions, idioms, and regional variations in a low-resource language. We\nthen demonstrate the challenges of training and evaluating NLP models for\nmachine translation in Creole. Lastly, we discuss the unique opportunities\npresented by recent NLP advancements for accelerating the formal adoption of\nCreole languages as official languages in the Caribbean.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 Main Conference Special Theme Track: Languages\n  of Latin America and The Caribbean",
    "pdf_url": "http://arxiv.org/pdf/2405.03832v3",
    "published_date": "2024-05-06 20:30:14 UTC",
    "updated_date": "2024-07-02 21:23:32 UTC"
  },
  {
    "arxiv_id": "2405.03825v1",
    "title": "Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence",
    "authors": [
      "Silvan Ferreira",
      "Ivanovitch Silva",
      "Allan Martins"
    ],
    "abstract": "Recent developments in Large Language Models (LLMs) have significantly\nexpanded their applications across various domains. However, the effectiveness\nof LLMs is often constrained when operating individually in complex\nenvironments. This paper introduces a transformative approach by organizing\nLLMs into community-based structures, aimed at enhancing their collective\nintelligence and problem-solving capabilities. We investigate different\norganizational models-hierarchical, flat, dynamic, and federated-each\npresenting unique benefits and challenges for collaborative AI systems. Within\nthese structured communities, LLMs are designed to specialize in distinct\ncognitive tasks, employ advanced interaction mechanisms such as direct\ncommunication, voting systems, and market-based approaches, and dynamically\nadjust their governance structures to meet changing demands. The implementation\nof such communities holds substantial promise for improve problem-solving\ncapabilities in AI, prompting an in-depth examination of their ethical\nconsiderations, management strategies, and scalability potential. This position\npaper seeks to lay the groundwork for future research, advocating a paradigm\nshift from isolated to synergistic operational frameworks in AI research and\napplication.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03825v1",
    "published_date": "2024-05-06 20:15:45 UTC",
    "updated_date": "2024-05-06 20:15:45 UTC"
  },
  {
    "arxiv_id": "2405.03821v1",
    "title": "Thoughtful Things: Building Human-Centric Smart Devices with Small Language Models",
    "authors": [
      "Evan King",
      "Haoxiang Yu",
      "Sahil Vartak",
      "Jenna Jacob",
      "Sangsu Lee",
      "Christine Julien"
    ],
    "abstract": "Everyday devices like light bulbs and kitchen appliances are now embedded\nwith so many features and automated behaviors that they have become complicated\nto actually use. While such \"smart\" capabilities can better support users'\ngoals, the task of learning the \"ins and outs\" of different devices is\ndaunting. Voice assistants aim to solve this problem by providing a natural\nlanguage interface to devices, yet such assistants cannot understand\nloosely-constrained commands, they lack the ability to reason about and explain\ndevices' behaviors to users, and they rely on connectivity to intrusive cloud\ninfrastructure. Toward addressing these issues, we propose thoughtful things:\ndevices that leverage lightweight, on-device language models to take actions\nand explain their behaviors in response to unconstrained user commands. We\npropose an end-to-end framework that leverages formal modeling, automated\ntraining data synthesis, and generative language models to create devices that\nare both capable and thoughtful in the presence of unconstrained user goals and\ninquiries. Our framework requires no labeled data and can be deployed\non-device, with no cloud dependency. We implement two thoughtful things (a lamp\nand a thermostat) and deploy them on real hardware, evaluating their practical\nperformance.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "24 pages (3 pages of references)",
    "pdf_url": "http://arxiv.org/pdf/2405.03821v1",
    "published_date": "2024-05-06 20:04:53 UTC",
    "updated_date": "2024-05-06 20:04:53 UTC"
  },
  {
    "arxiv_id": "2405.03820v2",
    "title": "False Sense of Security in Explainable Artificial Intelligence (XAI)",
    "authors": [
      "Neo Christopher Chung",
      "Hongkyou Chung",
      "Hearim Lee",
      "Lennart Brocki",
      "Hongbeom Chung",
      "George Dyer"
    ],
    "abstract": "A cautious interpretation of AI regulations and policy in the EU and the USA\nplace explainability as a central deliverable of compliant AI systems. However,\nfrom a technical perspective, explainable AI (XAI) remains an elusive and\ncomplex target where even state of the art methods often reach erroneous,\nmisleading, and incomplete explanations. \"Explainability\" has multiple meanings\nwhich are often used interchangeably, and there are an even greater number of\nXAI methods - none of which presents a clear edge. Indeed, there are multiple\nfailure modes for each XAI method, which require application-specific\ndevelopment and continuous evaluation. In this paper, we analyze legislative\nand policy developments in the United States and the European Union, such as\nthe Executive Order on the Safe, Secure, and Trustworthy Development and Use of\nArtificial Intelligence, the AI Act, the AI Liability Directive, and the\nGeneral Data Protection Regulation (GDPR) from a right to explanation\nperspective. We argue that these AI regulations and current market conditions\nthreaten effective AI governance and safety because the objective of\ntrustworthy, accountable, and transparent AI is intrinsically linked to the\nquestionable ability of AI operators to provide meaningful explanations. Unless\ngovernments explicitly tackle the issue of explainability through clear\nlegislative and policy statements that take into account technical realities,\nAI governance risks becoming a vacuous \"box-ticking\" exercise where scientific\nstandards are replaced with legalistic thresholds, providing only a false sense\nof security in XAI.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "AI Governance Workshop at the 2024 International Joint Conference on\n  Artificial Intelligence (IJCAI)",
    "pdf_url": "http://arxiv.org/pdf/2405.03820v2",
    "published_date": "2024-05-06 20:02:07 UTC",
    "updated_date": "2024-06-13 09:57:12 UTC"
  },
  {
    "arxiv_id": "2405.03809v1",
    "title": "SocialFormer: Social Interaction Modeling with Edge-enhanced Heterogeneous Graph Transformers for Trajectory Prediction",
    "authors": [
      "Zixu Wang",
      "Zhigang Sun",
      "Juergen Luettin",
      "Lavdim Halilaj"
    ],
    "abstract": "Accurate trajectory prediction is crucial for ensuring safe and efficient\nautonomous driving. However, most existing methods overlook complex\ninteractions between traffic participants that often govern their future\ntrajectories. In this paper, we propose SocialFormer, an agent\ninteraction-aware trajectory prediction method that leverages the semantic\nrelationship between the target vehicle and surrounding vehicles by making use\nof the road topology. We also introduce an edge-enhanced heterogeneous graph\ntransformer (EHGT) as the aggregator in a graph neural network (GNN) to encode\nthe semantic and spatial agent interaction information. Additionally, we\nintroduce a temporal encoder based on gated recurrent units (GRU) to model the\ntemporal social behavior of agent movements. Finally, we present an information\nfusion framework that integrates agent encoding, lane encoding, and agent\ninteraction encoding for a holistic representation of the traffic scene. We\nevaluate SocialFormer for the trajectory prediction task on the popular\nnuScenes benchmark and achieve state-of-the-art performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03809v1",
    "published_date": "2024-05-06 19:47:23 UTC",
    "updated_date": "2024-05-06 19:47:23 UTC"
  },
  {
    "arxiv_id": "2405.03799v1",
    "title": "Synthetic Data from Diffusion Models Improve Drug Discovery Prediction",
    "authors": [
      "Bing Hu",
      "Ashish Saragadam",
      "Anita Layton",
      "Helen Chen"
    ],
    "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug\ndevelopment. Continuing breakthroughs in AI-based methods for drug discovery\nrequire the creation, improvement, and refinement of drug discovery data. We\nposit a new data challenge that slows the advancement of drug discovery AI:\ndatasets are often collected independently from each other, often with little\noverlap, creating data sparsity. Data sparsity makes data curation difficult\nfor researchers looking to answer key research questions requiring values posed\nacross multiple datasets. We propose a novel diffusion GNN model Syngand\ncapable of generating ligand and pharmacokinetic data end-to-end. We show and\nprovide a methodology for sampling pharmacokinetic data for existing ligands\nusing our Syngand model. We show the initial promising results on the efficacy\nof the Syngand-generated synthetic target property data on downstream\nregression tasks with AqSolDB, LD50, and hERG central. Using our proposed model\nand methodology, researchers can easily generate synthetic ligand data to help\nthem explore research questions that require data spanning multiple datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03799v1",
    "published_date": "2024-05-06 19:09:37 UTC",
    "updated_date": "2024-05-06 19:09:37 UTC"
  },
  {
    "arxiv_id": "2405.03789v1",
    "title": "On Adversarial Examples for Text Classification by Perturbing Latent Representations",
    "authors": [
      "Korn Sooksatra",
      "Bikram Khanal",
      "Pablo Rivas"
    ],
    "abstract": "Recently, with the advancement of deep learning, several applications in text\nclassification have advanced significantly. However, this improvement comes\nwith a cost because deep learning is vulnerable to adversarial examples. This\nweakness indicates that deep learning is not very robust. Fortunately, the\ninput of a text classifier is discrete. Hence, it can prevent the classifier\nfrom state-of-the-art attacks. Nonetheless, previous works have generated\nblack-box attacks that successfully manipulate the discrete values of the input\nto find adversarial examples. Therefore, instead of changing the discrete\nvalues, we transform the input into its embedding vector containing real values\nto perform the state-of-the-art white-box attacks. Then, we convert the\nperturbed embedding vector back into a text and name it an adversarial example.\nIn summary, we create a framework that measures the robustness of a text\nclassifier by using the gradients of the classifier.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "68T01, 68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.03789v1",
    "published_date": "2024-05-06 18:45:18 UTC",
    "updated_date": "2024-05-06 18:45:18 UTC"
  },
  {
    "arxiv_id": "2405.03777v1",
    "title": "Is ReLU Adversarially Robust?",
    "authors": [
      "Korn Sooksatra",
      "Greg Hamerly",
      "Pablo Rivas"
    ],
    "abstract": "The efficacy of deep learning models has been called into question by the\npresence of adversarial examples. Addressing the vulnerability of deep learning\nmodels to adversarial examples is crucial for ensuring their continued\ndevelopment and deployment. In this work, we focus on the role of rectified\nlinear unit (ReLU) activation functions in the generation of adversarial\nexamples. ReLU functions are commonly used in deep learning models because they\nfacilitate the training process. However, our empirical analysis demonstrates\nthat ReLU functions are not robust against adversarial examples. We propose a\nmodified version of the ReLU function, which improves robustness against\nadversarial examples. Our results are supported by an experiment, which\nconfirms the effectiveness of our proposed modification. Additionally, we\ndemonstrate that applying adversarial training to our customized model further\nenhances its robustness compared to a general model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.03777v1",
    "published_date": "2024-05-06 18:19:01 UTC",
    "updated_date": "2024-05-06 18:19:01 UTC"
  },
  {
    "arxiv_id": "2407.10311v1",
    "title": "Sora and V-JEPA Have Not Learned The Complete Real World Model -- A Philosophical Analysis of Video AIs Through the Theory of Productive Imagination",
    "authors": [
      "Jianqiu Zhang"
    ],
    "abstract": "Sora from Open AI has shown exceptional performance, yet it faces scrutiny\nover whether its technological prowess equates to an authentic comprehension of\nreality. Critics contend that it lacks a foundational grasp of the world, a\ndeficiency V-JEPA from Meta aims to amend with its joint embedding approach.\nThis debate is vital for steering the future direction of Artificial General\nIntelligence(AGI). We enrich this debate by developing a theory of productive\nimagination that generates a coherent world model based on Kantian philosophy.\nWe identify three indispensable components of the coherent world model capable\nof genuine world understanding: representations of isolated objects, an a\npriori law of change across space and time, and Kantian categories. Our\nanalysis reveals that Sora is limited because of its oversight of the a priori\nlaw of change and Kantian categories, flaws that are not rectifiable through\nscaling up the training. V-JEPA learns the context-dependent aspect of the a\npriori law of change. Yet it fails to fully comprehend Kantian categories and\nincorporate experience, leading us to conclude that neither system currently\nachieves a comprehensive world understanding. Nevertheless, each system has\ndeveloped components essential to advancing an integrated AI productive\nimagination-understanding engine. Finally, we propose an innovative training\nframework for an AI productive imagination-understanding engine, centered\naround a joint embedding system designed to transform disordered perceptual\ninput into a structured, coherent world model. Our philosophical analysis\npinpoints critical challenges within contemporary video AI technologies and a\npathway toward achieving an AI system capable of genuine world understanding,\nsuch that it can be applied for reasoning and planning in the future.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "00-68",
      "K.m"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.10311v1",
    "published_date": "2024-05-06 18:18:13 UTC",
    "updated_date": "2024-05-06 18:18:13 UTC"
  },
  {
    "arxiv_id": "2405.03685v1",
    "title": "Language-Image Models with 3D Understanding",
    "authors": [
      "Jang Hyun Cho",
      "Boris Ivanovic",
      "Yulong Cao",
      "Edward Schmerling",
      "Yue Wang",
      "Xinshuo Weng",
      "Boyi Li",
      "Yurong You",
      "Philipp Krähenbühl",
      "Yan Wang",
      "Marco Pavone"
    ],
    "abstract": "Multi-modal large language models (MLLMs) have shown incredible capabilities\nin a variety of 2D vision and language tasks. We extend MLLMs' perceptual\ncapabilities to ground and reason about images in 3-dimensional space. To that\nend, we first develop a large-scale pre-training dataset for 2D and 3D called\nLV3D by combining multiple existing 2D and 3D recognition datasets under a\ncommon task formulation: as multi-turn question-answering. Next, we introduce a\nnew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data\nscaling makes a strong 3D perception capability without 3D specific\narchitectural design or training objective. Cube-LLM exhibits intriguing\nproperties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting\nto improve 3D understanding from 2D context information. (2) Cube-LLM can\nfollow complex and diverse instructions and adapt to versatile input and output\nformats. (3) Cube-LLM can be visually prompted such as 2D box or a set of\ncandidate 3D boxes from specialists. Our experiments on outdoor benchmarks\ndemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3\npoints of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7\npoints on the DriveLM dataset for complex reasoning about driving scenarios,\nrespectively. Cube-LLM also shows competitive results in general MLLM\nbenchmarks such as refCOCO for 2D grounding with (87.0) average score, as well\nas visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for\ncomplex reasoning. Our project is available at\nhttps://janghyuncho.github.io/Cube-LLM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://janghyuncho.github.io/Cube-LLM",
    "pdf_url": "http://arxiv.org/pdf/2405.03685v1",
    "published_date": "2024-05-06 17:57:27 UTC",
    "updated_date": "2024-05-06 17:57:27 UTC"
  },
  {
    "arxiv_id": "2405.03673v1",
    "title": "MemoryMamba: Memory-Augmented State Space Model for Defect Recognition",
    "authors": [
      "Qianning Wang",
      "He Hu",
      "Yucheng Zhou"
    ],
    "abstract": "As automation advances in manufacturing, the demand for precise and\nsophisticated defect detection technologies grows. Existing vision models for\ndefect recognition methods are insufficient for handling the complexities and\nvariations of defects in contemporary manufacturing settings. These models\nespecially struggle in scenarios involving limited or imbalanced defect data.\nIn this work, we introduce MemoryMamba, a novel memory-augmented state space\nmodel (SSM), designed to overcome the limitations of existing defect\nrecognition models. MemoryMamba integrates the state space model with the\nmemory augmentation mechanism, enabling the system to maintain and retrieve\nessential defect-specific information in training. Its architecture is designed\nto capture dependencies and intricate defect characteristics, which are crucial\nfor effective defect detection. In the experiments, MemoryMamba was evaluated\nacross four industrial datasets with diverse defect types and complexities. The\nmodel consistently outperformed other methods, demonstrating its capability to\nadapt to various defect recognition scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03673v1",
    "published_date": "2024-05-06 17:49:31 UTC",
    "updated_date": "2024-05-06 17:49:31 UTC"
  },
  {
    "arxiv_id": "2405.03671v1",
    "title": "Prompting Task Trees using Gemini: Methodologies and Insights",
    "authors": [
      "Pallavi Tandra"
    ],
    "abstract": "Robots are the future of every technology where every advanced technology\neventually will be used to make robots which are more efficient. The major\nchallenge today is to train the robots exactly and empathetically using\nknowledge representation. This paper gives you insights of how we can use\nunstructured knowledge representation and convert them to meaningful structured\nrepresentation with the help of prompt engineering which can be eventually used\nin the robots to make help them understand how human brain can make wonders\nwith the minimal data or objects can providing to them.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03671v1",
    "published_date": "2024-05-06 17:48:10 UTC",
    "updated_date": "2024-05-06 17:48:10 UTC"
  },
  {
    "arxiv_id": "2405.03666v1",
    "title": "ScrewMimic: Bimanual Imitation from Human Videos with Screw Space Projection",
    "authors": [
      "Arpit Bahety",
      "Priyanka Mandikal",
      "Ben Abbatematteo",
      "Roberto Martín-Martín"
    ],
    "abstract": "Bimanual manipulation is a longstanding challenge in robotics due to the\nlarge number of degrees of freedom and the strict spatial and temporal\nsynchronization required to generate meaningful behavior. Humans learn bimanual\nmanipulation skills by watching other humans and by refining their abilities\nthrough play. In this work, we aim to enable robots to learn bimanual\nmanipulation behaviors from human video demonstrations and fine-tune them\nthrough interaction. Inspired by seminal work in psychology and biomechanics,\nwe propose modeling the interaction between two hands as a serial kinematic\nlinkage -- as a screw motion, in particular, that we use to define a new action\nspace for bimanual manipulation: screw actions. We introduce ScrewMimic, a\nframework that leverages this novel action representation to facilitate\nlearning from human demonstration and self-supervised policy fine-tuning. Our\nexperiments demonstrate that ScrewMimic is able to learn several complex\nbimanual behaviors from a single human video demonstration, and that it\noutperforms baselines that interpret demonstrations and fine-tune directly in\nthe original space of motion of both arms. For more information and video\nresults, https://robin-lab.cs.utexas.edu/ScrewMimic/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.03666v1",
    "published_date": "2024-05-06 17:43:34 UTC",
    "updated_date": "2024-05-06 17:43:34 UTC"
  },
  {
    "arxiv_id": "2405.15793v3",
    "title": "SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering",
    "authors": [
      "John Yang",
      "Carlos E. Jimenez",
      "Alexander Wettig",
      "Kilian Lieret",
      "Shunyu Yao",
      "Karthik Narasimhan",
      "Ofir Press"
    ],
    "abstract": "Language model (LM) agents are increasingly being used to automate\ncomplicated tasks in digital environments. Just as humans benefit from powerful\nsoftware applications, such as integrated development environments, for complex\ntasks like software engineering, we posit that LM agents represent a new\ncategory of end users with their own needs and abilities, and would benefit\nfrom specially-built interfaces to the software they use. We investigate how\ninterface design affects the performance of language model agents. As a result\nof this exploration, we introduce SWE-agent: a system that facilitates LM\nagents to autonomously use computers to solve software engineering tasks.\nSWE-agent's custom agent-computer interface (ACI) significantly enhances an\nagent's ability to create and edit code files, navigate entire repositories,\nand execute tests and other programs. We evaluate SWE-agent on SWE-bench and\nHumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate\nof 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art\nachieved with non-interactive LMs. Finally, we provide insight on how the\ndesign of the ACI can impact agents' behavior and performance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Code, data, and demo available at https://swe-agent.com",
    "pdf_url": "http://arxiv.org/pdf/2405.15793v3",
    "published_date": "2024-05-06 17:41:33 UTC",
    "updated_date": "2024-11-11 20:01:15 UTC"
  },
  {
    "arxiv_id": "2405.03654v2",
    "title": "Can LLMs Deeply Detect Complex Malicious Queries? A Framework for Jailbreaking via Obfuscating Intent",
    "authors": [
      "Shang Shang",
      "Xinqiang Zhao",
      "Zhongjiang Yao",
      "Yepeng Yao",
      "Liya Su",
      "Zijing Fan",
      "Xiaodan Zhang",
      "Zhengwei Jiang"
    ],
    "abstract": "To demonstrate and address the underlying maliciousness, we propose a\ntheoretical hypothesis and analytical approach, and introduce a new black-box\njailbreak attack methodology named IntentObfuscator, exploiting this identified\nflaw by obfuscating the true intentions behind user prompts.This approach\ncompels LLMs to inadvertently generate restricted content, bypassing their\nbuilt-in content security measures. We detail two implementations under this\nframework: \"Obscure Intention\" and \"Create Ambiguity\", which manipulate query\ncomplexity and ambiguity to evade malicious intent detection effectively. We\nempirically validate the effectiveness of the IntentObfuscator method across\nseveral models, including ChatGPT-3.5, ChatGPT-4, Qwen and Baichuan, achieving\nan average jailbreak success rate of 69.21\\%. Notably, our tests on\nChatGPT-3.5, which claims 100 million weekly active users, achieved a\nremarkable success rate of 83.65\\%. We also extend our validation to diverse\ntypes of sensitive content like graphic violence, racism, sexism, political\nsensitivity, cybersecurity threats, and criminal skills, further proving the\nsubstantial impact of our findings on enhancing 'Red Team' strategies against\nLLM content security frameworks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03654v2",
    "published_date": "2024-05-06 17:26:34 UTC",
    "updated_date": "2024-05-07 10:20:07 UTC"
  },
  {
    "arxiv_id": "2405.03644v2",
    "title": "When LLMs Meet Cybersecurity: A Systematic Literature Review",
    "authors": [
      "Jie Zhang",
      "Haoyu Bu",
      "Hui Wen",
      "Yongji Liu",
      "Haiqiang Fei",
      "Rongrong Xi",
      "Lun Li",
      "Yun Yang",
      "Hongsong Zhu",
      "Dan Meng"
    ],
    "abstract": "The rapid development of large language models (LLMs) has opened new avenues\nacross various fields, including cybersecurity, which faces an evolving threat\nlandscape and demand for innovative technologies. Despite initial explorations\ninto the application of LLMs in cybersecurity, there is a lack of a\ncomprehensive overview of this research area. This paper addresses this gap by\nproviding a systematic literature review, covering the analysis of over 300\nworks, encompassing 25 LLMs and more than 10 downstream scenarios. Our\ncomprehensive overview addresses three key research questions: the construction\nof cybersecurity-oriented LLMs, the application of LLMs to various\ncybersecurity tasks, the challenges and further research in this area. This\nstudy aims to shed light on the extensive potential of LLMs in enhancing\ncybersecurity practices and serve as a valuable resource for applying LLMs in\nthis field. We also maintain and regularly update a list of practical guides on\nLLMs for cybersecurity at https://github.com/tmylla/Awesome-LLM4Cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "We have updated the related papers up to Aug 31st, with 50+ new\n  papers added",
    "pdf_url": "http://arxiv.org/pdf/2405.03644v2",
    "published_date": "2024-05-06 17:07:28 UTC",
    "updated_date": "2024-12-04 14:27:06 UTC"
  },
  {
    "arxiv_id": "2405.03620v2",
    "title": "Detecting Android Malware: From Neural Embeddings to Hands-On Validation with BERTroid",
    "authors": [
      "Meryam Chaieb",
      "Mostafa Anouar Ghorab",
      "Mohamed Aymen Saied"
    ],
    "abstract": "As cyber threats and malware attacks increasingly alarm both individuals and\nbusinesses, the urgency for proactive malware countermeasures intensifies. This\nhas driven a rising interest in automated machine learning solutions.\nTransformers, a cutting-edge category of attention-based deep learning methods,\nhave demonstrated remarkable success. In this paper, we present BERTroid, an\ninnovative malware detection model built on the BERT architecture. Overall,\nBERTroid emerged as a promising solution for combating Android malware. Its\nability to outperform state-of-the-art solutions demonstrates its potential as\na proactive defense mechanism against malicious software attacks. Additionally,\nwe evaluate BERTroid on multiple datasets to assess its performance across\ndiverse scenarios. In the dynamic landscape of cybersecurity, our approach has\ndemonstrated promising resilience against the rapid evolution of malware on\nAndroid systems. While the machine learning model captures broad patterns, we\nemphasize the role of manual validation for deeper comprehension and insight\ninto these behaviors. This human intervention is critical for discerning\nintricate and context-specific behaviors, thereby validating and reinforcing\nthe model's findings.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03620v2",
    "published_date": "2024-05-06 16:35:56 UTC",
    "updated_date": "2024-08-12 15:16:15 UTC"
  },
  {
    "arxiv_id": "2405.03616v1",
    "title": "A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama",
    "authors": [
      "Vlad-Andrei Cursaru",
      "Laura Duits",
      "Joel Milligan",
      "Damla Ural",
      "Berta Rodriguez Sanchez",
      "Vincenzo Stoico",
      "Ivano Malavolta"
    ],
    "abstract": "Context. Nowadays, 83% of software developers use Large Language Models\n(LLMs) to generate code. LLMs recently became essential to increase the\nproductivity of software developers and decrease the time and cost of software\ndevelopment. Developers ranging from novices to experts use LLM tools not only\nto detect and patch bugs, but also to integrate generated code into their\nsoftware. However, as of today there is no objective assessment of the energy\nefficiency of the source code generated by LLM tools. Released in August 2023,\nCode Llama is one of the most recent LLM tools.\n  Goal. In this paper, we present an empirical study that assesses the energy\nefficiency of Code Llama with respect to human-written source code.\n  Method. We design an experiment involving three human-written benchmarks\nimplemented in C++, JavaScript, and Python. We ask Code Llama to generate the\ncode of the benchmarks using different prompts and temperatures. Therefore, we\nexecute both implementations and profile their energy efficiency.\n  Results. Our study shows that the energy efficiency of code generated by Code\nLlama is heavily-dependent on the chosen programming language and the specific\ncode problem at hand. Also, human implementations tend to be more energy\nefficient overall, with generated JavaScript code outperforming its human\ncounterpart. Moreover, explicitly asking Code Llama to generate\nenergy-efficient code results in an equal or worse energy efficiency, as well\nas using different temperatures seems not to affect the energy efficiency of\ngenerated code.\n  Conclusions. According to our results, code generated using Code Llama does\nnot guarantee energy efficiency, even when prompted to do so. Therefore,\nsoftware developers should evaluate the energy efficiency of generated code\nbefore integrating it into the software system under development.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03616v1",
    "published_date": "2024-05-06 16:32:29 UTC",
    "updated_date": "2024-05-06 16:32:29 UTC"
  },
  {
    "arxiv_id": "2406.04347v1",
    "title": "Process Variant Analysis Across Continuous Features: A Novel Framework",
    "authors": [
      "Ali Norouzifar",
      "Majid Rafiei",
      "Marcus Dees",
      "Wil van der Aalst"
    ],
    "abstract": "Extracted event data from information systems often contain a variety of\nprocess executions making the data complex and difficult to comprehend. Unlike\ncurrent research which only identifies the variability over time, we focus on\nother dimensions that may play a role in the performance of the process. This\nresearch addresses the challenge of effectively segmenting cases within\noperational processes based on continuous features, such as duration of cases,\nand evaluated risk score of cases, which are often overlooked in traditional\nprocess analysis. We present a novel approach employing a sliding window\ntechnique combined with the earth mover's distance to detect changes in control\nflow behavior over continuous dimensions. This approach enables case\nsegmentation, hierarchical merging of similar segments, and pairwise comparison\nof them, providing a comprehensive perspective on process behavior. We validate\nour methodology through a real-life case study in collaboration with UWV, the\nDutch employee insurance agency, demonstrating its practical applicability.\nThis research contributes to the field by aiding organizations in improving\nprocess efficiency, pinpointing abnormal behaviors, and providing valuable\ninputs for process comparison, and outcome prediction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the BPMDS 2024 conference and to be published in their\n  proceedings",
    "pdf_url": "http://arxiv.org/pdf/2406.04347v1",
    "published_date": "2024-05-06 16:10:13 UTC",
    "updated_date": "2024-05-06 16:10:13 UTC"
  },
  {
    "arxiv_id": "2405.12997v1",
    "title": "Research information in the light of artificial intelligence: quality and data ecologies",
    "authors": [
      "Otmane Azeroual",
      "Tibor Koltay"
    ],
    "abstract": "This paper presents multi- and interdisciplinary approaches for finding the\nappropriate AI technologies for research information. Professional research\ninformation management (RIM) is becoming increasingly important as an expressly\ndata-driven tool for researchers. It is not only the basis of scientific\nknowledge processes, but also related to other data. A concept and a process\nmodel of the elementary phases from the start of the project to the ongoing\noperation of the AI methods in the RIM is presented, portraying the\nimplementation of an AI project, meant to enable universities and research\ninstitutions to support their researchers in dealing with incorrect and\nincomplete research information, while it is being stored in their RIMs. Our\naim is to show how research information harmonizes with the challenges of data\nliteracy and data quality issues, related to AI, also wanting to underline that\nany project can be successful if the research institutions and various\ndepartments of universities, involved work together and appropriate support is\noffered to improve research information and data management.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "Education and Research in the Information Society (ERIS2023)",
    "pdf_url": "http://arxiv.org/pdf/2405.12997v1",
    "published_date": "2024-05-06 16:07:56 UTC",
    "updated_date": "2024-05-06 16:07:56 UTC"
  },
  {
    "arxiv_id": "2405.03595v2",
    "title": "GREEN: Generative Radiology Report Evaluation and Error Notation",
    "authors": [
      "Sophie Ostmeier",
      "Justin Xu",
      "Zhihong Chen",
      "Maya Varma",
      "Louis Blankemeier",
      "Christian Bluethgen",
      "Arne Edward Michalson",
      "Michael Moseley",
      "Curtis Langlotz",
      "Akshay S Chaudhari",
      "Jean-Benoit Delbrouck"
    ],
    "abstract": "Evaluating radiology reports is a challenging problem as factual correctness\nis extremely important due to the need for accurate medical communication about\nmedical images. Existing automatic evaluation metrics either suffer from\nfailing to consider factual correctness (e.g., BLEU and ROUGE) or are limited\nin their interpretability (e.g., F1CheXpert and F1RadGraph). In this paper, we\nintroduce GREEN (Generative Radiology Report Evaluation and Error Notation), a\nradiology report generation metric that leverages the natural language\nunderstanding of language models to identify and explain clinically significant\nerrors in candidate reports, both quantitatively and qualitatively. Compared to\ncurrent metrics, GREEN offers: 1) a score aligned with expert preferences, 2)\nhuman interpretable explanations of clinically significant errors, enabling\nfeedback loops with end-users, and 3) a lightweight open-source method that\nreaches the performance of commercial counterparts. We validate our GREEN\nmetric by comparing it to GPT-4, as well as to error counts of 6 experts and\npreferences of 2 experts. Our method demonstrates not only higher correlation\nwith expert error counts, but simultaneously higher alignment with expert\npreferences when compared to previous approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03595v2",
    "published_date": "2024-05-06 16:04:03 UTC",
    "updated_date": "2025-01-22 06:24:43 UTC"
  },
  {
    "arxiv_id": "2405.03594v1",
    "title": "Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment",
    "authors": [
      "Abhinav Agarwalla",
      "Abhay Gupta",
      "Alexandre Marques",
      "Shubhra Pandit",
      "Michael Goin",
      "Eldar Kurtic",
      "Kevin Leong",
      "Tuan Nguyen",
      "Mahmoud Salem",
      "Dan Alistarh",
      "Sean Lie",
      "Mark Kurtz"
    ],
    "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing\n(NLP), but their size creates computational bottlenecks. We introduce a novel\napproach to create accurate, sparse foundational versions of performant LLMs\nthat achieve full accuracy recovery for fine-tuning tasks at up to 70%\nsparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT\none-shot pruning method and sparse pretraining of those models on a subset of\nthe SlimPajama dataset mixed with a Python subset of The Stack dataset. We\nexhibit training acceleration due to sparsity on Cerebras CS-3 chips that\nclosely matches theoretical scaling. In addition, we establish inference\nacceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine\nand 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are\nrealized via sparsity alone, thus enabling further gains through additional use\nof quantization. Specifically, we show a total speedup on CPUs for\nsparse-quantized LLaMA models of up to 8.6x. We demonstrate these results\nacross diverse, challenging tasks, including chat, instruction following, code\ngeneration, arithmetic reasoning, and summarization to prove their generality.\nThis work paves the way for rapidly creating smaller and faster LLMs without\nsacrificing accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03594v1",
    "published_date": "2024-05-06 16:03:32 UTC",
    "updated_date": "2024-05-06 16:03:32 UTC"
  },
  {
    "arxiv_id": "2405.03735v1",
    "title": "Select to Perfect: Imitating desired behavior from large multi-agent data",
    "authors": [
      "Tim Franzmeyer",
      "Edith Elkind",
      "Philip Torr",
      "Jakob Foerster",
      "Joao Henriques"
    ],
    "abstract": "AI agents are commonly trained with large datasets of demonstrations of human\nbehavior. However, not all behaviors are equally safe or desirable. Desired\ncharacteristics for an AI agent can be expressed by assigning desirability\nscores, which we assume are not assigned to individual behaviors but to\ncollective trajectories. For example, in a dataset of vehicle interactions,\nthese scores might relate to the number of incidents that occurred. We first\nassess the effect of each individual agent's behavior on the collective\ndesirability score, e.g., assessing how likely an agent is to cause incidents.\nThis allows us to selectively imitate agents with a positive effect, e.g., only\nimitating agents that are unlikely to cause incidents. To enable this, we\npropose the concept of an agent's Exchange Value, which quantifies an\nindividual agent's contribution to the collective desirability score. The\nExchange Value is the expected change in desirability score when substituting\nthe agent for a randomly selected agent. We propose additional methods for\nestimating Exchange Values from real-world datasets, enabling us to learn\ndesired imitation policies that outperform relevant baselines. The project\nwebsite can be found at https://tinyurl.com/select-to-perfect.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03735v1",
    "published_date": "2024-05-06 15:48:24 UTC",
    "updated_date": "2024-05-06 15:48:24 UTC"
  },
  {
    "arxiv_id": "2405.03567v1",
    "title": "Deep Space Separable Distillation for Lightweight Acoustic Scene Classification",
    "authors": [
      "ShuQi Ye",
      "Yuan Tian"
    ],
    "abstract": "Acoustic scene classification (ASC) is highly important in the real world.\nRecently, deep learning-based methods have been widely employed for acoustic\nscene classification. However, these methods are currently not lightweight\nenough as well as their performance is not satisfactory. To solve these\nproblems, we propose a deep space separable distillation network. Firstly, the\nnetwork performs high-low frequency decomposition on the log-mel spectrogram,\nsignificantly reducing computational complexity while maintaining model\nperformance. Secondly, we specially design three lightweight operators for ASC,\nincluding Separable Convolution (SC), Orthonormal Separable Convolution (OSC),\nand Separable Partial Convolution (SPC). These operators exhibit highly\nefficient feature extraction capabilities in acoustic scene classification\ntasks. The experimental results demonstrate that the proposed method achieves a\nperformance gain of 9.8% compared to the currently popular deep learning\nmethods, while also having smaller parameter count and computational\ncomplexity.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03567v1",
    "published_date": "2024-05-06 15:41:41 UTC",
    "updated_date": "2024-05-06 15:41:41 UTC"
  },
  {
    "arxiv_id": "2405.03553v3",
    "title": "AlphaMath Almost Zero: Process Supervision without Process",
    "authors": [
      "Guoxin Chen",
      "Minpeng Liao",
      "Chengxi Li",
      "Kai Fan"
    ],
    "abstract": "Although recent advancements in large language models (LLMs) have\nsignificantly improved their performance on various tasks, they still face\nchallenges with complex and symbolic multi-step reasoning, particularly in\nmathematical reasoning. To bolster the mathematical reasoning capabilities of\nLLMs, most existing efforts concentrate on seeking assistance from either\ndomain experts or GPT-4 for high-quality process-supervised data, which is not\nonly expensive but also labor-intensive. In our study, we propose an innovative\nframework, AlphaMath, that bypasses the need for process annotations (from\nhumans or GPTs) by leveraging Monte Carlo Tree Search (MCTS). This framework\nfocuses on unleashing the potential of a well-pretrained LLM to autonomously\nenhance its mathematical reasoning. Specifically, we integrate a value model\nwith the LLM, automatically generating both process supervision and step-level\nevaluation signals in MCTS. Furthermore, we propose an efficient inference\nstrategy, step-level beam search, where the value model is crafted to assist\nthe policy model (i.e., LLM) in navigating more effective reasoning paths,\nrather than solely relying on prior probabilities. The experimental results on\nboth in-domain and out-of-domain datasets demonstrate that even without GPT-4\nor human-annotated process supervision, our AlphaMath framework achieves\ncomparable or superior results to previous state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera ready version for NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03553v3",
    "published_date": "2024-05-06 15:20:30 UTC",
    "updated_date": "2024-09-27 08:16:28 UTC"
  },
  {
    "arxiv_id": "2405.03734v1",
    "title": "FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering",
    "authors": [
      "Silan Hu",
      "Xiaoning Wang"
    ],
    "abstract": "Integrating large language models (LLMs) and knowledge graphs (KGs) holds\ngreat promise for revolutionizing intelligent education, but challenges remain\nin achieving personalization, interactivity, and explainability. We propose\nFOKE, a Forest Of Knowledge and Education framework that synergizes foundation\nmodels, knowledge graphs, and prompt engineering to address these challenges.\nFOKE introduces three key innovations: (1) a hierarchical knowledge forest for\nstructured domain knowledge representation; (2) a multi-dimensional user\nprofiling mechanism for comprehensive learner modeling; and (3) an interactive\nprompt engineering scheme for generating precise and tailored learning\nguidance.\n  We showcase FOKE's application in programming education, homework assessment,\nand learning path planning, demonstrating its effectiveness and practicality.\nAdditionally, we implement Scholar Hero, a real-world instantiation of FOKE.\nOur research highlights the potential of integrating foundation models,\nknowledge graphs, and prompt engineering to revolutionize intelligent education\npractices, ultimately benefiting learners worldwide. FOKE provides a principled\nand unified approach to harnessing cutting-edge AI technologies for\npersonalized, interactive, and explainable educational services, paving the way\nfor further research and development in this critical direction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03734v1",
    "published_date": "2024-05-06 15:11:05 UTC",
    "updated_date": "2024-05-06 15:11:05 UTC"
  },
  {
    "arxiv_id": "2405.03547v2",
    "title": "Position: Leverage Foundational Models for Black-Box Optimization",
    "authors": [
      "Xingyou Song",
      "Yingtao Tian",
      "Robert Tjarko Lange",
      "Chansoo Lee",
      "Yujin Tang",
      "Yutian Chen"
    ],
    "abstract": "Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave\nof innovation in the machine learning research domain, resulting in substantial\nimpact across diverse fields such as reinforcement learning, robotics, and\ncomputer vision. Their incorporation has been rapid and transformative, marking\na significant paradigm shift in the field of machine learning research.\nHowever, the field of experimental design, grounded on black-box optimization,\nhas been much less affected by such a paradigm shift, even though integrating\nLLMs with optimization presents a unique landscape ripe for exploration. In\nthis position paper, we frame the field of black-box optimization around\nsequence-based foundation models and organize their relationship with previous\nliterature. We discuss the most promising ways foundational language models can\nrevolutionize optimization, which include harnessing the vast wealth of\ninformation encapsulated in free-form text to enrich task comprehension,\nutilizing highly flexible sequence models such as Transformers to engineer\nsuperior optimization strategies, and enhancing performance prediction over\npreviously unseen search spaces.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03547v2",
    "published_date": "2024-05-06 15:10:46 UTC",
    "updated_date": "2024-05-09 14:44:22 UTC"
  },
  {
    "arxiv_id": "2405.03541v1",
    "title": "RepVGG-GELAN: Enhanced GELAN with VGG-STYLE ConvNets for Brain Tumour Detection",
    "authors": [
      "Thennarasi Balakrishnan",
      "Sandeep Singh Sengar"
    ],
    "abstract": "Object detection algorithms particularly those based on YOLO have\ndemonstrated remarkable efficiency in balancing speed and accuracy. However,\ntheir application in brain tumour detection remains underexplored. This study\nproposes RepVGG-GELAN, a novel YOLO architecture enhanced with RepVGG, a\nreparameterized convolutional approach for object detection tasks particularly\nfocusing on brain tumour detection within medical images. RepVGG-GELAN\nleverages the RepVGG architecture to improve both speed and accuracy in\ndetecting brain tumours. Integrating RepVGG into the YOLO framework aims to\nachieve a balance between computational efficiency and detection performance.\nThis study includes a spatial pyramid pooling-based Generalized Efficient Layer\nAggregation Network (GELAN) architecture which further enhances the capability\nof RepVGG. Experimental evaluation conducted on a brain tumour dataset\ndemonstrates the effectiveness of RepVGG-GELAN surpassing existing RCS-YOLO in\nterms of precision and speed. Specifically, RepVGG-GELAN achieves an increased\nprecision of 4.91% and an increased AP50 of 2.54% over the latest existing\napproach while operating at 240.7 GFLOPs. The proposed RepVGG-GELAN with GELAN\narchitecture presents promising results establishing itself as a\nstate-of-the-art solution for accurate and efficient brain tumour detection in\nmedical images. The implementation code is publicly available at\nhttps://github.com/ThensiB/RepVGG-GELAN.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03541v1",
    "published_date": "2024-05-06 15:02:16 UTC",
    "updated_date": "2024-05-06 15:02:16 UTC"
  },
  {
    "arxiv_id": "2405.03537v2",
    "title": "Exploring the Efficacy of Federated-Continual Learning Nodes with Attention-Based Classifier for Robust Web Phishing Detection: An Empirical Investigation",
    "authors": [
      "Jesher Joshua M",
      "Adhithya R",
      "Sree Dananjay S",
      "M Revathi"
    ],
    "abstract": "Web phishing poses a dynamic threat, requiring detection systems to quickly\nadapt to the latest tactics. Traditional approaches of accumulating data and\nperiodically retraining models are outpaced. We propose a novel paradigm\ncombining federated learning and continual learning, enabling distributed nodes\nto continually update models on streams of new phishing data, without\naccumulating data. These locally adapted models are then aggregated at a\ncentral server via federated learning. To enhance detection, we introduce a\ncustom attention-based classifier model with residual connections, tailored for\nweb phishing, leveraging attention mechanisms to capture intricate phishing\npatterns. We evaluate our hybrid learning paradigm across continual learning\nstrategies (cumulative, replay, MIR, LwF) and model architectures through an\nempirical investigation. Our main contributions are: (1) a new hybrid\nfederated-continual learning paradigm for robust web phishing detection, and\n(2) a novel attention + residual connections based model explicitly designed\nfor this task, attaining 0.93 accuracy, 0.90 precision, 0.96 recall and 0.93\nf1-score with the LwF strategy, outperforming traditional approaches in\ndetecting emerging phishing threats while retaining past knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03537v2",
    "published_date": "2024-05-06 14:55:37 UTC",
    "updated_date": "2024-06-16 14:05:53 UTC"
  },
  {
    "arxiv_id": "2405.03534v1",
    "title": "Meta-Evolve: Continuous Robot Evolution for One-to-many Policy Transfer",
    "authors": [
      "Xingyu Liu",
      "Deepak Pathak",
      "Ding Zhao"
    ],
    "abstract": "We investigate the problem of transferring an expert policy from a source\nrobot to multiple different robots. To solve this problem, we propose a method\nnamed $Meta$-$Evolve$ that uses continuous robot evolution to efficiently\ntransfer the policy to each target robot through a set of tree-structured\nevolutionary robot sequences. The robot evolution tree allows the robot\nevolution paths to be shared, so our approach can significantly outperform\nnaive one-to-one policy transfer. We present a heuristic approach to determine\nan optimized robot evolution tree. Experiments have shown that our method is\nable to improve the efficiency of one-to-three transfer of manipulation policy\nby up to 3.2$\\times$ and one-to-six transfer of agile locomotion policy by\n2.4$\\times$ in terms of simulation cost over the baseline of launching multiple\nindependent one-to-one policy transfers.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03534v1",
    "published_date": "2024-05-06 14:52:23 UTC",
    "updated_date": "2024-05-06 14:52:23 UTC"
  },
  {
    "arxiv_id": "2405.09563v1",
    "title": "Stressor Type Matters! -- Exploring Factors Influencing Cross-Dataset Generalizability of Physiological Stress Detection",
    "authors": [
      "Pooja Prajod",
      "Bhargavi Mahesh",
      "Elisabeth André"
    ],
    "abstract": "Automatic stress detection using heart rate variability (HRV) features has\ngained significant traction as it utilizes unobtrusive wearable sensors\nmeasuring signals like electrocardiogram (ECG) or blood volume pulse (BVP).\nHowever, detecting stress through such physiological signals presents a\nconsiderable challenge owing to the variations in recorded signals influenced\nby factors, such as perceived stress intensity and measurement devices.\nConsequently, stress detection models developed on one dataset may perform\npoorly on unseen data collected under different conditions. To address this\nchallenge, this study explores the generalizability of machine learning models\ntrained on HRV features for binary stress detection. Our goal extends beyond\nevaluating generalization performance; we aim to identify the characteristics\nof datasets that have the most significant influence on generalizability. We\nleverage four publicly available stress datasets (WESAD, SWELL-KW,\nForDigitStress, VerBIO) that vary in at least one of the characteristics such\nas stress elicitation techniques, stress intensity, and sensor devices.\nEmploying a cross-dataset evaluation approach, we explore which of these\ncharacteristics strongly influence model generalizability. Our findings reveal\na crucial factor affecting model generalizability: stressor type. Models\nachieved good performance across datasets when the type of stressor (e.g.,\nsocial stress in our case) remains consistent. Factors like stress intensity or\nbrand of the measurement device had minimal impact on cross-dataset\nperformance. Based on our findings, we recommend matching the stressor type\nwhen deploying HRV-based stress models in new environments. To the best of our\nknowledge, this is the first study to systematically investigate factors\ninfluencing the cross-dataset applicability of HRV-based stress models.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.09563v1",
    "published_date": "2024-05-06 14:47:48 UTC",
    "updated_date": "2024-05-06 14:47:48 UTC"
  },
  {
    "arxiv_id": "2405.03524v5",
    "title": "A short Survey: Exploring knowledge graph-based neural-symbolic system from application perspective",
    "authors": [
      "Shenzhe Zhu",
      "Shengxiang Sun"
    ],
    "abstract": "Advancements in Artificial Intelligence (AI) and deep neural networks have\ndriven significant progress in vision and text processing. However, achieving\nhuman-like reasoning and interpretability in AI systems remains a substantial\nchallenge. The Neural-Symbolic paradigm, which integrates neural networks with\nsymbolic systems, presents a promising pathway toward more interpretable AI.\nWithin this paradigm, Knowledge Graphs (KG) are crucial, offering a structured\nand dynamic method for representing knowledge through interconnected entities\nand relationships, typically as triples (subject, predicate, object). This\npaper explores recent advancements in neural-symbolic integration based on KG,\nexamining how it supports integration in three categories: enhancing the\nreasoning and interpretability of neural networks with symbolic knowledge\n(Symbol for Neural), refining the completeness and accuracy of symbolic systems\nvia neural network methodologies (Neural for Symbol), and facilitating their\ncombined application in Hybrid Neural-Symbolic Integration. It highlights\ncurrent trends and proposes future research directions in Neural-Symbolic AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03524v5",
    "published_date": "2024-05-06 14:40:50 UTC",
    "updated_date": "2025-02-18 15:30:43 UTC"
  },
  {
    "arxiv_id": "2405.03521v1",
    "title": "Optimisation challenge for superconducting adiabatic neural network implementing XOR and OR boolean functions",
    "authors": [
      "D. S. Pashin",
      "M. V. Bastrakova",
      "D. A. Rybin",
      "I. I. Soloviev",
      "A. E. Schegolev",
      "N. V. Klenov"
    ],
    "abstract": "In this article, we consider designs of simple analog artificial neural\nnetworks based on adiabatic Josephson cells with a sigmoid activation function.\nA new approach based on the gradient descent method is developed to adjust the\ncircuit parameters, allowing efficient signal transmission between the network\nlayers. The proposed solution is demonstrated on the example of the system\nimplementing XOR and OR logical operations.",
    "categories": [
      "cond-mat.supr-con",
      "cs.AI"
    ],
    "primary_category": "cond-mat.supr-con",
    "comment": "13 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03521v1",
    "published_date": "2024-05-06 14:38:43 UTC",
    "updated_date": "2024-05-06 14:38:43 UTC"
  },
  {
    "arxiv_id": "2405.06686v1",
    "title": "Word2World: Generating Stories and Worlds through Large Language Models",
    "authors": [
      "Muhammad U. Nasir",
      "Steven James",
      "Julian Togelius"
    ],
    "abstract": "Large Language Models (LLMs) have proven their worth across a diverse\nspectrum of disciplines. LLMs have shown great potential in Procedural Content\nGeneration (PCG) as well, but directly generating a level through a pre-trained\nLLM is still challenging. This work introduces Word2World, a system that\nenables LLMs to procedurally design playable games through stories, without any\ntask-specific fine-tuning. Word2World leverages the abilities of LLMs to create\ndiverse content and extract information. Combining these abilities, LLMs can\ncreate a story for the game, design narrative, and place tiles in appropriate\nplaces to create coherent worlds and playable games. We test Word2World with\ndifferent LLMs and perform a thorough ablation study to validate each step. We\nopen-source the code at https://github.com/umair-nasir14/Word2World.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06686v1",
    "published_date": "2024-05-06 14:21:52 UTC",
    "updated_date": "2024-05-06 14:21:52 UTC"
  },
  {
    "arxiv_id": "2405.03501v1",
    "title": "Boosting Single Positive Multi-label Classification with Generalized Robust Loss",
    "authors": [
      "Yanxi Chen",
      "Chunxiao Li",
      "Xinyang Dai",
      "Jinhuan Li",
      "Weiyu Sun",
      "Yiming Wang",
      "Renyuan Zhang",
      "Tinghe Zhang",
      "Bo Wang"
    ],
    "abstract": "Multi-label learning (MLL) requires comprehensive multi-semantic annotations\nthat is hard to fully obtain, thus often resulting in missing labels scenarios.\nIn this paper, we investigate Single Positive Multi-label Learning (SPML),\nwhere each image is associated with merely one positive label. Existing SPML\nmethods only focus on designing losses using mechanisms such as hard\npseudo-labeling and robust losses, mostly leading to unacceptable false\nnegatives. To address this issue, we first propose a generalized loss framework\nbased on expected risk minimization to provide soft pseudo labels, and point\nout that the former losses can be seamlessly converted into our framework. In\nparticular, we design a novel robust loss based on our framework, which enjoys\nflexible coordination between false positives and false negatives, and can\nadditionally deal with the imbalance between positive and negative samples.\nExtensive experiments show that our approach can significantly improve SPML\nperformance and outperform the vast majority of state-of-the-art methods on all\nthe four benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.03501v1",
    "published_date": "2024-05-06 14:13:38 UTC",
    "updated_date": "2024-05-06 14:13:38 UTC"
  },
  {
    "arxiv_id": "2405.03500v1",
    "title": "A Rate-Distortion-Classification Approach for Lossy Image Compression",
    "authors": [
      "Yuefeng Zhang"
    ],
    "abstract": "In lossy image compression, the objective is to achieve minimal signal\ndistortion while compressing images to a specified bit rate. The increasing\ndemand for visual analysis applications, particularly in classification tasks,\nhas emphasized the significance of considering semantic distortion in\ncompressed images. To bridge the gap between image compression and visual\nanalysis, we propose a Rate-Distortion-Classification (RDC) model for lossy\nimage compression, offering a unified framework to optimize the trade-off\nbetween rate, distortion, and classification accuracy. The RDC model is\nextensively analyzed both statistically on a multi-distribution source and\nexperimentally on the widely used MNIST dataset. The findings reveal that the\nRDC model exhibits desirable properties, including monotonic non-increasing and\nconvex functions, under certain conditions. This work provides insights into\nthe development of human-machine friendly compression methods and Video Coding\nfor Machine (VCM) approaches, paving the way for end-to-end image compression\ntechniques in real-world applications.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.MM",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.03500v1",
    "published_date": "2024-05-06 14:11:36 UTC",
    "updated_date": "2024-05-06 14:11:36 UTC"
  },
  {
    "arxiv_id": "2405.03462v1",
    "title": "A Lightweight Neural Architecture Search Model for Medical Image Classification",
    "authors": [
      "Lunchen Xie",
      "Eugenio Lomurno",
      "Matteo Gambella",
      "Danilo Ardagna",
      "Manuel Roveri",
      "Matteo Matteucci",
      "Qingjiang Shi"
    ],
    "abstract": "Accurate classification of medical images is essential for modern\ndiagnostics. Deep learning advancements led clinicians to increasingly use\nsophisticated models to make faster and more accurate decisions, sometimes\nreplacing human judgment. However, model development is costly and repetitive.\nNeural Architecture Search (NAS) provides solutions by automating the design of\ndeep learning architectures. This paper presents ZO-DARTS+, a differentiable\nNAS algorithm that improves search efficiency through a novel method of\ngenerating sparse probabilities by bi-level optimization. Experiments on five\npublic medical datasets show that ZO-DARTS+ matches the accuracy of\nstate-of-the-art solutions while reducing search times by up to three times.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03462v1",
    "published_date": "2024-05-06 13:33:38 UTC",
    "updated_date": "2024-05-06 13:33:38 UTC"
  },
  {
    "arxiv_id": "2405.03452v3",
    "title": "Large Language Models (LLMs) as Agents for Augmented Democracy",
    "authors": [
      "Jairo Gudiño-Rosero",
      "Umberto Grandi",
      "César A. Hidalgo"
    ],
    "abstract": "We explore an augmented democracy system built on off-the-shelf LLMs\nfine-tuned to augment data on citizen's preferences elicited over policies\nextracted from the government programs of the two main candidates of Brazil's\n2022 presidential election. We use a train-test cross-validation setup to\nestimate the accuracy with which the LLMs predict both: a subject's individual\npolitical choices and the aggregate preferences of the full sample of\nparticipants. At the individual level, we find that LLMs predict out of sample\npreferences more accurately than a \"bundle rule\", which would assume that\ncitizens always vote for the proposals of the candidate aligned with their\nself-reported political orientation. At the population level, we show that a\nprobabilistic sample augmented by an LLM provides a more accurate estimate of\nthe aggregate preferences of a population than the non-augmented probabilistic\nsample alone. Together, these results indicates that policy preference data\naugmented using LLMs can capture nuances that transcend party lines and\nrepresents a promising avenue of research for data augmentation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "24 pages main manuscript with 4 figures. 13 pages of supplementary\n  material",
    "pdf_url": "http://arxiv.org/pdf/2405.03452v3",
    "published_date": "2024-05-06 13:23:57 UTC",
    "updated_date": "2024-07-30 09:51:41 UTC"
  },
  {
    "arxiv_id": "2405.03440v1",
    "title": "Robotic Constrained Imitation Learning for the Peg Transfer Task in Fundamentals of Laparoscopic Surgery",
    "authors": [
      "Kento Kawaharazuka",
      "Kei Okada",
      "Masayuki Inaba"
    ],
    "abstract": "In this study, we present an implementation strategy for a robot that\nperforms peg transfer tasks in Fundamentals of Laparoscopic Surgery (FLS) via\nimitation learning, aimed at the development of an autonomous robot for\nlaparoscopic surgery. Robotic laparoscopic surgery presents two main\nchallenges: (1) the need to manipulate forceps using ports established on the\nbody surface as fulcrums, and (2) difficulty in perceiving depth information\nwhen working with a monocular camera that displays its images on a monitor.\nEspecially, regarding issue (2), most prior research has assumed the\navailability of depth images or models of a target to be operated on.\nTherefore, in this study, we achieve more accurate imitation learning with only\nmonocular images by extracting motion constraints from one exemplary motion of\nskilled operators, collecting data based on these constraints, and conducting\nimitation learning based on the collected data. We implemented an overall\nsystem using two Franka Emika Panda Robot Arms and validated its effectiveness.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at ICRA2024, website -\n  https://haraduka.github.io/fls-imitation",
    "pdf_url": "http://arxiv.org/pdf/2405.03440v1",
    "published_date": "2024-05-06 13:12:25 UTC",
    "updated_date": "2024-05-06 13:12:25 UTC"
  },
  {
    "arxiv_id": "2405.03435v1",
    "title": "A method for quantifying the generalization capabilities of generative models for solving Ising models",
    "authors": [
      "Qunlong Ma",
      "Zhi Ma",
      "Ming Gao"
    ],
    "abstract": "For Ising models with complex energy landscapes, whether the ground state can\nbe found by neural networks depends heavily on the Hamming distance between the\ntraining datasets and the ground state. Despite the fact that various recently\nproposed generative models have shown good performance in solving Ising models,\nthere is no adequate discussion on how to quantify their generalization\ncapabilities. Here we design a Hamming distance regularizer in the framework of\na class of generative models, variational autoregressive networks (VAN), to\nquantify the generalization capabilities of various network architectures\ncombined with VAN. The regularizer can control the size of the overlaps between\nthe ground state and the training datasets generated by networks, which,\ntogether with the success rates of finding the ground state, form a\nquantitative metric to quantify their generalization capabilities. We conduct\nnumerical experiments on several prototypical network architectures combined\nwith VAN, including feed-forward neural networks, recurrent neural networks,\nand graph neural networks, to quantify their generalization capabilities when\nsolving Ising models. Moreover, considering the fact that the quantification of\nthe generalization capabilities of networks on small-scale problems can be used\nto predict their relative performance on large-scale problems, our method is of\ngreat significance for assisting in the Neural Architecture Search field of\nsearching for the optimal network architectures when solving large-scale Ising\nmodels.",
    "categories": [
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03435v1",
    "published_date": "2024-05-06 12:58:48 UTC",
    "updated_date": "2024-05-06 12:58:48 UTC"
  },
  {
    "arxiv_id": "2405.03429v1",
    "title": "ReCycle: Fast and Efficient Long Time Series Forecasting with Residual Cyclic Transformers",
    "authors": [
      "Arvid Weyrauch",
      "Thomas Steens",
      "Oskar Taubert",
      "Benedikt Hanke",
      "Aslan Eqbal",
      "Ewa Götz",
      "Achim Streit",
      "Markus Götz",
      "Charlotte Debus"
    ],
    "abstract": "Transformers have recently gained prominence in long time series forecasting\nby elevating accuracies in a variety of use cases. Regrettably, in the race for\nbetter predictive performance the overhead of model architectures has grown\nonerous, leading to models with computational demand infeasible for most\npractical applications. To bridge the gap between high method complexity and\nrealistic computational resources, we introduce the Residual Cyclic\nTransformer, ReCycle. ReCycle utilizes primary cycle compression to address the\ncomputational complexity of the attention mechanism in long time series. By\nlearning residuals from refined smoothing average techniques, ReCycle surpasses\nstate-of-the-art accuracy in a variety of application use cases. The reliable\nand explainable fallback behavior ensured by simple, yet robust, smoothing\naverage techniques additionally lowers the barrier for user acceptance. At the\nsame time, our approach reduces the run time and energy consumption by more\nthan an order of magnitude, making both training and inference feasible on\nlow-performance, low-power and edge computing devices. Code is available at\nhttps://github.com/Helmholtz-AI-Energy/ReCycle",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures, to be published at IEEE CAI 2024, Associated code\n  available at https://github.com/Helmholtz-AI-Energy/ReCycle",
    "pdf_url": "http://arxiv.org/pdf/2405.03429v1",
    "published_date": "2024-05-06 12:48:34 UTC",
    "updated_date": "2024-05-06 12:48:34 UTC"
  },
  {
    "arxiv_id": "2405.03406v1",
    "title": "Automated Computation of Therapies Using Failure Mode and Effects Analysis in the Medical Domain",
    "authors": [
      "Malte Luttermann",
      "Edgar Baake",
      "Juljan Bouchagiar",
      "Benjamin Gebel",
      "Philipp Grüning",
      "Dilini Manikwadura",
      "Franziska Schollemann",
      "Elisa Teifke",
      "Philipp Rostalski",
      "Ralf Möller"
    ],
    "abstract": "Failure mode and effects analysis (FMEA) is a systematic approach to identify\nand analyse potential failures and their effects in a system or process. The\nFMEA approach, however, requires domain experts to manually analyse the FMEA\nmodel to derive risk-reducing actions that should be applied. In this paper, we\nprovide a formal framework to allow for automatic planning and acting in FMEA\nmodels. More specifically, we cast the FMEA model into a Markov decision\nprocess which can then be solved by existing solvers. We show that the FMEA\napproach can not only be used to support medical experts during the modelling\nprocess but also to automatically derive optimal therapies for the treatment of\npatients.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the German Journal of Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2405.03406v1",
    "published_date": "2024-05-06 12:16:53 UTC",
    "updated_date": "2024-05-06 12:16:53 UTC"
  },
  {
    "arxiv_id": "2405.03401v1",
    "title": "E2GNN: Efficient Graph Neural Network Ensembles for Semi-Supervised Classification",
    "authors": [
      "Xin Zhang",
      "Daochen Zha",
      "Qiaoyu Tan"
    ],
    "abstract": "This work studies ensemble learning for graph neural networks (GNNs) under\nthe popular semi-supervised setting. Ensemble learning has shown superiority in\nimproving the accuracy and robustness of traditional machine learning by\ncombining the outputs of multiple weak learners. However, adopting a similar\nidea to integrate different GNN models is challenging because of two reasons.\nFirst, GNN is notorious for its poor inference ability, so naively assembling\nmultiple GNN models would deteriorate the inference efficiency. Second, when\nGNN models are trained with few labeled nodes, their performance are limited.\nIn this case, the vanilla ensemble approach, e.g., majority vote, may be\nsub-optimal since most base models, i.e., GNNs, may make the wrong predictions.\nTo this end, in this paper, we propose an efficient ensemble learner--E2GNN to\nassemble multiple GNNs in a learnable way by leveraging both labeled and\nunlabeled nodes. Specifically, we first pre-train different GNN models on a\ngiven data scenario according to the labeled nodes. Next, instead of directly\ncombing their outputs for label inference, we train a simple multi-layer\nperceptron--MLP model to mimic their predictions on both labeled and unlabeled\nnodes. Then the unified MLP model is deployed to infer labels for unlabeled or\nnew nodes. Since the predictions of unlabeled nodes from different GNN models\nmay be incorrect, we develop a reinforced discriminator to effectively filter\nout those wrongly predicted nodes to boost the performance of MLP. By doing\nthis, we suggest a principled approach to tackle the inference issues of GNN\nensembles and maintain the merit of ensemble learning: improved performance.\nComprehensive experiments over both transductive and inductive settings, across\ndifferent GNN backbones and 8 benchmark datasets, demonstrate the superiority\nof E2GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03401v1",
    "published_date": "2024-05-06 12:11:46 UTC",
    "updated_date": "2024-05-06 12:11:46 UTC"
  },
  {
    "arxiv_id": "2405.03389v2",
    "title": "Don't Waste Your Time: Early Stopping Cross-Validation",
    "authors": [
      "Edward Bergman",
      "Lennart Purucker",
      "Frank Hutter"
    ],
    "abstract": "State-of-the-art automated machine learning systems for tabular data often\nemploy cross-validation; ensuring that measured performances generalize to\nunseen data, or that subsequent ensembling does not overfit. However, using\nk-fold cross-validation instead of holdout validation drastically increases the\ncomputational cost of validating a single configuration. While ensuring better\ngeneralization and, by extension, better performance, the additional cost is\noften prohibitive for effective model selection within a time budget. We aim to\nmake model selection with cross-validation more effective. Therefore, we study\nearly stopping the process of cross-validation during model selection. We\ninvestigate the impact of early stopping on random search for two algorithms,\nMLP and random forest, across 36 classification datasets. We further analyze\nthe impact of the number of folds by considering 3-, 5-, and 10-folds. In\naddition, we investigate the impact of early stopping with Bayesian\noptimization instead of random search and also repeated cross-validation. Our\nexploratory study shows that even a simple-to-understand and easy-to-implement\nmethod consistently allows model selection to converge faster; in ~94% of all\ndatasets, on average by ~214%. Moreover, stopping cross-validation enables\nmodel selection to explore the search space more exhaustively by considering\n+167% configurations on average within one hour, while also obtaining better\noverall performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Third International Conference on Automated Machine\n  Learning (AutoML 2024); for code, see\n  https://github.com/automl/DontWasteYourTime-early-stopping",
    "pdf_url": "http://arxiv.org/pdf/2405.03389v2",
    "published_date": "2024-05-06 11:51:09 UTC",
    "updated_date": "2024-08-02 14:33:32 UTC"
  },
  {
    "arxiv_id": "2405.03379v1",
    "title": "Reverse Forward Curriculum Learning for Extreme Sample and Demonstration Efficiency in Reinforcement Learning",
    "authors": [
      "Stone Tao",
      "Arth Shukla",
      "Tse-kai Chan",
      "Hao Su"
    ],
    "abstract": "Reinforcement learning (RL) presents a promising framework to learn policies\nthrough environment interaction, but often requires an infeasible amount of\ninteraction data to solve complex tasks from sparse rewards. One direction\nincludes augmenting RL with offline data demonstrating desired tasks, but past\nwork often require a lot of high-quality demonstration data that is difficult\nto obtain, especially for domains such as robotics. Our approach consists of a\nreverse curriculum followed by a forward curriculum. Unique to our approach\ncompared to past work is the ability to efficiently leverage more than one\ndemonstration via a per-demonstration reverse curriculum generated via state\nresets. The result of our reverse curriculum is an initial policy that performs\nwell on a narrow initial state distribution and helps overcome difficult\nexploration problems. A forward curriculum is then used to accelerate the\ntraining of the initial policy to perform well on the full initial state\ndistribution of the task and improve demonstration and sample efficiency. We\nshow how the combination of a reverse curriculum and forward curriculum in our\nmethod, RFCL, enables significant improvements in demonstration and sample\nefficiency compared against various state-of-the-art\nlearning-from-demonstration baselines, even solving previously unsolvable tasks\nthat require high precision and control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at The Twelfth International Conference on Learning\n  Representations (ICLR 2024). Website: https://reverseforward-cl.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.03379v1",
    "published_date": "2024-05-06 11:33:12 UTC",
    "updated_date": "2024-05-06 11:33:12 UTC"
  },
  {
    "arxiv_id": "2405.03372v2",
    "title": "Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G",
    "authors": [
      "Xiaoxue Yu",
      "Xingfu Yi",
      "Rongpeng Li",
      "Fei Wang",
      "Chenghui Peng",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "abstract": "In the evolution towards 6G, integrating Artificial Intelligence (AI) with\nadvanced network infrastructure emerges as a pivotal strategy for enhancing\nnetwork intelligence and resource utilization. Existing distributed learning\nframeworks like Federated Learning and Split Learning often struggle with\nsignificant challenges in dynamic network environments including high\nsynchronization demands, costly communication overhead, severe computing\nresource consumption, and data heterogeneity across network nodes. These\nobstacles hinder the applications of ubiquitous computing capabilities of 6G\nnetworks, especially in light of the trend of escalating model parameters and\ntraining data volumes. To address these challenges effectively, this paper\nintroduces ``Snake Learning\", a cost-effective distributed learning framework.\nSpecifically, Snake Learning respects the heterogeneity of inter-node computing\ncapability and local data distribution in 6G networks, and sequentially trains\nthe designated part of model layers on individual nodes. This layer-by-layer\nserpentine update mechanism contributes to significantly reducing the\nrequirements for storage, memory and communication during the model training\nphase, and demonstrates superior adaptability and efficiency for both\nclassification and fine-tuning tasks across homogeneous and heterogeneous data\ndistributions.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03372v2",
    "published_date": "2024-05-06 11:25:59 UTC",
    "updated_date": "2025-01-14 07:26:51 UTC"
  },
  {
    "arxiv_id": "2405.03359v1",
    "title": "MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline",
    "authors": [
      "Mohamed Yaseen Jabarulla",
      "Steffen Oeltze-Jafra",
      "Philipp Beerbaum",
      "Theodor Uden"
    ],
    "abstract": "This research focuses on evaluating the non-commercial open-source large\nlanguage models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their\nefficacy in interpreting medical guidelines saved in PDF format. As a specific\ntest scenario, we applied these models to the guidelines for hypertension in\nchildren and adolescents provided by the European Society of Cardiology (ESC).\nLeveraging Streamlit, a Python library, we developed a user-friendly medical\ndocument chatbot tool (MedDoc-Bot). This tool enables authorized users to\nupload PDF files and pose questions, generating interpretive responses from\nfour locally stored LLMs. A pediatric expert provides a benchmark for\nevaluation by formulating questions and responses extracted from the ESC\nguidelines. The expert rates the model-generated responses based on their\nfidelity and relevance. Additionally, we evaluated the METEOR and chrF metric\nscores to assess the similarity of model responses to reference answers. Our\nstudy found that Llama-2 and Mistral performed well in metrics evaluation.\nHowever, Llama-2 was slower when dealing with text and tabular data. In our\nhuman evaluation, we observed that responses created by Mistral, Meditron, and\nLlama-2 exhibited reasonable fidelity and relevance. This study provides\nvaluable insights into the strengths and limitations of LLMs for future\ndevelopments in medical document interpretation. Open-Source Code:\nhttps://github.com/yaseen28/MedDoc-Bot",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "{copyright} 2024 IEEE. This work has been accepted for publication\n  and presentation at the 46th Annual International Conference of the IEEE\n  Engineering in Medicine and Biology Society, to be held in Orlando, Florida,\n  USA, July 15-19, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03359v1",
    "published_date": "2024-05-06 11:11:23 UTC",
    "updated_date": "2024-05-06 11:11:23 UTC"
  },
  {
    "arxiv_id": "2405.05978v2",
    "title": "Addressing Unboundedness in Quadratically-Constrained Mixed-Integer Problems",
    "authors": [
      "Guy Zepko",
      "Ofer M. Shir"
    ],
    "abstract": "Mixed-integer (MI) quadratic models subject to quadratic constraints, known\nas All-Quadratic MI Programs, constitute a challenging class of NP-complete\noptimization problems. The particular scenario of unbounded integers defines a\nsubclass that holds the distinction of being even undecidable [Jeroslow, 1973].\nThis complexity suggests a possible soft-spot for Mathematical Programming (MP)\ntechniques, which otherwise constitute a good choice to treat MI problems. We\nconsider the task of minimizing MI convex quadratic objective and constraint\nfunctions with unbounded decision variables. Given the theoretical weakness of\nwhite-box MP solvers to handle such models, we turn to black-box\nmeta-heuristics of the Evolution Strategies (ESs) family, and question their\ncapacity to solve this challenge. Through an empirical assessment of\nall-quadratic test-cases, across varying Hessian forms and condition numbers,\nwe compare the performance of the CPLEX solver to modern MI ESs, which handle\nconstraints by penalty. Our systematic investigation begins where the CPLEX\nsolver encounters difficulties (timeouts as the search-space dimensionality\nincreases, D>=30), and we report in detail on the D=64 case. Overall, the\nempirical observations confirm that black-box and white-box solvers can be\ncompetitive, where CPLEX is evidently outperformed on 13% of the cases. This\ntrend is flipped when unboundedness is amplified by a significant translation\nof the optima, leading to a totally inferior performance of CPLEX at 83% of the\ncases. We also conclude that conditioning and separability are not intuitive\nfactors in determining the hardness degree of this class of MI problems.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05978v2",
    "published_date": "2024-05-06 10:54:55 UTC",
    "updated_date": "2024-10-15 09:44:45 UTC"
  },
  {
    "arxiv_id": "2405.03732v3",
    "title": "Deep Learning-based Accelerated MR Cholangiopancreatography without Fully-sampled Data",
    "authors": [
      "Jinho Kim",
      "Marcel Dominik Nickel",
      "Florian Knoll"
    ],
    "abstract": "The purpose of this study was to accelerate MR cholangiopancreatography\n(MRCP) acquisitions using deep learning-based (DL) reconstruction at 3T and\n0.55T. A total of 35 healthy volunteers underwent conventional two-fold\naccelerated MRCP scans at field strengths of 3T and 0.55T. We trained DL\nreconstructions using two different training strategies, supervised (SV) and\nself-supervised (SSV), with retrospectively six-fold undersampled data obtained\nat 3T. We then evaluated the DL reconstructions against standard techniques,\nparallel imaging (PI) and compressed sensing (CS), focusing on peak\nsignal-to-noise ratio (PSNR) and structural similarity (SSIM) as metrics. We\nalso tested DL reconstructions with prospectively accelerated acquisitions and\nevaluated their robustness when changing fields strengths from 3T to 0.55T. DL\nreconstructions demonstrated a reduction in average acquisition time from\n599/542 to 255/180 seconds for MRCP at 3T/0.55T. In both retrospective and\nprospective undersampling, PSNR and SSIM of DL reconstructions were higher than\nthose of PI and CS. At the same time, DL reconstructions preserved the image\nquality of undersampled data, including sharpness and the visibility of\nhepatobiliary ducts. In addition, both DL approaches produced high-quality\nreconstructions at 0.55T. In summary, DL reconstructions trained for highly\naccelerated MRCP enabled a reduction in acquisition time by a factor of 2.4/3.0\nat 3T/0.55T while maintaining the image quality of conventional acquisitions.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "19 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.03732v3",
    "published_date": "2024-05-06 10:53:13 UTC",
    "updated_date": "2025-01-07 15:46:25 UTC"
  },
  {
    "arxiv_id": "2405.03341v3",
    "title": "Enhancing Q-Learning with Large Language Model Heuristics",
    "authors": [
      "Xiefeng Wu"
    ],
    "abstract": "Q-learning excels in learning from feedback within sequential decision-making\ntasks but often requires extensive sampling to achieve significant\nimprovements. While reward shaping can enhance learning efficiency,\nnon-potential-based methods introduce biases that affect performance, and\npotential-based reward shaping, though unbiased, lacks the ability to provide\nheuristics for state-action pairs, limiting its effectiveness in complex\nenvironments. Large language models (LLMs) can achieve zero-shot learning for\nsimpler tasks, but they suffer from low inference speeds and occasional\nhallucinations. To address these challenges, we propose \\textbf{LLM-guided\nQ-learning}, a framework that leverages LLMs as heuristics to aid in learning\nthe Q-function for reinforcement learning. Our theoretical analysis\ndemonstrates that this approach adapts to hallucinations, improves sample\nefficiency, and avoids biasing final performance. Experimental results show\nthat our algorithm is general, robust, and capable of preventing ineffective\nexploration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Note:Arxiv,Draft",
    "pdf_url": "http://arxiv.org/pdf/2405.03341v3",
    "published_date": "2024-05-06 10:42:28 UTC",
    "updated_date": "2024-05-24 06:32:06 UTC"
  },
  {
    "arxiv_id": "2405.03340v1",
    "title": "Functional Equivalence with NARS",
    "authors": [
      "Robert Johansson",
      "Patrick Hammer",
      "Tony Lofthouse"
    ],
    "abstract": "This study explores the concept of functional equivalence within the\nframework of the Non-Axiomatic Reasoning System (NARS), specifically through\nOpenNARS for Applications (ONA). Functional equivalence allows organisms to\ncategorize and respond to varied stimuli based on their utility rather than\nperceptual similarity, thus enhancing cognitive efficiency and adaptability. In\nthis study, ONA was modified to allow the derivation of functional equivalence.\nThis paper provides practical examples of the capability of ONA to apply\nlearned knowledge across different functional situations, demonstrating its\nutility in complex problem-solving and decision-making. An extended example is\nincluded, where training of ONA aimed to learn basic human-like language\nabilities, using a systematic procedure in relating spoken words, objects and\nwritten words. The research carried out as part of this study extends the\nunderstanding of functional equivalence in AGI systems, and argues for its\nnecessity for level of flexibility in learning and adapting necessary for\nhuman-level AGI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03340v1",
    "published_date": "2024-05-06 10:40:34 UTC",
    "updated_date": "2024-05-06 10:40:34 UTC"
  },
  {
    "arxiv_id": "2405.03328v1",
    "title": "Enhancing Spatiotemporal Disease Progression Models via Latent Diffusion and Prior Knowledge",
    "authors": [
      "Lemuel Puglisi",
      "Daniel C. Alexander",
      "Daniele Ravì"
    ],
    "abstract": "In this work, we introduce Brain Latent Progression (BrLP), a novel\nspatiotemporal disease progression model based on latent diffusion. BrLP is\ndesigned to predict the evolution of diseases at the individual level on 3D\nbrain MRIs. Existing deep generative models developed for this task are\nprimarily data-driven and face challenges in learning disease progressions.\nBrLP addresses these challenges by incorporating prior knowledge from disease\nmodels to enhance the accuracy of predictions. To implement this, we propose to\nintegrate an auxiliary model that infers volumetric changes in various brain\nregions. Additionally, we introduce Latent Average Stabilization (LAS), a novel\ntechnique to improve spatiotemporal consistency of the predicted progression.\nBrLP is trained and evaluated on a large dataset comprising 11,730 T1-weighted\nbrain MRIs from 2,805 subjects, collected from three publicly available,\nlongitudinal Alzheimer's Disease (AD) studies. In our experiments, we compare\nthe MRI scans generated by BrLP with the actual follow-up MRIs available from\nthe subjects, in both cross-sectional and longitudinal settings. BrLP\ndemonstrates significant improvements over existing methods, with an increase\nof 22% in volumetric accuracy across AD-related brain regions and 43% in image\nsimilarity to the ground-truth scans. The ability of BrLP to generate\nconditioned 3D scans at the subject level, along with the novelty of\nintegrating prior knowledge to enhance accuracy, represents a significant\nadvancement in disease progression modeling, opening new avenues for precision\nmedicine. The code of BrLP is available at the following link:\nhttps://github.com/LemuelPuglisi/BrLP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03328v1",
    "published_date": "2024-05-06 10:07:16 UTC",
    "updated_date": "2024-05-06 10:07:16 UTC"
  },
  {
    "arxiv_id": "2405.03320v1",
    "title": "Denoising of Geodetic Time Series Using Spatiotemporal Graph Neural Networks: Application to Slow Slip Event Extraction",
    "authors": [
      "Giuseppe Costantino",
      "Sophie Giffard-Roisin",
      "Mauro Dalla Mura",
      "Anne Socquet"
    ],
    "abstract": "Geospatial data has been transformative for the monitoring of the Earth, yet,\nas in the case of (geo)physical monitoring, the measurements can have variable\nspatial and temporal sampling and may be associated with a significant level of\nperturbations degrading the signal quality. Denoising geospatial data is,\ntherefore, essential, yet often challenging because the observations may\ncomprise noise coming from different origins, including both environmental\nsignals and instrumental artifacts, which are spatially and temporally\ncorrelated, thus hard to disentangle. This study addresses the denoising of\nmultivariate time series acquired by irregularly distributed networks of\nsensors, requiring specific methods to handle the spatiotemporal correlation of\nthe noise and the signal of interest. Specifically, our method focuses on the\ndenoising of geodetic position time series, used to monitor ground displacement\nworldwide with centimeter- to-millimeter precision. Among the signals affecting\nGNSS data, slow slip events (SSEs) are of interest to seismologists. These are\ntransients of deformation that are weakly emerging compared to other signals.\nHere, we design SSEdenoiser, a multi-station spatiotemporal graph-based\nattentive denoiser that learns latent characteristics of GNSS noise to reveal\nSSE-related displacement with sub-millimeter precision. It is based on the key\ncombination of graph recurrent networks and spatiotemporal Transformers. The\nproposed method is applied to the Cascadia subduction zone, where SSEs occur\nalong with bursts of tectonic tremors, a seismic rumbling identified from\nindependent seismic recordings. The extracted events match the spatiotemporal\nevolution of tremors. This good space-time correlation of the denoised GNSS\nsignals with the tremors validates the proposed denoising procedure.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03320v1",
    "published_date": "2024-05-06 09:55:11 UTC",
    "updated_date": "2024-05-06 09:55:11 UTC"
  },
  {
    "arxiv_id": "2405.03305v1",
    "title": "Artificial Intelligence in the Autonomous Navigation of Endovascular Interventions: A Systematic Review",
    "authors": [
      "Harry Robertshaw",
      "Lennart Karstensen",
      "Benjamin Jackson",
      "Hadi Sadati",
      "Kawal Rhode",
      "Sebastien Ourselin",
      "Alejandro Granados",
      "Thomas C Booth"
    ],
    "abstract": "Purpose: Autonomous navigation of devices in endovascular interventions can\ndecrease operation times, improve decision-making during surgery, and reduce\noperator radiation exposure while increasing access to treatment. This\nsystematic review explores recent literature to assess the impact, challenges,\nand opportunities artificial intelligence (AI) has for the autonomous\nendovascular intervention navigation.\n  Methods: PubMed and IEEEXplore databases were queried. Eligibility criteria\nincluded studies investigating the use of AI in enabling the autonomous\nnavigation of catheters/guidewires in endovascular interventions. Following\nPRISMA, articles were assessed using QUADAS-2. PROSPERO: CRD42023392259.\n  Results: Among 462 studies, fourteen met inclusion criteria. Reinforcement\nlearning (9/14, 64%) and learning from demonstration (7/14, 50%) were used as\ndata-driven models for autonomous navigation. Studies predominantly utilised\nphysical phantoms (10/14, 71%) and in silico (4/14, 29%) models. Experiments\nwithin or around the blood vessels of the heart were reported by the majority\nof studies (10/14, 71%), while simple non-anatomical vessel platforms were used\nin three studies (3/14, 21%), and the porcine liver venous system in one study.\nWe observed that risk of bias and poor generalisability were present across\nstudies. No procedures were performed on patients in any of the studies\nreviewed. Studies lacked patient selection criteria, reference standards, and\nreproducibility, resulting in low clinical evidence levels.\n  Conclusions: AI's potential in autonomous endovascular navigation is\npromising, but in an experimental proof-of-concept stage, with a technology\nreadiness level of 3. We highlight that reference standards with\nwell-identified performance metrics are crucial to allow for comparisons of\ndata-driven algorithms proposed in the years to come.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Abstract shortened for arXiv character limit",
    "pdf_url": "http://arxiv.org/pdf/2405.03305v1",
    "published_date": "2024-05-06 09:28:30 UTC",
    "updated_date": "2024-05-06 09:28:30 UTC"
  },
  {
    "arxiv_id": "2405.03296v1",
    "title": "Coefficient Decomposition for Spectral Graph Convolution",
    "authors": [
      "Feng Huang",
      "Wen Zhang"
    ],
    "abstract": "Spectral graph convolutional network (SGCN) is a kind of graph neural\nnetworks (GNN) based on graph signal filters, and has shown compelling\nexpressivity for modeling graph-structured data. Most SGCNs adopt polynomial\nfilters and learn the coefficients from the training data. Many of them focus\non which polynomial basis leads to optimal expressive power and models'\narchitecture is little discussed. In this paper, we propose a general form in\nterms of spectral graph convolution, where the coefficients of polynomial basis\nare stored in a third-order tensor. Then, we show that the convolution block in\nexisting SGCNs can be derived by performing a certain coefficient decomposition\noperation on the coefficient tensor. Based on the generalized view, we develop\nnovel spectral graph convolutions CoDeSGC-CP and -Tucker by tensor\ndecomposition CP and Tucker on the coefficient tensor. Extensive experimental\nresults demonstrate that the proposed convolutions achieve favorable\nperformance improvements.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03296v1",
    "published_date": "2024-05-06 09:17:23 UTC",
    "updated_date": "2024-05-06 09:17:23 UTC"
  },
  {
    "arxiv_id": "2405.03728v2",
    "title": "Pretrained Optimization Model for Zero-Shot Black Box Optimization",
    "authors": [
      "Xiaobin Li",
      "Kai Wu",
      "Yujian Betterest Li",
      "Xiaoyu Zhang",
      "Handing Wang",
      "Jing Liu"
    ],
    "abstract": "Zero-shot optimization involves optimizing a target task that was not seen\nduring training, aiming to provide the optimal solution without or with minimal\nadjustments to the optimizer. It is crucial to ensure reliable and robust\nperformance in various applications. Current optimizers often struggle with\nzero-shot optimization and require intricate hyperparameter tuning to adapt to\nnew tasks. To address this, we propose a Pretrained Optimization Model (POM)\nthat leverages knowledge gained from optimizing diverse tasks, offering\nefficient solutions to zero-shot optimization through direct application or\nfine-tuning with few-shot samples. Evaluation on the BBOB benchmark and two\nrobot control tasks demonstrates that POM outperforms state-of-the-art\nblack-box optimization methods, especially for high-dimensional tasks.\nFine-tuning POM with a small number of samples and budget yields significant\nperformance improvements. Moreover, POM demonstrates robust generalization\nacross diverse task distributions, dimensions, population sizes, and\noptimization horizons. For code implementation, see\nhttps://github.com/ninja-wm/POM/.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03728v2",
    "published_date": "2024-05-06 09:11:49 UTC",
    "updated_date": "2024-12-06 08:55:26 UTC"
  },
  {
    "arxiv_id": "2406.06478v1",
    "title": "High-precision surgical navigation using speckle structured light-based thoracoabdominal puncture robot",
    "authors": [
      "Zezhao Guo",
      "Yanzhong Guo",
      "Zhanfang Zhao"
    ],
    "abstract": "Abstract\n  Background During percutaneous puncture robotic surgical navigation, the\nneedle insertion point is positioned on the patient's chest and abdomen body\nsurface. By locating any point on the soft skin tissue, it is difficult to\napply the traditional reflective ball tracking method. The patient's chest and\nabdomen body surface has fluctuations in breathing and appears irregular. The\nchest and abdomen are regular and smooth, lacking obvious features, and it is\nchallenging to locate the needle insertion point on the body surface. Methods\nThis paper designs and experiments a method that is different from previous\nreflective ball optical markers or magnetic positioning surgical navigation and\ntracking methods. It is based on a speckle structured light camera to identify\nthe patient's body surface and fit it into a hollow ring with a diameter of\n24mm. Results Experimental results show that this method of the system can be\nsmall, flexible, and high-precision positioning of any body surface point at\nmultiple angles, achieving a positioning accuracy of 0.033-0.563mm and an image\nof 7-30 frames/s. Conclusions The positioning recognition ring material used in\nthis method can be well imaged under CT, so the optical positioning of the body\nsurface and the in vivo imaging positioning under CT can be combined to form a\nunified patient's internal and external positioning world coordinates to\nachieve internal and external registration. Positioning integration. The system\nsenses motion with six degrees of freedom, up and down, front and back, left\nand right, and all rotations, with sub-millimeter accuracy, and has broad\napplication prospects in future puncture surgeries.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "17pages,7figures",
    "pdf_url": "http://arxiv.org/pdf/2406.06478v1",
    "published_date": "2024-05-06 08:59:51 UTC",
    "updated_date": "2024-05-06 08:59:51 UTC"
  },
  {
    "arxiv_id": "2407.00020v1",
    "title": "Visual Language Model based Cross-modal Semantic Communication Systems",
    "authors": [
      "Feibo Jiang",
      "Chuanguo Tang",
      "Li Dong",
      "Kezhi Wang",
      "Kun Yang",
      "Cunhua Pan"
    ],
    "abstract": "Semantic Communication (SC) has emerged as a novel communication paradigm in\nrecent years, successfully transcending the Shannon physical capacity limits\nthrough innovative semantic transmission concepts. Nevertheless, extant Image\nSemantic Communication (ISC) systems face several challenges in dynamic\nenvironments, including low semantic density, catastrophic forgetting, and\nuncertain Signal-to-Noise Ratio (SNR). To address these challenges, we propose\na novel Vision-Language Model-based Cross-modal Semantic Communication\n(VLM-CSC) system. The VLM-CSC comprises three novel components: (1) Cross-modal\nKnowledge Base (CKB) is used to extract high-density textual semantics from the\nsemantically sparse image at the transmitter and reconstruct the original image\nbased on textual semantics at the receiver. The transmission of high-density\nsemantics contributes to alleviating bandwidth pressure. (2) Memory-assisted\nEncoder and Decoder (MED) employ a hybrid long/short-term memory mechanism,\nenabling the semantic encoder and decoder to overcome catastrophic forgetting\nin dynamic environments when there is a drift in the distribution of semantic\nfeatures. (3) Noise Attention Module (NAM) employs attention mechanisms to\nadaptively adjust the semantic coding and the channel coding based on SNR,\nensuring the robustness of the CSC system. The experimental simulations\nvalidate the effectiveness, adaptability, and robustness of the CSC system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.00020v1",
    "published_date": "2024-05-06 08:59:16 UTC",
    "updated_date": "2024-05-06 08:59:16 UTC"
  },
  {
    "arxiv_id": "2405.03280v2",
    "title": "Animate Your Thoughts: Decoupled Reconstruction of Dynamic Natural Vision from Slow Brain Activity",
    "authors": [
      "Yizhuo Lu",
      "Changde Du",
      "Chong Wang",
      "Xuanliu Zhu",
      "Liuyun Jiang",
      "Xujin Li",
      "Huiguang He"
    ],
    "abstract": "Reconstructing human dynamic vision from brain activity is a challenging task\nwith great scientific significance. Although prior video reconstruction methods\nhave made substantial progress, they still suffer from several limitations,\nincluding: (1) difficulty in simultaneously reconciling semantic (e.g.\ncategorical descriptions), structure (e.g. size and color), and consistent\nmotion information (e.g. order of frames); (2) low temporal resolution of fMRI,\nwhich poses a challenge in decoding multiple frames of video dynamics from a\nsingle fMRI frame; (3) reliance on video generation models, which introduces\nambiguity regarding whether the dynamics observed in the reconstructed videos\nare genuinely derived from fMRI data or are hallucinations from generative\nmodel. To overcome these limitations, we propose a two-stage model named\nMind-Animator. During the fMRI-to-feature stage, we decouple semantic,\nstructure, and motion features from fMRI. Specifically, we employ\nfMRI-vision-language tri-modal contrastive learning to decode semantic feature\nfrom fMRI and design a sparse causal attention mechanism for decoding\nmulti-frame video motion features through a next-frame-prediction task. In the\nfeature-to-video stage, these features are integrated into videos using an\ninflated Stable Diffusion, effectively eliminating external video data\ninterference. Extensive experiments on multiple video-fMRI datasets demonstrate\nthat our model achieves state-of-the-art performance. Comprehensive\nvisualization analyses further elucidate the interpretability of our model from\na neurobiological perspective. Project page:\nhttps://mind-animator-design.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03280v2",
    "published_date": "2024-05-06 08:56:41 UTC",
    "updated_date": "2025-02-19 05:02:08 UTC"
  },
  {
    "arxiv_id": "2405.03262v2",
    "title": "End-to-End Reinforcement Learning of Curative Curtailment with Partial Measurement Availability",
    "authors": [
      "Hinrikus Wolf",
      "Luis Böttcher",
      "Sarra Bouchkati",
      "Philipp Lutat",
      "Jens Breitung",
      "Bastian Jung",
      "Tina Möllemann",
      "Viktor Todosijević",
      "Jan Schiefelbein-Lach",
      "Oliver Pohl",
      "Andreas Ulbig",
      "Martin Grohe"
    ],
    "abstract": "In the course of the energy transition, the expansion of generation and\nconsumption will change, and many of these technologies, such as PV systems,\nelectric cars and heat pumps, will influence the power flow, especially in the\ndistribution grids. Scalable methods that can make decisions for each grid\nconnection are needed to enable congestion-free grid operation in the\ndistribution grids. This paper presents a novel end-to-end approach to\nresolving congestion in distribution grids with deep reinforcement learning.\nOur architecture learns to curtail power and set appropriate reactive power to\ndetermine a non-congested and, thus, feasible grid state. State-of-the-art\nmethods such as the optimal power flow (OPF) demand high computational costs\nand detailed measurements of every bus in a grid. In contrast, the presented\nmethod enables decisions under sparse information with just some buses\nobservable in the grid. Distribution grids are generally not yet fully\ndigitized and observable, so this method can be used for decision-making on the\nmajority of low-voltage grids. On a real low-voltage grid the approach resolves\n100\\% of violations in the voltage band and 98.8\\% of asset overloads. The\nresults show that decisions can also be made on real grids that guarantee\nsufficient quality for congestion-free grid operation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03262v2",
    "published_date": "2024-05-06 08:34:15 UTC",
    "updated_date": "2024-06-10 11:04:04 UTC"
  },
  {
    "arxiv_id": "2405.03251v1",
    "title": "Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond",
    "authors": [
      "Jiuxiang Gu",
      "Chenyang Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "The softmax activation function plays a crucial role in the success of large\nlanguage models (LLMs), particularly in the self-attention mechanism of the\nwidely adopted Transformer architecture. However, the underlying learning\ndynamics that contribute to the effectiveness of softmax remain largely\nunexplored. As a step towards better understanding, this paper provides a\ntheoretical study of the optimization and generalization properties of\ntwo-layer softmax neural networks, providing theoretical insights into their\nsuperior performance as other activation functions, such as ReLU and\nexponential. Leveraging the Neural Tangent Kernel (NTK) framework, our analysis\nreveals that the normalization effect of the softmax function leads to a good\nperturbation property of the induced NTK matrix, resulting in a good convex\nregion of the loss landscape. Consequently, softmax neural networks can learn\nthe target function in the over-parametrization regime. To demonstrate the\nbroad applicability of our theoretical findings, we apply them to the task of\nlearning score estimation functions in diffusion models, a promising approach\nfor generative modeling. Our analysis shows that gradient-based algorithms can\nlearn the score function with a provable accuracy. Our work provides a deeper\nunderstanding of the effectiveness of softmax neural networks and their\npotential in various domains, paving the way for further advancements in\nnatural language processing and beyond.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "53 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.03251v1",
    "published_date": "2024-05-06 08:15:29 UTC",
    "updated_date": "2024-05-06 08:15:29 UTC"
  },
  {
    "arxiv_id": "2405.03727v3",
    "title": "Large Language Models Synergize with Automated Machine Learning",
    "authors": [
      "Jinglue Xu",
      "Jialong Li",
      "Zhen Liu",
      "Nagar Anthel Venkatesh Suryanarayanan",
      "Guoyuan Zhou",
      "Jia Guo",
      "Hitoshi Iba",
      "Kenji Tei"
    ],
    "abstract": "Recently, program synthesis driven by large language models (LLMs) has become\nincreasingly popular. However, program synthesis for machine learning (ML)\ntasks still poses significant challenges. This paper explores a novel form of\nprogram synthesis, targeting ML programs, by combining LLMs and automated\nmachine learning (autoML). Specifically, our goal is to fully automate the\ngeneration and optimization of the code of the entire ML workflow, from data\npreparation to modeling and post-processing, utilizing only textual\ndescriptions of the ML tasks. To manage the length and diversity of ML\nprograms, we propose to break each ML program into smaller, manageable parts.\nEach part is generated separately by the LLM, with careful consideration of\ntheir compatibilities. To ensure compatibilities, we design a testing technique\nfor ML programs. Unlike traditional program synthesis, which typically relies\non binary evaluations (i.e., correct or incorrect), evaluating ML programs\nnecessitates more than just binary judgments. Our approach automates the\nnumerical evaluation and optimization of these programs, selecting the best\ncandidates through autoML techniques. In experiments across various ML tasks,\nour method outperforms existing methods in 10 out of 12 tasks for generating ML\nprograms. In addition, autoML significantly improves the performance of the\ngenerated ML programs. In experiments, given the textual task description, our\nmethod, Text-to-ML, generates the complete and optimized ML program in a fully\nautonomous process. The implementation of our method is available at\nhttps://github.com/JLX0/llm-automl.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "published at TMLR",
    "pdf_url": "http://arxiv.org/pdf/2405.03727v3",
    "published_date": "2024-05-06 08:09:46 UTC",
    "updated_date": "2024-09-09 15:04:15 UTC"
  },
  {
    "arxiv_id": "2405.03248v1",
    "title": "Communication-Efficient Federated Learning with Adaptive Compression under Dynamic Bandwidth",
    "authors": [
      "Ying Zhuansun",
      "Dandan Li",
      "Xiaohong Huang",
      "Caijun Sun"
    ],
    "abstract": "Federated learning can train models without directly providing local data to\nthe server. However, the frequent updating of the local model brings the\nproblem of large communication overhead. Recently, scholars have achieved the\ncommunication efficiency of federated learning mainly by model compression. But\nthey ignore two problems: 1) network state of each client changes dynamically;\n2) network state among clients is not the same. The clients with poor bandwidth\nupdate local model slowly, which leads to low efficiency. To address this\nchallenge, we propose a communication-efficient federated learning algorithm\nwith adaptive compression under dynamic bandwidth (called AdapComFL).\nConcretely, each client performs bandwidth awareness and bandwidth prediction.\nThen, each client adaptively compresses its local model via the improved sketch\nmechanism based on his predicted bandwidth. Further, the server aggregates\nsketched models with different sizes received. To verify the effectiveness of\nthe proposed method, the experiments are based on real bandwidth data which are\ncollected from the network topology we build, and benchmark datasets which are\nobtained from open repositories. We show the performance of AdapComFL\nalgorithm, and compare it with existing algorithms. The experimental results\nshow that our AdapComFL achieves more efficient communication as well as\ncompetitive accuracy compared to existing algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03248v1",
    "published_date": "2024-05-06 08:00:43 UTC",
    "updated_date": "2024-05-06 08:00:43 UTC"
  },
  {
    "arxiv_id": "2407.10312v1",
    "title": "Effective Design Verification -- Constrained Random with Python and Cocotb",
    "authors": [
      "Deepak Narayan Gadde",
      "Suruchi Kumari",
      "Aman Kumar"
    ],
    "abstract": "Being the most widely used language across the world due to its simplicity\nand with 35 keywords (v3.7), Python attracts both hardware and software\nengineers. Python-based verification environment leverages open-source\nlibraries such as cocotb and cocotb-coverage that enables interfacing the\ntesbenches with any available simulator and facilitating constrained\nrandomization, coverage respectively. These libraries significantly ease the\ndevelopment of testbenches and have the potential to reduce the setup cost. The\ngoal of this paper is to assess the effectiveness of a Python-Cocotb\nverification setup with design IPs and compare its features and performance\nmetrics with the current de-facto hardware verification language i.e.,\nSystemVerilog.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Published in DVCon Europe 2023",
    "pdf_url": "http://arxiv.org/pdf/2407.10312v1",
    "published_date": "2024-05-06 07:58:16 UTC",
    "updated_date": "2024-05-06 07:58:16 UTC"
  },
  {
    "arxiv_id": "2405.03239v3",
    "title": "Deep Learning for Detecting and Early Predicting Chronic Obstructive Pulmonary Disease from Spirogram Time Series",
    "authors": [
      "Shuhao Mei",
      "Xin Li",
      "Yuxi Zhou",
      "Jiahao Xu",
      "Yong Zhang",
      "Yuxuan Wan",
      "Shan Cao",
      "Qinghao Zhao",
      "Shijia Geng",
      "Junqing Xie",
      "Shengyong Chen",
      "Shenda Hong"
    ],
    "abstract": "Chronic Obstructive Pulmonary Disease (COPD) is a chronic lung condition\ncharacterized by airflow obstruction. Current diagnostic methods primarily rely\non identifying prominent features in spirometry (Volume-Flow time series) to\ndetect COPD, but they are not adept at predicting future COPD risk based on\nsubtle data patterns. In this study, we introduce a novel deep learning-based\napproach, DeepSpiro, aimed at the early prediction of future COPD risk.\nDeepSpiro consists of four key components: SpiroSmoother for stabilizing the\nVolume-Flow curve, SpiroEncoder for capturing volume variability-pattern\nthrough key patches of varying lengths, SpiroExplainer for integrating\nheterogeneous data and explaining predictions through volume attention, and\nSpiroPredictor for predicting the disease risk of undiagnosed high-risk\npatients based on key patch concavity, with prediction horizons of 1, 2, 3, 4,\n5 years, or even longer. Evaluated on the UK Biobank dataset, DeepSpiro\nachieved an AUC of 0.8328 for COPD detection and demonstrated strong predictive\nperformance for future COPD risk (p-value < 0.001). In summary, DeepSpiro can\neffectively predicts the long-term progression of the COPD disease.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03239v3",
    "published_date": "2024-05-06 07:48:34 UTC",
    "updated_date": "2024-12-28 14:18:37 UTC"
  },
  {
    "arxiv_id": "2405.03206v1",
    "title": "Vietnamese AI Generated Text Detection",
    "authors": [
      "Quang-Dan Tran",
      "Van-Quan Nguyen",
      "Quang-Huy Pham",
      "K. B. Thang Nguyen",
      "Trong-Hop Do"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have become integrated into our\ndaily lives, serving as invaluable assistants in completing tasks. Widely\nembraced by users, the abuse of LLMs is inevitable, particularly in using them\nto generate text content for various purposes, leading to difficulties in\ndistinguishing between text generated by LLMs and that written by humans. In\nthis study, we present a dataset named ViDetect, comprising 6.800 samples of\nVietnamese essay, with 3.400 samples authored by humans and the remainder\ngenerated by LLMs, serving the purpose of detecting text generated by AI. We\nconducted evaluations using state-of-the-art methods, including ViT5, BartPho,\nPhoBERT, mDeberta V3, and mBERT. These results contribute not only to the\ngrowing body of research on detecting text generated by AI but also demonstrate\nthe adaptability and effectiveness of different methods in the Vietnamese\nlanguage context. This research lays the foundation for future advancements in\nAI-generated text detection and provides valuable insights for researchers in\nthe field of natural language processing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03206v1",
    "published_date": "2024-05-06 07:12:22 UTC",
    "updated_date": "2024-05-06 07:12:22 UTC"
  },
  {
    "arxiv_id": "2405.03205v2",
    "title": "Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions",
    "authors": [
      "Ruizhe Li",
      "Yanjun Gao"
    ],
    "abstract": "Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have\ndemonstrated considerable success across diverse tasks, including\nmultiple-choice questions (MCQs). However, these models exhibit a positional\nbias, particularly an even worse anchored bias in the GPT-2 family, where they\nconsistently favour the first choice 'A' in MCQs during inference. This\nanchored bias challenges the integrity of GPT-2's decision-making process, as\nit skews performance based on the position rather than the content of the\nchoices in MCQs. In this study, we utilise the mechanistic interpretability\napproach to identify the internal modules within GPT-2 models responsible for\nthis bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention\nheads, using the \"logit lens\" method to trace and modify the specific value\nvectors that contribute to the bias. By updating these vectors within MLP and\nrecalibrating attention patterns to neutralise the preference for the first\nchoice 'A', we effectively mitigate the anchored bias. Our interventions not\nonly mitigate the bias but also improve the overall MCQ prediction accuracy for\nthe GPT-2 family across various datasets. This work represents the first\ncomprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2\nmodels, introducing targeted, minimal-intervention strategies that\nsignificantly enhance GPT2 model robustness and accuracy in MCQs. Our code is\navailable at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in process",
    "pdf_url": "http://arxiv.org/pdf/2405.03205v2",
    "published_date": "2024-05-06 07:10:09 UTC",
    "updated_date": "2024-05-23 07:47:02 UTC"
  },
  {
    "arxiv_id": "2405.03192v2",
    "title": "QuadraNet V2: Efficient and Sustainable Training of High-Order Neural Networks with Quadratic Adaptation",
    "authors": [
      "Chenhui Xu",
      "Xinyao Wang",
      "Fuxun Yu",
      "Jinjun Xiong",
      "Xiang Chen"
    ],
    "abstract": "Machine learning is evolving towards high-order models that necessitate\npre-training on extensive datasets, a process associated with significant\noverheads. Traditional models, despite having pre-trained weights, are becoming\nobsolete due to architectural differences that obstruct the effective transfer\nand initialization of these weights. To address these challenges, we introduce\na novel framework, QuadraNet V2, which leverages quadratic neural networks to\ncreate efficient and sustainable high-order learning models. Our method\ninitializes the primary term of the quadratic neuron using a standard neural\nnetwork, while the quadratic term is employed to adaptively enhance the\nlearning of data non-linearity or shifts. This integration of pre-trained\nprimary terms with quadratic terms, which possess advanced modeling\ncapabilities, significantly augments the information characterization capacity\nof the high-order network. By utilizing existing pre-trained weights, QuadraNet\nV2 reduces the required GPU hours for training by 90\\% to 98.4\\% compared to\ntraining from scratch, demonstrating both efficiency and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03192v2",
    "published_date": "2024-05-06 06:31:47 UTC",
    "updated_date": "2024-05-09 02:20:42 UTC"
  },
  {
    "arxiv_id": "2405.03725v2",
    "title": "Deep Oscillatory Neural Network",
    "authors": [
      "Nurani Rajagopal Rohan",
      "Vigneswaran C",
      "Sayan Ghosh",
      "Kishore Rajendran",
      "Gaurav A",
      "V Srinivasa Chakravarthy"
    ],
    "abstract": "We propose a novel, brain-inspired deep neural network model known as the\nDeep Oscillatory Neural Network (DONN). Deep neural networks like the Recurrent\nNeural Networks indeed possess sequence processing capabilities but the\ninternal states of the network are not designed to exhibit brain-like\noscillatory activity. With this motivation, the DONN is designed to have\noscillatory internal dynamics. Neurons of the DONN are either nonlinear neural\noscillators or traditional neurons with sigmoidal or ReLU activation. The\nneural oscillator used in the model is the Hopf oscillator, with the dynamics\ndescribed in the complex domain. Input can be presented to the neural\noscillator in three possible modes. The sigmoid and ReLU neurons also use\ncomplex-valued extensions. All the weight stages are also complex-valued.\nTraining follows the general principle of weight change by minimizing the\noutput error and therefore has an overall resemblance to complex\nbackpropagation. A generalization of DONN to convolutional networks known as\nthe Oscillatory Convolutional Neural Network is also proposed. The two proposed\noscillatory networks are applied to a variety of benchmark problems in signal\nand image/video processing. The performance of the proposed models is either\ncomparable or superior to published results on the same data sets.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03725v2",
    "published_date": "2024-05-06 06:17:16 UTC",
    "updated_date": "2024-09-09 08:33:40 UTC"
  },
  {
    "arxiv_id": "2405.03164v1",
    "title": "The Role of Predictive Uncertainty and Diversity in Embodied AI and Robot Learning",
    "authors": [
      "Ransalu Senanayake"
    ],
    "abstract": "Uncertainty has long been a critical area of study in robotics, particularly\nwhen robots are equipped with analytical models. As we move towards the\nwidespread use of deep neural networks in robots, which have demonstrated\nremarkable performance in research settings, understanding the nuances of\nuncertainty becomes crucial for their real-world deployment. This guide offers\nan overview of the importance of uncertainty and provides methods to quantify\nand evaluate it from an applications perspective.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03164v1",
    "published_date": "2024-05-06 05:04:59 UTC",
    "updated_date": "2024-05-06 05:04:59 UTC"
  },
  {
    "arxiv_id": "2405.03162v1",
    "title": "Advancing Multimodal Medical Capabilities of Gemini",
    "authors": [
      "Lin Yang",
      "Shawn Xu",
      "Andrew Sellergren",
      "Timo Kohlberger",
      "Yuchen Zhou",
      "Ira Ktena",
      "Atilla Kiraly",
      "Faruk Ahmed",
      "Farhad Hormozdiari",
      "Tiam Jaroensri",
      "Eric Wang",
      "Ellery Wulczyn",
      "Fayaz Jamil",
      "Theo Guidroz",
      "Chuck Lau",
      "Siyuan Qiao",
      "Yun Liu",
      "Akshay Goel",
      "Kendall Park",
      "Arnav Agharwal",
      "Nick George",
      "Yang Wang",
      "Ryutaro Tanno",
      "David G. T. Barrett",
      "Wei-Hung Weng",
      "S. Sara Mahdavi",
      "Khaled Saab",
      "Tao Tu",
      "Sreenivasa Raju Kalidindi",
      "Mozziyar Etemadi",
      "Jorge Cuadros",
      "Gregory Sorensen",
      "Yossi Matias",
      "Katherine Chou",
      "Greg Corrado",
      "Joelle Barral",
      "Shravya Shetty",
      "David Fleet",
      "S. M. Ali Eslami",
      "Daniel Tse",
      "Shruthi Prabhakara",
      "Cory McLean",
      "Dave Steiner",
      "Rory Pilgrim",
      "Christopher Kelly",
      "Shekoofeh Azizi",
      "Daniel Golden"
    ],
    "abstract": "Many clinical tasks require an understanding of specialized data, such as\nmedical images and genomics, which is not typically found in general-purpose\nlarge multimodal models. Building upon Gemini's multimodal models, we develop\nseveral models within the new Med-Gemini family that inherit core capabilities\nof Gemini and are optimized for medical use via fine-tuning with 2D and 3D\nradiology, histopathology, ophthalmology, dermatology and genomic data.\nMed-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report\ngeneration based on expert evaluation, exceeding previous best results across\ntwo separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of\nAI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as\n\"equivalent or better\" than the original radiologists' reports. We demonstrate\nthe first ever large multimodal model-based report generation for 3D computed\ntomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered\nclinically acceptable, although additional research is needed to meet expert\nradiologist reporting quality. Beyond report generation, Med-Gemini-2D\nsurpasses the previous best performance in CXR visual question answering (VQA)\nand performs well in CXR classification and radiology VQA, exceeding SoTA or\nbaselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology\nimage classification, Med-Gemini-2D surpasses baselines across 18 out of 20\ntasks and approaches task-specific model performance. Beyond imaging,\nMed-Gemini-Polygenic outperforms the standard linear polygenic risk score-based\napproach for disease risk prediction and generalizes to genetically correlated\ndiseases for which it has never been trained. Although further development and\nevaluation are necessary in the safety-critical medical domain, our results\nhighlight the potential of Med-Gemini across a wide range of medical tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03162v1",
    "published_date": "2024-05-06 04:44:22 UTC",
    "updated_date": "2024-05-06 04:44:22 UTC"
  },
  {
    "arxiv_id": "2405.03151v1",
    "title": "Time Series Stock Price Forecasting Based on Genetic Algorithm (GA)-Long Short-Term Memory Network (LSTM) Optimization",
    "authors": [
      "Xinye Sha"
    ],
    "abstract": "In this paper, a time series algorithm based on Genetic Algorithm (GA) and\nLong Short-Term Memory Network (LSTM) optimization is used to forecast stock\nprices effectively, taking into account the trend of the big data era. The data\nare first analyzed by descriptive statistics, and then the model is built and\ntrained and tested on the dataset. After optimization and adjustment, the mean\nabsolute error (MAE) of the model gradually decreases from 0.11 to 0.01 and\ntends to be stable, indicating that the model prediction effect is gradually\nclose to the real value. The results on the test set show that the time series\nalgorithm optimized based on Genetic Algorithm (GA)-Long Short-Term Memory\nNetwork (LSTM) is able to accurately predict the stock prices, and is highly\nconsistent with the actual price trends and values, with strong generalization\nability. The MAE on the test set is 2.41, the MSE is 9.84, the RMSE is 3.13,\nand the R2 is 0.87. This research result not only provides a novel stock price\nprediction method, but also provides a useful reference for financial market\nanalysis using computer technology and big data.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03151v1",
    "published_date": "2024-05-06 04:04:27 UTC",
    "updated_date": "2024-05-06 04:04:27 UTC"
  },
  {
    "arxiv_id": "2405.03146v2",
    "title": "Quantifying the Capabilities of LLMs across Scale and Precision",
    "authors": [
      "Sher Badshah",
      "Hassan Sajjad"
    ],
    "abstract": "Scale is often attributed as one of the factors that cause an increase in the\nperformance of LLMs, resulting in models with billion and trillion parameters.\nOne of the limitations of such large models is the high computational\nrequirements that limit their usage, deployment, and debugging in\nresource-constrained scenarios. Two commonly used alternatives to bypass these\nlimitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of\nLlama 70B) and lower the memory requirements by using quantization. While these\napproaches effectively address the limitation of resources, their impact on\nmodel performance needs thorough examination. In this study, we perform a\ncomprehensive evaluation to investigate the effect of model scale and\nquantization on the performance. We experiment with two major families of\nopen-source instruct models ranging from 7 billion to 70 billion parameters.\nOur extensive zero-shot experiments across various tasks including natural\nlanguage understanding, reasoning, misinformation detection, and hallucination\nreveal that larger models generally outperform their smaller counterparts,\nsuggesting that scale remains an important factor in enhancing performance. We\nfound that larger models show exceptional resilience to precision reduction and\ncan maintain high accuracy even at 4-bit quantization for numerous tasks and\nthey serve as a better solution than using smaller models at high precision\nunder similar memory requirements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03146v2",
    "published_date": "2024-05-06 03:42:34 UTC",
    "updated_date": "2024-05-08 02:10:36 UTC"
  },
  {
    "arxiv_id": "2405.03141v2",
    "title": "Automatic Ultrasound Curve Angle Measurement via Affinity Clustering for Adolescent Idiopathic Scoliosis Evaluation",
    "authors": [
      "Yihao Zhou",
      "Timothy Tin-Yan Lee",
      "Kelly Ka-Lee Lai",
      "Chonglin Wu",
      "Hin Ting Lau",
      "De Yang",
      "Chui-Yi Chan",
      "Winnie Chiu-Wing Chu",
      "Jack Chun-Yiu Cheng",
      "Tsz-Ping Lam",
      "Yong-Ping Zheng"
    ],
    "abstract": "The current clinical gold standard for evaluating adolescent idiopathic\nscoliosis (AIS) is X-ray radiography, using Cobb angle measurement. However,\nthe frequent monitoring of the AIS progression using X-rays poses a challenge\ndue to the cumulative radiation exposure. Although 3D ultrasound has been\nvalidated as a reliable and radiation-free alternative for scoliosis\nassessment, the process of measuring spinal curvature is still carried out\nmanually. Consequently, there is a considerable demand for a fully automatic\nsystem that can locate bony landmarks and perform angle measurements. To this\nend, we introduce an estimation model for automatic ultrasound curve angle\n(UCA) measurement. The model employs a dual-branch network to detect candidate\nlandmarks and perform vertebra segmentation on ultrasound coronal images. An\naffinity clustering strategy is utilized within the vertebral segmentation area\nto illustrate the affinity relationship between candidate landmarks.\nSubsequently, we can efficiently perform line delineation from a clustered\naffinity map for UCA measurement. As our method is specifically designed for\nUCA calculation, this method outperforms other state-of-the-art methods for\nlandmark and line detection tasks. The high correlation between the automatic\nUCA and Cobb angle (R$^2$=0.858) suggests that our proposed method can\npotentially replace manual UCA measurement in ultrasound scoliosis assessment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03141v2",
    "published_date": "2024-05-06 03:28:47 UTC",
    "updated_date": "2024-05-07 03:21:18 UTC"
  },
  {
    "arxiv_id": "2405.10329v3",
    "title": "Causal inference approach to appraise long-term effects of maintenance policy on functional performance of asphalt pavements",
    "authors": [
      "Lingyun You",
      "Nanning Guo",
      "Zhengwu Long",
      "Fusong Wang",
      "Chundi Si",
      "Aboelkasim Diab"
    ],
    "abstract": "Asphalt pavements as the most prevalent transportation infrastructure, are\nprone to serious traffic safety problems due to functional or structural damage\ncaused by stresses or strains imposed through repeated traffic loads and\ncontinuous climatic cycles. The good quality or high serviceability of\ninfrastructure networks is vital to the urbanization and industrial development\nof nations. In order to maintain good functional pavement performance and\nextend the service life of asphalt pavements, the long-term performance of\npavements under maintenance policies needs to be evaluated and favorable\noptions selected based on the condition of the pavement. A major challenge in\nevaluating maintenance policies is to produce valid treatments for the outcome\nassessment under the control of uncertainty of vehicle loads and the\ndisturbance of freeze-thaw cycles in the climatic environment. In this study, a\nnovel causal inference approach combining a classical causal structural model\nand a potential outcome model framework is proposed to appraise the long-term\neffects of four preventive maintenance treatments for longitudinal cracking\nover a 5-year period of upkeep. Three fundamental issues were brought to our\nattention: 1) detection of causal relationships prior to variables under\nenvironmental loading (identification of causal structure); 2) obtaining direct\ncausal effects of treatment on outcomes excluding covariates (identification of\ncausal effects); and 3) sensitivity analysis of causal relationships. The\nresults show that the method can accurately evaluate the effect of preventive\nmaintenance treatments and assess the maintenance time to cater well for the\nfunctional performance of different preventive maintenance approaches. This\nframework could help policymakers to develop appropriate maintenance strategies\nfor pavements.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "The arXiv version needs to be withdrawn since the model needs to be\n  validated and updated with advanced machine learning technologies to enhance\n  the accuracy of the model, and there are some crucial definition errors of\n  symbols in the arXiv version",
    "pdf_url": "http://arxiv.org/pdf/2405.10329v3",
    "published_date": "2024-05-06 03:22:38 UTC",
    "updated_date": "2024-07-03 00:53:21 UTC"
  },
  {
    "arxiv_id": "2405.03131v1",
    "title": "WDMoE: Wireless Distributed Large Language Models with Mixture of Experts",
    "authors": [
      "Nan Xue",
      "Yaping Sun",
      "Zhiyong Chen",
      "Meixia Tao",
      "Xiaodong Xu",
      "Liang Qian",
      "Shuguang Cui",
      "Ping Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but how wireless communications can support\nLLMs has not been extensively studied. In this paper, we propose a wireless\ndistributed LLMs paradigm based on Mixture of Experts (MoE), named WDMoE,\ndeploying LLMs collaboratively across edge servers of base station (BS) and\nmobile devices in the wireless communications system. Specifically, we\ndecompose the MoE layer in LLMs by deploying the gating network and the\npreceding neural network layer at BS, while distributing the expert networks\nacross the devices. This arrangement leverages the parallel capabilities of\nexpert networks on distributed devices. Moreover, to overcome the instability\nof wireless communications, we design an expert selection policy by taking into\naccount both the performance of the model and the end-to-end latency, which\nincludes both transmission delay and inference delay. Evaluations conducted\nacross various LLMs and multiple datasets demonstrate that WDMoE not only\noutperforms existing models, such as Llama 2 with 70 billion parameters, but\nalso significantly reduces end-to-end latency.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "submitted to IEEE conference",
    "pdf_url": "http://arxiv.org/pdf/2405.03131v1",
    "published_date": "2024-05-06 02:55:50 UTC",
    "updated_date": "2024-05-06 02:55:50 UTC"
  },
  {
    "arxiv_id": "2405.03121v1",
    "title": "AniTalker: Animate Vivid and Diverse Talking Faces through Identity-Decoupled Facial Motion Encoding",
    "authors": [
      "Tao Liu",
      "Feilong Chen",
      "Shuai Fan",
      "Chenpeng Du",
      "Qi Chen",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "The paper introduces AniTalker, an innovative framework designed to generate\nlifelike talking faces from a single portrait. Unlike existing models that\nprimarily focus on verbal cues such as lip synchronization and fail to capture\nthe complex dynamics of facial expressions and nonverbal cues, AniTalker\nemploys a universal motion representation. This innovative representation\neffectively captures a wide range of facial dynamics, including subtle\nexpressions and head movements. AniTalker enhances motion depiction through two\nself-supervised learning strategies: the first involves reconstructing target\nvideo frames from source frames within the same identity to learn subtle motion\nrepresentations, and the second develops an identity encoder using metric\nlearning while actively minimizing mutual information between the identity and\nmotion encoders. This approach ensures that the motion representation is\ndynamic and devoid of identity-specific details, significantly reducing the\nneed for labeled data. Additionally, the integration of a diffusion model with\na variance adapter allows for the generation of diverse and controllable facial\nanimations. This method not only demonstrates AniTalker's capability to create\ndetailed and realistic facial movements but also underscores its potential in\ncrafting dynamic avatars for real-world applications. Synthetic results can be\nviewed at https://github.com/X-LANCE/AniTalker.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.03121v1",
    "published_date": "2024-05-06 02:32:41 UTC",
    "updated_date": "2024-05-06 02:32:41 UTC"
  },
  {
    "arxiv_id": "2405.03113v1",
    "title": "Robot Air Hockey: A Manipulation Testbed for Robot Learning with Reinforcement Learning",
    "authors": [
      "Caleb Chuck",
      "Carl Qi",
      "Michael J. Munje",
      "Shuozhe Li",
      "Max Rudolph",
      "Chang Shi",
      "Siddhant Agarwal",
      "Harshit Sikchi",
      "Abhinav Peri",
      "Sarthak Dayal",
      "Evan Kuo",
      "Kavan Mehta",
      "Anthony Wang",
      "Peter Stone",
      "Amy Zhang",
      "Scott Niekum"
    ],
    "abstract": "Reinforcement Learning is a promising tool for learning complex policies even\nin fast-moving and object-interactive domains where human teleoperation or\nhard-coded policies might fail. To effectively reflect this challenging\ncategory of tasks, we introduce a dynamic, interactive RL testbed based on\nrobot air hockey. By augmenting air hockey with a large family of tasks ranging\nfrom easy tasks like reaching, to challenging ones like pushing a block by\nhitting it with a puck, as well as goal-based and human-interactive tasks, our\ntestbed allows a varied assessment of RL capabilities. The robot air hockey\ntestbed also supports sim-to-real transfer with three domains: two simulators\nof increasing fidelity and a real robot system. Using a dataset of\ndemonstration data gathered through two teleoperation systems: a virtualized\ncontrol environment, and human shadowing, we assess the testbed with behavior\ncloning, offline RL, and RL from scratch.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.03113v1",
    "published_date": "2024-05-06 02:13:08 UTC",
    "updated_date": "2024-05-06 02:13:08 UTC"
  },
  {
    "arxiv_id": "2405.03097v1",
    "title": "To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models",
    "authors": [
      "George-Octavian Barbulescu",
      "Peter Triantafillou"
    ],
    "abstract": "LLMs have been found to memorize training textual sequences and regurgitate\nverbatim said sequences during text generation time. This fact is known to be\nthe cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs\nthen takes the form of devising new algorithms that will properly deal with\nthese side-effects of memorized data, while not hurting the model's utility. We\noffer a fresh perspective towards this goal, namely, that each textual sequence\nto be forgotten should be treated differently when being unlearned based on its\ndegree of memorization within the LLM. We contribute a new metric for measuring\nunlearning quality, an adversarial attack showing that SOTA algorithms lacking\nthis perspective fail for privacy, and two new unlearning methods based on\nGradient Ascent and Task Arithmetic, respectively. A comprehensive performance\nevaluation across an extensive suite of NLP tasks then mapped the solution\nspace, identifying the best solutions under different scales in model\ncapacities and forget set sizes and quantified the gains of the new approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.03097v1",
    "published_date": "2024-05-06 01:21:50 UTC",
    "updated_date": "2024-05-06 01:21:50 UTC"
  }
]