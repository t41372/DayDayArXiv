{
  "date": "2025-03-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 128 篇论文，主要聚焦 AI 模型优化、LLM 在代码生成和问答中的应用、强化学习算法、图像生成以及医疗 AI 等领域，其中令人印象深刻的包括 DeepSeek-R1 的零 RL 训练框架和 Aether 的几何感知世界建模，而 Michael I. Jordan 等知名学者参与的 LLM 微调安全权衡论文也值得关注。\n\n### LLM 和 AI 代理应用\n这些论文探讨了大型语言模型在代码开发、问答和代理系统中的性能提升。\n- **LLM Benchmarking with LLaMA2: Evaluating Code Development Performance Across Multiple Programming Languages**（LLM 与 LLaMA2 的代码开发性能评估）：Diehl 等评估 Llama 2-70B 在科学应用的代码生成、文档和单元测试能力，发现它在简单任务中表现良好，但复杂并行计算需手动修正，强调 AI 在软件开发中的局限性。\n- **A Survey of Large Language Model Agents for Question Answering**（大型语言模型代理在问答中的调查）：Yue 综述 LLM 代理如何通过外部环境交互提升问答性能，讨论规划、信息检索和答案生成的关键阶段，并指出未来挑战如泛化改进。\n- **Overtrained Language Models Are Harder to Fine-Tune**（过度训练的语言模型更难微调）：Springer 等揭示过度训练导致模型参数敏感性增加，影响下游性能，提出“灾难性过度训练”概念，并通过实验验证其在 LLM 基准上的负面影响（72 页报告）。\n- **Fundamental Safety-Capability Trade-offs in Fine-tuning Large Language Models**（LLM 微调中的安全-能力权衡）：Chen 等理论分析微调策略下安全与能力的冲突，强调数据相似性和上下文重叠的影响，为 LLM 适应性设计提供新见解。\n- **A Shared Low-Rank Adaptation Approach to Personalized RLHF**（个性化 RLHF 的低秩适应方法）：Liu 等引入 LoRA 用于个性化强化学习反馈，提升对异质偏好的适应性，并提供样本复杂度保证。\n- **LookAhead Tuning: Safer Language Models via Partial Answer Previews**（预览部分答案的更安全 LLM 微调）：Liu 等提出微调时预览部分答案的方法，减少对安全机制的干扰，提高下游任务性能。\n\n### 强化学习和规划\n这些论文推进了强化学习在机器人和决策中的应用，强调效率和鲁棒性。\n- **Continual Reinforcement Learning for HVAC Systems Control: Integrating Hypernetworks and Transfer Learning**（HVAC 系统控制的持续强化学习）：Bekal 等提出基于 Hypernetworks 的框架，提升 HVAC 系统的样本效率和泛化能力，缓解灾难性遗忘问题，支持可持续能源目标。\n- **Efficient Joint Prediction of Multiple Future Tokens**（高效的多未来标记联合预测）：Ahn 等引入 JTP 方法，通过教师强制和表示瓶颈提升强化学习中的预测准确性。\n- **Evolutionary Policy Optimization**（进化策略优化）：Wang 等结合进化算法和策略梯度，改善并行模拟下的强化学习性能。\n- **Aether: Geometric-Aware Unified World Modeling**（几何感知的统一世界建模）：Aether 团队开发几何感知框架，支持 4D 重建和视觉规划，实现零样本泛化。\n- **SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild**（SimpleRL-Zoo：零强化学习的基准环境）：Zeng 等探索零 RL 在不同基模型上的性能，提供新数据集和工具。\n\n### 图像和视频生成\n这些论文优化了多模态生成模型，提升了生成质量和效率。\n- **Video-T1: Test-Time Scaling for Video Generation**（视频生成中的测试时缩放）：Liu 等提出测试时搜索策略，提升视频生成质量，支持高加速生成。\n- **AdaWorld: Learning Adaptable World Models with Latent Actions**（自适应世界建模）：Gao 等使用潜在动作学习自适应世界模型，提高探索效率。\n- **Diffusion Models for Video Generation**（相关生成模型）：如 EvAnimate，使用事件流作为运动线索生成视频，改善时序一致性。\n\n### 医疗和科学应用\n这些论文将 AI 应用于医疗和科学领域，关注实际影响。\n- **PSO-UNet: Particle Swarm-Optimized U-Net Framework for Precise Multimodal Brain Tumor Segmentation**（粒子群优化的 U-Net 框架）：Saifullah 等优化 U-Net 参数，提升脑肿瘤分割精度和效率。\n- **ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports**（语言模型集成预测肿瘤组）：Gondara 等提出集成模型从病理报告预测肿瘤组，提高医疗数据提取效率。\n- **The Case for \"Thick Evaluations\" of Cultural Representation in AI**（AI 中文化表示的“厚评估”）：Qadri 等建议更细粒度的文化表示评估框架，促进 AI 公平性。\n\n其他论文如经济学、音频水印和网络安全等主题（如第15篇的决策策略和第8篇的音频水印鲁棒性分析）虽有贡献，但相对次要，这里快速掠过：它们分别探讨不确定环境下的决策优化和水印抗攻击方法，提供新基准和框架，但未见重大突破。\n\n总之，今天的论文突显 AI 在实际应用中的潜力，尤其在 LLM 和强化学习的优化上，未来研究可关注模型鲁棒性和跨领域泛化。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2503.19217v1",
      "title": "LLM Benchmarking with LLaMA2: Evaluating Code Development Performance Across Multiple Programming Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Diehl",
        "Nojoud Nader",
        "Maxim Moraru",
        "Steven R. Brandt"
      ],
      "abstract": "The rapid evolution of large language models (LLMs) has opened new\npossibilities for automating various tasks in software development. This paper\nevaluates the capabilities of the Llama 2-70B model in automating these tasks\nfor scientific applications written in commonly used programming languages.\nUsing representative test problems, we assess the model's capacity to generate\ncode, documentation, and unit tests, as well as its ability to translate\nexisting code between commonly used programming languages. Our comprehensive\nanalysis evaluates the compilation, runtime behavior, and correctness of the\ngenerated and translated code. Additionally, we assess the quality of\nautomatically generated code, documentation and unit tests. Our results\nindicate that while Llama 2-70B frequently generates syntactically correct and\nfunctional code for simpler numerical tasks, it encounters substantial\ndifficulties with more complex, parallelized, or distributed computations,\nrequiring considerable manual corrections. We identify key limitations and\nsuggest areas for future improvements to better leverage AI-driven automation\nin scientific computing workflows.",
      "tldr_zh": "本论文评估了Llama 2-70B模型在多个编程语言中自动化软件开发任务的能力，包括代码生成、文档编写、单元测试以及代码翻译。研究通过代表性测试问题分析了生成的代码在编译、运行行为和正确性方面的表现，结果显示模型在简单数值任务上能产生语法正确且功能性的代码，但对复杂、并行或分布式计算存在显著挑战，需要大量手动修正。论文识别了关键限制，并建议未来改进方向，以更好地将AI应用于科学计算工作流。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19217v1",
      "published_date": "2025-03-24 23:46:14 UTC",
      "updated_date": "2025-03-24 23:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:25:17.092760"
    },
    {
      "arxiv_id": "2503.19213v1",
      "title": "A Survey of Large Language Model Agents for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Murong Yue"
      ],
      "abstract": "This paper surveys the development of large language model (LLM)-based agents\nfor question answering (QA). Traditional agents face significant limitations,\nincluding substantial data requirements and difficulty in generalizing to new\nenvironments. LLM-based agents address these challenges by leveraging LLMs as\ntheir core reasoning engine. These agents achieve superior QA results compared\nto traditional QA pipelines and naive LLM QA systems by enabling interaction\nwith external environments. We systematically review the design of LLM agents\nin the context of QA tasks, organizing our discussion across key stages:\nplanning, question understanding, information retrieval, and answer generation.\nAdditionally, this paper identifies ongoing challenges and explores future\nresearch directions to enhance the performance of LLM agent QA systems.",
      "tldr_zh": "这篇论文调查了大型语言模型 (LLM) 基于代理在问答 (QA) 任务中的发展，强调了 LLM 代理如何通过与外部环境的交互来克服传统代理的局限性，如数据需求大和泛化能力差。论文系统地审视了 LLM 代理的设计流程，包括规划、问题理解、信息检索和答案生成阶段，并展示了这些代理在 QA 性能上优于传统系统和简单 LLM 方法。最终，论文指出了当前挑战并探讨了未来研究方向，以进一步提升 LLM 代理系统的效能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19213v1",
      "published_date": "2025-03-24 23:39:44 UTC",
      "updated_date": "2025-03-24 23:39:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:25:28.182943"
    },
    {
      "arxiv_id": "2503.19212v1",
      "title": "Continual Reinforcement Learning for HVAC Systems Control: Integrating Hypernetworks and Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gautham Udayakumar Bekal",
        "Ahmed Ghareeb",
        "Ashish Pujari"
      ],
      "abstract": "Buildings with Heating, Ventilation, and Air Conditioning (HVAC) systems play\na crucial role in ensuring indoor comfort and efficiency. While traditionally\ngoverned by physics-based models, the emergence of big data has enabled\ndata-driven methods like Deep Reinforcement Learning (DRL). However,\nReinforcement Learning (RL)-based techniques often suffer from sample\ninefficiency and limited generalization, especially across varying HVAC\nsystems. We introduce a model-based reinforcement learning framework that uses\na Hypernetwork to continuously learn environment dynamics across tasks with\ndifferent action spaces. This enables efficient synthetic rollout generation\nand improved sample usage. Our approach demonstrates strong backward transfer\nin a continual learning setting after training on a second task, minimal\nfine-tuning on the first task allows rapid convergence within just 5 episodes\nand thus outperforming Model Free Reinforcement Learning (MFRL) and effectively\nmitigating catastrophic forgetting. These findings have significant\nimplications for reducing energy consumption and operational costs in building\nmanagement, thus supporting global sustainability goals.\n  Keywords: Deep Reinforcement Learning, HVAC Systems Control, Hypernetworks,\nTransfer and Continual Learning, Catastrophic Forgetting",
      "tldr_zh": "本研究提出了一种基于模型的强化学习框架，用于 HVAC 系统控制，通过整合 Hypernetworks 实现不同任务的环境动态持续学习，即使行动空间不同，从而提高样本效率和合成 rollout 生成。该框架在持续学习设置中展示了强 backward transfer，仅需对第一个任务微调 5 个 episodes 即可快速收敛，优于 Model Free Reinforcement Learning (MFRL)，并有效缓解 catastrophic forgetting。实验结果表明，该方法显著提升了 HVAC 系统的泛化能力，最终有助于减少建筑能源消耗和运营成本，支持可持续发展目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19212v1",
      "published_date": "2025-03-24 23:38:04 UTC",
      "updated_date": "2025-03-24 23:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:25:39.569054"
    },
    {
      "arxiv_id": "2503.19206v2",
      "title": "Overtrained Language Models Are Harder to Fine-Tune",
      "title_zh": "过度训练的语言模型更难微调",
      "authors": [
        "Jacob Mitchell Springer",
        "Sachin Goyal",
        "Kaiyue Wen",
        "Tanishq Kumar",
        "Xiang Yue",
        "Sadhika Malladi",
        "Graham Neubig",
        "Aditi Raghunathan"
      ],
      "abstract": "Large language models are pre-trained on ever-growing token budgets under the\nassumption that better pre-training performance translates to improved\ndownstream models. In this work, we challenge this assumption and show that\nextended pre-training can make models harder to fine-tune, leading to degraded\nfinal performance. We term this phenomenon catastrophic overtraining. For\nexample, the instruction-tuned OLMo-1B model pre-trained on 3T tokens leads to\nover 2% worse performance on multiple standard LLM benchmarks than its 2.3T\ntoken counterpart. Through controlled experiments and theoretical analysis, we\nshow that catastrophic overtraining arises from a systematic increase in the\nbroad sensitivity of pre-trained parameters to modifications, including but not\nlimited to fine-tuning. Our findings call for a critical reassessment of\npre-training design that considers the downstream adaptability of the model.",
      "tldr_zh": "该研究挑战了大型语言模型（Large Language Models）通过更多 token 预训练就能提升下游性能的假设，发现过度预训练会导致 catastrophic overtraining 现象，使模型更难 fine-tune 并降低最终表现。举例来说，OLMo-1B 模型在 3T tokens 上预训练比 2.3T tokens 上预训练的表现在多个 LLM 基准上差超过 2%。通过控制实验和理论分析，作者证明了过度预训练会增加预训练参数的广泛敏感性。研究呼吁重新评估 pre-training 设计，以改善模型的下游适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "72 pages, 65 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.19206v2",
      "published_date": "2025-03-24 23:11:56 UTC",
      "updated_date": "2025-03-28 02:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:25:52.562121"
    },
    {
      "arxiv_id": "2503.19201v1",
      "title": "A Shared Low-Rank Adaptation Approach to Personalized RLHF",
      "title_zh": "一种共享低秩适配方法，用于个性化的 RLHF",
      "authors": [
        "Renpu Liu",
        "Peng Wang",
        "Donghao Li",
        "Cong Shen",
        "Jing Yang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal\ntechnique for aligning artificial intelligence systems with human values,\nachieving remarkable success in fine-tuning large language models. However,\nexisting RLHF frameworks often assume that human preferences are relatively\nhomogeneous and can be captured by a single, unified reward model. This\nassumption overlooks the inherent diversity and heterogeneity across\nindividuals, limiting the adaptability of RLHF to personalized scenarios and\nrisking misalignments that can diminish user satisfaction and trust in AI\nsystems. In this paper, we address these challenges by introducing Low-Rank\nAdaptation (LoRA) into the personalized RLHF framework. We apply LoRA in the\nthe aggregated parameter space of all personalized reward functions, thereby\nenabling efficient learning of personalized reward models from potentially\nlimited local datasets. Our approach exploits potential shared structures among\nthe local ground-truth reward models while allowing for individual adaptation,\nwithout relying on restrictive assumptions about shared representations as in\nprior works. We further establish sample complexity guarantees for our method.\nTheoretical analysis demonstrates the effectiveness of the proposed approach in\ncapturing both shared and individual-specific structures within heterogeneous\nhuman preferences, addressing the dual challenge of personalization\nrequirements and practical data constraints. Experimental results on real-world\ndatasets corroborate the efficiency of our algorithm in the personalized RLHF\nsetting.",
      "tldr_zh": "这篇论文针对 Reinforcement Learning from Human Feedback (RLHF) 的局限性，提出了一种基于 Low-Rank Adaptation (LoRA) 的个性化方法，以解决现有框架忽略人类偏好异质性的问题。该方法在所有个性化奖励函数的聚合参数空间应用 LoRA，利用潜在共享结构从有限本地数据集高效学习个性化奖励模型，同时允许个体适应，而不依赖于先前工作的限制性假设。理论分析提供了样本复杂度保证，证明了该方法在捕捉共享和个体特定结构方面的有效性。实验结果在真实数据集上验证了算法在个性化 RLHF 场景中的高效性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.19201v1",
      "published_date": "2025-03-24 23:01:08 UTC",
      "updated_date": "2025-03-24 23:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:26:04.611047"
    },
    {
      "arxiv_id": "2503.19195v1",
      "title": "Mining-Gym: A Configurable RL Benchmarking Environment for Truck Dispatch Scheduling",
      "title_zh": "Mining-Gym：一个可配置的强化学习基准测试环境，用于卡车调度",
      "authors": [
        "Chayan Banerjee",
        "Kien Nguyen",
        "Clinton Fookes"
      ],
      "abstract": "Mining process optimization particularly truck dispatch scheduling is a\ncritical factor in enhancing the efficiency of open pit mining operations\nHowever the dynamic and stochastic nature of mining environments characterized\nby uncertainties such as equipment failures truck maintenance and variable haul\ncycle times poses significant challenges for traditional optimization methods\nWhile Reinforcement Learning RL has shown promise in adaptive decision making\nfor mining logistics its practical deployment requires rigorous evaluation in\nrealistic and customizable simulation environments The lack of standardized\nbenchmarking environments limits fair algorithm comparisons reproducibility and\nthe real world applicability of RL based approaches in open pit mining settings\nTo address this challenge we introduce Mining Gym a configurable open source\nbenchmarking environment designed for training testing and comparing RL\nalgorithms in mining process optimization Built on Discrete Event Simulation\nDES and seamlessly integrated with the OpenAI Gym interface Mining Gym provides\na structured testbed that enables the direct application of advanced RL\nalgorithms from Stable Baselines The framework models key mining specific\nuncertainties such as equipment failures queue congestion and the stochasticity\nof mining processes ensuring a realistic and adaptive learning environment\nAdditionally Mining Gym features a graphical user interface GUI for intuitive\nmine site configuration a comprehensive data logging system a built in KPI\ndashboard and real time visual representation of the mine site These\ncapabilities facilitate standardized reproducible evaluations across multiple\nRL strategies and baseline heuristics",
      "tldr_zh": "该论文介绍了 Mining-Gym，一个可配置的开源基准环境，旨在通过 Reinforcement Learning (RL) 算法优化露天矿业的卡车调度问题，以应对动态不确定性如设备故障和运输周期变异。Mining-Gym 基于 Discrete Event Simulation (DES) 构建，并与 OpenAI Gym 接口无缝集成，提供模拟关键矿业不确定性、图形用户界面 (GUI) 配置、数据日志系统和 KPI 仪表板的功能。实验评估显示，该框架支持标准化、可复现的 RL 策略比较和基线启发式方法测试，有助于提升矿业物流效率和算法实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.19195v1",
      "published_date": "2025-03-24 22:48:20 UTC",
      "updated_date": "2025-03-24 22:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:26:16.881070"
    },
    {
      "arxiv_id": "2503.19193v1",
      "title": "Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Sky CH-Wang",
        "Darshan Deshpande",
        "Smaranda Muresan",
        "Anand Kannappan",
        "Rebecca Qian"
      ],
      "abstract": "We introduce Browsing Lost Unformed Recollections, a tip-of-the-tongue\nknown-item search and reasoning benchmark for general AI assistants. BLUR\nintroduces a set of 573 real-world validated questions that demand searching\nand reasoning across multi-modal and multilingual inputs, as well as proficient\ntool use, in order to excel on. Humans easily ace these questions (scoring on\naverage 98%), while the best-performing system scores around 56%. To facilitate\nprogress toward addressing this challenging and aspirational use case for\ngeneral AI assistants, we release 350 questions through a public leaderboard,\nretain the answers to 250 of them, and have the rest as a private test set.",
      "tldr_zh": "本研究引入了 BLUR 基准测试，用于评估通用 AI 助手的“tip-of-the-tongue”已知项目搜索和推理能力。BLUR 包含 573 个真实世界验证的问题，这些问题需要跨多模态和多语言输入进行搜索、推理以及熟练工具使用。人类在这些问题上平均得分 98%，而最佳 AI 系统仅达到 56%，突显了 AI 在此方面的不足。为推动进展，研究团队发布 350 个问题用于公共排行榜，并保留 250 个答案作为测试集，其余作为私有测试集。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19193v1",
      "published_date": "2025-03-24 22:46:25 UTC",
      "updated_date": "2025-03-24 22:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:26:27.989361"
    },
    {
      "arxiv_id": "2503.19176v2",
      "title": "SoK: How Robust is Audio Watermarking in Generative AI models?",
      "title_zh": "SoK: 生成式 AI 模型中音频水印的鲁棒性如何？",
      "authors": [
        "Yizhu Wen",
        "Ashwin Innuganti",
        "Aaron Bien Ramos",
        "Hanqing Guo",
        "Qiben Yan"
      ],
      "abstract": "Audio watermarking is increasingly used to verify the provenance of\nAI-generated content, enabling applications such as detecting AI-generated\nspeech, protecting music IP, and defending against voice cloning. To be\neffective, audio watermarks must resist removal attacks that distort signals to\nevade detection. While many schemes claim robustness, these claims are\ntypically tested in isolation and against a limited set of attacks. A\nsystematic evaluation against diverse removal attacks is lacking, hindering\npractical deployment. In this paper, we investigate whether recent watermarking\nschemes that claim robustness can withstand a broad range of removal attacks.\nFirst, we introduce a taxonomy covering 22 audio watermarking schemes. Next, we\nsummarize their underlying technologies and potential vulnerabilities. We then\npresent a large-scale empirical study to assess their robustness. To support\nthis, we build an evaluation framework encompassing 22 types of removal attacks\n(109 configurations) including signal-level, physical-level, and AI-induced\ndistortions. We reproduce 9 watermarking schemes using open-source code,\nidentify 8 new highly effective attacks, and highlight 11 key findings that\nexpose the fundamental limitations of these methods across 3 public datasets.\nOur results reveal that none of the surveyed schemes can withstand all tested\ndistortions. This evaluation offers a comprehensive view of how current\nwatermarking methods perform under real-world threats. Our demo and code are\navailable at https://sokaudiowm.github.io/.",
      "tldr_zh": "本论文（SoK）系统评估了 Generative AI 模型中 audio watermarking 的鲁棒性，针对移除攻击进行全面调查，以验证其在检测 AI 生成语音、保护音乐知识产权和防御语音克隆等方面的有效性。研究者引入了 22 种 audio watermarking 方案的分类，总结了其底层技术和潜在漏洞，并构建了一个评估框架，涵盖 22 种移除攻击（109 个配置），包括信号级、物理级和 AI 诱导扭曲。实验中，他们复制了 9 种方案，识别了 8 种新高度有效的攻击，并揭示了 11 个关键发现，暴露这些方法的根本限制。最终结果显示，没有任何方案能抵抗所有测试扭曲，为 audio watermarking 的实际部署提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19176v2",
      "published_date": "2025-03-24 21:57:59 UTC",
      "updated_date": "2025-03-27 00:51:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:26:42.269087"
    },
    {
      "arxiv_id": "2503.19174v2",
      "title": "AssertionForge: Enhancing Formal Verification Assertion Generation with Structured Representation of Specifications and RTL",
      "title_zh": "翻译失败",
      "authors": [
        "Yunsheng Bai",
        "Ghaith Bany Hamad",
        "Syed Suhaib",
        "Haoxing Ren"
      ],
      "abstract": "Generating SystemVerilog Assertions (SVAs) from natural language\nspecifications remains a major challenge in formal verification (FV) due to the\ninherent ambiguity and incompleteness of specifications. Existing LLM-based\napproaches, such as AssertLLM, focus on extracting information solely from\nspecification documents, often failing to capture essential internal signal\ninteractions and design details present in the RTL code, leading to incomplete\nor incorrect assertions. We propose a novel approach that constructs a\nKnowledge Graph (KG) from both specifications and RTL, using a\nhardware-specific schema with domain-specific entity and relation types. We\ncreate an initial KG from the specification and then systematically fuse it\nwith information extracted from the RTL code, resulting in a unified,\ncomprehensive KG. This combined representation enables a more thorough\nunderstanding of the design and allows for a multi-resolution context synthesis\nprocess which is designed to extract diverse verification contexts from the KG.\nExperiments on four designs demonstrate that our method significantly enhances\nSVA quality over prior methods. This structured representation not only\nimproves FV but also paves the way for future research in tasks like code\ngeneration and design understanding.",
      "tldr_zh": "该研究提出AssertionForge方法，通过构建从规范和RTL代码的结构化Knowledge Graph (KG)来提升正式验证(FV)中SystemVerilog Assertions (SVAs)的生成质量。方法首先从自然语言规范创建初始KG，然后与从RTL代码提取的信息融合，形成统一的KG，并进行多分辨率上下文合成以提取全面的验证上下文。实验在四个设计上证明，该方法显著提高了SVAs的质量，不仅改善了FV过程，还为代码生成和设计理解等任务提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "LAD 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.19174v2",
      "published_date": "2025-03-24 21:53:37 UTC",
      "updated_date": "2025-05-14 20:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:26:51.776019"
    },
    {
      "arxiv_id": "2503.19152v1",
      "title": "PSO-UNet: Particle Swarm-Optimized U-Net Framework for Precise Multimodal Brain Tumor Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Shoffan Saifullah",
        "Rafał Dreżewski"
      ],
      "abstract": "Medical image segmentation, particularly for brain tumor analysis, demands\nprecise and computationally efficient models due to the complexity of\nmultimodal MRI datasets and diverse tumor morphologies. This study introduces\nPSO-UNet, which integrates Particle Swarm Optimization (PSO) with the U-Net\narchitecture for dynamic hyperparameter optimization. Unlike traditional manual\ntuning or alternative optimization approaches, PSO effectively navigates\ncomplex hyperparameter search spaces, explicitly optimizing the number of\nfilters, kernel size, and learning rate. PSO-UNet substantially enhances\nsegmentation performance, achieving Dice Similarity Coefficients (DSC) of\n0.9578 and 0.9523 and Intersection over Union (IoU) scores of 0.9194 and 0.9097\non the BraTS 2021 and Figshare datasets, respectively. Moreover, the method\nreduces computational complexity significantly, utilizing only 7.8 million\nparameters and executing in approximately 906 seconds, markedly faster than\ncomparable U-Net-based frameworks. These outcomes underscore PSO-UNet's robust\ngeneralization capabilities across diverse MRI modalities and tumor\nclassifications, emphasizing its clinical potential and clear advantages over\nconventional hyperparameter tuning methods. Future research will explore hybrid\noptimization strategies and validate the framework against other bio-inspired\nalgorithms to enhance its robustness and scalability.",
      "tldr_zh": "本研究提出PSO-UNet框架，将Particle Swarm Optimization (PSO)与U-Net架构相结合，用于精确的多模态脑肿瘤分割，通过动态优化超参数（如过滤器数量、内核大小和学习率）来提升模型性能。实验结果显示，该框架在BraTS 2021数据集上达到Dice Similarity Coefficients (DSC) 0.9578和Intersection over Union (IoU) 0.9194，在Figshare数据集上分别达到DSC 0.9523和IoU 0.9097，显著优于传统方法。PSO-UNet还降低了计算复杂性，仅使用7.8百万参数和约906秒的运行时间，展示了其在不同MRI模态和肿瘤分类中的鲁棒性及临床潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68Q07",
        "I.4.6; I.2"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages, 6 figures, 4 tables, Gecco 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2503.19152v1",
      "published_date": "2025-03-24 21:14:08 UTC",
      "updated_date": "2025-03-24 21:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:27:05.083466"
    },
    {
      "arxiv_id": "2503.20807v1",
      "title": "Fundamental Safety-Capability Trade-offs in Fine-tuning Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pin-Yu Chen",
        "Han Shen",
        "Payel Das",
        "Tianyi Chen"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) on some task-specific datasets has\nbeen a primary use of LLMs. However, it has been empirically observed that this\napproach to enhancing capability inevitably compromises safety, a phenomenon\nalso known as the safety-capability trade-off in LLM fine-tuning. This paper\npresents a theoretical framework for understanding the interplay between safety\nand capability in two primary safety-aware LLM fine-tuning strategies,\nproviding new insights into the effects of data similarity, context overlap,\nand alignment loss landscape. Our theoretical results characterize the\nfundamental limits of the safety-capability trade-off in LLM fine-tuning, which\nare also validated by numerical experiments.",
      "tldr_zh": "本研究探讨了在Fine-tuning Large Language Models (LLMs)时，增强模型能力（如任务特定性能）不可避免地会牺牲安全性的现象，即Safety-Capability Trade-offs。该论文提出一个理论框架，分析了两种主要的安全感知微调策略，考察数据相似性、上下文重叠以及Alignment loss landscape的影响。理论结果揭示了这种权衡的基本限制，并通过数值实验进行验证，为LLMs的安全优化提供了新见解。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "The first two authors contribute equally to this work and are listed\n  in alphabetical order",
      "pdf_url": "http://arxiv.org/pdf/2503.20807v1",
      "published_date": "2025-03-24 20:41:57 UTC",
      "updated_date": "2025-03-24 20:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:27:15.607148"
    },
    {
      "arxiv_id": "2503.19123v1",
      "title": "Overcoming Vocabulary Mismatch: Vocabulary-agnostic Teacher Guided Language Modeling",
      "title_zh": "克服词汇不匹配：词汇无关的教师引导语言建模",
      "authors": [
        "Haebin Shin",
        "Lei Ji",
        "Xiao Liu",
        "Yeyun Gong"
      ],
      "abstract": "Using large teacher models to guide the training of smaller student models\nhas become the prevailing paradigm for efficient and effective learning.\nHowever, vocabulary mismatches between teacher and student language models pose\nsignificant challenges in language modeling, resulting in divergent token\nsequences and output distributions. To overcome these limitations, we propose\nVocabulary-agnostic Teacher Guided Language Modeling (VocAgnoLM), a novel\napproach that bridges the gap caused by vocabulary mismatch through two key\nmethods: (1) Token-level Lexical Alignment, which aligns token sequences across\nmismatched vocabularies, and (2) Teacher Guided Loss, which leverages the loss\nof teacher model to guide effective student training. We demonstrate its\neffectiveness in language modeling with 1B student model using various 7B\nteacher models with different vocabularies. Notably, with\nQwen2.5-Math-Instruct, a teacher model sharing only about 6% of its vocabulary\nwith TinyLlama, VocAgnoLM achieves a 46% performance improvement compared to\nnaive continual pretraining. Furthermore, we demonstrate that VocAgnoLM\nconsistently benefits from stronger teacher models, providing a robust solution\nto vocabulary mismatches in language modeling.",
      "tldr_zh": "该研究提出了一种名为 VocAgnoLM 的方法，用于解决教师模型和学生模型之间词汇不匹配的问题，从而提升语言建模的效率。VocAgnoLM 通过 Token-level Lexical Alignment 对齐不同词汇表中的 token 序列，以及 Teacher Guided Loss 利用教师模型的损失来指导学生模型训练。实验结果显示，在使用 7B 教师模型（如 Qwen2.5-Math-Instruct）指导 1B 学生模型时，与 naive continual pretraining 相比，VocAgnoLM 实现了高达 46% 的性能提升，且能从更强的教师模型中获益，提供了一个稳健的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19123v1",
      "published_date": "2025-03-24 20:19:31 UTC",
      "updated_date": "2025-03-24 20:19:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:27:28.761518"
    },
    {
      "arxiv_id": "2504.07971v1",
      "title": "SPHERE: An Evaluation Card for Human-AI Systems",
      "title_zh": "SPHERE：人类-AI 系统的评估卡",
      "authors": [
        "Qianou Ma",
        "Dora Zhao",
        "Xinran Zhao",
        "Chenglei Si",
        "Chenyang Yang",
        "Ryan Louie",
        "Ehud Reiter",
        "Diyi Yang",
        "Tongshuang Wu"
      ],
      "abstract": "In the era of Large Language Models (LLMs), establishing effective evaluation\nmethods and standards for diverse human-AI interaction systems is increasingly\nchallenging. To encourage more transparent documentation and facilitate\ndiscussion on human-AI system evaluation design options, we present an\nevaluation card SPHERE, which encompasses five key dimensions: 1) What is being\nevaluated?; 2) How is the evaluation conducted?; 3) Who is participating in the\nevaluation?; 4) When is evaluation conducted?; 5) How is evaluation validated?\nWe conduct a review of 39 human-AI systems using SPHERE, outlining current\nevaluation practices and areas for improvement. We provide three\nrecommendations for improving the validity and rigor of evaluation practices.",
      "tldr_zh": "该论文提出了一种名为 SPHERE 的评估卡，用于评估人类-AI 系统，以应对大型语言模型(LLMs)时代评估方法的挑战。SPHERE 涵盖五个关键维度：1) 评估的是什么？2) 评估如何进行？3) 谁参与评估？4) 评估何时进行？5) 评估如何验证？研究者审阅了 39 个人类-AI 系统，总结了当前评估实践的不足，并提供了三个改进建议，以提升评估的有效性和严谨性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07971v1",
      "published_date": "2025-03-24 20:17:20 UTC",
      "updated_date": "2025-03-24 20:17:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:27:39.811206"
    },
    {
      "arxiv_id": "2503.19120v1",
      "title": "Where is this coming from? Making groundedness count in the evaluation of Document VQA models",
      "title_zh": "翻译失败",
      "authors": [
        "Armineh Nourbakhsh",
        "Siddharth Parekh",
        "Pranav Shetty",
        "Zhao Jin",
        "Sameena Shah",
        "Carolyn Rose"
      ],
      "abstract": "Document Visual Question Answering (VQA) models have evolved at an impressive\nrate over the past few years, coming close to or matching human performance on\nsome benchmarks. We argue that common evaluation metrics used by popular\nbenchmarks do not account for the semantic and multimodal groundedness of a\nmodel's outputs. As a result, hallucinations and major semantic errors are\ntreated the same way as well-grounded outputs, and the evaluation scores do not\nreflect the reasoning capabilities of the model. In response, we propose a new\nevaluation methodology that accounts for the groundedness of predictions with\nregard to the semantic characteristics of the output as well as the multimodal\nplacement of the output within the input document. Our proposed methodology is\nparameterized in such a way that users can configure the score according to\ntheir preferences. We validate our scoring methodology using human judgment and\nshow its potential impact on existing popular leaderboards. Through extensive\nanalyses, we demonstrate that our proposed method produces scores that are a\nbetter indicator of a model's robustness and tends to give higher rewards to\nbetter-calibrated answers.",
      "tldr_zh": "这篇论文指出，现有的 Document VQA 模型评估指标忽略了模型输出的语义和多模态 groundedness，导致幻觉错误与正确输出被同等对待，无法真正反映模型的推理能力。作者提出了一种新的评估方法，该方法通过参数化设计来量化预测的语义特性和多模态位置上的 groundedness，允许用户根据偏好自定义评分。实验结果显示，这种方法经人类判断验证后，能更好地评估模型的鲁棒性，并为现有排行榜提供更可靠的排名指标。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL Findings 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.19120v1",
      "published_date": "2025-03-24 20:14:46 UTC",
      "updated_date": "2025-03-24 20:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:27:52.521808"
    },
    {
      "arxiv_id": "2503.19107v1",
      "title": "Information-Seeking Decision Strategies Mitigate Risk in Dynamic, Uncertain Environments",
      "title_zh": "寻求信息决策策略缓解动态不确定环境中的风险",
      "authors": [
        "Nicholas W. Barendregt",
        "Joshua I. Gold",
        "Krešimir Josić",
        "Zachary P. Kilpatrick"
      ],
      "abstract": "To survive in dynamic and uncertain environments, individuals must develop\neffective decision strategies that balance information gathering and decision\ncommitment. Models of such strategies often prioritize either optimizing\ntangible payoffs, like reward rate, or gathering information to support a\ndiversity of (possibly unknown) objectives. However, our understanding of the\nrelative merits of these two approaches remains incomplete, in part because\ndirect comparisons have been limited to idealized, static environments that\nlack the dynamic complexity of the real world. Here we compared the performance\nof normative reward- and information-seeking strategies in a dynamic foraging\ntask. Both strategies show similar transitions between exploratory and\nexploitative behaviors as environmental uncertainty changes. However, we find\nsubtle disparities in the actions they take, resulting in meaningful\nperformance differences: whereas reward-seeking strategies generate slightly\nmore reward on average, information-seeking strategies provide more consistent\nand predictable outcomes. Our findings support the adaptive value of\ninformation-seeking behaviors that can mitigate risk with minimal reward loss.",
      "tldr_zh": "本研究探讨了在动态、不确定环境中，information-seeking 决策策略如何与 reward-seeking 策略相比，更好地平衡信息收集和决策承诺，以缓解风险。研究者通过一个 dynamic foraging task 进行实验，发现两种策略在环境不确定性变化时，都表现出从 exploratory 到 exploitative 行为的转变。结果显示，reward-seeking 策略平均产生更多 reward，但 information-seeking 策略提供更一致、可预测的结果，从而在最小化 reward loss 的情况下，支持其在风险管理中的适应价值。",
      "categories": [
        "cs.AI",
        "math.PR",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19107v1",
      "published_date": "2025-03-24 19:55:41 UTC",
      "updated_date": "2025-03-24 19:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:28:04.341863"
    },
    {
      "arxiv_id": "2503.21801v1",
      "title": "Efficient Joint Prediction of Multiple Future Tokens",
      "title_zh": "高效联合预测多个未来标记",
      "authors": [
        "Kwangjun Ahn",
        "Alex Lamb",
        "John Langford"
      ],
      "abstract": "In this short report, we introduce joint multi-token prediction (JTP), a\nlightweight modification of standard next-token prediction designed to enrich\nhidden state representations by jointly predicting multiple future tokens.\nUnlike previous multi-token prediction approaches, JTP strategically employs\nteacher forcing of future-tokens through a carefully designed representation\nbottleneck, allowing the model to encode rich predictive information with\nminimal computational overhead during training. We show that the JTP approach\nachieves a short-horizon belief state representation, while popular\nalternatives for multi-token prediction fail to do so. We demonstrate the\neffectiveness of our method on the synthetic star graph navigation task from\nfrom Bachmann and Nagarajan [2024], highlighting a significant performance\nimprovement over existing methods. This manuscript presents promising\npreliminary results intended to stimulate further research.",
      "tldr_zh": "该论文提出了一种名为 JTP（Joint Multi-Token Prediction）的轻量级方法，用于改进标准 next-token prediction，通过联合预测多个未来 tokens 来丰富隐藏状态表示。JTP 采用 teacher forcing 和精心设计的 representation bottleneck，确保模型在训练时以最小计算开销编码丰富的预测信息，同时实现短视野 belief state representation。实验结果显示，在 Bachmann and Nagarajan [2024] 的合成星形图导航任务上，JTP 比现有方法显著提升性能，为未来多 tokens 预测研究提供了有前景的初步基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical report; comments welcome!",
      "pdf_url": "http://arxiv.org/pdf/2503.21801v1",
      "published_date": "2025-03-24 19:52:42 UTC",
      "updated_date": "2025-03-24 19:52:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:28:16.384815"
    },
    {
      "arxiv_id": "2503.19100v1",
      "title": "Anomaly Detection Using Computer Vision: A Comparative Analysis of Class Distinction and Performance Metrics",
      "title_zh": "使用计算机视觉的异常检测：类别区分",
      "authors": [
        "Md. Barkat Ullah Tusher",
        "Shartaz Khan Akash",
        "Amirul Islam Showmik"
      ],
      "abstract": "This paper showcases an experimental study on anomaly detection using\ncomputer vision. The study focuses on class distinction and performance\nevaluation, combining OpenCV with deep learning techniques while employing a\nTensorFlow-based convolutional neural network for real-time face recognition\nand classification. The system effectively distinguishes among three classes:\nauthorized personnel (admin), intruders, and non-human entities. A\nMobileNetV2-based deep learning model is utilized to optimize real-time\nperformance, ensuring high computational efficiency without compromising\naccuracy. Extensive dataset preprocessing, including image augmentation and\nnormalization, enhances the models generalization capabilities. Our analysis\ndemonstrates classification accuracies of 90.20% for admin, 98.60% for\nintruders, and 75.80% for non-human detection, while maintaining an average\nprocessing rate of 30 frames per second. The study leverages transfer learning,\nbatch normalization, and Adam optimization to achieve stable and robust\nlearning, and a comparative analysis of class differentiation strategies\nhighlights the impact of feature extraction techniques and training\nmethodologies. The results indicate that advanced feature selection and data\naugmentation significantly enhance detection performance, particularly in\ndistinguishing human from non-human scenes. As an experimental study, this\nresearch provides critical insights into optimizing deep learning-based\nsurveillance systems for high-security environments and improving the accuracy\nand efficiency of real-time anomaly detection.",
      "tldr_zh": "这篇论文通过实验研究使用计算机视觉进行异常检测，重点比较类别区分策略和性能指标。系统结合 OpenCV 和基于 TensorFlow 的 CNN 模型，实现对授权人员（admin）、入侵者（intruders）和非人类实体（non-human entities）的实时识别，并采用 MobileNetV2 优化模型以提升计算效率，同时通过图像增强和归一化提高泛化能力。实验结果显示，分类准确率分别为 admin 90.20%、intruders 98.60% 和 non-human 75.80%，平均处理速率达 30 帧/秒。该研究强调迁移学习、批量归一化和 Adam 优化等技术显著提升检测性能，为高安全环境下的深度学习监控系统提供了关键优化见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.19100v1",
      "published_date": "2025-03-24 19:36:47 UTC",
      "updated_date": "2025-03-24 19:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:28:29.456719"
    },
    {
      "arxiv_id": "2503.19092v1",
      "title": "Rankers, Judges, and Assistants: Towards Understanding the Interplay of LLMs in Information Retrieval Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Krisztian Balog",
        "Donald Metzler",
        "Zhen Qin"
      ],
      "abstract": "Large language models (LLMs) are increasingly integral to information\nretrieval (IR), powering ranking, evaluation, and AI-assisted content creation.\nThis widespread adoption necessitates a critical examination of potential\nbiases arising from the interplay between these LLM-based components. This\npaper synthesizes existing research and presents novel experiment designs that\nexplore how LLM-based rankers and assistants influence LLM-based judges. We\nprovide the first empirical evidence of LLM judges exhibiting significant bias\ntowards LLM-based rankers. Furthermore, we observe limitations in LLM judges'\nability to discern subtle system performance differences. Contrary to some\nprevious findings, our preliminary study does not find evidence of bias against\nAI-generated content. These results highlight the need for a more holistic view\nof the LLM-driven information ecosystem. To this end, we offer initial\nguidelines and a research agenda to ensure the reliable use of LLMs in IR\nevaluation.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）在信息检索（IR）中的互动，特别是LLM-based rankers、judges和assistants之间的潜在偏见问题。研究通过综合现有文献并设计新实验，提供了首个实证证据，表明LLM judges对LLM-based rankers存在显著偏见，同时LLM judges在辨别系统性能细微差异方面能力有限。结果显示，与先前研究相反，本文未发现对AI生成内容的偏见，并提出初始指南和研究议程，以确保LLMs在IR评估中的可靠应用。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19092v1",
      "published_date": "2025-03-24 19:24:40 UTC",
      "updated_date": "2025-03-24 19:24:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:28:40.613934"
    },
    {
      "arxiv_id": "2503.21800v1",
      "title": "ELM: Ensemble of Language Models for Predicting Tumor Group from Pathology Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Lovedeep Gondara",
        "Jonathan Simkin",
        "Shebnum Devji",
        "Gregory Arbour",
        "Raymond Ng"
      ],
      "abstract": "Population-based cancer registries (PBCRs) face a significant bottleneck in\nmanually extracting data from unstructured pathology reports, a process crucial\nfor tasks like tumor group assignment, which can consume 900 person-hours for\napproximately 100,000 reports. To address this, we introduce ELM (Ensemble of\nLanguage Models), a novel ensemble-based approach leveraging both small\nlanguage models (SLMs) and large language models (LLMs). ELM utilizes six\nfine-tuned SLMs, where three SLMs use the top part of the pathology report and\nthree SLMs use the bottom part. This is done to maximize report coverage. ELM\nrequires five-out-of-six agreement for a tumor group classification.\nDisagreements are arbitrated by an LLM with a carefully curated prompt. Our\nevaluation across nineteen tumor groups demonstrates ELM achieves an average\nprecision and recall of 0.94, outperforming single-model and\nensemble-without-LLM approaches. Deployed at the British Columbia Cancer\nRegistry, ELM demonstrates how LLMs can be successfully applied in a PBCR\nsetting to achieve state-of-the-art results and significantly enhance\noperational efficiencies, saving hundreds of person-hours annually.",
      "tldr_zh": "本研究提出 ELM（Ensemble of Language Models），一种集成小语言模型（SLMs）和大语言模型（LLMs）的框架，用于从非结构化病理报告中预测肿瘤组，旨在解决人口-based 癌症注册处（PBCRs）的手动数据提取瓶颈，该过程通常耗费大量人力（如处理10万报告需900人小时）。ELM 通过六个微调的 SLMs（其中三个处理报告上半部分，三个处理下半部分）来最大化覆盖，并要求五票同意进行分类，分歧由 LLM 通过精心设计的提示仲裁。实验结果显示，ELM 在19个肿瘤组上平均精确度和召回率达到0.94，优于单一模型和无 LLM 集成方法；在不列颠哥伦比亚癌症注册处部署后，显著提升了操作效率，每年节省数百人小时。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21800v1",
      "published_date": "2025-03-24 19:21:53 UTC",
      "updated_date": "2025-03-24 19:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:28:53.859258"
    },
    {
      "arxiv_id": "2503.19075v1",
      "title": "The Case for \"Thick Evaluations\" of Cultural Representation in AI",
      "title_zh": "人工智能中文化表征的“厚评估”的理由",
      "authors": [
        "Rida Qadri",
        "Mark Diaz",
        "Ding Wang",
        "Michael Madaio"
      ],
      "abstract": "Generative AI image models have been increasingly evaluated for their\n(in)ability to represent non-Western cultures. We argue that these evaluations\noperate through reductive ideals of representation, abstracted from how people\ndefine their own representation and neglecting the inherently interpretive and\ncontextual nature of cultural representation. In contrast to these 'thin'\nevaluations, we introduce the idea of 'thick evaluations': a more granular,\nsituated, and discursive measurement framework for evaluating representations\nof social worlds in AI images, steeped in communities' own understandings of\nrepresentation. We develop this evaluation framework through workshops in South\nAsia, by studying the 'thick' ways in which people interpret and assign meaning\nto images of their own cultures. We introduce practices for thicker evaluations\nof representation that expand the understanding of representation underpinning\nAI evaluations and by co-constructing metrics with communities, bringing\nmeasurement in line with the experiences of communities on the ground.",
      "tldr_zh": "这篇论文批评了现有对生成式 AI 图像模型在非西方文化表示方面的评估过于简化（thin evaluations），因为这些评估忽略了人们对自身文化表示的定义以及其解释性和语境性。作者提出“thick evaluations”框架，这是一种更细致、情境化和基于社区理解的测量方法，用于评估 AI 图像中社会世界的表示。论文通过在南亚举办的工作坊，与当地社区合作，探索人们如何解读和赋予自身文化图像意义，并共同构建指标，使评估更贴合实际体验，从而扩展 AI 领域对文化表示的理解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.19075v1",
      "published_date": "2025-03-24 19:01:14 UTC",
      "updated_date": "2025-03-24 19:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:29:04.419470"
    },
    {
      "arxiv_id": "2503.19074v1",
      "title": "HingeRLC-GAN: Combating Mode Collapse with Hinge Loss and RLC Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Osman Goni",
        "Himadri Saha Arka",
        "Mithun Halder",
        "Mir Moynuddin Ahmed Shibly",
        "Swakkhar Shatabda"
      ],
      "abstract": "Recent advances in Generative Adversarial Networks (GANs) have demonstrated\ntheir capability for producing high-quality images. However, a significant\nchallenge remains mode collapse, which occurs when the generator produces a\nlimited number of data patterns that do not reflect the diversity of the\ntraining dataset. This study addresses this issue by proposing a number of\narchitectural changes aimed at increasing the diversity and stability of GAN\nmodels. We start by improving the loss function with Wasserstein loss and\nGradient Penalty to better capture the full range of data variations. We also\ninvestigate various network architectures and conclude that ResNet\nsignificantly contributes to increased diversity. Building on these findings,\nwe introduce HingeRLC-GAN, a novel approach that combines RLC Regularization\nand the Hinge loss function. With a FID Score of 18 and a KID Score of 0.001,\nour approach outperforms existing methods by effectively balancing training\nstability and increased diversity.",
      "tldr_zh": "本研究针对生成对抗网络(GANs)中的模式崩溃(mode collapse)问题，提出了一系列架构改进以提升模型的多样性和稳定性，包括采用Wasserstein loss和Gradient Penalty来更好地捕捉数据变化，并发现ResNet架构有助于增加多样性。作者引入了HingeRLC-GAN，这是一种结合Hinge loss和RLC Regularization的新方法，能够有效平衡训练稳定性和生成多样性。在实验中，HingeRLC-GAN实现了FID Score为18和KID Score为0.001的优异性能，超越了现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19074v1",
      "published_date": "2025-03-24 19:00:28 UTC",
      "updated_date": "2025-03-24 19:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:29:16.544949"
    },
    {
      "arxiv_id": "2503.19070v2",
      "title": "Graph-Level Label-Only Membership Inference Attack against Graph Neural Networks",
      "title_zh": "针对图神经网络的图级别仅标签成员推断攻击",
      "authors": [
        "Jiazhu Dai",
        "Yubing Lu"
      ],
      "abstract": "Graph neural networks (GNNs) are widely used for graph-structured data but\nare vulnerable to membership inference attacks (MIAs) in graph classification\ntasks, which determine if a graph was part of the training dataset, potentially\ncausing data leakage. Existing MIAs rely on prediction probability vectors, but\nthey become ineffective when only prediction labels are available. We propose a\nGraph-level Label-Only Membership Inference Attack (GLO-MIA), which is based on\nthe intuition that the target model's predictions on training data are more\nstable than those on testing data. GLO-MIA generates a set of perturbed graphs\nfor target graph by adding perturbations to its effective features and queries\nthe target model with the perturbed graphs to get their prediction labels,\nwhich are then used to calculate robustness score of the target graph. Finally,\nby comparing the robustness score with a predefined threshold, the membership\nof the target graph can be inferred correctly with high probability. Our\nevaluation on three datasets and four GNN models shows that GLO-MIA achieves an\nattack accuracy of up to 0.825, outperforming baseline work by 8.5% and closely\nmatching the performance of probability-based MIAs, even with only prediction\nlabels.",
      "tldr_zh": "该研究提出了一种针对图神经网络（GNNs）的图级标签-only成员推理攻击（GLO-MIA），旨在在仅获得预测标签的情况下检测图数据是否属于训练集，从而解决现有MIAs依赖预测概率向量的局限性。GLO-MIA基于训练数据预测更稳定的直觉，通过为目标图生成扰动图、查询其预测标签并计算鲁棒性分数来推断成员身份。实验结果显示，在三个数据集和四个GNN模型上，GLO-MIA的攻击准确率高达0.825，比基线方法提高8.5%，性能接近基于概率的MIAs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19070v2",
      "published_date": "2025-03-24 18:55:02 UTC",
      "updated_date": "2025-03-26 06:48:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:29:28.404814"
    },
    {
      "arxiv_id": "2503.19068v1",
      "title": "Minimum Volume Conformal Sets for Multivariate Regression",
      "title_zh": "最小体积保形集合用于多元回归",
      "authors": [
        "Sacha Braun",
        "Liviu Aolaritei",
        "Michael I. Jordan",
        "Francis Bach"
      ],
      "abstract": "Conformal prediction provides a principled framework for constructing\npredictive sets with finite-sample validity. While much of the focus has been\non univariate response variables, existing multivariate methods either impose\nrigid geometric assumptions or rely on flexible but computationally expensive\napproaches that do not explicitly optimize prediction set volume. We propose an\noptimization-driven framework based on a novel loss function that directly\nlearns minimum-volume covering sets while ensuring valid coverage. This\nformulation naturally induces a new nonconformity score for conformal\nprediction, which adapts to the residual distribution and covariates. Our\napproach optimizes over prediction sets defined by arbitrary norm balls,\nincluding single and multi-norm formulations. Additionally, by jointly\noptimizing both the predictive model and predictive uncertainty, we obtain\nprediction sets that are tight, informative, and computationally efficient, as\ndemonstrated in our experiments on real-world datasets.",
      "tldr_zh": "这项研究针对多变量回归中的 Conformal Prediction，提出了一种优化驱动的框架，使用新颖的损失函数来直接学习最小体积的覆盖集，同时确保有效的覆盖率。框架引入了一个适应残差分布和协变量的非一致性分数（nonconformity score），并优化基于任意范数球（包括单范数和多范数形式）的预测集。通过联合优化预测模型和预测不确定性，该方法在实际数据集实验中实现了紧凑、信息丰富且计算高效的预测集。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME",
        "stat.OT"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19068v1",
      "published_date": "2025-03-24 18:54:22 UTC",
      "updated_date": "2025-03-24 18:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:29:40.899008"
    },
    {
      "arxiv_id": "2504.08747v1",
      "title": "GridMind: A Multi-Agent NLP Framework for Unified, Cross-Modal NFL Data Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Chipka",
        "Chris Moyer",
        "Clay Troyer",
        "Tyler Fuelling",
        "Jeremy Hochstedler"
      ],
      "abstract": "The rapid growth of big data and advancements in computational techniques\nhave significantly transformed sports analytics. However, the diverse range of\ndata sources -- including structured statistics, semi-structured formats like\nsensor data, and unstructured media such as written articles, audio, and video\n-- creates substantial challenges in extracting actionable insights. These\nvarious formats, often referred to as multimodal data, require integration to\nfully leverage their potential. Conventional systems, which typically\nprioritize structured data, face limitations when processing and combining\nthese diverse content types, reducing their effectiveness in real-time sports\nanalysis.\n  To address these challenges, recent research highlights the importance of\nmultimodal data integration for capturing the complexity of real-world sports\nenvironments. Building on this foundation, this paper introduces GridMind, a\nmulti-agent framework that unifies structured, semi-structured, and\nunstructured data through Retrieval-Augmented Generation (RAG) and large\nlanguage models (LLMs) to facilitate natural language querying of NFL data.\nThis approach aligns with the evolving field of multimodal representation\nlearning, where unified models are increasingly essential for real-time,\ncross-modal interactions.\n  GridMind's distributed architecture includes specialized agents that\nautonomously manage each stage of a prompt -- from interpretation and data\nretrieval to response synthesis. This modular design enables flexible, scalable\nhandling of multimodal data, allowing users to pose complex, context-rich\nquestions and receive comprehensive, intuitive responses via a conversational\ninterface.",
      "tldr_zh": "这篇论文针对体育分析中多模态数据的整合挑战（如结构化统计、半结构化传感器数据和非结构化媒体），提出GridMind，这是一个多智能体NLP框架，利用Retrieval-Augmented Generation (RAG) 和大型语言模型 (LLMs) 来统一处理NFL数据。\nGridMind的分布式架构包括专门代理，负责提示解释、数据检索和响应合成，支持用户通过自然语言提出复杂查询并获得直观的对话式响应。\n这种模块化设计实现了灵活、可扩展的跨模态交互，有助于提升实时体育分析的有效性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 2 figures, submitted to 2025 Sloan Sports Analytics\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.08747v1",
      "published_date": "2025-03-24 18:33:36 UTC",
      "updated_date": "2025-03-24 18:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:29:53.143139"
    },
    {
      "arxiv_id": "2503.19050v1",
      "title": "Mist: Efficient Distributed Training of Large Language Models via Memory-Parallelism Co-Optimization",
      "title_zh": "Mist：通过内存并行性协同优化的高效大型语言模型分布式训练",
      "authors": [
        "Zhanda Zhu",
        "Christina Giannoula",
        "Muralidhar Andoorveedu",
        "Qidong Su",
        "Karttikeya Mangalam",
        "Bojian Zheng",
        "Gennady Pekhimenko"
      ],
      "abstract": "Various parallelism, such as data, tensor, and pipeline parallelism, along\nwith memory optimizations like activation checkpointing, redundancy\nelimination, and offloading, have been proposed to accelerate distributed\ntraining for Large Language Models. To find the best combination of these\ntechniques, automatic distributed training systems are proposed. However,\nexisting systems only tune a subset of optimizations, due to the lack of\noverlap awareness, inability to navigate the vast search space, and ignoring\nthe inter-microbatch imbalance, leading to sub-optimal performance. To address\nthese shortcomings, we propose Mist, a memory, overlap, and imbalance-aware\nautomatic distributed training system that comprehensively co-optimizes all\nmemory footprint reduction techniques alongside parallelism. Mist is based on\nthree key ideas: (1) fine-grained overlap-centric scheduling, orchestrating\noptimizations in an overlapped manner, (2) symbolic-based performance analysis\nthat predicts runtime and memory usage using symbolic expressions for fast\ntuning, and (3) imbalance-aware hierarchical tuning, decoupling the process\ninto an inter-stage imbalance and overlap aware Mixed Integer Linear\nProgramming problem and an intra-stage Dual-Objective Constrained Optimization\nproblem, and connecting them through Pareto frontier sampling. Our evaluation\nresults show that Mist achieves an average of 1.28$\\times$ (up to 1.73$\\times$)\nand 1.27$\\times$ (up to 2.04$\\times$) speedup compared to state-of-the-art\nmanual system Megatron-LM and state-of-the-art automatic system Aceso,\nrespectively.",
      "tldr_zh": "本研究提出Mist系统，一种高效的分布式训练框架，通过内存和并行性协同优化（Memory-Parallelism Co-Optimization），来加速Large Language Models的训练。Mist解决了现有系统的局限性，包括缺乏overlap意识、搜索空间导航困难和忽略inter-microbatch imbalance问题，采用三项关键策略：fine-grained overlap-centric scheduling、symbolic-based性能分析，以及imbalance-aware hierarchical tuning，以全面优化内存占用减少技术和并行性。实验结果显示，Mist相对于state-of-the-art手动系统Megatron-LM平均实现1.28倍加速（最高1.73倍），并相对于自动系统Aceso平均实现1.27倍加速（最高2.04倍），显著提升了训练效率。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by EuroSys 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.19050v1",
      "published_date": "2025-03-24 18:21:08 UTC",
      "updated_date": "2025-03-24 18:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:30:05.615450"
    },
    {
      "arxiv_id": "2503.19048v1",
      "title": "Forecasting Labor Demand: Predicting JOLT Job Openings using Deep Learning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungsu Kim"
      ],
      "abstract": "This thesis studies the effectiveness of Long Short Term Memory model in\nforecasting future Job Openings and Labor Turnover Survey data in the United\nStates. Drawing on multiple economic indicators from various sources, the data\nare fed directly into LSTM model to predict JOLT job openings in subsequent\nperiods. The performance of the LSTM model is compared with conventional\nautoregressive approaches, including ARIMA, SARIMA, and Holt-Winters. Findings\nsuggest that the LSTM model outperforms these traditional models in predicting\nJOLT job openings, as it not only captures the dependent variables trends but\nalso harmonized with key economic factors. These results highlight the\npotential of deep learning techniques in capturing complex temporal\ndependencies in economic data, offering valuable insights for policymakers and\nstakeholders in developing data-driven labor market strategies",
      "tldr_zh": "本研究评估了Long Short Term Memory (LSTM)模型在预测美国JOLT（Job Openings and Labor Turnover Survey）职位空缺的有效性，通过整合多种经济指标直接输入模型进行未来数据预测。论文将LSTM的表现与传统自回归模型如ARIMA、SARIMA和Holt-Winters进行比较，结果显示LSTM模型在捕捉变量趋势和经济因素方面表现出色，预测准确性更高。这些发现突出了深度学习技术在处理经济数据复杂时间依赖性上的潜力，为政策制定者和相关方提供数据驱动的劳动力市场策略指导。",
      "categories": [
        "econ.EM",
        "cs.AI"
      ],
      "primary_category": "econ.EM",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.19048v1",
      "published_date": "2025-03-24 18:19:33 UTC",
      "updated_date": "2025-03-24 18:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:30:17.022591"
    },
    {
      "arxiv_id": "2503.19041v1",
      "title": "LookAhead Tuning: Safer Language Models via Partial Answer Previews",
      "title_zh": "翻译失败",
      "authors": [
        "Kangwei Liu",
        "Mengru Wang",
        "Yujie Luo",
        "Lin Yuan",
        "Mengshu Sun",
        "Ningyu Zhang",
        "Lei Liang",
        "Zhiqiang Zhang",
        "Jun Zhou",
        "Huajun Chen"
      ],
      "abstract": "Fine-tuning enables large language models (LLMs) to adapt to specific\ndomains, but often undermines their previously established safety alignment. To\nmitigate the degradation of model safety during fine-tuning, we introduce\nLookAhead Tuning, which comprises two simple, low-resource, and effective\ndata-driven methods that modify training data by previewing partial answer\nprefixes. Both methods aim to preserve the model's inherent safety mechanisms\nby minimizing perturbations to initial token distributions. Comprehensive\nexperiments demonstrate that LookAhead Tuning effectively maintains model\nsafety without sacrificing robust performance on downstream tasks. Our findings\nposition LookAhead Tuning as a reliable and efficient solution for the safe and\neffective adaptation of LLMs. Code is released at\nhttps://github.com/zjunlp/LookAheadTuning.",
      "tldr_zh": "这篇论文针对 Fine-tuning 过程中大型语言模型 (LLMs) 的安全对齐退化问题，提出了 LookAhead Tuning 方法。该方法包括两个简单、低资源的基于数据的技术，通过预览部分答案前缀 (partial answer prefixes) 修改训练数据，以最小化对初始 token 分布的扰动，从而保留模型的固有安全机制。实验结果表明，LookAhead Tuning 能有效维持模型安全性，同时在下游任务上保持强劲性能，并已开源代码以供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.19041v1",
      "published_date": "2025-03-24 18:11:42 UTC",
      "updated_date": "2025-03-24 18:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:31:09.984193"
    },
    {
      "arxiv_id": "2503.19037v1",
      "title": "Evolutionary Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jianren Wang",
        "Yifan Su",
        "Abhinav Gupta",
        "Deepak Pathak"
      ],
      "abstract": "Despite its extreme sample inefficiency, on-policy reinforcement learning has\nbecome a fundamental tool in real-world applications. With recent advances in\nGPU-driven simulation, the ability to collect vast amounts of data for RL\ntraining has scaled exponentially. However, studies show that current on-policy\nmethods, such as PPO, fail to fully leverage the benefits of parallelized\nenvironments, leading to performance saturation beyond a certain scale. In\ncontrast, Evolutionary Algorithms (EAs) excel at increasing diversity through\nrandomization, making them a natural complement to RL. However, existing EvoRL\nmethods have struggled to gain widespread adoption due to their extreme sample\ninefficiency. To address these challenges, we introduce Evolutionary Policy\nOptimization (EPO), a novel policy gradient algorithm that combines the\nstrengths of EA and policy gradients. We show that EPO significantly improves\nperformance across diverse and challenging environments, demonstrating superior\nscalability with parallelized simulations.",
      "tldr_zh": "本研究针对 on-policy reinforcement learning（如 PPO）在样本效率上的不足，以及其无法充分利用并行模拟环境的性能饱和问题，提出了一种新型算法 Evolutionary Policy Optimization (EPO)。EPO 结合了 Evolutionary Algorithms (EAs) 的多样性优势和 policy gradients 的优化能力，旨在提升强化学习的整体表现。实验结果表明，EPO 在多样化和挑战性环境中显著提高了性能，并展示了出色的可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Website at https://sites.google.com/view/epo-rl",
      "pdf_url": "http://arxiv.org/pdf/2503.19037v1",
      "published_date": "2025-03-24 18:08:54 UTC",
      "updated_date": "2025-03-24 18:08:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:30:39.968944"
    },
    {
      "arxiv_id": "2503.18945v2",
      "title": "Aether: Geometric-Aware Unified World Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Aether Team",
        "Haoyi Zhu",
        "Yifan Wang",
        "Jianjun Zhou",
        "Wenzheng Chang",
        "Yang Zhou",
        "Zizun Li",
        "Junyi Chen",
        "Chunhua Shen",
        "Jiangmiao Pang",
        "Tong He"
      ],
      "abstract": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates unprecedented synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nRemarkably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.",
      "tldr_zh": "本论文提出 Aether 框架，这是一个统一的几何感知世界建模系统，通过联合优化 4D dynamic reconstruction、action-conditioned video prediction 和 goal-conditioned visual planning 等核心能力，实现任务交错特征学习并促进知识共享。Aether 基于视频生成模型，尽管训练时未接触真实世界数据，却实现了合成到真实世界的泛化，以及 zero-shot generalization 在动作跟随和重建任务中。实验结果显示，其重建性能即使没有真实数据，也可与或优于领域特定模型，并通过 camera trajectories 作为几何信息动作空间，支持有效的预测和视觉规划。该框架有望激发社区探索物理合理的世界建模及其应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://aether-world.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.18945v2",
      "published_date": "2025-03-24 17:59:51 UTC",
      "updated_date": "2025-03-25 15:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:30:53.422296"
    },
    {
      "arxiv_id": "2503.18942v2",
      "title": "Video-T1: Test-Time Scaling for Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Fangfu Liu",
        "Hanyang Wang",
        "Yimo Cai",
        "Kaiyan Zhang",
        "Xiaohang Zhan",
        "Yueqi Duan"
      ],
      "abstract": "With the scale capability of increasing training data, model size, and\ncomputational cost, video generation has achieved impressive results in digital\ncreation, enabling users to express creativity across various domains.\nRecently, researchers in Large Language Models (LLMs) have expanded the scaling\nto test-time, which can significantly improve LLM performance by using more\ninference-time computation. Instead of scaling up video foundation models\nthrough expensive training costs, we explore the power of Test-Time Scaling\n(TTS) in video generation, aiming to answer the question: if a video generation\nmodel is allowed to use non-trivial amount of inference-time compute, how much\ncan it improve generation quality given a challenging text prompt. In this\nwork, we reinterpret the test-time scaling of video generation as a searching\nproblem to sample better trajectories from Gaussian noise space to the target\nvideo distribution. Specifically, we build the search space with test-time\nverifiers to provide feedback and heuristic algorithms to guide searching\nprocess. Given a text prompt, we first explore an intuitive linear search\nstrategy by increasing noise candidates at inference time. As full-step\ndenoising all frames simultaneously requires heavy test-time computation costs,\nwe further design a more efficient TTS method for video generation called\nTree-of-Frames (ToF) that adaptively expands and prunes video branches in an\nautoregressive manner. Extensive experiments on text-conditioned video\ngeneration benchmarks demonstrate that increasing test-time compute\nconsistently leads to significant improvements in the quality of videos.\nProject page: https://liuff19.github.io/Video-T1",
      "tldr_zh": "这篇论文提出 Video-T1，一种 Test-Time Scaling (TTS) 方法，用于提升视频生成模型的性能，而非通过昂贵的训练扩展。作者将 TTS 重新定义为从高斯噪声空间采样到目标视频分布的搜索问题，并设计了线性搜索策略（通过增加噪声候选）和更高效的 Tree-of-Frames (ToF) 方法，以自回归方式自适应扩展和修剪视频分支，从而减少计算开销。实验在文本条件视频生成基准上表明，增加推理时计算可显著改善视频质量，提供了一个高效的视频生成优化途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://liuff19.github.io/Video-T1",
      "pdf_url": "http://arxiv.org/pdf/2503.18942v2",
      "published_date": "2025-03-24 17:59:04 UTC",
      "updated_date": "2025-04-01 06:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:31:16.172186"
    },
    {
      "arxiv_id": "2503.18938v3",
      "title": "AdaWorld: Learning Adaptable World Models with Latent Actions",
      "title_zh": "翻译失败",
      "authors": [
        "Shenyuan Gao",
        "Siyuan Zhou",
        "Yilun Du",
        "Jun Zhang",
        "Chuang Gan"
      ],
      "abstract": "World models aim to learn action-controlled future prediction and have proven\nessential for the development of intelligent agents. However, most existing\nworld models rely heavily on substantial action-labeled data and costly\ntraining, making it challenging to adapt to novel environments with\nheterogeneous actions through limited interactions. This limitation can hinder\ntheir applicability across broader domains. To overcome this limitation, we\npropose AdaWorld, an innovative world model learning approach that enables\nefficient adaptation. The key idea is to incorporate action information during\nthe pretraining of world models. This is achieved by extracting latent actions\nfrom videos in a self-supervised manner, capturing the most critical\ntransitions between frames. We then develop an autoregressive world model that\nconditions on these latent actions. This learning paradigm enables highly\nadaptable world models, facilitating efficient transfer and learning of new\nactions even with limited interactions and finetuning. Our comprehensive\nexperiments across multiple environments demonstrate that AdaWorld achieves\nsuperior performance in both simulation quality and visual planning.",
      "tldr_zh": "该论文提出AdaWorld，一种创新的世界模型学习方法，旨在解决现有world models对大量标记动作数据依赖的问题，从而实现高效适应新环境。核心思路是通过自监督方式从视频中提取latent actions，捕捉帧间关键过渡，并构建基于这些潜在动作的自回归world model，以支持有限互动下的快速转移和学习新动作。实验结果显示，AdaWorld在多个环境中表现出色，在模拟质量和视觉规划方面优于基线模型。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2025. Project page: https://adaptable-world-model.github.io/,\n  code: https://github.com/Little-Podi/AdaWorld, model:\n  https://huggingface.co/Little-Podi/AdaWorld",
      "pdf_url": "http://arxiv.org/pdf/2503.18938v3",
      "published_date": "2025-03-24 17:58:15 UTC",
      "updated_date": "2025-05-14 10:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:31:27.743911"
    },
    {
      "arxiv_id": "2503.18899v1",
      "title": "Statistical Proof of Execution (SPEX)",
      "title_zh": "统计执行证明 (SPEX)",
      "authors": [
        "Michele Dallachiesa",
        "Antonio Pitasi",
        "David Pinger",
        "Josh Goodbody",
        "Luis Vaello"
      ],
      "abstract": "Many real-world applications are increasingly incorporating automated\ndecision-making, driven by the widespread adoption of ML/AI inference for\nplanning and guidance. This study examines the growing need for verifiable\ncomputing in autonomous decision-making. We formalize the problem of verifiable\ncomputing and introduce a sampling-based protocol that is significantly faster,\nmore cost-effective, and simpler than existing methods. Furthermore, we tackle\nthe challenges posed by non-determinism, proposing a set of strategies to\neffectively manage common scenarios.",
      "tldr_zh": "该研究探讨了自动化决策中对可验证计算(verifiable computing)的需求，特别是在ML/AI推理应用中，并形式化了这一问题。作者引入了一种基于采样的sampling-based protocol，比现有方法更快、更经济且更简单，以实现高效的证明执行(Statistical Proof of Execution, SPEX)。此外，该协议还通过一组策略有效处理非确定性(non-determinism)挑战，提升了自主决策系统的可靠性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18899v1",
      "published_date": "2025-03-24 17:13:25 UTC",
      "updated_date": "2025-03-24 17:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:31:39.557088"
    },
    {
      "arxiv_id": "2503.18892v2",
      "title": "SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Zeng",
        "Yuzhen Huang",
        "Qian Liu",
        "Wei Liu",
        "Keqing He",
        "Zejun Ma",
        "Junxian He"
      ],
      "abstract": "DeepSeek-R1 has shown that long chain-of-thought (CoT) reasoning can\nnaturally emerge through a simple reinforcement learning (RL) framework with\nrule-based rewards, where the training may directly start from the base\nmodels-a paradigm referred to as zero RL training. Most recent efforts to\nreproduce zero RL training have primarily focused on the Qwen2.5 model series,\nwhich may not be representative as we find the base models already exhibit\nstrong instruction-following and self-reflection abilities. In this work, we\ninvestigate zero RL training across 10 diverse base models, spanning different\nfamilies and sizes including LLama3-8B, Mistral-7B/24B, DeepSeek-Math-7B,\nQwen2.5-math-7B, and all Qwen2.5 models from 0.5B to 32B. Leveraging several\nkey design strategies-such as adjusting format reward and controlling query\ndifficulty-we achieve substantial improvements in both reasoning accuracy and\nresponse length across most settings. However, by carefully monitoring the\ntraining dynamics, we observe that different base models exhibit distinct\npatterns during training. For instance, the increased response length does not\nalways correlate with the emergence of certain cognitive behaviors such as\nverification (i.e., the \"aha moment\"). Notably, we observe the \"aha moment\" for\nthe first time in small models not from the Qwen family. We share the key\ndesigns that enable successful zero RL training, along with our findings and\npractices. To facilitate further research, we open-source the code, models, and\nanalysis tools.",
      "tldr_zh": "本文研究了零强化学习（Zero Reinforcement Learning）在10个不同系列和大小的基础模型（如Llama3-8B、Mistral-7B/24B和Qwen2.5系列）上的应用，旨在解决其在野外环境的训练挑战。研究者通过关键策略，如调整格式奖励和控制查询难度，显著提升了模型的推理准确性和响应长度，但观察到不同模型的训练模式存在差异，例如响应长度增加不一定伴随认知行为如“aha moment”的出现。值得注意的是，本文首次在非Qwen系列的小模型中捕捉到“aha moment”。为了促进进一步研究，作者开源了代码、模型和分析工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18892v2",
      "published_date": "2025-03-24 17:06:10 UTC",
      "updated_date": "2025-05-07 09:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:31:54.032161"
    },
    {
      "arxiv_id": "2503.18891v1",
      "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhexuan Wang",
        "Yutong Wang",
        "Xuebo Liu",
        "Liang Ding",
        "Miao Zhang",
        "Jie Liu",
        "Min Zhang"
      ],
      "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have\ndemonstrated significant potential in collaborative problem-solving. However,\nthey still face substantial challenges of low communication efficiency and\nsuboptimal task performance, making the careful design of the agents'\ncommunication topologies particularly important. Inspired by the management\ntheory that roles in an efficient team are often dynamically adjusted, we\npropose AgentDropout, which identifies redundant agents and communication\nacross different communication rounds by optimizing the adjacency matrices of\nthe communication graphs and eliminates them to enhance both token efficiency\nand task performance. Compared to state-of-the-art methods, AgentDropout\nachieves an average reduction of 21.6% in prompt token consumption and 18.4% in\ncompletion token consumption, along with a performance improvement of 1.14 on\nthe tasks. Furthermore, the extended experiments demonstrate that AgentDropout\nachieves notable domain transferability and structure robustness, revealing its\nreliability and effectiveness. We release our code at\nhttps://github.com/wangzx1219/AgentDropout.",
      "tldr_zh": "该论文提出 AgentDropout 方法，用于优化基于大型语言模型 (LLMs) 的多智能体系统 (MAS)，通过动态识别并消除冗余智能体和通信来提升 token 效率和任务性能。AgentDropout 受管理理论启发，优化通信图的邻接矩阵，确保高效的协作问题解决。与最先进方法相比，它平均减少 21.6% 的提示 token 消耗和 18.4% 的完成 token 消耗，同时提高任务性能 1.14。扩展实验进一步证明了 AgentDropout 在领域转移性和结构鲁棒性方面的可靠性和有效性，并开源了代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18891v1",
      "published_date": "2025-03-24 17:04:55 UTC",
      "updated_date": "2025-03-24 17:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:32:05.440145"
    },
    {
      "arxiv_id": "2504.01973v1",
      "title": "Universally applicable and tunable graph-based coarse-graining for Machine learning force fields",
      "title_zh": "翻译失败",
      "authors": [
        "Christoph Brunken",
        "Sebastien Boyer",
        "Mustafa Omar",
        "Martin Maarand",
        "Olivier Peltre",
        "Solal Attias",
        "Bakary N'tji Diallo",
        "Anastasia Markina",
        "Olaf Othersen",
        "Oliver Bent"
      ],
      "abstract": "Coarse-grained (CG) force field methods for molecular systems are a crucial\ntool to simulate large biological macromolecules and are therefore essential\nfor characterisations of biomolecular systems. While state-of-the-art deep\nlearning (DL)-based models for all-atom force fields have improved immensely\nover recent years, we observe and analyse significant limitations of the\ncurrently available approaches for DL-based CG simulations. In this work, we\npresent the first transferable DL-based CG force field approach (i.e., not\nspecific to only one narrowly defined system type) applicable to a wide range\nof biosystems. To achieve this, our CG algorithm does not rely on hard-coded\nrules and is tuned to output coarse-grained systems optimised for minimal\nstatistical noise in the ground truth CG forces, which results in significant\nimprovement of model training. Our force field model is also the first CG\nvariant that is based on the MACE architecture and is trained on a custom\ndataset created by a new approach based on the fragmentation of large\nbiosystems covering protein, RNA and lipid chemistry. We demonstrate that our\nmodel can be applied in molecular dynamics simulations to obtain stable and\nqualitatively accurate trajectories for a variety of systems, while also\ndiscussing cases for which we observe limited reliability.",
      "tldr_zh": "本研究提出了一种通用且可调的基于图的粗粒化（CG）算法，用于机器学习力场（Machine learning force fields），旨在解决现有深度学习（DL）基于CG模拟方法的局限性，如系统特定性和训练噪声问题。该算法不依赖硬编码规则，而是优化输出以最小化CG力的统计噪声，从而显著提升模型训练效率，并首次基于MACE架构训练于一个自定义数据集，该数据集通过大生物系统的碎片化创建，覆盖蛋白质、RNA和脂质化学。实验结果显示，该模型在分子动力学模拟中可获得稳定且定性准确的轨迹，适用于多种生物系统，但也存在某些情况下可靠性有限的情况。",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01973v1",
      "published_date": "2025-03-24 16:55:53 UTC",
      "updated_date": "2025-03-24 16:55:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:32:16.577124"
    },
    {
      "arxiv_id": "2503.18871v2",
      "title": "Bootstrapped Model Predictive Control",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Wang",
        "Hanwei Guo",
        "Sizhe Wang",
        "Long Qian",
        "Xuguang Lan"
      ],
      "abstract": "Model Predictive Control (MPC) has been demonstrated to be effective in\ncontinuous control tasks. When a world model and a value function are\navailable, planning a sequence of actions ahead of time leads to a better\npolicy. Existing methods typically obtain the value function and the\ncorresponding policy in a model-free manner. However, we find that such an\napproach struggles with complex tasks, resulting in poor policy learning and\ninaccurate value estimation. To address this problem, we leverage the strengths\nof MPC itself. In this work, we introduce Bootstrapped Model Predictive Control\n(BMPC), a novel algorithm that performs policy learning in a bootstrapped\nmanner. BMPC learns a network policy by imitating an MPC expert, and in turn,\nuses this policy to guide the MPC process. Combined with model-based\nTD-learning, our policy learning yields better value estimation and further\nboosts the efficiency of MPC. We also introduce a lazy reanalyze mechanism,\nwhich enables computationally efficient imitation learning. Our method achieves\nsuperior performance over prior works on diverse continuous control tasks. In\nparticular, on challenging high-dimensional locomotion tasks, BMPC\nsignificantly improves data efficiency while also enhancing asymptotic\nperformance and training stability, with comparable training time and smaller\nnetwork sizes. Code is available at https://github.com/wertyuilife2/bmpc.",
      "tldr_zh": "该论文提出 Bootstrapped Model Predictive Control (BMPC)，一种新算法，用于提升 Model Predictive Control (MPC) 在复杂连续控制任务中的表现。BMPC 通过模仿 MPC 专家学习网络策略，并利用该策略指导 MPC 过程，同时结合模型-based TD-learning 来改善价值估计和整体效率；此外，引入 lazy reanalyze 机制以提高计算效率。实验结果显示，BMPC 在高维运动任务上显著提升数据效率、渐近性能和训练稳定性，与现有方法相比表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18871v2",
      "published_date": "2025-03-24 16:46:36 UTC",
      "updated_date": "2025-04-03 19:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:32:28.801461"
    },
    {
      "arxiv_id": "2503.18866v1",
      "title": "Reasoning to Learn from Latent Thoughts",
      "title_zh": "从潜在思维中学习的推理",
      "authors": [
        "Yangjun Ruan",
        "Neil Band",
        "Chris J. Maddison",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Compute scaling for language model (LM) pretraining has outpaced the growth\nof human-written texts, leading to concerns that data will become the\nbottleneck to LM scaling. To continue scaling pretraining in this\ndata-constrained regime, we propose that explicitly modeling and inferring the\nlatent thoughts that underlie the text generation process can significantly\nimprove pretraining data efficiency. Intuitively, our approach views web text\nas the compressed final outcome of a verbose human thought process and that the\nlatent thoughts contain important contextual knowledge and reasoning steps that\nare critical to data-efficient learning. We empirically demonstrate the\neffectiveness of our approach through data-constrained continued pretraining\nfor math. We first show that synthetic data approaches to inferring latent\nthoughts significantly improve data efficiency, outperforming training on the\nsame amount of raw data (5.7\\% $\\rightarrow$ 25.4\\% on MATH). Furthermore, we\ndemonstrate latent thought inference without a strong teacher, where an LM\nbootstraps its own performance by using an EM algorithm to iteratively improve\nthe capability of the trained LM and the quality of thought-augmented\npretraining data. We show that a 1B LM can bootstrap its performance across at\nleast three iterations and significantly outperform baselines trained on raw\ndata, with increasing gains from additional inference compute when performing\nthe E-step. The gains from inference scaling and EM iterations suggest new\nopportunities for scaling data-constrained pretraining.",
      "tldr_zh": "该论文探讨了在数据短缺环境下提升语言模型（LM）预训练效率的问题，提出通过显式建模和推断潜在想法（latent thoughts）来捕捉文本生成背后的上下文知识和推理步骤，从而提高数据利用率。实验在数学任务上证明了该方法的有效性，使用合成数据推断latent thoughts后，模型在MATH数据集上的性能从5.7%提升至25.4%，显著优于原始数据训练。进一步，该方法无需强教师，通过EM算法让LM迭代自举性能，实现至少三轮迭代提升，并在增加推理计算时获得更多收益，为数据受限的LM预训练提供了新机遇。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18866v1",
      "published_date": "2025-03-24 16:41:23 UTC",
      "updated_date": "2025-03-24 16:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:32:40.558988"
    },
    {
      "arxiv_id": "2503.18865v3",
      "title": "Structuring Scientific Innovation: A Framework for Modeling and Discovering Impactful Knowledge Combinations",
      "title_zh": "结构化科学创新：用于建模和发现影响深远的知识组合框架",
      "authors": [
        "Junlan Chen",
        "Kexin Zhang",
        "Daifeng Li",
        "Yangyang Feng",
        "Yuxuan Zhang",
        "Bowen Deng"
      ],
      "abstract": "The emergence of large language models offers new possibilities for\nstructured exploration of scientific knowledge. Rather than viewing scientific\ndiscovery as isolated ideas or content, we propose a structured approach that\nemphasizes the role of method combinations in shaping disruptive insights.\nSpecifically, we investigate how knowledge unit--especially those tied to\nmethodological design--can be modeled and recombined to yield research\nbreakthroughs. Our proposed framework addresses two key challenges. First, we\nintroduce a contrastive learning-based mechanism to identify distinguishing\nfeatures of historically disruptive method combinations within problem-driven\ncontexts. Second, we propose a reasoning-guided Monte Carlo search algorithm\nthat leverages the chain-of-thought capability of LLMs to identify promising\nknowledge recombinations for new problem statements.Empirical studies across\nmultiple domains show that the framework is capable of modeling the structural\ndynamics of innovation and successfully highlights combinations with high\ndisruptive potential. This research provides a new path for computationally\nguided scientific ideation grounded in structured reasoning and historical data\nmodeling.",
      "tldr_zh": "本研究提出一个框架，用于结构化科学创新，通过建模和发现影响力的知识组合，强调方法组合在产生突破性洞见中的作用。框架首先采用对比学习（contrastive learning）机制来识别历史破坏性方法组合的特征，其次利用大型语言模型（LLMs）的链式思维（chain-of-thought）能力，结合推理引导的 Monte Carlo 搜索算法，为新问题发现有潜力的知识重组。实证研究在多个领域验证了该框架，能有效模拟创新的结构动态，并突出高破坏潜力的组合，为基于计算的科学构想提供新的路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18865v3",
      "published_date": "2025-03-24 16:41:17 UTC",
      "updated_date": "2025-04-14 14:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:32:52.461128"
    },
    {
      "arxiv_id": "2503.18862v1",
      "title": "Exploring the Integration of Key-Value Attention Into Pure and Hybrid Transformers for Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "DeShin Hwa",
        "Tobias Holmes",
        "Klaus Drechsler"
      ],
      "abstract": "While CNNs were long considered state of the art for image processing, the\nintroduction of Transformer architectures has challenged this position. While\nachieving excellent results in image classification and segmentation,\nTransformers remain inherently reliant on large training datasets and remain\ncomputationally expensive. A newly introduced Transformer derivative named KV\nTransformer shows promising results in synthetic, NLP, and image classification\ntasks, while reducing complexity and memory usage. This is especially conducive\nto use cases where local inference is required, such as medical screening\napplications. We endeavoured to further evaluate the merit of KV Transformers\non semantic segmentation tasks, specifically in the domain of medical imaging.\nBy directly comparing traditional and KV variants of the same base\narchitectures, we provide further insight into the practical tradeoffs of\nreduced model complexity. We observe a notable reduction in parameter count and\nmultiply accumulate operations, while achieving similar performance from most\nof the KV variant models when directly compared to their QKV implementation.",
      "tldr_zh": "这篇论文探讨了将 Key-Value Attention 整合到纯和混合 Transformer 中的应用，以提升语义分割任务的效率。研究者通过直接比较传统 Transformer 和其 KV 变体，评估了在医疗成像领域的性能表现，结果显示 KV 变体显著降低了参数数量和乘积累加操作，同时在大多数情况下保持了与 QKV 实现相似的准确率。该工作为计算资源受限的场景，如医疗筛查，提供了一个更实用的 Transformer 替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 3 figures, Preprint. Final version published in:\n  Bildverarbeitung f\\\"ur die Medizin 2025, Springer. DOI:\n  https://doi.org/10.1007/978-3-658-47422-5_71",
      "pdf_url": "http://arxiv.org/pdf/2503.18862v1",
      "published_date": "2025-03-24 16:38:31 UTC",
      "updated_date": "2025-03-24 16:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:33:04.530793"
    },
    {
      "arxiv_id": "2503.19933v1",
      "title": "Role of AI Innovation, Clean Energy and Digital Economy towards Net Zero Emission in the United States: An ARDL Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Adita Sultana",
        "Abdullah Al Abrar Chowdhury",
        "Azizul Hakim Rafi",
        "Abdulla All Noman"
      ],
      "abstract": "The current paper investigates the influences of AI innovation, GDP growth,\nrenewable energy utilization, the digital economy, and industrialization on CO2\nemissions in the USA from 1990 to 2022, incorporating the ARDL methodology. The\noutcomes observe that AI innovation, renewable energy usage, and the digital\neconomy reduce CO2 emissions, while GDP expansion and industrialization\nintensify ecosystem damage. Unit root tests (ADF, PP, and DF-GLS) reveal\nheterogeneous integration levels amongst components, ensuring robustness in the\nARDL analysis. Complementary methods (FMOLS, DOLS, and CCR) validate the\nresults, enhancing their reliability. Pairwise Granger causality assessments\nidentify strong unidirectional connections within CO2 emissions and AI\ninnovation, as well as the digital economy, underscoring their significant\nroles in ecological sustainability. This research highlights the requirement\nfor strategic actions to nurture equitable growth, including advancements in AI\ntechnology, green energy adoption, and environmentally conscious industrial\ndevelopment, to improve environmental quality in the United States.",
      "tldr_zh": "本研究使用ARDL方法分析了1990-2022年间AI innovation、GDP增长、renewable energy利用、digital economy和industrialization对美国CO2排放的影响。结果显示，AI innovation、renewable energy和digital economy有助于减少CO2排放，而GDP增长和industrialization则会增加排放。单位根测试（包括ADF、PP和DF-GLS）及补充方法（如FMOLS、DOLS和CCR）验证了这些发现，并通过Granger因果关系测试确认了CO2排放与AI innovation及digital economy之间的单向联系。该研究强调，需要采取战略措施，如推动AI技术进步、推广绿色能源和可持续工业发展，以实现美国的净零排放目标。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "24 pages, 8 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.19933v1",
      "published_date": "2025-03-24 16:32:24 UTC",
      "updated_date": "2025-03-24 16:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:33:16.934984"
    },
    {
      "arxiv_id": "2503.18854v2",
      "title": "MC-LLaVA: Multi-Concept Personalized Vision-Language Model",
      "title_zh": "MC-LLaVA：多概念个性化视觉语言模型",
      "authors": [
        "Ruichuan An",
        "Sihan Yang",
        "Ming Lu",
        "Renrui Zhang",
        "Kai Zeng",
        "Yulin Luo",
        "Jiajun Cao",
        "Hao Liang",
        "Ying Chen",
        "Qi She",
        "Shanghang Zhang",
        "Wentao Zhang"
      ],
      "abstract": "Current vision-language models (VLMs) show exceptional abilities across\ndiverse tasks, such as visual question answering. To enhance user experience,\nrecent studies investigate VLM personalization to understand user-provided\nconcepts. However, they mainly focus on single-concept personalization,\nneglecting the existence and interplay of multiple concepts, which limits\nreal-world applicability. This paper proposes the first multi-concept\npersonalization paradigm, MC-LLaVA. Specifically, MC-LLaVA employs a\nmulti-concept instruction tuning strategy, effectively integrating multiple\nconcepts in a single training step. To reduce the costs related to joint\ntraining, we propose a personalized textual prompt that uses visual token\ninformation to initialize concept tokens. Additionally, we introduce a\npersonalized visual prompt during inference, aggregating location confidence\nmaps for enhanced recognition and grounding capabilities. To advance\nmulti-concept personalization research, we further contribute a high-quality\ninstruction tuning dataset. We carefully collect images with multiple\ncharacters and objects from movies and manually generate question-answer\nsamples for multi-concept scenarios, featuring superior diversity.\nComprehensive qualitative and quantitative experiments demonstrate that\nMC-LLaVA can achieve impressive multi-concept personalized responses, paving\nthe way for VLMs to become better user-specific assistants. The code and\ndataset will be publicly available at https://github.com/arctanxarc/MC-LLaVA}.",
      "tldr_zh": "本文提出 MC-LLaVA，一种多概念个性化视觉语言模型（VLM），旨在解决现有模型主要关注单概念而忽略多概念交互的局限性。该模型采用多概念指令微调策略，并在单个训练步骤中整合多个概念，同时通过个性化文本提示（使用视觉标记初始化概念标记）和视觉提示（聚合位置置信度地图）来降低训练成本并提升识别及 grounding 能力。为推进研究，他们构建了一个高质量指令调优数据集，从电影图像中收集多角色和对象，并生成多样化的问答样本。实验结果表明，MC-LLaVA 在多概念场景中实现出色的个性化响应，为 VLM 成为更高效的用户特定助手铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "I sincerely apologize for any inconvenience caused. We actually\n  uploaded this paper to arXiv in November 2024, as arXiv:2411.11706. During\n  this update, we did not consider the replacement operation of arXiv, which\n  led to duplicate submissions. We have made modifications at the original\n  address arXiv:2411.11706",
      "pdf_url": "http://arxiv.org/pdf/2503.18854v2",
      "published_date": "2025-03-24 16:32:17 UTC",
      "updated_date": "2025-03-25 13:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:33:29.668186"
    },
    {
      "arxiv_id": "2503.18852v1",
      "title": "Self-Organizing Graph Reasoning Evolves into a Critical State for Continuous Discovery Through Structural-Semantic Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Markus J. Buehler"
      ],
      "abstract": "We report fundamental insights into how agentic graph reasoning systems\nspontaneously evolve toward a critical state that sustains continuous semantic\ndiscovery. By rigorously analyzing structural (Von Neumann graph entropy) and\nsemantic (embedding) entropy, we identify a subtle yet robust regime in which\nsemantic entropy persistently dominates over structural entropy. This interplay\nis quantified by a dimensionless Critical Discovery Parameter that stabilizes\nat a small negative value, indicating a consistent excess of semantic entropy.\nEmpirically, we observe a stable fraction (12%) of \"surprising\" edges, links\nbetween semantically distant concepts, providing evidence of long-range or\ncross-domain connections that drive continuous innovation. Concomitantly, the\nsystem exhibits scale-free and small-world topological features, alongside a\nnegative cross-correlation between structural and semantic measures,\nreinforcing the analogy to self-organized criticality. These results establish\nclear parallels with critical phenomena in physical, biological, and cognitive\ncomplex systems, revealing an entropy-based principle governing adaptability\nand continuous innovation. Crucially, semantic richness emerges as the\nunderlying driver of sustained exploration, despite not being explicitly used\nby the reasoning process. Our findings provide interdisciplinary insights and\npractical strategies for engineering intelligent systems with intrinsic\ncapacities for long-term discovery and adaptation, and offer insights into how\nmodel training strategies can be developed that reinforce critical discovery.",
      "tldr_zh": "本研究探讨了代理图推理系统如何通过结构-语义动态自发演化到临界状态，实现持续语义发现。研究通过分析 Von Neumann graph entropy（结构熵）和 semantic entropy（语义熵），识别出语义熵主导的稳态，并引入 Critical Discovery Parameter（稳定在小负值），量化了语义熵的持续优势，同时观察到12%的“surprising” edges驱动创新。系统展现出 scale-free 和 small-world 拓扑特征，以及结构与语义措施的负相关，类似于 self-organized criticality的现象，为工程智能系统提供策略，以增强其长期发现和适应能力。",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cs.LG",
        "nlin.AO",
        "physics.app-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18852v1",
      "published_date": "2025-03-24 16:30:37 UTC",
      "updated_date": "2025-03-24 16:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:33:40.876025"
    },
    {
      "arxiv_id": "2503.18842v2",
      "title": "Three Kinds of AI Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Ratti"
      ],
      "abstract": "There is an overwhelming abundance of works in AI Ethics. This growth is\nchaotic because of how sudden it is, its volume, and its multidisciplinary\nnature. This makes difficult to keep track of debates, and to systematically\ncharacterize goals, research questions, methods, and expertise required by AI\nethicists. In this article, I show that the relation between AI and ethics can\nbe characterized in at least three ways, which correspond to three\nwell-represented kinds of AI ethics: ethics and AI; ethics in AI; ethics of AI.\nI elucidate the features of these three kinds of AI Ethics, characterize their\nresearch questions, and identify the kind of expertise that each kind needs. I\nalso show how certain criticisms to AI ethics are misplaced, as being done from\nthe point of view of one kind of AI ethics, to another kind with different\ngoals. All in all, this work sheds light on the nature of AI ethics, and sets\nthe groundwork for more informed discussions about the scope, methods, and\ntraining of AI ethicists.",
      "tldr_zh": "该论文分析了AI伦理领域的混乱现状，并将AI与伦理的关系分为三种类型：ethics and AI、ethics in AI和ethics of AI。每种类型具有独特的特征、研究问题和所需的专业知识，例如ethics and AI关注AI对伦理的影响，而ethics of AI则探讨AI本身的道德问题。论文澄清了某些对AI伦理的批评往往因视角差异而失当，并为更系统化的AI伦理讨论奠定基础，包括方法和从业者培训的指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, two figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18842v2",
      "published_date": "2025-03-24 16:15:03 UTC",
      "updated_date": "2025-03-26 09:03:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:33:51.972048"
    },
    {
      "arxiv_id": "2503.18836v1",
      "title": "Dual-domain Multi-path Self-supervised Diffusion Model for Accelerated MRI Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Zhang",
        "Jinkui Hao",
        "Bo Zhou"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a vital diagnostic tool, but its\ninherently long acquisition times reduce clinical efficiency and patient\ncomfort. Recent advancements in deep learning, particularly diffusion models,\nhave improved accelerated MRI reconstruction. However, existing diffusion\nmodels' training often relies on fully sampled data, models incur high\ncomputational costs, and often lack uncertainty estimation, limiting their\nclinical applicability. To overcome these challenges, we propose a novel\nframework, called Dual-domain Multi-path Self-supervised Diffusion Model\n(DMSM), that integrates a self-supervised dual-domain diffusion model training\nscheme, a lightweight hybrid attention network for the reconstruction diffusion\nmodel, and a multi-path inference strategy, to enhance reconstruction accuracy,\nefficiency, and explainability. Unlike traditional diffusion-based models, DMSM\neliminates the dependency on training from fully sampled data, making it more\npractical for real-world clinical settings. We evaluated DMSM on two human MRI\ndatasets, demonstrating that it achieves favorable performance over several\nsupervised and self-supervised baselines, particularly in preserving fine\nanatomical structures and suppressing artifacts under high acceleration\nfactors. Additionally, our model generates uncertainty maps that correlate\nreasonably well with reconstruction errors, offering valuable clinically\ninterpretable guidance and potentially enhancing diagnostic confidence.",
      "tldr_zh": "本论文提出了一种Dual-domain Multi-path Self-supervised Diffusion Model (DMSM)框架，用于加速MRI重建，以解决传统方法依赖完全采样数据、高计算成本和缺乏不确定性估计的问题。DMSM整合了自监督双域扩散模型训练方案、轻量级混合注意力网络以及多路径推理策略，从而提升重建的准确性、效率和可解释性，同时无需完全采样数据，适用于临床实践。在两个人类MRI数据集上的实验显示，DMSM优于现有监督和自监督基线，尤其在高加速因子下更好地保留精细解剖结构、抑制伪影，并生成与重建错误相关的不确定性地图，提供临床指导。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.18836v1",
      "published_date": "2025-03-24 16:10:51 UTC",
      "updated_date": "2025-03-24 16:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:34:04.101258"
    },
    {
      "arxiv_id": "2503.18826v2",
      "title": "Interpretable and Fair Mechanisms for Abstaining Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Daphne Lenders",
        "Andrea Pugnana",
        "Roberto Pellungrini",
        "Toon Calders",
        "Dino Pedreschi",
        "Fosca Giannotti"
      ],
      "abstract": "Abstaining classifiers have the option to refrain from providing a prediction\nfor instances that are difficult to classify. The abstention mechanism is\ndesigned to trade off the classifier's performance on the accepted data while\nensuring a minimum number of predictions. In this setting, often fairness\nconcerns arise when the abstention mechanism solely reduces errors for the\nmajority groups of the data, resulting in increased performance differences\nacross demographic groups. While there exist a bunch of methods that aim to\nreduce discrimination when abstaining, there is no mechanism that can do so in\nan explainable way. In this paper, we fill this gap by introducing\nInterpretable and Fair Abstaining Classifier IFAC, an algorithm that can reject\npredictions both based on their uncertainty and their unfairness. By rejecting\npossibly unfair predictions, our method reduces error and positive decision\nrate differences across demographic groups of the non-rejected data. Since the\nunfairness-based rejections are based on an interpretable-by-design method,\ni.e., rule-based fairness checks and situation testing, we create a transparent\nprocess that can empower human decision-makers to review the unfair predictions\nand make more just decisions for them. This explainable aspect is especially\nimportant in light of recent AI regulations, mandating that any high-risk\ndecision task should be overseen by human experts to reduce discrimination\nrisks.",
      "tldr_zh": "这篇论文针对 abstaining classifiers 的公平性问题，提出了一种可解释的算法 IFAC（Interpretable and Fair Abstaining Classifier），它能基于预测的不确定性和不公平性（如通过 rule-based fairness checks 和 situation testing）来拒绝预测，从而减少不同群体间的错误率和积极决策率差异。IFAC 的设计强调透明性，便于人类决策者审查不公平预测，提升整体决策公正性，尤其符合当前 AI 法规对高风险任务的人类监督要求。该方法为构建公平且可解释的分类器提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 8 figures. In: Machine Learning and Knowledge Discovery in\n  Databases. Research Track. ECML PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.18826v2",
      "published_date": "2025-03-24 16:06:43 UTC",
      "updated_date": "2025-04-14 09:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:34:16.792950"
    },
    {
      "arxiv_id": "2503.18825v1",
      "title": "EconEvals: Benchmarks and Litmus Tests for LLM Agents in Unknown Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Fish",
        "Julia Shephard",
        "Minkai Li",
        "Ran I. Shorrer",
        "Yannai A. Gonczarowski"
      ],
      "abstract": "We develop benchmarks for LLM agents that act in, learn from, and strategize\nin unknown environments, the specifications of which the LLM agent must learn\nover time from deliberate exploration. Our benchmarks consist of\ndecision-making tasks derived from key problems in economics. To forestall\nsaturation, the benchmark tasks are synthetically generated with scalable\ndifficulty levels. Additionally, we propose litmus tests, a new kind of\nquantitative measure for LLMs and LLM agents. Unlike benchmarks, litmus tests\nquantify differences in character, values, and tendencies of LLMs and LLM\nagents, by considering their behavior when faced with tradeoffs (e.g.,\nefficiency versus equality) where there is no objectively right or wrong\nbehavior. Overall, our benchmarks and litmus tests assess the abilities and\ntendencies of LLM agents in tackling complex economic problems in diverse\nsettings spanning procurement, scheduling, task allocation, and pricing --\napplications that should grow in importance as such agents are further\nintegrated into the economy.",
      "tldr_zh": "本文提出 EconEvals 基准测试，用于评估 LLM agents 在未知环境中的行动、学习和策略制定能力，这些任务基于经济学关键问题生成，具有可扩展难度以避免饱和。基准测试包括合成的决策任务，如采购、调度、任务分配和定价，帮助 LLM agents 通过 deliberate exploration 学习环境规范。此外，作者引入 litmus tests 作为一种新量化措施，评估 LLM agents 在权衡（如效率 vs. 平等）时的行为倾向和价值观差异，而非单纯的正确性。总体上，这些评估工具揭示了 LLM agents 在复杂经济场景中的能力和潜在应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18825v1",
      "published_date": "2025-03-24 16:06:04 UTC",
      "updated_date": "2025-03-24 16:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:34:29.096694"
    },
    {
      "arxiv_id": "2503.18817v1",
      "title": "Enhanced OoD Detection through Cross-Modal Alignment of Multi-Modal Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Jeonghyeon Kim",
        "Sangheum Hwang"
      ],
      "abstract": "Prior research on out-of-distribution detection (OoDD) has primarily focused\non single-modality models. Recently, with the advent of large-scale pretrained\nvision-language models such as CLIP, OoDD methods utilizing such multi-modal\nrepresentations through zero-shot and prompt learning strategies have emerged.\nHowever, these methods typically involve either freezing the pretrained weights\nor only partially tuning them, which can be suboptimal for downstream datasets.\nIn this paper, we highlight that multi-modal fine-tuning (MMFT) can achieve\nnotable OoDD performance. Despite some recent works demonstrating the impact of\nfine-tuning methods for OoDD, there remains significant potential for\nperformance improvement. We investigate the limitation of na\\\"ive fine-tuning\nmethods, examining why they fail to fully leverage the pretrained knowledge.\nOur empirical analysis suggests that this issue could stem from the modality\ngap within in-distribution (ID) embeddings. To address this, we propose a\ntraining objective that enhances cross-modal alignment by regularizing the\ndistances between image and text embeddings of ID data. This adjustment helps\nin better utilizing pretrained textual information by aligning similar\nsemantics from different modalities (i.e., text and image) more closely in the\nhyperspherical representation space. We theoretically demonstrate that the\nproposed regularization corresponds to the maximum likelihood estimation of an\nenergy-based model on a hypersphere. Utilizing ImageNet-1k OoD benchmark\ndatasets, we show that our method, combined with post-hoc OoDD approaches\nleveraging pretrained knowledge (e.g., NegLabel), significantly outperforms\nexisting methods, achieving state-of-the-art OoDD performance and leading ID\naccuracy.",
      "tldr_zh": "本文研究了多模态表示在 Out-of-Distribution Detection (OoD Detection) 中的应用，指出现有方法如零样本或部分微调未能充分利用预训练模型（如 CLIP）的知识，主要由于模态间差距。作者提出一种新的训练目标，通过正则化 In-Distribution (ID) 数据中图像和文本嵌入的距离，来增强 Cross-Modal Alignment，从而在超球面表示空间中更紧密地对齐不同模态的相似语义。理论上，该正则化对应于超球面能量模型的最大似然估计；实验在 ImageNet-1k OoD 基准数据集上显示，该方法结合后处理如 NegLabel，显著超越现有方法，实现了 state-of-the-art 的 OoD 性能并提升了 ID 准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18817v1",
      "published_date": "2025-03-24 16:00:21 UTC",
      "updated_date": "2025-03-24 16:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:34:42.522030"
    },
    {
      "arxiv_id": "2503.18816v2",
      "title": "Learning Multi-Robot Coordination through Locality-Based Factorized Multi-Agent Actor-Critic Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Chak Lam Shek",
        "Amrit Singh Bedi",
        "Anjon Basak",
        "Ellen Novoseller",
        "Nick Waytowich",
        "Priya Narayanan",
        "Dinesh Manocha",
        "Pratap Tokekar"
      ],
      "abstract": "In this work, we present a novel cooperative multi-agent reinforcement\nlearning method called \\textbf{Loc}ality based \\textbf{Fac}torized\n\\textbf{M}ulti-Agent \\textbf{A}ctor-\\textbf{C}ritic (Loc-FACMAC). Existing\nstate-of-the-art algorithms, such as FACMAC, rely on global reward information,\nwhich may not accurately reflect the quality of individual robots' actions in\ndecentralized systems. We integrate the concept of locality into critic\nlearning, where strongly related robots form partitions during training. Robots\nwithin the same partition have a greater impact on each other, leading to more\nprecise policy evaluation. Additionally, we construct a dependency graph to\ncapture the relationships between robots, facilitating the partitioning\nprocess. This approach mitigates the curse of dimensionality and prevents\nrobots from using irrelevant information. Our method improves existing\nalgorithms by focusing on local rewards and leveraging partition-based learning\nto enhance training efficiency and performance. We evaluate the performance of\nLoc-FACMAC in three environments: Hallway, Multi-cartpole, and\nBounded-Cooperative-Navigation. We explore the impact of partition sizes on the\nperformance and compare the result with baseline MARL algorithms such as LOMAQ,\nFACMAC, and QMIX. The experiments reveal that, if the locality structure is\ndefined properly, Loc-FACMAC outperforms these baseline algorithms up to 108\\%,\nindicating that exploiting the locality structure in the actor-critic framework\nimproves the MARL performance.",
      "tldr_zh": "本研究提出了一种新型合作多智能体强化学习算法，名为 Locality based Factorized Multi-Agent Actor-Critic (Loc-FACMAC)，旨在通过整合 locality 概念来提升多机器人协调效率。Loc-FACMAC 在训练中利用依赖图将密切相关的机器人分组成分区，关注局部奖励以避免全局奖励信息的局限性，从而缓解维度灾难并提高策略评估的精确性。与现有算法如 FACMAC 相比，该方法在 Hallway、Multi-cartpole 和 Bounded-Cooperative-Navigation 环境中进行评估，结果显示，如果 locality 结构定义适当，Loc-FACMAC 的性能可比基线算法如 LOMAQ 和 QMIX 高达 108%。这项创新为多智能体强化学习 (MARL) 提供了更高效的训练框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18816v2",
      "published_date": "2025-03-24 16:00:16 UTC",
      "updated_date": "2025-03-28 16:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:34:52.838018"
    },
    {
      "arxiv_id": "2503.18814v1",
      "title": "Towards Responsible AI Music: an Investigation of Trustworthy Features for Creative Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jacopo de Berardinis",
        "Lorenzo Porcaro",
        "Albert Meroño-Peñuela",
        "Angelo Cangelosi",
        "Tess Buckley"
      ],
      "abstract": "Generative AI is radically changing the creative arts, by fundamentally\ntransforming the way we create and interact with cultural artefacts. While\noffering unprecedented opportunities for artistic expression and\ncommercialisation, this technology also raises ethical, societal, and legal\nconcerns. Key among these are the potential displacement of human creativity,\ncopyright infringement stemming from vast training datasets, and the lack of\ntransparency, explainability, and fairness mechanisms. As generative systems\nbecome pervasive in this domain, responsible design is crucial. Whilst previous\nwork has tackled isolated aspects of generative systems (e.g., transparency,\nevaluation, data), we take a comprehensive approach, grounding these efforts\nwithin the Ethics Guidelines for Trustworthy Artificial Intelligence produced\nby the High-Level Expert Group on AI appointed by the European Commission - a\nframework for designing responsible AI systems across seven macro requirements.\nFocusing on generative music AI, we illustrate how these requirements can be\ncontextualised for the field, addressing trustworthiness across multiple\ndimensions and integrating insights from the existing literature. We further\npropose a roadmap for operationalising these contextualised requirements,\nemphasising interdisciplinary collaboration and stakeholder engagement. Our\nwork provides a foundation for designing and evaluating responsible music\ngeneration systems, calling for collaboration among AI experts, ethicists,\nlegal scholars, and artists. This manuscript is accompanied by a website:\nhttps://amresearchlab.github.io/raim-framework/.",
      "tldr_zh": "本研究探讨了生成式 AI 在音乐创作领域的负责任应用，针对潜在问题如取代人类创意、版权侵犯以及缺乏透明度、解释性和公平性机制。作者采用欧盟高水平专家组的 Ethics Guidelines for Trustworthy Artificial Intelligence 框架，将其七个宏观要求（包括透明度、公平性等）应用于生成式音乐 AI 系统，综合现有文献进行全面分析。论文为该领域提供了具体化这些要求的路线图，强调跨学科合作和利益相关者参与，以设计和评估可信赖的音乐生成系统。该工作呼吁 AI 专家、伦理学家、法律学者和艺术家共同努力，并附带一个配套网站以支持进一步探讨。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18814v1",
      "published_date": "2025-03-24 15:54:47 UTC",
      "updated_date": "2025-03-24 15:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:35:04.469284"
    },
    {
      "arxiv_id": "2503.18813v1",
      "title": "Defeating Prompt Injections by Design",
      "title_zh": "翻译失败",
      "authors": [
        "Edoardo Debenedetti",
        "Ilia Shumailov",
        "Tianqi Fan",
        "Jamie Hayes",
        "Nicholas Carlini",
        "Daniel Fabian",
        "Christoph Kern",
        "Chongyang Shi",
        "Andreas Terzis",
        "Florian Tramèr"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in agentic systems\nthat interact with an external environment. However, LLM agents are vulnerable\nto prompt injection attacks when handling untrusted data. In this paper we\npropose CaMeL, a robust defense that creates a protective system layer around\nthe LLM, securing it even when underlying models may be susceptible to attacks.\nTo operate, CaMeL explicitly extracts the control and data flows from the\n(trusted) query; therefore, the untrusted data retrieved by the LLM can never\nimpact the program flow. To further improve security, CaMeL relies on a notion\nof a capability to prevent the exfiltration of private data over unauthorized\ndata flows. We demonstrate effectiveness of CaMeL by solving $67\\%$ of tasks\nwith provable security in AgentDojo [NeurIPS 2024], a recent agentic security\nbenchmark.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在代理系统中处理不受信任数据时面临的提示注入攻击问题，并提出了一种名为 CaMeL 的鲁棒防御机制。CaMeL 通过从受信任查询中显式提取控制和数据流，确保不受信任数据无法影响程序流，并利用 capability 概念防止私人数据的泄露。实验结果显示，该机制在 AgentDojo 基准测试中实现了 67% 的任务解决率，并提供了可证明的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18813v1",
      "published_date": "2025-03-24 15:54:10 UTC",
      "updated_date": "2025-03-24 15:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:35:16.607992"
    },
    {
      "arxiv_id": "2503.18809v1",
      "title": "Classical Planning with LLM-Generated Heuristics: Challenging the State of the Art with Python Code",
      "title_zh": "翻译失败",
      "authors": [
        "Augusto B. Corrêa",
        "André G. Pereira",
        "Jendrik Seipp"
      ],
      "abstract": "In recent years, large language models (LLMs) have shown remarkable\ncapabilities in various artificial intelligence problems. However, they fail to\nplan reliably, even when prompted with a detailed definition of the planning\ntask. Attempts to improve their planning capabilities, such as chain-of-thought\nprompting, fine-tuning, and explicit \"reasoning\" still yield incorrect plans\nand usually fail to generalize to larger tasks. In this paper, we show how to\nuse LLMs to generate correct plans, even for out-of-distribution tasks of\nincreasing size. For a given planning domain, we ask an LLM to generate several\ndomain-dependent heuristic functions in the form of Python code, evaluate them\non a set of training tasks within a greedy best-first search, and choose the\nstrongest one. The resulting LLM-generated heuristics solve many more unseen\ntest tasks than state-of-the-art domain-independent heuristics for classical\nplanning. They are even competitive with the strongest learning algorithm for\ndomain-dependent planning. These findings are especially remarkable given that\nour proof-of-concept implementation is based on an unoptimized Python planner\nand the baselines all build upon highly optimized C++ code. In some domains,\nthe LLM-generated heuristics expand fewer states than the baselines, revealing\nthat they are not only efficiently computable, but sometimes even more\ninformative than the state-of-the-art heuristics. Overall, our results show\nthat sampling a set of planning heuristic function programs can significantly\nimprove the planning capabilities of LLMs.",
      "tldr_zh": "本研究探讨了利用大型语言模型 (LLMs) 生成 Python 代码形式的域相关启发式函数，以提升经典规划任务的性能。方法包括让 LLMs 创建多个启发式函数，并在训练任务上通过贪婪最佳优先搜索 (greedy best-first search) 评估和选择最有效的函数。实验结果显示，这些 LLM 生成的启发式函数在未见测试任务上显著优于现有最先进的域无关启发式函数，甚至与最强的域相关规划学习算法竞争，并在某些领域扩展的状态更少，证明其高效性和信息量。总体上，该方法证明了采样启发式函数程序能显著增强 LLMs 的规划能力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18809v1",
      "published_date": "2025-03-24 15:50:20 UTC",
      "updated_date": "2025-03-24 15:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:35:28.865539"
    },
    {
      "arxiv_id": "2503.19007v1",
      "title": "Option Discovery Using LLM-guided Semantic Hierarchical Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chak Lam Shek",
        "Pratap Tokekar"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable promise in reasoning and\ndecision-making, yet their integration with Reinforcement Learning (RL) for\ncomplex robotic tasks remains underexplored. In this paper, we propose an\nLLM-guided hierarchical RL framework, termed LDSC, that leverages LLM-driven\nsubgoal selection and option reuse to enhance sample efficiency,\ngeneralization, and multi-task adaptability. Traditional RL methods often\nsuffer from inefficient exploration and high computational cost. Hierarchical\nRL helps with these challenges, but existing methods often fail to reuse\noptions effectively when faced with new tasks. To address these limitations, we\nintroduce a three-stage framework that uses LLMs for subgoal generation given\nnatural language description of the task, a reusable option learning and\nselection method, and an action-level policy, enabling more effective\ndecision-making across diverse tasks. By incorporating LLMs for subgoal\nprediction and policy guidance, our approach improves exploration efficiency\nand enhances learning performance. On average, LDSC outperforms the baseline by\n55.9\\% in average reward, demonstrating its effectiveness in complex RL\nsettings. More details and experiment videos could be found in\n\\href{https://raaslab.org/projects/LDSC/}{this\nlink\\footnote{https://raaslab.org/projects/LDSC}}.",
      "tldr_zh": "本论文提出了一种名为 LDSC 的 LLM-guided hierarchical RL 框架，用于复杂机器人任务中选项发现和决策优化。该框架利用 LLM 生成基于自然语言任务描述的子目标，并结合可重用选项学习、选择机制和动作级别策略，提升 RL 的样本效率、一般化和多任务适应性。相比传统 RL 方法，LDSC 通过 LLM 的子目标预测和策略指导显著提高了探索效率，实验结果显示平均奖励比基线提升 55.9%。这为机器人强化学习提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19007v1",
      "published_date": "2025-03-24 15:49:56 UTC",
      "updated_date": "2025-03-24 15:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:35:41.641975"
    },
    {
      "arxiv_id": "2503.19006v1",
      "title": "Computational Thinking with Computer Vision: Developing AI Competency in an Introductory Computer Science Course",
      "title_zh": "利用计算机视觉的计算思维：在入门计算机科学课程中培养 AI 能力",
      "authors": [
        "Tahiya Chowdhury"
      ],
      "abstract": "Developing competency in artificial intelligence is becoming increasingly\ncrucial for computer science (CS) students at all levels of the CS curriculum.\nHowever, most previous research focuses on advanced CS courses, as traditional\nintroductory courses provide limited opportunities to develop AI skills and\nknowledge. This paper introduces an introductory CS course where students learn\ncomputational thinking through computer vision, a sub-field of AI, as an\napplication context. The course aims to achieve computational thinking outcomes\nalongside critical thinking outcomes that expose students to AI approaches and\ntheir societal implications. Through experiential activities such as individual\nprojects and reading discussions, our course seeks to balance technical\nlearning and critical thinking goals. Our evaluation, based on pre-and\npost-course surveys, shows an improved sense of belonging, self-efficacy, and\nAI ethics awareness among students. The results suggest that an AI-focused\ncontext can enhance participation and employability, student-selected projects\nsupport self-efficacy, and ethically grounded AI instruction can be effective\nfor interdisciplinary audiences. Students' discussions on reading assignments\ndemonstrated deep engagement with the complex challenges in today's AI\nlandscape. Finally, we share insights on scaling such courses for larger\ncohorts and improving the learning experience for introductory CS students.",
      "tldr_zh": "本研究提出了一种将计算机视觉作为应用背景的入门计算机科学（CS）课程，旨在通过培养计算思维（Computational Thinking）来提升学生的AI能力，并强调AI方法及其社会影响的批判性思考。该课程采用体验式活动，如个人项目和阅读讨论，平衡技术学习与伦理考虑，针对传统入门课程的局限性进行创新。评估结果显示，学生在课前课后调查中表现出归属感、自效能和AI伦理意识的显著改善，同时证明AI焦点背景能增强参与度与就业力，并为跨学科受众提供有效教学。最后，论文分享了扩展此类课程到更大规模的见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 3 figures, 3 tables, Proceedings of AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.19006v1",
      "published_date": "2025-03-24 15:49:37 UTC",
      "updated_date": "2025-03-24 15:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:35:53.160073"
    },
    {
      "arxiv_id": "2503.18792v1",
      "title": "REALM: A Dataset of Real-World LLM Use Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwen Cheng",
        "Kshitish Ghate",
        "Wenyue Hua",
        "William Yang Wang",
        "Hong Shen",
        "Fei Fang"
      ],
      "abstract": "Large Language Models, such as the GPT series, have driven significant\nindustrial applications, leading to economic and societal transformations.\nHowever, a comprehensive understanding of their real-world applications remains\nlimited. To address this, we introduce REALM, a dataset of over 94,000 LLM use\ncases collected from Reddit and news articles. REALM captures two key\ndimensions: the diverse applications of LLMs and the demographics of their\nusers. It categorizes LLM applications and explores how users' occupations\nrelate to the types of applications they use. By integrating real-world data,\nREALM offers insights into LLM adoption across different domains, providing a\nfoundation for future research on their evolving societal roles. A dedicated\ndashboard https://realm-e7682.web.app/ presents the data.",
      "tldr_zh": "本文介绍了 REALM 数据集，该数据集包含超过 94,000 个从 Reddit 和新闻文章中收集的真实 LLM 使用案例，旨在揭示 LLM 在实际应用中的多样性。REALM 通过分类 LLM 应用并分析用户职业与应用类型的关系，提供了对 LLM 在不同领域采用的宝贵洞见。数据集为未来研究 LLM 的社会角色演变奠定了基础，并附带了一个专用仪表板（https://realm-e7682.web.app/）。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18792v1",
      "published_date": "2025-03-24 15:39:25 UTC",
      "updated_date": "2025-03-24 15:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:36:04.653404"
    },
    {
      "arxiv_id": "2503.18783v2",
      "title": "Frequency Dynamic Convolution for Dense Image Prediction",
      "title_zh": "频率动态卷积用于密集图像预测",
      "authors": [
        "Linwei Chen",
        "Lin Gu",
        "Liang Li",
        "Chenggang Yan",
        "Ying Fu"
      ],
      "abstract": "While Dynamic Convolution (DY-Conv) has shown promising performance by\nenabling adaptive weight selection through multiple parallel weights combined\nwith an attention mechanism, the frequency response of these weights tends to\nexhibit high similarity, resulting in high parameter costs but limited\nadaptability. In this work, we introduce Frequency Dynamic Convolution\n(FDConv), a novel approach that mitigates these limitations by learning a fixed\nparameter budget in the Fourier domain. FDConv divides this budget into\nfrequency-based groups with disjoint Fourier indices, enabling the construction\nof frequency-diverse weights without increasing the parameter cost. To further\nenhance adaptability, we propose Kernel Spatial Modulation (KSM) and Frequency\nBand Modulation (FBM). KSM dynamically adjusts the frequency response of each\nfilter at the spatial level, while FBM decomposes weights into distinct\nfrequency bands in the frequency domain and modulates them dynamically based on\nlocal content. Extensive experiments on object detection, segmentation, and\nclassification validate the effectiveness of FDConv. We demonstrate that when\napplied to ResNet-50, FDConv achieves superior performance with a modest\nincrease of +3.6M parameters, outperforming previous methods that require\nsubstantial increases in parameter budgets (e.g., CondConv +90M, KW +76.5M).\nMoreover, FDConv seamlessly integrates into a variety of architectures,\nincluding ConvNeXt, Swin-Transformer, offering a flexible and efficient\nsolution for modern vision tasks. The code is made publicly available at\nhttps://github.com/Linwei-Chen/FDConv.",
      "tldr_zh": "本文提出 Frequency Dynamic Convolution (FDConv)，一种在傅立叶域学习固定参数预算的新方法，以解决 Dynamic Convolution (DY-Conv) 的频率响应相似性问题，从而提高参数效率和适应性。FDConv 通过将参数分为基于频率的组，并引入 Kernel Spatial Modulation (KSM) 和 Frequency Band Modulation (FBM) 来动态调整过滤器的空间和频率响应，实现频率多样化的权重。实验结果显示，FDConv 应用于 ResNet-50 时，仅增加 3.6M 参数就超过了现有方法（如 CondConv +90M），并在物体检测、分割和分类任务上表现出优越性能。该框架可灵活集成到多种架构中，如 ConvNeXt 和 Swin-Transformer，提供高效的密集图像预测解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18783v2",
      "published_date": "2025-03-24 15:32:06 UTC",
      "updated_date": "2025-03-25 03:09:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:36:18.478201"
    },
    {
      "arxiv_id": "2503.18778v1",
      "title": "The case for delegated AI autonomy for Human AI teaming in healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Jia",
        "Harriet Evans",
        "Zoe Porter",
        "Simon Graham",
        "John McDermid",
        "Tom Lawton",
        "David Snead",
        "Ibrahim Habli"
      ],
      "abstract": "In this paper we propose an advanced approach to integrating artificial\nintelligence (AI) into healthcare: autonomous decision support. This approach\nallows the AI algorithm to act autonomously for a subset of patient cases\nwhilst serving a supportive role in other subsets of patient cases based on\ndefined delegation criteria. By leveraging the complementary strengths of both\nhumans and AI, it aims to deliver greater overall performance than existing\nhuman-AI teaming models. It ensures safe handling of patient cases and\npotentially reduces clinician review time, whilst being mindful of AI tool\nlimitations. After setting the approach within the context of current human-AI\nteaming models, we outline the delegation criteria and apply them to a specific\nAI-based tool used in histopathology. The potential impact of the approach and\nthe regulatory requirements for its successful implementation are then\ndiscussed.",
      "tldr_zh": "本文提出了一种名为“delegated AI autonomy”的自主决策支持方法，用于优化医疗保健中的人类-AI 团队协作。该方法允许 AI 根据预定义的委托标准，在部分患者病例中独立行动，而在其他情况下提供辅助支持，从而发挥双方互补优势，实现比现有模型更高的整体性能。作者讨论了如何应用这一标准到组织病理学中的 AI 工具，并强调了其潜在益处，如减少临床医生审查时间和确保患者安全，同时分析了实施所需的监管要求。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18778v1",
      "published_date": "2025-03-24 15:26:54 UTC",
      "updated_date": "2025-03-24 15:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:36:28.107043"
    },
    {
      "arxiv_id": "2503.18773v1",
      "title": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs Decoding with Low-Bit KV Cache",
      "title_zh": "翻译失败",
      "authors": [
        "Dayou Du",
        "Shijie Cao",
        "Jianyi Cheng",
        "Ting Cao",
        "Mao Yang"
      ],
      "abstract": "The growing adoption of long-context Large Language Models (LLMs) has\nintroduced significant memory and computational challenges in autoregressive\ndecoding due to the expanding Key-Value (KV) cache. KV cache quantization has\nemerged as a promising solution, with prior work showing that 4-bit or even\n2-bit quantization can maintain model accuracy while reducing memory costs.\nHowever, despite these benefits, preliminary implementations for the low-bit KV\ncache struggle to deliver the expected speedup due to quantization and\ndequantization overheads and the lack of Tensor Cores utilization. In this\nwork, we propose BitDecoding, a GPU-optimized framework that unlocks Tensor\nCores for efficient decoding with low-bit KV cache. Efficiently leveraging\nTensor Cores for low-bit KV cache is challenging due to the dynamic nature of\nKV cache generation at each decoding step. BitDecoding addresses these\nchallenges with a Tensor Cores-Centric BitFusion Scheme that ensures data\nlayout compatibility to enable high utilization of Tensor Cores. Additionally,\nBitDecoding incorporates a warp-efficient parallel decoding kernel and a\nfine-grained asynchronous pipeline, minimizing dequantization overhead and\nimproving computational efficiency. Experiments show that BitDecoding achieves\nup to 7.5x speedup on RTX 4090, 4.8x on A100, and 8.9x on H100, compared to\nFP16 FlashDecoding-v2. It also outperforms the state-of-the-art low-bit KV\ncache implementation (QServe) by up to 4.3x. On LLaMA-3.1-8B with a 128K\nsequence length, BitDecoding reduces single-batch decoding latency by 3x,\ndemonstrating its effectiveness in long-context generation scenarios. The code\nis available at https://github.com/DD-DuDa/BitDecoding.",
      "tldr_zh": "这篇论文提出了 BitDecoding 框架，用于优化长上下文 Large Language Models (LLMs) 的自回归解码问题，通过低位 KV Cache 量化减少内存开销，同时解决量化/去量化开销和 Tensor Cores 利用率低的问题。框架的核心创新包括 Tensor Cores-Centric BitFusion Scheme 确保数据布局兼容、warp-efficient parallel decoding kernel 和 fine-grained asynchronous pipeline，以提高计算效率和最小化开销。实验结果显示，BitDecoding 在 RTX 4090 上实现高达 7.5x 加速，在 LLaMA-3.1-8B 的 128K 序列长度场景下，将单批解码延迟降低 3x，并比现有方法 QServe 快 4.3x。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18773v1",
      "published_date": "2025-03-24 15:22:41 UTC",
      "updated_date": "2025-03-24 15:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:36:42.786761"
    },
    {
      "arxiv_id": "2503.18762v1",
      "title": "Mechanistic Interpretability of Fine-Tuned Vision Transformers on Distorted Images: Decoding Attention Head Behavior for Transparent and Trustworthy AI",
      "title_zh": "翻译失败",
      "authors": [
        "Nooshin Bahador"
      ],
      "abstract": "Mechanistic interpretability improves the safety, reliability, and robustness\nof large AI models. This study examined individual attention heads in vision\ntransformers (ViTs) fine tuned on distorted 2D spectrogram images containing\nnon relevant content (axis labels, titles, color bars). By introducing\nextraneous features, the study analyzed how transformer components processed\nunrelated information, using mechanistic interpretability to debug issues and\nreveal insights into transformer architectures. Attention maps assessed head\ncontributions across layers. Heads in early layers (1 to 3) showed minimal task\nimpact with ablation increased MSE loss slightly ({\\mu}=0.11%, {\\sigma}=0.09%),\nindicating focus on less critical low level features. In contrast, deeper heads\n(e.g., layer 6) caused a threefold higher loss increase ({\\mu}=0.34%,\n{\\sigma}=0.02%), demonstrating greater task importance. Intermediate layers (6\nto 11) exhibited monosemantic behavior, attending exclusively to chirp regions.\nSome early heads (1 to 4) were monosemantic but non task relevant (e.g. text\ndetectors, edge or corner detectors). Attention maps distinguished monosemantic\nheads (precise chirp localization) from polysemantic heads (multiple irrelevant\nregions). These findings revealed functional specialization in ViTs, showing\nhow heads processed relevant vs. extraneous information. By decomposing\ntransformers into interpretable components, this work enhanced model\nunderstanding, identified vulnerabilities, and advanced safer, more transparent\nAI.",
      "tldr_zh": "本文研究了细调后的 Vision Transformers (ViTs) 在包含无关内容的扭曲 2D 谱图图像上的行为，使用 Mechanistic Interpretability 方法分析注意力头如何处理相关与无关信息。实验通过注意力图和消融测试发现，早期层（1-3）的注意力头对任务影响较小（MSE 损失增加微乎其微，{\\mu}=0.11%），而深层头（如层6）对任务更关键（损失增加{\\mu}=0.34%），中间层（6-11）则显示 Monosemantic 行为，专注于关键区域如chirp 区域。该工作揭示了 ViTs 的功能专业化，区分了单义头和多义头，从而提升模型的可解释性和可靠性，促进更安全透明的 AI 系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18762v1",
      "published_date": "2025-03-24 15:11:24 UTC",
      "updated_date": "2025-03-24 15:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:36:54.460380"
    },
    {
      "arxiv_id": "2503.18755v1",
      "title": "EgoSurgery-HTS: A Dataset for Egocentric Hand-Tool Segmentation in Open Surgery Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Darjana",
        "Ryo Fujii",
        "Hideo Saito",
        "Hiroki Kajita"
      ],
      "abstract": "Egocentric open-surgery videos capture rich, fine-grained details essential\nfor accurately modeling surgical procedures and human behavior in the operating\nroom. A detailed, pixel-level understanding of hands and surgical tools is\ncrucial for interpreting a surgeon's actions and intentions. We introduce\nEgoSurgery-HTS, a new dataset with pixel-wise annotations and a benchmark suite\nfor segmenting surgical tools, hands, and interacting tools in egocentric\nopen-surgery videos. Specifically, we provide a labeled dataset for (1) tool\ninstance segmentation of 14 distinct surgical tools, (2) hand instance\nsegmentation, and (3) hand-tool segmentation to label hands and the tools they\nmanipulate. Using EgoSurgery-HTS, we conduct extensive evaluations of\nstate-of-the-art segmentation methods and demonstrate significant improvements\nin the accuracy of hand and hand-tool segmentation in egocentric open-surgery\nvideos compared to existing datasets. The dataset will be released at\nhttps://github.com/Fujiry0/EgoSurgery.",
      "tldr_zh": "该研究引入了EgoSurgery-HTS数据集，用于在egocentric open-surgery videos中进行手部和手术工具的像素级分割。该数据集提供了14种手术工具的实例分割、手实例分割，以及手-tool交互的分割标注，并附带了一个基准测试套件。通过评估最先进的分割方法，研究者在手部和手-tool分割的准确性上取得了显著改进。该数据集将公开在GitHub上，促进手术视频分析领域的进一步发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18755v1",
      "published_date": "2025-03-24 15:04:32 UTC",
      "updated_date": "2025-03-24 15:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:37:04.291772"
    },
    {
      "arxiv_id": "2503.18751v1",
      "title": "Construction Identification and Disambiguation Using BERT: A Case Study of NPN",
      "title_zh": "使用 BERT 进行",
      "authors": [
        "Wesley Scivetti",
        "Nathan Schneider"
      ],
      "abstract": "Construction Grammar hypothesizes that knowledge of a language consists\nchiefly of knowledge of form-meaning pairs (''constructions'') that include\nvocabulary, general grammar rules, and even idiosyncratic patterns. Recent work\nhas shown that transformer language models represent at least some\nconstructional patterns, including ones where the construction is rare overall.\nIn this work, we probe BERT's representation of the form and meaning of a minor\nconstruction of English, the NPN (noun-preposition-noun) construction --\nexhibited in such expressions as face to face and day to day -- which is known\nto be polysemous. We construct a benchmark dataset of semantically annotated\ncorpus instances (including distractors that superficially resemble the\nconstruction). With this dataset, we train and evaluate probing classifiers.\nThey achieve decent discrimination of the construction from distractors, as\nwell as sense disambiguation among true instances of the construction,\nrevealing that BERT embeddings carry indications of the construction's\nsemantics. Moreover, artificially permuting the word order of true construction\ninstances causes them to be rejected, indicating sensitivity to matters of\nform. We conclude that BERT does latently encode at least some knowledge of the\nNPN construction going beyond a surface syntactic pattern and lexical cues.",
      "tldr_zh": "本文使用 BERT 模型对英语的 NPN construction（名词-介词-名词结构，如 face to face）进行识别和歧义消除，作为 Construction Grammar 的案例研究。研究者构建了一个语义标注数据集，包括真实实例和干扰项，并训练探测分类器来区分该结构并处理其多义性。结果显示，BERT 的嵌入表示不仅能准确识别 NPN construction 的形式（如对词序敏感），还捕捉了其语义特征，表明 transformer language models 隐式编码了超出表面句法和词汇线索的语言知识。总的来说，这为理解语言模型对次要语言模式的表征提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, ACL long-paper format (preprint)",
      "pdf_url": "http://arxiv.org/pdf/2503.18751v1",
      "published_date": "2025-03-24 14:59:39 UTC",
      "updated_date": "2025-03-24 14:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:37:17.775014"
    },
    {
      "arxiv_id": "2503.20804v1",
      "title": "AED: Automatic Discovery of Effective and Diverse Vulnerabilities for Autonomous Driving Policy with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Le Qiu",
        "Zelai Xu",
        "Qixin Tan",
        "Wenhao Tang",
        "Chao Yu",
        "Yu Wang"
      ],
      "abstract": "Assessing the safety of autonomous driving policy is of great importance, and\nreinforcement learning (RL) has emerged as a powerful method for discovering\ncritical vulnerabilities in driving policies. However, existing RL-based\napproaches often struggle to identify vulnerabilities that are both\neffective-meaning the autonomous vehicle is genuinely responsible for the\naccidents-and diverse-meaning they span various failure types. To address these\nchallenges, we propose AED, a framework that uses large language models (LLMs)\nto automatically discover effective and diverse vulnerabilities in autonomous\ndriving policies. We first utilize an LLM to automatically design reward\nfunctions for RL training. Then we let the LLM consider a diverse set of\naccident types and train adversarial policies for different accident types in\nparallel. Finally, we use preference-based learning to filter ineffective\naccidents and enhance the effectiveness of each vulnerability. Experiments\nacross multiple simulated traffic scenarios and tested policies show that AED\nuncovers a broader range of vulnerabilities and achieves higher attack success\nrates compared with expert-designed rewards, thereby reducing the need for\nmanual reward engineering and improving the diversity and effectiveness of\nvulnerability discovery.",
      "tldr_zh": "这篇论文提出了一种名为 AED 的框架，利用大型语言模型 (LLMs) 自动发现自动驾驶策略中的有效（即自动驾驶车辆真正负责的事故）和多样（覆盖各种失败类型）的漏洞，以解决现有强化学习 (RL) 方法的局限性。AED 的核心方法包括使用 LLMs 自动设计 RL 奖励函数、并行训练针对不同事故类型的对抗策略，以及通过基于偏好的学习过滤无效事故以提升漏洞有效性。在多个模拟交通场景的实验中，AED 比专家设计的奖励函数发现了更广泛的漏洞，并实现了更高的攻击成功率，从而减少了手动奖励工程的需求并提高了漏洞发现的多样性和有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.20804v1",
      "published_date": "2025-03-24 14:59:17 UTC",
      "updated_date": "2025-03-24 14:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:37:29.673010"
    },
    {
      "arxiv_id": "2503.22713v1",
      "title": "Chirp Localization via Fine-Tuned Transformer Model: A Proof-of-Concept Study",
      "title_zh": "基于微调 Transformer 模型的啁啾定位：一个概念验证研究",
      "authors": [
        "Nooshin Bahador",
        "Milad Lankarany"
      ],
      "abstract": "Spectrograms are pivotal in time-frequency signal analysis, widely used in\naudio processing and computational neuroscience. Chirp-like patterns in\nelectroencephalogram (EEG) spectrograms (marked by linear or exponential\nfrequency sweep) are key biomarkers for seizure dynamics, but automated tools\nfor their detection, localization, and feature extraction are lacking. This\nstudy bridges this gap by fine-tuning a Vision Transformer (ViT) model on\nsynthetic spectrograms, augmented with Low-Rank Adaptation (LoRA) to boost\nadaptability. We generated 100000 synthetic spectrograms with chirp parameters,\ncreating the first large-scale benchmark for chirp localization. These\nspectrograms mimic neural chirps using linear or exponential frequency sweep,\nGaussian noise, and smoothing. A ViT model, adapted for regression, predicted\nchirp parameters. LoRA fine-tuned the attention layers, enabling efficient\nupdates to the pre-trained backbone. Training used MSE loss and the AdamW\noptimizer, with a learning rate scheduler and early stopping to curb\noverfitting. Only three features were targeted: Chirp Start Time (Onset Time),\nChirp Start Frequency (Onset Frequency), and Chirp End Frequency (Offset\nFrequency). Performance was evaluated via Pearson correlation between predicted\nand actual labels. Results showed strong alignment: 0.9841 correlation for\nchirp start time, with stable inference times (137 to 140s) and minimal bias in\nerror distributions. This approach offers a tool for chirp analysis in EEG\ntime-frequency representation, filling a critical methodological void.",
      "tldr_zh": "本研究针对 EEG 光谱图中的 Chirp-like 模式（癫痫动态的关键生物标记）缺乏自动检测工具的问题，提出了一种基于 Vision Transformer (ViT) 模型的定位方法，通过生成 10 万个合成光谱图作为基准，并使用 Low-Rank Adaptation (LoRA) 增强模型适应性，以回归方式预测 Chirp 参数，包括 Chirp Start Time、Chirp Start Frequency 和 Chirp End Frequency。模型训练采用 MSE 损失、AdamW 优化器及学习率调度，以防止过拟合。结果显示，预测准确性高，Pearson 相关系数达 0.9841，为起始时间，且推理时间稳定（137-140 秒），为 EEG 时间-频率分析提供了一个高效工具，填补了方法空白。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.22713v1",
      "published_date": "2025-03-24 14:27:07 UTC",
      "updated_date": "2025-03-24 14:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:37:42.714106"
    },
    {
      "arxiv_id": "2503.18706v1",
      "title": "Energy-Efficient Dynamic Training and Inference for GNN-Based Network Modeling",
      "title_zh": "能量高效的动态训练与推理用于基于 GNN 的网络建模",
      "authors": [
        "Chetna Singhal",
        "Yassine Hadjadj-Aoul"
      ],
      "abstract": "Efficient network modeling is essential for resource optimization and network\nplanning in next-generation large-scale complex networks. Traditional\napproaches, such as queuing theory-based modeling and packet-based simulators,\ncan be inefficient due to the assumption made and the computational expense,\nrespectively. To address these challenges, we propose an innovative\nenergy-efficient dynamic orchestration of Graph Neural Networks (GNN) based\nmodel training and inference framework for context-aware network modeling and\npredictions. We have developed a low-complexity solution framework, QAG, that\nis a Quantum approximation optimization (QAO) algorithm for Adaptive\norchestration of GNN-based network modeling. We leverage the tripartite graph\nmodel to represent a multi-application system with many compute nodes.\nThereafter, we apply the constrained graph-cutting using QAO to find the\nfeasible energy-efficient configurations of the GNN-based model and deploying\nthem on the available compute nodes to meet the network modeling application\nrequirements. The proposed QAG scheme closely matches the optimum and offers\natleast a 50% energy saving while meeting the application requirements with 60%\nlower churn-rate.",
      "tldr_zh": "该研究针对下一代大规模复杂网络的资源优化和规划，提出了一种基于 Graph Neural Networks (GNN) 的能量高效动态训练和推理框架，以解决传统队列理论和基于包模拟器的效率问题。该框架引入了 QAG 方案，该方案利用 Quantum approximation optimization (QAO) 算法和 tripartite graph model 表示多应用系统，通过约束图切割来实现自适应编排 GNN 模型的配置，从而满足网络建模应用需求。实验结果显示，QAG 方案与最优解高度匹配，提供至少 50% 的能源节约，同时以 60% 更低的 churn-rate 维持应用性能。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted in IEEE WCNC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18706v1",
      "published_date": "2025-03-24 14:17:57 UTC",
      "updated_date": "2025-03-24 14:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:37:53.613792"
    },
    {
      "arxiv_id": "2503.18684v2",
      "title": "Efficient Continual Adaptation of Pretrained Robotic Policy with Online Meta-Learned Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Zhu",
        "Endong Sun",
        "Guanhe Huang",
        "Oya Celiktutan"
      ],
      "abstract": "Continual adaptation is essential for general autonomous agents. For example,\na household robot pretrained with a repertoire of skills must still adapt to\nunseen tasks specific to each household. Motivated by this, building upon\nparameter-efficient fine-tuning in language models, prior works have explored\nlightweight adapters to adapt pretrained policies, which can preserve learned\nfeatures from the pretraining phase and demonstrate good adaptation\nperformances. However, these approaches treat task learning separately,\nlimiting knowledge transfer between tasks. In this paper, we propose Online\nMeta-Learned adapters (OMLA). Instead of applying adapters directly, OMLA can\nfacilitate knowledge transfer from previously learned tasks to current learning\ntasks through a novel meta-learning objective. Extensive experiments in both\nsimulated and real-world environments demonstrate that OMLA can lead to better\nadaptation performances compared to the baseline methods. The project link:\nhttps://ricky-zhu.github.io/OMLA/.",
      "tldr_zh": "本研究针对预训练机器人策略的持续适配问题，提出 Online Meta-Learned adapters (OMLA) 方法，以实现任务间知识转移。OMLA 通过一个新颖的元学习(meta-learning)目标，在线学习先前任务的知识，并应用于当前任务的适应，从而提升整体性能。实验结果显示，在模拟和真实环境中，OMLA 比基线方法表现出更好的适应效果，为通用自主代理的持续学习提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project link: https://ricky-zhu.github.io/OMLA/",
      "pdf_url": "http://arxiv.org/pdf/2503.18684v2",
      "published_date": "2025-03-24 13:55:47 UTC",
      "updated_date": "2025-03-27 13:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:38:05.431565"
    },
    {
      "arxiv_id": "2503.18681v2",
      "title": "Commander-GPT: Fully Unleashing the Sarcasm Detection Capability of Multi-Modal Large Language Models",
      "title_zh": "Commander-GPT：充分发挥多模态大语言模型的讽刺检测能力",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Bo Wang",
        "Jing Qin"
      ],
      "abstract": "Sarcasm detection, as a crucial research direction in the field of Natural\nLanguage Processing (NLP), has attracted widespread attention. Traditional\nsarcasm detection tasks have typically focused on single-modal approaches\n(e.g., text), but due to the implicit and subtle nature of sarcasm, such\nmethods often fail to yield satisfactory results. In recent years, researchers\nhave shifted the focus of sarcasm detection to multi-modal approaches. However,\neffectively leveraging multi-modal information to accurately identify sarcastic\ncontent remains a challenge that warrants further exploration. Leveraging the\npowerful integrated processing capabilities of Multi-Modal Large Language\nModels (MLLMs) for various information sources, we propose an innovative\nmulti-modal Commander-GPT framework. Inspired by military strategy, we first\ndecompose the sarcasm detection task into six distinct sub-tasks. A central\ncommander (decision-maker) then assigns the best-suited large language model to\naddress each specific sub-task. Ultimately, the detection results from each\nmodel are aggregated to identify sarcasm. We conducted extensive experiments on\nMMSD and MMSD 2.0, utilizing four multi-modal large language models and six\nprompting strategies. Our experiments demonstrate that our approach achieves\nstate-of-the-art performance, with a 19.3% improvement in F1 score, without\nnecessitating fine-tuning or ground-truth rationales.",
      "tldr_zh": "这篇论文提出 Commander-GPT 框架，旨在充分发挥 Multi-Modal Large Language Models (MLLMs) 在讽刺检测任务中的潜力，以解决传统单模态方法（如文本分析）的局限性。框架受军事策略启发，将讽刺检测分解为六个子任务，由中央指挥官（decision-maker）分配最佳模型处理每个子任务，并最终聚合结果进行识别。在 MMSD 和 MMSD 2.0 数据集上的实验显示，该方法无需 fine-tuning 或 ground-truth rationales，便实现了 state-of-the-art 性能，F1 score 提高了 19.3%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18681v2",
      "published_date": "2025-03-24 13:53:00 UTC",
      "updated_date": "2025-03-25 04:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:38:17.646058"
    },
    {
      "arxiv_id": "2503.20802v1",
      "title": "CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhao Zhang",
        "Bo Cheng",
        "Jiale Han",
        "Yuli Chen",
        "Zhixuan Wu",
        "Changbao Li",
        "Pingli Gu"
      ],
      "abstract": "Text watermarking provides an effective solution for identifying synthetic\ntext generated by large language models. However, existing techniques often\nfocus on satisfying specific criteria while ignoring other key aspects, lacking\na unified evaluation. To fill this gap, we propose the Comprehensive Evaluation\nFramework for Watermark (CEFW), a unified framework that comprehensively\nevaluates watermarking methods across five key dimensions: ease of detection,\nfidelity of text quality, minimal embedding cost, robustness to adversarial\nattacks, and imperceptibility to prevent imitation or forgery. By assessing\nwatermarks according to all these key criteria, CEFW offers a thorough\nevaluation of their practicality and effectiveness. Moreover, we introduce a\nsimple and effective watermarking method called Balanced Watermark (BW), which\nguarantees robustness and imperceptibility through balancing the way watermark\ninformation is added. Extensive experiments show that BW outperforms existing\nmethods in overall performance across all evaluation dimensions. We release our\ncode to the community for future research.\nhttps://github.com/DrankXs/BalancedWatermark.",
      "tldr_zh": "本研究针对大型语言模型中的文本水印技术存在的评估不统一问题，提出了 Comprehensive Evaluation Framework for Watermark (CEFW)，这是一个统一的框架，用于全面评估水印方法在 ease of detection、fidelity of text quality、minimal embedding cost、robustness to adversarial attacks 和 imperceptibility 等五个关键维度的表现。CEFW 通过整合这些标准，提供对水印实用性和有效性的彻底评估。同时，研究引入了一种简单有效的水印方法 Balanced Watermark (BW)，通过平衡添加水印信息来确保鲁棒性和不易察觉性。实验结果显示，BW 在所有评估维度上优于现有方法，并开源了代码以促进进一步研究。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.20802v1",
      "published_date": "2025-03-24 13:50:32 UTC",
      "updated_date": "2025-03-24 13:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:38:29.221201"
    },
    {
      "arxiv_id": "2503.18673v2",
      "title": "Any6D: Model-free 6D Pose Estimation of Novel Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Taeyeop Lee",
        "Bowen Wen",
        "Minjun Kang",
        "Gyuree Kang",
        "In So Kweon",
        "Kuk-Jin Yoon"
      ],
      "abstract": "We introduce Any6D, a model-free framework for 6D object pose estimation that\nrequires only a single RGB-D anchor image to estimate both the 6D pose and size\nof unknown objects in novel scenes. Unlike existing methods that rely on\ntextured 3D models or multiple viewpoints, Any6D leverages a joint object\nalignment process to enhance 2D-3D alignment and metric scale estimation for\nimproved pose accuracy. Our approach integrates a render-and-compare strategy\nto generate and refine pose hypotheses, enabling robust performance in\nscenarios with occlusions, non-overlapping views, diverse lighting conditions,\nand large cross-environment variations. We evaluate our method on five\nchallenging datasets: REAL275, Toyota-Light, HO3D, YCBINEOAT, and LM-O,\ndemonstrating its effectiveness in significantly outperforming state-of-the-art\nmethods for novel object pose estimation. Project page:\nhttps://taeyeop.com/any6d",
      "tldr_zh": "该论文提出 Any6D，一种无模型的框架，用于估计新型对象的 6D pose estimation，仅需一个 RGB-D 锚点图像即可同时计算对象的 6D 姿势和大小。Any6D 通过联合对象对齐过程和渲染并比较策略，提升 2D-3D 对齐精度和度量尺度估计，从而在遮挡、非重叠视图、多样照明条件及跨环境变化等复杂场景中实现鲁棒性能。在 REAL275、Toyota-Light、HO3D、YCBINEOAT 和 LM-O 等五个数据集上的实验表明，该方法显著优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025, Project Page: https://taeyeop.com/any6d",
      "pdf_url": "http://arxiv.org/pdf/2503.18673v2",
      "published_date": "2025-03-24 13:46:21 UTC",
      "updated_date": "2025-03-25 06:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:38:42.267692"
    },
    {
      "arxiv_id": "2503.18666v2",
      "title": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents",
      "title_zh": "AgentSpec: 针对安全可靠的 LLM 代理的可定制运行",
      "authors": [
        "Haoyu Wang",
        "Christopher M. Poskitt",
        "Jun Sun"
      ],
      "abstract": "Agents built on LLMs are increasingly deployed across diverse domains,\nautomating complex decision-making and task execution. However, their autonomy\nintroduces safety risks, including security vulnerabilities, legal violations,\nand unintended harmful actions. Existing mitigation methods, such as\nmodel-based safeguards and early enforcement strategies, fall short in\nrobustness, interpretability, and adaptability. To address these challenges, we\npropose AgentSpec, a lightweight domain-specific language for specifying and\nenforcing runtime constraints on LLM agents. With AgentSpec, users define\nstructured rules that incorporate triggers, predicates, and enforcement\nmechanisms, ensuring agents operate within predefined safety boundaries. We\nimplement AgentSpec across multiple domains, including code execution, embodied\nagents, and autonomous driving, demonstrating its adaptability and\neffectiveness. Our evaluation shows that AgentSpec successfully prevents unsafe\nexecutions in over 90% of code agent cases, eliminates all hazardous actions in\nembodied agent tasks, and enforces 100% compliance by autonomous vehicles\n(AVs). Despite its strong safety guarantees, AgentSpec remains computationally\nlightweight, with overheads in milliseconds. By combining interpretability,\nmodularity, and efficiency, AgentSpec provides a practical and scalable\nsolution for enforcing LLM agent safety across diverse applications. We also\nautomate the generation of rules using LLMs and assess their effectiveness. Our\nevaluation shows that the rules generated by OpenAI o1 achieve a precision of\n95.56% and recall of 70.96% for embodied agents, successfully identifying\n87.26% of the risky code, and prevent AVs from breaking laws in 5 out of 8\nscenarios.",
      "tldr_zh": "该论文提出 AgentSpec，一种轻量级的领域特定语言（domain-specific language），用于自定义运行时约束，确保 LLM agents 在安全边界内操作，解决现有方法在鲁棒性、解释性和适应性方面的不足。用户可以通过 AgentSpec 定义结构化的规则，包括 triggers、predicates 和 enforcement mechanisms，并在代码执行、embodied agents 和 autonomous driving 等领域进行实施。实验结果显示，AgentSpec 在超过90%的代码代理案例中防止不安全执行，在embodied agents 任务中消除所有危险行为，并在autonomous vehicles 中实现100%遵守；此外，使用 OpenAI o1 自动生成的规则表现出95.56%的精确度和70.96%的召回率，提供高效且可扩展的安全解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18666v2",
      "published_date": "2025-03-24 13:31:48 UTC",
      "updated_date": "2025-04-07 10:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:38:54.074515"
    },
    {
      "arxiv_id": "2503.18641v1",
      "title": "From Fragment to One Piece: A Survey on AI-Driven Graphic Design",
      "title_zh": "翻译失败",
      "authors": [
        "Xingxing Zou",
        "Wen Zhang",
        "Nanxuan Zhao"
      ],
      "abstract": "This survey provides a comprehensive overview of the advancements in\nArtificial Intelligence in Graphic Design (AIGD), focusing on integrating AI\ntechniques to support design interpretation and enhance the creative process.\nWe categorize the field into two primary directions: perception tasks, which\ninvolve understanding and analyzing design elements, and generation tasks,\nwhich focus on creating new design elements and layouts. The survey covers\nvarious subtasks, including visual element perception and generation, aesthetic\nand semantic understanding, layout analysis, and generation. We highlight the\nrole of large language models and multimodal approaches in bridging the gap\nbetween localized visual features and global design intent. Despite significant\nprogress, challenges remain to understanding human intent, ensuring\ninterpretability, and maintaining control over multilayered compositions. This\nsurvey serves as a guide for researchers, providing information on the current\nstate of AIGD and potential future\ndirections\\footnote{https://github.com/zhangtianer521/excellent\\_Intelligent\\_graphic\\_design}.",
      "tldr_zh": "这篇调查综述了 AI-Driven Graphic Design (AIGD) 的进展，聚焦于 AI 技术如何整合以支持设计解释和提升创意过程。论文将该领域分为 perception tasks（感知任务）和 generation tasks（生成任务），涵盖子任务如视觉元素感知与生成、美学和语义理解、布局分析与生成。Large language models 和 multimodal approaches 被突出作为关键工具，帮助桥接局部视觉特征与全局设计意图。尽管取得了显著进展，挑战仍包括理解人类意图、确保 interpretability 和控制 multilayered compositions。该调查为研究者提供 AIGD 的当前状态和潜在未来方向的指南。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18641v1",
      "published_date": "2025-03-24 13:05:09 UTC",
      "updated_date": "2025-03-24 13:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:39:06.367137"
    },
    {
      "arxiv_id": "2503.18629v1",
      "title": "Towards Human-Understandable Multi-Dimensional Concept Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Arne Grobrügge",
        "Niklas Kühl",
        "Gerhard Satzger",
        "Philipp Spitzer"
      ],
      "abstract": "Concept-based eXplainable AI (C-XAI) aims to overcome the limitations of\ntraditional saliency maps by converting pixels into human-understandable\nconcepts that are consistent across an entire dataset. A crucial aspect of\nC-XAI is completeness, which measures how well a set of concepts explains a\nmodel's decisions. Among C-XAI methods, Multi-Dimensional Concept Discovery\n(MCD) effectively improves completeness by breaking down the CNN latent space\ninto distinct and interpretable concept subspaces. However, MCD's explanations\ncan be difficult for humans to understand, raising concerns about their\npractical utility. To address this, we propose Human-Understandable\nMulti-dimensional Concept Discovery (HU-MCD). HU-MCD uses the Segment Anything\nModel for concept identification and implements a CNN-specific input masking\ntechnique to reduce noise introduced by traditional masking methods. These\nchanges to MCD, paired with the completeness relation, enable HU-MCD to enhance\nconcept understandability while maintaining explanation faithfulness. Our\nexperiments, including human subject studies, show that HU-MCD provides more\nprecise and reliable explanations than existing C-XAI methods. The code is\navailable at https://github.com/grobruegge/hu-mcd.",
      "tldr_zh": "本文提出 Human-Understandable Multi-Dimensional Concept Discovery (HU-MCD)，旨在改进传统 C-XAI 方法中 Multi-Dimensional Concept Discovery (MCD) 的问题，使解释更易于人类理解。HU-MCD 使用 Segment Anything Model 进行概念识别，并引入 CNN 特定的输入掩码技术，以减少噪声并保持解释的忠实度，同时提升概念的完整性。实验包括人类受试者研究，证明 HU-MCD 比现有 C-XAI 方法提供更精确和可靠的解释，为可解释 AI 应用奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18629v1",
      "published_date": "2025-03-24 12:45:52 UTC",
      "updated_date": "2025-03-24 12:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:39:18.365123"
    },
    {
      "arxiv_id": "2503.18627v1",
      "title": "Dig2DIG: Dig into Diffusion Information Gains for Image Fusion",
      "title_zh": "Dig2DIG：深入挖掘扩散信息增益用于图像融合",
      "authors": [
        "Bing Cao",
        "Baoshuo Cai",
        "Changqing Zhang",
        "Qinghua Hu"
      ],
      "abstract": "Image fusion integrates complementary information from multi-source images to\ngenerate more informative results. Recently, the diffusion model, which\ndemonstrates unprecedented generative potential, has been explored in image\nfusion. However, these approaches typically incorporate predefined multimodal\nguidance into diffusion, failing to capture the dynamically changing\nsignificance of each modality, while lacking theoretical guarantees. To address\nthis issue, we reveal a significant spatio-temporal imbalance in image\ndenoising; specifically, the diffusion model produces dynamic information gains\nin different image regions with denoising steps. Based on this observation, we\nDig into the Diffusion Information Gains (Dig2DIG) and theoretically derive a\ndiffusion-based dynamic image fusion framework that provably reduces the upper\nbound of the generalization error. Accordingly, we introduce diffusion\ninformation gains (DIG) to quantify the information contribution of each\nmodality at different denoising steps, thereby providing dynamic guidance\nduring the fusion process. Extensive experiments on multiple fusion scenarios\nconfirm that our method outperforms existing diffusion-based approaches in\nterms of both fusion quality and inference efficiency.",
      "tldr_zh": "这篇论文提出了Dig2DIG框架，通过挖掘扩散模型（diffusion model）的动态信息增益（DIG），解决图像融合中多模态指导的不足问题。作者发现扩散模型在图像去噪过程中存在时空不平衡，并理论推导出该框架能降低泛化误差的上界，同时引入DIG来量化每个模态在不同去噪步骤的信息贡献，提供动态融合指导。实验结果显示，Dig2DIG在多个图像融合场景中，融合质量和推理效率均优于现有扩散模型-based方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18627v1",
      "published_date": "2025-03-24 12:43:11 UTC",
      "updated_date": "2025-03-24 12:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:39:29.808950"
    },
    {
      "arxiv_id": "2503.18612v1",
      "title": "Adventurer: Exploration with BiGAN for Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yongshuai Liu",
        "Xin Liu"
      ],
      "abstract": "Recent developments in deep reinforcement learning have been very successful\nin learning complex, previously intractable problems. Sample efficiency and\nlocal optimality, however, remain significant challenges. To address these\nchallenges, novelty-driven exploration strategies have emerged and shown\npromising potential. Unfortunately, no single algorithm outperforms all others\nin all tasks and most of them struggle with tasks with high-dimensional and\ncomplex observations. In this work, we propose Adventurer, a novelty-driven\nexploration algorithm that is based on Bidirectional Generative Adversarial\nNetworks (BiGAN), where BiGAN is trained to estimate state novelty.\nIntuitively, a generator that has been trained on the distribution of visited\nstates should only be able to generate a state coming from the distribution of\nvisited states. As a result, novel states using the generator to reconstruct\ninput states from certain latent representations would lead to larger\nreconstruction errors. We show that BiGAN performs well in estimating state\nnovelty for complex observations. This novelty estimation method can be\ncombined with intrinsic-reward-based exploration. Our empirical results show\nthat Adventurer produces competitive results on a range of popular benchmark\ntasks, including continuous robotic manipulation tasks (e.g. Mujoco robotics)\nand high-dimensional image-based tasks (e.g. Atari games).",
      "tldr_zh": "这篇论文提出了Adventurer，一种基于Bidirectional Generative Adversarial Networks (BiGAN)的探索算法，用于提升深度强化学习的样本效率和避免局部最优问题。算法通过训练BiGAN来估计状态的新颖性，利用生成器重建输入状态的错误大小作为内在奖励，从而驱动代理探索未知区域。实验结果表明，Adventurer在Mujoco机器人任务和高维图像任务（如Atari游戏）等基准上表现出色，实现了与现有方法竞争性的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Applied Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2503.18612v1",
      "published_date": "2025-03-24 12:13:24 UTC",
      "updated_date": "2025-03-24 12:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:39:41.608240"
    },
    {
      "arxiv_id": "2503.18607v1",
      "title": "Reinforcement Learning in Switching Non-Stationary Markov Decision Processes: Algorithms and Convergence Analysis",
      "title_zh": "在切换非平稳马尔可夫决策过程中的强化学习：算法与收敛分析",
      "authors": [
        "Mohsen Amiri",
        "Sindri Magnússon"
      ],
      "abstract": "Reinforcement learning in non-stationary environments is challenging due to\nabrupt and unpredictable changes in dynamics, often causing traditional\nalgorithms to fail to converge. However, in many real-world cases,\nnon-stationarity has some structure that can be exploited to develop algorithms\nand facilitate theoretical analysis. We introduce one such structure, Switching\nNon-Stationary Markov Decision Processes (SNS-MDP), where environments switch\nover time based on an underlying Markov chain. Under a fixed policy, the value\nfunction of an SNS-MDP admits a closed-form solution determined by the Markov\nchain's statistical properties, and despite the inherent non-stationarity,\nTemporal Difference (TD) learning methods still converge to the correct value\nfunction. Furthermore, policy improvement can be performed, and it is shown\nthat policy iteration converges to the optimal policy. Moreover, since\nQ-learning converges to the optimal Q-function, it likewise yields the\ncorresponding optimal policy. To illustrate the practical advantages of\nSNS-MDPs, we present an example in communication networks where channel noise\nfollows a Markovian pattern, demonstrating how this framework can effectively\nguide decision-making in complex, time-varying contexts.",
      "tldr_zh": "这篇论文探讨了强化学习在非平稳环境中面临的挑战，引入了Switching Non-Stationary Markov Decision Processes (SNS-MDP)结构，其中环境动态基于一个Markov链进行切换。研究证明，在SNS-MDP下，Temporal Difference (TD) learning方法能收敛到正确价值函数，同时策略迭代和Q-learning算法分别收敛到最优策略和最优Q函数。作者通过通信网络中Markovian噪声的示例，展示了该框架在复杂时间变异环境中的实际决策指导优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18607v1",
      "published_date": "2025-03-24 12:05:30 UTC",
      "updated_date": "2025-03-24 12:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:39:54.530368"
    },
    {
      "arxiv_id": "2503.18595v1",
      "title": "Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition",
      "title_zh": "自适应单模态调控",
      "authors": [
        "Chengxiang Huang",
        "Yake Wei",
        "Zequn Yang",
        "Di Hu"
      ],
      "abstract": "Sensory training during the early ages is vital for human development.\nInspired by this cognitive phenomenon, we observe that the early training stage\nis also important for the multimodal learning process, where dataset\ninformation is rapidly acquired. We refer to this stage as the prime learning\nwindow. However, based on our observation, this prime learning window in\nmultimodal learning is often dominated by information-sufficient modalities,\nwhich in turn suppresses the information acquisition of\ninformation-insufficient modalities. To address this issue, we propose\nInformation Acquisition Regulation (InfoReg), a method designed to balance\ninformation acquisition among modalities. Specifically, InfoReg slows down the\ninformation acquisition process of information-sufficient modalities during the\nprime learning window, which could promote information acquisition of\ninformation-insufficient modalities. This regulation enables a more balanced\nlearning process and improves the overall performance of the multimodal\nnetwork. Experiments show that InfoReg outperforms related multimodal\nimbalanced methods across various datasets, achieving superior model\nperformance. The code is available at\nhttps://github.com/GeWu-Lab/InfoReg_CVPR2025.",
      "tldr_zh": "本研究受人类早期感官训练启发，观察到多模态学习中的 prime learning window 阶段常被信息充足模态主导，从而抑制信息不足模态的信息获取。针对这一问题，提出 Information Acquisition Regulation (InfoReg) 方法，通过在 prime learning window 期间减缓信息充足模态的获取过程，促进各模态的平衡学习，从而提升多模态网络的整体性能。实验结果表明，InfoReg 在各种数据集上优于相关多模态不平衡方法，实现了显著的模型性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10pages, 16 figures, CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18595v1",
      "published_date": "2025-03-24 11:52:57 UTC",
      "updated_date": "2025-03-24 11:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:40:06.697781"
    },
    {
      "arxiv_id": "2503.18594v1",
      "title": "ClinText-SP and RigoBERTa Clinical: a new set of open resources for Spanish Clinical NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Guillem García Subies",
        "Álvaro Barbero Jiménez",
        "Paloma Martínez Fernández"
      ],
      "abstract": "We present a novel contribution to Spanish clinical natural language\nprocessing by introducing the largest publicly available clinical corpus,\nClinText-SP, along with a state-of-the-art clinical encoder language model,\nRigoBERTa Clinical. Our corpus was meticulously curated from diverse open\nsources, including clinical cases from medical journals and annotated corpora\nfrom shared tasks, providing a rich and diverse dataset that was previously\ndifficult to access. RigoBERTa Clinical, developed through domain-adaptive\npretraining on this comprehensive dataset, significantly outperforms existing\nmodels on multiple clinical NLP benchmarks. By publicly releasing both the\ndataset and the model, we aim to empower the research community with robust\nresources that can drive further advancements in clinical NLP and ultimately\ncontribute to improved healthcare applications.",
      "tldr_zh": "本研究介绍了最大的公开西班牙语临床语料库 ClinText-SP，以及先进的临床编码语言模型 RigoBERTa Clinical，以推动西班牙语临床 NLP 的发展。ClinText-SP 通过从医疗期刊的临床案例和共享任务的标注语料等多样来源精心整理而成，提供了一个之前难以获取的丰富数据集。RigoBERTa Clinical 通过在该数据集上进行领域适应预训练，在多个临床 NLP 基准上显著优于现有模型。通过公开发布这些资源，研究团队旨在为社区提供强大工具，促进临床 NLP 的进一步创新，并最终提升医疗应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18594v1",
      "published_date": "2025-03-24 11:52:17 UTC",
      "updated_date": "2025-03-24 11:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:40:17.707560"
    },
    {
      "arxiv_id": "2503.18592v1",
      "title": "The Role of Artificial Intelligence in Enhancing Insulin Recommendations and Therapy Outcomes",
      "title_zh": "人工智能在增强胰岛素推荐和治疗效果中的作用",
      "authors": [
        "Maria Panagiotou",
        "Knut Stroemmen",
        "Lorenzo Brigato",
        "Bastiaan E. de Galan",
        "Stavroula Mougiakakou"
      ],
      "abstract": "The growing worldwide incidence of diabetes requires more effective\napproaches for managing blood glucose levels. Insulin delivery systems have\nadvanced significantly, with artificial intelligence (AI) playing a key role in\nimproving their precision and adaptability. AI algorithms, particularly those\nbased on reinforcement learning, allow for personalised insulin dosing by\ncontinuously adapting to an individual's responses. Despite these advancements,\nchallenges such as data privacy, algorithm transparency, and accessibility\nstill need to be addressed. Continued progress and validation in AI-driven\ninsulin delivery systems promise to improve therapy outcomes further, offering\npeople more effective and individualised management of their diabetes. This\npaper presents an overview of current strategies, key challenges, and future\ndirections.",
      "tldr_zh": "人工智能(AI)在提升胰岛素推荐和治疗效果方面发挥关键作用，通过基于 reinforcement learning 的算法实现个性化剂量调整，并持续适应个体的血糖反应。该方法有助于改善糖尿病管理，但仍面临数据隐私、算法透明性和可访问性等挑战。尽管存在这些障碍，AI 驱动的胰岛素递送系统有望进一步优化治疗结果，提供更有效的个性化管理。本文概述了当前策略、关键挑战和未来方向。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "physics.med-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18592v1",
      "published_date": "2025-03-24 11:50:14 UTC",
      "updated_date": "2025-03-24 11:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:40:30.553757"
    },
    {
      "arxiv_id": "2503.19001v1",
      "title": "DisentTalk: Cross-lingual Talking Face Generation via Semantic Disentangled Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Kangwei Liu",
        "Junwu Liu",
        "Yun Cao",
        "Jinlin Guo",
        "Xiaowei Yi"
      ],
      "abstract": "Recent advances in talking face generation have significantly improved facial\nanimation synthesis. However, existing approaches face fundamental limitations:\n3DMM-based methods maintain temporal consistency but lack fine-grained regional\ncontrol, while Stable Diffusion-based methods enable spatial manipulation but\nsuffer from temporal inconsistencies. The integration of these approaches is\nhindered by incompatible control mechanisms and semantic entanglement of facial\nrepresentations. This paper presents DisentTalk, introducing a data-driven\nsemantic disentanglement framework that decomposes 3DMM expression parameters\ninto meaningful subspaces for fine-grained facial control. Building upon this\ndisentangled representation, we develop a hierarchical latent diffusion\narchitecture that operates in 3DMM parameter space, integrating region-aware\nattention mechanisms to ensure both spatial precision and temporal coherence.\nTo address the scarcity of high-quality Chinese training data, we introduce\nCHDTF, a Chinese high-definition talking face dataset. Extensive experiments\nshow superior performance over existing methods across multiple metrics,\nincluding lip synchronization, expression quality, and temporal consistency.\nProject Page: https://kangweiiliu.github.io/DisentTalk.",
      "tldr_zh": "本文提出 DisentTalk，一种基于语义解耦扩散模型的跨语言 talking face 生成框架，旨在解决现有方法的局限性，如 3DMM-based 方法缺乏精细区域控制，以及 Stable Diffusion-based 方法的时间不一致问题。该框架通过数据驱动的语义解耦，将 3DMM 表情参数分解成有意义的子空间，并采用分层潜在扩散架构结合区域感知注意力机制，实现精确的空间操控和时间连贯性。为应对中文数据短缺，作者引入了 CHDTF 数据集进行训练。实验结果显示，DisentTalk 在唇同步、表情质量和时间一致性等指标上显著优于基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.19001v1",
      "published_date": "2025-03-24 11:46:34 UTC",
      "updated_date": "2025-03-24 11:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:40:43.255033"
    },
    {
      "arxiv_id": "2504.03695v1",
      "title": "Are Anxiety Detection Models Generalizable? A Cross-Activity and Cross-Population Study Using Wearables",
      "title_zh": "翻译失败",
      "authors": [
        "Nilesh Kumar Sahu",
        "Snehil Gupta",
        "Haroon R Lone"
      ],
      "abstract": "Anxiety-provoking activities, such as public speaking, can trigger heightened\nanxiety responses in individuals with anxiety disorders. Recent research\nsuggests that physiological signals, including electrocardiogram (ECG) and\nelectrodermal activity (EDA), collected via wearable devices, can be used to\ndetect anxiety in such contexts through machine learning models. However, the\ngeneralizability of these anxiety prediction models across different activities\nand diverse populations remains underexplored-an essential step for assessing\nmodel bias and fostering user trust in broader applications. To address this\ngap, we conducted a study with 111 participants who engaged in three\nanxiety-provoking activities. Utilizing both our collected dataset and two\nwell-known publicly available datasets, we evaluated the generalizability of\nanxiety detection models within participants (for both same-activity and\ncross-activity scenarios) and across participants (within-activity and\ncross-activity). In total, we trained and tested more than 3348 anxiety\ndetection models (using six classifiers, 31 feature sets, and 18 train-test\nconfigurations). Our results indicate that three key metrics-AUROC, recall for\nanxious states, and recall for non-anxious states-were slightly above the\nbaseline score of 0.5. The best AUROC scores ranged from 0.62 to 0.73, with\nrecall for the anxious class spanning 35.19% to 74.3%. Interestingly, model\nperformance (as measured by AUROC) remained relatively stable across different\nactivities and participant groups, though recall for the anxious class did\nexhibit some variation.",
      "tldr_zh": "这篇论文探讨了使用可穿戴设备（如 ECG 和 EDA）检测焦虑的机器学习模型在不同活动和人群间的泛化能力，旨在评估模型偏见并提升用户信任。研究通过111名参与者参与三种引发焦虑的活动，并结合自有数据集和公开数据集，训练并测试了超过3348个模型（使用六种分类器、31种特征集和18种训练测试配置）。结果显示，模型的AUROC得分范围为0.62至0.73，anxious states的recall从35.19%至74.3%，性能在跨活动和跨人群场景中相对稳定，但anxious class的recall存在一定变异，突显了模型局限性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03695v1",
      "published_date": "2025-03-24 11:43:34 UTC",
      "updated_date": "2025-03-24 11:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:40:54.525670"
    },
    {
      "arxiv_id": "2503.18578v2",
      "title": "Galaxy Walker: Geometry-aware VLMs For Galaxy-scale Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Chen",
        "Xingcheng Fu",
        "Yisen Gao",
        "Haodong Qian",
        "Yuecen Wei",
        "Kun Yan",
        "Haoyi Zhou",
        "Jianxin Li"
      ],
      "abstract": "Modern vision-language models (VLMs) develop patch embedding and convolution\nbackbone within vector space, especially Euclidean ones, at the very founding.\nWhen expanding VLMs to a galaxy scale for understanding astronomical phenomena,\nthe integration of spherical space for planetary orbits and hyperbolic spaces\nfor black holes raises two formidable challenges. a) The current pre-training\nmodel is confined to Euclidean space rather than a comprehensive geometric\nembedding. b) The predominant architecture lacks suitable backbones for\nanisotropic physical geometries. In this paper, we introduced Galaxy-Walker, a\ngeometry-aware VLM, for the universe-level vision understanding tasks. We\nproposed the geometry prompt that generates geometry tokens by random walks\nacross diverse spaces on a multi-scale physical graph, along with a geometry\nadapter that compresses and reshapes the space anisotropy in a\nmixture-of-experts manner. Extensive experiments demonstrate the effectiveness\nof our approach, with Galaxy-Walker achieving state-of-the-art performance in\nboth galaxy property estimation ($R^2$ scores up to $0.91$) and morphology\nclassification tasks (up to $+0.17$ F1 improvement in challenging features),\nsignificantly outperforming both domain-specific models and general-purpose\nVLMs.",
      "tldr_zh": "这篇论文介绍了 Galaxy Walker，一种 geometry-aware VLM（视觉语言模型），旨在解决 VLMs 在星系规模宇宙理解中面临的挑战，如局限于 Euclidean space 而无法有效整合球面空间和双曲空间。论文提出 geometry prompt，通过在多尺度物理图上进行随机游走生成几何标记，以及 geometry adapter，以 mixture-of-experts 方式压缩和重塑空间各向异性。实验结果表明，Galaxy Walker 在星系属性估计任务中取得最高 R² 得分达 0.91，并在形态分类任务中较基线模型提升 F1 分数高达 +0.17，显著优于领域特定和通用 VLMs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18578v2",
      "published_date": "2025-03-24 11:35:56 UTC",
      "updated_date": "2025-04-30 06:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:41:06.949960"
    },
    {
      "arxiv_id": "2503.18572v1",
      "title": "Identifying and Characterising Higher Order Interactions in Mobility Networks Using Hypergraphs",
      "title_zh": "使用超图识别与表征移动网络中的高阶交互",
      "authors": [
        "Prathyush Sambaturu",
        "Bernardo Gutierrez",
        "Moritz U. G. Kraemer"
      ],
      "abstract": "Understanding human mobility is essential for applications ranging from urban\nplanning to public health. Traditional mobility models such as flow networks\nand colocation matrices capture only pairwise interactions between discrete\nlocations, overlooking higher-order relationships among locations (i.e.,\nmobility flow among two or more locations). To address this, we propose\nco-visitation hypergraphs, a model that leverages temporal observation windows\nto extract group interactions between locations from individual mobility\ntrajectory data. Using frequent pattern mining, our approach constructs\nhypergraphs that capture dynamic mobility behaviors across different spatial\nand temporal scales. We validate our method on a publicly available mobility\ndataset and demonstrate its effectiveness in analyzing city-scale mobility\npatterns, detecting shifts during external disruptions such as extreme weather\nevents, and examining how a location's connectivity (degree) relates to the\nnumber of points of interest (POIs) within it. Our results demonstrate that our\nhypergraph-based mobility analysis framework is a valuable tool with potential\napplications in diverse fields such as public health, disaster resilience, and\nurban planning.",
      "tldr_zh": "本研究针对传统移动模型（如 flow networks 和 colocation matrices）仅捕捉位置间成对互动的局限性，提出了一种基于 co-visitation hypergraphs 的框架，用于识别和表征移动网络中的高阶互动。该方法利用 temporal observation windows 从个体移动轨迹数据中提取群组互动，并结合 frequent pattern mining 构建动态 hypergraphs，以分析不同空间和时间尺度的移动行为。在公开数据集上验证后，结果显示该框架能有效分析城市规模移动模式、检测外部干扰（如极端天气事件），并揭示位置连通性（degree）与兴趣点（POIs）数量的相关性。该框架为公共卫生、灾害韧性和城市规划等领域提供了有价值的工具。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DB",
        "cs.DM",
        "math.CO"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18572v1",
      "published_date": "2025-03-24 11:29:06 UTC",
      "updated_date": "2025-03-24 11:29:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:41:18.351830"
    },
    {
      "arxiv_id": "2503.18569v1",
      "title": "Anchor-based oversampling for imbalanced tabular data via contrastive and adversarial learning",
      "title_zh": "基于锚点的过采样方法",
      "authors": [
        "Hadi Mohammadi",
        "Ehsan Nazerfard",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "Imbalanced data represent a distribution with more frequencies of one class\n(majority) than the other (minority). This phenomenon occurs across various\ndomains, such as security, medical care and human activity. In imbalanced\nlearning, classification algorithms are typically inclined to classify the\nmajority class accurately, resulting in artificially high accuracy rates. As a\nresult, many minority samples are mistakenly labelled as majority-class\ninstances, resulting in a bias that benefits the majority class. This study\npresents a framework based on boundary anchor samples to tackle the imbalance\nlearning challenge. First, we select and use anchor samples to train a\nmultilayer perceptron (MLP) classifier, which acts as a prior knowledge model\nand aids the adversarial and contrastive learning procedures. Then, we designed\na novel deep generative model called Anchor Stabilized Conditional Generative\nAdversarial Network or Anch-SCGAN in short. Anch-SCGAN is supported with two\ngenerators for the minority and majority classes and a discriminator\nincorporating additional class-specific information from the pre-trained\nfeature extractor MLP. In addition, we facilitate the generator's training\nprocedure in two ways. First, we define a new generator loss function based on\nreprocessed anchor samples and contrastive learning. Second, we apply a scoring\nstrategy to stabilize the adversarial training part in generators. We train\nAnch-SCGAN and further finetune it with anchor samples to improve the precision\nof the generated samples. Our experiments on 16 real-world imbalanced datasets\nillustrate that Anch-SCGAN outperforms the renowned methods in imbalanced\nlearning.",
      "tldr_zh": "这篇论文针对不平衡表格数据（imbalanced tabular data）的问题，提出了一种基于边界锚样本的过采样框架，通过对比学习（contrastive learning）和对抗学习（adversarial learning）来生成高质量的少数类样本。具体方法包括先用锚样本训练多层感知器（MLP）作为先验知识模型，然后设计了新型深度生成模型Anchor Stabilized Conditional Generative Adversarial Network（Anch-SCGAN），该模型配备两个生成器（针对少数类和多数类）和一个整合类特定信息的判别器，并通过新损失函数和评分策略优化训练。实验结果显示，在16个真实世界数据集上，Anch-SCGAN 优于现有方法，提升了分类准确性和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18569v1",
      "published_date": "2025-03-24 11:25:21 UTC",
      "updated_date": "2025-03-24 11:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:41:31.487221"
    },
    {
      "arxiv_id": "2503.18565v1",
      "title": "Distil-xLSTM: Learning Attention Mechanisms through Recurrent Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoul Majid O. Thiombiano",
        "Brahim Hnich",
        "Ali Ben Mrad",
        "Mohamed Wiem Mkaouer"
      ],
      "abstract": "The current era of Natural Language Processing (NLP) is dominated by\nTransformer models. However, novel architectures relying on recurrent\nmechanisms, such as xLSTM and Mamba, have been proposed as alternatives to\nattention-based models. Although computation is done differently than with the\nattention mechanism mechanism, these recurrent models yield good results and\nsometimes even outperform state-of-the-art attention-based models. In this\nwork, we propose Distil-xLSTM, an xLSTM-based Small Language Model (SLM)\ntrained by distilling knowledge from a Large Language Model (LLM) that shows\npromising results while being compute and scale efficient. Our Distil-xLSTM\nfocuses on approximating a transformer-based model attention parametrization\nusing its recurrent sequence mixing components and shows good results with\nminimal training.",
      "tldr_zh": "本文提出 Distil-xLSTM，一种基于 xLSTM 的小型语言模型 (SLM)，旨在通过循环结构学习近似 Transformer 的注意力机制，以应对当前 NLP 领域的模型效率挑战。该模型通过知识蒸馏 (knowledge distillation) 从大型语言模型 (LLM) 训练，仅需最小训练即可实现高效序列混合。实验结果显示，Distil-xLSTM 在计算和规模效率方面表现出色，与基于 attention 的模型相比，提供了可比或更优的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18565v1",
      "published_date": "2025-03-24 11:18:25 UTC",
      "updated_date": "2025-03-24 11:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:41:42.349010"
    },
    {
      "arxiv_id": "2503.18562v1",
      "title": "Self-Reported Confidence of Large Language Models in Gastroenterology: Analysis of Commercial, Open-Source, and Quantized Models",
      "title_zh": "大型语言模型在胃肠病学中的自我报告置信度：商业、开源和量化模型的分析",
      "authors": [
        "Nariman Naderi",
        "Seyed Amir Ahmad Safavi-Naini",
        "Thomas Savage",
        "Zahra Atf",
        "Peter Lewis",
        "Girish Nadkarni",
        "Ali Soroush"
      ],
      "abstract": "This study evaluated self-reported response certainty across several large\nlanguage models (GPT, Claude, Llama, Phi, Mistral, Gemini, Gemma, and Qwen)\nusing 300 gastroenterology board-style questions. The highest-performing models\n(GPT-o1 preview, GPT-4o, and Claude-3.5-Sonnet) achieved Brier scores of\n0.15-0.2 and AUROC of 0.6. Although newer models demonstrated improved\nperformance, all exhibited a consistent tendency towards overconfidence.\nUncertainty estimation presents a significant challenge to the safe use of LLMs\nin healthcare. Keywords: Large Language Models; Confidence Elicitation;\nArtificial Intelligence; Gastroenterology; Uncertainty Quantification",
      "tldr_zh": "这篇论文评估了多个大型语言模型（LLMs），包括 GPT、Claude、Llama 等，在 300 个胃肠病学板式问题上的自我报告响应确定性。表现最佳的模型如 GPT-o1 preview、GPT-4o 和 Claude-3.5-Sonnet 取得了 0.15-0.2 的 Brier scores 和 0.6 的 AUROC，尽管新模型性能有所改善，但所有模型都表现出过度自信的倾向。不确定性量化（Uncertainty Quantification）是 LLMs 在医疗领域安全应用的关键挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages, 5 figures, 1 table, 7 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18562v1",
      "published_date": "2025-03-24 11:16:41 UTC",
      "updated_date": "2025-03-24 11:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:41:55.273904"
    },
    {
      "arxiv_id": "2503.18552v1",
      "title": "EvAnimate: Event-conditioned Image-to-Video Generation for Human Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Qu",
        "Ming Li",
        "Xiaoming Chen",
        "Tongliang Liu"
      ],
      "abstract": "Conditional human animation transforms a static reference image into a\ndynamic sequence by applying motion cues such as poses. These motion cues are\ntypically derived from video data but are susceptible to limitations including\nlow temporal resolution, motion blur, overexposure, and inaccuracies under\nlow-light conditions. In contrast, event cameras provide data streams with\nexceptionally high temporal resolution, a wide dynamic range, and inherent\nresistance to motion blur and exposure issues. In this work, we propose\nEvAnimate, a framework that leverages event streams as motion cues to animate\nstatic human images. Our approach employs a specialized event representation\nthat transforms asynchronous event streams into 3-channel slices with\ncontrollable slicing rates and appropriate slice density, ensuring\ncompatibility with diffusion models. Subsequently, a dual-branch architecture\ngenerates high-quality videos by harnessing the inherent motion dynamics of the\nevent streams, thereby enhancing both video quality and temporal consistency.\nSpecialized data augmentation strategies further enhance cross-person\ngeneralization. Finally, we establish a new benchmarking, including simulated\nevent data for training and validation, and a real-world event dataset\ncapturing human actions under normal and extreme scenarios. The experiment\nresults demonstrate that EvAnimate achieves high temporal fidelity and robust\nperformance in scenarios where traditional video-derived cues fall short.",
      "tldr_zh": "该论文提出 EvAnimate 框架，利用 event streams 作为运动线索，将静态人类图像转化为动态视频序列，从而克服传统视频数据（如低时间分辨率和运动模糊）的局限性。框架采用一种专门的事件表示，将异步事件流转化为兼容 diffusion models 的 3 通道切片，并通过 dual-branch architecture 利用事件流的运动动态生成高质量视频，同时结合数据增强策略提升跨人泛化。论文建立了新的基准数据集，包括模拟和真实世界事件数据，并在实验中证明 EvAnimate 实现了高时间保真度，并在极端场景中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18552v1",
      "published_date": "2025-03-24 11:05:41 UTC",
      "updated_date": "2025-03-24 11:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:42:06.327002"
    },
    {
      "arxiv_id": "2503.18551v1",
      "title": "Discriminative protein sequence modelling with Latent Space Diffusion",
      "title_zh": "基于潜在空间扩散的判别性蛋白质序列建模",
      "authors": [
        "Eoin Quinn",
        "Ghassene Jebali",
        "Maxime Seince",
        "Oliver Bent"
      ],
      "abstract": "We explore a framework for protein sequence representation learning that\ndecomposes the task between manifold learning and distributional modelling.\nSpecifically we present a Latent Space Diffusion architecture which combines a\nprotein sequence autoencoder with a denoising diffusion model operating on its\nlatent space. We obtain a one-parameter family of learned representations from\nthe diffusion model, along with the autoencoder's latent representation. We\npropose and evaluate two autoencoder architectures: a homogeneous model forcing\namino acids of the same type to be identically distributed in the latent space,\nand an inhomogeneous model employing a noise-based variant of masking. As a\nbaseline we take a latent space learned by masked language modelling, and\nevaluate discriminative capability on a range of protein property prediction\ntasks. Our finding is twofold: the diffusion models trained on both our\nproposed variants display higher discriminative power than the one trained on\nthe masked language model baseline, none of the diffusion representations\nachieve the performance of the masked language model embeddings themselves.",
      "tldr_zh": "本研究提出了一种基于Latent Space Diffusion的蛋白质序列表示学习框架，将任务分解为流形学习和分布建模。该框架结合了蛋白质序列autoencoder和在潜在空间上操作的denoising diffusion model，生成一系列学得的表示，包括两种autoencoder架构：同质模型（forcing amino acids of the same type to be identically distributed）和非同质模型（employing a noise-based variant of masking）。与masked language modelling基线相比，扩散模型在蛋白质属性预测任务上显示出更高的区分能力；然而，没有任何扩散表示达到masked language model嵌入的性能水平。总的来说，该方法为蛋白质序列建模提供了新颖的改进途径，但仍需进一步优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18551v1",
      "published_date": "2025-03-24 11:03:57 UTC",
      "updated_date": "2025-03-24 11:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:42:17.692305"
    },
    {
      "arxiv_id": "2503.18549v1",
      "title": "RLCAD: Reinforcement Learning Training Gym for Revolution Involved CAD Command Sequence Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolong Yin",
        "Xingyu Lu",
        "Jiahang Shen",
        "Jingzhe Ni",
        "Hailong Li",
        "Ruofeng Tong",
        "Min Tang",
        "Peng Du"
      ],
      "abstract": "A CAD command sequence is a typical parametric design paradigm in 3D CAD\nsystems where a model is constructed by overlaying 2D sketches with operations\nsuch as extrusion, revolution, and Boolean operations. Although there is\ngrowing academic interest in the automatic generation of command sequences,\nexisting methods and datasets only support operations such as 2D sketching,\nextrusion,and Boolean operations. This limitation makes it challenging to\nrepresent more complex geometries. In this paper, we present a reinforcement\nlearning (RL) training environment (gym) built on a CAD geometric engine. Given\nan input boundary representation (B-Rep) geometry, the policy network in the RL\nalgorithm generates an action. This action, along with previously generated\nactions, is processed within the gym to produce the corresponding CAD geometry,\nwhich is then fed back into the policy network. The rewards, determined by the\ndifference between the generated and target geometries within the gym, are used\nto update the RL network. Our method supports operations beyond sketches,\nBoolean, and extrusion, including revolution operations. With this training\ngym, we achieve state-of-the-art (SOTA) quality in generating command sequences\nfrom B-Rep geometries. In addition, our method can significantly improve the\nefficiency of command sequence generation by a factor of 39X compared with the\nprevious training gym.",
      "tldr_zh": "该论文提出了RLCAD，一种基于强化学习（RL）的训练环境，用于生成涉及旋转操作的CAD命令序列，以解决现有方法仅支持2D草图、挤出和布尔操作的局限性。该环境以边界表示（B-Rep）几何作为输入，RL策略网络生成动作，通过CAD几何引擎处理生成对应的几何形状，并基于生成几何与目标几何的差异计算奖励来更新网络。与现有方法相比，RLCAD支持更多操作，如旋转，支持了更复杂的几何表示，并在命令序列生成质量上达到state-of-the-art (SOTA)水平，同时将效率提高了39倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18549v1",
      "published_date": "2025-03-24 11:01:05 UTC",
      "updated_date": "2025-03-24 11:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:42:30.009355"
    },
    {
      "arxiv_id": "2503.18542v1",
      "title": "An Identity and Interaction Based Network Forensic Analysis",
      "title_zh": "基于身份和交互的网络取证分析",
      "authors": [
        "Nathan Clarke",
        "Gaseb Alotibi",
        "Dany Joy",
        "Fudong Li",
        "Steven Furnell",
        "Ali Alshumrani",
        "Hussan Mohammed"
      ],
      "abstract": "In todays landscape of increasing electronic crime, network forensics plays a\npivotal role in digital investigations. It aids in understanding which systems\nto analyse and as a supplement to support evidence found through more\ntraditional computer based investigations. However, the nature and\nfunctionality of the existing Network Forensic Analysis Tools (NFATs) fall\nshort compared to File System Forensic Analysis Tools (FS FATs) in providing\nusable data. The analysis tends to focus upon IP addresses, which are not\nsynonymous with user identities, a point of significant interest to\ninvestigators. This paper presents several experiments designed to create a\nnovel NFAT approach that can identify users and understand how they are using\nnetwork based applications whilst the traffic remains encrypted. The\nexperiments build upon the prior art and investigate how effective this\napproach is in classifying users and their actions. Utilising an in-house\ndataset composed of 50 million packers, the experiments are formed of three\nincremental developments that assist in improving performance. Building upon\nthe successful experiments, a proposed NFAT interface is presented to\nillustrate the ease at which investigators would be able to ask relevant\nquestions of user interactions. The experiments profiled across 27 users, has\nyielded an average 93.3% True Positive Identification Rate (TPIR), with 41% of\nusers experiencing 100% TPIR. Skype, Wikipedia and Hotmail services achieved a\nnotably high level of recognition performance. The study has developed and\nevaluated an approach to analyse encrypted network traffic more effectively\nthrough the modelling of network traffic and to subsequently visualise these\ninteractions through a novel network forensic analysis tool.",
      "tldr_zh": "本论文针对现有网络取证分析工具（NFATs）在识别用户身份方面的不足，提出了一种基于身份和交互的新型网络取证分析方法，能够理解用户在加密流量中的行为。研究通过三个增量实验，利用包含5000万包的自有数据集，对27名用户的网络流量进行建模和分类，实现了平均93.3%的真正阳性识别率（TPIR），其中41%的用户达到100%识别率，且Skype、Wikipedia和Hotmail服务表现出色。最终，该方法开发了一个新型NFAT接口，便于调查者可视化和查询用户互动，从而提升加密网络流量的分析效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18542v1",
      "published_date": "2025-03-24 10:52:23 UTC",
      "updated_date": "2025-03-24 10:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:42:42.439962"
    },
    {
      "arxiv_id": "2503.18541v1",
      "title": "UniPCGC: Towards Practical Point Cloud Geometry Compression via an Efficient Unified Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Kangli Wang",
        "Wei Gao"
      ],
      "abstract": "Learning-based point cloud compression methods have made significant progress\nin terms of performance. However, these methods still encounter challenges\nincluding high complexity, limited compression modes, and a lack of support for\nvariable rate, which restrict the practical application of these methods. In\norder to promote the development of practical point cloud compression, we\npropose an efficient unified point cloud geometry compression framework, dubbed\nas UniPCGC. It is a lightweight framework that supports lossy compression,\nlossless compression, variable rate and variable complexity. First, we\nintroduce the Uneven 8-Stage Lossless Coder (UELC) in the lossless mode, which\nallocates more computational complexity to groups with higher coding\ndifficulty, and merges groups with lower coding difficulty. Second, Variable\nRate and Complexity Module (VRCM) is achieved in the lossy mode through joint\nadoption of a rate modulation module and dynamic sparse convolution. Finally,\nthrough the dynamic combination of UELC and VRCM, we achieve lossy compression,\nlossless compression, variable rate and complexity within a unified framework.\nCompared to the previous state-of-the-art method, our method achieves a\ncompression ratio (CR) gain of 8.1\\% on lossless compression, and a Bjontegaard\nDelta Rate (BD-Rate) gain of 14.02\\% on lossy compression, while also\nsupporting variable rate and variable complexity.",
      "tldr_zh": "这篇论文提出了UniPCGC，一种高效的统一点云几何压缩框架，旨在解决现有学习-based方法的复杂性高、压缩模式有限和缺乏可变速率支持等问题，支持有损压缩、无损压缩、可变速率和可变复杂度。框架的关键组件包括Uneven 8-Stage Lossless Coder (UELC)，用于无损模式通过不均等分配计算复杂度来优化编码，以及Variable Rate and Complexity Module (VRCM)，用于有损模式结合速率调节和动态稀疏卷积实现灵活性。通过动态组合UELC和VRCM，UniPCGC在统一框架内实现了这些功能。与最先进方法相比，该框架在无损压缩上提升了8.1%的压缩比(CR)，在有损压缩上获得了14.02%的BD-Rate收益。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18541v1",
      "published_date": "2025-03-24 10:51:28 UTC",
      "updated_date": "2025-03-24 10:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:42:54.742387"
    },
    {
      "arxiv_id": "2503.18540v1",
      "title": "HiRes-FusedMIM: A High-Resolution RGB-DSM Pre-trained Model for Building-Level Remote Sensing Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Guneet Mutreja",
        "Philipp Schuegraf",
        "Ksenia Bittner"
      ],
      "abstract": "Recent advances in self-supervised learning have led to the development of\nfoundation models that have significantly advanced performance in various\ncomputer vision tasks. However, despite their potential, these models often\noverlook the crucial role of high-resolution digital surface models (DSMs) in\nunderstanding urban environments, particularly for building-level analysis,\nwhich is essential for applications like digital twins. To address this gap, we\nintroduce HiRes-FusedMIM, a novel pre-trained model specifically designed to\nleverage the rich information contained within high-resolution RGB and DSM\ndata. HiRes-FusedMIM utilizes a dual-encoder simple masked image modeling\n(SimMIM) architecture with a multi-objective loss function that combines\nreconstruction and contrastive objectives, enabling it to learn powerful, joint\nrepresentations from both modalities. We conducted a comprehensive evaluation\nof HiRes-FusedMIM on a diverse set of downstream tasks, including\nclassification, semantic segmentation, and instance segmentation. Our results\ndemonstrate that: 1) HiRes-FusedMIM outperforms previous state-of-the-art\ngeospatial methods on several building-related datasets, including WHU Aerial\nand LoveDA, demonstrating its effectiveness in capturing and leveraging\nfine-grained building information; 2) Incorporating DSMs during pre-training\nconsistently improves performance compared to using RGB data alone,\nhighlighting the value of elevation information for building-level analysis; 3)\nThe dual-encoder architecture of HiRes-FusedMIM, with separate encoders for RGB\nand DSM data, significantly outperforms a single-encoder model on the Vaihingen\nsegmentation task, indicating the benefits of learning specialized\nrepresentations for each modality. To facilitate further research and\napplications in this direction, we will publicly release the trained model\nweights.",
      "tldr_zh": "本文提出 HiRes-FusedMIM，一种针对高分辨率 RGB-DSM 数据的预训练模型，旨在提升建筑级遥感应用中的性能，如数字孪生。模型采用双编码器简单掩码图像建模 (SimMIM) 架构，并结合重建和对比损失函数，从 RGB 和 DSM 数据中学习联合表示。实验评估显示，HiRes-FusedMIM 在分类、语义分割和实例分割任务上优于现有方法，包括在 WHU Aerial 和 LoveDA 数据集上的表现提升，并证明了加入 DSM 数据能显著改善结果。作者将公开模型权重，以推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18540v1",
      "published_date": "2025-03-24 10:49:55 UTC",
      "updated_date": "2025-03-24 10:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:43:06.815529"
    },
    {
      "arxiv_id": "2503.18539v1",
      "title": "Natural Language Processing for Electronic Health Records in Scandinavian Languages: Norwegian, Swedish, and Danish",
      "title_zh": "翻译失败",
      "authors": [
        "Ashenafi Zebene Woldaregay",
        "Jørgen Aarmo Lund",
        "Phuong Dinh Ngo",
        "Mariyam Tayefi",
        "Joel Burman",
        "Stine Hansen",
        "Martin Hylleholt Sillesen",
        "Hercules Dalianis",
        "Robert Jenssen",
        "Lindsetmo Rolf Ole",
        "Karl Øyvind Mikalsen"
      ],
      "abstract": "Background: Clinical natural language processing (NLP) refers to the use of\ncomputational methods for extracting, processing, and analyzing unstructured\nclinical text data, and holds a huge potential to transform healthcare in\nvarious clinical tasks. Objective: The study aims to perform a systematic\nreview to comprehensively assess and analyze the state-of-the-art NLP methods\nfor the mainland Scandinavian clinical text. Method: A literature search was\nconducted in various online databases including PubMed, ScienceDirect, Google\nScholar, ACM digital library, and IEEE Xplore between December 2022 and\nFebruary 2024. Further, relevant references to the included articles were also\nused to solidify our search. The final pool includes articles that conducted\nclinical NLP in the mainland Scandinavian languages and were published in\nEnglish between 2010 and 2024. Results: Out of the 113 articles, 18% (n=21)\nfocus on Norwegian clinical text, 64% (n=72) on Swedish, 10% (n=11) on Danish,\nand 8% (n=9) focus on more than one language. Generally, the review identified\npositive developments across the region despite some observable gaps and\ndisparities between the languages. There are substantial disparities in the\nlevel of adoption of transformer-based models. In essential tasks such as\nde-identification, there is significantly less research activity focusing on\nNorwegian and Danish compared to Swedish text. Further, the review identified a\nlow level of sharing resources such as data, experimentation code, pre-trained\nmodels, and rate of adaptation and transfer learning in the region. Conclusion:\nThe review presented a comprehensive assessment of the state-of-the-art\nClinical NLP for electronic health records (EHR) text in mainland Scandinavian\nlanguages and, highlighted the potential barriers and challenges that hinder\nthe rapid advancement of the field in the region.",
      "tldr_zh": "这篇论文通过系统综述评估了在挪威语、瑞典语和丹麦语的电子健康记录（EHR）文本中应用自然语言处理（NLP）的现状。研究方法包括在多个数据库中搜索2010-2024年间相关英文文献，最终筛选出113篇，其中64%关注瑞典语、21%关注挪威语、11%关注丹麦语，而9%涉及多种语言。结果显示，虽然该领域有积极发展，但存在显著差距，如transformer-based models的采用不均，以及挪威语和丹麦语在de-identification任务上的研究较少。综述强调了资源共享（如数据、代码和预训练模型）的不足，以及这些挑战可能阻碍Scandinavian语言临床NLP的快速发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "45 pages including the appendix, 9 figures in the main manuscript and\n  11 figures in the Appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.18539v1",
      "published_date": "2025-03-24 10:47:32 UTC",
      "updated_date": "2025-03-24 10:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:43:18.036280"
    },
    {
      "arxiv_id": "2503.18533v1",
      "title": "MMCR: Advancing Visual Language Model in Multimodal Multi-Turn Contextual Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Yan",
        "Yang Li",
        "Qing-Guo Chen",
        "Weihua Luo",
        "Peng Wang",
        "Haokui Zhang",
        "Chunhua Shen"
      ],
      "abstract": "Compared to single-turn dialogue, multi-turn dialogue involving multiple\nimages better aligns with the needs of real-world human-AI interactions.\nAdditionally, as training data, it provides richer contextual reasoning\ninformation, thereby guiding the model to achieve better performance. However,\nexisting vision-language models (VLMs) primarily rely on single-turn dialogue\ntraining and evaluation benchmarks. In this paper, following the\ncharacteristics of human dialogue, such as focused topics and concise, clear\ncontent, we present MMCR (Multimodal Multi-turn Contextual Reasoning), a novel\ndataset comprising: (1) MMCR-310k -- the largest multi-image multi-turn\ninstruction tuning dataset with 310K contextual dialogues, each covering 1-4\nimages and 4 or 8 dialogue turns; and (2) MMCR-Bench -- a diagnostic benchmark\nfeaturing dialogues, spanning 8 domains (Humanities, Natural, Science,\nEducation, etc.) and 40 sub-topics. Extensive evaluations demonstrate that\nmodels fine-tuned with MMCR-310k achieve 5.2\\% higher contextual accuracy on\nMMCR-Bench, while showing consistent improvements on existing benchmarks\n(+1.1\\% on AI2D, +1.2\\% on MMMU and MMVet). MMCR and prompt engineering will be\nreleased publicly.",
      "tldr_zh": "本论文提出MMCR数据集，以提升视觉语言模型（Visual Language Models, VLMs）在多模态多轮上下文推理中的性能，解决现有模型依赖单轮对话的局限性。MMCR包括MMCR-310k——一个规模最大的多图像多轮指令调整数据集，包含31万对话，每条覆盖1-4张图像和4或8轮对话；以及MMCR-Bench——一个跨8个领域（如人文、自然科学）和40个子主题的诊断基准。通过实验，MMCR-310k微调的模型在MMCR-Bench上上下文准确率提升5.2%，并在其他基准（如AI2D上+1.1%、MMMU和MMVet上+1.2%）中表现出一致改善。该数据集和提示工程将公开发布，推动更真实的人机交互应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18533v1",
      "published_date": "2025-03-24 10:40:33 UTC",
      "updated_date": "2025-03-24 10:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:43:30.371223"
    },
    {
      "arxiv_id": "2503.18526v1",
      "title": "SciClaims: An End-to-End Generative System for Biomedical Claim Analysis",
      "title_zh": "Sci",
      "authors": [
        "Raúl Ortega",
        "José Manuel Gómez-Pérez"
      ],
      "abstract": "Validating key claims in scientific literature, particularly in biomedical\nresearch, is essential for ensuring accuracy and advancing knowledge. This\nprocess is critical in sectors like the pharmaceutical industry, where rapid\nscientific progress requires automation and deep domain expertise. However,\ncurrent solutions have significant limitations. They lack end-to-end pipelines\nencompassing all claim extraction, evidence retrieval, and verification steps;\nrely on complex NLP and information retrieval pipelines prone to multiple\nfailure points; and often fail to provide clear, user-friendly justifications\nfor claim verification outcomes. To address these challenges, we introduce\nSciClaims, an advanced system powered by state-of-the-art large language models\n(LLMs) that seamlessly integrates the entire scientific claim analysis process.\nSciClaims outperforms previous approaches in both claim extraction and\nverification without requiring additional fine-tuning, setting a new benchmark\nfor automated scientific claim analysis.",
      "tldr_zh": "该论文针对生物医学文献中声明验证的挑战，指出现有方法缺乏端到端管道、依赖复杂NLP和信息检索系统、且无法提供清晰理由，从而影响准确性和效率。SciClaims系统基于先进的LLM（大型语言模型），无缝整合声明提取、证据检索和验证过程，实现端到端自动化分析，而无需额外微调。在性能测试中，SciClaims在声明提取和验证方面超越了先前方法，树立了新的基准，为科学声明分析提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Pre-print version",
      "pdf_url": "http://arxiv.org/pdf/2503.18526v1",
      "published_date": "2025-03-24 10:31:31 UTC",
      "updated_date": "2025-03-24 10:31:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:43:41.909062"
    },
    {
      "arxiv_id": "2503.18509v1",
      "title": "Neuro-symbolic Weak Supervision: Theory and Semantics",
      "title_zh": "神经符号弱监督：理论和语义",
      "authors": [
        "Nijesh Upreti",
        "Vaishak Belle"
      ],
      "abstract": "Weak supervision allows machine learning models to learn from limited or\nnoisy labels, but it introduces challenges in interpretability and reliability\n- particularly in multi-instance partial label learning (MI-PLL), where models\nmust resolve both ambiguous labels and uncertain instance-label mappings. We\npropose a semantics for neuro-symbolic framework that integrates Inductive\nLogic Programming (ILP) to improve MI-PLL by providing structured relational\nconstraints that guide learning. Within our semantic characterization, ILP\ndefines a logical hypothesis space for label transitions, clarifies classifier\nsemantics, and establishes interpretable performance standards. This hybrid\napproach improves robustness, transparency, and accountability in weakly\nsupervised settings, ensuring neural predictions align with domain knowledge.\nBy embedding weak supervision into a logical framework, we enhance both\ninterpretability and learning, making weak supervision more suitable for\nreal-world, high-stakes applications.",
      "tldr_zh": "该论文探讨了弱监督（Weak Supervision）在机器学习中的挑战，特别是多实例部分标签学习（MI-PLL）中的标签模糊和实例映射不确定性问题。作者提出了一种神经符号（Neuro-symbolic）框架，整合Inductive Logic Programming (ILP)来提供结构化的关系约束，从而指导学习过程并提升模型的鲁棒性和透明度。在语义层面，ILP定义了标签转换的逻辑假设空间、澄清分类器语义，并设定可解释的性能标准，最终使弱监督更适合高风险的真实世界应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18509v1",
      "published_date": "2025-03-24 10:02:51 UTC",
      "updated_date": "2025-03-24 10:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:43:53.661965"
    },
    {
      "arxiv_id": "2503.18497v2",
      "title": "Statistically Testing Training Data for Unwanted Error Patterns using Rule-Oriented Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Rass",
        "Martin Dallinger"
      ],
      "abstract": "Artificial intelligence models trained from data can only be as good as the\nunderlying data is. Biases in training data propagating through to the output\nof a machine learning model are a well-documented and well-understood\nphenomenon, but the machinery to prevent these undesired effects is much less\ndeveloped. Efforts to ensure data is clean during collection, such as using\nbias-aware sampling, are most effective when the entity controlling data\ncollection also trains the AI. In cases where the data is already available,\nhow do we find out if the data was already manipulated, i.e., ``poisoned'', so\nthat an undesired behavior would be trained into a machine learning model? This\nis a challenge fundamentally different to (just) improving approximation\naccuracy or efficiency, and we provide a method to test training data for\nflaws, to establish a trustworthy ground-truth for a subsequent training of\nmachine learning models (of any kind). Unlike the well-studied problem of\napproximating data using fuzzy rules that are generated from the data, our\nmethod hinges on a prior definition of rules to happen before seeing the data\nto be tested. Therefore, the proposed method can also discover hidden error\npatterns, which may also have substantial influence. Our approach extends the\nabilities of conventional statistical testing by letting the ``test-condition''\nbe any Boolean condition to describe a pattern in the data, whose presence we\nwish to determine. The method puts fuzzy inference into a regression model, to\nget the best of the two: explainability from fuzzy logic with statistical\nproperties and diagnostics from the regression, and finally also being\napplicable to ``small data'', hence not requiring large datasets as deep\nlearning methods do. We provide an open source implementation for demonstration\nand experiments.",
      "tldr_zh": "这篇论文提出了一种使用Rule-Oriented Regression的方法，来统计测试训练数据中的 unwanted 错误模式，以识别数据是否已被操纵（poisoned）并防止偏差传播到AI模型。不同于传统数据逼近方法，该方法要求在查看数据前预定义规则，并将fuzzy inference融入回归模型，从而结合模糊逻辑的可解释性和回归的统计诊断优势。实验表明，这种方法能发现隐藏的错误模式，适用于“小数据”场景，并提供了开源实现以支持进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T10 (Primary), 68M25, 62J86 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18497v2",
      "published_date": "2025-03-24 09:52:36 UTC",
      "updated_date": "2025-04-01 13:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:44:05.554879"
    },
    {
      "arxiv_id": "2503.18494v1",
      "title": "Verbal Process Supervision Elicits Better Coding Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Yuan Chen",
        "Cheng-Pong Huang",
        "Jui-Ming Yao"
      ],
      "abstract": "The emergence of large language models and their applications as AI agents\nhave significantly advanced state-of-the-art code generation benchmarks,\ntransforming modern software engineering tasks. However, even with test-time\ncomputed reasoning models, these systems still struggle with complex software\nengineering challenges. This work introduces CURA, a code understanding and\nreasoning agent system enhanced with verbal process supervision (VPS),\nachieving a 3.65\\% improvement over baseline models on challenging benchmarks\nlike BigCodeBench. Furthermore, CURA, when paired with the o3-mini model and\nVPS techniques, attains state-of-the-art performance. This work represents a\nstep forward in integrating reasoning-driven architectures with LLM-based code\ngeneration, enabling agentic reasoning for language models to solve complex\nsoftware engineering tasks.",
      "tldr_zh": "这项研究探讨了大型语言模型 (LLMs) 在代码生成中的应用，引入了 CURA 系统，该系统通过 verbal process supervision (VPS) 技术增强代码理解和推理能力，以应对复杂的软件工程挑战。相比基线模型，CURA 在 BigCodeBench 等基准上实现了 3.65% 的性能提升，并在与 o3-mini 模型结合时达到了 state-of-the-art 水平。该工作推动了推理驱动架构与 LLM-based 代码生成的整合，促进了语言模型在代理式推理方面的应用，以更好地解决实际软件工程任务。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18494v1",
      "published_date": "2025-03-24 09:48:59 UTC",
      "updated_date": "2025-03-24 09:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:44:18.668316"
    },
    {
      "arxiv_id": "2503.18492v1",
      "title": "Safeguarding Mobile GUI Agent via Logic-based Action Verification",
      "title_zh": "通过基于逻辑的动作验证保护移动图形用户界面代理",
      "authors": [
        "Jungjae Lee",
        "Dongjae Lee",
        "Chihun Choi",
        "Youngmin Im",
        "Jaeyoung Wi",
        "Kihong Heo",
        "Sangeun Oh",
        "Sunjae Lee",
        "Insik Shin"
      ],
      "abstract": "Large Foundation Models (LFMs) have unlocked new possibilities in\nhuman-computer interaction, particularly with the rise of mobile Graphical User\nInterface (GUI) Agents capable of interpreting GUIs. These agents promise to\nrevolutionize mobile computing by allowing users to automate complex mobile\ntasks through simple natural language instructions. However, the inherent\nprobabilistic nature of LFMs, coupled with the ambiguity and context-dependence\nof mobile tasks, makes LFM-based automation unreliable and prone to errors. To\naddress this critical challenge, we introduce VeriSafe Agent (VSA): a formal\nverification system that serves as a logically grounded safeguard for Mobile\nGUI Agents. VSA is designed to deterministically ensure that an agent's actions\nstrictly align with user intent before conducting an action. At its core, VSA\nintroduces a novel autoformalization technique that translates natural language\nuser instructions into a formally verifiable specification, expressed in our\ndomain-specific language (DSL). This enables runtime, rule-based verification,\nallowing VSA to detect and prevent erroneous actions executing an action,\neither by providing corrective feedback or halting unsafe behavior. To the best\nof our knowledge, VSA is the first attempt to bring the rigor of formal\nverification to GUI agent. effectively bridging the gap between LFM-driven\nautomation and formal software verification. We implement VSA using\noff-the-shelf LLM services (GPT-4o) and evaluate its performance on 300 user\ninstructions across 18 widely used mobile apps. The results demonstrate that\nVSA achieves 94.3%-98.33% accuracy in verifying agent actions, representing a\nsignificant 20.4%-25.6% improvement over existing LLM-based verification\nmethods, and consequently increases the GUI agent's task completion rate by\n90%-130%.",
      "tldr_zh": "该研究针对Large Foundation Models (LFMs) 在移动Graphical User Interface (GUI) 代理中存在的不可靠性问题，提出VeriSafe Agent (VSA)，一个基于逻辑的行动验证系统，以确保代理动作严格符合用户意图。VSA的核心是autoformalization 技术，将自然语言指令转化为领域特定语言 (DSL) 的正式可验证规范，从而实现运行时规则-based 验证，检测并防止错误动作。实验结果显示，在300个用户指令和18个移动应用上，VSA的动作验证准确率达到94.3%-98.33%，较现有LLM-based 方法提升20.4%-25.6%，并将GUI 代理的任务完成率提高90%-130%。这标志着首次将正式验证引入GUI 代理领域，有效桥接了LFM驱动自动化与软件验证之间的差距。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18492v1",
      "published_date": "2025-03-24 09:46:05 UTC",
      "updated_date": "2025-03-24 09:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:44:31.081707"
    },
    {
      "arxiv_id": "2503.18487v1",
      "title": "Large Language Models powered Network Attack Detection: Architecture, Opportunities and Case Study",
      "title_zh": "大语言模型驱动的网络攻击检测：架构、机会和案例研究",
      "authors": [
        "Xinggong Zhang",
        "Qingyang Li",
        "Yunpeng Tan",
        "Zongming Guo",
        "Lei Zhang",
        "Yong Cui"
      ],
      "abstract": "Network attack detection is a pivotal technology to identify network anomaly\nand classify malicious traffic. Large Language Models (LLMs) are trained on a\nvast corpus of text, have amassed remarkable capabilities of\ncontext-understanding and commonsense knowledge. This has opened up a new door\nfor network threat detection. Researchers have already initiated discussions\nregarding the application of LLMs on specific cyber-security tasks.\nUnfortunately, there is still a lack of comprehensive elaboration how to mine\nLLMs' potentials in network threat detections, as well as the opportunities and\nchallenges. In this paper, we mainly focus on the classification of malicious\ntraffic from the perspective of LLMs' capability. We present a holistic view of\nthe architecture of LLM-powered network attack detection, including\nPre-training, Fine-tuning, and Detection. Especially, by exploring the\nknowledge and capabilities of LLM, we identify three distinct roles LLM can act\nin network attack detection: \\textit{Classifier, Encoder, and Predictor}. For\neach of them, the modeling paradigm, opportunities and challenges are\nelaborated. Finally, we present our design on LLM-powered DDoS detection as a\ncase study. The proposed framework attains accurate detection on carpet bombing\nDDoS by exploiting LLMs' capabilities in contextual mining. The evaluation\nshows its efficacy, exhibiting a nearly $35$\\% improvement compared to existing\nsystems.",
      "tldr_zh": "这篇论文探讨了利用 Large Language Models (LLMs) 提升网络攻击检测的架构、机会和挑战，重点聚焦于恶意流量分类。论文提出一个整体框架，包括 Pre-training、Fine-tuning 和 Detection 阶段，并将 LLMs 定义为三种角色：Classifier（分类器）、Encoder（编码器）和 Predictor（预测器），并阐述了每个角色的建模范式、潜在机会及面临的挑战。最后，通过一个 LLM 驱动的 DDoS 检测案例研究，框架展示了在上下文挖掘方面的效能，与现有系统相比准确率提高了约 35%。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.NI",
      "comment": "submitted for peer-review",
      "pdf_url": "http://arxiv.org/pdf/2503.18487v1",
      "published_date": "2025-03-24 09:40:46 UTC",
      "updated_date": "2025-03-24 09:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:44:43.252137"
    },
    {
      "arxiv_id": "2503.18471v1",
      "title": "Words as Bridges: Exploring Computational Support for Cross-Disciplinary Translation Work",
      "title_zh": "翻译失败",
      "authors": [
        "Calvin Bao",
        "Yow-Ting Shiue",
        "Marine Carpuat",
        "Joel Chan"
      ],
      "abstract": "Scholars often explore literature outside of their home community of study.\nThis exploration process is frequently hampered by field-specific jargon. Past\ncomputational work often focuses on supporting translation work by removing\njargon through simplification and summarization; here, we explore a different\napproach that preserves jargon as useful bridges to new conceptual spaces.\nSpecifically, we cast different scholarly domains as different language-using\ncommunities, and explore how to adapt techniques from unsupervised\ncross-lingual alignment of word embeddings to explore conceptual alignments\nbetween domain-specific word embedding spaces.We developed a prototype\ncross-domain search engine that uses aligned domain-specific embeddings to\nsupport conceptual exploration, and tested this prototype in two case studies.\nWe discuss qualitative insights into the promises and pitfalls of this approach\nto translation work, and suggest design insights for future interfaces that\nprovide computational support for cross-domain information seeking.",
      "tldr_zh": "该论文探讨了如何通过保留领域特定术语（jargon）作为连接新概念的桥梁，来支持学者进行跨学科文献探索，而不是简单移除术语。研究将不同学术领域视为独立的语言社区，并应用无监督的跨语言词嵌入对齐（cross-lingual alignment）技术，对齐领域特定word embeddings空间，从而实现概念间的探索。作者开发了一个原型跨领域搜索引擎，并通过两个案例研究验证其效果，讨论了这种方法的潜在优势和挑战，并为未来提供计算支持的接口提出设计见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 8 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18471v1",
      "published_date": "2025-03-24 09:19:29 UTC",
      "updated_date": "2025-03-24 09:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:44:54.952375"
    },
    {
      "arxiv_id": "2503.18470v1",
      "title": "MetaSpatial: Reinforcing 3D Spatial Reasoning in VLMs for the Metaverse",
      "title_zh": "MetaSpatial：强化 VLMs 中的 3D 空间",
      "authors": [
        "Zhenyu Pan",
        "Han Liu"
      ],
      "abstract": "We present MetaSpatial, the first reinforcement learning (RL)-based framework\ndesigned to enhance 3D spatial reasoning in vision-language models (VLMs),\nenabling real-time 3D scene generation without the need for hard-coded\noptimizations. MetaSpatial addresses two core challenges: (i) the lack of\ninternalized 3D spatial reasoning in VLMs, which limits their ability to\ngenerate realistic layouts, and (ii) the inefficiency of traditional supervised\nfine-tuning (SFT) for layout generation tasks, as perfect ground truth\nannotations are unavailable. Our key innovation is a multi-turn RL-based\noptimization mechanism that integrates physics-aware constraints and rendered\nimage evaluations, ensuring generated 3D layouts are coherent, physically\nplausible, and aesthetically consistent. Methodologically, MetaSpatial\nintroduces an adaptive, iterative reasoning process, where the VLM refines\nspatial arrangements over multiple turns by analyzing rendered outputs,\nimproving scene coherence progressively. Empirical evaluations demonstrate that\nMetaSpatial significantly enhances the spatial consistency and formatting\nstability of various scale models. Post-training, object placements are more\nrealistic, aligned, and functionally coherent, validating the effectiveness of\nRL for 3D spatial reasoning in metaverse, AR/VR, digital twins, and game\ndevelopment applications. Our code, data, and training pipeline are publicly\navailable at https://github.com/PzySeere/MetaSpatial.",
      "tldr_zh": "本研究提出 MetaSpatial，一种基于强化学习 (RL) 的框架，用于增强视觉语言模型 (VLMs) 的 3D 空间推理能力，实现无需硬编码优化的实时 3D 场景生成。框架针对 VLMs 缺乏内在 3D 空间推理和传统监督微调 (SFT) 效率低下的问题，创新性地采用多轮 RL 优化机制，结合物理感知约束和渲染图像评估，使生成的布局更连贯、物理合理和美学一致。实验结果显示，MetaSpatial 显著提升了模型的空间一致性和格式稳定性，生成的物体放置更真实、对齐和功能连贯，适用于元宇宙、AR/VR、数字孪生和游戏开发等领域，并已公开代码、数据和训练管道。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Working Paper",
      "pdf_url": "http://arxiv.org/pdf/2503.18470v1",
      "published_date": "2025-03-24 09:18:01 UTC",
      "updated_date": "2025-03-24 09:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:45:06.547733"
    },
    {
      "arxiv_id": "2503.18462v1",
      "title": "PALATE: Peculiar Application of the Law of Total Expectation to Enhance the Evaluation of Deep Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tadeusz Dziarmaga",
        "Marcin Kądziołka",
        "Artur Kasymov",
        "Marcin Mazur"
      ],
      "abstract": "Deep generative models (DGMs) have caused a paradigm shift in the field of\nmachine learning, yielding noteworthy advancements in domains such as image\nsynthesis, natural language processing, and other related areas. However, a\ncomprehensive evaluation of these models that accounts for the trichotomy\nbetween fidelity, diversity, and novelty in generated samples remains a\nformidable challenge. A recently introduced solution that has emerged as a\npromising approach in this regard is the Feature Likelihood Divergence (FLD), a\nmethod that offers a theoretically motivated practical tool, yet also exhibits\nsome computational challenges. In this paper, we propose PALATE, a novel\nenhancement to the evaluation of DGMs that addresses limitations of existing\nmetrics. Our approach is based on a peculiar application of the law of total\nexpectation to random variables representing accessible real data. When\ncombined with the MMD baseline metric and DINOv2 feature extractor, PALATE\noffers a holistic evaluation framework that matches or surpasses\nstate-of-the-art solutions while providing superior computational efficiency\nand scalability to large-scale datasets. Through a series of experiments, we\ndemonstrate the effectiveness of the PALATE enhancement, contributing a\ncomputationally efficient, holistic evaluation approach that advances the field\nof DGMs assessment, especially in detecting sample memorization and evaluating\ngeneralization capabilities.",
      "tldr_zh": "该论文提出 PALATE，一种新颖的方法，通过奇特应用总期望定律（law of total expectation）来提升深度生成模型（DGMs）的评估，旨在解决现有指标在平衡保真度（fidelity）、多样性（diversity）和新颖性（novelty）方面的局限性。PALATE 将该定律应用于表示真实数据的随机变量，并与 MMD 基线指标和 DINOv2 特征提取器结合，构建了一个全面且计算高效的评估框架。实验结果表明，PALATE 匹配或超越了最先进解决方案，在检测样本记忆和评估泛化能力上表现出色，同时提升了可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18462v1",
      "published_date": "2025-03-24 09:06:45 UTC",
      "updated_date": "2025-03-24 09:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:45:18.978348"
    },
    {
      "arxiv_id": "2503.18460v1",
      "title": "ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahui Xiang",
        "Tong Ye",
        "Peiyu Liu",
        "Yinan Zhang",
        "Wenhai Wang"
      ],
      "abstract": "Modelica is a widely adopted language for simulating complex physical\nsystems, yet effective model creation and optimization require substantial\ndomain expertise. Although large language models (LLMs) have demonstrated\npromising capabilities in code generation, their application to modeling\nremains largely unexplored. To address this gap, we have developed benchmark\ndatasets specifically designed to evaluate the performance of LLMs in\ngenerating Modelica component models and test cases. Our evaluation reveals\nsubstantial limitations in current LLMs, as the generated code often fails to\nsimulate successfully. To overcome these challenges, we propose a specialized\nworkflow that integrates supervised fine-tuning, graph retrieval-augmented\ngeneration, and feedback optimization to improve the accuracy and reliability\nof Modelica code generation. The evaluation results demonstrate significant\nperformance gains: the maximum improvement in pass@1 reached 0.3349 for the\ncomponent generation task and 0.2457 for the test case generation task. This\nresearch underscores the potential of LLMs to advance intelligent modeling\ntools and offers valuable insights for future developments in system modeling\nand engineering applications.",
      "tldr_zh": "该研究针对 Modelica 语言在模拟复杂物理系统时的建模挑战，开发了基准数据集来评估 Large Language Models (LLMs) 在生成 Modelica 组件模型和测试用例方面的性能，发现当前 LLMs 存在显著局限，生成的代码往往无法成功模拟。作者提出 ModiGen 工作流，该框架整合 supervised fine-tuning、graph retrieval-augmented generation 和 feedback optimization 等技术，以提升代码生成的准确性和可靠性。实验结果显示，该工作流使组件生成任务的 pass@1 指标最大提升 0.3349，测试用例生成任务提升 0.2457，显著改善了 LLMs 在系统建模中的应用潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18460v1",
      "published_date": "2025-03-24 09:04:49 UTC",
      "updated_date": "2025-03-24 09:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:45:31.982329"
    },
    {
      "arxiv_id": "2504.08746v1",
      "title": "Enhancing Recommender Systems Using Textual Embeddings from Pre-trained Language Models",
      "title_zh": "利用预训练语言模型的文本嵌入增强推荐系统",
      "authors": [
        "Ngoc Luyen Le",
        "Marie-Hélène Abel"
      ],
      "abstract": "Recent advancements in language models and pre-trained language models like\nBERT and RoBERTa have revolutionized natural language processing, enabling a\ndeeper understanding of human-like language. In this paper, we explore\nenhancing recommender systems using textual embeddings from pre-trained\nlanguage models to address the limitations of traditional recommender systems\nthat rely solely on explicit features from users, items, and user-item\ninteractions. By transforming structured data into natural language\nrepresentations, we generate high-dimensional embeddings that capture deeper\nsemantic relationships between users, items, and contexts. Our experiments\ndemonstrate that this approach significantly improves recommendation accuracy\nand relevance, resulting in more personalized and context-aware\nrecommendations. The findings underscore the potential of PLMs to enhance the\neffectiveness of recommender systems.",
      "tldr_zh": "本论文探讨了利用预训练语言模型（如 BERT 和 RoBERTa）的文本嵌入来提升推荐系统的性能，以克服传统系统依赖用户、物品和交互显式特征的局限性。通过将结构化数据转化为自然语言表示，生成高维嵌入，该方法捕捉了用户、物品和上下文之间的深层语义关系。实验结果显示，这种方法显著提高了推荐准确性和相关性，提供更个性化和上下文感知的推荐。研究强调了 PLMs 在增强推荐系统有效性方面的巨大潜力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08746v1",
      "published_date": "2025-03-24 09:03:12 UTC",
      "updated_date": "2025-03-24 09:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:45:42.103114"
    },
    {
      "arxiv_id": "2503.18432v1",
      "title": "Teaching LLMs for Step-Level Automatic Math Correction via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Junsong Li",
        "Jie Zhou",
        "Yutao Yang",
        "Bihao Zhan",
        "Qianjun Pan",
        "Yuyang Ding",
        "Qin Chen",
        "Jiang Bo",
        "Xin Lin",
        "Liang He"
      ],
      "abstract": "Automatic math correction aims to check students' solutions to mathematical\nproblems via artificial intelligence technologies. Most existing studies focus\non judging the final answer at the problem level, while they ignore detailed\nfeedback on each step in a math problem-solving process, which requires\nabilities of semantic understanding and reasoning. In this paper, we propose a\nreinforcement learning (RL)-based method to boost large language model (LLM)\nfor step-level automatic math correction, named StepAMC. Particularly, we\nconvert the step-level automatic math correction within the text classification\ntask into an RL problem to enhance the reasoning capabilities of LLMs. Then, we\ndesign a space-constrained policy network to improve the stability of RL. Then,\nwe introduce a fine-grained reward network to convert the binary human feedback\ninto a continuous value. We conduct extensive experiments over two benchmark\ndatasets and the results show that our model outperforms the eleven strong\nbaselines.",
      "tldr_zh": "本研究针对自动数学修正的局限性，提出了一种基于强化学习（RL）的StepAMC方法，用于提升大型语言模型（LLM）的步骤级别反馈能力，从而提供详细的语义理解和推理支持。具体而言，该方法将文本分类任务转化为RL问题，设计了空间约束的政策网络（space-constrained policy network）以提高训练稳定性，并引入细粒度奖励网络（fine-grained reward network）将二元人工反馈转换为连续值。在两个基准数据集上的实验结果显示，StepAMC模型优于11个强基线模型，证明了其在自动数学修正方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18432v1",
      "published_date": "2025-03-24 08:28:34 UTC",
      "updated_date": "2025-03-24 08:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:45:54.521135"
    },
    {
      "arxiv_id": "2503.18419v1",
      "title": "Generative AI in Knowledge Work: Design Implications for Data Navigation and Decision-Making",
      "title_zh": "知识工作中的生成式 AI：数据导航和决策制定的设计启示",
      "authors": [
        "Bhada Yun",
        "Dana Feng",
        "Ace S. Chen",
        "Afshin Nikzad",
        "Niloufar Salehi"
      ],
      "abstract": "Our study of 20 knowledge workers revealed a common challenge: the difficulty\nof synthesizing unstructured information scattered across multiple platforms to\nmake informed decisions. Drawing on their vision of an ideal knowledge\nsynthesis tool, we developed Yodeai, an AI-enabled system, to explore both the\nopportunities and limitations of AI in knowledge work. Through a user study\nwith 16 product managers, we identified three key requirements for Generative\nAI in knowledge work: adaptable user control, transparent collaboration\nmechanisms, and the ability to integrate background knowledge with external\ninformation. However, we also found significant limitations, including\noverreliance on AI, user isolation, and contextual factors outside the AI's\nreach. As AI tools become increasingly prevalent in professional settings, we\npropose design principles that emphasize adaptability to diverse workflows,\naccountability in personal and collaborative contexts, and context-aware\ninteroperability to guide the development of human-centered AI systems for\nproduct managers and knowledge workers.",
      "tldr_zh": "本研究调查了20名知识工作者的需求，发现他们难以合成散布于多个平台的非结构化信息以做出决策，因此开发了Generative AI支持的Yodeai系统。用户研究涉及16名产品经理，识别了Generative AI在知识工作中的三大关键要求：可适应的用户控制、透明的协作机制，以及整合背景知识与外部信息的能力。然而，该研究也揭示了潜在限制，如对AI的过度依赖、用户孤立和上下文因素的缺失。最终，论文提出设计原则，强调适应多样工作流程、责任性以及上下文感知的互操作性，以推动人类中心AI系统的开发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "H.5.m"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CHI '25 (Conference on Human Factors in Computing\n  Systems), to appear April 26-May 1, 2025, Yokohama, Japan",
      "pdf_url": "http://arxiv.org/pdf/2503.18419v1",
      "published_date": "2025-03-24 08:02:44 UTC",
      "updated_date": "2025-03-24 08:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:46:06.786084"
    },
    {
      "arxiv_id": "2503.20800v1",
      "title": "Evidencing Unauthorized Training Data from AI Generated Content using Information Isotopes",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Tao",
        "Yin Jinhua",
        "Cai Dongqi",
        "Xie Yueqi",
        "Wang Huili",
        "Hu Zhiyang",
        "Yang Peiru",
        "Nan Guoshun",
        "Zhou Zhili",
        "Wang Shangguang",
        "Lyu Lingjuan",
        "Huang Yongfeng",
        "Lane Nicholas"
      ],
      "abstract": "In light of scaling laws, many AI institutions are intensifying efforts to\nconstruct advanced AIs on extensive collections of high-quality human data.\nHowever, in a rush to stay competitive, some institutions may inadvertently or\neven deliberately include unauthorized data (like privacy- or intellectual\nproperty-sensitive content) for AI training, which infringes on the rights of\ndata owners. Compounding this issue, these advanced AI services are typically\nbuilt on opaque cloud platforms, which restricts access to internal information\nduring AI training and inference, leaving only the generated outputs available\nfor forensics. Thus, despite the introduction of legal frameworks by various\ncountries to safeguard data rights, uncovering evidence of data misuse in\nmodern opaque AI applications remains a significant challenge. In this paper,\ninspired by the ability of isotopes to trace elements within chemical\nreactions, we introduce the concept of information isotopes and elucidate their\nproperties in tracing training data within opaque AI systems. Furthermore, we\npropose an information isotope tracing method designed to identify and provide\nevidence of unauthorized data usage by detecting the presence of target\ninformation isotopes in AI generations. We conduct experiments on ten AI models\n(including GPT-4o, Claude-3.5, and DeepSeek) and four benchmark datasets in\ncritical domains (medical data, copyrighted books, and news). Results show that\nour method can distinguish training datasets from non-training datasets with\n99\\% accuracy and significant evidence (p-value$<0.001$) by examining a data\nentry equivalent in length to a research paper. The findings show the potential\nof our work as an inclusive tool for empowering individuals, including those\nwithout expertise in AI, to safeguard their data rights in the rapidly evolving\nera of AI advancements and applications.",
      "tldr_zh": "该论文引入“information isotopes”概念，旨在追踪AI生成内容中未经授权的训练数据，以应对AI系统不透明导致的数据权利侵犯问题。该方法模拟化学同位素的追踪原理，通过检测AI生成物中的特定信息同位素来识别和提供未经授权数据使用的证据。实验在十个AI模型（如GPT-4o和Claude-3.5）及四个关键数据集（包括医疗数据和版权书籍）上进行，结果显示该方法能以99%的准确率区分训练与非训练数据集，并提供显著统计证据（p-value<0.001）。这项研究为非AI专家提供工具，帮助他们在AI快速发展时代保护个人数据权利。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.20800v1",
      "published_date": "2025-03-24 07:35:59 UTC",
      "updated_date": "2025-03-24 07:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:46:17.946225"
    },
    {
      "arxiv_id": "2503.18403v1",
      "title": "Knowledge Graph Enhanced Generative Multi-modal Models for Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xusheng Cao",
        "Haori Lu",
        "Linlan Huang",
        "Fei Yang",
        "Xialei Liu",
        "Ming-Ming Cheng"
      ],
      "abstract": "Continual learning in computer vision faces the critical challenge of\ncatastrophic forgetting, where models struggle to retain prior knowledge while\nadapting to new tasks. Although recent studies have attempted to leverage the\ngeneralization capabilities of pre-trained models to mitigate overfitting on\ncurrent tasks, models still tend to forget details of previously learned\ncategories as tasks progress, leading to misclassification. To address these\nlimitations, we introduce a novel Knowledge Graph Enhanced Generative\nMulti-modal model (KG-GMM) that builds an evolving knowledge graph throughout\nthe learning process. Our approach utilizes relationships within the knowledge\ngraph to augment the class labels and assigns different relations to similar\ncategories to enhance model differentiation. During testing, we propose a\nKnowledge Graph Augmented Inference method that locates specific categories by\nanalyzing relationships within the generated text, thereby reducing the loss of\ndetailed information about old classes when learning new knowledge and\nalleviating forgetting. Experiments demonstrate that our method effectively\nleverages relational information to help the model correct mispredictions,\nachieving state-of-the-art results in both conventional CIL and few-shot CIL\nsettings, confirming the efficacy of knowledge graphs at preserving knowledge\nin the continual learning scenarios.",
      "tldr_zh": "本研究针对计算机视觉中持续学习（Class-Incremental Learning）的灾难性遗忘问题，提出了一种新型 Knowledge Graph Enhanced Generative Multi-modal Models (KG-GMM)，通过构建演化的 Knowledge Graph 来增强类别标签并为相似类别分配不同关系，从而提高模型的区分能力和知识保留。KG-GMM 在测试阶段引入 Knowledge Graph Augmented Inference 方法，通过分析生成的文本中关系来定位特定类别，减少学习新知识时对旧类别的遗忘。实验结果表明，该方法有效修正了错误预测，在常规 CIL 和 Few-Shot CIL 设置中达到了最先进性能，验证了 Knowledge Graph 在知识保留中的功效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18403v1",
      "published_date": "2025-03-24 07:20:43 UTC",
      "updated_date": "2025-03-24 07:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:46:30.828832"
    },
    {
      "arxiv_id": "2503.18395v2",
      "title": "PRECTR: A Synergistic Framework for Integrating Personalized Search Relevance Matching and CTR Prediction",
      "title_zh": "PRECTR：一种整合个性化搜索相关性匹配和点击率预测的协同框架",
      "authors": [
        "Rong Chen",
        "Shuzhi Cao",
        "Ailong He",
        "Shuguang Han",
        "Jufeng Chen"
      ],
      "abstract": "The two primary tasks in the search recommendation system are search\nrelevance matching and click-through rate (CTR) prediction -- the former\nfocuses on seeking relevant items for user queries whereas the latter forecasts\nwhich item may better match user interest. Prior research typically develops\ntwo models to predict the CTR and search relevance separately, then ranking\ncandidate items based on the fusion of the two outputs. However, such a\ndivide-and-conquer paradigm creates the inconsistency between different models.\nMeanwhile, the search relevance model mainly concentrates on the degree of\nobjective text matching while neglecting personalized differences among\ndifferent users, leading to restricted model performance. To tackle these\nissues, we propose a unified Personalized Search RElevance Matching and CTR\nPrediction Fusion Model(PRECTR). Specifically, based on the conditional\nprobability fusion mechanism, PRECTR integrates the CTR prediction and search\nrelevance matching into one framework to enhance the interaction and\nconsistency of the two modules. However, directly optimizing CTR binary\nclassification loss may bring challenges to the fusion model's convergence and\nindefinitely promote the exposure of items with high CTR, regardless of their\nsearch relevance. Hence, we further introduce two-stage training and semantic\nconsistency regularization to accelerate the model's convergence and restrain\nthe recommendation of irrelevant items. Finally, acknowledging that different\nusers may have varied relevance preferences, we assessed current users'\nrelevance preferences by analyzing past users' preferences for similar queries\nand tailored incentives for different candidate items accordingly. Extensive\nexperimental results on our production dataset and online A/B testing\ndemonstrate the effectiveness and superiority of our proposed PRECTR method.",
      "tldr_zh": "该研究针对搜索推荐系统的搜索相关性匹配（search relevance matching）和点击率预测（CTR prediction）任务，提出了一个统一的框架PRECTR，以解决传统分开模型导致的不一致性和忽略用户个性化差异的问题。具体来说，PRECTR通过条件概率融合机制将CTR预测和搜索相关性匹配整合到一个框架中，并引入两阶段训练（two-stage training）和语义一致性正则化（semantic consistency regularization）来提升模型收敛性和抑制无关项推荐。此外，该框架根据用户过去偏好分析类似查询的个性化差异，提供针对性的项激励。实验结果在生产数据集和在线A/B测试中证明了PRECTR的有效性和优越性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18395v2",
      "published_date": "2025-03-24 07:07:04 UTC",
      "updated_date": "2025-03-26 14:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:46:42.563478"
    },
    {
      "arxiv_id": "2503.18387v1",
      "title": "Manipulation and the AI Act: Large Language Model Chatbots and the Danger of Mirrors",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Krook"
      ],
      "abstract": "Large Language Model chatbots are increasingly taking the form and visage of\nhuman beings, adapting human faces, names, voices, personalities, and quirks,\nincluding those of celebrities and well-known political figures. Personifying\nAI chatbots could foreseeably increase their trust with users. However, it\ncould also make them more capable of manipulation, by creating the illusion of\na close and intimate relationship with an artificial entity. The European\nCommission has finalized the AI Act, with the EU Parliament making amendments\nbanning manipulative and deceptive AI systems that cause significant harm to\nusers. Although the AI Act covers harms that accumulate over time, it is\nunlikely to prevent harms associated with prolonged discussions with AI\nchatbots. Specifically, a chatbot could reinforce a person's negative emotional\nstate over weeks, months, or years through negative feedback loops, prolonged\nconversations, or harmful recommendations, contributing to a user's\ndeteriorating mental health.",
      "tldr_zh": "该论文探讨了Large Language Model (LLM) 聊天机器人的拟人化问题，这些机器人模仿人类的外貌、姓名、声音和个性，可能增加用户信任但同时放大操纵风险，通过制造亲密关系的幻觉来影响用户行为。作者分析了欧盟AI Act的修正案，该法规禁止操纵性和欺骗性AI系统以防止重大伤害，但可能无法有效应对长期对话带来的累积危害，如负面反馈循环导致用户心理健康恶化。论文强调了需要更强的监管措施，以防范LLM聊天机器人长期潜移默化的危险影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18387v1",
      "published_date": "2025-03-24 06:56:29 UTC",
      "updated_date": "2025-03-24 06:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:46:53.591257"
    },
    {
      "arxiv_id": "2503.18386v1",
      "title": "Resource-Efficient Motion Control for Video Generation via Dynamic Mask Guidance",
      "title_zh": "基于动态掩码引导的资源高效视频生成运动控制",
      "authors": [
        "Sicong Feng",
        "Jielong Yang",
        "Li Peng"
      ],
      "abstract": "Recent advances in diffusion models bring new vitality to visual content\ncreation. However, current text-to-video generation models still face\nsignificant challenges such as high training costs, substantial data\nrequirements, and difficulties in maintaining consistency between given text\nand motion of the foreground object. To address these challenges, we propose\nmask-guided video generation, which can control video generation through mask\nmotion sequences, while requiring limited training data. Our model enhances\nexisting architectures by incorporating foreground masks for precise\ntext-position matching and motion trajectory control. Through mask motion\nsequences, we guide the video generation process to maintain consistent\nforeground objects throughout the sequence. Additionally, through a first-frame\nsharing strategy and autoregressive extension approach, we achieve more stable\nand longer video generation. Extensive qualitative and quantitative experiments\ndemonstrate that this approach excels in various video generation tasks, such\nas video editing and generating artistic videos, outperforming previous methods\nin terms of consistency and quality. Our generated results can be viewed in the\nsupplementary materials.",
      "tldr_zh": "该论文针对文本到视频生成模型的挑战（如高训练成本、数据需求大以及文本与前景物体运动一致性问题）提出了一种资源高效的动态掩码指导方法。模型通过 mask-guided video generation 整合前景掩码和运动序列，实现精确的文本-位置匹配和运动轨迹控制，同时使用 first-frame sharing 策略和 autoregressive extension 技术来生成更稳定、更长的视频序列。实验结果显示，该方法在视频编辑和艺术视频生成任务中表现出色，在一致性和质量方面优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18386v1",
      "published_date": "2025-03-24 06:53:08 UTC",
      "updated_date": "2025-03-24 06:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:47:06.170991"
    },
    {
      "arxiv_id": "2503.18385v1",
      "title": "RoCA: Robust Contrastive One-class Time Series Anomaly Detection with Contaminated Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Mou",
        "Rui Wang",
        "Bo Li",
        "Tianyu Wo",
        "Jie Sun",
        "Hui Wang",
        "Xudong Liu"
      ],
      "abstract": "The accumulation of time-series signals and the absence of labels make\ntime-series Anomaly Detection (AD) a self-supervised task of deep learning.\nMethods based on normality assumptions face the following three limitations:\n(1) A single assumption could hardly characterize the whole normality or lead\nto some deviation. (2) Some assumptions may go against the principle of AD. (3)\nTheir basic assumption is that the training data is uncontaminated (free of\nanomalies), which is unrealistic in practice, leading to a decline in\nrobustness. This paper proposes a novel robust approach, RoCA, which is the\nfirst to address all of the above three challenges, as far as we are aware. It\nfuses the separated assumptions of one-class classification and contrastive\nlearning in a single training process to characterize a more complete so-called\nnormality. Additionally, it monitors the training data and computes a carefully\ndesigned anomaly score throughout the training process. This score helps\nidentify latent anomalies, which are then used to define the classification\nboundary, inspired by the concept of outlier exposure. The performance on AIOps\ndatasets improved by 6% compared to when contamination was not considered\n(COCA). On two large and high-dimensional multivariate datasets, the\nperformance increased by 5% to 10%. RoCA achieves the highest average\nperformance on both univariate and multivariate datasets. The source code is\navailable at https://github.com/ruiking04/RoCA.",
      "tldr_zh": "该论文针对时间序列异常检测（Time Series Anomaly Detection）中的问题，提出了一种鲁棒方法RoCA，以应对单一normality假设的局限性、违背AD原则的风险以及训练数据污染（contaminated data）导致的鲁棒性下降。RoCA通过融合one-class classification和contrastive learning的假设，在单一训练过程中构建更完整的normality描述，同时监控训练数据计算anomaly score，并利用outlier exposure概念识别潜在异常以定义分类边界。实验结果显示，RoCA在AIOps数据集上比不考虑污染的COCA方法提高了6%的性能，在两个大型多变量数据集上提升5%至10%，并在单变量和多变量数据集上实现最高平均性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18385v1",
      "published_date": "2025-03-24 06:52:28 UTC",
      "updated_date": "2025-03-24 06:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:47:19.428220"
    },
    {
      "arxiv_id": "2503.18382v1",
      "title": "PP-FormulaNet: Bridging Accuracy and Efficiency in Advanced Formula Recognition",
      "title_zh": "PP-FormulaNet：在高级公式识别中桥接准确性和效率",
      "authors": [
        "Hongen Liu",
        "Cheng Cui",
        "Yuning Du",
        "Yi Liu",
        "Gang Pan"
      ],
      "abstract": "Formula recognition is an important task in document intelligence. It\ninvolves converting mathematical expressions from document images into\nstructured symbolic formats that computers can easily work with. LaTeX is the\nmost common format used for this purpose. In this work, we present\nPP-FormulaNet, a state-of-the-art formula recognition model that excels in both\naccuracy and efficiency. To meet the diverse needs of applications, we have\ndeveloped two specialized models: PP-FormulaNet-L, tailored for high-accuracy\nscenarios, and PP-FormulaNet-S, optimized for high-efficiency contexts. Our\nextensive evaluations reveal that PP-FormulaNet-L attains accuracy levels that\nsurpass those of prominent models such as UniMERNet by a significant 6%.\nConversely, PP-FormulaNet-S operates at speeds that are over 16 times faster.\nThese advancements facilitate seamless integration of PP-FormulaNet into a\nbroad spectrum of document processing environments that involve intricate\nmathematical formulas. Furthermore, we introduce a Formula Mining System, which\nis capable of extracting a vast amount of high-quality formula data. This\nsystem further enhances the robustness and applicability of our formula\nrecognition model. Code and models are publicly available at\nPaddleOCR(https://github.com/PaddlePaddle/PaddleOCR) and\nPaddleX(https://github.com/PaddlePaddle/PaddleX).",
      "tldr_zh": "这篇论文介绍了 PP-FormulaNet，一种先进的公式识别模型，旨在将文档图像中的数学表达式转换为结构化的 LaTeX 格式，同时平衡准确性和效率。该模型包括两个变体：PP-FormulaNet-L 针对高准确性场景，比 UniMERNet 准确率提升 6%；PP-FormulaNet-S 则优化为高效率，速度快 16 倍以上。这些改进使模型适用于各种文档处理环境。此外，论文还提出 Formula Mining System，用于提取高质量公式数据，进一步增强模型的稳健性和适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18382v1",
      "published_date": "2025-03-24 06:39:51 UTC",
      "updated_date": "2025-03-24 06:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:47:31.300960"
    },
    {
      "arxiv_id": "2503.18377v1",
      "title": "Maximum Redundancy Pruning: A Principle-Driven Layerwise Sparsity Allocation for LLMs",
      "title_zh": "最大冗余",
      "authors": [
        "Chang Gao",
        "Kang Zhao",
        "Jianfei Chen",
        "Liping Jing"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities, but\ntheir enormous size poses significant challenges for deployment in real-world\napplications. To address this issue, researchers have sought to apply network\npruning techniques to LLMs. A critical challenge in pruning is allocation the\nsparsity for each layer. Recent sparsity allocation methods is often based on\nheuristics or search that can easily lead to suboptimal performance. In this\npaper, we conducted an extensive investigation into various LLMs and revealed\nthree significant discoveries: (1) the layerwise pruning sensitivity (LPS) of\nLLMs is highly non-uniform, (2) the choice of pruning metric affects LPS, and\n(3) the performance of a sparse model is related to the uniformity of its\nlayerwise redundancy level. Based on these observations, we propose that the\nlayerwise sparsity of LLMs should adhere to three principles:\n\\emph{non-uniformity}, \\emph{pruning metric dependency}, and \\emph{uniform\nlayerwise redundancy level} in the pruned model. To this end, we proposed\nMaximum Redundancy Pruning (MRP), an iterative pruning algorithm that prunes in\nthe most redundant layers (\\emph{i.e.}, those with the highest non-outlier\nratio) at each iteration. The achieved layerwise sparsity aligns with the\noutlined principles. We conducted extensive experiments on publicly available\nLLMs, including the LLaMA2 and OPT, across various benchmarks. Experimental\nresults validate the effectiveness of MRP, demonstrating its superiority over\nprevious methods.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）的网络剪枝问题，旨在解决现有方法依赖启发式或搜索导致的性能次优问题。通过对各种LLMs的深入调查，作者发现LLMs的层级剪枝敏感度（LPS）高度不均匀、剪枝指标的选择影响LPS，以及稀疏模型性能与层级冗余水平的均匀性相关。基于这些原则，论文提出Maximum Redundancy Pruning (MRP)，一种迭代剪枝算法，在每个迭代中优先剪枝最冗余的层，以实现非均匀稀疏分配。实验结果显示，MRP在LLaMA2和OPT等模型上表现出色，在多种基准测试中优于先前方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18377v1",
      "published_date": "2025-03-24 06:17:30 UTC",
      "updated_date": "2025-03-24 06:17:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:47:44.072057"
    },
    {
      "arxiv_id": "2503.22711v1",
      "title": "Modeling speech emotion with label variance and analyzing performance across speakers and unseen acoustic conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Vikramjit Mitra",
        "Amrit Romana",
        "Dung T. Tran",
        "Erdrin Azemi"
      ],
      "abstract": "Spontaneous speech emotion data usually contain perceptual grades where\ngraders assign emotion score after listening to the speech files. Such\nperceptual grades introduce uncertainty in labels due to grader opinion\nvariation. Grader variation is addressed by using consensus grades as\ngroundtruth, where the emotion with the highest vote is selected. Consensus\ngrades fail to consider ambiguous instances where a speech sample may contain\nmultiple emotions, as captured through grader opinion uncertainty. We\ndemonstrate that using the probability density function of the emotion grades\nas targets instead of the commonly used consensus grades, provide better\nperformance on benchmark evaluation sets compared to results reported in the\nliterature. We show that a saliency driven foundation model (FM) representation\nselection helps to train a state-of-the-art speech emotion model for both\ndimensional and categorical emotion recognition. Comparing representations\nobtained from different FMs, we observed that focusing on overall test-set\nperformance can be deceiving, as it fails to reveal the models generalization\ncapacity across speakers and gender. We demonstrate that performance evaluation\nacross multiple test-sets and performance analysis across gender and speakers\nare useful in assessing usefulness of emotion models. Finally, we demonstrate\nthat label uncertainty and data-skew pose a challenge to model evaluation,\nwhere instead of using the best hypothesis, it is useful to consider the 2- or\n3-best hypotheses.",
      "tldr_zh": "本研究探讨了语音情感建模中的标签不确定性（label variance），提出使用情感等级的概率密度函数作为目标标签，而不是传统的共识标签（consensus grades），从而提高了语音情感识别的性能。作者采用显著性驱动的基础模型（saliency driven foundation model）表示来训练先进的语音情感模型，支持维度和分类情感识别（dimensional and categorical emotion recognition），并在基准数据集上取得了比文献报告更好的结果。实验发现，整体测试集性能可能掩盖模型在不同说话者和性别上的泛化能力，因此建议通过评估多个测试集并分析跨说话者、性别和未见声学条件（unseen acoustic conditions）的性能来评估模型有效性。最后，该研究强调标签不确定性和数据偏差（data-skew）对模型评估的挑战，推荐考虑2-或3-最佳假设以改进评估准确性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.22711v1",
      "published_date": "2025-03-24 06:13:27 UTC",
      "updated_date": "2025-03-24 06:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:47:54.688990"
    },
    {
      "arxiv_id": "2503.18347v1",
      "title": "Latent Embedding Adaptation for Human Preference Alignment in Diffusion Planners",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Zheng Terence Ng",
        "Jianda Chen",
        "Yuan Xu",
        "Tianwei Zhang"
      ],
      "abstract": "This work addresses the challenge of personalizing trajectories generated in\nautomated decision-making systems by introducing a resource-efficient approach\nthat enables rapid adaptation to individual users' preferences. Our method\nleverages a pretrained conditional diffusion model with Preference Latent\nEmbeddings (PLE), trained on a large, reward-free offline dataset. The PLE\nserves as a compact representation for capturing specific user preferences. By\nadapting the pretrained model using our proposed preference inversion method,\nwhich directly optimizes the learnable PLE, we achieve superior alignment with\nhuman preferences compared to existing solutions like Reinforcement Learning\nfrom Human Feedback (RLHF) and Low-Rank Adaptation (LoRA). To better reflect\npractical applications, we create a benchmark experiment using real human\npreferences on diverse, high-reward trajectories.",
      "tldr_zh": "这篇论文提出了一种资源高效的方法，用于在Diffusion Planners中个性化轨迹生成，以快速适应个体用户的偏好。该方法基于预训练的条件扩散模型和Preference Latent Embeddings (PLE)，后者作为紧凑的表示来捕捉特定用户偏好，通过偏好反转方法直接优化PLE，实现优于Reinforcement Learning from Human Feedback (RLHF)和Low-Rank Adaptation (LoRA)的偏好对齐效果。为验证实际应用，该研究创建了一个基准实验，使用真实人类偏好评估多样、高奖励轨迹的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.18347v1",
      "published_date": "2025-03-24 05:11:58 UTC",
      "updated_date": "2025-03-24 05:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:48:06.643322"
    },
    {
      "arxiv_id": "2503.18331v1",
      "title": "Optimizing Influence Campaigns: Nudging under Bounded Confidence",
      "title_zh": "优化影响宣传活动：在有限置信度下的引导",
      "authors": [
        "Yen-Shao Chen",
        "Tauhid Zaman"
      ],
      "abstract": "Influence campaigns in online social networks are often run by organizations,\npolitical parties, and nation states to influence large audiences. These\ncampaigns are employed through the use of agents in the network that share\npersuasive content. Yet, their impact might be minimal if the audiences remain\nunswayed, often due to the bounded confidence phenomenon, where only a narrow\nspectrum of viewpoints can influence them. Here we show that to persuade under\nbounded confidence, an agent must nudge its targets to gradually shift their\nopinions. Using a control theory approach, we show how to construct an agent's\nnudging policy under the bounded confidence opinion dynamics model and also how\nto select targets for multiple agents in an influence campaign on a social\nnetwork. Simulations on real Twitter networks show that a multi-agent nudging\npolicy can shift the mean opinion, decrease opinion polarization, or even\nincrease it. We find that our nudging based policies outperform other common\ntechniques that do not consider the bounded confidence effect. Finally, we show\nhow to craft prompts for large language models, such as ChatGPT, to generate\ntext-based content for real nudging policies. This illustrates the practical\nfeasibility of our approach, allowing one to go from mathematical nudging\npolicies to real social media content.",
      "tldr_zh": "本文研究了如何在bounded confidence（受限信心）条件下优化在线社交网络的影响活动，提出通过代理人nudging（推动）策略来逐渐改变目标意见，从而提升说服效果。利用控制理论方法，该框架构建了多代理人的nudging政策，并通过Twitter网络模拟证明其能有效改变平均意见、减少或增加意见两极分化，且优于不考虑bounded confidence的传统技术。最终，论文展示了如何为大型语言模型（如ChatGPT）设计提示，以生成实际的文本内容，实现从理论政策到社交媒体应用的转化。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18331v1",
      "published_date": "2025-03-24 04:30:58 UTC",
      "updated_date": "2025-03-24 04:30:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:48:19.513309"
    },
    {
      "arxiv_id": "2503.18324v1",
      "title": "Plug-and-Play Interpretable Responsible Text-to-Image Generation via Dual-Space Multi-facet Concept Control",
      "title_zh": "翻译失败",
      "authors": [
        "Basim Azam",
        "Naveed Akhtar"
      ],
      "abstract": "Ethical issues around text-to-image (T2I) models demand a comprehensive\ncontrol over the generative content. Existing techniques addressing these\nissues for responsible T2I models aim for the generated content to be fair and\nsafe (non-violent/explicit). However, these methods remain bounded to handling\nthe facets of responsibility concepts individually, while also lacking in\ninterpretability. Moreover, they often require alteration to the original\nmodel, which compromises the model performance. In this work, we propose a\nunique technique to enable responsible T2I generation by simultaneously\naccounting for an extensive range of concepts for fair and safe content\ngeneration in a scalable manner. The key idea is to distill the target T2I\npipeline with an external plug-and-play mechanism that learns an interpretable\ncomposite responsible space for the desired concepts, conditioned on the target\nT2I pipeline. We use knowledge distillation and concept whitening to enable\nthis. At inference, the learned space is utilized to modulate the generative\ncontent. A typical T2I pipeline presents two plug-in points for our approach,\nnamely; the text embedding space and the diffusion model latent space. We\ndevelop modules for both points and show the effectiveness of our approach with\na range of strong results.",
      "tldr_zh": "本文提出了一种即插即用 (plug-and-play) 方法，用于可解释的负责任文本到图像 (T2I) 生成，通过双空间多方面概念控制 (dual-space multi-facet concept control) 同时处理公平和安全概念。关键技术包括知识蒸馏 (knowledge distillation) 和概念白化 (concept whitening)，用于在文本嵌入空间和扩散模型潜在空间中学习一个可解释的复合责任空间，从而调节生成内容，而无需修改原模型。该方法在实验中展示了强大的可扩展性和有效性，能够全面提升 T2I 模型的伦理性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18324v1",
      "published_date": "2025-03-24 04:06:39 UTC",
      "updated_date": "2025-03-24 04:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:48:32.724262"
    },
    {
      "arxiv_id": "2503.18320v1",
      "title": "Bridging Writing Manner Gap in Visual Instruction Tuning by Creating LLM-aligned Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Jing",
        "Nanyi Fei",
        "Zhiwu Lu"
      ],
      "abstract": "In the realm of Large Multi-modal Models (LMMs), the instruction quality\nduring the visual instruction tuning stage significantly influences the\nperformance of modality alignment. In this paper, we assess the instruction\nquality from a unique perspective termed \\textbf{Writing Manner}, which\nencompasses the selection of vocabulary, grammar and sentence structure to\nconvey specific semantics. We argue that there exists a substantial writing\nmanner gap between the visual instructions and the base Large Language Models\n(LLMs) within LMMs. This gap forces the pre-trained base LLMs to deviate from\ntheir original writing styles, leading to capability degradation of both base\nLLMs and LMMs. To bridge the writing manner gap while preserving the original\nsemantics, we propose directly leveraging the base LLM to align the writing\nmanner of soft-format visual instructions with that of the base LLM itself,\nresulting in novel LLM-aligned instructions. The manual writing manner\nevaluation results demonstrate that our approach successfully minimizes the\nwriting manner gap. By utilizing LLM-aligned instructions, the baseline models\nLLaVA-7B and QwenVL demonstrate enhanced resistance to hallucinations and\nnon-trivial comprehensive improvements across all $15$ visual and language\nbenchmarks.",
      "tldr_zh": "本研究从写作方式（Writing Manner，包括词汇选择、语法和句子结构）的角度评估 Large Multi-modal Models (LMMs) 中视觉指令微调的指令质量，指出视觉指令与基底 Large Language Models (LLMs) 之间存在显著写作方式差距，导致模型能力下降。针对这一问题，论文提出一种方法，使用基底 LLM 直接调整软格式视觉指令的写作风格，生成 LLM-aligned instructions，同时保留原有语义。实验结果显示，这种方法显著缩小了写作方式差距，使基准模型如 LLaVA-7B 和 QwenVL 增强了抗幻觉能力，并在 15 个视觉和语言基准上实现了全面性能提升。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18320v1",
      "published_date": "2025-03-24 03:59:06 UTC",
      "updated_date": "2025-03-24 03:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:48:43.262033"
    },
    {
      "arxiv_id": "2503.18314v3",
      "title": "LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Christoforos N. Spartalis",
        "Theodoros Semertzidis",
        "Efstratios Gavves",
        "Petros Daras"
      ],
      "abstract": "We present LoTUS, a novel Machine Unlearning (MU) method that eliminates the\ninfluence of training samples from pre-trained models, avoiding retraining from\nscratch. LoTUS smooths the prediction probabilities of the model up to an\ninformation-theoretic bound, mitigating its over-confidence stemming from data\nmemorization. We evaluate LoTUS on Transformer and ResNet18 models against\neight baselines across five public datasets. Beyond established MU benchmarks,\nwe evaluate unlearning on ImageNet1k, a large-scale dataset, where retraining\nis impractical, simulating real-world conditions. Moreover, we introduce the\nnovel Retrain-Free Jensen-Shannon Divergence (RF-JSD) metric to enable\nevaluation under real-world conditions. The experimental results show that\nLoTUS outperforms state-of-the-art methods in terms of both efficiency and\neffectiveness. Code: https://github.com/cspartalis/LoTUS.",
      "tldr_zh": "本研究提出了一种名为 LoTUS 的 Machine Unlearning (MU) 方法，用于从预训练模型中消除训练样本的影响，而无需从零开始重新训练。LoTUS 通过平滑模型的预测概率直至信息理论边界，缓解模型因数据记忆导致的过度自信，从而提升其在真实场景下的鲁棒性。在实验中，LoTUS 在 Transformer 和 ResNet18 模型上与八个基线方法进行了比较，并在五个公共数据集以及大规模 ImageNet1k 上表现出优越性能，同时引入了新的 Retrain-Free Jensen-Shannon Divergence (RF-JSD) 指标来评估其有效性。结果表明，LoTUS 在效率和效果上超越了现有方法，为大规模 MU 应用提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a main conference paper at CVPR 2025\n  (https://cvpr.thecvf.com/virtual/2025/poster/33292)",
      "pdf_url": "http://arxiv.org/pdf/2503.18314v3",
      "published_date": "2025-03-24 03:34:23 UTC",
      "updated_date": "2025-05-07 15:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:48:57.248289"
    },
    {
      "arxiv_id": "2503.18313v1",
      "title": "DeepFund: Will LLM be Professional at Fund Investment? A Live Arena Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Changlun Li",
        "Yao Shi",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\nvarious domains, but their effectiveness in financial decision making,\nparticularly in fund investment, remains inadequately evaluated. Current\nbenchmarks primarily assess LLMs understanding of financial documents rather\nthan their ability to manage assets or analyze trading opportunities in dynamic\nmarket conditions. A critical limitation in existing evaluation methodologies\nis the backtesting approach, which suffers from information leakage when LLMs\nare evaluated on historical data they may have encountered during pretraining.\nThis paper introduces DeepFund, a comprehensive platform for evaluating LLM\nbased trading strategies in a simulated live environment. Our approach\nimplements a multi agent framework where LLMs serve as both analysts and\nmanagers, creating a realistic simulation of investment decision making. The\nplatform employs a forward testing methodology that mitigates information\nleakage by evaluating models on market data released after their training\ncutoff dates. We provide a web interface that visualizes model performance\nacross different market conditions and investment parameters, enabling detailed\ncomparative analysis. Through DeepFund, we aim to provide a more accurate and\nfair assessment of LLMs capabilities in fund investment, offering insights into\ntheir potential real world applications in financial markets.",
      "tldr_zh": "该论文引入DeepFund平台，以评估大型语言模型(LLM)在基金投资中的专业性，解决现有基准仅关注文档理解而非动态市场决策的问题。DeepFund采用多智能体框架和forward testing方法，让LLM充当分析师和经理，在模拟实时环境中进行评估，从而避免backtesting中的信息泄露。平台提供web界面可视化模型在不同市场条件和投资参数下的表现，最终为LLM在金融市场的实际应用提供更准确的洞见。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CE",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.18313v1",
      "published_date": "2025-03-24 03:32:13 UTC",
      "updated_date": "2025-03-24 03:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:49:06.882109"
    },
    {
      "arxiv_id": "2503.18998v1",
      "title": "FACE: Few-shot Adapter with Cross-view Fusion for Cross-subject EEG Emotion Recognition",
      "title_zh": "FACE：少样本适配器结合跨视图融合，用于跨",
      "authors": [
        "Haiqi Liu",
        "C. L. Philip Chen",
        "Tong Zhang"
      ],
      "abstract": "Cross-subject EEG emotion recognition is challenged by significant\ninter-subject variability and intricately entangled intra-subject variability.\nExisting works have primarily addressed these challenges through domain\nadaptation or generalization strategies. However, they typically require\nextensive target subject data or demonstrate limited generalization performance\nto unseen subjects. Recent few-shot learning paradigms attempt to address these\nlimitations but often encounter catastrophic overfitting during\nsubject-specific adaptation with limited samples. This article introduces the\nfew-shot adapter with a cross-view fusion method called FACE for cross-subject\nEEG emotion recognition, which leverages dynamic multi-view fusion and\neffective subject-specific adaptation. Specifically, FACE incorporates a\ncross-view fusion module that dynamically integrates global brain connectivity\nwith localized patterns via subject-specific fusion weights to provide\ncomplementary emotional information. Moreover, the few-shot adapter module is\nproposed to enable rapid adaptation for unseen subjects while reducing\noverfitting by enhancing adapter structures with meta-learning. Experimental\nresults on three public EEG emotion recognition benchmarks demonstrate FACE's\nsuperior generalization performance over state-of-the-art methods. FACE\nprovides a practical solution for cross-subject scenarios with limited labeled\ndata.",
      "tldr_zh": "这篇论文针对跨主体 EEG 情绪识别中的主体间变异性和主体内变异性挑战，提出了 FACE 方法，即一种结合 cross-view fusion 的 few-shot adapter 机制，以实现高效的主体特定适应。FACE 通过 cross-view fusion 模块动态整合全局脑连接和局部模式，使用主体特定的融合权重来提供互补的情绪信息，同时利用 few-shot adapter 模块和 meta-learning 技术减少过拟合风险。实验结果显示，在三个公共 EEG 情绪识别基准上，FACE 比最先进方法具有更优的泛化性能，为有限标记数据的跨主体场景提供实用解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.18998v1",
      "published_date": "2025-03-24 03:16:52 UTC",
      "updated_date": "2025-03-24 03:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:49:19.128665"
    },
    {
      "arxiv_id": "2503.18303v1",
      "title": "How to Capture and Study Conversations Between Research Participants and ChatGPT: GPT for Researchers (g4r.org)",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Kim"
      ],
      "abstract": "As large language models (LLMs) like ChatGPT become increasingly integrated\ninto our everyday lives--from customer service and education to creative work\nand personal productivity--understanding how people interact with these AI\nsystems has become a pressing issue. Despite the widespread use of LLMs,\nresearchers lack standardized tools for systematically studying people's\ninteractions with LLMs. To address this issue, we introduce GPT for Researchers\n(G4R), or g4r.org, a free website that researchers can use to easily create and\nintegrate a GPT Interface into their studies. At g4r.org, researchers can (1)\nenable their study participants to interact with GPT (such as ChatGPT), (2)\ncustomize GPT Interfaces to guide participants' interactions with GPT (e.g.,\nset constraints on topics or adjust GPT's tone or response style), and (3)\ncapture participants' interactions with GPT by downloading data on messages\nexchanged between participants and GPT. By facilitating study participants'\ninteractions with GPT and providing detailed data on these interactions, G4R\ncan support research on topics such as consumer interactions with AI agents or\nLLMs, AI-assisted decision-making, and linguistic patterns in human-AI\ncommunication. With this goal in mind, we provide a step-by-step guide to using\nG4R at g4r.org.",
      "tldr_zh": "研究人员推出了 GPT for Researchers (G4R) 或 g4r.org，这是一个免费网站，旨在解决缺乏标准化工具的问题，用于系统研究人们与大型语言模型(LLMs)如 ChatGPT 的互动。G4R 允许研究者创建自定义 GPT 接口，让参与者与 GPT 互动、设置主题约束或调整响应风格，并捕获并下载互动数据。借助这一工具，研究者可以探索消费者与 AI 代理的互动、AI 辅助决策以及人类-AI 沟通的语言模式，并通过提供的步步指南轻松应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18303v1",
      "published_date": "2025-03-24 03:10:12 UTC",
      "updated_date": "2025-03-24 03:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:49:30.601953"
    },
    {
      "arxiv_id": "2503.18302v1",
      "title": "DiffMove: Group Mobility Tendency Enhanced Trajectory Recovery via Diffusion Model",
      "title_zh": "DiffMove: 通过扩散模型增强群体移动倾向的轨迹恢复",
      "authors": [
        "Qingyue Long",
        "Can Rong",
        "Huandong Wang",
        "Shaw Rajib",
        "Yong Li"
      ],
      "abstract": "In the real world, trajectory data is often sparse and incomplete due to low\ncollection frequencies or limited device coverage. Trajectory recovery aims to\nrecover these missing trajectory points, making the trajectories denser and\nmore complete. However, this task faces two key challenges: 1) The excessive\nsparsity of individual trajectories makes it difficult to effectively leverage\nhistorical information for recovery; 2) Sparse trajectories make it harder to\ncapture complex individual mobility preferences. To address these challenges,\nwe propose a novel method called DiffMove. Firstly, we harness crowd wisdom for\ntrajectory recovery. Specifically, we construct a group tendency graph using\nthe collective trajectories of all users and then integrate the group mobility\ntrends into the location representations via graph embedding. This solves the\nchallenge of sparse trajectories being unable to rely on individual historical\ntrajectories for recovery. Secondly, we capture individual mobility preferences\nfrom both historical and current perspectives. Finally, we integrate group\nmobility tendencies and individual preferences into the spatiotemporal\ndistribution of the trajectory to recover high-quality trajectories. Extensive\nexperiments on two real-world datasets demonstrate that DiffMove outperforms\nexisting state-of-the-art methods. Further analysis validates the robustness of\nour method.",
      "tldr_zh": "本研究针对轨迹数据稀疏不完整的问题，提出了一种名为DiffMove的创新方法，利用Diffusion Model增强轨迹恢复。DiffMove首先构建Group Mobility Tendency图，通过图嵌入整合群体移动趋势来弥补个体轨迹的稀疏性，并从历史和当前视角捕捉个体移动偏好；随后，将这些趋势与偏好融入轨迹的时空分布中，实现高质量的轨迹恢复。在两个真实世界数据集上的广泛实验表明，DiffMove优于现有最先进方法，并展示了良好的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18302v1",
      "published_date": "2025-03-24 03:08:21 UTC",
      "updated_date": "2025-03-24 03:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:49:42.658234"
    },
    {
      "arxiv_id": "2503.18290v1",
      "title": "When is dataset cartography ineffective? Using training dynamics does not improve robustness against Adversarial SQuAD",
      "title_zh": "翻译失败",
      "authors": [
        "Paul K. Mandal"
      ],
      "abstract": "In this paper, I investigate the effectiveness of dataset cartography for\nextractive question answering on the SQuAD dataset. I begin by analyzing\nannotation artifacts in SQuAD and evaluate the impact of two adversarial\ndatasets, AddSent and AddOneSent, on an ELECTRA-small model. Using training\ndynamics, I partition SQuAD into easy-to-learn, ambiguous, and hard-to-learn\nsubsets. I then compare the performance of models trained on these subsets to\nthose trained on randomly selected samples of equal size. Results show that\ntraining on cartography-based subsets does not improve generalization to the\nSQuAD validation set or the AddSent adversarial set. While the hard-to-learn\nsubset yields a slightly higher F1 score on the AddOneSent dataset, the overall\ngains are limited. These findings suggest that dataset cartography provides\nlittle benefit for adversarial robustness in SQuAD-style QA tasks. I conclude\nby comparing these results to prior findings on SNLI and discuss possible\nreasons for the observed differences.",
      "tldr_zh": "本研究调查了在SQuAD数据集上使用dataset cartography和training dynamics是否能提升抽取式问答任务的鲁棒性，特别是针对Adversarial SQuAD（如AddSent和AddOneSent）的影响。作者通过将SQuAD分区为易学、模糊和难学子集，并与随机样本训练的模型进行比较，发现基于cartography的子集训练并未改善模型对SQuAD验证集或AddSent的泛化性能，仅在AddOneSent上略微提高了F1 score。总体结果表明，dataset cartography对SQuAD-style QA任务的adversarial robustness几乎无益，并与SNLI数据集的先前发现进行了对比，讨论了潜在差异。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; I.2.6; I.5.1"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.18290v1",
      "published_date": "2025-03-24 02:24:18 UTC",
      "updated_date": "2025-03-24 02:24:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:49:57.418011"
    },
    {
      "arxiv_id": "2503.18283v1",
      "title": "Voxel-based Point Cloud Geometry Compression with Space-to-Channel Context",
      "title_zh": "翻译失败",
      "authors": [
        "Bojun Liu",
        "Yangzhi Ma",
        "Ao Luo",
        "Li Li",
        "Dong Liu"
      ],
      "abstract": "Voxel-based methods are among the most efficient for point cloud geometry\ncompression, particularly with dense point clouds. However, they face\nlimitations due to a restricted receptive field, especially when handling\nhigh-bit depth point clouds. To overcome this issue, we introduce a stage-wise\nSpace-to-Channel (S2C) context model for both dense point clouds and low-level\nsparse point clouds. This model utilizes a channel-wise autoregressive strategy\nto effectively integrate neighborhood information at a coarse resolution. For\nhigh-level sparse point clouds, we further propose a level-wise S2C context\nmodel that addresses resolution limitations by incorporating Geometry Residual\nCoding (GRC) for consistent-resolution cross-level prediction. Additionally, we\nuse the spherical coordinate system for its compact representation and enhance\nour GRC approach with a Residual Probability Approximation (RPA) module, which\nfeatures a large kernel size. Experimental results show that our S2C context\nmodel not only achieves bit savings while maintaining or improving\nreconstruction quality but also reduces computational complexity compared to\nstate-of-the-art voxel-based compression methods.",
      "tldr_zh": "这篇论文提出了一种基于体素的点云几何压缩方法，使用 Space-to-Channel (S2C) 上下文模型来解决受限感受野问题，尤其适用于密集点云和高位深度点云。方法包括 stage-wise S2C 通过 channel-wise 自回归策略整合粗分辨率邻域信息，以及 level-wise S2C 结合 Geometry Residual Coding (GRC) 进行跨级别预测，并使用球坐标系统和 Residual Probability Approximation (RPA) 模块增强压缩效率。实验结果显示，该模型在保持或提升重建质量的同时，实现比特率节省并降低计算复杂度，优于现有体素-based 压缩方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.18283v1",
      "published_date": "2025-03-24 01:56:08 UTC",
      "updated_date": "2025-03-24 01:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:50:07.479987"
    },
    {
      "arxiv_id": "2503.18278v2",
      "title": "TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Yang",
        "Yang Sui",
        "Jinqi Xiao",
        "Lingyi Huang",
        "Yu Gong",
        "Chendi Li",
        "Jinghua Yan",
        "Yu Bai",
        "Ponnuswamy Sadayappan",
        "Xia Hu",
        "Bo Yuan"
      ],
      "abstract": "Vision-Language Models (VLMs) demand substantial computational resources\nduring inference, largely due to the extensive visual input tokens for\nrepresenting visual information. Previous studies have noted that visual tokens\ntend to receive less attention than text tokens, suggesting their lower\nimportance during inference and potential for pruning. However, their methods\nencounter several challenges: reliance on greedy heuristic criteria for token\nimportance and incompatibility with FlashAttention and KV cache. To address\nthese issues, we introduce \\textbf{TopV}, a compatible \\textbf{TO}ken\n\\textbf{P}runing with inference Time Optimization for fast and low-memory\n\\textbf{V}LM, achieving efficient pruning without additional training or\nfine-tuning. Instead of relying on attention scores, we formulate token pruning\nas an optimization problem, accurately identifying important visual tokens\nwhile remaining compatible with FlashAttention. Additionally, since we only\nperform this pruning once during the prefilling stage, it effectively reduces\nKV cache size. Our optimization framework incorporates a visual-aware cost\nfunction considering factors such as Feature Similarity, Relative Spatial\nDistance, and Absolute Central Distance, to measure the importance of each\nsource visual token, enabling effective pruning of low-importance tokens.\nExtensive experiments demonstrate that our method outperforms previous token\npruning methods, validating the effectiveness and efficiency of our approach.",
      "tldr_zh": "这篇论文针对视觉语言模型(VLMs)推理过程中的高计算需求，提出TopV方法，通过兼容的token pruning和推理时间优化，实现快速、低内存的多模态VLMs，而无需额外训练或微调。TopV将token pruning制定为优化问题，使用视觉感知成本函数（如Feature Similarity、Relative Spatial Distance和Absolute Central Distance）来评估并修剪低重要性视觉tokens，并在预填充阶段一次性执行，以兼容FlashAttention并减少KV cache大小。实验结果显示，TopV在效率和性能上优于现有方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18278v2",
      "published_date": "2025-03-24 01:47:26 UTC",
      "updated_date": "2025-03-29 23:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:50:18.862051"
    },
    {
      "arxiv_id": "2504.08745v1",
      "title": "Improving RAG for Personalization with Author Features and Contrastive Examples",
      "title_zh": "使用作者特征和对比示例改进 RAG 以实现个性化",
      "authors": [
        "Mert Yazan",
        "Suzan Verberne",
        "Frederik Situmeang"
      ],
      "abstract": "Personalization with retrieval-augmented generation (RAG) often fails to\ncapture fine-grained features of authors, making it hard to identify their\nunique traits. To enrich the RAG context, we propose providing Large Language\nModels (LLMs) with author-specific features, such as average sentiment polarity\nand frequently used words, in addition to past samples from the author's\nprofile. We introduce a new feature called Contrastive Examples: documents from\nother authors are retrieved to help LLM identify what makes an author's style\nunique in comparison to others. Our experiments show that adding a couple of\nsentences about the named entities, dependency patterns, and words a person\nuses frequently significantly improves personalized text generation. Combining\nfeatures with contrastive examples boosts the performance further, achieving a\nrelative 15% improvement over baseline RAG while outperforming the benchmarks.\nOur results show the value of fine-grained features for better personalization,\nwhile opening a new research dimension for including contrastive examples as a\ncomplement with RAG. We release our code publicly.",
      "tldr_zh": "本研究针对检索增强生成（RAG）在个性化文本生成中的不足，提出通过添加作者特定特征（如平均情感极性、常用词、命名实体和依赖模式）来丰富LLM的上下文，并引入Contrastive Examples（从其他作者文档中检索内容），以帮助LLM更好地识别作者风格的独特性。实验表明，这种结合方法显著提升了个性化性能，相对于基线RAG提高了15%，并超越了现有基准。总体上，该方法突出了细粒度特征的价值，并为Contrastive Examples作为RAG补充的新研究维度提供了启发。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08745v1",
      "published_date": "2025-03-24 01:41:22 UTC",
      "updated_date": "2025-03-24 01:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:50:31.321990"
    },
    {
      "arxiv_id": "2503.18265v1",
      "title": "Risk Management for Distributed Arbitrage Systems: Integrating Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Akaash Vishal Hazarika",
        "Mahak Shah",
        "Swapnil Patil",
        "Pradyumna Shukla"
      ],
      "abstract": "Effective risk management solutions become absolutely crucial when financial\nmarkets embrace distributed technology and decentralized financing (DeFi). This\nstudy offers a thorough survey and comparative analysis of the integration of\nartificial intelligence (AI) in risk management for distributed arbitrage\nsystems. We examine several modern caching techniques namely in memory caching,\ndistributed caching, and proxy caching and their functions in enhancing\nperformance in decentralized settings. Through literature review we examine the\nutilization of AI techniques for alleviating risks related to market\nvolatility, liquidity challenges, operational failures, regulatory compliance,\nand security threats. This comparison research evaluates various case studies\nfrom prominent DeFi technologies, emphasizing critical performance metrics like\nlatency reduction, load balancing, and system resilience. Additionally, we\nexamine the problems and trade offs associated with these technologies,\nemphasizing their effects on consistency, scalability, and fault tolerance. By\nmeticulously analyzing real world applications, specifically centering on the\nAave platform as our principal case study, we illustrate how the purposeful\namalgamation of AI with contemporary caching methodologies has revolutionized\nrisk management in distributed arbitrage systems.",
      "tldr_zh": "该研究对人工智能（AI）在分布式套利系统风险管理中的整合进行全面调查和比较分析，强调了在分布式技术和去中心化金融（DeFi）环境中有效风险管理的必要性。通过考察内存缓存（in-memory caching）、分布式缓存（distributed caching）和代理缓存（proxy caching）等技术，该论文探讨了AI如何缓解市场波动、流动性挑战、操作故障、监管合规和安全威胁。研究通过文献综述和案例分析（如Aave平台）评估关键性能指标，包括延迟减少、负载均衡和系统弹性，同时讨论了这些方法的挑战，如对一致性、可伸缩性和容错性的权衡影响。最终，该工作展示了AI与现代缓存技术的结合如何革新分布式套利系统的风险管理，提供更具弹性的解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "I.2.11; G.3"
      ],
      "primary_category": "cs.DC",
      "comment": "International Conference on AI and Financial Innovation AIFI-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.18265v1",
      "published_date": "2025-03-24 01:15:43 UTC",
      "updated_date": "2025-03-24 01:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:50:42.988222"
    },
    {
      "arxiv_id": "2503.18258v3",
      "title": "Severing Spurious Correlations with Data Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Varun Mulchandani",
        "Jung-Eun Kim"
      ],
      "abstract": "Deep neural networks have been shown to learn and rely on spurious\ncorrelations present in the data that they are trained on. Reliance on such\ncorrelations can cause these networks to malfunction when deployed in the real\nworld, where these correlations may no longer hold. To overcome the learning of\nand reliance on such correlations, recent studies propose approaches that yield\npromising results. These works, however, study settings where the strength of\nthe spurious signal is significantly greater than that of the core, invariant\nsignal, making it easier to detect the presence of spurious features in\nindividual training samples and allow for further processing. In this paper, we\nidentify new settings where the strength of the spurious signal is relatively\nweaker, making it difficult to detect any spurious information while continuing\nto have catastrophic consequences. We also discover that spurious correlations\nare learned primarily due to only a handful of all the samples containing the\nspurious feature and develop a novel data pruning technique that identifies and\nprunes small subsets of the training data that contain these samples. Our\nproposed technique does not require inferred domain knowledge, information\nregarding the sample-wise presence or nature of spurious information, or human\nintervention. Finally, we show that such data pruning attains state-of-the-art\nperformance on previously studied settings where spurious information is\nidentifiable.",
      "tldr_zh": "本研究发现，深度神经网络在训练数据中常依赖spurious correlations，导致实际部署时失效，尤其在spurious信号较弱的新场景中，问题更难检测但后果严重。论文揭示这些相关性主要由少数样本引起，并提出了一种新型data pruning技术，通过自动识别并修剪这些样本来消除虚假相关性，而无需推断领域知识、样本级信息或人工干预。实验结果显示，该方法在现有和新型设置中均达到了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025, Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2503.18258v3",
      "published_date": "2025-03-24 00:57:32 UTC",
      "updated_date": "2025-05-17 19:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:50:54.476095"
    },
    {
      "arxiv_id": "2503.18255v1",
      "title": "The Human-Machine Identity Blur: A Unified Framework for Cybersecurity Risk Management in 2025",
      "title_zh": "人机身份模糊：2025年网络安全风险管理的统一框架",
      "authors": [
        "Kush Janani"
      ],
      "abstract": "The modern enterprise is facing an unprecedented surge in digital identities,\nwith machine identities now significantly outnumbering human identities. This\npaper examines the cybersecurity risks emerging from what we define as the\n\"human-machine identity blur\" - the point at which human and machine identities\nintersect, delegate authority, and create new attack surfaces. Drawing from\nindustry data, expert insights, and real-world incident analysis, we identify\nkey governance gaps in current identity management models that treat human and\nmachine entities as separate domains. To address these challenges, we propose a\nUnified Identity Governance Framework based on four core principles: treating\nidentity as a continuum rather than a binary distinction, applying consistent\nrisk evaluation across all identity types, implementing continuous verification\nguided by zero trust principles, and maintaining governance throughout the\nentire identity lifecycle. Our research shows that organizations adopting this\nunified approach experience a 47 percent reduction in identity-related security\nincidents and a 62 percent improvement in incident response time. We conclude\nby offering a practical implementation roadmap and outlining future research\ndirections as AI-driven systems become increasingly autonomous.",
      "tldr_zh": "该论文探讨了2025年网络安全领域的“human-machine identity blur”现象，即人类和机器身份交织导致的新攻击面和治理缺口。通过分析行业数据和真实事件，该研究识别出当前身份管理模型将人类和机器实体视为独立领域的不足，并提出“Unified Identity Governance Framework”，基于四个核心原则：将身份视为连续体、一致风险评估、零信任原则的持续验证，以及全生命周期治理。研究发现，采用该框架的企业可将身份相关安全事件减少47%，并将事件响应时间提高62%。最终，该论文提供了一个实用实施路线图，并指出未来AI驱动系统自治的研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18255v1",
      "published_date": "2025-03-24 00:37:14 UTC",
      "updated_date": "2025-03-24 00:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T05:51:06.500050"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T05:51:25.732053"
}