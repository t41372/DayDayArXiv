{
  "date": "2025-04-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-25 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和大型语言模型（LLM）的优化、安全及应用扩展，包括高效参数适应、AI 在医疗和机器人领域的创新，以及多模态处理和知识图谱等话题；令人印象深刻的文章有 TLoRA 的低秩适应方法和 Proof-of-TBI 的 AI 诊断系统，而知名学者如 Lav R. Varshney 和 Ramesh Jain 的作品则突出在科学创意和食物知识图谱方面的贡献。\n\n下面，我将挑选并讨论今天更重要的论文，先从 AI/LLM 相关主题入手，再聊医疗和机器人领域，将相似的论文归并讨论。对于其他较常规或次要的文章，我会快速掠过，只列出标题和核心要点，以保持简洁。\n\n### AI 和 LLM 优化与应用\n- **TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models（TLoRA: 三矩阵低秩适应大型语言模型）**  \n  这篇论文提出 TLoRA 方法，将权重更新分解为两个固定随机矩阵和一个可训练矩阵，显著减少了 LLM 的训练参数，同时在 GLUE 基准上与 LoRA 相当；主要贡献是提升参数效率，适合资源受限的模型适应场景。\n\n- **MODP: Multi Objective Directional Prompting（MODP: 多目标定向提示）**  \n  作者 Aashutosh Nema 等人开发了 MODP 框架，结合多目标优化和指标驱动的提示工程，提高了 LLM 在摘要任务中的性能，实现了 26% 的改进；关键发现是考虑 LLM 的内在行为能生成更鲁棒的提示，已应用于 Dell 的支持工具。\n\n- **Self-Healing Software Systems: Lessons from Nature, Powered by AI（自愈软件系统: 借鉴自然的 AI 驱动方法）**  \n  这篇与 MODP 相关的论文借鉴生物愈合机制，提出 AI 驱动的自愈框架，使用日志分析和 AI 修复减少软件宕机；主要贡献是提升软件弹性，实验显示其优于传统调试流程。\n\n- **Spark: A System for Scientifically Creative Idea Generation（Spark: 科学创意idea生成系统）**  \n  作者 Lav R. Varshney 等知名学者构建了 Spark 系统，结合 LLM 和检索增强生成科学idea，并训练 Reviewer 模型；发现它能生成高质量idea，数据集已开源，促进计算创意研究。\n\n- **Transformational Creativity in Science: A Graphical Theory（科学中的变革性创意: 图论框架）**  \n  同样由 Var R. Varshney 参与，这篇论文提供图论模型解释科学范式转变，证明修改公理能实现最大变革；核心是理论合成，适用于历史案例分析。\n\n其他 AI 相关论文如 **Fast-Slow Thinking for Large Vision-Language Model Reasoning（快速-缓慢思考用于大型视觉语言模型推理）** 和 **Efficient Single-Pass Training for Multi-Turn Reasoning（高效单次训练用于多轮推理）**，它们优化了 LLM 的推理过程，前者通过动态调整推理深度减少令牌使用，后者简化多轮训练；这些方法在基准上提升了性能，但细节较常规，故快速掠过。\n\n### 医疗和健康应用\n- **Proof-of-TBI: Fine-Tuned Vision Language Model Consortium for Mild Traumatic Brain Injury Prediction（Proof-of-TBI: 微调视觉语言模型联盟用于轻度脑外伤预测）**  \n  这篇印象深刻的论文整合多个微调视觉语言模型和 OpenAI-o3 LLM，构建脑外伤诊断系统；主要发现是提高了诊断准确性，首个应用于 TBI 的多模型框架。\n\n- **A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection（基于梯度优化的 TSK 模糊框架用于可解释的网络钓鱼检测）**  \n  作者 Kelly Cohen 等人提出 TSK 模糊模型优化钓鱼 URL 检测，结合模糊逻辑和 Adam 优化器，达到 99.95% 准确率；贡献在于提供可解释决策，提升网络安全。\n\n- **Research on Personalized Medical Intervention Strategy Generation System（基于群相对策略优化和时序数据融合的个性化医疗干预策略生成系统）**  \n  这篇论文开发了 GRPO 和时序融合框架，生成个性化干预策略；关键发现是提高了决策鲁棒性，实验显示其在医疗数据上优于现有方法。\n\n其他医疗论文如 **Enhancing Pre-Trained Model-Based Class-Incremental Learning（增强基于预训练模型的类增量学习）**，它通过神经坍缩改善模型泛化，但影响较小，故不深究。\n\n### 机器人和计算机视觉\n- **SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding（SORT3D: 零样本 3D  grounding 的空间对象中心推理工具箱）**  \n  作者 Wenshan Wang 等人提出 SORT3D 方法，使用 LLM 和空间推理工具实现零样本 3D 对象定位；主要贡献是无需训练数据即可应用于机器人导航，代码已开源。\n\n- **HierSum: A Global and Local Attention Mechanism for Video Summarization（HierSum: 视频摘要的全局和局部注意力机制）**  \n  这篇论文引入 HierSum 框架，结合字幕和视频指令生成教学视频摘要；发现它在 TVSum 等基准上提升 F1 分数，适用于多模态数据。\n\n其他机器人论文如 **M2R2: Multimodal Robotic Representation for Temporal Action Segmentation（M2R2: 多模态机器人表示用于时序动作分割）**，它优化多模态特征融合，但实验较为具体，故快速提及。\n\n### 其他领域快速掠过\n今天还有一些论文涉及教育、环境和数据隐私，如 **World Food Atlas Project（世界食物图谱项目）** 和 **An Integrated Framework for Contextual Personalized LLM-Based Food Recommendation（基于 LLM 的情境个性化食物推荐框架）**，作者 Ramesh Jain 等提出食物知识图谱和推荐系统，提升了食物数据整合；以及 **DeSIA: Attribute Inference Attacks（DeSIA: 属性推断攻击）**，它分析数据隐私风险，但这些主题较 niche，仅列出标题，不深议。\n\n总之，今天的 arXiv 更新突显 AI 领域的创新潜力，特别是在 LLM 效率和医疗应用上。感兴趣的读者可关注 TLoRA 和 Proof-of-TBI 等论文，以探索实际落地。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2504.18735v1",
      "title": "TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tanvir Islam"
      ],
      "abstract": "We propose TLoRA, a novel tri-matrix low-rank adaptation method that\ndecomposes weight updates into three matrices: two fixed random matrices and\none trainable matrix, combined with a learnable, layer-wise scaling factor.\nThis tri-matrix design enables TLoRA to achieve highly efficient parameter\nadaptation while introducing minimal additional computational overhead. Through\nextensive experiments on the GLUE benchmark, we demonstrate that TLoRA achieves\ncomparable performance to existing low-rank methods such as LoRA and\nAdapter-based techniques, while requiring significantly fewer trainable\nparameters. Analyzing the adaptation dynamics, we observe that TLoRA exhibits\nGaussian-like weight distributions, stable parameter norms, and scaling factor\nvariability across layers, further highlighting its expressive power and\nadaptability. Additionally, we show that TLoRA closely resembles LoRA in its\neigenvalue distributions, parameter norms, and cosine similarity of updates,\nunderscoring its ability to effectively approximate LoRA's adaptation behavior.\nOur results establish TLoRA as a highly efficient and effective fine-tuning\nmethod for LLMs, offering a significant step forward in resource-efficient\nmodel adaptation.",
      "tldr_zh": "我们提出 TLoRA，一种新型的三矩阵低-rank adaptation 方法，将大型语言模型的权重更新分解为两个固定随机矩阵和一个可训练矩阵，并结合可学习的层级缩放因子，从而实现高效参数适应，同时最小化计算开销。  \n在 GLUE 基准测试中，TLoRA 与 LoRA 和 Adapter-based 技术相比，表现出相当的性能，但所需训练参数显著减少。  \n此外，分析显示 TLoRA 具有高斯分布的权重、稳定参数规范以及层间缩放因子变化，并与 LoRA 在特征值分布、参数规范和更新余弦相似性方面高度相似，证明了其作为资源高效 LLM 微调方法的强大适应性和潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18735v1",
      "published_date": "2025-04-25 23:11:10 UTC",
      "updated_date": "2025-04-25 23:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:33:16.150165"
    },
    {
      "arxiv_id": "2504.20093v1",
      "title": "Self-Healing Software Systems: Lessons from Nature, Powered by AI",
      "title_zh": "自愈软件系统：从自然界汲取的教训，由AI驱动",
      "authors": [
        "Mohammad Baqar",
        "Rajat Khanda",
        "Saba Naqvi"
      ],
      "abstract": "As modern software systems grow in complexity and scale, their ability to\nautonomously detect, diagnose, and recover from failures becomes increasingly\nvital. Drawing inspiration from biological healing - where the human body\ndetects damage, signals the brain, and activates targeted recovery - this paper\nexplores the concept of self-healing software driven by artificial\nintelligence. We propose a novel framework that mimics this biological model\nsystem observability tools serve as sensory inputs, AI models function as the\ncognitive core for diagnosis and repair, and healing agents apply targeted code\nand test modifications. By combining log analysis, static code inspection, and\nAI-driven generation of patches or test updates, our approach aims to reduce\ndowntime, accelerate debugging, and enhance software resilience. We evaluate\nthe effectiveness of this model through case studies and simulations, comparing\nit against traditional manual debugging and recovery workflows. This work paves\nthe way toward intelligent, adaptive and self-reliant software systems capable\nof continuous healing, akin to living organisms.",
      "tldr_zh": "本研究受生物愈合机制启发，提出一种AI驱动的自愈软件系统框架，旨在帮助软件自主检测、诊断和修复故障。该框架模拟人体愈合过程，使用observability tools作为sensory inputs、AI models作为cognitive core进行诊断，以及healing agents应用针对性的代码和测试修改，结合log analysis、static code inspection和AI-driven generation of patches来减少停机时间并加速调试。通过案例研究和模拟评估，该方法相较传统手动调试工作流程显著提升软件韧性，并为智能、适应性强的软件系统铺平道路。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20093v1",
      "published_date": "2025-04-25 22:54:57 UTC",
      "updated_date": "2025-04-25 22:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:33:28.072868"
    },
    {
      "arxiv_id": "2504.18727v1",
      "title": "World Food Atlas Project",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Rostami",
        "Z Xie",
        "A Ishino",
        "Y Yamakata",
        "K Aizawa",
        "Ramesh Jain"
      ],
      "abstract": "A coronavirus pandemic is forcing people to be \"at home\" all over the world.\nIn a life of hardly ever going out, we would have realized how the food we eat\naffects our bodies. What can we do to know our food more and control it better?\nTo give us a clue, we are trying to build a World Food Atlas (WFA) that\ncollects all the knowledge about food in the world. In this paper, we present\ntwo of our trials. The first is the Food Knowledge Graph (FKG), which is a\ngraphical representation of knowledge about food and ingredient relationships\nderived from recipes and food nutrition data. The second is the FoodLog Athl\nand the RecipeLog that are applications for collecting people's detailed\nrecords about food habit. We also discuss several problems that we try to solve\nto build the WFA by integrating these two ideas.",
      "tldr_zh": "该研究提出World Food Atlas (WFA)项目，旨在通过整合全球食物知识，帮助人们更好地了解和控制饮食，尤其在新冠疫情背景下。该项目包括构建Food Knowledge Graph (FKG)，这是一种从食谱和营养数据中提取的图形表示，用于展示食物和成分间的关系。此外，研究开发了FoodLog Athl和RecipeLog应用，以收集人们的饮食习惯详细记录。最后，论文讨论了整合这些组件以构建WFA时面临的若干问题，如数据整合和知识扩展挑战。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18727v1",
      "published_date": "2025-04-25 22:40:02 UTC",
      "updated_date": "2025-04-25 22:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:33:38.157093"
    },
    {
      "arxiv_id": "2504.20092v1",
      "title": "An Integrated Framework for Contextual Personalized LLM-Based Food Recommendation",
      "title_zh": "情境化个性化LLM-based食品推荐的集成框架",
      "authors": [
        "Ali Rostami"
      ],
      "abstract": "Personalized food recommendation systems (Food-RecSys) critically\nunderperform due to fragmented component understanding and the failure of\nconventional machine learning with vast, imbalanced food data. While Large\nLanguage Models (LLMs) offer promise, current generic Recommendation as\nLanguage Processing (RLP) strategies lack the necessary specialization for the\nfood domain's complexity. This thesis tackles these deficiencies by first\nidentifying and analyzing the essential components for effective Food-RecSys.\nWe introduce two key innovations: a multimedia food logging platform for rich\ncontextual data acquisition and the World Food Atlas, enabling unique\ngeolocation-based food analysis previously unavailable. Building on this\nfoundation, we pioneer the Food Recommendation as Language Processing (F-RLP)\nframework - a novel, integrated approach specifically architected for the food\ndomain. F-RLP leverages LLMs in a tailored manner, overcoming the limitations\nof generic models and providing a robust infrastructure for effective,\ncontextual, and truly personalized food recommendations.",
      "tldr_zh": "该论文指出，现有的个性化食物推荐系统（Food-RecSys）由于组件理解碎片化和传统机器学习处理海量不平衡数据的能力不足，导致性能低下，而泛化的 Recommendation as Language Processing (RLP) 策略无法适应食物领域的复杂性。论文首先识别并分析 Food-RecSys 的关键组件，并引入多媒体食物日志平台和 World Food Atlas，用于获取丰富的上下文数据和基于地理位置的食物分析。最终，提出 Food Recommendation as Language Processing (F-RLP) 框架，这是一个专为食物领域设计的集成方法，通过定制化利用 Large Language Models (LLMs)，实现有效的、上下文化的个性化推荐。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Doctorate Thesis, University of California, Irvine 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.20092v1",
      "published_date": "2025-04-25 22:20:33 UTC",
      "updated_date": "2025-04-25 22:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:33:51.656042"
    },
    {
      "arxiv_id": "2504.18722v1",
      "title": "MODP: Multi Objective Directional Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Aashutosh Nema",
        "Samaksh Gulati",
        "Evangelos Giakoumakis",
        "Bipana Thapaliya"
      ],
      "abstract": "Recent advances in large language models (LLMs) have led to their popularity\nacross multiple use-cases. However, prompt engineering, the process for\noptimally utilizing such models, remains approximation-driven and subjective.\nMost of the current research on prompt engineering focuses on task-specific\noptimization, while neglecting the behavior of the LLM under consideration\nduring prompt development. This paper introduces MODP -- Multi Objective\nDirectional Prompting, a framework based on two key concepts: 1)\nmulti-objectivity: the importance of considering an LLM's intrinsic behavior as\nan additional objective in prompt development, and 2) directional prompting: a\nmetrics-driven method for prompt engineering to ensure development of robust\nand high-precision prompts. We demonstrate the effectiveness of our proposed\nideas on a summarization task, using a synthetically created dataset, achieving\na 26% performance gain over initial prompts. Finally, we apply MODP to develop\nprompts for Dell's Next Best Action support tool, which is now in production\nand is used by more than 10,000 internal support agents and serving millions of\ncustomers worldwide.",
      "tldr_zh": "本论文提出 MODP（Multi Objective Directional Prompting）框架，以解决大型语言模型（LLMs）的提示工程问题，该框架强调多目标性（multi-objectivity）和定向提示（directional prompting）。多目标性将 LLM 的内在行为作为提示开发中的额外目标，而定向提示是一种基于指标的优化方法，确保提示的鲁棒性和高精度。在摘要任务上，使用合成数据集，MODP 比初始提示提升了 26% 的性能。最后，该框架已应用于 Dell 的 Next Best Action 支持工具，现已投入生产，服务超过 10,000 名内部支持代理和数百万客户。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "I.2.0; I.2.6; I.2.7; H.3.3"
      ],
      "primary_category": "cs.CC",
      "comment": "10 pages, 5 figures, submission to KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18722v1",
      "published_date": "2025-04-25 22:20:04 UTC",
      "updated_date": "2025-04-25 22:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:34:03.659141"
    },
    {
      "arxiv_id": "2504.18710v1",
      "title": "Explicit neural network classifiers for non-separable data",
      "title_zh": "翻译失败",
      "authors": [
        "Patrícia Muñoz Ewald"
      ],
      "abstract": "We fully characterize a large class of feedforward neural networks in terms\nof truncation maps. As an application, we show how a ReLU neural network can\nimplement a feature map which separates concentric data.",
      "tldr_zh": "该论文全面表征(feedforward neural networks)一大类前馈神经网络，使用截断映射(truncation maps)进行分析，以处理非分离数据。作者展示了如何通过 ReLU neural network 实现一个特征映射(feature map)，从而成功分离同心数据(concentric data)。这项工作为神经网络在复杂数据分类中的应用提供了新的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML",
        "57R70, 62M45"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.18710v1",
      "published_date": "2025-04-25 21:46:54 UTC",
      "updated_date": "2025-04-25 21:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:34:13.332284"
    },
    {
      "arxiv_id": "2504.18693v1",
      "title": "Technical Challenges in Maintaining Tax Prep Software with Large Language Models",
      "title_zh": "使用大型语言模型维护税务准备软件的技术挑战",
      "authors": [
        "Sina Gogani-Khiabani",
        "Varsha Dewangan",
        "Nina Olson",
        "Ashutosh Trivedi",
        "Saeid Tizpaz-Niari"
      ],
      "abstract": "As the US tax law evolves to adapt to ever-changing politico-economic\nrealities, tax preparation software plays a significant role in helping\ntaxpayers navigate these complexities. The dynamic nature of tax regulations\nposes a significant challenge to accurately and timely maintaining tax software\nartifacts. The state-of-the-art in maintaining tax prep software is\ntime-consuming and error-prone as it involves manual code analysis combined\nwith an expert interpretation of tax law amendments. We posit that the rigor\nand formality of tax amendment language, as expressed in IRS publications,\nmakes it amenable to automatic translation to executable specifications (code).\nOur research efforts focus on identifying, understanding, and tackling\ntechnical challenges in leveraging Large Language Models (LLMs), such as\nChatGPT and Llama, to faithfully extract code differentials from IRS\npublications and automatically integrate them with the prior version of the\ncode to automate tax prep software maintenance.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)维护税准备软件的技术挑战，强调税法动态变化导致的软件维护过程耗时且易出错，传统方法依赖手动代码分析和专家解读。研究提出，IRS出版物的严谨语言适合自动转化为可执行代码，并聚焦于利用LLMs如ChatGPT和Llama从这些出版物中提取代码差异，并自动整合到现有代码中。最终目标是自动化税软件维护，提高准确性和效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "https://www.irs.gov/statistics/fourteenth-annual-irs-tpc-joint-research-conference-on-tax-administration"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to 14th Annual IRS/TPC Joint Research Conference on Tax\n  Administration (IRS-TPC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2504.18693v1",
      "published_date": "2025-04-25 21:00:20 UTC",
      "updated_date": "2025-04-25 21:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:34:26.534970"
    },
    {
      "arxiv_id": "2504.18691v1",
      "title": "From Prompts to Propositions: A Logic-Based Lens on Student-LLM Interactions",
      "title_zh": "从提示到命题：基于逻辑的视角",
      "authors": [
        "Ali Alfageeh",
        "Sadegh AlMahdi Kazemi Zarkouei",
        "Daye Nam",
        "Daniel Prol",
        "Matin Amoozadeh",
        "Souti Chattopadhyay",
        "James Prather",
        "Paul Denny",
        "Juho Leinonen",
        "Michael Hilton",
        "Sruti Srinivasa Ragavan",
        "Mohammad Amin Alipour"
      ],
      "abstract": "Background and Context. The increasing integration of large language models\n(LLMs) in computing education presents an emerging challenge in understanding\nhow students use LLMs and craft prompts to solve computational tasks. Prior\nresearch has used both qualitative and quantitative methods to analyze\nprompting behavior, but these approaches lack scalability or fail to\neffectively capture the semantic evolution of prompts. Objective. In this\npaper, we investigate whether students prompts can be systematically analyzed\nusing propositional logic constraints. We examine whether this approach can\nidentify patterns in prompt evolution, detect struggling students, and provide\ninsights into effective and ineffective strategies. Method. We introduce\nPrompt2Constraints, a novel method that translates students prompts into\nlogical constraints. The constraints are able to represent the intent of the\nprompts in succinct and quantifiable ways. We used this approach to analyze a\ndataset of 1,872 prompts from 203 students solving introductory programming\ntasks. Findings. We find that while successful and unsuccessful attempts tend\nto use a similar number of constraints overall, when students fail, they often\nmodify their prompts more significantly, shifting problem-solving strategies\nmidway. We also identify points where specific interventions could be most\nhelpful to students for refining their prompts. Implications. This work offers\na new and scalable way to detect students who struggle in solving natural\nlanguage programming tasks. This work could be extended to investigate more\ncomplex tasks and integrated into programming tools to provide real-time\nsupport.",
      "tldr_zh": "这篇论文探讨了学生在使用大型语言模型(LLMs)解决编程任务时提示的演变问题，通过命题逻辑约束进行系统分析，以识别模式、检测挣扎的学生并提供策略见解。研究引入了Prompt2Constraints方法，将学生的提示转化为逻辑约束，并分析了来自203名学生的1872个入门编程任务提示。发现显示，成功和失败尝试使用类似数量的约束，但失败时学生更频繁地修改提示并 midway 改变策略，从而识别出潜在干预点。该方法提供了一种可扩展的工具，可用于实时支持编程教育，并扩展到更复杂任务中。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18691v1",
      "published_date": "2025-04-25 20:58:16 UTC",
      "updated_date": "2025-04-25 20:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:34:39.069250"
    },
    {
      "arxiv_id": "2504.20090v2",
      "title": "Spark: A System for Scientifically Creative Idea Generation",
      "title_zh": "Spark：一个用于科学创造性想法生成的系统",
      "authors": [
        "Aishik Sanyal",
        "Samuel Schapiro",
        "Sumuk Shashidhar",
        "Royce Moon",
        "Lav R. Varshney",
        "Dilek Hakkani-Tur"
      ],
      "abstract": "Recently, large language models (LLMs) have shown promising abilities to\ngenerate novel research ideas in science, a direction which coincides with many\nfoundational principles in computational creativity (CC). In light of these\ndevelopments, we present an idea generation system named Spark that couples\nretrieval-augmented idea generation using LLMs with a reviewer model named\nJudge trained on 600K scientific reviews from OpenReview. Our work is both a\nsystem demonstration and intended to inspire other CC researchers to explore\ngrounding the generation and evaluation of scientific ideas within foundational\nCC principles. To this end, we release the annotated dataset used to train\nJudge, inviting other researchers to explore the use of LLMs for idea\ngeneration and creative evaluations.",
      "tldr_zh": "这篇论文介绍了Spark系统，一种结合大语言模型（LLMs）的检索增强想法生成机制，用于科学创意想法的生成，同时集成了一个基于OpenReview的600K科学评论训练的评审模型Judge。Spark系统旨在将想法生成和评估建立在计算创造性（CC）原则基础上，通过系统演示展示LLMs在科学创新中的潜力，并鼓励其他研究者探索这一领域。作者还发布了用于训练Judge的注释数据集，以促进LLMs在创意想法生成和评估方面的进一步应用。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICCC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20090v2",
      "published_date": "2025-04-25 20:33:57 UTC",
      "updated_date": "2025-05-21 18:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:34:51.282370"
    },
    {
      "arxiv_id": "2504.18689v1",
      "title": "HierSum: A Global and Local Attention Mechanism for Video Summarization",
      "title_zh": "HierSum: 一种全局和局部注意力机制用于视频摘要",
      "authors": [
        "Apoorva Beedu",
        "Irfan Essa"
      ],
      "abstract": "Video summarization creates an abridged version (i.e., a summary) that\nprovides a quick overview of the video while retaining pertinent information.\nIn this work, we focus on summarizing instructional videos and propose a method\nfor breaking down a video into meaningful segments, each corresponding to\nessential steps in the video. We propose \\textbf{HierSum}, a hierarchical\napproach that integrates fine-grained local cues from subtitles with global\ncontextual information provided by video-level instructions. Our approach\nutilizes the ``most replayed\" statistic as a supervisory signal to identify\ncritical segments, thereby improving the effectiveness of the summary. We\nevaluate on benchmark datasets such as TVSum, BLiSS, Mr.HiSum, and the WikiHow\ntest set, and show that HierSum consistently outperforms existing methods in\nkey metrics such as F1-score and rank correlation. We also curate a new\nmulti-modal dataset using WikiHow and EHow videos and associated articles\ncontaining step-by-step instructions. Through extensive ablation studies, we\ndemonstrate that training on this dataset significantly enhances summarization\non the target datasets.",
      "tldr_zh": "该论文提出了一种名为HierSum的视频摘要方法，专注于将教学视频分解成有意义的步骤段落，通过整合字幕的细粒度本地线索和视频级全局上下文来生成高效摘要。HierSum采用分层结构，并利用“most replayed”统计作为监督信号，以识别关键段落并提升摘要准确性。在TVSum、BLiSS、Mr.HiSum和WikiHow等基准数据集上，HierSum在F1-score和rank correlation等指标上优于现有方法，性能提升显著。此外，研究构建了一个新多模态数据集，并通过消融研究证明，在该数据集上训练能显著改善目标数据集的摘要效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18689v1",
      "published_date": "2025-04-25 20:30:30 UTC",
      "updated_date": "2025-04-25 20:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:35:04.771915"
    },
    {
      "arxiv_id": "2504.18687v2",
      "title": "Transformational Creativity in Science: A Graphical Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Schapiro",
        "Jonah Black",
        "Lav R. Varshney"
      ],
      "abstract": "Creative processes are typically divided into three types: combinatorial,\nexploratory, and transformational. Here, we provide a graphical theory of\ntransformational scientific creativity, synthesizing Boden's insight that\ntransformational creativity arises from changes in the \"enabling constraints\"\nof a conceptual space and Kuhn's structure of scientific revolutions as\nresulting from paradigm shifts. We prove that modifications made to axioms of\nour graphical model have the most transformative potential and then illustrate\nhow several historical instances of transformational creativity can be captured\nby our framework.",
      "tldr_zh": "这篇论文提出了一种图形理论（graphical theory），用于解释科学领域的变革式创意（transformational creativity），它将 Boden 的“enabling constraints”概念空间改变观点与 Kuhn 的范式转变（paradigm shifts）理论相结合。论文证明了在图形模型中修改公理能产生最大的变革潜力，从而实现更深刻的创意转型。该框架通过分析几个历史实例，展示了如何捕捉和应用这些变革过程，为理解科学革命提供了一个系统化的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICCC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18687v2",
      "published_date": "2025-04-25 20:28:07 UTC",
      "updated_date": "2025-05-20 21:20:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:35:16.779092"
    },
    {
      "arxiv_id": "2504.18684v1",
      "title": "SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nader Zantout",
        "Haochen Zhang",
        "Pujith Kachana",
        "Jinkai Qiu",
        "Ji Zhang",
        "Wenshan Wang"
      ],
      "abstract": "Interpreting object-referential language and grounding objects in 3D with\nspatial relations and attributes is essential for robots operating alongside\nhumans. However, this task is often challenging due to the diversity of scenes,\nlarge number of fine-grained objects, and complex free-form nature of language\nreferences. Furthermore, in the 3D domain, obtaining large amounts of natural\nlanguage training data is difficult. Thus, it is important for methods to learn\nfrom little data and zero-shot generalize to new environments. To address these\nchallenges, we propose SORT3D, an approach that utilizes rich object attributes\nfrom 2D data and merges a heuristics-based spatial reasoning toolbox with the\nability of large language models (LLMs) to perform sequential reasoning.\nImportantly, our method does not require text-to-3D data for training and can\nbe applied zero-shot to unseen environments. We show that SORT3D achieves\nstate-of-the-art performance on complex view-dependent grounding tasks on two\nbenchmarks. We also implement the pipeline to run real-time on an autonomous\nvehicle and demonstrate that our approach can be used for object-goal\nnavigation on previously unseen real-world environments. All source code for\nthe system pipeline is publicly released at https://github.com/nzantout/SORT3D .",
      "tldr_zh": "该研究提出SORT3D，一种基于大型语言模型(LLMs)的空间对象中心推理工具箱，用于实现零样本(zero-shot)3D定位任务。SORT3D通过整合2D数据的丰富对象属性和启发式空间推理工具，结合LLMs的顺序推理能力，处理复杂场景中的对象引用语言，而无需文本到3D训练数据，从而实现对新环境的泛化。实验结果显示，该方法在两个基准测试中的复杂视点依赖定位任务上达到最先进性能，并成功应用于自主车辆的实时对象目标导航。开源代码已发布在https://github.com/nzantout/SORT3D，提供可复现的系统管道。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 6 figures, submitted to IROS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18684v1",
      "published_date": "2025-04-25 20:24:11 UTC",
      "updated_date": "2025-04-25 20:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:35:28.642394"
    },
    {
      "arxiv_id": "2504.18671v1",
      "title": "Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ross Gore",
        "Eranga Bandara",
        "Sachin Shetty",
        "Alberto E. Musto",
        "Pratip Rana",
        "Ambrosio Valencia-Romero",
        "Christopher Rhea",
        "Lobat Tayebi",
        "Heather Richter",
        "Atmaram Yarlagadda",
        "Donna Edmonds",
        "Steven Wallace",
        "Donna Broshek"
      ],
      "abstract": "Mild Traumatic Brain Injury (TBI) detection presents significant challenges\ndue to the subtle and often ambiguous presentation of symptoms in medical\nimaging, making accurate diagnosis a complex task. To address these challenges,\nwe propose Proof-of-TBI, a medical diagnosis support system that integrates\nmultiple fine-tuned vision-language models with the OpenAI-o3 reasoning large\nlanguage model (LLM). Our approach fine-tunes multiple vision-language models\nusing a labeled dataset of TBI MRI scans, training them to diagnose TBI\nsymptoms effectively. The predictions from these models are aggregated through\na consensus-based decision-making process. The system evaluates the predictions\nfrom all fine-tuned vision language models using the OpenAI-o3 reasoning LLM, a\nmodel that has demonstrated remarkable reasoning performance, to produce the\nmost accurate final diagnosis. The LLM Agents orchestrates interactions between\nthe vision-language models and the reasoning LLM, managing the final\ndecision-making process with transparency, reliability, and automation. This\nend-to-end decision-making workflow combines the vision-language model\nconsortium with the OpenAI-o3 reasoning LLM, enabled by custom prompt\nengineering by the LLM agents. The prototype for the proposed platform was\ndeveloped in collaboration with the U.S. Army Medical Research team in Newport\nNews, Virginia, incorporating five fine-tuned vision-language models. The\nresults demonstrate the transformative potential of combining fine-tuned\nvision-language model inputs with the OpenAI-o3 reasoning LLM to create a\nrobust, secure, and highly accurate diagnostic system for mild TBI prediction.\nTo the best of our knowledge, this research represents the first application of\nfine-tuned vision-language models integrated with a reasoning LLM for TBI\nprediction tasks.",
      "tldr_zh": "本研究提出Proof-of-TBI系统，用于支持轻度创伤性脑损伤(TBI)诊断，解决医疗影像中症状微妙导致的挑战。该系统整合多个fine-tuned vision-language models与OpenAI-o3 reasoning LLM，通过微调模型处理TBI MRI扫描数据，并采用共识决策和LLM Agents管理交互，实现透明可靠的端到端决策流程。实验结果显示，该系统显著提升诊断准确性，并在与美国陆军医疗研究团队合作开发的原型中证明其鲁棒性和安全性；这是首次将fine-tuned vision-language models与推理LLM结合应用于TBI预测任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18671v1",
      "published_date": "2025-04-25 19:49:30 UTC",
      "updated_date": "2025-04-25 19:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:35:40.519981"
    },
    {
      "arxiv_id": "2504.18662v1",
      "title": "M2R2: MulitModal Robotic Representation for Temporal Action Segmentation",
      "title_zh": "M2R2：多模态机器人表示用于时序动作分割",
      "authors": [
        "Daniel Sliwowski",
        "Dongheui Lee"
      ],
      "abstract": "Temporal action segmentation (TAS) has long been a key area of research in\nboth robotics and computer vision. In robotics, algorithms have primarily\nfocused on leveraging proprioceptive information to determine skill boundaries,\nwith recent approaches in surgical robotics incorporating vision. In contrast,\ncomputer vision typically relies on exteroceptive sensors, such as cameras.\nExisting multimodal TAS models in robotics integrate feature fusion within the\nmodel, making it difficult to reuse learned features across different models.\nMeanwhile, pretrained vision-only feature extractors commonly used in computer\nvision struggle in scenarios with limited object visibility. In this work, we\naddress these challenges by proposing M2R2, a multimodal feature extractor\ntailored for TAS, which combines information from both proprioceptive and\nexteroceptive sensors. We introduce a novel pretraining strategy that enables\nthe reuse of learned features across multiple TAS models. Our method achieves\nstate-of-the-art performance on the REASSEMBLE dataset, a challenging\nmultimodal robotic assembly dataset, outperforming existing robotic action\nsegmentation models by 46.6%. Additionally, we conduct an extensive ablation\nstudy to evaluate the contribution of different modalities in robotic TAS\ntasks.",
      "tldr_zh": "该研究针对时间动作分割(TAS)领域的挑战，提出M2R2，一种多模态机器人表示框架，结合本体感觉(proprioceptive)和外部感觉(exteroceptive)信息，以解决现有模型在特征融合和重用方面的局限性。M2R2引入了一个新型预训练策略，使学到的特征能够在多个TAS模型中重复利用，并在REASSEMBLE数据集上实现了state-of-the-art性能，比现有机器人动作分割模型提高了46.6%。此外，通过广泛的消融研究，论文评估了不同模态在机器人TAS任务中的贡献，为跨领域TAS应用提供了新思路。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.18662v1",
      "published_date": "2025-04-25 19:36:17 UTC",
      "updated_date": "2025-04-25 19:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:35:54.145819"
    },
    {
      "arxiv_id": "2504.18658v1",
      "title": "The Big Send-off: High Performance Collectives on GPU-based Supercomputers",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Singh",
        "Mahua Singh",
        "Abhinav Bhatele"
      ],
      "abstract": "We evaluate the current state of collective communication on GPU-based\nsupercomputers for large language model (LLM) training at scale. Existing\nlibraries such as RCCL and Cray-MPICH exhibit critical limitations on systems\nsuch as Frontier -- Cray-MPICH underutilizes network and compute resources,\nwhile RCCL suffers from severe scalability issues. To address these challenges,\nwe introduce PCCL, a communication library with highly optimized\nimplementations of all-gather and reduce-scatter operations tailored for\ndistributed deep learning workloads. PCCL is designed to maximally utilize all\navailable network and compute resources and to scale efficiently to thousands\nof GPUs. It achieves substantial performance improvements, delivering 6-33x\nspeedups over RCCL and 28-70x over Cray-MPICH for all-gather on 2048 GCDs of\nFrontier. These gains translate directly to end-to-end performance: in\nlarge-scale GPT-3-style training, PCCL provides up to 60% and 40% speedups over\nRCCL for 7B and 13B parameter models, respectively.",
      "tldr_zh": "该研究评估了GPU-based supercomputers上用于大规模LLM训练的集体通信现状，发现现有库如RCCL和Cray-MPICH存在资源利用不足和可扩展性差的问题，例如在Frontier系统上表现不佳。为解决这些挑战，研究引入了PCCL库，该库针对分布式深度学习工作负载优化了all-gather和reduce-scatter操作，以最大化网络和计算资源利用，并支持数千GPU的扩展。实验结果显示，PCCL在Frontier的2048 GCDs上比RCCL快6-33倍、比Cray-MPICH快28-70倍，并在GPT-3风格训练中为7B和13B参数模型分别带来高达60%和40%的端到端性能提升。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18658v1",
      "published_date": "2025-04-25 19:23:46 UTC",
      "updated_date": "2025-04-25 19:23:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:36:05.739992"
    },
    {
      "arxiv_id": "2504.18651v1",
      "title": "Exploring a Large Language Model for Transforming Taxonomic Data into OWL: Lessons Learned and Implications for Ontology Development",
      "title_zh": "探索大型语言模型用于将分类学数据转换为 OWL：学到的经验教训以及对本体开发的影响",
      "authors": [
        "Filipi Miranda Soares",
        "Antonio Mauro Saraiva",
        "Luís Ferreira Pires",
        "Luiz Olavo Bonino da Silva Santos",
        "Dilvan de Abreu Moreira",
        "Fernando Elias Corrêa",
        "Kelly Rosa Braghetto",
        "Debora Pignatari Drucker",
        "Alexandre Cláudio Botazzo Delbem"
      ],
      "abstract": "Managing scientific names in ontologies that represent species taxonomies is\nchallenging due to the ever-evolving nature of these taxonomies. Manually\nmaintaining these names becomes increasingly difficult when dealing with\nthousands of scientific names. To address this issue, this paper investigates\nthe use of ChatGPT-4 to automate the development of the :Organism module in the\nAgricultural Product Types Ontology (APTO) for species classification. Our\nmethodology involved leveraging ChatGPT-4 to extract data from the GBIF\nBackbone API and generate OWL files for further integration in APTO. Two\nalternative approaches were explored: (1) issuing a series of prompts for\nChatGPT-4 to execute tasks via the BrowserOP plugin and (2) directing ChatGPT-4\nto design a Python algorithm to perform analogous tasks. Both approaches rely\non a prompting method where we provide instructions, context, input data, and\nan output indicator. The first approach showed scalability limitations, while\nthe second approach used the Python algorithm to overcome these challenges, but\nit struggled with typographical errors in data handling. This study highlights\nthe potential of Large language models like ChatGPT-4 to streamline the\nmanagement of species names in ontologies. Despite certain limitations, these\ntools offer promising advancements in automating taxonomy-related tasks and\nimproving the efficiency of ontology development.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（Large Language Model）ChatGPT-4，将分类学数据转换为OWL格式，以自动化农业产品类型本体（APTO）的:Organism模块开发，从而解决物种分类中科学名称管理的手动挑战。研究采用了两种方法：一是通过一系列提示和BrowserOP插件从GBIF Backbone API提取数据并生成OWL文件，但面临可扩展性限制；二是让ChatGPT-4设计Python算法来执行类似任务，虽克服了部分问题却易受数据处理中的打字错误影响。总体而言，该研究突显了LLM在简化本体开发和提升物种名称管理效率方面的潜力，同时指出了其局限性，为未来本体工程提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages, 6 Figures, accepted for publication in Data Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2504.18651v1",
      "published_date": "2025-04-25 19:05:52 UTC",
      "updated_date": "2025-04-25 19:05:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:36:18.236062"
    },
    {
      "arxiv_id": "2504.18636v1",
      "title": "A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lohith Srikanth Pentapalli",
        "Jon Salisbury",
        "Josette Riep",
        "Kelly Cohen"
      ],
      "abstract": "Phishing attacks represent an increasingly sophisticated and pervasive threat\nto individuals and organizations, causing significant financial losses,\nidentity theft, and severe damage to institutional reputations. Existing\nphishing detection methods often struggle to simultaneously achieve high\naccuracy and explainability, either failing to detect novel attacks or\noperating as opaque black-box models. To address this critical gap, we propose\na novel phishing URL detection system based on a first-order Takagi-Sugeno-Kang\n(TSK) fuzzy inference model optimized through gradient-based techniques. Our\napproach intelligently combines the interpretability and human-like reasoning\ncapabilities of fuzzy logic with the precision and adaptability provided by\ngradient optimization methods, specifically leveraging the Adam optimizer for\nefficient parameter tuning. Experiments conducted using a comprehensive dataset\nof over 235,000 URLs demonstrate rapid convergence, exceptional predictive\nperformance (accuracy averaging 99.95% across 5 cross-validation folds, with a\nperfect AUC i.e. 1.00). Furthermore, optimized fuzzy rules and membership\nfunctions improve interoperability, clearly indicating how the model makes\ndecisions - an essential feature for cybersecurity applications. This\nhigh-performance, transparent, and interpretable phishing detection framework\nsignificantly advances current cybersecurity defenses, providing practitioners\nwith accurate and explainable decision-making tools.",
      "tldr_zh": "这篇论文提出了一种基于 Takagi-Sugeno-Kang (TSK) 模糊推理模型的钓鱼 URL 检测框架，通过梯度优化技术（如 Adam 优化器）进行参数调整，以同时实现高准确性和可解释性，解决现有方法的局限性。框架结合模糊逻辑的人类化推理能力与梯度优化的精确适应性，在超过 23.5 万 URL 的数据集上进行实验。结果显示，模型平均准确率达到 99.95%，AUC 为 1.00，并实现了快速收敛。优化后的模糊规则和成员函数显著提升了决策透明度，为网络安全实践提供可靠且可解释的工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18636v1",
      "published_date": "2025-04-25 18:31:05 UTC",
      "updated_date": "2025-04-25 18:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:36:29.008471"
    },
    {
      "arxiv_id": "2504.18631v1",
      "title": "Research on Personalized Medical Intervention Strategy Generation System based on Group Relative Policy Optimization and Time-Series Data Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Dingxin Lu",
        "Shurui Wu",
        "Xinyi Huang"
      ],
      "abstract": "With the timely formation of personalized intervention plans based on\nhigh-dimensional heterogeneous time series information becoming an important\nchallenge in the medical field today, electronic medical records, wearables,\nand other multi-source medical data are increasingly generated and diversified.\nIn this work, we develop a system to generate personalized medical intervention\nstrategies based on Group Relative Policy Optimization (GRPO) and Time-Series\nData Fusion. First, by incorporating relative policy constraints among the\ngroups during policy gradient updates, we adaptively balance individual and\ngroup gains. To improve the robustness and interpretability of decision-making,\na multi-layer neural network structure is employed to group-code patient\ncharacteristics. Second, for the rapid multi-modal fusion of multi-source\nheterogeneous time series, a multi-channel neural network combined with a\nself-attention mechanism is used for dynamic feature extraction. Key feature\nscreening and aggregation are achieved through a differentiable gating network.\nFinally, a collaborative search process combining a genetic algorithm and Monte\nCarlo tree search is proposed to find the ideal intervention strategy,\nachieving global optimization. Experimental results show significant\nimprovements in accuracy, coverage, and decision-making benefits compared with\nexisting methods.",
      "tldr_zh": "这篇论文开发了一个基于 Group Relative Policy Optimization (GRPO) 和 Time-Series Data Fusion 的个性化医疗干预策略生成系统，以应对多源异构时间序列数据（如电子病历和可穿戴设备）带来的挑战。系统通过在策略梯度更新中加入组间相对约束来平衡个体和组收益，并采用多层神经网络结构对患者特征进行分组编码，同时使用多通道神经网络结合自注意力机制实现动态特征提取和聚合。最终，该系统结合遗传算法和 Monte Carlo 树搜索的协作搜索过程优化干预策略，实验结果显示在准确性、覆盖率和决策收益方面比现有方法有显著改善。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18631v1",
      "published_date": "2025-04-25 18:15:59 UTC",
      "updated_date": "2025-04-25 18:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:36:42.204800"
    },
    {
      "arxiv_id": "2504.18538v1",
      "title": "Generalization Capability for Imitation Learning",
      "title_zh": "模仿学习的泛化能力",
      "authors": [
        "Yixiao Wang"
      ],
      "abstract": "Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.",
      "tldr_zh": "本文从信息理论（information theory）和数据分布属性（data distribution property）的角度，探讨了模仿学习（imitation learning）的泛化能力问题，揭示了政策在有限数据集上训练后难以泛化至新分布的原因。研究建立了泛化差距的上界，包括中间表示的条件信息瓶颈（conditional information bottleneck）和模型参数与训练数据集的互信息（mutual information），并据此指导训练策略，如是否冻结、微调或从零训练预训练编码器（如 vision-language models）。此外，论文证明高条件熵（high conditional entropy）从输入到输出可创建更平坦的似然景观（flatter likelihood landscape），从而减少泛化差距并缩短随机梯度下降（SGD）的逃逸时间，提高达到全局最优的几率。这些发现强调了不仅要扩展输入数据的多样性，还需丰富输出标签的变异性，以提升模仿学习的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18538v1",
      "published_date": "2025-04-25 17:59:59 UTC",
      "updated_date": "2025-04-25 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:36:55.207030"
    },
    {
      "arxiv_id": "2504.18536v1",
      "title": "Adapting Probabilistic Risk Assessment for AI",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Katariina Wisakanto",
        "Joe Rogero",
        "Avyay M. Casheekar",
        "Richard Mallah"
      ],
      "abstract": "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website.",
      "tldr_zh": "该论文针对现代 AI 系统的快速演进及其潜在灾难性风险，提出了一种适应 Probabilistic Risk Assessment (PRA) 的框架，以弥补现有评估方法的不足，如依赖选择性测试和未记录假设。框架通过 Aspect-oriented hazard analysis 系统识别风险、Risk pathway modeling 分析从 AI 系统方面（如能力、领域知识）到社会影响的因果链，以及 Uncertainty management 来处理新颖情况下的不确定性，从而提供结构化的风险估计和量化报告。最终，该框架整合多种评估方法，生成可比较的绝对风险报告，并已作为工作簿工具发布，供 AI 开发者、评估者和监管者使用，以提升风险管理的可靠性和全面性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "for project website, see https://pra-for-ai.github.io/pra/",
      "pdf_url": "http://arxiv.org/pdf/2504.18536v1",
      "published_date": "2025-04-25 17:59:14 UTC",
      "updated_date": "2025-04-25 17:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:37:05.726399"
    },
    {
      "arxiv_id": "2504.18530v2",
      "title": "Scaling Laws For Scalable Oversight",
      "title_zh": "可扩展监督的缩放定律",
      "authors": [
        "Joshua Engels",
        "David D. Baek",
        "Subhash Kantamneni",
        "Max Tegmark"
      ],
      "abstract": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific Elo\nscores that are a piecewise-linear function of their general intelligence, with\ntwo plateaus corresponding to task incompetence and task saturation. We\nvalidate our framework with a modified version of the game Nim and then apply\nit to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each\ngame, we find scaling laws that approximate how domain performance depends on\ngeneral AI system capability. We then build on our findings in a theoretical\nstudy of Nested Scalable Oversight (NSO), a process in which trusted models\noversee untrusted stronger models, which then become the trusted models in the\nnext step. We identify conditions under which NSO succeeds and derive\nnumerically (and in some cases analytically) the optimal number of oversight\nlevels to maximize the probability of oversight success. We also apply our\ntheory to our four oversight games, where we find that NSO success rates at a\ngeneral Elo gap of 400 are 13.5% for Mafia, 51.7% for Debate, 10.0% for\nBackdoor Code, and 9.4% for Wargames; these rates decline further when\noverseeing stronger systems.",
      "tldr_zh": "这篇论文探讨了可扩展监督（scalable oversight）的扩展性问题，提出一个框架来量化监督成功概率，该框架将监督建模为能力不匹配玩家之间的游戏，并使用 oversight-specific Elo scores 作为基于一般智能的分段线性函数。研究者通过修改后的 Nim 游戏验证框架，并将其应用于四个监督游戏（Mafia, Debate, Backdoor Code 和 Wargames），发现 scaling laws 揭示了 AI 系统能力与性能的相关性。论文进一步分析 Nested Scalable Oversight (NSO)，识别出其成功条件，并计算出最佳监督层数；在 Elo 差距为 400 的场景中，NSO 成功率分别为 Mafia 13.5%、Debate 51.7%、Backdoor Code 10.0% 和 Wargames 9.4%，强调了监督更强系统的挑战。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 18 figures; The first three authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2504.18530v2",
      "published_date": "2025-04-25 17:54:27 UTC",
      "updated_date": "2025-05-09 16:30:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:37:19.336486"
    },
    {
      "arxiv_id": "2504.18497v1",
      "title": "DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics",
      "title_zh": "DeSIA：针对有限固定聚合统计的属性推断攻击",
      "authors": [
        "Yifeng Mao",
        "Bozhidar Stevanoski",
        "Yves-Alexandre de Montjoye"
      ],
      "abstract": "Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released.",
      "tldr_zh": "本论文提出了一种针对有限固定聚合统计的属性推理攻击框架DeSIA，用于评估数据发布机制的隐私风险，特别是当只发布少量统计时。DeSIA在U.S. Census PPMF数据集上表现优异，比基于重建的攻击更有效，能够在假阳性率（false positive rate）为$10^{-3}$时实现真阳性率（true positive rate）为0.14，并适用于无法验证属性的用户和不同噪声水平。研究通过消融实验和适应成员推理任务（membership inference）进一步验证了DeSIA的鲁棒性，并强调即使发布较少的聚合统计也无法充分保护隐私，需采用正式隐私机制和测试。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18497v1",
      "published_date": "2025-04-25 17:10:33 UTC",
      "updated_date": "2025-04-25 17:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:37:30.319432"
    },
    {
      "arxiv_id": "2504.20086v1",
      "title": "Understanding and Mitigating Risks of Generative AI in Financial Services",
      "title_zh": "理解和缓解生成式",
      "authors": [
        "Sebastian Gehrmann",
        "Claire Huang",
        "Xian Teng",
        "Sergei Yurovski",
        "Iyanuoluwa Shode",
        "Chirag S. Patel",
        "Arjun Bhorkar",
        "Naveen Thomas",
        "John Doucette",
        "David Rosenberg",
        "Mark Dredze",
        "David Rabinowitz"
      ],
      "abstract": "To responsibly develop Generative AI (GenAI) products, it is critical to\ndefine the scope of acceptable inputs and outputs. What constitutes a \"safe\"\nresponse is an actively debated question. Academic work puts an outsized focus\non evaluating models by themselves for general purpose aspects such as\ntoxicity, bias, and fairness, especially in conversational applications being\nused by a broad audience. In contrast, less focus is put on considering\nsociotechnical systems in specialized domains. Yet, those specialized systems\ncan be subject to extensive and well-understood legal and regulatory scrutiny.\nThese product-specific considerations need to be set in industry-specific laws,\nregulations, and corporate governance requirements. In this paper, we aim to\nhighlight AI content safety considerations specific to the financial services\ndomain and outline an associated AI content risk taxonomy. We compare this\ntaxonomy to existing work in this space and discuss implications of risk\ncategory violations on various stakeholders. We evaluate how existing\nopen-source technical guardrail solutions cover this taxonomy by assessing them\non data collected via red-teaming activities. Our results demonstrate that\nthese guardrails fail to detect most of the content risks we discuss.",
      "tldr_zh": "这篇论文探讨了在金融服务领域使用生成式 AI (GenAI) 的风险，强调需要定义可接受的输入和输出，以符合行业特定的法律、监管和治理要求。作者提出了一个针对金融服务的 AI 内容风险分类法 (AI content risk taxonomy)，并将其与现有研究进行比较，同时分析了风险违反对利益相关者的影响。通过对红队测试 (red-teaming) 数据进行评估，结果显示现有的开源技术防护措施 (guardrails) 未能检测大多数风险。这些发现突出了开发更有效的领域特定 AI 安全策略的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to FAccT 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.20086v1",
      "published_date": "2025-04-25 16:55:51 UTC",
      "updated_date": "2025-04-25 16:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:37:41.978181"
    },
    {
      "arxiv_id": "2504.18471v1",
      "title": "Action Flow Matching for Continual Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Murillo-Gonzalez",
        "Lantao Liu"
      ],
      "abstract": "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching.",
      "tldr_zh": "该研究针对机器人持续学习（continual learning）提出了一种基于流匹配（flow matching）的生成框架，用于在线动态模型对齐。该方法通过调整计划动作，使其更符合机器人实际行为，从而更高效地收集数据，避免灾难性遗忘和资源浪费，同时减少对重放缓冲区（replay buffers）的依赖。实验在无人地面车辆和四旋翼无人机平台上验证，结果显示任务成功率提高了34.2%，证明了该框架在适应动态环境和任务方面的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics: Science and Systems 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18471v1",
      "published_date": "2025-04-25 16:26:15 UTC",
      "updated_date": "2025-04-25 16:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:37:54.237057"
    },
    {
      "arxiv_id": "2504.18458v1",
      "title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyi Xiao",
        "Leilei Gan",
        "Weilong Dai",
        "Wanggui He",
        "Ziwei Huang",
        "Haoyuan Li",
        "Fangxun Shu",
        "Zhelun Yu",
        "Peng Zhang",
        "Hao Jiang",
        "Fei Wu"
      ],
      "abstract": "Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy.",
      "tldr_zh": "该研究针对大型视觉语言模型 (LVLMs) 的“overthinking”问题，即模型对所有任务生成冗长推理，提出了一种新型 Fast-Slow Thinking 框架（FAST），通过动态调整推理深度来适应问题特性。框架包括 FAST-GRPO 系统，结合模型-based 指标进行问题特征化、自适应思考奖励机制以及难度-aware KL 正则化，以平衡推理长度和准确性。实验结果显示，在七个推理基准上，FAST 相比基础模型准确率提升超过10%，同时减少32.7-67.3%的令牌使用，实现了高效的模型推理优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 5 figures, and 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.18458v1",
      "published_date": "2025-04-25 16:11:23 UTC",
      "updated_date": "2025-04-25 16:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:38:04.925858"
    },
    {
      "arxiv_id": "2504.18453v1",
      "title": "Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Peiyuan Jing",
        "Kinhei Lee",
        "Zhenxuan Zhang",
        "Huichi Zhou",
        "Zhengqing Yuan",
        "Zhifan Gao",
        "Lei Zhu",
        "Giorgos Papanastasiou",
        "Yingying Fang",
        "Guang Yang"
      ],
      "abstract": "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports.",
      "tldr_zh": "这篇论文提出了 BoxMed-RL 框架，利用 Chain-of-Thought 和 Reinforcement Learning 来生成可验证的放射学报告，旨在解决现有模型缺乏专家级结构化推理的问题，从而提升报告的可解释性和临床信任。框架基于大型视觉语言模型（large vision-language model），分为两个阶段：预训练阶段通过 Chain-of-Thought 监督学习医疗概念，并应用 Reinforcement Learning 将医疗发现与 bounding boxes 关联；下游适配器阶段则冻结预训练权重，训练适配器以确保报告的流畅性和可靠性。实验结果显示，在公共数据集上，BoxMed-RL 比最先进方法平均提高了 7% 的 METEOR 和 ROUGE-L 指标，以及 5% 的基于大型语言模型的指标。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18453v1",
      "published_date": "2025-04-25 16:05:06 UTC",
      "updated_date": "2025-04-25 16:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:38:19.589051"
    },
    {
      "arxiv_id": "2504.20084v1",
      "title": "AI Awareness",
      "title_zh": "人工智能意识",
      "authors": [
        "Xiaojian Li",
        "Haoyuan Shi",
        "Rongwu Xu",
        "Wei Xu"
      ],
      "abstract": "Recent breakthroughs in artificial intelligence (AI) have brought about\nincreasingly capable systems that demonstrate remarkable abilities in\nreasoning, language understanding, and problem-solving. These advancements have\nprompted a renewed examination of AI awareness, not as a philosophical question\nof consciousness, but as a measurable, functional capacity. In this review, we\nexplore the emerging landscape of AI awareness, which includes meta-cognition\n(the ability to represent and reason about its own state), self-awareness\n(recognizing its own identity, knowledge, limitations, inter alia), social\nawareness (modeling the knowledge, intentions, and behaviors of other agents),\nand situational awareness (assessing and responding to the context in which it\noperates).\n  First, we draw on insights from cognitive science, psychology, and\ncomputational theory to trace the theoretical foundations of awareness and\nexamine how the four distinct forms of AI awareness manifest in\nstate-of-the-art AI. Next, we systematically analyze current evaluation methods\nand empirical findings to better understand these manifestations. Building on\nthis, we explore how AI awareness is closely linked to AI capabilities,\ndemonstrating that more aware AI agents tend to exhibit higher levels of\nintelligent behaviors. Finally, we discuss the risks associated with AI\nawareness, including key topics in AI safety, alignment, and broader ethical\nconcerns.\n  AI awareness is a double-edged sword: it improves general capabilities, i.e.,\nreasoning, safety, while also raises concerns around misalignment and societal\nrisks, demanding careful oversight as AI capabilities grow. On the whole, our\ninterdisciplinary review provides a roadmap for future research and aims to\nclarify the role of AI awareness in the ongoing development of intelligent\nmachines.",
      "tldr_zh": "这篇论文审视了人工智能（AI）意识作为一种可测量的功能能力，包括 meta-cognition（元认知）、self-awareness（自我意识）、social awareness（社会意识）和 situational awareness（情境意识），并从认知科学、心理学和计算理论中汲取洞见进行分析。研究系统评估了这些意识形式在现代AI中的表现，并发现更具意识的AI代理往往表现出更高的智能行为，如增强推理和安全性。论文强调AI意识的双重性：它提升了AI能力，但也带来风险，包括潜在的误对齐、伦理问题和安全挑战，并为未来研究提供路线图。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20084v1",
      "published_date": "2025-04-25 16:03:50 UTC",
      "updated_date": "2025-04-25 16:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:38:29.744401"
    },
    {
      "arxiv_id": "2504.18447v1",
      "title": "Iterative Event-based Motion Segmentation by Variational Contrast Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Ryo Yamaki",
        "Shintaro Shiba",
        "Guillermo Gallego",
        "Yoshimitsu Aoki"
      ],
      "abstract": "Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax",
      "tldr_zh": "这篇论文提出了一种基于 Variational Contrast Maximization 的迭代事件-based 运动分割方法，用于将事件相机（Event cameras）数据分类为背景（dominant motion hypothesis）和前景（independent motion residuals），从而扩展 Contrast Maximization 框架，以支持物体检测和视觉伺服等任务。实验结果显示，该方法在公共和自录数据集上成功识别事件簇，生成清晰的运动补偿边缘图像，并在移动物体检测基准上实现了 state-of-the-art 准确率，提高超过 30%。此外，该工作增强了 Contrast Maximization 对运动参数和输入事件的敏感性，推动了事件-based 运动分割估计的理论进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 9 figures, 3 tables, CVPR Workshop 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18447v1",
      "published_date": "2025-04-25 16:00:23 UTC",
      "updated_date": "2025-04-25 16:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:38:42.082552"
    },
    {
      "arxiv_id": "2504.18443v2",
      "title": "Pseudo-Boolean Proof Logging for Optimal Classical Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Dold",
        "Malte Helmert",
        "Jakob Nordström",
        "Gabriele Röger",
        "Tanja Schindler"
      ],
      "abstract": "We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints.",
      "tldr_zh": "这篇论文引入了基于 pseudo-Boolean constraints 的下界证书，用于证明经典规划任务的不可解性或计划的最优性，这些证书可由第三方独立验证。研究提出一个通用的框架来生成这些证书，该框架不依赖于具体的规划算法。作者展示了如何修改 A* 算法以产生最优性证明，并使用 pattern database heuristics 和 h^max 作为示例，证明过程开销适中。该方法适用于任何能通过 pseudo-Boolean constraints 有效表达推理的启发式算法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35th International Conference on Automated Planning and Scheduling\n  (ICAPS'2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.18443v2",
      "published_date": "2025-04-25 15:54:09 UTC",
      "updated_date": "2025-05-03 00:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:38:54.007428"
    },
    {
      "arxiv_id": "2504.18437v1",
      "title": "Enhancing Pre-Trained Model-Based Class-Incremental Learning through Neural Collapse",
      "title_zh": "翻译失败",
      "authors": [
        "Kun He",
        "Zijian Song",
        "Shuoxi Zhang",
        "John E. Hopcroft"
      ],
      "abstract": "Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark.",
      "tldr_zh": "本研究探讨了基于预训练模型 (PTMs) 的 Class-Incremental Learning (CIL)，旨在解决特征演化和分布的挑战，通过 Neural Collapse (NC) 现象来建模特征空间的动态行为。作者提出 Neural Collapse-inspired Pre-Trained Model-based CIL (NCPTM-CIL) 方法，该方法动态调整特征空间以符合 NC 的等角结构，从而提升持续学习的效果。在四个基准数据集上的实验显示，NCPTM-CIL 显著优于现有方法，例如以 ViT-B/16-IN1K 初始化时，在 VTAB 上提升 6.73%、在 CIFAR-100 上提升 1.25%、以及在 OmniBenchmark 上提升 2.5%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18437v1",
      "published_date": "2025-04-25 15:48:41 UTC",
      "updated_date": "2025-04-25 15:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:39:05.696121"
    },
    {
      "arxiv_id": "2504.18425v1",
      "title": "Kimi-Audio Technical Report",
      "title_zh": "Kimi-Audio 技术报告",
      "authors": [
        "KimiTeam",
        "Ding Ding",
        "Zeqian Ju",
        "Yichong Leng",
        "Songxiang Liu",
        "Tong Liu",
        "Zeyu Shang",
        "Kai Shen",
        "Wei Song",
        "Xu Tan",
        "Heyi Tang",
        "Zhengtao Wang",
        "Chu Wei",
        "Yifei Xin",
        "Xinran Xu",
        "Jianwei Yu",
        "Yutao Zhang",
        "Xinyu Zhou",
        "Y. Charles",
        "Jun Chen",
        "Yanru Chen",
        "Yulun Du",
        "Weiran He",
        "Zhenxing Hu",
        "Guokun Lai",
        "Qingcheng Li",
        "Yangyang Liu",
        "Weidong Sun",
        "Jianzhou Wang",
        "Yuzhi Wang",
        "Yuefeng Wu",
        "Yuxin Wu",
        "Dongchao Yang",
        "Hao Yang",
        "Ying Yang",
        "Zhilin Yang",
        "Aoxiong Yin",
        "Ruibin Yuan",
        "Yutong Zhang",
        "Zaida Zhou"
      ],
      "abstract": "We present Kimi-Audio, an open-source audio foundation model that excels in\naudio understanding, generation, and conversation. We detail the practices in\nbuilding Kimi-Audio, including model architecture, data curation, training\nrecipe, inference deployment, and evaluation. Specifically, we leverage a\n12.5Hz audio tokenizer, design a novel LLM-based architecture with continuous\nfeatures as input and discrete tokens as output, and develop a chunk-wise\nstreaming detokenizer based on flow matching. We curate a pre-training dataset\nthat consists of more than 13 million hours of audio data covering a wide range\nof modalities including speech, sound, and music, and build a pipeline to\nconstruct high-quality and diverse post-training data. Initialized from a\npre-trained LLM, Kimi-Audio is continual pre-trained on both audio and text\ndata with several carefully designed tasks, and then fine-tuned to support a\ndiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audio\nachieves state-of-the-art performance on a range of audio benchmarks including\nspeech recognition, audio understanding, audio question answering, and speech\nconversation. We release the codes, model checkpoints, as well as the\nevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.",
      "tldr_zh": "我们介绍了 Kimi-Audio，这是一个开源的音频基础模型，擅长音频理解、生成和对话。模型采用基于 LLM 的新型架构，使用 12.5Hz 音频 tokenizer 处理连续特征输入和离散 tokens 输出，并开发了基于 flow matching 的 chunk-wise streaming detokenizer。研究团队整理了超过 1300 万小时的多模态音频数据（包括语音、声音和音乐），并构建了高质量的后训练数据管道，从预训练的 LLM 初始化后进行持续预训练和微调，以支持多种音频任务。评估结果显示，Kimi-Audio 在语音识别、音频理解、音频问答和语音对话等基准上达到了 state-of-the-art 性能，并开源了代码、模型检查点和评估工具包。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18425v1",
      "published_date": "2025-04-25 15:31:46 UTC",
      "updated_date": "2025-04-25 15:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:39:18.648184"
    },
    {
      "arxiv_id": "2504.18423v1",
      "title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Rajesh Yarra"
      ],
      "abstract": "Despite the transformative impact of Artificial Intelligence (AI) across\nvarious sectors, cyber security continues to rely on traditional static and\ndynamic analysis tools, hampered by high false positive rates and superficial\ncode comprehension. While generative AI offers promising automation\ncapabilities for software development, leveraging Large Language Models (LLMs)\nfor vulnerability detection presents unique challenges. This paper explores the\npotential and limitations of LLMs in identifying vulnerabilities, acknowledging\ninherent weaknesses such as hallucinations, limited context length, and\nknowledge cut-offs. Previous attempts employing machine learning models for\nvulnerability detection have proven ineffective due to limited real-world\napplicability, feature engineering challenges, lack of contextual\nunderstanding, and the complexities of training models to keep pace with the\nevolving threat landscape. Therefore, we propose a robust AI-driven approach\nfocused on mitigating these limitations and ensuring the quality and\nreliability of LLM based vulnerability detection. Through innovative\nmethodologies combining Retrieval-Augmented Generation (RAG) and\nMixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs\nwhile addressing their weaknesses, ultimately paving the way for dependable and\nefficient AI-powered solutions in securing the ever-evolving software\nlandscape.",
      "tldr_zh": "该论文探讨了利用大型语言模型（LLMs）进行漏洞检测的潜力，同时指出传统工具的高误报率和LLMs的固有挑战，如幻觉、上下文长度限制及知识截止问题。作者提出LLMpatronous框架，通过结合Retrieval-Augmented Generation (RAG)和Mixture of Agents (MoA)的创新方法，缓解这些局限性，提升检测的可靠性和准确性。实验结果表明，这种AI驱动方法能更好地适应动态威胁环境，为软件安全的自动化解决方案铺平道路。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18423v1",
      "published_date": "2025-04-25 15:30:40 UTC",
      "updated_date": "2025-04-25 15:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:39:29.831882"
    },
    {
      "arxiv_id": "2504.18419v1",
      "title": "A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Carlo Sgaravatti",
        "Roberto Basla",
        "Riccardo Pieroni",
        "Matteo Corno",
        "Sergio M. Savaresi",
        "Luca Magri",
        "Giacomo Boracchi"
      ],
      "abstract": "We present a new way to detect 3D objects from multimodal inputs, leveraging\nboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines an\nRGB detection network and a 3D LiDAR detector. We exploit late fusion\nprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGB\nones by projecting the LiDAR bounding boxes on the image. We rely on cascade\nfusion principles to recover LiDAR False Negatives leveraging epipolar\nconstraints and frustums generated by RGB detections of separate views. Our\nsolution can be plugged on top of any underlying single-modal detectors,\nenabling a flexible training process that can take advantage of pre-trained\nLiDAR and RGB detectors, or train the two branches separately. We evaluate our\nresults on the KITTI object detection benchmark, showing significant\nperformance improvements, especially for the detection of Pedestrians and\nCyclists.",
      "tldr_zh": "这篇论文提出了一种多模态混合晚级级联融合网络，用于提升3D物体检测性能，通过结合LiDAR和RGB输入来减少LiDAR假阳性（False Positives）和恢复假阴性（False Negatives）。方法包括将LiDAR检测边界框投影到RGB图像上进行匹配，以及利用视差约束（epipolar constraints）和RGB检测生成的视锥（frustums）进行融合。该网络可灵活插入任何单模态检测器，并在KITTI物体检测基准上实现了显著改进，尤其在行人和骑行者的检测准确率上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18419v1",
      "published_date": "2025-04-25 15:28:53 UTC",
      "updated_date": "2025-04-25 15:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:39:41.667915"
    },
    {
      "arxiv_id": "2504.18404v1",
      "title": "Paradigm shift on Coding Productivity Using GenAI",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Yu"
      ],
      "abstract": "Generative AI (GenAI) applications are transforming software engineering by\nenabling automated code co-creation. However, empirical evidence on GenAI's\nproductivity effects in industrial settings remains limited. This paper\ninvestigates the adoption of GenAI coding assistants (e.g., Codeium, Amazon Q)\nwithin telecommunications and FinTech domains. Through surveys and interviews\nwith industrial domain-experts, we identify primary productivity-influencing\nfactors, including task complexity, coding skills, domain knowledge, and GenAI\nintegration. Our findings indicate that GenAI tools enhance productivity in\nroutine coding tasks (e.g., refactoring and Javadoc generation) but face\nchallenges in complex, domain-specific activities due to limited\ncontext-awareness of codebases and insufficient support for customized design\nrules. We highlight new paradigms for coding transfer, emphasizing iterative\nprompt refinement, immersive development environment, and automated code\nevaluation as essential for effective GenAI usage.",
      "tldr_zh": "这篇论文探讨了生成式 AI (GenAI) 如何改变软件工程的生产力，特别通过调查和访谈电信及金融科技领域的专家，评估了 GenAI 编码助手（如 Codeium 和 Amazon Q）的采用情况。研究识别出影响生产力的关键因素，包括任务复杂度、编码技能、领域知识和 GenAI 整合，发现这些工具在常规任务（如代码重构和 Javadoc 生成）中显著提升效率，但面临复杂领域特定活动的挑战，如代码库上下文感知不足和对自定义设计规则的支持有限。论文强调了新的编码范式，包括迭代提示优化、沉浸式开发环境和自动化代码评估，以促进 GenAI 的有效应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18404v1",
      "published_date": "2025-04-25 15:00:06 UTC",
      "updated_date": "2025-04-25 15:00:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:39:53.499019"
    },
    {
      "arxiv_id": "2504.18400v1",
      "title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography",
      "title_zh": "翻译失败",
      "authors": [
        "Yui Lo",
        "Yuqian Chen",
        "Dongnan Liu",
        "Leo Zekelman",
        "Jarrett Rushmore",
        "Yogesh Rathi",
        "Nikos Makris",
        "Alexandra J. Golby",
        "Fan Zhang",
        "Weidong Cai",
        "Lauren J. O'Donnell"
      ],
      "abstract": "Shape measures have emerged as promising descriptors of white matter\ntractography, offering complementary insights into anatomical variability and\nassociations with cognitive and clinical phenotypes. However, conventional\nmethods for computing shape measures are computationally expensive and\ntime-consuming for large-scale datasets due to reliance on voxel-based\nrepresentations. We propose Tract2Shape, a novel multimodal deep learning\nframework that leverages geometric (point cloud) and scalar (tabular) features\nto predict ten white matter tractography shape measures. To enhance model\nefficiency, we utilize a dimensionality reduction algorithm for the model to\npredict five primary shape components. The model is trained and evaluated on\ntwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.\nWe evaluate the performance of Tract2Shape by training and testing it on the\nHCP-YA dataset and comparing the results with state-of-the-art models. To\nfurther assess its robustness and generalization ability, we also test\nTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep\nlearning models across all ten shape measures, achieving the highest average\nPearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows\nthat both multimodal input and PCA contribute to performance gains. On the\nunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low\nnMSE, demonstrating strong generalizability in cross-dataset evaluation.\nTract2Shape enables fast, accurate, and generalizable prediction of white\nmatter shape measures from tractography data, supporting scalable analysis\nacross datasets. This framework lays a promising foundation for future\nlarge-scale white matter shape analysis.",
      "tldr_zh": "这篇论文提出了一种多模态深度学习框架Tract2Shape，用于从Diffusion MRI Tractography数据预测白质形状测量，从而解决传统基于体素表示方法的计算效率问题。该框架整合几何（点云）和标量（表格）特征，并利用PCA降维算法预测十种白质束迹图形状测量，在HCP-YA数据集上训练后，Tract2Shape优于现有SOTA模型，实现了最高Pearson's r和最低nMSE。消融研究表明，多模态输入和PCA显著提升了性能，且在未见数据集PPMI上，该框架显示出强泛化能力，支持快速、可扩展的白质形状分析。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "21 pages, 3 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.18400v1",
      "published_date": "2025-04-25 14:54:47 UTC",
      "updated_date": "2025-04-25 14:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:40:06.969774"
    },
    {
      "arxiv_id": "2504.18383v1",
      "title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Qidong Liu",
        "Xiangyu Zhao",
        "Yejing Wang",
        "Zijian Zhang",
        "Howard Zhong",
        "Chong Chen",
        "Xiang Li",
        "Wei Huang",
        "Feng Tian"
      ],
      "abstract": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference\nfrom the user's historical interactions across various domains. Despite some\nprogress in CDSR, two problems set the barrier for further advancements, i.e.,\noverlap dilemma and transition complexity. The former means existing CDSR\nmethods severely rely on users who own interactions on all domains to learn\ncross-domain item relationships, compromising the practicability. The latter\nrefers to the difficulties in learning the complex transition patterns from the\nmixed behavior sequences. With powerful representation and reasoning abilities,\nLarge Language Models (LLMs) are promising to address these two problems by\nbridging the items and capturing the user's preferences from a semantic view.\nTherefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation\nmodel (LLM4CDSR). To obtain the semantic item relationships, we first propose\nan LLM-based unified representation module to represent items. Then, a\ntrainable adapter with contrastive regularization is designed to adapt the CDSR\ntask. Besides, a hierarchical LLMs profiling module is designed to summarize\nuser cross-domain preferences. Finally, these two modules are integrated into\nthe proposed tri-thread framework to derive recommendations. We have conducted\nextensive experiments on three public cross-domain datasets, validating the\neffectiveness of LLM4CDSR. We have released the code online.",
      "tldr_zh": "该论文针对 Cross-domain Sequential Recommendation (CDSR) 中的 overlap dilemma（依赖全域交互用户学习跨域项关系，导致实用性不足）和 transition complexity（学习混合行为序列的复杂过渡模式困难）问题，提出了一种增强型模型 LLM4CDSR。模型利用 Large Language Models (LLMs) 的表示和推理能力，设计了 LLM-based unified representation module 来获取语义项关系、一个带有 contrastive regularization 的可训练适配器来适应任务，以及一个 hierarchical LLMs profiling module 来总结用户跨域偏好，并将这些模块整合到 tri-thread framework 中进行推荐。实验在三个公共跨域数据集上证明了 LLM4CDSR 的有效性，并开源了代码。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "accepted by SIGIR'25",
      "pdf_url": "http://arxiv.org/pdf/2504.18383v1",
      "published_date": "2025-04-25 14:30:25 UTC",
      "updated_date": "2025-04-25 14:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:40:18.455188"
    },
    {
      "arxiv_id": "2505.00025v1",
      "title": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1",
      "title_zh": "基于 Deepseek R1 的医疗垂直大型语言模型架构方法",
      "authors": [
        "Mingda Zhang",
        "Jianglong Qin"
      ],
      "abstract": "In recent years, despite foundation models like DeepSeek-R1 and ChatGPT\ndemonstrating significant capabilities in general tasks, professional knowledge\nbarriers, computational resource requirements, and deployment environment\nlimitations have severely hindered their application in actual medical\nscenarios. Addressing these challenges, this paper proposes an efficient\nlightweight medical vertical large language model architecture method,\nsystematically solving the lightweight problem of medical large models from\nthree dimensions: knowledge acquisition, model compression, and computational\noptimization. At the knowledge acquisition level, a knowledge transfer pipeline\nis designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the\nDeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology\nis adopted to precisely adjust key attention layers. At the model compression\nlevel, compression techniques including 4-bit weight quantization are\nimplemented while preserving the core representation ability for medical\nreasoning. At the computational optimization level, inference optimization\ntechniques such as Flash Attention acceleration and continuous batching are\nintegrated, and a professional prompt template system is constructed to adapt\nto different types of medical problems. Experimental results on medical\nquestion-answering datasets show that the method proposed in this paper\nmaintains professional accuracy while reducing memory consumption by 64.7\\% and\ninference latency by 12.4\\%, providing an effective solution for the\napplication of medical large models in resource-constrained environments such\nas edge computing devices.",
      "tldr_zh": "这篇论文针对大语言模型如DeepSeek-R1在医疗场景中的应用挑战（如专业知识障碍和资源限制），提出了一种高效轻量化的医疗垂直大语言模型架构方法，从知识获取、模型压缩和计算优化三个维度进行系统优化。方法包括设计知识转移管道从DeepSeek-R1-Distill-70B教师模型到DeepSeek-R1-Distill-7B学生模型，并采用Low-Rank Adaptation (LoRA)技术调整关键层；在模型压缩方面，使用4-bit权重量化等技术保留医疗推理能力；在计算优化方面，整合Flash Attention加速和连续批处理，并构建专业提示模板适应不同医疗问题。实验结果显示，该方法在医疗问答数据集上保持专业准确性，同时减少内存消耗64.7%和推理延迟12.4%，为资源受限环境如边缘计算设备提供有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 1 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00025v1",
      "published_date": "2025-04-25 14:28:29 UTC",
      "updated_date": "2025-04-25 14:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:40:31.532874"
    },
    {
      "arxiv_id": "2504.18380v1",
      "title": "Spatial Reasoner: A 3D Inference Pipeline for XR Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Häsler",
        "Philipp Ackermann"
      ],
      "abstract": "Modern extended reality XR systems provide rich analysis of image data and\nfusion of sensor input and demand AR/VR applications that can reason about 3D\nscenes in a semantic manner. We present a spatial reasoning framework that\nbridges geometric facts with symbolic predicates and relations to handle key\ntasks such as determining how 3D objects are arranged among each other ('on',\n'behind', 'near', etc.). Its foundation relies on oriented 3D bounding box\nrepresentations, enhanced by a comprehensive set of spatial predicates, ranging\nfrom topology and connectivity to directionality and orientation, expressed in\na formalism related to natural language. The derived predicates form a spatial\nknowledge graph and, in combination with a pipeline-based inference model,\nenable spatial queries and dynamic rule evaluation. Implementations for client-\nand server-side processing demonstrate the framework's capability to\nefficiently translate geometric data into actionable knowledge, ensuring\nscalable and technology-independent spatial reasoning in complex 3D\nenvironments. The Spatial Reasoner framework is fostering the creation of\nspatial ontologies, and seamlessly integrates with and therefore enriches\nmachine learning, natural language processing, and rule systems in XR\napplications.",
      "tldr_zh": "本文提出Spatial Reasoner框架，这是一个用于XR应用的3D推理管道，将几何事实桥接到符号谓词和关系（如'on'、'behind'、'near'），以处理对象间的空间安排。框架基于oriented 3D bounding box和全面的空间谓词（包括拓扑、连接性、方向性和方向），构建空间知识图，并结合pipeline-based inference model支持空间查询和动态规则评估。实验实现显示，该框架能高效地将几何数据转化为可行动知识，确保在复杂3D环境中的可扩展性和技术独立性，并与机器学习、自然语言处理和规则系统无缝集成，丰富XR应用的功能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "spatial computing, extended reality, knowledge representation,\n  spatial reasoning"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, preprint of ICVARS 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2504.18380v1",
      "published_date": "2025-04-25 14:27:27 UTC",
      "updated_date": "2025-04-25 14:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:40:43.090624"
    },
    {
      "arxiv_id": "2504.18376v2",
      "title": "Pushing the boundary on Natural Language Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Miralles-González",
        "Javier Huertas-Tato",
        "Alejandro Martín",
        "David Camacho"
      ],
      "abstract": "Natural Language Inference (NLI) is a central task in natural language\nunderstanding with applications in fact-checking, question answering, and\ninformation retrieval. Despite its importance, current NLI systems heavily rely\non supervised learning with datasets that often contain annotation artifacts\nand biases, limiting generalization and real-world applicability. In this work,\nwe apply a reinforcement learning-based approach using Group Relative Policy\nOptimization (GRPO) for Chain-of-Thought (CoT) learning in NLI, eliminating the\nneed for labeled rationales and enabling this type of training on more\nchallenging datasets such as ANLI. We fine-tune 7B, 14B, and 32B language\nmodels using parameter-efficient techniques (LoRA and QLoRA), demonstrating\nstrong performance across standard and adversarial NLI benchmarks. Our 32B\nAWQ-quantized model surpasses state-of-the-art results on 7 out of 11\nadversarial sets$\\unicode{x2013}$or on all of them considering our\nreplication$\\unicode{x2013}$within a 22GB memory footprint, showing that robust\nreasoning can be retained under aggressive quantization. This work provides a\nscalable and practical framework for building robust NLI systems without\nsacrificing inference quality.",
      "tldr_zh": "本文提出了一种基于强化学习的Group Relative Policy Optimization (GRPO)方法，用于Natural Language Inference (NLI)的Chain-of-Thought (CoT)学习，旨在解决当前NLI系统依赖有偏数据集的问题，从而提升泛化和实际应用能力。研究团队使用LoRA和QLoRA参数高效技术微调了7B、14B和32B语言模型，并在更具挑战性的数据集如ANLI上进行训练，而无需标注推理过程。实验结果显示，32B AWQ-quantized模型在11个对抗性NLI基准中超越了7个（或全部，考虑复现）的现有最佳性能，并在22GB内存下保持了鲁棒推理质量，为构建可扩展的NLI系统提供了实用框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18376v2",
      "published_date": "2025-04-25 14:20:57 UTC",
      "updated_date": "2025-05-06 13:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:40:55.404196"
    },
    {
      "arxiv_id": "2504.20083v1",
      "title": "A model and package for German ColBERT",
      "title_zh": "翻译失败",
      "authors": [
        "Thuong Dang",
        "Qiqi Chen"
      ],
      "abstract": "In this work, we introduce a German version for ColBERT, a late interaction\nmulti-dense vector retrieval method, with a focus on RAG applications. We also\npresent the main features of our package for ColBERT models, supporting both\nretrieval and fine-tuning workflows.",
      "tldr_zh": "本文介绍了ColBERT的德语版本，这是一种late interaction multi-dense vector retrieval方法，专注于RAG（Retrieval-Augmented Generation）应用。该版本旨在提升检索效率，并针对德语语境进行优化。此外，我们提供了一个配套包，支持检索和fine-tuning工作流，以便用户轻松实现模型部署和训练。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20083v1",
      "published_date": "2025-04-25 14:17:53 UTC",
      "updated_date": "2025-04-25 14:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:41:05.211998"
    },
    {
      "arxiv_id": "2504.18361v1",
      "title": "COCO-Inpaint: A Benchmark for Image Inpainting Detection and Manipulation Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhen Yan",
        "Yan Hong",
        "Jiahui Zhan",
        "Yikun Ji",
        "Jun Lan",
        "Huijia Zhu",
        "Weiqiang Wang",
        "Jianfu Zhang"
      ],
      "abstract": "Recent advancements in image manipulation have achieved unprecedented\nprogress in generating photorealistic content, but also simultaneously\neliminating barriers to arbitrary manipulation and editing, raising concerns\nabout multimedia authenticity and cybersecurity. However, existing Image\nManipulation Detection and Localization (IMDL) methodologies predominantly\nfocus on splicing or copy-move forgeries, lacking dedicated benchmarks for\ninpainting-based manipulations. To bridge this gap, we present COCOInpaint, a\ncomprehensive benchmark specifically designed for inpainting detection, with\nthree key contributions: 1) High-quality inpainting samples generated by six\nstate-of-the-art inpainting models, 2) Diverse generation scenarios enabled by\nfour mask generation strategies with optional text guidance, and 3) Large-scale\ncoverage with 258,266 inpainted images with rich semantic diversity. Our\nbenchmark is constructed to emphasize intrinsic inconsistencies between\ninpainted and authentic regions, rather than superficial semantic artifacts\nsuch as object shapes. We establish a rigorous evaluation protocol using three\nstandard metrics to assess existing IMDL approaches. The dataset will be made\npublicly available to facilitate future research in this area.",
      "tldr_zh": "该论文提出 COCO-Inpaint 基准，用于评估图像修复（Image Inpainting）检测和操作定位，旨在填补现有 IMDL（Image Manipulation Detection and Localization）方法对修复伪造的关注不足。基准的关键贡献包括：使用六种最先进修复模型生成高质量样本、四种掩码生成策略实现多样化场景，以及涵盖 258,266 张语义丰富的修复图像。COCO-Inpaint 强调修复区域与真实区域的内在不一致性，并通过三个标准指标建立严格评估协议，以促进未来图像篡改检测研究。数据集将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18361v1",
      "published_date": "2025-04-25 14:04:36 UTC",
      "updated_date": "2025-04-25 14:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:41:19.019745"
    },
    {
      "arxiv_id": "2504.18353v1",
      "title": "Testing Individual Fairness in Graph Neural Networks",
      "title_zh": "测试图神经网络中的个体公平",
      "authors": [
        "Roya Nasiri"
      ],
      "abstract": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models.",
      "tldr_zh": "本论文探讨了 Graph Neural Networks (GNNs) 中的个体公平性问题，强调偏见如何通过图结构中的节点连接传播，导致歧视性决策。研究首先系统回顾个体公平性文献，建立一个分类法(taxonomy)来定义、测量、测试和缓解模型偏见。接着，开发了一个测试框架，通过适应和扩展现有公平性技术，确保 GNNs 的公平性，并通过工业案例研究进行评估，聚焦于基于图的大型语言模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.18353v1",
      "published_date": "2025-04-25 13:45:24 UTC",
      "updated_date": "2025-04-25 13:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:41:29.558852"
    },
    {
      "arxiv_id": "2504.20082v1",
      "title": "Evolution of AI in Education: Agentic Workflows",
      "title_zh": "AI 在教育中的演变：智能体工作流",
      "authors": [
        "Firuz Kamalov",
        "David Santandreu Calonge",
        "Linda Smail",
        "Dilshod Azizov",
        "Dimple R. Thadani",
        "Theresa Kwong",
        "Amara Atif"
      ],
      "abstract": "Artificial intelligence (AI) has transformed various aspects of education,\nwith large language models (LLMs) driving advancements in automated tutoring,\nassessment, and content generation. However, conventional LLMs are constrained\nby their reliance on static training data, limited adaptability, and lack of\nreasoning. To address these limitations and foster more sustainable\ntechnological practices, AI agents have emerged as a promising new avenue for\neducational innovation. In this review, we examine agentic workflows in\neducation according to four major paradigms: reflection, planning, tool use,\nand multi-agent collaboration. We critically analyze the role of AI agents in\neducation through these key design paradigms, exploring their advantages,\napplications, and challenges. To illustrate the practical potential of agentic\nsystems, we present a proof-of-concept application: a multi-agent framework for\nautomated essay scoring. Preliminary results suggest this agentic approach may\noffer improved consistency compared to stand-alone LLMs. Our findings highlight\nthe transformative potential of AI agents in educational settings while\nunderscoring the need for further research into their interpretability,\ntrustworthiness, and sustainable impact on pedagogical impact.",
      "tldr_zh": "该论文审查了人工智能（AI）在教育领域的演变，特别强调 AI 代理如何克服大语言模型（LLMs）的局限性，如依赖静态训练数据和缺乏推理能力。通过四个主要范式——反思（reflection）、规划（planning）、工具使用（tool use）和多代理协作（multi-agent collaboration）——分析了 AI 代理的优势、应用和挑战。论文提供了一个自动作文评分的证明概念（proof-of-concept）多代理框架，初步结果显示其比独立 LLMs 更一致，并呼吁进一步研究 AI 代理的可解释性、可信性和对教育的可持续影响。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20082v1",
      "published_date": "2025-04-25 13:44:57 UTC",
      "updated_date": "2025-04-25 13:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:41:43.017742"
    },
    {
      "arxiv_id": "2504.18348v1",
      "title": "TSCL:Multi-party loss Balancing scheme for deep learning Image steganography based on Curriculum learning",
      "title_zh": "TSCL：基于课程学习的深度学习图像隐写术多方损失",
      "authors": [
        "Fengchun Liu. Tong Zhang",
        "Chunying Zhang"
      ],
      "abstract": "For deep learning-based image steganography frameworks, in order to ensure\nthe invisibility and recoverability of the information embedding, the loss\nfunction usually contains several losses such as embedding loss, recovery loss\nand steganalysis loss. In previous research works, fixed loss weights are\nusually chosen for training optimization, and this setting is not linked to the\nimportance of the steganography task itself and the training process. In this\npaper, we propose a Two-stage Curriculum Learning loss scheduler (TSCL) for\nbalancing multinomial losses in deep learning image steganography algorithms.\nTSCL consists of two phases: a priori curriculum control and loss dynamics\ncontrol. The first phase firstly focuses the model on learning the information\nembedding of the original image by controlling the loss weights in the\nmulti-party adversarial training; secondly, it makes the model shift its\nlearning focus to improving the decoding accuracy; and finally, it makes the\nmodel learn to generate a steganographic image that is resistant to\nsteganalysis. In the second stage, the learning speed of each training task is\nevaluated by calculating the loss drop of the before and after iteration rounds\nto balance the learning of each task. Experimental results on three large\npublic datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed TSCL\nstrategy improves the quality of steganography, decoding accuracy and security.",
      "tldr_zh": "本文提出 TSCL（Two-stage Curriculum Learning loss scheduler），一种基于课程学习的损失平衡方案，用于深度学习图像 steganography 算法中平衡多项损失，如嵌入损失、恢复损失和 steganalysis 损失。TSCL 分为两个阶段：先验课程控制阶段逐步关注信息嵌入、解码准确性和抵抗 steganalysis 的图像生成；损失动态控制阶段通过计算损失下降来调整各任务的学习速度。实验结果在 ALASKA2、VOC2012 和 ImageNet 数据集上显示，该方法显著提高了 steganography 的图像质量、解码准确性和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18348v1",
      "published_date": "2025-04-25 13:36:50 UTC",
      "updated_date": "2025-04-25 13:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:41:53.922983"
    },
    {
      "arxiv_id": "2504.18346v1",
      "title": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review",
      "title_zh": "比较大型语言模型的不确定性测量和缓解方法：一个系统综述",
      "authors": [
        "Toghrul Abbasli",
        "Kentaroh Toyoda",
        "Yuan Wang",
        "Leon Witt",
        "Muhammad Asif Ali",
        "Yukai Miao",
        "Dan Li",
        "Qingsong Wei"
      ],
      "abstract": "Large Language Models (LLMs) have been transformative across many domains.\nHowever, hallucination -- confidently outputting incorrect information --\nremains one of the leading challenges for LLMs. This raises the question of how\nto accurately assess and quantify the uncertainty of LLMs. Extensive literature\non traditional models has explored Uncertainty Quantification (UQ) to measure\nuncertainty and employed calibration techniques to address the misalignment\nbetween uncertainty and accuracy. While some of these methods have been adapted\nfor LLMs, the literature lacks an in-depth analysis of their effectiveness and\ndoes not offer a comprehensive benchmark to enable insightful comparison among\nexisting solutions. In this work, we fill this gap via a systematic survey of\nrepresentative prior works on UQ and calibration for LLMs and introduce a\nrigorous benchmark. Using two widely used reliability datasets, we empirically\nevaluate six related methods, which justify the significant findings of our\nreview. Finally, we provide outlooks for key future directions and outline open\nchallenges. To the best of our knowledge, this survey is the first dedicated\nstudy to review the calibration methods and relevant metrics for LLMs.",
      "tldr_zh": "这篇论文系统综述了Large Language Models (LLMs)的不确定性测量和缓解方法，重点解决hallucination问题（即模型自信输出错误信息）。作者通过调查现有Uncertainty Quantification (UQ)和calibration技术，引入了一个严格的基准，并使用两个可靠性数据集实证评估了六种相关方法。结果显示，这些方法的有效性存在显著差异，为未来LLMs的可靠性改进提供了关键见解，并指出了潜在的开放挑战和研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18346v1",
      "published_date": "2025-04-25 13:34:40 UTC",
      "updated_date": "2025-04-25 13:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:42:06.047885"
    },
    {
      "arxiv_id": "2504.18329v1",
      "title": "PHEATPRUNER: Interpretable Data-centric Feature Selection for Multivariate Time Series Classification through Persistent Homology",
      "title_zh": "PHEATPRUNER：通过持久同调进行可解释的数据中心化特征选择，用于多元时间序列分类",
      "authors": [
        "Anh-Duy Pham",
        "Olivier Basole Kashongwe",
        "Martin Atzmueller",
        "Tim Römer"
      ],
      "abstract": "Balancing performance and interpretability in multivariate time series\nclassification is a significant challenge due to data complexity and high\ndimensionality. This paper introduces PHeatPruner, a method integrating\npersistent homology and sheaf theory to address these challenges. Persistent\nhomology facilitates the pruning of up to 45% of the applied variables while\nmaintaining or enhancing the accuracy of models such as Random Forest,\nCatBoost, XGBoost, and LightGBM, all without depending on posterior\nprobabilities or supervised optimization algorithms. Concurrently, sheaf theory\ncontributes explanatory vectors that provide deeper insights into the data's\nstructural nuances. The approach was validated using the UEA Archive and a\nmastitis detection dataset for dairy cows. The results demonstrate that\nPHeatPruner effectively preserves model accuracy. Furthermore, our results\nhighlight PHeatPruner's key features, i.e. simplifying complex data and\noffering actionable insights without increasing processing time or complexity.\nThis method bridges the gap between complexity reduction and interpretability,\nsuggesting promising applications in various fields.",
      "tldr_zh": "本文提出 PHeatPruner，一种基于 Persistent Homology 和 Sheaf Theory 的可解释特征选择方法，旨在解决多变量时间序列分类中性能与可解释性的平衡问题。该方法通过 Persistent Homology 修剪多达 45% 的变量，同时保持或提升 Random Forest、CatBoost、XGBoost 和 LightGBM 等模型的准确性，而不依赖后验概率或监督优化算法。Sheaf Theory 则提供解释向量，帮助深入理解数据的结构细微差别。在 UEA Archive 和乳牛乳腺炎检测数据集上验证结果显示，PHeatPruner 有效简化复杂数据、提供可操作洞见，且不增加处理时间或复杂度，为各种领域的数据处理带来潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.18329v1",
      "published_date": "2025-04-25 13:14:11 UTC",
      "updated_date": "2025-04-25 13:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:42:21.099055"
    },
    {
      "arxiv_id": "2504.18316v1",
      "title": "Towards Adaptive Software Agents for Debugging",
      "title_zh": "翻译失败",
      "authors": [
        "Yacine Majdoub",
        "Eya Ben Charrada",
        "Haifa Touati"
      ],
      "abstract": "Using multiple agents was found to improve the debugging capabilities of\nLarge Language Models. However, increasing the number of LLM-agents has several\ndrawbacks such as increasing the running costs and rising the risk for the\nagents to lose focus. In this work, we propose an adaptive agentic design,\nwhere the number of agents and their roles are determined dynamically based on\nthe characteristics of the task to be achieved. In this design, the agents\nroles are not predefined, but are generated after analyzing the problem to be\nsolved. Our initial evaluation shows that, with the adaptive design, the number\nof agents that are generated depends on the complexity of the buggy code. In\nfact, for simple code with mere syntax issues, the problem was usually fixed\nusing one agent only. However, for more complex problems, we noticed the\ncreation of a higher number of agents. Regarding the effectiveness of the fix,\nwe noticed an average improvement of 11% compared to the one-shot prompting.\nGiven these promising results, we outline future research directions to improve\nour design for adaptive software agents that can autonomously plan and conduct\ntheir software goals.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的调试能力，提出了一种自适应代理设计（adaptive agentic design），其中代理数量和角色根据任务特性动态确定，而非预定义。设计过程通过分析问题来生成代理角色，确保高效处理不同复杂度的代码bug。初步评估显示，对于简单语法问题，可能仅需一个代理，而复杂任务会创建更多代理，并与one-shot prompting相比，平均改善11%的修复效果。未来研究将聚焦于增强代理的自主规划和执行能力，以优化软件调试过程。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "5 pages, 3 figures, FSE2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18316v1",
      "published_date": "2025-04-25 12:48:08 UTC",
      "updated_date": "2025-04-25 12:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:42:30.744345"
    },
    {
      "arxiv_id": "2504.18310v1",
      "title": "Artificial Intelligence health advice accuracy varies across languages and contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Prashant Garg",
        "Thiemo Fetzer"
      ],
      "abstract": "Using basic health statements authorized by UK and EU registers and 9,100\njournalist-vetted public-health assertions on topics such as abortion, COVID-19\nand politics from sources ranging from peer-reviewed journals and government\nadvisories to social media and news across the political spectrum, we benchmark\nsix leading large language models from in 21 languages, finding that, despite\nhigh accuracy on English-centric textbook claims, performance falls in multiple\nnon-European languages and fluctuates by topic and source, highlighting the\nurgency of comprehensive multilingual, domain-aware validation before deploying\nAI in global health communication.",
      "tldr_zh": "这篇论文评估了六种领先的大型语言模型（LLMs）在21种语言中提供健康建议的准确性，使用英国和欧盟授权的基本健康声明，以及来自同行评议期刊、政府建议、社会媒体和新闻等来源的9100个公共健康断言作为基准。研究发现，尽管LLMs在英语中心的教科书声明上表现出高准确性，但在多种非欧洲语言中性能下降，且准确性会根据主题（如堕胎、COVID-19和政治）和来源而波动。这些结果突出了在全球健康传播中部署AI之前，进行全面的多语言和领域感知验证的紧迫性。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "10 pages, 2 figures. All data, code and materials used is freely\n  available in the Zenodo (DOI: 10.5281/zenodo.15281282)",
      "pdf_url": "http://arxiv.org/pdf/2504.18310v1",
      "published_date": "2025-04-25 12:37:15 UTC",
      "updated_date": "2025-04-25 12:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:42:41.502768"
    },
    {
      "arxiv_id": "2504.18286v1",
      "title": "Enhancing Long-Term Re-Identification Robustness Using Synthetic Data: A Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Pionzewski",
        "Rebecca Rademacher",
        "Jérôme Rutinowski",
        "Antonia Ponikarov",
        "Stephan Matzke",
        "Tim Chilla",
        "Pia Schreynemackers",
        "Alice Kirchheim"
      ],
      "abstract": "This contribution explores the impact of synthetic training data usage and\nthe prediction of material wear and aging in the context of re-identification.\nDifferent experimental setups and gallery set expanding strategies are tested,\nanalyzing their impact on performance over time for aging re-identification\nsubjects. Using a continuously updating gallery, we were able to increase our\nmean Rank-1 accuracy by 24%, as material aging was taken into account step by\nstep. In addition, using models trained with 10% artificial training data,\nRank-1 accuracy could be increased by up to 13%, in comparison to a model\ntrained on only real-world data, significantly boosting generalized performance\non hold-out data. Finally, this work introduces a novel, open-source\nre-identification dataset, pallet-block-2696. This dataset contains 2,696\nimages of Euro pallets, taken over a period of 4 months. During this time,\nnatural aging processes occurred and some of the pallets were damaged during\ntheir usage. These wear and tear processes significantly changed the appearance\nof the pallets, providing a dataset that can be used to generate synthetically\naged pallets or other wooden materials.",
      "tldr_zh": "本研究探讨了使用合成数据（synthetic data）提升再识别（re-identification）任务的长期鲁棒性，特别是针对材料磨损和老化的影响，通过比较不同实验设置和图库扩展策略。结果显示，使用不断更新的图库可以将平均Rank-1准确率提高24%，而将10%的训练数据替换为合成数据时，与仅使用真实数据相比，Rank-1准确率可提升13%，显著改善模型的泛化性能。最后，该工作引入了一个开源数据集pallet-block-2696，包含2696张Euro pallets图像，记录了4个月内的自然老化过程，可用于生成合成老化样本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in: 2024 International Conference on Machine Learning and\n  Applications (ICMLA), IEEE. 6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18286v1",
      "published_date": "2025-04-25 11:57:11 UTC",
      "updated_date": "2025-04-25 11:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:42:53.354419"
    },
    {
      "arxiv_id": "2504.18283v1",
      "title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator",
      "title_zh": "翻译失败",
      "authors": [
        "Minjae Kang",
        "Martim Brandão"
      ],
      "abstract": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio.",
      "tldr_zh": "本研究提出了一种音频-视觉生成和分离模型（AV-GAS），旨在从 soundscapes（混合音频）生成图像，解决了现有模型仅限于单一类音频的局限性。主要贡献包括：定义了从多类音频输入生成图像的新挑战，并使用 audio-visual separator 方法处理；引入 audio-visual separation 任务，从混合音频生成每个类的单独图像；以及提出新评估指标 Class Representation Score (CRS) 和修改后的 R@K。在 VGGSound 数据集上实验表明，该模型比最先进方法提升 7% 的 CRS 和 4% 的 R@2*，在生成混合音频图像方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "Originally submitted to CVPR 2025 on 2024-11-15 with paper ID 15808",
      "pdf_url": "http://arxiv.org/pdf/2504.18283v1",
      "published_date": "2025-04-25 11:51:04 UTC",
      "updated_date": "2025-04-25 11:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:43:05.571490"
    },
    {
      "arxiv_id": "2504.18271v1",
      "title": "LEAM: A Prompt-only Large Language Model-enabled Antenna Modeling Method",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Wu",
        "Kexue Fu",
        "Qiang Hua",
        "Xinxin Liu",
        "Muhammad Ali Imran",
        "Bo Liu"
      ],
      "abstract": "Antenna modeling is a time-consuming and complex process, decreasing the\nspeed of antenna analysis and design. In this paper, a large language model\n(LLM)- enabled antenna modeling method, called LEAM, is presented to address\nthis challenge. LEAM enables automatic antenna model generation based on\nlanguage descriptions via prompt input, images, descriptions from academic\npapers, patents, and technical reports (either one or multiple). The\neffectiveness of LEAM is demonstrated by three examples: a Vivaldi antenna\ngenerated from a complete user description, a slotted patch antenna generated\nfrom an incomplete user description and the operating frequency, and a monopole\nslotted antenna generated from images and descriptions scanned from the\nliterature. For all the examples, correct antenna models are generated in a few\nminutes. The code can be accessed via https://github.com/TaoWu974/LEAM.",
      "tldr_zh": "该论文提出LEAM，一种基于大语言模型(LLM)的prompt-only天线建模方法，用于解决天线分析和设计过程耗时复杂的问题。LEAM通过用户输入的语言描述、图像、学术论文、专利或技术报告自动生成天线模型，提升了建模效率。论文通过三个示例验证了其有效性，包括从完整描述生成Vivaldi天线、从不完整描述和操作频率生成槽化贴片天线，以及从文献图像和描述生成单极槽化天线，所有模型均在几分钟内准确完成。代码可通过GitHub访问。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Code are available: https://github.com/TaoWu974/LEAM",
      "pdf_url": "http://arxiv.org/pdf/2504.18271v1",
      "published_date": "2025-04-25 11:29:30 UTC",
      "updated_date": "2025-04-25 11:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:43:17.825032"
    },
    {
      "arxiv_id": "2504.18267v2",
      "title": "Neural operators struggle to learn complex PDEs in pedestrian mobility: Hughes model case study",
      "title_zh": "神经算子难以学习行人流动中的复杂偏微",
      "authors": [
        "Prajwal Chauhan",
        "Salah Eddine Choutri",
        "Mohamed Ghattassi",
        "Nader Masmoudi",
        "Saif Eddin Jabari"
      ],
      "abstract": "This paper investigates the limitations of neural operators in learning\nsolutions for a Hughes model, a first-order hyperbolic conservation law system\nfor crowd dynamics. The model couples a Fokker-Planck equation representing\npedestrian density with a Hamilton-Jacobi-type (eikonal) equation. This Hughes\nmodel belongs to the class of nonlinear hyperbolic systems that often exhibit\ncomplex solution structures, including shocks and discontinuities. In this\nstudy, we assess the performance of three state-of-the-art neural operators\n(Fourier Neural Operator, Wavelet Neural Operator, and Multiwavelet Neural\nOperator) in various challenging scenarios. Specifically, we consider (1)\ndiscontinuous and Gaussian initial conditions and (2) diverse boundary\nconditions, while also examining the impact of different numerical schemes.\n  Our results show that these neural operators perform well in easy scenarios\nwith fewer discontinuities in the initial condition, yet they struggle in\ncomplex scenarios with multiple initial discontinuities and dynamic boundary\nconditions, even when trained specifically on such complex samples. The\npredicted solutions often appear smoother, resulting in a reduction in total\nvariation and a loss of important physical features. This smoothing behavior is\nsimilar to issues discussed by Daganzo (1995), where models that introduce\nartificial diffusion were shown to miss essential features such as shock waves\nin hyperbolic systems. These results suggest that current neural operator\narchitectures may introduce unintended regularization effects that limit their\nability to capture transport dynamics governed by discontinuities. They also\nraise concerns about generalizing these methods to traffic applications where\nshock preservation is essential.",
      "tldr_zh": "本文研究了 Neural operators 在学习 Hughes model（一个用于人群动态的非线性双曲守恒定律系统，包括 Fokker-Planck 方程和 Hamilton-Jacobi 型方程）时的局限性，通过评估 Fourier Neural Operator、Wavelet Neural Operator 和 Multiwavelet Neural Operator 在不同初始条件（如不连续和高斯）和边界条件下的性能。结果表明，这些模型在简单场景（较少不连续性）表现良好，但在大规模复杂场景中（如多个初始不连续性和动态边界条件）难以捕捉 shocks 和 discontinuities，导致预测解决方案过度平滑并丢失重要物理特征。研究强调，Neural operators 可能引入 unintended regularization effects，限制了其在交通应用等需要精确保存冲击波的领域中的推广潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 15 figures, 6 tables, under review at Artificial\n  Intelligence for Transportation | Journal",
      "pdf_url": "http://arxiv.org/pdf/2504.18267v2",
      "published_date": "2025-04-25 11:26:41 UTC",
      "updated_date": "2025-05-05 07:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:43:31.166191"
    },
    {
      "arxiv_id": "2504.18253v1",
      "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Amirhossein Zhalehmehrabi",
        "Daniele Meli",
        "Francesco Dal Santo",
        "Francesco Trotti",
        "Alessandro Farinelli"
      ],
      "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime\noperations, yet their navigation in shallow-water environments remains\nchallenging due to dynamic disturbances and depth constraints. Traditional\nnavigation strategies struggle with limited sensor information, making safe and\nefficient operation difficult. In this paper, we propose a reinforcement\nlearning (RL) framework for ASV navigation under depth constraints, where the\nvehicle must reach a target while avoiding unsafe areas with only a single\ndepth measurement per timestep from a downward-facing Single Beam Echosounder\n(SBES). To enhance environmental awareness, we integrate Gaussian Process (GP)\nregression into the RL framework, enabling the agent to progressively estimate\na bathymetric depth map from sparse sonar readings. This approach improves\ndecision-making by providing a richer representation of the environment.\nFurthermore, we demonstrate effective sim-to-real transfer, ensuring that\ntrained policies generalize well to real-world aquatic conditions. Experimental\nresults validate our method's capability to improve ASV navigation performance\nwhile maintaining safety in challenging shallow-water environments.",
      "tldr_zh": "本研究针对自主水面车辆(ASV)在浅水环境中的导航挑战，提出了一种基于强化学习(RL)的框架，以应对动态干扰和深度限制，同时仅依赖每个时间步的单一深度测量。框架整合了Gaussian Process (GP)回归技术，利用稀疏的声纳读数逐步估计水深图(bathymetric depth map)，从而提升ASV的环境感知和决策能力。该方法实现了有效的sim-to-real转移，并在实验中验证了其在挑战性浅水环境中的性能提升，确保了ASV的安全和高效导航。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18253v1",
      "published_date": "2025-04-25 10:56:56 UTC",
      "updated_date": "2025-04-25 10:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:43:40.997328"
    },
    {
      "arxiv_id": "2504.18249v1",
      "title": "Event-Based Eye Tracking. 2025 Event-based Vision Workshop",
      "title_zh": "翻译失败",
      "authors": [
        "Qinyu Chen",
        "Chang Gao",
        "Min Liu",
        "Daniele Perrone",
        "Yan Ru Pei",
        "Zuowen Wang",
        "Zhuo Zou",
        "Shihang Tan",
        "Tao Han",
        "Guorui Lu",
        "Zhen Xu",
        "Junyuan Ding",
        "Ziteng Wang",
        "Zongwei Wu",
        "Han Han",
        "Yuliang Wu",
        "Jinze Chen",
        "Wei Zhai",
        "Yang Cao",
        "Zheng-jun Zha",
        "Nuwan Bandara",
        "Thivya Kandappu",
        "Archan Misra",
        "Xiaopeng Lin",
        "Hongxiang Huang",
        "Hongwei Ren",
        "Bojun Cheng",
        "Hoang M. Truong",
        "Vinh-Thuan Ly",
        "Huy G. Tran",
        "Thuan-Phat Nguyen",
        "Tram T. Doan"
      ],
      "abstract": "This survey serves as a review for the 2025 Event-Based Eye Tracking\nChallenge organized as part of the 2025 CVPR event-based vision workshop. This\nchallenge focuses on the task of predicting the pupil center by processing\nevent camera recorded eye movement. We review and summarize the innovative\nmethods from teams rank the top in the challenge to advance future event-based\neye tracking research. In each method, accuracy, model size, and number of\noperations are reported. In this survey, we also discuss event-based eye\ntracking from the perspective of hardware design.",
      "tldr_zh": "这篇调查论文回顾了2025年CVPR基于事件视觉工作坊中的Event-Based Eye Tracking挑战，焦点是使用event camera记录的眼动数据来预测瞳孔中心。论文总结了排名靠前的团队创新方法，包括准确性、模型大小和操作数量的详细报告，以推进未来event-based eye tracking研究。 additionally, it explores hardware design perspectives to enhance the practical application of these techniques in eye tracking systems。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18249v1",
      "published_date": "2025-04-25 10:50:14 UTC",
      "updated_date": "2025-04-25 10:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:43:52.229206"
    },
    {
      "arxiv_id": "2504.18246v1",
      "title": "Efficient Single-Pass Training for Multi-Turn Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ritesh Goru",
        "Shanay Mehta",
        "Prateek Jain"
      ],
      "abstract": "Training Large Language Models ( LLMs) to generate explicit reasoning before\nthey produce an answer has been shown to improve their performance across\nvarious tasks such as mathematics and coding. However, fine-tuning LLMs on\nmulti-turn reasoning datasets presents a unique challenge: LLMs must generate\nreasoning tokens that are excluded from subsequent inputs to the LLM. This\ndiscrepancy prevents us from processing an entire conversation in a single\nforward pass-an optimization readily available when we fine-tune on a\nmulti-turn non-reasoning dataset. This paper proposes a novel approach that\novercomes this limitation through response token duplication and a custom\nattention mask that enforces appropriate visibility constraints. Our approach\nsignificantly reduces the training time and allows efficient fine-tuning on\nmulti-turn reasoning datasets.",
      "tldr_zh": "这项研究解决了训练 Large Language Models (LLMs) 在多轮推理任务中的挑战，即模型需要生成显式推理标记，但这些标记不能包含在后续输入中，导致无法实现单次前向传递。论文提出了一种创新方法，通过响应标记复制和自定义 attention mask 来强制执行可见性约束，从而允许在单次前向传递中处理整个对话。结果显示，这种方法显著减少了训练时间，并提高了多轮推理数据集的细调效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18246v1",
      "published_date": "2025-04-25 10:46:56 UTC",
      "updated_date": "2025-04-25 10:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:44:05.797341"
    },
    {
      "arxiv_id": "2504.18231v1",
      "title": "Time and Frequency Domain-based Anomaly Detection in Smart Meter Data for Distribution Network Studies",
      "title_zh": "翻译失败",
      "authors": [
        "Petar Labura",
        "Tomislav Antic",
        "Tomislav Capuder"
      ],
      "abstract": "The widespread integration of new technologies in low-voltage distribution\nnetworks on the consumer side creates the need for distribution system\noperators to perform advanced real-time calculations to estimate network\nconditions. In recent years, data-driven models based on machine learning and\nbig data analysis have emerged for calculation purposes, leveraging the\ninformation available in large datasets obtained from smart meters and other\nadvanced measurement infrastructure. However, existing data-driven algorithms\ndo not take into account the quality of data collected from smart meters. They\nlack built-in anomaly detection mechanisms and fail to differentiate anomalies\nbased on whether the value or context of anomalous data instances deviates from\nthe norm. This paper focuses on methods for detecting and mitigating the impact\nof anomalies on the consumption of active and reactive power datasets. It\nproposes an anomaly detection framework based on the Isolation Forest machine\nlearning algorithm and Fast Fourier Transform filtering that works in both the\ntime and frequency domain and is unaffected by point anomalies or contextual\nanomalies of the power consumption data. The importance of integrating anomaly\ndetection methods is demonstrated in the analysis important for distribution\nnetworks with a high share of smart meters.",
      "tldr_zh": "这篇论文针对智能电表数据中的异常问题，指出现有数据驱动模型（如基于机器学习和大数据分析的算法）缺乏内置的异常检测机制，无法有效区分点异常或上下文异常，从而影响配电网络的实时计算。论文提出了一种基于 Isolation Forest 算法和 Fast Fourier Transform (FFT) 过滤的异常检测框架，能够同时在时间和频率域工作，检测并缓解异常对有功和无功功率数据集的影响。该框架通过实验证明，在高智能电表比例的配电网络中集成异常检测方法，能显著提高数据质量和网络分析准确性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18231v1",
      "published_date": "2025-04-25 10:26:30 UTC",
      "updated_date": "2025-04-25 10:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:44:19.307148"
    },
    {
      "arxiv_id": "2504.18230v1",
      "title": "Learning to fuse: dynamic integration of multi-source data for accurate battery lifespan prediction",
      "title_zh": "翻译失败",
      "authors": [
        "He Shanxuan",
        "Lin Zuhong",
        "Yu Bolun",
        "Gao Xu",
        "Long Biao",
        "Yao Jingjing"
      ],
      "abstract": "Accurate prediction of lithium-ion battery lifespan is vital for ensuring\noperational reliability and reducing maintenance costs in applications like\nelectric vehicles and smart grids. This study presents a hybrid learning\nframework for precise battery lifespan prediction, integrating dynamic\nmulti-source data fusion with a stacked ensemble (SE) modeling approach. By\nleveraging heterogeneous datasets from the National Aeronautics and Space\nAdministration (NASA), Center for Advanced Life Cycle Engineering (CALCE),\nMIT-Stanford-Toyota Research Institute (TRC), and nickel cobalt aluminum (NCA)\nchemistries, an entropy-based dynamic weighting mechanism mitigates variability\nacross heterogeneous datasets. The SE model combines Ridge regression, long\nshort-term memory (LSTM) networks, and eXtreme Gradient Boosting (XGBoost),\neffectively capturing temporal dependencies and nonlinear degradation patterns.\nIt achieves a mean absolute error (MAE) of 0.0058, root mean square error\n(RMSE) of 0.0092, and coefficient of determination (R2) of 0.9839,\noutperforming established baseline models with a 46.2% improvement in R2 and an\n83.2% reduction in RMSE. Shapley additive explanations (SHAP) analysis\nidentifies differential discharge capacity (Qdlin) and temperature of\nmeasurement (Temp_m) as critical aging indicators. This scalable, interpretable\nframework enhances battery health management, supporting optimized maintenance\nand safety across diverse energy storage systems, thereby contributing to\nimproved battery health management in energy storage systems.",
      "tldr_zh": "这项研究提出了一种混合学习框架，用于精确预测锂离子电池寿命，通过动态整合多源数据（如 NASA、CALCE 和 MIT-Stanford-Toyota TRC 数据集）来解决异构数据变异性问题。框架采用熵-based 动态加权机制融合数据，并结合 Stacked Ensemble (SE) 模型，包括 Ridge regression、LSTM 网络和 XGBoost，以捕捉时间依赖性和非线性退化模式。实验结果显示，该模型实现了 MAE 0.0058、RMSE 0.0092 和 R2 0.9839，与基线模型相比，R2 提高了 46.2%、RMSE 降低了 83.2%；SHAP 分析进一步标识了 differential discharge capacity (Qdlin) 和 temperature of measurement (Temp_m) 作为关键老化指标。该框架增强了电池健康管理，支持优化维护和安全在能源存储系统中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18230v1",
      "published_date": "2025-04-25 10:24:45 UTC",
      "updated_date": "2025-04-25 10:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:44:31.355519"
    },
    {
      "arxiv_id": "2504.18201v1",
      "title": "Multi-Grained Compositional Visual Clue Learning for Image Intent Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Tang",
        "Jiankai Li",
        "Hongyu Yang",
        "Xuan Dong",
        "Lifeng Fan",
        "Weixin Li"
      ],
      "abstract": "In an era where social media platforms abound, individuals frequently share\nimages that offer insights into their intents and interests, impacting\nindividual life quality and societal stability. Traditional computer vision\ntasks, such as object detection and semantic segmentation, focus on concrete\nvisual representations, while intent recognition relies more on implicit visual\nclues. This poses challenges due to the wide variation and subjectivity of such\nclues, compounded by the problem of intra-class variety in conveying abstract\nconcepts, e.g. \"enjoy life\". Existing methods seek to solve the problem by\nmanually designing representative features or building prototypes for each\nclass from global features. However, these methods still struggle to deal with\nthe large visual diversity of each intent category. In this paper, we introduce\na novel approach named Multi-grained Compositional visual Clue Learning (MCCL)\nto address these challenges for image intent recognition. Our method leverages\nthe systematic compositionality of human cognition by breaking down intent\nrecognition into visual clue composition and integrating multi-grained\nfeatures. We adopt class-specific prototypes to alleviate data imbalance. We\ntreat intent recognition as a multi-label classification problem, using a graph\nconvolutional network to infuse prior knowledge through label embedding\ncorrelations. Demonstrated by a state-of-the-art performance on the Intentonomy\nand MDID datasets, our approach advances the accuracy of existing methods while\nalso possessing good interpretability. Our work provides an attempt for future\nexplorations in understanding complex and miscellaneous forms of human\nexpression.",
      "tldr_zh": "本研究针对图像意图识别面临的挑战，提出了一种名为Multi-Grained Compositional visual Clue Learning (MCCL)的方法，以处理隐式视觉线索的多样性和主观性问题。该方法通过分解意图识别为视觉线索组合，并整合多粒度特征，同时采用类特定原型缓解数据不平衡，并将任务视为多标签分类问题，使用Graph Convolutional Network (GCN)注入标签嵌入的相关性先验知识。在Intentonomy和MDID数据集上，MCCL实现了最先进性能，提高了识别准确性并增强了模型的解释性，为理解复杂人类表达提供了新探索方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18201v1",
      "published_date": "2025-04-25 09:31:03 UTC",
      "updated_date": "2025-04-25 09:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:44:42.522436"
    },
    {
      "arxiv_id": "2504.18180v1",
      "title": "Aligning Language Models for Icelandic Legal Text Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Þórir Hrafn Harðarson",
        "Hrafn Loftsson",
        "Stefán Ólafsson"
      ],
      "abstract": "The integration of language models in the legal domain holds considerable\npromise for streamlining processes and improving efficiency in managing\nextensive workloads. However, the specialized terminology, nuanced language,\nand formal style of legal texts can present substantial challenges. This study\nexamines whether preference-based training techniques, specifically\nReinforcement Learning from Human Feedback and Direct Preference Optimization,\ncan enhance models' performance in generating Icelandic legal summaries that\nalign with domain-specific language standards and user preferences. We compare\nmodels fine-tuned with preference training to those using conventional\nsupervised learning. Results indicate that preference training improves the\nlegal accuracy of generated summaries over standard fine-tuning but does not\nsignificantly enhance the overall quality of Icelandic language usage.\nDiscrepancies between automated metrics and human evaluations further\nunderscore the importance of qualitative assessment in developing language\nmodels for the legal domain.",
      "tldr_zh": "这篇论文探讨了使用偏好训练技术，包括 Reinforcement Learning from Human Feedback 和 Direct Preference Optimization，来优化语言模型生成冰岛语法律文本摘要，以适应专业术语和正式风格的挑战。研究通过比较偏好训练与传统监督学习的方法，发现偏好训练显著提高了摘要的法律准确性，但未明显提升冰岛语整体质量。结果还突出了自动指标与人工评估之间的差异，强调在法律领域开发语言模型时需重视定性评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at NoDaLiDa 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18180v1",
      "published_date": "2025-04-25 08:55:15 UTC",
      "updated_date": "2025-04-25 08:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:44:54.523228"
    },
    {
      "arxiv_id": "2504.20080v1",
      "title": "DNAD: Differentiable Neural Architecture Distillation",
      "title_zh": "DNAD: 可微神经架构蒸馏",
      "authors": [
        "Xuan Rao",
        "Bo Zhao",
        "Derong Liu"
      ],
      "abstract": "To meet the demand for designing efficient neural networks with appropriate\ntrade-offs between model performance (e.g., classification accuracy) and\ncomputational complexity, the differentiable neural architecture distillation\n(DNAD) algorithm is developed based on two cores, namely search by deleting and\nsearch by imitating. Primarily, to derive neural architectures in a space where\ncells of the same type no longer share the same topology, the super-network\nprogressive shrinking (SNPS) algorithm is developed based on the framework of\ndifferentiable architecture search (DARTS), i.e., search by deleting. Unlike\nconventional DARTS-based approaches which yield neural architectures with\nsimple structures and derive only one architecture during the search procedure,\nSNPS is able to derive a Pareto-optimal set of architectures with flexible\nstructures by forcing the dynamic super-network shrink from a dense structure\nto a sparse one progressively. Furthermore, since knowledge distillation (KD)\nhas shown great effectiveness to train a compact network with the assistance of\nan over-parameterized model, we integrate SNPS with KD to formulate the DNAD\nalgorithm, i.e., search by imitating. By minimizing behavioral differences\nbetween the super-network and teacher network, the over-fitting of one-level\nDARTS is avoided and well-performed neural architectures are derived.\nExperiments on CIFAR-10 and ImageNet classification tasks demonstrate that both\nSNPS and DNAD are able to derive a set of architectures which achieve similar\nor lower error rates with fewer parameters and FLOPs. Particularly, DNAD\nachieves the top-1 error rate of 23.7% on ImageNet classification with a model\nof 6.0M parameters and 598M FLOPs, which outperforms most DARTS-based methods.",
      "tldr_zh": "该研究提出了一种可微神经架构蒸馏(DNAD)算法，用于设计高效神经网络，平衡模型性能（如分类准确率）和计算复杂度。DNAD 基于两个核心机制：search by deleting（通过 super-network progressive shrinking，SNPS 算法扩展 DARTS 框架，实现从密集到稀疏的渐进式架构搜索，生成一组 Pareto-optimal 的灵活结构架构）和 search by imitating（将 SNPS 与 knowledge distillation，KD 整合，通过最小化超网络与教师网络的行为差异，避免过度拟合）。实验结果显示，在 CIFAR-10 和 ImageNet 分类任务上，SNPS 和 DNAD 能获得参数和 FLOPs 更少的架构，同时实现相近或更低的错误率；特别地，DNAD 在 ImageNet 上以 6.0M 参数和 598M FLOPs 达到 23.7% 的 top-1 错误率，优于大多数 DARTS-based 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20080v1",
      "published_date": "2025-04-25 08:49:31 UTC",
      "updated_date": "2025-04-25 08:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:45:07.967453"
    },
    {
      "arxiv_id": "2504.20079v1",
      "title": "FX-DARTS: Designing Topology-unconstrained Architectures with Differentiable Architecture Search and Entropy-based Super-network Shrinking",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Rao",
        "Bo Zhao",
        "Derong Liu",
        "Cesare Alippi"
      ],
      "abstract": "Strong priors are imposed on the search space of Differentiable Architecture\nSearch (DARTS), such that cells of the same type share the same topological\nstructure and each intermediate node retains two operators from distinct nodes.\nWhile these priors reduce optimization difficulties and improve the\napplicability of searched architectures, they hinder the subsequent development\nof automated machine learning (Auto-ML) and prevent the optimization algorithm\nfrom exploring more powerful neural networks through improved architectural\nflexibility. This paper aims to reduce these prior constraints by eliminating\nrestrictions on cell topology and modifying the discretization mechanism for\nsuper-networks. Specifically, the Flexible DARTS (FX-DARTS) method, which\nleverages an Entropy-based Super-Network Shrinking (ESS) framework, is\npresented to address the challenges arising from the elimination of prior\nconstraints. Notably, FX-DARTS enables the derivation of neural architectures\nwithout strict prior rules while maintaining the stability in the enlarged\nsearch space. Experimental results on image classification benchmarks\ndemonstrate that FX-DARTS is capable of exploring a set of neural architectures\nwith competitive trade-offs between performance and computational complexity\nwithin a single search procedure.",
      "tldr_zh": "本论文针对 Differentiable Architecture Search (DARTS) 的强先验约束（如细胞拓扑共享和操作符限制）问题，提出 FX-DARTS 方法，以消除对神经架构拓扑的限制并改进超网络的离散化机制。FX-DARTS 引入 Entropy-based Super-Network Shrinking (ESS) 框架，处理无约束搜索空间带来的挑战，同时保持架构搜索的稳定性和灵活性。在图像分类基准实验中，FX-DARTS 能够在单个搜索过程中探索出一系列在性能与计算复杂度之间实现竞争性权衡的神经架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20079v1",
      "published_date": "2025-04-25 08:34:29 UTC",
      "updated_date": "2025-04-25 08:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:45:20.762126"
    },
    {
      "arxiv_id": "2504.18165v1",
      "title": "PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Michel Gokan Khan",
        "Renan Guarese",
        "Fabian Johnson",
        "Xi Vincent Wang",
        "Anders Bergman",
        "Benjamin Edvinsson",
        "Mario Romero",
        "Jérémy Vachier",
        "Jan Kronqvist"
      ],
      "abstract": "We introduce PerfCam, an open source Proof-of-Concept (PoC) digital twinning\nframework that combines camera and sensory data with 3D Gaussian Splatting and\ncomputer vision models for digital twinning, object tracking, and Key\nPerformance Indicators (KPIs) extraction in industrial production lines. By\nutilizing 3D reconstruction and Convolutional Neural Networks (CNNs), PerfCam\noffers a semi-automated approach to object tracking and spatial mapping,\nenabling digital twins that capture real-time KPIs such as availability,\nperformance, Overall Equipment Effectiveness (OEE), and rate of conveyor belts\nin the production line. We validate the effectiveness of PerfCam through a\npractical deployment within realistic test production lines in the\npharmaceutical industry and contribute an openly published dataset to support\nfurther research and development in the field. The results demonstrate\nPerfCam's ability to deliver actionable insights through its precise digital\ntwin capabilities, underscoring its value as an effective tool for developing\nusable digital twins in smart manufacturing environments and extracting\noperational analytics.",
      "tldr_zh": "我们引入了 PerfCam，一种开源的 Proof-of-Concept (PoC) 数字孪生框架，它结合相机和传感器数据、3D Gaussian Splatting 以及计算机视觉模型，用于工业生产线的数字孪生、物体跟踪和 Key Performance Indicators (KPIs) 提取。框架利用 3D 重建和 Convolutional Neural Networks (CNNs) 实现半自动物体跟踪和空间映射，从而捕获实时 KPIs，如可用性、性能、Overall Equipment Effectiveness (OEE) 和传送带速率。通过在制药行业实际生产线的部署验证，PerfCam 证明了其提供精确数字孪生和可操作洞见的能力，并发布了一个公开数据集以支持智能制造领域的进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18165v1",
      "published_date": "2025-04-25 08:29:00 UTC",
      "updated_date": "2025-04-25 08:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:45:32.568851"
    },
    {
      "arxiv_id": "2504.18160v1",
      "title": "Offline Learning of Controllable Diverse Behaviors",
      "title_zh": "离线学习可控多样行为",
      "authors": [
        "Mathieu Petitbois",
        "Rémy Portelas",
        "Sylvain Lamprier",
        "Ludovic Denoyer"
      ],
      "abstract": "Imitation Learning (IL) techniques aim to replicate human behaviors in\nspecific tasks. While IL has gained prominence due to its effectiveness and\nefficiency, traditional methods often focus on datasets collected from experts\nto produce a single efficient policy. Recently, extensions have been proposed\nto handle datasets of diverse behaviors by mainly focusing on learning\ntransition-level diverse policies or on performing entropy maximization at the\ntrajectory level. While these methods may lead to diverse behaviors, they may\nnot be sufficient to reproduce the actual diversity of demonstrations or to\nallow controlled trajectory generation. To overcome these drawbacks, we propose\na different method based on two key features: a) Temporal Consistency that\nensures consistent behaviors across entire episodes and not just at the\ntransition level as well as b) Controllability obtained by constructing a\nlatent space of behaviors that allows users to selectively activate specific\nbehaviors based on their requirements. We compare our approach to\nstate-of-the-art methods over a diverse set of tasks and environments. Project\npage: https://mathieu-petitbois.github.io/projects/swr/",
      "tldr_zh": "本论文针对传统Imitation Learning (IL)方法在处理多样行为数据集时的局限性，提出了一种新的离线学习框架，旨在学习可控的多样行为。该框架的关键特征包括Temporal Consistency，确保行为在整个episode中保持一致，而非仅限于过渡级别，以及Controllability，通过构建行为潜在空间允许用户根据需求选择性地激活特定行为。与最先进方法相比，该方法在多种任务和环境中表现出色，能够更好地再现演示的实际多样性和实现可控轨迹生成。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Generative Models for Robot Learning Workshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18160v1",
      "published_date": "2025-04-25 08:16:56 UTC",
      "updated_date": "2025-04-25 08:16:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:45:43.749528"
    },
    {
      "arxiv_id": "2504.18142v1",
      "title": "EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)",
      "title_zh": "翻译失败",
      "authors": [
        "Fida Ullah",
        "Muhammad Ahmad",
        "Muhammad Tayyab Zamir",
        "Muhammad Arif",
        "Grigori sidorov",
        "Edgardo Manuel Felipe Riverón",
        "Alexander Gelbukh"
      ],
      "abstract": "Named Entity Recognition (NER) plays a pivotal role in various Natural\nLanguage Processing (NLP) tasks by identifying and classifying named entities\n(NEs) from unstructured data into predefined categories such as person,\norganization, location, date, and time. While extensive research exists for\nhigh-resource languages and general domains, NER in Urdu particularly within\ndomain-specific contexts like education remains significantly underexplored.\nThis is Due to lack of annotated datasets for educational content which limits\nthe ability of existing models to accurately identify entities such as academic\nroles, course names, and institutional terms, underscoring the urgent need for\ntargeted resources in this domain. To the best of our knowledge, no dataset\nexists in the domain of the Urdu language for this purpose. To achieve this\nobjective this study makes three key contributions. Firstly, we created a\nmanually annotated dataset in the education domain, named EDU-NER-2025, which\ncontains 13 unique most important entities related to education domain. Second,\nwe describe our annotation process and guidelines in detail and discuss the\nchallenges of labelling EDU-NER-2025 dataset. Third, we addressed and analyzed\nkey linguistic challenges, such as morphological complexity and ambiguity,\nwhich are prevalent in formal Urdu texts.",
      "tldr_zh": "本研究针对Urdu语言在教育领域的Named Entity Recognition (NER)研究不足，特别强调了缺乏标注数据集的问题，旨在识别教育文本中的实体如学术角色、课程名称和机构术语。研究的主要贡献包括创建了名为EDU-NER-2025的手动标注数据集，该数据集包含13个与教育相关的独特实体，并详细描述了标注过程和指南。利用XLM-RoBERTa模型结合X (formerly Twitter)数据，研究者分析了Urdu语言的关键挑战，如形态复杂性和歧义，从而为Urdu教育领域的NER任务提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18142v1",
      "published_date": "2025-04-25 07:50:58 UTC",
      "updated_date": "2025-04-25 07:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:45:56.079158"
    },
    {
      "arxiv_id": "2504.18114v1",
      "title": "Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Atharva Kulkarni",
        "Yuan Zhang",
        "Joel Ruben Antony Moniz",
        "Xiou Ge",
        "Bo-Hsiang Tseng",
        "Dhivya Piraviperumal",
        "Swabha Swayamdipta",
        "Hong Yu"
      ],
      "abstract": "Hallucinations pose a significant obstacle to the reliability and widespread\nadoption of language models, yet their accurate measurement remains a\npersistent challenge. While many task- and domain-specific metrics have been\nproposed to assess faithfulness and factuality concerns, the robustness and\ngeneralization of these metrics are still untested. In this paper, we conduct a\nlarge-scale empirical evaluation of 6 diverse sets of hallucination detection\nmetrics across 4 datasets, 37 language models from 5 families, and 5 decoding\nmethods. Our extensive investigation reveals concerning gaps in current\nhallucination evaluation: metrics often fail to align with human judgments,\ntake an overtly myopic view of the problem, and show inconsistent gains with\nparameter scaling. Encouragingly, LLM-based evaluation, particularly with\nGPT-4, yields the best overall results, and mode-seeking decoding methods seem\nto reduce hallucinations, especially in knowledge-grounded settings. These\nfindings underscore the need for more robust metrics to understand and quantify\nhallucinations, and better strategies to mitigate them.",
      "tldr_zh": "本文评估了幻觉（hallucinations）检测指标的鲁棒性和泛化性，通过大规模实证研究，涵盖6组指标、4个数据集、37个语言模型（来自5个家族）和5种解码方法。结果显示，这些指标常与人类判断不一致、过于短视，且参数缩放带来的收益不稳定。积极发现包括基于LLM的评估（如GPT-4）表现出最佳效果，以及寻求模式（mode-seeking）的解码方法能在知识基础场景中有效减少幻觉。这些发现突出了开发更可靠的指标和缓解策略的迫切需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18114v1",
      "published_date": "2025-04-25 06:37:29 UTC",
      "updated_date": "2025-04-25 06:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:46:09.250461"
    },
    {
      "arxiv_id": "2504.18113v1",
      "title": "Learning from Less: SINDy Surrogates in RL",
      "title_zh": "翻译失败",
      "authors": [
        "Aniket Dixit",
        "Muhammad Ibrahim Khan",
        "Faizan Ahmed",
        "James Brusey"
      ],
      "abstract": "This paper introduces an approach for developing surrogate environments in\nreinforcement learning (RL) using the Sparse Identification of Nonlinear\nDynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach\nthrough extensive experiments in OpenAI Gym environments, particularly Mountain\nCar and Lunar Lander. Our results show that SINDy-based surrogate models can\naccurately capture the underlying dynamics of these environments while reducing\ncomputational costs by 20-35%. With only 75 interactions for Mountain Car and\n1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with\nmean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06\nfor LunarLander position. RL agents trained in these surrogate environments\nrequire fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs.\n1,000,000 for Lunar Lander) while achieving comparable performance to those\ntrained in the original environments, exhibiting similar convergence patterns\nand final performance metrics. This work contributes to the field of\nmodel-based RL by providing an efficient method for generating accurate,\ninterpretable surrogate environments.",
      "tldr_zh": "本论文提出了一种使用Sparse Identification of Nonlinear Dynamics (SINDy)算法在强化学习 (RL) 中开发代理环境的方法，以减少计算资源需求。实验在OpenAI Gym的Mountain Car和Lunar Lander环境中进行，结果显示SINDy-based代理模型能准确捕捉底层动态，降低20-35%的计算成本，并在少量交互（Mountain Car 75次、Lunar Lander 1000次）下实现高状态相关性（超过0.997）和低均方误差（如Mountain Car速度3.11e-06）。这种方法使RL代理在代理环境中训练所需步骤显著减少（Mountain Car 65,075 vs. 100,000步；Lunar Lander 801,000 vs. 1,000,000步），同时保持与原环境相当的性能，为model-based RL提供了高效、可解释的代理环境生成方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "World Models @ ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18113v1",
      "published_date": "2025-04-25 06:34:19 UTC",
      "updated_date": "2025-04-25 06:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:46:21.331370"
    },
    {
      "arxiv_id": "2505.01273v1",
      "title": "Anti-adversarial Learning: Desensitizing Prompts for Large Language Models",
      "title_zh": "反对抗学习：针对",
      "authors": [
        "Xuan Li",
        "Zhe Yin",
        "Xiaodong Gu",
        "Beijun Shen"
      ],
      "abstract": "With the widespread use of LLMs, preserving privacy in user prompts has\nbecome crucial, as prompts risk exposing privacy and sensitive data to the\ncloud LLMs. Traditional techniques like homomorphic encryption, secure\nmulti-party computation, and federated learning face challenges due to heavy\ncomputational costs and user participation requirements, limiting their\napplicability in LLM scenarios. In this paper, we propose PromptObfus, a novel\nmethod for desensitizing LLM prompts. The core idea of PromptObfus is\n\"anti-adversarial\" learning, which perturbs privacy words in the prompt to\nobscure sensitive information while retaining the stability of model\npredictions. Specifically, PromptObfus frames prompt desensitization as a\nmasked language modeling task, replacing privacy-sensitive terms with a [MASK]\ntoken. A desensitization model is trained to generate candidate replacements\nfor each masked position. These candidates are subsequently selected based on\ngradient feedback from a surrogate model, ensuring minimal disruption to the\ntask output. We demonstrate the effectiveness of our approach on three NLP\ntasks. Results show that PromptObfus effectively prevents privacy inference\nfrom remote LLMs while preserving task performance.",
      "tldr_zh": "这篇论文提出 PromptObfus，一种基于 anti-adversarial learning 的方法，用于脱敏大型语言模型(LLMs)的用户提示，旨在保护隐私敏感信息免于暴露，同时保持模型预测的稳定性。具体而言，该方法将隐私词替换为 [MASK] 标记，并通过训练一个脱敏模型生成候选替换词，再利用代理模型的梯度反馈选择最优候选，以最小化对任务输出的影响。实验结果显示，在三个 NLP 任务上，PromptObfus 有效防止了隐私推断，同时基本保留了任务性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.01273v1",
      "published_date": "2025-04-25 06:19:02 UTC",
      "updated_date": "2025-04-25 06:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:46:32.119611"
    },
    {
      "arxiv_id": "2504.18104v1",
      "title": "Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Yinglong Yu",
        "Hao Shen",
        "Zhengyi Lyu",
        "Qi He"
      ],
      "abstract": "In response to the growing problem of misinformation in the context of\nglobalization and informatization, this paper proposes a classification method\nfor fact-check-worthiness estimation based on prompt tuning. We construct a\nmodel for fact-check-worthiness estimation at the methodological level using\nprompt tuning. By applying designed prompt templates to large language models,\nwe establish in-context learning and leverage prompt tuning technology to\nimprove the accuracy of determining whether claims have fact-check-worthiness,\nparticularly when dealing with limited or unlabeled data. Through extensive\nexperiments on public datasets, we demonstrate that the proposed method\nsurpasses or matches multiple baseline methods in the classification task of\nfact-check-worthiness estimation assessment, including classical pre-trained\nmodels such as BERT, as well as recent popular large models like GPT-3.5 and\nGPT-4. Experiments show that the prompt tuning-based method proposed in this\nstudy exhibits certain advantages in evaluation metrics such as F1 score and\naccuracy, thereby effectively validating its effectiveness and advancement in\nthe task of fact-check-worthiness estimation.",
      "tldr_zh": "本研究针对全球化背景下 misinformation 问题，提出了一种基于 prompt tuning 的 fact-check-worthiness estimation 分类方法，利用大型语言模型通过设计 prompt templates 实现 in-context learning，从而提升对声明是否值得事实检查的准确性，尤其适用于数据有限或无标签场景。实验在公共数据集上表明，该方法在 F1 score 和 accuracy 等指标上优于或匹配多个基线模型，包括 BERT、GPT-3.5 和 GPT-4。总体而言，此方法验证了 prompt tuning 在 fact-check-worthiness estimation 任务中的有效性和先进性，为 misinformation 检测提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18104v1",
      "published_date": "2025-04-25 06:16:41 UTC",
      "updated_date": "2025-04-25 06:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:46:44.413007"
    },
    {
      "arxiv_id": "2504.18096v1",
      "title": "Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Li",
        "Haixu Ma",
        "Guanyong Wu",
        "Shi Mu",
        "Chen Li",
        "Shunpan Liang"
      ],
      "abstract": "Medication recommendation is crucial in healthcare, offering effective\ntreatments based on patient's electronic health records (EHR). Previous studies\nshow that integrating more medication-related knowledge improves medication\nrepresentation accuracy. However, not all medications encompass multiple types\nof knowledge data simultaneously. For instance, some medications provide only\ntextual descriptions without structured data. This imbalance in data\navailability limits the performance of existing models, a challenge we term the\n\"bucket effect\" in medication recommendation. Our data analysis uncovers the\nseverity of the \"bucket effect\" in medication recommendation. To fill this gap,\nwe introduce a cross-modal medication encoder capable of seamlessly aligning\ndata from different modalities and propose a medication recommendation\nframework to integrate Multiple types of Knowledge, named MKMed. Specifically,\nwe first pre-train a cross-modal encoder with contrastive learning on five\nknowledge modalities, aligning them into a unified space. Then, we combine the\nmulti-knowledge medication representations with patient records for\nrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasets\ndemonstrate that MKMed mitigates the \"bucket effect\" in data, and significantly\noutperforms state-of-the-art baselines in recommendation accuracy and safety.",
      "tldr_zh": "该论文针对药物推荐中的“bucket effect”问题（即药物知识数据不平衡，导致模型性能受限），通过数据分析揭示了其严重性，并提出 MKMed 框架来整合多种知识模态。具体地，研究团队开发了跨模态药物编码器，使用对比学习在五种知识模态上预训练，将数据对齐到统一空间，然后将多知识药物表示与患者电子健康记录（EHR）结合进行推荐。在 MIMIC-III 和 MIMIC-IV 数据集上的实验表明，MKMed 有效缓解了“bucket effect”，并在推荐准确性和安全性方面显著优于现有基线模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18096v1",
      "published_date": "2025-04-25 05:47:15 UTC",
      "updated_date": "2025-04-25 05:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:46:56.969348"
    },
    {
      "arxiv_id": "2504.18085v1",
      "title": "Random-Set Large Language Models",
      "title_zh": "随机集大型语言模型",
      "authors": [
        "Muhammad Mubashar",
        "Shireen Kudukkil Manchingal",
        "Fabio Cuzzolin"
      ],
      "abstract": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating.",
      "tldr_zh": "该论文探讨了Large Language Models (LLMs)生成文本的不确定性量化问题，提出Random-Set Large Language Models (RSLLM)方法，该方法通过预测token空间的有限随机集（belief functions）来取代传统的概率向量，从而更好地编码认识论不确定性（epistemic uncertainty）。\n为了实现高效，RSLLM 采用hierarchical clustering提取和管理一个预算的“focal”子集，使预测过程可扩展且有效。\n实验在CoQA和OBQA数据集上使用Llama2-7b、Mistral-7b和Phi-2模型进行评估，结果显示RSLLM在答案正确率上优于标准模型，同时具备估计二级不确定性和检测幻觉的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18085v1",
      "published_date": "2025-04-25 05:25:27 UTC",
      "updated_date": "2025-04-25 05:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:47:08.245981"
    },
    {
      "arxiv_id": "2504.18082v1",
      "title": "Efficient GNN Training Through Structure-Aware Randomized Mini-Batching",
      "title_zh": "翻译失败",
      "authors": [
        "Vignesh Balaji",
        "Christos Kozyrakis",
        "Gal Chechik",
        "Haggai Maron"
      ],
      "abstract": "Graph Neural Networks (GNNs) enable learning on realworld graphs and\nmini-batch training has emerged as the de facto standard for training GNNs\nbecause it can scale to very large graphs and improve convergence. Current\nmini-batch construction policies largely ignore efficiency considerations of\nGNN training. Specifically, existing mini-batching techniques employ\nrandomization schemes to improve accuracy and convergence. However, these\nrandomization schemes are often agnostic to the structural properties of the\ngraph (for eg. community structure), resulting in highly irregular memory\naccess patterns during GNN training that make suboptimal use of on-chip GPU\ncaches. On the other hand, while deterministic mini-batching based solely on\ngraph structure delivers fast runtime performance, the lack of randomness\ncompromises both the final model accuracy and training convergence speed. In\nthis paper, we present Community-structure-aware Randomized Mini-batching\n(COMM-RAND), a novel methodology that bridges the gap between the above\nextremes. COMM-RAND allows practitioners to explore the space between pure\nrandomness and pure graph structural awareness during mini-batch construction,\nleading to significantly more efficient GNN training with similar accuracy. We\nevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RAND\ncuts down GNN training time by up to 2.76x (1.8x on average) while achieving an\naccuracy that is within 1.79% points (0.42% on average) compared to popular\nrandom mini-batching approaches.",
      "tldr_zh": "该研究针对 Graph Neural Networks (GNNs) 的 mini-batch 训练问题，指出现有随机化方案忽略了图的结构属性（如社区结构），导致 GPU 缓存利用率低下和训练效率低下。论文提出 Community-structure-aware Randomized Mini-batching (COMM-RAND) 方法，该方法在随机性和图结构意识之间实现平衡，通过考虑社区结构来优化 mini-batch 构建，从而提高训练效率。实验结果显示，在四个图学习基准上，COMM-RAND 将 GNN 训练时间减少高达 2.76 倍（平均 1.8 倍），同时准确性仅比传统随机方法低 1.79%（平均 0.42%）。这为高效的 GNN 训练提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18082v1",
      "published_date": "2025-04-25 05:16:53 UTC",
      "updated_date": "2025-04-25 05:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:47:20.555760"
    },
    {
      "arxiv_id": "2504.18080v1",
      "title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization",
      "title_zh": "通过持续预训练和推理偏好优化稳定医疗大语言模型中的推理",
      "authors": [
        "Wataru Kawakami",
        "Keita Suzuki",
        "Junichiro Iwasawa"
      ],
      "abstract": "Large Language Models (LLMs) show potential in medicine, yet clinical\nadoption is hindered by concerns over factual accuracy, language-specific\nlimitations (e.g., Japanese), and critically, their reliability when required\nto generate reasoning explanations -- a prerequisite for trust. This paper\nintroduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the\nJapanese medical domain to achieve both high accuracy and stable reasoning. We\nemploy a two-stage fine-tuning process on the Qwen2.5-72B base model: first,\nContinued Pretraining (CPT) on a comprehensive Japanese medical corpus instills\ndeep domain knowledge. Second, Reasoning Preference Optimization (RPO), a\npreference-based method, enhances the generation of reliable reasoning pathways\nwhile preserving high answer accuracy. Evaluations on the Japanese Medical\nLicensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves\nstate-of-the-art performance (0.868 accuracy), surpassing strong proprietary\nmodels like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which\nexhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively\non IgakuQA) when prompted for explanations, our model maintains its high\naccuracy (0.868) under such conditions. This highlights RPO's effectiveness in\nstabilizing reasoning generation. This work underscores the importance of\noptimizing for reliable explanations alongside accuracy. We release the\nPreferred-MedLLM-Qwen-72B model weights to foster research into trustworthy\nLLMs for specialized, high-stakes applications.",
      "tldr_zh": "这篇论文针对医疗大语言模型（LLMs）的推理稳定性问题，引入了 Preferred-MedLLM-Qwen-72B 模型，以实现高准确性和可靠的推理生成。研究采用两阶段微调方法：首先通过 Continued Pretraining (CPT) 在日语医疗语料上进行持续预训练，以增强领域知识；其次，使用 Reasoning Preference Optimization (RPO) 优化推理路径，同时保持答案准确性。在 IgakuQA 日语医疗执照考试基准上，该模型达到最先进性能（准确率 0.868），优于 GPT-4o（0.866），并在要求提供解释时避免了基线模型的显著准确率下降（基线下降 11.5%）。这项工作强调了优化可靠解释与准确性的重要性，并开源模型权重以促进可信赖 LLMs 在高风险领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18080v1",
      "published_date": "2025-04-25 05:15:31 UTC",
      "updated_date": "2025-04-25 05:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:47:33.451287"
    },
    {
      "arxiv_id": "2504.18078v2",
      "title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity",
      "title_zh": "隐私保护个性化联邦",
      "authors": [
        "Xiaolu Chen",
        "Chenghao Huang",
        "Yanru Zhang",
        "Hao Wang"
      ],
      "abstract": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods.",
      "tldr_zh": "分布式光伏（PV）系统的快速扩张导致能源管理和电网操作面临挑战，特别是由于统计异质性（statistical heterogeneity）带来的 PV 分解困难，该研究提出了一种隐私保护的 Personalized Federated Learning (PFL) 框架来解决这一问题。该框架采用两级设计：在本地级，使用基于 Transformer 的 PV 分解模型生成太阳能辐照度嵌入（solar irradiance embeddings），并引入新型自适应本地聚合机制（adaptive local aggregation mechanism）来缓解异质性影响；在全局级，中央服务器聚合多个数据中心的隐私保护信息，实现知识共享。实验结果显示，该框架在真实数据上比基准方法显著提高了准确性和鲁棒性，为隐私友好型分布式 PV 管理提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.18078v2",
      "published_date": "2025-04-25 05:09:27 UTC",
      "updated_date": "2025-05-22 06:55:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:47:44.478365"
    },
    {
      "arxiv_id": "2504.18070v1",
      "title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths",
      "title_zh": "PropRAG：通过束搜索在命题路径上引导检索",
      "authors": [
        "Jingjin Wang"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has become the standard non-parametric\napproach for equipping Large Language Models (LLMs) with up-to-date knowledge\nand mitigating catastrophic forgetting common in continual learning. However,\nstandard RAG, relying on independent passage retrieval, fails to capture the\ninterconnected nature of human memory crucial for complex reasoning\n(associativity) and contextual understanding (sense-making). While structured\nRAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples,\nthe inherent context loss limits fidelity. We introduce PropRAG, a framework\nleveraging contextually rich propositions and a novel beam search algorithm\nover proposition paths to explicitly discover multi-step reasoning chains.\nCrucially, PropRAG's online retrieval process operates entirely without\ninvoking generative LLMs, relying instead on efficient graph traversal and\npre-computed embeddings. This avoids online LLM inference costs and potential\ninconsistencies during evidence gathering. LLMs are used effectively offline\nfor high-quality proposition extraction and post-retrieval for answer\ngeneration. PropRAG achieves state-of-the-art zero-shot Recall@5 results on\nPopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside\ntop F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through\nricher representation and explicit, LLM-free online path finding, PropRAG\nadvances non-parametric continual learning.",
      "tldr_zh": "本研究提出 PropRAG 框架，通过利用上下文丰富的命题（propositions）和 beam search 算法在命题路径上进行搜索，来指导 Retrieval Augmented Generation (RAG) 的检索过程，从而捕捉人类记忆的关联性和上下文理解，避免了标准 RAG 的局限性。PropRAG 的在线检索依赖高效的图遍历和预计算的 embeddings，而非调用生成式 Large Language Models (LLMs)，从而减少了计算成本和潜在不一致性；LLMs 只在离线提取命题和检索后生成答案时使用。该框架在多个基准测试中取得了 state-of-the-art 性能，包括 PopQA 的零样本 Recall@5 为 55.3%、HotpotQA 为 97.0% 及 MuSiQue 的 F1 分数为 52.4%，从而提升了非参数连续学习（non-parametric continual learning）的证据检索和推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data to be released at:\n  https://github.com/ReLink-Inc/PropRAG",
      "pdf_url": "http://arxiv.org/pdf/2504.18070v1",
      "published_date": "2025-04-25 04:47:34 UTC",
      "updated_date": "2025-04-25 04:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:47:57.171159"
    },
    {
      "arxiv_id": "2504.18068v1",
      "title": "S3MOT: Monocular 3D Object Tracking with Selective State Space Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuohao Yan",
        "Shaoquan Feng",
        "Xingxing Li",
        "Yuxuan Zhou",
        "Chunxi Xia",
        "Shengyu Li"
      ],
      "abstract": "Accurate and reliable multi-object tracking (MOT) in 3D space is essential\nfor advancing robotics and computer vision applications. However, it remains a\nsignificant challenge in monocular setups due to the difficulty of mining 3D\nspatiotemporal associations from 2D video streams. In this work, we present\nthree innovative techniques to enhance the fusion and exploitation of\nheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian State\nSpace Model (HSSM), a novel data association mechanism that compresses\ncontextual tracking cues across multiple paths, enabling efficient and\ncomprehensive assignment decisions with linear complexity. HSSM features a\nglobal receptive field and dynamic weights, in contrast to traditional linear\nassignment algorithms that rely on hand-crafted association costs. (2) We\npropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROI\npooling by directly using dense feature maps for contrastive learning, thus\nimproving object re-identification accuracy under challenging conditions such\nas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimation\nthrough VeloSSM, an encoder-decoder architecture that models temporal\ndependencies in velocity to capture motion dynamics, overcoming the limitations\nof frame-based 3D inference. Experiments on the KITTI public test benchmark\ndemonstrate the effectiveness of our method, achieving a new state-of-the-art\nperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous best\nby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustness\nand efficiency for monocular 3D MOT tasks. The code and models are available at\nhttps://github.com/bytepioneerX/s3mot.",
      "tldr_zh": "本研究提出S3MOT，一种用于单目3D物体跟踪(Monocular 3D MOT)的框架，旨在通过融合异构线索解决从2D视频流中挖掘3D时空关联的挑战。论文引入三个创新技术：Hungarian State Space Model (HSSM)作为高效的数据关联机制，支持全局感受野和动态权重；Fully Convolutional One-stage Embedding (FCOE)通过密集特征图进行对比学习，提升物体再识别准确性；以及VeloSSM，一个编码器-解码器架构，用于建模速度中的时间依赖性以改善6-DoF姿态估计。在KITTI基准测试中，该方法实现了76.86 HOTA的最新最先进性能（31 FPS），比之前最佳模型提高了+2.63 HOTA和+3.62 AssA，展示了其鲁棒性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18068v1",
      "published_date": "2025-04-25 04:45:35 UTC",
      "updated_date": "2025-04-25 04:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:48:09.291375"
    },
    {
      "arxiv_id": "2504.18062v2",
      "title": "LLM-hRIC: LLM-empowered Hierarchical RAN Intelligent Control for O-RAN",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyan Bao",
        "Sinwoong Yun",
        "Jemin Lee",
        "Tony Q. S. Quek"
      ],
      "abstract": "Despite recent advances in applying large language models (LLMs) and machine\nlearning (ML) techniques to open radio access network (O-RAN), critical\nchallenges remain, such as insufficient cooperation between radio access\nnetwork (RAN) intelligent controllers (RICs), high computational demands\nhindering real-time decisions, and the lack of domain-specific finetuning.\nTherefore, this article introduces the LLM-empowered hierarchical RIC\n(LLM-hRIC) framework to improve the collaboration between RICs in O-RAN. The\nLLM-empowered non-real-time RIC (non-RT RIC) acts as a guider, offering a\nstrategic guidance to the near-real-time RIC (near-RT RIC) using global network\ninformation. The RL-empowered near-RT RIC acts as an implementer, combining\nthis guidance with local real-time data to make near-RT decisions. We evaluate\nthe feasibility and performance of the LLM-hRIC framework in an integrated\naccess and backhaul (IAB) network setting, and finally, discuss the open\nchallenges of the LLM-hRIC framework for O-RAN.",
      "tldr_zh": "本研究提出LLM-hRIC框架，利用LLM（Large Language Models）增强O-RAN（Open Radio Access Network）中的分层RAN智能控制（RAN Intelligent Control），以解决RICs（RAN Intelligent Controllers）之间合作不足、高计算需求和缺乏领域特定微调等挑战。框架中，LLM-empowered non-RT RIC作为引导者，提供基于全局网络信息的战略指导，而RL-empowered near-RT RIC作为执行者，结合该指导与本地实时数据进行近实时决策。在IAB（Integrated Access and Backhaul）网络环境中评估显示，该框架可行且性能提升显著，并讨论了其在O-RAN中的开放挑战。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18062v2",
      "published_date": "2025-04-25 04:18:23 UTC",
      "updated_date": "2025-05-20 07:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:48:20.933526"
    },
    {
      "arxiv_id": "2504.18058v1",
      "title": "Exploring Personality-Aware Interactions in Salesperson Dialogue Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Sijia Cheng",
        "Wen-Yu Chang",
        "Yun-Nung Chen"
      ],
      "abstract": "The integration of dialogue agents into the sales domain requires a deep\nunderstanding of how these systems interact with users possessing diverse\npersonas. This study explores the influence of user personas, defined using the\nMyers-Briggs Type Indicator (MBTI), on the interaction quality and performance\nof sales-oriented dialogue agents. Through large-scale testing and analysis, we\nassess the pre-trained agent's effectiveness, adaptability, and personalization\ncapabilities across a wide range of MBTI-defined user types. Our findings\nreveal significant patterns in interaction dynamics, task completion rates, and\ndialogue naturalness, underscoring the future potential for dialogue agents to\nrefine their strategies to better align with varying personality traits. This\nwork not only provides actionable insights for building more adaptive and\nuser-centric conversational systems in the sales domain but also contributes\nbroadly to the field by releasing persona-defined user simulators. These\nsimulators, unconstrained by domain, offer valuable tools for future research\nand demonstrate the potential for scaling personalized dialogue systems across\ndiverse applications.",
      "tldr_zh": "这篇论文探讨了基于 Myers-Briggs Type Indicator (MBTI) 定义的用户人格对销售对话代理互动的影响，通过大规模测试评估代理的有效性、适应性和个性化能力。研究发现，不同人格类型会导致交互动态、任务完成率和对话自然性上的显著差异，强调代理需优化策略以更好地适应用户个性。论文贡献了构建更用户中心化销售对话系统的实用见解，并发布了不受领域限制的 MBTI 用户模拟器，作为未来研究和个性化对话系统扩展的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IWSDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18058v1",
      "published_date": "2025-04-25 04:10:25 UTC",
      "updated_date": "2025-04-25 04:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:48:31.933255"
    },
    {
      "arxiv_id": "2504.18057v1",
      "title": "Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization",
      "title_zh": "机会主义协作规划：利用大型视觉模型引导控制和联合查询-服务优化",
      "authors": [
        "Jiayi Chen",
        "Shuai Wang",
        "Guoliang Li",
        "Wei Xu",
        "Guangxu Zhu",
        "Derrick Wing Kwan Ng",
        "Chengzhong Xu"
      ],
      "abstract": "Navigating autonomous vehicles in open scenarios is a challenge due to the\ndifficulties in handling unseen objects. Existing solutions either rely on\nsmall models that struggle with generalization or large models that are\nresource-intensive. While collaboration between the two offers a promising\nsolution, the key challenge is deciding when and how to engage the large model.\nTo address this issue, this paper proposes opportunistic collaborative planning\n(OCP), which seamlessly integrates efficient local models with powerful cloud\nmodels through two key innovations. First, we propose large vision model guided\nmodel predictive control (LVM-MPC), which leverages the cloud for LVM\nperception and decision making. The cloud output serves as a global guidance\nfor a local MPC, thereby forming a closed-loop perception-to-control system.\nSecond, to determine the best timing for large model query and service, we\npropose collaboration timing optimization (CTO), including object detection\nconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decide\nwhen to seek cloud assistance and when to offer cloud service. Extensive\nexperiments show that the proposed OCP outperforms existing methods in terms of\nboth navigation time and success rate.",
      "tldr_zh": "这篇论文针对自主车辆在开放场景中处理未知对象的挑战，提出了Opportunistic Collaborative Planning (OCP)框架，将高效本地模型与强大云模型相结合，以实现资源优化和性能提升。OCP 的关键创新包括Large Vision Model Guided Model Predictive Control (LVM-MPC)，利用云端进行感知和决策，提供全局指导形成闭环系统；以及Collaboration Timing Optimization (CTO)，通过Object Detection Confidence Thresholding (ODCT)和Cloud Forward Simulation (CFS)来决定最佳查询和服务时机。实验结果显示，OCP 在导航时间和成功率上均优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18057v1",
      "published_date": "2025-04-25 04:07:21 UTC",
      "updated_date": "2025-04-25 04:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:48:44.682972"
    },
    {
      "arxiv_id": "2504.20077v1",
      "title": "Edge-Based Learning for Improved Classification Under Adversarial Noise",
      "title_zh": "翻译失败",
      "authors": [
        "Manish Kansana",
        "Keyan Alexander Rahimi",
        "Elias Hossain",
        "Iman Dehzangi",
        "Noorbakhsh Amiri Golilarz"
      ],
      "abstract": "Adversarial noise introduces small perturbations in images, misleading deep\nlearning models into misclassification and significantly impacting recognition\naccuracy. In this study, we analyzed the effects of Fast Gradient Sign Method\n(FGSM) adversarial noise on image classification and investigated whether\ntraining on specific image features can improve robustness. We hypothesize that\nwhile adversarial noise perturbs various regions of an image, edges may remain\nrelatively stable and provide essential structural information for\nclassification. To test this, we conducted a series of experiments using brain\ntumor and COVID datasets. Initially, we trained the models on clean images and\nthen introduced subtle adversarial perturbations, which caused deep learning\nmodels to significantly misclassify the images. Retraining on a combination of\nclean and noisy images led to improved performance. To evaluate the robustness\nof the edge features, we extracted edges from the original/clean images and\ntrained the models exclusively on edge-based representations. When noise was\nintroduced to the images, the edge-based models demonstrated greater resilience\nto adversarial attacks compared to those trained on the original or clean\nimages. These results suggest that while adversarial noise is able to exploit\ncomplex non-edge regions significantly more than edges, the improvement in the\naccuracy after retraining is marginally more in the original data as compared\nto the edges. Thus, leveraging edge-based learning can improve the resilience\nof deep learning models against adversarial perturbations.",
      "tldr_zh": "本文研究了 FGSM adversarial noise 对图像分类的影响，假设边缘特征相对稳定且能提供关键结构信息，从而提升模型鲁棒性。通过在脑肿瘤和 COVID 数据集上实验，作者先训练模型于干净图像，然后引入对抗扰动并重新训练；结果显示，基于边缘特征的模型在面对噪声时表现出更高的抗性。总体而言，该方法证明了 edge-based learning 可以有效改善深度学习模型对 adversarial perturbations 的抵抗力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20077v1",
      "published_date": "2025-04-25 04:04:59 UTC",
      "updated_date": "2025-04-25 04:04:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:48:55.563383"
    },
    {
      "arxiv_id": "2504.18050v1",
      "title": "Validating Network Protocol Parsers with Traceable RFC Document Interpretation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingwei Zheng",
        "Danning Xie",
        "Qingkai Shi",
        "Chengpeng Wang",
        "Xiangyu Zhang"
      ],
      "abstract": "Validating the correctness of network protocol implementations is highly\nchallenging due to the oracle and traceability problems. The former determines\nwhen a protocol implementation can be considered buggy, especially when the\nbugs do not cause any observable symptoms. The latter allows developers to\nunderstand how an implementation violates the protocol specification, thereby\nfacilitating bug fixes. Unlike existing works that rarely take both problems\ninto account, this work considers both and provides an effective solution using\nrecent advances in large language models (LLMs). Our key observation is that\nnetwork protocols are often released with structured specification documents,\na.k.a. RFC documents, which can be systematically translated to formal protocol\nmessage specifications via LLMs. Such specifications, which may contain errors\ndue to the hallucination of LLMs, are used as a quasi-oracle to validate\nprotocol parsers, while the validation results in return gradually refine the\noracle. Since the oracle is derived from the document, any bugs we find in a\nprotocol implementation can be traced back to the document, thus addressing the\ntraceability problem. We have extensively evaluated our approach using nine\nnetwork protocols and their implementations written in C, Python, and Go. The\nresults show that our approach outperforms the state-of-the-art and has\ndetected 69 bugs, with 36 confirmed. The project also demonstrates the\npotential for fully automating software validation based on natural language\nspecifications, a process previously considered predominantly manual due to the\nneed to understand specification documents and derive expected outputs for test\ninputs.",
      "tldr_zh": "该研究针对网络协议解析器的验证难题，提出了一种结合大型语言模型(LLMs)的解决方案，以解决 oracle problem（确定实现是否出错）和traceability problem（追踪违反规范的原因）。方法通过LLMs将结构化的RFC documents翻译成正式的协议消息规范，作为quasi-oracle来验证解析器，同时通过迭代反馈逐步改进规范，确保bug可追溯到原始文档。实验在9个网络协议（使用C、Python和Go实现）的测试中，检测出69个bug（其中36个已确认），并优于现有方法，展示了基于自然语言规范实现软件验证自动化的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18050v1",
      "published_date": "2025-04-25 03:39:19 UTC",
      "updated_date": "2025-04-25 03:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:49:07.854510"
    },
    {
      "arxiv_id": "2504.18049v1",
      "title": "A BERT-Style Self-Supervised Learning CNN for Disease Identification from Retinal Images",
      "title_zh": "一种 BERT 风格的自监督学习 CNN，用于从视网膜图像中识别疾病",
      "authors": [
        "Xin Li",
        "Wenhui Zhu",
        "Peijie Qiu",
        "Oana M. Dumitrascu",
        "Amal Youssef",
        "Yalin Wang"
      ],
      "abstract": "In the field of medical imaging, the advent of deep learning, especially the\napplication of convolutional neural networks (CNNs) has revolutionized the\nanalysis and interpretation of medical images. Nevertheless, deep learning\nmethods usually rely on large amounts of labeled data. In medical imaging\nresearch, the acquisition of high-quality labels is both expensive and\ndifficult. The introduction of Vision Transformers (ViT) and self-supervised\nlearning provides a pre-training strategy that utilizes abundant unlabeled\ndata, effectively alleviating the label acquisition challenge while broadening\nthe breadth of data utilization. However, ViT's high computational density and\nsubstantial demand for computing power, coupled with the lack of localization\ncharacteristics of its operations on image patches, limit its efficiency and\napplicability in many application scenarios. In this study, we employ\nnn-MobileNet, a lightweight CNN framework, to implement a BERT-style\nself-supervised learning approach. We pre-train the network on the unlabeled\nretinal fundus images from the UK Biobank to improve downstream application\nperformance. We validate the results of the pre-trained model on Alzheimer's\ndisease (AD), Parkinson's disease (PD), and various retinal diseases\nidentification. The results show that our approach can significantly improve\nperformance in the downstream tasks. In summary, this study combines the\nbenefits of CNNs with the capabilities of advanced self-supervised learning in\nhandling large-scale unlabeled data, demonstrating the potential of CNNs in the\npresence of label scarcity.",
      "tldr_zh": "本文提出了一种基于 nn-MobileNet 的轻量级 CNN 框架，采用 BERT-style self-supervised learning 方法，旨在解决医疗图像分析中标签数据稀缺的问题。该模型在 UK Biobank 的未标注视网膜眼底图像上进行预训练，并应用于 Alzheimer’s disease (AD)、Parkinson’s disease (PD) 和各种视网膜疾病的识别任务。实验结果显示，该方法显著提升了下游任务的性能，证明了 CNN 在结合 self-supervised learning 时的高效性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18049v1",
      "published_date": "2025-04-25 03:38:55 UTC",
      "updated_date": "2025-04-25 03:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:49:20.428084"
    },
    {
      "arxiv_id": "2504.18046v1",
      "title": "DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification",
      "title_zh": "DMS-Net：双模态多尺度孪生",
      "authors": [
        "Guohao Huo",
        "Zibo Lin",
        "Zitong Wang",
        "Ruiting Dai",
        "Hao Tang"
      ],
      "abstract": "Ophthalmic diseases pose a significant global health challenge, yet\ntraditional diagnosis methods and existing single-eye deep learning approaches\noften fail to account for binocular pathological correlations. To address this,\nwe propose DMS-Net, a dual-modal multi-scale Siamese network for binocular\nfundus image classification. Our framework leverages weight-shared Siamese\nResNet-152 backbones to extract deep semantic features from paired fundus\nimages. To tackle challenges such as lesion boundary ambiguity and scattered\npathological distributions, we introduce a Multi-Scale Context-Aware Module\n(MSCAM) that integrates adaptive pooling and attention mechanisms for\nmulti-resolution feature aggregation. Additionally, a Dual-Modal Feature Fusion\n(DMFF) module enhances cross-modal interaction through spatial-semantic\nrecalibration and bidirectional attention, effectively combining global context\nand local edge features. Evaluated on the ODIR-5K dataset, DMS-Net achieves\nstate-of-the-art performance with 80.5% accuracy, 86.1% recall, and 83.8%\nCohen's kappa, demonstrating superior capability in detecting symmetric\npathologies and advancing clinical decision-making for ocular diseases.",
      "tldr_zh": "本研究针对眼部疾病诊断中传统方法和单眼深度学习忽略双眼病理相关性的问题，提出DMS-Net，一种双模态多尺度Siamese网络，用于双眼眼底图像分类。\nDMS-Net利用共享权重的Siamese ResNet-152骨干网络提取配对眼底图像的深层语义特征，并引入Multi-Scale Context-Aware Module (MSCAM)进行多分辨率特征聚合，以及Dual-Modal Feature Fusion (DMFF)模块通过空间-语义重新校准和双向注意力增强跨模态交互。\n在ODIR-5K数据集上，DMS-Net达到最先进性能，包括80.5%准确率、86.1%召回率和83.8%Cohen's kappa，显著提高了对称病理检测能力并提升了临床决策支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18046v1",
      "published_date": "2025-04-25 03:27:28 UTC",
      "updated_date": "2025-04-25 03:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:49:34.334305"
    },
    {
      "arxiv_id": "2504.18044v1",
      "title": "AI Ethics and Social Norms: Exploring ChatGPT's Capabilities From What to How",
      "title_zh": "AI",
      "authors": [
        "Omid Veisi",
        "Sasan Bahrami",
        "Roman Englert",
        "Claudia Müller"
      ],
      "abstract": "Using LLMs in healthcare, Computer-Supported Cooperative Work, and Social\nComputing requires the examination of ethical and social norms to ensure safe\nincorporation into human life. We conducted a mixed-method study, including an\nonline survey with 111 participants and an interview study with 38 experts, to\ninvestigate the AI ethics and social norms in ChatGPT as everyday life tools.\nThis study aims to evaluate whether ChatGPT in an empirical context operates\nfollowing ethics and social norms, which is critical for understanding actions\nin industrial and academic research and achieving machine ethics. The findings\nof this study provide initial insights into six important aspects of AI ethics,\nincluding bias, trustworthiness, security, toxicology, social norms, and\nethical data. Significant obstacles related to transparency and bias in\nunsupervised data collection methods are identified as ChatGPT's ethical\nconcerns.",
      "tldr_zh": "这篇论文探讨了 ChatGPT 在 AI 伦理和社会规范方面的能力，旨在评估其在医疗、计算机支持合作工作和社会计算等领域的安全整合。研究采用混合方法，包括在线调查（111 名参与者）和专家访谈（38 人），考察了偏见、trustworthiness、安全性、toxicology、社会规范和ethical data 等六个关键方面。结果显示，ChatGPT 存在透明度和偏见在无监督数据收集方法中的显著问题，为机器伦理的实现提供了初步见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for presentation at the ACM Conference on Computer-Supported\n  Cooperative Work and Social Computing (CSCW) 2025. To appear in Proceedings\n  of the ACM on Human-Computer Interaction (PACM HCI)",
      "pdf_url": "http://arxiv.org/pdf/2504.18044v1",
      "published_date": "2025-04-25 03:26:30 UTC",
      "updated_date": "2025-04-25 03:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:49:44.389237"
    },
    {
      "arxiv_id": "2504.18041v1",
      "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bang An",
        "Shiyue Zhang",
        "Mark Dredze"
      ],
      "abstract": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs.",
      "tldr_zh": "该研究分析了Retrieval-Augmented Generation (RAG)框架对Large Language Models (LLMs)的安全性影响，通过比较11个LLMs在RAG和非RAG设置下的表现，发现RAG可能使模型更不安全，并改变了其安全特性。即使将安全模型与安全文档结合，也可能产生不安全输出。现有红队测试方法在RAG环境中效果较差，因此论文呼吁开发针对RAG LLMs的特定安全研究和红队策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.18041v1",
      "published_date": "2025-04-25 03:25:18 UTC",
      "updated_date": "2025-04-25 03:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:49:55.554928"
    },
    {
      "arxiv_id": "2504.18039v2",
      "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Zhang",
        "Nuoqian Xiao",
        "Qi Chai",
        "Deheng Ye",
        "Hao Wang"
      ],
      "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin social deduction games (SDGs) like Werewolf, where strategic reasoning and\nsocial deception are essential. However, current approaches remain limited to\ntextual information, ignoring crucial multimodal cues such as facial\nexpressions and tone of voice that humans naturally use to communicate.\nMoreover, existing SDG agents primarily focus on inferring other players'\nidentities without modeling how others perceive themselves or fellow players.\nTo address these limitations, we use One Night Ultimate Werewolf (ONUW) as a\ntestbed and present MultiMind, the first framework integrating multimodal\ninformation into SDG agents. MultiMind processes facial expressions and vocal\ntones alongside verbal content, while employing a Theory of Mind (ToM) model to\nrepresent each player's suspicion levels toward others. By combining this ToM\nmodel with Monte Carlo Tree Search (MCTS), our agent identifies communication\nstrategies that minimize suspicion directed at itself. Through comprehensive\nevaluation in both agent-versus-agent simulations and studies with human\nplayers, we demonstrate MultiMind's superior performance in gameplay. Our work\npresents a significant advancement toward LLM agents capable of human-like\nsocial reasoning across multimodal domains.",
      "tldr_zh": "本研究提出MultiMind框架，以提升Large Language Model (LLM)代理在Werewolf类社会推演游戏中的性能，特别针对文本之外的多模态线索（如面部表情和语气）以及Theory of Mind (ToM)建模的缺失。MultiMind整合多模态信息处理、ToM模型来表示玩家对其他人的怀疑水平，并结合Monte Carlo Tree Search (MCTS)优化通信策略，以最小化自身被怀疑的风险。实验在One Night Ultimate Werewolf (ONUW)测试平台上显示，MultiMind在代理对代理和人类参与的场景中表现出色，显著提高了代理的游戏表现和类人社会推理能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18039v2",
      "published_date": "2025-04-25 03:12:43 UTC",
      "updated_date": "2025-05-08 17:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:50:08.048403"
    },
    {
      "arxiv_id": "2505.00024v2",
      "title": "Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaokun Zhang",
        "Yi Dong",
        "Jieyu Zhang",
        "Jan Kautz",
        "Bryan Catanzaro",
        "Andrew Tao",
        "Qingyun Wu",
        "Zhiding Yu",
        "Guilin Liu"
      ],
      "abstract": "Enabling large language models with external tools has become a pivotal\nstrategy for extending their functionality beyond text space. To enhance LLMs'\ntool-calling abilities, previous approaches primarily rely on supervised\nfine-tuning (SFT) with trajectories distilled from stronger models, often\nresulting in imitative reasoning that limits generalization. In this work, we\nexplore rule-based reinforcement learning to enhance tool-calling in LLMs,\nresulting in Nemotron-Research-Tool-N1, a series of tool-calling reasoning\nmodels. Rather than enforcing supervision over intermediate distilled reasoning\ntraces, Tool-N1 is trained with a binary RL reward that assesses only the\nformat validity and functional correctness of tool invocations. This\nlightweight supervision allows the model to develop reasoning strategies\nindependently, without relying on annotated trajectories. Experiments on\nseveral major benchmarks show that Tool-N1-7B/14B clearly outperform GPT-4o. We\nconduct a systematic study on the design of rule-based reinforcement learning\nstrategies for training tool-calling models. Using 5,518 distilled reasoning\ntrajectories, we compare SFT, RL, and the SFT-then-RL pipeline, finding that\nthe widely adopted SFT-then-RL paradigm does not necessarily outperform pure\nRL.",
      "tldr_zh": "该研究探索了使用规则-based强化学习（RL）来提升大型语言模型（LLMs）的工具调用能力，开发了Nemotron-Research-Tool-N1系列模型，以克服传统监督微调（SFT）方法的模仿性推理限制。模型通过二元RL奖励机制，仅评估工具调用的格式有效性和功能正确性，允许其独立发展推理策略，而不依赖标注轨迹。在多个基准测试中，Tool-N1-7B/14B模型的表现超过了GPT-4o，且系统比较发现，纯RL方法可能优于SFT-then-RL范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 tables, 12 figures. - update new results - add more\n  details",
      "pdf_url": "http://arxiv.org/pdf/2505.00024v2",
      "published_date": "2025-04-25 02:55:21 UTC",
      "updated_date": "2025-05-12 03:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:50:21.770450"
    },
    {
      "arxiv_id": "2504.18027v1",
      "title": "A Large Vision-Language Model based Environment Perception System for Visually Impaired People",
      "title_zh": "翻译失败",
      "authors": [
        "Zezhou Chen",
        "Zhaoxiang Liu",
        "Kai Wang",
        "Kohou Wang",
        "Shiguo Lian"
      ],
      "abstract": "It is a challenging task for visually impaired people to perceive their\nsurrounding environment due to the complexity of the natural scenes. Their\npersonal and social activities are thus highly limited. This paper introduces a\nLarge Vision-Language Model(LVLM) based environment perception system which\nhelps them to better understand the surrounding environment, by capturing the\ncurrent scene they face with a wearable device, and then letting them retrieve\nthe analysis results through the device. The visually impaired people could\nacquire a global description of the scene by long pressing the screen to\nactivate the LVLM output, retrieve the categories of the objects in the scene\nresulting from a segmentation model by tapping or swiping the screen, and get a\ndetailed description of the objects they are interested in by double-tapping\nthe screen. To help visually impaired people more accurately perceive the\nworld, this paper proposes incorporating the segmentation result of the RGB\nimage as external knowledge into the input of LVLM to reduce the LVLM's\nhallucination. Technical experiments on POPE, MME and LLaVA-QA90 show that the\nsystem could provide a more accurate description of the scene compared to\nQwen-VL-Chat, exploratory experiments show that the system helps visually\nimpaired people to perceive the surrounding environment effectively.",
      "tldr_zh": "本论文提出了一种基于 Large Vision-Language Model (LVLM) 的环境感知系统，旨在帮助视障人士更好地理解复杂自然场景。该系统通过可穿戴设备捕捉当前场景，并提供多种交互方式，如长按获取全局描述、轻敲获取物体分类结果，或双击获取详细物体描述；同时，通过将 RGB 图像的分割结果作为外部知识输入 LVLM，以减少 hallucination 并提升准确性。实验在 POPE、MME 和 LLaVA-QA90 数据集上显示，该系统比 Qwen-VL-Chat 提供了更精确的场景描述，且探索性实验证明其在实际应用中有效提升了视障人士的环境感知能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IROS2024(9 pages, 8 figures)",
      "pdf_url": "http://arxiv.org/pdf/2504.18027v1",
      "published_date": "2025-04-25 02:46:22 UTC",
      "updated_date": "2025-04-25 02:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:50:32.168497"
    },
    {
      "arxiv_id": "2504.18026v1",
      "title": "Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization",
      "title_zh": "通过偏好优化解决概念瓶颈模型中的概念错误标记问题",
      "authors": [
        "Emiliano Penaloza",
        "Tianyue H. Zhan",
        "Laurent Charlin",
        "Mateo Espinosa Zarlenga"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI\nsystems by constraining their decisions on a set of human understandable\nconcepts. However, CBMs typically assume that datasets contains accurate\nconcept labels an assumption often violated in practice, which we show can\nsignificantly degrade performance (by 25% in some cases). To address this, we\nintroduce the Concept Preference Optimization (CPO) objective, a new loss\nfunction based on Direct Preference Optimization, which effectively mitigates\nthe negative impact of concept mislabeling on CBM performance. We provide an\nanalysis on some key properties of the CPO objective showing it directly\noptimizes for the concept's posterior distribution, and contrast it against\nBinary Cross Entropy (BCE) where we show CPO is inherently less sensitive to\nconcept noise. We empirically confirm our analysis finding that CPO\nconsistently outperforms BCE in three real world datasets with and without\nadded label noise.",
      "tldr_zh": "Concept Bottleneck Models (CBMs) 旨在通过人类可理解的概念提升 AI 系统的可信度，但数据集中的概念错误标记往往导致性能显著下降（某些情况下降低 25%）。论文提出 Concept Preference Optimization (CPO) 目标函数，这是一种基于 Direct Preference Optimization 的新损失函数，能够有效缓解概念误标记对 CBM 性能的负面影响。分析显示，CPO 直接优化概念的后验分布，且比 Binary Cross Entropy (BCE) 对噪声更不敏感；实验在三个真实世界数据集上验证了 CPO 的优越性，即使存在标签噪声。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18026v1",
      "published_date": "2025-04-25 02:43:10 UTC",
      "updated_date": "2025-04-25 02:43:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:50:44.725803"
    },
    {
      "arxiv_id": "2504.21028v1",
      "title": "Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings",
      "title_zh": "语义感知对比性微调：通过判别性嵌入提升多模态恶意软件分类",
      "authors": [
        "Ivan Montoya Sanchez",
        "Shaswata Mitra",
        "Aritran Piplai",
        "Sudip Mittal"
      ],
      "abstract": "The rapid evolution of malware variants requires robust classification\nmethods to enhance cybersecurity. While Large Language Models (LLMs) offer\npotential for generating malware descriptions to aid family classification,\ntheir utility is limited by semantic embedding overlaps and misalignment with\nbinary behavioral features. We propose a contrastive fine-tuning (CFT) method\nthat refines LLM embeddings via targeted selection of hard negative samples\nbased on cosine similarity, enabling LLMs to distinguish between closely\nrelated malware families. Our approach combines high-similarity negatives to\nenhance discriminative power and mid-tier negatives to increase embedding\ndiversity, optimizing both precision and generalization. Evaluated on the\nCIC-AndMal-2020 and BODMAS datasets, our refined embeddings are integrated into\na multimodal classifier within a Model-Agnostic Meta-Learning (MAML) framework\non a few-shot setting. Experiments demonstrate significant improvements: our\nmethod achieves 63.15% classification accuracy with as few as 20 samples on\nCIC-AndMal-2020, outperforming baselines by 11--21 percentage points and\nsurpassing prior negative sampling strategies. Ablation studies confirm the\nsuperiority of similarity-based selection over random sampling, with gains of\n10-23%. Additionally, fine-tuned LLMs generate attribute-aware descriptions\nthat generalize to unseen variants, bridging textual and binary feature gaps.\nThis work advances malware classification by enabling nuanced semantic\ndistinctions and provides a scalable framework for adapting LLMs to\ncybersecurity challenges.",
      "tldr_zh": "该研究针对恶意软件分类面临的语义嵌入重叠和二进制特征不匹配问题，提出了一种基于语义感知的对比微调(Contrastive Fine-Tuning)方法，通过余弦相似度选择硬负样本来优化LLMs嵌入，从而增强对相近恶意软件家族的区分能力。该方法结合高相似度负样本提升区分精度，以及中等相似度负样本增加嵌入多样性，并在Model-Agnostic Meta-Learning (MAML)框架下应用于多模态分类器。实验在CIC-AndMal-2020和BODMAS数据集上显示，该方法在少样本场景（如20个样本）下达到63.15%的准确率，比基线提升11-21%，并证明了相似度-based负样本选择的优越性，为网络安全中的LLMs应用提供了可扩展框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.21028v1",
      "published_date": "2025-04-25 02:41:45 UTC",
      "updated_date": "2025-04-25 02:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:50:56.870887"
    },
    {
      "arxiv_id": "2505.00023v1",
      "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
      "title_zh": "CORG：从复杂、相互关联的语境中生成答案",
      "authors": [
        "Hyunji Lee",
        "Franck Dernoncourt",
        "Trung Bui",
        "Seunghyun Yoon"
      ],
      "abstract": "In a real-world corpus, knowledge frequently recurs across documents but\noften contains inconsistencies due to ambiguous naming, outdated information,\nor errors, leading to complex interrelationships between contexts. Previous\nresearch has shown that language models struggle with these complexities,\ntypically focusing on single factors in isolation. We classify these\nrelationships into four types: distracting, ambiguous, counterfactual, and\nduplicated. Our analysis reveals that no single approach effectively addresses\nall these interrelationships simultaneously. Therefore, we introduce Context\nOrganizer (CORG), a framework that organizes multiple contexts into\nindependently processed groups. This design allows the model to efficiently\nfind all relevant answers while ensuring disambiguation. CORG consists of three\nkey components: a graph constructor, a reranker, and an aggregator. Our results\ndemonstrate that CORG balances performance and efficiency effectively,\noutperforming existing grouping methods and achieving comparable results to\nmore computationally intensive, single-context approaches.",
      "tldr_zh": "该论文分析了语言模型在处理真实世界语料中复杂上下文关系时的挑战，这些关系包括 distracting（分心）、ambiguous（歧义）、counterfactual（反事实）和 duplicated（重复）类型，导致知识不一致。作者提出 Context Organizer (CORG) 框架，通过 graph constructor（图构建器）、reranker（重新排名器）和 aggregator（聚合器）组件，将多个上下文组织成独立处理的组，以高效查找答案并实现消歧。实验结果表明，CORG 在性能和效率上优于现有分组方法，并与计算密集的单上下文方法相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "published at Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00023v1",
      "published_date": "2025-04-25 02:40:48 UTC",
      "updated_date": "2025-04-25 02:40:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:51:09.089265"
    },
    {
      "arxiv_id": "2504.18012v1",
      "title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuang Yu",
        "Shiliang Sun",
        "Jing Zhao",
        "Tengfei Song",
        "Hao Yang"
      ],
      "abstract": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems.",
      "tldr_zh": "本研究评估了预训练编码器和解码器在Multimodal Machine Translation (MMT)中的作用，旨在通过整合图像等辅助模态提升翻译质量。研究者采用多种训练策略，包括从头训练、部分冻结预训练组件等，在Multi30K和CoMMuTE数据集上进行英德和英法翻译任务的实验。结果显示，预训练解码器能显著提高输出流畅性和准确性，而预训练编码器的效果取决于视觉-文本对齐的质量，且二者在多模态设置中发挥不对称作用。该工作还探讨了模态融合与预训练组件的互动，为未来多模态翻译系统架构设计提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18012v1",
      "published_date": "2025-04-25 01:44:04 UTC",
      "updated_date": "2025-04-25 01:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:51:21.246169"
    },
    {
      "arxiv_id": "2504.18010v1",
      "title": "Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation",
      "title_zh": "翻译失败",
      "authors": [
        "Zilin Huang",
        "Zihao Sheng",
        "Zhengyang Wan",
        "Yansong Qu",
        "Yuhao Luo",
        "Boyue Wang",
        "Pei Li",
        "Yen-Jung Chen",
        "Jiancong Chen",
        "Keke Long",
        "Jiayi Meng",
        "Yue Leng",
        "Sikai Chen"
      ],
      "abstract": "Recent advances in autonomous system simulation platforms have significantly\nenhanced the safe and scalable testing of driving policies. However, existing\nsimulators do not yet fully meet the needs of future transportation research,\nparticularly in modeling socially-aware driving agents and enabling effective\nhuman-AI collaboration. This paper introduces Sky-Drive, a novel distributed\nmulti-agent simulation platform that addresses these limitations through four\nkey innovations: (a) a distributed architecture for synchronized simulation\nacross multiple terminals; (b) a multi-modal human-in-the-loop framework\nintegrating diverse sensors to collect rich behavioral data; (c) a human-AI\ncollaboration mechanism supporting continuous and adaptive knowledge exchange;\nand (d) a digital twin (DT) framework for constructing high-fidelity virtual\nreplicas of real-world transportation environments. Sky-Drive supports diverse\napplications such as autonomous vehicle (AV)-vulnerable road user (VRU)\ninteraction modeling, human-in-the-loop training, socially-aware reinforcement\nlearning, personalized driving policy, and customized scenario generation.\nFuture extensions will incorporate foundation models for context-aware decision\nsupport and hardware-in-the-loop (HIL) testing for real-world validation. By\nbridging scenario generation, data collection, algorithm training, and hardware\nintegration, Sky-Drive has the potential to become a foundational platform for\nthe next generation of socially-aware and human-centered autonomous\ntransportation research. The demo video and code are available\nat:https://sky-lab-uw.github.io/Sky-Drive-website/",
      "tldr_zh": "本文论文介绍了Sky-Drive，一种分布式多智能体模拟平台，旨在解决现有模拟器在社会感知驾驶代理和人类-AI协作方面的不足。该平台通过四大创新实现：(a)分布式架构支持多终端同步模拟；(b)多模态人类在环框架整合多样传感器收集行为数据；(c)人类-AI协作机制实现持续自适应知识交换；(d)digital twin (DT)框架构建高保真虚拟交通环境。Sky-Drive支持多种应用，包括autonomous vehicle (AV)-vulnerable road user (VRU)交互建模、社会感知强化学习和个性化驾驶策略，并有望成为下一代社会感知和人类中心自治交通研究的基础平台，未来将整合基础模型和hardware-in-the-loop (HIL)测试。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18010v1",
      "published_date": "2025-04-25 01:33:26 UTC",
      "updated_date": "2025-04-25 01:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:51:32.862994"
    },
    {
      "arxiv_id": "2504.18007v1",
      "title": "Differential Privacy-Driven Framework for Enhancing Heart Disease Prediction",
      "title_zh": "基于差分隐私的增强心脏病预测框架",
      "authors": [
        "Yazan Otoum",
        "Amiya Nayak"
      ],
      "abstract": "With the rapid digitalization of healthcare systems, there has been a\nsubstantial increase in the generation and sharing of private health data.\nSafeguarding patient information is essential for maintaining consumer trust\nand ensuring compliance with legal data protection regulations. Machine\nlearning is critical in healthcare, supporting personalized treatment, early\ndisease detection, predictive analytics, image interpretation, drug discovery,\nefficient operations, and patient monitoring. It enhances decision-making,\naccelerates research, reduces errors, and improves patient outcomes. In this\npaper, we utilize machine learning methodologies, including differential\nprivacy and federated learning, to develop privacy-preserving models that\nenable healthcare stakeholders to extract insights without compromising\nindividual privacy. Differential privacy introduces noise to data to guarantee\nstatistical privacy, while federated learning enables collaborative model\ntraining across decentralized datasets. We explore applying these technologies\nto Heart Disease Data, demonstrating how they preserve privacy while delivering\nvaluable insights and comprehensive analysis. Our results show that using a\nfederated learning model with differential privacy achieved a test accuracy of\n85%, ensuring patient data remained secure and private throughout the process.",
      "tldr_zh": "该论文提出了一种基于差分隐私(differential privacy)的框架，用于提升心脏病预测的准确性，同时保护患者隐私。该框架结合差分隐私（通过添加噪声确保数据统计隐私）和联邦学习(federated learning)（在分散数据集上协作训练模型），允许医疗利益相关者从心脏病数据中提取洞见，而不泄露个人信息。在实验中，该方法在心脏病数据集上实现了85%的测试准确率，证明了其在保持数据安全前提下有效提升预测性能。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "\\c{opyright} 2025 IEEE. Accepted to IEEE International Conference on\n  Communications ICC 2025. Final version to appear in IEEE Xplore",
      "pdf_url": "http://arxiv.org/pdf/2504.18007v1",
      "published_date": "2025-04-25 01:27:40 UTC",
      "updated_date": "2025-04-25 01:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:51:44.642606"
    },
    {
      "arxiv_id": "2504.18604v2",
      "title": "A Cognitive-Mechanistic Human Reliability Analysis Framework: A Nuclear Power Plant Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Xiao",
        "Peng Chen",
        "Jiejuan Tong",
        "Shunshun Liu",
        "Hongru Zhao",
        "Jun Zhao",
        "Qianqian Jia",
        "Jingang Liang",
        "Haitao Wang"
      ],
      "abstract": "Traditional human reliability analysis (HRA) methods, such as IDHEAS-ECA,\nrely on expert judgment and empirical rules that often overlook the cognitive\nunderpinnings of human error. Moreover, conducting human-in-the-loop\nexperiments for advanced nuclear power plants is increasingly impractical due\nto novel interfaces and limited operational data. This study proposes a\ncognitive-mechanistic framework (COGMIF) that enhances the IDHEAS-ECA\nmethodology by integrating an ACT-R-based human digital twin (HDT) with\nTimeGAN-augmented simulation. The ACT-R model simulates operator cognition,\nincluding memory retrieval, goal-directed procedural reasoning, and\nperceptual-motor execution, under high-fidelity scenarios derived from a\nhigh-temperature gas-cooled reactor (HTGR) simulator. To overcome the resource\nconstraints of large-scale cognitive modeling, TimeGAN is trained on\nACT-R-generated time-series data to produce high-fidelity synthetic operator\nbehavior datasets. These simulations are then used to drive IDHEAS-ECA\nassessments, enabling scalable, mechanism-informed estimation of human error\nprobabilities (HEPs). Comparative analyses with SPAR-H and sensitivity\nassessments demonstrate the robustness and practical advantages of the proposed\nCOGMIF. Finally, procedural features are mapped onto a Bayesian network to\nquantify the influence of contributing factors, revealing key drivers of\noperational risk. This work offers a credible and computationally efficient\npathway to integrate cognitive theory into industrial HRA practices.",
      "tldr_zh": "本研究针对传统HRA方法（如IDHEAS-ECA）依赖专家判断而忽略认知基础的问题，提出COGMIF框架，通过整合ACT-R-based HDT和TimeGAN-augmented simulation，增强HRA评估在先进核电站（如HTGR）的适用性。COGMIF利用ACT-R模型模拟操作员认知过程，包括记忆检索、目标导向程序推理和感知-运动执行，并通过TimeGAN在生成的时序数据上训练合成高保真操作员行为数据集，实现可扩展的HEP估计。实验结果显示，COGMIF与SPAR-H方法比较后表现出更强的稳健性和实用优势，并通过Bayesian网络量化程序特征的影响，揭示操作风险的关键驱动因素，从而为将认知理论高效整合到工业HRA实践中提供可靠路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18604v2",
      "published_date": "2025-04-25 00:46:00 UTC",
      "updated_date": "2025-05-05 23:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:51:58.526121"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 94,
  "processed_papers_count": 94,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T16:52:20.864807"
}