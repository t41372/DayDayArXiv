[
  {
    "arxiv_id": "2504.18735v1",
    "title": "TLoRA: Tri-Matrix Low-Rank Adaptation of Large Language Models",
    "authors": [
      "Tanvir Islam"
    ],
    "abstract": "We propose TLoRA, a novel tri-matrix low-rank adaptation method that\ndecomposes weight updates into three matrices: two fixed random matrices and\none trainable matrix, combined with a learnable, layer-wise scaling factor.\nThis tri-matrix design enables TLoRA to achieve highly efficient parameter\nadaptation while introducing minimal additional computational overhead. Through\nextensive experiments on the GLUE benchmark, we demonstrate that TLoRA achieves\ncomparable performance to existing low-rank methods such as LoRA and\nAdapter-based techniques, while requiring significantly fewer trainable\nparameters. Analyzing the adaptation dynamics, we observe that TLoRA exhibits\nGaussian-like weight distributions, stable parameter norms, and scaling factor\nvariability across layers, further highlighting its expressive power and\nadaptability. Additionally, we show that TLoRA closely resembles LoRA in its\neigenvalue distributions, parameter norms, and cosine similarity of updates,\nunderscoring its ability to effectively approximate LoRA's adaptation behavior.\nOur results establish TLoRA as a highly efficient and effective fine-tuning\nmethod for LLMs, offering a significant step forward in resource-efficient\nmodel adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18735v1",
    "published_date": "2025-04-25 23:11:10 UTC",
    "updated_date": "2025-04-25 23:11:10 UTC"
  },
  {
    "arxiv_id": "2504.20093v1",
    "title": "Self-Healing Software Systems: Lessons from Nature, Powered by AI",
    "authors": [
      "Mohammad Baqar",
      "Rajat Khanda",
      "Saba Naqvi"
    ],
    "abstract": "As modern software systems grow in complexity and scale, their ability to\nautonomously detect, diagnose, and recover from failures becomes increasingly\nvital. Drawing inspiration from biological healing - where the human body\ndetects damage, signals the brain, and activates targeted recovery - this paper\nexplores the concept of self-healing software driven by artificial\nintelligence. We propose a novel framework that mimics this biological model\nsystem observability tools serve as sensory inputs, AI models function as the\ncognitive core for diagnosis and repair, and healing agents apply targeted code\nand test modifications. By combining log analysis, static code inspection, and\nAI-driven generation of patches or test updates, our approach aims to reduce\ndowntime, accelerate debugging, and enhance software resilience. We evaluate\nthe effectiveness of this model through case studies and simulations, comparing\nit against traditional manual debugging and recovery workflows. This work paves\nthe way toward intelligent, adaptive and self-reliant software systems capable\nof continuous healing, akin to living organisms.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20093v1",
    "published_date": "2025-04-25 22:54:57 UTC",
    "updated_date": "2025-04-25 22:54:57 UTC"
  },
  {
    "arxiv_id": "2504.18727v1",
    "title": "World Food Atlas Project",
    "authors": [
      "Ali Rostami",
      "Z Xie",
      "A Ishino",
      "Y Yamakata",
      "K Aizawa",
      "Ramesh Jain"
    ],
    "abstract": "A coronavirus pandemic is forcing people to be \"at home\" all over the world.\nIn a life of hardly ever going out, we would have realized how the food we eat\naffects our bodies. What can we do to know our food more and control it better?\nTo give us a clue, we are trying to build a World Food Atlas (WFA) that\ncollects all the knowledge about food in the world. In this paper, we present\ntwo of our trials. The first is the Food Knowledge Graph (FKG), which is a\ngraphical representation of knowledge about food and ingredient relationships\nderived from recipes and food nutrition data. The second is the FoodLog Athl\nand the RecipeLog that are applications for collecting people's detailed\nrecords about food habit. We also discuss several problems that we try to solve\nto build the WFA by integrating these two ideas.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18727v1",
    "published_date": "2025-04-25 22:40:02 UTC",
    "updated_date": "2025-04-25 22:40:02 UTC"
  },
  {
    "arxiv_id": "2504.20092v1",
    "title": "An Integrated Framework for Contextual Personalized LLM-Based Food Recommendation",
    "authors": [
      "Ali Rostami"
    ],
    "abstract": "Personalized food recommendation systems (Food-RecSys) critically\nunderperform due to fragmented component understanding and the failure of\nconventional machine learning with vast, imbalanced food data. While Large\nLanguage Models (LLMs) offer promise, current generic Recommendation as\nLanguage Processing (RLP) strategies lack the necessary specialization for the\nfood domain's complexity. This thesis tackles these deficiencies by first\nidentifying and analyzing the essential components for effective Food-RecSys.\nWe introduce two key innovations: a multimedia food logging platform for rich\ncontextual data acquisition and the World Food Atlas, enabling unique\ngeolocation-based food analysis previously unavailable. Building on this\nfoundation, we pioneer the Food Recommendation as Language Processing (F-RLP)\nframework - a novel, integrated approach specifically architected for the food\ndomain. F-RLP leverages LLMs in a tailored manner, overcoming the limitations\nof generic models and providing a robust infrastructure for effective,\ncontextual, and truly personalized food recommendations.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Doctorate Thesis, University of California, Irvine 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.20092v1",
    "published_date": "2025-04-25 22:20:33 UTC",
    "updated_date": "2025-04-25 22:20:33 UTC"
  },
  {
    "arxiv_id": "2504.18722v1",
    "title": "MODP: Multi Objective Directional Prompting",
    "authors": [
      "Aashutosh Nema",
      "Samaksh Gulati",
      "Evangelos Giakoumakis",
      "Bipana Thapaliya"
    ],
    "abstract": "Recent advances in large language models (LLMs) have led to their popularity\nacross multiple use-cases. However, prompt engineering, the process for\noptimally utilizing such models, remains approximation-driven and subjective.\nMost of the current research on prompt engineering focuses on task-specific\noptimization, while neglecting the behavior of the LLM under consideration\nduring prompt development. This paper introduces MODP -- Multi Objective\nDirectional Prompting, a framework based on two key concepts: 1)\nmulti-objectivity: the importance of considering an LLM's intrinsic behavior as\nan additional objective in prompt development, and 2) directional prompting: a\nmetrics-driven method for prompt engineering to ensure development of robust\nand high-precision prompts. We demonstrate the effectiveness of our proposed\nideas on a summarization task, using a synthetically created dataset, achieving\na 26% performance gain over initial prompts. Finally, we apply MODP to develop\nprompts for Dell's Next Best Action support tool, which is now in production\nand is used by more than 10,000 internal support agents and serving millions of\ncustomers worldwide.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "I.2.0; I.2.6; I.2.7; H.3.3"
    ],
    "primary_category": "cs.CC",
    "comment": "10 pages, 5 figures, submission to KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18722v1",
    "published_date": "2025-04-25 22:20:04 UTC",
    "updated_date": "2025-04-25 22:20:04 UTC"
  },
  {
    "arxiv_id": "2504.18710v1",
    "title": "Explicit neural network classifiers for non-separable data",
    "authors": [
      "Patrícia Muñoz Ewald"
    ],
    "abstract": "We fully characterize a large class of feedforward neural networks in terms\nof truncation maps. As an application, we show how a ReLU neural network can\nimplement a feature map which separates concentric data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML",
      "57R70, 62M45"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.18710v1",
    "published_date": "2025-04-25 21:46:54 UTC",
    "updated_date": "2025-04-25 21:46:54 UTC"
  },
  {
    "arxiv_id": "2504.18693v1",
    "title": "Technical Challenges in Maintaining Tax Prep Software with Large Language Models",
    "authors": [
      "Sina Gogani-Khiabani",
      "Varsha Dewangan",
      "Nina Olson",
      "Ashutosh Trivedi",
      "Saeid Tizpaz-Niari"
    ],
    "abstract": "As the US tax law evolves to adapt to ever-changing politico-economic\nrealities, tax preparation software plays a significant role in helping\ntaxpayers navigate these complexities. The dynamic nature of tax regulations\nposes a significant challenge to accurately and timely maintaining tax software\nartifacts. The state-of-the-art in maintaining tax prep software is\ntime-consuming and error-prone as it involves manual code analysis combined\nwith an expert interpretation of tax law amendments. We posit that the rigor\nand formality of tax amendment language, as expressed in IRS publications,\nmakes it amenable to automatic translation to executable specifications (code).\nOur research efforts focus on identifying, understanding, and tackling\ntechnical challenges in leveraging Large Language Models (LLMs), such as\nChatGPT and Llama, to faithfully extract code differentials from IRS\npublications and automatically integrate them with the prior version of the\ncode to automate tax prep software maintenance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "https://www.irs.gov/statistics/fourteenth-annual-irs-tpc-joint-research-conference-on-tax-administration"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to 14th Annual IRS/TPC Joint Research Conference on Tax\n  Administration (IRS-TPC 2024)",
    "pdf_url": "http://arxiv.org/pdf/2504.18693v1",
    "published_date": "2025-04-25 21:00:20 UTC",
    "updated_date": "2025-04-25 21:00:20 UTC"
  },
  {
    "arxiv_id": "2504.18691v1",
    "title": "From Prompts to Propositions: A Logic-Based Lens on Student-LLM Interactions",
    "authors": [
      "Ali Alfageeh",
      "Sadegh AlMahdi Kazemi Zarkouei",
      "Daye Nam",
      "Daniel Prol",
      "Matin Amoozadeh",
      "Souti Chattopadhyay",
      "James Prather",
      "Paul Denny",
      "Juho Leinonen",
      "Michael Hilton",
      "Sruti Srinivasa Ragavan",
      "Mohammad Amin Alipour"
    ],
    "abstract": "Background and Context. The increasing integration of large language models\n(LLMs) in computing education presents an emerging challenge in understanding\nhow students use LLMs and craft prompts to solve computational tasks. Prior\nresearch has used both qualitative and quantitative methods to analyze\nprompting behavior, but these approaches lack scalability or fail to\neffectively capture the semantic evolution of prompts. Objective. In this\npaper, we investigate whether students prompts can be systematically analyzed\nusing propositional logic constraints. We examine whether this approach can\nidentify patterns in prompt evolution, detect struggling students, and provide\ninsights into effective and ineffective strategies. Method. We introduce\nPrompt2Constraints, a novel method that translates students prompts into\nlogical constraints. The constraints are able to represent the intent of the\nprompts in succinct and quantifiable ways. We used this approach to analyze a\ndataset of 1,872 prompts from 203 students solving introductory programming\ntasks. Findings. We find that while successful and unsuccessful attempts tend\nto use a similar number of constraints overall, when students fail, they often\nmodify their prompts more significantly, shifting problem-solving strategies\nmidway. We also identify points where specific interventions could be most\nhelpful to students for refining their prompts. Implications. This work offers\na new and scalable way to detect students who struggle in solving natural\nlanguage programming tasks. This work could be extended to investigate more\ncomplex tasks and integrated into programming tools to provide real-time\nsupport.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18691v1",
    "published_date": "2025-04-25 20:58:16 UTC",
    "updated_date": "2025-04-25 20:58:16 UTC"
  },
  {
    "arxiv_id": "2504.20090v2",
    "title": "Spark: A System for Scientifically Creative Idea Generation",
    "authors": [
      "Aishik Sanyal",
      "Samuel Schapiro",
      "Sumuk Shashidhar",
      "Royce Moon",
      "Lav R. Varshney",
      "Dilek Hakkani-Tur"
    ],
    "abstract": "Recently, large language models (LLMs) have shown promising abilities to\ngenerate novel research ideas in science, a direction which coincides with many\nfoundational principles in computational creativity (CC). In light of these\ndevelopments, we present an idea generation system named Spark that couples\nretrieval-augmented idea generation using LLMs with a reviewer model named\nJudge trained on 600K scientific reviews from OpenReview. Our work is both a\nsystem demonstration and intended to inspire other CC researchers to explore\ngrounding the generation and evaluation of scientific ideas within foundational\nCC principles. To this end, we release the annotated dataset used to train\nJudge, inviting other researchers to explore the use of LLMs for idea\ngeneration and creative evaluations.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICCC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20090v2",
    "published_date": "2025-04-25 20:33:57 UTC",
    "updated_date": "2025-05-21 18:26:09 UTC"
  },
  {
    "arxiv_id": "2504.18689v1",
    "title": "HierSum: A Global and Local Attention Mechanism for Video Summarization",
    "authors": [
      "Apoorva Beedu",
      "Irfan Essa"
    ],
    "abstract": "Video summarization creates an abridged version (i.e., a summary) that\nprovides a quick overview of the video while retaining pertinent information.\nIn this work, we focus on summarizing instructional videos and propose a method\nfor breaking down a video into meaningful segments, each corresponding to\nessential steps in the video. We propose \\textbf{HierSum}, a hierarchical\napproach that integrates fine-grained local cues from subtitles with global\ncontextual information provided by video-level instructions. Our approach\nutilizes the ``most replayed\" statistic as a supervisory signal to identify\ncritical segments, thereby improving the effectiveness of the summary. We\nevaluate on benchmark datasets such as TVSum, BLiSS, Mr.HiSum, and the WikiHow\ntest set, and show that HierSum consistently outperforms existing methods in\nkey metrics such as F1-score and rank correlation. We also curate a new\nmulti-modal dataset using WikiHow and EHow videos and associated articles\ncontaining step-by-step instructions. Through extensive ablation studies, we\ndemonstrate that training on this dataset significantly enhances summarization\non the target datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18689v1",
    "published_date": "2025-04-25 20:30:30 UTC",
    "updated_date": "2025-04-25 20:30:30 UTC"
  },
  {
    "arxiv_id": "2504.18687v2",
    "title": "Transformational Creativity in Science: A Graphical Theory",
    "authors": [
      "Samuel Schapiro",
      "Jonah Black",
      "Lav R. Varshney"
    ],
    "abstract": "Creative processes are typically divided into three types: combinatorial,\nexploratory, and transformational. Here, we provide a graphical theory of\ntransformational scientific creativity, synthesizing Boden's insight that\ntransformational creativity arises from changes in the \"enabling constraints\"\nof a conceptual space and Kuhn's structure of scientific revolutions as\nresulting from paradigm shifts. We prove that modifications made to axioms of\nour graphical model have the most transformative potential and then illustrate\nhow several historical instances of transformational creativity can be captured\nby our framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICCC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18687v2",
    "published_date": "2025-04-25 20:28:07 UTC",
    "updated_date": "2025-05-20 21:20:03 UTC"
  },
  {
    "arxiv_id": "2504.18684v1",
    "title": "SORT3D: Spatial Object-centric Reasoning Toolbox for Zero-Shot 3D Grounding Using Large Language Models",
    "authors": [
      "Nader Zantout",
      "Haochen Zhang",
      "Pujith Kachana",
      "Jinkai Qiu",
      "Ji Zhang",
      "Wenshan Wang"
    ],
    "abstract": "Interpreting object-referential language and grounding objects in 3D with\nspatial relations and attributes is essential for robots operating alongside\nhumans. However, this task is often challenging due to the diversity of scenes,\nlarge number of fine-grained objects, and complex free-form nature of language\nreferences. Furthermore, in the 3D domain, obtaining large amounts of natural\nlanguage training data is difficult. Thus, it is important for methods to learn\nfrom little data and zero-shot generalize to new environments. To address these\nchallenges, we propose SORT3D, an approach that utilizes rich object attributes\nfrom 2D data and merges a heuristics-based spatial reasoning toolbox with the\nability of large language models (LLMs) to perform sequential reasoning.\nImportantly, our method does not require text-to-3D data for training and can\nbe applied zero-shot to unseen environments. We show that SORT3D achieves\nstate-of-the-art performance on complex view-dependent grounding tasks on two\nbenchmarks. We also implement the pipeline to run real-time on an autonomous\nvehicle and demonstrate that our approach can be used for object-goal\nnavigation on previously unseen real-world environments. All source code for\nthe system pipeline is publicly released at https://github.com/nzantout/SORT3D .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 6 figures, submitted to IROS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18684v1",
    "published_date": "2025-04-25 20:24:11 UTC",
    "updated_date": "2025-04-25 20:24:11 UTC"
  },
  {
    "arxiv_id": "2504.18671v1",
    "title": "Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction",
    "authors": [
      "Ross Gore",
      "Eranga Bandara",
      "Sachin Shetty",
      "Alberto E. Musto",
      "Pratip Rana",
      "Ambrosio Valencia-Romero",
      "Christopher Rhea",
      "Lobat Tayebi",
      "Heather Richter",
      "Atmaram Yarlagadda",
      "Donna Edmonds",
      "Steven Wallace",
      "Donna Broshek"
    ],
    "abstract": "Mild Traumatic Brain Injury (TBI) detection presents significant challenges\ndue to the subtle and often ambiguous presentation of symptoms in medical\nimaging, making accurate diagnosis a complex task. To address these challenges,\nwe propose Proof-of-TBI, a medical diagnosis support system that integrates\nmultiple fine-tuned vision-language models with the OpenAI-o3 reasoning large\nlanguage model (LLM). Our approach fine-tunes multiple vision-language models\nusing a labeled dataset of TBI MRI scans, training them to diagnose TBI\nsymptoms effectively. The predictions from these models are aggregated through\na consensus-based decision-making process. The system evaluates the predictions\nfrom all fine-tuned vision language models using the OpenAI-o3 reasoning LLM, a\nmodel that has demonstrated remarkable reasoning performance, to produce the\nmost accurate final diagnosis. The LLM Agents orchestrates interactions between\nthe vision-language models and the reasoning LLM, managing the final\ndecision-making process with transparency, reliability, and automation. This\nend-to-end decision-making workflow combines the vision-language model\nconsortium with the OpenAI-o3 reasoning LLM, enabled by custom prompt\nengineering by the LLM agents. The prototype for the proposed platform was\ndeveloped in collaboration with the U.S. Army Medical Research team in Newport\nNews, Virginia, incorporating five fine-tuned vision-language models. The\nresults demonstrate the transformative potential of combining fine-tuned\nvision-language model inputs with the OpenAI-o3 reasoning LLM to create a\nrobust, secure, and highly accurate diagnostic system for mild TBI prediction.\nTo the best of our knowledge, this research represents the first application of\nfine-tuned vision-language models integrated with a reasoning LLM for TBI\nprediction tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18671v1",
    "published_date": "2025-04-25 19:49:30 UTC",
    "updated_date": "2025-04-25 19:49:30 UTC"
  },
  {
    "arxiv_id": "2504.18662v1",
    "title": "M2R2: MulitModal Robotic Representation for Temporal Action Segmentation",
    "authors": [
      "Daniel Sliwowski",
      "Dongheui Lee"
    ],
    "abstract": "Temporal action segmentation (TAS) has long been a key area of research in\nboth robotics and computer vision. In robotics, algorithms have primarily\nfocused on leveraging proprioceptive information to determine skill boundaries,\nwith recent approaches in surgical robotics incorporating vision. In contrast,\ncomputer vision typically relies on exteroceptive sensors, such as cameras.\nExisting multimodal TAS models in robotics integrate feature fusion within the\nmodel, making it difficult to reuse learned features across different models.\nMeanwhile, pretrained vision-only feature extractors commonly used in computer\nvision struggle in scenarios with limited object visibility. In this work, we\naddress these challenges by proposing M2R2, a multimodal feature extractor\ntailored for TAS, which combines information from both proprioceptive and\nexteroceptive sensors. We introduce a novel pretraining strategy that enables\nthe reuse of learned features across multiple TAS models. Our method achieves\nstate-of-the-art performance on the REASSEMBLE dataset, a challenging\nmultimodal robotic assembly dataset, outperforming existing robotic action\nsegmentation models by 46.6%. Additionally, we conduct an extensive ablation\nstudy to evaluate the contribution of different modalities in robotic TAS\ntasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.18662v1",
    "published_date": "2025-04-25 19:36:17 UTC",
    "updated_date": "2025-04-25 19:36:17 UTC"
  },
  {
    "arxiv_id": "2504.18658v1",
    "title": "The Big Send-off: High Performance Collectives on GPU-based Supercomputers",
    "authors": [
      "Siddharth Singh",
      "Mahua Singh",
      "Abhinav Bhatele"
    ],
    "abstract": "We evaluate the current state of collective communication on GPU-based\nsupercomputers for large language model (LLM) training at scale. Existing\nlibraries such as RCCL and Cray-MPICH exhibit critical limitations on systems\nsuch as Frontier -- Cray-MPICH underutilizes network and compute resources,\nwhile RCCL suffers from severe scalability issues. To address these challenges,\nwe introduce PCCL, a communication library with highly optimized\nimplementations of all-gather and reduce-scatter operations tailored for\ndistributed deep learning workloads. PCCL is designed to maximally utilize all\navailable network and compute resources and to scale efficiently to thousands\nof GPUs. It achieves substantial performance improvements, delivering 6-33x\nspeedups over RCCL and 28-70x over Cray-MPICH for all-gather on 2048 GCDs of\nFrontier. These gains translate directly to end-to-end performance: in\nlarge-scale GPT-3-style training, PCCL provides up to 60% and 40% speedups over\nRCCL for 7B and 13B parameter models, respectively.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18658v1",
    "published_date": "2025-04-25 19:23:46 UTC",
    "updated_date": "2025-04-25 19:23:46 UTC"
  },
  {
    "arxiv_id": "2504.18651v1",
    "title": "Exploring a Large Language Model for Transforming Taxonomic Data into OWL: Lessons Learned and Implications for Ontology Development",
    "authors": [
      "Filipi Miranda Soares",
      "Antonio Mauro Saraiva",
      "Luís Ferreira Pires",
      "Luiz Olavo Bonino da Silva Santos",
      "Dilvan de Abreu Moreira",
      "Fernando Elias Corrêa",
      "Kelly Rosa Braghetto",
      "Debora Pignatari Drucker",
      "Alexandre Cláudio Botazzo Delbem"
    ],
    "abstract": "Managing scientific names in ontologies that represent species taxonomies is\nchallenging due to the ever-evolving nature of these taxonomies. Manually\nmaintaining these names becomes increasingly difficult when dealing with\nthousands of scientific names. To address this issue, this paper investigates\nthe use of ChatGPT-4 to automate the development of the :Organism module in the\nAgricultural Product Types Ontology (APTO) for species classification. Our\nmethodology involved leveraging ChatGPT-4 to extract data from the GBIF\nBackbone API and generate OWL files for further integration in APTO. Two\nalternative approaches were explored: (1) issuing a series of prompts for\nChatGPT-4 to execute tasks via the BrowserOP plugin and (2) directing ChatGPT-4\nto design a Python algorithm to perform analogous tasks. Both approaches rely\non a prompting method where we provide instructions, context, input data, and\nan output indicator. The first approach showed scalability limitations, while\nthe second approach used the Python algorithm to overcome these challenges, but\nit struggled with typographical errors in data handling. This study highlights\nthe potential of Large language models like ChatGPT-4 to streamline the\nmanagement of species names in ontologies. Despite certain limitations, these\ntools offer promising advancements in automating taxonomy-related tasks and\nimproving the efficiency of ontology development.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages, 6 Figures, accepted for publication in Data Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2504.18651v1",
    "published_date": "2025-04-25 19:05:52 UTC",
    "updated_date": "2025-04-25 19:05:52 UTC"
  },
  {
    "arxiv_id": "2504.18636v1",
    "title": "A Gradient-Optimized TSK Fuzzy Framework for Explainable Phishing Detection",
    "authors": [
      "Lohith Srikanth Pentapalli",
      "Jon Salisbury",
      "Josette Riep",
      "Kelly Cohen"
    ],
    "abstract": "Phishing attacks represent an increasingly sophisticated and pervasive threat\nto individuals and organizations, causing significant financial losses,\nidentity theft, and severe damage to institutional reputations. Existing\nphishing detection methods often struggle to simultaneously achieve high\naccuracy and explainability, either failing to detect novel attacks or\noperating as opaque black-box models. To address this critical gap, we propose\na novel phishing URL detection system based on a first-order Takagi-Sugeno-Kang\n(TSK) fuzzy inference model optimized through gradient-based techniques. Our\napproach intelligently combines the interpretability and human-like reasoning\ncapabilities of fuzzy logic with the precision and adaptability provided by\ngradient optimization methods, specifically leveraging the Adam optimizer for\nefficient parameter tuning. Experiments conducted using a comprehensive dataset\nof over 235,000 URLs demonstrate rapid convergence, exceptional predictive\nperformance (accuracy averaging 99.95% across 5 cross-validation folds, with a\nperfect AUC i.e. 1.00). Furthermore, optimized fuzzy rules and membership\nfunctions improve interoperability, clearly indicating how the model makes\ndecisions - an essential feature for cybersecurity applications. This\nhigh-performance, transparent, and interpretable phishing detection framework\nsignificantly advances current cybersecurity defenses, providing practitioners\nwith accurate and explainable decision-making tools.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18636v1",
    "published_date": "2025-04-25 18:31:05 UTC",
    "updated_date": "2025-04-25 18:31:05 UTC"
  },
  {
    "arxiv_id": "2504.18631v1",
    "title": "Research on Personalized Medical Intervention Strategy Generation System based on Group Relative Policy Optimization and Time-Series Data Fusion",
    "authors": [
      "Dingxin Lu",
      "Shurui Wu",
      "Xinyi Huang"
    ],
    "abstract": "With the timely formation of personalized intervention plans based on\nhigh-dimensional heterogeneous time series information becoming an important\nchallenge in the medical field today, electronic medical records, wearables,\nand other multi-source medical data are increasingly generated and diversified.\nIn this work, we develop a system to generate personalized medical intervention\nstrategies based on Group Relative Policy Optimization (GRPO) and Time-Series\nData Fusion. First, by incorporating relative policy constraints among the\ngroups during policy gradient updates, we adaptively balance individual and\ngroup gains. To improve the robustness and interpretability of decision-making,\na multi-layer neural network structure is employed to group-code patient\ncharacteristics. Second, for the rapid multi-modal fusion of multi-source\nheterogeneous time series, a multi-channel neural network combined with a\nself-attention mechanism is used for dynamic feature extraction. Key feature\nscreening and aggregation are achieved through a differentiable gating network.\nFinally, a collaborative search process combining a genetic algorithm and Monte\nCarlo tree search is proposed to find the ideal intervention strategy,\nachieving global optimization. Experimental results show significant\nimprovements in accuracy, coverage, and decision-making benefits compared with\nexisting methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18631v1",
    "published_date": "2025-04-25 18:15:59 UTC",
    "updated_date": "2025-04-25 18:15:59 UTC"
  },
  {
    "arxiv_id": "2504.18538v1",
    "title": "Generalization Capability for Imitation Learning",
    "authors": [
      "Yixiao Wang"
    ],
    "abstract": "Imitation learning holds the promise of equipping robots with versatile\nskills by learning from expert demonstrations. However, policies trained on\nfinite datasets often struggle to generalize beyond the training distribution.\nIn this work, we present a unified perspective on the generalization capability\nof imitation learning, grounded in both information theorey and data\ndistribution property. We first show that the generalization gap can be upper\nbounded by (i) the conditional information bottleneck on intermediate\nrepresentations and (ii) the mutual information between the model parameters\nand the training dataset. This characterization provides theoretical guidance\nfor designing effective training strategies in imitation learning, particularly\nin determining whether to freeze, fine-tune, or train large pretrained encoders\n(e.g., vision-language models or vision foundation models) from scratch to\nachieve better generalization. Furthermore, we demonstrate that high\nconditional entropy from input to output induces a flatter likelihood\nlandscape, thereby reducing the upper bound on the generalization gap. In\naddition, it shortens the stochastic gradient descent (SGD) escape time from\nsharp local minima, which may increase the likelihood of reaching global optima\nunder fixed optimization budgets. These insights explain why imitation learning\noften exhibits limited generalization and underscore the importance of not only\nscaling the diversity of input data but also enriching the variability of\noutput labels conditioned on the same input.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18538v1",
    "published_date": "2025-04-25 17:59:59 UTC",
    "updated_date": "2025-04-25 17:59:59 UTC"
  },
  {
    "arxiv_id": "2504.18536v1",
    "title": "Adapting Probabilistic Risk Assessment for AI",
    "authors": [
      "Anna Katariina Wisakanto",
      "Joe Rogero",
      "Avyay M. Casheekar",
      "Richard Mallah"
    ],
    "abstract": "Modern general-purpose artificial intelligence (AI) systems present an urgent\nrisk management challenge, as their rapidly evolving capabilities and potential\nfor catastrophic harm outpace our ability to reliably assess their risks.\nCurrent methods often rely on selective testing and undocumented assumptions\nabout risk priorities, frequently failing to make a serious attempt at\nassessing the set of pathways through which Al systems pose direct or indirect\nrisks to society and the biosphere. This paper introduces the probabilistic\nrisk assessment (PRA) for AI framework, adapting established PRA techniques\nfrom high-reliability industries (e.g., nuclear power, aerospace) for the new\nchallenges of advanced AI. The framework guides assessors in identifying\npotential risks, estimating likelihood and severity, and explicitly documenting\nevidence, underlying assumptions, and analyses at appropriate granularities.\nThe framework's implementation tool synthesizes the results into a risk report\ncard with aggregated risk estimates from all assessed risks. This systematic\napproach integrates three advances: (1) Aspect-oriented hazard analysis\nprovides systematic hazard coverage guided by a first-principles taxonomy of AI\nsystem aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk\npathway modeling analyzes causal chains from system aspects to societal impacts\nusing bidirectional analysis and incorporating prospective techniques; and (3)\nUncertainty management employs scenario decomposition, reference scales, and\nexplicit tracing protocols to structure credible projections with novelty or\nlimited data. Additionally, the framework harmonizes diverse assessment methods\nby integrating evidence into comparable, quantified absolute risk estimates for\ncritical decisions. We have implemented this as a workbook tool for AI\ndevelopers, evaluators, and regulators, available on the project website.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "for project website, see https://pra-for-ai.github.io/pra/",
    "pdf_url": "http://arxiv.org/pdf/2504.18536v1",
    "published_date": "2025-04-25 17:59:14 UTC",
    "updated_date": "2025-04-25 17:59:14 UTC"
  },
  {
    "arxiv_id": "2504.18530v2",
    "title": "Scaling Laws For Scalable Oversight",
    "authors": [
      "Joshua Engels",
      "David D. Baek",
      "Subhash Kantamneni",
      "Max Tegmark"
    ],
    "abstract": "Scalable oversight, the process by which weaker AI systems supervise stronger\nones, has been proposed as a key strategy to control future superintelligent\nsystems. However, it is still unclear how scalable oversight itself scales. To\naddress this gap, we propose a framework that quantifies the probability of\nsuccessful oversight as a function of the capabilities of the overseer and the\nsystem being overseen. Specifically, our framework models oversight as a game\nbetween capability-mismatched players; the players have oversight-specific Elo\nscores that are a piecewise-linear function of their general intelligence, with\ntwo plateaus corresponding to task incompetence and task saturation. We\nvalidate our framework with a modified version of the game Nim and then apply\nit to four oversight games: Mafia, Debate, Backdoor Code and Wargames. For each\ngame, we find scaling laws that approximate how domain performance depends on\ngeneral AI system capability. We then build on our findings in a theoretical\nstudy of Nested Scalable Oversight (NSO), a process in which trusted models\noversee untrusted stronger models, which then become the trusted models in the\nnext step. We identify conditions under which NSO succeeds and derive\nnumerically (and in some cases analytically) the optimal number of oversight\nlevels to maximize the probability of oversight success. We also apply our\ntheory to our four oversight games, where we find that NSO success rates at a\ngeneral Elo gap of 400 are 13.5% for Mafia, 51.7% for Debate, 10.0% for\nBackdoor Code, and 9.4% for Wargames; these rates decline further when\noverseeing stronger systems.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 18 figures; The first three authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2504.18530v2",
    "published_date": "2025-04-25 17:54:27 UTC",
    "updated_date": "2025-05-09 16:30:59 UTC"
  },
  {
    "arxiv_id": "2504.18497v1",
    "title": "DeSIA: Attribute Inference Attacks Against Limited Fixed Aggregate Statistics",
    "authors": [
      "Yifeng Mao",
      "Bozhidar Stevanoski",
      "Yves-Alexandre de Montjoye"
    ],
    "abstract": "Empirical inference attacks are a popular approach for evaluating the privacy\nrisk of data release mechanisms in practice. While an active attack literature\nexists to evaluate machine learning models or synthetic data release, we\ncurrently lack comparable methods for fixed aggregate statistics, in particular\nwhen only a limited number of statistics are released. We here propose an\ninference attack framework against fixed aggregate statistics and an attribute\ninference attack called DeSIA. We instantiate DeSIA against the U.S. Census\nPPMF dataset and show it to strongly outperform reconstruction-based attacks.\nIn particular, we show DeSIA to be highly effective at identifying vulnerable\nusers, achieving a true positive rate of 0.14 at a false positive rate of\n$10^{-3}$. We then show DeSIA to perform well against users whose attributes\ncannot be verified and when varying the number of aggregate statistics and\nlevel of noise addition. We also perform an extensive ablation study of DeSIA\nand show how DeSIA can be successfully adapted to the membership inference\ntask. Overall, our results show that aggregation alone is not sufficient to\nprotect privacy, even when a relatively small number of aggregates are being\nreleased, and emphasize the need for formal privacy mechanisms and testing\nbefore aggregate statistics are released.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18497v1",
    "published_date": "2025-04-25 17:10:33 UTC",
    "updated_date": "2025-04-25 17:10:33 UTC"
  },
  {
    "arxiv_id": "2504.20086v1",
    "title": "Understanding and Mitigating Risks of Generative AI in Financial Services",
    "authors": [
      "Sebastian Gehrmann",
      "Claire Huang",
      "Xian Teng",
      "Sergei Yurovski",
      "Iyanuoluwa Shode",
      "Chirag S. Patel",
      "Arjun Bhorkar",
      "Naveen Thomas",
      "John Doucette",
      "David Rosenberg",
      "Mark Dredze",
      "David Rabinowitz"
    ],
    "abstract": "To responsibly develop Generative AI (GenAI) products, it is critical to\ndefine the scope of acceptable inputs and outputs. What constitutes a \"safe\"\nresponse is an actively debated question. Academic work puts an outsized focus\non evaluating models by themselves for general purpose aspects such as\ntoxicity, bias, and fairness, especially in conversational applications being\nused by a broad audience. In contrast, less focus is put on considering\nsociotechnical systems in specialized domains. Yet, those specialized systems\ncan be subject to extensive and well-understood legal and regulatory scrutiny.\nThese product-specific considerations need to be set in industry-specific laws,\nregulations, and corporate governance requirements. In this paper, we aim to\nhighlight AI content safety considerations specific to the financial services\ndomain and outline an associated AI content risk taxonomy. We compare this\ntaxonomy to existing work in this space and discuss implications of risk\ncategory violations on various stakeholders. We evaluate how existing\nopen-source technical guardrail solutions cover this taxonomy by assessing them\non data collected via red-teaming activities. Our results demonstrate that\nthese guardrails fail to detect most of the content risks we discuss.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to FAccT 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.20086v1",
    "published_date": "2025-04-25 16:55:51 UTC",
    "updated_date": "2025-04-25 16:55:51 UTC"
  },
  {
    "arxiv_id": "2504.18471v1",
    "title": "Action Flow Matching for Continual Robot Learning",
    "authors": [
      "Alejandro Murillo-Gonzalez",
      "Lantao Liu"
    ],
    "abstract": "Continual learning in robotics seeks systems that can constantly adapt to\nchanging environments and tasks, mirroring human adaptability. A key challenge\nis refining dynamics models, essential for planning and control, while\naddressing issues such as safe adaptation, catastrophic forgetting, outlier\nmanagement, data efficiency, and balancing exploration with exploitation -- all\nwithin task and onboard resource constraints. Towards this goal, we introduce a\ngenerative framework leveraging flow matching for online robot dynamics model\nalignment. Rather than executing actions based on a misaligned model, our\napproach refines planned actions to better match with those the robot would\ntake if its model was well aligned. We find that by transforming the actions\nthemselves rather than exploring with a misaligned model -- as is traditionally\ndone -- the robot collects informative data more efficiently, thereby\naccelerating learning. Moreover, we validate that the method can handle an\nevolving and possibly imperfect model while reducing, if desired, the\ndependency on replay buffers or legacy model snapshots. We validate our\napproach using two platforms: an unmanned ground vehicle and a quadrotor. The\nresults highlight the method's adaptability and efficiency, with a record\n34.2\\% higher task success rate, demonstrating its potential towards enabling\ncontinual robot learning. Code:\nhttps://github.com/AlejandroMllo/action_flow_matching.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Robotics: Science and Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18471v1",
    "published_date": "2025-04-25 16:26:15 UTC",
    "updated_date": "2025-04-25 16:26:15 UTC"
  },
  {
    "arxiv_id": "2504.18458v1",
    "title": "Fast-Slow Thinking for Large Vision-Language Model Reasoning",
    "authors": [
      "Wenyi Xiao",
      "Leilei Gan",
      "Weilong Dai",
      "Wanggui He",
      "Ziwei Huang",
      "Haoyuan Li",
      "Fangxun Shu",
      "Zhelun Yu",
      "Peng Zhang",
      "Hao Jiang",
      "Fei Wu"
    ],
    "abstract": "Recent advances in large vision-language models (LVLMs) have revealed an\n\\textit{overthinking} phenomenon, where models generate verbose reasoning\nacross all tasks regardless of questions. To address this issue, we present\n\\textbf{FAST}, a novel \\textbf{Fa}st-\\textbf{S}low \\textbf{T}hinking framework\nthat dynamically adapts reasoning depth based on question characteristics.\nThrough empirical analysis, we establish the feasibility of fast-slow thinking\nin LVLMs by investigating how response length and data distribution affect\nperformance. We develop FAST-GRPO with three components: model-based metrics\nfor question characterization, an adaptive thinking reward mechanism, and\ndifficulty-aware KL regularization. Experiments across seven reasoning\nbenchmarks demonstrate that FAST achieves state-of-the-art accuracy with over\n10\\% relative improvement compared to the base model, while reducing token\nusage by 32.7-67.3\\% compared to previous slow-thinking approaches, effectively\nbalancing reasoning length and accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures, and 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.18458v1",
    "published_date": "2025-04-25 16:11:23 UTC",
    "updated_date": "2025-04-25 16:11:23 UTC"
  },
  {
    "arxiv_id": "2504.18453v1",
    "title": "Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation",
    "authors": [
      "Peiyuan Jing",
      "Kinhei Lee",
      "Zhenxuan Zhang",
      "Huichi Zhou",
      "Zhengqing Yuan",
      "Zhifan Gao",
      "Lei Zhu",
      "Giorgos Papanastasiou",
      "Yingying Fang",
      "Guang Yang"
    ],
    "abstract": "Radiology report generation is critical for efficiency but current models\nlack the structured reasoning of experts, hindering clinical trust and\nexplainability by failing to link visual findings to precise anatomical\nlocations. This paper introduces BoxMed-RL, a groundbreaking unified training\nframework for generating spatially verifiable and explainable radiology\nreports. Built on a large vision-language model, BoxMed-RL revolutionizes\nreport generation through two integrated phases: (1) In the Pretraining Phase,\nwe refine the model via medical concept learning, using Chain-of-Thought\nsupervision to internalize the radiologist-like workflow, followed by spatially\nverifiable reinforcement, which applies reinforcement learning to align medical\nfindings with bounding boxes. (2) In the Downstream Adapter Phase, we freeze\nthe pretrained weights and train a downstream adapter to ensure fluent and\nclinically credible reports. This framework precisely mimics radiologists'\nworkflow, compelling the model to connect high-level medical concepts with\ndefinitive anatomical evidence. Extensive experiments on public datasets\ndemonstrate that BoxMed-RL achieves an average 7% improvement in both METEOR\nand ROUGE-L metrics compared to state-of-the-art methods. An average 5%\nimprovement in large language model-based metrics further underscores\nBoxMed-RL's robustness in generating high-quality radiology reports.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18453v1",
    "published_date": "2025-04-25 16:05:06 UTC",
    "updated_date": "2025-04-25 16:05:06 UTC"
  },
  {
    "arxiv_id": "2504.20084v1",
    "title": "AI Awareness",
    "authors": [
      "Xiaojian Li",
      "Haoyuan Shi",
      "Rongwu Xu",
      "Wei Xu"
    ],
    "abstract": "Recent breakthroughs in artificial intelligence (AI) have brought about\nincreasingly capable systems that demonstrate remarkable abilities in\nreasoning, language understanding, and problem-solving. These advancements have\nprompted a renewed examination of AI awareness, not as a philosophical question\nof consciousness, but as a measurable, functional capacity. In this review, we\nexplore the emerging landscape of AI awareness, which includes meta-cognition\n(the ability to represent and reason about its own state), self-awareness\n(recognizing its own identity, knowledge, limitations, inter alia), social\nawareness (modeling the knowledge, intentions, and behaviors of other agents),\nand situational awareness (assessing and responding to the context in which it\noperates).\n  First, we draw on insights from cognitive science, psychology, and\ncomputational theory to trace the theoretical foundations of awareness and\nexamine how the four distinct forms of AI awareness manifest in\nstate-of-the-art AI. Next, we systematically analyze current evaluation methods\nand empirical findings to better understand these manifestations. Building on\nthis, we explore how AI awareness is closely linked to AI capabilities,\ndemonstrating that more aware AI agents tend to exhibit higher levels of\nintelligent behaviors. Finally, we discuss the risks associated with AI\nawareness, including key topics in AI safety, alignment, and broader ethical\nconcerns.\n  AI awareness is a double-edged sword: it improves general capabilities, i.e.,\nreasoning, safety, while also raises concerns around misalignment and societal\nrisks, demanding careful oversight as AI capabilities grow. On the whole, our\ninterdisciplinary review provides a roadmap for future research and aims to\nclarify the role of AI awareness in the ongoing development of intelligent\nmachines.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20084v1",
    "published_date": "2025-04-25 16:03:50 UTC",
    "updated_date": "2025-04-25 16:03:50 UTC"
  },
  {
    "arxiv_id": "2504.18447v1",
    "title": "Iterative Event-based Motion Segmentation by Variational Contrast Maximization",
    "authors": [
      "Ryo Yamaki",
      "Shintaro Shiba",
      "Guillermo Gallego",
      "Yoshimitsu Aoki"
    ],
    "abstract": "Event cameras provide rich signals that are suitable for motion estimation\nsince they respond to changes in the scene. As any visual changes in the scene\nproduce event data, it is paramount to classify the data into different motions\n(i.e., motion segmentation), which is useful for various tasks such as object\ndetection and visual servoing. We propose an iterative motion segmentation\nmethod, by classifying events into background (e.g., dominant motion\nhypothesis) and foreground (independent motion residuals), thus extending the\nContrast Maximization framework. Experimental results demonstrate that the\nproposed method successfully classifies event clusters both for public and\nself-recorded datasets, producing sharp, motion-compensated edge-like images.\nThe proposed method achieves state-of-the-art accuracy on moving object\ndetection benchmarks with an improvement of over 30%, and demonstrates its\npossibility of applying to more complex and noisy real-world scenes. We hope\nthis work broadens the sensitivity of Contrast Maximization with respect to\nboth motion parameters and input events, thus contributing to theoretical\nadvancements in event-based motion segmentation estimation.\nhttps://github.com/aoki-media-lab/event_based_segmentation_vcmax",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 9 figures, 3 tables, CVPR Workshop 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18447v1",
    "published_date": "2025-04-25 16:00:23 UTC",
    "updated_date": "2025-04-25 16:00:23 UTC"
  },
  {
    "arxiv_id": "2504.18443v2",
    "title": "Pseudo-Boolean Proof Logging for Optimal Classical Planning",
    "authors": [
      "Simon Dold",
      "Malte Helmert",
      "Jakob Nordström",
      "Gabriele Röger",
      "Tanja Schindler"
    ],
    "abstract": "We introduce lower-bound certificates for classical planning tasks, which can\nbe used to prove the unsolvability of a task or the optimality of a plan in a\nway that can be verified by an independent third party. We describe a general\nframework for generating lower-bound certificates based on pseudo-Boolean\nconstraints, which is agnostic to the planning algorithm used.\n  As a case study, we show how to modify the $A^{*}$ algorithm to produce\nproofs of optimality with modest overhead, using pattern database heuristics\nand $h^\\textit{max}$ as concrete examples. The same proof logging approach\nworks for any heuristic whose inferences can be efficiently expressed as\nreasoning over pseudo-Boolean constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "35th International Conference on Automated Planning and Scheduling\n  (ICAPS'2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.18443v2",
    "published_date": "2025-04-25 15:54:09 UTC",
    "updated_date": "2025-05-03 00:44:16 UTC"
  },
  {
    "arxiv_id": "2504.18437v1",
    "title": "Enhancing Pre-Trained Model-Based Class-Incremental Learning through Neural Collapse",
    "authors": [
      "Kun He",
      "Zijian Song",
      "Shuoxi Zhang",
      "John E. Hopcroft"
    ],
    "abstract": "Class-Incremental Learning (CIL) is a critical capability for real-world\napplications, enabling learning systems to adapt to new tasks while retaining\nknowledge from previous ones. Recent advancements in pre-trained models (PTMs)\nhave significantly advanced the field of CIL, demonstrating superior\nperformance over traditional methods. However, understanding how features\nevolve and are distributed across incremental tasks remains an open challenge.\nIn this paper, we propose a novel approach to modeling feature evolution in\nPTM-based CIL through the lens of neural collapse (NC), a striking phenomenon\nobserved in the final phase of training, which leads to a well-separated,\nequiangular feature space. We explore the connection between NC and CIL\neffectiveness, showing that aligning feature distributions with the NC geometry\nenhances the ability to capture the dynamic behavior of continual learning.\nBased on this insight, we introduce Neural Collapse-inspired Pre-Trained\nModel-based CIL (NCPTM-CIL), a method that dynamically adjusts the feature\nspace to conform to the elegant NC structure, thereby enhancing the continual\nlearning process. Extensive experiments demonstrate that NCPTM-CIL outperforms\nstate-of-the-art methods across four benchmark datasets. Notably, when\ninitialized with ViT-B/16-IN1K, NCPTM-CIL surpasses the runner-up method by\n6.73% on VTAB, 1.25% on CIFAR-100, and 2.5% on OmniBenchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18437v1",
    "published_date": "2025-04-25 15:48:41 UTC",
    "updated_date": "2025-04-25 15:48:41 UTC"
  },
  {
    "arxiv_id": "2504.18425v1",
    "title": "Kimi-Audio Technical Report",
    "authors": [
      "KimiTeam",
      "Ding Ding",
      "Zeqian Ju",
      "Yichong Leng",
      "Songxiang Liu",
      "Tong Liu",
      "Zeyu Shang",
      "Kai Shen",
      "Wei Song",
      "Xu Tan",
      "Heyi Tang",
      "Zhengtao Wang",
      "Chu Wei",
      "Yifei Xin",
      "Xinran Xu",
      "Jianwei Yu",
      "Yutao Zhang",
      "Xinyu Zhou",
      "Y. Charles",
      "Jun Chen",
      "Yanru Chen",
      "Yulun Du",
      "Weiran He",
      "Zhenxing Hu",
      "Guokun Lai",
      "Qingcheng Li",
      "Yangyang Liu",
      "Weidong Sun",
      "Jianzhou Wang",
      "Yuzhi Wang",
      "Yuefeng Wu",
      "Yuxin Wu",
      "Dongchao Yang",
      "Hao Yang",
      "Ying Yang",
      "Zhilin Yang",
      "Aoxiong Yin",
      "Ruibin Yuan",
      "Yutong Zhang",
      "Zaida Zhou"
    ],
    "abstract": "We present Kimi-Audio, an open-source audio foundation model that excels in\naudio understanding, generation, and conversation. We detail the practices in\nbuilding Kimi-Audio, including model architecture, data curation, training\nrecipe, inference deployment, and evaluation. Specifically, we leverage a\n12.5Hz audio tokenizer, design a novel LLM-based architecture with continuous\nfeatures as input and discrete tokens as output, and develop a chunk-wise\nstreaming detokenizer based on flow matching. We curate a pre-training dataset\nthat consists of more than 13 million hours of audio data covering a wide range\nof modalities including speech, sound, and music, and build a pipeline to\nconstruct high-quality and diverse post-training data. Initialized from a\npre-trained LLM, Kimi-Audio is continual pre-trained on both audio and text\ndata with several carefully designed tasks, and then fine-tuned to support a\ndiverse of audio-related tasks. Extensive evaluation shows that Kimi-Audio\nachieves state-of-the-art performance on a range of audio benchmarks including\nspeech recognition, audio understanding, audio question answering, and speech\nconversation. We release the codes, model checkpoints, as well as the\nevaluation toolkits in https://github.com/MoonshotAI/Kimi-Audio.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18425v1",
    "published_date": "2025-04-25 15:31:46 UTC",
    "updated_date": "2025-04-25 15:31:46 UTC"
  },
  {
    "arxiv_id": "2504.18423v1",
    "title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection",
    "authors": [
      "Rajesh Yarra"
    ],
    "abstract": "Despite the transformative impact of Artificial Intelligence (AI) across\nvarious sectors, cyber security continues to rely on traditional static and\ndynamic analysis tools, hampered by high false positive rates and superficial\ncode comprehension. While generative AI offers promising automation\ncapabilities for software development, leveraging Large Language Models (LLMs)\nfor vulnerability detection presents unique challenges. This paper explores the\npotential and limitations of LLMs in identifying vulnerabilities, acknowledging\ninherent weaknesses such as hallucinations, limited context length, and\nknowledge cut-offs. Previous attempts employing machine learning models for\nvulnerability detection have proven ineffective due to limited real-world\napplicability, feature engineering challenges, lack of contextual\nunderstanding, and the complexities of training models to keep pace with the\nevolving threat landscape. Therefore, we propose a robust AI-driven approach\nfocused on mitigating these limitations and ensuring the quality and\nreliability of LLM based vulnerability detection. Through innovative\nmethodologies combining Retrieval-Augmented Generation (RAG) and\nMixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs\nwhile addressing their weaknesses, ultimately paving the way for dependable and\nefficient AI-powered solutions in securing the ever-evolving software\nlandscape.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18423v1",
    "published_date": "2025-04-25 15:30:40 UTC",
    "updated_date": "2025-04-25 15:30:40 UTC"
  },
  {
    "arxiv_id": "2504.18419v1",
    "title": "A Multimodal Hybrid Late-Cascade Fusion Network for Enhanced 3D Object Detection",
    "authors": [
      "Carlo Sgaravatti",
      "Roberto Basla",
      "Riccardo Pieroni",
      "Matteo Corno",
      "Sergio M. Savaresi",
      "Luca Magri",
      "Giacomo Boracchi"
    ],
    "abstract": "We present a new way to detect 3D objects from multimodal inputs, leveraging\nboth LiDAR and RGB cameras in a hybrid late-cascade scheme, that combines an\nRGB detection network and a 3D LiDAR detector. We exploit late fusion\nprinciples to reduce LiDAR False Positives, matching LiDAR detections with RGB\nones by projecting the LiDAR bounding boxes on the image. We rely on cascade\nfusion principles to recover LiDAR False Negatives leveraging epipolar\nconstraints and frustums generated by RGB detections of separate views. Our\nsolution can be plugged on top of any underlying single-modal detectors,\nenabling a flexible training process that can take advantage of pre-trained\nLiDAR and RGB detectors, or train the two branches separately. We evaluate our\nresults on the KITTI object detection benchmark, showing significant\nperformance improvements, especially for the detection of Pedestrians and\nCyclists.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18419v1",
    "published_date": "2025-04-25 15:28:53 UTC",
    "updated_date": "2025-04-25 15:28:53 UTC"
  },
  {
    "arxiv_id": "2504.18404v1",
    "title": "Paradigm shift on Coding Productivity Using GenAI",
    "authors": [
      "Liang Yu"
    ],
    "abstract": "Generative AI (GenAI) applications are transforming software engineering by\nenabling automated code co-creation. However, empirical evidence on GenAI's\nproductivity effects in industrial settings remains limited. This paper\ninvestigates the adoption of GenAI coding assistants (e.g., Codeium, Amazon Q)\nwithin telecommunications and FinTech domains. Through surveys and interviews\nwith industrial domain-experts, we identify primary productivity-influencing\nfactors, including task complexity, coding skills, domain knowledge, and GenAI\nintegration. Our findings indicate that GenAI tools enhance productivity in\nroutine coding tasks (e.g., refactoring and Javadoc generation) but face\nchallenges in complex, domain-specific activities due to limited\ncontext-awareness of codebases and insufficient support for customized design\nrules. We highlight new paradigms for coding transfer, emphasizing iterative\nprompt refinement, immersive development environment, and automated code\nevaluation as essential for effective GenAI usage.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18404v1",
    "published_date": "2025-04-25 15:00:06 UTC",
    "updated_date": "2025-04-25 15:00:06 UTC"
  },
  {
    "arxiv_id": "2504.18400v1",
    "title": "A Multimodal Deep Learning Approach for White Matter Shape Prediction in Diffusion MRI Tractography",
    "authors": [
      "Yui Lo",
      "Yuqian Chen",
      "Dongnan Liu",
      "Leo Zekelman",
      "Jarrett Rushmore",
      "Yogesh Rathi",
      "Nikos Makris",
      "Alexandra J. Golby",
      "Fan Zhang",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "abstract": "Shape measures have emerged as promising descriptors of white matter\ntractography, offering complementary insights into anatomical variability and\nassociations with cognitive and clinical phenotypes. However, conventional\nmethods for computing shape measures are computationally expensive and\ntime-consuming for large-scale datasets due to reliance on voxel-based\nrepresentations. We propose Tract2Shape, a novel multimodal deep learning\nframework that leverages geometric (point cloud) and scalar (tabular) features\nto predict ten white matter tractography shape measures. To enhance model\nefficiency, we utilize a dimensionality reduction algorithm for the model to\npredict five primary shape components. The model is trained and evaluated on\ntwo independently acquired datasets, the HCP-YA dataset, and the PPMI dataset.\nWe evaluate the performance of Tract2Shape by training and testing it on the\nHCP-YA dataset and comparing the results with state-of-the-art models. To\nfurther assess its robustness and generalization ability, we also test\nTract2Shape on the unseen PPMI dataset. Tract2Shape outperforms SOTA deep\nlearning models across all ten shape measures, achieving the highest average\nPearson's r and the lowest nMSE on the HCP-YA dataset. The ablation study shows\nthat both multimodal input and PCA contribute to performance gains. On the\nunseen testing PPMI dataset, Tract2Shape maintains a high Pearson's r and low\nnMSE, demonstrating strong generalizability in cross-dataset evaluation.\nTract2Shape enables fast, accurate, and generalizable prediction of white\nmatter shape measures from tractography data, supporting scalable analysis\nacross datasets. This framework lays a promising foundation for future\nlarge-scale white matter shape analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "21 pages, 3 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.18400v1",
    "published_date": "2025-04-25 14:54:47 UTC",
    "updated_date": "2025-04-25 14:54:47 UTC"
  },
  {
    "arxiv_id": "2504.18383v1",
    "title": "Bridge the Domains: Large Language Models Enhanced Cross-domain Sequential Recommendation",
    "authors": [
      "Qidong Liu",
      "Xiangyu Zhao",
      "Yejing Wang",
      "Zijian Zhang",
      "Howard Zhong",
      "Chong Chen",
      "Xiang Li",
      "Wei Huang",
      "Feng Tian"
    ],
    "abstract": "Cross-domain Sequential Recommendation (CDSR) aims to extract the preference\nfrom the user's historical interactions across various domains. Despite some\nprogress in CDSR, two problems set the barrier for further advancements, i.e.,\noverlap dilemma and transition complexity. The former means existing CDSR\nmethods severely rely on users who own interactions on all domains to learn\ncross-domain item relationships, compromising the practicability. The latter\nrefers to the difficulties in learning the complex transition patterns from the\nmixed behavior sequences. With powerful representation and reasoning abilities,\nLarge Language Models (LLMs) are promising to address these two problems by\nbridging the items and capturing the user's preferences from a semantic view.\nTherefore, we propose an LLMs Enhanced Cross-domain Sequential Recommendation\nmodel (LLM4CDSR). To obtain the semantic item relationships, we first propose\nan LLM-based unified representation module to represent items. Then, a\ntrainable adapter with contrastive regularization is designed to adapt the CDSR\ntask. Besides, a hierarchical LLMs profiling module is designed to summarize\nuser cross-domain preferences. Finally, these two modules are integrated into\nthe proposed tri-thread framework to derive recommendations. We have conducted\nextensive experiments on three public cross-domain datasets, validating the\neffectiveness of LLM4CDSR. We have released the code online.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "accepted by SIGIR'25",
    "pdf_url": "http://arxiv.org/pdf/2504.18383v1",
    "published_date": "2025-04-25 14:30:25 UTC",
    "updated_date": "2025-04-25 14:30:25 UTC"
  },
  {
    "arxiv_id": "2505.00025v1",
    "title": "A Method for the Architecture of a Medical Vertical Large Language Model Based on Deepseek R1",
    "authors": [
      "Mingda Zhang",
      "Jianglong Qin"
    ],
    "abstract": "In recent years, despite foundation models like DeepSeek-R1 and ChatGPT\ndemonstrating significant capabilities in general tasks, professional knowledge\nbarriers, computational resource requirements, and deployment environment\nlimitations have severely hindered their application in actual medical\nscenarios. Addressing these challenges, this paper proposes an efficient\nlightweight medical vertical large language model architecture method,\nsystematically solving the lightweight problem of medical large models from\nthree dimensions: knowledge acquisition, model compression, and computational\noptimization. At the knowledge acquisition level, a knowledge transfer pipeline\nis designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the\nDeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology\nis adopted to precisely adjust key attention layers. At the model compression\nlevel, compression techniques including 4-bit weight quantization are\nimplemented while preserving the core representation ability for medical\nreasoning. At the computational optimization level, inference optimization\ntechniques such as Flash Attention acceleration and continuous batching are\nintegrated, and a professional prompt template system is constructed to adapt\nto different types of medical problems. Experimental results on medical\nquestion-answering datasets show that the method proposed in this paper\nmaintains professional accuracy while reducing memory consumption by 64.7\\% and\ninference latency by 12.4\\%, providing an effective solution for the\napplication of medical large models in resource-constrained environments such\nas edge computing devices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 1 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.00025v1",
    "published_date": "2025-04-25 14:28:29 UTC",
    "updated_date": "2025-04-25 14:28:29 UTC"
  },
  {
    "arxiv_id": "2504.18380v1",
    "title": "Spatial Reasoner: A 3D Inference Pipeline for XR Applications",
    "authors": [
      "Steven Häsler",
      "Philipp Ackermann"
    ],
    "abstract": "Modern extended reality XR systems provide rich analysis of image data and\nfusion of sensor input and demand AR/VR applications that can reason about 3D\nscenes in a semantic manner. We present a spatial reasoning framework that\nbridges geometric facts with symbolic predicates and relations to handle key\ntasks such as determining how 3D objects are arranged among each other ('on',\n'behind', 'near', etc.). Its foundation relies on oriented 3D bounding box\nrepresentations, enhanced by a comprehensive set of spatial predicates, ranging\nfrom topology and connectivity to directionality and orientation, expressed in\na formalism related to natural language. The derived predicates form a spatial\nknowledge graph and, in combination with a pipeline-based inference model,\nenable spatial queries and dynamic rule evaluation. Implementations for client-\nand server-side processing demonstrate the framework's capability to\nefficiently translate geometric data into actionable knowledge, ensuring\nscalable and technology-independent spatial reasoning in complex 3D\nenvironments. The Spatial Reasoner framework is fostering the creation of\nspatial ontologies, and seamlessly integrates with and therefore enriches\nmachine learning, natural language processing, and rule systems in XR\napplications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "spatial computing, extended reality, knowledge representation,\n  spatial reasoning"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages, preprint of ICVARS 2025 paper",
    "pdf_url": "http://arxiv.org/pdf/2504.18380v1",
    "published_date": "2025-04-25 14:27:27 UTC",
    "updated_date": "2025-04-25 14:27:27 UTC"
  },
  {
    "arxiv_id": "2504.18376v2",
    "title": "Pushing the boundary on Natural Language Inference",
    "authors": [
      "Pablo Miralles-González",
      "Javier Huertas-Tato",
      "Alejandro Martín",
      "David Camacho"
    ],
    "abstract": "Natural Language Inference (NLI) is a central task in natural language\nunderstanding with applications in fact-checking, question answering, and\ninformation retrieval. Despite its importance, current NLI systems heavily rely\non supervised learning with datasets that often contain annotation artifacts\nand biases, limiting generalization and real-world applicability. In this work,\nwe apply a reinforcement learning-based approach using Group Relative Policy\nOptimization (GRPO) for Chain-of-Thought (CoT) learning in NLI, eliminating the\nneed for labeled rationales and enabling this type of training on more\nchallenging datasets such as ANLI. We fine-tune 7B, 14B, and 32B language\nmodels using parameter-efficient techniques (LoRA and QLoRA), demonstrating\nstrong performance across standard and adversarial NLI benchmarks. Our 32B\nAWQ-quantized model surpasses state-of-the-art results on 7 out of 11\nadversarial sets$\\unicode{x2013}$or on all of them considering our\nreplication$\\unicode{x2013}$within a 22GB memory footprint, showing that robust\nreasoning can be retained under aggressive quantization. This work provides a\nscalable and practical framework for building robust NLI systems without\nsacrificing inference quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18376v2",
    "published_date": "2025-04-25 14:20:57 UTC",
    "updated_date": "2025-05-06 13:04:22 UTC"
  },
  {
    "arxiv_id": "2504.20083v1",
    "title": "A model and package for German ColBERT",
    "authors": [
      "Thuong Dang",
      "Qiqi Chen"
    ],
    "abstract": "In this work, we introduce a German version for ColBERT, a late interaction\nmulti-dense vector retrieval method, with a focus on RAG applications. We also\npresent the main features of our package for ColBERT models, supporting both\nretrieval and fine-tuning workflows.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20083v1",
    "published_date": "2025-04-25 14:17:53 UTC",
    "updated_date": "2025-04-25 14:17:53 UTC"
  },
  {
    "arxiv_id": "2504.18361v1",
    "title": "COCO-Inpaint: A Benchmark for Image Inpainting Detection and Manipulation Localization",
    "authors": [
      "Haozhen Yan",
      "Yan Hong",
      "Jiahui Zhan",
      "Yikun Ji",
      "Jun Lan",
      "Huijia Zhu",
      "Weiqiang Wang",
      "Jianfu Zhang"
    ],
    "abstract": "Recent advancements in image manipulation have achieved unprecedented\nprogress in generating photorealistic content, but also simultaneously\neliminating barriers to arbitrary manipulation and editing, raising concerns\nabout multimedia authenticity and cybersecurity. However, existing Image\nManipulation Detection and Localization (IMDL) methodologies predominantly\nfocus on splicing or copy-move forgeries, lacking dedicated benchmarks for\ninpainting-based manipulations. To bridge this gap, we present COCOInpaint, a\ncomprehensive benchmark specifically designed for inpainting detection, with\nthree key contributions: 1) High-quality inpainting samples generated by six\nstate-of-the-art inpainting models, 2) Diverse generation scenarios enabled by\nfour mask generation strategies with optional text guidance, and 3) Large-scale\ncoverage with 258,266 inpainted images with rich semantic diversity. Our\nbenchmark is constructed to emphasize intrinsic inconsistencies between\ninpainted and authentic regions, rather than superficial semantic artifacts\nsuch as object shapes. We establish a rigorous evaluation protocol using three\nstandard metrics to assess existing IMDL approaches. The dataset will be made\npublicly available to facilitate future research in this area.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18361v1",
    "published_date": "2025-04-25 14:04:36 UTC",
    "updated_date": "2025-04-25 14:04:36 UTC"
  },
  {
    "arxiv_id": "2504.18353v1",
    "title": "Testing Individual Fairness in Graph Neural Networks",
    "authors": [
      "Roya Nasiri"
    ],
    "abstract": "The biases in artificial intelligence (AI) models can lead to automated\ndecision-making processes that discriminate against groups and/or individuals\nbased on sensitive properties such as gender and race. While there are many\nstudies on diagnosing and mitigating biases in various AI models, there is\nlittle research on individual fairness in Graph Neural Networks (GNNs). Unlike\ntraditional models, which treat data features independently and overlook their\ninter-relationships, GNNs are designed to capture graph-based structure where\nnodes are interconnected. This relational approach enables GNNs to model\ncomplex dependencies, but it also means that biases can propagate through these\nconnections, complicating the detection and mitigation of individual fairness\nviolations. This PhD project aims to develop a testing framework to assess and\nensure individual fairness in GNNs. It first systematically reviews the\nliterature on individual fairness, categorizing existing approaches to define,\nmeasure, test, and mitigate model biases, creating a taxonomy of individual\nfairness. Next, the project will develop a framework for testing and ensuring\nfairness in GNNs by adapting and extending current fairness testing and\nmitigation techniques. The framework will be evaluated through industrial case\nstudies, focusing on graph-based large language models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.18353v1",
    "published_date": "2025-04-25 13:45:24 UTC",
    "updated_date": "2025-04-25 13:45:24 UTC"
  },
  {
    "arxiv_id": "2504.20082v1",
    "title": "Evolution of AI in Education: Agentic Workflows",
    "authors": [
      "Firuz Kamalov",
      "David Santandreu Calonge",
      "Linda Smail",
      "Dilshod Azizov",
      "Dimple R. Thadani",
      "Theresa Kwong",
      "Amara Atif"
    ],
    "abstract": "Artificial intelligence (AI) has transformed various aspects of education,\nwith large language models (LLMs) driving advancements in automated tutoring,\nassessment, and content generation. However, conventional LLMs are constrained\nby their reliance on static training data, limited adaptability, and lack of\nreasoning. To address these limitations and foster more sustainable\ntechnological practices, AI agents have emerged as a promising new avenue for\neducational innovation. In this review, we examine agentic workflows in\neducation according to four major paradigms: reflection, planning, tool use,\nand multi-agent collaboration. We critically analyze the role of AI agents in\neducation through these key design paradigms, exploring their advantages,\napplications, and challenges. To illustrate the practical potential of agentic\nsystems, we present a proof-of-concept application: a multi-agent framework for\nautomated essay scoring. Preliminary results suggest this agentic approach may\noffer improved consistency compared to stand-alone LLMs. Our findings highlight\nthe transformative potential of AI agents in educational settings while\nunderscoring the need for further research into their interpretability,\ntrustworthiness, and sustainable impact on pedagogical impact.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20082v1",
    "published_date": "2025-04-25 13:44:57 UTC",
    "updated_date": "2025-04-25 13:44:57 UTC"
  },
  {
    "arxiv_id": "2504.18348v1",
    "title": "TSCL:Multi-party loss Balancing scheme for deep learning Image steganography based on Curriculum learning",
    "authors": [
      "Fengchun Liu. Tong Zhang",
      "Chunying Zhang"
    ],
    "abstract": "For deep learning-based image steganography frameworks, in order to ensure\nthe invisibility and recoverability of the information embedding, the loss\nfunction usually contains several losses such as embedding loss, recovery loss\nand steganalysis loss. In previous research works, fixed loss weights are\nusually chosen for training optimization, and this setting is not linked to the\nimportance of the steganography task itself and the training process. In this\npaper, we propose a Two-stage Curriculum Learning loss scheduler (TSCL) for\nbalancing multinomial losses in deep learning image steganography algorithms.\nTSCL consists of two phases: a priori curriculum control and loss dynamics\ncontrol. The first phase firstly focuses the model on learning the information\nembedding of the original image by controlling the loss weights in the\nmulti-party adversarial training; secondly, it makes the model shift its\nlearning focus to improving the decoding accuracy; and finally, it makes the\nmodel learn to generate a steganographic image that is resistant to\nsteganalysis. In the second stage, the learning speed of each training task is\nevaluated by calculating the loss drop of the before and after iteration rounds\nto balance the learning of each task. Experimental results on three large\npublic datasets, ALASKA2, VOC2012 and ImageNet, show that the proposed TSCL\nstrategy improves the quality of steganography, decoding accuracy and security.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18348v1",
    "published_date": "2025-04-25 13:36:50 UTC",
    "updated_date": "2025-04-25 13:36:50 UTC"
  },
  {
    "arxiv_id": "2504.18346v1",
    "title": "Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review",
    "authors": [
      "Toghrul Abbasli",
      "Kentaroh Toyoda",
      "Yuan Wang",
      "Leon Witt",
      "Muhammad Asif Ali",
      "Yukai Miao",
      "Dan Li",
      "Qingsong Wei"
    ],
    "abstract": "Large Language Models (LLMs) have been transformative across many domains.\nHowever, hallucination -- confidently outputting incorrect information --\nremains one of the leading challenges for LLMs. This raises the question of how\nto accurately assess and quantify the uncertainty of LLMs. Extensive literature\non traditional models has explored Uncertainty Quantification (UQ) to measure\nuncertainty and employed calibration techniques to address the misalignment\nbetween uncertainty and accuracy. While some of these methods have been adapted\nfor LLMs, the literature lacks an in-depth analysis of their effectiveness and\ndoes not offer a comprehensive benchmark to enable insightful comparison among\nexisting solutions. In this work, we fill this gap via a systematic survey of\nrepresentative prior works on UQ and calibration for LLMs and introduce a\nrigorous benchmark. Using two widely used reliability datasets, we empirically\nevaluate six related methods, which justify the significant findings of our\nreview. Finally, we provide outlooks for key future directions and outline open\nchallenges. To the best of our knowledge, this survey is the first dedicated\nstudy to review the calibration methods and relevant metrics for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18346v1",
    "published_date": "2025-04-25 13:34:40 UTC",
    "updated_date": "2025-04-25 13:34:40 UTC"
  },
  {
    "arxiv_id": "2504.18329v1",
    "title": "PHEATPRUNER: Interpretable Data-centric Feature Selection for Multivariate Time Series Classification through Persistent Homology",
    "authors": [
      "Anh-Duy Pham",
      "Olivier Basole Kashongwe",
      "Martin Atzmueller",
      "Tim Römer"
    ],
    "abstract": "Balancing performance and interpretability in multivariate time series\nclassification is a significant challenge due to data complexity and high\ndimensionality. This paper introduces PHeatPruner, a method integrating\npersistent homology and sheaf theory to address these challenges. Persistent\nhomology facilitates the pruning of up to 45% of the applied variables while\nmaintaining or enhancing the accuracy of models such as Random Forest,\nCatBoost, XGBoost, and LightGBM, all without depending on posterior\nprobabilities or supervised optimization algorithms. Concurrently, sheaf theory\ncontributes explanatory vectors that provide deeper insights into the data's\nstructural nuances. The approach was validated using the UEA Archive and a\nmastitis detection dataset for dairy cows. The results demonstrate that\nPHeatPruner effectively preserves model accuracy. Furthermore, our results\nhighlight PHeatPruner's key features, i.e. simplifying complex data and\noffering actionable insights without increasing processing time or complexity.\nThis method bridges the gap between complexity reduction and interpretability,\nsuggesting promising applications in various fields.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.18329v1",
    "published_date": "2025-04-25 13:14:11 UTC",
    "updated_date": "2025-04-25 13:14:11 UTC"
  },
  {
    "arxiv_id": "2504.18316v1",
    "title": "Towards Adaptive Software Agents for Debugging",
    "authors": [
      "Yacine Majdoub",
      "Eya Ben Charrada",
      "Haifa Touati"
    ],
    "abstract": "Using multiple agents was found to improve the debugging capabilities of\nLarge Language Models. However, increasing the number of LLM-agents has several\ndrawbacks such as increasing the running costs and rising the risk for the\nagents to lose focus. In this work, we propose an adaptive agentic design,\nwhere the number of agents and their roles are determined dynamically based on\nthe characteristics of the task to be achieved. In this design, the agents\nroles are not predefined, but are generated after analyzing the problem to be\nsolved. Our initial evaluation shows that, with the adaptive design, the number\nof agents that are generated depends on the complexity of the buggy code. In\nfact, for simple code with mere syntax issues, the problem was usually fixed\nusing one agent only. However, for more complex problems, we noticed the\ncreation of a higher number of agents. Regarding the effectiveness of the fix,\nwe noticed an average improvement of 11% compared to the one-shot prompting.\nGiven these promising results, we outline future research directions to improve\nour design for adaptive software agents that can autonomously plan and conduct\ntheir software goals.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, 3 figures, FSE2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18316v1",
    "published_date": "2025-04-25 12:48:08 UTC",
    "updated_date": "2025-04-25 12:48:08 UTC"
  },
  {
    "arxiv_id": "2504.18310v1",
    "title": "Artificial Intelligence health advice accuracy varies across languages and contexts",
    "authors": [
      "Prashant Garg",
      "Thiemo Fetzer"
    ],
    "abstract": "Using basic health statements authorized by UK and EU registers and 9,100\njournalist-vetted public-health assertions on topics such as abortion, COVID-19\nand politics from sources ranging from peer-reviewed journals and government\nadvisories to social media and news across the political spectrum, we benchmark\nsix leading large language models from in 21 languages, finding that, despite\nhigh accuracy on English-centric textbook claims, performance falls in multiple\nnon-European languages and fluctuates by topic and source, highlighting the\nurgency of comprehensive multilingual, domain-aware validation before deploying\nAI in global health communication.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "10 pages, 2 figures. All data, code and materials used is freely\n  available in the Zenodo (DOI: 10.5281/zenodo.15281282)",
    "pdf_url": "http://arxiv.org/pdf/2504.18310v1",
    "published_date": "2025-04-25 12:37:15 UTC",
    "updated_date": "2025-04-25 12:37:15 UTC"
  },
  {
    "arxiv_id": "2504.18286v1",
    "title": "Enhancing Long-Term Re-Identification Robustness Using Synthetic Data: A Comparative Analysis",
    "authors": [
      "Christian Pionzewski",
      "Rebecca Rademacher",
      "Jérôme Rutinowski",
      "Antonia Ponikarov",
      "Stephan Matzke",
      "Tim Chilla",
      "Pia Schreynemackers",
      "Alice Kirchheim"
    ],
    "abstract": "This contribution explores the impact of synthetic training data usage and\nthe prediction of material wear and aging in the context of re-identification.\nDifferent experimental setups and gallery set expanding strategies are tested,\nanalyzing their impact on performance over time for aging re-identification\nsubjects. Using a continuously updating gallery, we were able to increase our\nmean Rank-1 accuracy by 24%, as material aging was taken into account step by\nstep. In addition, using models trained with 10% artificial training data,\nRank-1 accuracy could be increased by up to 13%, in comparison to a model\ntrained on only real-world data, significantly boosting generalized performance\non hold-out data. Finally, this work introduces a novel, open-source\nre-identification dataset, pallet-block-2696. This dataset contains 2,696\nimages of Euro pallets, taken over a period of 4 months. During this time,\nnatural aging processes occurred and some of the pallets were damaged during\ntheir usage. These wear and tear processes significantly changed the appearance\nof the pallets, providing a dataset that can be used to generate synthetically\naged pallets or other wooden materials.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in: 2024 International Conference on Machine Learning and\n  Applications (ICMLA), IEEE. 6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18286v1",
    "published_date": "2025-04-25 11:57:11 UTC",
    "updated_date": "2025-04-25 11:57:11 UTC"
  },
  {
    "arxiv_id": "2504.18283v1",
    "title": "Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator",
    "authors": [
      "Minjae Kang",
      "Martim Brandão"
    ],
    "abstract": "Recent audio-visual generative models have made substantial progress in\ngenerating images from audio. However, existing approaches focus on generating\nimages from single-class audio and fail to generate images from mixed audio. To\naddress this, we propose an Audio-Visual Generation and Separation model\n(AV-GAS) for generating images from soundscapes (mixed audio containing\nmultiple classes). Our contribution is threefold: First, we propose a new\nchallenge in the audio-visual generation task, which is to generate an image\ngiven a multi-class audio input, and we propose a method that solves this task\nusing an audio-visual separator. Second, we introduce a new audio-visual\nseparation task, which involves generating separate images for each class\npresent in a mixed audio input. Lastly, we propose new evaluation metrics for\nthe audio-visual generation task: Class Representation Score (CRS) and a\nmodified R@K. Our model is trained and evaluated on the VGGSound dataset. We\nshow that our method outperforms the state-of-the-art, achieving 7% higher CRS\nand 4% higher R@2* in generating plausible images with mixed audio.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "Originally submitted to CVPR 2025 on 2024-11-15 with paper ID 15808",
    "pdf_url": "http://arxiv.org/pdf/2504.18283v1",
    "published_date": "2025-04-25 11:51:04 UTC",
    "updated_date": "2025-04-25 11:51:04 UTC"
  },
  {
    "arxiv_id": "2504.18271v1",
    "title": "LEAM: A Prompt-only Large Language Model-enabled Antenna Modeling Method",
    "authors": [
      "Tao Wu",
      "Kexue Fu",
      "Qiang Hua",
      "Xinxin Liu",
      "Muhammad Ali Imran",
      "Bo Liu"
    ],
    "abstract": "Antenna modeling is a time-consuming and complex process, decreasing the\nspeed of antenna analysis and design. In this paper, a large language model\n(LLM)- enabled antenna modeling method, called LEAM, is presented to address\nthis challenge. LEAM enables automatic antenna model generation based on\nlanguage descriptions via prompt input, images, descriptions from academic\npapers, patents, and technical reports (either one or multiple). The\neffectiveness of LEAM is demonstrated by three examples: a Vivaldi antenna\ngenerated from a complete user description, a slotted patch antenna generated\nfrom an incomplete user description and the operating frequency, and a monopole\nslotted antenna generated from images and descriptions scanned from the\nliterature. For all the examples, correct antenna models are generated in a few\nminutes. The code can be accessed via https://github.com/TaoWu974/LEAM.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Code are available: https://github.com/TaoWu974/LEAM",
    "pdf_url": "http://arxiv.org/pdf/2504.18271v1",
    "published_date": "2025-04-25 11:29:30 UTC",
    "updated_date": "2025-04-25 11:29:30 UTC"
  },
  {
    "arxiv_id": "2504.18267v2",
    "title": "Neural operators struggle to learn complex PDEs in pedestrian mobility: Hughes model case study",
    "authors": [
      "Prajwal Chauhan",
      "Salah Eddine Choutri",
      "Mohamed Ghattassi",
      "Nader Masmoudi",
      "Saif Eddin Jabari"
    ],
    "abstract": "This paper investigates the limitations of neural operators in learning\nsolutions for a Hughes model, a first-order hyperbolic conservation law system\nfor crowd dynamics. The model couples a Fokker-Planck equation representing\npedestrian density with a Hamilton-Jacobi-type (eikonal) equation. This Hughes\nmodel belongs to the class of nonlinear hyperbolic systems that often exhibit\ncomplex solution structures, including shocks and discontinuities. In this\nstudy, we assess the performance of three state-of-the-art neural operators\n(Fourier Neural Operator, Wavelet Neural Operator, and Multiwavelet Neural\nOperator) in various challenging scenarios. Specifically, we consider (1)\ndiscontinuous and Gaussian initial conditions and (2) diverse boundary\nconditions, while also examining the impact of different numerical schemes.\n  Our results show that these neural operators perform well in easy scenarios\nwith fewer discontinuities in the initial condition, yet they struggle in\ncomplex scenarios with multiple initial discontinuities and dynamic boundary\nconditions, even when trained specifically on such complex samples. The\npredicted solutions often appear smoother, resulting in a reduction in total\nvariation and a loss of important physical features. This smoothing behavior is\nsimilar to issues discussed by Daganzo (1995), where models that introduce\nartificial diffusion were shown to miss essential features such as shock waves\nin hyperbolic systems. These results suggest that current neural operator\narchitectures may introduce unintended regularization effects that limit their\nability to capture transport dynamics governed by discontinuities. They also\nraise concerns about generalizing these methods to traffic applications where\nshock preservation is essential.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 15 figures, 6 tables, under review at Artificial\n  Intelligence for Transportation | Journal",
    "pdf_url": "http://arxiv.org/pdf/2504.18267v2",
    "published_date": "2025-04-25 11:26:41 UTC",
    "updated_date": "2025-05-05 07:05:20 UTC"
  },
  {
    "arxiv_id": "2504.18253v1",
    "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing",
    "authors": [
      "Amirhossein Zhalehmehrabi",
      "Daniele Meli",
      "Francesco Dal Santo",
      "Francesco Trotti",
      "Alessandro Farinelli"
    ],
    "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime\noperations, yet their navigation in shallow-water environments remains\nchallenging due to dynamic disturbances and depth constraints. Traditional\nnavigation strategies struggle with limited sensor information, making safe and\nefficient operation difficult. In this paper, we propose a reinforcement\nlearning (RL) framework for ASV navigation under depth constraints, where the\nvehicle must reach a target while avoiding unsafe areas with only a single\ndepth measurement per timestep from a downward-facing Single Beam Echosounder\n(SBES). To enhance environmental awareness, we integrate Gaussian Process (GP)\nregression into the RL framework, enabling the agent to progressively estimate\na bathymetric depth map from sparse sonar readings. This approach improves\ndecision-making by providing a richer representation of the environment.\nFurthermore, we demonstrate effective sim-to-real transfer, ensuring that\ntrained policies generalize well to real-world aquatic conditions. Experimental\nresults validate our method's capability to improve ASV navigation performance\nwhile maintaining safety in challenging shallow-water environments.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18253v1",
    "published_date": "2025-04-25 10:56:56 UTC",
    "updated_date": "2025-04-25 10:56:56 UTC"
  },
  {
    "arxiv_id": "2504.18249v1",
    "title": "Event-Based Eye Tracking. 2025 Event-based Vision Workshop",
    "authors": [
      "Qinyu Chen",
      "Chang Gao",
      "Min Liu",
      "Daniele Perrone",
      "Yan Ru Pei",
      "Zuowen Wang",
      "Zhuo Zou",
      "Shihang Tan",
      "Tao Han",
      "Guorui Lu",
      "Zhen Xu",
      "Junyuan Ding",
      "Ziteng Wang",
      "Zongwei Wu",
      "Han Han",
      "Yuliang Wu",
      "Jinze Chen",
      "Wei Zhai",
      "Yang Cao",
      "Zheng-jun Zha",
      "Nuwan Bandara",
      "Thivya Kandappu",
      "Archan Misra",
      "Xiaopeng Lin",
      "Hongxiang Huang",
      "Hongwei Ren",
      "Bojun Cheng",
      "Hoang M. Truong",
      "Vinh-Thuan Ly",
      "Huy G. Tran",
      "Thuan-Phat Nguyen",
      "Tram T. Doan"
    ],
    "abstract": "This survey serves as a review for the 2025 Event-Based Eye Tracking\nChallenge organized as part of the 2025 CVPR event-based vision workshop. This\nchallenge focuses on the task of predicting the pupil center by processing\nevent camera recorded eye movement. We review and summarize the innovative\nmethods from teams rank the top in the challenge to advance future event-based\neye tracking research. In each method, accuracy, model size, and number of\noperations are reported. In this survey, we also discuss event-based eye\ntracking from the perspective of hardware design.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18249v1",
    "published_date": "2025-04-25 10:50:14 UTC",
    "updated_date": "2025-04-25 10:50:14 UTC"
  },
  {
    "arxiv_id": "2504.18246v1",
    "title": "Efficient Single-Pass Training for Multi-Turn Reasoning",
    "authors": [
      "Ritesh Goru",
      "Shanay Mehta",
      "Prateek Jain"
    ],
    "abstract": "Training Large Language Models ( LLMs) to generate explicit reasoning before\nthey produce an answer has been shown to improve their performance across\nvarious tasks such as mathematics and coding. However, fine-tuning LLMs on\nmulti-turn reasoning datasets presents a unique challenge: LLMs must generate\nreasoning tokens that are excluded from subsequent inputs to the LLM. This\ndiscrepancy prevents us from processing an entire conversation in a single\nforward pass-an optimization readily available when we fine-tune on a\nmulti-turn non-reasoning dataset. This paper proposes a novel approach that\novercomes this limitation through response token duplication and a custom\nattention mask that enforces appropriate visibility constraints. Our approach\nsignificantly reduces the training time and allows efficient fine-tuning on\nmulti-turn reasoning datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18246v1",
    "published_date": "2025-04-25 10:46:56 UTC",
    "updated_date": "2025-04-25 10:46:56 UTC"
  },
  {
    "arxiv_id": "2504.18231v1",
    "title": "Time and Frequency Domain-based Anomaly Detection in Smart Meter Data for Distribution Network Studies",
    "authors": [
      "Petar Labura",
      "Tomislav Antic",
      "Tomislav Capuder"
    ],
    "abstract": "The widespread integration of new technologies in low-voltage distribution\nnetworks on the consumer side creates the need for distribution system\noperators to perform advanced real-time calculations to estimate network\nconditions. In recent years, data-driven models based on machine learning and\nbig data analysis have emerged for calculation purposes, leveraging the\ninformation available in large datasets obtained from smart meters and other\nadvanced measurement infrastructure. However, existing data-driven algorithms\ndo not take into account the quality of data collected from smart meters. They\nlack built-in anomaly detection mechanisms and fail to differentiate anomalies\nbased on whether the value or context of anomalous data instances deviates from\nthe norm. This paper focuses on methods for detecting and mitigating the impact\nof anomalies on the consumption of active and reactive power datasets. It\nproposes an anomaly detection framework based on the Isolation Forest machine\nlearning algorithm and Fast Fourier Transform filtering that works in both the\ntime and frequency domain and is unaffected by point anomalies or contextual\nanomalies of the power consumption data. The importance of integrating anomaly\ndetection methods is demonstrated in the analysis important for distribution\nnetworks with a high share of smart meters.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18231v1",
    "published_date": "2025-04-25 10:26:30 UTC",
    "updated_date": "2025-04-25 10:26:30 UTC"
  },
  {
    "arxiv_id": "2504.18230v1",
    "title": "Learning to fuse: dynamic integration of multi-source data for accurate battery lifespan prediction",
    "authors": [
      "He Shanxuan",
      "Lin Zuhong",
      "Yu Bolun",
      "Gao Xu",
      "Long Biao",
      "Yao Jingjing"
    ],
    "abstract": "Accurate prediction of lithium-ion battery lifespan is vital for ensuring\noperational reliability and reducing maintenance costs in applications like\nelectric vehicles and smart grids. This study presents a hybrid learning\nframework for precise battery lifespan prediction, integrating dynamic\nmulti-source data fusion with a stacked ensemble (SE) modeling approach. By\nleveraging heterogeneous datasets from the National Aeronautics and Space\nAdministration (NASA), Center for Advanced Life Cycle Engineering (CALCE),\nMIT-Stanford-Toyota Research Institute (TRC), and nickel cobalt aluminum (NCA)\nchemistries, an entropy-based dynamic weighting mechanism mitigates variability\nacross heterogeneous datasets. The SE model combines Ridge regression, long\nshort-term memory (LSTM) networks, and eXtreme Gradient Boosting (XGBoost),\neffectively capturing temporal dependencies and nonlinear degradation patterns.\nIt achieves a mean absolute error (MAE) of 0.0058, root mean square error\n(RMSE) of 0.0092, and coefficient of determination (R2) of 0.9839,\noutperforming established baseline models with a 46.2% improvement in R2 and an\n83.2% reduction in RMSE. Shapley additive explanations (SHAP) analysis\nidentifies differential discharge capacity (Qdlin) and temperature of\nmeasurement (Temp_m) as critical aging indicators. This scalable, interpretable\nframework enhances battery health management, supporting optimized maintenance\nand safety across diverse energy storage systems, thereby contributing to\nimproved battery health management in energy storage systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18230v1",
    "published_date": "2025-04-25 10:24:45 UTC",
    "updated_date": "2025-04-25 10:24:45 UTC"
  },
  {
    "arxiv_id": "2504.18201v1",
    "title": "Multi-Grained Compositional Visual Clue Learning for Image Intent Recognition",
    "authors": [
      "Yin Tang",
      "Jiankai Li",
      "Hongyu Yang",
      "Xuan Dong",
      "Lifeng Fan",
      "Weixin Li"
    ],
    "abstract": "In an era where social media platforms abound, individuals frequently share\nimages that offer insights into their intents and interests, impacting\nindividual life quality and societal stability. Traditional computer vision\ntasks, such as object detection and semantic segmentation, focus on concrete\nvisual representations, while intent recognition relies more on implicit visual\nclues. This poses challenges due to the wide variation and subjectivity of such\nclues, compounded by the problem of intra-class variety in conveying abstract\nconcepts, e.g. \"enjoy life\". Existing methods seek to solve the problem by\nmanually designing representative features or building prototypes for each\nclass from global features. However, these methods still struggle to deal with\nthe large visual diversity of each intent category. In this paper, we introduce\na novel approach named Multi-grained Compositional visual Clue Learning (MCCL)\nto address these challenges for image intent recognition. Our method leverages\nthe systematic compositionality of human cognition by breaking down intent\nrecognition into visual clue composition and integrating multi-grained\nfeatures. We adopt class-specific prototypes to alleviate data imbalance. We\ntreat intent recognition as a multi-label classification problem, using a graph\nconvolutional network to infuse prior knowledge through label embedding\ncorrelations. Demonstrated by a state-of-the-art performance on the Intentonomy\nand MDID datasets, our approach advances the accuracy of existing methods while\nalso possessing good interpretability. Our work provides an attempt for future\nexplorations in understanding complex and miscellaneous forms of human\nexpression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18201v1",
    "published_date": "2025-04-25 09:31:03 UTC",
    "updated_date": "2025-04-25 09:31:03 UTC"
  },
  {
    "arxiv_id": "2504.18180v1",
    "title": "Aligning Language Models for Icelandic Legal Text Summarization",
    "authors": [
      "Þórir Hrafn Harðarson",
      "Hrafn Loftsson",
      "Stefán Ólafsson"
    ],
    "abstract": "The integration of language models in the legal domain holds considerable\npromise for streamlining processes and improving efficiency in managing\nextensive workloads. However, the specialized terminology, nuanced language,\nand formal style of legal texts can present substantial challenges. This study\nexamines whether preference-based training techniques, specifically\nReinforcement Learning from Human Feedback and Direct Preference Optimization,\ncan enhance models' performance in generating Icelandic legal summaries that\nalign with domain-specific language standards and user preferences. We compare\nmodels fine-tuned with preference training to those using conventional\nsupervised learning. Results indicate that preference training improves the\nlegal accuracy of generated summaries over standard fine-tuning but does not\nsignificantly enhance the overall quality of Icelandic language usage.\nDiscrepancies between automated metrics and human evaluations further\nunderscore the importance of qualitative assessment in developing language\nmodels for the legal domain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at NoDaLiDa 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18180v1",
    "published_date": "2025-04-25 08:55:15 UTC",
    "updated_date": "2025-04-25 08:55:15 UTC"
  },
  {
    "arxiv_id": "2504.20080v1",
    "title": "DNAD: Differentiable Neural Architecture Distillation",
    "authors": [
      "Xuan Rao",
      "Bo Zhao",
      "Derong Liu"
    ],
    "abstract": "To meet the demand for designing efficient neural networks with appropriate\ntrade-offs between model performance (e.g., classification accuracy) and\ncomputational complexity, the differentiable neural architecture distillation\n(DNAD) algorithm is developed based on two cores, namely search by deleting and\nsearch by imitating. Primarily, to derive neural architectures in a space where\ncells of the same type no longer share the same topology, the super-network\nprogressive shrinking (SNPS) algorithm is developed based on the framework of\ndifferentiable architecture search (DARTS), i.e., search by deleting. Unlike\nconventional DARTS-based approaches which yield neural architectures with\nsimple structures and derive only one architecture during the search procedure,\nSNPS is able to derive a Pareto-optimal set of architectures with flexible\nstructures by forcing the dynamic super-network shrink from a dense structure\nto a sparse one progressively. Furthermore, since knowledge distillation (KD)\nhas shown great effectiveness to train a compact network with the assistance of\nan over-parameterized model, we integrate SNPS with KD to formulate the DNAD\nalgorithm, i.e., search by imitating. By minimizing behavioral differences\nbetween the super-network and teacher network, the over-fitting of one-level\nDARTS is avoided and well-performed neural architectures are derived.\nExperiments on CIFAR-10 and ImageNet classification tasks demonstrate that both\nSNPS and DNAD are able to derive a set of architectures which achieve similar\nor lower error rates with fewer parameters and FLOPs. Particularly, DNAD\nachieves the top-1 error rate of 23.7% on ImageNet classification with a model\nof 6.0M parameters and 598M FLOPs, which outperforms most DARTS-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20080v1",
    "published_date": "2025-04-25 08:49:31 UTC",
    "updated_date": "2025-04-25 08:49:31 UTC"
  },
  {
    "arxiv_id": "2504.20079v1",
    "title": "FX-DARTS: Designing Topology-unconstrained Architectures with Differentiable Architecture Search and Entropy-based Super-network Shrinking",
    "authors": [
      "Xuan Rao",
      "Bo Zhao",
      "Derong Liu",
      "Cesare Alippi"
    ],
    "abstract": "Strong priors are imposed on the search space of Differentiable Architecture\nSearch (DARTS), such that cells of the same type share the same topological\nstructure and each intermediate node retains two operators from distinct nodes.\nWhile these priors reduce optimization difficulties and improve the\napplicability of searched architectures, they hinder the subsequent development\nof automated machine learning (Auto-ML) and prevent the optimization algorithm\nfrom exploring more powerful neural networks through improved architectural\nflexibility. This paper aims to reduce these prior constraints by eliminating\nrestrictions on cell topology and modifying the discretization mechanism for\nsuper-networks. Specifically, the Flexible DARTS (FX-DARTS) method, which\nleverages an Entropy-based Super-Network Shrinking (ESS) framework, is\npresented to address the challenges arising from the elimination of prior\nconstraints. Notably, FX-DARTS enables the derivation of neural architectures\nwithout strict prior rules while maintaining the stability in the enlarged\nsearch space. Experimental results on image classification benchmarks\ndemonstrate that FX-DARTS is capable of exploring a set of neural architectures\nwith competitive trade-offs between performance and computational complexity\nwithin a single search procedure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20079v1",
    "published_date": "2025-04-25 08:34:29 UTC",
    "updated_date": "2025-04-25 08:34:29 UTC"
  },
  {
    "arxiv_id": "2504.18165v1",
    "title": "PerfCam: Digital Twinning for Production Lines Using 3D Gaussian Splatting and Vision Models",
    "authors": [
      "Michel Gokan Khan",
      "Renan Guarese",
      "Fabian Johnson",
      "Xi Vincent Wang",
      "Anders Bergman",
      "Benjamin Edvinsson",
      "Mario Romero",
      "Jérémy Vachier",
      "Jan Kronqvist"
    ],
    "abstract": "We introduce PerfCam, an open source Proof-of-Concept (PoC) digital twinning\nframework that combines camera and sensory data with 3D Gaussian Splatting and\ncomputer vision models for digital twinning, object tracking, and Key\nPerformance Indicators (KPIs) extraction in industrial production lines. By\nutilizing 3D reconstruction and Convolutional Neural Networks (CNNs), PerfCam\noffers a semi-automated approach to object tracking and spatial mapping,\nenabling digital twins that capture real-time KPIs such as availability,\nperformance, Overall Equipment Effectiveness (OEE), and rate of conveyor belts\nin the production line. We validate the effectiveness of PerfCam through a\npractical deployment within realistic test production lines in the\npharmaceutical industry and contribute an openly published dataset to support\nfurther research and development in the field. The results demonstrate\nPerfCam's ability to deliver actionable insights through its precise digital\ntwin capabilities, underscoring its value as an effective tool for developing\nusable digital twins in smart manufacturing environments and extracting\noperational analytics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18165v1",
    "published_date": "2025-04-25 08:29:00 UTC",
    "updated_date": "2025-04-25 08:29:00 UTC"
  },
  {
    "arxiv_id": "2504.18160v1",
    "title": "Offline Learning of Controllable Diverse Behaviors",
    "authors": [
      "Mathieu Petitbois",
      "Rémy Portelas",
      "Sylvain Lamprier",
      "Ludovic Denoyer"
    ],
    "abstract": "Imitation Learning (IL) techniques aim to replicate human behaviors in\nspecific tasks. While IL has gained prominence due to its effectiveness and\nefficiency, traditional methods often focus on datasets collected from experts\nto produce a single efficient policy. Recently, extensions have been proposed\nto handle datasets of diverse behaviors by mainly focusing on learning\ntransition-level diverse policies or on performing entropy maximization at the\ntrajectory level. While these methods may lead to diverse behaviors, they may\nnot be sufficient to reproduce the actual diversity of demonstrations or to\nallow controlled trajectory generation. To overcome these drawbacks, we propose\na different method based on two key features: a) Temporal Consistency that\nensures consistent behaviors across entire episodes and not just at the\ntransition level as well as b) Controllability obtained by constructing a\nlatent space of behaviors that allows users to selectively activate specific\nbehaviors based on their requirements. We compare our approach to\nstate-of-the-art methods over a diverse set of tasks and environments. Project\npage: https://mathieu-petitbois.github.io/projects/swr/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Generative Models for Robot Learning Workshop at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18160v1",
    "published_date": "2025-04-25 08:16:56 UTC",
    "updated_date": "2025-04-25 08:16:56 UTC"
  },
  {
    "arxiv_id": "2504.18142v1",
    "title": "EDU-NER-2025: Named Entity Recognition in Urdu Educational Texts using XLM-RoBERTa with X (formerly Twitter)",
    "authors": [
      "Fida Ullah",
      "Muhammad Ahmad",
      "Muhammad Tayyab Zamir",
      "Muhammad Arif",
      "Grigori sidorov",
      "Edgardo Manuel Felipe Riverón",
      "Alexander Gelbukh"
    ],
    "abstract": "Named Entity Recognition (NER) plays a pivotal role in various Natural\nLanguage Processing (NLP) tasks by identifying and classifying named entities\n(NEs) from unstructured data into predefined categories such as person,\norganization, location, date, and time. While extensive research exists for\nhigh-resource languages and general domains, NER in Urdu particularly within\ndomain-specific contexts like education remains significantly underexplored.\nThis is Due to lack of annotated datasets for educational content which limits\nthe ability of existing models to accurately identify entities such as academic\nroles, course names, and institutional terms, underscoring the urgent need for\ntargeted resources in this domain. To the best of our knowledge, no dataset\nexists in the domain of the Urdu language for this purpose. To achieve this\nobjective this study makes three key contributions. Firstly, we created a\nmanually annotated dataset in the education domain, named EDU-NER-2025, which\ncontains 13 unique most important entities related to education domain. Second,\nwe describe our annotation process and guidelines in detail and discuss the\nchallenges of labelling EDU-NER-2025 dataset. Third, we addressed and analyzed\nkey linguistic challenges, such as morphological complexity and ambiguity,\nwhich are prevalent in formal Urdu texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18142v1",
    "published_date": "2025-04-25 07:50:58 UTC",
    "updated_date": "2025-04-25 07:50:58 UTC"
  },
  {
    "arxiv_id": "2504.18114v1",
    "title": "Evaluating Evaluation Metrics -- The Mirage of Hallucination Detection",
    "authors": [
      "Atharva Kulkarni",
      "Yuan Zhang",
      "Joel Ruben Antony Moniz",
      "Xiou Ge",
      "Bo-Hsiang Tseng",
      "Dhivya Piraviperumal",
      "Swabha Swayamdipta",
      "Hong Yu"
    ],
    "abstract": "Hallucinations pose a significant obstacle to the reliability and widespread\nadoption of language models, yet their accurate measurement remains a\npersistent challenge. While many task- and domain-specific metrics have been\nproposed to assess faithfulness and factuality concerns, the robustness and\ngeneralization of these metrics are still untested. In this paper, we conduct a\nlarge-scale empirical evaluation of 6 diverse sets of hallucination detection\nmetrics across 4 datasets, 37 language models from 5 families, and 5 decoding\nmethods. Our extensive investigation reveals concerning gaps in current\nhallucination evaluation: metrics often fail to align with human judgments,\ntake an overtly myopic view of the problem, and show inconsistent gains with\nparameter scaling. Encouragingly, LLM-based evaluation, particularly with\nGPT-4, yields the best overall results, and mode-seeking decoding methods seem\nto reduce hallucinations, especially in knowledge-grounded settings. These\nfindings underscore the need for more robust metrics to understand and quantify\nhallucinations, and better strategies to mitigate them.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18114v1",
    "published_date": "2025-04-25 06:37:29 UTC",
    "updated_date": "2025-04-25 06:37:29 UTC"
  },
  {
    "arxiv_id": "2504.18113v1",
    "title": "Learning from Less: SINDy Surrogates in RL",
    "authors": [
      "Aniket Dixit",
      "Muhammad Ibrahim Khan",
      "Faizan Ahmed",
      "James Brusey"
    ],
    "abstract": "This paper introduces an approach for developing surrogate environments in\nreinforcement learning (RL) using the Sparse Identification of Nonlinear\nDynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach\nthrough extensive experiments in OpenAI Gym environments, particularly Mountain\nCar and Lunar Lander. Our results show that SINDy-based surrogate models can\naccurately capture the underlying dynamics of these environments while reducing\ncomputational costs by 20-35%. With only 75 interactions for Mountain Car and\n1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with\nmean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06\nfor LunarLander position. RL agents trained in these surrogate environments\nrequire fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs.\n1,000,000 for Lunar Lander) while achieving comparable performance to those\ntrained in the original environments, exhibiting similar convergence patterns\nand final performance metrics. This work contributes to the field of\nmodel-based RL by providing an efficient method for generating accurate,\ninterpretable surrogate environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "World Models @ ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18113v1",
    "published_date": "2025-04-25 06:34:19 UTC",
    "updated_date": "2025-04-25 06:34:19 UTC"
  },
  {
    "arxiv_id": "2505.01273v1",
    "title": "Anti-adversarial Learning: Desensitizing Prompts for Large Language Models",
    "authors": [
      "Xuan Li",
      "Zhe Yin",
      "Xiaodong Gu",
      "Beijun Shen"
    ],
    "abstract": "With the widespread use of LLMs, preserving privacy in user prompts has\nbecome crucial, as prompts risk exposing privacy and sensitive data to the\ncloud LLMs. Traditional techniques like homomorphic encryption, secure\nmulti-party computation, and federated learning face challenges due to heavy\ncomputational costs and user participation requirements, limiting their\napplicability in LLM scenarios. In this paper, we propose PromptObfus, a novel\nmethod for desensitizing LLM prompts. The core idea of PromptObfus is\n\"anti-adversarial\" learning, which perturbs privacy words in the prompt to\nobscure sensitive information while retaining the stability of model\npredictions. Specifically, PromptObfus frames prompt desensitization as a\nmasked language modeling task, replacing privacy-sensitive terms with a [MASK]\ntoken. A desensitization model is trained to generate candidate replacements\nfor each masked position. These candidates are subsequently selected based on\ngradient feedback from a surrogate model, ensuring minimal disruption to the\ntask output. We demonstrate the effectiveness of our approach on three NLP\ntasks. Results show that PromptObfus effectively prevents privacy inference\nfrom remote LLMs while preserving task performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.01273v1",
    "published_date": "2025-04-25 06:19:02 UTC",
    "updated_date": "2025-04-25 06:19:02 UTC"
  },
  {
    "arxiv_id": "2504.18104v1",
    "title": "Application and Optimization of Large Models Based on Prompt Tuning for Fact-Check-Worthiness Estimation",
    "authors": [
      "Yinglong Yu",
      "Hao Shen",
      "Zhengyi Lyu",
      "Qi He"
    ],
    "abstract": "In response to the growing problem of misinformation in the context of\nglobalization and informatization, this paper proposes a classification method\nfor fact-check-worthiness estimation based on prompt tuning. We construct a\nmodel for fact-check-worthiness estimation at the methodological level using\nprompt tuning. By applying designed prompt templates to large language models,\nwe establish in-context learning and leverage prompt tuning technology to\nimprove the accuracy of determining whether claims have fact-check-worthiness,\nparticularly when dealing with limited or unlabeled data. Through extensive\nexperiments on public datasets, we demonstrate that the proposed method\nsurpasses or matches multiple baseline methods in the classification task of\nfact-check-worthiness estimation assessment, including classical pre-trained\nmodels such as BERT, as well as recent popular large models like GPT-3.5 and\nGPT-4. Experiments show that the prompt tuning-based method proposed in this\nstudy exhibits certain advantages in evaluation metrics such as F1 score and\naccuracy, thereby effectively validating its effectiveness and advancement in\nthe task of fact-check-worthiness estimation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18104v1",
    "published_date": "2025-04-25 06:16:41 UTC",
    "updated_date": "2025-04-25 06:16:41 UTC"
  },
  {
    "arxiv_id": "2504.18096v1",
    "title": "Combating the Bucket Effect:Multi-Knowledge Alignment for Medication Recommendation",
    "authors": [
      "Xiang Li",
      "Haixu Ma",
      "Guanyong Wu",
      "Shi Mu",
      "Chen Li",
      "Shunpan Liang"
    ],
    "abstract": "Medication recommendation is crucial in healthcare, offering effective\ntreatments based on patient's electronic health records (EHR). Previous studies\nshow that integrating more medication-related knowledge improves medication\nrepresentation accuracy. However, not all medications encompass multiple types\nof knowledge data simultaneously. For instance, some medications provide only\ntextual descriptions without structured data. This imbalance in data\navailability limits the performance of existing models, a challenge we term the\n\"bucket effect\" in medication recommendation. Our data analysis uncovers the\nseverity of the \"bucket effect\" in medication recommendation. To fill this gap,\nwe introduce a cross-modal medication encoder capable of seamlessly aligning\ndata from different modalities and propose a medication recommendation\nframework to integrate Multiple types of Knowledge, named MKMed. Specifically,\nwe first pre-train a cross-modal encoder with contrastive learning on five\nknowledge modalities, aligning them into a unified space. Then, we combine the\nmulti-knowledge medication representations with patient records for\nrecommendations. Extensive experiments on the MIMIC-III and MIMIC-IV datasets\ndemonstrate that MKMed mitigates the \"bucket effect\" in data, and significantly\noutperforms state-of-the-art baselines in recommendation accuracy and safety.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18096v1",
    "published_date": "2025-04-25 05:47:15 UTC",
    "updated_date": "2025-04-25 05:47:15 UTC"
  },
  {
    "arxiv_id": "2504.18085v1",
    "title": "Random-Set Large Language Models",
    "authors": [
      "Muhammad Mubashar",
      "Shireen Kudukkil Manchingal",
      "Fabio Cuzzolin"
    ],
    "abstract": "Large Language Models (LLMs) are known to produce very high-quality tests and\nresponses to our queries. But how much can we trust this generated text? In\nthis paper, we study the problem of uncertainty quantification in LLMs. We\npropose a novel Random-Set Large Language Model (RSLLM) approach which predicts\nfinite random sets (belief functions) over the token space, rather than\nprobability vectors as in classical LLMs. In order to allow so efficiently, we\nalso present a methodology based on hierarchical clustering to extract and use\na budget of \"focal\" subsets of tokens upon which the belief prediction is\ndefined, rather than using all possible collections of tokens, making the\nmethod scalable yet effective. RS-LLMs encode the epistemic uncertainty induced\nin their generation process by the size and diversity of its training set via\nthe size of the credal sets associated with the predicted belief functions. The\nproposed approach is evaluated on CoQA and OBQA datasets using Llama2-7b,\nMistral-7b and Phi-2 models and is shown to outperform the standard model in\nboth datasets in terms of correctness of answer while also showing potential in\nestimating the second level uncertainty in its predictions and providing the\ncapability to detect when its hallucinating.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18085v1",
    "published_date": "2025-04-25 05:25:27 UTC",
    "updated_date": "2025-04-25 05:25:27 UTC"
  },
  {
    "arxiv_id": "2504.18082v1",
    "title": "Efficient GNN Training Through Structure-Aware Randomized Mini-Batching",
    "authors": [
      "Vignesh Balaji",
      "Christos Kozyrakis",
      "Gal Chechik",
      "Haggai Maron"
    ],
    "abstract": "Graph Neural Networks (GNNs) enable learning on realworld graphs and\nmini-batch training has emerged as the de facto standard for training GNNs\nbecause it can scale to very large graphs and improve convergence. Current\nmini-batch construction policies largely ignore efficiency considerations of\nGNN training. Specifically, existing mini-batching techniques employ\nrandomization schemes to improve accuracy and convergence. However, these\nrandomization schemes are often agnostic to the structural properties of the\ngraph (for eg. community structure), resulting in highly irregular memory\naccess patterns during GNN training that make suboptimal use of on-chip GPU\ncaches. On the other hand, while deterministic mini-batching based solely on\ngraph structure delivers fast runtime performance, the lack of randomness\ncompromises both the final model accuracy and training convergence speed. In\nthis paper, we present Community-structure-aware Randomized Mini-batching\n(COMM-RAND), a novel methodology that bridges the gap between the above\nextremes. COMM-RAND allows practitioners to explore the space between pure\nrandomness and pure graph structural awareness during mini-batch construction,\nleading to significantly more efficient GNN training with similar accuracy. We\nevaluated COMM-RAND across four popular graph learning benchmarks. COMM-RAND\ncuts down GNN training time by up to 2.76x (1.8x on average) while achieving an\naccuracy that is within 1.79% points (0.42% on average) compared to popular\nrandom mini-batching approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18082v1",
    "published_date": "2025-04-25 05:16:53 UTC",
    "updated_date": "2025-04-25 05:16:53 UTC"
  },
  {
    "arxiv_id": "2504.18080v1",
    "title": "Stabilizing Reasoning in Medical LLMs with Continued Pretraining and Reasoning Preference Optimization",
    "authors": [
      "Wataru Kawakami",
      "Keita Suzuki",
      "Junichiro Iwasawa"
    ],
    "abstract": "Large Language Models (LLMs) show potential in medicine, yet clinical\nadoption is hindered by concerns over factual accuracy, language-specific\nlimitations (e.g., Japanese), and critically, their reliability when required\nto generate reasoning explanations -- a prerequisite for trust. This paper\nintroduces Preferred-MedLLM-Qwen-72B, a 72B-parameter model optimized for the\nJapanese medical domain to achieve both high accuracy and stable reasoning. We\nemploy a two-stage fine-tuning process on the Qwen2.5-72B base model: first,\nContinued Pretraining (CPT) on a comprehensive Japanese medical corpus instills\ndeep domain knowledge. Second, Reasoning Preference Optimization (RPO), a\npreference-based method, enhances the generation of reliable reasoning pathways\nwhile preserving high answer accuracy. Evaluations on the Japanese Medical\nLicensing Exam benchmark (IgakuQA) show Preferred-MedLLM-Qwen-72B achieves\nstate-of-the-art performance (0.868 accuracy), surpassing strong proprietary\nmodels like GPT-4o (0.866). Crucially, unlike baseline or CPT-only models which\nexhibit significant accuracy degradation (up to 11.5\\% and 3.8\\% respectively\non IgakuQA) when prompted for explanations, our model maintains its high\naccuracy (0.868) under such conditions. This highlights RPO's effectiveness in\nstabilizing reasoning generation. This work underscores the importance of\noptimizing for reliable explanations alongside accuracy. We release the\nPreferred-MedLLM-Qwen-72B model weights to foster research into trustworthy\nLLMs for specialized, high-stakes applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18080v1",
    "published_date": "2025-04-25 05:15:31 UTC",
    "updated_date": "2025-04-25 05:15:31 UTC"
  },
  {
    "arxiv_id": "2504.18078v2",
    "title": "Privacy-Preserving Personalized Federated Learning for Distributed Photovoltaic Disaggregation under Statistical Heterogeneity",
    "authors": [
      "Xiaolu Chen",
      "Chenghao Huang",
      "Yanru Zhang",
      "Hao Wang"
    ],
    "abstract": "The rapid expansion of distributed photovoltaic (PV) installations worldwide,\nmany being behind-the-meter systems, has significantly challenged energy\nmanagement and grid operations, as unobservable PV generation further\ncomplicates the supply-demand balance. Therefore, estimating this generation\nfrom net load, known as PV disaggregation, is critical. Given privacy concerns\nand the need for large training datasets, federated learning becomes a\npromising approach, but statistical heterogeneity, arising from geographical\nand behavioral variations among prosumers, poses new challenges to PV\ndisaggregation. To overcome these challenges, a privacy-preserving distributed\nPV disaggregation framework is proposed using Personalized Federated Learning\n(PFL). The proposed method employs a two-level framework that combines local\nand global modeling. At the local level, a transformer-based PV disaggregation\nmodel is designed to generate solar irradiance embeddings for representing\nlocal PV conditions. A novel adaptive local aggregation mechanism is adopted to\nmitigate the impact of statistical heterogeneity on the local model, extracting\na portion of global information that benefits the local model. At the global\nlevel, a central server aggregates information uploaded from multiple data\ncenters, preserving privacy while enabling cross-center knowledge sharing.\nExperiments on real-world data demonstrate the effectiveness of this proposed\nframework, showing improved accuracy and robustness compared to benchmark\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.18078v2",
    "published_date": "2025-04-25 05:09:27 UTC",
    "updated_date": "2025-05-22 06:55:52 UTC"
  },
  {
    "arxiv_id": "2504.18070v1",
    "title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths",
    "authors": [
      "Jingjin Wang"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has become the standard non-parametric\napproach for equipping Large Language Models (LLMs) with up-to-date knowledge\nand mitigating catastrophic forgetting common in continual learning. However,\nstandard RAG, relying on independent passage retrieval, fails to capture the\ninterconnected nature of human memory crucial for complex reasoning\n(associativity) and contextual understanding (sense-making). While structured\nRAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples,\nthe inherent context loss limits fidelity. We introduce PropRAG, a framework\nleveraging contextually rich propositions and a novel beam search algorithm\nover proposition paths to explicitly discover multi-step reasoning chains.\nCrucially, PropRAG's online retrieval process operates entirely without\ninvoking generative LLMs, relying instead on efficient graph traversal and\npre-computed embeddings. This avoids online LLM inference costs and potential\ninconsistencies during evidence gathering. LLMs are used effectively offline\nfor high-quality proposition extraction and post-retrieval for answer\ngeneration. PropRAG achieves state-of-the-art zero-shot Recall@5 results on\nPopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside\ntop F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through\nricher representation and explicit, LLM-free online path finding, PropRAG\nadvances non-parametric continual learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and data to be released at:\n  https://github.com/ReLink-Inc/PropRAG",
    "pdf_url": "http://arxiv.org/pdf/2504.18070v1",
    "published_date": "2025-04-25 04:47:34 UTC",
    "updated_date": "2025-04-25 04:47:34 UTC"
  },
  {
    "arxiv_id": "2504.18068v1",
    "title": "S3MOT: Monocular 3D Object Tracking with Selective State Space Model",
    "authors": [
      "Zhuohao Yan",
      "Shaoquan Feng",
      "Xingxing Li",
      "Yuxuan Zhou",
      "Chunxi Xia",
      "Shengyu Li"
    ],
    "abstract": "Accurate and reliable multi-object tracking (MOT) in 3D space is essential\nfor advancing robotics and computer vision applications. However, it remains a\nsignificant challenge in monocular setups due to the difficulty of mining 3D\nspatiotemporal associations from 2D video streams. In this work, we present\nthree innovative techniques to enhance the fusion and exploitation of\nheterogeneous cues for monocular 3D MOT: (1) we introduce the Hungarian State\nSpace Model (HSSM), a novel data association mechanism that compresses\ncontextual tracking cues across multiple paths, enabling efficient and\ncomprehensive assignment decisions with linear complexity. HSSM features a\nglobal receptive field and dynamic weights, in contrast to traditional linear\nassignment algorithms that rely on hand-crafted association costs. (2) We\npropose Fully Convolutional One-stage Embedding (FCOE), which eliminates ROI\npooling by directly using dense feature maps for contrastive learning, thus\nimproving object re-identification accuracy under challenging conditions such\nas varying viewpoints and lighting. (3) We enhance 6-DoF pose estimation\nthrough VeloSSM, an encoder-decoder architecture that models temporal\ndependencies in velocity to capture motion dynamics, overcoming the limitations\nof frame-based 3D inference. Experiments on the KITTI public test benchmark\ndemonstrate the effectiveness of our method, achieving a new state-of-the-art\nperformance of 76.86~HOTA at 31~FPS. Our approach outperforms the previous best\nby significant margins of +2.63~HOTA and +3.62~AssA, showcasing its robustness\nand efficiency for monocular 3D MOT tasks. The code and models are available at\nhttps://github.com/bytepioneerX/s3mot.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18068v1",
    "published_date": "2025-04-25 04:45:35 UTC",
    "updated_date": "2025-04-25 04:45:35 UTC"
  },
  {
    "arxiv_id": "2504.18062v2",
    "title": "LLM-hRIC: LLM-empowered Hierarchical RAN Intelligent Control for O-RAN",
    "authors": [
      "Lingyan Bao",
      "Sinwoong Yun",
      "Jemin Lee",
      "Tony Q. S. Quek"
    ],
    "abstract": "Despite recent advances in applying large language models (LLMs) and machine\nlearning (ML) techniques to open radio access network (O-RAN), critical\nchallenges remain, such as insufficient cooperation between radio access\nnetwork (RAN) intelligent controllers (RICs), high computational demands\nhindering real-time decisions, and the lack of domain-specific finetuning.\nTherefore, this article introduces the LLM-empowered hierarchical RIC\n(LLM-hRIC) framework to improve the collaboration between RICs in O-RAN. The\nLLM-empowered non-real-time RIC (non-RT RIC) acts as a guider, offering a\nstrategic guidance to the near-real-time RIC (near-RT RIC) using global network\ninformation. The RL-empowered near-RT RIC acts as an implementer, combining\nthis guidance with local real-time data to make near-RT decisions. We evaluate\nthe feasibility and performance of the LLM-hRIC framework in an integrated\naccess and backhaul (IAB) network setting, and finally, discuss the open\nchallenges of the LLM-hRIC framework for O-RAN.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18062v2",
    "published_date": "2025-04-25 04:18:23 UTC",
    "updated_date": "2025-05-20 07:43:35 UTC"
  },
  {
    "arxiv_id": "2504.18058v1",
    "title": "Exploring Personality-Aware Interactions in Salesperson Dialogue Agents",
    "authors": [
      "Sijia Cheng",
      "Wen-Yu Chang",
      "Yun-Nung Chen"
    ],
    "abstract": "The integration of dialogue agents into the sales domain requires a deep\nunderstanding of how these systems interact with users possessing diverse\npersonas. This study explores the influence of user personas, defined using the\nMyers-Briggs Type Indicator (MBTI), on the interaction quality and performance\nof sales-oriented dialogue agents. Through large-scale testing and analysis, we\nassess the pre-trained agent's effectiveness, adaptability, and personalization\ncapabilities across a wide range of MBTI-defined user types. Our findings\nreveal significant patterns in interaction dynamics, task completion rates, and\ndialogue naturalness, underscoring the future potential for dialogue agents to\nrefine their strategies to better align with varying personality traits. This\nwork not only provides actionable insights for building more adaptive and\nuser-centric conversational systems in the sales domain but also contributes\nbroadly to the field by releasing persona-defined user simulators. These\nsimulators, unconstrained by domain, offer valuable tools for future research\nand demonstrate the potential for scaling personalized dialogue systems across\ndiverse applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IWSDS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18058v1",
    "published_date": "2025-04-25 04:10:25 UTC",
    "updated_date": "2025-04-25 04:10:25 UTC"
  },
  {
    "arxiv_id": "2504.18057v1",
    "title": "Opportunistic Collaborative Planning with Large Vision Model Guided Control and Joint Query-Service Optimization",
    "authors": [
      "Jiayi Chen",
      "Shuai Wang",
      "Guoliang Li",
      "Wei Xu",
      "Guangxu Zhu",
      "Derrick Wing Kwan Ng",
      "Chengzhong Xu"
    ],
    "abstract": "Navigating autonomous vehicles in open scenarios is a challenge due to the\ndifficulties in handling unseen objects. Existing solutions either rely on\nsmall models that struggle with generalization or large models that are\nresource-intensive. While collaboration between the two offers a promising\nsolution, the key challenge is deciding when and how to engage the large model.\nTo address this issue, this paper proposes opportunistic collaborative planning\n(OCP), which seamlessly integrates efficient local models with powerful cloud\nmodels through two key innovations. First, we propose large vision model guided\nmodel predictive control (LVM-MPC), which leverages the cloud for LVM\nperception and decision making. The cloud output serves as a global guidance\nfor a local MPC, thereby forming a closed-loop perception-to-control system.\nSecond, to determine the best timing for large model query and service, we\npropose collaboration timing optimization (CTO), including object detection\nconfidence thresholding (ODCT) and cloud forward simulation (CFS), to decide\nwhen to seek cloud assistance and when to offer cloud service. Extensive\nexperiments show that the proposed OCP outperforms existing methods in terms of\nboth navigation time and success rate.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18057v1",
    "published_date": "2025-04-25 04:07:21 UTC",
    "updated_date": "2025-04-25 04:07:21 UTC"
  },
  {
    "arxiv_id": "2504.20077v1",
    "title": "Edge-Based Learning for Improved Classification Under Adversarial Noise",
    "authors": [
      "Manish Kansana",
      "Keyan Alexander Rahimi",
      "Elias Hossain",
      "Iman Dehzangi",
      "Noorbakhsh Amiri Golilarz"
    ],
    "abstract": "Adversarial noise introduces small perturbations in images, misleading deep\nlearning models into misclassification and significantly impacting recognition\naccuracy. In this study, we analyzed the effects of Fast Gradient Sign Method\n(FGSM) adversarial noise on image classification and investigated whether\ntraining on specific image features can improve robustness. We hypothesize that\nwhile adversarial noise perturbs various regions of an image, edges may remain\nrelatively stable and provide essential structural information for\nclassification. To test this, we conducted a series of experiments using brain\ntumor and COVID datasets. Initially, we trained the models on clean images and\nthen introduced subtle adversarial perturbations, which caused deep learning\nmodels to significantly misclassify the images. Retraining on a combination of\nclean and noisy images led to improved performance. To evaluate the robustness\nof the edge features, we extracted edges from the original/clean images and\ntrained the models exclusively on edge-based representations. When noise was\nintroduced to the images, the edge-based models demonstrated greater resilience\nto adversarial attacks compared to those trained on the original or clean\nimages. These results suggest that while adversarial noise is able to exploit\ncomplex non-edge regions significantly more than edges, the improvement in the\naccuracy after retraining is marginally more in the original data as compared\nto the edges. Thus, leveraging edge-based learning can improve the resilience\nof deep learning models against adversarial perturbations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.20077v1",
    "published_date": "2025-04-25 04:04:59 UTC",
    "updated_date": "2025-04-25 04:04:59 UTC"
  },
  {
    "arxiv_id": "2504.18050v1",
    "title": "Validating Network Protocol Parsers with Traceable RFC Document Interpretation",
    "authors": [
      "Mingwei Zheng",
      "Danning Xie",
      "Qingkai Shi",
      "Chengpeng Wang",
      "Xiangyu Zhang"
    ],
    "abstract": "Validating the correctness of network protocol implementations is highly\nchallenging due to the oracle and traceability problems. The former determines\nwhen a protocol implementation can be considered buggy, especially when the\nbugs do not cause any observable symptoms. The latter allows developers to\nunderstand how an implementation violates the protocol specification, thereby\nfacilitating bug fixes. Unlike existing works that rarely take both problems\ninto account, this work considers both and provides an effective solution using\nrecent advances in large language models (LLMs). Our key observation is that\nnetwork protocols are often released with structured specification documents,\na.k.a. RFC documents, which can be systematically translated to formal protocol\nmessage specifications via LLMs. Such specifications, which may contain errors\ndue to the hallucination of LLMs, are used as a quasi-oracle to validate\nprotocol parsers, while the validation results in return gradually refine the\noracle. Since the oracle is derived from the document, any bugs we find in a\nprotocol implementation can be traced back to the document, thus addressing the\ntraceability problem. We have extensively evaluated our approach using nine\nnetwork protocols and their implementations written in C, Python, and Go. The\nresults show that our approach outperforms the state-of-the-art and has\ndetected 69 bugs, with 36 confirmed. The project also demonstrates the\npotential for fully automating software validation based on natural language\nspecifications, a process previously considered predominantly manual due to the\nneed to understand specification documents and derive expected outputs for test\ninputs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18050v1",
    "published_date": "2025-04-25 03:39:19 UTC",
    "updated_date": "2025-04-25 03:39:19 UTC"
  },
  {
    "arxiv_id": "2504.18049v1",
    "title": "A BERT-Style Self-Supervised Learning CNN for Disease Identification from Retinal Images",
    "authors": [
      "Xin Li",
      "Wenhui Zhu",
      "Peijie Qiu",
      "Oana M. Dumitrascu",
      "Amal Youssef",
      "Yalin Wang"
    ],
    "abstract": "In the field of medical imaging, the advent of deep learning, especially the\napplication of convolutional neural networks (CNNs) has revolutionized the\nanalysis and interpretation of medical images. Nevertheless, deep learning\nmethods usually rely on large amounts of labeled data. In medical imaging\nresearch, the acquisition of high-quality labels is both expensive and\ndifficult. The introduction of Vision Transformers (ViT) and self-supervised\nlearning provides a pre-training strategy that utilizes abundant unlabeled\ndata, effectively alleviating the label acquisition challenge while broadening\nthe breadth of data utilization. However, ViT's high computational density and\nsubstantial demand for computing power, coupled with the lack of localization\ncharacteristics of its operations on image patches, limit its efficiency and\napplicability in many application scenarios. In this study, we employ\nnn-MobileNet, a lightweight CNN framework, to implement a BERT-style\nself-supervised learning approach. We pre-train the network on the unlabeled\nretinal fundus images from the UK Biobank to improve downstream application\nperformance. We validate the results of the pre-trained model on Alzheimer's\ndisease (AD), Parkinson's disease (PD), and various retinal diseases\nidentification. The results show that our approach can significantly improve\nperformance in the downstream tasks. In summary, this study combines the\nbenefits of CNNs with the capabilities of advanced self-supervised learning in\nhandling large-scale unlabeled data, demonstrating the potential of CNNs in the\npresence of label scarcity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18049v1",
    "published_date": "2025-04-25 03:38:55 UTC",
    "updated_date": "2025-04-25 03:38:55 UTC"
  },
  {
    "arxiv_id": "2504.18046v1",
    "title": "DMS-Net:Dual-Modal Multi-Scale Siamese Network for Binocular Fundus Image Classification",
    "authors": [
      "Guohao Huo",
      "Zibo Lin",
      "Zitong Wang",
      "Ruiting Dai",
      "Hao Tang"
    ],
    "abstract": "Ophthalmic diseases pose a significant global health challenge, yet\ntraditional diagnosis methods and existing single-eye deep learning approaches\noften fail to account for binocular pathological correlations. To address this,\nwe propose DMS-Net, a dual-modal multi-scale Siamese network for binocular\nfundus image classification. Our framework leverages weight-shared Siamese\nResNet-152 backbones to extract deep semantic features from paired fundus\nimages. To tackle challenges such as lesion boundary ambiguity and scattered\npathological distributions, we introduce a Multi-Scale Context-Aware Module\n(MSCAM) that integrates adaptive pooling and attention mechanisms for\nmulti-resolution feature aggregation. Additionally, a Dual-Modal Feature Fusion\n(DMFF) module enhances cross-modal interaction through spatial-semantic\nrecalibration and bidirectional attention, effectively combining global context\nand local edge features. Evaluated on the ODIR-5K dataset, DMS-Net achieves\nstate-of-the-art performance with 80.5% accuracy, 86.1% recall, and 83.8%\nCohen's kappa, demonstrating superior capability in detecting symmetric\npathologies and advancing clinical decision-making for ocular diseases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18046v1",
    "published_date": "2025-04-25 03:27:28 UTC",
    "updated_date": "2025-04-25 03:27:28 UTC"
  },
  {
    "arxiv_id": "2504.18044v1",
    "title": "AI Ethics and Social Norms: Exploring ChatGPT's Capabilities From What to How",
    "authors": [
      "Omid Veisi",
      "Sasan Bahrami",
      "Roman Englert",
      "Claudia Müller"
    ],
    "abstract": "Using LLMs in healthcare, Computer-Supported Cooperative Work, and Social\nComputing requires the examination of ethical and social norms to ensure safe\nincorporation into human life. We conducted a mixed-method study, including an\nonline survey with 111 participants and an interview study with 38 experts, to\ninvestigate the AI ethics and social norms in ChatGPT as everyday life tools.\nThis study aims to evaluate whether ChatGPT in an empirical context operates\nfollowing ethics and social norms, which is critical for understanding actions\nin industrial and academic research and achieving machine ethics. The findings\nof this study provide initial insights into six important aspects of AI ethics,\nincluding bias, trustworthiness, security, toxicology, social norms, and\nethical data. Significant obstacles related to transparency and bias in\nunsupervised data collection methods are identified as ChatGPT's ethical\nconcerns.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for presentation at the ACM Conference on Computer-Supported\n  Cooperative Work and Social Computing (CSCW) 2025. To appear in Proceedings\n  of the ACM on Human-Computer Interaction (PACM HCI)",
    "pdf_url": "http://arxiv.org/pdf/2504.18044v1",
    "published_date": "2025-04-25 03:26:30 UTC",
    "updated_date": "2025-04-25 03:26:30 UTC"
  },
  {
    "arxiv_id": "2504.18041v1",
    "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models",
    "authors": [
      "Bang An",
      "Shiyue Zhang",
      "Mark Dredze"
    ],
    "abstract": "Efforts to ensure the safety of large language models (LLMs) include safety\nfine-tuning, evaluation, and red teaming. However, despite the widespread use\nof the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses\non standard LLMs, which means we know little about how RAG use cases change a\nmodel's safety profile. We conduct a detailed comparative analysis of RAG and\nnon-RAG frameworks with eleven LLMs. We find that RAG can make models less safe\nand change their safety profile. We explore the causes of this change and find\nthat even combinations of safe models with safe documents can cause unsafe\ngenerations. In addition, we evaluate some existing red teaming methods for RAG\nsettings and show that they are less effective than when used for non-RAG\nsettings. Our work highlights the need for safety research and red-teaming\nmethods specifically tailored for RAG LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.18041v1",
    "published_date": "2025-04-25 03:25:18 UTC",
    "updated_date": "2025-04-25 03:25:18 UTC"
  },
  {
    "arxiv_id": "2504.18039v2",
    "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind",
    "authors": [
      "Zheng Zhang",
      "Nuoqian Xiao",
      "Qi Chai",
      "Deheng Ye",
      "Hao Wang"
    ],
    "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin social deduction games (SDGs) like Werewolf, where strategic reasoning and\nsocial deception are essential. However, current approaches remain limited to\ntextual information, ignoring crucial multimodal cues such as facial\nexpressions and tone of voice that humans naturally use to communicate.\nMoreover, existing SDG agents primarily focus on inferring other players'\nidentities without modeling how others perceive themselves or fellow players.\nTo address these limitations, we use One Night Ultimate Werewolf (ONUW) as a\ntestbed and present MultiMind, the first framework integrating multimodal\ninformation into SDG agents. MultiMind processes facial expressions and vocal\ntones alongside verbal content, while employing a Theory of Mind (ToM) model to\nrepresent each player's suspicion levels toward others. By combining this ToM\nmodel with Monte Carlo Tree Search (MCTS), our agent identifies communication\nstrategies that minimize suspicion directed at itself. Through comprehensive\nevaluation in both agent-versus-agent simulations and studies with human\nplayers, we demonstrate MultiMind's superior performance in gameplay. Our work\npresents a significant advancement toward LLM agents capable of human-like\nsocial reasoning across multimodal domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18039v2",
    "published_date": "2025-04-25 03:12:43 UTC",
    "updated_date": "2025-05-08 17:34:57 UTC"
  },
  {
    "arxiv_id": "2505.00024v2",
    "title": "Nemotron-Research-Tool-N1: Exploring Tool-Using Language Models with Reinforced Reasoning",
    "authors": [
      "Shaokun Zhang",
      "Yi Dong",
      "Jieyu Zhang",
      "Jan Kautz",
      "Bryan Catanzaro",
      "Andrew Tao",
      "Qingyun Wu",
      "Zhiding Yu",
      "Guilin Liu"
    ],
    "abstract": "Enabling large language models with external tools has become a pivotal\nstrategy for extending their functionality beyond text space. To enhance LLMs'\ntool-calling abilities, previous approaches primarily rely on supervised\nfine-tuning (SFT) with trajectories distilled from stronger models, often\nresulting in imitative reasoning that limits generalization. In this work, we\nexplore rule-based reinforcement learning to enhance tool-calling in LLMs,\nresulting in Nemotron-Research-Tool-N1, a series of tool-calling reasoning\nmodels. Rather than enforcing supervision over intermediate distilled reasoning\ntraces, Tool-N1 is trained with a binary RL reward that assesses only the\nformat validity and functional correctness of tool invocations. This\nlightweight supervision allows the model to develop reasoning strategies\nindependently, without relying on annotated trajectories. Experiments on\nseveral major benchmarks show that Tool-N1-7B/14B clearly outperform GPT-4o. We\nconduct a systematic study on the design of rule-based reinforcement learning\nstrategies for training tool-calling models. Using 5,518 distilled reasoning\ntrajectories, we compare SFT, RL, and the SFT-then-RL pipeline, finding that\nthe widely adopted SFT-then-RL paradigm does not necessarily outperform pure\nRL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 6 tables, 12 figures. - update new results - add more\n  details",
    "pdf_url": "http://arxiv.org/pdf/2505.00024v2",
    "published_date": "2025-04-25 02:55:21 UTC",
    "updated_date": "2025-05-12 03:01:39 UTC"
  },
  {
    "arxiv_id": "2504.18027v1",
    "title": "A Large Vision-Language Model based Environment Perception System for Visually Impaired People",
    "authors": [
      "Zezhou Chen",
      "Zhaoxiang Liu",
      "Kai Wang",
      "Kohou Wang",
      "Shiguo Lian"
    ],
    "abstract": "It is a challenging task for visually impaired people to perceive their\nsurrounding environment due to the complexity of the natural scenes. Their\npersonal and social activities are thus highly limited. This paper introduces a\nLarge Vision-Language Model(LVLM) based environment perception system which\nhelps them to better understand the surrounding environment, by capturing the\ncurrent scene they face with a wearable device, and then letting them retrieve\nthe analysis results through the device. The visually impaired people could\nacquire a global description of the scene by long pressing the screen to\nactivate the LVLM output, retrieve the categories of the objects in the scene\nresulting from a segmentation model by tapping or swiping the screen, and get a\ndetailed description of the objects they are interested in by double-tapping\nthe screen. To help visually impaired people more accurately perceive the\nworld, this paper proposes incorporating the segmentation result of the RGB\nimage as external knowledge into the input of LVLM to reduce the LVLM's\nhallucination. Technical experiments on POPE, MME and LLaVA-QA90 show that the\nsystem could provide a more accurate description of the scene compared to\nQwen-VL-Chat, exploratory experiments show that the system helps visually\nimpaired people to perceive the surrounding environment effectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IROS2024(9 pages, 8 figures)",
    "pdf_url": "http://arxiv.org/pdf/2504.18027v1",
    "published_date": "2025-04-25 02:46:22 UTC",
    "updated_date": "2025-04-25 02:46:22 UTC"
  },
  {
    "arxiv_id": "2504.18026v1",
    "title": "Addressing Concept Mislabeling in Concept Bottleneck Models Through Preference Optimization",
    "authors": [
      "Emiliano Penaloza",
      "Tianyue H. Zhan",
      "Laurent Charlin",
      "Mateo Espinosa Zarlenga"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) propose to enhance the trustworthiness of AI\nsystems by constraining their decisions on a set of human understandable\nconcepts. However, CBMs typically assume that datasets contains accurate\nconcept labels an assumption often violated in practice, which we show can\nsignificantly degrade performance (by 25% in some cases). To address this, we\nintroduce the Concept Preference Optimization (CPO) objective, a new loss\nfunction based on Direct Preference Optimization, which effectively mitigates\nthe negative impact of concept mislabeling on CBM performance. We provide an\nanalysis on some key properties of the CPO objective showing it directly\noptimizes for the concept's posterior distribution, and contrast it against\nBinary Cross Entropy (BCE) where we show CPO is inherently less sensitive to\nconcept noise. We empirically confirm our analysis finding that CPO\nconsistently outperforms BCE in three real world datasets with and without\nadded label noise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18026v1",
    "published_date": "2025-04-25 02:43:10 UTC",
    "updated_date": "2025-04-25 02:43:10 UTC"
  },
  {
    "arxiv_id": "2504.21028v1",
    "title": "Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings",
    "authors": [
      "Ivan Montoya Sanchez",
      "Shaswata Mitra",
      "Aritran Piplai",
      "Sudip Mittal"
    ],
    "abstract": "The rapid evolution of malware variants requires robust classification\nmethods to enhance cybersecurity. While Large Language Models (LLMs) offer\npotential for generating malware descriptions to aid family classification,\ntheir utility is limited by semantic embedding overlaps and misalignment with\nbinary behavioral features. We propose a contrastive fine-tuning (CFT) method\nthat refines LLM embeddings via targeted selection of hard negative samples\nbased on cosine similarity, enabling LLMs to distinguish between closely\nrelated malware families. Our approach combines high-similarity negatives to\nenhance discriminative power and mid-tier negatives to increase embedding\ndiversity, optimizing both precision and generalization. Evaluated on the\nCIC-AndMal-2020 and BODMAS datasets, our refined embeddings are integrated into\na multimodal classifier within a Model-Agnostic Meta-Learning (MAML) framework\non a few-shot setting. Experiments demonstrate significant improvements: our\nmethod achieves 63.15% classification accuracy with as few as 20 samples on\nCIC-AndMal-2020, outperforming baselines by 11--21 percentage points and\nsurpassing prior negative sampling strategies. Ablation studies confirm the\nsuperiority of similarity-based selection over random sampling, with gains of\n10-23%. Additionally, fine-tuned LLMs generate attribute-aware descriptions\nthat generalize to unseen variants, bridging textual and binary feature gaps.\nThis work advances malware classification by enabling nuanced semantic\ndistinctions and provides a scalable framework for adapting LLMs to\ncybersecurity challenges.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.21028v1",
    "published_date": "2025-04-25 02:41:45 UTC",
    "updated_date": "2025-04-25 02:41:45 UTC"
  },
  {
    "arxiv_id": "2505.00023v1",
    "title": "CORG: Generating Answers from Complex, Interrelated Contexts",
    "authors": [
      "Hyunji Lee",
      "Franck Dernoncourt",
      "Trung Bui",
      "Seunghyun Yoon"
    ],
    "abstract": "In a real-world corpus, knowledge frequently recurs across documents but\noften contains inconsistencies due to ambiguous naming, outdated information,\nor errors, leading to complex interrelationships between contexts. Previous\nresearch has shown that language models struggle with these complexities,\ntypically focusing on single factors in isolation. We classify these\nrelationships into four types: distracting, ambiguous, counterfactual, and\nduplicated. Our analysis reveals that no single approach effectively addresses\nall these interrelationships simultaneously. Therefore, we introduce Context\nOrganizer (CORG), a framework that organizes multiple contexts into\nindependently processed groups. This design allows the model to efficiently\nfind all relevant answers while ensuring disambiguation. CORG consists of three\nkey components: a graph constructor, a reranker, and an aggregator. Our results\ndemonstrate that CORG balances performance and efficiency effectively,\noutperforming existing grouping methods and achieving comparable results to\nmore computationally intensive, single-context approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "published at Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00023v1",
    "published_date": "2025-04-25 02:40:48 UTC",
    "updated_date": "2025-04-25 02:40:48 UTC"
  },
  {
    "arxiv_id": "2504.18012v1",
    "title": "Memory Reviving, Continuing Learning and Beyond: Evaluation of Pre-trained Encoders and Decoders for Multimodal Machine Translation",
    "authors": [
      "Zhuang Yu",
      "Shiliang Sun",
      "Jing Zhao",
      "Tengfei Song",
      "Hao Yang"
    ],
    "abstract": "Multimodal Machine Translation (MMT) aims to improve translation quality by\nleveraging auxiliary modalities such as images alongside textual input. While\nrecent advances in large-scale pre-trained language and vision models have\nsignificantly benefited unimodal natural language processing tasks, their\neffectiveness and role in MMT remain underexplored. In this work, we conduct a\nsystematic study on the impact of pre-trained encoders and decoders in\nmultimodal translation models. Specifically, we analyze how different training\nstrategies, from training from scratch to using pre-trained and partially\nfrozen components, affect translation performance under a unified MMT\nframework. Experiments are carried out on the Multi30K and CoMMuTE dataset\nacross English-German and English-French translation tasks. Our results reveal\nthat pre-training plays a crucial yet asymmetrical role in multimodal settings:\npre-trained decoders consistently yield more fluent and accurate outputs, while\npre-trained encoders show varied effects depending on the quality of\nvisual-text alignment. Furthermore, we provide insights into the interplay\nbetween modality fusion and pre-trained components, offering guidance for\nfuture architecture design in multimodal translation systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18012v1",
    "published_date": "2025-04-25 01:44:04 UTC",
    "updated_date": "2025-04-25 01:44:04 UTC"
  },
  {
    "arxiv_id": "2504.18010v1",
    "title": "Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation",
    "authors": [
      "Zilin Huang",
      "Zihao Sheng",
      "Zhengyang Wan",
      "Yansong Qu",
      "Yuhao Luo",
      "Boyue Wang",
      "Pei Li",
      "Yen-Jung Chen",
      "Jiancong Chen",
      "Keke Long",
      "Jiayi Meng",
      "Yue Leng",
      "Sikai Chen"
    ],
    "abstract": "Recent advances in autonomous system simulation platforms have significantly\nenhanced the safe and scalable testing of driving policies. However, existing\nsimulators do not yet fully meet the needs of future transportation research,\nparticularly in modeling socially-aware driving agents and enabling effective\nhuman-AI collaboration. This paper introduces Sky-Drive, a novel distributed\nmulti-agent simulation platform that addresses these limitations through four\nkey innovations: (a) a distributed architecture for synchronized simulation\nacross multiple terminals; (b) a multi-modal human-in-the-loop framework\nintegrating diverse sensors to collect rich behavioral data; (c) a human-AI\ncollaboration mechanism supporting continuous and adaptive knowledge exchange;\nand (d) a digital twin (DT) framework for constructing high-fidelity virtual\nreplicas of real-world transportation environments. Sky-Drive supports diverse\napplications such as autonomous vehicle (AV)-vulnerable road user (VRU)\ninteraction modeling, human-in-the-loop training, socially-aware reinforcement\nlearning, personalized driving policy, and customized scenario generation.\nFuture extensions will incorporate foundation models for context-aware decision\nsupport and hardware-in-the-loop (HIL) testing for real-world validation. By\nbridging scenario generation, data collection, algorithm training, and hardware\nintegration, Sky-Drive has the potential to become a foundational platform for\nthe next generation of socially-aware and human-centered autonomous\ntransportation research. The demo video and code are available\nat:https://sky-lab-uw.github.io/Sky-Drive-website/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18010v1",
    "published_date": "2025-04-25 01:33:26 UTC",
    "updated_date": "2025-04-25 01:33:26 UTC"
  },
  {
    "arxiv_id": "2504.18007v1",
    "title": "Differential Privacy-Driven Framework for Enhancing Heart Disease Prediction",
    "authors": [
      "Yazan Otoum",
      "Amiya Nayak"
    ],
    "abstract": "With the rapid digitalization of healthcare systems, there has been a\nsubstantial increase in the generation and sharing of private health data.\nSafeguarding patient information is essential for maintaining consumer trust\nand ensuring compliance with legal data protection regulations. Machine\nlearning is critical in healthcare, supporting personalized treatment, early\ndisease detection, predictive analytics, image interpretation, drug discovery,\nefficient operations, and patient monitoring. It enhances decision-making,\naccelerates research, reduces errors, and improves patient outcomes. In this\npaper, we utilize machine learning methodologies, including differential\nprivacy and federated learning, to develop privacy-preserving models that\nenable healthcare stakeholders to extract insights without compromising\nindividual privacy. Differential privacy introduces noise to data to guarantee\nstatistical privacy, while federated learning enables collaborative model\ntraining across decentralized datasets. We explore applying these technologies\nto Heart Disease Data, demonstrating how they preserve privacy while delivering\nvaluable insights and comprehensive analysis. Our results show that using a\nfederated learning model with differential privacy achieved a test accuracy of\n85%, ensuring patient data remained secure and private throughout the process.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "\\c{opyright} 2025 IEEE. Accepted to IEEE International Conference on\n  Communications ICC 2025. Final version to appear in IEEE Xplore",
    "pdf_url": "http://arxiv.org/pdf/2504.18007v1",
    "published_date": "2025-04-25 01:27:40 UTC",
    "updated_date": "2025-04-25 01:27:40 UTC"
  },
  {
    "arxiv_id": "2504.18604v2",
    "title": "A Cognitive-Mechanistic Human Reliability Analysis Framework: A Nuclear Power Plant Case Study",
    "authors": [
      "Xingyu Xiao",
      "Peng Chen",
      "Jiejuan Tong",
      "Shunshun Liu",
      "Hongru Zhao",
      "Jun Zhao",
      "Qianqian Jia",
      "Jingang Liang",
      "Haitao Wang"
    ],
    "abstract": "Traditional human reliability analysis (HRA) methods, such as IDHEAS-ECA,\nrely on expert judgment and empirical rules that often overlook the cognitive\nunderpinnings of human error. Moreover, conducting human-in-the-loop\nexperiments for advanced nuclear power plants is increasingly impractical due\nto novel interfaces and limited operational data. This study proposes a\ncognitive-mechanistic framework (COGMIF) that enhances the IDHEAS-ECA\nmethodology by integrating an ACT-R-based human digital twin (HDT) with\nTimeGAN-augmented simulation. The ACT-R model simulates operator cognition,\nincluding memory retrieval, goal-directed procedural reasoning, and\nperceptual-motor execution, under high-fidelity scenarios derived from a\nhigh-temperature gas-cooled reactor (HTGR) simulator. To overcome the resource\nconstraints of large-scale cognitive modeling, TimeGAN is trained on\nACT-R-generated time-series data to produce high-fidelity synthetic operator\nbehavior datasets. These simulations are then used to drive IDHEAS-ECA\nassessments, enabling scalable, mechanism-informed estimation of human error\nprobabilities (HEPs). Comparative analyses with SPAR-H and sensitivity\nassessments demonstrate the robustness and practical advantages of the proposed\nCOGMIF. Finally, procedural features are mapped onto a Bayesian network to\nquantify the influence of contributing factors, revealing key drivers of\noperational risk. This work offers a credible and computationally efficient\npathway to integrate cognitive theory into industrial HRA practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18604v2",
    "published_date": "2025-04-25 00:46:00 UTC",
    "updated_date": "2025-05-05 23:28:11 UTC"
  }
]