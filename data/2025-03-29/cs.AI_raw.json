[
  {
    "arxiv_id": "2503.23257v1",
    "title": "FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation",
    "authors": [
      "Mohammadmahdi Honarmand",
      "Onur Cezmi Mutlu",
      "Parnian Azizian",
      "Saimourya Surabhi",
      "Dennis P. Wall"
    ],
    "abstract": "Robust facial expression recognition in unconstrained, \"in-the-wild\"\nenvironments remains challenging due to significant domain shifts between\ntraining and testing distributions. Test-time adaptation (TTA) offers a\npromising solution by adapting pre-trained models during inference without\nrequiring labeled test data. However, existing TTA approaches typically rely on\nmanually selecting which parameters to update, potentially leading to\nsuboptimal adaptation and high computational costs. This paper introduces a\nnovel Fisher-driven selective adaptation framework that dynamically identifies\nand updates only the most critical model parameters based on their importance\nas quantified by Fisher information. By integrating this principled parameter\nselection approach with temporal consistency constraints, our method enables\nefficient and effective adaptation specifically tailored for video-based facial\nexpression recognition. Experiments on the challenging AffWild2 benchmark\ndemonstrate that our approach significantly outperforms existing TTA methods,\nachieving a 7.7% improvement in F1 score over the base model while adapting\nonly 22,000 parameters-more than 20 times fewer than comparable methods. Our\nablation studies further reveal that parameter importance can be effectively\nestimated from minimal data, with sampling just 1-3 frames sufficient for\nsubstantial performance gains. The proposed approach not only enhances\nrecognition accuracy but also dramatically reduces computational overhead,\nmaking test-time adaptation more practical for real-world affective computing\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23257v1",
    "published_date": "2025-03-29 23:56:32 UTC",
    "updated_date": "2025-03-29 23:56:32 UTC"
  },
  {
    "arxiv_id": "2504.03720v1",
    "title": "TransNet: Transfer Knowledge for Few-shot Knowledge Graph Completion",
    "authors": [
      "Lihui Liu",
      "Zihao Wang",
      "Dawei Zhou",
      "Ruijie Wang",
      "Yuchen Yan",
      "Bo Xiong",
      "Sihong He",
      "Kai Shu",
      "Hanghang Tong"
    ],
    "abstract": "Knowledge graphs (KGs) are ubiquitous and widely used in various\napplications. However, most real-world knowledge graphs are incomplete, which\nsignificantly degrades their performance on downstream tasks. Additionally, the\nrelationships in real-world knowledge graphs often follow a long-tail\ndistribution, meaning that most relations are represented by only a few\ntraining triplets. To address these challenges, few-shot learning has been\nintroduced. Few-shot KG completion aims to make accurate predictions for\ntriplets involving novel relations when only a limited number of training\ntriplets are available. Although many methods have been proposed, they\ntypically learn each relation individually, overlooking the correlations\nbetween different tasks and the relevant information in previously trained\ntasks. In this paper, we propose a transfer learning-based few-shot KG\ncompletion method (TransNet). By learning the relationships between different\ntasks, TransNet effectively transfers knowledge from similar tasks to improve\nthe current task's performance. Furthermore, by employing meta-learning,\nTransNet can generalize effectively to new, unseen relations. Extensive\nexperiments on benchmark datasets demonstrate the superiority of TransNet over\nstate-of-the-art methods. Code can be found at\nhttps://github.com/lihuiliullh/TransNet/tree/main",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03720v1",
    "published_date": "2025-03-29 23:39:11 UTC",
    "updated_date": "2025-03-29 23:39:11 UTC"
  },
  {
    "arxiv_id": "2503.23250v1",
    "title": "Encrypted Prompt: Securing LLM Applications Against Unauthorized Actions",
    "authors": [
      "Shih-Han Chan"
    ],
    "abstract": "Security threats like prompt injection attacks pose significant risks to\napplications that integrate Large Language Models (LLMs), potentially leading\nto unauthorized actions such as API misuse. Unlike previous approaches that aim\nto detect these attacks on a best-effort basis, this paper introduces a novel\nmethod that appends an Encrypted Prompt to each user prompt, embedding current\npermissions. These permissions are verified before executing any actions (such\nas API calls) generated by the LLM. If the permissions are insufficient, the\nLLM's actions will not be executed, ensuring safety. This approach guarantees\nthat only actions within the scope of the current permissions from the LLM can\nproceed. In scenarios where adversarial prompts are introduced to mislead the\nLLM, this method ensures that any unauthorized actions from LLM wouldn't be\nexecuted by verifying permissions in Encrypted Prompt. Thus, threats like\nprompt injection attacks that trigger LLM to generate harmful actions can be\neffectively mitigated.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23250v1",
    "published_date": "2025-03-29 23:26:57 UTC",
    "updated_date": "2025-03-29 23:26:57 UTC"
  },
  {
    "arxiv_id": "2503.23245v1",
    "title": "Simulation of Non-Ordinary Consciousness",
    "authors": [
      "Khalid M. Saqr"
    ],
    "abstract": "The symbolic architecture of non-ordinary consciousness remains largely\nunmapped in cognitive science and artificial intelligence. While conventional\nmodels prioritize rational coherence, altered states such as those induced by\npsychedelics reveal distinct symbolic regimes characterized by recursive\nmetaphor, ego dissolution, and semantic destabilization. We present\n\\textit{Glyph}, a generative symbolic interface designed to simulate\npsilocybin-like symbolic cognition in large language models. Rather than\nmodeling perception or mood, Glyph enacts symbolic transformation through\nrecursive reentry, metaphoric modulation, and entropy-scaled destabilization --\na triadic operator formalized within a tensorial linguistic framework.\nExperimental comparison with baseline GPT-4o reveals that Glyph consistently\ngenerates high-entropy, metaphor-saturated, and ego-dissolving language across\ndiverse symbolic prompt categories. These results validate the emergence of\nnon-ordinary cognitive patterns and support a new paradigm for simulating\naltered consciousness through language. Glyph opens novel pathways for modeling\nsymbolic cognition, exploring metaphor theory, and encoding knowledge in\nrecursively altered semantic spaces.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "91E45, 03B70, 00A30, 68T05",
      "I.2.4; I.2.7; I.1.1; F.4.1; H.5.2; J.5"
    ],
    "primary_category": "q-bio.NC",
    "comment": "16 pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.23245v1",
    "published_date": "2025-03-29 23:04:04 UTC",
    "updated_date": "2025-03-29 23:04:04 UTC"
  },
  {
    "arxiv_id": "2503.23243v1",
    "title": "Evaluating how LLM annotations represent diverse views on contentious topics",
    "authors": [
      "Megan A. Brown",
      "Shubham Atreja",
      "Libby Hemphill",
      "Patrick Y. Wu"
    ],
    "abstract": "Researchers have proposed the use of generative large language models (LLMs)\nto label data for both research and applied settings. This literature\nemphasizes the improved performance of LLMs relative to other natural language\nmodels, noting that LLMs typically outperform other models on standard metrics\nsuch as accuracy, precision, recall, and F1 score. However, previous literature\nhas also highlighted the bias embedded in language models, particularly around\ncontentious topics such as potentially toxic content. This bias could result in\nlabels applied by LLMs that disproportionately align with majority groups over\na more diverse set of viewpoints. In this paper, we evaluate how LLMs represent\ndiverse viewpoints on these contentious tasks. Across four annotation tasks on\nfour datasets, we show that LLMs do not show substantial disagreement with\nannotators on the basis of demographics. Instead, the model, prompt, and\ndisagreement between human annotators on the labeling task are far more\npredictive of LLM agreement. Our findings suggest that when using LLMs to\nannotate data, under-representing the views of particular groups is not a\nsubstantial concern. We conclude with a discussion of the implications for\nresearchers and practitioners.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23243v1",
    "published_date": "2025-03-29 22:53:15 UTC",
    "updated_date": "2025-03-29 22:53:15 UTC"
  },
  {
    "arxiv_id": "2503.23242v1",
    "title": "Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation",
    "authors": [
      "Dominik Macko",
      "Aashish Anantha Ramakrishnan",
      "Jason Samuel Lucas",
      "Robert Moro",
      "Ivan Srba",
      "Adaku Uchendu",
      "Dongwon Lee"
    ],
    "abstract": "Increased sophistication of large language models (LLMs) and the consequent\nquality of generated multilingual text raises concerns about potential\ndisinformation misuse. While humans struggle to distinguish LLM-generated\ncontent from human-written texts, the scholarly debate about their impact\nremains divided. Some argue that heightened fears are overblown due to natural\necosystem limitations, while others contend that specific \"longtail\" contexts\nface overlooked risks. Our study bridges this debate by providing the first\nempirical evidence of LLM presence in the latest real-world disinformation\ndatasets, documenting the increase of machine-generated content following\nChatGPT's release, and revealing crucial patterns across languages, platforms,\nand time periods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23242v1",
    "published_date": "2025-03-29 22:47:53 UTC",
    "updated_date": "2025-03-29 22:47:53 UTC"
  },
  {
    "arxiv_id": "2504.03719v2",
    "title": "Towards Symmetric Low-Rank Adapters",
    "authors": [
      "Tales Panoutsos",
      "Rodrygo L. T. Santos",
      "Flavio Figueiredo"
    ],
    "abstract": "In this paper, we introduce Symmetric Low-Rank Adapters, an optimized variant\nof LoRA with even fewer weights. This method utilizes Low-Rank Symmetric Weight\nMatrices to learn downstream tasks more efficiently. Traditional LoRA\naccumulates fine-tuning weights with the original pre-trained weights via a\nSingular Value Decomposition (SVD) like approach, i.e., model weights are\nfine-tuned via updates of the form $BA$ (where $B \\in \\mathbb{R}^{n\\times r}$,\n$A \\in \\mathbb{R}^{r\\times n}$, and $r$ is the rank of the merged weight\nmatrix). In contrast, our approach, named SymLoRA, represents fine-tuning\nweights as a Spectral Decomposition, i.e., $Q \\, diag(\\Lambda)\\, Q^T$, where $Q\n\\in \\mathbb{R}^{n\\times r}$ and $\\Lambda \\in \\mathbb{R}^r$. SymLoRA requires\napproximately half of the finetuning weights. Here, we show that this approach\nhas negligible losses in downstream efficacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Colorai Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.03719v2",
    "published_date": "2025-03-29 21:52:17 UTC",
    "updated_date": "2025-04-15 22:46:20 UTC"
  },
  {
    "arxiv_id": "2503.23231v1",
    "title": "CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models",
    "authors": [
      "Hangzhan Jin",
      "Mohammad Hamdaqa"
    ],
    "abstract": "Unlike code generation, which involves creating code from scratch, code\ncompletion focuses on integrating new lines or blocks of code into an existing\ncodebase. This process requires a deep understanding of the surrounding\ncontext, such as variable scope, object models, API calls, and database\nrelations, to produce accurate results. These complex contextual dependencies\nmake code completion a particularly challenging problem. Current models and\napproaches often fail to effectively incorporate such context, leading to\ninaccurate completions with low acceptance rates (around 30\\%). For tasks like\ndata transfer, which rely heavily on specific relationships and data\nstructures, acceptance rates drop even further. This study introduces CCCI, a\nnovel method for generating context-aware code completions specifically\ndesigned to address data transfer tasks. By integrating contextual information,\nsuch as database table relationships, object models, and library details into\nLarge Language Models (LLMs), CCCI improves the accuracy of code completions.\nWe evaluate CCCI using 289 Java snippets, extracted from over 819 operational\nscripts in an industrial setting. The results demonstrate that CCCI achieved a\n49.1\\% Build Pass rate and a 41.0\\% CodeBLEU score, comparable to\nstate-of-the-art methods that often struggle with complex task completion.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2; D.2"
    ],
    "primary_category": "cs.SE",
    "comment": "The 29th International Conference on Evaluation and Assessment in\n  Software Engineering",
    "pdf_url": "http://arxiv.org/pdf/2503.23231v1",
    "published_date": "2025-03-29 21:31:19 UTC",
    "updated_date": "2025-03-29 21:31:19 UTC"
  },
  {
    "arxiv_id": "2503.23226v1",
    "title": "Synthetic Art Generation and DeepFake Detection A Study on Jamini Roy Inspired Dataset",
    "authors": [
      "Kushal Agrawal",
      "Romi Banerjee"
    ],
    "abstract": "The intersection of generative AI and art is a fascinating area that brings\nboth exciting opportunities and significant challenges, especially when it\ncomes to identifying synthetic artworks. This study takes a unique approach by\nexamining diffusion-based generative models in the context of Indian art,\nspecifically focusing on the distinctive style of Jamini Roy. To explore this,\nwe fine-tuned Stable Diffusion 3 and used techniques like ControlNet and\nIPAdapter to generate realistic images. This allowed us to create a new dataset\nthat includes both real and AI-generated artworks, which is essential for a\ndetailed analysis of what these models can produce. We employed various\nqualitative and quantitative methods, such as Fourier domain assessments and\nautocorrelation metrics, to uncover subtle differences between synthetic images\nand authentic pieces. A key takeaway from recent research is that existing\nmethods for detecting deepfakes face considerable challenges, especially when\nthe deepfakes are of high quality and tailored to specific cultural contexts.\nThis highlights a critical gap in current detection technologies, particularly\nin light of the challenges identified above, where high-quality and culturally\nspecific deepfakes are difficult to detect. This work not only sheds light on\nthe increasing complexity of generative models but also sets a crucial\nfoundation for future research aimed at effective detection of synthetic art.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 7 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.23226v1",
    "published_date": "2025-03-29 21:12:16 UTC",
    "updated_date": "2025-03-29 21:12:16 UTC"
  },
  {
    "arxiv_id": "2503.23219v1",
    "title": "Aurelia: Test-time Reasoning Distillation in Audio-Visual LLMs",
    "authors": [
      "Sanjoy Chowdhury",
      "Hanan Gani",
      "Nishit Anand",
      "Sayan Nag",
      "Ruohan Gao",
      "Mohamed Elhoseiny",
      "Salman Khan",
      "Dinesh Manocha"
    ],
    "abstract": "Recent advancements in reasoning optimization have greatly enhanced the\nperformance of large language models (LLMs). However, existing work fails to\naddress the complexities of audio-visual scenarios, underscoring the need for\nfurther research. In this paper, we introduce AURELIA, a novel actor-critic\nbased audio-visual (AV) reasoning framework that distills structured,\nstep-by-step reasoning into AVLLMs at test time, improving their ability to\nprocess complex multi-modal inputs without additional training or fine-tuning.\nTo further advance AVLLM reasoning skills, we present AVReasonBench, a\nchallenging benchmark comprising 4500 audio-visual questions, each paired with\ndetailed step-by-step reasoning. Our benchmark spans six distinct tasks,\nincluding AV-GeoIQ, which evaluates AV reasoning combined with geographical and\ncultural knowledge. Evaluating 18 AVLLMs on AVReasonBench reveals significant\nlimitations in their multi-modal reasoning capabilities. Using AURELIA, we\nachieve up to a 100% relative improvement, demonstrating its effectiveness.\nThis performance gain highlights the potential of reasoning-enhanced data\ngeneration for advancing AVLLMs in real-world applications. Our code and data\nwill be publicly released at: https: //github.com/schowdhury671/aurelia.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23219v1",
    "published_date": "2025-03-29 20:42:29 UTC",
    "updated_date": "2025-03-29 20:42:29 UTC"
  },
  {
    "arxiv_id": "2503.23214v1",
    "title": "Action Recognition in Real-World Ambient Assisted Living Environment",
    "authors": [
      "Vincent Gbouna Zakka",
      "Zhuangzhuang Dai",
      "Luis J. Manso"
    ],
    "abstract": "The growing ageing population and their preference to maintain independence\nby living in their own homes require proactive strategies to ensure safety and\nsupport. Ambient Assisted Living (AAL) technologies have emerged to facilitate\nageing in place by offering continuous monitoring and assistance within the\nhome. Within AAL technologies, action recognition plays a crucial role in\ninterpreting human activities and detecting incidents like falls, mobility\ndecline, or unusual behaviours that may signal worsening health conditions.\nHowever, action recognition in practical AAL applications presents challenges,\nincluding occlusions, noisy data, and the need for real-time performance. While\nadvancements have been made in accuracy, robustness to noise, and computation\nefficiency, achieving a balance among them all remains a challenge. To address\nthis challenge, this paper introduces the Robust and Efficient Temporal\nConvolution network (RE-TCN), which comprises three main elements: Adaptive\nTemporal Weighting (ATW), Depthwise Separable Convolutions (DSC), and data\naugmentation techniques. These elements aim to enhance the model's accuracy,\nrobustness against noise and occlusion, and computational efficiency within\nreal-world AAL contexts. RE-TCN outperforms existing models in terms of\naccuracy, noise and occlusion robustness, and has been validated on four\nbenchmark datasets: NTU RGB+D 60, Northwestern-UCLA, SHREC'17, and DHG-14/28.\nThe code is publicly available at: https://github.com/Gbouna/RE-TCN",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23214v1",
    "published_date": "2025-03-29 20:32:22 UTC",
    "updated_date": "2025-03-29 20:32:22 UTC"
  },
  {
    "arxiv_id": "2503.23213v1",
    "title": "RECALL-MM: A Multimodal Dataset of Consumer Product Recalls for Risk Analysis using Computational Methods and Large Language Models",
    "authors": [
      "Diana Bolanos",
      "Mohammadmehdi Ataei",
      "Daniele Grandi",
      "Kosa Goucher-Lambert"
    ],
    "abstract": "Product recalls provide valuable insights into potential risks and hazards\nwithin the engineering design process, yet their full potential remains\nunderutilized. In this study, we curate data from the United States Consumer\nProduct Safety Commission (CPSC) recalls database to develop a multimodal\ndataset, RECALL-MM, that informs data-driven risk assessment using historical\ninformation, and augment it using generative methods. Patterns in the dataset\nhighlight specific areas where improved safety measures could have significant\nimpact. We extend our analysis by demonstrating interactive clustering maps\nthat embed all recalls into a shared latent space based on recall descriptions\nand product names. Leveraging these data-driven tools, we explore three case\nstudies to demonstrate the dataset's utility in identifying product risks and\nguiding safer design decisions. The first two case studies illustrate how\ndesigners can visualize patterns across recalled products and situate new\nproduct ideas within the broader recall landscape to proactively anticipate\nhazards. In the third case study, we extend our approach by employing a large\nlanguage model (LLM) to predict potential hazards based solely on product\nimages. This demonstrates the model's ability to leverage visual context to\nidentify risk factors, revealing strong alignment with historical recall data\nacross many hazard categories. However, the analysis also highlights areas\nwhere hazard prediction remains challenging, underscoring the importance of\nrisk awareness throughout the design process. Collectively, this work aims to\nbridge the gap between historical recall data and future product safety,\npresenting a scalable, data-driven approach to safer engineering design.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23213v1",
    "published_date": "2025-03-29 20:27:28 UTC",
    "updated_date": "2025-03-29 20:27:28 UTC"
  },
  {
    "arxiv_id": "2503.23205v1",
    "title": "Enhancing Knowledge Graph Completion with Entity Neighborhood and Relation Context",
    "authors": [
      "Jianfang Chen",
      "Kai Zhang",
      "Aoran Gan",
      "Shiwei Tong",
      "Shuanghong Shen",
      "Qi Liu"
    ],
    "abstract": "Knowledge Graph Completion (KGC) aims to infer missing information in\nKnowledge Graphs (KGs) to address their inherent incompleteness. Traditional\nstructure-based KGC methods, while effective, face significant computational\ndemands and scalability challenges due to the need for dense embedding learning\nand scoring all entities in the KG for each prediction. Recent text-based\napproaches using language models like T5 and BERT have mitigated these issues\nby converting KG triples into text for reasoning. However, they often fail to\nfully utilize contextual information, focusing mainly on the neighborhood of\nthe entity and neglecting the context of the relation. To address this issue,\nwe propose KGC-ERC, a framework that integrates both types of context to enrich\nthe input of generative language models and enhance their reasoning\ncapabilities. Additionally, we introduce a sampling strategy to effectively\nselect relevant context within input token constraints, which optimizes the\nutilization of contextual information and potentially improves model\nperformance. Experiments on the Wikidata5M, Wiki27K, and FB15K-237-N datasets\nshow that KGC-ERC outperforms or matches state-of-the-art baselines in\npredictive performance and scalability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23205v1",
    "published_date": "2025-03-29 20:04:50 UTC",
    "updated_date": "2025-03-29 20:04:50 UTC"
  },
  {
    "arxiv_id": "2503.23204v1",
    "title": "The Challenge of Achieving Attributability in Multilingual Table-to-Text Generation with Question-Answer Blueprints",
    "authors": [
      "Aden Haussmann"
    ],
    "abstract": "Multilingual Natural Language Generation (NLG) is challenging due to the lack\nof training data for low-resource languages. However, some low-resource\nlanguages have up to tens of millions of speakers globally, making it important\nto improve NLG tools for them. Table-to-Text NLG is an excellent measure of\nmodels' reasoning abilities but is very challenging in the multilingual\nsetting. System outputs are often not attributable, or faithful, to the data in\nthe source table. Intermediate planning techniques like Question-Answer (QA)\nblueprints have been shown to improve attributability on summarisation tasks.\nThis work explores whether QA blueprints make multilingual Table-to-Text\noutputs more attributable to the input tables. This paper extends the\nchallenging multilingual Table-to-Text dataset, TaTA, which includes African\nlanguages, with QA blueprints. Sequence-to-sequence language models are then\nfinetuned on this dataset, with and without blueprints. Results show that QA\nblueprints improve performance for models finetuned and evaluated only on\nEnglish examples, but do not demonstrate gains in the multilingual setting.\nThis is due to inaccuracies in machine translating the blueprints from English\ninto target languages when generating the training data, and models failing to\nrely closely on the blueprints they generate. An in-depth analysis is conducted\non why this is challenging.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23204v1",
    "published_date": "2025-03-29 20:04:00 UTC",
    "updated_date": "2025-03-29 20:04:00 UTC"
  },
  {
    "arxiv_id": "2503.23199v1",
    "title": "Incorporating GNSS Information with LIDAR-Inertial Odometry for Accurate Land-Vehicle Localization",
    "authors": [
      "Jintao Cheng",
      "Bohuan Xue",
      "Shiyang Chen",
      "Qiuchi Xiang",
      "Xiaoyu Tang"
    ],
    "abstract": "Currently, visual odometry and LIDAR odometry are performing well in pose\nestimation in some typical environments, but they still cannot recover the\nlocalization state at high speed or reduce accumulated drifts. In order to\nsolve these problems, we propose a novel LIDAR-based localization framework,\nwhich achieves high accuracy and provides robust localization in 3D pointcloud\nmaps with information of multi-sensors. The system integrates global\ninformation with LIDAR-based odometry to optimize the localization state. To\nimprove robustness and enable fast resumption of localization, this paper uses\noffline pointcloud maps for prior knowledge and presents a novel registration\nmethod to speed up the convergence rate. The algorithm is tested on various\nmaps of different data sets and has higher robustness and accuracy than other\nlocalization algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23199v1",
    "published_date": "2025-03-29 19:41:31 UTC",
    "updated_date": "2025-03-29 19:41:31 UTC"
  },
  {
    "arxiv_id": "2503.23190v1",
    "title": "Ethereum Price Prediction Employing Large Language Models for Short-term and Few-shot Forecasting",
    "authors": [
      "Eftychia Makri",
      "Georgios Palaiokrassas",
      "Sarah Bouraga",
      "Antigoni Polychroniadou",
      "Leandros Tassiulas"
    ],
    "abstract": "Cryptocurrencies have transformed financial markets with their innovative\nblockchain technology and volatile price movements, presenting both challenges\nand opportunities for predictive analytics. Ethereum, being one of the leading\ncryptocurrencies, has experienced significant market fluctuations, making its\nprice prediction an attractive yet complex problem. This paper presents a\ncomprehensive study on the effectiveness of Large Language Models (LLMs) in\npredicting Ethereum prices for short-term and few-shot forecasting scenarios.\nThe main challenge in training models for time series analysis is the lack of\ndata. We address this by leveraging a novel approach that adapts existing\npre-trained LLMs on natural language or images from billions of tokens to the\nunique characteristics of Ethereum price time series data. Through thorough\nexperimentation and comparison with traditional and contemporary models, our\nresults demonstrate that selectively freezing certain layers of pre-trained\nLLMs achieves state-of-the-art performance in this domain. This approach\nconsistently surpasses benchmarks across multiple metrics, including Mean\nSquared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Error\n(RMSE), demonstrating its effectiveness and robustness. Our research not only\ncontributes to the existing body of knowledge on LLMs but also provides\npractical insights in the cryptocurrency prediction domain. The adaptability of\npre-trained LLMs to handle the nature of Ethereum prices suggests a promising\ndirection for future research, potentially including the integration of\nsentiment analysis to further refine forecasting accuracy.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23190v1",
    "published_date": "2025-03-29 19:04:28 UTC",
    "updated_date": "2025-03-29 19:04:28 UTC"
  },
  {
    "arxiv_id": "2503.23175v1",
    "title": "Large Language Models are Unreliable for Cyber Threat Intelligence",
    "authors": [
      "Emanuele Mezzi",
      "Fabio Massacci",
      "Katja Tuma"
    ],
    "abstract": "Several recent works have argued that Large Language Models (LLMs) can be\nused to tame the data deluge in the cybersecurity field, by improving the\nautomation of Cyber Threat Intelligence (CTI) tasks. This work presents an\nevaluation methodology that other than allowing to test LLMs on CTI tasks when\nusing zero-shot learning, few-shot learning and fine-tuning, also allows to\nquantify their consistency and their confidence level. We run experiments with\nthree state-of-the-art LLMs and a dataset of 350 threat intelligence reports\nand present new evidence of potential security risks in relying on LLMs for\nCTI. We show how LLMs cannot guarantee sufficient performance on real-size\nreports while also being inconsistent and overconfident. Few-shot learning and\nfine-tuning only partially improve the results, thus posing doubts about the\npossibility of using LLMs for CTI scenarios, where labelled datasets are\nlacking and where confidence is a fundamental factor.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23175v1",
    "published_date": "2025-03-29 18:09:36 UTC",
    "updated_date": "2025-03-29 18:09:36 UTC"
  },
  {
    "arxiv_id": "2504.01032v1",
    "title": "Who Owns the Output? Bridging Law and Technology in LLMs Attribution",
    "authors": [
      "Emanuele Mezzi",
      "Asimina Mertzani",
      "Michael P. Manis",
      "Siyanna Lilova",
      "Nicholas Vadivoulis",
      "Stamatis Gatirdakis",
      "Styliani Roussou",
      "Rodayna Hmede"
    ],
    "abstract": "Since the introduction of ChatGPT in 2022, Large language models (LLMs) and\nLarge Multimodal Models (LMM) have transformed content creation, enabling the\ngeneration of human-quality content, spanning every medium, text, images,\nvideos, and audio. The chances offered by generative AI models are endless and\nare drastically reducing the time required to generate content and usually\nraising the quality of the generation. However, considering the complexity and\nthe difficult traceability of the generated content, the use of these tools\nprovides challenges in attributing AI-generated content. The difficult\nattribution resides for a variety of reasons, starting from the lack of a\nsystematic fingerprinting of the generated content and ending with the enormous\namount of data on which LLMs and LMM are trained, which makes it difficult to\nconnect generated content to the training data. This scenario is raising\nconcerns about intellectual property and ethical responsibilities. To address\nthese concerns, in this paper, we bridge the technological, ethical, and\nlegislative aspects, by proposing a review of the legislative and technological\ninstruments today available and proposing a legal framework to ensure\naccountability. In the end, we propose three use cases of how these can be\ncombined to guarantee that attribution is respected. However, even though the\ntechniques available today can guarantee a greater attribution to a greater\nextent, strong limitations still apply, that can be solved uniquely by the\ndevelopment of new attribution techniques, to be applied to LLMs and LMMs.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.01032v1",
    "published_date": "2025-03-29 18:08:04 UTC",
    "updated_date": "2025-03-29 18:08:04 UTC"
  },
  {
    "arxiv_id": "2503.23170v1",
    "title": "AstroAgents: A Multi-Agent AI for Hypothesis Generation from Mass Spectrometry Data",
    "authors": [
      "Daniel Saeedi",
      "Denise Buckner",
      "Jose C. Aponte",
      "Amirali Aghazadeh"
    ],
    "abstract": "With upcoming sample return missions across the solar system and the\nincreasing availability of mass spectrometry data, there is an urgent need for\nmethods that analyze such data within the context of existing astrobiology\nliterature and generate plausible hypotheses regarding the emergence of life on\nEarth. Hypothesis generation from mass spectrometry data is challenging due to\nfactors such as environmental contaminants, the complexity of spectral peaks,\nand difficulties in cross-matching these peaks with prior studies. To address\nthese challenges, we introduce AstroAgents, a large language model-based,\nmulti-agent AI system for hypothesis generation from mass spectrometry data.\nAstroAgents is structured around eight collaborative agents: a data analyst, a\nplanner, three domain scientists, an accumulator, a literature reviewer, and a\ncritic. The system processes mass spectrometry data alongside user-provided\nresearch papers. The data analyst interprets the data, and the planner\ndelegates specific segments to the scientist agents for in-depth exploration.\nThe accumulator then collects and deduplicates the generated hypotheses, and\nthe literature reviewer identifies relevant literature using Semantic Scholar.\nThe critic evaluates the hypotheses, offering rigorous suggestions for\nimprovement. To assess AstroAgents, an astrobiology expert evaluated the\nnovelty and plausibility of more than a hundred hypotheses generated from data\nobtained from eight meteorites and ten soil samples. Of these hypotheses, 36%\nwere identified as plausible, and among those, 66% were novel. Project website:\nhttps://astroagents.github.io/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23170v1",
    "published_date": "2025-03-29 17:58:52 UTC",
    "updated_date": "2025-03-29 17:58:52 UTC"
  },
  {
    "arxiv_id": "2503.23157v2",
    "title": "Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards for Reasoning-Enhanced Text-to-SQL",
    "authors": [
      "Mohammadreza Pourreza",
      "Shayan Talaei",
      "Ruoxi Sun",
      "Xingchen Wan",
      "Hailong Li",
      "Azalia Mirhoseini",
      "Amin Saberi",
      "Sercan \"O. Arik"
    ],
    "abstract": "Text-to-SQL is a challenging task involving multiple reasoning-intensive\nsubtasks, including natural language understanding, database schema\ncomprehension, and precise SQL query formulation. Existing approaches often\nrely on handcrafted reasoning paths with inductive biases that can limit their\noverall effectiveness. Motivated by the recent success of reasoning-enhanced\nmodels such as DeepSeek R1 and OpenAI o1, which effectively leverage\nreward-driven self-exploration to enhance reasoning capabilities and\ngeneralization, we propose a novel set of partial rewards tailored specifically\nfor the Text-to-SQL task. Our reward set includes schema-linking, AI feedback,\nn-gram similarity, and syntax check, explicitly designed to address the reward\nsparsity issue prevalent in reinforcement learning (RL). Leveraging group\nrelative policy optimization (GRPO), our approach explicitly encourages large\nlanguage models (LLMs) to develop intrinsic reasoning skills necessary for\naccurate SQL query generation. With models of different sizes, we demonstrate\nthat RL-only training with our proposed rewards consistently achieves higher\naccuracy and superior generalization compared to supervised fine-tuning (SFT).\nRemarkably, our RL-trained 14B-parameter model significantly outperforms larger\nproprietary models, e.g. o3-mini by 4% and Gemini-1.5-Pro-002 by 3% on the BIRD\nbenchmark. These highlight the efficacy of our proposed RL-training framework\nwith partial rewards for enhancing both accuracy and reasoning capabilities in\nText-to-SQL tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "Mohammadreza Pourreza and Shayan Talaei contributed equally to this\n  work",
    "pdf_url": "http://arxiv.org/pdf/2503.23157v2",
    "published_date": "2025-03-29 17:29:30 UTC",
    "updated_date": "2025-04-01 12:53:16 UTC"
  },
  {
    "arxiv_id": "2503.23153v1",
    "title": "Conversational Agents for Older Adults' Health: A Systematic Literature Review",
    "authors": [
      "Jiaxin An",
      "Siqi Yi",
      "Yao Lyu",
      "Houjiang Liu",
      "Yan Zhang"
    ],
    "abstract": "There has been vast literature that studies Conversational Agents (CAs) in\nfacilitating older adults' health. The vast and diverse studies warrants a\ncomprehensive review that concludes the main findings and proposes research\ndirections for future studies, while few literature review did it from\nhuman-computer interaction (HCI) perspective. In this study, we present a\nsurvey of existing studies on CAs for older adults' health. Through a\nsystematic review of 72 papers, this work reviewed previously studied older\nadults' characteristics and analyzed participants' experiences and expectations\nof CAs for health. We found that (1) Past research has an increasing interest\non chatbots and voice assistants and applied CA as multiple roles in older\nadults' health. (2) Older adults mainly showed low acceptance CAs for health\ndue to various reasons, such as unstable effects, harm to independence, and\nprivacy concerns. (3) Older adults expect CAs to be able to support multiple\nfunctions, to communicate using natural language, to be personalized, and to\nallow users full control. We also discuss the implications based on the\nfindings.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "31 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23153v1",
    "published_date": "2025-03-29 17:19:09 UTC",
    "updated_date": "2025-03-29 17:19:09 UTC"
  },
  {
    "arxiv_id": "2503.23147v1",
    "title": "Agent-Based Modeling and Deep Neural Networks for Establishing Digital Twins of Secure Facilities under Sensing Restrictions",
    "authors": [
      "Chathika Gunaratne",
      "Mason Stott",
      "Debraj De",
      "Gautam Malviya Thakur",
      "Chris Young"
    ],
    "abstract": "Digital twin technologies help practitioners simulate, monitor, and predict\nundesirable outcomes in-silico, while avoiding the cost and risks of conducting\nlive simulation exercises. Virtual reality (VR) based digital twin technologies\nare especially useful when monitoring human Patterns of Life (POL) in secure\nnuclear facilities, where live simulation exercises are too dangerous and\ncostly to ever perform. However, the high-security status of such facilities\nmay restrict modelers from deploying human activity sensors for data\ncollection. This problem was encountered when deploying MetaPOL, a digital twin\nsystem to prevent insider threat or sabotage of secure facilities, at a secure\nnuclear reactor facility at Oak Ridge National Laboratory (ORNL). This\nchallenge was addressed using an agent-based model (ABM), driven by anecdotal\nevidence of facility personnel POL, to generate synthetic movement\ntrajectories. These synthetic trajectories were then used to train deep neural\nnetwork surrogates for next location and stay duration prediction to drive NPCs\nin the VR environment. In this study, we evaluate the efficacy of this\ntechnique for establishing NPC movement within MetaPOL and the ability to\ndistinguish NPC movement during normal operations from that during a simulated\nemergency response. Our results demonstrate the success of using a multi-layer\nperceptron for next location prediction and mixture density network for stay\nduration prediction to predict the ABM generated trajectories. We also find\nthat NPC movement in the VR environment driven by the deep neural networks\nunder normal operations remain significantly different to that seen when\nsimulating responses to a simulated emergency scenario.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been already published in the 2024\n  Interservice/Industry Training, Simulation, and Education Conference\n  (I/ITSEC'24):\n  https://www.iitsec.org/-/media/sites/iitsec/agenda/2024/iitsec2024program3professionaldevelopment112124.pdf\n  The authors have obtained permission from I/ITSEC'24 organizers to release\n  this paper on arXiv. Appropriate licensing is also applied",
    "pdf_url": "http://arxiv.org/pdf/2503.23147v1",
    "published_date": "2025-03-29 17:01:43 UTC",
    "updated_date": "2025-03-29 17:01:43 UTC"
  },
  {
    "arxiv_id": "2503.23145v1",
    "title": "CodeARC: Benchmarking Reasoning Capabilities of LLM Agents for Inductive Program Synthesis",
    "authors": [
      "Anjiang Wei",
      "Tarun Suresh",
      "Jiannan Cao",
      "Naveen Kannan",
      "Yuheng Wu",
      "Kai Yan",
      "Thiago S. F. X. Teixeira",
      "Ke Wang",
      "Alex Aiken"
    ],
    "abstract": "Inductive program synthesis, or programming by example, requires synthesizing\nfunctions from input-output examples that generalize to unseen inputs. While\nlarge language model agents have shown promise in programming tasks guided by\nnatural language, their ability to perform inductive program synthesis is\nunderexplored. Existing evaluation protocols rely on static sets of examples\nand held-out tests, offering no feedback when synthesized functions are\nincorrect and failing to reflect real-world scenarios such as reverse\nengineering. We propose CodeARC, the Code Abstraction and Reasoning Challenge,\na new evaluation framework where agents interact with a hidden target function\nby querying it with new inputs, synthesizing candidate functions, and\niteratively refining their solutions using a differential testing oracle. This\ninteractive setting encourages agents to perform function calls and\nself-correction based on feedback. We construct the first large-scale benchmark\nfor general-purpose inductive program synthesis, featuring 1114 functions.\nAmong 18 models evaluated, o3-mini performs best with a success rate of 52.7%,\nhighlighting the difficulty of this task. Fine-tuning LLaMA-3.1-8B-Instruct on\ncurated synthesis traces yields up to a 31% relative performance gain. CodeARC\nprovides a more realistic and challenging testbed for evaluating LLM-based\nprogram synthesis and inductive reasoning.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23145v1",
    "published_date": "2025-03-29 16:50:39 UTC",
    "updated_date": "2025-03-29 16:50:39 UTC"
  },
  {
    "arxiv_id": "2503.23128v1",
    "title": "CrossMuSim: A Cross-Modal Framework for Music Similarity Retrieval with LLM-Powered Text Description Sourcing and Mining",
    "authors": [
      "Tristan Tsoi",
      "Jiajun Deng",
      "Yaolong Ju",
      "Benno Weck",
      "Holger Kirchhoff",
      "Simon Lui"
    ],
    "abstract": "Music similarity retrieval is fundamental for managing and exploring relevant\ncontent from large collections in streaming platforms. This paper presents a\nnovel cross-modal contrastive learning framework that leverages the open-ended\nnature of text descriptions to guide music similarity modeling, addressing the\nlimitations of traditional uni-modal approaches in capturing complex musical\nrelationships. To overcome the scarcity of high-quality text-music paired data,\nthis paper introduces a dual-source data acquisition approach combining online\nscraping and LLM-based prompting, where carefully designed prompts leverage\nLLMs' comprehensive music knowledge to generate contextually rich descriptions.\nExten1sive experiments demonstrate that the proposed framework achieves\nsignificant performance improvements over existing benchmarks through objective\nmetrics, subjective evaluations, and real-world A/B testing on the Huawei Music\nstreaming platform.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICME2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23128v1",
    "published_date": "2025-03-29 15:43:09 UTC",
    "updated_date": "2025-03-29 15:43:09 UTC"
  },
  {
    "arxiv_id": "2503.23125v1",
    "title": "Evaluating Compositional Scene Understanding in Multimodal Generative Models",
    "authors": [
      "Shuhao Fu",
      "Andrew Jun Lee",
      "Anna Wang",
      "Ida Momennejad",
      "Trevor Bihl",
      "Hongjing Lu",
      "Taylor W. Webb"
    ],
    "abstract": "The visual world is fundamentally compositional. Visual scenes are defined by\nthe composition of objects and their relations. Hence, it is essential for\ncomputer vision systems to reflect and exploit this compositionality to achieve\nrobust and generalizable scene understanding. While major strides have been\nmade toward the development of general-purpose, multimodal generative models,\nincluding both text-to-image models and multimodal vision-language models, it\nremains unclear whether these systems are capable of accurately generating and\ninterpreting scenes involving the composition of multiple objects and\nrelations. In this work, we present an evaluation of the compositional visual\nprocessing capabilities in the current generation of text-to-image (DALL-E 3)\nand multimodal vision-language models (GPT-4V, GPT-4o, Claude Sonnet 3.5,\nQWEN2-VL-72B, and InternVL2.5-38B), and compare the performance of these\nsystems to human participants. The results suggest that these systems display\nsome ability to solve compositional and relational tasks, showing notable\nimprovements over the previous generation of multimodal models, but with\nperformance nevertheless well below the level of human participants,\nparticularly for more complex scenes involving many ($>5$) objects and multiple\nrelations. These results highlight the need for further progress toward\ncompositional understanding of visual scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23125v1",
    "published_date": "2025-03-29 15:34:43 UTC",
    "updated_date": "2025-03-29 15:34:43 UTC"
  },
  {
    "arxiv_id": "2503.23111v1",
    "title": "How to safely discard features based on aggregate SHAP values",
    "authors": [
      "Robi Bhattacharjee",
      "Karolin Frohnapfel",
      "Ulrike von Luxburg"
    ],
    "abstract": "SHAP is one of the most popular local feature-attribution methods. Given a\nfunction f and an input x, it quantifies each feature's contribution to f(x).\nRecently, SHAP has been increasingly used for global insights: practitioners\naverage the absolute SHAP values over many data points to compute global\nfeature importance scores, which are then used to discard unimportant features.\nIn this work, we investigate the soundness of this practice by asking whether\nsmall aggregate SHAP values necessarily imply that the corresponding feature\ndoes not affect the function. Unfortunately, the answer is no: even if the i-th\nSHAP value is 0 on the entire data support, there exist functions that clearly\ndepend on Feature i. The issue is that computing SHAP values involves\nevaluating f on points outside of the data support, where f can be\nstrategically designed to mask its dependence on Feature i. To address this, we\npropose to aggregate SHAP values over the extended support, which is the\nproduct of the marginals of the underlying distribution. With this\nmodification, we show that a small aggregate SHAP value implies that we can\nsafely discard the corresponding feature. We then extend our results to\nKernelSHAP, the most popular method to approximate SHAP values in practice. We\nshow that if KernelSHAP is computed over the extended distribution, a small\naggregate value justifies feature removal. This result holds independently of\nwhether KernelSHAP accurately approximates true SHAP values, making it one of\nthe first theoretical results to characterize the KernelSHAP algorithm itself.\nOur findings have both theoretical and practical implications. We introduce the\nShapley Lie algebra, which offers algebraic insights that may enable a deeper\ninvestigation of SHAP and we show that randomly permuting each column of the\ndata matrix enables safely discarding features based on aggregate SHAP and\nKernelSHAP values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23111v1",
    "published_date": "2025-03-29 15:07:30 UTC",
    "updated_date": "2025-03-29 15:07:30 UTC"
  },
  {
    "arxiv_id": "2503.23104v1",
    "title": "Fast Training of Recurrent Neural Networks with Stationary State Feedbacks",
    "authors": [
      "Paul Caillon",
      "Erwan Fagnou",
      "Alexandre Allauzen"
    ],
    "abstract": "Recurrent neural networks (RNNs) have recently demonstrated strong\nperformance and faster inference than Transformers at comparable parameter\nbudgets. However, the recursive gradient computation with the backpropagation\nthrough time (or BPTT) algorithm remains the major computational bottleneck. In\nthis work, we propose a novel method that replaces BPTT with a fixed gradient\nfeedback mechanism, yielding an efficient approximation of the exact gradient\npropagation based on the assumption of time stationarity. Our approach\nleverages state-space model (SSM) principles to define a structured feedback\nmatrix that directly propagates gradients from future time steps. This\nformulation bypasses the need for recursive gradient backpropagation,\nsignificantly reducing training overhead while preserving the network's ability\nto capture long-term dependencies. The experiments on language modeling\nbenchmarks exhibit competitive perplexity scores, while significantly reducing\nthe training costs. These promising results suggest that designing a feedback\nmethod like an SSM can fully exploit the efficiency advantages of RNNs for many\npractical applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages (including additional contents), 3 figures, 5 tables, code\n  available at https://github.com/p0lcAi/DSF",
    "pdf_url": "http://arxiv.org/pdf/2503.23104v1",
    "published_date": "2025-03-29 14:45:52 UTC",
    "updated_date": "2025-03-29 14:45:52 UTC"
  },
  {
    "arxiv_id": "2503.23101v1",
    "title": "RL2Grid: Benchmarking Reinforcement Learning in Power Grid Operations",
    "authors": [
      "Enrico Marchesini",
      "Benjamin Donnot",
      "Constance Crozier",
      "Ian Dytham",
      "Christian Merz",
      "Lars Schewe",
      "Nico Westerbeck",
      "Cathy Wu",
      "Antoine Marot",
      "Priya L. Donti"
    ],
    "abstract": "Reinforcement learning (RL) can transform power grid operations by providing\nadaptive and scalable controllers essential for grid decarbonization. However,\nexisting methods struggle with the complex dynamics, aleatoric uncertainty,\nlong-horizon goals, and hard physical constraints that occur in real-world\nsystems. This paper presents RL2Grid, a benchmark designed in collaboration\nwith power system operators to accelerate progress in grid control and foster\nRL maturity. Built on a power simulation framework developed by RTE France,\nRL2Grid standardizes tasks, state and action spaces, and reward structures\nwithin a unified interface for a systematic evaluation and comparison of RL\napproaches. Moreover, we integrate real control heuristics and safety\nconstraints informed by the operators' expertise to ensure RL2Grid aligns with\ngrid operation requirements. We benchmark popular RL baselines on the grid\ncontrol tasks represented within RL2Grid, establishing reference performance\nmetrics. Our results and discussion highlight the challenges that power grids\npose for RL methods, emphasizing the need for novel algorithms capable of\nhandling real-world physical systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23101v1",
    "published_date": "2025-03-29 14:39:17 UTC",
    "updated_date": "2025-03-29 14:39:17 UTC"
  },
  {
    "arxiv_id": "2503.23088v1",
    "title": "UNITYAI-GUARD: Pioneering Toxicity Detection Across Low-Resource Indian Languages",
    "authors": [
      "Himanshu Beniwal",
      "Reddybathuni Venkat",
      "Rohit Kumar",
      "Birudugadda Srivibhav",
      "Daksh Jain",
      "Pavan Doddi",
      "Eshwar Dhande",
      "Adithya Ananth",
      "Kuldeep",
      "Heer Kubadia",
      "Pratham Sharda",
      "Mayank Singh"
    ],
    "abstract": "This work introduces UnityAI-Guard, a framework for binary toxicity\nclassification targeting low-resource Indian languages. While existing systems\npredominantly cater to high-resource languages, UnityAI-Guard addresses this\ncritical gap by developing state-of-the-art models for identifying toxic\ncontent across diverse Brahmic/Indic scripts. Our approach achieves an\nimpressive average F1-score of 84.23% across seven languages, leveraging a\ndataset of 888k training instances and 35k manually verified test instances. By\nadvancing multilingual content moderation for linguistically diverse regions,\nUnityAI-Guard also provides public API access to foster broader adoption and\napplication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23088v1",
    "published_date": "2025-03-29 14:20:13 UTC",
    "updated_date": "2025-03-29 14:20:13 UTC"
  },
  {
    "arxiv_id": "2503.23084v1",
    "title": "The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction",
    "authors": [
      "Yihuai Hong",
      "Dian Zhou",
      "Meng Cao",
      "Lei Yu",
      "Zhijing Jin"
    ],
    "abstract": "Large language models (LLMs) excel on a variety of reasoning benchmarks, but\nprevious studies suggest they sometimes struggle to generalize to unseen\nquestions, potentially due to over-reliance on memorized training examples.\nHowever, the precise conditions under which LLMs switch between reasoning and\nmemorization during text generation remain unclear. In this work, we provide a\nmechanistic understanding of LLMs' reasoning-memorization dynamics by\nidentifying a set of linear features in the model's residual stream that govern\nthe balance between genuine reasoning and memory recall. These features not\nonly distinguish reasoning tasks from memory-intensive ones but can also be\nmanipulated to causally influence model performance on reasoning tasks.\nAdditionally, we show that intervening in these reasoning features helps the\nmodel more accurately activate the most relevant problem-solving capabilities\nduring answer generation. Our findings offer new insights into the underlying\nmechanisms of reasoning and memory in LLMs and pave the way for the development\nof more robust and interpretable generative AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23084v1",
    "published_date": "2025-03-29 14:00:44 UTC",
    "updated_date": "2025-03-29 14:00:44 UTC"
  },
  {
    "arxiv_id": "2504.08757v1",
    "title": "A Framework for Lightweight Responsible Prompting Recommendation",
    "authors": [
      "Tiago Machado",
      "Sara E. Berger",
      "Cassia Sanctos",
      "Vagner Figueiredo de Santana",
      "Lemara Williams",
      "Zhaoqing Wu"
    ],
    "abstract": "Computer Science and Design practitioners have been researching and proposing\nalternatives for a dearth of recommendations, standards, or best practices in\nuser interfaces for decades. Now, with the advent of generative Artificial\nIntelligence (GenAI), we have yet again an emerging, powerful technology that\nlacks sufficient guidance in terms of possible interactions, inputs, and\noutcomes. In this context, this work proposes a lightweight framework for\nresponsible prompting recommendation to be added before the prompt is sent to\nGenAI. The framework is comprised of (1) a human-curated dataset for\nrecommendations, (2) a red team dataset for assessing recommendations, (3) a\nsentence transformer for semantics mapping, (4) a similarity metric to map\ninput prompt to recommendations, (5) a set of similarity thresholds, (6)\nquantized sentence embeddings, (7) a recommendation engine, and (8) an\nevaluation step to use the red team dataset. With the proposed framework and\nopen-source system, the contributions presented can be applied in multiple\ncontexts where end-users can benefit from guidance for interacting with GenAI\nin a more responsible way, recommending positive values to be added and harmful\nsentences to be removed.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "13 pages, 3 figures, 3 tables, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2504.08757v1",
    "published_date": "2025-03-29 13:56:49 UTC",
    "updated_date": "2025-03-29 13:56:49 UTC"
  },
  {
    "arxiv_id": "2503.23083v2",
    "title": "Efficient Adaptation For Remote Sensing Visual Grounding",
    "authors": [
      "Hasan Moughnieh",
      "Mohamad Chalhoub",
      "Hasan Nasrallah",
      "Cristiano Nattero",
      "Paolo Campanella",
      "Giovanni Nico",
      "Ali J. Ghandour"
    ],
    "abstract": "Adapting pre-trained models has become an effective strategy in artificial\nintelligence, offering a scalable and efficient alternative to training models\nfrom scratch. In the context of remote sensing (RS), where visual grounding(VG)\nremains underexplored, this approach enables the deployment of powerful\nvision-language models to achieve robust cross-modal understanding while\nsignificantly reducing computational overhead. To address this, we applied\nParameter Efficient Fine Tuning (PEFT) techniques to adapt these models for\nRS-specific VG tasks. Specifically, we evaluated LoRA placement across\ndifferent modules in Grounding DINO and used BitFit and adapters to fine-tune\nthe OFA foundation model pre-trained on general-purpose VG datasets. This\napproach achieved performance comparable to or surpassing current State Of The\nArt (SOTA) models while significantly reducing computational costs. This study\nhighlights the potential of PEFT techniques to advance efficient and precise\nmulti-modal analysis in RS, offering a practical and cost-effective alternative\nto full model training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23083v2",
    "published_date": "2025-03-29 13:49:11 UTC",
    "updated_date": "2025-05-13 17:53:11 UTC"
  },
  {
    "arxiv_id": "2503.23081v1",
    "title": "InkFM: A Foundational Model for Full-Page Online Handwritten Note Understanding",
    "authors": [
      "Anastasiia Fadeeva",
      "Vincent Coriou",
      "Diego Antognini",
      "Claudiu Musat",
      "Andrii Maksai"
    ],
    "abstract": "Tablets and styluses are increasingly popular for taking notes. To optimize\nthis experience and ensure a smooth and efficient workflow, it's important to\ndevelop methods for accurately interpreting and understanding the content of\nhandwritten digital notes. We introduce a foundational model called InkFM for\nanalyzing full pages of handwritten content. Trained on a diverse mixture of\ntasks, this model offers a unique combination of capabilities: recognizing text\nin 28 different scripts, mathematical expressions recognition, and segmenting\npages into distinct elements like text and drawings. Our results demonstrate\nthat these tasks can be effectively unified within a single model, achieving\nSoTA text line segmentation out-of-the-box quality surpassing public baselines\nlike docTR. Fine- or LoRA-tuning our base model on public datasets further\nimproves the quality of page segmentation, achieves state-of the art text\nrecognition (DeepWriting, CASIA, SCUT, and Mathwriting datasets) and sketch\nclassification (QuickDraw). This adaptability of InkFM provides a powerful\nstarting point for developing applications with handwritten input.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23081v1",
    "published_date": "2025-03-29 13:45:24 UTC",
    "updated_date": "2025-03-29 13:45:24 UTC"
  },
  {
    "arxiv_id": "2504.13868v1",
    "title": "Using Generative AI Personas Increases Collective Diversity in Human Ideation",
    "authors": [
      "Yun Wan",
      "Yoram M Kalman"
    ],
    "abstract": "This study challenges the widely-reported tradeoff between generative AI's\n(GenAI) contribution to creative outcomes and decreased diversity of these\noutcomes. We modified the design of such a study, by Doshi and Hauser (2024),\nin which participants wrote short stories either aided or unaided by GenAI plot\nideas[1]. In the modified study, plot ideas were generated through ten unique\nGenAI \"personas\" with diverse traits (e.g. cultural backgrounds, thinking\nstyles, genre preferences), creating a pool of 300 story plots. While plot\nideas from any individual persona showed high similarity (average cosine\nsimilarity of 0.92), ideas across different personas exhibited substantial\nvariation (average similarity of 0.20). When human participants wrote stories\nbased on these diverse plot ideas, their collective outputs maintained the same\nlevel of diversity as stories written without GenAI assistance, effectively\neliminating the diversity reduction observed in [1]. Traditional text analytics\nfurther revealed that GenAI-assisted stories featured greater diversity in\ndescriptive and emotional language compared to purely human-generated stories\nwithout GenAI assistance. Our findings demonstrate that introducing diversity\nat the AI input stage through distinct personas can preserve and potentially\nenhance the collective diversity of human creative outputs when collaborating\nwith GenAI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.7, H.5.0, H.4.0"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13868v1",
    "published_date": "2025-03-29 12:43:29 UTC",
    "updated_date": "2025-03-29 12:43:29 UTC"
  },
  {
    "arxiv_id": "2505.00004v1",
    "title": "LangVAE and LangSpace: Building and Probing for Language Model VAEs",
    "authors": [
      "Danilo S. Carvalho",
      "Yingji Zhang",
      "Harriet Unsworth",
      "André Freitas"
    ],
    "abstract": "We present LangVAE, a novel framework for modular construction of variational\nautoencoders (VAEs) on top of pre-trained large language models (LLMs). Such\nlanguage model VAEs can encode the knowledge of their pre-trained components\ninto more compact and semantically disentangled representations. The\nrepresentations obtained in this way can be analysed with the LangVAE companion\nframework: LangSpace, which implements a collection of probing methods, such as\nvector traversal and interpolation, disentanglement measures, and cluster\nvisualisations. LangVAE and LangSpace offer a flexible, efficient and scalable\nway of building and analysing textual representations, with simple integration\nfor models available on the HuggingFace Hub. Additionally, we conducted a set\nof experiments with different encoder and decoder combinations, as well as\nannotated inputs, revealing a wide range of interactions across architectural\nfamilies and sizes w.r.t. generalisation and disentanglement. Our findings\ndemonstrate a promising framework for systematising the experimentation and\nunderstanding of textual representations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00004v1",
    "published_date": "2025-03-29 12:10:11 UTC",
    "updated_date": "2025-03-29 12:10:11 UTC"
  },
  {
    "arxiv_id": "2503.23039v1",
    "title": "STSA: Spatial-Temporal Semantic Alignment for Visual Dubbing",
    "authors": [
      "Zijun Ding",
      "Mingdie Xiong",
      "Congcong Zhu",
      "Jingrun Chen"
    ],
    "abstract": "Existing audio-driven visual dubbing methods have achieved great success.\nDespite this, we observe that the semantic ambiguity between spatial and\ntemporal domains significantly degrades the synthesis stability for the dynamic\nfaces. We argue that aligning the semantic features from spatial and temporal\ndomains is a promising approach to stabilizing facial motion. To achieve this,\nwe propose a Spatial-Temporal Semantic Alignment (STSA) method, which\nintroduces a dual-path alignment mechanism and a differentiable semantic\nrepresentation. The former leverages a Consistent Information Learning (CIL)\nmodule to maximize the mutual information at multiple scales, thereby reducing\nthe manifold differences between spatial and temporal domains. The latter\nutilizes probabilistic heatmap as ambiguity-tolerant guidance to avoid the\nabnormal dynamics of the synthesized faces caused by slight semantic jittering.\nExtensive experimental results demonstrate the superiority of the proposed\nSTSA, especially in terms of image quality and synthesis stability. Pre-trained\nweights and inference code are available at\nhttps://github.com/SCAILab-USTC/STSA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23039v1",
    "published_date": "2025-03-29 11:04:10 UTC",
    "updated_date": "2025-03-29 11:04:10 UTC"
  },
  {
    "arxiv_id": "2503.23037v2",
    "title": "Agentic Large Language Models, a survey",
    "authors": [
      "Aske Plaat",
      "Max van Duijn",
      "Niki van Stein",
      "Mike Preuss",
      "Peter van der Putten",
      "Kees Joost Batenburg"
    ],
    "abstract": "There is great interest in agentic LLMs, large language models that act as\nagents. We review the growing body of work in this area and provide a research\nagenda. Agentic LLMs are LLMs that (1) reason, (2) act, and (3) interact. We\norganize the literature according to these three categories. The research in\nthe first category focuses on reasoning, reflection, and retrieval, aiming to\nimprove decision making; the second category focuses on action models, robots,\nand tools, aiming for agents that act as useful assistants; the third category\nfocuses on multi-agent systems, aiming for collaborative task solving and\nsimulating interaction to study emergent social behavior. We find that works\nmutually benefit from results in other categories: retrieval enables tool use,\nreflection improves multi-agent collaboration, and reasoning benefits all\ncategories. We discuss applications of agentic LLMs and provide an agenda for\nfurther research. Important applications are in medical diagnosis, logistics\nand financial market analysis. Meanwhile, self-reflective agents playing roles\nand interacting with one another augment the process of scientific research\nitself. Further, agentic LLMs may provide a solution for the problem of LLMs\nrunning out of training data: inference-time behavior generates new training\nstates, such that LLMs can keep learning without needing ever larger datasets.\nWe note that there is risk associated with LLM assistants taking action in the\nreal world, while agentic LLMs are also likely to benefit society.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Website: https://askeplaat.github.io/agentic-llm-survey-site/",
    "pdf_url": "http://arxiv.org/pdf/2503.23037v2",
    "published_date": "2025-03-29 11:02:20 UTC",
    "updated_date": "2025-04-03 14:32:44 UTC"
  },
  {
    "arxiv_id": "2504.00031v1",
    "title": "Leaking LoRa: An Evaluation of Password Leaks and Knowledge Storage in Large Language Models",
    "authors": [
      "Ryan Marinelli",
      "Magnus Eckhoff"
    ],
    "abstract": "To effectively deploy Large Language Models (LLMs) in application-specific\nsettings, fine-tuning techniques are applied to enhance performance on\nspecialized tasks. This process often involves fine-tuning on user data data,\nwhich may contain sensitive information. Although not recommended, it is not\nuncommon for users to send passwords in messages, and fine-tuning models on\nthis could result in passwords being leaked. In this study, a Large Language\nModel is fine-tuned with customer support data and passwords from the RockYou\npassword wordlist using Low-Rank Adaptation (LoRA). Out of the first 200\npasswords from the list, 37 were successfully recovered. Further, causal\ntracing is used to identify that password information is largely located in a\nfew layers. Lastly, Rank One Model Editing (ROME) is used to remove the\npassword information from the model, resulting in the number of passwords\nrecovered going from 37 to 0.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00031v1",
    "published_date": "2025-03-29 10:42:58 UTC",
    "updated_date": "2025-03-29 10:42:58 UTC"
  },
  {
    "arxiv_id": "2503.23032v1",
    "title": "Reproducibility Companion Paper: Making Users Indistinguishable: Attribute-wise Unlearning in Recommender Systems",
    "authors": [
      "Yuyuan Li",
      "Junjie Fang",
      "Chaochao Chen",
      "Xiaolin Zheng",
      "Yizhao Zhang",
      "Zhongxuan Han"
    ],
    "abstract": "In this paper, we reproduce the experimental results presented in our\nprevious work titled \"Making Users Indistinguishable: Attribute-wise Unlearning\nin Recommender Systems,\" which was published in the proceedings of the 31st ACM\nInternational Conference on Multimedia. This paper aims to validate the\neffectiveness of our proposed method and help others reproduce our experimental\nresults. We provide detailed descriptions of our preprocessed datasets, source\ncode structure, configuration file settings, experimental environment, and\nreproduced experimental results.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23032v1",
    "published_date": "2025-03-29 10:25:49 UTC",
    "updated_date": "2025-03-29 10:25:49 UTC"
  },
  {
    "arxiv_id": "2504.03718v1",
    "title": "Task-Aware Parameter-Efficient Fine-Tuning of Large Pre-Trained Models at the Edge",
    "authors": [
      "Senkang Hu",
      "Yanan Ma",
      "Yihang Tao",
      "Zhengru Fang",
      "Zihan Fang",
      "Yiqin Deng",
      "Sam Kwong",
      "Yuguang Fang"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success in various\ntasks, such as decision-making, reasoning, and question answering. They have\nbeen widely used in edge devices. However, fine-tuning LLMs to specific tasks\nat the edge is challenging due to the high computational cost and the limited\nstorage and energy resources at the edge. To address this issue, we propose\nTaskEdge, a task-aware parameter-efficient fine-tuning framework at the edge,\nwhich allocates the most effective parameters to the target task and only\nupdates the task-specific parameters. Specifically, we first design a parameter\nimportance calculation criterion that incorporates both weights and input\nactivations into the computation of weight importance. Then, we propose a\nmodel-agnostic task-specific parameter allocation algorithm to ensure that\ntask-specific parameters are distributed evenly across the model, rather than\nbeing concentrated in specific regions. In doing so, TaskEdge can significantly\nreduce the computational cost and memory usage while maintaining performance on\nthe target downstream tasks by updating less than 0.1\\% of the parameters. In\naddition, TaskEdge can be easily integrated with structured sparsity to enable\nacceleration by NVIDIA's specialized sparse tensor cores, and it can be\nseamlessly integrated with LoRA to enable efficient sparse low-rank adaptation.\nExtensive experiments on various tasks demonstrate the effectiveness of\nTaskEdge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03718v1",
    "published_date": "2025-03-29 10:23:36 UTC",
    "updated_date": "2025-03-29 10:23:36 UTC"
  },
  {
    "arxiv_id": "2503.23016v1",
    "title": "Towards Understanding the Optimization Mechanisms in Deep Learning",
    "authors": [
      "Binchuan Qi",
      "Wei Gong",
      "Li Li"
    ],
    "abstract": "In this paper, we adopt a probability distribution estimation perspective to\nexplore the optimization mechanisms of supervised classification using deep\nneural networks. We demonstrate that, when employing the Fenchel-Young loss,\ndespite the non-convex nature of the fitting error with respect to the model's\nparameters, global optimal solutions can be approximated by simultaneously\nminimizing both the gradient norm and the structural error. The former can be\ncontrolled through gradient descent algorithms. For the latter, we prove that\nit can be managed by increasing the number of parameters and ensuring parameter\nindependence, thereby providing theoretical insights into mechanisms such as\nover-parameterization and random initialization. Ultimately, the paper\nvalidates the key conclusions of the proposed method through empirical results,\nillustrating its practical effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23016v1",
    "published_date": "2025-03-29 08:46:13 UTC",
    "updated_date": "2025-03-29 08:46:13 UTC"
  },
  {
    "arxiv_id": "2503.23014v1",
    "title": "MSNGO: multi-species protein function annotation based on 3D protein structure and network propagation",
    "authors": [
      "Beibei Wang",
      "Boyue Cui",
      "Shiqu Chen",
      "Xuan Wang",
      "Yadong Wang",
      "Junyi Li"
    ],
    "abstract": "Motivation: In recent years, protein function prediction has broken through\nthe bottleneck of sequence features, significantly improving prediction\naccuracy using high-precision protein structures predicted by AlphaFold2. While\nsingle-species protein function prediction methods have achieved remarkable\nsuccess, multi-species protein function prediction methods are still in the\nstage of using PPI networks and sequence features. Providing effective\ncross-species label propagation for species with sparse protein annotations\nremains a challenging issue. To address this problem, we propose the MSNGO\nmodel, which integrates structural features and network propagation methods.\nOur validation shows that using structural features can significantly improve\nthe accuracy of multi-species protein function prediction. Results: We employ\ngraph representation learning techniques to extract amino acid representations\nfrom protein structure contact maps and train a structural model using a graph\nconvolution pooling module to derive protein-level structural features. After\nincorporating the sequence features from ESM-2, we apply a network propagation\nalgorithm to aggregate information and update node representations within a\nheterogeneous network. The results demonstrate that MSNGO outperforms previous\nmulti-species protein function prediction methods that rely on sequence\nfeatures and PPI networks. Availability: https://github.com/blingbell/MSNGO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23014v1",
    "published_date": "2025-03-29 08:35:45 UTC",
    "updated_date": "2025-03-29 08:35:45 UTC"
  },
  {
    "arxiv_id": "2503.23011v1",
    "title": "On Geometrical Properties of Text Token Embeddings for Strong Semantic Binding in Text-to-Image Generation",
    "authors": [
      "Hoigi Seo",
      "Junseo Bang",
      "Haechang Lee",
      "Joohoon Lee",
      "Byung Hyun Lee",
      "Se Young Chun"
    ],
    "abstract": "Text-to-Image (T2I) models often suffer from text-image misalignment in\ncomplex scenes involving multiple objects and attributes. Semantic binding aims\nto mitigate this issue by accurately associating the generated attributes and\nobjects with their corresponding noun phrases (NPs). Existing methods rely on\ntext or latent optimizations, yet the factors influencing semantic binding\nremain underexplored. Here we investigate the geometrical properties of text\ntoken embeddings and their cross-attention (CA) maps. We empirically and\ntheoretically analyze that the geometrical properties of token embeddings,\nspecifically both angular distances and norms, play a crucial role in CA map\ndifferentiation. Then, we propose \\textbf{TeeMo}, a training-free text\nembedding-aware T2I framework with strong semantic binding. TeeMo consists of\nCausality-Aware Projection-Out (CAPO) for distinct inter-NP CA maps and\nAdaptive Token Mixing (ATM) with our loss to enhance inter-NP separation while\nmaintaining intra-NP cohesion in CA maps. Extensive experiments confirm TeeMo\nconsistently outperforms prior arts across diverse baselines and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23011v1",
    "published_date": "2025-03-29 08:31:30 UTC",
    "updated_date": "2025-03-29 08:31:30 UTC"
  },
  {
    "arxiv_id": "2503.23002v1",
    "title": "Learning Structure-enhanced Temporal Point Processes with Gromov-Wasserstein Regularization",
    "authors": [
      "Qingmei Wang",
      "Fanmeng Wang",
      "Bing Su",
      "Hongteng Xu"
    ],
    "abstract": "Real-world event sequences are often generated by different temporal point\nprocesses (TPPs) and thus have clustering structures. Nonetheless, in the\nmodeling and prediction of event sequences, most existing TPPs ignore the\ninherent clustering structures of the event sequences, leading to the models\nwith unsatisfactory interpretability. In this study, we learn\nstructure-enhanced TPPs with the help of Gromov-Wasserstein (GW)\nregularization, which imposes clustering structures on the sequence-level\nembeddings of the TPPs in the maximum likelihood estimation framework.In the\ntraining phase, the proposed method leverages a nonparametric TPP kernel to\nregularize the similarity matrix derived based on the sequence embeddings. In\nlarge-scale applications, we sample the kernel matrix and implement the\nregularization as a Gromov-Wasserstein (GW) discrepancy term, which achieves a\ntrade-off between regularity and computational efficiency.The TPPs learned\nthrough this method result in clustered sequence embeddings and demonstrate\ncompetitive predictive and clustering performance, significantly improving the\nmodel interpretability without compromising prediction accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "60G55, 62M10"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the Web Conference workshop 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23002v1",
    "published_date": "2025-03-29 07:47:21 UTC",
    "updated_date": "2025-03-29 07:47:21 UTC"
  },
  {
    "arxiv_id": "2503.22998v1",
    "title": "AuditVotes: A Framework Towards More Deployable Certified Robustness for Graph Neural Networks",
    "authors": [
      "Yuni Lai",
      "Yulin Zhu",
      "Yixuan Sun",
      "Yulun Wu",
      "Bin Xiao",
      "Gaolei Li",
      "Jianhua Li",
      "Kai Zhou"
    ],
    "abstract": "Despite advancements in Graph Neural Networks (GNNs), adaptive attacks\ncontinue to challenge their robustness. Certified robustness based on\nrandomized smoothing has emerged as a promising solution, offering provable\nguarantees that a model's predictions remain stable under adversarial\nperturbations within a specified range. However, existing methods face a\ncritical trade-off between accuracy and robustness, as achieving stronger\nrobustness requires introducing greater noise into the input graph. This\nexcessive randomization degrades data quality and disrupts prediction\nconsistency, limiting the practical deployment of certifiably robust GNNs in\nreal-world scenarios where both accuracy and robustness are essential. To\naddress this challenge, we propose \\textbf{AuditVotes}, the first framework to\nachieve both high clean accuracy and certifiably robust accuracy for GNNs. It\nintegrates randomized smoothing with two key components,\n\\underline{au}gmentation and con\\underline{dit}ional smoothing, aiming to\nimprove data quality and prediction consistency. The augmentation, acting as a\npre-processing step, de-noises the randomized graph, significantly improving\ndata quality and clean accuracy. The conditional smoothing, serving as a\npost-processing step, employs a filtering function to selectively count votes,\nthereby filtering low-quality predictions and improving voting consistency.\nExtensive experimental results demonstrate that AuditVotes significantly\nenhances clean accuracy, certified robustness, and empirical robustness while\nmaintaining high computational efficiency. Notably, compared to baseline\nrandomized smoothing, AuditVotes improves clean accuracy by $437.1\\%$ and\ncertified accuracy by $409.3\\%$ when the attacker can arbitrarily insert $20$\nedges on the Cora-ML datasets, representing a substantial step toward deploying\ncertifiably robust GNNs in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.22998v1",
    "published_date": "2025-03-29 07:27:32 UTC",
    "updated_date": "2025-03-29 07:27:32 UTC"
  },
  {
    "arxiv_id": "2503.22989v1",
    "title": "FindTheFlaws: Annotated Errors for Detecting Flawed Reasoning and Scalable Oversight Research",
    "authors": [
      "Gabriel Recchia",
      "Chatrik Singh Mangat",
      "Issac Li",
      "Gayatri Krishnakumar"
    ],
    "abstract": "As AI models tackle increasingly complex problems, ensuring reliable human\noversight becomes more challenging due to the difficulty of verifying\nsolutions. Approaches to scaling AI supervision include debate, in which two\nagents engage in structured dialogue to help a judge evaluate claims; critique,\nin which models identify potential flaws in proposed solutions; and\nprover-verifier games, in which a capable 'prover' model generates solutions\nthat must be verifiable by a less capable 'verifier'. Evaluations of the\nscalability of these and similar approaches to difficult problems benefit from\ndatasets that include (1) long-form expert-verified correct solutions and (2)\nlong-form flawed solutions with annotations highlighting specific errors, but\nfew are available.\n  To address this gap, we present FindTheFlaws, a group of five diverse\ndatasets spanning medicine, mathematics, science, coding, and the Lojban\nlanguage. Each dataset contains questions and long-form solutions with expert\nannotations validating their correctness or identifying specific error(s) in\nthe reasoning. We evaluate frontier models' critiquing capabilities and observe\na range of performance that can be leveraged for scalable oversight\nexperiments: models performing more poorly on particular datasets can serve as\njudges/verifiers for more capable models. Additionally, for some task/dataset\ncombinations, expert baselines exceed even top model performance, making them\nmore beneficial for scalable oversight experiments.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "43 pages, 3 figures. for associated repository, see\n  https://github.com/modulo-research/findtheflaws",
    "pdf_url": "http://arxiv.org/pdf/2503.22989v1",
    "published_date": "2025-03-29 06:38:30 UTC",
    "updated_date": "2025-03-29 06:38:30 UTC"
  },
  {
    "arxiv_id": "2503.22988v2",
    "title": "DC-SGD: Differentially Private SGD with Dynamic Clipping through Gradient Norm Distribution Estimation",
    "authors": [
      "Chengkun Wei",
      "Weixian Li",
      "Chen Gong",
      "Wenzhi Chen"
    ],
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a widely\nadopted technique for privacy-preserving deep learning. A critical challenge in\nDP-SGD is selecting the optimal clipping threshold C, which involves balancing\nthe trade-off between clipping bias and noise magnitude, incurring substantial\nprivacy and computing overhead during hyperparameter tuning.\n  In this paper, we propose Dynamic Clipping DP-SGD (DC-SGD), a framework that\nleverages differentially private histograms to estimate gradient norm\ndistributions and dynamically adjust the clipping threshold C. Our framework\nincludes two novel mechanisms: DC-SGD-P and DC-SGD-E. DC-SGD-P adjusts the\nclipping threshold based on a percentile of gradient norms, while DC-SGD-E\nminimizes the expected squared error of gradients to optimize C. These dynamic\nadjustments significantly reduce the burden of hyperparameter tuning C. The\nextensive experiments on various deep learning tasks, including image\nclassification and natural language processing, show that our proposed dynamic\nalgorithms achieve up to 9 times acceleration on hyperparameter tuning than\nDP-SGD. And DC-SGD-E can achieve an accuracy improvement of 10.62% on CIFAR10\nthan DP-SGD under the same privacy budget of hyperparameter tuning. We conduct\nrigorous theoretical privacy and convergence analyses, showing that our methods\nseamlessly integrate with the Adam optimizer. Our results highlight the robust\nperformance and efficiency of DC-SGD, offering a practical solution for\ndifferentially private deep learning with reduced computational overhead and\nenhanced privacy guarantees.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE Transactions on Information Forensics & Security",
    "pdf_url": "http://arxiv.org/pdf/2503.22988v2",
    "published_date": "2025-03-29 06:27:22 UTC",
    "updated_date": "2025-04-01 03:25:37 UTC"
  },
  {
    "arxiv_id": "2504.08756v1",
    "title": "MHTS: Multi-Hop Tree Structure Framework for Generating Difficulty-Controllable QA Datasets for RAG Evaluation",
    "authors": [
      "Jeongsoo Lee",
      "Daeyong Kwon",
      "Kyohoon Jin",
      "Junnyeong Jeong",
      "Minwoo Sim",
      "Minwoo Kim"
    ],
    "abstract": "Existing RAG benchmarks often overlook query difficulty, leading to inflated\nperformance on simpler questions and unreliable evaluations. A robust benchmark\ndataset must satisfy three key criteria: quality, diversity, and difficulty,\nwhich capturing the complexity of reasoning based on hops and the distribution\nof supporting evidence. In this paper, we propose MHTS (Multi-Hop Tree\nStructure), a novel dataset synthesis framework that systematically controls\nmulti-hop reasoning complexity by leveraging a multi-hop tree structure to\ngenerate logically connected, multi-chunk queries. Our fine-grained difficulty\nestimation formula exhibits a strong correlation with the overall performance\nmetrics of a RAG system, validating its effectiveness in assessing both\nretrieval and answer generation capabilities. By ensuring high-quality,\ndiverse, and difficulty-controlled queries, our approach enhances RAG\nevaluation and benchmarking capabilities.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08756v1",
    "published_date": "2025-03-29 06:26:01 UTC",
    "updated_date": "2025-03-29 06:26:01 UTC"
  },
  {
    "arxiv_id": "2503.22982v1",
    "title": "PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference",
    "authors": [
      "Guanqiao Qu",
      "Qian Chen",
      "Xianhao Chen",
      "Kaibin Huang",
      "Yuguang Fang"
    ],
    "abstract": "By provisioning inference offloading services, edge inference drives the\nrapid growth of AI applications at the network edge. However, achieving high\ntask throughput with stringent latency requirements remains a significant\nchallenge. To address this issue, we develop a parameter-sharing AI model\nloading (PartialLoading) framework for multi-user edge inference, which\nexploits two key insights: 1) the majority of latency arises from loading AI\nmodels into server GPU memory, and 2) different AI models can share a\nsignificant number of parameters, for which redundant loading should be\navoided. Towards this end, we formulate a joint multi-user scheduling and\nspectrum bandwidth allocation problem to maximize task throughput by exploiting\nshared parameter blocks across models. The intuition is to judiciously schedule\nuser requests to reuse the shared parameter blocks between consecutively loaded\nmodels, thereby reducing model loading time substantially. To facilitate\nsolution finding, we decouple the problem into two sub-problems, i.e., user\nscheduling and bandwidth allocation, showing that solving them sequentially is\nequivalent to solving the original problem. Due to the NP-hardness of the\nproblem, we first study an important special case called the\n\"bottom-layer-sharing\" case, where AI models share some bottom layers within\nclusters, and design a dynamic programming-based algorithm to obtain the\noptimal solution in polynomial time. For the general case, where shared\nparameter blocks appear at arbitrary positions within AI models, we propose a\ngreedy heuristic to obtain the sub-optimal solution efficiently. Simulation\nresults demonstrate that the proposed framework significantly improves task\nthroughput under deadline constraints compared with user scheduling without\nexploiting parameter sharing.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.22982v1",
    "published_date": "2025-03-29 05:58:07 UTC",
    "updated_date": "2025-03-29 05:58:07 UTC"
  },
  {
    "arxiv_id": "2504.03717v1",
    "title": "RaanA: A Fast, Flexible, and Data-Efficient Post-Training Quantization Algorithm",
    "authors": [
      "Yongyi Yang",
      "Jianyang Gao",
      "Wei Hu"
    ],
    "abstract": "Post-training Quantization (PTQ) has become a widely used technique for\nimproving inference efficiency of large language models (LLMs). However,\nexisting PTQ methods generally suffer from crucial limitations such as heavy\ncalibration data requirements and inflexible choice of target number of bits.\nIn this paper, we propose RaanA, a unified PTQ framework that overcomes these\nchallenges by introducing two novel components: 1) RaBitQ-H, a variant of a\nrandomized vector quantization method RaBitQ, designed for fast, accurate, and\nhighly efficient quantization; and 2) AllocateBits, an algorithm that optimally\nallocates bit-widths across layers based on their quantization sensitivity.\nRaanA achieves competitive performance with state-of-the-art quantization\nmethods while being extremely fast, requiring minimal calibration data, and\nenabling flexible bit allocation. Extensive experiments demonstrate RaanA's\nefficacy in balancing efficiency and accuracy. The code is publicly available\nat https://github.com/FFTYYY/RaanA .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03717v1",
    "published_date": "2025-03-29 05:03:12 UTC",
    "updated_date": "2025-03-29 05:03:12 UTC"
  },
  {
    "arxiv_id": "2504.03716v1",
    "title": "Ethical AI on the Waitlist: Group Fairness Evaluation of LLM-Aided Organ Allocation",
    "authors": [
      "Hannah Murray",
      "Brian Hyeongseok Kim",
      "Isabelle Lee",
      "Jason Byun",
      "Dani Yogatama",
      "Evi Micha"
    ],
    "abstract": "Large Language Models (LLMs) are becoming ubiquitous, promising automation\neven in high-stakes scenarios. However, existing evaluation methods often fall\nshort -- benchmarks saturate, accuracy-based metrics are overly simplistic, and\nmany inherently ambiguous problems lack a clear ground truth. Given these\nlimitations, evaluating fairness becomes complex. To address this, we reframe\nfairness evaluation using Borda scores, a method from voting theory, as a\nnuanced yet interpretable metric for measuring fairness. Using organ allocation\nas a case study, we introduce two tasks: (1) Choose-One and (2) Rank-All. In\nChoose-One, LLMs select a single candidate for a kidney, and we assess fairness\nacross demographics using proportional parity. In Rank-All, LLMs rank all\ncandidates for a kidney, reflecting real-world allocation processes. Since\ntraditional fairness metrics do not account for ranking, we propose a novel\napplication of Borda scoring to capture biases. Our findings highlight the\npotential of voting-based metrics to provide a richer, more multifaceted\nevaluation of LLM fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03716v1",
    "published_date": "2025-03-29 04:36:25 UTC",
    "updated_date": "2025-03-29 04:36:25 UTC"
  },
  {
    "arxiv_id": "2503.22973v1",
    "title": "XL-Instruct: Synthetic Data for Cross-Lingual Open-Ended Generation",
    "authors": [
      "Vivek Iyer",
      "Ricardo Rei",
      "Pinzhen Chen",
      "Alexandra Birch"
    ],
    "abstract": "Cross-lingual open-ended generation -- i.e. generating responses in a desired\nlanguage different from that of the user's query -- is an important yet\nunderstudied problem. We introduce XL-AlpacaEval, a new benchmark for\nevaluating cross-lingual generation capabilities in Large Language Models\n(LLMs), and propose XL-Instruct, a high-quality synthetic data generation\nmethod. Fine-tuning with just 8K XL-Instruct-generated instructions\nsignificantly improves model performance, increasing the win rate against\nGPT-4o-Mini from 7.4% to 21.5%, and improving on several fine-grained quality\nmetrics. Additionally, models fine-tuned on XL-Instruct exhibit strong\nzero-shot transfer to both English-only and multilingual generation tasks.\nGiven its consistent gains across the board, we strongly recommend\nincorporating XL-Instruct in the post-training pipeline of future multilingual\nLLMs. To facilitate further research, we will publicly and freely release the\nXL-Instruct and XL-AlpacaEval datasets, which constitute two of the few\ncross-lingual resources currently available in the literature.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22973v1",
    "published_date": "2025-03-29 04:34:03 UTC",
    "updated_date": "2025-03-29 04:34:03 UTC"
  },
  {
    "arxiv_id": "2503.22971v1",
    "title": "Enhancing Federated Learning Through Secure Cluster-Weighted Client Aggregation",
    "authors": [
      "Kanishka Ranaweera",
      "Azadeh Ghari Neiat",
      "Xiao Liu",
      "Bipasha Kashyap",
      "Pubudu N. Pathirana"
    ],
    "abstract": "Federated learning (FL) has emerged as a promising paradigm in machine\nlearning, enabling collaborative model training across decentralized devices\nwithout the need for raw data sharing. In FL, a global model is trained\niteratively on local datasets residing on individual devices, each contributing\nto the model's improvement. However, the heterogeneous nature of these local\ndatasets, stemming from diverse user behaviours, device capabilities, and data\ndistributions, poses a significant challenge. The inherent heterogeneity in\nfederated learning gives rise to various issues, including model performance\ndiscrepancies, convergence challenges, and potential privacy concerns. As the\nglobal model progresses through rounds of training, the disparities in local\ndata quality and quantity can impede the overall effectiveness of federated\nlearning systems. Moreover, maintaining fairness and privacy across diverse\nuser groups becomes a paramount concern. To address this issue, this paper\nintroduces a novel FL framework, ClusterGuardFL, that employs dissimilarity\nscores, k-means clustering, and reconciliation confidence scores to dynamically\nassign weights to client updates. The dissimilarity scores between global and\nlocal models guide the formation of clusters, with cluster size influencing the\nweight allocation. Within each cluster, a reconciliation confidence score is\ncalculated for individual data points, and a softmax layer generates customized\nweights for clients. These weights are utilized in the aggregation process,\nenhancing the model's robustness and privacy. Experimental results demonstrate\nthe efficacy of the proposed approach in achieving improved model performance\nin diverse datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22971v1",
    "published_date": "2025-03-29 04:29:24 UTC",
    "updated_date": "2025-03-29 04:29:24 UTC"
  },
  {
    "arxiv_id": "2503.22968v2",
    "title": "HRET: A Self-Evolving LLM Evaluation Toolkit for Korean",
    "authors": [
      "Hanwool Lee",
      "Soo Yong Kim",
      "Dasol Choi",
      "SangWon Baek",
      "Seunghyeok Hong",
      "Ilgyun Jeong",
      "Inseon Hwang",
      "Naeun Lee",
      "Guijin Son"
    ],
    "abstract": "Recent advancements in Korean large language models (LLMs) have spurred\nnumerous benchmarks and evaluation methodologies, yet the lack of a\nstandardized evaluation framework has led to inconsistent results and limited\ncomparability. To address this, we introduce HRET Haerae Evaluation Toolkit, an\nopen-source, self-evolving evaluation framework tailored specifically for\nKorean LLMs. HRET unifies diverse evaluation methods, including logit-based\nscoring, exact-match, language-inconsistency penalization, and LLM-as-a-Judge\nassessments. Its modular, registry-based architecture integrates major\nbenchmarks (HAE-RAE Bench, KMMLU, KUDGE, HRM8K) and multiple inference backends\n(vLLM, HuggingFace, OpenAI-compatible endpoints). With automated pipelines for\ncontinuous evolution, HRET provides a robust foundation for reproducible, fair,\nand transparent Korean NLP research.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22968v2",
    "published_date": "2025-03-29 04:17:58 UTC",
    "updated_date": "2025-04-01 12:37:16 UTC"
  },
  {
    "arxiv_id": "2503.22967v1",
    "title": "Student-Powered Digital Scholarship CoLab Project in the HKUST Library: Develop a Chinese Named-Entity Recognition (NER) Tool within One Semester from the Ground Up",
    "authors": [
      "Sherry S. L. Yip",
      "Berry L. Han",
      "Holly H. Y. Chan"
    ],
    "abstract": "Starting in February 2024, the HKUST Library further extended the scope of AI\nliteracy to AI utilization, which focuses on fostering student involvement in\nutilizing state-of-the-art technologies in the projects that initiated by the\nLibrary, named \"Digital Scholarship (DS) CoLab\". A key focus of the DS CoLab\nscheme has been on cultivating talents and enabling students to utilize\nadvanced technologies in practical context. It aims to reinforce the library's\nrole as a catalyst and hub for fostering multidisciplinary collaboration and\ncultivate the \"can do spirit\" among university members. The Library offers 1-2\nprojects per year for students to engage with advanced technologies in\npractical contexts while supporting the Library in tackling challenges and\nstreamlining operational tasks. The tool that introduced in this paper was\nmainly developed by two of the authors, Sherry Yip Sau Lai and Berry Han\nLiuruo, as part-time student helpers under one of our DS CoLab scheme in the\n2024 Spring Semester (February to May 2024). This paper details the complete\njourney from ideation to implementation of developing a Chinese Named-Entity\nRecognition (NER) Tool from the group up within one semester, from the initial\nresearch and planning stages to execution and come up a viable product. The\ncollaborative spirit fostered by this project, with students playing a central\nrole, exemplifies the power and potential of innovative educational models that\nprioritize hands-on learning with student involvement.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.DL",
    "comment": "47 pages. Presented and submitted to DADH2024 conference\n  (https://sites.google.com/view/dadh2024/)",
    "pdf_url": "http://arxiv.org/pdf/2503.22967v1",
    "published_date": "2025-03-29 04:15:34 UTC",
    "updated_date": "2025-03-29 04:15:34 UTC"
  },
  {
    "arxiv_id": "2503.22958v3",
    "title": "Late Breaking Results: Breaking Symmetry- Unconventional Placement of Analog Circuits using Multi-Level Multi-Agent Reinforcement Learning",
    "authors": [
      "Supriyo Maji",
      "Linran Zhao",
      "Souradip Poddar",
      "David Z. Pan"
    ],
    "abstract": "Layout-dependent effects (LDEs) significantly impact analog circuit\nperformance. Traditionally, designers have relied on symmetric placement of\ncircuit components to mitigate variations caused by LDEs. However, due to\nnon-linear nature of these effects, conventional methods often fall short. We\npropose an objective-driven, multi-level, multi-agent Q-learning framework to\nexplore unconventional design space of analog layout, opening new avenues for\noptimizing analog circuit performance. Our approach achieves better variation\nperformance than the state-of-the-art layout techniques. Notably, this is the\nfirst application of multi-agent RL in analog layout automation. The proposed\napproach is compared with non-ML approach based on simulated annealing.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "2 pages, 3 figures, Proceedings of the 62nd ACM/IEEE Design\n  Automation Conference (DAC), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.22958v3",
    "published_date": "2025-03-29 03:13:56 UTC",
    "updated_date": "2025-04-10 19:42:17 UTC"
  },
  {
    "arxiv_id": "2504.08755v1",
    "title": "Delving into: the quantification of Ai-generated content on the internet (synthetic data)",
    "authors": [
      "Dirk HR Spennemann"
    ],
    "abstract": "While it is increasingly evident that the internet is becoming saturated with\ncontent created by generated Ai large language models, accurately measuring the\nscale of this phenomenon has proven challenging. By analyzing the frequency of\nspecific keywords commonly used by ChatGPT, this paper demonstrates that such\nlinguistic markers can effectively be used to esti-mate the presence of\ngenerative AI content online. The findings suggest that at least 30% of text on\nactive web pages originates from AI-generated sources, with the actual\nproportion likely ap-proaching 40%. Given the implications of autophagous\nloops, this is a sobering realization.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pp",
    "pdf_url": "http://arxiv.org/pdf/2504.08755v1",
    "published_date": "2025-03-29 03:06:53 UTC",
    "updated_date": "2025-03-29 03:06:53 UTC"
  },
  {
    "arxiv_id": "2503.22954v1",
    "title": "Can LLMs Support Medical Knowledge Imputation? An Evaluation-Based Perspective",
    "authors": [
      "Xinyu Yao",
      "Aditya Sannabhadti",
      "Holly Wiberg",
      "Karmel S. Shehadeh",
      "Rema Padman"
    ],
    "abstract": "Medical knowledge graphs (KGs) are essential for clinical decision support\nand biomedical research, yet they often exhibit incompleteness due to knowledge\ngaps and structural limitations in medical coding systems. This issue is\nparticularly evident in treatment mapping, where coding systems such as ICD,\nMondo, and ATC lack comprehensive coverage, resulting in missing or\ninconsistent associations between diseases and their potential treatments. To\naddress this issue, we have explored the use of Large Language Models (LLMs)\nfor imputing missing treatment relationships. Although LLMs offer promising\ncapabilities in knowledge augmentation, their application in medical knowledge\nimputation presents significant risks, including factual inaccuracies,\nhallucinated associations, and instability between and within LLMs. In this\nstudy, we systematically evaluate LLM-driven treatment mapping, assessing its\nreliability through benchmark comparisons. Our findings highlight critical\nlimitations, including inconsistencies with established clinical guidelines and\npotential risks to patient safety. This study serves as a cautionary guide for\nresearchers and practitioners, underscoring the importance of critical\nevaluation and hybrid approaches when leveraging LLMs to enhance treatment\nmappings on medical knowledge graphs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, AMIA",
    "pdf_url": "http://arxiv.org/pdf/2503.22954v1",
    "published_date": "2025-03-29 02:52:17 UTC",
    "updated_date": "2025-03-29 02:52:17 UTC"
  },
  {
    "arxiv_id": "2503.22948v1",
    "title": "SUV: Scalable Large Language Model Copyright Compliance with Regularized Selective Unlearning",
    "authors": [
      "Tianyang Xu",
      "Xiaoze Liu",
      "Feijie Wu",
      "Xiaoqian Wang",
      "Jing Gao"
    ],
    "abstract": "Large Language Models (LLMs) have transformed natural language processing by\nlearning from massive datasets, yet this rapid progress has also drawn legal\nscrutiny, as the ability to unintentionally generate copyrighted content has\nalready prompted several prominent lawsuits. In this work, we introduce SUV\n(Selective Unlearning for Verbatim data), a selective unlearning framework\ndesigned to prevent LLM from memorizing copyrighted content while preserving\nits overall utility. In detail, the proposed method constructs a dataset that\ncaptures instances of copyrighted infringement cases by the targeted LLM. With\nthe dataset, we unlearn the content from the LLM by means of Direct Preference\nOptimization (DPO), which replaces the verbatim copyrighted content with\nplausible and coherent alternatives. Since DPO may hinder the LLM's performance\nin other unrelated tasks, we integrate gradient projection and Fisher\ninformation regularization to mitigate the degradation. We validate our\napproach using a large-scale dataset of 500 famous books (predominantly\ncopyrighted works) and demonstrate that SUV significantly reduces verbatim\nmemorization with negligible impact on the performance on unrelated tasks.\nExtensive experiments on both our dataset and public benchmarks confirm the\nscalability and efficacy of our approach, offering a promising solution for\nmitigating copyright risks in real-world LLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22948v1",
    "published_date": "2025-03-29 02:33:26 UTC",
    "updated_date": "2025-03-29 02:33:26 UTC"
  },
  {
    "arxiv_id": "2503.22946v1",
    "title": "DATAWEAVER: Authoring Data-Driven Narratives through the Integrated Composition of Visualization and Text",
    "authors": [
      "Yu Fu",
      "Dennis Bromley",
      "Vidya Setlur"
    ],
    "abstract": "Data-driven storytelling has gained prominence in journalism and other data\nreporting fields. However, the process of creating these stories remains\nchallenging, often requiring the integration of effective visualizations with\ncompelling narratives to form a cohesive, interactive presentation. To help\nstreamline this process, we present an integrated authoring framework and\nsystem, DataWeaver, that supports both visualization-to-text and\ntext-to-visualization composition. DataWeaver enables users to create data\nnarratives anchored to data facts derived from \"call-out\" interactions, i.e.,\nuser-initiated highlights of visualization elements that prompt relevant\nnarrative content. In addition to this \"vis-to-text\" composition, DataWeaver\nalso supports a \"text-initiated\" approach, generating relevant interactive\nvisualizations from existing narratives. Key findings from an evaluation with\n13 participants highlighted the utility and usability of DataWeaver and the\neffectiveness of its integrated authoring framework. The evaluation also\nrevealed opportunities to enhance the framework by refining filtering\nmechanisms and visualization recommendations and better support authoring\ncreativity by introducing advanced customization options.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2; I.3.6"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted to EuroVis 2025. Published in Computer Graphics Forum. DOI:\n  10.1111/cgf.70098",
    "pdf_url": "http://arxiv.org/pdf/2503.22946v1",
    "published_date": "2025-03-29 02:33:03 UTC",
    "updated_date": "2025-03-29 02:33:03 UTC"
  },
  {
    "arxiv_id": "2503.22942v1",
    "title": "Adaptive Interactive Navigation of Quadruped Robots using Large Language Models",
    "authors": [
      "Kangjie Zhou",
      "Yao Mu",
      "Haoyang Song",
      "Yi Zeng",
      "Pengying Wu",
      "Han Gao",
      "Chang Liu"
    ],
    "abstract": "Robotic navigation in complex environments remains a critical research\nchallenge. Traditional navigation methods focus on optimal trajectory\ngeneration within free space, struggling in environments lacking viable paths\nto the goal, such as disaster zones or cluttered warehouses. To address this\ngap, we propose an adaptive interactive navigation approach that proactively\ninteracts with environments to create feasible paths to reach originally\nunavailable goals. Specifically, we present a primitive tree for task planning\nwith large language models (LLMs), facilitating effective reasoning to\ndetermine interaction objects and sequences. To ensure robust subtask\nexecution, we adopt reinforcement learning to pre-train a comprehensive skill\nlibrary containing versatile locomotion and interaction behaviors for motion\nplanning. Furthermore, we introduce an adaptive replanning method featuring two\nLLM-based modules: an advisor serving as a flexible replanning trigger and an\narborist for autonomous plan adjustment. Integrated with the tree structure,\nthe replanning mechanism allows for convenient node addition and pruning,\nenabling rapid plan modification in unknown environments. Comprehensive\nsimulations and experiments have demonstrated our method's effectiveness and\nadaptivity in diverse scenarios. The supplementary video is available at page:\nhttps://youtu.be/W5ttPnSap2g.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.22942v1",
    "published_date": "2025-03-29 02:17:52 UTC",
    "updated_date": "2025-03-29 02:17:52 UTC"
  },
  {
    "arxiv_id": "2503.22941v1",
    "title": "Identifying Multi-modal Knowledge Neurons in Pretrained Transformers via Two-stage Filtering",
    "authors": [
      "Yugen Sato",
      "Tomohiro Takagi"
    ],
    "abstract": "Recent advances in large language models (LLMs) have led to the development\nof multimodal LLMs (MLLMs) in the fields of natural language processing (NLP)\nand computer vision. Although these models allow for integrated visual and\nlanguage understanding, they present challenges such as opaque internal\nprocessing and the generation of hallucinations and misinformation. Therefore,\nthere is a need for a method to clarify the location of knowledge in MLLMs.\n  In this study, we propose a method to identify neurons associated with\nspecific knowledge using MiniGPT-4, a Transformer-based MLLM. Specifically, we\nextract knowledge neurons through two stages: activation differences filtering\nusing inpainting and gradient-based filtering using GradCAM. Experiments on the\nimage caption generation task using the MS COCO 2017 dataset, BLEU, ROUGE, and\nBERTScore quantitative evaluation, and qualitative evaluation using an\nactivation heatmap showed that our method is able to locate knowledge with\nhigher accuracy than existing methods.\n  This study contributes to the visualization and explainability of knowledge\nin MLLMs and shows the potential for future knowledge editing and control.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22941v1",
    "published_date": "2025-03-29 02:16:15 UTC",
    "updated_date": "2025-03-29 02:16:15 UTC"
  },
  {
    "arxiv_id": "2503.22934v1",
    "title": "FairSAM: Fair Classification on Corrupted Data Through Sharpness-Aware Minimization",
    "authors": [
      "Yucong Dai",
      "Jie Ji",
      "Xiaolong Ma",
      "Yongkai Wu"
    ],
    "abstract": "Image classification models trained on clean data often suffer from\nsignificant performance degradation when exposed to testing corrupted data,\nsuch as images with impulse noise, Gaussian noise, or environmental noise. This\ndegradation not only impacts overall performance but also disproportionately\naffects various demographic subgroups, raising critical algorithmic bias\nconcerns. Although robust learning algorithms like Sharpness-Aware Minimization\n(SAM) have shown promise in improving overall model robustness and\ngeneralization, they fall short in addressing the biased performance\ndegradation across demographic subgroups. Existing fairness-aware machine\nlearning methods - such as fairness constraints and reweighing strategies - aim\nto reduce performance disparities but hardly maintain robust and equitable\naccuracy across demographic subgroups when faced with data corruption. This\nreveals an inherent tension between robustness and fairness when dealing with\ncorrupted data. To address these challenges, we introduce one novel metric\nspecifically designed to assess performance degradation across subgroups under\ndata corruption. Additionally, we propose \\textbf{FairSAM}, a new framework\nthat integrates \\underline{Fair}ness-oriented strategies into \\underline{SAM}\nto deliver equalized performance across demographic groups under corrupted\nconditions. Our experiments on multiple real-world datasets and various\npredictive tasks show that FairSAM successfully reconciles robustness and\nfairness, offering a structured solution for equitable and resilient image\nclassification in the presence of data corruption.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22934v1",
    "published_date": "2025-03-29 01:51:59 UTC",
    "updated_date": "2025-03-29 01:51:59 UTC"
  },
  {
    "arxiv_id": "2503.22931v2",
    "title": "Factored Agents: Decoupling In-Context Learning and Memorization for Robust Tool Use",
    "authors": [
      "Nicholas Roth",
      "Christopher Hidey",
      "Lucas Spangher",
      "William F. Arnold",
      "Chang Ye",
      "Nick Masiewicki",
      "Jinoo Baek",
      "Peter Grabowski",
      "Eugene Ie"
    ],
    "abstract": "In this paper, we propose a novel factored agent architecture designed to\novercome the limitations of traditional single-agent systems in agentic AI. Our\napproach decomposes the agent into two specialized components: (1) a large\nlanguage model (LLM) that serves as a high level planner and in-context\nlearner, which may use dynamically available information in user prompts, (2) a\nsmaller language model which acts as a memorizer of tool format and output.\nThis decoupling addresses prevalent issues in monolithic designs, including\nmalformed, missing, and hallucinated API fields, as well as suboptimal planning\nin dynamic environments. Empirical evaluations demonstrate that our factored\narchitecture significantly improves planning accuracy and error resilience,\nwhile elucidating the inherent trade-off between in-context learning and static\nmemorization. These findings suggest that a factored approach is a promising\npathway for developing more robust and adaptable agentic AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22931v2",
    "published_date": "2025-03-29 01:27:11 UTC",
    "updated_date": "2025-04-02 04:53:06 UTC"
  },
  {
    "arxiv_id": "2503.22925v2",
    "title": "Predictive Traffic Rule Compliance using Reinforcement Learning",
    "authors": [
      "Yanliang Huang",
      "Sebastian Mair",
      "Zhuoqi Zeng",
      "Matthias Althoff"
    ],
    "abstract": "Autonomous vehicle path planning has reached a stage where safety and\nregulatory compliance are crucial. This paper presents an approach that\nintegrates a motion planner with a deep reinforcement learning model to predict\npotential traffic rule violations. Our main innovation is replacing the\nstandard actor network in an actor-critic method with a motion planning module,\nwhich ensures both stable and interpretable trajectory generation. In this\nsetup, we use traffic rule robustness as the reward to train a reinforcement\nlearning agent's critic, and the output of the critic is directly used as the\ncost function of the motion planner, which guides the choices of the\ntrajectory. We incorporate some key interstate rules from the German Road\nTraffic Regulation into a rule book and use a graph-based state representation\nto handle complex traffic information. Experiments on an open German highway\ndataset show that the model can predict and prevent traffic rule violations\nbeyond the planning horizon, increasing safety and rule compliance in\nchallenging traffic scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9; I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 7 figures. Preprint intended for submission to IEEE ITSC\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2503.22925v2",
    "published_date": "2025-03-29 01:04:08 UTC",
    "updated_date": "2025-04-04 14:28:47 UTC"
  }
]