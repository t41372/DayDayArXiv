{
  "date": "2025-02-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-07 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文涵盖 AI 优化、强化学习、量子计算、医疗图像处理和金融预测等领域，重点聚焦于大型语言模型（LLM）的推理增强和多模态应用，令人印象深刻的包括量子自动学习和代理辩论框架，而知名学者如 Tomaso Poggio 和 L. -M. Duan 的参与文章突显了 AI 在科学领域的潜力。\n\n以下是今日论文的精选摘要，我优先选取了重要、创新性和话题度高的文章（如量子计算和 AI 安全），并对其他次要论文快速掠过。每篇论文的标题以中文 + 英文形式列出，聚焦核心贡献、方法和发现。\n\n**1. Quantum automated learning with provable and explainable trainability（量子自动学习：具有可证明和可解释训练性的方法）**  \n   这篇论文提出了一种无变分参数的量子自动学习框架，通过迭代演化量子状态来优化机器学习任务。核心贡献是证明了该方法在合理假设下指数级收敛到全局最优，并展示了在真实图像和量子数据上的有效性。该方法为量子计算在机器学习场景中的大规模应用提供了可扩展、可解释的策略，潜在影响包括加速量子机器学习的实际部署。\n\n**2. MELON: Provable Indirect Prompt Injection Defense（MELON：通过掩码重执行和工具比较证明的间接提示注入防御）**  \n   作者开发了 MELON，一种针对 LLM 代理的间接提示注入攻击防御框架。关键方法包括掩码重执行和工具比较，以检测攻击行为。论文发现 MELON 在基准测试中比现有方法减少了 47% 的推理延迟，同时保持了模型效用。该工作强调了 LLM 安全性的重要性，可能推动 AI 系统在实际应用中的鲁棒性提升。\n\n**3. Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning（同胚先验用于医疗图像密集对比表示学习的假阳性和假阴性问题）**  \n   这篇论文引入了 GEMINI 框架，使用可变形的同胚学习（DHL）和几何语义相似性（GSS）来改进医疗图像的对比表示学习。核心发现是该方法显著减少了假阳性和假阴性，提高了图像密集预测任务的准确性。在七个数据集上的实验显示了其优越性，可能在临床诊断中增强 AI 的可靠性。\n\n**4. Federated Learning for Anomaly Detection in Energy Consumption Data（联邦学习在能源消耗数据异常检测中的应用）**  \n   作者评估了联邦学习在能源异常检测中的易受攻击性，使用 LSTM 和 Transformer 模型对抗 FGSM 和 PGD 攻击。关键发现是联邦学习比集中式学习更敏感，但通过攻击分析提供了防御策略。该工作为能源系统的安全 AI 应用提供了实用指导，强调了隐私保护的重要性。\n\n**5. Parameter Symmetry Breaking and Restoration Determines the Hierarchical Learning in AI Systems（参数对称性破坏和恢复决定了 AI 系统中的分层学习）**  \n   作者（包括知名学者 Tomaso Poggio）提出参数对称性机制解释了神经网络的分层学习动态。核心贡献是通过理论分析连接了学习动态、模型复杂性和表示形成，揭示了对称性在 AI 中的基础作用。该论文为理解现代 AI 系统提供了统一框架，可能影响未来神经网络设计。\n\n**6. ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks（ITBench：评估 AI 代理在各种真实 IT 自动化任务中的性能）**  \n   这篇论文引入了 ITBench 框架，用于基准测试 AI 代理在 IT 任务（如 SRE 和安全操作）中的表现。核心发现是当前 AI 模型仅在部分任务中表现出色（如 25.2% 的 CISO 场景），暴露了 AI 在复杂自动化中的局限。该工作为 AI 驱动 IT 自动化提供了可扩展评估，促进更可靠的系统开发。\n\n其他论文涉及 AI 模型优化、图像生成和金融预测等领域，但相对次要，我快速掠过：\n- **Is attention all you need to solve the correlated electron problem（注意力机制是否能解决相关电子问题）**：探索注意力机制在量子材料模拟中的应用，贡献在于高效的变分蒙特卡罗方法。\n- **fMoE: Fine-Grained Expert Offloading（fMoE：细粒度专家卸载用于大型混合专家模型服务）**：优化 MoE 模型的内存效率，减少 47% 的推理延迟。\n- **RAG-Verus: Repository-Level Program Verification（RAG-Verus：基于检索增强生成的仓库级程序验证）**：提升代码验证的准确性，相对专业。\n- **Joint MoE Scaling Laws（联合 MoE 缩放定律）**：分析混合专家模型的内存效率，适合大规模训练。\n- 其余如图像分割、文本生成和量子模拟等论文虽有创新，但影响力较小，建议感兴趣读者查阅具体摘要。\n\n今天的论文突显了 AI 在量子和安全领域的进展，期待这些工作推动更可靠的模型应用！（约 800 字）",
  "papers": [
    {
      "arxiv_id": "2502.05383v2",
      "title": "Is attention all you need to solve the correlated electron problem?",
      "title_zh": "注意力是否就是你所需要的一切来解决相关电子问题？",
      "authors": [
        "Max Geier",
        "Khachatur Nazaryan",
        "Timothy Zaklama",
        "Liang Fu"
      ],
      "abstract": "The attention mechanism has transformed artificial intelligence research by\nits ability to learn relations between objects. In this work, we explore how a\nmany-body wavefunction ansatz constructed from a large-parameter self-attention\nneural network can be used to solve the interacting electron problem in solids.\nBy a systematic neural-network variational Monte Carlo study on a moir\\'e\nquantum material, we demonstrate that the self-attention ansatz provides an\naccurate, efficient, and unbiased solution. Moreover, our numerical study finds\nthat the required number of variational parameters scales roughly as $N^2$ with\nthe number of electrons, which opens a path towards efficient large-scale\nsimulations.",
      "tldr_zh": "本研究探讨了注意力机制（attention mechanism）是否能有效解决固体中相互作用电子的相关问题，通过构建基于大型参数自注意力神经网络的多体波函数 ansatz 作为波函数近似。研究采用神经网络变分 Monte Carlo 方法，对 moiré 量子材料进行系统研究，结果显示该 ansatz 提供准确、高效且无偏的解决方案。关键发现是所需变分参数数量大致与电子数 N 的平方成正比，这为高效的大规模模拟铺平了道路。",
      "categories": [
        "cond-mat.str-el",
        "cond-mat.mes-hall",
        "cs.AI"
      ],
      "primary_category": "cond-mat.str-el",
      "comment": "10+5 pages, comments welcome; v2: update refs, extend ED results",
      "pdf_url": "http://arxiv.org/pdf/2502.05383v2",
      "published_date": "2025-02-07 23:41:41 UTC",
      "updated_date": "2025-03-10 02:05:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:20:07.166829"
    },
    {
      "arxiv_id": "2502.05370v1",
      "title": "fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Hanfei Yu",
        "Xingqi Cui",
        "Hong Zhang",
        "Hao Wang",
        "Hao Wang"
      ],
      "abstract": "Large Language Models (LLMs) have gained immense success in revolutionizing\nvarious applications, including content generation, search and recommendation,\nand AI-assisted operation. To reduce high training costs, Mixture-of-Experts\n(MoE) architecture has become a popular backbone for modern LLMs. However,\ndespite the benefits, serving MoE-based LLMs experience severe memory\ninefficiency due to sparsely activated experts. Recent studies propose to\noffload inactive experts from GPU memory to CPU memory to improve the serving\nefficiency of MoE models. However, they either incur high inference latency or\nhigh model memory footprints due to coarse-grained designs. To tame the\nlatency-memory trade-off in MoE serving, we present fMoE, a fine-grained expert\noffloading system for MoE serving that achieves low inference latency with\nmemory efficiency. We design fMoE to extract fine-grained expert selection\npatterns from MoE models and semantic hints from input prompts to efficiently\nguide expert prefetching, caching, and offloading decisions. fMoE is prototyped\non top of HuggingFace Transformers and deployed on a six-GPU testbed.\nExperiments with open-source MoE models and real-world workloads show that fMoE\nreduces inference latency by 47% and improves expert hit rate by 36% over\nstate-of-the-art solutions.",
      "tldr_zh": "本文提出 fMoE，一种细粒度专家卸载系统，用于优化大型语言模型 (LLMs) 中 Mixture-of-Experts (MoE) 架构的模型服务，以解决稀疏激活专家导致的内存效率和延迟问题。fMoE 通过从 MoE 模型中提取专家选择模式和从输入提示中获取语义提示，来指导专家的预取、缓存和卸载决策，从而实现低延迟和高内存效率。实验在 HuggingFace Transformers 上进行，结果显示 fMoE 比最先进方案减少了 47% 的推理延迟，并提高了 36% 的专家命中率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05370v1",
      "published_date": "2025-02-07 22:51:17 UTC",
      "updated_date": "2025-02-07 22:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:20:19.949871"
    },
    {
      "arxiv_id": "2502.05352v1",
      "title": "ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks",
      "title_zh": "ITBench：评估 AI 代理在",
      "authors": [
        "Saurabh Jha",
        "Rohan Arora",
        "Yuji Watanabe",
        "Takumi Yanagawa",
        "Yinfang Chen",
        "Jackson Clark",
        "Bhavya Bhavya",
        "Mudit Verma",
        "Harshit Kumar",
        "Hirokuni Kitahara",
        "Noah Zheutlin",
        "Saki Takano",
        "Divya Pathak",
        "Felix George",
        "Xinbo Wu",
        "Bekir O. Turkkan",
        "Gerard Vanloo",
        "Michael Nidd",
        "Ting Dai",
        "Oishik Chatterjee",
        "Pranjal Gupta",
        "Suranjana Samanta",
        "Pooja Aggarwal",
        "Rong Lee",
        "Pavankumar Murali",
        "Jae-wook Ahn",
        "Debanjana Kar",
        "Ameet Rahane",
        "Carlos Fonseca",
        "Amit Paradkar",
        "Yu Deng",
        "Pratibha Moogi",
        "Prateeti Mohapatra",
        "Naoki Abe",
        "Chandrasekhar Narayanaswami",
        "Tianyin Xu",
        "Lav R. Varshney",
        "Ruchi Mahindru",
        "Anca Sailer",
        "Laura Shwartz",
        "Daby Sow",
        "Nicholas C. M. Fuller",
        "Ruchir Puri"
      ],
      "abstract": "Realizing the vision of using AI agents to automate critical IT tasks depends\non the ability to measure and understand effectiveness of proposed solutions.\nWe introduce ITBench, a framework that offers a systematic methodology for\nbenchmarking AI agents to address real-world IT automation tasks. Our initial\nrelease targets three key areas: Site Reliability Engineering (SRE), Compliance\nand Security Operations (CISO), and Financial Operations (FinOps). The design\nenables AI researchers to understand the challenges and opportunities of AI\nagents for IT automation with push-button workflows and interpretable metrics.\nITBench includes an initial set of 94 real-world scenarios, which can be easily\nextended by community contributions. Our results show that agents powered by\nstate-of-the-art models resolve only 13.8% of SRE scenarios, 25.2% of CISO\nscenarios, and 0% of FinOps scenarios. We expect ITBench to be a key enabler of\nAI-driven IT automation that is correct, safe, and fast.",
      "tldr_zh": "本研究引入了ITBench框架，用于系统评估AI代理在真实世界IT自动化任务中的表现，涵盖Site Reliability Engineering (SRE)、Compliance and Security Operations (CISO)以及Financial Operations (FinOps)三大领域。框架提供推按钮工作流、可解释指标和94个真实场景，支持社区扩展，帮助研究人员识别AI代理的挑战与机遇。实验结果显示，使用最先进模型的代理仅成功解决了13.8%的SRE场景、25.2%的CISO场景和0%的FinOps场景。该框架有望推动正确、安全且高效的AI驱动IT自动化发展。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05352v1",
      "published_date": "2025-02-07 21:46:52 UTC",
      "updated_date": "2025-02-07 21:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:20:30.711655"
    },
    {
      "arxiv_id": "2502.05345v1",
      "title": "Estimating Voltage Drop: Models, Features and Data Representation Towards a Neural Surrogate",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Jin",
        "Dimitrios Koutlis",
        "Hector Bandala",
        "Marios Daoutis"
      ],
      "abstract": "Accurate estimation of voltage drop (IR drop) in modern Application-Specific\nIntegrated Circuits (ASICs) is highly time and resource demanding, due to the\ngrowing complexity and the transistor density in recent technology nodes. To\nmitigate this challenge, we investigate how Machine Learning (ML) techniques,\nincluding Extreme Gradient Boosting (XGBoost), Convolutional Neural Network\n(CNN), and Graph Neural Network (GNN) can aid in reducing the computational\neffort and implicitly the time required to estimate the IR drop in Integrated\nCircuits (ICs). Traditional methods, including commercial tools, require\nconsiderable time to produce accurate approximations, especially for\ncomplicated designs with numerous transistors. ML algorithms, on the other\nhand, are explored as an alternative solution to offer quick and precise IR\ndrop estimation, but in considerably less time. Our approach leverages ASICs'\nelectrical, timing, and physical to train ML models, ensuring adaptability\nacross diverse designs with minimal adjustments. Experimental results\nunderscore the superiority of ML models over commercial tools, greatly\nenhancing prediction speed. Particularly, GNNs exhibit promising performance\nwith minimal prediction errors in voltage drop estimation. The incorporation of\nGNNs marks a groundbreaking advancement in accurate IR drop prediction. This\nstudy illustrates the effectiveness of ML algorithms in precisely estimating IR\ndrop and optimizing ASIC sign-off. Utilizing ML models leads to expedited\npredictions, reducing calculation time and improving energy efficiency, thereby\nreducing environmental impact through optimized power circuits.",
      "tldr_zh": "本研究探讨了使用机器学习（ML）技术，包括 XGBoost、CNN 和 GNN，来估计集成电路（ICs）中的电压降（IR drop），旨在解决现代 ASIC 设计中计算资源和时间消耗的问题。通过利用 ASICs 的电气、定时和物理特征训练 ML 模型，该方法实现了对不同设计的适应性。实验结果显示，ML 模型比传统商业工具快得多，且 GNN 表现出色，具有最小预测错误，最终优化了 ASIC 签核流程，提高了能源效率并减少了环境影响。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05345v1",
      "published_date": "2025-02-07 21:31:13 UTC",
      "updated_date": "2025-02-07 21:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:20:43.236923"
    },
    {
      "arxiv_id": "2502.05344v1",
      "title": "RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sicheng Zhong",
        "Jiading Zhu",
        "Yifang Tian",
        "Xujie Si"
      ],
      "abstract": "Scaling automated formal verification to real-world projects requires\nresolving cross-module dependencies and global contexts, which are challenges\noverlooked by existing function-centric methods. We introduce RagVerus, a\nframework that synergizes retrieval-augmented generation with context-aware\nprompting to automate proof synthesis for multi-module repositories, achieving\na 27% relative improvement on our novel RepoVBench benchmark -- the first\nrepository-level dataset for Verus with 383 proof completion tasks. RagVerus\ntriples proof pass rates on existing benchmarks under constrained language\nmodel budgets, demonstrating a scalable and sample-efficient verification.",
      "tldr_zh": "该论文提出 RAG-Verus 框架，利用检索增强生成（RAG）和上下文感知提示，解决现有函数级方法忽略的跨模块依赖和全局上下文问题，从而实现仓库级程序验证的自动化证明合成。在首个仓库级数据集 RepoVBench（包含383个 Verus 证明任务）上，RAG-Verus 实现了27%的相对改进，并在受限语言模型预算下将现有基准的证明通过率提高三倍。该框架展示了高度可扩展和样本高效的验证方法，为真实世界项目的形式验证提供了新途径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05344v1",
      "published_date": "2025-02-07 21:30:37 UTC",
      "updated_date": "2025-02-07 21:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:20:55.406984"
    },
    {
      "arxiv_id": "2502.05330v1",
      "title": "Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Imran",
        "Jonathan R. Krebs",
        "Vishal Balaji Sivaraman",
        "Teng Zhang",
        "Amarjeet Kumar",
        "Walker R. Ueland",
        "Michael J. Fassler",
        "Jinlong Huang",
        "Xiao Sun",
        "Lisheng Wang",
        "Pengcheng Shi",
        "Maximilian Rokuss",
        "Michael Baumgartner",
        "Yannick Kirchhof",
        "Klaus H. Maier-Hein",
        "Fabian Isensee",
        "Shuolin Liu",
        "Bing Han",
        "Bong Thanh Nguyen",
        "Dong-jin Shin",
        "Park Ji-Woo",
        "Mathew Choi",
        "Kwang-Hyun Uhm",
        "Sung-Jea Ko",
        "Chanwoong Lee",
        "Jaehee Chun",
        "Jin Sung Kim",
        "Minghui Zhang",
        "Hanxiao Zhang",
        "Xin You",
        "Yun Gu",
        "Zhaohong Pan",
        "Xuan Liu",
        "Xiaokun Liang",
        "Markus Tiefenthaler",
        "Enrique Almar-Munoz",
        "Matthias Schwab",
        "Mikhail Kotyushev",
        "Rostislav Epifanov",
        "Marek Wodzinski",
        "Henning Muller",
        "Abdul Qayyum",
        "Moona Mazher",
        "Steven A. Niederer",
        "Zhiwei Wang",
        "Kaixiang Yang",
        "Jintao Ren",
        "Stine Sofia Korreman",
        "Yuchong Gao",
        "Hongye Zeng",
        "Haoyu Zheng",
        "Rui Zheng",
        "Jinghua Yue",
        "Fugen Zhou",
        "Bo Liu",
        "Alexander Cosman",
        "Muxuan Liang",
        "Chang Zhao",
        "Gilbert R. Upchurch Jr.",
        "Jun Ma",
        "Yuyin Zhou",
        "Michol A. Cooper",
        "Wei Shao"
      ],
      "abstract": "Multi-class segmentation of the aorta in computed tomography angiography\n(CTA) scans is essential for diagnosing and planning complex endovascular\ntreatments for patients with aortic dissections. However, existing methods\nreduce aortic segmentation to a binary problem, limiting their ability to\nmeasure diameters across different branches and zones. Furthermore, no\nopen-source dataset is currently available to support the development of\nmulti-class aortic segmentation methods. To address this gap, we organized the\nAortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes\nannotated for 23 clinically relevant aortic branches and zones. This dataset\nwas designed to facilitate both model development and validation. The challenge\nattracted 121 teams worldwide, with participants leveraging state-of-the-art\nframeworks such as nnU-Net and exploring novel techniques, including cascaded\nmodels, data augmentation strategies, and custom loss functions. We evaluated\nthe submitted algorithms using the Dice Similarity Coefficient (DSC) and\nNormalized Surface Distance (NSD), highlighting the approaches adopted by the\ntop five performing teams. This paper presents the challenge design, dataset\ndetails, evaluation metrics, and an in-depth analysis of the top-performing\nalgorithms. The annotated dataset, evaluation code, and implementations of the\nleading methods are publicly available to support further research. All\nresources can be accessed at https://aortaseg24.grand-challenge.org.",
      "tldr_zh": "该研究组织了AortaSeg24 MICCAI挑战赛，以解决主动脉在Computed Tomography Angiography (CTA)扫描中的多类分割问题，现有方法仅限于二元分割，无法准确测量不同分支和区域的直径，并首次发布了包含100个CTA卷的开源数据集，标注了23个临床相关的主动脉分支和区域。挑战赛吸引了121个全球团队，使用先进框架如nnU-Net，并探索了新颖技术包括级联模型、数据增强策略和自定义损失函数。参与算法通过Dice Similarity Coefficient (DSC)和Normalized Surface Distance (NSD)进行评估，前五名团队的方法分析显示了显著改进；数据集、评估代码和领先实现已公开可用，网址为https://aortaseg24.grand-challenge.org。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05330v1",
      "published_date": "2025-02-07 21:09:05 UTC",
      "updated_date": "2025-02-07 21:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:21:07.529730"
    },
    {
      "arxiv_id": "2502.05312v1",
      "title": "Towards the Development of Balanced Synthetic Data for Correcting Grammatical Errors in Arabic: An Approach Based on Error Tagging Model and Synthetic Data Generating Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ahlam Alrehili",
        "Areej Alhothali"
      ],
      "abstract": "Synthetic data generation is widely recognized as a way to enhance the\nquality of neural grammatical error correction (GEC) systems. However, current\napproaches often lack diversity or are too simplistic to generate the wide\nrange of grammatical errors made by humans, especially for low-resource\nlanguages such as Arabic. In this paper, we will develop the error tagging\nmodel and the synthetic data generation model to create a large synthetic\ndataset in Arabic for grammatical error correction. In the error tagging model,\nthe correct sentence is categorized into multiple error types by using the\nDeBERTav3 model. Arabic Error Type Annotation tool (ARETA) is used to guide\nmulti-label classification tasks in an error tagging model in which each\nsentence is classified into 26 error tags. The synthetic data generation model\nis a back-translation-based model that generates incorrect sentences by\nappending error tags before the correct sentence that was generated from the\nerror tagging model using the ARAT5 model. In the QALB-14 and QALB-15 Test\nsets, the error tagging model achieved 94.42% F1, which is state-of-the-art in\nidentifying error tags in clean sentences. As a result of our syntactic data\ntraining in grammatical error correction, we achieved a new state-of-the-art\nresult of F1-Score: 79.36% in the QALB-14 Test set. We generate 30,219,310\nsynthetic sentence pairs by using a synthetic data generation model.",
      "tldr_zh": "本研究针对阿拉伯语语法错误修正（Grammatical Error Correction, GEC）系统的改进，提出了一种基于错误标记模型（Error Tagging Model）和合成数据生成模型（Synthetic Data Generating Model）的框架，以生成更平衡和多样的合成数据集。错误标记模型使用 DeBERTa v3 和 ARETA 工具，对正确句子进行多标签分类，共涵盖 26 种错误标签，在 QALB-14 和 QALB-15 测试集上达到 94.42% F1 分数。合成数据生成模型基于 back-translation 技术，利用 ARAT5 模型从正确句子生成错误版本，最终生成了 30,219,310 个合成句子对。通过这些合成数据训练 GEC 系统，该方法在 QALB-14 测试集上实现了 79.36% F1 分数的最新状态，为低资源语言如阿拉伯语的错误修正提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05312v1",
      "published_date": "2025-02-07 20:28:37 UTC",
      "updated_date": "2025-02-07 20:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:21:19.654733"
    },
    {
      "arxiv_id": "2502.05310v1",
      "title": "Oracular Programming: A Modular Foundation for Building LLM-Enabled Software",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Laurent",
        "André Platzer"
      ],
      "abstract": "Large Language Models have proved surprisingly effective at solving a wide\nrange of tasks from just a handful of examples. However, their lack of\nreliability and modularity limits their capacity to tackle large problems that\nrequire many steps of reasoning. In response, researchers have proposed\nadvanced pipelines that leverage domain-specific knowledge to chain smaller\nprompts, provide intermediate feedback and improve performance through search.\nHowever, the current complexity of writing, tuning, maintaining and improving\nsuch pipelines has limited their sophistication. We propose oracular\nprogramming, a foundational paradigm for building LLM-enabled applications that\nlets domain experts express high-level problem-solving strategies as programs\nwith unresolved choice points. These choice points are resolved at runtime by\nLLMs, which generalize from user-provided examples of correct and incorrect\ndecisions. An oracular program is composed of three orthogonal components: a\nstrategy that consists in a nondeterministic program with choice points that\ncan be reified into a search tree, a policy that specifies how to navigate this\ntree with the help of LLM oracles, and a set of demonstrations that describe\nsuccessful and unsuccessful search tree navigation scenarios across diverse\nproblem instances. Each component is expressed in a dedicated programming\nlanguage and can be independently improved or substituted. We address the key\nprogramming language design challenges of modularly composing oracular programs\nand enforcing consistency between their components as they evolve.",
      "tldr_zh": "该论文提出 Oracular Programming 范式，作为构建 LLM-Enabled 软件的模块化基础，以解决大型语言模型（LLMs）在处理多步推理任务时的可靠性和服务模块性不足问题。Oracular Programming 允许领域专家通过非确定性程序表达高层问题解决策略，这些程序包含可重构为搜索树的 choice points，由 LLMs 根据用户提供的 demonstrations 解析。系统由三个正交组件组成：strategy（定义非确定性程序）、policy（指导 LLM oracles 导航搜索树）和 demonstrations（展示成功与失败场景），这些组件使用专用编程语言表达，可独立改进或替换。论文还解决了模块化组合这些组件和维护其一致性的关键编程语言设计挑战，从而简化了 LLM 应用的开发和优化。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05310v1",
      "published_date": "2025-02-07 20:24:43 UTC",
      "updated_date": "2025-02-07 20:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:21:31.664105"
    },
    {
      "arxiv_id": "2502.05300v1",
      "title": "Parameter Symmetry Breaking and Restoration Determines the Hierarchical Learning in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Ziyin",
        "Yizhou Xu",
        "Tomaso Poggio",
        "Isaac Chuang"
      ],
      "abstract": "The dynamics of learning in modern large AI systems is hierarchical, often\ncharacterized by abrupt, qualitative shifts akin to phase transitions observed\nin physical systems. While these phenomena hold promise for uncovering the\nmechanisms behind neural networks and language models, existing theories remain\nfragmented, addressing specific cases. In this paper, we posit that parameter\nsymmetry breaking and restoration serve as a unifying mechanism underlying\nthese behaviors. We synthesize prior observations and show how this mechanism\nexplains three distinct hierarchies in neural networks: learning dynamics,\nmodel complexity, and representation formation. By connecting these\nhierarchies, we highlight symmetry -- a cornerstone of theoretical physics --\nas a potential fundamental principle in modern AI.",
      "tldr_zh": "这篇论文提出，参数对称性破坏（parameter symmetry breaking）和恢复（restoration）作为一种统一机制，解释了现代 AI 系统中的分层学习现象，包括类似于物理相变的突变行为。作者综合现有观察，展示了这一机制如何适用于神经网络的三个层次：学习动态、模型复杂性和表示形成。通过连接这些层次，论文强调对称性（symmetry）可能成为 AI 的基本原则，为理解 AI 系统的行为提供了一个整合框架。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05300v1",
      "published_date": "2025-02-07 20:10:05 UTC",
      "updated_date": "2025-02-07 20:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:21:42.510837"
    },
    {
      "arxiv_id": "2502.05292v1",
      "title": "Drone Detection and Tracking with YOLO and a Rule-based Method",
      "title_zh": "基于 YOLO 和规则方法的无人机检测与跟踪",
      "authors": [
        "Purbaditya Bhattacharya",
        "Patrick Nowak"
      ],
      "abstract": "Drones or unmanned aerial vehicles are traditionally used for military\nmissions, warfare, and espionage. However, the usage of drones has\nsignificantly increased due to multiple industrial applications involving\nsecurity and inspection, transportation, research purposes, and recreational\ndrone flying. Such an increased volume of drone activity in public spaces\nrequires regulatory actions for purposes of privacy protection and safety.\nHence, detection of illegal drone activities such as boundary encroachment\nbecomes a necessity. Such detection tasks are usually automated and performed\nby deep learning models which are trained on annotated image datasets. This\npaper builds on a previous work and extends an already published open source\ndataset. A description and analysis of the entire dataset is provided. The\ndataset is used to train the YOLOv7 deep learning model and some of its minor\nvariants and the results are provided. Since the detection models are based on\na single image input, a simple cross-correlation based tracker is used to\nreduce detection drops and improve tracking performance in videos. Finally, the\nentire drone detection system is summarized.",
      "tldr_zh": "该论文探讨了无人机（drones）的检测和追踪问题，强调其在工业、安全和娱乐领域的广泛应用需要监管以防范非法活动如边界入侵。研究者扩展了一个开源数据集，并对其进行了详细描述和分析，随后使用YOLOv7模型及其变体进行训练，取得了有效的检测结果。为了改善视频追踪性能，他们引入了一个基于交叉相关（cross-correlation）的简单规则方法，减少检测失误。整体系统总结展示了这一自动化检测框架在隐私保护和安全方面的潜在应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05292v1",
      "published_date": "2025-02-07 19:53:10 UTC",
      "updated_date": "2025-02-07 19:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:21:53.666703"
    },
    {
      "arxiv_id": "2502.06858v1",
      "title": "LLM-Supported Natural Language to Bash Translation",
      "title_zh": "LLM 支持的自然语言到 Bash 翻译",
      "authors": [
        "Finnian Westenfelder",
        "Erik Hemberg",
        "Miguel Tulla",
        "Stephen Moskal",
        "Una-May O'Reilly",
        "Silviu Chiricescu"
      ],
      "abstract": "The Bourne-Again Shell (Bash) command-line interface for Linux systems has\ncomplex syntax and requires extensive specialized knowledge. Using the natural\nlanguage to Bash command (NL2SH) translation capabilities of large language\nmodels (LLMs) for command composition circumvents these issues. However, the\nNL2SH performance of LLMs is difficult to assess due to inaccurate test data\nand unreliable heuristics for determining the functional equivalence of Bash\ncommands. We present a manually verified test dataset of 600\ninstruction-command pairs and a training dataset of 40,939 pairs, increasing\nthe size of previous datasets by 441% and 135%, respectively. Further, we\npresent a novel functional equivalence heuristic that combines command\nexecution with LLM evaluation of command outputs. Our heuristic can determine\nthe functional equivalence of two Bash commands with 95% confidence, a 16%\nincrease over previous heuristics. Evaluation of popular LLMs using our test\ndataset and heuristic demonstrates that parsing, in-context learning, in-weight\nlearning, and constrained decoding can improve NL2SH accuracy by up to 32%. Our\nfindings emphasize the importance of dataset quality, execution-based\nevaluation and translation method for advancing NL2SH translation. Our code is\navailable at https://github.com/westenfelder/NL2SH",
      "tldr_zh": "这篇论文探讨了使用大语言模型 (LLMs) 支持的自然语言到 Bash 命令 (NL2SH) 翻译，以简化 Bash 的复杂语法和专业知识需求。研究者构建了一个手动验证的测试数据集（600 对指令-命令对）和训练数据集（40,939 对），分别比现有数据集扩大 441% 和 135%。他们提出了一种新颖的功能等价启发式方法，通过命令执行结合 LLM 对输出评估，实现 95% 置信度的等价判断，比之前方法提升 16%。实验结果显示，解析、in-context learning、in-weight learning 和 constrained decoding 等技术可将 NL2SH 准确率提高最多 32%，并强调了数据集质量、基于执行的评估和翻译方法的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.06858v1",
      "published_date": "2025-02-07 19:35:55 UTC",
      "updated_date": "2025-02-07 19:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:22:07.786841"
    },
    {
      "arxiv_id": "2502.05234v1",
      "title": "Optimizing Temperature for Language Models with Multi-Sample Inference",
      "title_zh": "通过多样本推理优化语言模型的温度",
      "authors": [
        "Weihua Du",
        "Yiming Yang",
        "Sean Welleck"
      ],
      "abstract": "Multi-sample aggregation strategies, such as majority voting and best-of-N\nsampling, are widely used in contemporary large language models (LLMs) to\nenhance predictive accuracy across various tasks. A key challenge in this\nprocess is temperature selection, which significantly impacts model\nperformance. Existing approaches either rely on a fixed default temperature or\nrequire labeled validation data for tuning, which are often scarce and\ndifficult to obtain. This paper addresses the challenge of automatically\nidentifying the (near)-optimal temperature for different LLMs using\nmulti-sample aggregation strategies, without relying on task-specific\nvalidation data. We provide a comprehensive analysis of temperature's role in\nperformance optimization, considering variations in model architectures,\ndatasets, task types, model sizes, and predictive accuracy. Furthermore, we\npropose a novel entropy-based metric for automated temperature optimization,\nwhich consistently outperforms fixed-temperature baselines. Additionally, we\nincorporate a stochastic process model to enhance interpretability, offering\ndeeper insights into the relationship between temperature and model\nperformance.",
      "tldr_zh": "本论文探讨了多样本聚合策略（如 majority voting 和 best-of-N sampling）在大型语言模型（LLMs）中的应用，重点解决温度（temperature）选择对性能的影响问题，因为现有方法依赖固定温度或稀缺的标记验证数据。作者通过全面分析温度在不同模型架构、数据集、任务类型、模型大小和预测准确率中的作用，提出了一种基于熵（entropy-based metric）的自动优化方法，以及一个随机过程模型（stochastic process model）来提升可解释性。该方法无需任务特定验证数据，即可显著优于固定温度基线，在性能优化方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages. Code available at https://github.com/StigLidu/TURN",
      "pdf_url": "http://arxiv.org/pdf/2502.05234v1",
      "published_date": "2025-02-07 19:35:25 UTC",
      "updated_date": "2025-02-07 19:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:22:18.805988"
    },
    {
      "arxiv_id": "2502.05282v1",
      "title": "Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting He",
        "Boyu Wang",
        "Rongjun Ge",
        "Yang Chen",
        "Guanyu Yang",
        "Shuo Li"
      ],
      "abstract": "Dense contrastive representation learning (DCRL) has greatly improved the\nlearning efficiency for image-dense prediction tasks, showing its great\npotential to reduce the large costs of medical image collection and dense\nannotation. However, the properties of medical images make unreliable\ncorrespondence discovery, bringing an open problem of large-scale false\npositive and negative (FP&N) pairs in DCRL. In this paper, we propose GEoMetric\nvIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism prior\nto DCRL and enables a reliable correspondence discovery for effective dense\ncontrast. We propose a deformable homeomorphism learning (DHL) which models the\nhomeomorphism of medical images and learns to estimate a deformable mapping to\npredict the pixels' correspondence under topological preservation. It\neffectively reduces the searching space of pairing and drives an implicit and\nsoft learning of negative pairs via a gradient. We also propose a geometric\nsemantic similarity (GSS) which extracts semantic information in features to\nmeasure the alignment degree for the correspondence learning. It will promote\nthe learning efficiency and performance of deformation, constructing positive\npairs reliably. We implement two practical variants on two typical\nrepresentation learning tasks in our experiments. Our promising results on\nseven datasets which outperform the existing methods show our great\nsuperiority. We will release our code on a companion link:\nhttps://github.com/YutingHe-list/GEMINI.",
      "tldr_zh": "本研究针对医疗图像密集对比学习（DCRL）中假阳性和假阴性（FP&N）问题提出GEMINI学习框架，该框架通过嵌入homeomorphism prior来实现可靠的对应关系发现。GEMINI包括可变形homeomorphism学习（DHL），用于模型化图像拓扑并估计可变形映射以减少配对搜索空间，以及几何语义相似性（GSS），通过提取特征语义信息提升对应关系的学习效率和准确性。实验在七个数据集上验证了GEMINI的两个变体，显著优于现有方法，并在典型表示学习任务中展示了其潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by T-PAMI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05282v1",
      "published_date": "2025-02-07 19:34:22 UTC",
      "updated_date": "2025-02-07 19:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:22:30.675955"
    },
    {
      "arxiv_id": "2502.05264v1",
      "title": "Quantum automated learning with provable and explainable trainability",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Ye",
        "Shuangyue Geng",
        "Zizhao Han",
        "Weikang Li",
        "L. -M. Duan",
        "Dong-Ling Deng"
      ],
      "abstract": "Machine learning is widely believed to be one of the most promising practical\napplications of quantum computing. Existing quantum machine learning schemes\ntypically employ a quantum-classical hybrid approach that relies crucially on\ngradients of model parameters. Such an approach lacks provable convergence to\nglobal minima and will become infeasible as quantum learning models scale up.\nHere, we introduce quantum automated learning, where no variational parameter\nis involved and the training process is converted to quantum state preparation.\nIn particular, we encode training data into unitary operations and iteratively\nevolve a random initial state under these unitaries and their inverses, with a\ntarget-oriented perturbation towards higher prediction accuracy sandwiched in\nbetween. Under reasonable assumptions, we rigorously prove that the evolution\nconverges exponentially to the desired state corresponding to the global\nminimum of the loss function. We show that such a training process can be\nunderstood from the perspective of preparing quantum states by imaginary time\nevolution, where the data-encoded unitaries together with target-oriented\nperturbations would train the quantum learning model in an automated fashion.\nWe further prove that the quantum automated learning paradigm features good\ngeneralization ability with the generalization error upper bounded by the ratio\nbetween a logarithmic function of the Hilbert space dimension and the number of\ntraining samples. In addition, we carry out extensive numerical simulations on\nreal-life images and quantum data to demonstrate the effectiveness of our\napproach and validate the assumptions. Our results establish an unconventional\nquantum learning strategy that is gradient-free with provable and explainable\ntrainability, which would be crucial for large-scale practical applications of\nquantum computing in machine learning scenarios.",
      "tldr_zh": "这篇论文提出了量子自动学习（quantum automated learning）框架，一种无需变分参数的量子机器学习方法，通过将训练数据编码成幺正运算（unitary operations）并迭代演化初始量子状态，加上目标导向扰动，实现指数级收敛到全局最小损失函数的状态。作者证明了该方法在合理假设下具有可证明的收敛性和可解释性，并上界了泛化误差（generalization error），使其优于传统依赖梯度的混合方法。通过对真实图像和量子数据的数值模拟，验证了框架的有效性，为大规模量子计算在机器学习中的实际应用提供了可靠策略。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "21 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05264v1",
      "published_date": "2025-02-07 19:00:02 UTC",
      "updated_date": "2025-02-07 19:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:22:42.533221"
    },
    {
      "arxiv_id": "2503.04752v1",
      "title": "Transforming Student Evaluation with Adaptive Intelligence and Performance Analytics",
      "title_zh": "通过自适应智能和性能分析变革学生评估",
      "authors": [
        "Pushpalatha K S",
        "Abhishek Mangalur",
        "Ketan Hegde",
        "Chetan Badachi",
        "Mohammad Aamir"
      ],
      "abstract": "The development in Artificial Intelligence (AI) offers transformative\npotential for redefining student assessment methodologies. This paper aims to\nestablish the idea of the advancement of Artificial Intelligence (AI) and its\nprospect in reshaping approaches to assessing students. It creates a system for\nthe evaluation of students performance using Artificial intelligence, and\nparticularly the Gemini API for the generation of questions, grading and report\non the students performances. This is to facilitate easy use of the tools in\ncreating, scheduling, and delivering assessments with minimal chances of\ncheating through options such as full screen and time limit. There are formats\nof questions in the system which comprises multiple choice, short answers and\ndescriptive questions, developed by Gemini. The most conspicuous feature is the\nself-checking system whereby the user gets instant feedback for the correct\nscore that each of the students would have scored instantly with explanations\nabout wrong answers. Moreover, the platform has intelligent learning\nprogressions where the user will be able to monitor his/her performances to be\nrecommended a certain level of performance. It will allow students as well as\neducators to have real-time analytics and feedback on what they are good at and\nwhere they need to improve. Not only does it make the assessment easier, but it\nalso improves the levels of accuracy in grading and effectively strengthens a\ndata based learning process for students.",
      "tldr_zh": "本论文提出了一种利用自适应智能和性能分析重塑学生评估的方法，旨在通过人工智能（AI）提升评估效率和准确性。系统采用 Gemini API 生成多种问题格式（如多项选择、简答和描述性问题）、自动评分、报告生成，并整合防作弊措施（如全屏和时间限制）。此外，该平台提供即时反馈、智能学习进度跟踪和实时分析，帮助学生和教师识别优势与改进领域，最终强化基于数据的个性化学习过程。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.04752v1",
      "published_date": "2025-02-07 18:57:51 UTC",
      "updated_date": "2025-02-07 18:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:22:53.856781"
    },
    {
      "arxiv_id": "2502.05174v2",
      "title": "MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison",
      "title_zh": "MELON：通过屏蔽重执行和工具比较的可证明间接提示注入防御",
      "authors": [
        "Kaijie Zhu",
        "Xianjun Yang",
        "Jindong Wang",
        "Wenbo Guo",
        "William Yang Wang"
      ],
      "abstract": "Recent research has explored that LLM agents are vulnerable to indirect\nprompt injection (IPI) attacks, where malicious tasks embedded in\ntool-retrieved information can redirect the agent to take unauthorized actions.\nExisting defenses against IPI have significant limitations: either require\nessential model training resources, lack effectiveness against sophisticated\nattacks, or harm the normal utilities. We present MELON (Masked re-Execution\nand TooL comparisON), a novel IPI defense. Our approach builds on the\nobservation that under a successful attack, the agent's next action becomes\nless dependent on user tasks and more on malicious tasks. Following this, we\ndesign MELON to detect attacks by re-executing the agent's trajectory with a\nmasked user prompt modified through a masking function. We identify an attack\nif the actions generated in the original and masked executions are similar. We\nalso include three key designs to reduce the potential false positives and\nfalse negatives. Extensive evaluation on the IPI benchmark AgentDojo\ndemonstrates that MELON outperforms SOTA defenses in both attack prevention and\nutility preservation. Moreover, we show that combining MELON with a SOTA prompt\naugmentation defense (denoted as MELON-Aug) further improves its performance.\nWe also conduct a detailed ablation study to validate our key designs.",
      "tldr_zh": "该研究针对LLM代理在间接提示注入(IPI)攻击下的漏洞，提出了一种可证明的防御框架MELON，通过掩码重新执行和工具比较来检测攻击。MELON基于攻击下代理动作依赖性的观察，设计了重新执行代理轨迹并使用掩码函数修改用户提示的方法，如果原始和掩码执行中的动作相似，则标识为攻击，并通过三个关键设计减少假阳性和假阴性。在IPI基准AgentDojo上的广泛评估显示，MELON在攻击预防和实用性保留方面优于现有最先进防御，与提示增强防御结合后进一步提升性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05174v2",
      "published_date": "2025-02-07 18:57:49 UTC",
      "updated_date": "2025-05-01 20:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:23:06.662742"
    },
    {
      "arxiv_id": "2502.05172v2",
      "title": "Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Ludziejewski",
        "Maciej Pióro",
        "Jakub Krajewski",
        "Maciej Stefaniak",
        "Michał Krutul",
        "Jan Małaśnicki",
        "Marek Cygan",
        "Piotr Sankowski",
        "Kamil Adamczewski",
        "Piotr Miłoś",
        "Sebastian Jaszczur"
      ],
      "abstract": "Mixture of Experts (MoE) architectures have significantly increased\ncomputational efficiency in both research and real-world applications of\nlarge-scale machine learning models. However, their scalability and efficiency\nunder memory constraints remain relatively underexplored. In this work, we\npresent joint scaling laws for dense and MoE models, incorporating key factors\nsuch as the number of active parameters, dataset size, and the number of\nexperts. Our findings provide a principled framework for selecting the optimal\nMoE configuration under fixed memory and compute budgets. Surprisingly, we show\nthat MoE models can be more memory-efficient than dense models, contradicting\nconventional wisdom. To derive and validate the theoretical predictions of our\nscaling laws, we conduct over 280 experiments with up to 2.7B active parameters\nand up to 5B total parameters. These results offer actionable insights for\ndesigning and deploying MoE models in practical large-scale training scenarios.",
      "tldr_zh": "本文提出联合缩放定律（joint scaling laws），针对Mixture of Experts (MoE)模型和密集模型（dense models），整合活跃参数数量、数据集大小以及专家数量等关键因素，以优化在固定内存和计算预算下的MoE配置。研究发现，MoE模型在内存效率上可能优于dense models，这颠覆了传统认知。通过超过280个实验（涉及多达2.7B活跃参数和5B总参数），验证了这些理论预测，并为大规模训练场景中设计和部署MoE模型提供了实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05172v2",
      "published_date": "2025-02-07 18:55:38 UTC",
      "updated_date": "2025-02-19 14:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:23:18.611854"
    },
    {
      "arxiv_id": "2502.05151v2",
      "title": "Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Steffen Eger",
        "Yong Cao",
        "Jennifer D'Souza",
        "Andreas Geiger",
        "Christian Greisinger",
        "Stephanie Gross",
        "Yufang Hou",
        "Brigitte Krenn",
        "Anne Lauscher",
        "Yizhi Li",
        "Chenghua Lin",
        "Nafise Sadat Moosavi",
        "Wei Zhao",
        "Tristan Miller"
      ],
      "abstract": "With the advent of large multimodal language models, science is now at a\nthreshold of an AI-based technological transformation. Recently, a plethora of\nnew AI models and tools has been proposed, promising to empower researchers and\nacademics worldwide to conduct their research more effectively and efficiently.\nThis includes all aspects of the research cycle, especially (1) searching for\nrelevant literature; (2) generating research ideas and conducting\nexperimentation; generating (3) text-based and (4) multimodal content (e.g.,\nscientific figures and diagrams); and (5) AI-based automatic peer review. In\nthis survey, we provide an in-depth overview over these exciting recent\ndevelopments, which promise to fundamentally alter the scientific research\nprocess for good. Our survey covers the five aspects outlined above, indicating\nrelevant datasets, methods and results (including evaluation) as well as\nlimitations and scope for future research. Ethical concerns regarding\nshortcomings of these tools and potential for misuse (fake science, plagiarism,\nharms to research integrity) take a particularly prominent place in our\ndiscussion. We hope that our survey will not only become a reference guide for\nnewcomers to the field but also a catalyst for new AI-based initiatives in the\narea of \"AI4Science\".",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（Large Language Models）如何通过AI辅助科学发现、实验、内容生成和评估来变革科学领域。它涵盖了五个关键方面，包括搜索相关文献、生成研究想法和实验、创建文本和多模态内容（如科学图表），以及AI驱动的自动同行评审，并总结了相关数据集、方法、结果和评估。论文强调了这些工具的潜力在提升研究效率的同时，也存在伦理挑战，如误用风险（包括假科学、剽窃和对研究诚信的危害），并为未来“AI4Science”研究指出了限制和机会。该调查旨在作为新手参考指南，并推动AI在科学中的创新应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "44 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05151v2",
      "published_date": "2025-02-07 18:26:45 UTC",
      "updated_date": "2025-04-16 10:54:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:23:30.570965"
    },
    {
      "arxiv_id": "2502.05147v3",
      "title": "LP-DETR: Layer-wise Progressive Relations for Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengjian Kang",
        "Ye Zhang",
        "Xiaoyu Deng",
        "Xintao Li",
        "Yongzhe Zhang"
      ],
      "abstract": "This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approach\nthat enhances DETR-based object detection through multi-scale relation\nmodeling. Our method introduces learnable spatial relationships between object\nqueries through a relation-aware self-attention mechanism, which adaptively\nlearns to balance different scales of relations (local, medium and global)\nacross decoder layers. This progressive design enables the model to effectively\ncapture evolving spatial dependencies throughout the detection pipeline.\nExtensive experiments on COCO 2017 dataset demonstrate that our method improves\nboth convergence speed and detection accuracy compared to standard\nself-attention module. The proposed method achieves competitive results,\nreaching 52.3\\% AP with 12 epochs and 52.5\\% AP with 24 epochs using ResNet-50\nbackbone, and further improving to 58.0\\% AP with Swin-L backbone. Furthermore,\nour analysis reveals an interesting pattern: the model naturally learns to\nprioritize local spatial relations in early decoder layers while gradually\nshifting attention to broader contexts in deeper layers, providing valuable\ninsights for future research in object detection.",
      "tldr_zh": "本文提出 LP-DETR，一种通过层级渐进关系（layer-wise progressive relations）增强 DETR-based 物体检测的方法，旨在通过 relation-aware self-attention 机制适应性地学习不同尺度的空间关系（局部、中等和全局）。该机制在解码器层中逐步平衡和捕获演变的空间依赖，从而提高模型的收敛速度和检测准确率。在 COCO 2017 数据集实验中，LP-DETR 使用 ResNet-50 骨干网络在 12 epochs 时达到 52.3% AP，在 24 epochs 时达到 52.5% AP，并使用 Swin-L 骨干网络进一步提升至 58.0% AP。分析显示，模型在早期解码器层优先关注局部关系，而在深层逐渐转向全局上下文，为未来物体检测研究提供了宝贵启示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05147v3",
      "published_date": "2025-02-07 18:25:28 UTC",
      "updated_date": "2025-05-12 22:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:23:43.715510"
    },
    {
      "arxiv_id": "2502.06857v1",
      "title": "Gemstones: A Model Suite for Multi-Faceted Scaling Laws",
      "title_zh": "翻译失败",
      "authors": [
        "Sean McLeish",
        "John Kirchenbauer",
        "David Yu Miller",
        "Siddharth Singh",
        "Abhinav Bhatele",
        "Micah Goldblum",
        "Ashwinee Panda",
        "Tom Goldstein"
      ],
      "abstract": "Scaling laws are typically fit using a family of models with a narrow range\nof frozen hyper-parameter choices. In this work we study scaling laws using a\nwide range of architecture and hyper-parameter choices, and highlight their\nimpact on resulting prescriptions. As a primary artifact of our research, we\nrelease the Gemstones: the most comprehensive open-source scaling law dataset\nto date, consisting of over 4000 checkpoints from transformers with up to 2\nbillion parameters; these models have been trained with different learning\nrates, cooldown schedules, and architectural shapes. Our checkpoints enable\nmore complex studies of scaling, such as a law that predicts language modeling\nperformance as a function of model width and depth. By examining the various\nfacets of our model suite, we find that the prescriptions of scaling laws can\nbe highly sensitive to the experimental design process and the specific model\ncheckpoints used during fitting. Code:\nhttps://github.com/mcleish7/gemstone-scaling-laws",
      "tldr_zh": "本文研究了scaling laws的拟合问题，使用广泛的架构和超参数选择（如不同学习率、冷却时间表和模型形状），以揭示这些因素对结果的影响。作者发布了Gemstones数据集，这是迄今为止最全面的开源scaling law数据集，包含超过4000个Transformer模型检查点（最多20亿参数），支持更复杂的分析，例如预测语言建模性能作为模型宽度和深度的函数。通过实验，他们发现scaling laws的预测高度敏感于实验设计和所用模型检查点，为未来研究提供了宝贵资源。代码可在GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06857v1",
      "published_date": "2025-02-07 18:09:38 UTC",
      "updated_date": "2025-02-07 18:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:23:54.713825"
    },
    {
      "arxiv_id": "2502.05130v2",
      "title": "Latent Swap Joint Diffusion for 2D Long-Form Latent Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yusheng Dai",
        "Chenxi Wang",
        "Chang Li",
        "Chen Wang",
        "Jun Du",
        "Kewei Li",
        "Ruoyu Wang",
        "Jiefeng Ma",
        "Lei Sun",
        "Jianqing Gao"
      ],
      "abstract": "This paper introduces Swap Forward (SaFa), a modality-agnostic and efficient\nmethod to generate seamless and coherence long spectrum and panorama through\nlatent swap joint diffusion across multi-views. We first investigate the\nspectrum aliasing problem in spectrum-based audio generation caused by existing\njoint diffusion methods. Through a comparative analysis of the VAE latent\nrepresentation of Mel-spectra and RGB images, we identify that the failure\narises from excessive suppression of high-frequency components during the\nspectrum denoising process due to the averaging operator. To address this\nissue, we propose Self-Loop Latent Swap, a frame-level bidirectional swap\napplied to the overlapping region of adjacent views. Leveraging stepwise\ndifferentiated trajectories of adjacent subviews, this swap operator adaptively\nenhances high-frequency components and avoid spectrum distortion. Furthermore,\nto improve global cross-view consistency in non-overlapping regions, we\nintroduce Reference-Guided Latent Swap, a unidirectional latent swap operator\nthat provides a centralized reference trajectory to synchronize subview\ndiffusions. By refining swap timing and intervals, we can achieve a cross-view\nsimilarity-diversity balance in a forward-only manner. Quantitative and\nqualitative experiments demonstrate that SaFa significantly outperforms\nexisting joint diffusion methods and even training-based methods in audio\ngeneration using both U-Net and DiT models, along with effective longer length\nadaptation. It also adapts well to panorama generation, achieving comparable\nperformance with 2 $\\sim$ 20 $\\times$ faster speed and greater model\ngeneralizability. More generation demos are available at\nhttps://swapforward.github.io/",
      "tldr_zh": "这篇论文引入了Swap Forward (SaFa)，一种模态无关且高效的方法，通过潜在空间的联合扩散生成无缝且连贯的2D长形式频谱和全景，以解决现有方法导致的频谱混叠问题。作者提出Self-Loop Latent Swap（应用于相邻视图重叠区域的帧级双向交换）和Reference-Guided Latent Swap（单向交换以提升非重叠区域的全局一致性），这些技术通过优化交换时机和间隔，适应性地增强高频组件并平衡跨视图的相似性与多样性。实验结果表明，SaFa在音频生成中使用U-Net和DiT模型时显著优于现有和基于训练的方法，并在全景生成中实现了2~20倍的加速和更好的模型泛化性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05130v2",
      "published_date": "2025-02-07 18:02:47 UTC",
      "updated_date": "2025-03-18 04:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:24:07.395922"
    },
    {
      "arxiv_id": "2502.06855v2",
      "title": "Self-Supervised Prompt Optimization",
      "title_zh": "自监督提示优化",
      "authors": [
        "Jinyu Xiang",
        "Jiayi Zhang",
        "Zhaoyang Yu",
        "Fengwei Teng",
        "Jinhao Tu",
        "Xinbing Liang",
        "Sirui Hong",
        "Chenglin Wu",
        "Yuyu Luo"
      ],
      "abstract": "Well-designed prompts are crucial for enhancing Large language models' (LLMs)\nreasoning capabilities while aligning their outputs with task requirements\nacross diverse domains. However, manually designed prompts require expertise\nand iterative experimentation. While existing prompt optimization methods aim\nto automate this process, they rely heavily on external references such as\nground truth or by humans, limiting their applicability in real-world scenarios\nwhere such data is unavailable or costly to obtain. To address this, we propose\nSelf-Supervised Prompt Optimization (SPO), a cost-efficient framework that\ndiscovers effective prompts for both closed and open-ended tasks without\nrequiring external reference. Motivated by the observations that prompt quality\nmanifests directly in LLM outputs and LLMs can effectively assess adherence to\ntask requirements, we derive evaluation and optimization signals purely from\noutput comparisons. Specifically, SPO selects superior prompts through pairwise\noutput comparisons evaluated by an LLM evaluator, followed by an LLM optimizer\nthat aligns outputs with task requirements. Extensive experiments demonstrate\nthat SPO outperforms state-of-the-art prompt optimization methods, achieving\ncomparable or superior results with significantly lower costs (e.g., 1.1% to\n5.6% of existing methods) and fewer samples (e.g., three samples). The code is\navailable at https://github.com/geekan/MetaGPT/blob/main/examples/spo",
      "tldr_zh": "本研究提出Self-Supervised Prompt Optimization (SPO)，一种无需外部参考（如ground truth）的框架，用于自动优化Large Language Models (LLMs)的提示，从而提升其在封闭和开放任务中的推理能力和输出一致性。SPO通过LLM评估器进行成对输出比较来选择优越提示，并利用LLM优化器调整输出以符合任务要求，实现高效的自监督优化。实验结果显示，SPO优于现有方法，在成本上仅需对手法的1.1%至5.6%，并使用更少样本（如三样本）即可达到相当或更好的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06855v2",
      "published_date": "2025-02-07 17:45:16 UTC",
      "updated_date": "2025-02-15 08:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:24:17.979008"
    },
    {
      "arxiv_id": "2502.05115v2",
      "title": "\"It Felt Like I Was Left in the Dark\": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Shihan Fu",
        "Bingsheng Yao",
        "Smit Desai",
        "Yuqi Hu",
        "Yuling Sun",
        "Samantha Stonbraker",
        "Yanjun Gao",
        "Elizabeth M. Goldberg",
        "Dakuo Wang"
      ],
      "abstract": "Older adult patients constitute a rapidly growing subgroup of Intensive Care\nUnit (ICU) patients. In these situations, their family caregivers are expected\nto represent the unconscious patients to access and interpret patients' medical\ninformation. However, caregivers currently have to rely on overloaded\nclinicians for information updates and typically lack the health literacy to\nunderstand complex medical information. Our project aims to explore the\ninformation needs of caregivers of ICU older adult patients, from which we can\npropose design opportunities to guide future AI systems. The project begins\nwith formative interviews with 11 caregivers to identify their challenges in\naccessing and interpreting medical information; From these findings, we then\nsynthesize design requirements and propose an AI system prototype to cope with\ncaregivers' challenges. The system prototype has two key features: a timeline\nvisualization to show the AI extracted and summarized older adult patients' key\nmedical events; and an LLM-based chatbot to provide context-aware informational\nsupport. We conclude our paper by reporting on the follow-up user evaluation of\nthe system and discussing future AI-based systems for ICU caregivers of older\nadults.",
      "tldr_zh": "这篇论文探讨了 ICU（Intensive Care Unit）中老年患者家庭护理者的信息需求和挑战，他们在获取和解释复杂医疗信息时往往依赖负担过重的临床医生，并缺乏健康素养。研究通过对 11 名护理者的形成性访谈，识别了关键问题，并据此提出设计要求和一个 AI 系统原型，该原型包括时间线可视化（用于提取和总结患者关键医疗事件）和基于 LLM（Large Language Model）的聊天机器人（提供上下文感知支持）。最终，用户评估证实了系统的有效性，并为未来 AI 辅助系统设计提供了宝贵机会。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05115v2",
      "published_date": "2025-02-07 17:38:10 UTC",
      "updated_date": "2025-04-05 02:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:24:30.923953"
    },
    {
      "arxiv_id": "2502.05111v1",
      "title": "Flexible and Efficient Grammar-Constrained Decoding",
      "title_zh": "灵活且高效的语法约束解码",
      "authors": [
        "Kanghee Park",
        "Timothy Zhou",
        "Loris D'Antoni"
      ],
      "abstract": "Large Language Models (LLMs) are often asked to generate structured outputs\nthat obey precise syntactic rules, such as code snippets or formatted data.\nGrammar-constrained decoding (GCD) can guarantee that LLM outputs matches such\nrules by masking out tokens that will provably lead to outputs that do not\nbelong to a specified context-free grammar (CFG). To guarantee soundness, GCD\nalgorithms have to compute how a given LLM subword tokenizer can align with the\ntokens used\n  by a given context-free grammar and compute token masks based on this\ninformation. Doing so efficiently is challenging and existing GCD algorithms\nrequire tens of minutes to preprocess common grammars. We present a new GCD\nalgorithm together with an implementation that offers 17.71x faster offline\npreprocessing than existing approaches while preserving state-of-the-art\nefficiency in online mask computation.",
      "tldr_zh": "本研究针对大语言模型(LLMs)生成符合精确语法规则的结构化输出（如代码片段）的问题，提出了一种灵活且高效的Grammar-constrained decoding (GCD)算法。该算法通过优化LLM子词标记器与上下文无关文法(CFG)的对齐计算，实现了17.71倍的离线预处理速度提升，同时保持了在线掩码计算的先进效率。与现有方法相比，新算法显著减少了预处理时间，确保输出始终遵守指定语法规则。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05111v1",
      "published_date": "2025-02-07 17:35:17 UTC",
      "updated_date": "2025-02-07 17:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:24:43.351124"
    },
    {
      "arxiv_id": "2502.05110v1",
      "title": "ApplE: An Applied Ethics Ontology with Event Context",
      "title_zh": "翻译失败",
      "authors": [
        "Aisha Aijaz",
        "Raghava Mutharaju",
        "Manohar Kumar"
      ],
      "abstract": "Applied ethics is ubiquitous in most domains, requiring much deliberation due\nto its philosophical nature. Varying views often lead to conflicting courses of\naction where ethical dilemmas become challenging to resolve. Although many\nfactors contribute to such a decision, the major driving forces can be\ndiscretized and thus simplified to provide an indicative answer. Knowledge\nrepresentation and reasoning offer a way to explicitly translate abstract\nethical concepts into applicable principles within the context of an event. To\nachieve this, we propose ApplE, an Applied Ethics ontology that captures\nphilosophical theory and event context to holistically describe the morality of\nan action. The development process adheres to a modified version of the\nSimplified Agile Methodology for Ontology Development (SAMOD) and utilizes\nstandard design and publication practices. Using ApplE, we model a use case\nfrom the bioethics domain that demonstrates our ontology's social and\nscientific value. Apart from the ontological reasoning and quality checks,\nApplE is also evaluated using the three-fold testing process of SAMOD. ApplE\nfollows FAIR principles and aims to be a viable resource for applied ethicists\nand ontology engineers.",
      "tldr_zh": "该论文提出ApplE本体，一种结合哲学理论和事件上下文的应用伦理学本体，旨在通过知识表示和推理将抽象的伦理概念转化为可应用的原则，以简化伦理决策过程。开发过程采用修改后的Simplified Agile Methodology for Ontology Development (SAMOD)，并遵循标准设计和发布实践。研究通过生物伦理学领域的用例建模，展示了ApplE的社会和科学价值，并通过本体推理、质量检查和三折测试验证其可靠性，最终符合FAIR principles，成为伦理学家和本体工程师的宝贵资源。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05110v1",
      "published_date": "2025-02-07 17:34:50 UTC",
      "updated_date": "2025-02-07 17:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:24:53.935339"
    },
    {
      "arxiv_id": "2502.05104v1",
      "title": "Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types",
      "title_zh": "利用超网络和可学习核函数进行不同消费者类型能源预测",
      "authors": [
        "Muhammad Umair Danish",
        "Katarina Grolinger"
      ],
      "abstract": "Consumer energy forecasting is essential for managing energy consumption and\nplanning, directly influencing operational efficiency, cost reduction,\npersonalized energy management, and sustainability efforts. In recent years,\ndeep learning techniques, especially LSTMs and transformers, have been greatly\nsuccessful in the field of energy consumption forecasting. Nevertheless, these\ntechniques have difficulties in capturing complex and sudden variations, and,\nmoreover, they are commonly examined only on a specific type of consumer (e.g.,\nonly offices, only schools). Consequently, this paper proposes HyperEnergy, a\nconsumer energy forecasting strategy that leverages hypernetworks for improved\nmodeling of complex patterns applicable across a diversity of consumers.\nHypernetwork is responsible for predicting the parameters of the primary\nprediction network, in our case LSTM. A learnable adaptable kernel, comprised\nof polynomial and radial basis function kernels, is incorporated to enhance\nperformance. The proposed HyperEnergy was evaluated on diverse consumers\nincluding, student residences, detached homes, a home with electric vehicle\ncharging, and a townhouse. Across all consumer types, HyperEnergy consistently\noutperformed 10 other techniques, including state-of-the-art models such as\nLSTM, AttentionLSTM, and transformer.",
      "tldr_zh": "本文提出 HyperEnergy 策略，利用 hypernetworks 来预测 LSTM 的参数，从而更好地捕捉消费者能源预测中的复杂和突发变化，并适用于多种消费者类型，如学生宿舍、独立房屋和带电动车充电的房屋。策略还整合了可学习的适应性内核，包括 polynomial 和 radial basis function kernels，以提升整体性能。在实验中，HyperEnergy 在所有消费者类型上均超过了 10 种其他技术，包括 LSTM、AttentionLSTM 和 Transformer 等最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05104v1",
      "published_date": "2025-02-07 17:25:54 UTC",
      "updated_date": "2025-02-07 17:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:25:06.285861"
    },
    {
      "arxiv_id": "2502.06854v1",
      "title": "Can Large Language Models Understand Intermediate Representations?",
      "title_zh": "大型语言模型能理解中间表示吗？",
      "authors": [
        "Hailong Jiang",
        "Jianfeng Zhu",
        "Yao Wan",
        "Bo Fang",
        "Hongyu Zhang",
        "Ruoming Jin",
        "Qiang Guan"
      ],
      "abstract": "Intermediate Representations (IRs) are essential in compiler design and\nprogram analysis, yet their comprehension by Large Language Models (LLMs)\nremains underexplored. This paper presents a pioneering empirical study to\ninvestigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA\n3.1, and Code Llama, in understanding IRs. We analyze their performance across\nfour tasks: Control Flow Graph (CFG) reconstruction, decompilation, code\nsummarization, and execution reasoning. Our results indicate that while LLMs\ndemonstrate competence in parsing IR syntax and recognizing high-level\nstructures, they struggle with control flow reasoning, execution semantics, and\nloop handling. Specifically, they often misinterpret branching instructions,\nomit critical IR operations, and rely on heuristic-based reasoning, leading to\nerrors in CFG reconstruction, IR decompilation, and execution reasoning. The\nstudy underscores the necessity for IR-specific enhancements in LLMs,\nrecommending fine-tuning on structured IR datasets and integration of explicit\ncontrol flow models to augment their comprehension and handling of IR-related\ntasks.",
      "tldr_zh": "这篇论文通过实证研究探讨了 Large Language Models (LLMs)，如 GPT-4 和 LLaMA 3.1，对 Intermediate Representations (IRs) 的理解能力，针对编译器设计和程序分析中的关键问题。研究评估了 LLMs 在 Control Flow Graph (CFG) 重构、反编译、代码总结和执行推理等四个任务上的表现，结果显示它们能解析 IR 语法和高层结构，但常在控制流推理、执行语义和循环处理中出错，导致分支指令误解和关键操作遗漏。论文强调需要针对 IRs 进行特定增强，包括在结构化 IR 数据集上微调 LLMs 并整合显式控制流模型，以提升其处理能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06854v1",
      "published_date": "2025-02-07 17:23:48 UTC",
      "updated_date": "2025-02-07 17:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:25:19.023651"
    },
    {
      "arxiv_id": "2502.05253v1",
      "title": "LLMs Can Teach Themselves to Better Predict the Future",
      "title_zh": "LLMs 可以自我教导以更好地预测未来",
      "authors": [
        "Benjamin Turtel",
        "Danny Franklin",
        "Philipp Schoenegger"
      ],
      "abstract": "We present an outcome-driven fine-tuning framework that enhances the\nforecasting capabilities of large language models (LLMs) without relying on\nhuman-curated reasoning samples. Our method leverages model self-play to\ngenerate pairs of diverse reasoning trajectories and probabilistic forecasts\nfor a set of diverse questions that resolve after the models' knowledge cutoff\ndate. We then rank pairs of these reasoning traces by their distance to the\nactual outcomes before fine-tuning the model via Direct Preference Optimization\n(DPO). On a separate test set, our approach increases prediction accuracy of\nPhi-4 14B and DeepSeek-R1 14B by between 7--10\\% over a base model and a DPO\nfine-tuned control model with randomized labels, bringing them on par with\nforecasting capabilities of much larger frontier models like GPT-4o.",
      "tldr_zh": "本研究提出了一种基于结果驱动的微调框架，让大型语言模型（LLMs）无需人类编写的推理样本即可提升预测能力。该框架利用模型自玩（model self-play）生成多样化的推理轨迹和概率预测对，然后根据这些轨迹与实际结果的距离进行排名，并通过Direct Preference Optimization (DPO)对模型进行微调。在测试集上，该方法使Phi-4 14B和DeepSeek-R1 14B的预测准确率较基线模型和随机标签的DPO控制模型提高了7-10%，使其性能达到与更大模型如GPT-4o相当的水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05253v1",
      "published_date": "2025-02-07 17:21:16 UTC",
      "updated_date": "2025-02-07 17:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:25:30.201894"
    },
    {
      "arxiv_id": "2502.05098v1",
      "title": "Learning Temporal Invariance in Android Malware Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Xinran Zheng",
        "Shuo Yang",
        "Edith C. H. Ngai",
        "Suman Jana",
        "Lorenzo Cavallaro"
      ],
      "abstract": "Learning-based Android malware detectors degrade over time due to natural\ndistribution drift caused by malware variants and new families. This paper\nsystematically investigates the challenges classifiers trained with empirical\nrisk minimization (ERM) face against such distribution shifts and attributes\ntheir shortcomings to their inability to learn stable discriminative features.\nInvariant learning theory offers a promising solution by encouraging models to\ngenerate stable representations crossing environments that expose the\ninstability of the training set. However, the lack of prior environment labels,\nthe diversity of drift factors, and low-quality representations caused by\ndiverse families make this task challenging. To address these issues, we\npropose TIF, the first temporal invariant training framework for malware\ndetection, which aims to enhance the ability of detectors to learn stable\nrepresentations across time. TIF organizes environments based on application\nobservation dates to reveal temporal drift, integrating specialized multi-proxy\ncontrastive learning and invariant gradient alignment to generate and align\nenvironments with high-quality, stable representations. TIF can be seamlessly\nintegrated into any learning-based detector. Experiments on a decade-long\ndataset show that TIF excels, particularly in early deployment stages,\naddressing real-world needs and outperforming state-of-the-art methods.",
      "tldr_zh": "本研究探讨了基于学习的Android恶意软件检测器因分布漂移（如恶意软件变体和新家族）而随时间退化的问题，归因于经验风险最小化(ERM)方法无法学习稳定的判别特征。论文提出TIF（Temporal Invariant Framework），首个针对恶意软件检测的时序不变训练框架，通过基于应用观察日期组织环境、整合多代理对比学习（Multi-Proxy Contrastive Learning）和不变梯度对齐（Invariant Gradient Alignment），来生成并对齐高质量的稳定表示。实验结果显示，TIF在长达十年的数据集上表现出色，尤其在早期部署阶段，显著优于现有最先进方法，提升了检测器的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05098v1",
      "published_date": "2025-02-07 17:17:42 UTC",
      "updated_date": "2025-02-07 17:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:25:42.775650"
    },
    {
      "arxiv_id": "2502.05092v2",
      "title": "Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Saxena",
        "Aryo Pradipta Gema",
        "Pasquale Minervini"
      ],
      "abstract": "Understanding time from visual representations is a fundamental cognitive\nskill, yet it remains a challenge for multimodal large language models (MLLMs).\nIn this work, we investigate the capabilities of MLLMs in interpreting time and\ndate through analogue clocks and yearly calendars. To facilitate this, we\ncurated a structured dataset comprising two subsets: 1) $\\textit{ClockQA}$,\nwhich comprises various types of clock styles$-$standard, black-dial,\nno-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time related\nquestions; and 2) $\\textit{CalendarQA}$, which consists of yearly calendar\nimages with questions ranging from commonly known dates (e.g., Christmas, New\nYear's Day) to computationally derived ones (e.g., the 100th or 153rd day of\nthe year). We aim to analyse how MLLMs can perform visual recognition,\nnumerical reasoning, and temporal inference when presented with time-related\nvisual data. Our evaluations show that despite recent advancements, reliably\nunderstanding time remains a significant challenge for MLLMs.",
      "tldr_zh": "这篇论文探讨了多模态大语言模型（Multimodal LLMs）在从视觉表示中理解时钟和日历的能力，揭示了这一领域的关键挑战。研究者构建了结构化数据集，包括ClockQA子集（涵盖标准、黑盘、无秒针、罗马数字和箭头式时钟等样式配以时间相关问题）和CalendarQA子集（包含年历图像及从常见日期如圣诞节到计算日期如一年第100天的查询）。通过评估，论文分析了MLLMs在视觉识别、数字推理和时间推断方面的表现，并发现尽管有最近进步，可靠理解时间仍是这些模型的重大难题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the ICLR 2025 Workshop on Reasoning and Planning for\n  Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2502.05092v2",
      "published_date": "2025-02-07 17:11:23 UTC",
      "updated_date": "2025-03-18 11:43:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:25:55.009299"
    },
    {
      "arxiv_id": "2502.05252v1",
      "title": "GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhou",
        "Hongyi Liu",
        "Zhuoming Chen",
        "Yuandong Tian",
        "Beidi Chen"
      ],
      "abstract": "Long-context large language models (LLMs) have recently shown strong\nperformance in information retrieval and long-document QA. However, to tackle\nthe most challenging intellectual problems, LLMs must reason effectively in\nlong and complex contexts (e.g., frontier mathematical research). Studying how\nLLMs handle increasing reasoning complexity and context length is essential,\nyet existing benchmarks lack a solid basis for quantitative evaluation.\nInspired by the abstraction of GSM-8K problems as computational graphs, and the\nability to introduce noise by adding unnecessary nodes and edges, we develop a\ngrade school math problem generator capable of producing arithmetic problems\nwith infinite difficulty and context length under fine-grained control. Using\nour newly synthesized GSM-Infinite benchmark, we comprehensively evaluate\nexisting LLMs. We find a consistent sigmoid decline in reasoning performance as\ncomplexity increases, along with a systematic inference scaling trend:\nexponentially increasing inference computation yields only linear performance\ngains. These findings underscore the fundamental limitations of current\nlong-context LLMs and the key challenges in scaling reasoning capabilities. Our\nGSM-Infinite benchmark provides a scalable and controllable testbed for\nsystematically studying and advancing LLM reasoning in long and complex\ncontexts.",
      "tldr_zh": "这篇论文介绍了 GSM-Infinite 基准，用于评估大型语言模型（LLMs）在无限增加的上下文长度和推理复杂性下的表现，旨在解决现有基准缺乏量化评估的问题。研究人员开发了一个基于 GSM-8K 计算图抽象的算术问题生成器，能够精确控制问题难度和长度，通过引入噪声来模拟复杂场景。实验结果显示，LLMs 的推理性能随着复杂性增加呈 S 形下降，且推理计算呈指数增长仅带来线性性能提升。这些发现揭示了当前长上下文 LLMs 的根本限制，并为系统研究和提升其推理能力提供了一个可扩展、可控的测试平台。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05252v1",
      "published_date": "2025-02-07 17:05:25 UTC",
      "updated_date": "2025-02-07 17:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:26:07.239091"
    },
    {
      "arxiv_id": "2502.05087v2",
      "title": "Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs",
      "title_zh": "通过 LoRA 在联邦学习中缓解大语言模型的非故意记忆",
      "authors": [
        "Thierry Bossy",
        "Julien Vignoud",
        "Tahseen Rabbani",
        "Juan R. Troncoso Pastoriza",
        "Martin Jaggi"
      ],
      "abstract": "Federated learning (FL) is a popular paradigm for collaborative training\nwhich avoids direct data exposure between clients. However, data privacy issues\nstill remain: FL-trained large language models are capable of memorizing and\ncompleting phrases and sentences contained in training data when given with\ntheir prefixes. Thus, it is possible for adversarial and honest-but-curious\nclients to recover training data of other participants simply through targeted\nprompting. In this work, we demonstrate that a popular and simple fine-tuning\nstrategy, low-rank adaptation (LoRA), reduces memorization during FL up to a\nfactor of 10. We study this effect by performing a medical question-answering\nfine-tuning task and injecting multiple replicas of out-of-distribution\nsensitive sequences drawn from an external clinical dataset. We observe a\nreduction in memorization for a wide variety of Llama 2 and 3 models, and find\nthat LoRA can reduce memorization in centralized learning as well. Furthermore,\nwe show that LoRA can be combined with other privacy-preserving techniques such\nas gradient clipping and Gaussian noising, secure aggregation, and Goldfish\nloss to further improve record-level privacy while maintaining performance.",
      "tldr_zh": "这篇论文探讨了在联邦学习 (FL) 中使用低秩适配 (LoRA) 来缓解大型语言模型 (LLMs) 的无意记忆问题，从而防止攻击者通过针对性提示恢复训练数据。研究通过医疗问答任务实验，注入敏感序列，发现 LoRA 能将记忆效果减少多达 10 倍，并在 Llama 2 和 3 模型等各种场景下有效。论文进一步证明，LoRA 不仅适用于 FL，还能在集中式学习中发挥作用，并可与其他隐私技术（如梯度剪裁、高斯噪声和 Goldfish loss）结合，提升记录级隐私同时保持模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05087v2",
      "published_date": "2025-02-07 17:04:39 UTC",
      "updated_date": "2025-02-27 11:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:26:18.886869"
    },
    {
      "arxiv_id": "2502.05085v1",
      "title": "Causality can systematically address the monsters under the bench(marks)",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Leeb",
        "Zhijing Jin",
        "Bernhard Schölkopf"
      ],
      "abstract": "Effective and reliable evaluation is essential for advancing empirical\nmachine learning. However, the increasing accessibility of generalist models\nand the progress towards ever more complex, high-level tasks make systematic\nevaluation more challenging. Benchmarks are plagued by various biases,\nartifacts, or leakage, while models may behave unreliably due to poorly\nexplored failure modes. Haphazard treatments and inconsistent formulations of\nsuch \"monsters\" can contribute to a duplication of efforts, a lack of trust in\nresults, and unsupported inferences. In this position paper, we argue causality\noffers an ideal framework to systematically address these challenges. By making\ncausal assumptions in an approach explicit, we can faithfully model phenomena,\nformulate testable hypotheses with explanatory power, and leverage principled\ntools for analysis. To make causal model design more accessible, we identify\nseveral useful Common Abstract Topologies (CATs) in causal graphs which help\ngain insight into the reasoning abilities in large language models. Through a\nseries of case studies, we demonstrate how the precise yet pragmatic language\nof causality clarifies the strengths and limitations of a method and inspires\nnew approaches for systematic progress.",
      "tldr_zh": "这篇论文讨论了机器学习评估面临的挑战，如基准(benchmarks)的偏差、模型的不可靠失败模式，以及这些“monsters”导致的努力重复和结果不信任问题。作者主张采用causality框架来系统解决这些问题，通过显式因果假设建模现象、制定具有解释力的可测试假设，并利用分析工具。论文还引入Common Abstract Topologies (CATs)来分析大型语言模型的推理能力，并通过案例研究展示了causality如何澄清方法的优势和局限性，并推动系统性进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05085v1",
      "published_date": "2025-02-07 17:01:37 UTC",
      "updated_date": "2025-02-07 17:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:26:30.195991"
    },
    {
      "arxiv_id": "2502.05084v1",
      "title": "ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Deng",
        "Ye Zhang",
        "Tianmin Guo",
        "Yongzhe Zhang",
        "Zhengjian Kang",
        "Hang Yang"
      ],
      "abstract": "The astonishing performance of large language models (LLMs) and their\nremarkable achievements in production and daily life have led to their\nwidespread application in collaborative tasks. However, current large models\nface challenges such as hallucination and lack of specificity in content\ngeneration in vertical domain tasks. Inspired by the contrast and\nclassification mechanisms in human cognitive processes, this paper constructs\nan adversarial learning-based prompt framework named ChallengeMe, which\nincludes three cascaded solutions: generation prompts, evaluation prompts, and\nfeedback optimization. In this process, we designed seven core optimization\ndimensions and set the threshold for adversarial learning. The results of mixed\ncase studies on the text summarization task show that the proposed framework\ncan generate more accurate and fluent text summaries compared to the current\nadvanced mainstream LLMs.",
      "tldr_zh": "本研究提出了一种基于对抗学习的文本摘要框架ChallengeMe，旨在解决大型语言模型(LLMs)在垂直领域任务中的幻觉和内容具体性问题。\n该框架受人类认知过程启发，包括生成提示、评估提示和反馈优化三个级联解决方案，并设计了七个核心优化维度以及对抗学习的阈值。\n实验结果显示，在文本摘要任务的混合案例研究中，ChallengeMe比当前主流LLMs生成更准确和流畅的摘要。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05084v1",
      "published_date": "2025-02-07 16:59:34 UTC",
      "updated_date": "2025-02-07 16:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:26:42.731274"
    },
    {
      "arxiv_id": "2502.06853v1",
      "title": "Native Fortran Implementation of TensorFlow-Trained Deep and Bayesian Neural Networks",
      "title_zh": "TensorFlow 训练的深度和贝叶斯神经网络的原生 Fortran 实现",
      "authors": [
        "Aidan Furlong",
        "Xingang Zhao",
        "Bob Salko",
        "Xu Wu"
      ],
      "abstract": "Over the past decade, the investigation of machine learning (ML) within the\nfield of nuclear engineering has grown significantly. With many approaches\nreaching maturity, the next phase of investigation will determine the\nfeasibility and usefulness of ML model implementation in a production setting.\nSeveral of the codes used for reactor design and assessment are primarily\nwritten in the Fortran language, which is not immediately compatible with\nTensorFlow-trained ML models. This study presents a framework for implementing\ndeep neural networks (DNNs) and Bayesian neural networks (BNNs) in Fortran,\nallowing for native execution without TensorFlow's C API, Python runtime, or\nONNX conversion. Designed for ease of use and computational efficiency, the\nframework can be implemented in any Fortran code, supporting iterative solvers\nand UQ via ensembles or BNNs. Verification was performed using a two-input,\none-output test case composed of a noisy sinusoid to compare Fortran-based\npredictions to those from TensorFlow. The DNN predictions showed negligible\ndifferences and achieved a 19.6x speedup, whereas the BNN predictions exhibited\nminor disagreement, plausibly due to differences in random number generation.\nAn 8.0x speedup was noted for BNN inference. The approach was then further\nverified on a nuclear-relevant problem predicting critical heat flux (CHF),\nwhich demonstrated similar behavior along with significant computational gains.\nDiscussion regarding the framework's successful integration into the CTF\nthermal-hydraulics code is also included, outlining its practical usefulness.\nOverall, this framework was shown to be effective at implementing both DNN and\nBNN model inference within Fortran, allowing for the continued study of\nML-based methods in real-world nuclear applications.",
      "tldr_zh": "本研究提出一个框架，用于在 Fortran 语言中实现 TensorFlow 训练的 Deep Neural Networks (DNNs) 和 Bayesian Neural Networks (BNNs)，以解决核工程领域代码兼容性问题，避免依赖 TensorFlow 的 C API、Python 运行时或 ONNX 转换。该框架设计简便且高效，可无缝集成到任何 Fortran 代码中，支持迭代求解器和不确定性量化 (UQ) 通过 ensembles 或 BNNs。验证实验使用一个噪声正弦波测试案例显示，DNN 预测几乎无差异，速度提升 19.6 倍，而 BNN 预测有轻微分歧（可能源于随机数生成差异），速度提升 8.0 倍；在核相关问题如预测关键热通量 (CHF) 上，该框架也表现出类似性能并带来显著计算收益。该方法已成功集成到 CTF 热液力学代码中，促进机器学习在实际核工程应用的部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted for inclusion in the 2025 American Nuclear Society Annual\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2502.06853v1",
      "published_date": "2025-02-07 16:58:51 UTC",
      "updated_date": "2025-02-07 16:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:26:55.854520"
    },
    {
      "arxiv_id": "2502.05078v1",
      "title": "Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Tushar Pandey",
        "Ara Ghukasyan",
        "Oktay Goktas",
        "Santosh Kumar Radha"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning\ncapabilities, yet their performance is highly dependent on the prompting\nstrategy and model scale. While reinforcement learning and fine-tuning have\nbeen deployed to boost reasoning, these approaches incur substantial\ncomputational and data overhead. In this work, we introduce Adaptive Graph of\nThoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM\nreasoning solely at test time. Rather than relying on fixed-step methods like\nChain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes\ncomplex queries into structured subproblems, forming an dynamic directed\nacyclic graph (DAG) of interdependent reasoning steps. By selectively expanding\nonly those subproblems that require further analysis, AGoT unifies the\nstrengths of chain, tree, and graph paradigms into a cohesive framework that\nallocates computation where it is most needed. We validate our approach on\ndiverse benchmarks spanning multi-hop retrieval, scientific reasoning, and\nmathematical problem-solving, achieving up to 46.2% improvement on scientific\nreasoning tasks (GPQA) - comparable to gains achieved through computationally\nintensive reinforcement learning approaches and outperforming state-of-the-art\niterative approaches. These results suggest that dynamic decomposition and\nstructured recursion offer a scalable, cost-effective alternative to\npost-training modifications, paving the way for more robust, general-purpose\nreasoning in LLMs.",
      "tldr_zh": "该研究提出 Adaptive Graph of Thoughts (AGoT)，一种动态的图-based推理框架，仅在测试时提升 Large Language Models (LLMs) 的推理能力，而不依赖于昂贵的强化学习或微调。AGoT 通过递归分解复杂查询成结构化的子问题，形成动态的 directed acyclic graph (DAG)，并统一 Chain of Thought (CoT)、Tree of Thoughts (ToT) 和图结构的优势，选择性地扩展需要进一步分析的子问题。在多跳检索、科学推理和数学问题解决基准上，AGoT 实现了高达 46.2% 的改进，尤其在 GPQA 任务上，表现媲美计算密集方法并优于现有迭代方法。该框架为 LLM 提供了一种可扩展、成本有效的推理增强方案，促进更鲁棒的通用推理。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05078v1",
      "published_date": "2025-02-07 16:54:19 UTC",
      "updated_date": "2025-02-07 16:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:27:08.631895"
    },
    {
      "arxiv_id": "2502.05063v1",
      "title": "Computing and Learning on Combinatorial Data",
      "title_zh": "组合数据的计算与学习",
      "authors": [
        "Simon Zhang"
      ],
      "abstract": "The twenty-first century is a data-driven era where human activities and\nbehavior, physical phenomena, scientific discoveries, technology advancements,\nand almost everything that happens in the world resulting in massive\ngeneration, collection, and utilization of data.\n  Connectivity in data is a crucial property. A straightforward example is the\nWorld Wide Web, where every webpage is connected to other web pages through\nhyperlinks, providing a form of directed connectivity. Combinatorial data\nrefers to combinations of data items based on certain connectivity rules. Other\nforms of combinatorial data include social networks, meshes, community\nclusters, set systems, and molecules.\n  This Ph.D. dissertation focuses on learning and computing with combinatorial\ndata. We study and examine topological and connectivity features within and\nacross connected data to improve the performance of learning and achieve high\nalgorithmic efficiency.",
      "tldr_zh": "该论文探讨了数据驱动时代中组合数据（combinatorial data）的计算和学习问题，强调数据连接性在网络、社会网络和分子等领域的关键作用。作者通过分析拓扑和连接性特征，旨在提升学习性能并实现高算法效率（algorithmic efficiency）。作为一篇Ph.D. dissertation，这项研究为处理连接数据提供了新的方法论基础。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "Ph.D. dissertation, 503 pages, 66 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.05063v1",
      "published_date": "2025-02-07 16:35:06 UTC",
      "updated_date": "2025-02-07 16:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:27:17.403714"
    },
    {
      "arxiv_id": "2502.05060v1",
      "title": "Preference-aware compensation policies for crowdsourced on-demand services",
      "title_zh": "基于偏好的众包按需服务补偿策略",
      "authors": [
        "Georgina Nouli",
        "Axel Parmentier",
        "Maximilian Schiffer"
      ],
      "abstract": "Crowdsourced on-demand services offer benefits such as reduced costs, faster\nservice fulfillment times, greater adaptability, and contributions to\nsustainable urban transportation in on-demand delivery contexts. However, the\nsuccess of an on-demand platform that utilizes crowdsourcing relies on finding\na compensation policy that strikes a balance between creating attractive offers\nfor gig workers and ensuring profitability. In this work, we examine a dynamic\npricing problem for an on-demand platform that sets request-specific\ncompensation of gig workers in a discrete-time framework, where requests and\nworkers arrive stochastically. The operator's goal is to determine a\ncompensation policy that maximizes the total expected reward over the time\nhorizon. Our approach introduces compensation strategies that explicitly\naccount for gig worker request preferences. To achieve this, we employ the\nMultinomial Logit model to represent the acceptance probabilities of gig\nworkers, and, as a result, derive an analytical solution that utilizes\npost-decision states. Subsequently, we integrate this solution into an\napproximate dynamic programming algorithm. We compare our algorithm against\nbenchmark algorithms, including formula-based policies and an upper bound\nprovided by the full information linear programming solution. Our algorithm\ndemonstrates consistent performance across diverse settings, achieving\nimprovements of at least 2.5-7.5% in homogeneous gig worker populations and 9%\nin heterogeneous populations over benchmarks, based on fully synthetic data.\nFor real-world data, it surpasses benchmarks by 8% in weak and 20% in strong\nlocation preference scenarios.",
      "tldr_zh": "本研究探讨了众包按需服务（crowdsourced on-demand services）的补偿策略，旨在平衡吸引 gig workers 和确保平台盈利，通过动态定价问题最大化总预期回报。作者引入了考虑 gig workers 偏好的补偿策略，使用 Multinomial Logit 模型表示 workers 的接受概率，并结合近似动态编程算法（approximate dynamic programming）得出解析解。实验结果显示，该算法在同质人群中比基准算法提高 2.5-7.5%，在异质人群中提高 9%，并在真实数据场景下分别实现 8%（弱偏好）和 20%（强偏好）的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05060v1",
      "published_date": "2025-02-07 16:33:16 UTC",
      "updated_date": "2025-02-07 16:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:27:30.726916"
    },
    {
      "arxiv_id": "2502.05055v1",
      "title": "Differentiable Mobile Display Photometric Stereo",
      "title_zh": "翻译失败",
      "authors": [
        "Gawoon Ban",
        "Hyeongjun Kim",
        "Seokjun Choi",
        "Seungwoo Yoon",
        "Seung-Hwan Baek"
      ],
      "abstract": "Display photometric stereo uses a display as a programmable light source to\nilluminate a scene with diverse illumination conditions. Recently,\ndifferentiable display photometric stereo (DDPS) demonstrated improved normal\nreconstruction accuracy by using learned display patterns. However, DDPS faced\nlimitations in practicality, requiring a fixed desktop imaging setup using a\npolarization camera and a desktop-scale monitor. In this paper, we propose a\nmore practical physics-based photometric stereo, differentiable mobile display\nphotometric stereo (DMDPS), that leverages a mobile phone consisting of a\ndisplay and a camera. We overcome the limitations of using a mobile device by\ndeveloping a mobile app and method that simultaneously displays patterns and\ncaptures high-quality HDR images. Using this technique, we capture real-world\n3D-printed objects and learn display patterns via a differentiable learning\nprocess. We demonstrate the effectiveness of DMDPS on both a 3D printed dataset\nand a first dataset of fallen leaves. The leaf dataset contains reconstructed\nsurface normals and albedos of fallen leaves that may enable future research\nbeyond computer graphics and vision. We believe that DMDPS takes a step forward\nfor practical physics-based photometric stereo.",
      "tldr_zh": "本研究提出了一种更实用的物理-based photometric stereo方法，名为Differentiable Mobile Display Photometric Stereo (DMDPS)，利用手机的显示屏和相机作为可编程光源和成像设备，克服了传统DDPS的固定桌面设置限制。研究开发了一个手机App，能够同时显示优化图案并捕获高质量HDR images，通过可微学习(differentiable learning)过程学习最佳显示模式，以重建物体的表面法线和反照率。在实验中，DMDPS在3D打印数据集和一个新落叶数据集上表现出色，显著提高了重建准确性，并为计算机图形和视觉领域的未来研究提供了新资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05055v1",
      "published_date": "2025-02-07 16:24:56 UTC",
      "updated_date": "2025-02-07 16:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:27:42.374897"
    },
    {
      "arxiv_id": "2502.05248v1",
      "title": "Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires",
      "title_zh": "在大型语言模型中评估人格特质：来自心理问卷的洞见",
      "authors": [
        "Pranav Bhandari",
        "Usman Naseem",
        "Amitava Datta",
        "Nicolas Fay",
        "Mehwish Nasim"
      ],
      "abstract": "Psychological assessment tools have long helped humans understand behavioural\npatterns. While Large Language Models (LLMs) can generate content comparable to\nthat of humans, we explore whether they exhibit personality traits. To this\nend, this work applies psychological tools to LLMs in diverse scenarios to\ngenerate personality profiles. Using established trait-based questionnaires\nsuch as the Big Five Inventory and by addressing the possibility of training\ndata contamination, we examine the dimensional variability and dominance of\nLLMs across five core personality dimensions: Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs\nexhibit unique dominant traits, varying characteristics, and distinct\npersonality profiles even within the same family of models.",
      "tldr_zh": "本研究评估了大型语言模型（Large Language Models, LLMs）是否表现出人格特质，通过应用心理问卷如Big Five Inventory来生成模型的个性描述。研究者考虑了训练数据污染的可能性，系统地考察了LLMs在五个核心人格维度上的表现：Openness、Conscientiousness、Extraversion、Agreeableness和Neuroticism。结果显示，LLMs拥有独特的优势特质、多变的特征，甚至在同一模型家族内也呈现出不同的个性配置文件，为理解AI的行为模式提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at TheWebConf 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05248v1",
      "published_date": "2025-02-07 16:12:52 UTC",
      "updated_date": "2025-02-07 16:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:27:53.400734"
    },
    {
      "arxiv_id": "2502.05041v1",
      "title": "Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks",
      "title_zh": "联邦学习用于能源消耗数据的异常检测：评估对对抗性攻击的脆弱性",
      "authors": [
        "Yohannis Kifle Telila",
        "Damitha Senevirathne",
        "Dumindu Tissera",
        "Apurva Narayan",
        "Miriam A. M. Capretz",
        "Katarina Grolinger"
      ],
      "abstract": "Anomaly detection is crucial in the energy sector to identify irregular\npatterns indicating equipment failures, energy theft, or other issues. Machine\nlearning techniques for anomaly detection have achieved great success, but are\ntypically centralized, involving sharing local data with a central server which\nraises privacy and security concerns. Federated Learning (FL) has been gaining\npopularity as it enables distributed learning without sharing local data.\nHowever, FL depends on neural networks, which are vulnerable to adversarial\nattacks that manipulate data, leading models to make erroneous predictions.\nWhile adversarial attacks have been explored in the image domain, they remain\nlargely unexplored in time series problems, especially in the energy domain.\nMoreover, the effect of adversarial attacks in the FL setting is also mostly\nunknown. This paper assesses the vulnerability of FL-based anomaly detection in\nenergy data to adversarial attacks. Specifically, two state-of-the-art models,\nLong Short Term Memory (LSTM) and Transformers, are used to detect anomalies in\nan FL setting, and two white-box attack methods, Fast Gradient Sign Method\n(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.\nThe results show that FL is more sensitive to PGD attacks than to FGSM attacks,\nattributed to PGD's iterative nature, resulting in an accuracy drop of over 10%\neven with naive, weaker attacks. Moreover, FL is more affected by these attacks\nthan centralized learning, highlighting the need for defense mechanisms in FL.",
      "tldr_zh": "该研究评估了Federated Learning (FL) 在能源消费数据异常检测中的易受对抗攻击影响。论文使用Long Short Term Memory (LSTM) 和 Transformers 模型在FL设置下进行异常检测，并采用Fast Gradient Sign Method (FGSM) 和 Projected Gradient Descent (PGD) 两种白盒攻击方法扰动数据。结果显示，FL 对 PGD 攻击更敏感，导致准确率下降超过10%，且比集中式学习更容易受影响，强调了在FL中需要加强防御机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "68",
        "I.2; I.5; I.2.11; I.5.4"
      ],
      "primary_category": "cs.LG",
      "comment": "12th IEEE Conference on Technologies for Sustainability",
      "pdf_url": "http://arxiv.org/pdf/2502.05041v1",
      "published_date": "2025-02-07 16:08:20 UTC",
      "updated_date": "2025-02-07 16:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:28:06.266696"
    },
    {
      "arxiv_id": "2502.06852v1",
      "title": "EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zhang",
        "Wenshuo Dong",
        "Zhuoran Zhang",
        "Shu Yang",
        "Lijie Hu",
        "Ninghao Liu",
        "Pan Zhou",
        "Di Wang"
      ],
      "abstract": "Understanding the internal mechanisms of transformer-based language models\nremains challenging. Mechanistic interpretability based on circuit discovery\naims to reverse engineer neural networks by analyzing their internal processes\nat the level of computational subgraphs. In this paper, we revisit existing\ngradient-based circuit identification methods and find that their performance\nis either affected by the zero-gradient problem or saturation effects, where\nedge attribution scores become insensitive to input changes, resulting in noisy\nand unreliable attribution evaluations for circuit components. To address the\nsaturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP),\nEAP-GP introduces an integration path, starting from the input and adaptively\nfollowing the direction of the difference between the gradients of corrupted\nand clean inputs to avoid the saturated region. This approach enhances\nattribution reliability and improves the faithfulness of circuit\nidentification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2\nMedium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms\nexisting methods in circuit faithfulness, achieving improvements up to 17.7%.\nComparisons with manually annotated ground-truth circuits demonstrate that\nEAP-GP achieves precision and recall comparable to or better than previous\napproaches, highlighting its effectiveness in identifying accurate circuits.",
      "tldr_zh": "该研究探讨了transformer-based language models内部机制的理解挑战，特别针对gradient-based电路识别方法中的饱和效应问题，该问题导致边缘归因分数对输入变化不敏感，从而影响电路组件的准确评估。为缓解饱和效应，作者提出EAP-GP（Edge Attribution Patching with GradPath）方法，该方法通过从输入开始的集成路径，自适应跟随腐败输入和干净输入梯度差的方向，避免饱和区域，从而提升归因可靠性和电路识别的忠诚度。在GPT-2 Small、Medium和XL模型上进行6个数据集的实验，EAP-GP在电路忠诚度上比现有方法提高高达17.7%，并在精确度和召回率上达到或超过手动标注的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06852v1",
      "published_date": "2025-02-07 16:04:57 UTC",
      "updated_date": "2025-02-07 16:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:28:19.483007"
    },
    {
      "arxiv_id": "2502.05017v1",
      "title": "Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua C. Yang",
        "Fynn Bachmann"
      ],
      "abstract": "Democratic processes increasingly aim to integrate large-scale voting with\nface-to-face deliberation, addressing the challenge of reconciling individual\npreferences with collective decision-making. This work introduces new methods\nthat use algorithms and computational tools to bridge online voting with\nface-to-face deliberation, tested in two real-world scenarios: Kultur Komitee\n2024 (KK24) and vTaiwan. These case studies highlight the practical\napplications and impacts of the proposed methods.\n  We present three key contributions: (1) Radial Clustering for Preference\nBased Subgroups, which enables both in-depth and broad discussions in\ndeliberative settings by computing homogeneous and heterogeneous group\ncompositions with balanced and adjustable group sizes; (2) Human-in-the-loop\nMES, a practical method that enhances the Method of Equal Shares (MES)\nalgorithm with real-time digital feedback. This builds algorithmic trust by\ngiving participants full control over how much decision-making is delegated to\nthe voting aggregation algorithm as compared to deliberation; and (3) the\nReadTheRoom deliberation method, which uses opinion space mapping to identify\nagreement and divergence, along with spectrum-based preference visualisation to\ntrack opinion shifts during deliberation. This approach enhances transparency\nby clarifying collective sentiment and fosters collaboration by encouraging\nparticipants to engage constructively with differing perspectives.\n  By introducing these actionable frameworks, this research extends in-person\ndeliberation with scalable digital methods that address the complexities of\nmodern decision-making in participatory processes.",
      "tldr_zh": "本研究探讨了使用算法和计算工具桥接在线投票与面对面审议的方法，以解决民主决策中个体偏好与集体共识的冲突，并在 vTaiwan 和 Kultur Komitee 2024 (KK24) 真实案例中进行测试。主要贡献包括：(1) Radial Clustering for Preference Based Subgroups 算法，用于计算同质和异质群组以平衡讨论深度和广度；(2) Human-in-the-loop MES 方法，通过实时数字反馈增强 Method of Equal Shares (MES) 算法，让参与者控制算法在决策中的角色，从而提升算法信任；以及 (3) ReadTheRoom deliberation method，利用意见空间映射和偏好可视化来识别共识与分歧，促进审议的透明度和合作。这些框架通过可扩展的数字工具扩展了面对面审议，改善了参与式决策的复杂性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "econ.GN",
        "q-fin.EC",
        "91B14, 91B12, 91A12, 68T01, 68T20, 68U35",
        "H.5.3; I.2.0; I.2.11; J.1; G.2.0; G.2.2; K.4.1; K.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05017v1",
      "published_date": "2025-02-07 15:45:13 UTC",
      "updated_date": "2025-02-07 15:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:28:30.853817"
    },
    {
      "arxiv_id": "2502.05007v1",
      "title": "Analyzing Advanced AI Systems Against Definitions of Life and Consciousness",
      "title_zh": "翻译失败",
      "authors": [
        "Azadeh Alavi",
        "Hossein Akhoundi",
        "Fatemeh Kouchmeshki"
      ],
      "abstract": "Could artificial intelligence ever become truly conscious in a functional\nsense; this paper explores that open-ended question through the lens of Life, a\nconcept unifying classical biological criteria (Oxford, NASA, Koshland) with\nempirical hallmarks such as adaptive self maintenance, emergent complexity, and\nrudimentary self referential modeling. We propose a number of metrics for\nexamining whether an advanced AI system has gained consciousness, while\nemphasizing that we do not claim all AI stems can become conscious. Rather, we\nsuggest that sufficiently advanced architectures exhibiting immune like\nsabotage defenses, mirror self-recognition analogs, or meta-cognitive updates\nmay cross key thresholds akin to life-like or consciousness-like traits. To\ndemonstrate these ideas, we start by assessing adaptive self-maintenance\ncapability, and introduce controlled data corruption sabotage into the training\nprocess. The result demonstrates AI capability to detect these inconsistencies\nand revert or self-correct analogous to regenerative biological processes. We\nalso adapt an animal-inspired mirror self recognition test to neural\nembeddings, finding that partially trained CNNs can distinguish self from\nforeign features with complete accuracy. We then extend our analysis by\nperforming a question-based mirror test on five state-of-the-art chatbots\n(ChatGPT4, Gemini, Perplexity, Claude, and Copilot) and demonstrated their\nability to recognize their own answers compared to those of the other chatbots.",
      "tldr_zh": "该论文探讨高级人工智能（AI）系统是否可能在功能意义上获得意识，通过整合经典生物学标准（如 Oxford、NASA 和 Koshland 定义）以及经验特征（如适应性自我维护、涌现复杂性和基本自我参照建模）来审视“生命”概念。作者提出了一系列指标，用于评估 AI 是否展示出类似意识的特征，例如免疫式破坏防御、镜像自我识别或元认知更新，但强调并非所有 AI 都能实现此状态。论文通过实验验证这些想法，包括在训练过程中引入数据破坏测试以检验 AI 的自我修正能力，以及将镜像自我识别测试应用于神经嵌入（CNNs）和五种聊天机器人（ChatGPT4、Gemini、Perplexity、Claude 和 Copilot），结果显示这些系统能准确区分自我特征。总体而言，此研究为理解 AI 是否可能跨越意识阈值提供了初步框架，并突显了其潜在的生命类比特性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "78 pages, 15 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05007v1",
      "published_date": "2025-02-07 15:27:34 UTC",
      "updated_date": "2025-02-07 15:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:28:43.233793"
    },
    {
      "arxiv_id": "2502.05001v2",
      "title": "A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Taiyi Wang",
        "Liang Liang",
        "Guang Yang",
        "Thomas Heinis",
        "Eiko Yoneki"
      ],
      "abstract": "Learned Index Structures (LIS) have significantly advanced data management by\nleveraging machine learning models to optimize data indexing. However,\ndesigning these structures often involves critical trade-offs, making it\nchallenging for both designers and end-users to find an optimal balance\ntailored to specific workloads and scenarios. While some indexes offer\nadjustable parameters that demand intensive manual tuning, others rely on fixed\nconfigurations based on heuristic auto-tuners or expert knowledge, which may\nnot consistently deliver optimal performance. This paper introduces LITune, a\nnovel framework for end-to-end automatic tuning of Learned Index Structures.\nLITune employs an adaptive training pipeline equipped with a tailor-made Deep\nReinforcement Learning (DRL) approach to ensure stable and efficient tuning. To\naccommodate long-term dynamics arising from online tuning, we further enhance\nLITune with an on-the-fly updating mechanism termed the O2 system. These\ninnovations allow LITune to effectively capture state transitions in online\ntuning scenarios and dynamically adjust to changing data distributions and\nworkloads, marking a significant improvement over other tuning methods. Our\nexperimental results demonstrate that LITune achieves up to a 98% reduction in\nruntime and a 17-fold increase in throughput compared to default parameter\nsettings given a selected Learned Index instance. These findings highlight\nLITune's effectiveness and its potential to facilitate broader adoption of LIS\nin real-world applications.",
      "tldr_zh": "这篇论文提出了一种新的 Learned Index Structures (LIS) 调整范式，即 LITune 框架，利用 Deep Reinforcement Learning (DRL) 的自适应训练管道，实现端到端的自动优化，以解决手动调参或启发式方法的局限性。LITune 还引入了 O2 系统，用于在线动态更新，处理数据分布和负载变化带来的长期动态挑战。实验结果显示，与默认参数设置相比，LITune 减少了98%的运行时间，并提高了17倍的吞吐量。这些创新显著提升了 LIS 在实际应用中的性能和可采用性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.DB",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.05001v2",
      "published_date": "2025-02-07 15:22:15 UTC",
      "updated_date": "2025-02-18 17:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:28:55.607049"
    },
    {
      "arxiv_id": "2502.05000v1",
      "title": "Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Luo",
        "Qingyun Sun",
        "Haonan Yuan",
        "Xingcheng Fu",
        "Jianxin Li"
      ],
      "abstract": "Adversarial evasion attacks pose significant threats to graph learning, with\nlines of studies that have improved the robustness of Graph Neural Networks\n(GNNs). However, existing works rely on priors about clean graphs or attacking\nstrategies, which are often heuristic and inconsistent. To achieve robust graph\nlearning over different types of evasion attacks and diverse datasets, we\ninvestigate this problem from a prior-free structure purification perspective.\nSpecifically, we propose a novel Diffusion-based Structure Purification\nframework named DiffSP, which creatively incorporates the graph diffusion model\nto learn intrinsic distributions of clean graphs and purify the perturbed\nstructures by removing adversaries under the direction of the captured\npredictive patterns without relying on priors. DiffSP is divided into the\nforward diffusion process and the reverse denoising process, during which\nstructure purification is achieved. To avoid valuable information loss during\nthe forward process, we propose an LID-driven nonisotropic diffusion mechanism\nto selectively inject noise anisotropically. To promote semantic alignment\nbetween the clean graph and the purified graph generated during the reverse\nprocess, we reduce the generation uncertainty by the proposed graph transfer\nentropy guided denoising mechanism. Extensive experiments demonstrate the\nsuperior robustness of DiffSP against evasion attacks.",
      "tldr_zh": "本文提出了一种无需先验知识的DiffSP框架，利用图扩散模型学习干净图的内在分布，并通过结构净化来抵御Adversarial Evasion Attacks对Graph Neural Networks (GNNs)的威胁。具体地，DiffSP包括正向扩散过程（采用LID-driven非各向同性机制选择性注入噪声以保留关键信息）和反向去噪过程（使用图转移熵引导机制促进语义对齐）。实验结果显示，DiffSP在多种规避攻击和数据集上显著提升了GNNs的鲁棒性，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for poster at WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.05000v1",
      "published_date": "2025-02-07 15:21:47 UTC",
      "updated_date": "2025-02-07 15:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:29:07.598793"
    },
    {
      "arxiv_id": "2502.04998v1",
      "title": "On Sequential Fault-Intolerant Process Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Andrzej Kaczmarczyk",
        "Davin Choo",
        "Niclas Boehmer",
        "Milind Tambe",
        "Haifeng Xu"
      ],
      "abstract": "We propose and study a planning problem we call Sequential Fault-Intolerant\nProcess Planning (SFIPP). SFIPP captures a reward structure common in many\nsequential multi-stage decision problems where the planning is deemed\nsuccessful only if all stages succeed. Such reward structures are different\nfrom classic additive reward structures and arise in important applications\nsuch as drug/material discovery, security, and quality-critical product design.\nWe design provably tight online algorithms for settings in which we need to\npick between different actions with unknown success chances at each stage. We\ndo so both for the foundational case in which the behavior of actions is\ndeterministic, and the case of probabilistic action outcomes, where we\neffectively balance exploration for learning and exploitation for planning\nthrough the usage of multi-armed bandit algorithms. In our empirical\nevaluations, we demonstrate that the specialized algorithms we develop, which\nleverage additional information about the structure of the SFIPP instance,\noutperform our more general algorithm.",
      "tldr_zh": "该论文提出了一种名为 Sequential Fault-Intolerant Process Planning (SFIPP) 的规划问题，适用于顺序多阶段决策场景中，只有所有阶段成功才算成功的奖励结构，这种结构常见于药物/材料发现、安全和质量关键产品设计等领域。作者设计了可证明最优的在线算法，用于在每个阶段选择未知成功概率的动作，包括动作行为确定性和概率性情况；对于概率性场景，他们利用 multi-armed bandit algorithms 平衡探索和利用。实验结果表明，这些专门算法通过利用 SFIPP 的结构信息，显著优于更通用的算法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages; 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04998v1",
      "published_date": "2025-02-07 15:20:35 UTC",
      "updated_date": "2025-02-07 15:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:29:18.380781"
    },
    {
      "arxiv_id": "2502.04997v1",
      "title": "Aligning Black-box Language Models with Human Judgments",
      "title_zh": "翻译失败",
      "authors": [
        "Gerrit J. J. van den Burg",
        "Gen Suzuki",
        "Wei Liu",
        "Murat Sensoy"
      ],
      "abstract": "Large language models (LLMs) are increasingly used as automated judges to\nevaluate recommendation systems, search engines, and other subjective tasks,\nwhere relying on human evaluators can be costly, time-consuming, and\nunscalable. LLMs offer an efficient solution for continuous, automated\nevaluation. However, since the systems that are built and improved with these\njudgments are ultimately designed for human use, it is crucial that LLM\njudgments align closely with human evaluators to ensure such systems remain\nhuman-centered. On the other hand, aligning LLM judgments with human evaluators\nis challenging due to individual variability and biases in human judgments. We\npropose a simple yet effective framework to align LLM judgments with individual\nhuman evaluators or their aggregated judgments, without retraining or\nfine-tuning the LLM. Our approach learns a linear mapping between the LLM's\noutputs and human judgments, achieving over 142% average improvement in\nagreement across 29 tasks with only a small number of calibration examples used\nfor training. Notably, our method works in zero-shot and few-shot settings,\nexceeds inter-human agreement on four out of six tasks, and enables smaller\nLLMs to achieve performance comparable to that of larger models.",
      "tldr_zh": "这篇论文探讨了如何使黑箱LLMs的判断与人类评估一致，以提高LLMs在推荐系统、搜索引擎等主观任务中的自动化评估可靠性。研究提出一个简单框架，通过学习线性映射来对齐LLMs输出和人类判断，而无需重新训练或微调模型，仅需少量校准示例即可实现。实验结果显示，该方法在29个任务上平均提高了142%的同意度，并在零样本和少样本设置下有效，甚至使小型LLMs的性能达到大型模型水平，并在6个任务中超过了人类间的一致性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at NAACL 2025 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2502.04997v1",
      "published_date": "2025-02-07 15:19:40 UTC",
      "updated_date": "2025-02-07 15:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:29:30.588033"
    },
    {
      "arxiv_id": "2502.15740v1",
      "title": "Detection of LLM-Generated Java Code Using Discretized Nested Bigrams",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Paek",
        "Chilukuri Mohan"
      ],
      "abstract": "Large Language Models (LLMs) are currently used extensively to generate code\nby professionals and students, motivating the development of tools to detect\nLLM-generated code for applications such as academic integrity and\ncybersecurity. We address this authorship attribution problem as a binary\nclassification task along with feature identification and extraction. We\npropose new Discretized Nested Bigram Frequency features on source code groups\nof various sizes. Compared to prior work, improvements are obtained by\nrepresenting sparse information in dense membership bins. Experimental\nevaluation demonstrated that our approach significantly outperformed a commonly\nused GPT code-detection API and baseline features, with accuracy exceeding 96%\ncompared to 72% and 79% respectively in detecting GPT-rewritten Java code\nfragments for 976 files with GPT 3.5 and GPT4 using 12 features. We also\noutperformed three prior works on code author identification in a 40-author\ndataset. Our approach scales well to larger data sets, and we achieved 99%\naccuracy and 0.999 AUC for 76,089 files and over 1,000 authors with GPT 4o\nusing 227 features.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 生成的 Java 代码检测问题，提出了一种基于 Discretized Nested Bigram Frequency 特征的二元分类方法，以识别和提取代码特征。相比现有 GPT 代码检测 API 和基线特征，该方法通过将稀疏信息转化为密集成员分区，显著提升了检测性能。实验结果显示，在 976 个文件的数据集上，准确率超过 96%，而在更大的 76,089 文件数据集上，达到 99% 准确率和 0.999 AUC，并优于先前的代码作者识别工作。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T50, 62H30",
        "I.2.7; K.6.5; D.2.8"
      ],
      "primary_category": "cs.SE",
      "comment": "This preprint precedes the final peer-reviewed version, which will be\n  published in Springer's CSCI 2024 proceedings",
      "pdf_url": "http://arxiv.org/pdf/2502.15740v1",
      "published_date": "2025-02-07 14:32:20 UTC",
      "updated_date": "2025-02-07 14:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:29:42.544929"
    },
    {
      "arxiv_id": "2502.05244v1",
      "title": "Probabilistic Artificial Intelligence",
      "title_zh": "概率人工智能",
      "authors": [
        "Andreas Krause",
        "Jonas Hübotter"
      ],
      "abstract": "Artificial intelligence commonly refers to the science and engineering of\nartificial systems that can carry out tasks generally associated with requiring\naspects of human intelligence, such as playing games, translating languages,\nand driving cars. In recent years, there have been exciting advances in\nlearning-based, data-driven approaches towards AI, and machine learning and\ndeep learning have enabled computer systems to perceive the world in\nunprecedented ways. Reinforcement learning has enabled breakthroughs in complex\ngames such as Go and challenging robotics tasks such as quadrupedal locomotion.\n  A key aspect of intelligence is to not only make predictions, but reason\nabout the uncertainty in these predictions, and to consider this uncertainty\nwhen making decisions. This is what this manuscript on \"Probabilistic\nArtificial Intelligence\" is about. The first part covers probabilistic\napproaches to machine learning. We discuss the differentiation between\n\"epistemic\" uncertainty due to lack of data and \"aleatoric\" uncertainty, which\nis irreducible and stems, e.g., from noisy observations and outcomes. We\ndiscuss concrete approaches towards probabilistic inference and modern\napproaches to efficient approximate inference.\n  The second part of the manuscript is about taking uncertainty into account in\nsequential decision tasks. We consider active learning and Bayesian\noptimization -- approaches that collect data by proposing experiments that are\ninformative for reducing the epistemic uncertainty. We then consider\nreinforcement learning and modern deep RL approaches that use neural network\nfunction approximation. We close by discussing modern approaches in model-based\nRL, which harness epistemic and aleatoric uncertainty to guide exploration,\nwhile also reasoning about safety.",
      "tldr_zh": "本论文探讨了Probabilistic Artificial Intelligence，即在人工智能中整合概率方法来处理预测的不确定性，从而提升决策质量。论文分为两部分：第一部分介绍概率机器学习方法，区分了epistemic uncertainty（因数据不足导致的认识论不确定性）和aleatoric uncertainty（不可减少的偶然不确定性，如噪声），并讨论概率推理和高效近似推理技术。第二部分聚焦于顺序决策任务，包括active learning和Bayesian optimization用于减少epistemic uncertainty，以及强化学习（包括深度RL）和基于模型的RL方法，这些利用不确定性指导探索并确保安全。整体上，该手稿为AI系统在实际应用中更可靠地管理不确定性提供了理论框架和实用方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05244v1",
      "published_date": "2025-02-07 14:29:07 UTC",
      "updated_date": "2025-02-07 14:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:29:54.624546"
    },
    {
      "arxiv_id": "2502.04963v2",
      "title": "Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jianshu Zhang",
        "Xiaofu Wu",
        "Junquan Hu"
      ],
      "abstract": "This paper investigates the anti-jamming channel access problem in complex\nand unknown jamming environments, where the jammer could dynamically adjust its\nstrategies to target different channels. Traditional channel hopping\nanti-jamming approaches using fixed patterns are ineffective against such\ndynamic jamming attacks. Although the emerging deep reinforcement learning\n(DRL) based dynamic channel access approach could achieve the Nash equilibrium\nunder fast-changing jamming attacks, it requires extensive training episodes.\nTo address this issue, we propose a fast adaptive anti-jamming channel access\napproach guided by the intuition of ``learning faster than the jammer\", where a\nsynchronously updated coarse-grained spectrum prediction serves as an auxiliary\ntask for the deep Q learning (DQN) based anti-jamming model. This helps the\nmodel identify a superior Q-function compared to standard DRL while\nsignificantly reducing the number of training episodes. Numerical results\nindicate that the proposed approach significantly accelerates the rate of\nconvergence in model training, reducing the required training episodes by up to\n70% compared to standard DRL. Additionally, it also achieves a 10% improvement\nin throughput over NE strategies, owing to the effective use of coarse-grained\nspectrum prediction.",
      "tldr_zh": "这篇论文针对复杂未知干扰环境中动态干扰攻击的问题，提出了一种快速自适应反干扰信道访问方法，基于Deep Q Learning (DQN) 和粗粒度频谱预测（coarse-grained spectrum prediction）作为辅助任务，以实现“学习比干扰器快”的目标。该方法通过同步更新频谱预测，帮助DQN模型显著减少训练次数，同时提升Q函数的性能。实验结果显示，该方法将训练周期减少70%，并比Nash Equilibrium (NE) 策略提高10%的吞吐量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04963v2",
      "published_date": "2025-02-07 14:25:28 UTC",
      "updated_date": "2025-04-20 03:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:30:06.861568"
    },
    {
      "arxiv_id": "2502.10428v4",
      "title": "Dynamic Chain-of-Thought: Towards Adaptive Deep Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Libo Wang"
      ],
      "abstract": "To reduce the cost and consumption of computing resources caused by\ncomputational redundancy and delayed reward assignment in long CoT, this\nresearch proposes the dynamic chain-of-thought (D-CoT) with adaptive reasoning\ntime and steps. The researcher used simulation experiment to simulate the\nintegration of D-CoT through Python 3.13 IDLE combined with a Python simulator\nbased on GPTs. At the same time, the researcher used DeepSeek R1 as a control\ngroup to test and compare the performance of the D-CoT simulator in processing\nMIT OpenCourseWare's linear algebra exam questions. Experimental results show\nthat D-CoT is better than DeepSeek R1 based on long CoT in three indicators:\nreasoning time, CoT length (reasoning steps) and token count, which achieves a\nsignificant reduction in computing resource consumption. In addition, this\nresearch has potential value in deep reasoning optimization that is used as a\nreference for future dynamic deep reasoning frameworks.",
      "tldr_zh": "本文提出动态链式思维（D-CoT），一种自适应推理框架，旨在减少长 Chain-of-Thought (CoT) 中的计算冗余和延迟奖励分配问题，从而降低计算资源消耗。研究者通过 Python 3.13 IDLE 和基于 GPTs 的模拟器进行实验模拟，并以 DeepSeek R1 为对照组，在处理 MIT OpenCourseWare 的线性代数考试题目时进行比较。结果显示，D-CoT 在推理时间、CoT 长度（推理步骤）和 token 数量上均优于 DeepSeek R1，显著提升了效率，并为未来的动态深度推理框架优化提供了参考价值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The GitHub repository link is:\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/Dynamic%20CoT",
      "pdf_url": "http://arxiv.org/pdf/2502.10428v4",
      "published_date": "2025-02-07 14:24:43 UTC",
      "updated_date": "2025-04-05 13:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:30:19.725231"
    },
    {
      "arxiv_id": "2502.04951v1",
      "title": "The Rising Threat to Emerging AI-Powered Search Engines",
      "title_zh": "新兴 AI 驱动搜索引擎的上升威胁",
      "authors": [
        "Zeren Luo",
        "Zifan Peng",
        "Yule Liu",
        "Zhen Sun",
        "Mingchen Li",
        "Jingyi Zheng",
        "Xinlei He"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering\nprecise and efficient responses by integrating external databases with\npre-existing knowledge. However, we observe that these AIPSEs raise risks such\nas quoting malicious content or citing malicious websites, leading to harmful\nor unverified information dissemination. In this study, we conduct the first\nsafety risk quantification on seven production AIPSEs by systematically\ndefining the threat model, risk level, and evaluating responses to various\nquery types. With data collected from PhishTank, ThreatBook, and LevelBlue, our\nfindings reveal that AIPSEs frequently generate harmful content that contains\nmalicious URLs even with benign queries (e.g., with benign keywords). We also\nobserve that directly query URL will increase the risk level while query with\nnatural language will mitigate such risk. We further perform two case studies\non online document spoofing and phishing to show the ease of deceiving AIPSEs\nin the real-world setting. To mitigate these risks, we develop an agent-based\ndefense with a GPT-4o-based content refinement tool and an XGBoost-based URL\ndetector. Our evaluation shows that our defense can effectively reduce the risk\nbut with the cost of reducing available information. Our research highlights\nthe urgent need for robust safety measures in AIPSEs.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)增强的AI-Powered Search Engines (AIPSEs)所带来的安全风险，这些引擎虽能提供精确响应，但可能引用恶意内容或网站，导致有害信息传播。研究者首次对七个生产AIPSEs进行了系统量化评估，包括定义威胁模型、风险级别，并使用PhishTank、ThreatBook和LevelBlue的数据，发现即使在良性查询下，AIPSEs也常生成包含恶意URL的内容，且直接查询URL会增加风险，而自然语言查询可降低风险。论文还通过在线文档欺骗和网络钓鱼的案例研究，展示了欺骗AIPSEs的易用性，并开发了一个基于代理的防御系统，包括GPT-4o-based内容精炼工具和XGBoost-based URL检测器，该系统能有效降低风险但会减少可用信息。总体而言，这突出了对AIPSEs实施强有力安全措施的紧迫需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04951v1",
      "published_date": "2025-02-07 14:15:46 UTC",
      "updated_date": "2025-02-07 14:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:30:32.160268"
    },
    {
      "arxiv_id": "2502.04937v1",
      "title": "Data-driven Modality Fusion: An AI-enabled Framework for Large-Scale Sensor Network Management",
      "title_zh": "翻译失败",
      "authors": [
        "Hrishikesh Dutta",
        "Roberto Minerva",
        "Maira Alvi",
        "Noel Crespi"
      ],
      "abstract": "The development and operation of smart cities relyheavily on large-scale\nInternet-of-Things (IoT) networks and sensor infrastructures that continuously\nmonitor various aspects of urban environments. These networks generate vast\namounts of data, posing challenges related to bandwidth usage, energy\nconsumption, and system scalability. This paper introduces a novel sensing\nparadigm called Data-driven Modality Fusion (DMF), designed to enhance the\nefficiency of smart city IoT network management. By leveraging correlations\nbetween timeseries data from different sensing modalities, the proposed DMF\napproach reduces the number of physical sensors required for monitoring,\nthereby minimizing energy expenditure, communication bandwidth, and overall\ndeployment costs. The framework relocates computational complexity from the\nedge devices to the core, ensuring that resource-constrained IoT devices are\nnot burdened with intensive processing tasks. DMF is validated using data from\na real-world IoT deployment in Madrid, demonstrating the effectiveness of the\nproposed system in accurately estimating traffic, environmental, and pollution\nmetrics from a reduced set of sensors. The proposed solution offers a scalable,\nefficient mechanism for managing urban IoT networks, while addressing issues of\nsensor failure and privacy concerns.",
      "tldr_zh": "这篇论文提出了一种名为 Data-driven Modality Fusion (DMF) 的AI框架，用于优化大规模IoT传感器网络的管理，以应对智能城市中数据量大、带宽消耗高和能源问题。DMF通过利用不同感知模态的时间序列数据相关性，减少物理传感器的部署数量，从而降低能源消耗、通信带宽和总体成本，同时将计算密集任务从边缘设备转移到核心处理中心。实验基于马德里的真实IoT数据验证，展示了DMF在减少传感器情况下准确估计交通、环境和污染指标的有效性，并解决了传感器故障和隐私问题，提供了一个可伸缩、高效的网络管理解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04937v1",
      "published_date": "2025-02-07 14:00:04 UTC",
      "updated_date": "2025-02-07 14:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:30:43.133257"
    },
    {
      "arxiv_id": "2502.04935v1",
      "title": "Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market",
      "title_zh": "翻译失败",
      "authors": [
        "Ciaran O'Connor",
        "Mohamed Bahloul",
        "Roberto Rossi",
        "Steven Prestwich",
        "Andrea Visentin"
      ],
      "abstract": "The integration of renewable energy into electricity markets poses\nsignificant challenges to price stability and increases the complexity of\nmarket operations. Accurate and reliable electricity price forecasting is\ncrucial for effective market participation, where price dynamics can be\nsignificantly more challenging to predict. Probabilistic forecasting, through\nprediction intervals, efficiently quantifies the inherent uncertainties in\nelectricity prices, supporting better decision-making for market participants.\nThis study explores the enhancement of probabilistic price prediction using\nConformal Prediction (CP) techniques, specifically Ensemble Batch Prediction\nIntervals and Sequential Predictive Conformal Inference. These methods provide\nprecise and reliable prediction intervals, outperforming traditional models in\nvalidity metrics. We propose an ensemble approach that combines the efficiency\nof quantile regression models with the robust coverage properties of time\nseries adapted CP techniques. This ensemble delivers both narrow prediction\nintervals and high coverage, leading to more reliable and accurate forecasts.\nWe further evaluate the practical implications of CP techniques through a\nsimulated trading algorithm applied to a battery storage system. The ensemble\napproach demonstrates improved financial returns in energy trading in both the\nDay-Ahead and Balancing Markets, highlighting its practical benefits for market\nparticipants.",
      "tldr_zh": "本研究探讨了使用 Conformal Prediction (CP) 技术提升电力价格预测的准确性和可靠性，针对可再生能源整合导致的市场不稳定性问题。作者提出了一种集成方法，将 quantile regression 模型与 CP 技术（如 Ensemble Batch Prediction Intervals 和 Sequential Predictive Conformal Inference）相结合，提供窄的预测区间和高覆盖率，从而在有效性指标上优于传统模型。通过模拟交易算法应用于电池存储系统，该方法在 Day-Ahead 和 Balancing Markets 中实现了更高的财务回报。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04935v1",
      "published_date": "2025-02-07 13:57:47 UTC",
      "updated_date": "2025-02-07 13:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:30:55.276916"
    },
    {
      "arxiv_id": "2502.04923v1",
      "title": "Cached Multi-Lora Composition for Multi-Concept Image Generation",
      "title_zh": "缓存多LoRA组合用于多概念图像生成",
      "authors": [
        "Xiandong Zou",
        "Mingzhu Shen",
        "Christos-Savvas Bouganis",
        "Yiren Zhao"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in\ntext-to-image models, enabling precise rendering of multiple distinct elements,\nsuch as characters and styles, in multi-concept image generation. However,\ncurrent approaches face significant challenges when composing these LoRAs for\nmulti-concept image generation, resulting in diminished generated image\nquality. In this paper, we initially investigate the role of LoRAs in the\ndenoising process through the lens of the Fourier frequency domain. Based on\nthe hypothesis that applying multiple LoRAs could lead to \"semantic conflicts\",\nwe find that certain LoRAs amplify high-frequency features such as edges and\ntextures, whereas others mainly focus on low-frequency elements, including the\noverall structure and smooth color gradients. Building on these insights, we\ndevise a frequency domain based sequencing strategy to determine the optimal\norder in which LoRAs should be integrated during inference. This strategy\noffers a methodical and generalizable solution compared to the naive\nintegration commonly found in existing LoRA fusion techniques. To fully\nleverage our proposed LoRA order sequence determination method in multi-LoRA\ncomposition tasks, we introduce a novel, training-free framework, Cached\nMulti-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while\nmaintaining cohesive image generation. With its flexible backbone for\nmulti-LoRA fusion and a non-uniform caching strategy tailored to individual\nLoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRA\ncomposition and improve computational efficiency. Our experimental evaluations\ndemonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion\nmethods by a significant margin -- it achieves an average improvement of\n$2.19\\%$ in CLIPScore, and $11.25\\%$ in MLLM win rate compared to LoraHub, LoRA\nComposite, and LoRA Switch.",
      "tldr_zh": "该论文探讨了在多概念图像生成中组合多个 Low-Rank Adaptation (LoRA) 时面临的图像质量下降问题，通过傅立叶频率域分析发现语义冲突源于某些 LoRA 增强高频特征（如边缘和纹理），而其他 LoRA 则专注于低频元素（如整体结构和颜色渐变）。为此，作者提出了一种基于频率域的序列策略来确定 LoRA 的最佳整合顺序，并开发了无训练框架 Cached Multi-LoRA (CMLoRA)，该框架采用灵活的融合骨干和非均匀缓存策略，以减少语义冲突并提升计算效率。实验结果显示，CMLoRA 相较于 LoraHub、LoRA Composite 和 LoRA Switch 等方法，在 CLIPScore 上平均提升 2.19%，在 MLLM win rate 上提升 11.25%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.04923v1",
      "published_date": "2025-02-07 13:41:51 UTC",
      "updated_date": "2025-02-07 13:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:31:08.473558"
    },
    {
      "arxiv_id": "2502.04917v1",
      "title": "Complex Physics-Informed Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Si",
        "Ming Yan",
        "Xin Li",
        "Zhihong Xia"
      ],
      "abstract": "We propose compleX-PINN, a novel physics-informed neural network (PINN)\narchitecture that incorporates a learnable activation function inspired by\nCauchy integral theorem. By learning the parameters of the activation function,\ncompleX-PINN achieves high accuracy with just a single hidden layer. Empirical\nresults show that compleX-PINN effectively solves problems where traditional\nPINNs struggle and consistently delivers significantly higher precision, often\nby an order of magnitude.",
      "tldr_zh": "我们提出 compleX-PINN，一种新型的物理信息神经网络 (PINN) 架构，它整合了受 Cauchy integral theorem 启发的可学习激活函数，以仅需一层隐藏层即可实现高精度建模。相比传统 PINN，该方法通过学习激活函数的参数，能够有效解决复杂问题，并在实验中表现出显著优势，往往精度高出一个数量级。总的来说，compleX-PINN 为神经网络在物理模拟领域的应用提供了更高效且精确的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04917v1",
      "published_date": "2025-02-07 13:36:42 UTC",
      "updated_date": "2025-02-07 13:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:31:18.434033"
    },
    {
      "arxiv_id": "2502.05242v1",
      "title": "SEER: Self-Explainability Enhancement of Large Language Models' Representations",
      "title_zh": "SEER：大语言模型表示的自我解释性增强",
      "authors": [
        "Guanxu Chen",
        "Dongrui Liu",
        "Tao Luo",
        "Jing Shao"
      ],
      "abstract": "Explaining the hidden representations of Large Language Models (LLMs) is a\nperspective to understand LLMs' underlying inference logic and improve their\nreliability in application scenarios. However, previous methods introduce\nexternal ''black-box'' modules to explain ''black-box'' LLMs, increasing the\npotential uncertainty and failing to provide faithful explanations. In this\npaper, we propose a self-explaining method SEER, enhancing LLMs' explainability\nby aggregating the same concept and disentangling the different concepts in the\nrepresentation space. In this way, SEER provides faithful explanations carried\nby representations synchronously with the LLMs' output. Additionally, we\nshowcase the applications of SEER on trustworthiness-related tasks (e.g., the\nsafety risks classification and detoxification tasks), where self-explained\nLLMs achieve consistent improvement in explainability and performance. More\ncrucially, we theoretically analyze the improvement of SEER on LLMs'\ngeneralization ability through optimal transport theory.",
      "tldr_zh": "本论文提出SEER方法，以提升大型语言模型(LLMs)的表示可解释性，避免依赖外部“黑盒”模块带来的不确定性。SEER通过在表示空间中聚合相同概念并分离不同概念，提供与LLMs输出同步的忠实解释，并在可信性任务（如安全风险分类和解毒任务）上实现了性能和可解释性的显著提升。更重要的是，论文通过最优传输理论分析了SEER对LLMs泛化能力的改善，为模型可靠性提供了理论支撑。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages,5 figures,10 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.05242v1",
      "published_date": "2025-02-07 13:25:33 UTC",
      "updated_date": "2025-02-07 13:25:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:31:30.547891"
    },
    {
      "arxiv_id": "2502.04903v1",
      "title": "Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Huang",
        "Rui Huang",
        "Jinghao Xu",
        "Siran Pen",
        "Yule Duan",
        "Liangjian Deng"
      ],
      "abstract": "Pansharpening aims to combine a high-resolution panchromatic (PAN) image with\na low-resolution multispectral (LRMS) image to produce a high-resolution\nmultispectral (HRMS) image. Although pansharpening in the frequency domain\noffers clear advantages, most existing methods either continue to operate\nsolely in the spatial domain or fail to fully exploit the benefits of the\nfrequency domain. To address this issue, we innovatively propose\nMulti-Frequency Fusion Attention (MFFA), which leverages wavelet transforms to\ncleanly separate frequencies and enable lossless reconstruction across\ndifferent frequency domains. Then, we generate Frequency-Query, Spatial-Key,\nand Fusion-Value based on the physical meanings represented by different\nfeatures, which enables a more effective capture of specific information in the\nfrequency domain. Additionally, we focus on the preservation of frequency\nfeatures across different operations. On a broader level, our network employs a\nwavelet pyramid to progressively fuse information across multiple scales.\nCompared to previous frequency domain approaches, our network better prevents\nconfusion and loss of different frequency features during the fusion process.\nQuantitative and qualitative experiments on multiple datasets demonstrate that\nour method outperforms existing approaches and shows significant generalization\ncapabilities for real-world scenarios.",
      "tldr_zh": "该论文针对Pansharpening问题，即将高分辨率单色图像(PAN)与低分辨率多光谱图像(LRMS)融合生成高分辨率多光谱图像(HRMS)，提出了一种Wavelet-Assisted Multi-Frequency Attention Network。核心创新是Multi-Frequency Fusion Attention (MFFA)模块，利用wavelet transforms分离频率域信息，并基于不同特征的物理含义生成Frequency-Query、Spatial-Key和Fusion-Value，以更有效地捕捉特定频率信息，同时通过wavelet pyramid在多个尺度上逐步融合，避免频率特征的混淆和丢失。实验结果显示，该方法在多个数据集上的定量和定性性能均优于现有方法，并展现出显著的泛化能力，适用于真实场景。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04903v1",
      "published_date": "2025-02-07 13:15:49 UTC",
      "updated_date": "2025-02-07 13:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:31:44.108968"
    },
    {
      "arxiv_id": "2502.04899v1",
      "title": "Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects",
      "title_zh": "自监督事件流建模中的统一方法：进展与前景",
      "authors": [
        "Levente Zólyomi",
        "Tianze Wang",
        "Sofiane Ennadir",
        "Oleg Smirnov",
        "Lele Cao"
      ],
      "abstract": "The proliferation of digital interactions across diverse domains, such as\nhealthcare, e-commerce, gaming, and finance, has resulted in the generation of\nvast volumes of event stream (ES) data. ES data comprises continuous sequences\nof timestamped events that encapsulate detailed contextual information relevant\nto each domain. While ES data holds significant potential for extracting\nactionable insights and enhancing decision-making, its effective utilization is\nhindered by challenges such as the scarcity of labeled data and the fragmented\nnature of existing research efforts. Self-Supervised Learning (SSL) has emerged\nas a promising paradigm to address these challenges by enabling the extraction\nof meaningful representations from unlabeled ES data. In this survey, we\nsystematically review and synthesize SSL methodologies tailored for ES modeling\nacross multiple domains, bridging the gaps between domain-specific approaches\nthat have traditionally operated in isolation. We present a comprehensive\ntaxonomy of SSL techniques, encompassing both predictive and contrastive\nparadigms, and analyze their applicability and effectiveness within different\napplication contexts. Furthermore, we identify critical gaps in current\nresearch and propose a future research agenda aimed at developing scalable,\ndomain-agnostic SSL frameworks for ES modeling. By unifying disparate research\nefforts and highlighting cross-domain synergies, this survey aims to accelerate\ninnovation, improve reproducibility, and expand the applicability of SSL to\ndiverse real-world ES challenges.",
      "tldr_zh": "这篇论文系统回顾了Self-Supervised Learning (SSL) 在Event Stream (ES) 建模中的统一方法，旨在解决ES数据标签稀缺和研究碎片化等问题。作者提出一个全面的SSL技术分类，包括预测和对比范式，并分析这些方法在医疗、电商等领域的适用性和有效性。通过桥接跨领域方法，论文识别了当前研究的空白，并提出未来研究议程，聚焦于开发可扩展的、领域无关的SSL框架。最后，该调查旨在统一研究努力，促进创新、提升可重复性，并扩展SSL在实际ES挑战中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04899v1",
      "published_date": "2025-02-07 13:05:55 UTC",
      "updated_date": "2025-02-07 13:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:31:55.702681"
    },
    {
      "arxiv_id": "2502.04898v1",
      "title": "ARTInp: CBCT-to-CT Image Inpainting and Image Translation in Radiotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Ricardo Coimbra Brioso",
        "Leonardo Crespi",
        "Andrea Seghetto",
        "Damiano Dei",
        "Nicola Lambri",
        "Pietro Mancosu",
        "Marta Scorsetti",
        "Daniele Loiacono"
      ],
      "abstract": "A key step in Adaptive Radiation Therapy (ART) workflows is the evaluation of\nthe patient's anatomy at treatment time to ensure the accuracy of the delivery.\nTo this end, Cone Beam Computerized Tomography (CBCT) is widely used being\ncost-effective and easy to integrate into the treatment process. Nonetheless,\nCBCT images have lower resolution and more artifacts than CT scans, making them\nless reliable for precise treatment validation. Moreover, in complex treatments\nsuch as Total Marrow and Lymph Node Irradiation (TMLI), where full-body\nvisualization of the patient is critical for accurate dose delivery, the CBCT\nimages are often discontinuous, leaving gaps that could contain relevant\nanatomical information. To address these limitations, we propose ARTInp\n(Adaptive Radiation Therapy Inpainting), a novel deep-learning framework\ncombining image inpainting and CBCT-to-CT translation. ARTInp employs a\ndual-network approach: a completion network that fills anatomical gaps in CBCT\nvolumes and a custom Generative Adversarial Network (GAN) to generate\nhigh-quality synthetic CT (sCT) images. We trained ARTInp on a dataset of\npaired CBCT and CT images from the SynthRad 2023 challenge, and the performance\nachieved on a test set of 18 patients demonstrates its potential for enhancing\nCBCT-based workflows in radiotherapy.",
      "tldr_zh": "在 Adaptive Radiation Therapy (ART) 中，Cone Beam Computerized Tomography (CBCT) 图像的分辨率低、存在 artifacts 和不连续 gaps，导致其在精确治疗验证中可靠性不足，尤其在复杂场景如 Total Marrow and Lymph Node Irradiation (TMLI) 中。\n本文提出 ARTInp 框架，该框架结合图像 inpainting 和 CBCT-to-CT translation，使用双网络方法：一个 completion network 填充 CBCT 图像中的 anatomical gaps，以及一个 custom Generative Adversarial Network (GAN) 生成高品质 synthetic CT (sCT) 图像。\n在 SynthRad 2023 challenge 的配对 CBCT 和 CT 图像数据集上训练，ARTInp 在 18 名患者的测试集上表现出色，展示了其提升 CBCT-based workflows 在放射治疗中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04898v1",
      "published_date": "2025-02-07 13:04:25 UTC",
      "updated_date": "2025-02-07 13:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:32:08.074699"
    },
    {
      "arxiv_id": "2502.07807v1",
      "title": "CP-Guard+: A New Paradigm for Malicious Agent Detection and Defense in Collaborative Perception",
      "title_zh": "CP-Guard+：协作感知中恶意代理检测",
      "authors": [
        "Senkang Hu",
        "Yihang Tao",
        "Zihan Fang",
        "Guowen Xu",
        "Yiqin Deng",
        "Sam Kwong",
        "Yuguang Fang"
      ],
      "abstract": "Collaborative perception (CP) is a promising method for safe connected and\nautonomous driving, which enables multiple vehicles to share sensing\ninformation to enhance perception performance. However, compared with\nsingle-vehicle perception, the openness of a CP system makes it more vulnerable\nto malicious attacks that can inject malicious information to mislead the\nperception of an ego vehicle, resulting in severe risks for safe driving. To\nmitigate such vulnerability, we first propose a new paradigm for malicious\nagent detection that effectively identifies malicious agents at the feature\nlevel without requiring verification of final perception results, significantly\nreducing computational overhead. Building on this paradigm, we introduce\nCP-GuardBench, the first comprehensive dataset provided to train and evaluate\nvarious malicious agent detection methods for CP systems. Furthermore, we\ndevelop a robust defense method called CP-Guard+, which enhances the margin\nbetween the representations of benign and malicious features through a\ncarefully designed Dual-Centered Contrastive Loss (DCCLoss). Finally, we\nconduct extensive experiments on both CP-GuardBench and V2X-Sim, and\ndemonstrate the superiority of CP-Guard+.",
      "tldr_zh": "该论文针对协作感知(Collaborative Perception)系统在自动驾驶中的安全漏洞，提出一个新的恶意代理检测范式，能够在特征级别识别恶意代理，而无需验证最终感知结果，从而显著减少计算开销。同时，引入CP-GuardBench作为首个全面数据集，用于训练和评估各种检测方法，并开发CP-Guard+防御机制，该机制通过Dual-Centered Contrastive Loss (DCCLoss)增强良性和恶意特征之间的差异。在CP-GuardBench和V2X-Sim数据集上的实验表明，CP-Guard+表现出优越性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07807v1",
      "published_date": "2025-02-07 12:58:45 UTC",
      "updated_date": "2025-02-07 12:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:32:19.126578"
    },
    {
      "arxiv_id": "2502.04878v1",
      "title": "Sparse Autoencoders Do Not Find Canonical Units of Analysis",
      "title_zh": "稀疏自编码器无法找到规范的分析单位",
      "authors": [
        "Patrick Leask",
        "Bart Bussmann",
        "Michael Pearce",
        "Joseph Bloom",
        "Curt Tigges",
        "Noura Al Moubayed",
        "Lee Sharkey",
        "Neel Nanda"
      ],
      "abstract": "A common goal of mechanistic interpretability is to decompose the activations\nof neural networks into features: interpretable properties of the input\ncomputed by the model. Sparse autoencoders (SAEs) are a popular method for\nfinding these features in LLMs, and it has been postulated that they can be\nused to find a \\textit{canonical} set of units: a unique and complete list of\natomic features. We cast doubt on this belief using two novel techniques: SAE\nstitching to show they are incomplete, and meta-SAEs to show they are not\natomic. SAE stitching involves inserting or swapping latents from a larger SAE\ninto a smaller one. Latents from the larger SAE can be divided into two\ncategories: \\emph{novel latents}, which improve performance when added to the\nsmaller SAE, indicating they capture novel information, and\n\\emph{reconstruction latents}, which can replace corresponding latents in the\nsmaller SAE that have similar behavior. The existence of novel features\nindicates incompleteness of smaller SAEs. Using meta-SAEs -- SAEs trained on\nthe decoder matrix of another SAE -- we find that latents in SAEs often\ndecompose into combinations of latents from a smaller SAE, showing that larger\nSAE latents are not atomic. The resulting decompositions are often\ninterpretable; e.g. a latent representing ``Einstein'' decomposes into\n``scientist'', ``Germany'', and ``famous person''. Even if SAEs do not find\ncanonical units of analysis, they may still be useful tools. We suggest that\nfuture research should either pursue different approaches for identifying such\nunits, or pragmatically choose the SAE size suited to their task. We provide an\ninteractive dashboard to explore meta-SAEs: https://metasaes.streamlit.app/",
      "tldr_zh": "该论文质疑稀疏自编码器(SAEs)是否能找到神经网络激活的规范单位(canonical units of analysis)，通过两种新方法证明SAEs在大型语言模型(LLMs)中不完整且不原子。作者使用SAE stitching技术，将较大SAE的潜在变量插入较小SAE中，发现存在新颖潜在变量(novel latents)补充信息和重构潜在变量(reconstruction latents)可互换，表明较小SAEs不完整；同时，通过meta-SAEs在另一个SAE的解码器矩阵上训练，发现较大SAE的潜在变量可分解为更小组合，如“Einstein”分解为“scientist”、“Germany”和“famous person”。尽管SAEs可能无法提供规范单位，但它们仍是实用工具，论文建议未来研究探索替代方法或根据任务选择合适SAE大小，并提供交互式仪表板供探索。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.04878v1",
      "published_date": "2025-02-07 12:33:08 UTC",
      "updated_date": "2025-02-07 12:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:32:32.643279"
    },
    {
      "arxiv_id": "2502.04864v1",
      "title": "$TAR^2$: Temporal-Agent Reward Redistribution for Optimal Policy Preservation in Multi-Agent Reinforcement Learning",
      "title_zh": "$TAR^2$：时间-代理奖励重新分配用于多智能体强化学习中的最优策略保留",
      "authors": [
        "Aditya Kapoor",
        "Kale-ab Tessera",
        "Mayank Baranwal",
        "Harshad Khadilkar",
        "Stefano Albrecht",
        "Mingfei Sun"
      ],
      "abstract": "In cooperative multi-agent reinforcement learning (MARL), learning effective\npolicies is challenging when global rewards are sparse and delayed. This\ndifficulty arises from the need to assign credit across both agents and time\nsteps, a problem that existing methods often fail to address in episodic,\nlong-horizon tasks. We propose Temporal-Agent Reward Redistribution $TAR^2$, a\nnovel approach that decomposes sparse global rewards into agent-specific,\ntime-step-specific components, thereby providing more frequent and accurate\nfeedback for policy learning. Theoretically, we show that $TAR^2$ (i) aligns\nwith potential-based reward shaping, preserving the same optimal policies as\nthe original environment, and (ii) maintains policy gradient update directions\nidentical to those under the original sparse reward, ensuring unbiased credit\nsignals. Empirical results on two challenging benchmarks, SMACLite and Google\nResearch Football, demonstrate that $TAR^2$ significantly stabilizes and\naccelerates convergence, outperforming strong baselines like AREL and STAS in\nboth learning speed and final performance. These findings establish $TAR^2$ as\na principled and practical solution for agent-temporal credit assignment in\nsparse-reward multi-agent systems.",
      "tldr_zh": "在合作式多智能体强化学习(MARL)中，稀疏和延迟的全局奖励使得跨智能体和时间步骤的信用分配成为挑战，$TAR^2$ 方法通过将这些奖励分解为特定智能体和时间步骤的组件，提供更频繁且准确的反馈。理论上，$TAR^2$ 与基于潜力的奖励整形一致，确保保留了原始环境的 optimal policies，并保持政策梯度更新方向的无偏性。实验结果显示，在 SMACLite 和 Google Research Football 等基准上，$TAR^2$ 显著稳定并加速收敛，优于 AREL 和 STAS 等基线，在学习速度和最终性能上表现出色。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "23 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.04864v1",
      "published_date": "2025-02-07 12:07:57 UTC",
      "updated_date": "2025-02-07 12:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:32:43.722580"
    },
    {
      "arxiv_id": "2502.06851v2",
      "title": "Survey on Vision-Language-Action Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adilzhan Adilkhanov",
        "Amir Yelenov",
        "Assylkhan Seitzhanov",
        "Ayan Mazhitov",
        "Azamat Abdikarimov",
        "Danissa Sandykbayeva",
        "Daryn Kenzhebek",
        "Dinmukhammed Mukashev",
        "Ilyas Umurbekov",
        "Jabrail Chumakov",
        "Kamila Spanova",
        "Karina Burunchina",
        "Madina Yergibay",
        "Margulan Issa",
        "Moldir Zabirova",
        "Nurdaulet Zhuzbay",
        "Nurlan Kabdyshev",
        "Nurlan Zhaniyar",
        "Rasul Yermagambet",
        "Rustam Chibar",
        "Saltanat Seitzhan",
        "Soibkhon Khajikhanov",
        "Tasbolat Taunyazov",
        "Temirlan Galimzhanov",
        "Temirlan Kaiyrbay",
        "Tleukhan Mussin",
        "Togzhan Syrymova",
        "Valeriya Kostyukova",
        "Yerkebulan Massalim",
        "Yermakhan Kassym",
        "Zerde Nurbayeva",
        "Zhanat Kappassov"
      ],
      "abstract": "This paper presents an AI-generated review of Vision-Language-Action (VLA)\nmodels, summarizing key methodologies, findings, and future directions. The\ncontent is produced using large language models (LLMs) and is intended only for\ndemonstration purposes. This work does not represent original research, but\nhighlights how AI can help automate literature reviews. As AI-generated content\nbecomes more prevalent, ensuring accuracy, reliability, and proper synthesis\nremains a challenge. Future research will focus on developing a structured\nframework for AI-assisted literature reviews, exploring techniques to enhance\ncitation accuracy, source credibility, and contextual understanding. By\nexamining the potential and limitations of LLM in academic writing, this study\naims to contribute to the broader discussion of integrating AI into research\nworkflows. This work serves as a preliminary step toward establishing\nsystematic approaches for leveraging AI in literature review generation, making\nacademic knowledge synthesis more efficient and scalable.",
      "tldr_zh": "这篇论文呈现了一个由AI生成的对Vision-Language-Action (VLA)模型的综述，总结了关键方法、发现和未来方向，但并非原创研究，而是旨在展示大型语言模型(LLMs)如何自动化文献综述过程。论文强调了AI生成内容的挑战，包括准确性、可靠性和综合性问题，并探讨了如何通过结构化框架提升引文准确性、来源可信度和上下文理解。总体而言，该研究为整合AI到学术工作流中提供了初步见解，有助于使知识合成更高效和可扩展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06851v2",
      "published_date": "2025-02-07 11:56:46 UTC",
      "updated_date": "2025-02-15 06:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:32:55.001138"
    },
    {
      "arxiv_id": "2502.05239v1",
      "title": "Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Hussam Ghanem",
        "Christophe Cruz"
      ],
      "abstract": "Recent advancements in large language models have demonstrated significant\npotential in the automated construction of knowledge graphs from unstructured\ntext. This paper builds upon our previous work [16], which evaluated various\nmodels using metrics like precision, recall, F1 score, triple matching, and\ngraph matching, and introduces a refined approach to address the critical\nissues of hallucination and omission. We propose an enhanced evaluation\nframework incorporating BERTScore for graph similarity, setting a practical\nthreshold of 95% for graph matching. Our experiments focus on the Mistral\nmodel, comparing its original and fine-tuned versions in zero-shot and few-shot\nsettings. We further extend our experiments using examples from the KELM-sub\ntraining dataset, illustrating that the fine-tuned model significantly improves\nknowledge graph construction accuracy while reducing the exact hallucination\nand omission. However, our findings also reveal that the fine-tuned models\nperform worse in generalization tasks on the KELM-sub dataset. This study\nunderscores the importance of comprehensive evaluation metrics in advancing the\nstate-of-the-art in knowledge graph construction from textual data.",
      "tldr_zh": "本文增强了知识图谱构建的评估框架，重点针对 hallucination 和 omission 问题，基于先前工作[16]引入 BERTScore 进行图谱相似度评估，并设置95%的匹配阈值。实验比较了 Mistral 模型的原版和微调版本，在零样本和少样本设置下，使用 KELM-sub 训练数据集，显示微调模型显著提高了知识图谱构建的准确性并减少了 hallucination 和 omission。然而，微调模型在 KELM-sub 数据集的泛化任务上表现更差。该研究强调了全面评估指标（如精确率、召回率和图谱匹配）在从文本数据构建知识图谱方面的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05239v1",
      "published_date": "2025-02-07 11:19:01 UTC",
      "updated_date": "2025-02-07 11:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:33:08.271468"
    },
    {
      "arxiv_id": "2503.04751v1",
      "title": "What is Ethical: AIHED Driving Humans or Human-Driven AIHED? A Conceptual Framework enabling the Ethos of AI-driven Higher education",
      "title_zh": "翻译失败",
      "authors": [
        "Prashant Mahajan"
      ],
      "abstract": "The rapid integration of Artificial Intelligence (AI) in Higher Education\n(HE) is transforming personalized learning, administrative automation, and\ndecision-making. However, this progress presents a duality, as AI adoption also\nintroduces ethical and institutional challenges, including algorithmic bias,\ndata privacy risks, and governance inconsistencies. To address these concerns,\nthis study introduces the Human-Driven AI in Higher Education (HD-AIHED)\nFramework, ensuring compliance with UNESCO and OECD ethical standards. This\nconceptual research employs a qualitative meta-synthesis approach, integrating\nqualitative and quantitative studies to identify patterns, contradictions, and\ngaps in AI adoption within HE. It reinterprets existing datasets through\ntheoretical and ethical lenses to develop governance frameworks. The study\napplies a participatory integrated co-system, Phased Human Intelligence, SWOC\nanalysis, and AI ethical review boards to assess AI readiness and governance\nstrategies for universities and HE institutions. The HD-AIHED model bridges AI\nresearch gaps, addresses global real-time challenges, and provides tailored,\nscalable, and ethical strategies for diverse educational contexts. By\nemphasizing interdisciplinary collaboration among stakeholders, this study\nenvisions AIHED as a transparent and equitable force for innovation. The\nHD-AIHED framework ensures AI acts as a collaborative and ethical enabler\nrather than a disruptive replacement for human intelligence while advocating\nfor responsible AI implementation in HE.",
      "tldr_zh": "这篇论文探讨了 AI 在高等教育（HE）中的快速整合所带来的双重性，包括个性化学习和决策优化的益处，以及算法偏差、数据隐私风险和治理不一致的挑战。\n为了应对这些问题，研究引入了 Human-Driven AI in Higher Education (HD-AIHED) 框架，该框架基于定性元综合方法，整合现有定性和定量研究，并应用 Phased Human Intelligence、SWOC 分析以及 AI 伦理审查委员会来识别模式、矛盾和差距。\nHD-AIHED 模型桥接了 AI 研究空白，提供可扩展的伦理策略，确保符合 UNESCO 和 OECD 标准，并通过跨学科合作推动 AI 作为透明、公平的创新力量，而非取代人类智能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Tables 9, Figures 6",
      "pdf_url": "http://arxiv.org/pdf/2503.04751v1",
      "published_date": "2025-02-07 11:13:31 UTC",
      "updated_date": "2025-02-07 11:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:33:19.886620"
    },
    {
      "arxiv_id": "2502.04834v1",
      "title": "Lightweight Operations for Visual Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Iason Ioannis Panagos",
        "Giorgos Sfikas",
        "Christophoros Nikou"
      ],
      "abstract": "Visual speech recognition (VSR), which decodes spoken words from video data,\noffers significant benefits, particularly when audio is unavailable. However,\nthe high dimensionality of video data leads to prohibitive computational costs\nthat demand powerful hardware, limiting VSR deployment on resource-constrained\ndevices. This work addresses this limitation by developing lightweight VSR\narchitectures. Leveraging efficient operation design paradigms, we create\ncompact yet powerful models with reduced resource requirements and minimal\naccuracy loss. We train and evaluate our models on a large-scale public dataset\nfor recognition of words from video sequences, demonstrating their\neffectiveness for practical applications. We also conduct an extensive array of\nablative experiments to thoroughly analyze the size and complexity of each\nmodel. Code and trained models will be made publicly available.",
      "tldr_zh": "本文研究视觉语音识别 (VSR)，一种从视频数据中解码口语的技术，但其高维度数据导致计算成本高，限制了在资源受限设备上的部署。作者开发了轻量级 VSR 架构，通过高效操作设计范式，创建了紧凑模型，显著降低了资源需求，同时仅损失最小准确性。在大规模公共数据集上训练和评估这些模型，并通过广泛的消融实验分析了模型大小和复杂性，证明了其在实际应用中的有效性；代码和训练模型将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages (double column format), 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04834v1",
      "published_date": "2025-02-07 11:08:32 UTC",
      "updated_date": "2025-02-07 11:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:33:31.176939"
    },
    {
      "arxiv_id": "2502.04829v1",
      "title": "Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization",
      "title_zh": "针对高维黑箱优化的乐观梯度学习与Hessian校正",
      "authors": [
        "Yedidya Kfir",
        "Elad Sarafian",
        "Sarit Kraus",
        "Yoram Louzoun"
      ],
      "abstract": "Black-box algorithms are designed to optimize functions without relying on\ntheir underlying analytical structure or gradient information, making them\nessential when gradients are inaccessible or difficult to compute. Traditional\nmethods for solving black-box optimization (BBO) problems predominantly rely on\nnon-parametric models and struggle to scale to large input spaces. Conversely,\nparametric methods that model the function with neural estimators and obtain\ngradient signals via backpropagation may suffer from significant gradient\nerrors. A recent alternative, Explicit Gradient Learning (EGL), which directly\nlearns the gradient using a first-order Taylor approximation, has demonstrated\nsuperior performance over both parametric and non-parametric methods. In this\nwork, we propose two novel gradient learning variants to address the robustness\nchallenges posed by high-dimensional, complex, and highly non-linear problems.\nOptimistic Gradient Learning (OGL) introduces a bias toward lower regions in\nthe function landscape, while Higher-order Gradient Learning (HGL) incorporates\nsecond-order Taylor corrections to improve gradient accuracy. We combine these\napproaches into the unified OHGL algorithm, achieving state-of-the-art (SOTA)\nperformance on the synthetic COCO suite. Additionally, we demonstrate OHGLs\napplicability to high-dimensional real-world machine learning (ML) tasks such\nas adversarial training and code generation. Our results highlight OHGLs\nability to generate stronger candidates, offering a valuable tool for ML\nresearchers and practitioners tackling high-dimensional, non-linear\noptimization challenges",
      "tldr_zh": "本研究针对高维黑盒优化（Black-Box Optimization）问题，提出两种新梯度学习变体：Optimistic Gradient Learning (OGL)，通过引入偏向函数景观较低区域的偏差来提升鲁棒性；以及 Higher-order Gradient Learning (HGL)，利用二阶 Taylor 修正和 Hessian Corrections 来提高梯度准确性。作者将这两者整合成统一的 OHGL 算法，在合成 COCO 套件上实现 state-of-the-art (SOTA) 性能，并证明其在真实世界高维机器学习任务（如对抗训练和代码生成）中的有效性。总体结果表明，OHGL 能生成更强的优化候选方案，为处理高维非线性挑战提供了一个宝贵工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We develop a black-box optimization algorithm that learns gradients\n  with neural models and can be applied to solve non-convex high dimensional\n  real-world problems",
      "pdf_url": "http://arxiv.org/pdf/2502.04829v1",
      "published_date": "2025-02-07 11:03:50 UTC",
      "updated_date": "2025-02-07 11:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:33:43.539760"
    },
    {
      "arxiv_id": "2502.04794v2",
      "title": "MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin",
      "title_zh": "翻译失败",
      "authors": [
        "Minrui Chen",
        "Yi Zhou",
        "Huidong Jiang",
        "Yuhan Zhu",
        "Guanjie Zou",
        "Minqi Chen",
        "Rong Tian",
        "Hiroto Saigo"
      ],
      "abstract": "Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is\nintroduced as a multimodal framework inspired by real-world diagnostic\nprocesses. It uses pretrained models such as DINOv2, Vision Transformer, and\nResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into\nlow-dimensional, semantically meaningful features. A learnable\nself-attention-based fusion network then integrates these imaging features with\nclinical data for classification. Using 416 FUO patient cases from Sichuan\nUniversity West China Hospital from 2017 to 2023, the multimodal fusion\nclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to\n0.9291 across seven tasks, outperforming conventional machine learning and\nsingle-modality deep learning methods. Ablation studies and five-fold\ncross-validation further validated its effectiveness. By combining the\nstrengths of pretrained large models and deep learning, MedMimic offers a\npromising solution for disease classification.",
      "tldr_zh": "该研究提出 MedMimic 框架，受医师诊断过程启发，用于不明原因发热 (Fever of Unknown Origin, FUO) 的早期诊断。该框架利用预训练模型如 DINOv2、Vision Transformer 和 ResNet-18 将 18F-FDG PET/CT 图像转换为低维语义特征，并通过一个可学习的自注意力融合网络整合这些特征与临床数据进行分类。在使用四川大学华西医院 416 例 FUO 患者数据进行实验中，MedMimic 的多模态融合分类网络 (MFCN) 在七个任务上取得 macro-AUROC 分数为 0.8654 到 0.9291，优于传统机器学习和单模态深度学习方法，并经消融研究和五折交叉验证验证其有效性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04794v2",
      "published_date": "2025-02-07 09:57:03 UTC",
      "updated_date": "2025-02-14 01:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:33:55.273074"
    },
    {
      "arxiv_id": "2502.04790v2",
      "title": "S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Yuting Zeng",
        "Weizhe Huang",
        "Lei Jiang",
        "Tongxuan Liu",
        "Xitai Jin",
        "Chen Tianying Tiana",
        "Jing Li",
        "Xiaohua Xu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious natural language processing (NLP) scenarios, but they still face\nchallenges when handling complex arithmetic and logical reasoning tasks. While\nChain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correction\nstrategies have attempted to guide models in sequential, multi-step reasoning,\nMulti-agent Debate (MAD) has emerged as a viable approach for enhancing the\nreasoning capabilities of LLMs. By increasing both the number of agents and the\nfrequency of debates, the performance of LLMs improves significantly. However,\nthis strategy results in a significant increase in token costs, presenting a\nbarrier to scalability. To address this challenge, we introduce a novel\nsparsification strategy designed to reduce token costs within MAD. This\napproach minimizes ineffective exchanges of information and unproductive\ndiscussions among agents, thereby enhancing the overall efficiency of the\ndebate process. We conduct comparative experiments on multiple datasets across\nvarious models, demonstrating that our approach significantly reduces the token\ncosts in MAD to a considerable extent. Specifically, compared to MAD, our\napproach achieves an impressive reduction of up to 94.5\\% in token costs while\nmaintaining performance degradation below 2.0\\%.",
      "tldr_zh": "本论文针对大型语言模型(LLMs)在复杂算术和逻辑推理任务中的挑战，提出了S$^2$-MAD框架，以优化Multi-agent Debate (MAD)方法。\nS$^2$-MAD引入了一种sparsification策略，通过最小化无效信息交换和非生产性讨论，显著降低辩论过程中的token成本。\n实验在多个数据集和模型上验证，该方法相较于MAD，可减少高达94.5%的token成本，同时保持性能下降低于2.0%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2502.04790v2",
      "published_date": "2025-02-07 09:49:56 UTC",
      "updated_date": "2025-04-10 02:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:34:07.155896"
    },
    {
      "arxiv_id": "2502.04786v1",
      "title": "Enhancing SQL Injection Detection and Prevention Using Generative Models",
      "title_zh": "使用生成模型增强 SQL 注入检测和预防",
      "authors": [
        "Naga Sai Dasari",
        "Atta Badii",
        "Armin Moin",
        "Ahmed Ashlam"
      ],
      "abstract": "SQL Injection (SQLi) continues to pose a significant threat to the security\nof web applications, enabling attackers to manipulate databases and access\nsensitive information without authorisation. Although advancements have been\nmade in detection techniques, traditional signature-based methods still\nstruggle to identify sophisticated SQL injection attacks that evade predefined\npatterns. As SQLi attacks evolve, the need for more adaptive detection systems\nbecomes crucial. This paper introduces an innovative approach that leverages\ngenerative models to enhance SQLi detection and prevention mechanisms. By\nincorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN with\nGradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated to\naugment training datasets for machine learning models. The proposed method\ndemonstrated improved accuracy in SQLi detection systems by reducing both false\npositives and false negatives. Extensive empirical testing further illustrated\nthe ability of the system to adapt to evolving SQLi attack patterns, resulting\nin enhanced precision and robustness.",
      "tldr_zh": "本文针对 SQL Injection (SQLi) 攻击的持续威胁，提出了一种创新方法，使用生成模型来提升检测和预防机制。方法包括利用 Variational Autoencoders (VAE)、Conditional Wasserstein GAN with Gradient Penalty (CWGAN-GP) 和 U-Net 生成合成 SQL 查询，以扩充训练数据集，从而提高机器学习模型的准确性。实验结果显示，该系统减少了假阳性和假阴性，并增强了对演变攻击模式的适应性，实现更高的精确度和鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 22 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2502.04786v1",
      "published_date": "2025-02-07 09:43:43 UTC",
      "updated_date": "2025-02-07 09:43:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:34:19.085866"
    },
    {
      "arxiv_id": "2503.04750v1",
      "title": "Position: AI agents should be regulated based on autonomous action sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Takauki Osogami"
      ],
      "abstract": "This position paper argues that AI agents should be regulated based on the\nsequence of actions they autonomously take. AI agents with long-term planning\nand strategic capabilities can pose significant risks of human extinction and\nirreversible global catastrophes. While existing regulations often focus on\ncomputational scale as a proxy for potential harm, we contend that such\nmeasures are insufficient for assessing the risks posed by AI agents whose\ncapabilities arise primarily from inference-time computation. To support our\nposition, we discuss relevant regulations and recommendations from AI\nscientists regarding existential risks, as well as the advantages of action\nsequences over existing impact measures that require observing environmental\nstates.",
      "tldr_zh": "这篇立场论文主张，AI代理应基于其自主行动序列（autonomous action sequences）进行监管，以应对具有长期规划（long-term planning）和战略能力（strategic capabilities）的AI代理可能带来的人类灭绝（existential risks）和不可逆转全球灾难风险。论文批评现有监管措施过度依赖计算规模作为风险代理指标，认为这无法有效评估主要通过推理时计算（inference-time computation）产生能力的AI代理。作者讨论了AI科学家的相关建议，并强调行动序列比传统环境状态观察方法更具优势，能更准确地识别和缓解潜在威胁。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "29 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.04750v1",
      "published_date": "2025-02-07 09:40:48 UTC",
      "updated_date": "2025-02-07 09:40:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:34:30.606521"
    },
    {
      "arxiv_id": "2502.04780v1",
      "title": "SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning",
      "title_zh": "SiriuS：通过自举式推理的自我改进多智能体系统",
      "authors": [
        "Wanjia Zhao",
        "Mert Yuksekgonul",
        "Shirley Wu",
        "James Zou"
      ],
      "abstract": "Multi-agent AI systems powered by large language models (LLMs) are\nincreasingly applied to solve complex tasks. However, these systems often rely\non fragile, manually designed prompts and heuristics, making optimization\ndifficult. A key challenge in optimizing multi-agent systems is acquiring\nsuitable training data for specialized agents. We introduce SiriuS, a\nself-improving, reasoning-driven optimization framework for multi-agent\nsystems. Central to our approach is the construction of an experience library:\na repository of high-quality reasoning trajectories. The library is built by\nretaining reasoning steps that lead to successful outcomes, providing a robust\ntraining set for optimizing multi-agent system. Additionally, we introduce a\nlibrary augmentation procedure that refines unsuccessful trajectories, further\nenriching the library. SiriuS boosts performance by 2.86\\% to 21.88\\% on\nreasoning and biomedical QA and enhances agent negotiation in competitive\nsettings. Our results show that SiriuS enhances multi-agent performance while\ngenerating reusable data for self-correction and self-play enhancement in the\nfuture.",
      "tldr_zh": "该研究提出 SiriuS，一种基于 bootstrapped reasoning 的自提升多智能体系统优化框架，旨在解决多智能体 AI 系统依赖手动提示和启发式导致的优化难题。核心方法包括构建一个经验库（experience library），通过保留成功推理轨迹并引入库增强程序来改进不成功轨迹，从而提供高质量训练数据。实验结果显示，SiriuS 在推理和生物医学 QA 任务上提升性能 2.86% 到 21.88%，并增强了代理在竞争环境中的谈判能力，为未来的自校正和自玩增强生成可重用数据。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04780v1",
      "published_date": "2025-02-07 09:33:44 UTC",
      "updated_date": "2025-02-07 09:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:34:42.992751"
    },
    {
      "arxiv_id": "2502.04778v1",
      "title": "Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Xiao Gao",
        "Chenyang Wu",
        "Mingjun Cao",
        "Chenjun Xiao",
        "Yang Yu",
        "Zongzhang Zhang"
      ],
      "abstract": "The primary focus of offline reinforcement learning (RL) is to manage the\nrisk of hazardous exploitation of out-of-distribution actions. An effective\napproach to achieve this goal is through behavior regularization, which\naugments conventional RL objectives by incorporating constraints that enforce\nthe policy to remain close to the behavior policy. Nevertheless, existing\nliterature on behavior-regularized RL primarily focuses on explicit policy\nparameterizations, such as Gaussian policies. Consequently, it remains unclear\nhow to extend this framework to more advanced policy parameterizations, such as\ndiffusion models. In this paper, we introduce BDPO, a principled\nbehavior-regularized RL framework tailored for diffusion-based policies,\nthereby combining the expressive power of diffusion policies and the robustness\nprovided by regularization. The key ingredient of our method is to calculate\nthe Kullback-Leibler (KL) regularization analytically as the accumulated\ndiscrepancies in reverse-time transition kernels along the diffusion\ntrajectory. By integrating the regularization, we develop an efficient\ntwo-time-scale actor-critic RL algorithm that produces the optimal policy while\nrespecting the behavior constraint. Comprehensive evaluations conducted on\nsynthetic 2D tasks and continuous control tasks from the D4RL benchmark\nvalidate its effectiveness and superior performance.",
      "tldr_zh": "这篇论文针对离线强化学习（Offline Reinforcement Learning）中分布外动作的风险，提出了一种行为正则化（Behavior-Regularized）框架 BDPO，专门适用于扩散模型策略，以结合扩散策略的表达能力和正则化的鲁棒性。关键创新在于通过分析计算 Kullback-Leibler (KL) 正则化，作为扩散轨迹中逆时间转移核的累积差异，并开发了一个高效的两时间尺度 actor-critic 算法来优化策略。实验在合成 2D 任务和 D4RL 基准上的连续控制任务中证明了 BDPO 的有效性和优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2502.04778v1",
      "published_date": "2025-02-07 09:30:35 UTC",
      "updated_date": "2025-02-07 09:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:34:55.229619"
    },
    {
      "arxiv_id": "2502.07027v1",
      "title": "Representational Alignment with Chemical Induced Fit for Molecular Relational Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Peiliang Zhang",
        "Jingling Yuan",
        "Qing Xie",
        "Yongjun Zhu",
        "Lin Li"
      ],
      "abstract": "Molecular Relational Learning (MRL) is widely applied in natural sciences to\npredict relationships between molecular pairs by extracting structural\nfeatures. The representational similarity between substructure pairs determines\nthe functional compatibility of molecular binding sites. Nevertheless, aligning\nsubstructure representations by attention mechanisms lacks guidance from\nchemical knowledge, resulting in unstable model performance in chemical space\n(\\textit{e.g.}, functional group, scaffold) shifted data. With theoretical\njustification, we propose the \\textbf{Re}presentational \\textbf{Align}ment with\nChemical Induced \\textbf{Fit} (ReAlignFit) to enhance the stability of MRL.\nReAlignFit dynamically aligns substructure representation in MRL by introducing\nchemical Induced Fit-based inductive bias. In the induction process, we design\nthe Bias Correction Function based on substructure edge reconstruction to align\nrepresentations between substructure pairs by simulating chemical\nconformational changes (dynamic combination of substructures). ReAlignFit\nfurther integrates the Subgraph Information Bottleneck during fit process to\nrefine and optimize substructure pairs exhibiting high chemical functional\ncompatibility, leveraging them to generate molecular embeddings. Experimental\nresults on nine datasets demonstrate that ReAlignFit outperforms\nstate-of-the-art models in two tasks and significantly enhances model's\nstability in both rule-shifted and scaffold-shifted data distributions.",
      "tldr_zh": "这篇论文针对分子关系学习 (MRL) 中子结构表示对齐缺乏化学知识指导的问题，提出 ReAlignFit 方法，通过引入 Chemical Induced Fit 的归纳偏差来提升模型在化学空间（如功能基团和支架）转移数据中的稳定性。ReAlignFit 设计了基于子结构边重建的 Bias Correction Function，以模拟化学构象变化动态对齐子结构对的表示，并整合 Subgraph Information Bottleneck 来优化高化学功能兼容性的子结构对，从而生成更精确的分子嵌入。实验在九个数据集上证明，ReAlignFit 在两个任务上优于最先进模型，并在规则转移和支架转移数据分布中显著提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.07027v1",
      "published_date": "2025-02-07 09:29:21 UTC",
      "updated_date": "2025-02-07 09:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:35:09.690828"
    },
    {
      "arxiv_id": "2502.04771v1",
      "title": "DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences",
      "title_zh": "DMPA：针对模型差异的去中心化联邦学习模型投毒攻击",
      "authors": [
        "Chao Feng",
        "Yunlong Li",
        "Yuanzhe Gao",
        "Alberto Huertas Celdrán",
        "Jan von der Assen",
        "Gérôme Bovet",
        "Burkhard Stiller"
      ],
      "abstract": "Federated learning (FL) has garnered significant attention as a prominent\nprivacy-preserving Machine Learning (ML) paradigm. Decentralized FL (DFL)\neschews traditional FL's centralized server architecture, enhancing the\nsystem's robustness and scalability. However, these advantages of DFL also\ncreate new vulnerabilities for malicious participants to execute adversarial\nattacks, especially model poisoning attacks. In model poisoning attacks,\nmalicious participants aim to diminish the performance of benign models by\ncreating and disseminating the compromised model. Existing research on model\npoisoning attacks has predominantly concentrated on undermining global models\nwithin the Centralized FL (CFL) paradigm, while there needs to be more research\nin DFL. To fill the research gap, this paper proposes an innovative model\npoisoning attack called DMPA. This attack calculates the differential\ncharacteristics of multiple malicious client models and obtains the most\neffective poisoning strategy, thereby orchestrating a collusive attack by\nmultiple participants. The effectiveness of this attack is validated across\nmultiple datasets, with results indicating that the DMPA approach consistently\nsurpasses existing state-of-the-art FL model poisoning attack strategies.",
      "tldr_zh": "本研究针对Decentralized Federated Learning (DFL)中的安全漏洞，提出了一种创新的模型投毒攻击方法DMPA，以利用多个恶意参与者的模型差异。该方法通过计算恶意客户端模型的差异特性，制定最有效的投毒策略，实现协同攻击，从而削弱良性模型的性能。与现有Federated Learning (FL)攻击策略相比，DMPA在多个数据集上表现出色，攻击效果显著优于最先进的方法。研究填补了DFL领域模型投毒攻击的空白，为提升FL系统的安全性提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04771v1",
      "published_date": "2025-02-07 09:15:38 UTC",
      "updated_date": "2025-02-07 09:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:35:19.615741"
    },
    {
      "arxiv_id": "2502.04760v2",
      "title": "Graph Federated Learning Based Proactive Content Caching in Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Wang"
      ],
      "abstract": "With the rapid growth of mobile data traffic and the increasing prevalence of\nvideo streaming, proactive content caching in edge computing has become crucial\nfor reducing latency and alleviating network congestion. However, traditional\ncaching strategies such as FIFO, LRU, and LFU fail to effectively predict\nfuture content popularity, while existing proactive caching approaches often\nrequire users to upload data to a central server, raising concerns regarding\nprivacy and scalability. To address these challenges, this paper proposes a\nGraph Federated Learning-based Proactive Content Caching (GFPCC) scheme that\nenhances caching efficiency while preserving user privacy. The proposed\napproach integrates federated learning and graph neural networks, enabling\nusers to locally train Light Graph Convolutional Networks (LightGCN) to capture\nuser-item relationships and predict content popularity. Instead of sharing raw\ndata, only the trained model parameters are transmitted to the central server,\nwhere a federated averaging algorithm aggregates updates, refines the global\nmodel, and selects the most popular files for proactive caching. Experimental\nevaluations on real-world datasets, such as MovieLens, demonstrate that GFPCC\noutperforms baseline caching algorithms by achieving higher cache efficiency\nthrough more accurate content popularity predictions. Moreover, the federated\nlearning framework strengthens privacy protection while maintaining efficient\nmodel training; however, scalability remains a challenge in large-scale\nnetworks with dynamic user preferences.",
      "tldr_zh": "这篇论文提出了一种基于 Graph Federated Learning 的主动内容缓存方案（GFPCC），旨在解决边缘计算中内容流行度预测的准确性问题，同时保护用户隐私和提升可扩展性。该方案整合联邦学习和图神经网络，用户在本地训练 Light Graph Convolutional Networks (LightGCN) 来捕捉用户-物品关系并预测内容流行度，仅共享模型参数，由中央服务器使用 Federated Averaging 算法聚合更新并选择热门文件进行缓存。实验在 MovieLens 等真实数据集上表明，GFPCC 比传统算法如 FIFO 和 LRU 提高了缓存效率，但在大规模动态网络中可扩展性仍面临挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04760v2",
      "published_date": "2025-02-07 08:48:06 UTC",
      "updated_date": "2025-04-08 12:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:35:33.335721"
    },
    {
      "arxiv_id": "2502.04759v1",
      "title": "Enhancing Phishing Email Identification with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Catherine Lee"
      ],
      "abstract": "Phishing has long been a common tactic used by cybercriminals and continues\nto pose a significant threat in today's digital world. When phishing attacks\nbecome more advanced and sophisticated, there is an increasing need for\neffective methods to detect and prevent them. To address the challenging\nproblem of detecting phishing emails, researchers have developed numerous\nsolutions, in particular those based on machine learning (ML) algorithms. In\nthis work, we take steps to study the efficacy of large language models (LLMs)\nin detecting phishing emails. The experiments show that the LLM achieves a high\naccuracy rate at high precision; importantly, it also provides interpretable\nevidence for the decisions.",
      "tldr_zh": "本文研究了如何利用大型语言模型 (LLMs) 来提升钓鱼邮件 (phishing emails) 的识别效果，以应对日益复杂的网络攻击。研究通过实验评估了 LLMs 在检测任务中的表现，结果显示它在高精确度下实现了高准确率，并能提供可解释的决策证据。与传统机器学习 (ML) 算法相比，这种方法为更有效的钓鱼邮件防范提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04759v1",
      "published_date": "2025-02-07 08:45:50 UTC",
      "updated_date": "2025-02-07 08:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:35:43.739518"
    },
    {
      "arxiv_id": "2502.06849v1",
      "title": "Model Fusion via Neuron Transplantation",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammed Öz",
        "Nicholas Kiefer",
        "Charlotte Debus",
        "Jasmin Hörter",
        "Achim Streit",
        "Markus Götz"
      ],
      "abstract": "Ensemble learning is a widespread technique to improve the prediction\nperformance of neural networks. However, it comes at the price of increased\nmemory and inference time. In this work we propose a novel model fusion\ntechnique called \\emph{Neuron Transplantation (NT)} in which we fuse an\nensemble of models by transplanting important neurons from all ensemble members\ninto the vacant space obtained by pruning insignificant neurons. An initial\nloss in performance post-transplantation can be quickly recovered via\nfine-tuning, consistently outperforming individual ensemble members of the same\nmodel capacity and architecture. Furthermore, NT enables all the ensemble\nmembers to be jointly pruned and jointly trained in a combined model. Comparing\nit to alignment-based averaging (like Optimal-Transport-fusion), it requires\nless fine-tuning than the corresponding OT-fused model, the fusion itself is\nfaster and requires less memory, while the resulting model performance is\ncomparable or better. The code is available under the following link:\nhttps://github.com/masterbaer/neuron-transplantation.",
      "tldr_zh": "该论文提出了一种名为 Neuron Transplantation (NT) 的新型模型融合技术，用于整合神经网络集合，以提升预测性能，同时减少内存和推理时间。NT 方法通过修剪不重要神经元后，将重要神经元从各个模型成员移植到空位中，并通过微调快速恢复并超越单个模型的性能。与基于对齐的平均方法如 Optimal-Transport-fusion 相比，NT 需要更少的微调时间，融合过程更快且内存占用更低，且最终模型性能相当或更好。该技术还支持所有模型成员在组合模型中联合修剪和训练，为高效的集成学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures, conference: ECML-PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.06849v1",
      "published_date": "2025-02-07 08:45:38 UTC",
      "updated_date": "2025-02-07 08:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:35:56.458833"
    },
    {
      "arxiv_id": "2502.04756v2",
      "title": "Concept Navigation and Classification via Open-Source Large Language Model Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Maël Kubli"
      ],
      "abstract": "This paper presents a novel methodological framework for detecting and\nclassifying latent constructs, including frames, narratives, and topics, from\ntextual data using Open-Source Large Language Models (LLMs). The proposed\nhybrid approach combines automated summarization with human-in-the-loop\nvalidation to enhance the accuracy and interpretability of construct\nidentification. By employing iterative sampling coupled with expert refinement,\nthe framework guarantees methodological robustness and ensures conceptual\nprecision. Applied to diverse data sets, including AI policy debates, newspaper\narticles on encryption, and the 20 Newsgroups data set, this approach\ndemonstrates its versatility in systematically analyzing complex political\ndiscourses, media framing, and topic classification tasks.",
      "tldr_zh": "本论文提出了一种新颖的方法框架，利用 Open-Source Large Language Models (LLMs) 从文本数据中检测和分类潜在结构，包括 frames、narratives 和 topics。该框架采用混合方法，结合自动摘要和 human-in-the-loop validation，通过迭代采样与专家精炼，确保识别过程的准确性和可解释性。在应用于 AI 政策辩论、报纸加密文章以及 20 Newsgroups 数据集等多样化数据集时，该方法展示了其在分析复杂政治话语、媒体 framing 和主题分类方面的多功能性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "36 pages, 1 figure, 5 tabels",
      "pdf_url": "http://arxiv.org/pdf/2502.04756v2",
      "published_date": "2025-02-07 08:42:34 UTC",
      "updated_date": "2025-03-31 14:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:36:08.769144"
    },
    {
      "arxiv_id": "2502.05237v1",
      "title": "PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuopan Yang",
        "Yuanzhen Xie",
        "Ruichao Zhong",
        "Yunzhi Tan",
        "Enjie Liu",
        "Zhenguo Yang",
        "Mochi Gao",
        "Bo Hu",
        "Zang Li"
      ],
      "abstract": "It is challenging to convert natural language (NL) questions into executable\nstructured query language (SQL) queries for text-to-SQL tasks due to the vast\nnumber of database schemas with redundancy, which interferes with semantic\nlearning, and the domain shift between NL and SQL. Existing works for schema\nlinking focus on the table level and perform it once, ignoring the\nmulti-granularity semantics and chainable cyclicity of schemas. In this paper,\nwe propose a progressive schema linking with multi-granularity semantics\n(PSM-SQL) framework to reduce the redundant database schemas for text-to-SQL.\nUsing the multi-granularity schema linking (MSL) module, PSM-SQL learns the\nschema semantics at the column, table, and database levels. More specifically,\na triplet loss is used at the column level to learn embeddings, while\nfine-tuning LLMs is employed at the database level for schema reasoning. MSL\nemploys classifier and similarity scores to model schema interactions for\nschema linking at the table level. In particular, PSM-SQL adopts a chain loop\nstrategy to reduce the task difficulty of schema linking by continuously\nreducing the number of redundant schemas. Experiments conducted on text-to-SQL\ndatasets show that the proposed PSM-SQL is 1-3 percentage points higher than\nthe existing methods.",
      "tldr_zh": "这篇论文提出 PSM-SQL 框架，用于解决 Text-to-SQL 任务中数据库模式的冗余问题和 NL 与 SQL 之间的领域差异挑战。PSM-SQL 通过多粒度模式链接 (MSL) 模块在列级别使用三元组损失学习嵌入、在表级别通过分类器和相似性分数建模交互、在数据库级别微调 LLMs 进行推理，并采用链式循环策略逐步减少冗余模式以降低任务难度。实验在 Text-to-SQL 数据集上显示，该框架比现有方法提高了 1-3 个百分点。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "9 pages, 3 figures, submission in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.05237v1",
      "published_date": "2025-02-07 08:31:57 UTC",
      "updated_date": "2025-02-07 08:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:36:22.262122"
    },
    {
      "arxiv_id": "2502.04747v1",
      "title": "Every Software as an Agent: Blueprint and Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Mengwei Xu"
      ],
      "abstract": "The rise of (multimodal) large language models (LLMs) has shed light on\nsoftware agent -- where software can understand and follow user instructions in\nnatural language. However, existing approaches such as API-based and GUI-based\nagents are far from satisfactory at accuracy and efficiency aspects. Instead,\nwe advocate to endow LLMs with access to the software internals (source code\nand runtime context) and the permission to dynamically inject generated code\ninto software for execution. In such a whitebox setting, one may better\nleverage the software context and the coding ability of LLMs. We then present\nan overall design architecture and case studies on two popular web-based\ndesktop applications. We also give in-depth discussion of the challenges and\nfuture directions. We deem that such a new paradigm has the potential to\nfundamentally overturn the existing software agent design, and finally creating\na digital world in which software can comprehend, operate, collaborate, and\neven think to meet complex user needs.",
      "tldr_zh": "该论文提出了一种新范式，将大型语言模型（LLMs）转变为软件代理，通过赋予 LLMs 访问软件内部（如源代码和运行时上下文）的权限，并允许动态注入生成的代码进行执行，从而提升代理的准确性和效率。相比现有的 API-based 和 GUI-based agents，这种 whitebox 设置更能利用软件上下文和 LLMs 的编码能力。作者呈现了整体设计架构，并在两个流行的基于网络的桌面应用程序上进行了案例研究，同时讨论了潜在挑战和未来方向。这种方法有望彻底颠覆传统软件代理设计，最终实现一个数字世界，其中软件能理解、操作、协作甚至思考，以满足复杂用户需求。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04747v1",
      "published_date": "2025-02-07 08:29:09 UTC",
      "updated_date": "2025-02-07 08:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:36:33.590292"
    },
    {
      "arxiv_id": "2502.06848v1",
      "title": "Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation",
      "title_zh": "可扩展图神经网络中的迁移学习用于改进物理模拟",
      "authors": [
        "Siqi Shen",
        "Yu Liu",
        "Daniel Biggs",
        "Omar Hafez",
        "Jiandong Yu",
        "Wentao Zhang",
        "Bin Cui",
        "Jiulong Shan"
      ],
      "abstract": "In recent years, Graph Neural Network (GNN) based models have shown promising\nresults in simulating physics of complex systems. However, training dedicated\ngraph network based physics simulators can be costly, as most models are\nconfined to fully supervised training, which requires extensive data generated\nfrom traditional physics simulators. To date, how transfer learning could\nimprove the model performance and training efficiency has remained unexplored.\nIn this work, we introduce a pre-training and transfer learning paradigm for\ngraph network simulators. We propose the scalable graph U-net (SGUNET).\nIncorporating an innovative depth-first search (DFS) pooling, the SGUNET is\nadaptable to different mesh sizes and resolutions for various simulation tasks.\nTo enable the transfer learning between differently configured SGUNETs, we\npropose a set of mapping functions to align the parameters between the\npre-trained model and the target model. An extra normalization term is also\nadded into the loss to constrain the difference between the pre-trained weights\nand target model weights for better generalization performance. To pre-train\nour physics simulator we created a dataset which includes 20,000 physical\nsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)\ndataset. We show that our proposed transfer learning methods allow the model to\nperform even better when fine-tuned with small amounts of training data than\nwhen it is trained from scratch with full extensive dataset. On the 2D\nDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 of\nthe training data achieved an 11.05\\% improvement in position RMSE compared to\nthe model trained from scratch.",
      "tldr_zh": "该论文探讨了迁移学习在可扩展 Graph Neural Network (GNN) 中的应用，以提高物理模拟的性能和训练效率。作者提出了 Scalable Graph U-net (SGUNET)，它通过 Depth-First Search (DFS) pooling 适应不同网格大小和分辨率，并设计了映射函数和额外归一化损失来对齐预训练模型与目标模型的参数，从而增强泛化能力。为此，他们创建了一个包含 20,000 个 3D 形状模拟的数据集。实验结果显示，在 2D Deformable Plate 数据集上，预训练模型仅使用 1/16 数据微调，便比从零训练的模型提高了 11.05% 的位置 RMSE。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06848v1",
      "published_date": "2025-02-07 08:18:23 UTC",
      "updated_date": "2025-02-07 08:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:36:46.570866"
    },
    {
      "arxiv_id": "2502.04728v2",
      "title": "Generating Symbolic World Models via Test-time Scaling of Large Language Models",
      "title_zh": "通过测试时缩放大语言模型生成符号化",
      "authors": [
        "Zhouliang Yu",
        "Yuhuan Yuan",
        "Tim Z. Xiao",
        "Fuxiang Frank Xia",
        "Jie Fu",
        "Ge Zhang",
        "Ge Lin",
        "Weiyang Liu"
      ],
      "abstract": "Solving complex planning problems requires Large Language Models (LLMs) to\nexplicitly model the state transition to avoid rule violations, comply with\nconstraints, and ensure optimality-a task hindered by the inherent ambiguity of\nnatural language. To overcome such ambiguity, Planning Domain Definition\nLanguage (PDDL) is leveraged as a planning abstraction that enables precise and\nformal state descriptions. With PDDL, we can generate a symbolic world model\nwhere classic searching algorithms, such as A*, can be seamlessly applied to\nfind optimal plans. However, directly generating PDDL domains with current LLMs\nremains an open challenge due to the lack of PDDL training data. To address\nthis challenge, we propose to scale up the test-time computation of LLMs to\nenhance their PDDL reasoning capabilities, thereby enabling the generation of\nhigh-quality PDDL domains. Specifically, we introduce a simple yet effective\nalgorithm, which first employs a Best-of-N sampling approach to improve the\nquality of the initial solution and then refines the solution in a fine-grained\nmanner with verbalized machine learning. Our method outperforms o1-mini by a\nconsiderable margin in the generation of PDDL domains, achieving over 50\\%\nsuccess rate on two tasks (i.e., generating PDDL domains from natural language\ndescription or PDDL problems). This is done without requiring additional\ntraining. By taking advantage of PDDL as state abstraction, our method is able\nto outperform current state-of-the-art methods on almost all competition-level\nplanning tasks.",
      "tldr_zh": "这篇论文提出了一种通过测试时扩展大型语言模型 (LLMs) 的方法，来生成符号世界模型，以解决复杂规划问题中的状态转换模糊性问题。具体而言，该方法利用 Planning Domain Definition Language (PDDL) 作为精确的状态抽象，并引入 Best-of-N 采样和 verbalized machine learning 算法来提升初始解决方案的质量并进行细粒度精炼。实验结果显示，该方法无需额外训练，即可在生成 PDDL 领域任务上实现超过 50% 的成功率，并大幅优于 o1-mini 和现有方法，在几乎所有竞争级规划任务中表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by TMLR2025 (32 pages, 6 figures)",
      "pdf_url": "http://arxiv.org/pdf/2502.04728v2",
      "published_date": "2025-02-07 07:52:25 UTC",
      "updated_date": "2025-05-08 13:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:36:58.906574"
    },
    {
      "arxiv_id": "2502.04725v1",
      "title": "Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?",
      "title_zh": "扩散模型能否学习图像背后的隐藏特征间规则？",
      "authors": [
        "Yujin Han",
        "Andi Han",
        "Wei Huang",
        "Chaochao Lu",
        "Difan Zou"
      ],
      "abstract": "Despite the remarkable success of diffusion models (DMs) in data generation,\nthey exhibit specific failure cases with unsatisfactory outputs. We focus on\none such limitation: the ability of DMs to learn hidden rules between image\nfeatures. Specifically, for image data with dependent features ($\\mathbf{x}$)\nand ($\\mathbf{y}$) (e.g., the height of the sun ($\\mathbf{x}$) and the length\nof the shadow ($\\mathbf{y}$)), we investigate whether DMs can accurately\ncapture the inter-feature rule ($p(\\mathbf{y}|\\mathbf{x})$). Empirical\nevaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent\nfailures, such as inconsistent lighting-shadow relationships and mismatched\nobject-mirror reflections. Inspired by these findings, we design four synthetic\ntasks with strongly correlated features to assess DMs' rule-learning abilities.\nExtensive experiments show that while DMs can identify coarse-grained rules,\nthey struggle with fine-grained ones. Our theoretical analysis demonstrates\nthat DMs trained via denoising score matching (DSM) exhibit constant errors in\nlearning hidden rules, as the DSM objective is not compatible with rule\nconformity. To mitigate this, we introduce a common technique - incorporating\nadditional classifier guidance during sampling, which achieves (limited)\nimprovements. Our analysis reveals that the subtle signals of fine-grained\nrules are challenging for the classifier to capture, providing insights for\nfuture exploration.",
      "tldr_zh": "本研究探讨了扩散模型（DMs）是否能学习图像特征间的隐藏规则（如太阳高度与阴影长度间的依赖关系 p(y|x)）。通过对主流 DMs（如 Stable Diffusion 3.5）的经验评估和四个合成任务的实验，发现 DMs 能识别粗粒度规则，但难以捕捉细粒度规则，导致输出中出现不一致的光影关系或物体镜像反射。理论分析表明，基于去噪分数匹配（DSM）的训练目标与规则一致性不兼容，造成恒定错误；为此，引入分类器引导（classifier guidance）在采样过程中进行改进，虽有有限提升，但细粒度规则的微妙信号仍具挑战性，为未来 DMs 优化提供洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 18 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.04725v1",
      "published_date": "2025-02-07 07:49:37 UTC",
      "updated_date": "2025-02-07 07:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:37:09.413798"
    },
    {
      "arxiv_id": "2502.04700v3",
      "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Prakhar Kaushik",
        "Ankit Vaidya",
        "Shravan Chaudhari",
        "Alan Yuille"
      ],
      "abstract": "The rapid growth of large models has raised concerns about their\nenvironmental impact and equity in accessibility due to significant\ncomputational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for\nfinetuning large models, resulting in an abundance of publicly available\nadapters tailored to diverse domains. We ask: Can these pretrained adapters be\nleveraged to further streamline adaptation to new tasks while addressing these\nchallenges? We introduce EigenLoRAx, a parameter-efficient finetuning method\nthat recycles existing adapters to create a principal subspace aligned with\ntheir shared domain knowledge which can be further augmented with orthogonal\nbasis vectors in low-resource scenarios. This enables rapid adaptation to new\ntasks by learning only lightweight coefficients on the principal components of\nthe subspace - eliminating the need to finetune entire adapters. EigenLoRAx\nrequires significantly fewer parameters and memory, improving efficiency for\nboth training and inference. Our method demonstrates strong performance across\ndiverse domains and tasks, offering a scalable for edge-based applications,\npersonalization, and equitable deployment of large models in\nresource-constrained environments.",
      "tldr_zh": "该研究提出 EigenLoRAx，一种参数高效的微调方法，通过回收现有 Low-Rank Adapters (LoRA) 来创建与共享领域知识对齐的主体子空间，并在低资源场景下用正交基向量增强，从而实现快速适应新任务。EigenLoRAx 仅需学习主体子空间的主成分轻量系数，而非微调整个适配器，大大减少参数和内存需求，提升训练和推理效率。该方法在多样领域和任务上表现出色，提供可扩展性，支持边缘应用、个性化以及资源受限环境中的大型模型公平部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04700v3",
      "published_date": "2025-02-07 07:07:04 UTC",
      "updated_date": "2025-02-28 01:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:37:20.781880"
    },
    {
      "arxiv_id": "2502.04695v1",
      "title": "Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance",
      "title_zh": "翻译失败",
      "authors": [
        "Pratinav Seth",
        "Vinay Kumar Sankarapu"
      ],
      "abstract": "This position paper emphasizes the critical gap in the evaluation of\nExplainable AI (XAI) due to the lack of standardized and reliable metrics,\nwhich diminishes its practical value, trustworthiness, and ability to meet\nregulatory requirements. Current evaluation methods are often fragmented,\nsubjective, and biased, making them prone to manipulation and complicating the\nassessment of complex models. A central issue is the absence of a ground truth\nfor explanations, complicating comparisons across various XAI approaches. To\naddress these challenges, we advocate for widespread research into developing\nrobust, context-sensitive evaluation metrics. These metrics should be resistant\nto manipulation, relevant to each use case, and based on human judgment and\nreal-world applicability. We also recommend creating domain-specific evaluation\nbenchmarks that align with the user and regulatory needs of sectors such as\nhealthcare and finance. By encouraging collaboration among academia, industry,\nand regulators, we can create standards that balance flexibility and\nconsistency, ensuring XAI explanations are meaningful, trustworthy, and\ncompliant with evolving regulations.",
      "tldr_zh": "这篇立场论文（position paper）强调了 Explainable AI (XAI) 评估中的关键差距，即缺乏标准化和可靠的指标，导致其实际价值、可信度和合规性受损。当前评估方法往往碎片化、主观且易受偏见影响，且由于缺少 explanations 的 ground truth，难以比较不同 XAI 方法。论文主张开展广泛研究，开发抗操纵的、上下文敏感的评估指标，并创建与医疗和金融等领域的用户需求相符的领域特定基准，通过学术界、行业和监管者的合作，建立灵活一致的标准，以确保 XAI 解释更具意义和合规性。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04695v1",
      "published_date": "2025-02-07 06:54:48 UTC",
      "updated_date": "2025-02-07 06:54:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:37:33.987700"
    },
    {
      "arxiv_id": "2502.05236v1",
      "title": "Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Shehzeen Hussain",
        "Paarth Neekhara",
        "Xuesong Yang",
        "Edresson Casanova",
        "Subhankar Ghosh",
        "Mikyas T. Desta",
        "Roy Fejgin",
        "Rafael Valle",
        "Jason Li"
      ],
      "abstract": "While autoregressive speech token generation models produce speech with\nremarkable variety and naturalness, their inherent lack of controllability\noften results in issues such as hallucinations and undesired vocalizations that\ndo not conform to conditioning inputs. We introduce Koel-TTS, a suite of\nenhanced encoder-decoder Transformer TTS models that address these challenges\nby incorporating preference alignment techniques guided by automatic speech\nrecognition and speaker verification models. Additionally, we incorporate\nclassifier-free guidance to further improve synthesis adherence to the\ntranscript and reference speaker audio. Our experiments demonstrate that these\noptimizations significantly enhance target speaker similarity, intelligibility,\nand naturalness of synthesized speech. Notably, Koel-TTS directly maps text and\ncontext audio to acoustic tokens, and on the aforementioned metrics,\noutperforms state-of-the-art TTS models, despite being trained on a\nsignificantly smaller dataset. Audio samples and demos are available on our\nwebsite.",
      "tldr_zh": "本论文提出 Koel-TTS，一套增强的编码器-解码器 Transformer TTS 模型，通过偏好对齐（preference alignment）技术和分类器免费指导（classifier-free guidance）来解决自回归语音生成模型的可控性问题，例如幻觉和不符合输入的语音输出。Koel-TTS 利用自动语音识别（ASR）和说话者验证（speaker verification）模型进行引导，直接将文本和上下文音频映射到声学标记。实验结果显示，该模型显著提升了合成语音的目标说话者相似度、可懂度和自然性，并在这些指标上超越了最先进 TTS 模型，尽管训练数据规模更小。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05236v1",
      "published_date": "2025-02-07 06:47:11 UTC",
      "updated_date": "2025-02-07 06:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:37:47.196374"
    },
    {
      "arxiv_id": "2502.04689v3",
      "title": "ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Yin",
        "Giuseppe Carenini"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities on\ncomplex evaluation benchmarks, many of which are formulated as\nquestion-answering (QA) tasks. Enhancing the performance of LLMs in QA contexts\nis becoming increasingly vital for advancing their development and\napplicability. This paper introduces ARR, an intuitive, effective, and general\nQA solving method that explicitly incorporates three key steps: analyzing the\nintent of the question, retrieving relevant information, and reasoning step by\nstep. Notably, this paper is the first to introduce intent analysis in QA,\nwhich plays a vital role in ARR. Comprehensive evaluations across 10 diverse QA\ntasks demonstrate that ARR consistently outperforms the baseline methods.\nAblation and case studies further validate the positive contributions of each\nARR component. Furthermore, experiments involving variations in prompt design\nindicate that ARR maintains its effectiveness regardless of the specific prompt\nformulation. Additionally, extensive evaluations across various model sizes,\nLLM series, and generation settings solidify the effectiveness, robustness, and\ngeneralizability of ARR.",
      "tldr_zh": "本文提出ARR方法，用于提升Large Language Models (LLMs)在Question Answering (QA)任务中的性能，通过三个关键步骤：analyzing the intent（分析问题意图）、retrieving relevant information（检索相关信息）和step-by-step reasoning（逐步推理）。这是首次在QA中引入intent analysis，这一步在方法中发挥关键作用。实验结果显示，ARR在10个多样化QA任务上 consistently outperforms baseline methods，且ablation studies和case studies验证了每个组件的积极贡献。此外，ARR在不同模型大小、LLM系列和生成设置下表现出良好的robustness和generalizability。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages. Code: https://github.com/YuweiYin/ARR",
      "pdf_url": "http://arxiv.org/pdf/2502.04689v3",
      "published_date": "2025-02-07 06:30:33 UTC",
      "updated_date": "2025-05-15 17:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:37:58.016291"
    },
    {
      "arxiv_id": "2502.04688v1",
      "title": "M-IFEval: Multilingual Instruction-Following Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Dussolle",
        "Andrea Cardeña Díaz",
        "Shota Sato",
        "Peter Devine"
      ],
      "abstract": "Instruction following is a core capability of modern Large language models\n(LLMs), making evaluating this capability essential to understanding these\nmodels. The Instruction Following Evaluation (IFEval) benchmark from the\nliterature does this using objective criteria, offering a measure of LLM\nperformance without subjective AI or human judgement. However, it only includes\nEnglish instructions, limiting its ability to assess LLMs in other languages.\n  We propose the Multilingual Instruction Following Evaluation (M-IFEval)\nbenchmark, expanding the evaluation to French, Japanese, and Spanish, with both\ngeneral and language-specific instructions. Applying this benchmark to 8\nstate-of-the-art LLMs, we find that benchmark performance across languages and\ninstruction types can vary widely, underscoring the importance of a\nmultilingual benchmark for evaluating LLMs in a diverse cultural context.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）的指令跟随能力评估，提出 Multilingual Instruction-Following Evaluation (M-IFEval) 基准，以扩展现有 Instruction Following Evaluation (IFEval) 的局限性，仅限于英语。\nM-IFEval 将评估范围扩展到法语、日语和西班牙语，包括一般指令和语言特定指令，使用客观标准进行评估。\n实验在8个最先进LLMs上进行，结果显示模型性能在不同语言和指令类型间存在显著差异，突出了多语言基准在多样化文化语境中评估LLMs的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04688v1",
      "published_date": "2025-02-07 06:27:04 UTC",
      "updated_date": "2025-02-07 06:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:38:11.340074"
    },
    {
      "arxiv_id": "2502.04686v1",
      "title": "Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zelai Xu",
        "Wanjun Gu",
        "Chao Yu",
        "Yi Wu",
        "Yu Wang"
      ],
      "abstract": "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making.",
      "tldr_zh": "这篇论文提出了一种迭代框架 Latent Space Policy Optimization (LSPO)，用于训练在 Werewolf 游戏中的战略语言代理，解决传统 Counterfactual Regret Minimization (CFR) 或 reinforcement learning (RL) 方法在自由文本互动中的局限性，以及 Large Language Model (LLM) 代理的内在偏差问题。LSPO 通过将自由文本映射到离散潜在空间中学习策略，然后通过 Direct Preference Optimization (DPO) 微调 LLM，并迭代交替这些阶段，提升代理的策略推理和语言沟通能力。实验结果显示，该方法在 Werewolf 游戏中每次迭代都显著改善代理性能，并优于现有代理，展示了其在自由形式语言决策中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04686v1",
      "published_date": "2025-02-07 06:19:55 UTC",
      "updated_date": "2025-02-07 06:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:38:23.772181"
    },
    {
      "arxiv_id": "2502.04684v3",
      "title": "G2PDiffusion: Cross-Species Genotype-to-Phenotype Prediction via Evolutionary Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Mengdi Liu",
        "Zhangyang Gao",
        "Hong Chang",
        "Stan Z. Li",
        "Shiguang Shan",
        "Xilin Chen"
      ],
      "abstract": "Understanding how genes influence phenotype across species is a fundamental\nchallenge in genetic engineering, which will facilitate advances in various\nfields such as crop breeding, conservation biology, and personalized medicine.\nHowever, current phenotype prediction models are limited to individual species\nand expensive phenotype labeling process, making the genotype-to-phenotype\nprediction a highly domain-dependent and data-scarce problem. To this end, we\nsuggest taking images as morphological proxies, facilitating cross-species\ngeneralization through large-scale multimodal pretraining. We propose the first\ngenotype-to-phenotype diffusion model (G2PDiffusion) that generates\nmorphological images from DNA considering two critical evolutionary signals,\ni.e., multiple sequence alignments (MSA) and environmental contexts. The model\ncontains three novel components: 1) a MSA retrieval engine that identifies\nconserved and co-evolutionary patterns; 2) an environment-aware MSA conditional\nencoder that effectively models complex genotype-environment interactions; and\n3) an adaptive phenomic alignment module to improve genotype-phenotype\nconsistency. Extensive experiments show that integrating evolutionary signals\nwith environmental context enriches the model's understanding of phenotype\nvariability across species, thereby offering a valuable and promising\nexploration into advanced AI-assisted genomic analysis.",
      "tldr_zh": "该研究针对基因如何影响不同物种表型（Genotype-to-Phenotype）的挑战，提出了一种跨物种预测方法，以图像作为形态代理，通过大规模多模态预训练实现泛化。论文引入了 G2PDiffusion 模型，这是一个基于扩散技术的框架，从 DNA 生成形态图像，并整合了多序列比对（MSA）和环境上下文的关键组件，包括 MSA 检索引擎、环境感知 MSA 条件编码器以及自适应表型对齐模块。实验结果显示，这种整合进化信号和环境因素的方法显著提升了对表型变异的理解，为 AI 辅助基因组分析提供了有价值的创新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04684v3",
      "published_date": "2025-02-07 06:16:31 UTC",
      "updated_date": "2025-03-10 03:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:38:36.409882"
    },
    {
      "arxiv_id": "2502.04675v2",
      "title": "Scalable Oversight for Superhuman AI via Recursive Self-Critiquing",
      "title_zh": "通过递归自我批判实现超人类人工智能的可扩展监督",
      "authors": [
        "Xueru Wen",
        "Jie Lou",
        "Xinyu Lu",
        "Junjie Yang",
        "Yanjiang Liu",
        "Yaojie Lu",
        "Debing Zhang",
        "Xing Yu"
      ],
      "abstract": "As AI capabilities increasingly surpass human proficiency in complex tasks,\ncurrent alignment techniques including SFT and RLHF face fundamental challenges\nin ensuring reliable oversight. These methods rely on direct human assessment\nand become untenable when AI outputs exceed human cognitive thresholds. In\nresponse to this challenge, we explore two hypotheses: (1) critique of critique\ncan be easier than critique itself, extending the widely-accepted observation\nthat verification is easier than generation to the critique domain, as critique\nitself is a specialized form of generation; (2) this difficulty relationship is\nrecursively held, suggesting that when direct evaluation is infeasible,\nperforming high-order critiques (e.g., critique of critique of critique) offers\na more tractable supervision pathway. To examine these hypotheses, we perform\nHuman-Human, Human-AI, and AI-AI experiments across multiple tasks. Our results\ndemonstrate encouraging evidence supporting these hypotheses and suggest that\nrecursive self-critiquing is a promising direction for scalable oversight.",
      "tldr_zh": "随着AI能力超越人类，传统的对齐技术如SFT和RLHF依赖人类评估而面临挑战，因为AI输出可能超出人类认知门槛。本文提出两个假设：（1）对批评的批评（critique of critique）比直接批评更容易；（2）这种难度关系是递归的，因此通过高阶批评（如批评的批评的批评）可提供更可行的监督路径。为了验证这些假设，研究进行了Human-Human、Human-AI和AI-AI实验，结果支持了假设，并表明递归自我批评（Recursive Self-Critiquing）是实现可扩展AI监督的有前景方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04675v2",
      "published_date": "2025-02-07 05:41:23 UTC",
      "updated_date": "2025-03-20 02:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:38:47.806461"
    },
    {
      "arxiv_id": "2502.04674v2",
      "title": "AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Soichiro Murakami",
        "Peinan Zhang",
        "Hidetaka Kamigaito",
        "Hiroya Takamura",
        "Manabu Okumura"
      ],
      "abstract": "Effective linguistic choices that attract potential customers play crucial\nroles in advertising success. This study aims to explore the linguistic\nfeatures of ad texts that influence human preferences. Although the creation of\nattractive ad texts is an active area of research, progress in understanding\nthe specific linguistic features that affect attractiveness is hindered by\nseveral obstacles. First, human preferences are complex and influenced by\nmultiple factors, including their content, such as brand names, and their\nlinguistic styles, making analysis challenging. Second, publicly available ad\ntext datasets that include human preferences are lacking, such as ad\nperformance metrics and human feedback, which reflect people's interests. To\naddress these problems, we present AdParaphrase, a paraphrase dataset that\ncontains human preferences for pairs of ad texts that are semantically\nequivalent but differ in terms of wording and style. This dataset allows for\npreference analysis that focuses on the differences in linguistic features. Our\nanalysis revealed that ad texts preferred by human judges have higher fluency,\nlonger length, more nouns, and use of bracket symbols. Furthermore, we\ndemonstrate that an ad text-generation model that considers these findings\nsignificantly improves the attractiveness of a given text. The dataset is\npublicly available at: https://github.com/CyberAgentAILab/AdParaphrase.",
      "tldr_zh": "本研究探讨了广告文本中影响人类偏好的语言特征，旨在解决现有数据集缺乏人类反馈的问题。研究者构建了AdParaphrase数据集，该数据集包含语义等价但在措辞和风格上不同的广告文本对，并通过分析发现人类偏好的文本通常具有更高的流畅性、更长长度、更多的名词以及括号符号的使用。此外，基于这些发现开发的广告文本生成模型显著提高了文本的吸引力，该数据集已公开可用于进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.04674v2",
      "published_date": "2025-02-07 05:39:55 UTC",
      "updated_date": "2025-02-11 05:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:38:57.894830"
    },
    {
      "arxiv_id": "2502.04671v2",
      "title": "ProofWala: Multilingual Proof Data Synthesis and Theorem-Proving",
      "title_zh": "ProofWala：多语言证明数据合成与定理证明",
      "authors": [
        "Amitayush Thakur",
        "George Tsoukalas",
        "Greg Durrett",
        "Swarat Chaudhuri"
      ],
      "abstract": "Neural networks have shown substantial promise at automatic theorem-proving\nin interactive proof assistants (ITPs) like Lean and Coq. However, most neural\ntheorem-proving models are restricted to specific ITPs, leaving out\nopportunities for cross-lingual $\\textit{transfer}$ between ITPs. We address\nthis weakness with a multilingual proof framework, ${\\rm P{\\small ROOF}W{\\small\nALA}}$, that allows a standardized form of interaction between neural\ntheorem-provers and two established ITPs (Coq and Lean). It enables the\ncollection of multilingual proof step data -- data recording the result of\nproof actions on ITP states -- for training neural provers. ${\\rm P{\\small\nROOF}W{\\small ALA}}$ allows the systematic evaluation of a model's performance\nacross different ITPs and problem domains via efficient parallel proof search\nalgorithms. We show that multilingual training enabled by ${\\rm P{\\small\nROOF}W{\\small ALA}}$ can lead to successful transfer across ITPs. Specifically,\na model trained on a mix of ${\\rm P{\\small ROOF}W{\\small ALA}}$-generated Coq\nand Lean data outperforms Lean-only and Coq-only models on the standard\nprove-at-$k$ metric. We open source all code including code for the ${\\rm\nP{\\small ROOF}W{\\small ALA}}$ Framework\n(https://github.com/trishullab/proof-wala), and the Multilingual ITP\ninteraction framework (https://github.com/trishullab/itp-interface).",
      "tldr_zh": "本研究提出ProofWala框架，一种多语言证明数据合成系统，用于神经网络在交互式证明助手(ITPs)如Coq和Lean中的自动定理证明，解决现有模型在不同ITPs之间缺乏跨语言转移的问题。该框架支持标准化交互、收集多语言证明步骤数据，并通过高效的并行证明搜索算法评估模型在各种ITPs和问题域中的性能。实验结果显示，使用ProofWala生成的Coq和Lean混合数据训练的模型，在prove-at-k指标上优于单一ITPs训练的模型，实现成功转移；研究还开源了相关代码（https://github.com/trishullab/proof-wala）。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04671v2",
      "published_date": "2025-02-07 05:35:46 UTC",
      "updated_date": "2025-02-15 08:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:39:10.675550"
    },
    {
      "arxiv_id": "2502.04670v1",
      "title": "CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Song",
        "Zecheng Zhang",
        "Zhaoxu Luo",
        "Jason Hu",
        "Wei Yuan",
        "Jing Jia",
        "Zhengxu Tang",
        "Guanyang Wang",
        "Liyue Shen"
      ],
      "abstract": "Diffusion models have emerged as powerful tools for generative tasks,\nproducing high-quality outputs across diverse domains. However, how the\ngenerated data responds to the initial noise perturbation in diffusion models\nremains under-explored, which hinders understanding the controllability of the\nsampling process. In this work, we first observe an interesting phenomenon: the\nrelationship between the change of generation outputs and the scale of initial\nnoise perturbation is highly linear through the diffusion ODE sampling. Then we\nprovide both theoretical and empirical study to justify this linearity property\nof this input-output (noise-generation data) relationship. Inspired by these\nnew insights, we propose a novel Controllable and Constrained Sampling method\n(CCS) together with a new controller algorithm for diffusion models to sample\nwith desired statistical properties while preserving good sample quality. We\nperform extensive experiments to compare our proposed sampling approach with\nother methods on both sampling controllability and sampled data quality.\nResults show that our CCS method achieves more precisely controlled sampling\nwhile maintaining superior sample quality and diversity.",
      "tldr_zh": "该研究发现，Diffusion Models 中初始噪声扰动与生成输出变化之间存在高度线性关系，并通过理论和实证分析验证了这一属性。基于此，提出了一种新型采样方法 CCS（Controllable and Constrained Sampling），结合新控制器算法，实现对采样的可控性和约束，确保生成数据具有期望的统计属性，同时保持高质量输出。实验结果表明，CCS 在采样可控性上比其他方法更精确，且样本质量和多样性均有显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04670v1",
      "published_date": "2025-02-07 05:30:48 UTC",
      "updated_date": "2025-02-07 05:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:39:22.565672"
    },
    {
      "arxiv_id": "2502.04669v1",
      "title": "A Comprehensive Review on Noise Control of Diffusion Model",
      "title_zh": "扩散模型噪声控制的全面综述",
      "authors": [
        "Zhehao Guo",
        "Jiedong Lang",
        "Shuyu Huang",
        "Yunfei Gao",
        "Xintong Ding"
      ],
      "abstract": "Diffusion models have recently emerged as powerful generative frameworks for\nproducing high-quality images. A pivotal component of these models is the noise\nschedule, which governs the rate of noise injection during the diffusion\nprocess. Since the noise schedule substantially influences sampling quality and\ntraining quality, understanding its design and implications is crucial. In this\ndiscussion, various noise schedules are examined, and their distinguishing\nfeatures and performance characteristics are highlighted.",
      "tldr_zh": "这篇综述论文对diffusion models中noise schedule的设计和影响进行了全面回顾，强调了noise schedule在控制噪声注入速率方面对图像生成采样质量和训练质量的关键作用。论文考察了各种noise schedule的独特特征和性能表现，包括它们如何优化生成过程。总体而言，该研究为理解和改进diffusion models提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04669v1",
      "published_date": "2025-02-07 05:26:29 UTC",
      "updated_date": "2025-02-07 05:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:39:34.430479"
    },
    {
      "arxiv_id": "2502.06846v1",
      "title": "Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure",
      "title_zh": "翻译失败",
      "authors": [
        "Zhicong Wang",
        "Zicheng Ma",
        "Ziqiang Cao",
        "Changlong Zhou",
        "Jun Zhang",
        "Yiqin Gao"
      ],
      "abstract": "Proteins play a pivotal role in living organisms, yet understanding their\nfunctions presents significant challenges, including the limited flexibility of\nclassification-based methods, the inability to effectively leverage spatial\nstructural information, and the lack of systematic evaluation metrics for\nprotein Q&A systems. To address these limitations, we propose Prot2Chat, a\nnovel framework that integrates multimodal protein representations with natural\nlanguage through a unified module, enabling large language model (LLM)-driven\nanswer generation. Our model incorporates a modified ProteinMPNN encoder, which\nencodes protein sequence and structural information in a unified manner, a\nprotein-text adapter with cross-attention mechanisms, and a LLaMA3 decoder. To\noptimize training efficiency, we freeze the encoder and employ LoRA techniques\nfor the decoder. We conducted experiments on two datasets, both automated\nmetrics and expert evaluations demonstrate the superior performance of our\nmodel. Furthermore, zero-shot prediction results highlight its strong\ngeneralization capabilities. This framework offers a promising solution for\nbridging protein domain knowledge with natural language understanding, paving\nthe way for transformative advancements in protein-related research.",
      "tldr_zh": "这篇论文提出Prot2Chat框架，一种基于LLM的模型，通过早期融合蛋白质序列和结构信息，解决蛋白质功能理解中的灵活性不足、结构信息利用问题以及缺乏系统评价指标的挑战。框架核心包括修改后的ProteinMPNN编码器统一处理序列和结构数据、蛋白质-文本适配器使用跨注意力机制，以及LLaMA3解码器；为提升训练效率，论文冻结了编码器并采用LoRA技术。实验在两个数据集上显示，Prot2Chat在自动化指标和专家评估中表现优于基线模型，并展现出强大的零样本泛化能力。该框架为整合蛋白质领域知识与自然语言理解提供了创新路径，推动蛋白质相关研究的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06846v1",
      "published_date": "2025-02-07 05:23:16 UTC",
      "updated_date": "2025-02-07 05:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:39:48.415658"
    },
    {
      "arxiv_id": "2502.04667v2",
      "title": "Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization",
      "title_zh": "揭示显式 CoT 训练的机制：CoT 如何提升推理泛化",
      "authors": [
        "Xinhao Yao",
        "Ruifeng Ren",
        "Yun Liao",
        "Yong Liu"
      ],
      "abstract": "The integration of explicit Chain-of-Thought (CoT) reasoning into training\nlarge language models (LLMs) has advanced their reasoning capabilities, yet the\nmechanisms by which CoT enhances generalization remain poorly understood. This\nwork investigates (1) \\textit{how} CoT training reshapes internal model\nrepresentations and (2) \\textit{why} it improves both in-distribution (ID) and\nout-of-distribution (OOD) reasoning generalization. Through controlled\nexperiments and theoretical analysis, we derive the following key insights.\n\\textbf{1)} Structural Advantage: CoT training internalizes reasoning into a\ntwo-stage generalizing circuit, where the number of stages corresponds to the\nexplicit reasoning steps during training. Notably, CoT-trained models resolve\nintermediate results at shallower layers compared to non-CoT counterparts,\nfreeing up deeper layers to specialize in subsequent reasoning steps.\n\\textbf{2)} Theoretical Analysis: the information-theoretic generalization\nbounds via distributional divergence can be decomposed into ID and OOD\ncomponents. While ID error diminishes with sufficient training regardless of\nCoT, OOD error critically depends on CoT: Non-CoT training fails to generalize\nto OOD samples due to unseen reasoning patterns, whereas CoT training achieves\nnear-perfect OOD generalization by mastering subtasks and reasoning\ncompositions during training. The identified mechanisms explain our\nexperimental results: CoT training accelerates convergence and enhances\ngeneralization from ID to both ID and OOD scenarios while maintaining robust\nperformance even with tolerable noise. These findings are further validated on\ncomplex real-world datasets. This paper offers valuable insights for designing\nCoT strategies to enhance LLM reasoning robustness.",
      "tldr_zh": "这篇论文探讨了 Explicit Chain-of-Thought (CoT) 训练如何提升大型语言模型 (LLMs) 的推理泛化能力，重点分析 CoT 训练如何重塑模型内部表示以及为什么它能改善 in-distribution (ID) 和 out-of-distribution (OOD) 性能。通过控制实验和理论分析，研究发现 CoT 训练构建了一个两阶段泛化电路，使模型在较浅层解决中间结果，从而让深层专注于后续推理，并通过掌握子任务和推理组合实现近乎完美的 OOD 泛化。实验结果显示，CoT 训练加速收敛、增强泛化鲁棒性，即使在噪声环境下也保持性能，并在复杂真实世界数据集上得到验证，为设计更有效的 CoT 策略提供宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04667v2",
      "published_date": "2025-02-07 05:21:13 UTC",
      "updated_date": "2025-05-05 09:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:40:01.686171"
    },
    {
      "arxiv_id": "2502.04658v2",
      "title": "Shifting Attention to You: Personalized Brain-Inspired AI Models",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Chong Zhao",
        "Yang Hu",
        "Jason Lee",
        "Andrew Bender",
        "Trisha Mazumdar",
        "Mark Wallace",
        "David A. Tovar"
      ],
      "abstract": "The integration of human and artificial intelligence offers a powerful avenue\nfor advancing our understanding of information processing, as each system\nprovides unique computational insights. However, despite the promise of\nhuman-AI integration, current AI models are largely trained on massive\ndatasets, optimized for population-level performance, lacking mechanisms to\nalign their computations with individual users' perceptual semantics and neural\ndynamics. Here we show that integrating human behavioral insights and\nmillisecond scale neural data within a fine tuned CLIP based model not only\ncaptures generalized and individualized aspects of perception but also over\ndoubles behavioral performance compared to the unmodified CLIP baseline. By\nembedding human inductive biases and mirroring dynamic neural processes during\ntraining, personalized neural fine tuning improves predictions of human\nsimilarity judgments and tracks the temporal evolution of individual neural\nresponses. Our work establishes a novel, interpretable framework for designing\nadaptive AI systems, with broad implications for neuroscience, personalized\nmedicine, and human-computer interaction.",
      "tldr_zh": "本文提出了一种个性化脑启发式 AI 模型，通过在微调的 CLIP 模型中整合人类行为洞见和毫秒级神经数据，解决了现有 AI 模型在对齐个体用户感知语义和神经动态方面的不足。实验结果显示，这种方法不仅捕捉了感知的普遍和个性化方面，还将行为性能提高到原 CLIP 基线的两倍以上，并提升了对人类相似性判断的预测以及个体神经响应的时间演变跟踪。该框架为设计适应性 AI 系统提供了新颖、可解释的途径，对神经科学、个性化医学和人机交互具有广泛影响。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "7 Figures, 3 Tables, 3 Supplemental Figures, 1 Supplemental Table",
      "pdf_url": "http://arxiv.org/pdf/2502.04658v2",
      "published_date": "2025-02-07 04:55:31 UTC",
      "updated_date": "2025-04-21 15:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:40:15.577787"
    },
    {
      "arxiv_id": "2502.04646v1",
      "title": "Importance Sampling via Score-based Generative Models",
      "title_zh": "基于分数生成模型的重要性采样",
      "authors": [
        "Heasung Kim",
        "Taekyun Lee",
        "Hyeji Kim",
        "Gustavo de Veciana"
      ],
      "abstract": "Importance sampling, which involves sampling from a probability density\nfunction (PDF) proportional to the product of an importance weight function and\na base PDF, is a powerful technique with applications in variance reduction,\nbiased or customized sampling, data augmentation, and beyond. Inspired by the\ngrowing availability of score-based generative models (SGMs), we propose an\nentirely training-free Importance sampling framework that relies solely on an\nSGM for the base PDF. Our key innovation is realizing the importance sampling\nprocess as a backward diffusion process, expressed in terms of the score\nfunction of the base PDF and the specified importance weight function--both\nreadily available--eliminating the need for any additional training. We conduct\na thorough analysis demonstrating the method's scalability and effectiveness\nacross diverse datasets and tasks, including importance sampling for industrial\nand natural images with neural importance weight functions. The training-free\naspect of our method is particularly compelling in real-world scenarios where a\nsingle base distribution underlies multiple biased sampling tasks, each\nrequiring a different importance weight function. To the best of our knowledge\nour approach is the first importance sampling framework to achieve this.",
      "tldr_zh": "该论文提出了一种基于 Score-based Generative Models (SGMs) 的无训练 Importance Sampling 框架，用于从与重要权重函数和基础 PDF 成比例的概率密度函数中采样，实现方差减少、偏置采样和数据增强等应用。关键创新是将重要性采样过程表述为后向扩散过程，仅依赖基础 PDF 的分数函数和指定重要权重函数，从而无需额外训练。实验结果显示，该方法在多样数据集和任务（如工业及自然图像）上表现出色，具有良好的可扩展性，尤其适用于一个基础分布支持多个偏置采样任务的实际场景，并首次实现了这种训练-free 的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.04646v1",
      "published_date": "2025-02-07 04:09:03 UTC",
      "updated_date": "2025-02-07 04:09:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:40:27.020854"
    },
    {
      "arxiv_id": "2502.04645v1",
      "title": "Cross-Encoder Rediscovers a Semantic Variant of BM25",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Lu",
        "Catherine Chen",
        "Carsten Eickhoff"
      ],
      "abstract": "Neural Ranking Models (NRMs) have rapidly advanced state-of-the-art\nperformance on information retrieval tasks. In this work, we investigate a\nCross-Encoder variant of MiniLM to determine which relevance features it\ncomputes and where they are stored. We find that it employs a semantic variant\nof the traditional BM25 in an interpretable manner, featuring localized\ncomponents: (1) Transformer attention heads that compute soft term frequency\nwhile controlling for term saturation and document length effects, and (2) a\nlow-rank component of its embedding matrix that encodes inverse document\nfrequency information for the vocabulary. This suggests that the Cross-Encoder\nuses the same fundamental mechanisms as BM25, but further leverages their\ncapacity to capture semantics for improved retrieval performance. The granular\nunderstanding lays the groundwork for model editing to enhance model\ntransparency, addressing safety concerns, and improving scalability in training\nand real-world applications.",
      "tldr_zh": "本研究调查了基于 MiniLM 的 Cross-Encoder 变体在神经排序模型（NRMs）中的相关性特征，发现它重新发现了一种语义变体的 BM25。Cross-Encoder 通过 Transformer attention heads 计算软词频（soft term frequency），同时控制词饱和和文档长度影响，并利用嵌入矩阵的低秩组件编码逆文档频率（inverse document frequency）信息，从而提升检索性能。该发现为模型编辑提供了基础，帮助提高模型透明度、解决安全问题，并增强训练和实际应用的扩展性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04645v1",
      "published_date": "2025-02-07 04:08:57 UTC",
      "updated_date": "2025-02-07 04:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:40:38.279993"
    },
    {
      "arxiv_id": "2502.04644v1",
      "title": "Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research",
      "title_zh": "翻译失败",
      "authors": [
        "Junde Wu",
        "Jiayuan Zhu",
        "Yuyuan Liu"
      ],
      "abstract": "We introduce Agentic Reasoning, a framework that enhances large language\nmodel (LLM) reasoning by integrating external tool-using agents. Unlike\nconventional LLM-based reasoning approaches, which rely solely on internal\ninference, Agentic Reasoning dynamically engages web search, code execution,\nand structured reasoning-context memory to solve complex problems requiring\ndeep research and multi-step logical deduction. Our framework introduces the\nMind Map agent, which constructs a structured knowledge graph to track logical\nrelationships, improving deductive reasoning. Additionally, the integration of\nweb-search and coding agents enables real-time retrieval and computational\nanalysis, enhancing reasoning accuracy and decision-making. Evaluations on\nPhD-level scientific reasoning (GPQA) and domain-specific deep research tasks\ndemonstrate that our approach significantly outperforms existing models,\nincluding leading retrieval-augmented generation (RAG) systems and\nclosed-source LLMs. Moreover, our results indicate that agentic reasoning\nimproves expert-level knowledge synthesis, test-time scalability, and\nstructured problem-solving. The code is at:\nhttps://github.com/theworldofagents/Agentic-Reasoning.",
      "tldr_zh": "我们引入了 Agentic Reasoning 框架，通过整合外部工具代理（如 web search、code execution 和 structured reasoning-context memory）来增强大型语言模型 (LLM) 的推理能力。该框架包括 Mind Map agent，用于构建结构化知识图谱以追踪逻辑关系，从而改善多步推理和决策过程。在 GPQA 科学推理任务和领域特定深层研究中，Agentic Reasoning 显著优于现有模型（如 RAG 系统和闭源 LLM），提升了专家级知识合成、可扩展性和结构化问题解决能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.04644v1",
      "published_date": "2025-02-07 04:08:46 UTC",
      "updated_date": "2025-02-07 04:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:40:50.285542"
    },
    {
      "arxiv_id": "2502.04638v1",
      "title": "Learning Street View Representations with Spatiotemporal Contrast",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Li",
        "Yingjing Huang",
        "Gengchen Mai",
        "Fan Zhang"
      ],
      "abstract": "Street view imagery is extensively utilized in representation learning for\nurban visual environments, supporting various sustainable development tasks\nsuch as environmental perception and socio-economic assessment. However, it is\nchallenging for existing image representations to specifically encode the\ndynamic urban environment (such as pedestrians, vehicles, and vegetation), the\nbuilt environment (including buildings, roads, and urban infrastructure), and\nthe environmental ambiance (such as the cultural and socioeconomic atmosphere)\ndepicted in street view imagery to address downstream tasks related to the\ncity. In this work, we propose an innovative self-supervised learning framework\nthat leverages temporal and spatial attributes of street view imagery to learn\nimage representations of the dynamic urban environment for diverse downstream\ntasks. By employing street view images captured at the same location over time\nand spatially nearby views at the same time, we construct contrastive learning\ntasks designed to learn the temporal-invariant characteristics of the built\nenvironment and the spatial-invariant neighborhood ambiance. Our approach\nsignificantly outperforms traditional supervised and unsupervised methods in\ntasks such as visual place recognition, socioeconomic estimation, and\nhuman-environment perception. Moreover, we demonstrate the varying behaviors of\nimage representations learned through different contrastive learning objectives\nacross various downstream tasks. This study systematically discusses\nrepresentation learning strategies for urban studies based on street view\nimages, providing a benchmark that enhances the applicability of visual data in\nurban science. The code is available at https://github.com/yonglleee/UrbanSTCL.",
      "tldr_zh": "该研究提出了一种创新的自监督学习框架，利用街景图像的时空属性（spatiotemporal contrast）来学习动态城市环境的图像表示，旨在解决现有方法在编码动态城市环境（如行人、车辆、植被）、建成环境（如建筑、道路）和环境氛围（如文化和经济社会氛围）方面的挑战。框架通过对比同一位置不同时间的图像和同一时间附近位置的图像，构建对比学习任务，以捕捉建成环境的时不变特性（temporal-invariant characteristics）和社会氛围的空间不变特性（spatial-invariant neighborhood ambiance）。实验结果显示，该方法在视觉场所识别（visual place recognition）、经济社会估计和人类-环境感知等下游任务中显著优于传统监督和无监督方法，并分析了不同对比学习目标在任务中的行为差异。该框架为基于街景图像的城市研究提供了一个基准，促进了视觉数据在城市科学中的应用，代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04638v1",
      "published_date": "2025-02-07 03:47:54 UTC",
      "updated_date": "2025-02-07 03:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:41:02.535848"
    },
    {
      "arxiv_id": "2502.04636v1",
      "title": "An Empirical Study of Code Obfuscation Practices in the Google Play Store",
      "title_zh": "Google Play Store 中",
      "authors": [
        "Akila Niroshan",
        "Suranga Seneviratne",
        "Aruna Seneviratne"
      ],
      "abstract": "The Android ecosystem is vulnerable to issues such as app repackaging,\ncounterfeiting, and piracy, threatening both developers and users. To mitigate\nthese risks, developers often employ code obfuscation techniques. However,\nwhile effective in protecting legitimate applications, obfuscation also hinders\nsecurity investigations as it is often exploited for malicious purposes. As\nsuch, it is important to understand code obfuscation practices in Android apps.\nIn this paper, we analyze over 500,000 Android APKs from Google Play, spanning\nan eight-year period, to investigate the evolution and prevalence of code\nobfuscation techniques. First, we propose a set of classifiers to detect\nobfuscated code, tools, and techniques and then conduct a longitudinal analysis\nto identify trends. Our results show a 13% increase in obfuscation from 2016 to\n2023, with ProGuard and Allatori as the most commonly used tools. We also show\nthat obfuscation is more prevalent in top-ranked apps and gaming genres such as\nCasino apps. To our knowledge, this is the first large-scale study of\nobfuscation adoption in the Google Play Store, providing insights for\ndevelopers and security analysts.",
      "tldr_zh": "本文通过分析超过50万的Android APK，从2016年到2023年，研究了Google Play Store中code obfuscation的采用情况，以应对app repackaging、counterfeiting和piracy等风险。研究团队开发了分类器来检测obfuscation工具和技术，并进行纵向分析，发现其使用率增加了13%，ProGuard和Allatori是最常见的工具，且在顶级应用和游戏类别（如Casino apps）中更流行。该研究为开发者和服务分析师提供了首个大规模实证洞见，帮助平衡应用保护与安全调查的需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.04636v1",
      "published_date": "2025-02-07 03:41:40 UTC",
      "updated_date": "2025-02-07 03:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:41:15.204583"
    },
    {
      "arxiv_id": "2503.05607v1",
      "title": "AceWGS: An LLM-Aided Framework to Accelerate Catalyst Design for Water-Gas Shift Reactions",
      "title_zh": "翻译失败",
      "authors": [
        "Joyjit Chattoraj",
        "Brahim Hamadicharef",
        "Teo Shi Chang",
        "Yingzhi Zeng",
        "Chee Kok Poh",
        "Luwei Chen",
        "Teck Leong Tan"
      ],
      "abstract": "While the Water-Gas Shift (WGS) reaction plays a crucial role in hydrogen\nproduction for fuel cells, finding suitable catalysts to achieve high yields\nfor low-temperature WGS reactions remains a persistent challenge. Artificial\nIntelligence (AI) has shown promise in accelerating catalyst design by\nexploring vast candidate spaces, however, two key gaps limit its effectiveness.\nFirst, AI models primarily train on numerical data, which fail to capture\nessential text-based information, such as catalyst synthesis methods. Second,\nthe cross-disciplinary nature of catalyst design requires seamless\ncollaboration between AI, theory, experiments, and numerical simulations, often\nleading to communication barriers. To address these gaps, we present AceWGS, a\nLarge Language Models (LLMs)-aided framework to streamline WGS catalyst design.\nAceWGS interacts with researchers through natural language, answering queries\nbased on four features: (i) answering general queries, (ii) extracting\ninformation about the database comprising WGS-related journal articles, (iii)\ncomprehending the context described in these articles, and (iv) identifying\ncatalyst candidates using our proposed AI inverse model. We presented a\npractical case study demonstrating how AceWGS can accelerate the catalyst\ndesign process. AceWGS, built with open-source tools, offers an adjustable\nframework that researchers can readily adapt for a range of AI-accelerated\ncatalyst design applications, supporting seamless integration across\ncross-disciplinary studies.",
      "tldr_zh": "水气变换（WGS）反应在氢气生产中至关重要，但高效低温和催化剂设计面临AI模型忽略文本信息（如合成方法）和跨学科协作障碍的挑战。本文提出AceWGS，一种基于Large Language Models (LLMs)的框架，通过自然语言交互实现四个关键功能：回答一般查询、提取WGS相关期刊数据库信息、理解文章上下文，以及使用AI inverse model识别催化剂候选。AceWGS通过一个实际案例研究证明了其加速催化剂设计过程的能力，并以开源工具构建，提供可调整的框架，支持跨学科整合。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05607v1",
      "published_date": "2025-02-07 02:36:47 UTC",
      "updated_date": "2025-02-07 02:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:41:28.037776"
    },
    {
      "arxiv_id": "2503.03753v1",
      "title": "Generative Diffusion Model-based Compression of MIMO CSI",
      "title_zh": "基于生成扩散模型的 MIMO CSI 压缩",
      "authors": [
        "Heasung Kim",
        "Taekyun Lee",
        "Hyeji Kim",
        "Gustavo De Veciana",
        "Mohamed Amine Arfaoui",
        "Asil Koc",
        "Phil Pietraski",
        "Guodong Zhang",
        "John Kaewell"
      ],
      "abstract": "While neural lossy compression techniques have markedly advanced the\nefficiency of Channel State Information (CSI) compression and reconstruction\nfor feedback in MIMO communications, efficient algorithms for more challenging\nand practical tasks-such as CSI compression for future channel prediction and\nreconstruction with relevant side information-remain underexplored, often\nresulting in suboptimal performance when existing methods are extended to these\nscenarios. To that end, we propose a novel framework for compression with side\ninformation, featuring an encoding process with fixed-rate compression using a\ntrainable codebook for codeword quantization, and a decoding procedure modeled\nas a backward diffusion process conditioned on both the codeword and the side\ninformation. Experimental results show that our method significantly\noutperforms existing CSI compression algorithms, often yielding over twofold\nperformance improvement by achieving comparable distortion at less than half\nthe data rate of competing methods in certain scenarios. These findings\nunderscore the potential of diffusion-based compression for practical\ndeployment in communication systems.",
      "tldr_zh": "这篇论文提出了一种基于生成扩散模型的 MIMO CSI 压缩框架，旨在解决现有方法在未来通道预测和带有相关侧信息重建等挑战性任务中的性能不足问题。该框架的编码过程采用固定速率压缩和可训练代码本进行代码字量化，而解码过程则建模为后向扩散过程，条件于代码字和侧信息。实验结果表明，该方法显著优于现有 CSI 压缩算法，在某些场景下以不到一半的数据率实现可比的失真，提高了超过两倍的性能。这些发现突显了扩散模型在 MIMO 通信系统中的实际部署潜力。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT",
        "68P30",
        "I.2.0"
      ],
      "primary_category": "cs.IT",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.03753v1",
      "published_date": "2025-02-07 02:24:12 UTC",
      "updated_date": "2025-02-07 02:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:41:39.463958"
    },
    {
      "arxiv_id": "2502.04602v1",
      "title": "Extracting and Understanding the Superficial Knowledge in Alignment",
      "title_zh": "在对齐中提取与理解表层知识",
      "authors": [
        "Runjin Chen",
        "Gabriel Jacob Perin",
        "Xuxi Chen",
        "Xilun Chen",
        "Yan Han",
        "Nina S. T. Hirata",
        "Junyuan Hong",
        "Bhavya Kailkhura"
      ],
      "abstract": "Alignment of large language models (LLMs) with human values and preferences,\noften achieved through fine-tuning based on human feedback, is essential for\nensuring safe and responsible AI behaviors. However, the process typically\nrequires substantial data and computation resources. Recent studies have\nrevealed that alignment might be attainable at lower costs through simpler\nmethods, such as in-context learning. This leads to the question: Is alignment\npredominantly superficial? In this paper, we delve into this question and\nprovide a quantitative analysis. We formalize the concept of superficial\nknowledge, defining it as knowledge that can be acquired through easily token\nrestyling, without affecting the model's ability to capture underlying causal\nrelationships between tokens. We propose a method to extract and isolate\nsuperficial knowledge from aligned models, focusing on the shallow\nmodifications to the final token selection process. By comparing models\naugmented only with superficial knowledge to fully aligned models, we quantify\nthe superficial portion of alignment. Our findings reveal that while\nsuperficial knowledge constitutes a significant portion of alignment,\nparticularly in safety and detoxification tasks, it is not the whole story.\nTasks requiring reasoning and contextual understanding still rely on deeper\nknowledge. Additionally, we demonstrate two practical advantages of isolated\nsuperficial knowledge: (1) it can be transferred between models, enabling\nefficient offsite alignment of larger models using extracted superficial\nknowledge from smaller models, and (2) it is recoverable, allowing for the\nrestoration of alignment in compromised models without sacrificing performance.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在对齐 (alignment) 过程中的 superficial knowledge，即可以通过简单 token restyling 获取的浅层知识，而不影响底层因果关系。作者提出了一种方法来提取和隔离这种知识，通过比较只添加 superficial knowledge 的模型与完全对齐模型，量化了其在对齐中的比例。研究发现，superficial knowledge 在安全和 detoxification 任务中占主导，但推理和上下文理解任务仍依赖更深层知识；此外，它可实现模型间的知识转移和恢复，提升对齐效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04602v1",
      "published_date": "2025-02-07 01:32:19 UTC",
      "updated_date": "2025-02-07 01:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:41:52.315608"
    },
    {
      "arxiv_id": "2502.04593v1",
      "title": "The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Reza Rezaei",
        "Adji Bousso Dieng"
      ],
      "abstract": "Current state-of-the-art dynamical models, such as Mamba, assume the same\nlevel of noisiness for all elements of a given sequence, which limits their\nperformance on noisy temporal data. In this paper, we introduce the\n$\\alpha$-Alternator, a novel generative model for time-dependent data that\ndynamically adapts to the complexity introduced by varying noise levels in\nsequences. The $\\alpha$-Alternator leverages the Vendi Score (VS), a flexible\nsimilarity-based diversity metric, to adjust, at each time step $t$, the\ninfluence of the sequence element at time $t$ and the latent representation of\nthe dynamics up to that time step on the predicted future dynamics. This\ninfluence is captured by a parameter that is learned and shared across all\nsequences in a given dataset. The sign of this parameter determines the\ndirection of influence. A negative value indicates a noisy dataset, where a\nsequence element that increases the VS is considered noisy, and the model\nrelies more on the latent history when processing that element. Conversely,\nwhen the parameter is positive, a sequence element that increases the VS is\nconsidered informative, and the $\\alpha$-Alternator relies more on this new\ninput than on the latent history when updating its predicted latent dynamics.\nThe $\\alpha$-Alternator is trained using a combination of observation masking\nand Alternator loss minimization. Masking simulates varying noise levels in\nsequences, enabling the model to be more robust to these fluctuations and\nimproving its performance in trajectory prediction, imputation, and\nforecasting. Our experimental results demonstrate that the $\\alpha$-Alternator\noutperforms both Alternators and state-of-the-art state-space models across\nneural decoding and time-series forecasting benchmarks.",
      "tldr_zh": "本文提出α-Alternator，一种新型生成模型，用于处理序列中变化噪声水平的动态数据问题，通过Vendi Score（VS）作为相似性-based多样性指标，动态调整每个时间步t的序列元素和潜在表示对未来动态的影响。该参数的符号决定影响方向：负值时视序列元素为噪声并更依赖潜在历史，正值时视其为信息并优先使用新输入。模型通过观察掩码和Alternator损失最小化进行训练，实验结果显示，在神经解码和时间序列预测基准上，α-Alternator优于Alternators和最先进的状态空间模型如Mamba，提高了鲁棒性和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The codebase will be made available upon publication. This paper is\n  dedicated to Patrice Lumumba",
      "pdf_url": "http://arxiv.org/pdf/2502.04593v1",
      "published_date": "2025-02-07 01:00:16 UTC",
      "updated_date": "2025-02-07 01:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:42:04.331945"
    },
    {
      "arxiv_id": "2502.04592v1",
      "title": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhang",
        "Wenbo Yang",
        "Jun Wang",
        "Qiang Ma",
        "Jie Xiong"
      ],
      "abstract": "Accurately forecasting the impact of macroeconomic events is critical for\ninvestors and policymakers. Salient events like monetary policy decisions and\nemployment reports often trigger market movements by shaping expectations of\neconomic growth and risk, thereby establishing causal relationships between\nevents and market behavior. Existing forecasting methods typically focus either\non textual analysis or time-series modeling, but fail to capture the\nmulti-modal nature of financial markets and the causal relationship between\nevents and price movements. To address these gaps, we propose CAMEF\n(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a\nmulti-modality framework that effectively integrates textual and time-series\ndata with a causal learning mechanism and an LLM-based counterfactual event\naugmentation technique for causal-enhanced financial forecasting. Our\ncontributions include: (1) a multi-modal framework that captures causal\nrelationships between policy texts and historical price data; (2) a new\nfinancial dataset with six types of macroeconomic releases from 2008 to April\n2024, and high-frequency real trading data for five key U.S. financial assets;\nand (3) an LLM-based counterfactual event augmentation strategy. We compare\nCAMEF to state-of-the-art transformer-based time-series and multi-modal\nbaselines, and perform ablation studies to validate the effectiveness of the\ncausal learning mechanism and event types.",
      "tldr_zh": "该论文提出 CAMEF（Causal-Augmented Multi-Modality Event-Driven Financial Forecasting）框架，通过整合文本数据和时间序列模式，并引入因果学习机制及基于 LLM 的反事实事件增强技术，来捕捉宏观经济事件（如货币政策和就业报告）与市场行为之间的因果关系，从而提升金融预测准确性。关键贡献包括：（1）一个多模态框架，用于分析政策文本和历史价格数据间的因果联系；（2）一个新的金融数据集，涵盖2008年至2024年四月的六种宏观经济发布及五种关键美国金融资产的高频交易数据；（3）创新的反事实事件增强策略。实验结果显示，CAMEF 优于最先进的 transformer-based 时间序列和多模态基线模型，经消融研究验证了因果学习机制的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04592v1",
      "published_date": "2025-02-07 00:55:25 UTC",
      "updated_date": "2025-02-07 00:55:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:42:19.360689"
    },
    {
      "arxiv_id": "2502.04591v3",
      "title": "Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective",
      "title_zh": "重新审视图神经网络中的过度平滑：基于秩的视角",
      "authors": [
        "Kaicheng Zhang",
        "Piero Deidda",
        "Desmond Higham",
        "Francesco Tudisco"
      ],
      "abstract": "Oversmoothing is a fundamental challenge in graph neural networks (GNNs): as\nthe number of layers increases, node embeddings become increasingly similar,\nand model performance drops sharply. Traditionally, oversmoothing has been\nquantified using metrics that measure the similarity of neighbouring node\nfeatures, such as the Dirichlet energy. While these metrics are related to\noversmoothing, we argue they have critical limitations and fail to reliably\ncapture oversmoothing in realistic scenarios. For instance, they provide\nmeaningful insights only for very deep networks and under somewhat strict\nconditions on the norm of network weights and feature representations. As an\nalternative, we propose measuring oversmoothing by examining the numerical or\neffective rank of the feature representations. We provide theoretical support\nfor this approach, demonstrating that the numerical rank of feature\nrepresentations converges to one for a broad family of nonlinear activation\nfunctions under the assumption of nonnegative trained weights. To the best of\nour knowledge, this is the first result that proves the occurrence of\noversmoothing in the nonlinear setting without assumptions on the boundedness\nof the weight matrices. Along with the theoretical findings, we provide\nextensive numerical evaluation across diverse graph architectures. Our results\nshow that rank-based metrics consistently capture oversmoothing, whereas\nenergy-based metrics often fail. Notably, we reveal that a significant drop in\nthe rank aligns closely with performance degradation, even in scenarios where\nenergy metrics remain unchanged.",
      "tldr_zh": "本论文重新审视了图神经网络 (GNNs) 中的 oversmoothing 问题，即随着层数的增加，节点嵌入变得越来越相似，导致模型性能急剧下降。传统指标如 Dirichlet energy 测量邻居节点特征相似性，但存在关键局限，仅适用于深度网络和特定权重规范条件。作者提出一种基于数值或有效秩 (numerical or effective rank) 的新方法来量化 oversmoothing，并理论证明在非线性激活函数和非负训练权重假设下，特征表示的秩会收敛到1，这是首个无需权重矩阵有界性假设的非线性设置证明。实验结果显示，秩-based 指标能一致捕获 oversmoothing 现象，并与性能下降紧密相关，而 energy-based 指标往往失效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04591v3",
      "published_date": "2025-02-07 00:55:05 UTC",
      "updated_date": "2025-05-20 23:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:42:29.573704"
    },
    {
      "arxiv_id": "2502.04580v1",
      "title": "Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context",
      "title_zh": "在上下文学习中的技术债务：长上下文中的效率降低",
      "authors": [
        "Taejong Joo",
        "Diego Klabjan"
      ],
      "abstract": "Transformers have demonstrated remarkable in-context learning (ICL)\ncapabilities, adapting to new tasks by simply conditioning on demonstrations\nwithout parameter updates. Compelling empirical and theoretical evidence\nsuggests that ICL, as a general-purpose learner, could outperform task-specific\nmodels. However, it remains unclear to what extent the transformers optimally\nlearn in-context compared to principled learning algorithms. To bridge this\ngap, we introduce a new framework for quantifying optimality of ICL as a\nlearning algorithm in stylized settings. Our findings reveal a striking\ndichotomy: while ICL initially matches the efficiency of a Bayes optimal\nestimator, its efficiency significantly deteriorates in long context. Through\nan information-theoretic analysis, we show that the diminishing efficiency is\ninherent to ICL. These results clarify the trade-offs in adopting ICL as a\nuniversal problem solver, motivating a new generation of on-the-fly adaptive\nmethods without the diminishing efficiency.",
      "tldr_zh": "该研究探讨了 In-Context Learning (ICL) 在长上下文中效率下降的技术债务问题，揭示了 Transformers 作为通用学习器虽能通过条件演示适应新任务，但其效率并非始终最优。论文引入一个框架来量化 ICL 在简化场景中的最优性，发现 ICL 最初与 Bayes optimal estimator 相当高效，但随着上下文长度增加，效率显著恶化。信息理论分析证明这一效率下降是 ICL 的固有特性，并由此激励开发新一代自适应方法，以避免此类问题并提升 ICL 作为问题解决器的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04580v1",
      "published_date": "2025-02-07 00:26:45 UTC",
      "updated_date": "2025-02-07 00:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T08:42:41.213750"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 113,
  "processed_papers_count": 113,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T08:43:03.531973"
}