[
  {
    "arxiv_id": "2502.05383v2",
    "title": "Is attention all you need to solve the correlated electron problem?",
    "authors": [
      "Max Geier",
      "Khachatur Nazaryan",
      "Timothy Zaklama",
      "Liang Fu"
    ],
    "abstract": "The attention mechanism has transformed artificial intelligence research by\nits ability to learn relations between objects. In this work, we explore how a\nmany-body wavefunction ansatz constructed from a large-parameter self-attention\nneural network can be used to solve the interacting electron problem in solids.\nBy a systematic neural-network variational Monte Carlo study on a moir\\'e\nquantum material, we demonstrate that the self-attention ansatz provides an\naccurate, efficient, and unbiased solution. Moreover, our numerical study finds\nthat the required number of variational parameters scales roughly as $N^2$ with\nthe number of electrons, which opens a path towards efficient large-scale\nsimulations.",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.mes-hall",
      "cs.AI"
    ],
    "primary_category": "cond-mat.str-el",
    "comment": "10+5 pages, comments welcome; v2: update refs, extend ED results",
    "pdf_url": "http://arxiv.org/pdf/2502.05383v2",
    "published_date": "2025-02-07 23:41:41 UTC",
    "updated_date": "2025-03-10 02:05:44 UTC"
  },
  {
    "arxiv_id": "2502.05370v1",
    "title": "fMoE: Fine-Grained Expert Offloading for Large Mixture-of-Experts Serving",
    "authors": [
      "Hanfei Yu",
      "Xingqi Cui",
      "Hong Zhang",
      "Hao Wang",
      "Hao Wang"
    ],
    "abstract": "Large Language Models (LLMs) have gained immense success in revolutionizing\nvarious applications, including content generation, search and recommendation,\nand AI-assisted operation. To reduce high training costs, Mixture-of-Experts\n(MoE) architecture has become a popular backbone for modern LLMs. However,\ndespite the benefits, serving MoE-based LLMs experience severe memory\ninefficiency due to sparsely activated experts. Recent studies propose to\noffload inactive experts from GPU memory to CPU memory to improve the serving\nefficiency of MoE models. However, they either incur high inference latency or\nhigh model memory footprints due to coarse-grained designs. To tame the\nlatency-memory trade-off in MoE serving, we present fMoE, a fine-grained expert\noffloading system for MoE serving that achieves low inference latency with\nmemory efficiency. We design fMoE to extract fine-grained expert selection\npatterns from MoE models and semantic hints from input prompts to efficiently\nguide expert prefetching, caching, and offloading decisions. fMoE is prototyped\non top of HuggingFace Transformers and deployed on a six-GPU testbed.\nExperiments with open-source MoE models and real-world workloads show that fMoE\nreduces inference latency by 47% and improves expert hit rate by 36% over\nstate-of-the-art solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05370v1",
    "published_date": "2025-02-07 22:51:17 UTC",
    "updated_date": "2025-02-07 22:51:17 UTC"
  },
  {
    "arxiv_id": "2502.05352v1",
    "title": "ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks",
    "authors": [
      "Saurabh Jha",
      "Rohan Arora",
      "Yuji Watanabe",
      "Takumi Yanagawa",
      "Yinfang Chen",
      "Jackson Clark",
      "Bhavya Bhavya",
      "Mudit Verma",
      "Harshit Kumar",
      "Hirokuni Kitahara",
      "Noah Zheutlin",
      "Saki Takano",
      "Divya Pathak",
      "Felix George",
      "Xinbo Wu",
      "Bekir O. Turkkan",
      "Gerard Vanloo",
      "Michael Nidd",
      "Ting Dai",
      "Oishik Chatterjee",
      "Pranjal Gupta",
      "Suranjana Samanta",
      "Pooja Aggarwal",
      "Rong Lee",
      "Pavankumar Murali",
      "Jae-wook Ahn",
      "Debanjana Kar",
      "Ameet Rahane",
      "Carlos Fonseca",
      "Amit Paradkar",
      "Yu Deng",
      "Pratibha Moogi",
      "Prateeti Mohapatra",
      "Naoki Abe",
      "Chandrasekhar Narayanaswami",
      "Tianyin Xu",
      "Lav R. Varshney",
      "Ruchi Mahindru",
      "Anca Sailer",
      "Laura Shwartz",
      "Daby Sow",
      "Nicholas C. M. Fuller",
      "Ruchir Puri"
    ],
    "abstract": "Realizing the vision of using AI agents to automate critical IT tasks depends\non the ability to measure and understand effectiveness of proposed solutions.\nWe introduce ITBench, a framework that offers a systematic methodology for\nbenchmarking AI agents to address real-world IT automation tasks. Our initial\nrelease targets three key areas: Site Reliability Engineering (SRE), Compliance\nand Security Operations (CISO), and Financial Operations (FinOps). The design\nenables AI researchers to understand the challenges and opportunities of AI\nagents for IT automation with push-button workflows and interpretable metrics.\nITBench includes an initial set of 94 real-world scenarios, which can be easily\nextended by community contributions. Our results show that agents powered by\nstate-of-the-art models resolve only 13.8% of SRE scenarios, 25.2% of CISO\nscenarios, and 0% of FinOps scenarios. We expect ITBench to be a key enabler of\nAI-driven IT automation that is correct, safe, and fast.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05352v1",
    "published_date": "2025-02-07 21:46:52 UTC",
    "updated_date": "2025-02-07 21:46:52 UTC"
  },
  {
    "arxiv_id": "2502.05345v1",
    "title": "Estimating Voltage Drop: Models, Features and Data Representation Towards a Neural Surrogate",
    "authors": [
      "Yifei Jin",
      "Dimitrios Koutlis",
      "Hector Bandala",
      "Marios Daoutis"
    ],
    "abstract": "Accurate estimation of voltage drop (IR drop) in modern Application-Specific\nIntegrated Circuits (ASICs) is highly time and resource demanding, due to the\ngrowing complexity and the transistor density in recent technology nodes. To\nmitigate this challenge, we investigate how Machine Learning (ML) techniques,\nincluding Extreme Gradient Boosting (XGBoost), Convolutional Neural Network\n(CNN), and Graph Neural Network (GNN) can aid in reducing the computational\neffort and implicitly the time required to estimate the IR drop in Integrated\nCircuits (ICs). Traditional methods, including commercial tools, require\nconsiderable time to produce accurate approximations, especially for\ncomplicated designs with numerous transistors. ML algorithms, on the other\nhand, are explored as an alternative solution to offer quick and precise IR\ndrop estimation, but in considerably less time. Our approach leverages ASICs'\nelectrical, timing, and physical to train ML models, ensuring adaptability\nacross diverse designs with minimal adjustments. Experimental results\nunderscore the superiority of ML models over commercial tools, greatly\nenhancing prediction speed. Particularly, GNNs exhibit promising performance\nwith minimal prediction errors in voltage drop estimation. The incorporation of\nGNNs marks a groundbreaking advancement in accurate IR drop prediction. This\nstudy illustrates the effectiveness of ML algorithms in precisely estimating IR\ndrop and optimizing ASIC sign-off. Utilizing ML models leads to expedited\npredictions, reducing calculation time and improving energy efficiency, thereby\nreducing environmental impact through optimized power circuits.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05345v1",
    "published_date": "2025-02-07 21:31:13 UTC",
    "updated_date": "2025-02-07 21:31:13 UTC"
  },
  {
    "arxiv_id": "2502.05344v1",
    "title": "RAG-Verus: Repository-Level Program Verification with LLMs using Retrieval Augmented Generation",
    "authors": [
      "Sicheng Zhong",
      "Jiading Zhu",
      "Yifang Tian",
      "Xujie Si"
    ],
    "abstract": "Scaling automated formal verification to real-world projects requires\nresolving cross-module dependencies and global contexts, which are challenges\noverlooked by existing function-centric methods. We introduce RagVerus, a\nframework that synergizes retrieval-augmented generation with context-aware\nprompting to automate proof synthesis for multi-module repositories, achieving\na 27% relative improvement on our novel RepoVBench benchmark -- the first\nrepository-level dataset for Verus with 383 proof completion tasks. RagVerus\ntriples proof pass rates on existing benchmarks under constrained language\nmodel budgets, demonstrating a scalable and sample-efficient verification.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05344v1",
    "published_date": "2025-02-07 21:30:37 UTC",
    "updated_date": "2025-02-07 21:30:37 UTC"
  },
  {
    "arxiv_id": "2502.05330v1",
    "title": "Multi-Class Segmentation of Aortic Branches and Zones in Computed Tomography Angiography: The AortaSeg24 Challenge",
    "authors": [
      "Muhammad Imran",
      "Jonathan R. Krebs",
      "Vishal Balaji Sivaraman",
      "Teng Zhang",
      "Amarjeet Kumar",
      "Walker R. Ueland",
      "Michael J. Fassler",
      "Jinlong Huang",
      "Xiao Sun",
      "Lisheng Wang",
      "Pengcheng Shi",
      "Maximilian Rokuss",
      "Michael Baumgartner",
      "Yannick Kirchhof",
      "Klaus H. Maier-Hein",
      "Fabian Isensee",
      "Shuolin Liu",
      "Bing Han",
      "Bong Thanh Nguyen",
      "Dong-jin Shin",
      "Park Ji-Woo",
      "Mathew Choi",
      "Kwang-Hyun Uhm",
      "Sung-Jea Ko",
      "Chanwoong Lee",
      "Jaehee Chun",
      "Jin Sung Kim",
      "Minghui Zhang",
      "Hanxiao Zhang",
      "Xin You",
      "Yun Gu",
      "Zhaohong Pan",
      "Xuan Liu",
      "Xiaokun Liang",
      "Markus Tiefenthaler",
      "Enrique Almar-Munoz",
      "Matthias Schwab",
      "Mikhail Kotyushev",
      "Rostislav Epifanov",
      "Marek Wodzinski",
      "Henning Muller",
      "Abdul Qayyum",
      "Moona Mazher",
      "Steven A. Niederer",
      "Zhiwei Wang",
      "Kaixiang Yang",
      "Jintao Ren",
      "Stine Sofia Korreman",
      "Yuchong Gao",
      "Hongye Zeng",
      "Haoyu Zheng",
      "Rui Zheng",
      "Jinghua Yue",
      "Fugen Zhou",
      "Bo Liu",
      "Alexander Cosman",
      "Muxuan Liang",
      "Chang Zhao",
      "Gilbert R. Upchurch Jr.",
      "Jun Ma",
      "Yuyin Zhou",
      "Michol A. Cooper",
      "Wei Shao"
    ],
    "abstract": "Multi-class segmentation of the aorta in computed tomography angiography\n(CTA) scans is essential for diagnosing and planning complex endovascular\ntreatments for patients with aortic dissections. However, existing methods\nreduce aortic segmentation to a binary problem, limiting their ability to\nmeasure diameters across different branches and zones. Furthermore, no\nopen-source dataset is currently available to support the development of\nmulti-class aortic segmentation methods. To address this gap, we organized the\nAortaSeg24 MICCAI Challenge, introducing the first dataset of 100 CTA volumes\nannotated for 23 clinically relevant aortic branches and zones. This dataset\nwas designed to facilitate both model development and validation. The challenge\nattracted 121 teams worldwide, with participants leveraging state-of-the-art\nframeworks such as nnU-Net and exploring novel techniques, including cascaded\nmodels, data augmentation strategies, and custom loss functions. We evaluated\nthe submitted algorithms using the Dice Similarity Coefficient (DSC) and\nNormalized Surface Distance (NSD), highlighting the approaches adopted by the\ntop five performing teams. This paper presents the challenge design, dataset\ndetails, evaluation metrics, and an in-depth analysis of the top-performing\nalgorithms. The annotated dataset, evaluation code, and implementations of the\nleading methods are publicly available to support further research. All\nresources can be accessed at https://aortaseg24.grand-challenge.org.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05330v1",
    "published_date": "2025-02-07 21:09:05 UTC",
    "updated_date": "2025-02-07 21:09:05 UTC"
  },
  {
    "arxiv_id": "2502.05312v1",
    "title": "Towards the Development of Balanced Synthetic Data for Correcting Grammatical Errors in Arabic: An Approach Based on Error Tagging Model and Synthetic Data Generating Model",
    "authors": [
      "Ahlam Alrehili",
      "Areej Alhothali"
    ],
    "abstract": "Synthetic data generation is widely recognized as a way to enhance the\nquality of neural grammatical error correction (GEC) systems. However, current\napproaches often lack diversity or are too simplistic to generate the wide\nrange of grammatical errors made by humans, especially for low-resource\nlanguages such as Arabic. In this paper, we will develop the error tagging\nmodel and the synthetic data generation model to create a large synthetic\ndataset in Arabic for grammatical error correction. In the error tagging model,\nthe correct sentence is categorized into multiple error types by using the\nDeBERTav3 model. Arabic Error Type Annotation tool (ARETA) is used to guide\nmulti-label classification tasks in an error tagging model in which each\nsentence is classified into 26 error tags. The synthetic data generation model\nis a back-translation-based model that generates incorrect sentences by\nappending error tags before the correct sentence that was generated from the\nerror tagging model using the ARAT5 model. In the QALB-14 and QALB-15 Test\nsets, the error tagging model achieved 94.42% F1, which is state-of-the-art in\nidentifying error tags in clean sentences. As a result of our syntactic data\ntraining in grammatical error correction, we achieved a new state-of-the-art\nresult of F1-Score: 79.36% in the QALB-14 Test set. We generate 30,219,310\nsynthetic sentence pairs by using a synthetic data generation model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05312v1",
    "published_date": "2025-02-07 20:28:37 UTC",
    "updated_date": "2025-02-07 20:28:37 UTC"
  },
  {
    "arxiv_id": "2502.05310v1",
    "title": "Oracular Programming: A Modular Foundation for Building LLM-Enabled Software",
    "authors": [
      "Jonathan Laurent",
      "André Platzer"
    ],
    "abstract": "Large Language Models have proved surprisingly effective at solving a wide\nrange of tasks from just a handful of examples. However, their lack of\nreliability and modularity limits their capacity to tackle large problems that\nrequire many steps of reasoning. In response, researchers have proposed\nadvanced pipelines that leverage domain-specific knowledge to chain smaller\nprompts, provide intermediate feedback and improve performance through search.\nHowever, the current complexity of writing, tuning, maintaining and improving\nsuch pipelines has limited their sophistication. We propose oracular\nprogramming, a foundational paradigm for building LLM-enabled applications that\nlets domain experts express high-level problem-solving strategies as programs\nwith unresolved choice points. These choice points are resolved at runtime by\nLLMs, which generalize from user-provided examples of correct and incorrect\ndecisions. An oracular program is composed of three orthogonal components: a\nstrategy that consists in a nondeterministic program with choice points that\ncan be reified into a search tree, a policy that specifies how to navigate this\ntree with the help of LLM oracles, and a set of demonstrations that describe\nsuccessful and unsuccessful search tree navigation scenarios across diverse\nproblem instances. Each component is expressed in a dedicated programming\nlanguage and can be independently improved or substituted. We address the key\nprogramming language design challenges of modularly composing oracular programs\nand enforcing consistency between their components as they evolve.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05310v1",
    "published_date": "2025-02-07 20:24:43 UTC",
    "updated_date": "2025-02-07 20:24:43 UTC"
  },
  {
    "arxiv_id": "2502.05300v1",
    "title": "Parameter Symmetry Breaking and Restoration Determines the Hierarchical Learning in AI Systems",
    "authors": [
      "Liu Ziyin",
      "Yizhou Xu",
      "Tomaso Poggio",
      "Isaac Chuang"
    ],
    "abstract": "The dynamics of learning in modern large AI systems is hierarchical, often\ncharacterized by abrupt, qualitative shifts akin to phase transitions observed\nin physical systems. While these phenomena hold promise for uncovering the\nmechanisms behind neural networks and language models, existing theories remain\nfragmented, addressing specific cases. In this paper, we posit that parameter\nsymmetry breaking and restoration serve as a unifying mechanism underlying\nthese behaviors. We synthesize prior observations and show how this mechanism\nexplains three distinct hierarchies in neural networks: learning dynamics,\nmodel complexity, and representation formation. By connecting these\nhierarchies, we highlight symmetry -- a cornerstone of theoretical physics --\nas a potential fundamental principle in modern AI.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05300v1",
    "published_date": "2025-02-07 20:10:05 UTC",
    "updated_date": "2025-02-07 20:10:05 UTC"
  },
  {
    "arxiv_id": "2502.05292v1",
    "title": "Drone Detection and Tracking with YOLO and a Rule-based Method",
    "authors": [
      "Purbaditya Bhattacharya",
      "Patrick Nowak"
    ],
    "abstract": "Drones or unmanned aerial vehicles are traditionally used for military\nmissions, warfare, and espionage. However, the usage of drones has\nsignificantly increased due to multiple industrial applications involving\nsecurity and inspection, transportation, research purposes, and recreational\ndrone flying. Such an increased volume of drone activity in public spaces\nrequires regulatory actions for purposes of privacy protection and safety.\nHence, detection of illegal drone activities such as boundary encroachment\nbecomes a necessity. Such detection tasks are usually automated and performed\nby deep learning models which are trained on annotated image datasets. This\npaper builds on a previous work and extends an already published open source\ndataset. A description and analysis of the entire dataset is provided. The\ndataset is used to train the YOLOv7 deep learning model and some of its minor\nvariants and the results are provided. Since the detection models are based on\na single image input, a simple cross-correlation based tracker is used to\nreduce detection drops and improve tracking performance in videos. Finally, the\nentire drone detection system is summarized.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05292v1",
    "published_date": "2025-02-07 19:53:10 UTC",
    "updated_date": "2025-02-07 19:53:10 UTC"
  },
  {
    "arxiv_id": "2502.06858v1",
    "title": "LLM-Supported Natural Language to Bash Translation",
    "authors": [
      "Finnian Westenfelder",
      "Erik Hemberg",
      "Miguel Tulla",
      "Stephen Moskal",
      "Una-May O'Reilly",
      "Silviu Chiricescu"
    ],
    "abstract": "The Bourne-Again Shell (Bash) command-line interface for Linux systems has\ncomplex syntax and requires extensive specialized knowledge. Using the natural\nlanguage to Bash command (NL2SH) translation capabilities of large language\nmodels (LLMs) for command composition circumvents these issues. However, the\nNL2SH performance of LLMs is difficult to assess due to inaccurate test data\nand unreliable heuristics for determining the functional equivalence of Bash\ncommands. We present a manually verified test dataset of 600\ninstruction-command pairs and a training dataset of 40,939 pairs, increasing\nthe size of previous datasets by 441% and 135%, respectively. Further, we\npresent a novel functional equivalence heuristic that combines command\nexecution with LLM evaluation of command outputs. Our heuristic can determine\nthe functional equivalence of two Bash commands with 95% confidence, a 16%\nincrease over previous heuristics. Evaluation of popular LLMs using our test\ndataset and heuristic demonstrates that parsing, in-context learning, in-weight\nlearning, and constrained decoding can improve NL2SH accuracy by up to 32%. Our\nfindings emphasize the importance of dataset quality, execution-based\nevaluation and translation method for advancing NL2SH translation. Our code is\navailable at https://github.com/westenfelder/NL2SH",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.06858v1",
    "published_date": "2025-02-07 19:35:55 UTC",
    "updated_date": "2025-02-07 19:35:55 UTC"
  },
  {
    "arxiv_id": "2502.05234v1",
    "title": "Optimizing Temperature for Language Models with Multi-Sample Inference",
    "authors": [
      "Weihua Du",
      "Yiming Yang",
      "Sean Welleck"
    ],
    "abstract": "Multi-sample aggregation strategies, such as majority voting and best-of-N\nsampling, are widely used in contemporary large language models (LLMs) to\nenhance predictive accuracy across various tasks. A key challenge in this\nprocess is temperature selection, which significantly impacts model\nperformance. Existing approaches either rely on a fixed default temperature or\nrequire labeled validation data for tuning, which are often scarce and\ndifficult to obtain. This paper addresses the challenge of automatically\nidentifying the (near)-optimal temperature for different LLMs using\nmulti-sample aggregation strategies, without relying on task-specific\nvalidation data. We provide a comprehensive analysis of temperature's role in\nperformance optimization, considering variations in model architectures,\ndatasets, task types, model sizes, and predictive accuracy. Furthermore, we\npropose a novel entropy-based metric for automated temperature optimization,\nwhich consistently outperforms fixed-temperature baselines. Additionally, we\nincorporate a stochastic process model to enhance interpretability, offering\ndeeper insights into the relationship between temperature and model\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages. Code available at https://github.com/StigLidu/TURN",
    "pdf_url": "http://arxiv.org/pdf/2502.05234v1",
    "published_date": "2025-02-07 19:35:25 UTC",
    "updated_date": "2025-02-07 19:35:25 UTC"
  },
  {
    "arxiv_id": "2502.05282v1",
    "title": "Homeomorphism Prior for False Positive and Negative Problem in Medical Image Dense Contrastive Representation Learning",
    "authors": [
      "Yuting He",
      "Boyu Wang",
      "Rongjun Ge",
      "Yang Chen",
      "Guanyu Yang",
      "Shuo Li"
    ],
    "abstract": "Dense contrastive representation learning (DCRL) has greatly improved the\nlearning efficiency for image-dense prediction tasks, showing its great\npotential to reduce the large costs of medical image collection and dense\nannotation. However, the properties of medical images make unreliable\ncorrespondence discovery, bringing an open problem of large-scale false\npositive and negative (FP&N) pairs in DCRL. In this paper, we propose GEoMetric\nvIsual deNse sImilarity (GEMINI) learning which embeds the homeomorphism prior\nto DCRL and enables a reliable correspondence discovery for effective dense\ncontrast. We propose a deformable homeomorphism learning (DHL) which models the\nhomeomorphism of medical images and learns to estimate a deformable mapping to\npredict the pixels' correspondence under topological preservation. It\neffectively reduces the searching space of pairing and drives an implicit and\nsoft learning of negative pairs via a gradient. We also propose a geometric\nsemantic similarity (GSS) which extracts semantic information in features to\nmeasure the alignment degree for the correspondence learning. It will promote\nthe learning efficiency and performance of deformation, constructing positive\npairs reliably. We implement two practical variants on two typical\nrepresentation learning tasks in our experiments. Our promising results on\nseven datasets which outperform the existing methods show our great\nsuperiority. We will release our code on a companion link:\nhttps://github.com/YutingHe-list/GEMINI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by T-PAMI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05282v1",
    "published_date": "2025-02-07 19:34:22 UTC",
    "updated_date": "2025-02-07 19:34:22 UTC"
  },
  {
    "arxiv_id": "2502.05264v1",
    "title": "Quantum automated learning with provable and explainable trainability",
    "authors": [
      "Qi Ye",
      "Shuangyue Geng",
      "Zizhao Han",
      "Weikang Li",
      "L. -M. Duan",
      "Dong-Ling Deng"
    ],
    "abstract": "Machine learning is widely believed to be one of the most promising practical\napplications of quantum computing. Existing quantum machine learning schemes\ntypically employ a quantum-classical hybrid approach that relies crucially on\ngradients of model parameters. Such an approach lacks provable convergence to\nglobal minima and will become infeasible as quantum learning models scale up.\nHere, we introduce quantum automated learning, where no variational parameter\nis involved and the training process is converted to quantum state preparation.\nIn particular, we encode training data into unitary operations and iteratively\nevolve a random initial state under these unitaries and their inverses, with a\ntarget-oriented perturbation towards higher prediction accuracy sandwiched in\nbetween. Under reasonable assumptions, we rigorously prove that the evolution\nconverges exponentially to the desired state corresponding to the global\nminimum of the loss function. We show that such a training process can be\nunderstood from the perspective of preparing quantum states by imaginary time\nevolution, where the data-encoded unitaries together with target-oriented\nperturbations would train the quantum learning model in an automated fashion.\nWe further prove that the quantum automated learning paradigm features good\ngeneralization ability with the generalization error upper bounded by the ratio\nbetween a logarithmic function of the Hilbert space dimension and the number of\ntraining samples. In addition, we carry out extensive numerical simulations on\nreal-life images and quantum data to demonstrate the effectiveness of our\napproach and validate the assumptions. Our results establish an unconventional\nquantum learning strategy that is gradient-free with provable and explainable\ntrainability, which would be crucial for large-scale practical applications of\nquantum computing in machine learning scenarios.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "21 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05264v1",
    "published_date": "2025-02-07 19:00:02 UTC",
    "updated_date": "2025-02-07 19:00:02 UTC"
  },
  {
    "arxiv_id": "2503.04752v1",
    "title": "Transforming Student Evaluation with Adaptive Intelligence and Performance Analytics",
    "authors": [
      "Pushpalatha K S",
      "Abhishek Mangalur",
      "Ketan Hegde",
      "Chetan Badachi",
      "Mohammad Aamir"
    ],
    "abstract": "The development in Artificial Intelligence (AI) offers transformative\npotential for redefining student assessment methodologies. This paper aims to\nestablish the idea of the advancement of Artificial Intelligence (AI) and its\nprospect in reshaping approaches to assessing students. It creates a system for\nthe evaluation of students performance using Artificial intelligence, and\nparticularly the Gemini API for the generation of questions, grading and report\non the students performances. This is to facilitate easy use of the tools in\ncreating, scheduling, and delivering assessments with minimal chances of\ncheating through options such as full screen and time limit. There are formats\nof questions in the system which comprises multiple choice, short answers and\ndescriptive questions, developed by Gemini. The most conspicuous feature is the\nself-checking system whereby the user gets instant feedback for the correct\nscore that each of the students would have scored instantly with explanations\nabout wrong answers. Moreover, the platform has intelligent learning\nprogressions where the user will be able to monitor his/her performances to be\nrecommended a certain level of performance. It will allow students as well as\neducators to have real-time analytics and feedback on what they are good at and\nwhere they need to improve. Not only does it make the assessment easier, but it\nalso improves the levels of accuracy in grading and effectively strengthens a\ndata based learning process for students.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.04752v1",
    "published_date": "2025-02-07 18:57:51 UTC",
    "updated_date": "2025-02-07 18:57:51 UTC"
  },
  {
    "arxiv_id": "2502.05174v2",
    "title": "MELON: Provable Indirect Prompt Injection Defense via Masked Re-execution and Tool Comparison",
    "authors": [
      "Kaijie Zhu",
      "Xianjun Yang",
      "Jindong Wang",
      "Wenbo Guo",
      "William Yang Wang"
    ],
    "abstract": "Recent research has explored that LLM agents are vulnerable to indirect\nprompt injection (IPI) attacks, where malicious tasks embedded in\ntool-retrieved information can redirect the agent to take unauthorized actions.\nExisting defenses against IPI have significant limitations: either require\nessential model training resources, lack effectiveness against sophisticated\nattacks, or harm the normal utilities. We present MELON (Masked re-Execution\nand TooL comparisON), a novel IPI defense. Our approach builds on the\nobservation that under a successful attack, the agent's next action becomes\nless dependent on user tasks and more on malicious tasks. Following this, we\ndesign MELON to detect attacks by re-executing the agent's trajectory with a\nmasked user prompt modified through a masking function. We identify an attack\nif the actions generated in the original and masked executions are similar. We\nalso include three key designs to reduce the potential false positives and\nfalse negatives. Extensive evaluation on the IPI benchmark AgentDojo\ndemonstrates that MELON outperforms SOTA defenses in both attack prevention and\nutility preservation. Moreover, we show that combining MELON with a SOTA prompt\naugmentation defense (denoted as MELON-Aug) further improves its performance.\nWe also conduct a detailed ablation study to validate our key designs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05174v2",
    "published_date": "2025-02-07 18:57:49 UTC",
    "updated_date": "2025-05-01 20:51:22 UTC"
  },
  {
    "arxiv_id": "2502.05172v2",
    "title": "Joint MoE Scaling Laws: Mixture of Experts Can Be Memory Efficient",
    "authors": [
      "Jan Ludziejewski",
      "Maciej Pióro",
      "Jakub Krajewski",
      "Maciej Stefaniak",
      "Michał Krutul",
      "Jan Małaśnicki",
      "Marek Cygan",
      "Piotr Sankowski",
      "Kamil Adamczewski",
      "Piotr Miłoś",
      "Sebastian Jaszczur"
    ],
    "abstract": "Mixture of Experts (MoE) architectures have significantly increased\ncomputational efficiency in both research and real-world applications of\nlarge-scale machine learning models. However, their scalability and efficiency\nunder memory constraints remain relatively underexplored. In this work, we\npresent joint scaling laws for dense and MoE models, incorporating key factors\nsuch as the number of active parameters, dataset size, and the number of\nexperts. Our findings provide a principled framework for selecting the optimal\nMoE configuration under fixed memory and compute budgets. Surprisingly, we show\nthat MoE models can be more memory-efficient than dense models, contradicting\nconventional wisdom. To derive and validate the theoretical predictions of our\nscaling laws, we conduct over 280 experiments with up to 2.7B active parameters\nand up to 5B total parameters. These results offer actionable insights for\ndesigning and deploying MoE models in practical large-scale training scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05172v2",
    "published_date": "2025-02-07 18:55:38 UTC",
    "updated_date": "2025-02-19 14:36:33 UTC"
  },
  {
    "arxiv_id": "2502.05151v2",
    "title": "Transforming Science with Large Language Models: A Survey on AI-assisted Scientific Discovery, Experimentation, Content Generation, and Evaluation",
    "authors": [
      "Steffen Eger",
      "Yong Cao",
      "Jennifer D'Souza",
      "Andreas Geiger",
      "Christian Greisinger",
      "Stephanie Gross",
      "Yufang Hou",
      "Brigitte Krenn",
      "Anne Lauscher",
      "Yizhi Li",
      "Chenghua Lin",
      "Nafise Sadat Moosavi",
      "Wei Zhao",
      "Tristan Miller"
    ],
    "abstract": "With the advent of large multimodal language models, science is now at a\nthreshold of an AI-based technological transformation. Recently, a plethora of\nnew AI models and tools has been proposed, promising to empower researchers and\nacademics worldwide to conduct their research more effectively and efficiently.\nThis includes all aspects of the research cycle, especially (1) searching for\nrelevant literature; (2) generating research ideas and conducting\nexperimentation; generating (3) text-based and (4) multimodal content (e.g.,\nscientific figures and diagrams); and (5) AI-based automatic peer review. In\nthis survey, we provide an in-depth overview over these exciting recent\ndevelopments, which promise to fundamentally alter the scientific research\nprocess for good. Our survey covers the five aspects outlined above, indicating\nrelevant datasets, methods and results (including evaluation) as well as\nlimitations and scope for future research. Ethical concerns regarding\nshortcomings of these tools and potential for misuse (fake science, plagiarism,\nharms to research integrity) take a particularly prominent place in our\ndiscussion. We hope that our survey will not only become a reference guide for\nnewcomers to the field but also a catalyst for new AI-based initiatives in the\narea of \"AI4Science\".",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "44 pages, 7 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.05151v2",
    "published_date": "2025-02-07 18:26:45 UTC",
    "updated_date": "2025-04-16 10:54:12 UTC"
  },
  {
    "arxiv_id": "2502.05147v3",
    "title": "LP-DETR: Layer-wise Progressive Relations for Object Detection",
    "authors": [
      "Zhengjian Kang",
      "Ye Zhang",
      "Xiaoyu Deng",
      "Xintao Li",
      "Yongzhe Zhang"
    ],
    "abstract": "This paper presents LP-DETR (Layer-wise Progressive DETR), a novel approach\nthat enhances DETR-based object detection through multi-scale relation\nmodeling. Our method introduces learnable spatial relationships between object\nqueries through a relation-aware self-attention mechanism, which adaptively\nlearns to balance different scales of relations (local, medium and global)\nacross decoder layers. This progressive design enables the model to effectively\ncapture evolving spatial dependencies throughout the detection pipeline.\nExtensive experiments on COCO 2017 dataset demonstrate that our method improves\nboth convergence speed and detection accuracy compared to standard\nself-attention module. The proposed method achieves competitive results,\nreaching 52.3\\% AP with 12 epochs and 52.5\\% AP with 24 epochs using ResNet-50\nbackbone, and further improving to 58.0\\% AP with Swin-L backbone. Furthermore,\nour analysis reveals an interesting pattern: the model naturally learns to\nprioritize local spatial relations in early decoder layers while gradually\nshifting attention to broader contexts in deeper layers, providing valuable\ninsights for future research in object detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05147v3",
    "published_date": "2025-02-07 18:25:28 UTC",
    "updated_date": "2025-05-12 22:15:02 UTC"
  },
  {
    "arxiv_id": "2502.06857v1",
    "title": "Gemstones: A Model Suite for Multi-Faceted Scaling Laws",
    "authors": [
      "Sean McLeish",
      "John Kirchenbauer",
      "David Yu Miller",
      "Siddharth Singh",
      "Abhinav Bhatele",
      "Micah Goldblum",
      "Ashwinee Panda",
      "Tom Goldstein"
    ],
    "abstract": "Scaling laws are typically fit using a family of models with a narrow range\nof frozen hyper-parameter choices. In this work we study scaling laws using a\nwide range of architecture and hyper-parameter choices, and highlight their\nimpact on resulting prescriptions. As a primary artifact of our research, we\nrelease the Gemstones: the most comprehensive open-source scaling law dataset\nto date, consisting of over 4000 checkpoints from transformers with up to 2\nbillion parameters; these models have been trained with different learning\nrates, cooldown schedules, and architectural shapes. Our checkpoints enable\nmore complex studies of scaling, such as a law that predicts language modeling\nperformance as a function of model width and depth. By examining the various\nfacets of our model suite, we find that the prescriptions of scaling laws can\nbe highly sensitive to the experimental design process and the specific model\ncheckpoints used during fitting. Code:\nhttps://github.com/mcleish7/gemstone-scaling-laws",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06857v1",
    "published_date": "2025-02-07 18:09:38 UTC",
    "updated_date": "2025-02-07 18:09:38 UTC"
  },
  {
    "arxiv_id": "2502.05130v2",
    "title": "Latent Swap Joint Diffusion for 2D Long-Form Latent Generation",
    "authors": [
      "Yusheng Dai",
      "Chenxi Wang",
      "Chang Li",
      "Chen Wang",
      "Jun Du",
      "Kewei Li",
      "Ruoyu Wang",
      "Jiefeng Ma",
      "Lei Sun",
      "Jianqing Gao"
    ],
    "abstract": "This paper introduces Swap Forward (SaFa), a modality-agnostic and efficient\nmethod to generate seamless and coherence long spectrum and panorama through\nlatent swap joint diffusion across multi-views. We first investigate the\nspectrum aliasing problem in spectrum-based audio generation caused by existing\njoint diffusion methods. Through a comparative analysis of the VAE latent\nrepresentation of Mel-spectra and RGB images, we identify that the failure\narises from excessive suppression of high-frequency components during the\nspectrum denoising process due to the averaging operator. To address this\nissue, we propose Self-Loop Latent Swap, a frame-level bidirectional swap\napplied to the overlapping region of adjacent views. Leveraging stepwise\ndifferentiated trajectories of adjacent subviews, this swap operator adaptively\nenhances high-frequency components and avoid spectrum distortion. Furthermore,\nto improve global cross-view consistency in non-overlapping regions, we\nintroduce Reference-Guided Latent Swap, a unidirectional latent swap operator\nthat provides a centralized reference trajectory to synchronize subview\ndiffusions. By refining swap timing and intervals, we can achieve a cross-view\nsimilarity-diversity balance in a forward-only manner. Quantitative and\nqualitative experiments demonstrate that SaFa significantly outperforms\nexisting joint diffusion methods and even training-based methods in audio\ngeneration using both U-Net and DiT models, along with effective longer length\nadaptation. It also adapts well to panorama generation, achieving comparable\nperformance with 2 $\\sim$ 20 $\\times$ faster speed and greater model\ngeneralizability. More generation demos are available at\nhttps://swapforward.github.io/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05130v2",
    "published_date": "2025-02-07 18:02:47 UTC",
    "updated_date": "2025-03-18 04:31:39 UTC"
  },
  {
    "arxiv_id": "2502.06855v2",
    "title": "Self-Supervised Prompt Optimization",
    "authors": [
      "Jinyu Xiang",
      "Jiayi Zhang",
      "Zhaoyang Yu",
      "Fengwei Teng",
      "Jinhao Tu",
      "Xinbing Liang",
      "Sirui Hong",
      "Chenglin Wu",
      "Yuyu Luo"
    ],
    "abstract": "Well-designed prompts are crucial for enhancing Large language models' (LLMs)\nreasoning capabilities while aligning their outputs with task requirements\nacross diverse domains. However, manually designed prompts require expertise\nand iterative experimentation. While existing prompt optimization methods aim\nto automate this process, they rely heavily on external references such as\nground truth or by humans, limiting their applicability in real-world scenarios\nwhere such data is unavailable or costly to obtain. To address this, we propose\nSelf-Supervised Prompt Optimization (SPO), a cost-efficient framework that\ndiscovers effective prompts for both closed and open-ended tasks without\nrequiring external reference. Motivated by the observations that prompt quality\nmanifests directly in LLM outputs and LLMs can effectively assess adherence to\ntask requirements, we derive evaluation and optimization signals purely from\noutput comparisons. Specifically, SPO selects superior prompts through pairwise\noutput comparisons evaluated by an LLM evaluator, followed by an LLM optimizer\nthat aligns outputs with task requirements. Extensive experiments demonstrate\nthat SPO outperforms state-of-the-art prompt optimization methods, achieving\ncomparable or superior results with significantly lower costs (e.g., 1.1% to\n5.6% of existing methods) and fewer samples (e.g., three samples). The code is\navailable at https://github.com/geekan/MetaGPT/blob/main/examples/spo",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06855v2",
    "published_date": "2025-02-07 17:45:16 UTC",
    "updated_date": "2025-02-15 08:16:52 UTC"
  },
  {
    "arxiv_id": "2502.05115v2",
    "title": "\"It Felt Like I Was Left in the Dark\": Exploring Information Needs and Design Opportunities for Family Caregivers of Older Adult Patients in Critical Care Settings",
    "authors": [
      "Shihan Fu",
      "Bingsheng Yao",
      "Smit Desai",
      "Yuqi Hu",
      "Yuling Sun",
      "Samantha Stonbraker",
      "Yanjun Gao",
      "Elizabeth M. Goldberg",
      "Dakuo Wang"
    ],
    "abstract": "Older adult patients constitute a rapidly growing subgroup of Intensive Care\nUnit (ICU) patients. In these situations, their family caregivers are expected\nto represent the unconscious patients to access and interpret patients' medical\ninformation. However, caregivers currently have to rely on overloaded\nclinicians for information updates and typically lack the health literacy to\nunderstand complex medical information. Our project aims to explore the\ninformation needs of caregivers of ICU older adult patients, from which we can\npropose design opportunities to guide future AI systems. The project begins\nwith formative interviews with 11 caregivers to identify their challenges in\naccessing and interpreting medical information; From these findings, we then\nsynthesize design requirements and propose an AI system prototype to cope with\ncaregivers' challenges. The system prototype has two key features: a timeline\nvisualization to show the AI extracted and summarized older adult patients' key\nmedical events; and an LLM-based chatbot to provide context-aware informational\nsupport. We conclude our paper by reporting on the follow-up user evaluation of\nthe system and discussing future AI-based systems for ICU caregivers of older\nadults.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05115v2",
    "published_date": "2025-02-07 17:38:10 UTC",
    "updated_date": "2025-04-05 02:29:51 UTC"
  },
  {
    "arxiv_id": "2502.05111v1",
    "title": "Flexible and Efficient Grammar-Constrained Decoding",
    "authors": [
      "Kanghee Park",
      "Timothy Zhou",
      "Loris D'Antoni"
    ],
    "abstract": "Large Language Models (LLMs) are often asked to generate structured outputs\nthat obey precise syntactic rules, such as code snippets or formatted data.\nGrammar-constrained decoding (GCD) can guarantee that LLM outputs matches such\nrules by masking out tokens that will provably lead to outputs that do not\nbelong to a specified context-free grammar (CFG). To guarantee soundness, GCD\nalgorithms have to compute how a given LLM subword tokenizer can align with the\ntokens used\n  by a given context-free grammar and compute token masks based on this\ninformation. Doing so efficiently is challenging and existing GCD algorithms\nrequire tens of minutes to preprocess common grammars. We present a new GCD\nalgorithm together with an implementation that offers 17.71x faster offline\npreprocessing than existing approaches while preserving state-of-the-art\nefficiency in online mask computation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05111v1",
    "published_date": "2025-02-07 17:35:17 UTC",
    "updated_date": "2025-02-07 17:35:17 UTC"
  },
  {
    "arxiv_id": "2502.05110v1",
    "title": "ApplE: An Applied Ethics Ontology with Event Context",
    "authors": [
      "Aisha Aijaz",
      "Raghava Mutharaju",
      "Manohar Kumar"
    ],
    "abstract": "Applied ethics is ubiquitous in most domains, requiring much deliberation due\nto its philosophical nature. Varying views often lead to conflicting courses of\naction where ethical dilemmas become challenging to resolve. Although many\nfactors contribute to such a decision, the major driving forces can be\ndiscretized and thus simplified to provide an indicative answer. Knowledge\nrepresentation and reasoning offer a way to explicitly translate abstract\nethical concepts into applicable principles within the context of an event. To\nachieve this, we propose ApplE, an Applied Ethics ontology that captures\nphilosophical theory and event context to holistically describe the morality of\nan action. The development process adheres to a modified version of the\nSimplified Agile Methodology for Ontology Development (SAMOD) and utilizes\nstandard design and publication practices. Using ApplE, we model a use case\nfrom the bioethics domain that demonstrates our ontology's social and\nscientific value. Apart from the ontological reasoning and quality checks,\nApplE is also evaluated using the three-fold testing process of SAMOD. ApplE\nfollows FAIR principles and aims to be a viable resource for applied ethicists\nand ontology engineers.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05110v1",
    "published_date": "2025-02-07 17:34:50 UTC",
    "updated_date": "2025-02-07 17:34:50 UTC"
  },
  {
    "arxiv_id": "2502.05104v1",
    "title": "Leveraging Hypernetworks and Learnable Kernels for Consumer Energy Forecasting Across Diverse Consumer Types",
    "authors": [
      "Muhammad Umair Danish",
      "Katarina Grolinger"
    ],
    "abstract": "Consumer energy forecasting is essential for managing energy consumption and\nplanning, directly influencing operational efficiency, cost reduction,\npersonalized energy management, and sustainability efforts. In recent years,\ndeep learning techniques, especially LSTMs and transformers, have been greatly\nsuccessful in the field of energy consumption forecasting. Nevertheless, these\ntechniques have difficulties in capturing complex and sudden variations, and,\nmoreover, they are commonly examined only on a specific type of consumer (e.g.,\nonly offices, only schools). Consequently, this paper proposes HyperEnergy, a\nconsumer energy forecasting strategy that leverages hypernetworks for improved\nmodeling of complex patterns applicable across a diversity of consumers.\nHypernetwork is responsible for predicting the parameters of the primary\nprediction network, in our case LSTM. A learnable adaptable kernel, comprised\nof polynomial and radial basis function kernels, is incorporated to enhance\nperformance. The proposed HyperEnergy was evaluated on diverse consumers\nincluding, student residences, detached homes, a home with electric vehicle\ncharging, and a townhouse. Across all consumer types, HyperEnergy consistently\noutperformed 10 other techniques, including state-of-the-art models such as\nLSTM, AttentionLSTM, and transformer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05104v1",
    "published_date": "2025-02-07 17:25:54 UTC",
    "updated_date": "2025-02-07 17:25:54 UTC"
  },
  {
    "arxiv_id": "2502.06854v1",
    "title": "Can Large Language Models Understand Intermediate Representations?",
    "authors": [
      "Hailong Jiang",
      "Jianfeng Zhu",
      "Yao Wan",
      "Bo Fang",
      "Hongyu Zhang",
      "Ruoming Jin",
      "Qiang Guan"
    ],
    "abstract": "Intermediate Representations (IRs) are essential in compiler design and\nprogram analysis, yet their comprehension by Large Language Models (LLMs)\nremains underexplored. This paper presents a pioneering empirical study to\ninvestigate the capabilities of LLMs, including GPT-4, GPT-3, Gemma 2, LLaMA\n3.1, and Code Llama, in understanding IRs. We analyze their performance across\nfour tasks: Control Flow Graph (CFG) reconstruction, decompilation, code\nsummarization, and execution reasoning. Our results indicate that while LLMs\ndemonstrate competence in parsing IR syntax and recognizing high-level\nstructures, they struggle with control flow reasoning, execution semantics, and\nloop handling. Specifically, they often misinterpret branching instructions,\nomit critical IR operations, and rely on heuristic-based reasoning, leading to\nerrors in CFG reconstruction, IR decompilation, and execution reasoning. The\nstudy underscores the necessity for IR-specific enhancements in LLMs,\nrecommending fine-tuning on structured IR datasets and integration of explicit\ncontrol flow models to augment their comprehension and handling of IR-related\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06854v1",
    "published_date": "2025-02-07 17:23:48 UTC",
    "updated_date": "2025-02-07 17:23:48 UTC"
  },
  {
    "arxiv_id": "2502.05253v1",
    "title": "LLMs Can Teach Themselves to Better Predict the Future",
    "authors": [
      "Benjamin Turtel",
      "Danny Franklin",
      "Philipp Schoenegger"
    ],
    "abstract": "We present an outcome-driven fine-tuning framework that enhances the\nforecasting capabilities of large language models (LLMs) without relying on\nhuman-curated reasoning samples. Our method leverages model self-play to\ngenerate pairs of diverse reasoning trajectories and probabilistic forecasts\nfor a set of diverse questions that resolve after the models' knowledge cutoff\ndate. We then rank pairs of these reasoning traces by their distance to the\nactual outcomes before fine-tuning the model via Direct Preference Optimization\n(DPO). On a separate test set, our approach increases prediction accuracy of\nPhi-4 14B and DeepSeek-R1 14B by between 7--10\\% over a base model and a DPO\nfine-tuned control model with randomized labels, bringing them on par with\nforecasting capabilities of much larger frontier models like GPT-4o.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05253v1",
    "published_date": "2025-02-07 17:21:16 UTC",
    "updated_date": "2025-02-07 17:21:16 UTC"
  },
  {
    "arxiv_id": "2502.05098v1",
    "title": "Learning Temporal Invariance in Android Malware Detectors",
    "authors": [
      "Xinran Zheng",
      "Shuo Yang",
      "Edith C. H. Ngai",
      "Suman Jana",
      "Lorenzo Cavallaro"
    ],
    "abstract": "Learning-based Android malware detectors degrade over time due to natural\ndistribution drift caused by malware variants and new families. This paper\nsystematically investigates the challenges classifiers trained with empirical\nrisk minimization (ERM) face against such distribution shifts and attributes\ntheir shortcomings to their inability to learn stable discriminative features.\nInvariant learning theory offers a promising solution by encouraging models to\ngenerate stable representations crossing environments that expose the\ninstability of the training set. However, the lack of prior environment labels,\nthe diversity of drift factors, and low-quality representations caused by\ndiverse families make this task challenging. To address these issues, we\npropose TIF, the first temporal invariant training framework for malware\ndetection, which aims to enhance the ability of detectors to learn stable\nrepresentations across time. TIF organizes environments based on application\nobservation dates to reveal temporal drift, integrating specialized multi-proxy\ncontrastive learning and invariant gradient alignment to generate and align\nenvironments with high-quality, stable representations. TIF can be seamlessly\nintegrated into any learning-based detector. Experiments on a decade-long\ndataset show that TIF excels, particularly in early deployment stages,\naddressing real-world needs and outperforming state-of-the-art methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05098v1",
    "published_date": "2025-02-07 17:17:42 UTC",
    "updated_date": "2025-02-07 17:17:42 UTC"
  },
  {
    "arxiv_id": "2502.05092v2",
    "title": "Lost in Time: Clock and Calendar Understanding Challenges in Multimodal LLMs",
    "authors": [
      "Rohit Saxena",
      "Aryo Pradipta Gema",
      "Pasquale Minervini"
    ],
    "abstract": "Understanding time from visual representations is a fundamental cognitive\nskill, yet it remains a challenge for multimodal large language models (MLLMs).\nIn this work, we investigate the capabilities of MLLMs in interpreting time and\ndate through analogue clocks and yearly calendars. To facilitate this, we\ncurated a structured dataset comprising two subsets: 1) $\\textit{ClockQA}$,\nwhich comprises various types of clock styles$-$standard, black-dial,\nno-second-hand, Roman numeral, and arrow-hand clocks$-$paired with time related\nquestions; and 2) $\\textit{CalendarQA}$, which consists of yearly calendar\nimages with questions ranging from commonly known dates (e.g., Christmas, New\nYear's Day) to computationally derived ones (e.g., the 100th or 153rd day of\nthe year). We aim to analyse how MLLMs can perform visual recognition,\nnumerical reasoning, and temporal inference when presented with time-related\nvisual data. Our evaluations show that despite recent advancements, reliably\nunderstanding time remains a significant challenge for MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the ICLR 2025 Workshop on Reasoning and Planning for\n  Large Language Models",
    "pdf_url": "http://arxiv.org/pdf/2502.05092v2",
    "published_date": "2025-02-07 17:11:23 UTC",
    "updated_date": "2025-03-18 11:43:52 UTC"
  },
  {
    "arxiv_id": "2502.05252v1",
    "title": "GSM-Infinite: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?",
    "authors": [
      "Yang Zhou",
      "Hongyi Liu",
      "Zhuoming Chen",
      "Yuandong Tian",
      "Beidi Chen"
    ],
    "abstract": "Long-context large language models (LLMs) have recently shown strong\nperformance in information retrieval and long-document QA. However, to tackle\nthe most challenging intellectual problems, LLMs must reason effectively in\nlong and complex contexts (e.g., frontier mathematical research). Studying how\nLLMs handle increasing reasoning complexity and context length is essential,\nyet existing benchmarks lack a solid basis for quantitative evaluation.\nInspired by the abstraction of GSM-8K problems as computational graphs, and the\nability to introduce noise by adding unnecessary nodes and edges, we develop a\ngrade school math problem generator capable of producing arithmetic problems\nwith infinite difficulty and context length under fine-grained control. Using\nour newly synthesized GSM-Infinite benchmark, we comprehensively evaluate\nexisting LLMs. We find a consistent sigmoid decline in reasoning performance as\ncomplexity increases, along with a systematic inference scaling trend:\nexponentially increasing inference computation yields only linear performance\ngains. These findings underscore the fundamental limitations of current\nlong-context LLMs and the key challenges in scaling reasoning capabilities. Our\nGSM-Infinite benchmark provides a scalable and controllable testbed for\nsystematically studying and advancing LLM reasoning in long and complex\ncontexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05252v1",
    "published_date": "2025-02-07 17:05:25 UTC",
    "updated_date": "2025-02-07 17:05:25 UTC"
  },
  {
    "arxiv_id": "2502.05087v2",
    "title": "Mitigating Unintended Memorization with LoRA in Federated Learning for LLMs",
    "authors": [
      "Thierry Bossy",
      "Julien Vignoud",
      "Tahseen Rabbani",
      "Juan R. Troncoso Pastoriza",
      "Martin Jaggi"
    ],
    "abstract": "Federated learning (FL) is a popular paradigm for collaborative training\nwhich avoids direct data exposure between clients. However, data privacy issues\nstill remain: FL-trained large language models are capable of memorizing and\ncompleting phrases and sentences contained in training data when given with\ntheir prefixes. Thus, it is possible for adversarial and honest-but-curious\nclients to recover training data of other participants simply through targeted\nprompting. In this work, we demonstrate that a popular and simple fine-tuning\nstrategy, low-rank adaptation (LoRA), reduces memorization during FL up to a\nfactor of 10. We study this effect by performing a medical question-answering\nfine-tuning task and injecting multiple replicas of out-of-distribution\nsensitive sequences drawn from an external clinical dataset. We observe a\nreduction in memorization for a wide variety of Llama 2 and 3 models, and find\nthat LoRA can reduce memorization in centralized learning as well. Furthermore,\nwe show that LoRA can be combined with other privacy-preserving techniques such\nas gradient clipping and Gaussian noising, secure aggregation, and Goldfish\nloss to further improve record-level privacy while maintaining performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05087v2",
    "published_date": "2025-02-07 17:04:39 UTC",
    "updated_date": "2025-02-27 11:04:13 UTC"
  },
  {
    "arxiv_id": "2502.05085v1",
    "title": "Causality can systematically address the monsters under the bench(marks)",
    "authors": [
      "Felix Leeb",
      "Zhijing Jin",
      "Bernhard Schölkopf"
    ],
    "abstract": "Effective and reliable evaluation is essential for advancing empirical\nmachine learning. However, the increasing accessibility of generalist models\nand the progress towards ever more complex, high-level tasks make systematic\nevaluation more challenging. Benchmarks are plagued by various biases,\nartifacts, or leakage, while models may behave unreliably due to poorly\nexplored failure modes. Haphazard treatments and inconsistent formulations of\nsuch \"monsters\" can contribute to a duplication of efforts, a lack of trust in\nresults, and unsupported inferences. In this position paper, we argue causality\noffers an ideal framework to systematically address these challenges. By making\ncausal assumptions in an approach explicit, we can faithfully model phenomena,\nformulate testable hypotheses with explanatory power, and leverage principled\ntools for analysis. To make causal model design more accessible, we identify\nseveral useful Common Abstract Topologies (CATs) in causal graphs which help\ngain insight into the reasoning abilities in large language models. Through a\nseries of case studies, we demonstrate how the precise yet pragmatic language\nof causality clarifies the strengths and limitations of a method and inspires\nnew approaches for systematic progress.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05085v1",
    "published_date": "2025-02-07 17:01:37 UTC",
    "updated_date": "2025-02-07 17:01:37 UTC"
  },
  {
    "arxiv_id": "2502.05084v1",
    "title": "ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework",
    "authors": [
      "Xiaoyu Deng",
      "Ye Zhang",
      "Tianmin Guo",
      "Yongzhe Zhang",
      "Zhengjian Kang",
      "Hang Yang"
    ],
    "abstract": "The astonishing performance of large language models (LLMs) and their\nremarkable achievements in production and daily life have led to their\nwidespread application in collaborative tasks. However, current large models\nface challenges such as hallucination and lack of specificity in content\ngeneration in vertical domain tasks. Inspired by the contrast and\nclassification mechanisms in human cognitive processes, this paper constructs\nan adversarial learning-based prompt framework named ChallengeMe, which\nincludes three cascaded solutions: generation prompts, evaluation prompts, and\nfeedback optimization. In this process, we designed seven core optimization\ndimensions and set the threshold for adversarial learning. The results of mixed\ncase studies on the text summarization task show that the proposed framework\ncan generate more accurate and fluent text summaries compared to the current\nadvanced mainstream LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05084v1",
    "published_date": "2025-02-07 16:59:34 UTC",
    "updated_date": "2025-02-07 16:59:34 UTC"
  },
  {
    "arxiv_id": "2502.06853v1",
    "title": "Native Fortran Implementation of TensorFlow-Trained Deep and Bayesian Neural Networks",
    "authors": [
      "Aidan Furlong",
      "Xingang Zhao",
      "Bob Salko",
      "Xu Wu"
    ],
    "abstract": "Over the past decade, the investigation of machine learning (ML) within the\nfield of nuclear engineering has grown significantly. With many approaches\nreaching maturity, the next phase of investigation will determine the\nfeasibility and usefulness of ML model implementation in a production setting.\nSeveral of the codes used for reactor design and assessment are primarily\nwritten in the Fortran language, which is not immediately compatible with\nTensorFlow-trained ML models. This study presents a framework for implementing\ndeep neural networks (DNNs) and Bayesian neural networks (BNNs) in Fortran,\nallowing for native execution without TensorFlow's C API, Python runtime, or\nONNX conversion. Designed for ease of use and computational efficiency, the\nframework can be implemented in any Fortran code, supporting iterative solvers\nand UQ via ensembles or BNNs. Verification was performed using a two-input,\none-output test case composed of a noisy sinusoid to compare Fortran-based\npredictions to those from TensorFlow. The DNN predictions showed negligible\ndifferences and achieved a 19.6x speedup, whereas the BNN predictions exhibited\nminor disagreement, plausibly due to differences in random number generation.\nAn 8.0x speedup was noted for BNN inference. The approach was then further\nverified on a nuclear-relevant problem predicting critical heat flux (CHF),\nwhich demonstrated similar behavior along with significant computational gains.\nDiscussion regarding the framework's successful integration into the CTF\nthermal-hydraulics code is also included, outlining its practical usefulness.\nOverall, this framework was shown to be effective at implementing both DNN and\nBNN model inference within Fortran, allowing for the continued study of\nML-based methods in real-world nuclear applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted for inclusion in the 2025 American Nuclear Society Annual\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2502.06853v1",
    "published_date": "2025-02-07 16:58:51 UTC",
    "updated_date": "2025-02-07 16:58:51 UTC"
  },
  {
    "arxiv_id": "2502.05078v1",
    "title": "Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures",
    "authors": [
      "Tushar Pandey",
      "Ara Ghukasyan",
      "Oktay Goktas",
      "Santosh Kumar Radha"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning\ncapabilities, yet their performance is highly dependent on the prompting\nstrategy and model scale. While reinforcement learning and fine-tuning have\nbeen deployed to boost reasoning, these approaches incur substantial\ncomputational and data overhead. In this work, we introduce Adaptive Graph of\nThoughts (AGoT), a dynamic, graph-based inference framework that enhances LLM\nreasoning solely at test time. Rather than relying on fixed-step methods like\nChain of Thought (CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes\ncomplex queries into structured subproblems, forming an dynamic directed\nacyclic graph (DAG) of interdependent reasoning steps. By selectively expanding\nonly those subproblems that require further analysis, AGoT unifies the\nstrengths of chain, tree, and graph paradigms into a cohesive framework that\nallocates computation where it is most needed. We validate our approach on\ndiverse benchmarks spanning multi-hop retrieval, scientific reasoning, and\nmathematical problem-solving, achieving up to 46.2% improvement on scientific\nreasoning tasks (GPQA) - comparable to gains achieved through computationally\nintensive reinforcement learning approaches and outperforming state-of-the-art\niterative approaches. These results suggest that dynamic decomposition and\nstructured recursion offer a scalable, cost-effective alternative to\npost-training modifications, paving the way for more robust, general-purpose\nreasoning in LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05078v1",
    "published_date": "2025-02-07 16:54:19 UTC",
    "updated_date": "2025-02-07 16:54:19 UTC"
  },
  {
    "arxiv_id": "2502.05063v1",
    "title": "Computing and Learning on Combinatorial Data",
    "authors": [
      "Simon Zhang"
    ],
    "abstract": "The twenty-first century is a data-driven era where human activities and\nbehavior, physical phenomena, scientific discoveries, technology advancements,\nand almost everything that happens in the world resulting in massive\ngeneration, collection, and utilization of data.\n  Connectivity in data is a crucial property. A straightforward example is the\nWorld Wide Web, where every webpage is connected to other web pages through\nhyperlinks, providing a form of directed connectivity. Combinatorial data\nrefers to combinations of data items based on certain connectivity rules. Other\nforms of combinatorial data include social networks, meshes, community\nclusters, set systems, and molecules.\n  This Ph.D. dissertation focuses on learning and computing with combinatorial\ndata. We study and examine topological and connectivity features within and\nacross connected data to improve the performance of learning and achieve high\nalgorithmic efficiency.",
    "categories": [
      "cs.AI",
      "cs.DM",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "Ph.D. dissertation, 503 pages, 66 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05063v1",
    "published_date": "2025-02-07 16:35:06 UTC",
    "updated_date": "2025-02-07 16:35:06 UTC"
  },
  {
    "arxiv_id": "2502.05060v1",
    "title": "Preference-aware compensation policies for crowdsourced on-demand services",
    "authors": [
      "Georgina Nouli",
      "Axel Parmentier",
      "Maximilian Schiffer"
    ],
    "abstract": "Crowdsourced on-demand services offer benefits such as reduced costs, faster\nservice fulfillment times, greater adaptability, and contributions to\nsustainable urban transportation in on-demand delivery contexts. However, the\nsuccess of an on-demand platform that utilizes crowdsourcing relies on finding\na compensation policy that strikes a balance between creating attractive offers\nfor gig workers and ensuring profitability. In this work, we examine a dynamic\npricing problem for an on-demand platform that sets request-specific\ncompensation of gig workers in a discrete-time framework, where requests and\nworkers arrive stochastically. The operator's goal is to determine a\ncompensation policy that maximizes the total expected reward over the time\nhorizon. Our approach introduces compensation strategies that explicitly\naccount for gig worker request preferences. To achieve this, we employ the\nMultinomial Logit model to represent the acceptance probabilities of gig\nworkers, and, as a result, derive an analytical solution that utilizes\npost-decision states. Subsequently, we integrate this solution into an\napproximate dynamic programming algorithm. We compare our algorithm against\nbenchmark algorithms, including formula-based policies and an upper bound\nprovided by the full information linear programming solution. Our algorithm\ndemonstrates consistent performance across diverse settings, achieving\nimprovements of at least 2.5-7.5% in homogeneous gig worker populations and 9%\nin heterogeneous populations over benchmarks, based on fully synthetic data.\nFor real-world data, it surpasses benchmarks by 8% in weak and 20% in strong\nlocation preference scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05060v1",
    "published_date": "2025-02-07 16:33:16 UTC",
    "updated_date": "2025-02-07 16:33:16 UTC"
  },
  {
    "arxiv_id": "2502.05055v1",
    "title": "Differentiable Mobile Display Photometric Stereo",
    "authors": [
      "Gawoon Ban",
      "Hyeongjun Kim",
      "Seokjun Choi",
      "Seungwoo Yoon",
      "Seung-Hwan Baek"
    ],
    "abstract": "Display photometric stereo uses a display as a programmable light source to\nilluminate a scene with diverse illumination conditions. Recently,\ndifferentiable display photometric stereo (DDPS) demonstrated improved normal\nreconstruction accuracy by using learned display patterns. However, DDPS faced\nlimitations in practicality, requiring a fixed desktop imaging setup using a\npolarization camera and a desktop-scale monitor. In this paper, we propose a\nmore practical physics-based photometric stereo, differentiable mobile display\nphotometric stereo (DMDPS), that leverages a mobile phone consisting of a\ndisplay and a camera. We overcome the limitations of using a mobile device by\ndeveloping a mobile app and method that simultaneously displays patterns and\ncaptures high-quality HDR images. Using this technique, we capture real-world\n3D-printed objects and learn display patterns via a differentiable learning\nprocess. We demonstrate the effectiveness of DMDPS on both a 3D printed dataset\nand a first dataset of fallen leaves. The leaf dataset contains reconstructed\nsurface normals and albedos of fallen leaves that may enable future research\nbeyond computer graphics and vision. We believe that DMDPS takes a step forward\nfor practical physics-based photometric stereo.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05055v1",
    "published_date": "2025-02-07 16:24:56 UTC",
    "updated_date": "2025-02-07 16:24:56 UTC"
  },
  {
    "arxiv_id": "2502.05248v1",
    "title": "Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires",
    "authors": [
      "Pranav Bhandari",
      "Usman Naseem",
      "Amitava Datta",
      "Nicolas Fay",
      "Mehwish Nasim"
    ],
    "abstract": "Psychological assessment tools have long helped humans understand behavioural\npatterns. While Large Language Models (LLMs) can generate content comparable to\nthat of humans, we explore whether they exhibit personality traits. To this\nend, this work applies psychological tools to LLMs in diverse scenarios to\ngenerate personality profiles. Using established trait-based questionnaires\nsuch as the Big Five Inventory and by addressing the possibility of training\ndata contamination, we examine the dimensional variability and dominance of\nLLMs across five core personality dimensions: Openness, Conscientiousness,\nExtraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs\nexhibit unique dominant traits, varying characteristics, and distinct\npersonality profiles even within the same family of models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at TheWebConf 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05248v1",
    "published_date": "2025-02-07 16:12:52 UTC",
    "updated_date": "2025-02-07 16:12:52 UTC"
  },
  {
    "arxiv_id": "2502.05041v1",
    "title": "Federated Learning for Anomaly Detection in Energy Consumption Data: Assessing the Vulnerability to Adversarial Attacks",
    "authors": [
      "Yohannis Kifle Telila",
      "Damitha Senevirathne",
      "Dumindu Tissera",
      "Apurva Narayan",
      "Miriam A. M. Capretz",
      "Katarina Grolinger"
    ],
    "abstract": "Anomaly detection is crucial in the energy sector to identify irregular\npatterns indicating equipment failures, energy theft, or other issues. Machine\nlearning techniques for anomaly detection have achieved great success, but are\ntypically centralized, involving sharing local data with a central server which\nraises privacy and security concerns. Federated Learning (FL) has been gaining\npopularity as it enables distributed learning without sharing local data.\nHowever, FL depends on neural networks, which are vulnerable to adversarial\nattacks that manipulate data, leading models to make erroneous predictions.\nWhile adversarial attacks have been explored in the image domain, they remain\nlargely unexplored in time series problems, especially in the energy domain.\nMoreover, the effect of adversarial attacks in the FL setting is also mostly\nunknown. This paper assesses the vulnerability of FL-based anomaly detection in\nenergy data to adversarial attacks. Specifically, two state-of-the-art models,\nLong Short Term Memory (LSTM) and Transformers, are used to detect anomalies in\nan FL setting, and two white-box attack methods, Fast Gradient Sign Method\n(FGSM) and Projected Gradient Descent (PGD), are employed to perturb the data.\nThe results show that FL is more sensitive to PGD attacks than to FGSM attacks,\nattributed to PGD's iterative nature, resulting in an accuracy drop of over 10%\neven with naive, weaker attacks. Moreover, FL is more affected by these attacks\nthan centralized learning, highlighting the need for defense mechanisms in FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "68",
      "I.2; I.5; I.2.11; I.5.4"
    ],
    "primary_category": "cs.LG",
    "comment": "12th IEEE Conference on Technologies for Sustainability",
    "pdf_url": "http://arxiv.org/pdf/2502.05041v1",
    "published_date": "2025-02-07 16:08:20 UTC",
    "updated_date": "2025-02-07 16:08:20 UTC"
  },
  {
    "arxiv_id": "2502.06852v1",
    "title": "EAP-GP: Mitigating Saturation Effect in Gradient-based Automated Circuit Identification",
    "authors": [
      "Lin Zhang",
      "Wenshuo Dong",
      "Zhuoran Zhang",
      "Shu Yang",
      "Lijie Hu",
      "Ninghao Liu",
      "Pan Zhou",
      "Di Wang"
    ],
    "abstract": "Understanding the internal mechanisms of transformer-based language models\nremains challenging. Mechanistic interpretability based on circuit discovery\naims to reverse engineer neural networks by analyzing their internal processes\nat the level of computational subgraphs. In this paper, we revisit existing\ngradient-based circuit identification methods and find that their performance\nis either affected by the zero-gradient problem or saturation effects, where\nedge attribution scores become insensitive to input changes, resulting in noisy\nand unreliable attribution evaluations for circuit components. To address the\nsaturation effect, we propose Edge Attribution Patching with GradPath (EAP-GP),\nEAP-GP introduces an integration path, starting from the input and adaptively\nfollowing the direction of the difference between the gradients of corrupted\nand clean inputs to avoid the saturated region. This approach enhances\nattribution reliability and improves the faithfulness of circuit\nidentification. We evaluate EAP-GP on 6 datasets using GPT-2 Small, GPT-2\nMedium, and GPT-2 XL. Experimental results demonstrate that EAP-GP outperforms\nexisting methods in circuit faithfulness, achieving improvements up to 17.7%.\nComparisons with manually annotated ground-truth circuits demonstrate that\nEAP-GP achieves precision and recall comparable to or better than previous\napproaches, highlighting its effectiveness in identifying accurate circuits.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06852v1",
    "published_date": "2025-02-07 16:04:57 UTC",
    "updated_date": "2025-02-07 16:04:57 UTC"
  },
  {
    "arxiv_id": "2502.05017v1",
    "title": "Bridging Voting and Deliberation with Algorithms: Field Insights from vTaiwan and Kultur Komitee",
    "authors": [
      "Joshua C. Yang",
      "Fynn Bachmann"
    ],
    "abstract": "Democratic processes increasingly aim to integrate large-scale voting with\nface-to-face deliberation, addressing the challenge of reconciling individual\npreferences with collective decision-making. This work introduces new methods\nthat use algorithms and computational tools to bridge online voting with\nface-to-face deliberation, tested in two real-world scenarios: Kultur Komitee\n2024 (KK24) and vTaiwan. These case studies highlight the practical\napplications and impacts of the proposed methods.\n  We present three key contributions: (1) Radial Clustering for Preference\nBased Subgroups, which enables both in-depth and broad discussions in\ndeliberative settings by computing homogeneous and heterogeneous group\ncompositions with balanced and adjustable group sizes; (2) Human-in-the-loop\nMES, a practical method that enhances the Method of Equal Shares (MES)\nalgorithm with real-time digital feedback. This builds algorithmic trust by\ngiving participants full control over how much decision-making is delegated to\nthe voting aggregation algorithm as compared to deliberation; and (3) the\nReadTheRoom deliberation method, which uses opinion space mapping to identify\nagreement and divergence, along with spectrum-based preference visualisation to\ntrack opinion shifts during deliberation. This approach enhances transparency\nby clarifying collective sentiment and fosters collaboration by encouraging\nparticipants to engage constructively with differing perspectives.\n  By introducing these actionable frameworks, this research extends in-person\ndeliberation with scalable digital methods that address the complexities of\nmodern decision-making in participatory processes.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "91B14, 91B12, 91A12, 68T01, 68T20, 68U35",
      "H.5.3; I.2.0; I.2.11; J.1; G.2.0; G.2.2; K.4.1; K.4.3"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05017v1",
    "published_date": "2025-02-07 15:45:13 UTC",
    "updated_date": "2025-02-07 15:45:13 UTC"
  },
  {
    "arxiv_id": "2502.05007v1",
    "title": "Analyzing Advanced AI Systems Against Definitions of Life and Consciousness",
    "authors": [
      "Azadeh Alavi",
      "Hossein Akhoundi",
      "Fatemeh Kouchmeshki"
    ],
    "abstract": "Could artificial intelligence ever become truly conscious in a functional\nsense; this paper explores that open-ended question through the lens of Life, a\nconcept unifying classical biological criteria (Oxford, NASA, Koshland) with\nempirical hallmarks such as adaptive self maintenance, emergent complexity, and\nrudimentary self referential modeling. We propose a number of metrics for\nexamining whether an advanced AI system has gained consciousness, while\nemphasizing that we do not claim all AI stems can become conscious. Rather, we\nsuggest that sufficiently advanced architectures exhibiting immune like\nsabotage defenses, mirror self-recognition analogs, or meta-cognitive updates\nmay cross key thresholds akin to life-like or consciousness-like traits. To\ndemonstrate these ideas, we start by assessing adaptive self-maintenance\ncapability, and introduce controlled data corruption sabotage into the training\nprocess. The result demonstrates AI capability to detect these inconsistencies\nand revert or self-correct analogous to regenerative biological processes. We\nalso adapt an animal-inspired mirror self recognition test to neural\nembeddings, finding that partially trained CNNs can distinguish self from\nforeign features with complete accuracy. We then extend our analysis by\nperforming a question-based mirror test on five state-of-the-art chatbots\n(ChatGPT4, Gemini, Perplexity, Claude, and Copilot) and demonstrated their\nability to recognize their own answers compared to those of the other chatbots.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "78 pages, 15 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.05007v1",
    "published_date": "2025-02-07 15:27:34 UTC",
    "updated_date": "2025-02-07 15:27:34 UTC"
  },
  {
    "arxiv_id": "2502.05001v2",
    "title": "A New Paradigm in Tuning Learned Indexes: A Reinforcement Learning Enhanced Approach",
    "authors": [
      "Taiyi Wang",
      "Liang Liang",
      "Guang Yang",
      "Thomas Heinis",
      "Eiko Yoneki"
    ],
    "abstract": "Learned Index Structures (LIS) have significantly advanced data management by\nleveraging machine learning models to optimize data indexing. However,\ndesigning these structures often involves critical trade-offs, making it\nchallenging for both designers and end-users to find an optimal balance\ntailored to specific workloads and scenarios. While some indexes offer\nadjustable parameters that demand intensive manual tuning, others rely on fixed\nconfigurations based on heuristic auto-tuners or expert knowledge, which may\nnot consistently deliver optimal performance. This paper introduces LITune, a\nnovel framework for end-to-end automatic tuning of Learned Index Structures.\nLITune employs an adaptive training pipeline equipped with a tailor-made Deep\nReinforcement Learning (DRL) approach to ensure stable and efficient tuning. To\naccommodate long-term dynamics arising from online tuning, we further enhance\nLITune with an on-the-fly updating mechanism termed the O2 system. These\ninnovations allow LITune to effectively capture state transitions in online\ntuning scenarios and dynamically adjust to changing data distributions and\nworkloads, marking a significant improvement over other tuning methods. Our\nexperimental results demonstrate that LITune achieves up to a 98% reduction in\nruntime and a 17-fold increase in throughput compared to default parameter\nsettings given a selected Learned Index instance. These findings highlight\nLITune's effectiveness and its potential to facilitate broader adoption of LIS\nin real-world applications.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.DB",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.05001v2",
    "published_date": "2025-02-07 15:22:15 UTC",
    "updated_date": "2025-02-18 17:06:41 UTC"
  },
  {
    "arxiv_id": "2502.05000v1",
    "title": "Robust Graph Learning Against Adversarial Evasion Attacks via Prior-Free Diffusion-Based Structure Purification",
    "authors": [
      "Jiayi Luo",
      "Qingyun Sun",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Jianxin Li"
    ],
    "abstract": "Adversarial evasion attacks pose significant threats to graph learning, with\nlines of studies that have improved the robustness of Graph Neural Networks\n(GNNs). However, existing works rely on priors about clean graphs or attacking\nstrategies, which are often heuristic and inconsistent. To achieve robust graph\nlearning over different types of evasion attacks and diverse datasets, we\ninvestigate this problem from a prior-free structure purification perspective.\nSpecifically, we propose a novel Diffusion-based Structure Purification\nframework named DiffSP, which creatively incorporates the graph diffusion model\nto learn intrinsic distributions of clean graphs and purify the perturbed\nstructures by removing adversaries under the direction of the captured\npredictive patterns without relying on priors. DiffSP is divided into the\nforward diffusion process and the reverse denoising process, during which\nstructure purification is achieved. To avoid valuable information loss during\nthe forward process, we propose an LID-driven nonisotropic diffusion mechanism\nto selectively inject noise anisotropically. To promote semantic alignment\nbetween the clean graph and the purified graph generated during the reverse\nprocess, we reduce the generation uncertainty by the proposed graph transfer\nentropy guided denoising mechanism. Extensive experiments demonstrate the\nsuperior robustness of DiffSP against evasion attacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for poster at WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05000v1",
    "published_date": "2025-02-07 15:21:47 UTC",
    "updated_date": "2025-02-07 15:21:47 UTC"
  },
  {
    "arxiv_id": "2502.04998v1",
    "title": "On Sequential Fault-Intolerant Process Planning",
    "authors": [
      "Andrzej Kaczmarczyk",
      "Davin Choo",
      "Niclas Boehmer",
      "Milind Tambe",
      "Haifeng Xu"
    ],
    "abstract": "We propose and study a planning problem we call Sequential Fault-Intolerant\nProcess Planning (SFIPP). SFIPP captures a reward structure common in many\nsequential multi-stage decision problems where the planning is deemed\nsuccessful only if all stages succeed. Such reward structures are different\nfrom classic additive reward structures and arise in important applications\nsuch as drug/material discovery, security, and quality-critical product design.\nWe design provably tight online algorithms for settings in which we need to\npick between different actions with unknown success chances at each stage. We\ndo so both for the foundational case in which the behavior of actions is\ndeterministic, and the case of probabilistic action outcomes, where we\neffectively balance exploration for learning and exploitation for planning\nthrough the usage of multi-armed bandit algorithms. In our empirical\nevaluations, we demonstrate that the specialized algorithms we develop, which\nleverage additional information about the structure of the SFIPP instance,\noutperform our more general algorithm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages; 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04998v1",
    "published_date": "2025-02-07 15:20:35 UTC",
    "updated_date": "2025-02-07 15:20:35 UTC"
  },
  {
    "arxiv_id": "2502.04997v1",
    "title": "Aligning Black-box Language Models with Human Judgments",
    "authors": [
      "Gerrit J. J. van den Burg",
      "Gen Suzuki",
      "Wei Liu",
      "Murat Sensoy"
    ],
    "abstract": "Large language models (LLMs) are increasingly used as automated judges to\nevaluate recommendation systems, search engines, and other subjective tasks,\nwhere relying on human evaluators can be costly, time-consuming, and\nunscalable. LLMs offer an efficient solution for continuous, automated\nevaluation. However, since the systems that are built and improved with these\njudgments are ultimately designed for human use, it is crucial that LLM\njudgments align closely with human evaluators to ensure such systems remain\nhuman-centered. On the other hand, aligning LLM judgments with human evaluators\nis challenging due to individual variability and biases in human judgments. We\npropose a simple yet effective framework to align LLM judgments with individual\nhuman evaluators or their aggregated judgments, without retraining or\nfine-tuning the LLM. Our approach learns a linear mapping between the LLM's\noutputs and human judgments, achieving over 142% average improvement in\nagreement across 29 tasks with only a small number of calibration examples used\nfor training. Notably, our method works in zero-shot and few-shot settings,\nexceeds inter-human agreement on four out of six tasks, and enables smaller\nLLMs to achieve performance comparable to that of larger models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at NAACL 2025 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2502.04997v1",
    "published_date": "2025-02-07 15:19:40 UTC",
    "updated_date": "2025-02-07 15:19:40 UTC"
  },
  {
    "arxiv_id": "2502.15740v1",
    "title": "Detection of LLM-Generated Java Code Using Discretized Nested Bigrams",
    "authors": [
      "Timothy Paek",
      "Chilukuri Mohan"
    ],
    "abstract": "Large Language Models (LLMs) are currently used extensively to generate code\nby professionals and students, motivating the development of tools to detect\nLLM-generated code for applications such as academic integrity and\ncybersecurity. We address this authorship attribution problem as a binary\nclassification task along with feature identification and extraction. We\npropose new Discretized Nested Bigram Frequency features on source code groups\nof various sizes. Compared to prior work, improvements are obtained by\nrepresenting sparse information in dense membership bins. Experimental\nevaluation demonstrated that our approach significantly outperformed a commonly\nused GPT code-detection API and baseline features, with accuracy exceeding 96%\ncompared to 72% and 79% respectively in detecting GPT-rewritten Java code\nfragments for 976 files with GPT 3.5 and GPT4 using 12 features. We also\noutperformed three prior works on code author identification in a 40-author\ndataset. Our approach scales well to larger data sets, and we achieved 99%\naccuracy and 0.999 AUC for 76,089 files and over 1,000 authors with GPT 4o\nusing 227 features.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "68T50, 62H30",
      "I.2.7; K.6.5; D.2.8"
    ],
    "primary_category": "cs.SE",
    "comment": "This preprint precedes the final peer-reviewed version, which will be\n  published in Springer's CSCI 2024 proceedings",
    "pdf_url": "http://arxiv.org/pdf/2502.15740v1",
    "published_date": "2025-02-07 14:32:20 UTC",
    "updated_date": "2025-02-07 14:32:20 UTC"
  },
  {
    "arxiv_id": "2502.05244v1",
    "title": "Probabilistic Artificial Intelligence",
    "authors": [
      "Andreas Krause",
      "Jonas Hübotter"
    ],
    "abstract": "Artificial intelligence commonly refers to the science and engineering of\nartificial systems that can carry out tasks generally associated with requiring\naspects of human intelligence, such as playing games, translating languages,\nand driving cars. In recent years, there have been exciting advances in\nlearning-based, data-driven approaches towards AI, and machine learning and\ndeep learning have enabled computer systems to perceive the world in\nunprecedented ways. Reinforcement learning has enabled breakthroughs in complex\ngames such as Go and challenging robotics tasks such as quadrupedal locomotion.\n  A key aspect of intelligence is to not only make predictions, but reason\nabout the uncertainty in these predictions, and to consider this uncertainty\nwhen making decisions. This is what this manuscript on \"Probabilistic\nArtificial Intelligence\" is about. The first part covers probabilistic\napproaches to machine learning. We discuss the differentiation between\n\"epistemic\" uncertainty due to lack of data and \"aleatoric\" uncertainty, which\nis irreducible and stems, e.g., from noisy observations and outcomes. We\ndiscuss concrete approaches towards probabilistic inference and modern\napproaches to efficient approximate inference.\n  The second part of the manuscript is about taking uncertainty into account in\nsequential decision tasks. We consider active learning and Bayesian\noptimization -- approaches that collect data by proposing experiments that are\ninformative for reducing the epistemic uncertainty. We then consider\nreinforcement learning and modern deep RL approaches that use neural network\nfunction approximation. We close by discussing modern approaches in model-based\nRL, which harness epistemic and aleatoric uncertainty to guide exploration,\nwhile also reasoning about safety.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05244v1",
    "published_date": "2025-02-07 14:29:07 UTC",
    "updated_date": "2025-02-07 14:29:07 UTC"
  },
  {
    "arxiv_id": "2502.04963v2",
    "title": "Fast Adaptive Anti-Jamming Channel Access via Deep Q Learning and Coarse-Grained Spectrum Prediction",
    "authors": [
      "Jianshu Zhang",
      "Xiaofu Wu",
      "Junquan Hu"
    ],
    "abstract": "This paper investigates the anti-jamming channel access problem in complex\nand unknown jamming environments, where the jammer could dynamically adjust its\nstrategies to target different channels. Traditional channel hopping\nanti-jamming approaches using fixed patterns are ineffective against such\ndynamic jamming attacks. Although the emerging deep reinforcement learning\n(DRL) based dynamic channel access approach could achieve the Nash equilibrium\nunder fast-changing jamming attacks, it requires extensive training episodes.\nTo address this issue, we propose a fast adaptive anti-jamming channel access\napproach guided by the intuition of ``learning faster than the jammer\", where a\nsynchronously updated coarse-grained spectrum prediction serves as an auxiliary\ntask for the deep Q learning (DQN) based anti-jamming model. This helps the\nmodel identify a superior Q-function compared to standard DRL while\nsignificantly reducing the number of training episodes. Numerical results\nindicate that the proposed approach significantly accelerates the rate of\nconvergence in model training, reducing the required training episodes by up to\n70% compared to standard DRL. Additionally, it also achieves a 10% improvement\nin throughput over NE strategies, owing to the effective use of coarse-grained\nspectrum prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04963v2",
    "published_date": "2025-02-07 14:25:28 UTC",
    "updated_date": "2025-04-20 03:58:00 UTC"
  },
  {
    "arxiv_id": "2502.10428v4",
    "title": "Dynamic Chain-of-Thought: Towards Adaptive Deep Reasoning",
    "authors": [
      "Libo Wang"
    ],
    "abstract": "To reduce the cost and consumption of computing resources caused by\ncomputational redundancy and delayed reward assignment in long CoT, this\nresearch proposes the dynamic chain-of-thought (D-CoT) with adaptive reasoning\ntime and steps. The researcher used simulation experiment to simulate the\nintegration of D-CoT through Python 3.13 IDLE combined with a Python simulator\nbased on GPTs. At the same time, the researcher used DeepSeek R1 as a control\ngroup to test and compare the performance of the D-CoT simulator in processing\nMIT OpenCourseWare's linear algebra exam questions. Experimental results show\nthat D-CoT is better than DeepSeek R1 based on long CoT in three indicators:\nreasoning time, CoT length (reasoning steps) and token count, which achieves a\nsignificant reduction in computing resource consumption. In addition, this\nresearch has potential value in deep reasoning optimization that is used as a\nreference for future dynamic deep reasoning frameworks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The GitHub repository link is:\n  https://github.com/brucewang123456789/GeniusTrail/tree/main/Dynamic%20CoT",
    "pdf_url": "http://arxiv.org/pdf/2502.10428v4",
    "published_date": "2025-02-07 14:24:43 UTC",
    "updated_date": "2025-04-05 13:51:05 UTC"
  },
  {
    "arxiv_id": "2502.04951v1",
    "title": "The Rising Threat to Emerging AI-Powered Search Engines",
    "authors": [
      "Zeren Luo",
      "Zifan Peng",
      "Yule Liu",
      "Zhen Sun",
      "Mingchen Li",
      "Jingyi Zheng",
      "Xinlei He"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced the capabilities of AI-Powered Search Engines (AIPSEs), offering\nprecise and efficient responses by integrating external databases with\npre-existing knowledge. However, we observe that these AIPSEs raise risks such\nas quoting malicious content or citing malicious websites, leading to harmful\nor unverified information dissemination. In this study, we conduct the first\nsafety risk quantification on seven production AIPSEs by systematically\ndefining the threat model, risk level, and evaluating responses to various\nquery types. With data collected from PhishTank, ThreatBook, and LevelBlue, our\nfindings reveal that AIPSEs frequently generate harmful content that contains\nmalicious URLs even with benign queries (e.g., with benign keywords). We also\nobserve that directly query URL will increase the risk level while query with\nnatural language will mitigate such risk. We further perform two case studies\non online document spoofing and phishing to show the ease of deceiving AIPSEs\nin the real-world setting. To mitigate these risks, we develop an agent-based\ndefense with a GPT-4o-based content refinement tool and an XGBoost-based URL\ndetector. Our evaluation shows that our defense can effectively reduce the risk\nbut with the cost of reducing available information. Our research highlights\nthe urgent need for robust safety measures in AIPSEs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04951v1",
    "published_date": "2025-02-07 14:15:46 UTC",
    "updated_date": "2025-02-07 14:15:46 UTC"
  },
  {
    "arxiv_id": "2502.04937v1",
    "title": "Data-driven Modality Fusion: An AI-enabled Framework for Large-Scale Sensor Network Management",
    "authors": [
      "Hrishikesh Dutta",
      "Roberto Minerva",
      "Maira Alvi",
      "Noel Crespi"
    ],
    "abstract": "The development and operation of smart cities relyheavily on large-scale\nInternet-of-Things (IoT) networks and sensor infrastructures that continuously\nmonitor various aspects of urban environments. These networks generate vast\namounts of data, posing challenges related to bandwidth usage, energy\nconsumption, and system scalability. This paper introduces a novel sensing\nparadigm called Data-driven Modality Fusion (DMF), designed to enhance the\nefficiency of smart city IoT network management. By leveraging correlations\nbetween timeseries data from different sensing modalities, the proposed DMF\napproach reduces the number of physical sensors required for monitoring,\nthereby minimizing energy expenditure, communication bandwidth, and overall\ndeployment costs. The framework relocates computational complexity from the\nedge devices to the core, ensuring that resource-constrained IoT devices are\nnot burdened with intensive processing tasks. DMF is validated using data from\na real-world IoT deployment in Madrid, demonstrating the effectiveness of the\nproposed system in accurately estimating traffic, environmental, and pollution\nmetrics from a reduced set of sensors. The proposed solution offers a scalable,\nefficient mechanism for managing urban IoT networks, while addressing issues of\nsensor failure and privacy concerns.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04937v1",
    "published_date": "2025-02-07 14:00:04 UTC",
    "updated_date": "2025-02-07 14:00:04 UTC"
  },
  {
    "arxiv_id": "2502.04935v1",
    "title": "Conformal Prediction for Electricity Price Forecasting in the Day-Ahead and Real-Time Balancing Market",
    "authors": [
      "Ciaran O'Connor",
      "Mohamed Bahloul",
      "Roberto Rossi",
      "Steven Prestwich",
      "Andrea Visentin"
    ],
    "abstract": "The integration of renewable energy into electricity markets poses\nsignificant challenges to price stability and increases the complexity of\nmarket operations. Accurate and reliable electricity price forecasting is\ncrucial for effective market participation, where price dynamics can be\nsignificantly more challenging to predict. Probabilistic forecasting, through\nprediction intervals, efficiently quantifies the inherent uncertainties in\nelectricity prices, supporting better decision-making for market participants.\nThis study explores the enhancement of probabilistic price prediction using\nConformal Prediction (CP) techniques, specifically Ensemble Batch Prediction\nIntervals and Sequential Predictive Conformal Inference. These methods provide\nprecise and reliable prediction intervals, outperforming traditional models in\nvalidity metrics. We propose an ensemble approach that combines the efficiency\nof quantile regression models with the robust coverage properties of time\nseries adapted CP techniques. This ensemble delivers both narrow prediction\nintervals and high coverage, leading to more reliable and accurate forecasts.\nWe further evaluate the practical implications of CP techniques through a\nsimulated trading algorithm applied to a battery storage system. The ensemble\napproach demonstrates improved financial returns in energy trading in both the\nDay-Ahead and Balancing Markets, highlighting its practical benefits for market\nparticipants.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04935v1",
    "published_date": "2025-02-07 13:57:47 UTC",
    "updated_date": "2025-02-07 13:57:47 UTC"
  },
  {
    "arxiv_id": "2502.04923v1",
    "title": "Cached Multi-Lora Composition for Multi-Concept Image Generation",
    "authors": [
      "Xiandong Zou",
      "Mingzhu Shen",
      "Christos-Savvas Bouganis",
      "Yiren Zhao"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in\ntext-to-image models, enabling precise rendering of multiple distinct elements,\nsuch as characters and styles, in multi-concept image generation. However,\ncurrent approaches face significant challenges when composing these LoRAs for\nmulti-concept image generation, resulting in diminished generated image\nquality. In this paper, we initially investigate the role of LoRAs in the\ndenoising process through the lens of the Fourier frequency domain. Based on\nthe hypothesis that applying multiple LoRAs could lead to \"semantic conflicts\",\nwe find that certain LoRAs amplify high-frequency features such as edges and\ntextures, whereas others mainly focus on low-frequency elements, including the\noverall structure and smooth color gradients. Building on these insights, we\ndevise a frequency domain based sequencing strategy to determine the optimal\norder in which LoRAs should be integrated during inference. This strategy\noffers a methodical and generalizable solution compared to the naive\nintegration commonly found in existing LoRA fusion techniques. To fully\nleverage our proposed LoRA order sequence determination method in multi-LoRA\ncomposition tasks, we introduce a novel, training-free framework, Cached\nMulti-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while\nmaintaining cohesive image generation. With its flexible backbone for\nmulti-LoRA fusion and a non-uniform caching strategy tailored to individual\nLoRAs, CMLoRA has the potential to reduce semantic conflicts in LoRA\ncomposition and improve computational efficiency. Our experimental evaluations\ndemonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion\nmethods by a significant margin -- it achieves an average improvement of\n$2.19\\%$ in CLIPScore, and $11.25\\%$ in MLLM win rate compared to LoraHub, LoRA\nComposite, and LoRA Switch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.04923v1",
    "published_date": "2025-02-07 13:41:51 UTC",
    "updated_date": "2025-02-07 13:41:51 UTC"
  },
  {
    "arxiv_id": "2502.04917v1",
    "title": "Complex Physics-Informed Neural Network",
    "authors": [
      "Chenhao Si",
      "Ming Yan",
      "Xin Li",
      "Zhihong Xia"
    ],
    "abstract": "We propose compleX-PINN, a novel physics-informed neural network (PINN)\narchitecture that incorporates a learnable activation function inspired by\nCauchy integral theorem. By learning the parameters of the activation function,\ncompleX-PINN achieves high accuracy with just a single hidden layer. Empirical\nresults show that compleX-PINN effectively solves problems where traditional\nPINNs struggle and consistently delivers significantly higher precision, often\nby an order of magnitude.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04917v1",
    "published_date": "2025-02-07 13:36:42 UTC",
    "updated_date": "2025-02-07 13:36:42 UTC"
  },
  {
    "arxiv_id": "2502.05242v1",
    "title": "SEER: Self-Explainability Enhancement of Large Language Models' Representations",
    "authors": [
      "Guanxu Chen",
      "Dongrui Liu",
      "Tao Luo",
      "Jing Shao"
    ],
    "abstract": "Explaining the hidden representations of Large Language Models (LLMs) is a\nperspective to understand LLMs' underlying inference logic and improve their\nreliability in application scenarios. However, previous methods introduce\nexternal ''black-box'' modules to explain ''black-box'' LLMs, increasing the\npotential uncertainty and failing to provide faithful explanations. In this\npaper, we propose a self-explaining method SEER, enhancing LLMs' explainability\nby aggregating the same concept and disentangling the different concepts in the\nrepresentation space. In this way, SEER provides faithful explanations carried\nby representations synchronously with the LLMs' output. Additionally, we\nshowcase the applications of SEER on trustworthiness-related tasks (e.g., the\nsafety risks classification and detoxification tasks), where self-explained\nLLMs achieve consistent improvement in explainability and performance. More\ncrucially, we theoretically analyze the improvement of SEER on LLMs'\ngeneralization ability through optimal transport theory.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages,5 figures,10 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.05242v1",
    "published_date": "2025-02-07 13:25:33 UTC",
    "updated_date": "2025-02-07 13:25:33 UTC"
  },
  {
    "arxiv_id": "2502.04903v1",
    "title": "Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening",
    "authors": [
      "Jie Huang",
      "Rui Huang",
      "Jinghao Xu",
      "Siran Pen",
      "Yule Duan",
      "Liangjian Deng"
    ],
    "abstract": "Pansharpening aims to combine a high-resolution panchromatic (PAN) image with\na low-resolution multispectral (LRMS) image to produce a high-resolution\nmultispectral (HRMS) image. Although pansharpening in the frequency domain\noffers clear advantages, most existing methods either continue to operate\nsolely in the spatial domain or fail to fully exploit the benefits of the\nfrequency domain. To address this issue, we innovatively propose\nMulti-Frequency Fusion Attention (MFFA), which leverages wavelet transforms to\ncleanly separate frequencies and enable lossless reconstruction across\ndifferent frequency domains. Then, we generate Frequency-Query, Spatial-Key,\nand Fusion-Value based on the physical meanings represented by different\nfeatures, which enables a more effective capture of specific information in the\nfrequency domain. Additionally, we focus on the preservation of frequency\nfeatures across different operations. On a broader level, our network employs a\nwavelet pyramid to progressively fuse information across multiple scales.\nCompared to previous frequency domain approaches, our network better prevents\nconfusion and loss of different frequency features during the fusion process.\nQuantitative and qualitative experiments on multiple datasets demonstrate that\nour method outperforms existing approaches and shows significant generalization\ncapabilities for real-world scenarios.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "12 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04903v1",
    "published_date": "2025-02-07 13:15:49 UTC",
    "updated_date": "2025-02-07 13:15:49 UTC"
  },
  {
    "arxiv_id": "2502.04899v1",
    "title": "Unified Approaches in Self-Supervised Event Stream Modeling: Progress and Prospects",
    "authors": [
      "Levente Zólyomi",
      "Tianze Wang",
      "Sofiane Ennadir",
      "Oleg Smirnov",
      "Lele Cao"
    ],
    "abstract": "The proliferation of digital interactions across diverse domains, such as\nhealthcare, e-commerce, gaming, and finance, has resulted in the generation of\nvast volumes of event stream (ES) data. ES data comprises continuous sequences\nof timestamped events that encapsulate detailed contextual information relevant\nto each domain. While ES data holds significant potential for extracting\nactionable insights and enhancing decision-making, its effective utilization is\nhindered by challenges such as the scarcity of labeled data and the fragmented\nnature of existing research efforts. Self-Supervised Learning (SSL) has emerged\nas a promising paradigm to address these challenges by enabling the extraction\nof meaningful representations from unlabeled ES data. In this survey, we\nsystematically review and synthesize SSL methodologies tailored for ES modeling\nacross multiple domains, bridging the gaps between domain-specific approaches\nthat have traditionally operated in isolation. We present a comprehensive\ntaxonomy of SSL techniques, encompassing both predictive and contrastive\nparadigms, and analyze their applicability and effectiveness within different\napplication contexts. Furthermore, we identify critical gaps in current\nresearch and propose a future research agenda aimed at developing scalable,\ndomain-agnostic SSL frameworks for ES modeling. By unifying disparate research\nefforts and highlighting cross-domain synergies, this survey aims to accelerate\ninnovation, improve reproducibility, and expand the applicability of SSL to\ndiverse real-world ES challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04899v1",
    "published_date": "2025-02-07 13:05:55 UTC",
    "updated_date": "2025-02-07 13:05:55 UTC"
  },
  {
    "arxiv_id": "2502.04898v1",
    "title": "ARTInp: CBCT-to-CT Image Inpainting and Image Translation in Radiotherapy",
    "authors": [
      "Ricardo Coimbra Brioso",
      "Leonardo Crespi",
      "Andrea Seghetto",
      "Damiano Dei",
      "Nicola Lambri",
      "Pietro Mancosu",
      "Marta Scorsetti",
      "Daniele Loiacono"
    ],
    "abstract": "A key step in Adaptive Radiation Therapy (ART) workflows is the evaluation of\nthe patient's anatomy at treatment time to ensure the accuracy of the delivery.\nTo this end, Cone Beam Computerized Tomography (CBCT) is widely used being\ncost-effective and easy to integrate into the treatment process. Nonetheless,\nCBCT images have lower resolution and more artifacts than CT scans, making them\nless reliable for precise treatment validation. Moreover, in complex treatments\nsuch as Total Marrow and Lymph Node Irradiation (TMLI), where full-body\nvisualization of the patient is critical for accurate dose delivery, the CBCT\nimages are often discontinuous, leaving gaps that could contain relevant\nanatomical information. To address these limitations, we propose ARTInp\n(Adaptive Radiation Therapy Inpainting), a novel deep-learning framework\ncombining image inpainting and CBCT-to-CT translation. ARTInp employs a\ndual-network approach: a completion network that fills anatomical gaps in CBCT\nvolumes and a custom Generative Adversarial Network (GAN) to generate\nhigh-quality synthetic CT (sCT) images. We trained ARTInp on a dataset of\npaired CBCT and CT images from the SynthRad 2023 challenge, and the performance\nachieved on a test set of 18 patients demonstrates its potential for enhancing\nCBCT-based workflows in radiotherapy.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04898v1",
    "published_date": "2025-02-07 13:04:25 UTC",
    "updated_date": "2025-02-07 13:04:25 UTC"
  },
  {
    "arxiv_id": "2502.07807v1",
    "title": "CP-Guard+: A New Paradigm for Malicious Agent Detection and Defense in Collaborative Perception",
    "authors": [
      "Senkang Hu",
      "Yihang Tao",
      "Zihan Fang",
      "Guowen Xu",
      "Yiqin Deng",
      "Sam Kwong",
      "Yuguang Fang"
    ],
    "abstract": "Collaborative perception (CP) is a promising method for safe connected and\nautonomous driving, which enables multiple vehicles to share sensing\ninformation to enhance perception performance. However, compared with\nsingle-vehicle perception, the openness of a CP system makes it more vulnerable\nto malicious attacks that can inject malicious information to mislead the\nperception of an ego vehicle, resulting in severe risks for safe driving. To\nmitigate such vulnerability, we first propose a new paradigm for malicious\nagent detection that effectively identifies malicious agents at the feature\nlevel without requiring verification of final perception results, significantly\nreducing computational overhead. Building on this paradigm, we introduce\nCP-GuardBench, the first comprehensive dataset provided to train and evaluate\nvarious malicious agent detection methods for CP systems. Furthermore, we\ndevelop a robust defense method called CP-Guard+, which enhances the margin\nbetween the representations of benign and malicious features through a\ncarefully designed Dual-Centered Contrastive Loss (DCCLoss). Finally, we\nconduct extensive experiments on both CP-GuardBench and V2X-Sim, and\ndemonstrate the superiority of CP-Guard+.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07807v1",
    "published_date": "2025-02-07 12:58:45 UTC",
    "updated_date": "2025-02-07 12:58:45 UTC"
  },
  {
    "arxiv_id": "2502.04878v1",
    "title": "Sparse Autoencoders Do Not Find Canonical Units of Analysis",
    "authors": [
      "Patrick Leask",
      "Bart Bussmann",
      "Michael Pearce",
      "Joseph Bloom",
      "Curt Tigges",
      "Noura Al Moubayed",
      "Lee Sharkey",
      "Neel Nanda"
    ],
    "abstract": "A common goal of mechanistic interpretability is to decompose the activations\nof neural networks into features: interpretable properties of the input\ncomputed by the model. Sparse autoencoders (SAEs) are a popular method for\nfinding these features in LLMs, and it has been postulated that they can be\nused to find a \\textit{canonical} set of units: a unique and complete list of\natomic features. We cast doubt on this belief using two novel techniques: SAE\nstitching to show they are incomplete, and meta-SAEs to show they are not\natomic. SAE stitching involves inserting or swapping latents from a larger SAE\ninto a smaller one. Latents from the larger SAE can be divided into two\ncategories: \\emph{novel latents}, which improve performance when added to the\nsmaller SAE, indicating they capture novel information, and\n\\emph{reconstruction latents}, which can replace corresponding latents in the\nsmaller SAE that have similar behavior. The existence of novel features\nindicates incompleteness of smaller SAEs. Using meta-SAEs -- SAEs trained on\nthe decoder matrix of another SAE -- we find that latents in SAEs often\ndecompose into combinations of latents from a smaller SAE, showing that larger\nSAE latents are not atomic. The resulting decompositions are often\ninterpretable; e.g. a latent representing ``Einstein'' decomposes into\n``scientist'', ``Germany'', and ``famous person''. Even if SAEs do not find\ncanonical units of analysis, they may still be useful tools. We suggest that\nfuture research should either pursue different approaches for identifying such\nunits, or pragmatically choose the SAE size suited to their task. We provide an\ninteractive dashboard to explore meta-SAEs: https://metasaes.streamlit.app/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04878v1",
    "published_date": "2025-02-07 12:33:08 UTC",
    "updated_date": "2025-02-07 12:33:08 UTC"
  },
  {
    "arxiv_id": "2502.04864v1",
    "title": "$TAR^2$: Temporal-Agent Reward Redistribution for Optimal Policy Preservation in Multi-Agent Reinforcement Learning",
    "authors": [
      "Aditya Kapoor",
      "Kale-ab Tessera",
      "Mayank Baranwal",
      "Harshad Khadilkar",
      "Stefano Albrecht",
      "Mingfei Sun"
    ],
    "abstract": "In cooperative multi-agent reinforcement learning (MARL), learning effective\npolicies is challenging when global rewards are sparse and delayed. This\ndifficulty arises from the need to assign credit across both agents and time\nsteps, a problem that existing methods often fail to address in episodic,\nlong-horizon tasks. We propose Temporal-Agent Reward Redistribution $TAR^2$, a\nnovel approach that decomposes sparse global rewards into agent-specific,\ntime-step-specific components, thereby providing more frequent and accurate\nfeedback for policy learning. Theoretically, we show that $TAR^2$ (i) aligns\nwith potential-based reward shaping, preserving the same optimal policies as\nthe original environment, and (ii) maintains policy gradient update directions\nidentical to those under the original sparse reward, ensuring unbiased credit\nsignals. Empirical results on two challenging benchmarks, SMACLite and Google\nResearch Football, demonstrate that $TAR^2$ significantly stabilizes and\naccelerates convergence, outperforming strong baselines like AREL and STAS in\nboth learning speed and final performance. These findings establish $TAR^2$ as\na principled and practical solution for agent-temporal credit assignment in\nsparse-reward multi-agent systems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "23 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.04864v1",
    "published_date": "2025-02-07 12:07:57 UTC",
    "updated_date": "2025-02-07 12:07:57 UTC"
  },
  {
    "arxiv_id": "2502.06851v2",
    "title": "Survey on Vision-Language-Action Models",
    "authors": [
      "Adilzhan Adilkhanov",
      "Amir Yelenov",
      "Assylkhan Seitzhanov",
      "Ayan Mazhitov",
      "Azamat Abdikarimov",
      "Danissa Sandykbayeva",
      "Daryn Kenzhebek",
      "Dinmukhammed Mukashev",
      "Ilyas Umurbekov",
      "Jabrail Chumakov",
      "Kamila Spanova",
      "Karina Burunchina",
      "Madina Yergibay",
      "Margulan Issa",
      "Moldir Zabirova",
      "Nurdaulet Zhuzbay",
      "Nurlan Kabdyshev",
      "Nurlan Zhaniyar",
      "Rasul Yermagambet",
      "Rustam Chibar",
      "Saltanat Seitzhan",
      "Soibkhon Khajikhanov",
      "Tasbolat Taunyazov",
      "Temirlan Galimzhanov",
      "Temirlan Kaiyrbay",
      "Tleukhan Mussin",
      "Togzhan Syrymova",
      "Valeriya Kostyukova",
      "Yerkebulan Massalim",
      "Yermakhan Kassym",
      "Zerde Nurbayeva",
      "Zhanat Kappassov"
    ],
    "abstract": "This paper presents an AI-generated review of Vision-Language-Action (VLA)\nmodels, summarizing key methodologies, findings, and future directions. The\ncontent is produced using large language models (LLMs) and is intended only for\ndemonstration purposes. This work does not represent original research, but\nhighlights how AI can help automate literature reviews. As AI-generated content\nbecomes more prevalent, ensuring accuracy, reliability, and proper synthesis\nremains a challenge. Future research will focus on developing a structured\nframework for AI-assisted literature reviews, exploring techniques to enhance\ncitation accuracy, source credibility, and contextual understanding. By\nexamining the potential and limitations of LLM in academic writing, this study\naims to contribute to the broader discussion of integrating AI into research\nworkflows. This work serves as a preliminary step toward establishing\nsystematic approaches for leveraging AI in literature review generation, making\nacademic knowledge synthesis more efficient and scalable.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06851v2",
    "published_date": "2025-02-07 11:56:46 UTC",
    "updated_date": "2025-02-15 06:51:17 UTC"
  },
  {
    "arxiv_id": "2502.05239v1",
    "title": "Enhancing Knowledge Graph Construction: Evaluating with Emphasis on Hallucination, Omission, and Graph Similarity Metrics",
    "authors": [
      "Hussam Ghanem",
      "Christophe Cruz"
    ],
    "abstract": "Recent advancements in large language models have demonstrated significant\npotential in the automated construction of knowledge graphs from unstructured\ntext. This paper builds upon our previous work [16], which evaluated various\nmodels using metrics like precision, recall, F1 score, triple matching, and\ngraph matching, and introduces a refined approach to address the critical\nissues of hallucination and omission. We propose an enhanced evaluation\nframework incorporating BERTScore for graph similarity, setting a practical\nthreshold of 95% for graph matching. Our experiments focus on the Mistral\nmodel, comparing its original and fine-tuned versions in zero-shot and few-shot\nsettings. We further extend our experiments using examples from the KELM-sub\ntraining dataset, illustrating that the fine-tuned model significantly improves\nknowledge graph construction accuracy while reducing the exact hallucination\nand omission. However, our findings also reveal that the fine-tuned models\nperform worse in generalization tasks on the KELM-sub dataset. This study\nunderscores the importance of comprehensive evaluation metrics in advancing the\nstate-of-the-art in knowledge graph construction from textual data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05239v1",
    "published_date": "2025-02-07 11:19:01 UTC",
    "updated_date": "2025-02-07 11:19:01 UTC"
  },
  {
    "arxiv_id": "2503.04751v1",
    "title": "What is Ethical: AIHED Driving Humans or Human-Driven AIHED? A Conceptual Framework enabling the Ethos of AI-driven Higher education",
    "authors": [
      "Prashant Mahajan"
    ],
    "abstract": "The rapid integration of Artificial Intelligence (AI) in Higher Education\n(HE) is transforming personalized learning, administrative automation, and\ndecision-making. However, this progress presents a duality, as AI adoption also\nintroduces ethical and institutional challenges, including algorithmic bias,\ndata privacy risks, and governance inconsistencies. To address these concerns,\nthis study introduces the Human-Driven AI in Higher Education (HD-AIHED)\nFramework, ensuring compliance with UNESCO and OECD ethical standards. This\nconceptual research employs a qualitative meta-synthesis approach, integrating\nqualitative and quantitative studies to identify patterns, contradictions, and\ngaps in AI adoption within HE. It reinterprets existing datasets through\ntheoretical and ethical lenses to develop governance frameworks. The study\napplies a participatory integrated co-system, Phased Human Intelligence, SWOC\nanalysis, and AI ethical review boards to assess AI readiness and governance\nstrategies for universities and HE institutions. The HD-AIHED model bridges AI\nresearch gaps, addresses global real-time challenges, and provides tailored,\nscalable, and ethical strategies for diverse educational contexts. By\nemphasizing interdisciplinary collaboration among stakeholders, this study\nenvisions AIHED as a transparent and equitable force for innovation. The\nHD-AIHED framework ensures AI acts as a collaborative and ethical enabler\nrather than a disruptive replacement for human intelligence while advocating\nfor responsible AI implementation in HE.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Tables 9, Figures 6",
    "pdf_url": "http://arxiv.org/pdf/2503.04751v1",
    "published_date": "2025-02-07 11:13:31 UTC",
    "updated_date": "2025-02-07 11:13:31 UTC"
  },
  {
    "arxiv_id": "2502.04834v1",
    "title": "Lightweight Operations for Visual Speech Recognition",
    "authors": [
      "Iason Ioannis Panagos",
      "Giorgos Sfikas",
      "Christophoros Nikou"
    ],
    "abstract": "Visual speech recognition (VSR), which decodes spoken words from video data,\noffers significant benefits, particularly when audio is unavailable. However,\nthe high dimensionality of video data leads to prohibitive computational costs\nthat demand powerful hardware, limiting VSR deployment on resource-constrained\ndevices. This work addresses this limitation by developing lightweight VSR\narchitectures. Leveraging efficient operation design paradigms, we create\ncompact yet powerful models with reduced resource requirements and minimal\naccuracy loss. We train and evaluate our models on a large-scale public dataset\nfor recognition of words from video sequences, demonstrating their\neffectiveness for practical applications. We also conduct an extensive array of\nablative experiments to thoroughly analyze the size and complexity of each\nmodel. Code and trained models will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages (double column format), 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04834v1",
    "published_date": "2025-02-07 11:08:32 UTC",
    "updated_date": "2025-02-07 11:08:32 UTC"
  },
  {
    "arxiv_id": "2502.04829v1",
    "title": "Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization",
    "authors": [
      "Yedidya Kfir",
      "Elad Sarafian",
      "Sarit Kraus",
      "Yoram Louzoun"
    ],
    "abstract": "Black-box algorithms are designed to optimize functions without relying on\ntheir underlying analytical structure or gradient information, making them\nessential when gradients are inaccessible or difficult to compute. Traditional\nmethods for solving black-box optimization (BBO) problems predominantly rely on\nnon-parametric models and struggle to scale to large input spaces. Conversely,\nparametric methods that model the function with neural estimators and obtain\ngradient signals via backpropagation may suffer from significant gradient\nerrors. A recent alternative, Explicit Gradient Learning (EGL), which directly\nlearns the gradient using a first-order Taylor approximation, has demonstrated\nsuperior performance over both parametric and non-parametric methods. In this\nwork, we propose two novel gradient learning variants to address the robustness\nchallenges posed by high-dimensional, complex, and highly non-linear problems.\nOptimistic Gradient Learning (OGL) introduces a bias toward lower regions in\nthe function landscape, while Higher-order Gradient Learning (HGL) incorporates\nsecond-order Taylor corrections to improve gradient accuracy. We combine these\napproaches into the unified OHGL algorithm, achieving state-of-the-art (SOTA)\nperformance on the synthetic COCO suite. Additionally, we demonstrate OHGLs\napplicability to high-dimensional real-world machine learning (ML) tasks such\nas adversarial training and code generation. Our results highlight OHGLs\nability to generate stronger candidates, offering a valuable tool for ML\nresearchers and practitioners tackling high-dimensional, non-linear\noptimization challenges",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "We develop a black-box optimization algorithm that learns gradients\n  with neural models and can be applied to solve non-convex high dimensional\n  real-world problems",
    "pdf_url": "http://arxiv.org/pdf/2502.04829v1",
    "published_date": "2025-02-07 11:03:50 UTC",
    "updated_date": "2025-02-07 11:03:50 UTC"
  },
  {
    "arxiv_id": "2502.04794v2",
    "title": "MedMimic: Physician-Inspired Multimodal Fusion for Early Diagnosis of Fever of Unknown Origin",
    "authors": [
      "Minrui Chen",
      "Yi Zhou",
      "Huidong Jiang",
      "Yuhan Zhu",
      "Guanjie Zou",
      "Minqi Chen",
      "Rong Tian",
      "Hiroto Saigo"
    ],
    "abstract": "Fever of unknown origin FUO remains a diagnostic challenge. MedMimic is\nintroduced as a multimodal framework inspired by real-world diagnostic\nprocesses. It uses pretrained models such as DINOv2, Vision Transformer, and\nResNet-18 to convert high-dimensional 18F-FDG PET/CT imaging into\nlow-dimensional, semantically meaningful features. A learnable\nself-attention-based fusion network then integrates these imaging features with\nclinical data for classification. Using 416 FUO patient cases from Sichuan\nUniversity West China Hospital from 2017 to 2023, the multimodal fusion\nclassification network MFCN achieved macro-AUROC scores ranging from 0.8654 to\n0.9291 across seven tasks, outperforming conventional machine learning and\nsingle-modality deep learning methods. Ablation studies and five-fold\ncross-validation further validated its effectiveness. By combining the\nstrengths of pretrained large models and deep learning, MedMimic offers a\npromising solution for disease classification.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04794v2",
    "published_date": "2025-02-07 09:57:03 UTC",
    "updated_date": "2025-02-14 01:14:15 UTC"
  },
  {
    "arxiv_id": "2502.04790v2",
    "title": "S$^2$-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency",
    "authors": [
      "Yuting Zeng",
      "Weizhe Huang",
      "Lei Jiang",
      "Tongxuan Liu",
      "Xitai Jin",
      "Chen Tianying Tiana",
      "Jing Li",
      "Xiaohua Xu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious natural language processing (NLP) scenarios, but they still face\nchallenges when handling complex arithmetic and logical reasoning tasks. While\nChain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correction\nstrategies have attempted to guide models in sequential, multi-step reasoning,\nMulti-agent Debate (MAD) has emerged as a viable approach for enhancing the\nreasoning capabilities of LLMs. By increasing both the number of agents and the\nfrequency of debates, the performance of LLMs improves significantly. However,\nthis strategy results in a significant increase in token costs, presenting a\nbarrier to scalability. To address this challenge, we introduce a novel\nsparsification strategy designed to reduce token costs within MAD. This\napproach minimizes ineffective exchanges of information and unproductive\ndiscussions among agents, thereby enhancing the overall efficiency of the\ndebate process. We conduct comparative experiments on multiple datasets across\nvarious models, demonstrating that our approach significantly reduces the token\ncosts in MAD to a considerable extent. Specifically, compared to MAD, our\napproach achieves an impressive reduction of up to 94.5\\% in token costs while\nmaintaining performance degradation below 2.0\\%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2502.04790v2",
    "published_date": "2025-02-07 09:49:56 UTC",
    "updated_date": "2025-04-10 02:29:35 UTC"
  },
  {
    "arxiv_id": "2502.04786v1",
    "title": "Enhancing SQL Injection Detection and Prevention Using Generative Models",
    "authors": [
      "Naga Sai Dasari",
      "Atta Badii",
      "Armin Moin",
      "Ahmed Ashlam"
    ],
    "abstract": "SQL Injection (SQLi) continues to pose a significant threat to the security\nof web applications, enabling attackers to manipulate databases and access\nsensitive information without authorisation. Although advancements have been\nmade in detection techniques, traditional signature-based methods still\nstruggle to identify sophisticated SQL injection attacks that evade predefined\npatterns. As SQLi attacks evolve, the need for more adaptive detection systems\nbecomes crucial. This paper introduces an innovative approach that leverages\ngenerative models to enhance SQLi detection and prevention mechanisms. By\nincorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN with\nGradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated to\naugment training datasets for machine learning models. The proposed method\ndemonstrated improved accuracy in SQLi detection systems by reducing both false\npositives and false negatives. Extensive empirical testing further illustrated\nthe ability of the system to adapt to evolving SQLi attack patterns, resulting\nin enhanced precision and robustness.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 22 Figures, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2502.04786v1",
    "published_date": "2025-02-07 09:43:43 UTC",
    "updated_date": "2025-02-07 09:43:43 UTC"
  },
  {
    "arxiv_id": "2503.04750v1",
    "title": "Position: AI agents should be regulated based on autonomous action sequences",
    "authors": [
      "Takauki Osogami"
    ],
    "abstract": "This position paper argues that AI agents should be regulated based on the\nsequence of actions they autonomously take. AI agents with long-term planning\nand strategic capabilities can pose significant risks of human extinction and\nirreversible global catastrophes. While existing regulations often focus on\ncomputational scale as a proxy for potential harm, we contend that such\nmeasures are insufficient for assessing the risks posed by AI agents whose\ncapabilities arise primarily from inference-time computation. To support our\nposition, we discuss relevant regulations and recommendations from AI\nscientists regarding existential risks, as well as the advantages of action\nsequences over existing impact measures that require observing environmental\nstates.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "29 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04750v1",
    "published_date": "2025-02-07 09:40:48 UTC",
    "updated_date": "2025-02-07 09:40:48 UTC"
  },
  {
    "arxiv_id": "2502.04780v1",
    "title": "SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning",
    "authors": [
      "Wanjia Zhao",
      "Mert Yuksekgonul",
      "Shirley Wu",
      "James Zou"
    ],
    "abstract": "Multi-agent AI systems powered by large language models (LLMs) are\nincreasingly applied to solve complex tasks. However, these systems often rely\non fragile, manually designed prompts and heuristics, making optimization\ndifficult. A key challenge in optimizing multi-agent systems is acquiring\nsuitable training data for specialized agents. We introduce SiriuS, a\nself-improving, reasoning-driven optimization framework for multi-agent\nsystems. Central to our approach is the construction of an experience library:\na repository of high-quality reasoning trajectories. The library is built by\nretaining reasoning steps that lead to successful outcomes, providing a robust\ntraining set for optimizing multi-agent system. Additionally, we introduce a\nlibrary augmentation procedure that refines unsuccessful trajectories, further\nenriching the library. SiriuS boosts performance by 2.86\\% to 21.88\\% on\nreasoning and biomedical QA and enhances agent negotiation in competitive\nsettings. Our results show that SiriuS enhances multi-agent performance while\ngenerating reusable data for self-correction and self-play enhancement in the\nfuture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04780v1",
    "published_date": "2025-02-07 09:33:44 UTC",
    "updated_date": "2025-02-07 09:33:44 UTC"
  },
  {
    "arxiv_id": "2502.04778v1",
    "title": "Behavior-Regularized Diffusion Policy Optimization for Offline Reinforcement Learning",
    "authors": [
      "Chen-Xiao Gao",
      "Chenyang Wu",
      "Mingjun Cao",
      "Chenjun Xiao",
      "Yang Yu",
      "Zongzhang Zhang"
    ],
    "abstract": "The primary focus of offline reinforcement learning (RL) is to manage the\nrisk of hazardous exploitation of out-of-distribution actions. An effective\napproach to achieve this goal is through behavior regularization, which\naugments conventional RL objectives by incorporating constraints that enforce\nthe policy to remain close to the behavior policy. Nevertheless, existing\nliterature on behavior-regularized RL primarily focuses on explicit policy\nparameterizations, such as Gaussian policies. Consequently, it remains unclear\nhow to extend this framework to more advanced policy parameterizations, such as\ndiffusion models. In this paper, we introduce BDPO, a principled\nbehavior-regularized RL framework tailored for diffusion-based policies,\nthereby combining the expressive power of diffusion policies and the robustness\nprovided by regularization. The key ingredient of our method is to calculate\nthe Kullback-Leibler (KL) regularization analytically as the accumulated\ndiscrepancies in reverse-time transition kernels along the diffusion\ntrajectory. By integrating the regularization, we develop an efficient\ntwo-time-scale actor-critic RL algorithm that produces the optimal policy while\nrespecting the behavior constraint. Comprehensive evaluations conducted on\nsynthetic 2D tasks and continuous control tasks from the D4RL benchmark\nvalidate its effectiveness and superior performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.04778v1",
    "published_date": "2025-02-07 09:30:35 UTC",
    "updated_date": "2025-02-07 09:30:35 UTC"
  },
  {
    "arxiv_id": "2502.07027v1",
    "title": "Representational Alignment with Chemical Induced Fit for Molecular Relational Learning",
    "authors": [
      "Peiliang Zhang",
      "Jingling Yuan",
      "Qing Xie",
      "Yongjun Zhu",
      "Lin Li"
    ],
    "abstract": "Molecular Relational Learning (MRL) is widely applied in natural sciences to\npredict relationships between molecular pairs by extracting structural\nfeatures. The representational similarity between substructure pairs determines\nthe functional compatibility of molecular binding sites. Nevertheless, aligning\nsubstructure representations by attention mechanisms lacks guidance from\nchemical knowledge, resulting in unstable model performance in chemical space\n(\\textit{e.g.}, functional group, scaffold) shifted data. With theoretical\njustification, we propose the \\textbf{Re}presentational \\textbf{Align}ment with\nChemical Induced \\textbf{Fit} (ReAlignFit) to enhance the stability of MRL.\nReAlignFit dynamically aligns substructure representation in MRL by introducing\nchemical Induced Fit-based inductive bias. In the induction process, we design\nthe Bias Correction Function based on substructure edge reconstruction to align\nrepresentations between substructure pairs by simulating chemical\nconformational changes (dynamic combination of substructures). ReAlignFit\nfurther integrates the Subgraph Information Bottleneck during fit process to\nrefine and optimize substructure pairs exhibiting high chemical functional\ncompatibility, leveraging them to generate molecular embeddings. Experimental\nresults on nine datasets demonstrate that ReAlignFit outperforms\nstate-of-the-art models in two tasks and significantly enhances model's\nstability in both rule-shifted and scaffold-shifted data distributions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07027v1",
    "published_date": "2025-02-07 09:29:21 UTC",
    "updated_date": "2025-02-07 09:29:21 UTC"
  },
  {
    "arxiv_id": "2502.04771v1",
    "title": "DMPA: Model Poisoning Attacks on Decentralized Federated Learning for Model Differences",
    "authors": [
      "Chao Feng",
      "Yunlong Li",
      "Yuanzhe Gao",
      "Alberto Huertas Celdrán",
      "Jan von der Assen",
      "Gérôme Bovet",
      "Burkhard Stiller"
    ],
    "abstract": "Federated learning (FL) has garnered significant attention as a prominent\nprivacy-preserving Machine Learning (ML) paradigm. Decentralized FL (DFL)\neschews traditional FL's centralized server architecture, enhancing the\nsystem's robustness and scalability. However, these advantages of DFL also\ncreate new vulnerabilities for malicious participants to execute adversarial\nattacks, especially model poisoning attacks. In model poisoning attacks,\nmalicious participants aim to diminish the performance of benign models by\ncreating and disseminating the compromised model. Existing research on model\npoisoning attacks has predominantly concentrated on undermining global models\nwithin the Centralized FL (CFL) paradigm, while there needs to be more research\nin DFL. To fill the research gap, this paper proposes an innovative model\npoisoning attack called DMPA. This attack calculates the differential\ncharacteristics of multiple malicious client models and obtains the most\neffective poisoning strategy, thereby orchestrating a collusive attack by\nmultiple participants. The effectiveness of this attack is validated across\nmultiple datasets, with results indicating that the DMPA approach consistently\nsurpasses existing state-of-the-art FL model poisoning attack strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04771v1",
    "published_date": "2025-02-07 09:15:38 UTC",
    "updated_date": "2025-02-07 09:15:38 UTC"
  },
  {
    "arxiv_id": "2502.04760v2",
    "title": "Graph Federated Learning Based Proactive Content Caching in Edge Computing",
    "authors": [
      "Rui Wang"
    ],
    "abstract": "With the rapid growth of mobile data traffic and the increasing prevalence of\nvideo streaming, proactive content caching in edge computing has become crucial\nfor reducing latency and alleviating network congestion. However, traditional\ncaching strategies such as FIFO, LRU, and LFU fail to effectively predict\nfuture content popularity, while existing proactive caching approaches often\nrequire users to upload data to a central server, raising concerns regarding\nprivacy and scalability. To address these challenges, this paper proposes a\nGraph Federated Learning-based Proactive Content Caching (GFPCC) scheme that\nenhances caching efficiency while preserving user privacy. The proposed\napproach integrates federated learning and graph neural networks, enabling\nusers to locally train Light Graph Convolutional Networks (LightGCN) to capture\nuser-item relationships and predict content popularity. Instead of sharing raw\ndata, only the trained model parameters are transmitted to the central server,\nwhere a federated averaging algorithm aggregates updates, refines the global\nmodel, and selects the most popular files for proactive caching. Experimental\nevaluations on real-world datasets, such as MovieLens, demonstrate that GFPCC\noutperforms baseline caching algorithms by achieving higher cache efficiency\nthrough more accurate content popularity predictions. Moreover, the federated\nlearning framework strengthens privacy protection while maintaining efficient\nmodel training; however, scalability remains a challenge in large-scale\nnetworks with dynamic user preferences.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04760v2",
    "published_date": "2025-02-07 08:48:06 UTC",
    "updated_date": "2025-04-08 12:46:45 UTC"
  },
  {
    "arxiv_id": "2502.04759v1",
    "title": "Enhancing Phishing Email Identification with Large Language Models",
    "authors": [
      "Catherine Lee"
    ],
    "abstract": "Phishing has long been a common tactic used by cybercriminals and continues\nto pose a significant threat in today's digital world. When phishing attacks\nbecome more advanced and sophisticated, there is an increasing need for\neffective methods to detect and prevent them. To address the challenging\nproblem of detecting phishing emails, researchers have developed numerous\nsolutions, in particular those based on machine learning (ML) algorithms. In\nthis work, we take steps to study the efficacy of large language models (LLMs)\nin detecting phishing emails. The experiments show that the LLM achieves a high\naccuracy rate at high precision; importantly, it also provides interpretable\nevidence for the decisions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04759v1",
    "published_date": "2025-02-07 08:45:50 UTC",
    "updated_date": "2025-02-07 08:45:50 UTC"
  },
  {
    "arxiv_id": "2502.06849v1",
    "title": "Model Fusion via Neuron Transplantation",
    "authors": [
      "Muhammed Öz",
      "Nicholas Kiefer",
      "Charlotte Debus",
      "Jasmin Hörter",
      "Achim Streit",
      "Markus Götz"
    ],
    "abstract": "Ensemble learning is a widespread technique to improve the prediction\nperformance of neural networks. However, it comes at the price of increased\nmemory and inference time. In this work we propose a novel model fusion\ntechnique called \\emph{Neuron Transplantation (NT)} in which we fuse an\nensemble of models by transplanting important neurons from all ensemble members\ninto the vacant space obtained by pruning insignificant neurons. An initial\nloss in performance post-transplantation can be quickly recovered via\nfine-tuning, consistently outperforming individual ensemble members of the same\nmodel capacity and architecture. Furthermore, NT enables all the ensemble\nmembers to be jointly pruned and jointly trained in a combined model. Comparing\nit to alignment-based averaging (like Optimal-Transport-fusion), it requires\nless fine-tuning than the corresponding OT-fused model, the fusion itself is\nfaster and requires less memory, while the resulting model performance is\ncomparable or better. The code is available under the following link:\nhttps://github.com/masterbaer/neuron-transplantation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 figures, conference: ECML-PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.06849v1",
    "published_date": "2025-02-07 08:45:38 UTC",
    "updated_date": "2025-02-07 08:45:38 UTC"
  },
  {
    "arxiv_id": "2502.04756v2",
    "title": "Concept Navigation and Classification via Open-Source Large Language Model Processing",
    "authors": [
      "Maël Kubli"
    ],
    "abstract": "This paper presents a novel methodological framework for detecting and\nclassifying latent constructs, including frames, narratives, and topics, from\ntextual data using Open-Source Large Language Models (LLMs). The proposed\nhybrid approach combines automated summarization with human-in-the-loop\nvalidation to enhance the accuracy and interpretability of construct\nidentification. By employing iterative sampling coupled with expert refinement,\nthe framework guarantees methodological robustness and ensures conceptual\nprecision. Applied to diverse data sets, including AI policy debates, newspaper\narticles on encryption, and the 20 Newsgroups data set, this approach\ndemonstrates its versatility in systematically analyzing complex political\ndiscourses, media framing, and topic classification tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "36 pages, 1 figure, 5 tabels",
    "pdf_url": "http://arxiv.org/pdf/2502.04756v2",
    "published_date": "2025-02-07 08:42:34 UTC",
    "updated_date": "2025-03-31 14:37:40 UTC"
  },
  {
    "arxiv_id": "2502.05237v1",
    "title": "PSM-SQL: Progressive Schema Learning with Multi-granularity Semantics for Text-to-SQL",
    "authors": [
      "Zhuopan Yang",
      "Yuanzhen Xie",
      "Ruichao Zhong",
      "Yunzhi Tan",
      "Enjie Liu",
      "Zhenguo Yang",
      "Mochi Gao",
      "Bo Hu",
      "Zang Li"
    ],
    "abstract": "It is challenging to convert natural language (NL) questions into executable\nstructured query language (SQL) queries for text-to-SQL tasks due to the vast\nnumber of database schemas with redundancy, which interferes with semantic\nlearning, and the domain shift between NL and SQL. Existing works for schema\nlinking focus on the table level and perform it once, ignoring the\nmulti-granularity semantics and chainable cyclicity of schemas. In this paper,\nwe propose a progressive schema linking with multi-granularity semantics\n(PSM-SQL) framework to reduce the redundant database schemas for text-to-SQL.\nUsing the multi-granularity schema linking (MSL) module, PSM-SQL learns the\nschema semantics at the column, table, and database levels. More specifically,\na triplet loss is used at the column level to learn embeddings, while\nfine-tuning LLMs is employed at the database level for schema reasoning. MSL\nemploys classifier and similarity scores to model schema interactions for\nschema linking at the table level. In particular, PSM-SQL adopts a chain loop\nstrategy to reduce the task difficulty of schema linking by continuously\nreducing the number of redundant schemas. Experiments conducted on text-to-SQL\ndatasets show that the proposed PSM-SQL is 1-3 percentage points higher than\nthe existing methods.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "9 pages, 3 figures, submission in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.05237v1",
    "published_date": "2025-02-07 08:31:57 UTC",
    "updated_date": "2025-02-07 08:31:57 UTC"
  },
  {
    "arxiv_id": "2502.04747v1",
    "title": "Every Software as an Agent: Blueprint and Case Study",
    "authors": [
      "Mengwei Xu"
    ],
    "abstract": "The rise of (multimodal) large language models (LLMs) has shed light on\nsoftware agent -- where software can understand and follow user instructions in\nnatural language. However, existing approaches such as API-based and GUI-based\nagents are far from satisfactory at accuracy and efficiency aspects. Instead,\nwe advocate to endow LLMs with access to the software internals (source code\nand runtime context) and the permission to dynamically inject generated code\ninto software for execution. In such a whitebox setting, one may better\nleverage the software context and the coding ability of LLMs. We then present\nan overall design architecture and case studies on two popular web-based\ndesktop applications. We also give in-depth discussion of the challenges and\nfuture directions. We deem that such a new paradigm has the potential to\nfundamentally overturn the existing software agent design, and finally creating\na digital world in which software can comprehend, operate, collaborate, and\neven think to meet complex user needs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04747v1",
    "published_date": "2025-02-07 08:29:09 UTC",
    "updated_date": "2025-02-07 08:29:09 UTC"
  },
  {
    "arxiv_id": "2502.06848v1",
    "title": "Transfer learning in Scalable Graph Neural Network for Improved Physical Simulation",
    "authors": [
      "Siqi Shen",
      "Yu Liu",
      "Daniel Biggs",
      "Omar Hafez",
      "Jiandong Yu",
      "Wentao Zhang",
      "Bin Cui",
      "Jiulong Shan"
    ],
    "abstract": "In recent years, Graph Neural Network (GNN) based models have shown promising\nresults in simulating physics of complex systems. However, training dedicated\ngraph network based physics simulators can be costly, as most models are\nconfined to fully supervised training, which requires extensive data generated\nfrom traditional physics simulators. To date, how transfer learning could\nimprove the model performance and training efficiency has remained unexplored.\nIn this work, we introduce a pre-training and transfer learning paradigm for\ngraph network simulators. We propose the scalable graph U-net (SGUNET).\nIncorporating an innovative depth-first search (DFS) pooling, the SGUNET is\nadaptable to different mesh sizes and resolutions for various simulation tasks.\nTo enable the transfer learning between differently configured SGUNETs, we\npropose a set of mapping functions to align the parameters between the\npre-trained model and the target model. An extra normalization term is also\nadded into the loss to constrain the difference between the pre-trained weights\nand target model weights for better generalization performance. To pre-train\nour physics simulator we created a dataset which includes 20,000 physical\nsimulations of randomly selected 3D shapes from the open source A Big CAD (ABC)\ndataset. We show that our proposed transfer learning methods allow the model to\nperform even better when fine-tuned with small amounts of training data than\nwhen it is trained from scratch with full extensive dataset. On the 2D\nDeformable Plate benchmark dataset, our pre-trained model fine-tuned on 1/16 of\nthe training data achieved an 11.05\\% improvement in position RMSE compared to\nthe model trained from scratch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06848v1",
    "published_date": "2025-02-07 08:18:23 UTC",
    "updated_date": "2025-02-07 08:18:23 UTC"
  },
  {
    "arxiv_id": "2502.04728v2",
    "title": "Generating Symbolic World Models via Test-time Scaling of Large Language Models",
    "authors": [
      "Zhouliang Yu",
      "Yuhuan Yuan",
      "Tim Z. Xiao",
      "Fuxiang Frank Xia",
      "Jie Fu",
      "Ge Zhang",
      "Ge Lin",
      "Weiyang Liu"
    ],
    "abstract": "Solving complex planning problems requires Large Language Models (LLMs) to\nexplicitly model the state transition to avoid rule violations, comply with\nconstraints, and ensure optimality-a task hindered by the inherent ambiguity of\nnatural language. To overcome such ambiguity, Planning Domain Definition\nLanguage (PDDL) is leveraged as a planning abstraction that enables precise and\nformal state descriptions. With PDDL, we can generate a symbolic world model\nwhere classic searching algorithms, such as A*, can be seamlessly applied to\nfind optimal plans. However, directly generating PDDL domains with current LLMs\nremains an open challenge due to the lack of PDDL training data. To address\nthis challenge, we propose to scale up the test-time computation of LLMs to\nenhance their PDDL reasoning capabilities, thereby enabling the generation of\nhigh-quality PDDL domains. Specifically, we introduce a simple yet effective\nalgorithm, which first employs a Best-of-N sampling approach to improve the\nquality of the initial solution and then refines the solution in a fine-grained\nmanner with verbalized machine learning. Our method outperforms o1-mini by a\nconsiderable margin in the generation of PDDL domains, achieving over 50\\%\nsuccess rate on two tasks (i.e., generating PDDL domains from natural language\ndescription or PDDL problems). This is done without requiring additional\ntraining. By taking advantage of PDDL as state abstraction, our method is able\nto outperform current state-of-the-art methods on almost all competition-level\nplanning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by TMLR2025 (32 pages, 6 figures)",
    "pdf_url": "http://arxiv.org/pdf/2502.04728v2",
    "published_date": "2025-02-07 07:52:25 UTC",
    "updated_date": "2025-05-08 13:42:18 UTC"
  },
  {
    "arxiv_id": "2502.04725v1",
    "title": "Can Diffusion Models Learn Hidden Inter-Feature Rules Behind Images?",
    "authors": [
      "Yujin Han",
      "Andi Han",
      "Wei Huang",
      "Chaochao Lu",
      "Difan Zou"
    ],
    "abstract": "Despite the remarkable success of diffusion models (DMs) in data generation,\nthey exhibit specific failure cases with unsatisfactory outputs. We focus on\none such limitation: the ability of DMs to learn hidden rules between image\nfeatures. Specifically, for image data with dependent features ($\\mathbf{x}$)\nand ($\\mathbf{y}$) (e.g., the height of the sun ($\\mathbf{x}$) and the length\nof the shadow ($\\mathbf{y}$)), we investigate whether DMs can accurately\ncapture the inter-feature rule ($p(\\mathbf{y}|\\mathbf{x})$). Empirical\nevaluations on mainstream DMs (e.g., Stable Diffusion 3.5) reveal consistent\nfailures, such as inconsistent lighting-shadow relationships and mismatched\nobject-mirror reflections. Inspired by these findings, we design four synthetic\ntasks with strongly correlated features to assess DMs' rule-learning abilities.\nExtensive experiments show that while DMs can identify coarse-grained rules,\nthey struggle with fine-grained ones. Our theoretical analysis demonstrates\nthat DMs trained via denoising score matching (DSM) exhibit constant errors in\nlearning hidden rules, as the DSM objective is not compatible with rule\nconformity. To mitigate this, we introduce a common technique - incorporating\nadditional classifier guidance during sampling, which achieves (limited)\nimprovements. Our analysis reveals that the subtle signals of fine-grained\nrules are challenging for the classifier to capture, providing insights for\nfuture exploration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 18 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.04725v1",
    "published_date": "2025-02-07 07:49:37 UTC",
    "updated_date": "2025-02-07 07:49:37 UTC"
  },
  {
    "arxiv_id": "2502.04700v3",
    "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference",
    "authors": [
      "Prakhar Kaushik",
      "Ankit Vaidya",
      "Shravan Chaudhari",
      "Alan Yuille"
    ],
    "abstract": "The rapid growth of large models has raised concerns about their\nenvironmental impact and equity in accessibility due to significant\ncomputational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for\nfinetuning large models, resulting in an abundance of publicly available\nadapters tailored to diverse domains. We ask: Can these pretrained adapters be\nleveraged to further streamline adaptation to new tasks while addressing these\nchallenges? We introduce EigenLoRAx, a parameter-efficient finetuning method\nthat recycles existing adapters to create a principal subspace aligned with\ntheir shared domain knowledge which can be further augmented with orthogonal\nbasis vectors in low-resource scenarios. This enables rapid adaptation to new\ntasks by learning only lightweight coefficients on the principal components of\nthe subspace - eliminating the need to finetune entire adapters. EigenLoRAx\nrequires significantly fewer parameters and memory, improving efficiency for\nboth training and inference. Our method demonstrates strong performance across\ndiverse domains and tasks, offering a scalable for edge-based applications,\npersonalization, and equitable deployment of large models in\nresource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04700v3",
    "published_date": "2025-02-07 07:07:04 UTC",
    "updated_date": "2025-02-28 01:25:58 UTC"
  },
  {
    "arxiv_id": "2502.04695v1",
    "title": "Bridging the Gap in XAI-Why Reliable Metrics Matter for Explainability and Compliance",
    "authors": [
      "Pratinav Seth",
      "Vinay Kumar Sankarapu"
    ],
    "abstract": "This position paper emphasizes the critical gap in the evaluation of\nExplainable AI (XAI) due to the lack of standardized and reliable metrics,\nwhich diminishes its practical value, trustworthiness, and ability to meet\nregulatory requirements. Current evaluation methods are often fragmented,\nsubjective, and biased, making them prone to manipulation and complicating the\nassessment of complex models. A central issue is the absence of a ground truth\nfor explanations, complicating comparisons across various XAI approaches. To\naddress these challenges, we advocate for widespread research into developing\nrobust, context-sensitive evaluation metrics. These metrics should be resistant\nto manipulation, relevant to each use case, and based on human judgment and\nreal-world applicability. We also recommend creating domain-specific evaluation\nbenchmarks that align with the user and regulatory needs of sectors such as\nhealthcare and finance. By encouraging collaboration among academia, industry,\nand regulators, we can create standards that balance flexibility and\nconsistency, ensuring XAI explanations are meaningful, trustworthy, and\ncompliant with evolving regulations.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04695v1",
    "published_date": "2025-02-07 06:54:48 UTC",
    "updated_date": "2025-02-07 06:54:48 UTC"
  },
  {
    "arxiv_id": "2502.05236v1",
    "title": "Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance",
    "authors": [
      "Shehzeen Hussain",
      "Paarth Neekhara",
      "Xuesong Yang",
      "Edresson Casanova",
      "Subhankar Ghosh",
      "Mikyas T. Desta",
      "Roy Fejgin",
      "Rafael Valle",
      "Jason Li"
    ],
    "abstract": "While autoregressive speech token generation models produce speech with\nremarkable variety and naturalness, their inherent lack of controllability\noften results in issues such as hallucinations and undesired vocalizations that\ndo not conform to conditioning inputs. We introduce Koel-TTS, a suite of\nenhanced encoder-decoder Transformer TTS models that address these challenges\nby incorporating preference alignment techniques guided by automatic speech\nrecognition and speaker verification models. Additionally, we incorporate\nclassifier-free guidance to further improve synthesis adherence to the\ntranscript and reference speaker audio. Our experiments demonstrate that these\noptimizations significantly enhance target speaker similarity, intelligibility,\nand naturalness of synthesized speech. Notably, Koel-TTS directly maps text and\ncontext audio to acoustic tokens, and on the aforementioned metrics,\noutperforms state-of-the-art TTS models, despite being trained on a\nsignificantly smaller dataset. Audio samples and demos are available on our\nwebsite.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05236v1",
    "published_date": "2025-02-07 06:47:11 UTC",
    "updated_date": "2025-02-07 06:47:11 UTC"
  },
  {
    "arxiv_id": "2502.04689v3",
    "title": "ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning",
    "authors": [
      "Yuwei Yin",
      "Giuseppe Carenini"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities on\ncomplex evaluation benchmarks, many of which are formulated as\nquestion-answering (QA) tasks. Enhancing the performance of LLMs in QA contexts\nis becoming increasingly vital for advancing their development and\napplicability. This paper introduces ARR, an intuitive, effective, and general\nQA solving method that explicitly incorporates three key steps: analyzing the\nintent of the question, retrieving relevant information, and reasoning step by\nstep. Notably, this paper is the first to introduce intent analysis in QA,\nwhich plays a vital role in ARR. Comprehensive evaluations across 10 diverse QA\ntasks demonstrate that ARR consistently outperforms the baseline methods.\nAblation and case studies further validate the positive contributions of each\nARR component. Furthermore, experiments involving variations in prompt design\nindicate that ARR maintains its effectiveness regardless of the specific prompt\nformulation. Additionally, extensive evaluations across various model sizes,\nLLM series, and generation settings solidify the effectiveness, robustness, and\ngeneralizability of ARR.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages. Code: https://github.com/YuweiYin/ARR",
    "pdf_url": "http://arxiv.org/pdf/2502.04689v3",
    "published_date": "2025-02-07 06:30:33 UTC",
    "updated_date": "2025-05-15 17:52:51 UTC"
  },
  {
    "arxiv_id": "2502.04688v1",
    "title": "M-IFEval: Multilingual Instruction-Following Evaluation",
    "authors": [
      "Antoine Dussolle",
      "Andrea Cardeña Díaz",
      "Shota Sato",
      "Peter Devine"
    ],
    "abstract": "Instruction following is a core capability of modern Large language models\n(LLMs), making evaluating this capability essential to understanding these\nmodels. The Instruction Following Evaluation (IFEval) benchmark from the\nliterature does this using objective criteria, offering a measure of LLM\nperformance without subjective AI or human judgement. However, it only includes\nEnglish instructions, limiting its ability to assess LLMs in other languages.\n  We propose the Multilingual Instruction Following Evaluation (M-IFEval)\nbenchmark, expanding the evaluation to French, Japanese, and Spanish, with both\ngeneral and language-specific instructions. Applying this benchmark to 8\nstate-of-the-art LLMs, we find that benchmark performance across languages and\ninstruction types can vary widely, underscoring the importance of a\nmultilingual benchmark for evaluating LLMs in a diverse cultural context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04688v1",
    "published_date": "2025-02-07 06:27:04 UTC",
    "updated_date": "2025-02-07 06:27:04 UTC"
  },
  {
    "arxiv_id": "2502.04686v1",
    "title": "Learning Strategic Language Agents in the Werewolf Game with Iterative Latent Space Policy Optimization",
    "authors": [
      "Zelai Xu",
      "Wanjun Gu",
      "Chao Yu",
      "Yi Wu",
      "Yu Wang"
    ],
    "abstract": "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04686v1",
    "published_date": "2025-02-07 06:19:55 UTC",
    "updated_date": "2025-02-07 06:19:55 UTC"
  },
  {
    "arxiv_id": "2502.04684v3",
    "title": "G2PDiffusion: Cross-Species Genotype-to-Phenotype Prediction via Evolutionary Diffusion",
    "authors": [
      "Mengdi Liu",
      "Zhangyang Gao",
      "Hong Chang",
      "Stan Z. Li",
      "Shiguang Shan",
      "Xilin Chen"
    ],
    "abstract": "Understanding how genes influence phenotype across species is a fundamental\nchallenge in genetic engineering, which will facilitate advances in various\nfields such as crop breeding, conservation biology, and personalized medicine.\nHowever, current phenotype prediction models are limited to individual species\nand expensive phenotype labeling process, making the genotype-to-phenotype\nprediction a highly domain-dependent and data-scarce problem. To this end, we\nsuggest taking images as morphological proxies, facilitating cross-species\ngeneralization through large-scale multimodal pretraining. We propose the first\ngenotype-to-phenotype diffusion model (G2PDiffusion) that generates\nmorphological images from DNA considering two critical evolutionary signals,\ni.e., multiple sequence alignments (MSA) and environmental contexts. The model\ncontains three novel components: 1) a MSA retrieval engine that identifies\nconserved and co-evolutionary patterns; 2) an environment-aware MSA conditional\nencoder that effectively models complex genotype-environment interactions; and\n3) an adaptive phenomic alignment module to improve genotype-phenotype\nconsistency. Extensive experiments show that integrating evolutionary signals\nwith environmental context enriches the model's understanding of phenotype\nvariability across species, thereby offering a valuable and promising\nexploration into advanced AI-assisted genomic analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04684v3",
    "published_date": "2025-02-07 06:16:31 UTC",
    "updated_date": "2025-03-10 03:08:27 UTC"
  },
  {
    "arxiv_id": "2502.04675v2",
    "title": "Scalable Oversight for Superhuman AI via Recursive Self-Critiquing",
    "authors": [
      "Xueru Wen",
      "Jie Lou",
      "Xinyu Lu",
      "Junjie Yang",
      "Yanjiang Liu",
      "Yaojie Lu",
      "Debing Zhang",
      "Xing Yu"
    ],
    "abstract": "As AI capabilities increasingly surpass human proficiency in complex tasks,\ncurrent alignment techniques including SFT and RLHF face fundamental challenges\nin ensuring reliable oversight. These methods rely on direct human assessment\nand become untenable when AI outputs exceed human cognitive thresholds. In\nresponse to this challenge, we explore two hypotheses: (1) critique of critique\ncan be easier than critique itself, extending the widely-accepted observation\nthat verification is easier than generation to the critique domain, as critique\nitself is a specialized form of generation; (2) this difficulty relationship is\nrecursively held, suggesting that when direct evaluation is infeasible,\nperforming high-order critiques (e.g., critique of critique of critique) offers\na more tractable supervision pathway. To examine these hypotheses, we perform\nHuman-Human, Human-AI, and AI-AI experiments across multiple tasks. Our results\ndemonstrate encouraging evidence supporting these hypotheses and suggest that\nrecursive self-critiquing is a promising direction for scalable oversight.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04675v2",
    "published_date": "2025-02-07 05:41:23 UTC",
    "updated_date": "2025-03-20 02:52:15 UTC"
  },
  {
    "arxiv_id": "2502.04674v2",
    "title": "AdParaphrase: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts",
    "authors": [
      "Soichiro Murakami",
      "Peinan Zhang",
      "Hidetaka Kamigaito",
      "Hiroya Takamura",
      "Manabu Okumura"
    ],
    "abstract": "Effective linguistic choices that attract potential customers play crucial\nroles in advertising success. This study aims to explore the linguistic\nfeatures of ad texts that influence human preferences. Although the creation of\nattractive ad texts is an active area of research, progress in understanding\nthe specific linguistic features that affect attractiveness is hindered by\nseveral obstacles. First, human preferences are complex and influenced by\nmultiple factors, including their content, such as brand names, and their\nlinguistic styles, making analysis challenging. Second, publicly available ad\ntext datasets that include human preferences are lacking, such as ad\nperformance metrics and human feedback, which reflect people's interests. To\naddress these problems, we present AdParaphrase, a paraphrase dataset that\ncontains human preferences for pairs of ad texts that are semantically\nequivalent but differ in terms of wording and style. This dataset allows for\npreference analysis that focuses on the differences in linguistic features. Our\nanalysis revealed that ad texts preferred by human judges have higher fluency,\nlonger length, more nouns, and use of bracket symbols. Furthermore, we\ndemonstrate that an ad text-generation model that considers these findings\nsignificantly improves the attractiveness of a given text. The dataset is\npublicly available at: https://github.com/CyberAgentAILab/AdParaphrase.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.04674v2",
    "published_date": "2025-02-07 05:39:55 UTC",
    "updated_date": "2025-02-11 05:36:24 UTC"
  },
  {
    "arxiv_id": "2502.04671v2",
    "title": "ProofWala: Multilingual Proof Data Synthesis and Theorem-Proving",
    "authors": [
      "Amitayush Thakur",
      "George Tsoukalas",
      "Greg Durrett",
      "Swarat Chaudhuri"
    ],
    "abstract": "Neural networks have shown substantial promise at automatic theorem-proving\nin interactive proof assistants (ITPs) like Lean and Coq. However, most neural\ntheorem-proving models are restricted to specific ITPs, leaving out\nopportunities for cross-lingual $\\textit{transfer}$ between ITPs. We address\nthis weakness with a multilingual proof framework, ${\\rm P{\\small ROOF}W{\\small\nALA}}$, that allows a standardized form of interaction between neural\ntheorem-provers and two established ITPs (Coq and Lean). It enables the\ncollection of multilingual proof step data -- data recording the result of\nproof actions on ITP states -- for training neural provers. ${\\rm P{\\small\nROOF}W{\\small ALA}}$ allows the systematic evaluation of a model's performance\nacross different ITPs and problem domains via efficient parallel proof search\nalgorithms. We show that multilingual training enabled by ${\\rm P{\\small\nROOF}W{\\small ALA}}$ can lead to successful transfer across ITPs. Specifically,\na model trained on a mix of ${\\rm P{\\small ROOF}W{\\small ALA}}$-generated Coq\nand Lean data outperforms Lean-only and Coq-only models on the standard\nprove-at-$k$ metric. We open source all code including code for the ${\\rm\nP{\\small ROOF}W{\\small ALA}}$ Framework\n(https://github.com/trishullab/proof-wala), and the Multilingual ITP\ninteraction framework (https://github.com/trishullab/itp-interface).",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04671v2",
    "published_date": "2025-02-07 05:35:46 UTC",
    "updated_date": "2025-02-15 08:02:36 UTC"
  },
  {
    "arxiv_id": "2502.04670v1",
    "title": "CCS: Controllable and Constrained Sampling with Diffusion Models via Initial Noise Perturbation",
    "authors": [
      "Bowen Song",
      "Zecheng Zhang",
      "Zhaoxu Luo",
      "Jason Hu",
      "Wei Yuan",
      "Jing Jia",
      "Zhengxu Tang",
      "Guanyang Wang",
      "Liyue Shen"
    ],
    "abstract": "Diffusion models have emerged as powerful tools for generative tasks,\nproducing high-quality outputs across diverse domains. However, how the\ngenerated data responds to the initial noise perturbation in diffusion models\nremains under-explored, which hinders understanding the controllability of the\nsampling process. In this work, we first observe an interesting phenomenon: the\nrelationship between the change of generation outputs and the scale of initial\nnoise perturbation is highly linear through the diffusion ODE sampling. Then we\nprovide both theoretical and empirical study to justify this linearity property\nof this input-output (noise-generation data) relationship. Inspired by these\nnew insights, we propose a novel Controllable and Constrained Sampling method\n(CCS) together with a new controller algorithm for diffusion models to sample\nwith desired statistical properties while preserving good sample quality. We\nperform extensive experiments to compare our proposed sampling approach with\nother methods on both sampling controllability and sampled data quality.\nResults show that our CCS method achieves more precisely controlled sampling\nwhile maintaining superior sample quality and diversity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04670v1",
    "published_date": "2025-02-07 05:30:48 UTC",
    "updated_date": "2025-02-07 05:30:48 UTC"
  },
  {
    "arxiv_id": "2502.04669v1",
    "title": "A Comprehensive Review on Noise Control of Diffusion Model",
    "authors": [
      "Zhehao Guo",
      "Jiedong Lang",
      "Shuyu Huang",
      "Yunfei Gao",
      "Xintong Ding"
    ],
    "abstract": "Diffusion models have recently emerged as powerful generative frameworks for\nproducing high-quality images. A pivotal component of these models is the noise\nschedule, which governs the rate of noise injection during the diffusion\nprocess. Since the noise schedule substantially influences sampling quality and\ntraining quality, understanding its design and implications is crucial. In this\ndiscussion, various noise schedules are examined, and their distinguishing\nfeatures and performance characteristics are highlighted.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04669v1",
    "published_date": "2025-02-07 05:26:29 UTC",
    "updated_date": "2025-02-07 05:26:29 UTC"
  },
  {
    "arxiv_id": "2502.06846v1",
    "title": "Prot2Chat: Protein LLM with Early Fusion of Sequence and Structure",
    "authors": [
      "Zhicong Wang",
      "Zicheng Ma",
      "Ziqiang Cao",
      "Changlong Zhou",
      "Jun Zhang",
      "Yiqin Gao"
    ],
    "abstract": "Proteins play a pivotal role in living organisms, yet understanding their\nfunctions presents significant challenges, including the limited flexibility of\nclassification-based methods, the inability to effectively leverage spatial\nstructural information, and the lack of systematic evaluation metrics for\nprotein Q&A systems. To address these limitations, we propose Prot2Chat, a\nnovel framework that integrates multimodal protein representations with natural\nlanguage through a unified module, enabling large language model (LLM)-driven\nanswer generation. Our model incorporates a modified ProteinMPNN encoder, which\nencodes protein sequence and structural information in a unified manner, a\nprotein-text adapter with cross-attention mechanisms, and a LLaMA3 decoder. To\noptimize training efficiency, we freeze the encoder and employ LoRA techniques\nfor the decoder. We conducted experiments on two datasets, both automated\nmetrics and expert evaluations demonstrate the superior performance of our\nmodel. Furthermore, zero-shot prediction results highlight its strong\ngeneralization capabilities. This framework offers a promising solution for\nbridging protein domain knowledge with natural language understanding, paving\nthe way for transformative advancements in protein-related research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.06846v1",
    "published_date": "2025-02-07 05:23:16 UTC",
    "updated_date": "2025-02-07 05:23:16 UTC"
  },
  {
    "arxiv_id": "2502.04667v2",
    "title": "Unveiling the Mechanisms of Explicit CoT Training: How CoT Enhances Reasoning Generalization",
    "authors": [
      "Xinhao Yao",
      "Ruifeng Ren",
      "Yun Liao",
      "Yong Liu"
    ],
    "abstract": "The integration of explicit Chain-of-Thought (CoT) reasoning into training\nlarge language models (LLMs) has advanced their reasoning capabilities, yet the\nmechanisms by which CoT enhances generalization remain poorly understood. This\nwork investigates (1) \\textit{how} CoT training reshapes internal model\nrepresentations and (2) \\textit{why} it improves both in-distribution (ID) and\nout-of-distribution (OOD) reasoning generalization. Through controlled\nexperiments and theoretical analysis, we derive the following key insights.\n\\textbf{1)} Structural Advantage: CoT training internalizes reasoning into a\ntwo-stage generalizing circuit, where the number of stages corresponds to the\nexplicit reasoning steps during training. Notably, CoT-trained models resolve\nintermediate results at shallower layers compared to non-CoT counterparts,\nfreeing up deeper layers to specialize in subsequent reasoning steps.\n\\textbf{2)} Theoretical Analysis: the information-theoretic generalization\nbounds via distributional divergence can be decomposed into ID and OOD\ncomponents. While ID error diminishes with sufficient training regardless of\nCoT, OOD error critically depends on CoT: Non-CoT training fails to generalize\nto OOD samples due to unseen reasoning patterns, whereas CoT training achieves\nnear-perfect OOD generalization by mastering subtasks and reasoning\ncompositions during training. The identified mechanisms explain our\nexperimental results: CoT training accelerates convergence and enhances\ngeneralization from ID to both ID and OOD scenarios while maintaining robust\nperformance even with tolerable noise. These findings are further validated on\ncomplex real-world datasets. This paper offers valuable insights for designing\nCoT strategies to enhance LLM reasoning robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04667v2",
    "published_date": "2025-02-07 05:21:13 UTC",
    "updated_date": "2025-05-05 09:01:06 UTC"
  },
  {
    "arxiv_id": "2502.04658v2",
    "title": "Shifting Attention to You: Personalized Brain-Inspired AI Models",
    "authors": [
      "Stephen Chong Zhao",
      "Yang Hu",
      "Jason Lee",
      "Andrew Bender",
      "Trisha Mazumdar",
      "Mark Wallace",
      "David A. Tovar"
    ],
    "abstract": "The integration of human and artificial intelligence offers a powerful avenue\nfor advancing our understanding of information processing, as each system\nprovides unique computational insights. However, despite the promise of\nhuman-AI integration, current AI models are largely trained on massive\ndatasets, optimized for population-level performance, lacking mechanisms to\nalign their computations with individual users' perceptual semantics and neural\ndynamics. Here we show that integrating human behavioral insights and\nmillisecond scale neural data within a fine tuned CLIP based model not only\ncaptures generalized and individualized aspects of perception but also over\ndoubles behavioral performance compared to the unmodified CLIP baseline. By\nembedding human inductive biases and mirroring dynamic neural processes during\ntraining, personalized neural fine tuning improves predictions of human\nsimilarity judgments and tracks the temporal evolution of individual neural\nresponses. Our work establishes a novel, interpretable framework for designing\nadaptive AI systems, with broad implications for neuroscience, personalized\nmedicine, and human-computer interaction.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "7 Figures, 3 Tables, 3 Supplemental Figures, 1 Supplemental Table",
    "pdf_url": "http://arxiv.org/pdf/2502.04658v2",
    "published_date": "2025-02-07 04:55:31 UTC",
    "updated_date": "2025-04-21 15:57:10 UTC"
  },
  {
    "arxiv_id": "2502.04646v1",
    "title": "Importance Sampling via Score-based Generative Models",
    "authors": [
      "Heasung Kim",
      "Taekyun Lee",
      "Hyeji Kim",
      "Gustavo de Veciana"
    ],
    "abstract": "Importance sampling, which involves sampling from a probability density\nfunction (PDF) proportional to the product of an importance weight function and\na base PDF, is a powerful technique with applications in variance reduction,\nbiased or customized sampling, data augmentation, and beyond. Inspired by the\ngrowing availability of score-based generative models (SGMs), we propose an\nentirely training-free Importance sampling framework that relies solely on an\nSGM for the base PDF. Our key innovation is realizing the importance sampling\nprocess as a backward diffusion process, expressed in terms of the score\nfunction of the base PDF and the specified importance weight function--both\nreadily available--eliminating the need for any additional training. We conduct\na thorough analysis demonstrating the method's scalability and effectiveness\nacross diverse datasets and tasks, including importance sampling for industrial\nand natural images with neural importance weight functions. The training-free\naspect of our method is particularly compelling in real-world scenarios where a\nsingle base distribution underlies multiple biased sampling tasks, each\nrequiring a different importance weight function. To the best of our knowledge\nour approach is the first importance sampling framework to achieve this.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04646v1",
    "published_date": "2025-02-07 04:09:03 UTC",
    "updated_date": "2025-02-07 04:09:03 UTC"
  },
  {
    "arxiv_id": "2502.04645v1",
    "title": "Cross-Encoder Rediscovers a Semantic Variant of BM25",
    "authors": [
      "Meng Lu",
      "Catherine Chen",
      "Carsten Eickhoff"
    ],
    "abstract": "Neural Ranking Models (NRMs) have rapidly advanced state-of-the-art\nperformance on information retrieval tasks. In this work, we investigate a\nCross-Encoder variant of MiniLM to determine which relevance features it\ncomputes and where they are stored. We find that it employs a semantic variant\nof the traditional BM25 in an interpretable manner, featuring localized\ncomponents: (1) Transformer attention heads that compute soft term frequency\nwhile controlling for term saturation and document length effects, and (2) a\nlow-rank component of its embedding matrix that encodes inverse document\nfrequency information for the vocabulary. This suggests that the Cross-Encoder\nuses the same fundamental mechanisms as BM25, but further leverages their\ncapacity to capture semantics for improved retrieval performance. The granular\nunderstanding lays the groundwork for model editing to enhance model\ntransparency, addressing safety concerns, and improving scalability in training\nand real-world applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04645v1",
    "published_date": "2025-02-07 04:08:57 UTC",
    "updated_date": "2025-02-07 04:08:57 UTC"
  },
  {
    "arxiv_id": "2502.04644v1",
    "title": "Agentic Reasoning: Reasoning LLMs with Tools for the Deep Research",
    "authors": [
      "Junde Wu",
      "Jiayuan Zhu",
      "Yuyuan Liu"
    ],
    "abstract": "We introduce Agentic Reasoning, a framework that enhances large language\nmodel (LLM) reasoning by integrating external tool-using agents. Unlike\nconventional LLM-based reasoning approaches, which rely solely on internal\ninference, Agentic Reasoning dynamically engages web search, code execution,\nand structured reasoning-context memory to solve complex problems requiring\ndeep research and multi-step logical deduction. Our framework introduces the\nMind Map agent, which constructs a structured knowledge graph to track logical\nrelationships, improving deductive reasoning. Additionally, the integration of\nweb-search and coding agents enables real-time retrieval and computational\nanalysis, enhancing reasoning accuracy and decision-making. Evaluations on\nPhD-level scientific reasoning (GPQA) and domain-specific deep research tasks\ndemonstrate that our approach significantly outperforms existing models,\nincluding leading retrieval-augmented generation (RAG) systems and\nclosed-source LLMs. Moreover, our results indicate that agentic reasoning\nimproves expert-level knowledge synthesis, test-time scalability, and\nstructured problem-solving. The code is at:\nhttps://github.com/theworldofagents/Agentic-Reasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.04644v1",
    "published_date": "2025-02-07 04:08:46 UTC",
    "updated_date": "2025-02-07 04:08:46 UTC"
  },
  {
    "arxiv_id": "2502.04638v1",
    "title": "Learning Street View Representations with Spatiotemporal Contrast",
    "authors": [
      "Yong Li",
      "Yingjing Huang",
      "Gengchen Mai",
      "Fan Zhang"
    ],
    "abstract": "Street view imagery is extensively utilized in representation learning for\nurban visual environments, supporting various sustainable development tasks\nsuch as environmental perception and socio-economic assessment. However, it is\nchallenging for existing image representations to specifically encode the\ndynamic urban environment (such as pedestrians, vehicles, and vegetation), the\nbuilt environment (including buildings, roads, and urban infrastructure), and\nthe environmental ambiance (such as the cultural and socioeconomic atmosphere)\ndepicted in street view imagery to address downstream tasks related to the\ncity. In this work, we propose an innovative self-supervised learning framework\nthat leverages temporal and spatial attributes of street view imagery to learn\nimage representations of the dynamic urban environment for diverse downstream\ntasks. By employing street view images captured at the same location over time\nand spatially nearby views at the same time, we construct contrastive learning\ntasks designed to learn the temporal-invariant characteristics of the built\nenvironment and the spatial-invariant neighborhood ambiance. Our approach\nsignificantly outperforms traditional supervised and unsupervised methods in\ntasks such as visual place recognition, socioeconomic estimation, and\nhuman-environment perception. Moreover, we demonstrate the varying behaviors of\nimage representations learned through different contrastive learning objectives\nacross various downstream tasks. This study systematically discusses\nrepresentation learning strategies for urban studies based on street view\nimages, providing a benchmark that enhances the applicability of visual data in\nurban science. The code is available at https://github.com/yonglleee/UrbanSTCL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04638v1",
    "published_date": "2025-02-07 03:47:54 UTC",
    "updated_date": "2025-02-07 03:47:54 UTC"
  },
  {
    "arxiv_id": "2502.04636v1",
    "title": "An Empirical Study of Code Obfuscation Practices in the Google Play Store",
    "authors": [
      "Akila Niroshan",
      "Suranga Seneviratne",
      "Aruna Seneviratne"
    ],
    "abstract": "The Android ecosystem is vulnerable to issues such as app repackaging,\ncounterfeiting, and piracy, threatening both developers and users. To mitigate\nthese risks, developers often employ code obfuscation techniques. However,\nwhile effective in protecting legitimate applications, obfuscation also hinders\nsecurity investigations as it is often exploited for malicious purposes. As\nsuch, it is important to understand code obfuscation practices in Android apps.\nIn this paper, we analyze over 500,000 Android APKs from Google Play, spanning\nan eight-year period, to investigate the evolution and prevalence of code\nobfuscation techniques. First, we propose a set of classifiers to detect\nobfuscated code, tools, and techniques and then conduct a longitudinal analysis\nto identify trends. Our results show a 13% increase in obfuscation from 2016 to\n2023, with ProGuard and Allatori as the most commonly used tools. We also show\nthat obfuscation is more prevalent in top-ranked apps and gaming genres such as\nCasino apps. To our knowledge, this is the first large-scale study of\nobfuscation adoption in the Google Play Store, providing insights for\ndevelopers and security analysts.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04636v1",
    "published_date": "2025-02-07 03:41:40 UTC",
    "updated_date": "2025-02-07 03:41:40 UTC"
  },
  {
    "arxiv_id": "2503.05607v1",
    "title": "AceWGS: An LLM-Aided Framework to Accelerate Catalyst Design for Water-Gas Shift Reactions",
    "authors": [
      "Joyjit Chattoraj",
      "Brahim Hamadicharef",
      "Teo Shi Chang",
      "Yingzhi Zeng",
      "Chee Kok Poh",
      "Luwei Chen",
      "Teck Leong Tan"
    ],
    "abstract": "While the Water-Gas Shift (WGS) reaction plays a crucial role in hydrogen\nproduction for fuel cells, finding suitable catalysts to achieve high yields\nfor low-temperature WGS reactions remains a persistent challenge. Artificial\nIntelligence (AI) has shown promise in accelerating catalyst design by\nexploring vast candidate spaces, however, two key gaps limit its effectiveness.\nFirst, AI models primarily train on numerical data, which fail to capture\nessential text-based information, such as catalyst synthesis methods. Second,\nthe cross-disciplinary nature of catalyst design requires seamless\ncollaboration between AI, theory, experiments, and numerical simulations, often\nleading to communication barriers. To address these gaps, we present AceWGS, a\nLarge Language Models (LLMs)-aided framework to streamline WGS catalyst design.\nAceWGS interacts with researchers through natural language, answering queries\nbased on four features: (i) answering general queries, (ii) extracting\ninformation about the database comprising WGS-related journal articles, (iii)\ncomprehending the context described in these articles, and (iv) identifying\ncatalyst candidates using our proposed AI inverse model. We presented a\npractical case study demonstrating how AceWGS can accelerate the catalyst\ndesign process. AceWGS, built with open-source tools, offers an adjustable\nframework that researchers can readily adapt for a range of AI-accelerated\ncatalyst design applications, supporting seamless integration across\ncross-disciplinary studies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05607v1",
    "published_date": "2025-02-07 02:36:47 UTC",
    "updated_date": "2025-02-07 02:36:47 UTC"
  },
  {
    "arxiv_id": "2503.03753v1",
    "title": "Generative Diffusion Model-based Compression of MIMO CSI",
    "authors": [
      "Heasung Kim",
      "Taekyun Lee",
      "Hyeji Kim",
      "Gustavo De Veciana",
      "Mohamed Amine Arfaoui",
      "Asil Koc",
      "Phil Pietraski",
      "Guodong Zhang",
      "John Kaewell"
    ],
    "abstract": "While neural lossy compression techniques have markedly advanced the\nefficiency of Channel State Information (CSI) compression and reconstruction\nfor feedback in MIMO communications, efficient algorithms for more challenging\nand practical tasks-such as CSI compression for future channel prediction and\nreconstruction with relevant side information-remain underexplored, often\nresulting in suboptimal performance when existing methods are extended to these\nscenarios. To that end, we propose a novel framework for compression with side\ninformation, featuring an encoding process with fixed-rate compression using a\ntrainable codebook for codeword quantization, and a decoding procedure modeled\nas a backward diffusion process conditioned on both the codeword and the side\ninformation. Experimental results show that our method significantly\noutperforms existing CSI compression algorithms, often yielding over twofold\nperformance improvement by achieving comparable distortion at less than half\nthe data rate of competing methods in certain scenarios. These findings\nunderscore the potential of diffusion-based compression for practical\ndeployment in communication systems.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "eess.SP",
      "math.IT",
      "68P30",
      "I.2.0"
    ],
    "primary_category": "cs.IT",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03753v1",
    "published_date": "2025-02-07 02:24:12 UTC",
    "updated_date": "2025-02-07 02:24:12 UTC"
  },
  {
    "arxiv_id": "2502.04602v1",
    "title": "Extracting and Understanding the Superficial Knowledge in Alignment",
    "authors": [
      "Runjin Chen",
      "Gabriel Jacob Perin",
      "Xuxi Chen",
      "Xilun Chen",
      "Yan Han",
      "Nina S. T. Hirata",
      "Junyuan Hong",
      "Bhavya Kailkhura"
    ],
    "abstract": "Alignment of large language models (LLMs) with human values and preferences,\noften achieved through fine-tuning based on human feedback, is essential for\nensuring safe and responsible AI behaviors. However, the process typically\nrequires substantial data and computation resources. Recent studies have\nrevealed that alignment might be attainable at lower costs through simpler\nmethods, such as in-context learning. This leads to the question: Is alignment\npredominantly superficial? In this paper, we delve into this question and\nprovide a quantitative analysis. We formalize the concept of superficial\nknowledge, defining it as knowledge that can be acquired through easily token\nrestyling, without affecting the model's ability to capture underlying causal\nrelationships between tokens. We propose a method to extract and isolate\nsuperficial knowledge from aligned models, focusing on the shallow\nmodifications to the final token selection process. By comparing models\naugmented only with superficial knowledge to fully aligned models, we quantify\nthe superficial portion of alignment. Our findings reveal that while\nsuperficial knowledge constitutes a significant portion of alignment,\nparticularly in safety and detoxification tasks, it is not the whole story.\nTasks requiring reasoning and contextual understanding still rely on deeper\nknowledge. Additionally, we demonstrate two practical advantages of isolated\nsuperficial knowledge: (1) it can be transferred between models, enabling\nefficient offsite alignment of larger models using extracted superficial\nknowledge from smaller models, and (2) it is recoverable, allowing for the\nrestoration of alignment in compromised models without sacrificing performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04602v1",
    "published_date": "2025-02-07 01:32:19 UTC",
    "updated_date": "2025-02-07 01:32:19 UTC"
  },
  {
    "arxiv_id": "2502.04593v1",
    "title": "The $α$-Alternator: Dynamic Adaptation To Varying Noise Levels In Sequences Using The Vendi Score For Improved Robustness and Performance",
    "authors": [
      "Mohammad Reza Rezaei",
      "Adji Bousso Dieng"
    ],
    "abstract": "Current state-of-the-art dynamical models, such as Mamba, assume the same\nlevel of noisiness for all elements of a given sequence, which limits their\nperformance on noisy temporal data. In this paper, we introduce the\n$\\alpha$-Alternator, a novel generative model for time-dependent data that\ndynamically adapts to the complexity introduced by varying noise levels in\nsequences. The $\\alpha$-Alternator leverages the Vendi Score (VS), a flexible\nsimilarity-based diversity metric, to adjust, at each time step $t$, the\ninfluence of the sequence element at time $t$ and the latent representation of\nthe dynamics up to that time step on the predicted future dynamics. This\ninfluence is captured by a parameter that is learned and shared across all\nsequences in a given dataset. The sign of this parameter determines the\ndirection of influence. A negative value indicates a noisy dataset, where a\nsequence element that increases the VS is considered noisy, and the model\nrelies more on the latent history when processing that element. Conversely,\nwhen the parameter is positive, a sequence element that increases the VS is\nconsidered informative, and the $\\alpha$-Alternator relies more on this new\ninput than on the latent history when updating its predicted latent dynamics.\nThe $\\alpha$-Alternator is trained using a combination of observation masking\nand Alternator loss minimization. Masking simulates varying noise levels in\nsequences, enabling the model to be more robust to these fluctuations and\nimproving its performance in trajectory prediction, imputation, and\nforecasting. Our experimental results demonstrate that the $\\alpha$-Alternator\noutperforms both Alternators and state-of-the-art state-space models across\nneural decoding and time-series forecasting benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The codebase will be made available upon publication. This paper is\n  dedicated to Patrice Lumumba",
    "pdf_url": "http://arxiv.org/pdf/2502.04593v1",
    "published_date": "2025-02-07 01:00:16 UTC",
    "updated_date": "2025-02-07 01:00:16 UTC"
  },
  {
    "arxiv_id": "2502.04592v1",
    "title": "CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial Forecasting by Integrating Time Series Patterns and Salient Macroeconomic Announcements",
    "authors": [
      "Yang Zhang",
      "Wenbo Yang",
      "Jun Wang",
      "Qiang Ma",
      "Jie Xiong"
    ],
    "abstract": "Accurately forecasting the impact of macroeconomic events is critical for\ninvestors and policymakers. Salient events like monetary policy decisions and\nemployment reports often trigger market movements by shaping expectations of\neconomic growth and risk, thereby establishing causal relationships between\nevents and market behavior. Existing forecasting methods typically focus either\non textual analysis or time-series modeling, but fail to capture the\nmulti-modal nature of financial markets and the causal relationship between\nevents and price movements. To address these gaps, we propose CAMEF\n(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a\nmulti-modality framework that effectively integrates textual and time-series\ndata with a causal learning mechanism and an LLM-based counterfactual event\naugmentation technique for causal-enhanced financial forecasting. Our\ncontributions include: (1) a multi-modal framework that captures causal\nrelationships between policy texts and historical price data; (2) a new\nfinancial dataset with six types of macroeconomic releases from 2008 to April\n2024, and high-frequency real trading data for five key U.S. financial assets;\nand (3) an LLM-based counterfactual event augmentation strategy. We compare\nCAMEF to state-of-the-art transformer-based time-series and multi-modal\nbaselines, and perform ablation studies to validate the effectiveness of the\ncausal learning mechanism and event types.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04592v1",
    "published_date": "2025-02-07 00:55:25 UTC",
    "updated_date": "2025-02-07 00:55:25 UTC"
  },
  {
    "arxiv_id": "2502.04591v3",
    "title": "Rethinking Oversmoothing in Graph Neural Networks: A Rank-Based Perspective",
    "authors": [
      "Kaicheng Zhang",
      "Piero Deidda",
      "Desmond Higham",
      "Francesco Tudisco"
    ],
    "abstract": "Oversmoothing is a fundamental challenge in graph neural networks (GNNs): as\nthe number of layers increases, node embeddings become increasingly similar,\nand model performance drops sharply. Traditionally, oversmoothing has been\nquantified using metrics that measure the similarity of neighbouring node\nfeatures, such as the Dirichlet energy. While these metrics are related to\noversmoothing, we argue they have critical limitations and fail to reliably\ncapture oversmoothing in realistic scenarios. For instance, they provide\nmeaningful insights only for very deep networks and under somewhat strict\nconditions on the norm of network weights and feature representations. As an\nalternative, we propose measuring oversmoothing by examining the numerical or\neffective rank of the feature representations. We provide theoretical support\nfor this approach, demonstrating that the numerical rank of feature\nrepresentations converges to one for a broad family of nonlinear activation\nfunctions under the assumption of nonnegative trained weights. To the best of\nour knowledge, this is the first result that proves the occurrence of\noversmoothing in the nonlinear setting without assumptions on the boundedness\nof the weight matrices. Along with the theoretical findings, we provide\nextensive numerical evaluation across diverse graph architectures. Our results\nshow that rank-based metrics consistently capture oversmoothing, whereas\nenergy-based metrics often fail. Notably, we reveal that a significant drop in\nthe rank aligns closely with performance degradation, even in scenarios where\nenergy metrics remain unchanged.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04591v3",
    "published_date": "2025-02-07 00:55:05 UTC",
    "updated_date": "2025-05-20 23:43:44 UTC"
  },
  {
    "arxiv_id": "2502.04580v1",
    "title": "Technical Debt in In-Context Learning: Diminishing Efficiency in Long Context",
    "authors": [
      "Taejong Joo",
      "Diego Klabjan"
    ],
    "abstract": "Transformers have demonstrated remarkable in-context learning (ICL)\ncapabilities, adapting to new tasks by simply conditioning on demonstrations\nwithout parameter updates. Compelling empirical and theoretical evidence\nsuggests that ICL, as a general-purpose learner, could outperform task-specific\nmodels. However, it remains unclear to what extent the transformers optimally\nlearn in-context compared to principled learning algorithms. To bridge this\ngap, we introduce a new framework for quantifying optimality of ICL as a\nlearning algorithm in stylized settings. Our findings reveal a striking\ndichotomy: while ICL initially matches the efficiency of a Bayes optimal\nestimator, its efficiency significantly deteriorates in long context. Through\nan information-theoretic analysis, we show that the diminishing efficiency is\ninherent to ICL. These results clarify the trade-offs in adopting ICL as a\nuniversal problem solver, motivating a new generation of on-the-fly adaptive\nmethods without the diminishing efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04580v1",
    "published_date": "2025-02-07 00:26:45 UTC",
    "updated_date": "2025-02-07 00:26:45 UTC"
  }
]