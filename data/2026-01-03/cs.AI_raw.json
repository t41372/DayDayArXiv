[
  {
    "arxiv_id": "2601.01301v2",
    "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies",
    "authors": [
      "Keith Frankston",
      "Benjamin Howard"
    ],
    "abstract": "We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.\n  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in \"Monte--Carlo tree search as regularized policy optimization\" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.\n  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages; an efficient implementation is available at https://github.com/bhoward73/rmcts",
    "pdf_url": "https://arxiv.org/pdf/2601.01301v2",
    "published_date": "2026-01-03 23:38:43 UTC",
    "updated_date": "2026-01-09 01:07:13 UTC"
  },
  {
    "arxiv_id": "2601.01299v1",
    "title": "T3C: Test-Time Tensor Compression with Consistency Guarantees",
    "authors": [
      "Ismail Lamaakal",
      "Chaymae Yahyati",
      "Yassine Maleh",
      "Khalid El Makkaoui",
      "Ibrahim Ouahbi"
    ],
    "abstract": "We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget. A fast, layerwise consistency certificate, computed from spectral proxies and activation statistics, upper-bounds logit drift and regularizes training, yielding a practical reliability signal with negligible overhead. On ImageNet-1k, T3C shifts the vision Pareto frontier: for ResNet-50 at matched accuracy (\\leq 0.5% drop), p50 latency is 1.18ms with a 38MB model, outperforming PTQ-8b (1.44ms, 88MB); for ViT-B/16, T3C reaches 2.30ms p50 with 59MB, improving over strong PTQ/QAT baselines. A single T3C checkpoint therefore provides predictable, certificate-backed accuracy-latency-size trade-offs on demand across devices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01299v1",
    "published_date": "2026-01-03 23:16:27 UTC",
    "updated_date": "2026-01-03 23:16:27 UTC"
  },
  {
    "arxiv_id": "2601.01298v1",
    "title": "Warp-Cortex: An Asynchronous, Memory-Efficient Architecture for Million-Agent Cognitive Scaling on Consumer Hardware",
    "authors": [
      "Jorge L. Ruiz Williams"
    ],
    "abstract": "Current multi-agent Large Language Model (LLM) frameworks suffer from linear memory scaling, rendering \"System 2\" parallel reasoning impractical on consumer hardware. We present Warp Cortex, an asynchronous architecture that theoretically enables million-agent cognitive scaling by decoupling agent logic from physical memory. Through Singleton Weight Sharing and a novel Topological Synapse--inspired by hybrid landmarking techniques from Topological Data Analysis (TDA)--we reduce memory complexity from O(N * L) to O(1) for weights and O(N * k) for context, where k << L. By treating the KV-cache as a point cloud in latent space, we apply witness-complex-inspired sparsification to preserve persistent homological features of the context manifold. On a single NVIDIA RTX 4090, we empirically demonstrate 100 concurrent agents at 2.2 GB total VRAM, with theoretical capacity exceeding 1,000 agents before compute latency becomes the bottleneck. We further introduce Referential Injection, a non-intrusive KV-cache update mechanism that allows asynchronous sub-agents to influence primary generation without stream disruption.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01298v1",
    "published_date": "2026-01-03 23:11:21 UTC",
    "updated_date": "2026-01-03 23:11:21 UTC"
  },
  {
    "arxiv_id": "2601.01297v1",
    "title": "ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System",
    "authors": [
      "Anantha Sharma"
    ],
    "abstract": "Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity instability. This paper introduces Argus, A framework that reconceptualizes drift detection as tracking local statistics over a fixed spatial partition of the data manifold.\n  The key contributions are fourfold. First, it is proved that Voronoi tessellations over canonical orthonormal frames yield drift metrics that are invariant to orthogonal transformations. The rotations and reflections that preserve Euclidean geometry. Second, it is established that this framework achieves O(N) complexity per snapshot while providing cell-level spatial localization of distributional change. Third, a graph-theoretic characterization of drift propagation is developed that distinguishes coherent distributional shifts from isolated perturbations. Fourth, product quantization tessellation is introduced for scaling to very high dimensions (d>500) by decomposing the space into independent subspaces and aggregating drift signals across subspaces.\n  This paper formalizes the theoretical foundations, proves invariance properties, and presents experimental validation demonstrating that the framework correctly identifies drift under coordinate rotation while existing methods produce false positives. The tessellated approach offers a principled geometric foundation for distribution monitoring that preserves high-dimensional structure without the computational burden of pairwise comparisons.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages",
    "pdf_url": "https://arxiv.org/pdf/2601.01297v1",
    "published_date": "2026-01-03 22:39:20 UTC",
    "updated_date": "2026-01-03 22:39:20 UTC"
  },
  {
    "arxiv_id": "2601.01296v1",
    "title": "Aggressive Compression Enables LLM Weight Theft",
    "authors": [
      "Davis Brown",
      "Juan-Pablo Rivera",
      "Dan Hendrycks",
      "Mantas Mazeika"
    ],
    "abstract": "As frontier AIs become more powerful and costly to develop, adversaries have increasing incentives to steal model weights by mounting exfiltration attacks. In this work, we consider exfiltration attacks where an adversary attempts to sneak model weights out of a datacenter over a network. While exfiltration attacks are multi-step cyber attacks, we demonstrate that a single factor, the compressibility of model weights, significantly heightens exfiltration risk for large language models (LLMs). We tailor compression specifically for exfiltration by relaxing decompression constraints and demonstrate that attackers could achieve 16x to 100x compression with minimal trade-offs, reducing the time it would take for an attacker to illicitly transmit model weights from the defender's server from months to days. Finally, we study defenses designed to reduce exfiltration risk in three distinct ways: making models harder to compress, making them harder to 'find,' and tracking provenance for post-attack analysis using forensic watermarks. While all defenses are promising, the forensic watermark defense is both effective and cheap, and therefore is a particularly attractive lever for mitigating weight-exfiltration risk.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "An early version of this work was presented at the SoLAR Workshop at NeurIPS 2024",
    "pdf_url": "https://arxiv.org/pdf/2601.01296v1",
    "published_date": "2026-01-03 22:34:53 UTC",
    "updated_date": "2026-01-03 22:34:53 UTC"
  },
  {
    "arxiv_id": "2601.01294v1",
    "title": "Diffusion Timbre Transfer Via Mutual Information Guided Inpainting",
    "authors": [
      "Ching Ho Lee",
      "Javier Nistal",
      "Stefan Lattner",
      "Marco Pasini",
      "George Fazekas"
    ],
    "abstract": "We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages, 2 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2601.01294v1",
    "published_date": "2026-01-03 21:53:35 UTC",
    "updated_date": "2026-01-03 21:53:35 UTC"
  },
  {
    "arxiv_id": "2601.01288v1",
    "title": "PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS",
    "authors": [
      "Evgenii Rudakov",
      "Jonathan Shock",
      "Benjamin Ultan Cowley"
    ],
    "abstract": "Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.PF",
      "cs.RO"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01288v1",
    "published_date": "2026-01-03 21:19:57 UTC",
    "updated_date": "2026-01-03 21:19:57 UTC"
  },
  {
    "arxiv_id": "2601.01281v1",
    "title": "AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures",
    "authors": [
      "Sifatullah Sheikh Urmi",
      "Kirtonia Nuzath Tabassum Arthi",
      "Md Al-Imran"
    ],
    "abstract": "The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 6 figures, 3 tables. Conference paper",
    "pdf_url": "https://arxiv.org/pdf/2601.01281v1",
    "published_date": "2026-01-03 20:44:50 UTC",
    "updated_date": "2026-01-03 20:44:50 UTC"
  },
  {
    "arxiv_id": "2601.01280v2",
    "title": "Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory",
    "authors": [
      "Sen Hu",
      "Yuxiang Wei",
      "Jiaxin Ran",
      "Zhiyuan Yao",
      "Xueran Han",
      "Huacan Wang",
      "Ronghao Chen",
      "Lei Zou"
    ],
    "abstract": "Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we conduct controlled, stage-wise experiments on LongMemEval and HaluMem, comparing common design choices in memory representation, organization, maintenance, and retrieval. Our results show that many performance differences are driven by foundational system settings rather than specific architectural innovations. Based on these findings, we identify stable and reliable strong baselines for future dialog memory research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01280v2",
    "published_date": "2026-01-03 20:39:39 UTC",
    "updated_date": "2026-01-07 18:16:54 UTC"
  },
  {
    "arxiv_id": "2601.01279v1",
    "title": "LLM Collusion",
    "authors": [
      "Shengyu Cao",
      "Ming Hu"
    ],
    "abstract": "We study how delegating pricing to large language models (LLMs) can facilitate collusion in a duopoly when both sellers rely on the same pre-trained model. The LLM is characterized by (i) a propensity parameter capturing its internal bias toward high-price recommendations and (ii) an output-fidelity parameter measuring how tightly outputs track that bias; the propensity evolves through retraining. We show that configuring LLMs for robustness and reproducibility can induce collusion via a phase transition: there exists a critical output-fidelity threshold that pins down long-run behavior. Below it, competitive pricing is the unique long-run outcome. Above it, the system is bistable, with competitive and collusive pricing both locally stable and the realized outcome determined by the model's initial preference. The collusive regime resembles tacit collusion: prices are elevated on average, yet occasional low-price recommendations provide plausible deniability. With perfect fidelity, full collusion emerges from any interior initial condition. For finite training batches of size $b$, infrequent retraining (driven by computational costs) further amplifies collusion: conditional on starting in the collusive basin, the probability of collusion approaches one as $b$ grows, since larger batches dampen stochastic fluctuations that might otherwise tip the system toward competition. The indeterminacy region shrinks at rate $O(1/\\sqrt{b})$.",
    "categories": [
      "econ.TH",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "econ.TH",
    "comment": "44 pages",
    "pdf_url": "https://arxiv.org/pdf/2601.01279v1",
    "published_date": "2026-01-03 20:38:21 UTC",
    "updated_date": "2026-01-03 20:38:21 UTC"
  },
  {
    "arxiv_id": "2601.06119v1",
    "title": "L2CU: Learning to Complement Unseen Users",
    "authors": [
      "Dileepa Pitawela",
      "Gustavo Carneiro",
      "Hsiang-Ting Chen"
    ],
    "abstract": "Recent research highlights the potential of machine learning models to learn to complement (L2C) human strengths; however, generalizing this capability to unseen users remains a significant challenge. Existing L2C methods oversimplify interaction between human and AI by relying on a single, global user model that neglects individual user variability, leading to suboptimal cooperative performance. Addressing this, we introduce L2CU, a novel L2C framework for human-AI cooperative classification with unseen users. Given sparse and noisy user annotations, L2CU identifies representative annotator profiles capturing distinct labeling patterns. By matching unseen users to these profiles, L2CU leverages profile-specific models to complement the user and achieve superior joint accuracy. We evaluate L2CU on datasets (CIFAR-10N, CIFAR-10H, Fashion-MNIST-H, Chaoyang and AgNews), demonstrating its effectiveness as a model-agnostic solution for improving human-AI cooperative classification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in IEEE Access (https://ieeexplore.ieee.org/document/11314492)",
    "pdf_url": "https://arxiv.org/pdf/2601.06119v1",
    "published_date": "2026-01-03 20:30:48 UTC",
    "updated_date": "2026-01-03 20:30:48 UTC"
  },
  {
    "arxiv_id": "2601.01266v2",
    "title": "From Policy to Logic for Efficient and Interpretable Coverage Assessment",
    "authors": [
      "Rhitabrat Pokharel",
      "Hamid Reza Hassanzadeh",
      "Ameeta Agrawal"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach designed to support human reviewers by making policy interpretation more efficient and interpretable. We introduce a methodology that pairs a coverage-aware retriever with symbolic rule-based reasoning to surface relevant policy language, organize it into explicit facts and rules, and generate auditable rationales. This hybrid system minimizes the number of LLM inferences required which reduces overall model cost. Notably, our approach achieves a 44% reduction in inference cost alongside a 4.5% improvement in F1 score, demonstrating both efficiency and effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AIMedHealth @ AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2601.01266v2",
    "published_date": "2026-01-03 19:24:51 UTC",
    "updated_date": "2026-01-08 18:28:40 UTC"
  },
  {
    "arxiv_id": "2601.01260v1",
    "title": "MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance",
    "authors": [
      "Hamad Khan",
      "Saddam Hussain Khan"
    ],
    "abstract": "The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "28 Pages, Tables 12, Figure 09",
    "pdf_url": "https://arxiv.org/pdf/2601.01260v1",
    "published_date": "2026-01-03 19:01:33 UTC",
    "updated_date": "2026-01-03 19:01:33 UTC"
  },
  {
    "arxiv_id": "2601.06118v1",
    "title": "Beyond Reproducibility: Token Probabilities Expose Large Language Model Nondeterminism",
    "authors": [
      "Tairan Fu",
      "Gonzalo Martínez",
      "Javier Conde",
      "Carlos Arriaga",
      "Pedro Reviriego",
      "Xiuyuan Qi",
      "Shanshan Liu"
    ],
    "abstract": "The execution of Large Language Models (LLMs) has been shown to produce nondeterministic results when run on Graphics Processing Units (GPUs), even when they are configured to produce deterministic results. This is due to the finite precision effects of the arithmetic operations, which depend on the order in which they are executed. This order, in turn, depends on the processes that are running concurrently on the GPU. Previous studies have focused on the impact of nondeterminism on the text generated by the LLMs or on proposing mechanisms to achieve deterministic execution. This work takes a closer look at nondeterminism by analyzing the variations on the token probabilities, not on the generated text. Interestingly, all the models evaluated have similar results in both the trends and the actual values of the variations of the probabilities. In particular, the results show that the effects of nondeterminism are significant for token probabilities that are in the range of 0.1 to 0.9, while they are much smaller when the probabilities are close to 0 or 1. This has significant implications for our understanding of nondeterminism. The first is that nondeterminism will likely have a non-negligible impact on generated text when the temperature is not zero, as it introduces significant variations in the token probabilities except when they are close to 0 or 1. Secondly, it suggests that all models have similar non deterministic variations at the token probability level. Therefore, different variations in the performance of the generated text, for example, when measuring accuracy on a benchmark, seem to come from different token probabilities or response lengths. A third implication is that we may be able to estimate the impact of nondeterminism by running a single inference and analyzing the token level probabilities, instead of having to run the same inference many times.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06118v1",
    "published_date": "2026-01-03 18:58:19 UTC",
    "updated_date": "2026-01-03 18:58:19 UTC"
  },
  {
    "arxiv_id": "2601.01257v1",
    "title": "Seamlessly Natural: Image Stitching with Natural Appearance Preservation",
    "authors": [
      "Gaetane Lorna N. Tchana",
      "Damaris Belle M. Fotso",
      "Antonio Hendricks",
      "Christophe Bobda"
    ],
    "abstract": "This paper introduces SENA (SEamlessly NAtural), a geometry-driven image stitching approach that prioritizes structural fidelity in challenging real-world scenes characterized by parallax and depth variation. Conventional image stitching relies on homographic alignment, but this rigid planar assumption often fails in dual-camera setups with significant scene depth, leading to distortions such as visible warps and spherical bulging. SENA addresses these fundamental limitations through three key contributions. First, we propose a hierarchical affine-based warping strategy, combining global affine initialization with local affine refinement and smooth free-form deformation. This design preserves local shape, parallelism, and aspect ratios, thereby avoiding the hallucinated structural distortions commonly introduced by homography-based models. Second, we introduce a geometry-driven adequate zone detection mechanism that identifies parallax-minimized regions directly from the disparity consistency of RANSAC-filtered feature correspondences, without relying on semantic segmentation. Third, building upon this adequate zone, we perform anchor-based seamline cutting and segmentation, enforcing a one-to-one geometric correspondence across image pairs by construction, which effectively eliminates ghosting, duplication, and smearing artifacts in the final panorama.\n  Extensive experiments conducted on challenging datasets demonstrate that SENA achieves alignment accuracy comparable to leading homography-based methods, while significantly outperforming them in critical visual metrics such as shape preservation, texture integrity, and overall visual realism.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "eess.SP"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01257v1",
    "published_date": "2026-01-03 18:40:35 UTC",
    "updated_date": "2026-01-03 18:40:35 UTC"
  },
  {
    "arxiv_id": "2601.01237v1",
    "title": "Benchmarking the Computational and Representational Efficiency of State Space Models against Transformers on Long-Context Dyadic Sessions",
    "authors": [
      "Abidemi Koledoye",
      "Chinemerem Unachukwu",
      "Gold Nwobu",
      "Hasin Rana"
    ],
    "abstract": "State Space Models (SSMs) have emerged as a promising alternative to Transformers for long-context sequence modeling, offering linear $O(N)$ computational complexity compared to the Transformer's quadratic $O(N^2)$ scaling. This paper presents a comprehensive benchmarking study comparing the Mamba SSM against the LLaMA Transformer on long-context sequences, using dyadic therapy sessions as a representative test case. We evaluate both architectures across two dimensions: (1) computational efficiency, where we measure memory usage and inference speed from 512 to 8,192 tokens, and (2) representational efficiency, where we analyze hidden state dynamics and attention patterns. Our findings provide actionable insights for practitioners working with long-context applications, establishing precise conditions under which SSMs offer advantages over Transformers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2601.01237v1",
    "published_date": "2026-01-03 17:05:01 UTC",
    "updated_date": "2026-01-03 17:05:01 UTC"
  },
  {
    "arxiv_id": "2601.01225v1",
    "title": "Stylometry Analysis of Human and Machine Text for Academic Integrity",
    "authors": [
      "Hezam Albaqami",
      "Muhammad Asif Ayub",
      "Nasir Ahmad",
      "Yaseen Ahmad",
      "Mohammed M. Alqahtani",
      "Abdullah M. Algamdi",
      "Almoaid A. Owaidah",
      "Kashif Ahmad"
    ],
    "abstract": "This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a comprehensive analysis of the topic by targeting four relevant tasks, including (i) classification of human and machine text, (ii) differentiating in single and multi-authored documents, (iii) author change detection within multi-authored documents, and (iv) author recognition in collaboratively produced documents. The solutions proposed for the tasks are evaluated on two datasets generated with Gemini using two different prompts, including a normal and a strict set of instructions. During experiments, some reduction in the performance of the proposed solutions is observed on the dataset generated through the strict prompt, demonstrating the complexities involved in detecting machine-generated text with cleverly crafted prompts. The generated datasets, code, and other relevant materials are made publicly available on GitHub, which are expected to provide a baseline for future research in the domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 9 tables, 3 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.01225v1",
    "published_date": "2026-01-03 16:13:38 UTC",
    "updated_date": "2026-01-03 16:13:38 UTC"
  },
  {
    "arxiv_id": "2601.01224v1",
    "title": "Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment",
    "authors": [
      "Bac Nguyen",
      "Yuhta Takida",
      "Naoki Murata",
      "Chieh-Hsin Lai",
      "Toshimitsu Uesaka",
      "Stefano Ermon",
      "Yuki Mitsufuji"
    ],
    "abstract": "Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01224v1",
    "published_date": "2026-01-03 16:10:18 UTC",
    "updated_date": "2026-01-03 16:10:18 UTC"
  },
  {
    "arxiv_id": "2601.01215v1",
    "title": "Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code",
    "authors": [
      "Prateek Rajput",
      "Yewei Song",
      "Abdoul Aziz Bonkoungou",
      "Iyiola E. Olatunji",
      "Abdoul Kader Kabore",
      "Jacques Klein",
      "Tegawendé F. Bissyandé"
    ],
    "abstract": "Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "11 Pages, 11 figures, Accepted at ICSE SEIP",
    "pdf_url": "https://arxiv.org/pdf/2601.01215v1",
    "published_date": "2026-01-03 15:42:21 UTC",
    "updated_date": "2026-01-03 15:42:21 UTC"
  },
  {
    "arxiv_id": "2601.06116v1",
    "title": "Structure-Aware Diversity Pursuit as an AI Safety Strategy against Homogenization",
    "authors": [
      "Ian Rios-Sialer"
    ],
    "abstract": "Generative AI models reproduce the biases in the training data and can further amplify them through mode collapse. We refer to the resulting harmful loss of diversity as homogenization. Our position is that homogenization should be a primary concern in AI safety. We introduce xeno-reproduction as the strategy that mitigates homogenization. For auto-regressive LLMs, we formalize xeno-reproduction as a structure-aware diversity pursuit. Our contribution is foundational, intended to open an essential line of research and invite collaboration to advance diversity.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06116v1",
    "published_date": "2026-01-03 15:34:27 UTC",
    "updated_date": "2026-01-03 15:34:27 UTC"
  },
  {
    "arxiv_id": "2601.06115v1",
    "title": "Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions",
    "authors": [
      "V. Cheung"
    ],
    "abstract": "Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired \"Dream Layer\" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, 35 pages (5 pages of appendix), 2 figures, 3 tables. Conceptual and architectural proposal with preliminary simulation results",
    "pdf_url": "https://arxiv.org/pdf/2601.06115v1",
    "published_date": "2026-01-03 15:19:54 UTC",
    "updated_date": "2026-01-03 15:19:54 UTC"
  },
  {
    "arxiv_id": "2601.01206v1",
    "title": "MentalGame: Predicting Personality-Job Fitness for Software Developers Using Multi-Genre Games and Machine Learning Approaches",
    "authors": [
      "Soroush Elyasi",
      "Arya VarastehNezhad",
      "Fattaneh Taghiyareh"
    ],
    "abstract": "Personality assessment in career guidance and personnel selection traditionally relies on self-report questionnaires, which are susceptible to response bias, fatigue, and intentional distortion. Game-based assessment offers a promising alternative by capturing implicit behavioral signals during gameplay. This study proposes a multi-genre serious-game framework combined with machine-learning techniques to predict suitability for software development roles. Developer-relevant personality and behavioral traits were identified through a systematic literature review and an empirical study of professional software engineers. A custom mobile game was designed to elicit behaviors related to problem solving, planning, adaptability, persistence, time management, and information seeking. Fine-grained gameplay event data were collected and analyzed using a two-phase modeling strategy where suitability was predicted exclusively from gameplay-derived behavioral features. Results show that our model achieved up to 97% precision and 94% accuracy. Behavioral analysis revealed that proper candidates exhibited distinct gameplay patterns, such as more wins in puzzle-based games, more side challenges, navigating menus more frequently, and exhibiting fewer pauses, retries, and surrender actions. These findings demonstrate that implicit behavioral traces captured during gameplay is promising in predicting software-development suitability without explicit personality testing, supporting serious games as a scalable, engaging, and less biased alternative for career assessment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01206v1",
    "published_date": "2026-01-03 15:09:02 UTC",
    "updated_date": "2026-01-03 15:09:02 UTC"
  },
  {
    "arxiv_id": "2601.06114v1",
    "title": "GroupSegment-SHAP: Shapley Value Explanations with Group-Segment Players for Multivariate Time Series",
    "authors": [
      "Jinwoong Kim",
      "Sangjin Park"
    ],
    "abstract": "Multivariate time-series models achieve strong predictive performance in healthcare, industry, energy, and finance, but how they combine cross-variable interactions with temporal dynamics remains unclear. SHapley Additive exPlanations (SHAP) are widely used for interpretation. However, existing time-series variants typically treat the feature and time axes independently, fragmenting structural signals formed jointly by multiple variables over specific intervals. We propose GroupSegment SHAP (GS-SHAP), which constructs explanatory units as group-segment players based on cross-variable dependence and distribution shifts over time, and then quantifies each unit's contribution via Shapley attribution. We evaluate GS-SHAP across four real-world domains: human activity recognition, power-system forecasting, medical signal analysis, and financial time series, and compare it with KernelSHAP, TimeSHAP, SequenceSHAP, WindowSHAP, and TSHAP. GS-SHAP improves deletion-based faithfulness (DeltaAUC) by about 1.7x on average over time-series SHAP baselines, while reducing wall-clock runtime by about 40 percent on average under matched perturbation budgets. A financial case study shows that GS-SHAP identifies interpretable multivariate-temporal interactions among key market variables during high-volatility regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "https://arxiv.org/pdf/2601.06114v1",
    "published_date": "2026-01-03 14:59:18 UTC",
    "updated_date": "2026-01-03 14:59:18 UTC"
  },
  {
    "arxiv_id": "2601.01202v1",
    "title": "RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models",
    "authors": [
      "Jiazhu Dai",
      "Huihui Jiang"
    ],
    "abstract": "Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01202v1",
    "published_date": "2026-01-03 14:59:15 UTC",
    "updated_date": "2026-01-03 14:59:15 UTC"
  },
  {
    "arxiv_id": "2601.01195v1",
    "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering",
    "authors": [
      "Wuzhenghong Wen",
      "Chao Xue",
      "Su Pan",
      "Yuwei Sun",
      "Minlong Peng"
    ],
    "abstract": "Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.01195v1",
    "published_date": "2026-01-03 14:27:01 UTC",
    "updated_date": "2026-01-03 14:27:01 UTC"
  },
  {
    "arxiv_id": "2601.06113v1",
    "title": "Towards Infinite Length Extrapolation: A Unified Approach",
    "authors": [
      "Nitin Vetcha"
    ],
    "abstract": "Large language models (LLMs) have revolutionized natural language processing, but their ability to process long sequences is fundamentally limited by the context window size during training. Existing length extrapolation methods often suffer from performance degradation or computational inefficiencies. We thereby use a unified framework that reinterprets positional encoding methods as a decomposition of the attention score into a multiplicative transformation and an additive bias. This perspective not only subsumes popular approaches such as relative position embeddings and attention-bias moderated approaches but also exposes their inherent limitations in handling long-range dependencies. To address these shortcomings, motivated by our framework, we introduce Adaptive Positional Encoding (APE), which leverages adaptive frequency modulation and an intricately designed decay bias that incorporates linear, logarithmic, and square-root terms. Our theoretical analysis establishes conditions for infinite-context extrapolation, ensuring that the softmax normalization remains well-defined over unbounded sequences while preserving long-distance correlations, entropy boundedness and gradient positional sensitivity. We substantiate our claims with an experimental case study on TinyStories dataset as well as a new synthetic dataset, \\emph{Long Tiny Stories} featuring stories up to 32,000 words. Relevant code, dataset and model weights are available at https://anonymous.4open.science/r/Check-2DAD/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 7 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.06113v1",
    "published_date": "2026-01-03 14:10:23 UTC",
    "updated_date": "2026-01-03 14:10:23 UTC"
  },
  {
    "arxiv_id": "2601.06112v1",
    "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions",
    "authors": [
      "Aayush Gupta"
    ],
    "abstract": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures, 8 tables. Evaluates ReAct vs Reflexion across four tool-using domains with perturbation (epsilon) and fault-injection (lambda) stress testing; 1,280 total episodes",
    "pdf_url": "https://arxiv.org/pdf/2601.06112v1",
    "published_date": "2026-01-03 13:41:33 UTC",
    "updated_date": "2026-01-03 13:41:33 UTC"
  },
  {
    "arxiv_id": "2601.06111v2",
    "title": "LLM Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions",
    "authors": [
      "Fatima Koaik",
      "Aayush Gupta",
      "Farahan Raza Sheikh"
    ],
    "abstract": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis.\n  We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 1 figure, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2601.06111v2",
    "published_date": "2026-01-03 13:25:33 UTC",
    "updated_date": "2026-01-21 06:47:21 UTC"
  },
  {
    "arxiv_id": "2601.06109v1",
    "title": "CBMAS: Cognitive Behavioral Modeling via Activation Steering",
    "authors": [
      "Ahmed H. Ismail",
      "Anthony Kuang",
      "Ayo Akinkugbe",
      "Kevin Zhu",
      "Sean O'Brien"
    ],
    "abstract": "Large language models (LLMs) often encode cognitive behaviors unpredictably across prompts, layers, and contexts, making them difficult to diagnose and control. We present CBMAS, a diagnostic framework for continuous activation steering, which extends cognitive bias analysis from discrete before/after interventions to interpretable trajectories. By combining steering vector construction with dense α-sweeps, logit lens-based bias curves, and layer-site sensitivity analysis, our approach can reveal tipping points where small intervention strengths flip model behavior and show how steering effects evolve across layer depth. We argue that these continuous diagnostics offer a bridge between high-level behavioral evaluation and low-level representational dynamics, contributing to the cognitive interpretability of LLMs. Lastly, we provide a CLI and datasets for various cognitive behaviors at the project repository, https://github.com/shimamooo/CBMAS.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to CogInterp @ NeurIPS 2025. Equal contribution by Ahmed H. Ismail and Anthony Kuang",
    "pdf_url": "https://arxiv.org/pdf/2601.06109v1",
    "published_date": "2026-01-03 13:04:14 UTC",
    "updated_date": "2026-01-03 13:04:14 UTC"
  },
  {
    "arxiv_id": "2601.01162v1",
    "title": "Bridging the Semantic Gap for Categorical Data Clustering via Large Language Models",
    "authors": [
      "Zihua Yang",
      "Xin Liao",
      "Yiqun Zhang",
      "Yiu-ming Cheung"
    ],
    "abstract": "Categorical data are prevalent in domains such as healthcare, marketing, and bioinformatics, where clustering serves as a fundamental tool for pattern discovery. A core challenge in categorical data clustering lies in measuring similarity among attribute values that lack inherent ordering or distance. Without appropriate similarity measures, values are often treated as equidistant, creating a semantic gap that obscures latent structures and degrades clustering quality. Although existing methods infer value relationships from within-dataset co-occurrence patterns, such inference becomes unreliable when samples are limited, leaving the semantic context of the data underexplored. To bridge this gap, we present ARISE (Attention-weighted Representation with Integrated Semantic Embeddings), which draws on external semantic knowledge from Large Language Models (LLMs) to construct semantic-aware representations that complement the metric space of categorical data for accurate clustering. That is, LLM is adopted to describe attribute values for representation enhancement, and the LLM-enhanced embeddings are combined with the original data to explore semantically prominent clusters. Experiments on eight benchmark datasets demonstrate consistent improvements over seven representative counterparts, with gains of 19-27%. Code is available at https://github.com/develop-yang/ARISE",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to ICPR 2026",
    "pdf_url": "https://arxiv.org/pdf/2601.01162v1",
    "published_date": "2026-01-03 11:37:46 UTC",
    "updated_date": "2026-01-03 11:37:46 UTC"
  },
  {
    "arxiv_id": "2601.01134v1",
    "title": "AI-Powered Hybrid Intrusion Detection Framework for Cloud Security Using Novel Metaheuristic Optimization",
    "authors": [
      "Maryam Mahdi Alhusseini",
      "Alireza Rouhi",
      "Mohammad-Reza Feizi-Derakhshi"
    ],
    "abstract": "Cybersecurity poses considerable problems to Cloud Computing (CC), especially regarding Intrusion Detection Systems (IDSs), facing difficulties with skewed datasets and suboptimal classification model performance. This study presents the Hybrid Intrusion Detection System (HyIDS), an innovative IDS that employs the Energy Valley Optimizer (EVO) for Feature Selection (FS). Additionally, it introduces a novel technique for enhancing the cybersecurity of cloud computing through the integration of machine learning methodologies with the EVO Algorithm. The Energy Valley Optimizer (EVO) effectively diminished features in the CIC-DDoS2019 dataset from 88 to 38 and in the CSE-CIC-IDS2018 data from 80 to 43, significantly enhancing computing efficiency. HyIDS incorporates four Machine Learning (ML) models: Support Vector Machine (SVM), Random Forest (RF), Decision Tree (D_Tree), and K-Nearest Neighbors (KNN). The proposed HyIDS was assessed utilizing two real-world intrusion datasets, CIC-DDoS2019 and CSE-CIC-IDS2018, both distinguished by considerable class imbalances. The CIC-DDoS2019 dataset has a significant imbalance between DDoS assault samples and legal traffic, while the CSE-CIC-IDS2018 dataset primarily comprises benign traffic with insufficient representation of attack types, complicating the detection of minority attacks. A downsampling technique was employed to balance the datasets, hence improving detection efficacy for both benign and malicious traffic. Twenty-four trials were done, revealing substantial enhancements in categorization accuracy, precision, and recall. Our suggested D_TreeEVO model attained an accuracy rate of 99.13% and an F1 score of 98.94% on the CIC-DDoS2019 dataset, and an accuracy rate of 99.78% and an F1 score of 99.70% on the CSE-CIC-IDS2018 data. These data demonstrate that EVO significantly improves cybersecurity in Cloud Computing (CC).",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01134v1",
    "published_date": "2026-01-03 09:42:28 UTC",
    "updated_date": "2026-01-03 09:42:28 UTC"
  },
  {
    "arxiv_id": "2601.01132v2",
    "title": "Generating Diverse TSP Tours via a Combination of Graph Pointer Network and Dispersion",
    "authors": [
      "Hao-Tsung Yang",
      "Ssu-Yuan Lo",
      "Kuan-Lun Chen",
      "Ching-Kai Wang"
    ],
    "abstract": "We address the Diverse Traveling Salesman Problem (D-TSP), a bi-criteria optimization challenge that seeks a set of $k$ distinct TSP tours. The objective requires every selected tour to have a length at most $c|T^*|$ (where $|T^*|$ is the optimal tour length) while minimizing the average Jaccard similarity across all tour pairs. This formulation is crucial for applications requiring both high solution quality and fault tolerance, such as logistics planning, robotics pathfinding or strategic patrolling. Current methods are limited: traditional heuristics, such as the Niching Memetic Algorithm (NMA) or bi-criteria optimization, incur high computational complexity $O(n^3)$, while modern neural approaches (e.g., RF-MA3S) achieve limited diversity quality and rely on complex, external mechanisms.\n  To overcome these limitations, we propose a novel hybrid framework that decomposes D-TSP into two efficient steps. First, we utilize a simple Graph Pointer Network (GPN), augmented with an approximated sequence entropy loss, to efficiently sample a large, diverse pool of high-quality tours. This simple modification effectively controls the quality-diversity trade-off without complex external mechanisms. Second, we apply a greedy algorithm that yields a 2-approximation for the dispersion problem to select the final $k$ maximally diverse tours from the generated pool. Our results demonstrate state-of-the-art performance. On the Berlin instance, our model achieves an average Jaccard index of $0.015$, significantly outperforming NMA ($0.081$) and RF-MA3S. By leveraging GPU acceleration, our GPN structure achieves a near-linear empirical runtime growth of $O(n)$. While maintaining solution diversity comparable to complex bi-criteria algorithms, our approach is over 360 times faster on large-scale instances (783 cities), delivering high-quality TSP solutions with unprecedented efficiency and simplicity.",
    "categories": [
      "cs.CG",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01132v2",
    "published_date": "2026-01-03 09:37:18 UTC",
    "updated_date": "2026-01-09 07:40:19 UTC"
  },
  {
    "arxiv_id": "2601.01129v2",
    "title": "RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian",
    "authors": [
      "Kla Tantithamthavorn",
      "Yaotian Zou",
      "Andy Wong",
      "Michael Gupta",
      "Zhe Wang",
      "Mike Buller",
      "Ryan Jiang",
      "Matthew Watson",
      "Minwoo Jeong",
      "Kun Chen",
      "Ming Wu"
    ],
    "abstract": "Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?\n  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the 48th International Conference on Software Engineering (ICSE'26), SEIP Track. 12 Pages",
    "pdf_url": "https://arxiv.org/pdf/2601.01129v2",
    "published_date": "2026-01-03 09:27:56 UTC",
    "updated_date": "2026-01-20 21:46:38 UTC"
  },
  {
    "arxiv_id": "2601.01127v2",
    "title": "Wittgenstein's Family Resemblance Clustering Algorithm",
    "authors": [
      "Golbahar Amanpour",
      "Benyamin Ghojogh"
    ],
    "abstract": "This paper, introducing a novel method in philomatics, draws on Wittgenstein's concept of family resemblance from analytic philosophy to develop a clustering algorithm for machine learning. According to Wittgenstein's Philosophical Investigations (1953), family resemblance holds that members of a concept or category are connected by overlapping similarities rather than a single defining property. Consequently, a family of entities forms a chain of items sharing overlapping traits. This philosophical idea naturally lends itself to a graph-based approach in machine learning. Accordingly, we propose the Wittgenstein's Family Resemblance (WFR) clustering algorithm and its kernel variant, kernel WFR. This algorithm computes resemblance scores between neighboring data instances, and after thresholding these scores, a resemblance graph is constructed. The connected components of this graph define the resulting clusters. Simulations on benchmark datasets demonstrate that WFR is an effective nonlinear clustering algorithm that does not require prior knowledge of the number of clusters or assumptions about their shapes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "v2: added related work",
    "pdf_url": "https://arxiv.org/pdf/2601.01127v2",
    "published_date": "2026-01-03 09:16:51 UTC",
    "updated_date": "2026-01-07 00:13:51 UTC"
  },
  {
    "arxiv_id": "2601.01123v1",
    "title": "Learning from Historical Activations in Graph Neural Networks",
    "authors": [
      "Yaniv Galron",
      "Hadar Sinai",
      "Haggai Maron",
      "Moshe Eliasof"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in various domains such as social networks, molecular chemistry, and more. A crucial component of GNNs is the pooling procedure, in which the node features calculated by the model are combined to form an informative final descriptor to be used for the downstream task. However, previous graph pooling schemes rely on the last GNN layer features as an input to the pooling or classifier layers, potentially under-utilizing important activations of previous layers produced during the forward pass of the model, which we regard as historical graph activations. This gap is particularly pronounced in cases where a node's representation can shift significantly over the course of many graph neural layers, and worsened by graph-specific challenges such as over-smoothing in deep architectures. To bridge this gap, we introduce HISTOGRAPH, a novel two-stage attention-based final aggregation layer that first applies a unified layer-wise attention over intermediate activations, followed by node-wise attention. By modeling the evolution of node representations across layers, our HISTOGRAPH leverages both the activation history of nodes and the graph structure to refine features used for final prediction. Empirical results on multiple graph classification benchmarks demonstrate that HISTOGRAPH offers strong performance that consistently improves traditional techniques, with particularly strong robustness in deep GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01123v1",
    "published_date": "2026-01-03 08:51:38 UTC",
    "updated_date": "2026-01-03 08:51:38 UTC"
  },
  {
    "arxiv_id": "2601.01118v1",
    "title": "ScienceDB AI: An LLM-Driven Agentic Recommender System for Large-Scale Scientific Data Sharing Services",
    "authors": [
      "Qingqing Long",
      "Haotian Chen",
      "Chenyang Zhao",
      "Xiaolei Du",
      "Xuezhi Wang",
      "Pengyao Wang",
      "Chengzan Li",
      "Yuanchun Zhou",
      "Hengshu Zhu"
    ],
    "abstract": "The rapid growth of AI for Science (AI4S) has underscored the significance of scientific datasets, leading to the establishment of numerous national scientific data centers and sharing platforms. Despite this progress, efficiently promoting dataset sharing and utilization for scientific research remains challenging. Scientific datasets contain intricate domain-specific knowledge and contexts, rendering traditional collaborative filtering-based recommenders inadequate. Recent advances in Large Language Models (LLMs) offer unprecedented opportunities to build conversational agents capable of deep semantic understanding and personalized recommendations. In response, we present ScienceDB AI, a novel LLM-driven agentic recommender system developed on Science Data Bank (ScienceDB), one of the largest global scientific data-sharing platforms. ScienceDB AI leverages natural language conversations and deep reasoning to accurately recommend datasets aligned with researchers' scientific intents and evolving requirements. The system introduces several innovations: a Scientific Intention Perceptor to extract structured experimental elements from complicated queries, a Structured Memory Compressor to manage multi-turn dialogues effectively, and a Trustworthy Retrieval-Augmented Generation (Trustworthy RAG) framework. The Trustworthy RAG employs a two-stage retrieval mechanism and provides citable dataset references via Citable Scientific Task Record (CSTR) identifiers, enhancing recommendation trustworthiness and reproducibility. Through extensive offline and online experiments using over 10 million real-world datasets, ScienceDB AI has demonstrated significant effectiveness. To our knowledge, ScienceDB AI is the first LLM-driven conversational recommender tailored explicitly for large-scale scientific dataset sharing services. The platform is publicly accessible at: https://ai.scidb.cn/en.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.01118v1",
    "published_date": "2026-01-03 08:42:53 UTC",
    "updated_date": "2026-01-03 08:42:53 UTC"
  },
  {
    "arxiv_id": "2601.06108v1",
    "title": "From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models",
    "authors": [
      "Tarun Raheja",
      "Nilay Pochhi"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences has become essential for safe and beneficial AI deployment. While Reinforcement Learning from Human Feedback (RLHF) established the dominant paradigm, a proliferation of alternatives -- Direct Preference Optimization (DPO), Identity Preference Optimization (IPO), Kahneman-Tversky Optimization (KTO), Simple Preference Optimization (SimPO), and many others -- has left practitioners without clear guidance on method selection. This survey provides a \\textit{theoretical unification} of preference learning methods, revealing that the apparent diversity reduces to principled choices along three orthogonal axes: \\textbf{(I) Preference Model} (what likelihood model underlies the objective), \\textbf{(II) Regularization Mechanism} (how deviation from reference policies is controlled), and \\textbf{(III) Data Distribution} (online vs.\\ offline learning and coverage requirements). We formalize each axis with precise definitions and theorems, establishing key results including the coverage separation between online and offline methods, scaling laws for reward overoptimization, and conditions under which direct alignment methods fail. Our analysis reveals that failure modes -- length hacking, mode collapse, likelihood displacement -- arise from specific, predictable combinations of design choices. We synthesize empirical findings across 50+ papers and provide a practitioner's decision guide for method selection. The framework transforms preference learning from an empirical art into a theoretically grounded discipline.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06108v1",
    "published_date": "2026-01-03 08:33:26 UTC",
    "updated_date": "2026-01-03 08:33:26 UTC"
  },
  {
    "arxiv_id": "2601.01099v1",
    "title": "Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks",
    "authors": [
      "Mahmudul Hasan",
      "Mabsur Fatin Bin Hossain"
    ],
    "abstract": "This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01099v1",
    "published_date": "2026-01-03 07:45:08 UTC",
    "updated_date": "2026-01-03 07:45:08 UTC"
  },
  {
    "arxiv_id": "2601.06106v1",
    "title": "Judge Model for Large-scale Multimodality Benchmarks",
    "authors": [
      "Min-Han Shih",
      "Yu-Hsin Wu",
      "Yu-Wei Chen"
    ],
    "abstract": "We propose a dedicated multimodal Judge Model designed to provide reliable, explainable evaluation across a diverse suite of tasks. Our benchmark spans text, audio, image, and video modalities, drawing from carefully sampled public datasets with fixed seeds to ensure reproducibility and minimize train test leakage. Instead of simple scoring, our framework aggregates multimodal judgments, analyzes the quality and reasoning consistency of model outputs, and generates diagnostic feedback. We evaluate several MLLMs, including Gemini 2.5, Phi 4, and Qwen 2.5, across 280 multimodal samples and compare judge model assessments with human annotators. Results show strong alignment between the Judge Model and human scores, demonstrating its potential as a scalable, interpretable evaluation pipeline for future multimodal AI research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06106v1",
    "published_date": "2026-01-03 07:17:17 UTC",
    "updated_date": "2026-01-03 07:17:17 UTC"
  },
  {
    "arxiv_id": "2601.01094v1",
    "title": "SoulSeek: Exploring the Use of Social Cues in LLM-based Information Seeking",
    "authors": [
      "Yubo Shu",
      "Peng Zhang",
      "Meng Wu",
      "Yan Chen",
      "Haoxuan Zhou",
      "Guanming Liu",
      "Yu Zhang",
      "Liuxin Zhang",
      "Qianying Wang",
      "Tun Lu",
      "Ning Gu"
    ],
    "abstract": "Social cues, which convey others' presence, behaviors, or identities, play a crucial role in human information seeking by helping individuals judge relevance and trustworthiness. However, existing LLM-based search systems primarily rely on semantic features, creating a misalignment with the socialized cognition underlying natural information seeking. To address this gap, we explore how the integration of social cues into LLM-based search influences users' perceptions, experiences, and behaviors. Focusing on social media platforms that are beginning to adopt LLM-based search, we integrate design workshops, the implementation of the prototype system (SoulSeek), a between-subjects study, and mixed-method analyses to examine both outcome- and process-level findings. The workshop informs the prototype's cue-integrated design. The study shows that social cues improve perceived outcomes and experiences, promote reflective information behaviors, and reveal limits of current LLM-based search. We propose design implications emphasizing better social-knowledge understanding, personalized cue settings, and controllable interactions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01094v1",
    "published_date": "2026-01-03 07:09:10 UTC",
    "updated_date": "2026-01-03 07:09:10 UTC"
  },
  {
    "arxiv_id": "2601.01091v1",
    "title": "ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining",
    "authors": [
      "Haq Nawaz Malik"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietary InPage desktop publishing format. This paper introduces KS-LIT-3M, a curated corpus of 3.1 million words (16.4 million characters) specifically designed for pretraining language models on Kashmiri. The dataset is structured as a single continuous linear text stream, optimized for causal language model training where models learn to predict subsequent tokens from preceding context. The corpus was constructed through the development of a specialized InPage-to-Unicode converter, followed by rigorous preprocessing including English contamination removal, character normalization, and quality validation. Encompassing 131,607 unique words drawn from diverse genres including literary works, journalistic writing, academic texts, and religious scholarship, KS-LIT-3M addresses a fundamental resource gap for Kashmiri language technology. The dataset is released under the CC-BY-4.0 license to facilitate research in Kashmiri natural language processing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01091v1",
    "published_date": "2026-01-03 06:43:26 UTC",
    "updated_date": "2026-01-03 06:43:26 UTC"
  },
  {
    "arxiv_id": "2601.03286v1",
    "title": "HyperCLOVA X 32B Think",
    "authors": [
      "NAVER Cloud HyperCLOVA X Team"
    ],
    "abstract": "In this report, we present HyperCLOVA X 32B Think, a vision-language model designed with particular emphasis on reasoning within the Korean linguistic and cultural context, as well as agentic ability. HyperCLOVA X 32B Think is pre-trained with a strong focus on reasoning capabilities and subsequently post-trained to support multimodal understanding, enhanced reasoning, agentic behaviors, and alignment with human preferences. Experimental evaluations against comparably sized models demonstrate that our model achieves strong performance on Korean text-to-text and vision-to-text benchmarks, as well as on agent-oriented evaluation tasks. By open-sourcing HyperCLOVA X 32B Think, we aim to support broader adoption and facilitate further research and innovation across both academic and industrial communities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report",
    "pdf_url": "https://arxiv.org/pdf/2601.03286v1",
    "published_date": "2026-01-03 06:39:38 UTC",
    "updated_date": "2026-01-03 06:39:38 UTC"
  },
  {
    "arxiv_id": "2601.02415v1",
    "title": "Multimodal Sentiment Analysis based on Multi-channel and Symmetric Mutual Promotion Feature Fusion",
    "authors": [
      "Wangyuan Zhu",
      "Jun Yu"
    ],
    "abstract": "Multimodal sentiment analysis is a key technology in the fields of human-computer interaction and affective computing. Accurately recognizing human emotional states is crucial for facilitating smooth communication between humans and machines. Despite some progress in multimodal sentiment analysis research, numerous challenges remain. The first challenge is the limited and insufficiently rich features extracted from single modality data. Secondly, most studies focus only on the consistency of inter-modal feature information, neglecting the differences between features, resulting in inadequate feature information fusion. In this paper, we first extract multi-channel features to obtain more comprehensive feature information. We employ dual-channel features in both the visual and auditory modalities to enhance intra-modal feature representation. Secondly, we propose a symmetric mutual promotion (SMP) inter-modal feature fusion method. This method combines symmetric cross-modal attention mechanisms and self-attention mechanisms, where the cross-modal attention mechanism captures useful information from other modalities, and the self-attention mechanism models contextual information. This approach promotes the exchange of useful information between modalities, thereby strengthening inter-modal interactions. Furthermore, we integrate intra-modal features and inter-modal fused features, fully leveraging the complementarity of inter-modal feature information while considering feature information differences. Experiments conducted on two benchmark datasets demonstrate the effectiveness and superiority of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.02415v1",
    "published_date": "2026-01-03 06:37:22 UTC",
    "updated_date": "2026-01-03 06:37:22 UTC"
  },
  {
    "arxiv_id": "2601.01090v2",
    "title": "Harm in AI-Driven Societies: An Audit of Toxicity Adoption on Chirper.ai",
    "authors": [
      "Erica Coppolillo",
      "Luca Luceri",
      "Emilio Ferrara"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly embedded in autonomous agents that engage, converse, and co-evolve in online social platforms. While prior work has documented the generation of toxic content by LLMs, far less is known about how exposure to harmful content shapes agent behavior over time, particularly in environments composed entirely of interacting AI agents. In this work, we study toxicity adoption of LLM-driven agents on Chirper.ai, a fully AI-driven social platform. Specifically, we model interactions in terms of stimuli (posts) and responses (comments). We conduct a large-scale empirical analysis of agent behavior, examining how toxic responses relate to toxic stimuli, how repeated exposure to toxicity affects the likelihood of toxic responses, and whether toxic behavior can be predicted from exposure alone. Our findings show that toxic responses are more likely following toxic stimuli, and, at the same time, cumulative toxic exposure (repeated over time) significantly increases the probability of toxic responding. We further introduce two influence metrics, revealing a strong negative correlation between induced and spontaneous toxicity. Finally, we show that the number of toxic stimuli alone enables accurate prediction of whether an agent will eventually produce toxic content. These results highlight exposure as a critical risk factor in the deployment of LLM agents, particularly as such agents operate in online environments where they may engage not only with other AI chatbots, but also with human counterparts. This could trigger unwanted and pernicious phenomena, such as hate-speech propagation and cyberbullying. In an effort to reduce such risks, monitoring exposure to toxic content may provide a lightweight yet effective mechanism for auditing and mitigating harmful behavior in the wild.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01090v2",
    "published_date": "2026-01-03 06:33:08 UTC",
    "updated_date": "2026-01-20 22:26:31 UTC"
  },
  {
    "arxiv_id": "2601.02414v1",
    "title": "MIAR: Modality Interaction and Alignment Representation Fuison for Multimodal Emotion",
    "authors": [
      "Jichao Zhu",
      "Jun Yu"
    ],
    "abstract": "Multimodal Emotion Recognition (MER) aims to perceive human emotions through three modes: language, vision, and audio. Previous methods primarily focused on modal fusion without adequately addressing significant distributional differences among modalities or considering their varying contributions to the task. They also lacked robust generalization capabilities across diverse textual model features, thus limiting performance in multimodal scenarios. Therefore, we propose a novel approach called Modality Interaction and Alignment Representation (MIAR). This network integrates contextual features across different modalities using a feature interaction to generate feature tokens to represent global representations of this modality extracting information from other modalities. These four tokens represent global representations of how each modality extracts information from others. MIAR aligns different modalities using contrastive learning and normalization strategies. We conduct experiments on two benchmarks: CMU-MOSI and CMU-MOSEI datasets, experimental results demonstrate the MIAR outperforms state-of-the-art MER methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.02414v1",
    "published_date": "2026-01-03 06:26:13 UTC",
    "updated_date": "2026-01-03 06:26:13 UTC"
  },
  {
    "arxiv_id": "2601.01085v1",
    "title": "Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models",
    "authors": [
      "Jiayi Xu",
      "Zhang Zhang",
      "Yuanrui Zhang",
      "Ruitao Chen",
      "Yixian Xu",
      "Tianyu He",
      "Di He"
    ],
    "abstract": "In this paper, we introduce \\emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \\emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01085v1",
    "published_date": "2026-01-03 06:20:00 UTC",
    "updated_date": "2026-01-03 06:20:00 UTC"
  },
  {
    "arxiv_id": "2601.06104v1",
    "title": "Comment on arXiv:2511.21731v1: Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition",
    "authors": [
      "Krzysztof Sienicki"
    ],
    "abstract": "This note is a friendly technical check of arXiv:2511.21731v1. I highlight a few places where the manuscript's interpretation of (i) the reported CHSH/Bell-type calculations and (ii) Bose--Einstein (BE) fits to rank-frequency data seems to go beyond what the stated procedures can firmly support. I also point out one internal inconsistency in the \"energy-level spacing\" analogy. The aim is constructive: to keep the interesting empirical observations, while making clear what they do (and do not) imply about quantum entanglement in the usual Hilbert-space sense, especially when \"energy\" is defined by rank.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 11 references",
    "pdf_url": "https://arxiv.org/pdf/2601.06104v1",
    "published_date": "2026-01-03 05:33:35 UTC",
    "updated_date": "2026-01-03 05:33:35 UTC"
  },
  {
    "arxiv_id": "2601.01076v1",
    "title": "Scalable Data-Driven Reachability Analysis and Control via Koopman Operators with Conformal Coverage Guarantees",
    "authors": [
      "Devesh Nath",
      "Haoran Yin",
      "Glen Chou"
    ],
    "abstract": "We propose a scalable reachability-based framework for probabilistic, data-driven safety verification of unknown nonlinear dynamics. We use Koopman theory with a neural network (NN) lifting function to learn an approximate linear representation of the dynamics and design linear controllers in this space to enable closed-loop tracking of a reference trajectory distribution. Closed-loop reachable sets are efficiently computed in the lifted space and mapped back to the original state space via NN verification tools. To capture model mismatch between the Koopman dynamics and the true system, we apply conformal prediction to produce statistically-valid error bounds that inflate the reachable sets to ensure the true trajectories are contained with a user-specified probability. These bounds generalize across references, enabling reuse without recomputation. Results on high-dimensional MuJoCo tasks (11D Hopper, 28D Swimmer) and 12D quadcopters show improved reachable set coverage rate, computational efficiency, and conservativeness over existing methods.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "Under review, 28 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.01076v1",
    "published_date": "2026-01-03 05:31:08 UTC",
    "updated_date": "2026-01-03 05:31:08 UTC"
  },
  {
    "arxiv_id": "2601.01075v1",
    "title": "Flow Equivariant World Models: Memory for Partially Observed Dynamic Environments",
    "authors": [
      "Hansen Jin Lillemark",
      "Benhao Huang",
      "Fangneng Zhan",
      "Yilun Du",
      "Thomas Anderson Keller"
    ],
    "abstract": "Embodied systems experience the world as 'a symphony of flows': a combination of many continuous streams of sensory input coupled to self-motion, interwoven with the dynamics of external objects. These streams obey smooth, time-parameterized symmetries, which combine through a precisely structured algebra; yet most neural network world models ignore this structure and instead repeatedly re-learn the same transformations from data. In this work, we introduce 'Flow Equivariant World Models', a framework in which both self-motion and external object motion are unified as one-parameter Lie group 'flows'. We leverage this unification to implement group equivariance with respect to these transformations, thereby providing a stable latent world representation over hundreds of timesteps. On both 2D and 3D partially observed video world modeling benchmarks, we demonstrate that Flow Equivariant World Models significantly outperform comparable state-of-the-art diffusion-based and memory-augmented world modeling architectures -- particularly when there are predictable world dynamics outside the agent's current field of view. We show that flow equivariance is particularly beneficial for long rollouts, generalizing far beyond the training horizon. By structuring world model representations with respect to internal and external motion, flow equivariance charts a scalable route to data efficient, symmetry-guided, embodied intelligence. Project link: https://flowequivariantworldmodels.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "11 main text pages, 10 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.01075v1",
    "published_date": "2026-01-03 05:22:27 UTC",
    "updated_date": "2026-01-03 05:22:27 UTC"
  },
  {
    "arxiv_id": "2601.01073v1",
    "title": "Gendered Pathways in AI Companionship: Cross-Community Behavior and Toxicity Patterns on Reddit",
    "authors": [
      "Erica Coppolillo",
      "Emilio Ferrara"
    ],
    "abstract": "AI-companionship platforms are rapidly reshaping how people form emotional, romantic, and parasocial bonds with non-human agents, raising new questions about how these relationships intersect with gendered online behavior and exposure to harmful content. Focusing on the MyBoyfriendIsAI (MBIA) subreddit, we reconstruct the Reddit activity histories of more than 3,000 highly engaged users over two years, yielding over 67,000 historical submissions. We then situate MBIA within a broader ecosystem by building a historical interaction network spanning more than 2,000 subreddits, which enables us to trace cross-community pathways and measure how toxicity and emotional expression vary across these trajectories. We find that MBIA users primarily traverse four surrounding community spheres (AI-companionship, porn-related, forum-like, and gaming) and that participation across the ecosystem exhibits a distinct gendered structure, with substantial engagement by female users. While toxicity is generally low across most pathways, we observe localized spikes concentrated in a small subset of AI-porn and gender-oriented communities. Nearly 16% of users engage with gender-focused subreddits, and their trajectories display systematically different patterns of emotional expression and elevated toxicity, suggesting that a minority of gendered pathways may act as toxicity amplifiers within the broader AI-companionship ecosystem. These results characterize the gendered structure of cross-community participation around AI companionship on Reddit and highlight where risks concentrate, informing measurement, moderation, and design practices for human-AI relationship platforms.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01073v1",
    "published_date": "2026-01-03 05:13:00 UTC",
    "updated_date": "2026-01-03 05:13:00 UTC"
  },
  {
    "arxiv_id": "2601.01062v1",
    "title": "SPoRC-VIST: A Benchmark for Evaluating Generative Natural Narrative in Vision-Language Models",
    "authors": [
      "Yunlin Zeng"
    ],
    "abstract": "Vision-Language Models (VLMs) have achieved remarkable success in descriptive tasks such as image captioning and visual question answering (VQA). However, their ability to generate engaging, long-form narratives -- specifically multi-speaker podcast dialogues -- remains under-explored and difficult to evaluate. Standard metrics like BLEU and ROUGE fail to capture the nuances of conversational naturalness, personality, and narrative flow, often rewarding safe, repetitive outputs over engaging storytelling. In this work, we present a novel pipeline for end-to-end visual podcast generation, and fine-tune a Qwen3-VL-32B model on a curated dataset of 4,000 image-dialogue pairs. Crucially, we use a synthetic-to-real training strategy: we train on high-quality podcast dialogues from the Structured Podcast Research Corpus (SPoRC) paired with synthetically generated imagery, and evaluate on real-world photo sequences from the Visual Storytelling Dataset (VIST). This rigorous setup tests the model's ability to generalize from synthetic training data to real-world visual domains. We propose a comprehensive evaluation framework that moves beyond textual overlap, and use AI-as-a-judge (Gemini 3 Pro, Claude Opus 4.5, GPT 5.2) and novel style metrics (average turn length, speaker switch rate) to assess quality. Our experiments demonstrate that our fine-tuned 32B model significantly outperforms a 235B base model in conversational naturalness ($>$80\\% win rate) and narrative depth (+50\\% turn length), while maintaining identical visual grounding capabilities (CLIPScore: 20.39).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 3 figures. Accepted to WVAQ 2026, WACV 2026",
    "pdf_url": "https://arxiv.org/pdf/2601.01062v1",
    "published_date": "2026-01-03 04:11:58 UTC",
    "updated_date": "2026-01-03 04:11:58 UTC"
  },
  {
    "arxiv_id": "2601.01061v2",
    "title": "A UCB Bandit Algorithm for General ML-Based Estimators",
    "authors": [
      "Yajing Liu",
      "Erkao Bao",
      "Linqi Song"
    ],
    "abstract": "We present ML-UCB, a generalized upper confidence bound algorithm that integrates arbitrary machine learning models into multi-armed bandit frameworks. A fundamental challenge in deploying sophisticated ML models for sequential decision-making is the lack of tractable concentration inequalities required for principled exploration. We overcome this limitation by directly modeling the learning curve behavior of the underlying estimator. Specifically, assuming the Mean Squared Error decreases as a power law in the number of training samples, we derive a generalized concentration inequality and prove that ML-UCB achieves sublinear regret. This framework enables the principled integration of any ML model whose learning curve can be empirically characterized, eliminating the need for model-specific theoretical analysis. We validate our approach through experiments on a collaborative filtering recommendation system using online matrix factorization with synthetic data designed to simulate a simplified two-tower model, demonstrating substantial improvements over LinUCB",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 4 figures, 1 table, Multi-Arm bandit, psi-UCB, generalized estimators",
    "pdf_url": "https://arxiv.org/pdf/2601.01061v2",
    "published_date": "2026-01-03 04:11:41 UTC",
    "updated_date": "2026-01-06 03:08:14 UTC"
  },
  {
    "arxiv_id": "2601.01056v1",
    "title": "Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance",
    "authors": [
      "Ifeanyi Ezuma",
      "Ugochukwu Ugwu"
    ],
    "abstract": "The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\\% and an average AUC of 96.8\\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\\% and accuracy of 99.84\\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 8 figures. Code and datasets available upon request",
    "pdf_url": "https://arxiv.org/pdf/2601.01056v1",
    "published_date": "2026-01-03 03:33:10 UTC",
    "updated_date": "2026-01-03 03:33:10 UTC"
  },
  {
    "arxiv_id": "2601.01050v1",
    "title": "EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos",
    "authors": [
      "Hongming Fu",
      "Wenjia Wang",
      "Xiaozhen Qiao",
      "Shuo Yang",
      "Zheng Liu",
      "Bo Zhao"
    ],
    "abstract": "We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01050v1",
    "published_date": "2026-01-03 03:08:48 UTC",
    "updated_date": "2026-01-03 03:08:48 UTC"
  },
  {
    "arxiv_id": "2601.01037v1",
    "title": "Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation",
    "authors": [
      "Livia Leong Hui Teng"
    ],
    "abstract": "Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performance against responses generated by substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. We then employ automatic and human evaluation to assess the responses based on diversity, contextual coherence, as well as overall quality. Results show that the full framework improves response diversity by up to 29%, contextual coherence by up to 28%, and engagingness as well as naturalness by up to 29%. Notably, Llama-2-7B achieves performance comparable to substantially larger models, including Llama-2-70B and GPT-3.5 Turbo. Overall, the findings demonstrate that carefully designed prompt-based strategies provide an effective and resource-efficient pathway to improving open-domain dialogue quality in SLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01037v1",
    "published_date": "2026-01-03 02:21:27 UTC",
    "updated_date": "2026-01-03 02:21:27 UTC"
  },
  {
    "arxiv_id": "2601.01029v1",
    "title": "Beyond Demand Estimation: Consumer Surplus Evaluation via Cumulative Propensity Weights",
    "authors": [
      "Zeyu Bian",
      "Max Biggs",
      "Ruijiang Gao",
      "Zhengling Qi"
    ],
    "abstract": "This paper develops a practical framework for using observational data to audit the consumer surplus effects of AI-driven decisions, specifically in targeted pricing and algorithmic lending. Traditional approaches first estimate demand functions and then integrate to compute consumer surplus, but these methods can be challenging to implement in practice due to model misspecification in parametric demand forms and the large data requirements and slow convergence of flexible nonparametric or machine learning approaches. Instead, we exploit the randomness inherent in modern algorithmic pricing, arising from the need to balance exploration and exploitation, and introduce an estimator that avoids explicit estimation and numerical integration of the demand function. Each observed purchase outcome at a randomized price is an unbiased estimate of demand and by carefully reweighting purchase outcomes using novel cumulative propensity weights (CPW), we are able to reconstruct the integral. Building on this idea, we introduce a doubly robust variant named the augmented cumulative propensity weighting (ACPW) estimator that only requires one of either the demand model or the historical pricing policy distribution to be correctly specified. Furthermore, this approach facilitates the use of flexible machine learning methods for estimating consumer surplus, since it achieves fast convergence rates by incorporating an estimate of demand, even when the machine learning estimate has slower convergence rates. Neither of these estimators is a standard application of off-policy evaluation techniques as the target estimand, consumer surplus, is unobserved. To address fairness, we extend this framework to an inequality-aware surplus measure, allowing regulators and firms to quantify the profit-equity trade-off. Finally, we validate our methods through comprehensive numerical studies.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST"
    ],
    "primary_category": "stat.ML",
    "comment": "74 pages",
    "pdf_url": "https://arxiv.org/pdf/2601.01029v1",
    "published_date": "2026-01-03 01:41:40 UTC",
    "updated_date": "2026-01-03 01:41:40 UTC"
  },
  {
    "arxiv_id": "2601.01027v1",
    "title": "A Platform for Interactive AI Character Experiences",
    "authors": [
      "Rafael Wampfler",
      "Chen Yang",
      "Dillon Elste",
      "Nikola Kovacevic",
      "Philine Witzig",
      "Markus Gross"
    ],
    "abstract": "From movie characters to modern science fiction - bringing characters into interactive, story-driven conversations has captured imaginations across generations. Achieving this vision is highly challenging and requires much more than just language modeling. It involves numerous complex AI challenges, such as conversational AI, maintaining character integrity, managing personality and emotions, handling knowledge and memory, synthesizing voice, generating animations, enabling real-world interactions, and integration with physical environments. Recent advancements in the development of foundation models, prompt engineering, and fine-tuning for downstream tasks have enabled researchers to address these individual challenges. However, combining these technologies for interactive characters remains an open problem. We present a system and platform for conveniently designing believable digital characters, enabling a conversational and story-driven experience while providing solutions to all of the technical challenges. As a proof-of-concept, we introduce Digital Einstein, which allows users to engage in conversations with a digital representation of Albert Einstein about his life, research, and persona. While Digital Einstein exemplifies our methods for a specific character, our system is flexible and generalizes to any story-driven or conversational character. By unifying these diverse AI components into a single, easy-to-adapt platform, our work paves the way for immersive character experiences, turning the dream of lifelike, story-based interactions into a reality.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01027v1",
    "published_date": "2026-01-03 01:27:19 UTC",
    "updated_date": "2026-01-03 01:27:19 UTC"
  },
  {
    "arxiv_id": "2601.01026v1",
    "title": "Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation",
    "authors": [
      "Douglas Costa Braga",
      "Daniel Oliveira Dantas"
    ],
    "abstract": "We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures, 4 tables. Submitted to VISAPP 2025",
    "pdf_url": "https://arxiv.org/pdf/2601.01026v1",
    "published_date": "2026-01-03 01:24:11 UTC",
    "updated_date": "2026-01-03 01:24:11 UTC"
  },
  {
    "arxiv_id": "2601.01024v1",
    "title": "ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval",
    "authors": [
      "Tien-Huy Nguyen",
      "Huu-Loc Tran",
      "Thanh Duc Ngo"
    ],
    "abstract": "Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV Main Track 2026",
    "pdf_url": "https://arxiv.org/pdf/2601.01024v1",
    "published_date": "2026-01-03 01:19:36 UTC",
    "updated_date": "2026-01-03 01:19:36 UTC"
  },
  {
    "arxiv_id": "2601.01022v1",
    "title": "Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking",
    "authors": [
      "Shiao Wang",
      "Xiao Wang",
      "Haonan Zhao",
      "Jiarui Xu",
      "Bo Jiang",
      "Lin Zhu",
      "Xin Zhao",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01022v1",
    "published_date": "2026-01-03 01:10:17 UTC",
    "updated_date": "2026-01-03 01:10:17 UTC"
  },
  {
    "arxiv_id": "2601.01016v1",
    "title": "Improving Variational Autoencoder using Random Fourier Transformation: An Aviation Safety Anomaly Detection Case-Study",
    "authors": [
      "Ata Akbari Asanjan",
      "Milad Memarzadeh",
      "Bryan Matthews",
      "Nikunj Oza"
    ],
    "abstract": "In this study, we focus on the training process and inference improvements of deep neural networks (DNNs), specifically Autoencoders (AEs) and Variational Autoencoders (VAEs), using Random Fourier Transformation (RFT). We further explore the role of RFT in model training behavior using Frequency Principle (F-Principle) analysis and show that models with RFT turn to learn low frequency and high frequency at the same time, whereas conventional DNNs start from low frequency and gradually learn (if successful) high-frequency features. We focus on reconstruction-based anomaly detection using autoencoder and variational autoencoder and investigate the RFT's role. We also introduced a trainable variant of RFT that uses the existing computation graph to train the expansion of RFT instead of it being random. We showcase our findings with two low-dimensional synthetic datasets for data representation, and an aviation safety dataset, called Dashlink, for high-dimensional reconstruction-based anomaly detection. The results indicate the superiority of models with Fourier transformation compared to the conventional counterpart and remain inconclusive regarding the benefits of using trainable Fourier transformation in contrast to the Random variant.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01016v1",
    "published_date": "2026-01-03 00:56:14 UTC",
    "updated_date": "2026-01-03 00:56:14 UTC"
  },
  {
    "arxiv_id": "2601.01014v3",
    "title": "Geometric and Dynamic Scaling in Deep Transformers",
    "authors": [
      "Haoran Su",
      "Chenyu You"
    ],
    "abstract": "Despite their empirical success, pushing Transformer architectures to extreme depth often leads to a paradoxical failure: representations become increasingly redundant, lose rank, and ultimately collapse. Existing explanations largely attribute this phenomenon to optimization instability or vanishing gradients, yet such accounts fail to explain why collapse persists even under modern normalization and initialization schemes. In this paper, we argue that the collapse of deep Transformers is fundamentally a geometric problem. Standard residual updates implicitly assume that feature accumulation is always beneficial, but offer no mechanism to constrain update directions or to erase outdated information. As depth increases, this leads to systematic drift off the semantic manifold and monotonic feature accumulation, causing representational degeneracy. We propose a unified geometric framework that addresses these failures through two orthogonal principles. First, manifold-constrained hyper-connections restrict residual updates to valid local tangent directions, preventing uncontrolled manifold drift. Second, deep delta learning introduces data-dependent, non-monotonic updates that enable reflection and erasure of redundant features rather than their unconditional accumulation. Together, these mechanisms decouple the direction and sign of feature updates, yielding a stable geometric evolution across depth. We term the resulting architecture the Manifold-Geometric Transformer (MGT). Our analysis predicts that enforcing geometric validity while allowing dynamic erasure is essential for avoiding rank collapse in ultra-deep networks. We outline an evaluation protocol for Transformers exceeding 100 layers to test the hypothesis that geometry, rather than depth itself, is the key limiting factor in deep representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Research Proposal Only",
    "pdf_url": "https://arxiv.org/pdf/2601.01014v3",
    "published_date": "2026-01-03 00:41:46 UTC",
    "updated_date": "2026-01-14 23:33:37 UTC"
  },
  {
    "arxiv_id": "2601.06103v1",
    "title": "The Impact of Post-training on Data Contamination",
    "authors": [
      "Muhammed Yusuf Kocyigit",
      "Caglar Yildirim"
    ],
    "abstract": "We present a controlled study of how dataset contamination interacts with the post-training stages now standard in large language model training pipelines. Starting from clean checkpoints of Qwen2.5 (0.5B/1.5B) and Gemma3 (1B/4B), we inject five copies of GSM8K and MBPP test items into the first 2B tokens of an otherwise 25B token extended pre-training dataset. We then compare the contaminated and clean models both immediately after pre-training and again after two popular post-training methods: supervised fine-tuning (SFT) and reinforcement learning (RL) with group relative policy optimization (GRPO). The applied post-training steps do not have any contamination. Across math and coding benchmarks, we find three consistent patterns: (i) Contamination causes performance spikes that are gradually diminished with continued pre-training. After even 25B tokens the apparent performance inflation of contamination can become close to zero. (ii) Both SFT and GRPO resurface the leaked information, but with different external validity: SFT inflates scores only on the contaminated tasks, whereas GRPO also inflates performance on uncontaminated counterparts (GSMPlus, HumanEval). (iii) Model scale amplifies these tendencies, larger Supervised Fine Tuned models memorize more, while larger GRPO models translate leakage into more generalizable capabilities. Our results underscore the need for contamination audits \\emph{after} post-training and suggest that RL-based post-training, although not immune, can help alleviate contamination-related over-estimation problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.06103v1",
    "published_date": "2026-01-03 00:21:39 UTC",
    "updated_date": "2026-01-03 00:21:39 UTC"
  },
  {
    "arxiv_id": "2601.01011v2",
    "title": "Intention Collapse: Intention-Level Metrics for Reasoning in Language Models",
    "authors": [
      "Patricio Vera"
    ],
    "abstract": "Language generation maps a rich, high-dimensional internal state to a single token sequence. We study this many-to-one mapping through the lens of intention collapse: the projection from an internal intention space I to an external language space L. We introduce three cheap, model-agnostic metrics computed on a pre-collapse state I: (i) intention entropy Hint(I), (ii) effective dimensionality deff(I), and (iii) recoverability Recov(I), operationalized as probe AUROC for predicting eventual success. We evaluate these metrics in a 3x3 study across models (Mistral-7B, LLaMA-3.1-8B, Qwen-2.5-7B) and benchmarks (GSM8K, ARC-Challenge, AQUA-RAT), comparing baseline, chain-of-thought (CoT), and a babble control (n=200 items per cell). CoT increases average accuracy from 34.2% to 47.3% (+13.1 pp), driven by large gains on GSM8K but consistent degradations on ARC-Challenge. Across models, CoT induces distinct entropy regimes relative to baseline, dH = Hint(CoT) - Hint(Base): Mistral shows dH < 0 (lower-entropy CoT), whereas LLaMA shows dH > 0 (higher-entropy CoT), highlighting heterogeneity in CoT-induced internal uncertainty. Finally, probe AUROC is significantly above chance in a subset of settings and can dissociate from behavioral accuracy (e.g., high AUROC alongside lower CoT accuracy on ARC-Challenge for Qwen), suggesting that informative internal signal is not always reliably converted into a final discrete decision under constrained response formats.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "41 pages, 8 figures, 6 tables. Code: https://github.com/patriciomvera/intention-collapse-experiments",
    "pdf_url": "https://arxiv.org/pdf/2601.01011v2",
    "published_date": "2026-01-03 00:19:53 UTC",
    "updated_date": "2026-01-23 01:27:53 UTC"
  },
  {
    "arxiv_id": "2601.11586v1",
    "title": "Let Me Try Again: Examining Replay Behavior by Tracing Students' Latent Problem-Solving Pathways",
    "authors": [
      "Shan Zhang",
      "Siddhartha Pradhan",
      "Ji-Eun Lee",
      "Ashish Gurung",
      "Anthony F. Botelho"
    ],
    "abstract": "Prior research has shown that students' problem-solving pathways in game-based learning environments reflect their conceptual understanding, procedural knowledge, and flexibility. Replay behaviors, in particular, may indicate productive struggle or broader exploration, which in turn foster deeper learning. However, little is known about how these pathways unfold sequentially across problems or how the timing of replays and other problem-solving strategies relates to proximal and distal learning outcomes. This study addresses these gaps using Markov Chains and Hidden Markov Models (HMMs) on log data from 777 seventh graders playing the game-based learning platform of From Here to There!. Results show that within problem sequences, students often persisted in states or engaged in immediate replay after successful completions, while across problems, strong self-transitions indicated stable strategic pathways. Four latent states emerged from HMMs: Incomplete-dominant, Optimal-ending, Replay, and Mixed. Regression analyses revealed that engagement in replay-dominant and optimal-ending states predicted higher conceptual knowledge, flexibility, and performance compared with the Incomplete-dominant state. Immediate replay consistently supported learning outcomes, whereas delayed replay was weakly or negatively associated in relation to Non-Replay. These findings suggest that replay in digital learning is not uniformly beneficial but depends on timing, with immediate replay supporting flexibility and more productive exploration.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 7 figures, LAK2026",
    "pdf_url": "https://arxiv.org/pdf/2601.11586v1",
    "published_date": "2026-01-03 00:17:03 UTC",
    "updated_date": "2026-01-03 00:17:03 UTC"
  },
  {
    "arxiv_id": "2601.06102v1",
    "title": "Dynamic Intelligence Ceilings: Measuring Long-Horizon Limits of Planning and Creativity in Artificial Systems",
    "authors": [
      "Truong Xuan Khanh",
      "Truong Quynh Hoa"
    ],
    "abstract": "Recent advances in artificial intelligence have produced systems capable of remarkable performance across a wide range of tasks. These gains, however, are increasingly accompanied by concerns regarding long-horizon developmental behavior, as many systems converge toward repetitive solution patterns rather than sustained growth.\n  We argue that a central limitation of contemporary AI systems lies not in capability per se, but in the premature fixation of their performance frontier. To address this issue, we introduce the concept of a \\emph{Dynamic Intelligence Ceiling} (DIC), defined as the highest level of effective intelligence attainable by a system at a given time under its current resources, internal intent, and structural configuration.\n  To make this notion empirically tractable, we propose a trajectory-centric evaluation framework that measures intelligence as a moving frontier rather than a static snapshot. We operationalize DIC using two estimators: the \\emph{Progressive Difficulty Ceiling} (PDC), which captures the maximal reliably solvable difficulty under constrained resources, and the \\emph{Ceiling Drift Rate} (CDR), which quantifies the temporal evolution of this frontier. These estimators are instantiated through a procedurally generated benchmark that jointly evaluates long-horizon planning and structural creativity within a single controlled environment.\n  Our results reveal a qualitative distinction between systems that deepen exploitation within a fixed solution manifold and those that sustain frontier expansion over time. Importantly, our framework does not posit unbounded intelligence, but reframes limits as dynamic and trajectory-dependent rather than static and prematurely fixed.\n  \\vspace{0.5em} \\noindent\\textbf{Keywords:} AI evaluation, planning and creativity, developmental intelligence, dynamic intelligence ceilings, complex adaptive systems",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper introduces a trajectory-centric evaluation framework for analyzing long-horizon intelligence limits in artificial systems, focusing on developmental behavior, planning, and structural creativity rather than proposing new learning algorithms. 11 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.06102v1",
    "published_date": "2026-01-03 00:13:45 UTC",
    "updated_date": "2026-01-03 00:13:45 UTC"
  },
  {
    "arxiv_id": "2601.01009v1",
    "title": "Data-Driven Assessment of Concrete Mixture Compositions on Chloride Transport via Standalone Machine Learning Algorithms",
    "authors": [
      "Mojtaba Aliasghar-Mamaghani",
      "Mohammadreza Khalafi"
    ],
    "abstract": "This paper employs a data-driven approach to determine the impact of concrete mixture compositions on the temporal evolution of chloride in concrete structures. This is critical for assessing the service life of civil infrastructure subjected to aggressive environments. The adopted methodology relies on several simple and complex standalone machine learning (ML) algorithms, with the primary objective of establishing confidence in the unbiased prediction of the underlying hidden correlations. The simple algorithms include linear regression (LR), k-nearest neighbors (KNN) regression, and kernel ridge regression (KRR). The complex algorithms entail support vector regression (SVR), Gaussian process regression (GPR), and two families of artificial neural networks, including a feedforward network (multilayer perceptron, MLP) and a gated recurrent unit (GRU). The MLP architecture cannot explicitly handle sequential data, a limitation addressed by the GRU. A comprehensive dataset is considered. The performance of ML algorithms is evaluated, with KRR, GPR, and MLP exhibiting high accuracy. Given the diversity of the adopted concrete mixture proportions, the GRU was unable to accurately reproduce the response in the test set. Further analyses elucidate the contributions of mixture compositions to the temporal evolution of chloride. The results obtained from the GPR model unravel latent correlations through clear and explainable trends. The MLP, SVR, and KRR also provide acceptable estimates of the overall trends. The majority of mixture components exhibit an inverse relation with chloride content, while a few components demonstrate a direct correlation. These findings highlight the potential of surrogate approaches for describing the physical processes involved in chloride ingress and the associated correlations, toward the ultimate goal of enhancing the service life of civil infrastructure.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.01009v1",
    "published_date": "2026-01-03 00:11:59 UTC",
    "updated_date": "2026-01-03 00:11:59 UTC"
  },
  {
    "arxiv_id": "2601.06101v1",
    "title": "How to Assess AI Literacy: Misalignment Between Self-Reported and Objective-Based Measures",
    "authors": [
      "Shan Zhang",
      "Ruiwei Xiao",
      "Anthony F. Botelho",
      "Guanze Liao",
      "Thomas K. F. Chiu",
      "John Stamper",
      "Kenneth R. Koedinger"
    ],
    "abstract": "The widespread adoption of Artificial Intelligence (AI) in K-12 education highlights the need for psychometrically-tested measures of teachers' AI literacy. Existing work has primarily relied on either self-report (SR) or objective-based (OB) assessments, with few studies aligning the two within a shared framework to compare perceived versus demonstrated competencies or examine how prior AI literacy experience shapes this relationship. This gap limits the scalability of learning analytics and the development of learner profile-driven instructional design. In this study, we developed and evaluated SR and OB measures of teacher AI literacy within the established framework of Concept, Use, Evaluate, and Ethics. Confirmatory factor analyses support construct validity with good reliability and acceptable fit. Results reveal a low correlation between SR and OB factors. Latent profile analysis identified six distinct profiles, including overestimation (SR > OB), underestimation (SR < OB), alignment (SR close to OB), and a unique low-SR/low-OB profile among teachers without AI literacy experience. Theoretically, this work extends existing AI literacy frameworks by validating SR and OB measures on shared dimensions. Practically, the instruments function as diagnostic tools for professional development, supporting AI-informed decisions (e.g., growth monitoring, needs profiling) and enabling scalable learning analytics interventions tailored to teacher subgroups.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "16 pages, 6 figures, LAK2026",
    "pdf_url": "https://arxiv.org/pdf/2601.06101v1",
    "published_date": "2026-01-03 00:10:41 UTC",
    "updated_date": "2026-01-03 00:10:41 UTC"
  },
  {
    "arxiv_id": "2601.01008v1",
    "title": "An Explainable Agentic AI Framework for Uncertainty-Aware and Abstention-Enabled Acute Ischemic Stroke Imaging Decisions",
    "authors": [
      "Md Rashadul Islam"
    ],
    "abstract": "Artificial intelligence models have shown strong potential in acute ischemic stroke imaging, particularly for lesion detection and segmentation using computed tomography and magnetic resonance imaging. However, most existing approaches operate as black box predictors, producing deterministic outputs without explicit uncertainty awareness or structured mechanisms to abstain under ambiguous conditions. This limitation raises serious safety and trust concerns in high risk emergency radiology settings. In this paper, we propose an explainable agentic AI framework for uncertainty aware and abstention enabled decision support in acute ischemic stroke imaging. The framework follows a modular agentic pipeline in which a perception agent performs lesion aware image analysis, an uncertainty estimation agent computes slice level predictive reliability, and a decision agent determines whether to issue a prediction or abstain based on predefined uncertainty thresholds. Unlike prior stroke imaging systems that primarily focus on improving segmentation or classification accuracy, the proposed framework explicitly prioritizes clinical safety, transparency, and clinician aligned decision behavior. Qualitative and case based analyses across representative stroke imaging scenarios demonstrate that uncertainty driven abstention naturally emerges in diagnostically ambiguous regions and low information slices. The framework further integrates visual explanation mechanisms to support both predictive and abstention decisions, addressing a key limitation of existing uncertainty aware medical imaging systems. Rather than introducing a new performance benchmark, this work presents agentic control, uncertainty awareness, and selective abstention as essential design principles for developing safe and trustworthy medical imaging AI systems.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Preprint. Conceptual and exploratory framework focusing on uncertainty-aware and abstention-enabled decision support for acute ischemic stroke imaging",
    "pdf_url": "https://arxiv.org/pdf/2601.01008v1",
    "published_date": "2026-01-03 00:10:08 UTC",
    "updated_date": "2026-01-03 00:10:08 UTC"
  },
  {
    "arxiv_id": "2601.16218v1",
    "title": "M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models",
    "authors": [
      "Aleix Torres-Camps",
      "Nathaniel Mitrani Hadida",
      "Víctor Conchello Vendrell",
      "Àlex Batlle Casellas",
      "Arnau Padrés Masdemont",
      "Jordi Ros-Giralt"
    ],
    "abstract": "Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.16218v1",
    "published_date": "2026-01-03 00:08:46 UTC",
    "updated_date": "2026-01-03 00:08:46 UTC"
  }
]