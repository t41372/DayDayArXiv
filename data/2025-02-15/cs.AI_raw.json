[
  {
    "arxiv_id": "2502.10931v2",
    "title": "D-CIPHER: Dynamic Collaborative Intelligent Multi-Agent System with Planner and Heterogeneous Executors for Offensive Security",
    "authors": [
      "Meet Udeshi",
      "Minghao Shao",
      "Haoran Xi",
      "Nanda Rani",
      "Kimberly Milner",
      "Venkata Sai Charan Putrevu",
      "Brendan Dolan-Gavitt",
      "Sandeep Kumar Shukla",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Ramesh Karri",
      "Muhammad Shafique"
    ],
    "abstract": "Large Language Models (LLMs) have been used in cybersecurity such as\nautonomous security analysis or penetration testing. Capture the Flag (CTF)\nchallenges serve as benchmarks to assess automated task-planning abilities of\nLLM agents for cybersecurity. Early attempts to apply LLMs for solving CTF\nchallenges used single-agent systems, where feedback was restricted to a single\nreasoning-action loop. This approach was inadequate for complex CTF tasks.\nInspired by real-world CTF competitions, where teams of experts collaborate, we\nintroduce the D-CIPHER LLM multi-agent framework for collaborative CTF solving.\nD-CIPHER integrates agents with distinct roles with dynamic feedback loops to\nenhance reasoning on complex tasks. It introduces the Planner-Executor agent\nsystem, consisting of a Planner agent for overall problem-solving along with\nmultiple heterogeneous Executor agents for individual tasks, facilitating\nefficient allocation of responsibilities among the agents. Additionally,\nD-CIPHER incorporates an Auto-prompter agent to improve problem-solving by\nauto-generating a highly relevant initial prompt. We evaluate D-CIPHER on\nmultiple CTF benchmarks and LLM models via comprehensive studies to highlight\nthe impact of our enhancements. Additionally, we manually map the CTFs in NYU\nCTF Bench to MITRE ATT&CK techniques that apply for a comprehensive evaluation\nof D-CIPHER's offensive security capability. D-CIPHER achieves state-of-the-art\nperformance on three benchmarks: 22.0% on NYU CTF Bench, 22.5% on Cybench, and\n44.0% on HackTheBox, which is 2.5% to 8.5% better than previous work. D-CIPHER\nsolves 65% more ATT&CK techniques compared to previous work, demonstrating\nstronger offensive capability.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10931v2",
    "published_date": "2025-02-15 23:43:18 UTC",
    "updated_date": "2025-05-11 03:59:37 UTC"
  },
  {
    "arxiv_id": "2502.10928v2",
    "title": "Probing Semantic Routing in Large Mixture-of-Expert Models",
    "authors": [
      "Matthew Lyle Olson",
      "Neale Ratzlaff",
      "Musashi Hinck",
      "Man Luo",
      "Sungduk Yu",
      "Chendi Xue",
      "Vasudev Lal"
    ],
    "abstract": "In the past year, large (>100B parameter) mixture-of-expert (MoE) models have\nbecome increasingly common in the open domain. While their advantages are often\nframed in terms of efficiency, prior work has also explored functional\ndifferentiation through routing behavior. We investigate whether expert routing\nin large MoE models is influenced by the semantics of the inputs. To test this,\nwe design two controlled experiments. First, we compare activations on sentence\npairs with a shared target word used in the same or different senses. Second,\nwe fix context and substitute the target word with semantically similar or\ndissimilar alternatives. Comparing expert overlap across these conditions\nreveals clear, statistically significant evidence of semantic routing in large\nMoE models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.10928v2",
    "published_date": "2025-02-15 23:37:32 UTC",
    "updated_date": "2025-05-21 16:32:41 UTC"
  },
  {
    "arxiv_id": "2502.10920v1",
    "title": "Do Deepfake Detectors Work in Reality?",
    "authors": [
      "Simiao Ren",
      "Hengwei Xu",
      "Tsang Ng",
      "Kidus Zewde",
      "Shengkai Jiang",
      "Ramini Desai",
      "Disha Patil",
      "Ning-Yau Cheng",
      "Yining Zhou",
      "Ragavi Muthukrishnan"
    ],
    "abstract": "Deepfakes, particularly those involving faceswap-based manipulations, have\nsparked significant societal concern due to their increasing realism and\npotential for misuse. Despite rapid advancements in generative models,\ndetection methods have not kept pace, creating a critical gap in defense\nstrategies. This disparity is further amplified by the disconnect between\nacademic research and real-world applications, which often prioritize different\nobjectives and evaluation criteria. In this study, we take a pivotal step\ntoward bridging this gap by presenting a novel observation: the post-processing\nstep of super-resolution, commonly employed in real-world scenarios,\nsubstantially undermines the effectiveness of existing deepfake detection\nmethods. To substantiate this claim, we introduce and publish the first\nreal-world faceswap dataset, collected from popular online faceswap platforms.\nWe then qualitatively evaluate the performance of state-of-the-art deepfake\ndetectors on real-world deepfakes, revealing that their accuracy approaches the\nlevel of random guessing. Furthermore, we quantitatively demonstrate the\nsignificant performance degradation caused by common post-processing\ntechniques. By addressing this overlooked challenge, our study underscores a\ncritical avenue for enhancing the robustness and practical applicability of\ndeepfake detection methods in real-world settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10920v1",
    "published_date": "2025-02-15 22:38:40 UTC",
    "updated_date": "2025-02-15 22:38:40 UTC"
  },
  {
    "arxiv_id": "2502.10908v1",
    "title": "Automatic Quality Assessment of First Trimester Crown-Rump-Length Ultrasound Images",
    "authors": [
      "Sevim Cengiz",
      "Ibraheem Hamdi",
      "Mohammad Yaqub"
    ],
    "abstract": "Fetal gestational age (GA) is vital clinical information that is estimated\nduring pregnancy in order to assess fetal growth. This is usually performed by\nmeasuring the crown-rump-length (CRL) on an ultrasound image in the Dating scan\nwhich is then correlated with fetal age and growth trajectory. A major issue\nwhen performing the CRL measurement is ensuring that the image is acquired at\nthe correct view, otherwise it could be misleading. Although clinical\nguidelines specify the criteria for the correct CRL view, sonographers may not\nregularly adhere to such rules. In this paper, we propose a new deep\nlearning-based solution that is able to verify the adherence of a CRL image to\nclinical guidelines in order to assess image quality and facilitate accurate\nestimation of GA. We first segment out important fetal structures then use the\nlocalized structures to perform a clinically-guided mapping that verifies the\nadherence of criteria. The segmentation method combines the benefits of\nConvolutional Neural Network (CNN) and the Vision Transformer (ViT) to segment\nfetal structures in ultrasound images and localize important fetal landmarks.\nFor segmentation purposes, we compare our proposed work with UNet and show that\nour CNN/ViT-based method outperforms an optimized version of UNet. Furthermore,\nwe compare the output of the mapping with classification CNNs when assessing\nthe clinical criteria and the overall acceptability of CRL images. We show that\nthe proposed mapping is not only explainable but also more accurate than the\nbest performing classification CNNs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10908v1",
    "published_date": "2025-02-15 21:05:07 UTC",
    "updated_date": "2025-02-15 21:05:07 UTC"
  },
  {
    "arxiv_id": "2502.10906v1",
    "title": "PCGRLLM: Large Language Model-Driven Reward Design for Procedural Content Generation Reinforcement Learning",
    "authors": [
      "In-Chang Baek",
      "Sung-Hyun Kim",
      "Sam Earle",
      "Zehua Jiang",
      "Noh Jin-Ha",
      "Julian Togelius",
      "Kyung-Joong Kim"
    ],
    "abstract": "Reward design plays a pivotal role in the training of game AIs, requiring\nsubstantial domain-specific knowledge and human effort. In recent years,\nseveral studies have explored reward generation for training game agents and\ncontrolling robots using large language models (LLMs). In the content\ngeneration literature, there has been early work on generating reward functions\nfor reinforcement learning agent generators. This work introduces PCGRLLM, an\nextended architecture based on earlier work, which employs a feedback mechanism\nand several reasoning-based prompt engineering techniques. We evaluate the\nproposed method on a story-to-reward generation task in a two-dimensional\nenvironment using two state-of-the-art LLMs, demonstrating the generalizability\nof our approach. Our experiments provide insightful evaluations that\ndemonstrate the capabilities of LLMs essential for content generation tasks.\nThe results highlight significant performance improvements of 415% and 40%\nrespectively, depending on the zero-shot capabilities of the language model.\nOur work demonstrates the potential to reduce human dependency in game AI\ndevelopment, while supporting and enhancing creative processes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10906v1",
    "published_date": "2025-02-15 21:00:40 UTC",
    "updated_date": "2025-02-15 21:00:40 UTC"
  },
  {
    "arxiv_id": "2502.10899v1",
    "title": "Breaking Down the Hierarchy: A New Approach to Leukemia Classification",
    "authors": [
      "Ibraheem Hamdi",
      "Hosam El-Gendy",
      "Ahmed Sharshar",
      "Mohamed Saeed",
      "Muhammad Ridzuan",
      "Shahrukh K. Hashmi",
      "Naveed Syed",
      "Imran Mirza",
      "Shakir Hussain",
      "Amira Mahmoud Abdalla",
      "Mohammad Yaqub"
    ],
    "abstract": "The complexities inherent to leukemia, multifaceted cancer affecting white\nblood cells, pose considerable diagnostic and treatment challenges, primarily\ndue to reliance on laborious morphological analyses and expert judgment that\nare susceptible to errors. Addressing these challenges, this study presents a\nrefined, comprehensive strategy leveraging advanced deep-learning techniques\nfor the classification of leukemia subtypes. We commence by developing a\nhierarchical label taxonomy, paving the way for differentiating between various\nsubtypes of leukemia. The research further introduces a novel hierarchical\napproach inspired by clinical procedures capable of accurately classifying\ndiverse types of leukemia alongside reactive and healthy cells. An integral\npart of this study involves a meticulous examination of the performance of\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs) as\nclassifiers. The proposed method exhibits an impressive success rate, achieving\napproximately 90\\% accuracy across all leukemia subtypes, as substantiated by\nour experimental results. A visual representation of the experimental findings\nis provided to enhance the model's explainability and aid in understanding the\nclassification process.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10899v1",
    "published_date": "2025-02-15 20:36:15 UTC",
    "updated_date": "2025-02-15 20:36:15 UTC"
  },
  {
    "arxiv_id": "2502.10894v1",
    "title": "Bridging the Sim-to-Real Gap for Athletic Loco-Manipulation",
    "authors": [
      "Nolan Fey",
      "Gabriel B. Margolis",
      "Martin Peticco",
      "Pulkit Agrawal"
    ],
    "abstract": "Achieving athletic loco-manipulation on robots requires moving beyond\ntraditional tracking rewards - which simply guide the robot along a reference\ntrajectory - to task rewards that drive truly dynamic, goal-oriented behaviors.\nCommands such as \"throw the ball as far as you can\" or \"lift the weight as\nquickly as possible\" compel the robot to exhibit the agility and power inherent\nin athletic performance. However, training solely with task rewards introduces\ntwo major challenges: these rewards are prone to exploitation (reward hacking),\nand the exploration process can lack sufficient direction. To address these\nissues, we propose a two-stage training pipeline. First, we introduce the\nUnsupervised Actuator Net (UAN), which leverages real-world data to bridge the\nsim-to-real gap for complex actuation mechanisms without requiring access to\ntorque sensing. UAN mitigates reward hacking by ensuring that the learned\nbehaviors remain robust and transferable. Second, we use a pre-training and\nfine-tuning strategy that leverages reference trajectories as initial hints to\nguide exploration. With these innovations, our robot athlete learns to lift,\nthrow, and drag with remarkable fidelity from simulation to reality.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: http://uan.csail.mit.edu",
    "pdf_url": "http://arxiv.org/pdf/2502.10894v1",
    "published_date": "2025-02-15 20:18:37 UTC",
    "updated_date": "2025-02-15 20:18:37 UTC"
  },
  {
    "arxiv_id": "2502.10883v1",
    "title": "Learning Identifiable Structures Helps Avoid Bias in DNN-based Supervised Causal Learning",
    "authors": [
      "Jiaru Zhang",
      "Rui Ding",
      "Qiang Fu",
      "Bojun Huang",
      "Zizhen Deng",
      "Yang Hua",
      "Haibing Guan",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "abstract": "Causal discovery is a structured prediction task that aims to predict causal\nrelations among variables based on their data samples. Supervised Causal\nLearning (SCL) is an emerging paradigm in this field. Existing Deep Neural\nNetwork (DNN)-based methods commonly adopt the \"Node-Edge approach\", in which\nthe model first computes an embedding vector for each variable-node, then uses\nthese variable-wise representations to concurrently and independently predict\nfor each directed causal-edge. In this paper, we first show that this\narchitecture has some systematic bias that cannot be mitigated regardless of\nmodel size and data size. We then propose SiCL, a DNN-based SCL method that\npredicts a skeleton matrix together with a v-tensor (a third-order tensor\nrepresenting the v-structures). According to the Markov Equivalence Class (MEC)\ntheory, both the skeleton and the v-structures are identifiable causal\nstructures under the canonical MEC setting, so predictions about skeleton and\nv-structures do not suffer from the identifiability limit in causal discovery,\nthus SiCL can avoid the systematic bias in Node-Edge architecture, and enable\nconsistent estimators for causal discovery. Moreover, SiCL is also equipped\nwith a specially designed pairwise encoder module with a unidirectional\nattention layer to model both internal and external relationships of pairs of\nnodes. Experimental results on both synthetic and real-world benchmarks show\nthat SiCL significantly outperforms other DNN-based SCL approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10883v1",
    "published_date": "2025-02-15 19:10:35 UTC",
    "updated_date": "2025-02-15 19:10:35 UTC"
  },
  {
    "arxiv_id": "2502.10878v1",
    "title": "Broadcast Channel Cooperative Gain: An Operational Interpretation of Partial Information Decomposition",
    "authors": [
      "Chao Tian",
      "Shlomo Shamai"
    ],
    "abstract": "Partial information decomposition has recently found applications in\nbiological signal processing and machine learning. Despite its impacts, the\ndecomposition was introduced through an informal and heuristic route, and its\nexact operational meaning is unclear. In this work, we fill this gap by\nconnecting partial information decomposition to the capacity of the broadcast\nchannel, which has been well-studied in the information theory literature. We\nshow that the synergistic information in the decomposition can be rigorously\ninterpreted as the cooperative gain, or a lower bound of this gain, on the\ncorresponding broadcast channel. This interpretation can help practitioners to\nbetter explain and expand the applications of the partial information\ndecomposition technique.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.10878v1",
    "published_date": "2025-02-15 18:28:36 UTC",
    "updated_date": "2025-02-15 18:28:36 UTC"
  },
  {
    "arxiv_id": "2502.10875v1",
    "title": "A Geometric Approach to Personalized Recommendation with Set-Theoretic Constraints Using Box Embeddings",
    "authors": [
      "Shib Dasgupta",
      "Michael Boratko",
      "Andrew McCallum"
    ],
    "abstract": "Personalized item recommendation typically suffers from data sparsity, which\nis most often addressed by learning vector representations of users and items\nvia low-rank matrix factorization. While this effectively densifies the matrix\nby assuming users and movies can be represented by linearly dependent latent\nfeatures, it does not capture more complicated interactions. For example,\nvector representations struggle with set-theoretic relationships, such as\nnegation and intersection, e.g. recommending a movie that is \"comedy and\naction, but not romance\". In this work, we formulate the problem of\npersonalized item recommendation as matrix completion where rows are\nset-theoretically dependent. To capture this set-theoretic dependence we\nrepresent each user and attribute by a hyper-rectangle or box (i.e. a Cartesian\nproduct of intervals). Box embeddings can intuitively be understood as\ntrainable Venn diagrams, and thus not only inherently represent similarity (via\nthe Jaccard index), but also naturally and faithfully support arbitrary\nset-theoretic relationships. Queries involving set-theoretic constraints can be\nefficiently computed directly on the embedding space by performing geometric\noperations on the representations. We empirically demonstrate the superiority\nof box embeddings over vector-based neural methods on both simple and complex\nitem recommendation queries by up to 30 \\% overall.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10875v1",
    "published_date": "2025-02-15 18:18:00 UTC",
    "updated_date": "2025-02-15 18:18:00 UTC"
  },
  {
    "arxiv_id": "2502.12197v1",
    "title": "A Closer Look at System Prompt Robustness",
    "authors": [
      "Norman Mu",
      "Jonathan Lu",
      "Michael Lavery",
      "David Wagner"
    ],
    "abstract": "System prompts have emerged as a critical control surface for specifying the\nbehavior of LLMs in chat and agent settings. Developers depend on system\nprompts to specify important context, output format, personalities, guardrails,\ncontent policies, and safety countermeasures, all of which require models to\nrobustly adhere to the system prompt, especially when facing conflicting or\nadversarial user inputs. In practice, models often forget to consider relevant\nguardrails or fail to resolve conflicting demands between the system and the\nuser. In this work, we study various methods for improving system prompt\nrobustness by creating realistic new evaluation and fine-tuning datasets based\non prompts collected from from OpenAI's GPT Store and HuggingFace's\nHuggingChat. Our experiments assessing models with a panel of new and existing\nbenchmarks show that performance can be considerably improved with realistic\nfine-tuning data, as well as inference-time interventions such as\nclassifier-free guidance. Finally, we analyze the results of recently released\nreasoning models from OpenAI and DeepSeek, which show exciting but uneven\nimprovements on the benchmarks we study. Overall, current techniques fall short\nof ensuring system prompt robustness and further study is warranted.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Artifacts: https://github.com/normster/RealGuardrails",
    "pdf_url": "http://arxiv.org/pdf/2502.12197v1",
    "published_date": "2025-02-15 18:10:45 UTC",
    "updated_date": "2025-02-15 18:10:45 UTC"
  },
  {
    "arxiv_id": "2502.10871v1",
    "title": "The Representation and Recall of Interwoven Structured Knowledge in LLMs: A Geometric and Layered Analysis",
    "authors": [
      "Ge Lei",
      "Samuel J. Cooper"
    ],
    "abstract": "This study investigates how large language models (LLMs) represent and recall\nmulti-associated attributes across transformer layers. We show that\nintermediate layers encode factual knowledge by superimposing related\nattributes in overlapping spaces, along with effective recall even when\nattributes are not explicitly prompted. In contrast, later layers refine\nlinguistic patterns and progressively separate attribute representations,\noptimizing task-specific outputs while appropriately narrowing attribute\nrecall. We identify diverse encoding patterns including, for the first time,\nthe observation of 3D spiral structures when exploring information related to\nthe periodic table of elements. Our findings reveal a dynamic transition in\nattribute representations across layers, contributing to mechanistic\ninterpretability and providing insights for understanding how LLMs handle\ncomplex, interrelated knowledge.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10871v1",
    "published_date": "2025-02-15 18:08:51 UTC",
    "updated_date": "2025-02-15 18:08:51 UTC"
  },
  {
    "arxiv_id": "2502.10867v1",
    "title": "A Tutorial on LLM Reasoning: Relevant Methods behind ChatGPT o1",
    "authors": [
      "Jun Wang"
    ],
    "abstract": "OpenAI o1 has shown that applying reinforcement learning to integrate\nreasoning steps directly during inference can significantly improve a model's\nreasoning capabilities. This result is exciting as the field transitions from\nthe conventional autoregressive method of generating answers to a more\ndeliberate approach that models the slow-thinking process through step-by-step\nreasoning training. Reinforcement learning plays a key role in both the model's\ntraining and decoding processes. In this article, we present a comprehensive\nformulation of reasoning problems and investigate the use of both model-based\nand model-free approaches to better support this slow-thinking framework.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10867v1",
    "published_date": "2025-02-15 17:52:11 UTC",
    "updated_date": "2025-02-15 17:52:11 UTC"
  },
  {
    "arxiv_id": "2502.10858v2",
    "title": "Is Depth All You Need? An Exploration of Iterative Reasoning in LLMs",
    "authors": [
      "Zongqian Wu",
      "Tianyu Li",
      "Baoduo Xu",
      "Jiaying Yang",
      "Mengmeng Zhan",
      "Xiaofeng Zhu",
      "Lei Feng"
    ],
    "abstract": "Deep iterative chain-of-thought (CoT) reasoning enables LLMs to tackle\ncomplex tasks by progressively activating relevant pre-trained knowledge.\nHowever, it faces challenges in ensuring continual improvement and determining\na stopping criterion. In this paper, we investigate whether the relevant\nknowledge that contributes directly to solving the given question can be\nactivated from the initial reasoning path, thus circumventing the need for\niterative refinement. Our experiments reveal that increasing the diversity of\ninitial reasoning paths can achieve comparable or superior performance, a\nconcept we term \\textit{breadth reasoning}. However, existing breadth reasoning\napproaches, such as self-consistency, offer limited diversity. To address this\nlimitation, we propose a simple yet effective method that enhances reasoning\nbreadth by integrating contextual exploration with reduced sampling randomness.\nExtensive experiments demonstrate that our approach significantly outperforms\ndeep iterative reasoning. Our code is provided in\nhttps://github.com/zongqianwu/breadth.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10858v2",
    "published_date": "2025-02-15 16:59:59 UTC",
    "updated_date": "2025-02-18 07:58:19 UTC"
  },
  {
    "arxiv_id": "2502.10852v1",
    "title": "Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages",
    "authors": [
      "Zeli Su",
      "Ziyin Zhang",
      "Guixian Xu",
      "Jianing Liu",
      "XU Han",
      "Ting Zhang",
      "Yushuang Dong"
    ],
    "abstract": "While multilingual language models like XLM-R have advanced multilingualism\nin NLP, they still perform poorly in extremely low-resource languages. This\nsituation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen\nsupport far fewer languages than XLM-R, making text generation models\nnon-existent for many languages in the world. To tackle this challenge, we\npropose a novel framework for adapting multilingual encoders to text generation\nin extremely low-resource languages. By reusing the weights between the encoder\nand the decoder, our framework allows the model to leverage the learned\nsemantic space of the encoder, enabling efficient learning and effective\ngeneralization in low-resource languages. Applying this framework to four\nChinese minority languages, we present XLM-SWCM, and demonstrate its superior\nperformance on various downstream tasks even when compared with much larger\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10852v1",
    "published_date": "2025-02-15 16:53:10 UTC",
    "updated_date": "2025-02-15 16:53:10 UTC"
  },
  {
    "arxiv_id": "2502.10828v1",
    "title": "The Vendiscope: An Algorithmic Microscope For Data Collections",
    "authors": [
      "Amey P. Pasarkar",
      "Adji Bousso Dieng"
    ],
    "abstract": "The evolution of microscopy, beginning with its invention in the late 16th\ncentury, has continuously enhanced our ability to explore and understand the\nmicroscopic world, enabling increasingly detailed observations of structures\nand phenomena. In parallel, the rise of data-driven science has underscored the\nneed for sophisticated methods to explore and understand the composition of\ncomplex data collections. This paper introduces the Vendiscope, the first\nalgorithmic microscope designed to extend traditional microscopy to\ncomputational analysis. The Vendiscope leverages the Vendi scores -- a family\nof differentiable diversity metrics rooted in ecology and quantum mechanics --\nand assigns weights to data points based on their contribution to the overall\ndiversity of the collection. These weights enable high-resolution data analysis\nat scale. We demonstrate this across biology, materials science, and machine\nlearning (ML). We analyzed the $250$ million protein sequences in the protein\nuniverse, discovering that over $200$ million are near-duplicates and that\nAlphaFold fails on proteins with Gene Ontology (GO) functions that contribute\nmost to diversity. Applying the Vendiscope to the Materials Project database\nled to similar findings: more than $85\\%$ of the crystals with formation energy\ndata are near-duplicates and ML models perform poorly on materials that enhance\ndiversity. Additionally, the Vendiscope can be used to study phenomena such as\nmemorization in generative models. We used the Vendiscope to identify memorized\ntraining samples from $13$ different generative models and found that the\nbest-performing ones often memorize the training samples that contribute least\nto diversity. Our findings demonstrate that the Vendiscope can serve as a\npowerful tool for data-driven science.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper introduces the concept of \"algorithmic microscopes\" and\n  proposes the Vendiscope, an algorithmic microscope for data-driven science",
    "pdf_url": "http://arxiv.org/pdf/2502.10828v1",
    "published_date": "2025-02-15 15:07:01 UTC",
    "updated_date": "2025-02-15 15:07:01 UTC"
  },
  {
    "arxiv_id": "2502.10825v1",
    "title": "MITRE ATT&CK Applications in Cybersecurity and The Way Forward",
    "authors": [
      "Yuning Jiang",
      "Qiaoran Meng",
      "Feiyang Shang",
      "Nay Oo",
      "Le Thi Hong Minh",
      "Hoon Wei Lim",
      "Biplab Sikdar"
    ],
    "abstract": "The MITRE ATT&CK framework is a widely adopted tool for enhancing\ncybersecurity, supporting threat intelligence, incident response, attack\nmodeling, and vulnerability prioritization. This paper synthesizes research on\nits application across these domains by analyzing 417 peer-reviewed\npublications. We identify commonly used adversarial tactics, techniques, and\nprocedures (TTPs) and examine the integration of natural language processing\n(NLP) and machine learning (ML) with ATT&CK to improve threat detection and\nresponse. Additionally, we explore the interoperability of ATT&CK with other\nframeworks, such as the Cyber Kill Chain, NIST guidelines, and STRIDE,\nhighlighting its versatility. The paper further evaluates the framework from\nmultiple perspectives, including its effectiveness, validation methods, and\nsector-specific challenges, particularly in industrial control systems (ICS)\nand healthcare. We conclude by discussing current limitations and proposing\nfuture research directions to enhance the applicability of ATT&CK in dynamic\ncybersecurity environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68M25 (Primary) 68T99 (Secondary)"
    ],
    "primary_category": "cs.CR",
    "comment": "37 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.10825v1",
    "published_date": "2025-02-15 15:01:04 UTC",
    "updated_date": "2025-02-15 15:01:04 UTC"
  },
  {
    "arxiv_id": "2502.10822v1",
    "title": "NeuroAMP: A Novel End-to-end General Purpose Deep Neural Amplifier for Personalized Hearing Aids",
    "authors": [
      "Shafique Ahmed",
      "Ryandhimas E. Zezario",
      "Hui-Guan Yuan",
      "Amir Hussain",
      "Hsin-Min Wang",
      "Wei-Ho Chung",
      "Yu Tsao"
    ],
    "abstract": "The prevalence of hearing aids is increasing. However, optimizing the\namplification processes of hearing aids remains challenging due to the\ncomplexity of integrating multiple modular components in traditional methods.\nTo address this challenge, we present NeuroAMP, a novel deep neural network\ndesigned for end-to-end, personalized amplification in hearing aids. NeuroAMP\nleverages both spectral features and the listener's audiogram as inputs, and we\ninvestigate four architectures: Convolutional Neural Network (CNN), Long\nShort-Term Memory (LSTM), Convolutional Recurrent Neural Network (CRNN), and\nTransformer. We also introduce Denoising NeuroAMP, an extension that integrates\nnoise reduction along with amplification capabilities for improved performance\nin real-world scenarios. To enhance generalization, a comprehensive data\naugmentation strategy was employed during training on diverse speech (TIMIT and\nTMHINT) and music (Cadenza Challenge MUSIC) datasets. Evaluation using the\nHearing Aid Speech Perception Index (HASPI), Hearing Aid Speech Quality Index\n(HASQI), and Hearing Aid Audio Quality Index (HAAQI) demonstrates that the\nTransformer architecture within NeuroAMP achieves the best performance, with\nSRCC scores of 0.9927 (HASQI) and 0.9905 (HASPI) on TIMIT, and 0.9738 (HAAQI)\non the Cadenza Challenge MUSIC dataset. Notably, our data augmentation strategy\nmaintains high performance on unseen datasets (e.g., VCTK, MUSDB18-HQ).\nFurthermore, Denoising NeuroAMP outperforms both the conventional NAL-R+WDRC\napproach and a two-stage baseline on the VoiceBank+DEMAND dataset, achieving a\n10% improvement in both HASPI (0.90) and HASQI (0.59) scores. These results\nhighlight the potential of NeuroAMP and Denoising NeuroAMP to deliver notable\nimprovements in personalized hearing aid amplification.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10822v1",
    "published_date": "2025-02-15 14:55:40 UTC",
    "updated_date": "2025-02-15 14:55:40 UTC"
  },
  {
    "arxiv_id": "2502.10818v1",
    "title": "On Vanishing Gradients, Over-Smoothing, and Over-Squashing in GNNs: Bridging Recurrent and Graph Learning",
    "authors": [
      "Álvaro Arroyo",
      "Alessio Gravina",
      "Benjamin Gutteridge",
      "Federico Barbero",
      "Claudio Gallicchio",
      "Xiaowen Dong",
      "Michael Bronstein",
      "Pierre Vandergheynst"
    ],
    "abstract": "Graph Neural Networks (GNNs) are models that leverage the graph structure to\ntransmit information between nodes, typically through the message-passing\noperation. While widely successful, this approach is well known to suffer from\nthe over-smoothing and over-squashing phenomena, which result in\nrepresentational collapse as the number of layers increases and insensitivity\nto the information contained at distant and poorly connected nodes,\nrespectively. In this paper, we present a unified view of these problems\nthrough the lens of vanishing gradients, using ideas from linear control theory\nfor our analysis. We propose an interpretation of GNNs as recurrent models and\nempirically demonstrate that a simple state-space formulation of a GNN\neffectively alleviates over-smoothing and over-squashing at no extra trainable\nparameter cost. Further, we show theoretically and empirically that (i) GNNs\nare by design prone to extreme gradient vanishing even after a few layers; (ii)\nOver-smoothing is directly related to the mechanism causing vanishing\ngradients; (iii) Over-squashing is most easily alleviated by a combination of\ngraph rewiring and vanishing gradient mitigation. We believe our work will help\nbridge the gap between the recurrent and graph neural network literature and\nwill unlock the design of new deep and performant GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10818v1",
    "published_date": "2025-02-15 14:43:41 UTC",
    "updated_date": "2025-02-15 14:43:41 UTC"
  },
  {
    "arxiv_id": "2502.10816v3",
    "title": "BalanceBenchmark: A Survey for Multimodal Imbalance Learning",
    "authors": [
      "Shaoxuan Xu",
      "Menglu Cui",
      "Chengxiang Huang",
      "Hongfa Wang",
      "Di Hu"
    ],
    "abstract": "Multimodal learning has gained attention for its capacity to integrate\ninformation from different modalities. However, it is often hindered by the\nmultimodal imbalance problem, where certain modality dominates while others\nremain underutilized. Although recent studies have proposed various methods to\nalleviate this problem, they lack comprehensive and fair comparisons. In this\npaper, we systematically categorize various mainstream multimodal imbalance\nalgorithms into four groups based on the strategies they employ to mitigate\nimbalance. To facilitate a comprehensive evaluation of these methods, we\nintroduce BalanceBenchmark, a benchmark including multiple widely used\nmultidimensional datasets and evaluation metrics from three perspectives:\nperformance, imbalance degree, and complexity. To ensure fair comparisons, we\nhave developed a modular and extensible toolkit that standardizes the\nexperimental workflow across different methods. Based on the experiments using\nBalanceBenchmark, we have identified several key insights into the\ncharacteristics and advantages of different method groups in terms of\nperformance, balance degree and computational complexity. We expect such\nanalysis could inspire more efficient approaches to address the imbalance\nproblem in the future, as well as foundation models. The code of the toolkit is\navailable at https://github.com/GeWu-Lab/BalanceBenchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10816v3",
    "published_date": "2025-02-15 14:42:42 UTC",
    "updated_date": "2025-02-23 10:19:36 UTC"
  },
  {
    "arxiv_id": "2502.10807v2",
    "title": "HybriDNA: A Hybrid Transformer-Mamba2 Long-Range DNA Language Model",
    "authors": [
      "Mingqian Ma",
      "Guoqing Liu",
      "Chuan Cao",
      "Pan Deng",
      "Tri Dao",
      "Albert Gu",
      "Peiran Jin",
      "Zhao Yang",
      "Yingce Xia",
      "Renqian Luo",
      "Pipi Hu",
      "Zun Wang",
      "Yuan-Jyue Chen",
      "Haiguang Liu",
      "Tao Qin"
    ],
    "abstract": "Advances in natural language processing and large language models have\nsparked growing interest in modeling DNA, often referred to as the \"language of\nlife\". However, DNA modeling poses unique challenges. First, it requires the\nability to process ultra-long DNA sequences while preserving single-nucleotide\nresolution, as individual nucleotides play a critical role in DNA function.\nSecond, success in this domain requires excelling at both generative and\nunderstanding tasks: generative tasks hold potential for therapeutic and\nindustrial applications, while understanding tasks provide crucial insights\ninto biological mechanisms and diseases. To address these challenges, we\npropose HybriDNA, a decoder-only DNA language model that incorporates a hybrid\nTransformer-Mamba2 architecture, seamlessly integrating the strengths of\nattention mechanisms with selective state-space models. This hybrid design\nenables HybriDNA to efficiently process DNA sequences up to 131kb in length\nwith single-nucleotide resolution. HybriDNA achieves state-of-the-art\nperformance across 33 DNA understanding datasets curated from the BEND, GUE,\nand LRB benchmarks, and demonstrates exceptional capability in generating\nsynthetic cis-regulatory elements (CREs) with desired properties. Furthermore,\nwe show that HybriDNA adheres to expected scaling laws, with performance\nimproving consistently as the model scales from 300M to 3B and 7B parameters.\nThese findings underscore HybriDNA's versatility and its potential to advance\nDNA research and applications, paving the way for innovations in understanding\nand engineering the \"language of life\".",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "Project page: https://hybridna-project.github.io/HybriDNA-Project/",
    "pdf_url": "http://arxiv.org/pdf/2502.10807v2",
    "published_date": "2025-02-15 14:23:43 UTC",
    "updated_date": "2025-02-18 02:00:07 UTC"
  },
  {
    "arxiv_id": "2502.10803v1",
    "title": "PDA: Generalizable Detection of AI-Generated Images via Post-hoc Distribution Alignment",
    "authors": [
      "Li Wang",
      "Wenyu Chen",
      "Zheng Li",
      "Shanqing Guo"
    ],
    "abstract": "The rapid advancement of generative models has led to the proliferation of\nhighly realistic AI-generated images, posing significant challenges for\ndetection methods to generalize across diverse and evolving generative\ntechniques. Existing approaches often fail to adapt to unknown models without\ncostly retraining, limiting their practicability. To fill this gap, we propose\nPost-hoc Distribution Alignment (PDA), a novel approach for the generalizable\ndetection for AI-generated images. The key idea is to use the known generative\nmodel to regenerate undifferentiated test images. This process aligns the\ndistributions of the re-generated real images with the known fake images,\nenabling effective distinction from unknown fake images. PDA employs a two-step\ndetection framework: 1) evaluating whether a test image aligns with the known\nfake distribution based on deep k-nearest neighbor (KNN) distance, and 2)\nre-generating test images using known generative models to create pseudo-fake\nimages for further classification. This alignment strategy allows PDA to\neffectively detect fake images without relying on unseen data or requiring\nretraining. Extensive experiments demonstrate the superiority of PDA, achieving\n96.73\\% average accuracy across six state-of-the-art generative models,\nincluding GANs, diffusion models, and text-to-image models, and improving by\n16.07\\% over the best baseline. Through t-SNE visualizations and KNN distance\nanalysis, we provide insights into PDA's effectiveness in separating real and\nfake images. Our work provides a flexible and effective solution for real-world\nfake image detection, advancing the generalization ability of detection\nsystems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10803v1",
    "published_date": "2025-02-15 13:55:34 UTC",
    "updated_date": "2025-02-15 13:55:34 UTC"
  },
  {
    "arxiv_id": "2502.10802v1",
    "title": "CoCoEvo: Co-Evolution of Programs and Test Cases to Enhance Code Generation",
    "authors": [
      "Kefan Li",
      "Hongyue Yu",
      "Tingyu Guo",
      "Shijie Cao",
      "Yuan Yuan"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable performance in automated\ncode generation. However, existing approaches often rely heavily on pre-defined\ntest cases, which become impractical in scenarios where such cases are\nunavailable. While prior works explore filtering techniques between programs\nand test cases, they overlook the refinement of test cases. To address this\nlimitation, we introduce CoCoEvo, a novel LLM-based co-evolution framework that\nsimultaneously evolves programs and test cases. CoCoEvo eliminates the\ndependency on pre-defined test cases by generating both programs and test cases\ndirectly from natural language problem descriptions and function headers. The\nframework employs specialized evolutionary operators, including LLM-based\ncrossover and mutation operators for program evolution, along with a test case\ngeneration operator for test case evolution. Additionally, we propose\noptimization strategies such as a crossover rate scheduler to balance\nexploration and convergence, and a multi-objective optimization method for test\ncase selection. Experimental results on multiple state-of-the-art LLMs\ndemonstrate that CoCoEvo surpasses existing methods, achieving state-of-the-art\nperformance in automated code generation and testing. These results underscore\nthe potential of co-evolutionary techniques in advancing the field of automated\nprogramming.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10802v1",
    "published_date": "2025-02-15 13:52:30 UTC",
    "updated_date": "2025-02-15 13:52:30 UTC"
  },
  {
    "arxiv_id": "2502.10801v1",
    "title": "FaceSwapGuard: Safeguarding Facial Privacy from DeepFake Threats through Identity Obfuscation",
    "authors": [
      "Li Wang",
      "Zheng Li",
      "Xuhong Zhang",
      "Shouling Ji",
      "Shanqing Guo"
    ],
    "abstract": "DeepFakes pose a significant threat to our society. One representative\nDeepFake application is face-swapping, which replaces the identity in a facial\nimage with that of a victim. Although existing methods partially mitigate these\nrisks by degrading the quality of swapped images, they often fail to disrupt\nthe identity transformation effectively. To fill this gap, we propose\nFaceSwapGuard (FSG), a novel black-box defense mechanism against deepfake\nface-swapping threats. Specifically, FSG introduces imperceptible perturbations\nto a user's facial image, disrupting the features extracted by identity\nencoders. When shared online, these perturbed images mislead face-swapping\ntechniques, causing them to generate facial images with identities\nsignificantly different from the original user. Extensive experiments\ndemonstrate the effectiveness of FSG against multiple face-swapping techniques,\nreducing the face match rate from 90\\% (without defense) to below 10\\%. Both\nqualitative and quantitative studies further confirm its ability to confuse\nhuman perception, highlighting its practical utility. Additionally, we\ninvestigate key factors that may influence FSG and evaluate its robustness\nagainst various adaptive adversaries.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10801v1",
    "published_date": "2025-02-15 13:45:19 UTC",
    "updated_date": "2025-02-15 13:45:19 UTC"
  },
  {
    "arxiv_id": "2502.10793v1",
    "title": "Dynamic Influence Tracker: Measuring Time-Varying Sample Influence During Training",
    "authors": [
      "Jie Xu",
      "Zihan Wu"
    ],
    "abstract": "Existing methods for measuring training sample influence on models only\nprovide static, overall measurements, overlooking how sample influence changes\nduring training. We propose Dynamic Influence Tracker (DIT), which captures the\ntime-varying sample influence across arbitrary time windows during training.\n  DIT offers three key insights: 1) Samples show different time-varying\ninfluence patterns, with some samples important in the early training stage\nwhile others become important later. 2) Sample influences show a weak\ncorrelation between early and late stages, demonstrating that the model\nundergoes distinct learning phases with shifting priorities. 3) Analyzing\ninfluence during the convergence period provides more efficient and accurate\ndetection of corrupted samples than full-training analysis. Supported by\ntheoretical guarantees without assuming loss convexity or model convergence,\nDIT significantly outperforms existing methods, achieving up to 0.99\ncorrelation with ground truth and above 98\\% accuracy in detecting corrupted\nsamples in complex architectures.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10793v1",
    "published_date": "2025-02-15 13:24:21 UTC",
    "updated_date": "2025-02-15 13:24:21 UTC"
  },
  {
    "arxiv_id": "2502.10776v1",
    "title": "A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction",
    "authors": [
      "Zhipeng Liu",
      "Peibo Duan",
      "Mingyang Geng",
      "Bin Zhang"
    ],
    "abstract": "Stock trend prediction involves forecasting the future price movements by\nanalyzing historical data and various market indicators. With the advancement\nof machine learning, graph neural networks (GNNs) have been extensively\nemployed in stock prediction due to their powerful capability to capture\nspatiotemporal dependencies of stocks. However, despite the efforts of various\nGNN stock predictors to enhance predictive performance, the improvements remain\nlimited, as they focus solely on analyzing historical spatiotemporal\ndependencies, overlooking the correlation between historical and future\npatterns. In this study, we propose a novel distillation-based future-aware GNN\nframework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN\ntrains a teacher model and a student model, iteratively. The teacher model\nlearns to capture the correlation between distribution shifts of historical and\nfuture data, which is then utilized as intermediate supervision to guide the\nstudent model to learn future-aware spatiotemporal embeddings for accurate\nprediction. Through extensive experiments on two real-world datasets, we verify\nthe state-of-the-art performance of DishFT-GNN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.PM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10776v1",
    "published_date": "2025-02-15 11:44:15 UTC",
    "updated_date": "2025-02-15 11:44:15 UTC"
  },
  {
    "arxiv_id": "2502.10768v1",
    "title": "Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)",
    "authors": [
      "Sandra Schaftner"
    ],
    "abstract": "Current research highlights the great potential of Large Language Models\n(LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly\ncomplex step in this process is relation extraction, aimed at identifying\nsuitable properties to describe the content of research. This study builds\ndirectly on previous research of three Open Research Knowledge Graph (ORKG)\nteam members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and\nMistral for property extraction in scientific literature. Given the moderate\nperformance observed, the previous work concluded that fine-tuning is needed to\nimprove these models' alignment with scientific tasks and their emulation of\nhuman expertise. Expanding on this prior experiment, this study evaluates the\nimpact of advanced prompt engineering techniques and demonstrates that these\ntechniques can highly significantly enhance the results. Additionally, this\nstudy extends the property extraction process to include property matching to\nexisting ORKG properties, which are retrieved via the API. The evaluation\nreveals that results generated through advanced prompt engineering achieve a\nhigher proportion of matches with ORKG properties, further emphasizing the\nenhanced alignment achieved. Moreover, this lays the groundwork for addressing\nchallenges such as the inconsistency of ORKG properties, an issue highlighted\nin prior studies. By assigning unique URIs and using standardized terminology,\nthis work increases the consistency of the properties, fulfilling a crucial\naspect of Linked Data and FAIR principles - core commitments of ORKG. This, in\nturn, significantly enhances the applicability of ORKG content for subsequent\ntasks such as comparisons of research publications. Finally, the study\nconcludes with recommendations for future improvements in the overall property\nextraction process.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10768v1",
    "published_date": "2025-02-15 11:17:37 UTC",
    "updated_date": "2025-02-15 11:17:37 UTC"
  },
  {
    "arxiv_id": "2502.10762v1",
    "title": "Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation",
    "authors": [
      "Guofu Xie",
      "Xiao Zhang",
      "Ting Yao",
      "Yunsheng Shi"
    ],
    "abstract": "User information needs are often highly diverse and varied. A key challenge\nin current research is how to achieve controllable multi-objective generation\nwhile enabling rapid adaptation to accommodate diverse user demands during test\ntime. Existing solutions, such as Rewarded Soup, focus on merging language\nmodels individually tuned on single objectives. While easy to implement and\nwidely used, these approaches face limitations in achieving optimal performance\ndue to their disregard for the impacts of competing objectives on model tuning.\nTo address this issue, we propose Bone Soup, a novel model merging approach\nthat first seeks a series of backbone models by considering the impacts of\nmultiple objectives and then makes the soup (i.e., merge the backbone models).\nSpecifically, Bone Soup begins by training multiple backbone models for\ndifferent objectives using multi-objective reinforcement learning. Each\nbackbone model is guided by a combination of backbone reward signals. To ensure\nthat these models are optimal for the Pareto front, the backbone rewards are\ncrafted by combining standard reward functions into basis vectors, which can\nthen be modified through a rule-based construction method. Bone Soup leverages\na symmetric circulant matrix mapping to generate the merging coefficients,\nwhich are used to merge the backbone models according to user preferences.\nExtensive experimental results demonstrate that Bone Soup exhibits strong\ncontrollability and Pareto optimality in controllable multi-objective\ngeneration, providing a more effective and efficient approach to addressing\ndiverse user needs at test time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.10762v1",
    "published_date": "2025-02-15 11:00:36 UTC",
    "updated_date": "2025-02-15 11:00:36 UTC"
  },
  {
    "arxiv_id": "2502.10750v1",
    "title": "Human-Centric Community Detection in Hybrid Metaverse Networks with Integrated AI Entities",
    "authors": [
      "Shih-Hsuan Chiu",
      "Ya-Wen Teng",
      "De-Nian Yang",
      "Ming-Syan Chen"
    ],
    "abstract": "Community detection is a cornerstone problem in social network analysis\n(SNA), aimed at identifying cohesive communities with minimal external links.\nHowever, the rise of generative AI and Metaverse introduce complexities by\ncreating hybrid human-AI social networks (denoted by HASNs), where traditional\nmethods fall short, especially in human-centric settings. This paper introduces\na novel community detection problem in HASNs (denoted by MetaCD), which seeks\nto enhance human connectivity within communities while reducing the presence of\nAI nodes. Effective processing of MetaCD poses challenges due to the delicate\ntrade-off between excluding certain AI nodes and maintaining community\nstructure. To address this, we propose CUSA, an innovative framework\nincorporating AI-aware clustering techniques that navigate this trade-off by\nselectively retaining AI nodes that contribute to community integrity.\nFurthermore, given the scarcity of real-world HASNs, we devise four strategies\nfor synthesizing these networks under various hypothetical scenarios. Empirical\nevaluations on real social networks, reconfigured as HASNs, demonstrate the\neffectiveness and practicality of our approach compared to traditional non-deep\nlearning and graph neural network (GNN)-based methods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "15 pages, Accepted for publication in the ACM WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10750v1",
    "published_date": "2025-02-15 10:21:10 UTC",
    "updated_date": "2025-02-15 10:21:10 UTC"
  },
  {
    "arxiv_id": "2502.10749v1",
    "title": "LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging",
    "authors": [
      "Zehua Liu",
      "Han Wu",
      "Yuxuan Yao",
      "Ruifeng She",
      "Xiongwei Han",
      "Tao Zhong",
      "Mingxuan Yuan"
    ],
    "abstract": "While most current approaches rely on further training techniques, such as\nfine-tuning or reinforcement learning, to enhance model capacities, model\nmerging stands out for its ability of improving models without requiring any\nadditional training. In this paper, we propose a unified framework for model\nmerging based on low-rank estimation of task vectors without the need for\naccess to the base model, named \\textsc{LoRE-Merging}. Our approach is\nmotivated by the observation that task vectors from fine-tuned models\nfrequently exhibit a limited number of dominant singular values, making\nlow-rank estimations less prone to interference. We implement the method by\nformulating the merging problem as an optimization problem. Extensive empirical\nexperiments demonstrate the effectiveness of our framework in mitigating\ninterference and preserving task-specific information, thereby advancing the\nstate-of-the-art performance in model merging techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10749v1",
    "published_date": "2025-02-15 10:18:46 UTC",
    "updated_date": "2025-02-15 10:18:46 UTC"
  },
  {
    "arxiv_id": "2502.14883v1",
    "title": "Can LVLMs and Automatic Metrics Capture Underlying Preferences of Blind and Low-Vision Individuals for Navigational Aid?",
    "authors": [
      "Na Min An",
      "Eunki Kim",
      "Wan Ju Kang",
      "Sangryul Kim",
      "Hyunjung Shim",
      "James Thorne"
    ],
    "abstract": "Vision is a primary means of how humans perceive the environment, but Blind\nand Low-Vision (BLV) people need assistance understanding their surroundings,\nespecially in unfamiliar environments. The emergence of semantic-based systems\nas assistance tools for BLV users has motivated many researchers to explore\nresponses from Large Vision-Language Models (LVLMs). However, it has yet been\nstudied preferences of BLV users on diverse types/styles of responses from\nLVLMs, specifically for navigational aid. To fill this gap, we first construct\nEye4B dataset, consisting of human-validated 1.1k curated outdoor/indoor scenes\nwith 5-10 relevant requests per scene. Then, we conduct an in-depth user study\nwith eight BLV users to evaluate their preferences on six LVLMs from five\nperspectives: Afraidness, Nonactionability, Sufficiency, and Conciseness.\nFinally, we introduce Eye4B benchmark for evaluating alignment between widely\nused model-based image-text metrics and our collected BLV preferences. Our work\ncan be set as a guideline for developing BLV-aware LVLMs towards a Barrier-Free\nAI system.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages, 12 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.14883v1",
    "published_date": "2025-02-15 10:17:52 UTC",
    "updated_date": "2025-02-15 10:17:52 UTC"
  },
  {
    "arxiv_id": "2502.10742v1",
    "title": "The Philosophical Foundations of Growing AI Like A Child",
    "authors": [
      "Dezhi Luo",
      "Yijiang Li",
      "Hokin Deng"
    ],
    "abstract": "Despite excelling in high-level reasoning, current language models lack\nrobustness in real-world scenarios and perform poorly on fundamental\nproblem-solving tasks that are intuitive to humans. This paper argues that both\nchallenges stem from a core discrepancy between human and machine cognitive\ndevelopment. While both systems rely on increasing representational power, the\nabsence of core knowledge-foundational cognitive structures in humans-prevents\nlanguage models from developing robust, generalizable abilities, where complex\nskills are grounded in simpler ones within their respective domains. It\nexplores empirical evidence of core knowledge in humans, analyzes why language\nmodels fail to acquire it, and argues that this limitation is not an inherent\narchitectural constraint. Finally, it outlines a workable proposal for\nsystematically integrating core knowledge into future multi-modal language\nmodels through the large-scale generation of synthetic training data using a\ncognitive prototyping strategy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10742v1",
    "published_date": "2025-02-15 09:47:20 UTC",
    "updated_date": "2025-02-15 09:47:20 UTC"
  },
  {
    "arxiv_id": "2502.12193v1",
    "title": "AI and the Law: Evaluating ChatGPT's Performance in Legal Classification",
    "authors": [
      "Pawel Weichbroth"
    ],
    "abstract": "The use of ChatGPT to analyze and classify evidence in criminal proceedings\nhas been a topic of ongoing discussion. However, to the best of our knowledge,\nthis issue has not been studied in the context of the Polish language. This\nstudy addresses this research gap by evaluating the effectiveness of ChatGPT in\nclassifying legal cases under the Polish Penal Code. The results show excellent\nbinary classification accuracy, with all positive and negative cases correctly\ncategorized. In addition, a qualitative evaluation confirms that the legal\nbasis provided for each case, along with the relevant legal content, was\nappropriate. The results obtained suggest that ChatGPT can effectively analyze\nand classify evidence while applying the appropriate legal rules. In\nconclusion, ChatGPT has the potential to assist interested parties in the\nanalysis of evidence and serve as a valuable legal resource for individuals\nwith less experience or knowledge in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages; 1 figure; 2 tables; 32 references",
    "pdf_url": "http://arxiv.org/pdf/2502.12193v1",
    "published_date": "2025-02-15 09:28:52 UTC",
    "updated_date": "2025-02-15 09:28:52 UTC"
  },
  {
    "arxiv_id": "2502.10732v1",
    "title": "Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision Optimization for Resource Allocation with Language Agents",
    "authors": [
      "Mauricio Tec",
      "Guojun Xiong",
      "Haichuan Wang",
      "Francesca Dominici",
      "Milind Tambe"
    ],
    "abstract": "Deep Reinforcement Learning (RL) is remarkably effective in addressing\nsequential resource allocation problems in domains such as healthcare, public\npolicy, and resource management. However, deep RL policies often lack\ntransparency and adaptability, challenging their deployment alongside human\ndecision-makers. In contrast, Language Agents, powered by large language models\n(LLMs), provide human-understandable reasoning but may struggle with effective\ndecision making. To bridge this gap, we propose Rule-Bottleneck Reinforcement\nLearning (RBRL), a novel framework that jointly optimizes decision and\nexplanations. At each step, RBRL generates candidate rules with an LLM, selects\namong them using an attention-based RL policy, and determines the environment\naction with an explanation via chain-of-thought reasoning. The RL rule\nselection is optimized using the environment rewards and an explainability\nmetric judged by the LLM. Evaluations in real-world scenarios highlight RBRL's\ncompetitive performance with deep RL and efficiency gains over LLM fine-tuning.\nA survey further confirms the enhanced quality of its explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10732v1",
    "published_date": "2025-02-15 09:01:31 UTC",
    "updated_date": "2025-02-15 09:01:31 UTC"
  },
  {
    "arxiv_id": "2502.10725v3",
    "title": "PropNet: a White-Box and Human-Like Network for Sentence Representation",
    "authors": [
      "Fei Yang"
    ],
    "abstract": "Transformer-based embedding methods have dominated the field of sentence\nrepresentation in recent years. Although they have achieved remarkable\nperformance on NLP missions, such as semantic textual similarity (STS) tasks,\ntheir black-box nature and large-data-driven training style have raised\nconcerns, including issues related to bias, trust, and safety. Many efforts\nhave been made to improve the interpretability of embedding models, but these\nproblems have not been fundamentally resolved. To achieve inherent\ninterpretability, we propose a purely white-box and human-like sentence\nrepresentation network, PropNet. Inspired by findings from cognitive science,\nPropNet constructs a hierarchical network based on the propositions contained\nin a sentence. While experiments indicate that PropNet has a significant gap\ncompared to state-of-the-art (SOTA) embedding models in STS tasks, case studies\nreveal substantial room for improvement. Additionally, PropNet enables us to\nanalyze and understand the human cognitive processes underlying STS benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Clarified some ambiguities in the previous version",
    "pdf_url": "http://arxiv.org/pdf/2502.10725v3",
    "published_date": "2025-02-15 08:28:58 UTC",
    "updated_date": "2025-05-14 08:07:08 UTC"
  },
  {
    "arxiv_id": "2502.10723v1",
    "title": "A Mathematics Framework of Artificial Shifted Population Risk and Its Further Understanding Related to Consistency Regularization",
    "authors": [
      "Xiliang Yang",
      "Shenyang Deng",
      "Shicong Liu",
      "Yuanchi Suo",
      "Wing. W. Y NG",
      "Jianjun Zhang"
    ],
    "abstract": "Data augmentation is an important technique in training deep neural networks\nas it enhances their ability to generalize and remain robust. While data\naugmentation is commonly used to expand the sample size and act as a\nconsistency regularization term, there is a lack of research on the\nrelationship between them. To address this gap, this paper introduces a more\ncomprehensive mathematical framework for data augmentation. Through this\nframework, we establish that the expected risk of the shifted population is the\nsum of the original population risk and a gap term, which can be interpreted as\na consistency regularization term. The paper also provides a theoretical\nunderstanding of this gap, highlighting its negative effects on the early\nstages of training. We also propose a method to mitigate these effects. To\nvalidate our approach, we conducted experiments using same data augmentation\ntechniques and computing resources under several scenarios, including standard\ntraining, out-of-distribution, and imbalanced classification. The results\ndemonstrate that our methods surpass compared methods under all scenarios in\nterms of generalization ability and convergence stability. We provide our code\nimplementation at the following link: https://github.com/ydlsfhll/ASPR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10723v1",
    "published_date": "2025-02-15 08:26:49 UTC",
    "updated_date": "2025-02-15 08:26:49 UTC"
  },
  {
    "arxiv_id": "2502.12189v1",
    "title": "Self-supervised Attribute-aware Dynamic Preference Ranking Alignment",
    "authors": [
      "Hongyu Yang",
      "Qi Zhao",
      "Zhenhua hu",
      "Rui Li"
    ],
    "abstract": "Reinforcement Learning from Human Feedback and its variants excel in aligning\nwith human intentions to generate helpful, harmless, and honest responses.\nHowever, most of them rely on costly human-annotated pairwise comparisons for\nsupervised alignment, which is not suitable for list-level scenarios, such as\ncommunity question answering. Additionally, human preferences are influenced by\nmultiple intrinsic factors in responses, leading to decision-making\ninconsistencies. Therefore, we propose \\textbf{Se}lf-supervised\n\\textbf{A}ttribute-aware \\textbf{d}ynamic \\textbf{p}reference \\textbf{ra}nking,\ncalled \\shortname. \\ It quantifies preference differences between responses\nbased on Attribute-Perceptual Distance Factors (APDF) and dynamically\ndetermines the list-wise alignment order. Furthermore, it achieves fine-grained\npreference difference learning and enables precise alignment with the optimal\none. We specifically constructed a challenging code preference dataset named\nStaCoCoQA, and introduced more cost-effective and scalable preference\nevaluation metrics: PrefHit and PrefRecall. Extensive experimental results show\nthat SeAdpra exhibits superior performance and generalizability on both\nStaCoCoQA and preference datasets from eight popular domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12189v1",
    "published_date": "2025-02-15 08:20:42 UTC",
    "updated_date": "2025-02-15 08:20:42 UTC"
  },
  {
    "arxiv_id": "2502.10718v1",
    "title": "Hyperdimensional Intelligent Sensing for Efficient Real-Time Audio Processing on Extreme Edge",
    "authors": [
      "Sanggeon Yun",
      "Ryozo Masukawa",
      "Hanning Chen",
      "SungHeon Jeong",
      "Wenjun Huang",
      "Arghavan Rezvani",
      "Minhyoung Na",
      "Yoshiki Yamaguchi",
      "Mohsen Imani"
    ],
    "abstract": "The escalating challenges of managing vast sensor-generated data,\nparticularly in audio applications, necessitate innovative solutions. Current\nsystems face significant computational and storage demands, especially in\nreal-time applications like gunshot detection systems (GSDS), and the\nproliferation of edge sensors exacerbates these issues. This paper proposes a\ngroundbreaking approach with a near-sensor model tailored for intelligent\naudio-sensing frameworks. Utilizing a Fast Fourier Transform (FFT) module,\nconvolutional neural network (CNN) layers, and HyperDimensional Computing\n(HDC), our model excels in low-energy, rapid inference, and online learning. It\nis highly adaptable for efficient ASIC design implementation, offering superior\nenergy efficiency compared to conventional embedded CPUs or GPUs, and is\ncompatible with the trend of shrinking microphone sensor sizes. Comprehensive\nevaluations at both software and hardware levels underscore the model's\nefficacy. Software assessments through detailed ROC curve analysis revealed a\ndelicate balance between energy conservation and quality loss, achieving up to\n82.1% energy savings with only 1.39% quality loss. Hardware evaluations\nhighlight the model's commendable energy efficiency when implemented via ASIC\ndesign, especially with the Google Edge TPU, showcasing its superiority over\nprevalent embedded CPUs and GPUs.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2502.10718v1",
    "published_date": "2025-02-15 08:19:20 UTC",
    "updated_date": "2025-02-15 08:19:20 UTC"
  },
  {
    "arxiv_id": "2502.12188v1",
    "title": "Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling",
    "authors": [
      "Haoyu Lei",
      "Kaiwen Zhou",
      "Yinchuan Li",
      "Zhitang Chen",
      "Farzan Farnia"
    ],
    "abstract": "Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated\neffectiveness in solving NP-complete (NPC) problems by learning discrete\ndiffusion models for solution generation, eliminating hand-crafted domain\nknowledge. Despite their success, existing NCO methods face significant\nchallenges in both cross-scale and cross-problem generalization, and high\ntraining costs compared to traditional solvers. While recent studies have\nintroduced training-free guidance approaches that leverage pre-defined guidance\nfunctions for zero-shot conditional generation, such methodologies have not\nbeen extensively explored in combinatorial optimization. To bridge this gap, we\npropose a general energy-guided sampling framework during inference time that\nenhances both the cross-scale and cross-problem generalization capabilities of\ndiffusion-based NCO solvers without requiring additional training. We provide\ntheoretical analysis that helps understanding the cross-problem transfer\ncapability. Our experimental results demonstrate that a diffusion solver,\ntrained exclusively on the Traveling Salesman Problem (TSP), can achieve\ncompetitive zero-shot solution generation on TSP variants, such as Prize\nCollecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided\nsampling across different problem scales.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12188v1",
    "published_date": "2025-02-15 08:04:00 UTC",
    "updated_date": "2025-02-15 08:04:00 UTC"
  },
  {
    "arxiv_id": "2502.10712v2",
    "title": "FuncGenFoil: Airfoil Generation and Editing Model in Function Space",
    "authors": [
      "Jinouwen Zhang",
      "Junjie Ren",
      "Aobo Yang",
      "Yan Lu",
      "Lu Chen",
      "Hairun Xie",
      "Jing Wang",
      "Miao Zhang",
      "Wanli Ouyang",
      "Shixiang Tang"
    ],
    "abstract": "Aircraft manufacturing is the jewel in the crown of industry, among which\ngenerating high-fidelity airfoil geometries with controllable and editable\nrepresentations remains a fundamental challenge. While existing\ndeep-learning-based methods rely on predefined parametric function families,\ne.g., B\\'ezier curves and discrete point-based representations, they suffer\nfrom inherent trade-offs between expressiveness and resolution flexibility. To\ntackle this challenge, we introduce FuncGenFoil, a novel function-space\ngenerative model that directly learns functional airfoil geometries. Our method\ninherits both the advantages of arbitrary resolution sampling and the\nsmoothness of parametric functions, as well as the strong expressiveness of\ndiscrete point-based functions. Empirical evaluations on the AFBench dataset\ndemonstrate that FuncGenFoil improves upon state-of-the-art methods in airfoil\ngeneration by achieving a relative -74.4 label error reduction and +23.2\ndiversity increase on the AF-200K dataset. Our results highlight the advantages\nof function-space modeling for aerodynamic shape optimization, offering a\npowerful and flexible framework for high-fidelity airfoil design. Our code will\nbe released.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10712v2",
    "published_date": "2025-02-15 07:56:58 UTC",
    "updated_date": "2025-04-29 13:18:11 UTC"
  },
  {
    "arxiv_id": "2502.10709v2",
    "title": "An Empirical Analysis of Uncertainty in Large Language Model Evaluations",
    "authors": [
      "Qiujie Xie",
      "Qingqiu Li",
      "Zhuohao Yu",
      "Yuejie Zhang",
      "Yue Zhang",
      "Linyi Yang"
    ],
    "abstract": "As LLM-as-a-Judge emerges as a new paradigm for assessing large language\nmodels (LLMs), concerns have been raised regarding the alignment, bias, and\nstability of LLM evaluators. While substantial work has focused on alignment\nand bias, little research has concentrated on the stability of LLM evaluators.\nIn this paper, we conduct extensive experiments involving 9 widely used LLM\nevaluators across 2 different evaluation settings to investigate the\nuncertainty in model-based LLM evaluations. We pinpoint that LLM evaluators\nexhibit varying uncertainty based on model families and sizes. With careful\ncomparative analyses, we find that employing special prompting strategies,\nwhether during inference or post-training, can alleviate evaluation uncertainty\nto some extent. By utilizing uncertainty to enhance LLM's reliability and\ndetection capability in Out-Of-Distribution (OOD) data, we further fine-tune an\nuncertainty-aware LLM evaluator named ConfiLM using a human-annotated\nfine-tuning set and assess ConfiLM's OOD evaluation ability on a manually\ndesigned test set sourced from the 2024 Olympics. Experimental results\ndemonstrate that incorporating uncertainty as additional information during the\nfine-tuning phase can largely improve the model's evaluation performance in OOD\nscenarios. The code and data are released at:\nhttps://github.com/hasakiXie123/LLM-Evaluator-Uncertainty.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10709v2",
    "published_date": "2025-02-15 07:45:20 UTC",
    "updated_date": "2025-03-02 04:37:08 UTC"
  },
  {
    "arxiv_id": "2502.10707v1",
    "title": "Reading Your Heart: Learning ECG Words and Sentences via Pre-training ECG Language Model",
    "authors": [
      "Jiarui Jin",
      "Haoyu Wang",
      "Hongyan Li",
      "Jun Li",
      "Jiahui Pan",
      "Shenda Hong"
    ],
    "abstract": "Electrocardiogram (ECG) is essential for the clinical diagnosis of\narrhythmias and other heart diseases, but deep learning methods based on ECG\noften face limitations due to the need for high-quality annotations. Although\nprevious ECG self-supervised learning (eSSL) methods have made significant\nprogress in representation learning from unannotated ECG data, they typically\ntreat ECG signals as ordinary time-series data, segmenting the signals using\nfixed-size and fixed-step time windows, which often ignore the form and rhythm\ncharacteristics and latent semantic relationships in ECG signals. In this work,\nwe introduce a novel perspective on ECG signals, treating heartbeats as words\nand rhythms as sentences. Based on this perspective, we first designed the\nQRS-Tokenizer, which generates semantically meaningful ECG sentences from the\nraw ECG signals. Building on these, we then propose HeartLang, a novel\nself-supervised learning framework for ECG language processing, learning\ngeneral representations at form and rhythm levels. Additionally, we construct\nthe largest heartbeat-based ECG vocabulary to date, which will further advance\nthe development of ECG language processing. We evaluated HeartLang across six\npublic ECG datasets, where it demonstrated robust competitiveness against other\neSSL methods. Our data and code are publicly available at\nhttps://github.com/PKUDigitalHealth/HeartLang.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 8 figures, accepted by International Conference on Learning\n  Representations 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10707v1",
    "published_date": "2025-02-15 07:40:57 UTC",
    "updated_date": "2025-02-15 07:40:57 UTC"
  },
  {
    "arxiv_id": "2502.10706v2",
    "title": "Raising the Bar in Graph OOD Generalization: Invariant Learning Beyond Explicit Environment Modeling",
    "authors": [
      "Xu Shen",
      "Yixin Liu",
      "Yili Wang",
      "Rui Miao",
      "Yiwei Dai",
      "Shirui Pan",
      "Xin Wang"
    ],
    "abstract": "Out-of-distribution (OOD) generalization has emerged as a critical challenge\nin graph learning, as real-world graph data often exhibit diverse and shifting\nenvironments that traditional models fail to generalize across. A promising\nsolution to address this issue is graph invariant learning (GIL), which aims to\nlearn invariant representations by disentangling label-correlated invariant\nsubgraphs from environment-specific subgraphs. However, existing GIL methods\nface two major challenges: (1) the difficulty of capturing and modeling diverse\nenvironments in graph data, and (2) the semantic cliff, where invariant\nsubgraphs from different classes are difficult to distinguish, leading to poor\nclass separability and increased misclassifications. To tackle these\nchallenges, we propose a novel method termed Multi-Prototype Hyperspherical\nInvariant Learning (MPHIL), which introduces two key innovations: (1)\nhyperspherical invariant representation extraction, enabling robust and highly\ndiscriminative hyperspherical invariant feature extraction, and (2)\nmulti-prototype hyperspherical classification, which employs class prototypes\nas intermediate variables to eliminate the need for explicit environment\nmodeling in GIL and mitigate the semantic cliff issue. Derived from the\ntheoretical framework of GIL, we introduce two novel objective functions: the\ninvariant prototype matching loss to ensure samples are matched to the correct\nclass prototypes, and the prototype separation loss to increase the distinction\nbetween prototypes of different classes in the hyperspherical space. Extensive\nexperiments on 11 OOD generalization benchmark datasets demonstrate that MPHIL\nachieves state-of-the-art performance, significantly outperforming existing\nmethods across graph data from various domains and with different distribution\nshifts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10706v2",
    "published_date": "2025-02-15 07:40:14 UTC",
    "updated_date": "2025-02-19 02:41:12 UTC"
  },
  {
    "arxiv_id": "2502.10705v1",
    "title": "CoPEFT: Fast Adaptation Framework for Multi-Agent Collaborative Perception with Parameter-Efficient Fine-Tuning",
    "authors": [
      "Quanmin Wei",
      "Penglin Dai",
      "Wei Li",
      "Bingyi Liu",
      "Xiao Wu"
    ],
    "abstract": "Multi-agent collaborative perception is expected to significantly improve\nperception performance by overcoming the limitations of single-agent perception\nthrough exchanging complementary information. However, training a robust\ncollaborative perception model requires collecting sufficient training data\nthat covers all possible collaboration scenarios, which is impractical due to\nintolerable deployment costs. Hence, the trained model is not robust against\nnew traffic scenarios with inconsistent data distribution and fundamentally\nrestricts its real-world applicability. Further, existing methods, such as\ndomain adaptation, have mitigated this issue by exposing the deployment data\nduring the training stage but incur a high training cost, which is infeasible\nfor resource-constrained agents. In this paper, we propose a\nParameter-Efficient Fine-Tuning-based lightweight framework, CoPEFT, for fast\nadapting a trained collaborative perception model to new deployment\nenvironments under low-cost conditions. CoPEFT develops a Collaboration Adapter\nand Agent Prompt to perform macro-level and micro-level adaptations separately.\nSpecifically, the Collaboration Adapter utilizes the inherent knowledge from\ntraining data and limited deployment data to adapt the feature map to new data\ndistribution. The Agent Prompt further enhances the Collaboration Adapter by\ninserting fine-grained contextual information about the environment. Extensive\nexperiments demonstrate that our CoPEFT surpasses existing methods with less\nthan 1\\% trainable parameters, proving the effectiveness and efficiency of our\nproposed method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2502.10705v1",
    "published_date": "2025-02-15 07:33:33 UTC",
    "updated_date": "2025-02-15 07:33:33 UTC"
  },
  {
    "arxiv_id": "2502.10704v1",
    "title": "Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy",
    "authors": [
      "Mingyang Zhao",
      "Gaofeng Meng",
      "Dong-Ming Yan"
    ],
    "abstract": "Non-rigid alignment of point clouds is crucial for scene understanding,\nreconstruction, and various computer vision and robotics tasks. Recent\nadvancements in implicit deformation networks for non-rigid registration have\nsignificantly reduced the reliance on large amounts of annotated training data.\nHowever, existing state-of-the-art methods still face challenges in handling\nocclusion scenarios. To address this issue, this paper introduces an innovative\nunsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly\naligning point clouds. The key innovation of our method lies in the utilization\nof the adaptive correntropy function as a localized similarity measure,\nenabling us to treat individual points distinctly. In contrast to previous\napproaches that solely minimize overall deviations between two shapes, we\ncombine unsupervised implicit neural representations with the maximum\ncorrentropy criterion to optimize the deformation of unoccluded regions. This\neffectively avoids collapsed, tearing, and other physically implausible\nresults. Moreover, we present a theoretical analysis and establish the\nrelationship between the maximum correntropy criterion and the commonly used\nChamfer distance, highlighting that the correntropy-induced metric can be\nserved as a more universal measure for point cloud analysis. Additionally, we\nintroduce locally linear reconstruction to ensure that regions lacking\ncorrespondences between shapes still undergo physically natural deformations.\nOur method achieves superior or competitive performance compared to existing\napproaches, particularly when dealing with occluded geometries. We also\ndemonstrate the versatility of our method in challenging tasks such as large\ndeformations, shape interpolation, and shape completion under occlusion\ndisturbances.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "[ICLR 2025] Project and code at: https://github.com/zikai1/OAReg",
    "pdf_url": "http://arxiv.org/pdf/2502.10704v1",
    "published_date": "2025-02-15 07:27:15 UTC",
    "updated_date": "2025-02-15 07:27:15 UTC"
  },
  {
    "arxiv_id": "2502.10699v1",
    "title": "Exploring Synaptic Resonance in Large Language Models: A Novel Approach to Contextual Memory Integration",
    "authors": [
      "George Applegarth",
      "Christian Weatherstone",
      "Maximilian Hollingsworth",
      "Henry Middlebrook",
      "Marcus Irvin"
    ],
    "abstract": "Contextual memory integration remains a high challenge in the development of\nlanguage models, particularly in tasks that require maintaining coherence over\nextended sequences. Traditional approaches, such as self-attention mechanisms\nand memory-augmented architectures, often prioritize short-term dependencies,\nleading to fragmentation and inconsistency in long-range contextual\nunderstanding. Inspired by principles of synaptic plasticity observed in\nbiological neural systems, a novel mechanism, Synaptic Resonance, is introduced\nto dynamically reinforce relevant memory pathways during training and\ninference. Unlike static memory representations, this mechanism continuously\nadjusts synaptic weight matrices based on contextual relevance, allowing for\nimproved information retention without excessive computational overhead.\nEvaluations conducted on an open-source language model demonstrate reductions\nin perplexity, enhancements in contextual coherence, and increased robustness\nagainst input noise, highlighting the effectiveness of reinforcement-driven\nmemory modulation. Comparative analysis against baseline models further reveals\nthat the proposed approach achieves higher memory retention efficiency while\nmaintaining computational feasibility. The architectural modifications\nintegrate seamlessly into existing transformer-based frameworks, ensuring\nstable convergence and efficient inference without sacrificing scalability.\nApplications benefiting from improved long-term contextual consistency, such as\ndialogue systems and document summarization, stand to gain from this approach.\nEmpirical findings suggest that dynamically reinforced memory pathways offer a\npromising alternative to conventional memory mechanisms, addressing\nlongstanding limitations in extended sequence modeling.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10699v1",
    "published_date": "2025-02-15 07:06:10 UTC",
    "updated_date": "2025-02-15 07:06:10 UTC"
  },
  {
    "arxiv_id": "2502.10698v1",
    "title": "Superpose Singular Features for Model Merging",
    "authors": [
      "Haiquan Qiu",
      "You Wu",
      "Quanming Yao"
    ],
    "abstract": "Model merging is a critical technique for combining the capabilities of\nmultiple fine-tuned models without requiring additional training. While\nexisting methods treat parameters as vectors, they overlook the intrinsic\nstructure of linear transformation matrices - the core components that comprise\nthe majority of model parameters. These matrices are fundamental to neural\nnetworks, mapping input representations to output features through linear\ncombinations. Motivated by the linear representation hypothesis, we introduce\ntask matrix and propose to Superpose Features from Task Matrix (SFTM), a novel\napproach that superposes features from individual task models into a merged\nmodel. SFTM employs singular value decomposition to identify feature bases of\nlinear transformation matrices and solves a linear system to optimally combine\nthem while preserving input-output mappings from individual task models.\nExtensive experiments on vision transformers and language models demonstrate\nthat our method consistently outperforms existing methods, achieving superior\nperformance and enhanced out-of-distribution generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10698v1",
    "published_date": "2025-02-15 07:05:55 UTC",
    "updated_date": "2025-02-15 07:05:55 UTC"
  },
  {
    "arxiv_id": "2502.10694v1",
    "title": "Simulations of Common Unsupervised Domain Adaptation Algorithms for Image Classification",
    "authors": [
      "Ahmad Chaddad",
      "Yihang Wu",
      "Yuchen Jiang",
      "Ahmed Bouridane",
      "Christian Desrosiers"
    ],
    "abstract": "Traditional machine learning assumes that training and test sets are derived\nfrom the same distribution; however, this assumption does not always hold in\npractical applications. This distribution disparity can lead to severe\nperformance drops when the trained model is used in new data sets. Domain\nadaptation (DA) is a machine learning technique that aims to address this\nproblem by reducing the differences between domains. This paper presents\nsimulation-based algorithms of recent DA techniques, mainly related to\nunsupervised domain adaptation (UDA), where labels are available only in the\nsource domain. Our study compares these techniques with public data sets and\ndiverse characteristics, highlighting their respective strengths and drawbacks.\nFor example, Safe Self-Refinement for Transformer-based DA (SSRT) achieved the\nhighest accuracy (91.6\\%) in the office-31 data set during our simulations,\nhowever, the accuracy dropped to 72.4\\% in the Office-Home data set when using\nlimited batch sizes. In addition to improving the reader's comprehension of\nrecent techniques in DA, our study also highlights challenges and upcoming\ndirections for research in this domain. The codes are available at\nhttps://github.com/AIPMLab/Domain_Adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE TIM",
    "pdf_url": "http://arxiv.org/pdf/2502.10694v1",
    "published_date": "2025-02-15 06:58:57 UTC",
    "updated_date": "2025-02-15 06:58:57 UTC"
  },
  {
    "arxiv_id": "2502.10689v2",
    "title": "Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction",
    "authors": [
      "Leisheng Yu",
      "Yanxiao Cai",
      "Minxing Zhang",
      "Xia Hu"
    ],
    "abstract": "The burgeoning volume of electronic health records (EHRs) has enabled deep\nlearning models to excel in predictive healthcare. However, for high-stakes\napplications such as diagnosis prediction, model interpretability remains\nparamount. Existing deep learning diagnosis prediction models with intrinsic\ninterpretability often assign attention weights to every past diagnosis or\nhospital visit, providing explanations lacking flexibility and succinctness. In\nthis paper, we introduce SHy, a self-explaining hypergraph neural network\nmodel, designed to offer personalized, concise and faithful explanations that\nallow for interventions from clinical experts. By modeling each patient as a\nunique hypergraph and employing a message-passing mechanism, SHy captures\nhigher-order disease interactions and extracts distinct temporal phenotypes as\npersonalized explanations. It also addresses the incompleteness of the EHR data\nby accounting for essential false negatives in the original diagnosis record. A\nqualitative case study and extensive quantitative evaluations on two real-world\nEHR datasets demonstrate the superior predictive performance and\ninterpretability of SHy over existing state-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10689v2",
    "published_date": "2025-02-15 06:33:02 UTC",
    "updated_date": "2025-05-01 03:27:16 UTC"
  },
  {
    "arxiv_id": "2502.10678v1",
    "title": "GenComUI: Exploring Generative Visual Aids as Medium to Support Task-Oriented Human-Robot Communication",
    "authors": [
      "Yate Ge",
      "Meiying Li",
      "Xipeng Huang",
      "Yuanda Hu",
      "Qi Wang",
      "Xiaohua Sun",
      "Weiwei Guo"
    ],
    "abstract": "This work investigates the integration of generative visual aids in\nhuman-robot task communication. We developed GenComUI, a system powered by\nlarge language models that dynamically generates contextual visual aids (such\nas map annotations, path indicators, and animations) to support verbal task\ncommunication and facilitate the generation of customized task programs for the\nrobot. This system was informed by a formative study that examined how humans\nuse external visual tools to assist verbal communication in spatial tasks. To\nevaluate its effectiveness, we conducted a user experiment (n = 20) comparing\nGenComUI with a voice-only baseline. The results demonstrate that generative\nvisual aids, through both qualitative and quantitative analysis, enhance verbal\ntask communication by providing continuous visual feedback, thus promoting\nnatural and effective human-robot communication. Additionally, the study offers\na set of design implications, emphasizing how dynamically generated visual aids\ncan serve as an effective communication medium in human-robot interaction.\nThese findings underscore the potential of generative visual aids to inform the\ndesign of more intuitive and effective human-robot communication, particularly\nfor complex communication scenarios in human-robot interaction and LLM-based\nend-user development.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO",
      "H.5.2; H.5.3; I.2.7; I.2.0"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear at ACM CHI '25",
    "pdf_url": "http://arxiv.org/pdf/2502.10678v1",
    "published_date": "2025-02-15 05:31:37 UTC",
    "updated_date": "2025-02-15 05:31:37 UTC"
  },
  {
    "arxiv_id": "2502.12186v1",
    "title": "E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor Ligand Activity Prediction",
    "authors": [
      "Jiacheng Xie",
      "Yingrui Ji",
      "Linghuan Zeng",
      "Xi Xiao",
      "Gaofei Chen",
      "Lijing Zhu",
      "Joyanta Jyoti Mondal",
      "Jiansheng Chen"
    ],
    "abstract": "Accurate prediction of CB2 receptor ligand activity is pivotal for advancing\ndrug discovery targeting this receptor, which is implicated in inflammation,\npain management, and neurodegenerative conditions. Although conventional\nmachine learning and deep learning techniques have shown promise, their limited\ninterpretability remains a significant barrier to rational drug design. In this\nwork, we introduce CB2former, a framework that combines a Graph Convolutional\nNetwork with a Transformer architecture to predict CB2 receptor ligand\nactivity. By leveraging the Transformer's self attention mechanism alongside\nthe GCN's structural learning capability, CB2former not only enhances\npredictive performance but also offers insights into the molecular features\nunderlying receptor activity. We benchmark CB2former against diverse baseline\nmodels including Random Forest, Support Vector Machine, K Nearest Neighbors,\nGradient Boosting, Extreme Gradient Boosting, Multilayer Perceptron,\nConvolutional Neural Network, and Recurrent Neural Network and demonstrate its\nsuperior performance with an R squared of 0.685, an RMSE of 0.675, and an AUC\nof 0.940. Moreover, attention weight analysis reveals key molecular\nsubstructures influencing CB2 receptor activity, underscoring the model's\npotential as an interpretable AI tool for drug discovery. This ability to\npinpoint critical molecular motifs can streamline virtual screening, guide lead\noptimization, and expedite therapeutic development. Overall, our results\nshowcase the transformative potential of advanced AI approaches exemplified by\nCB2former in delivering both accurate predictions and actionable molecular\ninsights, thus fostering interdisciplinary collaboration and innovation in drug\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12186v1",
    "published_date": "2025-02-15 05:05:49 UTC",
    "updated_date": "2025-02-15 05:05:49 UTC"
  },
  {
    "arxiv_id": "2502.12185v1",
    "title": "Large Language Models for Extrapolative Modeling of Manufacturing Processes",
    "authors": [
      "Kiarash Naghavi Khanghah",
      "Anandkumar Patel",
      "Rajiv Malhotra",
      "Hongyi Xu"
    ],
    "abstract": "Conventional predictive modeling of parametric relationships in manufacturing\nprocesses is limited by the subjectivity of human expertise and intuition on\nthe one hand and by the cost and time of experimental data generation on the\nother hand. This work addresses this issue by establishing a new Large Language\nModel (LLM) framework. The novelty lies in combining automatic extraction of\nprocess-relevant knowledge embedded in the literature with iterative model\nrefinement based on a small amount of experimental data. This approach is\nevaluated on three distinct manufacturing processes that are based on\nmachining, deformation, and additive principles. The results show that for the\nsame small experimental data budget the models derived by our framework have\nunexpectedly high extrapolative performance, often surpassing the capabilities\nof conventional Machine Learning. Further, our approach eliminates manual\ngeneration of initial models or expertise-dependent interpretation of the\nliterature. The results also reveal the importance of the nature of the\nknowledge extracted from the literature and the significance of both the\nknowledge extraction and model refinement components.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.12185v1",
    "published_date": "2025-02-15 02:43:22 UTC",
    "updated_date": "2025-02-15 02:43:22 UTC"
  },
  {
    "arxiv_id": "2502.10642v1",
    "title": "Demographic User Modeling for Social Robotics with Multimodal Pre-trained Models",
    "authors": [
      "Hamed Rahimi",
      "Mouad Abrini",
      "Mahdi Khoramshahi",
      "Mohamed Chetouani"
    ],
    "abstract": "This paper investigates the performance of multimodal pre-trained models in\nuser profiling tasks based on visual-linguistic demographic data. These models\nare critical for adapting to the needs and preferences of human users in social\nrobotics, thereby providing personalized responses and enhancing interaction\nquality. First, we introduce two datasets specifically curated to represent\ndemographic characteristics derived from user facial images. Next, we evaluate\nthe performance of a prominent contrastive multimodal pre-trained model, CLIP,\non these datasets, both in its out-of-the-box state and after fine-tuning.\nInitial results indicate that CLIP performs suboptimal in matching images to\ndemographic descriptions without fine-tuning. Although fine-tuning\nsignificantly enhances its predictive capacity, the model continues to exhibit\nlimitations in effectively generalizing subtle demographic nuances. To address\nthis, we propose adopting a masked image modeling strategy to improve\ngeneralization and better capture subtle demographic attributes. This approach\noffers a pathway for enhancing demographic sensitivity in multimodal user\nmodeling tasks.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10642v1",
    "published_date": "2025-02-15 02:38:58 UTC",
    "updated_date": "2025-02-15 02:38:58 UTC"
  },
  {
    "arxiv_id": "2502.10637v1",
    "title": "Proof of Response",
    "authors": [
      "Illia Polosukhin",
      "Alex Skidanov"
    ],
    "abstract": "We present a mechanism that for a network of participants allows one\nparticipant of the network (Alice) to request some data from another\nparticipant (Bob) and either receive a response from Bob within a\nknown-in-advance, bounded time b, or receive a proof that at least one edge on\nthe way to Bob was broken within b, or receive a streaming payment proportional\nto time passed beyond b during which neither was received. This mechanism\nallows for building downstream applications that require provable responses\nfrom other participants, such as decentralized storage solutions, decentralized\nAI agents, and more.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10637v1",
    "published_date": "2025-02-15 02:25:57 UTC",
    "updated_date": "2025-02-15 02:25:57 UTC"
  },
  {
    "arxiv_id": "2502.10636v2",
    "title": "USER-VLM 360: Personalized Vision Language Models with User-aware Tuning for Social Human-Robot Interactions",
    "authors": [
      "Hamed Rahimi",
      "Adil Bahaj",
      "Mouad Abrini",
      "Mahdi Khoramshahi",
      "Mounir Ghogho",
      "Mohamed Chetouani"
    ],
    "abstract": "The integration of vision-language models into robotic systems constitutes a\nsignificant advancement in enabling machines to interact with their\nsurroundings in a more intuitive manner. While VLMs offer rich multimodal\nreasoning, existing approaches lack user-specific adaptability, often relying\non generic interaction paradigms that fail to account for individual\nbehavioral, contextual, or socio-emotional nuances. When customization is\nattempted, ethical concerns arise from unmitigated biases in user data, risking\nexclusion or unfair treatment. To address these dual challenges, we propose\nUser-VLM 360{\\deg}, a holistic framework integrating multimodal user modeling\nwith bias-aware optimization. Our approach features: (1) user-aware tuning that\nadapts interactions in real time using visual-linguistic signals; (2) bias\nmitigation via preference optimization; and (3) curated 360{\\deg} socio-emotive\ninteraction datasets annotated with demographic, emotion, and relational\nmetadata. Evaluations across eight benchmarks demonstrate state-of-the-art\nresults: +35.3% F1 in personalized VQA, +47.5% F1 in facial features\nunderstanding, 15% bias reduction, and 30X speedup over baselines. Ablation\nstudies confirm component efficacy, and deployment on the Pepper robot\nvalidates real-time adaptability across diverse users. We open-source\nparameter-efficient 3B/10B models and an ethical verification framework for\nresponsible adaptation.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10636v2",
    "published_date": "2025-02-15 02:25:49 UTC",
    "updated_date": "2025-02-28 09:38:19 UTC"
  },
  {
    "arxiv_id": "2502.10631v1",
    "title": "ControllableGPT: A Ground-Up Designed Controllable GPT for Molecule Optimization",
    "authors": [
      "Xuefeng Liu",
      "Songhao Jiang",
      "Bo Li",
      "Rick Stevens"
    ],
    "abstract": "Large Language Models (LLMs) employ three popular training approaches: Masked\nLanguage Models (MLM), Causal Language Models (CLM), and Sequence-to-Sequence\nModels (seq2seq). However, each approach has its strengths and limitations, and\nfaces challenges in addressing specific tasks that require controllable and\nbidirectional generation, such as drug optimization. To address this challenge,\ninspired by the biological processes of growth and evolution, which involve the\nexpansion, shrinking, and mutation of sequences, we introduce ControllableGPT.\nThis initiative represents the first effort to combine the advantages of MLM,\nCLM, and seq2seq into a single unified, controllable GPT framework. It enables\nthe precise management of specific locations and ranges within a sequence,\nallowing for expansion, reduction, or mutation over chosen or random lengths,\nwhile maintaining the integrity of any specified positions or subsequences. In\nthis work, we designed ControllableGPT for drug optimization from the ground\nup, which included proposing the Causally Masked Seq2seq (CMS) objective,\ndeveloping the training corpus, introducing a novel pre-training approach, and\ndevising a unique generation process. We demonstrate the effectiveness and\ncontrollability of ControllableGPT by conducting experiments on drug\noptimization tasks for both viral and cancer benchmarks, surpassing competing\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10631v1",
    "published_date": "2025-02-15 01:49:35 UTC",
    "updated_date": "2025-02-15 01:49:35 UTC"
  },
  {
    "arxiv_id": "2502.10626v2",
    "title": "K-Edit: Language Model Editing with Contextual Knowledge Awareness",
    "authors": [
      "Elan Markowitz",
      "Anil Ramakrishna",
      "Ninareh Mehrabi",
      "Charith Peris",
      "Rahul Gupta",
      "Kai-Wei Chang",
      "Aram Galstyan"
    ],
    "abstract": "As the world changes, we need to be able to update our models and correct\nfalse information without costly retraining. Knowledge-based model editing\nenables precise modifications to the weights of large language models in order\nto modify the information encoded within. Recent approaches have seen success\nin enabling recall of edited information for thousands of edits at once.\nHowever, these approaches fail to produce edits that account for associated\ncontextual information. We present K-Edit, an effective approach to generating\ncontextually consistent knowledge edits. By using knowledge graphs, which\nmaintain contextual consistency when an edge is edited, we are able to generate\nadditional \\textit{contextual edits} that ensure consistency of related\ninformation in the language model. Our experiments demonstrate significant\nimprovements in multi-hop question answering while maintaining the general\neffectiveness and scalability of model edits.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10626v2",
    "published_date": "2025-02-15 01:35:13 UTC",
    "updated_date": "2025-02-27 06:59:27 UTC"
  },
  {
    "arxiv_id": "2502.10624v1",
    "title": "Network evasion detection with Bi-LSTM model",
    "authors": [
      "Kehua Chen",
      "Jingping Jia"
    ],
    "abstract": "Network evasion detection aims to distinguish whether the network flow comes\nfrom link layer exists network evasion threat, which is a means to disguise the\ndata traffic on detection system by confusing the signature. Since the previous\nresearch works has all sorts of frauds, we propose a architecture with deep\nlearning network to handle this problem. In this paper, we extract the critical\ninformation as key features from data frame and also specifically propose to\nuse bidirectional long short-term memory (Bi-LSTM) neural network which shows\nan outstanding performance to trace the serial information, to encode both the\npast and future trait on the network flows. Furthermore we introduce a\nclassifier named Softmax at the bottom of Bi-LSTM, holding a character to\nselect the correct class. All experiments results shows that we can achieve a\nsignificant performance with a deep Bi-LSTM in network evasion detection and\nit's average accuracy reaches 96.1%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "4 pages,5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10624v1",
    "published_date": "2025-02-15 01:25:13 UTC",
    "updated_date": "2025-02-15 01:25:13 UTC"
  },
  {
    "arxiv_id": "2502.10620v1",
    "title": "ProMRVL-CAD: Proactive Dialogue System with Multi-Round Vision-Language Interactions for Computer-Aided Diagnosis",
    "authors": [
      "Xueshen Li",
      "Xinlong Hou",
      "Ziyi Huang",
      "Yu Gan"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nextraordinary comprehension capabilities with remarkable breakthroughs on\nvarious vision-language tasks. However, the application of LLMs in generating\nreliable medical diagnostic reports remains in the early stages. Currently,\nmedical LLMs typically feature a passive interaction model where doctors\nrespond to patient queries with little or no involvement in analyzing medical\nimages. In contrast, some ChatBots simply respond to predefined queries based\non visual inputs, lacking interactive dialogue or consideration of medical\nhistory. As such, there is a gap between LLM-generated patient-ChatBot\ninteractions and those occurring in actual patient-doctor consultations. To\nbridge this gap, we develop an LLM-based dialogue system, namely proactive\nmulti-round vision-language interactions for computer-aided diagnosis\n(ProMRVL-CAD), to generate patient-friendly disease diagnostic reports. The\nproposed ProMRVL-CAD system allows proactive dialogue to provide patients with\nconstant and reliable medical access via an integration of knowledge graph into\na recommendation system. Specifically, we devise two generators: a Proactive\nQuestion Generator (Pro-Q Gen) to generate proactive questions that guide the\ndiagnostic procedure and a Multi-Vision Patient-Text Diagnostic Report\nGenerator (MVP-DR Gen) to produce high-quality diagnostic reports. Evaluating\ntwo real-world publicly available datasets, MIMIC-CXR and IU-Xray, our model\nhas better quality in generating medical reports. We further demonstrate the\nperformance of ProMRVL achieves robust under the scenarios with low image\nquality. Moreover, we have created a synthetic medical dialogue dataset that\nsimulates proactive diagnostic interactions between patients and doctors,\nserving as a valuable resource for training LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10620v1",
    "published_date": "2025-02-15 01:14:23 UTC",
    "updated_date": "2025-02-15 01:14:23 UTC"
  },
  {
    "arxiv_id": "2502.10614v1",
    "title": "Optimizing CNN Architectures for Advanced Thoracic Disease Classification",
    "authors": [
      "Tejas Mirthipati"
    ],
    "abstract": "Machine learning, particularly convolutional neural networks (CNNs), has\nshown promise in medical image analysis, especially for thoracic disease\ndetection using chest X-ray images. In this study, we evaluate various CNN\narchitectures, including binary classification, multi-label classification, and\nResNet50 models, to address challenges like dataset imbalance, variations in\nimage quality, and hidden biases. We introduce advanced preprocessing\ntechniques such as principal component analysis (PCA) for image compression and\npropose a novel class-weighted loss function to mitigate imbalance issues. Our\nresults highlight the potential of CNNs in medical imaging but emphasize that\nissues like unbalanced datasets and variations in image acquisition methods\nmust be addressed for optimal model performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10614v1",
    "published_date": "2025-02-15 00:27:37 UTC",
    "updated_date": "2025-02-15 00:27:37 UTC"
  }
]