[
  {
    "arxiv_id": "2401.11627v2",
    "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
    "authors": [
      "Ben Batten",
      "Mehran Hosseini",
      "Alessio Lomuscio"
    ],
    "abstract": "We introduce two algorithms for computing tight guarantees on the\nprobabilistic robustness of Bayesian Neural Networks (BNNs). Computing\nrobustness guarantees for BNNs is a significantly more challenging task than\nverifying the robustness of standard Neural Networks (NNs) because it requires\nsearching the parameters' space for safe weights. Moreover, tight and complete\napproaches for the verification of standard NNs, such as those based on\nMixed-Integer Linear Programming (MILP), cannot be directly used for the\nverification of BNNs because of the polynomial terms resulting from the\nconsecutive multiplication of variables encoding the weights. Our algorithms\nefficiently and effectively search the parameters' space for safe weights by\nusing iterative expansion and the network's gradient and can be used with any\nverification algorithm of choice for BNNs. In addition to proving that our\nalgorithms compute tighter bounds than the SoA, we also evaluate our algorithms\nagainst the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that\nour algorithms compute bounds up to 40% tighter than the SoA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.FL",
      "cs.LO",
      "68T27 (Primary) 68T45, 68T07, 68T01 (Secondary)",
      "I.2.0; I.2.4; F.3.1; D.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11627v2",
    "published_date": "2024-01-21 23:41:32 UTC",
    "updated_date": "2024-02-28 19:04:12 UTC"
  },
  {
    "arxiv_id": "2402.01680v2",
    "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges",
    "authors": [
      "Taicheng Guo",
      "Xiuying Chen",
      "Yaqi Wang",
      "Ruidi Chang",
      "Shichao Pei",
      "Nitesh V. Chawla",
      "Olaf Wiest",
      "Xiangliang Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across a wide\narray of tasks. Due to the impressive planning and reasoning abilities of LLMs,\nthey have been used as autonomous agents to do many tasks automatically.\nRecently, based on the development of using one LLM as a single planning or\ndecision-making agent, LLM-based multi-agent systems have achieved considerable\nprogress in complex problem-solving and world simulation. To provide the\ncommunity with an overview of this dynamic field, we present this survey to\noffer an in-depth discussion on the essential aspects of multi-agent systems\nbased on LLMs, as well as the challenges. Our goal is for readers to gain\nsubstantial insights on the following questions: What domains and environments\ndo LLM-based multi-agents simulate? How are these agents profiled and how do\nthey communicate? What mechanisms contribute to the growth of agents'\ncapacities? For those interested in delving into this field of study, we also\nsummarize the commonly used datasets or benchmarks for them to have convenient\naccess. To keep researchers updated on the latest studies, we maintain an\nopen-source GitHub repository, dedicated to outlining the research on LLM-based\nmulti-agent systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "This work is ongoing and we welcome your contribution!",
    "pdf_url": "http://arxiv.org/pdf/2402.01680v2",
    "published_date": "2024-01-21 23:36:14 UTC",
    "updated_date": "2024-04-19 01:15:16 UTC"
  },
  {
    "arxiv_id": "2401.11624v5",
    "title": "In-context Learning with Retrieved Demonstrations for Language Models: A Survey",
    "authors": [
      "Man Luo",
      "Xin Xu",
      "Yue Liu",
      "Panupong Pasupat",
      "Mehran Kazemi"
    ],
    "abstract": "Language models, especially pre-trained large language models, have showcased\nremarkable abilities as few-shot in-context learners (ICL), adept at adapting\nto new tasks with just a few demonstrations in the input context. However, the\nmodel's ability to perform ICL is sensitive to the choice of the few-shot\ndemonstrations. Instead of using a fixed set of demonstrations, one recent\ndevelopment is to retrieve demonstrations tailored to each input query. The\nimplementation of demonstration retrieval is relatively straightforward,\nleveraging existing databases and retrieval systems. This not only improves the\nefficiency and scalability of the learning process but also has been shown to\nreduce biases inherent in manual example selection. In light of the encouraging\nresults and growing research in ICL with retrieved demonstrations, we conduct\nan extensive review of studies in this area. In this survey, we discuss and\ncompare different design choices for retrieval models, retrieval training\nprocedures, and inference algorithms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11624v5",
    "published_date": "2024-01-21 23:34:42 UTC",
    "updated_date": "2024-03-23 16:35:45 UTC"
  },
  {
    "arxiv_id": "2401.11618v2",
    "title": "Efficient local linearity regularization to overcome catastrophic overfitting",
    "authors": [
      "Elias Abad Rocamora",
      "Fanghui Liu",
      "Grigorios G. Chrysos",
      "Pablo M. Olmos",
      "Volkan Cevher"
    ],
    "abstract": "Catastrophic overfitting (CO) in single-step adversarial training (AT)\nresults in abrupt drops in the adversarial test accuracy (even down to 0%). For\nmodels trained with multi-step AT, it has been observed that the loss function\nbehaves locally linearly with respect to the input, this is however lost in\nsingle-step AT. To address CO in single-step AT, several methods have been\nproposed to enforce local linearity of the loss via regularization. However,\nthese regularization terms considerably slow down training due to Double\nBackpropagation. Instead, in this work, we introduce a regularization term,\ncalled ELLE, to mitigate CO effectively and efficiently in classical AT\nevaluations, as well as some more difficult regimes, e.g., large adversarial\nperturbations and long training schedules. Our regularization term can be\ntheoretically linked to curvature of the loss function and is computationally\ncheaper than previous methods by avoiding Double Backpropagation. Our thorough\nexperimental validation demonstrates that our work does not suffer from CO,\neven in challenging settings where previous works suffer from it. We also\nnotice that adapting our regularization parameter during training (ELLE-A)\ngreatly improves the performance, specially in large $\\epsilon$ setups. Our\nimplementation is available in https://github.com/LIONS-EPFL/ELLE .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11618v2",
    "published_date": "2024-01-21 22:55:26 UTC",
    "updated_date": "2024-02-28 16:37:00 UTC"
  },
  {
    "arxiv_id": "2401.11609v3",
    "title": "Graph Edits for Counterfactual Explanations: A comparative study",
    "authors": [
      "Angeliki Dimitriou",
      "Nikolaos Chaidos",
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "abstract": "Counterfactuals have been established as a popular explainability technique\nwhich leverages a set of minimal edits to alter the prediction of a classifier.\nWhen considering conceptual counterfactuals on images, the edits requested\nshould correspond to salient concepts present in the input data. At the same\ntime, conceptual distances are defined by knowledge graphs, ensuring the\noptimality of conceptual edits. In this work, we extend previous endeavors on\ngraph edits as counterfactual explanations by conducting a comparative study\nwhich encompasses both supervised and unsupervised Graph Neural Network (GNN)\napproaches. To this end, we pose the following significant research question:\nshould we represent input data as graphs, which is the optimal GNN approach in\nterms of performance and time efficiency to generate minimal and meaningful\ncounterfactual explanations for black-box image classifiers?",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11609v3",
    "published_date": "2024-01-21 22:11:29 UTC",
    "updated_date": "2024-04-18 14:29:29 UTC"
  },
  {
    "arxiv_id": "2403.08775v1",
    "title": "Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN",
    "authors": [
      "Ioannis Panitsas",
      "Akrit Mudvari",
      "Leandros Tassiulas"
    ],
    "abstract": "In software-defined networking (SDN), the implementation of distributed SDN\ncontrollers, with each controller responsible for managing a specific\nsub-network or domain, plays a critical role in achieving a balance between\ncentralized control, scalability, reliability, and network efficiency. These\ncontrollers must be synchronized to maintain a logically centralized view of\nthe entire network. While there are various approaches for synchronizing\ndistributed SDN controllers, most tend to prioritize goals such as optimization\nof communication latency or load balancing, often neglecting to address both\nthe aspects simultaneously. This limitation becomes particularly significant\nwhen considering applications like Augmented and Virtual Reality (AR/VR), which\ndemand constrained network latencies and substantial computational resources.\nAdditionally, many existing studies in this field predominantly rely on\nvalue-based reinforcement learning (RL) methods, overlooking the potential\nadvantages offered by state-of-the-art policy-based RL algorithms. To bridge\nthis gap, our work focuses on examining deep reinforcement learning (DRL)\ntechniques, encompassing both value-based and policy-based methods, to\nguarantee an upper latency threshold for AR/VR task offloading within SDN\nenvironments, while selecting the most cost-effective servers for AR/VR task\noffloading. Our evaluation results indicate that while value-based methods\nexcel in optimizing individual network metrics such as latency or load\nbalancing, policy-based approaches exhibit greater robustness in adapting to\nsudden network changes or reconfiguration.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08775v1",
    "published_date": "2024-01-21 21:57:22 UTC",
    "updated_date": "2024-01-21 21:57:22 UTC"
  },
  {
    "arxiv_id": "2401.11605v1",
    "title": "Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass Diffusion Transformers",
    "authors": [
      "Katherine Crowson",
      "Stefan Andreas Baumann",
      "Alex Birch",
      "Tanishq Mathew Abraham",
      "Daniel Z. Kaplan",
      "Enrico Shippole"
    ],
    "abstract": "We present the Hourglass Diffusion Transformer (HDiT), an image generative\nmodel that exhibits linear scaling with pixel count, supporting training at\nhigh-resolution (e.g. $1024 \\times 1024$) directly in pixel-space. Building on\nthe Transformer architecture, which is known to scale to billions of\nparameters, it bridges the gap between the efficiency of convolutional U-Nets\nand the scalability of Transformers. HDiT trains successfully without typical\nhigh-resolution training techniques such as multiscale architectures, latent\nautoencoders or self-conditioning. We demonstrate that HDiT performs\ncompetitively with existing models on ImageNet $256^2$, and sets a new\nstate-of-the-art for diffusion models on FFHQ-$1024^2$.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 13 figures, project page and code available at\n  https://crowsonkb.github.io/hourglass-diffusion-transformers/",
    "pdf_url": "http://arxiv.org/pdf/2401.11605v1",
    "published_date": "2024-01-21 21:49:49 UTC",
    "updated_date": "2024-01-21 21:49:49 UTC"
  },
  {
    "arxiv_id": "2401.11596v2",
    "title": "Learning to Maximize Gains From Trade in Small Markets",
    "authors": [
      "Moshe Babaioff",
      "Amitai Frey",
      "Noam Nisan"
    ],
    "abstract": "We study the problem of designing a two-sided market (double auction) to\nmaximize the gains from trade (social welfare) under the constraints of\n(dominant-strategy) incentive compatibility and budget-balance. Our goal is to\ndo so for an unknown distribution from which we are given a polynomial number\nof samples. Our first result is a general impossibility for the case of\ncorrelated distributions of values even between just one seller and two buyers,\nin contrast to the case of one seller and one buyer (bilateral trade) where\nthis is possible. Our second result is an efficient learning algorithm for one\nseller and two buyers in the case of independent distributions which is based\non a novel algorithm for computing optimal mechanisms for finitely supported\nand explicitly given independent distributions. Both results rely heavily on\ncharacterizations of (dominant-strategy) incentive compatible mechanisms that\nare strongly budget-balanced.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "F.0; I.2; I.2.6; J.4"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11596v2",
    "published_date": "2024-01-21 20:57:12 UTC",
    "updated_date": "2024-06-19 21:02:22 UTC"
  },
  {
    "arxiv_id": "2401.11553v1",
    "title": "Taxi dispatching strategies with compensations",
    "authors": [
      "Holger Billhardt",
      "Alberto Fernández",
      "Sascha Ossowski",
      "Javier Palanca",
      "Javier Bajo"
    ],
    "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi\nvehicles are key elements in daily traffic activity. The advance of ICT and\ngeo-positioning systems has given rise to new opportunities for improving the\nefficiency of taxi fleets in terms of waiting times of passengers, cost and\ntime for drivers, traffic density, CO2 emissions, etc., by using more informed,\nintelligent dispatching. Still, the explicit spatial and temporal components,\nas well as the scale and, in particular, the dynamicity of the problem of\npairing passengers and taxis in big towns, render traditional approaches for\nsolving standard assignment problem useless for this purpose, and call for\nintelligent approximation strategies based on domain-specific heuristics.\nFurthermore, taxi drivers are often autonomous actors and may not agree to\nparticipate in assignments that, though globally efficient, may not be\nsufficently beneficial for them individually. This paper presents a new\nheuristic algorithm for taxi assignment to customers that considers taxi\nreassignments if this may lead to globally better solutions. In addition, as\nsuch new assignments may reduce the expected revenues of individual drivers, we\npropose an economic compensation scheme to make individually rational drivers\nagree to proposed modifications in their assigned clients. We carried out a set\nof experiments, where several commonly used assignment strategies are compared\nto three different instantiations of our heuristic algorithm. The results\nindicate that our proposal has the potential to reduce customer waiting times\nin fleets of autonomous taxis, while being also beneficial from an economic\npoint of view.",
    "categories": [
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11553v1",
    "published_date": "2024-01-21 17:54:46 UTC",
    "updated_date": "2024-01-21 17:54:46 UTC"
  },
  {
    "arxiv_id": "2401.12259v1",
    "title": "Agreement Technologies for Coordination in Smart Cities",
    "authors": [
      "Holger Billhardt",
      "Alberto Fernández",
      "Marin Lujak",
      "Sascha Ossowski"
    ],
    "abstract": "Many challenges in today's society can be tackled by distributed open\nsystems. This is particularly true for domains that are commonly perceived\nunder the umbrella of smart cities, such as intelligent transportation, smart\nenergy grids, or participative governance. When designing computer applications\nfor these domains, it is necessary to account for the fact that the elements of\nsuch systems, often called software agents, are usually made by different\ndesigners and act on behalf of particular stakeholders. Furthermore, it is\nunknown at design time when such agents will enter or leave the system, and\nwhat interests new agents will represent. To instil coordination in such\nsystems is particularly demanding, as usually only part of them can be directly\ncontrolled at runtime. Agreement technologies refer to a sandbox of tools and\nmechanisms for the development of such open multiagent systems, which are based\non the notion of agreement. In this paper, we argue that agreement technologies\nare a suitable means for achieving coordination in smart city domains, and back\nour claim through examples of several real-world applications.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12259v1",
    "published_date": "2024-01-21 17:43:08 UTC",
    "updated_date": "2024-01-21 17:43:08 UTC"
  },
  {
    "arxiv_id": "2401.12258v7",
    "title": "Emergent Dominance Hierarchies in Reinforcement Learning Agents",
    "authors": [
      "Ram Rachum",
      "Yonatan Nakar",
      "Bill Tomlinson",
      "Nitay Alon",
      "Reuth Mirsky"
    ],
    "abstract": "Modern Reinforcement Learning (RL) algorithms are able to outperform humans\nin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings\npresent additional challenges, and successful cooperation in mixed-motive\ngroups of agents depends on a delicate balancing act between individual and\ngroup objectives. Social conventions and norms, often inspired by human\ninstitutions, are used as tools for striking this balance.\n  In this paper, we examine a fundamental, well-studied social convention that\nunderlies cooperation in both animal and human societies: dominance\nhierarchies.\n  We adapt the ethological theory of dominance hierarchies to artificial\nagents, borrowing the established terminology and definitions with as few\namendments as possible. We demonstrate that populations of RL agents, operating\nwithout explicit programming or intrinsic rewards, can invent, learn, enforce,\nand transmit a dominance hierarchy to new populations. The dominance\nhierarchies that emerge have a similar structure to those studied in chickens,\nmice, fish, and other species.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.12258v7",
    "published_date": "2024-01-21 16:59:45 UTC",
    "updated_date": "2024-06-22 11:44:33 UTC"
  },
  {
    "arxiv_id": "2403.08774v2",
    "title": "Discussion of Loop Expansion and Introduction of Series Cutting Functions to Local Potential Approximation: Complexity Analysis Using Green's Functions, Cutting Of Nth-Order Social Interactions For Progressive Safety",
    "authors": [
      "Yasuko Kawahata"
    ],
    "abstract": "In this study, we focus on the aforementioned paper, \"Examination\nKubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value\nInformation Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena\nUsing The Replica Method (2024)\". This paper also applies theoretical physics\nmethods to better understand the filter bubble phenomenon, focusing in\nparticular on loop expansions and truncation functions. Using the loop\nexpansion method, the complexity of social interactions during the occurrence\nof filter bubbles will be discussed in order to introduce series, express\nmathematically, and evaluate the impact of these interactions. We analyze the\ninteractions between agents and their time evolution using a variety of Green's\nfunctions, including delayed Green's functions, advanced Green's functions, and\ncausal Green's functions, to capture the dynamic response of the system through\nlocal potential approximations. In addition, we apply truncation functions and\ntruncation techniques to ensure incremental safety and evaluate the long-term\nstability of the system. This approach will enable a better understanding of\nthe mechanisms of filter bubble generation and dissolution, and discuss\ninsights into their prevention and management. This research explores the\npossibilities of applying theoretical physics frameworks to social science\nproblems and examines methods for analyzing the complex dynamics of information\nflow and opinion formation in digital society.This paper is partially an\nattempt to utilize \"Generative AI\" and was written with educational intent.\nThere are currently no plans for it to become a peer-reviewed paper.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "In this study, we focus on the aforementioned paper, \"Examination\n  Kubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value\n  Information Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena\n  Using The Replica Method (2024)\"",
    "pdf_url": "http://arxiv.org/pdf/2403.08774v2",
    "published_date": "2024-01-21 15:03:17 UTC",
    "updated_date": "2024-04-19 14:52:01 UTC"
  },
  {
    "arxiv_id": "2401.11512v1",
    "title": "Information-Theoretic State Variable Selection for Reinforcement Learning",
    "authors": [
      "Charles Westphal",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "abstract": "Identifying the most suitable variables to represent the state is a\nfundamental challenge in Reinforcement Learning (RL). These variables must\nefficiently capture the information necessary for making optimal decisions. In\norder to address this problem, in this paper, we introduce the Transfer Entropy\nRedundancy Criterion (TERC), an information-theoretic criterion, which\ndetermines if there is \\textit{entropy transferred} from state variables to\nactions during training. We define an algorithm based on TERC that provably\nexcludes variables from the state that have no effect on the final performance\nof the agent, resulting in more sample efficient learning. Experimental results\nshow that this speed-up is present across three different algorithm classes\n(represented by tabular Q-learning, Actor-Critic, and Proximal Policy\nOptimization (PPO)) in a variety of environments. Furthermore, to highlight the\ndifferences between the proposed methodology and the current state-of-the-art\nfeature selection approaches, we present a series of controlled experiments on\nsynthetic data, before generalizing to real-world decision-making tasks. We\nalso introduce a representation of the problem that compactly captures the\ntransfer of information from state variables to actions as Bayesian networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.11512v1",
    "published_date": "2024-01-21 14:51:09 UTC",
    "updated_date": "2024-01-21 14:51:09 UTC"
  },
  {
    "arxiv_id": "2401.11504v3",
    "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation",
    "authors": [
      "Y. Wang",
      "D. Ma",
      "D. Cai"
    ],
    "abstract": "Long text generation, such as novel writing and discourse-level translation\nwith extremely long contexts, presents significant challenges to current\nlanguage models. Existing methods mainly focus on extending the model's context\nwindow through strategies like length extrapolation. However, these approaches\ndemand substantial hardware resources during the training and/or inference\nphases. Our proposed method, Temp-Lora, introduces an alternative concept.\nInstead of relying on the KV cache to store all context information, we embeds\nthis information directly into a temporary Lora module. In the process of long\ntext generation, this module is progressively trained with text generated\npreviously. This approach not only efficiently preserves contextual knowledge\nbut also prevents any permanent alteration to the model's parameters given that\nthe module is discarded post-generation. Extensive experiments on the PG19\nlanguage modeling benchmark and the GuoFeng discourse-level translation\nbenchmark validate the effectiveness of Temp-Lora. Our results show that: 1)\nTemp-Lora substantially enhances generation quality for long text, as indicated\nby a 13.2% decrease in perplexity (PPL) on a subset of PG19, and a 29.3%\ndecrease in PPL along with a 113.2% increase in BLEU score on a subset of\nGuoFeng, 2) Temp-Lora is compatible with and enhances most existing long text\ngeneration methods, and 3) Temp-Lora can greatly reduce computational costs by\nshortening the context window. For example, we can ensure a moderate\nimprovement in generation quality (a decrease of 3.8% in PPL) while enabling a\n51.5% memory usage reduction and a 60.0% decrease in latency for inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11504v3",
    "published_date": "2024-01-21 14:28:41 UTC",
    "updated_date": "2024-09-11 02:22:58 UTC"
  },
  {
    "arxiv_id": "2401.11500v1",
    "title": "Integration of Large Language Models in Control of EHD Pumps for Precise Color Synthesis",
    "authors": [
      "Yanhong Peng",
      "Ceng Zhang",
      "Chenlong Hu",
      "Zebing Mao"
    ],
    "abstract": "This paper presents an innovative approach to integrating Large Language\nModels (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for\nprecise color synthesis in automation systems. We propose a novel framework\nthat employs fine-tuned LLMs to interpret natural language commands and convert\nthem into specific operational instructions for EHD pump control. This approach\naims to enhance user interaction with complex hardware systems, making it more\nintuitive and efficient. The methodology involves four key steps: fine-tuning\nthe language model with a dataset of color specifications and corresponding\nArduino code, developing a natural language processing interface, translating\nuser inputs into executable Arduino code, and controlling EHD pumps for\naccurate color mixing. Conceptual experiment results, based on theoretical\nassumptions, indicate a high potential for accurate color synthesis, efficient\nlanguage model interpretation, and reliable EHD pump operation. This research\nextends the application of LLMs beyond text-based tasks, demonstrating their\npotential in industrial automation and control systems. While highlighting the\nlimitations and the need for real-world testing, this study opens new avenues\nfor AI applications in physical system control and sets a foundation for future\nadvancements in AI-driven automation technologies.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11500v1",
    "published_date": "2024-01-21 14:10:27 UTC",
    "updated_date": "2024-01-21 14:10:27 UTC"
  },
  {
    "arxiv_id": "2401.11489v1",
    "title": "MapChange: Enhancing Semantic Change Detection with Temporal-Invariant Historical Maps Based on Deep Triplet Network",
    "authors": [
      "Yinhe Liu",
      "Sunan Shi",
      "Zhuo Zheng",
      "Jue Wang",
      "Shiqi Tian",
      "Yanfei Zhong"
    ],
    "abstract": "Semantic Change Detection (SCD) is recognized as both a crucial and\nchallenging task in the field of image analysis. Traditional methods for SCD\nhave predominantly relied on the comparison of image pairs. However, this\napproach is significantly hindered by substantial imaging differences, which\narise due to variations in shooting times, atmospheric conditions, and angles.\nSuch discrepancies lead to two primary issues: the under-detection of minor yet\nsignificant changes, and the generation of false alarms due to temporal\nvariances. These factors often result in unchanged objects appearing markedly\ndifferent in multi-temporal images. In response to these challenges, the\nMapChange framework has been developed. This framework introduces a novel\nparadigm that synergizes temporal-invariant historical map data with\ncontemporary high-resolution images. By employing this combination, the\ntemporal variance inherent in conventional image pair comparisons is\neffectively mitigated. The efficacy of the MapChange framework has been\nempirically validated through comprehensive testing on two public datasets.\nThese tests have demonstrated the framework's marked superiority over existing\nstate-of-the-art SCD methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11489v1",
    "published_date": "2024-01-21 13:30:02 UTC",
    "updated_date": "2024-01-21 13:30:02 UTC"
  },
  {
    "arxiv_id": "2401.11472v3",
    "title": "Abstract Weighted Based Gradual Semantics in Argumentation Theory",
    "authors": [
      "Assaf Libman",
      "Nir Oren",
      "Bruno Yun"
    ],
    "abstract": "Weighted gradual semantics provide an acceptability degree to each argument\nrepresenting the strength of the argument, computed based on factors including\nbackground evidence for the argument, and taking into account interactions\nbetween this argument and others. We introduce four important problems linking\ngradual semantics and acceptability degrees. First, we reexamine the inverse\nproblem, seeking to identify the argument weights of the argumentation\nframework which lead to a specific final acceptability degree. Second, we ask\nwhether the function mapping between argument weights and acceptability degrees\nis injective or a homeomorphism onto its image. Third, we ask whether argument\nweights can be found when preferences, rather than acceptability degrees for\narguments are considered. Fourth, we consider the topology of the space of\nvalid acceptability degrees, asking whether \"gaps\" exist in this space. While\ndifferent gradual semantics have been proposed in the literature, in this\npaper, we identify a large family of weighted gradual semantics, called\nabstract weighted based gradual semantics. These generalise many of the\nexisting semantics while maintaining desirable properties such as convergence\nto a unique fixed point. We also show that a sub-family of the weighted gradual\nsemantics, called abstract weighted (L^p,\\lambda,\\mu)-based gradual semantics\nand which include well-known semantics, solve all four of the aforementioned\nproblems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11472v3",
    "published_date": "2024-01-21 12:22:48 UTC",
    "updated_date": "2024-08-20 12:44:00 UTC"
  },
  {
    "arxiv_id": "2401.11471v1",
    "title": "LR-CNN: Lightweight Row-centric Convolutional Neural Network Training for Memory Reduction",
    "authors": [
      "Zhigang Wang",
      "Hangyu Yang",
      "Ning Wang",
      "Chuanfei Xu",
      "Jie Nie",
      "Zhiqiang Wei",
      "Yu Gu",
      "Ge Yu"
    ],
    "abstract": "In the last decade, Convolutional Neural Network with a multi-layer\narchitecture has advanced rapidly. However, training its complex network is\nvery space-consuming, since a lot of intermediate data are preserved across\nlayers, especially when processing high-dimension inputs with a big batch size.\nThat poses great challenges to the limited memory capacity of current\naccelerators (e.g., GPUs). Existing efforts mitigate such bottleneck by\nexternal auxiliary solutions with additional hardware costs, and internal\nmodifications with potential accuracy penalty. Differently, our analysis\nreveals that computations intra- and inter-layers exhibit the spatial-temporal\nweak dependency and even complete independency features. That inspires us to\nbreak the traditional layer-by-layer (column) dataflow rule. Now operations are\nnovelly re-organized into rows throughout all convolution layers. This\nlightweight design allows a majority of intermediate data to be removed without\nany loss of accuracy. We particularly study the weak dependency between two\nconsecutive rows. For the resulting skewed memory consumption, we give two\nsolutions with different favorite scenarios. Evaluations on two representative\nnetworks confirm the effectiveness. We also validate that our middle dataflow\noptimization can be smoothly embraced by existing works for better memory\nreduction.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11471v1",
    "published_date": "2024-01-21 12:19:13 UTC",
    "updated_date": "2024-01-21 12:19:13 UTC"
  },
  {
    "arxiv_id": "2401.11459v1",
    "title": "AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology",
    "authors": [
      "Rongqing Cong",
      "Wenyang He",
      "Mingxuan Li",
      "Bangning Luo",
      "Zebin Yang",
      "Yuchao Yang",
      "Ru Huang",
      "Bonan Yan"
    ],
    "abstract": "Large language models (LLMs) with Transformer architectures have become\nphenomenal in natural language processing, multimodal generative artificial\nintelligence, and agent-oriented artificial intelligence. The self-attention\nmodule is the most dominating sub-structure inside Transformer-based LLMs.\nComputation using general-purpose graphics processing units (GPUs) inflicts\nreckless demand for I/O bandwidth for transferring intermediate calculation\nresults between memories and processing units. To tackle this challenge, this\nwork develops a fully customized vanilla self-attention accelerator,\nAttentionLego, as the basic building block for constructing spatially\nexpandable LLM processors. AttentionLego provides basic implementation with\nfully-customized digital logic incorporating Processing-In-Memory (PIM)\ntechnology. It is based on PIM-based matrix-vector multiplication and look-up\ntable-based Softmax design. The open-source code is available online:\nhttps://bonany.cc/attentionleg.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "for associated source codes, see https://bonany.cc/attentionleg",
    "pdf_url": "http://arxiv.org/pdf/2401.11459v1",
    "published_date": "2024-01-21 10:48:08 UTC",
    "updated_date": "2024-01-21 10:48:08 UTC"
  },
  {
    "arxiv_id": "2401.12255v2",
    "title": "Instructional Fingerprinting of Large Language Models",
    "authors": [
      "Jiashu Xu",
      "Fei Wang",
      "Mingyu Derek Ma",
      "Pang Wei Koh",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "abstract": "The exorbitant cost of training Large language models (LLMs) from scratch\nmakes it essential to fingerprint the models to protect intellectual property\nvia ownership authentication and to ensure downstream users and developers\ncomply with their license terms (e.g. restricting commercial use). In this\nstudy, we present a pilot study on LLM fingerprinting as a form of very\nlightweight instruction tuning. Model publisher specifies a confidential\nprivate key and implants it as an instruction backdoor that causes the LLM to\ngenerate specific text when the key is present. Results on 11 popularly-used\nLLMs showed that this approach is lightweight and does not affect the normal\nbehavior of the model. It also prevents publisher overclaim, maintains\nrobustness against fingerprint guessing and parameter-efficient training, and\nsupports multi-stage fingerprinting akin to MIT License. Code is available in\nhttps://cnut1648.github.io/Model-Fingerprint/.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at NAACL 2024; 30 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.12255v2",
    "published_date": "2024-01-21 09:51:45 UTC",
    "updated_date": "2024-04-03 06:23:34 UTC"
  },
  {
    "arxiv_id": "2401.11439v2",
    "title": "General Flow as Foundation Affordance for Scalable Robot Learning",
    "authors": [
      "Chengbo Yuan",
      "Chuan Wen",
      "Tong Zhang",
      "Yang Gao"
    ],
    "abstract": "We address the challenge of acquiring real-world manipulation skills with a\nscalable framework. We hold the belief that identifying an appropriate\nprediction target capable of leveraging large-scale datasets is crucial for\nachieving efficient and universal learning. Therefore, we propose to utilize 3D\nflow, which represents the future trajectories of 3D points on objects of\ninterest, as an ideal prediction target. To exploit scalable data resources, we\nturn our attention to human videos. We develop, for the first time, a\nlanguage-conditioned 3D flow prediction model directly from large-scale RGBD\nhuman video datasets. Our predicted flow offers actionable guidance, thus\nfacilitating zero-shot skill transfer in real-world scenarios. We deploy our\nmethod with a policy based on closed-loop flow prediction. Remarkably, without\nany in-domain finetuning, our method achieves an impressive 81\\% success rate\nin zero-shot human-to-robot skill transfer, covering 18 tasks in 6 scenes. Our\nframework features the following benefits: (1) scalability: leveraging\ncross-embodiment data resources; (2) wide application: multiple object\ncategories, including rigid, articulated, and soft bodies; (3) stable skill\ntransfer: providing actionable guidance with a small inference domain-gap.\nCode, data, and supplementary materials are available\nhttps://general-flow.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "https://general-flow.github.io",
    "pdf_url": "http://arxiv.org/pdf/2401.11439v2",
    "published_date": "2024-01-21 09:39:11 UTC",
    "updated_date": "2024-09-23 08:22:04 UTC"
  },
  {
    "arxiv_id": "2401.11418v1",
    "title": "Double-Bounded Optimal Transport for Advanced Clustering and Classification",
    "authors": [
      "Liangliang Shi",
      "Zhaoqi Shen",
      "Junchi Yan"
    ],
    "abstract": "Optimal transport (OT) is attracting increasing attention in machine\nlearning. It aims to transport a source distribution to a target one at minimal\ncost. In its vanilla form, the source and target distributions are\npredetermined, which contracts to the real-world case involving undetermined\ntargets. In this paper, we propose Doubly Bounded Optimal Transport (DB-OT),\nwhich assumes that the target distribution is restricted within two boundaries\ninstead of a fixed one, thus giving more freedom for the transport to find\nsolutions. Based on the entropic regularization of DB-OT, three scaling-based\nalgorithms are devised for calculating the optimal solution. We also show that\nour DB-OT is helpful for barycenter-based clustering, which can avoid the\nexcessive concentration of samples in a single cluster. Then we further develop\nDB-OT techniques for long-tailed classification which is an emerging and open\nproblem. We first propose a connection between OT and classification, that is,\nin the classification task, training involves optimizing the Inverse OT to\nlearn the representations, while testing involves optimizing the OT for\npredictions. With this OT perspective, we first apply DB-OT to improve the\nloss, and the Balanced Softmax is shown as a special case. Then we apply DB-OT\nfor inference in the testing process. Even with vanilla Softmax trained\nfeatures, our extensive experimental results show that our method can achieve\ngood results with our improved inference scheme in the testing stage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11418v1",
    "published_date": "2024-01-21 07:43:01 UTC",
    "updated_date": "2024-01-21 07:43:01 UTC"
  },
  {
    "arxiv_id": "2401.11414v2",
    "title": "S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching for Autonomous Driving",
    "authors": [
      "Zhiyuan Wu",
      "Yi Feng",
      "Chuang-Wei Liu",
      "Fisher Yu",
      "Qijun Chen",
      "Rui Fan"
    ],
    "abstract": "Semantic segmentation and stereo matching are two essential components of 3D\nenvironmental perception systems for autonomous driving. Nevertheless,\nconventional approaches often address these two problems independently,\nemploying separate models for each task. This approach poses practical\nlimitations in real-world scenarios, particularly when computational resources\nare scarce or real-time performance is imperative. Hence, in this article, we\nintroduce S$^3$M-Net, a novel joint learning framework developed to perform\nsemantic segmentation and stereo matching simultaneously. Specifically,\nS$^3$M-Net shares the features extracted from RGB images between both tasks,\nresulting in an improved overall scene understanding capability. This feature\nsharing process is realized using a feature fusion adaption (FFA) module, which\neffectively transforms the shared features into semantic space and subsequently\nfuses them with the encoded disparity features. The entire joint learning\nframework is trained by minimizing a novel semantic consistency-guided (SCG)\nloss, which places emphasis on the structural consistency in both tasks.\nExtensive experimental results conducted on the vKITTI2 and KITTI datasets\ndemonstrate the effectiveness of our proposed joint learning framework and its\nsuperior performance compared to other state-of-the-art single-task networks.\nOur project webpage is accessible at mias.group/S3M-Net.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to IEEE Trans. on Intelligent Vehicles (T-IV)",
    "pdf_url": "http://arxiv.org/pdf/2401.11414v2",
    "published_date": "2024-01-21 06:47:33 UTC",
    "updated_date": "2024-01-29 02:07:56 UTC"
  },
  {
    "arxiv_id": "2401.11410v3",
    "title": "Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach",
    "authors": [
      "Md Zubair",
      "Md. Shahidul Salim",
      "Mehrab Mustafy Rahman",
      "Mohammad Jahid Ibna Basher",
      "Shahin Imran",
      "Iqbal H. Sarker"
    ],
    "abstract": "Agriculture plays a fundamental role in driving economic growth and ensuring\nfood security for populations around the world. Although labor-intensive\nagriculture has led to steady increases in food grain production in many\ndeveloping countries, it is frequently challenged by adverse weather\nconditions, including heavy rainfall, low temperatures, and drought. These\nfactors substantially hinder food production, posing significant risks to\nglobal food security. In order to have a profitable, sustainable, and\nfarmer-friendly agricultural practice, this paper proposes a context-based crop\nrecommendation system powered by a weather forecast model. For implementation\npurposes, we have considered the whole territory of Bangladesh. With extensive\nevaluation, the multivariate Stacked Bi-LSTM (three Bi-LSTM layers with a time\nDistributed layer) Network is employed as the weather forecasting model. The\nproposed weather model can forecast Rainfall, Temperature, Humidity, and\nSunshine for any given location in Bangladesh with an average R-Squared value\nof 0.9824, and the model outperforms other state-of-the-art LSTM models. These\npredictions guide our system in generating viable farming decisions.\nAdditionally, our full-fledged system is capable of alerting the farmers about\nextreme weather conditions so that preventive measures can be undertaken to\nprotect the crops. Finally, the system is also adept at making knowledge-based\ncrop suggestions for flood and drought-prone regions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 16 figures and 13 tables. Two figures and one table have\n  been added to this version",
    "pdf_url": "http://arxiv.org/pdf/2401.11410v3",
    "published_date": "2024-01-21 06:33:45 UTC",
    "updated_date": "2024-07-12 02:02:45 UTC"
  },
  {
    "arxiv_id": "2401.11408v1",
    "title": "SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction Tasks Oriented to the Finance Field",
    "authors": [
      "Congqing He",
      "Xiangyu Zhu",
      "Yuquan Le",
      "Yuzhong Liu",
      "Jianhong Yin"
    ],
    "abstract": "Event extraction lies at the cores of investment analysis and asset\nmanagement in the financial field, and thus has received much attention. The\n2019 China conference on knowledge graph and semantic computing (CCKS)\nchallenge sets up a evaluation competition for event entity extraction task\noriented to the finance field. In this task, we mainly focus on how to extract\nthe event entity accurately, and recall all the corresponding event entity\neffectively. In this paper, we propose a novel model, Sequence Enhanced BERT\nNetworks (SEBERTNets for short), which can inherit the advantages of the\nBERT,and while capturing sequence semantic information. In addition, motivated\nby recommendation system, we propose Hybrid Sequence Enhanced BERT Networks\n(HSEBERTNets for short), which uses a multi-channel recall method to recall all\nthe corresponding event entity. The experimental results show that, the F1\nscore of SEBERTNets is 0.905 in the first stage, and the F1 score of\nHSEBERTNets is 0.934 in the first stage, which demonstarate the effectiveness\nof our methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "CCKS 2019",
    "pdf_url": "http://arxiv.org/pdf/2401.11408v1",
    "published_date": "2024-01-21 06:10:03 UTC",
    "updated_date": "2024-01-21 06:10:03 UTC"
  },
  {
    "arxiv_id": "2404.15279v1",
    "title": "Jointly Modeling Spatio-Temporal Features of Tactile Signals for Action Classification",
    "authors": [
      "Jimmy Lin",
      "Junkai Li",
      "Jiasi Gao",
      "Weizhi Ma",
      "Yang Liu"
    ],
    "abstract": "Tactile signals collected by wearable electronics are essential in modeling\nand understanding human behavior. One of the main applications of tactile\nsignals is action classification, especially in healthcare and robotics.\nHowever, existing tactile classification methods fail to capture the spatial\nand temporal features of tactile signals simultaneously, which results in\nsub-optimal performances. In this paper, we design Spatio-Temporal Aware\ntactility Transformer (STAT) to utilize continuous tactile signals for action\nclassification. We propose spatial and temporal embeddings along with a new\ntemporal pretraining task in our model, which aims to enhance the transformer\nin modeling the spatio-temporal features of tactile signals. Specially, the\ndesigned temporal pretraining task is to differentiate the time order of\ntubelet inputs to model the temporal properties explicitly. Experimental\nresults on a public action classification dataset demonstrate that our model\noutperforms state-of-the-art methods in all metrics.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted by AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15279v1",
    "published_date": "2024-01-21 03:47:57 UTC",
    "updated_date": "2024-01-21 03:47:57 UTC"
  },
  {
    "arxiv_id": "2401.11389v2",
    "title": "MedLM: Exploring Language Models for Medical Question Answering Systems",
    "authors": [
      "Niraj Yagnik",
      "Jay Jhaveri",
      "Vivek Sharma",
      "Gabriel Pila"
    ],
    "abstract": "In the face of rapidly expanding online medical literature, automated systems\nfor aggregating and summarizing information are becoming increasingly crucial\nfor healthcare professionals and patients. Large Language Models (LLMs), with\ntheir advanced generative capabilities, have shown promise in various NLP\ntasks, and their potential in the healthcare domain, particularly for\nClosed-Book Generative QnA, is significant. However, the performance of these\nmodels in domain-specific tasks such as medical Q&A remains largely unexplored.\nThis study aims to fill this gap by comparing the performance of general and\nmedical-specific distilled LMs for medical Q&A. We aim to evaluate the\neffectiveness of fine-tuning domain-specific LMs and compare the performance of\ndifferent families of Language Models. The study will address critical\nquestions about these models' reliability, comparative performance, and\neffectiveness in the context of medical Q&A. The findings will provide valuable\ninsights into the suitability of different LMs for specific applications in the\nmedical domain.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.11389v2",
    "published_date": "2024-01-21 03:37:47 UTC",
    "updated_date": "2024-03-06 03:26:46 UTC"
  },
  {
    "arxiv_id": "2401.11382v2",
    "title": "Using Large Language Model for End-to-End Chinese ASR and NER",
    "authors": [
      "Yuang Li",
      "Jiawei Yu",
      "Min Zhang",
      "Mengxin Ren",
      "Yanqing Zhao",
      "Xiaofeng Zhao",
      "Shimin Tao",
      "Jinsong Su",
      "Hao Yang"
    ],
    "abstract": "Mapping speech tokens to the same feature space as text tokens has become the\nparadigm for the integration of speech modality into decoder-only large\nlanguage models (LLMs). An alternative approach is to use an encoder-decoder\narchitecture that incorporates speech features through cross-attention. This\napproach, however, has received less attention in the literature. In this work,\nwe connect the Whisper encoder with ChatGLM3 and provide in-depth comparisons\nof these two approaches using Chinese automatic speech recognition (ASR) and\nname entity recognition (NER) tasks. We evaluate them not only by conventional\nmetrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NER\nerrors. Our experiments reveal that encoder-decoder architecture outperforms\ndecoder-only architecture with a short context, while decoder-only architecture\nbenefits from a long context as it fully exploits all layers of the LLM. By\nusing LLM, we significantly reduced the entity omission errors and improved the\nentity ASR accuracy compared to the Conformer baseline. Additionally, we\nobtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER test\nset by using chain-of-thought (CoT) NER which first infers long-form ASR\ntranscriptions and then predicts NER labels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 2 figures, Accepted to InterSpeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11382v2",
    "published_date": "2024-01-21 03:15:05 UTC",
    "updated_date": "2024-06-06 05:39:50 UTC"
  },
  {
    "arxiv_id": "2402.16863v1",
    "title": "Quantum Inspired Chaotic Salp Swarm Optimization for Dynamic Optimization",
    "authors": [
      "Sanjai Pathak",
      "Ashish Mani",
      "Mayank Sharma",
      "Amlan Chatterjee"
    ],
    "abstract": "Many real-world problems are dynamic optimization problems that are unknown\nbeforehand. In practice, unpredictable events such as the arrival of new jobs,\ndue date changes, and reservation cancellations, changes in parameters or\nconstraints make the search environment dynamic. Many algorithms are designed\nto deal with stationary optimization problems, but these algorithms do not face\ndynamic optimization problems or manage them correctly. Although some\noptimization algorithms are proposed to deal with the changes in dynamic\nenvironments differently, there are still areas of improvement in existing\nalgorithms due to limitations or drawbacks, especially in terms of locating and\nfollowing the previously identified optima. With this in mind, we studied a\nvariant of SSA known as QSSO, which integrates the principles of quantum\ncomputing. An attempt is made to improve the overall performance of standard\nSSA to deal with the dynamic environment effectively by locating and tracking\nthe global optima for DOPs. This work is an extension of the proposed new\nalgorithm QSSO, known as the Quantum-inspired Chaotic Salp Swarm Optimization\n(QCSSO) Algorithm, which details the various approaches considered while\nsolving DOPs. A chaotic operator is employed with quantum computing to respond\nto change and guarantee to increase individual searchability by improving\npopulation diversity and the speed at which the algorithm converges. We\nexperimented by evaluating QCSSO on a well-known generalized dynamic benchmark\nproblem (GDBG) provided for CEC 2009, followed by a comparative numerical study\nwith well-regarded algorithms. As promised, the introduced QCSSO is discovered\nas the rival algorithm for DOPs.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "14 pages, 2 figures, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2402.16863v1",
    "published_date": "2024-01-21 02:59:37 UTC",
    "updated_date": "2024-01-21 02:59:37 UTC"
  },
  {
    "arxiv_id": "2401.11374v4",
    "title": "Language Models as Hierarchy Encoders",
    "authors": [
      "Yuan He",
      "Zhangdie Yuan",
      "Jiaoyan Chen",
      "Ian Horrocks"
    ],
    "abstract": "Interpreting hierarchical structures latent in language is a key limitation\nof current language models (LMs). While previous research has implicitly\nleveraged these hierarchies to enhance LMs, approaches for their explicit\nencoding are yet to be explored. To address this, we introduce a novel approach\nto re-train transformer encoder-based LMs as Hierarchy Transformer encoders\n(HiTs), harnessing the expansive nature of hyperbolic space. Our method\nsituates the output embedding space of pre-trained LMs within a Poincar\\'e ball\nwith a curvature that adapts to the embedding dimension, followed by training\non hyperbolic clustering and centripetal losses. These losses are designed to\neffectively cluster related entities (input as texts) and organise them\nhierarchically. We evaluate HiTs against pre-trained LMs, standard fine-tuned\nLMs, and several hyperbolic embedding baselines, focusing on their capabilities\nin simulating transitive inference, predicting subsumptions, and transferring\nknowledge across hierarchies. The results demonstrate that HiTs consistently\noutperform all baselines in these tasks, underscoring the effectiveness and\ntransferability of our re-trained hierarchy encoders.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accept at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11374v4",
    "published_date": "2024-01-21 02:29:12 UTC",
    "updated_date": "2024-11-21 00:19:27 UTC"
  },
  {
    "arxiv_id": "2401.11370v1",
    "title": "Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation",
    "authors": [
      "Christian Cabrera",
      "Andrei Paleyes",
      "Neil D. Lawrence"
    ],
    "abstract": "Software systems impact society at different levels as they pervasively solve\nreal-world problems. Modern software systems are often so sophisticated that\ntheir complexity exceeds the limits of human comprehension. These systems must\nrespond to changing goals, dynamic data, unexpected failures, and security\nthreats, among other variable factors in real-world environments. Systems'\ncomplexity challenges their interpretability and requires autonomous responses\nto dynamic changes. Two main research areas explore autonomous systems'\nresponses: evolutionary computing and autonomic computing. Evolutionary\ncomputing focuses on software improvement based on iterative modifications to\nthe source code. Autonomic computing focuses on optimising systems' performance\nby changing their structure, behaviour, or environment variables. Approaches\nfrom both areas rely on feedback loops that accumulate knowledge from the\nsystem interactions to inform autonomous decision-making. However, this\nknowledge is often limited, constraining the systems' interpretability and\nadaptability. This paper proposes a new concept for interpretable and adaptable\nsoftware systems: self-sustaining software systems (S4). S4 builds knowledge\nloops between all available knowledge sources that define modern software\nsystems to improve their interpretability and adaptability. This paper\nintroduces and discusses the S4 concept.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at The 1st International Workshop New Trends in Software\n  Architecture (SATrends) 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.11370v1",
    "published_date": "2024-01-21 02:07:34 UTC",
    "updated_date": "2024-01-21 02:07:34 UTC"
  },
  {
    "arxiv_id": "2401.11361v1",
    "title": "Revolutionizing API Documentation through Summarization",
    "authors": [
      "AmirHossein Naghshzan",
      "Sylvie Ratte"
    ],
    "abstract": "This study tackles the challenges associated with interpreting Application\nProgramming Interface (API) documentation, an integral aspect of software\ndevelopment. Official API documentation, while essential, can be lengthy and\nchallenging to navigate, prompting developers to seek unofficial sources such\nas Stack Overflow. Leveraging the vast user-generated content on Stack\nOverflow, including code snippets and discussions, we employ BERTopic and\nextractive summarization to automatically generate concise and informative API\nsummaries. These summaries encompass key insights like general usage, common\ndeveloper issues, and potential solutions, sourced from the wealth of knowledge\non Stack Overflow. Software developers evaluate these summaries for\nperformance, coherence, and interoperability, providing valuable feedback on\nthe practicality of our approach.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "arXiv admin note: text overlap with arXiv:2308.09070",
    "pdf_url": "http://arxiv.org/pdf/2401.11361v1",
    "published_date": "2024-01-21 01:18:08 UTC",
    "updated_date": "2024-01-21 01:18:08 UTC"
  },
  {
    "arxiv_id": "2401.11360v1",
    "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated Sequence and Structure-Based Peptide Encoding",
    "authors": [
      "Ruochi Zhang",
      "Haoran Wu",
      "Chang Liu",
      "Huaping Li",
      "Yuqian Wu",
      "Kewei Li",
      "Yifan Wang",
      "Yifan Deng",
      "Jiahui Chen",
      "Fengfeng Zhou",
      "Xin Gao"
    ],
    "abstract": "Recent advances in protein language models have catalyzed significant\nprogress in peptide sequence representation. Despite extensive exploration in\nthis field, pre-trained models tailored for peptide-specific needs remain\nlargely unaddressed due to the difficulty in capturing the complex and\nsometimes unstable structures of peptides. This study introduces a novel\nmulti-view contrastive learning framework PepHarmony for the sequence-based\npeptide encoding task. PepHarmony innovatively combines both sequence- and\nstructure-level information into a sequence-level encoding module through\ncontrastive learning. We carefully select datasets from the Protein Data Bank\n(PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences\nand structures. The experimental data highlights PepHarmony's exceptional\ncapability in capturing the intricate relationship between peptide sequences\nand structures compared with the baseline and fine-tuned models. The robustness\nof our model is confirmed through extensive ablation studies, which emphasize\nthe crucial roles of contrastive loss and strategic data sorting in enhancing\npredictive performance. The proposed PepHarmony framework serves as a notable\ncontribution to peptide representations, and offers valuable insights for\nfuture applications in peptide drug discovery and peptide engineering. We have\nmade all the source code utilized in this study publicly accessible via GitHub\nat https://github.com/zhangruochi/PepHarmony or\nhttp://www.healthinformaticslab.org/supp/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.11360v1",
    "published_date": "2024-01-21 01:16:53 UTC",
    "updated_date": "2024-01-21 01:16:53 UTC"
  },
  {
    "arxiv_id": "2401.11351v2",
    "title": "A comprehensive review of Quantum Machine Learning: from NISQ to Fault Tolerance",
    "authors": [
      "Yunfei Wang",
      "Junyu Liu"
    ],
    "abstract": "Quantum machine learning, which involves running machine learning algorithms\non quantum devices, has garnered significant attention in both academic and\nbusiness circles. In this paper, we offer a comprehensive and unbiased review\nof the various concepts that have emerged in the field of quantum machine\nlearning. This includes techniques used in Noisy Intermediate-Scale Quantum\n(NISQ) technologies and approaches for algorithms compatible with\nfault-tolerant quantum computing hardware. Our review covers fundamental\nconcepts, algorithms, and the statistical learning theory pertinent to quantum\nmachine learning.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "quant-ph",
    "comment": "28 pages. Invited review",
    "pdf_url": "http://arxiv.org/pdf/2401.11351v2",
    "published_date": "2024-01-21 00:19:16 UTC",
    "updated_date": "2024-03-31 00:32:13 UTC"
  }
]