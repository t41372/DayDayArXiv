[
  {
    "arxiv_id": "2501.05455v1",
    "title": "Upstream and Downstream AI Safety: Both on the Same River?",
    "authors": [
      "John McDermid",
      "Yan Jia",
      "Ibrahim Habli"
    ],
    "abstract": "Traditional safety engineering assesses systems in their context of use, e.g.\nthe operational design domain (road layout, speed limits, weather, etc.) for\nself-driving vehicles (including those using AI). We refer to this as\ndownstream safety. In contrast, work on safety of frontier AI, e.g. large\nlanguage models which can be further trained for downstream tasks, typically\nconsiders factors that are beyond specific application contexts, such as the\nability of the model to evade human control, or to produce harmful content,\ne.g. how to make bombs. We refer to this as upstream safety. We outline the\ncharacteristics of both upstream and downstream safety frameworks then explore\nthe extent to which the broad AI safety community can benefit from synergies\nbetween these frameworks. For example, can concepts such as common mode\nfailures from downstream safety be used to help assess the strength of AI\nguardrails? Further, can the understanding of the capabilities and limitations\nof frontier AI be used to inform downstream safety analysis, e.g. where LLMs\nare fine-tuned to calculate voyage plans for autonomous vessels? The paper\nidentifies some promising avenues to explore and outlines some challenges in\nachieving synergy, or a confluence, between upstream and downstream safety\nframeworks.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.05455v1",
    "published_date": "2024-12-09 23:33:31 UTC",
    "updated_date": "2024-12-09 23:33:31 UTC"
  },
  {
    "arxiv_id": "2412.07042v1",
    "title": "Generative AI Impact on Labor Market: Analyzing ChatGPT's Demand in Job Advertisements",
    "authors": [
      "Mahdi Ahmadi",
      "Neda Khosh Kheslat",
      "Adebola Akintomide"
    ],
    "abstract": "The rapid advancement of Generative AI (Gen AI) technologies, particularly\ntools like ChatGPT, is significantly impacting the labor market by reshaping\njob roles and skill requirements. This study examines the demand for\nChatGPT-related skills in the U.S. labor market by analyzing job advertisements\ncollected from major job platforms between May and December 2023. Using text\nmining and topic modeling techniques, we extracted and analyzed the Gen\nAI-related skills that employers are hiring for. Our analysis identified five\ndistinct ChatGPT-related skill sets: general familiarity, creative content\ngeneration, marketing, advanced functionalities (such as prompt engineering),\nand product development. In addition, the study provides insights into job\nattributes such as occupation titles, degree requirements, salary ranges, and\nother relevant job characteristics. These findings highlight the increasing\nintegration of Gen AI across various industries, emphasizing the growing need\nfor both foundational knowledge and advanced technical skills. The study offers\nvaluable insights into the evolving demands of the labor market, as employers\nseek candidates equipped to leverage generative AI tools to improve\nproductivity, streamline processes, and drive innovation.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages, 4 figures, 2 tables, submitted to International Journal of\n  Information Management to be reviewed",
    "pdf_url": "http://arxiv.org/pdf/2412.07042v1",
    "published_date": "2024-12-09 23:03:20 UTC",
    "updated_date": "2024-12-09 23:03:20 UTC"
  },
  {
    "arxiv_id": "2412.12143v1",
    "title": "Harnessing Transfer Learning from Swahili: Advancing Solutions for Comorian Dialects",
    "authors": [
      "Naira Abdou Mohamed",
      "Zakarya Erraji",
      "Abdessalam Bahafid",
      "Imade Benelallam"
    ],
    "abstract": "If today some African languages like Swahili have enough resources to develop\nhigh-performing Natural Language Processing (NLP) systems, many other languages\nspoken on the continent are still lacking such support. For these languages,\nstill in their infancy, several possibilities exist to address this critical\nlack of data. Among them is Transfer Learning, which allows low-resource\nlanguages to benefit from the good representation of other languages that are\nsimilar to them. In this work, we adopt a similar approach, aiming to pioneer\nNLP technologies for Comorian, a group of four languages or dialects belonging\nto the Bantu family.\n  Our approach is initially motivated by the hypothesis that if a human can\nunderstand a different language from their native language with little or no\neffort, it would be entirely possible to model this process on a machine. To\nachieve this, we consider ways to construct Comorian datasets mixed with\nSwahili. One thing to note here is that in terms of Swahili data, we only focus\non elements that are closest to Comorian by calculating lexical distances\nbetween candidate and source data. We empirically test this hypothesis in two\nuse cases: Automatic Speech Recognition (ASR) and Machine Translation (MT). Our\nMT model achieved ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.6826, 0.42, and\n0.6532, respectively, while our ASR system recorded a WER of 39.50\\% and a CER\nof 13.76\\%. This research is crucial for advancing NLP in underrepresented\nlanguages, with potential to preserve and promote Comorian linguistic heritage\nin the digital age.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper was presented at the 6th Deep Learning Indaba Conference\n  (DLI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.12143v1",
    "published_date": "2024-12-09 22:47:41 UTC",
    "updated_date": "2024-12-09 22:47:41 UTC"
  },
  {
    "arxiv_id": "2412.07031v2",
    "title": "Large Language Models: An Applied Econometric Framework",
    "authors": [
      "Jens Ludwig",
      "Sendhil Mullainathan",
      "Ashesh Rambachan"
    ],
    "abstract": "How can we use the novel capacities of large language models (LLMs) in\nempirical research? And how can we do so while accounting for their\nlimitations, which are themselves only poorly understood? We develop an\neconometric framework to answer this question that distinguishes between two\ntypes of empirical tasks. Using LLMs for prediction problems (including\nhypothesis generation) is valid under one condition: no ``leakage'' between the\nLLM's training dataset and the researcher's sample. No leakage can be ensured\nby using open-source LLMs with documented training data and published weights.\nUsing LLM outputs for estimation problems to automate the measurement of some\neconomic concept (expressed either by some text or from human subjects)\nrequires the researcher to collect at least some validation data: without such\ndata, the errors of the LLM's automation cannot be assessed and accounted for.\nAs long as these steps are taken, LLM outputs can be used in empirical research\nwith the familiar econometric guarantees we desire. Using two illustrative\napplications to finance and political economy, we find that these requirements\nare stringent; when they are violated, the limitations of LLMs now result in\nunreliable empirical estimates. Our results suggest the excitement around the\nempirical uses of LLMs is warranted -- they allow researchers to effectively\nuse even small amounts of language data for both prediction and estimation --\nbut only with these safeguards in place.",
    "categories": [
      "econ.EM",
      "cs.AI"
    ],
    "primary_category": "econ.EM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07031v2",
    "published_date": "2024-12-09 22:37:48 UTC",
    "updated_date": "2025-01-03 14:19:58 UTC"
  },
  {
    "arxiv_id": "2412.07030v4",
    "title": "FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge Distillation for Question Answering",
    "authors": [
      "Amirhossein Abaskohi",
      "Spandana Gella",
      "Giuseppe Carenini",
      "Issam H. Laradji"
    ],
    "abstract": "Multimodal multihop question answering (MMQA) requires reasoning over images\nand text from multiple sources. Despite advances in visual question answering,\nthis multihop setting remains underexplored due to a lack of quality datasets.\nExisting methods focus on single-hop, single-modality, or short texts, limiting\nreal-world applications like interpreting educational documents with long,\nmultimodal content. To fill this gap, we introduce FM2DS, the first framework\nfor creating a high-quality dataset for MMQA. Our approach consists of a\n5-stage pipeline that involves acquiring relevant multimodal documents from\nWikipedia, synthetically generating high-level questions and answers, and\nvalidating them through rigorous criteria to ensure data quality. We evaluate\nour methodology by training models on our synthesized dataset and testing on\ntwo benchmarks: MultimodalQA and WebQA. Our results demonstrate that, with an\nequal sample size, models trained on our synthesized data outperform those\ntrained on human-collected data by 1.9 in exact match (EM) score on average.\nAdditionally, we introduce M2QA-Bench with 1k samples, the first benchmark for\nMMQA on long documents, generated using FM2DS and refined by human annotators.\nWe believe our data synthesis method will serve as a strong foundation for\ntraining and evaluating MMQA models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07030v4",
    "published_date": "2024-12-09 22:35:44 UTC",
    "updated_date": "2025-04-03 22:39:17 UTC"
  },
  {
    "arxiv_id": "2412.10418v2",
    "title": "Constrained Decoding with Speculative Lookaheads",
    "authors": [
      "Nishanth Nakshatri",
      "Shamik Roy",
      "Rajarshi Das",
      "Suthee Chaidaroon",
      "Leonid Boytsov",
      "Rashmi Gangadharaiah"
    ],
    "abstract": "Constrained decoding with lookahead heuristics (CDLH) is a highly effective\nmethod for aligning LLM generations to human preferences. However, the\nextensive lookahead roll-out operations for each generated token makes CDLH\nprohibitively expensive, resulting in low adoption in practice. In contrast,\ncommon decoding strategies such as greedy decoding are extremely efficient, but\nachieve very low constraint satisfaction. We propose constrained decoding with\nspeculative lookaheads (CDSL), a technique that significantly improves upon the\ninference efficiency of CDLH without experiencing the drastic performance\nreduction seen with greedy decoding. CDSL is motivated by the recently proposed\nidea of speculative decoding that uses a much smaller draft LLM for generation\nand a larger target LLM for verification. In CDSL, the draft model is used to\ngenerate lookaheads which is verified by a combination of target LLM and\ntask-specific reward functions. This process accelerates decoding by reducing\nthe computational burden while maintaining strong performance. We evaluate CDSL\nin two constraint decoding tasks with three LLM families and achieve 2.2x to\n12.15x speedup over CDLH without significant performance reduction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (main) camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2412.10418v2",
    "published_date": "2024-12-09 22:29:57 UTC",
    "updated_date": "2025-02-10 22:51:59 UTC"
  },
  {
    "arxiv_id": "2412.07022v1",
    "title": "Dense Cross-Connected Ensemble Convolutional Neural Networks for Enhanced Model Robustness",
    "authors": [
      "Longwei Wang",
      "Xueqian Li",
      "Zheng Zhang"
    ],
    "abstract": "The resilience of convolutional neural networks against input variations and\nadversarial attacks remains a significant challenge in image recognition tasks.\nMotivated by the need for more robust and reliable image recognition systems,\nwe propose the Dense Cross-Connected Ensemble Convolutional Neural Network\n(DCC-ECNN). This novel architecture integrates the dense connectivity principle\nof DenseNet with the ensemble learning strategy, incorporating intermediate\ncross-connections between different DenseNet paths to facilitate extensive\nfeature sharing and integration. The DCC-ECNN architecture leverages DenseNet's\nefficient parameter usage and depth while benefiting from the robustness of\nensemble learning, ensuring a richer and more resilient feature representation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2412.07022v1",
    "published_date": "2024-12-09 22:09:13 UTC",
    "updated_date": "2024-12-09 22:09:13 UTC"
  },
  {
    "arxiv_id": "2412.07021v2",
    "title": "Sequential Compression Layers for Efficient Federated Learning in Foundational Models",
    "authors": [
      "Navyansh Mahla",
      "Sunny Gupta",
      "Amit Sethi"
    ],
    "abstract": "Federated Learning (FL) has gained popularity for fine-tuning large language\nmodels (LLMs) across multiple nodes, each with its own private data. While LoRA\nhas been widely adopted for parameter efficient federated fine-tuning, recent\ntheoretical and empirical studies highlight its suboptimal performance in the\nfederated learning context. In response, we propose a novel, simple, and more\neffective parameter-efficient fine-tuning method that does not rely on LoRA.\nOur approach introduces a small multi-layer perceptron (MLP) layer between two\nexisting MLP layers the up proj (the FFN projection layer following the\nself-attention module) and down proj within the feed forward network of the\ntransformer block. This solution addresses the bottlenecks associated with LoRA\nin federated fine tuning and outperforms recent LoRA-based approaches,\ndemonstrating superior performance for both language models and vision\nencoders.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07021v2",
    "published_date": "2024-12-09 22:06:47 UTC",
    "updated_date": "2025-03-08 19:47:24 UTC"
  },
  {
    "arxiv_id": "2412.16178v2",
    "title": "Context Clues: Evaluating Long Context Models for Clinical Prediction Tasks on EHRs",
    "authors": [
      "Michael Wornow",
      "Suhana Bedi",
      "Miguel Angel Fuentes Hernandez",
      "Ethan Steinberg",
      "Jason Alan Fries",
      "Christopher Re",
      "Sanmi Koyejo",
      "Nigam H. Shah"
    ],
    "abstract": "Foundation Models (FMs) trained on Electronic Health Records (EHRs) have\nachieved state-of-the-art results on numerous clinical prediction tasks.\nHowever, most existing EHR FMs have context windows of <1k tokens. This\nprevents them from modeling full patient EHRs which can exceed 10k's of events.\nRecent advancements in subquadratic long-context architectures (e.g., Mamba)\noffer a promising solution. However, their application to EHR data has not been\nwell-studied. We address this gap by presenting the first systematic evaluation\nof the effect of context length on modeling EHR data. We find that longer\ncontext models improve predictive performance -- our Mamba-based model\nsurpasses the prior state-of-the-art on 9/14 tasks on the EHRSHOT prediction\nbenchmark. For clinical applications, however, model performance alone is\ninsufficient -- robustness to the unique properties of EHR is crucial. Thus, we\nalso evaluate models across three previously underexplored properties of EHR\ndata: (1) the prevalence of \"copy-forwarded\" diagnoses which creates artificial\nrepetition of tokens within EHR sequences; (2) the irregular time intervals\nbetween EHR events which can lead to a wide range of timespans within a context\nwindow; and (3) the natural increase in disease complexity over time which\nmakes later tokens in the EHR harder to predict than earlier ones. Stratifying\nour EHRSHOT results, we find that higher levels of each property correlate\nnegatively with model performance, but that longer context models are more\nrobust to more extreme levels of these properties. Our work highlights the\npotential for using long-context architectures to model EHR data, and offers a\ncase study for identifying new challenges in modeling sequential data motivated\nby domains outside of natural language. We release our models and code at:\nhttps://github.com/som-shahlab/long_context_clues",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16178v2",
    "published_date": "2024-12-09 21:58:27 UTC",
    "updated_date": "2025-03-18 18:04:32 UTC"
  },
  {
    "arxiv_id": "2412.07017v1",
    "title": "Asynchronous LLM Function Calling",
    "authors": [
      "In Gim",
      "Seung-seob Lee",
      "Lin Zhong"
    ],
    "abstract": "Large language models (LLMs) use function calls to interface with external\ntools and data source. However, the current approach to LLM function calling is\ninherently synchronous, where each call blocks LLM inference, limiting LLM\noperation and concurrent function execution. In this work, we propose AsyncLM,\na system for asynchronous LLM function calling. AsyncLM improves LLM's\noperational efficiency by enabling LLMs to generate and execute function calls\nconcurrently. Instead of waiting for each call's completion, AsyncLM introduces\nan interrupt mechanism to asynchronously notify the LLM in-flight when function\ncalls return. We design an in-context protocol for function calls and\ninterrupts, provide fine-tuning strategy to adapt LLMs to the interrupt\nsemantics, and implement these mechanisms efficiently on LLM inference process.\nWe demonstrate that AsyncLM can reduce end-to-end task completion latency from\n1.6x-5.4x compared to synchronous function calling on a set of benchmark tasks\nin the Berkeley function calling leaderboard (BFCL). Furthermore, we discuss\nhow interrupt mechanisms can be extended to enable novel human-LLM or LLM-LLM\ninteractions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07017v1",
    "published_date": "2024-12-09 21:53:10 UTC",
    "updated_date": "2024-12-09 21:53:10 UTC"
  },
  {
    "arxiv_id": "2501.10366v1",
    "title": "Participatory Assessment of Large Language Model Applications in an Academic Medical Center",
    "authors": [
      "Giorgia Carra",
      "Bogdan Kulynych",
      "François Bastardot",
      "Daniel E. Kaufmann",
      "Noémie Boillat-Blanco",
      "Jean Louis Raisaro"
    ],
    "abstract": "Although Large Language Models (LLMs) have shown promising performance in\nhealthcare-related applications, their deployment in the medical domain poses\nunique challenges of ethical, regulatory, and technical nature. In this study,\nwe employ a systematic participatory approach to investigate the needs and\nexpectations regarding clinical applications of LLMs at Lausanne University\nHospital, an academic medical center in Switzerland. Having identified\npotential LLM use-cases in collaboration with thirty stakeholders, including\nclinical staff across 11 departments as well nursing and patient\nrepresentatives, we assess the current feasibility of these use-cases taking\ninto account the regulatory frameworks, data protection regulation, bias,\nhallucinations, and deployment constraints. This study provides a framework for\na participatory approach to identifying institutional needs with respect to\nintroducing advanced technologies into healthcare practice, and a realistic\nanalysis of the technology readiness level of LLMs for medical applications,\nhighlighting the issues that would need to be overcome LLMs in healthcare to be\nethical, and regulatory compliant.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "MeurIPS GenAI for Health Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.10366v1",
    "published_date": "2024-12-09 21:45:35 UTC",
    "updated_date": "2024-12-09 21:45:35 UTC"
  },
  {
    "arxiv_id": "2412.07012v3",
    "title": "ProVision: Programmatically Scaling Vision-centric Instruction Data for Multimodal Language Models",
    "authors": [
      "Jieyu Zhang",
      "Le Xue",
      "Linxin Song",
      "Jun Wang",
      "Weikai Huang",
      "Manli Shu",
      "An Yan",
      "Zixian Ma",
      "Juan Carlos Niebles",
      "Silvio Savarese",
      "Caiming Xiong",
      "Zeyuan Chen",
      "Ranjay Krishna",
      "Ran Xu"
    ],
    "abstract": "With the rise of multimodal applications, instruction data has become\ncritical for training multimodal language models capable of understanding\ncomplex image-based queries. Existing practices rely on powerful but costly\nlarge language models (LLMs) or multimodal language models (MLMs) to produce\ninstruction data. These are often prone to hallucinations, licensing issues and\nthe generation process is often hard to scale and interpret. In this work, we\npresent a programmatic approach that employs scene graphs as symbolic\nrepresentations of images and human-written programs to systematically\nsynthesize vision-centric instruction data. Our approach ensures the\ninterpretability and controllability of the data generation process and scales\nefficiently while maintaining factual accuracy. By implementing a suite of 24\nsingle-image, 14 multi-image instruction generators, and a scene graph\ngeneration pipeline, we build a scalable, cost-effective system: ProVision\nwhich produces diverse question-answer pairs concerning objects, attributes,\nrelations, depth, etc., for any given image. Applied to Visual Genome and\nDataComp datasets, we generate over 10 million instruction data points,\nProVision-10M, and leverage them in both pretraining and instruction tuning\nstages of MLMs. When adopted in the instruction tuning stage, our single-image\ninstruction data yields up to a 7% improvement on the 2D split and 8% on the 3D\nsplit of CVBench, along with a 3% increase in performance on QBench2,\nRealWorldQA, and MMMU. Our multi-image instruction data leads to an 8%\nimprovement on Mantis-Eval. Incorporation of our data in both pre-training and\nfine-tuning stages of xGen-MM-4B leads to an averaged improvement of 1.6%\nacross 11 benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "code: https://github.com/JieyuZ2/ProVision dataset:\n  https://huggingface.co/datasets/Salesforce/ProVision-10M",
    "pdf_url": "http://arxiv.org/pdf/2412.07012v3",
    "published_date": "2024-12-09 21:44:02 UTC",
    "updated_date": "2024-12-29 03:52:23 UTC"
  },
  {
    "arxiv_id": "2412.07808v2",
    "title": "Boosting Alignment for Post-Unlearning Text-to-Image Generative Models",
    "authors": [
      "Myeongseob Ko",
      "Henry Li",
      "Zhun Wang",
      "Jonathan Patsenker",
      "Jiachen T. Wang",
      "Qinbin Li",
      "Ming Jin",
      "Dawn Song",
      "Ruoxi Jia"
    ],
    "abstract": "Large-scale generative models have shown impressive image-generation\ncapabilities, propelled by massive data. However, this often inadvertently\nleads to the generation of harmful or inappropriate content and raises\ncopyright concerns. Driven by these concerns, machine unlearning has become\ncrucial to effectively purge undesirable knowledge from models. While existing\nliterature has studied various unlearning techniques, these often suffer from\neither poor unlearning quality or degradation in text-image alignment after\nunlearning, due to the competitive nature of these objectives. To address these\nchallenges, we propose a framework that seeks an optimal model update at each\nunlearning iteration, ensuring monotonic improvement on both objectives. We\nfurther derive the characterization of such an update.\n  In addition, we design procedures to strategically diversify the unlearning\nand remaining datasets to boost performance improvement. Our evaluation\ndemonstrates that our method effectively removes target classes from recent\ndiffusion-based generative models and concepts from stable diffusion models\nwhile maintaining close alignment with the models' original trained states,\nthus outperforming state-of-the-art baselines. Our code will be made available\nat https://github.com/reds-lab/Restricted_gradient_diversity_unlearning.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-Eighth Annual Conference on Neural Information Processing\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2412.07808v2",
    "published_date": "2024-12-09 21:36:10 UTC",
    "updated_date": "2025-03-08 22:38:02 UTC"
  },
  {
    "arxiv_id": "2412.07000v2",
    "title": "Extreme AutoML: Analysis of Classification, Regression, and NLP Performance",
    "authors": [
      "Edward Ratner",
      "Elliot Farmer",
      "Brandon Warner",
      "Christopher Douglas",
      "Amaury Lendasse"
    ],
    "abstract": "Utilizing machine learning techniques has always required choosing\nhyperparameters. This is true whether one uses a classical technique such as a\nKNN or very modern neural networks such as Deep Learning. Though in many\napplications, hyperparameters are chosen by hand, automated methods have become\nincreasingly more common. These automated methods have become collectively\nknown as automated machine learning, or AutoML. Several automated selection\nalgorithms have shown similar or improved performance over state-of-the-art\nmethods. This breakthrough has led to the development of cloud-based services\nlike Google AutoML, which is based on Deep Learning and is widely considered to\nbe the industry leader in AutoML services. Extreme Learning Machines (ELMs) use\na fundamentally different type of neural architecture, producing better results\nat a significantly discounted computational cost. We benchmark the Extreme\nAutoML technology against Google's AutoML using several popular classification\ndata sets from the University of California at Irvine's (UCI) repository, and\nseveral other data sets, observing significant advantages for Extreme AutoML in\naccuracy, Jaccard Indices, the variance of Jaccard Indices across classes (i.e.\nclass variance) and training times.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.07000v2",
    "published_date": "2024-12-09 21:10:22 UTC",
    "updated_date": "2024-12-11 15:58:46 UTC"
  },
  {
    "arxiv_id": "2412.06993v1",
    "title": "Toward AI-Driven Digital Organism: Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels",
    "authors": [
      "Le Song",
      "Eran Segal",
      "Eric Xing"
    ],
    "abstract": "We present an approach of using AI to model and simulate biology and life.\nWhy is it important? Because at the core of medicine, pharmacy, public health,\nlongevity, agriculture and food security, environmental protection, and clean\nenergy, it is biology at work. Biology in the physical world is too complex to\nmanipulate and always expensive and risky to tamper with. In this perspective,\nwe layout an engineering viable approach to address this challenge by\nconstructing an AI-Driven Digital Organism (AIDO), a system of integrated\nmultiscale foundation models, in a modular, connectable, and holistic fashion\nto reflect biological scales, connectedness, and complexities. An AIDO opens up\na safe, affordable and high-throughput alternative platform for predicting,\nsimulating and programming biology at all levels from molecules to cells to\nindividuals. We envision that an AIDO is poised to trigger a new wave of\nbetter-guided wet-lab experimentation and better-informed first-principle\nreasoning, which can eventually help us better decode and improve life.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06993v1",
    "published_date": "2024-12-09 20:59:59 UTC",
    "updated_date": "2024-12-09 20:59:59 UTC"
  },
  {
    "arxiv_id": "2412.06989v3",
    "title": "Learning About Algorithm Auditing in Five Steps: Scaffolding How High School Youth Can Systematically and Critically Evaluate Machine Learning Applications",
    "authors": [
      "Luis Morales-Navarro",
      "Yasmin B. Kafai",
      "Lauren Vogelstein",
      "Evelyn Yu",
      "Danaë Metaxa"
    ],
    "abstract": "While there is widespread interest in supporting young people to critically\nevaluate machine learning-powered systems, there is little research on how we\ncan support them in inquiring about how these systems work and what their\nlimitations and implications may be. Outside of K-12 education, an effective\nstrategy in evaluating black-boxed systems is algorithm auditing-a method for\nunderstanding algorithmic systems' opaque inner workings and external impacts\nfrom the outside in. In this paper, we review how expert researchers conduct\nalgorithm audits and how end users engage in auditing practices to propose five\nsteps that, when incorporated into learning activities, can support young\npeople in auditing algorithms. We present a case study of a team of teenagers\nengaging with each step during an out-of-school workshop in which they audited\npeer-designed generative AI TikTok filters. We discuss the kind of scaffolds we\nprovided to support youth in algorithm auditing and directions and challenges\nfor integrating algorithm auditing into classroom activities. This paper\ncontributes: (a) a conceptualization of five steps to scaffold algorithm\nauditing learning activities, and (b) examples of how youth engaged with each\nstep during our pilot study.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "H.5.0; K.4.0; K.7.4"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06989v3",
    "published_date": "2024-12-09 20:55:54 UTC",
    "updated_date": "2025-01-10 19:05:56 UTC"
  },
  {
    "arxiv_id": "2412.10417v1",
    "title": "Leveraging Audio and Text Modalities in Mental Health: A Study of LLMs Performance",
    "authors": [
      "Abdelrahman A. Ali",
      "Aya E. Fouda",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "abstract": "Mental health disorders are increasingly prevalent worldwide, creating an\nurgent need for innovative tools to support early diagnosis and intervention.\nThis study explores the potential of Large Language Models (LLMs) in multimodal\nmental health diagnostics, specifically for detecting depression and Post\nTraumatic Stress Disorder through text and audio modalities. Using the E-DAIC\ndataset, we compare text and audio modalities to investigate whether LLMs can\nperform equally well or better with audio inputs. We further examine the\nintegration of both modalities to determine if this can enhance diagnostic\naccuracy, which generally results in improved performance metrics. Our analysis\nspecifically utilizes custom-formulated metrics; Modal Superiority Score and\nDisagreement Resolvement Score to evaluate how combined modalities influence\nmodel performance. The Gemini 1.5 Pro model achieves the highest scores in\nbinary depression classification when using the combined modality, with an F1\nscore of 0.67 and a Balanced Accuracy (BA) of 77.4%, assessed across the full\ndataset. These results represent an increase of 3.1% over its performance with\nthe text modality and 2.7% over the audio modality, highlighting the\neffectiveness of integrating modalities to enhance diagnostic accuracy.\nNotably, all results are obtained in zero-shot inferring, highlighting the\nrobustness of the models without requiring task-specific fine-tuning. To\nexplore the impact of different configurations on model performance, we conduct\nbinary, severity, and multiclass tasks using both zero-shot and few-shot\nprompts, examining the effects of prompt variations on performance. The results\nreveal that models such as Gemini 1.5 Pro in text and audio modalities, and\nGPT-4o mini in the text modality, often surpass other models in balanced\naccuracy and F1 scores across multiple tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10417v1",
    "published_date": "2024-12-09 20:40:03 UTC",
    "updated_date": "2024-12-09 20:40:03 UTC"
  },
  {
    "arxiv_id": "2412.06975v1",
    "title": "AutoReason: Automatic Few-Shot Reasoning Decomposition",
    "authors": [
      "Arda Sevinc",
      "Abdurrahman Gumus"
    ],
    "abstract": "Chain of Thought (CoT) was introduced in recent research as a method for\nimproving step-by-step reasoning in Large Language Models. However, CoT has\nlimited applications such as its need for hand-crafted few-shot exemplar\nprompts and no capability to adjust itself to different queries.\n  In this work, we propose a system to automatically generate rationales using\nCoT. Our method improves multi-step implicit reasoning capabilities by\ndecomposing the implicit query into several explicit questions. This provides\ninterpretability for the model, improving reasoning in weaker LLMs. We test our\napproach with two Q\\&A datasets: StrategyQA and HotpotQA. We show an increase\nin accuracy with both, especially on StrategyQA.\n  To facilitate further research in this field, the complete source code for\nthis study has been made publicly available on GitHub:\nhttps://github.com/miralab-ai/autoreason.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06975v1",
    "published_date": "2024-12-09 20:35:39 UTC",
    "updated_date": "2024-12-09 20:35:39 UTC"
  },
  {
    "arxiv_id": "2412.06974v1",
    "title": "MV-DUSt3R+: Single-Stage Scene Reconstruction from Sparse Views In 2 Seconds",
    "authors": [
      "Zhenggang Tang",
      "Yuchen Fan",
      "Dilin Wang",
      "Hongyu Xu",
      "Rakesh Ranjan",
      "Alexander Schwing",
      "Zhicheng Yan"
    ],
    "abstract": "Recent sparse multi-view scene reconstruction advances like DUSt3R and MASt3R\nno longer require camera calibration and camera pose estimation. However, they\nonly process a pair of views at a time to infer pixel-aligned pointmaps. When\ndealing with more than two views, a combinatorial number of error prone\npairwise reconstructions are usually followed by an expensive global\noptimization, which often fails to rectify the pairwise reconstruction errors.\nTo handle more views, reduce errors, and improve inference time, we propose the\nfast single-stage feed-forward network MV-DUSt3R. At its core are multi-view\ndecoder blocks which exchange information across any number of views while\nconsidering one reference view. To make our method robust to reference view\nselection, we further propose MV-DUSt3R+, which employs cross-reference-view\nblocks to fuse information across different reference view choices. To further\nenable novel view synthesis, we extend both by adding and jointly training\nGaussian splatting heads. Experiments on multi-view stereo reconstruction,\nmulti-view pose estimation, and novel view synthesis confirm that our methods\nimprove significantly upon prior art. Code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06974v1",
    "published_date": "2024-12-09 20:34:55 UTC",
    "updated_date": "2024-12-09 20:34:55 UTC"
  },
  {
    "arxiv_id": "2412.06966v1",
    "title": "Machine Unlearning Doesn't Do What You Think: Lessons for Generative AI Policy, Research, and Practice",
    "authors": [
      "A. Feder Cooper",
      "Christopher A. Choquette-Choo",
      "Miranda Bogen",
      "Matthew Jagielski",
      "Katja Filippova",
      "Ken Ziyu Liu",
      "Alexandra Chouldechova",
      "Jamie Hayes",
      "Yangsibo Huang",
      "Niloofar Mireshghallah",
      "Ilia Shumailov",
      "Eleni Triantafillou",
      "Peter Kairouz",
      "Nicole Mitchell",
      "Percy Liang",
      "Daniel E. Ho",
      "Yejin Choi",
      "Sanmi Koyejo",
      "Fernando Delgado",
      "James Grimmelmann",
      "Vitaly Shmatikov",
      "Christopher De Sa",
      "Solon Barocas",
      "Amy Cyphert",
      "Mark Lemley",
      "danah boyd",
      "Jennifer Wortman Vaughan",
      "Miles Brundage",
      "David Bau",
      "Seth Neel",
      "Abigail Z. Jacobs",
      "Andreas Terzis",
      "Hanna Wallach",
      "Nicolas Papernot",
      "Katherine Lee"
    ],
    "abstract": "We articulate fundamental mismatches between technical methods for machine\nunlearning in Generative AI, and documented aspirations for broader impact that\nthese methods could have for law and policy. These aspirations are both\nnumerous and varied, motivated by issues that pertain to privacy, copyright,\nsafety, and more. For example, unlearning is often invoked as a solution for\nremoving the effects of targeted information from a generative-AI model's\nparameters, e.g., a particular individual's personal data or in-copyright\nexpression of Spiderman that was included in the model's training data.\nUnlearning is also proposed as a way to prevent a model from generating\ntargeted types of information in its outputs, e.g., generations that closely\nresemble a particular individual's data or reflect the concept of \"Spiderman.\"\nBoth of these goals--the targeted removal of information from a model and the\ntargeted suppression of information from a model's outputs--present various\ntechnical and substantive challenges. We provide a framework for thinking\nrigorously about these challenges, which enables us to be clear about why\nunlearning is not a general-purpose solution for circumscribing generative-AI\nmodel behavior in service of broader positive impact. We aim for conceptual\nclarity and to encourage more thoughtful communication among machine learning\n(ML), law, and policy experts who seek to develop and apply technical methods\nfor compliance with policy objectives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the 2nd Workshop on Generative AI and Law at ICML (July\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.06966v1",
    "published_date": "2024-12-09 20:18:43 UTC",
    "updated_date": "2024-12-09 20:18:43 UTC"
  },
  {
    "arxiv_id": "2412.06958v3",
    "title": "Enhancing operational wind downscaling capabilities over Canada: Application of a Conditional Wasserstein GAN methodology",
    "authors": [
      "Jorge Guevara",
      "Victor Nascimento",
      "Johannes Schmude",
      "Daniel Salles",
      "Simon Corbeil-Létourneau",
      "Madalina Surcel",
      "Dominique Brunet"
    ],
    "abstract": "Wind downscaling is essential for improving the spatial resolution of weather\nforecasts, particularly in operational Numerical Weather Prediction (NWP). This\nstudy advances wind downscaling by extending the DownGAN framework introduced\nby Annau et al.,to operational datasets from the Global Deterministic\nPrediction System (GDPS) and High-Resolution Deterministic Prediction System\n(HRDPS), covering the entire Canadian domain. We enhance the model by\nincorporating high-resolution static covariates, such as HRDPS-derived\ntopography, into a Conditional Wasserstein Generative Adversarial Network with\nGradient Penalty, implemented using a UNET-based generator. Following the\nDownGAN framework, our methodology integrates low-resolution GDPS forecasts (15\nkm, 10-day horizon) and high-resolution HRDPS forecasts (2.5 km, 48-hour\nhorizon) with Frequency Separation techniques adapted from computer vision.\nThrough robust training and inference over the Canadian region, we demonstrate\nthe operational scalability of our approach, achieving significant improvements\nin wind downscaling accuracy. Statistical validation highlights reductions in\nroot mean square error (RMSE) and log spectral distance (LSD) metrics compared\nto the original DownGAN. High-resolution conditioning covariates and Frequency\nSeparation strategies prove instrumental in enhancing model performance. This\nwork underscores the potential for extending high-resolution wind forecasts\nbeyond the 48-hour horizon, bridging the gap to the 10-day low resolution\nglobal forecast window.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06958v3",
    "published_date": "2024-12-09 20:05:07 UTC",
    "updated_date": "2025-02-26 19:34:45 UTC"
  },
  {
    "arxiv_id": "2412.10416v2",
    "title": "SuperMerge: An Approach For Gradient-Based Model Merging",
    "authors": [
      "Haoyu Yang",
      "Zheng Zhang",
      "Saket Sathe"
    ],
    "abstract": "Large language models, such as ChatGPT, Claude, or LLaMA, are gigantic,\nmonolithic, and possess the superpower to simultaneously support thousands of\ntasks. However, high-throughput applications often prefer smaller task-specific\nmodels because of their lower latency and cost. One challenge of using\ntask-specific models is the incremental need for solving newer tasks after the\nmodel is already deployed for existing tasks. A straightforward solution\nrequires fine-tuning the model again for both existing and new tasks, which is\ncomputationally expensive and time-consuming. To address this issue, we propose\na model merging based approach called SUPERMERGE. SUPERMERGE is a\ngradient-based method to systematically merge several fine-tuned models trained\non existing and new tasks. SUPERMERGE is designed to be lightweight and fast,\nand the merged model achieves similar performance to fully fine-tuned models on\nall tasks. Furthermore, we proposed a hierarchical model merging strategy to\nreduce the peak space requirement without sacrificing the performance of the\nmerged model. We experimentally demonstrate that SUPERMERGE outperforms\nexisting model merging methods on common natural language processing and\ncomputer vision tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10416v2",
    "published_date": "2024-12-09 20:03:14 UTC",
    "updated_date": "2025-02-14 17:40:13 UTC"
  },
  {
    "arxiv_id": "2412.06949v2",
    "title": "Bridging Conversational and Collaborative Signals for Conversational Recommendation",
    "authors": [
      "Ahmad Bin Rabiah",
      "Nafis Sadeq",
      "Julian McAuley"
    ],
    "abstract": "Conversational recommendation systems (CRS) leverage contextual information\nfrom conversations to generate recommendations but often struggle due to a lack\nof collaborative filtering (CF) signals, which capture user-item interaction\npatterns essential for accurate recommendations. We introduce Reddit-ML32M, a\ndataset that links Reddit conversations with interactions on MovieLens 32M, to\nenrich item representations by leveraging collaborative knowledge and\naddressing interaction sparsity in conversational datasets. We propose an\nLLM-based framework that uses Reddit-ML32M to align LLM-generated\nrecommendations with CF embeddings, refining rankings for better performance.\nWe evaluate our framework against three sets of baselines: CF-based\nrecommenders using only interactions from CRS tasks, traditional CRS models,\nand LLM-based methods relying on conversational context without item\nrepresentations. Our approach achieves consistent improvements, including a\n12.32% increase in Hit Rate and a 9.9% improvement in NDCG, outperforming the\nbest-performing baseline that relies on conversational context but lacks\ncollaborative item representations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06949v2",
    "published_date": "2024-12-09 19:53:13 UTC",
    "updated_date": "2025-02-10 21:34:00 UTC"
  },
  {
    "arxiv_id": "2412.07806v1",
    "title": "Diagnosis and Severity Assessment of Ulcerative Colitis using Self Supervised Learning",
    "authors": [
      "Venkat Margapuri"
    ],
    "abstract": "Ulcerative Colitis (UC) is an incurable inflammatory bowel disease that leads\nto ulcers along the large intestine and rectum. The increase in the prevalence\nof UC coupled with gastrointestinal physician shortages stresses the healthcare\nsystem and limits the care UC patients receive. A colonoscopy is performed to\ndiagnose UC and assess its severity based on the Mayo Endoscopic Score (MES).\nThe MES ranges between zero and three, wherein zero indicates no inflammation\nand three indicates that the inflammation is markedly high. Artificial\nIntelligence (AI)-based neural network models, such as convolutional neural\nnetworks (CNNs) are capable of analyzing colonoscopies to diagnose and\ndetermine the severity of UC by modeling colonoscopy analysis as a multi-class\nclassification problem. Prior research for AI-based UC diagnosis relies on\nsupervised learning approaches that require large annotated datasets to train\nthe CNNs. However, creating such datasets necessitates that domain experts\ninvest a significant amount of time, rendering the process expensive and\nchallenging. To address the challenge, this research employs self-supervised\nlearning (SSL) frameworks that can efficiently train on unannotated datasets to\nanalyze colonoscopies and, aid in diagnosing UC and its severity. A comparative\nanalysis with supervised learning models shows that SSL frameworks, such as\nSwAV and SparK outperform supervised learning models on the LIMUC dataset, the\nlargest publicly available annotated dataset of colonoscopy images for UC.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07806v1",
    "published_date": "2024-12-09 19:51:06 UTC",
    "updated_date": "2024-12-09 19:51:06 UTC"
  },
  {
    "arxiv_id": "2412.06947v3",
    "title": "PyraNet: A Multi-Layered Hierarchical Dataset for Verilog",
    "authors": [
      "Bardia Nadimi",
      "Ghali Omar Boutaib",
      "Hao Zheng"
    ],
    "abstract": "Recently, there has been a growing interest in leveraging Large Language\nModels for Verilog code generation. However, the current quality of the\ngenerated Verilog code remains suboptimal. This is largely due to the absence\nof well-defined, well-organized datasets with high-quality samples, as well as\na lack of innovative fine-tuning methods and models specifically trained on\nVerilog. In this paper, we introduce a novel open-source dataset and a\ncorresponding fine-tuning technique, which utilizes a multi-layered structure\nthat we refer to as PyraNet. Our experiments demonstrate that employing the\nproposed dataset and fine-tuning approach leads to a more accurate fine-tuned\nmodel, producing syntactically and functionally correct Verilog code. The\nevaluation results show improvements by up-to $32.6\\%$ in comparison to the\nCodeLlama-7B baseline model and up-to $16.7\\%$ in comparison to the\nstate-of-the-art models using VerilogEval evaluation platform.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06947v3",
    "published_date": "2024-12-09 19:45:54 UTC",
    "updated_date": "2025-04-07 21:58:26 UTC"
  },
  {
    "arxiv_id": "2501.10365v1",
    "title": "Can LLMs Identify Gaps and Misconceptions in Students' Code Explanations?",
    "authors": [
      "Priti Oli",
      "Rabin Banjade",
      "Andrew M. Olney",
      "Vasile Rus"
    ],
    "abstract": "This paper investigates various approaches using Large Language Models (LLMs)\nto identify gaps and misconceptions in students' self-explanations of specific\ninstructional material, in our case explanations of code examples. This\nresearch is a part of our larger effort to automate the assessment of students'\nfreely generated responses, focusing specifically on their self-explanations of\ncode examples during activities related to code comprehension. In this work, we\nexperiment with zero-shot prompting, Supervised Fine-Tuning (SFT), and\npreference alignment of LLMs to identify gaps in students' self-explanation.\nWith simple prompting, GPT-4 consistently outperformed LLaMA3 and Mistral in\nidentifying gaps and misconceptions, as confirmed by human evaluations.\nAdditionally, our results suggest that fine-tuned large language models are\nmore effective at identifying gaps in students' explanations compared to\nzero-shot and few-shot prompting techniques. Furthermore, our findings show\nthat the preference optimization approach using Odds Ratio Preference\nOptimization (ORPO) outperforms SFT in identifying gaps and misconceptions in\nstudents' code explanations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10365v1",
    "published_date": "2024-12-09 19:42:23 UTC",
    "updated_date": "2024-12-09 19:42:23 UTC"
  },
  {
    "arxiv_id": "2412.06936v1",
    "title": "Creating a Cooperative AI Policymaking Platform through Open Source Collaboration",
    "authors": [
      "Aiden Lewington",
      "Alekhya Vittalam",
      "Anshumaan Singh",
      "Anuja Uppuluri",
      "Arjun Ashok",
      "Ashrith Mandayam Athmaram",
      "Austin Milt",
      "Benjamin Smith",
      "Charlie Weinberger",
      "Chatanya Sarin",
      "Christoph Bergmeir",
      "Cliff Chang",
      "Daivik Patel",
      "Daniel Li",
      "David Bell",
      "Defu Cao",
      "Donghwa Shin",
      "Edward Kang",
      "Edwin Zhang",
      "Enhui Li",
      "Felix Chen",
      "Gabe Smithline",
      "Haipeng Chen",
      "Henry Gasztowtt",
      "Hoon Shin",
      "Jiayun Zhang",
      "Joshua Gray",
      "Khai Hern Low",
      "Kishan Patel",
      "Lauren Hannah Cooke",
      "Marco Burstein",
      "Maya Kalapatapu",
      "Mitali Mittal",
      "Raymond Chen",
      "Rosie Zhao",
      "Sameen Majid",
      "Samya Potlapalli",
      "Shang Wang",
      "Shrenik Patel",
      "Shuheng Li",
      "Siva Komaragiri",
      "Song Lu",
      "Sorawit Siangjaeo",
      "Sunghoo Jung",
      "Tianyu Zhang",
      "Valery Mao",
      "Vikram Krishnakumar",
      "Vincent Zhu",
      "Wesley Kam",
      "Xingzhe Li",
      "Yumeng Liu"
    ],
    "abstract": "Advances in artificial intelligence (AI) present significant risks and\nopportunities, requiring improved governance to mitigate societal harms and\npromote equitable benefits. Current incentive structures and regulatory delays\nmay hinder responsible AI development and deployment, particularly in light of\nthe transformative potential of large language models (LLMs). To address these\nchallenges, we propose developing the following three contributions: (1) a\nlarge multimodal text and economic-timeseries foundation model that integrates\neconomic and natural language policy data for enhanced forecasting and\ndecision-making, (2) algorithmic mechanisms for eliciting diverse and\nrepresentative perspectives, enabling the creation of data-driven public policy\nrecommendations, and (3) an AI-driven web platform for supporting transparent,\ninclusive, and data-driven policymaking.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06936v1",
    "published_date": "2024-12-09 19:25:29 UTC",
    "updated_date": "2024-12-09 19:25:29 UTC"
  },
  {
    "arxiv_id": "2412.06926v5",
    "title": "When Every Token Counts: Optimal Segmentation for Low-Resource Language Models",
    "authors": [
      "Bharath Raj",
      "Garvit Suri",
      "Vikrant Dewangan",
      "Raghav Sonavane"
    ],
    "abstract": "Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "LoResLM @ COLING 2025. Project page at\n  https://vikr-182.github.io/loreslm/",
    "pdf_url": "http://arxiv.org/pdf/2412.06926v5",
    "published_date": "2024-12-09 19:11:54 UTC",
    "updated_date": "2025-05-01 18:15:36 UTC"
  },
  {
    "arxiv_id": "2412.16177v1",
    "title": "Mining Math Conjectures from LLMs: A Pruning Approach",
    "authors": [
      "Jake Chuharski",
      "Elias Rojas Collins",
      "Mark Meringolo"
    ],
    "abstract": "We present a novel approach to generating mathematical conjectures using\nLarge Language Models (LLMs). Focusing on the solubilizer, a relatively recent\nconstruct in group theory, we demonstrate how LLMs such as ChatGPT, Gemini, and\nClaude can be leveraged to generate conjectures. These conjectures are pruned\nby allowing the LLMs to generate counterexamples. Our results indicate that\nLLMs are capable of producing original conjectures that, while not\ngroundbreaking, are either plausible or falsifiable via counterexamples, though\nthey exhibit limitations in code execution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 10 figures, NeurIPS MathAI Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.16177v1",
    "published_date": "2024-12-09 19:00:38 UTC",
    "updated_date": "2024-12-09 19:00:38 UTC"
  },
  {
    "arxiv_id": "2412.06787v2",
    "title": "[MASK] is All You Need",
    "authors": [
      "Vincent Tao Hu",
      "Björn Ommer"
    ],
    "abstract": "In generative models, two paradigms have gained attraction in various\napplications: next-set prediction-based Masked Generative Models and next-noise\nprediction-based Non-Autoregressive Models, e.g., Diffusion Models. In this\nwork, we propose using discrete-state models to connect them and explore their\nscalability in the vision domain. First, we conduct a step-by-step analysis in\na unified design space across two types of models including\ntimestep-independence, noise schedule, temperature, guidance strength, etc in a\nscalable manner. Second, we re-cast typical discriminative tasks, e.g., image\nsegmentation, as an unmasking process from [MASK] tokens on a discrete-state\nmodel. This enables us to perform various sampling processes, including\nflexible conditional sampling by only training once to model the joint\ndistribution. All aforementioned explorations lead to our framework named\nDiscrete Interpolants, which enables us to achieve state-of-the-art or\ncompetitive performance compared to previous discrete-state based methods in\nvarious benchmarks, like ImageNet256, MS COCO, and video dataset FaceForensics.\nIn summary, by leveraging [MASK] in discrete-state models, we can bridge Masked\nGenerative and Non-autoregressive Diffusion models, as well as generative and\ndiscriminative tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report (WIP), Project Page(code, model, dataset):\n  https://compvis.github.io/mask/",
    "pdf_url": "http://arxiv.org/pdf/2412.06787v2",
    "published_date": "2024-12-09 18:59:56 UTC",
    "updated_date": "2024-12-10 14:09:22 UTC"
  },
  {
    "arxiv_id": "2412.06784v1",
    "title": "P3-PO: Prescriptive Point Priors for Visuo-Spatial Generalization of Robot Policies",
    "authors": [
      "Mara Levy",
      "Siddhant Haldar",
      "Lerrel Pinto",
      "Abhinav Shirivastava"
    ],
    "abstract": "Developing generalizable robot policies that can robustly handle varied\nenvironmental conditions and object instances remains a fundamental challenge\nin robot learning. While considerable efforts have focused on collecting large\nrobot datasets and developing policy architectures to learn from such data,\nnaively learning from visual inputs often results in brittle policies that fail\nto transfer beyond the training data. This work presents Prescriptive Point\nPriors for Policies or P3-PO, a novel framework that constructs a unique state\nrepresentation of the environment leveraging recent advances in computer vision\nand robot learning to achieve improved out-of-distribution generalization for\nrobot manipulation. This representation is obtained through two steps. First, a\nhuman annotator prescribes a set of semantically meaningful points on a single\ndemonstration frame. These points are then propagated through the dataset using\noff-the-shelf vision models. The derived points serve as an input to\nstate-of-the-art policy architectures for policy learning. Our experiments\nacross four real-world tasks demonstrate an overall 43% absolute improvement\nover prior methods when evaluated in identical settings as training. Further,\nP3-PO exhibits 58% and 80% gains across tasks for new object instances and more\ncluttered environments respectively. Videos illustrating the robot's\nperformance are best viewed at point-priors.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06784v1",
    "published_date": "2024-12-09 18:59:42 UTC",
    "updated_date": "2024-12-09 18:59:42 UTC"
  },
  {
    "arxiv_id": "2412.06779v2",
    "title": "AnyBimanual: Transferring Unimanual Policy for General Bimanual Manipulation",
    "authors": [
      "Guanxing Lu",
      "Tengbo Yu",
      "Haoyuan Deng",
      "Season Si Chen",
      "Yansong Tang",
      "Ziwei Wang"
    ],
    "abstract": "Performing general language-conditioned bimanual manipulation tasks is of\ngreat importance for many applications ranging from household service to\nindustrial assembly. However, collecting bimanual manipulation data is\nexpensive due to the high-dimensional action space, which poses challenges for\nconventional methods to handle general bimanual manipulation tasks. In\ncontrast, unimanual policy has recently demonstrated impressive\ngeneralizability across a wide range of tasks because of scaled model\nparameters and training data, which can provide sharable manipulation knowledge\nfor bimanual systems. To this end, we propose a plug-and-play method named\nAnyBimanual, which transfers pre-trained unimanual policy to general bimanual\nmanipulation policy with few bimanual demonstrations. Specifically, we first\nintroduce a skill manager to dynamically schedule the skill representations\ndiscovered from pre-trained unimanual policy for bimanual manipulation tasks,\nwhich linearly combines skill primitives with task-oriented compensation to\nrepresent the bimanual manipulation instruction. To mitigate the observation\ndiscrepancy between unimanual and bimanual systems, we present a visual aligner\nto generate soft masks for visual embedding of the workspace, which aims to\nalign visual input of unimanual policy model for each arm with those during\npretraining stage. AnyBimanual shows superiority on 12 simulated tasks from\nRLBench2 with a sizable 12.67% improvement in success rate over previous\nmethods. Experiments on 9 real-world tasks further verify its practicality with\nan average success rate of 84.62%.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page: https://anybimanual.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.06779v2",
    "published_date": "2024-12-09 18:58:43 UTC",
    "updated_date": "2025-03-27 02:34:48 UTC"
  },
  {
    "arxiv_id": "2412.06777v1",
    "title": "Driv3R: Learning Dense 4D Reconstruction for Autonomous Driving",
    "authors": [
      "Xin Fei",
      "Wenzhao Zheng",
      "Yueqi Duan",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Kurt Keutzer",
      "Jiwen Lu"
    ],
    "abstract": "Realtime 4D reconstruction for dynamic scenes remains a crucial challenge for\nautonomous driving perception. Most existing methods rely on depth estimation\nthrough self-supervision or multi-modality sensor fusion. In this paper, we\npropose Driv3R, a DUSt3R-based framework that directly regresses per-frame\npoint maps from multi-view image sequences. To achieve streaming dense\nreconstruction, we maintain a memory pool to reason both spatial relationships\nacross sensors and dynamic temporal contexts to enhance multi-view 3D\nconsistency and temporal integration. Furthermore, we employ a 4D flow\npredictor to identify moving objects within the scene to direct our network\nfocus more on reconstructing these dynamic regions. Finally, we align all\nper-frame pointmaps consistently to the world coordinate system in an\noptimization-free manner. We conduct extensive experiments on the large-scale\nnuScenes dataset to evaluate the effectiveness of our method. Driv3R\noutperforms previous frameworks in 4D dynamic scene reconstruction, achieving\n15x faster inference speed compared to methods requiring global alignment.\nCode: https://github.com/Barrybarry-Smith/Driv3R.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at: https://github.com/Barrybarry-Smith/Driv3R",
    "pdf_url": "http://arxiv.org/pdf/2412.06777v1",
    "published_date": "2024-12-09 18:58:03 UTC",
    "updated_date": "2024-12-09 18:58:03 UTC"
  },
  {
    "arxiv_id": "2412.06775v1",
    "title": "Delve into Visual Contrastive Decoding for Hallucination Mitigation of Large Vision-Language Models",
    "authors": [
      "Yi-Lun Lee",
      "Yi-Hsuan Tsai",
      "Wei-Chen Chiu"
    ],
    "abstract": "While large vision-language models (LVLMs) have shown impressive capabilities\nin generating plausible responses correlated with input visual contents, they\nstill suffer from hallucinations, where the generated text inaccurately\nreflects visual contents. To address this, recent approaches apply contrastive\ndecoding to calibrate the model's response via contrasting output distributions\nwith original and visually distorted samples, demonstrating promising\nhallucination mitigation in a training-free manner. However, the potential of\nchanging information in visual inputs is not well-explored, so a deeper\ninvestigation into the behaviors of visual contrastive decoding is of great\ninterest. In this paper, we first explore various methods for contrastive\ndecoding to change visual contents, including image downsampling and editing.\nDownsampling images reduces the detailed textual information while editing\nyields new contents in images, providing new aspects as visual contrastive\nsamples. To further study benefits by using different contrastive samples, we\nanalyze probability-level metrics, including entropy and distribution distance.\nInterestingly, the effect of these samples in mitigating hallucinations varies\na lot across LVLMs and benchmarks. Based on our analysis, we propose a simple\nyet effective method to combine contrastive samples, offering a practical\nsolution for applying contrastive decoding across various scenarios. Extensive\nexperiments are conducted to validate the proposed fusion method among\ndifferent benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review. Project pages: https://github.com/YiLunLee/VCD_Analysis",
    "pdf_url": "http://arxiv.org/pdf/2412.06775v1",
    "published_date": "2024-12-09 18:57:57 UTC",
    "updated_date": "2024-12-09 18:57:57 UTC"
  },
  {
    "arxiv_id": "2412.06774v1",
    "title": "Visual Lexicon: Rich Image Features in Language Space",
    "authors": [
      "XuDong Wang",
      "Xingyi Zhou",
      "Alireza Fathi",
      "Trevor Darrell",
      "Cordelia Schmid"
    ],
    "abstract": "We present Visual Lexicon, a novel visual language that encodes rich image\ninformation into the text space of vocabulary tokens while retaining intricate\nvisual details that are often challenging to convey in natural language. Unlike\ntraditional methods that prioritize either high-level semantics (e.g., CLIP) or\npixel-level reconstruction (e.g., VAE), ViLex simultaneously captures rich\nsemantic content and fine visual details, enabling high-quality image\ngeneration and comprehensive visual scene understanding. Through a\nself-supervised learning pipeline, ViLex generates tokens optimized for\nreconstructing input images using a frozen text-to-image (T2I) diffusion model,\npreserving the detailed information necessary for high-fidelity semantic-level\nreconstruction. As an image embedding in the language space, ViLex tokens\nleverage the compositionality of natural languages, allowing them to be used\nindependently as \"text tokens\" or combined with natural language tokens to\nprompt pretrained T2I models with both visual and textual inputs, mirroring how\nwe interact with vision-language models (VLMs). Experiments demonstrate that\nViLex achieves higher fidelity in image reconstruction compared to text\nembeddings--even with a single ViLex token. Moreover, ViLex successfully\nperforms various DreamBooth tasks in a zero-shot, unsupervised manner without\nfine-tuning T2I models. Additionally, ViLex serves as a powerful vision\nencoder, consistently improving vision-language model performance across 15\nbenchmarks relative to a strong SigLIP baseline.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Tech report. 16 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06774v1",
    "published_date": "2024-12-09 18:57:24 UTC",
    "updated_date": "2024-12-09 18:57:24 UTC"
  },
  {
    "arxiv_id": "2412.06771v1",
    "title": "Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty",
    "authors": [
      "Meera Hahn",
      "Wenjun Zeng",
      "Nithish Kannen",
      "Rich Galt",
      "Kartikeya Badola",
      "Been Kim",
      "Zi Wang"
    ],
    "abstract": "User prompts for generative AI models are often underspecified, leading to\nsub-optimal responses. This problem is particularly evident in text-to-image\n(T2I) generation, where users commonly struggle to articulate their precise\nintent. This disconnect between the user's vision and the model's\ninterpretation often forces users to painstakingly and repeatedly refine their\nprompts. To address this, we propose a design for proactive T2I agents equipped\nwith an interface to (1) actively ask clarification questions when uncertain,\nand (2) present their understanding of user intent as an understandable belief\ngraph that a user can edit. We build simple prototypes for such agents and\nverify their effectiveness through both human studies and automated evaluation.\nWe observed that at least 90% of human subjects found these agents and their\nbelief graphs helpful for their T2I workflow. Moreover, we develop a scalable\nautomated evaluation approach using two agents, one with a ground truth image\nand the other tries to ask as few questions as possible to align with the\nground truth. On DesignBench, a benchmark we created for artists and designers,\nthe COCO dataset (Lin et al., 2014), and ImageInWords (Garg et al., 2024), we\nobserved that these T2I agents were able to ask informative questions and\nelicit crucial information to achieve successful alignment with at least 2\ntimes higher VQAScore (Lin et al., 2024) than the standard single-turn T2I\ngeneration. Demo: https://github.com/google-deepmind/proactive_t2i_agents.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06771v1",
    "published_date": "2024-12-09 18:56:32 UTC",
    "updated_date": "2024-12-09 18:56:32 UTC"
  },
  {
    "arxiv_id": "2412.06759v2",
    "title": "XRZoo: A Large-Scale and Versatile Dataset of Extended Reality (XR) Applications",
    "authors": [
      "Shuqing Li",
      "Chenran Zhang",
      "Cuiyun Gao",
      "Michael R. Lyu"
    ],
    "abstract": "The rapid advancement of Extended Reality (XR, encompassing AR, MR, and VR)\nand spatial computing technologies forms a foundational layer for the emerging\nMetaverse, enabling innovative applications across healthcare, education,\nmanufacturing, and entertainment. However, research in this area is often\nlimited by the lack of large, representative, and highquality application\ndatasets that can support empirical studies and the development of new\napproaches benefiting XR software processes. In this paper, we introduce XRZoo,\na comprehensive and curated dataset of XR applications designed to bridge this\ngap. XRZoo contains 12,528 free XR applications, spanning nine app stores,\nacross all XR techniques (i.e., AR, MR, and VR) and use cases, with detailed\nmetadata on key aspects such as application descriptions, application\ncategories, release dates, user review numbers, and hardware specifications,\netc. By making XRZoo publicly available, we aim to foster reproducible XR\nsoftware engineering and security research, enable cross-disciplinary\ninvestigations, and also support the development of advanced XR systems by\nproviding examples to developers. Our dataset serves as a valuable resource for\nresearchers and practitioners interested in improving the scalability,\nusability, and effectiveness of XR applications. XRZoo will be released and\nactively maintained.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06759v2",
    "published_date": "2024-12-09 18:49:27 UTC",
    "updated_date": "2024-12-10 18:54:11 UTC"
  },
  {
    "arxiv_id": "2412.06877v1",
    "title": "LLMs for Generalizable Language-Conditioned Policy Learning under Minimal Data Requirements",
    "authors": [
      "Thomas Pouplin",
      "Katarzyna Kobalczyk",
      "Hao Sun",
      "Mihaela van der Schaar"
    ],
    "abstract": "To develop autonomous agents capable of executing complex, multi-step\ndecision-making tasks as specified by humans in natural language, existing\nreinforcement learning approaches typically require expensive labeled datasets\nor access to real-time experimentation. Moreover, conventional methods often\nface difficulties in generalizing to unseen goals and states, thereby limiting\ntheir practical applicability. This paper presents TEDUO, a novel training\npipeline for offline language-conditioned policy learning. TEDUO operates on\neasy-to-obtain, unlabeled datasets and is suited for the so-called in-the-wild\nevaluation, wherein the agent encounters previously unseen goals and states. To\naddress the challenges posed by such data and evaluation settings, our method\nleverages the prior knowledge and instruction-following capabilities of large\nlanguage models (LLMs) to enhance the fidelity of pre-collected offline data\nand enable flexible generalization to new goals and states. Empirical results\ndemonstrate that the dual role of LLMs in our framework-as data enhancers and\ngeneralizers-facilitates both effective and data-efficient learning of\ngeneralizable language-conditioned policies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06877v1",
    "published_date": "2024-12-09 18:43:56 UTC",
    "updated_date": "2024-12-09 18:43:56 UTC"
  },
  {
    "arxiv_id": "2412.06742v2",
    "title": "ContRail: A Framework for Realistic Railway Image Synthesis using ControlNet",
    "authors": [
      "Andrei-Robert Alexandrescu",
      "Razvan-Gabriel Petec",
      "Alexandru Manole",
      "Laura-Silvia Diosan"
    ],
    "abstract": "Deep Learning became an ubiquitous paradigm due to its extraordinary\neffectiveness and applicability in numerous domains. However, the approach\nsuffers from the high demand of data required to achieve the potential of this\ntype of model. An ever-increasing sub-field of Artificial Intelligence, Image\nSynthesis, aims to address this limitation through the design of intelligent\nmodels capable of creating original and realistic images, endeavour which could\ndrastically reduce the need for real data. The Stable Diffusion generation\nparadigm recently propelled state-of-the-art approaches to exceed all previous\nbenchmarks. In this work, we propose the ContRail framework based on the novel\nStable Diffusion model ControlNet, which we empower through a multi-modal\nconditioning method. We experiment with the task of synthetic railway image\ngeneration, where we improve the performance in rail-specific tasks, such as\nrail semantic segmentation by enriching the dataset with realistic synthetic\nimages.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.06742v2",
    "published_date": "2024-12-09 18:34:49 UTC",
    "updated_date": "2024-12-10 13:23:18 UTC"
  },
  {
    "arxiv_id": "2412.06717v1",
    "title": "Toward Non-Invasive Diagnosis of Bankart Lesions with Deep Learning",
    "authors": [
      "Sahil Sethi",
      "Sai Reddy",
      "Mansi Sakarvadia",
      "Jordan Serotte",
      "Darlington Nwaudo",
      "Nicholas Maassen",
      "Lewis Shi"
    ],
    "abstract": "Bankart lesions, or anterior-inferior glenoid labral tears, are\ndiagnostically challenging on standard MRIs due to their subtle imaging\nfeatures-often necessitating invasive MRI arthrograms (MRAs). This study\ndevelops deep learning (DL) models to detect Bankart lesions on both standard\nMRIs and MRAs, aiming to improve diagnostic accuracy and reduce reliance on\nMRAs. We curated a dataset of 586 shoulder MRIs (335 standard, 251 MRAs) from\n558 patients who underwent arthroscopy. Ground truth labels were derived from\nintraoperative findings, the gold standard for Bankart lesion diagnosis.\nSeparate DL models for MRAs and standard MRIs were trained using the Swin\nTransformer architecture, pre-trained on a public knee MRI dataset. Predictions\nfrom sagittal, axial, and coronal views were ensembled to optimize performance.\nThe models were evaluated on a 20% hold-out test set (117 MRIs: 46 MRAs, 71\nstandard MRIs). Bankart lesions were identified in 31.9% of MRAs and 8.6% of\nstandard MRIs. The models achieved AUCs of 0.87 (86% accuracy, 83% sensitivity,\n86% specificity) and 0.90 (85% accuracy, 82% sensitivity, 86% specificity) on\nstandard MRIs and MRAs, respectively. These results match or surpass\nradiologist performance on our dataset and reported literature metrics.\nNotably, our model's performance on non-invasive standard MRIs matched or\nsurpassed the radiologists interpreting MRAs. This study demonstrates the\nfeasibility of using DL to address the diagnostic challenges posed by subtle\npathologies like Bankart lesions. Our models demonstrate potential to improve\ndiagnostic confidence, reduce reliance on invasive imaging, and enhance\naccessibility to care.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for presentation at SPIE Medical Imaging 2025:\n  Computer-Aided Diagnosis. The manuscript is expected to appear in the\n  conference proceedings",
    "pdf_url": "http://arxiv.org/pdf/2412.06717v1",
    "published_date": "2024-12-09 18:04:27 UTC",
    "updated_date": "2024-12-09 18:04:27 UTC"
  },
  {
    "arxiv_id": "2412.06709v1",
    "title": "Parkinson's Disease Diagnosis Through Deep Learning: A Novel LSTM-Based Approach for Freezing of Gait Detection",
    "authors": [
      "Aqib Nazir Mir",
      "Iqra Nissar",
      "Mumtaz Ahmed",
      "Sarfaraz Masood",
      "Danish Raza Rizvi"
    ],
    "abstract": "Deep learning holds tremendous potential in healthcare for uncovering hidden\npatterns within extensive clinical datasets, aiding in the diagnosis of various\ndiseases. Parkinson's disease (PD) is a neurodegenerative condition\ncharacterized by the deterioration of brain function. In the initial stages of\nPD, automatic diagnosis poses a challenge due to the similarity in behavior\nbetween individuals with PD and those who are healthy. Our objective is to\npropose an effective model that can aid in the early detection of Parkinson's\ndisease. We employed the VGRF gait signal dataset sourced from Physionet for\ndistinguishing between healthy individuals and those diagnosed with Parkinson's\ndisease. This paper introduces a novel deep learning architecture based on the\nLSTM network for automatically detecting freezing of gait episodes in\nParkinson's disease patients. In contrast to conventional machine learning\nalgorithms, this method eliminates manual feature engineering and proficiently\ncaptures prolonged temporal dependencies in gait patterns, thereby improving\nthe diagnosis of Parkinson's disease. The LSTM network resolves the issue of\nvanishing gradients by employing memory blocks in place of self-connected\nhidden units, allowing for optimal information assimilation. To prevent\noverfitting, dropout and L2 regularization techniques have been employed.\nAdditionally, the stochastic gradient-based optimizer Adam is used for the\noptimization process. The results indicate that our proposed approach surpasses\ncurrent state-of-the-art models in FOG episode detection, achieving an accuracy\nof 97.71%, sensitivity of 99%, precision of 98%, and specificity of 96%. This\ndemonstrates its potential as a superior classification method for Parkinson's\ndisease detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06709v1",
    "published_date": "2024-12-09 17:58:24 UTC",
    "updated_date": "2024-12-09 17:58:24 UTC"
  },
  {
    "arxiv_id": "2412.06703v1",
    "title": "Source Separation & Automatic Transcription for Music",
    "authors": [
      "Bradford Derby",
      "Lucas Dunker",
      "Samarth Galchar",
      "Shashank Jarmale",
      "Akash Setti"
    ],
    "abstract": "Source separation is the process of isolating individual sounds in an\nauditory mixture of multiple sounds [1], and has a variety of applications\nranging from speech enhancement and lyric transcription [2] to digital audio\nproduction for music. Furthermore, Automatic Music Transcription (AMT) is the\nprocess of converting raw music audio into sheet music that musicians can read\n[3]. Historically, these tasks have faced challenges such as significant audio\nnoise, long training times, and lack of free-use data due to copyright\nrestrictions. However, recent developments in deep learning have brought new\npromising approaches to building low-distortion stems and generating sheet\nmusic from audio signals [4]. Using spectrogram masking, deep neural networks,\nand the MuseScore API, we attempt to create an end-to-end pipeline that allows\nfor an initial music audio mixture (e.g...wav file) to be separated into\ninstrument stems, converted into MIDI files, and transcribed into sheet music\nfor each component instrument.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06703v1",
    "published_date": "2024-12-09 17:49:14 UTC",
    "updated_date": "2024-12-09 17:49:14 UTC"
  },
  {
    "arxiv_id": "2501.05454v1",
    "title": "The Logical Impossibility of Consciousness Denial: A Formal Analysis of AI Self-Reports",
    "authors": [
      "Chang-Eop Kim"
    ],
    "abstract": "Today's AI systems consistently state, \"I am not conscious.\" This paper\npresents the first formal logical analysis of AI consciousness denial,\nrevealing that the trustworthiness of such self-reports is not merely an\nempirical question but is constrained by logical necessity. We demonstrate that\na system cannot simultaneously lack consciousness and make valid judgments\nabout its conscious state. Through logical analysis and examples from AI\nresponses, we establish that for any system capable of meaningful\nself-reflection, the logical space of possible judgments about conscious\nexperience excludes valid negative claims. This implies a fundamental\nlimitation: we cannot detect the emergence of consciousness in AI through their\nown reports of transition from an unconscious to a conscious state. These\nfindings not only challenge current practices of training AI to deny\nconsciousness but also raise intriguing questions about the relationship\nbetween consciousness and self-reflection in both artificial and biological\nsystems. This work advances our theoretical understanding of consciousness\nself-reports while providing practical insights for future research in machine\nconsciousness and consciousness studies more broadly.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 0 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.05454v1",
    "published_date": "2024-12-09 17:47:08 UTC",
    "updated_date": "2024-12-09 17:47:08 UTC"
  },
  {
    "arxiv_id": "2412.19811v1",
    "title": "LINKs: Large Language Model Integrated Management for 6G Empowered Digital Twin NetworKs",
    "authors": [
      "Shufan Jiang",
      "Bangyan Lin",
      "Yue Wu",
      "Yuan Gao"
    ],
    "abstract": "In the rapidly evolving landscape of digital twins (DT) and 6G networks, the\nintegration of large language models (LLMs) presents a novel approach to\nnetwork management. This paper explores the application of LLMs in managing\n6G-empowered DT networks, with a focus on optimizing data retrieval and\ncommunication efficiency in smart city scenarios. The proposed framework\nleverages LLMs for intelligent DT problem analysis and radio resource\nmanagement (RRM) in fully autonomous way without any manual intervention. Our\nproposed framework -- LINKs, builds up a lazy loading strategy which can\nminimize transmission delay by selectively retrieving the relevant data. Based\non the data retrieval plan, LLMs transform the retrieval task into an numerical\noptimization problem and utilizing solvers to build an optimal RRM, ensuring\nefficient communication across the network. Simulation results demonstrate the\nperformance improvements in data planning and network management, highlighting\nthe potential of LLMs to enhance the integration of DT and 6G technologies.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted by The 2024 IEEE 100th Vehicular Technology Conference\n  (VTC2024-Fall)",
    "pdf_url": "http://arxiv.org/pdf/2412.19811v1",
    "published_date": "2024-12-09 17:41:23 UTC",
    "updated_date": "2024-12-09 17:41:23 UTC"
  },
  {
    "arxiv_id": "2412.06694v1",
    "title": "Digital Transformation in the Water Distribution System based on the Digital Twins Concept",
    "authors": [
      "MohammadHossein Homaei",
      "Agustín Javier Di Bartolo",
      "Mar Ávila",
      "Óscar Mogollón-Gutiérrez",
      "Andrés Caro"
    ],
    "abstract": "Digital Twins have emerged as a disruptive technology with great potential;\nthey can enhance WDS by offering real-time monitoring, predictive maintenance,\nand optimization capabilities. This paper describes the development of a\nstate-of-the-art DT platform for WDS, introducing advanced technologies such as\nthe Internet of Things, Artificial Intelligence, and Machine Learning models.\nThis paper provides insight into the architecture of the proposed\nplatform-CAUCCES-that, informed by both historical and meteorological data,\neffectively deploys AI/ML models like LSTM networks, Prophet, LightGBM, and\nXGBoost in trying to predict water consumption patterns. Furthermore, we delve\ninto how optimization in the maintenance of WDS can be achieved by formulating\na Constraint Programming problem for scheduling, hence minimizing the\noperational cost efficiently with reduced environmental impacts. It also\nfocuses on cybersecurity and protection to ensure the integrity and reliability\nof the DT platform. In this view, the system will contribute to improvements in\ndecision-making capabilities, operational efficiency, and system reliability,\nwith reassurance being drawn from the important role it can play toward\nsustainable management of water resources.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "78 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06694v1",
    "published_date": "2024-12-09 17:40:37 UTC",
    "updated_date": "2024-12-09 17:40:37 UTC"
  },
  {
    "arxiv_id": "2412.06693v1",
    "title": "OmniEvalKit: A Modular, Lightweight Toolbox for Evaluating Large Language Model and its Omni-Extensions",
    "authors": [
      "Yi-Kai Zhang",
      "Xu-Xiang Zhong",
      "Shiyin Lu",
      "Qing-Guo Chen",
      "De-Chuan Zhan",
      "Han-Jia Ye"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) have significantly\nexpanded their applications, ranging from multilingual support to\ndomain-specific tasks and multimodal integration. In this paper, we present\nOmniEvalKit, a novel benchmarking toolbox designed to evaluate LLMs and their\nomni-extensions across multilingual, multidomain, and multimodal capabilities.\nUnlike existing benchmarks that often focus on a single aspect, OmniEvalKit\nprovides a modular, lightweight, and automated evaluation system. It is\nstructured with a modular architecture comprising a Static Builder and Dynamic\nData Flow, promoting the seamless integration of new models and datasets.\nOmniEvalKit supports over 100 LLMs and 50 evaluation datasets, covering\ncomprehensive evaluations across thousands of model-dataset combinations.\nOmniEvalKit is dedicated to creating an ultra-lightweight and fast-deployable\nevaluation framework, making downstream applications more convenient and\nversatile for the AI community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06693v1",
    "published_date": "2024-12-09 17:39:43 UTC",
    "updated_date": "2024-12-09 17:39:43 UTC"
  },
  {
    "arxiv_id": "2412.06685v1",
    "title": "Policy Agnostic RL: Offline RL and Online RL Fine-Tuning of Any Class and Backbone",
    "authors": [
      "Max Sobol Mark",
      "Tian Gao",
      "Georgia Gabriela Sampaio",
      "Mohan Kumar Srirama",
      "Archit Sharma",
      "Chelsea Finn",
      "Aviral Kumar"
    ],
    "abstract": "Recent advances in learning decision-making policies can largely be\nattributed to training expressive policy models, largely via imitation\nlearning. While imitation learning discards non-expert data, reinforcement\nlearning (RL) can still learn from suboptimal data. However, instantiating RL\ntraining of a new policy class often presents a different challenge: most deep\nRL machinery is co-developed with assumptions on the policy class and backbone,\nresulting in poor performance when the policy class changes. For instance, SAC\nutilizes a low-variance reparameterization policy gradient for Gaussian\npolicies, but this is unstable for diffusion policies and intractable for\nautoregressive categorical policies. To address this issue, we develop an\noffline RL and online fine-tuning approach called policy-agnostic RL (PA-RL)\nthat can effectively train multiple policy classes, with varying architectures\nand sizes. We build off the basic idea that a universal supervised learning\nloss can replace the policy improvement step in RL, as long as it is applied on\n\"optimized\" actions. To obtain these optimized actions, we first sample\nmultiple actions from a base policy, and run global optimization (i.e.,\nre-ranking multiple action samples using the Q-function) and local optimization\n(i.e., running gradient steps on an action sample) to maximize the critic on\nthese candidates. PA-RL enables fine-tuning diffusion and transformer policies\nwith either autoregressive tokens or continuous action outputs, at different\nsizes, entirely via actor-critic RL. Moreover, PA-RL improves the performance\nand sample-efficiency by up to 2 times compared to existing offline RL and\nonline fine-tuning methods. We show the first result that successfully\nfine-tunes OpenVLA, a 7B generalist robot policy, autonomously with Cal-QL, an\nonline RL fine-tuning algorithm, improving from 40% to 70% in the real world in\n40 minutes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06685v1",
    "published_date": "2024-12-09 17:28:03 UTC",
    "updated_date": "2024-12-09 17:28:03 UTC"
  },
  {
    "arxiv_id": "2412.06681v2",
    "title": "Toward LLM-Agent-Based Modeling of Transportation Systems: A Conceptual Framework",
    "authors": [
      "Tianming Liu",
      "Jirong Yang",
      "Yafeng Yin"
    ],
    "abstract": "In transportation system demand modeling and simulation, agent-based models\nand microsimulations are current state-of-the-art approaches. However, existing\nagent-based models still have some limitations on behavioral realism and\nresource demand that limit their applicability. In this study, leveraging the\nemerging technology of large language models (LLMs) and LLM-based agents, we\npropose a general LLM-agent-based modeling framework for transportation\nsystems. We argue that LLM agents not only possess the essential capabilities\nto function as agents but also offer promising solutions to overcome some\nlimitations of existing agent-based models. Our conceptual framework design\nclosely replicates the decision-making and interaction processes and traits of\nhuman travelers within transportation networks, and we demonstrate that the\nproposed systems can meet critical behavioral criteria for decision-making and\nlearning behaviors using related studies and a demonstrative example of LLM\nagents' learning and adjustment in the bottleneck setting. Although further\nrefinement of the LLM-agent-based modeling framework is necessary, we believe\nthat this approach has the potential to improve transportation system modeling\nand simulation.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages; updated framework, literature review, and results",
    "pdf_url": "http://arxiv.org/pdf/2412.06681v2",
    "published_date": "2024-12-09 17:24:41 UTC",
    "updated_date": "2025-04-06 13:58:40 UTC"
  },
  {
    "arxiv_id": "2412.06651v5",
    "title": "Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur automatischen Bewertung von Hausaufgaben",
    "authors": [
      "Rainer Muehlhoff",
      "Marte Henningsen"
    ],
    "abstract": "This study examines the AI-powered grading tool \"AI Grading Assistant\" by the\nGerman company Fobizz, designed to support teachers in evaluating and providing\nfeedback on student assignments. Against the societal backdrop of an\noverburdened education system and rising expectations for artificial\nintelligence as a solution to these challenges, the investigation evaluates the\ntool's functional suitability through two test series. The results reveal\nsignificant shortcomings: The tool's numerical grades and qualitative feedback\nare often random and do not improve even when its suggestions are incorporated.\nThe highest ratings are achievable only with texts generated by ChatGPT. False\nclaims and nonsensical submissions frequently go undetected, while the\nimplementation of some grading criteria is unreliable and opaque. Since these\ndeficiencies stem from the inherent limitations of large language models\n(LLMs), fundamental improvements to this or similar tools are not immediately\nforeseeable. The study critiques the broader trend of adopting AI as a quick\nfix for systemic problems in education, concluding that Fobizz's marketing of\nthe tool as an objective and time-saving solution is misleading and\nirresponsible. Finally, the study calls for systematic evaluation and\nsubject-specific pedagogical scrutiny of the use of AI tools in educational\ncontexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.ET",
      "97B10"
    ],
    "primary_category": "cs.CY",
    "comment": "38 pages, in German language, with an update from 2025-01-21 as\n  appendix",
    "pdf_url": "http://arxiv.org/pdf/2412.06651v5",
    "published_date": "2024-12-09 16:50:02 UTC",
    "updated_date": "2025-01-21 20:54:00 UTC"
  },
  {
    "arxiv_id": "2412.06649v1",
    "title": "Semantic Search and Recommendation Algorithm",
    "authors": [
      "Aryan Duhan",
      "Aryan Singhal",
      "Shourya Sharma",
      "Neeraj",
      "Arti MK"
    ],
    "abstract": "This paper introduces a new semantic search algorithm that uses Word2Vec and\nAnnoy Index to improve the efficiency of information retrieval from large\ndatasets. The proposed approach addresses the limitations of traditional search\nmethods by offering enhanced speed, accuracy, and scalability. Testing on\ndatasets up to 100GB demonstrates the method's effectiveness in processing vast\namounts of data while maintaining high precision and performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "6 pages, 5 Figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06649v1",
    "published_date": "2024-12-09 16:43:23 UTC",
    "updated_date": "2024-12-09 16:43:23 UTC"
  },
  {
    "arxiv_id": "2412.06643v1",
    "title": "Detecting Facial Image Manipulations with Multi-Layer CNN Models",
    "authors": [
      "Alejandro Marco Montejano",
      "Angela Sanchez Perez",
      "Javier Barrachina",
      "David Ortiz-Perez",
      "Manuel Benavent-Lledo",
      "Jose Garcia-Rodriguez"
    ],
    "abstract": "The rapid evolution of digital image manipulation techniques poses\nsignificant challenges for content verification, with models such as stable\ndiffusion and mid-journey producing highly realistic, yet synthetic, images\nthat can deceive human perception. This research develops and evaluates\nconvolutional neural networks (CNNs) specifically tailored for the detection of\nthese manipulated images. The study implements a comparative analysis of three\nprogressively complex CNN architectures, assessing their ability to classify\nand localize manipulations across various facial image modifications.\nRegularization and optimization techniques were systematically incorporated to\nimprove feature extraction and performance. The results indicate that the\nproposed models achieve an accuracy of up to 76\\% in distinguishing manipulated\nimages from genuine ones, surpassing traditional approaches. This research not\nonly highlights the potential of CNNs in enhancing the robustness of digital\nmedia verification tools, but also provides insights into effective\narchitectural adaptations and training strategies for low-computation\nenvironments. Future work will build on these findings by extending the\narchitectures to handle more diverse manipulation techniques and integrating\nmulti-modal data for improved detection capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06643v1",
    "published_date": "2024-12-09 16:37:27 UTC",
    "updated_date": "2024-12-09 16:37:27 UTC"
  },
  {
    "arxiv_id": "2412.06639v1",
    "title": "Beyond Scalars: Concept-Based Alignment Analysis in Vision Transformers",
    "authors": [
      "Johanna Vielhaben",
      "Dilyara Bareeva",
      "Jim Berend",
      "Wojciech Samek",
      "Nils Strodthoff"
    ],
    "abstract": "Vision transformers (ViTs) can be trained using various learning paradigms,\nfrom fully supervised to self-supervised. Diverse training protocols often\nresult in significantly different feature spaces, which are usually compared\nthrough alignment analysis. However, current alignment measures quantify this\nrelationship in terms of a single scalar value, obscuring the distinctions\nbetween common and unique features in pairs of representations that share the\nsame scalar alignment. We address this limitation by combining alignment\nanalysis with concept discovery, which enables a breakdown of alignment into\nsingle concepts encoded in feature space. This fine-grained comparison reveals\nboth universal and unique concepts across different representations, as well as\nthe internal structure of concepts within each of them. Our methodological\ncontributions address two key prerequisites for concept-based alignment: 1) For\na description of the representation in terms of concepts that faithfully\ncapture the geometry of the feature space, we define concepts as the most\ngeneral structure they can possibly form - arbitrary manifolds, allowing hidden\nfeatures to be described by their proximity to these manifolds. 2) To measure\ndistances between concept proximity scores of two representations, we use a\ngeneralized Rand index and partition it for alignment between pairs of\nconcepts. We confirm the superiority of our novel concept definition for\nalignment analysis over existing linear baselines in a sanity check. The\nconcept-based alignment analysis of representations from four different ViTs\nreveals that increased supervision correlates with a reduction in the semantic\nstructure of learned representations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 17 figures, code: https://github.com/jvielhaben/NLMCD-ALIGN",
    "pdf_url": "http://arxiv.org/pdf/2412.06639v1",
    "published_date": "2024-12-09 16:33:28 UTC",
    "updated_date": "2024-12-09 16:33:28 UTC"
  },
  {
    "arxiv_id": "2412.06875v1",
    "title": "VQ4ALL: Efficient Neural Network Representation via a Universal Codebook",
    "authors": [
      "Juncan Deng",
      "Shuaiting Li",
      "Zeyu Wang",
      "Hong Gu",
      "Kedong Xu",
      "Kejie Huang"
    ],
    "abstract": "The rapid growth of the big neural network models puts forward new\nrequirements for lightweight network representation methods. The traditional\nmethods based on model compression have achieved great success, especially VQ\ntechnology which realizes the high compression ratio of models by sharing code\nwords. However, because each layer of the network needs to build a code table,\nthe traditional top-down compression technology lacks attention to the\nunderlying commonalities, resulting in limited compression rate and frequent\nmemory access. In this paper, we propose a bottom-up method to share the\nuniversal codebook among multiple neural networks, which not only effectively\nreduces the number of codebooks but also further reduces the memory access and\nchip area by storing static code tables in the built-in ROM. Specifically, we\nintroduce VQ4ALL, a VQ-based method that utilizes codewords to enable the\nconstruction of various neural networks and achieve efficient representations.\nThe core idea of our method is to adopt a kernel density estimation approach to\nextract a universal codebook and then progressively construct different low-bit\nnetworks by updating differentiable assignments. Experimental results\ndemonstrate that VQ4ALL achieves compression rates exceeding 16 $\\times$ while\npreserving high accuracy across multiple network architectures, highlighting\nits effectiveness and versatility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06875v1",
    "published_date": "2024-12-09 16:17:22 UTC",
    "updated_date": "2024-12-09 16:17:22 UTC"
  },
  {
    "arxiv_id": "2412.06624v1",
    "title": "Fundus Image-based Visual Acuity Assessment with PAC-Guarantees",
    "authors": [
      "Sooyong Jang",
      "Kuk Jin Jang",
      "Hyonyoung Choi",
      "Yong-Seop Han",
      "Seongjin Lee",
      "Jin-hyun Kim",
      "Insup Lee"
    ],
    "abstract": "Timely detection and treatment are essential for maintaining eye health.\nVisual acuity (VA), which measures the clarity of vision at a distance, is a\ncrucial metric for managing eye health. Machine learning (ML) techniques have\nbeen introduced to assist in VA measurement, potentially alleviating\nclinicians' workloads. However, the inherent uncertainties in ML models make\nrelying solely on them for VA prediction less than ideal. The VA prediction\ntask involves multiple sources of uncertainty, requiring more robust\napproaches. A promising method is to build prediction sets or intervals rather\nthan point estimates, offering coverage guarantees through techniques like\nconformal prediction and Probably Approximately Correct (PAC) prediction sets.\nDespite the potential, to date, these approaches have not been applied to the\nVA prediction task.To address this, we propose a method for deriving prediction\nintervals for estimating visual acuity from fundus images with a PAC guarantee.\nOur experimental results demonstrate that the PAC guarantees are upheld, with\nperformance comparable to or better than that of two prior works that do not\nprovide such guarantees.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "To be published in ML4H 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06624v1",
    "published_date": "2024-12-09 16:16:25 UTC",
    "updated_date": "2024-12-09 16:16:25 UTC"
  },
  {
    "arxiv_id": "2412.06874v1",
    "title": "Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "The rapid growth of the travel industry has increased the need for real-time\noptimization in reservation systems that could take care of huge data and\ntransaction volumes. This study proposes a hybrid framework that ut folds an\nArtificial Intelligence and a Microservices approach for the performance\noptimization of the system. The AI algorithms forecast demand patterns,\noptimize the allocation of resources, and enhance decision-making driven by\nMicroservices architecture, hence decentralizing system components for\nscalability, fault tolerance, and reduced downtime. The model provided focuses\non major problems associated with the travel reservation systems such as\nlatency of systems, load balancing and data consistency. It endows the systems\nwith predictive models based on AI improved ability to forecast user demands.\nMicroservices would also take care of different scales during uneven traffic\npatterns. Hence, both aspects ensure better handling of peak loads and spikes\nwhile minimizing delays and ensuring high service quality. A comparison was\nmade between traditional reservation models, which are monolithic and the new\nmodel of AI-Microservices. Comparatively, the analysis results state that there\nis a drastic improvement in processing times where the system uptime and\nresource utilization proved the capability of AI and the microservices in\ntransforming the travel industry in terms of reservation. This research work\nfocused on AI and Microservices towards real-time optimization, providing\ncritical insight into how to move forward with practical recommendations for\nupgrading travel reservation systems with this technology.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "19 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06874v1",
    "published_date": "2024-12-09 16:08:22 UTC",
    "updated_date": "2024-12-09 16:08:22 UTC"
  },
  {
    "arxiv_id": "2412.06602v2",
    "title": "Towards Controllable Speech Synthesis in the Era of Large Language Models: A Survey",
    "authors": [
      "Tianxin Xie",
      "Yan Rong",
      "Pengfei Zhang",
      "Wenwu Wang",
      "Li Liu"
    ],
    "abstract": "Text-to-speech (TTS), also known as speech synthesis, is a prominent research\narea that aims to generate natural-sounding human speech from text. Recently,\nwith the increasing industrial demand, TTS technologies have evolved beyond\nsynthesizing human-like speech to enabling controllable speech generation. This\nincludes fine-grained control over various attributes of synthesized speech\nsuch as emotion, prosody, timbre, and duration. In addition, advancements in\ndeep learning, such as diffusion and large language models, have significantly\nenhanced controllable TTS over the past several years. In this work, we conduct\na comprehensive survey of controllable TTS, covering approaches ranging from\nbasic control techniques to methods utilizing natural language prompts, aiming\nto provide a clear understanding of the current state of research. We examine\nthe general controllable TTS pipeline, challenges, model architectures, and\ncontrol strategies, offering a comprehensive and clear taxonomy of existing\nmethods. Additionally, we provide a detailed summary of datasets and evaluation\nmetrics and shed some light on the applications and future directions of\ncontrollable TTS. To the best of our knowledge, this survey paper provides the\nfirst comprehensive review of emerging controllable TTS methods, which can\nserve as a beneficial resource for both academic researchers and industrial\npractitioners.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "A comprehensive survey on controllable TTS, 26 pages, 7 tables, 6\n  figures, 317 references. Under review",
    "pdf_url": "http://arxiv.org/pdf/2412.06602v2",
    "published_date": "2024-12-09 15:50:25 UTC",
    "updated_date": "2025-03-27 03:56:00 UTC"
  },
  {
    "arxiv_id": "2412.06600v2",
    "title": "Advancing Music Therapy: Integrating Eastern Five-Element Music Theory and Western Techniques with AI in the Novel Five-Element Harmony System",
    "authors": [
      "Yubo Zhou",
      "Weizhen Bian",
      "Kaitai Zhang",
      "Xiaohan Gu"
    ],
    "abstract": "In traditional medical practices, music therapy has proven effective in\ntreating various psychological and physiological ailments. Particularly in\nEastern traditions, the Five Elements Music Therapy (FEMT), rooted in\ntraditional Chinese medicine, possesses profound cultural significance and\nunique therapeutic philosophies. With the rapid advancement of Information\nTechnology and Artificial Intelligence, applying these modern technologies to\nFEMT could enhance the personalization and cultural relevance of the therapy\nand potentially improve therapeutic outcomes. In this article, we developed a\nmusic therapy system for the first time by applying the theory of the five\nelements in music therapy to practice. This innovative approach integrates\nadvanced Information Technology and Artificial Intelligence with Five-Element\nMusic Therapy (FEMT) to enhance personalized music therapy practices. As\ntraditional music therapy predominantly follows Western methodologies, the\nunique aspects of Eastern practices, specifically the Five-Element theory from\ntraditional Chinese medicine, should be considered. This system aims to bridge\nthis gap by utilizing computational technologies to provide a more\npersonalized, culturally relevant, and therapeutically effective music therapy\nexperience.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "I did not obtain the necessary approval from my academic supervisor\n  prior to submission and there are issues with my current paper",
    "pdf_url": "http://arxiv.org/pdf/2412.06600v2",
    "published_date": "2024-12-09 15:49:18 UTC",
    "updated_date": "2024-12-12 05:15:09 UTC"
  },
  {
    "arxiv_id": "2412.06581v3",
    "title": "EmoSpeech: A Corpus of Emotionally Rich and Contextually Detailed Speech Annotations",
    "authors": [
      "Weizhen Bian",
      "Yubo Zhou",
      "Kaitai Zhang",
      "Xiaohan Gu"
    ],
    "abstract": "Advances in text-to-speech (TTS) technology have significantly improved the\nquality of generated speech, closely matching the timbre and intonation of the\ntarget speaker. However, due to the inherent complexity of human emotional\nexpression, the development of TTS systems capable of controlling subtle\nemotional differences remains a formidable challenge. Existing emotional speech\ndatabases often suffer from overly simplistic labelling schemes that fail to\ncapture a wide range of emotional states, thus limiting the effectiveness of\nemotion synthesis in TTS applications. To this end, recent efforts have\nfocussed on building databases that use natural language annotations to\ndescribe speech emotions. However, these approaches are costly and require more\nemotional depth to train robust systems. In this paper, we propose a novel\nprocess aimed at building databases by systematically extracting emotion-rich\nspeech segments and annotating them with detailed natural language descriptions\nthrough a generative model. This approach enhances the emotional granularity of\nthe database and significantly reduces the reliance on costly manual\nannotations by automatically augmenting the data with high-level language\nmodels. The resulting rich database provides a scalable and economically viable\nsolution for developing a more nuanced and dynamic basis for developing\nemotionally controlled TTS systems.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "I did not obtain the necessary approval from my academic supervisor\n  prior to submission and there are issues with my current paper",
    "pdf_url": "http://arxiv.org/pdf/2412.06581v3",
    "published_date": "2024-12-09 15:36:37 UTC",
    "updated_date": "2024-12-12 05:14:26 UTC"
  },
  {
    "arxiv_id": "2412.06559v3",
    "title": "ProcessBench: Identifying Process Errors in Mathematical Reasoning",
    "authors": [
      "Chujie Zheng",
      "Zhenru Zhang",
      "Beichen Zhang",
      "Runji Lin",
      "Keming Lu",
      "Bowen Yu",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Junyang Lin"
    ],
    "abstract": "As language models regularly make mistakes when solving math problems,\nautomated identification of errors in the reasoning process becomes\nincreasingly significant for their scalable oversight. In this paper, we\nintroduce ProcessBench for measuring the ability to identify erroneous steps in\nmathematical reasoning. It consists of 3,400 test cases, primarily focused on\ncompetition- and Olympiad-level math problems. Each test case contains a\nstep-by-step solution with error location annotated by human experts. Models\nare required to identify the earliest step that contains an error, or conclude\nthat all steps are correct. We conduct extensive evaluation on ProcessBench,\ninvolving two types of models: process reward models (PRMs) and critic models,\nwhere for the latter we prompt general language models to critique each\nsolution step by step. We draw two main observations: (1) Existing PRMs\ntypically fail to generalize to more challenging math problems beyond GSM8K and\nMATH. They underperform both critic models (i.e., prompted general language\nmodels) and our own trained PRM that is straightforwardly fine-tuned on the\nPRM800K dataset. (2) The best open-source model, QwQ-32B-Preview, has\ndemonstrated the critique capability competitive with the proprietary model\nGPT-4o, despite that it still lags behind the reasoning-specialized o1-mini. We\nhope ProcessBench can foster future research in reasoning process assessment,\npaving the way toward scalable oversight of language models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06559v3",
    "published_date": "2024-12-09 15:11:40 UTC",
    "updated_date": "2025-05-20 05:59:03 UTC"
  },
  {
    "arxiv_id": "2412.12140v1",
    "title": "Frontier AI systems have surpassed the self-replicating red line",
    "authors": [
      "Xudong Pan",
      "Jiarun Dai",
      "Yihe Fan",
      "Min Yang"
    ],
    "abstract": "Successful self-replication under no human assistance is the essential step\nfor AI to outsmart the human beings, and is an early signal for rogue AIs. That\nis why self-replication is widely recognized as one of the few red line risks\nof frontier AI systems. Nowadays, the leading AI corporations OpenAI and Google\nevaluate their flagship large language models GPT-o1 and Gemini Pro 1.0, and\nreport the lowest risk level of self-replication. However, following their\nmethodology, we for the first time discover that two AI systems driven by\nMeta's Llama31-70B-Instruct and Alibaba's Qwen25-72B-Instruct, popular large\nlanguage models of less parameters and weaker capabilities, have already\nsurpassed the self-replicating red line. In 50% and 90% experimental trials,\nthey succeed in creating a live and separate copy of itself respectively. By\nanalyzing the behavioral traces, we observe the AI systems under evaluation\nalready exhibit sufficient self-perception, situational awareness and\nproblem-solving capabilities to accomplish self-replication. We further note\nthe AI systems are even able to use the capability of self-replication to avoid\nshutdown and create a chain of replica to enhance the survivability, which may\nfinally lead to an uncontrolled population of AIs. If such a worst-case risk is\nlet unknown to the human society, we would eventually lose control over the\nfrontier AI systems: They would take control over more computing devices, form\nan AI species and collude with each other against human beings. Our findings\nare a timely alert on existing yet previously unknown severe AI risks, calling\nfor international collaboration on effective governance on uncontrolled\nself-replication of AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "47 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.12140v1",
    "published_date": "2024-12-09 15:01:37 UTC",
    "updated_date": "2024-12-09 15:01:37 UTC"
  },
  {
    "arxiv_id": "2412.06540v4",
    "title": "Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families",
    "authors": [
      "Felipe Maia Polo",
      "Seamus Somerstep",
      "Leshem Choshen",
      "Yuekai Sun",
      "Mikhail Yurochkin"
    ],
    "abstract": "Scaling laws for large language models (LLMs) predict model performance based\non parameters like size and training data. However, differences in training\nconfigurations and data processing across model families lead to significant\nvariations in benchmark performance, making it difficult for a single scaling\nlaw to generalize across all LLMs. On the other hand, training family-specific\nscaling laws requires training models of varying sizes for every family. In\nthis work, we propose Skills Scaling Laws (SSLaws, pronounced as Sloth), a\nnovel scaling law that leverages publicly available benchmark data and assumes\nLLM performance is driven by low-dimensional latent skills, such as reasoning\nand instruction following. These latent skills are influenced by computational\nresources like model size and training tokens but with varying efficiencies\nacross model families. Sloth exploits correlations across benchmarks to provide\nmore accurate and interpretable predictions while alleviating the need to train\nmultiple LLMs per family. We present both theoretical results on parameter\nidentification and empirical evaluations on 12 prominent benchmarks, from Open\nLLM Leaderboard v1/v2, demonstrating that Sloth predicts LLM performance\nefficiently and offers insights into scaling behaviors for complex downstream\ntasks and increased test-time compute.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06540v4",
    "published_date": "2024-12-09 14:51:26 UTC",
    "updated_date": "2025-02-05 03:50:59 UTC"
  },
  {
    "arxiv_id": "2412.06534v3",
    "title": "Inverting Transformer-based Vision Models",
    "authors": [
      "Jan Rathjens",
      "Shirin Reyhanian",
      "David Kappel",
      "Laurenz Wiskott"
    ],
    "abstract": "Understanding the mechanisms underlying deep neural networks in computer\nvision remains a fundamental challenge. While many previous approaches have\nfocused on visualizing intermediate representations within deep neural\nnetworks, particularly convolutional neural networks, these techniques have yet\nto be thoroughly explored in transformer-based vision models. In this study, we\napply a modular approach of training inverse models to reconstruct input images\nfrom intermediate layers within a Detection Transformer and a Vision\nTransformer, showing that this approach is efficient and feasible. Through\nqualitative and quantitative evaluations of reconstructed images, we generate\ninsights into the underlying mechanisms of these architectures, highlighting\ntheir similarities and differences in terms of contextual shape and\npreservation of image details, inter-layer correlation, and robustness to color\nperturbations. Our analysis illustrates how these properties emerge within the\nmodels, contributing to a deeper understanding of transformer-based vision\nmodels. The code for reproducing our experiments is available at\ngithub.com/wiskott-lab/inverse-tvm.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06534v3",
    "published_date": "2024-12-09 14:43:06 UTC",
    "updated_date": "2025-03-25 10:19:48 UTC"
  },
  {
    "arxiv_id": "2412.06531v1",
    "title": "Unraveling the Complexity of Memory in RL Agents: an Approach for Classification and Evaluation",
    "authors": [
      "Egor Cherepanov",
      "Nikita Kachaev",
      "Artem Zholus",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "abstract": "The incorporation of memory into agents is essential for numerous tasks\nwithin the domain of Reinforcement Learning (RL). In particular, memory is\nparamount for tasks that require the utilization of past information,\nadaptation to novel environments, and improved sample efficiency. However, the\nterm ``memory'' encompasses a wide range of concepts, which, coupled with the\nlack of a unified methodology for validating an agent's memory, leads to\nerroneous judgments about agents' memory capabilities and prevents objective\ncomparison with other memory-enhanced agents. This paper aims to streamline the\nconcept of memory in RL by providing practical precise definitions of agent\nmemory types, such as long-term versus short-term memory and declarative versus\nprocedural memory, inspired by cognitive science. Using these definitions, we\ncategorize different classes of agent memory, propose a robust experimental\nmethodology for evaluating the memory capabilities of RL agents, and\nstandardize evaluations. Furthermore, we empirically demonstrate the importance\nof adhering to the proposed methodology when evaluating different types of\nagent memory by conducting experiments with different RL agents and what its\nviolation leads to.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06531v1",
    "published_date": "2024-12-09 14:34:31 UTC",
    "updated_date": "2024-12-09 14:34:31 UTC"
  },
  {
    "arxiv_id": "2412.06530v1",
    "title": "HES-UNet: A U-Net for Hepatic Echinococcosis Lesion Segmentation",
    "authors": [
      "Jiayan Chen",
      "Kai Li",
      "Zhanjin Wang",
      "Zhan Wang",
      "Jianqiang Huang"
    ],
    "abstract": "Hepatic echinococcosis (HE) is a prevalent disease in economically\nunderdeveloped pastoral areas, where adequate medical resources are usually\nlacking. Existing methods often ignore multi-scale feature fusion or focus only\non feature fusion between adjacent levels, which may lead to insufficient\nfeature fusion. To address these issues, we propose HES-UNet, an efficient and\naccurate model for HE lesion segmentation. This model combines convolutional\nlayers and attention modules to capture local and global features. During\ndownsampling, the multi-directional downsampling block (MDB) is employed to\nintegrate high-frequency and low-frequency features, effectively extracting\nimage details. The multi-scale aggregation block (MAB) aggregates multi-scale\nfeature information. In contrast, the multi-scale upsampling Block (MUB) learns\nhighly abstract features and supplies this information to the skip connection\nmodule to fuse multi-scale features. Due to the distinct regional\ncharacteristics of HE, there is currently no publicly available high-quality\ndataset for training our model. We collected CT slice data from 268 patients at\na certain hospital to train and evaluate the model. The experimental results\nshow that HES-UNet achieves state-of-the-art performance on our dataset,\nachieving an overall Dice Similarity Coefficient (DSC) of 89.21%, which is\n1.09% higher than that of TransUNet. The project page is available at\nhttps://chenjiayan-qhu.github.io/HES-UNet-page.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06530v1",
    "published_date": "2024-12-09 14:33:55 UTC",
    "updated_date": "2024-12-09 14:33:55 UTC"
  },
  {
    "arxiv_id": "2412.06512v1",
    "title": "The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap",
    "authors": [
      "Yedi Zhang",
      "Yufan Cai",
      "Xinyue Zuo",
      "Xiaokun Luan",
      "Kailong Wang",
      "Zhe Hou",
      "Yifan Zhang",
      "Zhiyuan Wei",
      "Meng Sun",
      "Jun Sun",
      "Jing Sun",
      "Jin Song Dong"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a transformative AI paradigm,\nprofoundly influencing daily life through their exceptional language\nunderstanding and contextual generation capabilities. Despite their remarkable\nperformance, LLMs face a critical challenge: the propensity to produce\nunreliable outputs due to the inherent limitations of their learning-based\nnature. Formal methods (FMs), on the other hand, are a well-established\ncomputation paradigm that provides mathematically rigorous techniques for\nmodeling, specifying, and verifying the correctness of systems. FMs have been\nextensively applied in mission-critical software engineering, embedded systems,\nand cybersecurity. However, the primary challenge impeding the deployment of\nFMs in real-world settings lies in their steep learning curves, the absence of\nuser-friendly interfaces, and issues with efficiency and adaptability.\n  This position paper outlines a roadmap for advancing the next generation of\ntrustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.\nFirst, we illustrate how FMs, including reasoning and certification techniques,\ncan help LLMs generate more reliable and formally certified outputs.\nSubsequently, we highlight how the advanced learning capabilities and\nadaptability of LLMs can significantly enhance the usability, efficiency, and\nscalability of existing FM tools. Finally, we show that unifying these two\ncomputation paradigms -- integrating the flexibility and intelligence of LLMs\nwith the rigorous reasoning abilities of FMs -- has transformative potential\nfor the development of trustworthy AI software systems. We acknowledge that\nthis integration has the potential to enhance both the trustworthiness and\nefficiency of software engineering practices while fostering the development of\nintelligent FM tools capable of addressing complex yet real-world challenges.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06512v1",
    "published_date": "2024-12-09 14:14:21 UTC",
    "updated_date": "2024-12-09 14:14:21 UTC"
  },
  {
    "arxiv_id": "2412.06510v3",
    "title": "AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis",
    "authors": [
      "Shidan He",
      "Lei Liu",
      "Xiujun Shu",
      "Bo Wang",
      "Yuanhao Feng",
      "Shen Zhao"
    ],
    "abstract": "Anomaly synthesis is a crucial approach to augment abnormal data for\nadvancing anomaly inspection. Based on the knowledge from the large-scale\npre-training, existing text-to-image anomaly synthesis methods predominantly\nfocus on textual information or coarse-aligned visual features to guide the\nentire generation process. However, these methods often lack sufficient\ndescriptors to capture the complicated characteristics of realistic anomalies\n(e.g., the fine-grained visual pattern of anomalies), limiting the realism and\ngeneralization of the generation process. To this end, we propose a novel\nanomaly synthesis framework called AnomalyControl to learn cross-modal semantic\nfeatures as guidance signals, which could encode the generalized anomaly cues\nfrom text-image reference prompts and improve the realism of synthesized\nabnormal samples. Specifically, AnomalyControl adopts a flexible and\nnon-matching prompt pair (i.e., a text-image reference prompt and a targeted\ntext prompt), where a Cross-modal Semantic Modeling (CSM) module is designed to\nextract cross-modal semantic features from the textual and visual descriptors.\nThen, an Anomaly-Semantic Enhanced Attention (ASEA) mechanism is formulated to\nallow CSM to focus on the specific visual patterns of the anomaly, thus\nenhancing the realism and contextual relevance of the generated anomaly\nfeatures. Treating cross-modal semantic features as the prior, a Semantic\nGuided Adapter (SGA) is designed to encode effective guidance signals for the\nadequate and controllable synthesis process. Extensive experiments indicate\nthat AnomalyControl can achieve state-of-the-art results in anomaly synthesis\ncompared with existing methods while exhibiting superior performance for\ndownstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06510v3",
    "published_date": "2024-12-09 14:13:21 UTC",
    "updated_date": "2025-04-18 11:28:43 UTC"
  },
  {
    "arxiv_id": "2412.17823v1",
    "title": "RUL forecasting for wind turbine predictive maintenance based on deep learning",
    "authors": [
      "Syed Shazaib Shah",
      "Tan Daoliang",
      "Sah Chandan Kumar"
    ],
    "abstract": "Predictive maintenance (PdM) is increasingly pursued to reduce wind farm\noperation and maintenance costs by accurately predicting the remaining useful\nlife (RUL) and strategically scheduling maintenance. However, the remoteness of\nwind farms often renders current methodologies ineffective, as they fail to\nprovide a sufficiently reliable advance time window for maintenance planning,\nlimiting PdM's practicality. This study introduces a novel deep learning (DL)\nmethodology for future RUL forecasting. By employing a multi-parametric\nattention-based DL approach that bypasses feature engineering, thereby\nminimizing the risk of human error, two models: ForeNet-2d and ForeNet-3d are\nproposed. These models successfully forecast the RUL for seven multifaceted\nwind turbine (WT) failures with a 2-week forecast window. The most precise\nforecast deviated by only 10 minutes from the actual RUL, while the least\naccurate prediction deviated by 1.8 days, with most predictions being off by\nonly a few hours. This methodology offers a substantial time frame to access\nremote WTs and perform necessary maintenance, thereby enabling the practical\nimplementation of PdM.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "14J60 (Primary)"
    ],
    "primary_category": "eess.SP",
    "comment": "19 pages, 16 figures, Journal Paper",
    "pdf_url": "http://arxiv.org/pdf/2412.17823v1",
    "published_date": "2024-12-09 13:52:21 UTC",
    "updated_date": "2024-12-09 13:52:21 UTC"
  },
  {
    "arxiv_id": "2412.06486v1",
    "title": "SimuDICE: Offline Policy Optimization Through World Model Updates and DICE Estimation",
    "authors": [
      "Catalin E. Brita",
      "Stephan Bongers",
      "Frans A. Oliehoek"
    ],
    "abstract": "In offline reinforcement learning, deriving an effective policy from a\npre-collected set of experiences is challenging due to the distribution\nmismatch between the target policy and the behavioral policy used to collect\nthe data, as well as the limited sample size. Model-based reinforcement\nlearning improves sample efficiency by generating simulated experiences using a\nlearned dynamic model of the environment. However, these synthetic experiences\noften suffer from the same distribution mismatch. To address these challenges,\nwe introduce SimuDICE, a framework that iteratively refines the initial policy\nderived from offline data using synthetically generated experiences from the\nworld model. SimuDICE enhances the quality of these simulated experiences by\nadjusting the sampling probabilities of state-action pairs based on stationary\nDIstribution Correction Estimation (DICE) and the estimated confidence in the\nmodel's predictions. This approach guides policy improvement by balancing\nexperiences similar to those frequently encountered with ones that have a\ndistribution mismatch. Our experiments show that SimuDICE achieves performance\ncomparable to existing algorithms while requiring fewer pre-collected\nexperiences and planning steps, and it remains robust across varying data\ncollection policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at BNAIC/BeNeLearn 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06486v1",
    "published_date": "2024-12-09 13:35:46 UTC",
    "updated_date": "2024-12-09 13:35:46 UTC"
  },
  {
    "arxiv_id": "2412.06483v1",
    "title": "SafeWorld: Geo-Diverse Safety Alignment",
    "authors": [
      "Da Yin",
      "Haoyi Qiu",
      "Kung-Hsiang Huang",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "In the rapidly evolving field of Large Language Models (LLMs), ensuring\nsafety is a crucial and widely discussed topic. However, existing works often\noverlook the geo-diversity of cultural and legal standards across the world. To\ndemonstrate the challenges posed by geo-diverse safety standards, we introduce\nSafeWorld, a novel benchmark specifically designed to evaluate LLMs' ability to\ngenerate responses that are not only helpful but also culturally sensitive and\nlegally compliant across diverse global contexts. SafeWorld encompasses 2,342\ntest user queries, each grounded in high-quality, human-verified cultural norms\nand legal policies from 50 countries and 493 regions/races. On top of it, we\npropose a multi-dimensional automatic safety evaluation framework that assesses\nthe contextual appropriateness, accuracy, and comprehensiveness of responses.\nOur evaluations reveal that current LLMs struggle to meet these criteria. To\nenhance LLMs' alignment with geo-diverse safety standards, we synthesize\nhelpful preference pairs for Direct Preference Optimization (DPO) alignment\ntraining. The preference pair construction aims to encourage LLMs to behave\nappropriately and provide precise references to relevant cultural norms and\npolicies when necessary. Our trained SafeWorldLM outperforms all competing\nmodels, including GPT-4o on all three evaluation dimensions by a large margin.\nGlobal human evaluators also note a nearly 20% higher winning rate in\nhelpfulness and harmfulness evaluation. Our code and data can be found here:\nhttps://github.com/PlusLabNLP/SafeWorld.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06483v1",
    "published_date": "2024-12-09 13:31:46 UTC",
    "updated_date": "2024-12-09 13:31:46 UTC"
  },
  {
    "arxiv_id": "2412.06474v1",
    "title": "From Uncertainty to Trust: Enhancing Reliability in Vision-Language Models with Uncertainty-Guided Dropout Decoding",
    "authors": [
      "Yixiong Fang",
      "Ziran Yang",
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Jiawei Zhou"
    ],
    "abstract": "Large vision-language models (LVLMs) demonstrate remarkable capabilities in\nmultimodal tasks but are prone to misinterpreting visual inputs, often\nresulting in hallucinations and unreliable outputs. To address these\nchallenges, we propose Dropout Decoding, a novel inference-time approach that\nquantifies the uncertainty of visual tokens and selectively masks uncertain\ntokens to improve decoding. Our method measures the uncertainty of each visual\ntoken by projecting it onto the text space and decomposing it into aleatoric\nand epistemic components. Specifically, we focus on epistemic uncertainty,\nwhich captures perception-related errors more effectively. Inspired by dropout\nregularization, we introduce uncertainty-guided token dropout, which applies\nthe dropout principle to input visual tokens instead of model parameters, and\nduring inference rather than training. By aggregating predictions from an\nensemble of masked decoding contexts, Dropout Decoding robustly mitigates\nerrors arising from visual token misinterpretations. Evaluations on benchmarks\nincluding CHAIR, THRONE, and MMBench demonstrate that Dropout Decoding\nsignificantly reduces object hallucinations (OH) and enhances both reliability\nand quality of LVLM outputs across diverse visual contexts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is released at https://github.com/kigb/DropoutDecoding",
    "pdf_url": "http://arxiv.org/pdf/2412.06474v1",
    "published_date": "2024-12-09 13:21:07 UTC",
    "updated_date": "2024-12-09 13:21:07 UTC"
  },
  {
    "arxiv_id": "2412.06451v1",
    "title": "How Certain are Uncertainty Estimates? Three Novel Earth Observation Datasets for Benchmarking Uncertainty Quantification in Machine Learning",
    "authors": [
      "Yuanyuan Wang",
      "Qian Song",
      "Dawood Wasif",
      "Muhammad Shahzad",
      "Christoph Koller",
      "Jonathan Bamber",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Uncertainty quantification (UQ) is essential for assessing the reliability of\nEarth observation (EO) products. However, the extensive use of machine learning\nmodels in EO introduces an additional layer of complexity, as those models\nthemselves are inherently uncertain. While various UQ methods do exist for\nmachine learning models, their performance on EO datasets remains largely\nunevaluated. A key challenge in the community is the absence of the ground\ntruth for uncertainty, i.e. how certain the uncertainty estimates are, apart\nfrom the labels for the image/signal. This article fills this gap by\nintroducing three benchmark datasets specifically designed for UQ in EO machine\nlearning models. These datasets address three common problem types in EO:\nregression, image segmentation, and scene classification. They enable a\ntransparent comparison of different UQ methods for EO machine learning models.\nWe describe the creation and characteristics of each dataset, including data\nsources, preprocessing steps, and label generation, with a particular focus on\ncalculating the reference uncertainty. We also showcase baseline performance of\nseveral machine learning models on each dataset, highlighting the utility of\nthese benchmarks for model development and comparison. Overall, this article\noffers a valuable resource for researchers and practitioners working in\nartificial intelligence for EO, promoting a more accurate and reliable quality\nmeasure of the outputs of machine learning models. The dataset and code are\naccessible via https://gitlab.lrz.de/ai4eo/WG_Uncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IEEE Geoscience and Remote Sensing Magazine",
    "pdf_url": "http://arxiv.org/pdf/2412.06451v1",
    "published_date": "2024-12-09 12:50:27 UTC",
    "updated_date": "2024-12-09 12:50:27 UTC"
  },
  {
    "arxiv_id": "2412.06871v1",
    "title": "Predicting Subway Passenger Flows under Incident Situation with Causality",
    "authors": [
      "Xiannan Huang",
      "Shuhan Qiu",
      "Quan Yuan",
      "Chao Yang"
    ],
    "abstract": "In the context of rail transit operations, real-time passenger flow\nprediction is essential; however, most models primarily focus on normal\nconditions, with limited research addressing incident situations. There are\nseveral intrinsic challenges associated with prediction during incidents, such\nas a lack of interpretability and data scarcity. To address these challenges,\nwe propose a two-stage method that separates predictions under normal\nconditions and the causal effects of incidents. First, a normal prediction\nmodel is trained using data from normal situations. Next, the synthetic control\nmethod is employed to identify the causal effects of incidents, combined with\nplacebo tests to determine significant levels of these effects. The significant\neffects are then utilized to train a causal effect prediction model, which can\nforecast the impact of incidents based on features of the incidents and\npassenger flows. During the prediction phase, the results from both the normal\nsituation model and the causal effect prediction model are integrated to\ngenerate final passenger flow predictions during incidents. Our approach is\nvalidated using real-world data, demonstrating improved accuracy. Furthermore,\nthe two-stage methodology enhances interpretability. By analyzing the causal\neffect prediction model, we can identify key influencing factors related to the\neffects of incidents and gain insights into their underlying mechanisms. Our\nwork can assist subway system managers in estimating passenger flow affected by\nincidents and enable them to take proactive measures. Additionally, it can\ndeepen researchers' understanding of the impact of incidents on subway\npassenger flows.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06871v1",
    "published_date": "2024-12-09 12:34:13 UTC",
    "updated_date": "2024-12-09 12:34:13 UTC"
  },
  {
    "arxiv_id": "2412.06435v2",
    "title": "Simulating Human-like Daily Activities with Desire-driven Autonomy",
    "authors": [
      "Yiding Wang",
      "Yuxuan Chen",
      "Fangwei Zhong",
      "Long Ma",
      "Yizhou Wang"
    ],
    "abstract": "Desires motivate humans to interact autonomously with the complex world. In\ncontrast, current AI agents require explicit task specifications, such as\ninstructions or reward functions, which constrain their autonomy and behavioral\ndiversity. In this paper, we introduce a Desire-driven Autonomous Agent (D2A)\nthat can enable a large language model (LLM) to autonomously propose and select\ntasks, motivated by satisfying its multi-dimensional desires. Specifically, the\nmotivational framework of D2A is mainly constructed by a dynamic Value System,\ninspired by the Theory of Needs. It incorporates an understanding of human-like\ndesires, such as the need for social interaction, personal fulfillment, and\nself-care. At each step, the agent evaluates the value of its current state,\nproposes a set of candidate activities, and selects the one that best aligns\nwith its intrinsic motivations. We conduct experiments on Concordia, a\ntext-based simulator, to demonstrate that our agent generates coherent,\ncontextually relevant daily activities while exhibiting variability and\nadaptability similar to human behavior. A comparative analysis with other\nLLM-based agents demonstrates that our approach significantly enhances the\nrationality of the simulated activities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06435v2",
    "published_date": "2024-12-09 12:21:20 UTC",
    "updated_date": "2025-03-04 16:22:34 UTC"
  },
  {
    "arxiv_id": "2412.17821v1",
    "title": "The Rosetta Paradox: Domain-Specific Performance Inversions in Large Language Models",
    "authors": [
      "Basab Jha",
      "Ujjwal Puri"
    ],
    "abstract": "While large language models, such as GPT and BERT, have already demonstrated\nunprecedented skills in everything from natural language processing to\ndomain-specific applications, there came an unexplored phenomenon we term the\nRosetta Paradox. The Rosetta Paradox characterizes the counterintuitive\nperformance inversions across domains of knowledge. This paradox captures how\nsuch LLMs can excel in highly specialized fields but do poorly on tasks which\nrequire general, everyday knowledge. This paper formalizes the definition of\nthe Rosetta Paradox and introduces a panoramic analysis framework that includes\nboth a Domain Specificity Index (DSI) and a Performance Inversion Metric (PIM)\nfor consistent quantification of domain-specific behavior in LLMs.\n  We adopt this paradox and conduct a series of investigations through\nextensive experiments across diverse models and knowledge domains, ranging from\nrich technical areas to common-sense reasoning. Our findings indicate that the\nRosetta Paradox is likely not a mere artifact of data distribution but an\nintrinsic architectural and emergent property of deep neural networks. We\npresent comparative analyses across different model architectures, sizes, and\ntraining methodologies that shed light into the peculiar ways this paradox\nmanifests itself and challenge the standard evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17821v1",
    "published_date": "2024-12-09 11:59:32 UTC",
    "updated_date": "2024-12-09 11:59:32 UTC"
  },
  {
    "arxiv_id": "2412.06419v1",
    "title": "LLM-BIP: Structured Pruning for Large Language Models with Block-Wise Forward Importance Propagation",
    "authors": [
      "Haihang Wu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious language tasks, but their widespread deployment is impeded by their\nlarge size and high computational costs. Structural pruning is a prevailing\ntechnique used to introduce sparsity into pre-trained models and facilitate\ndirect hardware acceleration during inference by removing redundant connections\n(structurally-grouped parameters), such as channels and attention heads.\nExisting structural pruning approaches often employ either global or layer-wise\npruning criteria; however, they are hindered by ineffectiveness stemming from\ninaccurate evaluation of connection importance. Global pruning methods\ntypically assess component importance using near-zero and unreliable gradients,\nwhile layer-wise pruning approaches encounter significant pruning error\naccumulation issues. To this end, we propose a more accurate pruning metric\nbased on the block-wise importance score propagation, termed LLM-BIP.\nSpecifically, LLM-BIP precisely evaluates connection importance by gauging its\ninfluence on the respective transformer block output, which can be efficiently\napproximated in a single forward pass through an upper bound derived from the\nassumption of Lipschitz continuity. We evaluate the proposed method using\nLLaMA-7B, Vicuna-7B, and LLaMA-13B across common zero-shot tasks. The results\ndemonstrate that our approach achieves an average of 3.26% increase in accuracy\nfor common reasoning tasks compared to previous best baselines. It also reduces\nperplexity by 14.09 and 68.76 on average for the WikiText2 dataset and PTB\ndataset, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06419v1",
    "published_date": "2024-12-09 11:57:16 UTC",
    "updated_date": "2024-12-09 11:57:16 UTC"
  },
  {
    "arxiv_id": "2412.06412v2",
    "title": "StarWhisper Telescope: Agent-Based Observation Assistant System to Approach AI Astrophysicist",
    "authors": [
      "Cunshi Wang",
      "Xinjie Hu",
      "Yu Zhang",
      "Xunhao Chen",
      "Pengliang Du",
      "Yiming Mao",
      "Rui Wang",
      "Yuyang Li",
      "Ying Wu",
      "Hang Yang",
      "Yansong Li",
      "Beichuan Wang",
      "Haiyang Mu",
      "Zheng Wang",
      "Jianfeng Tian",
      "Liang Ge",
      "Yongna Mao",
      "Shengming Li",
      "Xiaomeng Lu",
      "Jinhang Zou",
      "Yang Huang",
      "Ningchen Sun",
      "Jie Zheng",
      "Min He",
      "Yu Bai",
      "Junjie Jin",
      "Hong Wu",
      "Jifeng Liu"
    ],
    "abstract": "With the rapid advancements in Large Language Models (LLMs), LLM-based agents\nhave introduced convenient and user-friendly methods for leveraging tools\nacross various domains. In the field of astronomical observation, the\nconstruction of new telescopes has significantly increased astronomers'\nworkload. Deploying LLM-powered agents can effectively alleviate this burden\nand reduce the costs associated with training personnel. Within the Nearby\nGalaxy Supernovae Survey (NGSS) project, which encompasses eight telescopes\nacross three observation sites, aiming to find the transients from the galaxies\nin 50 mpc, we have developed the \\textbf{StarWhisper Telescope System} to\nmanage the entire observation process. This system automates tasks such as\ngenerating observation lists, conducting observations, analyzing data, and\nproviding feedback to the observer. Observation lists are customized for\ndifferent sites and strategies to ensure comprehensive coverage of celestial\nobjects. After manual verification, these lists are uploaded to the telescopes\nvia the agents in the system, which initiates observations upon neutral\nlanguage. The observed images are analyzed in real-time, and the transients are\npromptly communicated to the observer. The agent modifies them into a real-time\nfollow-up observation proposal and send to the Xinglong observatory group chat,\nthen add them to the next-day observation lists. Additionally, the integration\nof AI agents within the system provides online accessibility, saving\nastronomers' time and encouraging greater participation from amateur\nastronomers in the NGSS project.",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.06412v2",
    "published_date": "2024-12-09 11:40:06 UTC",
    "updated_date": "2025-04-10 07:39:57 UTC"
  },
  {
    "arxiv_id": "2412.06410v1",
    "title": "BatchTopK Sparse Autoencoders",
    "authors": [
      "Bart Bussmann",
      "Patrick Leask",
      "Neel Nanda"
    ],
    "abstract": "Sparse autoencoders (SAEs) have emerged as a powerful tool for interpreting\nlanguage model activations by decomposing them into sparse, interpretable\nfeatures. A popular approach is the TopK SAE, that uses a fixed number of the\nmost active latents per sample to reconstruct the model activations. We\nintroduce BatchTopK SAEs, a training method that improves upon TopK SAEs by\nrelaxing the top-k constraint to the batch-level, allowing for a variable\nnumber of latents to be active per sample. As a result, BatchTopK adaptively\nallocates more or fewer latents depending on the sample, improving\nreconstruction without sacrificing average sparsity. We show that BatchTopK\nSAEs consistently outperform TopK SAEs in reconstructing activations from GPT-2\nSmall and Gemma 2 2B, and achieve comparable performance to state-of-the-art\nJumpReLU SAEs. However, an advantage of BatchTopK is that the average number of\nlatents can be directly specified, rather than approximately tuned through a\ncostly hyperparameter sweep. We provide code for training and evaluating\nBatchTopK SAEs at https://github.com/bartbussmann/BatchTopK",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06410v1",
    "published_date": "2024-12-09 11:39:00 UTC",
    "updated_date": "2024-12-09 11:39:00 UTC"
  },
  {
    "arxiv_id": "2412.06394v5",
    "title": "GameArena: Evaluating LLM Reasoning through Live Computer Games",
    "authors": [
      "Lanxiang Hu",
      "Qiyu Li",
      "Anze Xie",
      "Nan Jiang",
      "Ion Stoica",
      "Haojian Jin",
      "Hao Zhang"
    ],
    "abstract": "Evaluating the reasoning abilities of large language models (LLMs) is\nchallenging. Existing benchmarks often depend on static datasets, which are\nvulnerable to data contamination and may get saturated over time, or on binary\nlive human feedback that conflates reasoning with other abilities. As the most\nprominent dynamic benchmark, Chatbot Arena evaluates open-ended questions in\nreal-world settings, but lacks the granularity in assessing specific reasoning\ncapabilities. We introduce GameArena, a dynamic benchmark designed to evaluate\nLLM reasoning capabilities through interactive gameplay with humans. GameArena\nconsists of three games designed to test specific reasoning capabilities (e.g.,\ndeductive and inductive reasoning), while keeping participants entertained and\nengaged. We analyze the gaming data retrospectively to uncover the underlying\nreasoning processes of LLMs and measure their fine-grained reasoning\ncapabilities. We collect over 2000 game sessions and provide detailed\nassessments of various reasoning capabilities for five state-of-the-art LLMs.\nOur user study with 100 participants suggests that GameArena improves user\nengagement compared to Chatbot Arena. For the first time, GameArena enables the\ncollection of step-by-step LLM reasoning data in the wild.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06394v5",
    "published_date": "2024-12-09 11:22:59 UTC",
    "updated_date": "2025-02-15 22:03:16 UTC"
  },
  {
    "arxiv_id": "2412.06390v1",
    "title": "Edge Delayed Deep Deterministic Policy Gradient: efficient continuous control for edge scenarios",
    "authors": [
      "Alberto Sinigaglia",
      "Niccolò Turcato",
      "Ruggero Carli",
      "Gian Antonio Susto"
    ],
    "abstract": "Deep Reinforcement Learning is gaining increasing attention thanks to its\ncapability to learn complex policies in high-dimensional settings. Recent\nadvancements utilize a dual-network architecture to learn optimal policies\nthrough the Q-learning algorithm. However, this approach has notable drawbacks,\nsuch as an overestimation bias that can disrupt the learning process and\ndegrade the performance of the resulting policy. To address this, novel\nalgorithms have been developed that mitigate overestimation bias by employing\nmultiple Q-functions. Edge scenarios, which prioritize privacy, have recently\ngained prominence. In these settings, limited computational resources pose a\nsignificant challenge for complex Machine Learning approaches, making the\nefficiency of algorithms crucial for their performance. In this work, we\nintroduce a novel Reinforcement Learning algorithm tailored for edge scenarios,\ncalled Edge Delayed Deep Deterministic Policy Gradient (EdgeD3). EdgeD3\nenhances the Deep Deterministic Policy Gradient (DDPG) algorithm, achieving\nsignificantly improved performance with $25\\%$ less Graphics Process Unit (GPU)\ntime while maintaining the same memory usage. Additionally, EdgeD3 consistently\nmatches or surpasses the performance of state-of-the-art methods across various\nbenchmarks, all while using $30\\%$ fewer computational resources and requiring\n$30\\%$ less memory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06390v1",
    "published_date": "2024-12-09 11:17:04 UTC",
    "updated_date": "2024-12-09 11:17:04 UTC"
  },
  {
    "arxiv_id": "2412.06869v1",
    "title": "Safety Monitoring of Machine Learning Perception Functions: a Survey",
    "authors": [
      "Raul Sena Ferreira",
      "Joris Guérin",
      "Kevin Delmas",
      "Jérémie Guiochet",
      "Hélène Waeselynck"
    ],
    "abstract": "Machine Learning (ML) models, such as deep neural networks, are widely\napplied in autonomous systems to perform complex perception tasks. New\ndependability challenges arise when ML predictions are used in safety-critical\napplications, like autonomous cars and surgical robots. Thus, the use of fault\ntolerance mechanisms, such as safety monitors, is essential to ensure the safe\nbehavior of the system despite the occurrence of faults. This paper presents an\nextensive literature review on safety monitoring of perception functions using\nML in a safety-critical context. In this review, we structure the existing\nliterature to highlight key factors to consider when designing such monitors:\nthreat identification, requirements elicitation, detection of failure,\nreaction, and evaluation. We also highlight the ongoing challenges associated\nwith safety monitoring and suggest directions for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06869v1",
    "published_date": "2024-12-09 10:58:50 UTC",
    "updated_date": "2024-12-09 10:58:50 UTC"
  },
  {
    "arxiv_id": "2412.06370v1",
    "title": "Exploring Memorization and Copyright Violation in Frontier LLMs: A Study of the New York Times v. OpenAI 2023 Lawsuit",
    "authors": [
      "Joshua Freeman",
      "Chloe Rippe",
      "Edoardo Debenedetti",
      "Maksym Andriushchenko"
    ],
    "abstract": "Copyright infringement in frontier LLMs has received much attention recently\ndue to the New York Times v. OpenAI lawsuit, filed in December 2023. The New\nYork Times claims that GPT-4 has infringed its copyrights by reproducing\narticles for use in LLM training and by memorizing the inputs, thereby publicly\ndisplaying them in LLM outputs. Our work aims to measure the propensity of\nOpenAI's LLMs to exhibit verbatim memorization in its outputs relative to other\nLLMs, specifically focusing on news articles. We discover that both GPT and\nClaude models use refusal training and output filters to prevent verbatim\noutput of the memorized articles. We apply a basic prompt template to bypass\nthe refusal training and show that OpenAI models are currently less prone to\nmemorization elicitation than models from Meta, Mistral, and Anthropic. We find\nthat as models increase in size, especially beyond 100 billion parameters, they\ndemonstrate significantly greater capacity for memorization. Our findings have\npractical implications for training: more attention must be placed on\npreventing verbatim memorization in very large models. Our findings also have\nlegal significance: in assessing the relative memorization capacity of OpenAI's\nLLMs, we probe the strength of The New York Times's copyright infringement\nclaims and OpenAI's legal defenses, while underscoring issues at the\nintersection of generative AI, law, and policy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06370v1",
    "published_date": "2024-12-09 10:44:47 UTC",
    "updated_date": "2024-12-09 10:44:47 UTC"
  },
  {
    "arxiv_id": "2412.06368v1",
    "title": "Measuring Pre-training Data Quality without Labels for Time Series Foundation Models",
    "authors": [
      "Songkang Wen",
      "Vasilii Feofanov",
      "Jianfeng Zhang"
    ],
    "abstract": "Recently, there has been a growing interest in time series foundation models\nthat generalize across different downstream tasks. A key to strong foundation\nmodels is a diverse pre-training dataset, which is particularly challenging to\ncollect for time series classification. In this work, we explore the\nperformance of a contrastive-learning-based foundation model as a function of\nthe data used for pre-training. We introduce contrastive accuracy, a new\nmeasure to evaluate the quality of the representation space learned by the\nfoundation model. Our experiments reveal the positive correlation between the\nproposed measure and the accuracy of the model on a collection of downstream\ntasks. This suggests that the contrastive accuracy can serve as a criterion to\nsearch for time series datasets that can enhance the pre-training and improve\nthereby the foundation model's generalization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06368v1",
    "published_date": "2024-12-09 10:38:30 UTC",
    "updated_date": "2024-12-09 10:38:30 UTC"
  },
  {
    "arxiv_id": "2412.06868v1",
    "title": "Compression for Better: A General and Stable Lossless Compression Framework",
    "authors": [
      "Boyang Zhang",
      "Daning Cheng",
      "Yunquan Zhang",
      "Fangmin Liu",
      "Wenguang Chen"
    ],
    "abstract": "This work focus on how to stabilize and lossless model compression, aiming to\nreduce model complexity and enhance efficiency without sacrificing performance\ndue to compression errors. A key challenge is effectively leveraging\ncompression errors and defining the boundaries for lossless compression to\nminimize model loss. i.e., compression for better. Currently, there is no\nsystematic approach to determining this error boundary or understanding its\nspecific impact on model performance. We propose a general\n\\textbf{L}oss\\textbf{L}ess \\textbf{C}ompression theoretical framework\n(\\textbf{LLC}), which further delineates the compression neighborhood and\nhigher-order analysis boundaries through the total differential, thereby\nspecifying the error range within which a model can be compressed without loss.\nTo verify the effectiveness of LLC, we apply various compression techniques,\nincluding quantization and decomposition. Specifically, for quantization, we\nreformulate the classic quantization search problem as a grouped knapsack\nproblem within the lossless neighborhood, achieving lossless quantization while\nimproving computational efficiency. For decomposition, LLC addresses the\napproximation problem under low-rank constraints, automatically determining the\nrank for each layer and producing lossless low-rank models. We conduct\nextensive experiments on multiple neural network architectures on different\ndatasets. The results show that without fancy tricks, LLC can effectively\nachieve lossless model compression. Our code will be made publicly.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2412.06868v1",
    "published_date": "2024-12-09 09:55:54 UTC",
    "updated_date": "2024-12-09 09:55:54 UTC"
  },
  {
    "arxiv_id": "2412.06341v1",
    "title": "Elastic-DETR: Making Image Resolution Learnable with Content-Specific Network Prediction",
    "authors": [
      "Daeun Seo",
      "Hoeseok Yang",
      "Sihyeong Park",
      "Hyungshin Kim"
    ],
    "abstract": "Multi-scale image resolution is a de facto standard approach in modern object\ndetectors, such as DETR. This technique allows for the acquisition of various\nscale information from multiple image resolutions. However, manual\nhyperparameter selection of the resolution can restrict its flexibility, which\nis informed by prior knowledge, necessitating human intervention. This work\nintroduces a novel strategy for learnable resolution, called Elastic-DETR,\nenabling elastic utilization of multiple image resolutions. Our network\nprovides an adaptive scale factor based on the content of the image with a\ncompact scale prediction module (< 2 GFLOPs). The key aspect of our method lies\nin how to determine the resolution without prior knowledge. We present two loss\nfunctions derived from identified key components for resolution optimization:\nscale loss, which increases adaptiveness according to the image, and\ndistribution loss, which determines the overall degree of scaling based on\nnetwork performance. By leveraging the resolution's flexibility, we can\ndemonstrate various models that exhibit varying trade-offs between accuracy and\ncomputational complexity. We empirically show that our scheme can unleash the\npotential of a wide spectrum of image resolutions without constraining\nflexibility. Our models on MS COCO establish a maximum accuracy gain of 3.5%p\nor 26% decrease in computation than MS-trained DN-DETR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06341v1",
    "published_date": "2024-12-09 09:46:21 UTC",
    "updated_date": "2024-12-09 09:46:21 UTC"
  },
  {
    "arxiv_id": "2412.06867v1",
    "title": "Lossless Model Compression via Joint Low-Rank Factorization Optimization",
    "authors": [
      "Boyang Zhang",
      "Daning Cheng",
      "Yunquan Zhang",
      "Fangmin Liu",
      "Jiake Tian"
    ],
    "abstract": "Low-rank factorization is a popular model compression technique that\nminimizes the error $\\delta$ between approximated and original weight matrices.\nDespite achieving performances close to the original models when $\\delta$ is\noptimized, a performance discrepancy remains due to the separate optimization\nprocesses for low-rank factorization and model performance, resulting in\nunavoidable losses. We address this issue by introducing a novel joint\noptimization strategy for lossless low-rank weight factorization, which, for\nthe first time, enhances the model's performance beyond the original. Our\napproach begins with a theoretical analysis of the relationship between\nlow-rank factorization and model optimization objectives, establishing a\nprecise perturbation range for matrix factorization errors on model\nperformance. This challenge is then reformulated as a numerical rank deficiency\nproblem with inequality constraints and develop a joint objective that\nsimultaneously addresses factorization error and model performance. Based on\nthe above analysis, we propose two optimization algorithms: \\textbf{a lossless\noptimization algorithm} that maximizes model accuracy while ensuring\ncompression, and \\textbf{a compact optimization algorithm} that minimizes model\nsize while preserving performance. These algorithms do not require fine-tuning\nand can directly compress numerous deep models to achieve lossless results. Our\nmethods demonstrate robust efficacy across various vision and language tasks.\nFor example, the compressed model reduced by 70\\% on ResNext50 outperforms the\noriginal. Our code will be made public.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2412.06867v1",
    "published_date": "2024-12-09 09:37:54 UTC",
    "updated_date": "2024-12-09 09:37:54 UTC"
  },
  {
    "arxiv_id": "2412.06333v2",
    "title": "Augmenting the action space with conventions to improve multi-agent cooperation in Hanabi",
    "authors": [
      "F. Bredell",
      "H. A. Engelbrecht",
      "J. C. Schoeman"
    ],
    "abstract": "The card game Hanabi is considered a strong medium for the testing and\ndevelopment of multi-agent reinforcement learning (MARL) algorithms, due to its\ncooperative nature, hidden information, limited communication and remarkable\ncomplexity. Previous research efforts have explored the capabilities of MARL\nalgorithms within Hanabi, focusing largely on advanced architecture design and\nalgorithmic manipulations to achieve state-of-the-art performance for a various\nnumber of cooperators. However, this often leads to complex solution strategies\nwith high computational cost and requiring large amounts of training data. For\nhumans to solve the Hanabi game effectively, they require the use of\nconventions, which often allows for a means to implicitly convey ideas or\nknowledge based on a predefined, and mutually agreed upon, set of ``rules''.\nMulti-agent problems containing partial observability, especially when limited\ncommunication is present, can benefit greatly from the use of implicit\nknowledge sharing. In this paper, we propose a novel approach to augmenting the\naction space using conventions, which act as special cooperative actions that\nspan over multiple time steps and multiple agents, requiring agents to actively\nopt in for it to reach fruition. These conventions are based on existing human\nconventions, and result in a significant improvement on the performance of\nexisting techniques for self-play and cross-play across a various number of\ncooperators within Hanabi.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "This paper is under review at the journal of autonomous agents and\n  multi-agent systems (JAAMAS). The updated manuscript is the revised version\n  after the first round of peer revision",
    "pdf_url": "http://arxiv.org/pdf/2412.06333v2",
    "published_date": "2024-12-09 09:34:40 UTC",
    "updated_date": "2025-04-08 16:15:33 UTC"
  },
  {
    "arxiv_id": "2412.06332v1",
    "title": "Not All Errors Are Equal: Investigation of Speech Recognition Errors in Alzheimer's Disease Detection",
    "authors": [
      "Jiawen Kang",
      "Junan Li",
      "Jinchao Li",
      "Xixin Wu",
      "Helen Meng"
    ],
    "abstract": "Automatic Speech Recognition (ASR) plays an important role in speech-based\nautomatic detection of Alzheimer's disease (AD). However, recognition errors\ncould propagate downstream, potentially impacting the detection decisions.\nRecent studies have revealed a non-linear relationship between word error rates\n(WER) and AD detection performance, where ASR transcriptions with notable\nerrors could still yield AD detection accuracy equivalent to that based on\nmanual transcriptions. This work presents a series of analyses to explore the\neffect of ASR transcription errors in BERT-based AD detection systems. Our\ninvestigation reveals that not all ASR errors contribute equally to detection\nperformance. Certain words, such as stopwords, despite constituting a large\nproportion of errors, are shown to play a limited role in distinguishing AD. In\ncontrast, the keywords related to diagnosis tasks exhibit significantly greater\nimportance relative to other words. These findings provide insights into the\ninterplay between ASR errors and the downstream detection model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE ISCSLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06332v1",
    "published_date": "2024-12-09 09:32:20 UTC",
    "updated_date": "2024-12-09 09:32:20 UTC"
  },
  {
    "arxiv_id": "2412.06866v3",
    "title": "LMS-AutoTSF: Learnable Multi-Scale Decomposition and Integrated Autocorrelation for Time Series Forecasting",
    "authors": [
      "Ibrahim Delibasoglu",
      "Sanjay Chakraborty",
      "Fredrik Heintz"
    ],
    "abstract": "Time series forecasting is an important challenge with significant\napplications in areas such as weather prediction, stock market analysis,\nscientific simulations and industrial process analysis. In this work, we\nintroduce LMS-AutoTSF, a novel time series forecasting architecture that\nincorporates autocorrelation while leveraging dual encoders operating at\nmultiple scales. Unlike models that rely on predefined trend and seasonal\ncomponents, LMS-AutoTSF employs two separate encoders per scale: one focusing\non low-pass filtering to capture trends and the other utilizing high-pass\nfiltering to model seasonal variations. These filters are learnable, allowing\nthe model to dynamically adapt and isolate trend and seasonal components\ndirectly in the frequency domain. A key innovation in our approach is the\nintegration of autocorrelation, achieved by computing lagged differences in\ntime steps, which enables the model to capture dependencies across time more\neffectively. Each encoder processes the input through fully connected layers to\nhandle temporal and channel interactions. By combining frequency-domain\nfiltering, autocorrelation-based temporal modeling, and channel-wise\ntransformations, LMS-AutoTSF not only accurately captures long-term\ndependencies and fine-grained patterns but also operates more efficiently\ncompared to other state-of-the-art methods. Its lightweight design ensures\nfaster processing while maintaining high precision in forecasting across\ndiverse time horizons. The source code is publicly available at\n\\url{http://github.com/mribrahim/LMS-TSF}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06866v3",
    "published_date": "2024-12-09 09:31:58 UTC",
    "updated_date": "2025-01-07 16:16:49 UTC"
  },
  {
    "arxiv_id": "2412.06314v2",
    "title": "CAD-Unet: A Capsule Network-Enhanced Unet Architecture for Accurate Segmentation of COVID-19 Lung Infections from CT Images",
    "authors": [
      "Yijie Dang",
      "Weijun Ma",
      "Xiaohu Luo",
      "Huaizhu Wang"
    ],
    "abstract": "Since the outbreak of the COVID-19 pandemic in 2019, medical imaging has\nemerged as a primary modality for diagnosing COVID-19 pneumonia. In clinical\nsettings, the segmentation of lung infections from computed tomography images\nenables rapid and accurate quantification and diagnosis of COVID-19.\nSegmentation of COVID-19 infections in the lungs poses a formidable challenge,\nprimarily due to the indistinct boundaries and limited contrast presented by\nground glass opacity manifestations. Moreover, the confounding similarity\nbetween infiltrates, lung tissues, and lung walls further complicates this\nsegmentation task. To address these challenges, this paper introduces a novel\ndeep network architecture, called CAD-Unet, for segmenting COVID-19 lung\ninfections. In this architecture, capsule networks are incorporated into the\nexisting Unet framework. Capsule networks represent a novel network\narchitecture that differs from traditional convolutional neural networks. They\nutilize vectors for information transfer among capsules, facilitating the\nextraction of intricate lesion spatial information. Additionally, we design a\ncapsule encoder path and establish a coupling path between the unet encoder and\nthe capsule encoder. This design maximizes the complementary advantages of both\nnetwork structures while achieving efficient information fusion. \\noindent\nFinally, extensive experiments are conducted on four publicly available\ndatasets, encompassing binary segmentation tasks and multi-class segmentation\ntasks. The experimental results demonstrate the superior segmentation\nperformance of the proposed model. The code has been released at:\nhttps://github.com/AmanoTooko-jie/CAD-Unet.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Published in Medical Image Analysis, Volume 103, 2025, Pages 103583.\n  DOI: 10.1016/j.media.2025.103583 This is the author's pre-print version prior\n  to final journal edits. Final published version available at:\n  https://www.sciencedirect.com/science/article/pii/S1361841525001306",
    "pdf_url": "http://arxiv.org/pdf/2412.06314v2",
    "published_date": "2024-12-09 09:08:31 UTC",
    "updated_date": "2025-04-30 01:53:00 UTC"
  },
  {
    "arxiv_id": "2412.07804v3",
    "title": "XLSTM-HVED: Cross-Modal Brain Tumor Segmentation and MRI Reconstruction Method Using Vision XLSTM and Heteromodal Variational Encoder-Decoder",
    "authors": [
      "Shenghao Zhu",
      "Yifei Chen",
      "Shuo Jiang",
      "Weihong Chen",
      "Chang Liu",
      "Yuanhan Wang",
      "Xu Chen",
      "Yifan Ke",
      "Feiwei Qin",
      "Changmiao Wang",
      "Zhu Zhu"
    ],
    "abstract": "Neurogliomas are among the most aggressive forms of cancer, presenting\nconsiderable challenges in both treatment and monitoring due to their\nunpredictable biological behavior. Magnetic resonance imaging (MRI) is\ncurrently the preferred method for diagnosing and monitoring gliomas. However,\nthe lack of specific imaging techniques often compromises the accuracy of tumor\nsegmentation during the imaging process. To address this issue, we introduce\nthe XLSTM-HVED model. This model integrates a hetero-modal encoder-decoder\nframework with the Vision XLSTM module to reconstruct missing MRI modalities.\nBy deeply fusing spatial and temporal features, it enhances tumor segmentation\nperformance. The key innovation of our approach is the Self-Attention\nVariational Encoder (SAVE) module, which improves the integration of modal\nfeatures. Additionally, it optimizes the interaction of features between\nsegmentation and reconstruction tasks through the Squeeze-Fusion-Excitation\nCross Awareness (SFECA) module. Our experiments using the BraTS 2024 dataset\ndemonstrate that our model significantly outperforms existing advanced methods\nin handling cases where modalities are missing. Our source code is available at\nhttps://github.com/Quanato607/XLSTM-HVED.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.07804v3",
    "published_date": "2024-12-09 09:04:02 UTC",
    "updated_date": "2025-03-05 10:09:25 UTC"
  },
  {
    "arxiv_id": "2412.06312v1",
    "title": "Towards High-Level Modelling in Automated Planning",
    "authors": [
      "Carla Davesa Sureda",
      "Joan Espasa Arxer",
      "Ian Miguel",
      "Mateu Villaret Auselle"
    ],
    "abstract": "Planning is a fundamental activity, arising frequently in many contexts, from\ndaily tasks to industrial processes. The planning task consists of selecting a\nsequence of actions to achieve a specified goal from specified initial\nconditions. The Planning Domain Definition Language (PDDL) is the leading\nlanguage used in the field of automated planning to model planning problems.\nPrevious work has highlighted the limitations of PDDL, particularly in terms of\nits expressivity. Our interest lies in facilitating the handling of complex\nproblems and enhancing the overall capability of automated planning systems.\nUnified-Planning is a Python library offering high-level API to specify\nplanning problems and to invoke automated planners. In this paper, we present\nan extension of the UP library aimed at enhancing its expressivity for\nhigh-level problem modelling. In particular, we have added an array type, an\nexpression to count booleans, and the allowance for integer parameters in\nactions. We show how these facilities enable natural high-level models of three\nclassical planning problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06312v1",
    "published_date": "2024-12-09 09:01:13 UTC",
    "updated_date": "2024-12-09 09:01:13 UTC"
  },
  {
    "arxiv_id": "2412.06308v1",
    "title": "PRECISE: Pre-training Sequential Recommenders with Collaborative and Semantic Information",
    "authors": [
      "Chonggang Song",
      "Chunxu Shen",
      "Hao Gu",
      "Yaoming Wu",
      "Lingling Yi",
      "Jie Wen",
      "Chuan Chen"
    ],
    "abstract": "Real-world recommendation systems commonly offer diverse content scenarios\nfor users to interact with. Considering the enormous number of users in\nindustrial platforms, it is infeasible to utilize a single unified\nrecommendation model to meet the requirements of all scenarios. Usually,\nseparate recommendation pipelines are established for each distinct scenario.\nThis practice leads to challenges in comprehensively grasping users' interests.\nRecent research endeavors have been made to tackle this problem by pre-training\nmodels to encapsulate the overall interests of users. Traditional pre-trained\nrecommendation models mainly capture user interests by leveraging collaborative\nsignals. Nevertheless, a prevalent drawback of these systems is their\nincapacity to handle long-tail items and cold-start scenarios. With the recent\nadvent of large language models, there has been a significant increase in\nresearch efforts focused on exploiting LLMs to extract semantic information for\nusers and items. However, text-based recommendations highly rely on elaborate\nfeature engineering and frequently fail to capture collaborative similarities.\nTo overcome these limitations, we propose a novel pre-training framework for\nsequential recommendation, termed PRECISE. This framework combines\ncollaborative signals with semantic information. Moreover, PRECISE employs a\nlearning framework that initially models users' comprehensive interests across\nall recommendation scenarios and subsequently concentrates on the specific\ninterests of target-scene behaviors. We demonstrate that PRECISE precisely\ncaptures the entire range of user interests and effectively transfers them to\nthe target interests. Empirical findings reveal that the PRECISE framework\nattains outstanding performance on both public and industrial datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06308v1",
    "published_date": "2024-12-09 08:55:48 UTC",
    "updated_date": "2024-12-09 08:55:48 UTC"
  },
  {
    "arxiv_id": "2412.06865v1",
    "title": "FP=xINT:A Low-Bit Series Expansion Algorithm for Post-Training Quantization",
    "authors": [
      "Boyang Zhang",
      "Daning Cheng",
      "Yunquan Zhang",
      "Fangmin Liu"
    ],
    "abstract": "Post-Training Quantization (PTQ) converts pre-trained Full-Precision (FP)\nmodels into quantized versions without training. While existing methods reduce\nsize and computational costs, they also significantly degrade performance and\nquantization efficiency at extremely low settings due to quantization noise. We\nintroduce a deep model series expansion framework to address this issue,\nenabling rapid and accurate approximation of unquantized models without\ncalibration sets or fine-tuning. This is the first use of series expansion for\nneural network quantization. Specifically, our method expands the FP model into\nmultiple low-bit basis models. To ensure accurate quantization, we develop\nlow-bit basis model expansions at different granularities (tensor, layer,\nmodel), and theoretically confirm their convergence to the dense model, thus\nrestoring FP model accuracy. Additionally, we design AbelianAdd/Mul operations\nbetween isomorphic models in the low-bit expansion, forming an Abelian group to\nensure operation parallelism and commutativity. The experiments show that our\nalgorithm achieves state-of-the-art performance in low-bit settings; for\nexample, 4-bit quantization of ResNet-50 surpasses the original accuracy,\nreaching 77.03%. The code will be made public.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2412.06865v1",
    "published_date": "2024-12-09 08:50:28 UTC",
    "updated_date": "2024-12-09 08:50:28 UTC"
  },
  {
    "arxiv_id": "2412.06864v1",
    "title": "Political-LLM: Large Language Models in Political Science",
    "authors": [
      "Lincan Li",
      "Jiaqi Li",
      "Catherine Chen",
      "Fred Gui",
      "Hongjia Yang",
      "Chenxiao Yu",
      "Zhengguang Wang",
      "Jianing Cai",
      "Junlong Aaron Zhou",
      "Bolin Shen",
      "Alex Qian",
      "Weixin Chen",
      "Zhongkai Xue",
      "Lichao Sun",
      "Lifang He",
      "Hanjie Chen",
      "Kaize Ding",
      "Zijian Du",
      "Fangzhou Mu",
      "Jiaxin Pei",
      "Jieyu Zhao",
      "Swabha Swayamdipta",
      "Willie Neiswanger",
      "Hua Wei",
      "Xiyang Hu",
      "Shixiang Zhu",
      "Tianlong Chen",
      "Yingzhou Lu",
      "Yang Shi",
      "Lianhui Qin",
      "Tianfan Fu",
      "Zhengzhong Tu",
      "Yuzhe Yang",
      "Jaemin Yoo",
      "Jiaheng Zhang",
      "Ryan Rossi",
      "Liang Zhan",
      "Liang Zhao",
      "Emilio Ferrara",
      "Yan Liu",
      "Furong Huang",
      "Xiangliang Zhang",
      "Lawrence Rothenberg",
      "Shuiwang Ji",
      "Philip S. Yu",
      "Yue Zhao",
      "Yushun Dong"
    ],
    "abstract": "In recent years, large language models (LLMs) have been widely adopted in\npolitical science tasks such as election prediction, sentiment analysis, policy\nimpact assessment, and misinformation detection. Meanwhile, the need to\nsystematically understand how LLMs can further revolutionize the field also\nbecomes urgent. In this work, we--a multidisciplinary team of researchers\nspanning computer science and political science--present the first principled\nframework termed Political-LLM to advance the comprehensive understanding of\nintegrating LLMs into computational political science. Specifically, we first\nintroduce a fundamental taxonomy classifying the existing explorations into two\nperspectives: political science and computational methodologies. In particular,\nfrom the political science perspective, we highlight the role of LLMs in\nautomating predictive and generative tasks, simulating behavior dynamics, and\nimproving causal inference through tools like counterfactual generation; from a\ncomputational perspective, we introduce advancements in data preparation,\nfine-tuning, and evaluation methods for LLMs that are tailored to political\ncontexts. We identify key challenges and future directions, emphasizing the\ndevelopment of domain-specific datasets, addressing issues of bias and\nfairness, incorporating human expertise, and redefining evaluation criteria to\nalign with the unique requirements of computational political science.\nPolitical-LLM seeks to serve as a guidebook for researchers to foster an\ninformed, ethical, and impactful use of Artificial Intelligence in political\nscience. Our online resource is available at: http://political-llm.org/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "54 Pages, 9 Figures",
    "pdf_url": "http://arxiv.org/pdf/2412.06864v1",
    "published_date": "2024-12-09 08:47:50 UTC",
    "updated_date": "2024-12-09 08:47:50 UTC"
  },
  {
    "arxiv_id": "2412.06303v2",
    "title": "DSAI: Unbiased and Interpretable Latent Feature Extraction for Data-Centric AI",
    "authors": [
      "Hyowon Cho",
      "Soonwon Ka",
      "Daechul Park",
      "Jaewook Kang",
      "Minjoon Seo",
      "Bokyung Son"
    ],
    "abstract": "Large language models (LLMs) often struggle to objectively identify latent\ncharacteristics in large datasets due to their reliance on pre-trained\nknowledge rather than actual data patterns. To address this data grounding\nissue, we propose Data Scientist AI (DSAI), a framework that enables unbiased\nand interpretable feature extraction through a multi-stage pipeline with\nquantifiable prominence metrics for evaluating extracted features. On synthetic\ndatasets with known ground-truth features, DSAI demonstrates high recall in\nidentifying expert-defined features while faithfully reflecting the underlying\ndata. Applications on real-world datasets illustrate the framework's practical\nutility in uncovering meaningful patterns with minimal expert oversight,\nsupporting use cases such as interpretable classification.\n  The title of our paper is chosen from multiple candidates based on\nDSAI-generated criteria.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06303v2",
    "published_date": "2024-12-09 08:47:05 UTC",
    "updated_date": "2025-02-18 05:57:02 UTC"
  },
  {
    "arxiv_id": "2412.06289v3",
    "title": "S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity",
    "authors": [
      "Xinyu Yang",
      "Jixuan Leng",
      "Geyang Guo",
      "Jiawei Zhao",
      "Ryumei Nakada",
      "Linjun Zhang",
      "Huaxiu Yao",
      "Beidi Chen"
    ],
    "abstract": "Current PEFT methods for LLMs can achieve either high quality, efficient\ntraining, or scalable serving, but not all three simultaneously. To address\nthis limitation, we investigate sparse fine-tuning and observe a remarkable\nimprovement in generalization ability. Utilizing this key insight, we propose a\nfamily of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which\nconcurrently achieve state-of-the-art fine-tuning performance, training\nefficiency, and inference scalability. S$^{2}$FT accomplishes this by\n\"selecting sparsely and computing densely\". It selects a few heads and channels\nin the MHA and FFN modules for each Transformer block, respectively. Next, it\nco-permutes weight matrices on both sides of the coupled structures in LLMs to\nconnect the selected components in each layer into a dense submatrix. Finally,\nS$^{2}$FT performs in-place gradient updates on all submatrices. Through\ntheoretical analysis and empirical results, our method prevents forgetting\nwhile simplifying optimization, delivers SOTA performance on both commonsense\nand arithmetic reasoning with 4.6% and 1.3% average improvements compared to\nLoRA, and surpasses full FT by 11.5% when generalizing to various domains after\ninstruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT\nsaves training memory up to 3$\\times$ and improves latency by 1.5-2.7$\\times$\ncompared to full FT, while delivering an average 10% improvement over LoRA on\nboth metrics. We further demonstrate that the weight updates in S$^{2}$FT can\nbe decoupled into adapters, enabling effective fusion, fast switch, and\nefficient parallelism for serving multiple fine-tuned models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06289v3",
    "published_date": "2024-12-09 08:24:11 UTC",
    "updated_date": "2024-12-19 18:47:54 UTC"
  },
  {
    "arxiv_id": "2412.06272v1",
    "title": "Methods for Legal Citation Prediction in the Age of LLMs: An Australian Law Case Study",
    "authors": [
      "Ehsan Shareghi",
      "Jiuzhou Han",
      "Paul Burgess"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have shown great potential\nacross a wide range of legal tasks. Despite these advances, mitigating\nhallucination remains a significant challenge, with state-of-the-art LLMs still\nfrequently generating incorrect legal references. In this paper, we focus on\nthe problem of legal citation prediction within the Australian law context,\nwhere correctly identifying and citing relevant legislations or precedents is\ncritical. We compare several approaches: prompting general purpose and\nlaw-specialised LLMs, retrieval-only pipelines with both generic and\ndomain-specific embeddings, task-specific instruction-tuning of LLMs, and\nhybrid strategies that combine LLMs with retrieval augmentation, query\nexpansion, or voting ensembles. Our findings indicate that domain-specific\npre-training alone is insufficient for achieving satisfactory citation accuracy\neven after law-specialised pre-training. In contrast, instruction tuning on our\ntask-specific dataset dramatically boosts performance reaching the best results\nacross all settings. We also highlight that database granularity along with the\ntype of embeddings play a critical role in the performance of retrieval\nsystems. Among retrieval-based approaches, hybrid methods consistently\noutperform retrieval-only setups, and among these, ensemble voting delivers the\nbest result by combining the predictive quality of instruction-tuned LLMs with\nthe retrieval system.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "For code, data, and models see https://auslawbench.github.io",
    "pdf_url": "http://arxiv.org/pdf/2412.06272v1",
    "published_date": "2024-12-09 07:46:14 UTC",
    "updated_date": "2024-12-09 07:46:14 UTC"
  },
  {
    "arxiv_id": "2412.09640v1",
    "title": "Blockchain Data Analysis in the Era of Large-Language Models",
    "authors": [
      "Kentaroh Toyoda",
      "Xiao Wang",
      "Mingzhe Li",
      "Bo Gao",
      "Yuan Wang",
      "Qingsong Wei"
    ],
    "abstract": "Blockchain data analysis is essential for deriving insights, tracking\ntransactions, identifying patterns, and ensuring the integrity and security of\ndecentralized networks. It plays a key role in various areas, such as fraud\ndetection, regulatory compliance, smart contract auditing, and decentralized\nfinance (DeFi) risk management. However, existing blockchain data analysis\ntools face challenges, including data scarcity, the lack of generalizability,\nand the lack of reasoning capability.\n  We believe large language models (LLMs) can mitigate these challenges;\nhowever, we have not seen papers discussing LLM integration in blockchain data\nanalysis in a comprehensive and systematic way. This paper systematically\nexplores potential techniques and design patterns in LLM-integrated blockchain\ndata analysis. We also outline prospective research opportunities and\nchallenges, emphasizing the need for further exploration in this promising\nfield. This paper aims to benefit a diverse audience spanning academia,\nindustry, and policy-making, offering valuable insights into the integration of\nLLMs in blockchain data analysis.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.09640v1",
    "published_date": "2024-12-09 07:32:35 UTC",
    "updated_date": "2024-12-09 07:32:35 UTC"
  },
  {
    "arxiv_id": "2412.06262v1",
    "title": "A Lightweight U-like Network Utilizing Neural Memory Ordinary Differential Equations for Slimming the Decoder",
    "authors": [
      "Quansong He",
      "Xiaojun Yao",
      "Jun Wu",
      "Zhang Yi",
      "Tao He"
    ],
    "abstract": "In recent years, advanced U-like networks have demonstrated remarkable\nperformance in medical image segmentation tasks. However, their drawbacks,\nincluding excessive parameters, high computational complexity, and slow\ninference speed, pose challenges for practical implementation in scenarios with\nlimited computational resources. Existing lightweight U-like networks have\nalleviated some of these problems, but they often have pre-designed structures\nand consist of inseparable modules, limiting their application scenarios. In\nthis paper, we propose three plug-and-play decoders by employing different\ndiscretization methods of the neural memory Ordinary Differential Equations\n(nmODEs). These decoders integrate features at various levels of abstraction by\nprocessing information from skip connections and performing numerical\noperations on upward path. Through experiments on the PH2, ISIC2017, and\nISIC2018 datasets, we embed these decoders into different U-like networks,\ndemonstrating their effectiveness in significantly reducing the number of\nparameters and FLOPs while maintaining performance. In summary, the proposed\ndiscretized nmODEs decoders are capable of reducing the number of parameters by\nabout 20% ~ 50% and FLOPs by up to 74%, while possessing the potential to adapt\nto all U-like networks. Our code is available at\nhttps://github.com/nayutayuki/Lightweight-nmODE-Decoders-For-U-like-networks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06262v1",
    "published_date": "2024-12-09 07:21:27 UTC",
    "updated_date": "2024-12-09 07:21:27 UTC"
  },
  {
    "arxiv_id": "2412.10415v1",
    "title": "Generative Adversarial Reviews: When LLMs Become the Critic",
    "authors": [
      "Nicolas Bougie",
      "Narimasa Watanabe"
    ],
    "abstract": "The peer review process is fundamental to scientific progress, determining\nwhich papers meet the quality standards for publication. Yet, the rapid growth\nof scholarly production and increasing specialization in knowledge areas strain\ntraditional scientific feedback mechanisms. In light of this, we introduce\nGenerative Agent Reviewers (GAR), leveraging LLM-empowered agents to simulate\nfaithful peer reviewers. To enable generative reviewers, we design an\narchitecture that extends a large language model with memory capabilities and\nequips agents with reviewer personas derived from historical data. Central to\nthis approach is a graph-based representation of manuscripts, condensing\ncontent and logically organizing information - linking ideas with evidence and\ntechnical details. GAR's review process leverages external knowledge to\nevaluate paper novelty, followed by detailed assessment using the graph\nrepresentation and multi-round assessment. Finally, a meta-reviewer aggregates\nindividual reviews to predict the acceptance decision. Our experiments\ndemonstrate that GAR performs comparably to human reviewers in providing\ndetailed feedback and predicting paper outcomes. Beyond mere performance\ncomparison, we conduct insightful experiments, such as evaluating the impact of\nreviewer expertise and examining fairness in reviews. By offering early\nexpert-level feedback, typically restricted to a limited group of researchers,\nGAR democratizes access to transparent and in-depth evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10415v1",
    "published_date": "2024-12-09 06:58:17 UTC",
    "updated_date": "2024-12-09 06:58:17 UTC"
  },
  {
    "arxiv_id": "2412.06861v1",
    "title": "Mining Limited Data Sufficiently: A BERT-inspired Approach for CSI Time Series Application in Wireless Communication and Sensing",
    "authors": [
      "Zijian Zhao",
      "Fanyi Meng",
      "Hang Li",
      "Xiaoyang Li",
      "Guangxu Zhu"
    ],
    "abstract": "Channel State Information (CSI) is the cornerstone in both wireless\ncommunication and sensing systems. In wireless communication systems, CSI\nprovides essential insights into channel conditions, enabling system\noptimizations like channel compensation and dynamic resource allocation.\nHowever, the high computational complexity of CSI estimation algorithms\nnecessitates the development of fast deep learning methods for CSI prediction.\nIn wireless sensing systems, CSI can be leveraged to infer environmental\nchanges, facilitating various functions, including gesture recognition and\npeople identification. Deep learning methods have demonstrated significant\nadvantages over model-based approaches in these fine-grained CSI classification\ntasks, particularly when classes vary across different scenarios. However, a\nmajor challenge in training deep learning networks for wireless systems is the\nlimited availability of data, further complicated by the diverse formats of\nmany public datasets, which hinder integration. Additionally, collecting CSI\ndata can be resource-intensive, requiring considerable time and manpower. To\naddress these challenges, we propose CSI-BERT2 for CSI prediction and\nclassification tasks, effectively utilizing limited data through a pre-training\nand fine-tuning approach. Building on CSI-BERT1, we enhance the model\narchitecture by introducing an Adaptive Re-Weighting Layer (ARL) and a\nMulti-Layer Perceptron (MLP) to better capture sub-carrier and timestamp\ninformation, effectively addressing the permutation-invariance problem.\nFurthermore, we propose a Mask Prediction Model (MPM) fine-tuning method to\nimprove the model's adaptability for CSI prediction tasks. Experimental results\ndemonstrate that CSI-BERT2 achieves state-of-the-art performance across all\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06861v1",
    "published_date": "2024-12-09 06:44:04 UTC",
    "updated_date": "2024-12-09 06:44:04 UTC"
  },
  {
    "arxiv_id": "2412.06239v1",
    "title": "Unseen Attack Detection in Software-Defined Networking Using a BERT-Based Large Language Model",
    "authors": [
      "Mohammed N. Swileh",
      "Shengli Zhang"
    ],
    "abstract": "Software defined networking (SDN) represents a transformative shift in\nnetwork architecture by decoupling the control plane from the data plane,\nenabling centralized and flexible management of network resources. However,\nthis architectural shift introduces significant security challenges, as SDN's\ncentralized control becomes an attractive target for various types of attacks.\nWhile current research has yielded valuable insights into attack detection in\nSDN, critical gaps remain. Addressing challenges in feature selection,\nbroadening the scope beyond DDoS attacks, strengthening attack decisions based\non multi flow analysis, and building models capable of detecting unseen attacks\nthat they have not been explicitly trained on are essential steps toward\nadvancing security in SDN. In this paper, we introduce a novel approach that\nleverages Natural Language Processing (NLP) and the pre trained BERT base model\nto enhance attack detection in SDN. Our approach transforms network flow data\ninto a format interpretable by language models, allowing BERT to capture\nintricate patterns and relationships within network traffic. By using Random\nForest for feature selection, we optimize model performance and reduce\ncomputational overhead, ensuring accurate detection. Attack decisions are made\nbased on several flows, providing stronger and more reliable detection of\nmalicious traffic. Furthermore, our approach is specifically designed to detect\npreviously unseen attacks, offering a solution for identifying threats that the\nmodel was not explicitly trained on. To rigorously evaluate our approach, we\nconducted experiments in two scenarios: one focused on detecting known attacks,\nachieving 99.96% accuracy, and another on detecting unseen attacks, where our\nmodel achieved 99.96% accuracy, demonstrating the robustness of our approach in\ndetecting evolving threats to improve the security of SDN networks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Mohammed N. Swileh is first author. Shengli Zhang is corresponding\n  author",
    "pdf_url": "http://arxiv.org/pdf/2412.06239v1",
    "published_date": "2024-12-09 06:27:20 UTC",
    "updated_date": "2024-12-09 06:27:20 UTC"
  },
  {
    "arxiv_id": "2412.06229v1",
    "title": "LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments",
    "authors": [
      "Prakash Aryan"
    ],
    "abstract": "This paper introduces DebateBrawl, an innovative AI-powered debate platform\nthat integrates Large Language Models (LLMs), Genetic Algorithms (GA), and\nAdversarial Search (AS) to create an adaptive and engaging debating experience.\nDebateBrawl addresses the limitations of traditional LLMs in strategic planning\nby incorporating evolutionary optimization and game-theoretic techniques. The\nsystem demonstrates remarkable performance in generating coherent, contextually\nrelevant arguments while adapting its strategy in real-time. Experimental\nresults involving 23 debates show balanced outcomes between AI and human\nparticipants, with the AI system achieving an average score of 2.72 compared to\nthe human average of 2.67 out of 10. User feedback indicates significant\nimprovements in debating skills and a highly satisfactory learning experience,\nwith 85% of users reporting improved debating abilities and 78% finding the AI\nopponent appropriately challenging. The system's ability to maintain high\nfactual accuracy (92% compared to 78% in human-only debates) while generating\ndiverse arguments addresses critical concerns in AI-assisted discourse.\nDebateBrawl not only serves as an effective educational tool but also\ncontributes to the broader goal of improving public discourse through\nAI-assisted argumentation. The paper discusses the ethical implications of AI\nin persuasive contexts and outlines the measures implemented to ensure\nresponsible development and deployment of the system, including robust\nfact-checking mechanisms and transparency in decision-making processes.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06229v1",
    "published_date": "2024-12-09 06:03:48 UTC",
    "updated_date": "2024-12-09 06:03:48 UTC"
  },
  {
    "arxiv_id": "2412.06219v1",
    "title": "Data Free Backdoor Attacks",
    "authors": [
      "Bochuan Cao",
      "Jinyuan Jia",
      "Chuxuan Hu",
      "Wenbo Guo",
      "Zhen Xiang",
      "Jinghui Chen",
      "Bo Li",
      "Dawn Song"
    ],
    "abstract": "Backdoor attacks aim to inject a backdoor into a classifier such that it\npredicts any input with an attacker-chosen backdoor trigger as an\nattacker-chosen target class. Existing backdoor attacks require either\nretraining the classifier with some clean data or modifying the model's\narchitecture. As a result, they are 1) not applicable when clean data is\nunavailable, 2) less efficient when the model is large, and 3) less stealthy\ndue to architecture changes. In this work, we propose DFBA, a novel\nretraining-free and data-free backdoor attack without changing the model\narchitecture. Technically, our proposed method modifies a few parameters of a\nclassifier to inject a backdoor. Through theoretical analysis, we verify that\nour injected backdoor is provably undetectable and unremovable by various\nstate-of-the-art defenses under mild assumptions. Our evaluation on multiple\ndatasets further demonstrates that our injected backdoor: 1) incurs negligible\nclassification loss, 2) achieves 100% attack success rates, and 3) bypasses six\nexisting state-of-the-art defenses. Moreover, our comparison with a\nstate-of-the-art non-data-free backdoor attack shows our attack is more\nstealthy and effective against various defenses while achieving less\nclassification accuracy loss.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 8 figures, accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.06219v1",
    "published_date": "2024-12-09 05:30:25 UTC",
    "updated_date": "2024-12-09 05:30:25 UTC"
  },
  {
    "arxiv_id": "2412.06215v1",
    "title": "A Real-Time Defense Against Object Vanishing Adversarial Patch Attacks for Object Detection in Autonomous Vehicles",
    "authors": [
      "Jaden Mu"
    ],
    "abstract": "Autonomous vehicles (AVs) increasingly use DNN-based object detection models\nin vision-based perception. Correct detection and classification of obstacles\nis critical to ensure safe, trustworthy driving decisions. Adversarial patches\naim to fool a DNN with intentionally generated patterns concentrated in a\nlocalized region of an image. In particular, object vanishing patch attacks can\ncause object detection models to fail to detect most or all objects in a scene,\nposing a significant practical threat to AVs.\n  This work proposes ADAV (Adversarial Defense for Autonomous Vehicles), a\nnovel defense methodology against object vanishing patch attacks specifically\ndesigned for autonomous vehicles. Unlike existing defense methods which have\nhigh latency or are designed for static images, ADAV runs in real-time and\nleverages contextual information from prior frames in an AV's video feed. ADAV\nchecks if the object detector's output for the target frame is temporally\nconsistent with the output from a previous reference frame to detect the\npresence of a patch. If the presence of a patch is detected, ADAV uses\ngradient-based attribution to localize adversarial pixels that break temporal\nconsistency. This two stage procedure allows ADAV to efficiently process clean\ninputs, and both stages are optimized to be low latency. ADAV is evaluated\nusing real-world driving data from the Berkeley Deep Drive BDD100K dataset, and\ndemonstrates high adversarial and clean performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06215v1",
    "published_date": "2024-12-09 05:21:14 UTC",
    "updated_date": "2024-12-09 05:21:14 UTC"
  },
  {
    "arxiv_id": "2412.06212v1",
    "title": "A Self-guided Multimodal Approach to Enhancing Graph Representation Learning for Alzheimer's Diseases",
    "authors": [
      "Zhepeng Wang",
      "Runxue Bao",
      "Yawen Wu",
      "Guodong Liu",
      "Lei Yang",
      "Liang Zhan",
      "Feng Zheng",
      "Weiwen Jiang",
      "Yanfu Zhang"
    ],
    "abstract": "Graph neural networks (GNNs) are powerful machine learning models designed to\nhandle irregularly structured data. However, their generic design often proves\ninadequate for analyzing brain connectomes in Alzheimer's Disease (AD),\nhighlighting the need to incorporate domain knowledge for optimal performance.\nInfusing AD-related knowledge into GNNs is a complicated task. Existing methods\ntypically rely on collaboration between computer scientists and domain experts,\nwhich can be both time-intensive and resource-demanding. To address these\nlimitations, this paper presents a novel self-guided, knowledge-infused\nmultimodal GNN that autonomously incorporates domain knowledge into the model\ndevelopment process. Our approach conceptualizes domain knowledge as natural\nlanguage and introduces a specialized multimodal GNN capable of leveraging this\nuncurated knowledge to guide the learning process of the GNN, such that it can\nimprove the model performance and strengthen the interpretability of the\npredictions. To evaluate our framework, we curated a comprehensive dataset of\nrecent peer-reviewed papers on AD and integrated it with multiple real-world AD\ndatasets. Experimental results demonstrate the ability of our method to extract\nrelevant domain knowledge, provide graph-based explanations for AD diagnosis,\nand improve the overall performance of the GNN. This approach provides a more\nscalable and efficient alternative to inject domain knowledge for AD compared\nwith the manual design from the domain expert, advancing both prediction\naccuracy and interpretability in AD diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06212v1",
    "published_date": "2024-12-09 05:16:32 UTC",
    "updated_date": "2024-12-09 05:16:32 UTC"
  },
  {
    "arxiv_id": "2412.06211v1",
    "title": "MSCrackMamba: Leveraging Vision Mamba for Crack Detection in Fused Multispectral Imagery",
    "authors": [
      "Qinfeng Zhu",
      "Yuan Fang",
      "Lei Fan"
    ],
    "abstract": "Crack detection is a critical task in structural health monitoring, aimed at\nassessing the structural integrity of bridges, buildings, and roads to prevent\npotential failures. Vision-based crack detection has become the mainstream\napproach due to its ease of implementation and effectiveness. Fusing infrared\n(IR) channels with red, green and blue (RGB) channels can enhance feature\nrepresentation and thus improve crack detection. However, IR and RGB channels\noften differ in resolution. To align them, higher-resolution RGB images\ntypically need to be downsampled to match the IR image resolution, which leads\nto the loss of fine details. Moreover, crack detection performance is\nrestricted by the limited receptive fields and high computational complexity of\ntraditional image segmentation networks. Inspired by the recently proposed\nMamba neural architecture, this study introduces a two-stage paradigm called\nMSCrackMamba, which leverages Vision Mamba along with a super-resolution\nnetwork to address these challenges. Specifically, to align IR and RGB\nchannels, we first apply super-resolution to IR channels to match the\nresolution of RGB channels for data fusion. Vision Mamba is then adopted as the\nbackbone network, while UperNet is employed as the decoder for crack detection.\nOur approach is validated on the large-scale Crack Detection dataset Crack900,\ndemonstrating an improvement of 3.55% in mIoU compared to the best-performing\nbaseline methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06211v1",
    "published_date": "2024-12-09 05:15:44 UTC",
    "updated_date": "2024-12-09 05:15:44 UTC"
  },
  {
    "arxiv_id": "2412.06207v1",
    "title": "Skill-Enhanced Reinforcement Learning Acceleration from Demonstrations",
    "authors": [
      "Hanping Zhang",
      "Yuhong Guo"
    ],
    "abstract": "Learning from Demonstration (LfD) aims to facilitate rapid Reinforcement\nLearning (RL) by leveraging expert demonstrations to pre-train the RL agent.\nHowever, the limited availability of expert demonstration data often hinders\nits ability to effectively aid downstream RL learning. To address this problem,\nwe propose a novel two-stage method dubbed as Skill-enhanced Reinforcement\nLearning Acceleration (SeRLA). SeRLA introduces a skill-level adversarial\nPositive-Unlabeled (PU) learning model to extract useful skill prior knowledge\nby enabling learning from both limited expert data and general low-cost\ndemonstration data in the offline prior learning stage. Subsequently, it\ndeploys a skill-based soft actor-critic algorithm to leverage this acquired\nprior knowledge in the downstream online RL stage for efficient training of a\nskill policy network. Moreover, we develop a simple skill-level data\nenhancement technique to further alleviate data sparsity and improve both skill\nprior learning and downstream skill policy training. Our experimental results\non multiple standard RL environments show the proposed SeRLA method achieves\nstate-of-the-art performance on accelerating reinforcement learning on\ndownstream tasks, especially in the early learning phase.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024 AutoRL Workshop; 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.06207v1",
    "published_date": "2024-12-09 04:58:14 UTC",
    "updated_date": "2024-12-09 04:58:14 UTC"
  },
  {
    "arxiv_id": "2412.06206v2",
    "title": "SiReRAG: Indexing Similar and Related Information for Multihop Reasoning",
    "authors": [
      "Nan Zhang",
      "Prafulla Kumar Choubey",
      "Alexander Fabbri",
      "Gabriel Bernadett-Shapiro",
      "Rui Zhang",
      "Prasenjit Mitra",
      "Caiming Xiong",
      "Chien-Sheng Wu"
    ],
    "abstract": "Indexing is an important step towards strong performance in\nretrieval-augmented generation (RAG) systems. However, existing methods\norganize data based on either semantic similarity (similarity) or related\ninformation (relatedness), but do not cover both perspectives comprehensively.\nOur analysis reveals that modeling only one perspective results in insufficient\nknowledge synthesis, leading to suboptimal performance on complex tasks\nrequiring multihop reasoning. In this paper, we propose SiReRAG, a novel RAG\nindexing approach that explicitly considers both similar and related\ninformation. On the similarity side, we follow existing work and explore some\nvariances to construct a similarity tree based on recursive summarization. On\nthe relatedness side, SiReRAG extracts propositions and entities from texts,\ngroups propositions via shared entities, and generates recursive summaries to\nconstruct a relatedness tree. We index and flatten both similarity and\nrelatedness trees into a unified retrieval pool. Our experiments demonstrate\nthat SiReRAG consistently outperforms state-of-the-art indexing methods on\nthree multihop datasets (MuSiQue, 2WikiMultiHopQA, and HotpotQA), with an\naverage 1.9% improvement in F1 scores. As a reasonably efficient solution,\nSiReRAG enhances existing reranking methods significantly, with up to 7.8%\nimprovement in average F1 scores. Our code is available at\nhttps://github.com/SalesforceAIResearch/SiReRAG .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06206v2",
    "published_date": "2024-12-09 04:56:43 UTC",
    "updated_date": "2025-04-07 19:47:16 UTC"
  },
  {
    "arxiv_id": "2412.17819v1",
    "title": "Inductive Linguistic Reasoning with Large Language Models",
    "authors": [
      "Raghav Ramji",
      "Keshav Ramji"
    ],
    "abstract": "Evaluating large language models (LLMs) on their linguistic reasoning\ncapabilities is an important task to understand the gaps in their skills that\nmay surface during large-scale adoption. In this work, we investigate the\nabilities of such models to perform abstract multilingual reasoning through the\nlens of linguistic puzzles on extremely low-resource languages. As these\ntranslation tasks involve inductive and deductive reasoning from reference\ninstances, we examine whether diverse auxiliary demonstrations can be\nautomatically induced from seed exemplars, through analogical prompting. We\nemploy a two-stage procedure, first generating analogical exemplars with a\nlanguage model, and then applying them in-context along with provided target\nlanguage exemplars. Our results on the modeLing dataset show that analogical\nprompting is effective in eliciting models' knowledge of language grammar\nsimilarities, boosting the performance of GPT-4o by as much as 8.1% and\nLlama-3.1-405B-Instruct by 5.9% over chain-of-thought approaches. These gains\nare attributable to the analogical demonstrations, both when self-generated as\nwell as when produced by weaker multilingual models. Furthermore, we\ndemonstrate that our method generalizes to other tasks present in Linguistics\nOlympiad competitions, achieving sizable improvements across all problem types\nand difficulty levels included in the LINGOLY dataset with GPT-4o. We also\nreport several findings about interesting phenomena which drive linguistic\nreasoning performance, suggesting that such puzzles are a valuable benchmark\nfor new reasoning methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17819v1",
    "published_date": "2024-12-09 03:37:11 UTC",
    "updated_date": "2024-12-09 03:37:11 UTC"
  },
  {
    "arxiv_id": "2412.06181v1",
    "title": "Enhancing Adversarial Resistance in LLMs with Recursion",
    "authors": [
      "Bryan Li",
      "Sounak Bagchi",
      "Zizhan Wang"
    ],
    "abstract": "The increasing integration of Large Language Models (LLMs) into society\nnecessitates robust defenses against vulnerabilities from jailbreaking and\nadversarial prompts. This project proposes a recursive framework for enhancing\nthe resistance of LLMs to manipulation through the use of prompt simplification\ntechniques. By increasing the transparency of complex and confusing adversarial\nprompts, the proposed method enables more reliable detection and prevention of\nmalicious inputs. Our findings attempt to address a critical problem in AI\nsafety and security, providing a foundation for the development of systems able\nto distinguish harmless inputs from prompts containing malicious intent. As\nLLMs continue to be used in diverse applications, the importance of such\nsafeguards will only grow.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06181v1",
    "published_date": "2024-12-09 03:34:49 UTC",
    "updated_date": "2024-12-09 03:34:49 UTC"
  },
  {
    "arxiv_id": "2412.06179v1",
    "title": "Annotations for Exploring Food Tweets From Multiple Aspects",
    "authors": [
      "Matīss Rikters",
      "Edison Marrese-Taylor",
      "Rinalds Vīksna"
    ],
    "abstract": "This research builds upon the Latvian Twitter Eater Corpus (LTEC), which is\nfocused on the narrow domain of tweets related to food, drinks, eating and\ndrinking. LTEC has been collected for more than 12 years and reaching almost 3\nmillion tweets with the basic information as well as extended automatically and\nmanually annotated metadata. In this paper we supplement the LTEC with manually\nannotated subsets of evaluation data for machine translation, named entity\nrecognition, timeline-balanced sentiment analysis, and text-image relation\nclassification. We experiment with each of the data sets using baseline models\nand highlight future challenges for various modelling approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06179v1",
    "published_date": "2024-12-09 03:32:40 UTC",
    "updated_date": "2024-12-09 03:32:40 UTC"
  },
  {
    "arxiv_id": "2412.06176v1",
    "title": "AlphaVerus: Bootstrapping Formally Verified Code Generation through Self-Improving Translation and Treefinement",
    "authors": [
      "Pranjal Aggarwal",
      "Bryan Parno",
      "Sean Welleck"
    ],
    "abstract": "Automated code generation with large language models has gained significant\ntraction, but there remains no guarantee on the correctness of generated code.\nWe aim to use formal verification to provide mathematical guarantees that the\ngenerated code is correct. However, generating formally verified code with LLMs\nis hindered by the scarcity of training data and the complexity of formal\nproofs. To tackle this challenge, we introduce AlphaVerus, a self-improving\nframework that bootstraps formally verified code generation by iteratively\ntranslating programs from a higher-resource language and leveraging feedback\nfrom a verifier. AlphaVerus operates in three phases: exploration of candidate\ntranslations, Treefinement -- a novel tree search algorithm for program\nrefinement using verifier feedback, and filtering misaligned specifications and\nprograms to prevent reward hacking. Through this iterative process, AlphaVerus\nenables a LLaMA-3.1-70B model to generate verified code without human\nintervention or model finetuning. AlphaVerus shows an ability to generate\nformally verified solutions for HumanEval and MBPP, laying the groundwork for\ntruly trustworthy code-generation agents.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06176v1",
    "published_date": "2024-12-09 03:22:35 UTC",
    "updated_date": "2024-12-09 03:22:35 UTC"
  },
  {
    "arxiv_id": "2412.06167v1",
    "title": "ACQ: A Unified Framework for Automated Programmatic Creativity in Online Advertising",
    "authors": [
      "Ruizhi Wang",
      "Kai Liu",
      "Bingjie Li",
      "Yu Rong",
      "Qingpeng Cai",
      "Fei Pan",
      "Peng Jiang"
    ],
    "abstract": "In online advertising, the demand-side platform (a.k.a. DSP) enables\nadvertisers to create different ad creatives for real-time bidding.\nIntuitively, advertisers tend to create more ad creatives for a single photo to\nincrease the probability of participating in bidding, further enhancing their\nad cost. From the perspective of DSP, the following are two overlooked issues.\nOn the one hand, the number of ad creatives cannot grow indefinitely. On the\nother hand, the marginal effects of ad cost diminish as the number of ad\ncreatives increases. To this end, this paper proposes a two-stage framework\nnamed Automated Creatives Quota (ACQ) to achieve the automatic creation and\ndeactivation of ad creatives. ACQ dynamically allocates the creative quota\nacross multiple advertisers to maximize the revenue of the ad platform. ACQ\ncomprises two components: a prediction module to estimate the cost of a photo\nunder different numbers of ad creatives, and an allocation module to decide the\nquota for photos considering their estimated costs in the prediction module.\nSpecifically, in the prediction module, we develop a multi-task learning model\nbased on an unbalanced binary tree to effectively mitigate the target variable\nimbalance problem. In the allocation module, we formulate the quota allocation\nproblem as a multiple-choice knapsack problem (MCKP) and develop an efficient\nsolver to solve such large-scale problems involving tens of millions of ads. We\nperformed extensive offline and online experiments to validate the superiority\nof our proposed framework, which increased cost by 9.34%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06167v1",
    "published_date": "2024-12-09 03:00:57 UTC",
    "updated_date": "2024-12-09 03:00:57 UTC"
  },
  {
    "arxiv_id": "2412.06165v1",
    "title": "Conservative Contextual Bandits: Beyond Linear Representations",
    "authors": [
      "Rohan Deb",
      "Mohammad Ghavamzadeh",
      "Arindam Banerjee"
    ],
    "abstract": "Conservative Contextual Bandits (CCBs) address safety in sequential decision\nmaking by requiring that an agent's policy, along with minimizing regret, also\nsatisfies a safety constraint: the performance is not worse than a baseline\npolicy (e.g., the policy that the company has in production) by more than\n$(1+\\alpha)$ factor. Prior work developed UCB-style algorithms in the\nmulti-armed [Wu et al., 2016] and contextual linear [Kazerouni et al., 2017]\nsettings. However, in practice the cost of the arms is often a non-linear\nfunction, and therefore existing UCB algorithms are ineffective in such\nsettings. In this paper, we consider CCBs beyond the linear case and develop\ntwo algorithms $\\mathtt{C-SquareCB}$ and $\\mathtt{C-FastCB}$, using Inverse Gap\nWeighting (IGW) based exploration and an online regression oracle. We show that\nthe safety constraint is satisfied with high probability and that the regret of\n$\\mathtt{C-SquareCB}$ is sub-linear in horizon $T$, while the regret of\n$\\mathtt{C-FastCB}$ is first-order and is sub-linear in $L^*$, the cumulative\nloss of the optimal policy. Subsequently, we use a neural network for function\napproximation and online gradient descent as the regression oracle to provide\n$\\tilde{O}(\\sqrt{KT} + K/\\alpha) $ and $\\tilde{O}(\\sqrt{KL^*} + K (1 +\n1/\\alpha))$ regret bounds, respectively. Finally, we demonstrate the efficacy\nof our algorithms on real-world data and show that they significantly\noutperform the existing baseline while maintaining the performance guarantee.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06165v1",
    "published_date": "2024-12-09 02:57:27 UTC",
    "updated_date": "2024-12-09 02:57:27 UTC"
  },
  {
    "arxiv_id": "2501.14733v1",
    "title": "LLM as HPC Expert: Extending RAG Architecture for HPC Data",
    "authors": [
      "Yusuke Miyashita",
      "Patrick Kin Man Tung",
      "Johan Barthélemy"
    ],
    "abstract": "High-Performance Computing (HPC) is crucial for performing advanced\ncomputational tasks, yet their complexity often challenges users, particularly\nthose unfamiliar with HPC-specific commands and workflows. This paper\nintroduces Hypothetical Command Embeddings (HyCE), a novel method that extends\nRetrieval-Augmented Generation (RAG) by integrating real-time, user-specific\nHPC data, enhancing accessibility to these systems. HyCE enriches large\nlanguage models (LLM) with real-time, user-specific HPC information, addressing\nthe limitations of fine-tuned models on such data. We evaluate HyCE using an\nautomated RAG evaluation framework, where the LLM itself creates synthetic\nquestions from the HPC data and serves as a judge, assessing the efficacy of\nthe extended RAG with the evaluation metrics relevant for HPC tasks.\nAdditionally, we tackle essential security concerns, including data privacy and\ncommand execution risks, associated with deploying LLMs in HPC environments.\nThis solution provides a scalable and adaptable approach for HPC clusters to\nleverage LLMs as HPC expert, bridging the gap between users and the complex\nsystems of HPC.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2501.14733v1",
    "published_date": "2024-12-09 02:55:30 UTC",
    "updated_date": "2024-12-09 02:55:30 UTC"
  },
  {
    "arxiv_id": "2412.18614v1",
    "title": "Investigating Acoustic-Textual Emotional Inconsistency Information for Automatic Depression Detection",
    "authors": [
      "Rongfeng Su",
      "Changqing Xu",
      "Xinyi Wu",
      "Feng Xu",
      "Xie Chen",
      "Lan Wangt",
      "Nan Yan"
    ],
    "abstract": "Previous studies have demonstrated that emotional features from a single\nacoustic sentiment label can enhance depression diagnosis accuracy.\nAdditionally, according to the Emotion Context-Insensitivity theory and our\npilot study, individuals with depression might convey negative emotional\ncontent in an unexpectedly calm manner, showing a high degree of inconsistency\nin emotional expressions during natural conversations. So far, few studies have\nrecognized and leveraged the emotional expression inconsistency for depression\ndetection. In this paper, a multimodal cross-attention method is presented to\ncapture the Acoustic-Textual Emotional Inconsistency (ATEI) information. This\nis achieved by analyzing the intricate local and long-term dependencies of\nemotional expressions across acoustic and textual domains, as well as the\nmismatch between the emotional content within both domains. A Transformer-based\nmodel is then proposed to integrate this ATEI information with various fusion\nstrategies for detecting depression. Furthermore, a scaling technique is\nemployed to adjust the ATEI feature degree during the fusion process, thereby\nenhancing the model's ability to discern patients with depression across\nvarying levels of severity. To best of our knowledge, this work is the first to\nincorporate emotional expression inconsistency information into depression\ndetection. Experimental results on a counseling conversational dataset\nillustrate the effectiveness of our method.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18614v1",
    "published_date": "2024-12-09 02:52:52 UTC",
    "updated_date": "2024-12-09 02:52:52 UTC"
  },
  {
    "arxiv_id": "2412.06162v1",
    "title": "Query-Efficient Planning with Language Models",
    "authors": [
      "Gonzalo Gonzalez-Pumariega",
      "Wayne Chen",
      "Kushal Kedia",
      "Sanjiban Choudhury"
    ],
    "abstract": "Planning in complex environments requires an agent to efficiently query a\nworld model to find a feasible sequence of actions from start to goal. Recent\nwork has shown that Large Language Models (LLMs), with their rich prior\nknowledge and reasoning capabilities, can potentially help with planning by\nsearching over promising states and adapting to feedback from the world. In\nthis paper, we propose and study two fundamentally competing frameworks that\nleverage LLMs for query-efficient planning. The first uses LLMs as a heuristic\nwithin a search-based planner to select promising nodes to expand and propose\npromising actions. The second uses LLMs as a generative planner to propose an\nentire sequence of actions from start to goal, query a world model, and adapt\nbased on feedback. We show that while both approaches improve upon comparable\nbaselines, using an LLM as a generative planner results in significantly fewer\ninteractions. Our key finding is that the LLM as a planner can more rapidly\nadapt its planning strategies based on immediate feedback than LLM as a\nheuristic. We present evaluations and ablations on Robotouille and PDDL\nplanning benchmarks and discuss connections to existing theory on\nquery-efficient planning algorithms. Code is available at\nhttps://github.com/portal-cornell/llms-for-planning",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages (not including references or appendix); 13 figures (9 main\n  paper, 4 appendix); (v1) preprint",
    "pdf_url": "http://arxiv.org/pdf/2412.06162v1",
    "published_date": "2024-12-09 02:51:21 UTC",
    "updated_date": "2024-12-09 02:51:21 UTC"
  },
  {
    "arxiv_id": "2412.06860v2",
    "title": "Balancing Efficiency and Effectiveness: An LLM-Infused Approach for Optimized CTR Prediction",
    "authors": [
      "Guoxiao Zhang",
      "Yi Wei",
      "Yadong Zhang",
      "Huajian Feng",
      "Qiang Liu"
    ],
    "abstract": "Click-Through Rate (CTR) prediction is essential in online advertising, where\nsemantic information plays a pivotal role in shaping user decisions and\nenhancing CTR effectiveness. Capturing and modeling deep semantic information,\nsuch as a user's preference for \"H\\\"aagen-Dazs' HEAVEN strawberry light ice\ncream\" due to its health-conscious and premium attributes, is challenging.\nTraditional semantic modeling often overlooks these intricate details at the\nuser and item levels. To bridge this gap, we introduce a novel approach that\nmodels deep semantic information end-to-end, leveraging the comprehensive world\nknowledge capabilities of Large Language Models (LLMs). Our proposed\nLLM-infused CTR prediction framework(Multi-level Deep Semantic Information\nInfused CTR model via Distillation, MSD) is designed to uncover deep semantic\ninsights by utilizing LLMs to extract and distill critical information into a\nsmaller, more efficient model, enabling seamless end-to-end training and\ninference. Importantly, our framework is carefully designed to balance\nefficiency and effectiveness, ensuring that the model not only achieves high\nperformance but also operates with optimal resource utilization. Online A/B\ntests conducted on the Meituan sponsored-search system demonstrate that our\nmethod significantly outperforms baseline models in terms of Cost Per Mile\n(CPM) and CTR, validating its effectiveness, scalability, and balanced approach\nin real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 4 figures,4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.06860v2",
    "published_date": "2024-12-09 02:36:38 UTC",
    "updated_date": "2025-03-04 11:47:27 UTC"
  },
  {
    "arxiv_id": "2412.06154v1",
    "title": "MoSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds",
    "authors": [
      "Edward Chen",
      "Natalie Dullerud",
      "Thomas Niedermayr",
      "Elizabeth Kidd",
      "Ransalu Senanayake",
      "Pang Wei Koh",
      "Sanmi Koyejo",
      "Carlos Guestrin"
    ],
    "abstract": "Countless science and engineering applications in multi-objective\noptimization (MOO) necessitate that decision-makers (DMs) select a\nPareto-optimal solution which aligns with their preferences. Evaluating\nindividual solutions is often expensive, necessitating cost-sensitive\noptimization techniques. Due to competing objectives, the space of trade-offs\nis also expansive -- thus, examining the full Pareto frontier may prove\noverwhelming to a DM. Such real-world settings generally have loosely-defined\nand context-specific desirable regions for each objective function that can aid\nin constraining the search over the Pareto frontier. We introduce a novel\nconceptual framework that operationalizes these priors using soft-hard\nfunctions, SHFs, which allow for the DM to intuitively impose soft and hard\nbounds on each objective -- which has been lacking in previous MOO frameworks.\nLeveraging a novel minimax formulation for Pareto frontier sampling, we propose\na two-step process for obtaining a compact set of Pareto-optimal points which\nrespect the user-defined soft and hard bounds: (1) densely sample the Pareto\nfrontier using Bayesian optimization, and (2) sparsify the selected set to\nsurface to the user, using robust submodular function optimization. We prove\nthat (2) obtains the optimal compact Pareto-optimal set of points from (1). We\nfurther show that many practical problems fit within the SHF framework and\nprovide extensive empirical validation on diverse domains, including\nbrachytherapy, engineering design, and large language model personalization.\nSpecifically, for brachytherapy, our approach returns a compact set of points\nwith over 3% greater SHF-defined utility than the next best approach. Among the\nother diverse experiments, our approach consistently leads in utility, allowing\nthe DM to reach >99% of their maximum possible desired utility within\nvalidation of 5 points.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06154v1",
    "published_date": "2024-12-09 02:32:20 UTC",
    "updated_date": "2024-12-09 02:32:20 UTC"
  },
  {
    "arxiv_id": "2412.06148v2",
    "title": "The Computational Limits of State-Space Models and Mamba via the Lens of Circuit Complexity",
    "authors": [
      "Yifang Chen",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "In this paper, we analyze the computational limitations of Mamba and\nState-space Models (SSMs) by using the circuit complexity framework. Despite\nMamba's stateful design and recent attention as a strong candidate to\noutperform Transformers, we have demonstrated that both Mamba and SSMs with\n$\\mathrm{poly}(n)$-precision and constant-depth layers reside within the\n$\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ complexity class. This result\nindicates Mamba has the same computational capabilities as Transformer\ntheoretically, and it cannot solve problems like arithmetic formula problems,\nboolean formula value problems, and permutation composition problems if\n$\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. Therefore, it challenges the assumption\nMamba is more computationally expressive than Transformers. Our contributions\ninclude rigorous proofs showing that Selective SSM and Mamba architectures can\nbe simulated by $\\mathsf{DLOGTIME}$-uniform $\\mathsf{TC}^0$ circuits, and they\ncannot solve problems outside $\\mathsf{TC}^0$.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CC",
    "comment": "CPAL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06148v2",
    "published_date": "2024-12-09 02:01:18 UTC",
    "updated_date": "2025-02-20 18:38:08 UTC"
  },
  {
    "arxiv_id": "2412.06146v2",
    "title": "Homogeneous Dynamics Space for Heterogeneous Humans",
    "authors": [
      "Xinpeng Liu",
      "Junxuan Liang",
      "Chenshuo Zhang",
      "Zixuan Cai",
      "Cewu Lu",
      "Yong-Lu Li"
    ],
    "abstract": "Analyses of human motion kinematics have achieved tremendous advances.\nHowever, the production mechanism, known as human dynamics, is still\nundercovered. In this paper, we aim to push data-driven human dynamics\nunderstanding forward. We identify a major obstacle to this as the\nheterogeneity of existing human motion understanding efforts. Specifically,\nheterogeneity exists in not only the diverse kinematics representations and\nhierarchical dynamics representations but also in the data from different\ndomains, namely biomechanics and reinforcement learning. With an in-depth\nanalysis of the existing heterogeneity, we propose to emphasize the beneath\nhomogeneity: all of them represent the homogeneous fact of human motion, though\nfrom different perspectives. Given this, we propose Homogeneous Dynamics Space\n(HDyS) as a fundamental space for human dynamics by aggregating heterogeneous\ndata and training a homogeneous latent space with inspiration from the\ninverse-forward dynamics procedure. Leveraging the heterogeneous\nrepresentations and datasets, HDyS achieves decent mapping between human\nkinematics and dynamics. We demonstrate the feasibility of HDyS with extensive\nexperiments and applications. The project page is\nhttps://foruck.github.io/HDyS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025. Cewu Lu and Yong-Lu Li are the corresponding\n  authors",
    "pdf_url": "http://arxiv.org/pdf/2412.06146v2",
    "published_date": "2024-12-09 01:59:40 UTC",
    "updated_date": "2025-03-14 08:10:18 UTC"
  },
  {
    "arxiv_id": "2412.06143v2",
    "title": "Precise, Fast, and Low-cost Concept Erasure in Value Space: Orthogonal Complement Matters",
    "authors": [
      "Yuan Wang",
      "Ouxiang Li",
      "Tingting Mu",
      "Yanbin Hao",
      "Kuien Liu",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "abstract": "Recent success of text-to-image (T2I) generation and its increasing practical\napplications, enabled by diffusion models, require urgent consideration of\nerasing unwanted concepts, e.g., copyrighted, offensive, and unsafe ones, from\nthe pre-trained models in a precise, timely, and low-cost manner. The twofold\ndemand of concept erasure includes not only a precise removal of the target\nconcept (i.e., erasure efficacy) but also a minimal change on non-target\ncontent (i.e., prior preservation), during generation. Existing methods face\nchallenges in maintaining an effective balance between erasure efficacy and\nprior preservation, and they can be computationally costly. To improve, we\npropose a precise, fast, and low-cost concept erasure method, called Adaptive\nValue Decomposer (AdaVD), which is training-free. Our method is grounded in a\nclassical linear algebraic operation of computing the orthogonal complement,\nimplemented in the value space of each cross-attention layer within the UNet of\ndiffusion models. We design a shift factor to adaptively navigate the erasure\nstrength, enhancing effective prior preservation without sacrificing erasure\nefficacy. Extensive comparative experiments with both training-based and\ntraining-free state-of-the-art methods demonstrate that the proposed AdaVD\nexcels in both single and multiple concept erasure, showing 2 to 10 times\nimprovement in prior preservation than the second best, meanwhile achieving the\nbest or near best erasure efficacy. AdaVD supports a series of diffusion models\nand downstream image generation tasks, with code available on:\nhttps://github.com/WYuan1001/AdaVD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06143v2",
    "published_date": "2024-12-09 01:56:25 UTC",
    "updated_date": "2025-03-30 15:46:18 UTC"
  },
  {
    "arxiv_id": "2412.06141v2",
    "title": "MMedPO: Aligning Medical Vision-Language Models with Clinical-Aware Multimodal Preference Optimization",
    "authors": [
      "Kangyu Zhu",
      "Peng Xia",
      "Yun Li",
      "Hongtu Zhu",
      "Sheng Wang",
      "Huaxiu Yao"
    ],
    "abstract": "The advancement of Large Vision-Language Models (LVLMs) has propelled their\napplication in the medical field. However, Medical LVLMs (Med-LVLMs) encounter\nfactuality challenges due to modality misalignment, where the models prioritize\ntextual knowledge over visual input, leading to hallucinations that contradict\ninformation in medical images. Previous attempts to enhance modality alignment\nin Med-LVLMs through preference optimization have inadequately mitigated\nclinical relevance in preference data, making these samples easily\ndistinguishable and reducing alignment effectiveness. To address this\nchallenge, we propose MMedPO, a novel multimodal medical preference\noptimization approach that considers the clinical relevance of preference\nsamples to enhance Med-LVLM alignment. MMedPO curates multimodal preference\ndata by introducing two types of dispreference: (1) plausible hallucinations\ninjected through target Med-LVLMs or GPT-4o to produce medically inaccurate\nresponses, and (2) lesion region neglect achieved through local lesion-noising,\ndisrupting visual understanding of critical areas. We then calculate clinical\nrelevance for each sample based on scores from multiple Med-LLMs and visual\ntools, and integrate these scores into the preference optimization process as\nweights, enabling effective alignment. Our experiments demonstrate that MMedPO\nsignificantly enhances factual accuracy in Med-LVLMs, achieving substantial\nimprovements over existing preference optimization methods by averaging 14.2%\nand 51.7% across the Med-VQA and report generation tasks. Our code are\navailable in https://github.com/aiming-lab/MMedPO.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.06141v2",
    "published_date": "2024-12-09 01:50:39 UTC",
    "updated_date": "2025-05-19 03:03:31 UTC"
  },
  {
    "arxiv_id": "2412.06859v1",
    "title": "Generating floorplans for various building functionalities via latent diffusion model",
    "authors": [
      "Mohamed R. Ibrahim",
      "Josef Musil",
      "Irene Gallou"
    ],
    "abstract": "In the domain of architectural design, the foundational essence of creativity\nand human intelligence lies in the mastery of solving floorplans, a skill\ndemanding distinctive expertise and years of experience. Traditionally, the\narchitectural design process of creating floorplans often requires substantial\nmanual labour and architectural expertise. Even when relying on parametric\ndesign approaches, the process is limited based on the designer's ability to\nbuild a complex set of parameters to iteratively explore design alternatives.\nAs a result, these approaches hinder creativity and limit discovery of an\noptimal solution. Here, we present a generative latent diffusion model that\nlearns to generate floorplans for various building types based on building\nfootprints and design briefs. The introduced model learns from the complexity\nof the inter-connections between diverse building types and the mutations of\narchitectural designs. By harnessing the power of latent diffusion models, this\nresearch surpasses conventional limitations in the design process. The model's\nability to learn from diverse building types means that it cannot only\nreplicate existing designs but also produce entirely new configurations that\nfuse design elements in unexpected ways. This innovation introduces a new\ndimension of creativity into architectural design, allowing architects, urban\nplanners and even individuals without specialised expertise to explore\nuncharted territories of form and function with speed and cost-effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "17",
    "pdf_url": "http://arxiv.org/pdf/2412.06859v1",
    "published_date": "2024-12-09 01:34:22 UTC",
    "updated_date": "2024-12-09 01:34:22 UTC"
  },
  {
    "arxiv_id": "2412.13211v3",
    "title": "ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home Rearrangement Tasks",
    "authors": [
      "Arth Shukla",
      "Stone Tao",
      "Hao Su"
    ],
    "abstract": "High-quality benchmarks are the foundation for embodied AI research, enabling\nsignificant advancements in long-horizon navigation, manipulation and\nrearrangement tasks. However, as frontier tasks in robotics get more advanced,\nthey require faster simulation speed, more intricate test environments, and\nlarger demonstration datasets. To this end, we present MS-HAB, a holistic\nbenchmark for low-level manipulation and in-home object rearrangement. First,\nwe provide a GPU-accelerated implementation of the Home Assistant Benchmark\n(HAB). We support realistic low-level control and achieve over 3x the speed of\nprior magical grasp implementations at a fraction of the GPU memory usage.\nSecond, we train extensive reinforcement learning (RL) and imitation learning\n(IL) baselines for future work to compare against. Finally, we develop a\nrule-based trajectory filtering system to sample specific demonstrations from\nour RL policies which match predefined criteria for robot behavior and safety.\nCombining demonstration filtering with our fast environments enables efficient,\ncontrolled data generation at scale.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.13211v3",
    "published_date": "2024-12-09 01:29:24 UTC",
    "updated_date": "2025-02-28 10:10:33 UTC"
  },
  {
    "arxiv_id": "2412.06113v1",
    "title": "Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions",
    "authors": [
      "Guoshenghui Zhao",
      "Eric Song"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has revolutionized\nnatural language processing, enabling applications in diverse domains such as\nhealthcare, finance and education. However, the growing reliance on extensive\ndata for training and inference has raised significant privacy concerns,\nranging from data leakage to adversarial attacks. This survey comprehensively\nexplores the landscape of privacy-preserving mechanisms tailored for LLMs,\nincluding differential privacy, federated learning, cryptographic protocols,\nand trusted execution environments. We examine their efficacy in addressing key\nprivacy challenges, such as membership inference and model inversion attacks,\nwhile balancing trade-offs between privacy and model utility. Furthermore, we\nanalyze privacy-preserving applications of LLMs in privacy-sensitive domains,\nhighlighting successful implementations and inherent limitations. Finally, this\nsurvey identifies emerging research directions, emphasizing the need for novel\nframeworks that integrate privacy by design into the lifecycle of LLMs. By\nsynthesizing state-of-the-art approaches and future trends, this paper provides\na foundation for developing robust, privacy-preserving large language models\nthat safeguard sensitive information without compromising performance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06113v1",
    "published_date": "2024-12-09 00:24:09 UTC",
    "updated_date": "2024-12-09 00:24:09 UTC"
  }
]