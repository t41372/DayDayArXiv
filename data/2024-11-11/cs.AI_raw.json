[
  {
    "arxiv_id": "2411.07441v1",
    "title": "Automatically Detecting Online Deceptive Patterns in Real-time",
    "authors": [
      "Asmit Nayak",
      "Shirley Zhang",
      "Yash Wani",
      "Rishabh Khandelwal",
      "Kassem Fawaz"
    ],
    "abstract": "Deceptive patterns (DPs) in digital interfaces manipulate users into making\nunintended decisions, exploiting cognitive biases and psychological\nvulnerabilities. These patterns have become ubiquitous across various digital\nplatforms. While efforts to mitigate DPs have emerged from legal and technical\nperspectives, a significant gap in usable solutions that empower users to\nidentify and make informed decisions about DPs in real-time remains. In this\nwork, we introduce AutoBot, an automated, deceptive pattern detector that\nanalyzes websites' visual appearances using machine learning techniques to\nidentify and notify users of DPs in real-time. AutoBot employs a two-staged\npipeline that processes website screenshots, identifying interactable elements\nand extracting textual features without relying on HTML structure. By\nleveraging a custom language model, AutoBot understands the context surrounding\nthese elements to determine the presence of deceptive patterns. We implement\nAutoBot as a lightweight Chrome browser extension that performs all analyses\nlocally, minimizing latency and preserving user privacy. Through extensive\nevaluation, we demonstrate AutoBot's effectiveness in enhancing users' ability\nto navigate digital environments safely while providing a valuable tool for\nregulators to assess and enforce compliance with DP regulations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07441v1",
    "published_date": "2024-11-11 23:49:02 UTC",
    "updated_date": "2024-11-11 23:49:02 UTC"
  },
  {
    "arxiv_id": "2411.07426v1",
    "title": "Evaluating Detection Thresholds: The Impact of False Positives and Negatives on Super-Resolution Ultrasound Localization Microscopy",
    "authors": [
      "Sepideh K. Gharamaleki",
      "Brandon Helfield",
      "Hassan Rivaz"
    ],
    "abstract": "Super-resolution ultrasound imaging with ultrasound localization microscopy\n(ULM) offers a high-resolution view of microvascular structures. Yet, ULM image\nquality heavily relies on precise microbubble (MB) detection. Despite the\ncrucial role of localization algorithms, there has been limited focus on the\npractical pitfalls in MB detection tasks such as setting the detection\nthreshold. This study examines how False Positives (FPs) and False Negatives\n(FNs) affect ULM image quality by systematically adding controlled detection\nerrors to simulated data. Results indicate that while both FP and FN rates\nimpact Peak Signal-to-Noise Ratio (PSNR) similarly, increasing FP rates from\n0\\% to 20\\% decreases Structural Similarity Index (SSIM) by 7\\%, whereas same\nFN rates cause a greater drop of around 45\\%. Moreover, dense MB regions are\nmore resilient to detection errors, while sparse regions show high sensitivity,\nshowcasing the need for robust MB detection frameworks to enhance\nsuper-resolution imaging.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07426v1",
    "published_date": "2024-11-11 22:58:56 UTC",
    "updated_date": "2024-11-11 22:58:56 UTC"
  },
  {
    "arxiv_id": "2411.07425v1",
    "title": "Predicting BWR Criticality with Data-Driven Machine Learning Model",
    "authors": [
      "Muhammad Rizki Oktavian",
      "Anirudh Tunga",
      "Jonathan Nistor",
      "James Tusar",
      "J. Thomas Gruenwald",
      "Yunlin Xu"
    ],
    "abstract": "One of the challenges in operating nuclear power plants is to decide the\namount of fuel needed in a cycle. Large-scale nuclear power plants are designed\nto operate at base load, meaning that they are expected to always operate at\nfull power. Economically, a nuclear power plant should burn enough fuel to\nmaintain criticality until the end of a cycle (EOC). If the reactor goes\nsubcritical before the end of a cycle, it may result in early coastdown as the\nfuel in the core is already depleted. On contrary, if the reactor still has\nsignificant excess reactivity by the end of a cycle, the remaining fuels will\nremain unused. In both cases, the plant may lose a significant amount of money.\nThis work proposes an innovative method based on a data-driven deep learning\nmodel to estimate the excess criticality of a boiling water reactor.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07425v1",
    "published_date": "2024-11-11 22:57:11 UTC",
    "updated_date": "2024-11-11 22:57:11 UTC"
  },
  {
    "arxiv_id": "2411.07404v2",
    "title": "Controllable Context Sensitivity and the Knob Behind It",
    "authors": [
      "Julian Minder",
      "Kevin Du",
      "Niklas Stoehr",
      "Giovanni Monea",
      "Chris Wendler",
      "Robert West",
      "Ryan Cotterell"
    ],
    "abstract": "When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07404v2",
    "published_date": "2024-11-11 22:22:21 UTC",
    "updated_date": "2025-03-03 03:02:55 UTC"
  },
  {
    "arxiv_id": "2411.07398v1",
    "title": "Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews",
    "authors": [
      "Aakash Sorathiya",
      "Gouri Ginde"
    ],
    "abstract": "With the increasing proliferation of mobile applications in our everyday\nexperiences, the concerns surrounding ethics have surged significantly. Users\ngenerally communicate their feedback, report issues, and suggest new\nfunctionalities in application (app) reviews, frequently emphasizing safety,\nprivacy, and accountability concerns. Incorporating these reviews is essential\nto developing successful products. However, app reviews related to ethical\nconcerns generally use domain-specific language and are expressed using a more\nvaried vocabulary. Thus making automated ethical concern-related app review\nextraction a challenging and time-consuming effort.\n  This study proposes a novel Natural Language Processing (NLP) based approach\nthat combines Natural Language Inference (NLI), which provides a deep\ncomprehension of language nuances, and a decoder-only (LLaMA-like) Large\nLanguage Model (LLM) to extract ethical concern-related app reviews at scale.\nUtilizing 43,647 app reviews from the mental health domain, the proposed\nmethodology 1) Evaluates four NLI models to extract potential privacy reviews\nand compares the results of domain-specific privacy hypotheses with generic\nprivacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to\nprivacy concerns; and 3) Uses the best NLI and LLM models further to extract\nnew privacy reviews from the dataset. Results show that the\nDeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses\nyields the best performance, and Llama3.1-8B-Instruct LLM performs best in the\nclassification of app reviews. Then, using NLI+LLM, an additional 1,008 new\nprivacy-related reviews were extracted that were not identified through the\nkeyword-based approach in previous research, thus demonstrating the\neffectiveness of the proposed approach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07398v1",
    "published_date": "2024-11-11 22:08:48 UTC",
    "updated_date": "2024-11-11 22:08:48 UTC"
  },
  {
    "arxiv_id": "2411.07395v1",
    "title": "Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery",
    "authors": [
      "Mohamed Abul Hassan",
      "Pu Sun",
      "Xiangnan Zhou",
      "Lisanne Kraft",
      "Kelsey T Hadfield",
      "Katjana Ehrlich",
      "Jinyi Qi",
      "Andrew Birkeland",
      "Laura Marcu"
    ],
    "abstract": "This study introduces a novel data-centric approach to improve real-time\nsurgical guidance using fiber-based fluorescence lifetime imaging (FLIm). A key\naspect of the methodology is the accurate detection of the aiming beam, which\nis essential for localizing points used to map FLIm measurements onto the\ntissue region within the surgical field. The primary challenge arises from the\ncomplex and variable conditions encountered in the surgical environment,\nparticularly in Transoral Robotic Surgery (TORS). Uneven illumination in the\nsurgical field can cause reflections, reduce contrast, and results in\ninconsistent color representation, further complicating aiming beam detection.\nTo overcome these challenges, an instance segmentation model was developed\nusing a data-centric training strategy that improves accuracy by minimizing\nlabel noise and enhancing detection robustness. The model was evaluated on a\ndataset comprising 40 in vivo surgical videos, demonstrating a median detection\nrate of 85%. This performance was maintained when the model was integrated in a\nclinical system, achieving a similar detection rate of 85% during TORS\nprocedures conducted in patients. The system's computational efficiency,\nmeasured at approximately 24 frames per second (FPS), was sufficient for\nreal-time surgical guidance. This study enhances the reliability of FLIm-based\naiming beam detection in complex surgical environments, advancing the\nfeasibility of real-time, image-guided interventions for improved surgical\nprecision",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07395v1",
    "published_date": "2024-11-11 22:04:32 UTC",
    "updated_date": "2024-11-11 22:04:32 UTC"
  },
  {
    "arxiv_id": "2411.10478v2",
    "title": "Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey",
    "authors": [
      "Yang Gu",
      "Hengyu You",
      "Jian Cao",
      "Muran Yu",
      "Haoran Fan",
      "Shiyou Qian"
    ],
    "abstract": "Building effective machine learning (ML) workflows to address complex tasks\nis a primary focus of the Automatic ML (AutoML) community and a critical step\ntoward achieving artificial general intelligence (AGI). Recently, the\nintegration of Large Language Models (LLMs) into ML workflows has shown great\npotential for automating and enhancing various stages of the ML pipeline. This\nsurvey provides a comprehensive and up-to-date review of recent advancements in\nusing LLMs to construct and optimize ML workflows, focusing on key components\nencompassing data and feature engineering, model selection and hyperparameter\noptimization, and workflow evaluation. We discuss both the advantages and\nlimitations of LLM-driven approaches, emphasizing their capacity to streamline\nand enhance ML workflow modeling process through language understanding,\nreasoning, interaction, and generation. Finally, we highlight open challenges\nand propose future research directions to advance the effective application of\nLLMs in ML workflows.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.10478v2",
    "published_date": "2024-11-11 21:54:26 UTC",
    "updated_date": "2024-12-25 16:38:51 UTC"
  },
  {
    "arxiv_id": "2411.07392v1",
    "title": "Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set Domain Generalization",
    "authors": [
      "Haoliang Wang",
      "Chen Zhao",
      "Feng Chen"
    ],
    "abstract": "Open-set domain generalization addresses a real-world challenge: training a\nmodel to generalize across unseen domains (domain generalization) while also\ndetecting samples from unknown classes not encountered during training\n(open-set recognition). However, most existing approaches tackle these issues\nseparately, limiting their practical applicability. To overcome this\nlimitation, we propose a unified framework for open-set domain generalization\nby introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic\nconsistency across different domains within the feature space, enabling more\naccurate detection of OOD instances in unseen domains. Additionally, we adopt a\ngenerative model to produce synthetic data with novel domain styles or class\nlabels, enhancing model robustness. Initial experiments show that our method\nimproves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly\nincreasing in-distribution classification accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE BigData 2024, Ph.D. Forum",
    "pdf_url": "http://arxiv.org/pdf/2411.07392v1",
    "published_date": "2024-11-11 21:51:45 UTC",
    "updated_date": "2024-11-11 21:51:45 UTC"
  },
  {
    "arxiv_id": "2411.07391v1",
    "title": "Federated Learning Client Pruning for Noisy Labels",
    "authors": [
      "Mahdi Morafah",
      "Hojin Chang",
      "Chen Chen",
      "Bill Lin"
    ],
    "abstract": "Federated Learning (FL) enables collaborative model training across\ndecentralized edge devices while preserving data privacy. However, existing FL\nmethods often assume clean annotated datasets, impractical for\nresource-constrained edge devices. In reality, noisy labels are prevalent,\nposing significant challenges to FL performance. Prior approaches attempt label\ncorrection and robust training techniques but exhibit limited efficacy,\nparticularly under high noise levels. This paper introduces ClipFL (Federated\nLearning Client Pruning), a novel framework addressing noisy labels from a\nfresh perspective. ClipFL identifies and excludes noisy clients based on their\nperformance on a clean validation dataset, tracked using a Noise Candidacy\nScore (NCS). The framework comprises three phases: pre-client pruning to\nidentify potential noisy clients and calculate their NCS, client pruning to\nexclude a percentage of clients with the highest NCS, and post-client pruning\nfor fine-tuning the global model with standard FL on clean clients. Empirical\nevaluation demonstrates ClipFL's efficacy across diverse datasets and noise\nlevels, achieving accurate noisy client identification, superior performance,\nfaster convergence, and reduced communication costs compared to\nstate-of-the-art FL methods. Our code is available at\nhttps://github.com/MMorafah/ClipFL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07391v1",
    "published_date": "2024-11-11 21:46:34 UTC",
    "updated_date": "2024-11-11 21:46:34 UTC"
  },
  {
    "arxiv_id": "2411.07388v1",
    "title": "Firing Rate Models as Associative Memory: Excitatory-Inhibitory Balance for Robust Retrieval",
    "authors": [
      "Simone Betteti",
      "Giacomo Baggio",
      "Francesco Bullo",
      "Sandro Zampieri"
    ],
    "abstract": "Firing rate models are dynamical systems widely used in applied and\ntheoretical neuroscience to describe local cortical dynamics in neuronal\npopulations. By providing a macroscopic perspective of neuronal activity, these\nmodels are essential for investigating oscillatory phenomena, chaotic behavior,\nand associative memory processes. Despite their widespread use, the application\nof firing rate models to associative memory networks has received limited\nmathematical exploration, and most existing studies are focused on specific\nmodels. Conversely, well-established associative memory designs, such as\nHopfield networks, lack key biologically-relevant features intrinsic to firing\nrate models, including positivity and interpretable synaptic matrices that\nreflect excitatory and inhibitory interactions. To address this gap, we propose\na general framework that ensures the emergence of re-scaled memory patterns as\nstable equilibria in the firing rate dynamics. Furthermore, we analyze the\nconditions under which the memories are locally and globally asymptotically\nstable, providing insights into constructing biologically-plausible and robust\nsystems for associative memory retrieval.",
    "categories": [
      "q-bio.NC",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "math.DS",
      "37N25 (Primary) 34D45, 34D23 (Secondary)",
      "I.2.11; I.5.1"
    ],
    "primary_category": "q-bio.NC",
    "comment": "20 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07388v1",
    "published_date": "2024-11-11 21:40:57 UTC",
    "updated_date": "2024-11-11 21:40:57 UTC"
  },
  {
    "arxiv_id": "2411.07378v2",
    "title": "Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data",
    "authors": [
      "Yu Han",
      "Aaron Ceross",
      "Sarim Ather",
      "Jeroen H. M. Bergmann"
    ],
    "abstract": "Artificial intelligence (AI) in medical device software (MDSW) represents a\ntransformative clinical technology, attracting increasing attention within both\nthe medical community and the regulators. In this study, we leverage a\ndata-driven approach to automatically extract and analyze AI-enabled medical\ndevices (AIMD) from the National Medical Products Administration (NMPA)\nregulatory database. The continued increase in publicly available regulatory\ndata requires scalable methods for analysis. Automation of regulatory\ninformation screening is essential to create reproducible insights that can be\nquickly updated in an ever changing medical device landscape. More than 4\nmillion entries were assessed, identifying 2,174 MDSW registrations, including\n531 standalone applications and 1,643 integrated within medical devices, of\nwhich 43 were AI-enabled. It was shown that the leading medical specialties\nutilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology\n(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of\ndata extracting providing a greater ability to compare and contrast. This study\nprovides the first extensive, data-driven exploration of AIMD in China,\nshowcasing the potential of automated regulatory data analysis in understanding\nand advancing the landscape of AI in medical technology.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07378v2",
    "published_date": "2024-11-11 21:28:50 UTC",
    "updated_date": "2025-03-25 11:39:49 UTC"
  },
  {
    "arxiv_id": "2411.07376v2",
    "title": "Ensemble Learning for Microbubble Localization in Super-Resolution Ultrasound",
    "authors": [
      "Sepideh K. Gharamaleki",
      "Brandon Helfield",
      "Hassan Rivaz"
    ],
    "abstract": "Super-resolution ultrasound (SR-US) is a powerful imaging technique for\ncapturing microvasculature and blood flow at high spatial resolution. However,\naccurate microbubble (MB) localization remains a key challenge, as errors in\nlocalization can propagate through subsequent stages of the super-resolution\nprocess, affecting overall performance. In this paper, we explore the potential\nof ensemble learning techniques to enhance MB localization by increasing\ndetection sensitivity and reducing false positives. Our study evaluates the\neffectiveness of ensemble methods on both in vivo and simulated outputs of a\nDeformable DEtection TRansformer (Deformable DETR) network. As a result of our\nstudy, we are able to demonstrate the advantages of these ensemble approaches\nby showing improved precision and recall in MB detection and offering insights\ninto their application in SR-US.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07376v2",
    "published_date": "2024-11-11 21:26:36 UTC",
    "updated_date": "2025-01-03 03:55:39 UTC"
  },
  {
    "arxiv_id": "2411.07340v1",
    "title": "Warmstarting for Scaling Language Models",
    "authors": [
      "Neeratyoy Mallik",
      "Maciej Janowski",
      "Johannes Hog",
      "Herilalaina Rakotoarison",
      "Aaron Klein",
      "Josif Grabocka",
      "Frank Hutter"
    ],
    "abstract": "Scaling model sizes to scale performance has worked remarkably well for the\ncurrent large language models paradigm. The research and empirical findings of\nvarious scaling studies led to novel scaling results and laws that guides\nsubsequent research. High training costs for contemporary scales of data and\nmodels result in a lack of thorough understanding of how to tune and arrive at\nsuch training setups. One direction to ameliorate the cost of pretraining large\nmodels is to warmstart the large-scale training from smaller models that are\ncheaper to tune. In this work, we attempt to understand if the behavior of\noptimal hyperparameters can be retained under warmstarting for scaling. We\nexplore simple operations that allow the application of theoretically motivated\nmethods of zero-shot transfer of optimal hyperparameters using {\\mu}Transfer.\nWe investigate the aspects that contribute to the speedup in convergence and\nthe preservation of stable training dynamics under warmstarting with\n{\\mu}Transfer. We find that shrinking smaller model weights, zero-padding, and\nperturbing the resulting larger model with scaled initialization from {\\mu}P\nenables effective warmstarting of $\\mut{}$.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07340v1",
    "published_date": "2024-11-11 20:02:29 UTC",
    "updated_date": "2024-11-11 20:02:29 UTC"
  },
  {
    "arxiv_id": "2411.07335v2",
    "title": "Multimodal Fusion Balancing Through Game-Theoretic Regularization",
    "authors": [
      "Konstantinos Kontras",
      "Thomas Strypsteen",
      "Christos Chatzichristos",
      "Paul Pu Liang",
      "Matthew Blaschko",
      "Maarten De Vos"
    ],
    "abstract": "Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GT",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 6 figures, 4 tables, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2411.07335v2",
    "published_date": "2024-11-11 19:53:05 UTC",
    "updated_date": "2024-12-07 16:56:16 UTC"
  },
  {
    "arxiv_id": "2411.07320v2",
    "title": "Richer Output for Richer Countries: Uncovering Geographical Disparities in Generated Stories and Travel Recommendations",
    "authors": [
      "Kirti Bhagat",
      "Kinshuk Vasisht",
      "Danish Pruthi"
    ],
    "abstract": "While a large body of work inspects language models for biases concerning\ngender, race, occupation and religion, biases of geographical nature are\nrelatively less explored. Some recent studies benchmark the degree to which\nlarge language models encode geospatial knowledge. However, the impact of the\nencoded geographical knowledge (or lack thereof) on real-world applications has\nnot been documented. In this work, we examine large language models for two\ncommon scenarios that require geographical knowledge: (a) travel\nrecommendations and (b) geo-anchored story generation. Specifically, we study\nfive popular language models, and across about $100$K travel requests, and\n$200$K story generations, we observe that travel recommendations corresponding\nto poorer countries are less unique with fewer location references, and stories\nfrom these regions more often convey emotions of hardship and sadness compared\nto those from wealthier nations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of NAACL (2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.07320v2",
    "published_date": "2024-11-11 19:25:25 UTC",
    "updated_date": "2025-02-18 08:43:27 UTC"
  },
  {
    "arxiv_id": "2411.07315v2",
    "title": "Harnessing Smartphone Sensors for Enhanced Road Safety: A Comprehensive Dataset and Review",
    "authors": [
      "Amith Khandakar",
      "David G. Michelson",
      "Mansura Naznine",
      "Abdus Salam",
      "Md. Nahiduzzaman",
      "Khaled M. Khan",
      "Ponnuthurai Nagaratnam Suganthan",
      "Mohamed Arselene Ayari",
      "Hamid Menouar",
      "Julfikar Haider"
    ],
    "abstract": "Severe collisions can result from aggressive driving and poor road\nconditions, emphasizing the need for effective monitoring to ensure safety.\nSmartphones, with their array of built-in sensors, offer a practical and\naffordable solution for road-sensing. However, the lack of reliable,\nstandardized datasets has hindered progress in assessing road conditions and\ndriving patterns. This study addresses this gap by introducing a comprehensive\ndataset derived from smartphone sensors, which surpasses existing datasets by\nincorporating a diverse range of sensors including accelerometer, gyroscope,\nmagnetometer, GPS, gravity, orientation, and uncalibrated sensors. These\nsensors capture extensive parameters such as acceleration force, gravitation,\nrotation rate, magnetic field strength, and vehicle speed, providing a detailed\nunderstanding of road conditions and driving behaviors. The dataset is designed\nto enhance road safety, infrastructure maintenance, traffic management, and\nurban planning. By making this dataset available to the community, the study\naims to foster collaboration, inspire further research, and facilitate the\ndevelopment of innovative solutions in intelligent transportation systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "29 pages, 14 Figures, journal paper, submitted into Scientific Data\n  Journal",
    "pdf_url": "http://arxiv.org/pdf/2411.07315v2",
    "published_date": "2024-11-11 19:15:29 UTC",
    "updated_date": "2024-11-13 17:28:15 UTC"
  },
  {
    "arxiv_id": "2411.07308v1",
    "title": "X-DFS: Explainable Artificial Intelligence Guided Design-for-Security Solution Space Exploration",
    "authors": [
      "Tanzim Mahfuz",
      "Swarup Bhunia",
      "Prabuddha Chakraborty"
    ],
    "abstract": "Design and manufacturing of integrated circuits predominantly use a globally\ndistributed semiconductor supply chain involving diverse entities. The modern\nsemiconductor supply chain has been designed to boost production efficiency,\nbut is filled with major security concerns such as malicious modifications\n(hardware Trojans), reverse engineering (RE), and cloning. While being\ndeployed, digital systems are also subject to a plethora of threats such as\npower, timing, and electromagnetic (EM) side channel attacks. Many\nDesign-for-Security (DFS) solutions have been proposed to deal with these\nvulnerabilities, and such solutions (DFS) relays on strategic modifications\n(e.g., logic locking, side channel resilient masking, and dummy logic\ninsertion) of the digital designs for ensuring a higher level of security.\nHowever, most of these DFS strategies lack robust formalism, are often not\nhuman-understandable, and require an extensive amount of human expert effort\nduring their development/use. All of these factors make it difficult to keep up\nwith the ever growing number of microelectronic vulnerabilities. In this work,\nwe propose X-DFS, an explainable Artificial Intelligence (AI) guided DFS\nsolution-space exploration approach that can dramatically cut down the\nmitigation strategy development/use time while enriching our understanding of\nthe vulnerability by providing human-understandable decision rationale. We\nimplement X-DFS and comprehensively evaluate it for reverse engineering threats\n(SAIL, SWEEP, and OMLA) and formalize a generalized mechanism for applying\nX-DFS to defend against other threats such as hardware Trojans, fault attacks,\nand side channel attacks for seamless future extensions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07308v1",
    "published_date": "2024-11-11 19:04:29 UTC",
    "updated_date": "2024-11-11 19:04:29 UTC"
  },
  {
    "arxiv_id": "2411.07300v1",
    "title": "Artificial Intelligence Ecosystem for Automating Self-Directed Teaching",
    "authors": [
      "Tejas Satish Gotavade"
    ],
    "abstract": "This research introduces an innovative artificial intelligence-driven\neducational concept designed to optimize self-directed learning through\npersonalized course delivery and automated teaching assistance. The system\nleverages fine-tuned AI models to create an adaptive learning environment that\nencompasses customized roadmaps, automated presentation generation, and\nthree-dimensional modeling for complex concept visualization. By integrating\nreal-time virtual assistance for doubt resolution, the platform addresses the\nimmediate educational needs of learners while promoting autonomous learning\npractices. This study explores the psychological advantages of self-directed\nlearning and demonstrates how AI automation can enhance educational outcomes\nthrough personalized content delivery and interactive support mechanisms. The\nresearch contributes to the growing field of educational technology by\npresenting a comprehensive framework that combines automated content\ngeneration, visual learning aids, and intelligent tutoring to create an\nefficient, scalable solution for modern educational needs. Preliminary findings\nsuggest that this approach not only accommodates diverse learning styles but\nalso strengthens student engagement and knowledge retention through its\nemphasis on self-paced, independent learning methodologies.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 15 figures, 12 references and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.07300v1",
    "published_date": "2024-11-11 19:00:22 UTC",
    "updated_date": "2024-11-11 19:00:22 UTC"
  },
  {
    "arxiv_id": "2411.07279v2",
    "title": "The Surprising Effectiveness of Test-Time Training for Few-Shot Learning",
    "authors": [
      "Ekin Aky√ºrek",
      "Mehul Damani",
      "Adam Zweiger",
      "Linlu Qiu",
      "Han Guo",
      "Jyothish Pari",
      "Yoon Kim",
      "Jacob Andreas"
    ],
    "abstract": "Language models (LMs) have shown impressive performance on tasks within their\ntraining distribution, but often struggle with structurally novel tasks even\nwhen given a small number of in-context task examples. We investigate the\neffectiveness of test-time training (TTT) -- temporarily updating model\nparameters during inference using a loss derived from input data -- as a\nmechanism for improving LMs' reasoning and few-shot learning capabilities. On\nthe Abstraction and Reasoning Corpus (ARC), performing TTT with in-context\nexamples yields up to $6\\times$ higher accuracy compared to fine-tuned\nbaselines -- reaching $53.0\\%$ on the public validation set with an\n8B-parameter LM and $61.9\\%$ when ensembled with program-synthesis methods,\nmatching average human performance. On BIG-Bench Hard (BBH), TTT on in-context\nexamples surpasses standard few-shot prompting in the $10$-shot setting by\n$7.3$ percentage points ($50.5\\%$ to $57.8\\%$). Our findings highlight the\nlimitations of in-context learning for novel tasks and demonstrate the\npotential of test-time training to enhance language model adaptability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.07279v2",
    "published_date": "2024-11-11 18:59:45 UTC",
    "updated_date": "2025-03-25 03:36:21 UTC"
  },
  {
    "arxiv_id": "2411.07240v2",
    "title": "UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts",
    "authors": [
      "Bo Yang",
      "Qingping Yang",
      "Yingwei Ma",
      "Runtao Liu"
    ],
    "abstract": "The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and generality. This paper\nintroduces the UTMath Benchmark, a robust evaluation framework designed to\nassess LLMs through extensive unit tests, with a focus on both the accuracy and\ngenerality of model responses. It comprises 1,053 cutting-edge problems\nspanning nine mathematical domains, with an average of 68 test cases per\nproblem. UTMath is highly challenging, with the best-performing model, o1-mini,\nsolving only 32.57\\% of the problems, followed by o1-preview at 27.16\\%, and\nGPT-4o at 26.93\\%. Furthermore, we present the Reasoning-to-Coding of Thoughts\n(RCoT) approach, which encourages LLMs to engage in explicit reasoning prior to\ncode generation, thereby facilitating the production of more sophisticated\nsolutions and enhancing overall performance and efficiency. Additionally, we\nalso release the UTMath-Train training dataset (more than 70k samples), to\nsupport the community in further exploring mathematical reasoning. Our\nbenchmark can be accessed via the following link:\nhttps://github.com/UTMathGroup/UTMath",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07240v2",
    "published_date": "2024-11-11 18:59:02 UTC",
    "updated_date": "2025-01-14 07:57:26 UTC"
  },
  {
    "arxiv_id": "2411.07232v2",
    "title": "Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models",
    "authors": [
      "Yoad Tewel",
      "Rinon Gal",
      "Dvir Samuel",
      "Yuval Atzmon",
      "Lior Wolf",
      "Gal Chechik"
    ],
    "abstract": "Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page is at https://research.nvidia.com/labs/par/addit/",
    "pdf_url": "http://arxiv.org/pdf/2411.07232v2",
    "published_date": "2024-11-11 18:50:09 UTC",
    "updated_date": "2024-11-12 07:49:39 UTC"
  },
  {
    "arxiv_id": "2411.07228v2",
    "title": "ChemToolAgent: The Impact of Tools on Language Agents for Chemistry Problem Solving",
    "authors": [
      "Botao Yu",
      "Frazier N. Baker",
      "Ziru Chen",
      "Garrett Herb",
      "Boyu Gou",
      "Daniel Adu-Ampratwum",
      "Xia Ning",
      "Huan Sun"
    ],
    "abstract": "To enhance large language models (LLMs) for chemistry problem solving,\nseveral LLM-based agents augmented with tools have been proposed, such as\nChemCrow and Coscientist. However, their evaluations are narrow in scope,\nleaving a large gap in understanding the benefits of tools across diverse\nchemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced\nchemistry agent over ChemCrow, and conduct a comprehensive evaluation of its\nperformance on both specialized chemistry tasks and general chemistry\nquestions. Surprisingly, ChemToolAgent does not consistently outperform its\nbase LLMs without tools. Our error analysis with a chemistry expert suggests\nthat: For specialized chemistry tasks, such as synthesis prediction, we should\naugment agents with specialized tools; however, for general chemistry questions\nlike those in exams, agents' ability to reason correctly with chemistry\nknowledge matters more, and tool augmentation does not always help.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NAACL 2025 Findings. Previous title: Tooling or Not\n  Tooling? The Impact of Tools on Language Agents for Chemistry Problem\n  Solving. Based on the camera ready version, this version adds more\n  experimental results",
    "pdf_url": "http://arxiv.org/pdf/2411.07228v2",
    "published_date": "2024-11-11 18:46:37 UTC",
    "updated_date": "2025-03-03 18:09:54 UTC"
  },
  {
    "arxiv_id": "2411.07223v2",
    "title": "Grounding Video Models to Actions through Goal Conditioned Exploration",
    "authors": [
      "Yunhao Luo",
      "Yilun Du"
    ],
    "abstract": "Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICLR 2025 (Spotlight). Project page:\n  https://video-to-action.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.07223v2",
    "published_date": "2024-11-11 18:43:44 UTC",
    "updated_date": "2025-03-12 17:03:25 UTC"
  },
  {
    "arxiv_id": "2411.07218v1",
    "title": "TreeCoders: Trees of Transformers",
    "authors": [
      "Pierre Colonna D'Istria",
      "Abdulrahman Altahhan"
    ],
    "abstract": "In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07218v1",
    "published_date": "2024-11-11 18:40:04 UTC",
    "updated_date": "2024-11-11 18:40:04 UTC"
  },
  {
    "arxiv_id": "2411.07200v1",
    "title": "'Explaining RL Decisions with Trajectories': A Reproducibility Study",
    "authors": [
      "Karim Abdel Sadek",
      "Matteo Nulli",
      "Joan Velja",
      "Jort Vincenti"
    ],
    "abstract": "This work investigates the reproducibility of the paper 'Explaining RL\ndecisions with trajectories'. The original paper introduces a novel approach in\nexplainable reinforcement learning based on the attribution decisions of an\nagent to specific clusters of trajectories encountered during training. We\nverify the main claims from the paper, which state that (i) training on less\ntrajectories induces a lower initial state value, (ii) trajectories in a\ncluster present similar high-level patterns, (iii) distant trajectories\ninfluence the decision of an agent, and (iv) humans correctly identify the\nattributed trajectories to the decision of the agent. We recover the\nenvironments used by the authors based on the partial original code they\nprovided for one of the environments (Grid-World), and implemented the\nremaining from scratch (Seaquest, HalfCheetah, Breakout and Q*Bert). While we\nconfirm that (i), (ii), and (iii) partially hold, we extend on the largely\nqualitative experiments from the authors by introducing a quantitative metric\nto further support (iii), and new experiments and visual results for (i).\nMoreover, we investigate the use of different clustering algorithms and encoder\narchitectures to further support (ii). We could not support (iv), given the\nlimited extent of the original experiments. We conclude that, while some of the\nclaims can be supported, further investigations and experiments could be of\ninterest. We recognise the novelty of the work from the authors and hope that\nour work paves the way for clearer and more transparent approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07200v1",
    "published_date": "2024-11-11 18:24:27 UTC",
    "updated_date": "2024-11-11 18:24:27 UTC"
  },
  {
    "arxiv_id": "2411.07199v2",
    "title": "OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision",
    "authors": [
      "Cong Wei",
      "Zheyang Xiong",
      "Weiming Ren",
      "Xinrun Du",
      "Ge Zhang",
      "Wenhu Chen"
    ],
    "abstract": "Instruction-guided image editing methods have demonstrated significant\npotential by training diffusion models on automatically synthesized or manually\nannotated image editing pairs. However, these methods remain far from\npractical, real-life applications. We identify three primary challenges\ncontributing to this gap. Firstly, existing models have limited editing skills\ndue to the biased synthesis process. Secondly, these methods are trained with\ndatasets with a high volume of noise and artifacts. This is due to the\napplication of simple filtering methods like CLIP-score. Thirdly, all these\ndatasets are restricted to a single low resolution and fixed aspect ratio,\nlimiting the versatility to handle real-world use cases. In this paper, we\npresent \\omniedit, which is an omnipotent editor to handle seven different\nimage editing tasks with any aspect ratio seamlessly. Our contribution is in\nfour folds: (1) \\omniedit is trained by utilizing the supervision from seven\ndifferent specialist models to ensure task coverage. (2) we utilize importance\nsampling based on the scores provided by large multimodal models (like GPT-4o)\ninstead of CLIP-score to improve the data quality. (3) we propose a new editing\narchitecture called EditNet to greatly boost the editing success rate, (4) we\nprovide images with different aspect ratios to ensure that our model can handle\nany image in the wild. We have curated a test set containing images of\ndifferent aspect ratios, accompanied by diverse instructions to cover different\ntasks. Both automatic evaluation and human evaluations demonstrate that\n\\omniedit can significantly outperform all the existing models. Our code,\ndataset and model will be available at https://tiger-ai-lab.github.io/OmniEdit/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.07199v2",
    "published_date": "2024-11-11 18:21:43 UTC",
    "updated_date": "2025-04-28 14:16:29 UTC"
  },
  {
    "arxiv_id": "2411.07191v1",
    "title": "The Super Weight in Large Language Models",
    "authors": [
      "Mengxia Yu",
      "De Wang",
      "Qi Shan",
      "Colorado Reed",
      "Alvin Wan"
    ],
    "abstract": "Recent works have shown a surprising result: a small fraction of Large\nLanguage Model (LLM) parameter outliers are disproportionately important to the\nquality of the model. LLMs contain billions of parameters, so these small\nfractions, such as 0.01%, translate to hundreds of thousands of parameters. In\nthis work, we present an even more surprising finding: Pruning as few as a\nsingle parameter can destroy an LLM's ability to generate text -- increasing\nperplexity by 3 orders of magnitude and reducing zero-shot accuracy to\nguessing. We propose a data-free method for identifying such parameters, termed\nsuper weights, using a single forward pass through the model. We additionally\nfind that these super weights induce correspondingly rare and large activation\noutliers, termed super activations. When preserved with high precision, super\nactivations can improve simple round-to-nearest quantization to become\ncompetitive with state-of-the-art methods. For weight quantization, we\nsimilarly find that by preserving the super weight and clipping other weight\noutliers, round-to-nearest quantization can scale to much larger block sizes\nthan previously considered. To facilitate further research into super weights,\nwe provide an index of super weight coordinates for common, openly available\nLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07191v1",
    "published_date": "2024-11-11 18:05:48 UTC",
    "updated_date": "2024-11-11 18:05:48 UTC"
  },
  {
    "arxiv_id": "2411.07186v1",
    "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics",
    "authors": [
      "David Robinson",
      "Marius Miron",
      "Masato Hagiwara",
      "Olivier Pietquin"
    ],
    "abstract": "Large language models (LLMs) prompted with text and audio represent the state\nof the art in various auditory tasks, including speech, music, and general\naudio, showing emergent abilities on unseen tasks. However, these capabilities\nhave yet to be fully demonstrated in bioacoustics tasks, such as detecting\nanimal vocalizations in large recordings, classifying rare and endangered\nspecies, and labeling context and behavior - tasks that are crucial for\nconservation, biodiversity monitoring, and the study of animal behavior. In\nthis work, we present NatureLM-audio, the first audio-language foundation model\nspecifically designed for bioacoustics. Our carefully curated training dataset\ncomprises text-audio pairs spanning a diverse range of bioacoustics, speech,\nand music data, designed to address the challenges posed by limited annotated\ndatasets in the field. We demonstrate successful transfer of learned\nrepresentations from music and speech to bioacoustics, and our model shows\npromising generalization to unseen taxa and tasks. Importantly, we test\nNatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of\nthe art (SotA) on several bioacoustics tasks, including zero-shot\nclassification of unseen species. To advance bioacoustics research, we also\nopen-source the code for generating training and benchmark data, as well as for\ntraining the model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Demo page: https://earthspecies.github.io/naturelm-audio-demo/ The\n  code will be open-sourced and available shortly",
    "pdf_url": "http://arxiv.org/pdf/2411.07186v1",
    "published_date": "2024-11-11 18:01:45 UTC",
    "updated_date": "2024-11-11 18:01:45 UTC"
  },
  {
    "arxiv_id": "2411.07185v1",
    "title": "Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation",
    "authors": [
      "Yao Ma",
      "Samuel Louvan",
      "Zhunxuan Wang"
    ],
    "abstract": "Multi-source unsupervised domain adaptation aims to leverage labeled data\nfrom multiple source domains for training a machine learning model to\ngeneralize well on a target domain without labels. Source domain selection\nplays a crucial role in determining the model's performance. It relies on the\nsimilarities amongst source and target domains. Nonetheless, existing work for\nsource domain selection often involves heavyweight computational procedures,\nespecially when dealing with numerous source domains and the need to identify\nthe best ones from them. In this paper, we introduce a framework for gradual\nfine tuning (GFT) of machine learning models on multiple source domains. We\nrepresent multiple source domains as an undirected weighted graph. We then give\na new generalization error bound for GFT along any path within the graph, which\nis used to determine the optimal path corresponding to the optimal training\norder. With this formulation, we introduce three lightweight graph-routing\nstrategies which tend to minimize the error bound. Our best strategy improves\n$2.3\\%$ of accuracy over the state-of-the-art on Natural Language Inference\n(NLI) task and achieves competitive performance on Sentiment Analysis (SA)\ntask, especially a $3.9\\%$ improvement on a more diverse subset of data we use\nfor SA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 3rd Conference on Lifelong Learning Agents\n  (CoLLAs 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.07185v1",
    "published_date": "2024-11-11 17:59:21 UTC",
    "updated_date": "2024-11-11 17:59:21 UTC"
  },
  {
    "arxiv_id": "2411.07180v5",
    "title": "Gumbel Counterfactual Generation From Language Models",
    "authors": [
      "Shauli Ravfogel",
      "Anej Svete",
      "V√©steinn Sn√¶bjarnarson",
      "Ryan Cotterell"
    ],
    "abstract": "Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07180v5",
    "published_date": "2024-11-11 17:57:30 UTC",
    "updated_date": "2025-03-06 15:26:56 UTC"
  },
  {
    "arxiv_id": "2411.07176v3",
    "title": "More Expressive Attention with Negative Weights",
    "authors": [
      "Ang Lv",
      "Ruobing Xie",
      "Shuaipeng Li",
      "Jiayi Liao",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Di Wang",
      "Rui Yan"
    ],
    "abstract": "We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention enhances parameter flexibility. For example,\nunlike traditional softmax attention heads that use a static output-value (OV)\nmatrix to delete or copy inputs that the heads attend to, Cog Attention\nnaturally learns to use the sign of dynamic query-key (QK) inner products to\nrepresent these operations. This enables Cog Attention to perform multiple\noperations simultaneously within a single head. Meanwhile, Cog Attention's OV\nmatrix can focus more on refinement or modification. (2) Cog Attention enhances\nthe model's robustness against representational collapse by preventing the\n``over-squashing'' of earlier tokens into later positions. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models at various scales for language modeling and U-ViT diffusion\nmodels for image generation. Experiments show that models using Cog Attention\nexhibit superior performance compared to those employing traditional softmax\nattention modules. Our approach suggests a promising research direction for\nrethinking and breaking the entrenched constraints of traditional softmax\nattention, such as the requirement for non-negative weights.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07176v3",
    "published_date": "2024-11-11 17:56:28 UTC",
    "updated_date": "2025-01-30 18:17:13 UTC"
  },
  {
    "arxiv_id": "2411.07171v1",
    "title": "Anytime Sequential Halving in Monte-Carlo Tree Search",
    "authors": [
      "Dominic Sagers",
      "Mark H. M. Winands",
      "Dennis J. N. J. Soemers"
    ],
    "abstract": "Monte-Carlo Tree Search (MCTS) typically uses multi-armed bandit (MAB)\nstrategies designed to minimize cumulative regret, such as UCB1, as its\nselection strategy. However, in the root node of the search tree, it is more\nsensible to minimize simple regret. Previous work has proposed using Sequential\nHalving as selection strategy in the root node, as, in theory, it performs\nbetter with respect to simple regret. However, Sequential Halving requires a\nbudget of iterations to be predetermined, which is often impractical. This\npaper proposes an anytime version of the algorithm, which can be halted at any\narbitrary time and still return a satisfactory result, while being designed\nsuch that it approximates the behavior of Sequential Halving. Empirical results\nin synthetic MAB problems and ten different board games demonstrate that the\nalgorithm's performance is competitive with Sequential Halving and UCB1 (and\ntheir analogues in MCTS).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Computers and Games 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2411.07171v1",
    "published_date": "2024-11-11 17:49:47 UTC",
    "updated_date": "2024-11-11 17:49:47 UTC"
  },
  {
    "arxiv_id": "2411.07163v1",
    "title": "A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19",
    "authors": [
      "Vedant Khandelwal",
      "Manas Gaur",
      "Ugur Kursuncu",
      "Valerie Shalin",
      "Amit Sheth"
    ],
    "abstract": "Monitoring public sentiment via social media is potentially helpful during\nhealth crises such as the COVID-19 pandemic. However, traditional\nfrequency-based, data-driven neural network-based approaches can miss newly\nrelevant content due to the evolving nature of language in a dynamically\nevolving environment. Human-curated symbolic knowledge sources, such as\nlexicons for standard language and slang terms, can potentially elevate social\nmedia signals in evolving language. We introduce a neurosymbolic method that\nintegrates neural networks with symbolic knowledge sources, enhancing the\ndetection and interpretation of mental health-related tweets relevant to\nCOVID-19. Our method was evaluated using a corpus of large datasets\n(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news\narticles) and multiple knowledge graphs. This method dynamically adapts to\nevolving language, outperforming purely data-driven models with an F1 score\nexceeding 92\\%. This approach also showed faster adaptation to new data and\nlower computational demands than fine-tuning pre-trained large language models\n(LLMs). This study demonstrates the benefit of neurosymbolic methods in\ninterpreting text in a dynamic environment for tasks such as health\nsurveillance.",
    "categories": [
      "cs.AI",
      "I.2.4; I.2.6; I.2.7; I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "13 Pages, 5 Figures, 5 Tables, 2024 IEEE International Conference on\n  Big Data, Regular Paper",
    "pdf_url": "http://arxiv.org/pdf/2411.07163v1",
    "published_date": "2024-11-11 17:41:54 UTC",
    "updated_date": "2024-11-11 17:41:54 UTC"
  },
  {
    "arxiv_id": "2411.07161v1",
    "title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration",
    "authors": [
      "Young-Min Cho",
      "Raphael Shu",
      "Nilaksh Das",
      "Tamer Alkhouli",
      "Yi-An Lai",
      "Jason Cai",
      "Monica Sunkara",
      "Yi Zhang"
    ],
    "abstract": "This study investigates the efficacy of Multi-Agent Systems in eliciting\ncross-agent communication and enhancing collective intelligence through group\ndecision-making in a decentralized setting. Unlike centralized mechanisms,\nwhere a fixed hierarchy governs social choice, decentralized group\ndecision-making allows agents to engage in joint deliberation. Our research\nfocuses on the dynamics of communication and decision-making within various\nsocial choice methods. By applying different voting rules in various\nenvironments, we find that moderate decision flexibility yields better\noutcomes. Additionally, exploring the linguistic features of agent-to-agent\nconversations reveals indicators of effective collaboration, offering insights\ninto communication patterns that facilitate or hinder collaboration. Finally,\nwe propose various methods for determining the optimal stopping point in\nmulti-agent collaborations based on linguistic cues. Our findings contribute to\na deeper understanding of how decentralized decision-making and group\nconversation shape multi-agent collaboration, with implications for the design\nof more effective MAS environments.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.07161v1",
    "published_date": "2024-11-11 17:37:47 UTC",
    "updated_date": "2024-11-11 17:37:47 UTC"
  },
  {
    "arxiv_id": "2411.07152v1",
    "title": "HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals",
    "authors": [
      "Lingbo Mo",
      "Shun Jiang",
      "Akash Maharaj",
      "Bernard Hishamunda",
      "Yunyao Li"
    ],
    "abstract": "Task-Oriented Dialogue (TOD) systems assist users in completing tasks through\nnatural language interactions, often relying on a single-layered workflow\nstructure for slot-filling in public tasks, such as hotel bookings. However, in\nenterprise environments, which involve rich domain-specific knowledge, TOD\nsystems face challenges due to task complexity and the lack of standardized\ndocumentation. In this work, we introduce HierTOD, an enterprise TOD system\ndriven by hierarchical goals and can support composite workflows. By focusing\non goal-driven interactions, our system serves a more proactive role,\nfacilitating mixed-initiative dialogue and improving task completion. Equipped\nwith components for natural language understanding, composite goal retriever,\ndialogue management, and response generation, backed by a well-organized data\nservice with domain knowledge base and retrieval engine, HierTOD delivers\nefficient task assistance. Furthermore, our system implementation unifies two\nTOD paradigms: slot-filling for information collection and step-by-step\nguidance for task execution. Our human study demonstrates the effectiveness and\nhelpfulness of HierTOD in performing both paradigms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07152v1",
    "published_date": "2024-11-11 17:28:19 UTC",
    "updated_date": "2024-11-11 17:28:19 UTC"
  },
  {
    "arxiv_id": "2411.07150v1",
    "title": "Variational Graph Contrastive Learning",
    "authors": [
      "Shifeng Xie",
      "Jhony H. Giraldo"
    ],
    "abstract": "Graph representation learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-supervised learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of graph\ncharacteristics while controlling the distribution of generated subgraphs. We\nemploy optimal transport distances, including Wasserstein and\nGromov-Wasserstein distances, to effectively measure the similarity between\nsubgraphs, enhancing the robustness of the contrastive learning process.\nExtensive experiments across multiple benchmarks demonstrate that SGEC\noutperforms or presents competitive performance against state-of-the-art\napproaches. Our findings provide insights into the design of SSL methods for\nGRL, emphasizing the importance of the distribution of the generated\ncontrastive pairs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07150v1",
    "published_date": "2024-11-11 17:23:07 UTC",
    "updated_date": "2024-11-11 17:23:07 UTC"
  },
  {
    "arxiv_id": "2411.07135v1",
    "title": "Edify 3D: Scalable High-Quality 3D Asset Generation",
    "authors": [
      "NVIDIA",
      ":",
      "Maciej Bala",
      "Yin Cui",
      "Yifan Ding",
      "Yunhao Ge",
      "Zekun Hao",
      "Jon Hasselgren",
      "Jacob Huffman",
      "Jingyi Jin",
      "J. P. Lewis",
      "Zhaoshuo Li",
      "Chen-Hsuan Lin",
      "Yen-Chen Lin",
      "Tsung-Yi Lin",
      "Ming-Yu Liu",
      "Alice Luo",
      "Qianli Ma",
      "Jacob Munkberg",
      "Stella Shi",
      "Fangyin Wei",
      "Donglai Xiang",
      "Jiashu Xu",
      "Xiaohui Zeng",
      "Qinsheng Zhang"
    ],
    "abstract": "We introduce Edify 3D, an advanced solution designed for high-quality 3D\nasset generation. Our method first synthesizes RGB and surface normal images of\nthe described object at multiple viewpoints using a diffusion model. The\nmulti-view observations are then used to reconstruct the shape, texture, and\nPBR materials of the object. Our method can generate high-quality 3D assets\nwith detailed geometry, clean shape topologies, high-resolution textures, and\nmaterials within 2 minutes of runtime.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://research.nvidia.com/labs/dir/edify-3d",
    "pdf_url": "http://arxiv.org/pdf/2411.07135v1",
    "published_date": "2024-11-11 17:07:43 UTC",
    "updated_date": "2024-11-11 17:07:43 UTC"
  },
  {
    "arxiv_id": "2411.07133v3",
    "title": "Stronger Models are NOT Stronger Teachers for Instruction Tuning",
    "authors": [
      "Zhangchen Xu",
      "Fengqing Jiang",
      "Luyao Niu",
      "Bill Yuchen Lin",
      "Radha Poovendran"
    ],
    "abstract": "Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This is paper is accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07133v3",
    "published_date": "2024-11-11 17:06:48 UTC",
    "updated_date": "2025-02-26 18:10:05 UTC"
  },
  {
    "arxiv_id": "2411.07132v1",
    "title": "Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis",
    "authors": [
      "Taihang Hu",
      "Linxuan Li",
      "Joost van de Weijer",
      "Hongcheng Gao",
      "Fahad Shahbaz Khan",
      "Jian Yang",
      "Ming-Ming Cheng",
      "Kai Wang",
      "Yaxing Wang"
    ],
    "abstract": "Although text-to-image (T2I) models exhibit remarkable generation\ncapabilities, they frequently fail to accurately bind semantically related\nobjects or attributes in the input prompts; a challenge termed semantic\nbinding. Previous approaches either involve intensive fine-tuning of the entire\nT2I model or require users or large language models to specify generation\nlayouts, adding complexity. In this paper, we define semantic binding as the\ntask of associating a given object with its attribute, termed attribute\nbinding, or linking it to other related sub-objects, referred to as object\nbinding. We introduce a novel method called Token Merging (ToMe), which\nenhances semantic binding by aggregating relevant tokens into a single\ncomposite token. This ensures that the object, its attributes and sub-objects\nall share the same cross-attention map. Additionally, to address potential\nconfusion among main objects with complex textual prompts, we propose end token\nsubstitution as a complementary strategy. To further refine our approach in the\ninitial stages of T2I generation, where layouts are determined, we incorporate\ntwo auxiliary losses, an entropy loss and a semantic binding loss, to\niteratively update the composite token to improve the generation integrity. We\nconducted extensive experiments to validate the effectiveness of ToMe,\ncomparing it against various existing methods on the T2I-CompBench and our\nproposed GPT-4o object binding benchmark. Our method is particularly effective\nin complex scenarios that involve multiple objects and attributes, which\nprevious methods often fail to address. The code will be publicly available at\n\\url{https://github.com/hutaihang/ToMe}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by Neurips2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07132v1",
    "published_date": "2024-11-11 17:05:15 UTC",
    "updated_date": "2024-11-11 17:05:15 UTC"
  },
  {
    "arxiv_id": "2411.07123v1",
    "title": "Fast and Robust Contextual Node Representation Learning over Dynamic Graphs",
    "authors": [
      "Xingzhi Guo",
      "Silong Wang",
      "Baojian Zhou",
      "Yanghua Xiao",
      "Steven Skiena"
    ],
    "abstract": "Real-world graphs grow rapidly with edge and vertex insertions over time,\nmotivating the problem of efficiently maintaining robust node representation\nover evolving graphs. Recent efficient GNNs are designed to decouple recursive\nmessage passing from the learning process, and favor Personalized PageRank\n(PPR) as the underlying feature propagation mechanism. However, most PPR-based\nGNNs are designed for static graphs, and efficient PPR maintenance remains as\nan open problem. Further, there is surprisingly little theoretical\njustification for the choice of PPR, despite its impressive empirical\nperformance.\n  In this paper, we are inspired by the recent PPR formulation as an explicit\n$\\ell_1$-regularized optimization problem and propose a unified dynamic graph\nlearning framework based on sparse node-wise attention. We also present a set\nof desired properties to justify the choice of PPR in STOA GNNs, and serves as\nthe guideline for future node attention designs. Meanwhile, we take advantage\nof the PPR-equivalent optimization formulation and employ the proximal gradient\nmethod (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.\nFinally, we instantiate a simple-yet-effective model (\\textsc{GoPPE}) with\nrobust positional encodings by maximizing PPR previously used as attention. The\nmodel performs comparably to or better than the STOA baselines and greatly\noutperforms when the initial node attributes are noisy during graph evolution,\ndemonstrating the effectiveness and robustness of \\textsc{GoPPE}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07123v1",
    "published_date": "2024-11-11 16:51:51 UTC",
    "updated_date": "2024-11-11 16:51:51 UTC"
  },
  {
    "arxiv_id": "2411.07104v4",
    "title": "Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing",
    "authors": [
      "Yuming Feng",
      "Chuye Hong",
      "Yaru Niu",
      "Shiqi Liu",
      "Yuxiang Yang",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Jie Tan",
      "Ding Zhao"
    ],
    "abstract": "Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07104v4",
    "published_date": "2024-11-11 16:27:25 UTC",
    "updated_date": "2025-03-29 04:50:27 UTC"
  },
  {
    "arxiv_id": "2411.07099v2",
    "title": "Bounded Rationality Equilibrium Learning in Mean Field Games",
    "authors": [
      "Yannick Eich",
      "Christian Fabian",
      "Kai Cui",
      "Heinz Koeppl"
    ],
    "abstract": "Mean field games (MFGs) tractably model behavior in large agent populations.\nThe literature on learning MFG equilibria typically focuses on finding Nash\nequilibria (NE), which assume perfectly rational agents and are hence\nimplausible in many realistic situations. To overcome these limitations, we\nincorporate bounded rationality into MFGs by leveraging the well-known concept\nof quantal response equilibria (QRE). Two novel types of MFG QRE enable the\nmodeling of large agent populations where individuals only noisily estimate the\ntrue objective. We also introduce a second source of bounded rationality to\nMFGs by restricting agents' planning horizon. The resulting novel receding\nhorizon (RH) MFGs are combined with QRE and existing approaches to model\ndifferent aspects of bounded rationality in MFGs. We formally define MFG QRE\nand RH MFGs and compare them to existing equilibrium concepts such as\nentropy-regularized NE. Subsequently, we design generalized fixed point\niteration and fictitious play algorithms to learn QRE and RH equilibria. After\na theoretical analysis, we give different examples to evaluate the capabilities\nof our learning algorithms and outline practical differences between the\nequilibrium concepts.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07099v2",
    "published_date": "2024-11-11 16:24:03 UTC",
    "updated_date": "2025-01-30 08:37:52 UTC"
  },
  {
    "arxiv_id": "2411.07098v2",
    "title": "A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs",
    "authors": [
      "Myeongsoo Kim",
      "Tyler Stennett",
      "Saurabh Sinha",
      "Alessandro Orso"
    ],
    "abstract": "As modern web services increasingly rely on REST APIs, their thorough testing\nhas become crucial. Furthermore, the advent of REST API documentation\nlanguages, such as the OpenAPI Specification, has led to the emergence of many\nblack-box REST API testing tools. However, these tools often focus on\nindividual test elements in isolation (e.g., APIs, parameters, values),\nresulting in lower coverage and less effectiveness in fault detection. To\naddress these limitations, we present AutoRestTest, the first black-box tool to\nadopt a dependency-embedded multi-agent approach for REST API testing that\nintegrates multi-agent reinforcement learning (MARL) with a semantic property\ndependency graph (SPDG) and Large Language Models (LLMs). Our approach treats\nREST API testing as a separable problem, where four agents -- API, dependency,\nparameter, and value agents -- collaborate to optimize API exploration. LLMs\nhandle domain-specific value generation, the SPDG model simplifies the search\nspace for dependencies using a similarity score between API operations, and\nMARL dynamically optimizes the agents' behavior. Our evaluation of AutoRestTest\non 12 real-world REST services shows that it outperforms the four leading\nblack-box REST API testing tools, including those assisted by RESTGPT (which\ngenerates realistic test inputs using LLMs), in terms of code coverage,\noperation coverage, and fault detection. Notably, AutoRestTest is the only tool\nable to trigger an internal server error in the Spotify service. Our ablation\nstudy illustrates that each component of AutoRestTest -- the SPDG, the LLM, and\nthe agent-learning mechanism -- contributes to its overall effectiveness.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To be published in the 47th IEEE/ACM International Conference on\n  Software Engineering (ICSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.07098v2",
    "published_date": "2024-11-11 16:20:27 UTC",
    "updated_date": "2025-01-22 04:42:10 UTC"
  },
  {
    "arxiv_id": "2411.07089v1",
    "title": "Towards Characterizing Cyber Networks with Large Language Models",
    "authors": [
      "Alaric Hartsock",
      "Luiz Manella Pereira",
      "Glenn Fink"
    ],
    "abstract": "Threat hunting analyzes large, noisy, high-dimensional data to find sparse\nadversarial behavior. We believe adversarial activities, however they are\ndisguised, are extremely difficult to completely obscure in high dimensional\nspace. In this paper, we employ these latent features of cyber data to find\nanomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM\nwas trained on Zeek network traffic logs from both a real-world production\nnetwork and an from Internet of Things (IoT) cybersecurity testbed. The model\nis deliberately overtrained on a sliding window of data to characterize each\nwindow closely. We use the Adjusted Rand Index (ARI) to comparing the k-means\nclustering of CLEM output to expert labeling of the embeddings. Our approach\ndemonstrates that there is promise in using natural language modeling to\nunderstand cyber data.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07089v1",
    "published_date": "2024-11-11 16:09:13 UTC",
    "updated_date": "2024-11-11 16:09:13 UTC"
  },
  {
    "arxiv_id": "2411.07087v4",
    "title": "OCMDP: Observation-Constrained Markov Decision Process",
    "authors": [
      "Taiyi Wang",
      "Jianheng Liu",
      "Bryan Lee",
      "Zhihao Wu",
      "Yu Wu"
    ],
    "abstract": "In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Full paper, 14 Pages",
    "pdf_url": "http://arxiv.org/pdf/2411.07087v4",
    "published_date": "2024-11-11 16:04:49 UTC",
    "updated_date": "2025-01-23 18:08:31 UTC"
  },
  {
    "arxiv_id": "2411.07086v1",
    "title": "To Train or Not to Train: Balancing Efficiency and Training Cost in Deep Reinforcement Learning for Mobile Edge Computing",
    "authors": [
      "Maddalena Boscaro",
      "Federico Mason",
      "Federico Chiariotti",
      "Andrea Zanella"
    ],
    "abstract": "Artificial Intelligence (AI) is a key component of 6G networks, as it enables\ncommunication and computing services to adapt to end users' requirements and\ndemand patterns. The management of Mobile Edge Computing (MEC) is a meaningful\nexample of AI application: computational resources available at the network\nedge need to be carefully allocated to users, whose jobs may have different\npriorities and latency requirements. The research community has developed\nseveral AI algorithms to perform this resource allocation, but it has neglected\na key aspect: learning is itself a computationally demanding task, and\nconsidering free training results in idealized conditions and performance in\nsimulations. In this work, we consider a more realistic case in which the cost\nof learning is specifically accounted for, presenting a new algorithm to\ndynamically select when to train a Deep Reinforcement Learning (DRL) agent that\nallocates resources. Our method is highly general, as it can be directly\napplied to any scenario involving a training overhead, and it can approach the\nsame performance as an ideal learning agent even under realistic training\nconditions.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07086v1",
    "published_date": "2024-11-11 16:02:12 UTC",
    "updated_date": "2024-11-11 16:02:12 UTC"
  },
  {
    "arxiv_id": "2411.07076v2",
    "title": "StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification",
    "authors": [
      "Yichen He",
      "Yuan Lin",
      "Jianchao Wu",
      "Hanchong Zhang",
      "Yuchen Zhang",
      "Ruicheng Le"
    ],
    "abstract": "Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as consistent character\nidentification and plot-level descriptions incorporating both visual and audio\ninformation. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nStoryQA, a large set of multiple-choice questions for MovieStory101 test set.\nWe assess descriptions by inputting them into GPT-4 to answer these questions,\nusing accuracy as an automatic evaluation metric. Experiments show that\nStoryTeller outperforms all open and closed-source baselines on StoryQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on StoryQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07076v2",
    "published_date": "2024-11-11 15:51:48 UTC",
    "updated_date": "2025-03-06 09:13:28 UTC"
  },
  {
    "arxiv_id": "2411.07072v2",
    "title": "An Interpretable X-ray Style Transfer via Trainable Local Laplacian Filter",
    "authors": [
      "Dominik Eckert",
      "Ludwig Ritschl",
      "Christopher Syben",
      "Christian H√ºmmer",
      "Julia Wicklein",
      "Marcel Beister",
      "Steffen Kappler",
      "Sebastian Stober"
    ],
    "abstract": "Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07072v2",
    "published_date": "2024-11-11 15:47:25 UTC",
    "updated_date": "2025-01-24 15:26:34 UTC"
  },
  {
    "arxiv_id": "2411.07071v1",
    "title": "Universal Response and Emergence of Induction in LLMs",
    "authors": [
      "Niclas Luick"
    ],
    "abstract": "While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07071v1",
    "published_date": "2024-11-11 15:47:15 UTC",
    "updated_date": "2024-11-11 15:47:15 UTC"
  },
  {
    "arxiv_id": "2411.07070v2",
    "title": "On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models",
    "authors": [
      "Qian Sun",
      "Hanpeng Wu",
      "Xi Sheryl Zhang"
    ],
    "abstract": "The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://anonymous.4open.science/r/PARSING-4817/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07070v2",
    "published_date": "2024-11-11 15:46:07 UTC",
    "updated_date": "2024-11-12 04:12:32 UTC"
  },
  {
    "arxiv_id": "2411.07066v3",
    "title": "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training",
    "authors": [
      "Elia Cunegatti",
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "abstract": "Network pruning focuses on computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has been pruning and re-training, which nowadays\nis inconvenient due to the vast amount of pre-trained models, which are in any\ncase too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAL}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs,\nwhich modifies the block-wise and row-wise sparsity exploiting information from\nboth the dense model and its sparse version to maximize the \\emph{neuron\nalignment} among activations. Differently from existing methods, our approach\nadaptively selects the best hyperparameters for the block-wise and row-wise\nsparsity ratios w.r.t. the model and the desired sparsity, and requires\n\\emph{no re-training}. We test our method over 276 cases combining four LLM\nfamilies, three sparsity ratios, and ten language tasks (three language\nmodeling and seven zero-shot datasets), showing how it consistently outperforms\nthe latest state-of-the-art methods in terms of performance-runtime trade-off.\nThe code is available at\n\\href{https://github.com/eliacunegatti/NeuroAL}{https://github.com/eliacunegatti/NeuroAL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.07066v3",
    "published_date": "2024-11-11 15:30:16 UTC",
    "updated_date": "2025-01-30 15:24:28 UTC"
  },
  {
    "arxiv_id": "2411.07042v1",
    "title": "Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications",
    "authors": [
      "Xianzhe Fan",
      "Qing Xiao",
      "Xuhui Zhou",
      "Yuran Su",
      "Zhicong Lu",
      "Maarten Sap",
      "Hong Shen"
    ],
    "abstract": "AI companions based on large language models can role-play and converse very\nnaturally. When value conflicts arise between the AI companion and the user, it\nmay offend or upset the user. Yet, little research has examined such conflicts.\nWe first conducted a formative study that analyzed 151 user complaints about\nconflicts with AI companions, providing design implications for our study.\nBased on these, we created Minion, a technology probe to help users resolve\nhuman-AI value conflicts. Minion applies a user-empowerment intervention method\nthat provides suggestions by combining expert-driven and user-driven conflict\nresolution strategies. We conducted a technology probe study, creating 40 value\nconflict scenarios on Character.AI and Talkie. 22 participants completed 274\ntasks and successfully resolved conflicts 94.16% of the time. We summarize user\nresponses, preferences, and needs in resolving value conflicts, and propose\ndesign implications to reduce conflicts and empower users to resolve them more\neffectively.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07042v1",
    "published_date": "2024-11-11 14:49:43 UTC",
    "updated_date": "2024-11-11 14:49:43 UTC"
  },
  {
    "arxiv_id": "2411.07038v1",
    "title": "Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind",
    "authors": [
      "Alejandro Leonardo Garc√≠a Navarro",
      "Nataliia Koneva",
      "Alfonso S√°nchez-Maci√°n",
      "Jos√© Alberto Hern√°ndez",
      "Manuel Goyanes"
    ],
    "abstract": "In social sciences, researchers often face challenges when conducting\nlarge-scale experiments, particularly due to the simulations' complexity and\nthe lack of technical expertise required to develop such frameworks.\nAgent-Based Modeling (ABM) is a computational approach that simulates agents'\nactions and interactions to evaluate how their behaviors influence the\noutcomes. However, the traditional implementation of ABM can be demanding and\ncomplex. Generative Agent-Based Modeling (GABM) offers a solution by enabling\nscholars to create simulations where AI-driven agents can generate complex\nbehaviors based on underlying rules and interactions. This paper introduces a\nframework for designing reliable experiments using GABM, making sophisticated\nsimulation techniques more accessible to researchers across various fields. We\nprovide a step-by-step guide for selecting appropriate tools, designing the\nmodel, establishing experimentation protocols, and validating results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07038v1",
    "published_date": "2024-11-11 14:45:08 UTC",
    "updated_date": "2024-11-11 14:45:08 UTC"
  },
  {
    "arxiv_id": "2411.07031v1",
    "title": "Evaluating the Accuracy of Chatbots in Financial Literature",
    "authors": [
      "Orhan Erdem",
      "Kristi Hassett",
      "Feyzullah Egriboyun"
    ],
    "abstract": "We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "categories": [
      "cs.AI",
      "econ.EM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07031v1",
    "published_date": "2024-11-11 14:37:57 UTC",
    "updated_date": "2024-11-11 14:37:57 UTC"
  },
  {
    "arxiv_id": "2411.07019v3",
    "title": "UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction",
    "authors": [
      "Zhiqiang Liu",
      "Yin Hua",
      "Mingyang Chen",
      "Zhuo Chen",
      "Ziqi Liu",
      "Lei Liang",
      "Huajun Chen",
      "Wen Zhang"
    ],
    "abstract": "Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, constrained by complex fact representation forms, existing\nlink prediction models for beyond-triple facts have difficulty achieving\nhierarchical fact modeling and generalizing the modules for one specific facts\nto other fact types. To overcome this limitation, we propose a Unified\nHierarchical Representation learning framework (UniHR) for unified knowledge\ngraph link prediction. It consists of a unified Hierarchical Data\nRepresentation (HiDR) module and a unified Hierarchical Structure Learning\n(HiSL) module as graph encoder. The HiDR module unifies hyper-relational KGs,\ntemporal KGs, and nested factual KGs into triple-based representations. Then\nHiSL incorporates intra-fact and inter-fact message passing, focusing on\nenhancing the semantic information within individual facts and enriching the\nstructural information between facts. Empirical results demonstrate the\neffectiveness of UniHR and highlight the strong potential of unified\nrepresentations. Code and data are available at\nhttps://github.com/Lza12a/UniHR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07019v3",
    "published_date": "2024-11-11 14:22:42 UTC",
    "updated_date": "2025-05-16 02:46:54 UTC"
  },
  {
    "arxiv_id": "2411.07015v1",
    "title": "Leveraging LSTM for Predictive Modeling of Satellite Clock Bias",
    "authors": [
      "Ahan Bhatt",
      "Ishaan Mehta",
      "Pravin Patidar"
    ],
    "abstract": "Satellite clock bias prediction plays a crucial role in enhancing the\naccuracy of satellite navigation systems. In this paper, we propose an approach\nutilizing Long Short-Term Memory (LSTM) networks to predict satellite clock\nbias. We gather data from the PRN 8 satellite of the Galileo and preprocess it\nto obtain a single difference sequence, crucial for normalizing the data.\nNormalization allows resampling of the data, ensuring that the predictions are\nequidistant and complete. Our methodology involves training the LSTM model on\nvarying lengths of datasets, ranging from 7 days to 31 days. We employ a\ntraining set consisting of two days' worth of data in each case. Our LSTM model\nexhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11\n$\\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used\nfor similar time-series forecasting projects, being 170 times more accurate\nthan RNN, 2.3 $\\times$ 10$^7$ times more accurate than MLP, and 1.9 $\\times$\n10$^4$ times more accurate than ARIMA. This study holds significant potential\nin enhancing the accuracy and efficiency of low-power receivers used in various\ndevices, particularly those requiring power conservation. By providing more\naccurate predictions of satellite clock bias, the findings of this research can\nbe integrated into the algorithms of such devices, enabling them to function\nwith heightened precision while conserving power. Improved accuracy in clock\nbias predictions ensures that low-power receivers can maintain optimal\nperformance levels, thereby enhancing the overall reliability and effectiveness\nof satellite navigation systems. Consequently, this advancement holds promise\nfor a wide range of applications, including remote areas, IoT devices, wearable\ntechnology, and other devices where power efficiency and navigation accuracy\nare paramount.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "6 Pages, 6 figures (8 sub-figures), 5 Tables Index Terms-LSTM,\n  Satellite Navigation, Deep Learning, Clock Bias",
    "pdf_url": "http://arxiv.org/pdf/2411.07015v1",
    "published_date": "2024-11-11 14:18:32 UTC",
    "updated_date": "2024-11-11 14:18:32 UTC"
  },
  {
    "arxiv_id": "2411.07013v1",
    "title": "A neural-network based anomaly detection system and a safety protocol to protect vehicular network",
    "authors": [
      "Marco Franceschini"
    ],
    "abstract": "This thesis addresses the use of Cooperative Intelligent Transport Systems\n(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle\ncommunication, highlighting the importance of secure and accurate data\nexchange. To ensure safety, the thesis proposes a Machine Learning-based\nMisbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks\nto detect and mitigate incorrect or misleading messages within vehicular\nnetworks. Trained offline on the VeReMi dataset, the detection model is tested\nin real-time within a platooning scenario, demonstrating that it can prevent\nnearly all accidents caused by misbehavior by triggering a defense protocol\nthat dissolves the platoon if anomalies are detected. The results show that\nwhile the system can accurately detect general misbehavior, it struggles to\nlabel specific types due to varying traffic conditions, implying the difficulty\nof creating a universally adaptive protocol. However, the thesis suggests that\nwith more data and further refinement, this MDS could be implemented in\nreal-world CITS, enhancing driving safety by mitigating risks from misbehavior\nin cooperative driving networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Master's thesis 2023-2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07013v1",
    "published_date": "2024-11-11 14:15:59 UTC",
    "updated_date": "2024-11-11 14:15:59 UTC"
  },
  {
    "arxiv_id": "2411.07008v1",
    "title": "Permutative redundancy and uncertainty of the objective in deep learning",
    "authors": [
      "Vacslav Glukhov"
    ],
    "abstract": "Implications of uncertain objective functions and permutative symmetry of\ntraditional deep learning architectures are discussed. It is shown that\ntraditional architectures are polluted by an astronomical number of equivalent\nglobal and local optima. Uncertainty of the objective makes local optima\nunattainable, and, as the size of the network grows, the global optimization\nlandscape likely becomes a tangled web of valleys and ridges. Some remedies\nwhich reduce or eliminate ghost optima are discussed including forced\npre-pruning, re-ordering, ortho-polynomial activations, and modular\nbio-inspired architectures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07008v1",
    "published_date": "2024-11-11 14:06:56 UTC",
    "updated_date": "2024-11-11 14:06:56 UTC"
  },
  {
    "arxiv_id": "2411.07007v2",
    "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching",
    "authors": [
      "Arnav Kumar Jain",
      "Harley Wiltzer",
      "Jesse Farebrother",
      "Irina Rish",
      "Glen Berseth",
      "Sanjiban Choudhury"
    ],
    "abstract": "In inverse reinforcement learning (IRL), an agent seeks to replicate expert\ndemonstrations through interactions with the environment. Traditionally, IRL is\ntreated as an adversarial game, where an adversary searches over reward models,\nand a learner optimizes the reward through repeated RL procedures. This\ngame-solving approach is both computationally expensive and difficult to\nstabilize. In this work, we propose a novel approach to IRL by direct policy\noptimization: exploiting a linear factorization of the return as the inner\nproduct of successor features and a reward vector, we design an IRL algorithm\nby policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can\nbe solved seamlessly with existing actor-critic RL algorithms. Remarkably, our\napproach works in state-only settings without expert action labels, a setting\nwhich behavior cloning (BC) cannot solve. Empirical results demonstrate that\nour method learns from as few as a single expert demonstration and achieves\nimproved performance on various control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07007v2",
    "published_date": "2024-11-11 14:05:50 UTC",
    "updated_date": "2025-04-22 17:59:03 UTC"
  },
  {
    "arxiv_id": "2411.07006v1",
    "title": "Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs",
    "authors": [
      "Malte Luttermann",
      "Tanya Braun",
      "Ralf M√∂ller",
      "Marcel Gehrke"
    ],
    "abstract": "Lifting uses a representative of indistinguishable individuals to exploit\nsymmetries in probabilistic relational models, denoted as parametric factor\ngraphs, to speed up inference while maintaining exact answers. In this paper,\nwe show how lifting can be applied to causal inference in partially directed\ngraphs, i.e., graphs that contain both directed and undirected edges to\nrepresent causal relationships between random variables. We present partially\ndirected parametric causal factor graphs (PPCFGs) as a generalisation of\npreviously introduced parametric causal factor graphs, which require a fully\ndirected graph. We further show how causal inference can be performed on a\nlifted level in PPCFGs, thereby extending the applicability of lifted causal\ninference to a broader range of models requiring less prior knowledge about\ncausal relationships.",
    "categories": [
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Proceedings of the 16th International Conference on\n  Scalable Uncertainty Management (SUM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.07006v1",
    "published_date": "2024-11-11 14:05:39 UTC",
    "updated_date": "2024-11-11 14:05:39 UTC"
  },
  {
    "arxiv_id": "2411.07003v1",
    "title": "Enhancing Robot Assistive Behaviour with Reinforcement Learning and Theory of Mind",
    "authors": [
      "Antonio Andriella",
      "Giovanni Falcone",
      "Silvia Rossi"
    ],
    "abstract": "The adaptation to users' preferences and the ability to infer and interpret\nhumans' beliefs and intents, which is known as the Theory of Mind (ToM), are\ntwo crucial aspects for achieving effective human-robot collaboration. Despite\nits importance, very few studies have investigated the impact of adaptive\nrobots with ToM abilities. In this work, we present an exploratory comparative\nstudy to investigate how social robots equipped with ToM abilities impact\nusers' performance and perception. We design a two-layer architecture. The\nQ-learning agent on the first layer learns the robot's higher-level behaviour.\nOn the second layer, a heuristic-based ToM infers the user's intended strategy\nand is responsible for implementing the robot's assistance, as well as\nproviding the motivation behind its choice. We conducted a user study in a\nreal-world setting, involving 56 participants who interacted with either an\nadaptive robot capable of ToM, or with a robot lacking such abilities. Our\nfindings suggest that participants in the ToM condition performed better,\naccepted the robot's assistance more often, and perceived its ability to adapt,\npredict and recognise their intents to a higher degree. Our preliminary\ninsights could inform future research and pave the way for designing more\ncomplex computation architectures for adaptive behaviour with ToM capabilities.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07003v1",
    "published_date": "2024-11-11 14:01:15 UTC",
    "updated_date": "2024-11-11 14:01:15 UTC"
  },
  {
    "arxiv_id": "2411.06995v1",
    "title": "Which PPML Would a User Choose? A Structured Decision Support Framework for Developers to Rank PPML Techniques Based on User Acceptance Criteria",
    "authors": [
      "Sascha L√∂bner",
      "Sebastian Pape",
      "Vanessa Bracamonte",
      "Kittiphop Phalakarn"
    ],
    "abstract": "Using Privacy-Enhancing Technologies (PETs) for machine learning often\ninfluences the characteristics of a machine learning approach, e.g., the needed\ncomputational power, timing of the answers or how the data can be utilized.\nWhen designing a new service, the developer faces the problem that some\ndecisions require a trade-off. For example, the use of a PET may cause a delay\nin the responses or adding noise to the data to improve the users' privacy\nmight have a negative impact on the accuracy of the machine learning approach.\nAs of now, there is no structured way how the users' perception of a machine\nlearning based service can contribute to the selection of Privacy Preserving\nMachine Learning (PPML) methods. This is especially a challenge since one\ncannot assume that users have a deep technical understanding of these\ntechnologies. Therefore, they can only be asked about certain attributes that\nthey can perceive when using the service and not directly which PPML they\nprefer.\n  This study introduces a decision support framework with the aim of supporting\nthe selection of PPML technologies based on user preferences. Based on prior\nwork analysing User Acceptance Criteria (UAC), we translate these criteria into\ndifferentiating characteristics for various PPML techniques. As a final result,\nwe achieve a technology ranking based on the User Acceptance Criteria while\nproviding technology insights for the developers. We demonstrate its\napplication using the use case of classifying privacy-relevant information.\n  Our contribution consists of the decision support framework which consists of\na process to connect PPML technologies with UAC, a process for evaluating the\ncharacteristics that separate PPML techniques, and a ranking method to evaluate\nthe best PPML technique for the use case.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06995v1",
    "published_date": "2024-11-11 13:53:33 UTC",
    "updated_date": "2024-11-11 13:53:33 UTC"
  },
  {
    "arxiv_id": "2411.06989v2",
    "title": "The Backpropagation of the Wave Network",
    "authors": [
      "Xin Zhang",
      "Victor S. Sheng"
    ],
    "abstract": "This paper provides an in-depth analysis of Wave Network, a novel token\nrepresentation method derived from the Wave Network, designed to capture both\nglobal and local semantics of input text through wave-inspired complex vectors.\nIn complex vector token representation, each token is represented with a\nmagnitude component, capturing the global semantics of the entire input text,\nand a phase component, encoding the relationships between individual tokens and\nthe global semantics. Building on prior research that demonstrated the\neffectiveness of wave-like operations, such as interference and modulation,\nduring forward propagation, this study investigates the convergence behavior,\nbackpropagation characteristics, and embedding independence within the\nToken2Wave framework. A detailed computational complexity analysis shows that\nToken2Wave can significantly reduce video memory usage and training time\ncompared to BERT. Gradient comparisons for the [CLS] token, total input text,\nand classifier parameters further highlight Token2Wave's unique\ncharacteristics. This research offers new insights into wave-based token\nrepresentations, demonstrating their potential to enable efficient and\ncomputationally friendly language model architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06989v2",
    "published_date": "2024-11-11 13:48:01 UTC",
    "updated_date": "2025-01-11 03:06:07 UTC"
  },
  {
    "arxiv_id": "2411.06965v2",
    "title": "Imitation from Diverse Behaviors: Wasserstein Quality Diversity Imitation Learning with Single-Step Archive Exploration",
    "authors": [
      "Xingrui Yu",
      "Zhenglin Wan",
      "David Mark Bossens",
      "Yueming Lyu",
      "Qing Guo",
      "Ivor W. Tsang"
    ],
    "abstract": "Learning diverse and high-performance behaviors from a limited set of\ndemonstrations is a grand challenge. Traditional imitation learning methods\nusually fail in this task because most of them are designed to learn one\nspecific behavior even with multiple demonstrations. Therefore, novel\ntechniques for \\textit{quality diversity imitation learning}, which bridges the\nquality diversity optimization and imitation learning methods, are needed to\nsolve the above challenge. This work introduces Wasserstein Quality Diversity\nImitation Learning (WQDIL), which 1) improves the stability of imitation\nlearning in the quality diversity setting with latent adversarial training\nbased on a Wasserstein Auto-Encoder (WAE), and 2) mitigates a\nbehavior-overfitting issue using a measure-conditioned reward function with a\nsingle-step archive exploration bonus. Empirically, our method significantly\noutperforms state-of-the-art IL methods, achieving near-expert or beyond-expert\nQD performance on the challenging continuous control tasks derived from MuJoCo\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06965v2",
    "published_date": "2024-11-11 13:11:18 UTC",
    "updated_date": "2025-04-04 05:10:15 UTC"
  },
  {
    "arxiv_id": "2411.06959v1",
    "title": "ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis",
    "authors": [
      "Zanlin Ni",
      "Yulin Wang",
      "Renping Zhou",
      "Yizeng Han",
      "Jiayi Guo",
      "Zhiyuan Liu",
      "Yuan Yao",
      "Gao Huang"
    ],
    "abstract": "Recently, token-based generation have demonstrated their effectiveness in\nimage synthesis. As a representative example, non-autoregressive Transformers\n(NATs) can generate decent-quality images in a few steps. NATs perform\ngeneration in a progressive manner, where the latent tokens of a resulting\nimage are incrementally revealed. At each step, the unrevealed image regions\nare padded with mask tokens and inferred by NAT. In this paper, we delve into\nthe mechanisms behind the effectiveness of NATs and uncover two important\npatterns that naturally emerge from NATs: Spatially (within a step), although\nmask and visible tokens are processed uniformly by NATs, the interactions\nbetween them are highly asymmetric. In specific, mask tokens mainly gather\ninformation for decoding, while visible tokens tend to primarily provide\ninformation, and their deep representations can be built only upon themselves.\nTemporally (across steps), the interactions between adjacent generation steps\nmostly concentrate on updating the representations of a few critical tokens,\nwhile the computation for the majority of tokens is generally repetitive.\nDriven by these findings, we propose EfficientNAT (ENAT), a NAT model that\nexplicitly encourages these critical interactions inherent in NATs. At the\nspatial level, we disentangle the computations of visible and mask tokens by\nencoding visible tokens independently, while decoding mask tokens conditioned\non the fully encoded visible tokens. At the temporal level, we prioritize the\ncomputation of the critical tokens at each step, while maximally reusing\npreviously computed token representations to supplement necessary information.\nENAT improves the performance of NATs notably with significantly reduced\ncomputational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO\nvalidate the effectiveness of ENAT. Code is available at\nhttps://github.com/LeapLabTHU/ENAT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06959v1",
    "published_date": "2024-11-11 13:05:39 UTC",
    "updated_date": "2024-11-11 13:05:39 UTC"
  },
  {
    "arxiv_id": "2411.06928v2",
    "title": "Multi-class Decoding of Attended Speaker Direction Using Electroencephalogram and Audio Spatial Spectrum",
    "authors": [
      "Yuanming Zhang",
      "Jing Lu",
      "Fei Chen",
      "Haoliang Du",
      "Xia Gao",
      "Zhibin Lin"
    ],
    "abstract": "Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, it is found that on\nthe recently presented dataset with 14-class directional focus, models relying\nexclusively on EEG inputs exhibit significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. The CNN, LSM-CNN, and Deformer models are\nemployed to decode the directional focus from listeners' EEG signals and audio\nspatial spectra. The proposed Sp-EEG-Deformer model achieves notable 14-class\ndecoding accuracies of 55.35% and 57.19% in leave-one-subject-out and\nleave-one-trial-out scenarios with a decision window of 1 second, respectively.\nExperiment results indicate increased decoding accuracy as the number of\nalternative directions reduces. These findings suggest the efficacy of our\nproposed dual modal directional focus decoding strategy.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to IEEE TNSRE",
    "pdf_url": "http://arxiv.org/pdf/2411.06928v2",
    "published_date": "2024-11-11 12:32:26 UTC",
    "updated_date": "2025-01-09 13:56:49 UTC"
  },
  {
    "arxiv_id": "2411.06927v1",
    "title": "Multi-modal Iterative and Deep Fusion Frameworks for Enhanced Passive DOA Sensing via a Green Massive H2AD MIMO Receiver",
    "authors": [
      "Jiatong Bai",
      "Minghao Chen",
      "Wankai Tang",
      "Yifan Li",
      "Cunhua Pan",
      "Yongpeng Wu",
      "Feng Shu"
    ],
    "abstract": "Most existing DOA estimation methods assume ideal source incident angles with\nminimal noise. Moreover, directly using pre-estimated angles to calculate\nweighted coefficients can lead to performance loss. Thus, a green multi-modal\n(MM) fusion DOA framework is proposed to realize a more practical, low-cost and\nhigh time-efficiency DOA estimation for a H$^2$AD array. Firstly, two more\nefficient clustering methods, global maximum cos\\_similarity clustering\n(GMaxCS) and global minimum distance clustering (GMinD), are presented to infer\nmore precise true solutions from the candidate solution sets. Based on this, an\niteration weighted fusion (IWF)-based method is introduced to iteratively\nupdate weighted fusion coefficients and the clustering center of the true\nsolution classes by using the estimated values. Particularly, the coarse DOA\ncalculated by fully digital (FD) subarray, serves as the initial cluster\ncenter. The above process yields two methods called MM-IWF-GMaxCS and\nMM-IWF-GMinD. To further provide a higher-accuracy DOA estimation, a fusion\nnetwork (fusionNet) is proposed to aggregate the inferred two-part true angles\nand thus generates two effective approaches called MM-fusionNet-GMaxCS and\nMM-fusionNet-GMinD. The simulation outcomes show the proposed four approaches\ncan achieve the ideal DOA performance and the CRLB. Meanwhile, proposed\nMM-fusionNet-GMaxCS and MM-fusionNet-GMinD exhibit superior DOA performance\ncompared to MM-IWF-GMaxCS and MM-IWF-GMinD, especially in extremely-low SNR\nrange.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06927v1",
    "published_date": "2024-11-11 12:32:18 UTC",
    "updated_date": "2024-11-11 12:32:18 UTC"
  },
  {
    "arxiv_id": "2411.06916v2",
    "title": "Slowing Down Forgetting in Continual Learning",
    "authors": [
      "Pascal Janetzky",
      "Tobias Schlagenhauf",
      "Stefan Feuerriegel"
    ],
    "abstract": "A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06916v2",
    "published_date": "2024-11-11 12:19:28 UTC",
    "updated_date": "2025-03-03 10:22:24 UTC"
  },
  {
    "arxiv_id": "2411.06911v2",
    "title": "Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI",
    "authors": [
      "Bruno Viti",
      "Franz Thaler",
      "Kathrin Lisa Kapper",
      "Martin Urschler",
      "Martin Holler",
      "Elias Karabelas"
    ],
    "abstract": "Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06911v2",
    "published_date": "2024-11-11 12:13:58 UTC",
    "updated_date": "2024-11-12 12:07:00 UTC"
  },
  {
    "arxiv_id": "2411.06899v2",
    "title": "LongSafety: Enhance Safety for Long-Context LLMs",
    "authors": [
      "Mianqiu Huang",
      "Xiaoran Liu",
      "Shaojun Zhou",
      "Mozhi Zhang",
      "Qipeng Guo",
      "Linyang Li",
      "Chenkun Tan",
      "Yang Gao",
      "Pengyu Wang",
      "Linlin Li",
      "Qun Liu",
      "Yaqian Zhou",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "abstract": "Recent advancements in model architectures and length extrapolation\ntechniques have significantly extended the context length of large language\nmodels (LLMs), paving the way for their application in increasingly complex\ntasks. However, despite the growing capabilities of long-context LLMs, the\nsafety issues in long-context scenarios remain underexplored. While safety\nalignment in short context has been widely studied, the safety concerns of\nlong-context LLMs have not been adequately addressed. In this work, we\nintroduce \\textbf{LongSafety}, a comprehensive safety alignment dataset for\nlong-context LLMs, containing 10 tasks and 17k samples, with an average length\nof 40.9k tokens. Our experiments demonstrate that training with LongSafety can\nenhance long-context safety performance while enhancing short-context safety\nand preserving general capabilities. Furthermore, we demonstrate that\nlong-context safety does not equal long-context alignment with short-context\nsafety data and LongSafety has generalizing capabilities in context length and\nlong-context safety scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06899v2",
    "published_date": "2024-11-11 11:57:37 UTC",
    "updated_date": "2025-02-27 13:08:46 UTC"
  },
  {
    "arxiv_id": "2411.06878v1",
    "title": "GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs",
    "authors": [
      "Sheng Tian",
      "Xintan Zeng",
      "Yifei Hu",
      "Baokun Wang",
      "Yongchao Liu",
      "Yue Jin",
      "Changhua Meng",
      "Chuntao Hong",
      "Tianyi Zhang",
      "Weiqiang Wang"
    ],
    "abstract": "Graph-based patterns are extensively employed and favored by practitioners\nwithin industrial companies due to their capacity to represent the behavioral\nattributes and topological relationships among users, thereby offering enhanced\ninterpretability in comparison to black-box models commonly utilized for\nclassification and recognition tasks. For instance, within the scenario of\ntransaction risk management, a graph pattern that is characteristic of a\nparticular risk category can be readily employed to discern transactions\nfraught with risk, delineate networks of criminal activity, or investigate the\nmethodologies employed by fraudsters. Nonetheless, graph data in industrial\nsettings is often characterized by its massive scale, encompassing data sets\nwith millions or even billions of nodes, making the manual extraction of graph\npatterns not only labor-intensive but also necessitating specialized knowledge\nin particular domains of risk. Moreover, existing methodologies for mining\ngraph patterns encounter significant obstacles when tasked with analyzing\nlarge-scale attributed graphs. In this work, we introduce GraphRPM, an\nindustry-purpose parallel and distributed risk pattern mining framework on\nlarge attributed graphs. The framework incorporates a novel edge-involved graph\nisomorphism network alongside optimized operations for parallel graph\ncomputation, which collectively contribute to a considerable reduction in\ncomputational complexity and resource expenditure. Moreover, the intelligent\nfiltration of efficacious risky graph patterns is facilitated by the proposed\nevaluation metrics. Comprehensive experimental evaluations conducted on\nreal-world datasets of varying sizes substantiate the capability of GraphRPM to\nadeptly address the challenges inherent in mining patterns from large-scale\nindustrial attributed graphs, thereby underscoring its substantial value for\nindustrial deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06878v1",
    "published_date": "2024-11-11 11:20:30 UTC",
    "updated_date": "2024-11-11 11:20:30 UTC"
  },
  {
    "arxiv_id": "2411.06872v1",
    "title": "Multi-Modal interpretable automatic video captioning",
    "authors": [
      "Antoine Hanna-Asaad",
      "Decky Aspandi",
      "Titus Zaharia"
    ],
    "abstract": "Video captioning aims to describe video contents using natural language\nformat that involves understanding and interpreting scenes, actions and events\nthat occurs simultaneously on the view. Current approaches have mainly\nconcentrated on visual cues, often neglecting the rich information available\nfrom other important modality of audio information, including their\ninter-dependencies. In this work, we introduce a novel video captioning method\ntrained with multi-modal contrastive loss that emphasizes both multi-modal\nintegration and interpretability. Our approach is designed to capture the\ndependency between these modalities, resulting in more accurate, thus pertinent\ncaptions. Furthermore, we highlight the importance of interpretability,\nemploying multiple attention mechanisms that provide explanation into the\nmodel's decision-making process. Our experimental results demonstrate that our\nproposed method performs favorably against the state-of the-art models on\ncommonly used benchmark datasets of MSR-VTT and VATEX.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06872v1",
    "published_date": "2024-11-11 11:12:23 UTC",
    "updated_date": "2024-11-11 11:12:23 UTC"
  },
  {
    "arxiv_id": "2411.06870v2",
    "title": "AI-Native Multi-Access Future Networks -- The REASON Architecture",
    "authors": [
      "Konstantinos Katsaros",
      "Ioannis Mavromatis",
      "Kostantinos Antonakoglou",
      "Saptarshi Ghosh",
      "Dritan Kaleshi",
      "Toktam Mahmoodi",
      "Hamid Asgari",
      "Anastasios Karousos",
      "Iman Tavakkolnia",
      "Hossein Safi",
      "Harald Hass",
      "Constantinos Vrontos",
      "Amin Emami",
      "Juan Parra Ullauri",
      "Shadi Moazzeni",
      "Dimitra Simeonidou"
    ],
    "abstract": "The development of the sixth generation of communication networks (6G) has\nbeen gaining momentum over the past years, with a target of being introduced by\n2030. Several initiatives worldwide are developing innovative solutions and\nsetting the direction for the key features of these networks. Some common\nemerging themes are the tight integration of AI, the convergence of multiple\naccess technologies and sustainable operation, aiming to meet stringent\nperformance and societal requirements. To that end, we are introducing REASON -\nRealising Enabling Architectures and Solutions for Open Networks. The REASON\nproject aims to address technical challenges in future network deployments,\nsuch as E2E service orchestration, sustainability, security and trust\nmanagement, and policy management, utilising AI-native principles, considering\nmultiple access technologies and cloud-native solutions.\n  This paper presents REASON's architecture and the identified requirements for\nfuture networks. The architecture is meticulously designed for modularity,\ninteroperability, scalability, simplified troubleshooting, flexibility, and\nenhanced security, taking into consideration current and future standardisation\nefforts, and the ease of implementation and training. It is structured into\nfour horizontal layers: Physical Infrastructure, Network Service, Knowledge,\nand End-User Application, complemented by two vertical layers: Management and\nOrchestration, and E2E Security. This layered approach ensures a robust,\nadaptable framework to support the diverse and evolving requirements of 6G\nnetworks, fostering innovation and facilitating seamless integration of\nadvanced technologies.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted for publication at IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2411.06870v2",
    "published_date": "2024-11-11 11:10:39 UTC",
    "updated_date": "2024-11-25 11:58:44 UTC"
  },
  {
    "arxiv_id": "2411.06866v1",
    "title": "Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering",
    "authors": [
      "Boci Peng",
      "Yongchao Liu",
      "Xiaohe Bo",
      "Sheng Tian",
      "Baokun Wang",
      "Chuntao Hong",
      "Yan Zhang"
    ],
    "abstract": "Commonsense question answering is a crucial task that requires machines to\nemploy reasoning according to commonsense. Previous studies predominantly\nemploy an extracting-and-modeling paradigm to harness the information in KG,\nwhich first extracts relevant subgraphs based on pre-defined rules and then\nproceeds to design various strategies aiming to improve the representations and\nfusion of the extracted structural knowledge. Despite their effectiveness,\nthere are still two challenges. On one hand, subgraphs extracted by rule-based\nmethods may have the potential to overlook critical nodes and result in\nuncontrollable subgraph size. On the other hand, the misalignment between graph\nand text modalities undermines the effectiveness of knowledge fusion,\nultimately impacting the task performance. To deal with the problems above, we\npropose a novel framework: \\textbf{S}ubgraph R\\textbf{E}trieval Enhanced by\nGra\\textbf{P}h-\\textbf{T}ext \\textbf{A}lignment, named \\textbf{SEPTA}. Firstly,\nwe transform the knowledge graph into a database of subgraph vectors and\npropose a BFS-style subgraph sampling strategy to avoid information loss,\nleveraging the analogy between BFS and the message-passing mechanism. In\naddition, we propose a bidirectional contrastive learning approach for\ngraph-text alignment, which effectively enhances both subgraph retrieval and\nknowledge fusion. Finally, all the retrieved information is combined for\nreasoning in the prediction module. Extensive experiments on five datasets\ndemonstrate the effectiveness and robustness of our framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06866v1",
    "published_date": "2024-11-11 10:57:31 UTC",
    "updated_date": "2024-11-11 10:57:31 UTC"
  },
  {
    "arxiv_id": "2411.06863v1",
    "title": "Computable Model-Independent Bounds for Adversarial Quantum Machine Learning",
    "authors": [
      "Bacui Li",
      "Tansu Alpcan",
      "Chandra Thapa",
      "Udaya Parampalli"
    ],
    "abstract": "By leveraging the principles of quantum mechanics, QML opens doors to novel\napproaches in machine learning and offers potential speedup. However, machine\nlearning models are well-documented to be vulnerable to malicious\nmanipulations, and this susceptibility extends to the models of QML. This\nsituation necessitates a thorough understanding of QML's resilience against\nadversarial attacks, particularly in an era where quantum computing\ncapabilities are expanding. In this regard, this paper examines\nmodel-independent bounds on adversarial performance for QML. To the best of our\nknowledge, we introduce the first computation of an approximate lower bound for\nadversarial error when evaluating model resilience against sophisticated\nquantum-based adversarial attacks. Experimental results are compared to the\ncomputed bound, demonstrating the potential of QML models to achieve high\nrobustness. In the best case, the experimental error is only 10% above the\nestimated bound, offering evidence of the inherent robustness of quantum\nmodels. This work not only advances our theoretical understanding of quantum\nmodel resilience but also provides a precise reference bound for the future\ndevelopment of robust QML algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06863v1",
    "published_date": "2024-11-11 10:56:31 UTC",
    "updated_date": "2024-11-11 10:56:31 UTC"
  },
  {
    "arxiv_id": "2411.06860v1",
    "title": "Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models",
    "authors": [
      "Abdullah Fajar",
      "Setiadi Yazid",
      "Indra Budi"
    ],
    "abstract": "Phishing attacks remain a persistent threat to online security, demanding\nrobust detection methods. This study investigates the use of machine learning\nto identify phishing URLs, emphasizing the crucial role of feature selection\nand model interpretability for improved performance. Employing Recursive\nFeature Elimination, the research pinpointed key features like \"length_url,\"\n\"time_domain_activation\" and \"Page_rank\" as strong indicators of phishing\nattempts. The study evaluated various algorithms, including CatBoost, XGBoost,\nand Explainable Boosting Machine, assessing their robustness and scalability.\nXGBoost emerged as highly efficient in terms of runtime, making it well-suited\nfor large datasets. CatBoost, on the other hand, demonstrated resilience by\nmaintaining high accuracy even with reduced features. To enhance transparency\nand trustworthiness, Explainable AI techniques, such as SHAP, were employed to\nprovide insights into feature importance. The study's findings highlight that\neffective feature selection and model interpretability can significantly\nbolster phishing detection systems, paving the way for more efficient and\nadaptable defenses against evolving cyber threats",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06860v1",
    "published_date": "2024-11-11 10:49:24 UTC",
    "updated_date": "2024-11-11 10:49:24 UTC"
  },
  {
    "arxiv_id": "2411.06858v1",
    "title": "Scientific machine learning in ecological systems: A study on the predator-prey dynamics",
    "authors": [
      "Ranabir Devgupta",
      "Raj Abhijit Dandekar",
      "Rajat Dandekar",
      "Sreedath Panat"
    ],
    "abstract": "In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental\necological model describing the dynamic interactions between predator and prey\npopulations. The Lotka-Volterra model is critical for understanding ecological\ndynamics, population control, and species interactions, as it is represented by\na system of differential equations. In this work, we aim to uncover the\nunderlying differential equations without prior knowledge of the system,\nrelying solely on training data and neural networks. Using robust modeling in\nthe Julia programming language, we demonstrate that both Neural ODEs and UDEs\ncan be effectively utilized for prediction and forecasting of the\nLotka-Volterra system. More importantly, we introduce the forecasting breakdown\npoint: the time at which forecasting fails for both Neural ODEs and UDEs. We\nobserve how UDEs outperform Neural ODEs by effectively recovering the\nunderlying dynamics and achieving accurate forecasting with significantly less\ntraining data. Additionally, we introduce Gaussian noise of varying magnitudes\n(from mild to high) to simulate real-world data perturbations and show that\nUDEs exhibit superior robustness, effectively recovering the underlying\ndynamics even in the presence of noisy data, while Neural ODEs struggle with\nhigh levels of noise. Through extensive hyperparameter optimization, we offer\ninsights into neural network architectures, activation functions, and\noptimizers that yield the best results. This study opens the door to applying\nScientific Machine Learning frameworks for forecasting tasks across a wide\nrange of ecological and scientific domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 7 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2411.06858v1",
    "published_date": "2024-11-11 10:40:45 UTC",
    "updated_date": "2024-11-11 10:40:45 UTC"
  },
  {
    "arxiv_id": "2411.06852v1",
    "title": "Evaluating Large Language Models on Financial Report Summarization: An Empirical Study",
    "authors": [
      "Xinqi Yang",
      "Scott Zang",
      "Yong Ren",
      "Dingjie Peng",
      "Zheng Wen"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\nversatility across various applications, including natural language\nunderstanding, domain-specific knowledge tasks, etc. However, applying LLMs to\ncomplex, high-stakes domains like finance requires rigorous evaluation to\nensure reliability, accuracy, and compliance with industry standards. To\naddress this need, we conduct a comprehensive and comparative study on three\nstate-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their\neffectiveness in generating automated financial reports. Our primary motivation\nis to explore how these models can be harnessed within finance, a field\ndemanding precision, contextual relevance, and robustness against erroneous or\nmisleading information. By examining each model's capabilities, we aim to\nprovide an insightful assessment of their strengths and limitations. Our paper\noffers benchmarks for financial report analysis, encompassing proposed metrics\nsuch as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative\nevaluation framework that integrates both quantitative metrics (e.g.,\nprecision, recall) and qualitative analyses (e.g., contextual fit, consistency)\nto provide a holistic view of each model's output quality. Additionally, we\nmake our financial dataset publicly available, inviting researchers and\npractitioners to leverage, scrutinize, and enhance our findings through broader\ncommunity engagement and collaborative improvement. Our dataset is available on\nhuggingface.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06852v1",
    "published_date": "2024-11-11 10:36:04 UTC",
    "updated_date": "2024-11-11 10:36:04 UTC"
  },
  {
    "arxiv_id": "2411.13566v1",
    "title": "Integrated Water Resource Management in the Segura Hydrographic Basin: An Artificial Intelligence Approach",
    "authors": [
      "Urtzi Otamendi",
      "Mikel Maiza",
      "Igor G. Olaizola",
      "Basilio Sierra",
      "Markel Flores",
      "Marco Quartulli"
    ],
    "abstract": "Managing resources effectively in uncertain demand, variable availability,\nand complex governance policies is a significant challenge. This paper presents\na paradigmatic framework for addressing these issues in water management\nscenarios by integrating advanced physical modelling, remote sensing\ntechniques, and Artificial Intelligence algorithms. The proposed approach\naccurately predicts water availability, estimates demand, and optimizes\nresource allocation on both short- and long-term basis, combining a\ncomprehensive hydrological model, agronomic crop models for precise demand\nestimation, and Mixed-Integer Linear Programming for efficient resource\ndistribution. In the study case of the Segura Hydrographic Basin, the approach\nsuccessfully allocated approximately 642 million cubic meters ($hm^3$) of water\nover six months, minimizing the deficit to 9.7% of the total estimated demand.\nThe methodology demonstrated significant environmental benefits, reducing CO2\nemissions while optimizing resource distribution. This robust solution supports\ninformed decision-making processes, ensuring sustainable water management\nacross diverse contexts. The generalizability of this approach allows its\nadaptation to other basins, contributing to improved governance and policy\nimplementation on a broader scale. Ultimately, the methodology has been\nvalidated and integrated into the operational water management practices in the\nSegura Hydrographic Basin in Spain.",
    "categories": [
      "cs.AI",
      "J.m; I.2.1; I.4.9"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 14 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.13566v1",
    "published_date": "2024-11-11 10:35:41 UTC",
    "updated_date": "2024-11-11 10:35:41 UTC"
  },
  {
    "arxiv_id": "2411.06850v1",
    "title": "1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs",
    "authors": [
      "Jebish Purbey",
      "Siddartha Pullakhandam",
      "Kanwal Mehreen",
      "Muhammad Arham",
      "Drishti Sharma",
      "Ashay Srivastava",
      "Ram Mohan Rao Kadiyala"
    ],
    "abstract": "This paper presents a detailed system description of our entry for the\nCHiPSAL 2025 shared task, focusing on language detection, hate speech\nidentification, and target detection in Devanagari script languages. We\nexperimented with a combination of large language models and their ensembles,\nincluding MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like\nfocal loss to address challenges in the natural understanding of Devanagari\nlanguages, such as multilingual processing and class imbalance. Our approach\nachieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804\nfor Sub-tasks A, B, and C respectively. This work provides insights into the\neffectiveness of transformer models in tasks with domain-specific and\nlinguistic challenges, as well as areas for potential improvement in future\niterations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, Submitted to CHIPSAL workshop @ COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.06850v1",
    "published_date": "2024-11-11 10:34:36 UTC",
    "updated_date": "2024-11-11 10:34:36 UTC"
  },
  {
    "arxiv_id": "2411.06839v2",
    "title": "LLM-NEO: Parameter Efficient Knowledge Distillation for Large Language Models",
    "authors": [
      "Runming Yang",
      "Taiqiang Wu",
      "Jiahao Wang",
      "Pengfei Hu",
      "Yik-Chung Wu",
      "Ngai Wong",
      "Yujiu Yang"
    ],
    "abstract": "Knowledge distillation (KD) has been a predominant method for compressing\nLarge Language Models (LLMs). In this paper, we first revisit KD and Low-Rank\nAdaption (LoRA) and demonstrate that they follow the same paradigm. Inspired by\nthis observation, we propose a parameter-efficient knowledge distillation\nmethod, LLM-NEO, which integrates LoRA into KD to improve the efficiency of\nknowledge transfer. After that, we summarize some valuable guidelines for the\nhyperparameters in LLM-NEO. Experimental results on compressing Llama 2 and\nLlama 3.2 show that LLM-NEO outperforms various baselines. Further analysis\ndemonstrates the robustness of the proposed LLM-NEO on variants of LoRA. The\ncode and trained models are available at\n[Github](https://github.com/yang3121099/LLM-Neo).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ARR under review",
    "pdf_url": "http://arxiv.org/pdf/2411.06839v2",
    "published_date": "2024-11-11 10:07:51 UTC",
    "updated_date": "2025-02-25 06:42:57 UTC"
  },
  {
    "arxiv_id": "2411.06833v1",
    "title": "Learning Interpretable Network Dynamics via Universal Neural Symbolic Regression",
    "authors": [
      "Jiao Hu",
      "Jiaxu Cui",
      "Bo Yang"
    ],
    "abstract": "Discovering governing equations of complex network dynamics is a fundamental\nchallenge in contemporary science with rich data, which can uncover the\nmysterious patterns and mechanisms of the formation and evolution of complex\nphenomena in various fields and assist in decision-making. In this work, we\ndevelop a universal computational tool that can automatically, efficiently, and\naccurately learn the symbolic changing patterns of complex system states by\ncombining the excellent fitting ability from deep learning and the equation\ninference ability from pre-trained symbolic regression. We conduct intensive\nexperimental verifications on more than ten representative scenarios from\nphysics, biochemistry, ecology, epidemiology, etc. Results demonstrate the\noutstanding effectiveness and efficiency of our tool by comparing with the\nstate-of-the-art symbolic regression techniques for network dynamics. The\napplication to real-world systems including global epidemic transmission and\npedestrian movements has verified its practical applicability. We believe that\nour tool can serve as a universal solution to dispel the fog of hidden\nmechanisms of changes in complex phenomena, advance toward interpretability,\nand inspire more scientific discoveries.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.06833v1",
    "published_date": "2024-11-11 09:51:22 UTC",
    "updated_date": "2024-11-11 09:51:22 UTC"
  },
  {
    "arxiv_id": "2411.06824v1",
    "title": "Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs",
    "authors": [
      "Megh Thakkar",
      "Yash More",
      "Quentin Fournier",
      "Matthew Riemer",
      "Pin-Yu Chen",
      "Amal Zouaq",
      "Payel Das",
      "Sarath Chandar"
    ],
    "abstract": "There is a growing interest in training domain-expert LLMs that excel in\nspecific technical fields compared to their general-purpose instruction-tuned\ncounterparts. However, these expert models often experience a loss in their\nsafety abilities in the process, making them capable of generating harmful\ncontent. As a solution, we introduce an efficient and effective merging-based\nalignment method called \\textsc{MergeAlign} that interpolates the domain and\nalignment vectors, creating safer domain-specific models while preserving their\nutility. We apply \\textsc{MergeAlign} on Llama3 variants that are experts in\nmedicine and finance, obtaining substantial alignment improvements with minimal\nto no degradation on domain-specific benchmarks. We study the impact of model\nmerging through model similarity metrics and contributions of individual models\nbeing merged. We hope our findings open new research avenues and inspire more\nefficient development of safe expert LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06824v1",
    "published_date": "2024-11-11 09:32:20 UTC",
    "updated_date": "2024-11-11 09:32:20 UTC"
  },
  {
    "arxiv_id": "2411.06812v1",
    "title": "Generative midtended cognition and Artificial Intelligence. Thinging with thinging things",
    "authors": [
      "Xabier E. Barandiaran",
      "Marta P√©rez-Verdugo"
    ],
    "abstract": "This paper introduces the concept of ``generative midtended cognition'',\nexploring the integration of generative AI with human cognition. The term\n\"generative\" reflects AI's ability to iteratively produce structured outputs,\nwhile \"midtended\" captures the potential hybrid (human-AI) nature of the\nprocess. It stands between traditional conceptions of intended creation,\nunderstood directed from within, and extended processes that bring\nexo-biological processes into the creative process. We examine current\ngenerative technologies (based on multimodal transformer architectures typical\nof large language models like ChatGPT), to explain how they can transform human\ncognitive agency beyond what standard theories of extended cognition can\ncapture. We suggest that the type of cognitive activity typical of the coupling\nbetween a human and generative technologies is closer (but not equivalent) to\nsocial cognition than to classical extended cognitive paradigms. Yet, it\ndeserves a specific treatment. We provide an explicit definition of generative\nmidtended cognition in which we treat interventions by AI systems as\nconstitutive of the agent's intentional creative processes. Furthermore, we\ndistinguish two dimensions of generative hybrid creativity: 1. Width: captures\nthe sensitivity of the context of the generative process (from the single\nletter to the whole historical and surrounding data), 2. Depth: captures the\ngranularity of iteration loops involved in the process. Generative midtended\ncognition stands in the middle depth between conversational forms of cognition\nin which complete utterances or creative units are exchanged, and\nmicro-cognitive (e.g. neural) subpersonal processes. Finally, the paper\ndiscusses the potential risks and benefits of widespread generative AI\nadoption, including the challenges of authenticity, generative power asymmetry,\nand creative boost or atrophy.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 2 figures. Submitted to \"Synthese\" Journal, accepted",
    "pdf_url": "http://arxiv.org/pdf/2411.06812v1",
    "published_date": "2024-11-11 09:14:27 UTC",
    "updated_date": "2024-11-11 09:14:27 UTC"
  },
  {
    "arxiv_id": "2411.06810v1",
    "title": "JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset",
    "authors": [
      "Daria Tsereh",
      "Mark Mirgaleev",
      "Ivan Molodetskikh",
      "Roman Kazantsev",
      "Dmitriy Vatolin"
    ],
    "abstract": "Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06810v1",
    "published_date": "2024-11-11 09:11:01 UTC",
    "updated_date": "2024-11-11 09:11:01 UTC"
  },
  {
    "arxiv_id": "2411.06805v1",
    "title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant",
    "authors": [
      "Yujia Zhou",
      "Zheng Liu",
      "Zhicheng Dou"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024 (poster)",
    "pdf_url": "http://arxiv.org/pdf/2411.06805v1",
    "published_date": "2024-11-11 09:03:52 UTC",
    "updated_date": "2024-11-11 09:03:52 UTC"
  },
  {
    "arxiv_id": "2411.06798v2",
    "title": "LA4SR: illuminating the dark proteome with generative AI",
    "authors": [
      "David R. Nelson",
      "Ashish Kumar Jaiswal",
      "Noha Ismail",
      "Alexandra Mystikou",
      "Kourosh Salehi-Ashtiani"
    ],
    "abstract": "AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CL",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06798v2",
    "published_date": "2024-11-11 08:51:18 UTC",
    "updated_date": "2024-12-11 11:10:22 UTC"
  },
  {
    "arxiv_id": "2411.06792v1",
    "title": "Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks",
    "authors": [
      "Wenxuan Pan",
      "Feifei Zhao",
      "Bing Han",
      "Haibo Tong",
      "Yi Zeng"
    ],
    "abstract": "By exploiting discrete signal processing and simulating brain neuron\ncommunication, Spiking Neural Networks (SNNs) offer a low-energy alternative to\nArtificial Neural Networks (ANNs). However, existing SNN models, still face\nhigh computational costs due to the numerous time steps as well as network\ndepth and scale. The tens of billions of neurons and trillions of synapses in\nthe human brain are developed from only 20,000 genes, which inspires us to\ndesign an efficient genetic encoding strategy that dynamic evolves to regulate\nlarge-scale deep SNNs at low cost. Therefore, we first propose a genetically\nscaled SNN encoding scheme that incorporates globally shared genetic\ninteractions to indirectly optimize neuronal encoding instead of weight, which\nobviously brings about reductions in parameters and energy consumption. Then, a\nspatio-temporal evolutionary framework is designed to optimize the inherently\ninitial wiring rules. Two dynamic regularization operators in the fitness\nfunction evolve the neuronal encoding to a suitable distribution and enhance\ninformation quality of the genetic interaction respectively, substantially\naccelerating evolutionary speed and improving efficiency. Experiments show that\nour approach compresses parameters by approximately 50\\% to 80\\%, while\noutperforming models on the same architectures by 0.21\\% to 4.38\\% on CIFAR-10,\nCIFAR-100 and ImageNet. In summary, the consistent trends of the proposed\ngenetically encoded spatio-temporal evolution across different datasets and\narchitectures highlight its significant enhancements in terms of efficiency,\nbroad scalability and robustness, demonstrating the advantages of the\nbrain-inspired evolutionary genetic coding for SNN optimization.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06792v1",
    "published_date": "2024-11-11 08:40:52 UTC",
    "updated_date": "2024-11-11 08:40:52 UTC"
  },
  {
    "arxiv_id": "2411.06786v1",
    "title": "ScaleKD: Strong Vision Transformers Could Be Excellent Teachers",
    "authors": [
      "Jiawei Fan",
      "Chao Li",
      "Xiaolong Liu",
      "Anbang Yao"
    ],
    "abstract": "In this paper, we question if well pre-trained vision transformer (ViT)\nmodels could be used as teachers that exhibit scalable properties to advance\ncross architecture knowledge distillation (KD) research, in the context of\nusing large-scale datasets for evaluation. To make this possible, our analysis\nunderlines the importance of seeking effective strategies to align (1) feature\ncomputing paradigm differences, (2) model scale differences, and (3) knowledge\ndensity differences. By combining three coupled components namely cross\nattention projector, dual-view feature mimicking and teacher parameter\nperception tailored to address the above problems, we present a simple and\neffective KD method, called ScaleKD. Our method can train student backbones\nthat span across a variety of convolutional neural network (CNN), multi-layer\nperceptron (MLP), and ViT architectures on image classification datasets,\nachieving state-of-the-art distillation performance. For instance, taking a\nwell pre-trained Swin-L as the teacher model, our method gets\n75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for\nMobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16\nmodels trained on ImageNet-1K dataset from scratch, showing\n3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the\nindividually trained counterparts. Intriguingly, when scaling up the size of\nteacher models or their pre-training datasets, our method showcases the desired\nscalable properties, bringing increasingly larger gains to student models. The\nstudent backbones trained by our method transfer well on downstream MS-COCO and\nADE20K datasets. More importantly, our method could be used as a more efficient\nalternative to the time-intensive pre-training paradigm for any target student\nmodel if a strong pre-trained ViT is available, reducing the amount of viewed\ntraining samples up to 195x.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work is accepted to NeurIPS 2024. The project page:\n  https://github.com/deep-optimization/ScaleKD",
    "pdf_url": "http://arxiv.org/pdf/2411.06786v1",
    "published_date": "2024-11-11 08:25:21 UTC",
    "updated_date": "2024-11-11 08:25:21 UTC"
  },
  {
    "arxiv_id": "2411.06782v2",
    "title": "QuadWBG: Generalizable Quadrupedal Whole-Body Grasping",
    "authors": [
      "Jilong Wang",
      "Javokhirbek Rajabov",
      "Chaoyi Xu",
      "Yiming Zheng",
      "He Wang"
    ],
    "abstract": "Legged robots with advanced manipulation capabilities have the potential to\nsignificantly improve household duties and urban maintenance. Despite\nconsiderable progress in developing robust locomotion and precise manipulation\nmethods, seamlessly integrating these into cohesive whole-body control for\nreal-world applications remains challenging. In this paper, we present a\nmodular framework for robust and generalizable whole-body loco-manipulation\ncontroller based on a single arm-mounted camera. By using reinforcement\nlearning (RL), we enable a robust low-level policy for command execution over 5\ndimensions (5D) and a grasp-aware high-level policy guided by a novel metric,\nGeneralized Oriented Reachability Map (GORM). The proposed system achieves\nstate-of-the-art one-time grasping accuracy of 89% in the real world, including\nchallenging tasks such as grasping transparent objects. Through extensive\nsimulations and real-world experiments, we demonstrate that our system can\neffectively manage a large workspace, from floor level to above body height,\nand perform diverse whole-body loco-manipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06782v2",
    "published_date": "2024-11-11 08:19:54 UTC",
    "updated_date": "2025-01-13 14:11:49 UTC"
  },
  {
    "arxiv_id": "2411.06781v1",
    "title": "MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting",
    "authors": [
      "Thang Nguyen",
      "Dung Nguyen",
      "Kha Pham",
      "Truyen Tran"
    ],
    "abstract": "Forecasting temporal processes such as virus spreading in epidemics often\nrequires more than just observed time-series data, especially at the beginning\nof a wave when data is limited. Traditional methods employ mechanistic models\nlike the SIR family, which make strong assumptions about the underlying\nspreading process, often represented as a small set of compact differential\nequations. Data-driven methods such as deep neural networks make no such\nassumptions and can capture the generative process in more detail, but fail in\nlong-term forecasting due to data limitations. We propose a new hybrid method\ncalled MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the\nlimitations of these two major approaches. MP-PINN instils the spreading\nmechanism into a neural network, enabling the mechanism to update in phases\nover time, reflecting the dynamics of the epidemics due to policy\ninterventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves\nsuperior performance over pure data-driven or model-driven approaches for both\nshort-term and long-term forecasting.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06781v1",
    "published_date": "2024-11-11 08:19:22 UTC",
    "updated_date": "2024-11-11 08:19:22 UTC"
  },
  {
    "arxiv_id": "2411.06776v1",
    "title": "Machine vision-aware quality metrics for compressed image and video assessment",
    "authors": [
      "Mikhail Dremin",
      "Konstantin Kozhemyakov",
      "Ivan Molodetskikh",
      "Malakhov Kirill",
      "Artur Sagitov",
      "Dmitriy Vatolin"
    ],
    "abstract": "A main goal in developing video-compression algorithms is to enhance\nhuman-perceived visual quality while maintaining file size. But modern\nvideo-analysis efforts such as detection and recognition, which are integral to\nvideo surveillance and autonomous vehicles, involve so much data that they\nnecessitate machine-vision processing with minimal human intervention. In such\ncases, the video codec must be optimized for machine vision. This paper\nexplores the effects of compression on detection and recognition algorithms\n(objects, faces, and license plates) and introduces novel full-reference\nimage/video-quality metrics for each task, tailored to machine vision.\nExperimental results indicate our proposed metrics correlate better with the\nmachine-vision results for the respective tasks than do existing\nimage/video-quality metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06776v1",
    "published_date": "2024-11-11 08:07:34 UTC",
    "updated_date": "2024-11-11 08:07:34 UTC"
  },
  {
    "arxiv_id": "2411.06772v1",
    "title": "A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts",
    "authors": [
      "Liu Zhuoxian",
      "Shi Tuo",
      "Hu Xiaofeng"
    ],
    "abstract": "Front-line police officers often categorize all police call reported cases of\nTelecom Fraud into 14 subcategories to facilitate targeted prevention measures,\nsuch as precise public education. However, the associated data is characterized\nby its large volume, diverse information content, and variations in expression.\nCurrently, there is a lack of efficient and accurate intelligent models to\nreplace manual classification, which, while precise, is relatively inefficient.\nTo address these challenges, this paper proposes a text classification model\nthat combines adversarial training with Pre-trained Language Model and neural\nnetworks. The Linguistically-motivated Pre-trained Language Model model\nextracts three types of language features and then utilizes the Fast Gradient\nMethod algorithm to perturb the generated embedding layer. Subsequently, the\nBi-directional Long Short-Term Memory and Convolutional Neural Networks\nnetworks extract contextual syntactic information and local semantic\ninformation, respectively. The model achieved an 83.9% classification accuracy\nwhen trained on a portion of telecom fraud case data provided by the\noperational department. The model established in this paper has been deployed\nin the operational department, freeing up a significant amount of manpower and\nimproving the department's efficiency in combating Telecom Fraud crimes.\nFurthermore, considering the universality of the model established in this\npaper, other application scenarios await further exploration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06772v1",
    "published_date": "2024-11-11 07:52:38 UTC",
    "updated_date": "2024-11-11 07:52:38 UTC"
  },
  {
    "arxiv_id": "2411.06767v1",
    "title": "PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing",
    "authors": [
      "Yiwen Duan",
      "Yonghong Yu",
      "Xiaoming Zhao",
      "Yichang Wu",
      "Wenbo Liu"
    ],
    "abstract": "Code Large Language Models (Code LLMs), such as Code llama and\nDeepSeek-Coder, have demonstrated exceptional performance in the code\ngeneration tasks. However, most existing models focus on the abilities of\ngenerating correct code, but often struggle with bug repair. We introduce a\nsuit of methods to enhance LLM's SQL bug-fixing abilities. The methods are\nmainly consisted of two parts: A Progressive Dataset Construction (PDC) from\nscratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data\nexpansion methods from the perspectives of breadth first and depth first\nrespectively. DM-SFT introduces an efficient bug-fixing supervised learning\napproach, which effectively reduce the total training steps and mitigate the\n\"disorientation\" in SQL code bug-fixing training. In our evaluation, the code\nLLM models trained with two methods have exceeds all current best performing\nmodel which size is much larger.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING-Industry 2025 accepted",
    "pdf_url": "http://arxiv.org/pdf/2411.06767v1",
    "published_date": "2024-11-11 07:47:20 UTC",
    "updated_date": "2024-11-11 07:47:20 UTC"
  },
  {
    "arxiv_id": "2411.06765v1",
    "title": "Research on an intelligent fault diagnosis method for nuclear power plants based on ETCN-SSA combined algorithm",
    "authors": [
      "Jiayan Fang",
      "Siwei Li",
      "Yichun Wu"
    ],
    "abstract": "Utilizing fault diagnosis methods is crucial for nuclear power professionals\nto achieve efficient and accurate fault diagnosis for nuclear power plants\n(NPPs). The performance of traditional methods is limited by their dependence\non complex feature extraction and skilled expert knowledge, which can be\ntime-consuming and subjective. This paper proposes a novel intelligent fault\ndiagnosis method for NPPs that combines enhanced temporal convolutional network\n(ETCN) with sparrow search algorithm (SSA). ETCN utilizes temporal\nconvolutional network (TCN), self-attention (SA) mechanism and residual block\nfor enhancing performance. ETCN excels at extracting local features and\ncapturing time series information, while SSA adaptively optimizes its\nhyperparameters for superior performance. The proposed method's performance is\nexperimentally verified on a CPR1000 simulation dataset. Compared to other\nadvanced intelligent fault diagnosis methods, the proposed one demonstrates\nsuperior performance across all evaluation metrics. This makes it a promising\ntool for NPP intelligent fault diagnosis, ultimately enhancing operational\nreliability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06765v1",
    "published_date": "2024-11-11 07:43:12 UTC",
    "updated_date": "2024-11-11 07:43:12 UTC"
  },
  {
    "arxiv_id": "2411.06749v1",
    "title": "KLCBL: An Improved Police Incident Classification Model",
    "authors": [
      "Liu Zhuoxian",
      "Shi Tuo",
      "Hu Xiaofeng"
    ],
    "abstract": "Police incident data is crucial for public security intelligence, yet\ngrassroots agencies struggle with efficient classification due to manual\ninefficiency and automated system limitations, especially in telecom and online\nfraud cases. This research proposes a multichannel neural network model, KLCBL,\nintegrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text\npreprocessing approach (LERT), Convolutional Neural Network (CNN), and\nBidirectional Long Short-Term Memory (BiLSTM) for police incident\nclassification. Evaluated with real data, KLCBL achieved 91.9% accuracy,\noutperforming baseline models. The model addresses classification challenges,\nenhances police informatization, improves resource allocation, and offers broad\napplicability to other classification tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06749v1",
    "published_date": "2024-11-11 07:02:23 UTC",
    "updated_date": "2024-11-11 07:02:23 UTC"
  },
  {
    "arxiv_id": "2411.06740v4",
    "title": "Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening",
    "authors": [
      "Zhangfan Yang",
      "Junkai Ji",
      "Shan He",
      "Jianqiang Li",
      "Tiantian He",
      "Ruibin Bai",
      "Zexuan Zhu",
      "Yew Soon Ong"
    ],
    "abstract": "Molecular docking is a crucial step in drug development, which enables the\nvirtual screening of compound libraries to identify potential ligands that\ntarget proteins of interest. However, the computational complexity of\ntraditional docking models increases as the size of the compound library\nincreases. Recently, deep learning algorithms can provide data-driven research\nand development models to increase the speed of the docking process.\nUnfortunately, few models can achieve superior screening performance compared\nto that of traditional models. Therefore, a novel deep learning-based docking\napproach named Dockformer is introduced in this study. Dockformer leverages\nmultimodal information to capture the geometric topology and structural\nknowledge of molecules and can directly generate binding conformations with the\ncorresponding confidence measures in an end-to-end manner. The experimental\nresults show that Dockformer achieves success rates of 90.53% and 82.71% on the\nPDBbind core set and PoseBusters benchmarks, respectively, and more than a\n100-fold increase in the inference process speed, outperforming almost all\nstate-of-the-art docking methods. In addition, the ability of Dockformer to\nidentify the main protease inhibitors of coronaviruses is demonstrated in a\nreal-world virtual screening scenario. Considering its high docking accuracy\nand screening efficiency, Dockformer can be regarded as a powerful and robust\ntool in the field of drug design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06740v4",
    "published_date": "2024-11-11 06:25:13 UTC",
    "updated_date": "2024-12-05 14:56:30 UTC"
  },
  {
    "arxiv_id": "2411.06735v2",
    "title": "Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data",
    "authors": [
      "Kai Kim",
      "Howard Tsai",
      "Rajat Sen",
      "Abhimanyu Das",
      "Zihao Zhou",
      "Abhishek Tanpure",
      "Mathew Luo",
      "Rose Yu"
    ],
    "abstract": "Current forecasting approaches are largely unimodal and ignore the rich\ntextual data that often accompany the time series due to lack of well-curated\nmultimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a\ncarefully curated, time-aligned text and time dataset for multimodal\nforecasting. Our dataset is composed of sequences of numbers and text aligned\nto timestamps, and includes data from two different domains: climate science\nand healthcare. Our data is a significant contribution to the rare selection of\navailable multimodal datasets. We also propose the Hybrid Multi-Modal\nForecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and\ntime series data using shared embeddings. However, contrary to our\nexpectations, our Hybrid-MMF model does not outperform existing baselines in\nour experiments. This negative result highlights the challenges inherent in\nmultimodal forecasting. Our code and data are available at\nhttps://github.com/Rose-STL-Lab/Multimodal_ Forecasting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 4 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06735v2",
    "published_date": "2024-11-11 06:04:15 UTC",
    "updated_date": "2024-11-21 00:52:53 UTC"
  },
  {
    "arxiv_id": "2411.06728v1",
    "title": "On the Principles of ReLU Networks with One Hidden Layer",
    "authors": [
      "Changcun Huang"
    ],
    "abstract": "A neural network with one hidden layer or a two-layer network (regardless of\nthe input layer) is the simplest feedforward neural network, whose mechanism\nmay be the basis of more general network architectures. However, even to this\ntype of simple architecture, it is also a ``black box''; that is, it remains\nunclear how to interpret the mechanism of its solutions obtained by the\nback-propagation algorithm and how to control the training process through a\ndeterministic way. This paper systematically studies the first problem by\nconstructing universal function-approximation solutions. It is shown that, both\ntheoretically and experimentally, the training solution for the one-dimensional\ninput could be completely understood, and that for a higher-dimensional input\ncan also be well interpreted to some extent. Those results pave the way for\nthoroughly revealing the black box of two-layer ReLU networks and advance the\nunderstanding of deep ReLU networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "68T07(Primary), 41A15(Secondary)",
      "I.2.6; G.1.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06728v1",
    "published_date": "2024-11-11 05:51:11 UTC",
    "updated_date": "2024-11-11 05:51:11 UTC"
  },
  {
    "arxiv_id": "2411.06723v1",
    "title": "Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy",
    "authors": [
      "Xin Sun",
      "Jan de Wit",
      "Zhuying Li",
      "Jiahuan Pei",
      "Abdallah El Ali",
      "Jos A. Bosch"
    ],
    "abstract": "Chatbots or conversational agents (CAs) are increasingly used to improve\naccess to digital psychotherapy. Many current systems rely on rigid, rule-based\ndesigns, heavily dependent on expert-crafted dialogue scripts for guiding\ntherapeutic conversations. Although recent advances in large language models\n(LLMs) offer the potential for more flexible interactions, their lack of\ncontrollability and transparency poses significant challenges in sensitive\nareas like psychotherapy. In this work, we explored how aligning LLMs with\nexpert-crafted scripts can enhance psychotherapeutic chatbot performance. Our\ncomparative study showed that LLMs aligned with expert-crafted scripts through\nprompting and fine-tuning significantly outperformed both pure LLMs and\nrule-based chatbots, achieving a more effective balance between dialogue\nflexibility and adherence to therapeutic principles. Building on findings, we\nproposed ``Script-Strategy Aligned Generation (SSAG)'', a flexible alignment\napproach that reduces reliance on fully scripted content while enhancing LLMs'\ntherapeutic adherence and controllability. In a 10-day field study, SSAG\ndemonstrated performance comparable to full script alignment and outperformed\nrule-based chatbots, empirically supporting SSAG as an efficient approach for\naligning LLMs with domain expertise. Our work advances LLM applications in\npsychotherapy by providing a controllable, adaptable, and scalable solution for\ndigital interventions, reducing reliance on expert effort. It also provides a\ncollaborative framework for domain experts and developers to efficiently build\nexpertise-aligned chatbots, broadening access to psychotherapy and behavioral\ninterventions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06723v1",
    "published_date": "2024-11-11 05:14:14 UTC",
    "updated_date": "2024-11-11 05:14:14 UTC"
  },
  {
    "arxiv_id": "2411.06722v1",
    "title": "Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models",
    "authors": [
      "Yeming Wen",
      "Swarat Chaudhuri"
    ],
    "abstract": "Presenting users with diverse responses from foundation models is crucial for\nenhancing user experience and accommodating varying preferences. However,\ngenerating multiple high-quality and diverse responses without sacrificing\naccuracy remains a challenge, especially when using greedy sampling. In this\nwork, we propose a novel framework, Synthesize-Partition-Adapt (SPA), that\nleverages the abundant synthetic data available in many domains to elicit\ndiverse responses from foundation models. By leveraging signal provided by data\nattribution methods such as influence functions, SPA partitions data into\nsubsets, each targeting unique aspects of the data, and trains multiple model\nadaptations optimized for these subsets. Experimental results demonstrate the\neffectiveness of our approach in diversifying foundation model responses while\nmaintaining high quality, showcased through the HumanEval and MBPP tasks in the\ncode generation domain and several tasks in the natural language understanding\ndomain, highlighting its potential to enrich user experience across various\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06722v1",
    "published_date": "2024-11-11 05:13:21 UTC",
    "updated_date": "2024-11-11 05:13:21 UTC"
  },
  {
    "arxiv_id": "2411.06714v1",
    "title": "DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations",
    "authors": [
      "Xuming He",
      "Zhiwang Zhou",
      "Wenlong Zhang",
      "Xiangyu Zhao",
      "Hao Chen",
      "Shiqi Chen",
      "Lei Bai"
    ],
    "abstract": "Weather radar data synthesis can fill in data for areas where ground\nobservations are missing. Existing methods often employ reconstruction-based\napproaches with MSE loss to reconstruct radar data from satellite observation.\nHowever, such methods lead to over-smoothing, which hinders the generation of\nhigh-frequency details or high-value observation areas associated with\nconvective weather. To address this issue, we propose a two-stage\ndiffusion-based method called DiffSR. We first pre-train a reconstruction model\non global-scale data to obtain radar estimation and then synthesize radar\nreflectivity by combining radar estimation results with satellite data as\nconditions for the diffusion model. Extensive experiments show that our method\nachieves state-of-the-art (SOTA) results, demonstrating the ability to generate\nhigh-frequency details and high-value areas.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06714v1",
    "published_date": "2024-11-11 04:50:34 UTC",
    "updated_date": "2024-11-11 04:50:34 UTC"
  },
  {
    "arxiv_id": "2411.06713v1",
    "title": "Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models",
    "authors": [
      "Chanseo Lee",
      "Sonu Kumar",
      "Kimon A. Vogt",
      "Sam Meraj"
    ],
    "abstract": "This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned\nfor medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and\nLlama-3.2-3B) in clinical documentation. We analyzed de-identified patient\ntranscripts from partner clinics, using clinician-provided SOAP notes as the\nground truth. Each model generated SOAP summaries using zero-shot prompting,\nwith performance assessed via recall, precision, and F1 scores. Sporo\noutperformed all models, achieving the highest recall (73.3%), precision\n(78.6%), and F1 score (75.3%) with the lowest performance variance.\nStatistically significant differences (p < 0.05) were found between Sporo and\nthe other models, with post-hoc tests showing significant improvements over\nGPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to\n10%, the difference was not statistically significant (p = 0.25). Clinical user\nsatisfaction, measured with a modified PDQI-9 inventory, favored Sporo.\nEvaluations indicated Sporo's outputs were more accurate and relevant. This\nhighlights the potential of Sporo's multi-agentic architecture to improve\nclinical workflows.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2410.15528",
    "pdf_url": "http://arxiv.org/pdf/2411.06713v1",
    "published_date": "2024-11-11 04:45:48 UTC",
    "updated_date": "2024-11-11 04:45:48 UTC"
  },
  {
    "arxiv_id": "2411.06711v1",
    "title": "Anytime Probabilistically Constrained Provably Convergent Online Belief Space Planning",
    "authors": [
      "Andrey Zhitnikov",
      "Vadim Indelman"
    ],
    "abstract": "Taking into account future risk is essential for an autonomously operating\nrobot to find online not only the best but also a safe action to execute. In\nthis paper, we build upon the recently introduced formulation of probabilistic\nbelief-dependent constraints. We present an anytime approach employing the\nMonte Carlo Tree Search (MCTS) method in continuous domains. Unlike previous\napproaches, our method assures safety anytime with respect to the currently\nexpanded search tree without relying on the convergence of the search. We prove\nconvergence in probability with an exponential rate of a version of our\nalgorithms and study proposed techniques via extensive simulations. Even with a\ntiny number of tree queries, the best action found by our approach is much\nsafer than the baseline. Moreover, our approach constantly finds better than\nthe baseline action in terms of objective. This is because we revise the values\nand statistics maintained in the search tree and remove from them the\ncontribution of the pruned actions.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2302.10439 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2411.06711v1",
    "published_date": "2024-11-11 04:42:18 UTC",
    "updated_date": "2024-11-11 04:42:18 UTC"
  },
  {
    "arxiv_id": "2411.06710v2",
    "title": "Model Fusion through Bayesian Optimization in Language Model Fine-Tuning",
    "authors": [
      "Chaeyun Jang",
      "Hyungi Lee",
      "Jungtaek Kim",
      "Juho Lee"
    ],
    "abstract": "Fine-tuning pre-trained models for downstream tasks is a widely adopted\ntechnique known for its adaptability and reliability across various domains.\nDespite its conceptual simplicity, fine-tuning entails several troublesome\nengineering choices, such as selecting hyperparameters and determining\ncheckpoints from an optimization trajectory. To tackle the difficulty of\nchoosing the best model, one effective solution is model fusion, which combines\nmultiple models in a parameter space. However, we observe a large discrepancy\nbetween loss and metric landscapes during the fine-tuning of pre-trained\nlanguage models. Building on this observation, we introduce a novel model\nfusion technique that optimizes both the desired metric and loss through\nmulti-objective Bayesian optimization. In addition, to effectively select\nhyperparameters, we establish a two-stage procedure by integrating Bayesian\noptimization processes into our framework. Experiments across various\ndownstream tasks show considerable performance improvements using our Bayesian\noptimization-guided method.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06710v2",
    "published_date": "2024-11-11 04:36:58 UTC",
    "updated_date": "2024-12-27 04:27:23 UTC"
  },
  {
    "arxiv_id": "2411.06691v1",
    "title": "Autonomous Droplet Microfluidic Design Framework with Large Language Models",
    "authors": [
      "Dinh-Nguyen Nguyen",
      "Raymond Kai-Yu Tong",
      "Ngoc-Duy Dinh"
    ],
    "abstract": "Droplet-based microfluidic devices have substantial promise as cost-effective\nalternatives to current assessment tools in biological research. Moreover,\nmachine learning models that leverage tabular data, including input design\nparameters and their corresponding efficiency outputs, are increasingly\nutilised to automate the design process of these devices and to predict their\nperformance. However, these models fail to fully leverage the data presented in\nthe tables, neglecting crucial contextual information, including column\nheadings and their associated descriptions. This study presents\nMicroFluidic-LLMs, a framework designed for processing and feature extraction,\nwhich effectively captures contextual information from tabular data formats.\nMicroFluidic-LLMs overcomes processing challenges by transforming the content\ninto a linguistic format and leveraging pre-trained large language models\n(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11\nprediction tasks, covering aspects such as geometry, flow conditions, regimes,\nand performance, utilising a publicly available dataset on flow-focusing\ndroplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can\nempower deep neural network models to be highly effective and straightforward\nwhile minimising the need for extensive data preprocessing. Moreover, the\nexceptional performance of deep neural network models, particularly when\ncombined with advanced natural language processing models such as DistilBERT\nand GPT-2, reduces the mean absolute error in the droplet diameter and\ngeneration rate by nearly 5- and 7-fold, respectively, and enhances the regime\nclassification accuracy by over 4%, compared with the performance reported in a\nprevious study. This study lays the foundation for the huge potential\napplications of LLMs and machine learning in a wider spectrum of microfluidic\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06691v1",
    "published_date": "2024-11-11 03:20:53 UTC",
    "updated_date": "2024-11-11 03:20:53 UTC"
  },
  {
    "arxiv_id": "2411.06685v2",
    "title": "High-Frequency Enhanced Hybrid Neural Representation for Video Compression",
    "authors": [
      "Li Yu",
      "Zhihui Li",
      "Jimin Xiao",
      "Moncef Gabbouj"
    ],
    "abstract": "Neural Representations for Videos (NeRV) have simplified the video codec\nprocess and achieved swift decoding speeds by encoding video content into a\nneural network, presenting a promising solution for video compression. However,\nexisting work overlooks the crucial issue that videos reconstructed by these\nmethods lack high-frequency details. To address this problem, this paper\nintroduces a High-Frequency Enhanced Hybrid Neural Representation Network. Our\nmethod focuses on leveraging high-frequency information to improve the\nsynthesis of fine details by the network. Specifically, we design a wavelet\nhigh-frequency encoder that incorporates Wavelet Frequency Decomposer (WFD)\nblocks to generate high-frequency feature embeddings. Next, we design the\nHigh-Frequency Feature Modulation (HFM) block, which leverages the extracted\nhigh-frequency embeddings to enhance the fitting process of the decoder.\nFinally, with the refined Harmonic decoder block and a Dynamic Weighted\nFrequency Loss, we further reduce the potential loss of high-frequency\ninformation. Experiments on the Bunny and UVG datasets demonstrate that our\nmethod outperforms other methods, showing notable improvements in detail\npreservation and compression performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06685v2",
    "published_date": "2024-11-11 03:04:46 UTC",
    "updated_date": "2025-04-30 02:50:26 UTC"
  },
  {
    "arxiv_id": "2411.06681v1",
    "title": "WDMoE: Wireless Distributed Mixture of Experts for Large Language Models",
    "authors": [
      "Nan Xue",
      "Yaping Sun",
      "Zhiyong Chen",
      "Meixia Tao",
      "Xiaodong Xu",
      "Liang Qian",
      "Shuguang Cui",
      "Wenjun Zhang",
      "Ping Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but the role of wireless networks in\nsupporting LLMs has not been thoroughly explored. In this paper, we propose a\nwireless distributed Mixture of Experts (WDMoE) architecture to enable\ncollaborative deployment of LLMs across edge servers at the base station (BS)\nand mobile devices in wireless networks. Specifically, we decompose the MoE\nlayer in LLMs by placing the gating network and the preceding neural network\nlayer at BS, while distributing the expert networks among the devices. This\ndeployment leverages the parallel inference capabilities of expert networks on\nmobile devices, effectively utilizing the limited computing and caching\nresources of these devices. Accordingly, we develop a performance metric for\nWDMoE-based LLMs, which accounts for both model capability and latency. To\nminimize the latency while maintaining accuracy, we jointly optimize expert\nselection and bandwidth allocation based on the performance metric. Moreover,\nwe build a hardware testbed using NVIDIA Jetson kits to validate the\neffectiveness of WDMoE. Both theoretical simulations and practical hardware\nexperiments demonstrate that the proposed method can significantly reduce the\nlatency without compromising LLM performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06681v1",
    "published_date": "2024-11-11 02:48:00 UTC",
    "updated_date": "2024-11-11 02:48:00 UTC"
  },
  {
    "arxiv_id": "2411.06672v1",
    "title": "What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance",
    "authors": [
      "Hong Meng Yam",
      "Nathan J Paek"
    ],
    "abstract": "We explore the impact of pre-training data composition on the performance of\nsmall language models in a sample-efficient setting. Using datasets limited to\n10 million words, we evaluate several dataset sources, including child-directed\nspeech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and\na mix of these (Mix) across different model sizes ranging from 18 million to\n705 million parameters. Our experiments show that smaller models (e.g.,\nGPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex\nand rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories\ndatasets underperformed across all model sizes. These findings suggest that the\noptimal dataset for sample efficient training depends on the model size, and\nthat neither child-directed speech nor simplified stories are optimal for\nlanguage models of all sizes. We highlight the importance of considering both\ndataset composition and model capacity for effective sample efficient language\nmodel training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 6 figures, CoNLL 2024 (Shared Task) Accepted Paper",
    "pdf_url": "http://arxiv.org/pdf/2411.06672v1",
    "published_date": "2024-11-11 02:37:21 UTC",
    "updated_date": "2024-11-11 02:37:21 UTC"
  },
  {
    "arxiv_id": "2411.06666v1",
    "title": "Adversarial Detection with a Dynamically Stable System",
    "authors": [
      "Xiaowei Long",
      "Jie Lin",
      "Xiangyuan Yang"
    ],
    "abstract": "Adversarial detection is designed to identify and reject maliciously crafted\nadversarial examples(AEs) which are generated to disrupt the classification of\ntarget models.\n  Presently, various input transformation-based methods have been developed on\nadversarial example detection, which typically rely on empirical experience and\nlead to unreliability against new attacks.\n  To address this issue, we propose and conduct a Dynamically Stable System\n(DSS), which can effectively detect the adversarial examples from normal\nexamples according to the stability of input examples.\n  Particularly, in our paper, the generation of adversarial examples is\nconsidered as the perturbation process of a Lyapunov dynamic system, and we\npropose an example stability mechanism, in which a novel control term is added\nin adversarial example generation to ensure that the normal examples can\nachieve dynamic stability while the adversarial examples cannot achieve the\nstability.\n  Then, based on the proposed example stability mechanism, a Dynamically Stable\nSystem (DSS) is proposed, which can utilize the disruption and restoration\nactions to determine the stability of input examples and detect the adversarial\nexamples through changes in the stability of the input examples.\n  In comparison with existing methods in three benchmark datasets(MNIST,\nCIFAR10, and CIFAR100), our evaluation results show that our proposed DSS can\nachieve ROC-AUC values of 99.83%, 97.81% and 94.47%, surpassing the\nstate-of-the-art(SOTA) values of 97.35%, 91.10% and 93.49% in the other 7\nmethods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06666v1",
    "published_date": "2024-11-11 02:16:17 UTC",
    "updated_date": "2024-11-11 02:16:17 UTC"
  },
  {
    "arxiv_id": "2411.06659v1",
    "title": "An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning",
    "authors": [
      "Dong Li",
      "Aijia Zhang",
      "Junqi Gao",
      "Biqing Qi"
    ],
    "abstract": "Incremental graph learning has gained significant attention for its ability\nto address the catastrophic forgetting problem in graph representation\nlearning. However, traditional methods often rely on a large number of labels\nfor node classification, which is impractical in real-world applications. This\nmakes few-shot incremental learning on graphs a pressing need. Current methods\ntypically require extensive training samples from meta-learning to build memory\nand perform intensive fine-tuning of GNN parameters, leading to high memory\nconsumption and potential loss of previously learned knowledge. To tackle these\nchallenges, we introduce Mecoin, an efficient method for building and\nmaintaining memory. Mecoin employs Structured Memory Units to cache prototypes\nof learned categories, as well as Memory Construction Modules to update these\nprototypes for new categories through interactions between the nodes and the\ncached prototypes. Additionally, we have designed a Memory Representation\nAdaptation Module to store probabilities associated with each class prototype,\nreducing the need for parameter fine-tuning and lowering the forgetting rate.\nWhen a sample matches its corresponding class prototype, the relevant\nprobabilities are retrieved from the MRaM. Knowledge is then distilled back\ninto the GNN through a Graph Knowledge Distillation Module, preserving the\nmodel's memory. We analyze the effectiveness of Mecoin in terms of\ngeneralization error and explore the impact of different distillation\nstrategies on model performance through experiments and VC-dimension analysis.\nCompared to other related works, Mecoin shows superior performance in accuracy\nand forgetting rate. Our code is publicly available on the\nhttps://github.com/Arvin0313/Mecoin-GFSCIL.git .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 6 figures, 38th Conference on Neural Information Processing\n  Systems, 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06659v1",
    "published_date": "2024-11-11 01:53:14 UTC",
    "updated_date": "2024-11-11 01:53:14 UTC"
  },
  {
    "arxiv_id": "2411.06657v1",
    "title": "Renaissance: Investigating the Pretraining of Vision-Language Encoders",
    "authors": [
      "Clayton Fields",
      "Casey Kennington"
    ],
    "abstract": "In the past several years there has been an explosion of available models for\nvision-language tasks. Unfortunately, the literature still leaves open a number\nof questions related to best practices in designing and training such models.\nIn this paper we seek to answer several questions related to the pretraining of\nvision-language encoders through meta-analysis. In our first set of\nexperiments, we show that we can save significant compute at no cost to\ndownstream performance, by freezing large parts of vision-language models\nduring pretraining. In our second set of experiments we examine the effect of\nbasing a VL transformer on a vision model versus a text model. Additionally, we\nintroduce a VL modeling platform called Renaissance that we use to conduct all\nof the experiments. This program offers a great deal of flexibility in\ncreating, training and evaluating transformer encoders for VL modeling. The\nsource code for Renaissance can be found at\nhttps://github.com/bsu-slim/renaissance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06657v1",
    "published_date": "2024-11-11 01:44:54 UTC",
    "updated_date": "2024-11-11 01:44:54 UTC"
  },
  {
    "arxiv_id": "2411.06655v2",
    "title": "Explore the Reasoning Capability of LLMs in the Chess Testbed",
    "authors": [
      "Shu Wang",
      "Lei Ji",
      "Renxi Wang",
      "Wenxiao Zhao",
      "Haokun Liu",
      "Yifan Hou",
      "Ying Nian Wu"
    ],
    "abstract": "Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL2025 Main Conference. Data and models are available:\n  https://mate-chess.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.06655v2",
    "published_date": "2024-11-11 01:42:56 UTC",
    "updated_date": "2025-02-28 11:58:28 UTC"
  },
  {
    "arxiv_id": "2411.06646v1",
    "title": "Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data",
    "authors": [
      "Alex Havrilla",
      "Wenjing Liao"
    ],
    "abstract": "When training deep neural networks, a model's generalization error is often\nobserved to follow a power scaling law dependent both on the model size and the\ndata size. Perhaps the best known example of such scaling laws are for\ntransformer-based large language models, where networks with billions of\nparameters are trained on trillions of tokens of text. Yet, despite sustained\nwidespread interest, a rigorous understanding of why transformer scaling laws\nexist is still missing. To answer this question, we establish novel statistical\nestimation and mathematical approximation theories for transformers when the\ninput data are concentrated on a low-dimensional manifold. Our theory predicts\na power law between the generalization error and both the training data size\nand the network size for transformers, where the power depends on the intrinsic\ndimension $d$ of the training data. Notably, the constructed model architecture\nis shallow, requiring only logarithmic depth in $d$. By leveraging\nlow-dimensional data structures under a manifold hypothesis, we are able to\nexplain transformer scaling laws in a way which respects the data geometry.\nMoreover, we test our theory with empirical observation by training LLMs on\nnatural language datasets. We find the observed empirical data scaling laws\nclosely agree with our theoretical predictions. Taken together, these results\nrigorously show the intrinsic dimension of data to be a crucial quantity\naffecting transformer scaling laws in both theory and practice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06646v1",
    "published_date": "2024-11-11 01:05:28 UTC",
    "updated_date": "2024-11-11 01:05:28 UTC"
  },
  {
    "arxiv_id": "2411.06639v1",
    "title": "Predicting Country Instability Using Bayesian Deep Learning and Random Forest",
    "authors": [
      "Adam Zebrowski",
      "Haithem Afli"
    ],
    "abstract": "Country instability is a global issue, with unpredictably high levels of\ninstability thwarting socio-economic growth and possibly causing a slew of\nnegative consequences. As a result, uncertainty prediction models for a country\nare becoming increasingly important in the real world, and they are expanding\nto provide more input from 'big data' collections, as well as the\ninterconnectedness of global economies and social networks. This has culminated\nin massive volumes of qualitative data from outlets like television, print,\ndigital, and social media, necessitating the use of artificial intelligence\n(AI) tools like machine learning to make sense of it all and promote predictive\nprecision [1]. The Global Database of Activities, Voice, and Tone (GDELT\nProject) records broadcast, print, and web news in over 100 languages every\nsecond of every day, identifying the people, locations, organisations, counts,\nthemes, outlets, and events that propel our global community and offering a\nfree open platform for computation on the entire world. The main goal of our\nresearch is to investigate how, when our data grows more voluminous and\nfine-grained, we can conduct a more complex methodological analysis of\npolitical conflict. The GDELT dataset, which was released in 2012, is the first\nand potentially the most technologically sophisticated publicly accessible\ndataset on political conflict.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06639v1",
    "published_date": "2024-11-11 00:23:03 UTC",
    "updated_date": "2024-11-11 00:23:03 UTC"
  }
]