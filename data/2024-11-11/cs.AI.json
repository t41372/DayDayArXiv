{
  "date": "2024-11-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-11 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 更新聚焦于 AI 和机器学习领域的创新，特别是大型语言模型 (LLMs) 的优化、知识蒸馏和应用扩展，同时涉及图像生成、强化学习和医学图像处理等主题；亮点包括 ICLR 2025 论文如 \"Controllable Context Sensitivity and the Knob Behind It\"，以及知名学者如 Ryan Cotterell 和 Frank Hutter 的贡献，这些工作展示了 LLM 在上下文控制和机器学习工作流构建中的潜力。\n\n下面，我们挑选并讨论一些重要、令人印象深刻的论文，先从 LLM 和 AI 相关主题入手，再聊图像生成和强化学习领域，其他次要论文则快速掠过，仅简要概述其主要贡献。\n\n**LLM 和 AI 优化主题：**  \n这些论文探讨了 LLM 的高效训练、知识转移和应用，相关工作显示了在资源有限场景下的实用性提升。  \n- **Controllable Context Sensitivity and the Knob Behind It (可控上下文敏感性和背后的调节机制)**: 作者包括 Ryan Cotterell，这篇 ICLR 2025 论文的主要贡献是识别一个 1-D 子空间来控制 LLM 对上下文和先验知识的依赖，实现 85-95% 的准确率，提高了 LLM 在检索增强生成等任务中的性能。  \n- **Large Language Models for Constructing and Optimizing Machine Learning Workflows (用于构建和优化机器学习工作流的LLM)**: 该论文强调 LLM 在数据工程和模型选择的潜力，贡献包括一个全面框架来自动化 ML 管道，提升效率并讨论了挑战，如语言理解和推理的应用。  \n- **The Surprising Effectiveness of Test-Time Training for Few-Shot Learning (少样本学习的测试时训练惊人效果)**: 主要发现是测试时训练能让 LLM 在抽象推理任务中提升 6 倍准确率，如 ARC 数据集上达到 61.9%，证明了其在资源有限场景下的鲁棒性。  \n- **UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts (UTMath: 通过推理到编码思想的单元测试数学评估)**: 贡献包括一个新基准数据集和 RCoT 方法，提升了 LLM 在数学推理的性能，o1-mini 模型仅解决 32.57% 问题，但展示了可扩展性。  \n- **Stronger Models are NOT Stronger Teachers for Instruction Tuning (更强的模型不是更好的教师用于指令微调)**: 论文挑战了传统假设，提出一个新指标 Compatibility-Adjusted Reward，显著提升了 LLM 指令微调的效率和性能。  \n其他如 **LLM-NEO: Parameter Efficient Knowledge Distillation for Large Language Models (LLM-NEO: 参数高效的 LLM 知识蒸馏)**，则快速提到其通过 LoRA 集成实现了高效知识转移，减少了训练成本。\n\n**图像生成和计算机视觉主题：**  \n这些工作突出了生成模型在细节保留和实际应用中的进步。  \n- **OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision (OmniEdit: 通过专家监督构建图像编辑通用模型)**: 主要贡献是处理七种编辑任务的框架，使用重要采样提升数据质量，实现了高编辑成功率，并在基准上超越基线。  \n- **Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models (Add-it: 使用预训练扩散模型的无训练对象插入)**: 论文提出一个加权注意力机制，实现无训练对象插入，显著提高了图像编辑的精确性和自然性。  \n其他图像相关论文，如 **Edify 3D: Scalable High-Quality 3D Asset Generation (Edify 3D: 可扩展的高质量 3D 资产生成)**，则简要指出其在 2 分钟内生成高质量 3D 资产的贡献。\n\n**强化学习和决策主题：**  \n这些论文展示了在复杂环境中的智能决策能力。  \n- **Grounding Video Models to Actions through Goal Conditioned Exploration (通过目标条件探索将视频模型接地到动作)**: 贡献包括一个框架，使代理在无监督下解决复杂任务，如 Libero 和 MetaWorld 基准上超越行为克隆基线。  \n- **Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing (多代理长时长四足推动的运动操纵学习)**: 主要发现是分层强化学习框架，提高了四足机器人协作推动任务的成功率和效率。\n\n其他论文主题多样，如医学和量子计算，但多为次要贡献，我们快速掠过：  \n- **Data-Driven Analysis of AI in Medical Device Software in China (基于数据驱动的中国医疗设备软件中的 AI 分析)**: 使用自动化提取方法分析 AI 医疗设备，贡献包括识别呼吸等领域的主导应用。  \n- **Federated Learning Client Pruning for Noisy Labels (联邦学习中针对噪声标签的客户端修剪)**: 提出 ClipFL 框架，提升了联邦学习在噪声数据下的性能。  \n其余如生态建模或理论分析论文（如量子机器学习），则因影响力较小，仅提及其在特定领域的发现，例如 **NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics (NatureLM-audio: 用于生物声学的音频-语言基础模型)** 在生物声学任务上设定了新标准。\n\n总之，今天的更新突出了 AI 领域的实用创新，LLM 相关工作尤其值得关注，期待后续应用！",
  "papers": [
    {
      "arxiv_id": "2411.07441v1",
      "title": "Automatically Detecting Online Deceptive Patterns in Real-time",
      "title_zh": "实时自动检测在线欺骗模式",
      "authors": [
        "Asmit Nayak",
        "Shirley Zhang",
        "Yash Wani",
        "Rishabh Khandelwal",
        "Kassem Fawaz"
      ],
      "abstract": "Deceptive patterns (DPs) in digital interfaces manipulate users into making\nunintended decisions, exploiting cognitive biases and psychological\nvulnerabilities. These patterns have become ubiquitous across various digital\nplatforms. While efforts to mitigate DPs have emerged from legal and technical\nperspectives, a significant gap in usable solutions that empower users to\nidentify and make informed decisions about DPs in real-time remains. In this\nwork, we introduce AutoBot, an automated, deceptive pattern detector that\nanalyzes websites' visual appearances using machine learning techniques to\nidentify and notify users of DPs in real-time. AutoBot employs a two-staged\npipeline that processes website screenshots, identifying interactable elements\nand extracting textual features without relying on HTML structure. By\nleveraging a custom language model, AutoBot understands the context surrounding\nthese elements to determine the presence of deceptive patterns. We implement\nAutoBot as a lightweight Chrome browser extension that performs all analyses\nlocally, minimizing latency and preserving user privacy. Through extensive\nevaluation, we demonstrate AutoBot's effectiveness in enhancing users' ability\nto navigate digital environments safely while providing a valuable tool for\nregulators to assess and enforce compliance with DP regulations.",
      "tldr_zh": "该研究针对数字界面中的欺骗模式（Deceptive Patterns, DPs）问题，提出了一种实时检测工具AutoBot，以帮助用户识别这些操纵决策的模式。AutoBot采用两阶段机器学习管道，分析网站截图来提取可交互元素和文本特征，并利用自定义语言模型理解上下文，从而在不依赖HTML结构的情况下检测DPs。实验结果显示，该工具作为轻量级Chrome浏览器扩展，能有效提升用户的安全导航能力，并为监管者提供评估和执法的实用手段。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07441v1",
      "published_date": "2024-11-11 23:49:02 UTC",
      "updated_date": "2024-11-11 23:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:17:11.631851"
    },
    {
      "arxiv_id": "2411.07426v1",
      "title": "Evaluating Detection Thresholds: The Impact of False Positives and Negatives on Super-Resolution Ultrasound Localization Microscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Sepideh K. Gharamaleki",
        "Brandon Helfield",
        "Hassan Rivaz"
      ],
      "abstract": "Super-resolution ultrasound imaging with ultrasound localization microscopy\n(ULM) offers a high-resolution view of microvascular structures. Yet, ULM image\nquality heavily relies on precise microbubble (MB) detection. Despite the\ncrucial role of localization algorithms, there has been limited focus on the\npractical pitfalls in MB detection tasks such as setting the detection\nthreshold. This study examines how False Positives (FPs) and False Negatives\n(FNs) affect ULM image quality by systematically adding controlled detection\nerrors to simulated data. Results indicate that while both FP and FN rates\nimpact Peak Signal-to-Noise Ratio (PSNR) similarly, increasing FP rates from\n0\\% to 20\\% decreases Structural Similarity Index (SSIM) by 7\\%, whereas same\nFN rates cause a greater drop of around 45\\%. Moreover, dense MB regions are\nmore resilient to detection errors, while sparse regions show high sensitivity,\nshowcasing the need for robust MB detection frameworks to enhance\nsuper-resolution imaging.",
      "tldr_zh": "本研究评估了假阳性(False Positives, FPs)和假阴性(False Negatives, FNs)对超分辨率超声定位显微镜(Super-Resolution Ultrasound Localization Microscopy, ULM)图像质量的影响，焦点在于微气泡(MB)检测阈值的实际挑战。  \n研究方法涉及在模拟数据中系统添加受控检测错误，分析这些错误对峰值信噪比(PSNR)和结构相似性指数(SSIM)的作用。  \n结果表明，FPs 率从0%到20%导致SSIM下降7%，而相同FN率会造成更大下降约45%；此外，密集MB区域对检测错误更耐受，而稀疏区域显示出高度敏感性。  \n这强调了开发更鲁棒的MB检测框架，以提升ULM的超分辨率成像质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07426v1",
      "published_date": "2024-11-11 22:58:56 UTC",
      "updated_date": "2024-11-11 22:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:17:25.727905"
    },
    {
      "arxiv_id": "2411.07425v1",
      "title": "Predicting BWR Criticality with Data-Driven Machine Learning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Rizki Oktavian",
        "Anirudh Tunga",
        "Jonathan Nistor",
        "James Tusar",
        "J. Thomas Gruenwald",
        "Yunlin Xu"
      ],
      "abstract": "One of the challenges in operating nuclear power plants is to decide the\namount of fuel needed in a cycle. Large-scale nuclear power plants are designed\nto operate at base load, meaning that they are expected to always operate at\nfull power. Economically, a nuclear power plant should burn enough fuel to\nmaintain criticality until the end of a cycle (EOC). If the reactor goes\nsubcritical before the end of a cycle, it may result in early coastdown as the\nfuel in the core is already depleted. On contrary, if the reactor still has\nsignificant excess reactivity by the end of a cycle, the remaining fuels will\nremain unused. In both cases, the plant may lose a significant amount of money.\nThis work proposes an innovative method based on a data-driven deep learning\nmodel to estimate the excess criticality of a boiling water reactor.",
      "tldr_zh": "本研究针对核电站运营中的关键挑战，即精确决定沸水反应堆（BWR）燃料量以维持循环结束时的临界性，避免提前耗尽燃料或浪费剩余燃料导致经济损失。论文提出了一种基于数据驱动的深度学习模型，用于估计 BWR 的过剩临界性。该方法通过机器学习技术创新性地预测反应堆临界状态，有助于优化燃料管理和提高核电站的经济性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07425v1",
      "published_date": "2024-11-11 22:57:11 UTC",
      "updated_date": "2024-11-11 22:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:17:35.973846"
    },
    {
      "arxiv_id": "2411.07404v2",
      "title": "Controllable Context Sensitivity and the Knob Behind It",
      "title_zh": "可控上下文敏感性及其背后的调节机制",
      "authors": [
        "Julian Minder",
        "Kevin Du",
        "Niklas Stoehr",
        "Giovanni Monea",
        "Chris Wendler",
        "Robert West",
        "Ryan Cotterell"
      ],
      "abstract": "When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.",
      "tldr_zh": "本研究探讨了语言模型在预测时如何平衡上下文和先验知识依赖，提出一个可控上下文敏感性任务：通过提供虚假上下文（如“Paris is in England”）和指令，评估模型是否能准确切换使用上下文或先验知识。实验显示，微调后的 Llama-3.1、Mistral-v0.3 和 Gemma-2 模型在该任务上达到85-95%的准确率，并通过线性时间算法识别出每个模型中一个关键层内的1-D subspace，作为控制上下文敏感性的“旋钮”。这一发现表明，该子空间在微调和未微调模型中均有效，且模型性能与子空间对上下文与先验知识的分离度高度相关，暗示了语言模型中一个简单机制控制这种行为。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.07404v2",
      "published_date": "2024-11-11 22:22:21 UTC",
      "updated_date": "2025-03-03 03:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:17:47.806855"
    },
    {
      "arxiv_id": "2411.07398v1",
      "title": "Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical Concern-related App Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Aakash Sorathiya",
        "Gouri Ginde"
      ],
      "abstract": "With the increasing proliferation of mobile applications in our everyday\nexperiences, the concerns surrounding ethics have surged significantly. Users\ngenerally communicate their feedback, report issues, and suggest new\nfunctionalities in application (app) reviews, frequently emphasizing safety,\nprivacy, and accountability concerns. Incorporating these reviews is essential\nto developing successful products. However, app reviews related to ethical\nconcerns generally use domain-specific language and are expressed using a more\nvaried vocabulary. Thus making automated ethical concern-related app review\nextraction a challenging and time-consuming effort.\n  This study proposes a novel Natural Language Processing (NLP) based approach\nthat combines Natural Language Inference (NLI), which provides a deep\ncomprehension of language nuances, and a decoder-only (LLaMA-like) Large\nLanguage Model (LLM) to extract ethical concern-related app reviews at scale.\nUtilizing 43,647 app reviews from the mental health domain, the proposed\nmethodology 1) Evaluates four NLI models to extract potential privacy reviews\nand compares the results of domain-specific privacy hypotheses with generic\nprivacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to\nprivacy concerns; and 3) Uses the best NLI and LLM models further to extract\nnew privacy reviews from the dataset. Results show that the\nDeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses\nyields the best performance, and Llama3.1-8B-Instruct LLM performs best in the\nclassification of app reviews. Then, using NLI+LLM, an additional 1,008 new\nprivacy-related reviews were extracted that were not identified through the\nkeyword-based approach in previous research, thus demonstrating the\neffectiveness of the proposed approach.",
      "tldr_zh": "本研究提出了一种基于语境的混合方法，用于挖掘与伦理问题相关的应用评论，该方法超越传统关键词搜索，结合 Natural Language Inference (NLI) 和 Large Language Model (LLM) 来处理用户反馈中安全、隐私和责任等方面的复杂语言。利用43,647条心理健康领域应用评论，研究评估了四个NLI模型（如DeBERTa-v3-base-mnli-fever-anli）和四个LLM（如Llama3.1-8B-Instruct），发现使用特定领域隐私假设的NLI模型表现最佳，并通过NLI+LLM组合提取了1,008条新隐私相关评论，比关键词方法更有效。总体结果证明，该方法能更准确地识别多样化词汇的伦理问题，提升了应用评论分析的效率和全面性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07398v1",
      "published_date": "2024-11-11 22:08:48 UTC",
      "updated_date": "2024-11-11 22:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:18:00.315147"
    },
    {
      "arxiv_id": "2411.07395v1",
      "title": "Data-Centric Learning Framework for Real-Time Detection of Aiming Beam in Fluorescence Lifetime Imaging Guided Surgery",
      "title_zh": "以数据为中心的学习框架，用于荧光寿命成像引导手术中",
      "authors": [
        "Mohamed Abul Hassan",
        "Pu Sun",
        "Xiangnan Zhou",
        "Lisanne Kraft",
        "Kelsey T Hadfield",
        "Katjana Ehrlich",
        "Jinyi Qi",
        "Andrew Birkeland",
        "Laura Marcu"
      ],
      "abstract": "This study introduces a novel data-centric approach to improve real-time\nsurgical guidance using fiber-based fluorescence lifetime imaging (FLIm). A key\naspect of the methodology is the accurate detection of the aiming beam, which\nis essential for localizing points used to map FLIm measurements onto the\ntissue region within the surgical field. The primary challenge arises from the\ncomplex and variable conditions encountered in the surgical environment,\nparticularly in Transoral Robotic Surgery (TORS). Uneven illumination in the\nsurgical field can cause reflections, reduce contrast, and results in\ninconsistent color representation, further complicating aiming beam detection.\nTo overcome these challenges, an instance segmentation model was developed\nusing a data-centric training strategy that improves accuracy by minimizing\nlabel noise and enhancing detection robustness. The model was evaluated on a\ndataset comprising 40 in vivo surgical videos, demonstrating a median detection\nrate of 85%. This performance was maintained when the model was integrated in a\nclinical system, achieving a similar detection rate of 85% during TORS\nprocedures conducted in patients. The system's computational efficiency,\nmeasured at approximately 24 frames per second (FPS), was sufficient for\nreal-time surgical guidance. This study enhances the reliability of FLIm-based\naiming beam detection in complex surgical environments, advancing the\nfeasibility of real-time, image-guided interventions for improved surgical\nprecision",
      "tldr_zh": "这篇论文提出了一种数据中心学习框架，用于实时检测荧光寿命成像 (FLIm) 引导手术中的瞄准光束 (aiming beam)，以提高手术精确性。针对手术环境中的挑战，如不均匀照明导致的反射和对比度降低，该框架采用实例 segmentation 模型，通过最小化标签噪声和增强检测鲁棒性的训练策略来优化性能。在包含 40 个 in vivo 手术视频的数据集上，该模型实现了 85% 的检测率，并在临床 Transoral Robotic Surgery (TORS) 程序中保持相同水平，同时支持约 24 FPS 的实时处理。该方法提升了 FLIm-based 手术引导的可靠性和可行性，促进了实时图像引导干预的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07395v1",
      "published_date": "2024-11-11 22:04:32 UTC",
      "updated_date": "2024-11-11 22:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:18:12.561626"
    },
    {
      "arxiv_id": "2411.10478v2",
      "title": "Large Language Models for Constructing and Optimizing Machine Learning Workflows: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Gu",
        "Hengyu You",
        "Jian Cao",
        "Muran Yu",
        "Haoran Fan",
        "Shiyou Qian"
      ],
      "abstract": "Building effective machine learning (ML) workflows to address complex tasks\nis a primary focus of the Automatic ML (AutoML) community and a critical step\ntoward achieving artificial general intelligence (AGI). Recently, the\nintegration of Large Language Models (LLMs) into ML workflows has shown great\npotential for automating and enhancing various stages of the ML pipeline. This\nsurvey provides a comprehensive and up-to-date review of recent advancements in\nusing LLMs to construct and optimize ML workflows, focusing on key components\nencompassing data and feature engineering, model selection and hyperparameter\noptimization, and workflow evaluation. We discuss both the advantages and\nlimitations of LLM-driven approaches, emphasizing their capacity to streamline\nand enhance ML workflow modeling process through language understanding,\nreasoning, interaction, and generation. Finally, we highlight open challenges\nand propose future research directions to advance the effective application of\nLLMs in ML workflows.",
      "tldr_zh": "这篇调查论文回顾了Large Language Models (LLMs) 在构建和优化Machine Learning (ML) 工作流中的最新进展，聚焦于AutoML 社区的核心目标。论文详细探讨了LLMs 如何通过语言理解、推理、交互和生成能力，增强ML 管道的各个阶段，包括数据和特征工程、模型选择与超参数优化，以及工作流评估。LLMs 驱动的方法优势在于自动化简化流程，但也存在局限性，如潜在的准确性问题。最终，论文指出了开放挑战并提出未来研究方向，以推动LLMs 在ML 工作流中的有效应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.10478v2",
      "published_date": "2024-11-11 21:54:26 UTC",
      "updated_date": "2024-12-25 16:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:18:23.483933"
    },
    {
      "arxiv_id": "2411.07392v1",
      "title": "Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoliang Wang",
        "Chen Zhao",
        "Feng Chen"
      ],
      "abstract": "Open-set domain generalization addresses a real-world challenge: training a\nmodel to generalize across unseen domains (domain generalization) while also\ndetecting samples from unknown classes not encountered during training\n(open-set recognition). However, most existing approaches tackle these issues\nseparately, limiting their practical applicability. To overcome this\nlimitation, we propose a unified framework for open-set domain generalization\nby introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic\nconsistency across different domains within the feature space, enabling more\naccurate detection of OOD instances in unseen domains. Additionally, we adopt a\ngenerative model to produce synthetic data with novel domain styles or class\nlabels, enhancing model robustness. Initial experiments show that our method\nimproves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly\nincreasing in-distribution classification accuracy.",
      "tldr_zh": "这篇论文针对开放集域泛化问题，提出了一种统一框架，通过引入 Feature-space Semantic Invariance (FSI) 在特征空间中保持不同域的语义一致性，从而提升 OOD (Out-of-Distribution) 实例的检测准确性。框架还结合生成模型产生合成数据，包括新域风格或类别标签，以增强模型的鲁棒性。实验结果显示，在 ColoredMNIST 数据集上，该方法将 AUROC 提高了 9.1% 到 18.9%，并显著提升了分布内分类准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE BigData 2024, Ph.D. Forum",
      "pdf_url": "http://arxiv.org/pdf/2411.07392v1",
      "published_date": "2024-11-11 21:51:45 UTC",
      "updated_date": "2024-11-11 21:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:18:36.499806"
    },
    {
      "arxiv_id": "2411.07391v1",
      "title": "Federated Learning Client Pruning for Noisy Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Morafah",
        "Hojin Chang",
        "Chen Chen",
        "Bill Lin"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across\ndecentralized edge devices while preserving data privacy. However, existing FL\nmethods often assume clean annotated datasets, impractical for\nresource-constrained edge devices. In reality, noisy labels are prevalent,\nposing significant challenges to FL performance. Prior approaches attempt label\ncorrection and robust training techniques but exhibit limited efficacy,\nparticularly under high noise levels. This paper introduces ClipFL (Federated\nLearning Client Pruning), a novel framework addressing noisy labels from a\nfresh perspective. ClipFL identifies and excludes noisy clients based on their\nperformance on a clean validation dataset, tracked using a Noise Candidacy\nScore (NCS). The framework comprises three phases: pre-client pruning to\nidentify potential noisy clients and calculate their NCS, client pruning to\nexclude a percentage of clients with the highest NCS, and post-client pruning\nfor fine-tuning the global model with standard FL on clean clients. Empirical\nevaluation demonstrates ClipFL's efficacy across diverse datasets and noise\nlevels, achieving accurate noisy client identification, superior performance,\nfaster convergence, and reduced communication costs compared to\nstate-of-the-art FL methods. Our code is available at\nhttps://github.com/MMorafah/ClipFL.",
      "tldr_zh": "本论文针对 Federated Learning (FL) 中噪声标签问题，提出了一种新框架 ClipFL，通过识别和排除噪声客户端来提升模型性能。ClipFL 利用 Noise Candidacy Score (NCS) 评估客户端的噪声程度，并分为三个阶段：预客户端剪枝（识别潜在噪声客户端并计算 NCS）、客户端剪枝（排除 NCS 最高的客户端），以及后客户端剪枝（在干净客户端上使用标准 FL 微调全局模型）。实验结果显示，ClipFL 在多种数据集和噪声水平下，实现了准确的噪声客户端识别、更优的性能、更快的收敛和更低的通信成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07391v1",
      "published_date": "2024-11-11 21:46:34 UTC",
      "updated_date": "2024-11-11 21:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:18:48.712603"
    },
    {
      "arxiv_id": "2411.07388v1",
      "title": "Firing Rate Models as Associative Memory: Excitatory-Inhibitory Balance for Robust Retrieval",
      "title_zh": "放电率模型作为联想记忆：兴奋-抑制平衡用于稳健检索",
      "authors": [
        "Simone Betteti",
        "Giacomo Baggio",
        "Francesco Bullo",
        "Sandro Zampieri"
      ],
      "abstract": "Firing rate models are dynamical systems widely used in applied and\ntheoretical neuroscience to describe local cortical dynamics in neuronal\npopulations. By providing a macroscopic perspective of neuronal activity, these\nmodels are essential for investigating oscillatory phenomena, chaotic behavior,\nand associative memory processes. Despite their widespread use, the application\nof firing rate models to associative memory networks has received limited\nmathematical exploration, and most existing studies are focused on specific\nmodels. Conversely, well-established associative memory designs, such as\nHopfield networks, lack key biologically-relevant features intrinsic to firing\nrate models, including positivity and interpretable synaptic matrices that\nreflect excitatory and inhibitory interactions. To address this gap, we propose\na general framework that ensures the emergence of re-scaled memory patterns as\nstable equilibria in the firing rate dynamics. Furthermore, we analyze the\nconditions under which the memories are locally and globally asymptotically\nstable, providing insights into constructing biologically-plausible and robust\nsystems for associative memory retrieval.",
      "tldr_zh": "该研究探讨了firing rate models在联想记忆(associative memory)中的应用，强调了兴奋-抑制平衡(Excitatory-Inhibitory Balance)对鲁棒检索的重要性，以填补现有模型的生物学相关特征缺失，如Hopfield networks的局限性。作者提出一个通用框架，确保记忆模式在firing rate dynamics中作为稳定平衡点出现，并分析了这些模式在局部和全局渐近稳定的条件。结果表明，该框架有助于构建生物学上合理的神经元网络系统，提升联想记忆的准确性和鲁棒性。",
      "categories": [
        "q-bio.NC",
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "math.DS",
        "37N25 (Primary) 34D45, 34D23 (Secondary)",
        "I.2.11; I.5.1"
      ],
      "primary_category": "q-bio.NC",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07388v1",
      "published_date": "2024-11-11 21:40:57 UTC",
      "updated_date": "2024-11-11 21:40:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:00.068855"
    },
    {
      "arxiv_id": "2411.07378v2",
      "title": "Data-Driven Analysis of AI in Medical Device Software in China: Deep Learning and General AI Trends Based on Regulatory Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Han",
        "Aaron Ceross",
        "Sarim Ather",
        "Jeroen H. M. Bergmann"
      ],
      "abstract": "Artificial intelligence (AI) in medical device software (MDSW) represents a\ntransformative clinical technology, attracting increasing attention within both\nthe medical community and the regulators. In this study, we leverage a\ndata-driven approach to automatically extract and analyze AI-enabled medical\ndevices (AIMD) from the National Medical Products Administration (NMPA)\nregulatory database. The continued increase in publicly available regulatory\ndata requires scalable methods for analysis. Automation of regulatory\ninformation screening is essential to create reproducible insights that can be\nquickly updated in an ever changing medical device landscape. More than 4\nmillion entries were assessed, identifying 2,174 MDSW registrations, including\n531 standalone applications and 1,643 integrated within medical devices, of\nwhich 43 were AI-enabled. It was shown that the leading medical specialties\nutilizing AIMD include respiratory (20.5%), ophthalmology/endocrinology\n(12.8%), and orthopedics (10.3%). This approach greatly improves the speed of\ndata extracting providing a greater ability to compare and contrast. This study\nprovides the first extensive, data-driven exploration of AIMD in China,\nshowcasing the potential of automated regulatory data analysis in understanding\nand advancing the landscape of AI in medical technology.",
      "tldr_zh": "该研究采用数据驱动方法，从中国国家药品监督管理局 (NMPA) 监管数据库中自动提取和分析 AI 启用医疗设备 (AIMD)，处理超过 400 万条目，识别出 2174 个医疗设备软件注册，其中 43 个为 AIMD。结果显示，AIMD 主要应用于呼吸 (20.5%)、眼科/内分泌 (12.8%) 和骨科 (10.3%) 等领域，突显了 Deep Learning 和 General AI 在医疗技术中的增长趋势。该方法显著提高了数据提取效率和分析可重复性，为理解中国 AI 医疗设备景观提供了首次广泛的数据驱动探索。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07378v2",
      "published_date": "2024-11-11 21:28:50 UTC",
      "updated_date": "2025-03-25 11:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:12.221738"
    },
    {
      "arxiv_id": "2411.07376v2",
      "title": "Ensemble Learning for Microbubble Localization in Super-Resolution Ultrasound",
      "title_zh": "翻译失败",
      "authors": [
        "Sepideh K. Gharamaleki",
        "Brandon Helfield",
        "Hassan Rivaz"
      ],
      "abstract": "Super-resolution ultrasound (SR-US) is a powerful imaging technique for\ncapturing microvasculature and blood flow at high spatial resolution. However,\naccurate microbubble (MB) localization remains a key challenge, as errors in\nlocalization can propagate through subsequent stages of the super-resolution\nprocess, affecting overall performance. In this paper, we explore the potential\nof ensemble learning techniques to enhance MB localization by increasing\ndetection sensitivity and reducing false positives. Our study evaluates the\neffectiveness of ensemble methods on both in vivo and simulated outputs of a\nDeformable DEtection TRansformer (Deformable DETR) network. As a result of our\nstudy, we are able to demonstrate the advantages of these ensemble approaches\nby showing improved precision and recall in MB detection and offering insights\ninto their application in SR-US.",
      "tldr_zh": "本文研究了超分辨率超声（SR-US）中微泡（MB）定位的准确性问题，该技术用于高分辨率捕获微血管和血流，但定位错误会影响整体性能。作者探索了集成学习（ensemble learning）技术，通过提高检测敏感性和减少假阳性来提升MB检测效果，并在vivo和模拟数据上评估了其在Deformable DETR网络输出中的应用。实验结果显示，该方法显著提高了MB检测的精确度和召回率，并为SR-US中的实际应用提供了宝贵见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07376v2",
      "published_date": "2024-11-11 21:26:36 UTC",
      "updated_date": "2025-01-03 03:55:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:23.669780"
    },
    {
      "arxiv_id": "2411.07340v1",
      "title": "Warmstarting for Scaling Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Neeratyoy Mallik",
        "Maciej Janowski",
        "Johannes Hog",
        "Herilalaina Rakotoarison",
        "Aaron Klein",
        "Josif Grabocka",
        "Frank Hutter"
      ],
      "abstract": "Scaling model sizes to scale performance has worked remarkably well for the\ncurrent large language models paradigm. The research and empirical findings of\nvarious scaling studies led to novel scaling results and laws that guides\nsubsequent research. High training costs for contemporary scales of data and\nmodels result in a lack of thorough understanding of how to tune and arrive at\nsuch training setups. One direction to ameliorate the cost of pretraining large\nmodels is to warmstart the large-scale training from smaller models that are\ncheaper to tune. In this work, we attempt to understand if the behavior of\noptimal hyperparameters can be retained under warmstarting for scaling. We\nexplore simple operations that allow the application of theoretically motivated\nmethods of zero-shot transfer of optimal hyperparameters using {\\mu}Transfer.\nWe investigate the aspects that contribute to the speedup in convergence and\nthe preservation of stable training dynamics under warmstarting with\n{\\mu}Transfer. We find that shrinking smaller model weights, zero-padding, and\nperturbing the resulting larger model with scaled initialization from {\\mu}P\nenables effective warmstarting of $\\mut{}$.",
      "tldr_zh": "本研究探讨了 warmstarting 技术，用于降低大规模语言模型训练成本，通过从较小模型开始逐步扩展到更大模型。研究者采用 {\\mu}Transfer 方法实现零-shot 转移最优超参数，并探索操作如缩小模型权重、零填充和扰动，以加速收敛并维持稳定训练动态。实验结果表明，这种 warmstarting 策略能有效保留训练行为，并显著提升效率，为缩放语言模型提供实用指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07340v1",
      "published_date": "2024-11-11 20:02:29 UTC",
      "updated_date": "2024-11-11 20:02:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:36.357851"
    },
    {
      "arxiv_id": "2411.07335v2",
      "title": "Multimodal Fusion Balancing Through Game-Theoretic Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Kontras",
        "Thomas Strypsteen",
        "Christos Chatzichristos",
        "Paul Pu Liang",
        "Matthew Blaschko",
        "Maarten De Vos"
      ],
      "abstract": "Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.",
      "tldr_zh": "本研究针对多模态学习中模态竞争问题，提出 Multimodal Competition Regularizer (MCR)，这是一个基于 game-theoretic regularization 的损失组件，旨在通过互信息 (MI) 分解自动平衡模态间的训练资源。关键贡献包括引入游戏理论原则让每个模态作为玩家竞争以优化 MI 术语、改进 MI 术语的上下界以提取任务相关信息，以及使用潜在空间置换提升条件 MI 估计的计算效率。实验结果表明，MCR 超越所有先前策略，在合成和真实世界数据集上首次实现多模态学习性能超过集成基线，证明了模态融合的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GT",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 6 figures, 4 tables, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2411.07335v2",
      "published_date": "2024-11-11 19:53:05 UTC",
      "updated_date": "2024-12-07 16:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:48.251089"
    },
    {
      "arxiv_id": "2411.07320v2",
      "title": "Richer Output for Richer Countries: Uncovering Geographical Disparities in Generated Stories and Travel Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Kirti Bhagat",
        "Kinshuk Vasisht",
        "Danish Pruthi"
      ],
      "abstract": "While a large body of work inspects language models for biases concerning\ngender, race, occupation and religion, biases of geographical nature are\nrelatively less explored. Some recent studies benchmark the degree to which\nlarge language models encode geospatial knowledge. However, the impact of the\nencoded geographical knowledge (or lack thereof) on real-world applications has\nnot been documented. In this work, we examine large language models for two\ncommon scenarios that require geographical knowledge: (a) travel\nrecommendations and (b) geo-anchored story generation. Specifically, we study\nfive popular language models, and across about $100$K travel requests, and\n$200$K story generations, we observe that travel recommendations corresponding\nto poorer countries are less unique with fewer location references, and stories\nfrom these regions more often convey emotions of hardship and sadness compared\nto those from wealthier nations.",
      "tldr_zh": "这项研究揭示了大型语言模型（LLMs）中存在的地理偏见，通过分析约10万条旅行推荐和20万条故事生成，评估模型在处理不同国家时的表现。结果显示，对于较贫穷国家的旅行推荐，输出内容较不独特且位置引用较少，而这些地区的故事生成更常表达hardship和sadness等负面情绪，与富裕国家形成鲜明对比。该发现突显了LLMs中编码的地理知识不足，可能加剧现实世界的地理不平等，并呼吁进一步优化模型以减少此类偏差。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of NAACL (2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.07320v2",
      "published_date": "2024-11-11 19:25:25 UTC",
      "updated_date": "2025-02-18 08:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:19:59.309819"
    },
    {
      "arxiv_id": "2411.07315v2",
      "title": "Harnessing Smartphone Sensors for Enhanced Road Safety: A Comprehensive Dataset and Review",
      "title_zh": "利用智能手机传感器提升道路安全：一个全面数据集和综述",
      "authors": [
        "Amith Khandakar",
        "David G. Michelson",
        "Mansura Naznine",
        "Abdus Salam",
        "Md. Nahiduzzaman",
        "Khaled M. Khan",
        "Ponnuthurai Nagaratnam Suganthan",
        "Mohamed Arselene Ayari",
        "Hamid Menouar",
        "Julfikar Haider"
      ],
      "abstract": "Severe collisions can result from aggressive driving and poor road\nconditions, emphasizing the need for effective monitoring to ensure safety.\nSmartphones, with their array of built-in sensors, offer a practical and\naffordable solution for road-sensing. However, the lack of reliable,\nstandardized datasets has hindered progress in assessing road conditions and\ndriving patterns. This study addresses this gap by introducing a comprehensive\ndataset derived from smartphone sensors, which surpasses existing datasets by\nincorporating a diverse range of sensors including accelerometer, gyroscope,\nmagnetometer, GPS, gravity, orientation, and uncalibrated sensors. These\nsensors capture extensive parameters such as acceleration force, gravitation,\nrotation rate, magnetic field strength, and vehicle speed, providing a detailed\nunderstanding of road conditions and driving behaviors. The dataset is designed\nto enhance road safety, infrastructure maintenance, traffic management, and\nurban planning. By making this dataset available to the community, the study\naims to foster collaboration, inspire further research, and facilitate the\ndevelopment of innovative solutions in intelligent transportation systems.",
      "tldr_zh": "本研究强调了 aggressive driving 和 poor road conditions 导致的严重碰撞风险，并提出利用智能手机内置传感器作为经济有效的路况监测解决方案，以填补可靠标准化数据集的缺失。研究贡献了一个全面数据集，涵盖 accelerometer, gyroscope, magnetometer, GPS, gravity, orientation 和 uncalibrated sensors 等传感器，捕获 acceleration force, gravitation, rotation rate, magnetic field strength 和 vehicle speed 等参数，以深入分析路况和驾驶行为。该数据集旨在提升 road safety, infrastructure maintenance, traffic management 和 urban planning 等领域，并通过公开分享促进研究协作和智能交通系统的创新发展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "29 pages, 14 Figures, journal paper, submitted into Scientific Data\n  Journal",
      "pdf_url": "http://arxiv.org/pdf/2411.07315v2",
      "published_date": "2024-11-11 19:15:29 UTC",
      "updated_date": "2024-11-13 17:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:20:11.994387"
    },
    {
      "arxiv_id": "2411.07308v1",
      "title": "X-DFS: Explainable Artificial Intelligence Guided Design-for-Security Solution Space Exploration",
      "title_zh": "X-",
      "authors": [
        "Tanzim Mahfuz",
        "Swarup Bhunia",
        "Prabuddha Chakraborty"
      ],
      "abstract": "Design and manufacturing of integrated circuits predominantly use a globally\ndistributed semiconductor supply chain involving diverse entities. The modern\nsemiconductor supply chain has been designed to boost production efficiency,\nbut is filled with major security concerns such as malicious modifications\n(hardware Trojans), reverse engineering (RE), and cloning. While being\ndeployed, digital systems are also subject to a plethora of threats such as\npower, timing, and electromagnetic (EM) side channel attacks. Many\nDesign-for-Security (DFS) solutions have been proposed to deal with these\nvulnerabilities, and such solutions (DFS) relays on strategic modifications\n(e.g., logic locking, side channel resilient masking, and dummy logic\ninsertion) of the digital designs for ensuring a higher level of security.\nHowever, most of these DFS strategies lack robust formalism, are often not\nhuman-understandable, and require an extensive amount of human expert effort\nduring their development/use. All of these factors make it difficult to keep up\nwith the ever growing number of microelectronic vulnerabilities. In this work,\nwe propose X-DFS, an explainable Artificial Intelligence (AI) guided DFS\nsolution-space exploration approach that can dramatically cut down the\nmitigation strategy development/use time while enriching our understanding of\nthe vulnerability by providing human-understandable decision rationale. We\nimplement X-DFS and comprehensively evaluate it for reverse engineering threats\n(SAIL, SWEEP, and OMLA) and formalize a generalized mechanism for applying\nX-DFS to defend against other threats such as hardware Trojans, fault attacks,\nand side channel attacks for seamless future extensions.",
      "tldr_zh": "该论文针对半导体供应链的安全问题，如硬件 Trojans、reverse engineering (RE) 和侧信道攻击，提出了一种基于 Explainable Artificial Intelligence (AI) 的框架 X-DFS，用于探索 Design-for-Security (DFS) 解决方案空间。X-DFS 通过 AI 指导的解释性方法，显著减少了缓解策略的开发和使用时间，并提供人类可理解的决策理由，从而提升了对微电子漏洞的理解和响应效率。在实验中，X-DFS 在针对逆向工程威胁（如 SAIL, SWEEP 和 OMLA）的评估中表现出色，并为扩展到硬件 Trojans、故障攻击和侧信道攻击等其他威胁提供了通用机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07308v1",
      "published_date": "2024-11-11 19:04:29 UTC",
      "updated_date": "2024-11-11 19:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:20:25.026704"
    },
    {
      "arxiv_id": "2411.07300v1",
      "title": "Artificial Intelligence Ecosystem for Automating Self-Directed Teaching",
      "title_zh": "翻译失败",
      "authors": [
        "Tejas Satish Gotavade"
      ],
      "abstract": "This research introduces an innovative artificial intelligence-driven\neducational concept designed to optimize self-directed learning through\npersonalized course delivery and automated teaching assistance. The system\nleverages fine-tuned AI models to create an adaptive learning environment that\nencompasses customized roadmaps, automated presentation generation, and\nthree-dimensional modeling for complex concept visualization. By integrating\nreal-time virtual assistance for doubt resolution, the platform addresses the\nimmediate educational needs of learners while promoting autonomous learning\npractices. This study explores the psychological advantages of self-directed\nlearning and demonstrates how AI automation can enhance educational outcomes\nthrough personalized content delivery and interactive support mechanisms. The\nresearch contributes to the growing field of educational technology by\npresenting a comprehensive framework that combines automated content\ngeneration, visual learning aids, and intelligent tutoring to create an\nefficient, scalable solution for modern educational needs. Preliminary findings\nsuggest that this approach not only accommodates diverse learning styles but\nalso strengthens student engagement and knowledge retention through its\nemphasis on self-paced, independent learning methodologies.",
      "tldr_zh": "这篇论文提出了一种AI驱动的教育生态系统，旨在自动化自导学习（self-directed learning）过程，通过个性化课程交付和自动化教学辅助优化学习体验。该系统利用微调AI模型（fine-tuned AI models）生成定制学习路线图、自动化演示和三维建模，以可视化复杂概念，并提供实时虚拟辅助来解决学习疑问。研究探讨了自导学习的心理优势，并通过初步发现证明，这种方法能适应多样学习风格，提升学生参与度和知识保留，从而为教育技术领域提供一个高效、可扩展的综合框架。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 15 figures, 12 references and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.07300v1",
      "published_date": "2024-11-11 19:00:22 UTC",
      "updated_date": "2024-11-11 19:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:20:35.351018"
    },
    {
      "arxiv_id": "2411.07279v2",
      "title": "The Surprising Effectiveness of Test-Time Training for Few-Shot Learning",
      "title_zh": "测试时训练在少样本学习中的惊人有效性",
      "authors": [
        "Ekin Akyürek",
        "Mehul Damani",
        "Adam Zweiger",
        "Linlu Qiu",
        "Han Guo",
        "Jyothish Pari",
        "Yoon Kim",
        "Jacob Andreas"
      ],
      "abstract": "Language models (LMs) have shown impressive performance on tasks within their\ntraining distribution, but often struggle with structurally novel tasks even\nwhen given a small number of in-context task examples. We investigate the\neffectiveness of test-time training (TTT) -- temporarily updating model\nparameters during inference using a loss derived from input data -- as a\nmechanism for improving LMs' reasoning and few-shot learning capabilities. On\nthe Abstraction and Reasoning Corpus (ARC), performing TTT with in-context\nexamples yields up to $6\\times$ higher accuracy compared to fine-tuned\nbaselines -- reaching $53.0\\%$ on the public validation set with an\n8B-parameter LM and $61.9\\%$ when ensembled with program-synthesis methods,\nmatching average human performance. On BIG-Bench Hard (BBH), TTT on in-context\nexamples surpasses standard few-shot prompting in the $10$-shot setting by\n$7.3$ percentage points ($50.5\\%$ to $57.8\\%$). Our findings highlight the\nlimitations of in-context learning for novel tasks and demonstrate the\npotential of test-time training to enhance language model adaptability.",
      "tldr_zh": "本研究探讨了测试时训练（Test-Time Training, TTT）在少样本学习（Few-Shot Learning）中的惊人效果，通过在推理过程中使用输入数据导出的损失临时更新语言模型（LMs）参数，以提升其推理能力和对新颖任务的适应性。实验显示，在Abstraction and Reasoning Corpus (ARC)数据集上，TTT结合上下文示例使模型准确率比微调基线高出6倍，达到53.0%（8B参数LM），并在集成程序合成方法后达61.9%，接近人类平均表现；在BIG-Bench Hard (BBH)数据集的10-shot设置下，TTT比标准少样本提示提升7.3个百分点（50.5%至57.8%）。这些发现突出了上下文学习的局限性，并证明了TTT在增强语言模型适应性方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.07279v2",
      "published_date": "2024-11-11 18:59:45 UTC",
      "updated_date": "2025-03-25 03:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:20:48.023591"
    },
    {
      "arxiv_id": "2411.07240v2",
      "title": "UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Yang",
        "Qingping Yang",
        "Yingwei Ma",
        "Runtao Liu"
      ],
      "abstract": "The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and generality. This paper\nintroduces the UTMath Benchmark, a robust evaluation framework designed to\nassess LLMs through extensive unit tests, with a focus on both the accuracy and\ngenerality of model responses. It comprises 1,053 cutting-edge problems\nspanning nine mathematical domains, with an average of 68 test cases per\nproblem. UTMath is highly challenging, with the best-performing model, o1-mini,\nsolving only 32.57\\% of the problems, followed by o1-preview at 27.16\\%, and\nGPT-4o at 26.93\\%. Furthermore, we present the Reasoning-to-Coding of Thoughts\n(RCoT) approach, which encourages LLMs to engage in explicit reasoning prior to\ncode generation, thereby facilitating the production of more sophisticated\nsolutions and enhancing overall performance and efficiency. Additionally, we\nalso release the UTMath-Train training dataset (more than 70k samples), to\nsupport the community in further exploring mathematical reasoning. Our\nbenchmark can be accessed via the following link:\nhttps://github.com/UTMathGroup/UTMath",
      "tldr_zh": "本论文提出 UTMath 基准，这是一个用于评估大型语言模型 (LLMs) 数学推理能力的框架，通过广泛的单元测试来检验模型的准确性和一般性，以克服现有基准如 GSM8K 和 MATH 的局限性。UTMath 包含 1,053 个跨九个数学领域的难题，每个问题平均有 68 个测试案例，目前最强模型 o1-mini 仅解决 32.57%，突显其挑战性。论文还引入 Reasoning-to-Coding of Thoughts (RCoT) 方法，鼓励 LLMs 在生成代码前进行明确推理，从而提升解决方案的复杂性和整体性能。此外，作者发布了 UTMath-Train 数据集（超过 70k 样本），以支持社区进一步探索数学推理研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07240v2",
      "published_date": "2024-11-11 18:59:02 UTC",
      "updated_date": "2025-01-14 07:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:21:00.710285"
    },
    {
      "arxiv_id": "2411.07232v2",
      "title": "Add-it: Training-Free Object Insertion in Images With Pretrained Diffusion Models",
      "title_zh": "Add-it：基于预训练扩散模型的无需训练图像物体插入",
      "authors": [
        "Yoad Tewel",
        "Rinon Gal",
        "Dvir Samuel",
        "Yuval Atzmon",
        "Lior Wolf",
        "Gal Chechik"
      ],
      "abstract": "Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.",
      "tldr_zh": "本研究提出 Add-it，一种无需训练的图像对象插入方法，利用预训练 diffusion models，通过扩展注意力机制整合场景图像、文本提示和生成图像本身的信息，确保新对象在复杂场景中自然放置并保持结构一致性。该方法采用加权扩展-attention 机制，实现无缝整合，而无需任务特定微调。在基准测试中，Add-it 在真实和生成图像插入任务上达到最先进水平，包括新构建的 \"Additing Affordance Benchmark\"，并优于监督方法；在人类评估中，超过80%的案例更偏好该方法，并在各种自动化指标上表现出显著改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page is at https://research.nvidia.com/labs/par/addit/",
      "pdf_url": "http://arxiv.org/pdf/2411.07232v2",
      "published_date": "2024-11-11 18:50:09 UTC",
      "updated_date": "2024-11-12 07:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:21:11.459054"
    },
    {
      "arxiv_id": "2411.07228v2",
      "title": "ChemToolAgent: The Impact of Tools on Language Agents for Chemistry Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Botao Yu",
        "Frazier N. Baker",
        "Ziru Chen",
        "Garrett Herb",
        "Boyu Gou",
        "Daniel Adu-Ampratwum",
        "Xia Ning",
        "Huan Sun"
      ],
      "abstract": "To enhance large language models (LLMs) for chemistry problem solving,\nseveral LLM-based agents augmented with tools have been proposed, such as\nChemCrow and Coscientist. However, their evaluations are narrow in scope,\nleaving a large gap in understanding the benefits of tools across diverse\nchemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced\nchemistry agent over ChemCrow, and conduct a comprehensive evaluation of its\nperformance on both specialized chemistry tasks and general chemistry\nquestions. Surprisingly, ChemToolAgent does not consistently outperform its\nbase LLMs without tools. Our error analysis with a chemistry expert suggests\nthat: For specialized chemistry tasks, such as synthesis prediction, we should\naugment agents with specialized tools; however, for general chemistry questions\nlike those in exams, agents' ability to reason correctly with chemistry\nknowledge matters more, and tool augmentation does not always help.",
      "tldr_zh": "本研究开发了ChemToolAgent，一种基于ChemCrow的增强化学代理，用于评估工具对LLMs在化学问题解决中的影响。研究通过全面测试，发现ChemToolAgent在专业化学任务（如合成预测）和一般化学问题（如考试题）上并不总是优于没有工具的基线LLMs。错误分析显示，对于专业任务，添加专用工具能显著提升性能，而对于一般问题，代理的正确推理能力更为重要。",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL 2025 Findings. Previous title: Tooling or Not\n  Tooling? The Impact of Tools on Language Agents for Chemistry Problem\n  Solving. Based on the camera ready version, this version adds more\n  experimental results",
      "pdf_url": "http://arxiv.org/pdf/2411.07228v2",
      "published_date": "2024-11-11 18:46:37 UTC",
      "updated_date": "2025-03-03 18:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:21:23.824643"
    },
    {
      "arxiv_id": "2411.07223v2",
      "title": "Grounding Video Models to Actions through Goal Conditioned Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhao Luo",
        "Yilun Du"
      ],
      "abstract": "Large video models, pretrained on massive amounts of Internet video, provide\na rich source of physical knowledge about the dynamics and motions of objects\nand tasks. However, video models are not grounded in the embodiment of an\nagent, and do not describe how to actuate the world to reach the visual states\ndepicted in a video. To tackle this problem, current methods use a separate\nvision-based inverse dynamic model trained on embodiment-specific data to map\nimage states to actions. Gathering data to train such a model is often\nexpensive and challenging, and this model is limited to visual settings similar\nto the ones in which data are available. In this paper, we investigate how to\ndirectly ground video models to continuous actions through self-exploration in\nthe embodied environment -- using generated video states as visual goals for\nexploration. We propose a framework that uses trajectory level action\ngeneration in combination with video guidance to enable an agent to solve\ncomplex tasks without any external supervision, e.g., rewards, action labels,\nor segmentation masks. We validate the proposed approach on 8 tasks in Libero,\n6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual\nNavigation. We show how our approach is on par with or even surpasses multiple\nbehavior cloning baselines trained on expert demonstrations while without\nrequiring any action annotations.",
      "tldr_zh": "本文提出一种框架，通过目标条件探索（Goal Conditioned Exploration）将大型视频模型直接接地到连续动作上，使用生成的视频状态作为视觉目标，让代理在环境中进行自我探索。不同于传统方法，该框架无需外部监督（如奖励、动作标签或分割掩码），即可生成轨迹级动作并解决复杂任务。在Libero（8任务）、MetaWorld（6任务）、Calvin（4任务）和iThor Visual Navigation（12任务）的基准测试中，该方法表现与或优于行为克隆基线，同时避免了收集动作标注的成本。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2025 (Spotlight). Project page:\n  https://video-to-action.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.07223v2",
      "published_date": "2024-11-11 18:43:44 UTC",
      "updated_date": "2025-03-12 17:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:21:36.226216"
    },
    {
      "arxiv_id": "2411.07218v1",
      "title": "TreeCoders: Trees of Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Colonna D'Istria",
        "Abdulrahman Altahhan"
      ],
      "abstract": "In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation.",
      "tldr_zh": "本研究提出 TreeCoders，一种新型的 Transformer 树家族，将传统线性 Transformer 替换为完整的 k-ary 树结构，其中 Transformer 块作为节点，通用分类器负责选择最佳子节点并路由 token 序列到特定叶节点。 该架构将选择器置于 Transformer 块之外，支持多种设计并实现稀疏节点激活，利用树搜索的对数复杂度提升效率。 在实验中，decoder-only 树 Transformer 在各种语言数据集上表现优于等大小的线性 Transformer，胜率达76%，并天然适合分布式实现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07218v1",
      "published_date": "2024-11-11 18:40:04 UTC",
      "updated_date": "2024-11-11 18:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:21:47.367552"
    },
    {
      "arxiv_id": "2411.07200v1",
      "title": "'Explaining RL Decisions with Trajectories': A Reproducibility Study",
      "title_zh": "使用轨迹解释强化学习决策：一个可重复性研究",
      "authors": [
        "Karim Abdel Sadek",
        "Matteo Nulli",
        "Joan Velja",
        "Jort Vincenti"
      ],
      "abstract": "This work investigates the reproducibility of the paper 'Explaining RL\ndecisions with trajectories'. The original paper introduces a novel approach in\nexplainable reinforcement learning based on the attribution decisions of an\nagent to specific clusters of trajectories encountered during training. We\nverify the main claims from the paper, which state that (i) training on less\ntrajectories induces a lower initial state value, (ii) trajectories in a\ncluster present similar high-level patterns, (iii) distant trajectories\ninfluence the decision of an agent, and (iv) humans correctly identify the\nattributed trajectories to the decision of the agent. We recover the\nenvironments used by the authors based on the partial original code they\nprovided for one of the environments (Grid-World), and implemented the\nremaining from scratch (Seaquest, HalfCheetah, Breakout and Q*Bert). While we\nconfirm that (i), (ii), and (iii) partially hold, we extend on the largely\nqualitative experiments from the authors by introducing a quantitative metric\nto further support (iii), and new experiments and visual results for (i).\nMoreover, we investigate the use of different clustering algorithms and encoder\narchitectures to further support (ii). We could not support (iv), given the\nlimited extent of the original experiments. We conclude that, while some of the\nclaims can be supported, further investigations and experiments could be of\ninterest. We recognise the novelty of the work from the authors and hope that\nour work paves the way for clearer and more transparent approaches.",
      "tldr_zh": "本研究对原论文“Explaining RL Decisions with Trajectories”进行了再现性研究，验证其在可解释强化学习（RL）中的新方法，即将代理决策归因于训练轨迹的特定聚类。研究者复现了多个环境（如Grid-World、Seaquest、HalfCheetah、Breakout和Q*Bert），并通过定量指标和新实验部分支持了原论文的声明：(i) 训练轨迹减少导致初始状态值降低，(ii) 聚类中轨迹显示相似的高级模式，以及(iii) 遥远轨迹影响代理决策，但未能验证(iv) 人类正确识别归因轨迹的声明。总体而言，该工作确认了部分声明的有效性，并建议进一步实验以提升RL解释方法的透明度和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07200v1",
      "published_date": "2024-11-11 18:24:27 UTC",
      "updated_date": "2024-11-11 18:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:22:00.457744"
    },
    {
      "arxiv_id": "2411.07199v2",
      "title": "OmniEdit: Building Image Editing Generalist Models Through Specialist Supervision",
      "title_zh": "OmniEdit：通过专家监督构建图像编辑通用模型",
      "authors": [
        "Cong Wei",
        "Zheyang Xiong",
        "Weiming Ren",
        "Xinrun Du",
        "Ge Zhang",
        "Wenhu Chen"
      ],
      "abstract": "Instruction-guided image editing methods have demonstrated significant\npotential by training diffusion models on automatically synthesized or manually\nannotated image editing pairs. However, these methods remain far from\npractical, real-life applications. We identify three primary challenges\ncontributing to this gap. Firstly, existing models have limited editing skills\ndue to the biased synthesis process. Secondly, these methods are trained with\ndatasets with a high volume of noise and artifacts. This is due to the\napplication of simple filtering methods like CLIP-score. Thirdly, all these\ndatasets are restricted to a single low resolution and fixed aspect ratio,\nlimiting the versatility to handle real-world use cases. In this paper, we\npresent \\omniedit, which is an omnipotent editor to handle seven different\nimage editing tasks with any aspect ratio seamlessly. Our contribution is in\nfour folds: (1) \\omniedit is trained by utilizing the supervision from seven\ndifferent specialist models to ensure task coverage. (2) we utilize importance\nsampling based on the scores provided by large multimodal models (like GPT-4o)\ninstead of CLIP-score to improve the data quality. (3) we propose a new editing\narchitecture called EditNet to greatly boost the editing success rate, (4) we\nprovide images with different aspect ratios to ensure that our model can handle\nany image in the wild. We have curated a test set containing images of\ndifferent aspect ratios, accompanied by diverse instructions to cover different\ntasks. Both automatic evaluation and human evaluations demonstrate that\n\\omniedit can significantly outperform all the existing models. Our code,\ndataset and model will be available at https://tiger-ai-lab.github.io/OmniEdit/",
      "tldr_zh": "这篇论文提出了OmniEdit，一种通用图像编辑模型，通过专业模型监督来处理七种不同编辑任务，支持任意长宽比，旨在解决现有方法的编辑技能有限、数据集噪声高以及分辨率限制等问题。OmniEdit的关键贡献包括：利用七个专业模型提供监督确保任务覆盖、采用基于GPT-4o的分数进行重要性采样提升数据质量、提出EditNet架构提高编辑成功率，以及提供不同比例的图像以适应真实场景。实验通过一个包含多样指令和比例的测试集进行评估，结果显示OmniEdit在自动和人工评估中显著优于基线模型，并公开了代码、数据集和模型资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.07199v2",
      "published_date": "2024-11-11 18:21:43 UTC",
      "updated_date": "2025-04-28 14:16:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:22:13.029591"
    },
    {
      "arxiv_id": "2411.07191v1",
      "title": "The Super Weight in Large Language Models",
      "title_zh": "大型语言模型中的超级权重",
      "authors": [
        "Mengxia Yu",
        "De Wang",
        "Qi Shan",
        "Colorado Reed",
        "Alvin Wan"
      ],
      "abstract": "Recent works have shown a surprising result: a small fraction of Large\nLanguage Model (LLM) parameter outliers are disproportionately important to the\nquality of the model. LLMs contain billions of parameters, so these small\nfractions, such as 0.01%, translate to hundreds of thousands of parameters. In\nthis work, we present an even more surprising finding: Pruning as few as a\nsingle parameter can destroy an LLM's ability to generate text -- increasing\nperplexity by 3 orders of magnitude and reducing zero-shot accuracy to\nguessing. We propose a data-free method for identifying such parameters, termed\nsuper weights, using a single forward pass through the model. We additionally\nfind that these super weights induce correspondingly rare and large activation\noutliers, termed super activations. When preserved with high precision, super\nactivations can improve simple round-to-nearest quantization to become\ncompetitive with state-of-the-art methods. For weight quantization, we\nsimilarly find that by preserving the super weight and clipping other weight\noutliers, round-to-nearest quantization can scale to much larger block sizes\nthan previously considered. To facilitate further research into super weights,\nwe provide an index of super weight coordinates for common, openly available\nLLMs.",
      "tldr_zh": "本研究发现，大语言模型 (LLM) 中的一小部分参数异常值（super weights）对模型性能至关重要，修剪单个 super weight 即可导致困惑度 (perplexity) 增加三个数量级，并使零样本准确率 (zero-shot accuracy) 降至随机水平。作者提出了一种无需数据的方法，仅通过单次前向传播识别这些 super weights，并观察到它们会引发对应的 super activations。实验结果显示，通过保留 super activations 和 super weights，可以显著提升简单量化技术（如 round-to-nearest），使其在更大块大小上与最先进方法竞争；此外，论文提供了常见开源 LLM 的 super weights 坐标索引，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07191v1",
      "published_date": "2024-11-11 18:05:48 UTC",
      "updated_date": "2024-11-11 18:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:22:24.868647"
    },
    {
      "arxiv_id": "2411.07186v1",
      "title": "NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics",
      "title_zh": "NatureLM-audio：一种用于生物声学的音频-语言基础模型",
      "authors": [
        "David Robinson",
        "Marius Miron",
        "Masato Hagiwara",
        "Olivier Pietquin"
      ],
      "abstract": "Large language models (LLMs) prompted with text and audio represent the state\nof the art in various auditory tasks, including speech, music, and general\naudio, showing emergent abilities on unseen tasks. However, these capabilities\nhave yet to be fully demonstrated in bioacoustics tasks, such as detecting\nanimal vocalizations in large recordings, classifying rare and endangered\nspecies, and labeling context and behavior - tasks that are crucial for\nconservation, biodiversity monitoring, and the study of animal behavior. In\nthis work, we present NatureLM-audio, the first audio-language foundation model\nspecifically designed for bioacoustics. Our carefully curated training dataset\ncomprises text-audio pairs spanning a diverse range of bioacoustics, speech,\nand music data, designed to address the challenges posed by limited annotated\ndatasets in the field. We demonstrate successful transfer of learned\nrepresentations from music and speech to bioacoustics, and our model shows\npromising generalization to unseen taxa and tasks. Importantly, we test\nNatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state of\nthe art (SotA) on several bioacoustics tasks, including zero-shot\nclassification of unseen species. To advance bioacoustics research, we also\nopen-source the code for generating training and benchmark data, as well as for\ntraining the model.",
      "tldr_zh": "本研究提出NatureLM-audio，这是第一个专门为生物声学设计的音频-语言基础模型（audio-language foundation model），旨在处理动物 vocalizations 检测、物种分类和行为标记等任务，支持生物多样性监测和保护。模型使用精心策划的文本-音频数据集，包括生物声学、语音和音乐数据，以克服标注数据有限的挑战，并成功转移从音乐和语音学到的表示到生物声学领域。实验结果显示，NatureLM-audio 在新的基准测试（BEANS-Zero）上实现了零-shot classification 的新状态-of-the-art（SotA）性能，并展示了良好的泛化能力。作者开源了代码，用于生成训练数据、基准数据和模型训练，以促进生物声学研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Demo page: https://earthspecies.github.io/naturelm-audio-demo/ The\n  code will be open-sourced and available shortly",
      "pdf_url": "http://arxiv.org/pdf/2411.07186v1",
      "published_date": "2024-11-11 18:01:45 UTC",
      "updated_date": "2024-11-11 18:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:22:36.820745"
    },
    {
      "arxiv_id": "2411.07185v1",
      "title": "Gradual Fine-Tuning with Graph Routing for Multi-Source Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Ma",
        "Samuel Louvan",
        "Zhunxuan Wang"
      ],
      "abstract": "Multi-source unsupervised domain adaptation aims to leverage labeled data\nfrom multiple source domains for training a machine learning model to\ngeneralize well on a target domain without labels. Source domain selection\nplays a crucial role in determining the model's performance. It relies on the\nsimilarities amongst source and target domains. Nonetheless, existing work for\nsource domain selection often involves heavyweight computational procedures,\nespecially when dealing with numerous source domains and the need to identify\nthe best ones from them. In this paper, we introduce a framework for gradual\nfine tuning (GFT) of machine learning models on multiple source domains. We\nrepresent multiple source domains as an undirected weighted graph. We then give\na new generalization error bound for GFT along any path within the graph, which\nis used to determine the optimal path corresponding to the optimal training\norder. With this formulation, we introduce three lightweight graph-routing\nstrategies which tend to minimize the error bound. Our best strategy improves\n$2.3\\%$ of accuracy over the state-of-the-art on Natural Language Inference\n(NLI) task and achieves competitive performance on Sentiment Analysis (SA)\ntask, especially a $3.9\\%$ improvement on a more diverse subset of data we use\nfor SA.",
      "tldr_zh": "这篇论文针对多源无监督域适应（Multi-Source Unsupervised Domain Adaptation）提出了一种渐进式微调（Gradual Fine-Tuning, GFT）框架，通过将多个源域表示为无向加权图，并基于新的泛化误差界限来确定最佳训练路径，从而优化源域选择过程。作者引入了三种轻量级图路由策略，以最小化误差界限，避免了传统方法的计算密集问题。在实验中，该框架在自然语言推理（NLI）任务上比最先进方法提高了2.3%的准确率，并在情感分析（SA）任务上实现了竞争性表现，尤其在更多样化的数据子集上提升了3.9%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 3rd Conference on Lifelong Learning Agents\n  (CoLLAs 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.07185v1",
      "published_date": "2024-11-11 17:59:21 UTC",
      "updated_date": "2024-11-11 17:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:22:48.830988"
    },
    {
      "arxiv_id": "2411.07180v5",
      "title": "Gumbel Counterfactual Generation From Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shauli Ravfogel",
        "Anej Svete",
        "Vésteinn Snæbjarnarson",
        "Ryan Cotterell"
      ],
      "abstract": "Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to\n\\emph{intervene} on these models. To understand the impact of interventions\nprecisely, it is useful to examine \\emph{counterfactuals} -- e.g., how a given\nsentence would have appeared had it been generated by the model following a\nspecific intervention. We highlight that counterfactual reasoning is\nconceptually distinct from interventions, as articulated in Pearl's causal\nhierarchy. Based on this observation, we propose a framework for generating\ntrue string counterfactuals by reformulating language models as a structural\nequation model using the Gumbel-max trick, which we called Gumbel\ncounterfactual generation. This reformulation allows us to model the joint\ndistribution over original strings and their counterfactuals resulting from the\nsame instantiation of the sampling noise. We develop an algorithm based on\nhindsight Gumbel sampling that allows us to infer the latent noise variables\nand generate counterfactuals of observed strings. Our experiments demonstrate\nthat the approach produces meaningful counterfactuals while at the same time\nshowing that commonly used intervention techniques have considerable undesired\nside effects.",
      "tldr_zh": "该论文探讨了理解和操纵语言模型因果生成机制的方法，强调反事实(counterfactuals)推理与干预的区别，如Pearl的因果层次所述。作者提出Gumbel counterfactual generation框架，将语言模型重构为结构方程模型(structural equation model)并使用Gumbel-max trick，允许建模原始字符串与其反事实的联合分布。实验结果显示，该框架通过hindsight Gumbel sampling算法生成有意义的反事实，同时揭示常用干预技术存在显著副作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.07180v5",
      "published_date": "2024-11-11 17:57:30 UTC",
      "updated_date": "2025-03-06 15:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:23:00.004995"
    },
    {
      "arxiv_id": "2411.07176v3",
      "title": "More Expressive Attention with Negative Weights",
      "title_zh": "翻译失败",
      "authors": [
        "Ang Lv",
        "Ruobing Xie",
        "Shuaipeng Li",
        "Jiayi Liao",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Di Wang",
        "Rui Yan"
      ],
      "abstract": "We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention enhances parameter flexibility. For example,\nunlike traditional softmax attention heads that use a static output-value (OV)\nmatrix to delete or copy inputs that the heads attend to, Cog Attention\nnaturally learns to use the sign of dynamic query-key (QK) inner products to\nrepresent these operations. This enables Cog Attention to perform multiple\noperations simultaneously within a single head. Meanwhile, Cog Attention's OV\nmatrix can focus more on refinement or modification. (2) Cog Attention enhances\nthe model's robustness against representational collapse by preventing the\n``over-squashing'' of earlier tokens into later positions. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models at various scales for language modeling and U-ViT diffusion\nmodels for image generation. Experiments show that models using Cog Attention\nexhibit superior performance compared to those employing traditional softmax\nattention modules. Our approach suggests a promising research direction for\nrethinking and breaking the entrenched constraints of traditional softmax\nattention, such as the requirement for non-negative weights.",
      "tldr_zh": "我们提出了一种名为 Cog Attention 的新型注意力机制，它允许注意力权重为负，从而提升模型的表达性和参数灵活性，例如通过动态 query-key (QK) 内积的符号在单个注意力头中同时执行删除、复制等操作，同时使 OV 矩阵更专注于细化。Cog Attention 还增强了模型的鲁棒性，防止“over-squashing”问题，即早期标记被过度压缩到后期位置。研究开发了基于 Cog Attention 的 Transformer-like 模型，包括用于语言建模的解码器模型和用于图像生成的 U-ViT 扩散模型。实验结果显示，这些模型在相关任务上比传统 softmax attention 模块表现出色，为重新审视注意力机制的非负权重限制提供了新研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07176v3",
      "published_date": "2024-11-11 17:56:28 UTC",
      "updated_date": "2025-01-30 18:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:23:12.676875"
    },
    {
      "arxiv_id": "2411.07171v1",
      "title": "Anytime Sequential Halving in Monte-Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Dominic Sagers",
        "Mark H. M. Winands",
        "Dennis J. N. J. Soemers"
      ],
      "abstract": "Monte-Carlo Tree Search (MCTS) typically uses multi-armed bandit (MAB)\nstrategies designed to minimize cumulative regret, such as UCB1, as its\nselection strategy. However, in the root node of the search tree, it is more\nsensible to minimize simple regret. Previous work has proposed using Sequential\nHalving as selection strategy in the root node, as, in theory, it performs\nbetter with respect to simple regret. However, Sequential Halving requires a\nbudget of iterations to be predetermined, which is often impractical. This\npaper proposes an anytime version of the algorithm, which can be halted at any\narbitrary time and still return a satisfactory result, while being designed\nsuch that it approximates the behavior of Sequential Halving. Empirical results\nin synthetic MAB problems and ten different board games demonstrate that the\nalgorithm's performance is competitive with Sequential Halving and UCB1 (and\ntheir analogues in MCTS).",
      "tldr_zh": "该研究针对 Monte-Carlo Tree Search (MCTS) 在根节点最小化简单 regret 的需求，提出了一种 Anytime Sequential Halving 算法，以解决传统 Sequential Halving 需要预先设定迭代预算的问题。该算法允许在任意时间点停止，同时近似模拟 Sequential Halving 的行为，确保返回满意的结果。在合成 multi-armed bandit (MAB) 问题和十种棋类游戏的实验中，该算法的表现与 Sequential Halving 和 UCB1 相当，展示了其竞争性优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Computers and Games 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2411.07171v1",
      "published_date": "2024-11-11 17:49:47 UTC",
      "updated_date": "2024-11-11 17:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:23:25.205675"
    },
    {
      "arxiv_id": "2411.07163v1",
      "title": "A Domain-Agnostic Neurosymbolic Approach for Big Social Data Analysis: Evaluating Mental Health Sentiment on Social Media during COVID-19",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Khandelwal",
        "Manas Gaur",
        "Ugur Kursuncu",
        "Valerie Shalin",
        "Amit Sheth"
      ],
      "abstract": "Monitoring public sentiment via social media is potentially helpful during\nhealth crises such as the COVID-19 pandemic. However, traditional\nfrequency-based, data-driven neural network-based approaches can miss newly\nrelevant content due to the evolving nature of language in a dynamically\nevolving environment. Human-curated symbolic knowledge sources, such as\nlexicons for standard language and slang terms, can potentially elevate social\nmedia signals in evolving language. We introduce a neurosymbolic method that\nintegrates neural networks with symbolic knowledge sources, enhancing the\ndetection and interpretation of mental health-related tweets relevant to\nCOVID-19. Our method was evaluated using a corpus of large datasets\n(approximately 12 billion tweets, 2.5 million subreddit data, and 700k news\narticles) and multiple knowledge graphs. This method dynamically adapts to\nevolving language, outperforming purely data-driven models with an F1 score\nexceeding 92\\%. This approach also showed faster adaptation to new data and\nlower computational demands than fine-tuning pre-trained large language models\n(LLMs). This study demonstrates the benefit of neurosymbolic methods in\ninterpreting text in a dynamic environment for tasks such as health\nsurveillance.",
      "tldr_zh": "该研究提出了一种通用的神经符号(neurosymbolic)方法，用于分析大数据，特别针对COVID-19期间社交媒体的心理健康情绪监测。该方法将神经网络与符号知识源（如词汇表和知识 graphs）整合，动态适应语言演变，从而提升对相关推文的检测和解释准确性。在使用约120亿推文、250万subreddit数据和70万新闻文章的庞大数据集进行评估时，该方法实现了超过92%的F1 score，并比纯数据驱动模型和微调LLMs更快适应新数据且计算需求更低。该方法证明了神经符号方法在动态环境下的文本解读优势，尤其适用于健康监控任务。",
      "categories": [
        "cs.AI",
        "I.2.4; I.2.6; I.2.7; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "13 Pages, 5 Figures, 5 Tables, 2024 IEEE International Conference on\n  Big Data, Regular Paper",
      "pdf_url": "http://arxiv.org/pdf/2411.07163v1",
      "published_date": "2024-11-11 17:41:54 UTC",
      "updated_date": "2024-11-11 17:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:23:37.001262"
    },
    {
      "arxiv_id": "2411.07161v1",
      "title": "RoundTable: Investigating Group Decision-Making Mechanism in Multi-Agent Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Young-Min Cho",
        "Raphael Shu",
        "Nilaksh Das",
        "Tamer Alkhouli",
        "Yi-An Lai",
        "Jason Cai",
        "Monica Sunkara",
        "Yi Zhang"
      ],
      "abstract": "This study investigates the efficacy of Multi-Agent Systems in eliciting\ncross-agent communication and enhancing collective intelligence through group\ndecision-making in a decentralized setting. Unlike centralized mechanisms,\nwhere a fixed hierarchy governs social choice, decentralized group\ndecision-making allows agents to engage in joint deliberation. Our research\nfocuses on the dynamics of communication and decision-making within various\nsocial choice methods. By applying different voting rules in various\nenvironments, we find that moderate decision flexibility yields better\noutcomes. Additionally, exploring the linguistic features of agent-to-agent\nconversations reveals indicators of effective collaboration, offering insights\ninto communication patterns that facilitate or hinder collaboration. Finally,\nwe propose various methods for determining the optimal stopping point in\nmulti-agent collaborations based on linguistic cues. Our findings contribute to\na deeper understanding of how decentralized decision-making and group\nconversation shape multi-agent collaboration, with implications for the design\nof more effective MAS environments.",
      "tldr_zh": "本研究探讨了多智能体系统（Multi-Agent Systems）在去中心化环境中通过群决策机制促进跨代理通信和集体智能的效能。与中心化机制不同，该机制允许代理进行联合审议。研究者通过应用不同投票规则（voting rules）于各种环境，分析通信动态和决策过程，发现适度决策灵活性可显著提升结果。进一步，分析代理间对话的语言特征，识别出有效协作的指标，并提出基于语言线索的方法来确定多智能体协作的最佳停止点。这些发现加深了对去中心化决策和群对话的理解，并为设计更有效的 MAS 环境提供重要启示。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.07161v1",
      "published_date": "2024-11-11 17:37:47 UTC",
      "updated_date": "2024-11-11 17:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:23:47.535095"
    },
    {
      "arxiv_id": "2411.07152v1",
      "title": "HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals",
      "title_zh": "翻译失败",
      "authors": [
        "Lingbo Mo",
        "Shun Jiang",
        "Akash Maharaj",
        "Bernard Hishamunda",
        "Yunyao Li"
      ],
      "abstract": "Task-Oriented Dialogue (TOD) systems assist users in completing tasks through\nnatural language interactions, often relying on a single-layered workflow\nstructure for slot-filling in public tasks, such as hotel bookings. However, in\nenterprise environments, which involve rich domain-specific knowledge, TOD\nsystems face challenges due to task complexity and the lack of standardized\ndocumentation. In this work, we introduce HierTOD, an enterprise TOD system\ndriven by hierarchical goals and can support composite workflows. By focusing\non goal-driven interactions, our system serves a more proactive role,\nfacilitating mixed-initiative dialogue and improving task completion. Equipped\nwith components for natural language understanding, composite goal retriever,\ndialogue management, and response generation, backed by a well-organized data\nservice with domain knowledge base and retrieval engine, HierTOD delivers\nefficient task assistance. Furthermore, our system implementation unifies two\nTOD paradigms: slot-filling for information collection and step-by-step\nguidance for task execution. Our human study demonstrates the effectiveness and\nhelpfulness of HierTOD in performing both paradigms.",
      "tldr_zh": "本论文提出了 HierTOD，一种基于分层目标驱动的任务导向对话系统（TOD），旨在解决企业环境中任务复杂性和知识文档缺乏的问题，支持复合工作流和主动混合对话。系统整合了自然语言理解、复合目标检索器、对话管理和响应生成等组件，并结合域知识库和检索引擎，统一了槽位填充（用于信息收集）和逐步指导（用于任务执行）的两种 TOD 范式。实验结果显示，HierTOD 在人类研究中表现出色，提高了任务完成效率和用户帮助性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07152v1",
      "published_date": "2024-11-11 17:28:19 UTC",
      "updated_date": "2024-11-11 17:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:24:00.363775"
    },
    {
      "arxiv_id": "2411.07150v1",
      "title": "Variational Graph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shifeng Xie",
        "Jhony H. Giraldo"
      ],
      "abstract": "Graph representation learning (GRL) is a fundamental task in machine\nlearning, aiming to encode high-dimensional graph-structured data into\nlow-dimensional vectors. Self-supervised learning (SSL) methods are widely used\nin GRL because they can avoid expensive human annotation. In this work, we\npropose a novel Subgraph Gaussian Embedding Contrast (SGEC) method. Our\napproach introduces a subgraph Gaussian embedding module, which adaptively maps\nsubgraphs to a structured Gaussian space, ensuring the preservation of graph\ncharacteristics while controlling the distribution of generated subgraphs. We\nemploy optimal transport distances, including Wasserstein and\nGromov-Wasserstein distances, to effectively measure the similarity between\nsubgraphs, enhancing the robustness of the contrastive learning process.\nExtensive experiments across multiple benchmarks demonstrate that SGEC\noutperforms or presents competitive performance against state-of-the-art\napproaches. Our findings provide insights into the design of SSL methods for\nGRL, emphasizing the importance of the distribution of the generated\ncontrastive pairs.",
      "tldr_zh": "本论文提出了一种名为 Subgraph Gaussian Embedding Contrast (SGEC) 的新方法，用于图表示学习 (Graph Representation Learning)，以自监督学习 (Self-Supervised Learning) 方式将高维图结构数据编码为低维向量。SGEC 通过子图高斯嵌入模块将子图自适应映射到结构化高斯空间，确保保留图特性并控制生成子图的分布，同时利用 Wasserstein 和 Gromov-Wasserstein 距离等最优传输距离来测量子图相似性，从而提升对比学习过程的鲁棒性。在多个基准测试中，SGEC 优于或与最先进方法相当，并为自监督学习在图表示学习中的设计提供见解，强调对比对分布的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07150v1",
      "published_date": "2024-11-11 17:23:07 UTC",
      "updated_date": "2024-11-11 17:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:24:12.127288"
    },
    {
      "arxiv_id": "2411.07135v1",
      "title": "Edify 3D: Scalable High-Quality 3D Asset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "NVIDIA",
        ":",
        "Maciej Bala",
        "Yin Cui",
        "Yifan Ding",
        "Yunhao Ge",
        "Zekun Hao",
        "Jon Hasselgren",
        "Jacob Huffman",
        "Jingyi Jin",
        "J. P. Lewis",
        "Zhaoshuo Li",
        "Chen-Hsuan Lin",
        "Yen-Chen Lin",
        "Tsung-Yi Lin",
        "Ming-Yu Liu",
        "Alice Luo",
        "Qianli Ma",
        "Jacob Munkberg",
        "Stella Shi",
        "Fangyin Wei",
        "Donglai Xiang",
        "Jiashu Xu",
        "Xiaohui Zeng",
        "Qinsheng Zhang"
      ],
      "abstract": "We introduce Edify 3D, an advanced solution designed for high-quality 3D\nasset generation. Our method first synthesizes RGB and surface normal images of\nthe described object at multiple viewpoints using a diffusion model. The\nmulti-view observations are then used to reconstruct the shape, texture, and\nPBR materials of the object. Our method can generate high-quality 3D assets\nwith detailed geometry, clean shape topologies, high-resolution textures, and\nmaterials within 2 minutes of runtime.",
      "tldr_zh": "本研究引入了 Edify 3D，这是一个可扩展的高质量 3D 资产生成解决方案。方法首先利用 diffusion model 合成描述对象的 RGB 和 surface normal 图像，从多个视角进行观察；随后基于这些多视角数据重建对象的形状、texture 和 PBR materials。该系统能在 2 分钟内生成具有详细 geometry、干净的形状 topologies、高分辨率 textures 和 materials 的 3D 资产，显著提升了生成效率和质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website: https://research.nvidia.com/labs/dir/edify-3d",
      "pdf_url": "http://arxiv.org/pdf/2411.07135v1",
      "published_date": "2024-11-11 17:07:43 UTC",
      "updated_date": "2024-11-11 17:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:24:25.839905"
    },
    {
      "arxiv_id": "2411.07133v3",
      "title": "Stronger Models are NOT Stronger Teachers for Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchen Xu",
        "Fengqing Jiang",
        "Luyao Niu",
        "Bill Yuchen Lin",
        "Radha Poovendran"
      ],
      "abstract": "Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines.",
      "tldr_zh": "本文挑战了指令微调（Instruction Tuning）中普遍的假设，即更大或更强的模型是更好的教师。通过对五种基模型和二十种响应生成器的广泛实验，发现更大模型并不总是更有效的教师，这一现象被称为 Larger Models' Paradox，因为现有指标忽略了教师和基模型之间的兼容性。为此，作者提出了一种新指标 Compatibility-Adjusted Reward (CAR)，用于评估响应生成器的有效性。实验结果显示，CAR 优于几乎所有基线模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This is paper is accepted at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.07133v3",
      "published_date": "2024-11-11 17:06:48 UTC",
      "updated_date": "2025-02-26 18:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:24:36.763908"
    },
    {
      "arxiv_id": "2411.07132v1",
      "title": "Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Taihang Hu",
        "Linxuan Li",
        "Joost van de Weijer",
        "Hongcheng Gao",
        "Fahad Shahbaz Khan",
        "Jian Yang",
        "Ming-Ming Cheng",
        "Kai Wang",
        "Yaxing Wang"
      ],
      "abstract": "Although text-to-image (T2I) models exhibit remarkable generation\ncapabilities, they frequently fail to accurately bind semantically related\nobjects or attributes in the input prompts; a challenge termed semantic\nbinding. Previous approaches either involve intensive fine-tuning of the entire\nT2I model or require users or large language models to specify generation\nlayouts, adding complexity. In this paper, we define semantic binding as the\ntask of associating a given object with its attribute, termed attribute\nbinding, or linking it to other related sub-objects, referred to as object\nbinding. We introduce a novel method called Token Merging (ToMe), which\nenhances semantic binding by aggregating relevant tokens into a single\ncomposite token. This ensures that the object, its attributes and sub-objects\nall share the same cross-attention map. Additionally, to address potential\nconfusion among main objects with complex textual prompts, we propose end token\nsubstitution as a complementary strategy. To further refine our approach in the\ninitial stages of T2I generation, where layouts are determined, we incorporate\ntwo auxiliary losses, an entropy loss and a semantic binding loss, to\niteratively update the composite token to improve the generation integrity. We\nconducted extensive experiments to validate the effectiveness of ToMe,\ncomparing it against various existing methods on the T2I-CompBench and our\nproposed GPT-4o object binding benchmark. Our method is particularly effective\nin complex scenarios that involve multiple objects and attributes, which\nprevious methods often fail to address. The code will be publicly available at\n\\url{https://github.com/hutaihang/ToMe}.",
      "tldr_zh": "本研究针对Text-to-Image (T2I) 合成中常见的语义绑定（semantic binding）问题，包括属性绑定（attribute binding）和对象绑定（object binding），提出了一种无需训练（training-free）的Token Merging (ToMe) 方法，通过聚合相关tokens成一个复合token，确保对象、属性和子对象共享相同的cross-attention map，从而提升生成准确性。ToMe 还结合end token substitution策略处理复杂提示中的对象混淆，并在生成初始阶段引入entropy loss和semantic binding loss来优化复合token。实验结果显示，该方法在T2I-CompBench和GPT-4o object binding benchmark上优于现有方法，尤其在涉及多个对象和属性的复杂场景中，显著提高了生成完整性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Neurips2024",
      "pdf_url": "http://arxiv.org/pdf/2411.07132v1",
      "published_date": "2024-11-11 17:05:15 UTC",
      "updated_date": "2024-11-11 17:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:24:49.631437"
    },
    {
      "arxiv_id": "2411.07123v1",
      "title": "Fast and Robust Contextual Node Representation Learning over Dynamic Graphs",
      "title_zh": "针对动态图的快速且鲁棒的上下文节点表示学习",
      "authors": [
        "Xingzhi Guo",
        "Silong Wang",
        "Baojian Zhou",
        "Yanghua Xiao",
        "Steven Skiena"
      ],
      "abstract": "Real-world graphs grow rapidly with edge and vertex insertions over time,\nmotivating the problem of efficiently maintaining robust node representation\nover evolving graphs. Recent efficient GNNs are designed to decouple recursive\nmessage passing from the learning process, and favor Personalized PageRank\n(PPR) as the underlying feature propagation mechanism. However, most PPR-based\nGNNs are designed for static graphs, and efficient PPR maintenance remains as\nan open problem. Further, there is surprisingly little theoretical\njustification for the choice of PPR, despite its impressive empirical\nperformance.\n  In this paper, we are inspired by the recent PPR formulation as an explicit\n$\\ell_1$-regularized optimization problem and propose a unified dynamic graph\nlearning framework based on sparse node-wise attention. We also present a set\nof desired properties to justify the choice of PPR in STOA GNNs, and serves as\nthe guideline for future node attention designs. Meanwhile, we take advantage\nof the PPR-equivalent optimization formulation and employ the proximal gradient\nmethod (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.\nFinally, we instantiate a simple-yet-effective model (\\textsc{GoPPE}) with\nrobust positional encodings by maximizing PPR previously used as attention. The\nmodel performs comparably to or better than the STOA baselines and greatly\noutperforms when the initial node attributes are noisy during graph evolution,\ndemonstrating the effectiveness and robustness of \\textsc{GoPPE}.",
      "tldr_zh": "这篇论文针对动态图上高效维护节点表示的问题，提出一个基于稀疏节点注意力的统一框架，利用Personalized PageRank (PPR)作为核心机制。作者将PPR表述为显式的ℓ1-正则化优化问题，并采用proximal gradient method (ISTA)来提高GNNs的效率，最多提升6倍。论文还提供了PPR选择的理论依据，作为未来节点注意力设计的指导。实验结果表明，所提出的GoPPE模型在动态图上与最先进基线相当或更优，尤其在初始节点属性有噪声时表现出更高的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07123v1",
      "published_date": "2024-11-11 16:51:51 UTC",
      "updated_date": "2024-11-11 16:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:25:02.139144"
    },
    {
      "arxiv_id": "2411.07104v4",
      "title": "Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing",
      "title_zh": "翻译失败",
      "authors": [
        "Yuming Feng",
        "Chuye Hong",
        "Yaru Niu",
        "Shiqi Liu",
        "Yuxiang Yang",
        "Wenhao Yu",
        "Tingnan Zhang",
        "Jie Tan",
        "Ding Zhao"
      ],
      "abstract": "Recently, quadrupedal locomotion has achieved significant success, but their\nmanipulation capabilities, particularly in handling large objects, remain\nlimited, restricting their usefulness in demanding real-world applications such\nas search and rescue, construction, industrial automation, and room\norganization. This paper tackles the task of obstacle-aware, long-horizon\npushing by multiple quadrupedal robots. We propose a hierarchical multi-agent\nreinforcement learning framework with three levels of control. The high-level\ncontroller integrates an RRT planner and a centralized adaptive policy to\ngenerate subgoals, while the mid-level controller uses a decentralized\ngoal-conditioned policy to guide the robots toward these sub-goals. A\npre-trained low-level locomotion policy executes the movement commands. We\nevaluate our method against several baselines in simulation, demonstrating\nsignificant improvements over baseline approaches, with 36.0% higher success\nrates and 24.5% reduction in completion time than the best baseline. Our\nframework successfully enables long-horizon, obstacle-aware manipulation tasks\nlike Push-Cuboid and Push-T on Go1 robots in the real world.",
      "tldr_zh": "该论文针对四足机器人（quadrupedal robots）在处理大物体时的操纵能力不足问题，提出了一种分层多智能体强化学习（multi-agent reinforcement learning）框架，用于实现长时段、障碍感知的推动任务。高层控制器整合 RRT 规划器和集中式自适应策略生成子目标，中层控制器使用分散式目标条件策略引导机器人移动，而底层控制器则依赖预训练的运动策略执行命令。在模拟实验中，该框架比基线方法成功率提高 36.0%，完成时间减少 24.5%；在现实世界中，它成功应用于 Go1 机器人上的任务，如 Push-Cuboid 和 Push-T。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07104v4",
      "published_date": "2024-11-11 16:27:25 UTC",
      "updated_date": "2025-03-29 04:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:25:14.512267"
    },
    {
      "arxiv_id": "2411.07099v2",
      "title": "Bounded Rationality Equilibrium Learning in Mean Field Games",
      "title_zh": "平均场博弈中的有限理性均衡学习",
      "authors": [
        "Yannick Eich",
        "Christian Fabian",
        "Kai Cui",
        "Heinz Koeppl"
      ],
      "abstract": "Mean field games (MFGs) tractably model behavior in large agent populations.\nThe literature on learning MFG equilibria typically focuses on finding Nash\nequilibria (NE), which assume perfectly rational agents and are hence\nimplausible in many realistic situations. To overcome these limitations, we\nincorporate bounded rationality into MFGs by leveraging the well-known concept\nof quantal response equilibria (QRE). Two novel types of MFG QRE enable the\nmodeling of large agent populations where individuals only noisily estimate the\ntrue objective. We also introduce a second source of bounded rationality to\nMFGs by restricting agents' planning horizon. The resulting novel receding\nhorizon (RH) MFGs are combined with QRE and existing approaches to model\ndifferent aspects of bounded rationality in MFGs. We formally define MFG QRE\nand RH MFGs and compare them to existing equilibrium concepts such as\nentropy-regularized NE. Subsequently, we design generalized fixed point\niteration and fictitious play algorithms to learn QRE and RH equilibria. After\na theoretical analysis, we give different examples to evaluate the capabilities\nof our learning algorithms and outline practical differences between the\nequilibrium concepts.",
      "tldr_zh": "这篇论文在Mean Field Games (MFGs)中引入bounded rationality，以解决传统Nash Equilibria (NE)假设代理完全理性的局限性。作者提出两种新型MFG Quantal Response Equilibria (QRE)，允许代理对目标进行噪声估计，并结合Receding Horizon (RH) MFGs来限制代理的规划地平线，从而更真实地建模大规模代理人群的行为。论文定义了MFG QRE和RH MFGs，并与现有概念如entropy-regularized NE进行比较，同时设计了generalized fixed point iteration和fictitious play算法来学习这些均衡。通过理论分析和示例评估，展示了这些新方法在处理bounded rationality方面的优势和实际差异。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.07099v2",
      "published_date": "2024-11-11 16:24:03 UTC",
      "updated_date": "2025-01-30 08:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:25:27.092733"
    },
    {
      "arxiv_id": "2411.07098v2",
      "title": "A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs",
      "title_zh": "一种基于语义图和 LLM 驱动输入的多智能体 REST API 测试方法",
      "authors": [
        "Myeongsoo Kim",
        "Tyler Stennett",
        "Saurabh Sinha",
        "Alessandro Orso"
      ],
      "abstract": "As modern web services increasingly rely on REST APIs, their thorough testing\nhas become crucial. Furthermore, the advent of REST API documentation\nlanguages, such as the OpenAPI Specification, has led to the emergence of many\nblack-box REST API testing tools. However, these tools often focus on\nindividual test elements in isolation (e.g., APIs, parameters, values),\nresulting in lower coverage and less effectiveness in fault detection. To\naddress these limitations, we present AutoRestTest, the first black-box tool to\nadopt a dependency-embedded multi-agent approach for REST API testing that\nintegrates multi-agent reinforcement learning (MARL) with a semantic property\ndependency graph (SPDG) and Large Language Models (LLMs). Our approach treats\nREST API testing as a separable problem, where four agents -- API, dependency,\nparameter, and value agents -- collaborate to optimize API exploration. LLMs\nhandle domain-specific value generation, the SPDG model simplifies the search\nspace for dependencies using a similarity score between API operations, and\nMARL dynamically optimizes the agents' behavior. Our evaluation of AutoRestTest\non 12 real-world REST services shows that it outperforms the four leading\nblack-box REST API testing tools, including those assisted by RESTGPT (which\ngenerates realistic test inputs using LLMs), in terms of code coverage,\noperation coverage, and fault detection. Notably, AutoRestTest is the only tool\nable to trigger an internal server error in the Spotify service. Our ablation\nstudy illustrates that each component of AutoRestTest -- the SPDG, the LLM, and\nthe agent-learning mechanism -- contributes to its overall effectiveness.",
      "tldr_zh": "该研究提出 AutoRestTest，一种创新的黑盒 REST API 测试工具，采用多智能体强化学习(MARL)、语义属性依赖图(SPDG)和大语言模型(LLMs)的整合方法，以解决现有工具在覆盖率和故障检测方面的局限性。AutoRestTest 包括四个协作智能体（API、依赖、参数和值智能体），其中 LLMs 用于生成领域特定输入，SPDG 通过 API 操作相似性分数简化依赖搜索空间，而 MARL 动态优化智能体行为。在 12 个真实世界 REST 服务上的评估中，AutoRestTest 优于领先工具，在代码覆盖率、操作覆盖率和故障检测方面表现出色，并是唯一能触发 Spotify 服务内部服务器错误的工具。消融研究证明了 SPDG、LLM 和智能体学习机制对整体效果的贡献。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To be published in the 47th IEEE/ACM International Conference on\n  Software Engineering (ICSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2411.07098v2",
      "published_date": "2024-11-11 16:20:27 UTC",
      "updated_date": "2025-01-22 04:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:25:40.455935"
    },
    {
      "arxiv_id": "2411.07089v1",
      "title": "Towards Characterizing Cyber Networks with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alaric Hartsock",
        "Luiz Manella Pereira",
        "Glenn Fink"
      ],
      "abstract": "Threat hunting analyzes large, noisy, high-dimensional data to find sparse\nadversarial behavior. We believe adversarial activities, however they are\ndisguised, are extremely difficult to completely obscure in high dimensional\nspace. In this paper, we employ these latent features of cyber data to find\nanomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEM\nwas trained on Zeek network traffic logs from both a real-world production\nnetwork and an from Internet of Things (IoT) cybersecurity testbed. The model\nis deliberately overtrained on a sliding window of data to characterize each\nwindow closely. We use the Adjusted Rand Index (ARI) to comparing the k-means\nclustering of CLEM output to expert labeling of the embeddings. Our approach\ndemonstrates that there is promise in using natural language modeling to\nunderstand cyber data.",
      "tldr_zh": "本研究探讨了使用大型语言模型（Large Language Models）来表征网络数据，以辅助威胁狩猎。论文提出了一种原型工具Cyber Log Embeddings Model (CLEM)，通过在Zeek网络流量日志上过度训练（基于滑动窗口），捕捉高维数据中的潜在异常特征。CLEM将模型输出与专家标记进行k-means聚类比较，使用Adjusted Rand Index (ARI)作为评估指标，结果显示该方法在真实世界生产网络和IoT安全测试床中有效识别敌对行为。总体而言，该工作证明了自然语言建模在理解网络数据方面的潜力，为未来网络安全分析提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07089v1",
      "published_date": "2024-11-11 16:09:13 UTC",
      "updated_date": "2024-11-11 16:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:25:49.480550"
    },
    {
      "arxiv_id": "2411.07087v4",
      "title": "OCMDP: Observation-Constrained Markov Decision Process",
      "title_zh": "OCMDP：观察约束的 Markov 决策过程",
      "authors": [
        "Taiyi Wang",
        "Jianheng Liu",
        "Bryan Lee",
        "Zhihao Wu",
        "Yu Wu"
      ],
      "abstract": "In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.",
      "tldr_zh": "本文提出Observation-Constrained Markov Decision Process (OCMDP)，一种用于处理观察成本高决策环境的框架，其中策略会影响状态的可观察性，以平衡信息获取成本和收益。作者开发了一个迭代的模型无关深度强化学习算法，将感知和控制组件分离，实现高效学习，包括何时、何物观察以及最佳控制动作，而无需环境动态知识。在模拟诊断任务和HeartPole医疗环境中，实验结果显示OCMDP显著降低了观察成本，比基线方法更高效。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Full paper, 14 Pages",
      "pdf_url": "http://arxiv.org/pdf/2411.07087v4",
      "published_date": "2024-11-11 16:04:49 UTC",
      "updated_date": "2025-01-23 18:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:26:00.548557"
    },
    {
      "arxiv_id": "2411.07086v1",
      "title": "To Train or Not to Train: Balancing Efficiency and Training Cost in Deep Reinforcement Learning for Mobile Edge Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Maddalena Boscaro",
        "Federico Mason",
        "Federico Chiariotti",
        "Andrea Zanella"
      ],
      "abstract": "Artificial Intelligence (AI) is a key component of 6G networks, as it enables\ncommunication and computing services to adapt to end users' requirements and\ndemand patterns. The management of Mobile Edge Computing (MEC) is a meaningful\nexample of AI application: computational resources available at the network\nedge need to be carefully allocated to users, whose jobs may have different\npriorities and latency requirements. The research community has developed\nseveral AI algorithms to perform this resource allocation, but it has neglected\na key aspect: learning is itself a computationally demanding task, and\nconsidering free training results in idealized conditions and performance in\nsimulations. In this work, we consider a more realistic case in which the cost\nof learning is specifically accounted for, presenting a new algorithm to\ndynamically select when to train a Deep Reinforcement Learning (DRL) agent that\nallocates resources. Our method is highly general, as it can be directly\napplied to any scenario involving a training overhead, and it can approach the\nsame performance as an ideal learning agent even under realistic training\nconditions.",
      "tldr_zh": "该论文探讨了在 Mobile Edge Computing (MEC) 中使用 Deep Reinforcement Learning (DRL) 进行资源分配时，如何平衡效率与训练成本的问题，强调现有 AI 算法忽略了训练过程的计算开销，导致模拟性能不切实际。作者提出了一种新算法，通过动态选择何时训练 DRL 代理，实现资源分配的优化。该方法高度通用，可应用于任何涉及训练开销的场景，并在现实条件下接近理想学习代理的性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07086v1",
      "published_date": "2024-11-11 16:02:12 UTC",
      "updated_date": "2024-11-11 16:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:26:12.341501"
    },
    {
      "arxiv_id": "2411.07076v2",
      "title": "StoryTeller: Improving Long Video Description through Global Audio-Visual Character Identification",
      "title_zh": "StoryTeller：通过全局音频-视觉人物识别改善长视频描述",
      "authors": [
        "Yichen He",
        "Yuan Lin",
        "Jianchao Wu",
        "Hanchong Zhang",
        "Yuchen Zhang",
        "Ruicheng Le"
      ],
      "abstract": "Existing large vision-language models (LVLMs) are largely limited to\nprocessing short, seconds-long videos and struggle with generating coherent\ndescriptions for extended video spanning minutes or more. Long video\ndescription introduces new challenges, such as consistent character\nidentification and plot-level descriptions incorporating both visual and audio\ninformation. To address these, we figure out audio-visual character\nidentification, matching character names to each dialogue, as a key factor. We\npropose StoryTeller, a system for generating dense descriptions of long videos,\nincorporating both low-level visual concepts and high-level plot information.\nStoryTeller uses a multimodal large language model that integrates visual,\naudio, and text modalities to perform audio-visual character identification on\nminute-long video clips. The results are then fed into a LVLM to enhance\nconsistency of video description. We validate our approach on movie description\ntasks and introduce MovieStory101, a dataset with dense descriptions for\nthree-minute movie clips. To evaluate long video descriptions, we create\nStoryQA, a large set of multiple-choice questions for MovieStory101 test set.\nWe assess descriptions by inputting them into GPT-4 to answer these questions,\nusing accuracy as an automatic evaluation metric. Experiments show that\nStoryTeller outperforms all open and closed-source baselines on StoryQA,\nachieving 9.5% higher accuracy than the strongest baseline, Gemini-1.5-pro, and\ndemonstrating a +15.56% advantage in human side-by-side evaluations.\nAdditionally, incorporating audio-visual character identification from\nStoryTeller improves the performance of all video description models, with\nGemini-1.5-pro and GPT-4o showing relative improvement of 5.5% and 13.0%,\nrespectively, in accuracy on StoryQA.",
      "tldr_zh": "本论文针对现有大型视觉语言模型（LVLMs）在处理长视频时的局限性（如生成连贯描述的挑战），提出StoryTeller系统，通过全局音频-视觉角色识别来提升长视频描述的质量。StoryTeller整合视觉、音频和文本模态的多模态大语言模型，对一分钟视频片段进行角色匹配和剧情级描述，确保描述的一致性和密集性。论文引入MovieStory101数据集（包含三分钟电影片段的密集描述）和StoryQA评估集（多选题形式），使用GPT-4回答问题并以准确率评估性能。实验结果显示，StoryTeller在StoryQA上比最强基线Gemini-1.5-pro高出9.5%准确率，并在人类评估中优势达15.56%；此外，该方法还提升了其他模型如Gemini-1.5-pro和GPT-4o的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07076v2",
      "published_date": "2024-11-11 15:51:48 UTC",
      "updated_date": "2025-03-06 09:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:26:26.951983"
    },
    {
      "arxiv_id": "2411.07072v2",
      "title": "An Interpretable X-ray Style Transfer via Trainable Local Laplacian Filter",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Eckert",
        "Ludwig Ritschl",
        "Christopher Syben",
        "Christian Hümmer",
        "Julia Wicklein",
        "Marcel Beister",
        "Steffen Kappler",
        "Sebastian Stober"
      ],
      "abstract": "Radiologists have preferred visual impressions or 'styles' of X-ray images\nthat are manually adjusted to their needs to support their diagnostic\nperformance. In this work, we propose an automatic and interpretable X-ray\nstyle transfer by introducing a trainable version of the Local Laplacian Filter\n(LLF). From the shape of the LLF's optimized remap function, the\ncharacteristics of the style transfer can be inferred and reliability of the\nalgorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray\nstyle features by replacing the remap function with a Multi-Layer Perceptron\n(MLP) and adding a trainable normalization layer. We demonstrate the\neffectiveness of the proposed method by transforming unprocessed mammographic\nX-ray images into images that match the style of target mammograms and achieve\na Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline\nLLF style transfer method from Aubry et al.",
      "tldr_zh": "本研究提出了一种可解释的 X-ray 图像风格转移方法，通过引入可训练的 Local Laplacian Filter (LLF)，以自动调整图像风格支持放射科医生的诊断性能。方法将 LLF 的 remap 函数替换为 Multi-Layer Perceptron (MLP)，并添加可训练的归一化层，从而捕捉复杂 X-ray 风格特征，并通过优化 remap 函数形状确保算法的可解释性和可靠性。在实验中，该方法将未处理的乳腺 X-ray 图像转换为目标风格图像，达到 Structural Similarity Index (SSIM) 0.94，比基线 LLF 方法（Aubry et al.）的 0.82 显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07072v2",
      "published_date": "2024-11-11 15:47:25 UTC",
      "updated_date": "2025-01-24 15:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:26:36.895306"
    },
    {
      "arxiv_id": "2411.07071v1",
      "title": "Universal Response and Emergence of Induction in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Niclas Luick"
      ],
      "abstract": "While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）中归纳（induction）行为的涌现及其机制，通过对 residual stream 的弱单 token 扰动进行探测来量化 token 相关性的积累。研究发现，LLMs 表现出一种鲁棒的 universal 响应模式，在扰动强度变化下保持 scale-invariant，从而揭示了归纳签名在 Gemma-2-2B、Llama-3.2-3B 和 GPT-2-XL 模型的中间层逐渐出现，并识别了相关模型部分。这些结果为理解 LLMs 内部组件的集体互动提供了新洞见，并作为大规模电路分析的基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07071v1",
      "published_date": "2024-11-11 15:47:15 UTC",
      "updated_date": "2024-11-11 15:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:26:50.292161"
    },
    {
      "arxiv_id": "2411.07070v2",
      "title": "On Active Privacy Auditing in Supervised Fine-tuning for White-Box Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Sun",
        "Hanpeng Wu",
        "Xi Sheryl Zhang"
      ],
      "abstract": "The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://anonymous.4open.science/r/PARSING-4817/.",
      "tldr_zh": "本研究探讨了在监督微调 (SFT) 过程中，白盒语言模型 (LMs) 的隐私泄露风险，引入了名为 Parsing 的主动隐私审计框架，以识别和量化这些风险。框架利用改进的白盒成员推断攻击 (MIAs)，结合新型学习目标和两阶段管道，监控 LMs 微调过程并最大化隐私风险暴露，同时提升 MIAs 在 GPT-2 和 Llama2 等大型模型上的有效性。实验结果显示，该框架在多种模型和任务上表现出高效性能，突显了 SFT 过程中的显著隐私问题，并为社区提供了一个可靠的审计工具和隐私保护见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07070v2",
      "published_date": "2024-11-11 15:46:07 UTC",
      "updated_date": "2024-11-12 04:12:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:27:00.900277"
    },
    {
      "arxiv_id": "2411.07066v3",
      "title": "Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Elia Cunegatti",
        "Leonardo Lucio Custode",
        "Giovanni Iacca"
      ],
      "abstract": "Network pruning focuses on computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has been pruning and re-training, which nowadays\nis inconvenient due to the vast amount of pre-trained models, which are in any\ncase too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAL}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs,\nwhich modifies the block-wise and row-wise sparsity exploiting information from\nboth the dense model and its sparse version to maximize the \\emph{neuron\nalignment} among activations. Differently from existing methods, our approach\nadaptively selects the best hyperparameters for the block-wise and row-wise\nsparsity ratios w.r.t. the model and the desired sparsity, and requires\n\\emph{no re-training}. We test our method over 276 cases combining four LLM\nfamilies, three sparsity ratios, and ten language tasks (three language\nmodeling and seven zero-shot datasets), showing how it consistently outperforms\nthe latest state-of-the-art methods in terms of performance-runtime trade-off.\nThe code is available at\n\\href{https://github.com/eliacunegatti/NeuroAL}{https://github.com/eliacunegatti/NeuroAL}.",
      "tldr_zh": "本研究提出了一种名为 NeuroAL 的剪枝算法，旨在通过最大化神经元对齐（neuron alignment）来减少大语言模型（LLMs）的参数，而无需重新训练，从而解决传统剪枝方法的计算开销问题。NeuroAL 算法利用密集预训练模型的激活信息，自适应调整块级和行级稀疏比率，并在任何现有剪枝基础上进行优化，确保稀疏模型与原模型的性能保持高度一致。在涵盖四个 LLM 系列、三个稀疏比率和十个语言任务（包括语言建模和零-shot 数据集）的 276 个案例中，该方法在性能-运行时权衡上 consistently 优于最新 state-of-the-art 方法，提供了一个高效的模型优化方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.07066v3",
      "published_date": "2024-11-11 15:30:16 UTC",
      "updated_date": "2025-01-30 15:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:27:13.175770"
    },
    {
      "arxiv_id": "2411.07042v1",
      "title": "Minion: A Technology Probe for Resolving Value Conflicts through Expert-Driven and User-Driven Strategies in AI Companion Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Xianzhe Fan",
        "Qing Xiao",
        "Xuhui Zhou",
        "Yuran Su",
        "Zhicong Lu",
        "Maarten Sap",
        "Hong Shen"
      ],
      "abstract": "AI companions based on large language models can role-play and converse very\nnaturally. When value conflicts arise between the AI companion and the user, it\nmay offend or upset the user. Yet, little research has examined such conflicts.\nWe first conducted a formative study that analyzed 151 user complaints about\nconflicts with AI companions, providing design implications for our study.\nBased on these, we created Minion, a technology probe to help users resolve\nhuman-AI value conflicts. Minion applies a user-empowerment intervention method\nthat provides suggestions by combining expert-driven and user-driven conflict\nresolution strategies. We conducted a technology probe study, creating 40 value\nconflict scenarios on Character.AI and Talkie. 22 participants completed 274\ntasks and successfully resolved conflicts 94.16% of the time. We summarize user\nresponses, preferences, and needs in resolving value conflicts, and propose\ndesign implications to reduce conflicts and empower users to resolve them more\neffectively.",
      "tldr_zh": "该研究探讨了AI伴侣应用中人类-AI价值冲突的问题，通过分析151个用户投诉，开发了Minion技术探针（technology probe）。Minion结合expert-driven和user-driven策略，提供用户赋权干预方法，帮助解决冲突，并在Character.AI和Talkie平台上创建40个场景进行测试。结果显示，22名参与者在274个任务中成功解决了94.16%的冲突，并基于用户响应和偏好，提出了设计含义，以减少冲突并提升用户解决能力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07042v1",
      "published_date": "2024-11-11 14:49:43 UTC",
      "updated_date": "2024-11-11 14:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:27:25.309925"
    },
    {
      "arxiv_id": "2411.07038v1",
      "title": "Designing Reliable Experiments with Generative Agent-Based Modeling: A Comprehensive Guide Using Concordia by Google DeepMind",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Leonardo García Navarro",
        "Nataliia Koneva",
        "Alfonso Sánchez-Macián",
        "José Alberto Hernández",
        "Manuel Goyanes"
      ],
      "abstract": "In social sciences, researchers often face challenges when conducting\nlarge-scale experiments, particularly due to the simulations' complexity and\nthe lack of technical expertise required to develop such frameworks.\nAgent-Based Modeling (ABM) is a computational approach that simulates agents'\nactions and interactions to evaluate how their behaviors influence the\noutcomes. However, the traditional implementation of ABM can be demanding and\ncomplex. Generative Agent-Based Modeling (GABM) offers a solution by enabling\nscholars to create simulations where AI-driven agents can generate complex\nbehaviors based on underlying rules and interactions. This paper introduces a\nframework for designing reliable experiments using GABM, making sophisticated\nsimulation techniques more accessible to researchers across various fields. We\nprovide a step-by-step guide for selecting appropriate tools, designing the\nmodel, establishing experimentation protocols, and validating results.",
      "tldr_zh": "这篇论文针对社会科学中大规模实验的复杂性和技术挑战，介绍了 Generative Agent-Based Modeling (GABM) 作为一种基于 AI 驱动代理的模拟方法，以简化传统 Agent-Based Modeling (ABM) 的实现过程。论文提供了一个全面框架，使用 Google DeepMind 的 Concordia 工具，指导研究者从工具选择、模型设计到实验协议制定和结果验证的完整步骤。该框架提升了实验的可靠性和可访问性，使更多领域的学者能够高效开展复杂行为模拟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07038v1",
      "published_date": "2024-11-11 14:45:08 UTC",
      "updated_date": "2024-11-11 14:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:27:37.244013"
    },
    {
      "arxiv_id": "2411.07031v1",
      "title": "Evaluating the Accuracy of Chatbots in Financial Literature",
      "title_zh": "评估聊天机器人在金融文献中的准确性",
      "authors": [
        "Orhan Erdem",
        "Kristi Hassett",
        "Feyzullah Egriboyun"
      ],
      "abstract": "We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
      "tldr_zh": "本研究评估了 ChatGPT (4o 和 o1-preview 版本) 与 Gemini Advanced 在金融文献引用方面的准确性，引入了非二元方法和一个新颖度度量来分析幻觉率（hallucination rates）如何随主题时效性变化。研究分析了150个引用，发现 ChatGPT-4o 的幻觉率为20.0%（95% CI, 13.6%-26.4%），o1-preview 为21.3%（95% CI, 14.8%-27.9%），而 Gemini Advanced 高达76.7%（95% CI, 69.9%-83.4%）。虽然幻觉率在较新主题上有所增加，但对 Gemini Advanced 而言这一趋势未达统计显著水平，结果强调在快速演变的领域中，用户需验证聊天机器人提供的引用以确保可靠性。",
      "categories": [
        "cs.AI",
        "econ.EM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07031v1",
      "published_date": "2024-11-11 14:37:57 UTC",
      "updated_date": "2024-11-11 14:37:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:27:49.522148"
    },
    {
      "arxiv_id": "2411.07019v3",
      "title": "UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Liu",
        "Yin Hua",
        "Mingyang Chen",
        "Zhuo Chen",
        "Ziqi Liu",
        "Lei Liang",
        "Huajun Chen",
        "Wen Zhang"
      ],
      "abstract": "Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, constrained by complex fact representation forms, existing\nlink prediction models for beyond-triple facts have difficulty achieving\nhierarchical fact modeling and generalizing the modules for one specific facts\nto other fact types. To overcome this limitation, we propose a Unified\nHierarchical Representation learning framework (UniHR) for unified knowledge\ngraph link prediction. It consists of a unified Hierarchical Data\nRepresentation (HiDR) module and a unified Hierarchical Structure Learning\n(HiSL) module as graph encoder. The HiDR module unifies hyper-relational KGs,\ntemporal KGs, and nested factual KGs into triple-based representations. Then\nHiSL incorporates intra-fact and inter-fact message passing, focusing on\nenhancing the semantic information within individual facts and enriching the\nstructural information between facts. Empirical results demonstrate the\neffectiveness of UniHR and highlight the strong potential of unified\nrepresentations. Code and data are available at\nhttps://github.com/Lza12a/UniHR.",
      "tldr_zh": "本文提出 UniHR 框架，用于统一知识图谱链接预测，旨在解决超关系 KGs（hyper-relational KGs）、时间 KGs（temporal KGs）和嵌套事实 KGs（nested factual KGs）的复杂表示问题。UniHR 包括 Hierarchical Data Representation (HiDR) 模块，将不同事实类型统一为基于三元组的表示，以及 Hierarchical Structure Learning (HiSL) 模块，通过 intra-fact 和 inter-fact 消息传递来增强语义和结构信息。实验结果证明 UniHR 显著提高了链接预测性能，并展示了统一表示的强大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07019v3",
      "published_date": "2024-11-11 14:22:42 UTC",
      "updated_date": "2025-05-16 02:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:28:02.125107"
    },
    {
      "arxiv_id": "2411.07015v1",
      "title": "Leveraging LSTM for Predictive Modeling of Satellite Clock Bias",
      "title_zh": "利用 LSTM 进行卫星钟偏差预测建模",
      "authors": [
        "Ahan Bhatt",
        "Ishaan Mehta",
        "Pravin Patidar"
      ],
      "abstract": "Satellite clock bias prediction plays a crucial role in enhancing the\naccuracy of satellite navigation systems. In this paper, we propose an approach\nutilizing Long Short-Term Memory (LSTM) networks to predict satellite clock\nbias. We gather data from the PRN 8 satellite of the Galileo and preprocess it\nto obtain a single difference sequence, crucial for normalizing the data.\nNormalization allows resampling of the data, ensuring that the predictions are\nequidistant and complete. Our methodology involves training the LSTM model on\nvarying lengths of datasets, ranging from 7 days to 31 days. We employ a\ntraining set consisting of two days' worth of data in each case. Our LSTM model\nexhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11\n$\\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods used\nfor similar time-series forecasting projects, being 170 times more accurate\nthan RNN, 2.3 $\\times$ 10$^7$ times more accurate than MLP, and 1.9 $\\times$\n10$^4$ times more accurate than ARIMA. This study holds significant potential\nin enhancing the accuracy and efficiency of low-power receivers used in various\ndevices, particularly those requiring power conservation. By providing more\naccurate predictions of satellite clock bias, the findings of this research can\nbe integrated into the algorithms of such devices, enabling them to function\nwith heightened precision while conserving power. Improved accuracy in clock\nbias predictions ensures that low-power receivers can maintain optimal\nperformance levels, thereby enhancing the overall reliability and effectiveness\nof satellite navigation systems. Consequently, this advancement holds promise\nfor a wide range of applications, including remote areas, IoT devices, wearable\ntechnology, and other devices where power efficiency and navigation accuracy\nare paramount.",
      "tldr_zh": "本文提出一种利用Long Short-Term Memory (LSTM) 网络来预测卫星钟偏差的方法，旨在提升卫星导航系统的准确性。通过对Galileo PRN 8卫星数据进行预处理（如获取单差序列并归一化），并使用7日至31日的不同数据集进行训练，每次仅需两天数据即可实现高效预测。实验结果显示，LSTM模型的Root Mean Square Error (RMSE) 达到2.11 × 10^{-11}，比RNN准确性高170倍，比MLP高2.3 × 10^7倍，比ARIMA高1.9 × 10^4倍。该方法可显著提高低功耗接收器的性能，适用于IoT设备、穿戴技术和偏远地区导航等领域，提升整体系统可靠性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "6 Pages, 6 figures (8 sub-figures), 5 Tables Index Terms-LSTM,\n  Satellite Navigation, Deep Learning, Clock Bias",
      "pdf_url": "http://arxiv.org/pdf/2411.07015v1",
      "published_date": "2024-11-11 14:18:32 UTC",
      "updated_date": "2024-11-11 14:18:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:28:16.078689"
    },
    {
      "arxiv_id": "2411.07013v1",
      "title": "A neural-network based anomaly detection system and a safety protocol to protect vehicular network",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Franceschini"
      ],
      "abstract": "This thesis addresses the use of Cooperative Intelligent Transport Systems\n(CITS) to improve road safety and efficiency by enabling vehicle-to-vehicle\ncommunication, highlighting the importance of secure and accurate data\nexchange. To ensure safety, the thesis proposes a Machine Learning-based\nMisbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networks\nto detect and mitigate incorrect or misleading messages within vehicular\nnetworks. Trained offline on the VeReMi dataset, the detection model is tested\nin real-time within a platooning scenario, demonstrating that it can prevent\nnearly all accidents caused by misbehavior by triggering a defense protocol\nthat dissolves the platoon if anomalies are detected. The results show that\nwhile the system can accurately detect general misbehavior, it struggles to\nlabel specific types due to varying traffic conditions, implying the difficulty\nof creating a universally adaptive protocol. However, the thesis suggests that\nwith more data and further refinement, this MDS could be implemented in\nreal-world CITS, enhancing driving safety by mitigating risks from misbehavior\nin cooperative driving networks.",
      "tldr_zh": "这篇论文提出了一种基于神经网络的异常检测系统和安全协议，用于保护 Cooperative Intelligent Transport Systems (CITS) 中的车辆网络，确保数据交换的安全和准确。系统采用 Long Short-Term Memory (LSTM) 网络构建 Machine Learning-based Misbehavior Detection System (MDS)，在 VeReMi 数据集上离线训练，并在实时车队场景中测试，能够通过触发防御协议解散车队，从而防止几乎所有由不当行为引起的事故。结果显示，该系统在检测一般不当行为方面表现出色，但由于交通条件变化，难以准确标记特定类型不当行为。作者建议通过更多数据和进一步优化，将该系统应用于真实世界 CITS，以提升驾驶安全。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Master's thesis 2023-2024",
      "pdf_url": "http://arxiv.org/pdf/2411.07013v1",
      "published_date": "2024-11-11 14:15:59 UTC",
      "updated_date": "2024-11-11 14:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:28:25.928238"
    },
    {
      "arxiv_id": "2411.07008v1",
      "title": "Permutative redundancy and uncertainty of the objective in deep learning",
      "title_zh": "翻译失败",
      "authors": [
        "Vacslav Glukhov"
      ],
      "abstract": "Implications of uncertain objective functions and permutative symmetry of\ntraditional deep learning architectures are discussed. It is shown that\ntraditional architectures are polluted by an astronomical number of equivalent\nglobal and local optima. Uncertainty of the objective makes local optima\nunattainable, and, as the size of the network grows, the global optimization\nlandscape likely becomes a tangled web of valleys and ridges. Some remedies\nwhich reduce or eliminate ghost optima are discussed including forced\npre-pruning, re-ordering, ortho-polynomial activations, and modular\nbio-inspired architectures.",
      "tldr_zh": "这篇论文探讨了深度学习中目标函数的不确定性(uncertainty of the objective)和置换冗余(permutative redundancy)的含义，揭示了传统架构存在大量等价的全局和局部最优(global and local optima)，这些“ghost optima”由于不确定性而难以达到，并随着网络规模增长导致优化景观变得纠缠复杂。论文指出，这种问题可能使全局优化陷入山谷和山脊的混乱网络。针对这些问题，论文提出了几种补救措施，包括强制预剪枝(forced pre-pruning)、重新排序(re-ordering)、正交多项式激活(ortho-polynomial activations)和模块化生物启发架构(modular bio-inspired architectures)，以减少或消除这些冗余最优解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07008v1",
      "published_date": "2024-11-11 14:06:56 UTC",
      "updated_date": "2024-11-11 14:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:28:38.390874"
    },
    {
      "arxiv_id": "2411.07007v2",
      "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching",
      "title_zh": "非对抗逆强化学习通过后继特征匹配",
      "authors": [
        "Arnav Kumar Jain",
        "Harley Wiltzer",
        "Jesse Farebrother",
        "Irina Rish",
        "Glen Berseth",
        "Sanjiban Choudhury"
      ],
      "abstract": "In inverse reinforcement learning (IRL), an agent seeks to replicate expert\ndemonstrations through interactions with the environment. Traditionally, IRL is\ntreated as an adversarial game, where an adversary searches over reward models,\nand a learner optimizes the reward through repeated RL procedures. This\ngame-solving approach is both computationally expensive and difficult to\nstabilize. In this work, we propose a novel approach to IRL by direct policy\noptimization: exploiting a linear factorization of the return as the inner\nproduct of successor features and a reward vector, we design an IRL algorithm\nby policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can\nbe solved seamlessly with existing actor-critic RL algorithms. Remarkably, our\napproach works in state-only settings without expert action labels, a setting\nwhich behavior cloning (BC) cannot solve. Empirical results demonstrate that\nour method learns from as few as a single expert demonstration and achieves\nimproved performance on various control tasks.",
      "tldr_zh": "本文提出了一种非对抗的逆强化学习（IRL）方法，通过后继特征匹配（Successor Feature Matching）直接优化策略，避开了传统IRL的对抗游戏框架，从而减少计算开销并提高稳定性。方法利用回报的线性分解，将其视为后继特征和奖励向量的内积，并通过策略梯度下降最小化学习者与专家特征的差距，无需学习奖励函数。实验结果显示，该方法能在仅状态设置下（无需专家动作标签）从少至一个专家演示中学习，并在各种控制任务上实现更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.07007v2",
      "published_date": "2024-11-11 14:05:50 UTC",
      "updated_date": "2025-04-22 17:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:28:49.366186"
    },
    {
      "arxiv_id": "2411.07006v1",
      "title": "Estimating Causal Effects in Partially Directed Parametric Causal Factor Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Tanya Braun",
        "Ralf Möller",
        "Marcel Gehrke"
      ],
      "abstract": "Lifting uses a representative of indistinguishable individuals to exploit\nsymmetries in probabilistic relational models, denoted as parametric factor\ngraphs, to speed up inference while maintaining exact answers. In this paper,\nwe show how lifting can be applied to causal inference in partially directed\ngraphs, i.e., graphs that contain both directed and undirected edges to\nrepresent causal relationships between random variables. We present partially\ndirected parametric causal factor graphs (PPCFGs) as a generalisation of\npreviously introduced parametric causal factor graphs, which require a fully\ndirected graph. We further show how causal inference can be performed on a\nlifted level in PPCFGs, thereby extending the applicability of lifted causal\ninference to a broader range of models requiring less prior knowledge about\ncausal relationships.",
      "tldr_zh": "本论文探讨了如何将 lifting 技术应用于部分有向参数因果因子图 (PPCFGs) 中的因果推理，利用不可区分个体的对称性来加速推理过程，同时保持精确性。作者将 PPCFGs 作为先前参数因果因子图的泛化，允许图中包含有向和无向边，以更灵活地表示随机变量之间的因果关系。实验结果表明，这种方法扩展了 lifted 因果推理的适用范围，减少了对因果关系的先验知识需求，从而适用于更广泛的概率关系模型。",
      "categories": [
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 16th International Conference on\n  Scalable Uncertainty Management (SUM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.07006v1",
      "published_date": "2024-11-11 14:05:39 UTC",
      "updated_date": "2024-11-11 14:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:29:01.460049"
    },
    {
      "arxiv_id": "2411.07003v1",
      "title": "Enhancing Robot Assistive Behaviour with Reinforcement Learning and Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Andriella",
        "Giovanni Falcone",
        "Silvia Rossi"
      ],
      "abstract": "The adaptation to users' preferences and the ability to infer and interpret\nhumans' beliefs and intents, which is known as the Theory of Mind (ToM), are\ntwo crucial aspects for achieving effective human-robot collaboration. Despite\nits importance, very few studies have investigated the impact of adaptive\nrobots with ToM abilities. In this work, we present an exploratory comparative\nstudy to investigate how social robots equipped with ToM abilities impact\nusers' performance and perception. We design a two-layer architecture. The\nQ-learning agent on the first layer learns the robot's higher-level behaviour.\nOn the second layer, a heuristic-based ToM infers the user's intended strategy\nand is responsible for implementing the robot's assistance, as well as\nproviding the motivation behind its choice. We conducted a user study in a\nreal-world setting, involving 56 participants who interacted with either an\nadaptive robot capable of ToM, or with a robot lacking such abilities. Our\nfindings suggest that participants in the ToM condition performed better,\naccepted the robot's assistance more often, and perceived its ability to adapt,\npredict and recognise their intents to a higher degree. Our preliminary\ninsights could inform future research and pave the way for designing more\ncomplex computation architectures for adaptive behaviour with ToM capabilities.",
      "tldr_zh": "该研究探讨了如何通过 Reinforcement Learning 和 Theory of Mind (ToM) 提升机器人的辅助行为，以实现更有效的机器人与人类协作。研究设计了一个两层架构：第一层使用 Q-learning 代理学习机器人的高层行为，第二层基于启发式方法推断用户的意图并提供相应辅助。实验涉及56名参与者，结果显示配备 ToM 能力的机器人能显著改善用户表现、增加对机器人辅助的接受度，并提升用户对机器人适应、预测和识别意图的感知。该工作为未来开发更复杂的人机交互架构提供了宝贵见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07003v1",
      "published_date": "2024-11-11 14:01:15 UTC",
      "updated_date": "2024-11-11 14:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:29:14.491068"
    },
    {
      "arxiv_id": "2411.06995v1",
      "title": "Which PPML Would a User Choose? A Structured Decision Support Framework for Developers to Rank PPML Techniques Based on User Acceptance Criteria",
      "title_zh": "用户会选择哪种 PPML？ 一种针对开发人员的结构化决策支持框架，用于基于用户接受标准对 PPML 技术进行排名",
      "authors": [
        "Sascha Löbner",
        "Sebastian Pape",
        "Vanessa Bracamonte",
        "Kittiphop Phalakarn"
      ],
      "abstract": "Using Privacy-Enhancing Technologies (PETs) for machine learning often\ninfluences the characteristics of a machine learning approach, e.g., the needed\ncomputational power, timing of the answers or how the data can be utilized.\nWhen designing a new service, the developer faces the problem that some\ndecisions require a trade-off. For example, the use of a PET may cause a delay\nin the responses or adding noise to the data to improve the users' privacy\nmight have a negative impact on the accuracy of the machine learning approach.\nAs of now, there is no structured way how the users' perception of a machine\nlearning based service can contribute to the selection of Privacy Preserving\nMachine Learning (PPML) methods. This is especially a challenge since one\ncannot assume that users have a deep technical understanding of these\ntechnologies. Therefore, they can only be asked about certain attributes that\nthey can perceive when using the service and not directly which PPML they\nprefer.\n  This study introduces a decision support framework with the aim of supporting\nthe selection of PPML technologies based on user preferences. Based on prior\nwork analysing User Acceptance Criteria (UAC), we translate these criteria into\ndifferentiating characteristics for various PPML techniques. As a final result,\nwe achieve a technology ranking based on the User Acceptance Criteria while\nproviding technology insights for the developers. We demonstrate its\napplication using the use case of classifying privacy-relevant information.\n  Our contribution consists of the decision support framework which consists of\na process to connect PPML technologies with UAC, a process for evaluating the\ncharacteristics that separate PPML techniques, and a ranking method to evaluate\nthe best PPML technique for the use case.",
      "tldr_zh": "这篇论文提出一个结构化的决策支持框架，帮助开发者基于用户接受标准(User Acceptance Criteria, UAC)对Privacy Preserving Machine Learning (PPML)技术进行排名，以解决使用Privacy-Enhancing Technologies (PETs)时可能带来的权衡问题，如响应延迟或准确性下降。框架将UAC转化为PPML技术的区分特征，并包括评估这些特征的过程和一种排名方法。最终，通过隐私相关信息分类的用例演示，该框架为开发者提供技术洞见，帮助选择最适合用户偏好的PPML技术。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06995v1",
      "published_date": "2024-11-11 13:53:33 UTC",
      "updated_date": "2024-11-11 13:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:29:26.038719"
    },
    {
      "arxiv_id": "2411.06989v2",
      "title": "The Backpropagation of the Wave Network",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhang",
        "Victor S. Sheng"
      ],
      "abstract": "This paper provides an in-depth analysis of Wave Network, a novel token\nrepresentation method derived from the Wave Network, designed to capture both\nglobal and local semantics of input text through wave-inspired complex vectors.\nIn complex vector token representation, each token is represented with a\nmagnitude component, capturing the global semantics of the entire input text,\nand a phase component, encoding the relationships between individual tokens and\nthe global semantics. Building on prior research that demonstrated the\neffectiveness of wave-like operations, such as interference and modulation,\nduring forward propagation, this study investigates the convergence behavior,\nbackpropagation characteristics, and embedding independence within the\nToken2Wave framework. A detailed computational complexity analysis shows that\nToken2Wave can significantly reduce video memory usage and training time\ncompared to BERT. Gradient comparisons for the [CLS] token, total input text,\nand classifier parameters further highlight Token2Wave's unique\ncharacteristics. This research offers new insights into wave-based token\nrepresentations, demonstrating their potential to enable efficient and\ncomputationally friendly language model architectures.",
      "tldr_zh": "本论文深入分析了 Wave Network，这是一种基于波浪灵感的复杂向量 token 表示方法，能够通过 magnitude 组件捕捉输入文本的全局语义，并通过 phase 组件编码 token 间的局部关系。研究重点考察了 Token2Wave 框架的收敛行为、backpropagation 特性以及嵌入独立性，并通过计算复杂性分析证明其比 BERT 显著降低了视频内存使用和训练时间。总体而言，该工作揭示了 wave-based token 表示的独特优势，为高效的语言模型架构提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06989v2",
      "published_date": "2024-11-11 13:48:01 UTC",
      "updated_date": "2025-01-11 03:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:29:37.355126"
    },
    {
      "arxiv_id": "2411.06965v2",
      "title": "Imitation from Diverse Behaviors: Wasserstein Quality Diversity Imitation Learning with Single-Step Archive Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Xingrui Yu",
        "Zhenglin Wan",
        "David Mark Bossens",
        "Yueming Lyu",
        "Qing Guo",
        "Ivor W. Tsang"
      ],
      "abstract": "Learning diverse and high-performance behaviors from a limited set of\ndemonstrations is a grand challenge. Traditional imitation learning methods\nusually fail in this task because most of them are designed to learn one\nspecific behavior even with multiple demonstrations. Therefore, novel\ntechniques for \\textit{quality diversity imitation learning}, which bridges the\nquality diversity optimization and imitation learning methods, are needed to\nsolve the above challenge. This work introduces Wasserstein Quality Diversity\nImitation Learning (WQDIL), which 1) improves the stability of imitation\nlearning in the quality diversity setting with latent adversarial training\nbased on a Wasserstein Auto-Encoder (WAE), and 2) mitigates a\nbehavior-overfitting issue using a measure-conditioned reward function with a\nsingle-step archive exploration bonus. Empirically, our method significantly\noutperforms state-of-the-art IL methods, achieving near-expert or beyond-expert\nQD performance on the challenging continuous control tasks derived from MuJoCo\nenvironments.",
      "tldr_zh": "该论文针对从有限演示中学习多样和高性能行为的挑战，提出了一种Wasserstein Quality Diversity Imitation Learning (WQDIL)方法，将质量多样性优化与模仿学习相结合。WQDIL通过基于Wasserstein Auto-Encoder (WAE)的潜在对抗训练，提高了在多样性设置下的模仿学习稳定性，并使用测量条件奖励函数和单步存档探索奖金来缓解行为过拟合问题。实验结果显示，该方法在MuJoCo环境的连续控制任务中显著优于现有模仿学习方法，实现了接近或超越专家水平的质量多样性性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06965v2",
      "published_date": "2024-11-11 13:11:18 UTC",
      "updated_date": "2025-04-04 05:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:29:51.894745"
    },
    {
      "arxiv_id": "2411.06959v1",
      "title": "ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zanlin Ni",
        "Yulin Wang",
        "Renping Zhou",
        "Yizeng Han",
        "Jiayi Guo",
        "Zhiyuan Liu",
        "Yuan Yao",
        "Gao Huang"
      ],
      "abstract": "Recently, token-based generation have demonstrated their effectiveness in\nimage synthesis. As a representative example, non-autoregressive Transformers\n(NATs) can generate decent-quality images in a few steps. NATs perform\ngeneration in a progressive manner, where the latent tokens of a resulting\nimage are incrementally revealed. At each step, the unrevealed image regions\nare padded with mask tokens and inferred by NAT. In this paper, we delve into\nthe mechanisms behind the effectiveness of NATs and uncover two important\npatterns that naturally emerge from NATs: Spatially (within a step), although\nmask and visible tokens are processed uniformly by NATs, the interactions\nbetween them are highly asymmetric. In specific, mask tokens mainly gather\ninformation for decoding, while visible tokens tend to primarily provide\ninformation, and their deep representations can be built only upon themselves.\nTemporally (across steps), the interactions between adjacent generation steps\nmostly concentrate on updating the representations of a few critical tokens,\nwhile the computation for the majority of tokens is generally repetitive.\nDriven by these findings, we propose EfficientNAT (ENAT), a NAT model that\nexplicitly encourages these critical interactions inherent in NATs. At the\nspatial level, we disentangle the computations of visible and mask tokens by\nencoding visible tokens independently, while decoding mask tokens conditioned\non the fully encoded visible tokens. At the temporal level, we prioritize the\ncomputation of the critical tokens at each step, while maximally reusing\npreviously computed token representations to supplement necessary information.\nENAT improves the performance of NATs notably with significantly reduced\ncomputational cost. Experiments on ImageNet-256, ImageNet-512 and MS-COCO\nvalidate the effectiveness of ENAT. Code is available at\nhttps://github.com/LeapLabTHU/ENAT.",
      "tldr_zh": "该论文重新审视了基于 token 的图像合成中空间-时间交互的机制，分析了非自回归 Transformer (NATs) 的生成过程，发现空间上 mask tokens 与 visible tokens 的交互不对称，而时间上相邻步骤主要更新少数关键 tokens。该研究提出 EfficientNAT (ENAT) 模型，通过独立编码 visible tokens 并据此解码 mask tokens、在时间层面优先计算关键 tokens 并重用先前表示，显著提高了 NATs 的性能并降低了计算成本。在 ImageNet-256、ImageNet-512 和 MS-COCO 数据集上的实验验证了 ENAT 的有效性，代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06959v1",
      "published_date": "2024-11-11 13:05:39 UTC",
      "updated_date": "2024-11-11 13:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:30:02.517468"
    },
    {
      "arxiv_id": "2411.06928v2",
      "title": "Multi-class Decoding of Attended Speaker Direction Using Electroencephalogram and Audio Spatial Spectrum",
      "title_zh": "多类关注说话者方向解码使用脑电图和音频空间谱",
      "authors": [
        "Yuanming Zhang",
        "Jing Lu",
        "Fei Chen",
        "Haoliang Du",
        "Xia Gao",
        "Zhibin Lin"
      ],
      "abstract": "Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, it is found that on\nthe recently presented dataset with 14-class directional focus, models relying\nexclusively on EEG inputs exhibit significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. The CNN, LSM-CNN, and Deformer models are\nemployed to decode the directional focus from listeners' EEG signals and audio\nspatial spectra. The proposed Sp-EEG-Deformer model achieves notable 14-class\ndecoding accuracies of 55.35% and 57.19% in leave-one-subject-out and\nleave-one-trial-out scenarios with a decision window of 1 second, respectively.\nExperiment results indicate increased decoding accuracy as the number of\nalternative directions reduces. These findings suggest the efficacy of our\nproposed dual modal directional focus decoding strategy.",
      "tldr_zh": "该研究旨在从听众的 EEG 信号中解码关注说话者的多类方向，以提升脑机接口对听力障碍者的帮助，超越了以往的二元解码（left or right）。他们发现，单纯使用 EEG 输入的模型在 14 类方向数据集上，准确率较低；因此，提出整合音频 spatial spectra 与 EEG 特征的方法，并采用 CNN、LSM-CNN 和 Deformer 模型，特别是 Sp-EEG-Deformer 模型。实验结果显示，该模型在 1 秒决策窗口下，分别在 leave-one-subject-out 和 leave-one-trial-out 场景中实现了 55.35% 和 57.19% 的 14 类解码准确率，随着备选方向减少准确率进一步提升，证明了双模态策略的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to IEEE TNSRE",
      "pdf_url": "http://arxiv.org/pdf/2411.06928v2",
      "published_date": "2024-11-11 12:32:26 UTC",
      "updated_date": "2025-01-09 13:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:30:17.473871"
    },
    {
      "arxiv_id": "2411.06927v1",
      "title": "Multi-modal Iterative and Deep Fusion Frameworks for Enhanced Passive DOA Sensing via a Green Massive H2AD MIMO Receiver",
      "title_zh": "翻译失败",
      "authors": [
        "Jiatong Bai",
        "Minghao Chen",
        "Wankai Tang",
        "Yifan Li",
        "Cunhua Pan",
        "Yongpeng Wu",
        "Feng Shu"
      ],
      "abstract": "Most existing DOA estimation methods assume ideal source incident angles with\nminimal noise. Moreover, directly using pre-estimated angles to calculate\nweighted coefficients can lead to performance loss. Thus, a green multi-modal\n(MM) fusion DOA framework is proposed to realize a more practical, low-cost and\nhigh time-efficiency DOA estimation for a H$^2$AD array. Firstly, two more\nefficient clustering methods, global maximum cos\\_similarity clustering\n(GMaxCS) and global minimum distance clustering (GMinD), are presented to infer\nmore precise true solutions from the candidate solution sets. Based on this, an\niteration weighted fusion (IWF)-based method is introduced to iteratively\nupdate weighted fusion coefficients and the clustering center of the true\nsolution classes by using the estimated values. Particularly, the coarse DOA\ncalculated by fully digital (FD) subarray, serves as the initial cluster\ncenter. The above process yields two methods called MM-IWF-GMaxCS and\nMM-IWF-GMinD. To further provide a higher-accuracy DOA estimation, a fusion\nnetwork (fusionNet) is proposed to aggregate the inferred two-part true angles\nand thus generates two effective approaches called MM-fusionNet-GMaxCS and\nMM-fusionNet-GMinD. The simulation outcomes show the proposed four approaches\ncan achieve the ideal DOA performance and the CRLB. Meanwhile, proposed\nMM-fusionNet-GMaxCS and MM-fusionNet-GMinD exhibit superior DOA performance\ncompared to MM-IWF-GMaxCS and MM-IWF-GMinD, especially in extremely-low SNR\nrange.",
      "tldr_zh": "这篇论文提出了一种绿色多模态 (MM) 融合 DOA 框架，用于提升 H2AD MIMO 接收器的被动 DOA 估计性能，针对现实场景中的噪声和预估角度误差问题。框架引入了全局最大余弦相似度聚类 (GMaxCS) 和全局最小距离聚类 (GMinD) 方法，以及迭代加权融合 (IWF) 和融合网络 (fusionNet) 技术，分别生成 MM-IWF-GMaxCS/MM-IWF-GMinD 和 MM-fusionNet-GMaxCS/MM-fusionNet-GMinD 方案，以迭代更新系数和聚合真角度，从而实现更高准确性和效率。模拟结果表明，这些方法在极低 SNR 条件下优于基线，达到了理想 DOA 性能和 CRLB。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06927v1",
      "published_date": "2024-11-11 12:32:18 UTC",
      "updated_date": "2024-11-11 12:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:30:31.436794"
    },
    {
      "arxiv_id": "2411.06916v2",
      "title": "Slowing Down Forgetting in Continual Learning",
      "title_zh": "持续学习中的遗忘减缓",
      "authors": [
        "Pascal Janetzky",
        "Tobias Schlagenhauf",
        "Stefan Feuerriegel"
      ],
      "abstract": "A common challenge in continual learning (CL) is catastrophic forgetting,\nwhere the performance on old tasks drops after new, additional tasks are\nlearned. In this paper, we propose a novel framework called ReCL to slow down\nforgetting in CL. Our framework exploits an implicit bias of gradient-based\nneural networks due to which these converge to margin maximization points. Such\nconvergence points allow us to reconstruct old data from previous tasks, which\nwe then combine with the current training data. Our framework is flexible and\ncan be applied on top of existing, state-of-the-art CL methods. We further\ndemonstrate the performance gain from our framework across a large series of\nexperiments, including two challenging CL scenarios (class incremental and\ndomain incremental learning), different datasets (MNIST, CIFAR10,\nTinyImagenet), and different network architectures. Across all experiments, we\nfind large performance gains through ReCL. To the best of our knowledge, our\nframework is the first to address catastrophic forgetting by leveraging models\nin CL as their own memory buffers.",
      "tldr_zh": "本文提出 ReCL 框架，用于减缓 continual learning (CL) 中的 catastrophic forgetting 问题，即在新任务学习后旧任务性能下降。ReCL 利用梯度-based 神经网络的隐式偏差（如 convergence to margin maximization points）来重建旧任务数据，并将其与当前训练数据结合，从而增强模型的记忆能力。该框架灵活，可应用于现有 CL 方法，并在实验中（如 class incremental 和 domain incremental learning 场景，使用 MNIST、CIFAR10 和 TinyImagenet 数据集）显示出显著性能提升，是首个将模型作为自身内存缓冲区的创新方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06916v2",
      "published_date": "2024-11-11 12:19:28 UTC",
      "updated_date": "2025-03-03 10:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:30:38.449547"
    },
    {
      "arxiv_id": "2411.06911v2",
      "title": "Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI",
      "title_zh": "高斯过程仿真器用于",
      "authors": [
        "Bruno Viti",
        "Franz Thaler",
        "Kathrin Lisa Kapper",
        "Martin Urschler",
        "Martin Holler",
        "Elias Karabelas"
      ],
      "abstract": "Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.",
      "tldr_zh": "该研究针对心脏MRI分割问题，提出了一种结合few-shot learning、U-Net架构和Gaussian Process Emulators (GPEs)的新方法，以减少对大量标注数据的依赖。GPEs在潜在空间中学习支持图像与对应掩码的关系，从而提升对未见查询图像的分割性能。实验在M&Ms-2数据集上显示，该方法在不同心脏MRI方向的分割中，DICE coefficients显著高于现有无监督和few-shot方法，尤其在支持集规模较小时表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06911v2",
      "published_date": "2024-11-11 12:13:58 UTC",
      "updated_date": "2024-11-12 12:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:30:49.799550"
    },
    {
      "arxiv_id": "2411.06899v2",
      "title": "LongSafety: Enhance Safety for Long-Context LLMs",
      "title_zh": "LongSafety: 增强长上下文大语言",
      "authors": [
        "Mianqiu Huang",
        "Xiaoran Liu",
        "Shaojun Zhou",
        "Mozhi Zhang",
        "Qipeng Guo",
        "Linyang Li",
        "Chenkun Tan",
        "Yang Gao",
        "Pengyu Wang",
        "Linlin Li",
        "Qun Liu",
        "Yaqian Zhou",
        "Xipeng Qiu",
        "Xuanjing Huang"
      ],
      "abstract": "Recent advancements in model architectures and length extrapolation\ntechniques have significantly extended the context length of large language\nmodels (LLMs), paving the way for their application in increasingly complex\ntasks. However, despite the growing capabilities of long-context LLMs, the\nsafety issues in long-context scenarios remain underexplored. While safety\nalignment in short context has been widely studied, the safety concerns of\nlong-context LLMs have not been adequately addressed. In this work, we\nintroduce \\textbf{LongSafety}, a comprehensive safety alignment dataset for\nlong-context LLMs, containing 10 tasks and 17k samples, with an average length\nof 40.9k tokens. Our experiments demonstrate that training with LongSafety can\nenhance long-context safety performance while enhancing short-context safety\nand preserving general capabilities. Furthermore, we demonstrate that\nlong-context safety does not equal long-context alignment with short-context\nsafety data and LongSafety has generalizing capabilities in context length and\nlong-context safety scenarios.",
      "tldr_zh": "该研究针对长上下文大语言模型(LLMs)的安全问题，引入了LongSafety数据集，该数据集包含10个任务和17k个样本，平均长度为40.9k tokens。\n实验结果显示，使用LongSafety进行训练不仅提升了长上下文的安全性能，还改善了短上下文的安全性，同时保留了模型的一般能力。\n此外，该研究证明，长上下文安全不能仅依赖短上下文安全数据，而是需要专门的数据集，且LongSafety在上下文长度和安全场景中具有良好的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06899v2",
      "published_date": "2024-11-11 11:57:37 UTC",
      "updated_date": "2025-02-27 13:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:31:01.881909"
    },
    {
      "arxiv_id": "2411.06878v1",
      "title": "GraphRPM: Risk Pattern Mining on Industrial Large Attributed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Tian",
        "Xintan Zeng",
        "Yifei Hu",
        "Baokun Wang",
        "Yongchao Liu",
        "Yue Jin",
        "Changhua Meng",
        "Chuntao Hong",
        "Tianyi Zhang",
        "Weiqiang Wang"
      ],
      "abstract": "Graph-based patterns are extensively employed and favored by practitioners\nwithin industrial companies due to their capacity to represent the behavioral\nattributes and topological relationships among users, thereby offering enhanced\ninterpretability in comparison to black-box models commonly utilized for\nclassification and recognition tasks. For instance, within the scenario of\ntransaction risk management, a graph pattern that is characteristic of a\nparticular risk category can be readily employed to discern transactions\nfraught with risk, delineate networks of criminal activity, or investigate the\nmethodologies employed by fraudsters. Nonetheless, graph data in industrial\nsettings is often characterized by its massive scale, encompassing data sets\nwith millions or even billions of nodes, making the manual extraction of graph\npatterns not only labor-intensive but also necessitating specialized knowledge\nin particular domains of risk. Moreover, existing methodologies for mining\ngraph patterns encounter significant obstacles when tasked with analyzing\nlarge-scale attributed graphs. In this work, we introduce GraphRPM, an\nindustry-purpose parallel and distributed risk pattern mining framework on\nlarge attributed graphs. The framework incorporates a novel edge-involved graph\nisomorphism network alongside optimized operations for parallel graph\ncomputation, which collectively contribute to a considerable reduction in\ncomputational complexity and resource expenditure. Moreover, the intelligent\nfiltration of efficacious risky graph patterns is facilitated by the proposed\nevaluation metrics. Comprehensive experimental evaluations conducted on\nreal-world datasets of varying sizes substantiate the capability of GraphRPM to\nadeptly address the challenges inherent in mining patterns from large-scale\nindustrial attributed graphs, thereby underscoring its substantial value for\nindustrial deployment.",
      "tldr_zh": "本文提出 GraphRPM，一种针对工业大规模属性图的风险模式挖掘框架，旨在解决手动提取模式 laborious 问题和现有方法在处理巨量图数据时的挑战。该框架整合了新型 edge-involved graph isomorphism network 和优化的并行图计算操作，显著降低了计算复杂性和资源消耗，同时通过智能评价指标过滤有效风险模式。实验在各种真实数据集上验证了 GraphRPM 的性能，提升了风险管理如检测欺诈交易的准确性和效率，具有重要的工业部署价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECML PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06878v1",
      "published_date": "2024-11-11 11:20:30 UTC",
      "updated_date": "2024-11-11 11:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:31:13.208586"
    },
    {
      "arxiv_id": "2411.06872v1",
      "title": "Multi-Modal interpretable automatic video captioning",
      "title_zh": "多模态可解释自动视频字幕生成",
      "authors": [
        "Antoine Hanna-Asaad",
        "Decky Aspandi",
        "Titus Zaharia"
      ],
      "abstract": "Video captioning aims to describe video contents using natural language\nformat that involves understanding and interpreting scenes, actions and events\nthat occurs simultaneously on the view. Current approaches have mainly\nconcentrated on visual cues, often neglecting the rich information available\nfrom other important modality of audio information, including their\ninter-dependencies. In this work, we introduce a novel video captioning method\ntrained with multi-modal contrastive loss that emphasizes both multi-modal\nintegration and interpretability. Our approach is designed to capture the\ndependency between these modalities, resulting in more accurate, thus pertinent\ncaptions. Furthermore, we highlight the importance of interpretability,\nemploying multiple attention mechanisms that provide explanation into the\nmodel's decision-making process. Our experimental results demonstrate that our\nproposed method performs favorably against the state-of the-art models on\ncommonly used benchmark datasets of MSR-VTT and VATEX.",
      "tldr_zh": "这篇论文提出了一种多模态可解释自动视频字幕方法，旨在整合视觉和音频信息以更准确地描述视频中的场景、动作和事件，同时捕捉模态间的相互依赖性。方法采用 multi-modal contrastive loss 进行训练，强调多模态整合，并通过 multiple attention mechanisms 提供模型决策过程的可解释性。实验结果表明，该方法在 MSR-VTT 和 VATEX 等基准数据集上优于现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06872v1",
      "published_date": "2024-11-11 11:12:23 UTC",
      "updated_date": "2024-11-11 11:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:31:25.134576"
    },
    {
      "arxiv_id": "2411.06870v2",
      "title": "AI-Native Multi-Access Future Networks -- The REASON Architecture",
      "title_zh": "AI 原生多接入未来网络 -- REASON 架构",
      "authors": [
        "Konstantinos Katsaros",
        "Ioannis Mavromatis",
        "Kostantinos Antonakoglou",
        "Saptarshi Ghosh",
        "Dritan Kaleshi",
        "Toktam Mahmoodi",
        "Hamid Asgari",
        "Anastasios Karousos",
        "Iman Tavakkolnia",
        "Hossein Safi",
        "Harald Hass",
        "Constantinos Vrontos",
        "Amin Emami",
        "Juan Parra Ullauri",
        "Shadi Moazzeni",
        "Dimitra Simeonidou"
      ],
      "abstract": "The development of the sixth generation of communication networks (6G) has\nbeen gaining momentum over the past years, with a target of being introduced by\n2030. Several initiatives worldwide are developing innovative solutions and\nsetting the direction for the key features of these networks. Some common\nemerging themes are the tight integration of AI, the convergence of multiple\naccess technologies and sustainable operation, aiming to meet stringent\nperformance and societal requirements. To that end, we are introducing REASON -\nRealising Enabling Architectures and Solutions for Open Networks. The REASON\nproject aims to address technical challenges in future network deployments,\nsuch as E2E service orchestration, sustainability, security and trust\nmanagement, and policy management, utilising AI-native principles, considering\nmultiple access technologies and cloud-native solutions.\n  This paper presents REASON's architecture and the identified requirements for\nfuture networks. The architecture is meticulously designed for modularity,\ninteroperability, scalability, simplified troubleshooting, flexibility, and\nenhanced security, taking into consideration current and future standardisation\nefforts, and the ease of implementation and training. It is structured into\nfour horizontal layers: Physical Infrastructure, Network Service, Knowledge,\nand End-User Application, complemented by two vertical layers: Management and\nOrchestration, and E2E Security. This layered approach ensures a robust,\nadaptable framework to support the diverse and evolving requirements of 6G\nnetworks, fostering innovation and facilitating seamless integration of\nadvanced technologies.",
      "tldr_zh": "该论文介绍了 REASON 架构，一种 AI-native 的多接入未来网络设计，旨在解决 6G 网络部署中的技术挑战，包括端到端 (E2E) 服务编排、可持续性、安全与信任管理以及政策管理。REASON 项目采用 AI-native 原则，结合多种接入技术和云原生解决方案，构建了一个模块化、可互操作、可扩展的架构，分为四个横向层（Physical Infrastructure、Network Service、Knowledge 和 End-User Application）和两个纵向层（Management and Orchestration 以及 E2E Security）。这种分层方法增强了网络的灵活性、安全性和可扩展性，支持 6G 网络的创新发展，并促进先进技术的无缝集成。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted for publication at IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2411.06870v2",
      "published_date": "2024-11-11 11:10:39 UTC",
      "updated_date": "2024-11-25 11:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:31:37.732818"
    },
    {
      "arxiv_id": "2411.06866v1",
      "title": "Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering",
      "title_zh": "通过图-文本",
      "authors": [
        "Boci Peng",
        "Yongchao Liu",
        "Xiaohe Bo",
        "Sheng Tian",
        "Baokun Wang",
        "Chuntao Hong",
        "Yan Zhang"
      ],
      "abstract": "Commonsense question answering is a crucial task that requires machines to\nemploy reasoning according to commonsense. Previous studies predominantly\nemploy an extracting-and-modeling paradigm to harness the information in KG,\nwhich first extracts relevant subgraphs based on pre-defined rules and then\nproceeds to design various strategies aiming to improve the representations and\nfusion of the extracted structural knowledge. Despite their effectiveness,\nthere are still two challenges. On one hand, subgraphs extracted by rule-based\nmethods may have the potential to overlook critical nodes and result in\nuncontrollable subgraph size. On the other hand, the misalignment between graph\nand text modalities undermines the effectiveness of knowledge fusion,\nultimately impacting the task performance. To deal with the problems above, we\npropose a novel framework: \\textbf{S}ubgraph R\\textbf{E}trieval Enhanced by\nGra\\textbf{P}h-\\textbf{T}ext \\textbf{A}lignment, named \\textbf{SEPTA}. Firstly,\nwe transform the knowledge graph into a database of subgraph vectors and\npropose a BFS-style subgraph sampling strategy to avoid information loss,\nleveraging the analogy between BFS and the message-passing mechanism. In\naddition, we propose a bidirectional contrastive learning approach for\ngraph-text alignment, which effectively enhances both subgraph retrieval and\nknowledge fusion. Finally, all the retrieved information is combined for\nreasoning in the prediction module. Extensive experiments on five datasets\ndemonstrate the effectiveness and robustness of our framework.",
      "tldr_zh": "本文针对常识问答（Commonsense Question Answering）任务中的子图提取问题，提出SEPTA框架，以解决基于规则的子图提取可能忽略关键节点和图-文本不对齐的问题。框架将知识图谱（Knowledge Graph）转换为子图向量数据库，并采用BFS-style子图采样策略避免信息丢失，同时通过双向对比学习（bidirectional contrastive learning）增强图-文本对齐，从而改善知识融合和推理过程。在五个数据集上的广泛实验中，SEPTA展示了显著的有效性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECML PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06866v1",
      "published_date": "2024-11-11 10:57:31 UTC",
      "updated_date": "2024-11-11 10:57:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:31:50.139021"
    },
    {
      "arxiv_id": "2411.06863v1",
      "title": "Computable Model-Independent Bounds for Adversarial Quantum Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bacui Li",
        "Tansu Alpcan",
        "Chandra Thapa",
        "Udaya Parampalli"
      ],
      "abstract": "By leveraging the principles of quantum mechanics, QML opens doors to novel\napproaches in machine learning and offers potential speedup. However, machine\nlearning models are well-documented to be vulnerable to malicious\nmanipulations, and this susceptibility extends to the models of QML. This\nsituation necessitates a thorough understanding of QML's resilience against\nadversarial attacks, particularly in an era where quantum computing\ncapabilities are expanding. In this regard, this paper examines\nmodel-independent bounds on adversarial performance for QML. To the best of our\nknowledge, we introduce the first computation of an approximate lower bound for\nadversarial error when evaluating model resilience against sophisticated\nquantum-based adversarial attacks. Experimental results are compared to the\ncomputed bound, demonstrating the potential of QML models to achieve high\nrobustness. In the best case, the experimental error is only 10% above the\nestimated bound, offering evidence of the inherent robustness of quantum\nmodels. This work not only advances our theoretical understanding of quantum\nmodel resilience but also provides a precise reference bound for the future\ndevelopment of robust QML algorithms.",
      "tldr_zh": "本论文探讨了量子机器学习 (QML) 在对抗攻击下的模型无关边界，通过量子力学原理评估其鲁棒性。研究首次计算了对抗错误的下界，用于量化 QML 模型对复杂量子攻击的弹性，并通过实验与该边界进行比较。结果显示，实验错误在最佳情况下仅比估计下界高 10%，证明了 QML 模型的固有鲁棒性。该工作不仅深化了对量子模型弹性的理论理解，还为开发更可靠的 QML 算法提供了精确参考。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06863v1",
      "published_date": "2024-11-11 10:56:31 UTC",
      "updated_date": "2024-11-11 10:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:32:01.237892"
    },
    {
      "arxiv_id": "2411.06860v1",
      "title": "Enhancing Phishing Detection through Feature Importance Analysis and Explainable AI: A Comparative Study of CatBoost, XGBoost, and EBM Models",
      "title_zh": "通过特征重要性分析和可解释 AI 提升钓鱼检测：CatBoost、XGBoost 和 EBM 模型的比较研究",
      "authors": [
        "Abdullah Fajar",
        "Setiadi Yazid",
        "Indra Budi"
      ],
      "abstract": "Phishing attacks remain a persistent threat to online security, demanding\nrobust detection methods. This study investigates the use of machine learning\nto identify phishing URLs, emphasizing the crucial role of feature selection\nand model interpretability for improved performance. Employing Recursive\nFeature Elimination, the research pinpointed key features like \"length_url,\"\n\"time_domain_activation\" and \"Page_rank\" as strong indicators of phishing\nattempts. The study evaluated various algorithms, including CatBoost, XGBoost,\nand Explainable Boosting Machine, assessing their robustness and scalability.\nXGBoost emerged as highly efficient in terms of runtime, making it well-suited\nfor large datasets. CatBoost, on the other hand, demonstrated resilience by\nmaintaining high accuracy even with reduced features. To enhance transparency\nand trustworthiness, Explainable AI techniques, such as SHAP, were employed to\nprovide insights into feature importance. The study's findings highlight that\neffective feature selection and model interpretability can significantly\nbolster phishing detection systems, paving the way for more efficient and\nadaptable defenses against evolving cyber threats",
      "tldr_zh": "本研究通过特征重要性分析和可解释AI（Explainable AI）提升钓鱼URL检测性能，对CatBoost、XGBoost和EBM（Explainable Boosting Machine）模型进行比较评估。研究采用Recursive Feature Elimination（RFE）方法，识别出关键特征如“length_url”、“time_domain_activation”和“Page_rank”，这些特征被证明是钓鱼攻击的强有力指标。结果显示，XGBoost在运行时间上表现出色，适合处理大型数据集，而CatBoost在减少特征时仍保持高准确率；通过SHAP技术分析特征重要性，增强了模型的透明度和可信度。该研究强调，有效的特征选择和模型可解释性可显著强化钓鱼检测系统，对抗不断演变的网络威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06860v1",
      "published_date": "2024-11-11 10:49:24 UTC",
      "updated_date": "2024-11-11 10:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:32:14.400737"
    },
    {
      "arxiv_id": "2411.06858v1",
      "title": "Scientific machine learning in ecological systems: A study on the predator-prey dynamics",
      "title_zh": "科学机器学习在生态系统中的应用：捕食者-猎物动力学的研究",
      "authors": [
        "Ranabir Devgupta",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Lotka Volterra Predator Prey Model, a fundamental\necological model describing the dynamic interactions between predator and prey\npopulations. The Lotka-Volterra model is critical for understanding ecological\ndynamics, population control, and species interactions, as it is represented by\na system of differential equations. In this work, we aim to uncover the\nunderlying differential equations without prior knowledge of the system,\nrelying solely on training data and neural networks. Using robust modeling in\nthe Julia programming language, we demonstrate that both Neural ODEs and UDEs\ncan be effectively utilized for prediction and forecasting of the\nLotka-Volterra system. More importantly, we introduce the forecasting breakdown\npoint: the time at which forecasting fails for both Neural ODEs and UDEs. We\nobserve how UDEs outperform Neural ODEs by effectively recovering the\nunderlying dynamics and achieving accurate forecasting with significantly less\ntraining data. Additionally, we introduce Gaussian noise of varying magnitudes\n(from mild to high) to simulate real-world data perturbations and show that\nUDEs exhibit superior robustness, effectively recovering the underlying\ndynamics even in the presence of noisy data, while Neural ODEs struggle with\nhigh levels of noise. Through extensive hyperparameter optimization, we offer\ninsights into neural network architectures, activation functions, and\noptimizers that yield the best results. This study opens the door to applying\nScientific Machine Learning frameworks for forecasting tasks across a wide\nrange of ecological and scientific domains.",
      "tldr_zh": "本研究应用 Scientific Machine Learning 的两大支柱——Neural ODEs 和 UDEs——来分析 Lotka-Volterra Predator Prey Model，该模型通过微分方程描述生态系统中捕食者与猎物种群的动态交互。研究目标是通过训练数据和神经网络，无需先验知识揭示底层微分方程，并在 Julia 编程语言中验证这些方法在预测和预报方面的有效性。结果显示，UDEs 优于 Neural ODEs，能更准确地恢复动态、实现高效预报，并对 Gaussian noise 表现出更高的鲁棒性，即使在高噪声环境下也能维持性能。该工作通过超参数优化提供神经网络架构建议，并为 Scientific Machine Learning 在生态和科学领域预报任务的应用开辟新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.06858v1",
      "published_date": "2024-11-11 10:40:45 UTC",
      "updated_date": "2024-11-11 10:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:32:27.362566"
    },
    {
      "arxiv_id": "2411.06852v1",
      "title": "Evaluating Large Language Models on Financial Report Summarization: An Empirical Study",
      "title_zh": "评估大语言模型在财务报告摘要化上的表现：一个实证研究",
      "authors": [
        "Xinqi Yang",
        "Scott Zang",
        "Yong Ren",
        "Dingjie Peng",
        "Zheng Wen"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\nversatility across various applications, including natural language\nunderstanding, domain-specific knowledge tasks, etc. However, applying LLMs to\ncomplex, high-stakes domains like finance requires rigorous evaluation to\nensure reliability, accuracy, and compliance with industry standards. To\naddress this need, we conduct a comprehensive and comparative study on three\nstate-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their\neffectiveness in generating automated financial reports. Our primary motivation\nis to explore how these models can be harnessed within finance, a field\ndemanding precision, contextual relevance, and robustness against erroneous or\nmisleading information. By examining each model's capabilities, we aim to\nprovide an insightful assessment of their strengths and limitations. Our paper\noffers benchmarks for financial report analysis, encompassing proposed metrics\nsuch as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative\nevaluation framework that integrates both quantitative metrics (e.g.,\nprecision, recall) and qualitative analyses (e.g., contextual fit, consistency)\nto provide a holistic view of each model's output quality. Additionally, we\nmake our financial dataset publicly available, inviting researchers and\npractitioners to leverage, scrutinize, and enhance our findings through broader\ncommunity engagement and collaborative improvement. Our dataset is available on\nhuggingface.",
      "tldr_zh": "本研究通过实证方法评估了大型语言模型（LLMs）如 GLM-4、Mistral-NeMo 和 LLaMA3.1 在财务报告总结方面的表现，旨在确保这些模型在金融领域的可靠性、准确性和合规性。研究采用 ROUGE-1、BERT Score 和 LLM Score 等定量指标，以及定性分析（如上下文相关性和一致性），构建了一个全面的评估框架。结果突出了各模型的优缺点，并公开了财务数据集以促进社区协作和进一步改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06852v1",
      "published_date": "2024-11-11 10:36:04 UTC",
      "updated_date": "2024-11-11 10:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:32:38.020141"
    },
    {
      "arxiv_id": "2411.13566v1",
      "title": "Integrated Water Resource Management in the Segura Hydrographic Basin: An Artificial Intelligence Approach",
      "title_zh": "Segura 流域的综合水资源管理：人工智能方法",
      "authors": [
        "Urtzi Otamendi",
        "Mikel Maiza",
        "Igor G. Olaizola",
        "Basilio Sierra",
        "Markel Flores",
        "Marco Quartulli"
      ],
      "abstract": "Managing resources effectively in uncertain demand, variable availability,\nand complex governance policies is a significant challenge. This paper presents\na paradigmatic framework for addressing these issues in water management\nscenarios by integrating advanced physical modelling, remote sensing\ntechniques, and Artificial Intelligence algorithms. The proposed approach\naccurately predicts water availability, estimates demand, and optimizes\nresource allocation on both short- and long-term basis, combining a\ncomprehensive hydrological model, agronomic crop models for precise demand\nestimation, and Mixed-Integer Linear Programming for efficient resource\ndistribution. In the study case of the Segura Hydrographic Basin, the approach\nsuccessfully allocated approximately 642 million cubic meters ($hm^3$) of water\nover six months, minimizing the deficit to 9.7% of the total estimated demand.\nThe methodology demonstrated significant environmental benefits, reducing CO2\nemissions while optimizing resource distribution. This robust solution supports\ninformed decision-making processes, ensuring sustainable water management\nacross diverse contexts. The generalizability of this approach allows its\nadaptation to other basins, contributing to improved governance and policy\nimplementation on a broader scale. Ultimately, the methodology has been\nvalidated and integrated into the operational water management practices in the\nSegura Hydrographic Basin in Spain.",
      "tldr_zh": "本研究提出了一种整合高级物理建模、遥感技术和人工智能算法的框架，用于应对Segura Hydrographic Basin水资源管理的挑战，包括不确定需求、可变可用性和复杂治理政策。该框架通过结合全面水文模型、农作物模型和Mixed-Integer Linear Programming优化算法，精确预测水可用性、估计需求并实现短期和长期资源分配。在Segura Hydrographic Basin的案例中，该方法成功分配了约6.42亿立方米的水，需求缺口仅为9.7%，并显著减少了CO2排放。该框架已验证并应用于实际管理，并可推广到其他流域，支持可持续决策和政策实施。",
      "categories": [
        "cs.AI",
        "J.m; I.2.1; I.4.9"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 14 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.13566v1",
      "published_date": "2024-11-11 10:35:41 UTC",
      "updated_date": "2024-11-11 10:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:32:49.084299"
    },
    {
      "arxiv_id": "2411.06850v1",
      "title": "1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jebish Purbey",
        "Siddartha Pullakhandam",
        "Kanwal Mehreen",
        "Muhammad Arham",
        "Drishti Sharma",
        "Ashay Srivastava",
        "Ram Mohan Rao Kadiyala"
      ],
      "abstract": "This paper presents a detailed system description of our entry for the\nCHiPSAL 2025 shared task, focusing on language detection, hate speech\nidentification, and target detection in Devanagari script languages. We\nexperimented with a combination of large language models and their ensembles,\nincluding MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like\nfocal loss to address challenges in the natural understanding of Devanagari\nlanguages, such as multilingual processing and class imbalance. Our approach\nachieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804\nfor Sub-tasks A, B, and C respectively. This work provides insights into the\neffectiveness of transformer models in tasks with domain-specific and\nlinguistic challenges, as well as areas for potential improvement in future\niterations.",
      "tldr_zh": "这篇论文介绍了针对 Devanagari 脚本语言的自然语言理解（NLU）共享任务（CHiPSAL 2025）的系统，专注于语言检测、仇恨言论识别和目标检测，使用大型语言模型（LLMs）如 MuRIL、IndicBERT 和 Gemma-2 的集成方法。研究团队采用 focal loss 等技术来应对多语言处理和类别不平衡的挑战，提升了模型在这些领域的性能。结果显示，该系统在子任务 A、B 和 C 中分别取得了 F1 分数 0.9980、0.7652 和 0.6804 的竞争性表现。该工作突出了 transformer 模型在特定语言挑战中的有效性，并为未来迭代提供了改进建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, Submitted to CHIPSAL workshop @ COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.06850v1",
      "published_date": "2024-11-11 10:34:36 UTC",
      "updated_date": "2024-11-11 10:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:33:02.535804"
    },
    {
      "arxiv_id": "2411.06839v2",
      "title": "LLM-NEO: Parameter Efficient Knowledge Distillation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Runming Yang",
        "Taiqiang Wu",
        "Jiahao Wang",
        "Pengfei Hu",
        "Yik-Chung Wu",
        "Ngai Wong",
        "Yujiu Yang"
      ],
      "abstract": "Knowledge distillation (KD) has been a predominant method for compressing\nLarge Language Models (LLMs). In this paper, we first revisit KD and Low-Rank\nAdaption (LoRA) and demonstrate that they follow the same paradigm. Inspired by\nthis observation, we propose a parameter-efficient knowledge distillation\nmethod, LLM-NEO, which integrates LoRA into KD to improve the efficiency of\nknowledge transfer. After that, we summarize some valuable guidelines for the\nhyperparameters in LLM-NEO. Experimental results on compressing Llama 2 and\nLlama 3.2 show that LLM-NEO outperforms various baselines. Further analysis\ndemonstrates the robustness of the proposed LLM-NEO on variants of LoRA. The\ncode and trained models are available at\n[Github](https://github.com/yang3121099/LLM-Neo).",
      "tldr_zh": "本论文重新审视了知识蒸馏 (KD) 和 Low-Rank Adaption (LoRA)，发现它们遵循相同范式，并提出了一种参数高效的知识蒸馏方法 LLM-NEO，通过将 LoRA 整合到 KD 中，提高了大型语言模型 (LLMs) 的知识转移效率。该方法还总结了超参数的指导方针，以优化性能。在压缩 Llama 2 和 Llama 3.2 的实验中，LLM-NEO 超过了各种基线，并展示了在 LoRA 变体上的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ARR under review",
      "pdf_url": "http://arxiv.org/pdf/2411.06839v2",
      "published_date": "2024-11-11 10:07:51 UTC",
      "updated_date": "2025-02-25 06:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:33:13.428728"
    },
    {
      "arxiv_id": "2411.06833v1",
      "title": "Learning Interpretable Network Dynamics via Universal Neural Symbolic Regression",
      "title_zh": "通过通用神经符号回归学习可解释的网络动态",
      "authors": [
        "Jiao Hu",
        "Jiaxu Cui",
        "Bo Yang"
      ],
      "abstract": "Discovering governing equations of complex network dynamics is a fundamental\nchallenge in contemporary science with rich data, which can uncover the\nmysterious patterns and mechanisms of the formation and evolution of complex\nphenomena in various fields and assist in decision-making. In this work, we\ndevelop a universal computational tool that can automatically, efficiently, and\naccurately learn the symbolic changing patterns of complex system states by\ncombining the excellent fitting ability from deep learning and the equation\ninference ability from pre-trained symbolic regression. We conduct intensive\nexperimental verifications on more than ten representative scenarios from\nphysics, biochemistry, ecology, epidemiology, etc. Results demonstrate the\noutstanding effectiveness and efficiency of our tool by comparing with the\nstate-of-the-art symbolic regression techniques for network dynamics. The\napplication to real-world systems including global epidemic transmission and\npedestrian movements has verified its practical applicability. We believe that\nour tool can serve as a universal solution to dispel the fog of hidden\nmechanisms of changes in complex phenomena, advance toward interpretability,\nand inspire more scientific discoveries.",
      "tldr_zh": "本研究开发了一个通用计算工具，通过结合深度学习和预训练符号回归（Neural Symbolic Regression），自动、高效地学习复杂网络动态的符号变化模式，以揭示各种领域中复杂现象的形成和演化机制。实验在物理、生物化学、生态学和流行病学等十多个代表性场景中验证了该工具的优越性，其性能超过了现有的最先进符号回归技术。应用于真实世界系统，如全球疫情传播和行人运动，该工具展示了实际适用性，并有望作为通用解决方案，推动复杂现象的可解释性和科学发现。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2411.06833v1",
      "published_date": "2024-11-11 09:51:22 UTC",
      "updated_date": "2024-11-11 09:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:33:25.435914"
    },
    {
      "arxiv_id": "2411.06824v1",
      "title": "Combining Domain and Alignment Vectors to Achieve Better Knowledge-Safety Trade-offs in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Megh Thakkar",
        "Yash More",
        "Quentin Fournier",
        "Matthew Riemer",
        "Pin-Yu Chen",
        "Amal Zouaq",
        "Payel Das",
        "Sarath Chandar"
      ],
      "abstract": "There is a growing interest in training domain-expert LLMs that excel in\nspecific technical fields compared to their general-purpose instruction-tuned\ncounterparts. However, these expert models often experience a loss in their\nsafety abilities in the process, making them capable of generating harmful\ncontent. As a solution, we introduce an efficient and effective merging-based\nalignment method called \\textsc{MergeAlign} that interpolates the domain and\nalignment vectors, creating safer domain-specific models while preserving their\nutility. We apply \\textsc{MergeAlign} on Llama3 variants that are experts in\nmedicine and finance, obtaining substantial alignment improvements with minimal\nto no degradation on domain-specific benchmarks. We study the impact of model\nmerging through model similarity metrics and contributions of individual models\nbeing merged. We hope our findings open new research avenues and inspire more\nefficient development of safe expert LLMs.",
      "tldr_zh": "该研究探讨了训练领域专家大型语言模型（LLMs）时面临的权衡问题：这些模型在特定技术领域（如医学和金融）表现出色，但往往会丧失安全能力，导致生成有害内容。为解决此问题，作者提出了一种高效的合并方法 \\textsc{MergeAlign}，通过插值领域向量和对齐向量，创建更安全的领域特定模型，同时基本保持其领域性能。在 Llama3 变体上应用该方法后，模型在对齐指标上显著提升，而在领域基准测试中几乎无退化；此外，通过模型相似性指标分析了合并的影响。该方法有望为开发更高效、安全的专家 LLMs 开启新研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06824v1",
      "published_date": "2024-11-11 09:32:20 UTC",
      "updated_date": "2024-11-11 09:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:33:37.770247"
    },
    {
      "arxiv_id": "2411.06812v1",
      "title": "Generative midtended cognition and Artificial Intelligence. Thinging with thinging things",
      "title_zh": "翻译失败",
      "authors": [
        "Xabier E. Barandiaran",
        "Marta Pérez-Verdugo"
      ],
      "abstract": "This paper introduces the concept of ``generative midtended cognition'',\nexploring the integration of generative AI with human cognition. The term\n\"generative\" reflects AI's ability to iteratively produce structured outputs,\nwhile \"midtended\" captures the potential hybrid (human-AI) nature of the\nprocess. It stands between traditional conceptions of intended creation,\nunderstood directed from within, and extended processes that bring\nexo-biological processes into the creative process. We examine current\ngenerative technologies (based on multimodal transformer architectures typical\nof large language models like ChatGPT), to explain how they can transform human\ncognitive agency beyond what standard theories of extended cognition can\ncapture. We suggest that the type of cognitive activity typical of the coupling\nbetween a human and generative technologies is closer (but not equivalent) to\nsocial cognition than to classical extended cognitive paradigms. Yet, it\ndeserves a specific treatment. We provide an explicit definition of generative\nmidtended cognition in which we treat interventions by AI systems as\nconstitutive of the agent's intentional creative processes. Furthermore, we\ndistinguish two dimensions of generative hybrid creativity: 1. Width: captures\nthe sensitivity of the context of the generative process (from the single\nletter to the whole historical and surrounding data), 2. Depth: captures the\ngranularity of iteration loops involved in the process. Generative midtended\ncognition stands in the middle depth between conversational forms of cognition\nin which complete utterances or creative units are exchanged, and\nmicro-cognitive (e.g. neural) subpersonal processes. Finally, the paper\ndiscusses the potential risks and benefits of widespread generative AI\nadoption, including the challenges of authenticity, generative power asymmetry,\nand creative boost or atrophy.",
      "tldr_zh": "这篇论文引入了“generative midtended cognition”的概念，探讨生成式 AI 与人类认知的整合，将其描述为介于内部导向创造和扩展认知（extended cognition）之间的混合过程。作者分析基于多模态 transformer 架构的生成技术（如 ChatGPT），解释这些技术如何超越传统扩展认知理论，并将其与社会认知相比较。论文定义 generative midtended cognition，将 AI 系统干预视为代理者意图创造过程的组成部分，并区分了生成式混合创造性的两个维度：Width（上下文敏感度）和 Depth（迭代循环粒度）。此外，它强调 generative midtended cognition 位于对话式认知和微观（subpersonal）过程之间的中间深度。最后，论文讨论了生成式 AI 普及的潜在风险和益处，包括真实性（authenticity）挑战、权力不对称以及对创造力的增强或衰退。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 2 figures. Submitted to \"Synthese\" Journal, accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.06812v1",
      "published_date": "2024-11-11 09:14:27 UTC",
      "updated_date": "2024-11-11 09:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:33:51.185831"
    },
    {
      "arxiv_id": "2411.06810v1",
      "title": "JPEG AI Image Compression Visual Artifacts: Detection Methods and Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Daria Tsereh",
        "Mark Mirgaleev",
        "Ivan Molodetskikh",
        "Roman Kazantsev",
        "Dmitriy Vatolin"
      ],
      "abstract": "Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available.",
      "tldr_zh": "该论文探讨了基于神经网络的图像压缩方法（如JPEG AI）可能引入的visual artifacts问题，并提出方法来检测、定位和量化三种类型：texture and boundary degradation、color change和text corruption。这些方法仅针对neural compression导致的失真，而traditional codecs在相同bitrate下能成功恢复。研究人员使用这些方法处理了约35万张Open Images数据集图像，创建了一个包含46,440个经crowd-sourced主观评估验证的artifacts数据集。该数据集和方法可用于测试neural-network-based image codecs、识别bugs并提升性能，并已公开源代码和数据集。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06810v1",
      "published_date": "2024-11-11 09:11:01 UTC",
      "updated_date": "2024-11-11 09:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:34:01.437830"
    },
    {
      "arxiv_id": "2411.06805v1",
      "title": "AssistRAG: Boosting the Potential of Large Language Models with an Intelligent Information Assistant",
      "title_zh": "AssistRAG：利用智能信息助手提升大型语言模型的潜力",
      "authors": [
        "Yujia Zhou",
        "Zheng Liu",
        "Zhicheng Dou"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)存在的虚假信息生成(hallucination)问题，提出AssistRAG框架，通过整合一个智能信息助理来提升LLMs的潜力。该助理负责工具使用、行动执行、记忆构建和计划指定，并采用双阶段训练方法，包括Curriculum Assistant Learning和Reinforced Preference Optimization，以改进信息检索和决策能力。实验结果显示，AssistRAG在基准测试中显著优于现有方法，特别是对性能较弱的LLMs，提供更强的推理能力和准确响应。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024 (poster)",
      "pdf_url": "http://arxiv.org/pdf/2411.06805v1",
      "published_date": "2024-11-11 09:03:52 UTC",
      "updated_date": "2024-11-11 09:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:34:13.548915"
    },
    {
      "arxiv_id": "2411.06798v2",
      "title": "LA4SR: illuminating the dark proteome with generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "David R. Nelson",
        "Ashish Kumar Jaiswal",
        "Noha Ismail",
        "Alexandra Mystikou",
        "Kourosh Salehi-Ashtiani"
      ],
      "abstract": "AI language models (LMs) show promise for biological sequence analysis. We\nre-engineered open-source LMs (GPT-2, BLOOM, DistilRoBERTa, ELECTRA, and Mamba,\nranging from 70M to 12B parameters) for microbial sequence classification. The\nmodels achieved F1 scores up to 95 and operated 16,580x faster and at 2.9x the\nrecall of BLASTP. They effectively classified the algal dark proteome -\nuncharacterized proteins comprising about 65% of total proteins - validated on\nnew data including a new, complete Hi-C/Pacbio Chlamydomonas genome. Larger\n(>1B) LA4SR models reached high accuracy (F1 > 86) when trained on less than 2%\nof available data, rapidly achieving strong generalization capacity. High\naccuracy was achieved when training data had intact or scrambled terminal\ninformation, demonstrating robust generalization to incomplete sequences.\nFinally, we provide custom AI explainability software tools for attributing\namino acid patterns to AI generative processes and interpret their outputs in\nevolutionary and biophysical contexts.",
      "tldr_zh": "该研究引入 LA4SR 框架，利用生成式 AI 语言模型（如 GPT-2、BLOOM 和 ELECTRA，从 70M 到 12B 参数）重新设计用于微生物序列分类，这些模型的 F1 分数高达 95，比 BLASTP 快 16,580 倍且召回率高 2.9 倍。LA4SR 成功分类藻类暗蛋白质组（dark proteome），即占总蛋白质 65% 的未表征蛋白，并在新数据（如 Chlamydomonas 基因组）上验证其有效性。更大模型（>1B 参数）在训练数据少于 2% 时即可达到高准确率（F1 > 86），并展示对不完整序列的鲁棒泛化能力。最后，该框架提供自定义 AI 可解释性工具，用于分析氨基酸模式并从进化和生物物理角度解释输出。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06798v2",
      "published_date": "2024-11-11 08:51:18 UTC",
      "updated_date": "2024-12-11 11:10:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:34:26.677520"
    },
    {
      "arxiv_id": "2411.06792v1",
      "title": "Evolving Efficient Genetic Encoding for Deep Spiking Neural Networks",
      "title_zh": "用于深度脉冲神经网络的演化高效遗传编码",
      "authors": [
        "Wenxuan Pan",
        "Feifei Zhao",
        "Bing Han",
        "Haibo Tong",
        "Yi Zeng"
      ],
      "abstract": "By exploiting discrete signal processing and simulating brain neuron\ncommunication, Spiking Neural Networks (SNNs) offer a low-energy alternative to\nArtificial Neural Networks (ANNs). However, existing SNN models, still face\nhigh computational costs due to the numerous time steps as well as network\ndepth and scale. The tens of billions of neurons and trillions of synapses in\nthe human brain are developed from only 20,000 genes, which inspires us to\ndesign an efficient genetic encoding strategy that dynamic evolves to regulate\nlarge-scale deep SNNs at low cost. Therefore, we first propose a genetically\nscaled SNN encoding scheme that incorporates globally shared genetic\ninteractions to indirectly optimize neuronal encoding instead of weight, which\nobviously brings about reductions in parameters and energy consumption. Then, a\nspatio-temporal evolutionary framework is designed to optimize the inherently\ninitial wiring rules. Two dynamic regularization operators in the fitness\nfunction evolve the neuronal encoding to a suitable distribution and enhance\ninformation quality of the genetic interaction respectively, substantially\naccelerating evolutionary speed and improving efficiency. Experiments show that\nour approach compresses parameters by approximately 50\\% to 80\\%, while\noutperforming models on the same architectures by 0.21\\% to 4.38\\% on CIFAR-10,\nCIFAR-100 and ImageNet. In summary, the consistent trends of the proposed\ngenetically encoded spatio-temporal evolution across different datasets and\narchitectures highlight its significant enhancements in terms of efficiency,\nbroad scalability and robustness, demonstrating the advantages of the\nbrain-inspired evolutionary genetic coding for SNN optimization.",
      "tldr_zh": "本文提出了一种高效遗传编码策略，针对深度脉冲神经网络（SNNs）的计算成本问题，通过模拟人脑基因调控机制来动态优化大规模SNNs。具体方法包括遗传缩放编码方案，利用全局共享遗传交互间接优化神经元编码而非权重，并设计时空进化框架及动态正则化操作，以加速演化和提升信息质量。实验结果显示，该方法在CIFAR-10、CIFAR-100和ImageNet数据集上参数压缩50%至80%，性能比相同架构模型提升0.21%至4.38%，显著提高了SNNs的效率、可扩展性和鲁棒性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06792v1",
      "published_date": "2024-11-11 08:40:52 UTC",
      "updated_date": "2024-11-11 08:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:34:39.113376"
    },
    {
      "arxiv_id": "2411.06786v1",
      "title": "ScaleKD: Strong Vision Transformers Could Be Excellent Teachers",
      "title_zh": "ScaleKD：强大的视觉 Transformer 可能成为优秀的教师",
      "authors": [
        "Jiawei Fan",
        "Chao Li",
        "Xiaolong Liu",
        "Anbang Yao"
      ],
      "abstract": "In this paper, we question if well pre-trained vision transformer (ViT)\nmodels could be used as teachers that exhibit scalable properties to advance\ncross architecture knowledge distillation (KD) research, in the context of\nusing large-scale datasets for evaluation. To make this possible, our analysis\nunderlines the importance of seeking effective strategies to align (1) feature\ncomputing paradigm differences, (2) model scale differences, and (3) knowledge\ndensity differences. By combining three coupled components namely cross\nattention projector, dual-view feature mimicking and teacher parameter\nperception tailored to address the above problems, we present a simple and\neffective KD method, called ScaleKD. Our method can train student backbones\nthat span across a variety of convolutional neural network (CNN), multi-layer\nperceptron (MLP), and ViT architectures on image classification datasets,\nachieving state-of-the-art distillation performance. For instance, taking a\nwell pre-trained Swin-L as the teacher model, our method gets\n75.15%|82.03%|84.16%|78.63%|81.96%|83.93%|83.80%|85.53% top-1 accuracies for\nMobileNet-V1|ResNet-50|ConvNeXt-T|Mixer-S/16|Mixer-B/16|ViT-S/16|Swin-T|ViT-B/16\nmodels trained on ImageNet-1K dataset from scratch, showing\n3.05%|3.39%|2.02%|4.61%|5.52%|4.03%|2.62%|3.73% absolute gains to the\nindividually trained counterparts. Intriguingly, when scaling up the size of\nteacher models or their pre-training datasets, our method showcases the desired\nscalable properties, bringing increasingly larger gains to student models. The\nstudent backbones trained by our method transfer well on downstream MS-COCO and\nADE20K datasets. More importantly, our method could be used as a more efficient\nalternative to the time-intensive pre-training paradigm for any target student\nmodel if a strong pre-trained ViT is available, reducing the amount of viewed\ntraining samples up to 195x.",
      "tldr_zh": "本研究质疑预训练的 Vision Transformer (ViT) 模型是否能作为高效教师模型，提升跨架构知识蒸馏 (KD)，并提出 ScaleKD 方法来解决特征计算范式差异、模型规模差异和知识密度差异。该方法通过交叉注意力投影器 (cross attention projector)、双视图特征模仿 (dual-view feature mimicking) 和教师参数感知 (teacher parameter perception) 等组件，实现了对各种学生模型（如 CNN、MLP 和 ViT 架构）的训练优化。在 ImageNet-1K 数据集上，ScaleKD 使学生模型的 top-1 准确率提升了最高 5.52%，并展示出可扩展性：当教师模型或数据集规模增大时，学生模型收益更大，且在下游任务如 MS-COCO 和 ADE20K 上表现优秀，最终可将训练样本量减少高达 195 倍，提供更高效的模型训练替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work is accepted to NeurIPS 2024. The project page:\n  https://github.com/deep-optimization/ScaleKD",
      "pdf_url": "http://arxiv.org/pdf/2411.06786v1",
      "published_date": "2024-11-11 08:25:21 UTC",
      "updated_date": "2024-11-11 08:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:34:49.773782"
    },
    {
      "arxiv_id": "2411.06782v2",
      "title": "QuadWBG: Generalizable Quadrupedal Whole-Body Grasping",
      "title_zh": "翻译失败",
      "authors": [
        "Jilong Wang",
        "Javokhirbek Rajabov",
        "Chaoyi Xu",
        "Yiming Zheng",
        "He Wang"
      ],
      "abstract": "Legged robots with advanced manipulation capabilities have the potential to\nsignificantly improve household duties and urban maintenance. Despite\nconsiderable progress in developing robust locomotion and precise manipulation\nmethods, seamlessly integrating these into cohesive whole-body control for\nreal-world applications remains challenging. In this paper, we present a\nmodular framework for robust and generalizable whole-body loco-manipulation\ncontroller based on a single arm-mounted camera. By using reinforcement\nlearning (RL), we enable a robust low-level policy for command execution over 5\ndimensions (5D) and a grasp-aware high-level policy guided by a novel metric,\nGeneralized Oriented Reachability Map (GORM). The proposed system achieves\nstate-of-the-art one-time grasping accuracy of 89% in the real world, including\nchallenging tasks such as grasping transparent objects. Through extensive\nsimulations and real-world experiments, we demonstrate that our system can\neffectively manage a large workspace, from floor level to above body height,\nand perform diverse whole-body loco-manipulation tasks.",
      "tldr_zh": "这篇论文提出了QuadWBG框架，一个模块化的系统，用于实现四足机器人的通用整体抓取能力，旨在提升家庭和城市维护任务。框架基于强化学习 (RL) 开发，包括一个处理5维 (5D) 命令的稳健低级策略，以及由新型指标Generalized Oriented Reachability Map (GORM) 指导的抓取感知高级策略。该系统在真实世界实验中实现了89%的单次抓取准确率，包括挑战性任务如抓取透明物体，并证明了其在从地板到身体高度的大工作空间中进行多样化运动-操纵任务的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06782v2",
      "published_date": "2024-11-11 08:19:54 UTC",
      "updated_date": "2025-01-13 14:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:35:01.460155"
    },
    {
      "arxiv_id": "2411.06781v1",
      "title": "MP-PINN: A Multi-Phase Physics-Informed Neural Network for Epidemic Forecasting",
      "title_zh": "MP-PINN：多阶段物理信息神经网络用于流行病预测",
      "authors": [
        "Thang Nguyen",
        "Dung Nguyen",
        "Kha Pham",
        "Truyen Tran"
      ],
      "abstract": "Forecasting temporal processes such as virus spreading in epidemics often\nrequires more than just observed time-series data, especially at the beginning\nof a wave when data is limited. Traditional methods employ mechanistic models\nlike the SIR family, which make strong assumptions about the underlying\nspreading process, often represented as a small set of compact differential\nequations. Data-driven methods such as deep neural networks make no such\nassumptions and can capture the generative process in more detail, but fail in\nlong-term forecasting due to data limitations. We propose a new hybrid method\ncalled MP-PINN (Multi-Phase Physics-Informed Neural Network) to overcome the\nlimitations of these two major approaches. MP-PINN instils the spreading\nmechanism into a neural network, enabling the mechanism to update in phases\nover time, reflecting the dynamics of the epidemics due to policy\ninterventions. Experiments on COVID-19 waves demonstrate that MP-PINN achieves\nsuperior performance over pure data-driven or model-driven approaches for both\nshort-term and long-term forecasting.",
      "tldr_zh": "该研究针对疫情传播预测的挑战，指出传统机制模型（如 SIR 家族）依赖强假设，而数据驱动方法（如深度神经网络）虽能捕捉细节，但数据有限时长期预测表现不佳。作者提出 MP-PINN（Multi-Phase Physics-Informed Neural Network），一种混合方法，将传播机制融入神经网络中，并允许机制随时间分阶段更新，以反映政策干预等动态因素。在 COVID-19 波次实验中，MP-PINN 在短期和长期预测中均优于纯数据驱动或模型驱动方法，展示了其在数据有限场景下的卓越性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06781v1",
      "published_date": "2024-11-11 08:19:22 UTC",
      "updated_date": "2024-11-11 08:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:35:13.350723"
    },
    {
      "arxiv_id": "2411.06776v1",
      "title": "Machine vision-aware quality metrics for compressed image and video assessment",
      "title_zh": "针对机器",
      "authors": [
        "Mikhail Dremin",
        "Konstantin Kozhemyakov",
        "Ivan Molodetskikh",
        "Malakhov Kirill",
        "Artur Sagitov",
        "Dmitriy Vatolin"
      ],
      "abstract": "A main goal in developing video-compression algorithms is to enhance\nhuman-perceived visual quality while maintaining file size. But modern\nvideo-analysis efforts such as detection and recognition, which are integral to\nvideo surveillance and autonomous vehicles, involve so much data that they\nnecessitate machine-vision processing with minimal human intervention. In such\ncases, the video codec must be optimized for machine vision. This paper\nexplores the effects of compression on detection and recognition algorithms\n(objects, faces, and license plates) and introduces novel full-reference\nimage/video-quality metrics for each task, tailored to machine vision.\nExperimental results indicate our proposed metrics correlate better with the\nmachine-vision results for the respective tasks than do existing\nimage/video-quality metrics.",
      "tldr_zh": "该论文探讨了视频压缩算法在机器视觉任务（如对象检测、面部识别和车牌识别）中的优化问题，强调传统算法虽注重人类感知视觉质量，但需针对 machine vision 进行调整，以支持视频监控和自动驾驶等应用。作者引入了新型 full-reference image/video-quality metrics，这些指标专门针对上述任务设计，用于评估压缩对检测和识别算法的影响。实验结果显示，这些新指标与机器视觉结果的相关性显著优于现有质量指标，从而提升了机器处理效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06776v1",
      "published_date": "2024-11-11 08:07:34 UTC",
      "updated_date": "2024-11-11 08:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:35:26.023423"
    },
    {
      "arxiv_id": "2411.06772v1",
      "title": "A Text Classification Model Combining Adversarial Training with Pre-trained Language Model and neural networks: A Case Study on Telecom Fraud Incident Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Zhuoxian",
        "Shi Tuo",
        "Hu Xiaofeng"
      ],
      "abstract": "Front-line police officers often categorize all police call reported cases of\nTelecom Fraud into 14 subcategories to facilitate targeted prevention measures,\nsuch as precise public education. However, the associated data is characterized\nby its large volume, diverse information content, and variations in expression.\nCurrently, there is a lack of efficient and accurate intelligent models to\nreplace manual classification, which, while precise, is relatively inefficient.\nTo address these challenges, this paper proposes a text classification model\nthat combines adversarial training with Pre-trained Language Model and neural\nnetworks. The Linguistically-motivated Pre-trained Language Model model\nextracts three types of language features and then utilizes the Fast Gradient\nMethod algorithm to perturb the generated embedding layer. Subsequently, the\nBi-directional Long Short-Term Memory and Convolutional Neural Networks\nnetworks extract contextual syntactic information and local semantic\ninformation, respectively. The model achieved an 83.9% classification accuracy\nwhen trained on a portion of telecom fraud case data provided by the\noperational department. The model established in this paper has been deployed\nin the operational department, freeing up a significant amount of manpower and\nimproving the department's efficiency in combating Telecom Fraud crimes.\nFurthermore, considering the universality of the model established in this\npaper, other application scenarios await further exploration.",
      "tldr_zh": "本研究针对电信欺诈案件的文本分类问题，提出了一种结合adversarial training、Pre-trained Language Model和neural networks的模型，以解决数据量大、信息多样和表达变化带来的分类挑战。该模型使用Linguistically-motivated Pre-trained Language Model提取三种语言特征，并通过Fast Gradient Method算法扰动嵌入层，随后利用Bi-directional Long Short-Term Memory提取上下文语法信息，以及Convolutional Neural Networks提取局部语义信息。在电信欺诈案例数据上训练后，模型达到了83.9%的分类准确率，已部署于相关部门，显著解放人力并提升打击犯罪效率。该模型具有通用性，可扩展至其他应用场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06772v1",
      "published_date": "2024-11-11 07:52:38 UTC",
      "updated_date": "2024-11-11 07:52:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:35:38.830980"
    },
    {
      "arxiv_id": "2411.06767v1",
      "title": "PDC & DM-SFT: A Road for LLM SQL Bug-Fix Enhancing",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Duan",
        "Yonghong Yu",
        "Xiaoming Zhao",
        "Yichang Wu",
        "Wenbo Liu"
      ],
      "abstract": "Code Large Language Models (Code LLMs), such as Code llama and\nDeepSeek-Coder, have demonstrated exceptional performance in the code\ngeneration tasks. However, most existing models focus on the abilities of\ngenerating correct code, but often struggle with bug repair. We introduce a\nsuit of methods to enhance LLM's SQL bug-fixing abilities. The methods are\nmainly consisted of two parts: A Progressive Dataset Construction (PDC) from\nscratch and Dynamic Mask Supervised Fine-tuning (DM-SFT). PDC proposes two data\nexpansion methods from the perspectives of breadth first and depth first\nrespectively. DM-SFT introduces an efficient bug-fixing supervised learning\napproach, which effectively reduce the total training steps and mitigate the\n\"disorientation\" in SQL code bug-fixing training. In our evaluation, the code\nLLM models trained with two methods have exceeds all current best performing\nmodel which size is much larger.",
      "tldr_zh": "该论文针对 Code LLMs（如 Code Llama 和 DeepSeek-Coder）在 SQL 错误修复方面的不足，提出两种方法：Progressive Dataset Construction (PDC) 和 Dynamic Mask Supervised Fine-tuning (DM-SFT)。PDC 通过广度优先和深度优先的数据扩展，从零构建数据集，以丰富训练资源；DM-SFT 则采用高效的监督学习策略，减少训练步骤并缓解 SQL 代码修复中的“disorientation”问题。实验结果显示，使用这些方法的模型超过了规模更大的现有最佳模型，在 SQL bug-fixing 任务上表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING-Industry 2025 accepted",
      "pdf_url": "http://arxiv.org/pdf/2411.06767v1",
      "published_date": "2024-11-11 07:47:20 UTC",
      "updated_date": "2024-11-11 07:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:35:50.341779"
    },
    {
      "arxiv_id": "2411.06765v1",
      "title": "Research on an intelligent fault diagnosis method for nuclear power plants based on ETCN-SSA combined algorithm",
      "title_zh": "基于 ETCN-SSA 组合算法的核电站智能故障诊断方法研究",
      "authors": [
        "Jiayan Fang",
        "Siwei Li",
        "Yichun Wu"
      ],
      "abstract": "Utilizing fault diagnosis methods is crucial for nuclear power professionals\nto achieve efficient and accurate fault diagnosis for nuclear power plants\n(NPPs). The performance of traditional methods is limited by their dependence\non complex feature extraction and skilled expert knowledge, which can be\ntime-consuming and subjective. This paper proposes a novel intelligent fault\ndiagnosis method for NPPs that combines enhanced temporal convolutional network\n(ETCN) with sparrow search algorithm (SSA). ETCN utilizes temporal\nconvolutional network (TCN), self-attention (SA) mechanism and residual block\nfor enhancing performance. ETCN excels at extracting local features and\ncapturing time series information, while SSA adaptively optimizes its\nhyperparameters for superior performance. The proposed method's performance is\nexperimentally verified on a CPR1000 simulation dataset. Compared to other\nadvanced intelligent fault diagnosis methods, the proposed one demonstrates\nsuperior performance across all evaluation metrics. This makes it a promising\ntool for NPP intelligent fault diagnosis, ultimately enhancing operational\nreliability.",
      "tldr_zh": "本研究针对核电站（NPPs）的故障诊断问题，提出了一种基于ETCN-SSA结合算法的智能方法，以克服传统方法依赖复杂特征提取和专家知识的局限性。ETCN整合了时间卷积网络（TCN）、自注意力机制（SA）和残差块，能够高效提取局部特征并捕获时间序列信息，而SSA则用于自适应优化ETCN的超参数。在CPR1000模拟数据集上的实验验证显示，该方法在所有评估指标上优于其他先进方法，提升了诊断准确性和效率。该方法有望作为可靠工具，提高核电站的运行可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06765v1",
      "published_date": "2024-11-11 07:43:12 UTC",
      "updated_date": "2024-11-11 07:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:36:01.262742"
    },
    {
      "arxiv_id": "2411.06749v1",
      "title": "KLCBL: An Improved Police Incident Classification Model",
      "title_zh": "KLCBL：改进的警察事件分类模型",
      "authors": [
        "Liu Zhuoxian",
        "Shi Tuo",
        "Hu Xiaofeng"
      ],
      "abstract": "Police incident data is crucial for public security intelligence, yet\ngrassroots agencies struggle with efficient classification due to manual\ninefficiency and automated system limitations, especially in telecom and online\nfraud cases. This research proposes a multichannel neural network model, KLCBL,\nintegrating Kolmogorov-Arnold Networks (KAN), a linguistically enhanced text\npreprocessing approach (LERT), Convolutional Neural Network (CNN), and\nBidirectional Long Short-Term Memory (BiLSTM) for police incident\nclassification. Evaluated with real data, KLCBL achieved 91.9% accuracy,\noutperforming baseline models. The model addresses classification challenges,\nenhances police informatization, improves resource allocation, and offers broad\napplicability to other classification tasks.",
      "tldr_zh": "本研究针对警察事件分类中的手动效率低和自动化系统限制问题（如电信和在线欺诈案件），提出了一种改进的多通道神经网络模型KLCBL。KLCBL整合了Kolmogorov-Arnold Networks (KAN)、语言增强文本预处理方法(LERT)、Convolutional Neural Network (CNN)以及Bidirectional Long Short-Term Memory (BiLSTM)，以提升分类准确性。在真实数据评估中，该模型达到了91.9%的准确率，优于基线模型。KLCBL不仅解决了分类挑战，还提高了警察信息化水平、优化了资源分配，并可扩展应用于其他分类任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06749v1",
      "published_date": "2024-11-11 07:02:23 UTC",
      "updated_date": "2024-11-11 07:02:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:36:13.112582"
    },
    {
      "arxiv_id": "2411.06740v4",
      "title": "Dockformer: A transformer-based molecular docking paradigm for large-scale virtual screening",
      "title_zh": "Dockformer：一种基于 Transformer 的分子对接范式，用于大规模虚拟筛选",
      "authors": [
        "Zhangfan Yang",
        "Junkai Ji",
        "Shan He",
        "Jianqiang Li",
        "Tiantian He",
        "Ruibin Bai",
        "Zexuan Zhu",
        "Yew Soon Ong"
      ],
      "abstract": "Molecular docking is a crucial step in drug development, which enables the\nvirtual screening of compound libraries to identify potential ligands that\ntarget proteins of interest. However, the computational complexity of\ntraditional docking models increases as the size of the compound library\nincreases. Recently, deep learning algorithms can provide data-driven research\nand development models to increase the speed of the docking process.\nUnfortunately, few models can achieve superior screening performance compared\nto that of traditional models. Therefore, a novel deep learning-based docking\napproach named Dockformer is introduced in this study. Dockformer leverages\nmultimodal information to capture the geometric topology and structural\nknowledge of molecules and can directly generate binding conformations with the\ncorresponding confidence measures in an end-to-end manner. The experimental\nresults show that Dockformer achieves success rates of 90.53% and 82.71% on the\nPDBbind core set and PoseBusters benchmarks, respectively, and more than a\n100-fold increase in the inference process speed, outperforming almost all\nstate-of-the-art docking methods. In addition, the ability of Dockformer to\nidentify the main protease inhibitors of coronaviruses is demonstrated in a\nreal-world virtual screening scenario. Considering its high docking accuracy\nand screening efficiency, Dockformer can be regarded as a powerful and robust\ntool in the field of drug design.",
      "tldr_zh": "本研究提出了一种基于 Transformer 的分子对接方法 Dockformer，用于大规模虚拟筛选，以解决传统模型计算复杂度高的问题。Dockformer 利用多模态信息捕获分子的几何拓扑和结构知识，并能端到端生成结合构象及其置信度。实验结果显示，该方法在 PDBbind core set 和 PoseBusters 基准上分别达到 90.53% 和 82.71% 的成功率，推理速度比现有方法提高 100 倍以上，并在实际场景中成功识别冠状病毒主蛋白酶抑制剂。作为药物设计领域的强大工具，Dockformer 显著提升了筛选效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06740v4",
      "published_date": "2024-11-11 06:25:13 UTC",
      "updated_date": "2024-12-05 14:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:36:26.434728"
    },
    {
      "arxiv_id": "2411.06735v2",
      "title": "Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data",
      "title_zh": "多模态预测器：联合预测时间序列和文本数据",
      "authors": [
        "Kai Kim",
        "Howard Tsai",
        "Rajat Sen",
        "Abhimanyu Das",
        "Zihao Zhou",
        "Abhishek Tanpure",
        "Mathew Luo",
        "Rose Yu"
      ],
      "abstract": "Current forecasting approaches are largely unimodal and ignore the rich\ntextual data that often accompany the time series due to lack of well-curated\nmultimodal benchmark dataset. In this work, we develop TimeText Corpus (TTC), a\ncarefully curated, time-aligned text and time dataset for multimodal\nforecasting. Our dataset is composed of sequences of numbers and text aligned\nto timestamps, and includes data from two different domains: climate science\nand healthcare. Our data is a significant contribution to the rare selection of\navailable multimodal datasets. We also propose the Hybrid Multi-Modal\nForecaster (Hybrid-MMF), a multimodal LLM that jointly forecasts both text and\ntime series data using shared embeddings. However, contrary to our\nexpectations, our Hybrid-MMF model does not outperform existing baselines in\nour experiments. This negative result highlights the challenges inherent in\nmultimodal forecasting. Our code and data are available at\nhttps://github.com/Rose-STL-Lab/Multimodal_ Forecasting.",
      "tldr_zh": "本研究指出，现有的预测方法多为单模态，忽略了时间序列数据中伴随的文本信息，并为此开发了TimeText Corpus (TTC)，一个精心策划的时间对齐文本和时间序列数据集，涵盖气候科学和医疗领域。该数据集填补了多模态基准数据集的空白，促进多模态预测的研究。作者提出Hybrid Multi-Modal Forecaster (Hybrid-MMF)，一个基于多模态LLM的模型，使用共享嵌入来联合预测文本和时间序列数据。然而，在实验中，Hybrid-MMF并未超越现有基线模型，这一负面结果突显了多模态预测的固有挑战。代码和数据已在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 4 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06735v2",
      "published_date": "2024-11-11 06:04:15 UTC",
      "updated_date": "2024-11-21 00:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:36:37.330966"
    },
    {
      "arxiv_id": "2411.06728v1",
      "title": "On the Principles of ReLU Networks with One Hidden Layer",
      "title_zh": "翻译失败",
      "authors": [
        "Changcun Huang"
      ],
      "abstract": "A neural network with one hidden layer or a two-layer network (regardless of\nthe input layer) is the simplest feedforward neural network, whose mechanism\nmay be the basis of more general network architectures. However, even to this\ntype of simple architecture, it is also a ``black box''; that is, it remains\nunclear how to interpret the mechanism of its solutions obtained by the\nback-propagation algorithm and how to control the training process through a\ndeterministic way. This paper systematically studies the first problem by\nconstructing universal function-approximation solutions. It is shown that, both\ntheoretically and experimentally, the training solution for the one-dimensional\ninput could be completely understood, and that for a higher-dimensional input\ncan also be well interpreted to some extent. Those results pave the way for\nthoroughly revealing the black box of two-layer ReLU networks and advance the\nunderstanding of deep ReLU networks.",
      "tldr_zh": "这篇论文探讨了单隐藏层 ReLU 网络的原理，旨在揭示其作为“黑箱”的机制，包括如何解释通过 back-propagation 算法得到的解决方案以及通过确定性方式控制训练过程。研究者通过构建通用函数逼近解决方案，理论和实验上证明了对一维输入的训练结果可以完全理解，而高维输入也能部分解释。这些发现为彻底揭示两层 ReLU 网络的内部机制并推进对深度 ReLU 网络的理解奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "68T07(Primary), 41A15(Secondary)",
        "I.2.6; G.1.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06728v1",
      "published_date": "2024-11-11 05:51:11 UTC",
      "updated_date": "2024-11-11 05:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:36:49.635557"
    },
    {
      "arxiv_id": "2411.06723v1",
      "title": "Script-Strategy Aligned Generation: Aligning LLMs with Expert-Crafted Dialogue Scripts and Therapeutic Strategies for Psychotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Sun",
        "Jan de Wit",
        "Zhuying Li",
        "Jiahuan Pei",
        "Abdallah El Ali",
        "Jos A. Bosch"
      ],
      "abstract": "Chatbots or conversational agents (CAs) are increasingly used to improve\naccess to digital psychotherapy. Many current systems rely on rigid, rule-based\ndesigns, heavily dependent on expert-crafted dialogue scripts for guiding\ntherapeutic conversations. Although recent advances in large language models\n(LLMs) offer the potential for more flexible interactions, their lack of\ncontrollability and transparency poses significant challenges in sensitive\nareas like psychotherapy. In this work, we explored how aligning LLMs with\nexpert-crafted scripts can enhance psychotherapeutic chatbot performance. Our\ncomparative study showed that LLMs aligned with expert-crafted scripts through\nprompting and fine-tuning significantly outperformed both pure LLMs and\nrule-based chatbots, achieving a more effective balance between dialogue\nflexibility and adherence to therapeutic principles. Building on findings, we\nproposed ``Script-Strategy Aligned Generation (SSAG)'', a flexible alignment\napproach that reduces reliance on fully scripted content while enhancing LLMs'\ntherapeutic adherence and controllability. In a 10-day field study, SSAG\ndemonstrated performance comparable to full script alignment and outperformed\nrule-based chatbots, empirically supporting SSAG as an efficient approach for\naligning LLMs with domain expertise. Our work advances LLM applications in\npsychotherapy by providing a controllable, adaptable, and scalable solution for\ndigital interventions, reducing reliance on expert effort. It also provides a\ncollaborative framework for domain experts and developers to efficiently build\nexpertise-aligned chatbots, broadening access to psychotherapy and behavioral\ninterventions.",
      "tldr_zh": "本研究探讨了如何通过提示和微调，将大语言模型(LLMs)与专家编写的对话脚本和治疗策略对齐，以提升心理治疗聊天机器人的性能，从而解决LLMs在敏感领域缺乏可控性和透明度的挑战。研究提出“Script-Strategy Aligned Generation (SSAG)”方法，这是一种灵活的对齐框架，能减少对完整脚本的依赖，同时提高LLMs的治疗依从性和对话灵活性。在10天现场研究中，SSAG的表现与完全脚本对齐相当，并优于规则-based聊天机器人，为LLMs在心理治疗中的应用提供了一个可控、可适应且可扩展的解决方案，减少了对专家努力的依赖并促进专家与开发者的协作。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06723v1",
      "published_date": "2024-11-11 05:14:14 UTC",
      "updated_date": "2024-11-11 05:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:37:01.791632"
    },
    {
      "arxiv_id": "2411.06722v1",
      "title": "Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models",
      "title_zh": "合成、分区，然后适应：从基础模型中提取多样样本",
      "authors": [
        "Yeming Wen",
        "Swarat Chaudhuri"
      ],
      "abstract": "Presenting users with diverse responses from foundation models is crucial for\nenhancing user experience and accommodating varying preferences. However,\ngenerating multiple high-quality and diverse responses without sacrificing\naccuracy remains a challenge, especially when using greedy sampling. In this\nwork, we propose a novel framework, Synthesize-Partition-Adapt (SPA), that\nleverages the abundant synthetic data available in many domains to elicit\ndiverse responses from foundation models. By leveraging signal provided by data\nattribution methods such as influence functions, SPA partitions data into\nsubsets, each targeting unique aspects of the data, and trains multiple model\nadaptations optimized for these subsets. Experimental results demonstrate the\neffectiveness of our approach in diversifying foundation model responses while\nmaintaining high quality, showcased through the HumanEval and MBPP tasks in the\ncode generation domain and several tasks in the natural language understanding\ndomain, highlighting its potential to enrich user experience across various\napplications.",
      "tldr_zh": "该研究提出了一种名为 Synthesize-Partition-Adapt (SPA) 的框架，用于从基础模型中生成多样化的响应，从而提升用户体验并满足不同偏好，同时避免牺牲准确性。SPA 方法利用合成数据，通过 influence functions 等数据归因技术将数据分区成针对独特方面的子集，然后针对这些子集训练多个模型适应。实验结果显示，该框架在代码生成任务（如 HumanEval 和 MBPP）以及自然语言理解领域表现出色，能够显著提高响应多样性，同时保持高质量表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06722v1",
      "published_date": "2024-11-11 05:13:21 UTC",
      "updated_date": "2024-11-11 05:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:37:13.448571"
    },
    {
      "arxiv_id": "2411.06714v1",
      "title": "DiffSR: Learning Radar Reflectivity Synthesis via Diffusion Model from Satellite Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Xuming He",
        "Zhiwang Zhou",
        "Wenlong Zhang",
        "Xiangyu Zhao",
        "Hao Chen",
        "Shiqi Chen",
        "Lei Bai"
      ],
      "abstract": "Weather radar data synthesis can fill in data for areas where ground\nobservations are missing. Existing methods often employ reconstruction-based\napproaches with MSE loss to reconstruct radar data from satellite observation.\nHowever, such methods lead to over-smoothing, which hinders the generation of\nhigh-frequency details or high-value observation areas associated with\nconvective weather. To address this issue, we propose a two-stage\ndiffusion-based method called DiffSR. We first pre-train a reconstruction model\non global-scale data to obtain radar estimation and then synthesize radar\nreflectivity by combining radar estimation results with satellite data as\nconditions for the diffusion model. Extensive experiments show that our method\nachieves state-of-the-art (SOTA) results, demonstrating the ability to generate\nhigh-frequency details and high-value areas.",
      "tldr_zh": "该研究针对现有基于MSE loss的重建方法在合成weather radar data时导致over-smoothing问题，提出了一种two-stage diffusion-based方法DiffSR，以从satellite observations生成更精确的radar reflectivity。首先，通过在全球规模数据上预训练一个reconstruction model来获取radar estimation，然后将该结果与satellite data结合作为条件输入diffusion model进行合成。实验结果显示，DiffSR达到了state-of-the-art (SOTA)性能，能够有效生成高频细节和高值区域，从而提升了天气雷达数据合成的质量。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06714v1",
      "published_date": "2024-11-11 04:50:34 UTC",
      "updated_date": "2024-11-11 04:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:37:25.561713"
    },
    {
      "arxiv_id": "2411.06713v1",
      "title": "Ambient AI Scribing Support: Comparing the Performance of Specialized AI Agentic Architecture to Leading Foundational Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chanseo Lee",
        "Sonu Kumar",
        "Kimon A. Vogt",
        "Sam Meraj"
      ],
      "abstract": "This study compares Sporo Health's AI Scribe, a proprietary model fine-tuned\nfor medical scribing, with various LLMs (GPT-4o, GPT-3.5, Gemma-9B, and\nLlama-3.2-3B) in clinical documentation. We analyzed de-identified patient\ntranscripts from partner clinics, using clinician-provided SOAP notes as the\nground truth. Each model generated SOAP summaries using zero-shot prompting,\nwith performance assessed via recall, precision, and F1 scores. Sporo\noutperformed all models, achieving the highest recall (73.3%), precision\n(78.6%), and F1 score (75.3%) with the lowest performance variance.\nStatistically significant differences (p < 0.05) were found between Sporo and\nthe other models, with post-hoc tests showing significant improvements over\nGPT-3.5, Gemma-9B, and Llama 3.2-3B. While Sporo outperformed GPT-4o by up to\n10%, the difference was not statistically significant (p = 0.25). Clinical user\nsatisfaction, measured with a modified PDQI-9 inventory, favored Sporo.\nEvaluations indicated Sporo's outputs were more accurate and relevant. This\nhighlights the potential of Sporo's multi-agentic architecture to improve\nclinical workflows.",
      "tldr_zh": "本研究比较了Sporo Health的AI Scribe（一个针对医疗记录微调的专有模型）与主流LLMs（如GPT-4o、GPT-3.5、Gemma-9B和Llama-3.2-3B）在临床文档生成中的性能，使用脱敏患者转录和临床医生提供的SOAP笔记作为基准。模型通过零-shot prompting生成SOAP总结，并以recall、precision和F1 score进行评估，结果显示Sporo取得了最高的recall（73.3%）、precision（78.6%）和F1 score（75.3%），且性能方差最低，与其他模型的差异具有统计显著性（p < 0.05）。尽管Sporo比GPT-4o高出10%但未达显著水平（p = 0.25），临床用户满意度调查（如修改后的PDQI-9）也更青睐Sporo，这突显了其多-agentic架构在提升临床工作流程方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2410.15528",
      "pdf_url": "http://arxiv.org/pdf/2411.06713v1",
      "published_date": "2024-11-11 04:45:48 UTC",
      "updated_date": "2024-11-11 04:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:37:39.432470"
    },
    {
      "arxiv_id": "2411.06711v1",
      "title": "Anytime Probabilistically Constrained Provably Convergent Online Belief Space Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Andrey Zhitnikov",
        "Vadim Indelman"
      ],
      "abstract": "Taking into account future risk is essential for an autonomously operating\nrobot to find online not only the best but also a safe action to execute. In\nthis paper, we build upon the recently introduced formulation of probabilistic\nbelief-dependent constraints. We present an anytime approach employing the\nMonte Carlo Tree Search (MCTS) method in continuous domains. Unlike previous\napproaches, our method assures safety anytime with respect to the currently\nexpanded search tree without relying on the convergence of the search. We prove\nconvergence in probability with an exponential rate of a version of our\nalgorithms and study proposed techniques via extensive simulations. Even with a\ntiny number of tree queries, the best action found by our approach is much\nsafer than the baseline. Moreover, our approach constantly finds better than\nthe baseline action in terms of objective. This is because we revise the values\nand statistics maintained in the search tree and remove from them the\ncontribution of the pruned actions.",
      "tldr_zh": "该论文提出了一种随时可用（anytime）的在线信念空间规划方法，基于概率信念依赖约束，利用Monte Carlo Tree Search (MCTS) 在连续域中确保机器人选择最佳且安全的行动。\n该方法的关键创新在于，在搜索树扩展过程中随时维护安全性，而不依赖于搜索的完全收敛，并证明了算法版本的概率收敛性，具有指数级速率。\n实验模拟结果显示，即使在少量树查询下，该方法比基线模型提供更安全的行动，并在优化目标方面表现出色，因为它通过修正搜索树中的值和统计来去除被修剪行动的影响。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2302.10439 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2411.06711v1",
      "published_date": "2024-11-11 04:42:18 UTC",
      "updated_date": "2024-11-11 04:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:37:49.540978"
    },
    {
      "arxiv_id": "2411.06710v2",
      "title": "Model Fusion through Bayesian Optimization in Language Model Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chaeyun Jang",
        "Hyungi Lee",
        "Jungtaek Kim",
        "Juho Lee"
      ],
      "abstract": "Fine-tuning pre-trained models for downstream tasks is a widely adopted\ntechnique known for its adaptability and reliability across various domains.\nDespite its conceptual simplicity, fine-tuning entails several troublesome\nengineering choices, such as selecting hyperparameters and determining\ncheckpoints from an optimization trajectory. To tackle the difficulty of\nchoosing the best model, one effective solution is model fusion, which combines\nmultiple models in a parameter space. However, we observe a large discrepancy\nbetween loss and metric landscapes during the fine-tuning of pre-trained\nlanguage models. Building on this observation, we introduce a novel model\nfusion technique that optimizes both the desired metric and loss through\nmulti-objective Bayesian optimization. In addition, to effectively select\nhyperparameters, we establish a two-stage procedure by integrating Bayesian\noptimization processes into our framework. Experiments across various\ndownstream tasks show considerable performance improvements using our Bayesian\noptimization-guided method.",
      "tldr_zh": "本论文探讨了语言模型微调过程中选择超参数和检查点的工程挑战，提出了一种通过多目标Bayesian Optimization优化的模型融合技术，以解决损失和指标景观之间存在的显著差异。\n该方法结合多目标Bayesian Optimization来同时优化所需指标和损失，并采用两阶段过程来有效选择超参数，从而在参数空间中融合多个模型。\n实验结果显示，在各种下游任务上，该框架显著提升了性能，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06710v2",
      "published_date": "2024-11-11 04:36:58 UTC",
      "updated_date": "2024-12-27 04:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:38:01.242702"
    },
    {
      "arxiv_id": "2411.06691v1",
      "title": "Autonomous Droplet Microfluidic Design Framework with Large Language Models",
      "title_zh": "自主液滴微流控设计框架结合大型语言模型",
      "authors": [
        "Dinh-Nguyen Nguyen",
        "Raymond Kai-Yu Tong",
        "Ngoc-Duy Dinh"
      ],
      "abstract": "Droplet-based microfluidic devices have substantial promise as cost-effective\nalternatives to current assessment tools in biological research. Moreover,\nmachine learning models that leverage tabular data, including input design\nparameters and their corresponding efficiency outputs, are increasingly\nutilised to automate the design process of these devices and to predict their\nperformance. However, these models fail to fully leverage the data presented in\nthe tables, neglecting crucial contextual information, including column\nheadings and their associated descriptions. This study presents\nMicroFluidic-LLMs, a framework designed for processing and feature extraction,\nwhich effectively captures contextual information from tabular data formats.\nMicroFluidic-LLMs overcomes processing challenges by transforming the content\ninto a linguistic format and leveraging pre-trained large language models\n(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11\nprediction tasks, covering aspects such as geometry, flow conditions, regimes,\nand performance, utilising a publicly available dataset on flow-focusing\ndroplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can\nempower deep neural network models to be highly effective and straightforward\nwhile minimising the need for extensive data preprocessing. Moreover, the\nexceptional performance of deep neural network models, particularly when\ncombined with advanced natural language processing models such as DistilBERT\nand GPT-2, reduces the mean absolute error in the droplet diameter and\ngeneration rate by nearly 5- and 7-fold, respectively, and enhances the regime\nclassification accuracy by over 4%, compared with the performance reported in a\nprevious study. This study lays the foundation for the huge potential\napplications of LLMs and machine learning in a wider spectrum of microfluidic\napplications.",
      "tldr_zh": "这篇论文提出 MicroFluidic-LLMs 框架，利用 Large Language Models (LLMs) 处理微滴基微流体设备的表格数据，捕获上下文信息如列标题和描述，以克服传统机器学习模型的局限性。框架通过将数据转化为语言格式，并结合预训练模型如 DistilBERT 和 GPT-2，与深度神经网络集成，实现自动化设计和性能预测。实验在 11 个任务上评估，包括几何、流动条件和性能指标，使用公开数据集，结果显示微滴直径的平均绝对误差减少约 5 倍，生成速率减少约 7 倍，模式分类准确率提高超过 4%。这项研究为 LLMs 在更广泛微流体应用中的潜力应用奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06691v1",
      "published_date": "2024-11-11 03:20:53 UTC",
      "updated_date": "2024-11-11 03:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:38:14.498497"
    },
    {
      "arxiv_id": "2411.06685v2",
      "title": "High-Frequency Enhanced Hybrid Neural Representation for Video Compression",
      "title_zh": "高频增强混合神经表示用于视频压缩",
      "authors": [
        "Li Yu",
        "Zhihui Li",
        "Jimin Xiao",
        "Moncef Gabbouj"
      ],
      "abstract": "Neural Representations for Videos (NeRV) have simplified the video codec\nprocess and achieved swift decoding speeds by encoding video content into a\nneural network, presenting a promising solution for video compression. However,\nexisting work overlooks the crucial issue that videos reconstructed by these\nmethods lack high-frequency details. To address this problem, this paper\nintroduces a High-Frequency Enhanced Hybrid Neural Representation Network. Our\nmethod focuses on leveraging high-frequency information to improve the\nsynthesis of fine details by the network. Specifically, we design a wavelet\nhigh-frequency encoder that incorporates Wavelet Frequency Decomposer (WFD)\nblocks to generate high-frequency feature embeddings. Next, we design the\nHigh-Frequency Feature Modulation (HFM) block, which leverages the extracted\nhigh-frequency embeddings to enhance the fitting process of the decoder.\nFinally, with the refined Harmonic decoder block and a Dynamic Weighted\nFrequency Loss, we further reduce the potential loss of high-frequency\ninformation. Experiments on the Bunny and UVG datasets demonstrate that our\nmethod outperforms other methods, showing notable improvements in detail\npreservation and compression performance.",
      "tldr_zh": "该论文针对 Neural Representations for Videos (NeRV) 在视频压缩中重建视频缺乏高频细节的问题，提出了一种 High-Frequency Enhanced Hybrid Neural Representation Network。方法包括设计 Wavelet Frequency Decomposer (WFD) 块生成高频特征嵌入、High-Frequency Feature Modulation (HFM) 块增强解码器拟合过程，以及结合改进的 Harmonic 解码器和 Dynamic Weighted Frequency Loss 来减少高频信息损失。实验在 Bunny 和 UVG 数据集上显示，该方法在细节保留和压缩性能方面显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06685v2",
      "published_date": "2024-11-11 03:04:46 UTC",
      "updated_date": "2025-04-30 02:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:38:26.324223"
    },
    {
      "arxiv_id": "2411.06681v1",
      "title": "WDMoE: Wireless Distributed Mixture of Experts for Large Language Models",
      "title_zh": "WDMoE：面向大型语言模型的无线分布式混合专家系统",
      "authors": [
        "Nan Xue",
        "Yaping Sun",
        "Zhiyong Chen",
        "Meixia Tao",
        "Xiaodong Xu",
        "Liang Qian",
        "Shuguang Cui",
        "Wenjun Zhang",
        "Ping Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved significant success in various\nnatural language processing tasks, but the role of wireless networks in\nsupporting LLMs has not been thoroughly explored. In this paper, we propose a\nwireless distributed Mixture of Experts (WDMoE) architecture to enable\ncollaborative deployment of LLMs across edge servers at the base station (BS)\nand mobile devices in wireless networks. Specifically, we decompose the MoE\nlayer in LLMs by placing the gating network and the preceding neural network\nlayer at BS, while distributing the expert networks among the devices. This\ndeployment leverages the parallel inference capabilities of expert networks on\nmobile devices, effectively utilizing the limited computing and caching\nresources of these devices. Accordingly, we develop a performance metric for\nWDMoE-based LLMs, which accounts for both model capability and latency. To\nminimize the latency while maintaining accuracy, we jointly optimize expert\nselection and bandwidth allocation based on the performance metric. Moreover,\nwe build a hardware testbed using NVIDIA Jetson kits to validate the\neffectiveness of WDMoE. Both theoretical simulations and practical hardware\nexperiments demonstrate that the proposed method can significantly reduce the\nlatency without compromising LLM performance.",
      "tldr_zh": "本研究提出了一种无线分布式 Mixture of Experts (WDMoE) 架构，用于在无线网络中实现 Large Language Models (LLMs) 的协作部署，将 MoE 层的 gating network 和前置神经网络层放置在基站 (BS)，而将 expert networks 分布到移动设备上，以充分利用设备的并行推理能力和有限资源。研究开发了一个综合性能指标，考虑模型能力和延迟，并通过联合优化专家选择和带宽分配来最小化延迟同时保持准确性。硬件实验使用 NVIDIA Jetson 套件验证了该方法，能够显著降低延迟而不牺牲 LLM 的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06681v1",
      "published_date": "2024-11-11 02:48:00 UTC",
      "updated_date": "2024-11-11 02:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:38:38.513168"
    },
    {
      "arxiv_id": "2411.06672v1",
      "title": "What Should Baby Models Read? Exploring Sample-Efficient Data Composition on Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Meng Yam",
        "Nathan J Paek"
      ],
      "abstract": "We explore the impact of pre-training data composition on the performance of\nsmall language models in a sample-efficient setting. Using datasets limited to\n10 million words, we evaluate several dataset sources, including child-directed\nspeech (CHILDES), classic books (Gutenberg), synthetic data (TinyStories), and\na mix of these (Mix) across different model sizes ranging from 18 million to\n705 million parameters. Our experiments show that smaller models (e.g.,\nGPT2-97M, GPT2-705M, Llama-360M) perform better when trained on more complex\nand rich datasets like Gutenberg. Models trained on the CHILDES and TinyStories\ndatasets underperformed across all model sizes. These findings suggest that the\noptimal dataset for sample efficient training depends on the model size, and\nthat neither child-directed speech nor simplified stories are optimal for\nlanguage models of all sizes. We highlight the importance of considering both\ndataset composition and model capacity for effective sample efficient language\nmodel training.",
      "tldr_zh": "本研究探讨了在样本高效设置下，预训练数据组成对小型语言模型性能的影响，使用限制在10百万词的数据集，包括CHILDES（儿童导向语音）、Gutenberg（经典书籍）、TinyStories（合成数据）和它们的混合（Mix）。实验评估了不同模型大小，从18百万到705百万参数（如GPT2-97M、GPT2-705M和Llama-360M），结果显示小型模型在更复杂丰富的Gutenberg数据集上表现最佳，而CHILDES和TinyStories在所有模型大小上表现较差。这些发现表明，最优数据集取决于模型容量，并强调了在样本高效语言模型训练中兼顾数据集组成和模型能力的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 figures, CoNLL 2024 (Shared Task) Accepted Paper",
      "pdf_url": "http://arxiv.org/pdf/2411.06672v1",
      "published_date": "2024-11-11 02:37:21 UTC",
      "updated_date": "2024-11-11 02:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:38:50.224636"
    },
    {
      "arxiv_id": "2411.06666v1",
      "title": "Adversarial Detection with a Dynamically Stable System",
      "title_zh": "基于动态稳定系统的对抗检测",
      "authors": [
        "Xiaowei Long",
        "Jie Lin",
        "Xiangyuan Yang"
      ],
      "abstract": "Adversarial detection is designed to identify and reject maliciously crafted\nadversarial examples(AEs) which are generated to disrupt the classification of\ntarget models.\n  Presently, various input transformation-based methods have been developed on\nadversarial example detection, which typically rely on empirical experience and\nlead to unreliability against new attacks.\n  To address this issue, we propose and conduct a Dynamically Stable System\n(DSS), which can effectively detect the adversarial examples from normal\nexamples according to the stability of input examples.\n  Particularly, in our paper, the generation of adversarial examples is\nconsidered as the perturbation process of a Lyapunov dynamic system, and we\npropose an example stability mechanism, in which a novel control term is added\nin adversarial example generation to ensure that the normal examples can\nachieve dynamic stability while the adversarial examples cannot achieve the\nstability.\n  Then, based on the proposed example stability mechanism, a Dynamically Stable\nSystem (DSS) is proposed, which can utilize the disruption and restoration\nactions to determine the stability of input examples and detect the adversarial\nexamples through changes in the stability of the input examples.\n  In comparison with existing methods in three benchmark datasets(MNIST,\nCIFAR10, and CIFAR100), our evaluation results show that our proposed DSS can\nachieve ROC-AUC values of 99.83%, 97.81% and 94.47%, surpassing the\nstate-of-the-art(SOTA) values of 97.35%, 91.10% and 93.49% in the other 7\nmethods.",
      "tldr_zh": "该论文提出了一种动态稳定系统 (Dynamically Stable System, DSS) 来检测对抗样本 (adversarial examples)，以解决现有基于输入转换方法的经验依赖和针对新攻击的不可靠性问题。DSS 将对抗样本生成视为 Lyapunov 动态系统的扰动过程，并引入示例稳定性机制，通过添加一个新颖的控制项确保正常样本达到动态稳定，而对抗样本无法稳定。然后，系统利用扰动和恢复动作评估输入样本的稳定性，从而实现有效检测。在 MNIST、CIFAR10 和 CIFAR100 数据集上，DSS 分别取得了 99.83%、97.81% 和 94.47% 的 ROC-AUC 值，超过了现有最先进方法的表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06666v1",
      "published_date": "2024-11-11 02:16:17 UTC",
      "updated_date": "2024-11-11 02:16:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:39:01.806937"
    },
    {
      "arxiv_id": "2411.06659v1",
      "title": "An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Li",
        "Aijia Zhang",
        "Junqi Gao",
        "Biqing Qi"
      ],
      "abstract": "Incremental graph learning has gained significant attention for its ability\nto address the catastrophic forgetting problem in graph representation\nlearning. However, traditional methods often rely on a large number of labels\nfor node classification, which is impractical in real-world applications. This\nmakes few-shot incremental learning on graphs a pressing need. Current methods\ntypically require extensive training samples from meta-learning to build memory\nand perform intensive fine-tuning of GNN parameters, leading to high memory\nconsumption and potential loss of previously learned knowledge. To tackle these\nchallenges, we introduce Mecoin, an efficient method for building and\nmaintaining memory. Mecoin employs Structured Memory Units to cache prototypes\nof learned categories, as well as Memory Construction Modules to update these\nprototypes for new categories through interactions between the nodes and the\ncached prototypes. Additionally, we have designed a Memory Representation\nAdaptation Module to store probabilities associated with each class prototype,\nreducing the need for parameter fine-tuning and lowering the forgetting rate.\nWhen a sample matches its corresponding class prototype, the relevant\nprobabilities are retrieved from the MRaM. Knowledge is then distilled back\ninto the GNN through a Graph Knowledge Distillation Module, preserving the\nmodel's memory. We analyze the effectiveness of Mecoin in terms of\ngeneralization error and explore the impact of different distillation\nstrategies on model performance through experiments and VC-dimension analysis.\nCompared to other related works, Mecoin shows superior performance in accuracy\nand forgetting rate. Our code is publicly available on the\nhttps://github.com/Arvin0313/Mecoin-GFSCIL.git .",
      "tldr_zh": "该论文针对图表示学习中的灾难性遗忘问题，提出了一种高效内存模块Mecoin，用于Graph Few-Shot Class-Incremental Learning，旨在减少对大量标签的依赖并降低内存消耗。Mecoin包括Structured Memory Units缓存类别原型、Memory Construction Modules更新新原型，以及Memory Representation Adaptation Module和Graph Knowledge Distillation Module来存储概率并通过知识蒸馏保留GNN模型的记忆，从而避免参数微调带来的遗忘。实验结果显示，Mecoin在准确性和遗忘率上优于现有方法，并通过泛化错误分析和VC-dimension验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, 38th Conference on Neural Information Processing\n  Systems, 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06659v1",
      "published_date": "2024-11-11 01:53:14 UTC",
      "updated_date": "2024-11-11 01:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:39:13.660269"
    },
    {
      "arxiv_id": "2411.06657v1",
      "title": "Renaissance: Investigating the Pretraining of Vision-Language Encoders",
      "title_zh": "翻译失败",
      "authors": [
        "Clayton Fields",
        "Casey Kennington"
      ],
      "abstract": "In the past several years there has been an explosion of available models for\nvision-language tasks. Unfortunately, the literature still leaves open a number\nof questions related to best practices in designing and training such models.\nIn this paper we seek to answer several questions related to the pretraining of\nvision-language encoders through meta-analysis. In our first set of\nexperiments, we show that we can save significant compute at no cost to\ndownstream performance, by freezing large parts of vision-language models\nduring pretraining. In our second set of experiments we examine the effect of\nbasing a VL transformer on a vision model versus a text model. Additionally, we\nintroduce a VL modeling platform called Renaissance that we use to conduct all\nof the experiments. This program offers a great deal of flexibility in\ncreating, training and evaluating transformer encoders for VL modeling. The\nsource code for Renaissance can be found at\nhttps://github.com/bsu-slim/renaissance.",
      "tldr_zh": "本论文通过元分析(meta-analysis)调查视觉语言编码器(vision-language encoders)的预训练最佳实践，旨在解决现有文献中未解答的设计和训练问题。在第一组实验中，研究者证明了在预训练期间冻结视觉语言模型的大部分部分，能显著节省计算资源，同时不影响下游性能；在第二组实验中，比较了基于视觉模型与文本模型的VL transformer的影响。论文还引入了名为Renaissance的灵活平台，用于创建、训练和评估VL transformer编码器，并提供了源代码（https://github.com/bsu-slim/renaissance）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06657v1",
      "published_date": "2024-11-11 01:44:54 UTC",
      "updated_date": "2024-11-11 01:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:39:25.278110"
    },
    {
      "arxiv_id": "2411.06655v2",
      "title": "Explore the Reasoning Capability of LLMs in the Chess Testbed",
      "title_zh": "探究 LLMs 在国际象棋测试床中的推理能力",
      "authors": [
        "Shu Wang",
        "Lei Ji",
        "Renxi Wang",
        "Wenxiao Zhao",
        "Haokun Liu",
        "Yifan Hou",
        "Ying Nian Wu"
      ],
      "abstract": "Reasoning is a central capability of human intelligence. In recent years,\nwith the advent of large-scale datasets, pretrained large language models have\nemerged with new capabilities, including reasoning. However, these models still\nstruggle with long-term, complex reasoning tasks, such as playing chess. Based\non the observation that expert chess players employ a dual approach combining\nlong-term strategic play with short-term tactical play along with language\nexplanation, we propose improving the reasoning capability of large language\nmodels in chess by integrating annotated strategy and tactic. Specifically, we\ncollect a dataset named MATE, which consists of 1 million chess positions with\ncandidate moves annotated by chess experts for strategy and tactics. We\nfinetune the LLaMA-3-8B model and compare it against state-of-the-art\ncommercial language models in the task of selecting better chess moves. Our\nexperiments show that our models perform better than GPT, Claude, and Gemini\nmodels. We find that language explanations can enhance the reasoning capability\nof large language models.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在国际象棋测试中的推理能力，针对其在长期复杂任务（如下棋）上的不足，提出通过整合专家注释的策略和战术来提升模型性能。研究者收集了名为MATE的数据集，包含100万份棋局位置的详细注释，并微调LLaMA-3-8B模型进行比较实验。结果显示，微调后的模型在选择更好棋步的任务上优于GPT、Claude和Gemini等商业模型，并证明语言解释能显著增强LLMs的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL2025 Main Conference. Data and models are available:\n  https://mate-chess.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2411.06655v2",
      "published_date": "2024-11-11 01:42:56 UTC",
      "updated_date": "2025-02-28 11:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:39:37.912899"
    },
    {
      "arxiv_id": "2411.06646v1",
      "title": "Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Havrilla",
        "Wenjing Liao"
      ],
      "abstract": "When training deep neural networks, a model's generalization error is often\nobserved to follow a power scaling law dependent both on the model size and the\ndata size. Perhaps the best known example of such scaling laws are for\ntransformer-based large language models, where networks with billions of\nparameters are trained on trillions of tokens of text. Yet, despite sustained\nwidespread interest, a rigorous understanding of why transformer scaling laws\nexist is still missing. To answer this question, we establish novel statistical\nestimation and mathematical approximation theories for transformers when the\ninput data are concentrated on a low-dimensional manifold. Our theory predicts\na power law between the generalization error and both the training data size\nand the network size for transformers, where the power depends on the intrinsic\ndimension $d$ of the training data. Notably, the constructed model architecture\nis shallow, requiring only logarithmic depth in $d$. By leveraging\nlow-dimensional data structures under a manifold hypothesis, we are able to\nexplain transformer scaling laws in a way which respects the data geometry.\nMoreover, we test our theory with empirical observation by training LLMs on\nnatural language datasets. We find the observed empirical data scaling laws\nclosely agree with our theoretical predictions. Taken together, these results\nrigorously show the intrinsic dimension of data to be a crucial quantity\naffecting transformer scaling laws in both theory and practice.",
      "tldr_zh": "该研究探讨了Transformer神经网络在本质低维数据上的缩放定律，通过统计估计和数学近似理论来解释模型泛化错误与模型大小及数据大小之间的幂律关系。作者假设输入数据集中在低维流形上，建立了新的理论框架，预测泛化错误遵循幂律，其中幂指数取决于数据的内在维度$d$，并设计了仅需在$d$上取对数深度的浅层模型架构。实验结果显示，该理论与在自然语言数据集上训练的大型语言模型(LLMs)的实证观察高度一致，强调了数据内在维度在Transformer缩放定律中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06646v1",
      "published_date": "2024-11-11 01:05:28 UTC",
      "updated_date": "2024-11-11 01:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:39:49.777809"
    },
    {
      "arxiv_id": "2411.06639v1",
      "title": "Predicting Country Instability Using Bayesian Deep Learning and Random Forest",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Zebrowski",
        "Haithem Afli"
      ],
      "abstract": "Country instability is a global issue, with unpredictably high levels of\ninstability thwarting socio-economic growth and possibly causing a slew of\nnegative consequences. As a result, uncertainty prediction models for a country\nare becoming increasingly important in the real world, and they are expanding\nto provide more input from 'big data' collections, as well as the\ninterconnectedness of global economies and social networks. This has culminated\nin massive volumes of qualitative data from outlets like television, print,\ndigital, and social media, necessitating the use of artificial intelligence\n(AI) tools like machine learning to make sense of it all and promote predictive\nprecision [1]. The Global Database of Activities, Voice, and Tone (GDELT\nProject) records broadcast, print, and web news in over 100 languages every\nsecond of every day, identifying the people, locations, organisations, counts,\nthemes, outlets, and events that propel our global community and offering a\nfree open platform for computation on the entire world. The main goal of our\nresearch is to investigate how, when our data grows more voluminous and\nfine-grained, we can conduct a more complex methodological analysis of\npolitical conflict. The GDELT dataset, which was released in 2012, is the first\nand potentially the most technologically sophisticated publicly accessible\ndataset on political conflict.",
      "tldr_zh": "这篇论文探讨了使用Bayesian Deep Learning和Random Forest预测国家不稳定性的方法，以应对其对社会经济成长的负面影响。研究利用GDELT数据集——一个实时收集全球新闻数据的开源平台——来处理海量定性数据，包括电视、印刷、数字和社交媒体信息。作者强调，通过这些AI工具进行更复杂的方法分析，能提升政治冲突的预测精度，并为全球经济和社会网络的互联性提供更可靠的洞见。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06639v1",
      "published_date": "2024-11-11 00:23:03 UTC",
      "updated_date": "2024-11-11 00:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:40:01.455823"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 115,
  "processed_papers_count": 115,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T23:40:20.587392"
}