[
  {
    "arxiv_id": "2409.06111v4",
    "title": "Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty",
    "authors": [
      "Sara Pohland",
      "Claire Tomlin"
    ],
    "abstract": "Perception-based navigation systems are useful for unmanned ground vehicle\n(UGV) navigation in complex terrains, where traditional depth-based navigation\nschemes are insufficient. However, these data-driven methods are highly\ndependent on their training data and can fail in surprising and dramatic ways\nwith little warning. To ensure the safety of the vehicle and the surrounding\nenvironment, it is imperative that the navigation system is able to recognize\nthe predictive uncertainty of the perception model and respond safely and\neffectively in the face of uncertainty. In an effort to enable safe navigation\nunder perception uncertainty, we develop a probabilistic and\nreconstruction-based competency estimation (PaRCE) method to estimate the\nmodel's level of familiarity with an input image as a whole and with specific\nregions in the image. We find that the overall competency score can correctly\npredict correctly classified, misclassified, and out-of-distribution (OOD)\nsamples. We also confirm that the regional competency maps can accurately\ndistinguish between familiar and unfamiliar regions across images. We then use\nthis competency information to develop a planning and control scheme that\nenables effective navigation while maintaining a low probability of error. We\nfind that the competency-aware scheme greatly reduces the number of collisions\nwith unfamiliar obstacles, compared to a baseline controller with no competency\nawareness. Furthermore, the regional competency information is very valuable in\nenabling efficient navigation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06111v4",
    "published_date": "2024-09-09 23:34:24 UTC",
    "updated_date": "2025-01-28 21:14:37 UTC"
  },
  {
    "arxiv_id": "2409.06107v1",
    "title": "Doppelgänger's Watch: A Split Objective Approach to Large Language Models",
    "authors": [
      "Shervin Ghasemlou",
      "Ashish Katiyar",
      "Aparajita Saraf",
      "Seungwhan Moon",
      "Mangesh Pujari",
      "Pinar Donmez",
      "Babak Damavandi",
      "Anuj Kumar"
    ],
    "abstract": "In this paper, we investigate the problem of \"generation supervision\" in\nlarge language models, and present a novel bicameral architecture to separate\nsupervision signals from their core capability, helpfulness. Doppelg\\\"anger, a\nnew module parallel to the underlying language model, supervises the generation\nof each token, and learns to concurrently predict the supervision score(s) of\nthe sequences up to and including each token. In this work, we present the\ntheoretical findings, and leave the report on experimental results to a\nforthcoming publication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06107v1",
    "published_date": "2024-09-09 23:22:27 UTC",
    "updated_date": "2024-09-09 23:22:27 UTC"
  },
  {
    "arxiv_id": "2409.15342v1",
    "title": "Recall: Empowering Multimodal Embedding for Edge Devices",
    "authors": [
      "Dongqi Cai",
      "Shangguang Wang",
      "Chen Peng",
      "Zeling Zhang",
      "Mengwei Xu"
    ],
    "abstract": "Human memory is inherently prone to forgetting. To address this, multimodal\nembedding models have been introduced, which transform diverse real-world data\ninto a unified embedding space. These embeddings can be retrieved efficiently,\naiding mobile users in recalling past information. However, as model complexity\ngrows, so do its resource demands, leading to reduced throughput and heavy\ncomputational requirements that limit mobile device implementation. In this\npaper, we introduce RECALL, a novel on-device multimodal embedding system\noptimized for resource-limited mobile environments. RECALL achieves\nhigh-throughput, accurate retrieval by generating coarse-grained embeddings and\nleveraging query-based filtering for refined retrieval. Experimental results\ndemonstrate that RECALL delivers high-quality embeddings with superior\nthroughput, all while operating unobtrusively with minimal memory and energy\nconsumption.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15342v1",
    "published_date": "2024-09-09 22:34:19 UTC",
    "updated_date": "2024-09-09 22:34:19 UTC"
  },
  {
    "arxiv_id": "2409.06096v4",
    "title": "Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer",
    "authors": [
      "Michele Mancusi",
      "Yurii Halychanskyi",
      "Kin Wai Cheuk",
      "Eloi Moliner",
      "Chieh-Hsin Lai",
      "Stefan Uhlich",
      "Junghyun Koo",
      "Marco A. Martínez-Ramírez",
      "Wei-Hsiang Liao",
      "Giorgio Fabbro",
      "Yuki Mitsufuji"
    ],
    "abstract": "Music timbre transfer is a challenging task that involves modifying the\ntimbral characteristics of an audio signal while preserving its melodic\nstructure. In this paper, we propose a novel method based on dual diffusion\nbridges, trained using the CocoChorales Dataset, which consists of unpaired\nmonophonic single-instrument audio data. Each diffusion model is trained on a\nspecific instrument with a Gaussian prior. During inference, a model is\ndesignated as the source model to map the input audio to its corresponding\nGaussian prior, and another model is designated as the target model to\nreconstruct the target audio from this Gaussian prior, thereby facilitating\ntimbre transfer. We compare our approach against existing unsupervised timbre\ntransfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental\nresults demonstrate that our method achieves both better Fr\\'echet Audio\nDistance (FAD) and melody preservation, as reflected by lower pitch distances\n(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise\nlevel from the Gaussian prior, $\\sigma$, can be adjusted to control the degree\nof melody preservation and amount of timbre transferred.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06096v4",
    "published_date": "2024-09-09 22:16:48 UTC",
    "updated_date": "2025-01-07 10:45:58 UTC"
  },
  {
    "arxiv_id": "2409.06091v2",
    "title": "Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity",
    "authors": [
      "Dongyue Li",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "abstract": "Multitask learning is a widely used paradigm for training models on diverse\ntasks, with applications ranging from graph neural networks to language model\nfine-tuning. Since tasks may interfere with each other, a key notion for\nmodeling their relationships is task affinity. This includes pairwise task\naffinity, computed among pairs of tasks, and higher-order affinity, computed\namong subsets of tasks. Naively computing either of them requires repeatedly\ntraining on data from various task combinations, which is computationally\nintensive. We present a new algorithm Grad-TAG that can estimate task\naffinities without this repeated training.\n  The key idea of Grad-TAG is to train a \"base\" model for all tasks and then\nuse a linearization technique to estimate the loss of the model for a specific\ntask combination. The linearization works by computing a gradient-based\napproximation of the loss, using low-dimensional projections of gradients as\nfeatures in a logistic regression to predict labels for the task combination.\nWe show that the linearized model can provably approximate the loss when the\ngradient-based approximation is accurate, and also empirically verify that on\nseveral large models. Then, given the estimated task affinity, we design a\nsemi-definite program for clustering similar tasks by maximizing the average\ndensity of clusters.\n  We evaluate Grad-TAG's performance across seven datasets, including\nmulti-label classification on graphs, and instruction fine-tuning of language\nmodels. Our task affinity estimates are within 2.7% distance to the true\naffinities while needing only 3% of FLOPs in full training. On our largest\ngraph with 21M edges and 500 labeling tasks, our algorithm delivers estimates\nwithin 5% distance to the true affinities, using only 112 GPU hours. Our\nresults show that Grad-TAG achieves excellent performance and runtime tradeoffs\ncompared to existing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages. Appeared in KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.06091v2",
    "published_date": "2024-09-09 21:59:27 UTC",
    "updated_date": "2024-11-20 22:13:47 UTC"
  },
  {
    "arxiv_id": "2409.06077v2",
    "title": "MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization",
    "authors": [
      "Faezeh Faez",
      "Raika Karimi",
      "Yingxue Zhang",
      "Xing Li",
      "Lei Chen",
      "Mingxuan Yuan",
      "Mahdi Biparva"
    ],
    "abstract": "Electronic Design Automation (EDA) is essential for IC design and has\nrecently benefited from AI-based techniques to improve efficiency. Logic\nsynthesis, a key EDA stage, transforms high-level hardware descriptions into\noptimized netlists. Recent research has employed machine learning to predict\nQuality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis\nrecipes. However, the severe scarcity of data due to a very limited number of\navailable AIGs results in overfitting, significantly hindering performance.\nAdditionally, the complexity and large number of nodes in AIGs make plain GNNs\nless effective for learning expressive graph-level representations. To tackle\nthese challenges, we propose MTLSO - a Multi-Task Learning approach for Logic\nSynthesis Optimization. On one hand, it maximizes the use of limited data by\ntraining the model across different tasks. This includes introducing an\nauxiliary task of binary multi-label graph classification alongside the primary\nregression task, allowing the model to benefit from diverse supervision\nsources. On the other hand, we employ a hierarchical graph representation\nlearning strategy to improve the model's capacity for learning expressive\ngraph-level representations of large AIGs, surpassing traditional plain GNNs.\nExtensive experiments across multiple datasets and against state-of-the-art\nbaselines demonstrate the superiority of our method, achieving an average\nperformance gain of 8.22\\% for delay and 5.95\\% for area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06077v2",
    "published_date": "2024-09-09 21:20:36 UTC",
    "updated_date": "2024-10-31 19:52:26 UTC"
  },
  {
    "arxiv_id": "2409.14565v1",
    "title": "Combating Spatial Disorientation in a Dynamic Self-Stabilization Task Using AI Assistants",
    "authors": [
      "Sheikh Mannan",
      "Paige Hansen",
      "Vivekanand Pandey Vimal",
      "Hannah N. Davies",
      "Paul DiZio",
      "Nikhil Krishnaswamy"
    ],
    "abstract": "Spatial disorientation is a leading cause of fatal aircraft accidents. This\npaper explores the potential of AI agents to aid pilots in maintaining balance\nand preventing unrecoverable losses of control by offering cues and corrective\nmeasures that ameliorate spatial disorientation. A multi-axis rotation system\n(MARS) was used to gather data from human subjects self-balancing in a\nspaceflight analog condition. We trained models over this data to create\n\"digital twins\" that exemplified performance characteristics of humans with\ndifferent proficiency levels. We then trained various reinforcement learning\nand deep learning models to offer corrective cues if loss of control is\npredicted. Digital twins and assistant models then co-performed a virtual\ninverted pendulum (VIP) programmed with identical physics. From these\nsimulations, we picked the 5 best-performing assistants based on task metrics\nsuch as crash frequency and mean distance from the direction of balance. These\nwere used in a co-performance study with 20 new human subjects performing a\nversion of the VIP task with degraded spatial information. We show that certain\nAI assistants were able to improve human performance and that\nreinforcement-learning based assistants were objectively more effective but\nrated as less trusted and preferable by humans.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, To be published in the International Conference on\n  Human-Agent Interaction (HAI '24) proceedings",
    "pdf_url": "http://arxiv.org/pdf/2409.14565v1",
    "published_date": "2024-09-09 21:06:22 UTC",
    "updated_date": "2024-09-09 21:06:22 UTC"
  },
  {
    "arxiv_id": "2409.06067v2",
    "title": "MLLM-LLaVA-FL: Multimodal Large Language Model Assisted Federated Learning",
    "authors": [
      "Jianyi Zhang",
      "Hao Frank Yang",
      "Ang Li",
      "Xin Guo",
      "Pu Wang",
      "Haiming Wang",
      "Yiran Chen",
      "Hai Li"
    ],
    "abstract": "Previous studies on federated learning (FL) often encounter performance\ndegradation due to data heterogeneity among different clients. In light of the\nrecent advances in multimodal large language models (MLLMs), such as GPT-4v and\nLLaVA, which demonstrate their exceptional proficiency in multimodal tasks,\nsuch as image captioning and multimodal question answering. We introduce a\nnovel federated learning framework, named Multimodal Large Language Model\nAssisted Federated Learning (MLLM-LLaVA-FL), which employs powerful MLLMs at\nthe server end to address the heterogeneous and long-tailed challenges. Owing\nto the advanced cross-modality representation capabilities and the extensive\nopen-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing\nthe extensive, yet previously underexploited, open-source data accessible from\nwebsites and powerful server-side computational resources. Hence, the\nMLLM-LLaVA-FL not only enhances the performance but also avoids increasing the\nrisk of privacy leakage and the computational burden on local devices,\ndistinguishing it from prior methodologies. Our framework has three key stages.\nInitially, we conduct global visual-text pretraining of the model. This\npretraining is facilitated by utilizing the extensive open-source data\navailable online, with the assistance of MLLMs. Subsequently, the pretrained\nmodel is distributed among various clients for local training. Finally, once\nthe locally trained models are transmitted back to the server, a global\nalignment is carried out under the supervision of MLLMs to further enhance the\nperformance. Experimental evaluations on established benchmarks, show that our\nframework delivers promising performance in the typical scenarios with data\nheterogeneity and long-tail distribution across different clients in FL.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.06067v2",
    "published_date": "2024-09-09 21:04:16 UTC",
    "updated_date": "2024-12-02 10:18:38 UTC"
  },
  {
    "arxiv_id": "2409.06029v2",
    "title": "SongCreator: Lyrics-based Universal Song Generation",
    "authors": [
      "Shun Lei",
      "Yixuan Zhou",
      "Boshi Tang",
      "Max W. Y. Lam",
      "Feng Liu",
      "Hangyu Liu",
      "Jingcheng Wu",
      "Shiyin Kang",
      "Zhiyong Wu",
      "Helen Meng"
    ],
    "abstract": "Music is an integral part of human culture, embodying human intelligence and\ncreativity, of which songs compose an essential part. While various aspects of\nsong generation have been explored by previous works, such as singing voice,\nvocal composition and instrumental arrangement, etc., generating songs with\nboth vocals and accompaniment given lyrics remains a significant challenge,\nhindering the application of music generation models in the real world. In this\nlight, we propose SongCreator, a song-generation system designed to tackle this\nchallenge. The model features two novel designs: a meticulously designed\ndual-sequence language model (DSLM) to capture the information of vocals and\naccompaniment for song generation, and a series of attention mask strategies\nfor DSLM, which allows our model to understand, generate and edit songs, making\nit suitable for various songrelated generation tasks by utilizing specific\nattention masks. Extensive experiments demonstrate the effectiveness of\nSongCreator by achieving state-of-the-art or competitive performances on all\neight tasks. Notably, it surpasses previous works by a large margin in\nlyrics-to-song and lyrics-to-vocals. Additionally, it is able to independently\ncontrol the acoustic conditions of the vocals and accompaniment in the\ngenerated song through different audio prompts, exhibiting its potential\napplicability. Our samples are available at\nhttps://thuhcsi.github.io/SongCreator/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.06029v2",
    "published_date": "2024-09-09 19:37:07 UTC",
    "updated_date": "2024-10-30 20:44:46 UTC"
  },
  {
    "arxiv_id": "2409.16299v2",
    "title": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale",
    "authors": [
      "Huy Nhat Phan",
      "Tien N. Nguyen",
      "Phong X. Nguyen",
      "Nghi D. Q. Bui"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized software engineering (SE),\nshowcasing remarkable proficiency in various coding tasks. Despite recent\nadvancements that have enabled the creation of autonomous software agents\nutilizing LLMs for end-to-end development tasks, these systems are typically\ndesigned for specific SE functions. We introduce HyperAgent, an innovative\ngeneralist multi-agent system designed to tackle a wide range of SE tasks\nacross different programming languages by mimicking the workflows of human\ndevelopers. HyperAgent features four specialized agents-Planner, Navigator,\nCode Editor, and Executor-capable of handling the entire lifecycle of SE tasks,\nfrom initial planning to final verification. HyperAgent sets new benchmarks in\ndiverse SE tasks, including GitHub issue resolution on the renowned SWE-Bench\nbenchmark, outperforming robust baselines. Furthermore, HyperAgent demonstrates\nexceptional performance in repository-level code generation (RepoExec) and\nfault localization and program repair (Defects4J), often surpassing\nstate-of-the-art baselines.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "49 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.16299v2",
    "published_date": "2024-09-09 19:35:34 UTC",
    "updated_date": "2024-11-05 17:22:10 UTC"
  },
  {
    "arxiv_id": "2409.06016v3",
    "title": "Deep Generative Model for Mechanical System Configuration Design",
    "authors": [
      "Yasaman Etesam",
      "Hyunmin Cheong",
      "Mohammadmehdi Ataei",
      "Pradeep Kumar Jayaraman"
    ],
    "abstract": "Generative AI has made remarkable progress in addressing various design\nchallenges. One prominent area where generative AI could bring significant\nvalue is in engineering design. In particular, selecting an optimal set of\ncomponents and their interfaces to create a mechanical system that meets design\nrequirements is one of the most challenging and time-consuming tasks for\nengineers. This configuration design task is inherently challenging due to its\ncategorical nature, multiple design requirements a solution must satisfy, and\nthe reliance on physics simulations for evaluating potential solutions. These\ncharacteristics entail solving a combinatorial optimization problem with\nmultiple constraints involving black-box functions. To address this challenge,\nwe propose a deep generative model to predict the optimal combination of\ncomponents and interfaces for a given design problem. To demonstrate our\napproach, we solve a gear train synthesis problem by first creating a synthetic\ndataset using a grammar, a parts catalogue, and a physics simulator. We then\ntrain a Transformer using this dataset, named GearFormer, which can not only\ngenerate quality solutions on its own, but also augment search methods such as\nan evolutionary algorithm and Monte Carlo tree search. We show that GearFormer\noutperforms such search methods on their own in terms of satisfying the\nspecified design requirements with orders of magnitude faster generation time.\nAdditionally, we showcase the benefit of hybrid methods that leverage both\nGearFormer and search methods, which further improve the quality of the\nsolutions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI-25",
    "pdf_url": "http://arxiv.org/pdf/2409.06016v3",
    "published_date": "2024-09-09 19:15:45 UTC",
    "updated_date": "2025-01-23 21:24:54 UTC"
  },
  {
    "arxiv_id": "2409.05994v1",
    "title": "MessIRve: A Large-Scale Spanish Information Retrieval Dataset",
    "authors": [
      "Francisco Valentini",
      "Viviana Cotik",
      "Damián Furman",
      "Ivan Bercovich",
      "Edgar Altszyler",
      "Juan Manuel Pérez"
    ],
    "abstract": "Information retrieval (IR) is the task of finding relevant documents in\nresponse to a user query. Although Spanish is the second most spoken native\nlanguage, current IR benchmarks lack Spanish data, hindering the development of\ninformation access tools for Spanish speakers. We introduce MessIRve, a\nlarge-scale Spanish IR dataset with around 730 thousand queries from Google's\nautocomplete API and relevant documents sourced from Wikipedia. MessIRve's\nqueries reflect diverse Spanish-speaking regions, unlike other datasets that\nare translated from English or do not consider dialectal variations. The large\nsize of the dataset allows it to cover a wide variety of topics, unlike smaller\ndatasets. We provide a comprehensive description of the dataset, comparisons\nwith existing datasets, and baseline evaluations of prominent IR models. Our\ncontributions aim to advance Spanish IR research and improve information access\nfor Spanish speakers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05994v1",
    "published_date": "2024-09-09 18:45:04 UTC",
    "updated_date": "2024-09-09 18:45:04 UTC"
  },
  {
    "arxiv_id": "2409.13726v1",
    "title": "Multilingual Dyadic Interaction Corpus NoXi+J: Toward Understanding Asian-European Non-verbal Cultural Characteristics and their Influences on Engagement",
    "authors": [
      "Marius Funk",
      "Shogo Okada",
      "Elisabeth André"
    ],
    "abstract": "Non-verbal behavior is a central challenge in understanding the dynamics of a\nconversation and the affective states between interlocutors arising from the\ninteraction. Although psychological research has demonstrated that non-verbal\nbehaviors vary across cultures, limited computational analysis has been\nconducted to clarify these differences and assess their impact on engagement\nrecognition. To gain a greater understanding of engagement and non-verbal\nbehaviors among a wide range of cultures and language spheres, in this study we\nconduct a multilingual computational analysis of non-verbal features and\ninvestigate their role in engagement and engagement prediction. To achieve this\ngoal, we first expanded the NoXi dataset, which contains interaction data from\nparticipants living in France, Germany, and the United Kingdom, by collecting\nsession data of dyadic conversations in Japanese and Chinese, resulting in the\nenhanced dataset NoXi+J. Next, we extracted multimodal non-verbal features,\nincluding speech acoustics, facial expressions, backchanneling and gestures,\nvia various pattern recognition techniques and algorithms. Then, we conducted a\nstatistical analysis of listening behaviors and backchannel patterns to\nidentify culturally dependent and independent features in each language and\ncommon features among multiple languages. These features were also correlated\nwith the engagement shown by the interlocutors. Finally, we analyzed the\ninfluence of cultural differences in the input features of LSTM models trained\nto predict engagement for five language datasets. A SHAP analysis combined with\ntransfer learning confirmed a considerable correlation between the importance\nof input features for a language set and the significant cultural\ncharacteristics analyzed.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages. 6 figures. International Conference on Multimodal\n  Interaction, November 4-8, 2024, San Jose, Costa Rica",
    "pdf_url": "http://arxiv.org/pdf/2409.13726v1",
    "published_date": "2024-09-09 18:37:34 UTC",
    "updated_date": "2024-09-09 18:37:34 UTC"
  },
  {
    "arxiv_id": "2409.10559v1",
    "title": "Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers",
    "authors": [
      "Siyu Chen",
      "Heejune Sheen",
      "Tianhao Wang",
      "Zhuoran Yang"
    ],
    "abstract": "In-context learning (ICL) is a cornerstone of large language model (LLM)\nfunctionality, yet its theoretical foundations remain elusive due to the\ncomplexity of transformer architectures. In particular, most existing work only\ntheoretically explains how the attention mechanism facilitates ICL under\ncertain data models. It remains unclear how the other building blocks of the\ntransformer contribute to ICL. To address this question, we study how a\ntwo-attention-layer transformer is trained to perform ICL on $n$-gram Markov\nchain data, where each token in the Markov chain statistically depends on the\nprevious $n$ tokens. We analyze a sophisticated transformer model featuring\nrelative positional embedding, multi-head softmax attention, and a feed-forward\nlayer with normalization. We prove that the gradient flow with respect to a\ncross-entropy ICL loss converges to a limiting model that performs a\ngeneralized version of the induction head mechanism with a learned feature,\nresulting from the congruous contribution of all the building blocks. In the\nlimiting model, the first attention layer acts as a $\\mathit{copier}$, copying\npast tokens within a given window to each position, and the feed-forward\nnetwork with normalization acts as a $\\mathit{selector}$ that generates a\nfeature vector by only looking at informationally relevant parents from the\nwindow. Finally, the second attention layer is a $\\mathit{classifier}$ that\ncompares these features with the feature at the output position, and uses the\nresulting similarity scores to generate the desired output. Our theory is\nfurther validated by experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "100 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.10559v1",
    "published_date": "2024-09-09 18:10:26 UTC",
    "updated_date": "2024-09-09 18:10:26 UTC"
  },
  {
    "arxiv_id": "2409.05864v1",
    "title": "Neural MP: A Generalist Neural Motion Planner",
    "authors": [
      "Murtaza Dalal",
      "Jiahui Yang",
      "Russell Mendonca",
      "Youssef Khaky",
      "Ruslan Salakhutdinov",
      "Deepak Pathak"
    ],
    "abstract": "The current paradigm for motion planning generates solutions from scratch for\nevery new problem, which consumes significant amounts of time and computational\nresources. For complex, cluttered scenes, motion planning approaches can often\ntake minutes to produce a solution, while humans are able to accurately and\nsafely reach any goal in seconds by leveraging their prior experience. We seek\nto do the same by applying data-driven learning at scale to the problem of\nmotion planning. Our approach builds a large number of complex scenes in\nsimulation, collects expert data from a motion planner, then distills it into a\nreactive generalist policy. We then combine this with lightweight optimization\nto obtain a safe path for real world deployment. We perform a thorough\nevaluation of our method on 64 motion planning tasks across four diverse\nenvironments with randomized poses, scenes and obstacles, in the real world,\ndemonstrating an improvement of 23%, 17% and 79% motion planning success rate\nover state of the art sampling, optimization and learning based planning\nmethods. Video results available at mihdalal.github.io/neuralmotionplanner",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Website at mihdalal.github.io/neuralmotionplanner. Main paper: 7\n  pages, 4 figures, 2 tables. Appendix: 9 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.05864v1",
    "published_date": "2024-09-09 17:59:45 UTC",
    "updated_date": "2024-09-09 17:59:45 UTC"
  },
  {
    "arxiv_id": "2409.05863v1",
    "title": "Promptable Closed-loop Traffic Simulation",
    "authors": [
      "Shuhan Tan",
      "Boris Ivanovic",
      "Yuxiao Chen",
      "Boyi Li",
      "Xinshuo Weng",
      "Yulong Cao",
      "Philipp Krähenbühl",
      "Marco Pavone"
    ],
    "abstract": "Simulation stands as a cornerstone for safe and efficient autonomous driving\ndevelopment. At its core a simulation system ought to produce realistic,\nreactive, and controllable traffic patterns. In this paper, we propose ProSim,\na multimodal promptable closed-loop traffic simulation framework. ProSim allows\nthe user to give a complex set of numerical, categorical or textual prompts to\ninstruct each agent's behavior and intention. ProSim then rolls out a traffic\nscenario in a closed-loop manner, modeling each agent's interaction with other\ntraffic participants. Our experiments show that ProSim achieves high prompt\ncontrollability given different user prompts, while reaching competitive\nperformance on the Waymo Sim Agents Challenge when no prompt is given. To\nsupport research on promptable traffic simulation, we create\nProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with\nover 10M text prompts for over 520k real-world driving scenarios. We will\nrelease code of ProSim as well as data and labeling tools of\nProSim-Instruct-520k at https://ariostgx.github.io/ProSim.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CoRL 2024. Website available at\n  https://ariostgx.github.io/ProSim",
    "pdf_url": "http://arxiv.org/pdf/2409.05863v1",
    "published_date": "2024-09-09 17:59:15 UTC",
    "updated_date": "2024-09-09 17:59:15 UTC"
  },
  {
    "arxiv_id": "2409.05846v1",
    "title": "An Introduction to Quantum Reinforcement Learning (QRL)",
    "authors": [
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "Recent advancements in quantum computing (QC) and machine learning (ML) have\nsparked considerable interest in the integration of these two cutting-edge\nfields. Among the various ML techniques, reinforcement learning (RL) stands out\nfor its ability to address complex sequential decision-making problems. RL has\nalready demonstrated substantial success in the classical ML community. Now,\nthe emerging field of Quantum Reinforcement Learning (QRL) seeks to enhance RL\nalgorithms by incorporating principles from quantum computing. This paper\noffers an introduction to this exciting area for the broader AI and ML\ncommunity.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted by The 15th International Conference on ICT Convergence -\n  ICTC 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05846v1",
    "published_date": "2024-09-09 17:45:37 UTC",
    "updated_date": "2024-09-09 17:45:37 UTC"
  },
  {
    "arxiv_id": "2409.05831v1",
    "title": "Applying Attribution Explanations in Truth-Discovery Quantitative Bipolar Argumentation Frameworks",
    "authors": [
      "Xiang Yin",
      "Nico Potyka",
      "Francesca Toni"
    ],
    "abstract": "Explaining the strength of arguments under gradual semantics is receiving\nincreasing attention. For example, various studies in the literature offer\nexplanations by computing the attribution scores of arguments or edges in\nQuantitative Bipolar Argumentation Frameworks (QBAFs). These explanations,\nknown as Argument Attribution Explanations (AAEs) and Relation Attribution\nExplanations (RAEs), commonly employ removal-based and Shapley-based techniques\nfor computing the attribution scores. While AAEs and RAEs have proven useful in\nseveral applications with acyclic QBAFs, they remain largely unexplored for\ncyclic QBAFs. Furthermore, existing applications tend to focus solely on either\nAAEs or RAEs, but do not compare them directly. In this paper, we apply both\nAAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess the\ntrustworthiness of sources (e.g., websites) and their claims (e.g., the\nseverity of a virus), and feature complex cycles. We find that both AAEs and\nRAEs can provide interesting explanations and can give non-trivial and\nsurprising insights.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted at ArgXAI Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05831v1",
    "published_date": "2024-09-09 17:36:39 UTC",
    "updated_date": "2024-09-09 17:36:39 UTC"
  },
  {
    "arxiv_id": "2409.05938v1",
    "title": "DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning",
    "authors": [
      "Condy Bao",
      "Fuxiao Liu"
    ],
    "abstract": "Since the advent of CRISPR-Cas9, a groundbreaking gene-editing technology\nthat enables precise genomic modifications via a short RNA guide sequence,\nthere has been a marked increase in the accessibility and application of this\ntechnology across various fields. The success of CRISPR-Cas9 has spurred\nfurther investment and led to the discovery of additional CRISPR systems,\nincluding CRISPR-Cas13. Distinct from Cas9, which targets DNA, Cas13 targets\nRNA, offering unique advantages for gene modulation. We focus on Cas13d, a\nvariant known for its collateral activity where it non-specifically cleaves\nadjacent RNA molecules upon activation, a feature critical to its function. We\nintroduce DeepFM-Crispr, a novel deep learning model developed to predict the\non-target efficiency and evaluate the off-target effects of Cas13d. This model\nharnesses a large language model to generate comprehensive representations rich\nin evolutionary and structural data, thereby enhancing predictions of RNA\nsecondary structures and overall sgRNA efficacy. A transformer-based\narchitecture processes these inputs to produce a predictive efficacy score.\nComparative experiments show that DeepFM-Crispr not only surpasses traditional\nmodels but also outperforms recent state-of-the-art deep learning methods in\nterms of prediction accuracy and reliability.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "11 page, 2 figures, accepted to ICMLA 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05938v1",
    "published_date": "2024-09-09 17:33:54 UTC",
    "updated_date": "2024-09-09 17:33:54 UTC"
  },
  {
    "arxiv_id": "2409.05808v2",
    "title": "The Future of Software Testing: AI-Powered Test Case Generation and Validation",
    "authors": [
      "Mohammad Baqar",
      "Rajat Khanda"
    ],
    "abstract": "Software testing is a crucial phase in the software development lifecycle\n(SDLC), ensuring that products meet necessary functional, performance, and\nquality benchmarks before release. Despite advancements in automation,\ntraditional methods of generating and validating test cases still face\nsignificant challenges, including prolonged timelines, human error, incomplete\ntest coverage, and high costs of manual intervention. These limitations often\nlead to delayed product launches and undetected defects that compromise\nsoftware quality and user satisfaction. The integration of artificial\nintelligence (AI) into software testing presents a promising solution to these\npersistent challenges. AI-driven testing methods automate the creation of\ncomprehensive test cases, dynamically adapt to changes, and leverage machine\nlearning to identify high-risk areas in the codebase. This approach enhances\nregression testing efficiency while expanding overall test coverage.\nFurthermore, AI-powered tools enable continuous testing and self-healing test\ncases, significantly reducing manual oversight and accelerating feedback loops,\nultimately leading to faster and more reliable software releases. This paper\nexplores the transformative potential of AI in improving test case generation\nand validation, focusing on its ability to enhance efficiency, accuracy, and\nscalability in testing processes. It also addresses key challenges associated\nwith adapting AI for testing, including the need for high quality training\ndata, ensuring model transparency, and maintaining a balance between automation\nand human oversight. Through case studies and examples of real-world\napplications, this paper illustrates how AI can significantly enhance testing\nefficiency across both legacy and modern software systems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Version 2, 19 Pages",
    "pdf_url": "http://arxiv.org/pdf/2409.05808v2",
    "published_date": "2024-09-09 17:12:40 UTC",
    "updated_date": "2025-05-10 01:03:08 UTC"
  },
  {
    "arxiv_id": "2409.05806v3",
    "title": "CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs",
    "authors": [
      "Jizhan Fang",
      "Tianhe Lu",
      "Yunzhi Yao",
      "Ziyan Jiang",
      "Xin Xu",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "abstract": "Chinese, as a linguistic system rich in depth and complexity, is\ncharacterized by distinctive elements such as ancient poetry, proverbs, idioms,\nand other cultural constructs. However, current Large Language Models (LLMs)\nface limitations in these specialized domains, highlighting the need for the\ndevelopment of comprehensive datasets that can assess, continuously update, and\nprogressively improve these culturally-grounded linguistic competencies through\ntargeted training optimizations. To address this gap, we introduce CKnowEdit,\nthe first-ever Chinese knowledge editing dataset designed to correct\nlinguistic, factual, and logical errors in LLMs. We collect seven types of\nknowledge from a wide range of sources, including classical texts, idioms, and\ncontent from Baidu Tieba Ruozhiba, taking into account the unique polyphony,\nantithesis, and logical structures inherent in the Chinese language. By\nanalyzing this dataset, we highlight the challenges current LLMs face in\nmastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge\nediting techniques reveals opportunities to advance the correction of Chinese\nknowledge. Code and dataset are available at\nhttps://github.com/zjunlp/EasyEdit.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Ongoing work; project website is available at\n  https://zjunlp.github.io/project/CKnowEdit code and dataset are available at\n  https://github.com/zjunlp/EasyEdit",
    "pdf_url": "http://arxiv.org/pdf/2409.05806v3",
    "published_date": "2024-09-09 17:11:51 UTC",
    "updated_date": "2025-02-24 11:02:47 UTC"
  },
  {
    "arxiv_id": "2409.05798v4",
    "title": "Enhancing Preference-based Linear Bandits via Human Response Time",
    "authors": [
      "Shen Li",
      "Yuyang Zhang",
      "Zhaolin Ren",
      "Claire Liang",
      "Na Li",
      "Julie A. Shah"
    ],
    "abstract": "Interactive preference learning systems infer human preferences by presenting\nqueries as pairs of options and collecting binary choices. Although binary\nchoices are simple and widely used, they provide limited information about\npreference strength. To address this, we leverage human response times, which\nare inversely related to preference strength, as an additional signal. We\npropose a computationally efficient method that combines choices and response\ntimes to estimate human utility functions, grounded in the EZ diffusion model\nfrom psychology. Theoretical and empirical analyses show that for queries with\nstrong preferences, response times complement choices by providing extra\ninformation about preference strength, leading to significantly improved\nutility estimation. We incorporate this estimator into preference-based linear\nbandits for fixed-budget best-arm identification. Simulations on three\nreal-world datasets demonstrate that using response times significantly\naccelerates preference learning compared to choice-only approaches. Additional\nmaterials, such as code, slides, and talk video, are available at\nhttps://shenlirobot.github.io/pages/NeurIPS24.html",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "econ.EM",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 (Oral) camera ready",
    "pdf_url": "http://arxiv.org/pdf/2409.05798v4",
    "published_date": "2024-09-09 17:02:47 UTC",
    "updated_date": "2025-01-02 12:00:28 UTC"
  },
  {
    "arxiv_id": "2409.15338v1",
    "title": "Explainable AI: Definition and attributes of a good explanation for health AI",
    "authors": [
      "Evangelia Kyrimi",
      "Scott McLachlan",
      "Jared M Wohlgemut",
      "Zane B Perkins",
      "David A. Lagnado",
      "William Marsh",
      "the ExAIDSS Expert Group"
    ],
    "abstract": "Proposals of artificial intelligence (AI) solutions based on increasingly\ncomplex and accurate predictive models are becoming ubiquitous across many\ndisciplines. As the complexity of these models grows, transparency and users'\nunderstanding often diminish. This suggests that accurate prediction alone is\ninsufficient for making an AI-based solution truly useful. In the development\nof healthcare systems, this introduces new issues related to accountability and\nsafety. Understanding how and why an AI system makes a recommendation may\nrequire complex explanations of its inner workings and reasoning processes.\nAlthough research on explainable AI (XAI) has significantly increased in recent\nyears and there is high demand for XAI in medicine, defining what constitutes a\ngood explanation remains ad hoc, and providing adequate explanations continues\nto be challenging. To fully realize the potential of AI, it is critical to\naddress two fundamental questions about explanations for safety-critical AI\napplications, such as health-AI: (1) What is an explanation in health-AI? and\n(2) What are the attributes of a good explanation in health-AI? In this study,\nwe examined published literature and gathered expert opinions through a\ntwo-round Delphi study. The research outputs include (1) a definition of what\nconstitutes an explanation in health-AI and (2) a comprehensive list of\nattributes that characterize a good explanation in health-AI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15338v1",
    "published_date": "2024-09-09 16:56:31 UTC",
    "updated_date": "2024-09-09 16:56:31 UTC"
  },
  {
    "arxiv_id": "2409.05786v1",
    "title": "Leveraging Object Priors for Point Tracking",
    "authors": [
      "Bikram Boote",
      "Anh Thai",
      "Wenqi Jia",
      "Ozgur Kara",
      "Stefan Stojanov",
      "James M. Rehg",
      "Sangmin Lee"
    ],
    "abstract": "Point tracking is a fundamental problem in computer vision with numerous\napplications in AR and robotics. A common failure mode in long-term point\ntracking occurs when the predicted point leaves the object it belongs to and\nlands on the background or another object. We identify this as the failure to\ncorrectly capture objectness properties in learning to track. To address this\nlimitation of prior work, we propose a novel objectness regularization approach\nthat guides points to be aware of object priors by forcing them to stay inside\nthe the boundaries of object instances. By capturing objectness cues at\ntraining time, we avoid the need to compute object masks during testing. In\naddition, we leverage contextual attention to enhance the feature\nrepresentation for capturing objectness at the feature level more effectively.\nAs a result, our approach achieves state-of-the-art performance on three point\ntracking benchmarks, and we further validate the effectiveness of our\ncomponents via ablation studies. The source code is available at:\nhttps://github.com/RehgLab/tracking_objectness",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024 ILR Workshop",
    "pdf_url": "http://arxiv.org/pdf/2409.05786v1",
    "published_date": "2024-09-09 16:48:42 UTC",
    "updated_date": "2024-09-09 16:48:42 UTC"
  },
  {
    "arxiv_id": "2409.05785v4",
    "title": "NeurLZ: An Online Neural Learning-Based Method to Enhance Scientific Lossy Compression",
    "authors": [
      "Wenqi Jia",
      "Zhewen Hu",
      "Youyuan Liu",
      "Boyuan Zhang",
      "Jinzhen Wang",
      "Jinyang Liu",
      "Wei Niu",
      "Stavros Kalafatis",
      "Junzhou Huang",
      "Sian Jin",
      "Daoce Wang",
      "Jiannan Tian",
      "Miao Yin"
    ],
    "abstract": "Large-scale scientific simulations generate massive datasets, posing\nchallenges for storage and I/O. Traditional lossy compression struggles to\nadvance more in balancing compression ratio, data quality, and adaptability to\ndiverse scientific data features. While deep learning-based solutions have been\nexplored, their common practice of relying on large models and offline training\nlimits adaptability to dynamic data characteristics and computational\nefficiency. To address these challenges, we propose NeurLZ, a neural method\ndesigned to enhance lossy compression by integrating online learning,\ncross-field learning, and robust error regulation. Key innovations of NeurLZ\ninclude: (1) compression-time online neural learning with lightweight skipping\nDNN models, adapting to residual errors without costly offline pertaining, (2)\nthe error-mitigating capability, recovering fine details from compression\nerrors overlooked by conventional compressors, (3) $1\\times$ and $2\\times$\nerror-regulation modes, ensuring strict adherence to $1\\times$ user-input error\nbounds strictly or relaxed 2$\\times$ bounds for better overall quality, and (4)\ncross-field learning leveraging inter-field correlations in scientific data to\nimprove conventional methods. Comprehensive evaluations on representative HPC\ndatasets, e.g., Nyx, Miranda, Hurricane, against state-of-the-art compressors\nshow NeurLZ's effectiveness. During the first five learning epochs, NeurLZ\nachieves an 89% bit rate reduction, with further optimization yielding up to\naround 94% reduction at equivalent distortion, significantly outperforming\nexisting methods, demonstrating NeurLZ's superior performance in enhancing\nscientific lossy compression as a scalable and efficient solution.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "ICS 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.05785v4",
    "published_date": "2024-09-09 16:48:09 UTC",
    "updated_date": "2025-04-18 04:00:31 UTC"
  },
  {
    "arxiv_id": "2409.07497v1",
    "title": "OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System",
    "authors": [
      "Ningyu Zhang",
      "Zekun Xi",
      "Yujie Luo",
      "Peng Wang",
      "Bozhong Tian",
      "Yunzhi Yao",
      "Jintian Zhang",
      "Shumin Deng",
      "Mengshu Sun",
      "Lei Liang",
      "Zhiqiang Zhang",
      "Xiaowei Zhu",
      "Jun Zhou",
      "Huajun Chen"
    ],
    "abstract": "Knowledge representation has been a central aim of AI since its inception.\nSymbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can\nboth represent knowledge. KGs provide highly accurate and explicit knowledge\nrepresentation, but face scalability issue; while LLMs offer expansive coverage\nof knowledge, but incur significant training costs and struggle with precise\nand reliable knowledge manipulation. To this end, we introduce OneEdit, a\nneural-symbolic prototype system for collaborative knowledge editing using\nnatural language, which facilitates easy-to-use knowledge management with KG\nand LLM. OneEdit consists of three modules: 1) The Interpreter serves for user\ninteraction with natural language; 2) The Controller manages editing requests\nfrom various users, leveraging the KG with rollbacks to handle knowledge\nconflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the\nknowledge from the Controller to edit KG and LLM. We conduct experiments on two\nnew datasets with KGs which demonstrate that OneEdit can achieve superior\nperformance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "LLM+KG@VLDB2024, code is available at\n  https://github.com/zjunlp/OneEdit",
    "pdf_url": "http://arxiv.org/pdf/2409.07497v1",
    "published_date": "2024-09-09 16:46:47 UTC",
    "updated_date": "2024-09-09 16:46:47 UTC"
  },
  {
    "arxiv_id": "2409.05773v2",
    "title": "Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera",
    "authors": [
      "Ross Greer",
      "Laura Fleig",
      "Shlomo Dubnov"
    ],
    "abstract": "This paper explores the integration of visual communication and musical\ninteraction by implementing a robotic camera within a \"Guided Harmony\" musical\ngame. We aim to examine co-creative behaviors between human musicians and\nrobotic systems. Our research explores existing methodologies like\nimprovisational game pieces and extends these concepts to include robotic\nparticipation using a PTZ camera. The robotic system interprets and responds to\nnonverbal cues from musicians, creating a collaborative and adaptive musical\nexperience. This initial case study underscores the importance of intuitive\nvisual communication channels. We also propose future research directions,\nincluding parameters for refining the visual cue toolkit and data collection\nmethods to understand human-machine co-creativity further. Our findings\ncontribute to the broader understanding of machine intelligence in augmenting\nhuman creativity, particularly in musical settings.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05773v2",
    "published_date": "2024-09-09 16:34:36 UTC",
    "updated_date": "2024-10-28 01:34:48 UTC"
  },
  {
    "arxiv_id": "2409.05771v1",
    "title": "Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models",
    "authors": [
      "Emily Cheng",
      "Richard J. Antonello"
    ],
    "abstract": "Research has repeatedly demonstrated that intermediate hidden states\nextracted from large language models are able to predict measured brain\nresponse to natural language stimuli. Yet, very little is known about the\nrepresentation properties that enable this high prediction performance. Why is\nit the intermediate layers, and not the output layers, that are most capable\nfor this unique and highly general transfer task? In this work, we show that\nevidence from language encoding models in fMRI supports the existence of a\ntwo-phase abstraction process within LLMs. We use manifold learning methods to\nshow that this abstraction process naturally arises over the course of training\na language model and that the first \"composition\" phase of this abstraction\nprocess is compressed into fewer layers as training continues. Finally, we\ndemonstrate a strong correspondence between layerwise encoding performance and\nthe intrinsic dimensionality of representations from LLMs. We give initial\nevidence that this correspondence primarily derives from the inherent\ncompositionality of LLMs and not their next-word prediction properties.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Equal contribution from both authors. Submitted to NeurIPS NeuroAI\n  workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05771v1",
    "published_date": "2024-09-09 16:33:16 UTC",
    "updated_date": "2024-09-09 16:33:16 UTC"
  },
  {
    "arxiv_id": "2409.06493v1",
    "title": "Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models",
    "authors": [
      "Rohit Jena",
      "Ali Taghibakhshi",
      "Sahil Jain",
      "Gerald Shen",
      "Nima Tajbakhsh",
      "Arash Vahdat"
    ],
    "abstract": "Text-to-image (T2I) diffusion models have become prominent tools for\ngenerating high-fidelity images from text prompts. However, when trained on\nunfiltered internet data, these models can produce unsafe, incorrect, or\nstylistically undesirable images that are not aligned with human preferences.\nTo address this, recent approaches have incorporated human preference datasets\nto fine-tune T2I models or to optimize reward functions that capture these\npreferences. Although effective, these methods are vulnerable to reward\nhacking, where the model overfits to the reward function, leading to a loss of\ndiversity in the generated images. In this paper, we prove the inevitability of\nreward hacking and study natural regularization techniques like KL divergence\nand LoRA scaling, and their limitations for diffusion models. We also introduce\nAnnealed Importance Guidance (AIG), an inference-time regularization inspired\nby Annealed Importance Sampling, which retains the diversity of the base model\nwhile achieving Pareto-Optimal reward-diversity tradeoffs. Our experiments\ndemonstrate the benefits of AIG for Stable Diffusion models, striking the\noptimal balance between reward optimization and image diversity. Furthermore, a\nuser study confirms that AIG improves diversity and quality of generated images\nacross different model architectures and reward functions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06493v1",
    "published_date": "2024-09-09 16:27:26 UTC",
    "updated_date": "2024-09-09 16:27:26 UTC"
  },
  {
    "arxiv_id": "2409.05749v1",
    "title": "ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL",
    "authors": [
      "Safwen Naimi",
      "Wassim Bouachir",
      "Guillaume-Alexandre Bilodeau"
    ],
    "abstract": "To extract robust and generalizable skeleton action recognition features,\nlarge amounts of well-curated data are typically required, which is a\nchallenging task hindered by annotation and computation costs. Therefore,\nunsupervised representation learning is of prime importance to leverage\nunlabeled skeleton data. In this work, we investigate unsupervised\nrepresentation learning for skeleton action recognition. For this purpose, we\ndesigned a lightweight convolutional transformer framework, named ReL-SAR,\nexploiting the complementarity of convolutional and attention layers for\njointly modeling spatial and temporal cues in skeleton sequences. We also use a\nSelection-Permutation strategy for skeleton joints to ensure more informative\ndescriptions from skeletal data. Finally, we capitalize on Bootstrap Your Own\nLatent (BYOL) to learn robust representations from unlabeled skeleton sequence\ndata. We achieved very competitive results on limited-size datasets: MCAD,\nIXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method\nagainst state-of-the-art methods in terms of both performance and computational\nefficiency. To ensure reproducibility and reusability, the source code\nincluding all implementation parameters is provided at:\nhttps://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.05749v1",
    "published_date": "2024-09-09 16:03:26 UTC",
    "updated_date": "2024-09-09 16:03:26 UTC"
  },
  {
    "arxiv_id": "2409.05747v1",
    "title": "A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System",
    "authors": [
      "B. Sankar",
      "Dibakar Sen"
    ],
    "abstract": "This paper presents a novel conversational AI-enabled active ideation\ninterface as a creative idea-generation tool to assist novice designers in\nmitigating the initial latency and ideation bottlenecks that are commonly\nobserved. It is a dynamic, interactive, and contextually responsive approach,\nactively involving a large language model (LLM) from the domain of natural\nlanguage processing (NLP) in artificial intelligence (AI) to produce multiple\nstatements of potential ideas for different design problems. Integrating such\nAI models with ideation creates what we refer to as an Active Ideation\nscenario, which helps foster continuous dialogue-based interaction,\ncontext-sensitive conversation, and prolific idea generation. A pilot study was\nconducted with thirty novice designers to generate ideas for given problems\nusing traditional methods and the new CAI-based interface. The key parameters\nof fluency, novelty, and variety were used to compare the outcomes\nqualitatively by a panel of experts. The findings demonstrated the\neffectiveness of the proposed tool for generating prolific, diverse and novel\nideas. The interface was enhanced by incorporating a prompt-engineered\nstructured dialogue style for each ideation stage to make it uniform and more\nconvenient for the designers. The resulting responses of such a structured CAI\ninterface were found to be more succinct and aligned towards the subsequent\ndesign stage, namely conceptualization. The paper thus established the rich\npotential of using Generative AI (Gen-AI) for the early ill-structured phase of\nthe creative product design process.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2; J.6"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 16 figures, AIEDAM Journal Article",
    "pdf_url": "http://arxiv.org/pdf/2409.05747v1",
    "published_date": "2024-09-09 16:02:27 UTC",
    "updated_date": "2024-09-09 16:02:27 UTC"
  },
  {
    "arxiv_id": "2409.05735v2",
    "title": "A System and Benchmark for LLM-based Q&A on Heterogeneous Data",
    "authors": [
      "Achille Fokoue",
      "Srideepika Jayaraman",
      "Elham Khabiri",
      "Jeffrey O. Kephart",
      "Yingjie Li",
      "Dhruv Shah",
      "Youssef Drissi",
      "Fenno F. Heath III",
      "Anu Bhamidipaty",
      "Fateh A. Tipu",
      "Robert J. Baseman"
    ],
    "abstract": "In many industrial settings, users wish to ask questions whose answers may be\nfound in structured data sources such as a spreadsheets, databases, APIs, or\ncombinations thereof. Often, the user doesn't know how to identify or access\nthe right data source. This problem is compounded even further if multiple (and\npotentially siloed) data sources must be assembled to derive the answer.\nRecently, various Text-to-SQL applications that leverage Large Language Models\n(LLMs) have addressed some of these problems by enabling users to ask questions\nin natural language. However, these applications remain impractical in\nrealistic industrial settings because they fail to cope with the data source\nheterogeneity that typifies such environments. In this paper, we address\nheterogeneity by introducing the siwarex platform, which enables seamless\nnatural language access to both databases and APIs. To demonstrate the\neffectiveness of siwarex, we extend the popular Spider dataset and benchmark by\nreplacing some of its tables by data retrieval APIs. We find that siwarex does\na good job of coping with data source heterogeneity. Our modified Spider\nbenchmark will soon be available to the research community",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05735v2",
    "published_date": "2024-09-09 15:44:39 UTC",
    "updated_date": "2024-09-10 21:46:32 UTC"
  },
  {
    "arxiv_id": "2409.05731v3",
    "title": "What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence",
    "authors": [
      "Robert Kaufman",
      "Aaron Broukhim",
      "David Kirsh",
      "Nadir Weibel"
    ],
    "abstract": "Explanations for autonomous vehicle (AV) decisions may build trust, however,\nexplanations can contain errors. In a simulated driving study (n = 232), we\ntested how AV explanation errors, driving context characteristics (perceived\nharm and driving difficulty), and personal traits (prior trust and expertise)\naffected a passenger's comfort in relying on an AV, preference for control,\nconfidence in the AV's ability, and explanation satisfaction. Errors negatively\naffected all outcomes. Surprisingly, despite identical driving, explanation\nerrors reduced ratings of the AV's driving ability. Severity and potential harm\namplified the negative impact of errors. Contextual harm and driving difficulty\ndirectly impacted outcome ratings and influenced the relationship between\nerrors and outcomes. Prior trust and expertise were positively associated with\noutcome ratings. Results emphasize the need for accurate, contextually\nadaptive, and personalized AV explanations to foster trust, reliance,\nsatisfaction, and confidence. We conclude with design, research, and deployment\nrecommendations for trustworthy AV explanation systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, Accepted to CHI Conference on Human Factors in Computing\n  Systems (CHI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2409.05731v3",
    "published_date": "2024-09-09 15:41:53 UTC",
    "updated_date": "2025-01-28 21:31:59 UTC"
  },
  {
    "arxiv_id": "2409.05721v1",
    "title": "Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding",
    "authors": [
      "Bram Willemsen",
      "Gabriel Skantze"
    ],
    "abstract": "We propose an approach to referring expression generation (REG) in visually\ngrounded dialogue that is meant to produce referring expressions (REs) that are\nboth discriminative and discourse-appropriate. Our method constitutes a\ntwo-stage process. First, we model REG as a text- and image-conditioned\nnext-token prediction task. REs are autoregressively generated based on their\npreceding linguistic context and a visual representation of the referent.\nSecond, we propose the use of discourse-aware comprehension guiding as part of\na generate-and-rerank strategy through which candidate REs generated with our\nREG model are reranked based on their discourse-dependent discriminatory power.\nResults from our human evaluation indicate that our proposed two-stage approach\nis effective in producing discriminative REs, with higher performance in terms\nof text-image retrieval accuracy for reranked REs compared to those generated\nusing greedy decoding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication at INLG 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05721v1",
    "published_date": "2024-09-09 15:33:07 UTC",
    "updated_date": "2024-09-09 15:33:07 UTC"
  },
  {
    "arxiv_id": "2409.05701v3",
    "title": "pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning",
    "authors": [
      "Jiahao Lai",
      "Jiaqi Li",
      "Jian Xu",
      "Yanru Wu",
      "Boshi Tang",
      "Siqi Chen",
      "Yongfeng Huang",
      "Wenbo Ding",
      "Yang Li"
    ],
    "abstract": "Federated Learning (FL) offers a decentralized approach to model training,\nwhere data remains local and only model parameters are shared between the\nclients and the central server. Traditional methods, such as Federated\nAveraging (FedAvg), linearly aggregate these parameters which are usually\ntrained on heterogeneous data distributions, potentially overlooking the\ncomplex, high-dimensional nature of the parameter space. This can result in\ndegraded performance of the aggregated model. While personalized FL approaches\ncan mitigate the heterogeneous data issue to some extent, the limitation of\nlinear aggregation remains unresolved. To alleviate this issue, we investigate\nthe generative approach of diffusion model and propose a novel generative\nparameter aggregation framework for personalized FL, \\texttt{pFedGPA}. In this\nframework, we deploy a diffusion model on the server to integrate the diverse\nparameter distributions and propose a parameter inversion method to efficiently\ngenerate a set of personalized parameters for each client. This inversion\nmethod transforms the uploaded parameters into a latent code, which is then\naggregated through denoising sampling to produce the final personalized\nparameters. By encoding the dependence of a client's model parameters on the\nspecific data distribution using the high-capacity diffusion model,\n\\texttt{pFedGPA} can effectively decouple the complexity of the overall\ndistribution of all clients' model parameters from the complexity of each\nindividual client's parameter distribution. Our experimental results\nconsistently demonstrate the superior performance of the proposed method across\nmultiple datasets, surpassing baseline approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05701v3",
    "published_date": "2024-09-09 15:13:56 UTC",
    "updated_date": "2025-02-11 17:14:43 UTC"
  },
  {
    "arxiv_id": "2409.05698v1",
    "title": "MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction",
    "authors": [
      "Mengyu Wang",
      "Tiejun Ma"
    ],
    "abstract": "It is widely acknowledged that extracting market sentiments from news data\nbenefits market predictions. However, existing methods of using financial\nsentiments remain simplistic, relying on equal-weight and static aggregation to\nmanage sentiments from multiple news items. This leads to a critical issue\ntermed ``Aggregated Sentiment Homogenization'', which has been explored through\nour analysis of a large financial news dataset from industry practice. This\nphenomenon occurs when aggregating numerous sentiments, causing representations\nto converge towards the mean values of sentiment distributions and thereby\nsmoothing out unique and important information. Consequently, the aggregated\nsentiment representations lose much predictive value of news data. To address\nthis problem, we introduce the Market Attention-weighted News Aggregation\nNetwork (MANA-Net), a novel method that leverages a dynamic market-news\nattention mechanism to aggregate news sentiments for market prediction.\nMANA-Net learns the relevance of news sentiments to price changes and assigns\nvarying weights to individual news items. By integrating the news aggregation\nstep into the networks for market prediction, MANA-Net allows for trainable\nsentiment representations that are optimized directly for prediction. We\nevaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with\nfinancial news spanning from 2003 to 2018. Experimental results demonstrate\nthat MANA-Net outperforms various recent market prediction methods, enhancing\nProfit & Loss by 1.1% and the daily Sharpe ratio by 0.252.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-fin.CP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CIKM 24",
    "pdf_url": "http://arxiv.org/pdf/2409.05698v1",
    "published_date": "2024-09-09 15:12:24 UTC",
    "updated_date": "2024-09-09 15:12:24 UTC"
  },
  {
    "arxiv_id": "2409.05677v2",
    "title": "RIRAG: Regulatory Information Retrieval and Answer Generation",
    "authors": [
      "Tuba Gokhan",
      "Kexin Wang",
      "Iryna Gurevych",
      "Ted Briscoe"
    ],
    "abstract": "Regulatory documents, issued by governmental regulatory bodies, establish\nrules, guidelines, and standards that organizations must adhere to for legal\ncompliance. These documents, characterized by their length, complexity and\nfrequent updates, are challenging to interpret, requiring significant\nallocation of time and expertise on the part of organizations to ensure ongoing\ncompliance. Regulatory Natural Language Processing (RegNLP) is a\nmultidisciplinary field aimed at simplifying access to and interpretation of\nregulatory rules and obligations. We introduce a task of generating\nquestion-passages pairs, where questions are automatically created and paired\nwith relevant regulatory passages, facilitating the development of regulatory\nquestion-answering systems. We create the ObliQA dataset, containing 27,869\nquestions derived from the collection of Abu Dhabi Global Markets (ADGM)\nfinancial regulation documents, design a baseline Regulatory Information\nRetrieval and Answer Generation (RIRAG) system and evaluate it with RePASs, a\nnovel evaluation metric that tests whether generated answers accurately capture\nall relevant obligations while avoiding contradictions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.ET",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05677v2",
    "published_date": "2024-09-09 14:44:19 UTC",
    "updated_date": "2024-12-02 18:13:28 UTC"
  },
  {
    "arxiv_id": "2409.05674v2",
    "title": "Evaluation of real-time transcriptions using end-to-end ASR models",
    "authors": [
      "Carlos Arriaga",
      "Alejandro Pozo",
      "Javier Conde",
      "Alvaro Alonso"
    ],
    "abstract": "Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly\nevolved in the last few years. Traditional architectures based on pipelines\nhave been replaced by joint end-to-end (E2E) architectures that simplify and\nstreamline the model training process. In addition, new AI training methods,\nsuch as weak-supervised learning have reduced the need for high-quality audio\ndatasets for model training. However, despite all these advancements, little to\nno research has been done on real-time transcription. In real-time scenarios,\nthe audio is not pre-recorded, and the input audio must be fragmented to be\nprocessed by the ASR systems. To achieve real-time requirements, these\nfragments must be as short as possible to reduce latency. However, audio cannot\nbe split at any point as dividing an utterance into two separate fragments will\ngenerate an incorrect transcription. Also, shorter fragments provide less\ncontext for the ASR model. For this reason, it is necessary to design and test\ndifferent splitting algorithms to optimize the quality and delay of the\nresulting transcription. In this paper, three audio splitting algorithms are\nevaluated with different ASR models to determine their impact on both the\nquality of the transcription and the end-to-end delay. The algorithms are\nfragmentation at fixed intervals, voice activity detection (VAD), and\nfragmentation with feedback. The results are compared to the performance of the\nsame model, without audio fragmentation, to determine the effects of this\ndivision. The results show that VAD fragmentation provides the best quality\nwith the highest delay, whereas fragmentation at fixed intervals provides the\nlowest quality and the lowest delay. The newly proposed feedback algorithm\nexchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,\nto the VAD splitting.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.SD",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05674v2",
    "published_date": "2024-09-09 14:41:57 UTC",
    "updated_date": "2024-09-11 10:00:53 UTC"
  },
  {
    "arxiv_id": "2409.05672v2",
    "title": "Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!",
    "authors": [
      "Yuchen Shen",
      "Haomin Wen",
      "Leman Akoglu"
    ],
    "abstract": "Outlier detection (OD) has a vast literature as it finds numerous real-world\napplications. Being an inherently unsupervised task, model selection is a key\nbottleneck for OD without label supervision. Despite many OD techniques are\navailable to choose from, algorithm and hyperparameter selection remain\nchallenging for OD, limiting its effective use in practice. In this paper, we\npresent FoMo-0D, a pre-trained Foundation Model for zero/0-shot OD on tabular\ndata, which bypasses the hurdle of model selection. To overcome the difficulty\nof labeled data collection, FoMo-0D is trained on synthetic data and can\ndirectly predict the (outlier/inlier) label of test samples without parameter\nfine-tuning -- making the need obsolete for choosing an algorithm/architecture\nand tuning its associated hyperparameters when given a new OD dataset.\nExtensive experiments on 57 real-world datasets against 26 baselines show that\nFoMo-0D significantly outperforms the vast majority of the baselines and is\nstatistically no different from the 2nd best method, with an average inference\ntime of 7.7 ms per sample, offering at least 7x speed-up compared to previous\nmethods. To facilitate future research, our implementations and checkpoints are\nopenly available at https://anonymous.4open.science/r/PFN40D.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2409.05672v2",
    "published_date": "2024-09-09 14:41:24 UTC",
    "updated_date": "2025-02-06 19:40:04 UTC"
  },
  {
    "arxiv_id": "2409.05662v2",
    "title": "Real-Time Human Action Recognition on Embedded Platforms",
    "authors": [
      "Ruiqi Wang",
      "Zichen Wang",
      "Peiqi Gao",
      "Mingzhen Li",
      "Jaehwan Jeong",
      "Yihang Xu",
      "Yejin Lee",
      "Carolyn M. Baum",
      "Lisa Tabor Connor",
      "Chenyang Lu"
    ],
    "abstract": "With advancements in computer vision and deep learning, video-based human\naction recognition (HAR) has become practical. However, due to the complexity\nof the computation pipeline, running HAR on live video streams incurs excessive\ndelays on embedded platforms. This work tackles the real-time performance\nchallenges of HAR with four contributions: 1) an experimental study identifying\na standard Optical Flow (OF) extraction technique as the latency bottleneck in\na state-of-the-art HAR pipeline, 2) an exploration of the latency-accuracy\ntradeoff between the standard and deep learning approaches to OF extraction,\nwhich highlights the need for a novel, efficient motion feature extractor, 3)\nthe design of Integrated Motion Feature Extractor (IMFE), a novel single-shot\nneural network architecture for motion feature extraction with drastic\nimprovement in latency, 4) the development of RT-HARE, a real-time HAR system\ntailored for embedded platforms. Experimental results on an Nvidia Jetson\nXavier NX platform demonstrated that RT-HARE realizes real-time HAR at a video\nframe rate of 30 frames per second while delivering high levels of recognition\naccuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05662v2",
    "published_date": "2024-09-09 14:35:23 UTC",
    "updated_date": "2024-09-11 14:21:29 UTC"
  },
  {
    "arxiv_id": "2409.05655v3",
    "title": "Interactive incremental learning of generalizable skills with local trajectory modulation",
    "authors": [
      "Markus Knauer",
      "Alin Albu-Schäffer",
      "Freek Stulp",
      "João Silvério"
    ],
    "abstract": "The problem of generalization in learning from demonstration (LfD) has\nreceived considerable attention over the years, particularly within the context\nof movement primitives, where a number of approaches have emerged. Recently,\ntwo important approaches have gained recognition. While one leverages\nvia-points to adapt skills locally by modulating demonstrated trajectories,\nanother relies on so-called task-parameterized models that encode movements\nwith respect to different coordinate systems, using a product of probabilities\nfor generalization. While the former are well-suited to precise, local\nmodulations, the latter aim at generalizing over large regions of the workspace\nand often involve multiple objects. Addressing the quality of generalization by\nleveraging both approaches simultaneously has received little attention. In\nthis work, we propose an interactive imitation learning framework that\nsimultaneously leverages local and global modulations of trajectory\ndistributions. Building on the kernelized movement primitives (KMP) framework,\nwe introduce novel mechanisms for skill modulation from direct human corrective\nfeedback. Our approach particularly exploits the concept of via-points to\nincrementally and interactively 1) improve the model accuracy locally, 2) add\nnew objects to the task during execution and 3) extend the skill into regions\nwhere demonstrations were not provided. We evaluate our method on a bearing\nring-loading task using a torque-controlled, 7-DoF, DLR SARA robot.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE Robotics and Automation Letters (RA-L), 16 pages, 19\n  figures, 6 tables. See\n  https://github.com/DLR-RM/interactive-incremental-learning for further\n  information and video",
    "pdf_url": "http://arxiv.org/pdf/2409.05655v3",
    "published_date": "2024-09-09 14:22:19 UTC",
    "updated_date": "2025-02-21 08:46:59 UTC"
  },
  {
    "arxiv_id": "2409.05650v3",
    "title": "Replay Consolidation with Label Propagation for Continual Object Detection",
    "authors": [
      "Riccardo De Monte",
      "Davide Dalle Pezze",
      "Marina Ceccon",
      "Francesco Pasti",
      "Francesco Paissan",
      "Elisabetta Farella",
      "Gian Antonio Susto",
      "Nicola Bellotto"
    ],
    "abstract": "Continual Learning (CL) aims to learn new data while remembering previously\nacquired knowledge. In contrast to CL for image classification, CL for Object\nDetection faces additional challenges such as the missing annotations problem.\nIn this scenario, images from previous tasks may contain instances of unknown\nclasses that could reappear as labeled in future tasks, leading to task\ninterference in replay-based approaches. Consequently, most approaches in the\nliterature have focused on distillation-based techniques, which are effective\nwhen there is a significant class overlap between tasks. In our work, we\npropose an alternative to distillation-based approaches with a novel approach\ncalled Replay Consolidation with Label Propagation for Object Detection\n(RCLPOD). RCLPOD enhances the replay memory by improving the quality of the\nstored samples through a technique that promotes class balance while also\nimproving the quality of the ground truth associated with these samples through\na technique called label propagation. RCLPOD outperforms existing techniques on\nwell-established benchmarks such as VOC and COC. Moreover, our approach is\ndeveloped to work with modern architectures like YOLOv8, making it suitable for\ndynamic, real-world applications such as autonomous driving and robotics, where\ncontinuous learning and resource efficiency are essential.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05650v3",
    "published_date": "2024-09-09 14:16:27 UTC",
    "updated_date": "2025-03-04 10:22:01 UTC"
  },
  {
    "arxiv_id": "2409.05636v1",
    "title": "3D-SAR Tomography and Machine Learning for High-Resolution Tree Height Estimation",
    "authors": [
      "Grace Colverd",
      "Jumpei Takami",
      "Laura Schade",
      "Karol Bot",
      "Joseph A. Gallego-Mejia"
    ],
    "abstract": "Accurately estimating forest biomass is crucial for global carbon cycle\nmodelling and climate change mitigation. Tree height, a key factor in biomass\ncalculations, can be measured using Synthetic Aperture Radar (SAR) technology.\nThis study applies machine learning to extract forest height data from two SAR\nproducts: Single Look Complex (SLC) images and tomographic cubes, in\npreparation for the ESA Biomass Satellite mission. We use the TomoSense\ndataset, containing SAR and LiDAR data from Germany's Eifel National Park, to\ndevelop and evaluate height estimation models. Our approach includes classical\nmethods, deep learning with a 3D U-Net, and Bayesian-optimized techniques. By\ntesting various SAR frequencies and polarimetries, we establish a baseline for\nfuture height and biomass modelling. Best-performing models predict forest\nheight to be within 2.82m mean absolute error for canopies around 30m,\nadvancing our ability to measure global carbon stocks and support climate\naction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05636v1",
    "published_date": "2024-09-09 14:07:38 UTC",
    "updated_date": "2024-09-09 14:07:38 UTC"
  },
  {
    "arxiv_id": "2409.05620v1",
    "title": "Joint Input and Output Coordination for Class-Incremental Learning",
    "authors": [
      "Shuai Wang",
      "Yibing Zhan",
      "Yong Luo",
      "Han Hu",
      "Wei Yu",
      "Yonggang Wen",
      "Dacheng Tao"
    ],
    "abstract": "Incremental learning is nontrivial due to severe catastrophic forgetting.\nAlthough storing a small amount of data on old tasks during incremental\nlearning is a feasible solution, current strategies still do not 1) adequately\naddress the class bias problem, and 2) alleviate the mutual interference\nbetween new and old tasks, and 3) consider the problem of class bias within\ntasks. This motivates us to propose a joint input and output coordination\n(JIOC) mechanism to address these issues. This mechanism assigns different\nweights to different categories of data according to the gradient of the output\nscore, and uses knowledge distillation (KD) to reduce the mutual interference\nbetween the outputs of old and new tasks. The proposed mechanism is general and\nflexible, and can be incorporated into different incremental learning\napproaches that use memory storage. Extensive experiments show that our\nmechanism can significantly improve their performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figues. Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05620v1",
    "published_date": "2024-09-09 13:55:07 UTC",
    "updated_date": "2024-09-09 13:55:07 UTC"
  },
  {
    "arxiv_id": "2409.05611v1",
    "title": "Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection",
    "authors": [
      "Tianwu Lei",
      "Silin Chen",
      "Bohan Wang",
      "Zhengkai Jiang",
      "Ningmu Zou"
    ],
    "abstract": "Most unsupervised anomaly detection methods based on representations of\nnormal samples to distinguish anomalies have recently made remarkable progress.\nHowever, existing methods only learn a single decision boundary for\ndistinguishing the samples within the training dataset, neglecting the\nvariation in feature distribution for normal samples even in the same category\nin the real world. Furthermore, it was not considered that a distribution bias\nstill exists between the test set and the train set. Therefore, we propose an\nAdapted-MoE which contains a routing network and a series of expert models to\nhandle multiple distributions of same-category samples by divide and conquer.\nSpecifically, we propose a routing network based on representation learning to\nroute same-category samples into the subclasses feature space. Then, a series\nof expert models are utilized to learn the representation of various normal\nsamples and construct several independent decision boundaries. We propose the\ntest-time adaption to eliminate the bias between the unseen test sample\nrepresentation and the feature distribution learned by the expert model. Our\nexperiments are conducted on a dataset that provides multiple subclasses from\nthree categories, namely Texture AD benchmark. The Adapted-MoE significantly\nimproves the performance of the baseline model, achieving 2.18%-7.20% and\n1.57%-16.30% increase in I-AUROC and P-AUROC, which outperforms the current\nstate-of-the-art methods. Our code is available at https://github.com/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05611v1",
    "published_date": "2024-09-09 13:49:09 UTC",
    "updated_date": "2024-09-09 13:49:09 UTC"
  },
  {
    "arxiv_id": "2409.05595v2",
    "title": "SynMorph: Generating Synthetic Face Morphing Dataset with Mated Samples",
    "authors": [
      "Haoyu Zhang",
      "Raghavendra Ramachandra",
      "Kiran Raja",
      "Christoph Busch"
    ],
    "abstract": "Face morphing attack detection (MAD) algorithms have become essential to\novercome the vulnerability of face recognition systems. To solve the lack of\nlarge-scale and public-available datasets due to privacy concerns and\nrestrictions, in this work we propose a new method to generate a synthetic face\nmorphing dataset with 2450 identities and more than 100k morphs. The proposed\nsynthetic face morphing dataset is unique for its high-quality samples,\ndifferent types of morphing algorithms, and the generalization for both single\nand differential morphing attack detection algorithms. For experiments, we\napply face image quality assessment and vulnerability analysis to evaluate the\nproposed synthetic face morphing dataset from the perspective of biometric\nsample quality and morphing attack potential on face recognition systems. The\nresults are benchmarked with an existing SOTA synthetic dataset and a\nrepresentative non-synthetic and indicate improvement compared with the SOTA.\nAdditionally, we design different protocols and study the applicability of\nusing the proposed synthetic dataset on training morphing attack detection\nalgorithms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This preprint has been further published in IEEE Access. Print ISSN:\n  2169-3536. Online ISSN: 2169-3536. Digital Object Identifier:\n  10.1109/ACCESS.2025.3548957",
    "pdf_url": "http://arxiv.org/pdf/2409.05595v2",
    "published_date": "2024-09-09 13:29:53 UTC",
    "updated_date": "2025-03-22 17:21:22 UTC"
  },
  {
    "arxiv_id": "2409.05592v1",
    "title": "ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language",
    "authors": [
      "Zhaoyue Sun",
      "Jiazheng Li",
      "Gabriele Pergola",
      "Yulan He"
    ],
    "abstract": "Predicting unknown drug-drug interactions (DDIs) is crucial for improving\nmedication safety. Previous efforts in DDI prediction have typically focused on\nbinary classification or predicting DDI categories, with the absence of\nexplanatory insights that could enhance trust in these predictions. In this\nwork, we propose to generate natural language explanations for DDI predictions,\nenabling the model to reveal the underlying pharmacodynamics and\npharmacokinetics mechanisms simultaneously as making the prediction. To do\nthis, we have collected DDI explanations from DDInter and DrugBank and\ndeveloped various models for extensive experiments and analysis. Our models can\nprovide accurate explanations for unknown DDIs between known drugs. This paper\ncontributes new tools to the field of DDI prediction and lays a solid\nfoundation for further research on generating explanations for DDI predictions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05592v1",
    "published_date": "2024-09-09 13:23:14 UTC",
    "updated_date": "2024-09-09 13:23:14 UTC"
  },
  {
    "arxiv_id": "2409.05591v3",
    "title": "MemoRAG: Boosting Long Context Processing with Global Memory-Enhanced Retrieval Augmentation",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu",
      "Peitian Zhang",
      "Kelong Mao",
      "Defu Lian",
      "Zhicheng Dou",
      "Tiejun Huang"
    ],
    "abstract": "Processing long contexts presents a significant challenge for large language\nmodels (LLMs). While recent advancements allow LLMs to handle much longer\ncontexts than before (e.g., 32K or 128K tokens), it is computationally\nexpensive and can still be insufficient for many applications.\nRetrieval-Augmented Generation (RAG) is considered a promising strategy to\naddress this problem. However, conventional RAG methods face inherent\nlimitations because of two underlying requirements: 1) explicitly stated\nqueries, and 2) well-structured knowledge. These conditions, however, do not\nhold in general long-context processing tasks.\n  In this work, we propose MemoRAG, a novel RAG framework empowered by global\nmemory-augmented retrieval. MemoRAG features a dual-system architecture. First,\nit employs a light but long-range system to create a global memory of the long\ncontext. Once a task is presented, it generates draft answers, providing useful\nclues for the retrieval tools to locate relevant information within the long\ncontext. Second, it leverages an expensive but expressive system, which\ngenerates the final answer based on the retrieved information. Building upon\nthis fundamental framework, we realize the memory module in the form of KV\ncompression, and reinforce its memorization and cluing capacity from the\nGeneration quality's Feedback (a.k.a. RLGF). In our experiments, MemoRAG\nachieves superior performances across a variety of long-context evaluation\ntasks, not only complex scenarios where traditional RAG methods struggle, but\nalso simpler ones where RAG is typically applied.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "theWebConf 2025. Codes and models are in\n  https://github.com/qhjqhj00/MemoRAG",
    "pdf_url": "http://arxiv.org/pdf/2409.05591v3",
    "published_date": "2024-09-09 13:20:31 UTC",
    "updated_date": "2025-04-09 09:09:37 UTC"
  },
  {
    "arxiv_id": "2409.05586v1",
    "title": "Interpretable Responsibility Sharing as a Heuristic for Task and Motion Planning",
    "authors": [
      "Arda Sarp Yenicesu",
      "Sepehr Nourmohammadi",
      "Berk Cicek",
      "Ozgur S. Oguz"
    ],
    "abstract": "This article introduces a novel heuristic for Task and Motion Planning (TAMP)\nnamed Interpretable Responsibility Sharing (IRS), which enhances planning\nefficiency in domestic robots by leveraging human-constructed environments and\ninherent biases. Utilizing auxiliary objects (e.g., trays and pitchers), which\nare commonly found in household settings, IRS systematically incorporates these\nelements to simplify and optimize task execution. The heuristic is rooted in\nthe novel concept of Responsibility Sharing (RS), where auxiliary objects share\nthe task's responsibility with the embodied agent, dividing complex tasks into\nmanageable sub-problems. This division not only reflects human usage patterns\nbut also aids robots in navigating and manipulating within human spaces more\neffectively. By integrating Optimized Rule Synthesis (ORS) for decision-making,\nIRS ensures that the use of auxiliary objects is both strategic and\ncontext-aware, thereby improving the interpretability and effectiveness of\nrobotic planning. Experiments conducted across various household tasks\ndemonstrate that IRS significantly outperforms traditional methods by reducing\nthe effort required in task execution and enhancing the overall decision-making\nprocess. This approach not only aligns with human intuitive methods but also\noffers a scalable solution adaptable to diverse domestic environments. Code is\navailable at https://github.com/asyncs/IRS.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05586v1",
    "published_date": "2024-09-09 13:15:53 UTC",
    "updated_date": "2024-09-09 13:15:53 UTC"
  },
  {
    "arxiv_id": "2409.05585v1",
    "title": "Latent 3D Brain MRI Counterfactual",
    "authors": [
      "Wei Peng",
      "Tian Xia",
      "Fabio De Sousa Ribeiro",
      "Tomas Bosschieter",
      "Ehsan Adeli",
      "Qingyu Zhao",
      "Ben Glocker",
      "Kilian M. Pohl"
    ],
    "abstract": "The number of samples in structural brain MRI studies is often too small to\nproperly train deep learning models. Generative models show promise in\naddressing this issue by effectively learning the data distribution and\ngenerating high-fidelity MRI. However, they struggle to produce diverse,\nhigh-quality data outside the distribution defined by the training data. One\nway to address the issue is using causal models developed for 3D volume\ncounterfactuals. However, accurately modeling causality in high-dimensional\nspaces is a challenge so that these models generally generate 3D brain MRIS of\nlower quality. To address these challenges, we propose a two-stage method that\nconstructs a Structural Causal Model (SCM) within the latent space. In the\nfirst stage, we employ a VQ-VAE to learn a compact embedding of the MRI volume.\nSubsequently, we integrate our causal model into this latent space and execute\na three-step counterfactual procedure using a closed-form Generalized Linear\nModel (GLM). Our experiments conducted on real-world high-resolution MRI data\n(1mm) demonstrate that our method can generate high-quality 3D MRI\ncounterfactuals.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05585v1",
    "published_date": "2024-09-09 13:15:03 UTC",
    "updated_date": "2024-09-09 13:15:03 UTC"
  },
  {
    "arxiv_id": "2409.05573v1",
    "title": "Learning to Model Graph Structural Information on MLPs via Graph Structure Self-Contrasting",
    "authors": [
      "Lirong Wu",
      "Haitao Lin",
      "Guojiang Zhao",
      "Cheng Tan",
      "Stan Z. Li"
    ],
    "abstract": "Recent years have witnessed great success in handling graph-related tasks\nwith Graph Neural Networks (GNNs). However, most existing GNNs are based on\nmessage passing to perform feature aggregation and transformation, where the\nstructural information is explicitly involved in the forward propagation by\ncoupling with node features through graph convolution at each layer. As a\nresult, subtle feature noise or structure perturbation may cause severe error\npropagation, resulting in extremely poor robustness. In this paper, we rethink\nthe roles played by graph structural information in graph data training and\nidentify that message passing is not the only path to modeling structural\ninformation. Inspired by this, we propose a simple but effective Graph\nStructure Self-Contrasting (GSSC) framework that learns graph structural\ninformation without message passing. The proposed framework is based purely on\nMulti-Layer Perceptrons (MLPs), where the structural information is only\nimplicitly incorporated as prior knowledge to guide the computation of\nsupervision signals, substituting the explicit message propagation as in GNNs.\nSpecifically, it first applies structural sparsification to remove potentially\nuninformative or noisy edges in the neighborhood, and then performs structural\nself-contrasting in the sparsified neighborhood to learn robust node\nrepresentations. Finally, structural sparsification and self-contrasting are\nformulated as a bi-level optimization problem and solved in a unified\nframework. Extensive experiments have qualitatively and quantitatively\ndemonstrated that the GSSC framework can produce truly encouraging performance\nwith better generalization and robustness than other leading competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05573v1",
    "published_date": "2024-09-09 12:56:02 UTC",
    "updated_date": "2024-09-09 12:56:02 UTC"
  },
  {
    "arxiv_id": "2409.05565v1",
    "title": "On the Convergence of Sigmoid and tanh Fuzzy General Grey Cognitive Maps",
    "authors": [
      "Xudong Gao",
      "Xiao Guang Gao",
      "Jia Rong",
      "Ni Li",
      "Yifeng Niu",
      "Jun Chen"
    ],
    "abstract": "Fuzzy General Grey Cognitive Map (FGGCM) and Fuzzy Grey Cognitive Map (FGCM)\nare extensions of Fuzzy Cognitive Map (FCM) in terms of uncertainty. FGGCM\nallows for the processing of general grey number with multiple intervals,\nenabling FCM to better address uncertain situations. Although the convergence\nof FCM and FGCM has been discussed in many literature, the convergence of FGGCM\nhas not been thoroughly explored. This paper aims to fill this research gap.\nFirst, metrics for the general grey number space and its vector space is given\nand proved using the Minkowski inequality. By utilizing the characteristic that\nCauchy sequences are convergent sequences, the completeness of these two space\nis demonstrated. On this premise, utilizing Banach fixed point theorem and\nBrowder-Gohde-Kirk fixed point theorem, combined with Lagrange's mean value\ntheorem and Cauchy's inequality, deduces the sufficient conditions for FGGCM to\nconverge to a unique fixed point when using tanh and sigmoid functions as\nactivation functions. The sufficient conditions for the kernels and greyness of\nFGGCM to converge to a unique fixed point are also provided separately.\nFinally, based on Web Experience and Civil engineering FCM, designed\ncorresponding FGGCM with sigmoid and tanh as activation functions by modifying\nthe weights to general grey numbers. By comparing with the convergence theorems\nof FCM and FGCM, the effectiveness of the theorems proposed in this paper was\nverified. It was also demonstrated that the convergence theorems of FCM are\nspecial cases of the theorems proposed in this paper. The study for convergence\nof FGGCM is of great significance for guiding the learning algorithm of FGGCM,\nwhich is needed for designing FGGCM with specific fixed points, lays a solid\ntheoretical foundation for the application of FGGCM in fields such as control,\nprediction, and decision support systems.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05565v1",
    "published_date": "2024-09-09 12:46:03 UTC",
    "updated_date": "2024-09-09 12:46:03 UTC"
  },
  {
    "arxiv_id": "2409.05564v1",
    "title": "LEROjD: Lidar Extended Radar-Only Object Detection",
    "authors": [
      "Patrick Palmer",
      "Martin Krüger",
      "Stefan Schütte",
      "Richard Altendorfer",
      "Ganesh Adam",
      "Torsten Bertram"
    ],
    "abstract": "Accurate 3D object detection is vital for automated driving. While lidar\nsensors are well suited for this task, they are expensive and have limitations\nin adverse weather conditions. 3+1D imaging radar sensors offer a\ncost-effective, robust alternative but face challenges due to their low\nresolution and high measurement noise. Existing 3+1D imaging radar datasets\ninclude radar and lidar data, enabling cross-modal model improvements. Although\nlidar should not be used during inference, it can aid the training of\nradar-only object detectors. We explore two strategies to transfer knowledge\nfrom the lidar to the radar domain and radar-only object detectors: 1.\nmulti-stage training with sequential lidar point cloud thin-out, and 2.\ncross-modal knowledge distillation. In the multi-stage process, three thin-out\nmethods are examined. Our results show significant performance gains of up to\n4.2 percentage points in mean Average Precision with multi-stage training and\nup to 3.9 percentage points with knowledge distillation by initializing the\nstudent with the teacher's weights. The main benefit of these approaches is\ntheir applicability to other 3D object detection networks without altering\ntheir architecture, as we show by analyzing it on two different object\ndetectors. Our code is available at https://github.com/rst-tu-dortmund/lerojd",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication as ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05564v1",
    "published_date": "2024-09-09 12:43:25 UTC",
    "updated_date": "2024-09-09 12:43:25 UTC"
  },
  {
    "arxiv_id": "2409.05559v1",
    "title": "CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning",
    "authors": [
      "Jinwei He",
      "Feng Lu"
    ],
    "abstract": "Large language models (LLMs) have been utilized in solving diverse reasoning\ntasks, encompassing common sense, arithmetic and deduction tasks. However, with\ndifficulties of reversing thinking patterns and irrelevant premises, how to\ndetermine the authenticity of the cause in abductive logical reasoning remains\nunderexplored. Inspired by hypothesis and verification method and\nidentification of irrelevant information in human thinking process, we propose\na new framework for LLMs abductive logical reasoning called CauseJudger (CJ),\nwhich identifies the authenticity of possible cause by transforming thinking\nfrom reverse to forward and removing irrelevant information. In addition, we\nconstruct an abductive logical reasoning dataset for decision task called\nCauseLogics, which contains 200,000 tasks of varying reasoning lengths. Our\nexperiments show the efficiency of CJ with overall experiments and ablation\nexperiments as well as case studies on our dataset and reconstructed public\ndataset. Notably, CJ's implementation is efficient, requiring only two calls to\nLLM. Its impact is profound: when using gpt-3.5, CJ achieves a maximum\ncorrectness improvement of 41% compared to Zero-Shot-CoT. Moreover, with gpt-4,\nCJ attains an accuracy exceeding 90% across all datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05559v1",
    "published_date": "2024-09-09 12:30:43 UTC",
    "updated_date": "2024-09-09 12:30:43 UTC"
  },
  {
    "arxiv_id": "2409.05558v1",
    "title": "Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs",
    "authors": [
      "Yahya Jabary",
      "Andreas Plesner",
      "Turlan Kuzhagaliyev",
      "Roger Wattenhofer"
    ],
    "abstract": "Modern CAPTCHAs rely heavily on vision tasks that are supposedly hard for\ncomputers but easy for humans. However, advances in image recognition models\npose a significant threat to such CAPTCHAs. These models can easily be fooled\nby generating some well-hidden \"random\" noise and adding it to the image, or\nhiding objects in the image. However, these methods are model-specific and thus\ncan not aid CAPTCHAs in fooling all models. We show in this work that by\nallowing for more significant changes to the images while preserving the\nsemantic information and keeping it solvable by humans, we can fool many\nstate-of-the-art models. Specifically, we demonstrate that by adding masks of\nvarious intensities the Accuracy @ 1 (Acc@1) drops by more than 50%-points for\nall models, and supposedly robust models such as vision transformers see an\nAcc@1 drop of 80%-points.\n  These masks can therefore effectively fool modern image classifiers, thus\nshowing that machines have not caught up with humans -- yet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2409.05558v1",
    "published_date": "2024-09-09 12:29:53 UTC",
    "updated_date": "2024-09-09 12:29:53 UTC"
  },
  {
    "arxiv_id": "2409.05556v1",
    "title": "SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning",
    "authors": [
      "Alireza Ghafarollahi",
      "Markus J. Buehler"
    ],
    "abstract": "A key challenge in artificial intelligence is the creation of systems capable\nof autonomously advancing scientific understanding by exploring novel domains,\nidentifying complex patterns, and uncovering previously unseen connections in\nvast scientific data. In this work, we present SciAgents, an approach that\nleverages three core concepts: (1) the use of large-scale ontological knowledge\ngraphs to organize and interconnect diverse scientific concepts, (2) a suite of\nlarge language models (LLMs) and data retrieval tools, and (3) multi-agent\nsystems with in-situ learning capabilities. Applied to biologically inspired\nmaterials, SciAgents reveals hidden interdisciplinary relationships that were\npreviously considered unrelated, achieving a scale, precision, and exploratory\npower that surpasses traditional human-driven research methods. The framework\nautonomously generates and refines research hypotheses, elucidating underlying\nmechanisms, design principles, and unexpected material properties. By\nintegrating these capabilities in a modular fashion, the intelligent system\nyields material discoveries, critique and improve existing hypotheses, retrieve\nup-to-date data about existing research, and highlights their strengths and\nlimitations. Our case studies demonstrate scalable capabilities to combine\ngenerative AI, ontological representations, and multi-agent modeling,\nharnessing a `swarm of intelligence' similar to biological systems. This\nprovides new avenues for materials discovery and accelerates the development of\nadvanced materials by unlocking Nature's design principles.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "cond-mat.mtrl-sci",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05556v1",
    "published_date": "2024-09-09 12:25:10 UTC",
    "updated_date": "2024-09-09 12:25:10 UTC"
  },
  {
    "arxiv_id": "2409.05531v3",
    "title": "HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment",
    "authors": [
      "Dianbo Ma",
      "Kousuke Imamura",
      "Ziyan Gao",
      "Xiangjie Wang",
      "Satoshi Yamane"
    ],
    "abstract": "Optical flow estimation is a fundamental and long-standing visual task. In\nthis work, we present a novel method, dubbed HMAFlow, to improve optical flow\nestimation in challenging scenes, particularly those involving small objects.\nThe proposed model mainly consists of two core components: a Hierarchical\nMotion Field Alignment (HMA) module and a Correlation Self-Attention (CSA)\nmodule. In addition, we rebuild 4D cost volumes by employing a Multi-Scale\nCorrelation Search (MCS) layer and replacing average pooling in common cost\nvolumes with a search strategy utilizing multiple search ranges. Experimental\nresults demonstrate that our model achieves the best generalization performance\ncompared to other state-of-the-art methods. Specifically, compared with RAFT,\nour method achieves relative error reductions of 14.2% and 3.4% on the clean\npass and final pass of the Sintel online benchmark, respectively. On the KITTI\ntest benchmark, HMAFlow surpasses RAFT and GMA in the Fl-all metric by relative\nmargins of 6.8% and 7.7%, respectively. To facilitate future research, our code\nwill be made available at https://github.com/BooTurbo/HMAFlow.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05531v3",
    "published_date": "2024-09-09 11:43:35 UTC",
    "updated_date": "2024-11-15 05:49:30 UTC"
  },
  {
    "arxiv_id": "2409.05524v1",
    "title": "An encoding of argumentation problems using quadratic unconstrained binary optimization",
    "authors": [
      "Marco Baioletti",
      "Francesco Santini"
    ],
    "abstract": "In this paper, we develop a way to encode several NP-Complete problems in\nAbstract Argumentation to Quadratic Unconstrained Binary Optimization (QUBO)\nproblems. In this form, a solution for a QUBO problem involves minimizing a\nquadratic function over binary variables (0/1), where the coefficients can be\nrepresented by a symmetric square matrix (or an equivalent upper triangular\nversion). With the QUBO formulation, exploiting new computing architectures,\nsuch as Quantum and Digital Annealers, is possible. A more conventional\napproach consists of developing approximate solvers, which, in this case, are\nused to tackle the intrinsic complexity. We performed tests to prove the\ncorrectness and applicability of classical problems in Argumentation and\nenforcement of argument sets. We compared our approach to two other approximate\nsolvers in the literature during tests. In the final experimentation, we used a\nSimulated Annealing algorithm on a local machine. Also, we tested a Quantum\nAnnealer from the D-Wave Ocean SDK and the Leap Quantum Cloud Service.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05524v1",
    "published_date": "2024-09-09 11:29:46 UTC",
    "updated_date": "2024-09-09 11:29:46 UTC"
  },
  {
    "arxiv_id": "2409.05521v1",
    "title": "Harmonic Reasoning in Large Language Models",
    "authors": [
      "Anna Kruspe"
    ],
    "abstract": "Large Language Models (LLMs) are becoming very popular and are used for many\ndifferent purposes, including creative tasks in the arts. However, these models\nsometimes have trouble with specific reasoning tasks, especially those that\ninvolve logical thinking and counting. This paper looks at how well LLMs\nunderstand and reason when dealing with musical tasks like figuring out notes\nfrom intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o\nto see how they handle these tasks. Our results show that while LLMs do well\nwith note intervals, they struggle with more complicated tasks like recognizing\nchords and scales. This points out clear limits in current LLM abilities and\nshows where we need to make them better, which could help improve how they\nthink and work in both artistic and other complex areas. We also provide an\nautomatically generated benchmark data set for the described tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05521v1",
    "published_date": "2024-09-09 11:28:02 UTC",
    "updated_date": "2024-09-09 11:28:02 UTC"
  },
  {
    "arxiv_id": "2409.13724v1",
    "title": "Logically Consistent Language Models via Neuro-Symbolic Integration",
    "authors": [
      "Diego Calanzone",
      "Stefano Teso",
      "Antonio Vergari"
    ],
    "abstract": "Large language models (LLMs) are a promising venue for natural language\nunderstanding and generation. However, current LLMs are far from reliable: they\nare prone to generating non-factual information and, more crucially, to\ncontradicting themselves when prompted to reason about relations between\nentities of the world. These problems are currently addressed with large scale\nfine-tuning or by delegating reasoning to external tools. In this work, we\nstrive for a middle ground and introduce a loss based on neuro-symbolic\nreasoning that teaches an LLM to be logically consistent with an external set\nof facts and rules and improves self-consistency even when the LLM is\nfine-tuned on a limited set of facts. Our approach also allows to easily\ncombine multiple logical constraints at once in a principled way, delivering\nLLMs that are more consistent w.r.t. all constraints and improve over several\nbaselines w.r.t. a given constraint. Moreover, our method allows LLMs to\nextrapolate to unseen but semantically similar factual knowledge, represented\nin unseen datasets, more systematically.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13724v1",
    "published_date": "2024-09-09 10:52:57 UTC",
    "updated_date": "2024-09-09 10:52:57 UTC"
  },
  {
    "arxiv_id": "2409.09074v1",
    "title": "Fair Reinforcement Learning Algorithm for PV Active Control in LV Distribution Networks",
    "authors": [
      "Maurizio Vassallo",
      "Amina Benzerga",
      "Alireza Bahmanyar",
      "Damien Ernst"
    ],
    "abstract": "The increasing adoption of distributed energy resources, particularly\nphotovoltaic (PV) panels, has presented new and complex challenges for power\nnetwork control. With the significant energy production from PV panels, voltage\nissues in the network have become a problem. Currently, PV smart inverters\n(SIs) are used to mitigate the voltage problems by controlling their active\npower generation and reactive power injection or absorption. However, reducing\nthe active power output of PV panels can be perceived as unfair to some\ncustomers, discouraging future installations. To solve this issue, in this\npaper, a reinforcement learning technique is proposed to address voltage issues\nin a distribution network, while considering fairness in active power\ncurtailment among customers. The feasibility of the proposed approach is\nexplored through experiments, demonstrating its ability to effectively control\nvoltage in a fair and efficient manner.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09074v1",
    "published_date": "2024-09-09 10:51:08 UTC",
    "updated_date": "2024-09-09 10:51:08 UTC"
  },
  {
    "arxiv_id": "2409.05495v1",
    "title": "Using machine learning for fault detection in lighthouse light sensors",
    "authors": [
      "Michael Kampouridis",
      "Nikolaos Vastardis",
      "George Rayment"
    ],
    "abstract": "Lighthouses play a crucial role in ensuring maritime safety by signaling\nhazardous areas such as dangerous coastlines, shoals, reefs, and rocks, along\nwith aiding harbor entries and aerial navigation. This is achieved through the\nuse of photoresistor sensors that activate or deactivate based on the time of\nday. However, a significant issue is the potential malfunction of these\nsensors, leading to the gradual misalignment of the light's operational timing.\nThis paper introduces an innovative machine learning-based approach for\nautomatically detecting such malfunctions. We evaluate four distinct\nalgorithms: decision trees, random forest, extreme gradient boosting, and\nmulti-layer perceptron. Our findings indicate that the multi-layer perceptron\nis the most effective, capable of detecting timing discrepancies as small as\n10-15 minutes. This accuracy makes it a highly efficient tool for automating\nthe detection of faults in lighthouse light sensors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05495v1",
    "published_date": "2024-09-09 10:47:41 UTC",
    "updated_date": "2024-09-09 10:47:41 UTC"
  },
  {
    "arxiv_id": "2409.05929v4",
    "title": "M3-Jepa: Multimodal Alignment via Multi-directional MoE based on the JEPA framework",
    "authors": [
      "Hongyang Lei",
      "Xiaolong Cheng",
      "Dan Wang",
      "Kun Fan",
      "Qi Qin",
      "Huazhen Huang",
      "Yetao Wu",
      "Qingqing Gu",
      "Zhonglin Jiang",
      "Yong Chen",
      "Luo Ji"
    ],
    "abstract": "Current multimodal alignment strategies primarily use single or unified\nmodality encoders, while optimizing the alignment on the original token space.\nSuch a framework is easy to implement and incorporate with the pretrained\nknowledge, but might result in information bias. To deal with such issues, the\njoint encoding predictive architecture (JEPA) learns the alignment loss on the\nlatent space, with a predictor to convert the input encoding to the output\nlatent space. However, the application of JEPA in multimodal scenarios is\nlimited so far. In this paper, we introduce M3-Jepa, a scalable multimodal\nalignment framework, with the predictor implemented by a multi-directional\nmixture of experts (MoE). We demonstrate the framework can maximize the mutual\ninformation with information theory derivations, by alternating the\noptimization between different uni-directional tasks. By thoroughly designed\nexperiments, we show that M3-Jepa can obtain state-of-the-art performance on\ndifferent modalities and tasks, generalize to unseen datasets and domains, and\nis computationally efficient in training and inference. Our study indicates\nthat M3-Jepa might provide a new paradigm to self-supervised learning and\nopen-world modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 4 figures. Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.05929v4",
    "published_date": "2024-09-09 10:40:50 UTC",
    "updated_date": "2025-05-05 16:48:19 UTC"
  },
  {
    "arxiv_id": "2409.05486v2",
    "title": "Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models",
    "authors": [
      "Camilo Thorne",
      "Christian Druckenbrodt",
      "Kinga Szarkowska",
      "Deepika Goyal",
      "Pranita Marajan",
      "Vijay Somanath",
      "Corey Harper",
      "Mao Yan",
      "Tony Scerri"
    ],
    "abstract": "arXiv admin comment: This version has been removed by arXiv administrators as\nthe submitter did not have the rights to agree to the license at the time of\nsubmission",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This document was submitted without obtaining all necessary\n  permissions and therefore needs to be withdrawn. The corresponding author\n  apologizes for any inconvenience this might cause",
    "pdf_url": "http://arxiv.org/pdf/2409.05486v2",
    "published_date": "2024-09-09 10:30:00 UTC",
    "updated_date": "2024-09-17 11:41:28 UTC"
  },
  {
    "arxiv_id": "2409.05484v2",
    "title": "CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement",
    "authors": [
      "Seungheun Baek",
      "Soyon Park",
      "Yan Ting Chok",
      "Junhyun Lee",
      "Jueon Park",
      "Mogan Gim",
      "Jaewoo Kang"
    ],
    "abstract": "Predicting cellular responses to various perturbations is a critical focus in\ndrug discovery and personalized therapeutics, with deep learning models playing\na significant role in this endeavor. Single-cell datasets contain technical\nartifacts that may hinder the predictability of such models, which poses\nquality control issues highly regarded in this area. To address this, we\npropose CRADLE-VAE, a causal generative framework tailored for single-cell gene\nperturbation modeling, enhanced with counterfactual reasoning-based artifact\ndisentanglement. Throughout training, CRADLE-VAE models the underlying latent\ndistribution of technical artifacts and perturbation effects present in\nsingle-cell datasets. It employs counterfactual reasoning to effectively\ndisentangle such artifacts by modulating the latent basal spaces and learns\nrobust features for generating cellular response data with improved quality.\nExperimental results demonstrate that this approach improves not only treatment\neffect estimation performance but also generative quality as well. The\nCRADLE-VAE codebase is publicly available at\nhttps://github.com/dmis-lab/CRADLE-VAE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05484v2",
    "published_date": "2024-09-09 10:29:28 UTC",
    "updated_date": "2024-09-10 02:47:49 UTC"
  },
  {
    "arxiv_id": "2409.05466v2",
    "title": "Proto-OOD: Enhancing OOD Object Detection with Prototype Feature Similarity",
    "authors": [
      "Junkun Chen",
      "Jilin Mei",
      "Liang Chen",
      "Fangzhou Zhao",
      "Yan Xing",
      "Yu Hu"
    ],
    "abstract": "Neural networks that are trained on limited category samples often mispredict\nout-of-distribution (OOD) objects. We observe that features of the same\ncategory are more tightly clustered in feature space, while those of different\ncategories are more dispersed. Based on this, we propose using prototype\nsimilarity for OOD detection. Drawing on widely used prototype features in\nfew-shot learning, we introduce a novel OOD detection network structure\n(Proto-OOD). Proto-OOD enhances the representativeness of category prototypes\nusing contrastive loss and detects OOD data by evaluating the similarity\nbetween input features and category prototypes. During training, Proto-OOD\ngenerates OOD samples for training the similarity module with a negative\nembedding generator. When Pascal VOC are used as the in-distribution dataset\nand MS-COCO as the OOD dataset, Proto-OOD significantly reduces the FPR (false\npositive rate). Moreover, considering the limitations of existing evaluation\nmetrics, we propose a more reasonable evaluation protocol. The code will be\nreleased.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05466v2",
    "published_date": "2024-09-09 09:48:27 UTC",
    "updated_date": "2025-01-28 05:29:55 UTC"
  },
  {
    "arxiv_id": "2409.05457v1",
    "title": "Visualizing Extensions of Argumentation Frameworks as Layered Graphs",
    "authors": [
      "Martin Nöllenburg",
      "Christian Pirker",
      "Anna Rapberger",
      "Stefan Woltran",
      "Jules Wulms"
    ],
    "abstract": "The visualization of argumentation frameworks (AFs) is crucial for enabling a\nwide applicability of argumentative tools. However, their visualization is\noften considered only as an accompanying part of tools for computing semantics\nand standard graphical representations are used. We introduce a new\nvisualization technique that draws an AF, together with an extension (as part\nof the input), as a 3-layer graph layout. Our technique supports the user to\nmore easily explore the visualized AF, better understand extensions, and verify\nalgorithms for computing semantics. To optimize the visual clarity and\naesthetics of this layout, we propose to minimize edge crossings in our 3-layer\ndrawing. We do so by an exact ILP-based approach, but also propose a fast\nheuristic pipeline. Via a quantitative evaluation, we show that the heuristic\nis feasible even for large instances, while producing at most twice as many\ncrossings as an optimal drawing in most cases.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05457v1",
    "published_date": "2024-09-09 09:29:53 UTC",
    "updated_date": "2024-09-09 09:29:53 UTC"
  },
  {
    "arxiv_id": "2409.05435v1",
    "title": "Semifactual Explanations for Reinforcement Learning",
    "authors": [
      "Jasmina Gajcin",
      "Jovan Jeromela",
      "Ivana Dusparic"
    ],
    "abstract": "Reinforcement Learning (RL) is a learning paradigm in which the agent learns\nfrom its environment through trial and error. Deep reinforcement learning (DRL)\nalgorithms represent the agent's policies using neural networks, making their\ndecisions difficult to interpret. Explaining the behaviour of DRL agents is\nnecessary to advance user trust, increase engagement, and facilitate\nintegration with real-life tasks. Semifactual explanations aim to explain an\noutcome by providing \"even if\" scenarios, such as \"even if the car were moving\ntwice as slowly, it would still have to swerve to avoid crashing\". Semifactuals\nhelp users understand the effects of different factors on the outcome and\nsupport the optimisation of resources. While extensively studied in psychology\nand even utilised in supervised learning, semifactuals have not been used to\nexplain the decisions of RL systems. In this work, we develop a first approach\nto generating semifactual explanations for RL agents. We start by defining five\nproperties of desirable semifactual explanations in RL and then introducing\nSGRL-Rewind and SGRL-Advance, the first algorithms for generating semifactual\nexplanations in RL. We evaluate the algorithms in two standard RL environments\nand find that they generate semifactuals that are easier to reach, represent\nthe agent's policy better, and are more diverse compared to baselines. Lastly,\nwe conduct and analyse a user study to assess the participant's perception of\nsemifactual explanations of the agent's actions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.05435v1",
    "published_date": "2024-09-09 08:37:47 UTC",
    "updated_date": "2024-09-09 08:37:47 UTC"
  },
  {
    "arxiv_id": "2409.05433v1",
    "title": "State-Novelty Guided Action Persistence in Deep Reinforcement Learning",
    "authors": [
      "Jianshu Hu",
      "Paul Weng",
      "Yutong Ban"
    ],
    "abstract": "While a powerful and promising approach, deep reinforcement learning (DRL)\nstill suffers from sample inefficiency, which can be notably improved by\nresorting to more sophisticated techniques to address the\nexploration-exploitation dilemma. One such technique relies on action\npersistence (i.e., repeating an action over multiple steps). However, previous\nwork exploiting action persistence either applies a fixed strategy or learns\nadditional value functions (or policy) for selecting the repetition number. In\nthis paper, we propose a novel method to dynamically adjust the action\npersistence based on the current exploration status of the state space. In such\na way, our method does not require training of additional value functions or\npolicy. Moreover, the use of a smooth scheduling of the repeat probability\nallows a more effective balance between exploration and exploitation.\nFurthermore, our method can be seamlessly integrated into various basic\nexploration strategies to incorporate temporal persistence. Finally, extensive\nexperiments on different DMControl tasks demonstrate that our state-novelty\nguided action persistence method significantly improves the sample efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2409.05433v1",
    "published_date": "2024-09-09 08:34:22 UTC",
    "updated_date": "2024-09-09 08:34:22 UTC"
  },
  {
    "arxiv_id": "2409.05925v2",
    "title": "Assessing SPARQL capabilities of Large Language Models",
    "authors": [
      "Lars-Peter Meyer",
      "Johannes Frey",
      "Felix Brei",
      "Natanael Arndt"
    ],
    "abstract": "The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)\noffers significant synergistic potential for knowledge-driven applications. One\npossible integration is the interpretation and generation of formal languages,\nsuch as those used in the Semantic Web, with SPARQL being a core technology for\naccessing KGs. In this paper, we focus on measuring out-of-the box capabilities\nof LLMs to work with SPARQL and more specifically with SPARQL SELECT queries\napplying a quantitative approach.\n  We implemented various benchmarking tasks in the LLM-KG-Bench framework for\nautomated execution and evaluation with several LLMs. The tasks assess\ncapabilities along the dimensions of syntax, semantic read, semantic create,\nand the role of knowledge graph prompt inclusion.\n  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,\nand Claude models. Our findings indicate that working with SPARQL SELECT\nqueries is still challenging for LLMs and heavily depends on the specific LLM\nas well as the complexity of the task. While fixing basic syntax errors seems\nto pose no problems for the best of the current LLMs evaluated, creating\nsemantically correct SPARQL SELECT queries is difficult in several cases.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "Peer reviewed and published at NLP4KGc @ Semantics 2024, see original\n  publication at https://ceur-ws.org/Vol-3874/paper3.pdf . Updated Metadata",
    "pdf_url": "http://arxiv.org/pdf/2409.05925v2",
    "published_date": "2024-09-09 08:29:39 UTC",
    "updated_date": "2025-04-04 11:59:49 UTC"
  },
  {
    "arxiv_id": "2409.05420v1",
    "title": "AD-Net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation",
    "authors": [
      "Asim Naveed",
      "Syed S. Naqvi",
      "Tariq M. Khan",
      "Shahzaib Iqbal",
      "M. Yaqoob Wani",
      "Haroon Ahmed Khan"
    ],
    "abstract": "In computer-aided diagnosis tools employed for skin cancer treatment and\nearly diagnosis, skin lesion segmentation is important. However, achieving\nprecise segmentation is challenging due to inherent variations in appearance,\ncontrast, texture, and blurry lesion boundaries. This research presents a\nrobust approach utilizing a dilated convolutional residual network, which\nincorporates an attention-based spatial feature enhancement block (ASFEB) and\nemploys a guided decoder strategy. In each dilated convolutional residual\nblock, dilated convolution is employed to broaden the receptive field with\nvarying dilation rates. To improve the spatial feature information of the\nencoder, we employed an attention-based spatial feature enhancement block in\nthe skip connections. The ASFEB in our proposed method combines feature maps\nobtained from average and maximum-pooling operations. These combined features\nare then weighted using the active outcome of global average pooling and\nconvolution operations. Additionally, we have incorporated a guided decoder\nstrategy, where each decoder block is optimized using an individual loss\nfunction to enhance the feature learning process in the proposed AD-Net. The\nproposed AD-Net presents a significant benefit by necessitating fewer model\nparameters compared to its peer methods. This reduction in parameters directly\nimpacts the number of labeled data required for training, facilitating faster\nconvergence during the training process. The effectiveness of the proposed\nAD-Net was evaluated using four public benchmark datasets. We conducted a\nWilcoxon signed-rank test to verify the efficiency of the AD-Net. The outcomes\nsuggest that our method surpasses other cutting-edge methods in performance,\neven without the implementation of data augmentation strategies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05420v1",
    "published_date": "2024-09-09 08:21:17 UTC",
    "updated_date": "2024-09-09 08:21:17 UTC"
  },
  {
    "arxiv_id": "2409.13723v3",
    "title": "Explainable Artificial Intelligence (XAI) for Malware Analysis: A Survey of Techniques, Applications, and Open Challenges",
    "authors": [
      "Harikha Manthena",
      "Shaghayegh Shajarian",
      "Jeffrey Kimmell",
      "Mahmoud Abdelsalam",
      "Sajad Khorsandroo",
      "Maanak Gupta"
    ],
    "abstract": "Machine learning (ML) has rapidly advanced in recent years, revolutionizing\nfields such as finance, medicine, and cybersecurity. In malware detection,\nML-based approaches have demonstrated high accuracy; however, their lack of\ntransparency poses a significant challenge. Traditional black-box models often\nfail to provide interpretable justifications for their predictions, limiting\ntheir adoption in security-critical environments where understanding the\nreasoning behind a detection is essential for threat mitigation and response.\nExplainable AI (XAI) addresses this gap by enhancing model interpretability\nwhile maintaining strong detection capabilities. This survey presents a\ncomprehensive review of state-of-the-art ML techniques for malware analysis,\nwith a specific focus on explainability methods. We examine existing XAI\nframeworks, their application in malware classification and detection, and the\nchallenges associated with making malware detection models more interpretable.\nAdditionally, we explore recent advancements and highlight open research\nchallenges in the field of explainable malware analysis. By providing a\nstructured overview of XAI-driven malware detection approaches, this survey\nserves as a valuable resource for researchers and practitioners seeking to\nbridge the gap between ML performance and explainability in cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13723v3",
    "published_date": "2024-09-09 08:19:33 UTC",
    "updated_date": "2025-04-03 22:09:42 UTC"
  },
  {
    "arxiv_id": "2409.05414v1",
    "title": "CipherDM: Secure Three-Party Inference for Diffusion Model Sampling",
    "authors": [
      "Xin Zhao",
      "Xiaojun Chen",
      "Xudong Chen",
      "He Li",
      "Tingyu Fan",
      "Zhendong Zhao"
    ],
    "abstract": "Diffusion Models (DMs) achieve state-of-the-art synthesis results in image\ngeneration and have been applied to various fields. However, DMs sometimes\nseriously violate user privacy during usage, making the protection of privacy\nan urgent issue. Using traditional privacy computing schemes like Secure\nMulti-Party Computation (MPC) directly in DMs faces significant computation and\ncommunication challenges. To address these issues, we propose CipherDM, the\nfirst novel, versatile and universal framework applying MPC technology to DMs\nfor secure sampling, which can be widely implemented on multiple DM based\ntasks. We thoroughly analyze sampling latency breakdown, find time-consuming\nparts and design corresponding secure MPC protocols for computing nonlinear\nactivations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular\narchitectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers.\nCompared to direct implementation on SPU, our approach improves running time by\napproximately 1.084\\times \\sim 2.328\\times, and reduces communication costs by\napproximately 1.212\\times \\sim 1.791\\times.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05414v1",
    "published_date": "2024-09-09 08:16:17 UTC",
    "updated_date": "2024-09-09 08:16:17 UTC"
  },
  {
    "arxiv_id": "2409.05405v2",
    "title": "A Survey of Multimodal Composite Editing and Retrieval",
    "authors": [
      "Suyan Li",
      "Fuxiang Huang",
      "Lei Zhang"
    ],
    "abstract": "In the real world, where information is abundant and diverse across different\nmodalities, understanding and utilizing various data types to improve retrieval\nsystems is a key focus of research. Multimodal composite retrieval integrates\ndiverse modalities such as text, image and audio, etc. to provide more\naccurate, personalized, and contextually relevant results. To facilitate a\ndeeper understanding of this promising direction, this survey explores\nmultimodal composite editing and retrieval in depth, covering image-text\ncomposite editing, image-text composite retrieval, and other multimodal\ncomposite retrieval. In this survey, we systematically organize the application\nscenarios, methods, benchmarks, experiments, and future directions. Multimodal\nlearning is a hot topic in large model era, and have also witnessed some\nsurveys in multimodal learning and vision-language models with transformers\npublished in the PAMI journal. To the best of our knowledge, this survey is the\nfirst comprehensive review of the literature on multimodal composite retrieval,\nwhich is a timely complement of multimodal fusion to existing reviews. To help\nreaders' quickly track this field, we build the project page for this survey,\nwhich can be found at\nhttps://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 3 figures, and 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.05405v2",
    "published_date": "2024-09-09 08:06:50 UTC",
    "updated_date": "2024-09-11 02:44:52 UTC"
  },
  {
    "arxiv_id": "2409.05402v1",
    "title": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications",
    "authors": [
      "Ziming Zhao",
      "Tiehua Zhang",
      "Zijian Yi",
      "Zhishu Shen"
    ],
    "abstract": "Hypergraphs are increasingly utilized in both unimodal and multimodal data\nscenarios due to their superior ability to model and extract higher-order\nrelationships among nodes, compared to traditional graphs. However, current\nhypergraph models are encountering challenges related to imbalanced data, as\nthis imbalance can lead to biases in the model towards the more prevalent\nclasses. While the existing techniques, such as GraphSMOTE, have improved\nclassification accuracy for minority samples in graph data, they still fall\nshort when addressing the unique structure of hypergraphs. Inspired by SMOTE\nconcept, we propose HyperSMOTE as a solution to alleviate the class imbalance\nissue in hypergraph learning. This method involves a two-step process:\ninitially synthesizing minority class nodes, followed by the nodes integration\ninto the original hypergraph. We synthesize new nodes based on samples from\nminority classes and their neighbors. At the same time, in order to solve the\nproblem on integrating the new node into the hypergraph, we train a decoder\nbased on the original hypergraph incidence matrix to adaptively associate the\naugmented node to hyperedges. We conduct extensive evaluation on multiple\nsingle-modality datasets, such as Cora, Cora-CA and Citeseer, as well as\nmultimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE,\nshowing an average performance gain of 3.38% and 2.97% on accuracy,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05402v1",
    "published_date": "2024-09-09 08:01:28 UTC",
    "updated_date": "2024-09-09 08:01:28 UTC"
  },
  {
    "arxiv_id": "2409.05396v1",
    "title": "FacialFlowNet: Advancing Facial Optical Flow Estimation with a Diverse Dataset and a Decomposed Model",
    "authors": [
      "Jianzhi Lu",
      "Ruian He",
      "Shili Zhou",
      "Weimin Tan",
      "Bo Yan"
    ],
    "abstract": "Facial movements play a crucial role in conveying altitude and intentions,\nand facial optical flow provides a dynamic and detailed representation of it.\nHowever, the scarcity of datasets and a modern baseline hinders the progress in\nfacial optical flow research. This paper proposes FacialFlowNet (FFN), a novel\nlarge-scale facial optical flow dataset, and the Decomposed Facial Flow Model\n(DecFlow), the first method capable of decomposing facial flow. FFN comprises\n9,635 identities and 105,970 image pairs, offering unprecedented diversity for\ndetailed facial and head motion analysis. DecFlow features a facial\nsemantic-aware encoder and a decomposed flow decoder, excelling in accurately\nestimating and decomposing facial flow into head and expression components.\nComprehensive experiments demonstrate that FFN significantly enhances the\naccuracy of facial flow estimation across various optical flow methods,\nachieving up to an 11% reduction in Endpoint Error (EPE) (from 3.91 to 3.48).\nMoreover, DecFlow, when coupled with FFN, outperforms existing methods in both\nsynthetic and real-world scenarios, enhancing facial expression analysis. The\ndecomposed expression flow achieves a substantial accuracy improvement of 18%\n(from 69.1% to 82.1%) in micro-expressions recognition. These contributions\nrepresent a significant advancement in facial motion analysis and optical flow\nestimation. Codes and datasets can be found.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ACMMM2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05396v1",
    "published_date": "2024-09-09 07:49:13 UTC",
    "updated_date": "2024-09-09 07:49:13 UTC"
  },
  {
    "arxiv_id": "2409.05395v2",
    "title": "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling",
    "authors": [
      "Georgios Pantazopoulos",
      "Malvina Nikandrou",
      "Alessandro Suglia",
      "Oliver Lemon",
      "Arash Eshghi"
    ],
    "abstract": "This study explores replacing Transformers in Visual Language Models (VLMs)\nwith Mamba, a recent structured state space model (SSM) that demonstrates\npromising performance in sequence modeling. We test models up to 3B parameters\nunder controlled conditions, showing that Mamba-based VLMs outperforms\nTransformers-based VLMs in captioning, question answering, and reading\ncomprehension. However, we find that Transformers achieve greater performance\nin visual grounding and the performance gap widens with scale. We explore two\nhypotheses to explain this phenomenon: 1) the effect of task-agnostic visual\nencoding on the updates of the hidden states, and 2) the difficulty in\nperforming visual grounding from the perspective of in-context multimodal\nretrieval. Our results indicate that a task-aware encoding yields minimal\nperformance gains on grounding, however, Transformers significantly outperform\nMamba at in-context multimodal retrieval. Overall, Mamba shows promising\nperformance on tasks where the correct output relies on a summary of the image\nbut struggles when retrieval of explicit information from the context is\nrequired.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05395v2",
    "published_date": "2024-09-09 07:49:09 UTC",
    "updated_date": "2024-10-01 08:29:53 UTC"
  },
  {
    "arxiv_id": "2409.05385v3",
    "title": "Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models",
    "authors": [
      "Xingyun Hong",
      "Yan Shao",
      "Zhilin Wang",
      "Manni Duan",
      "Jin Xiongnan"
    ],
    "abstract": "The development of LLMs has greatly enhanced the intelligence and fluency of\nquestion answering, while the emergence of retrieval enhancement has enabled\nmodels to better utilize external information. However, the presence of noise\nand errors in retrieved information poses challenges to the robustness of LLMs.\nIn this work, to evaluate the model's performance under multiple interferences,\nwe first construct a dataset based on machine reading comprehension datasets\nsimulating various scenarios, including critical information absence, noise,\nand conflicts. To address the issue of model accuracy decline caused by noisy\nexternal information, we propose a data augmentation-based fine-tuning method\nto enhance LLM's robustness against noise. Additionally, contrastive learning\napproach is utilized to preserve the model's discrimination capability of\nexternal information. We have conducted experiments on both existing LLMs and\nour approach, the results are evaluated by GPT-4, which indicates that our\nproposed methods improve model robustness while strengthening the model's\ndiscrimination capability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by NLPCC-2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05385v3",
    "published_date": "2024-09-09 07:32:30 UTC",
    "updated_date": "2024-09-18 01:39:02 UTC"
  },
  {
    "arxiv_id": "2409.05384v1",
    "title": "Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition",
    "authors": [
      "Shiming Ge",
      "Kangkai Zhang",
      "Haolin Liu",
      "Yingying Hua",
      "Shengwei Zhao",
      "Xin Jin",
      "Hao Wen"
    ],
    "abstract": "In spite of great success in many image recognition tasks achieved by recent\ndeep models, directly applying them to recognize low-resolution images may\nsuffer from low accuracy due to the missing of informative details during\nresolution degradation. However, these images are still recognizable for\nsubjects who are familiar with the corresponding high-resolution ones. Inspired\nby that, we propose a teacher-student learning approach to facilitate\nlow-resolution image recognition via hybrid order relational knowledge\ndistillation. The approach refers to three streams: the teacher stream is\npretrained to recognize high-resolution images in high accuracy, the student\nstream is learned to identify low-resolution images by mimicking the teacher's\nbehaviors, and the extra assistant stream is introduced as bridge to help\nknowledge transfer across the teacher to the student. To extract sufficient\nknowledge for reducing the loss in accuracy, the learning of student is\nsupervised with multiple losses, which preserves the similarities in various\norder relational structures. In this way, the capability of recovering missing\ndetails of familiar low-resolution images can be effectively enhanced, leading\nto a better knowledge transfer. Extensive experiments on metric learning,\nlow-resolution image classification and low-resolution face recognition tasks\nshow the effectiveness of our approach, while taking reduced models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2020",
    "pdf_url": "http://arxiv.org/pdf/2409.05384v1",
    "published_date": "2024-09-09 07:32:18 UTC",
    "updated_date": "2024-09-09 07:32:18 UTC"
  },
  {
    "arxiv_id": "2409.05383v1",
    "title": "Deep Learning for Video Anomaly Detection: A Review",
    "authors": [
      "Peng Wu",
      "Chengyu Pan",
      "Yuting Yan",
      "Guansong Pang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "abstract": "Video anomaly detection (VAD) aims to discover behaviors or events deviating\nfrom the normality in videos. As a long-standing task in the field of computer\nvision, VAD has witnessed much good progress. In the era of deep learning, with\nthe explosion of architectures of continuously growing capability and capacity,\na great variety of deep learning based methods are constantly emerging for the\nVAD task, greatly improving the generalization ability of detection algorithms\nand broadening the application scenarios. Therefore, such a multitude of\nmethods and a large body of literature make a comprehensive survey a pressing\nnecessity. In this paper, we present an extensive and comprehensive research\nreview, covering the spectrum of five different categories, namely,\nsemi-supervised, weakly supervised, fully supervised, unsupervised and open-set\nsupervised VAD, and we also delve into the latest VAD works based on\npre-trained large models, remedying the limitations of past reviews in terms of\nonly focusing on semi-supervised VAD and small model based methods. For the VAD\ntask with different levels of supervision, we construct a well-organized\ntaxonomy, profoundly discuss the characteristics of different types of methods,\nand show their performance comparisons. In addition, this review involves the\npublic datasets, open-source codes, and evaluation metrics covering all the\naforementioned VAD tasks. Finally, we provide several important research\ndirections for the VAD community.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2409.05383v1",
    "published_date": "2024-09-09 07:31:16 UTC",
    "updated_date": "2024-09-09 07:31:16 UTC"
  },
  {
    "arxiv_id": "2409.15337v1",
    "title": "Revisiting the Solution of Meta KDD Cup 2024: CRAG",
    "authors": [
      "Jie Ouyang",
      "Yucong Luo",
      "Mingyue Cheng",
      "Daoyu Wang",
      "Shuo Yu",
      "Qi Liu",
      "Enhong Chen"
    ],
    "abstract": "This paper presents the solution of our team APEX in the Meta KDD CUP 2024:\nCRAG Comprehensive RAG Benchmark Challenge. The CRAG benchmark addresses the\nlimitations of existing QA benchmarks in evaluating the diverse and dynamic\nchallenges faced by Retrieval-Augmented Generation (RAG) systems. It provides a\nmore comprehensive assessment of RAG performance and contributes to advancing\nresearch in this field. We propose a routing-based domain and dynamic adaptive\nRAG pipeline, which performs specific processing for the diverse and dynamic\nnature of the question in all three stages: retrieval, augmentation, and\ngeneration. Our method achieved superior performance on CRAG and ranked 2nd for\nTask 2&3 on the final competition leaderboard. Our implementation is available\nat this link: https://github.com/USTCAGI/CRAG-in-KDD-Cup2024.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15337v1",
    "published_date": "2024-09-09 07:28:14 UTC",
    "updated_date": "2024-09-09 07:28:14 UTC"
  },
  {
    "arxiv_id": "2409.05379v1",
    "title": "PersonaTalk: Bring Attention to Your Persona in Visual Dubbing",
    "authors": [
      "Longhao Zhang",
      "Shuang Liang",
      "Zhipeng Ge",
      "Tianshu Hu"
    ],
    "abstract": "For audio-driven visual dubbing, it remains a considerable challenge to\nuphold and highlight speaker's persona while synthesizing accurate lip\nsynchronization. Existing methods fall short of capturing speaker's unique\nspeaking style or preserving facial details. In this paper, we present\nPersonaTalk, an attention-based two-stage framework, including geometry\nconstruction and face rendering, for high-fidelity and personalized visual\ndubbing. In the first stage, we propose a style-aware audio encoding module\nthat injects speaking style into audio features through a cross-attention\nlayer. The stylized audio features are then used to drive speaker's template\ngeometry to obtain lip-synced geometries. In the second stage, a dual-attention\nface renderer is introduced to render textures for the target geometries. It\nconsists of two parallel cross-attention layers, namely Lip-Attention and\nFace-Attention, which respectively sample textures from different reference\nframes to render the entire face. With our innovative design, intricate facial\ndetails can be well preserved. Comprehensive experiments and user studies\ndemonstrate our advantages over other state-of-the-art methods in terms of\nvisual quality, lip-sync accuracy and persona preservation. Furthermore, as a\nperson-generic framework, PersonaTalk can achieve competitive performance as\nstate-of-the-art person-specific methods. Project Page:\nhttps://grisoon.github.io/PersonaTalk/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at SIGGRAPH Asia 2024 (Conference Track)",
    "pdf_url": "http://arxiv.org/pdf/2409.05379v1",
    "published_date": "2024-09-09 07:23:28 UTC",
    "updated_date": "2024-09-09 07:23:28 UTC"
  },
  {
    "arxiv_id": "2409.05370v1",
    "title": "KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models",
    "authors": [
      "Yingshu Li",
      "Zhanyu Wang",
      "Yunyi Liu",
      "Lei Wang",
      "Lingqiao Liu",
      "Luping Zhou"
    ],
    "abstract": "Harnessing the robust capabilities of Large Language Models (LLMs) for\nnarrative generation, logical reasoning, and common-sense knowledge\nintegration, this study delves into utilizing LLMs to enhance automated\nradiology report generation (R2Gen). Despite the wealth of knowledge within\nLLMs, efficiently triggering relevant knowledge within these large models for\nspecific tasks like R2Gen poses a critical research challenge. This paper\npresents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration\nframework based on LLMs. Utilizing a frozen LLM to generate reports, the\nframework integrates a knowledge graph to unlock chest disease-related\nknowledge within the LLM to enhance the clinical utility of generated reports.\nThis is achieved by leveraging the knowledge graph to distill disease-related\nfeatures in a designed way. Since a radiology report encompasses both normal\nand disease-related findings, the extracted graph-enhanced disease-related\nfeatures are integrated with regional image features, attending to both\naspects. We explore two fusion methods to automatically prioritize and select\nthe most relevant features. The fused features are employed by LLM to generate\nreports that are more sensitive to diseases and of improved quality. Our\napproach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05370v1",
    "published_date": "2024-09-09 06:57:22 UTC",
    "updated_date": "2024-09-09 06:57:22 UTC"
  },
  {
    "arxiv_id": "2409.05358v2",
    "title": "BAMDP Shaping: a Unified Framework for Intrinsic Motivation and Reward Shaping",
    "authors": [
      "Aly Lidayan",
      "Michael Dennis",
      "Stuart Russell"
    ],
    "abstract": "Intrinsic motivation and reward shaping guide reinforcement learning (RL)\nagents by adding pseudo-rewards, which can lead to useful emergent behaviors.\nHowever, they can also encourage counterproductive exploits, e.g., fixation\nwith noisy TV screens. Here we provide a theoretical model which anticipates\nthese behaviors, and provides broad criteria under which adverse effects can be\nbounded. We characterize all pseudo-rewards as reward shaping in Bayes-Adaptive\nMarkov Decision Processes (BAMDPs), which formulates the problem of learning in\nMDPs as an MDP over the agent's knowledge. Optimal exploration maximizes BAMDP\nstate value, which we decompose into the value of the information gathered and\nthe prior value of the physical state. Psuedo-rewards guide RL agents by\nrewarding behavior that increases these value components, while they hinder\nexploration when they align poorly with the actual value. We extend\npotential-based shaping theory to prove BAMDP Potential-based shaping Functions\n(BAMPFs) are immune to reward-hacking (convergence to behaviors maximizing\ncomposite rewards to the detriment of real rewards) in meta-RL, and show\nempirically how a BAMPF helps a meta-RL agent learn optimal RL algorithms for a\nBernoulli Bandit domain. We finally prove that BAMPFs with bounded monotone\nincreasing potentials also resist reward-hacking in the regular RL setting. We\nshow that it is straightforward to retrofit or design new pseudo-reward terms\nin this form, and provide an empirical demonstration in the Mountain Car\nenvironment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.05358v2",
    "published_date": "2024-09-09 06:39:56 UTC",
    "updated_date": "2025-03-22 02:05:56 UTC"
  },
  {
    "arxiv_id": "2409.05347v2",
    "title": "TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency",
    "authors": [
      "Ahmed Imteaj",
      "Md Zarif Hossain",
      "Saika Zaman",
      "Abdur R. Shahid"
    ],
    "abstract": "The rapid advancement and increasing complexity of pretrained models,\nexemplified by CLIP, offer significant opportunities as well as challenges for\nFederated Learning (FL), a critical component of privacy-preserving artificial\nintelligence. This research delves into the intricacies of integrating large\nfoundation models like CLIP within FL frameworks to enhance privacy,\nefficiency, and adaptability across heterogeneous data landscapes. It\nspecifically addresses the challenges posed by non-IID data distributions, the\ncomputational and communication overheads of leveraging such complex models,\nand the skewed representation of classes within datasets. We propose\nTriplePlay, a framework that integrates CLIP as an adapter to enhance FL's\nadaptability and performance across diverse data distributions. This approach\naddresses the long-tail distribution challenge to ensure fairness while\nreducing resource demands through quantization and low-rank adaptation\ntechniques.Our simulation results demonstrate that TriplePlay effectively\ndecreases GPU usage costs and speeds up the learning process, achieving\nconvergence with reduced communication overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05347v2",
    "published_date": "2024-09-09 06:04:42 UTC",
    "updated_date": "2024-10-08 04:54:27 UTC"
  },
  {
    "arxiv_id": "2409.05346v1",
    "title": "GDFlow: Anomaly Detection with NCDE-based Normalizing Flow for Advanced Driver Assistance System",
    "authors": [
      "Kangjun Lee",
      "Minha Kim",
      "Youngho Jun",
      "Simon S. Woo"
    ],
    "abstract": "For electric vehicles, the Adaptive Cruise Control (ACC) in Advanced Driver\nAssistance Systems (ADAS) is designed to assist braking based on driving\nconditions, road inclines, predefined deceleration strengths, and user braking\npatterns. However, the driving data collected during the development of ADAS\nare generally limited and lack diversity. This deficiency leads to late or\naggressive braking for different users. Crucially, it is necessary to\neffectively identify anomalies, such as unexpected or inconsistent braking\npatterns in ADAS, especially given the challenge of working with unlabelled,\nlimited, and noisy datasets from real-world electric vehicles. In order to\ntackle the aforementioned challenges in ADAS, we propose Graph Neural\nControlled Differential Equation Normalizing Flow (GDFlow), a model that\nleverages Normalizing Flow (NF) with Neural Controlled Differential Equations\n(NCDE) to learn the distribution of normal driving patterns continuously.\nCompared to the traditional clustering or anomaly detection algorithms, our\napproach effectively captures the spatio-temporal information from different\nsensor data and more accurately models continuous changes in driving patterns.\nAdditionally, we introduce a quantile-based maximum likelihood objective to\nimprove the likelihood estimate of the normal data near the boundary of the\ndistribution, enhancing the model's ability to distinguish between normal and\nanomalous patterns. We validate GDFlow using real-world electric vehicle\ndriving data that we collected from Hyundai IONIQ5 and GV80EV, achieving\nstate-of-the-art performance compared to six baselines across four dataset\nconfigurations of different vehicle types and drivers. Furthermore, our model\noutperforms the latest anomaly detection methods across four time series\nbenchmark datasets. Our approach demonstrates superior efficiency in inference\ntime compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05346v1",
    "published_date": "2024-09-09 06:04:41 UTC",
    "updated_date": "2024-09-09 06:04:41 UTC"
  },
  {
    "arxiv_id": "2409.05344v2",
    "title": "GOPT: Generalizable Online 3D Bin Packing via Transformer-based Deep Reinforcement Learning",
    "authors": [
      "Heng Xiong",
      "Changrong Guo",
      "Jian Peng",
      "Kai Ding",
      "Wenjie Chen",
      "Xuchong Qiu",
      "Long Bai",
      "Jianfeng Xu"
    ],
    "abstract": "Robotic object packing has broad practical applications in the logistics and\nautomation industry, often formulated by researchers as the online 3D Bin\nPacking Problem (3D-BPP). However, existing DRL-based methods primarily focus\non enhancing performance in limited packing environments while neglecting the\nability to generalize across multiple environments characterized by different\nbin dimensions. To this end, we propose GOPT, a generalizable online 3D Bin\nPacking approach via Transformer-based deep reinforcement learning (DRL).\nFirst, we design a Placement Generator module to yield finite subspaces as\nplacement candidates and the representation of the bin. Second, we propose a\nPacking Transformer, which fuses the features of the items and bin, to identify\nthe spatial correlation between the item to be packed and available sub-spaces\nwithin the bin. Coupling these two components enables GOPT's ability to perform\ninference on bins of varying dimensions. We conduct extensive experiments and\ndemonstrate that GOPT not only achieves superior performance against the\nbaselines, but also exhibits excellent generalization capabilities.\nFurthermore, the deployment with a robot showcases the practical applicability\nof our method in the real world. The source code will be publicly available at\nhttps://github.com/Xiong5Heng/GOPT.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures. This paper has been accepted by IEEE Robotics and\n  Automation Letters",
    "pdf_url": "http://arxiv.org/pdf/2409.05344v2",
    "published_date": "2024-09-09 06:02:17 UTC",
    "updated_date": "2024-09-12 08:49:20 UTC"
  },
  {
    "arxiv_id": "2409.05336v1",
    "title": "Early-exit Convolutional Neural Networks",
    "authors": [
      "Edanur Demir",
      "Emre Akbas"
    ],
    "abstract": "This paper is aimed at developing a method that reduces the computational\ncost of convolutional neural networks (CNN) during inference. Conventionally,\nthe input data pass through a fixed neural network architecture. However, easy\nexamples can be classified at early stages of processing and conventional\nnetworks do not take this into account. In this paper, we introduce 'Early-exit\nCNNs', EENets for short, which adapt their computational cost based on the\ninput by stopping the inference process at certain exit locations. In EENets,\nthere are a number of exit blocks each of which consists of a confidence branch\nand a softmax branch. The confidence branch computes the confidence score of\nexiting (i.e. stopping the inference process) at that location; while the\nsoftmax branch outputs a classification probability vector. Both branches are\nlearnable and their parameters are separate. During training of EENets, in\naddition to the classical classification loss, the computational cost of\ninference is taken into account as well. As a result, the network adapts its\nmany confidence branches to the inputs so that less computation is spent for\neasy examples. Inference works as in conventional feed-forward networks,\nhowever, when the output of a confidence branch is larger than a certain\nthreshold, the inference stops for that specific example. The idea of EENets is\napplicable to available CNN architectures such as ResNets. Through\ncomprehensive experiments on MNIST, SVHN, CIFAR10 and Tiny-ImageNet datasets,\nwe show that early-exit (EE) ResNets achieve similar accuracy with their non-EE\nversions while reducing the computational cost to 20% of the original. Code is\navailable at https://github.com/eksuas/eenets.pytorch",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05336v1",
    "published_date": "2024-09-09 05:29:38 UTC",
    "updated_date": "2024-09-09 05:29:38 UTC"
  },
  {
    "arxiv_id": "2409.05335v1",
    "title": "A Multi-Modal Deep Learning Based Approach for House Price Prediction",
    "authors": [
      "Md Hasebul Hasan",
      "Md Abid Jahan",
      "Mohammed Eunus Ali",
      "Yuan-Fang Li",
      "Timos Sellis"
    ],
    "abstract": "Accurate prediction of house price, a vital aspect of the residential real\nestate sector, is of substantial interest for a wide range of stakeholders.\nHowever, predicting house prices is a complex task due to the significant\nvariability influenced by factors such as house features, location,\nneighborhood, and many others. Despite numerous attempts utilizing a wide array\nof algorithms, including recent deep learning techniques, to predict house\nprices accurately, existing approaches have fallen short of considering a wide\nrange of factors such as textual and visual features. This paper addresses this\ngap by comprehensively incorporating attributes, such as features, textual\ndescriptions, geo-spatial neighborhood, and house images, typically showcased\nin real estate listings in a house price prediction system. Specifically, we\npropose a multi-modal deep learning approach that leverages different types of\ndata to learn more accurate representation of the house. In particular, we\nlearn a joint embedding of raw house attributes, geo-spatial neighborhood, and\nmost importantly from textual description and images representing the house;\nand finally use a downstream regression model to predict the house price from\nthis jointly learned embedding vector. Our experimental results with a\nreal-world dataset show that the text embedding of the house advertisement\ndescription and image embedding of the house pictures in addition to raw\nattributes and geo-spatial embedding, can significantly improve the house price\nprediction accuracy. The relevant source code and dataset are publicly\naccessible at the following URL: https://github.com/4P0N/mhpp",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.05335v1",
    "published_date": "2024-09-09 05:26:33 UTC",
    "updated_date": "2024-09-09 05:26:33 UTC"
  },
  {
    "arxiv_id": "2409.11416v1",
    "title": "The Unseen AI Disruptions for Power Grids: LLM-Induced Transients",
    "authors": [
      "Yuzhuo Li",
      "Mariam Mughees",
      "Yize Chen",
      "Yunwei Ryan Li"
    ],
    "abstract": "Recent breakthroughs of large language models (LLMs) have exhibited superior\ncapability across major industries and stimulated multi-hundred-billion-dollar\ninvestment in AI-centric data centers in the next 3-5 years. This, in turn,\nbring the increasing concerns on sustainability and AI-related energy usage.\nHowever, there is a largely overlooked issue as challenging and critical as AI\nmodel and infrastructure efficiency: the disruptive dynamic power consumption\nbehaviour. With fast, transient dynamics, AI infrastructure features ultra-low\ninertia, sharp power surge and dip, and a significant peak-idle power ratio.\nThe power scale covers from several hundred watts to megawatts, even to\ngigawatts. These never-seen-before characteristics make AI a very unique load\nand pose threats to the power grid reliability and resilience. To reveal this\nhidden problem, this paper examines the scale of AI power consumption, analyzes\nAI transient behaviour in various scenarios, develops high-level mathematical\nmodels to depict AI workload behaviour and discusses the multifaceted\nchallenges and opportunities they potentially bring to existing power grids.\nObserving the rapidly evolving machine learning (ML) and AI technologies, this\nwork emphasizes the critical need for interdisciplinary approaches to ensure\nreliable and sustainable AI infrastructure development, and provides a starting\npoint for researchers and practitioners to tackle such challenges.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.PF",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AR",
    "comment": "21 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.11416v1",
    "published_date": "2024-09-09 05:22:01 UTC",
    "updated_date": "2024-09-09 05:22:01 UTC"
  },
  {
    "arxiv_id": "2409.07493v1",
    "title": "Complex Emotion Recognition System using basic emotions via Facial Expression, EEG, and ECG Signals: a review",
    "authors": [
      "Javad Hassannataj Joloudari",
      "Mohammad Maftoun",
      "Bahareh Nakisa",
      "Roohallah Alizadehsani",
      "Meisam Yadollahzadeh-Tabari"
    ],
    "abstract": "The Complex Emotion Recognition System (CERS) deciphers complex emotional\nstates by examining combinations of basic emotions expressed, their\ninterconnections, and the dynamic variations. Through the utilization of\nadvanced algorithms, CERS provides profound insights into emotional dynamics,\nfacilitating a nuanced understanding and customized responses. The attainment\nof such a level of emotional recognition in machines necessitates the knowledge\ndistillation and the comprehension of novel concepts akin to human cognition.\nThe development of AI systems for discerning complex emotions poses a\nsubstantial challenge with significant implications for affective computing.\nFurthermore, obtaining a sizable dataset for CERS proves to be a daunting task\ndue to the intricacies involved in capturing subtle emotions, necessitating\nspecialized methods for data collection and processing. Incorporating\nphysiological signals such as Electrocardiogram (ECG) and Electroencephalogram\n(EEG) can notably enhance CERS by furnishing valuable insights into the user's\nemotional state, enhancing the quality of datasets, and fortifying system\ndependability. A comprehensive literature review was conducted in this study to\nassess the efficacy of machine learning, deep learning, and meta-learning\napproaches in both basic and complex emotion recognition utilizing EEG, ECG\nsignals, and facial expression datasets. The chosen research papers offer\nperspectives on potential applications, clinical implications, and results of\nCERSs, with the objective of promoting their acceptance and integration into\nclinical decision-making processes. This study highlights research gaps and\nchallenges in understanding CERSs, encouraging further investigation by\nrelevant studies and organizations. Lastly, the significance of meta-learning\napproaches in improving CERS performance and guiding future research endeavors\nis underscored.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "29 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07493v1",
    "published_date": "2024-09-09 05:06:10 UTC",
    "updated_date": "2024-09-09 05:06:10 UTC"
  },
  {
    "arxiv_id": "2409.05325v1",
    "title": "Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces",
    "authors": [
      "Aryan Deshwal",
      "Sait Cakmak",
      "Yuhou Xia",
      "David Eriksson"
    ],
    "abstract": "Bayesian optimization (BO) is a powerful approach to sample-efficient\noptimization of black-box functions. However, in settings with very few\nfunction evaluations, a successful application of BO may require transferring\ninformation from historical experiments. These related experiments may not have\nexactly the same tunable parameters (search spaces), motivating the need for BO\nwith transfer learning for heterogeneous search spaces. In this paper, we\npropose two methods for this setting. The first approach leverages a Gaussian\nprocess (GP) model with a conditional kernel to transfer information between\ndifferent search spaces. Our second approach treats the missing parameters as\nhyperparameters of the GP model that can be inferred jointly with the other GP\nhyperparameters or set to fixed values. We show that these two methods perform\nwell on several benchmark problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05325v1",
    "published_date": "2024-09-09 04:36:06 UTC",
    "updated_date": "2024-09-09 04:36:06 UTC"
  },
  {
    "arxiv_id": "2409.05319v1",
    "title": "Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks",
    "authors": [
      "Kai Li",
      "Khalid Zaman",
      "Xingfeng Li",
      "Masato Akagi",
      "Masashi Unoki"
    ],
    "abstract": "Early detection of factory machinery malfunctions is crucial in industrial\napplications. In machine anomalous sound detection (ASD), different machines\nexhibit unique vibration-frequency ranges based on their physical properties.\nMeanwhile, the human auditory system is adept at tracking both temporal and\nspectral dynamics of machine sounds. Consequently, integrating the\ncomputational auditory models of the human auditory system with\nmachine-specific properties can be an effective approach to machine ASD. We\nfirst quantified the frequency importances of four types of machines using the\nFisher ratio (F-ratio). The quantified frequency importances were then used to\ndesign machine-specific non-uniform filterbanks (NUFBs), which extract the log\nnon-uniform spectrum (LNS) feature. The designed NUFBs have a narrower\nbandwidth and higher filter distribution density in frequency regions with\nrelatively high F-ratios. Finally, spectral and temporal modulation\nrepresentations derived from the LNS feature were proposed. These proposed LNS\nfeature and modulation representations are input into an autoencoder\nneural-network-based detector for ASD. The quantification results from the\ntraining set of the Malfunctioning Industrial Machine Investigation and\nInspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the\ndistinguishing information between normal and anomalous sounds of different\nmachines is encoded non-uniformly in the frequency domain. By highlighting\nthese important frequency regions using NUFBs, the LNS feature can\nsignificantly enhance performance using the metric of AUC (area under the\nreceiver operating characteristic curve) under various SNR conditions.\nFurthermore, modulation representations can further improve performance.\nSpecifically, temporal modulation is effective for fans, pumps, and sliders,\nwhile spectral modulation is particularly effective for valves.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05319v1",
    "published_date": "2024-09-09 04:27:17 UTC",
    "updated_date": "2024-09-09 04:27:17 UTC"
  },
  {
    "arxiv_id": "2409.05314v3",
    "title": "Tele-LLMs: A Series of Specialized Large Language Models for Telecommunications",
    "authors": [
      "Ali Maatouk",
      "Kenny Chirino Ampudia",
      "Rex Ying",
      "Leandros Tassiulas"
    ],
    "abstract": "The emergence of large language models (LLMs) has significantly impacted\nvarious fields, from natural language processing to sectors like medicine and\nfinance. However, despite their rapid proliferation, the applications of LLMs\nin telecommunications remain limited, often relying on general-purpose models\nthat lack domain-specific specialization. This lack of specialization results\nin underperformance, particularly when dealing with telecommunications-specific\ntechnical terminology and their associated mathematical representations. This\npaper addresses this gap by first creating and disseminating Tele-Data, a\ncomprehensive dataset of telecommunications material curated from relevant\nsources, and Tele-Eval, a large-scale question-and-answer dataset tailored to\nthe domain. Through extensive experiments, we explore the most effective\ntraining techniques for adapting LLMs to the telecommunications domain, ranging\nfrom examining the division of expertise across various telecommunications\naspects to employing parameter-efficient techniques. We also investigate how\nmodels of different sizes behave during adaptation and analyze the impact of\ntheir training data on this behavior. Leveraging these findings, we develop and\nopen-source Tele-LLMs, the first series of language models ranging from 1B to\n8B parameters, specifically tailored for telecommunications. Our evaluations\ndemonstrate that these models outperform their general-purpose counterparts on\nTele-Eval and telecommunications-related literature tasks while retaining their\npreviously acquired capabilities, thus avoiding the catastrophic forgetting\nphenomenon.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05314v3",
    "published_date": "2024-09-09 03:58:51 UTC",
    "updated_date": "2025-05-05 04:44:30 UTC"
  },
  {
    "arxiv_id": "2409.05305v3",
    "title": "Closed-Form Interpretation of Neural Network Latent Spaces with Symbolic Gradients",
    "authors": [
      "Zakaria Patel",
      "Sebastian J. Wetzel"
    ],
    "abstract": "It has been demonstrated in many scientific fields that artificial neural\nnetworks like autoencoders or Siamese networks encode meaningful concepts in\ntheir latent spaces. However, there does not exist a comprehensive framework\nfor retrieving this information in a human-readable form without prior\nknowledge. In order to extract these concepts, we introduce a framework for\nfinding closed-form interpretations of neurons in latent spaces of artificial\nneural networks. The interpretation framework is based on embedding trained\nneural networks into an equivalence class of functions that encode the same\nconcept. We interpret these neural networks by finding an intersection between\nthe equivalence class and human-readable equations defined by a symbolic search\nspace. The approach is demonstrated by retrieving invariants of matrices and\nconserved quantities of dynamical systems from latent spaces of Siamese neural\nnetworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Revised to correct minor issues",
    "pdf_url": "http://arxiv.org/pdf/2409.05305v3",
    "published_date": "2024-09-09 03:26:07 UTC",
    "updated_date": "2025-01-17 20:17:40 UTC"
  },
  {
    "arxiv_id": "2409.09072v1",
    "title": "Joint Model Assignment and Resource Allocation for Cost-Effective Mobile Generative Services",
    "authors": [
      "Shuangwei Gao",
      "Peng Yang",
      "Yuxin Kong",
      "Feng Lyu",
      "Ning Zhang"
    ],
    "abstract": "Artificial Intelligence Generated Content (AIGC) services can efficiently\nsatisfy user-specified content creation demands, but the high computational\nrequirements pose various challenges to supporting mobile users at scale. In\nthis paper, we present our design of an edge-enabled AIGC service provisioning\nsystem to properly assign computing tasks of generative models to edge servers,\nthereby improving overall user experience and reducing content generation\nlatency. Specifically, once the edge server receives user requested task\nprompts, it dynamically assigns appropriate models and allocates computing\nresources based on features of each category of prompts. The generated contents\nare then delivered to users. The key to this system is a proposed probabilistic\nmodel assignment approach, which estimates the quality score of generated\ncontents for each prompt based on category labels. Next, we introduce a\nheuristic algorithm that enables adaptive configuration of both generation\nsteps and resource allocation, according to the various task requests received\nby each generative model on the edge.Simulation results demonstrate that the\ndesigned system can effectively enhance the quality of generated content by up\nto 4.7% while reducing response delay by up to 39.1% compared to benchmarks.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09072v1",
    "published_date": "2024-09-09 03:20:53 UTC",
    "updated_date": "2024-09-09 03:20:53 UTC"
  },
  {
    "arxiv_id": "2409.05303v1",
    "title": "Resource-Efficient Generative AI Model Deployment in Mobile Edge Networks",
    "authors": [
      "Yuxin Liang",
      "Peng Yang",
      "Yuanyuan He",
      "Feng Lyu"
    ],
    "abstract": "The surging development of Artificial Intelligence-Generated Content (AIGC)\nmarks a transformative era of the content creation and production. Edge servers\npromise attractive benefits, e.g., reduced service delay and backhaul traffic\nload, for hosting AIGC services compared to cloud-based solutions. However, the\nscarcity of available resources on the edge pose significant challenges in\ndeploying generative AI models. In this paper, by characterizing the resource\nand delay demands of typical generative AI models, we find that the consumption\nof storage and GPU memory, as well as the model switching delay represented by\nI/O delay during the preloading phase, are significant and vary across models.\nThese multidimensional coupling factors render it difficult to make efficient\nedge model deployment decisions. Hence, we present a collaborative edge-cloud\nframework aiming to properly manage generative AI model deployment on the edge.\nSpecifically, we formulate edge model deployment problem considering\nheterogeneous features of models as an optimization problem, and propose a\nmodel-level decision selection algorithm to solve it. It enables pooled\nresource sharing and optimizes the trade-off between resource consumption and\ndelay in edge generative AI model deployment. Simulation results validate the\nefficacy of the proposed algorithm compared with baselines, demonstrating its\npotential to reduce overall costs by providing feature-aware model deployment\ndecisions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05303v1",
    "published_date": "2024-09-09 03:17:28 UTC",
    "updated_date": "2024-09-09 03:17:28 UTC"
  },
  {
    "arxiv_id": "2409.05294v1",
    "title": "TERD: A Unified Framework for Safeguarding Diffusion Models Against Backdoors",
    "authors": [
      "Yichuan Mo",
      "Hui Huang",
      "Mingjie Li",
      "Ang Li",
      "Yisen Wang"
    ],
    "abstract": "Diffusion models have achieved notable success in image generation, but they\nremain highly vulnerable to backdoor attacks, which compromise their integrity\nby producing specific undesirable outputs when presented with a pre-defined\ntrigger. In this paper, we investigate how to protect diffusion models from\nthis dangerous threat. Specifically, we propose TERD, a backdoor defense\nframework that builds unified modeling for current attacks, which enables us to\nderive an accessible reversed loss. A trigger reversion strategy is further\nemployed: an initial approximation of the trigger through noise sampled from a\nprior distribution, followed by refinement through differential multi-step\nsamplers. Additionally, with the reversed trigger, we propose backdoor\ndetection from the noise space, introducing the first backdoor input detection\napproach for diffusion models and a novel model detection algorithm that\ncalculates the KL divergence between reversed and benign distributions.\nExtensive evaluations demonstrate that TERD secures a 100% True Positive Rate\n(TPR) and True Negative Rate (TNR) across datasets of varying resolutions. TERD\nalso demonstrates nice adaptability to other Stochastic Differential Equation\n(SDE)-based models. Our code is available at https://github.com/PKU-ML/TERD.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05294v1",
    "published_date": "2024-09-09 03:02:16 UTC",
    "updated_date": "2024-09-09 03:02:16 UTC"
  },
  {
    "arxiv_id": "2409.05292v4",
    "title": "Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis",
    "authors": [
      "Nirmalya Thakur"
    ],
    "abstract": "The world is currently experiencing an outbreak of mpox, which has been\ndeclared a Public Health Emergency of International Concern by WHO. No prior\nwork related to social media mining has focused on the development of a dataset\nof Instagram posts about the mpox outbreak. The work presented in this paper\naims to address this research gap and makes two scientific contributions to\nthis field. First, it presents a multilingual dataset of 60,127 Instagram posts\nabout mpox, published between July 23, 2022, and September 5, 2024. The\ndataset, available at https://dx.doi.org/10.21227/7fvc-y093, contains Instagram\nposts about mpox in 52 languages. For each of these posts, the Post ID, Post\nDescription, Date of publication, language, and translated version of the post\n(translation to English was performed using the Google Translate API) are\npresented as separate attributes in the dataset. After developing this dataset,\nsentiment analysis, hate speech detection, and anxiety or stress detection were\nperformed. This process included classifying each post into (i) one of the\nsentiment classes, i.e., fear, surprise, joy, sadness, anger, disgust, or\nneutral, (ii) hate or not hate, and (iii) anxiety/stress detected or no\nanxiety/stress detected. These results are presented as separate attributes in\nthe dataset. Second, this paper presents the results of performing sentiment\nanalysis, hate speech analysis, and anxiety or stress analysis. The variation\nof the sentiment classes - fear, surprise, joy, sadness, anger, disgust, and\nneutral were observed to be 27.95%, 2.57%, 8.69%, 5.94%, 2.69%, 1.53%, and\n50.64%, respectively. In terms of hate speech detection, 95.75% of the posts\ndid not contain hate and the remaining 4.25% of the posts contained hate.\nFinally, 72.05% of the posts did not indicate any anxiety/stress, and the\nremaining 27.95% of the posts represented some form of anxiety/stress.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.SI",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05292v4",
    "published_date": "2024-09-09 03:00:53 UTC",
    "updated_date": "2024-10-11 17:19:44 UTC"
  },
  {
    "arxiv_id": "2409.05286v3",
    "title": "Seek and Solve Reasoning for Table Question Answering",
    "authors": [
      "Ruya Jiang",
      "Chun Wang",
      "Weihong Deng"
    ],
    "abstract": "The complexities of table structures and question logic make table-based\nquestion answering (TQA) tasks challenging for Large Language Models (LLMs),\noften requiring task simplification before solving. This paper reveals that the\nreasoning process during task simplification may be more valuable than the\nsimplified tasks themselves and aims to improve TQA performance by leveraging\nLLMs' reasoning capabilities. We propose a Seek-and-Solve pipeline that\ninstructs the LLM to first seek relevant information and then answer questions,\nintegrating these two stages at the reasoning level into a coherent\nSeek-and-Solve Chain of Thought (SS-CoT). Additionally, we distill a\nsingle-step TQA-solving prompt from this pipeline, using demonstrations with\nSS-CoT paths to guide the LLM in solving complex TQA tasks under In-Context\nLearning settings. Our experiments show that our approaches result in improved\nperformance and reliability while being efficient. Our findings emphasize the\nimportance of eliciting LLMs' reasoning capabilities to handle complex TQA\ntasks effectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in: ICASSP 2025 - 2025 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP)",
    "pdf_url": "http://arxiv.org/pdf/2409.05286v3",
    "published_date": "2024-09-09 02:41:00 UTC",
    "updated_date": "2025-04-20 13:28:25 UTC"
  },
  {
    "arxiv_id": "2409.05283v2",
    "title": "On the Relationship between Truth and Political Bias in Language Models",
    "authors": [
      "Suyash Fulay",
      "William Brannon",
      "Shrestha Mohanty",
      "Cassandra Overney",
      "Elinor Poole-Dayan",
      "Deb Roy",
      "Jad Kabbara"
    ],
    "abstract": "Language model alignment research often attempts to ensure that models are\nnot only helpful and harmless, but also truthful and unbiased. However,\noptimizing these objectives simultaneously can obscure how improving one aspect\nmight impact the others. In this work, we focus on analyzing the relationship\nbetween two concepts essential in both language model alignment and political\nscience: truthfulness and political bias. We train reward models on various\npopular truthfulness datasets and subsequently evaluate their political bias.\nOur findings reveal that optimizing reward models for truthfulness on these\ndatasets tends to result in a left-leaning political bias. We also find that\nexisting open-source reward models (i.e., those trained on standard human\npreference datasets) already show a similar bias and that the bias is larger\nfor larger models. These results raise important questions about the datasets\nused to represent truthfulness, potential limitations of aligning models to be\nboth truthful and politically unbiased, and what language models capture about\nthe relationship between truth and politics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05283v2",
    "published_date": "2024-09-09 02:28:53 UTC",
    "updated_date": "2024-10-11 20:10:53 UTC"
  },
  {
    "arxiv_id": "2409.05280v2",
    "title": "RotCAtt-TransUNet++: Novel Deep Neural Network for Sophisticated Cardiac Segmentation",
    "authors": [
      "Quoc-Bao Nguyen-Le",
      "Tuan-Hy Le",
      "Anh-Triet Do",
      "Quoc-Huy Trinh"
    ],
    "abstract": "Cardiovascular disease remains a predominant global health concern,\nresponsible for a significant portion of mortality worldwide. Accurate\nsegmentation of cardiac medical imaging data is pivotal in mitigating fatality\nrates associated with cardiovascular conditions. However, existing\nstate-of-the-art (SOTA) neural networks, including both CNN-based and\nTransformer-based approaches, exhibit limitations in practical applicability\ndue to their inability to effectively capture inter-slice connections alongside\nintra-slice information. This deficiency is particularly evident in datasets\nfeaturing intricate, long-range details along the z-axis, such as coronary\narteries in axial views. Additionally, SOTA methods fail to differentiate\nnon-cardiac components from myocardium in segmentation, leading to the\n\"spraying\" phenomenon. To address these challenges, we present\nRotCAtt-TransUNet++, a novel architecture tailored for robust segmentation of\ncomplex cardiac structures. Our approach emphasizes modeling global contexts by\naggregating multiscale features with nested skip connections in the encoder. It\nintegrates transformer layers to capture interactions between patches and\nemploys a rotatory attention mechanism to capture connectivity between multiple\nslices (inter-slice information). Additionally, a channel-wise cross-attention\ngate guides the fused multi-scale channel-wise information and features from\ndecoder stages to bridge semantic gaps. Experimental results demonstrate that\nour proposed model outperforms existing SOTA approaches across four cardiac\ndatasets and one abdominal dataset. Importantly, coronary arteries and\nmyocardium are annotated with near-perfect accuracy during inference. An\nablation study shows that the rotatory attention mechanism effectively\ntransforms embedded vectorized patches in the semantic dimensional space,\nenhancing segmentation accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05280v2",
    "published_date": "2024-09-09 02:18:50 UTC",
    "updated_date": "2024-10-23 04:41:51 UTC"
  },
  {
    "arxiv_id": "2409.05279v1",
    "title": "BrainDecoder: Style-Based Visual Decoding of EEG Signals",
    "authors": [
      "Minsuk Choi",
      "Hiroshi Ishikawa"
    ],
    "abstract": "Decoding neural representations of visual stimuli from electroencephalography\n(EEG) offers valuable insights into brain activity and cognition. Recent\nadvancements in deep learning have significantly enhanced the field of visual\ndecoding of EEG, primarily focusing on reconstructing the semantic content of\nvisual stimuli. In this paper, we present a novel visual decoding pipeline\nthat, in addition to recovering the content, emphasizes the reconstruction of\nthe style, such as color and texture, of images viewed by the subject. Unlike\nprevious methods, this ``style-based'' approach learns in the CLIP spaces of\nimage and text separately, facilitating a more nuanced extraction of\ninformation from EEG signals. We also use captions for text alignment simpler\nthan previously employed, which we find work better. Both quantitative and\nqualitative evaluations show that our method better preserves the style of\nvisual stimuli and extracts more fine-grained semantic information from neural\nsignals. Notably, it achieves significant improvements in quantitative results\nand sets a new state-of-the-art on the popular Brain2Image dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.05279v1",
    "published_date": "2024-09-09 02:14:23 UTC",
    "updated_date": "2024-09-09 02:14:23 UTC"
  },
  {
    "arxiv_id": "2409.05277v1",
    "title": "Disentangled Representations for Short-Term and Long-Term Person Re-Identification",
    "authors": [
      "Chanho Eom",
      "Wonkyung Lee",
      "Geon Lee",
      "Bumsub Ham"
    ],
    "abstract": "We address the problem of person re-identification (reID), that is,\nretrieving person images from a large dataset, given a query image of the\nperson of interest. A key challenge is to learn person representations robust\nto intra-class variations, as different persons could have the same attribute,\nand persons' appearances look different, e.g., with viewpoint changes. Recent\nreID methods focus on learning person features discriminative only for a\nparticular factor of variations (e.g., human pose), which also requires\ncorresponding supervisory signals (e.g., pose annotations). To tackle this\nproblem, we propose to factorize person images into identity-related and\nunrelated features. Identity-related features contain information useful for\nspecifying a particular person (e.g., clothing), while identity-unrelated ones\nhold other factors (e.g., human pose). To this end, we propose a new generative\nadversarial network, dubbed identity shuffle GAN (IS-GAN). It disentangles\nidentity-related and unrelated features from person images through an\nidentity-shuffling technique that exploits identification labels alone without\nany auxiliary supervisory signals. We restrict the distribution of\nidentity-unrelated features or encourage the identity-related and unrelated\nfeatures to be uncorrelated, facilitating the disentanglement process.\nExperimental results validate the effectiveness of IS-GAN, showing\nstate-of-the-art performance on standard reID benchmarks, including\nMarket-1501, CUHK03, and DukeMTMC-reID. We further demonstrate the advantages\nof disentangling person representations on a long-term reID task, setting a new\nstate of the art on a Celeb-reID dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:1910.12003",
    "pdf_url": "http://arxiv.org/pdf/2409.05277v1",
    "published_date": "2024-09-09 02:09:49 UTC",
    "updated_date": "2024-09-09 02:09:49 UTC"
  },
  {
    "arxiv_id": "2409.05923v1",
    "title": "$\\mathbb{USCD}$: Improving Code Generation of LLMs by Uncertainty-Aware Selective Contrastive Decoding",
    "authors": [
      "Shuai Wang",
      "Liang Ding",
      "Li Shen",
      "Yong Luo",
      "Zheng He",
      "Wei Yu",
      "Dacheng Tao"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capabilities in code\ngeneration. However, the effects of hallucinations (e.g., output noise) make it\nparticularly challenging for LLMs to generate high-quality code in one pass. In\nthis work, we propose a simple and effective \\textbf{u}ncertainty-aware\n\\textbf{s}elective \\textbf{c}ontrastive \\textbf{d}ecoding ($\\mathbb{USCD}$)\nmechanism to improve the quality of one-pass code generation in LLMs and reduce\nthe impact of output noise. To be specific, we first elaborately designed a\nnegative prompt (namely lame prompt) to output noise by removing input-output\nexamples from the standard few-shot prompt. Our preliminary study shows that\nthe Jensen-Shannon divergence (JS divergence) between token distribution\nuncertainty and the output noise is relatively low (approximately $0.25$),\nindicating their high relevance. Then, we selectively eliminate output noise\ninduced by lame prompts based on the uncertainty of the prediction distribution\nfrom the standard prompt. Notably, our proposed plug-and-play mechanism is an\ninference-only method, enjoying appealing flexibility. Extensive experiments on\nwidely used benchmarks, e.g., HumanEval, MBPP, and MultiPL-E, upon several LLMs\n(i.e., Inocder-6b, CodeLlama-7b, WizardCoder-15b, StarCoder, and Llama2-7b),\ndemonstrate that our proposed USCD significantly improves one-pass code\ngeneration, with an average \\textit{pass@$1$} scores increase of 16.59\\%. We\nwill release code and data on GitHub.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "13pages,8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05923v1",
    "published_date": "2024-09-09 02:07:41 UTC",
    "updated_date": "2024-09-09 02:07:41 UTC"
  },
  {
    "arxiv_id": "2409.05265v1",
    "title": "Learning Submodular Sequencing from Samples",
    "authors": [
      "Jing Yuan",
      "Shaojie Tang"
    ],
    "abstract": "This paper addresses the problem of sequential submodular maximization:\nselecting and ranking items in a sequence to optimize some composite submodular\nfunction. In contrast to most of the previous works, which assume access to the\nutility function, we assume that we are given only a set of samples. Each\nsample includes a random sequence of items and its associated utility. We\npresent an algorithm that, given polynomially many samples drawn from a\ntwo-stage uniform distribution, achieves an approximation ratio dependent on\nthe curvature of individual submodular functions. Our results apply in a wide\nvariety of real-world scenarios, such as ranking products in online retail\nplatforms, where complete knowledge of the utility function is often impossible\nto obtain. Our algorithm gives an empirically useful solution in such contexts,\nthus proving that limited data can be of great use in sequencing tasks. From a\ntechnical perspective, our results extend prior work on ``optimization from\nsamples'' by generalizing from optimizing a set function to a\nsequence-dependent function.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05265v1",
    "published_date": "2024-09-09 01:33:13 UTC",
    "updated_date": "2024-09-09 01:33:13 UTC"
  },
  {
    "arxiv_id": "2409.05258v1",
    "title": "Towards Automated Machine Learning Research",
    "authors": [
      "Shervin Ardeshir"
    ],
    "abstract": "This paper explores a top-down approach to automating incremental advances in\nmachine learning research through component-level innovation, facilitated by\nLarge Language Models (LLMs). Our framework systematically generates novel\ncomponents, validates their feasibility, and evaluates their performance\nagainst existing baselines. A key distinction of this approach lies in how\nthese novel components are generated. Unlike traditional AutoML and NAS\nmethods, which often rely on a bottom-up combinatorial search over predefined,\nhardcoded base components, our method leverages the cross-domain knowledge\nembedded in LLMs to propose new components that may not be confined to any\nhard-coded predefined set. By incorporating a reward model to prioritize\npromising hypotheses, we aim to improve the efficiency of the hypothesis\ngeneration and evaluation process. We hope this approach offers a new avenue\nfor exploration and contributes to the ongoing dialogue in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05258v1",
    "published_date": "2024-09-09 00:47:30 UTC",
    "updated_date": "2024-09-09 00:47:30 UTC"
  }
]