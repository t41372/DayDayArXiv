{
  "date": "2024-05-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-07 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了大量论文，主要聚焦于 AI 模型创新（如大型语言模型和强化学习算法）、计算机视觉应用（如视频生成和图像处理）、以及医疗和生物领域的机器学习方法，其中 DeepSeek-V2 和 xLSTM 等论文令人印象深刻，它们展示了高效的多专家模型和序列建模优化；有名学者如 Sergey Levine 在强化学习领域的 RACER 论文也值得关注。\n\n以下是今天值得关注的论文摘要，我会优先选取重要、创新性和话题度高的论文进行详细讨论（如 AI 模型和强化学习），并将相关主题归类；其他较常规的论文（如某些图像处理或小规模优化方法）会快速掠过，只简要概述主要贡献。\n\n### AI 模型与语言模型创新\n- **DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model（DeepSeek-V2: 一个强大、经济且高效的多专家语言模型）**  \n  这篇论文引入了 DeepSeek-V2 模型，包含 236B 参数但仅激活 21B，用于多语言任务。它采用 Multi-head Latent Attention 和 DeepSeekMoE 架构，提高了计算效率和性能，在 MMLU 基准上超越 GPT-3.5 和 Llama2。主要发现：在保持准确性的同时，减少了训练成本和 KV 缓存，适用于资源受限的场景。\n\n- **xLSTM: Extended Long Short-Term Memory（xLSTM: 扩展的长短期记忆网络）**  \n  作者 Sepp Hochreiter 等人扩展了 LSTM 架构，引入指数门控和修改内存结构（如 sLSTM 和 mLSTM），使其在序列建模中更高效。关键贡献：xLSTM 在长序列任务中超越 Transformer 和状态空间模型，展示了线性时间复杂度的优势。\n\n- **SUTRA: Scalable Multilingual Language Model Architecture（SUTRA: 可扩展的多语言语言模型架构）**  \n  这篇论文提出 SUTRA 模型，支持 50 多种语言，通过 Mixture of Experts 框架实现高效的多语言理解。主要发现：在 MMLU 基准上比 GPT-3.5 和 Llama2 高 20-30%，并提供实时知识整合，强调了 AI 在全球语言公平中的潜力。\n\n- **Granite Code Models: A Family of Open Foundation Models for Code Intelligence（Granite Code Models: 用于代码智能的一系列开源基础模型）**  \n  作者团队包括 Rameswar Panda 和 Ruchir Puri，开发了 Granite 系列模型（3B 到 34B 参数），针对代码生成和调试任务。贡献：在 116 种编程语言上训练，显著提升代码任务性能，并开源 Apache 2.0 许可。\n\n这些论文突出了 LLM 的高效性和多语言扩展，相关工作如 Towards Human-AI Mutual Learning（人类-AI 互学习）则快速掠过：它定义了人类和 AI 知识交换框架，但细节较泛。\n\n### 强化学习与决策优化\n- **RACER: Epistemic Risk-Sensitive RL Enables Fast Driving with Fewer Crashes（RACER: 认识论风险敏感强化学习实现快速驾驶并减少碰撞）**  \n  作者 Sergey Levine 等人提出风险敏感强化学习框架，结合自适应动作空间和不确定性估计。关键发现：在真实越野驾驶任务中，显著减少安全违规，同时提升性能，适用于机器人控制。\n\n- **Proximal Policy Optimization with Adaptive Exploration（自适应探索的近端策略优化）**  \n  这篇论文引入 axPPO 算法，通过动态调整探索强度改善学习效率。主要贡献：在需要大量探索的环境中，超越标准 PPO，提升了强化学习的鲁棒性。\n\n- **FedStale: leveraging stale client updates in federated learning（FedStale: 在联邦学习中利用过时客户端更新）**  \n  论文探索了联邦学习中过时更新的利用，提出 FedStale 算法优化数据异质性。发现：在参与率不均的环境中，显著减少训练误差，提供实用指导。\n\n强化学习主题较多，如 ACGEN（药物发现的生成性化学代理）和 Switchable Decision（动态神经生成网络），但它们较常规，因此快速总结：ACGEN 使用 TorchRL 库提升药物设计效率；Switchable Decision 通过动态计算资源分配加速生成任务。\n\n### 计算机视觉与多模态应用\n- **Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition（Video-of-Thought: 从感知到认知的逐步视频推理）**  \n  作者 Hao Fei 等人开发 MotionEpic 模型和 Video-of-Thought 框架，实现视频多场景理解。主要发现：在复杂视频 QA 任务中，超越 SOTA 方法，展示了从像素感知到高级认知的潜力。\n\n- **TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation（TALC: 用于多场景文本到视频生成的时序对齐字幕）**  \n  论文提出 TALC 框架，提升文本到视频生成的时序一致性。贡献：通过细调预训练模型，实现多场景视频生成，视觉一致性和文本相关性均有提升。\n\n视觉相关论文如 Vision Mamba（视觉 Mamba 调查）和 3DMeshNet（三维网格生成）快速掠过：Vision Mamba 综述了 Mamba 在视觉任务的应用；3DMeshNet 使用神经网络优化网格生成，效率高但主题较窄。\n\n### 医疗与生物应用\n- **Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities（基于物理的深度学习揭示挪威城市供暖需求增加加剧空气污染）**  \n  作者 Cong Cao 等使用 PBDL 和 LSTM 分析空气污染数据。关键发现：供暖需求与污染相关，提供数据驱动的政策建议。\n\n- **ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography（ResNCT: 用于 CT 尿路造影肾图阶段图像合成的深度学习模型）**  \n  论文提出 ResNCT 模型合成 CT 图像，减少辐射剂量。贡献：准确率高（PSNR 27.8 dB），可降低临床检查风险。\n\n医疗主题论文众多，如 AI in Lung Health（肺部 CT 检测基准）和 QServe（LLM 量化），但后者更偏 AI 效率，因此快速提到：QServe 优化 LLM 服务，减少延迟；其他如药物发现方法则强调了强化学习在生物领域的潜力。\n\n其他论文如元宇宙调查（Metaverse Survey）、图神经网络优化（Towards Continual Knowledge Graph Embedding）和边缘计算（Robust Implementation of Retrieval-Augmented Generation）等，虽然有趣，但影响力较小，因此仅简要注：Metaverse Survey 综述了元宇宙技术；图神经网络方法改善了知识图谱持续学习。\n\n总之，今天的 arXiv 更新突出了 AI 模型的创新和实际应用潜力，建议关注 DeepSeek-V2 和 RACER 等前沿工作，以推动更高效的 AI 研究和部署。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2405.04718v1",
      "title": "Metaverse Survey & Tutorial: Exploring Key Requirements, Technologies, Standards, Applications, Challenges, and Perspectives",
      "title_zh": "Metaverse 调查与教程：探索关键要求、技术、标准、应用、挑战和前景",
      "authors": [
        "Danda B. Rawat",
        "Hassan El alami",
        "Desta Haileselassie Hagos"
      ],
      "abstract": "In this paper, we present a comprehensive survey of the metaverse, envisioned\nas a transformative dimension of next-generation Internet technologies. This\nstudy not only outlines the structural components of our survey but also makes\na substantial scientific contribution by elucidating the foundational concepts\nunderlying the emergence of the metaverse. We analyze its architecture by\ndefining key characteristics and requirements, thereby illuminating the nascent\nreality set to revolutionize digital interactions. Our analysis emphasizes the\nimportance of collaborative efforts in developing metaverse standards, thereby\nfostering a unified understanding among industry stakeholders, organizations,\nand regulatory bodies. We extend our scrutiny to critical technologies integral\nto the metaverse, including interactive experiences, communication\ntechnologies, ubiquitous computing, digital twins, artificial intelligence, and\ncybersecurity measures. For each technological domain, we rigorously assess\ncurrent contributions, principal techniques, and representative use cases,\nproviding a nuanced perspective on their potential impacts. Furthermore, we\ndelve into the metaverse's diverse applications across education, healthcare,\nbusiness, social interactions, industrial sectors, defense, and\nmission-critical operations, highlighting its extensive utility. Each\napplication is thoroughly analyzed, demonstrating its value and addressing\nassociated challenges. The survey concludes with an overview of persistent\nchallenges and future directions, offering insights into essential\nconsiderations and strategies necessary to harness the full potential of the\nmetaverse. Through this detailed investigation, our goal is to articulate the\nscientific contributions of this survey paper, transcending a mere structural\noverview to highlight the transformative implications of the metaverse.",
      "tldr_zh": "本篇论文对元宇宙（metaverse）进行全面调查和教程，阐述了其作为下一代互联网技术的关键要求、架构特性，以及推动其发展的标准和技术。研究分析了核心技术领域，包括interactive experiences、communication technologies、ubiquitous computing、digital twins、artificial intelligence和cybersecurity，并评估了这些技术的当前贡献、主要方法和实际应用案例。论文探讨了元宇宙在教育、健康、商业、社会互动、工业、国防和关键任务等领域的多样应用，同时指出了面临的挑战，并提出未来方向以充分发挥其潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04718v1",
      "published_date": "2024-05-07 23:49:02 UTC",
      "updated_date": "2024-05-07 23:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:32:11.852015"
    },
    {
      "arxiv_id": "2405.04716v1",
      "title": "Physics-based deep learning reveals rising heating demand heightens air pollution in Norwegian cities",
      "title_zh": "基于物理的深度学习揭示上升的供暖需求加剧了挪威城市的空气污染",
      "authors": [
        "Cong Cao",
        "Ramit Debnath",
        "R. Michael Alvarez"
      ],
      "abstract": "Policymakers frequently analyze air quality and climate change in isolation,\ndisregarding their interactions. This study explores the influence of specific\nclimate factors on air quality by contrasting a regression model with K-Means\nClustering, Hierarchical Clustering, and Random Forest techniques. We employ\nPhysics-based Deep Learning (PBDL) and Long Short-Term Memory (LSTM) to examine\nthe air pollution predictions. Our analysis utilizes ten years (2009-2018) of\ndaily traffic, weather, and air pollution data from three major cities in\nNorway. Findings from feature selection reveal a correlation between rising\nheating degree days and heightened air pollution levels, suggesting increased\nheating activities in Norway are a contributing factor to worsening air\nquality. PBDL demonstrates superior accuracy in air pollution predictions\ncompared to LSTM. This paper contributes to the growing literature on PBDL\nmethods for more accurate air pollution predictions using environmental\nvariables, aiding policymakers in formulating effective data-driven climate\npolicies.",
      "tldr_zh": "本研究探讨了气候因素对挪威城市空气质量的影响，通过对比回归模型、K-Means Clustering、Hierarchical Clustering 和 Random Forest 等方法，并使用 Physics-based Deep Learning (PBDL) 与 Long Short-Term Memory (LSTM) 分析2009-2018十年间的交通、天气和空气污染数据。结果显示，加热度日上升与空气污染水平增加密切相关，表明增加的加热需求是空气质量恶化的主要贡献因素。PBDL 在预测准确性上优于 LSTM，为政策制定者提供更精确的数据驱动气候政策建议。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "K.4.1; J.2; I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "52 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04716v1",
      "published_date": "2024-05-07 23:43:46 UTC",
      "updated_date": "2024-05-07 23:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:32:27.486880"
    },
    {
      "arxiv_id": "2405.04714v1",
      "title": "RACER: Epistemic Risk-Sensitive RL Enables Fast Driving with Fewer Crashes",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Stachowicz",
        "Sergey Levine"
      ],
      "abstract": "Reinforcement learning provides an appealing framework for robotic control\ndue to its ability to learn expressive policies purely through real-world\ninteraction. However, this requires addressing real-world constraints and\navoiding catastrophic failures during training, which might severely impede\nboth learning progress and the performance of the final policy. In many\nrobotics settings, this amounts to avoiding certain \"unsafe\" states. The\nhigh-speed off-road driving task represents a particularly challenging\ninstantiation of this problem: a high-return policy should drive as\naggressively and as quickly as possible, which often requires getting close to\nthe edge of the set of \"safe\" states, and therefore places a particular burden\non the method to avoid frequent failures.\n  To both learn highly performant policies and avoid excessive failures, we\npropose a reinforcement learning framework that combines risk-sensitive control\nwith an adaptive action space curriculum.\n  Furthermore, we show that our risk-sensitive objective automatically avoids\nout-of-distribution states when equipped with an estimator for epistemic\nuncertainty.\n  We implement our algorithm on a small-scale rally car and show that it is\ncapable of learning high-speed policies for a real-world off-road driving task.\nWe show that our method greatly reduces the number of safety violations during\nthe training process, and actually leads to higher-performance policies in both\ndriving and non-driving simulation environments with similar challenges.",
      "tldr_zh": "该研究提出RACER框架，一种基于认识论风险敏感强化学习（Epistemic Risk-Sensitive RL）的算法，旨在解决机器人控制中训练过程中的灾难性失败问题，尤其适用于高速度越野驾驶任务。该框架结合风险敏感控制（risk-sensitive control）和自适应动作空间课程（adaptive action space curriculum），通过估计认识论不确定性（epistemic uncertainty）自动避免分布外状态，从而实现更激进且安全的政策。在小型集结车上的实验表明，RACER显著减少了训练中的安全违规，并提升了最终政策的性能，在真实和模拟环境中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "In review, RSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04714v1",
      "published_date": "2024-05-07 23:32:36 UTC",
      "updated_date": "2024-05-07 23:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:32:36.421716"
    },
    {
      "arxiv_id": "2405.05286v1",
      "title": "Tiny Deep Ensemble: Uncertainty Estimation in Edge AI Accelerators via Ensembling Normalization Layers with Shared Weights",
      "title_zh": "翻译失败",
      "authors": [
        "Soyed Tuhin Ahmed",
        "Michael Hefenbrock",
        "Mehdi B. Tahoori"
      ],
      "abstract": "The applications of artificial intelligence (AI) are rapidly evolving, and\nthey are also commonly used in safety-critical domains, such as autonomous\ndriving and medical diagnosis, where functional safety is paramount. In\nAI-driven systems, uncertainty estimation allows the user to avoid\noverconfidence predictions and achieve functional safety. Therefore, the\nrobustness and reliability of model predictions can be improved. However,\nconventional uncertainty estimation methods, such as the deep ensemble method,\nimpose high computation and, accordingly, hardware (latency and energy)\noverhead because they require the storage and processing of multiple models.\nAlternatively, Monte Carlo dropout (MC-dropout) methods, although having low\nmemory overhead, necessitate numerous ($\\sim 100$) forward passes, leading to\nhigh computational overhead and latency. Thus, these approaches are not\nsuitable for battery-powered edge devices with limited computing and memory\nresources. In this paper, we propose the Tiny-Deep Ensemble approach, a\nlow-cost approach for uncertainty estimation on edge devices. In our approach,\nonly normalization layers are ensembled $M$ times, with all ensemble members\nsharing common weights and biases, leading to a significant decrease in storage\nrequirements and latency. Moreover, our approach requires only one forward pass\nin a hardware architecture that allows batch processing for inference and\nuncertainty estimation. Furthermore, it has approximately the same memory\noverhead compared to a single model. Therefore, latency and memory overhead are\nreduced by a factor of up to $\\sim M\\times$. Nevertheless, our method does not\ncompromise accuracy, with an increase in inference accuracy of up to $\\sim 1\\%$\nand a reduction in RMSE of $17.17\\%$ in various benchmark datasets, tasks, and\nstate-of-the-art architectures.",
      "tldr_zh": "本论文提出Tiny-Deep Ensemble方法，用于在Edge AI Accelerators上进行不确定性估计，以提升AI系统在安全关键领域（如自动驾驶和医疗诊断）的鲁棒性和可靠性。传统方法如deep ensemble需要处理多个模型，或Monte Carlo dropout需多次前向传递，导致高计算和硬件开销；相比之下，该方法仅对normalization layers进行集成，同时所有成员共享权重和偏差，从而显著减少存储需求和延迟，仅需一次前向传递。实验结果显示，在各种基准数据集和任务中，该方法将延迟和内存开销降低约M倍，同时提高推理准确率约1%并减少RMSE 17.17%。这种低成本方案适用于资源受限的边缘设备，而不牺牲整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05286v1",
      "published_date": "2024-05-07 22:54:17 UTC",
      "updated_date": "2024-05-07 22:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:32:50.077950"
    },
    {
      "arxiv_id": "2405.04700v1",
      "title": "Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyang Qin",
        "Zheyu Yan",
        "Dewen Zeng",
        "Zhenge Jia",
        "Dancheng Liu",
        "Jianbo Liu",
        "Zhi Zheng",
        "Ningyuan Cao",
        "Kai Ni",
        "Jinjun Xiong",
        "Yiyu Shi"
      ],
      "abstract": "Large Language Models (LLMs) deployed on edge devices learn through\nfine-tuning and updating a certain portion of their parameters. Although such\nlearning methods can be optimized to reduce resource utilization, the overall\nrequired resources remain a heavy burden on edge devices. Instead,\nRetrieval-Augmented Generation (RAG), a resource-efficient LLM learning method,\ncan improve the quality of the LLM-generated content without updating model\nparameters. However, the RAG-based LLM may involve repetitive searches on the\nprofile data in every user-LLM interaction. This search can lead to significant\nlatency along with the accumulation of user data. Conventional efforts to\ndecrease latency result in restricting the size of saved user data, thus\nreducing the scalability of RAG as user data continuously grows. It remains an\nopen question: how to free RAG from the constraints of latency and scalability\non edge devices? In this paper, we propose a novel framework to accelerate RAG\nvia Computing-in-Memory (CiM) architectures. It accelerates matrix\nmultiplications by performing in-situ computation inside the memory while\navoiding the expensive data transfer between the computing unit and memory. Our\nframework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive\nlearning-based training method and noise-aware training, can enable RAG to\nefficiently search profile data with CiM. To the best of our knowledge, this is\nthe first work utilizing CiM to accelerate RAG.",
      "tldr_zh": "本研究针对大型语言模型（Large Language Models, LLMs）在边缘设备上的部署问题，提出Retrieval-Augmented Generation (RAG)作为一种不需更新参数的资源高效学习方法，以提升生成内容质量，但RAG在用户交互中面临重复搜索profile数据导致的延迟和可扩展性挑战。论文引入Robust CiM-backed RAG (RoCR)框架，利用Computing-in-Memory (CiM)架构加速矩阵乘法，通过在内存内进行计算避免数据传输开销。RoCR结合对比学习-based训练方法和noise-aware训练，使RAG能够在边缘设备上高效搜索数据，并首次将CiM应用于RAG加速，显著改善延迟和可扩展性问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04700v1",
      "published_date": "2024-05-07 22:31:50 UTC",
      "updated_date": "2024-05-07 22:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:33:02.747940"
    },
    {
      "arxiv_id": "2405.05285v1",
      "title": "Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance",
      "title_zh": "翻译失败",
      "authors": [
        "Jelena Pavlovic",
        "Jugoslav Krstic",
        "Luka Mitrovic",
        "Djordje Babic",
        "Adrijana Milosavljevic",
        "Milena Nikolic",
        "Tijana Karaklic",
        "Tijana Mitrovic"
      ],
      "abstract": "This study investigates the metacognitive capabilities of Large Language\nModels relative to human metacognition in the context of the International\nCoaching Federation ICF mimicking exam, a situational judgment test related to\ncoaching competencies. Using a mixed method approach, we assessed the\nmetacognitive performance, including sensitivity, accuracy in probabilistic\npredictions, and bias, of human participants and five advanced LLMs (GPT-4,\nClaude-3-Opus 3, Mistral Large, Llama 3, and Gemini 1.5 Pro). The results\nindicate that LLMs outperformed humans across all metacognitive metrics,\nparticularly in terms of reduced overconfidence, compared to humans. However,\nboth LLMs and humans showed less adaptability in ambiguous scenarios, adhering\nclosely to predefined decision frameworks. The study suggests that Generative\nAI can effectively engage in human-like metacognitive processing without\nconscious awareness. Implications of the study are discussed in relation to\ndevelopment of AI simulators that scaffold cognitive and metacognitive aspects\nof mastering coaching competencies. More broadly, implications of these results\nare discussed in relation to development of metacognitive modules that lead\ntowards more autonomous and intuitive AI systems.",
      "tldr_zh": "本研究使用 mixed-method approach 比较了大型语言模型（LLMs，包括 GPT-4、Claude-3-Opus 3、Mistral Large、Llama 3 和 Gemini 1.5 Pro）与人类参与者在 ICF-mimicking exam 中的元认知（metacognitive）表现，评估了敏感性、概率预测准确性和偏差等指标。结果显示，LLMs 在所有元认知指标上超过了人类，尤其是在减少过度自信方面，但两者在模糊场景中均表现出较低的适应性。研究表明，Generative AI 可以像人类一样进行元认知处理，而无需意识，并为开发 AI 模拟器以辅助认知和元认知能力，以及构建更自主的 AI 系统提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05285v1",
      "published_date": "2024-05-07 22:15:12 UTC",
      "updated_date": "2024-05-07 22:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:33:13.812085"
    },
    {
      "arxiv_id": "2405.04687v1",
      "title": "Towards Human-AI Mutual Learning: A New Research Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaomei Wang",
        "Xiaoyu Chen"
      ],
      "abstract": "This paper describes a new research paradigm for studying human-AI\ncollaboration, named \"human-AI mutual learning\", defined as the process where\nhumans and AI agents preserve, exchange, and improve knowledge during human-AI\ncollaboration. We describe relevant methodologies, motivations, domain\nexamples, benefits, challenges, and future research agenda under this paradigm.",
      "tldr_zh": "这篇论文提出了一种新的研究范式，名为 \"human-AI mutual learning\"，定义为人类和AI代理在合作过程中相互保留、交换和改进知识的过程。该范式探讨了相关方法论、动机、领域示例、益处（如提升合作效率）、挑战（如知识不平衡问题），并概述了未来研究议程。这种方法旨在为人类-AI 协作研究提供新视角，推动更智能且可持续的交互模式。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04687v1",
      "published_date": "2024-05-07 21:59:57 UTC",
      "updated_date": "2024-05-07 21:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:33:25.421993"
    },
    {
      "arxiv_id": "2405.04685v1",
      "title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Emre Can Acikgoz",
        "Mete Erdogan",
        "Deniz Yuret"
      ],
      "abstract": "Large Language Models (LLMs) are becoming crucial across various fields,\nemphasizing the urgency for high-quality models in underrepresented languages.\nThis study explores the unique challenges faced by low-resource languages, such\nas data scarcity, model selection, evaluation, and computational limitations,\nwith a special focus on Turkish. We conduct an in-depth analysis to evaluate\nthe impact of training strategies, model choices, and data availability on the\nperformance of LLMs designed for underrepresented languages. Our approach\nincludes two methodologies: (i) adapting existing LLMs originally pretrained in\nEnglish to understand Turkish, and (ii) developing a model from the ground up\nusing Turkish pretraining data, both supplemented with supervised fine-tuning\non a novel Turkish instruction-tuning dataset aimed at enhancing reasoning\ncapabilities. The relative performance of these methods is evaluated through\nthe creation of a new leaderboard for Turkish LLMs, featuring benchmarks that\nassess different reasoning and knowledge skills. Furthermore, we conducted\nexperiments on data and model scaling, both during pretraining and fine-tuning,\nsimultaneously emphasizing the capacity for knowledge transfer across languages\nand addressing the challenges of catastrophic forgetting encountered during\nfine-tuning on a different language. Our goal is to offer a detailed guide for\nadvancing the LLM framework in low-resource linguistic contexts, thereby making\nnatural language processing (NLP) benefits more globally accessible.",
      "tldr_zh": "该研究探讨了低资源语言（如土耳其语）在Large Language Models (LLMs) 发展中的挑战，包括数据稀缺、模型选择、评估和计算限制。研究提出两种策略：(i) 适应现有英文预训练LLMs 以理解土耳其语，(ii) 从零开始使用土耳其预训练数据开发新模型，并通过一个新型土耳其指令微调数据集增强推理能力。实验评估了这些方法的性能，包括数据和模型缩放、知识转移及灾难性遗忘问题，并创建了土耳其LLMs排行榜作为基准，最终为低资源语言的LLM框架提供详尽指南，促进NLP的全球可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04685v1",
      "published_date": "2024-05-07 21:58:45 UTC",
      "updated_date": "2024-05-07 21:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:33:36.874054"
    },
    {
      "arxiv_id": "2405.04682v4",
      "title": "TALC: Time-Aligned Captions for Multi-Scene Text-to-Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hritik Bansal",
        "Yonatan Bitton",
        "Michal Yarom",
        "Idan Szpektor",
        "Aditya Grover",
        "Kai-Wei Chang"
      ],
      "abstract": "Most of these text-to-video (T2V) generative models often produce\nsingle-scene video clips that depict an entity performing a particular action\n(e.g., 'a red panda climbing a tree'). However, it is pertinent to generate\nmulti-scene videos since they are ubiquitous in the real-world (e.g., 'a red\npanda climbing a tree' followed by 'the red panda sleeps on the top of the\ntree'). To generate multi-scene videos from the pretrained T2V model, we\nintroduce a simple and effective Time-Aligned Captions (TALC) framework.\nSpecifically, we enhance the text-conditioning mechanism in the T2V\narchitecture to recognize the temporal alignment between the video scenes and\nscene descriptions. For instance, we condition the visual features of the\nearlier and later scenes of the generated video with the representations of the\nfirst scene description (e.g., 'a red panda climbing a tree') and second scene\ndescription (e.g., 'the red panda sleeps on the top of the tree'),\nrespectively. As a result, we show that the T2V model can generate multi-scene\nvideos that adhere to the multi-scene text descriptions and be visually\nconsistent (e.g., entity and background). Further, we finetune the pretrained\nT2V model with multi-scene video-text data using the TALC framework. We show\nthat the TALC-finetuned model outperforms the baseline by achieving a relative\ngain of 29% in the overall score, which averages visual consistency and text\nadherence using human evaluation.",
      "tldr_zh": "该论文针对现有文本到视频 (T2V) 模型仅生成单场景视频的局限性，提出了一种简单有效的 Time-Aligned Captions (TALC) 框架，用于生成多场景视频。TALC 通过增强 T2V 模型的文本条件机制，实现视频场景与场景描述之间的 temporal alignment，例如将早期场景与第一个描述（如“a red panda climbing a tree”）关联，后续场景与第二个描述（如“the red panda sleeps on the top of the tree”）对齐，从而确保视觉一致性和文本 adherence。实验结果表明，使用 TALC 微调的模型在人类评估中比基线模型整体得分提升 29%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 14 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.04682v4",
      "published_date": "2024-05-07 21:52:39 UTC",
      "updated_date": "2024-11-08 05:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:33:49.786944"
    },
    {
      "arxiv_id": "2405.04677v1",
      "title": "Responding to Generative AI Technologies with Research-through-Design: The Ryelands AI Lab as an Exploratory Study",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Josua Benjamin",
        "Joseph Lindley",
        "Elizabeth Edwards",
        "Elisa Rubegni",
        "Tim Korjakow",
        "David Grist",
        "Rhiannon Sharkey"
      ],
      "abstract": "Generative AI technologies demand new practical and critical competencies,\nwhich call on design to respond to and foster these. We present an exploratory\nstudy guided by Research-through-Design, in which we partnered with a primary\nschool to develop a constructionist curriculum centered on students interacting\nwith a generative AI technology. We provide a detailed account of the design of\nand outputs from the curriculum and learning materials, finding centrally that\nthe reflexive and prolonged `hands-on' approach led to a co-development of\nstudents' practical and critical competencies. From the study, we contribute\nguidance for designing constructionist approaches to generative AI technology\neducation; further arguing to do so with `critical responsivity.' We then\ndiscuss how HCI researchers may leverage constructionist strategies in\ndesigning interactions with generative AI technologies; and suggest that\nResearch-through-Design can play an important role as a `rapid response\nmethodology' capable of reacting to fast-evolving, disruptive technologies such\nas generative AI.",
      "tldr_zh": "该研究探讨了生成式 AI 技术对新实践和批判性能力的需求，通过 Research-through-Design 方法进行探索性研究。研究者与一所小学合作，设计了一个以学生互动生成式 AI 为核心的建构主义课程，发现反思性和长期的“动手”方法能共同提升学生的实践和批判性能力。论文贡献了针对生成式 AI 教育的建构主义设计指导，主张采用“批判响应性”方法，并建议 HCI 研究者利用此类策略设计互动，同时将 Research-through-Design 视为应对快速演变技术的“快速响应方法”。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Conditionally Accepted at ACM DIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04677v1",
      "published_date": "2024-05-07 21:34:10 UTC",
      "updated_date": "2024-05-07 21:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:34:00.461036"
    },
    {
      "arxiv_id": "2405.04664v1",
      "title": "Proximal Policy Optimization with Adaptive Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Lixandru"
      ],
      "abstract": "Proximal Policy Optimization with Adaptive Exploration (axPPO) is introduced\nas a novel learning algorithm. This paper investigates the\nexploration-exploitation tradeoff within the context of reinforcement learning\nand aims to contribute new insights into reinforcement learning algorithm\ndesign. The proposed adaptive exploration framework dynamically adjusts the\nexploration magnitude during training based on the recent performance of the\nagent. Our proposed method outperforms standard PPO algorithms in learning\nefficiency, particularly when significant exploratory behavior is needed at the\nbeginning of the learning process.",
      "tldr_zh": "这篇论文引入了 Proximal Policy Optimization with Adaptive Exploration (axPPO)，一种新型强化学习算法，旨在优化探索-利用权衡并为算法设计提供新见解。axPPO 通过动态调整探索幅度，根据代理的近期表现来适应训练过程，从而提升学习效率。该方法在实验中 outperform 了标准 PPO 算法，尤其在学习初期需要大量探索的场景中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04664v1",
      "published_date": "2024-05-07 20:51:49 UTC",
      "updated_date": "2024-05-07 20:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:34:11.845779"
    },
    {
      "arxiv_id": "2405.04657v3",
      "title": "ACEGEN: Reinforcement learning of generative chemical agents for drug discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Albert Bou",
        "Morgan Thomas",
        "Sebastian Dittert",
        "Carles Navarro Ramírez",
        "Maciej Majewski",
        "Ye Wang",
        "Shivam Patel",
        "Gary Tresadern",
        "Mazen Ahmad",
        "Vincent Moens",
        "Woody Sherman",
        "Simone Sciabola",
        "Gianni De Fabritiis"
      ],
      "abstract": "In recent years, reinforcement learning (RL) has emerged as a valuable tool\nin drug design, offering the potential to propose and optimize molecules with\ndesired properties. However, striking a balance between capabilities,\nflexibility, reliability, and efficiency remains challenging due to the\ncomplexity of advanced RL algorithms and the significant reliance on\nspecialized code. In this work, we introduce ACEGEN, a comprehensive and\nstreamlined toolkit tailored for generative drug design, built using TorchRL, a\nmodern RL library that offers thoroughly tested reusable components. We\nvalidate ACEGEN by benchmarking against other published generative modeling\nalgorithms and show comparable or improved performance. We also show examples\nof ACEGEN applied in multiple drug discovery case studies. ACEGEN is accessible\nat \\url{https://github.com/acellera/acegen-open} and available for use under\nthe MIT license.",
      "tldr_zh": "该研究介绍了ACEGEN，一种基于Reinforcement Learning (RL)的生成化学代理工具包，旨在优化药物发现过程，同时平衡能力、灵活性、可靠性和效率。ACEGEN利用TorchRL库构建，提供经过彻底测试的可重用组件，便于简化复杂RL算法的应用。通过基准测试，该工具包在生成建模算法中表现出与现有方法相当或更好的性能，并在多个药物发现案例研究中展示了实际应用。ACEGEN以开源形式提供，可在GitHub上获取，并采用MIT许可。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04657v3",
      "published_date": "2024-05-07 20:30:14 UTC",
      "updated_date": "2024-07-22 17:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:34:24.176991"
    },
    {
      "arxiv_id": "2405.06694v1",
      "title": "SUTRA: Scalable Multilingual Language Model Architecture",
      "title_zh": "SUTRA：可扩展的多语言语言模型架构",
      "authors": [
        "Abhijit Bendale",
        "Michael Sapienza",
        "Steven Ripplinger",
        "Simon Gibbs",
        "Jaewon Lee",
        "Pranav Mistry"
      ],
      "abstract": "In this paper, we introduce SUTRA, multilingual Large Language Model\narchitecture capable of understanding, reasoning, and generating text in over\n50 languages. SUTRA's design uniquely decouples core conceptual understanding\nfrom language-specific processing, which facilitates scalable and efficient\nmultilingual alignment and learning. Employing a Mixture of Experts framework\nboth in language and concept processing, SUTRA demonstrates both computational\nefficiency and responsiveness. Through extensive evaluations, SUTRA is\ndemonstrated to surpass existing models like GPT-3.5, Llama2 by 20-30% on\nleading Massive Multitask Language Understanding (MMLU) benchmarks for\nmultilingual tasks. SUTRA models are also online LLMs that can use knowledge\nfrom the internet to provide hallucination-free, factual and up-to-date\nresponses while retaining their multilingual capabilities. Furthermore, we\nexplore the broader implications of its architecture for the future of\nmultilingual AI, highlighting its potential to democratize access to AI\ntechnology globally and to improve the equity and utility of AI in regions with\npredominantly non-English languages. Our findings suggest that SUTRA not only\nfills pivotal gaps in multilingual model capabilities but also establishes a\nnew benchmark for operational efficiency and scalability in AI applications.",
      "tldr_zh": "本论文介绍了SUTRA，一种可扩展的多语言大型语言模型架构，能够理解、推理和生成超过50种语言的文本。SUTRA的设计将核心概念理解与语言特定处理分离，并采用Mixture of Experts框架，提高计算效率和多语言对齐能力。在MMLU基准测试中，SUTRA比GPT-3.5和Llama2高出20-30%，并作为在线LLM从互联网获取实时知识，提供无幻觉的准确响应，同时探讨其架构在全球AI公平性和非英语地区应用方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.06694v1",
      "published_date": "2024-05-07 20:11:44 UTC",
      "updated_date": "2024-05-07 20:11:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:34:37.696384"
    },
    {
      "arxiv_id": "2405.04650v1",
      "title": "A Self-Supervised Method for Body Part Segmentation and Keypoint Detection of Rat Images",
      "title_zh": "翻译失败",
      "authors": [
        "László Kopácsi",
        "Áron Fóthi",
        "András Lőrincz"
      ],
      "abstract": "Recognition of individual components and keypoint detection supported by\ninstance segmentation is crucial to analyze the behavior of agents on the\nscene. Such systems could be used for surveillance, self-driving cars, and also\nfor medical research, where behavior analysis of laboratory animals is used to\nconfirm the aftereffects of a given medicine. A method capable of solving the\naforementioned tasks usually requires a large amount of high-quality\nhand-annotated data, which takes time and money to produce. In this paper, we\npropose a method that alleviates the need for manual labeling of laboratory\nrats. To do so, first, we generate initial annotations with a computer\nvision-based approach, then through extensive augmentation, we train a deep\nneural network on the generated data. The final system is capable of instance\nsegmentation, keypoint detection, and body part segmentation even when the\nobjects are heavily occluded.",
      "tldr_zh": "这篇论文提出了一种自监督方法，用于实验室鼠图像的身体部位分割和关键点检测，旨在减少手动标注数据的依赖，以降低时间和成本。方法首先通过计算机视觉技术生成初始标注，然后利用广泛的数据增强来训练深度神经网络。最终系统能够实现实例 segmentation、keypoint detection 和身体部位分割，即使物体严重遮挡，从而支持行为分析应用，如医疗研究中的药物后遗症验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04650v1",
      "published_date": "2024-05-07 20:11:07 UTC",
      "updated_date": "2024-05-07 20:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:34:48.414852"
    },
    {
      "arxiv_id": "2405.04629v2",
      "title": "ResNCT: A Deep Learning Model for the Synthesis of Nephrographic Phase Images in CT Urography",
      "title_zh": "ResNCT：CT Urography中肾图阶段图像合成的深度学习模型",
      "authors": [
        "Syed Jamal Safdar Gardezi",
        "Lucas Aronson",
        "Peter Wawrzyn",
        "Hongkun Yu",
        "E. Jason Abel",
        "Daniel D. Shapiro",
        "Meghan G. Lubner",
        "Joshua Warner",
        "Giuseppe Toia",
        "Lu Mao",
        "Pallavi Tiwari",
        "Andrew L. Wentland"
      ],
      "abstract": "Purpose: To develop and evaluate a transformer-based deep learning model for\nthe synthesis of nephrographic phase images in CT urography (CTU) examinations\nfrom the unenhanced and urographic phases.\n  Materials and Methods: This retrospective study was approved by the local\nInstitutional Review Board. A dataset of 119 patients (mean $\\pm$ SD age, 65\n$\\pm$ 12 years; 75/44 males/females) with three-phase CT urography studies was\ncurated for deep learning model development. The three phases for each patient\nwere aligned with an affine registration algorithm. A custom model, coined\nResidual transformer model for Nephrographic phase CT image synthesis (ResNCT),\nwas developed and implemented with paired inputs of non-contrast and urographic\nsets of images trained to produce the nephrographic phase images, that were\ncompared with the corresponding ground truth nephrographic phase images. The\nsynthesized images were evaluated with multiple performance metrics, including\npeak signal to noise ratio (PSNR), structural similarity index (SSIM),\nnormalized cross correlation coefficient (NCC), mean absolute error (MAE), and\nroot mean squared error (RMSE).\n  Results: The ResNCT model successfully generated synthetic nephrographic\nimages from non-contrast and urographic image inputs. With respect to ground\ntruth nephrographic phase images, the images synthesized by the model achieved\nhigh PSNR (27.8 $\\pm$ 2.7 dB), SSIM (0.88 $\\pm$ 0.05), and NCC (0.98 $\\pm$\n0.02), and low MAE (0.02 $\\pm$ 0.005) and RMSE (0.042 $\\pm$ 0.016).\n  Conclusion: The ResNCT model synthesized nephrographic phase CT images with\nhigh similarity to ground truth images. The ResNCT model provides a means of\neliminating the acquisition of the nephrographic phase with a resultant 33%\nreduction in radiation dose for CTU examinations.",
      "tldr_zh": "这篇论文开发了ResNCT模型，一种基于Transformer的深度学习框架，用于从CT Urography的非增强相和尿路相图像合成肾图相图像，从而减少辐射暴露。研究团队使用119名患者的图像数据，通过仿射注册对齐图像，并训练模型以生成合成图像。评估结果显示，合成图像与真实图像高度相似，达到高PSNR (27.8 ± 2.7 dB)、SSIM (0.88 ± 0.05)和NCC (0.98 ± 0.02)，同时MAE和RMSE较低；该方法可消除肾图相的直接获取，实现CTU检查辐射剂量减少33%。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph",
        "J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 5 Figures,2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2405.04629v2",
      "published_date": "2024-05-07 19:20:32 UTC",
      "updated_date": "2024-05-29 02:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:35:01.766768"
    },
    {
      "arxiv_id": "2405.04620v5",
      "title": "Folded Context Condensation in Path Integral Formalism for Infinite Context Transformers",
      "title_zh": "折叠上下文浓缩：在无限上下文 Transformer 的路径积分形式主义中",
      "authors": [
        "Won-Gi Paeng",
        "Daesuk Kwon",
        "Kyungwon Jeong",
        "Honggyo Suh"
      ],
      "abstract": "In this work, we present a generalized formulation of the Transformer\nalgorithm by reinterpreting its core mechanisms within the framework of Path\nIntegral formalism. In this perspective, the attention mechanism is recast as a\nprocess that integrates all possible transition paths leading to future token\nstates, with temporal evolution governed by the Feed-Forward Network. By\nsystematically mapping each component of the Transformer to its counterpart in\nthe Path Integral formulation, we obtain a more compact and efficient\nrepresentation, in which the contextual information of a sequence is condensed\ninto memory-like segments. These segments are recurrently processed across\nTransformer layers, enabling more effective long-term information retention. We\nvalidate the effectiveness of this approach through the Passkey retrieval task\nand a summarization task, demonstrating that the proposed method preserves\nhistorical information while exhibiting memory usage that scales linearly with\nsequence length. This contrasts with the non-linear memory growth typically\nobserved in standard attention mechanisms. We expect that this quantum-inspired\ngeneralization of the Transformer architecture will open new avenues for\nenhancing both the efficiency and expressiveness of future Transformer models.",
      "tldr_zh": "本论文将 Transformer 算法重新表述为 Path Integral 形式主义框架，其中注意力机制被视为整合所有可能过渡路径的过程，而 Feed-Forward Network 控制时间演化。作者通过映射 Transformer 组件到 Path Integral 对应部分，开发了一种紧凑表示方法，将序列的上下文信息浓缩成记忆-like 段，并在 Transformer 层中循环处理，以实现更有效的长期信息保留和线性内存增长。实验在 Passkey 检索任务和总结任务上验证，该方法保留了历史信息，同时避免了标准注意力机制的非线性内存增长。总之，这种量子启发的泛化有望提升未来 Transformer 模型的效率和表现力。",
      "categories": [
        "hep-ph",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "hep-ph",
      "comment": "11 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04620v5",
      "published_date": "2024-05-07 19:05:26 UTC",
      "updated_date": "2025-05-01 04:45:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:35:13.033992"
    },
    {
      "arxiv_id": "2405.17438v1",
      "title": "An LLM-Tool Compiler for Fused Parallel Function Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Simranjit Singh",
        "Andreas Karatzas",
        "Michael Fore",
        "Iraklis Anagnostopoulos",
        "Dimitrios Stamoulis"
      ],
      "abstract": "State-of-the-art sequential reasoning in Large Language Models (LLMs) has\nexpanded the capabilities of Copilots beyond conversational tasks to complex\nfunction calling, managing thousands of API calls. However, the tendency of\ncompositional prompting to segment tasks into multiple steps, each requiring a\nround-trip to the GPT APIs, leads to increased system latency and costs.\nAlthough recent advancements in parallel function calling have improved tool\nexecution per API call, they may necessitate more detailed in-context\ninstructions and task breakdown at the prompt level, resulting in higher\nengineering and production costs. Inspired by the hardware design principles of\nmultiply-add (MAD) operations, which fuse multiple arithmetic operations into a\nsingle task from the compiler's perspective, we propose LLM-Tool Compiler,\nwhich selectively fuses similar types of tool operations under a single\nfunction at runtime, presenting them as a unified task to the LLM. This\nselective fusion inherently enhances parallelization and efficiency.\nBenchmarked on a large-scale Copilot platform, LLM-Tool Compiler achieves up to\nfour times more parallel calls than existing methods, reducing token costs and\nlatency by up to 40% and 12%, respectively.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)中函数调用的顺序推理问题，指出传统compositional prompting导致任务分解增加系统延迟和成本，尽管并行函数调用有所改进但仍需更多提示指令。研究提出LLM-Tool Compiler，一种受硬件multiply-add (MAD)操作启发的工具编译器，它在运行时选择性地融合类似工具操作，将它们作为单一任务呈现给LLM，从而提升并行化和效率。在大型Copilot平台基准测试中，该方法实现了高达四倍的并行调用，并将token成本和延迟分别降低高达40%和12%。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17438v1",
      "published_date": "2024-05-07 18:55:50 UTC",
      "updated_date": "2024-05-07 18:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:35:25.426757"
    },
    {
      "arxiv_id": "2405.04605v3",
      "title": "AI in Lung Health: Benchmarking Detection and Diagnostic Models Across Multiple CT Scan Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Fakrul Islam Tushar",
        "Avivah Wang",
        "Lavsen Dahal",
        "Michael R. Harowicz",
        "Kyle J. Lafata",
        "Tina D. Tailor",
        "Joseph Y. Lo"
      ],
      "abstract": "Lung cancer remains the leading cause of cancer-related mortality worldwide,\nand early detection through low-dose computed tomography (LDCT) has shown\nsignificant promise in reducing death rates. With the growing integration of\nartificial intelligence (AI) into medical imaging, the development and\nevaluation of robust AI models require access to large, well-annotated\ndatasets. In this study, we introduce the utility of Duke Lung Cancer Screening\n(DLCS) Dataset, the largest open-access LDCT dataset with over 2,000 scans and\n3,000 expert-verified nodules. We benchmark deep learning models for both 3D\nnodule detection and lung cancer classification across internal and external\ndatasets including LUNA16, LUNA25, and NLST-3D+. For detection, we develop two\nMONAI-based RetinaNet models (DLCSDmD and LUNA16-mD), evaluated using the\nCompetition Performance Metric (CPM). For classification, we compare five\nmodels, including state-of-the-art pretrained models (Models Genesis, Med3D), a\nselfsupervised foundation model (FMCB), a randomly initialized ResNet50, and\nproposed a novel Strategic Warm-Start++ (SWS++) model. SWS++ uses curated\ncandidate patches to pretrain a classification backbone within the same\ndetection pipeline, enabling task-relevant feature learning. Our models\ndemonstrated strong generalizability, with SWS++ achieving comparable or\nsuperior performance to existing foundational models across multiple datasets\n(AUC: 0.71 to 0.90). All code, models, and data are publicly released to\npromote reproducibility and collaboration. This work establishes a standardized\nbenchmarking resource for lung cancer AI research, supporting future efforts in\nmodel development, validation, and clinical translation.",
      "tldr_zh": "本文研究了人工智能在肺健康中的应用，特别引入了最大的公开低剂量 CT (LDCT) 数据集 Duke Lung Cancer Screening (DLCS)，包含超过 2,000 个扫描和 3,000 个专家验证结节，用于基准测试肺癌检测和分类模型。研究开发了基于 MONAI 的 RetinaNet 模型（如 DLCSDmD 和 LUNA16-mD）用于 3D 结节检测，并比较了五种分类模型，包括新提出的 Strategic Warm-Start++ (SWS++) 模型，该模型通过精选候选补丁预训练分类骨干网络，提升任务相关特征学习。结果显示，SWS++ 在多个数据集（如 LUNA16 和 NLST-3D+）上表现出强泛化能力，AUC 值达到 0.71 至 0.90，与现有基础模型相当或优越；所有代码、模型和数据已公开，以推动肺癌 AI 研究的重复性和临床翻译。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "2 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04605v3",
      "published_date": "2024-05-07 18:36:40 UTC",
      "updated_date": "2025-04-23 21:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:35:39.556779"
    },
    {
      "arxiv_id": "2405.04532v3",
      "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Yujun Lin",
        "Haotian Tang",
        "Shang Yang",
        "Zhekai Zhang",
        "Guangxuan Xiao",
        "Chuang Gan",
        "Song Han"
      ],
      "abstract": "Quantization can accelerate large language model (LLM) inference. Going\nbeyond INT8 quantization, the research community is actively exploring even\nlower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization\ntechniques only accelerate low-batch, edge LLM inference, failing to deliver\nperformance gains in large-batch, cloud-based LLM serving. We uncover a\ncritical issue: existing INT4 quantization methods suffer from significant\nruntime overhead (20-90%) when dequantizing either weights or partial sums on\nGPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization\nalgorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands\nfor quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented\nby the QServe inference library that achieves measured speedup. The key insight\ndriving QServe is that the efficiency of LLM serving on GPUs is critically\ninfluenced by operations on low-throughput CUDA cores. Building upon this\ninsight, in QoQ algorithm, we introduce progressive quantization that can allow\nlow dequantization overhead in W4A8 GEMM. Additionally, we develop\nSmoothAttention to effectively mitigate the accuracy degradation incurred by\n4-bit KV quantization. In the QServe system, we perform compute-aware weight\nreordering and take advantage of register-level parallelism to reduce\ndequantization latency. We also make fused attention memory-bound, harnessing\nthe performance gain brought by KV4 quantization. As a result, QServe improves\nthe maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x\non L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to\nTensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput\nthan TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of\nLLM serving by 3x. Code is available at\nhttps://github.com/mit-han-lab/omniserve.",
      "tldr_zh": "该研究提出 QoQ 算法和 QServe 系统，以 W4A8KV4 量化（4-bit 权重、8-bit 激活、4-bit KV 缓存）优化大型语言模型（LLM）的服务效率，解决现有 INT4 量化方法在云端大批量推理中存在的运行时开销问题。QoQ 通过渐进量化减少 W4A8 GEMM 的去量化开销，并引入 SmoothAttention 来缓解 4-bit KV 量化带来的准确性损失；QServe 系统则采用计算感知权重重新排序、寄存器级并行性和融合注意力优化，进一步提升 GPU 性能。实验结果显示，QServe 在 A100 GPU 上将 Llama-3-8B 的最大服务吞吐量提高 1.2 倍，在 L40S 上提高 1.4 倍，并将 Qwen1.5-72B 的吞吐量提高 2.4 倍和 3.5 倍，最终将 LLM 服务的美元成本降低了 3 倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "The first three authors contribute equally to this project and are\n  listed in the alphabetical order. Yujun Lin leads the quantization algorithm,\n  Haotian Tang and Shang Yang lead the GPU kernels and the serving system. Code\n  is available at https://github.com/mit-han-lab/omniserve",
      "pdf_url": "http://arxiv.org/pdf/2405.04532v3",
      "published_date": "2024-05-07 17:59:30 UTC",
      "updated_date": "2025-05-01 02:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:35:51.104861"
    },
    {
      "arxiv_id": "2405.04517v2",
      "title": "xLSTM: Extended Long Short-Term Memory",
      "title_zh": "xLSTM: 扩展的长短时记忆",
      "authors": [
        "Maximilian Beck",
        "Korbinian Pöppel",
        "Markus Spanring",
        "Andreas Auer",
        "Oleksandra Prudnikova",
        "Michael Kopp",
        "Günter Klambauer",
        "Johannes Brandstetter",
        "Sepp Hochreiter"
      ],
      "abstract": "In the 1990s, the constant error carousel and gating were introduced as the\ncentral ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have\nstood the test of time and contributed to numerous deep learning success\nstories, in particular they constituted the first Large Language Models (LLMs).\nHowever, the advent of the Transformer technology with parallelizable\nself-attention at its core marked the dawn of a new era, outpacing LSTMs at\nscale. We now raise a simple question: How far do we get in language modeling\nwhen scaling LSTMs to billions of parameters, leveraging the latest techniques\nfrom modern LLMs, but mitigating known limitations of LSTMs? Firstly, we\nintroduce exponential gating with appropriate normalization and stabilization\ntechniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM\nwith a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that\nis fully parallelizable with a matrix memory and a covariance update rule.\nIntegrating these LSTM extensions into residual block backbones yields xLSTM\nblocks that are then residually stacked into xLSTM architectures. Exponential\ngating and modified memory structures boost xLSTM capabilities to perform\nfavorably when compared to state-of-the-art Transformers and State Space\nModels, both in performance and scaling.",
      "tldr_zh": "本文扩展了 Long Short-Term Memory (LSTM) 模型，旨在通过现代大型语言模型 (LLMs) 技术解决其局限性，并与 Transformer 竞争。关键创新包括引入 exponential gating 结合 normalization 和 stabilization 技术，以及修改内存结构：sLSTM 使用标量内存和更新规则，mLSTM 采用矩阵内存和协方差更新以实现完全并行化。将这些扩展整合到 residual block backbones 中，形成 xLSTM 架构。实验结果显示，xLSTM 在性能和扩展性上可与 state-of-the-art Transformers 和 State Space Models 相媲美。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at https://github.com/NX-AI/xlstm",
      "pdf_url": "http://arxiv.org/pdf/2405.04517v2",
      "published_date": "2024-05-07 17:50:21 UTC",
      "updated_date": "2024-12-06 15:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:36:01.485906"
    },
    {
      "arxiv_id": "2405.04513v1",
      "title": "Switchable Decision: Dynamic Neural Generation Networks",
      "title_zh": "可切换决策：动态神经生成网络",
      "authors": [
        "Shujian Zhang",
        "Korawat Tanwisuth",
        "Chengyue Gong",
        "Pengcheng He",
        "Mingyuan Zhou"
      ],
      "abstract": "Auto-regressive generation models achieve competitive performance across many\ndifferent NLP tasks such as summarization, question answering, and\nclassifications. However, they are also known for being slow in inference,\nwhich makes them challenging to deploy in real-time applications. We propose a\nswitchable decision to accelerate inference by dynamically assigning\ncomputation resources for each data instance. Automatically making decisions on\nwhere to skip and how to balance quality and computation cost with constrained\noptimization, our dynamic neural generation networks enforce the efficient\ninference path and determine the optimized trade-off. Experiments across\nquestion answering, summarization, and classification benchmarks show that our\nmethod benefits from less computation cost during inference while keeping the\nsame accuracy. Extensive experiments and ablation studies demonstrate that our\nmethod can be general, effective, and beneficial for many NLP tasks.",
      "tldr_zh": "本研究针对自动回归生成模型在自然语言处理(NLP)任务（如问答、摘要和分类）中的推理速度慢问题，提出了一种Switchable Decision机制和Dynamic Neural Generation Networks框架。该框架通过动态分配计算资源，并利用约束优化自动决定跳过某些计算步骤，从而平衡模型质量和计算成本。实验结果显示，在多个NLP基准测试中，该方法在保持相同准确性的前提下显著减少了推理计算开销，且证明了其通用性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04513v1",
      "published_date": "2024-05-07 17:44:54 UTC",
      "updated_date": "2024-05-07 17:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:36:13.669820"
    },
    {
      "arxiv_id": "2405.04495v1",
      "title": "Toward In-Context Teaching: Adapting Examples to Students' Misconceptions",
      "title_zh": "翻译失败",
      "authors": [
        "Alexis Ross",
        "Jacob Andreas"
      ],
      "abstract": "When a teacher provides examples for a student to study, these examples must\nbe informative, enabling a student to progress from their current state toward\na target concept or skill. Good teachers must therefore simultaneously infer\nwhat students already know and adapt their teaching to students' changing state\nof knowledge. There is increasing interest in using computational models,\nparticularly large language models, as pedagogical tools. As students, language\nmodels in particular have shown a remarkable ability to adapt to new tasks\ngiven small numbers of examples. But how effectively can these models adapt as\nteachers to students of different types? To study this question, we introduce a\nsuite of models and evaluation methods we call AdapT. AdapT has two components:\n(1) a collection of simulated Bayesian student models that can be used for\nevaluation of automated teaching methods; (2) a platform for evaluation with\nhuman students, to characterize the real-world effectiveness of these methods.\nWe additionally introduce (3) AToM, a new probabilistic model for adaptive\nteaching that jointly infers students' past beliefs and optimizes for the\ncorrectness of future beliefs. In evaluations of simulated students across\nthree learning domains (fraction arithmetic, English morphology, function\nlearning), AToM systematically outperforms LLM-based and standard Bayesian\nteaching models. In human experiments, both AToM and LLMs outperform\nnon-adaptive random example selection. Our results highlight both the\ndifficulty of the adaptive teaching task and the potential of learned adaptive\nmodels for solving it.",
      "tldr_zh": "这篇论文探讨了如何让教学系统根据学生的错误观念（misconceptions）适应性地提供例子，以提升学习效果。研究引入了AdapT框架，包括模拟的Bayesian student models用于评估，以及一个人类学生评估平台；同时提出AToM模型，这是一个概率模型，能联合推断学生的过去信念并优化未来信念。在模拟实验中，AToM在分数算术、英语形态和函数学习等领域 outperform了LLM-based和标准Bayesian教学模型；在人类实验中，AToM和LLMs均优于随机例子选择，突显了适应性教学的挑战与潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04495v1",
      "published_date": "2024-05-07 17:05:27 UTC",
      "updated_date": "2024-05-07 17:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:36:27.864964"
    },
    {
      "arxiv_id": "2405.04491v1",
      "title": "TorchDriveEnv: A Reinforcement Learning Benchmark for Autonomous Driving with Reactive, Realistic, and Diverse Non-Playable Characters",
      "title_zh": "TorchDriveEnv：一种用于自动驾驶的强化学习基准，具备反应式、真实且多样的非玩家角色",
      "authors": [
        "Jonathan Wilder Lavington",
        "Ke Zhang",
        "Vasileios Lioutas",
        "Matthew Niedoba",
        "Yunpeng Liu",
        "Dylan Green",
        "Saeid Naderiparizi",
        "Xiaoxuan Liang",
        "Setareh Dabiri",
        "Adam Ścibior",
        "Berend Zwartsenberg",
        "Frank Wood"
      ],
      "abstract": "The training, testing, and deployment, of autonomous vehicles requires\nrealistic and efficient simulators. Moreover, because of the high variability\nbetween different problems presented in different autonomous systems, these\nsimulators need to be easy to use, and easy to modify. To address these\nproblems we introduce TorchDriveSim and its benchmark extension TorchDriveEnv.\nTorchDriveEnv is a lightweight reinforcement learning benchmark programmed\nentirely in Python, which can be modified to test a number of different factors\nin learned vehicle behavior, including the effect of varying kinematic models,\nagent types, and traffic control patterns. Most importantly unlike many replay\nbased simulation approaches, TorchDriveEnv is fully integrated with a state of\nthe art behavioral simulation API. This allows users to train and evaluate\ndriving models alongside data driven Non-Playable Characters (NPC) whose\ninitializations and driving behavior are reactive, realistic, and diverse. We\nillustrate the efficiency and simplicity of TorchDriveEnv by evaluating common\nreinforcement learning baselines in both training and validation environments.\nOur experiments show that TorchDriveEnv is easy to use, but difficult to solve.",
      "tldr_zh": "该论文引入了 TorchDriveEnv，这是一个轻量级的强化学习基准，用于自主驾驶的训练、测试和部署。TorchDriveEnv 完全用 Python 编程设计，便于修改和测试各种因素，如不同的运动学模型、代理类型和交通控制模式，并集成了先进的行为模拟 API，以支持反应性、现实性和多样的 Non-Playable Characters (NPC)。与基于重放的模拟方法不同，该基准允许用户在真实数据驱动的 NPC 环境中训练和评估驾驶模型。实验结果显示，TorchDriveEnv 易于使用，但对强化学习基线模型的挑战性较高。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04491v1",
      "published_date": "2024-05-07 17:02:02 UTC",
      "updated_date": "2024-05-07 17:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:36:39.419871"
    },
    {
      "arxiv_id": "2405.04480v2",
      "title": "Concentration Tail-Bound Analysis of Coevolutionary and Bandit Learning Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Per Kristian Lehre",
        "Shishen Lin"
      ],
      "abstract": "Runtime analysis, as a branch of the theory of AI, studies how the number of\niterations algorithms take before finding a solution (its runtime) depends on\nthe design of the algorithm and the problem structure. Drift analysis is a\nstate-of-the-art tool for estimating the runtime of randomised algorithms, such\nas evolutionary and bandit algorithms. Drift refers roughly to the expected\nprogress towards the optimum per iteration. This paper considers the problem of\nderiving concentration tail-bounds on the runtime/regret of algorithms. It\nprovides a novel drift theorem that gives precise exponential tail-bounds given\npositive, weak, zero and even negative drift. Previously, such exponential tail\nbounds were missing in the case of weak, zero, or negative drift. Our drift\ntheorem can be used to prove a strong concentration of the runtime/regret of\nalgorithms in AI. For example, we prove that the regret of the \\rwab bandit\nalgorithm is highly concentrated, while previous analyses only considered the\nexpected regret. This means that the algorithm obtains the optimum within a\ngiven time frame with high probability, i.e. a form of algorithm reliability.\nMoreover, our theorem implies that the time needed by the co-evolutionary\nalgorithm RLS-PD to obtain a Nash equilibrium in a \\bilinear max-min-benchmark\nproblem is highly concentrated. However, we also prove that the algorithm\nforgets the Nash equilibrium, and the time until this occurs is highly\nconcentrated. This highlights a weakness in the RLS-PD which should be\naddressed by future work.",
      "tldr_zh": "本文通过 drift analysis 分析进化算法和 bandit 算法的运行时间，提出一个新颖的 drift theorem，能提供精确的指数尾界（exponential tail-bounds），适用于正、弱、零和负 drift 情况，以填补先前分析的空白。 该定理证明了 \\rwab bandit 算法的 regret 高度集中，不仅限于期望 regret，从而确保算法在给定时间内以高概率达到最优，提升了算法可靠性。 此外，应用于 co-evolutionary 算法 RLS-PD 时，发现其在 bilinear max-min-benchmark 问题中快速达到 Nash equilibrium，但也揭示了算法容易忘记 equilibrium 的弱点，需要未来研究改进。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at International Joint Conference on Artificial Intelligence\n  (IJCAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04480v2",
      "published_date": "2024-05-07 16:45:15 UTC",
      "updated_date": "2024-05-11 00:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:36:51.452915"
    },
    {
      "arxiv_id": "2405.04459v1",
      "title": "A Significantly Better Class of Activation Functions Than ReLU Like Activation Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Mathew Mithra Noel",
        "Yug Oswal"
      ],
      "abstract": "This paper introduces a significantly better class of activation functions\nthan the almost universally used ReLU like and Sigmoidal class of activation\nfunctions. Two new activation functions referred to as the Cone and\nParabolic-Cone that differ drastically from popular activation functions and\nsignificantly outperform these on the CIFAR-10 and Imagenette benchmmarks are\nproposed. The cone activation functions are positive only on a finite interval\nand are strictly negative except at the end-points of the interval, where they\nbecome zero. Thus the set of inputs that produce a positive output for a neuron\nwith cone activation functions is a hyperstrip and not a half-space as is the\nusual case. Since a hyper strip is the region between two parallel\nhyper-planes, it allows neurons to more finely divide the input feature space\ninto positive and negative classes than with infinitely wide half-spaces. In\nparticular the XOR function can be learn by a single neuron with cone-like\nactivation functions. Both the cone and parabolic-cone activation functions are\nshown to achieve higher accuracies with significantly fewer neurons on\nbenchmarks. The results presented in this paper indicate that many nonlinear\nreal-world datasets may be separated with fewer hyperstrips than half-spaces.\nThe Cone and Parabolic-Cone activation functions have larger derivatives than\nReLU and are shown to significantly speedup training.",
      "tldr_zh": "本论文提出两种新的激活函数，Cone 和 Parabolic-Cone，它们显著优于常见的 ReLU-like 和 Sigmoidal 激活函数，在 CIFAR-10 和 Imagenette 数据集上表现出色。不同于传统激活函数，这些新函数仅在有限区间内为正值，其他地方为负或零，从而将输入空间划分为超带（hyperstrip）而非半空间（half-space），允许神经元更精细地划分特征空间，例如单个神经元即可学习 XOR 函数。实验结果显示，Cone 和 Parabolic-Cone 激活函数在使用更少神经元的情况下实现了更高准确率，并显著加速了训练过程，表明它们更适合处理非线性真实数据集。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NE",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04459v1",
      "published_date": "2024-05-07 16:24:03 UTC",
      "updated_date": "2024-05-07 16:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:37:02.368889"
    },
    {
      "arxiv_id": "2405.04453v1",
      "title": "Towards Continual Knowledge Graph Embedding via Incremental Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Liu",
        "Wenjun Ke",
        "Peng Wang",
        "Ziyu Shang",
        "Jinhua Gao",
        "Guozheng Li",
        "Ke Ji",
        "Yanhe Liu"
      ],
      "abstract": "Traditional knowledge graph embedding (KGE) methods typically require\npreserving the entire knowledge graph (KG) with significant training costs when\nnew knowledge emerges. To address this issue, the continual knowledge graph\nembedding (CKGE) task has been proposed to train the KGE model by learning\nemerging knowledge efficiently while simultaneously preserving decent old\nknowledge. However, the explicit graph structure in KGs, which is critical for\nthe above goal, has been heavily ignored by existing CKGE methods. On the one\nhand, existing methods usually learn new triples in a random order, destroying\nthe inner structure of new KGs. On the other hand, old triples are preserved\nwith equal priority, failing to alleviate catastrophic forgetting effectively.\nIn this paper, we propose a competitive method for CKGE based on incremental\ndistillation (IncDE), which considers the full use of the explicit graph\nstructure in KGs. First, to optimize the learning order, we introduce a\nhierarchical strategy, ranking new triples for layer-by-layer learning. By\nemploying the inter- and intra-hierarchical orders together, new triples are\ngrouped into layers based on the graph structure features. Secondly, to\npreserve the old knowledge effectively, we devise a novel incremental\ndistillation mechanism, which facilitates the seamless transfer of entity\nrepresentations from the previous layer to the next one, promoting old\nknowledge preservation. Finally, we adopt a two-stage training paradigm to\navoid the over-corruption of old knowledge influenced by under-trained new\nknowledge. Experimental results demonstrate the superiority of IncDE over\nstate-of-the-art baselines. Notably, the incremental distillation mechanism\ncontributes to improvements of 0.2%-6.5% in the mean reciprocal rank (MRR)\nscore.",
      "tldr_zh": "该研究针对传统知识图嵌入(KGE)模型在处理新增知识时的高训练成本问题，提出了一种基于增量蒸馏(Incremental Distillation)的持续知识图嵌入(CKGE)方法，即IncDE，以充分利用KG的显式图结构。首先，IncDE引入分层策略，通过inter-和intra-hierarchical orders对新三元组进行分层学习，优化学习顺序并维护KG结构。其次，该方法设计了新型增量蒸馏机制，促进实体表示从前一层无缝转移，从而有效缓解灾难性遗忘，并采用两阶段训练范式避免新知识干扰旧知识。实验结果显示，IncDE在MRR分数上比现有基线方法提高了0.2%-6.5%，证明了其在CKGE任务中的优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04453v1",
      "published_date": "2024-05-07 16:16:00 UTC",
      "updated_date": "2024-05-07 16:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:37:14.231576"
    },
    {
      "arxiv_id": "2405.04443v1",
      "title": "POV Learning: Individual Alignment of Multimodal Models using Human Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Werner",
        "Katharina Christ",
        "Laura Bernardy",
        "Marion G. Müller",
        "Achim Rettinger"
      ],
      "abstract": "Aligning machine learning systems with human expectations is mostly attempted\nby training with manually vetted human behavioral samples, typically explicit\nfeedback. This is done on a population level since the context that is\ncapturing the subjective Point-Of-View (POV) of a concrete person in a specific\nsituational context is not retained in the data. However, we argue that\nalignment on an individual level can boost the subjective predictive\nperformance for the individual user interacting with the system considerably.\nSince perception differs for each person, the same situation is observed\ndifferently. Consequently, the basis for decision making and the subsequent\nreasoning processes and observable reactions differ. We hypothesize that\nindividual perception patterns can be used for improving the alignment on an\nindividual level. We test this, by integrating perception information into\nmachine learning systems and measuring their predictive performance\nwrt.~individual subjective assessments. For our empirical study, we collect a\nnovel data set of multimodal stimuli and corresponding eye tracking sequences\nfor the novel task of Perception-Guided Crossmodal Entailment and tackle it\nwith our Perception-Guided Multimodal Transformer. Our findings suggest that\nexploiting individual perception signals for the machine learning of subjective\nhuman assessments provides a valuable cue for individual alignment. It does not\nonly improve the overall predictive performance from the point-of-view of the\nindividual user but might also contribute to steering AI systems towards every\nperson's individual expectations and values.",
      "tldr_zh": "这篇论文提出POV Learning方法，通过整合人类感知（如眼动追踪）来实现多模态模型的个体对齐（Individual Alignment），以解决传统基于人口水平训练的局限性。研究假设个体感知模式会影响决策和反应，因此开发了Perception-Guided Multimodal Transformer模型，并收集了一个新数据集用于Perception-Guided Crossmodal Entailment任务。实验结果表明，这种方法显著提升了主观预测性能，并有助于AI系统更好地适应每个用户的个人期望和价值观。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04443v1",
      "published_date": "2024-05-07 16:07:29 UTC",
      "updated_date": "2024-05-07 16:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:37:27.029217"
    },
    {
      "arxiv_id": "2405.04442v1",
      "title": "AugmenTory: A Fast and Flexible Polygon Augmentation Library",
      "title_zh": "翻译失败",
      "authors": [
        "Tanaz Ghahremani",
        "Mohammad Hoseyni",
        "Mohammad Javad Ahmadi",
        "Pouria Mehrabi",
        "Amirhossein Nikoofard"
      ],
      "abstract": "Data augmentation is a key technique for addressing the challenge of limited\ndatasets, which have become a major component in the training procedures of\nimage processing. Techniques such as geometric transformations and color space\nadjustments have been thoroughly tested for their ability to artificially\nexpand training datasets and generate semi-realistic data for training\npurposes. Data augmentation is the most important key to addressing the\nchallenge of limited datasets, which have become a major component of image\nprocessing training procedures. Data augmentation techniques, such as geometric\ntransformations and color space adjustments, are thoroughly tested for their\nability to artificially expand training datasets and generate semi-realistic\ndata for training purposes. Polygons play a crucial role in instance\nsegmentation and have seen a surge in use across advanced models, such as\nYOLOv8. Despite their growing popularity, the lack of specialized libraries\nhampers the polygon-augmentation process. This paper introduces a novel\nsolution to this challenge, embodied in the newly developed AugmenTory library.\nNotably, AugmenTory offers reduced computational demands in both time and space\ncompared to existing methods. Additionally, the library includes a\npostprocessing thresholding feature. The AugmenTory package is publicly\navailable on GitHub, where interested users can access the source code:\nhttps://github.com/Smartory/AugmenTory",
      "tldr_zh": "本文研究了数据增强（Data augmentation）在图像处理训练中的关键作用，特别是针对实例分割（instance segmentation）中多边形（Polygons）的增强需求，如 YOLOv8 等模型。论文引入了 AugmenTory 库，这是一个快速且灵活的多边形增强库，能够比现有方法显著降低时间和空间计算需求，并提供后处理阈值功能。AugmenTory 已开源在 GitHub 上（https://github.com/Smartory/AugmenTory），为用户提供易访问的工具来扩展训练数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04442v1",
      "published_date": "2024-05-07 16:07:05 UTC",
      "updated_date": "2024-05-07 16:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:37:38.616100"
    },
    {
      "arxiv_id": "2405.04434v5",
      "title": "DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "DeepSeek-AI",
        "Aixin Liu",
        "Bei Feng",
        "Bin Wang",
        "Bingxuan Wang",
        "Bo Liu",
        "Chenggang Zhao",
        "Chengqi Dengr",
        "Chong Ruan",
        "Damai Dai",
        "Daya Guo",
        "Dejian Yang",
        "Deli Chen",
        "Dongjie Ji",
        "Erhang Li",
        "Fangyun Lin",
        "Fuli Luo",
        "Guangbo Hao",
        "Guanting Chen",
        "Guowei Li",
        "H. Zhang",
        "Hanwei Xu",
        "Hao Yang",
        "Haowei Zhang",
        "Honghui Ding",
        "Huajian Xin",
        "Huazuo Gao",
        "Hui Li",
        "Hui Qu",
        "J. L. Cai",
        "Jian Liang",
        "Jianzhong Guo",
        "Jiaqi Ni",
        "Jiashi Li",
        "Jin Chen",
        "Jingyang Yuan",
        "Junjie Qiu",
        "Junxiao Song",
        "Kai Dong",
        "Kaige Gao",
        "Kang Guan",
        "Lean Wang",
        "Lecong Zhang",
        "Lei Xu",
        "Leyi Xia",
        "Liang Zhao",
        "Liyue Zhang",
        "Meng Li",
        "Miaojun Wang",
        "Mingchuan Zhang",
        "Minghua Zhang",
        "Minghui Tang",
        "Mingming Li",
        "Ning Tian",
        "Panpan Huang",
        "Peiyi Wang",
        "Peng Zhang",
        "Qihao Zhu",
        "Qinyu Chen",
        "Qiushi Du",
        "R. J. Chen",
        "R. L. Jin",
        "Ruiqi Ge",
        "Ruizhe Pan",
        "Runxin Xu",
        "Ruyi Chen",
        "S. S. Li",
        "Shanghao Lu",
        "Shangyan Zhou",
        "Shanhuang Chen",
        "Shaoqing Wu",
        "Shengfeng Ye",
        "Shirong Ma",
        "Shiyu Wang",
        "Shuang Zhou",
        "Shuiping Yu",
        "Shunfeng Zhou",
        "Size Zheng",
        "T. Wang",
        "Tian Pei",
        "Tian Yuan",
        "Tianyu Sun",
        "W. L. Xiao",
        "Wangding Zeng",
        "Wei An",
        "Wen Liu",
        "Wenfeng Liang",
        "Wenjun Gao",
        "Wentao Zhang",
        "X. Q. Li",
        "Xiangyue Jin",
        "Xianzu Wang",
        "Xiao Bi",
        "Xiaodong Liu",
        "Xiaohan Wang",
        "Xiaojin Shen",
        "Xiaokang Chen",
        "Xiaosha Chen",
        "Xiaotao Nie",
        "Xiaowen Sun",
        "Xiaoxiang Wang",
        "Xin Liu",
        "Xin Xie",
        "Xingkai Yu",
        "Xinnan Song",
        "Xinyi Zhou",
        "Xinyu Yang",
        "Xuan Lu",
        "Xuecheng Su",
        "Y. Wu",
        "Y. K. Li",
        "Y. X. Wei",
        "Y. X. Zhu",
        "Yanhong Xu",
        "Yanping Huang",
        "Yao Li",
        "Yao Zhao",
        "Yaofeng Sun",
        "Yaohui Li",
        "Yaohui Wang",
        "Yi Zheng",
        "Yichao Zhang",
        "Yiliang Xiong",
        "Yilong Zhao",
        "Ying He",
        "Ying Tang",
        "Yishi Piao",
        "Yixin Dong",
        "Yixuan Tan",
        "Yiyuan Liu",
        "Yongji Wang",
        "Yongqiang Guo",
        "Yuchen Zhu",
        "Yuduan Wang",
        "Yuheng Zou",
        "Yukun Zha",
        "Yunxian Ma",
        "Yuting Yan",
        "Yuxiang You",
        "Yuxuan Liu",
        "Z. Z. Ren",
        "Zehui Ren",
        "Zhangli Sha",
        "Zhe Fu",
        "Zhen Huang",
        "Zhen Zhang",
        "Zhenda Xie",
        "Zhewen Hao",
        "Zhihong Shao",
        "Zhiniu Wen",
        "Zhipeng Xu",
        "Zhongyu Zhang",
        "Zhuoshu Li",
        "Zihan Wang",
        "Zihui Gu",
        "Zilin Li",
        "Ziwei Xie"
      ],
      "abstract": "We present DeepSeek-V2, a strong Mixture-of-Experts (MoE) language model\ncharacterized by economical training and efficient inference. It comprises 236B\ntotal parameters, of which 21B are activated for each token, and supports a\ncontext length of 128K tokens. DeepSeek-V2 adopts innovative architectures\nincluding Multi-head Latent Attention (MLA) and DeepSeekMoE. MLA guarantees\nefficient inference through significantly compressing the Key-Value (KV) cache\ninto a latent vector, while DeepSeekMoE enables training strong models at an\neconomical cost through sparse computation. Compared with DeepSeek 67B,\nDeepSeek-V2 achieves significantly stronger performance, and meanwhile saves\n42.5% of training costs, reduces the KV cache by 93.3%, and boosts the maximum\ngeneration throughput to 5.76 times. We pretrain DeepSeek-V2 on a high-quality\nand multi-source corpus consisting of 8.1T tokens, and further perform\nSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL) to fully unlock\nits potential. Evaluation results show that, even with only 21B activated\nparameters, DeepSeek-V2 and its chat versions still achieve top-tier\nperformance among open-source models.",
      "tldr_zh": "我们介绍了 DeepSeek-V2，一种强大的 Mixture-of-Experts (MoE) 语言模型，具有经济训练和高效推理的特点，总参数达 236B，但每个 token 只激活 21B 参数，并支持 128K tokens 的上下文长度。 该模型创新性地采用 Multi-head Latent Attention (MLA) 和 DeepSeekMoE 架构，其中 MLA 通过压缩 Key-Value (KV) cache 为潜在向量显著提高推理效率，而 DeepSeekMoE 通过稀疏计算降低训练成本，与 DeepSeek 67B 相比节省 42.5% 成本并提升 5.76 倍生成吞吐量。 在 8.1T tokens 的高质量多源语料上预训练后，通过 Supervised Fine-Tuning (SFT) 和 Reinforcement Learning (RL) 优化，DeepSeek-V2 即使仅激活 21B 参数，也在开源模型中实现顶尖性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04434v5",
      "published_date": "2024-05-07 15:56:43 UTC",
      "updated_date": "2024-06-19 06:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:37:50.934262"
    },
    {
      "arxiv_id": "2405.04407v2",
      "title": "Super-Exponential Regret for UCT, AlphaGo and Variants",
      "title_zh": "翻译失败",
      "authors": [
        "Laurent Orseau",
        "Remi Munos"
      ],
      "abstract": "We improve the proofs of the lower bounds of Coquelin and Munos (2007) that\ndemonstrate that UCT can have $\\exp(\\dots\\exp(1)\\dots)$ regret (with\n$\\Omega(D)$ exp terms) on the $D$-chain environment, and that a `polynomial'\nUCT variant has $\\exp_2(\\exp_2(D - O(\\log D)))$ regret on the same environment\n-- the original proofs contain an oversight for rewards bounded in $[0, 1]$,\nwhich we fix in the present draft. We also adapt the proofs to AlphaGo's MCTS\nand its descendants (e.g., AlphaZero, Leela Zero) to also show $\\exp_2(\\exp_2(D\n- O(\\log D)))$ regret.",
      "tldr_zh": "这篇论文改进了Coquelin和Munos (2007)的下界证明，修复了原证明中奖励限制在[0, 1]的遗漏，展示了UCT算法在D-chain环境中可能出现超级指数级的regret，包括exp(…exp(1)…)形式（包含Ω(D)个exp项）。对于一个“polynomial”UCT变体，该论文证明了其regret达到exp2(exp2(D - O(log D)))。此外，证明被扩展到AlphaGo的MCTS及其衍生（如AlphaZero和Leela Zero），同样显示出exp2(exp2(D - O(log D)))的regret，从而突显了这些算法在特定环境下的性能局限。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04407v2",
      "published_date": "2024-05-07 15:35:30 UTC",
      "updated_date": "2024-05-17 12:15:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:38:03.982717"
    },
    {
      "arxiv_id": "2405.04404v1",
      "title": "Vision Mamba: A Comprehensive Survey and Taxonomy",
      "title_zh": "Vision Mamba：全面综述与分类体系",
      "authors": [
        "Xiao Liu",
        "Chenxu Zhang",
        "Lei Zhang"
      ],
      "abstract": "State Space Model (SSM) is a mathematical model used to describe and analyze\nthe behavior of dynamic systems. This model has witnessed numerous applications\nin several fields, including control theory, signal processing, economics and\nmachine learning. In the field of deep learning, state space models are used to\nprocess sequence data, such as time series analysis, natural language\nprocessing (NLP) and video understanding. By mapping sequence data to state\nspace, long-term dependencies in the data can be better captured. In\nparticular, modern SSMs have shown strong representational capabilities in NLP,\nespecially in long sequence modeling, while maintaining linear time complexity.\nNotably, based on the latest state-space models, Mamba merges time-varying\nparameters into SSMs and formulates a hardware-aware algorithm for efficient\ntraining and inference. Given its impressive efficiency and strong long-range\ndependency modeling capability, Mamba is expected to become a new AI\narchitecture that may outperform Transformer. Recently, a number of works have\nattempted to study the potential of Mamba in various fields, such as general\nvision, multi-modal, medical image analysis and remote sensing image analysis,\nby extending Mamba from natural language domain to visual domain. To fully\nunderstand Mamba in the visual domain, we conduct a comprehensive survey and\npresent a taxonomy study. This survey focuses on Mamba's application to a\nvariety of visual tasks and data types, and discusses its predecessors, recent\nadvances and far-reaching impact on a wide range of domains. Since Mamba is now\non an upward trend, please actively notice us if you have new findings, and new\nprogress on Mamba will be included in this survey in a timely manner and\nupdated on the Mamba project at\nhttps://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.",
      "tldr_zh": "这篇论文对Vision Mamba进行了全面调查和分类，聚焦于State Space Model (SSM)在其视觉领域的应用。Mamba通过引入时间变化参数，提升了序列数据处理的效率和长距离依赖建模能力，可能超越Transformer，成为新一代AI架构。论文回顾了Mamba的前身、最新进展，并系统分类其在一般视觉、多模态、医疗图像分析和遥感图像分析等任务中的扩展，为未来研究提供重要参考。作者鼓励提交新发现，并通过GitHub持续更新调查内容。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy",
      "pdf_url": "http://arxiv.org/pdf/2405.04404v1",
      "published_date": "2024-05-07 15:30:14 UTC",
      "updated_date": "2024-05-07 15:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:38:16.471605"
    },
    {
      "arxiv_id": "2405.04386v1",
      "title": "Pragmatist Intelligence: Where the Principle of Usefulness Can Take ANNs",
      "title_zh": "实用主义智能：有用性原则能将 ANNs",
      "authors": [
        "Antonio Bikić",
        "Sayan Mukherjee"
      ],
      "abstract": "Artificial neural networks (ANNs) perform extraordinarily on numerous tasks\nincluding classification or prediction, e.g., speech processing and image\nclassification. These new functions are based on a computational model that is\nenabled to select freely all necessary internal model parameters as long as it\neventually delivers the functionality it is supposed to exhibit. Here, we\nreview the connection between the model parameter selection in machine learning\n(ML) algorithms running on ANNs and the epistemological theory of neopragmatism\nfocusing on the theory's utility and anti-representationalist aspects. To\nunderstand the consequences of the model parameter selection of an ANN, we\nsuggest using neopragmatist theories whose implications are well studied.\nIncidentally, neopragmatism's notion of optimization is also based on utility\nconsiderations. This means that applying this approach elegantly reveals the\ninherent connections between optimization in ML, using a numerical method\nduring the learning phase, and optimization in the ethical theory of\nconsequentialism, where it occurs as a maxim of action. We suggest that these\nconnections originate from the way relevance is calculated in ML systems. This\ncould ultimately reveal a tendency for specific actions in ML systems.",
      "tldr_zh": "该论文探讨了人工神经网络 (ANNs) 在分类和预测任务中的出色表现，并审视了模型参数选择如何与新实用主义 (neopragmatism) 认识论的实用性和反代表性方面相联系。作者建议通过新实用主义理论来分析 ANN 参数选择的后果，强调优化过程在机器学习 (ML) 中的数值方法与道德理论 consequentialism 中的行动准则具有内在联系。这些联系源于 ML 系统对相关性的计算，可能揭示 ML 系统潜在的行动倾向，从而为 ANN 的发展提供新的哲学视角。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04386v1",
      "published_date": "2024-05-07 15:11:42 UTC",
      "updated_date": "2024-05-07 15:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:38:27.925172"
    },
    {
      "arxiv_id": "2405.04373v1",
      "title": "Leveraging LSTM and GAN for Modern Malware Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ishita Gupta",
        "Sneha Kumari",
        "Priya Jha",
        "Mohona Ghosh"
      ],
      "abstract": "The malware booming is a cyberspace equal to the effect of climate change to\necosystems in terms of danger. In the case of significant investments in\ncybersecurity technologies and staff training, the global community has become\nlocked up in the eternal war with cyber security threats. The multi-form and\nchanging faces of malware are continuously pushing the boundaries of the\ncybersecurity practitioners employ various approaches like detection and\nmitigate in coping with this issue. Some old mannerisms like signature-based\ndetection and behavioral analysis are slow to adapt to the speedy evolution of\nmalware types. Consequently, this paper proposes the utilization of the Deep\nLearning Model, LSTM networks, and GANs to amplify malware detection accuracy\nand speed. A fast-growing, state-of-the-art technology that leverages raw\nbytestream-based data and deep learning architectures, the AI technology\nprovides better accuracy and performance than the traditional methods.\nIntegration of LSTM and GAN model is the technique that is used for the\nsynthetic generation of data, leading to the expansion of the training\ndatasets, and as a result, the detection accuracy is improved. The paper uses\nthe VirusShare dataset which has more than one million unique samples of the\nmalware as the training and evaluation set for the presented models. Through\nthorough data preparation including tokenization, augmentation, as well as\nmodel training, the LSTM and GAN models convey the better performance in the\ntasks compared to straight classifiers. The research outcomes come out with 98%\naccuracy that shows the efficiency of deep learning plays a decisive role in\nproactive cybersecurity defense. Aside from that, the paper studies the output\nof ensemble learning and model fusion methods as a way to reduce biases and\nlift model complexity.",
      "tldr_zh": "这篇论文针对恶意软件的快速演变及其对网络安全的威胁，提出了一种结合 LSTM 网络和 GAN 的深度学习方法，以提高检测的准确性和速度。方法通过 GAN 生成合成数据来扩展训练数据集（如 VirusShare 数据集中的超过一百万样本），从而提升 LSTM 模型的性能。实验结果显示，该方法在检测任务中达到了 98% 的准确率，并通过集成学习和模型融合技术进一步减少偏差和提升模型复杂度，证明了深度学习在主动网络安全防御中的关键作用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04373v1",
      "published_date": "2024-05-07 14:57:24 UTC",
      "updated_date": "2024-05-07 14:57:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:38:41.395103"
    },
    {
      "arxiv_id": "2405.04372v2",
      "title": "Explainable machine learning for predicting shellfish toxicity in the Adriatic Sea using long-term monitoring data of HABs",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Marzidovšek",
        "Janja Francé",
        "Vid Podpečan",
        "Stanka Vadnjal",
        "Jožica Dolenc",
        "Patricija Mozetič"
      ],
      "abstract": "In this study, explainable machine learning techniques are applied to predict\nthe toxicity of mussels in the Gulf of Trieste (Adriatic Sea) caused by harmful\nalgal blooms. By analysing a newly created 28-year dataset containing records\nof toxic phytoplankton in mussel farming areas and toxin concentrations in\nmussels (Mytilus galloprovincialis), we train and evaluate the performance of\nML models to accurately predict diarrhetic shellfish poisoning (DSP) events.\nThe random forest model provided the best prediction of positive toxicity\nresults based on the F1 score. Explainability methods such as permutation\nimportance and SHAP identified key species (Dinophysis fortii and D. caudata)\nand environmental factors (salinity, river discharge and precipitation) as the\nbest predictors of DSP outbreaks. These findings are important for improving\nearly warning systems and supporting sustainable aquaculture practices.",
      "tldr_zh": "本研究运用explainable machine learning技术，基于亚得里亚海28年的有害藻华(HABs)监测数据，预测贻贝(Mytilus galloprovincialis)的毒性，特别是diarrhetic shellfish poisoning (DSP)事件。随机森林(random forest)模型在预测准确性上表现最佳，根据F1分数提供了优越的性能。通过permutation importance和SHAP方法，识别了关键物种Dinophysis fortii和D. caudata，以及环境因素如salinity、river discharge和precipitation作为主要预测指标。这些发现有助于改进早期预警系统并支持可持续水产养殖实践。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04372v2",
      "published_date": "2024-05-07 14:55:42 UTC",
      "updated_date": "2024-05-09 09:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:38:54.718770"
    },
    {
      "arxiv_id": "2405.04561v1",
      "title": "Inferring Discussion Topics about Exploitation of Vulnerabilities from Underground Hacking Forums",
      "title_zh": "从地下黑客论坛推断关于漏洞利用的讨论主题",
      "authors": [
        "Felipe Moreno-Vera"
      ],
      "abstract": "The increasing sophistication of cyber threats necessitates proactive\nmeasures to identify vulnerabilities and potential exploits. Underground\nhacking forums serve as breeding grounds for the exchange of hacking techniques\nand discussions related to exploitation. In this research, we propose an\ninnovative approach using topic modeling to analyze and uncover key themes in\nvulnerabilities discussed within these forums. The objective of our study is to\ndevelop a machine learning-based model that can automatically detect and\nclassify vulnerability-related discussions in underground hacking forums. By\nmonitoring and analyzing the content of these forums, we aim to identify\nemerging vulnerabilities, exploit techniques, and potential threat actors. To\nachieve this, we collect a large-scale dataset consisting of posts and threads\nfrom multiple underground forums. We preprocess and clean the data to ensure\naccuracy and reliability. Leveraging topic modeling techniques, specifically\nLatent Dirichlet Allocation (LDA), we uncover latent topics and their\nassociated keywords within the dataset. This enables us to identify recurring\nthemes and prevalent discussions related to vulnerabilities, exploits, and\npotential targets.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用主题建模（topic modeling）来分析地下黑客论坛中关于漏洞利用（vulnerabilities）的讨论主题，旨在帮助识别新兴威胁。研究团队收集并预处理了大规模数据集，包括帖子和线程，然后应用Latent Dirichlet Allocation (LDA)技术来挖掘潜在主题和相关关键词。最终，该方法能够自动检测和分类漏洞相关讨论，从而揭示常见利用技术、潜在目标和威胁者，为主动网络安全措施提供支持。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04561v1",
      "published_date": "2024-05-07 14:54:32 UTC",
      "updated_date": "2024-05-07 14:54:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:39:04.011850"
    },
    {
      "arxiv_id": "2405.04371v1",
      "title": "Community Detection for Heterogeneous Multiple Social Networks",
      "title_zh": "异构多个社交网络的社区检测",
      "authors": [
        "Ziqing Zhu",
        "Guan Yuan",
        "Tao Zhou",
        "Jiuxin Cao"
      ],
      "abstract": "The community plays a crucial role in understanding user behavior and network\ncharacteristics in social networks. Some users can use multiple social networks\nat once for a variety of objectives. These users are called overlapping users\nwho bridge different social networks. Detecting communities across multiple\nsocial networks is vital for interaction mining, information diffusion, and\nbehavior migration analysis among networks. This paper presents a community\ndetection method based on nonnegative matrix tri-factorization for multiple\nheterogeneous social networks, which formulates a common consensus matrix to\nrepresent the global fused community. Specifically, the proposed method\ninvolves creating adjacency matrices based on network structure and content\nsimilarity, followed by alignment matrices which distinguish overlapping users\nin different social networks. With the generated alignment matrices, the method\ncould enhance the fusion degree of the global community by detecting\noverlapping user communities across networks. The effectiveness of the proposed\nmethod is evaluated with new metrics on Twitter, Instagram, and Tumblr\ndatasets. The results of the experiments demonstrate its superior performance\nin terms of community quality and community fusion.",
      "tldr_zh": "这篇论文针对异构多社交网络提出了一种基于非负矩阵三因子分解(nonnegative matrix tri-factorization)的社区检测方法，旨在通过识别重叠用户(overlapping users)来融合全局社区。方法涉及创建邻接矩阵(adjacency matrices)基于网络结构和内容相似度，以及对齐矩阵(alignment matrices)来区分不同网络中的重叠用户，从而增强跨网络社区的融合度。在Twitter、Instagram和Tumblr数据集上的实验结果显示，该方法在社区质量和社区融合方面显著优于基线模型。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SI",
      "comment": "This paper was accepted by IEEE Transactions on Computational Social\n  Systems(TCSS)",
      "pdf_url": "http://arxiv.org/pdf/2405.04371v1",
      "published_date": "2024-05-07 14:52:34 UTC",
      "updated_date": "2024-05-07 14:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:39:16.168117"
    },
    {
      "arxiv_id": "2405.04357v1",
      "title": "Global Scale Self-Supervised Channel Charting with Sensor Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Omid Esrafilian",
        "Mohsen Ahadi",
        "Florian Kaltenberger",
        "David Gesbert"
      ],
      "abstract": "The sensing and positioning capabilities foreseen in 6G have great potential\nfor technology advancements in various domains, such as future smart cities and\nindustrial use cases. Channel charting has emerged as a promising technology in\nrecent years for radio frequency-based sensing and localization. However, the\naccuracy of these techniques is yet far behind the numbers envisioned in 6G. To\nreduce this gap, in this paper, we propose a novel channel charting technique\ncapitalizing on the time of arrival measurements from surrounding Transmission\nReception Points (TRPs) along with their locations and leveraging sensor fusion\nin channel charting by incorporating laser scanner data during the training\nphase of our algorithm. The proposed algorithm remains self-supervised during\ntraining and test phases, requiring no geometrical models or user position\nground truth. Simulation results validate the achievement of a sub-meter level\nlocalization accuracy using our algorithm 90% of the time, outperforming the\nstate-of-the-art channel charting techniques and the traditional\ntriangulation-based approaches.",
      "tldr_zh": "本研究针对6G时代感知和定位技术的需求，提出了一种全球规模的自监督Channel Charting方法，通过Sensor Fusion整合Time of Arrival (ToA)测量、Transmission Reception Points (TRPs)的位置以及激光扫描仪数据，实现精确的射频感知和定位。不同于传统方法，该算法在训练和测试阶段保持自监督状态，不依赖几何模型或用户位置的真实数据。模拟结果显示，该方法在90%的时间内实现亚米级定位精度，显著优于现有Channel Charting技术和三角测量方法。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "This paper is submitted to the Globecom 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2405.04357v1",
      "published_date": "2024-05-07 14:33:45 UTC",
      "updated_date": "2024-05-07 14:33:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:39:28.081195"
    },
    {
      "arxiv_id": "2405.04346v2",
      "title": "Revisiting Character-level Adversarial Attacks for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Abad Rocamora",
        "Yongtao Wu",
        "Fanghui Liu",
        "Grigorios G. Chrysos",
        "Volkan Cevher"
      ],
      "abstract": "Adversarial attacks in Natural Language Processing apply perturbations in the\ncharacter or token levels. Token-level attacks, gaining prominence for their\nuse of gradient-based methods, are susceptible to altering sentence semantics,\nleading to invalid adversarial examples. While character-level attacks easily\nmaintain semantics, they have received less attention as they cannot easily\nadopt popular gradient-based methods, and are thought to be easy to defend.\nChallenging these beliefs, we introduce Charmer, an efficient query-based\nadversarial attack capable of achieving high attack success rate (ASR) while\ngenerating highly similar adversarial examples. Our method successfully targets\nboth small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2,\nCharmer improves the ASR in 4.84% points and the USE similarity in 8% points\nwith respect to the previous art. Our implementation is available in\nhttps://github.com/LIONS-EPFL/Charmer.",
      "tldr_zh": "这篇论文重新审视了字符级对抗攻击在语言模型中的应用，指出虽然字符级攻击能更好地保持句子语义，但以往被认为不易采用梯度-based 方法且易防御。作者引入了 Charmer，一种高效的查询-based 字符级攻击方法，能够实现高攻击成功率 (ASR) 和高相似性 adversarial examples，并适用于小模型（如 BERT）和大模型（如 Llama 2）。在 BERT 与 SST-2 数据集的实验中，Charmer 比现有方法提高了 4.84% 的 ASR 和 8% 的 USE 相似性，挑战了传统观点并为改进对抗攻击提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04346v2",
      "published_date": "2024-05-07 14:23:22 UTC",
      "updated_date": "2024-09-04 15:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:39:42.583844"
    },
    {
      "arxiv_id": "2405.04345v1",
      "title": "Novel View Synthesis with Neural Radiance Fields for Industrial Robot Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Hillemann",
        "Robert Langendörfer",
        "Max Heiken",
        "Max Mehltretter",
        "Andreas Schenk",
        "Martin Weinmann",
        "Stefan Hinz",
        "Christian Heipke",
        "Markus Ulrich"
      ],
      "abstract": "Neural Radiance Fields (NeRFs) have become a rapidly growing research field\nwith the potential to revolutionize typical photogrammetric workflows, such as\nthose used for 3D scene reconstruction. As input, NeRFs require multi-view\nimages with corresponding camera poses as well as the interior orientation. In\nthe typical NeRF workflow, the camera poses and the interior orientation are\nestimated in advance with Structure from Motion (SfM). But the quality of the\nresulting novel views, which depends on different parameters such as the number\nand distribution of available images, as well as the accuracy of the related\ncamera poses and interior orientation, is difficult to predict. In addition,\nSfM is a time-consuming pre-processing step, and its quality strongly depends\non the image content. Furthermore, the undefined scaling factor of SfM hinders\nsubsequent steps in which metric information is required. In this paper, we\nevaluate the potential of NeRFs for industrial robot applications. We propose\nan alternative to SfM pre-processing: we capture the input images with a\ncalibrated camera that is attached to the end effector of an industrial robot\nand determine accurate camera poses with metric scale based on the robot\nkinematics. We then investigate the quality of the novel views by comparing\nthem to ground truth, and by computing an internal quality measure based on\nensemble methods. For evaluation purposes, we acquire multiple datasets that\npose challenges for reconstruction typical of industrial applications, like\nreflective objects, poor texture, and fine structures. We show that the\nrobot-based pose determination reaches similar accuracy as SfM in non-demanding\ncases, while having clear advantages in more challenging scenarios. Finally, we\npresent first results of applying the ensemble method to estimate the quality\nof the synthetic novel view in the absence of a ground truth.",
      "tldr_zh": "本研究探讨了Neural Radiance Fields (NeRFs) 在工业机器人应用中的潜力，针对传统依赖Structure from Motion (SfM) 的相机位姿估计问题，该方法耗时且易受图像内容影响。论文提出一种替代方案，使用附着在机器人末端的校准相机，通过机器人运动学获取精确的带尺度相机位姿，从而生成高质量的新视图合成。实验结果显示，该方法在处理工业挑战（如反光物体、纹理差和精细结构）的场景中，位姿准确性优于SfM，并通过集成方法（ensemble methods）实现了对合成视图质量的无地面实况估计。总的来说，这一创新提升了NeRFs在工业场景重建的鲁棒性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 8 figures, accepted for publication in The International\n  Archives of the Photogrammetry, Remote Sensing and Spatial Information\n  Sciences (ISPRS Archives) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04345v1",
      "published_date": "2024-05-07 14:22:32 UTC",
      "updated_date": "2024-05-07 14:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:39:52.891332"
    },
    {
      "arxiv_id": "2405.04344v2",
      "title": "Enhancing Scalability of Metric Differential Privacy via Secret Dataset Partitioning and Benders Decomposition",
      "title_zh": "通过秘密数据集分区和 Benders Decomposition 增强度量差分隐私的可扩展性",
      "authors": [
        "Chenxi Qiu"
      ],
      "abstract": "Metric Differential Privacy (mDP) extends the concept of Differential Privacy\n(DP) to serve as a new paradigm of data perturbation. It is designed to protect\nsecret data represented in general metric space, such as text data encoded as\nword embeddings or geo-location data on the road network or grid maps. To\nderive an optimal data perturbation mechanism under mDP, a widely used method\nis linear programming (LP), which, however, might suffer from a polynomial\nexplosion of decision variables, rendering it impractical in large-scale mDP.\n  In this paper, our objective is to develop a new computation framework to\nenhance the scalability of the LP-based mDP. Considering the connections\nestablished by the mDP constraints among the secret records, we partition the\noriginal secret dataset into various subsets. Building upon the partition, we\nreformulate the LP problem for mDP and solve it via Benders Decomposition,\nwhich is composed of two stages: (1) a master program to manage the\nperturbation calculation across subsets and (2) a set of subproblems, each\nmanaging the perturbation derivation within a subset. Our experimental results\non multiple datasets, including geo-location data in the road network/grid\nmaps, text data, and synthetic data, underscore our proposed mechanism's\nsuperior scalability and efficiency.",
      "tldr_zh": "该论文旨在提升 Metric Differential Privacy (mDP) 的可扩展性，以解决传统线性规划 (LP) 方法在处理大规模数据集时决策变量爆炸的问题。研究者通过将秘密数据集分区，并利用 Benders Decomposition 重构 LP 问题，该方法包括主程序管理子集间的扰动计算，以及子问题处理子集内的扰动派生，从而显著提高了计算效率。实验结果显示，在地理位置数据、文本数据和合成数据集上，该机制表现出色，可扩展性和效率均优于基线方法。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04344v2",
      "published_date": "2024-05-07 14:19:09 UTC",
      "updated_date": "2024-05-09 04:36:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:40:03.671714"
    },
    {
      "arxiv_id": "2405.04336v2",
      "title": "Temporal and Heterogeneous Graph Neural Network for Remaining Useful Life Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihao Wen",
        "Yuan Fang",
        "Pengcheng Wei",
        "Fayao Liu",
        "Zhenghua Chen",
        "Min Wu"
      ],
      "abstract": "Predicting Remaining Useful Life (RUL) plays a crucial role in the\nprognostics and health management of industrial systems that involve a variety\nof interrelated sensors. Given a constant stream of time series sensory data\nfrom such systems, deep learning models have risen to prominence at identifying\ncomplex, nonlinear temporal dependencies in these data. In addition to the\ntemporal dependencies of individual sensors, spatial dependencies emerge as\nimportant correlations among these sensors, which can be naturally modelled by\na temporal graph that describes time-varying spatial relationships. However,\nthe majority of existing studies have relied on capturing discrete snapshots of\nthis temporal graph, a coarse-grained approach that leads to loss of temporal\ninformation. Moreover, given the variety of heterogeneous sensors, it becomes\nvital that such inherent heterogeneity is leveraged for RUL prediction in\ntemporal sensor graphs. To capture the nuances of the temporal and spatial\nrelationships and heterogeneous characteristics in an interconnected graph of\nsensors, we introduce a novel model named Temporal and Heterogeneous Graph\nNeural Networks (THGNN). Specifically, THGNN aggregates historical data from\nneighboring nodes to accurately capture the temporal dynamics and spatial\ncorrelations within the stream of sensor data in a fine-grained manner.\nMoreover, the model leverages Feature-wise Linear Modulation (FiLM) to address\nthe diversity of sensor types, significantly improving the model's capacity to\nlearn the heterogeneity in the data sources. Finally, we have validated the\neffectiveness of our approach through comprehensive experiments. Our empirical\nfindings demonstrate significant advancements on the N-CMAPSS dataset,\nachieving improvements of up to 19.2% and 31.6% in terms of two different\nevaluation metrics over state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种名为 Temporal and Heterogeneous Graph Neural Networks (THGNN) 的模型，用于预测工业系统传感器的 Remaining Useful Life (RUL)，通过捕捉时序数据中的时序动态和空间相关性来解决现有方法的局限性。THGNN 通过聚合邻居节点的历史数据实现细粒度建模，并利用 Feature-wise Linear Modulation (FiLM) 处理传感器类型的异质性，从而提升预测准确性。在 N-CMAPSS 数据集上的实验表明，该模型在两个评估指标上比最先进方法分别提高了 19.2% 和 31.6%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04336v2",
      "published_date": "2024-05-07 14:08:57 UTC",
      "updated_date": "2024-06-01 04:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:40:16.852345"
    },
    {
      "arxiv_id": "2405.04333v1",
      "title": "A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Chafetz",
        "Sampriti Saxena",
        "Stefaan G. Verhulst"
      ],
      "abstract": "Since late 2022, generative AI has taken the world by storm, with widespread\nuse of tools including ChatGPT, Gemini, and Claude. Generative AI and large\nlanguage model (LLM) applications are transforming how individuals find and\naccess data and knowledge. However, the intricate relationship between open\ndata and generative AI, and the vast potential it holds for driving innovation\nin this field remain underexplored areas. This white paper seeks to unpack the\nrelationship between open data and generative AI and explore possible\ncomponents of a new Fourth Wave of Open Data: Is open data becoming AI ready?\nIs open data moving towards a data commons approach? Is generative AI making\nopen data more conversational? Will generative AI improve open data quality and\nprovenance? Towards this end, we provide a new Spectrum of Scenarios framework.\nThis framework outlines a range of scenarios in which open data and generative\nAI could intersect and what is required from a data quality and provenance\nperspective to make open data ready for those specific scenarios. These\nscenarios include: pertaining, adaptation, inference and insight generation,\ndata augmentation, and open-ended exploration. Through this process, we found\nthat in order for data holders to embrace generative AI to improve open data\naccess and develop greater insights from open data, they first must make\nprogress around five key areas: enhance transparency and documentation, uphold\nquality and integrity, promote interoperability and standards, improve\naccessibility and useability, and address ethical considerations.",
      "tldr_zh": "这篇白皮书探讨了开放数据和 generative AI 的关系，分析 generative AI（如 ChatGPT）是否会引发第四波开放数据浪潮。作者提出了 Spectrum of Scenarios 框架，该框架概述了开放数据与 generative AI 相交的多种场景，包括训练、适应、推理洞察生成、数据增强和开放探索，并强调了数据质量和来源的重要性。框架要求数据持有者改进五个关键领域：提升透明度和文档、维护质量和完整性、促进互操作性和标准、改善可访问性和可用性，以及处理伦理考虑。通过这些努力，开放数据可以更好地支持 generative AI 的创新应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "58 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.04333v1",
      "published_date": "2024-05-07 14:01:33 UTC",
      "updated_date": "2024-05-07 14:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:40:31.091800"
    },
    {
      "arxiv_id": "2405.04324v1",
      "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Mayank Mishra",
        "Matt Stallone",
        "Gaoyuan Zhang",
        "Yikang Shen",
        "Aditya Prasad",
        "Adriana Meza Soria",
        "Michele Merler",
        "Parameswaran Selvam",
        "Saptha Surendran",
        "Shivdeep Singh",
        "Manish Sethi",
        "Xuan-Hong Dang",
        "Pengyuan Li",
        "Kun-Lung Wu",
        "Syed Zawad",
        "Andrew Coleman",
        "Matthew White",
        "Mark Lewis",
        "Raju Pavuluri",
        "Yan Koyfman",
        "Boris Lublinsky",
        "Maximilien de Bayser",
        "Ibrahim Abdelaziz",
        "Kinjal Basu",
        "Mayank Agarwal",
        "Yi Zhou",
        "Chris Johnson",
        "Aanchal Goyal",
        "Hima Patel",
        "Yousaf Shah",
        "Petros Zerfos",
        "Heiko Ludwig",
        "Asim Munawar",
        "Maxwell Crouse",
        "Pavan Kapanipathi",
        "Shweta Salaria",
        "Bob Calio",
        "Sophia Wen",
        "Seetharami Seelam",
        "Brian Belgodere",
        "Carlos Fonseca",
        "Amith Singhee",
        "Nirmit Desai",
        "David D. Cox",
        "Ruchir Puri",
        "Rameswar Panda"
      ],
      "abstract": "Large Language Models (LLMs) trained on code are revolutionizing the software\ndevelopment process. Increasingly, code LLMs are being integrated into software\ndevelopment environments to improve the productivity of human programmers, and\nLLM-based agents are beginning to show promise for handling complex tasks\nautonomously. Realizing the full potential of code LLMs requires a wide range\nof capabilities, including code generation, fixing bugs, explaining and\ndocumenting code, maintaining repositories, and more. In this work, we\nintroduce the Granite series of decoder-only code models for code generative\ntasks, trained with code written in 116 programming languages. The Granite Code\nmodels family consists of models ranging in size from 3 to 34 billion\nparameters, suitable for applications ranging from complex application\nmodernization tasks to on-device memory-constrained use cases. Evaluation on a\ncomprehensive set of tasks demonstrates that Granite Code models consistently\nreaches state-of-the-art performance among available open-source code LLMs. The\nGranite Code model family was optimized for enterprise software development\nworkflows and performs well across a range of coding tasks (e.g. code\ngeneration, fixing and explanation), making it a versatile all around code\nmodel. We release all our Granite Code models under an Apache 2.0 license for\nboth research and commercial use.",
      "tldr_zh": "该研究介绍了Granite Code Models系列的开源基础模型，旨在提升代码智能领域的大语言模型(LLMs)能力，包括代码生成、修复、解释和仓库维护等任务。这些模型采用decoder-only架构，训练于116种编程语言的代码数据，模型参数从3亿到34亿不等，适用于从复杂应用现代化到设备内存限制的各种场景。评估结果显示，Granite Code Models在多项代码任务上超越现有开源LLMs，并在企业软件开发流程中表现出色，所有模型以Apache 2.0许可免费发布用于研究和商业用途。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Corresponding Authors: Rameswar Panda, Ruchir Puri; Equal\n  Contributors: Mayank Mishra, Matt Stallone, Gaoyuan Zhang",
      "pdf_url": "http://arxiv.org/pdf/2405.04324v1",
      "published_date": "2024-05-07 13:50:40 UTC",
      "updated_date": "2024-05-07 13:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:40:39.440073"
    },
    {
      "arxiv_id": "2405.04323v1",
      "title": "Beyond human subjectivity and error: a novel AI grading system",
      "title_zh": "超越人类的主观性和错误：一种新型AI评分系统",
      "authors": [
        "Alexandra Gobrecht",
        "Felix Tuma",
        "Moritz Möller",
        "Thomas Zöller",
        "Mark Zakhvatkin",
        "Alexandra Wuttig",
        "Holger Sommerfeldt",
        "Sven Schütt"
      ],
      "abstract": "The grading of open-ended questions is a high-effort, high-impact task in\neducation. Automating this task promises a significant reduction in workload\nfor education professionals, as well as more consistent grading outcomes for\nstudents, by circumventing human subjectivity and error. While recent\nbreakthroughs in AI technology might facilitate such automation, this has not\nbeen demonstrated at scale. It this paper, we introduce a novel automatic short\nanswer grading (ASAG) system. The system is based on a fine-tuned open-source\ntransformer model which we trained on large set of exam data from university\ncourses across a large range of disciplines. We evaluated the trained model's\nperformance against held-out test data in a first experiment and found high\naccuracy levels across a broad spectrum of unseen questions, even in unseen\ncourses. We further compared the performance of our model with that of\ncertified human domain experts in a second experiment: we first assembled\nanother test dataset from real historical exams - the historic grades contained\nin that data were awarded to students in a regulated, legally binding\nexamination process; we therefore considered them as ground truth for our\nexperiment. We then asked certified human domain experts and our model to grade\nthe historic student answers again without disclosing the historic grades.\nFinally, we compared the hence obtained grades with the historic grades (our\nground truth). We found that for the courses examined, the model deviated less\nfrom the official historic grades than the human re-graders - the model's\nmedian absolute error was 44 % smaller than the human re-graders', implying\nthat the model is more consistent than humans in grading. These results suggest\nthat leveraging AI enhanced grading can reduce human subjectivity, improve\nconsistency and thus ultimately increase fairness.",
      "tldr_zh": "本论文提出了一种新型AI自动短答案评分（ASAG）系统，利用微调的开源Transformer模型，基于大学课程的大量考试数据进行训练，以减少人类主观性和错误带来的评分不一致。实验结果显示，该模型在未见问题和课程的测试数据上表现出高准确率，并在与人类专家的比较中，其评分与历史官方评分更接近，绝对误差中位数比人类重新评分者小44%。这些发现表明，AI评分系统能提升评分的一致性和公平性，从而减轻教育工作者的负担。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04323v1",
      "published_date": "2024-05-07 13:49:59 UTC",
      "updated_date": "2024-05-07 13:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:40:50.657865"
    },
    {
      "arxiv_id": "2405.04311v1",
      "title": "Cross-IQA: Unsupervised Learning for Image Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Zhang"
      ],
      "abstract": "Automatic perception of image quality is a challenging problem that impacts\nbillions of Internet and social media users daily. To advance research in this\nfield, we propose a no-reference image quality assessment (NR-IQA) method\ntermed Cross-IQA based on vision transformer(ViT) model. The proposed Cross-IQA\nmethod can learn image quality features from unlabeled image data. We construct\nthe pretext task of synthesized image reconstruction to unsupervised extract\nthe image quality information based ViT block. The pretrained encoder of\nCross-IQA is used to fine-tune a linear regression model for score prediction.\nExperimental results show that Cross-IQA can achieve state-of-the-art\nperformance in assessing the low-frequency degradation information (e.g., color\nchange, blurring, etc.) of images compared with the classical full-reference\nIQA and NR-IQA under the same datasets.",
      "tldr_zh": "本研究提出了一种无参考图像质量评估（NR-IQA）方法，名为 Cross-IQA，基于视觉Transformer (ViT) 模型，用于从无标签图像数据中无监督学习图像质量特征。具体而言，该方法通过构建合成图像重建的预训练任务，利用 ViT 块提取质量信息，并微调线性回归模型进行分数预测。实验结果显示，Cross-IQA 在评估图像的低频退化信息（如颜色变化和模糊）方面，超过了经典的全参考 IQA 和 NR-IQA 方法，在相同数据集上实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04311v1",
      "published_date": "2024-05-07 13:35:51 UTC",
      "updated_date": "2024-05-07 13:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:41:03.173197"
    },
    {
      "arxiv_id": "2405.04309v3",
      "title": "Non-rigid Structure-from-Motion: Temporally-smooth Procrustean Alignment and Spatially-variant Deformation Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Shi",
        "Hui Deng",
        "Yuchao Dai"
      ],
      "abstract": "Even though Non-rigid Structure-from-Motion (NRSfM) has been extensively\nstudied and great progress has been made, there are still key challenges that\nhinder their broad real-world applications: 1) the inherent motion/rotation\nambiguity requires either explicit camera motion recovery with extra constraint\nor complex Procrustean Alignment; 2) existing low-rank modeling of the global\nshape can over-penalize drastic deformations in the 3D shape sequence. This\npaper proposes to resolve the above issues from a spatial-temporal modeling\nperspective. First, we propose a novel Temporally-smooth Procrustean Alignment\nmodule that estimates 3D deforming shapes and adjusts the camera motion by\naligning the 3D shape sequence consecutively. Our new alignment module remedies\nthe requirement of complex reference 3D shape during alignment, which is more\nconductive to non-isotropic deformation modeling. Second, we propose a\nspatial-weighted approach to enforce the low-rank constraint adaptively at\ndifferent locations to accommodate drastic spatially-variant deformation\nreconstruction better. Our modeling outperform existing low-rank based methods,\nand extensive experiments across different datasets validate the effectiveness\nof our method.",
      "tldr_zh": "本论文针对 Non-rigid Structure-from-Motion (NRSfM) 的关键挑战，包括运动/旋转模糊和现有低秩建模对剧烈变形的过度惩罚，提出从空间-时间建模角度的解决方案。论文引入 Temporally-smooth Procrustean Alignment 模块，通过连续对齐 3D 形状序列来估计变形形状并调整相机运动，避免了复杂参考形状的需求，从而更适合非各向同性变形建模。同时，论文采用空间加权方法，自适应地在不同位置强制低秩约束，以更好地处理剧烈空间变异变形。实验结果显示，该方法在多个数据集上优于现有低秩方法，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024; The new version adds additional experiments\n  and corrects typos",
      "pdf_url": "http://arxiv.org/pdf/2405.04309v3",
      "published_date": "2024-05-07 13:33:50 UTC",
      "updated_date": "2025-03-04 08:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:41:16.544894"
    },
    {
      "arxiv_id": "2405.04307v1",
      "title": "Improving Offline Reinforcement Learning with Inaccurate Simulators",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Hou",
        "Haoyuan Sun",
        "Jinming Ma",
        "Feng Wu"
      ],
      "abstract": "Offline reinforcement learning (RL) provides a promising approach to avoid\ncostly online interaction with the real environment. However, the performance\nof offline RL highly depends on the quality of the datasets, which may cause\nextrapolation error in the learning process. In many robotic applications, an\ninaccurate simulator is often available. However, the data directly collected\nfrom the inaccurate simulator cannot be directly used in offline RL due to the\nwell-known exploration-exploitation dilemma and the dynamic gap between\ninaccurate simulation and the real environment. To address these issues, we\npropose a novel approach to combine the offline dataset and the inaccurate\nsimulation data in a better manner. Specifically, we pre-train a generative\nadversarial network (GAN) model to fit the state distribution of the offline\ndataset. Given this, we collect data from the inaccurate simulator starting\nfrom the distribution provided by the generator and reweight the simulated data\nusing the discriminator. Our experimental results in the D4RL benchmark and a\nreal-world manipulation task confirm that our method can benefit more from both\ninaccurate simulator and limited offline datasets to achieve better performance\nthan the state-of-the-art methods.",
      "tldr_zh": "该研究针对离线强化学习（Offline RL）的性能依赖于数据集质量的问题，提出了一种新方法来整合不准确模拟器数据，以缓解外推错误和动态差距。方法包括预训练一个生成对抗网络（GAN）模型来拟合离线数据集的状态分布，然后从模拟器中收集数据，并使用GAN的判别器对模拟数据进行重新加权。实验结果显示，该方法在D4RL基准测试和真实世界操作任务中，比现有最先进方法取得了更好的性能，充分利用了不准确模拟器和有限的离线数据集。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04307v1",
      "published_date": "2024-05-07 13:29:41 UTC",
      "updated_date": "2024-05-07 13:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:41:27.173162"
    },
    {
      "arxiv_id": "2405.04305v1",
      "title": "A New Dataset and Comparative Study for Aphid Cluster Detection and Segmentation in Sorghum Fields",
      "title_zh": "一种新的数据集及高粱田中蚜虫集群检测与分割的比较研究",
      "authors": [
        "Raiyan Rahman",
        "Christopher Indris",
        "Goetz Bramesfeld",
        "Tianxiao Zhang",
        "Kaidong Li",
        "Xiangyu Chen",
        "Ivan Grijalva",
        "Brian McCornack",
        "Daniel Flippo",
        "Ajay Sharda",
        "Guanghui Wang"
      ],
      "abstract": "Aphid infestations are one of the primary causes of extensive damage to wheat\nand sorghum fields and are one of the most common vectors for plant viruses,\nresulting in significant agricultural yield losses. To address this problem,\nfarmers often employ the inefficient use of harmful chemical pesticides that\nhave negative health and environmental impacts. As a result, a large amount of\npesticide is wasted on areas without significant pest infestation. This brings\nto attention the urgent need for an intelligent autonomous system that can\nlocate and spray sufficiently large infestations selectively within the complex\ncrop canopies. We have developed a large multi-scale dataset for aphid cluster\ndetection and segmentation, collected from actual sorghum fields and\nmeticulously annotated to include clusters of aphids. Our dataset comprises a\ntotal of 54,742 image patches, showcasing a variety of viewpoints, diverse\nlighting conditions, and multiple scales, highlighting its effectiveness for\nreal-world applications. In this study, we trained and evaluated four real-time\nsemantic segmentation models and three object detection models specifically for\naphid cluster segmentation and detection. Considering the balance between\naccuracy and efficiency, Fast-SCNN delivered the most effective segmentation\nresults, achieving 80.46% mean precision, 81.21% mean recall, and 91.66 frames\nper second (FPS). For object detection, RT-DETR exhibited the best overall\nperformance with a 61.63% mean average precision (mAP), 92.6% mean recall, and\n72.55 on an NVIDIA V100 GPU. Our experiments further indicate that aphid\ncluster segmentation is more suitable for assessing aphid infestations than\nusing detection models.",
      "tldr_zh": "本研究针对蚜虫侵扰导致的高粱田作物损失和过度农药使用问题，开发了一个大型多尺度数据集，共54,742张图像补丁，涵盖实际田间视角、多样照明条件和蚜虫集群标注，以支持蚜虫检测和分割任务。研究比较了四种实时语义分割模型（如Fast-SCNN）和三种物体检测模型（如RT-DETR），评估其在蚜虫集群识别中的性能。结果显示，Fast-SCNN在分割方面表现出色，达到80.46% mean precision、81.21% mean recall和91.66 FPS，而RT-DETR在检测方面最佳，获得61.63% mAP和92.6% mean recall。实验结论表明，语义分割模型更适合评估蚜虫侵扰，提供更精确的农业智能解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04305v1",
      "published_date": "2024-05-07 13:27:58 UTC",
      "updated_date": "2024-05-07 13:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:41:40.782928"
    },
    {
      "arxiv_id": "2405.04300v1",
      "title": "Behaviour Planning: A Toolkit for Diverse Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa F Abdelwahed",
        "Joan Espasa",
        "Alice Toniolo",
        "Ian P. Gent"
      ],
      "abstract": "Diverse planning is the problem of generating plans with distinct\ncharacteristics. This is valuable for many real-world scenarios, including\napplications related to plan recognition and business process automation. In\nthis work, we introduce \\emph{Behaviour Planning}, a diverse planning toolkit\nthat can characterise and generate diverse plans based on modular diversity\nmodels. We present a qualitative framework for describing diversity models, a\nplanning approach for generating plans aligned with any given diversity model,\nand provide a practical implementation of an SMT-based behaviour planner. We\nshowcase how the qualitative approach offered by Behaviour Planning allows it\nto overcome various challenges faced by previous approaches. Finally, the\nexperimental evaluation shows the effectiveness of Behaviour Planning in\ngenerating diverse plans compared to state-of-the-art approaches.",
      "tldr_zh": "本论文提出 Behaviour Planning，这是一个用于多样性规划的工具包，旨在生成具有不同特征的计划，以支持计划识别和业务流程自动化等应用。工具包基于模块化的多样性模型，提供了一个定性框架、一种生成计划的方法，以及一个基于 SMT-based behaviour planner 的实际实现。该方法克服了现有方法的各种挑战，并在实验评估中证明了其在生成多样计划方面的优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04300v1",
      "published_date": "2024-05-07 13:18:22 UTC",
      "updated_date": "2024-05-07 13:18:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:41:52.198749"
    },
    {
      "arxiv_id": "2405.04294v1",
      "title": "Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework",
      "title_zh": "提升结构性金融中底层资产审查",
      "authors": [
        "Xiangpeng Wan",
        "Haicheng Deng",
        "Kai Zou",
        "Shiqi Xu"
      ],
      "abstract": "Structured finance, which involves restructuring diverse assets into\nsecurities like MBS, ABS, and CDOs, enhances capital market efficiency but\npresents significant due diligence challenges. This study explores the\nintegration of artificial intelligence (AI) with traditional asset review\nprocesses to improve efficiency and accuracy in structured finance. Using both\nopen-sourced and close-sourced large language models (LLMs), we demonstrate\nthat AI can automate the verification of information between loan applications\nand bank statements effectively. While close-sourced models such as GPT-4 show\nsuperior performance, open-sourced models like LLAMA3 offer a cost-effective\nalternative. Dual-agent systems further increase accuracy, though this comes\nwith higher operational costs. This research highlights AI's potential to\nminimize manual errors and streamline due diligence, suggesting a broader\napplication of AI in financial document analysis and risk management.",
      "tldr_zh": "这篇论文探讨了在结构化金融（如 MBS、ABS 和 CDO）中，使用 Multi-agent Framework 结合人工智能（AI）来提升底层资产审查的效率和准确性。研究通过开源和闭源 LLMs（如 LLAMA3 和 GPT-4）自动化贷款申请与银行对账单的信息验证，证明了 AI 在减少手动错误和优化尽职调查方面的潜力。结果显示，GPT-4 表现出色，而 LLAMA3 作为成本效益更高的替代方案；引入双智能体系统进一步提高了准确性，但也带来了更高的运营成本。该框架为 AI 在金融文档分析和风险管理中的 broader application 提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04294v1",
      "published_date": "2024-05-07 13:09:49 UTC",
      "updated_date": "2024-05-07 13:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:42:05.371486"
    },
    {
      "arxiv_id": "2405.04292v1",
      "title": "Mitigating Clickbait: An Approach to Spoiler Generation Using Multitask Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sayantan Pal",
        "Souvik Das",
        "Rohini K. Srihari"
      ],
      "abstract": "This study introduces 'clickbait spoiling', a novel technique designed to\ndetect, categorize, and generate spoilers as succinct text responses,\ncountering the curiosity induced by clickbait content. By leveraging a\nmulti-task learning framework, our model's generalization capabilities are\nsignificantly enhanced, effectively addressing the pervasive issue of\nclickbait. The crux of our research lies in generating appropriate spoilers, be\nit a phrase, an extended passage, or multiple, depending on the spoiler type\nrequired. Our methodology integrates two crucial techniques: a refined spoiler\ncategorization method and a modified version of the Question Answering (QA)\nmechanism, incorporated within a multi-task learning paradigm for optimized\nspoiler extraction from context. Notably, we have included fine-tuning methods\nfor models capable of handling longer sequences to accommodate the generation\nof extended spoilers. This research highlights the potential of sophisticated\ntext processing techniques in tackling the omnipresent issue of clickbait,\npromising an enhanced user experience in the digital realm.",
      "tldr_zh": "这篇论文提出了“clickbait spoiling”技术，使用多任务学习框架来检测、分类和生成简洁文本spoiler，以缓解点击诱饵对用户的好奇心。方法整合了改进的spoiler分类机制和修改的Question Answering (QA)机制，实现从上下文中优化spoiler提取，并通过微调长序列模型支持生成扩展spoiler。研究结果表明，该框架显著提升了模型的泛化能力，并展示了高级文本处理技术在提升数字用户体验方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in ICON 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.04292v1",
      "published_date": "2024-05-07 13:09:25 UTC",
      "updated_date": "2024-05-07 13:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:42:18.254535"
    },
    {
      "arxiv_id": "2407.01560v1",
      "title": "3DMeshNet: A Three-Dimensional Differential Neural Network for Structured Mesh Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Peng",
        "Xinhai Chen",
        "Jie Liu"
      ],
      "abstract": "Mesh generation is a crucial step in numerical simulations, significantly\nimpacting simulation accuracy and efficiency. However, generating meshes\nremains time-consuming and requires expensive computational resources. In this\npaper, we propose a novel method, 3DMeshNet, for three-dimensional structured\nmesh generation. The method embeds the meshing-related differential equations\ninto the loss function of neural networks, formulating the meshing task as an\nunsupervised optimization problem. It takes geometric points as input to learn\nthe potential mapping between parametric and computational domains. After\nsuitable offline training, 3DMeshNet can efficiently output a three-dimensional\nstructured mesh with a user-defined number of quadrilateral/hexahedral cells\nthrough the feed-forward neural prediction. To enhance training stability and\naccelerate convergence, we integrate loss function reweighting through weight\nadjustments and gradient projection alongside applying finite difference\nmethods to streamline derivative computations in the loss. Experiments on\ndifferent cases show that 3DMeshNet is robust and fast. It outperforms neural\nnetwork-based methods and yields superior meshes compared to traditional mesh\npartitioning methods. 3DMeshNet significantly reduces training times by up to\n85% compared to other neural network-based approaches and lowers meshing\noverhead by 4 to 8 times relative to traditional meshing methods.",
      "tldr_zh": "本研究提出了一种新型方法 3DMeshNet，用于三维结构化网格生成，以解决传统网格生成耗时且计算资源密集的问题。该方法将网格相关的微分方程嵌入神经网络的损失函数，将任务转化为无监督优化问题，并通过输入几何点学习参数域和计算域之间的潜在映射；同时，采用损失函数加权、梯度投影和有限差分方法来提升训练稳定性和收敛速度。实验结果表明，3DMeshNet 比其他神经网络方法训练时间减少高达 85%，网格生成开销较传统方法降低 4 到 8 倍，并产生更高质量的网格，在鲁棒性和效率上表现出色。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01560v1",
      "published_date": "2024-05-07 13:07:07 UTC",
      "updated_date": "2024-05-07 13:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:42:31.583774"
    },
    {
      "arxiv_id": "2405.04285v1",
      "title": "On the Foundations of Earth and Climate Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Xiang Zhu",
        "Zhitong Xiong",
        "Yi Wang",
        "Adam J. Stewart",
        "Konrad Heidler",
        "Yuanyuan Wang",
        "Zhenghang Yuan",
        "Thomas Dujardin",
        "Qingsong Xu",
        "Yilei Shi"
      ],
      "abstract": "Foundation models have enormous potential in advancing Earth and climate\nsciences, however, current approaches may not be optimal as they focus on a few\nbasic features of a desirable Earth and climate foundation model. Crafting the\nideal Earth foundation model, we define eleven features which would allow such\na foundation model to be beneficial for any geoscientific downstream\napplication in an environmental- and human-centric manner.We further shed light\non the way forward to achieve the ideal model and to evaluate Earth foundation\nmodels. What comes after foundation models? Energy efficient adaptation,\nadversarial defenses, and interpretability are among the emerging directions.",
      "tldr_zh": "该论文探讨了基础模型（Foundation models）在地球和气候科学中的基础潜力，指出当前方法过于注重少数基本特征，可能无法优化应用。作者定义了11个关键特征，用于构建理想的地球基础模型（Earth foundation model），以环境和人类为中心，支持各种地球科学下游任务。论文还提出实现和评估该模型的路径，以及未来方向，如能量高效适应、对抗防御和可解释性，以推动该领域的进步。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04285v1",
      "published_date": "2024-05-07 12:54:54 UTC",
      "updated_date": "2024-05-07 12:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:42:41.425283"
    },
    {
      "arxiv_id": "2405.04260v2",
      "title": "Verified Neural Compressed Sensing",
      "title_zh": "验证神经压缩感知",
      "authors": [
        "Rudy Bunel",
        "Krishnamurthy Dvijotham",
        "M. Pawan Kumar",
        "Alessandro De Palma",
        "Robert Stanforth"
      ],
      "abstract": "We develop the first (to the best of our knowledge) provably correct neural\nnetworks for a precise computational task, with the proof of correctness\ngenerated by an automated verification algorithm without any human input. Prior\nwork on neural network verification has focused on partial specifications that,\neven when satisfied, are not sufficient to ensure that a neural network never\nmakes errors. We focus on applying neural network verification to computational\ntasks with a precise notion of correctness, where a verifiably correct neural\nnetwork provably solves the task at hand with no caveats. In particular, we\ndevelop an approach to train and verify the first provably correct neural\nnetworks for compressed sensing, i.e., recovering sparse vectors from a number\nof measurements smaller than the dimension of the vector. We show that for\nmodest problem dimensions (up to 50), we can train neural networks that\nprovably recover a sparse vector from linear and binarized linear measurements.\nFurthermore, we show that the complexity of the network (number of\nneurons/layers) can be adapted to the problem difficulty and solve problems\nwhere traditional compressed sensing methods are not known to provably work.",
      "tldr_zh": "本文首次开发了可证明正确的neural networks，用于精确计算任务，通过自动化验证算法自动生成证明，而非依赖人工输入。研究聚焦于compressed sensing，训练神经网络从少于向量维度的线性或二值化线性测量中，准确恢复稀疏向量。实验结果显示，对于维度达50的场景，网络能适应问题难度调整复杂度（如神经元和层数），并在传统compressed sensing方法无法证明有效的情况下实现可靠恢复。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04260v2",
      "published_date": "2024-05-07 12:20:12 UTC",
      "updated_date": "2024-05-08 09:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:42:54.070719"
    },
    {
      "arxiv_id": "2405.04252v1",
      "title": "VAEneu: A New Avenue for VAE Application on Probabilistic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Koochali",
        "Ensiye Tahaei",
        "Andreas Dengel",
        "Sheraz Ahmed"
      ],
      "abstract": "This paper presents VAEneu, an innovative autoregressive method for multistep\nahead univariate probabilistic time series forecasting. We employ the\nconditional VAE framework and optimize the lower bound of the predictive\ndistribution likelihood function by adopting the Continuous Ranked Probability\nScore (CRPS), a strictly proper scoring rule, as the loss function. This novel\npipeline results in forecasting sharp and well-calibrated predictive\ndistribution. Through a comprehensive empirical study, VAEneu is rigorously\nbenchmarked against 12 baseline models across 12 datasets. The results\nunequivocally demonstrate VAEneu's remarkable forecasting performance. VAEneu\nprovides a valuable tool for quantifying future uncertainties, and our\nextensive empirical study lays the foundation for future comparative studies\nfor univariate multistep ahead probabilistic forecasting.",
      "tldr_zh": "本论文提出 VAEneu，一种创新的自回归方法，用于多步预测的单变量概率时间序列预测。它采用条件 VAE 框架，并通过 Continuous Ranked Probability Score (CRPS) 作为损失函数来优化预测分布的似然下界，从而生成更尖锐且校准良好的预测分布。在全面实证研究中，VAEneu 在 12 个数据集上与 12 个基线模型比较，展现出显著的预测性能，并为量化未来不确定性提供了一个宝贵工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04252v1",
      "published_date": "2024-05-07 12:13:11 UTC",
      "updated_date": "2024-05-07 12:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:43:06.744683"
    },
    {
      "arxiv_id": "2405.04249v2",
      "title": "Federated Learning for Collaborative Inference Systems: The Case of Early Exit Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Caelin Kaplan",
        "Angelo Rodio",
        "Tareq Si Salem",
        "Chuan Xu",
        "Giovanni Neglia"
      ],
      "abstract": "As Internet of Things (IoT) technology advances, end devices like sensors and\nsmartphones are progressively equipped with AI models tailored to their local\nmemory and computational constraints. Local inference reduces communication\ncosts and latency; however, these smaller models typically underperform\ncompared to more sophisticated models deployed on edge servers or in the cloud.\nCooperative Inference Systems (CISs) address this performance trade-off by\nenabling smaller devices to offload part of their inference tasks to more\ncapable devices. These systems often deploy hierarchical models that share\nnumerous parameters, exemplified by Deep Neural Networks (DNNs) that utilize\nstrategies like early exits or ordered dropout. In such instances, Federated\nLearning (FL) may be employed to jointly train the models within a CIS. Yet,\ntraditional training methods have overlooked the operational dynamics of CISs\nduring inference, particularly the potential high heterogeneity in serving\nrates across clients. To address this gap, we propose a novel FL approach\ndesigned explicitly for use in CISs that accounts for these variations in\nserving rates. Our framework not only offers rigorous theoretical guarantees,\nbut also surpasses state-of-the-art (SOTA) training algorithms for CISs,\nespecially in scenarios where inference request rates or data availability are\nuneven among clients.",
      "tldr_zh": "本研究探讨了在合作推理系统（CISs）中应用联邦学习（Federated Learning, FL），特别针对 Early Exit Networks 的场景。传统 FL 方法忽略了客户端服务速率的异质性，导致在 IoT 设备间任务卸载时性能不足。为解决这一问题，作者提出了一种新型 FL 框架，该框架考虑了客户端间推理请求率和数据可用性的不均匀性，并提供了严格的理论保证。实验结果显示，该框架在不均匀场景下超越了现有最先进（SOTA）算法，提升了 CISs 的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04249v2",
      "published_date": "2024-05-07 12:07:06 UTC",
      "updated_date": "2024-08-21 09:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:43:17.594177"
    },
    {
      "arxiv_id": "2405.04245v2",
      "title": "Exploring Correlations of Self-Supervised Tasks for Graphs",
      "title_zh": "探索图自监督任务的相关性",
      "authors": [
        "Taoran Fang",
        "Wei Zhou",
        "Yifei Sun",
        "Kaiqiao Han",
        "Lvbin Ma",
        "Yang Yang"
      ],
      "abstract": "Graph self-supervised learning has sparked a research surge in training\ninformative representations without accessing any labeled data. However, our\nunderstanding of graph self-supervised learning remains limited, and the\ninherent relationships between various self-supervised tasks are still\nunexplored. Our paper aims to provide a fresh understanding of graph\nself-supervised learning based on task correlations. Specifically, we evaluate\nthe performance of the representations trained by one specific task on other\ntasks and define correlation values to quantify task correlations. Through this\nprocess, we unveil the task correlations between various self-supervised tasks\nand can measure their expressive capabilities, which are closely related to\ndownstream performance. By analyzing the correlation values between tasks\nacross various datasets, we reveal the complexity of task correlations and the\nlimitations of existing multi-task learning methods. To obtain more capable\nrepresentations, we propose Graph Task Correlation Modeling (GraphTCM) to\nillustrate the task correlations and utilize it to enhance graph\nself-supervised training. The experimental results indicate that our method\nsignificantly outperforms existing methods across various downstream tasks.",
      "tldr_zh": "本文探讨了图自监督学习（Graph self-supervised learning）中各种自监督任务之间的相关性，通过评估一个任务训练的表示在其他任务上的性能，并定义相关性值来量化这些关系。研究发现，任务相关性存在复杂性，且现有多任务学习（multi-task learning）方法有显著局限，因此提出Graph Task Correlation Modeling (GraphTCM)框架来建模任务相关性并增强自监督训练。实验结果显示，该方法在多种下游任务上显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2405.04245v2",
      "published_date": "2024-05-07 12:02:23 UTC",
      "updated_date": "2024-05-16 06:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:43:30.187831"
    },
    {
      "arxiv_id": "2405.04241v1",
      "title": "Exploring the Potential of Robot-Collected Data for Training Gesture Classification Systems",
      "title_zh": "探索机器人收集数据用于训练手势分类系统的潜力",
      "authors": [
        "Alejandro Garcia-Sosa",
        "Jose J. Quintana-Hernandez",
        "Miguel A. Ferrer Ballester",
        "Cristina Carmona-Duarte"
      ],
      "abstract": "Sensors and Artificial Intelligence (AI) have revolutionized the analysis of\nhuman movement, but the scarcity of specific samples presents a significant\nchallenge in training intelligent systems, particularly in the context of\ndiagnosing neurodegenerative diseases. This study investigates the feasibility\nof utilizing robot-collected data to train classification systems traditionally\ntrained with human-collected data. As a proof of concept, we recorded a\ndatabase of numeric characters using an ABB robotic arm and an Apple Watch. We\ncompare the classification performance of the trained systems using both\nhuman-recorded and robot-recorded data. Our primary objective is to determine\nthe potential for accurate identification of human numeric characters wearing a\nsmartwatch using robotic movement as training data. The findings of this study\noffer valuable insights into the feasibility of using robot-collected data for\ntraining classification systems. This research holds broad implications across\nvarious domains that require reliable identification, particularly in scenarios\nwhere access to human-specific data is limited.",
      "tldr_zh": "本研究探讨了使用机器人收集数据训练手势分类系统的潜力，以解决人类运动数据稀缺性对诊断神经退行性疾病等应用的挑战。研究者使用 ABB robotic arm 和 Apple Watch 记录了一个数字字符数据库，并比较了基于人类记录数据和机器人记录数据训练的系统分类性能。结果显示，机器人-collected data 可实现准确识别人类手势，为数据有限场景下的可靠识别提供重要见解，具有广泛的应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04241v1",
      "published_date": "2024-05-07 11:58:34 UTC",
      "updated_date": "2024-05-07 11:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:43:41.872813"
    },
    {
      "arxiv_id": "2501.03230v1",
      "title": "Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Fei",
        "Shengqiong Wu",
        "Wei Ji",
        "Hanwang Zhang",
        "Meishan Zhang",
        "Mong-Li Lee",
        "Wynne Hsu"
      ],
      "abstract": "Existing research of video understanding still struggles to achieve in-depth\ncomprehension and reasoning in complex videos, primarily due to the\nunder-exploration of two key bottlenecks: fine-grained spatial-temporal\nperceptive understanding and cognitive-level video scene comprehension. This\npaper bridges the gap by presenting a novel solution. We first introduce a\nnovel video Multimodal Large Language Model (MLLM), MotionEpic, which achieves\nfine-grained pixel-level spatial-temporal video grounding by integrating video\nspatial-temporal scene graph (STSG) representation. Building upon MotionEpic,\nwe then develop a Video-of-Thought (VoT) reasoning framework. VoT inherits the\nChain-of-Thought (CoT) core, breaking down a complex task into simpler and\nmanageable sub-problems, and addressing them step-by-step from a low-level\npixel perception to high-level cognitive interpretation. Extensive experiments\nacross various complex video QA benchmarks demonstrate that our overall\nframework strikingly boosts existing state-of-the-art. To our knowledge, this\nis the first attempt at successfully implementing the CoT technique for\nachieving human-level video reasoning, where we show great potential in\nextending it to a wider range of video understanding scenarios. Project is open\nat https://haofei.vip/VoT",
      "tldr_zh": "本文提出了一种新颖的视频理解框架，以解决现有研究在复杂视频中的细粒度时空感知理解和认知级场景理解瓶颈。首先，引入 MotionEpic，一个整合 spatial-temporal scene graph (STSG) 的视频 Multimodal Large Language Model (MLLM)，实现像素级时空视频 grounding。然后，基于 MotionEpic 开发 Video-of-Thought (VoT) 推理框架，该框架继承 Chain-of-Thought (CoT) 的核心，将复杂任务分解为子问题，从低级像素感知逐步到高级认知解释。实验在各种视频 QA 基准上显示，该框架显著提升了现有最先进水平，并首次实现了人类水平的视频推理，具有扩展到更广泛场景的潜力。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.03230v1",
      "published_date": "2024-05-07 11:55:10 UTC",
      "updated_date": "2024-05-07 11:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:43:55.469904"
    },
    {
      "arxiv_id": "2405.04230v3",
      "title": "Unveiling the optimization process of Physics Informed Neural Networks: How accurate and competitive can PINNs be?",
      "title_zh": "揭示 Physics Informed Neural Networks 的优化过程：PINNs 能有多准确和竞争性？",
      "authors": [
        "Jorge F. Urbán",
        "Petros Stefanou",
        "José A. Pons"
      ],
      "abstract": "This study investigates the potential accuracy boundaries of physics-informed\nneural networks, contrasting their approach with previous similar works and\ntraditional numerical methods. We find that selecting improved optimization\nalgorithms significantly enhances the accuracy of the results. Simple\nmodifications to the loss function may also improve precision, offering an\nadditional avenue for enhancement. Despite optimization algorithms having a\ngreater impact on convergence than adjustments to the loss function, practical\nconsiderations often favor tweaking the latter due to ease of implementation.\nOn a global scale, the integration of an enhanced optimizer and a marginally\nadjusted loss function enables a reduction in the loss function by several\norders of magnitude across diverse physical problems. Consequently, our results\nobtained using compact networks (typically comprising 2 or 3 layers of 20-30\nneurons) achieve accuracies comparable to finite difference schemes employing\nthousands of grid points. This study encourages the continued advancement of\nPINNs and associated optimization techniques for broader applications across\nvarious fields.",
      "tldr_zh": "这篇论文探讨了Physics Informed Neural Networks (PINNs) 的优化过程，并评估其准确性和与传统数值方法的竞争力。研究发现，选择先进的优化算法能显著提升结果准确性，而对损失函数的简单修改也提供额外改进途径，尽管优化算法对收敛的影响更大。实验结果显示，通过结合增强优化器和微调损失函数，可将损失函数减少几个数量级，使用小型网络（通常2或3层，20-30神经元）即可达到与采用数千网格点的有限差分方案相当的精度。该研究鼓励进一步推进PINNs及其优化技术，以扩展其在各种领域的应用。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "63 pages, 25 figures. This is the author-accepted manuscript of the\n  paper published in Journal of Computational Physics",
      "pdf_url": "http://arxiv.org/pdf/2405.04230v3",
      "published_date": "2024-05-07 11:50:25 UTC",
      "updated_date": "2024-12-13 10:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:44:06.610495"
    },
    {
      "arxiv_id": "2405.04219v1",
      "title": "Iterative Experience Refinement of Software-Developing Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Qian",
        "Jiahao Li",
        "Yufan Dang",
        "Wei Liu",
        "YiFei Wang",
        "Zihao Xie",
        "Weize Chen",
        "Cheng Yang",
        "Yingli Zhang",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Autonomous agents powered by large language models (LLMs) show significant\npotential for achieving high autonomy in various scenarios such as software\ndevelopment. Recent research has shown that LLM agents can leverage past\nexperiences to reduce errors and enhance efficiency. However, the static\nexperience paradigm, reliant on a fixed collection of past experiences acquired\nheuristically, lacks iterative refinement and thus hampers agents'\nadaptability. In this paper, we introduce the Iterative Experience Refinement\nframework, enabling LLM agents to refine experiences iteratively during task\nexecution. We propose two fundamental patterns: the successive pattern,\nrefining based on nearest experiences within a task batch, and the cumulative\npattern, acquiring experiences across all previous task batches. Augmented with\nour heuristic experience elimination, the method prioritizes high-quality and\nfrequently-used experiences, effectively managing the experience space and\nenhancing efficiency. Extensive experiments show that while the successive\npattern may yield superior results, the cumulative pattern provides more stable\nperformance. Moreover, experience elimination facilitates achieving better\nperformance using just 11.54% of a high-quality subset.",
      "tldr_zh": "本研究提出 Iterative Experience Refinement 框架，用于提升基于大型语言模型(LLMs)的软件开发代理的适应性和效率，以解决传统静态经验范式缺乏迭代精炼的问题。该框架包括两种模式：successive pattern（基于任务批次内最近经验进行精炼）和 cumulative pattern（跨所有先前任务批次积累经验），并结合 heuristic experience elimination 机制来优先保留高质和频繁使用的经验，从而优化经验空间管理。实验结果显示，successive pattern 可能带来更优表现，而 cumulative pattern 提供更稳定的性能；此外，通过经验消除，仅使用 11.54% 的高质子集即可实现更好的整体效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2405.04219v1",
      "published_date": "2024-05-07 11:33:49 UTC",
      "updated_date": "2024-05-07 11:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:44:19.003885"
    },
    {
      "arxiv_id": "2405.04215v1",
      "title": "NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot Gestrin",
        "Marco Kuhlmann",
        "Jendrik Seipp"
      ],
      "abstract": "Today's classical planners are powerful, but modeling input tasks in formats\nsuch as PDDL is tedious and error-prone. In contrast, planning with Large\nLanguage Models (LLMs) allows for almost any input text, but offers no\nguarantees on plan quality or even soundness. In an attempt to merge the best\nof these two approaches, some work has begun to use LLMs to automate parts of\nthe PDDL creation process. However, these methods still require various degrees\nof expert input. We present NL2Plan, the first domain-agnostic offline\nLLM-driven planning system. NL2Plan uses an LLM to incrementally extract the\nnecessary information from a short text prompt before creating a complete PDDL\ndescription of both the domain and the problem, which is finally solved by a\nclassical planner. We evaluate NL2Plan on four planning domains and find that\nit solves 10 out of 15 tasks - a clear improvement over a plain\nchain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover,\nin two out of the five failure cases, instead of returning an invalid plan,\nNL2Plan reports that it failed to solve the task. In addition to using NL2Plan\nin end-to-end mode, users can inspect and correct all of its intermediate\nresults, such as the PDDL representation, increasing explainability and making\nit an assistive tool for PDDL creation.",
      "tldr_zh": "这篇论文介绍了NL2Plan，一个鲁棒的LLM驱动规划系统，旨在从简短文本描述中自动生成完整的PDDL（Planning Domain Definition Language）模型，从而解决传统规划器输入繁琐和LLM规划不可靠的问题。NL2Plan使用LLM逐步提取必要信息，构建领域和问题描述，然后交由古典规划器求解。实验结果显示，在四个规划领域中，NL2Plan成功解决了15个任务中的10个，显著优于纯chain-of-thought推理方法（仅解决2个任务），并允许用户检查和修正中间结果，提升了可解释性和作为PDDL创建辅助工具的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for the ICAPS 2024 Workshop on Human-Aware and Explainable\n  Planning",
      "pdf_url": "http://arxiv.org/pdf/2405.04215v1",
      "published_date": "2024-05-07 11:27:13 UTC",
      "updated_date": "2024-05-07 11:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:44:31.869796"
    },
    {
      "arxiv_id": "2405.04212v1",
      "title": "Green Tsetlin Redefining Efficiency in Tsetlin Machine Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Sondre Glimsdal",
        "Sebastian Østby",
        "Tobias M. Brambo",
        "Eirik M. Vinje"
      ],
      "abstract": "Green Tsetlin (GT) is a Tsetlin Machine (TM) framework developed to solve\nreal-world problems using TMs. Several frameworks already exist that provide\naccess to TM implementations. However, these either lack features or have a\nresearch-first focus. GT is an easy-to-use framework that aims to lower the\ncomplexity and provide a production-ready TM implementation that is great for\nexperienced practitioners and beginners. To this end, GT establishes a clear\nseparation between training and inference. A C++ backend with a Python\ninterface provides competitive training and inference performance, with the\noption of running in pure Python. It also integrates support for critical\ncomponents such as exporting trained models, hyper-parameter search, and\ncross-validation out-of-the-box.",
      "tldr_zh": "Green Tsetlin (GT) 是一个新的 Tsetlin Machine (TM) 框架，旨在简化 TM 的实际应用，提供易于使用的生产就绪实现，适合初学者和经验丰富的从业者。\n该框架通过清晰分离训练和推理，使用 C++ 后端结合 Python 接口，实现高效的训练和推理性能，同时支持纯 Python 运行。\nGT 还内置关键功能，如模型导出、超参数搜索和交叉验证，降低了使用复杂性并提升了整体效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04212v1",
      "published_date": "2024-05-07 11:24:56 UTC",
      "updated_date": "2024-05-07 11:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:44:42.885939"
    },
    {
      "arxiv_id": "2405.04206v1",
      "title": "NOVA: NoC-based Vector Unit for Mapping Attention Layers on a CNN Accelerator",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Upadhyay",
        "Rohan Juneja",
        "Weng-Fai Wong",
        "Li-Shiuan Peh"
      ],
      "abstract": "Attention mechanisms are becoming increasingly popular, being used in neural\nnetwork models in multiple domains such as natural language processing (NLP)\nand vision applications, especially at the edge. However, attention layers are\ndifficult to map onto existing neuro accelerators since they have a much higher\ndensity of non-linear operations, which lead to inefficient utilization of\ntoday's vector units. This work introduces NOVA, a NoC-based Vector Unit that\ncan perform non-linear operations within the NoC of the accelerators, and can\nbe overlaid onto existing neuro accelerators to map attention layers at the\nedge. Our results show that the NOVA architecture is up to 37.8x more\npower-efficient than state-of-the-art hardware approximators when running\nexisting attention-based neural networks.",
      "tldr_zh": "该研究针对注意力机制在神经网络（如NLP和视觉应用）中的广泛使用，但现有CNN加速器难以高效映射这些层的问题，提出了NOVA，一种基于NoC的向量单元。NOVA能够在加速器的NoC中执行非线性操作，并与现有神经加速器无缝整合，以支持边缘计算环境下的注意力层映射。实验结果显示，NOVA在运行注意力-based神经网络时，比最先进的硬件近似器节能高达37.8倍，从而提升了整体能效。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "B.2.4"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04206v1",
      "published_date": "2024-05-07 11:20:10 UTC",
      "updated_date": "2024-05-07 11:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:44:55.278141"
    },
    {
      "arxiv_id": "2405.04171v1",
      "title": "FedStale: leveraging stale client updates in federated learning",
      "title_zh": "翻译失败",
      "authors": [
        "Angelo Rodio",
        "Giovanni Neglia"
      ],
      "abstract": "Federated learning algorithms, such as FedAvg, are negatively affected by\ndata heterogeneity and partial client participation. To mitigate the latter\nproblem, global variance reduction methods, like FedVARP, leverage stale model\nupdates for non-participating clients. These methods are effective under\nhomogeneous client participation. Yet, this paper shows that, when some clients\nparticipate much less than others, aggregating updates with different levels of\nstaleness can detrimentally affect the training process. Motivated by this\nobservation, we introduce FedStale, a novel algorithm that updates the global\nmodel in each round through a convex combination of \"fresh\" updates from\nparticipating clients and \"stale\" updates from non-participating ones. By\nadjusting the weight in the convex combination, FedStale interpolates between\nFedAvg, which only uses fresh updates, and FedVARP, which treats fresh and\nstale updates equally. Our analysis of FedStale convergence yields the\nfollowing novel findings: i) it integrates and extends previous FedAvg and\nFedVARP analyses to heterogeneous client participation; ii) it underscores how\nthe least participating client influences convergence error; iii) it provides\npractical guidelines to best exploit stale updates, showing that their\nusefulness diminishes as data heterogeneity decreases and participation\nheterogeneity increases. Extensive experiments featuring diverse levels of\nclient data and participation heterogeneity not only confirm these findings but\nalso show that FedStale outperforms both FedAvg and FedVARP in many settings.",
      "tldr_zh": "这篇论文针对联邦学习中的数据异质性和部分客户端参与问题，提出了FedStale算法，以缓解现有方法如FedAvg和FedVARP的局限。FedStale通过凸组合（convex combination）更新全局模型，将参与客户端的“fresh”更新和非参与客户端的“stale”更新相结合，并通过调整权重在FedAvg（仅用fresh更新）和FedVARP（stale和fresh等同）之间插值。分析结果显示，该算法扩展了FedAvg和FedVARP的收敛分析，突出了参与最少客户端对收敛错误的影响，并提供了实用指导，表明stale更新的价值随数据异质性减少和参与异质性增加而降低。实验在多种异质性场景下验证了这些发现，并证明FedStale在许多设置中优于基准算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 5 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.04171v1",
      "published_date": "2024-05-07 10:11:42 UTC",
      "updated_date": "2024-05-07 10:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:45:08.886764"
    },
    {
      "arxiv_id": "2405.04161v2",
      "title": "Decoding complexity: how machine learning is redefining scientific discovery",
      "title_zh": "解码复杂性：机器学习如何重新定义科学发现",
      "authors": [
        "Ricardo Vinuesa",
        "Paola Cinnella",
        "Jean Rabault",
        "Hossein Azizpour",
        "Stefan Bauer",
        "Bingni W. Brunton",
        "Arne Elofsson",
        "Elias Jarlebring",
        "Hedvig Kjellstrom",
        "Stefano Markidis",
        "David Marlevi",
        "Javier Garcia-Martinez",
        "Steven L. Brunton"
      ],
      "abstract": "As modern scientific instruments generate vast amounts of data and the volume\nof information in the scientific literature continues to grow, machine learning\n(ML) has become an essential tool for organising, analysing, and interpreting\nthese complex datasets. This paper explores the transformative role of ML in\naccelerating breakthroughs across a range of scientific disciplines. By\npresenting key examples -- such as brain mapping and exoplanet detection -- we\ndemonstrate how ML is reshaping scientific research. We also explore different\nscenarios where different levels of knowledge of the underlying phenomenon are\navailable, identifying strategies to overcome limitations and unlock the full\npotential of ML. Despite its advances, the growing reliance on ML poses\nchallenges for research applications and rigorous validation of discoveries. We\nargue that even with these challenges, ML is poised to disrupt traditional\nmethodologies and advance the boundaries of knowledge by enabling researchers\nto tackle increasingly complex problems. Thus, the scientific community can\nmove beyond the necessary traditional oversimplifications to embrace the full\ncomplexity of natural systems, ultimately paving the way for interdisciplinary\nbreakthroughs and innovative solutions to humanity's most pressing challenges.",
      "tldr_zh": "本论文探讨了机器学习（ML）在科学发现中的变革性作用，随着科学仪器产生海量数据和文献信息激增，ML已成为组织、分析和解释复杂数据集的关键工具。通过脑图谱（brain mapping）和外星行星检测（exoplanet detection）等例子，论文展示了ML如何加速跨学科突破，并针对不同知识水平提出策略来克服局限性。尽管ML依赖性带来的验证挑战不可忽视，但论文认为它将颠覆传统方法，推动研究者处理自然系统的复杂性，并促成创新解决方案以应对人类重大挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04161v2",
      "published_date": "2024-05-07 09:58:02 UTC",
      "updated_date": "2025-04-25 14:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:45:18.302016"
    },
    {
      "arxiv_id": "2405.06691v3",
      "title": "Fleet of Agents: Coordinated Problem Solving with Large Language Models",
      "title_zh": "Fleet of Agents：利用大型语言模型的协调问题求解",
      "authors": [
        "Lars Klein",
        "Nearchos Potamitis",
        "Roland Aydin",
        "Robert West",
        "Caglar Gulcehre",
        "Akhil Arora"
      ],
      "abstract": "While numerous frameworks have been developed to enhance the reasoning\nabilities of large language models (LLMs), there is a scarcity of methods that\neffectively balance the trade-off between cost and quality. In this paper, we\nintroduce Fleet of Agents (FoA), a novel and intuitive yet principled framework\nutilizing LLMs as agents to navigate through dynamic tree searches, employing a\ngenetic-type particle filtering approach. FoA spawns a multitude of agents,\neach exploring the search space autonomously, followed by a selection phase\nwhere resampling based on a heuristic value function optimizes the balance\nbetween exploration and exploitation. This mechanism enables dynamic branching,\nadapting the exploration strategy based on discovered solutions. We conduct\nextensive experiments on three benchmark tasks, ``Game of 24'',\n``Mini-Crosswords'', and ``WebShop'', utilizing four different LLMs,\n``GPT-3.5'', ``GPT-4'', ``LLaMA3.2-11B'', and ``LLaMA3.2-90B''. On average\nacross all tasks and LLMs, FoA obtains a quality improvement of ~5% while\nrequiring only ~40% of the cost of previous SOTA methods. Notably, our analyses\nreveal that (1) FoA achieves the best cost-quality trade-off among all\nbenchmarked methods and (2) FoA + LLaMA3.2-11B surpasses the Llama3.2-90B\nmodel. FoA is publicly available at https://github.com/au-clan/FoA.",
      "tldr_zh": "本研究引入了 Fleet of Agents (FoA)，一个利用大型语言模型 (LLMs) 作为代理的框架，通过动态树搜索和遗传型粒子过滤方法来协调问题解决，实现成本与质量的平衡。FoA 机制包括生成多个代理进行自主探索搜索空间，随后通过基于启发式值函数的重采样优化探索与利用的动态调整。在三个基准任务（“Game of 24”、“Mini-Crosswords”和“WebShop”）上，使用 GPT-3.5、GPT-4、LLaMA3.2-11B 和 LLaMA3.2-90B 等四种 LLMs，FoA 平均提高了约 5% 的质量，同时仅需约 40% 的先前最先进方法成本；此外，分析显示 FoA 提供了最佳的成本-质量权衡，且 FoA + LLaMA3.2-11B 超过了 LLaMA3.2-90B 模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025; 28 pages, 68 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.06691v3",
      "published_date": "2024-05-07 09:36:23 UTC",
      "updated_date": "2025-05-10 19:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:45:32.850544"
    },
    {
      "arxiv_id": "2405.04138v1",
      "title": "GPT-Enabled Cybersecurity Training: A Tailored Approach for Effective Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Nabil Al-Dhamari",
        "Nathan Clarke"
      ],
      "abstract": "This study explores the limitations of traditional Cybersecurity Awareness\nand Training (CSAT) programs and proposes an innovative solution using\nGenerative Pre-Trained Transformers (GPT) to address these shortcomings.\nTraditional approaches lack personalization and adaptability to individual\nlearning styles. To overcome these challenges, the study integrates GPT models\nto deliver highly tailored and dynamic cybersecurity learning expe-riences.\nLeveraging natural language processing capabilities, the proposed approach\npersonalizes training modules based on individual trainee pro-files, helping to\nensure engagement and effectiveness. An experiment using a GPT model to provide\na real-time and adaptive CSAT experience through generating customized training\ncontent. The findings have demonstrated a significant improvement over\ntraditional programs, addressing issues of en-gagement, dynamicity, and\nrelevance. GPT-powered CSAT programs offer a scalable and effective solution to\nenhance cybersecurity awareness, provid-ing personalized training content that\nbetter prepares individuals to miti-gate cybersecurity risks in their specific\nroles within the organization.",
      "tldr_zh": "本研究探讨了传统网络安全意识和培训（CSAT）程序的局限性，如缺乏个性化及适应性，并提出一种基于Generative Pre-Trained Transformers (GPT) 的创新解决方案来提升培训效果。方法通过GPT模型的自然语言处理能力，根据个体学习风格和配置文件生成动态、个性化的培训内容，从而提高参与度和相关性。实验结果显示，该方法显著优于传统程序，在提升网络安全意识和风险应对方面取得了更好的效果，提供了一个可扩展的CSAT框架。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04138v1",
      "published_date": "2024-05-07 09:08:00 UTC",
      "updated_date": "2024-05-07 09:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:45:41.546067"
    },
    {
      "arxiv_id": "2405.04136v1",
      "title": "Enriched BERT Embeddings for Scholarly Publication Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Wolff",
        "Eva Seidlmayer",
        "Konrad U. Förstner"
      ],
      "abstract": "With the rapid expansion of academic literature and the proliferation of\npreprints, researchers face growing challenges in manually organizing and\nlabeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses\nthis challenge organized as a competition. The goal is to develop a classifier\ncapable of predicting one of 123 predefined classes from the Open Research\nKnowledge Graph (ORKG) taxonomy of research fields for a given article.This\npaper presents our results. Initially, we enrich the dataset (containing\nEnglish scholarly articles sourced from ORKG and arXiv), then leverage\ndifferent pre-trained language Models (PLMs), specifically BERT, and explore\ntheir efficacy in transfer learning for this downstream task. Our experiments\nencompass feature-based and fine-tuned transfer learning approaches using\ndiverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and\nSPECTER2. We conduct hyperparameter tuning and investigate the impact of data\naugmentation from bibliographic databases such as OpenAlex, Semantic Scholar,\nand Crossref. Our results demonstrate that fine-tuning pre-trained models\nsubstantially enhances classification performance, with SPECTER2 emerging as\nthe most accurate model. Moreover, enriching the dataset with additional\nmetadata improves classification outcomes significantly, especially when\nintegrating information from S2AG, OpenAlex and Crossref. Our best-performing\napproach achieves a weighted F1-score of 0.7415. Overall, our study contributes\nto the advancement of reliable automated systems for scholarly publication\ncategorization, offering a potential solution to the laborious manual curation\nprocess, thereby facilitating researchers in efficiently locating relevant\nresources.",
      "tldr_zh": "这篇论文针对学术文献快速增长带来的分类挑战，提出了一种使用增强BERT嵌入的转移学习方法，针对NSLP 2024 FoRC Shared Task I竞赛中的123个ORKG研究领域类别进行文章分类。作者通过丰富数据集（整合OpenAlex、Semantic Scholar和Crossref的元数据），并fine-tuning多种预训练语言模型（PLMs）如SciBERT、SciNCL和SPECTER2，进行超参数调整和数据增强，显著提高了分类性能。实验结果显示，SPECTER2模型表现出色，weighted F1-score达到0.7415，为可靠的自动学术出版物分类系统提供了高效解决方案，帮助研究者减少手动整理工作。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, NSLP2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2405.04136v1",
      "published_date": "2024-05-07 09:05:20 UTC",
      "updated_date": "2024-05-07 09:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:45:56.878226"
    },
    {
      "arxiv_id": "2405.04135v3",
      "title": "Human-centric Reward Optimization for Reinforcement Learning-based Automated Driving using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Zhou",
        "Jingyue Zhang",
        "Jingyuan Zhang",
        "Yangfan He",
        "Boyue Wang",
        "Tianyu Shi",
        "Alaa Khamis"
      ],
      "abstract": "One of the key challenges in current Reinforcement Learning (RL)-based\nAutomated Driving (AD) agents is achieving flexible, precise, and human-like\nbehavior cost-effectively. This paper introduces an innovative approach that\nuses large language models (LLMs) to intuitively and effectively optimize RL\nreward functions in a human-centric way. We developed a framework where\ninstructions and dynamic environment descriptions are input into the LLM. The\nLLM then utilizes this information to assist in generating rewards, thereby\nsteering the behavior of RL agents towards patterns that more closely resemble\nhuman driving. The experimental results demonstrate that this approach not only\nmakes RL agents more anthropomorphic but also achieves better performance.\nAdditionally, various strategies for reward-proxy and reward-shaping are\ninvestigated, revealing the significant impact of prompt design on shaping an\nAD vehicle's behavior. These findings offer a promising direction for the\ndevelopment of more advanced, human-like automated driving systems. Our\nexperimental data and source code can be found here",
      "tldr_zh": "这篇论文提出了一种以人为本的奖励优化方法，使用大型语言模型 (LLMs) 来提升基于强化学习 (RL) 的自动驾驶 (AD) 代理的灵活性、精确性和人性化。框架通过将指令和动态环境描述输入 LLM，以生成合适的奖励函数，从而引导 RL 代理的行为更接近人类驾驶习惯。实验结果表明，该方法不仅使代理更具拟人化特征，还显著提高了整体性能；此外，研究探讨了奖励代理 (reward-proxy) 和奖励塑造 (reward-shaping) 策略，强调了提示设计对行为的影响。该创新为开发更先进的人性化自动驾驶系统提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, 34 references",
      "pdf_url": "http://arxiv.org/pdf/2405.04135v3",
      "published_date": "2024-05-07 09:04:52 UTC",
      "updated_date": "2024-12-26 11:55:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:46:07.390622"
    },
    {
      "arxiv_id": "2405.04124v5",
      "title": "Comparative Study of State-based Neural Networks for Virtual Analog Audio Effects Modeling",
      "title_zh": "基于状态的神经网络在虚拟模拟音频效果建模中的比较研究",
      "authors": [
        "Riccardo Simionato",
        "Stefano Fasciani"
      ],
      "abstract": "Analog electronic circuits are at the core of an important category of\nmusical devices, which includes a broad range of sound synthesizers and audio\neffects. The development of software that simulates analog musical devices,\nknown as virtual analog modeling, is a significant sub-field in audio signal\nprocessing. Artificial neural networks are a promising technique for virtual\nanalog modeling. While neural approaches have successfully accurately modeled\ndistortion circuits, they require architectural improvements that account for\nparameter conditioning and low-latency response. This article explores the\napplication of recent machine learning advancements for virtual analog\nmodeling. In particular, we compare State-Space models and Linear Recurrent\nUnits against the more common Long Short-Term Memory networks. Our comparative\nstudy uses these black-box neural modeling techniques with various audio\neffects. We evaluate the performance and limitations of these models using\nmultiple metrics, providing insights for future research and development. Our\nmetrics aim to assess the models' ability to accurately replicate energy\nenvelopes and frequency contents, with a particular focus on transients in the\naudio signal. To incorporate control parameters into the models, we employ the\nFeature-wise Linear Modulation method. Long Short-Term Memory networks exhibit\nbetter accuracy in emulating distortions and equalizers, while the State-Space\nmodel, followed by Long Short-Term Memory networks when integrated in an\nencoder-decoder structure, and Linear Recurrent Unit outperforms others in\nemulating saturation and compression. When considering long time-variant\ncharacteristics, the State-Space model demonstrates the greatest capability to\ntrack history. Long Short-Term Memory networks tend to introduce audio\nartifacts.",
      "tldr_zh": "这篇论文比较了 State-Space models、Linear Recurrent Units 和 Long Short-Term Memory (LSTM) networks 在虚拟模拟音频效果建模中的性能，针对模拟电子电路的音乐设备如失真、均衡器、饱和和压缩。研究采用 Feature-wise Linear Modulation (FiLM) 方法处理控制参数，并使用多种指标评估模型在复制音频能量包络、频率内容和瞬态方面的准确性。结果显示，LSTM networks 在模拟失真和均衡器时更精确，而 State-Space models 在饱和、压缩和长时变特性跟踪上表现出色，且 LSTM networks 易引入音频 artifacts，为未来音频信号处理研究提供见解。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to EURASIP Journal on Audio, Speech, and Music Processing",
      "pdf_url": "http://arxiv.org/pdf/2405.04124v5",
      "published_date": "2024-05-07 08:47:40 UTC",
      "updated_date": "2024-08-29 09:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:46:20.486542"
    },
    {
      "arxiv_id": "2405.04118v2",
      "title": "Policy Learning with a Language Bottleneck",
      "title_zh": "翻译失败",
      "authors": [
        "Megha Srivastava",
        "Cedric Colas",
        "Dorsa Sadigh",
        "Jacob Andreas"
      ],
      "abstract": "Modern AI systems such as self-driving cars and game-playing agents achieve\nsuperhuman performance, but often lack human-like generalization,\ninterpretability, and inter-operability with human users. Inspired by the rich\ninteractions between language and decision-making in humans, we introduce\nPolicy Learning with a Language Bottleneck (PLLB), a framework enabling AI\nagents to generate linguistic rules that capture the high-level strategies\nunderlying rewarding behaviors. PLLB alternates between a *rule generation*\nstep guided by language models, and an *update* step where agents learn new\npolicies guided by rules, even when a rule is insufficient to describe an\nentire complex policy. Across five diverse tasks, including a two-player\nsignaling game, maze navigation, image reconstruction, and robot grasp\nplanning, we show that PLLB agents are not only able to learn more\ninterpretable and generalizable behaviors, but can also share the learned rules\nwith human users, enabling more effective human-AI coordination. We provide\nsource code for our experiments at https://github.com/meghabyte/bottleneck .",
      "tldr_zh": "该研究提出Policy Learning with a Language Bottleneck (PLLB)框架，旨在提升AI代理的泛化性、可解释性和与人类用户的互操作性，通过生成语言规则来捕捉高层次决策策略。PLLB框架交替进行rule generation步骤（由语言模型引导生成规则）和update步骤（代理根据规则学习新策略，即使规则不完整）。在五个多样化任务上，包括两玩家信号游戏、迷宫导航、图像重建和机器人抓取规划，实验结果表明PLLB代理能学习更可解释和可泛化的行为，并通过共享规则实现更有效的人类-AI协调。源代码可从GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 15 figures, updated with robot manipulation task",
      "pdf_url": "http://arxiv.org/pdf/2405.04118v2",
      "published_date": "2024-05-07 08:40:21 UTC",
      "updated_date": "2025-03-26 20:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:46:32.572964"
    },
    {
      "arxiv_id": "2405.04114v1",
      "title": "Acceleration Algorithms in GNNs: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Ma",
        "Zeang Sheng",
        "Xunkai Li",
        "Xinyi Gao",
        "Zhezheng Hao",
        "Ling Yang",
        "Wentao Zhang",
        "Bin Cui"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated effectiveness in various\ngraph-based tasks. However, their inefficiency in training and inference\npresents challenges for scaling up to real-world and large-scale graph\napplications. To address the critical challenges, a range of algorithms have\nbeen proposed to accelerate training and inference of GNNs, attracting\nincreasing attention from the research community. In this paper, we present a\nsystematic review of acceleration algorithms in GNNs, which can be categorized\ninto three main topics based on their purpose: training acceleration, inference\nacceleration, and execution acceleration. Specifically, we summarize and\ncategorize the existing approaches for each main topic, and provide detailed\ncharacterizations of the approaches within each category. Additionally, we\nreview several libraries related to acceleration algorithms in GNNs and discuss\nour Scalable Graph Learning (SGL) library. Finally, we propose promising\ndirections for future research. A complete summary is presented in our GitHub\nrepository:\nhttps://github.com/PKU-DAIR/SGL/blob/main/Awsome-GNN-Acceleration.md.",
      "tldr_zh": "这篇论文对图神经网络 (GNNs) 中的加速算法进行了系统调查，旨在解决 GNNs 在训练和推理过程中效率低下的问题，从而支持大规模图应用。作者将加速算法分为三类：training acceleration、inference acceleration 和 execution acceleration，并详细总结了每类下的现有方法及其特性。论文还审查了相关库，如 Scalable Graph Learning (SGL) 库，并提出了未来研究的有前景方向，同时提供了一个 GitHub 仓库作为完整总结。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04114v1",
      "published_date": "2024-05-07 08:34:33 UTC",
      "updated_date": "2024-05-07 08:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:46:43.184951"
    },
    {
      "arxiv_id": "2405.04108v1",
      "title": "A2-DIDM: Privacy-preserving Accumulator-enabled Auditing for Distributed Identity of DNN Model",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxiu Xie",
        "Keke Gai",
        "Jing Yu",
        "Liehuang Zhu",
        "Kim-Kwang Raymond Choo"
      ],
      "abstract": "Recent booming development of Generative Artificial Intelligence (GenAI) has\nfacilitated an emerging model commercialization for the purpose of\nreinforcement on model performance, such as licensing or trading Deep Neural\nNetwork (DNN) models. However, DNN model trading may trigger concerns of the\nunauthorized replications or misuses over the model, so that the benefit of the\nmodel ownership will be violated. Model identity auditing is a challenging\nissue in protecting intellectual property of DNN models and verifying the\nintegrity and ownership of models for guaranteeing trusts in transactions is\none of the critical obstacles. In this paper, we focus on the above issue and\npropose a novel Accumulator-enabled Auditing for Distributed Identity of DNN\nModel (A2-DIDM) that utilizes blockchain and zero-knowledge techniques to\nprotect data and function privacy while ensuring the lightweight on-chain\nownership verification. The proposed model presents a scheme of identity\nrecords via configuring model weight checkpoints with corresponding\nzero-knowledge proofs, which incorporates predicates to capture incremental\nstate changes in model weight checkpoints. Our scheme ensures both\ncomputational integrity of DNN training process and programmability, so that\nthe uniqueness of the weight checkpoint sequence in a DNN model is preserved,\nensuring the correctness of the model identity auditing. In addition, A2-DIDM\nalso addresses privacy protections in distributed identity via a proposed\nmethod of accumulators. We systematically analyze the security and robustness\nof our proposed model and further evaluate the effectiveness and usability of\nauditing DNN model identities.",
      "tldr_zh": "该论文针对深度神经网络(DNN)模型的商业化中存在的未经授权复制和误用问题，提出了一种隐私保护型审计方案A2-DIDM，利用区块链和零知识技术(zero-knowledge techniques)来验证模型所有权。A2-DIDM 通过配置模型权重检查点(model weight checkpoints)并结合谓词(predicates)捕获其增量状态变化，确保DNN训练过程的计算完整性(computational integrity)和模型身份的唯一性，同时采用累加器(accumulators)保护分布式身份隐私。实验分析表明，该方案实现了轻量级的链上所有权验证，并提升了DNN模型身份审计的安全性和可用性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04108v1",
      "published_date": "2024-05-07 08:24:50 UTC",
      "updated_date": "2024-05-07 08:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:46:56.878930"
    },
    {
      "arxiv_id": "2405.04101v2",
      "title": "Continual Learning in the Presence of Repetition",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Hemati",
        "Lorenzo Pellegrini",
        "Xiaotian Duan",
        "Zixuan Zhao",
        "Fangfang Xia",
        "Marc Masana",
        "Benedikt Tscheschner",
        "Eduardo Veas",
        "Yuxiang Zheng",
        "Shiji Zhao",
        "Shao-Yuan Li",
        "Sheng-Jun Huang",
        "Vincenzo Lomonaco",
        "Gido M. van de Ven"
      ],
      "abstract": "Continual learning (CL) provides a framework for training models in\never-evolving environments. Although re-occurrence of previously seen objects\nor tasks is common in real-world problems, the concept of repetition in the\ndata stream is not often considered in standard benchmarks for CL. Unlike with\nthe rehearsal mechanism in buffer-based strategies, where sample repetition is\ncontrolled by the strategy, repetition in the data stream naturally stems from\nthe environment. This report provides a summary of the CLVision challenge at\nCVPR 2023, which focused on the topic of repetition in class-incremental\nlearning. The report initially outlines the challenge objective and then\ndescribes three solutions proposed by finalist teams that aim to effectively\nexploit the repetition in the stream to learn continually. The experimental\nresults from the challenge highlight the effectiveness of ensemble-based\nsolutions that employ multiple versions of similar modules, each trained on\ndifferent but overlapping subsets of classes. This report underscores the\ntransformative potential of taking a different perspective in CL by employing\nrepetition in the data stream to foster innovative strategy design.",
      "tldr_zh": "这篇报告探讨了持续学习（Continual Learning）在数据流中存在重复时的挑战，强调现实环境中重复现象的常见性及其在标准基准测试中的忽视。报告总结了CVPR 2023 CLVision挑战赛的目标和结果，该赛聚焦于类增量学习（class-incremental learning），并介绍了三个决赛团队的解决方案，这些方案通过利用数据流重复来设计创新策略。实验结果显示，基于集成（ensemble-based）的模型——使用多个类似模块在不同但重叠的类子集上训练——显著提高了持续学习性能，突显了这种视角的变革潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted version, to appear in Neural Networks; Challenge Report of\n  the 4th Workshop on Continual Learning in Computer Vision at CVPR",
      "pdf_url": "http://arxiv.org/pdf/2405.04101v2",
      "published_date": "2024-05-07 08:15:48 UTC",
      "updated_date": "2024-12-02 14:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:47:07.411975"
    },
    {
      "arxiv_id": "2405.04097v2",
      "title": "Unmasking Illusions: Understanding Human Perception of Audiovisual Deepfakes",
      "title_zh": "揭露幻觉：理解人类对视听 Deepfakes 的感知",
      "authors": [
        "Ammarah Hashmi",
        "Sahibzada Adil Shahzad",
        "Chia-Wen Lin",
        "Yu Tsao",
        "Hsin-Min Wang"
      ],
      "abstract": "The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.",
      "tldr_zh": "这篇论文探讨了人类对audiovisual deepfakes的感知能力，通过一项主观研究评估人们辨别假视频的准确性。研究采用gamification概念，在一个web-based平台上，让110名参与者（包括55名母语英语者和55名非母语者）两次观看来自FakeAVCeleb数据集的40个视频（20个真实、20个假），并将人类表现与五种state-of-the-art audiovisual deepfake检测模型进行比较。结果显示，所有AI模型的表现均优于人类，且人类倾向于高估自己的检测能力；这些发现有助于建立人类与机器性能基准、推进取证分析并开发自适应对策。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04097v2",
      "published_date": "2024-05-07 07:57:15 UTC",
      "updated_date": "2024-11-11 09:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:47:20.886219"
    },
    {
      "arxiv_id": "2405.04095v2",
      "title": "DREAM: Combating Concept Drift with Explanatory Detection and Adaptation in Malware Classification",
      "title_zh": "DREAM：通过解释性检测和适应对抗恶意软件分类中的概念漂移",
      "authors": [
        "Yiling He",
        "Junchi Lei",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "Deep learning-based malware classifiers face significant challenges due to\nconcept drift. The rapid evolution of malware, especially with new families,\ncan depress classification accuracy to near-random levels. Previous research\nhas primarily focused on detecting drift samples, relying on expert-led\nanalysis and labeling for model retraining. However, these methods often lack a\ncomprehensive understanding of malware concepts and provide limited guidance\nfor effective drift adaptation, leading to unstable detection performance and\nhigh human labeling costs. To address these limitations, we introduce DREAM, a\nnovel system designed to surpass the capabilities of existing drift detectors\nand to establish an explanatory drift adaptation process. DREAM enhances drift\ndetection through model sensitivity and data autonomy. The detector, trained in\na semi-supervised approach, proactively captures malware behavior concepts\nthrough classifier feedback. During testing, it utilizes samples generated by\nthe detector itself, eliminating reliance on extensive training data. For drift\nadaptation, DREAM enlarges human intervention, enabling revisions of malware\nlabels and concept explanations embedded within the detector's latent space. To\nensure a comprehensive response to concept drift, it facilitates a coordinated\nupdate process for both the classifier and the detector. Our evaluation shows\nthat DREAM can effectively improve the drift detection accuracy and reduce the\nexpert analysis effort in adaptation across different malware datasets and\nclassifiers.",
      "tldr_zh": "该论文提出DREAM系统，用于应对恶意软件分类中的concept drift问题，该问题会导致分类准确率急剧下降。DREAM通过模型敏感性和数据自治增强漂移检测，采用半监督训练方法让检测器主动捕捉恶意软件行为概念，并在测试中使用自身生成的样本，减少对大量训练数据的依赖。对于漂移适应，DREAM扩大人类干预，允许修订恶意软件标签和嵌入检测器潜在空间的概念解释，并协调更新分类器和检测器。实验结果表明，DREAM在不同恶意软件数据集和分类器上显著提高了检测准确率，并降低了专家分析的努力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04095v2",
      "published_date": "2024-05-07 07:55:45 UTC",
      "updated_date": "2024-08-08 05:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:47:32.161547"
    },
    {
      "arxiv_id": "2405.04093v1",
      "title": "DCNN: Dual Cross-current Neural Networks Realized Using An Interactive Deep Learning Discriminator for Fine-grained Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Da Fu",
        "Mingfei Rong",
        "Eun-Hu Kim",
        "Hao Huang",
        "Witold Pedrycz"
      ],
      "abstract": "Accurate classification of fine-grained images remains a challenge in\nbackbones based on convolutional operations or self-attention mechanisms. This\nstudy proposes novel dual-current neural networks (DCNN), which combine the\nadvantages of convolutional operations and self-attention mechanisms to improve\nthe accuracy of fine-grained image classification. The main novel design\nfeatures for constructing a weakly supervised learning backbone model DCNN\ninclude (a) extracting heterogeneous data, (b) keeping the feature map\nresolution unchanged, (c) expanding the receptive field, and (d) fusing global\nrepresentations and local features. Experimental results demonstrated that\nusing DCNN as the backbone network for classifying certain fine-grained\nbenchmark datasets achieved performance advantage improvements of 13.5--19.5%\nand 2.2--12.9%, respectively, compared to other advanced convolution or\nattention-based fine-grained backbones.",
      "tldr_zh": "该研究提出了一种新型的 Dual Cross-current Neural Networks (DCNN)，通过结合 convolutional operations 和 self-attention mechanisms 的优势，来提升细粒度图像分类的准确性。DCNN 的关键设计包括提取 heterogeneous data、保持特征图分辨率不变、扩展 receptive field，以及融合全局 representations 和局部 features，从而构建一个弱监督学习 backbone 模型。实验结果显示，在多个细粒度 benchmark 数据集上，DCNN 相比其他先进的卷积或注意力-based 骨干网络，性能提升了 13.5-19.5% 和 2.2-12.9%。这为细粒度对象分类提供了更有效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04093v1",
      "published_date": "2024-05-07 07:51:28 UTC",
      "updated_date": "2024-05-07 07:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:47:43.653489"
    },
    {
      "arxiv_id": "2405.04081v1",
      "title": "Counterfactual and Semifactual Explanations in Abstract Argumentation: Formal Foundations, Complexity and Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Gianvincenzo Alfano",
        "Sergio Greco",
        "Francesco Parisi",
        "Irina Trubitsyna"
      ],
      "abstract": "Explainable Artificial Intelligence and Formal Argumentation have received\nsignificant attention in recent years. Argumentation-based systems often lack\nexplainability while supporting decision-making processes. Counterfactual and\nsemifactual explanations are interpretability techniques that provide insights\ninto the outcome of a model by generating alternative hypothetical instances.\nWhile there has been important work on counterfactual and semifactual\nexplanations for Machine Learning models, less attention has been devoted to\nthese kinds of problems in argumentation. In this paper, we explore\ncounterfactual and semifactual reasoning in abstract Argumentation Framework.\nWe investigate the computational complexity of counterfactual- and\nsemifactual-based reasoning problems, showing that they are generally harder\nthan classical argumentation problems such as credulous and skeptical\nacceptance. Finally, we show that counterfactual and semifactual queries can be\nencoded in weak-constrained Argumentation Framework, and provide a\ncomputational strategy through ASP solvers.",
      "tldr_zh": "本研究探讨了抽象论证框架（Abstract Argumentation Framework）中的反事实（Counterfactual）和半事实（Semifactual）解释，旨在提升论证系统的解释性以支持决策过程。论文首先形式化了这些解释技术的理论基础，并分析了相关推理问题的计算复杂度，发现它们比经典论证问题（如credulous acceptance和skeptical acceptance）更具挑战性。最终，研究展示了这些查询可以通过编码到弱约束论证框架（weak-constrained Argumentation Framework）中，并利用ASP solvers实现有效的计算策略，为可解释AI在论证领域的应用提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04081v1",
      "published_date": "2024-05-07 07:27:27 UTC",
      "updated_date": "2024-05-07 07:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:47:55.631773"
    },
    {
      "arxiv_id": "2405.04078v1",
      "title": "WISER: Weak supervISion and supErvised Representation learning to improve drug response prediction in cancer",
      "title_zh": "翻译失败",
      "authors": [
        "Kumar Shubham",
        "Aishwarya Jayagopal",
        "Syed Mohammed Danish",
        "Prathosh AP",
        "Vaibhav Rajan"
      ],
      "abstract": "Cancer, a leading cause of death globally, occurs due to genomic changes and\nmanifests heterogeneously across patients. To advance research on personalized\ntreatment strategies, the effectiveness of various drugs on cells derived from\ncancers (`cell lines') is experimentally determined in laboratory settings.\nNevertheless, variations in the distribution of genomic data and drug responses\nbetween cell lines and humans arise due to biological and environmental\ndifferences. Moreover, while genomic profiles of many cancer patients are\nreadily available, the scarcity of corresponding drug response data limits the\nability to train machine learning models that can predict drug response in\npatients effectively. Recent cancer drug response prediction methods have\nlargely followed the paradigm of unsupervised domain-invariant representation\nlearning followed by a downstream drug response classification step.\nIntroducing supervision in both stages is challenging due to heterogeneous\npatient response to drugs and limited drug response data. This paper addresses\nthese challenges through a novel representation learning method in the first\nphase and weak supervision in the second. Experimental results on real patient\ndata demonstrate the efficacy of our method (WISER) over state-of-the-art\nalternatives on predicting personalized drug response.",
      "tldr_zh": "本文提出WISER框架，结合Weak supervision和Supervised Representation learning，以提升癌症药物反应预测的准确性。针对基因数据分布差异和药物反应数据稀缺的挑战，该方法在表示学习阶段引入监督机制，并在下游分类阶段采用弱监督策略，解决患者异质性和数据限制问题。实验结果显示，WISER在真实患者数据上优于现有方法，能够更有效地预测个性化药物反应。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04078v1",
      "published_date": "2024-05-07 07:21:20 UTC",
      "updated_date": "2024-05-07 07:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:48:08.100585"
    },
    {
      "arxiv_id": "2405.04074v1",
      "title": "A simple theory for training response of deep neural networks",
      "title_zh": "深度神经网络训练响应的简单理论",
      "authors": [
        "Kenichi Nakazato"
      ],
      "abstract": "Deep neural networks give us a powerful method to model the training\ndataset's relationship between input and output. We can regard that as a\ncomplex adaptive system consisting of many artificial neurons that work as an\nadaptive memory as a whole. The network's behavior is training dynamics with a\nfeedback loop from the evaluation of the loss function. We already know the\ntraining response can be constant or shows power law-like aging in some ideal\nsituations. However, we still have gaps between those findings and other\ncomplex phenomena, like network fragility. To fill the gap, we introduce a very\nsimple network and analyze it. We show the training response consists of some\ndifferent factors based on training stages, activation functions, or training\nmethods. In addition, we show feature space reduction as an effect of\nstochastic training dynamics, which can result in network fragility. Finally,\nwe discuss some complex phenomena of deep networks.",
      "tldr_zh": "本论文提出一个简单理论来分析深度神经网络（deep neural networks）的训练响应，将其视为一个由人工神经元组成的复杂适应系统，强调训练动态中的反馈循环。作者通过引入一个简化网络模型，探讨了训练响应的不同因素，包括训练阶段、激活函数（activation functions）和训练方法，并揭示了随机训练动态（stochastic training dynamics）导致的特征空间减少，可能引发网络脆弱性（network fragility）。最终，该理论填补了现有发现（如常量或幂律衰减）与深度网络复杂现象之间的空白，为理解网络行为提供新见解。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.LG",
        "nlin.AO"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04074v1",
      "published_date": "2024-05-07 07:20:15 UTC",
      "updated_date": "2024-05-07 07:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:48:20.960623"
    },
    {
      "arxiv_id": "2405.04064v2",
      "title": "MFA-Net: Multi-Scale feature fusion attention network for liver tumor segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yanli Yuan",
        "Bingbing Wang",
        "Chuan Zhang",
        "Jingyi Xu",
        "Ximeng Liu",
        "Liehuang Zhu"
      ],
      "abstract": "Segmentation of organs of interest in medical CT images is beneficial for\ndiagnosis of diseases. Though recent methods based on Fully Convolutional\nNeural Networks (F-CNNs) have shown success in many segmentation tasks, fusing\nfeatures from images with different scales is still a challenge: (1) Due to the\nlack of spatial awareness, F-CNNs share the same weights at different spatial\nlocations. (2) F-CNNs can only obtain surrounding information through local\nreceptive fields. To address the above challenge, we propose a new segmentation\nframework based on attention mechanisms, named MFA-Net (Multi-Scale Feature\nFusion Attention Network). The proposed framework can learn more meaningful\nfeature maps among multiple scales and result in more accurate automatic\nsegmentation. We compare our proposed MFA-Net with SOTA methods on two 2D liver\nCT datasets. The experimental results show that our MFA-Net produces more\nprecise segmentation on images with different scales.",
      "tldr_zh": "本研究针对医疗CT图像中肝脏肿瘤分割的挑战，提出了一种新型框架MFA-Net（Multi-Scale Feature Fusion Attention Network），以解决Fully Convolutional Neural Networks (F-CNNs) 在多尺度特征融合中存在的空间意识不足和局部感受野限制问题。MFA-Net 通过注意力机制在多个尺度上学习更有意义的特征图，从而实现更准确的自动分割。实验结果显示，该网络在两个2D肝脏CT数据集上与SOTA方法相比，产生了更精确的图像分割效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04064v2",
      "published_date": "2024-05-07 07:10:44 UTC",
      "updated_date": "2024-05-09 12:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:48:32.675912"
    },
    {
      "arxiv_id": "2405.04061v3",
      "title": "Generalized Cauchy-Schwarz Divergence and Its Deep Learning Applications",
      "title_zh": "广义 Cauchy-Schwarz 散度及其深度学习应用",
      "authors": [
        "Mingfei Lu",
        "Chenxu Li",
        "Shujian Yu",
        "Robert Jenssen",
        "Badong Chen"
      ],
      "abstract": "Divergence measures play a central role and become increasingly essential in\ndeep learning, yet efficient measures for multiple (more than two)\ndistributions are rarely explored. This becomes particularly crucial in areas\nwhere the simultaneous management of multiple distributions is both inevitable\nand essential. Examples include clustering, multi-source domain adaptation or\ngeneralization, and multi-view learning, among others. While computing the mean\nof pairwise distances between any two distributions is a prevalent method to\nquantify the total divergence among multiple distributions, it is imperative to\nacknowledge that this approach is not straightforward and necessitates\nsignificant computational resources. In this study, we introduce a new\ndivergence measure tailored for multiple distributions named the generalized\nCauchy-Schwarz divergence (GCSD). Additionally, we furnish a kernel-based\nclosed-form sample estimator, making it convenient and straightforward to use\nin various machine-learning applications. Finally, we explore its profound\nimplications in the realm of deep learning by applying it to tackle two\nthoughtfully chosen machine-learning tasks: deep clustering and multi-source\ndomain adaptation. Our extensive experimental investigations confirm the\nrobustness and effectiveness of GCSD in both scenarios. The findings also\nunderscore the innovative potential of GCSD and its capability to significantly\npropel machine learning methodologies that necessitate the quantification of\nmultiple distributions.",
      "tldr_zh": "本研究引入了 Generalized Cauchy-Schwarz Divergence (GCSD)，一种新的散度措施，专门用于量化多个分布间的差异，以解决深度学习中多分布管理（如聚类、多源域适应和多视图学习）的挑战。GCSD 结合了一个基于核的闭式形式样本估计器，使其在机器学习应用中易于使用和计算高效。实验结果显示，GCSD 在深度聚类和多源域适应任务中表现出色，证明了其稳健性，并为需要处理多个分布的机器学习方法提供了显著推进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04061v3",
      "published_date": "2024-05-07 07:07:44 UTC",
      "updated_date": "2024-06-06 02:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:48:44.612835"
    },
    {
      "arxiv_id": "2405.04053v1",
      "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Shakil",
        "Atqiya Munawara Mahi",
        "Phuoc Nguyen",
        "Zeydy Ortiz",
        "Mamoun T. Mardini"
      ],
      "abstract": "This research examines the effectiveness of OpenAI's GPT models as\nindependent evaluators of text summaries generated by six transformer-based\nmodels from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS.\nWe evaluated these summaries based on essential properties of high-quality\nsummary - conciseness, relevance, coherence, and readability - using\ntraditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely,\nwe also employed GPT not as a summarizer but as an evaluator, allowing it to\nindependently assess summary quality without predefined metrics. Our analysis\nrevealed significant correlations between GPT evaluations and traditional\nmetrics, particularly in assessing relevance and coherence. The results\ndemonstrate GPT's potential as a robust tool for evaluating text summaries,\noffering insights that complement established metrics and providing a basis for\ncomparative analysis of transformer-based models in natural language processing\ntasks.",
      "tldr_zh": "本研究评估了 OpenAI's GPT 模型作为独立评估器的有效性，用于判断由 DistilBART、BERT、ProphetNet、T5、BART 和 PEGASUS 等六种 transformer-based 模型生成的文本摘要。评估基于关键属性包括 conciseness、relevance、coherence 和 readability，结合传统指标如 ROUGE 和 Latent Semantic Analysis (LSA)。结果显示，GPT 的评估与传统指标有显著相关性，尤其在 relevance 和 coherence 方面，证明了 GPT 作为补充工具的潜力，并为比较自然语言处理中的 transformer-based 模型提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04053v1",
      "published_date": "2024-05-07 06:52:34 UTC",
      "updated_date": "2024-05-07 06:52:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:48:56.948822"
    },
    {
      "arxiv_id": "2405.04050v1",
      "title": "Learning Linear Block Error Correction Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Yoni Choukroun",
        "Lior Wolf"
      ],
      "abstract": "Error correction codes are a crucial part of the physical communication\nlayer, ensuring the reliable transfer of data over noisy channels. The design\nof optimal linear block codes capable of being efficiently decoded is of major\nconcern, especially for short block lengths. While neural decoders have\nrecently demonstrated their advantage over classical decoding techniques, the\nneural design of the codes remains a challenge. In this work, we propose for\nthe first time a unified encoder-decoder training of binary linear block codes.\nTo this end, we adapt the coding setting to support efficient and\ndifferentiable training of the code for end-to-end optimization over the order\ntwo Galois field. We also propose a novel Transformer model in which the\nself-attention masking is performed in a differentiable fashion for the\nefficient backpropagation of the code gradient. Our results show that (i) the\nproposed decoder outperforms existing neural decoding on conventional codes,\n(ii) the suggested framework generates codes that outperform the {analogous}\nconventional codes, and (iii) the codes we developed not only excel with our\ndecoder but also show enhanced performance with traditional decoding\ntechniques.",
      "tldr_zh": "这篇论文提出了一种首次统一训练二进制线性块 codes 的编码器-解码器方法，以优化短块长度下的错误修正码设计。作者改进了编码设置，使其在 Galois field 上支持高效、可微分训练，并开发了一个新颖的 Transformer 模型，使用可微自注意力掩码进行梯度反向传播。实验结果显示，该解码器在传统 codes 上优于现有神经 decoders，所生成的 codes 不仅性能超越类似传统 codes，还能与传统解码技术兼容。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04050v1",
      "published_date": "2024-05-07 06:47:12 UTC",
      "updated_date": "2024-05-07 06:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:49:08.267176"
    },
    {
      "arxiv_id": "2405.04042v1",
      "title": "Space-time Reinforcement Network for Video Object Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yadang Chen",
        "Wentao Zhu",
        "Zhi-Xin Yang",
        "Enhua Wu"
      ],
      "abstract": "Recently, video object segmentation (VOS) networks typically use memory-based\nmethods: for each query frame, the mask is predicted by space-time matching to\nmemory frames. Despite these methods having superior performance, they suffer\nfrom two issues: 1) Challenging data can destroy the space-time coherence\nbetween adjacent video frames. 2) Pixel-level matching will lead to undesired\nmismatching caused by the noises or distractors. To address the aforementioned\nissues, we first propose to generate an auxiliary frame between adjacent\nframes, serving as an implicit short-temporal reference for the query one.\nNext, we learn a prototype for each video object and prototype-level matching\ncan be implemented between the query and memory. The experiment demonstrated\nthat our network outperforms the state-of-the-art method on the DAVIS 2017,\nachieving a J&F score of 86.4%, and attains a competitive result 85.0% on\nYouTube VOS 2018. In addition, our network exhibits a high inference speed of\n32+ FPS.",
      "tldr_zh": "这篇论文针对视频对象分割 (VOS) 的问题，提出了一种空间-时间强化网络，以解决现有内存-based 方法中相邻帧的空间-时间连贯性破坏和像素级匹配的错误匹配问题。该网络通过生成辅助帧作为查询帧的隐式短时参考，并为每个视频对象学习原型进行原型-level 匹配，从而提升分割准确性。实验结果显示，该网络在 DAVIS 2017 数据集上达到 86.4% 的 J&F 分数，在 YouTube VOS 2018 上获得 85.0% 的竞争性能，并实现 32+ FPS 的高推理速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME 2024. 6 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04042v1",
      "published_date": "2024-05-07 06:26:30 UTC",
      "updated_date": "2024-05-07 06:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:49:20.822713"
    },
    {
      "arxiv_id": "2405.04041v1",
      "title": "Feature Map Convergence Evaluation for Functional Module",
      "title_zh": "功能模块的特征图收敛评估",
      "authors": [
        "Ludan Zhang",
        "Chaoyi Chen",
        "Lei He",
        "Keqiang Li"
      ],
      "abstract": "Autonomous driving perception models are typically composed of multiple\nfunctional modules that interact through complex relationships to accomplish\nenvironment understanding. However, perception models are predominantly\noptimized as a black box through end-to-end training, lacking independent\nevaluation of functional modules, which poses difficulties for interpretability\nand optimization. Pioneering in the issue, we propose an evaluation method\nbased on feature map analysis to gauge the convergence of model, thereby\nassessing functional modules' training maturity. We construct a quantitative\nmetric named as the Feature Map Convergence Score (FMCS) and develop Feature\nMap Convergence Evaluation Network (FMCE-Net) to measure and predict the\nconvergence degree of models respectively. FMCE-Net achieves remarkable\npredictive accuracy for FMCS across multiple image classification experiments,\nvalidating the efficacy and robustness of the introduced approach. To the best\nof our knowledge, this is the first independent evaluation method for\nfunctional modules, offering a new paradigm for the training assessment towards\nperception models.",
      "tldr_zh": "该论文针对自动驾驶感知模型的功能模块独立评估问题，提出了一种基于特征图分析的评估方法，以量化模型的收敛度，从而提升模型的可解释性和优化效率。具体而言，他们开发了Feature Map Convergence Score (FMCS)作为量化指标，并构建了Feature Map Convergence Evaluation Network (FMCE-Net)来测量和预测模型收敛度。在多个图像分类实验中，FMCE-Net 显示出卓越的预测准确性，这标志着首次针对功能模块的独立评估方法，为自动驾驶感知模型的训练评估提供了新范式。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04041v1",
      "published_date": "2024-05-07 06:25:49 UTC",
      "updated_date": "2024-05-07 06:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:49:32.134218"
    },
    {
      "arxiv_id": "2405.04039v1",
      "title": "Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Shakil",
        "Zeydy Ortiz",
        "Grant C. Forbes"
      ],
      "abstract": "In this research, we uses the DistilBERT model to generate extractive summary\nand the T5 model to generate abstractive summaries. Also, we generate hybrid\nsummaries by combining both DistilBERT and T5 models. Central to our research\nis the implementation of GPT-based refining process to minimize the common\nproblem of hallucinations that happens in AI-generated summaries. We evaluate\nunrefined summaries and, after refining, we also assess refined summaries using\na range of traditional and novel metrics, demonstrating marked improvements in\nthe accuracy and reliability of the summaries. Results highlight significant\nimprovements in reducing hallucinatory content, thereby increasing the factual\nintegrity of the summaries.",
      "tldr_zh": "这篇论文提出了一种利用 GPT 的策略来提升文本摘要的准确性，旨在最小化 AI 生成摘要中的 hallucinations。研究采用 DistilBERT 生成提取式摘要、T5 生成抽象式摘要，并结合两者创建混合摘要，然后通过 GPT 基于提炼过程优化这些摘要。评估结果显示，提炼后的摘要在传统和新型指标上表现出显著改善，减少了幻觉内容并提升了事实完整性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.04039v1",
      "published_date": "2024-05-07 06:23:02 UTC",
      "updated_date": "2024-05-07 06:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:49:44.049018"
    },
    {
      "arxiv_id": "2405.04032v2",
      "title": "Locally Differentially Private In-Context Learning",
      "title_zh": "本地差分隐私的上下文学习",
      "authors": [
        "Chunyan Zheng",
        "Keke Sun",
        "Wenhao Zhao",
        "Haibo Zhou",
        "Lixin Jiang",
        "Shaoyang Song",
        "Chunlai Zhou"
      ],
      "abstract": "Large pretrained language models (LLMs) have shown surprising In-Context\nLearning (ICL) ability. An important application in deploying large language\nmodels is to augment LLMs with a private database for some specific task. The\nmain problem with this promising commercial use is that LLMs have been shown to\nmemorize their training data and their prompt data are vulnerable to membership\ninference attacks (MIA) and prompt leaking attacks. In order to deal with this\nproblem, we treat LLMs as untrusted in privacy and propose a locally\ndifferentially private framework of in-context learning(LDP-ICL) in the\nsettings where labels are sensitive. Considering the mechanisms of in-context\nlearning in Transformers by gradient descent, we provide an analysis of the\ntrade-off between privacy and utility in such LDP-ICL for classification.\nMoreover, we apply LDP-ICL to the discrete distribution estimation problem. In\nthe end, we perform several experiments to demonstrate our analysis results.",
      "tldr_zh": "本研究探讨了大型预训练语言模型（LLMs）在 In-Context Learning (ICL) 中的隐私风险，包括数据记忆导致的 membership inference attacks (MIA) 和 prompt leaking attacks。为此，提出了一种本地差分隐私框架（LDP-ICL），将 LLMs 视为不受信任的实体，并在标签敏感场景下通过分析 Transformers 的梯度下降机制，实现隐私与效用的权衡。该框架应用于离散分布估计问题，并通过实验证明了其有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper was published at LREC-Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04032v2",
      "published_date": "2024-05-07 06:05:43 UTC",
      "updated_date": "2024-05-08 17:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:49:57.218708"
    },
    {
      "arxiv_id": "2405.04017v1",
      "title": "An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifa Ke",
        "Zaiwen Wen",
        "Junyu Zhang"
      ],
      "abstract": "Temporal difference (TD) learning algorithms with neural network function\nparameterization have well-established empirical success in many practical\nlarge-scale reinforcement learning tasks. However, theoretical understanding of\nthese algorithms remains challenging due to the nonlinearity of the\naction-value approximation. In this paper, we develop an improved\nnon-asymptotic analysis of the neural TD method with a general $L$-layer neural\nnetwork. New proof techniques are developed and an improved new\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ sample complexity is derived. To our best\nknowledge, this is the first finite-time analysis of neural TD that achieves an\n$\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ complexity under the Markovian sampling,\nas opposed to the best known $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ complexity in\nthe existing literature.",
      "tldr_zh": "这篇论文针对 Temporal Difference (TD) 学习算法与深度神经网络相结合的强化学习任务，进行了改进的有限时间分析，以应对神经网络非线性带来的挑战。研究者开发了新证明技术，对一般 L-层神经网络的神经 TD 方法进行了非渐近分析，实现了 $\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ 的样本复杂度。相比现有文献的最佳 $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ 复杂度，这一成果在 Markovian 采样条件下首次达到了更高效的性能，为 TD 算法的理论理解提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04017v1",
      "published_date": "2024-05-07 05:29:55 UTC",
      "updated_date": "2024-05-07 05:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:50:08.750679"
    },
    {
      "arxiv_id": "2405.04015v1",
      "title": "Certified Policy Verification and Synthesis for MDPs under Distributional Reach-avoidance Properties",
      "title_zh": "翻译失败",
      "authors": [
        "S. Akshay",
        "Krishnendu Chatterjee",
        "Tobias Meggendorfer",
        "Đorđe Žikelić"
      ],
      "abstract": "Markov Decision Processes (MDPs) are a classical model for decision making in\nthe presence of uncertainty. Often they are viewed as state transformers with\nplanning objectives defined with respect to paths over MDP states. An\nincreasingly popular alternative is to view them as distribution transformers,\ngiving rise to a sequence of probability distributions over MDP states. For\ninstance, reachability and safety properties in modeling robot swarms or\nchemical reaction networks are naturally defined in terms of probability\ndistributions over states. Verifying such distributional properties is known to\nbe hard and often beyond the reach of classical state-based verification\ntechniques.\n  In this work, we consider the problems of certified policy (i.e. controller)\nverification and synthesis in MDPs under distributional reach-avoidance\nspecifications. By certified we mean that, along with a policy, we also aim to\nsynthesize a (checkable) certificate ensuring that the MDP indeed satisfies the\nproperty. Thus, given the target set of distributions and an unsafe set of\ndistributions over MDP states, our goal is to either synthesize a certificate\nfor a given policy or synthesize a policy along with a certificate, proving\nthat the target distribution can be reached while avoiding unsafe\ndistributions. To solve this problem, we introduce the novel notion of\ndistributional reach-avoid certificates and present automated procedures for\n(1) synthesizing a certificate for a given policy, and (2) synthesizing a\npolicy together with the certificate, both providing formal guarantees on\ncertificate correctness. Our experimental evaluation demonstrates the ability\nof our method to solve several non-trivial examples, including a multi-agent\nrobot-swarm model, to synthesize certified policies and to certify existing\npolicies.",
      "tldr_zh": "本研究探讨了Markov Decision Processes (MDPs) 的分布转换视角，针对分布性的 reach-avoidance 属性，提出了一种认证策略（policy）验证和合成方法。该方法引入了新型的 distributional reach-avoid certificates 概念，并开发了自动化程序：（1）为给定策略合成证书，以证明MDPs满足属性；（2）同时合成策略和证书，确保目标分布可达同时避开不安全分布。这些程序提供了正式的正确性保证。实验结果显示，该方法在多代理机器人群模型等非平凡示例中成功合成和验证策略，证明了其实际有效性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper accepted at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04015v1",
      "published_date": "2024-05-07 05:23:56 UTC",
      "updated_date": "2024-05-07 05:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:50:20.508813"
    },
    {
      "arxiv_id": "2405.04009v1",
      "title": "Structured Click Control in Transformer-based Interactive Segmentation",
      "title_zh": "基于 Transformer 的交互式分割中的结构化点击控制",
      "authors": [
        "Long Xu",
        "Yongquan Chen",
        "Rui Huang",
        "Feng Wu",
        "Shiwu Lai"
      ],
      "abstract": "Click-point-based interactive segmentation has received widespread attention\ndue to its efficiency. However, it's hard for existing algorithms to obtain\nprecise and robust responses after multiple clicks. In this case, the\nsegmentation results tend to have little change or are even worse than before.\nTo improve the robustness of the response, we propose a structured click intent\nmodel based on graph neural networks, which adaptively obtains graph nodes via\nthe global similarity of user-clicked Transformer tokens. Then the graph nodes\nwill be aggregated to obtain structured interaction features. Finally, the dual\ncross-attention will be used to inject structured interaction features into\nvision Transformer features, thereby enhancing the control of clicks over\nsegmentation results. Extensive experiments demonstrated the proposed algorithm\ncan serve as a general structure in improving Transformer-based interactive\nsegmenta?tion performance. The code and data will be released at\nhttps://github.com/hahamyt/scc.",
      "tldr_zh": "该论文针对基于点击点的交互式分割算法在多次点击后响应不精确和不鲁棒的问题，提出了一种结构化点击控制方法。方法利用图神经网络（Graph Neural Networks）基于用户点击的 Transformer tokens 的全局相似性，自适应获取图节点，并聚合生成结构化交互特征。随后，通过双交叉注意力机制将这些特征注入视觉 Transformer 特征中，从而增强点击对分割结果的控制。实验结果表明，该算法作为一种通用结构，能够显著改善基于 Transformer's 交互式分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures, submitted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.04009v1",
      "published_date": "2024-05-07 04:57:25 UTC",
      "updated_date": "2024-05-07 04:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:50:32.936810"
    },
    {
      "arxiv_id": "2405.03990v2",
      "title": "TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Guanqiao Qu",
        "Zheng Lin",
        "Fangming Liu",
        "Xianhao Chen",
        "Kaibin Huang"
      ],
      "abstract": "Next-generation mobile networks are expected to facilitate fast AI model\ndownloading to end users. By caching models on edge servers, mobile networks\ncan deliver models to end users with low latency, resulting in a paradigm\ncalled edge model caching. In this paper, we develop a novel model placement\nscheme, called parameter-sharing model caching (TrimCaching). TrimCaching\nexploits the key observation that a wide range of AI models, such as\nconvolutional neural networks or large language models, can share a significant\nproportion of parameter blocks containing reusable knowledge, thereby improving\nstorage efficiency. To this end, we formulate a parameter-sharing model\nplacement problem to maximize the cache hit ratio in multi-edge wireless\nnetworks by balancing the fundamental tradeoff between storage efficiency and\nservice latency. We show that the formulated problem is a submodular\nmaximization problem with submodular constraints, for which no polynomial-time\napproximation algorithm exists. To overcome this challenge, we study an\nimportant special case, where a small fixed number of parameter blocks are\nshared across models, which often holds in practice. In such a case, a\npolynomial-time algorithm with $\\left(1-\\epsilon\\right)/2$-approximation\nguarantee is developed. Subsequently, we address the original problem for the\ngeneral case by developing a greedy algorithm. Simulation results demonstrate\nthat the proposed TrimCaching framework significantly improves the cache hit\nratio compared with state-of-the-art content caching without exploiting shared\nparameters in AI models.",
      "tldr_zh": "这篇论文提出了TrimCaching，一种基于参数共享的AI模型缓存方案，用于无线边际网络中，以降低AI模型（如卷积神经网络或大型语言模型）下载延迟并提高存储效率。研究者通过制定一个最大化缓存命中率的子模优化问题，平衡存储效率和服务延迟的权衡，并开发了针对特定情况的（1-ε）/2逼近算法以及针对一般情况的贪婪算法。模拟结果表明，TrimCaching框架显著提升了缓存命中率，比不利用共享参数的传统内容缓存方法更具优势。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "11 pages, 7 figures. This paper has been accepted by ICDCS 2024. The\n  extended version of this paper is at arXiv:2404.14204",
      "pdf_url": "http://arxiv.org/pdf/2405.03990v2",
      "published_date": "2024-05-07 04:08:49 UTC",
      "updated_date": "2024-05-20 03:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:50:45.711494"
    },
    {
      "arxiv_id": "2405.03988v3",
      "title": "LEARN: Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Jia",
        "Yipei Wang",
        "Yan Li",
        "Honggang Chen",
        "Xuehan Bai",
        "Zhaocheng Liu",
        "Jian Liang",
        "Quan Chen",
        "Han Li",
        "Peng Jiang",
        "Kun Gai"
      ],
      "abstract": "Contemporary recommendation systems predominantly rely on ID embedding to\ncapture latent associations among users and items. However, this approach\noverlooks the wealth of semantic information embedded within textual\ndescriptions of items, leading to suboptimal performance and poor\ngeneralizations. Leveraging the capability of large language models to\ncomprehend and reason about textual content presents a promising avenue for\nadvancing recommendation systems. To achieve this, we propose an Llm-driven\nknowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world\nknowledge with collaborative knowledge. We address computational complexity\nconcerns by utilizing pretrained LLMs as item encoders and freezing LLM\nparameters to avoid catastrophic forgetting and preserve open-world knowledge.\nTo bridge the gap between the open-world and collaborative domains, we design a\ntwin-tower structure supervised by the recommendation task and tailored for\npractical industrial application. Through experiments on the real large-scale\nindustrial dataset and online A/B tests, we demonstrate the efficacy of our\napproach in industry application. We also achieve state-of-the-art performance\non six Amazon Review datasets to verify the superiority of our method.",
      "tldr_zh": "本研究指出，传统推荐系统依赖 ID embedding 而忽略物品文本描述的语义信息，导致性能和泛化能力不足。为此，提出 LEARN 框架，利用预训练 Large Language Model (LLMs) 作为物品编码器，并冻结其参数以避免灾难性遗忘，同时结合开放世界知识和协作知识，通过双塔结构 (twin-tower structure) 优化推荐任务。实验结果显示，该框架在真实大规模工业数据集和在线 A/B 测试中表现出色，并在六个 Amazon Review 数据集上达到最先进性能，验证了其在实际工业应用中的优越性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by AAAI 2025. Codes are released at\n  https://github.com/adxcreative/LEARN",
      "pdf_url": "http://arxiv.org/pdf/2405.03988v3",
      "published_date": "2024-05-07 04:00:30 UTC",
      "updated_date": "2024-12-26 03:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:50:58.191759"
    },
    {
      "arxiv_id": "2405.03986v1",
      "title": "Factors Influencing User Willingness To Use SORA",
      "title_zh": "影响用户使用 SORA 意愿的因素",
      "authors": [
        "Gustave Florentin Nkoulou Mvondo",
        "Ben Niu"
      ],
      "abstract": "Sora promises to redefine the way visual content is created. Despite its\nnumerous forecasted benefits, the drivers of user willingness to use the\ntext-to-video (T2V) model are unknown. This study extends the extended unified\ntheory of acceptance and use of technology (UTAUT2) with perceived realism and\nnovelty value. Using a purposive sampling method, we collected data from 940\nrespondents in the US and analyzed the sample using covariance-based structural\nequation modeling and fuzzy set qualitative comparative analysis (fsQCA). The\nfindings reveal that all hypothesized relationships are supported, with\nperceived realism emerging as the most influential driver, followed by novelty\nvalue. Moreover, fsQCA identifies five configurations leading to high and low\nwillingness to use, and the model demonstrates high predictive validity,\ncontributing to theory advancement. Our study provides valuable insights for\ndevelopers and marketers, offering guidance for strategic decisions to promote\nthe widespread adoption of T2V models.",
      "tldr_zh": "本研究扩展了 UTAUT2 理论，加入 perceived realism 和 novelty value，探讨影响用户使用 SORA（文本到视频 T2V 模型）的关键因素。通过 purposive sampling 收集940名美国受访者的数据，并采用 covariance-based structural equation modeling 和 fsQCA 分析，结果显示 perceived realism 是最强驱动因素，其次是 novelty value，且识别了五种配置导致高或低使用意愿。该研究为 T2V 模型的开发者提供战略指导，促进其广泛采用，并提升理论预测有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "62P225"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 3 figures, 7 tables, 2 authors; first author* corresponding\n  author,",
      "pdf_url": "http://arxiv.org/pdf/2405.03986v1",
      "published_date": "2024-05-07 03:55:32 UTC",
      "updated_date": "2024-05-07 03:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:51:09.582877"
    },
    {
      "arxiv_id": "2405.03977v1",
      "title": "Can citations tell us about a paper's reproducibility? A case study of machine learning papers",
      "title_zh": "翻译失败",
      "authors": [
        "Rochana R. Obadage",
        "Sarah M. Rajtmajer",
        "Jian Wu"
      ],
      "abstract": "The iterative character of work in machine learning (ML) and artificial\nintelligence (AI) and reliance on comparisons against benchmark datasets\nemphasize the importance of reproducibility in that literature. Yet, resource\nconstraints and inadequate documentation can make running replications\nparticularly challenging. Our work explores the potential of using downstream\ncitation contexts as a signal of reproducibility. We introduce a sentiment\nanalysis framework applied to citation contexts from papers involved in Machine\nLearning Reproducibility Challenges in order to interpret the positive or\nnegative outcomes of reproduction attempts. Our contributions include training\nclassifiers for reproducibility-related contexts and sentiment analysis, and\nexploring correlations between citation context sentiment and reproducibility\nscores. Study data, software, and an artifact appendix are publicly available\nat https://github.com/lamps-lab/ccair-ai-reproducibility .",
      "tldr_zh": "这篇论文探讨了引用上下文是否能作为机器学习（ML）论文可复现性（reproducibility）的指标，通过对ML和人工智能（AI）文献的案例研究来评估其重要性。研究引入了一个情感分析（sentiment analysis）框架，应用于引用上下文，以分析复现尝试的积极或消极结果，并训练分类器探索情感与可复现性分数之间的相关性。主要贡献包括公开的数据、软件和工件附录，这为提升ML领域的复现性提供了新工具。实验结果显示，这种方法能有效识别复现信号，有助于改进学术文献的可靠性。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03977v1",
      "published_date": "2024-05-07 03:29:11 UTC",
      "updated_date": "2024-05-07 03:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:51:21.752545"
    },
    {
      "arxiv_id": "2405.03974v1",
      "title": "TBNet: A Neural Architectural Defense Framework Facilitating DNN Model Protection in Trusted Execution Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Liu",
        "Tong Zhou",
        "Yukui Luo",
        "Xiaolin Xu"
      ],
      "abstract": "Trusted Execution Environments (TEEs) have become a promising solution to\nsecure DNN models on edge devices. However, the existing solutions either\nprovide inadequate protection or introduce large performance overhead. Taking\nboth security and performance into consideration, this paper presents TBNet, a\nTEE-based defense framework that protects DNN model from a neural architectural\nperspective. Specifically, TBNet generates a novel Two-Branch substitution\nmodel, to respectively exploit (1) the computational resources in the untrusted\nRich Execution Environment (REE) for latency reduction and (2) the\nphysically-isolated TEE for model protection. Experimental results on a\nRaspberry Pi across diverse DNN model architectures and datasets demonstrate\nthat TBNet achieves efficient model protection at a low cost.",
      "tldr_zh": "本研究提出 TBNet，一种基于神经架构的防御框架，用于在 Trusted Execution Environments (TEEs) 中保护 DNN 模型，同时兼顾安全性和性能。TBNet 通过生成 Two-Branch 替代模型，利用不受信任的 Rich Execution Environment (REE) 减少计算延迟，并依赖物理隔离的 TEE 确保模型安全。实验结果显示，在 Raspberry Pi 上的多种 DNN 架构和数据集测试中，TBNet 实现了高效的模型保护，同时显著降低了性能开销。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03974v1",
      "published_date": "2024-05-07 03:08:30 UTC",
      "updated_date": "2024-05-07 03:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:51:32.312085"
    },
    {
      "arxiv_id": "2405.03967v1",
      "title": "SwiftRL: Towards Efficient Reinforcement Learning on Real Processing-In-Memory Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Kailash Gogineni",
        "Sai Santosh Dayapule",
        "Juan Gómez-Luna",
        "Karthikeya Gogineni",
        "Peng Wei",
        "Tian Lan",
        "Mohammad Sadrosadati",
        "Onur Mutlu",
        "Guru Venkataramani"
      ],
      "abstract": "Reinforcement Learning (RL) trains agents to learn optimal behavior by\nmaximizing reward signals from experience datasets. However, RL training often\nfaces memory limitations, leading to execution latencies and prolonged training\ntimes. To overcome this, SwiftRL explores Processing-In-Memory (PIM)\narchitectures to accelerate RL workloads. We achieve near-linear performance\nscaling by implementing RL algorithms like Tabular Q-learning and SARSA on\nUPMEM PIM systems and optimizing for hardware. Our experiments on OpenAI GYM\nenvironments using UPMEM hardware demonstrate superior performance compared to\nCPU and GPU implementations.",
      "tldr_zh": "强化学习 (RL) 在训练代理以最大化奖励信号时，常因内存限制导致执行延迟和训练时间延长。SwiftRL 提出一种基于 Processing-In-Memory (PIM) 架构的解决方案，通过在 UPMEM PIM 系统上实现和优化 RL 算法如 Tabular Q-learning 和 SARSA，来加速 RL 工作负载。实验在 OpenAI GYM 环境中表明，SwiftRL 相对于 CPU 和 GPU 实现实现了近线性的性能扩展，显著提升了训练效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03967v1",
      "published_date": "2024-05-07 02:54:31 UTC",
      "updated_date": "2024-05-07 02:54:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:51:45.286801"
    },
    {
      "arxiv_id": "2405.03963v4",
      "title": "ERATTA: Extreme RAG for Table To Answers with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sohini Roychowdhury",
        "Marko Krema",
        "Anvar Mahammad",
        "Brian Moore",
        "Arijit Mukherjee",
        "Punit Prakashchandra"
      ],
      "abstract": "Large language models (LLMs) with retrieval augmented-generation (RAG) have\nbeen the optimal choice for scalable generative AI solutions in the recent\npast. Although RAG implemented with AI agents (agentic-RAG) has been recently\npopularized, its suffers from unstable cost and unreliable performances for\nEnterprise-level data-practices. Most existing use-cases that incorporate RAG\nwith LLMs have been either generic or extremely domain specific, thereby\nquestioning the scalability and generalizability of RAG-LLM approaches. In this\nwork, we propose a unique LLM-based system where multiple LLMs can be invoked\nto enable data authentication, user-query routing, data-retrieval and custom\nprompting for question-answering capabilities from Enterprise-data tables. The\nsource tables here are highly fluctuating and large in size and the proposed\nframework enables structured responses in under 10 seconds per query.\nAdditionally, we propose a five metric scoring module that detects and reports\nhallucinations in the LLM responses. Our proposed system and scoring metrics\nachieve >90% confidence scores across hundreds of user queries in the\nsustainability, financial health and social media domains. Extensions to the\nproposed extreme RAG architectures can enable heterogeneous source querying\nusing LLMs.",
      "tldr_zh": "该研究提出 ERATTA，一种极端的 RAG（Retrieval Augmented-Generation）框架，用于利用 Large Language Models (LLMs) 从企业级数据表中生成答案，以解决现有 RAG 系统在成本和性能上的不稳定性问题。ERATTA 系统通过调用多个 LLMs 来实现数据认证、用户查询路由、数据检索和自定义提示，确保对大规模、波动性高的表数据提供结构化响应，并在 10 秒内完成查询。系统还引入了一个五指标评分模块，用于检测和报告 LLM 响应中的 hallucinations（幻觉）。实验结果显示，该框架在可持续性、金融健康和社会媒体领域处理数百个查询时，达到了超过 90% 的置信度分数，并可扩展到异构数据源查询。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 tables, IEEE Big Data, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03963v4",
      "published_date": "2024-05-07 02:49:59 UTC",
      "updated_date": "2024-11-17 07:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:51:58.040024"
    },
    {
      "arxiv_id": "2405.03958v3",
      "title": "Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Joo Young Choi",
        "Jaesung R. Park",
        "Inkyu Park",
        "Jaewoong Cho",
        "Albert No",
        "Ernest K. Ryu"
      ],
      "abstract": "Current state-of-the-art diffusion models employ U-Net architectures\ncontaining convolutional and (qkv) self-attention layers. The U-Net processes\nimages while being conditioned on the time embedding input for each sampling\nstep and the class or caption embedding input corresponding to the desired\nconditional generation. Such conditioning involves scale-and-shift operations\nto the convolutional layers but does not directly affect the attention layers.\nWhile these standard architectural choices are certainly effective, not\nconditioning the attention layers feels arbitrary and potentially suboptimal.\nIn this work, we show that simply adding LoRA conditioning to the attention\nlayers without changing or tuning the other parts of the U-Net architecture\nimproves the image generation quality. For example, a drop-in addition of LoRA\nconditioning to EDM diffusion model yields FID scores of 1.91/1.75 for\nunconditional and class-conditional CIFAR-10 generation, improving upon the\nbaseline of 1.97/1.79.",
      "tldr_zh": "该研究发现，在扩散模型的U-Net架构中，仅在注意力层添加LoRA条件化，而不修改其他部分，就能显著提升图像生成质量。传统方法只对卷积层进行条件化（如时间嵌入或类别嵌入），忽略了注意力层的潜在优化机会。作者通过简单“即插即用”的LoRA（Low-Rank Adaptation）技术，实验显示在EDM模型上，CIFAR-10的无条件和条件生成FID分数从1.97/1.79改善到1.91/1.75，证明了这一方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03958v3",
      "published_date": "2024-05-07 02:45:28 UTC",
      "updated_date": "2024-10-04 09:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:52:09.962589"
    },
    {
      "arxiv_id": "2405.03950v1",
      "title": "Relating-Up: Advancing Graph Neural Networks through Inter-Graph Relationships",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zou",
        "Na Yu",
        "Daoliang Zhang",
        "Wei Zhang",
        "Rui Gao"
      ],
      "abstract": "Graph Neural Networks (GNNs) have excelled in learning from graph-structured\ndata, especially in understanding the relationships within a single graph,\ni.e., intra-graph relationships. Despite their successes, GNNs are limited by\nneglecting the context of relationships across graphs, i.e., inter-graph\nrelationships. Recognizing the potential to extend this capability, we\nintroduce Relating-Up, a plug-and-play module that enhances GNNs by exploiting\ninter-graph relationships. This module incorporates a relation-aware encoder\nand a feedback training strategy. The former enables GNNs to capture\nrelationships across graphs, enriching relation-aware graph representation\nthrough collective context. The latter utilizes a feedback loop mechanism for\nthe recursively refinement of these representations, leveraging insights from\nrefining inter-graph dynamics to conduct feedback loop. The synergy between\nthese two innovations results in a robust and versatile module. Relating-Up\nenhances the expressiveness of GNNs, enabling them to encapsulate a wider\nspectrum of graph relationships with greater precision. Our evaluations across\n16 benchmark datasets demonstrate that integrating Relating-Up into GNN\narchitectures substantially improves performance, positioning Relating-Up as a\nformidable choice for a broad spectrum of graph representation learning tasks.",
      "tldr_zh": "该研究指出，Graph Neural Networks (GNNs) 擅长处理单图内关系（intra-graph relationships），但忽略了跨图关系（inter-graph relationships），从而限制了其表现力。为此，作者提出 Relating-Up 模块，这是一个即插即用组件，结合 relation-aware encoder 来捕获跨图关系并丰富图表示，以及 feedback training strategy 通过反馈循环机制递归精炼这些表示。实验结果显示，在 16 个基准数据集上，集成 Relating-Up 显著提升了 GNN 的性能，使其能够更精确地处理更广泛的图关系学习任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.03950v1",
      "published_date": "2024-05-07 02:16:54 UTC",
      "updated_date": "2024-05-07 02:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:52:22.518132"
    },
    {
      "arxiv_id": "2405.03943v1",
      "title": "Predictive Modeling with Temporal Graphical Representation on Electronic Health Records",
      "title_zh": "基于电子健康记录的时序图形表示预测建模",
      "authors": [
        "Jiayuan Chen",
        "Changchang Yin",
        "Yuanlong Wang",
        "Ping Zhang"
      ],
      "abstract": "Deep learning-based predictive models, leveraging Electronic Health Records\n(EHR), are receiving increasing attention in healthcare. An effective\nrepresentation of a patient's EHR should hierarchically encompass both the\ntemporal relationships between historical visits and medical events, and the\ninherent structural information within these elements. Existing patient\nrepresentation methods can be roughly categorized into sequential\nrepresentation and graphical representation. The sequential representation\nmethods focus only on the temporal relationships among longitudinal visits. On\nthe other hand, the graphical representation approaches, while adept at\nextracting the graph-structured relationships between various medical events,\nfall short in effectively integrate temporal information. To capture both types\nof information, we model a patient's EHR as a novel temporal heterogeneous\ngraph. This graph includes historical visits nodes and medical events nodes. It\npropagates structured information from medical event nodes to visit nodes and\nutilizes time-aware visit nodes to capture changes in the patient's health\nstatus. Furthermore, we introduce a novel temporal graph transformer (TRANS)\nthat integrates temporal edge features, global positional encoding, and local\nstructural encoding into heterogeneous graph convolution, capturing both\ntemporal and structural information. We validate the effectiveness of TRANS\nthrough extensive experiments on three real-world datasets. The results show\nthat our proposed approach achieves state-of-the-art performance.",
      "tldr_zh": "本文提出一种基于电子健康记录 (EHR) 的预测模型，通过构建一个新型 temporal heterogeneous graph 来同时捕捉历史就诊之间的时间关系和医疗事件之间的结构信息。该图包括历史就诊节点和医疗事件节点，能够传播结构信息并利用 time-aware visit nodes 追踪患者健康状态变化。作者引入了 temporal graph transformer (TRANS)，它整合 temporal edge features、global positional encoding 和 local structural encoding 到 heterogeneous graph convolution 中，以有效融合时间和结构数据。在三个真实数据集上的实验表明，该方法实现了 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2024 main track",
      "pdf_url": "http://arxiv.org/pdf/2405.03943v1",
      "published_date": "2024-05-07 02:05:30 UTC",
      "updated_date": "2024-05-07 02:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:52:34.252992"
    },
    {
      "arxiv_id": "2407.10254v1",
      "title": "The Elephant in the Room -- Why AI Safety Demands Diverse Teams",
      "title_zh": "房间里的那头大象——",
      "authors": [
        "David Rostcheck",
        "Lara Scheibling"
      ],
      "abstract": "We consider that existing approaches to AI \"safety\" and \"alignment\" may not\nbe using the most effective tools, teams, or approaches. We suggest that an\nalternative and better approach to the problem may be to treat alignment as a\nsocial science problem, since the social sciences enjoy a rich toolkit of\nmodels for understanding and aligning motivation and behavior, much of which\ncould be repurposed to problems involving AI models, and enumerate reasons why\nthis is so. We introduce an alternate alignment approach informed by social\nscience tools and characterized by three steps: 1. defining a positive desired\nsocial outcome for human/AI collaboration as the goal or \"North Star,\" 2.\nproperly framing knowns and unknowns, and 3. forming diverse teams to\ninvestigate, observe, and navigate emerging challenges in alignment.",
      "tldr_zh": "该论文指出，现有的AI安全（AI safety）和对齐（alignment）方法可能未采用最有效的工具、团队或策略，建议将对齐问题视为社会科学问题，因为社会科学提供了丰富的模型来理解和调整动机与行为，并可应用于AI模型。论文提出一种基于社会科学的新对齐方法，包括三个关键步骤：1. 定义人类/AI协作的积极社会结果作为目标；2. 正确框架已知和未知因素；3. 组建多样化团队来调查、观察并应对对齐挑战。这种方法强调多样化团队的重要性，以提升AI安全性和有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.10254v1",
      "published_date": "2024-05-07 02:05:23 UTC",
      "updated_date": "2024-05-07 02:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:52:46.293923"
    },
    {
      "arxiv_id": "2405.03942v1",
      "title": "Collaborative Intelligence in Sequential Experiments: A Human-in-the-Loop Framework for Drug Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghai He",
        "Cheng Hua",
        "Yingfei Wang",
        "Zeyu Zheng"
      ],
      "abstract": "Drug discovery is a complex process that involves sequentially screening and\nexamining a vast array of molecules to identify those with the target\nproperties. This process, also referred to as sequential experimentation, faces\nchallenges due to the vast search space, the rarity of target molecules, and\nconstraints imposed by limited data and experimental budgets. To address these\nchallenges, we introduce a human-in-the-loop framework for sequential\nexperiments in drug discovery. This collaborative approach combines human\nexpert knowledge with deep learning algorithms, enhancing the discovery of\ntarget molecules within a specified experimental budget. The proposed algorithm\nprocesses experimental data to recommend both promising molecules and those\nthat could improve its performance to human experts. Human experts retain the\nfinal decision-making authority based on these recommendations and their domain\nexpertise, including the ability to override algorithmic recommendations. We\napplied our method to drug discovery tasks using real-world data and found that\nit consistently outperforms all baseline methods, including those which rely\nsolely on human or algorithmic input. This demonstrates the complementarity\nbetween human experts and the algorithm. Our results provide key insights into\nthe levels of humans' domain knowledge, the importance of meta-knowledge, and\neffective work delegation strategies. Our findings suggest that such a\nframework can significantly accelerate the development of new vaccines and\ndrugs by leveraging the best of both human and artificial intelligence.",
      "tldr_zh": "该论文提出了一种 Human-in-the-Loop 框架，用于药物发现中的顺序实验，该框架将人类专家知识与深度学习算法相结合，以应对搜索空间大、目标分子稀少和资源限制等挑战。算法处理实验数据，推荐有前景的分子并建议改进自身性能的分子，同时允许人类专家拥有最终决策权，包括覆盖算法建议。在真实世界数据上的应用显示，该方法优于仅依赖人类或算法的基线模型，突显了二者的互补性，并提供洞见如人类领域知识和元知识的重要性，从而加速新疫苗和药物的开发。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03942v1",
      "published_date": "2024-05-07 02:03:07 UTC",
      "updated_date": "2024-05-07 02:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:52:58.250004"
    },
    {
      "arxiv_id": "2405.03932v2",
      "title": "CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion",
      "title_zh": "CleanGraph: 人类在环中的知识图谱细化和完善",
      "authors": [
        "Tyler Bikaun",
        "Michael Stewart",
        "Wei Liu"
      ],
      "abstract": "This paper presents CleanGraph, an interactive web-based tool designed to\nfacilitate the refinement and completion of knowledge graphs. Maintaining the\nreliability of knowledge graphs, which are grounded in high-quality and\nerror-free facts, is crucial for real-world applications such as\nquestion-answering and information retrieval systems. These graphs are often\nautomatically assembled from textual sources by extracting semantic triples via\ninformation extraction. However, assuring the quality of these extracted\ntriples, especially when dealing with large or low-quality datasets, can pose a\nsignificant challenge and adversely affect the performance of downstream\napplications. CleanGraph allows users to perform Create, Read, Update, and\nDelete (CRUD) operations on their graphs, as well as apply models in the form\nof plugins for graph refinement and completion tasks. These functionalities\nenable users to enhance the integrity and reliability of their graph data. A\ndemonstration of CleanGraph and its source code can be accessed at\nhttps://github.com/nlp-tlp/CleanGraph under the MIT License.",
      "tldr_zh": "论文提出了 CleanGraph，这是一个人类在循环（Human-in-the-loop）的交互式网络工具，用于知识图谱（Knowledge Graph）的完善和完成。CleanGraph 允许用户进行 CRUD（Create, Read, Update, Delete）操作，并通过插件形式的模型处理从文本来源提取的语义三元组，从而解决自动构建图谱时的数据质量问题。实验表明，该工具能显著提升知识图谱的可靠性和完整性，支持下游应用如问答和信息检索系统的性能，并提供了开源代码以供进一步演示。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03932v2",
      "published_date": "2024-05-07 01:40:23 UTC",
      "updated_date": "2024-05-08 00:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:53:10.820563"
    },
    {
      "arxiv_id": "2405.03929v2",
      "title": "Unicorn: U-Net for Sea Ice Forecasting with Convolutional Neural Ordinary Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Jaesung Park",
        "Sungchul Hong",
        "Yoonseo Cho",
        "Jong-June Jeon"
      ],
      "abstract": "Sea ice at the North Pole is vital to global climate dynamics. However,\naccurately forecasting sea ice poses a significant challenge due to the\nintricate interaction among multiple variables. Leveraging the capability to\nintegrate multiple inputs and powerful performances seamlessly, many studies\nhave turned to neural networks for sea ice forecasting. This paper introduces a\nnovel deep architecture named Unicorn, designed to forecast weekly sea ice. Our\nmodel integrates multiple time series images within its architecture to enhance\nits forecasting performance. Moreover, we incorporate a bottleneck layer within\nthe U-Net architecture, serving as neural ordinary differential equations with\nconvolution operations, to capture the spatiotemporal dynamics of latent\nvariables. Through real data analysis with datasets spanning from 1998 to 2021,\nour proposed model demonstrates significant improvements over state-of-the-art\nmodels in the sea ice concentration forecasting task. It achieves an average\nMAE improvement of 12% compared to benchmark models. Additionally, our method\noutperforms existing approaches in sea ice extent forecasting, achieving a\nclassification performance improvement of approximately 18%. These experimental\nresults show the superiority of our proposed model.",
      "tldr_zh": "本文提出Unicorn模型，一种基于U-Net架构的深度学习框架，用于预测每周海冰变化，该模型整合多个时间序列图像并通过Convolutional Neural Ordinary Differential Equations的瓶颈层捕捉潜在变量的时空动态。相比现有模型，Unicorn在海冰浓度预测任务上实现了平均MAE改善12%，并在海冰范围预测中提升分类性能约18%。实验结果基于1998-2021年真实数据集，证明了该方法的优越性。",
      "categories": [
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03929v2",
      "published_date": "2024-05-07 01:17:06 UTC",
      "updated_date": "2024-09-02 03:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:53:22.729252"
    },
    {
      "arxiv_id": "2405.03924v2",
      "title": "NeurDB: An AI-powered Autonomous Data System",
      "title_zh": "翻译失败",
      "authors": [
        "Beng Chin Ooi",
        "Shaofeng Cai",
        "Gang Chen",
        "Yanyan Shen",
        "Kian-Lee Tan",
        "Yuncheng Wu",
        "Xiaokui Xiao",
        "Naili Xing",
        "Cong Yue",
        "Lingze Zeng",
        "Meihui Zhang",
        "Zhanhao Zhao"
      ],
      "abstract": "In the wake of rapid advancements in artificial intelligence (AI), we stand\non the brink of a transformative leap in data systems. The imminent fusion of\nAI and DB (AIxDB) promises a new generation of data systems, which will relieve\nthe burden on end-users across all industry sectors by featuring AI-enhanced\nfunctionalities, such as personalized and automated in-database AI-powered\nanalytics, self-driving capabilities for improved system performance, etc. In\nthis paper, we explore the evolution of data systems with a focus on deepening\nthe fusion of AI and DB. We present NeurDB, an AI-powered autonomous data\nsystem designed to fully embrace AI design in each major system component and\nprovide in-database AI-powered analytics. We outline the conceptual and\narchitectural overview of NeurDB, discuss its design choices and key\ncomponents, and report its current development and future plan.",
      "tldr_zh": "该论文探讨了人工智能（AI）和数据库（DB）的深度融合（AIxDB），旨在通过AI增强功能（如个性化自动化分析和自驱动能力）来减轻用户负担，并推动数据系统演变。作者介绍了NeurDB，一种AI-powered自主数据系统，在每个主要组件中全面融入AI设计，提供数据库内的AI-powered analytics。NeurDB的架构概述了其关键设计选择和组件，并报告了当前的开发进展及未来计划，为新一代数据系统奠定基础。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03924v2",
      "published_date": "2024-05-07 00:51:48 UTC",
      "updated_date": "2024-07-04 08:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:53:33.602122"
    },
    {
      "arxiv_id": "2405.03920v1",
      "title": "A Roadmap for Multilingual, Multimodal Domain Independent Deception Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Dainis Boumber",
        "Rakesh M. Verma",
        "Fatima Zahra Qachfar"
      ],
      "abstract": "Deception, a prevalent aspect of human communication, has undergone a\nsignificant transformation in the digital age. With the globalization of online\ninteractions, individuals are communicating in multiple languages and mixing\nlanguages on social media, with varied data becoming available in each language\nand dialect. At the same time, the techniques for detecting deception are\nsimilar across the board. Recent studies have shown the possibility of the\nexistence of universal linguistic cues to deception across domains within the\nEnglish language; however, the existence of such cues in other languages\nremains unknown. Furthermore, the practical task of deception detection in\nlow-resource languages is not a well-studied problem due to the lack of labeled\ndata. Another dimension of deception is multimodality. For example, a picture\nwith an altered caption in fake news or disinformation may exist. This paper\ncalls for a comprehensive investigation into the complexities of deceptive\nlanguage across linguistic boundaries and modalities within the realm of\ncomputer security and natural language processing and the possibility of using\nmultilingual transformer models and labeled data in various languages to\nuniversally address the task of deception detection.",
      "tldr_zh": "该论文概述了在计算机安全和自然语言处理领域中，进行多语言（Multilingual）和多模态（Multimodal）欺骗检测的路线图（Roadmap），强调欺骗行为在数字时代跨语言和领域的复杂性。研究发现，英语中存在通用语言线索（universal linguistic cues）用于检测欺骗，但其他语言和低资源语言（low-resource languages）缺乏相关研究和标记数据（labeled data）。论文呼吁通过利用多语言Transformer模型和跨语言标记数据，进行全面调查，以实现独立于领域的欺骗检测，并解决多模态挑战，如假新闻中的图片篡改。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM",
        "I.2.6; I.2.7; I.2.10; K.4.4"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure, shorter version in SIAM International Conference\n  on Data Mining (SDM) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03920v1",
      "published_date": "2024-05-07 00:38:34 UTC",
      "updated_date": "2024-05-07 00:38:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:53:46.944996"
    },
    {
      "arxiv_id": "2405.03911v4",
      "title": "Federated Graph Condensation with Information Bottleneck Principles",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Yan",
        "Sihao He",
        "Cheng Yang",
        "Shang Liu",
        "Yang Cao",
        "Chuan Shi"
      ],
      "abstract": "Graph condensation (GC), which reduces the size of a large-scale graph by\nsynthesizing a small-scale condensed graph as its substitution, has benefited\nvarious graph learning tasks. However, existing GC methods rely on centralized\ndata storage, which is unfeasible for real-world decentralized data\ndistribution, and overlook data holders' privacy-preserving requirements. To\nbridge this gap, we propose and study the novel problem of federated graph\ncondensation (FGC) for graph neural networks (GNNs). Specifically, we first\npropose a general framework for FGC, where we decouple the typical gradient\nmatching process for GC into client-side gradient calculation and server-side\ngradient matching, integrating knowledge from multiple clients' subgraphs into\none smaller condensed graph. Nevertheless, our empirical studies show that\nunder the federated setting, the condensed graph will consistently leak data\nmembership privacy, i.e., the condensed graph during federated training can be\nutilized to steal training data under the membership inference attack (MIA). To\ntackle this issue, we innovatively incorporate information bottleneck\nprinciples into the FGC, which only needs to extract partial node features in\none local pre-training step and utilize the features during federated training.\nTheoretical and experimental analyses demonstrate that our framework\nconsistently protects membership privacy during training. Meanwhile, it can\nachieve comparable and even superior performance against existing centralized\nGC and federated graph learning (FGL) methods.",
      "tldr_zh": "本文提出联邦图凝缩 (Federated Graph Condensation, FGC) 的新问题，针对图神经网络 (Graph Neural Networks, GNNs) 在去中心化数据分布和隐私保护方面的挑战，设计了一个通用框架，将梯度匹配过程解耦为客户端侧计算和服务器侧匹配，以整合多个客户端子图知识生成小型凝缩图。针对凝缩图可能泄露数据成员隐私的问题（如成员推理攻击，Membership Inference Attack, MIA），作者创新性地融入信息瓶颈原则 (Information Bottleneck Principles)，仅提取部分节点特征进行本地预训练，从而在联邦训练中保护隐私。实验和理论分析显示，该框架在保持与集中式图凝缩 (Graph Condensation, GC) 或联邦图学习 (Federated Graph Learning, FGL) 方法相当性能的同时，有效提升了隐私安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages. Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.03911v4",
      "published_date": "2024-05-07 00:08:15 UTC",
      "updated_date": "2024-12-20 07:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:54:00.897830"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 109,
  "processed_papers_count": 109,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T06:54:25.414051"
}