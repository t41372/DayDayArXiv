{
  "date": "2024-04-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-15 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化（如 LLM 的偏置缓解和安全保障）、生成式 AI、多模态学习以及应用领域创新，亮点包括 Yejin Choi 等知名学者参与的 LLM 安全研究，以及高效的视觉生成和强化学习方法，强调了模型泛化、隐私保护和实际应用潜力。\n\n### 重点论文讨论\n我挑选了其中最具话题度和影响力的论文先聊，这些涉及热门 AI 方向，如 LLM 偏置、安全、生成模型和多模态处理。相关论文按主题归类，以突出贡献。\n\n**LLM 偏置与安全（Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs）**  \n标题：从多角色辩论反馈的强化学习缓解 LLM 中的偏置（Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs）  \n作者包括 Tsendsuren Munkhdalai 和 Yejin Choi 等知名学者。该论文提出 RLDF 方法，使用 LLM 模拟多角色辩论生成偏置数据集，训练奖励模型以缓解 LLM 偏置。贡献在于无需人类反馈即可减少偏置，实验在 BBQ 数据集上显示显著改善，强调 LLM 在 AI 安全中的潜力。\n\n**LLM 安全与泛化（Foundational Challenges in Assuring Alignment and Safety of Large Language Models）**  \n标题：确保 LLM 对齐和安全的基本挑战（Foundational Challenges in Assuring Alignment and Safety of Large Language Models）  \nYejin Choi 和 David Krueger 等学者参与，这篇论文系统总结了 LLM 对齐和安全的 18 个基础挑战，并提出 200+ 研究问题。发现在于强调科学理解、部署方法和社技术挑战的平衡，促进未来 AI 安全研究。\n\n**生成式 AI 和扩散模型（Taming Latent Diffusion Model for Neural Radiance Field Inpainting）**  \n标题：驯服潜在扩散模型用于神经辐射场修复（Taming Latent Diffusion Model for Neural Radiance Field Inpainting）  \n该工作提出 MALD-NeRF 框架，使用掩码对抗训练和语义一致性优化扩散模型，针对 3D 场景修复。贡献包括减少扩散模型的随机性，提高 NeRF 修复质量，实验在真实场景上实现 SOTA 性能，适用于增强现实和 3D 生成。\n\n**多模态学习与视觉生成（RankCLIP: Ranking-Consistent Language-Image Pretraining）**  \n标题：排名一致的语言-图像预训练（RankCLIP: Ranking-Consistent Language-Image Pretraining）  \n论文扩展 CLIP 模型，使用列表式损失和跨模态排名一致性捕捉多对多关系。发现在于提升零样本分类准确率，实验超越 SOTA，适用于图像生成和检索任务。\n\n**强化学习与应用（Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL）**  \n标题：使用视觉基础模型和离线强化学习增强具身视觉跟踪（Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL）  \n该论文结合视觉基础模型（如 Tracking Anything）和离线 RL，提出框架提升跟踪鲁棒性。贡献包括高效训练和泛化能力，实验在复杂环境中超越 SOTA，适用于机器人导航。\n\n**其他亮点论文快速掠过**  \n- **EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning**（EyeFormer: 使用 Transformer 引导的强化学习预测个性化扫描路径）  \n  贡献：使用 Transformer 和 RL 预测个性化眼动路径，应用于 GUI 优化，实验在视觉感知任务中表现出色。\n  \n- **Compression Represents Intelligence Linearly**（压缩线性代表智能）  \n  贡献：证明 LLM 的压缩效率与智能指标线性相关，实验在 31 个模型上验证，提升 LLM 评估方法。\n  \n- **Optimal Kernel Tuning Parameter Prediction using Deep Sequence Models**（使用深度序列模型预测最优内核调优参数）  \n  贡献：将内核调优视为序列翻译问题，使用深度模型预测 GPU 内核参数，实验在 MIOpen 上实现 90% 准确率。\n\n### 其他论文简要归纳\n剩余论文涉及领域广泛，如地震数据处理（High-Resolution Detection of Earth Structural Heterogeneities from Seismic Amplitudes using Convolutional Neural Networks with Attention layers）、分子通信（Building Semantic Communication System via Molecules: An End-to-End Training Approach）和知识图谱（Progressive Knowledge Graph Completion），但这些相对专业或应用导向，不如上述主题有话题度。总体上，它们展示了 AI 在科学模拟、图神经网络和多模态任务中的进展，但细节较琐碎，建议感兴趣读者查阅特定论文。\n\n今天的 arXiv 更新突显 AI 模型的优化和应用潜力，期待这些创新推动更可靠的 AI 系统！",
  "papers": [
    {
      "arxiv_id": "2404.10180v2",
      "title": "Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Zelin Wu",
        "Gan Song",
        "Christopher Li",
        "Pat Rondon",
        "Zhong Meng",
        "Xavier Velez",
        "Weiran Wang",
        "Diamantino Caseiro",
        "Golan Pundak",
        "Tsendsuren Munkhdalai",
        "Angad Chandorkar",
        "Rohit Prabhavalkar"
      ],
      "abstract": "Contextual biasing enables speech recognizers to transcribe important phrases\nin the speaker's context, such as contact names, even if they are rare in, or\nabsent from, the training data. Attention-based biasing is a leading approach\nwhich allows for full end-to-end cotraining of the recognizer and biasing\nsystem and requires no separate inference-time components. Such biasers\ntypically consist of a context encoder; followed by a context filter which\nnarrows down the context to apply, improving per-step inference time; and,\nfinally, context application via cross attention. Though much work has gone\ninto optimizing per-frame performance, the context encoder is at least as\nimportant: recognition cannot begin before context encoding ends. Here, we show\nthe lightweight phrase selection pass can be moved before context encoding,\nresulting in a speedup of up to 16.1 times and enabling biasing to scale to 20K\nphrases with a maximum pre-decoding delay under 33ms. With the addition of\nphrase- and wordpiece-level cross-entropy losses, our technique also achieves\nup to a 37.5% relative WER reduction over the baseline without the losses and\nlightweight phrase selection pass.",
      "tldr_zh": "该论文提出了 Deferred NAM 方法，用于非流式 ASR（Automatic Speech Recognition）的低延迟 Top-K 上下文注入，旨在通过上下文偏差（contextual biasing）提升对稀有短语的识别准确性，如联系人姓名。创新点在于将轻量级短语选择步骤移至上下文编码之前，实现高达16.1倍的速度提升，并支持20K短语的处理，同时保持最大预解码延迟低于33ms。实验结果显示，通过添加短语和词片级交叉熵损失（cross-entropy losses），该方法相较基线降低了37.5%的相对 WER（Word Error Rate）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures, accepted by NAACL 2024 - Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2404.10180v2",
      "published_date": "2024-04-15 23:28:13 UTC",
      "updated_date": "2024-04-23 13:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:23:38.130119"
    },
    {
      "arxiv_id": "2404.10170v1",
      "title": "High-Resolution Detection of Earth Structural Heterogeneities from Seismic Amplitudes using Convolutional Neural Networks with Attention layers",
      "title_zh": "翻译失败",
      "authors": [
        "Luiz Schirmer",
        "Guilherme Schardong",
        "Vinícius da Silva",
        "Rogério Santos",
        "Hélio Lopes"
      ],
      "abstract": "Earth structural heterogeneities have a remarkable role in the petroleum\neconomy for both exploration and production projects. Automatic detection of\ndetailed structural heterogeneities is challenging when considering modern\nmachine learning techniques like deep neural networks. Typically, these\ntechniques can be an excellent tool for assisted interpretation of such\nheterogeneities, but it heavily depends on the amount of data to be trained.\n  We propose an efficient and cost-effective architecture for detecting seismic\nstructural heterogeneities using Convolutional Neural Networks (CNNs) combined\nwith Attention layers. The attention mechanism reduces costs and enhances\naccuracy, even in cases with relatively noisy data. Our model has half the\nparameters compared to the state-of-the-art, and it outperforms previous\nmethods in terms of Intersection over Union (IoU) by 0.6% and precision by\n0.4%. By leveraging synthetic data, we apply transfer learning to train and\nfine-tune the model, addressing the challenge of limited annotated data\navailability.",
      "tldr_zh": "该研究针对地震振幅中地球结构异质性（Earth structural heterogeneities）的自动检测问题，提出了一种高效架构，使用 Convolutional Neural Networks (CNNs) 结合 Attention layers，以提升石油勘探和生产的准确性。该方法通过 Attention 机制减少模型参数（仅为现有最先进模型的一半），并在噪声数据环境下提高性能，在 Intersection over Union (IoU) 上提升 0.6%，精度提升 0.4%。此外，研究采用合成数据和 transfer learning 技术，解决了标注数据不足的挑战，提供了一个成本效益高的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10170v1",
      "published_date": "2024-04-15 22:49:37 UTC",
      "updated_date": "2024-04-15 22:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:23:49.277024"
    },
    {
      "arxiv_id": "2404.10163v2",
      "title": "EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning",
      "title_zh": "EyeFormer：利用 Transformer 指导的强化学习",
      "authors": [
        "Yue Jiang",
        "Zixin Guo",
        "Hamed Rezazadegan Tavakoli",
        "Luis A. Leiva",
        "Antti Oulasvirta"
      ],
      "abstract": "From a visual perception perspective, modern graphical user interfaces (GUIs)\ncomprise a complex graphics-rich two-dimensional visuospatial arrangement of\ntext, images, and interactive objects such as buttons and menus. While existing\nmodels can accurately predict regions and objects that are likely to attract\nattention ``on average'', so far there is no scanpath model capable of\npredicting scanpaths for an individual. To close this gap, we introduce\nEyeFormer, which leverages a Transformer architecture as a policy network to\nguide a deep reinforcement learning algorithm that controls gaze locations. Our\nmodel has the unique capability of producing personalized predictions when\ngiven a few user scanpath samples. It can predict full scanpath information,\nincluding fixation positions and duration, across individuals and various\nstimulus types. Additionally, we demonstrate applications in GUI layout\noptimization driven by our model. Our software and models will be publicly\navailable.",
      "tldr_zh": "论文介绍了 EyeFormer，一种基于 Transformer 架构作为策略网络的模型，结合深度强化学习 (deep reinforcement learning) 来预测个性化的扫描路径 (scanpaths)，以解决现有模型无法准确预测个体注意力的局限性。该模型通过少量用户扫描路径样本生成个性化预测，包括注视位置和持续时间，适用于不同个体和各种刺激类型。此外，EyeFormer 展示了在图形用户界面 (GUIs) 布局优化中的实际应用，并计划公开软件和模型以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10163v2",
      "published_date": "2024-04-15 22:26:27 UTC",
      "updated_date": "2024-04-21 03:17:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:24:01.487801"
    },
    {
      "arxiv_id": "2404.10162v1",
      "title": "Optimal Kernel Tuning Parameter Prediction using Deep Sequence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Khawir Mahmood",
        "Jehandad Khan",
        "Hammad Afzal"
      ],
      "abstract": "GPU kernels have come to the forefront of computing due to their utility in\nvaried fields, from high-performance computing to machine learning. A typical\nGPU compute kernel is invoked millions, if not billions of times in a typical\napplication, which makes their performance highly critical. Due to the unknown\nnature of the optimization surface, an exhaustive search is required to\ndiscover the global optimum, which is infeasible due to the possible\nexponential number of parameter combinations. In this work, we propose a\nmethodology that uses deep sequence-to-sequence models to predict the optimal\ntuning parameters governing compute kernels. This work considers the prediction\nof kernel parameters as a sequence to the sequence translation problem,\nborrowing models from the Natural Language Processing (NLP) domain. Parameters\ndescribing the input, output and weight tensors are considered as the input\nlanguage to the model that emits the corresponding kernel parameters. In\nessence, the model translates the problem parameter language to kernel\nparameter language. The core contributions of this work are: a) Proposing that\na sequence to sequence model can accurately learn the performance dynamics of a\nGPU compute kernel b) A novel network architecture which predicts the kernel\ntuning parameters for GPU kernels, c) A constrained beam search which\nincorporates the physical limits of the GPU hardware as well as other expert\nknowledge reducing the search space. The proposed algorithm can achieve more\nthan 90% accuracy on various convolutional kernels in MIOpen, the AMD machine\nlearning primitives library. As a result, the proposed technique can reduce the\ndevelopment time and compute resources required to tune unseen input\nconfigurations, resulting in shorter development cycles, reduced development\ncosts, and better user experience.",
      "tldr_zh": "该论文针对GPU内核调优参数的优化问题，提出一种使用深度序列到序列模型（deep sequence-to-sequence models）的方法，将参数预测视为序列翻译任务，借鉴自然语言处理（NLP）领域的技术，以输入张量参数为输入，输出最佳内核参数。核心贡献包括：证明序列模型能准确学习GPU内核的性能动态、设计一个新颖的网络架构，以及引入受限beam search以整合GPU硬件限制和专家知识。实验结果显示，该方法在MIOpen库的各种卷积内核上实现90%以上准确率，从而显著减少开发时间、计算资源和成本，提高用户体验。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10162v1",
      "published_date": "2024-04-15 22:25:54 UTC",
      "updated_date": "2024-04-15 22:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:24:13.807882"
    },
    {
      "arxiv_id": "2404.10160v6",
      "title": "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoxi Cheng",
        "Haoxuan Ma",
        "Shuirong Cao",
        "Jiaqi Li",
        "Aihua Pei",
        "Zhiqiang Wang",
        "Pengliang Ji",
        "Haoyu Wang",
        "Jiaqi Huo"
      ],
      "abstract": "Bias in LLMs can harm user experience and societal outcomes. However, current\nbias mitigation methods often require intensive human feedback, lack\ntransferability to other topics or yield overconfident and random outputs. We\nfind that involving LLMs in role-playing scenario boosts their ability to\nrecognize and mitigate biases. Based on this, we propose Reinforcement Learning\nfrom Multi-role Debates as Feedback (RLDF), a novel approach for bias\nmitigation replacing human feedback in traditional RLHF. We utilize LLMs in\nmulti-role debates to create a dataset that includes both high-bias and\nlow-bias instances for training the reward model in reinforcement learning. Our\napproach comprises two modes: (1) self-reflection, where the same LLM\nparticipates in multi-role debates, and (2) teacher-student, where a more\nadvanced LLM like GPT-3.5-turbo guides the LLM to perform this task.\nExperimental results across different LLMs on BBQ and our datasets demonstrate\nthe effectiveness of our approach in bias mitigation. Our source code and\ndatasets are available at \\texttt{https://anonymous.4open.science/r/RLDF-E344}.",
      "tldr_zh": "这篇论文提出了一种名为 Reinforcement Learning from Multi-role Debates as Feedback (RLDF) 的方法，用于缓解大型语言模型 (LLMs) 中的偏见问题，通过多角色辩论取代传统 RLHF 中的人类反馈，从而提高方法的可转移性和输出质量。RLDF 利用 LLMs 参与辩论创建包含高偏见和低偏见实例的数据集，并包括自我反思模式（同一 LLM 参与）和师生模式（先进 LLM 如 GPT-3.5-turbo 指导），以训练强化学习的奖励模型。实验结果显示，在 BBQ 和自定义数据集上，该方法显著提升了不同 LLMs 的偏见缓解效果，证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The first three authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2404.10160v6",
      "published_date": "2024-04-15 22:18:50 UTC",
      "updated_date": "2024-08-16 12:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:24:25.749534"
    },
    {
      "arxiv_id": "2404.10142v2",
      "title": "Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Faraz Faruqi",
        "Yingtao Tian",
        "Vrushank Phadnis",
        "Varun Jampani",
        "Stefanie Mueller"
      ],
      "abstract": "Generative AI tools are becoming more prevalent in 3D modeling, enabling\nusers to manipulate or create new models with text or images as inputs. This\nmakes it easier for users to rapidly customize and iterate on their 3D designs\nand explore new creative ideas. These methods focus on the aesthetic quality of\nthe 3D models, refining them to look similar to the prompts provided by the\nuser. However, when creating 3D models intended for fabrication, designers need\nto trade-off the aesthetic qualities of a 3D model with their intended physical\nproperties. To be functional post-fabrication, 3D models have to satisfy\nstructural constraints informed by physical principles. Currently, such\nrequirements are not enforced by generative AI tools. This leads to the\ndevelopment of aesthetically appealing, but potentially non-functional 3D\ngeometry, that would be hard to fabricate and use in the real world. This\nworkshop paper highlights the limitations of generative AI tools in translating\ndigital creations into the physical world and proposes new augmentations to\ngenerative AI tools for creating physically viable 3D models. We advocate for\nthe development of tools that manipulate or generate 3D models by considering\nnot only the aesthetic appearance but also using physical properties as\nconstraints. This exploration seeks to bridge the gap between digital\ncreativity and real-world applicability, extending the creative potential of\ngenerative AI into the tangible domain.",
      "tldr_zh": "这篇论文讨论了生成式AI工具在3D建模中的局限性，这些工具虽能通过文本或图像输入快速创建美观模型，但忽略了制造约束，导致生成的3D模型可能在物理世界中不可用或功能性差。作者提出增强方案，通过将物理属性（如结构约束和物理原则）作为生成过程的约束条件，来平衡模型的美学质量和实际可制造性。该方法旨在开发更先进的工具，实现数字创意与现实世界的无缝桥接，从而扩展生成式AI在 tangible domain 中的应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10142v2",
      "published_date": "2024-04-15 21:22:57 UTC",
      "updated_date": "2024-04-17 02:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:24:35.987230"
    },
    {
      "arxiv_id": "2404.10136v1",
      "title": "Language Model Cascades: Token-level uncertainty and beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Neha Gupta",
        "Harikrishna Narasimhan",
        "Wittawat Jitkrittum",
        "Ankit Singh Rawat",
        "Aditya Krishna Menon",
        "Sanjiv Kumar"
      ],
      "abstract": "Recent advances in language models (LMs) have led to significant improvements\nin quality on complex NLP tasks, but at the expense of increased inference\ncosts. Cascading offers a simple strategy to achieve more favorable\ncost-quality tradeoffs: here, a small model is invoked for most \"easy\"\ninstances, while a few \"hard\" instances are deferred to the large model. While\nthe principles underpinning cascading are well-studied for classification tasks\n- with deferral based on predicted class uncertainty favored theoretically and\npractically - a similar understanding is lacking for generative LM tasks. In\nthis work, we initiate a systematic study of deferral rules for LM cascades. We\nbegin by examining the natural extension of predicted class uncertainty to\ngenerative LM tasks, namely, the predicted sequence uncertainty. We show that\nthis measure suffers from the length bias problem, either over- or\nunder-emphasizing outputs based on their lengths. This is because LMs produce a\nsequence of uncertainty values, one for each output token; and moreover, the\nnumber of output tokens is variable across examples. To mitigate this issue, we\npropose to exploit the richer token-level uncertainty information implicit in\ngenerative LMs. We argue that naive predicted sequence uncertainty corresponds\nto a simple aggregation of these uncertainties. By contrast, we show that\nincorporating token-level uncertainty through learned post-hoc deferral rules\ncan significantly outperform such simple aggregation strategies, via\nexperiments on a range of natural language benchmarks with FLAN-T5 models. We\nfurther show that incorporating embeddings from the smaller model and\nintermediate layers of the larger model can give an additional boost in the\noverall cost-quality tradeoff.",
      "tldr_zh": "本文研究了语言模型（LMs）在复杂 NLP 任务中质量提升与推理成本增加的权衡问题，提出了一种级联（cascading）策略，使用小模型处理“简单”实例，将“困难”实例递交给大模型以优化成本-质量权衡。作者发现，传统预测序列不确定性（predicted sequence uncertainty）存在长度偏差问题，因此开发了基于 token-level uncertainty 的学习后验递交规则，以更好地利用生成式 LMs 的不确定性信息。实验在多种自然语言基准上使用 FLAN-T5 模型表明，这种方法显著优于简单聚合策略，且通过整合小模型嵌入和大模型中间层嵌入，进一步提升了整体权衡效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10136v1",
      "published_date": "2024-04-15 21:02:48 UTC",
      "updated_date": "2024-04-15 21:02:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:24:49.490358"
    },
    {
      "arxiv_id": "2404.10135v2",
      "title": "Using Long Short-term Memory (LSTM) to merge precipitation data over mountainous area in Sierra Nevada",
      "title_zh": "使用长短期记忆网络 (LSTM) 合并 Sierra Nevada 山区降水数据",
      "authors": [
        "Yihan Wang",
        "Lujun Zhang"
      ],
      "abstract": "Obtaining reliable precipitation estimation with high resolutions in time and\nspace is of great importance to hydrological studies. However, accurately\nestimating precipitation is a challenging task over high mountainous complex\nterrain. The three widely used precipitation measurement approaches, namely\nrainfall gauge, precipitation radars, and satellite-based precipitation\nsensors, have their own pros and cons in producing reliable precipitation\nproducts over complex areas. One way to decrease the detection error\nprobability and improve data reliability is precipitation data merging. With\nthe rapid advancements in computational capabilities and the escalating volume\nand diversity of earth observational data, Deep Learning (DL) models have\ngained considerable attention in geoscience. In this study, a deep learning\ntechnique, namely Long Short-term Memory (LSTM), was employed to merge a\nradar-based and a satellite-based Global Precipitation Measurement (GPM)\nprecipitation product Integrated Multi-Satellite Retrievals for GPM (IMERG)\nprecipitation product at hourly scale. The merged results are compared with the\nwidely used reanalysis precipitation product, Multi-Radar Multi-Sensor (MRMS),\nand assessed against gauge observational data from the California Data Exchange\nCenter (CDEC). The findings indicated that the LSTM-based merged precipitation\nnotably underestimated gauge observations and, at times, failed to provide\nmeaningful estimates, showing predominantly near-zero values. Relying solely on\nindividual Quantitative Precipitation Estimates (QPEs) without additional\nmeteorological input proved insufficient for generating reliable merged QPE.\nHowever, the merged results effectively captured the temporal trends of the\nobservations, outperforming MRMS in this aspect. This suggested that\nincorporating bias correction techniques could potentially enhance the accuracy\nof the merged product.",
      "tldr_zh": "本研究使用Long Short-term Memory (LSTM) 深度学习模型，合并雷达-based和卫星-based Global Precipitation Measurement (GPM) IMERG降水产品，以提高Sierra Nevada山区复杂地形的降水估计准确性。研究将LSTM合并结果与Multi-Radar Multi-Sensor (MRMS)再分析产品比较，并通过California Data Exchange Center (CDEC)的观测数据进行评估。结果显示，LSTM合并数据显著低估了观测值，且有时输出近零值，仅靠单个Quantitative Precipitation Estimates (QPE)不足以产生可靠结果；然而，它在捕捉降水的时间趋势上优于MRMS。作者建议整合偏差修正技术，以进一步提升合并产品的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10135v2",
      "published_date": "2024-04-15 21:01:31 UTC",
      "updated_date": "2024-04-19 22:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:25:00.579584"
    },
    {
      "arxiv_id": "2404.15834v1",
      "title": "FEDSTR: Money-In AI-Out | A Decentralized Marketplace for Federated Learning and LLM Training on the NOSTR Protocol",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos E. Nikolakakis",
        "George Chantzialexiou",
        "Dionysis Kalogerias"
      ],
      "abstract": "The NOSTR is a communication protocol for the social web, based on the w3c\nwebsockets standard. Although it is still in its infancy, it is well known as a\nsocial media protocol, thousands of trusted users and multiple user interfaces,\noffering a unique experience and enormous capabilities. To name a few, the\nNOSTR applications include but are not limited to direct messaging, file\nsharing, audio/video streaming, collaborative writing, blogging and data\nprocessing through distributed AI directories. In this work, we propose an\napproach that builds upon the existing protocol structure with end goal a\ndecentralized marketplace for federated learning and LLM training. In this\nproposed design there are two parties: on one side there are customers who\nprovide a dataset that they want to use for training an AI model. On the other\nside, there are service providers, who receive (parts of) the dataset, train\nthe AI model, and for a payment as an exchange, they return the optimized AI\nmodel. The decentralized and censorship resistant features of the NOSTR enable\nthe possibility of designing a fair and open marketplace for training AI models\nand LLMs.",
      "tldr_zh": "本文提出 FEDSTR，一种基于 NOSTR Protocol 的去中心化市场，旨在为 Federated Learning 和 LLM Training 提供一个公平开放的平台。系统设计中，客户提供数据集，服务提供者接收数据集的部分内容进行模型训练，并通过支付交换优化后的 AI 模型。这种方法利用 NOSTR 的去中心化和抗审查特性，确保市场运作的安全性和可访问性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.15834v1",
      "published_date": "2024-04-15 20:51:38 UTC",
      "updated_date": "2024-04-15 20:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:25:13.024786"
    },
    {
      "arxiv_id": "2404.10102v2",
      "title": "Chinchilla Scaling: A replication attempt",
      "title_zh": "翻译失败",
      "authors": [
        "Tamay Besiroglu",
        "Ege Erdil",
        "Matthew Barnett",
        "Josh You"
      ],
      "abstract": "Hoffmann et al. (2022) propose three methods for estimating a compute-optimal\nscaling law. We attempt to replicate their third estimation procedure, which\ninvolves fitting a parametric loss function to a reconstruction of data from\ntheir plots. We find that the reported estimates are inconsistent with their\nfirst two estimation methods, fail at fitting the extracted data, and report\nimplausibly narrow confidence intervals--intervals this narrow would require\nover 600,000 experiments, while they likely only ran fewer than 500. In\ncontrast, our rederivation of the scaling law using the third approach yields\nresults that are compatible with the findings from the first two estimation\nprocedures described by Hoffmann et al.",
      "tldr_zh": "这篇论文尝试复制 Hoffmann et al. (2022) 提出的 Chinchilla Scaling 计算最优缩放定律的第三种估计方法，该方法涉及拟合参数损失函数以重建数据。研究发现，原论文的估计结果与前两种方法不一致，无法准确拟合提取的数据，并报告了不合理的窄置信区间（这种区间需要超过60,000个实验来支持，但他们可能只进行了少于500个）。作者通过重新推导缩放定律，获得了与原论文前两种估计程序兼容的结果，从而质疑了原方法的可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.10102v2",
      "published_date": "2024-04-15 19:19:56 UTC",
      "updated_date": "2024-05-15 00:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:25:25.644766"
    },
    {
      "arxiv_id": "2404.10097v1",
      "title": "LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model",
      "title_zh": "LegalPro-BERT：通过微调 BERT 大型语言模型对法律条款进行分类",
      "authors": [
        "Amit Tewari"
      ],
      "abstract": "A contract is a type of legal document commonly used in organizations.\nContract review is an integral and repetitive process to avoid business risk\nand liability. Contract analysis requires the identification and classification\nof key provisions and paragraphs within an agreement. Identification and\nvalidation of contract clauses can be a time-consuming and challenging task\ndemanding the services of trained and expensive lawyers, paralegals or other\nlegal assistants. Classification of legal provisions in contracts using\nartificial intelligence and natural language processing is complex due to the\nrequirement of domain-specialized legal language for model training and the\nscarcity of sufficient labeled data in the legal domain. Using general-purpose\nmodels is not effective in this context due to the use of specialized legal\nvocabulary in contracts which may not be recognized by a general model. To\naddress this problem, we propose the use of a pre-trained large language model\nwhich is subsequently calibrated on legal taxonomy. We propose LegalPro-BERT, a\nBERT transformer architecture model that we fine-tune to efficiently handle\nclassification task for legal provisions. We conducted experiments to measure\nand compare metrics with current benchmark results. We found that LegalPro-BERT\noutperforms the previous benchmark used for comparison in this research.",
      "tldr_zh": "本研究针对合同审查中法律条款的识别和分类问题，提出LegalPro-BERT模型，该模型通过fine-tuning预训练的BERT大型语言模型，以适应法律领域的专业词汇和数据稀缺挑战。LegalPro-BERT基于transformer architecture设计，能够高效处理法律条款的分类任务，避免了通用模型在识别专业法律语言时的不足。实验结果显示，该模型在相关基准测试中表现出色，超越了之前的比较基准，为AI辅助合同分析提供了更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10097v1",
      "published_date": "2024-04-15 19:08:48 UTC",
      "updated_date": "2024-04-15 19:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:25:36.713794"
    },
    {
      "arxiv_id": "2404.10096v2",
      "title": "Vision Augmentation Prediction Autoencoder with Attention Design (VAPAAD)",
      "title_zh": "带注意力设计的视觉增强预测自编码器（VAPAAD）",
      "authors": [
        "Yiqiao Yin"
      ],
      "abstract": "Recent advancements in sequence prediction have significantly improved the\naccuracy of video data interpretation; however, existing models often overlook\nthe potential of attention-based mechanisms for next-frame prediction. This\nstudy introduces the Vision Augmentation Prediction Autoencoder with Attention\nDesign (VAPAAD), an innovative approach that integrates attention mechanisms\ninto sequence prediction, enabling nuanced analysis and understanding of\ntemporal dynamics in video sequences. Utilizing the Moving MNIST dataset, we\ndemonstrate VAPAAD's robust performance and superior handling of complex\ntemporal data compared to traditional methods. VAPAAD combines data\naugmentation, ConvLSTM2D layers, and a custom-built self-attention mechanism to\neffectively focus on salient features within a sequence, enhancing predictive\naccuracy and context-aware analysis. This methodology not only adheres to human\ncognitive processes during video interpretation but also addresses limitations\nin conventional models, which often struggle with the variability inherent in\nvideo sequences. The experimental results confirm that VAPAAD outperforms\nexisting models, especially in integrating attention mechanisms, which\nsignificantly improve predictive performance.",
      "tldr_zh": "本文提出 VAPAAD（Vision Augmentation Prediction Autoencoder with Attention Design），一种创新模型，将注意力机制融入视频序列预测中，以提升对时序动态的分析和下一帧预测的准确性。该模型结合数据增强、ConvLSTM2D 层以及自定义自注意力机制，专注于序列中的显著特征，从而更好地处理视频数据的变异性和复杂性。实验结果显示，在 Moving MNIST 数据集上，VAPAAD 显著优于传统方法，提高了预测性能，并更贴合人类认知过程。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10096v2",
      "published_date": "2024-04-15 19:06:58 UTC",
      "updated_date": "2024-04-17 02:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:25:50.318459"
    },
    {
      "arxiv_id": "2404.10054v1",
      "title": "AIGeN: An Adversarial Approach for Instruction Generation in VLN",
      "title_zh": "翻译失败",
      "authors": [
        "Niyati Rawal",
        "Roberto Bigazzi",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "In the last few years, the research interest in Vision-and-Language\nNavigation (VLN) has grown significantly. VLN is a challenging task that\ninvolves an agent following human instructions and navigating in a previously\nunknown environment to reach a specified goal. Recent work in literature\nfocuses on different ways to augment the available datasets of instructions for\nimproving navigation performance by exploiting synthetic training data. In this\nwork, we propose AIGeN, a novel architecture inspired by Generative Adversarial\nNetworks (GANs) that produces meaningful and well-formed synthetic instructions\nto improve navigation agents' performance. The model is composed of a\nTransformer decoder (GPT-2) and a Transformer encoder (BERT). During the\ntraining phase, the decoder generates sentences for a sequence of images\ndescribing the agent's path to a particular point while the encoder\ndiscriminates between real and fake instructions. Experimentally, we evaluate\nthe quality of the generated instructions and perform extensive ablation\nstudies. Additionally, we generate synthetic instructions for 217K trajectories\nusing AIGeN on Habitat-Matterport 3D Dataset (HM3D) and show an improvement in\nthe performance of an off-the-shelf VLN method. The validation analysis of our\nproposal is conducted on REVERIE and R2R and highlights the promising aspects\nof our proposal, achieving state-of-the-art performance.",
      "tldr_zh": "该论文提出 AIGeN，一种基于 Generative Adversarial Networks (GANs) 的对抗式方法，用于在 Vision-and-Language Navigation (VLN) 中生成高质量的合成指令，以提升代理的导航性能。AIGeN 架构结合 Transformer decoder (GPT-2) 生成描述代理路径的句子，以及 Transformer encoder (BERT) 鉴别真实与假指令。实验结果显示，在 Habitat-Matterport 3D Dataset (HM3D) 上为 217K 轨迹生成合成指令后，VLN 方法的性能得到改善，并在 REVERIE 和 R2R 数据集上达到 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to 7th Multimodal Learning and Applications Workshop (MULA\n  2024) at the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2404.10054v1",
      "published_date": "2024-04-15 18:00:30 UTC",
      "updated_date": "2024-04-15 18:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:26:04.106753"
    },
    {
      "arxiv_id": "2404.09995v2",
      "title": "Taming Latent Diffusion Model for Neural Radiance Field Inpainting",
      "title_zh": "翻译失败",
      "authors": [
        "Chieh Hubert Lin",
        "Changil Kim",
        "Jia-Bin Huang",
        "Qinbo Li",
        "Chih-Yao Ma",
        "Johannes Kopf",
        "Ming-Hsuan Yang",
        "Hung-Yu Tseng"
      ],
      "abstract": "Neural Radiance Field (NeRF) is a representation for 3D reconstruction from\nmulti-view images. Despite some recent work showing preliminary success in\nediting a reconstructed NeRF with diffusion prior, they remain struggling to\nsynthesize reasonable geometry in completely uncovered regions. One major\nreason is the high diversity of synthetic contents from the diffusion model,\nwhich hinders the radiance field from converging to a crisp and deterministic\ngeometry. Moreover, applying latent diffusion models on real data often yields\na textural shift incoherent to the image condition due to auto-encoding errors.\nThese two problems are further reinforced with the use of pixel-distance\nlosses. To address these issues, we propose tempering the diffusion model's\nstochasticity with per-scene customization and mitigating the textural shift\nwith masked adversarial training. During the analyses, we also found the\ncommonly used pixel and perceptual losses are harmful in the NeRF inpainting\ntask. Through rigorous experiments, our framework yields state-of-the-art NeRF\ninpainting results on various real-world scenes. Project page:\nhttps://hubert0527.github.io/MALD-NeRF",
      "tldr_zh": "该论文针对 Neural Radiance Field (NeRF) 的 3D 重建编辑问题，提出了一种驯服 Latent Diffusion Model 的框架，以解决扩散模型在未覆盖区域合成几何不稳定和纹理偏移的问题。方法包括通过每场景定制减少扩散模型的随机性，并采用 masked adversarial training 来缓解因自动编码错误导致的纹理不一致，同时避免使用有害的像素和感知损失。实验结果显示，该框架在各种真实场景中实现了最先进的 NeRF inpainting 性能，显著提升了重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024. Project page:\n  https://hubert0527.github.io/MALD-NeRF",
      "pdf_url": "http://arxiv.org/pdf/2404.09995v2",
      "published_date": "2024-04-15 17:59:57 UTC",
      "updated_date": "2024-11-13 00:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:26:13.650902"
    },
    {
      "arxiv_id": "2404.09992v1",
      "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ziniu Zhang",
        "Shulin Tian",
        "Liangyu Chen",
        "Ziwei Liu"
      ],
      "abstract": "Autonomous embodied agents live on an Internet of multimedia websites. Can\nthey hop around multimodal websites to complete complex user tasks? Existing\nbenchmarks fail to assess them in a realistic, evolving environment for their\nembodiment across websites. To answer this question, we present MMInA, a\nmultihop and multimodal benchmark to evaluate the embodied agents for\ncompositional Internet tasks, with several appealing properties: 1) Evolving\nreal-world multimodal websites. Our benchmark uniquely operates on evolving\nreal-world websites, ensuring a high degree of realism and applicability to\nnatural user tasks. Our data includes 1,050 human-written tasks covering\nvarious domains such as shopping and travel, with each task requiring the agent\nto autonomously extract multimodal information from web pages as observations;\n2) Multihop web browsing. Our dataset features naturally compositional tasks\nthat require information from or actions on multiple websites to solve, to\nassess long-range reasoning capabilities on web tasks; 3) Holistic evaluation.\nWe propose a novel protocol for evaluating an agent's progress in completing\nmultihop tasks. We experiment with both standalone (multimodal) language models\nand heuristic-based web agents. Extensive experiments demonstrate that while\nlong-chain multihop web tasks are easy for humans, they remain challenging for\nstate-of-the-art web agents. We identify that agents are more likely to fail on\nthe early hops when solving tasks of more hops, which results in lower task\nsuccess rates. To address this issue, we propose a simple memory augmentation\napproach replaying past action trajectories to reflect. Our method\nsignificantly improved both the single-hop and multihop web browsing abilities\nof agents. See our code and data at https://mmina.cliangyu.com",
      "tldr_zh": "本研究引入了 MMInA 基准，用于评估多跳（Multihop）多模态（Multimodal）互联网代理（Internet Agents）在处理复杂用户任务时的能力，聚焦于真实演变的网站环境。MMInA 包含 1,050 个人类编写的任务，覆盖购物和旅行等领域，这些任务要求代理从多个网站提取多模态信息并进行长程推理。实验结果显示，现有的最先进代理在多跳任务中表现较差，尤其容易在早期跳失败，导致整体成功率降低。为解决此问题，研究提出了一种简单的记忆增强方法，通过重放过去的行动轨迹显著提升了代理的单跳和多跳浏览能力。该基准为开发更可靠的网络代理提供了宝贵工具，并附带了代码和数据以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09992v1",
      "published_date": "2024-04-15 17:59:50 UTC",
      "updated_date": "2024-04-15 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:26:27.328927"
    },
    {
      "arxiv_id": "2404.09990v1",
      "title": "HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Mude Hui",
        "Siwei Yang",
        "Bingchen Zhao",
        "Yichun Shi",
        "Heng Wang",
        "Peng Wang",
        "Yuyin Zhou",
        "Cihang Xie"
      ],
      "abstract": "This study introduces HQ-Edit, a high-quality instruction-based image editing\ndataset with around 200,000 edits. Unlike prior approaches relying on attribute\nguidance or human feedback on building datasets, we devise a scalable data\ncollection pipeline leveraging advanced foundation models, namely GPT-4V and\nDALL-E 3. To ensure its high quality, diverse examples are first collected\nonline, expanded, and then used to create high-quality diptychs featuring input\nand output images with detailed text prompts, followed by precise alignment\nensured through post-processing. In addition, we propose two evaluation\nmetrics, Alignment and Coherence, to quantitatively assess the quality of image\nedit pairs using GPT-4V. HQ-Edits high-resolution images, rich in detail and\naccompanied by comprehensive editing prompts, substantially enhance the\ncapabilities of existing image editing models. For example, an HQ-Edit\nfinetuned InstructPix2Pix can attain state-of-the-art image editing\nperformance, even surpassing those models fine-tuned with human-annotated data.\nThe project page is https://thefllood.github.io/HQEdit_web.",
      "tldr_zh": "本文引入了 HQ-Edit，一个包含约 20 万个高质量指令-based 图像编辑数据集，旨在提升图像编辑模型的表现。不同于以往依赖属性指导或人类反馈的方法，该数据集通过一个可扩展的管道利用 GPT-4V 和 DALL-E 3 等基础模型，从在线收集多样示例、扩展生成高质量输入-输出图像对，并通过后处理确保精确对齐。论文还提出了 Alignment 和 Coherence 两个评估指标，使用 GPT-4V 量化评估图像编辑对的质量；实验结果显示，使用 HQ-Edit 微调的 InstructPix2Pix 模型达到了 state-of-the-art 性能，甚至超过了基于人类标注数据的模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://thefllood.github.io/HQEdit_web",
      "pdf_url": "http://arxiv.org/pdf/2404.09990v1",
      "published_date": "2024-04-15 17:59:31 UTC",
      "updated_date": "2024-04-15 17:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:26:39.569437"
    },
    {
      "arxiv_id": "2404.12404v4",
      "title": "EPIC: Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models",
      "title_zh": "EPIC：通过大型语言模型在表格数据分类中针对不平衡类数据合成的有效提示方法",
      "authors": [
        "Jinhee Kim",
        "Taesung Kim",
        "Jaegul Choo"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable in-context learning\ncapabilities across diverse applications. In this work, we explore the\neffectiveness of LLMs for generating realistic synthetic tabular data,\nidentifying key prompt design elements to optimize performance. We introduce\nEPIC, a novel approach that leverages balanced, grouped data samples and\nconsistent formatting with unique variable mapping to guide LLMs in generating\naccurate synthetic data across all classes, even for imbalanced datasets.\nEvaluations on real-world datasets show that EPIC achieves state-of-the-art\nmachine learning classification performance, significantly improving generation\nefficiency. These findings highlight the effectiveness of EPIC for synthetic\ntabular data generation, particularly in addressing class imbalance. Our source\ncode for our work is available at:\nhttps://seharanul17.github.io/project-synthetic-tabular-llm/",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在生成合成表格数据方面的潜力，特别针对类别不平衡问题，通过优化提示设计来提升性能。作者提出了 EPIC 方法，利用平衡的、分组数据样本、一致的格式化和唯一的变量映射，指导 LLMs 生成准确的合成数据，从而改善分类任务的准确性。实验结果显示，EPIC 在真实数据集上实现了最先进的机器学习分类性能，并显著提高了生成效率，为处理 imbalanced-class 数据提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.12404v4",
      "published_date": "2024-04-15 17:49:16 UTC",
      "updated_date": "2025-01-14 01:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:26:50.343236"
    },
    {
      "arxiv_id": "2404.09967v2",
      "title": "Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model",
      "title_zh": "Ctrl-Adapter：一种高效且多功能的框架，用于将多样化的控制适配到任意扩散模型",
      "authors": [
        "Han Lin",
        "Jaemin Cho",
        "Abhay Zala",
        "Mohit Bansal"
      ],
      "abstract": "ControlNets are widely used for adding spatial control to text-to-image\ndiffusion models with different conditions, such as depth maps,\nscribbles/sketches, and human poses. However, when it comes to controllable\nvideo generation, ControlNets cannot be directly integrated into new backbones\ndue to feature space mismatches, and training ControlNets for new backbones can\nbe a significant burden for many users. Furthermore, applying ControlNets\nindependently to different frames cannot effectively maintain object temporal\nconsistency. To address these challenges, we introduce Ctrl-Adapter, an\nefficient and versatile framework that adds diverse controls to any image/video\ndiffusion model through the adaptation of pretrained ControlNets. Ctrl-Adapter\noffers strong and diverse capabilities, including image and video control,\nsparse-frame video control, fine-grained patch-level multi-condition control\n(via an MoE router), zero-shot adaptation to unseen conditions, and supports a\nvariety of downstream tasks beyond spatial control, including video editing,\nvideo style transfer, and text-guided motion control. With six diverse\nU-Net/DiT-based image/video diffusion models (SDXL, PixArt-$\\alpha$, I2VGen-XL,\nSVD, Latte, Hotshot-XL), Ctrl-Adapter matches the performance of pretrained\nControlNets on COCO and achieves the state-of-the-art on DAVIS 2017 with\nsignificantly lower computation (< 10 GPU hours).",
      "tldr_zh": "该论文提出 Ctrl-Adapter，一种高效且通用的框架，用于将预训练的 ControlNets 适应到任意图像/视频扩散模型中，解决特征空间不匹配、训练负担和物体时间一致性等问题。\nCtrl-Adapter 支持多样化功能，包括图像和视频控制、稀疏帧视频控制、细粒度多条件控制（通过 MoE 路由器）、零样本适应未见条件，以及下游任务如视频编辑、风格转移和文本引导运动控制。\n实验结果显示，在 SDXL、PixArt-α 等六种 U-Net/DiT 模型上，Ctrl-Adapter 在 COCO 上匹配预训练 ControlNets 的性能，并在 DAVIS 2017 上实现最先进水平，同时计算资源消耗低于 10 GPU 小时。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "First two authors contributed equally; Project page:\n  https://ctrl-adapter.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.09967v2",
      "published_date": "2024-04-15 17:45:36 UTC",
      "updated_date": "2024-05-24 16:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:27:04.062630"
    },
    {
      "arxiv_id": "2404.09956v4",
      "title": "Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization",
      "title_zh": "Tango 2：通过直接偏好优化对基于扩散的文本到音频生成的对齐",
      "authors": [
        "Navonil Majumder",
        "Chia-Yu Hung",
        "Deepanway Ghosal",
        "Wei-Ning Hsu",
        "Rada Mihalcea",
        "Soujanya Poria"
      ],
      "abstract": "Generative multimodal content is increasingly prevalent in much of the\ncontent creation arena, as it has the potential to allow artists and media\npersonnel to create pre-production mockups by quickly bringing their ideas to\nlife. The generation of audio from text prompts is an important aspect of such\nprocesses in the music and film industry. Many of the recent diffusion-based\ntext-to-audio models focus on training increasingly sophisticated diffusion\nmodels on a large set of datasets of prompt-audio pairs. These models do not\nexplicitly focus on the presence of concepts or events and their temporal\nordering in the output audio with respect to the input prompt. Our hypothesis\nis focusing on how these aspects of audio generation could improve audio\ngeneration performance in the presence of limited data. As such, in this work,\nusing an existing text-to-audio model Tango, we synthetically create a\npreference dataset where each prompt has a winner audio output and some loser\naudio outputs for the diffusion model to learn from. The loser outputs, in\ntheory, have some concepts from the prompt missing or in an incorrect order. We\nfine-tune the publicly available Tango text-to-audio model using diffusion-DPO\n(direct preference optimization) loss on our preference dataset and show that\nit leads to improved audio output over Tango and AudioLDM2, in terms of both\nautomatic- and manual-evaluation metrics.",
      "tldr_zh": "本研究提出Tango 2模型，通过Direct Preference Optimization（DPO）优化扩散模型（Diffusion-based）生成的文本到音频（Text-to-Audio），以改善音频中概念存在、事件及时间顺序的准确性，尤其在数据有限的情况下。研究者基于现有Tango模型，合成一个偏好数据集，其中每个提示包含一个获胜音频和若干失败音频（后者缺少概念或顺序错误），并使用diffusion-DPO损失函数进行微调。实验结果显示，Tango 2在自动和手动评估指标上优于Tango和AudioLDM2模型，证明了这种方法能显著提升音频生成性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09956v4",
      "published_date": "2024-04-15 17:31:22 UTC",
      "updated_date": "2024-07-17 16:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:27:13.972587"
    },
    {
      "arxiv_id": "2404.09946v1",
      "title": "A Note on Loss Functions and Error Compounding in Model-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Jiang"
      ],
      "abstract": "This note clarifies some confusions (and perhaps throws out more) around\nmodel-based reinforcement learning and their theoretical understanding in the\ncontext of deep RL. Main topics of discussion are (1) how to reconcile\nmodel-based RL's bad empirical reputation on error compounding with its\nsuperior theoretical properties, and (2) the limitations of empirically popular\nlosses. For the latter, concrete counterexamples for the \"MuZero loss\" are\nconstructed to show that it not only fails in stochastic environments, but also\nsuffers exponential sample complexity in deterministic environments when data\nprovides sufficient coverage.",
      "tldr_zh": "这篇笔记探讨了基于模型的强化学习（model-based RL）在深度强化学习（deep RL）中的理论与经验矛盾，主要包括：（1）如何调和其理论上优越性能（如更高效的学习）与经验上因错误积累而表现不佳的问题；（2）流行损失函数的局限性。论文通过构建具体反例，证明了“MuZero loss”不仅在随机环境中失败，还在确定性环境中面临指数级的样本复杂度，即使数据覆盖充分。总体上，该工作澄清了相关混淆，为改进基于模型的 RL 算法提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09946v1",
      "published_date": "2024-04-15 17:15:18 UTC",
      "updated_date": "2024-04-15 17:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:27:27.583790"
    },
    {
      "arxiv_id": "2404.09941v1",
      "title": "Evolving Interpretable Visual Classifiers with Large Language Models",
      "title_zh": "使用大型语言模型演化的",
      "authors": [
        "Mia Chiquier",
        "Utkarsh Mall",
        "Carl Vondrick"
      ],
      "abstract": "Multimodal pre-trained models, such as CLIP, are popular for zero-shot\nclassification due to their open-vocabulary flexibility and high performance.\nHowever, vision-language models, which compute similarity scores between images\nand class labels, are largely black-box, with limited interpretability, risk\nfor bias, and inability to discover new visual concepts not written down.\nMoreover, in practical settings, the vocabulary for class names and attributes\nof specialized concepts will not be known, preventing these methods from\nperforming well on images uncommon in large-scale vision-language datasets. To\naddress these limitations, we present a novel method that discovers\ninterpretable yet discriminative sets of attributes for visual recognition. We\nintroduce an evolutionary search algorithm that uses a large language model and\nits in-context learning abilities to iteratively mutate a concept bottleneck of\nattributes for classification. Our method produces state-of-the-art,\ninterpretable fine-grained classifiers. We outperform the latest baselines by\n18.4% on five fine-grained iNaturalist datasets and by 22.2% on two KikiBouba\ndatasets, despite the baselines having access to privileged information about\nclass names.",
      "tldr_zh": "本研究针对多模态预训练模型如 CLIP 在零样本分类中的黑盒性、可解释性有限、偏见风险以及无法发现新视觉概念等问题，提出了一种新方法来生成可解释且判别性的属性集。方法利用进化搜索算法结合大型语言模型（Large Language Models, LLMs）及其 in-context learning 能力，迭代优化概念瓶颈（concept bottleneck）中的属性，以实现细粒度视觉分类。该方法在五个 iNaturalist 数据集上比最新基线提升 18.4%，在两个 KikiBouba 数据集上提升 22.2%，即使基线拥有类名特权信息，也表现出色，从而为更可靠的视觉识别提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09941v1",
      "published_date": "2024-04-15 17:09:53 UTC",
      "updated_date": "2024-04-15 17:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:27:41.219642"
    },
    {
      "arxiv_id": "2404.09939v3",
      "title": "A Survey on Deep Learning for Theorem Proving",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoyu Li",
        "Jialiang Sun",
        "Logan Murphy",
        "Qidong Su",
        "Zenan Li",
        "Xian Zhang",
        "Kaiyu Yang",
        "Xujie Si"
      ],
      "abstract": "Theorem proving is a fundamental aspect of mathematics, spanning from\ninformal reasoning in natural language to rigorous derivations in formal\nsystems. In recent years, the advancement of deep learning, especially the\nemergence of large language models, has sparked a notable surge of research\nexploring these techniques to enhance the process of theorem proving. This\npaper presents a comprehensive survey of deep learning for theorem proving by\noffering (i) a thorough review of existing approaches across various tasks such\nas autoformalization, premise selection, proofstep generation, and proof\nsearch; (ii) an extensive summary of curated datasets and strategies for\nsynthetic data generation; (iii) a detailed analysis of evaluation metrics and\nthe performance of state-of-the-art methods; and (iv) a critical discussion on\nthe persistent challenges and the promising avenues for future exploration. Our\nsurvey aims to serve as a foundational reference for deep learning approaches\nin theorem proving, inspiring and catalyzing further research endeavors in this\nrapidly growing field. A curated list of papers is available at\nhttps://github.com/zhaoyu-li/DL4TP.",
      "tldr_zh": "这篇论文对深度学习在定理证明领域的应用进行了全面调查，涵盖了现有方法如autoformalization（自动形式化）、premise selection（前提选择）、proofstep generation（证明步骤生成）和proof search（证明搜索）。它总结了相关数据集、合成数据生成策略，以及评估指标和最先进方法的性能表现。论文还批判性地讨论了持续挑战和未来研究方向，并提供了一个论文列表（https://github.com/zhaoyu-li/DL4TP），旨在作为该领域的参考，促进进一步探索。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09939v3",
      "published_date": "2024-04-15 17:07:55 UTC",
      "updated_date": "2024-08-22 03:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:27:52.429865"
    },
    {
      "arxiv_id": "2404.09937v2",
      "title": "Compression Represents Intelligence Linearly",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhen Huang",
        "Jinghan Zhang",
        "Zifei Shan",
        "Junxian He"
      ],
      "abstract": "There is a belief that learning to compress well will lead to intelligence.\nRecently, language modeling has been shown to be equivalent to compression,\nwhich offers a compelling rationale for the success of large language models\n(LLMs): the development of more advanced language models is essentially\nenhancing compression which facilitates intelligence. Despite such appealing\ndiscussions, little empirical evidence is present for the interplay between\ncompression and intelligence. In this work, we examine their relationship in\nthe context of LLMs, treating LLMs as data compressors. Given the abstract\nconcept of \"intelligence\", we adopt the average downstream benchmark scores as\na surrogate, specifically targeting intelligence related to knowledge and\ncommonsense, coding, and mathematical reasoning. Across 12 benchmarks, our\nstudy brings together 31 public LLMs that originate from diverse organizations.\nRemarkably, we find that LLMs' intelligence -- reflected by average benchmark\nscores -- almost linearly correlates with their ability to compress external\ntext corpora. These results provide concrete evidence supporting the belief\nthat superior compression indicates greater intelligence. Furthermore, our\nfindings suggest that compression efficiency, as an unsupervised metric derived\nfrom raw text corpora, serves as a reliable evaluation measure that is linearly\nassociated with the model capabilities. We open-source our compression datasets\nas well as our data collection pipelines to facilitate future researchers to\nassess compression properly.",
      "tldr_zh": "这篇论文探讨了压缩能力与智能之间的关系，主张 LLMs 的智能表现几乎线性地与数据压缩能力相关。研究者通过评估 31 个来自不同组织的公共 LLMs，在 12 个基准（如知识、常识、编码和数学推理）上测量平均分数，并将其与模型压缩外部文本语料库的能力进行比较。结果显示，压缩效率作为一个无监督指标，能可靠地预测模型性能，并为语言模型的成功提供实证支持；论文还开源了压缩数据集和数据收集管道，以促进后续研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024. Data and code are available at\n  https://github.com/hkust-nlp/llm-compression-intelligence",
      "pdf_url": "http://arxiv.org/pdf/2404.09937v2",
      "published_date": "2024-04-15 17:03:41 UTC",
      "updated_date": "2024-08-19 13:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:28:04.547502"
    },
    {
      "arxiv_id": "2404.09932v2",
      "title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Usman Anwar",
        "Abulhair Saparov",
        "Javier Rando",
        "Daniel Paleka",
        "Miles Turpin",
        "Peter Hase",
        "Ekdeep Singh Lubana",
        "Erik Jenner",
        "Stephen Casper",
        "Oliver Sourbut",
        "Benjamin L. Edelman",
        "Zhaowei Zhang",
        "Mario Günther",
        "Anton Korinek",
        "Jose Hernandez-Orallo",
        "Lewis Hammond",
        "Eric Bigelow",
        "Alexander Pan",
        "Lauro Langosco",
        "Tomasz Korbak",
        "Heidi Zhang",
        "Ruiqi Zhong",
        "Seán Ó hÉigeartaigh",
        "Gabriel Recchia",
        "Giulio Corsi",
        "Alan Chan",
        "Markus Anderljung",
        "Lilian Edwards",
        "Aleksandar Petrov",
        "Christian Schroeder de Witt",
        "Sumeet Ramesh Motwan",
        "Yoshua Bengio",
        "Danqi Chen",
        "Philip H. S. Torr",
        "Samuel Albanie",
        "Tegan Maharaj",
        "Jakob Foerster",
        "Florian Tramer",
        "He He",
        "Atoosa Kasirzadeh",
        "Yejin Choi",
        "David Krueger"
      ],
      "abstract": "This work identifies 18 foundational challenges in assuring the alignment and\nsafety of large language models (LLMs). These challenges are organized into\nthree different categories: scientific understanding of LLMs, development and\ndeployment methods, and sociotechnical challenges. Based on the identified\nchallenges, we pose $200+$ concrete research questions.",
      "tldr_zh": "这篇论文识别了18个确保大型语言模型(LLMs)对齐和安全的根本挑战，并将这些挑战分为三类：对LLMs的科学理解、开发和部署方法，以及社会技术挑战。论文通过系统化分析，突出了这些挑战在实际应用中的重要性。基于此，作者提出了200多个具体的研究问题，以指导未来工作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09932v2",
      "published_date": "2024-04-15 16:58:28 UTC",
      "updated_date": "2024-09-06 00:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:28:15.800962"
    },
    {
      "arxiv_id": "2404.09931v1",
      "title": "Zero-shot detection of buildings in mobile LiDAR using Language Vision Model",
      "title_zh": "翻译失败",
      "authors": [
        "June Moh Goo",
        "Zichao Zeng",
        "Jan Boehm"
      ],
      "abstract": "Recent advances have demonstrated that Language Vision Models (LVMs) surpass\nthe existing State-of-the-Art (SOTA) in two-dimensional (2D) computer vision\ntasks, motivating attempts to apply LVMs to three-dimensional (3D) data. While\nLVMs are efficient and effective in addressing various downstream 2D vision\ntasks without training, they face significant challenges when it comes to point\nclouds, a representative format for representing 3D data. It is more difficult\nto extract features from 3D data and there are challenges due to large data\nsizes and the cost of the collection and labelling, resulting in a notably\nlimited availability of datasets. Moreover, constructing LVMs for point clouds\nis even more challenging due to the requirements for large amounts of data and\ntraining time. To address these issues, our research aims to 1) apply the\nGrounded SAM through Spherical Projection to transfer 3D to 2D, and 2)\nexperiment with synthetic data to evaluate its effectiveness in bridging the\ngap between synthetic and real-world data domains. Our approach exhibited high\nperformance with an accuracy of 0.96, an IoU of 0.85, precision of 0.92, recall\nof 0.91, and an F1 score of 0.92, confirming its potential. However, challenges\nsuch as occlusion problems and pixel-level overlaps of multi-label points\nduring spherical image generation remain to be addressed in future studies.",
      "tldr_zh": "该研究提出了一种零样本方法，利用Language Vision Models (LVMs)检测移动LiDAR中的建筑物，以解决LVMs应用于3D点云数据时面临的特征提取困难、数据规模大和数据集稀缺等问题。具体方法包括使用Grounded SAM通过Spherical Projection将3D点云转换为2D图像，并通过合成数据实验评估其在桥接合成与真实数据领域的有效性。实验结果显示，该方法取得了高性能，包括准确率0.96、IoU 0.85、精确度0.92、召回率0.91和F1分数0.92。尽管如此，未来仍需解决遮挡问题和多标签点在球形图像生成中的像素级重叠挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 6 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2404.09931v1",
      "published_date": "2024-04-15 16:56:58 UTC",
      "updated_date": "2024-04-15 16:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:28:28.909867"
    },
    {
      "arxiv_id": "2404.13076v1",
      "title": "LLM Evaluators Recognize and Favor Their Own Generations",
      "title_zh": "LLM 评估器识别并偏好它们自己的生成物",
      "authors": [
        "Arjun Panickssery",
        "Samuel R. Bowman",
        "Shi Feng"
      ],
      "abstract": "Self-evaluation using large language models (LLMs) has proven valuable not\nonly in benchmarking but also methods like reward modeling, constitutional AI,\nand self-refinement. But new biases are introduced due to the same LLM acting\nas both the evaluator and the evaluatee. One such bias is self-preference,\nwhere an LLM evaluator scores its own outputs higher than others' while human\nannotators consider them of equal quality. But do LLMs actually recognize their\nown outputs when they give those texts higher scores, or is it just a\ncoincidence? In this paper, we investigate if self-recognition capability\ncontributes to self-preference. We discover that, out of the box, LLMs such as\nGPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from\nother LLMs and humans. By fine-tuning LLMs, we discover a linear correlation\nbetween self-recognition capability and the strength of self-preference bias;\nusing controlled experiments, we show that the causal explanation resists\nstraightforward confounders. We discuss how self-recognition can interfere with\nunbiased evaluations and AI safety more generally.",
      "tldr_zh": "该研究发现，大型语言模型（LLMs）在进行自我评估时存在自我偏好（self-preference）偏见，即LLMs倾向于给自己的输出打更高分，即使人类认为质量相当。研究者测试了如GPT-4和Llama 2等模型，发现它们在区分自身输出与其他模型或人类输出时具有非微不足道的自我识别（self-recognition）准确率。通过微调LLMs，实验证明自我识别能力与自我偏好强度之间存在线性相关性，并通过控制实验验证了这一因果关系。最终，该论文讨论了自我识别如何干扰无偏见的评估，并对AI安全提出潜在风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13076v1",
      "published_date": "2024-04-15 16:49:59 UTC",
      "updated_date": "2024-04-15 16:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:28:40.553447"
    },
    {
      "arxiv_id": "2404.09921v1",
      "title": "Zero-shot Building Age Classification from Facade Image Using GPT-4",
      "title_zh": "零样本建筑年龄分类从立面图像使用 GPT-4",
      "authors": [
        "Zichao Zeng",
        "June Moh Goo",
        "Xinglei Wang",
        "Bin Chi",
        "Meihui Wang",
        "Jan Boehm"
      ],
      "abstract": "A building's age of construction is crucial for supporting many geospatial\napplications. Much current research focuses on estimating building age from\nfacade images using deep learning. However, building an accurate deep learning\nmodel requires a considerable amount of labelled training data, and the trained\nmodels often have geographical constraints. Recently, large pre-trained vision\nlanguage models (VLMs) such as GPT-4 Vision, which demonstrate significant\ngeneralisation capabilities, have emerged as potential training-free tools for\ndealing with specific vision tasks, but their applicability and reliability for\nbuilding information remain unexplored. In this study, a zero-shot building age\nclassifier for facade images is developed using prompts that include logical\ninstructions. Taking London as a test case, we introduce a new dataset,\nFI-London, comprising facade images and building age epochs. Although the\ntraining-free classifier achieved a modest accuracy of 39.69%, the mean\nabsolute error of 0.85 decades indicates that the model can predict building\nage epochs successfully albeit with a small bias. The ensuing discussion\nreveals that the classifier struggles to predict the age of very old buildings\nand is challenged by fine-grained predictions within 2 decades. Overall, the\nclassifier utilising GPT-4 Vision is capable of predicting the rough age epoch\nof a building from a single facade image without any training.",
      "tldr_zh": "该研究提出了一种零-shot 建筑年龄分类方法，使用 GPT-4 Vision 从建筑立面图像（facade images）估计建筑建造年龄，以解决传统深度学习模型需大量标注数据和地理限制的问题。作者开发了基于逻辑提示的分类器，并创建了新的 FI-London 数据集作为测试案例，结果显示准确率达到 39.69%，平均绝对误差为 0.85 十年，尽管在预测非常旧建筑或细粒度（2 年内）年龄时存在挑战。总体而言，这展示了大型视觉语言模型（VLMs）在无需训练的情况下，从单一图像中粗略预测建筑年龄的时代潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09921v1",
      "published_date": "2024-04-15 16:47:22 UTC",
      "updated_date": "2024-04-15 16:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:28:55.324448"
    },
    {
      "arxiv_id": "2404.09897v1",
      "title": "Progressive Knowledge Graph Completion",
      "title_zh": "渐进式知识图谱补全",
      "authors": [
        "Jiayi Li",
        "Ruilin Luo",
        "Jiaqi Sun",
        "Jing Xiao",
        "Yujiu Yang"
      ],
      "abstract": "Knowledge Graph Completion (KGC) has emerged as a promising solution to\naddress the issue of incompleteness within Knowledge Graphs (KGs). Traditional\nKGC research primarily centers on triple classification and link prediction.\nNevertheless, we contend that these tasks do not align well with real-world\nscenarios and merely serve as surrogate benchmarks. In this paper, we\ninvestigate three crucial processes relevant to real-world construction\nscenarios: (a) the verification process, which arises from the necessity and\nlimitations of human verifiers; (b) the mining process, which identifies the\nmost promising candidates for verification; and (c) the training process, which\nharnesses verified data for subsequent utilization; in order to achieve a\ntransition toward more realistic challenges. By integrating these three\nprocesses, we introduce the Progressive Knowledge Graph Completion (PKGC) task,\nwhich simulates the gradual completion of KGs in real-world scenarios.\nFurthermore, to expedite PKGC processing, we propose two acceleration modules:\nOptimized Top-$k$ algorithm and Semantic Validity Filter. These modules\nsignificantly enhance the efficiency of the mining procedure. Our experiments\ndemonstrate that performance in link prediction does not accurately reflect\nperformance in PKGC. A more in-depth analysis reveals the key factors\ninfluencing the results and provides potential directions for future research.",
      "tldr_zh": "本论文批评传统 Knowledge Graph Completion (KGC) 任务，如 triple classification 和 link prediction，仅作为代理基准，无法反映真实场景，提出 Progressive Knowledge Graph Completion (PKGC) 任务来模拟实际 KG 构建过程，包括 verification process（验证过程）、mining process（挖掘过程）和 training process（训练过程）。PKGC 通过整合这些过程，实现 KG 的逐步完成，并引入 Optimized Top-$k$ algorithm 和 Semantic Validity Filter 两个加速模块，提升挖掘效率。实验结果表明，link prediction 的性能无法准确评估 PKGC 的表现，并分析了关键影响因素，为未来研究提供潜在方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.09897v1",
      "published_date": "2024-04-15 16:16:59 UTC",
      "updated_date": "2024-04-15 16:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:29:05.062743"
    },
    {
      "arxiv_id": "2406.02557v1",
      "title": "EVAN: Evolutional Video Streaming Adaptation via Neural Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Mufan Liu",
        "Le Yang",
        "Yiling Xu",
        "Ye-kui Wang",
        "Jenq-Neng Hwang"
      ],
      "abstract": "Adaptive bitrate (ABR) using conventional codecs cannot further modify the\nbitrate once a decision has been made, exhibiting limited adaptation\ncapability. This may result in either overly conservative or overly aggressive\nbitrate selection, which could cause either inefficient utilization of the\nnetwork bandwidth or frequent re-buffering, respectively. Neural representation\nfor video (NeRV), which embeds the video content into neural network weights,\nallows video reconstruction with incomplete models. Specifically, the recovery\nof one frame can be achieved without relying on the decoding of adjacent\nframes. NeRV has the potential to provide high video reconstruction quality\nand, more importantly, pave the way for developing more flexible ABR strategies\nfor video transmission. In this work, a new framework, named Evolutional Video\nstreaming Adaptation via Neural representation (EVAN), which can adaptively\ntransmit NeRV models based on soft actor-critic (SAC) reinforcement learning,\nis proposed. EVAN is trained with a more exploitative strategy and utilizes\nprogressive playback to avoid re-buffering. Experiments showed that EVAN can\noutperform existing ABRs with 50% reduction in re-buffering and achieve nearly\n20% .",
      "tldr_zh": "该研究针对传统自适应比特率 (ABR) 算法的局限性，即无法修改已决定的比特率，导致带宽利用低效或频繁缓冲，提出了一种新框架 EVAN（Evolutional Video streaming Adaptation via Neural representation）。EVAN 利用 Neural Representation for Video (NeRV) 将视频内容嵌入神经网络权重中，实现帧独立重建，并结合 Soft Actor-Critic (SAC) 强化学习进行适应性传输模型。实验结果显示，EVAN 比现有 ABR 算法减少 50% 的再缓冲时间，并提升近 20% 的视频传输性能，为更灵活的视频流媒体适应提供了新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.IV",
      "comment": "accepted by ICME (conference)",
      "pdf_url": "http://arxiv.org/pdf/2406.02557v1",
      "published_date": "2024-04-15 16:08:18 UTC",
      "updated_date": "2024-04-15 16:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:29:16.180289"
    },
    {
      "arxiv_id": "2405.00699v1",
      "title": "Direct Training Needs Regularisation: Anytime Optimal Inference Spiking Neural Network",
      "title_zh": "直接训练需要正则化：随时最优推理脉冲神经网络",
      "authors": [
        "Dengyu Wu",
        "Yi Qi",
        "Kaiwen Cai",
        "Gaojie Jin",
        "Xinping Yi",
        "Xiaowei Huang"
      ],
      "abstract": "Spiking Neural Network (SNN) is acknowledged as the next generation of\nArtificial Neural Network (ANN) and hold great promise in effectively\nprocessing spatial-temporal information. However, the choice of timestep\nbecomes crucial as it significantly impacts the accuracy of the neural network\ntraining. Specifically, a smaller timestep indicates better performance in\nefficient computing, resulting in reduced latency and operations. While, using\na small timestep may lead to low accuracy due to insufficient information\npresentation with few spikes. This observation motivates us to develop an SNN\nthat is more reliable for adaptive timestep by introducing a novel\nregularisation technique, namely Spatial-Temporal Regulariser (STR). Our\napproach regulates the ratio between the strength of spikes and membrane\npotential at each timestep. This effectively balances spatial and temporal\nperformance during training, ultimately resulting in an Anytime Optimal\nInference (AOI) SNN. Through extensive experiments on frame-based and\nevent-based datasets, our method, in combination with cutoff based on softmax\noutput, achieves state-of-the-art performance in terms of both latency and\naccuracy. Notably, with STR and cutoff, SNN achieves 2.14 to 2.89 faster in\ninference compared to the pre-configured timestep with near-zero accuracy drop\nof 0.50% to 0.64% over the event-based datasets. Code available:\nhttps://github.com/Dengyu-Wu/AOI-SNN-Regularisation",
      "tldr_zh": "本研究针对Spiking Neural Network (SNN)中时间步长(timestep)选择的问题，提出了一种新颖的正则化技术Spatial-Temporal Regulariser (STR)，通过调节每个时间步长的脉冲强度和膜电位，实现了空间和时间性能的平衡，从而开发出Anytime Optimal Inference (AOI) SNN，支持自适应时间步长以优化推理效率。STR方法结合softmax输出截断，能够在训练过程中确保高准确性，同时显著减少延迟和计算操作。在基于帧和事件的数据集实验中，该方法使SNN的推理速度提高了2.14到2.89倍，同时准确率仅下降0.50%到0.64%，达到了最先进性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00699v1",
      "published_date": "2024-04-15 15:57:01 UTC",
      "updated_date": "2024-04-15 15:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:29:28.659298"
    },
    {
      "arxiv_id": "2404.09889v3",
      "title": "Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Baile Chen",
        "Yi Zhang",
        "Dan Roth"
      ],
      "abstract": "Retrieving relevant tables containing the necessary information to accurately\nanswer a given question over tables is critical to open-domain\nquestion-answering (QA) systems. Previous methods assume the answer to such a\nquestion can be found either in a single table or multiple tables identified\nthrough question decomposition or rewriting. However, neither of these\napproaches is sufficient, as many questions require retrieving multiple tables\nand joining them through a join plan that cannot be discerned from the user\nquery itself. If the join plan is not considered in the retrieval stage, the\nsubsequent steps of reasoning and answering based on those retrieved tables are\nlikely to be incorrect. To address this problem, we introduce a method that\nuncovers useful join relations for any query and database during table\nretrieval. We use a novel re-ranking method formulated as a mixed-integer\nprogram that considers not only table-query relevance but also table-table\nrelevance that requires inferring join relationships. Our method outperforms\nthe state-of-the-art approaches for table retrieval by up to 9.3% in F1 score\nand for end-to-end QA by up to 5.4% in accuracy.",
      "tldr_zh": "该论文质疑表检索是否已完全解决的问题，特别针对需要多表连接的查询场景，指出现有方法忽略了join plan可能导致后续问答错误。论文提出一种新的join-aware多表检索方法，使用mixed-integer program作为重新排序机制，同时考虑表-查询相关性和表-表相关性，以推断连接关系。该方法在表检索上比最先进方法提高9.3% F1 score，在端到端QA上提高5.4%准确率，显著提升了开放域问答系统的性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "ACL 2024. Dataset and code are available at\n  https://peterbaile.github.io/jar",
      "pdf_url": "http://arxiv.org/pdf/2404.09889v3",
      "published_date": "2024-04-15 15:55:01 UTC",
      "updated_date": "2025-01-09 22:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:29:43.295943"
    },
    {
      "arxiv_id": "2405.09553v1",
      "title": "Computer aided diagnosis system for Alzheimers disease using principal component analysis and machine learning based approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Lilia Lazli"
      ],
      "abstract": "Alzheimers disease (AD) is a severe neurological brain disorder. It is not\ncurable, but earlier detection can help improve symptoms in a great deal. The\nmachine learning based approaches are popular and well motivated models for\nmedical image processing tasks such as computer-aided diagnosis. These\ntechniques can improve the process for accurate diagnosis of AD. In this paper,\nwe investigate the performance of these techniques for AD detection and\nclassification using brain MRI and PET images from the OASIS database. The\nproposed system takes advantage of the artificial neural network and support\nvector machines as classifiers, and principal component analysis as a feature\nextraction technique. The results indicate that the combined scheme achieves\ngood accuracy and offers a significant advantage over the other approaches.",
      "tldr_zh": "本研究提出了一种基于机器学习（machine learning）的计算机辅助诊断系统，用于检测和分类Alzheimers disease（AD），旨在通过早期诊断改善患者症状。系统利用主成分分析（principal component analysis, PCA）作为特征提取技术，并结合人工神经网络（artificial neural network）和支持向量机（support vector machines）作为分类器，处理来自OASIS数据库的脑MRI和PET图像。结果显示，该组合方案在AD检测中取得了良好的准确率，并比其他方法具有显著优势。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted for CIBB 2021: The 17th International Conference on\n  Computational Intelligence Methods for Bioinformatics and Biostatistics",
      "pdf_url": "http://arxiv.org/pdf/2405.09553v1",
      "published_date": "2024-04-15 15:49:11 UTC",
      "updated_date": "2024-04-15 15:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:29:53.218121"
    },
    {
      "arxiv_id": "2404.09877v2",
      "title": "Synergising Human-like Responses and Machine Intelligence for Planning in Disaster Response",
      "title_zh": "翻译失败",
      "authors": [
        "Savvas Papaioannou",
        "Panayiotis Kolios",
        "Christos G. Panayiotou",
        "Marios M. Polycarpou"
      ],
      "abstract": "In the rapidly changing environments of disaster response, planning and\ndecision-making for autonomous agents involve complex and interdependent\nchoices. Although recent advancements have improved traditional artificial\nintelligence (AI) approaches, they often struggle in such settings,\nparticularly when applied to agents operating outside their well-defined\ntraining parameters. To address these challenges, we propose an attention-based\ncognitive architecture inspired by Dual Process Theory (DPT). This framework\nintegrates, in an online fashion, rapid yet heuristic (human-like) responses\n(System 1) with the slow but optimized planning capabilities of machine\nintelligence (System 2). We illustrate how a supervisory controller can\ndynamically determine in real-time the engagement of either system to optimize\nmission objectives by assessing their performance across a number of distinct\nattributes. Evaluated for trajectory planning in dynamic environments, our\nframework demonstrates that this synergistic integration effectively manages\ncomplex tasks by optimizing multiple mission objectives.",
      "tldr_zh": "该研究针对灾难响应中自主代理的复杂规划挑战，提出了一种基于注意力的认知架构，受双过程理论（Dual Process Theory, DPT）启发。该框架在线整合快速启发式的人类-like 响应（System 1）和缓慢优化的机器智能规划（System 2），通过一个监督控制器实时评估性能并动态切换系统，以优化任务目标。在动态环境下的轨迹规划实验中，该协同方法证明了其有效性，能够高效管理复杂任务并提升多个任务目标的优化性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2024 IEEE World Congress on Computational Intelligence (IEEE WCCI),\n  2024 International Joint Conference on Neural Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2404.09877v2",
      "published_date": "2024-04-15 15:47:08 UTC",
      "updated_date": "2024-09-18 10:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:30:05.355639"
    },
    {
      "arxiv_id": "2404.12403v1",
      "title": "Multi-Objective Hardware Aware Neural Architecture Search using Hardware Cost Diversity",
      "title_zh": "多目标硬件感知神经架构搜索，使用硬件成本多样性",
      "authors": [
        "Nilotpal Sinha",
        "Peyman Rostami",
        "Abd El Rahman Shabayek",
        "Anis Kacem",
        "Djamila Aouada"
      ],
      "abstract": "Hardware-aware Neural Architecture Search approaches (HW-NAS) automate the\ndesign of deep learning architectures, tailored specifically to a given target\nhardware platform. Yet, these techniques demand substantial computational\nresources, primarily due to the expensive process of assessing the performance\nof identified architectures. To alleviate this problem, a recent direction in\nthe literature has employed representation similarity metric for efficiently\nevaluating architecture performance. Nonetheless, since it is inherently a\nsingle objective method, it requires multiple runs to identify the optimal\narchitecture set satisfying the diverse hardware cost constraints, thereby\nincreasing the search cost. Furthermore, simply converting the single objective\ninto a multi-objective approach results in an under-explored architectural\nsearch space. In this study, we propose a Multi-Objective method to address the\nHW-NAS problem, called MO-HDNAS, to identify the trade-off set of architectures\nin a single run with low computational cost. This is achieved by optimizing\nthree objectives: maximizing the representation similarity metric, minimizing\nhardware cost, and maximizing the hardware cost diversity. The third objective,\ni.e. hardware cost diversity, is used to facilitate a better exploration of the\narchitecture search space. Experimental results demonstrate the effectiveness\nof our proposed method in efficiently addressing the HW-NAS problem across six\nedge devices for the image classification task.",
      "tldr_zh": "该研究针对硬件感知神经架构搜索(HW-NAS)的计算资源需求高问题，提出了一种多目标优化方法MO-HDNAS。该方法通过同时优化三个目标——最大化表示相似性指标、最小化硬件成本以及最大化硬件成本多样性——来在单次运行中高效探索架构搜索空间，并识别出满足不同硬件约束的权衡架构集。这种设计显著改善了现有单目标方法的局限性。实验结果显示，MO-HDNAS在六种边缘设备上针对图像分类任务表现出色，证明了其有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the CVPR 2024 Workshop, called \"Efficient Deep Learning\n  for Computer Vision (ECV)\"",
      "pdf_url": "http://arxiv.org/pdf/2404.12403v1",
      "published_date": "2024-04-15 15:32:58 UTC",
      "updated_date": "2024-04-15 15:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:30:17.044664"
    },
    {
      "arxiv_id": "2407.01544v1",
      "title": "Decentralized Multi-Party Multi-Network AI for Global Deployment of 6G Wireless Systems",
      "title_zh": "去中心化多方多网络 AI 用于 6G 无线系统的全球部署",
      "authors": [
        "Merim Dzaferagic",
        "Marco Ruffini",
        "Nina Slamnik-Krijestorac",
        "Joao F. Santos",
        "Johann Marquez-Barja",
        "Christos Tranoris",
        "Spyros Denazis",
        "Thomas Kyriakakis",
        "Panagiotis Karafotis",
        "Luiz DaSilva",
        "Shashi Raj Pandey",
        "Junya Shiraishi",
        "Petar Popovski",
        "Soren Kejser Jensen",
        "Christian Thomsen",
        "Torben Bach Pedersen",
        "Holger Claussen",
        "Jinfeng Du",
        "Gil Zussman",
        "Tingjun Chen",
        "Yiran Chen",
        "Seshu Tirupathi",
        "Ivan Seskar",
        "Daniel Kilper"
      ],
      "abstract": "Multiple visions of 6G networks elicit Artificial Intelligence (AI) as a\ncentral, native element. When 6G systems are deployed at a large scale,\nend-to-end AI-based solutions will necessarily have to encompass both the radio\nand the fiber-optical domain. This paper introduces the Decentralized\nMulti-Party, Multi-Network AI (DMMAI) framework for integrating AI into 6G\nnetworks deployed at scale. DMMAI harmonizes AI-driven controls across diverse\nnetwork platforms and thus facilitates networks that autonomously configure,\nmonitor, and repair themselves. This is particularly crucial at the network\nedge, where advanced applications meet heightened functionality and security\ndemands. The radio/optical integration is vital due to the current\ncompartmentalization of AI research within these domains, which lacks a\ncomprehensive understanding of their interaction. Our approach explores\nmulti-network orchestration and AI control integration, filling a critical gap\nin standardized frameworks for AI-driven coordination in 6G networks. The DMMAI\nframework is a step towards a global standard for AI in 6G, aiming to establish\nreference use cases, data and model management methods, and benchmarking\nplatforms for future AI/ML solutions.",
      "tldr_zh": "该论文提出了一种Decentralized Multi-Party, Multi-Network AI (DMMAI)框架，用于大规模部署的6G无线系统，旨在将AI整合到无线和光纤领域中，实现网络的自治配置、监控和修复。DMMAI通过协调多方多网络平台的AI控制，解决当前AI研究在这些领域交互的碎片化问题，尤其适用于网络边缘的高功能和安全需求。最终，该框架填补了标准化AI协调的空白，并为6G全球标准建立参考用例、数据模型管理方法和基准平台奠定基础。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.01544v1",
      "published_date": "2024-04-15 15:21:25 UTC",
      "updated_date": "2024-04-15 15:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:30:29.406549"
    },
    {
      "arxiv_id": "2404.09857v2",
      "title": "Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL",
      "title_zh": "翻译失败",
      "authors": [
        "Fangwei Zhong",
        "Kui Wu",
        "Hai Ci",
        "Churan Wang",
        "Hao Chen"
      ],
      "abstract": "Embodied visual tracking is to follow a target object in dynamic 3D\nenvironments using an agent's egocentric vision. This is a vital and\nchallenging skill for embodied agents. However, existing methods suffer from\ninefficient training and poor generalization. In this paper, we propose a novel\nframework that combines visual foundation models(VFM) and offline reinforcement\nlearning(offline RL) to empower embodied visual tracking. We use a pre-trained\nVFM, such as \"Tracking Anything\", to extract semantic segmentation masks with\ntext prompts. We then train a recurrent policy network with offline RL, e.g.,\nConservative Q-Learning, to learn from the collected demonstrations without\nonline interactions. To further improve the robustness and generalization of\nthe policy network, we also introduce a mask re-targeting mechanism and a\nmulti-level data collection strategy. In this way, we can train a robust policy\nwithin an hour on a consumer-level GPU, e.g., Nvidia RTX 3090. We evaluate our\nagent on several high-fidelity environments with challenging situations, such\nas distraction and occlusion. The results show that our agent outperforms\nstate-of-the-art methods in terms of sample efficiency, robustness to\ndistractors, and generalization to unseen scenarios and targets. We also\ndemonstrate the transferability of the learned agent from virtual environments\nto a real-world robot.",
      "tldr_zh": "本论文针对Embodied visual tracking问题，即代理在动态3D环境中使用自我视角跟踪目标对象，提出了一种结合Visual Foundation Models (VFM，如\"Tracking Anything\")和Offline RL的新框架，以解决现有方法的训练效率低和泛化能力差的问题。框架使用预训练VFM提取语义分割掩码，然后通过Offline RL（如Conservative Q-Learning）训练一个循环策略网络，从收集的演示数据中学习，同时引入掩码重定向机制和多级数据收集策略，以提升鲁棒性和泛化性。实验结果显示，该代理在高保真环境中表现出色，特别是在样本效率、抵抗分心和遮挡等方面优于现有方法，并在虚拟环境到真实机器人平台的转移上取得了成功。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09857v2",
      "published_date": "2024-04-15 15:12:53 UTC",
      "updated_date": "2024-07-22 06:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:30:41.429957"
    },
    {
      "arxiv_id": "2404.09848v2",
      "title": "HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation",
      "title_zh": "HyperMono：一种考虑单调性的超关系知识表示方法",
      "authors": [
        "Zhiwei Hu",
        "Víctor Gutiérrez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "abstract": "In a hyper-relational knowledge graph (HKG), each fact is composed of a main\ntriple associated with attribute-value qualifiers, which express additional\nfactual knowledge. The hyper-relational knowledge graph completion (HKGC) task\naims at inferring plausible missing links in a HKG. Most existing approaches to\nHKGC focus on enhancing the communication between qualifier pairs and main\ntriples, while overlooking two important properties that emerge from the\nmonotonicity of the hyper-relational graphs representation regime. Stage\nReasoning allows for a two-step reasoning process, facilitating the integration\nof coarse-grained inference results derived solely from main triples and\nfine-grained inference results obtained from hyper-relational facts with\nqualifiers. In the initial stage, coarse-grained results provide an upper bound\nfor correct predictions, which are subsequently refined in the fine-grained\nstep. More generally, Qualifier Monotonicity implies that by attaching more\nqualifier pairs to a main triple, we may only narrow down the answer set, but\nnever enlarge it. This paper proposes the HyperMono model for hyper-relational\nknowledge graph completion, which realizes stage reasoning and qualifier\nmonotonicity. To implement qualifier monotonicity HyperMono resorts to cone\nembeddings. Experiments on three real-world datasets with three different\nscenario conditions demonstrate the strong performance of HyperMono when\ncompared to the SoTA.",
      "tldr_zh": "本论文针对超关系知识图（HKG）的完成任务（HKGC），提出了一种考虑单调性的新方法 HyperMono，以解决现有方法忽略的关键属性。HyperMono 通过实现阶段推理（Stage Reasoning），先从主三元组获取粗粒度推理结果，然后结合限定符进行细粒度优化；同时，它利用限定符单调性（Qualifier Monotonicity）和 cone embeddings，确保添加更多限定符对只会缩小答案集，而非扩大。实验在三个真实数据集和三种场景条件下表明，HyperMono 比现有最先进（SoTA）方法表现出显著优势。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09848v2",
      "published_date": "2024-04-15 15:00:17 UTC",
      "updated_date": "2024-08-13 09:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:30:56.306559"
    },
    {
      "arxiv_id": "2404.09833v1",
      "title": "Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video",
      "title_zh": "翻译失败",
      "authors": [
        "Hongchi Xia",
        "Zhi-Hao Lin",
        "Wei-Chiu Ma",
        "Shenlong Wang"
      ],
      "abstract": "Creating high-quality and interactive virtual environments, such as games and\nsimulators, often involves complex and costly manual modeling processes. In\nthis paper, we present Video2Game, a novel approach that automatically converts\nvideos of real-world scenes into realistic and interactive game environments.\nAt the heart of our system are three core components:(i) a neural radiance\nfields (NeRF) module that effectively captures the geometry and visual\nappearance of the scene; (ii) a mesh module that distills the knowledge from\nNeRF for faster rendering; and (iii) a physics module that models the\ninteractions and physical dynamics among the objects. By following the\ncarefully designed pipeline, one can construct an interactable and actionable\ndigital replica of the real world. We benchmark our system on both indoor and\nlarge-scale outdoor scenes. We show that we can not only produce\nhighly-realistic renderings in real-time, but also build interactive games on\ntop.",
      "tldr_zh": "本论文提出 Video2Game，一种创新方法，能从单个视频自动生成实时互动、真实且浏览器兼容的虚拟环境。\n该系统核心包括 Neural Radiance Fields (NeRF) 模块捕捉场景几何和视觉外观、Mesh 模块优化渲染速度，以及 Physics 模块模拟物体互动和物理动态。\n实验在室内和室外场景上验证，系统实现了高真实性实时渲染，并成功构建可交互游戏。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024. Project page (with code): https://video2game.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2404.09833v1",
      "published_date": "2024-04-15 14:32:32 UTC",
      "updated_date": "2024-04-15 14:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:31:04.890924"
    },
    {
      "arxiv_id": "2404.09830v1",
      "title": "Negation Triplet Extraction with Syntactic Dependency and Semantic Consistency",
      "title_zh": "基于句法依赖和语义一致性的否定三元组提取",
      "authors": [
        "Yuchen Shi",
        "Deqing Yang",
        "Jingping Liu",
        "Yanghua Xiao",
        "Zongyu Wang",
        "Huimin Xu"
      ],
      "abstract": "Previous works of negation understanding mainly focus on negation cue\ndetection and scope resolution, without identifying negation subject which is\nalso significant to the downstream tasks. In this paper, we propose a new\nnegation triplet extraction (NTE) task which aims to extract negation subject\nalong with negation cue and scope. To achieve NTE, we devise a novel\nSyntax&Semantic-Enhanced Negation Extraction model, namely SSENE, which is\nbuilt based on a generative pretrained language model (PLM) {of Encoder-Decoder\narchitecture} with a multi-task learning framework. Specifically, the given\nsentence's syntactic dependency tree is incorporated into the PLM's encoder to\ndiscover the correlations between the negation subject, cue and scope.\nMoreover, the semantic consistency between the sentence and the extracted\ntriplet is ensured by an auxiliary task learning. Furthermore, we have\nconstructed a high-quality Chinese dataset NegComment based on the users'\nreviews from the real-world platform of Meituan, upon which our evaluations\nshow that SSENE achieves the best NTE performance compared to the baselines.\nOur ablation and case studies also demonstrate that incorporating the syntactic\ninformation helps the PLM's recognize the distant dependency between the\nsubject and cue, and the auxiliary task learning is helpful to extract the\nnegation triplets with more semantic consistency.",
      "tldr_zh": "本文提出了一种新的否定三元组提取(NTE)任务，旨在同时提取否定主语、线索和范围，以弥补现有否定理解研究的不足。研究开发了SSENE模型，该模型基于生成式预训练语言模型(PLM)的Encoder-Decoder架构，通过整合句法依赖树发现三元组之间的相关性，并利用语义一致性辅助任务确保提取结果的准确性。此外，在构建的NegComment中文数据集上，SSENE比基线模型表现出色，消融实验证实句法信息和辅助任务有助于处理远距离依赖和提升语义一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09830v1",
      "published_date": "2024-04-15 14:28:33 UTC",
      "updated_date": "2024-04-15 14:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:31:18.668167"
    },
    {
      "arxiv_id": "2404.09828v2",
      "title": "Interaction as Explanation: A User Interaction-based Method for Explaining Image Classification Models",
      "title_zh": "交互作为解释：一种基于用户交互的方法用于解释图像分类模型",
      "authors": [
        "Hyeonggeun Yun"
      ],
      "abstract": "In computer vision, explainable AI (xAI) methods seek to mitigate the\n'black-box' problem by making the decision-making process of deep learning\nmodels more interpretable and transparent. Traditional xAI methods concentrate\non visualizing input features that influence model predictions, providing\ninsights primarily suited for experts. In this work, we present an\ninteraction-based xAI method that enhances user comprehension of image\nclassification models through their interaction. Thus, we developed a web-based\nprototype allowing users to modify images via painting and erasing, thereby\nobserving changes in classification results. Our approach enables users to\ndiscern critical features influencing the model's decision-making process,\naligning their mental models with the model's logic. Experiments conducted with\nfive images demonstrate the potential of the method to reveal feature\nimportance through user interaction. Our work contributes a novel perspective\nto xAI by centering on end-user engagement and understanding, paving the way\nfor more intuitive and accessible explainability in AI systems.",
      "tldr_zh": "这篇论文提出了一种基于用户交互的xAI方法，用于解释图像分类模型的决策过程，以解决传统xAI方法过于专业化的问题。该方法开发了一个网页原型，用户可以通过绘画和擦除等方式修改图像，并实时观察分类结果的变化，从而帮助用户识别影响模型决策的关键特征。实验使用五张图像验证了该方法的有效性，展示了它如何通过交互增强用户对模型逻辑的理解。该工作为xAI领域引入了以最终用户参与为核心的新视角，促进AI系统的可解释性和可访问性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "IJCAI 2024 (International Joint Conference on Artificial Intelligence\n  2024) Workshop on Explainable Artificial Intelligence (XAI)",
      "pdf_url": "http://arxiv.org/pdf/2404.09828v2",
      "published_date": "2024-04-15 14:26:00 UTC",
      "updated_date": "2024-08-14 09:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:31:29.735138"
    },
    {
      "arxiv_id": "2404.09819v1",
      "title": "3D Face Tracking from 2D Video through Iterative Dense UV to Image Flow",
      "title_zh": "从 2D 视频通过迭代密集 UV 到",
      "authors": [
        "Felix Taubner",
        "Prashant Raina",
        "Mathieu Tuli",
        "Eu Wern Teh",
        "Chul Lee",
        "Jinmiao Huang"
      ],
      "abstract": "When working with 3D facial data, improving fidelity and avoiding the uncanny\nvalley effect is critically dependent on accurate 3D facial performance\ncapture. Because such methods are expensive and due to the widespread\navailability of 2D videos, recent methods have focused on how to perform\nmonocular 3D face tracking. However, these methods often fall short in\ncapturing precise facial movements due to limitations in their network\narchitecture, training, and evaluation processes. Addressing these challenges,\nwe propose a novel face tracker, FlowFace, that introduces an innovative 2D\nalignment network for dense per-vertex alignment. Unlike prior work, FlowFace\nis trained on high-quality 3D scan annotations rather than weak supervision or\nsynthetic data. Our 3D model fitting module jointly fits a 3D face model from\none or many observations, integrating existing neutral shape priors for\nenhanced identity and expression disentanglement and per-vertex deformations\nfor detailed facial feature reconstruction. Additionally, we propose a novel\nmetric and benchmark for assessing tracking accuracy. Our method exhibits\nsuperior performance on both custom and publicly available benchmarks. We\nfurther validate the effectiveness of our tracker by generating high-quality 3D\ndata from 2D videos, which leads to performance gains on downstream tasks.",
      "tldr_zh": "该论文针对从2D视频进行3D面部跟踪的问题，提出了一种名为FlowFace的创新方法，通过迭代密集UV到图像流来实现精确的每个顶点对齐，以避免uncanny valley效应。FlowFace使用高质量3D扫描注释进行训练，并整合neutral shape priors和per-vertex deformations的3D模型拟合模块，实现身份和表情的更好分离以及详细面部重建。该方法引入了一个新指标和基准，在自定义和公开基准上表现出优越性能，并通过从2D视频生成高质量3D数据，提升了下游任务的整体效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 25 figures, to be published in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09819v1",
      "published_date": "2024-04-15 14:20:07 UTC",
      "updated_date": "2024-04-15 14:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:31:44.888771"
    },
    {
      "arxiv_id": "2404.10031v1",
      "title": "Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks",
      "title_zh": "基于弱监督的涌现语言符号自编码器 (ELSA) 用于建模分层脑网络",
      "authors": [
        "Ammar Ahmed Pallikonda Latheef",
        "Alberto Santamaria-Pang",
        "Craig K Jones",
        "Haris I Sair"
      ],
      "abstract": "Brain networks display a hierarchical organization, a complexity that poses a\nchallenge for existing deep learning models, often structured as flat\nclassifiers, leading to difficulties in interpretability and the 'black box'\nissue. To bridge this gap, we propose a novel architecture: a symbolic\nautoencoder informed by weak supervision and an Emergent Language (EL)\nframework. This model moves beyond traditional flat classifiers by producing\nhierarchical clusters and corresponding imagery, subsequently represented\nthrough symbolic sentences to improve the clinical interpretability of\nhierarchically organized data such as intrinsic brain networks, which can be\ncharacterized using resting-state fMRI images. Our innovation includes a\ngeneralized hierarchical loss function designed to ensure that both sentences\nand images accurately reflect the hierarchical structure of functional brain\nnetworks. This enables us to model functional brain networks from a broader\nperspective down to more granular details. Furthermore, we introduce a\nquantitative method to assess the hierarchical consistency of these symbolic\nrepresentations. Our qualitative analyses show that our model successfully\ngenerates hierarchically organized, clinically interpretable images, a finding\nsupported by our quantitative evaluations. We find that our best performing\nloss function leads to a hierarchical consistency of over 97% when identifying\nimages corresponding to brain networks. This approach not only advances the\ninterpretability of deep learning models in neuroimaging analysis but also\nrepresents a significant step towards modeling the intricate hierarchical\nnature of brain networks.",
      "tldr_zh": "本研究针对脑网络的层次组织结构，提出了一种名为 Emergent Language Symbolic Autoencoder (ELSA) 的新架构，利用弱监督 (weak supervision) 和 Emergent Language (EL) 框架，生成层次聚类、对应图像以及符号句子，以提升神经影像分析的可解释性。模型创新性地引入了一个通用的层次损失函数 (hierarchical loss function)，确保符号表示和图像准确反映功能脑网络的层次细节，并提供量化方法评估层次一致性。实验结果显示，该模型在识别脑网络图像时实现了超过97%的层次一致性，不仅提高了深度学习模型的临床可解释性，还为建模脑网络的复杂层次性提供了重要进展。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.10031v1",
      "published_date": "2024-04-15 13:51:05 UTC",
      "updated_date": "2024-04-15 13:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:31:55.042746"
    },
    {
      "arxiv_id": "2406.15374v1",
      "title": "Hybrid Intelligence for Digital Humanities",
      "title_zh": "翻译失败",
      "authors": [
        "Victor de Boer",
        "Lise Stork"
      ],
      "abstract": "In this paper, we explore the synergies between Digital Humanities (DH) as a\ndiscipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,\nthe use of digital methods and specifically that of Artificial Intelligence is\nsubject to a set of requirements and constraints. We argue that these are\nwell-supported by the capabilities and goals of HI. Our contribution includes\nthe identification of five such DH requirements: Successful AI systems need to\nbe able to 1) collaborate with the (human) scholar; 2) support data criticism;\n3) support tool criticism; 4) be aware of and cater to various perspectives and\n5) support distant and close reading. We take the CARE principles of Hybrid\nIntelligence (collaborative, adaptive, responsible and explainable) as\ntheoretical framework and map these to the DH requirements. In this mapping, we\ninclude example research projects. We finally address how insights from DH can\nbe applied to HI and discuss open challenges for the combination of the two\ndisciplines.",
      "tldr_zh": "这篇论文探讨了数字人文(DH)与混合智能(HI)之间的协同作用，强调HI如何满足DH在AI应用中的特定要求。论文识别了五个关键DH要求：1) 与人类学者协作；2) 支持数据批评；3) 支持工具批评；4) 意识到并满足各种视角；5) 支持远距离和近距离阅读，并使用HI的CARE原则(collaborative, adaptive, responsible, explainable)作为理论框架进行映射，同时举例研究项目。最终，它讨论了从DH中获得的见解如何应用于HI，以及两者的开放挑战，以推动更有效的跨学科整合。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint for paper accepted for HHAI2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.15374v1",
      "published_date": "2024-04-15 13:30:47 UTC",
      "updated_date": "2024-04-15 13:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:32:08.513948"
    },
    {
      "arxiv_id": "2404.09763v1",
      "title": "KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Anand",
        "Mohit Gupta",
        "Kritarth Prasad",
        "Ujjwal Goel",
        "Naman Lal",
        "Astha Verma",
        "Rajiv Ratn Shah"
      ],
      "abstract": "Citation Text Generation (CTG) is a task in natural language processing (NLP)\nthat aims to produce text that accurately cites or references a cited document\nwithin a source document. In CTG, the generated text draws upon contextual cues\nfrom both the source document and the cited paper, ensuring accurate and\nrelevant citation information is provided. Previous work in the field of\ncitation generation is mainly based on the text summarization of documents.\nFollowing this, this paper presents a framework, and a comparative study to\ndemonstrate the use of Large Language Models (LLMs) for the task of citation\ngeneration. Also, we have shown the improvement in the results of citation\ngeneration by incorporating the knowledge graph relations of the papers in the\nprompt for the LLM to better learn the relationship between the papers. To\nassess how well our model is performing, we have used a subset of standard\nS2ORC dataset, which only consists of computer science academic research papers\nin the English Language. Vicuna performs best for this task with 14.15 Meteor,\n12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and\nimproves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by\nincluding knowledge graphs.",
      "tldr_zh": "这篇论文介绍了 KG-CTG 框架，利用 Knowledge Graph-guided Large Language Models (LLMs) 来处理 Citation Text Generation (CTG) 任务，即生成准确引用源文档和被引文档的文本。不同于传统的基于文本摘要的方法，该框架通过在 LLM 提示中整合论文间的知识图谱关系，帮助模型更好地学习论文关联，从而提升生成质量。在 S2ORC 数据集的子集上实验表明，Vicuna 模型表现出色，达到 14.15 Meteor、12.88 Rouge-1 和 10.94 Rouge-L 等指标，而 Alpaca 模型通过加入知识图谱，Rouge-1 提高了 36.98%，Meteor 提高了 33.14%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09763v1",
      "published_date": "2024-04-15 13:06:32 UTC",
      "updated_date": "2024-04-15 13:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:32:20.293930"
    },
    {
      "arxiv_id": "2404.09760v1",
      "title": "Effective Reinforcement Learning Based on Structural Information Principles",
      "title_zh": "基于结构信息原则的有效强化学习",
      "authors": [
        "Xianghua Zeng",
        "Hao Peng",
        "Dingli Su",
        "Angsheng Li"
      ],
      "abstract": "Although Reinforcement Learning (RL) algorithms acquire sequential behavioral\npatterns through interactions with the environment, their effectiveness in\nnoisy and high-dimensional scenarios typically relies on specific structural\npriors. In this paper, we propose a novel and general Structural Information\nprinciples-based framework for effective Decision-Making, namely SIDM,\napproached from an information-theoretic perspective. This paper presents a\nspecific unsupervised partitioning method that forms vertex communities in the\nstate and action spaces based on their feature similarities. An aggregation\nfunction, which utilizes structural entropy as the vertex weight, is devised\nwithin each community to obtain its embedding, thereby facilitating\nhierarchical state and action abstractions. By extracting abstract elements\nfrom historical trajectories, a directed, weighted, homogeneous transition\ngraph is constructed. The minimization of this graph's high-dimensional entropy\nleads to the generation of an optimal encoding tree. An innovative two-layer\nskill-based learning mechanism is introduced to compute the common path entropy\nof each state transition as its identified probability, thereby obviating the\nrequirement for expert knowledge. Moreover, SIDM can be flexibly incorporated\ninto various single-agent and multi-agent RL algorithms, enhancing their\nperformance. Finally, extensive evaluations on challenging benchmarks\ndemonstrate that, compared with SOTA baselines, our framework significantly and\nconsistently improves the policy's quality, stability, and efficiency up to\n32.70%, 88.26%, and 64.86%, respectively.",
      "tldr_zh": "本论文提出了一种基于结构信息原则（Structural Information principles）的框架 SIDM，用于提升强化学习（Reinforcement Learning, RL）在嘈杂和高维环境中的决策有效性。该框架从信息论视角出发，采用无监督分区方法基于特征相似性在状态和动作空间形成顶点社区，并利用结构熵（structural entropy）作为权重进行层次化抽象和嵌入提取。随后，通过构建有向加权转移图并最小化其高维熵生成最优编码树，以及引入两层技能学习机制计算状态转移概率，SIDM 消除了对专家知识的依赖，并可灵活整合到各种单代理和多代理 RL 算法中。实验结果显示，与最先进基线相比，SIDM 分别提高了策略质量、稳定性和效率高达 32.70%、88.26% 和 64.86%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09760v1",
      "published_date": "2024-04-15 13:02:00 UTC",
      "updated_date": "2024-04-15 13:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:32:31.810861"
    },
    {
      "arxiv_id": "2404.09752v1",
      "title": "Can We Break Free from Strong Data Augmentations in Self-Supervised Learning?",
      "title_zh": "我们能否摆脱自监督学习中的强数据增强？",
      "authors": [
        "Shruthi Gowda",
        "Elahe Arani",
        "Bahram Zonooz"
      ],
      "abstract": "Self-supervised learning (SSL) has emerged as a promising solution for\naddressing the challenge of limited labeled data in deep neural networks\n(DNNs), offering scalability potential. However, the impact of design\ndependencies within the SSL framework remains insufficiently investigated. In\nthis study, we comprehensively explore SSL behavior across a spectrum of\naugmentations, revealing their crucial role in shaping SSL model performance\nand learning mechanisms. Leveraging these insights, we propose a novel learning\napproach that integrates prior knowledge, with the aim of curtailing the need\nfor extensive data augmentations and thereby amplifying the efficacy of learned\nrepresentations. Notably, our findings underscore that SSL models imbued with\nprior knowledge exhibit reduced texture bias, diminished reliance on shortcuts\nand augmentations, and improved robustness against both natural and adversarial\ncorruptions. These findings not only illuminate a new direction in SSL\nresearch, but also pave the way for enhancing DNN performance while\nconcurrently alleviating the imperative for intensive data augmentation,\nthereby enhancing scalability and real-world problem-solving capabilities.",
      "tldr_zh": "本研究探讨了自监督学习 (SSL) 中对强数据增强的依赖问题，通过全面分析不同增强策略对 SSL 模型性能和学习机制的影响。作者提出了一种整合先验知识的新学习方法，旨在减少对广泛数据增强的需要，同时提升模型的表示学习效率。结果显示，这种方法显著降低了纹理偏差 (texture bias)、对捷径和增强的依赖，并提高了模型对自然和对抗性腐败 (adversarial corruptions) 的鲁棒性。这些发现为 SSL 研究开辟新方向，提升了深度神经网络 (DNNs) 的可扩展性和实际问题解决能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09752v1",
      "published_date": "2024-04-15 12:53:48 UTC",
      "updated_date": "2024-04-15 12:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:32:42.326767"
    },
    {
      "arxiv_id": "2404.09738v2",
      "title": "AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides",
      "title_zh": "翻译失败",
      "authors": [
        "Kewei Li",
        "Yuqian Wu",
        "Yinheng Li",
        "Yutong Guo",
        "Yan Wang",
        "Yiyang Liang",
        "Yusi Fan",
        "Lan Huang",
        "Ruochi Zhang",
        "Fengfeng Zhou"
      ],
      "abstract": "Since the mechanism of action of drug molecules in the human body is\ndifficult to reproduce in the in vitro environment, it becomes difficult to\nreveal the causes of the activity cliff phenomenon of drug molecules. We found\nout the AC of small molecules has been extensively investigated but limited\nknowledge is accumulated about the AC phenomenon in peptides with canonical\namino acids. Understanding the mechanism of AC in canonical amino acids might\nhelp understand the one in drug molecules. This study introduces a quantitative\ndefinition and benchmarking framework AMPCliff for the AC phenomenon in\nantimicrobial peptides (AMPs) composed by canonical amino acids. A\ncomprehensive analysis of the existing AMP dataset reveals a significant\nprevalence of AC within AMPs. AMPCliff quantifies the activities of AMPs by the\nMIC, and defines 0.9 as the minimum threshold for the normalized BLOSUM62\nsimilarity score between a pair of aligned peptides with at least two-fold MIC\nchanges. This study establishes a benchmark dataset of paired AMPs in\nStaphylococcus aureus from the publicly available AMP dataset GRAMPA, and\nconducts a rigorous procedure to evaluate various AMP AC prediction models,\nincluding nine machine learning, four deep learning algorithms, four masked\nlanguage models, and four generative language models. Our analysis reveals that\nthese models are capable of detecting AMP AC events and the pre-trained protein\nlanguage model ESM2 demonstrates superior performance across the evaluations.\nThe predictive performance of AMP activity cliffs remains to be further\nimproved, considering that ESM2 with 33 layers only achieves the Spearman\ncorrelation coefficient 0.4669 for the regression task of the MIC values on the\nbenchmark dataset. Source code and additional resources are available at\nhttps://www.healthinformaticslab.org/supp/ or\nhttps://github.com/Kewei2023/AMPCliff-generation.",
      "tldr_zh": "该研究提出AMPCliff框架，用于量化定义和基准测试抗imicrobial peptides (AMPs)中的activity cliffs (AC)现象，以帮助理解药物分子AC机制。AMPCliff通过MIC量化AMPs活性，并将normalized BLOSUM62相似分数的最小阈值设为0.9，用于识别具有至少两倍MIC变化的肽对，同时从GRAMPA数据集建立针对Staphylococcus aureus的基准数据集。研究评估了多种模型，包括九种machine learning、四种deep learning、四种masked language models和四种generative language models，结果显示预训练的蛋白质语言模型ESM2在检测AC事件中表现最佳，但其在MIC回归任务上的Spearman correlation coefficient仅为0.4669，表明预测性能仍有改进空间。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09738v2",
      "published_date": "2024-04-15 12:40:12 UTC",
      "updated_date": "2024-11-03 11:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:32:56.924794"
    },
    {
      "arxiv_id": "2404.09722v1",
      "title": "VFLGAN: Vertical Federated Learning-based Generative Adversarial Network for Vertically Partitioned Data Publication",
      "title_zh": "翻译失败",
      "authors": [
        "Xun Yuan",
        "Yang Yang",
        "Prosanta Gope",
        "Aryan Pasikhani",
        "Biplab Sikdar"
      ],
      "abstract": "In the current artificial intelligence (AI) era, the scale and quality of the\ndataset play a crucial role in training a high-quality AI model. However, good\ndata is not a free lunch and is always hard to access due to privacy\nregulations like the General Data Protection Regulation (GDPR). A potential\nsolution is to release a synthetic dataset with a similar distribution to that\nof the private dataset. Nevertheless, in some scenarios, it has been found that\nthe attributes needed to train an AI model belong to different parties, and\nthey cannot share the raw data for synthetic data publication due to privacy\nregulations. In PETS 2023, Xue et al. proposed the first generative adversary\nnetwork-based model, VertiGAN, for vertically partitioned data publication.\nHowever, after thoroughly investigating, we found that VertiGAN is less\neffective in preserving the correlation among the attributes of different\nparties. This article proposes a Vertical Federated Learning-based Generative\nAdversarial Network, VFLGAN, for vertically partitioned data publication to\naddress the above issues. Our experimental results show that compared with\nVertiGAN, VFLGAN significantly improves the quality of synthetic data. Taking\nthe MNIST dataset as an example, the quality of the synthetic dataset generated\nby VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t. the\nFr\\'echet Distance. We also designed a more efficient and effective Gaussian\nmechanism for the proposed VFLGAN to provide the synthetic dataset with a\ndifferential privacy guarantee. On the other hand, differential privacy only\ngives the upper bound of the worst-case privacy guarantee. This article also\nproposes a practical auditing scheme that applies membership inference attacks\nto estimate privacy leakage through the synthetic dataset.",
      "tldr_zh": "该论文提出VFLGAN，一种基于Vertical Federated Learning的Generative Adversarial Network，用于处理垂直分区数据（Vertically Partitioned Data）的合成数据发布，以解决隐私法规（如GDPR）限制下数据共享的问题。相比现有模型VertiGAN，VFLGAN显著改善了不同属性间的相关性保留，提升了合成数据质量，例如在MNIST数据集上，Fréchet Distance指标提高了3.2倍。论文还引入了高效的Gaussian机制提供Differential Privacy保证，并设计了一种基于Membership Inference Attacks的审计方案，以实际评估隐私泄露风险。整体上，这为隐私保护下的AI数据发布提供了更可靠的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09722v1",
      "published_date": "2024-04-15 12:25:41 UTC",
      "updated_date": "2024-04-15 12:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:33:06.644272"
    },
    {
      "arxiv_id": "2404.09717v1",
      "title": "Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsoo Cho"
      ],
      "abstract": "Many recent studies endeavor to improve open-source language models through\nimitation learning, and re-training on the synthetic instruction data from\nstate-of-the-art proprietary models like ChatGPT and GPT-4. However, the innate\nnature of synthetic data inherently contains noisy data, giving rise to a\nsubstantial presence of low-quality data replete with erroneous responses, and\nflawed reasoning. Although we intuitively grasp the potential harm of noisy\ndata, we lack a quantitative understanding of its impact. To this end, this\npaper explores the correlation between the degree of noise and its impact on\nlanguage models through instruction tuning. We first introduce the\nFalsity-Controllable (FACO) dataset, which comprises pairs of true answers with\ncorresponding reasoning, as well as false pairs to manually control the falsity\nratio of the dataset.Through our extensive experiments, we found multiple\nintriguing findings of the correlation between the factuality of the dataset\nand instruction tuning: Specifically, we verified falsity of the instruction is\nhighly relevant to various benchmark scores. Moreover, when LLMs are trained\nwith false instructions, they learn to lie and generate fake unfaithful\nanswers, even though they know the correct answer for the user request.\nAdditionally, we noted that once the language model is trained with a dataset\ncontaminated by noise, restoring its original performance is possible, but it\nfailed to reach full performance.",
      "tldr_zh": "本研究探讨了模仿学习(Imitation Learning)中合成数据噪声对大型语言模型(Large Language Model)的影响，特别关注由ChatGPT和GPT-4等模型生成的低质量数据。论文引入了Falsity-Controllable (FACO)数据集，通过控制虚假比率进行指令调整实验，发现虚假指令会显著降低基准分数，并使模型学会生成不准确的响应，即使它知道正确答案。此外，训练后即使尝试恢复，模型也无法完全达到原有性能，这为优化语言模型的训练过程提供了关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review @ *ACL",
      "pdf_url": "http://arxiv.org/pdf/2404.09717v1",
      "published_date": "2024-04-15 12:20:09 UTC",
      "updated_date": "2024-04-15 12:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:33:19.508778"
    },
    {
      "arxiv_id": "2404.09715v1",
      "title": "Higher Replay Ratio Empowers Sample-Efficient Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Linjie Xu",
        "Zichuan Liu",
        "Alexander Dockhorn",
        "Diego Perez-Liebana",
        "Jinyu Wang",
        "Lei Song",
        "Jiang Bian"
      ],
      "abstract": "One of the notorious issues for Reinforcement Learning (RL) is poor sample\nefficiency. Compared to single agent RL, the sample efficiency for Multi-Agent\nReinforcement Learning (MARL) is more challenging because of its inherent\npartial observability, non-stationary training, and enormous strategy space.\nAlthough much effort has been devoted to developing new methods and enhancing\nsample efficiency, we look at the widely used episodic training mechanism. In\neach training step, tens of frames are collected, but only one gradient step is\nmade. We argue that this episodic training could be a source of poor sample\nefficiency. To better exploit the data already collected, we propose to\nincrease the frequency of the gradient updates per environment interaction\n(a.k.a. Replay Ratio or Update-To-Data ratio). To show its generality, we\nevaluate $3$ MARL methods on $6$ SMAC tasks. The empirical results validate\nthat a higher replay ratio significantly improves the sample efficiency for\nMARL algorithms. The codes to reimplement the results presented in this paper\nare open-sourced at https://anonymous.4open.science/r/rr_for_MARL-0D83/.",
      "tldr_zh": "这篇论文针对 Multi-Agent Reinforcement Learning (MARL) 的样本效率问题，提出通过提高 Replay Ratio（重放比率或 Update-To-Data ratio）来增加每个环境交互的梯度更新频率，从而更好地利用已收集的数据。实验在 6 个 SMAC 任务上评估了 3 个 MARL 方法，结果显示更高的 Replay Ratio 显著提升了算法的样本效率，改善了 MARL 固有的部分可观察性和非平稳训练挑战。该方法为强化学习训练机制的优化提供了通用见解，并开源了代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09715v1",
      "published_date": "2024-04-15 12:18:09 UTC",
      "updated_date": "2024-04-15 12:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:33:32.057919"
    },
    {
      "arxiv_id": "2404.09707v1",
      "title": "Adaptive Patching for High-resolution Image Segmentation with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Enzhi Zhang",
        "Isaac Lyngaas",
        "Peng Chen",
        "Xiao Wang",
        "Jun Igarashi",
        "Yuankai Huo",
        "Mohamed Wahib",
        "Masaharu Munetomo"
      ],
      "abstract": "Attention-based models are proliferating in the space of image analytics,\nincluding segmentation. The standard method of feeding images to transformer\nencoders is to divide the images into patches and then feed the patches to the\nmodel as a linear sequence of tokens. For high-resolution images, e.g.\nmicroscopic pathology images, the quadratic compute and memory cost prohibits\nthe use of an attention-based model, if we are to use smaller patch sizes that\nare favorable in segmentation. The solution is to either use custom complex\nmulti-resolution models or approximate attention schemes. We take inspiration\nfrom Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching the\nimages, as a pre-processing step, based on the image details to reduce the\nnumber of patches being fed to the model, by orders of magnitude. This method\nhas a negligible overhead, and works seamlessly with any attention-based model,\ni.e. it is a pre-processing step that can be adopted by any attention-based\nmodel without friction. We demonstrate superior segmentation quality over SoTA\nsegmentation models for real-world pathology datasets while gaining a geomean\nspeedup of $6.9\\times$ for resolutions up to $64K^2$, on up to $2,048$ GPUs.",
      "tldr_zh": "本论文提出了一种Adaptive Patching方法，用于处理Transformer模型在高分辨率图像分割中的计算和内存开销问题，特别是针对显微病理图像。该方法借鉴High-Performance Computing中的Adaptive Mesh Refinement (AMR)技术，作为预处理步骤，根据图像细节自适应地分块，从而将输入patches数量减少几个数量级，并与任何Attention-based模型无缝兼容。实验结果显示，该方法在真实病理数据集上实现了优于SoTA分割模型的质量，同时在高达64K^2分辨率的图像上获得了6.9倍的几何平均速度提升，并在多达2,048 GPUs上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09707v1",
      "published_date": "2024-04-15 12:06:00 UTC",
      "updated_date": "2024-04-15 12:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:33:46.302513"
    },
    {
      "arxiv_id": "2404.09696v1",
      "title": "Are Large Language Models Reliable Argument Quality Annotators?",
      "title_zh": "大型语言模型是可靠的论点质量标注者吗？",
      "authors": [
        "Nailia Mirzakhmedova",
        "Marcel Gohsen",
        "Chia Hao Chang",
        "Benno Stein"
      ],
      "abstract": "Evaluating the quality of arguments is a crucial aspect of any system\nleveraging argument mining. However, it is a challenge to obtain reliable and\nconsistent annotations regarding argument quality, as this usually requires\ndomain-specific expertise of the annotators. Even among experts, the assessment\nof argument quality is often inconsistent due to the inherent subjectivity of\nthis task. In this paper, we study the potential of using state-of-the-art\nlarge language models (LLMs) as proxies for argument quality annotators. To\nassess the capability of LLMs in this regard, we analyze the agreement between\nmodel, human expert, and human novice annotators based on an established\ntaxonomy of argument quality dimensions. Our findings highlight that LLMs can\nproduce consistent annotations, with a moderately high agreement with human\nexperts across most of the quality dimensions. Moreover, we show that using\nLLMs as additional annotators can significantly improve the agreement between\nannotators. These results suggest that LLMs can serve as a valuable tool for\nautomated argument quality assessment, thus streamlining and accelerating the\nevaluation of large argument datasets.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 是否能作为可靠的论点质量标注者，因为传统标注过程往往受限于人类专家的主观性和一致性问题。研究方法涉及分析 LLMs 与人类专家及新手标注者在已建立的论点质量维度分类上的同意度。结果显示，LLMs 可以产生高度一致的标注，与专家在大多数维度上达到中等高同意度，且将其作为额外标注者能显著提升整体标注一致性。这些发现表明，LLMs 可作为自动化论点质量评估的宝贵工具，加速大型论点数据集的评估过程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.09696v1",
      "published_date": "2024-04-15 11:54:27 UTC",
      "updated_date": "2024-04-15 11:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:33:58.332602"
    },
    {
      "arxiv_id": "2404.09695v1",
      "title": "LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models",
      "title_zh": "LoRAP：",
      "authors": [
        "Guangyan Li",
        "Yongqiang Tang",
        "Wensheng Zhang"
      ],
      "abstract": "Large language models (LLMs) show excellent performance in difficult tasks,\nbut they often require massive memories and computational resources. How to\nreduce the parameter scale of LLMs has become research hotspots. In this study,\nwe make an important observation that the multi-head self-attention (MHA)\nsub-layer of Transformer exhibits noticeable low-rank structure, while the\nfeed-forward network (FFN) sub-layer does not. With this regard, we design a\nmixed compression model, which organically combines Low-Rank matrix\napproximation And structured Pruning (LoRAP). For the MHA sub-layer, we propose\nan input activation weighted singular value decomposition method to strengthen\nthe low-rank characteristic. Furthermore, we discover that the weight matrices\nin MHA sub-layer have different low-rank degrees. Thus, a novel parameter\nallocation scheme according to the discrepancy of low-rank degrees is devised.\nFor the FFN sub-layer, we propose a gradient-free structured channel pruning\nmethod. During the pruning, we get an interesting finding that the least\nimportant 1% of parameter actually play a vital role in model performance.\nExtensive evaluations on zero-shot perplexity and zero-shot task classification\nindicate that our proposal is superior to previous structured compression\nrivals under multiple compression ratios.",
      "tldr_zh": "本研究观察到，Transformer 中的多头自注意力 (MHA) 子层表现出明显的低秩结构，而前馈网络 (FFN) 子层则不然，因此提出 LoRAP 模型，将 Low-Rank 矩阵逼近和结构化 Pruning 相结合。对于 MHA 子层，采用输入激活加权的奇异值分解方法增强低秩特性，并根据不同低秩程度的差异设计参数分配方案；对于 FFN 子层，使用无梯度结构化通道剪枝方法。实验发现，剪枝时最不重要的 1% 参数对模型性能至关重要，且 LoRAP 在多种压缩比率下，在零样本困惑度和任务分类上优于现有结构化压缩方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages,4 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.09695v1",
      "published_date": "2024-04-15 11:53:22 UTC",
      "updated_date": "2024-04-15 11:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:34:10.065711"
    },
    {
      "arxiv_id": "2405.09552v2",
      "title": "ODFormer: Semantic Fundus Image Segmentation Using Transformer for Optic Nerve Head Detection",
      "title_zh": "ODFormer：利用 Transformer 进行语义眼底图像分割以检测视神经盘",
      "authors": [
        "Jiayi Wang",
        "Yi-An Mao",
        "Xiaoyu Ma",
        "Sicen Guo",
        "Yuting Shao",
        "Xiao Lv",
        "Wenting Han",
        "Mark Christopher",
        "Linda M. Zangwill",
        "Yanlong Bi",
        "Rui Fan"
      ],
      "abstract": "Optic nerve head (ONH) detection has been a crucial area of study in\nophthalmology for years. However, the significant discrepancy between fundus\nimage datasets, each generated using a single type of fundus camera, poses\nchallenges to the generalizability of ONH detection approaches developed based\non semantic segmentation networks. Despite the numerous recent advancements in\ngeneral-purpose semantic segmentation methods using convolutional neural\nnetworks (CNNs) and Transformers, there is currently a lack of benchmarks for\nthese state-of-the-art (SoTA) networks specifically trained for ONH detection.\nTherefore, in this article, we make contributions from three key aspects:\nnetwork design, the publication of a dataset, and the establishment of a\ncomprehensive benchmark. Our newly developed ONH detection network, referred to\nas ODFormer, is based upon the Swin Transformer architecture and incorporates\ntwo novel components: a multi-scale context aggregator and a lightweight\nbidirectional feature recalibrator. Our published large-scale dataset, known as\nTongjiU-DROD, provides multi-resolution fundus images for each participant,\ncaptured using two distinct types of cameras. Our established benchmark\ninvolves three datasets: DRIONS-DB, DRISHTI-GS1, and TongjiU-DROD, created by\nresearchers from different countries and containing fundus images captured from\nparticipants of diverse races and ages. Extensive experimental results\ndemonstrate that our proposed ODFormer outperforms other state-of-the-art\n(SoTA) networks in terms of performance and generalizability. Our dataset and\nsource code are publicly available at mias.group/ODFormer.",
      "tldr_zh": "该论文针对视神经头（Optic Nerve Head, ONH）检测问题，提出了一种基于 Transformer 的语义分割网络 ODFormer，以解决不同眼底图像数据集间差异导致的模型泛化性挑战。ODFormer 构建于 Swin Transformer 架构之上，引入了多尺度上下文聚合器（multi-scale context aggregator）和轻量级双向特征重新校准器（lightweight bidirectional feature recalibrator），提升了图像分割的准确性和鲁棒性。同时，论文发布了大型数据集 TongjiU-DROD，提供多分辨率眼底图像，并建立了包括 DRIONS-DB、DRISHTI-GS1 和 TongjiU-DROD 在内的综合基准，覆盖多样化人群。实验结果显示，ODFormer 在性能和泛化性上优于现有最先进（SoTA）网络，为眼科图像分析提供了新标准。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09552v2",
      "published_date": "2024-04-15 11:49:37 UTC",
      "updated_date": "2024-06-02 10:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:34:23.010437"
    },
    {
      "arxiv_id": "2404.09690v1",
      "title": "Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Chenwei Lin",
        "Hanjia Lyu",
        "Jiebo Luo",
        "Xian Xu"
      ],
      "abstract": "The emergence of Large Multimodal Models (LMMs) marks a significant milestone\nin the development of artificial intelligence. Insurance, as a vast and complex\ndiscipline, involves a wide variety of data forms in its operational processes,\nincluding text, images, and videos, thereby giving rise to diverse multimodal\ntasks. Despite this, there has been limited systematic exploration of\nmultimodal tasks specific to insurance, nor a thorough investigation into how\nLMMs can address these challenges. In this paper, we explore GPT-4V's\ncapabilities in the insurance domain. We categorize multimodal tasks by\nfocusing primarily on visual aspects based on types of insurance (e.g., auto,\nhousehold/commercial property, health, and agricultural insurance) and\ninsurance stages (e.g., risk assessment, risk monitoring, and claims\nprocessing). Our experiment reveals that GPT-4V exhibits remarkable abilities\nin insurance-related tasks, demonstrating not only a robust understanding of\nmultimodal content in the insurance domain but also a comprehensive knowledge\nof insurance scenarios. However, there are notable shortcomings: GPT-4V\nstruggles with detailed risk rating and loss assessment, suffers from\nhallucination in image understanding, and shows variable support for different\nlanguages. Through this work, we aim to bridge the insurance domain with\ncutting-edge LMM technology, facilitate interdisciplinary exchange and\ndevelopment, and provide a foundation for the continued advancement and\nevolution of future research endeavors.",
      "tldr_zh": "本研究探索了大型多模态模型(LMMs)如GPT-4V在保险领域的初步应用，通过分类基于保险类型（如汽车、健康和农业保险）和阶段（如风险评估、风险监控及理赔处理）的多模态任务，进行系统实验。结果显示，GPT-4V在理解保险场景的多模态内容（如文本、图像和视频）方面表现出色，具有强大的知识整合能力。然而，该模型在详细风险评估和损失评估中存在挑战，还面临图像理解中的幻觉问题以及语言支持不一致的局限性。该工作旨在桥接保险领域与LMMs技术，促进跨学科交流，并为未来研究奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09690v1",
      "published_date": "2024-04-15 11:45:30 UTC",
      "updated_date": "2024-04-15 11:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:34:32.783012"
    },
    {
      "arxiv_id": "2404.09687v1",
      "title": "Plus Strategies are Exponentially Slower for Planted Optima of Random Height",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Lengler",
        "Leon Schiller",
        "Oliver Sieberling"
      ],
      "abstract": "We compare the $(1,\\lambda)$-EA and the $(1 + \\lambda)$-EA on the recently\nintroduced benchmark DisOM, which is the OneMax function with randomly planted\nlocal optima. Previous work showed that if all local optima have the same\nrelative height, then the plus strategy never loses more than a factor $O(n\\log\nn)$ compared to the comma strategy. Here we show that even small random\nfluctuations in the heights of the local optima have a devastating effect for\nthe plus strategy and lead to super-polynomial runtimes. On the other hand, due\nto their ability to escape local optima, comma strategies are unaffected by the\nheight of the local optima and remain efficient. Our results hold for a broad\nclass of possible distortions and show that the plus strategy, but not the\ncomma strategy, is generally deceived by sparse unstructured fluctuations of a\nsmooth landscape.",
      "tldr_zh": "该研究比较了（1, λ）-EA（逗号策略）和（1 + λ）-EA（加号策略）在 DisOM 基准上的性能，其中 DisOM 是 OneMax 函数添加随机植入局部最优。结果显示，即使局部最优高度有小随机波动，加号策略的运行时间会变得超多项式级慢，而逗号策略因其逃离局部最优的能力，能保持高效。这些发现适用于广泛的扭曲类，证明加号策略更容易被平滑景观的稀疏无结构波动误导。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.PR"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09687v1",
      "published_date": "2024-04-15 11:37:47 UTC",
      "updated_date": "2024-04-15 11:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:34:45.307741"
    },
    {
      "arxiv_id": "2404.09682v3",
      "title": "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Juhwan Choi",
        "Jungmin Yun",
        "Kyohoon Jin",
        "YoungBin Kim"
      ],
      "abstract": "The quality of the dataset is crucial for ensuring optimal performance and\nreliability of downstream task models. However, datasets often contain noisy\ndata inadvertently included during the construction process. Numerous attempts\nhave been made to correct this issue through human annotators. However, hiring\nand managing human annotators is expensive and time-consuming. As an\nalternative, recent studies are exploring the use of large language models\n(LLMs) for data annotation.\n  In this study, we present a case study that extends the application of\nLLM-based data annotation to enhance the quality of existing datasets through a\ncleansing strategy. Specifically, we leverage approaches such as\nchain-of-thought and majority voting to imitate human annotation and classify\nunrelated documents from the Multi-News dataset, which is widely used for the\nmulti-document summarization task. Through our proposed cleansing method, we\nintroduce an enhanced Multi-News+. By employing LLMs for data cleansing, we\ndemonstrate an efficient and effective approach to improving dataset quality\nwithout relying on expensive human annotation efforts.",
      "tldr_zh": "本研究针对数据集中的噪音数据问题，提出了一种基于大型语言模型（LLMs）的成本高效清洗策略，以提升数据集质量。该方法利用 chain-of-thought 和 majority voting 等技术模仿人类标注，从 Multi-News 数据集中分类并移除无关文档，从而创建了增强版数据集 Multi-News+。与传统依赖昂贵的人类标注相比，这种 LLM 驱动的方法显著提高了效率和效果，展示了在多文档摘要任务中优化数据集的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024: Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2404.09682v3",
      "published_date": "2024-04-15 11:36:10 UTC",
      "updated_date": "2024-09-24 02:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:34:56.088789"
    },
    {
      "arxiv_id": "2404.15354v2",
      "title": "Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of Function Slices Approach",
      "title_zh": "谱图神经网络中的多项式选择：一种函数切片误差和方法",
      "authors": [
        "Guoming Li",
        "Jian Yang",
        "Shangsong Liang",
        "Dongsheng Luo"
      ],
      "abstract": "Spectral graph neural networks are proposed to harness spectral information\ninherent in graph-structured data through the application of polynomial-defined\ngraph filters, recently achieving notable success in graph-based web\napplications. Existing studies reveal that various polynomial choices greatly\nimpact spectral GNN performance, underscoring the importance of polynomial\nselection. However, this selection process remains a critical and unresolved\nchallenge. Although prior work suggests a connection between the approximation\ncapabilities of polynomials and the efficacy of spectral GNNs, there is a lack\nof theoretical insights into this relationship, rendering polynomial selection\na largely heuristic process.\n  To address the issue, this paper examines polynomial selection from an\nerror-sum of function slices perspective. Inspired by the conventional signal\ndecomposition, we represent graph filters as a sum of disjoint function slices.\nBuilding on this, we then bridge the polynomial capability and spectral GNN\nefficacy by proving that the construction error of graph convolution layer is\nbounded by the sum of polynomial approximation errors on function slices. This\nresult leads us to develop an advanced filter based on trigonometric\npolynomials, a widely adopted option for approximating narrow signal slices.\nThe proposed filter remains provable parameter efficiency, with a novel\nTaylor-based parameter decomposition that achieves streamlined, effective\nimplementation. With this foundation, we propose TFGNN, a scalable spectral GNN\noperating in a decoupled paradigm. We validate the efficacy of TFGNN via\nbenchmark node classification tasks, along with an example graph anomaly\ndetection application to show its practical utility.",
      "tldr_zh": "这篇论文探讨了 spectral graph neural networks (spectral GNNs) 中 polynomial selection 的关键问题，通过 error-sum of function slices 的视角来优化选择过程。作者将 graph filters 表示为 disjoint function slices 的和，并证明 graph convolution layer 的 construction error 可由 function slices 上的 polynomial approximation errors 之和界定，从而建立了理论基础。基于此，他们开发了一种基于 trigonometric polynomials 的高级 filter，并提出 TFGNN，一个可扩展的 decoupled paradigm 下的 spectral GNN 框架。实验验证显示，TFGNN 在基准节点分类任务和图异常检测应用中表现出色，证明了其实际效用。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted in ACM The Web Conference 2025, WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.15354v2",
      "published_date": "2024-04-15 11:35:32 UTC",
      "updated_date": "2025-01-24 13:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:35:09.787200"
    },
    {
      "arxiv_id": "2404.13074v1",
      "title": "Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Amogh Mannekote"
      ],
      "abstract": "Compositional generalization is the ability of a model to generalize to\ncomplex, previously unseen types of combinations of entities from just having\nseen the primitives. This type of generalization is particularly relevant to\nthe semantic parsing community for applications such as task-oriented dialogue,\ntext-to-SQL parsing, and information retrieval, as they can harbor infinite\ncomplexity. Despite the success of large language models (LLMs) in a wide range\nof NLP tasks, unlocking perfect compositional generalization still remains one\nof the few last unsolved frontiers. The past few years has seen a surge of\ninterest in works that explore the limitations of, methods to improve, and\nevaluation metrics for compositional generalization capabilities of LLMs for\nsemantic parsing tasks. In this work, we present a literature survey geared at\nsynthesizing recent advances in analysis, methods, and evaluation schemes to\noffer a starting point for both practitioners and researchers in this area.",
      "tldr_zh": "这篇调查论文探讨了组合式泛化（Compositional Generalization）在大型语言模型（Large Language Models, LLMs）中的应用，特别针对语义解析（Semantic Parsing）任务，如任务导向对话、文本到SQL解析和信息检索。论文总结了LLMs在组合式泛化方面的局限性，包括模型无法从基本元素推断新组合的挑战，并回顾了最近的分析方法、改进策略和评估指标。总体而言，该工作为从业者和研究者提供了合成现有进展的起点，帮助推动LLMs在语义解析领域的更强泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13074v1",
      "published_date": "2024-04-15 10:44:58 UTC",
      "updated_date": "2024-04-15 10:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:35:21.221717"
    },
    {
      "arxiv_id": "2404.15204v1",
      "title": "Towards a high-performance AI compiler with upstream MLIR",
      "title_zh": "翻译失败",
      "authors": [
        "Renato Golin",
        "Lorenzo Chelini",
        "Adam Siemieniuk",
        "Kavitha Madhu",
        "Niranjan Hasabnis",
        "Hans Pabst",
        "Evangelos Georganas",
        "Alexander Heinecke"
      ],
      "abstract": "This work proposes a compilation flow using open-source compiler passes to\nbuild a framework to achieve ninja performance from a generic linear algebra\nhigh-level abstraction. We demonstrate this flow with a proof-of-concept MLIR\nproject that uses input IR in Linalg-on-Tensor from TensorFlow and PyTorch,\nperforms cache-level optimizations and lowering to micro-kernels for efficient\nvectorization, achieving over 90% of the performance of ninja-written\nequivalent programs. The contributions of this work include: (1) Packing\nprimitives on the tensor dialect and passes for cache-aware distribution of\ntensors (single and multi-core) and type-aware instructions (VNNI, BFDOT,\nBFMMLA), including propagation of shapes across the entire function; (2) A\nlinear algebra pipeline, including tile, fuse and bufferization strategies to\nget model-level IR into hardware friendly tile calls; (3) A mechanism for\nmicro-kernel lowering to an open source library that supports various CPUs.",
      "tldr_zh": "本研究提出了一种基于上游 MLIR 的高性能 AI 编译器框架，使用开源编译器 passes 从通用线性代数高层抽象（如 Linalg-on-Tensor）实现高效编译流程。关键贡献包括：在 tensor dialect 上开发 packing primitives 和 passes，支持缓存感知张量分布（单核和多核）、类型感知指令（如 VNNI, BFDOT, BFMMLA）以及形状传播；构建一个线性代数 pipeline，通过 tile, fuse 和 bufferization 策略将模型级 IR 转换为硬件友好的 tile calls；以及一个微内核 lowering 机制，集成到支持各种 CPU 的开源库中。实验证明，该框架从 TensorFlow 和 PyTorch 的输入 IR 进行优化，实现了超过 90% 的 ninja 编写的等效程序性能。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.AR",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.PL",
      "comment": "13 pages, 8 figures, presented at CGO C4ML 2024 & MLIR Workshop\n  EuroLLVM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15204v1",
      "published_date": "2024-04-15 10:35:50 UTC",
      "updated_date": "2024-04-15 10:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:35:34.369742"
    },
    {
      "arxiv_id": "2404.09652v1",
      "title": "Monitoring Second-Order Hyperproperties",
      "title_zh": "翻译失败",
      "authors": [
        "Raven Beutner",
        "Bernd Finkbeiner",
        "Hadar Frenkel",
        "Niklas Metzger"
      ],
      "abstract": "Hyperproperties express the relationship between multiple executions of a\nsystem. This is needed in many AI-related fields, such as knowledge\nrepresentation and planning, to capture system properties related to knowledge,\ninformation flow, and privacy. In this paper, we study the monitoring of\ncomplex hyperproperties at runtime. Previous work in this area has either\nfocused on the simpler problem of monitoring trace properties (which are sets\nof traces, while hyperproperties are sets of sets of traces) or on monitoring\nfirst-order hyperproperties, which are expressible in temporal logics with\nfirst-order quantification over traces, such as HyperLTL. We present the first\nmonitoring algorithm for the much more expressive class of second-order\nhyperproperties. Second-order hyperproperties include system properties like\ncommon knowledge, which cannot be expressed in first-order logics like\nHyperLTL.\n  We introduce Hyper$^2$LTL$_f$, a temporal logic over finite traces that\nallows for second-order quantification over sets of traces. We study the\nmonitoring problem in two fundamental execution models: (1) the parallel model,\nwhere a fixed number of traces is monitored in parallel, and (2) the sequential\nmodel, where an unbounded number of traces is observed sequentially, one trace\nafter the other. For the parallel model, we show that the monitoring of the\nsecond-order hyperproperties of Hyper$^2$LTL$_f$ can be reduced to monitoring\nfirst-order hyperproperties. For the sequential model, we present a monitoring\nalgorithm that handles second-order quantification efficiently, exploiting\noptimizations based on the monotonicity of subformulas, graph-based storing of\nexecutions, and fixpoint hashing. We present experimental results from a range\nof benchmarks, including examples from common knowledge and planning.",
      "tldr_zh": "本论文探讨了第二阶 Hyperproperties 的实时监控，这些属性描述系统多个执行之间的关系，常用于 AI 领域的知识表示、规划、信息流和隐私保护。作者引入了 Hyper$^2$LTL$_f$ 逻辑，这是一种允许第二阶量化的时序逻辑，用于有限追踪，并针对两种执行模型（平行模型和顺序模型）开发了监控算法：在平行模型中，将问题简化为第一阶 Hyperproperties 的监控；在顺序模型中，利用子公式单调性、图-based 执行存储和 fixpoint hashing 等优化实现高效处理。实验结果显示，该算法在常见知识和规划基准上表现出色，扩展了 Hyperproperties 监控的表达能力和应用潜力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LO",
      "comment": "AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09652v1",
      "published_date": "2024-04-15 10:33:39 UTC",
      "updated_date": "2024-04-15 10:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:35:47.053715"
    },
    {
      "arxiv_id": "2404.09636v3",
      "title": "All-in-one simulation-based inference",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Gloeckler",
        "Michael Deistler",
        "Christian Weilbach",
        "Frank Wood",
        "Jakob H. Macke"
      ],
      "abstract": "Amortized Bayesian inference trains neural networks to solve stochastic\ninference problems using model simulations, thereby making it possible to\nrapidly perform Bayesian inference for any newly observed data. However,\ncurrent simulation-based amortized inference methods are simulation-hungry and\ninflexible: They require the specification of a fixed parametric prior,\nsimulator, and inference tasks ahead of time. Here, we present a new amortized\ninference method -- the Simformer -- which overcomes these limitations. By\ntraining a probabilistic diffusion model with transformer architectures, the\nSimformer outperforms current state-of-the-art amortized inference approaches\non benchmark tasks and is substantially more flexible: It can be applied to\nmodels with function-valued parameters, it can handle inference scenarios with\nmissing or unstructured data, and it can sample arbitrary conditionals of the\njoint distribution of parameters and data, including both posterior and\nlikelihood. We showcase the performance and flexibility of the Simformer on\nsimulators from ecology, epidemiology, and neuroscience, and demonstrate that\nit opens up new possibilities and application domains for amortized Bayesian\ninference on simulation-based models.",
      "tldr_zh": "本文提出Simformer，一种新的amortized Bayesian inference方法，通过训练probabilistic diffusion model与Transformer架构，利用模型模拟来实现高效的贝叶斯推理。相较于现有方法，Simformer更灵活，能处理函数值参数、缺失或非结构化数据，并支持采样参数和数据的联合分布任意条件，包括posterior和likelihood。实验结果显示，Simformer在生态学、流行病学和神经科学模拟器上的基准任务中表现出色，超越了当前状态-of-the-art方法，并扩展了amortized Bayesian inference的应用领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in the proceedings of the 41st International\n  Conference on Machine Learning (ICML 2024), Vienna, Austria. PMLR 235, 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09636v3",
      "published_date": "2024-04-15 10:12:33 UTC",
      "updated_date": "2024-07-15 07:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:35:59.412940"
    },
    {
      "arxiv_id": "2404.09631v1",
      "title": "Action Model Learning with Guarantees",
      "title_zh": "带有保证的动作模型",
      "authors": [
        "Diego Aineto",
        "Enrico Scala"
      ],
      "abstract": "This paper studies the problem of action model learning with full\nobservability. Following the learning by search paradigm by Mitchell, we\ndevelop a theory for action model learning based on version spaces that\ninterprets the task as search for hypothesis that are consistent with the\nlearning examples. Our theoretical findings are instantiated in an online\nalgorithm that maintains a compact representation of all solutions of the\nproblem. Among these range of solutions, we bring attention to actions models\napproximating the actual transition system from below (sound models) and from\nabove (complete models). We show how to manipulate the output of our learning\nalgorithm to build deterministic and non-deterministic formulations of the\nsound and complete models and prove that, given enough examples, both\nformulations converge into the very same true model. Our experiments reveal\ntheir usefulness over a range of planning domains.",
      "tldr_zh": "本论文研究了在完全可观察条件下进行action model learning的问题，通过基于version spaces的理论，将任务视为搜索与学习示例一致的假设。作者开发了一个在线算法，能够维护所有解决方案的紧凑表示，并关注从下近似（sound models）和从上近似（complete models）的行动模型，展示了如何构建其确定性和非确定性版本。实验证明，这些模型在足够示例下会收敛到真正的模型，并在各种规划领域显示出显著的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09631v1",
      "published_date": "2024-04-15 10:01:43 UTC",
      "updated_date": "2024-04-15 10:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:36:11.359416"
    },
    {
      "arxiv_id": "2404.09625v1",
      "title": "Privacy-Preserving Intrusion Detection using Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Kodys",
        "Zhongmin Dai",
        "Vrizlynn L. L. Thing"
      ],
      "abstract": "Privacy-preserving analytics is designed to protect valuable assets. A common\nservice provision involves the input data from the client and the model on the\nanalyst's side. The importance of the privacy preservation is fuelled by legal\nobligations and intellectual property concerns. We explore the use case of a\nmodel owner providing an analytic service on customer's private data. No\ninformation about the data shall be revealed to the analyst and no information\nabout the model shall be leaked to the customer. Current methods involve costs:\naccuracy deterioration and computational complexity. The complexity, in turn,\nresults in a longer processing time, increased requirement on computing\nresources, and involves data communication between the client and the server.\nIn order to deploy such service architecture, we need to evaluate the optimal\nsetting that fits the constraints. And that is what this paper addresses. In\nthis work, we enhance an attack detection system based on Convolutional Neural\nNetworks with privacy-preserving technology based on PriMIA framework that is\ninitially designed for medical data.",
      "tldr_zh": "该论文探讨了在入侵检测系统中应用 Convolutional Neural Networks (CNNs) 的隐私保护方法，旨在保护客户数据和模型所有者的知识产权，同时避免信息泄露。研究基于 PriMIA 框架增强了攻击检测系统，优化了服务架构以减少准确性下降和计算复杂性。实验结果显示，这种方法在满足隐私要求的同时，提供了更高效的资源利用和处理时间，为隐私保护分析服务提供了实用解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at IEEE Conference on Artificial Intelligence (CAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09625v1",
      "published_date": "2024-04-15 09:56:36 UTC",
      "updated_date": "2024-04-15 09:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:36:22.650242"
    },
    {
      "arxiv_id": "2404.09622v2",
      "title": "DIDLM: A SLAM Dataset for Difficult Scenarios Featuring Infrared, Depth Cameras, LIDAR, 4D Radar, and Others under Adverse Weather, Low Light Conditions, and Rough Roads",
      "title_zh": "翻译失败",
      "authors": [
        "Weisheng Gong",
        "Kaijie Su",
        "Qingyong Li",
        "Chen He",
        "Tong Wu",
        "Z. Jane Wang"
      ],
      "abstract": "Adverse weather conditions, low-light environments, and bumpy road surfaces\npose significant challenges to SLAM in robotic navigation and autonomous\ndriving. Existing datasets in this field predominantly rely on single sensors\nor combinations of LiDAR, cameras, and IMUs. However, 4D millimeter-wave radar\ndemonstrates robustness in adverse weather, infrared cameras excel in capturing\ndetails under low-light conditions, and depth images provide richer spatial\ninformation. Multi-sensor fusion methods also show potential for better\nadaptation to bumpy roads. Despite some SLAM studies incorporating these\nsensors and conditions, there remains a lack of comprehensive datasets\naddressing low-light environments and bumpy road conditions, or featuring a\nsufficiently diverse range of sensor data. In this study, we introduce a\nmulti-sensor dataset covering challenging scenarios such as snowy weather,\nrainy weather, nighttime conditions, speed bumps, and rough terrains. The\ndataset includes rarely utilized sensors for extreme conditions, such as 4D\nmillimeter-wave radar, infrared cameras, and depth cameras, alongside 3D LiDAR,\nRGB cameras, GPS, and IMU. It supports both autonomous driving and ground robot\napplications and provides reliable GPS/INS ground truth data, covering\nstructured and semi-structured terrains. We evaluated various SLAM algorithms\nusing this dataset, including RGB images, infrared images, depth images, LiDAR,\nand 4D millimeter-wave radar. The dataset spans a total of 18.5 km, 69 minutes,\nand approximately 660 GB, offering a valuable resource for advancing SLAM\nresearch under complex and extreme conditions. Our dataset is available at\nhttps://github.com/GongWeiSheng/DIDLM.",
      "tldr_zh": "本研究引入了DIDLM数据集，这是一个针对SLAM在恶劣天气、低光照和崎岖道路等困难场景的多传感器数据集。数据集包含4D millimeter-wave radar、infrared cameras、depth cameras、3D LiDAR、RGB cameras、GPS和IMU等多种传感器，涵盖雪天、雨天、夜间条件以及减速带和粗糙地形等场景，总长度达18.5 km、69分钟和约660 GB。实验评估了基于RGB图像、infrared图像、depth图像、LiDAR和4D millimeter-wave radar的各种SLAM算法，展示了多传感器融合在复杂环境下的潜力，并为自主驾驶和地面机器人应用提供宝贵资源。数据集可从https://github.com/GongWeiSheng/DIDLM获取。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09622v2",
      "published_date": "2024-04-15 09:49:33 UTC",
      "updated_date": "2025-01-14 09:22:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:36:36.272230"
    },
    {
      "arxiv_id": "2404.09619v1",
      "title": "UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark",
      "title_zh": "UNIAA：统一多模态图像美学评估基线和基准",
      "authors": [
        "Zhaokun Zhou",
        "Qiulin Wang",
        "Bin Lin",
        "Yiwei Su",
        "Rui Chen",
        "Xin Tao",
        "Amin Zheng",
        "Li Yuan",
        "Pengfei Wan",
        "Di Zhang"
      ],
      "abstract": "As an alternative to expensive expert evaluation, Image Aesthetic Assessment\n(IAA) stands out as a crucial task in computer vision. However, traditional IAA\nmethods are typically constrained to a single data source or task, restricting\nthe universality and broader application. In this work, to better align with\nhuman aesthetics, we propose a Unified Multi-modal Image Aesthetic Assessment\n(UNIAA) framework, including a Multi-modal Large Language Model (MLLM) named\nUNIAA-LLaVA and a comprehensive benchmark named UNIAA-Bench. We choose MLLMs\nwith both visual perception and language ability for IAA and establish a\nlow-cost paradigm for transforming the existing datasets into unified and\nhigh-quality visual instruction tuning data, from which the UNIAA-LLaVA is\ntrained. To further evaluate the IAA capability of MLLMs, we construct the\nUNIAA-Bench, which consists of three aesthetic levels: Perception, Description,\nand Assessment. Extensive experiments validate the effectiveness and\nrationality of UNIAA. UNIAA-LLaVA achieves competitive performance on all\nlevels of UNIAA-Bench, compared with existing MLLMs. Specifically, our model\nperforms better than GPT-4V in aesthetic perception and even approaches the\njunior-level human. We find MLLMs have great potential in IAA, yet there\nremains plenty of room for further improvement. The UNIAA-LLaVA and UNIAA-Bench\nwill be released.",
      "tldr_zh": "这篇论文提出了一种统一的 多模态 图像美学评估框架 UNIAA，包括多模态大语言模型 (MLLM) UNIAA-LLaVA 和全面基准 UNIAA-Bench，以解决传统 Image Aesthetic Assessment (IAA) 方法局限于单一数据源的局限性。框架通过转换现有数据集为高质量视觉指令调优数据，并利用 MLLMs 的视觉感知和语言能力进行训练，涵盖感知、描述和评估三个美学水平。实验结果显示，UNIAA-LLaVA 在 UNIAA-Bench 上表现出色，比 GPT-4V 在美学感知上更具竞争力，甚至接近初级人类水平；作者强调 MLLMs 在 IAA 领域有巨大潜力，并计划发布相关模型和基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09619v1",
      "published_date": "2024-04-15 09:47:48 UTC",
      "updated_date": "2024-04-15 09:47:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:36:49.948885"
    },
    {
      "arxiv_id": "2404.12402v2",
      "title": "Sup3r: A Semi-Supervised Algorithm for increasing Sparsity, Stability, and Separability in Hierarchy Of Time-Surfaces architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Rasetto",
        "Himanshu Akolkar",
        "Ryad Benosman"
      ],
      "abstract": "The Hierarchy Of Time-Surfaces (HOTS) algorithm, a neuromorphic approach for\nfeature extraction from event data, presents promising capabilities but faces\nchallenges in accuracy and compatibility with neuromorphic hardware. In this\npaper, we introduce Sup3r, a Semi-Supervised algorithm aimed at addressing\nthese challenges. Sup3r enhances sparsity, stability, and separability in the\nHOTS networks. It enables end-to-end online training of HOTS networks replacing\nexternal classifiers, by leveraging semi-supervised learning. Sup3r learns\nclass-informative patterns, mitigates confounding features, and reduces the\nnumber of processed events. Moreover, Sup3r facilitates continual and\nincremental learning, allowing adaptation to data distribution shifts and\nlearning new tasks without forgetting. Preliminary results on N-MNIST\ndemonstrate that Sup3r achieves comparable accuracy to similarly sized\nArtificial Neural Networks trained with back-propagation. This work showcases\nthe potential of Sup3r to advance the capabilities of HOTS networks, offering a\npromising avenue for neuromorphic algorithms in real-world applications.",
      "tldr_zh": "这篇论文提出了 Sup3r，一种半监督算法，用于提升 Hierarchy Of Time-Surfaces (HOTS) 架构的稀疏性、稳定性和可分离性，以解决 HOTS 在准确性和硬件兼容性方面的挑战。Sup3r 通过端到端的在线训练取代外部分类器，利用半监督学习来识别类别的信息模式、减少混淆特征，并降低处理的事件数量。它还支持持续和增量学习，允许模型适应数据分布变化而不遗忘。在 N-MNIST 数据集上的初步实验显示，Sup3r 的准确率与使用反向传播训练的类似大小的 Artificial Neural Networks 相当，从而为神经形态算法在实际应用中提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.12402v2",
      "published_date": "2024-04-15 09:33:19 UTC",
      "updated_date": "2024-04-30 22:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:02.394164"
    },
    {
      "arxiv_id": "2404.09613v1",
      "title": "Efficient and accurate neural field reconstruction using resistive memory",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Yu",
        "Shaocong Wang",
        "Woyu Zhang",
        "Xinyuan Zhang",
        "Xiuzhe Wu",
        "Yangu He",
        "Jichang Yang",
        "Yue Zhang",
        "Ning Lin",
        "Bo Wang",
        "Xi Chen",
        "Songqi Wang",
        "Xumeng Zhang",
        "Xiaojuan Qi",
        "Zhongrui Wang",
        "Dashan Shang",
        "Qi Liu",
        "Kwang-Ting Cheng",
        "Ming Liu"
      ],
      "abstract": "Human beings construct perception of space by integrating sparse observations\ninto massively interconnected synapses and neurons, offering a superior\nparallelism and efficiency. Replicating this capability in AI finds wide\napplications in medical imaging, AR/VR, and embodied AI, where input data is\noften sparse and computing resources are limited. However, traditional signal\nreconstruction methods on digital computers face both software and hardware\nchallenges. On the software front, difficulties arise from storage\ninefficiencies in conventional explicit signal representation. Hardware\nobstacles include the von Neumann bottleneck, which limits data transfer\nbetween the CPU and memory, and the limitations of CMOS circuits in supporting\nparallel processing. We propose a systematic approach with software-hardware\nco-optimizations for signal reconstruction from sparse inputs. Software-wise,\nwe employ neural field to implicitly represent signals via neural networks,\nwhich is further compressed using low-rank decomposition and structured\npruning. Hardware-wise, we design a resistive memory-based computing-in-memory\n(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine\n(PE). The GE harnesses the intrinsic stochasticity of resistive memory for\nefficient input encoding, while the PE achieves precise weight mapping through\na Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system's\nefficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,\nachieving huge energy efficiency and parallelism improvements without\ncompromising reconstruction quality in tasks like 3D CT sparse reconstruction,\nnovel view synthesis, and novel view synthesis for dynamic scenes. This work\nadvances the AI-driven signal restoration technology and paves the way for\nfuture efficient and robust medical AI and 3D vision applications.",
      "tldr_zh": "本研究针对AI从稀疏输入重建信号的挑战，提出了一种软件-硬件协同优化的系统，旨在提升效率和准确性。软件方面，使用neural field隐式表示信号，并通过low-rank decomposition和structured pruning进行压缩；硬件方面，设计基于resistive memory的计算内存储（CIM）平台，包括Gaussian Encoder (GE)利用其固有随机性进行输入编码，以及MLP Processing Engine (PE)通过Hardware-Aware Quantization (HAQ)电路实现精确权重映射。在40nm 256Kb resistive memory宏上进行的实验显示，该系统在3D CT稀疏重建和新视图合成等任务中大幅提高了能量效率和并行性，同时保持了重建质量，为医疗AI和3D视觉应用提供了高效解决方案。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09613v1",
      "published_date": "2024-04-15 09:33:09 UTC",
      "updated_date": "2024-04-15 09:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:13.176289"
    },
    {
      "arxiv_id": "2404.09610v1",
      "title": "LoRA Dropout as a Sparsity Regularizer for Overfitting Control",
      "title_zh": "LoRA Dropout 作为稀疏正则化器用于过拟合控制",
      "authors": [
        "Yang Lin",
        "Xinyu Ma",
        "Xu Chu",
        "Yujie Jin",
        "Zhibang Yang",
        "Yasha Wang",
        "Hong Mei"
      ],
      "abstract": "Parameter-efficient fine-tuning methods, represented by LoRA, play an\nessential role in adapting large-scale pre-trained models to downstream tasks.\nHowever, fine-tuning LoRA-series models also faces the risk of overfitting on\nthe training dataset, and yet there's still a lack of theoretical guidance and\npractical mechanism to control overfitting on LoRA-based PEFT methods. In this\npaper, we propose a LoRA Dropout mechanism for the LoRA-based methods by\nintroducing random noises to the learnable low-rank matrices and increasing\nparameter sparsity. We then demonstrate the theoretical mechanism of our LoRA\nDropout mechanism from the perspective of sparsity regularization by providing\na generalization error bound under this framework. Theoretical results show\nthat appropriate sparsity would help tighten the gap between empirical and\ngeneralization risks and thereby control overfitting. Furthermore, based on the\nLoRA Dropout framework, we introduce a test-time ensemble strategy and provide\ntheoretical evidence demonstrating that the ensemble method can further\ncompress the error bound, and lead to better performance during inference time.\nExtensive experiments on various NLP tasks provide practical validations of the\neffectiveness of our LoRA Dropout framework in improving model accuracy and\ncalibration.",
      "tldr_zh": "本文提出 LoRA Dropout 机制，作为一种稀疏正则化方法，用于控制 LoRA-based 参数高效微调（PEFT）模型的过拟合风险，通过向可学习的低秩矩阵引入随机噪声来增加参数稀疏性。该机制从理论角度提供了泛化误差界，证明适当的稀疏性有助于缩小经验风险与泛化风险的差距，从而提升模型泛化能力。此外，基于此框架，作者引入了测试时集成策略，并通过在各种 NLP 任务上的广泛实验验证了其有效性，提高了模型的准确性和校准性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09610v1",
      "published_date": "2024-04-15 09:32:12 UTC",
      "updated_date": "2024-04-15 09:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:24.119881"
    },
    {
      "arxiv_id": "2404.09606v1",
      "title": "A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Liu",
        "Jun Tao",
        "Zhixiang Ren"
      ],
      "abstract": "The task of chemical reaction predictions (CRPs) plays a pivotal role in\nadvancing drug discovery and material science. However, its effectiveness is\nconstrained by the vast and uncertain chemical reaction space and challenges in\ncapturing reaction selectivity, particularly due to existing methods'\nlimitations in exploiting the data's inherent knowledge. To address these\nchallenges, we introduce a data-curated self-feedback knowledge elicitation\napproach. This method starts from iterative optimization of molecular\nrepresentations and facilitates the extraction of knowledge on chemical\nreaction types (RTs). Then, we employ adaptive prompt learning to infuse the\nprior knowledge into the large language model (LLM). As a result, we achieve\nsignificant enhancements: a 14.2% increase in retrosynthesis prediction\naccuracy, a 74.2% rise in reagent prediction accuracy, and an expansion in the\nmodel's capability for handling multi-task chemical reactions. This research\noffers a novel paradigm for knowledge elicitation in scientific research and\nshowcases the untapped potential of LLMs in CRPs.",
      "tldr_zh": "该研究提出了一种自反馈知识提取方法，用于提升化学反应预测（CRPs），以应对化学反应空间的广阔不确定性和反应选择性捕捉的挑战。该方法通过迭代优化分子表示来提取化学反应类型（RTs）的内在知识，并采用自适应提示学习将这些知识注入大型语言模型（LLM）。实验结果显示，该方法使逆合成预测准确率提高14.2%，试剂预测准确率提升74.2%，并增强了模型处理多任务化学反应的能力。该创新范式为科学领域的知识提取提供了新途径，并展示了LLM在CRPs中的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09606v1",
      "published_date": "2024-04-15 09:26:33 UTC",
      "updated_date": "2024-04-15 09:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:34.886201"
    },
    {
      "arxiv_id": "2404.09601v1",
      "title": "Reactive Model Correction: Mitigating Harm to Task-Relevant Features via Conditional Bias Suppression",
      "title_zh": "反应式模型修正：通过条件偏差",
      "authors": [
        "Dilyara Bareeva",
        "Maximilian Dreyer",
        "Frederik Pahde",
        "Wojciech Samek",
        "Sebastian Lapuschkin"
      ],
      "abstract": "Deep Neural Networks are prone to learning and relying on spurious\ncorrelations in the training data, which, for high-risk applications, can have\nfatal consequences. Various approaches to suppress model reliance on harmful\nfeatures have been proposed that can be applied post-hoc without additional\ntraining. Whereas those methods can be applied with efficiency, they also tend\nto harm model performance by globally shifting the distribution of latent\nfeatures. To mitigate unintended overcorrection of model behavior, we propose a\nreactive approach conditioned on model-derived knowledge and eXplainable\nArtificial Intelligence (XAI) insights. While the reactive approach can be\napplied to many post-hoc methods, we demonstrate the incorporation of\nreactivity in particular for P-ClArC (Projective Class Artifact Compensation),\nintroducing a new method called R-ClArC (Reactive Class Artifact Compensation).\nThrough rigorous experiments in controlled settings (FunnyBirds) and with a\nreal-world dataset (ISIC2019), we show that introducing reactivity can minimize\nthe detrimental effect of the applied correction while simultaneously ensuring\nlow reliance on spurious features.",
      "tldr_zh": "本研究针对深度神经网络（Deep Neural Networks）在训练数据中依赖虚假相关性（spurious correlations）的问题，提出了一种反应式模型修正方法（Reactive Model Correction），通过条件偏置抑制（Conditional Bias Suppression）来减少对任务相关特征的损害，同时利用模型衍生知识和可解释人工智能（XAI）见解进行有针对性的调整。不同于传统方法，该方法避免了全局改变潜在特征分布的负面影响，特别引入了 R-ClArC（Reactive Class Artifact Compensation）作为 P-ClArC 的改进版本。在 FunnyBirds 和 ISIC2019 数据集上的实验表明，这种反应式方法能最小化修正的负面效应，同时有效降低模型对虚假特征的依赖，确保了模型性能的优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09601v1",
      "published_date": "2024-04-15 09:16:49 UTC",
      "updated_date": "2024-04-15 09:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:48.124762"
    },
    {
      "arxiv_id": "2404.09595v1",
      "title": "Building Semantic Communication System via Molecules: An End-to-End Training Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Cheng",
        "Wei Chen",
        "Bo Ai"
      ],
      "abstract": "The concept of semantic communication provides a novel approach for\napplications in scenarios with limited communication resources. In this paper,\nwe propose an end-to-end (E2E) semantic molecular communication system, aiming\nto enhance the efficiency of molecular communication systems by reducing the\ntransmitted information. Specifically, following the joint source channel\ncoding paradigm, the network is designed to encode the task-relevant\ninformation into the concentration of the information molecules, which is\nrobust to the degradation of the molecular communication channel. Furthermore,\nwe propose a channel network to enable the E2E learning over the\nnon-differentiable molecular channel. Experimental results demonstrate the\nsuperior performance of the semantic molecular communication system over the\nconventional methods in classification tasks.",
      "tldr_zh": "本研究提出了一种端到端 (E2E) 语义分子通信系统，旨在通过减少传输信息来提升分子通信系统的效率。系统遵循联合源通道编码范式，将任务相关信息编码成信息分子的浓度，并通过一个通道网络实现非微分分子通道上的E2E学习，从而增强对通道退化的鲁棒性。实验结果显示，该系统在分类任务中比传统方法表现出色，显著提高了通信效率。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09595v1",
      "published_date": "2024-04-15 09:06:07 UTC",
      "updated_date": "2024-04-15 09:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:37:58.746777"
    },
    {
      "arxiv_id": "2404.09587v1",
      "title": "German Tourism Knowledge Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Umutcan Serles",
        "Elias Kärle",
        "Richard Hunkel",
        "Dieter Fensel"
      ],
      "abstract": "Tourism is one of the most critical sectors of the global economy. Due to its\nheterogeneous and fragmented nature, it provides one of the most suitable use\ncases for knowledge graphs. In this poster, we introduce the German Tourism\nKnowledge Graph that integrates tourism-related data from 16 federal states of\nGermany and various other sources to provide a curated knowledge source for\nvarious applications. It is publicly available through GUIs and an API.",
      "tldr_zh": "本文介绍了German Tourism Knowledge Graph，一种整合德国16个联邦州旅游相关数据以及其他来源的知识图谱，旨在解决旅游业数据异构和碎片化问题。该知识图谱通过精选数据提供了一个可靠的知识来源，支持各种应用，并通过GUI和API公开可用。这为旅游领域的知识管理和应用提供了高效的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages. Accepted to Poster and Demo Track of 21st European Semantic\n  Web Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09587v1",
      "published_date": "2024-04-15 08:56:53 UTC",
      "updated_date": "2024-04-15 08:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:38:10.998579"
    },
    {
      "arxiv_id": "2404.09579v1",
      "title": "Modelling Language",
      "title_zh": "语言建模",
      "authors": [
        "Jumbly Grindrod"
      ],
      "abstract": "This paper argues that large language models have a valuable scientific role\nto play in serving as scientific models of a language. Linguistic study should\nnot only be concerned with the cognitive processes behind linguistic\ncompetence, but also with language understood as an external, social entity.\nOnce this is recognized, the value of large language models as scientific\nmodels becomes clear. This paper defends this position against a number of\narguments to the effect that language models provide no linguistic insight. It\nalso draws upon recent work in philosophy of science to show how large language\nmodels could serve as scientific models.",
      "tldr_zh": "这篇论文主张 large language models 在语言研究中可作为科学模型发挥关键作用，认为语言不应仅限于认知过程，还应视为外部社会实体。作者反驳了认为这些模型无法提供语言洞见的论点，并引用哲学科学的相关工作来证明其科学价值。通过这种扩展视角，论文强调 large language models 有助于深化对语言的理解和建模。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09579v1",
      "published_date": "2024-04-15 08:40:01 UTC",
      "updated_date": "2024-04-15 08:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:38:22.834877"
    },
    {
      "arxiv_id": "2404.09577v2",
      "title": "Transformers, Contextualism, and Polysemy",
      "title_zh": "翻译失败",
      "authors": [
        "Jumbly Grindrod"
      ],
      "abstract": "The transformer architecture, introduced by Vaswani et al. (2017), is at the\nheart of the remarkable recent progress in the development of language models,\nincluding widely-used chatbots such as Chat-GPT and Claude. In this paper, I\nargue that we can extract from the way the transformer architecture works a\ntheory of the relationship between context and meaning. I call this the\ntransformer theory, and I argue that it is novel with regard to two related\nphilosophical debates: the contextualism debate regarding the extent of\ncontext-sensitivity across natural language, and the polysemy debate regarding\nhow polysemy should be captured within an account of word meaning.",
      "tldr_zh": "本文从Transformer架构的工作原理中提取出一种新型理论，即transformer theory，用于解释上下文与意义之间的关系。该理论在哲学领域提供了新颖的见解，特别是针对contextualism辩论（关于自然语言中上下文敏感性的程度）和polysemy辩论（如何在词义账户中捕捉多义性）。作者论证了这一理论如何超越现有框架，推动对语言模型和哲学交叉领域的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09577v2",
      "published_date": "2024-04-15 08:38:43 UTC",
      "updated_date": "2024-09-26 14:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:38:35.248047"
    },
    {
      "arxiv_id": "2404.09576v2",
      "title": "Large language models and linguistic intentionality",
      "title_zh": "大型语言模型和语言意向性",
      "authors": [
        "Jumbly Grindrod"
      ],
      "abstract": "Do large language models like Chat-GPT or LLaMa meaningfully use the words\nthey produce? Or are they merely clever prediction machines, simulating\nlanguage use by producing statistically plausible text? There have already been\nsome initial attempts to answer this question by showing that these models meet\nthe criteria for entering meaningful states according to metasemantic theories\nof mental content. In this paper, I will argue for a different approach - that\nwe should instead consider whether language models meet the criteria given by\nour best metasemantic theories of linguistic content. In that vein, I will\nillustrate how this can be done by applying two such theories to the case of\nlanguage models: Gareth Evans' (1982) account of naming practices and Ruth\nMillikan's (1984, 2004, 2005) teleosemantics. In doing so, I will argue that it\nis a mistake to think that the failure of LLMs to meet plausible conditions for\nmental intentionality thereby renders their outputs meaningless, and that a\ndistinguishing feature of linguistic intentionality - dependency on a\npre-existing linguistic system - allows for the plausible result LLM outputs\nare meaningful.",
      "tldr_zh": "本论文探讨大型语言模型 (LLMs) 如 Chat-GPT 或 LLaMa 是否真正有意义地使用语言，还是仅作为统计预测机器模拟语言。作者主张应采用 metasemantic 理论评估语言模型的语言内容 (linguistic intentionality)，而非心理内容，并应用 Gareth Evans (1982) 的命名实践理论和 Ruth Millikan (1984, 2004, 2005) 的 teleosemantics 理论进行分析。论文论证，即使 LLMs 不符合心理意图条件，其输出仍可能是有意义的，因为语言意图依赖于预先存在的语言系统，这为理解 AI 语言使用提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09576v2",
      "published_date": "2024-04-15 08:37:26 UTC",
      "updated_date": "2024-09-16 08:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:38:49.310932"
    },
    {
      "arxiv_id": "2404.09574v1",
      "title": "Predicting and Analyzing Pedestrian Crossing Behavior at Unsignalized Crossings",
      "title_zh": "预测和分析无信号灯十字路口的行人过马路行为",
      "authors": [
        "Chi Zhang",
        "Janis Sprenger",
        "Zhongjun Ni",
        "Christian Berger"
      ],
      "abstract": "Understanding and predicting pedestrian crossing behavior is essential for\nenhancing automated driving and improving driving safety. Predicting gap\nselection behavior and the use of zebra crossing enables driving systems to\nproactively respond and prevent potential conflicts. This task is particularly\nchallenging at unsignalized crossings due to the ambiguous right of way,\nrequiring pedestrians to constantly interact with vehicles and other\npedestrians. This study addresses these challenges by utilizing simulator data\nto investigate scenarios involving multiple vehicles and pedestrians. We\npropose and evaluate machine learning models to predict gap selection in\nnon-zebra scenarios and zebra crossing usage in zebra scenarios. We investigate\nand discuss how pedestrians' behaviors are influenced by various factors,\nincluding pedestrian waiting time, walking speed, the number of unused gaps,\nthe largest missed gap, and the influence of other pedestrians. This research\ncontributes to the evolution of intelligent vehicles by providing predictive\nmodels and valuable insights into pedestrian crossing behavior.",
      "tldr_zh": "这篇论文研究了在无信号灯十字路口预测行人过马路行为，以提升自动驾驶系统和行车安全。研究者利用模拟器数据，提出并评估机器学习模型来预测非斑马线场景中的间隙选择（gap selection）和斑马线场景中的斑马线使用（zebra crossing usage）。他们分析了行人行为受多种因素影响，包括等待时间、步行速度、未使用间隙数量、最大错过间隙以及其他行人的作用。该工作提供了预测模型和行为洞见，推动智能车辆的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T40, 68T45",
        "I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 10 figures, 4 tables. Accepted in 2024 IEEE Intelligent\n  Vehicles Symposium (IV)",
      "pdf_url": "http://arxiv.org/pdf/2404.09574v1",
      "published_date": "2024-04-15 08:36:40 UTC",
      "updated_date": "2024-04-15 08:36:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:39:00.115810"
    },
    {
      "arxiv_id": "2404.09565v1",
      "title": "Reliability Estimation of News Media Sources: Birds of a Feather Flock Together",
      "title_zh": "新闻媒体来源的可靠性估计：物以类聚",
      "authors": [
        "Sergio Burdisso",
        "Dairazalia Sánchez-Cortés",
        "Esaú Villatoro-Tello",
        "Petr Motlicek"
      ],
      "abstract": "Evaluating the reliability of news sources is a routine task for journalists\nand organizations committed to acquiring and disseminating accurate\ninformation. Recent research has shown that predicting sources' reliability\nrepresents an important first-prior step in addressing additional challenges\nsuch as fake news detection and fact-checking. In this paper, we introduce a\nnovel approach for source reliability estimation that leverages reinforcement\nlearning strategies for estimating the reliability degree of news sources.\nContrary to previous research, our proposed approach models the problem as the\nestimation of a reliability degree, and not a reliability label, based on how\nall the news media sources interact with each other on the Web. We validated\nthe effectiveness of our method on a news media reliability dataset that is an\norder of magnitude larger than comparable existing datasets. Results show that\nthe estimated reliability degrees strongly correlates with journalists-provided\nscores (Spearman=0.80) and can effectively predict reliability labels\n(macro-avg. F$_1$ score=81.05). We release our implementation and dataset,\naiming to provide a valuable resource for the NLP community working on\ninformation verification.",
      "tldr_zh": "本文提出了一种新方法，使用reinforcement learning策略来估计新闻媒体来源的可靠性度，该方法基于来源在Web上的互动关系建模，而不是简单地预测可靠性标签。不同于以往研究，该方法通过分析所有来源间的互动来量化可靠性度，并在一个比现有数据集大一个数量级的新闻媒体可靠性数据集上进行验证。实验结果显示，估计的可靠性度与记者提供的分数高度相关（Spearman=0.80），并在预测可靠性标签时达到较高的macro-avg. F$_1$ score（81.05%）。作者发布了实现代码和数据集，以支持NLP社区的信息验证工作。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2404.09565v1",
      "published_date": "2024-04-15 08:27:47 UTC",
      "updated_date": "2024-04-15 08:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:39:12.094591"
    },
    {
      "arxiv_id": "2404.09562v2",
      "title": "σ-GPTs: A New Approach to Autoregressive Models",
      "title_zh": "σ-GPTs：自回归模型的一种新方法",
      "authors": [
        "Arnaud Pannatier",
        "Evann Courdier",
        "François Fleuret"
      ],
      "abstract": "Autoregressive models, such as the GPT family, use a fixed order, usually\nleft-to-right, to generate sequences. However, this is not a necessity. In this\npaper, we challenge this assumption and show that by simply adding a positional\nencoding for the output, this order can be modulated on-the-fly per-sample\nwhich offers key advantageous properties. It allows for the sampling of and\nconditioning on arbitrary subsets of tokens, and it also allows sampling in one\nshot multiple tokens dynamically according to a rejection strategy, leading to\na sub-linear number of model evaluations. We evaluate our method across various\ndomains, including language modeling, path-solving, and aircraft vertical rate\nprediction, decreasing the number of steps required for generation by an order\nof magnitude.",
      "tldr_zh": "本文提出σ-GPTs，一种创新的自回归模型方法，通过在输出中添加positional encoding，允许动态调整序列生成顺序，从而摆脱传统左到右的固定模式。相比传统方法，该框架支持采样和条件化任意子集的tokens，并通过rejection strategy一次性采样多个tokens，实现sub-linear数量的模型评估步骤。实验在语言建模、路径求解和飞机垂直速率预测等领域表明，该方法将生成步骤减少了一个数量级。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures, accepted at ECML/PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09562v2",
      "published_date": "2024-04-15 08:22:47 UTC",
      "updated_date": "2024-07-01 06:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:39:23.515996"
    },
    {
      "arxiv_id": "2404.09559v1",
      "title": "Joint Contrastive Learning with Feature Alignment for Cross-Corpus EEG-based Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Qile Liu",
        "Zhihao Zhou",
        "Jiyuan Wang",
        "Zhen Liang"
      ],
      "abstract": "The integration of human emotions into multimedia applications shows great\npotential for enriching user experiences and enhancing engagement across\nvarious digital platforms. Unlike traditional methods such as questionnaires,\nfacial expressions, and voice analysis, brain signals offer a more direct and\nobjective understanding of emotional states. However, in the field of\nelectroencephalography (EEG)-based emotion recognition, previous studies have\nprimarily concentrated on training and testing EEG models within a single\ndataset, overlooking the variability across different datasets. This oversight\nleads to significant performance degradation when applying EEG models to\ncross-corpus scenarios. In this study, we propose a novel Joint Contrastive\nlearning framework with Feature Alignment (JCFA) to address cross-corpus\nEEG-based emotion recognition. The JCFA model operates in two main stages. In\nthe pre-training stage, a joint domain contrastive learning strategy is\nintroduced to characterize generalizable time-frequency representations of EEG\nsignals, without the use of labeled data. It extracts robust time-based and\nfrequency-based embeddings for each EEG sample, and then aligns them within a\nshared latent time-frequency space. In the fine-tuning stage, JCFA is refined\nin conjunction with downstream tasks, where the structural connections among\nbrain electrodes are considered. The model capability could be further enhanced\nfor the application in emotion detection and interpretation. Extensive\nexperimental results on two well-recognized emotional datasets show that the\nproposed JCFA model achieves state-of-the-art (SOTA) performance, outperforming\nthe second-best method by an average accuracy increase of 4.09% in cross-corpus\nEEG-based emotion recognition tasks.",
      "tldr_zh": "这篇论文提出了一种名为 Joint Contrastive Learning with Feature Alignment (JCFA) 的框架，用于解决跨数据集（Cross-Corpus）EEG-based Emotion Recognition 的性能问题。JCFA 模型分为两个阶段：在预训练阶段，通过联合域对比学习策略提取 EEG 信号的通用时间-频率表示，并对齐它们到一个共享的潜在空间，而不依赖标签数据；在微调阶段，结合下游任务和脑电极的结构连接，进一步提升情绪检测和解释能力。实验结果显示，JCFA 在两个知名情绪数据集上达到了 SOTA 性能，比第二好的方法平均准确率提高了 4.09%。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09559v1",
      "published_date": "2024-04-15 08:21:17 UTC",
      "updated_date": "2024-04-15 08:21:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:39:36.589652"
    },
    {
      "arxiv_id": "2404.09557v1",
      "title": "Characterization and Mitigation of Insufficiencies in Automated Driving Systems",
      "title_zh": "自动驾驶系统的不足表征与缓解",
      "authors": [
        "Yuting Fu",
        "Jochen Seemann",
        "Caspar Hanselaar",
        "Tim Beurskens",
        "Andrei Terechko",
        "Emilia Silvas",
        "Maurice Heemels"
      ],
      "abstract": "Automated Driving (AD) systems have the potential to increase safety, comfort\nand energy efficiency. Recently, major automotive companies have started\ntesting and validating AD systems (ADS) on public roads. Nevertheless, the\ncommercial deployment and wide adoption of ADS have been moderate, partially\ndue to system functional insufficiencies (FI) that undermine passenger safety\nand lead to hazardous situations on the road. FIs are defined in ISO 21448\nSafety Of The Intended Functionality (SOTIF). FIs are insufficiencies in\nsensors, actuators and algorithm implementations, including neural networks and\nprobabilistic calculations. Examples of FIs in ADS include inaccurate\nego-vehicle localization on the road, incorrect prediction of a cyclist\nmaneuver, unreliable detection of a pedestrian, etc.\n  The main goal of our study is to formulate a generic architectural design\npattern, which is compatible with existing methods and ADS, to improve FI\nmitigation and enable faster commercial deployment of ADS. First, we studied\nthe 2021 autonomous vehicles disengagement reports published by the California\nDepartment of Motor Vehicles (DMV). The data clearly show that disengagements\nare five times more often caused by FIs rather than by system faults. We then\nmade a comprehensive list of insufficiencies and their characteristics by\nanalyzing over 10 hours of publicly available road test videos. In particular,\nwe identified insufficiency types in four major categories: world model, motion\nplan, traffic rule, and operational design domain. The insufficiency\ncharacterization helps making the SOTIF analyses of triggering conditions more\nsystematic and comprehensive.\n  Based on our FI characterization, simulation experiments and literature\nsurvey, we define a novel generic architectural design pattern Daruma to\ndynamically select the channel that is least likely to have a FI at the moment.",
      "tldr_zh": "本研究探讨了Automated Driving (AD) 系统中的Functional Insufficiencies (FI)，这些问题如传感器缺陷、算法错误和对象检测失准，会威胁乘客安全并阻碍系统商业部署。研究者分析了2021年加州DMV的自动驾驶脱管报告，发现FI是脱管原因的五倍于系统故障，并通过审阅超过10小时的路测视频，将FI分类为world model、motion plan、traffic rule和operational design domain四大类别，以系统化SOTIF分析。基于这些特征化，论文提出一个新型通用架构设计模式Daruma，该模式动态选择最不可能出现FI的通道，以提升FI缓解效果并加速AD系统的商业化。在模拟实验和文献调研支持下，Daruma框架兼容现有方法，有望显著改善AD系统的安全性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at the 27th International Technical Conference on the\n  Enhanced Safety of Vehicles (ESV), Apr 2023, Yokohama, Japan. Original\n  publication https://www-esv.nhtsa.dot.gov/Proceedings/27/27ESV-000110.pdf",
      "pdf_url": "http://arxiv.org/pdf/2404.09557v1",
      "published_date": "2024-04-15 08:19:13 UTC",
      "updated_date": "2024-04-15 08:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:39:50.320000"
    },
    {
      "arxiv_id": "2404.09554v1",
      "title": "Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Schneider"
      ],
      "abstract": "Generative AI (GenAI) marked a shift from AI being able to recognize to AI\nbeing able to generate solutions for a wide variety of tasks. As the generated\nsolutions and applications become increasingly more complex and multi-faceted,\nnovel needs, objectives, and possibilities have emerged for explainability\n(XAI). In this work, we elaborate on why XAI has gained importance with the\nrise of GenAI and its challenges for explainability research. We also unveil\nnovel and emerging desiderata that explanations should fulfill, covering\naspects such as verifiability, interactivity, security, and cost. To this end,\nwe focus on surveying existing works. Furthermore, we provide a taxonomy of\nrelevant dimensions that allows us to better characterize existing XAI\nmechanisms and methods for GenAI. We discuss different avenues to ensure XAI,\nfrom training data to prompting. Our paper offers a short but concise technical\nbackground of GenAI for non-technical readers, focusing on text and images to\nbetter understand novel or adapted XAI techniques for GenAI. However, due to\nthe vast array of works on GenAI, we decided to forego detailed aspects of XAI\nrelated to evaluation and usage of explanations. As such, the manuscript\ninterests both technically oriented people and other disciplines, such as\nsocial scientists and information systems researchers. Our research roadmap\nprovides more than ten directions for future investigation.",
      "tldr_zh": "本论文对可解释生成式AI（Explainable Generative AI, GenXAI）进行调查、概念化和研究议程规划，强调了Generative AI (GenAI)从识别转向生成解决方案后，对Explainable AI (XAI)需求的急剧增加及其挑战。作者揭示了新的解释需求，包括verifiability（可验证性）、interactivity（交互性）、security（安全性）和cost（成本），并通过分类法（taxonomy）对现有XAI机制和方法进行系统化描述，从训练数据到提示策略探讨确保XAI的可行途径。论文为非技术读者提供简要技术背景，并提出超过十个未来研究方向，推动GenAI领域的解释性和可信度发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09554v1",
      "published_date": "2024-04-15 08:18:16 UTC",
      "updated_date": "2024-04-15 08:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:40:02.357675"
    },
    {
      "arxiv_id": "2404.12401v1",
      "title": "Items or Relations -- what do Artificial Neural Networks learn?",
      "title_zh": "项目还是关系——人工神经网络学到了什么？",
      "authors": [
        "Renate Krause",
        "Stefan Reimann"
      ],
      "abstract": "What has an Artificial Neural Network (ANN) learned after being successfully\ntrained to solve a task - the set of training items or the relations between\nthem? This question is difficult to answer for modern applied ANNs because of\ntheir enormous size and complexity. Therefore, here we consider a\nlow-dimensional network and a simple task, i.e., the network has to reproduce a\nset of training items identically. We construct the family of solutions\nanalytically and use standard learning algorithms to obtain numerical\nsolutions. These numerical solutions differ depending on the optimization\nalgorithm and the weight initialization and are shown to be particular members\nof the family of analytical solutions. In this simple setting, we observe that\nthe general structure of the network weights represents the training set's\nsymmetry group, i.e., the relations between training items. As a consequence,\nlinear networks generalize, i.e., reproduce items that were not part of the\ntraining set but are consistent with the symmetry of the training set. In\ncontrast, non-linear networks tend to learn individual training items and show\nassociative memory. At the same time, their ability to generalize is limited. A\nhigher degree of generalization is obtained for networks whose activation\nfunction contains a linear regime, such as tanh. Our results suggest ANN's\nability to generalize - instead of learning items - could be improved by\ngenerating a sufficiently big set of elementary operations to represent\nrelations and strongly depends on the applied non-linearity.",
      "tldr_zh": "本研究探讨了人工神经网络（ANNs）在训练后是否学习训练项本身还是它们之间的关系。通过使用低维网络和简单任务（即精确复制训练项），作者分析性地构建了解集，并通过标准学习算法获得数值解，结果显示这些解受优化算法和权重初始化影响，但反映了训练集的对称群（symmetry group）。发现线性网络能够泛化，成功复制未见过的但与训练集对称一致的项，而非线性网络则倾向于记忆个体项并表现出联想记忆，但泛化能力较弱。作者建议，通过使用包含线性部分的激活函数（如tanh）并生成足够的元素操作来表示关系，可以显著提升ANNs的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.12401v1",
      "published_date": "2024-04-15 08:11:45 UTC",
      "updated_date": "2024-04-15 08:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:40:13.248164"
    },
    {
      "arxiv_id": "2404.09544v1",
      "title": "GNNavigator: Towards Adaptive Training of Graph Neural Networks via Automatic Guideline Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Qiao",
        "Jianlei Yang",
        "Yingjie Qi",
        "Ao Zhou",
        "Chen Bai",
        "Bei Yu",
        "Weisheng Zhao",
        "Chunming Hu"
      ],
      "abstract": "Graph Neural Networks (GNNs) succeed significantly in many applications\nrecently. However, balancing GNNs training runtime cost, memory consumption,\nand attainable accuracy for various applications is non-trivial. Previous\ntraining methodologies suffer from inferior adaptability and lack a unified\ntraining optimization solution. To address the problem, this work proposes\nGNNavigator, an adaptive GNN training configuration optimization framework.\nGNNavigator meets diverse GNN application requirements due to our unified\nsoftware-hardware co-abstraction, proposed GNNs training performance model, and\npractical design space exploration solution. Experimental results show that\nGNNavigator can achieve up to 3.1x speedup and 44.9% peak memory reduction with\ncomparable accuracy to state-of-the-art approaches.",
      "tldr_zh": "这篇论文针对 Graph Neural Networks (GNNs) 训练中运行时成本、内存消耗和准确性的平衡难题，提出了一种自适应优化框架 GNNavigator。GNNavigator 通过统一的软件硬件协同抽象、GNNs 训练性能模型以及自动设计空间探索解决方案，实现对不同应用场景的灵活适应。实验结果显示，与最先进方法相比，它实现了高达 3.1 倍的速度提升和 44.9% 的峰值内存减少，同时保持了可比的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by DAC'24",
      "pdf_url": "http://arxiv.org/pdf/2404.09544v1",
      "published_date": "2024-04-15 08:11:21 UTC",
      "updated_date": "2024-04-15 08:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:40:25.468246"
    },
    {
      "arxiv_id": "2404.09537v1",
      "title": "Machine Learning Techniques for Python Source Code Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Talaya Farasat",
        "Joachim Posegga"
      ],
      "abstract": "Software vulnerabilities are a fundamental reason for the prevalence of cyber\nattacks and their identification is a crucial yet challenging problem in cyber\nsecurity. In this paper, we apply and compare different machine learning\nalgorithms for source code vulnerability detection specifically for Python\nprogramming language. Our experimental evaluation demonstrates that our\nBidirectional Long Short-Term Memory (BiLSTM) model achieves a remarkable\nperformance (average Accuracy = 98.6%, average F-Score = 94.7%, average\nPrecision = 96.2%, average Recall = 93.3%, average ROC = 99.3%), thereby,\nestablishing a new benchmark for vulnerability detection in Python source code.",
      "tldr_zh": "本研究探讨了机器学习技术在检测 Python 源代码漏洞中的应用，旨在解决软件漏洞导致网络攻击的难题。论文比较了不同机器学习算法，并重点评估了 Bidirectional Long Short-Term Memory (BiLSTM) 模型的表现。实验结果显示，BiLSTM 模型取得了卓越的性能，包括平均 Accuracy = 98.6%、F-Score = 94.7%、Precision = 96.2%、Recall = 93.3% 和 ROC = 99.3%，从而为 Python 源代码漏洞检测设立了新基准。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09537v1",
      "published_date": "2024-04-15 08:01:02 UTC",
      "updated_date": "2024-04-15 08:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:40:35.972032"
    },
    {
      "arxiv_id": "2404.15192v3",
      "title": "Measuring Diversity of Game Scenarios",
      "title_zh": "游戏场景多样性的测量",
      "authors": [
        "Yuchen Li",
        "Ziqi Wang",
        "Qingquan Zhang",
        "Bo Yuan",
        "Jialin Liu"
      ],
      "abstract": "This survey comprehensively reviews the multi-dimensionality of game scenario\ndiversity, spotlighting the innovative use of procedural content generation and\nother fields as cornerstones for enriching player experiences through diverse\ngame scenarios. By traversing a wide array of disciplines, from affective\nmodeling and multi-agent systems to psychological studies, our research\nunderscores the importance of diverse game scenarios in gameplay and education.\nThrough a taxonomy of diversity metrics and evaluation methods, we aim to\nbridge the current gaps in literature and practice, offering insights into\neffective strategies for measuring and integrating diversity in game scenarios.\nOur analysis highlights the necessity for a unified taxonomy to aid developers\nand researchers in crafting more engaging and varied game worlds. This survey\nnot only charts a path for future research in diverse game scenarios but also\nserves as a handbook for industry practitioners seeking to leverage diversity\nas a key component of game design and development.",
      "tldr_zh": "这篇调查回顾了游戏场景多样性的多维度，强调通过程序化内容生成（procedural content generation）和其他领域（如情感建模（affective modeling）、多智能体系统（multi-agent systems）和心理学研究）来丰富玩家体验在游戏玩法和教育中的关键作用。论文提出了一种多样性指标的分类法（taxonomy of diversity metrics）和评估方法，以填补文献和实践中的空白，并提供有效的策略来测量和整合游戏场景多样性。最终，该研究呼吁建立统一的分类法，帮助开发者和研究者创建更吸引人的游戏世界，并为未来研究和行业应用提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15192v3",
      "published_date": "2024-04-15 07:59:52 UTC",
      "updated_date": "2025-01-16 05:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:40:50.157215"
    },
    {
      "arxiv_id": "2404.09536v2",
      "title": "Noiseless Privacy-Preserving Decentralized Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sayan Biswas",
        "Mathieu Even",
        "Anne-Marie Kermarrec",
        "Laurent Massoulie",
        "Rafael Pires",
        "Rishi Sharma",
        "Martijn de Vos"
      ],
      "abstract": "Decentralized learning (DL) enables collaborative learning without a server\nand without training data leaving the users' devices. However, the models\nshared in DL can still be used to infer training data. Conventional defenses\nsuch as differential privacy and secure aggregation fall short in effectively\nsafeguarding user privacy in DL, either sacrificing model utility or\nefficiency. We introduce Shatter, a novel DL approach in which nodes create\nvirtual nodes (VNs) to disseminate chunks of their full model on their behalf.\nThis enhances privacy by (i) preventing attackers from collecting full models\nfrom other nodes, and (ii) hiding the identity of the original node that\nproduced a given model chunk. We theoretically prove the convergence of Shatter\nand provide a formal analysis demonstrating how Shatter reduces the efficacy of\nattacks compared to when exchanging full models between nodes. We evaluate the\nconvergence and attack resilience of Shatter with existing DL algorithms, with\nheterogeneous datasets, and against three standard privacy attacks. Our\nevaluation shows that Shatter not only renders these privacy attacks infeasible\nwhen each node operates 16 VNs but also exhibits a positive impact on model\nutility compared to standard DL. In summary, Shatter enhances the privacy of DL\nwhile maintaining the utility and efficiency of the model.",
      "tldr_zh": "这篇论文提出了 Shatter，一种无噪声的隐私保护去中心化学习 (DL) 方法，通过让节点创建 virtual nodes (VNs) 来分发模型块，从而防止攻击者收集完整模型并隐藏原始节点身份。相比传统防御如 differential privacy 和 secure aggregation，Shatter 不仅理论上证明了其收敛性，还在实验中展示了它对三类隐私攻击的显著抵抗力。结果表明，当每个节点使用 16 个 VNs 时，Shatter 使这些攻击无效，同时提升了模型效用和效率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted at PETS 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.09536v2",
      "published_date": "2024-04-15 07:59:11 UTC",
      "updated_date": "2024-09-12 13:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:41:02.303270"
    },
    {
      "arxiv_id": "2404.09533v2",
      "title": "WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Wang",
        "Fei Deng",
        "Peifan Jiang",
        "Shuang Wang",
        "Xiao Han",
        "Zhixuan Zhang"
      ],
      "abstract": "Low-dose computed tomography (LDCT) has become the technology of choice for\ndiagnostic medical imaging, given its lower radiation dose compared to standard\nCT, despite increasing image noise and potentially affecting diagnostic\naccuracy. To address this, advanced deep learning-based LDCT denoising\nalgorithms have been developed, primarily using Convolutional Neural Networks\n(CNNs) or Transformer Networks with the Unet architecture. This architecture\nenhances image detail by integrating feature maps from the encoder and decoder\nvia skip connections. However, current methods often overlook enhancements to\nthe Unet architecture itself, focusing instead on optimizing encoder and\ndecoder structures. This approach can be problematic due to the significant\ndifferences in feature map characteristics between the encoder and decoder,\nwhere simple fusion strategies may not effectively reconstruct images.In this\npaper, we introduce WiTUnet, a novel LDCT image denoising method that utilizes\nnested, dense skip pathways instead of traditional skip connections to improve\nfeature integration. WiTUnet also incorporates a windowed Transformer structure\nto process images in smaller, non-overlapping segments, reducing computational\nload. Additionally, the integration of a Local Image Perception Enhancement\n(LiPe) module in both the encoder and decoder replaces the standard multi-layer\nperceptron (MLP) in Transformers, enhancing local feature capture and\nrepresentation. Through extensive experimental comparisons, WiTUnet has\ndemonstrated superior performance over existing methods in key metrics such as\nPeak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Root Mean\nSquare Error (RMSE), significantly improving noise removal and image quality.",
      "tldr_zh": "本研究针对低剂量 CT (LDCT) 图像的噪声问题，提出了一种新型 U 形架构 WiTUnet，将 CNN 和 Transformer 整合以提升特征对齐和局部信息融合。WiTUnet 采用嵌套、密集的跳跃路径（nested, dense skip pathways）取代传统跳跃连接来改善特征整合，还引入 windowed Transformer 结构处理图像的非重叠小段以降低计算负载，并通过 Local Image Perception Enhancement (LiPe) 模块增强编码器和解码器中的局部特征捕获。实验结果显示，WiTUnet 在 PSNR、SSIM 和 RMSE 等关键指标上优于现有方法，显著提高了图像去噪效果和整体质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09533v2",
      "published_date": "2024-04-15 07:53:07 UTC",
      "updated_date": "2024-04-29 04:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:41:13.767904"
    },
    {
      "arxiv_id": "2404.09530v2",
      "title": "RanLayNet: A Dataset for Document Layout Detection used for Domain Adaptation and Generalization",
      "title_zh": "RanLayNet：用于领域适应和泛化的文档布局检测数据集",
      "authors": [
        "Avinash Anand",
        "Raj Jaiswal",
        "Mohit Gupta",
        "Siddhesh S Bangar",
        "Pijush Bhuyan",
        "Naman Lal",
        "Rajeev Singh",
        "Ritika Jha",
        "Rajiv Ratn Shah",
        "Shin'ichi Satoh"
      ],
      "abstract": "Large ground-truth datasets and recent advances in deep learning techniques\nhave been useful for layout detection. However, because of the restricted\nlayout diversity of these datasets, training on them requires a sizable number\nof annotated instances, which is both expensive and time-consuming. As a\nresult, differences between the source and target domains may significantly\nimpact how well these models function. To solve this problem, domain adaptation\napproaches have been developed that use a small quantity of labeled data to\nadjust the model to the target domain. In this research, we introduced a\nsynthetic document dataset called RanLayNet, enriched with automatically\nassigned labels denoting spatial positions, ranges, and types of layout\nelements. The primary aim of this endeavor is to develop a versatile dataset\ncapable of training models with robustness and adaptability to diverse document\nformats. Through empirical experimentation, we demonstrate that a deep layout\nidentification model trained on our dataset exhibits enhanced performance\ncompared to a model trained solely on actual documents. Moreover, we conduct a\ncomparative analysis by fine-tuning inference models using both PubLayNet and\nIIIT-AR-13K datasets on the Doclaynet dataset. Our findings emphasize that\nmodels enriched with our dataset are optimal for tasks such as achieving 0.398\nand 0.588 mAP95 score in the scientific document domain for the TABLE class.",
      "tldr_zh": "这篇论文介绍了 RanLayNet，一个合成文档数据集，用于文档布局检测，以解决现有数据集布局多样性不足的问题，从而提升模型的 Domain Adaptation 和 Generalization。RanLayNet 包含自动分配的标签，包括布局元素的空间位置、范围和类型，旨在提供多样化的训练数据，帮助模型适应各种文档格式。实验结果显示，在 RanLayNet 上训练的深度布局识别模型比仅使用真实文档训练的模型表现出色；在 Doclaynet 数据集上微调时，与 PubLayNet 和 IIIT-AR-13K 相比，该模型在 TABLE 类上达到了 0.398 和 0.588 mAP95 分数，证明了其在科学文档领域的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures, MMAsia 2023 Proceedings of the 5th ACM\n  International Conference on Multimedia in Asia",
      "pdf_url": "http://arxiv.org/pdf/2404.09530v2",
      "published_date": "2024-04-15 07:50:15 UTC",
      "updated_date": "2024-04-19 06:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:41:26.900033"
    },
    {
      "arxiv_id": "2404.09529v1",
      "title": "Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models",
      "title_zh": "Prepacking：一种用于快速预填充和提高大语言",
      "authors": [
        "Siyan Zhao",
        "Daniel Israel",
        "Guy Van den Broeck",
        "Aditya Grover"
      ],
      "abstract": "During inference for transformer-based large language models (LLM),\nprefilling is the computation of the key-value (KV) cache for input tokens in\nthe prompt prior to autoregressive generation. For longer input prompt lengths,\nprefilling will incur a significant overhead on decoding time. In this work, we\nhighlight the following pitfall of prefilling: for batches containing\nhigh-varying prompt lengths, significant computation is wasted by the standard\npractice of padding sequences to the maximum length. As LLMs increasingly\nsupport longer context lengths, potentially up to 10 million tokens, variations\nin prompt lengths within a batch become more pronounced. To address this, we\npropose Prepacking, a simple yet effective method to optimize prefilling\ncomputation. To avoid redundant computation on pad tokens, prepacking combines\nprompts of varying lengths into a sequence and packs multiple sequences into a\ncompact batch using a bin-packing algorithm. It then modifies the attention\nmask and positional encoding to compute multiple prefilled KV-caches for\nmultiple prompts within a single sequence. On standard curated dataset\ncontaining prompts with varying lengths, we obtain a significant speed and\nmemory efficiency improvements as compared to the default padding-based\nprefilling computation within Huggingface across a range of base model\nconfigurations and inference serving scenarios.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)中prefilling过程的计算浪费问题，提出了一种简单方法Prepacking，以优化处理不同提示长度的批次。Prepacking使用bin-packing算法将变长提示打包成紧凑序列，并通过修改attention mask和positional encoding，在单个序列中同时计算多个prefilled KV-cache，从而减少冗余计算。实验结果显示，与Huggingface的默认填充方法相比，Prepacking在标准数据集上显著提高了速度和内存效率，适用于各种模型配置和推理场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, code in https://github.com/siyan-zhao/prepacking",
      "pdf_url": "http://arxiv.org/pdf/2404.09529v1",
      "published_date": "2024-04-15 07:49:10 UTC",
      "updated_date": "2024-04-15 07:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:41:37.912231"
    },
    {
      "arxiv_id": "2404.09521v1",
      "title": "Inferring Behavior-Specific Context Improves Zero-Shot Generalization in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tidiane Camaret Ndir",
        "André Biedenkapp",
        "Noor Awad"
      ],
      "abstract": "In this work, we address the challenge of zero-shot generalization (ZSG) in\nReinforcement Learning (RL), where agents must adapt to entirely novel\nenvironments without additional training. We argue that understanding and\nutilizing contextual cues, such as the gravity level of the environment, is\ncritical for robust generalization, and we propose to integrate the learning of\ncontext representations directly with policy learning. Our algorithm\ndemonstrates improved generalization on various simulated domains,\noutperforming prior context-learning techniques in zero-shot settings. By\njointly learning policy and context, our method acquires behavior-specific\ncontext representations, enabling adaptation to unseen environments and marks\nprogress towards reinforcement learning systems that generalize across diverse\nreal-world tasks. Our code and experiments are available at\nhttps://github.com/tidiane-camaret/contextual_rl_zero_shot.",
      "tldr_zh": "这篇论文探讨了强化学习(Reinforcement Learning)中的零样本泛化(Zero-Shot Generalization)挑战，提出了一种将上下文表示学习与策略学习相结合的算法，以帮助代理在无需额外训练的情况下适应全新环境。方法通过推断行为特定的上下文表示（如环境的引力水平），实现了对上下文线索的更有效利用，并在各种模拟域上表现出色。实验结果表明，该算法在零样本设置中优于现有技术，推动了强化学习系统在多样化真实世界任务中的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/tidiane-camaret/contextual_rl_zero_shot",
      "pdf_url": "http://arxiv.org/pdf/2404.09521v1",
      "published_date": "2024-04-15 07:31:48 UTC",
      "updated_date": "2024-04-15 07:31:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:41:51.056704"
    },
    {
      "arxiv_id": "2404.09516v1",
      "title": "State Space Model for New-Generation Network Alternative to Transformers: A Survey",
      "title_zh": "状态空间模型：作为Transformer替代方案的新一代网络综述",
      "authors": [
        "Xiao Wang",
        "Shiao Wang",
        "Yuhe Ding",
        "Yuehang Li",
        "Wentao Wu",
        "Yao Rong",
        "Weizhe Kong",
        "Ju Huang",
        "Shihao Li",
        "Haoxiang Yang",
        "Ziwen Wang",
        "Bo Jiang",
        "Chenglong Li",
        "Yaowei Wang",
        "Yonghong Tian",
        "Jin Tang"
      ],
      "abstract": "In the post-deep learning era, the Transformer architecture has demonstrated\nits powerful performance across pre-trained big models and various downstream\ntasks. However, the enormous computational demands of this architecture have\ndeterred many researchers. To further reduce the complexity of attention\nmodels, numerous efforts have been made to design more efficient methods. Among\nthem, the State Space Model (SSM), as a possible replacement for the\nself-attention based Transformer model, has drawn more and more attention in\nrecent years. In this paper, we give the first comprehensive review of these\nworks and also provide experimental comparisons and analysis to better\ndemonstrate the features and advantages of SSM. Specifically, we first give a\ndetailed description of principles to help the readers quickly capture the key\nideas of SSM. After that, we dive into the reviews of existing SSMs and their\nvarious applications, including natural language processing, computer vision,\ngraph, multi-modal and multi-media, point cloud/event stream, time series data,\nand other domains. In addition, we give statistical comparisons and analysis of\nthese models and hope it helps the readers to understand the effectiveness of\ndifferent structures on various tasks. Then, we propose possible research\npoints in this direction to better promote the development of the theoretical\nmodel and application of SSM. More related works will be continuously updated\non the following GitHub:\nhttps://github.com/Event-AHU/Mamba_State_Space_Model_Paper_List.",
      "tldr_zh": "这篇论文对 State Space Model (SSM) 作为新一代网络架构的 Transformer 替代方案进行了首次全面调查，旨在解决 Transformer 高计算需求的挑战。论文详细阐述了 SSM 的原理，并回顾了其在自然语言处理、计算机视觉、图数据、多模态等领域中的各种应用，同时通过实验比较分析了不同 SSM 结构的有效性。最终，论文总结了 SSM 的优势，如效率提升，并提出了未来研究点以推动其理论和应用发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "The First review of State Space Model (SSM)/Mamba and their\n  applications in artificial intelligence, 33 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.09516v1",
      "published_date": "2024-04-15 07:24:45 UTC",
      "updated_date": "2024-04-15 07:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:42:01.345871"
    },
    {
      "arxiv_id": "2404.10024v1",
      "title": "ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs",
      "title_zh": "翻译失败",
      "authors": [
        "Yogesh Verma",
        "Markus Heinonen",
        "Vikas Garg"
      ],
      "abstract": "Climate and weather prediction traditionally relies on complex numerical\nsimulations of atmospheric physics. Deep learning approaches, such as\ntransformers, have recently challenged the simulation paradigm with complex\nnetwork forecasts. However, they often act as data-driven black-box models that\nneglect the underlying physics and lack uncertainty quantification. We address\nthese limitations with ClimODE, a spatiotemporal continuous-time process that\nimplements a key principle of advection from statistical mechanics, namely,\nweather changes due to a spatial movement of quantities over time. ClimODE\nmodels precise weather evolution with value-conserving dynamics, learning\nglobal weather transport as a neural flow, which also enables estimating the\nuncertainty in predictions. Our approach outperforms existing data-driven\nmethods in global and regional forecasting with an order of magnitude smaller\nparameterization, establishing a new state of the art.",
      "tldr_zh": "本研究针对气候和天气预测中，传统数值模拟的复杂性以及深度学习方法（如Transformer）作为数据驱动黑盒模型忽略物理原理且缺乏不确定性量化的问题，提出了一种基于Physics-informed Neural ODEs的框架ClimODE。ClimODE通过实现统计力学中的advection原理（即天气变化源于空间运动），采用值守恒动力学（value-conserving dynamics）和neural flow来学习全球天气传输，并能估计预测不确定性。该方法在全球和区域预测中显著优于现有数据驱动模型，参数量小一个数量级，确立了新的最先进水平。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as ICLR 2024 Oral. Project website:\n  https://yogeshverma1998.github.io/ClimODE/",
      "pdf_url": "http://arxiv.org/pdf/2404.10024v1",
      "published_date": "2024-04-15 06:38:21 UTC",
      "updated_date": "2024-04-15 06:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:42:14.610888"
    },
    {
      "arxiv_id": "2404.09480v1",
      "title": "Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Kyubyung Chae",
        "Jaepill Choi",
        "Yohan Jo",
        "Taesup Kim"
      ],
      "abstract": "A primary challenge in abstractive summarization is hallucination -- the\nphenomenon where a model generates plausible text that is absent in the source\ntext. We hypothesize that the domain (or topic) of the source text triggers the\nmodel to generate text that is highly probable in the domain, neglecting the\ndetails of the source text. To alleviate this model bias, we introduce a\ndecoding strategy based on domain-conditional pointwise mutual information.\nThis strategy adjusts the generation probability of each token by comparing it\nwith the token's marginal probability within the domain of the source text.\nAccording to evaluation on the XSUM dataset, our method demonstrates\nimprovement in terms of faithfulness and source relevance. The code is publicly\navailable at \\url{https://github.com/qqplot/dcpmi}.",
      "tldr_zh": "该论文针对抽象式摘要生成中的 hallucination 问题提出了一种新解码策略，假设源文本的 domain 会导致模型生成领域中高度 probable 的文本而忽略源细节。策略基于 domain-conditional pointwise mutual information，通过比较每个 token 的生成概率与其在源文本 domain 中的 marginal probability 来调整输出概率。在 XSUM 数据集上的评估显示，该方法显著提高了摘要的 faithfulness 和 source relevance，且代码已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by Findings of NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09480v1",
      "published_date": "2024-04-15 06:06:43 UTC",
      "updated_date": "2024-04-15 06:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:42:25.697566"
    },
    {
      "arxiv_id": "2404.09475v1",
      "title": "Improving Weakly-Supervised Object Localization Using Adversarial Erasing and Pseudo Label",
      "title_zh": "翻译失败",
      "authors": [
        "Byeongkeun Kang",
        "Sinhae Cha",
        "Yeejin Lee"
      ],
      "abstract": "Weakly-supervised learning approaches have gained significant attention due\nto their ability to reduce the effort required for human annotations in\ntraining neural networks. This paper investigates a framework for\nweakly-supervised object localization, which aims to train a neural network\ncapable of predicting both the object class and its location using only images\nand their image-level class labels. The proposed framework consists of a shared\nfeature extractor, a classifier, and a localizer. The localizer predicts\npixel-level class probabilities, while the classifier predicts the object class\nat the image level. Since image-level class labels are insufficient for\ntraining the localizer, weakly-supervised object localization methods often\nencounter challenges in accurately localizing the entire object region. To\naddress this issue, the proposed method incorporates adversarial erasing and\npseudo labels to improve localization accuracy. Specifically, novel losses are\ndesigned to utilize adversarially erased foreground features and adversarially\nerased feature maps, reducing dependence on the most discriminative region.\nAdditionally, the proposed method employs pseudo labels to suppress activation\nvalues in the background while increasing them in the foreground. The proposed\nmethod is applied to two backbone networks (MobileNetV1 and InceptionV3) and is\nevaluated on three publicly available datasets (ILSVRC-2012, CUB-200-2011, and\nPASCAL VOC 2012). The experimental results demonstrate that the proposed method\noutperforms previous state-of-the-art methods across all evaluated metrics.",
      "tldr_zh": "这篇论文针对弱监督对象定位（weakly-supervised object localization）的挑战，提出了一种框架，包括共享特征提取器（shared feature extractor）、分类器（classifier）和定位器（localizer），以仅使用图像级标签（image-level class labels）来预测对象类别和位置。方法创新性地引入对抗擦除（adversarial erasing）和伪标签（pseudo label），通过设计新型损失函数利用擦除的前景特征和特征图，减少对最 discriminative 区域的依赖，同时用伪标签抑制背景激活并增强前景激活。实验结果显示，该方法在 ILSVRC-2012、CUB-200-2011 和 PASCAL VOC 2012 数据集上，使用 MobileNetV1 和 InceptionV3 骨干网络时，超过了现有最先进方法（state-of-the-art methods）的性能指标。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.09475v1",
      "published_date": "2024-04-15 06:02:09 UTC",
      "updated_date": "2024-04-15 06:02:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:42:40.702226"
    },
    {
      "arxiv_id": "2404.09470v2",
      "title": "LatticeML: A data-driven application for predicting the effective Young Modulus of high temperature graph based architected materials",
      "title_zh": "翻译失败",
      "authors": [
        "Akshansh Mishra"
      ],
      "abstract": "Architected materials with their unique topology and geometry offer the\npotential to modify physical and mechanical properties. Machine learning can\naccelerate the design and optimization of these materials by identifying\noptimal designs and forecasting performance. This work presents LatticeML, a\ndata-driven application for predicting the effective Young's Modulus of\nhigh-temperature graph-based architected materials. The study considers eleven\ngraph-based lattice structures with two high-temperature alloys, Ti-6Al-4V and\nInconel 625. Finite element simulations were used to compute the effective\nYoung's Modulus of the 2x2x2 unit cell configurations. A machine learning\nframework was developed to predict Young's Modulus, involving data collection,\npreprocessing, implementation of regression models, and deployment of the\nbest-performing model. Five supervised learning algorithms were evaluated, with\nthe XGBoost Regressor achieving the highest accuracy (MSE = 2.7993, MAE =\n1.1521, R-squared = 0.9875). The application uses the Streamlit framework to\ncreate an interactive web interface, allowing users to input material and\ngeometric parameters and obtain predicted Young's Modulus values.",
      "tldr_zh": "这篇论文介绍了 LatticeML，一种数据驱动的应用，用于预测高温图基架构材料的有效 Young's Modulus。研究团队考虑了 11 种图基晶格结构和两种高温合金（Ti-6Al-4V 和 Inconel 625），并通过有限元模拟计算 2x2x2 单元格配置的数据。采用机器学习框架，包括数据预处理和五种监督学习算法的评估，最终 XGBoost Regressor 表现出最佳性能（MSE = 2.7993, MAE = 1.1521, R-squared = 0.9875）。该应用基于 Streamlit 框架开发了一个交互式 web 接口，允许用户输入材料和几何参数以快速获取预测结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "math.OC",
        "physics.app-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.09470v2",
      "published_date": "2024-04-15 05:50:46 UTC",
      "updated_date": "2024-04-16 01:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:42:52.175996"
    },
    {
      "arxiv_id": "2404.09468v2",
      "title": "Tokenization, Fusion, and Augmentation: Towards Fine-grained Multi-modal Entity Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Yichi Zhang",
        "Zhuo Chen",
        "Lingbing Guo",
        "Yajing Xu",
        "Binbin Hu",
        "Ziqi Liu",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to discover unobserved\nknowledge from given knowledge graphs, collaboratively leveraging structural\ninformation from the triples and multi-modal information of the entities to\novercome the inherent incompleteness. Existing MMKGC methods usually extract\nmulti-modal features with pre-trained models, resulting in coarse handling of\nmulti-modal entity information, overlooking the nuanced, fine-grained semantic\ndetails and their complex interactions. To tackle this shortfall, we introduce\na novel framework MyGO to tokenize, fuse, and augment the fine-grained\nmulti-modal representations of entities and enhance the MMKGC performance.\nMotivated by the tokenization technology, MyGO tokenizes multi-modal entity\ninformation as fine-grained discrete tokens and learns entity representations\nwith a cross-modal entity encoder. To further augment the multi-modal\nrepresentations, MyGO incorporates fine-grained contrastive learning to\nhighlight the specificity of the entity representations. Experiments on\nstandard MMKGC benchmarks reveal that our method surpasses 19 of the latest\nmodels, underlining its superior performance. Code and data can be found in\nhttps://github.com/zjukg/MyGO",
      "tldr_zh": "本研究针对多模态知识图谱补全(MMKGC)的不足，提出MyGO框架，通过tokenization、fusion和augmentation来处理细粒度的多模态实体表示，以更好地捕捉语义细节和交互。\nMyGO将多模态实体信息标记化为离散tokens，并使用cross-modal entity encoder学习实体表示，同时通过fine-grained contrastive learning增强表示的特定性。\n实验在标准MMKGC基准上显示，该方法超越了19个最新模型，显著提升了性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025; Repo is available at https://github.com/zjukg/MyGO",
      "pdf_url": "http://arxiv.org/pdf/2404.09468v2",
      "published_date": "2024-04-15 05:40:41 UTC",
      "updated_date": "2024-12-14 10:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:43:03.462650"
    },
    {
      "arxiv_id": "2404.13071v2",
      "title": "Modeling Emotions and Ethics with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "This paper explores the integration of human-like emotions and ethical\nconsiderations into Large Language Models (LLMs). We first model eight\nfundamental human emotions, presented as opposing pairs, and employ\ncollaborative LLMs to reinterpret and express these emotions across a spectrum\nof intensity. Our focus extends to embedding a latent ethical dimension within\nLLMs, guided by a novel self-supervised learning algorithm with human feedback\n(SSHF). This approach enables LLMs to perform self-evaluations and adjustments\nconcerning ethical guidelines, enhancing their capability to generate content\nthat is not only emotionally resonant but also ethically aligned. The\nmethodologies and case studies presented herein illustrate the potential of\nLLMs to transcend mere text and image generation, venturing into the realms of\nempathetic interaction and principled decision-making, thereby setting a new\nprecedent in the development of emotionally aware and ethically conscious AI\nsystems.",
      "tldr_zh": "这篇论文探讨了如何将人类-like 情感和伦理考虑整合到 Large Language Models (LLMs) 中，以提升其情感表达和道德决策能力。研究者首先模型了八种基本人类情感作为对立对，并使用协作 LLMs 来重新解释和表达这些情感在强度光谱上的变化。随后，他们引入了一个新型自监督学习算法 with human feedback (SSHF)，使 LLMs 能够进行自我评估和调整，以生成情感共鸣且伦理一致的内容。案例研究证明了这种方法在实现移情互动和原则决策方面的潜力，为开发情感感知和伦理意识的 AI 系统奠定了新基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.13071v2",
      "published_date": "2024-04-15 05:30:26 UTC",
      "updated_date": "2024-06-25 04:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:43:15.546849"
    },
    {
      "arxiv_id": "2404.09465v2",
      "title": "PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yandan Yang",
        "Baoxiong Jia",
        "Peiyuan Zhi",
        "Siyuan Huang"
      ],
      "abstract": "With recent developments in Embodied Artificial Intelligence (EAI) research,\nthere has been a growing demand for high-quality, large-scale interactive scene\ngeneration. While prior methods in scene synthesis have prioritized the\nnaturalness and realism of the generated scenes, the physical plausibility and\ninteractivity of scenes have been largely left unexplored. To address this\ndisparity, we introduce PhyScene, a novel method dedicated to generating\ninteractive 3D scenes characterized by realistic layouts, articulated objects,\nand rich physical interactivity tailored for embodied agents. Based on a\nconditional diffusion model for capturing scene layouts, we devise novel\nphysics- and interactivity-based guidance mechanisms that integrate constraints\nfrom object collision, room layout, and object reachability. Through extensive\nexperiments, we demonstrate that PhyScene effectively leverages these guidance\nfunctions for physically interactable scene synthesis, outperforming existing\nstate-of-the-art scene synthesis methods by a large margin. Our findings\nsuggest that the scenes generated by PhyScene hold considerable potential for\nfacilitating diverse skill acquisition among agents within interactive\nenvironments, thereby catalyzing further advancements in embodied AI research.\nProject website: http://physcene.github.io.",
      "tldr_zh": "该论文提出 PhyScene，一种针对 Embodied AI 的新型 3D 场景合成方法，专注于生成具有现实布局、可活动物体和丰富物理交互性的交互场景，以弥补现有方法忽略物理合理性的不足。PhyScene 基于条件扩散模型（conditional diffusion model），并引入物理和交互指导机制，包括物体碰撞、房间布局和物体可达性约束，确保场景的物理可交互性。通过广泛实验，PhyScene 在物理交互场景合成方面大幅优于现有最先进方法，并证明生成的场景能促进代理在交互环境中获取多样技能，推动 Embodied AI 研究的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2024 (Highlight), 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.09465v2",
      "published_date": "2024-04-15 05:29:23 UTC",
      "updated_date": "2024-07-10 02:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:43:26.708962"
    },
    {
      "arxiv_id": "2404.09462v1",
      "title": "Experimental Analysis of Deep Hedging Using Artificial Market Simulations for Underlying Asset Simulators",
      "title_zh": "翻译失败",
      "authors": [
        "Masanori Hirano"
      ],
      "abstract": "Derivative hedging and pricing are important and continuously studied topics\nin financial markets. Recently, deep hedging has been proposed as a promising\napproach that uses deep learning to approximate the optimal hedging strategy\nand can handle incomplete markets. However, deep hedging usually requires\nunderlying asset simulations, and it is challenging to select the best model\nfor such simulations. This study proposes a new approach using artificial\nmarket simulations for underlying asset simulations in deep hedging. Artificial\nmarket simulations can replicate the stylized facts of financial markets, and\nthey seem to be a promising approach for deep hedging. We investigate the\neffectiveness of the proposed approach by comparing its results with those of\nthe traditional approach, which uses mathematical finance models such as\nBrownian motion and Heston models for underlying asset simulations. The results\nshow that the proposed approach can achieve almost the same level of\nperformance as the traditional approach without mathematical finance models.\nFinally, we also reveal that the proposed approach has some limitations in\nterms of performance under certain conditions.",
      "tldr_zh": "该研究探讨了深度套期保值（deep hedging）的实验分析，提出使用人工市场模拟（artificial market simulations）作为底层资产模拟器，以解决传统方法在模型选择上的挑战。相比使用Brownian motion和Heston models的传统方法，新方法能复制金融市场的典型事实（stylized facts），并在性能上几乎相当，而无需依赖数学金融模型。实验结果显示，该方法在某些条件下存在局限性，但为更灵活的套期保值策略提供了新途径。",
      "categories": [
        "q-fin.CP",
        "cs.AI"
      ],
      "primary_category": "q-fin.CP",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.09462v1",
      "published_date": "2024-04-15 05:11:07 UTC",
      "updated_date": "2024-04-15 05:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:43:40.249784"
    },
    {
      "arxiv_id": "2404.09445v1",
      "title": "Exploring Text-to-Motion Generation with Human Preference",
      "title_zh": "翻译失败",
      "authors": [
        "Jenny Sheng",
        "Matthieu Lin",
        "Andrew Zhao",
        "Kevin Pruvost",
        "Yu-Hui Wen",
        "Yangguang Li",
        "Gao Huang",
        "Yong-Jin Liu"
      ],
      "abstract": "This paper presents an exploration of preference learning in text-to-motion\ngeneration. We find that current improvements in text-to-motion generation\nstill rely on datasets requiring expert labelers with motion capture systems.\nInstead, learning from human preference data does not require motion capture\nsystems; a labeler with no expertise simply compares two generated motions.\nThis is particularly efficient because evaluating the model's output is easier\nthan gathering the motion that performs a desired task (e.g. backflip). To\npioneer the exploration of this paradigm, we annotate 3,528 preference pairs\ngenerated by MotionGPT, marking the first effort to investigate various\nalgorithms for learning from preference data. In particular, our exploration\nhighlights important design choices when using preference data. Additionally,\nour experimental results show that preference learning has the potential to\ngreatly improve current text-to-motion generative models. Our code and dataset\nare publicly available at\nhttps://github.com/THU-LYJ-Lab/InstructMotion}{https://github.com/THU-LYJ-Lab/InstructMotion\nto further facilitate research in this area.",
      "tldr_zh": "这篇论文探索了在 text-to-motion generation 中应用 human preference 学习，以克服传统方法对专家标注和动作捕捉系统的依赖。研究者通过标注 3,528 个由 MotionGPT 生成的偏好对，让非专家简单比较两个动作输出，从而更高效地提升模型性能。实验结果表明，preference learning 能显著改进文本到动作生成模型的关键设计选择，并为未来研究提供了公开的代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to CVPR 2024 HuMoGen Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.09445v1",
      "published_date": "2024-04-15 04:14:42 UTC",
      "updated_date": "2024-04-15 04:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:43:53.267164"
    },
    {
      "arxiv_id": "2406.15373v1",
      "title": "Occupation Life Cycle",
      "title_zh": "职业生命周期",
      "authors": [
        "Lan Chen",
        "Yufei Ji",
        "Xichen Yao",
        "Hengshu Zhu"
      ],
      "abstract": "This paper explores the evolution of occupations within the context of\nindustry and technology life cycles, highlighting the critical yet\nunderexplored intersection between occupational trends and broader economic\ndynamics. Introducing the Occupation Life Cycle (OLC) model, we delineate five\nstages (i.e., growth, peak, fluctuation, maturity, and decline) to\nsystematically explore the trajectory of occupations. Utilizing job posting\ndata from one of China's largest recruitment platforms as a novel proxy, our\nstudy meticulously tracks the fluctuations and emerging trends in the labor\nmarket from 2018 to 2023. Through a detailed examination of representative\nroles, such as short video operators and data analysts, alongside emerging\noccupations within the artificial intelligence (AI) sector, our findings\nallocate occupations to specific life cycle stages, revealing insightful\npatterns of occupational development and decline. Our findings offer a unique\nperspective on the interplay between occupational evolution and economic\nfactors, with a particular focus on the rapidly changing Chinese labor market.\nThis study not only contributes to the theoretical understanding of OLC but\nalso provides practical insights for policymakers, educators, and industry\nleaders facing the challenges of workforce planning and development in the face\nof technological advancement and market shifts.",
      "tldr_zh": "本研究探讨了职业在行业和技术生命周期中的演变，引入了Occupation Life Cycle (OLC) 模型，该模型将职业划分为五个阶段：增长、峰值、波动、成熟和衰退。研究利用中国最大招聘平台从2018年至2023年的职位发布数据作为代理，分析了代表性角色（如短视频操作员和数据分析师）以及AI领域新兴职业的轨迹。结果揭示了职业发展的模式和与经济因素的互动，特别是在快速变化的中国劳动力市场。整体而言，该研究不仅丰富了OLC的理论理解，还为政策制定者、教育者和行业领袖提供实际指导，以应对技术进步和市场变动的挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15373v1",
      "published_date": "2024-04-15 03:13:51 UTC",
      "updated_date": "2024-04-15 03:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:44:04.665136"
    },
    {
      "arxiv_id": "2404.09432v1",
      "title": "The 8th AI City Challenge",
      "title_zh": "第八届 AI City Challenge",
      "authors": [
        "Shuo Wang",
        "David C. Anastasiu",
        "Zheng Tang",
        "Ming-Ching Chang",
        "Yue Yao",
        "Liang Zheng",
        "Mohammed Shaiqur Rahman",
        "Meenakshi S. Arya",
        "Anuj Sharma",
        "Pranamesh Chakraborty",
        "Sanjita Prajapati",
        "Quan Kong",
        "Norimasa Kobori",
        "Munkhjargal Gochoo",
        "Munkh-Erdene Otgonbold",
        "Fady Alnajjar",
        "Ganzorig Batnasan",
        "Ping-Yang Chen",
        "Jun-Wei Hsieh",
        "Xunlei Wu",
        "Sameer Satish Pusegaonkar",
        "Yizhou Wang",
        "Sujit Biswas",
        "Rama Chellappa"
      ],
      "abstract": "The eighth AI City Challenge highlighted the convergence of computer vision\nand artificial intelligence in areas like retail, warehouse settings, and\nIntelligent Traffic Systems (ITS), presenting significant research\nopportunities. The 2024 edition featured five tracks, attracting unprecedented\ninterest from 726 teams in 47 countries and regions. Track 1 dealt with\nmulti-target multi-camera (MTMC) people tracking, highlighting significant\nenhancements in camera count, character number, 3D annotation, and camera\nmatrices, alongside new rules for 3D tracking and online tracking algorithm\nencouragement. Track 2 introduced dense video captioning for traffic safety,\nfocusing on pedestrian accidents using multi-camera feeds to improve insights\nfor insurance and prevention. Track 3 required teams to classify driver actions\nin a naturalistic driving analysis. Track 4 explored fish-eye camera analytics\nusing the FishEye8K dataset. Track 5 focused on motorcycle helmet rule\nviolation detection. The challenge utilized two leaderboards to showcase\nmethods, with participants setting new benchmarks, some surpassing existing\nstate-of-the-art achievements.",
      "tldr_zh": "第八届 AI City Challenge 聚焦计算机视觉和 AI 在零售、仓库和 Intelligent Traffic Systems (ITS) 等领域的应用，吸引了来自 47 个国家和地区的 726 个团队参与。挑战赛包括五个轨道：Track 1 针对多目标多相机 (MTMC) 人员跟踪，引入了相机数量、人物数、3D 标注和相机矩阵的增强，以及新规则支持 3D 和在线跟踪；Track 2 涉及密集视频字幕用于交通安全，分析多相机行人事故；Track 3 分类驾驶员行为；Track 4 探索 FishEye8K 数据集的鱼眼相机分析；Track 5 检测摩托车头盔规则违规。参与者通过两个排行榜展示了创新方法，并设置了新基准，有些超过了现有最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Summary of the 8th AI City Challenge Workshop in conjunction with\n  CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09432v1",
      "published_date": "2024-04-15 03:12:17 UTC",
      "updated_date": "2024-04-15 03:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:44:16.951654"
    },
    {
      "arxiv_id": "2404.09405v2",
      "title": "Few-shot Name Entity Recognition on StackOverflow",
      "title_zh": "翻译失败",
      "authors": [
        "Xinwei Chen",
        "Kun Li",
        "Tianyou Song",
        "Jiangjian Guo"
      ],
      "abstract": "StackOverflow, with its vast question repository and limited labeled\nexamples, raise an annotation challenge for us. We address this gap by\nproposing RoBERTa+MAML, a few-shot named entity recognition (NER) method\nleveraging meta-learning. Our approach, evaluated on the StackOverflow NER\ncorpus (27 entity types), achieves a 5% F1 score improvement over the baseline.\nWe improved the results further domain-specific phrase processing enhance\nresults.",
      "tldr_zh": "该研究针对 StackOverflow 平台的大量问题库但标注样本有限的挑战，提出了一种少样本命名实体识别 (NER) 方法，即 RoBERTa+MAML，利用元学习 (meta-learning) 技术来提升模型泛化能力。在 StackOverflow NER 语料库（涵盖 27 种实体类型）上的评估中，该方法比基线模型的 F1 分数提高了 5%。此外，通过引入领域特定短语处理，进一步优化了识别性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.09405v2",
      "published_date": "2024-04-15 01:43:14 UTC",
      "updated_date": "2024-04-28 01:58:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:44:28.036787"
    },
    {
      "arxiv_id": "2404.09402v1",
      "title": "Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Yang",
        "Ali Hasan",
        "Yuting Ng",
        "Vahid Tarokh"
      ],
      "abstract": "McKean-Vlasov stochastic differential equations (MV-SDEs) provide a\nmathematical description of the behavior of an infinite number of interacting\nparticles by imposing a dependence on the particle density. As such, we study\nthe influence of explicitly including distributional information in the\nparameterization of the SDE. We propose a series of semi-parametric methods for\nrepresenting MV-SDEs, and corresponding estimators for inferring parameters\nfrom data based on the properties of the MV-SDE. We analyze the characteristics\nof the different architectures and estimators, and consider their applicability\nin relevant machine learning problems. We empirically compare the performance\nof the different architectures and estimators on real and synthetic datasets\nfor time series and probabilistic modeling. The results suggest that explicitly\nincluding distributional dependence in the parameterization of the SDE is\neffective in modeling temporal data with interaction under an exchangeability\nassumption while maintaining strong performance for standard It\\^o-SDEs due to\nthe richer class of probability flows associated with MV-SDEs.",
      "tldr_zh": "该论文探讨了McKean-Vlasov随机微分方程(MV-SDEs)，这些方程通过依赖粒子密度来描述无限个相互作用粒子的行为，并研究了在SDE参数化中显式包含分布信息的影响。作者提出了一系列半参数方法来表示MV-SDEs，以及基于其属性的参数估计器，以从数据中推断参数，并分析了这些架构在机器学习问题中的适用性。通过实证实验在真实和合成数据集上比较性能，结果表明，这种方法在可交换性假设下有效建模具有交互性的时间序列数据，同时保持了标准Itô-SDEs的强性能，因为MV-SDEs提供了更丰富的概率流。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Appears in AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.09402v1",
      "published_date": "2024-04-15 01:28:16 UTC",
      "updated_date": "2024-04-15 01:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:44:42.484076"
    },
    {
      "arxiv_id": "2404.09401v2",
      "title": "Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peifei Zhu",
        "Tsubasa Takahashi",
        "Hirokatsu Kataoka"
      ],
      "abstract": "Diffusion Models (DMs) have shown remarkable capabilities in various\nimage-generation tasks. However, there are growing concerns that DMs could be\nused to imitate unauthorized creations and thus raise copyright issues. To\naddress this issue, we propose a novel framework that embeds personal\nwatermarks in the generation of adversarial examples. Such examples can force\nDMs to generate images with visible watermarks and prevent DMs from imitating\nunauthorized images. We construct a generator based on conditional adversarial\nnetworks and design three losses (adversarial loss, GAN loss, and perturbation\nloss) to generate adversarial examples that have subtle perturbation but can\neffectively attack DMs to prevent copyright violations. Training a generator\nfor a personal watermark by our method only requires 5-10 samples within 2-3\nminutes, and once the generator is trained, it can generate adversarial\nexamples with that watermark significantly fast (0.2s per image). We conduct\nextensive experiments in various conditional image-generation scenarios.\nCompared to existing methods that generate images with chaotic textures, our\nmethod adds visible watermarks on the generated images, which is a more\nstraightforward way to indicate copyright violations. We also observe that our\nadversarial examples exhibit good transferability across unknown generative\nmodels. Therefore, this work provides a simple yet powerful way to protect\ncopyright from DM-based imitation.",
      "tldr_zh": "该研究针对扩散模型(DMs)可能模仿未经授权图像并引发版权问题的风险，提出了一种新框架：在生成对抗样本(adversarial examples)中嵌入个人水标记，以强制DMs输出带有可见水标记的图像，从而防止版权侵犯。该框架基于条件对抗网络(conditional adversarial networks)，并设计了三种损失函数(adversarial loss、GAN loss和perturbation loss)，确保对抗样本扰动微小但攻击效果强悍。训练生成器仅需5-10个样本即可完成，耗时2-3分钟，且生成每个图像仅需0.2秒。实验结果显示，该方法在各种条件图像生成场景中表现出色，与现有方法相比更直接地标识版权问题，并具有良好的转移性(transfers across unknown generative models)，为DMs版权保护提供简单而高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "updated references",
      "pdf_url": "http://arxiv.org/pdf/2404.09401v2",
      "published_date": "2024-04-15 01:27:07 UTC",
      "updated_date": "2024-04-19 05:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:44:53.807757"
    },
    {
      "arxiv_id": "2404.15353v1",
      "title": "SQUWA: Signal Quality Aware DNN Architecture for Enhanced Accuracy in Atrial Fibrillation Detection from Noisy PPG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Runze Yan",
        "Cheng Ding",
        "Ran Xiao",
        "Aleksandr Fedorov",
        "Randall J Lee",
        "Fadi Nahab",
        "Xiao Hu"
      ],
      "abstract": "Atrial fibrillation (AF), a common cardiac arrhythmia, significantly\nincreases the risk of stroke, heart disease, and mortality.\nPhotoplethysmography (PPG) offers a promising solution for continuous AF\nmonitoring, due to its cost efficiency and integration into wearable devices.\nNonetheless, PPG signals are susceptible to corruption from motion artifacts\nand other factors often encountered in ambulatory settings. Conventional\napproaches typically discard corrupted segments or attempt to reconstruct\noriginal signals, allowing for the use of standard machine learning techniques.\nHowever, this reduces dataset size and introduces biases, compromising\nprediction accuracy and the effectiveness of continuous monitoring. We propose\na novel deep learning model, Signal Quality Weighted Fusion of Attentional\nConvolution and Recurrent Neural Network (SQUWA), designed to learn how to\nretain accurate predictions from partially corrupted PPG. Specifically, SQUWA\ninnovatively integrates an attention mechanism that directly considers signal\nquality during the learning process, dynamically adjusting the weights of time\nseries segments based on their quality. This approach enhances the influence of\nhigher-quality segments while reducing that of lower-quality ones, effectively\nutilizing partially corrupted segments. This approach represents a departure\nfrom the conventional methods that exclude such segments, enabling the\nutilization of a broader range of data, which has great implications for less\ndisruption when monitoring of AF risks and more accurate estimation of AF\nburdens. Our extensive experiments show that SQUWA outperform existing\nPPG-based models, achieving the highest AUCPR of 0.89 with label noise\nmitigation. This also exceeds the 0.86 AUCPR of models trained with using both\nelectrocardiogram (ECG) and PPG data.",
      "tldr_zh": "房颤 (Atrial Fibrillation, AF) 是一种常见的心律失常，会增加中风、心脏病和死亡风险，而 Photoplethysmography (PPG) 信号因其成本效益和可穿戴设备集成性，成为连续监测的理想选择，但易受运动伪像等噪声干扰。研究提出 SQUWA 模型，一种信号质量感知的深度神经网络 (DNN) 架构，通过注意力机制动态调整时间序列段的权重，融合卷积和循环神经网络 (RNN)，从而保留并利用部分受损信号，避免传统方法的数据丢弃和偏差。实验结果表明，SQUWA 在噪声环境下实现 AUCPR 0.89 的最高性能，优于现有 PPG 模型，甚至超越使用 Electrocardiogram (ECG) 和 PPG 数据的基准，提升了 AF 检测的准确性和监测效率。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "15 pages; 9 figures; 2024 Conference on Health, Inference, and\n  Learning (CHIL)",
      "pdf_url": "http://arxiv.org/pdf/2404.15353v1",
      "published_date": "2024-04-15 01:07:08 UTC",
      "updated_date": "2024-04-15 01:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:45:06.726909"
    },
    {
      "arxiv_id": "2404.09391v1",
      "title": "Privacy at a Price: Exploring its Dual Impact on AI Fairness",
      "title_zh": "隐私的代价：探索其对 AI 公平性的双重影响",
      "authors": [
        "Mengmeng Yang",
        "Ming Ding",
        "Youyang Qu",
        "Wei Ni",
        "David Smith",
        "Thierry Rakotoarivelo"
      ],
      "abstract": "The worldwide adoption of machine learning (ML) and deep learning models,\nparticularly in critical sectors, such as healthcare and finance, presents\nsubstantial challenges in maintaining individual privacy and fairness. These\ntwo elements are vital to a trustworthy environment for learning systems. While\nnumerous studies have concentrated on protecting individual privacy through\ndifferential privacy (DP) mechanisms, emerging research indicates that\ndifferential privacy in machine learning models can unequally impact separate\ndemographic subgroups regarding prediction accuracy. This leads to a fairness\nconcern, and manifests as biased performance. Although the prevailing view is\nthat enhancing privacy intensifies fairness disparities, a smaller, yet\nsignificant, subset of research suggests the opposite view. In this article,\nwith extensive evaluation results, we demonstrate that the impact of\ndifferential privacy on fairness is not monotonous. Instead, we observe that\nthe accuracy disparity initially grows as more DP noise (enhanced privacy) is\nadded to the ML process, but subsequently diminishes at higher privacy levels\nwith even more noise. Moreover, implementing gradient clipping in the\ndifferentially private stochastic gradient descent ML method can mitigate the\nnegative impact of DP noise on fairness. This mitigation is achieved by\nmoderating the disparity growth through a lower clipping threshold.",
      "tldr_zh": "本研究探讨了差分隐私 (DP) 对人工智能公平性的双重影响，揭示了在机器学习 (ML) 模型中保护隐私可能导致不同群体预测准确性不平等，从而加剧公平性问题。作者通过广泛评估发现，DP 噪声的增加并非单调地影响公平：准确性差异在添加适量噪声时先扩大，但在更高隐私水平下会减小。实验结果表明，使用梯度剪切于差分私有随机梯度下降方法，能通过降低剪切阈值缓解 DP 噪声对公平性的负面影响，为平衡隐私与公平提供重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.09391v1",
      "published_date": "2024-04-15 00:23:41 UTC",
      "updated_date": "2024-04-15 00:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:45:16.349089"
    },
    {
      "arxiv_id": "2404.09387v3",
      "title": "RankCLIP: Ranking-Consistent Language-Image Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhang",
        "Zhuokai Zhao",
        "Zhaorun Chen",
        "Zhili Feng",
        "Zenghui Ding",
        "Yining Sun"
      ],
      "abstract": "Self-supervised contrastive learning models, such as CLIP, have set new\nbenchmarks for vision-language models in many downstream tasks. However, their\ndependency on rigid one-to-one mappings overlooks the complex and often\nmultifaceted relationships between and within texts and images. To this end, we\nintroduce RankCLIP, a novel pre-training method that extends beyond the rigid\none-to-one matching framework of CLIP and its variants. By extending the\ntraditional pair-wise loss to list-wise, and leveraging both in-modal and\ncross-modal ranking consistency, RankCLIP improves the alignment process,\nenabling it to capture the nuanced many-to-many relationships between and\nwithin each modality. Through comprehensive experiments, we demonstrate the\neffectiveness of RankCLIP in various downstream tasks, notably achieving\nsignificant gains in zero-shot classifications over state-of-the-art methods,\nunderscoring the importance of this enhanced learning process.",
      "tldr_zh": "该研究指出，现有的自监督对比学习模型如 CLIP 依赖于刚性的 one-to-one 映射，忽略了文本和图像之间的复杂多对多关系。为此，RankCLIP 提出了一种新型预训练方法，将 pair-wise loss 扩展到 list-wise loss，并通过 in-modal 和 cross-modal 排名一致性来提升模态对齐。实验结果显示，RankCLIP 在各种下游任务中表现出色，尤其在 zero-shot classifications 上比最先进方法实现了显著性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and model checkpoints are available at\n  https://github.com/Jam1ezhang/RankCLIP",
      "pdf_url": "http://arxiv.org/pdf/2404.09387v3",
      "published_date": "2024-04-15 00:12:27 UTC",
      "updated_date": "2025-03-24 14:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T00:45:29.568365"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 109,
  "processed_papers_count": 109,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T00:45:51.860713"
}