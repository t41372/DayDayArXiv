[
  {
    "arxiv_id": "2404.10180v2",
    "title": "Deferred NAM: Low-latency Top-K Context Injection via Deferred Context Encoding for Non-Streaming ASR",
    "authors": [
      "Zelin Wu",
      "Gan Song",
      "Christopher Li",
      "Pat Rondon",
      "Zhong Meng",
      "Xavier Velez",
      "Weiran Wang",
      "Diamantino Caseiro",
      "Golan Pundak",
      "Tsendsuren Munkhdalai",
      "Angad Chandorkar",
      "Rohit Prabhavalkar"
    ],
    "abstract": "Contextual biasing enables speech recognizers to transcribe important phrases\nin the speaker's context, such as contact names, even if they are rare in, or\nabsent from, the training data. Attention-based biasing is a leading approach\nwhich allows for full end-to-end cotraining of the recognizer and biasing\nsystem and requires no separate inference-time components. Such biasers\ntypically consist of a context encoder; followed by a context filter which\nnarrows down the context to apply, improving per-step inference time; and,\nfinally, context application via cross attention. Though much work has gone\ninto optimizing per-frame performance, the context encoder is at least as\nimportant: recognition cannot begin before context encoding ends. Here, we show\nthe lightweight phrase selection pass can be moved before context encoding,\nresulting in a speedup of up to 16.1 times and enabling biasing to scale to 20K\nphrases with a maximum pre-decoding delay under 33ms. With the addition of\nphrase- and wordpiece-level cross-entropy losses, our technique also achieves\nup to a 37.5% relative WER reduction over the baseline without the losses and\nlightweight phrase selection pass.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures, accepted by NAACL 2024 - Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2404.10180v2",
    "published_date": "2024-04-15 23:28:13 UTC",
    "updated_date": "2024-04-23 13:43:26 UTC"
  },
  {
    "arxiv_id": "2404.10170v1",
    "title": "High-Resolution Detection of Earth Structural Heterogeneities from Seismic Amplitudes using Convolutional Neural Networks with Attention layers",
    "authors": [
      "Luiz Schirmer",
      "Guilherme Schardong",
      "Vinícius da Silva",
      "Rogério Santos",
      "Hélio Lopes"
    ],
    "abstract": "Earth structural heterogeneities have a remarkable role in the petroleum\neconomy for both exploration and production projects. Automatic detection of\ndetailed structural heterogeneities is challenging when considering modern\nmachine learning techniques like deep neural networks. Typically, these\ntechniques can be an excellent tool for assisted interpretation of such\nheterogeneities, but it heavily depends on the amount of data to be trained.\n  We propose an efficient and cost-effective architecture for detecting seismic\nstructural heterogeneities using Convolutional Neural Networks (CNNs) combined\nwith Attention layers. The attention mechanism reduces costs and enhances\naccuracy, even in cases with relatively noisy data. Our model has half the\nparameters compared to the state-of-the-art, and it outperforms previous\nmethods in terms of Intersection over Union (IoU) by 0.6% and precision by\n0.4%. By leveraging synthetic data, we apply transfer learning to train and\nfine-tune the model, addressing the challenge of limited annotated data\navailability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10170v1",
    "published_date": "2024-04-15 22:49:37 UTC",
    "updated_date": "2024-04-15 22:49:37 UTC"
  },
  {
    "arxiv_id": "2404.10163v2",
    "title": "EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning",
    "authors": [
      "Yue Jiang",
      "Zixin Guo",
      "Hamed Rezazadegan Tavakoli",
      "Luis A. Leiva",
      "Antti Oulasvirta"
    ],
    "abstract": "From a visual perception perspective, modern graphical user interfaces (GUIs)\ncomprise a complex graphics-rich two-dimensional visuospatial arrangement of\ntext, images, and interactive objects such as buttons and menus. While existing\nmodels can accurately predict regions and objects that are likely to attract\nattention ``on average'', so far there is no scanpath model capable of\npredicting scanpaths for an individual. To close this gap, we introduce\nEyeFormer, which leverages a Transformer architecture as a policy network to\nguide a deep reinforcement learning algorithm that controls gaze locations. Our\nmodel has the unique capability of producing personalized predictions when\ngiven a few user scanpath samples. It can predict full scanpath information,\nincluding fixation positions and duration, across individuals and various\nstimulus types. Additionally, we demonstrate applications in GUI layout\noptimization driven by our model. Our software and models will be publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10163v2",
    "published_date": "2024-04-15 22:26:27 UTC",
    "updated_date": "2024-04-21 03:17:23 UTC"
  },
  {
    "arxiv_id": "2404.10162v1",
    "title": "Optimal Kernel Tuning Parameter Prediction using Deep Sequence Models",
    "authors": [
      "Khawir Mahmood",
      "Jehandad Khan",
      "Hammad Afzal"
    ],
    "abstract": "GPU kernels have come to the forefront of computing due to their utility in\nvaried fields, from high-performance computing to machine learning. A typical\nGPU compute kernel is invoked millions, if not billions of times in a typical\napplication, which makes their performance highly critical. Due to the unknown\nnature of the optimization surface, an exhaustive search is required to\ndiscover the global optimum, which is infeasible due to the possible\nexponential number of parameter combinations. In this work, we propose a\nmethodology that uses deep sequence-to-sequence models to predict the optimal\ntuning parameters governing compute kernels. This work considers the prediction\nof kernel parameters as a sequence to the sequence translation problem,\nborrowing models from the Natural Language Processing (NLP) domain. Parameters\ndescribing the input, output and weight tensors are considered as the input\nlanguage to the model that emits the corresponding kernel parameters. In\nessence, the model translates the problem parameter language to kernel\nparameter language. The core contributions of this work are: a) Proposing that\na sequence to sequence model can accurately learn the performance dynamics of a\nGPU compute kernel b) A novel network architecture which predicts the kernel\ntuning parameters for GPU kernels, c) A constrained beam search which\nincorporates the physical limits of the GPU hardware as well as other expert\nknowledge reducing the search space. The proposed algorithm can achieve more\nthan 90% accuracy on various convolutional kernels in MIOpen, the AMD machine\nlearning primitives library. As a result, the proposed technique can reduce the\ndevelopment time and compute resources required to tune unseen input\nconfigurations, resulting in shorter development cycles, reduced development\ncosts, and better user experience.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10162v1",
    "published_date": "2024-04-15 22:25:54 UTC",
    "updated_date": "2024-04-15 22:25:54 UTC"
  },
  {
    "arxiv_id": "2404.10160v6",
    "title": "Reinforcement Learning from Multi-role Debates as Feedback for Bias Mitigation in LLMs",
    "authors": [
      "Ruoxi Cheng",
      "Haoxuan Ma",
      "Shuirong Cao",
      "Jiaqi Li",
      "Aihua Pei",
      "Zhiqiang Wang",
      "Pengliang Ji",
      "Haoyu Wang",
      "Jiaqi Huo"
    ],
    "abstract": "Bias in LLMs can harm user experience and societal outcomes. However, current\nbias mitigation methods often require intensive human feedback, lack\ntransferability to other topics or yield overconfident and random outputs. We\nfind that involving LLMs in role-playing scenario boosts their ability to\nrecognize and mitigate biases. Based on this, we propose Reinforcement Learning\nfrom Multi-role Debates as Feedback (RLDF), a novel approach for bias\nmitigation replacing human feedback in traditional RLHF. We utilize LLMs in\nmulti-role debates to create a dataset that includes both high-bias and\nlow-bias instances for training the reward model in reinforcement learning. Our\napproach comprises two modes: (1) self-reflection, where the same LLM\nparticipates in multi-role debates, and (2) teacher-student, where a more\nadvanced LLM like GPT-3.5-turbo guides the LLM to perform this task.\nExperimental results across different LLMs on BBQ and our datasets demonstrate\nthe effectiveness of our approach in bias mitigation. Our source code and\ndatasets are available at \\texttt{https://anonymous.4open.science/r/RLDF-E344}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The first three authors contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2404.10160v6",
    "published_date": "2024-04-15 22:18:50 UTC",
    "updated_date": "2024-08-16 12:20:22 UTC"
  },
  {
    "arxiv_id": "2404.10142v2",
    "title": "Shaping Realities: Enhancing 3D Generative AI with Fabrication Constraints",
    "authors": [
      "Faraz Faruqi",
      "Yingtao Tian",
      "Vrushank Phadnis",
      "Varun Jampani",
      "Stefanie Mueller"
    ],
    "abstract": "Generative AI tools are becoming more prevalent in 3D modeling, enabling\nusers to manipulate or create new models with text or images as inputs. This\nmakes it easier for users to rapidly customize and iterate on their 3D designs\nand explore new creative ideas. These methods focus on the aesthetic quality of\nthe 3D models, refining them to look similar to the prompts provided by the\nuser. However, when creating 3D models intended for fabrication, designers need\nto trade-off the aesthetic qualities of a 3D model with their intended physical\nproperties. To be functional post-fabrication, 3D models have to satisfy\nstructural constraints informed by physical principles. Currently, such\nrequirements are not enforced by generative AI tools. This leads to the\ndevelopment of aesthetically appealing, but potentially non-functional 3D\ngeometry, that would be hard to fabricate and use in the real world. This\nworkshop paper highlights the limitations of generative AI tools in translating\ndigital creations into the physical world and proposes new augmentations to\ngenerative AI tools for creating physically viable 3D models. We advocate for\nthe development of tools that manipulate or generate 3D models by considering\nnot only the aesthetic appearance but also using physical properties as\nconstraints. This exploration seeks to bridge the gap between digital\ncreativity and real-world applicability, extending the creative potential of\ngenerative AI into the tangible domain.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10142v2",
    "published_date": "2024-04-15 21:22:57 UTC",
    "updated_date": "2024-04-17 02:33:32 UTC"
  },
  {
    "arxiv_id": "2404.10136v1",
    "title": "Language Model Cascades: Token-level uncertainty and beyond",
    "authors": [
      "Neha Gupta",
      "Harikrishna Narasimhan",
      "Wittawat Jitkrittum",
      "Ankit Singh Rawat",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ],
    "abstract": "Recent advances in language models (LMs) have led to significant improvements\nin quality on complex NLP tasks, but at the expense of increased inference\ncosts. Cascading offers a simple strategy to achieve more favorable\ncost-quality tradeoffs: here, a small model is invoked for most \"easy\"\ninstances, while a few \"hard\" instances are deferred to the large model. While\nthe principles underpinning cascading are well-studied for classification tasks\n- with deferral based on predicted class uncertainty favored theoretically and\npractically - a similar understanding is lacking for generative LM tasks. In\nthis work, we initiate a systematic study of deferral rules for LM cascades. We\nbegin by examining the natural extension of predicted class uncertainty to\ngenerative LM tasks, namely, the predicted sequence uncertainty. We show that\nthis measure suffers from the length bias problem, either over- or\nunder-emphasizing outputs based on their lengths. This is because LMs produce a\nsequence of uncertainty values, one for each output token; and moreover, the\nnumber of output tokens is variable across examples. To mitigate this issue, we\npropose to exploit the richer token-level uncertainty information implicit in\ngenerative LMs. We argue that naive predicted sequence uncertainty corresponds\nto a simple aggregation of these uncertainties. By contrast, we show that\nincorporating token-level uncertainty through learned post-hoc deferral rules\ncan significantly outperform such simple aggregation strategies, via\nexperiments on a range of natural language benchmarks with FLAN-T5 models. We\nfurther show that incorporating embeddings from the smaller model and\nintermediate layers of the larger model can give an additional boost in the\noverall cost-quality tradeoff.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10136v1",
    "published_date": "2024-04-15 21:02:48 UTC",
    "updated_date": "2024-04-15 21:02:48 UTC"
  },
  {
    "arxiv_id": "2404.10135v2",
    "title": "Using Long Short-term Memory (LSTM) to merge precipitation data over mountainous area in Sierra Nevada",
    "authors": [
      "Yihan Wang",
      "Lujun Zhang"
    ],
    "abstract": "Obtaining reliable precipitation estimation with high resolutions in time and\nspace is of great importance to hydrological studies. However, accurately\nestimating precipitation is a challenging task over high mountainous complex\nterrain. The three widely used precipitation measurement approaches, namely\nrainfall gauge, precipitation radars, and satellite-based precipitation\nsensors, have their own pros and cons in producing reliable precipitation\nproducts over complex areas. One way to decrease the detection error\nprobability and improve data reliability is precipitation data merging. With\nthe rapid advancements in computational capabilities and the escalating volume\nand diversity of earth observational data, Deep Learning (DL) models have\ngained considerable attention in geoscience. In this study, a deep learning\ntechnique, namely Long Short-term Memory (LSTM), was employed to merge a\nradar-based and a satellite-based Global Precipitation Measurement (GPM)\nprecipitation product Integrated Multi-Satellite Retrievals for GPM (IMERG)\nprecipitation product at hourly scale. The merged results are compared with the\nwidely used reanalysis precipitation product, Multi-Radar Multi-Sensor (MRMS),\nand assessed against gauge observational data from the California Data Exchange\nCenter (CDEC). The findings indicated that the LSTM-based merged precipitation\nnotably underestimated gauge observations and, at times, failed to provide\nmeaningful estimates, showing predominantly near-zero values. Relying solely on\nindividual Quantitative Precipitation Estimates (QPEs) without additional\nmeteorological input proved insufficient for generating reliable merged QPE.\nHowever, the merged results effectively captured the temporal trends of the\nobservations, outperforming MRMS in this aspect. This suggested that\nincorporating bias correction techniques could potentially enhance the accuracy\nof the merged product.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10135v2",
    "published_date": "2024-04-15 21:01:31 UTC",
    "updated_date": "2024-04-19 22:44:29 UTC"
  },
  {
    "arxiv_id": "2404.15834v1",
    "title": "FEDSTR: Money-In AI-Out | A Decentralized Marketplace for Federated Learning and LLM Training on the NOSTR Protocol",
    "authors": [
      "Konstantinos E. Nikolakakis",
      "George Chantzialexiou",
      "Dionysis Kalogerias"
    ],
    "abstract": "The NOSTR is a communication protocol for the social web, based on the w3c\nwebsockets standard. Although it is still in its infancy, it is well known as a\nsocial media protocol, thousands of trusted users and multiple user interfaces,\noffering a unique experience and enormous capabilities. To name a few, the\nNOSTR applications include but are not limited to direct messaging, file\nsharing, audio/video streaming, collaborative writing, blogging and data\nprocessing through distributed AI directories. In this work, we propose an\napproach that builds upon the existing protocol structure with end goal a\ndecentralized marketplace for federated learning and LLM training. In this\nproposed design there are two parties: on one side there are customers who\nprovide a dataset that they want to use for training an AI model. On the other\nside, there are service providers, who receive (parts of) the dataset, train\nthe AI model, and for a payment as an exchange, they return the optimized AI\nmodel. The decentralized and censorship resistant features of the NOSTR enable\nthe possibility of designing a fair and open marketplace for training AI models\nand LLMs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.15834v1",
    "published_date": "2024-04-15 20:51:38 UTC",
    "updated_date": "2024-04-15 20:51:38 UTC"
  },
  {
    "arxiv_id": "2404.10102v2",
    "title": "Chinchilla Scaling: A replication attempt",
    "authors": [
      "Tamay Besiroglu",
      "Ege Erdil",
      "Matthew Barnett",
      "Josh You"
    ],
    "abstract": "Hoffmann et al. (2022) propose three methods for estimating a compute-optimal\nscaling law. We attempt to replicate their third estimation procedure, which\ninvolves fitting a parametric loss function to a reconstruction of data from\ntheir plots. We find that the reported estimates are inconsistent with their\nfirst two estimation methods, fail at fitting the extracted data, and report\nimplausibly narrow confidence intervals--intervals this narrow would require\nover 600,000 experiments, while they likely only ran fewer than 500. In\ncontrast, our rederivation of the scaling law using the third approach yields\nresults that are compatible with the findings from the first two estimation\nprocedures described by Hoffmann et al.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10102v2",
    "published_date": "2024-04-15 19:19:56 UTC",
    "updated_date": "2024-05-15 00:57:23 UTC"
  },
  {
    "arxiv_id": "2404.10097v1",
    "title": "LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model",
    "authors": [
      "Amit Tewari"
    ],
    "abstract": "A contract is a type of legal document commonly used in organizations.\nContract review is an integral and repetitive process to avoid business risk\nand liability. Contract analysis requires the identification and classification\nof key provisions and paragraphs within an agreement. Identification and\nvalidation of contract clauses can be a time-consuming and challenging task\ndemanding the services of trained and expensive lawyers, paralegals or other\nlegal assistants. Classification of legal provisions in contracts using\nartificial intelligence and natural language processing is complex due to the\nrequirement of domain-specialized legal language for model training and the\nscarcity of sufficient labeled data in the legal domain. Using general-purpose\nmodels is not effective in this context due to the use of specialized legal\nvocabulary in contracts which may not be recognized by a general model. To\naddress this problem, we propose the use of a pre-trained large language model\nwhich is subsequently calibrated on legal taxonomy. We propose LegalPro-BERT, a\nBERT transformer architecture model that we fine-tune to efficiently handle\nclassification task for legal provisions. We conducted experiments to measure\nand compare metrics with current benchmark results. We found that LegalPro-BERT\noutperforms the previous benchmark used for comparison in this research.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10097v1",
    "published_date": "2024-04-15 19:08:48 UTC",
    "updated_date": "2024-04-15 19:08:48 UTC"
  },
  {
    "arxiv_id": "2404.10096v2",
    "title": "Vision Augmentation Prediction Autoencoder with Attention Design (VAPAAD)",
    "authors": [
      "Yiqiao Yin"
    ],
    "abstract": "Recent advancements in sequence prediction have significantly improved the\naccuracy of video data interpretation; however, existing models often overlook\nthe potential of attention-based mechanisms for next-frame prediction. This\nstudy introduces the Vision Augmentation Prediction Autoencoder with Attention\nDesign (VAPAAD), an innovative approach that integrates attention mechanisms\ninto sequence prediction, enabling nuanced analysis and understanding of\ntemporal dynamics in video sequences. Utilizing the Moving MNIST dataset, we\ndemonstrate VAPAAD's robust performance and superior handling of complex\ntemporal data compared to traditional methods. VAPAAD combines data\naugmentation, ConvLSTM2D layers, and a custom-built self-attention mechanism to\neffectively focus on salient features within a sequence, enhancing predictive\naccuracy and context-aware analysis. This methodology not only adheres to human\ncognitive processes during video interpretation but also addresses limitations\nin conventional models, which often struggle with the variability inherent in\nvideo sequences. The experimental results confirm that VAPAAD outperforms\nexisting models, especially in integrating attention mechanisms, which\nsignificantly improve predictive performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10096v2",
    "published_date": "2024-04-15 19:06:58 UTC",
    "updated_date": "2024-04-17 02:02:33 UTC"
  },
  {
    "arxiv_id": "2404.10054v1",
    "title": "AIGeN: An Adversarial Approach for Instruction Generation in VLN",
    "authors": [
      "Niyati Rawal",
      "Roberto Bigazzi",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "In the last few years, the research interest in Vision-and-Language\nNavigation (VLN) has grown significantly. VLN is a challenging task that\ninvolves an agent following human instructions and navigating in a previously\nunknown environment to reach a specified goal. Recent work in literature\nfocuses on different ways to augment the available datasets of instructions for\nimproving navigation performance by exploiting synthetic training data. In this\nwork, we propose AIGeN, a novel architecture inspired by Generative Adversarial\nNetworks (GANs) that produces meaningful and well-formed synthetic instructions\nto improve navigation agents' performance. The model is composed of a\nTransformer decoder (GPT-2) and a Transformer encoder (BERT). During the\ntraining phase, the decoder generates sentences for a sequence of images\ndescribing the agent's path to a particular point while the encoder\ndiscriminates between real and fake instructions. Experimentally, we evaluate\nthe quality of the generated instructions and perform extensive ablation\nstudies. Additionally, we generate synthetic instructions for 217K trajectories\nusing AIGeN on Habitat-Matterport 3D Dataset (HM3D) and show an improvement in\nthe performance of an off-the-shelf VLN method. The validation analysis of our\nproposal is conducted on REVERIE and R2R and highlights the promising aspects\nof our proposal, achieving state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to 7th Multimodal Learning and Applications Workshop (MULA\n  2024) at the IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10054v1",
    "published_date": "2024-04-15 18:00:30 UTC",
    "updated_date": "2024-04-15 18:00:30 UTC"
  },
  {
    "arxiv_id": "2404.09995v2",
    "title": "Taming Latent Diffusion Model for Neural Radiance Field Inpainting",
    "authors": [
      "Chieh Hubert Lin",
      "Changil Kim",
      "Jia-Bin Huang",
      "Qinbo Li",
      "Chih-Yao Ma",
      "Johannes Kopf",
      "Ming-Hsuan Yang",
      "Hung-Yu Tseng"
    ],
    "abstract": "Neural Radiance Field (NeRF) is a representation for 3D reconstruction from\nmulti-view images. Despite some recent work showing preliminary success in\nediting a reconstructed NeRF with diffusion prior, they remain struggling to\nsynthesize reasonable geometry in completely uncovered regions. One major\nreason is the high diversity of synthetic contents from the diffusion model,\nwhich hinders the radiance field from converging to a crisp and deterministic\ngeometry. Moreover, applying latent diffusion models on real data often yields\na textural shift incoherent to the image condition due to auto-encoding errors.\nThese two problems are further reinforced with the use of pixel-distance\nlosses. To address these issues, we propose tempering the diffusion model's\nstochasticity with per-scene customization and mitigating the textural shift\nwith masked adversarial training. During the analyses, we also found the\ncommonly used pixel and perceptual losses are harmful in the NeRF inpainting\ntask. Through rigorous experiments, our framework yields state-of-the-art NeRF\ninpainting results on various real-world scenes. Project page:\nhttps://hubert0527.github.io/MALD-NeRF",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024. Project page:\n  https://hubert0527.github.io/MALD-NeRF",
    "pdf_url": "http://arxiv.org/pdf/2404.09995v2",
    "published_date": "2024-04-15 17:59:57 UTC",
    "updated_date": "2024-11-13 00:41:01 UTC"
  },
  {
    "arxiv_id": "2404.09992v1",
    "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents",
    "authors": [
      "Ziniu Zhang",
      "Shulin Tian",
      "Liangyu Chen",
      "Ziwei Liu"
    ],
    "abstract": "Autonomous embodied agents live on an Internet of multimedia websites. Can\nthey hop around multimodal websites to complete complex user tasks? Existing\nbenchmarks fail to assess them in a realistic, evolving environment for their\nembodiment across websites. To answer this question, we present MMInA, a\nmultihop and multimodal benchmark to evaluate the embodied agents for\ncompositional Internet tasks, with several appealing properties: 1) Evolving\nreal-world multimodal websites. Our benchmark uniquely operates on evolving\nreal-world websites, ensuring a high degree of realism and applicability to\nnatural user tasks. Our data includes 1,050 human-written tasks covering\nvarious domains such as shopping and travel, with each task requiring the agent\nto autonomously extract multimodal information from web pages as observations;\n2) Multihop web browsing. Our dataset features naturally compositional tasks\nthat require information from or actions on multiple websites to solve, to\nassess long-range reasoning capabilities on web tasks; 3) Holistic evaluation.\nWe propose a novel protocol for evaluating an agent's progress in completing\nmultihop tasks. We experiment with both standalone (multimodal) language models\nand heuristic-based web agents. Extensive experiments demonstrate that while\nlong-chain multihop web tasks are easy for humans, they remain challenging for\nstate-of-the-art web agents. We identify that agents are more likely to fail on\nthe early hops when solving tasks of more hops, which results in lower task\nsuccess rates. To address this issue, we propose a simple memory augmentation\napproach replaying past action trajectories to reflect. Our method\nsignificantly improved both the single-hop and multihop web browsing abilities\nof agents. See our code and data at https://mmina.cliangyu.com",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09992v1",
    "published_date": "2024-04-15 17:59:50 UTC",
    "updated_date": "2024-04-15 17:59:50 UTC"
  },
  {
    "arxiv_id": "2404.09990v1",
    "title": "HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing",
    "authors": [
      "Mude Hui",
      "Siwei Yang",
      "Bingchen Zhao",
      "Yichun Shi",
      "Heng Wang",
      "Peng Wang",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "abstract": "This study introduces HQ-Edit, a high-quality instruction-based image editing\ndataset with around 200,000 edits. Unlike prior approaches relying on attribute\nguidance or human feedback on building datasets, we devise a scalable data\ncollection pipeline leveraging advanced foundation models, namely GPT-4V and\nDALL-E 3. To ensure its high quality, diverse examples are first collected\nonline, expanded, and then used to create high-quality diptychs featuring input\nand output images with detailed text prompts, followed by precise alignment\nensured through post-processing. In addition, we propose two evaluation\nmetrics, Alignment and Coherence, to quantitatively assess the quality of image\nedit pairs using GPT-4V. HQ-Edits high-resolution images, rich in detail and\naccompanied by comprehensive editing prompts, substantially enhance the\ncapabilities of existing image editing models. For example, an HQ-Edit\nfinetuned InstructPix2Pix can attain state-of-the-art image editing\nperformance, even surpassing those models fine-tuned with human-annotated data.\nThe project page is https://thefllood.github.io/HQEdit_web.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://thefllood.github.io/HQEdit_web",
    "pdf_url": "http://arxiv.org/pdf/2404.09990v1",
    "published_date": "2024-04-15 17:59:31 UTC",
    "updated_date": "2024-04-15 17:59:31 UTC"
  },
  {
    "arxiv_id": "2404.12404v4",
    "title": "EPIC: Effective Prompting for Imbalanced-Class Data Synthesis in Tabular Data Classification via Large Language Models",
    "authors": [
      "Jinhee Kim",
      "Taesung Kim",
      "Jaegul Choo"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable in-context learning\ncapabilities across diverse applications. In this work, we explore the\neffectiveness of LLMs for generating realistic synthetic tabular data,\nidentifying key prompt design elements to optimize performance. We introduce\nEPIC, a novel approach that leverages balanced, grouped data samples and\nconsistent formatting with unique variable mapping to guide LLMs in generating\naccurate synthetic data across all classes, even for imbalanced datasets.\nEvaluations on real-world datasets show that EPIC achieves state-of-the-art\nmachine learning classification performance, significantly improving generation\nefficiency. These findings highlight the effectiveness of EPIC for synthetic\ntabular data generation, particularly in addressing class imbalance. Our source\ncode for our work is available at:\nhttps://seharanul17.github.io/project-synthetic-tabular-llm/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.12404v4",
    "published_date": "2024-04-15 17:49:16 UTC",
    "updated_date": "2025-01-14 01:41:21 UTC"
  },
  {
    "arxiv_id": "2404.09967v2",
    "title": "Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model",
    "authors": [
      "Han Lin",
      "Jaemin Cho",
      "Abhay Zala",
      "Mohit Bansal"
    ],
    "abstract": "ControlNets are widely used for adding spatial control to text-to-image\ndiffusion models with different conditions, such as depth maps,\nscribbles/sketches, and human poses. However, when it comes to controllable\nvideo generation, ControlNets cannot be directly integrated into new backbones\ndue to feature space mismatches, and training ControlNets for new backbones can\nbe a significant burden for many users. Furthermore, applying ControlNets\nindependently to different frames cannot effectively maintain object temporal\nconsistency. To address these challenges, we introduce Ctrl-Adapter, an\nefficient and versatile framework that adds diverse controls to any image/video\ndiffusion model through the adaptation of pretrained ControlNets. Ctrl-Adapter\noffers strong and diverse capabilities, including image and video control,\nsparse-frame video control, fine-grained patch-level multi-condition control\n(via an MoE router), zero-shot adaptation to unseen conditions, and supports a\nvariety of downstream tasks beyond spatial control, including video editing,\nvideo style transfer, and text-guided motion control. With six diverse\nU-Net/DiT-based image/video diffusion models (SDXL, PixArt-$\\alpha$, I2VGen-XL,\nSVD, Latte, Hotshot-XL), Ctrl-Adapter matches the performance of pretrained\nControlNets on COCO and achieves the state-of-the-art on DAVIS 2017 with\nsignificantly lower computation (< 10 GPU hours).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "First two authors contributed equally; Project page:\n  https://ctrl-adapter.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.09967v2",
    "published_date": "2024-04-15 17:45:36 UTC",
    "updated_date": "2024-05-24 16:29:38 UTC"
  },
  {
    "arxiv_id": "2404.09956v4",
    "title": "Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization",
    "authors": [
      "Navonil Majumder",
      "Chia-Yu Hung",
      "Deepanway Ghosal",
      "Wei-Ning Hsu",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "abstract": "Generative multimodal content is increasingly prevalent in much of the\ncontent creation arena, as it has the potential to allow artists and media\npersonnel to create pre-production mockups by quickly bringing their ideas to\nlife. The generation of audio from text prompts is an important aspect of such\nprocesses in the music and film industry. Many of the recent diffusion-based\ntext-to-audio models focus on training increasingly sophisticated diffusion\nmodels on a large set of datasets of prompt-audio pairs. These models do not\nexplicitly focus on the presence of concepts or events and their temporal\nordering in the output audio with respect to the input prompt. Our hypothesis\nis focusing on how these aspects of audio generation could improve audio\ngeneration performance in the presence of limited data. As such, in this work,\nusing an existing text-to-audio model Tango, we synthetically create a\npreference dataset where each prompt has a winner audio output and some loser\naudio outputs for the diffusion model to learn from. The loser outputs, in\ntheory, have some concepts from the prompt missing or in an incorrect order. We\nfine-tune the publicly available Tango text-to-audio model using diffusion-DPO\n(direct preference optimization) loss on our preference dataset and show that\nit leads to improved audio output over Tango and AudioLDM2, in terms of both\nautomatic- and manual-evaluation metrics.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09956v4",
    "published_date": "2024-04-15 17:31:22 UTC",
    "updated_date": "2024-07-17 16:17:50 UTC"
  },
  {
    "arxiv_id": "2404.09946v1",
    "title": "A Note on Loss Functions and Error Compounding in Model-based Reinforcement Learning",
    "authors": [
      "Nan Jiang"
    ],
    "abstract": "This note clarifies some confusions (and perhaps throws out more) around\nmodel-based reinforcement learning and their theoretical understanding in the\ncontext of deep RL. Main topics of discussion are (1) how to reconcile\nmodel-based RL's bad empirical reputation on error compounding with its\nsuperior theoretical properties, and (2) the limitations of empirically popular\nlosses. For the latter, concrete counterexamples for the \"MuZero loss\" are\nconstructed to show that it not only fails in stochastic environments, but also\nsuffers exponential sample complexity in deterministic environments when data\nprovides sufficient coverage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09946v1",
    "published_date": "2024-04-15 17:15:18 UTC",
    "updated_date": "2024-04-15 17:15:18 UTC"
  },
  {
    "arxiv_id": "2404.09941v1",
    "title": "Evolving Interpretable Visual Classifiers with Large Language Models",
    "authors": [
      "Mia Chiquier",
      "Utkarsh Mall",
      "Carl Vondrick"
    ],
    "abstract": "Multimodal pre-trained models, such as CLIP, are popular for zero-shot\nclassification due to their open-vocabulary flexibility and high performance.\nHowever, vision-language models, which compute similarity scores between images\nand class labels, are largely black-box, with limited interpretability, risk\nfor bias, and inability to discover new visual concepts not written down.\nMoreover, in practical settings, the vocabulary for class names and attributes\nof specialized concepts will not be known, preventing these methods from\nperforming well on images uncommon in large-scale vision-language datasets. To\naddress these limitations, we present a novel method that discovers\ninterpretable yet discriminative sets of attributes for visual recognition. We\nintroduce an evolutionary search algorithm that uses a large language model and\nits in-context learning abilities to iteratively mutate a concept bottleneck of\nattributes for classification. Our method produces state-of-the-art,\ninterpretable fine-grained classifiers. We outperform the latest baselines by\n18.4% on five fine-grained iNaturalist datasets and by 22.2% on two KikiBouba\ndatasets, despite the baselines having access to privileged information about\nclass names.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09941v1",
    "published_date": "2024-04-15 17:09:53 UTC",
    "updated_date": "2024-04-15 17:09:53 UTC"
  },
  {
    "arxiv_id": "2404.09939v3",
    "title": "A Survey on Deep Learning for Theorem Proving",
    "authors": [
      "Zhaoyu Li",
      "Jialiang Sun",
      "Logan Murphy",
      "Qidong Su",
      "Zenan Li",
      "Xian Zhang",
      "Kaiyu Yang",
      "Xujie Si"
    ],
    "abstract": "Theorem proving is a fundamental aspect of mathematics, spanning from\ninformal reasoning in natural language to rigorous derivations in formal\nsystems. In recent years, the advancement of deep learning, especially the\nemergence of large language models, has sparked a notable surge of research\nexploring these techniques to enhance the process of theorem proving. This\npaper presents a comprehensive survey of deep learning for theorem proving by\noffering (i) a thorough review of existing approaches across various tasks such\nas autoformalization, premise selection, proofstep generation, and proof\nsearch; (ii) an extensive summary of curated datasets and strategies for\nsynthetic data generation; (iii) a detailed analysis of evaluation metrics and\nthe performance of state-of-the-art methods; and (iv) a critical discussion on\nthe persistent challenges and the promising avenues for future exploration. Our\nsurvey aims to serve as a foundational reference for deep learning approaches\nin theorem proving, inspiring and catalyzing further research endeavors in this\nrapidly growing field. A curated list of papers is available at\nhttps://github.com/zhaoyu-li/DL4TP.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09939v3",
    "published_date": "2024-04-15 17:07:55 UTC",
    "updated_date": "2024-08-22 03:56:45 UTC"
  },
  {
    "arxiv_id": "2404.09937v2",
    "title": "Compression Represents Intelligence Linearly",
    "authors": [
      "Yuzhen Huang",
      "Jinghan Zhang",
      "Zifei Shan",
      "Junxian He"
    ],
    "abstract": "There is a belief that learning to compress well will lead to intelligence.\nRecently, language modeling has been shown to be equivalent to compression,\nwhich offers a compelling rationale for the success of large language models\n(LLMs): the development of more advanced language models is essentially\nenhancing compression which facilitates intelligence. Despite such appealing\ndiscussions, little empirical evidence is present for the interplay between\ncompression and intelligence. In this work, we examine their relationship in\nthe context of LLMs, treating LLMs as data compressors. Given the abstract\nconcept of \"intelligence\", we adopt the average downstream benchmark scores as\na surrogate, specifically targeting intelligence related to knowledge and\ncommonsense, coding, and mathematical reasoning. Across 12 benchmarks, our\nstudy brings together 31 public LLMs that originate from diverse organizations.\nRemarkably, we find that LLMs' intelligence -- reflected by average benchmark\nscores -- almost linearly correlates with their ability to compress external\ntext corpora. These results provide concrete evidence supporting the belief\nthat superior compression indicates greater intelligence. Furthermore, our\nfindings suggest that compression efficiency, as an unsupervised metric derived\nfrom raw text corpora, serves as a reliable evaluation measure that is linearly\nassociated with the model capabilities. We open-source our compression datasets\nas well as our data collection pipelines to facilitate future researchers to\nassess compression properly.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024. Data and code are available at\n  https://github.com/hkust-nlp/llm-compression-intelligence",
    "pdf_url": "http://arxiv.org/pdf/2404.09937v2",
    "published_date": "2024-04-15 17:03:41 UTC",
    "updated_date": "2024-08-19 13:55:42 UTC"
  },
  {
    "arxiv_id": "2404.09932v2",
    "title": "Foundational Challenges in Assuring Alignment and Safety of Large Language Models",
    "authors": [
      "Usman Anwar",
      "Abulhair Saparov",
      "Javier Rando",
      "Daniel Paleka",
      "Miles Turpin",
      "Peter Hase",
      "Ekdeep Singh Lubana",
      "Erik Jenner",
      "Stephen Casper",
      "Oliver Sourbut",
      "Benjamin L. Edelman",
      "Zhaowei Zhang",
      "Mario Günther",
      "Anton Korinek",
      "Jose Hernandez-Orallo",
      "Lewis Hammond",
      "Eric Bigelow",
      "Alexander Pan",
      "Lauro Langosco",
      "Tomasz Korbak",
      "Heidi Zhang",
      "Ruiqi Zhong",
      "Seán Ó hÉigeartaigh",
      "Gabriel Recchia",
      "Giulio Corsi",
      "Alan Chan",
      "Markus Anderljung",
      "Lilian Edwards",
      "Aleksandar Petrov",
      "Christian Schroeder de Witt",
      "Sumeet Ramesh Motwan",
      "Yoshua Bengio",
      "Danqi Chen",
      "Philip H. S. Torr",
      "Samuel Albanie",
      "Tegan Maharaj",
      "Jakob Foerster",
      "Florian Tramer",
      "He He",
      "Atoosa Kasirzadeh",
      "Yejin Choi",
      "David Krueger"
    ],
    "abstract": "This work identifies 18 foundational challenges in assuring the alignment and\nsafety of large language models (LLMs). These challenges are organized into\nthree different categories: scientific understanding of LLMs, development and\ndeployment methods, and sociotechnical challenges. Based on the identified\nchallenges, we pose $200+$ concrete research questions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09932v2",
    "published_date": "2024-04-15 16:58:28 UTC",
    "updated_date": "2024-09-06 00:46:40 UTC"
  },
  {
    "arxiv_id": "2404.09931v1",
    "title": "Zero-shot detection of buildings in mobile LiDAR using Language Vision Model",
    "authors": [
      "June Moh Goo",
      "Zichao Zeng",
      "Jan Boehm"
    ],
    "abstract": "Recent advances have demonstrated that Language Vision Models (LVMs) surpass\nthe existing State-of-the-Art (SOTA) in two-dimensional (2D) computer vision\ntasks, motivating attempts to apply LVMs to three-dimensional (3D) data. While\nLVMs are efficient and effective in addressing various downstream 2D vision\ntasks without training, they face significant challenges when it comes to point\nclouds, a representative format for representing 3D data. It is more difficult\nto extract features from 3D data and there are challenges due to large data\nsizes and the cost of the collection and labelling, resulting in a notably\nlimited availability of datasets. Moreover, constructing LVMs for point clouds\nis even more challenging due to the requirements for large amounts of data and\ntraining time. To address these issues, our research aims to 1) apply the\nGrounded SAM through Spherical Projection to transfer 3D to 2D, and 2)\nexperiment with synthetic data to evaluate its effectiveness in bridging the\ngap between synthetic and real-world data domains. Our approach exhibited high\nperformance with an accuracy of 0.96, an IoU of 0.85, precision of 0.92, recall\nof 0.91, and an F1 score of 0.92, confirming its potential. However, challenges\nsuch as occlusion problems and pixel-level overlaps of multi-label points\nduring spherical image generation remain to be addressed in future studies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 6 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2404.09931v1",
    "published_date": "2024-04-15 16:56:58 UTC",
    "updated_date": "2024-04-15 16:56:58 UTC"
  },
  {
    "arxiv_id": "2404.13076v1",
    "title": "LLM Evaluators Recognize and Favor Their Own Generations",
    "authors": [
      "Arjun Panickssery",
      "Samuel R. Bowman",
      "Shi Feng"
    ],
    "abstract": "Self-evaluation using large language models (LLMs) has proven valuable not\nonly in benchmarking but also methods like reward modeling, constitutional AI,\nand self-refinement. But new biases are introduced due to the same LLM acting\nas both the evaluator and the evaluatee. One such bias is self-preference,\nwhere an LLM evaluator scores its own outputs higher than others' while human\nannotators consider them of equal quality. But do LLMs actually recognize their\nown outputs when they give those texts higher scores, or is it just a\ncoincidence? In this paper, we investigate if self-recognition capability\ncontributes to self-preference. We discover that, out of the box, LLMs such as\nGPT-4 and Llama 2 have non-trivial accuracy at distinguishing themselves from\nother LLMs and humans. By fine-tuning LLMs, we discover a linear correlation\nbetween self-recognition capability and the strength of self-preference bias;\nusing controlled experiments, we show that the causal explanation resists\nstraightforward confounders. We discuss how self-recognition can interfere with\nunbiased evaluations and AI safety more generally.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13076v1",
    "published_date": "2024-04-15 16:49:59 UTC",
    "updated_date": "2024-04-15 16:49:59 UTC"
  },
  {
    "arxiv_id": "2404.09921v1",
    "title": "Zero-shot Building Age Classification from Facade Image Using GPT-4",
    "authors": [
      "Zichao Zeng",
      "June Moh Goo",
      "Xinglei Wang",
      "Bin Chi",
      "Meihui Wang",
      "Jan Boehm"
    ],
    "abstract": "A building's age of construction is crucial for supporting many geospatial\napplications. Much current research focuses on estimating building age from\nfacade images using deep learning. However, building an accurate deep learning\nmodel requires a considerable amount of labelled training data, and the trained\nmodels often have geographical constraints. Recently, large pre-trained vision\nlanguage models (VLMs) such as GPT-4 Vision, which demonstrate significant\ngeneralisation capabilities, have emerged as potential training-free tools for\ndealing with specific vision tasks, but their applicability and reliability for\nbuilding information remain unexplored. In this study, a zero-shot building age\nclassifier for facade images is developed using prompts that include logical\ninstructions. Taking London as a test case, we introduce a new dataset,\nFI-London, comprising facade images and building age epochs. Although the\ntraining-free classifier achieved a modest accuracy of 39.69%, the mean\nabsolute error of 0.85 decades indicates that the model can predict building\nage epochs successfully albeit with a small bias. The ensuing discussion\nreveals that the classifier struggles to predict the age of very old buildings\nand is challenged by fine-grained predictions within 2 decades. Overall, the\nclassifier utilising GPT-4 Vision is capable of predicting the rough age epoch\nof a building from a single facade image without any training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09921v1",
    "published_date": "2024-04-15 16:47:22 UTC",
    "updated_date": "2024-04-15 16:47:22 UTC"
  },
  {
    "arxiv_id": "2404.09897v1",
    "title": "Progressive Knowledge Graph Completion",
    "authors": [
      "Jiayi Li",
      "Ruilin Luo",
      "Jiaqi Sun",
      "Jing Xiao",
      "Yujiu Yang"
    ],
    "abstract": "Knowledge Graph Completion (KGC) has emerged as a promising solution to\naddress the issue of incompleteness within Knowledge Graphs (KGs). Traditional\nKGC research primarily centers on triple classification and link prediction.\nNevertheless, we contend that these tasks do not align well with real-world\nscenarios and merely serve as surrogate benchmarks. In this paper, we\ninvestigate three crucial processes relevant to real-world construction\nscenarios: (a) the verification process, which arises from the necessity and\nlimitations of human verifiers; (b) the mining process, which identifies the\nmost promising candidates for verification; and (c) the training process, which\nharnesses verified data for subsequent utilization; in order to achieve a\ntransition toward more realistic challenges. By integrating these three\nprocesses, we introduce the Progressive Knowledge Graph Completion (PKGC) task,\nwhich simulates the gradual completion of KGs in real-world scenarios.\nFurthermore, to expedite PKGC processing, we propose two acceleration modules:\nOptimized Top-$k$ algorithm and Semantic Validity Filter. These modules\nsignificantly enhance the efficiency of the mining procedure. Our experiments\ndemonstrate that performance in link prediction does not accurately reflect\nperformance in PKGC. A more in-depth analysis reveals the key factors\ninfluencing the results and provides potential directions for future research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.09897v1",
    "published_date": "2024-04-15 16:16:59 UTC",
    "updated_date": "2024-04-15 16:16:59 UTC"
  },
  {
    "arxiv_id": "2406.02557v1",
    "title": "EVAN: Evolutional Video Streaming Adaptation via Neural Representation",
    "authors": [
      "Mufan Liu",
      "Le Yang",
      "Yiling Xu",
      "Ye-kui Wang",
      "Jenq-Neng Hwang"
    ],
    "abstract": "Adaptive bitrate (ABR) using conventional codecs cannot further modify the\nbitrate once a decision has been made, exhibiting limited adaptation\ncapability. This may result in either overly conservative or overly aggressive\nbitrate selection, which could cause either inefficient utilization of the\nnetwork bandwidth or frequent re-buffering, respectively. Neural representation\nfor video (NeRV), which embeds the video content into neural network weights,\nallows video reconstruction with incomplete models. Specifically, the recovery\nof one frame can be achieved without relying on the decoding of adjacent\nframes. NeRV has the potential to provide high video reconstruction quality\nand, more importantly, pave the way for developing more flexible ABR strategies\nfor video transmission. In this work, a new framework, named Evolutional Video\nstreaming Adaptation via Neural representation (EVAN), which can adaptively\ntransmit NeRV models based on soft actor-critic (SAC) reinforcement learning,\nis proposed. EVAN is trained with a more exploitative strategy and utilizes\nprogressive playback to avoid re-buffering. Experiments showed that EVAN can\noutperform existing ABRs with 50% reduction in re-buffering and achieve nearly\n20% .",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "eess.IV",
    "comment": "accepted by ICME (conference)",
    "pdf_url": "http://arxiv.org/pdf/2406.02557v1",
    "published_date": "2024-04-15 16:08:18 UTC",
    "updated_date": "2024-04-15 16:08:18 UTC"
  },
  {
    "arxiv_id": "2405.00699v1",
    "title": "Direct Training Needs Regularisation: Anytime Optimal Inference Spiking Neural Network",
    "authors": [
      "Dengyu Wu",
      "Yi Qi",
      "Kaiwen Cai",
      "Gaojie Jin",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "abstract": "Spiking Neural Network (SNN) is acknowledged as the next generation of\nArtificial Neural Network (ANN) and hold great promise in effectively\nprocessing spatial-temporal information. However, the choice of timestep\nbecomes crucial as it significantly impacts the accuracy of the neural network\ntraining. Specifically, a smaller timestep indicates better performance in\nefficient computing, resulting in reduced latency and operations. While, using\na small timestep may lead to low accuracy due to insufficient information\npresentation with few spikes. This observation motivates us to develop an SNN\nthat is more reliable for adaptive timestep by introducing a novel\nregularisation technique, namely Spatial-Temporal Regulariser (STR). Our\napproach regulates the ratio between the strength of spikes and membrane\npotential at each timestep. This effectively balances spatial and temporal\nperformance during training, ultimately resulting in an Anytime Optimal\nInference (AOI) SNN. Through extensive experiments on frame-based and\nevent-based datasets, our method, in combination with cutoff based on softmax\noutput, achieves state-of-the-art performance in terms of both latency and\naccuracy. Notably, with STR and cutoff, SNN achieves 2.14 to 2.89 faster in\ninference compared to the pre-configured timestep with near-zero accuracy drop\nof 0.50% to 0.64% over the event-based datasets. Code available:\nhttps://github.com/Dengyu-Wu/AOI-SNN-Regularisation",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00699v1",
    "published_date": "2024-04-15 15:57:01 UTC",
    "updated_date": "2024-04-15 15:57:01 UTC"
  },
  {
    "arxiv_id": "2404.09889v3",
    "title": "Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval",
    "authors": [
      "Peter Baile Chen",
      "Yi Zhang",
      "Dan Roth"
    ],
    "abstract": "Retrieving relevant tables containing the necessary information to accurately\nanswer a given question over tables is critical to open-domain\nquestion-answering (QA) systems. Previous methods assume the answer to such a\nquestion can be found either in a single table or multiple tables identified\nthrough question decomposition or rewriting. However, neither of these\napproaches is sufficient, as many questions require retrieving multiple tables\nand joining them through a join plan that cannot be discerned from the user\nquery itself. If the join plan is not considered in the retrieval stage, the\nsubsequent steps of reasoning and answering based on those retrieved tables are\nlikely to be incorrect. To address this problem, we introduce a method that\nuncovers useful join relations for any query and database during table\nretrieval. We use a novel re-ranking method formulated as a mixed-integer\nprogram that considers not only table-query relevance but also table-table\nrelevance that requires inferring join relationships. Our method outperforms\nthe state-of-the-art approaches for table retrieval by up to 9.3% in F1 score\nand for end-to-end QA by up to 5.4% in accuracy.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "ACL 2024. Dataset and code are available at\n  https://peterbaile.github.io/jar",
    "pdf_url": "http://arxiv.org/pdf/2404.09889v3",
    "published_date": "2024-04-15 15:55:01 UTC",
    "updated_date": "2025-01-09 22:43:05 UTC"
  },
  {
    "arxiv_id": "2405.09553v1",
    "title": "Computer aided diagnosis system for Alzheimers disease using principal component analysis and machine learning based approaches",
    "authors": [
      "Lilia Lazli"
    ],
    "abstract": "Alzheimers disease (AD) is a severe neurological brain disorder. It is not\ncurable, but earlier detection can help improve symptoms in a great deal. The\nmachine learning based approaches are popular and well motivated models for\nmedical image processing tasks such as computer-aided diagnosis. These\ntechniques can improve the process for accurate diagnosis of AD. In this paper,\nwe investigate the performance of these techniques for AD detection and\nclassification using brain MRI and PET images from the OASIS database. The\nproposed system takes advantage of the artificial neural network and support\nvector machines as classifiers, and principal component analysis as a feature\nextraction technique. The results indicate that the combined scheme achieves\ngood accuracy and offers a significant advantage over the other approaches.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted for CIBB 2021: The 17th International Conference on\n  Computational Intelligence Methods for Bioinformatics and Biostatistics",
    "pdf_url": "http://arxiv.org/pdf/2405.09553v1",
    "published_date": "2024-04-15 15:49:11 UTC",
    "updated_date": "2024-04-15 15:49:11 UTC"
  },
  {
    "arxiv_id": "2404.09877v2",
    "title": "Synergising Human-like Responses and Machine Intelligence for Planning in Disaster Response",
    "authors": [
      "Savvas Papaioannou",
      "Panayiotis Kolios",
      "Christos G. Panayiotou",
      "Marios M. Polycarpou"
    ],
    "abstract": "In the rapidly changing environments of disaster response, planning and\ndecision-making for autonomous agents involve complex and interdependent\nchoices. Although recent advancements have improved traditional artificial\nintelligence (AI) approaches, they often struggle in such settings,\nparticularly when applied to agents operating outside their well-defined\ntraining parameters. To address these challenges, we propose an attention-based\ncognitive architecture inspired by Dual Process Theory (DPT). This framework\nintegrates, in an online fashion, rapid yet heuristic (human-like) responses\n(System 1) with the slow but optimized planning capabilities of machine\nintelligence (System 2). We illustrate how a supervisory controller can\ndynamically determine in real-time the engagement of either system to optimize\nmission objectives by assessing their performance across a number of distinct\nattributes. Evaluated for trajectory planning in dynamic environments, our\nframework demonstrates that this synergistic integration effectively manages\ncomplex tasks by optimizing multiple mission objectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2024 IEEE World Congress on Computational Intelligence (IEEE WCCI),\n  2024 International Joint Conference on Neural Networks (IJCNN)",
    "pdf_url": "http://arxiv.org/pdf/2404.09877v2",
    "published_date": "2024-04-15 15:47:08 UTC",
    "updated_date": "2024-09-18 10:19:38 UTC"
  },
  {
    "arxiv_id": "2404.12403v1",
    "title": "Multi-Objective Hardware Aware Neural Architecture Search using Hardware Cost Diversity",
    "authors": [
      "Nilotpal Sinha",
      "Peyman Rostami",
      "Abd El Rahman Shabayek",
      "Anis Kacem",
      "Djamila Aouada"
    ],
    "abstract": "Hardware-aware Neural Architecture Search approaches (HW-NAS) automate the\ndesign of deep learning architectures, tailored specifically to a given target\nhardware platform. Yet, these techniques demand substantial computational\nresources, primarily due to the expensive process of assessing the performance\nof identified architectures. To alleviate this problem, a recent direction in\nthe literature has employed representation similarity metric for efficiently\nevaluating architecture performance. Nonetheless, since it is inherently a\nsingle objective method, it requires multiple runs to identify the optimal\narchitecture set satisfying the diverse hardware cost constraints, thereby\nincreasing the search cost. Furthermore, simply converting the single objective\ninto a multi-objective approach results in an under-explored architectural\nsearch space. In this study, we propose a Multi-Objective method to address the\nHW-NAS problem, called MO-HDNAS, to identify the trade-off set of architectures\nin a single run with low computational cost. This is achieved by optimizing\nthree objectives: maximizing the representation similarity metric, minimizing\nhardware cost, and maximizing the hardware cost diversity. The third objective,\ni.e. hardware cost diversity, is used to facilitate a better exploration of the\narchitecture search space. Experimental results demonstrate the effectiveness\nof our proposed method in efficiently addressing the HW-NAS problem across six\nedge devices for the image classification task.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the CVPR 2024 Workshop, called \"Efficient Deep Learning\n  for Computer Vision (ECV)\"",
    "pdf_url": "http://arxiv.org/pdf/2404.12403v1",
    "published_date": "2024-04-15 15:32:58 UTC",
    "updated_date": "2024-04-15 15:32:58 UTC"
  },
  {
    "arxiv_id": "2407.01544v1",
    "title": "Decentralized Multi-Party Multi-Network AI for Global Deployment of 6G Wireless Systems",
    "authors": [
      "Merim Dzaferagic",
      "Marco Ruffini",
      "Nina Slamnik-Krijestorac",
      "Joao F. Santos",
      "Johann Marquez-Barja",
      "Christos Tranoris",
      "Spyros Denazis",
      "Thomas Kyriakakis",
      "Panagiotis Karafotis",
      "Luiz DaSilva",
      "Shashi Raj Pandey",
      "Junya Shiraishi",
      "Petar Popovski",
      "Soren Kejser Jensen",
      "Christian Thomsen",
      "Torben Bach Pedersen",
      "Holger Claussen",
      "Jinfeng Du",
      "Gil Zussman",
      "Tingjun Chen",
      "Yiran Chen",
      "Seshu Tirupathi",
      "Ivan Seskar",
      "Daniel Kilper"
    ],
    "abstract": "Multiple visions of 6G networks elicit Artificial Intelligence (AI) as a\ncentral, native element. When 6G systems are deployed at a large scale,\nend-to-end AI-based solutions will necessarily have to encompass both the radio\nand the fiber-optical domain. This paper introduces the Decentralized\nMulti-Party, Multi-Network AI (DMMAI) framework for integrating AI into 6G\nnetworks deployed at scale. DMMAI harmonizes AI-driven controls across diverse\nnetwork platforms and thus facilitates networks that autonomously configure,\nmonitor, and repair themselves. This is particularly crucial at the network\nedge, where advanced applications meet heightened functionality and security\ndemands. The radio/optical integration is vital due to the current\ncompartmentalization of AI research within these domains, which lacks a\ncomprehensive understanding of their interaction. Our approach explores\nmulti-network orchestration and AI control integration, filling a critical gap\nin standardized frameworks for AI-driven coordination in 6G networks. The DMMAI\nframework is a step towards a global standard for AI in 6G, aiming to establish\nreference use cases, data and model management methods, and benchmarking\nplatforms for future AI/ML solutions.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01544v1",
    "published_date": "2024-04-15 15:21:25 UTC",
    "updated_date": "2024-04-15 15:21:25 UTC"
  },
  {
    "arxiv_id": "2404.09857v2",
    "title": "Empowering Embodied Visual Tracking with Visual Foundation Models and Offline RL",
    "authors": [
      "Fangwei Zhong",
      "Kui Wu",
      "Hai Ci",
      "Churan Wang",
      "Hao Chen"
    ],
    "abstract": "Embodied visual tracking is to follow a target object in dynamic 3D\nenvironments using an agent's egocentric vision. This is a vital and\nchallenging skill for embodied agents. However, existing methods suffer from\ninefficient training and poor generalization. In this paper, we propose a novel\nframework that combines visual foundation models(VFM) and offline reinforcement\nlearning(offline RL) to empower embodied visual tracking. We use a pre-trained\nVFM, such as \"Tracking Anything\", to extract semantic segmentation masks with\ntext prompts. We then train a recurrent policy network with offline RL, e.g.,\nConservative Q-Learning, to learn from the collected demonstrations without\nonline interactions. To further improve the robustness and generalization of\nthe policy network, we also introduce a mask re-targeting mechanism and a\nmulti-level data collection strategy. In this way, we can train a robust policy\nwithin an hour on a consumer-level GPU, e.g., Nvidia RTX 3090. We evaluate our\nagent on several high-fidelity environments with challenging situations, such\nas distraction and occlusion. The results show that our agent outperforms\nstate-of-the-art methods in terms of sample efficiency, robustness to\ndistractors, and generalization to unseen scenarios and targets. We also\ndemonstrate the transferability of the learned agent from virtual environments\nto a real-world robot.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09857v2",
    "published_date": "2024-04-15 15:12:53 UTC",
    "updated_date": "2024-07-22 06:13:32 UTC"
  },
  {
    "arxiv_id": "2404.09848v2",
    "title": "HyperMono: A Monotonicity-aware Approach to Hyper-Relational Knowledge Representation",
    "authors": [
      "Zhiwei Hu",
      "Víctor Gutiérrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "abstract": "In a hyper-relational knowledge graph (HKG), each fact is composed of a main\ntriple associated with attribute-value qualifiers, which express additional\nfactual knowledge. The hyper-relational knowledge graph completion (HKGC) task\naims at inferring plausible missing links in a HKG. Most existing approaches to\nHKGC focus on enhancing the communication between qualifier pairs and main\ntriples, while overlooking two important properties that emerge from the\nmonotonicity of the hyper-relational graphs representation regime. Stage\nReasoning allows for a two-step reasoning process, facilitating the integration\nof coarse-grained inference results derived solely from main triples and\nfine-grained inference results obtained from hyper-relational facts with\nqualifiers. In the initial stage, coarse-grained results provide an upper bound\nfor correct predictions, which are subsequently refined in the fine-grained\nstep. More generally, Qualifier Monotonicity implies that by attaching more\nqualifier pairs to a main triple, we may only narrow down the answer set, but\nnever enlarge it. This paper proposes the HyperMono model for hyper-relational\nknowledge graph completion, which realizes stage reasoning and qualifier\nmonotonicity. To implement qualifier monotonicity HyperMono resorts to cone\nembeddings. Experiments on three real-world datasets with three different\nscenario conditions demonstrate the strong performance of HyperMono when\ncompared to the SoTA.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09848v2",
    "published_date": "2024-04-15 15:00:17 UTC",
    "updated_date": "2024-08-13 09:51:39 UTC"
  },
  {
    "arxiv_id": "2404.09833v1",
    "title": "Video2Game: Real-time, Interactive, Realistic and Browser-Compatible Environment from a Single Video",
    "authors": [
      "Hongchi Xia",
      "Zhi-Hao Lin",
      "Wei-Chiu Ma",
      "Shenlong Wang"
    ],
    "abstract": "Creating high-quality and interactive virtual environments, such as games and\nsimulators, often involves complex and costly manual modeling processes. In\nthis paper, we present Video2Game, a novel approach that automatically converts\nvideos of real-world scenes into realistic and interactive game environments.\nAt the heart of our system are three core components:(i) a neural radiance\nfields (NeRF) module that effectively captures the geometry and visual\nappearance of the scene; (ii) a mesh module that distills the knowledge from\nNeRF for faster rendering; and (iii) a physics module that models the\ninteractions and physical dynamics among the objects. By following the\ncarefully designed pipeline, one can construct an interactable and actionable\ndigital replica of the real world. We benchmark our system on both indoor and\nlarge-scale outdoor scenes. We show that we can not only produce\nhighly-realistic renderings in real-time, but also build interactive games on\ntop.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project page (with code): https://video2game.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.09833v1",
    "published_date": "2024-04-15 14:32:32 UTC",
    "updated_date": "2024-04-15 14:32:32 UTC"
  },
  {
    "arxiv_id": "2404.09830v1",
    "title": "Negation Triplet Extraction with Syntactic Dependency and Semantic Consistency",
    "authors": [
      "Yuchen Shi",
      "Deqing Yang",
      "Jingping Liu",
      "Yanghua Xiao",
      "Zongyu Wang",
      "Huimin Xu"
    ],
    "abstract": "Previous works of negation understanding mainly focus on negation cue\ndetection and scope resolution, without identifying negation subject which is\nalso significant to the downstream tasks. In this paper, we propose a new\nnegation triplet extraction (NTE) task which aims to extract negation subject\nalong with negation cue and scope. To achieve NTE, we devise a novel\nSyntax&Semantic-Enhanced Negation Extraction model, namely SSENE, which is\nbuilt based on a generative pretrained language model (PLM) {of Encoder-Decoder\narchitecture} with a multi-task learning framework. Specifically, the given\nsentence's syntactic dependency tree is incorporated into the PLM's encoder to\ndiscover the correlations between the negation subject, cue and scope.\nMoreover, the semantic consistency between the sentence and the extracted\ntriplet is ensured by an auxiliary task learning. Furthermore, we have\nconstructed a high-quality Chinese dataset NegComment based on the users'\nreviews from the real-world platform of Meituan, upon which our evaluations\nshow that SSENE achieves the best NTE performance compared to the baselines.\nOur ablation and case studies also demonstrate that incorporating the syntactic\ninformation helps the PLM's recognize the distant dependency between the\nsubject and cue, and the auxiliary task learning is helpful to extract the\nnegation triplets with more semantic consistency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09830v1",
    "published_date": "2024-04-15 14:28:33 UTC",
    "updated_date": "2024-04-15 14:28:33 UTC"
  },
  {
    "arxiv_id": "2404.09828v2",
    "title": "Interaction as Explanation: A User Interaction-based Method for Explaining Image Classification Models",
    "authors": [
      "Hyeonggeun Yun"
    ],
    "abstract": "In computer vision, explainable AI (xAI) methods seek to mitigate the\n'black-box' problem by making the decision-making process of deep learning\nmodels more interpretable and transparent. Traditional xAI methods concentrate\non visualizing input features that influence model predictions, providing\ninsights primarily suited for experts. In this work, we present an\ninteraction-based xAI method that enhances user comprehension of image\nclassification models through their interaction. Thus, we developed a web-based\nprototype allowing users to modify images via painting and erasing, thereby\nobserving changes in classification results. Our approach enables users to\ndiscern critical features influencing the model's decision-making process,\naligning their mental models with the model's logic. Experiments conducted with\nfive images demonstrate the potential of the method to reveal feature\nimportance through user interaction. Our work contributes a novel perspective\nto xAI by centering on end-user engagement and understanding, paving the way\nfor more intuitive and accessible explainability in AI systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "IJCAI 2024 (International Joint Conference on Artificial Intelligence\n  2024) Workshop on Explainable Artificial Intelligence (XAI)",
    "pdf_url": "http://arxiv.org/pdf/2404.09828v2",
    "published_date": "2024-04-15 14:26:00 UTC",
    "updated_date": "2024-08-14 09:11:33 UTC"
  },
  {
    "arxiv_id": "2404.09819v1",
    "title": "3D Face Tracking from 2D Video through Iterative Dense UV to Image Flow",
    "authors": [
      "Felix Taubner",
      "Prashant Raina",
      "Mathieu Tuli",
      "Eu Wern Teh",
      "Chul Lee",
      "Jinmiao Huang"
    ],
    "abstract": "When working with 3D facial data, improving fidelity and avoiding the uncanny\nvalley effect is critically dependent on accurate 3D facial performance\ncapture. Because such methods are expensive and due to the widespread\navailability of 2D videos, recent methods have focused on how to perform\nmonocular 3D face tracking. However, these methods often fall short in\ncapturing precise facial movements due to limitations in their network\narchitecture, training, and evaluation processes. Addressing these challenges,\nwe propose a novel face tracker, FlowFace, that introduces an innovative 2D\nalignment network for dense per-vertex alignment. Unlike prior work, FlowFace\nis trained on high-quality 3D scan annotations rather than weak supervision or\nsynthetic data. Our 3D model fitting module jointly fits a 3D face model from\none or many observations, integrating existing neutral shape priors for\nenhanced identity and expression disentanglement and per-vertex deformations\nfor detailed facial feature reconstruction. Additionally, we propose a novel\nmetric and benchmark for assessing tracking accuracy. Our method exhibits\nsuperior performance on both custom and publicly available benchmarks. We\nfurther validate the effectiveness of our tracker by generating high-quality 3D\ndata from 2D videos, which leads to performance gains on downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 25 figures, to be published in CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09819v1",
    "published_date": "2024-04-15 14:20:07 UTC",
    "updated_date": "2024-04-15 14:20:07 UTC"
  },
  {
    "arxiv_id": "2404.10031v1",
    "title": "Emergent Language Symbolic Autoencoder (ELSA) with Weak Supervision to Model Hierarchical Brain Networks",
    "authors": [
      "Ammar Ahmed Pallikonda Latheef",
      "Alberto Santamaria-Pang",
      "Craig K Jones",
      "Haris I Sair"
    ],
    "abstract": "Brain networks display a hierarchical organization, a complexity that poses a\nchallenge for existing deep learning models, often structured as flat\nclassifiers, leading to difficulties in interpretability and the 'black box'\nissue. To bridge this gap, we propose a novel architecture: a symbolic\nautoencoder informed by weak supervision and an Emergent Language (EL)\nframework. This model moves beyond traditional flat classifiers by producing\nhierarchical clusters and corresponding imagery, subsequently represented\nthrough symbolic sentences to improve the clinical interpretability of\nhierarchically organized data such as intrinsic brain networks, which can be\ncharacterized using resting-state fMRI images. Our innovation includes a\ngeneralized hierarchical loss function designed to ensure that both sentences\nand images accurately reflect the hierarchical structure of functional brain\nnetworks. This enables us to model functional brain networks from a broader\nperspective down to more granular details. Furthermore, we introduce a\nquantitative method to assess the hierarchical consistency of these symbolic\nrepresentations. Our qualitative analyses show that our model successfully\ngenerates hierarchically organized, clinically interpretable images, a finding\nsupported by our quantitative evaluations. We find that our best performing\nloss function leads to a hierarchical consistency of over 97% when identifying\nimages corresponding to brain networks. This approach not only advances the\ninterpretability of deep learning models in neuroimaging analysis but also\nrepresents a significant step towards modeling the intricate hierarchical\nnature of brain networks.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.10031v1",
    "published_date": "2024-04-15 13:51:05 UTC",
    "updated_date": "2024-04-15 13:51:05 UTC"
  },
  {
    "arxiv_id": "2406.15374v1",
    "title": "Hybrid Intelligence for Digital Humanities",
    "authors": [
      "Victor de Boer",
      "Lise Stork"
    ],
    "abstract": "In this paper, we explore the synergies between Digital Humanities (DH) as a\ndiscipline and Hybrid Intelligence (HI) as a research paradigm. In DH research,\nthe use of digital methods and specifically that of Artificial Intelligence is\nsubject to a set of requirements and constraints. We argue that these are\nwell-supported by the capabilities and goals of HI. Our contribution includes\nthe identification of five such DH requirements: Successful AI systems need to\nbe able to 1) collaborate with the (human) scholar; 2) support data criticism;\n3) support tool criticism; 4) be aware of and cater to various perspectives and\n5) support distant and close reading. We take the CARE principles of Hybrid\nIntelligence (collaborative, adaptive, responsible and explainable) as\ntheoretical framework and map these to the DH requirements. In this mapping, we\ninclude example research projects. We finally address how insights from DH can\nbe applied to HI and discuss open challenges for the combination of the two\ndisciplines.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Preprint for paper accepted for HHAI2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.15374v1",
    "published_date": "2024-04-15 13:30:47 UTC",
    "updated_date": "2024-04-15 13:30:47 UTC"
  },
  {
    "arxiv_id": "2404.09763v1",
    "title": "KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models",
    "authors": [
      "Avinash Anand",
      "Mohit Gupta",
      "Kritarth Prasad",
      "Ujjwal Goel",
      "Naman Lal",
      "Astha Verma",
      "Rajiv Ratn Shah"
    ],
    "abstract": "Citation Text Generation (CTG) is a task in natural language processing (NLP)\nthat aims to produce text that accurately cites or references a cited document\nwithin a source document. In CTG, the generated text draws upon contextual cues\nfrom both the source document and the cited paper, ensuring accurate and\nrelevant citation information is provided. Previous work in the field of\ncitation generation is mainly based on the text summarization of documents.\nFollowing this, this paper presents a framework, and a comparative study to\ndemonstrate the use of Large Language Models (LLMs) for the task of citation\ngeneration. Also, we have shown the improvement in the results of citation\ngeneration by incorporating the knowledge graph relations of the papers in the\nprompt for the LLM to better learn the relationship between the papers. To\nassess how well our model is performing, we have used a subset of standard\nS2ORC dataset, which only consists of computer science academic research papers\nin the English Language. Vicuna performs best for this task with 14.15 Meteor,\n12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and\nimproves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by\nincluding knowledge graphs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09763v1",
    "published_date": "2024-04-15 13:06:32 UTC",
    "updated_date": "2024-04-15 13:06:32 UTC"
  },
  {
    "arxiv_id": "2404.09760v1",
    "title": "Effective Reinforcement Learning Based on Structural Information Principles",
    "authors": [
      "Xianghua Zeng",
      "Hao Peng",
      "Dingli Su",
      "Angsheng Li"
    ],
    "abstract": "Although Reinforcement Learning (RL) algorithms acquire sequential behavioral\npatterns through interactions with the environment, their effectiveness in\nnoisy and high-dimensional scenarios typically relies on specific structural\npriors. In this paper, we propose a novel and general Structural Information\nprinciples-based framework for effective Decision-Making, namely SIDM,\napproached from an information-theoretic perspective. This paper presents a\nspecific unsupervised partitioning method that forms vertex communities in the\nstate and action spaces based on their feature similarities. An aggregation\nfunction, which utilizes structural entropy as the vertex weight, is devised\nwithin each community to obtain its embedding, thereby facilitating\nhierarchical state and action abstractions. By extracting abstract elements\nfrom historical trajectories, a directed, weighted, homogeneous transition\ngraph is constructed. The minimization of this graph's high-dimensional entropy\nleads to the generation of an optimal encoding tree. An innovative two-layer\nskill-based learning mechanism is introduced to compute the common path entropy\nof each state transition as its identified probability, thereby obviating the\nrequirement for expert knowledge. Moreover, SIDM can be flexibly incorporated\ninto various single-agent and multi-agent RL algorithms, enhancing their\nperformance. Finally, extensive evaluations on challenging benchmarks\ndemonstrate that, compared with SOTA baselines, our framework significantly and\nconsistently improves the policy's quality, stability, and efficiency up to\n32.70%, 88.26%, and 64.86%, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09760v1",
    "published_date": "2024-04-15 13:02:00 UTC",
    "updated_date": "2024-04-15 13:02:00 UTC"
  },
  {
    "arxiv_id": "2404.09752v1",
    "title": "Can We Break Free from Strong Data Augmentations in Self-Supervised Learning?",
    "authors": [
      "Shruthi Gowda",
      "Elahe Arani",
      "Bahram Zonooz"
    ],
    "abstract": "Self-supervised learning (SSL) has emerged as a promising solution for\naddressing the challenge of limited labeled data in deep neural networks\n(DNNs), offering scalability potential. However, the impact of design\ndependencies within the SSL framework remains insufficiently investigated. In\nthis study, we comprehensively explore SSL behavior across a spectrum of\naugmentations, revealing their crucial role in shaping SSL model performance\nand learning mechanisms. Leveraging these insights, we propose a novel learning\napproach that integrates prior knowledge, with the aim of curtailing the need\nfor extensive data augmentations and thereby amplifying the efficacy of learned\nrepresentations. Notably, our findings underscore that SSL models imbued with\nprior knowledge exhibit reduced texture bias, diminished reliance on shortcuts\nand augmentations, and improved robustness against both natural and adversarial\ncorruptions. These findings not only illuminate a new direction in SSL\nresearch, but also pave the way for enhancing DNN performance while\nconcurrently alleviating the imperative for intensive data augmentation,\nthereby enhancing scalability and real-world problem-solving capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09752v1",
    "published_date": "2024-04-15 12:53:48 UTC",
    "updated_date": "2024-04-15 12:53:48 UTC"
  },
  {
    "arxiv_id": "2404.09738v2",
    "title": "AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides",
    "authors": [
      "Kewei Li",
      "Yuqian Wu",
      "Yinheng Li",
      "Yutong Guo",
      "Yan Wang",
      "Yiyang Liang",
      "Yusi Fan",
      "Lan Huang",
      "Ruochi Zhang",
      "Fengfeng Zhou"
    ],
    "abstract": "Since the mechanism of action of drug molecules in the human body is\ndifficult to reproduce in the in vitro environment, it becomes difficult to\nreveal the causes of the activity cliff phenomenon of drug molecules. We found\nout the AC of small molecules has been extensively investigated but limited\nknowledge is accumulated about the AC phenomenon in peptides with canonical\namino acids. Understanding the mechanism of AC in canonical amino acids might\nhelp understand the one in drug molecules. This study introduces a quantitative\ndefinition and benchmarking framework AMPCliff for the AC phenomenon in\nantimicrobial peptides (AMPs) composed by canonical amino acids. A\ncomprehensive analysis of the existing AMP dataset reveals a significant\nprevalence of AC within AMPs. AMPCliff quantifies the activities of AMPs by the\nMIC, and defines 0.9 as the minimum threshold for the normalized BLOSUM62\nsimilarity score between a pair of aligned peptides with at least two-fold MIC\nchanges. This study establishes a benchmark dataset of paired AMPs in\nStaphylococcus aureus from the publicly available AMP dataset GRAMPA, and\nconducts a rigorous procedure to evaluate various AMP AC prediction models,\nincluding nine machine learning, four deep learning algorithms, four masked\nlanguage models, and four generative language models. Our analysis reveals that\nthese models are capable of detecting AMP AC events and the pre-trained protein\nlanguage model ESM2 demonstrates superior performance across the evaluations.\nThe predictive performance of AMP activity cliffs remains to be further\nimproved, considering that ESM2 with 33 layers only achieves the Spearman\ncorrelation coefficient 0.4669 for the regression task of the MIC values on the\nbenchmark dataset. Source code and additional resources are available at\nhttps://www.healthinformaticslab.org/supp/ or\nhttps://github.com/Kewei2023/AMPCliff-generation.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09738v2",
    "published_date": "2024-04-15 12:40:12 UTC",
    "updated_date": "2024-11-03 11:59:50 UTC"
  },
  {
    "arxiv_id": "2404.09722v1",
    "title": "VFLGAN: Vertical Federated Learning-based Generative Adversarial Network for Vertically Partitioned Data Publication",
    "authors": [
      "Xun Yuan",
      "Yang Yang",
      "Prosanta Gope",
      "Aryan Pasikhani",
      "Biplab Sikdar"
    ],
    "abstract": "In the current artificial intelligence (AI) era, the scale and quality of the\ndataset play a crucial role in training a high-quality AI model. However, good\ndata is not a free lunch and is always hard to access due to privacy\nregulations like the General Data Protection Regulation (GDPR). A potential\nsolution is to release a synthetic dataset with a similar distribution to that\nof the private dataset. Nevertheless, in some scenarios, it has been found that\nthe attributes needed to train an AI model belong to different parties, and\nthey cannot share the raw data for synthetic data publication due to privacy\nregulations. In PETS 2023, Xue et al. proposed the first generative adversary\nnetwork-based model, VertiGAN, for vertically partitioned data publication.\nHowever, after thoroughly investigating, we found that VertiGAN is less\neffective in preserving the correlation among the attributes of different\nparties. This article proposes a Vertical Federated Learning-based Generative\nAdversarial Network, VFLGAN, for vertically partitioned data publication to\naddress the above issues. Our experimental results show that compared with\nVertiGAN, VFLGAN significantly improves the quality of synthetic data. Taking\nthe MNIST dataset as an example, the quality of the synthetic dataset generated\nby VFLGAN is 3.2 times better than that generated by VertiGAN w.r.t. the\nFr\\'echet Distance. We also designed a more efficient and effective Gaussian\nmechanism for the proposed VFLGAN to provide the synthetic dataset with a\ndifferential privacy guarantee. On the other hand, differential privacy only\ngives the upper bound of the worst-case privacy guarantee. This article also\nproposes a practical auditing scheme that applies membership inference attacks\nto estimate privacy leakage through the synthetic dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09722v1",
    "published_date": "2024-04-15 12:25:41 UTC",
    "updated_date": "2024-04-15 12:25:41 UTC"
  },
  {
    "arxiv_id": "2404.09717v1",
    "title": "Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model",
    "authors": [
      "Hyunsoo Cho"
    ],
    "abstract": "Many recent studies endeavor to improve open-source language models through\nimitation learning, and re-training on the synthetic instruction data from\nstate-of-the-art proprietary models like ChatGPT and GPT-4. However, the innate\nnature of synthetic data inherently contains noisy data, giving rise to a\nsubstantial presence of low-quality data replete with erroneous responses, and\nflawed reasoning. Although we intuitively grasp the potential harm of noisy\ndata, we lack a quantitative understanding of its impact. To this end, this\npaper explores the correlation between the degree of noise and its impact on\nlanguage models through instruction tuning. We first introduce the\nFalsity-Controllable (FACO) dataset, which comprises pairs of true answers with\ncorresponding reasoning, as well as false pairs to manually control the falsity\nratio of the dataset.Through our extensive experiments, we found multiple\nintriguing findings of the correlation between the factuality of the dataset\nand instruction tuning: Specifically, we verified falsity of the instruction is\nhighly relevant to various benchmark scores. Moreover, when LLMs are trained\nwith false instructions, they learn to lie and generate fake unfaithful\nanswers, even though they know the correct answer for the user request.\nAdditionally, we noted that once the language model is trained with a dataset\ncontaminated by noise, restoring its original performance is possible, but it\nfailed to reach full performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review @ *ACL",
    "pdf_url": "http://arxiv.org/pdf/2404.09717v1",
    "published_date": "2024-04-15 12:20:09 UTC",
    "updated_date": "2024-04-15 12:20:09 UTC"
  },
  {
    "arxiv_id": "2404.09715v1",
    "title": "Higher Replay Ratio Empowers Sample-Efficient Multi-Agent Reinforcement Learning",
    "authors": [
      "Linjie Xu",
      "Zichuan Liu",
      "Alexander Dockhorn",
      "Diego Perez-Liebana",
      "Jinyu Wang",
      "Lei Song",
      "Jiang Bian"
    ],
    "abstract": "One of the notorious issues for Reinforcement Learning (RL) is poor sample\nefficiency. Compared to single agent RL, the sample efficiency for Multi-Agent\nReinforcement Learning (MARL) is more challenging because of its inherent\npartial observability, non-stationary training, and enormous strategy space.\nAlthough much effort has been devoted to developing new methods and enhancing\nsample efficiency, we look at the widely used episodic training mechanism. In\neach training step, tens of frames are collected, but only one gradient step is\nmade. We argue that this episodic training could be a source of poor sample\nefficiency. To better exploit the data already collected, we propose to\nincrease the frequency of the gradient updates per environment interaction\n(a.k.a. Replay Ratio or Update-To-Data ratio). To show its generality, we\nevaluate $3$ MARL methods on $6$ SMAC tasks. The empirical results validate\nthat a higher replay ratio significantly improves the sample efficiency for\nMARL algorithms. The codes to reimplement the results presented in this paper\nare open-sourced at https://anonymous.4open.science/r/rr_for_MARL-0D83/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09715v1",
    "published_date": "2024-04-15 12:18:09 UTC",
    "updated_date": "2024-04-15 12:18:09 UTC"
  },
  {
    "arxiv_id": "2404.09707v1",
    "title": "Adaptive Patching for High-resolution Image Segmentation with Transformers",
    "authors": [
      "Enzhi Zhang",
      "Isaac Lyngaas",
      "Peng Chen",
      "Xiao Wang",
      "Jun Igarashi",
      "Yuankai Huo",
      "Mohamed Wahib",
      "Masaharu Munetomo"
    ],
    "abstract": "Attention-based models are proliferating in the space of image analytics,\nincluding segmentation. The standard method of feeding images to transformer\nencoders is to divide the images into patches and then feed the patches to the\nmodel as a linear sequence of tokens. For high-resolution images, e.g.\nmicroscopic pathology images, the quadratic compute and memory cost prohibits\nthe use of an attention-based model, if we are to use smaller patch sizes that\nare favorable in segmentation. The solution is to either use custom complex\nmulti-resolution models or approximate attention schemes. We take inspiration\nfrom Adapative Mesh Refinement (AMR) methods in HPC by adaptively patching the\nimages, as a pre-processing step, based on the image details to reduce the\nnumber of patches being fed to the model, by orders of magnitude. This method\nhas a negligible overhead, and works seamlessly with any attention-based model,\ni.e. it is a pre-processing step that can be adopted by any attention-based\nmodel without friction. We demonstrate superior segmentation quality over SoTA\nsegmentation models for real-world pathology datasets while gaining a geomean\nspeedup of $6.9\\times$ for resolutions up to $64K^2$, on up to $2,048$ GPUs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09707v1",
    "published_date": "2024-04-15 12:06:00 UTC",
    "updated_date": "2024-04-15 12:06:00 UTC"
  },
  {
    "arxiv_id": "2404.09696v1",
    "title": "Are Large Language Models Reliable Argument Quality Annotators?",
    "authors": [
      "Nailia Mirzakhmedova",
      "Marcel Gohsen",
      "Chia Hao Chang",
      "Benno Stein"
    ],
    "abstract": "Evaluating the quality of arguments is a crucial aspect of any system\nleveraging argument mining. However, it is a challenge to obtain reliable and\nconsistent annotations regarding argument quality, as this usually requires\ndomain-specific expertise of the annotators. Even among experts, the assessment\nof argument quality is often inconsistent due to the inherent subjectivity of\nthis task. In this paper, we study the potential of using state-of-the-art\nlarge language models (LLMs) as proxies for argument quality annotators. To\nassess the capability of LLMs in this regard, we analyze the agreement between\nmodel, human expert, and human novice annotators based on an established\ntaxonomy of argument quality dimensions. Our findings highlight that LLMs can\nproduce consistent annotations, with a moderately high agreement with human\nexperts across most of the quality dimensions. Moreover, we show that using\nLLMs as additional annotators can significantly improve the agreement between\nannotators. These results suggest that LLMs can serve as a valuable tool for\nautomated argument quality assessment, thus streamlining and accelerating the\nevaluation of large argument datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.09696v1",
    "published_date": "2024-04-15 11:54:27 UTC",
    "updated_date": "2024-04-15 11:54:27 UTC"
  },
  {
    "arxiv_id": "2404.09695v1",
    "title": "LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models",
    "authors": [
      "Guangyan Li",
      "Yongqiang Tang",
      "Wensheng Zhang"
    ],
    "abstract": "Large language models (LLMs) show excellent performance in difficult tasks,\nbut they often require massive memories and computational resources. How to\nreduce the parameter scale of LLMs has become research hotspots. In this study,\nwe make an important observation that the multi-head self-attention (MHA)\nsub-layer of Transformer exhibits noticeable low-rank structure, while the\nfeed-forward network (FFN) sub-layer does not. With this regard, we design a\nmixed compression model, which organically combines Low-Rank matrix\napproximation And structured Pruning (LoRAP). For the MHA sub-layer, we propose\nan input activation weighted singular value decomposition method to strengthen\nthe low-rank characteristic. Furthermore, we discover that the weight matrices\nin MHA sub-layer have different low-rank degrees. Thus, a novel parameter\nallocation scheme according to the discrepancy of low-rank degrees is devised.\nFor the FFN sub-layer, we propose a gradient-free structured channel pruning\nmethod. During the pruning, we get an interesting finding that the least\nimportant 1% of parameter actually play a vital role in model performance.\nExtensive evaluations on zero-shot perplexity and zero-shot task classification\nindicate that our proposal is superior to previous structured compression\nrivals under multiple compression ratios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages,4 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.09695v1",
    "published_date": "2024-04-15 11:53:22 UTC",
    "updated_date": "2024-04-15 11:53:22 UTC"
  },
  {
    "arxiv_id": "2405.09552v2",
    "title": "ODFormer: Semantic Fundus Image Segmentation Using Transformer for Optic Nerve Head Detection",
    "authors": [
      "Jiayi Wang",
      "Yi-An Mao",
      "Xiaoyu Ma",
      "Sicen Guo",
      "Yuting Shao",
      "Xiao Lv",
      "Wenting Han",
      "Mark Christopher",
      "Linda M. Zangwill",
      "Yanlong Bi",
      "Rui Fan"
    ],
    "abstract": "Optic nerve head (ONH) detection has been a crucial area of study in\nophthalmology for years. However, the significant discrepancy between fundus\nimage datasets, each generated using a single type of fundus camera, poses\nchallenges to the generalizability of ONH detection approaches developed based\non semantic segmentation networks. Despite the numerous recent advancements in\ngeneral-purpose semantic segmentation methods using convolutional neural\nnetworks (CNNs) and Transformers, there is currently a lack of benchmarks for\nthese state-of-the-art (SoTA) networks specifically trained for ONH detection.\nTherefore, in this article, we make contributions from three key aspects:\nnetwork design, the publication of a dataset, and the establishment of a\ncomprehensive benchmark. Our newly developed ONH detection network, referred to\nas ODFormer, is based upon the Swin Transformer architecture and incorporates\ntwo novel components: a multi-scale context aggregator and a lightweight\nbidirectional feature recalibrator. Our published large-scale dataset, known as\nTongjiU-DROD, provides multi-resolution fundus images for each participant,\ncaptured using two distinct types of cameras. Our established benchmark\ninvolves three datasets: DRIONS-DB, DRISHTI-GS1, and TongjiU-DROD, created by\nresearchers from different countries and containing fundus images captured from\nparticipants of diverse races and ages. Extensive experimental results\ndemonstrate that our proposed ODFormer outperforms other state-of-the-art\n(SoTA) networks in terms of performance and generalizability. Our dataset and\nsource code are publicly available at mias.group/ODFormer.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.09552v2",
    "published_date": "2024-04-15 11:49:37 UTC",
    "updated_date": "2024-06-02 10:49:47 UTC"
  },
  {
    "arxiv_id": "2404.09690v1",
    "title": "Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration",
    "authors": [
      "Chenwei Lin",
      "Hanjia Lyu",
      "Jiebo Luo",
      "Xian Xu"
    ],
    "abstract": "The emergence of Large Multimodal Models (LMMs) marks a significant milestone\nin the development of artificial intelligence. Insurance, as a vast and complex\ndiscipline, involves a wide variety of data forms in its operational processes,\nincluding text, images, and videos, thereby giving rise to diverse multimodal\ntasks. Despite this, there has been limited systematic exploration of\nmultimodal tasks specific to insurance, nor a thorough investigation into how\nLMMs can address these challenges. In this paper, we explore GPT-4V's\ncapabilities in the insurance domain. We categorize multimodal tasks by\nfocusing primarily on visual aspects based on types of insurance (e.g., auto,\nhousehold/commercial property, health, and agricultural insurance) and\ninsurance stages (e.g., risk assessment, risk monitoring, and claims\nprocessing). Our experiment reveals that GPT-4V exhibits remarkable abilities\nin insurance-related tasks, demonstrating not only a robust understanding of\nmultimodal content in the insurance domain but also a comprehensive knowledge\nof insurance scenarios. However, there are notable shortcomings: GPT-4V\nstruggles with detailed risk rating and loss assessment, suffers from\nhallucination in image understanding, and shows variable support for different\nlanguages. Through this work, we aim to bridge the insurance domain with\ncutting-edge LMM technology, facilitate interdisciplinary exchange and\ndevelopment, and provide a foundation for the continued advancement and\nevolution of future research endeavors.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09690v1",
    "published_date": "2024-04-15 11:45:30 UTC",
    "updated_date": "2024-04-15 11:45:30 UTC"
  },
  {
    "arxiv_id": "2404.09687v1",
    "title": "Plus Strategies are Exponentially Slower for Planted Optima of Random Height",
    "authors": [
      "Johannes Lengler",
      "Leon Schiller",
      "Oliver Sieberling"
    ],
    "abstract": "We compare the $(1,\\lambda)$-EA and the $(1 + \\lambda)$-EA on the recently\nintroduced benchmark DisOM, which is the OneMax function with randomly planted\nlocal optima. Previous work showed that if all local optima have the same\nrelative height, then the plus strategy never loses more than a factor $O(n\\log\nn)$ compared to the comma strategy. Here we show that even small random\nfluctuations in the heights of the local optima have a devastating effect for\nthe plus strategy and lead to super-polynomial runtimes. On the other hand, due\nto their ability to escape local optima, comma strategies are unaffected by the\nheight of the local optima and remain efficient. Our results hold for a broad\nclass of possible distortions and show that the plus strategy, but not the\ncomma strategy, is generally deceived by sparse unstructured fluctuations of a\nsmooth landscape.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "math.PR"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09687v1",
    "published_date": "2024-04-15 11:37:47 UTC",
    "updated_date": "2024-04-15 11:37:47 UTC"
  },
  {
    "arxiv_id": "2404.09682v3",
    "title": "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation",
    "authors": [
      "Juhwan Choi",
      "Jungmin Yun",
      "Kyohoon Jin",
      "YoungBin Kim"
    ],
    "abstract": "The quality of the dataset is crucial for ensuring optimal performance and\nreliability of downstream task models. However, datasets often contain noisy\ndata inadvertently included during the construction process. Numerous attempts\nhave been made to correct this issue through human annotators. However, hiring\nand managing human annotators is expensive and time-consuming. As an\nalternative, recent studies are exploring the use of large language models\n(LLMs) for data annotation.\n  In this study, we present a case study that extends the application of\nLLM-based data annotation to enhance the quality of existing datasets through a\ncleansing strategy. Specifically, we leverage approaches such as\nchain-of-thought and majority voting to imitate human annotation and classify\nunrelated documents from the Multi-News dataset, which is widely used for the\nmulti-document summarization task. Through our proposed cleansing method, we\nintroduce an enhanced Multi-News+. By employing LLMs for data cleansing, we\ndemonstrate an efficient and effective approach to improving dataset quality\nwithout relying on expensive human annotation efforts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024: Camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2404.09682v3",
    "published_date": "2024-04-15 11:36:10 UTC",
    "updated_date": "2024-09-24 02:35:41 UTC"
  },
  {
    "arxiv_id": "2404.15354v2",
    "title": "Polynomial Selection in Spectral Graph Neural Networks: An Error-Sum of Function Slices Approach",
    "authors": [
      "Guoming Li",
      "Jian Yang",
      "Shangsong Liang",
      "Dongsheng Luo"
    ],
    "abstract": "Spectral graph neural networks are proposed to harness spectral information\ninherent in graph-structured data through the application of polynomial-defined\ngraph filters, recently achieving notable success in graph-based web\napplications. Existing studies reveal that various polynomial choices greatly\nimpact spectral GNN performance, underscoring the importance of polynomial\nselection. However, this selection process remains a critical and unresolved\nchallenge. Although prior work suggests a connection between the approximation\ncapabilities of polynomials and the efficacy of spectral GNNs, there is a lack\nof theoretical insights into this relationship, rendering polynomial selection\na largely heuristic process.\n  To address the issue, this paper examines polynomial selection from an\nerror-sum of function slices perspective. Inspired by the conventional signal\ndecomposition, we represent graph filters as a sum of disjoint function slices.\nBuilding on this, we then bridge the polynomial capability and spectral GNN\nefficacy by proving that the construction error of graph convolution layer is\nbounded by the sum of polynomial approximation errors on function slices. This\nresult leads us to develop an advanced filter based on trigonometric\npolynomials, a widely adopted option for approximating narrow signal slices.\nThe proposed filter remains provable parameter efficiency, with a novel\nTaylor-based parameter decomposition that achieves streamlined, effective\nimplementation. With this foundation, we propose TFGNN, a scalable spectral GNN\noperating in a decoupled paradigm. We validate the efficacy of TFGNN via\nbenchmark node classification tasks, along with an example graph anomaly\ndetection application to show its practical utility.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted in ACM The Web Conference 2025, WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.15354v2",
    "published_date": "2024-04-15 11:35:32 UTC",
    "updated_date": "2025-01-24 13:57:49 UTC"
  },
  {
    "arxiv_id": "2404.13074v1",
    "title": "Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey",
    "authors": [
      "Amogh Mannekote"
    ],
    "abstract": "Compositional generalization is the ability of a model to generalize to\ncomplex, previously unseen types of combinations of entities from just having\nseen the primitives. This type of generalization is particularly relevant to\nthe semantic parsing community for applications such as task-oriented dialogue,\ntext-to-SQL parsing, and information retrieval, as they can harbor infinite\ncomplexity. Despite the success of large language models (LLMs) in a wide range\nof NLP tasks, unlocking perfect compositional generalization still remains one\nof the few last unsolved frontiers. The past few years has seen a surge of\ninterest in works that explore the limitations of, methods to improve, and\nevaluation metrics for compositional generalization capabilities of LLMs for\nsemantic parsing tasks. In this work, we present a literature survey geared at\nsynthesizing recent advances in analysis, methods, and evaluation schemes to\noffer a starting point for both practitioners and researchers in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13074v1",
    "published_date": "2024-04-15 10:44:58 UTC",
    "updated_date": "2024-04-15 10:44:58 UTC"
  },
  {
    "arxiv_id": "2404.15204v1",
    "title": "Towards a high-performance AI compiler with upstream MLIR",
    "authors": [
      "Renato Golin",
      "Lorenzo Chelini",
      "Adam Siemieniuk",
      "Kavitha Madhu",
      "Niranjan Hasabnis",
      "Hans Pabst",
      "Evangelos Georganas",
      "Alexander Heinecke"
    ],
    "abstract": "This work proposes a compilation flow using open-source compiler passes to\nbuild a framework to achieve ninja performance from a generic linear algebra\nhigh-level abstraction. We demonstrate this flow with a proof-of-concept MLIR\nproject that uses input IR in Linalg-on-Tensor from TensorFlow and PyTorch,\nperforms cache-level optimizations and lowering to micro-kernels for efficient\nvectorization, achieving over 90% of the performance of ninja-written\nequivalent programs. The contributions of this work include: (1) Packing\nprimitives on the tensor dialect and passes for cache-aware distribution of\ntensors (single and multi-core) and type-aware instructions (VNNI, BFDOT,\nBFMMLA), including propagation of shapes across the entire function; (2) A\nlinear algebra pipeline, including tile, fuse and bufferization strategies to\nget model-level IR into hardware friendly tile calls; (3) A mechanism for\nmicro-kernel lowering to an open source library that supports various CPUs.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.AR",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.PL",
    "comment": "13 pages, 8 figures, presented at CGO C4ML 2024 & MLIR Workshop\n  EuroLLVM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15204v1",
    "published_date": "2024-04-15 10:35:50 UTC",
    "updated_date": "2024-04-15 10:35:50 UTC"
  },
  {
    "arxiv_id": "2404.09652v1",
    "title": "Monitoring Second-Order Hyperproperties",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner",
      "Hadar Frenkel",
      "Niklas Metzger"
    ],
    "abstract": "Hyperproperties express the relationship between multiple executions of a\nsystem. This is needed in many AI-related fields, such as knowledge\nrepresentation and planning, to capture system properties related to knowledge,\ninformation flow, and privacy. In this paper, we study the monitoring of\ncomplex hyperproperties at runtime. Previous work in this area has either\nfocused on the simpler problem of monitoring trace properties (which are sets\nof traces, while hyperproperties are sets of sets of traces) or on monitoring\nfirst-order hyperproperties, which are expressible in temporal logics with\nfirst-order quantification over traces, such as HyperLTL. We present the first\nmonitoring algorithm for the much more expressive class of second-order\nhyperproperties. Second-order hyperproperties include system properties like\ncommon knowledge, which cannot be expressed in first-order logics like\nHyperLTL.\n  We introduce Hyper$^2$LTL$_f$, a temporal logic over finite traces that\nallows for second-order quantification over sets of traces. We study the\nmonitoring problem in two fundamental execution models: (1) the parallel model,\nwhere a fixed number of traces is monitored in parallel, and (2) the sequential\nmodel, where an unbounded number of traces is observed sequentially, one trace\nafter the other. For the parallel model, we show that the monitoring of the\nsecond-order hyperproperties of Hyper$^2$LTL$_f$ can be reduced to monitoring\nfirst-order hyperproperties. For the sequential model, we present a monitoring\nalgorithm that handles second-order quantification efficiently, exploiting\noptimizations based on the monotonicity of subformulas, graph-based storing of\nexecutions, and fixpoint hashing. We present experimental results from a range\nof benchmarks, including examples from common knowledge and planning.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LO",
    "comment": "AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09652v1",
    "published_date": "2024-04-15 10:33:39 UTC",
    "updated_date": "2024-04-15 10:33:39 UTC"
  },
  {
    "arxiv_id": "2404.09636v3",
    "title": "All-in-one simulation-based inference",
    "authors": [
      "Manuel Gloeckler",
      "Michael Deistler",
      "Christian Weilbach",
      "Frank Wood",
      "Jakob H. Macke"
    ],
    "abstract": "Amortized Bayesian inference trains neural networks to solve stochastic\ninference problems using model simulations, thereby making it possible to\nrapidly perform Bayesian inference for any newly observed data. However,\ncurrent simulation-based amortized inference methods are simulation-hungry and\ninflexible: They require the specification of a fixed parametric prior,\nsimulator, and inference tasks ahead of time. Here, we present a new amortized\ninference method -- the Simformer -- which overcomes these limitations. By\ntraining a probabilistic diffusion model with transformer architectures, the\nSimformer outperforms current state-of-the-art amortized inference approaches\non benchmark tasks and is substantially more flexible: It can be applied to\nmodels with function-valued parameters, it can handle inference scenarios with\nmissing or unstructured data, and it can sample arbitrary conditionals of the\njoint distribution of parameters and data, including both posterior and\nlikelihood. We showcase the performance and flexibility of the Simformer on\nsimulators from ecology, epidemiology, and neuroscience, and demonstrate that\nit opens up new possibilities and application domains for amortized Bayesian\ninference on simulation-based models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in the proceedings of the 41st International\n  Conference on Machine Learning (ICML 2024), Vienna, Austria. PMLR 235, 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09636v3",
    "published_date": "2024-04-15 10:12:33 UTC",
    "updated_date": "2024-07-15 07:45:28 UTC"
  },
  {
    "arxiv_id": "2404.09631v1",
    "title": "Action Model Learning with Guarantees",
    "authors": [
      "Diego Aineto",
      "Enrico Scala"
    ],
    "abstract": "This paper studies the problem of action model learning with full\nobservability. Following the learning by search paradigm by Mitchell, we\ndevelop a theory for action model learning based on version spaces that\ninterprets the task as search for hypothesis that are consistent with the\nlearning examples. Our theoretical findings are instantiated in an online\nalgorithm that maintains a compact representation of all solutions of the\nproblem. Among these range of solutions, we bring attention to actions models\napproximating the actual transition system from below (sound models) and from\nabove (complete models). We show how to manipulate the output of our learning\nalgorithm to build deterministic and non-deterministic formulations of the\nsound and complete models and prove that, given enough examples, both\nformulations converge into the very same true model. Our experiments reveal\ntheir usefulness over a range of planning domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09631v1",
    "published_date": "2024-04-15 10:01:43 UTC",
    "updated_date": "2024-04-15 10:01:43 UTC"
  },
  {
    "arxiv_id": "2404.09625v1",
    "title": "Privacy-Preserving Intrusion Detection using Convolutional Neural Networks",
    "authors": [
      "Martin Kodys",
      "Zhongmin Dai",
      "Vrizlynn L. L. Thing"
    ],
    "abstract": "Privacy-preserving analytics is designed to protect valuable assets. A common\nservice provision involves the input data from the client and the model on the\nanalyst's side. The importance of the privacy preservation is fuelled by legal\nobligations and intellectual property concerns. We explore the use case of a\nmodel owner providing an analytic service on customer's private data. No\ninformation about the data shall be revealed to the analyst and no information\nabout the model shall be leaked to the customer. Current methods involve costs:\naccuracy deterioration and computational complexity. The complexity, in turn,\nresults in a longer processing time, increased requirement on computing\nresources, and involves data communication between the client and the server.\nIn order to deploy such service architecture, we need to evaluate the optimal\nsetting that fits the constraints. And that is what this paper addresses. In\nthis work, we enhance an attack detection system based on Convolutional Neural\nNetworks with privacy-preserving technology based on PriMIA framework that is\ninitially designed for medical data.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at IEEE Conference on Artificial Intelligence (CAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09625v1",
    "published_date": "2024-04-15 09:56:36 UTC",
    "updated_date": "2024-04-15 09:56:36 UTC"
  },
  {
    "arxiv_id": "2404.09622v2",
    "title": "DIDLM: A SLAM Dataset for Difficult Scenarios Featuring Infrared, Depth Cameras, LIDAR, 4D Radar, and Others under Adverse Weather, Low Light Conditions, and Rough Roads",
    "authors": [
      "Weisheng Gong",
      "Kaijie Su",
      "Qingyong Li",
      "Chen He",
      "Tong Wu",
      "Z. Jane Wang"
    ],
    "abstract": "Adverse weather conditions, low-light environments, and bumpy road surfaces\npose significant challenges to SLAM in robotic navigation and autonomous\ndriving. Existing datasets in this field predominantly rely on single sensors\nor combinations of LiDAR, cameras, and IMUs. However, 4D millimeter-wave radar\ndemonstrates robustness in adverse weather, infrared cameras excel in capturing\ndetails under low-light conditions, and depth images provide richer spatial\ninformation. Multi-sensor fusion methods also show potential for better\nadaptation to bumpy roads. Despite some SLAM studies incorporating these\nsensors and conditions, there remains a lack of comprehensive datasets\naddressing low-light environments and bumpy road conditions, or featuring a\nsufficiently diverse range of sensor data. In this study, we introduce a\nmulti-sensor dataset covering challenging scenarios such as snowy weather,\nrainy weather, nighttime conditions, speed bumps, and rough terrains. The\ndataset includes rarely utilized sensors for extreme conditions, such as 4D\nmillimeter-wave radar, infrared cameras, and depth cameras, alongside 3D LiDAR,\nRGB cameras, GPS, and IMU. It supports both autonomous driving and ground robot\napplications and provides reliable GPS/INS ground truth data, covering\nstructured and semi-structured terrains. We evaluated various SLAM algorithms\nusing this dataset, including RGB images, infrared images, depth images, LiDAR,\nand 4D millimeter-wave radar. The dataset spans a total of 18.5 km, 69 minutes,\nand approximately 660 GB, offering a valuable resource for advancing SLAM\nresearch under complex and extreme conditions. Our dataset is available at\nhttps://github.com/GongWeiSheng/DIDLM.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09622v2",
    "published_date": "2024-04-15 09:49:33 UTC",
    "updated_date": "2025-01-14 09:22:35 UTC"
  },
  {
    "arxiv_id": "2404.09619v1",
    "title": "UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark",
    "authors": [
      "Zhaokun Zhou",
      "Qiulin Wang",
      "Bin Lin",
      "Yiwei Su",
      "Rui Chen",
      "Xin Tao",
      "Amin Zheng",
      "Li Yuan",
      "Pengfei Wan",
      "Di Zhang"
    ],
    "abstract": "As an alternative to expensive expert evaluation, Image Aesthetic Assessment\n(IAA) stands out as a crucial task in computer vision. However, traditional IAA\nmethods are typically constrained to a single data source or task, restricting\nthe universality and broader application. In this work, to better align with\nhuman aesthetics, we propose a Unified Multi-modal Image Aesthetic Assessment\n(UNIAA) framework, including a Multi-modal Large Language Model (MLLM) named\nUNIAA-LLaVA and a comprehensive benchmark named UNIAA-Bench. We choose MLLMs\nwith both visual perception and language ability for IAA and establish a\nlow-cost paradigm for transforming the existing datasets into unified and\nhigh-quality visual instruction tuning data, from which the UNIAA-LLaVA is\ntrained. To further evaluate the IAA capability of MLLMs, we construct the\nUNIAA-Bench, which consists of three aesthetic levels: Perception, Description,\nand Assessment. Extensive experiments validate the effectiveness and\nrationality of UNIAA. UNIAA-LLaVA achieves competitive performance on all\nlevels of UNIAA-Bench, compared with existing MLLMs. Specifically, our model\nperforms better than GPT-4V in aesthetic perception and even approaches the\njunior-level human. We find MLLMs have great potential in IAA, yet there\nremains plenty of room for further improvement. The UNIAA-LLaVA and UNIAA-Bench\nwill be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09619v1",
    "published_date": "2024-04-15 09:47:48 UTC",
    "updated_date": "2024-04-15 09:47:48 UTC"
  },
  {
    "arxiv_id": "2404.12402v2",
    "title": "Sup3r: A Semi-Supervised Algorithm for increasing Sparsity, Stability, and Separability in Hierarchy Of Time-Surfaces architectures",
    "authors": [
      "Marco Rasetto",
      "Himanshu Akolkar",
      "Ryad Benosman"
    ],
    "abstract": "The Hierarchy Of Time-Surfaces (HOTS) algorithm, a neuromorphic approach for\nfeature extraction from event data, presents promising capabilities but faces\nchallenges in accuracy and compatibility with neuromorphic hardware. In this\npaper, we introduce Sup3r, a Semi-Supervised algorithm aimed at addressing\nthese challenges. Sup3r enhances sparsity, stability, and separability in the\nHOTS networks. It enables end-to-end online training of HOTS networks replacing\nexternal classifiers, by leveraging semi-supervised learning. Sup3r learns\nclass-informative patterns, mitigates confounding features, and reduces the\nnumber of processed events. Moreover, Sup3r facilitates continual and\nincremental learning, allowing adaptation to data distribution shifts and\nlearning new tasks without forgetting. Preliminary results on N-MNIST\ndemonstrate that Sup3r achieves comparable accuracy to similarly sized\nArtificial Neural Networks trained with back-propagation. This work showcases\nthe potential of Sup3r to advance the capabilities of HOTS networks, offering a\npromising avenue for neuromorphic algorithms in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.12402v2",
    "published_date": "2024-04-15 09:33:19 UTC",
    "updated_date": "2024-04-30 22:37:21 UTC"
  },
  {
    "arxiv_id": "2404.09613v1",
    "title": "Efficient and accurate neural field reconstruction using resistive memory",
    "authors": [
      "Yifei Yu",
      "Shaocong Wang",
      "Woyu Zhang",
      "Xinyuan Zhang",
      "Xiuzhe Wu",
      "Yangu He",
      "Jichang Yang",
      "Yue Zhang",
      "Ning Lin",
      "Bo Wang",
      "Xi Chen",
      "Songqi Wang",
      "Xumeng Zhang",
      "Xiaojuan Qi",
      "Zhongrui Wang",
      "Dashan Shang",
      "Qi Liu",
      "Kwang-Ting Cheng",
      "Ming Liu"
    ],
    "abstract": "Human beings construct perception of space by integrating sparse observations\ninto massively interconnected synapses and neurons, offering a superior\nparallelism and efficiency. Replicating this capability in AI finds wide\napplications in medical imaging, AR/VR, and embodied AI, where input data is\noften sparse and computing resources are limited. However, traditional signal\nreconstruction methods on digital computers face both software and hardware\nchallenges. On the software front, difficulties arise from storage\ninefficiencies in conventional explicit signal representation. Hardware\nobstacles include the von Neumann bottleneck, which limits data transfer\nbetween the CPU and memory, and the limitations of CMOS circuits in supporting\nparallel processing. We propose a systematic approach with software-hardware\nco-optimizations for signal reconstruction from sparse inputs. Software-wise,\nwe employ neural field to implicitly represent signals via neural networks,\nwhich is further compressed using low-rank decomposition and structured\npruning. Hardware-wise, we design a resistive memory-based computing-in-memory\n(CIM) platform, featuring a Gaussian Encoder (GE) and an MLP Processing Engine\n(PE). The GE harnesses the intrinsic stochasticity of resistive memory for\nefficient input encoding, while the PE achieves precise weight mapping through\na Hardware-Aware Quantization (HAQ) circuit. We demonstrate the system's\nefficacy on a 40nm 256Kb resistive memory-based in-memory computing macro,\nachieving huge energy efficiency and parallelism improvements without\ncompromising reconstruction quality in tasks like 3D CT sparse reconstruction,\nnovel view synthesis, and novel view synthesis for dynamic scenes. This work\nadvances the AI-driven signal restoration technology and paves the way for\nfuture efficient and robust medical AI and 3D vision applications.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09613v1",
    "published_date": "2024-04-15 09:33:09 UTC",
    "updated_date": "2024-04-15 09:33:09 UTC"
  },
  {
    "arxiv_id": "2404.09610v1",
    "title": "LoRA Dropout as a Sparsity Regularizer for Overfitting Control",
    "authors": [
      "Yang Lin",
      "Xinyu Ma",
      "Xu Chu",
      "Yujie Jin",
      "Zhibang Yang",
      "Yasha Wang",
      "Hong Mei"
    ],
    "abstract": "Parameter-efficient fine-tuning methods, represented by LoRA, play an\nessential role in adapting large-scale pre-trained models to downstream tasks.\nHowever, fine-tuning LoRA-series models also faces the risk of overfitting on\nthe training dataset, and yet there's still a lack of theoretical guidance and\npractical mechanism to control overfitting on LoRA-based PEFT methods. In this\npaper, we propose a LoRA Dropout mechanism for the LoRA-based methods by\nintroducing random noises to the learnable low-rank matrices and increasing\nparameter sparsity. We then demonstrate the theoretical mechanism of our LoRA\nDropout mechanism from the perspective of sparsity regularization by providing\na generalization error bound under this framework. Theoretical results show\nthat appropriate sparsity would help tighten the gap between empirical and\ngeneralization risks and thereby control overfitting. Furthermore, based on the\nLoRA Dropout framework, we introduce a test-time ensemble strategy and provide\ntheoretical evidence demonstrating that the ensemble method can further\ncompress the error bound, and lead to better performance during inference time.\nExtensive experiments on various NLP tasks provide practical validations of the\neffectiveness of our LoRA Dropout framework in improving model accuracy and\ncalibration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09610v1",
    "published_date": "2024-04-15 09:32:12 UTC",
    "updated_date": "2024-04-15 09:32:12 UTC"
  },
  {
    "arxiv_id": "2404.09606v1",
    "title": "A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions",
    "authors": [
      "Pengfei Liu",
      "Jun Tao",
      "Zhixiang Ren"
    ],
    "abstract": "The task of chemical reaction predictions (CRPs) plays a pivotal role in\nadvancing drug discovery and material science. However, its effectiveness is\nconstrained by the vast and uncertain chemical reaction space and challenges in\ncapturing reaction selectivity, particularly due to existing methods'\nlimitations in exploiting the data's inherent knowledge. To address these\nchallenges, we introduce a data-curated self-feedback knowledge elicitation\napproach. This method starts from iterative optimization of molecular\nrepresentations and facilitates the extraction of knowledge on chemical\nreaction types (RTs). Then, we employ adaptive prompt learning to infuse the\nprior knowledge into the large language model (LLM). As a result, we achieve\nsignificant enhancements: a 14.2% increase in retrosynthesis prediction\naccuracy, a 74.2% rise in reagent prediction accuracy, and an expansion in the\nmodel's capability for handling multi-task chemical reactions. This research\noffers a novel paradigm for knowledge elicitation in scientific research and\nshowcases the untapped potential of LLMs in CRPs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09606v1",
    "published_date": "2024-04-15 09:26:33 UTC",
    "updated_date": "2024-04-15 09:26:33 UTC"
  },
  {
    "arxiv_id": "2404.09601v1",
    "title": "Reactive Model Correction: Mitigating Harm to Task-Relevant Features via Conditional Bias Suppression",
    "authors": [
      "Dilyara Bareeva",
      "Maximilian Dreyer",
      "Frederik Pahde",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "abstract": "Deep Neural Networks are prone to learning and relying on spurious\ncorrelations in the training data, which, for high-risk applications, can have\nfatal consequences. Various approaches to suppress model reliance on harmful\nfeatures have been proposed that can be applied post-hoc without additional\ntraining. Whereas those methods can be applied with efficiency, they also tend\nto harm model performance by globally shifting the distribution of latent\nfeatures. To mitigate unintended overcorrection of model behavior, we propose a\nreactive approach conditioned on model-derived knowledge and eXplainable\nArtificial Intelligence (XAI) insights. While the reactive approach can be\napplied to many post-hoc methods, we demonstrate the incorporation of\nreactivity in particular for P-ClArC (Projective Class Artifact Compensation),\nintroducing a new method called R-ClArC (Reactive Class Artifact Compensation).\nThrough rigorous experiments in controlled settings (FunnyBirds) and with a\nreal-world dataset (ISIC2019), we show that introducing reactivity can minimize\nthe detrimental effect of the applied correction while simultaneously ensuring\nlow reliance on spurious features.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09601v1",
    "published_date": "2024-04-15 09:16:49 UTC",
    "updated_date": "2024-04-15 09:16:49 UTC"
  },
  {
    "arxiv_id": "2404.09595v1",
    "title": "Building Semantic Communication System via Molecules: An End-to-End Training Approach",
    "authors": [
      "Yukun Cheng",
      "Wei Chen",
      "Bo Ai"
    ],
    "abstract": "The concept of semantic communication provides a novel approach for\napplications in scenarios with limited communication resources. In this paper,\nwe propose an end-to-end (E2E) semantic molecular communication system, aiming\nto enhance the efficiency of molecular communication systems by reducing the\ntransmitted information. Specifically, following the joint source channel\ncoding paradigm, the network is designed to encode the task-relevant\ninformation into the concentration of the information molecules, which is\nrobust to the degradation of the molecular communication channel. Furthermore,\nwe propose a channel network to enable the E2E learning over the\nnon-differentiable molecular channel. Experimental results demonstrate the\nsuperior performance of the semantic molecular communication system over the\nconventional methods in classification tasks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09595v1",
    "published_date": "2024-04-15 09:06:07 UTC",
    "updated_date": "2024-04-15 09:06:07 UTC"
  },
  {
    "arxiv_id": "2404.09587v1",
    "title": "German Tourism Knowledge Graph",
    "authors": [
      "Umutcan Serles",
      "Elias Kärle",
      "Richard Hunkel",
      "Dieter Fensel"
    ],
    "abstract": "Tourism is one of the most critical sectors of the global economy. Due to its\nheterogeneous and fragmented nature, it provides one of the most suitable use\ncases for knowledge graphs. In this poster, we introduce the German Tourism\nKnowledge Graph that integrates tourism-related data from 16 federal states of\nGermany and various other sources to provide a curated knowledge source for\nvarious applications. It is publicly available through GUIs and an API.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages. Accepted to Poster and Demo Track of 21st European Semantic\n  Web Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09587v1",
    "published_date": "2024-04-15 08:56:53 UTC",
    "updated_date": "2024-04-15 08:56:53 UTC"
  },
  {
    "arxiv_id": "2404.09579v1",
    "title": "Modelling Language",
    "authors": [
      "Jumbly Grindrod"
    ],
    "abstract": "This paper argues that large language models have a valuable scientific role\nto play in serving as scientific models of a language. Linguistic study should\nnot only be concerned with the cognitive processes behind linguistic\ncompetence, but also with language understood as an external, social entity.\nOnce this is recognized, the value of large language models as scientific\nmodels becomes clear. This paper defends this position against a number of\narguments to the effect that language models provide no linguistic insight. It\nalso draws upon recent work in philosophy of science to show how large language\nmodels could serve as scientific models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09579v1",
    "published_date": "2024-04-15 08:40:01 UTC",
    "updated_date": "2024-04-15 08:40:01 UTC"
  },
  {
    "arxiv_id": "2404.09577v2",
    "title": "Transformers, Contextualism, and Polysemy",
    "authors": [
      "Jumbly Grindrod"
    ],
    "abstract": "The transformer architecture, introduced by Vaswani et al. (2017), is at the\nheart of the remarkable recent progress in the development of language models,\nincluding widely-used chatbots such as Chat-GPT and Claude. In this paper, I\nargue that we can extract from the way the transformer architecture works a\ntheory of the relationship between context and meaning. I call this the\ntransformer theory, and I argue that it is novel with regard to two related\nphilosophical debates: the contextualism debate regarding the extent of\ncontext-sensitivity across natural language, and the polysemy debate regarding\nhow polysemy should be captured within an account of word meaning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09577v2",
    "published_date": "2024-04-15 08:38:43 UTC",
    "updated_date": "2024-09-26 14:34:53 UTC"
  },
  {
    "arxiv_id": "2404.09576v2",
    "title": "Large language models and linguistic intentionality",
    "authors": [
      "Jumbly Grindrod"
    ],
    "abstract": "Do large language models like Chat-GPT or LLaMa meaningfully use the words\nthey produce? Or are they merely clever prediction machines, simulating\nlanguage use by producing statistically plausible text? There have already been\nsome initial attempts to answer this question by showing that these models meet\nthe criteria for entering meaningful states according to metasemantic theories\nof mental content. In this paper, I will argue for a different approach - that\nwe should instead consider whether language models meet the criteria given by\nour best metasemantic theories of linguistic content. In that vein, I will\nillustrate how this can be done by applying two such theories to the case of\nlanguage models: Gareth Evans' (1982) account of naming practices and Ruth\nMillikan's (1984, 2004, 2005) teleosemantics. In doing so, I will argue that it\nis a mistake to think that the failure of LLMs to meet plausible conditions for\nmental intentionality thereby renders their outputs meaningless, and that a\ndistinguishing feature of linguistic intentionality - dependency on a\npre-existing linguistic system - allows for the plausible result LLM outputs\nare meaningful.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09576v2",
    "published_date": "2024-04-15 08:37:26 UTC",
    "updated_date": "2024-09-16 08:35:51 UTC"
  },
  {
    "arxiv_id": "2404.09574v1",
    "title": "Predicting and Analyzing Pedestrian Crossing Behavior at Unsignalized Crossings",
    "authors": [
      "Chi Zhang",
      "Janis Sprenger",
      "Zhongjun Ni",
      "Christian Berger"
    ],
    "abstract": "Understanding and predicting pedestrian crossing behavior is essential for\nenhancing automated driving and improving driving safety. Predicting gap\nselection behavior and the use of zebra crossing enables driving systems to\nproactively respond and prevent potential conflicts. This task is particularly\nchallenging at unsignalized crossings due to the ambiguous right of way,\nrequiring pedestrians to constantly interact with vehicles and other\npedestrians. This study addresses these challenges by utilizing simulator data\nto investigate scenarios involving multiple vehicles and pedestrians. We\npropose and evaluate machine learning models to predict gap selection in\nnon-zebra scenarios and zebra crossing usage in zebra scenarios. We investigate\nand discuss how pedestrians' behaviors are influenced by various factors,\nincluding pedestrian waiting time, walking speed, the number of unused gaps,\nthe largest missed gap, and the influence of other pedestrians. This research\ncontributes to the evolution of intelligent vehicles by providing predictive\nmodels and valuable insights into pedestrian crossing behavior.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T40, 68T45",
      "I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 10 figures, 4 tables. Accepted in 2024 IEEE Intelligent\n  Vehicles Symposium (IV)",
    "pdf_url": "http://arxiv.org/pdf/2404.09574v1",
    "published_date": "2024-04-15 08:36:40 UTC",
    "updated_date": "2024-04-15 08:36:40 UTC"
  },
  {
    "arxiv_id": "2404.09565v1",
    "title": "Reliability Estimation of News Media Sources: Birds of a Feather Flock Together",
    "authors": [
      "Sergio Burdisso",
      "Dairazalia Sánchez-Cortés",
      "Esaú Villatoro-Tello",
      "Petr Motlicek"
    ],
    "abstract": "Evaluating the reliability of news sources is a routine task for journalists\nand organizations committed to acquiring and disseminating accurate\ninformation. Recent research has shown that predicting sources' reliability\nrepresents an important first-prior step in addressing additional challenges\nsuch as fake news detection and fact-checking. In this paper, we introduce a\nnovel approach for source reliability estimation that leverages reinforcement\nlearning strategies for estimating the reliability degree of news sources.\nContrary to previous research, our proposed approach models the problem as the\nestimation of a reliability degree, and not a reliability label, based on how\nall the news media sources interact with each other on the Web. We validated\nthe effectiveness of our method on a news media reliability dataset that is an\norder of magnitude larger than comparable existing datasets. Results show that\nthe estimated reliability degrees strongly correlates with journalists-provided\nscores (Spearman=0.80) and can effectively predict reliability labels\n(macro-avg. F$_1$ score=81.05). We release our implementation and dataset,\naiming to provide a valuable resource for the NLP community working on\ninformation verification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.09565v1",
    "published_date": "2024-04-15 08:27:47 UTC",
    "updated_date": "2024-04-15 08:27:47 UTC"
  },
  {
    "arxiv_id": "2404.09562v2",
    "title": "σ-GPTs: A New Approach to Autoregressive Models",
    "authors": [
      "Arnaud Pannatier",
      "Evann Courdier",
      "François Fleuret"
    ],
    "abstract": "Autoregressive models, such as the GPT family, use a fixed order, usually\nleft-to-right, to generate sequences. However, this is not a necessity. In this\npaper, we challenge this assumption and show that by simply adding a positional\nencoding for the output, this order can be modulated on-the-fly per-sample\nwhich offers key advantageous properties. It allows for the sampling of and\nconditioning on arbitrary subsets of tokens, and it also allows sampling in one\nshot multiple tokens dynamically according to a rejection strategy, leading to\na sub-linear number of model evaluations. We evaluate our method across various\ndomains, including language modeling, path-solving, and aircraft vertical rate\nprediction, decreasing the number of steps required for generation by an order\nof magnitude.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 7 figures, accepted at ECML/PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09562v2",
    "published_date": "2024-04-15 08:22:47 UTC",
    "updated_date": "2024-07-01 06:46:36 UTC"
  },
  {
    "arxiv_id": "2404.09559v1",
    "title": "Joint Contrastive Learning with Feature Alignment for Cross-Corpus EEG-based Emotion Recognition",
    "authors": [
      "Qile Liu",
      "Zhihao Zhou",
      "Jiyuan Wang",
      "Zhen Liang"
    ],
    "abstract": "The integration of human emotions into multimedia applications shows great\npotential for enriching user experiences and enhancing engagement across\nvarious digital platforms. Unlike traditional methods such as questionnaires,\nfacial expressions, and voice analysis, brain signals offer a more direct and\nobjective understanding of emotional states. However, in the field of\nelectroencephalography (EEG)-based emotion recognition, previous studies have\nprimarily concentrated on training and testing EEG models within a single\ndataset, overlooking the variability across different datasets. This oversight\nleads to significant performance degradation when applying EEG models to\ncross-corpus scenarios. In this study, we propose a novel Joint Contrastive\nlearning framework with Feature Alignment (JCFA) to address cross-corpus\nEEG-based emotion recognition. The JCFA model operates in two main stages. In\nthe pre-training stage, a joint domain contrastive learning strategy is\nintroduced to characterize generalizable time-frequency representations of EEG\nsignals, without the use of labeled data. It extracts robust time-based and\nfrequency-based embeddings for each EEG sample, and then aligns them within a\nshared latent time-frequency space. In the fine-tuning stage, JCFA is refined\nin conjunction with downstream tasks, where the structural connections among\nbrain electrodes are considered. The model capability could be further enhanced\nfor the application in emotion detection and interpretation. Extensive\nexperimental results on two well-recognized emotional datasets show that the\nproposed JCFA model achieves state-of-the-art (SOTA) performance, outperforming\nthe second-best method by an average accuracy increase of 4.09% in cross-corpus\nEEG-based emotion recognition tasks.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09559v1",
    "published_date": "2024-04-15 08:21:17 UTC",
    "updated_date": "2024-04-15 08:21:17 UTC"
  },
  {
    "arxiv_id": "2404.09557v1",
    "title": "Characterization and Mitigation of Insufficiencies in Automated Driving Systems",
    "authors": [
      "Yuting Fu",
      "Jochen Seemann",
      "Caspar Hanselaar",
      "Tim Beurskens",
      "Andrei Terechko",
      "Emilia Silvas",
      "Maurice Heemels"
    ],
    "abstract": "Automated Driving (AD) systems have the potential to increase safety, comfort\nand energy efficiency. Recently, major automotive companies have started\ntesting and validating AD systems (ADS) on public roads. Nevertheless, the\ncommercial deployment and wide adoption of ADS have been moderate, partially\ndue to system functional insufficiencies (FI) that undermine passenger safety\nand lead to hazardous situations on the road. FIs are defined in ISO 21448\nSafety Of The Intended Functionality (SOTIF). FIs are insufficiencies in\nsensors, actuators and algorithm implementations, including neural networks and\nprobabilistic calculations. Examples of FIs in ADS include inaccurate\nego-vehicle localization on the road, incorrect prediction of a cyclist\nmaneuver, unreliable detection of a pedestrian, etc.\n  The main goal of our study is to formulate a generic architectural design\npattern, which is compatible with existing methods and ADS, to improve FI\nmitigation and enable faster commercial deployment of ADS. First, we studied\nthe 2021 autonomous vehicles disengagement reports published by the California\nDepartment of Motor Vehicles (DMV). The data clearly show that disengagements\nare five times more often caused by FIs rather than by system faults. We then\nmade a comprehensive list of insufficiencies and their characteristics by\nanalyzing over 10 hours of publicly available road test videos. In particular,\nwe identified insufficiency types in four major categories: world model, motion\nplan, traffic rule, and operational design domain. The insufficiency\ncharacterization helps making the SOTIF analyses of triggering conditions more\nsystematic and comprehensive.\n  Based on our FI characterization, simulation experiments and literature\nsurvey, we define a novel generic architectural design pattern Daruma to\ndynamically select the channel that is least likely to have a FI at the moment.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at the 27th International Technical Conference on the\n  Enhanced Safety of Vehicles (ESV), Apr 2023, Yokohama, Japan. Original\n  publication https://www-esv.nhtsa.dot.gov/Proceedings/27/27ESV-000110.pdf",
    "pdf_url": "http://arxiv.org/pdf/2404.09557v1",
    "published_date": "2024-04-15 08:19:13 UTC",
    "updated_date": "2024-04-15 08:19:13 UTC"
  },
  {
    "arxiv_id": "2404.09554v1",
    "title": "Explainable Generative AI (GenXAI): A Survey, Conceptualization, and Research Agenda",
    "authors": [
      "Johannes Schneider"
    ],
    "abstract": "Generative AI (GenAI) marked a shift from AI being able to recognize to AI\nbeing able to generate solutions for a wide variety of tasks. As the generated\nsolutions and applications become increasingly more complex and multi-faceted,\nnovel needs, objectives, and possibilities have emerged for explainability\n(XAI). In this work, we elaborate on why XAI has gained importance with the\nrise of GenAI and its challenges for explainability research. We also unveil\nnovel and emerging desiderata that explanations should fulfill, covering\naspects such as verifiability, interactivity, security, and cost. To this end,\nwe focus on surveying existing works. Furthermore, we provide a taxonomy of\nrelevant dimensions that allows us to better characterize existing XAI\nmechanisms and methods for GenAI. We discuss different avenues to ensure XAI,\nfrom training data to prompting. Our paper offers a short but concise technical\nbackground of GenAI for non-technical readers, focusing on text and images to\nbetter understand novel or adapted XAI techniques for GenAI. However, due to\nthe vast array of works on GenAI, we decided to forego detailed aspects of XAI\nrelated to evaluation and usage of explanations. As such, the manuscript\ninterests both technically oriented people and other disciplines, such as\nsocial scientists and information systems researchers. Our research roadmap\nprovides more than ten directions for future investigation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09554v1",
    "published_date": "2024-04-15 08:18:16 UTC",
    "updated_date": "2024-04-15 08:18:16 UTC"
  },
  {
    "arxiv_id": "2404.12401v1",
    "title": "Items or Relations -- what do Artificial Neural Networks learn?",
    "authors": [
      "Renate Krause",
      "Stefan Reimann"
    ],
    "abstract": "What has an Artificial Neural Network (ANN) learned after being successfully\ntrained to solve a task - the set of training items or the relations between\nthem? This question is difficult to answer for modern applied ANNs because of\ntheir enormous size and complexity. Therefore, here we consider a\nlow-dimensional network and a simple task, i.e., the network has to reproduce a\nset of training items identically. We construct the family of solutions\nanalytically and use standard learning algorithms to obtain numerical\nsolutions. These numerical solutions differ depending on the optimization\nalgorithm and the weight initialization and are shown to be particular members\nof the family of analytical solutions. In this simple setting, we observe that\nthe general structure of the network weights represents the training set's\nsymmetry group, i.e., the relations between training items. As a consequence,\nlinear networks generalize, i.e., reproduce items that were not part of the\ntraining set but are consistent with the symmetry of the training set. In\ncontrast, non-linear networks tend to learn individual training items and show\nassociative memory. At the same time, their ability to generalize is limited. A\nhigher degree of generalization is obtained for networks whose activation\nfunction contains a linear regime, such as tanh. Our results suggest ANN's\nability to generalize - instead of learning items - could be improved by\ngenerating a sufficiently big set of elementary operations to represent\nrelations and strongly depends on the applied non-linearity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.12401v1",
    "published_date": "2024-04-15 08:11:45 UTC",
    "updated_date": "2024-04-15 08:11:45 UTC"
  },
  {
    "arxiv_id": "2404.09544v1",
    "title": "GNNavigator: Towards Adaptive Training of Graph Neural Networks via Automatic Guideline Exploration",
    "authors": [
      "Tong Qiao",
      "Jianlei Yang",
      "Yingjie Qi",
      "Ao Zhou",
      "Chen Bai",
      "Bei Yu",
      "Weisheng Zhao",
      "Chunming Hu"
    ],
    "abstract": "Graph Neural Networks (GNNs) succeed significantly in many applications\nrecently. However, balancing GNNs training runtime cost, memory consumption,\nand attainable accuracy for various applications is non-trivial. Previous\ntraining methodologies suffer from inferior adaptability and lack a unified\ntraining optimization solution. To address the problem, this work proposes\nGNNavigator, an adaptive GNN training configuration optimization framework.\nGNNavigator meets diverse GNN application requirements due to our unified\nsoftware-hardware co-abstraction, proposed GNNs training performance model, and\npractical design space exploration solution. Experimental results show that\nGNNavigator can achieve up to 3.1x speedup and 44.9% peak memory reduction with\ncomparable accuracy to state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by DAC'24",
    "pdf_url": "http://arxiv.org/pdf/2404.09544v1",
    "published_date": "2024-04-15 08:11:21 UTC",
    "updated_date": "2024-04-15 08:11:21 UTC"
  },
  {
    "arxiv_id": "2404.09537v1",
    "title": "Machine Learning Techniques for Python Source Code Vulnerability Detection",
    "authors": [
      "Talaya Farasat",
      "Joachim Posegga"
    ],
    "abstract": "Software vulnerabilities are a fundamental reason for the prevalence of cyber\nattacks and their identification is a crucial yet challenging problem in cyber\nsecurity. In this paper, we apply and compare different machine learning\nalgorithms for source code vulnerability detection specifically for Python\nprogramming language. Our experimental evaluation demonstrates that our\nBidirectional Long Short-Term Memory (BiLSTM) model achieves a remarkable\nperformance (average Accuracy = 98.6%, average F-Score = 94.7%, average\nPrecision = 96.2%, average Recall = 93.3%, average ROC = 99.3%), thereby,\nestablishing a new benchmark for vulnerability detection in Python source code.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09537v1",
    "published_date": "2024-04-15 08:01:02 UTC",
    "updated_date": "2024-04-15 08:01:02 UTC"
  },
  {
    "arxiv_id": "2404.15192v3",
    "title": "Measuring Diversity of Game Scenarios",
    "authors": [
      "Yuchen Li",
      "Ziqi Wang",
      "Qingquan Zhang",
      "Bo Yuan",
      "Jialin Liu"
    ],
    "abstract": "This survey comprehensively reviews the multi-dimensionality of game scenario\ndiversity, spotlighting the innovative use of procedural content generation and\nother fields as cornerstones for enriching player experiences through diverse\ngame scenarios. By traversing a wide array of disciplines, from affective\nmodeling and multi-agent systems to psychological studies, our research\nunderscores the importance of diverse game scenarios in gameplay and education.\nThrough a taxonomy of diversity metrics and evaluation methods, we aim to\nbridge the current gaps in literature and practice, offering insights into\neffective strategies for measuring and integrating diversity in game scenarios.\nOur analysis highlights the necessity for a unified taxonomy to aid developers\nand researchers in crafting more engaging and varied game worlds. This survey\nnot only charts a path for future research in diverse game scenarios but also\nserves as a handbook for industry practitioners seeking to leverage diversity\nas a key component of game design and development.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15192v3",
    "published_date": "2024-04-15 07:59:52 UTC",
    "updated_date": "2025-01-16 05:35:43 UTC"
  },
  {
    "arxiv_id": "2404.09536v2",
    "title": "Noiseless Privacy-Preserving Decentralized Learning",
    "authors": [
      "Sayan Biswas",
      "Mathieu Even",
      "Anne-Marie Kermarrec",
      "Laurent Massoulie",
      "Rafael Pires",
      "Rishi Sharma",
      "Martijn de Vos"
    ],
    "abstract": "Decentralized learning (DL) enables collaborative learning without a server\nand without training data leaving the users' devices. However, the models\nshared in DL can still be used to infer training data. Conventional defenses\nsuch as differential privacy and secure aggregation fall short in effectively\nsafeguarding user privacy in DL, either sacrificing model utility or\nefficiency. We introduce Shatter, a novel DL approach in which nodes create\nvirtual nodes (VNs) to disseminate chunks of their full model on their behalf.\nThis enhances privacy by (i) preventing attackers from collecting full models\nfrom other nodes, and (ii) hiding the identity of the original node that\nproduced a given model chunk. We theoretically prove the convergence of Shatter\nand provide a formal analysis demonstrating how Shatter reduces the efficacy of\nattacks compared to when exchanging full models between nodes. We evaluate the\nconvergence and attack resilience of Shatter with existing DL algorithms, with\nheterogeneous datasets, and against three standard privacy attacks. Our\nevaluation shows that Shatter not only renders these privacy attacks infeasible\nwhen each node operates 16 VNs but also exhibits a positive impact on model\nutility compared to standard DL. In summary, Shatter enhances the privacy of DL\nwhile maintaining the utility and efficiency of the model.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at PETS 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.09536v2",
    "published_date": "2024-04-15 07:59:11 UTC",
    "updated_date": "2024-09-12 13:53:31 UTC"
  },
  {
    "arxiv_id": "2404.09533v2",
    "title": "WiTUnet: A U-Shaped Architecture Integrating CNN and Transformer for Improved Feature Alignment and Local Information Fusion",
    "authors": [
      "Bin Wang",
      "Fei Deng",
      "Peifan Jiang",
      "Shuang Wang",
      "Xiao Han",
      "Zhixuan Zhang"
    ],
    "abstract": "Low-dose computed tomography (LDCT) has become the technology of choice for\ndiagnostic medical imaging, given its lower radiation dose compared to standard\nCT, despite increasing image noise and potentially affecting diagnostic\naccuracy. To address this, advanced deep learning-based LDCT denoising\nalgorithms have been developed, primarily using Convolutional Neural Networks\n(CNNs) or Transformer Networks with the Unet architecture. This architecture\nenhances image detail by integrating feature maps from the encoder and decoder\nvia skip connections. However, current methods often overlook enhancements to\nthe Unet architecture itself, focusing instead on optimizing encoder and\ndecoder structures. This approach can be problematic due to the significant\ndifferences in feature map characteristics between the encoder and decoder,\nwhere simple fusion strategies may not effectively reconstruct images.In this\npaper, we introduce WiTUnet, a novel LDCT image denoising method that utilizes\nnested, dense skip pathways instead of traditional skip connections to improve\nfeature integration. WiTUnet also incorporates a windowed Transformer structure\nto process images in smaller, non-overlapping segments, reducing computational\nload. Additionally, the integration of a Local Image Perception Enhancement\n(LiPe) module in both the encoder and decoder replaces the standard multi-layer\nperceptron (MLP) in Transformers, enhancing local feature capture and\nrepresentation. Through extensive experimental comparisons, WiTUnet has\ndemonstrated superior performance over existing methods in key metrics such as\nPeak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Root Mean\nSquare Error (RMSE), significantly improving noise removal and image quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09533v2",
    "published_date": "2024-04-15 07:53:07 UTC",
    "updated_date": "2024-04-29 04:58:20 UTC"
  },
  {
    "arxiv_id": "2404.09530v2",
    "title": "RanLayNet: A Dataset for Document Layout Detection used for Domain Adaptation and Generalization",
    "authors": [
      "Avinash Anand",
      "Raj Jaiswal",
      "Mohit Gupta",
      "Siddhesh S Bangar",
      "Pijush Bhuyan",
      "Naman Lal",
      "Rajeev Singh",
      "Ritika Jha",
      "Rajiv Ratn Shah",
      "Shin'ichi Satoh"
    ],
    "abstract": "Large ground-truth datasets and recent advances in deep learning techniques\nhave been useful for layout detection. However, because of the restricted\nlayout diversity of these datasets, training on them requires a sizable number\nof annotated instances, which is both expensive and time-consuming. As a\nresult, differences between the source and target domains may significantly\nimpact how well these models function. To solve this problem, domain adaptation\napproaches have been developed that use a small quantity of labeled data to\nadjust the model to the target domain. In this research, we introduced a\nsynthetic document dataset called RanLayNet, enriched with automatically\nassigned labels denoting spatial positions, ranges, and types of layout\nelements. The primary aim of this endeavor is to develop a versatile dataset\ncapable of training models with robustness and adaptability to diverse document\nformats. Through empirical experimentation, we demonstrate that a deep layout\nidentification model trained on our dataset exhibits enhanced performance\ncompared to a model trained solely on actual documents. Moreover, we conduct a\ncomparative analysis by fine-tuning inference models using both PubLayNet and\nIIIT-AR-13K datasets on the Doclaynet dataset. Our findings emphasize that\nmodels enriched with our dataset are optimal for tasks such as achieving 0.398\nand 0.588 mAP95 score in the scientific document domain for the TABLE class.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures, MMAsia 2023 Proceedings of the 5th ACM\n  International Conference on Multimedia in Asia",
    "pdf_url": "http://arxiv.org/pdf/2404.09530v2",
    "published_date": "2024-04-15 07:50:15 UTC",
    "updated_date": "2024-04-19 06:44:18 UTC"
  },
  {
    "arxiv_id": "2404.09529v1",
    "title": "Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models",
    "authors": [
      "Siyan Zhao",
      "Daniel Israel",
      "Guy Van den Broeck",
      "Aditya Grover"
    ],
    "abstract": "During inference for transformer-based large language models (LLM),\nprefilling is the computation of the key-value (KV) cache for input tokens in\nthe prompt prior to autoregressive generation. For longer input prompt lengths,\nprefilling will incur a significant overhead on decoding time. In this work, we\nhighlight the following pitfall of prefilling: for batches containing\nhigh-varying prompt lengths, significant computation is wasted by the standard\npractice of padding sequences to the maximum length. As LLMs increasingly\nsupport longer context lengths, potentially up to 10 million tokens, variations\nin prompt lengths within a batch become more pronounced. To address this, we\npropose Prepacking, a simple yet effective method to optimize prefilling\ncomputation. To avoid redundant computation on pad tokens, prepacking combines\nprompts of varying lengths into a sequence and packs multiple sequences into a\ncompact batch using a bin-packing algorithm. It then modifies the attention\nmask and positional encoding to compute multiple prefilled KV-caches for\nmultiple prompts within a single sequence. On standard curated dataset\ncontaining prompts with varying lengths, we obtain a significant speed and\nmemory efficiency improvements as compared to the default padding-based\nprefilling computation within Huggingface across a range of base model\nconfigurations and inference serving scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, code in https://github.com/siyan-zhao/prepacking",
    "pdf_url": "http://arxiv.org/pdf/2404.09529v1",
    "published_date": "2024-04-15 07:49:10 UTC",
    "updated_date": "2024-04-15 07:49:10 UTC"
  },
  {
    "arxiv_id": "2404.09521v1",
    "title": "Inferring Behavior-Specific Context Improves Zero-Shot Generalization in Reinforcement Learning",
    "authors": [
      "Tidiane Camaret Ndir",
      "André Biedenkapp",
      "Noor Awad"
    ],
    "abstract": "In this work, we address the challenge of zero-shot generalization (ZSG) in\nReinforcement Learning (RL), where agents must adapt to entirely novel\nenvironments without additional training. We argue that understanding and\nutilizing contextual cues, such as the gravity level of the environment, is\ncritical for robust generalization, and we propose to integrate the learning of\ncontext representations directly with policy learning. Our algorithm\ndemonstrates improved generalization on various simulated domains,\noutperforming prior context-learning techniques in zero-shot settings. By\njointly learning policy and context, our method acquires behavior-specific\ncontext representations, enabling adaptation to unseen environments and marks\nprogress towards reinforcement learning systems that generalize across diverse\nreal-world tasks. Our code and experiments are available at\nhttps://github.com/tidiane-camaret/contextual_rl_zero_shot.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/tidiane-camaret/contextual_rl_zero_shot",
    "pdf_url": "http://arxiv.org/pdf/2404.09521v1",
    "published_date": "2024-04-15 07:31:48 UTC",
    "updated_date": "2024-04-15 07:31:48 UTC"
  },
  {
    "arxiv_id": "2404.09516v1",
    "title": "State Space Model for New-Generation Network Alternative to Transformers: A Survey",
    "authors": [
      "Xiao Wang",
      "Shiao Wang",
      "Yuhe Ding",
      "Yuehang Li",
      "Wentao Wu",
      "Yao Rong",
      "Weizhe Kong",
      "Ju Huang",
      "Shihao Li",
      "Haoxiang Yang",
      "Ziwen Wang",
      "Bo Jiang",
      "Chenglong Li",
      "Yaowei Wang",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "In the post-deep learning era, the Transformer architecture has demonstrated\nits powerful performance across pre-trained big models and various downstream\ntasks. However, the enormous computational demands of this architecture have\ndeterred many researchers. To further reduce the complexity of attention\nmodels, numerous efforts have been made to design more efficient methods. Among\nthem, the State Space Model (SSM), as a possible replacement for the\nself-attention based Transformer model, has drawn more and more attention in\nrecent years. In this paper, we give the first comprehensive review of these\nworks and also provide experimental comparisons and analysis to better\ndemonstrate the features and advantages of SSM. Specifically, we first give a\ndetailed description of principles to help the readers quickly capture the key\nideas of SSM. After that, we dive into the reviews of existing SSMs and their\nvarious applications, including natural language processing, computer vision,\ngraph, multi-modal and multi-media, point cloud/event stream, time series data,\nand other domains. In addition, we give statistical comparisons and analysis of\nthese models and hope it helps the readers to understand the effectiveness of\ndifferent structures on various tasks. Then, we propose possible research\npoints in this direction to better promote the development of the theoretical\nmodel and application of SSM. More related works will be continuously updated\non the following GitHub:\nhttps://github.com/Event-AHU/Mamba_State_Space_Model_Paper_List.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "The First review of State Space Model (SSM)/Mamba and their\n  applications in artificial intelligence, 33 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.09516v1",
    "published_date": "2024-04-15 07:24:45 UTC",
    "updated_date": "2024-04-15 07:24:45 UTC"
  },
  {
    "arxiv_id": "2404.10024v1",
    "title": "ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs",
    "authors": [
      "Yogesh Verma",
      "Markus Heinonen",
      "Vikas Garg"
    ],
    "abstract": "Climate and weather prediction traditionally relies on complex numerical\nsimulations of atmospheric physics. Deep learning approaches, such as\ntransformers, have recently challenged the simulation paradigm with complex\nnetwork forecasts. However, they often act as data-driven black-box models that\nneglect the underlying physics and lack uncertainty quantification. We address\nthese limitations with ClimODE, a spatiotemporal continuous-time process that\nimplements a key principle of advection from statistical mechanics, namely,\nweather changes due to a spatial movement of quantities over time. ClimODE\nmodels precise weather evolution with value-conserving dynamics, learning\nglobal weather transport as a neural flow, which also enables estimating the\nuncertainty in predictions. Our approach outperforms existing data-driven\nmethods in global and regional forecasting with an order of magnitude smaller\nparameterization, establishing a new state of the art.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as ICLR 2024 Oral. Project website:\n  https://yogeshverma1998.github.io/ClimODE/",
    "pdf_url": "http://arxiv.org/pdf/2404.10024v1",
    "published_date": "2024-04-15 06:38:21 UTC",
    "updated_date": "2024-04-15 06:38:21 UTC"
  },
  {
    "arxiv_id": "2404.09480v1",
    "title": "Mitigating Hallucination in Abstractive Summarization with Domain-Conditional Mutual Information",
    "authors": [
      "Kyubyung Chae",
      "Jaepill Choi",
      "Yohan Jo",
      "Taesup Kim"
    ],
    "abstract": "A primary challenge in abstractive summarization is hallucination -- the\nphenomenon where a model generates plausible text that is absent in the source\ntext. We hypothesize that the domain (or topic) of the source text triggers the\nmodel to generate text that is highly probable in the domain, neglecting the\ndetails of the source text. To alleviate this model bias, we introduce a\ndecoding strategy based on domain-conditional pointwise mutual information.\nThis strategy adjusts the generation probability of each token by comparing it\nwith the token's marginal probability within the domain of the source text.\nAccording to evaluation on the XSUM dataset, our method demonstrates\nimprovement in terms of faithfulness and source relevance. The code is publicly\navailable at \\url{https://github.com/qqplot/dcpmi}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by Findings of NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09480v1",
    "published_date": "2024-04-15 06:06:43 UTC",
    "updated_date": "2024-04-15 06:06:43 UTC"
  },
  {
    "arxiv_id": "2404.09475v1",
    "title": "Improving Weakly-Supervised Object Localization Using Adversarial Erasing and Pseudo Label",
    "authors": [
      "Byeongkeun Kang",
      "Sinhae Cha",
      "Yeejin Lee"
    ],
    "abstract": "Weakly-supervised learning approaches have gained significant attention due\nto their ability to reduce the effort required for human annotations in\ntraining neural networks. This paper investigates a framework for\nweakly-supervised object localization, which aims to train a neural network\ncapable of predicting both the object class and its location using only images\nand their image-level class labels. The proposed framework consists of a shared\nfeature extractor, a classifier, and a localizer. The localizer predicts\npixel-level class probabilities, while the classifier predicts the object class\nat the image level. Since image-level class labels are insufficient for\ntraining the localizer, weakly-supervised object localization methods often\nencounter challenges in accurately localizing the entire object region. To\naddress this issue, the proposed method incorporates adversarial erasing and\npseudo labels to improve localization accuracy. Specifically, novel losses are\ndesigned to utilize adversarially erased foreground features and adversarially\nerased feature maps, reducing dependence on the most discriminative region.\nAdditionally, the proposed method employs pseudo labels to suppress activation\nvalues in the background while increasing them in the foreground. The proposed\nmethod is applied to two backbone networks (MobileNetV1 and InceptionV3) and is\nevaluated on three publicly available datasets (ILSVRC-2012, CUB-200-2011, and\nPASCAL VOC 2012). The experimental results demonstrate that the proposed method\noutperforms previous state-of-the-art methods across all evaluated metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.09475v1",
    "published_date": "2024-04-15 06:02:09 UTC",
    "updated_date": "2024-04-15 06:02:09 UTC"
  },
  {
    "arxiv_id": "2404.09470v2",
    "title": "LatticeML: A data-driven application for predicting the effective Young Modulus of high temperature graph based architected materials",
    "authors": [
      "Akshansh Mishra"
    ],
    "abstract": "Architected materials with their unique topology and geometry offer the\npotential to modify physical and mechanical properties. Machine learning can\naccelerate the design and optimization of these materials by identifying\noptimal designs and forecasting performance. This work presents LatticeML, a\ndata-driven application for predicting the effective Young's Modulus of\nhigh-temperature graph-based architected materials. The study considers eleven\ngraph-based lattice structures with two high-temperature alloys, Ti-6Al-4V and\nInconel 625. Finite element simulations were used to compute the effective\nYoung's Modulus of the 2x2x2 unit cell configurations. A machine learning\nframework was developed to predict Young's Modulus, involving data collection,\npreprocessing, implementation of regression models, and deployment of the\nbest-performing model. Five supervised learning algorithms were evaluated, with\nthe XGBoost Regressor achieving the highest accuracy (MSE = 2.7993, MAE =\n1.1521, R-squared = 0.9875). The application uses the Streamlit framework to\ncreate an interactive web interface, allowing users to input material and\ngeometric parameters and obtain predicted Young's Modulus values.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "math.OC",
      "physics.app-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.09470v2",
    "published_date": "2024-04-15 05:50:46 UTC",
    "updated_date": "2024-04-16 01:52:45 UTC"
  },
  {
    "arxiv_id": "2404.09468v2",
    "title": "Tokenization, Fusion, and Augmentation: Towards Fine-grained Multi-modal Entity Representation",
    "authors": [
      "Yichi Zhang",
      "Zhuo Chen",
      "Lingbing Guo",
      "Yajing Xu",
      "Binbin Hu",
      "Ziqi Liu",
      "Wen Zhang",
      "Huajun Chen"
    ],
    "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to discover unobserved\nknowledge from given knowledge graphs, collaboratively leveraging structural\ninformation from the triples and multi-modal information of the entities to\novercome the inherent incompleteness. Existing MMKGC methods usually extract\nmulti-modal features with pre-trained models, resulting in coarse handling of\nmulti-modal entity information, overlooking the nuanced, fine-grained semantic\ndetails and their complex interactions. To tackle this shortfall, we introduce\na novel framework MyGO to tokenize, fuse, and augment the fine-grained\nmulti-modal representations of entities and enhance the MMKGC performance.\nMotivated by the tokenization technology, MyGO tokenizes multi-modal entity\ninformation as fine-grained discrete tokens and learns entity representations\nwith a cross-modal entity encoder. To further augment the multi-modal\nrepresentations, MyGO incorporates fine-grained contrastive learning to\nhighlight the specificity of the entity representations. Experiments on\nstandard MMKGC benchmarks reveal that our method surpasses 19 of the latest\nmodels, underlining its superior performance. Code and data can be found in\nhttps://github.com/zjukg/MyGO",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2025; Repo is available at https://github.com/zjukg/MyGO",
    "pdf_url": "http://arxiv.org/pdf/2404.09468v2",
    "published_date": "2024-04-15 05:40:41 UTC",
    "updated_date": "2024-12-14 10:57:06 UTC"
  },
  {
    "arxiv_id": "2404.13071v2",
    "title": "Modeling Emotions and Ethics with Large Language Models",
    "authors": [
      "Edward Y. Chang"
    ],
    "abstract": "This paper explores the integration of human-like emotions and ethical\nconsiderations into Large Language Models (LLMs). We first model eight\nfundamental human emotions, presented as opposing pairs, and employ\ncollaborative LLMs to reinterpret and express these emotions across a spectrum\nof intensity. Our focus extends to embedding a latent ethical dimension within\nLLMs, guided by a novel self-supervised learning algorithm with human feedback\n(SSHF). This approach enables LLMs to perform self-evaluations and adjustments\nconcerning ethical guidelines, enhancing their capability to generate content\nthat is not only emotionally resonant but also ethically aligned. The\nmethodologies and case studies presented herein illustrate the potential of\nLLMs to transcend mere text and image generation, venturing into the realms of\nempathetic interaction and principled decision-making, thereby setting a new\nprecedent in the development of emotionally aware and ethically conscious AI\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.13071v2",
    "published_date": "2024-04-15 05:30:26 UTC",
    "updated_date": "2024-06-25 04:36:08 UTC"
  },
  {
    "arxiv_id": "2404.09465v2",
    "title": "PhyScene: Physically Interactable 3D Scene Synthesis for Embodied AI",
    "authors": [
      "Yandan Yang",
      "Baoxiong Jia",
      "Peiyuan Zhi",
      "Siyuan Huang"
    ],
    "abstract": "With recent developments in Embodied Artificial Intelligence (EAI) research,\nthere has been a growing demand for high-quality, large-scale interactive scene\ngeneration. While prior methods in scene synthesis have prioritized the\nnaturalness and realism of the generated scenes, the physical plausibility and\ninteractivity of scenes have been largely left unexplored. To address this\ndisparity, we introduce PhyScene, a novel method dedicated to generating\ninteractive 3D scenes characterized by realistic layouts, articulated objects,\nand rich physical interactivity tailored for embodied agents. Based on a\nconditional diffusion model for capturing scene layouts, we devise novel\nphysics- and interactivity-based guidance mechanisms that integrate constraints\nfrom object collision, room layout, and object reachability. Through extensive\nexperiments, we demonstrate that PhyScene effectively leverages these guidance\nfunctions for physically interactable scene synthesis, outperforming existing\nstate-of-the-art scene synthesis methods by a large margin. Our findings\nsuggest that the scenes generated by PhyScene hold considerable potential for\nfacilitating diverse skill acquisition among agents within interactive\nenvironments, thereby catalyzing further advancements in embodied AI research.\nProject website: http://physcene.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024 (Highlight), 18 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.09465v2",
    "published_date": "2024-04-15 05:29:23 UTC",
    "updated_date": "2024-07-10 02:43:14 UTC"
  },
  {
    "arxiv_id": "2404.09462v1",
    "title": "Experimental Analysis of Deep Hedging Using Artificial Market Simulations for Underlying Asset Simulators",
    "authors": [
      "Masanori Hirano"
    ],
    "abstract": "Derivative hedging and pricing are important and continuously studied topics\nin financial markets. Recently, deep hedging has been proposed as a promising\napproach that uses deep learning to approximate the optimal hedging strategy\nand can handle incomplete markets. However, deep hedging usually requires\nunderlying asset simulations, and it is challenging to select the best model\nfor such simulations. This study proposes a new approach using artificial\nmarket simulations for underlying asset simulations in deep hedging. Artificial\nmarket simulations can replicate the stylized facts of financial markets, and\nthey seem to be a promising approach for deep hedging. We investigate the\neffectiveness of the proposed approach by comparing its results with those of\nthe traditional approach, which uses mathematical finance models such as\nBrownian motion and Heston models for underlying asset simulations. The results\nshow that the proposed approach can achieve almost the same level of\nperformance as the traditional approach without mathematical finance models.\nFinally, we also reveal that the proposed approach has some limitations in\nterms of performance under certain conditions.",
    "categories": [
      "q-fin.CP",
      "cs.AI"
    ],
    "primary_category": "q-fin.CP",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.09462v1",
    "published_date": "2024-04-15 05:11:07 UTC",
    "updated_date": "2024-04-15 05:11:07 UTC"
  },
  {
    "arxiv_id": "2404.09445v1",
    "title": "Exploring Text-to-Motion Generation with Human Preference",
    "authors": [
      "Jenny Sheng",
      "Matthieu Lin",
      "Andrew Zhao",
      "Kevin Pruvost",
      "Yu-Hui Wen",
      "Yangguang Li",
      "Gao Huang",
      "Yong-Jin Liu"
    ],
    "abstract": "This paper presents an exploration of preference learning in text-to-motion\ngeneration. We find that current improvements in text-to-motion generation\nstill rely on datasets requiring expert labelers with motion capture systems.\nInstead, learning from human preference data does not require motion capture\nsystems; a labeler with no expertise simply compares two generated motions.\nThis is particularly efficient because evaluating the model's output is easier\nthan gathering the motion that performs a desired task (e.g. backflip). To\npioneer the exploration of this paradigm, we annotate 3,528 preference pairs\ngenerated by MotionGPT, marking the first effort to investigate various\nalgorithms for learning from preference data. In particular, our exploration\nhighlights important design choices when using preference data. Additionally,\nour experimental results show that preference learning has the potential to\ngreatly improve current text-to-motion generative models. Our code and dataset\nare publicly available at\nhttps://github.com/THU-LYJ-Lab/InstructMotion}{https://github.com/THU-LYJ-Lab/InstructMotion\nto further facilitate research in this area.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CVPR 2024 HuMoGen Workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.09445v1",
    "published_date": "2024-04-15 04:14:42 UTC",
    "updated_date": "2024-04-15 04:14:42 UTC"
  },
  {
    "arxiv_id": "2406.15373v1",
    "title": "Occupation Life Cycle",
    "authors": [
      "Lan Chen",
      "Yufei Ji",
      "Xichen Yao",
      "Hengshu Zhu"
    ],
    "abstract": "This paper explores the evolution of occupations within the context of\nindustry and technology life cycles, highlighting the critical yet\nunderexplored intersection between occupational trends and broader economic\ndynamics. Introducing the Occupation Life Cycle (OLC) model, we delineate five\nstages (i.e., growth, peak, fluctuation, maturity, and decline) to\nsystematically explore the trajectory of occupations. Utilizing job posting\ndata from one of China's largest recruitment platforms as a novel proxy, our\nstudy meticulously tracks the fluctuations and emerging trends in the labor\nmarket from 2018 to 2023. Through a detailed examination of representative\nroles, such as short video operators and data analysts, alongside emerging\noccupations within the artificial intelligence (AI) sector, our findings\nallocate occupations to specific life cycle stages, revealing insightful\npatterns of occupational development and decline. Our findings offer a unique\nperspective on the interplay between occupational evolution and economic\nfactors, with a particular focus on the rapidly changing Chinese labor market.\nThis study not only contributes to the theoretical understanding of OLC but\nalso provides practical insights for policymakers, educators, and industry\nleaders facing the challenges of workforce planning and development in the face\nof technological advancement and market shifts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15373v1",
    "published_date": "2024-04-15 03:13:51 UTC",
    "updated_date": "2024-04-15 03:13:51 UTC"
  },
  {
    "arxiv_id": "2404.09432v1",
    "title": "The 8th AI City Challenge",
    "authors": [
      "Shuo Wang",
      "David C. Anastasiu",
      "Zheng Tang",
      "Ming-Ching Chang",
      "Yue Yao",
      "Liang Zheng",
      "Mohammed Shaiqur Rahman",
      "Meenakshi S. Arya",
      "Anuj Sharma",
      "Pranamesh Chakraborty",
      "Sanjita Prajapati",
      "Quan Kong",
      "Norimasa Kobori",
      "Munkhjargal Gochoo",
      "Munkh-Erdene Otgonbold",
      "Fady Alnajjar",
      "Ganzorig Batnasan",
      "Ping-Yang Chen",
      "Jun-Wei Hsieh",
      "Xunlei Wu",
      "Sameer Satish Pusegaonkar",
      "Yizhou Wang",
      "Sujit Biswas",
      "Rama Chellappa"
    ],
    "abstract": "The eighth AI City Challenge highlighted the convergence of computer vision\nand artificial intelligence in areas like retail, warehouse settings, and\nIntelligent Traffic Systems (ITS), presenting significant research\nopportunities. The 2024 edition featured five tracks, attracting unprecedented\ninterest from 726 teams in 47 countries and regions. Track 1 dealt with\nmulti-target multi-camera (MTMC) people tracking, highlighting significant\nenhancements in camera count, character number, 3D annotation, and camera\nmatrices, alongside new rules for 3D tracking and online tracking algorithm\nencouragement. Track 2 introduced dense video captioning for traffic safety,\nfocusing on pedestrian accidents using multi-camera feeds to improve insights\nfor insurance and prevention. Track 3 required teams to classify driver actions\nin a naturalistic driving analysis. Track 4 explored fish-eye camera analytics\nusing the FishEye8K dataset. Track 5 focused on motorcycle helmet rule\nviolation detection. The challenge utilized two leaderboards to showcase\nmethods, with participants setting new benchmarks, some surpassing existing\nstate-of-the-art achievements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Summary of the 8th AI City Challenge Workshop in conjunction with\n  CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09432v1",
    "published_date": "2024-04-15 03:12:17 UTC",
    "updated_date": "2024-04-15 03:12:17 UTC"
  },
  {
    "arxiv_id": "2404.09405v2",
    "title": "Few-shot Name Entity Recognition on StackOverflow",
    "authors": [
      "Xinwei Chen",
      "Kun Li",
      "Tianyou Song",
      "Jiangjian Guo"
    ],
    "abstract": "StackOverflow, with its vast question repository and limited labeled\nexamples, raise an annotation challenge for us. We address this gap by\nproposing RoBERTa+MAML, a few-shot named entity recognition (NER) method\nleveraging meta-learning. Our approach, evaluated on the StackOverflow NER\ncorpus (27 entity types), achieves a 5% F1 score improvement over the baseline.\nWe improved the results further domain-specific phrase processing enhance\nresults.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.09405v2",
    "published_date": "2024-04-15 01:43:14 UTC",
    "updated_date": "2024-04-28 01:58:10 UTC"
  },
  {
    "arxiv_id": "2404.09402v1",
    "title": "Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes",
    "authors": [
      "Haoming Yang",
      "Ali Hasan",
      "Yuting Ng",
      "Vahid Tarokh"
    ],
    "abstract": "McKean-Vlasov stochastic differential equations (MV-SDEs) provide a\nmathematical description of the behavior of an infinite number of interacting\nparticles by imposing a dependence on the particle density. As such, we study\nthe influence of explicitly including distributional information in the\nparameterization of the SDE. We propose a series of semi-parametric methods for\nrepresenting MV-SDEs, and corresponding estimators for inferring parameters\nfrom data based on the properties of the MV-SDE. We analyze the characteristics\nof the different architectures and estimators, and consider their applicability\nin relevant machine learning problems. We empirically compare the performance\nof the different architectures and estimators on real and synthetic datasets\nfor time series and probabilistic modeling. The results suggest that explicitly\nincluding distributional dependence in the parameterization of the SDE is\neffective in modeling temporal data with interaction under an exchangeability\nassumption while maintaining strong performance for standard It\\^o-SDEs due to\nthe richer class of probability flows associated with MV-SDEs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Appears in AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.09402v1",
    "published_date": "2024-04-15 01:28:16 UTC",
    "updated_date": "2024-04-15 01:28:16 UTC"
  },
  {
    "arxiv_id": "2404.09401v2",
    "title": "Watermark-embedded Adversarial Examples for Copyright Protection against Diffusion Models",
    "authors": [
      "Peifei Zhu",
      "Tsubasa Takahashi",
      "Hirokatsu Kataoka"
    ],
    "abstract": "Diffusion Models (DMs) have shown remarkable capabilities in various\nimage-generation tasks. However, there are growing concerns that DMs could be\nused to imitate unauthorized creations and thus raise copyright issues. To\naddress this issue, we propose a novel framework that embeds personal\nwatermarks in the generation of adversarial examples. Such examples can force\nDMs to generate images with visible watermarks and prevent DMs from imitating\nunauthorized images. We construct a generator based on conditional adversarial\nnetworks and design three losses (adversarial loss, GAN loss, and perturbation\nloss) to generate adversarial examples that have subtle perturbation but can\neffectively attack DMs to prevent copyright violations. Training a generator\nfor a personal watermark by our method only requires 5-10 samples within 2-3\nminutes, and once the generator is trained, it can generate adversarial\nexamples with that watermark significantly fast (0.2s per image). We conduct\nextensive experiments in various conditional image-generation scenarios.\nCompared to existing methods that generate images with chaotic textures, our\nmethod adds visible watermarks on the generated images, which is a more\nstraightforward way to indicate copyright violations. We also observe that our\nadversarial examples exhibit good transferability across unknown generative\nmodels. Therefore, this work provides a simple yet powerful way to protect\ncopyright from DM-based imitation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "updated references",
    "pdf_url": "http://arxiv.org/pdf/2404.09401v2",
    "published_date": "2024-04-15 01:27:07 UTC",
    "updated_date": "2024-04-19 05:26:28 UTC"
  },
  {
    "arxiv_id": "2404.15353v1",
    "title": "SQUWA: Signal Quality Aware DNN Architecture for Enhanced Accuracy in Atrial Fibrillation Detection from Noisy PPG Signals",
    "authors": [
      "Runze Yan",
      "Cheng Ding",
      "Ran Xiao",
      "Aleksandr Fedorov",
      "Randall J Lee",
      "Fadi Nahab",
      "Xiao Hu"
    ],
    "abstract": "Atrial fibrillation (AF), a common cardiac arrhythmia, significantly\nincreases the risk of stroke, heart disease, and mortality.\nPhotoplethysmography (PPG) offers a promising solution for continuous AF\nmonitoring, due to its cost efficiency and integration into wearable devices.\nNonetheless, PPG signals are susceptible to corruption from motion artifacts\nand other factors often encountered in ambulatory settings. Conventional\napproaches typically discard corrupted segments or attempt to reconstruct\noriginal signals, allowing for the use of standard machine learning techniques.\nHowever, this reduces dataset size and introduces biases, compromising\nprediction accuracy and the effectiveness of continuous monitoring. We propose\na novel deep learning model, Signal Quality Weighted Fusion of Attentional\nConvolution and Recurrent Neural Network (SQUWA), designed to learn how to\nretain accurate predictions from partially corrupted PPG. Specifically, SQUWA\ninnovatively integrates an attention mechanism that directly considers signal\nquality during the learning process, dynamically adjusting the weights of time\nseries segments based on their quality. This approach enhances the influence of\nhigher-quality segments while reducing that of lower-quality ones, effectively\nutilizing partially corrupted segments. This approach represents a departure\nfrom the conventional methods that exclude such segments, enabling the\nutilization of a broader range of data, which has great implications for less\ndisruption when monitoring of AF risks and more accurate estimation of AF\nburdens. Our extensive experiments show that SQUWA outperform existing\nPPG-based models, achieving the highest AUCPR of 0.89 with label noise\nmitigation. This also exceeds the 0.86 AUCPR of models trained with using both\nelectrocardiogram (ECG) and PPG data.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "15 pages; 9 figures; 2024 Conference on Health, Inference, and\n  Learning (CHIL)",
    "pdf_url": "http://arxiv.org/pdf/2404.15353v1",
    "published_date": "2024-04-15 01:07:08 UTC",
    "updated_date": "2024-04-15 01:07:08 UTC"
  },
  {
    "arxiv_id": "2404.09391v1",
    "title": "Privacy at a Price: Exploring its Dual Impact on AI Fairness",
    "authors": [
      "Mengmeng Yang",
      "Ming Ding",
      "Youyang Qu",
      "Wei Ni",
      "David Smith",
      "Thierry Rakotoarivelo"
    ],
    "abstract": "The worldwide adoption of machine learning (ML) and deep learning models,\nparticularly in critical sectors, such as healthcare and finance, presents\nsubstantial challenges in maintaining individual privacy and fairness. These\ntwo elements are vital to a trustworthy environment for learning systems. While\nnumerous studies have concentrated on protecting individual privacy through\ndifferential privacy (DP) mechanisms, emerging research indicates that\ndifferential privacy in machine learning models can unequally impact separate\ndemographic subgroups regarding prediction accuracy. This leads to a fairness\nconcern, and manifests as biased performance. Although the prevailing view is\nthat enhancing privacy intensifies fairness disparities, a smaller, yet\nsignificant, subset of research suggests the opposite view. In this article,\nwith extensive evaluation results, we demonstrate that the impact of\ndifferential privacy on fairness is not monotonous. Instead, we observe that\nthe accuracy disparity initially grows as more DP noise (enhanced privacy) is\nadded to the ML process, but subsequently diminishes at higher privacy levels\nwith even more noise. Moreover, implementing gradient clipping in the\ndifferentially private stochastic gradient descent ML method can mitigate the\nnegative impact of DP noise on fairness. This mitigation is achieved by\nmoderating the disparity growth through a lower clipping threshold.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.09391v1",
    "published_date": "2024-04-15 00:23:41 UTC",
    "updated_date": "2024-04-15 00:23:41 UTC"
  },
  {
    "arxiv_id": "2404.09387v3",
    "title": "RankCLIP: Ranking-Consistent Language-Image Pretraining",
    "authors": [
      "Yiming Zhang",
      "Zhuokai Zhao",
      "Zhaorun Chen",
      "Zhili Feng",
      "Zenghui Ding",
      "Yining Sun"
    ],
    "abstract": "Self-supervised contrastive learning models, such as CLIP, have set new\nbenchmarks for vision-language models in many downstream tasks. However, their\ndependency on rigid one-to-one mappings overlooks the complex and often\nmultifaceted relationships between and within texts and images. To this end, we\nintroduce RankCLIP, a novel pre-training method that extends beyond the rigid\none-to-one matching framework of CLIP and its variants. By extending the\ntraditional pair-wise loss to list-wise, and leveraging both in-modal and\ncross-modal ranking consistency, RankCLIP improves the alignment process,\nenabling it to capture the nuanced many-to-many relationships between and\nwithin each modality. Through comprehensive experiments, we demonstrate the\neffectiveness of RankCLIP in various downstream tasks, notably achieving\nsignificant gains in zero-shot classifications over state-of-the-art methods,\nunderscoring the importance of this enhanced learning process.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and model checkpoints are available at\n  https://github.com/Jam1ezhang/RankCLIP",
    "pdf_url": "http://arxiv.org/pdf/2404.09387v3",
    "published_date": "2024-04-15 00:12:27 UTC",
    "updated_date": "2025-03-24 14:48:12 UTC"
  }
]