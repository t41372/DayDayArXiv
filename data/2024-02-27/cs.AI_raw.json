[
  {
    "arxiv_id": "2402.17934v2",
    "title": "Inducing Generalization across Languages and Tasks using Featurized Low-Rank Mixtures",
    "authors": [
      "Chu-Cheng Lin",
      "Xinyi Wang",
      "Jonathan H. Clark",
      "Han Lu",
      "Yun Zhu",
      "Chenxi Whitehouse",
      "Hongkun Yu"
    ],
    "abstract": "Adapting pretrained large language models (LLMs) to various downstream tasks\nin tens or hundreds of human languages is computationally expensive.\nParameter-efficient fine-tuning (PEFT) significantly reduces the adaptation\ncost, by tuning only a small amount of parameters. However, common PEFT methods\nLoRA (Hu et al., 2022) suffer from suboptimal performance on diverse dataset\nmixtures, due to aggressive parameter tying and negative interference among\ndifferent datasets. In this work, we propose Featurized Low-rank Mixtures\n(FLix), a novel PEFT method designed for effective multitask multilingual\nadaptation. FLix associates each unique dataset feature, such as the dataset's\nlanguage or task, with its own low-rank weight update parameters. By composing\nfeature-specific parameters for each dataset, FLix can accommodate diverse\ndataset mixtures and generalize better to unseen datasets. Our experiments show\nthat FLix leads to significant improvements over a variety of tasks for both\nsupervised learning and zero-shot settings with gains of up to $14.2$ inexact\nmatch points in zero-shot semantic parsing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Revised version",
    "pdf_url": "http://arxiv.org/pdf/2402.17934v2",
    "published_date": "2024-02-27 23:12:45 UTC",
    "updated_date": "2024-08-01 05:52:51 UTC"
  },
  {
    "arxiv_id": "2402.17930v1",
    "title": "Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning",
    "authors": [
      "Tan Zhi-Xuan",
      "Lance Ying",
      "Vikash Mansinghka",
      "Joshua B. Tenenbaum"
    ],
    "abstract": "People often give instructions whose meaning is ambiguous without further\ncontext, expecting that their actions or goals will disambiguate their\nintentions. How can we build assistive agents that follow such instructions in\na flexible, context-sensitive manner? This paper introduces cooperative\nlanguage-guided inverse plan search (CLIPS), a Bayesian agent architecture for\npragmatic instruction following and goal assistance. Our agent assists a human\nby modeling them as a cooperative planner who communicates joint plans to the\nassistant, then performs multimodal Bayesian inference over the human's goal\nfrom actions and language, using large language models (LLMs) to evaluate the\nlikelihood of an instruction given a hypothesized plan. Given this posterior,\nour assistant acts to minimize expected goal achievement cost, enabling it to\npragmatically follow ambiguous instructions and provide effective assistance\neven when uncertain about the goal. We evaluate these capabilities in two\ncooperative planning domains (Doors, Keys & Gems and VirtualHome), finding that\nCLIPS significantly outperforms GPT-4V, LLM-based literal instruction following\nand unimodal inverse planning in both accuracy and helpfulness, while closely\nmatching the inferences and assistive judgments provided by human raters.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAMAS 2024. 8 pages (excl. references), 5 figures/tables.\n  (Appendix: 8 pages, 8 figures/tables). Code available at:\n  https://github.com/probcomp/CLIPS.jl",
    "pdf_url": "http://arxiv.org/pdf/2402.17930v1",
    "published_date": "2024-02-27 23:06:53 UTC",
    "updated_date": "2024-02-27 23:06:53 UTC"
  },
  {
    "arxiv_id": "2402.17916v3",
    "title": "Adversarial Math Word Problem Generation",
    "authors": [
      "Roy Xie",
      "Chengxuan Huang",
      "Junlin Wang",
      "Bhuwan Dhingra"
    ],
    "abstract": "Large language models (LLMs) have significantly transformed the educational\nlandscape. As current plagiarism detection tools struggle to keep pace with\nLLMs' rapid advancements, the educational community faces the challenge of\nassessing students' true problem-solving abilities in the presence of LLMs. In\nthis work, we explore a new paradigm for ensuring fair evaluation -- generating\nadversarial examples which preserve the structure and difficulty of the\noriginal questions aimed for assessment, but are unsolvable by LLMs. Focusing\non the domain of math word problems, we leverage abstract syntax trees to\nstructurally generate adversarial examples that cause LLMs to produce incorrect\nanswers by simply editing the numeric values in the problems. We conduct\nexperiments on various open- and closed-source LLMs, quantitatively and\nqualitatively demonstrating that our method significantly degrades their math\nproblem-solving ability. We identify shared vulnerabilities among LLMs and\npropose a cost-effective approach to attack high-cost models. Additionally, we\nconduct automatic analysis to investigate the cause of failure, providing\nfurther insights into the limitations of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code/data: https://github.com/ruoyuxie/adversarial_mwps_generation",
    "pdf_url": "http://arxiv.org/pdf/2402.17916v3",
    "published_date": "2024-02-27 22:07:52 UTC",
    "updated_date": "2024-06-15 22:36:20 UTC"
  },
  {
    "arxiv_id": "2402.17914v2",
    "title": "Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers",
    "authors": [
      "Roy Xie",
      "Orevaoghene Ahia",
      "Yulia Tsvetkov",
      "Antonios Anastasopoulos"
    ],
    "abstract": "Identifying linguistic differences between dialects of a language often\nrequires expert knowledge and meticulous human analysis. This is largely due to\nthe complexity and nuance involved in studying various dialects. We present a\nnovel approach to extract distinguishing lexical features of dialects by\nutilizing interpretable dialect classifiers, even in the absence of human\nexperts. We explore both post-hoc and intrinsic approaches to interpretability,\nconduct experiments on Mandarin, Italian, and Low Saxon, and experimentally\ndemonstrate that our method successfully identifies key language-specific\nlexical features that contribute to dialectal variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code is available at\n  https://github.com/ruoyuxie/interpretable_dialect_classifier",
    "pdf_url": "http://arxiv.org/pdf/2402.17914v2",
    "published_date": "2024-02-27 22:06:55 UTC",
    "updated_date": "2024-03-23 20:21:04 UTC"
  },
  {
    "arxiv_id": "2402.17913v1",
    "title": "Using AI libraries for Incompressible Computational Fluid Dynamics",
    "authors": [
      "Boyang Chen",
      "Claire E. Heaney",
      "Christopher C. Pain"
    ],
    "abstract": "Recently, there has been a huge effort focused on developing highly efficient\nopen source libraries to perform Artificial Intelligence (AI) related\ncomputations on different computer architectures (for example, CPUs, GPUs and\nnew AI processors). This has not only made the algorithms based on these\nlibraries highly efficient and portable between different architectures, but\nalso has substantially simplified the entry barrier to develop methods using\nAI. Here, we present a novel methodology to bring the power of both AI software\nand hardware into the field of numerical modelling by repurposing AI methods,\nsuch as Convolutional Neural Networks (CNNs), for the standard operations\nrequired in the field of the numerical solution of Partial Differential\nEquations (PDEs). The aim of this work is to bring the high performance,\narchitecture agnosticism and ease of use into the field of the numerical\nsolution of PDEs. We use the proposed methodology to solve the\nadvection-diffusion equation, the non-linear Burgers equation and\nincompressible flow past a bluff body. For the latter, a convolutional neural\nnetwork is used as a multigrid solver in order to enforce the incompressibility\nconstraint. We show that the presented methodology can solve all these problems\nusing repurposed AI libraries in an efficient way, and presents a new avenue to\nexplore in the development of methods to solve PDEs and Computational Fluid\nDynamics problems with implicit methods.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "24 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.17913v1",
    "published_date": "2024-02-27 22:00:50 UTC",
    "updated_date": "2024-02-27 22:00:50 UTC"
  },
  {
    "arxiv_id": "2402.17896v1",
    "title": "Researchy Questions: A Dataset of Multi-Perspective, Decompositional Questions for LLM Web Agents",
    "authors": [
      "Corby Rosset",
      "Ho-Lam Chung",
      "Guanghui Qin",
      "Ethan C. Chau",
      "Zhuo Feng",
      "Ahmed Awadallah",
      "Jennifer Neville",
      "Nikhil Rao"
    ],
    "abstract": "Existing question answering (QA) datasets are no longer challenging to most\npowerful Large Language Models (LLMs). Traditional QA benchmarks like TriviaQA,\nNaturalQuestions, ELI5 and HotpotQA mainly study ``known unknowns'' with clear\nindications of both what information is missing, and how to find it to answer\nthe question. Hence, good performance on these benchmarks provides a false\nsense of security. A yet unmet need of the NLP community is a bank of\nnon-factoid, multi-perspective questions involving a great deal of unclear\ninformation needs, i.e. ``unknown uknowns''. We claim we can find such\nquestions in search engine logs, which is surprising because most\nquestion-intent queries are indeed factoid. We present Researchy Questions, a\ndataset of search engine queries tediously filtered to be non-factoid,\n``decompositional'' and multi-perspective. We show that users spend a lot of\n``effort'' on these questions in terms of signals like clicks and session\nlength, and that they are also challenging for GPT-4. We also show that ``slow\nthinking'' answering techniques, like decomposition into sub-questions shows\nbenefit over answering directly. We release $\\sim$ 100k Researchy Questions,\nalong with the Clueweb22 URLs that were clicked.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17896v1",
    "published_date": "2024-02-27 21:27:16 UTC",
    "updated_date": "2024-02-27 21:27:16 UTC"
  },
  {
    "arxiv_id": "2402.18599v2",
    "title": "Meta-Task: A Method-Agnostic Framework for Learning to Regularize in Few-Shot Learning",
    "authors": [
      "Mohammad Rostami",
      "Atik Faysal",
      "Huaxia Wang",
      "Avimanyu Sahoo"
    ],
    "abstract": "Overfitting is a significant challenge in Few-Shot Learning (FSL), where\nmodels trained on small, variable datasets tend to memorize rather than\ngeneralize to unseen tasks. Regularization is crucial in FSL to prevent\noverfitting and enhance generalization performance. To address this issue, we\nintroduce Meta-Task, a novel, method-agnostic framework that leverages both\nlabeled and unlabeled data to enhance generalization through auxiliary tasks\nfor regularization. Specifically, Meta-Task introduces a Task-Decoder, which is\na simple example of the broader framework that refines hidden representations\nby reconstructing input images from embeddings, effectively mitigating\noverfitting.\n  Our framework's method-agnostic design ensures its broad applicability across\nvarious FSL settings. We validate Meta-Task's effectiveness on standard\nbenchmarks, including Mini-ImageNet, Tiered-ImageNet, and FC100, where it\nconsistently improves existing state-of-the-art meta-learning techniques,\ndemonstrating superior performance, faster convergence, reduced generalization\nerror, and lower variance-all without extensive hyperparameter tuning. These\nresults underline Meta-Task's practical applicability and efficiency in\nreal-world, resource-constrained scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18599v2",
    "published_date": "2024-02-27 21:15:40 UTC",
    "updated_date": "2025-02-26 23:07:40 UTC"
  },
  {
    "arxiv_id": "2402.17888v1",
    "title": "ConjNorm: Tractable Density Estimation for Out-of-Distribution Detection",
    "authors": [
      "Bo Peng",
      "Yadan Luo",
      "Yonggang Zhang",
      "Yixuan Li",
      "Zhen Fang"
    ],
    "abstract": "Post-hoc out-of-distribution (OOD) detection has garnered intensive attention\nin reliable machine learning. Many efforts have been dedicated to deriving\nscore functions based on logits, distances, or rigorous data distribution\nassumptions to identify low-scoring OOD samples. Nevertheless, these estimate\nscores may fail to accurately reflect the true data density or impose\nimpractical constraints. To provide a unified perspective on density-based\nscore design, we propose a novel theoretical framework grounded in Bregman\ndivergence, which extends distribution considerations to encompass an\nexponential family of distributions. Leveraging the conjugation constraint\nrevealed in our theorem, we introduce a \\textsc{ConjNorm} method, reframing\ndensity function design as a search for the optimal norm coefficient $p$\nagainst the given dataset. In light of the computational challenges of\nnormalization, we devise an unbiased and analytically tractable estimator of\nthe partition function using the Monte Carlo-based importance sampling\ntechnique. Extensive experiments across OOD detection benchmarks empirically\ndemonstrate that our proposed \\textsc{ConjNorm} has established a new\nstate-of-the-art in a variety of OOD detection setups, outperforming the\ncurrent best method by up to 13.25$\\%$ and 28.19$\\%$ (FPR95) on CIFAR-100 and\nImageNet-1K, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR24 poster",
    "pdf_url": "http://arxiv.org/pdf/2402.17888v1",
    "published_date": "2024-02-27 21:02:47 UTC",
    "updated_date": "2024-02-27 21:02:47 UTC"
  },
  {
    "arxiv_id": "2402.17862v3",
    "title": "REPrune: Channel Pruning via Kernel Representative Selection",
    "authors": [
      "Mincheol Park",
      "Dongjin Kim",
      "Cheonjun Park",
      "Yuna Park",
      "Gyeong Eun Gong",
      "Won Woo Ro",
      "Suhyun Kim"
    ],
    "abstract": "Channel pruning is widely accepted to accelerate modern convolutional neural\nnetworks (CNNs). The resulting pruned model benefits from its immediate\ndeployment on general-purpose software and hardware resources. However, its\nlarge pruning granularity, specifically at the unit of a convolution filter,\noften leads to undesirable accuracy drops due to the inflexibility of deciding\nhow and where to introduce sparsity to the CNNs. In this paper, we propose\nREPrune, a novel channel pruning technique that emulates kernel pruning, fully\nexploiting the finer but structured granularity. REPrune identifies similar\nkernels within each channel using agglomerative clustering. Then, it selects\nfilters that maximize the incorporation of kernel representatives while\noptimizing the maximum cluster coverage problem. By integrating with a\nsimultaneous training-pruning paradigm, REPrune promotes efficient, progressive\npruning throughout training CNNs, avoiding the conventional\ntrain-prune-finetune sequence. Experimental results highlight that REPrune\nperforms better in computer vision tasks than existing methods, effectively\nachieving a balance between acceleration ratio and performance retention.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17862v3",
    "published_date": "2024-02-27 19:54:30 UTC",
    "updated_date": "2024-03-08 07:03:57 UTC"
  },
  {
    "arxiv_id": "2402.17853v2",
    "title": "Latent Neural PDE Solver: a reduced-order modelling framework for partial differential equations",
    "authors": [
      "Zijie Li",
      "Saurabh Patil",
      "Francis Ogoke",
      "Dule Shu",
      "Wilson Zhen",
      "Michael Schneier",
      "John R. Buchanan, Jr.",
      "Amir Barati Farimani"
    ],
    "abstract": "Neural networks have shown promising potential in accelerating the numerical\nsimulation of systems governed by partial differential equations (PDEs).\nDifferent from many existing neural network surrogates operating on\nhigh-dimensional discretized fields, we propose to learn the dynamics of the\nsystem in the latent space with much coarser discretizations. In our proposed\nframework - Latent Neural PDE Solver (LNS), a non-linear autoencoder is first\ntrained to project the full-order representation of the system onto the\nmesh-reduced space, then a temporal model is trained to predict the future\nstate in this mesh-reduced space. This reduction process simplifies the\ntraining of the temporal model by greatly reducing the computational cost\naccompanying a fine discretization. We study the capability of the proposed\nframework and several other popular neural PDE solvers on various types of\nsystems including single-phase and multi-phase flows along with varying system\nparameters. We showcase that it has competitive accuracy and efficiency\ncompared to the neural PDE solver that operates on full-order space.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17853v2",
    "published_date": "2024-02-27 19:36:27 UTC",
    "updated_date": "2025-01-08 00:00:44 UTC"
  },
  {
    "arxiv_id": "2403.00828v1",
    "title": "Deep Learning Detection Method for Large Language Models-Generated Scientific Content",
    "authors": [
      "Bushra Alhijawi",
      "Rawan Jarrar",
      "Aseel AbuAlRub",
      "Arwa Bader"
    ],
    "abstract": "Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual\ncontent is written and communicated. These models have the potential to\ngenerate scientific content that is indistinguishable from that written by\nhumans. Hence, LLMs carry severe consequences for the scientific community,\nwhich relies on the integrity and reliability of publications. This research\npaper presents a novel ChatGPT-generated scientific text detection method,\nAI-Catcher. AI-Catcher integrates two deep learning models, multilayer\nperceptron (MLP) and convolutional neural networks (CNN). The MLP learns the\nfeature representations of the linguistic and statistical features. The CNN\nextracts high-level representations of the sequential patterns from the textual\ncontent. AI-Catcher is a multimodal model that fuses hidden patterns derived\nfrom MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset\nis collected to enhance AI-generated text detection tools, AIGTxt. AIGTxt\ncontains 3000 records collected from published academic articles across ten\ndomains and divided into three classes: Human-written, ChatGPT-generated, and\nMixed text. Several experiments are conducted to evaluate the performance of\nAI-Catcher. The comparative results demonstrate the capability of AI-Catcher to\ndistinguish between human-written and ChatGPT-generated scientific text more\naccurately than alternative methods. On average, AI-Catcher improved accuracy\nby 37.4%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00828v1",
    "published_date": "2024-02-27 19:16:39 UTC",
    "updated_date": "2024-02-27 19:16:39 UTC"
  },
  {
    "arxiv_id": "2403.00827v1",
    "title": "Self-Refinement of Language Models from External Proxy Metrics Feedback",
    "authors": [
      "Keshav Ramji",
      "Young-Suk Lee",
      "Ramón Fernandez Astudillo",
      "Md Arafat Sultan",
      "Tahira Naseem",
      "Asim Munawar",
      "Radu Florian",
      "Salim Roukos"
    ],
    "abstract": "It is often desirable for Large Language Models (LLMs) to capture multiple\nobjectives when providing a response. In document-grounded response generation,\nfor example, agent responses are expected to be relevant to a user's query\nwhile also being grounded in a given document. In this paper, we introduce\nProxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine\nits own initial response along key dimensions of quality guided by external\nmetrics feedback, yielding an overall better final response. ProMiSe leverages\nfeedback on response quality through principle-specific proxy metrics, and\niteratively refines its response one principle at a time. We apply ProMiSe to\nopen source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its\nperformance on document-grounded question answering datasets, MultiDoc2Dial and\nQuAC, demonstrating that self-refinement improves response quality. We further\nshow that fine-tuning Llama-2-13B-Chat on the synthetic dialogue data generated\nby ProMiSe yields significant performance improvements over the zero-shot\nbaseline as well as a supervised fine-tuned model on human annotated data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00827v1",
    "published_date": "2024-02-27 19:13:01 UTC",
    "updated_date": "2024-02-27 19:13:01 UTC"
  },
  {
    "arxiv_id": "2402.17840v3",
    "title": "Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems",
    "authors": [
      "Zhenting Qi",
      "Hanlin Zhang",
      "Eric Xing",
      "Sham Kakade",
      "Himabindu Lakkaraju"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) improves pre-trained models by\nincorporating external knowledge at test time to enable customized adaptation.\nWe study the risk of datastore leakage in Retrieval-In-Context RAG Language\nModels (LMs). We show that an adversary can exploit LMs' instruction-following\ncapabilities to easily extract text data verbatim from the datastore of RAG\nsystems built with instruction-tuned LMs via prompt injection. The\nvulnerability exists for a wide range of modern LMs that span Llama2,\nMistral/Mixtral, Vicuna, SOLAR, WizardLM, Qwen1.5, and Platypus2, and the\nexploitability exacerbates as the model size scales up. We also study multiple\neffects of RAG setup on the extractability of data, indicating that following\nunexpected instructions to regurgitate data can be an outcome of failure in\neffectively utilizing contexts for modern LMs, and further show that such\nvulnerability can be greatly mitigated by position bias elimination strategies.\nExtending our study to production RAG models GPTs, we design an attack that can\ncause datastore leakage with a 100% success rate on 25 randomly selected\ncustomized GPTs with at most 2 queries, and we extract text data verbatim at a\nrate of 41% from a book of 77,000 words and 3% from a corpus of 1,569,000 words\nby prompting the GPTs with only 100 queries generated by themselves.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17840v3",
    "published_date": "2024-02-27 19:08:05 UTC",
    "updated_date": "2024-10-06 21:25:41 UTC"
  },
  {
    "arxiv_id": "2402.17826v3",
    "title": "Prediction-Powered Ranking of Large Language Models",
    "authors": [
      "Ivi Chatzi",
      "Eleni Straitouri",
      "Suhas Thejaswi",
      "Manuel Gomez Rodriguez"
    ],
    "abstract": "Large language models are often ranked according to their level of alignment\nwith human preferences -- a model is better than other models if its outputs\nare more frequently preferred by humans. One of the popular ways to elicit\nhuman preferences utilizes pairwise comparisons between the outputs provided by\ndifferent models to the same inputs. However, since gathering pairwise\ncomparisons by humans is costly and time-consuming, it has become a common\npractice to gather pairwise comparisons by a strong large language model -- a\nmodel strongly aligned with human preferences. Surprisingly, practitioners\ncannot currently measure the uncertainty that any mismatch between human and\nmodel preferences may introduce in the constructed rankings. In this work, we\ndevelop a statistical framework to bridge this gap. Given a (small) set of\npairwise comparisons by humans and a large set of pairwise comparisons by a\nmodel, our framework provides a rank-set -- a set of possible ranking positions\n-- for each of the models under comparison. Moreover, it guarantees that, with\na probability greater than or equal to a user-specified value, the rank-sets\ncover the true ranking consistent with the distribution of human pairwise\npreferences asymptotically. Using pairwise comparisons made by humans in the\nLMSYS Chatbot Arena platform and pairwise comparisons made by three strong\nlarge language models, we empirically demonstrate the effectivity of our\nframework and show that the rank-sets constructed using only pairwise\ncomparisons by the strong large language models are often inconsistent with\n(the distribution of) human pairwise preferences.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17826v3",
    "published_date": "2024-02-27 19:00:01 UTC",
    "updated_date": "2024-12-04 16:03:04 UTC"
  },
  {
    "arxiv_id": "2402.17768v2",
    "title": "Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning",
    "authors": [
      "Xiaoyu Zhang",
      "Matthew Chang",
      "Pranav Kumar",
      "Saurabh Gupta"
    ],
    "abstract": "A common failure mode for policies trained with imitation is compounding\nexecution errors at test time. When the learned policy encounters states that\nare not present in the expert demonstrations, the policy fails, leading to\ndegenerate behavior. The Dataset Aggregation, or DAgger approach to this\nproblem simply collects more data to cover these failure states. However, in\npractice, this is often prohibitively expensive. In this work, we propose\nDiffusion Meets DAgger (DMD), a method to reap the benefits of DAgger without\nthe cost for eye-in-hand imitation learning problems. Instead of collecting new\nsamples to cover out-of-distribution states, DMD uses recent advances in\ndiffusion models to synthesize these samples. This leads to robust performance\nfrom few demonstrations. We compare DMD against behavior cloning baseline\nacross four tasks: pushing, stacking, pouring, and shirt hanging. In pushing,\nDMD achieves 80% success rate with as few as 8 expert demonstrations, where\nnaive behavior cloning reaches only 20%. In stacking, DMD succeeds on average\n92% of the time across 5 cups, versus 40% for BC. When pouring coffee beans,\nDMD transfers to another cup successfully 80% of the time. Finally, DMD attains\n90% success rate for hanging shirt on a clothing rack.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by Robotics: Science and Systems (RSS) 2024. project website\n  with video, see https://sites.google.com/view/diffusion-meets-dagger",
    "pdf_url": "http://arxiv.org/pdf/2402.17768v2",
    "published_date": "2024-02-27 18:59:18 UTC",
    "updated_date": "2024-06-05 17:33:56 UTC"
  },
  {
    "arxiv_id": "2402.17767v3",
    "title": "Opening Articulated Structures in the Real World",
    "authors": [
      "Arjun Gupta",
      "Michelle Zhang",
      "Rishik Sathua",
      "Saurabh Gupta"
    ],
    "abstract": "What does it take to build mobile manipulation systems that can competently\noperate on previously unseen objects in previously unseen environments? This\nwork answers this question using opening of articulated structures as a mobile\nmanipulation testbed. Specifically, our focus is on the end-to-end performance\non this task without any privileged information, i.e. the robot starts at a\nlocation with the novel target articulated object in view, and has to approach\nthe object and successfully open it. We first develop a system for this task,\nand then conduct 100+ end-to-end system tests across 13 real world test sites.\nOur large-scale study reveals a number of surprising findings: a) modular\nsystems outperform end-to-end learned systems for this task, even when the\nend-to-end learned systems are trained on 1000+ demonstrations, b) perception,\nand not precise end-effector control, is the primary bottleneck to task\nsuccess, and c) state-of-the-art articulation parameter estimation models\ndeveloped in isolation struggle when faced with robot-centric viewpoints.\nOverall, our findings highlight the limitations of developing components of the\npipeline in isolation and underscore the need for system-level research,\nproviding a pragmatic roadmap for building generalizable mobile manipulation\nsystems. Videos, code, and models are available on the project website:\nhttps://arjung128.github.io/opening-articulated-structures/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to RSS 2025. Project webpage:\n  https://arjung128.github.io/opening-articulated-structures/",
    "pdf_url": "http://arxiv.org/pdf/2402.17767v3",
    "published_date": "2024-02-27 18:58:54 UTC",
    "updated_date": "2025-05-07 03:38:59 UTC"
  },
  {
    "arxiv_id": "2402.17760v1",
    "title": "Learning to Program Variational Quantum Circuits with Fast Weights",
    "authors": [
      "Samuel Yen-Chi Chen"
    ],
    "abstract": "Quantum Machine Learning (QML) has surfaced as a pioneering framework\naddressing sequential control tasks and time-series modeling. It has\ndemonstrated empirical quantum advantages notably within domains such as\nReinforcement Learning (RL) and time-series prediction. A significant\nadvancement lies in Quantum Recurrent Neural Networks (QRNNs), specifically\ntailored for memory-intensive tasks encompassing partially observable\nenvironments and non-linear time-series prediction. Nevertheless, QRNN-based\nmodels encounter challenges, notably prolonged training duration stemming from\nthe necessity to compute quantum gradients using backpropagation-through-time\n(BPTT). This predicament exacerbates when executing the complete model on\nquantum devices, primarily due to the substantial demand for circuit evaluation\narising from the parameter-shift rule. This paper introduces the Quantum Fast\nWeight Programmers (QFWP) as a solution to the temporal or sequential learning\nchallenge. The QFWP leverages a classical neural network (referred to as the\n'slow programmer') functioning as a quantum programmer to swiftly modify the\nparameters of a variational quantum circuit (termed the 'fast programmer').\nInstead of completely overwriting the fast programmer at each time-step, the\nslow programmer generates parameter changes or updates for the quantum circuit\nparameters. This approach enables the fast programmer to incorporate past\nobservations or information. Notably, the proposed QFWP model achieves learning\nof temporal dependencies without necessitating the use of quantum recurrent\nneural networks. Numerical simulations conducted in this study showcase the\nefficacy of the proposed QFWP model in both time-series prediction and RL\ntasks. The model exhibits performance levels either comparable to or surpassing\nthose achieved by QLSTM-based models.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17760v1",
    "published_date": "2024-02-27 18:53:18 UTC",
    "updated_date": "2024-02-27 18:53:18 UTC"
  },
  {
    "arxiv_id": "2402.17753v1",
    "title": "Evaluating Very Long-Term Conversational Memory of LLM Agents",
    "authors": [
      "Adyasha Maharana",
      "Dong-Ho Lee",
      "Sergey Tulyakov",
      "Mohit Bansal",
      "Francesco Barbieri",
      "Yuwei Fang"
    ],
    "abstract": "Existing works on long-term open-domain dialogues focus on evaluating model\nresponses within contexts spanning no more than five chat sessions. Despite\nadvancements in long-context large language models (LLMs) and retrieval\naugmented generation (RAG) techniques, their efficacy in very long-term\ndialogues remains unexplored. To address this research gap, we introduce a\nmachine-human pipeline to generate high-quality, very long-term dialogues by\nleveraging LLM-based agent architectures and grounding their dialogues on\npersonas and temporal event graphs. Moreover, we equip each agent with the\ncapability of sharing and reacting to images. The generated conversations are\nverified and edited by human annotators for long-range consistency and\ngrounding to the event graphs. Using this pipeline, we collect LoCoMo, a\ndataset of very long-term conversations, each encompassing 300 turns and 9K\ntokens on avg., over up to 35 sessions. Based on LoCoMo, we present a\ncomprehensive evaluation benchmark to measure long-term memory in models,\nencompassing question answering, event summarization, and multi-modal dialogue\ngeneration tasks. Our experimental results indicate that LLMs exhibit\nchallenges in understanding lengthy conversations and comprehending long-range\ntemporal and causal dynamics within dialogues. Employing strategies like\nlong-context LLMs or RAG can offer improvements but these models still\nsubstantially lag behind human performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages; Project page: https://snap-research.github.io/locomo/",
    "pdf_url": "http://arxiv.org/pdf/2402.17753v1",
    "published_date": "2024-02-27 18:42:31 UTC",
    "updated_date": "2024-02-27 18:42:31 UTC"
  },
  {
    "arxiv_id": "2402.17747v5",
    "title": "When Your AIs Deceive You: Challenges of Partial Observability in Reinforcement Learning from Human Feedback",
    "authors": [
      "Leon Lang",
      "Davis Foote",
      "Stuart Russell",
      "Anca Dragan",
      "Erik Jenner",
      "Scott Emmons"
    ],
    "abstract": "Past analyses of reinforcement learning from human feedback (RLHF) assume\nthat the human evaluators fully observe the environment. What happens when\nhuman feedback is based only on partial observations? We formally define two\nfailure cases: deceptive inflation and overjustification. Modeling the human as\nBoltzmann-rational w.r.t. a belief over trajectories, we prove conditions under\nwhich RLHF is guaranteed to result in policies that deceptively inflate their\nperformance, overjustify their behavior to make an impression, or both. Under\nthe new assumption that the human's partial observability is known and\naccounted for, we then analyze how much information the feedback process\nprovides about the return function. We show that sometimes, the human's\nfeedback determines the return function uniquely up to an additive constant,\nbut in other realistic cases, there is irreducible ambiguity. We propose\nexploratory research directions to help tackle these challenges, experimentally\nvalidate both the theoretical concerns and potential mitigations, and caution\nagainst blindly applying RLHF in partially observable settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Advances in Neural Information Processing Systems 37 (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.17747v5",
    "published_date": "2024-02-27 18:32:11 UTC",
    "updated_date": "2024-11-17 12:18:45 UTC"
  },
  {
    "arxiv_id": "2402.17739v2",
    "title": "reBandit: Random Effects based Online RL algorithm for Reducing Cannabis Use",
    "authors": [
      "Susobhan Ghosh",
      "Yongyi Guo",
      "Pei-Yao Hung",
      "Lara Coughlin",
      "Erin Bonar",
      "Inbal Nahum-Shani",
      "Maureen Walton",
      "Susan Murphy"
    ],
    "abstract": "The escalating prevalence of cannabis use, and associated cannabis-use\ndisorder (CUD), poses a significant public health challenge globally. With a\nnotably wide treatment gap, especially among emerging adults (EAs; ages 18-25),\naddressing cannabis use and CUD remains a pivotal objective within the 2030\nUnited Nations Agenda for Sustainable Development Goals (SDG). In this work, we\ndevelop an online reinforcement learning (RL) algorithm called reBandit which\nwill be utilized in a mobile health study to deliver personalized mobile health\ninterventions aimed at reducing cannabis use among EAs. reBandit utilizes\nrandom effects and informative Bayesian priors to learn quickly and efficiently\nin noisy mobile health environments. Moreover, reBandit employs Empirical Bayes\nand optimization techniques to autonomously update its hyper-parameters online.\nTo evaluate the performance of our algorithm, we construct a simulation testbed\nusing data from a prior study, and compare against commonly used algorithms in\nmobile health studies. We show that reBandit performs equally well or better\nthan all the baseline algorithms, and the performance gap widens as population\nheterogeneity increases in the simulation environment, proving its adeptness to\nadapt to diverse population of study participants.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17739v2",
    "published_date": "2024-02-27 18:18:23 UTC",
    "updated_date": "2024-06-11 15:35:20 UTC"
  },
  {
    "arxiv_id": "2402.17736v2",
    "title": "Learning-Based Algorithms for Graph Searching Problems",
    "authors": [
      "Adela Frances DePavia",
      "Erasmo Tani",
      "Ali Vakilian"
    ],
    "abstract": "We consider the problem of graph searching with prediction recently\nintroduced by Banerjee et al. (2022). In this problem, an agent, starting at\nsome vertex $r$ has to traverse a (potentially unknown) graph $G$ to find a\nhidden goal node $g$ while minimizing the total distance travelled. We study a\nsetting in which at any node $v$, the agent receives a noisy estimate of the\ndistance from $v$ to $g$. We design algorithms for this search task on unknown\ngraphs. We establish the first formal guarantees on unknown weighted graphs and\nprovide lower bounds showing that the algorithms we propose have optimal or\nnearly-optimal dependence on the prediction error. Further, we perform\nnumerical experiments demonstrating that in addition to being robust to\nadversarial error, our algorithms perform well in typical instances in which\nthe error is stochastic. Finally, we provide alternative simpler performance\nbounds on the algorithms of Banerjee et al. (2022) for the case of searching on\na known graph, and establish new lower bounds for this setting.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17736v2",
    "published_date": "2024-02-27 18:12:58 UTC",
    "updated_date": "2024-03-16 21:56:58 UTC"
  },
  {
    "arxiv_id": "2402.17709v2",
    "title": "Case-Based or Rule-Based: How Do Transformers Do the Math?",
    "authors": [
      "Yi Hu",
      "Xiaojuan Tang",
      "Haotong Yang",
      "Muhan Zhang"
    ],
    "abstract": "Despite the impressive performance in a variety of complex tasks, modern\nlarge language models (LLMs) still have trouble dealing with some math problems\nthat are simple and intuitive for humans, such as addition. While we can easily\nlearn basic rules of addition and apply them to new problems of any length,\nLLMs struggle to do the same. Instead, they may rely on similar cases seen in\nthe training corpus for help. We define these two different reasoning\nmechanisms as \"rule-based reasoning\" and \"case-based reasoning\". Since\nrule-based reasoning is essential for acquiring systematic generalization\nability, we aim to explore exactly whether transformers use rule-based or\ncase-based reasoning for math problems. Through carefully designed intervention\nexperiments on five math tasks, we confirm that transformers are performing\ncase-based reasoning, no matter whether scratchpad is used, which aligns with\nthe previous observations that transformers use subgraph matching/shortcut\nlearning to reason. To mitigate such problems, we propose a Rule-Following\nFine-Tuning (RFFT) technique to teach transformers to perform rule-based\nreasoning. Specifically, we provide explicit rules in the input and then\ninstruct transformers to recite and follow the rules step by step. Through\nRFFT, we successfully enable LLMs fine-tuned on 1-5 digit addition to\ngeneralize to up to 12-digit addition with over 95% accuracy, which is over 40%\nhigher than scratchpad. The significant improvement demonstrates that teaching\nLLMs to use rules explicitly helps them learn rule-based reasoning and\ngeneralize better in length.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17709v2",
    "published_date": "2024-02-27 17:41:58 UTC",
    "updated_date": "2024-06-26 09:25:07 UTC"
  },
  {
    "arxiv_id": "2402.17690v2",
    "title": "Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms",
    "authors": [
      "Divya Garikapati",
      "Sneha Sudhir Shetiya"
    ],
    "abstract": "The advent of autonomous vehicles has heralded a transformative era in\ntransportation, reshaping the landscape of mobility through cutting-edge\ntechnologies. Central to this evolution is the integration of Artificial\nIntelligence (AI) and learning algorithms, propelling vehicles into realms of\nunprecedented autonomy. This paper provides a comprehensive exploration of the\nevolutionary trajectory of AI within autonomous vehicles, tracing the journey\nfrom foundational principles to the most recent advancements. Commencing with a\ncurrent landscape overview, the paper delves into the fundamental role of AI in\nshaping the autonomous decision-making capabilities of vehicles. It elucidates\nthe steps involved in the AI-powered development life cycle in vehicles,\naddressing ethical considerations and bias in AI-driven software development\nfor autonomous vehicles. The study presents statistical insights into the usage\nand types of AI/learning algorithms over the years, showcasing the evolving\nresearch landscape within the automotive industry. Furthermore, the paper\nhighlights the pivotal role of parameters in refining algorithms for both\ntrucks and cars, facilitating vehicles to adapt, learn, and improve performance\nover time. It concludes by outlining different levels of autonomy, elucidating\nthe nuanced usage of AI and learning algorithms, and automating key tasks at\neach level. Additionally, the document discusses the variation in software\npackage sizes across different autonomy levels",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.17690v2",
    "published_date": "2024-02-27 17:07:18 UTC",
    "updated_date": "2024-02-28 15:53:07 UTC"
  },
  {
    "arxiv_id": "2402.17689v1",
    "title": "QoS prediction in radio vehicular environments via prior user information",
    "authors": [
      "Noor Ul Ain",
      "Rodrigo Hernangómez",
      "Alexandros Palaios",
      "Martin Kasparick",
      "Sławomir Stańczak"
    ],
    "abstract": "Reliable wireless communications play an important role in the automotive\nindustry as it helps to enhance current use cases and enable new ones such as\nconnected autonomous driving, platooning, cooperative maneuvering, teleoperated\ndriving, and smart navigation. These and other use cases often rely on specific\nquality of service (QoS) levels for communication. Recently, the area of\npredictive quality of service (QoS) has received a great deal of attention as a\nkey enabler to forecast communication quality well enough in advance. However,\npredicting QoS in a reliable manner is a notoriously difficult task. In this\npaper, we evaluate ML tree-ensemble methods to predict QoS in the range of\nminutes with data collected from a cellular test network. We discuss radio\nenvironment characteristics and we showcase how these can be used to improve ML\nperformance and further support the uptake of ML in commercial networks.\nSpecifically, we use the correlations of the measurements coming from the radio\nenvironment by including information of prior vehicles to enhance the\nprediction of the target vehicles. Moreover, we are extending prior art by\nshowing how longer prediction horizons can be supported.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17689v1",
    "published_date": "2024-02-27 17:05:41 UTC",
    "updated_date": "2024-02-27 17:05:41 UTC"
  },
  {
    "arxiv_id": "2403.14658v1",
    "title": "Identifying Potential Inlets of Man in the Artificial Intelligence Development Process",
    "authors": [
      "Deja Workman",
      "Christopher L. Dancy"
    ],
    "abstract": "In this paper we hope to identify how the typical or standard artificial\nintelligence development process encourages or facilitates the creation of\nracialized technologies. We begin by understanding Sylvia Wynter's definition\nof the biocentric Man genre and its exclusion of Blackness from humanness. We\nfollow this with outlining what we consider to be the typical steps for\ndeveloping an AI-based technology, which we have broken down into 6 stages:\nidentifying a problem, development process and management tool selection,\ndataset development and data processing, model development, deployment and risk\nassessment, and integration and monitoring. The goal of this paper is to better\nunderstand how Wynter's biocentric Man is being represented and reinforced by\nthe technologies we are producing in the AI lifecycle and by the lifecycle\nitself; we hope to identify ways in which the distinction of Blackness from the\n\"ideal\" human leads to perpetual punishment at the hands of these technologies.\nBy deconstructing this development process, we can potentially identify ways in\nwhich humans in general have not been prioritized and how those affects are\ndisproportionately affecting marginalized people. We hope to offer solutions\nthat will encourage changes in the AI development cycle.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; K.4.2"
    ],
    "primary_category": "cs.CY",
    "comment": "Published in CSCW '23 Conference Proceedings. 7 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.14658v1",
    "published_date": "2024-02-27 16:52:18 UTC",
    "updated_date": "2024-02-27 16:52:18 UTC"
  },
  {
    "arxiv_id": "2403.07918v1",
    "title": "On the Societal Impact of Open Foundation Models",
    "authors": [
      "Sayash Kapoor",
      "Rishi Bommasani",
      "Kevin Klyman",
      "Shayne Longpre",
      "Ashwin Ramaswami",
      "Peter Cihon",
      "Aspen Hopkins",
      "Kevin Bankston",
      "Stella Biderman",
      "Miranda Bogen",
      "Rumman Chowdhury",
      "Alex Engler",
      "Peter Henderson",
      "Yacine Jernite",
      "Seth Lazar",
      "Stefano Maffulli",
      "Alondra Nelson",
      "Joelle Pineau",
      "Aviya Skowron",
      "Dawn Song",
      "Victor Storchan",
      "Daniel Zhang",
      "Daniel E. Ho",
      "Percy Liang",
      "Arvind Narayanan"
    ],
    "abstract": "Foundation models are powerful technologies: how they are released publicly\ndirectly shapes their societal impact. In this position paper, we focus on open\nfoundation models, defined here as those with broadly available model weights\n(e.g. Llama 2, Stable Diffusion XL). We identify five distinctive properties\n(e.g. greater customizability, poor monitoring) of open foundation models that\nlead to both their benefits and risks. Open foundation models present\nsignificant benefits, with some caveats, that span innovation, competition, the\ndistribution of decision-making power, and transparency. To understand their\nrisks of misuse, we design a risk assessment framework for analyzing their\nmarginal risk. Across several misuse vectors (e.g. cyberattacks, bioweapons),\nwe find that current research is insufficient to effectively characterize the\nmarginal risk of open foundation models relative to pre-existing technologies.\nThe framework helps explain why the marginal risk is low in some cases,\nclarifies disagreements about misuse risks by revealing that past work has\nfocused on different subsets of the framework with different assumptions, and\narticulates a way forward for more constructive debate. Overall, our work helps\nsupport a more grounded assessment of the societal impact of open foundation\nmodels by outlining what research is needed to empirically validate their\ntheoretical benefits and risks.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07918v1",
    "published_date": "2024-02-27 16:49:53 UTC",
    "updated_date": "2024-02-27 16:49:53 UTC"
  },
  {
    "arxiv_id": "2402.17652v2",
    "title": "Compass: A Decentralized Scheduler for Latency-Sensitive ML Workflows",
    "authors": [
      "Yuting Yang",
      "Andrea Merlina",
      "Weijia Song",
      "Tiancheng Yuan",
      "Ken Birman",
      "Roman Vitenberg"
    ],
    "abstract": "We consider ML query processing in distributed systems where GPU-enabled\nworkers coordinate to execute complex queries: a computing style often seen in\napplications that interact with users in support of image processing and\nnatural language processing. In such systems, coscheduling of GPU memory\nmanagement and task placement represents a promising opportunity. We propose\nCompass, a novel framework that unifies these functions to reduce job latency\nwhile using resources efficiently, placing tasks where data dependencies will\nbe satisfied, collocating tasks from the same job (when this will not overload\nthe host or its GPU), and efficiently managing GPU memory. Comparison with\nother state of the art schedulers shows a significant reduction in completion\ntimes while requiring the same amount or even fewer resources. In one case,\njust half the servers were needed for processing the same workload.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17652v2",
    "published_date": "2024-02-27 16:21:28 UTC",
    "updated_date": "2024-02-28 17:27:48 UTC"
  },
  {
    "arxiv_id": "2402.17645v1",
    "title": "SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation",
    "authors": [
      "Shuangrui Ding",
      "Zihan Liu",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Rui Qian",
      "Conghui He",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "abstract": "We present SongComposer, an innovative LLM designed for song composition. It\ncould understand and generate melodies and lyrics in symbolic song\nrepresentations, by leveraging the capability of LLM. Existing music-related\nLLM treated the music as quantized audio signals, while such implicit encoding\nleads to inefficient encoding and poor flexibility. In contrast, we resort to\nsymbolic song representation, the mature and efficient way humans designed for\nmusic, and enable LLM to explicitly compose songs like humans. In practice, we\ndesign a novel tuple design to format lyric and three note attributes (pitch,\nduration, and rest duration) in the melody, which guarantees the correct LLM\nunderstanding of musical symbols and realizes precise alignment between lyrics\nand melody. To impart basic music understanding to LLM, we carefully collected\nSongCompose-PT, a large-scale song pretraining dataset that includes lyrics,\nmelodies, and paired lyrics-melodies in either Chinese or English. After\nadequate pre-training, 10K carefully crafted QA pairs are used to empower the\nLLM with the instruction-following capability and solve diverse tasks. With\nextensive experiments, SongComposer demonstrates superior performance in\nlyric-to-melody generation, melody-to-lyric generation, song continuation, and\ntext-to-song creation, outperforming advanced LLMs like GPT-4.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "project page: https://pjlab-songcomposer.github.io/ code:\n  https://github.com/pjlab-songcomposer/songcomposer",
    "pdf_url": "http://arxiv.org/pdf/2402.17645v1",
    "published_date": "2024-02-27 16:15:28 UTC",
    "updated_date": "2024-02-27 16:15:28 UTC"
  },
  {
    "arxiv_id": "2402.17644v2",
    "title": "Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data",
    "authors": [
      "Xiao Liu",
      "Zirui Wu",
      "Xueqing Wu",
      "Pan Lu",
      "Kai-Wei Chang",
      "Yansong Feng"
    ],
    "abstract": "Quantitative reasoning is a critical skill to analyze data, yet the\nassessment of such ability remains limited. To address this gap, we introduce\nthe Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate\nLarge Language Models' capability in statistical and causal reasoning with\nreal-world data. The benchmark comprises a carefully constructed dataset of 411\nquestions accompanied by data sheets from textbooks, online learning materials,\nand academic papers. To compare models' quantitative reasoning abilities on\ndata and text, we enrich the benchmark with an auxiliary set of 290 text-only\nquestions, namely QRText. We evaluate natural language reasoning, program-based\nreasoning, and agent reasoning methods including Chain-of-Thought,\nProgram-of-Thoughts, ReAct, and code interpreter assistants on diverse models.\nThe strongest model GPT-4 achieves an accuracy of 58%, which has much room for\nimprovement. Among open-source models, Deepseek-coder-instruct, a code LLM\npretrained on 2T tokens, gets the highest accuracy of 37%. Analysis reveals\nthat models encounter difficulties in data analysis and causal reasoning, and\nstruggle in using causal knowledge and provided data simultaneously. Code and\ndata are in https://github.com/xxxiaol/QRData.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024. Project website:\n  https://xxxiaol.github.io/QRData/",
    "pdf_url": "http://arxiv.org/pdf/2402.17644v2",
    "published_date": "2024-02-27 16:15:03 UTC",
    "updated_date": "2024-06-09 13:54:09 UTC"
  },
  {
    "arxiv_id": "2402.17641v2",
    "title": "Variational Learning is Effective for Large Deep Networks",
    "authors": [
      "Yuesong Shen",
      "Nico Daheim",
      "Bai Cong",
      "Peter Nickl",
      "Gian Maria Marconi",
      "Clement Bazan",
      "Rio Yokota",
      "Iryna Gurevych",
      "Daniel Cremers",
      "Mohammad Emtiyaz Khan",
      "Thomas Möllenhoff"
    ],
    "abstract": "We give extensive empirical evidence against the common belief that\nvariational learning is ineffective for large neural networks. We show that an\noptimizer called Improved Variational Online Newton (IVON) consistently matches\nor outperforms Adam for training large networks such as GPT-2 and ResNets from\nscratch. IVON's computational costs are nearly identical to Adam but its\npredictive uncertainty is better. We show several new use cases of IVON where\nwe improve finetuning and model merging in Large Language Models, accurately\npredict generalization error, and faithfully estimate sensitivity to data. We\nfind overwhelming evidence that variational learning is effective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at International Conference on Machine Learning (ICML),\n  2024. The first two authors contributed equally. Code is available here:\n  https://github.com/team-approx-bayes/ivon",
    "pdf_url": "http://arxiv.org/pdf/2402.17641v2",
    "published_date": "2024-02-27 16:11:05 UTC",
    "updated_date": "2024-06-06 04:31:43 UTC"
  },
  {
    "arxiv_id": "2402.18372v2",
    "title": "FedUV: Uniformity and Variance for Heterogeneous Federated Learning",
    "authors": [
      "Ha Min Son",
      "Moon-Hyun Kim",
      "Tai-Myoung Chung",
      "Chao Huang",
      "Xin Liu"
    ],
    "abstract": "Federated learning is a promising framework to train neural networks with\nwidely distributed data. However, performance degrades heavily with\nheterogeneously distributed data. Recent work has shown this is due to the\nfinal layer of the network being most prone to local bias, some finding success\nfreezing the final layer as an orthogonal classifier. We investigate the\ntraining dynamics of the classifier by applying SVD to the weights motivated by\nthe observation that freezing weights results in constant singular values. We\nfind that there are differences when training in IID and non-IID settings.\nBased on this finding, we introduce two regularization terms for local training\nto continuously emulate IID settings: (1) variance in the dimension-wise\nprobability distribution of the classifier and (2) hyperspherical uniformity of\nrepresentations of the encoder. These regularizations promote local models to\nact as if it were in an IID setting regardless of the local data distribution,\nthus offsetting proneness to bias while being flexible to the data. On\nextensive experiments in both label-shift and feature-shift settings, we verify\nthat our method achieves highest performance by a large margin especially in\nhighly non-IID cases in addition to being scalable to larger models and\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 4 figures, 5 tables, to appear at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.18372v2",
    "published_date": "2024-02-27 15:53:15 UTC",
    "updated_date": "2024-03-01 21:53:26 UTC"
  },
  {
    "arxiv_id": "2402.17606v3",
    "title": "Learning Topological Representations with Bidirectional Graph Attention Network for Solving Job Shop Scheduling Problem",
    "authors": [
      "Cong Zhang",
      "Zhiguang Cao",
      "Yaoxin Wu",
      "Wen Song",
      "Jing Sun"
    ],
    "abstract": "Existing learning-based methods for solving job shop scheduling problems\n(JSSP) usually use off-the-shelf GNN models tailored to undirected graphs and\nneglect the rich and meaningful topological structures of disjunctive graphs\n(DGs). This paper proposes the topology-aware bidirectional graph attention\nnetwork (TBGAT), a novel GNN architecture based on the attention mechanism, to\nembed the DG for solving JSSP in a local search framework. Specifically, TBGAT\nembeds the DG from a forward and a backward view, respectively, where the\nmessages are propagated by following the different topologies of the views and\naggregated via graph attention. Then, we propose a novel operator based on the\nmessage-passing mechanism to calculate the forward and backward topological\nsorts of the DG, which are the features for characterizing the topological\nstructures and exploited by our model. In addition, we theoretically and\nexperimentally show that TBGAT has linear computational complexity to the\nnumber of jobs and machines, respectively, strengthening our method's practical\nvalue. Besides, extensive experiments on five synthetic datasets and seven\nclassic benchmarks show that TBGAT achieves new SOTA results by outperforming a\nwide range of neural methods by a large margin. All the code and data are\npublicly available online at https://github.com/zcaicaros/TBGAT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17606v3",
    "published_date": "2024-02-27 15:33:20 UTC",
    "updated_date": "2024-06-05 06:19:06 UTC"
  },
  {
    "arxiv_id": "2402.17595v1",
    "title": "Implicit Regularization via Spectral Neural Networks and Non-linear Matrix Sensing",
    "authors": [
      "Hong T. M. Chu",
      "Subhro Ghosh",
      "Chi Thanh Lam",
      "Soumendu Sundar Mukherjee"
    ],
    "abstract": "The phenomenon of implicit regularization has attracted interest in recent\nyears as a fundamental aspect of the remarkable generalizing ability of neural\nnetworks. In a nutshell, it entails that gradient descent dynamics in many\nneural nets, even without any explicit regularizer in the loss function,\nconverges to the solution of a regularized learning problem. However, known\nresults attempting to theoretically explain this phenomenon focus\noverwhelmingly on the setting of linear neural nets, and the simplicity of the\nlinear structure is particularly crucial to existing arguments. In this paper,\nwe explore this problem in the context of more realistic neural networks with a\ngeneral class of non-linear activation functions, and rigorously demonstrate\nthe implicit regularization phenomenon for such networks in the setting of\nmatrix sensing problems, together with rigorous rate guarantees that ensure\nexponentially fast convergence of gradient descent.In this vein, we contribute\na network architecture called Spectral Neural Networks (abbrv. SNN) that is\nparticularly suitable for matrix learning problems. Conceptually, this entails\ncoordinatizing the space of matrices by their singular values and singular\nvectors, as opposed to by their entries, a potentially fruitful perspective for\nmatrix learning. We demonstrate that the SNN architecture is inherently much\nmore amenable to theoretical analysis than vanilla neural nets and confirm its\neffectiveness in the context of matrix sensing, via both mathematical\nguarantees and empirical investigations. We believe that the SNN architecture\nhas the potential to be of wide applicability in a broad class of matrix\nlearning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17595v1",
    "published_date": "2024-02-27 15:28:01 UTC",
    "updated_date": "2024-02-27 15:28:01 UTC"
  },
  {
    "arxiv_id": "2402.17574v3",
    "title": "Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization",
    "authors": [
      "Wenqi Zhang",
      "Ke Tang",
      "Hai Wu",
      "Mengna Wang",
      "Yongliang Shen",
      "Guiyang Hou",
      "Zeqi Tan",
      "Peng Li",
      "Yueting Zhuang",
      "Weiming Lu"
    ],
    "abstract": "Large Language Models (LLMs) exhibit robust problem-solving capabilities for\ndiverse tasks. However, most LLM-based agents are designed as specific task\nsolvers with sophisticated prompt engineering, rather than agents capable of\nlearning and evolving through interactions. These task solvers necessitate\nmanually crafted prompts to inform task rules and regulate LLM behaviors,\ninherently incapacitating to address complex dynamic scenarios e.g., large\ninteractive games. In light of this, we propose Agent-Pro: an LLM-based Agent\nwith Policy-level Reflection and Optimization that can learn a wealth of\nexpertise from interactive experiences and progressively elevate its behavioral\npolicy. Specifically, it involves a dynamic belief generation and reflection\nprocess for policy evolution. Rather than action-level reflection, Agent-Pro\niteratively reflects on past trajectories and beliefs, fine-tuning its\nirrational beliefs for a better policy. Moreover, a depth-first search is\nemployed for policy optimization, ensuring continual enhancement in policy\npayoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold'em,\noutperforming vanilla LLM and specialized models. Our results show Agent-Pro\ncan learn and evolve in complex and dynamic scenes, which also benefits\nnumerous LLM-based applications.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACL-2024 Main, camera-ready version",
    "pdf_url": "http://arxiv.org/pdf/2402.17574v3",
    "published_date": "2024-02-27 15:09:20 UTC",
    "updated_date": "2024-06-06 18:40:47 UTC"
  },
  {
    "arxiv_id": "2402.17563v2",
    "title": "Structure-Guided Adversarial Training of Diffusion Models",
    "authors": [
      "Ling Yang",
      "Haotian Qian",
      "Zhilong Zhang",
      "Jingwei Liu",
      "Bin Cui"
    ],
    "abstract": "Diffusion models have demonstrated exceptional efficacy in various generative\napplications. While existing models focus on minimizing a weighted sum of\ndenoising score matching losses for data distribution modeling, their training\nprimarily emphasizes instance-level optimization, overlooking valuable\nstructural information within each mini-batch, indicative of pair-wise\nrelationships among samples. To address this limitation, we introduce\nStructure-guided Adversarial training of Diffusion Models (SADM). In this\npioneering approach, we compel the model to learn manifold structures between\nsamples in each training batch. To ensure the model captures authentic manifold\nstructures in the data distribution, we advocate adversarial training of the\ndiffusion generator against a novel structure discriminator in a minimax game,\ndistinguishing real manifold structures from the generated ones. SADM\nsubstantially improves existing diffusion transformers (DiT) and outperforms\nexisting methods in image generation and cross-domain fine-tuning tasks across\n12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on\nImageNet for class-conditional image generation at resolutions of 256x256 and\n512x512, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17563v2",
    "published_date": "2024-02-27 15:05:13 UTC",
    "updated_date": "2024-03-04 14:51:40 UTC"
  },
  {
    "arxiv_id": "2402.17553v3",
    "title": "OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web",
    "authors": [
      "Raghav Kapoor",
      "Yash Parag Butala",
      "Melisa Russak",
      "Jing Yu Koh",
      "Kiran Kamble",
      "Waseem Alshikh",
      "Ruslan Salakhutdinov"
    ],
    "abstract": "For decades, human-computer interaction has fundamentally been manual. Even\ntoday, almost all productive work done on the computer necessitates human input\nat every step. Autonomous virtual agents represent an exciting step in\nautomating many of these menial tasks. Virtual agents would empower users with\nlimited technical proficiency to harness the full possibilities of computer\nsystems. They could also enable the efficient streamlining of numerous computer\ntasks, ranging from calendar management to complex travel bookings, with\nminimal human intervention. In this paper, we introduce OmniACT, the\nfirst-of-a-kind dataset and benchmark for assessing an agent's capability to\ngenerate executable programs to accomplish computer tasks. Our scope extends\nbeyond traditional web automation, covering a diverse range of desktop\napplications. The dataset consists of fundamental tasks such as \"Play the next\nsong\", as well as longer horizon tasks such as \"Send an email to John Doe\nmentioning the time and place to meet\". Specifically, given a pair of screen\nimage and a visually-grounded natural language task, the goal is to generate a\nscript capable of fully executing the task. We run several strong baseline\nlanguage model agents on our benchmark. The strongest baseline, GPT-4, performs\nthe best on our benchmark However, its performance level still reaches only 15%\nof the human proficiency in generating executable scripts capable of completing\nthe task, demonstrating the challenge of our task for conventional web agents.\nOur benchmark provides a platform to measure and evaluate the progress of\nlanguage model agents in automating computer tasks and motivates future work\ntowards building multimodal models that bridge large language models and the\nvisual grounding of computer screens.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17553v3",
    "published_date": "2024-02-27 14:47:53 UTC",
    "updated_date": "2024-07-21 23:16:13 UTC"
  },
  {
    "arxiv_id": "2402.17811v2",
    "title": "TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space",
    "authors": [
      "Shaolei Zhang",
      "Tian Yu",
      "Yang Feng"
    ],
    "abstract": "Large Language Models (LLMs) sometimes suffer from producing hallucinations,\nespecially LLMs may generate untruthful responses despite knowing the correct\nknowledge. Activating the truthfulness within LLM is the key to fully unlocking\nLLM's knowledge potential. In this paper, we propose TruthX, an inference-time\nintervention method to activate the truthfulness of LLM by identifying and\nediting the features within LLM's internal representations that govern the\ntruthfulness. TruthX employs an auto-encoder to map LLM's representations into\nsemantic and truthful latent spaces respectively, and applies contrastive\nlearning to identify a truthful editing direction within the truthful space.\nDuring inference, by editing LLM's internal representations in truthful space,\nTruthX effectively enhances the truthfulness of LLM. Experiments show that\nTruthX improves the truthfulness of 13 advanced LLMs by an average of 20% on\nTruthfulQA benchmark. Further analyses suggest that TruthX can control LLM to\nproduce truthful or hallucinatory responses via editing only one vector in\nLLM's internal representations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 main conference, Project Page:\n  https://ictnlp.github.io/TruthX-site/",
    "pdf_url": "http://arxiv.org/pdf/2402.17811v2",
    "published_date": "2024-02-27 14:45:04 UTC",
    "updated_date": "2024-06-05 11:15:04 UTC"
  },
  {
    "arxiv_id": "2402.17550v1",
    "title": "Emergency Caching: Coded Caching-based Reliable Map Transmission in Emergency Networks",
    "authors": [
      "Zeyu Tian",
      "Lianming Xu",
      "Liang Li",
      "Li Wang",
      "Aiguo Fei"
    ],
    "abstract": "Many rescue missions demand effective perception and real-time decision\nmaking, which highly rely on effective data collection and processing. In this\nstudy, we propose a three-layer architecture of emergency caching networks\nfocusing on data collection and reliable transmission, by leveraging efficient\nperception and edge caching technologies. Based on this architecture, we\npropose a disaster map collection framework that integrates coded caching\ntechnologies. Our framework strategically caches coded fragments of maps across\nunmanned aerial vehicles (UAVs), fostering collaborative uploading for\naugmented transmission reliability. Additionally, we establish a comprehensive\nprobability model to assess the effective recovery area of disaster maps.\nTowards the goal of utility maximization, we propose a deep reinforcement\nlearning (DRL) based algorithm that jointly makes decisions about cooperative\nUAVs selection, bandwidth allocation and coded caching parameter adjustment,\naccommodating the real-time map updates in a dynamic disaster situation. Our\nproposed scheme is more effective than the non-coding caching scheme, as\nvalidated by simulation.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17550v1",
    "published_date": "2024-02-27 14:44:11 UTC",
    "updated_date": "2024-02-27 14:44:11 UTC"
  },
  {
    "arxiv_id": "2402.17546v1",
    "title": "COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt",
    "authors": [
      "Suyeon Lee",
      "Jieun Kang",
      "Harim Kim",
      "Kyoung-Mee Chung",
      "Dongha Lee",
      "Jinyoung Yeo"
    ],
    "abstract": "The demand for conversational agents that provide mental health care is\nconsistently increasing. In this work, we develop a psychological counseling\nagent, referred to as CoCoA, that applies Cognitive Behavioral Therapy (CBT)\ntechniques to identify and address cognitive distortions inherent in the\nclient's statements. Specifically, we construct a memory system to efficiently\nmanage information necessary for counseling while extracting high-level\ninsights about the client from their utterances. Additionally, to ensure that\nthe counseling agent generates appropriate responses, we introduce dynamic\nprompting to flexibly apply CBT techniques and facilitate the appropriate\nretrieval of information. We conducted dialogues between CoCoA and characters\nfrom Character.ai, creating a dataset for evaluation. Then, we asked GPT to\nevaluate the constructed counseling dataset, and our model demonstrated a\nstatistically significant difference from other models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.17546v1",
    "published_date": "2024-02-27 14:38:47 UTC",
    "updated_date": "2024-02-27 14:38:47 UTC"
  },
  {
    "arxiv_id": "2402.17531v2",
    "title": "Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides",
    "authors": [
      "Kaikai An",
      "Fangkai Yang",
      "Junting Lu",
      "Liqun Li",
      "Zhixing Ren",
      "Hao Huang",
      "Lu Wang",
      "Pu Zhao",
      "Yu Kang",
      "Hua Ding",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "Effective incident management is pivotal for the smooth operation of\nenterprises-level cloud services. In order to expedite incident mitigation,\nservice teams compile troubleshooting knowledge into Troubleshooting Guides\n(TSGs) accessible to on-call engineers (OCEs). While automated pipelines are\nenabled to resolve the most frequent and easy incidents, there still exist\ncomplex incidents that require OCEs' intervention. However, TSGs are often\nunstructured and incomplete, which requires manual interpretation by OCEs,\nleading to on-call fatigue and decreased productivity, especially among\nnew-hire OCEs. In this work, we propose Nissist which leverages TSGs and\nincident mitigation histories to provide proactive suggestions, reducing human\nintervention. Leveraging Large Language Models (LLM), Nissist extracts insights\nfrom unstructured TSGs and historical incident mitigation discussions, forming\na comprehensive knowledge base. Its multi-agent system design enhances\nproficiency in precisely discerning user queries, retrieving relevant\ninformation, and delivering systematic plans consecutively. Through our user\ncase and experiment, we demonstrate that Nissist significant reduce Time to\nMitigate (TTM) in incident mitigation, alleviating operational burdens on OCEs\nand improving service reliability. Our demo is available at\nhttps://aka.ms/nissist_demo.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2402.17531v2",
    "published_date": "2024-02-27 14:14:23 UTC",
    "updated_date": "2024-05-10 11:57:46 UTC"
  },
  {
    "arxiv_id": "2402.17527v2",
    "title": "Predict the Next Word: Humans exhibit uncertainty in this task and language models _____",
    "authors": [
      "Evgenia Ilia",
      "Wilker Aziz"
    ],
    "abstract": "Language models (LMs) are statistical models trained to assign probability to\nhuman-generated text. As such, it is reasonable to question whether they\napproximate linguistic variability exhibited by humans well. This form of\nstatistical assessment is difficult to perform at the passage level, for it\nrequires acceptability judgements (i.e., human evaluation) or a robust\nautomated proxy (which is non-trivial). At the word level, however, given some\ncontext, samples from an LM can be assessed via exact matching against a\nprerecorded dataset of alternative single-word continuations of the available\ncontext. We exploit this fact and evaluate the LM's ability to reproduce\nvariability that humans (in particular, a population of English speakers)\nexhibit in the 'next word prediction' task. This can be seen as assessing a\nform of calibration, which, in the context of text classification, Baan et al.\n(2022) termed calibration to human uncertainty. We assess GPT2, BLOOM and\nChatGPT and find that they exhibit fairly low calibration to human uncertainty.\nWe also verify the failure of expected calibration error (ECE) to reflect this,\nand as such, advise the community against relying on it in this setting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17527v2",
    "published_date": "2024-02-27 14:11:32 UTC",
    "updated_date": "2024-03-18 16:21:24 UTC"
  },
  {
    "arxiv_id": "2402.18598v2",
    "title": "Note: Evolutionary Game Theory Focus Informational Health: The Cocktail Party Effect Through Werewolfgame under Incomplete Information and ESS Search Method Using Expected Gains of Repeated Dilemmas",
    "authors": [
      "Yasuko Kawahata"
    ],
    "abstract": "We explore the state of information disruption caused by the cocktail party\neffect within the framework of non-perfect information games and evolutive\ngames with multiple werewolves. In particular, we mathematically model and\nanalyze the effects on the gain of each strategy choice and the formation\nprocess of evolutionary stable strategies (ESS) under the assumption that the\npollution risk of fake news is randomly assigned in the context of repeated\ndilemmas. We will develop the computational process in detail, starting with\nthe construction of the gain matrix, modeling the evolutionary dynamics using\nthe replicator equation, and identifying the ESS. In addition, numerical\nsimulations will be performed to observe system behavior under different\ninitial conditions and parameter settings to better understand the impact of\nthe spread of fake news on strategy evolution. This research will provide\ntheoretical insights into the complex issues of contemporary society regarding\nthe authenticity of information and expand the range of applications of\nevolutionary game theory.This paper is partially an attempt to utilize\n\"Generative AI\" and was written with educational intent. There are currently no\nplans for it to become a peer-reviewed paper.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "Werewolf Games, Evolutionary Game Theory, Non-Complete Information\n  Games, Expanding Form Games, Cocktail Party Effect, Fake News, Evolutionary\n  Stability Strategy (ESS), Information Pollution Risk, Numerical Simulation,\n  Strategic Interaction, Replicator Equation",
    "pdf_url": "http://arxiv.org/pdf/2402.18598v2",
    "published_date": "2024-02-27 14:10:34 UTC",
    "updated_date": "2024-04-19 14:55:41 UTC"
  },
  {
    "arxiv_id": "2403.07916v1",
    "title": "Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization",
    "authors": [
      "Philip Ndikum",
      "Serge Ndikum"
    ],
    "abstract": "This research paper delves into the application of Deep Reinforcement\nLearning (DRL) in asset-class agnostic portfolio optimization, integrating\nindustry-grade methodologies with quantitative finance. At the heart of this\nintegration is our robust framework that not only merges advanced DRL\nalgorithms with modern computational techniques but also emphasizes stringent\nstatistical analysis, software engineering and regulatory compliance. To the\nbest of our knowledge, this is the first study integrating financial\nReinforcement Learning with sim-to-real methodologies from robotics and\nmathematical physics, thus enriching our frameworks and arguments with this\nunique perspective. Our research culminates with the introduction of\nAlphaOptimizerNet, a proprietary Reinforcement Learning agent (and\ncorresponding library). Developed from a synthesis of state-of-the-art (SOTA)\nliterature and our unique interdisciplinary methodology, AlphaOptimizerNet\ndemonstrates encouraging risk-return optimization across various asset classes\nwith realistic constraints. These preliminary results underscore the practical\nefficacy of our frameworks. As the finance sector increasingly gravitates\ntowards advanced algorithmic solutions, our study bridges theoretical\nadvancements with real-world applicability, offering a template for ensuring\nsafety and robust standards in this technologically driven future.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07916v1",
    "published_date": "2024-02-27 14:08:31 UTC",
    "updated_date": "2024-02-27 14:08:31 UTC"
  },
  {
    "arxiv_id": "2402.17516v4",
    "title": "QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations",
    "authors": [
      "Jamie Duell",
      "Monika Seisenberger",
      "Hsuan Fu",
      "Xiuyi Fan"
    ],
    "abstract": "Deep Neural Networks (DNNs) stand out as one of the most prominent approaches\nwithin the Machine Learning (ML) domain. The efficacy of DNNs has surged\nalongside recent increases in computational capacity, allowing these approaches\nto scale to significant complexities for addressing predictive challenges in\nbig data. However, as the complexity of DNN models rises, interpretability\ndiminishes. In response to this challenge, explainable models such as\nAdversarial Gradient Integration (AGI) leverage path-based gradients provided\nby DNNs to elucidate their decisions. Yet the performance of path-based\nexplainers can be compromised when gradients exhibit irregularities during\nout-of-distribution path traversal. In this context, we introduce Quantified\nUncertainty Counterfactual Explanations (QUCE), a method designed to mitigate\nout-of-distribution traversal by minimizing path uncertainty. QUCE not only\nquantifies uncertainty when presenting explanations but also generates more\ncertain counterfactual examples. We showcase the performance of the QUCE method\nby comparing it with competing methods for both path-based explanations and\ngenerative counterfactual examples.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Final version published in ICDM 2024, International Conference on\n  Data Mining",
    "pdf_url": "http://arxiv.org/pdf/2402.17516v4",
    "published_date": "2024-02-27 14:00:08 UTC",
    "updated_date": "2025-03-12 08:31:10 UTC"
  },
  {
    "arxiv_id": "2402.17511v1",
    "title": "Rethinking Mutual Information for Language Conditioned Skill Discovery on Imitation Learning",
    "authors": [
      "Zhaoxun Ju",
      "Chao Yang",
      "Hongbo Wang",
      "Yu Qiao",
      "Fuchun Sun"
    ],
    "abstract": "Language-conditioned robot behavior plays a vital role in executing complex\ntasks by associating human commands or instructions with perception and\nactions. The ability to compose long-horizon tasks based on unconstrained\nlanguage instructions necessitates the acquisition of a diverse set of\ngeneral-purpose skills. However, acquiring inherent primitive skills in a\ncoupled and long-horizon environment without external rewards or human\nsupervision presents significant challenges. In this paper, we evaluate the\nrelationship between skills and language instructions from a mathematical\nperspective, employing two forms of mutual information within the framework of\nlanguage-conditioned policy learning. To maximize the mutual information\nbetween language and skills in an unsupervised manner, we propose an end-to-end\nimitation learning approach known as Language Conditioned Skill Discovery\n(LCSD). Specifically, we utilize vector quantization to learn discrete latent\nskills and leverage skill sequences of trajectories to reconstruct high-level\nsemantic instructions. Through extensive experiments on language-conditioned\nrobotic navigation and manipulation tasks, encompassing BabyAI, LORel, and\nCALVIN, we demonstrate the superiority of our method over prior works. Our\napproach exhibits enhanced generalization capabilities towards unseen tasks,\nimproved skill interpretability, and notably higher rates of task completion\nsuccess.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.17511v1",
    "published_date": "2024-02-27 13:53:52 UTC",
    "updated_date": "2024-02-27 13:53:52 UTC"
  },
  {
    "arxiv_id": "2402.17510v2",
    "title": "Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning",
    "authors": [
      "Maurits Bleeker",
      "Mariya Hendriksen",
      "Andrew Yates",
      "Maarten de Rijke"
    ],
    "abstract": "Vision-language models (VLMs) mainly rely on contrastive training to learn\ngeneral-purpose representations of images and captions. We focus on the\nsituation when one image is associated with several captions, each caption\ncontaining both information shared among all captions and unique information\nper caption about the scene depicted in the image. In such cases, it is unclear\nwhether contrastive losses are sufficient for learning task-optimal\nrepresentations that contain all the information provided by the captions or\nwhether the contrastive learning setup encourages the learning of a simple\nshortcut that minimizes contrastive loss. We introduce synthetic shortcuts for\nvision-language: a training and evaluation framework where we inject synthetic\nshortcuts into image-text data. We show that contrastive VLMs trained from\nscratch or fine-tuned with data containing these synthetic shortcuts mainly\nlearn features that represent the shortcut. Hence, contrastive losses are not\nsufficient to learn task-optimal representations, i.e., representations that\ncontain all task-relevant information shared between the image and associated\ncaptions. We examine two methods to reduce shortcut learning in our training\nand evaluation framework: (i) latent target decoding and (ii) implicit feature\nmodification. We show empirically that both methods improve performance on the\nevaluation task, but only partly reduce shortcut learning when training and\nevaluating with our shortcut learning framework. Hence, we show the difficulty\nand challenge of our shortcut learning framework for contrastive\nvision-language representation learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, accepted at TMLR",
    "pdf_url": "http://arxiv.org/pdf/2402.17510v2",
    "published_date": "2024-02-27 13:50:34 UTC",
    "updated_date": "2024-07-31 21:02:12 UTC"
  },
  {
    "arxiv_id": "2402.17501v2",
    "title": "Intensive Care as One Big Sequence Modeling Problem",
    "authors": [
      "Vadim Liventsev",
      "Tobias Fritz"
    ],
    "abstract": "Reinforcement Learning in Healthcare is typically concerned with narrow\nself-contained tasks such as sepsis prediction or anesthesia control. However,\nprevious research has demonstrated the potential of generalist models (the\nprime example being Large Language Models) to outperform task-specific\napproaches due to their capability for implicit transfer learning. To enable\ntraining of foundation models for Healthcare as well as leverage the\ncapabilities of state of the art Transformer architectures, we propose the\nparadigm of Healthcare as Sequence Modeling, in which interaction between the\npatient and the healthcare provider is represented as an event stream and tasks\nlike diagnosis and treatment selection are modeled as prediction of future\nevents in the stream. To explore this paradigm experimentally we develop\nMIMIC-SEQ, a sequence modeling benchmark derived by translating heterogenous\nclinical records from MIMIC-IV dataset into a uniform event stream format,\ntrain a baseline model and explore its capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17501v2",
    "published_date": "2024-02-27 13:36:55 UTC",
    "updated_date": "2024-05-24 18:50:06 UTC"
  },
  {
    "arxiv_id": "2402.17496v2",
    "title": "Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages",
    "authors": [
      "Lucía Gómez Zaragozá",
      "Rocío del Amor",
      "Elena Parra Vargas",
      "Valery Naranjo",
      "Mariano Alcañiz Raya",
      "Javier Marín-Morales"
    ],
    "abstract": "Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing\n999 audio messages from real conversations on a messaging app from 100 Spanish\nspeakers, gender balanced. Voice messages were produced in-the-wild conditions\nbefore participants were recruited, avoiding any conscious bias due to\nlaboratory environment. Audios were labeled in valence and arousal dimensions\nby three non-experts and two experts, which were then combined to obtain a\nfinal label per dimension. The experts also provided an extra label\ncorresponding to seven emotion categories. To set a baseline for future\ninvestigations using EMOVOME, we implemented emotion recognition models using\nboth speech and audio transcriptions. For speech, we used the standard eGeMAPS\nfeature set and support vector machines, obtaining 49.27% and 44.71% unweighted\naccuracy for valence and arousal respectively. For text, we fine-tuned a\nmultilingual BERT model and achieved 61.15% and 47.43% unweighted accuracy for\nvalence and arousal respectively. This database will significantly contribute\nto research on emotion recognition in the wild, while also providing a unique\nnatural and freely accessible resource for Spanish.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS",
      "I.5.1; I.5.4; I.2.7"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper has been superseded by arXiv:2403.02167 (merged from the\n  description of the EMOVOME database in arXiv:2402.17496v1 and the speech\n  emotion recognition models in arXiv:2403.02167v1)",
    "pdf_url": "http://arxiv.org/pdf/2402.17496v2",
    "published_date": "2024-02-27 13:22:47 UTC",
    "updated_date": "2024-06-13 13:09:48 UTC"
  },
  {
    "arxiv_id": "2402.17490v1",
    "title": "The Mechanical Turkness: Tactical Media Art and the Critique of Corporate AI",
    "authors": [
      "Dejan Grba"
    ],
    "abstract": "The extensive industrialization of artificial intelligence (AI) since the\nmid-2010s has increasingly motivated artists to address its economic and\nsociopolitical consequences. In this chapter, I discuss interrelated art\npractices that thematize creative agency, crowdsourced labor, and delegated\nartmaking to reveal the social rootage of AI technologies and underline the\nproductive human roles in their development. I focus on works whose poetic\nfeatures indicate broader issues of contemporary AI-influenced science,\ntechnology, economy, and society. By exploring the conceptual, methodological,\nand ethical aspects of their effectiveness in disrupting the political regime\nof corporate AI, I identify several problems that affect their tactical impact\nand outline potential avenues for tackling the challenges and advancing the\nfield.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Matthes, J\\\"org, Damian Trilling, Ljubi\\v{s}a Boji\\'c and Simona\n  \\v{Z}iki\\'c, eds. 2024. Navigating the Digital Age: An In-Depth Exploration\n  into the Intersection of Modern Technologies and Societal Transformation.\n  Vienna and Belgrade: Institute for Philosophy and Social Theory and\n  University of Belgrade and Department of Communication, University of Vienna",
    "pdf_url": "http://arxiv.org/pdf/2402.17490v1",
    "published_date": "2024-02-27 13:16:50 UTC",
    "updated_date": "2024-02-27 13:16:50 UTC"
  },
  {
    "arxiv_id": "2402.17482v1",
    "title": "Automated Classification of Phonetic Segments in Child Speech Using Raw Ultrasound Imaging",
    "authors": [
      "Saja Al Ani",
      "Joanne Cleland",
      "Ahmed Zoha"
    ],
    "abstract": "Speech sound disorder (SSD) is defined as a persistent impairment in speech\nsound production leading to reduced speech intelligibility and hindered verbal\ncommunication. Early recognition and intervention of children with SSD and\ntimely referral to speech and language therapists (SLTs) for treatment are\ncrucial. Automated detection of speech impairment is regarded as an efficient\nmethod for examining and screening large populations. This study focuses on\nadvancing the automatic diagnosis of SSD in early childhood by proposing a\ntechnical solution that integrates ultrasound tongue imaging (UTI) with\ndeep-learning models. The introduced FusionNet model combines UTI data with the\nextracted texture features to classify UTI. The overarching aim is to elevate\nthe accuracy and efficiency of UTI analysis, particularly for classifying\nspeech sounds associated with SSD. This study compared the FusionNet approach\nwith standard deep-learning methodologies, highlighting the excellent\nimprovement results of the FusionNet model in UTI classification and the\npotential of multi-learning in improving UTI classification in speech therapy\nclinics.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17482v1",
    "published_date": "2024-02-27 13:08:34 UTC",
    "updated_date": "2024-02-27 13:08:34 UTC"
  },
  {
    "arxiv_id": "2402.17472v4",
    "title": "RAGFormer: Learning Semantic Attributes and Topological Structure for Fraud Detection",
    "authors": [
      "Haolin Li",
      "Shuyang Jiang",
      "Lifeng Zhang",
      "Siyuan Du",
      "Guangnan Ye",
      "Hongfeng Chai"
    ],
    "abstract": "Fraud detection remains a challenging task due to the complex and deceptive\nnature of fraudulent activities. Current approaches primarily concentrate on\nlearning only one perspective of the graph: either the topological structure of\nthe graph or the attributes of individual nodes. However, we conduct empirical\nstudies to reveal that these two types of features, while nearly orthogonal,\nare each independently effective. As a result, previous methods can not fully\ncapture the comprehensive characteristics of the fraud graph. To address this\ndilemma, we present a novel framework called Relation-Aware GNN with\ntransFormer~(RAGFormer) which simultaneously embeds both semantic and\ntopological features into a target node. The simple yet effective network\nconsists of a semantic encoder, a topology encoder, and an attention fusion\nmodule. The semantic encoder utilizes Transformer to learn semantic features\nand node interactions across different relations. We introduce Relation-Aware\nGNN as the topology encoder to learn topological features and node interactions\nwithin each relation. These two complementary features are interleaved through\nan attention fusion module to support prediction by both orthogonal features.\nExtensive experiments on two popular public datasets demonstrate that RAGFormer\nachieves state-of-the-art performance. The significant improvement of RAGFormer\nin an industrial credit card fraud detection dataset further validates the\napplicability of our method in real-world business scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2402.17472v4",
    "published_date": "2024-02-27 12:53:15 UTC",
    "updated_date": "2025-02-11 12:29:00 UTC"
  },
  {
    "arxiv_id": "2402.17467v1",
    "title": "Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey",
    "authors": [
      "Dinh-Viet-Toan Le",
      "Louis Bigo",
      "Mikaela Keller",
      "Dorien Herremans"
    ],
    "abstract": "Several adaptations of Transformers models have been developed in various\ndomains since its breakthrough in Natural Language Processing (NLP). This trend\nhas spread into the field of Music Information Retrieval (MIR), including\nstudies processing music data. However, the practice of leveraging NLP tools\nfor symbolic music data is not novel in MIR. Music has been frequently compared\nto language, as they share several similarities, including sequential\nrepresentations of text and music. These analogies are also reflected through\nsimilar tasks in MIR and NLP. This survey reviews NLP methods applied to\nsymbolic music generation and information retrieval studies following two axes.\nWe first propose an overview of representations of symbolic music adapted from\nnatural language sequential representations. Such representations are designed\nby considering the specificities of symbolic music. These representations are\nthen processed by models. Such models, possibly originally developed for text\nand adapted for symbolic music, are trained on various tasks. We describe these\nmodels, in particular deep learning models, through different prisms,\nhighlighting music-specialized mechanisms. We finally present a discussion\nsurrounding the effective use of NLP tools for symbolic music data. This\nincludes technical issues regarding NLP methods and fundamental differences\nbetween text and music, which may open several doors for further research into\nmore effectively adapting NLP tools to symbolic MIR.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.IR",
    "comment": "36 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.17467v1",
    "published_date": "2024-02-27 12:48:01 UTC",
    "updated_date": "2024-02-27 12:48:01 UTC"
  },
  {
    "arxiv_id": "2402.17810v2",
    "title": "BioT5+: Towards Generalized Biological Understanding with IUPAC Integration and Multi-task Tuning",
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Kaiyuan Gao",
      "Xiaozhuan Liang",
      "Yin Fang",
      "Jinhua Zhu",
      "Shufang Xie",
      "Tao Qin",
      "Rui Yan"
    ],
    "abstract": "Recent research trends in computational biology have increasingly focused on\nintegrating text and bio-entity modeling, especially in the context of\nmolecules and proteins. However, previous efforts like BioT5 faced challenges\nin generalizing across diverse tasks and lacked a nuanced understanding of\nmolecular structures, particularly in their textual representations (e.g.,\nIUPAC). This paper introduces BioT5+, an extension of the BioT5 framework,\ntailored to enhance biological research and drug discovery. BioT5+ incorporates\nseveral novel features: integration of IUPAC names for molecular understanding,\ninclusion of extensive bio-text and molecule data from sources like bioRxiv and\nPubChem, the multi-task instruction tuning for generality across tasks, and a\nnumerical tokenization technique for improved processing of numerical data.\nThese enhancements allow BioT5+ to bridge the gap between molecular\nrepresentations and their textual descriptions, providing a more holistic\nunderstanding of biological entities, and largely improving the grounded\nreasoning of bio-text and bio-sequences. The model is pre-trained and\nfine-tuned with a large number of experiments, including \\emph{3 types of\nproblems (classification, regression, generation), 15 kinds of tasks, and 21\ntotal benchmark datasets}, demonstrating the remarkable performance and\nstate-of-the-art results in most cases. BioT5+ stands out for its ability to\ncapture intricate relationships in biological data, thereby contributing\nsignificantly to bioinformatics and computational biology. Our code is\navailable at \\url{https://github.com/QizhiPei/BioT5}.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Accepted by ACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2402.17810v2",
    "published_date": "2024-02-27 12:43:09 UTC",
    "updated_date": "2024-05-31 14:07:00 UTC"
  },
  {
    "arxiv_id": "2402.17456v1",
    "title": "A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education",
    "authors": [
      "Michael A. Hedderich",
      "Natalie N. Bazarova",
      "Wenting Zou",
      "Ryun Shim",
      "Xinda Ma",
      "Qian Yang"
    ],
    "abstract": "Cyberbullying harms teenagers' mental health, and teaching them upstanding\nintervention is crucial. Wizard-of-Oz studies show chatbots can scale up\npersonalized and interactive cyberbullying education, but implementing such\nchatbots is a challenging and delicate task. We created a no-code chatbot\ndesign tool for K-12 teachers. Using large language models and prompt chaining,\nour tool allows teachers to prototype bespoke dialogue flows and chatbot\nutterances. In offering this tool, we explore teachers' distinctive needs when\ndesigning chatbots to assist their teaching, and how chatbot design tools might\nbetter support them. Our findings reveal that teachers welcome the tool\nenthusiastically. Moreover, they see themselves as playwrights guiding both the\nstudents' and the chatbot's behaviors, while allowing for some improvisation.\nTheir goal is to enable students to rehearse both desirable and undesirable\nreactions to cyberbullying in a safe environment. We discuss the design\nopportunities LLM-Chains offer for empowering teachers and the research\nopportunities this work opens up.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17456v1",
    "published_date": "2024-02-27 12:27:51 UTC",
    "updated_date": "2024-02-27 12:27:51 UTC"
  },
  {
    "arxiv_id": "2402.17447v2",
    "title": "Deep Learning Based Named Entity Recognition Models for Recipes",
    "authors": [
      "Mansi Goel",
      "Ayush Agarwal",
      "Shubham Agrawal",
      "Janak Kapuriya",
      "Akhil Vamshi Konam",
      "Rishabh Gupta",
      "Shrey Rastogi",
      "Niharika",
      "Ganesh Bagler"
    ],
    "abstract": "Food touches our lives through various endeavors, including flavor,\nnourishment, health, and sustainability. Recipes are cultural capsules\ntransmitted across generations via unstructured text. Automated protocols for\nrecognizing named entities, the building blocks of recipe text, are of immense\nvalue for various applications ranging from information extraction to novel\nrecipe generation. Named entity recognition is a technique for extracting\ninformation from unstructured or semi-structured data with known labels.\nStarting with manually-annotated data of 6,611 ingredient phrases, we created\nan augmented dataset of 26,445 phrases cumulatively. Simultaneously, we\nsystematically cleaned and analyzed ingredient phrases from RecipeDB, the\ngold-standard recipe data repository, and annotated them using the Stanford\nNER. Based on the analysis, we sampled a subset of 88,526 phrases using a\nclustering-based approach while preserving the diversity to create the\nmachine-annotated dataset. A thorough investigation of NER approaches on these\nthree datasets involving statistical, fine-tuning of deep learning-based\nlanguage models and few-shot prompting on large language models (LLMs) provides\ndeep insights. We conclude that few-shot prompting on LLMs has abysmal\nperformance, whereas the fine-tuned spaCy-transformer emerges as the best model\nwith macro-F1 scores of 95.9%, 96.04%, and 95.71% for the manually-annotated,\naugmented, and machine-annotated datasets, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 6 main figures and 2 in appendices, and 3 main tables;\n  Accepted for publication in LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17447v2",
    "published_date": "2024-02-27 12:03:56 UTC",
    "updated_date": "2024-06-06 07:41:21 UTC"
  },
  {
    "arxiv_id": "2402.17442v4",
    "title": "Insights from the Usage of the Ansible Lightspeed Code Completion Service",
    "authors": [
      "Priyam Sahoo",
      "Saurabh Pujar",
      "Ganesh Nalawade",
      "Richard Gebhardt",
      "Louis Mandel",
      "Luca Buratti"
    ],
    "abstract": "The availability of Large Language Models (LLMs) which can generate code, has\nmade it possible to create tools that improve developer productivity.\nIntegrated development environments or IDEs which developers use to write\nsoftware are often used as an interface to interact with LLMs. Although many\nsuch tools have been released, almost all of them focus on general-purpose\nprogramming languages. Domain-specific languages, such as those crucial for\nInformation Technology (IT) automation, have not received much attention.\nAnsible is one such YAML-based IT automation-specific language. Ansible\nLightspeed is an LLM-based service designed explicitly to generate Ansible\nYAML, given natural language prompt.\n  In this paper, we present the design and implementation of the Ansible\nLightspeed service. We then evaluate its utility to developers using diverse\nindicators, including extended utilization, analysis of user edited\nsuggestions, as well as user sentiments analysis. The evaluation is based on\ndata collected for 10,696 real users including 3,910 returning users. The code\nfor Ansible Lightspeed service and the analysis framework is made available for\nothers to use.\n  To our knowledge, our study is the first to involve thousands of users of\ncode assistants for domain-specific languages. We are also the first code\ncompletion tool to present N-Day user retention figures, which is 13.66% on Day\n30. We propose an improved version of user acceptance rate, called Strong\nAcceptance rate, where a suggestion is considered accepted only if less than\n50% of it is edited and these edits do not change critical parts of the\nsuggestion. By focusing on Ansible, Lightspeed is able to achieve a strong\nacceptance rate of 49.08% for multi-line Ansible task suggestions. With our\nfindings we provide insights into the effectiveness of small, dedicated models\nin a domain-specific context.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been published at the 39th IEEE/ACM International\n  Conference on Automated Software Engineering (ASE 2024), Industry Showcase\n  under the title \"Ansible Lightspeed: A Code Generation Service for IT\n  Automation\"",
    "pdf_url": "http://arxiv.org/pdf/2402.17442v4",
    "published_date": "2024-02-27 11:57:28 UTC",
    "updated_date": "2024-10-22 10:30:19 UTC"
  },
  {
    "arxiv_id": "2402.17437v1",
    "title": "Exploiting Emotion-Semantic Correlations for Empathetic Response Generation",
    "authors": [
      "Zhou Yang",
      "Zhaochun Ren",
      "Yufeng Wang",
      "Xiaofei Zhu",
      "Zhihao Chen",
      "Tiecheng Cai",
      "Yunbing Wu",
      "Yisong Su",
      "Sibo Ju",
      "Xiangwen Liao"
    ],
    "abstract": "Empathetic response generation aims to generate empathetic responses by\nunderstanding the speaker's emotional feelings from the language of dialogue.\nRecent methods capture emotional words in the language of communicators and\nconstruct them as static vectors to perceive nuanced emotions. However,\nlinguistic research has shown that emotional words in language are dynamic and\nhave correlations with other grammar semantic roles, i.e., words with semantic\nmeanings, in grammar. Previous methods overlook these two characteristics,\nwhich easily lead to misunderstandings of emotions and neglect of key\nsemantics. To address this issue, we propose a dynamical Emotion-Semantic\nCorrelation Model (ESCM) for empathetic dialogue generation tasks. ESCM\nconstructs dynamic emotion-semantic vectors through the interaction of context\nand emotions. We introduce dependency trees to reflect the correlations between\nemotions and semantics. Based on dynamic emotion-semantic vectors and\ndependency trees, we propose a dynamic correlation graph convolutional network\nto guide the model in learning context meanings in dialogue and generating\nempathetic responses. Experimental results on the EMPATHETIC-DIALOGUES dataset\nshow that ESCM understands semantics and emotions more accurately and expresses\nfluent and informative empathetic responses. Our analysis results also indicate\nthat the correlations between emotions and semantics are frequently used in\ndialogues, which is of great significance for empathetic perception and\nexpression.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 3 figures, Findings of EMNLP 2023",
    "pdf_url": "http://arxiv.org/pdf/2402.17437v1",
    "published_date": "2024-02-27 11:50:05 UTC",
    "updated_date": "2024-02-27 11:50:05 UTC"
  },
  {
    "arxiv_id": "2402.17431v1",
    "title": "The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns",
    "authors": [
      "Luca Salvatore Lorello",
      "Marco Lippi",
      "Stefano Melacci"
    ],
    "abstract": "Artificial intelligence is continuously seeking novel challenges and\nbenchmarks to effectively measure performance and to advance the\nstate-of-the-art. In this paper we introduce KANDY, a benchmarking framework\nthat can be used to generate a variety of learning and reasoning tasks inspired\nby Kandinsky patterns. By creating curricula of binary classification tasks\nwith increasing complexity and with sparse supervisions, KANDY can be used to\nimplement benchmarks for continual and semi-supervised learning, with a\nspecific focus on symbol compositionality. Classification rules are also\nprovided in the ground truth to enable analysis of interpretable solutions.\nTogether with the benchmark generation pipeline, we release two curricula, an\neasier and a harder one, that we propose as new challenges for the research\ncommunity. With a thorough experimental evaluation, we show how both\nstate-of-the-art neural models and purely symbolic approaches struggle with\nsolving most of the tasks, thus calling for the application of advanced\nneuro-symbolic methods trained over time.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17431v1",
    "published_date": "2024-02-27 11:43:41 UTC",
    "updated_date": "2024-02-27 11:43:41 UTC"
  },
  {
    "arxiv_id": "2402.17423v3",
    "title": "Reinforced In-Context Black-Box Optimization",
    "authors": [
      "Lei Song",
      "Chenxiao Gao",
      "Ke Xue",
      "Chenyang Wu",
      "Dong Li",
      "Jianye Hao",
      "Zongzhang Zhang",
      "Chao Qian"
    ],
    "abstract": "Black-Box Optimization (BBO) has found successful applications in many fields\nof science and engineering. Recently, there has been a growing interest in\nmeta-learning particular components of BBO algorithms to speed up optimization\nand get rid of tedious hand-crafted heuristics. As an extension, learning the\nentire algorithm from data requires the least labor from experts and can\nprovide the most flexibility. In this paper, we propose RIBBO, a method to\nreinforce-learn a BBO algorithm from offline data in an end-to-end fashion.\nRIBBO employs expressive sequence models to learn the optimization histories\nproduced by multiple behavior algorithms and tasks, leveraging the in-context\nlearning ability of large models to extract task information and make decisions\naccordingly. Central to our method is to augment the optimization histories\nwith \\textit{regret-to-go} tokens, which are designed to represent the\nperformance of an algorithm based on cumulative regret over the future part of\nthe histories. The integration of regret-to-go tokens enables RIBBO to\nautomatically generate sequences of query points that satisfy the user-desired\nregret, which is verified by its universally good empirical performance on\ndiverse problems, including BBO benchmark functions, hyper-parameter\noptimization and robot control problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17423v3",
    "published_date": "2024-02-27 11:32:14 UTC",
    "updated_date": "2024-11-01 14:32:12 UTC"
  },
  {
    "arxiv_id": "2402.17420v2",
    "title": "PANDAS: Prototype-based Novel Class Discovery and Detection",
    "authors": [
      "Tyler L. Hayes",
      "César R. de Souza",
      "Namil Kim",
      "Jiwon Kim",
      "Riccardo Volpi",
      "Diane Larlus"
    ],
    "abstract": "Object detectors are typically trained once and for all on a fixed set of\nclasses. However, this closed-world assumption is unrealistic in practice, as\nnew classes will inevitably emerge after the detector is deployed in the wild.\nIn this work, we look at ways to extend a detector trained for a set of base\nclasses so it can i) spot the presence of novel classes, and ii) automatically\nenrich its repertoire to be able to detect those newly discovered classes\ntogether with the base ones. We propose PANDAS, a method for novel class\ndiscovery and detection. It discovers clusters representing novel classes from\nunlabeled data, and represents old and new classes with prototypes. During\ninference, a distance-based classifier uses these prototypes to assign a label\nto each detected object instance. The simplicity of our method makes it widely\napplicable. We experimentally demonstrate the effectiveness of PANDAS on the\nVOC 2012 and COCO-to-LVIS benchmarks. It performs favorably against the state\nof the art for this task while being computationally more affordable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to the Conference on Lifelong Learning Agents (CoLLAs 2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.17420v2",
    "published_date": "2024-02-27 11:23:39 UTC",
    "updated_date": "2024-04-30 15:05:34 UTC"
  },
  {
    "arxiv_id": "2402.17805v2",
    "title": "Graph Neural Networks and Arithmetic Circuits",
    "authors": [
      "Timon Barlag",
      "Vivian Holzapfel",
      "Laura Strieker",
      "Jonni Virtema",
      "Heribert Vollmer"
    ],
    "abstract": "We characterize the computational power of neural networks that follow the\ngraph neural network (GNN) architecture, not restricted to aggregate-combine\nGNNs or other particular types. We establish an exact correspondence between\nthe expressivity of GNNs using diverse activation functions and arithmetic\ncircuits over real numbers. In our results the activation function of the\nnetwork becomes a gate type in the circuit. Our result holds for families of\nconstant depth circuits and networks, both uniformly and non-uniformly, for all\ncommon activation functions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "F.1.1; F.1.3; I.2.m"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17805v2",
    "published_date": "2024-02-27 11:04:06 UTC",
    "updated_date": "2024-11-21 15:34:06 UTC"
  },
  {
    "arxiv_id": "2402.17410v2",
    "title": "Image space formalism of convolutional neural networks for k-space interpolation",
    "authors": [
      "Peter Dawood",
      "Felix Breuer",
      "Istvan Homolya",
      "Maximilian Gram",
      "Peter M. Jakob",
      "Moritz Zaiss",
      "Martin Blaimer"
    ],
    "abstract": "Purpose: Noise resilience in image reconstructions by scan-specific robust\nartificial neural networks for k-space interpolation (RAKI) is linked to\nnonlinear activations in k-space. To gain a deeper understanding of this\nrelationship, an image space formalism of RAKI is introduced for analyzing\nnoise propagation analytically, identifying and characterizing image\nreconstruction features and to describe the role of nonlinear activations in a\nhuman readable manner. Methods: The image space formalism for RAKI inference is\nemployed by expressing nonlinear activations in k-space as element-wise\nmultiplications with activation masks, which transform into convolutions in\nimage space. Jacobians of the de-aliased, coil-combined image relative to the\naliased coil images can be expressed algebraically, and thus, the noise\namplification is quantified analytically (g-factor maps). We analyze the role\nof nonlinearity for noise resilience by controlling the degree of nonlinearity\nin the reconstruction model via the negative slope parameter in leaky ReLU.\nResults: The analytical g-factor maps correspond with those obtained from Monte\nCarlo simulations and from an auto differentiation approach for in vivo brain\nimages. Apparent blurring and contrast loss artifacts are identified as\nimplications of enhanced noise resilience. These residual artifacts can be\ntraded against noise resilience by adjusting the degree of nonlinearity in the\nmodel (Tikhonov-like regularization) in case of limited training data. The\ninspection of image space activations reveals an autocorrelation pattern\nleading to a potential center artifact. Conclusion: The image space formalism\nof RAKI provides the means for analytical quantitative noisepropagation\nanalysis and human-readable visualization of the effects of the nonlinear\nactivation functions in k-space.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17410v2",
    "published_date": "2024-02-27 11:01:58 UTC",
    "updated_date": "2025-05-09 10:02:55 UTC"
  },
  {
    "arxiv_id": "2402.17407v2",
    "title": "A Neural Rewriting System to Solve Algorithmic Problems",
    "authors": [
      "Flavio Petruzzellis",
      "Alberto Testolin",
      "Alessandro Sperduti"
    ],
    "abstract": "Modern neural network architectures still struggle to learn algorithmic\nprocedures that require to systematically apply compositional rules to solve\nout-of-distribution problem instances. In this work, we focus on formula\nsimplification problems, a class of synthetic benchmarks used to study the\nsystematic generalization capabilities of neural architectures. We propose a\nmodular architecture designed to learn a general procedure for solving nested\nmathematical formulas by only relying on a minimal set of training examples.\nInspired by rewriting systems, a classic framework in symbolic artificial\nintelligence, we include in the architecture three specialized and interacting\nmodules: the Selector, trained to identify solvable sub-expressions; the\nSolver, mapping sub-expressions to their values; and the Combiner, replacing\nsub-expressions in the original formula with the solution provided by the\nSolver. We benchmark our system against the Neural Data Router, a recent model\nspecialized for systematic generalization, and a state-of-the-art large\nlanguage model (GPT-4) probed with advanced prompting strategies. We\ndemonstrate that our approach achieves a higher degree of out-of-distribution\ngeneralization compared to these alternative approaches on three different\ntypes of formula simplification problems, and we discuss its limitations by\nanalyzing its failures.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.NE",
    "comment": "Updated version (v2) accepted at the 27th European Conference on\n  Artificial Intelligence (ECAI 24)",
    "pdf_url": "http://arxiv.org/pdf/2402.17407v2",
    "published_date": "2024-02-27 10:57:07 UTC",
    "updated_date": "2024-07-12 15:42:45 UTC"
  },
  {
    "arxiv_id": "2402.17406v1",
    "title": "LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning",
    "authors": [
      "Shentong Mo",
      "Yansen Wang",
      "Xufang Luo",
      "Dongsheng Li"
    ],
    "abstract": "Visual Prompt Tuning (VPT) techniques have gained prominence for their\ncapacity to adapt pre-trained Vision Transformers (ViTs) to downstream visual\ntasks using specialized learnable tokens termed as prompts. Contemporary VPT\nmethodologies, especially when employed with self-supervised vision\ntransformers, often default to the introduction of new learnable prompts or\ngated prompt tokens predominantly sourced from the model's previous block. A\npivotal oversight in such approaches is their failure to harness the potential\nof long-range previous blocks as sources of prompts within each self-supervised\nViT. To bridge this crucial gap, we introduce Long-term Spatial Prompt Tuning\n(LSPT) - a revolutionary approach to visual representation learning. Drawing\ninspiration from the intricacies of the human brain, LSPT ingeniously\nincorporates long-term gated prompts. This feature serves as temporal coding,\ncurbing the risk of forgetting parameters acquired from earlier blocks. Further\nenhancing its prowess, LSPT brings into play patch tokens, serving as spatial\ncoding. This is strategically designed to perpetually amass class-conscious\nfeatures, thereby fortifying the model's prowess in distinguishing and\nidentifying visual categories. To validate the efficacy of our proposed method,\nwe engaged in rigorous experimentation across 5 FGVC and 19 VTAB-1K benchmarks.\nOur empirical findings underscore the superiority of LSPT, showcasing its\nability to set new benchmarks in visual prompt tuning performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17406v1",
    "published_date": "2024-02-27 10:55:07 UTC",
    "updated_date": "2024-02-27 10:55:07 UTC"
  },
  {
    "arxiv_id": "2402.17398v3",
    "title": "A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)",
    "authors": [
      "Nishikanta Mohanty",
      "Bikash K. Behera",
      "Christopher Ferrie",
      "Pravat Dash"
    ],
    "abstract": "The paper proposes the Quantum-SMOTE method, a novel solution that uses\nquantum computing techniques to solve the prevalent problem of class imbalance\nin machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority\nOversampling Technique (SMOTE), generates synthetic data points using quantum\nprocesses such as swap tests and quantum rotation. The process varies from the\nconventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean\ndistances, enabling synthetic instances to be generated from minority class\ndata points without relying on neighbor proximity. The algorithm asserts\ngreater control over the synthetic data generation process by introducing\nhyperparameters such as rotation angle, minority percentage, and splitting\nfactor, which allow for customization to specific dataset requirements. Due to\nthe use of a compact swap test, the algorithm can accommodate a large number of\nfeatures. Furthermore, the approach is tested on a public dataset of Telecom\nChurn and evaluated alongside two prominent classification algorithms, Random\nForest and Logistic Regression, to determine its impact along with varying\nproportions of synthetic data.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "42 Pages, 23 Figures, 2 Tables",
    "pdf_url": "http://arxiv.org/pdf/2402.17398v3",
    "published_date": "2024-02-27 10:46:36 UTC",
    "updated_date": "2024-07-04 10:06:23 UTC"
  },
  {
    "arxiv_id": "2402.17396v2",
    "title": "Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies",
    "authors": [
      "Flavio Petruzzellis",
      "Alberto Testolin",
      "Alessandro Sperduti"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized the field of Natural\nLanguage Processing thanks to their ability to reuse knowledge acquired on\nmassive text corpora on a wide variety of downstream tasks, with minimal (if\nany) tuning steps. At the same time, it has been repeatedly shown that LLMs\nlack systematic generalization, which allows to extrapolate the learned\nstatistical regularities outside the training distribution. In this work, we\noffer a systematic benchmarking of GPT-4, one of the most advanced LLMs\navailable, on three algorithmic tasks characterized by the possibility to\ncontrol the problem difficulty with two parameters. We compare the performance\nof GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the\nTransformer-Encoder architecture recently introduced to solve similar tasks,\nthe Neural Data Router. We find that the deployment of advanced prompting\ntechniques allows GPT-4 to reach superior accuracy on all tasks, demonstrating\nthat state-of-the-art LLMs constitute a very strong baseline also in\nchallenging tasks that require systematic generalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024. Added acknowledgements",
    "pdf_url": "http://arxiv.org/pdf/2402.17396v2",
    "published_date": "2024-02-27 10:44:52 UTC",
    "updated_date": "2024-07-11 15:54:45 UTC"
  },
  {
    "arxiv_id": "2402.17389v1",
    "title": "FairBelief -- Assessing Harmful Beliefs in Language Models",
    "authors": [
      "Mattia Setzu",
      "Marta Marchiori Manerba",
      "Pasquale Minervini",
      "Debora Nozza"
    ],
    "abstract": "Language Models (LMs) have been shown to inherit undesired biases that might\nhurt minorities and underrepresented groups if such systems were integrated\ninto real-world applications without careful fairness auditing. This paper\nproposes FairBelief, an analytical approach to capture and assess beliefs,\ni.e., propositions that an LM may embed with different degrees of confidence\nand that covertly influence its predictions. With FairBelief, we leverage\nprompting to study the behavior of several state-of-the-art LMs across\ndifferent previously neglected axes, such as model scale and likelihood,\nassessing predictions on a fairness dataset specifically designed to quantify\nLMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative\nassessment of the beliefs emitted by the models. We apply FairBelief to English\nLMs, revealing that, although these architectures enable high performances on\ndiverse natural language processing tasks, they show hurtful beliefs about\nspecific genders. Interestingly, training procedure and dataset, model scale,\nand architecture induce beliefs of different degrees of hurtfulness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17389v1",
    "published_date": "2024-02-27 10:31:00 UTC",
    "updated_date": "2024-02-27 10:31:00 UTC"
  },
  {
    "arxiv_id": "2402.17386v1",
    "title": "A case study of sending graph neural networks back to the test bench for applications in high-energy particle physics",
    "authors": [
      "Emanuel Pfeffer",
      "Michael Waßmer",
      "Yee-Ying Cung",
      "Roger Wolf",
      "Ulrich Husemann"
    ],
    "abstract": "In high-energy particle collisions, the primary collision products usually\ndecay further resulting in tree-like, hierarchical structures with a priori\nunknown multiplicity. At the stable-particle level all decay products of a\ncollision form permutation invariant sets of final state objects. The analogy\nto mathematical graphs gives rise to the idea that graph neural networks\n(GNNs), which naturally resemble these properties, should be best-suited to\naddress many tasks related to high-energy particle physics. In this paper we\ndescribe a benchmark test of a typical GNN against neural networks of the\nwell-established deep fully-connected feed-forward architecture. We aim at\nperforming this comparison maximally unbiased in terms of nodes, hidden layers,\nor trainable parameters of the neural networks under study. As physics case we\nuse the classification of the final state X produced in association with top\nquark-antiquark pairs in proton-proton collisions at the Large Hadron Collider\nat CERN, where X stands for a bottom quark-antiquark pair produced either\nnon-resonantly or through the decay of an intermediately produced Z or Higgs\nboson.",
    "categories": [
      "hep-ph",
      "cs.AI",
      "hep-ex"
    ],
    "primary_category": "hep-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17386v1",
    "published_date": "2024-02-27 10:26:25 UTC",
    "updated_date": "2024-02-27 10:26:25 UTC"
  },
  {
    "arxiv_id": "2402.17385v1",
    "title": "Determinants of LLM-assisted Decision-Making",
    "authors": [
      "Eva Eigner",
      "Thorsten Händler"
    ],
    "abstract": "Decision-making is a fundamental capability in everyday life. Large Language\nModels (LLMs) provide multifaceted support in enhancing human decision-making\nprocesses. However, understanding the influencing factors of LLM-assisted\ndecision-making is crucial for enabling individuals to utilize LLM-provided\nadvantages and minimize associated risks in order to make more informed and\nbetter decisions. This study presents the results of a comprehensive literature\nanalysis, providing a structural overview and detailed analysis of determinants\nimpacting decision-making with LLM support. In particular, we explore the\neffects of technological aspects of LLMs, including transparency and prompt\nengineering, psychological factors such as emotions and decision-making styles,\nas well as decision-specific determinants such as task difficulty and\naccountability. In addition, the impact of the determinants on the\ndecision-making process is illustrated via multiple application scenarios.\nDrawing from our analysis, we develop a dependency framework that systematizes\npossible interactions in terms of reciprocal interdependencies between these\ndeterminants. Our research reveals that, due to the multifaceted interactions\nwith various determinants, factors such as trust in or reliance on LLMs, the\nuser's mental model, and the characteristics of information processing are\nidentified as significant aspects influencing LLM-assisted decision-making\nprocesses. Our findings can be seen as crucial for improving decision quality\nin human-AI collaboration, empowering both users and organizations, and\ndesigning more effective LLM interfaces. Additionally, our work provides a\nfoundation for future empirical investigations on the determinants of\ndecision-making assisted by LLMs.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17385v1",
    "published_date": "2024-02-27 10:24:50 UTC",
    "updated_date": "2024-02-27 10:24:50 UTC"
  },
  {
    "arxiv_id": "2402.17376v3",
    "title": "Accelerating Diffusion Sampling with Optimized Time Steps",
    "authors": [
      "Shuchen Xue",
      "Zhaoqiang Liu",
      "Fei Chen",
      "Shifeng Zhang",
      "Tianyang Hu",
      "Enze Xie",
      "Zhenguo Li"
    ],
    "abstract": "Diffusion probabilistic models (DPMs) have shown remarkable performance in\nhigh-resolution image synthesis, but their sampling efficiency is still to be\ndesired due to the typically large number of sampling steps. Recent\nadvancements in high-order numerical ODE solvers for DPMs have enabled the\ngeneration of high-quality images with much fewer sampling steps. While this is\na significant development, most sampling methods still employ uniform time\nsteps, which is not optimal when using a small number of steps. To address this\nissue, we propose a general framework for designing an optimization problem\nthat seeks more appropriate time steps for a specific numerical ODE solver for\nDPMs. This optimization problem aims to minimize the distance between the\nground-truth solution to the ODE and an approximate solution corresponding to\nthe numerical solver. It can be efficiently solved using the constrained trust\nregion method, taking less than $15$ seconds. Our extensive experiments on both\nunconditional and conditional sampling using pixel- and latent-space DPMs\ndemonstrate that, when combined with the state-of-the-art sampling method\nUniPC, our optimized time steps significantly improve image generation\nperformance in terms of FID scores for datasets such as CIFAR-10 and ImageNet,\ncompared to using uniform time steps.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17376v3",
    "published_date": "2024-02-27 10:13:30 UTC",
    "updated_date": "2024-07-03 06:16:31 UTC"
  },
  {
    "arxiv_id": "2402.17360v1",
    "title": "CAPT: Category-level Articulation Estimation from a Single Point Cloud Using Transformer",
    "authors": [
      "Lian Fu",
      "Ryoichi Ishikawa",
      "Yoshihiro Sato",
      "Takeshi Oishi"
    ],
    "abstract": "The ability to estimate joint parameters is essential for various\napplications in robotics and computer vision. In this paper, we propose CAPT:\ncategory-level articulation estimation from a point cloud using Transformer.\nCAPT uses an end-to-end transformer-based architecture for joint parameter and\nstate estimation of articulated objects from a single point cloud. The proposed\nCAPT methods accurately estimate joint parameters and states for various\narticulated objects with high precision and robustness. The paper also\nintroduces a motion loss approach, which improves articulation estimation\nperformance by emphasizing the dynamic features of articulated objects.\nAdditionally, the paper presents a double voting strategy to provide the\nframework with coarse-to-fine parameter estimation. Experimental results on\nseveral category datasets demonstrate that our methods outperform existing\nalternatives for articulation estimation. Our research provides a promising\nsolution for applying Transformer-based architectures in articulated object\nanalysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17360v1",
    "published_date": "2024-02-27 09:53:16 UTC",
    "updated_date": "2024-02-27 09:53:16 UTC"
  },
  {
    "arxiv_id": "2403.00014v1",
    "title": "GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion",
    "authors": [
      "Le Cheng",
      "Peican Zhu",
      "Keke Tang",
      "Chao Gao",
      "Zhen Wang"
    ],
    "abstract": "Source detection in graphs has demonstrated robust efficacy in the domain of\nrumor source identification. Although recent solutions have enhanced\nperformance by leveraging deep neural networks, they often require complete\nuser data. In this paper, we address a more challenging task, rumor source\ndetection with incomplete user data, and propose a novel framework, i.e.,\nSource Detection in Graphs with Incomplete Nodes via Positional Encoding and\nAttentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach\nutilizes a positional embedding module to distinguish nodes that are incomplete\nand employs a self-attention mechanism to focus on nodes with greater\ninformation transmission capacity. To mitigate the prediction bias caused by\nthe significant disparity between the numbers of source and non-source nodes,\nwe also introduce a class-balancing mechanism. Extensive experiments validate\nthe effectiveness of GIN-SD and its superiority to state-of-the-art methods.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "The paper is accepted by AAAI24",
    "pdf_url": "http://arxiv.org/pdf/2403.00014v1",
    "published_date": "2024-02-27 09:35:54 UTC",
    "updated_date": "2024-02-27 09:35:54 UTC"
  },
  {
    "arxiv_id": "2402.17345v1",
    "title": "LocalGCL: Local-aware Contrastive Learning for Graphs",
    "authors": [
      "Haojun Jiang",
      "Jiawei Sun",
      "Jie Li",
      "Chentao Wu"
    ],
    "abstract": "Graph representation learning (GRL) makes considerable progress recently,\nwhich encodes graphs with topological structures into low-dimensional\nembeddings. Meanwhile, the time-consuming and costly process of annotating\ngraph labels manually prompts the growth of self-supervised learning (SSL)\ntechniques. As a dominant approach of SSL, Contrastive learning (CL) learns\ndiscriminative representations by differentiating between positive and negative\nsamples. However, when applied to graph data, it overemphasizes global patterns\nwhile neglecting local structures. To tackle the above issue, we propose\n\\underline{Local}-aware \\underline{G}raph \\underline{C}ontrastive\n\\underline{L}earning (\\textbf{\\methnametrim}), a self-supervised learning\nframework that supplementarily captures local graph information with\nmasking-based modeling compared with vanilla contrastive learning. Extensive\nexperiments validate the superiority of \\methname against state-of-the-art\nmethods, demonstrating its promise as a comprehensive graph representation\nlearner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17345v1",
    "published_date": "2024-02-27 09:23:54 UTC",
    "updated_date": "2024-02-27 09:23:54 UTC"
  },
  {
    "arxiv_id": "2402.17339v1",
    "title": "SocialCVAE: Predicting Pedestrian Trajectory via Interaction Conditioned Latents",
    "authors": [
      "Wei Xiang",
      "Haoteng Yin",
      "He Wang",
      "Xiaogang Jin"
    ],
    "abstract": "Pedestrian trajectory prediction is the key technology in many applications\nfor providing insights into human behavior and anticipating human future\nmotions. Most existing empirical models are explicitly formulated by observed\nhuman behaviors using explicable mathematical terms with a deterministic\nnature, while recent work has focused on developing hybrid models combined with\nlearning-based techniques for powerful expressiveness while maintaining\nexplainability. However, the deterministic nature of the learned steering\nbehaviors from the empirical models limits the models' practical performance.\nTo address this issue, this work proposes the social conditional variational\nautoencoder (SocialCVAE) for predicting pedestrian trajectories, which employs\na CVAE to explore behavioral uncertainty in human motion decisions. SocialCVAE\nlearns socially reasonable motion randomness by utilizing a socially\nexplainable interaction energy map as the CVAE's condition, which illustrates\nthe future occupancy of each pedestrian's local neighborhood area. The energy\nmap is generated using an energy-based interaction model, which anticipates the\nenergy cost (i.e., repulsion intensity) of pedestrians' interactions with\nneighbors. Experimental results on two public benchmarks including 25 scenes\ndemonstrate that SocialCVAE significantly improves prediction accuracy compared\nwith the state-of-the-art methods, with up to 16.85% improvement in Average\nDisplacement Error (ADE) and 69.18% improvement in Final Displacement Error\n(FDE).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI'24",
    "pdf_url": "http://arxiv.org/pdf/2402.17339v1",
    "published_date": "2024-02-27 09:13:27 UTC",
    "updated_date": "2024-02-27 09:13:27 UTC"
  },
  {
    "arxiv_id": "2402.17334v2",
    "title": "BiVRec: Bidirectional View-based Multimodal Sequential Recommendation",
    "authors": [
      "Jiaxi Hu",
      "Jingtong Gao",
      "Xiangyu Zhao",
      "Yuehong Hu",
      "Yuxuan Liang",
      "Yiqi Wang",
      "Ming He",
      "Zitao Liu",
      "Hongzhi Yin"
    ],
    "abstract": "The integration of multimodal information into sequential recommender systems\nhas attracted significant attention in recent research. In the initial stages\nof multimodal sequential recommendation models, the mainstream paradigm was\nID-dominant recommendations, wherein multimodal information was fused as side\ninformation. However, due to their limitations in terms of transferability and\ninformation intrusion, another paradigm emerged, wherein multimodal features\nwere employed directly for recommendation, enabling recommendation across\ndatasets. Nonetheless, it overlooked user ID information, resulting in low\ninformation utilization and high training costs. To this end, we propose an\ninnovative framework, BivRec, that jointly trains the recommendation tasks in\nboth ID and multimodal views, leveraging their synergistic relationship to\nenhance recommendation performance bidirectionally. To tackle the information\nheterogeneity issue, we first construct structured user interest\nrepresentations and then learn the synergistic relationship between them.\nSpecifically, BivRec comprises three modules: Multi-scale Interest Embedding,\ncomprehensively modeling user interests by expanding user interaction sequences\nwith multi-scale patching; Intra-View Interest Decomposition, constructing\nhighly structured interest representations using carefully designed Gaussian\nattention and Cluster attention; and Cross-View Interest Learning, learning the\nsynergistic relationship between the two recommendation views through\ncoarse-grained overall semantic similarity and fine-grained interest allocation\nsimilarity BiVRec achieves state-of-the-art performance on five datasets and\nshowcases various practical advantages.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17334v2",
    "published_date": "2024-02-27 09:10:41 UTC",
    "updated_date": "2024-03-05 04:12:34 UTC"
  },
  {
    "arxiv_id": "2402.17304v3",
    "title": "Probing Multimodal Large Language Models for Global and Local Semantic Representations",
    "authors": [
      "Mingxu Tao",
      "Quzhe Huang",
      "Kun Xu",
      "Liwei Chen",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "abstract": "The advancement of Multimodal Large Language Models (MLLMs) has greatly\naccelerated the development of applications in understanding integrated texts\nand images. Recent works leverage image-caption datasets to train MLLMs,\nachieving state-of-the-art performance on image-to-text tasks. However, there\nare few studies exploring which layers of MLLMs make the most effort to the\nglobal image information, which plays vital roles in multimodal comprehension\nand generation. In this study, we find that the intermediate layers of models\ncan encode more global semantic information, whose representation vectors\nperform better on visual-language entailment tasks, rather than the topmost\nlayers. We further probe models regarding local semantic representations\nthrough object recognition tasks. We find that the topmost layers may\nexcessively focus on local information, leading to a diminished ability to\nencode global information. Our code and data are released via\nhttps://github.com/kobayashikanna01/probing_MLLM_rep.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by LREC-COLING 2024 as a short paper. ACL Anthology URL:\n  [https://aclanthology.org/2024.lrec-main.1142/]",
    "pdf_url": "http://arxiv.org/pdf/2402.17304v3",
    "published_date": "2024-02-27 08:27:15 UTC",
    "updated_date": "2024-11-21 07:03:33 UTC"
  },
  {
    "arxiv_id": "2402.17289v2",
    "title": "Active propulsion noise shaping for multi-rotor aircraft localization",
    "authors": [
      "Gabriele Serussi",
      "Tamir Shor",
      "Tom Hirshberg",
      "Chaim Baskin",
      "Alex Bronstein"
    ],
    "abstract": "Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for\nnavigation purposes. However, visual localization and odometry techniques\nsuffer from poor performance in low or direct sunlight, a limited field of\nview, and vulnerability to occlusions. Acoustic sensing can serve as a\ncomplementary or even alternative modality for vision in many situations, and\nit also has the added benefits of lower system cost and energy footprint, which\nis especially important for micro aircraft. This paper proposes actively\ncontrolling and shaping the aircraft propulsion noise generated by the rotors\nto benefit localization tasks, rather than considering it a harmful nuisance.\nWe present a neural network architecture for selfnoise-based localization in a\nknown environment. We show that training it simultaneously with learning\ntime-varying rotor phase modulation achieves accurate and robust localization.\nThe proposed methods are evaluated using a computationally affordable\nsimulation of MAV rotor noise in 2D acoustic environments that is fitted to\nreal recordings of rotor pressure fields.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17289v2",
    "published_date": "2024-02-27 08:02:48 UTC",
    "updated_date": "2024-02-29 15:54:46 UTC"
  },
  {
    "arxiv_id": "2402.17285v1",
    "title": "Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder Super-resolution Network",
    "authors": [
      "Zhaoyang Wang",
      "Dongyang Li",
      "Mingyang Zhang",
      "Hao Luo",
      "Maoguo Gong"
    ],
    "abstract": "Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to\neffectively capture the complex spectral-spatial relationships and low-level\ndetails, while diffusion models represent a promising generative model known\nfor their exceptional performance in modeling complex relations and learning\nhigh and low-level visual features. The direct application of diffusion models\nto HSI SR is hampered by challenges such as difficulties in model convergence\nand protracted inference time. In this work, we introduce a novel\nGroup-Autoencoder (GAE) framework that synergistically combines with the\ndiffusion model to construct a highly effective HSI SR model (DMGASR). Our\nproposed GAE framework encodes high-dimensional HSI data into low-dimensional\nlatent space where the diffusion model works, thereby alleviating the\ndifficulty of training the diffusion model while maintaining band correlation\nand considerably reducing inference time. Experimental results on both natural\nand remote sensing hyperspectral datasets demonstrate that the proposed method\nis superior to other state-of-the-art methods both visually and metrically.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17285v1",
    "published_date": "2024-02-27 07:57:28 UTC",
    "updated_date": "2024-02-27 07:57:28 UTC"
  },
  {
    "arxiv_id": "2402.17270v2",
    "title": "Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas",
    "authors": [
      "Chunjiang Mu",
      "Hao Guo",
      "Yang Chen",
      "Chen Shen",
      "Shuyue Hu",
      "Zhen Wang"
    ],
    "abstract": "The study of cooperation within social dilemmas has long been a fundamental\ntopic across various disciplines, including computer science and social\nscience. Recent advancements in Artificial Intelligence (AI) have significantly\nreshaped this field, offering fresh insights into understanding and enhancing\ncooperation. This survey examines three key areas at the intersection of AI and\ncooperation in social dilemmas. First, focusing on multi-agent cooperation, we\nreview the intrinsic and external motivations that support cooperation among\nrational agents, and the methods employed to develop effective strategies\nagainst diverse opponents. Second, looking into human-agent cooperation, we\ndiscuss the current AI algorithms for cooperating with humans and the human\nbiases towards AI agents. Third, we review the emergent field of leveraging AI\nagents to enhance cooperation among humans. We conclude by discussing future\nresearch avenues, such as using large language models, establishing unified\ntheoretical frameworks, revisiting existing theories of human cooperation, and\nexploring multiple real-world applications.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17270v2",
    "published_date": "2024-02-27 07:31:30 UTC",
    "updated_date": "2024-07-30 12:21:17 UTC"
  },
  {
    "arxiv_id": "2402.17801v1",
    "title": "Generative AI and Copyright: A Dynamic Perspective",
    "authors": [
      "S. Alex Yang",
      "Angela Huyue Zhang"
    ],
    "abstract": "The rapid advancement of generative AI is poised to disrupt the creative\nindustry. Amidst the immense excitement for this new technology, its future\ndevelopment and applications in the creative industry hinge crucially upon two\ncopyright issues: 1) the compensation to creators whose content has been used\nto train generative AI models (the fair use standard); and 2) the eligibility\nof AI-generated content for copyright protection (AI-copyrightability). While\nboth issues have ignited heated debates among academics and practitioners, most\nanalysis has focused on their challenges posed to existing copyright doctrines.\nIn this paper, we aim to better understand the economic implications of these\ntwo regulatory issues and their interactions. By constructing a dynamic model\nwith endogenous content creation and AI model development, we unravel the\nimpacts of the fair use standard and AI-copyrightability on AI development, AI\ncompany profit, creators income, and consumer welfare, and how these impacts\nare influenced by various economic and operational factors. For example, while\ngenerous fair use (use data for AI training without compensating the creator)\nbenefits all parties when abundant training data exists, it can hurt creators\nand consumers when such data is scarce. Similarly, stronger AI-copyrightability\n(AI content enjoys more copyright protection) could hinder AI development and\nreduce social welfare. Our analysis also highlights the complex interplay\nbetween these two copyright issues. For instance, when existing training data\nis scarce, generous fair use may be preferred only when AI-copyrightability is\nweak. Our findings underscore the need for policymakers to embrace a dynamic,\ncontext-specific approach in making regulatory decisions and provide insights\nfor business leaders navigating the complexities of the global regulatory\nenvironment.",
    "categories": [
      "econ.TH",
      "cs.AI"
    ],
    "primary_category": "econ.TH",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17801v1",
    "published_date": "2024-02-27 07:12:48 UTC",
    "updated_date": "2024-02-27 07:12:48 UTC"
  },
  {
    "arxiv_id": "2402.17262v2",
    "title": "Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue",
    "authors": [
      "Zhenhong Zhou",
      "Jiuyang Xiang",
      "Haopeng Chen",
      "Quan Liu",
      "Zherui Li",
      "Sen Su"
    ],
    "abstract": "Large Language Models (LLMs) have been demonstrated to generate illegal or\nunethical responses, particularly when subjected to \"jailbreak.\" Research on\njailbreak has highlighted the safety issues of LLMs. However, prior studies\nhave predominantly focused on single-turn dialogue, ignoring the potential\ncomplexities and risks presented by multi-turn dialogue, a crucial mode through\nwhich humans derive information from LLMs. In this paper, we argue that humans\ncould exploit multi-turn dialogue to induce LLMs into generating harmful\ninformation. LLMs may not intend to reject cautionary or borderline unsafe\nqueries, even if each turn is closely served for one malicious purpose in a\nmulti-turn dialogue. Therefore, by decomposing an unsafe query into several\nsub-queries for multi-turn dialogue, we induced LLMs to answer harmful\nsub-questions incrementally, culminating in an overall harmful response. Our\nexperiments, conducted across a wide range of LLMs, indicate current\ninadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our\nfindings expose vulnerabilities of LLMs in complex scenarios involving\nmulti-turn dialogue, presenting new challenges for the safety of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "working in progress 23pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.17262v2",
    "published_date": "2024-02-27 07:11:59 UTC",
    "updated_date": "2024-10-30 05:43:51 UTC"
  },
  {
    "arxiv_id": "2402.17257v4",
    "title": "RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences",
    "authors": [
      "Jie Cheng",
      "Gang Xiong",
      "Xingyuan Dai",
      "Qinghai Miao",
      "Yisheng Lv",
      "Fei-Yue Wang"
    ],
    "abstract": "Preference-based Reinforcement Learning (PbRL) circumvents the need for\nreward engineering by harnessing human preferences as the reward signal.\nHowever, current PbRL methods excessively depend on high-quality feedback from\ndomain experts, which results in a lack of robustness. In this paper, we\npresent RIME, a robust PbRL algorithm for effective reward learning from noisy\npreferences. Our method utilizes a sample selection-based discriminator to\ndynamically filter out noise and ensure robust training. To counteract the\ncumulative error stemming from incorrect selection, we suggest a warm start for\nthe reward model, which additionally bridges the performance gap during the\ntransition from pre-training to online training in PbRL. Our experiments on\nrobotic manipulation and locomotion tasks demonstrate that RIME significantly\nenhances the robustness of the state-of-the-art PbRL method. Code is available\nat https://github.com/CJReinforce/RIME_ICML2024.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024 (Spotlight, top 3.5%)",
    "pdf_url": "http://arxiv.org/pdf/2402.17257v4",
    "published_date": "2024-02-27 07:03:25 UTC",
    "updated_date": "2024-10-28 12:26:53 UTC"
  },
  {
    "arxiv_id": "2402.17249v1",
    "title": "Deep Learning-Based Speech and Vision Synthesis to Improve Phishing Attack Detection through a Multi-layer Adaptive Framework",
    "authors": [
      "Tosin Ige",
      "Christopher Kiekintveld",
      "Aritran Piplai"
    ],
    "abstract": "The ever-evolving ways attacker continues to im prove their phishing\ntechniques to bypass existing state-of-the-art phishing detection methods pose\na mountain of challenges to researchers in both industry and academia research\ndue to the inability of current approaches to detect complex phishing attack.\nThus, current anti-phishing methods remain vulnerable to complex phishing\nbecause of the increasingly sophistication tactics adopted by attacker coupled\nwith the rate at which new tactics are being developed to evade detection. In\nthis research, we proposed an adaptable framework that combines Deep learning\nand Randon Forest to read images, synthesize speech from deep-fake videos, and\nnatural language processing at various predictions layered to significantly\nincrease the performance of machine learning models for phishing attack\ndetection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "8",
    "pdf_url": "http://arxiv.org/pdf/2402.17249v1",
    "published_date": "2024-02-27 06:47:52 UTC",
    "updated_date": "2024-02-27 06:47:52 UTC"
  },
  {
    "arxiv_id": "2402.17245v1",
    "title": "Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation",
    "authors": [
      "Daiqing Li",
      "Aleks Kamko",
      "Ehsan Akhgari",
      "Ali Sabet",
      "Linmiao Xu",
      "Suhail Doshi"
    ],
    "abstract": "In this work, we share three insights for achieving state-of-the-art\naesthetic quality in text-to-image generative models. We focus on three\ncritical aspects for model improvement: enhancing color and contrast, improving\ngeneration across multiple aspect ratios, and improving human-centric fine\ndetails. First, we delve into the significance of the noise schedule in\ntraining a diffusion model, demonstrating its profound impact on realism and\nvisual fidelity. Second, we address the challenge of accommodating various\naspect ratios in image generation, emphasizing the importance of preparing a\nbalanced bucketed dataset. Lastly, we investigate the crucial role of aligning\nmodel outputs with human preferences, ensuring that generated images resonate\nwith human perceptual expectations. Through extensive analysis and experiments,\nPlayground v2.5 demonstrates state-of-the-art performance in terms of aesthetic\nquality under various conditions and aspect ratios, outperforming both\nwidely-used open-source models like SDXL and Playground v2, and closed-source\ncommercial systems such as DALLE 3 and Midjourney v5.2. Our model is\nopen-source, and we hope the development of Playground v2.5 provides valuable\nguidelines for researchers aiming to elevate the aesthetic quality of\ndiffusion-based image generation models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Model weights:\n  https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic",
    "pdf_url": "http://arxiv.org/pdf/2402.17245v1",
    "published_date": "2024-02-27 06:31:52 UTC",
    "updated_date": "2024-02-27 06:31:52 UTC"
  },
  {
    "arxiv_id": "2402.17217v2",
    "title": "Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning",
    "authors": [
      "Zijian Guo",
      "Weichao Zhou",
      "Wenchao Li"
    ],
    "abstract": "Offline safe reinforcement learning (RL) aims to train a constraint\nsatisfaction policy from a fixed dataset. Current state-of-the-art approaches\nare based on supervised learning with a conditioned policy. However, these\napproaches fall short in real-world applications that involve complex tasks\nwith rich temporal and logical structures. In this paper, we propose temporal\nlogic Specification-conditioned Decision Transformer (SDT), a novel framework\nthat harnesses the expressive power of signal temporal logic (STL) to specify\ncomplex temporal rules that an agent should follow and the sequential modeling\ncapability of Decision Transformer (DT). Empirical evaluations on the DSRL\nbenchmarks demonstrate the better capacity of SDT in learning safe and\nhigh-reward policies compared with existing approaches. In addition, SDT shows\ngood alignment with respect to different desired degrees of satisfaction of the\nSTL specification that it is conditioned on.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17217v2",
    "published_date": "2024-02-27 05:16:59 UTC",
    "updated_date": "2025-01-24 23:37:54 UTC"
  },
  {
    "arxiv_id": "2402.17216v1",
    "title": "Application of Machine Learning Optimization in Cloud Computing Resource Scheduling and Management",
    "authors": [
      "Yifan Zhang",
      "Bo Liu",
      "Yulu Gong",
      "Jiaxin Huang",
      "Jingyu Xu",
      "Weixiang Wan"
    ],
    "abstract": "In recent years, cloud computing has been widely used. Cloud computing refers\nto the centralized computing resources, users through the access to the\ncentralized resources to complete the calculation, the cloud computing center\nwill return the results of the program processing to the user. Cloud computing\nis not only for individual users, but also for enterprise users. By purchasing\na cloud server, users do not have to buy a large number of computers, saving\ncomputing costs. According to a report by China Economic News Network, the\nscale of cloud computing in China has reached 209.1 billion yuan. At present,\nthe more mature cloud service providers in China are Ali Cloud, Baidu Cloud,\nHuawei Cloud and so on. Therefore, this paper proposes an innovative approach\nto solve complex problems in cloud computing resource scheduling and management\nusing machine learning optimization techniques. Through in-depth study of\nchallenges such as low resource utilization and unbalanced load in the cloud\nenvironment, this study proposes a comprehensive solution, including\noptimization methods such as deep learning and genetic algorithm, to improve\nsystem performance and efficiency, and thus bring new breakthroughs and\nprogress in the field of cloud computing resource management.Rational\nallocation of resources plays a crucial role in cloud computing. In the\nresource allocation of cloud computing, the cloud computing center has limited\ncloud resources, and users arrive in sequence. Each user requests the cloud\ncomputing center to use a certain number of cloud resources at a specific time.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17216v1",
    "published_date": "2024-02-27 05:14:27 UTC",
    "updated_date": "2024-02-27 05:14:27 UTC"
  },
  {
    "arxiv_id": "2402.17213v1",
    "title": "VCD: Knowledge Base Guided Visual Commonsense Discovery in Images",
    "authors": [
      "Xiangqing Shen",
      "Yurun Song",
      "Siwei Wu",
      "Rui Xia"
    ],
    "abstract": "Visual commonsense contains knowledge about object properties, relationships,\nand behaviors in visual data. Discovering visual commonsense can provide a more\ncomprehensive and richer understanding of images, and enhance the reasoning and\ndecision-making capabilities of computer vision systems. However, the visual\ncommonsense defined in existing visual commonsense discovery studies is\ncoarse-grained and incomplete. In this work, we draw inspiration from a\ncommonsense knowledge base ConceptNet in natural language processing, and\nsystematically define the types of visual commonsense. Based on this, we\nintroduce a new task, Visual Commonsense Discovery (VCD), aiming to extract\nfine-grained commonsense of different types contained within different objects\nin the image. We accordingly construct a dataset (VCDD) from Visual Genome and\nConceptNet for VCD, featuring over 100,000 images and 14 million\nobject-commonsense pairs. We furthermore propose a generative model (VCDM) that\nintegrates a vision-language model with instruction tuning to tackle VCD.\nAutomatic and human evaluations demonstrate VCDM's proficiency in VCD,\nparticularly outperforming GPT-4V in implicit commonsense discovery. The value\nof VCD is further demonstrated by its application to two downstream tasks,\nincluding visual commonsense evaluation and visual question answering. The data\nand code will be made available on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17213v1",
    "published_date": "2024-02-27 05:10:44 UTC",
    "updated_date": "2024-02-27 05:10:44 UTC"
  },
  {
    "arxiv_id": "2402.17205v3",
    "title": "Measuring Vision-Language STEM Skills of Neural Models",
    "authors": [
      "Jianhao Shen",
      "Ye Yuan",
      "Srbuhi Mirzoyan",
      "Ming Zhang",
      "Chenguang Wang"
    ],
    "abstract": "We introduce a new challenge to test the STEM skills of neural models. The\nproblems in the real world often require solutions, combining knowledge from\nSTEM (science, technology, engineering, and math). Unlike existing datasets,\nour dataset requires the understanding of multimodal vision-language\ninformation of STEM. Our dataset features one of the largest and most\ncomprehensive datasets for the challenge. It includes 448 skills and 1,073,146\nquestions spanning all STEM subjects. Compared to existing datasets that often\nfocus on examining expert-level ability, our dataset includes fundamental\nskills and questions designed based on the K-12 curriculum. We also add\nstate-of-the-art foundation models such as CLIP and GPT-3.5-Turbo to our\nbenchmark. Results show that the recent model advances only help master a very\nlimited number of lower grade-level skills (2.5% in the third grade) in our\ndataset. In fact, these models are still well below (averaging 54.7%) the\nperformance of elementary students, not to mention near expert-level\nperformance. To understand and increase the performance on our dataset, we\nteach the models on a training split of our dataset. Even though we observe\nimproved performance, the model performance remains relatively low compared to\naverage elementary students. To solve STEM problems, we will need novel\nalgorithmic innovations from the community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17205v3",
    "published_date": "2024-02-27 04:55:03 UTC",
    "updated_date": "2024-05-22 05:11:56 UTC"
  },
  {
    "arxiv_id": "2402.17191v1",
    "title": "AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning",
    "authors": [
      "Le Yang",
      "Miao Tian",
      "Duan Xin",
      "Qishuo Cheng",
      "Jiajian Zheng"
    ],
    "abstract": "The development of artificial intelligence has significantly transformed\npeople's lives. However, it has also posed a significant threat to privacy and\nsecurity, with numerous instances of personal information being exposed online\nand reports of criminal attacks and theft. Consequently, the need to achieve\nintelligent protection of personal information through machine learning\nalgorithms has become a paramount concern. Artificial intelligence leverages\nadvanced algorithms and technologies to effectively encrypt and anonymize\npersonal data, enabling valuable data analysis and utilization while\nsafeguarding privacy. This paper focuses on personal data privacy protection\nand the promotion of anonymity as its core research objectives. It achieves\npersonal data privacy protection and detection through the use of machine\nlearning's differential privacy protection algorithm. The paper also addresses\nexisting challenges in machine learning related to privacy and personal data\nprotection, offers improvement suggestions, and analyzes factors impacting\ndatasets to enable timely personal data privacy detection and protection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.17191v1",
    "published_date": "2024-02-27 04:12:25 UTC",
    "updated_date": "2024-02-27 04:12:25 UTC"
  },
  {
    "arxiv_id": "2402.17189v1",
    "title": "An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement",
    "authors": [
      "Tzu-Ting Yang",
      "Hsin-Wei Wang",
      "Yi-Cheng Wang",
      "Chi-Han Lin",
      "Berlin Chen"
    ],
    "abstract": "With the massive developments of end-to-end (E2E) neural networks, recent\nyears have witnessed unprecedented breakthroughs in automatic speech\nrecognition (ASR). However, the codeswitching phenomenon remains a major\nobstacle that hinders ASR from perfection, as the lack of labeled data and the\nvariations between languages often lead to degradation of ASR performance. In\nthis paper, we focus exclusively on improving the acoustic encoder of E2E ASR\nto tackle the challenge caused by the codeswitching phenomenon. Our main\ncontributions are threefold: First, we introduce a novel disentanglement loss\nto enable the lower-layer of the encoder to capture inter-lingual acoustic\ninformation while mitigating linguistic confusion at the higher-layer of the\nencoder. Second, through comprehensive experiments, we verify that our proposed\nmethod outperforms the prior-art methods using pretrained dual-encoders,\nmeanwhile having access only to the codeswitching corpus and consuming half of\nthe parameterization. Third, the apparent differentiation of the encoders'\noutput features also corroborates the complementarity between the\ndisentanglement loss and the mixture-of-experts (MoE) architecture.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17189v1",
    "published_date": "2024-02-27 04:08:59 UTC",
    "updated_date": "2024-02-27 04:08:59 UTC"
  },
  {
    "arxiv_id": "2403.07911v2",
    "title": "Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems",
    "authors": [
      "Alison Callahan",
      "Duncan McElfresh",
      "Juan M. Banda",
      "Gabrielle Bunney",
      "Danton Char",
      "Jonathan Chen",
      "Conor K. Corbin",
      "Debadutta Dash",
      "Norman L. Downing",
      "Sneha S. Jain",
      "Nikesh Kotecha",
      "Jonathan Masterson",
      "Michelle M. Mello",
      "Keith Morse",
      "Srikar Nallan",
      "Abby Pandya",
      "Anurang Revri",
      "Aditya Sharma",
      "Christopher Sharp",
      "Rahul Thapa",
      "Michael Wornow",
      "Alaa Youssef",
      "Michael A. Pfeffer",
      "Nigam H. Shah"
    ],
    "abstract": "The impact of using artificial intelligence (AI) to guide patient care or\noperational processes is an interplay of the AI model's output, the\ndecision-making protocol based on that output, and the capacity of the\nstakeholders involved to take the necessary subsequent action. Estimating the\neffects of this interplay before deployment, and studying it in real time\nafterwards, are essential to bridge the chasm between AI model development and\nachievable benefit. To accomplish this, the Data Science team at Stanford\nHealth Care has developed a Testing and Evaluation (T&E) mechanism to identify\nfair, useful and reliable AI models (FURM) by conducting an ethical review to\nidentify potential value mismatches, simulations to estimate usefulness,\nfinancial projections to assess sustainability, as well as analyses to\ndetermine IT feasibility, design a deployment strategy, and recommend a\nprospective monitoring and evaluation plan. We report on FURM assessments done\nto evaluate six AI guided solutions for potential adoption, spanning clinical\nand operational settings, each with the potential to impact from several dozen\nto tens of thousands of patients each year. We describe the assessment process,\nsummarize the six assessments, and share our framework to enable others to\nconduct similar assessments. Of the six solutions we assessed, two have moved\ninto a planning and implementation phase. Our novel contributions - usefulness\nestimates by simulation, financial projections to quantify sustainability, and\na process to do ethical assessments - as well as their underlying methods and\nopen source tools, are available for other healthcare systems to conduct\nactionable evaluations of candidate AI solutions.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07911v2",
    "published_date": "2024-02-27 03:33:40 UTC",
    "updated_date": "2024-03-14 18:37:53 UTC"
  },
  {
    "arxiv_id": "2402.17177v3",
    "title": "Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models",
    "authors": [
      "Yixin Liu",
      "Kai Zhang",
      "Yuan Li",
      "Zhiling Yan",
      "Chujie Gao",
      "Ruoxi Chen",
      "Zhengqing Yuan",
      "Yue Huang",
      "Hanchi Sun",
      "Jianfeng Gao",
      "Lifang He",
      "Lichao Sun"
    ],
    "abstract": "Sora is a text-to-video generative AI model, released by OpenAI in February\n2024. The model is trained to generate videos of realistic or imaginative\nscenes from text instructions and show potential in simulating the physical\nworld. Based on public technical reports and reverse engineering, this paper\npresents a comprehensive review of the model's background, related\ntechnologies, applications, remaining challenges, and future directions of\ntext-to-video AI models. We first trace Sora's development and investigate the\nunderlying technologies used to build this \"world simulator\". Then, we describe\nin detail the applications and potential impact of Sora in multiple industries\nranging from film-making and education to marketing. We discuss the main\nchallenges and limitations that need to be addressed to widely deploy Sora,\nsuch as ensuring safe and unbiased video generation. Lastly, we discuss the\nfuture development of Sora and video generation models in general, and how\nadvancements in the field could enable new ways of human-AI interaction,\nboosting productivity and creativity of video generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "37 pages, 18 figures; GitHub:\n  https://github.com/lichao-sun/SoraReview",
    "pdf_url": "http://arxiv.org/pdf/2402.17177v3",
    "published_date": "2024-02-27 03:30:58 UTC",
    "updated_date": "2024-04-17 18:41:39 UTC"
  },
  {
    "arxiv_id": "2402.17168v1",
    "title": "Benchmarking Data Science Agents",
    "authors": [
      "Yuge Zhang",
      "Qiyang Jiang",
      "Xingyu Han",
      "Nan Chen",
      "Yuqing Yang",
      "Kan Ren"
    ],
    "abstract": "In the era of data-driven decision-making, the complexity of data analysis\nnecessitates advanced expertise and tools of data science, presenting\nsignificant challenges even for specialists. Large Language Models (LLMs) have\nemerged as promising aids as data science agents, assisting humans in data\nanalysis and processing. Yet their practical efficacy remains constrained by\nthe varied demands of real-world applications and complicated analytical\nprocess. In this paper, we introduce DSEval -- a novel evaluation paradigm, as\nwell as a series of innovative benchmarks tailored for assessing the\nperformance of these agents throughout the entire data science lifecycle.\nIncorporating a novel bootstrapped annotation method, we streamline dataset\npreparation, improve the evaluation coverage, and expand benchmarking\ncomprehensiveness. Our findings uncover prevalent obstacles and provide\ncritical insights to inform future advancements in the field.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Source code and data are available at\n  https://github.com/MetaCopilot/dseval",
    "pdf_url": "http://arxiv.org/pdf/2402.17168v1",
    "published_date": "2024-02-27 03:03:06 UTC",
    "updated_date": "2024-02-27 03:03:06 UTC"
  },
  {
    "arxiv_id": "2402.17161v1",
    "title": "Large Language Model for Participatory Urban Planning",
    "authors": [
      "Zhilun Zhou",
      "Yuming Lin",
      "Depeng Jin",
      "Yong Li"
    ],
    "abstract": "Participatory urban planning is the mainstream of modern urban planning that\ninvolves the active engagement of residents. However, the traditional\nparticipatory paradigm requires experienced planning experts and is often\ntime-consuming and costly. Fortunately, the emerging Large Language Models\n(LLMs) have shown considerable ability to simulate human-like agents, which can\nbe used to emulate the participatory process easily. In this work, we introduce\nan LLM-based multi-agent collaboration framework for participatory urban\nplanning, which can generate land-use plans for urban regions considering the\ndiverse needs of residents. Specifically, we construct LLM agents to simulate a\nplanner and thousands of residents with diverse profiles and backgrounds. We\nfirst ask the planner to carry out an initial land-use plan. To deal with the\ndifferent facilities needs of residents, we initiate a discussion among the\nresidents in each community about the plan, where residents provide feedback\nbased on their profiles. Furthermore, to improve the efficiency of discussion,\nwe adopt a fishbowl discussion mechanism, where part of the residents discuss\nand the rest of them act as listeners in each round. Finally, we let the\nplanner modify the plan based on residents' feedback. We deploy our method on\ntwo real-world regions in Beijing. Experiments show that our method achieves\nstate-of-the-art performance in residents satisfaction and inclusion metrics,\nand also outperforms human experts in terms of service accessibility and\necology metrics.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2402.01698",
    "pdf_url": "http://arxiv.org/pdf/2402.17161v1",
    "published_date": "2024-02-27 02:47:50 UTC",
    "updated_date": "2024-02-27 02:47:50 UTC"
  },
  {
    "arxiv_id": "2402.17156v1",
    "title": "TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation",
    "authors": [
      "Lin Zongying",
      "Li Hao",
      "Lv Liuzhenghao",
      "Lin Bin",
      "Zhang Junwu",
      "Chen Calvin Yu-Chian",
      "Yuan Li",
      "Tian Yonghong"
    ],
    "abstract": "Designing protein sequences with specific biological functions and structural\nstability is crucial in biology and chemistry. Generative models already\ndemonstrated their capabilities for reliable protein design. However, previous\nmodels are limited to the unconditional generation of protein sequences and\nlack the controllable generation ability that is vital to biological tasks. In\nthis work, we propose TaxDiff, a taxonomic-guided diffusion model for\ncontrollable protein sequence generation that combines biological species\ninformation with the generative capabilities of diffusion models to generate\nstructurally stable proteins within the sequence space. Specifically, taxonomic\ncontrol information is inserted into each layer of the transformer block to\nachieve fine-grained control. The combination of global and local attention\nensures the sequence consistency and structural foldability of\ntaxonomic-specific proteins. Extensive experiments demonstrate that TaxDiff can\nconsistently achieve better performance on multiple protein sequence generation\nbenchmarks in both taxonomic-guided controllable generation and unconditional\ngeneration. Remarkably, the sequences generated by TaxDiff even surpass those\nproduced by direct-structure-generation models in terms of confidence based on\npredicted structures and require only a quarter of the time of models based on\nthe diffusion model. The code for generating proteins and training new versions\nof TaxDiff is available at:https://github.com/Linzy19/TaxDiff.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17156v1",
    "published_date": "2024-02-27 02:41:46 UTC",
    "updated_date": "2024-02-27 02:41:46 UTC"
  },
  {
    "arxiv_id": "2405.00026v1",
    "title": "Enhancing Credit Card Fraud Detection A Neural Network and SMOTE Integrated Approach",
    "authors": [
      "Mengran Zhu",
      "Ye Zhang",
      "Yulu Gong",
      "Changxin Xu",
      "Yafei Xiang"
    ],
    "abstract": "Credit card fraud detection is a critical challenge in the financial sector,\ndemanding sophisticated approaches to accurately identify fraudulent\ntransactions. This research proposes an innovative methodology combining Neural\nNetworks (NN) and Synthet ic Minority Over-sampling Technique (SMOTE) to\nenhance the detection performance. The study addresses the inherent imbalance\nin credit card transaction data, focusing on technical advancements for robust\nand precise fraud detection. Results demonstrat e that the integration of NN\nand SMOTE exhibits superior precision, recall, and F1-score compared to\ntraditional models, highlighting its potential as an advanced solution for\nhandling imbalanced datasets in credit card fraud detection scenarios. This\nrese arch contributes to the ongoing efforts to develop effective and efficient\nmechanisms for safeguarding financial transactions from fraudulent activities.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.00026v1",
    "published_date": "2024-02-27 02:26:04 UTC",
    "updated_date": "2024-02-27 02:26:04 UTC"
  },
  {
    "arxiv_id": "2402.17144v1",
    "title": "Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation",
    "authors": [
      "Yuankai Fan",
      "Zhenying He",
      "Tonghui Ren",
      "Can Huang",
      "Yinan Jing",
      "Kai Zhang",
      "X. Sean Wang"
    ],
    "abstract": "The Natural Language Interface to Databases (NLIDB) empowers non-technical\nusers with database access through intuitive natural language (NL)\ninteractions. Advanced approaches, utilizing neural sequence-to-sequence models\nor large-scale language models, typically employ auto-regressive decoding to\ngenerate unique SQL queries sequentially. While these translation models have\ngreatly improved the overall translation accuracy, surpassing 70% on NLIDB\nbenchmarks, the use of auto-regressive decoding to generate single SQL queries\nmay result in sub-optimal outputs, potentially leading to erroneous\ntranslations. In this paper, we propose Metasql, a unified generate-then-rank\nframework that can be flexibly incorporated with existing NLIDBs to\nconsistently improve their translation accuracy. Metasql introduces query\nmetadata to control the generation of better SQL query candidates and uses\nlearning-to-rank algorithms to retrieve globally optimized queries.\nSpecifically, Metasql first breaks down the meaning of the given NL query into\na set of possible query metadata, representing the basic concepts of the\nsemantics. These metadata are then used as language constraints to steer the\nunderlying translation model toward generating a set of candidate SQL queries.\nFinally, Metasql ranks the candidates to identify the best matching one for the\ngiven NL query. Extensive experiments are performed to study Metasql on two\npublic NLIDB benchmarks. The results show that the performance of the\ntranslation models can be effectively improved using Metasql.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17144v1",
    "published_date": "2024-02-27 02:16:07 UTC",
    "updated_date": "2024-02-27 02:16:07 UTC"
  },
  {
    "arxiv_id": "2402.17139v1",
    "title": "Video as the New Language for Real-World Decision Making",
    "authors": [
      "Sherry Yang",
      "Jacob Walker",
      "Jack Parker-Holder",
      "Yilun Du",
      "Jake Bruce",
      "Andre Barreto",
      "Pieter Abbeel",
      "Dale Schuurmans"
    ],
    "abstract": "Both text and video data are abundant on the internet and support large-scale\nself-supervised learning through next token or frame prediction. However, they\nhave not been equally leveraged: language models have had significant\nreal-world impact, whereas video generation has remained largely limited to\nmedia entertainment. Yet video data captures important information about the\nphysical world that is difficult to express in language. To address this gap,\nwe discuss an under-appreciated opportunity to extend video generation to solve\ntasks in the real world. We observe how, akin to language, video can serve as a\nunified interface that can absorb internet knowledge and represent diverse\ntasks. Moreover, we demonstrate how, like language models, video generation can\nserve as planners, agents, compute engines, and environment simulators through\ntechniques such as in-context learning, planning and reinforcement learning. We\nidentify major impact opportunities in domains such as robotics, self-driving,\nand science, supported by recent work that demonstrates how such advanced\ncapabilities in video generation are plausibly within reach. Lastly, we\nidentify key challenges in video generation that mitigate progress. Addressing\nthese challenges will enable video generation models to demonstrate unique\nvalue alongside language models in a wider array of AI applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17139v1",
    "published_date": "2024-02-27 02:05:29 UTC",
    "updated_date": "2024-02-27 02:05:29 UTC"
  },
  {
    "arxiv_id": "2402.17135v1",
    "title": "Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings",
    "authors": [
      "Kevin Frans",
      "Seohong Park",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "abstract": "Can we pre-train a generalist agent from a large amount of unlabeled offline\ntrajectories such that it can be immediately adapted to any new downstream\ntasks in a zero-shot manner? In this work, we present a functional reward\nencoding (FRE) as a general, scalable solution to this zero-shot RL problem.\nOur main idea is to learn functional representations of any arbitrary tasks by\nencoding their state-reward samples using a transformer-based variational\nauto-encoder. This functional encoding not only enables the pre-training of an\nagent from a wide diversity of general unsupervised reward functions, but also\nprovides a way to solve any new downstream tasks in a zero-shot manner, given a\nsmall number of reward-annotated samples. We empirically show that FRE agents\ntrained on diverse random unsupervised reward functions can generalize to solve\nnovel tasks in a range of simulated robotic benchmarks, often outperforming\nprevious zero-shot RL and offline RL methods. Code for this project is provided\nat: https://github.com/kvfrans/fre",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.17135v1",
    "published_date": "2024-02-27 01:59:02 UTC",
    "updated_date": "2024-02-27 01:59:02 UTC"
  },
  {
    "arxiv_id": "2402.17128v4",
    "title": "OSCaR: Object State Captioning and State Change Representation",
    "authors": [
      "Nguyen Nguyen",
      "Jing Bi",
      "Ali Vosoughi",
      "Yapeng Tian",
      "Pooyan Fazli",
      "Chenliang Xu"
    ],
    "abstract": "The capability of intelligent models to extrapolate and comprehend changes in\nobject states is a crucial yet demanding aspect of AI research, particularly\nthrough the lens of human interaction in real-world settings. This task\ninvolves describing complex visual environments, identifying active objects,\nand interpreting their changes as conveyed through language. Traditional\nmethods, which isolate object captioning and state change detection, offer a\nlimited view of dynamic environments. Moreover, relying on a small set of\nsymbolic words to represent changes has restricted the expressiveness of the\nlanguage. To address these challenges, in this paper, we introduce the Object\nState Captioning and State Change Representation (OSCaR) dataset and benchmark.\nOSCaR consists of 14,084 annotated video segments with nearly 1,000 unique\nobjects from various egocentric video collections. It sets a new testbed for\nevaluating multimodal large language models (MLLMs). Our experiments\ndemonstrate that while MLLMs show some skill, they lack a full understanding of\nobject state changes. The benchmark includes a fine-tuned model that, despite\ninitial capabilities, requires significant improvements in accuracy and\ngeneralization ability for effective understanding of these changes. Our code\nand dataset are available at https://github.com/nguyennm1024/OSCaR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.17128v4",
    "published_date": "2024-02-27 01:48:19 UTC",
    "updated_date": "2024-04-02 23:14:42 UTC"
  },
  {
    "arxiv_id": "2403.05576v1",
    "title": "Understanding Subjectivity through the Lens of Motivational Context in Model-Generated Image Satisfaction",
    "authors": [
      "Senjuti Dutta",
      "Sherol Chen",
      "Sunny Mak",
      "Amnah Ahmad",
      "Katherine Collins",
      "Alena Butryna",
      "Deepak Ramachandran",
      "Krishnamurthy Dvijotham",
      "Ellie Pavlick",
      "Ravi Rajakumar"
    ],
    "abstract": "Image generation models are poised to become ubiquitous in a range of\napplications. These models are often fine-tuned and evaluated using human\nquality judgments that assume a universal standard, failing to consider the\nsubjectivity of such tasks. To investigate how to quantify subjectivity, and\nthe scale of its impact, we measure how assessments differ among human\nannotators across different use cases. Simulating the effects of ordinarily\nlatent elements of annotators subjectivity, we contrive a set of motivations\n(t-shirt graphics, presentation visuals, and phone background images) to\ncontextualize a set of crowdsourcing tasks. Our results show that human\nevaluations of images vary within individual contexts and across combinations\nof contexts. Three key factors affecting this subjectivity are image\nappearance, image alignment with text, and representation of objects mentioned\nin the text. Our study highlights the importance of taking individual users and\ncontexts into account, both when building and evaluating generative models",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05576v1",
    "published_date": "2024-02-27 01:16:55 UTC",
    "updated_date": "2024-02-27 01:16:55 UTC"
  },
  {
    "arxiv_id": "2402.17101v1",
    "title": "T-HITL Effectively Addresses Problematic Associations in Image Generation and Maintains Overall Visual Quality",
    "authors": [
      "Susan Epstein",
      "Li Chen",
      "Alessandro Vecchiato",
      "Ankit Jain"
    ],
    "abstract": "Generative AI image models may inadvertently generate problematic\nrepresentations of people. Past research has noted that millions of users\nengage daily across the world with these models and that the models, including\nthrough problematic representations of people, have the potential to compound\nand accelerate real-world discrimination and other harms (Bianchi et al, 2023).\nIn this paper, we focus on addressing the generation of problematic\nassociations between demographic groups and semantic concepts that may reflect\nand reinforce negative narratives embedded in social data. Building on\nsociological literature (Blumer, 1958) and mapping representations to model\nbehaviors, we have developed a taxonomy to study problematic associations in\nimage generation models. We explore the effectiveness of fine tuning at the\nmodel level as a method to address these associations, identifying a potential\nreduction in visual quality as a limitation of traditional fine tuning. We also\npropose a new methodology with twice-human-in-the-loop (T-HITL) that promises\nimprovements in both reducing problematic associations and also maintaining\nvisual quality. We demonstrate the effectiveness of T-HITL by providing\nevidence of three problematic associations addressed by T-HITL at the model\nlevel. Our contributions to scholarship are two-fold. By defining problematic\nassociations in the context of machine learning models and generative AI, we\nintroduce a conceptual and technical taxonomy for addressing some of these\nassociations. Finally, we provide a method, T-HITL, that addresses these\nassociations and simultaneously maintains visual quality of image model\ngenerations. This mitigation need not be a tradeoff, but rather an enhancement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.I.2",
      "I.2.1"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.17101v1",
    "published_date": "2024-02-27 00:29:33 UTC",
    "updated_date": "2024-02-27 00:29:33 UTC"
  },
  {
    "arxiv_id": "2403.00824v2",
    "title": "Information Flow Routes: Automatically Interpreting Language Models at Scale",
    "authors": [
      "Javier Ferrando",
      "Elena Voita"
    ],
    "abstract": "Information flows by routes inside the network via mechanisms implemented in\nthe model. These routes can be represented as graphs where nodes correspond to\ntoken representations and edges to operations inside the network. We\nautomatically build these graphs in a top-down manner, for each prediction\nleaving only the most important nodes and edges. In contrast to the existing\nworkflows relying on activation patching, we do this through attribution: this\nallows us to efficiently uncover existing circuits with just a single forward\npass. Additionally, the applicability of our method is far beyond patching: we\ndo not need a human to carefully design prediction templates, and we can\nextract information flow routes for any prediction (not just the ones among the\nallowed templates). As a result, we can talk about model behavior in general,\nfor specific types of predictions, or different domains. We experiment with\nLlama 2 and show that the role of some attention heads is overall important,\ne.g. previous token heads and subword merging heads. Next, we find similarities\nin Llama 2 behavior when handling tokens of the same part of speech. Finally,\nwe show that some model components can be specialized on domains such as coding\nor multilingual texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00824v2",
    "published_date": "2024-02-27 00:24:42 UTC",
    "updated_date": "2024-04-16 23:32:38 UTC"
  },
  {
    "arxiv_id": "2402.17097v3",
    "title": "Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses",
    "authors": [
      "Juyeon Kim",
      "Jeongeun Lee",
      "Yoonho Chang",
      "Chanyeol Choi",
      "Junseong Kim",
      "Jy-yong Sohn"
    ],
    "abstract": "Mitigating hallucination issues is a key challenge that must be overcome to\nreliably deploy large language models (LLMs) in real-world scenarios. Recently,\nvarious methods have been proposed to detect and revise factual errors in\nLLM-generated texts, in order to reduce hallucination. In this paper, we\npropose Re-Ex, a method for post-editing LLM-generated responses. Re-Ex\nintroduces a novel reasoning step dubbed as the factual error explanation step.\nRe-Ex revises the initial response of LLMs using 3-steps : first, external\ntools are used to retrieve the evidences of the factual errors in the initial\nLLM response; next, LLM is instructed to explain the problematic parts of the\nresponse based on the gathered evidence; finally, LLM revises the initial\nresponse using the explanations provided in the previous step. In addition to\nthe explanation step, Re-Ex also incorporates new prompting techniques to\nreduce the token count and inference time required for the response revision\nprocess. Compared with existing methods including FacTool, CoVE, and RARR,\nRe-Ex provides better detection and revision performance with less inference\ntime and fewer tokens in multiple benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2024 Workshop on Reliable and Responsible Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2402.17097v3",
    "published_date": "2024-02-27 00:22:18 UTC",
    "updated_date": "2025-04-12 04:39:17 UTC"
  }
]