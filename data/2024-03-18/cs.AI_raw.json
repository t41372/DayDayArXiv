[
  {
    "arxiv_id": "2403.12320v1",
    "title": "Approximated Likelihood Ratio: A Forward-Only and Parallel Framework for Boosting Neural Network Training",
    "authors": [
      "Zeliang Zhang",
      "Jinyang Jiang",
      "Zhuo Liu",
      "Susan Liang",
      "Yijie Peng",
      "Chenliang Xu"
    ],
    "abstract": "Efficient and biologically plausible alternatives to backpropagation in\nneural network training remain a challenge due to issues such as high\ncomputational complexity and additional assumptions about neural networks,\nwhich limit scalability to deeper networks. The likelihood ratio method offers\na promising gradient estimation strategy but is constrained by significant\nmemory consumption, especially when deploying multiple copies of data to reduce\nestimation variance. In this paper, we introduce an approximation technique for\nthe likelihood ratio (LR) method to alleviate computational and memory demands\nin gradient estimation. By exploiting the natural parallelism during the\nbackward pass using LR, we further provide a high-performance training\nstrategy, which pipelines both the forward and backward pass, to make it more\nsuitable for the computation on specialized hardware. Extensive experiments\ndemonstrate the effectiveness of the approximation technique in neural network\ntraining. This work underscores the potential of the likelihood ratio method in\nachieving high-performance neural network training, suggesting avenues for\nfurther exploration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12320v1",
    "published_date": "2024-03-18 23:23:50 UTC",
    "updated_date": "2024-03-18 23:23:50 UTC"
  },
  {
    "arxiv_id": "2403.12309v2",
    "title": "Reinforcement Learning from Delayed Observations via World Models",
    "authors": [
      "Armin Karamzade",
      "Kyungmin Kim",
      "Montek Kalsi",
      "Roy Fox"
    ],
    "abstract": "In standard reinforcement learning settings, agents typically assume\nimmediate feedback about the effects of their actions after taking them.\nHowever, in practice, this assumption may not hold true due to physical\nconstraints and can significantly impact the performance of learning\nalgorithms. In this paper, we address observation delays in partially\nobservable environments. We propose leveraging world models, which have shown\nsuccess in integrating past observations and learning dynamics, to handle\nobservation delays. By reducing delayed POMDPs to delayed MDPs with world\nmodels, our methods can effectively handle partial observability, where\nexisting approaches achieve sub-optimal performance or degrade quickly as\nobservability decreases. Experiments suggest that one of our methods can\noutperform a naive model-based approach by up to 250%. Moreover, we evaluate\nour methods on visual delayed environments, for the first time showcasing\ndelay-aware reinforcement learning continuous control with visual observations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12309v2",
    "published_date": "2024-03-18 23:18:27 UTC",
    "updated_date": "2024-06-26 02:44:18 UTC"
  },
  {
    "arxiv_id": "2403.12308v1",
    "title": "Gradient-based Fuzzy System Optimisation via Automatic Differentiation -- FuzzyR as a Use Case",
    "authors": [
      "Chao Chen",
      "Christian Wagner",
      "Jonathan M. Garibaldi"
    ],
    "abstract": "Since their introduction, fuzzy sets and systems have become an important\narea of research known for its versatility in modelling, knowledge\nrepresentation and reasoning, and increasingly its potential within the context\nexplainable AI. While the applications of fuzzy systems are diverse, there has\nbeen comparatively little advancement in their design from a machine learning\nperspective. In other words, while representations such as neural networks have\nbenefited from a boom in learning capability driven by an increase in\ncomputational performance in combination with advances in their training\nmechanisms and available tool, in particular gradient descent, the impact on\nfuzzy system design has been limited. In this paper, we discuss\ngradient-descent-based optimisation of fuzzy systems, focussing in particular\non automatic differentiation -- crucial to neural network learning -- with a\nview to free fuzzy system designers from intricate derivative computations,\nallowing for more focus on the functional and explainability aspects of their\ndesign. As a starting point, we present a use case in FuzzyR which demonstrates\nhow current fuzzy inference system implementations can be adjusted to leverage\npowerful features of automatic differentiation tools sets, discussing its\npotential for the future of fuzzy system design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12308v1",
    "published_date": "2024-03-18 23:18:16 UTC",
    "updated_date": "2024-03-18 23:18:16 UTC"
  },
  {
    "arxiv_id": "2403.12307v1",
    "title": "Molecular Classification Using Hyperdimensional Graph Classification",
    "authors": [
      "Pere Verges",
      "Igor Nunes",
      "Mike Heddes",
      "Tony Givargis",
      "Alexandru Nicolau"
    ],
    "abstract": "Our work introduces an innovative approach to graph learning by leveraging\nHyperdimensional Computing. Graphs serve as a widely embraced method for\nconveying information, and their utilization in learning has gained significant\nattention. This is notable in the field of chemoinformatics, where learning\nfrom graph representations plays a pivotal role. An important application\nwithin this domain involves the identification of cancerous cells across\ndiverse molecular structures.\n  We propose an HDC-based model that demonstrates comparable Area Under the\nCurve results when compared to state-of-the-art models like Graph Neural\nNetworks (GNNs) or the Weisfieler-Lehman graph kernel (WL). Moreover, it\noutperforms previously proposed hyperdimensional computing graph learning\nmethods. Furthermore, it achieves noteworthy speed enhancements, boasting a 40x\nacceleration in the training phase and a 15x improvement in inference time\ncompared to GNN and WL models. This not only underscores the efficacy of the\nHDC-based method, but also highlights its potential for expedited and\nresource-efficient graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12307v1",
    "published_date": "2024-03-18 23:16:17 UTC",
    "updated_date": "2024-03-18 23:16:17 UTC"
  },
  {
    "arxiv_id": "2403.12297v1",
    "title": "Leveraging Large Language Models to Extract Information on Substance Use Disorder Severity from Clinical Notes: A Zero-shot Learning Approach",
    "authors": [
      "Maria Mahbub",
      "Gregory M. Dams",
      "Sudarshan Srinivasan",
      "Caitlin Rizy",
      "Ioana Danciu",
      "Jodie Trafton",
      "Kathryn Knight"
    ],
    "abstract": "Substance use disorder (SUD) poses a major concern due to its detrimental\neffects on health and society. SUD identification and treatment depend on a\nvariety of factors such as severity, co-determinants (e.g., withdrawal\nsymptoms), and social determinants of health. Existing diagnostic coding\nsystems used by American insurance providers, like the International\nClassification of Diseases (ICD-10), lack granularity for certain diagnoses,\nbut clinicians will add this granularity (as that found within the Diagnostic\nand Statistical Manual of Mental Disorders classification or DSM-5) as\nsupplemental unstructured text in clinical notes. Traditional natural language\nprocessing (NLP) methods face limitations in accurately parsing such diverse\nclinical language. Large Language Models (LLMs) offer promise in overcoming\nthese challenges by adapting to diverse language patterns. This study\ninvestigates the application of LLMs for extracting severity-related\ninformation for various SUD diagnoses from clinical notes. We propose a\nworkflow employing zero-shot learning of LLMs with carefully crafted prompts\nand post-processing techniques. Through experimentation with Flan-T5, an\nopen-source LLM, we demonstrate its superior recall compared to the rule-based\napproach. Focusing on 11 categories of SUD diagnoses, we show the effectiveness\nof LLMs in extracting severity information, contributing to improved risk\nassessment and treatment planning for SUD patients.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.12297v1",
    "published_date": "2024-03-18 22:39:03 UTC",
    "updated_date": "2024-03-18 22:39:03 UTC"
  },
  {
    "arxiv_id": "2403.12242v3",
    "title": "Reference-based Metrics Disprove Themselves in Question Generation",
    "authors": [
      "Bang Nguyen",
      "Mengxia Yu",
      "Yun Huang",
      "Meng Jiang"
    ],
    "abstract": "Reference-based metrics such as BLEU and BERTScore are widely used to\nevaluate question generation (QG). In this study, on QG benchmarks such as\nSQuAD and HotpotQA, we find that using human-written references cannot\nguarantee the effectiveness of the reference-based metrics. Most QG benchmarks\nhave only one reference; we replicate the annotation process and collect\nanother reference. A good metric is expected to grade a human-validated\nquestion no worse than generated questions. However, the results of\nreference-based metrics on our newly collected reference disproved the metrics\nthemselves. We propose a reference-free metric consisted of multi-dimensional\ncriteria such as naturalness, answerability, and complexity, utilizing large\nlanguage models. These criteria are not constrained to the syntactic or\nsemantic of a single reference question, and the metric does not require a\ndiverse set of references. Experiments reveal that our metric accurately\ndistinguishes between high-quality questions and flawed ones, and achieves\nstate-of-the-art alignment with human judgment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings - Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2403.12242v3",
    "published_date": "2024-03-18 20:47:10 UTC",
    "updated_date": "2024-10-10 16:55:31 UTC"
  },
  {
    "arxiv_id": "2403.12237v2",
    "title": "Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments",
    "authors": [
      "Ibrahim Shaer",
      "Soodeh Nikan",
      "Abdallah Shami"
    ],
    "abstract": "The hyper-parameter optimization (HPO) process is imperative for finding the\nbest-performing Convolutional Neural Networks (CNNs). The automation process of\nHPO is characterized by its sizable computational footprint and its lack of\ntransparency; both important factors in a resource-constrained Internet of\nThings (IoT) environment. In this paper, we address these problems by proposing\na novel approach that combines transformer architecture and actor-critic\nReinforcement Learning (RL) model, TRL-HPO, equipped with multi-headed\nattention that enables parallelization and progressive generation of layers.\nThese assumptions are founded empirically by evaluating TRL-HPO on the MNIST\ndataset and comparing it with state-of-the-art approaches that build CNN models\nfrom scratch. The results show that TRL-HPO outperforms the classification\nresults of these approaches by 6.8% within the same time frame, demonstrating\nthe efficiency of TRL-HPO for the HPO process. The analysis of the results\nidentifies the main culprit for performance degradation attributed to stacking\nfully connected layers. This paper identifies new avenues for improving\nRL-based HPO processes in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, Submitted to IEEE Internet of Things Magazine",
    "pdf_url": "http://arxiv.org/pdf/2403.12237v2",
    "published_date": "2024-03-18 20:35:35 UTC",
    "updated_date": "2024-05-01 21:39:21 UTC"
  },
  {
    "arxiv_id": "2403.15453v1",
    "title": "Span-Oriented Information Extraction -- A Unifying Perspective on Information Extraction",
    "authors": [
      "Yifan Ding",
      "Michael Yankoski",
      "Tim Weninger"
    ],
    "abstract": "Information Extraction refers to a collection of tasks within Natural\nLanguage Processing (NLP) that identifies sub-sequences within text and their\nlabels. These tasks have been used for many years to link extract relevant\ninformation and to link free text to structured data. However, the\nheterogeneity among information extraction tasks impedes progress in this area.\nWe therefore offer a unifying perspective centered on what we define to be\nspans in text. We then re-orient these seemingly incongruous tasks into this\nunified perspective and then re-present the wide assortment of information\nextraction tasks as variants of the same basic Span-Oriented Information\nExtraction task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "35 Pages, 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2403.15453v1",
    "published_date": "2024-03-18 20:10:44 UTC",
    "updated_date": "2024-03-18 20:10:44 UTC"
  },
  {
    "arxiv_id": "2403.12212v2",
    "title": "Evaluating Named Entity Recognition: A comparative analysis of mono- and multilingual transformer models on a novel Brazilian corporate earnings call transcripts dataset",
    "authors": [
      "Ramon Abilio",
      "Guilherme Palermo Coelho",
      "Ana Estela Antunes da Silva"
    ],
    "abstract": "Since 2018, when the Transformer architecture was introduced, Natural\nLanguage Processing has gained significant momentum with pre-trained\nTransformer-based models that can be fine-tuned for various tasks. Most models\nare pre-trained on large English corpora, making them less applicable to other\nlanguages, such as Brazilian Portuguese. In our research, we identified two\nmodels pre-trained in Brazilian Portuguese (BERTimbau and PTT5) and two\nmultilingual models (mBERT and mT5). BERTimbau and mBERT use only the Encoder\nmodule, while PTT5 and mT5 use both the Encoder and Decoder. Our study aimed to\nevaluate their performance on a financial Named Entity Recognition (NER) task\nand determine the computational requirements for fine-tuning and inference. To\nthis end, we developed the Brazilian Financial NER (BraFiNER) dataset,\ncomprising sentences from Brazilian banks' earnings calls transcripts annotated\nusing a weakly supervised approach. Additionally, we introduced a novel\napproach that reframes the token classification task as a text generation\nproblem. After fine-tuning the models, we evaluated them using performance and\nerror metrics. Our findings reveal that BERT-based models consistently\noutperform T5-based models. While the multilingual models exhibit comparable\nmacro F1-scores, BERTimbau demonstrates superior performance over PTT5. In\nterms of error metrics, BERTimbau outperforms the other models. We also\nobserved that PTT5 and mT5 generated sentences with changes in monetary and\npercentage values, highlighting the importance of accuracy and consistency in\nthe financial domain. Our findings provide insights into the differing\nperformance of BERT- and T5-based models for the NER task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12212v2",
    "published_date": "2024-03-18 19:53:56 UTC",
    "updated_date": "2024-08-30 17:02:11 UTC"
  },
  {
    "arxiv_id": "2403.12211v2",
    "title": "A Unified Model for Longitudinal Multi-Modal Multi-View Prediction with Missingness",
    "authors": [
      "Boqi Chen",
      "Junier Oliva",
      "Marc Niethammer"
    ],
    "abstract": "Medical records often consist of different modalities, such as images, text,\nand tabular information. Integrating all modalities offers a holistic view of a\npatient's condition, while analyzing them longitudinally provides a better\nunderstanding of disease progression. However, real-world longitudinal medical\nrecords present challenges: 1) patients may lack some or all of the data for a\nspecific timepoint, and 2) certain modalities or views might be absent for all\npatients during a particular period. In this work, we introduce a unified model\nfor longitudinal multi-modal multi-view prediction with missingness. Our method\nallows as many timepoints as desired for input, and aims to leverage all\navailable data, regardless of their availability. We conduct extensive\nexperiments on the knee osteoarthritis dataset from the Osteoarthritis\nInitiative for pain and Kellgren-Lawrence grade prediction at a future\ntimepoint. We demonstrate the effectiveness of our method by comparing results\nfrom our unified model to specific models that use the same modality and view\ncombinations during training and evaluation. We also show the benefit of having\nextended temporal data and provide post-hoc analysis for a deeper understanding\nof each modality/view's importance for different tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12211v2",
    "published_date": "2024-03-18 19:51:55 UTC",
    "updated_date": "2024-03-22 00:17:11 UTC"
  },
  {
    "arxiv_id": "2403.12207v1",
    "title": "Synthetic Image Generation in Cyber Influence Operations: An Emergent Threat?",
    "authors": [
      "Melanie Mathys",
      "Marco Willi",
      "Michael Graber",
      "Raphael Meier"
    ],
    "abstract": "The evolution of artificial intelligence (AI) has catalyzed a transformation\nin digital content generation, with profound implications for cyber influence\noperations. This report delves into the potential and limitations of generative\ndeep learning models, such as diffusion models, in fabricating convincing\nsynthetic images. We critically assess the accessibility, practicality, and\noutput quality of these tools and their implications in threat scenarios of\ndeception, influence, and subversion. Notably, the report generates content for\nseveral hypothetical cyber influence operations to demonstrate the current\ncapabilities and limitations of these AI-driven methods for threat actors.\nWhile generative models excel at producing illustrations and non-realistic\nimagery, creating convincing photo-realistic content remains a significant\nchallenge, limited by computational resources and the necessity for\nhuman-guided refinement. Our exploration underscores the delicate balance\nbetween technological advancement and its potential for misuse, prompting\nrecommendations for ongoing research, defense mechanisms, multi-disciplinary\ncollaboration, and policy development. These recommendations aim to leverage\nAI's potential for positive impact while safeguarding against its risks to the\nintegrity of information, especially in the context of cyber influence.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "K.4.0; I.2.0; I.4.0"
    ],
    "primary_category": "cs.CY",
    "comment": "44 pages, 56 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.12207v1",
    "published_date": "2024-03-18 19:44:30 UTC",
    "updated_date": "2024-03-18 19:44:30 UTC"
  },
  {
    "arxiv_id": "2403.12201v1",
    "title": "Compositional learning of functions in humans and machines",
    "authors": [
      "Yanli Zhou",
      "Brenden M. Lake",
      "Adina Williams"
    ],
    "abstract": "The ability to learn and compose functions is foundational to efficient\nlearning and reasoning in humans, enabling flexible generalizations such as\ncreating new dishes from known cooking processes. Beyond sequential chaining of\nfunctions, existing linguistics literature indicates that humans can grasp more\ncomplex compositions with interacting functions, where output production\ndepends on context changes induced by different function orderings. Extending\nthe investigation into the visual domain, we developed a function learning\nparadigm to explore the capacity of humans and neural network models in\nlearning and reasoning with compositional functions under varied interaction\nconditions. Following brief training on individual functions, human\nparticipants were assessed on composing two learned functions, in ways covering\nfour main interaction types, including instances in which the application of\nthe first function creates or removes the context for applying the second\nfunction. Our findings indicate that humans can make zero-shot generalizations\non novel visual function compositions across interaction conditions,\ndemonstrating sensitivity to contextual changes. A comparison with a neural\nnetwork model on the same task reveals that, through the meta-learning for\ncompositionality (MLC) approach, a standard sequence-to-sequence Transformer\ncan mimic human generalization patterns in composing functions.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.12201v1",
    "published_date": "2024-03-18 19:22:53 UTC",
    "updated_date": "2024-03-18 19:22:53 UTC"
  },
  {
    "arxiv_id": "2403.12197v1",
    "title": "E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space",
    "authors": [
      "Ahmad Hassanpour",
      "Fatemeh Jamalbafrani",
      "Bian Yang",
      "Kiran Raja",
      "Raymond Veldhuis",
      "Julian Fierrez"
    ],
    "abstract": "Face inpainting, the technique of restoring missing or damaged regions in\nfacial images, is pivotal for applications like face recognition in occluded\nscenarios and image analysis with poor-quality captures. This process not only\nneeds to produce realistic visuals but also preserve individual identity\ncharacteristics. The aim of this paper is to inpaint a face given periocular\nregion (eyes-to-face) through a proposed new Generative Adversarial Network\n(GAN)-based model called Eyes-to-Face Network (E2F-Net). The proposed approach\nextracts identity and non-identity features from the periocular region using\ntwo dedicated encoders have been used. The extracted features are then mapped\nto the latent space of a pre-trained StyleGAN generator to benefit from its\nstate-of-the-art performance and its rich, diverse and expressive latent space\nwithout any additional training. We further improve the StyleGAN output to find\nthe optimal code in the latent space using a new optimization for GAN inversion\ntechnique. Our E2F-Net requires a minimum training process reducing the\ncomputational complexity as a secondary benefit. Through extensive experiments,\nwe show that our method successfully reconstructs the whole face with high\nquality, surpassing current techniques, despite significantly less training and\nsupervision efforts. We have generated seven eyes-to-face datasets based on\nwell-known public face datasets for training and verifying our proposed\nmethods. The code and datasets are publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12197v1",
    "published_date": "2024-03-18 19:11:34 UTC",
    "updated_date": "2024-03-18 19:11:34 UTC"
  },
  {
    "arxiv_id": "2403.12196v4",
    "title": "Leveraging Large Language Models to Detect npm Malicious Packages",
    "authors": [
      "Nusrat Zahan",
      "Philipp Burckhardt",
      "Mikola Lysenko",
      "Feross Aboukhadijeh",
      "Laurie Williams"
    ],
    "abstract": "Existing malicious code detection techniques demand the integration of\nmultiple tools to detect different malware patterns, often suffering from high\nmisclassification rates. Therefore, malicious code detection techniques could\nbe enhanced by adopting advanced, more automated approaches to achieve high\naccuracy and a low misclassification rate. The goal of this study is to aid\nsecurity analysts in detecting malicious packages by empirically studying the\neffectiveness of Large Language Models (LLMs) in detecting malicious code. We\npresent SocketAI, a malicious code review workflow to detect malicious code. To\nevaluate the effectiveness of SocketAI, we leverage a benchmark dataset of\n5,115 npm packages, of which 2,180 packages have malicious code. We conducted a\nbaseline comparison of GPT-3 and GPT-4 models with the state-of-the-art CodeQL\nstatic analysis tool, using 39 custom CodeQL rules developed in prior research\nto detect malicious Javascript code. We also compare the effectiveness of\nstatic analysis as a pre-screener with SocketAI workflow, measuring the number\nof files that need to be analyzed. and the associated costs. Additionally, we\nperformed a qualitative study to understand the types of malicious activities\ndetected or missed by our workflow. Our baseline comparison demonstrates a 16%\nand 9% improvement over static analysis in precision and F1 scores,\nrespectively. GPT-4 achieves higher accuracy with 99% precision and 97% F1\nscores, while GPT-3 offers a more cost-effective balance at 91% precision and\n94% F1 scores. Pre-screening files with a static analyzer reduces the number of\nfiles requiring LLM analysis by 77.9% and decreases costs by 60.9% for GPT-3\nand 76.1% for GPT-4. Our qualitative analysis identified data theft, execution\nof arbitrary code, and suspicious domain categories as the top detected\nmalicious packages.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 2 Figure, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.12196v4",
    "published_date": "2024-03-18 19:10:12 UTC",
    "updated_date": "2025-01-06 16:29:32 UTC"
  },
  {
    "arxiv_id": "2403.12181v1",
    "title": "MAC Advice for Facility Location Mechanism Design",
    "authors": [
      "Zohar Barak",
      "Anupam Gupta",
      "Inbal Talgam-Cohen"
    ],
    "abstract": "Algorithms with predictions have attracted much attention in the last years\nacross various domains, including variants of facility location, as a way to\nsurpass traditional worst-case analyses. We study the $k$-facility location\nmechanism design problem, where the $n$ agents are strategic and might\nmisreport their location.\n  Unlike previous models, where predictions are for the $k$ optimal facility\nlocations, we receive $n$ predictions for the locations of each of the agents.\nHowever, these predictions are only \"mostly\" and \"approximately\" correct (or\nMAC for short) -- i.e., some $\\delta$-fraction of the predicted locations are\nallowed to be arbitrarily incorrect, and the remainder of the predictions are\nallowed to be correct up to an $\\varepsilon$-error. We make no assumption on\nthe independence of the errors. Can such predictions allow us to beat the\ncurrent best bounds for strategyproof facility location?\n  We show that the $1$-median (geometric median) of a set of points is\nnaturally robust under corruptions, which leads to an algorithm for\nsingle-facility location with MAC predictions. We extend the robustness result\nto a \"balanced\" variant of the $k$ facilities case. Without balancedness, we\nshow that robustness completely breaks down, even for the setting of $k=2$\nfacilities on a line. For this \"unbalanced\" setting, we devise a truthful\nrandom mechanism that outperforms the best known result of Lu et al. [2010],\nwhich does not use predictions. En route, we introduce the problem of \"second\"\nfacility location (when the first facility's location is already fixed). Our\nfindings on the robustness of the $1$-median and more generally $k$-medians may\nbe of independent interest, as quantitative versions of classic breakdown-point\nresults in robust statistics.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12181v1",
    "published_date": "2024-03-18 18:52:04 UTC",
    "updated_date": "2024-03-18 18:52:04 UTC"
  },
  {
    "arxiv_id": "2403.12176v4",
    "title": "Safety Implications of Explainable Artificial Intelligence in End-to-End Autonomous Driving",
    "authors": [
      "Shahin Atakishiyev",
      "Mohammad Salameh",
      "Randy Goebel"
    ],
    "abstract": "The end-to-end learning pipeline is gradually creating a paradigm shift in\nthe ongoing development of highly autonomous vehicles (AVs), largely due to\nadvances in deep learning, the availability of large-scale training datasets,\nand improvements in integrated sensor devices. However, a lack of\nexplainability in real-time decisions with contemporary learning methods\nimpedes user trust and attenuates the widespread deployment and\ncommercialization of such vehicles. Moreover, the issue is exacerbated when\nthese cars are involved in or cause traffic accidents. Consequently,\nexplainability in end-to-end autonomous driving is essential to build trust in\nvehicular automation. With that said, automotive researchers have not yet\nrigorously explored safety benefits and consequences of explanations in\nend-to-end autonomous driving. This paper aims to bridge the gaps between these\ntopics and seeks to answer the following research question: What are safety\nimplications of explanations in end-to-end autonomous driving? In this regard,\nwe first revisit established safety and explainability concepts in end-to-end\ndriving. Furthermore, we present critical case studies and show the pivotal\nrole of explanations in enhancing driving safety. Finally, we describe insights\nfrom empirical studies and reveal potential value, limitations, and caveats of\npractical explainable AI methods with respect to their potential impacts on\nsafety of end-to-end driving.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12176v4",
    "published_date": "2024-03-18 18:49:20 UTC",
    "updated_date": "2025-04-20 23:39:27 UTC"
  },
  {
    "arxiv_id": "2403.12173v1",
    "title": "TnT-LLM: Text Mining at Scale with Large Language Models",
    "authors": [
      "Mengting Wan",
      "Tara Safavi",
      "Sujay Kumar Jauhar",
      "Yujin Kim",
      "Scott Counts",
      "Jennifer Neville",
      "Siddharth Suri",
      "Chirag Shah",
      "Ryen W White",
      "Longqi Yang",
      "Reid Andersen",
      "Georg Buscher",
      "Dhruv Joshi",
      "Nagu Rangan"
    ],
    "abstract": "Transforming unstructured text into structured and meaningful forms,\norganized by useful category labels, is a fundamental step in text mining for\ndownstream analysis and application. However, most existing methods for\nproducing label taxonomies and building text-based label classifiers still rely\nheavily on domain expertise and manual curation, making the process expensive\nand time-consuming. This is particularly challenging when the label space is\nunder-specified and large-scale data annotations are unavailable. In this\npaper, we address these challenges with Large Language Models (LLMs), whose\nprompt-based interface facilitates the induction and use of large-scale pseudo\nlabels. We propose TnT-LLM, a two-phase framework that employs LLMs to automate\nthe process of end-to-end label generation and assignment with minimal human\neffort for any given use-case. In the first phase, we introduce a zero-shot,\nmulti-stage reasoning approach which enables LLMs to produce and refine a label\ntaxonomy iteratively. In the second phase, LLMs are used as data labelers that\nyield training samples so that lightweight supervised classifiers can be\nreliably built, deployed, and served at scale. We apply TnT-LLM to the analysis\nof user intent and conversational domain for Bing Copilot (formerly Bing Chat),\nan open-domain chat-based search engine. Extensive experiments using both human\nand automatic evaluation metrics demonstrate that TnT-LLM generates more\naccurate and relevant label taxonomies when compared against state-of-the-art\nbaselines, and achieves a favorable balance between accuracy and efficiency for\nclassification at scale. We also share our practical experiences and insights\non the challenges and opportunities of using LLMs for large-scale text mining\nin real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages main content, 8 pages references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2403.12173v1",
    "published_date": "2024-03-18 18:45:28 UTC",
    "updated_date": "2024-03-18 18:45:28 UTC"
  },
  {
    "arxiv_id": "2403.12172v2",
    "title": "Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection",
    "authors": [
      "Ali Karami",
      "Thi Kieu Khanh Ho",
      "Narges Armanfard"
    ],
    "abstract": "Skeleton-based video anomaly detection (SVAD) is a crucial task in computer\nvision. Accurately identifying abnormal patterns or events enables operators to\npromptly detect suspicious activities, thereby enhancing safety. Achieving this\ndemands a comprehensive understanding of human motions, both at body and region\nlevels, while also accounting for the wide variations of performing a single\naction. However, existing studies fail to simultaneously address these crucial\nproperties. This paper introduces a novel, practical and lightweight framework,\nnamely Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video\nAnomaly Detection (GiCiSAD) to overcome the challenges associated with SVAD.\nGiCiSAD consists of three novel modules: the Graph Attention-based Forecasting\nmodule to capture the spatio-temporal dependencies inherent in the data, the\nGraph-level Jigsaw Puzzle Maker module to distinguish subtle region-level\ndiscrepancies between normal and abnormal motions, and the Graph-based\nConditional Diffusion model to generate a wide spectrum of human motions.\nExtensive experiments on four widely used skeleton-based video datasets show\nthat GiCiSAD outperforms existing methods with significantly fewer training\nparameters, establishing it as the new state-of-the-art.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the Winter Conference on Applications of Computer Vision\n  (WACV). 17 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.12172v2",
    "published_date": "2024-03-18 18:42:32 UTC",
    "updated_date": "2024-08-31 02:36:11 UTC"
  },
  {
    "arxiv_id": "2403.12171v1",
    "title": "EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models",
    "authors": [
      "Weikang Zhou",
      "Xiao Wang",
      "Limao Xiong",
      "Han Xia",
      "Yingshuang Gu",
      "Mingxu Chai",
      "Fukang Zhu",
      "Caishuang Huang",
      "Shihan Dou",
      "Zhiheng Xi",
      "Rui Zheng",
      "Songyang Gao",
      "Yicheng Zou",
      "Hang Yan",
      "Yifan Le",
      "Ruohui Wang",
      "Lijun Li",
      "Jing Shao",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Jailbreak attacks are crucial for identifying and mitigating the security\nvulnerabilities of Large Language Models (LLMs). They are designed to bypass\nsafeguards and elicit prohibited outputs. However, due to significant\ndifferences among various jailbreak methods, there is no standard\nimplementation framework available for the community, which limits\ncomprehensive security evaluations. This paper introduces EasyJailbreak, a\nunified framework simplifying the construction and evaluation of jailbreak\nattacks against LLMs. It builds jailbreak attacks using four components:\nSelector, Mutator, Constraint, and Evaluator. This modular framework enables\nresearchers to easily construct attacks from combinations of novel and existing\ncomponents. So far, EasyJailbreak supports 11 distinct jailbreak methods and\nfacilitates the security validation of a broad spectrum of LLMs. Our validation\nacross 10 distinct LLMs reveals a significant vulnerability, with an average\nbreach probability of 60% under various jailbreaking attacks. Notably, even\nadvanced models like GPT-3.5-Turbo and GPT-4 exhibit average Attack Success\nRates (ASR) of 57% and 33%, respectively. We have released a wealth of\nresources for researchers, including a web platform, PyPI published package,\nscreencast video, and experimental outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12171v1",
    "published_date": "2024-03-18 18:39:53 UTC",
    "updated_date": "2024-03-18 18:39:53 UTC"
  },
  {
    "arxiv_id": "2403.12162v1",
    "title": "Intelligent Execution through Plan Analysis",
    "authors": [
      "Daniel Borrajo",
      "Manuela Veloso"
    ],
    "abstract": "Intelligent robots need to generate and execute plans. In order to deal with\nthe complexity of real environments, planning makes some assumptions about the\nworld. When executing plans, the assumptions are usually not met. Most works\nhave focused on the negative impact of this fact and the use of replanning\nafter execution failures. Instead, we focus on the positive impact, or\nopportunities to find better plans. When planning, the proposed technique finds\nand stores those opportunities. Later, during execution, the monitoring system\ncan use them to focus perception and repair the plan, instead of replanning\nfrom scratch. Experiments in several paradigmatic robotic tasks show how the\napproach outperforms standard replanning strategies.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at IROS 21, 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.12162v1",
    "published_date": "2024-03-18 18:23:36 UTC",
    "updated_date": "2024-03-18 18:23:36 UTC"
  },
  {
    "arxiv_id": "2403.12153v1",
    "title": "Routing and Scheduling in Answer Set Programming applied to Multi-Agent Path Finding: Preliminary Report",
    "authors": [
      "Roland Kaminski",
      "Torsten Schaub",
      "Tran Cao Son",
      "Jiří Švancara",
      "Philipp Wanko"
    ],
    "abstract": "We present alternative approaches to routing and scheduling in Answer Set\nProgramming (ASP), and explore them in the context of Multi-agent Path Finding.\nThe idea is to capture the flow of time in terms of partial orders rather than\ntime steps attached to actions and fluents. This also abolishes the need for\nfixed upper bounds on the length of plans. The trade-off for this avoidance is\nthat (parts of) temporal trajectories must be acyclic, since multiple\noccurrences of the same action or fluent cannot be distinguished anymore. While\nthis approach provides an interesting alternative for modeling routing, it is\nwithout alternative for scheduling since fine-grained timings cannot be\nrepresented in ASP in a feasible way. This is different for partial orders that\ncan be efficiently handled by external means such as acyclicity and difference\nconstraints. We formally elaborate upon this idea and present several resulting\nASP encodings. Finally, we demonstrate their effectiveness via an empirical\nanalysis.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12153v1",
    "published_date": "2024-03-18 18:09:47 UTC",
    "updated_date": "2024-03-18 18:09:47 UTC"
  },
  {
    "arxiv_id": "2403.12151v3",
    "title": "Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification",
    "authors": [
      "Filippos Gouidis",
      "Katerina Papantoniou",
      "Konstantinos Papoutsakis",
      "Theodore Patkos",
      "Antonis Argyros",
      "Dimitris Plexousakis"
    ],
    "abstract": "Domain-specific knowledge can significantly contribute to addressing a wide\nvariety of vision tasks. However, the generation of such knowledge entails\nconsiderable human labor and time costs. This study investigates the potential\nof Large Language Models (LLMs) in generating and providing domain-specific\ninformation through semantic embeddings. To achieve this, an LLM is integrated\ninto a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors\nin the context of the Vision-based Zero-shot Object State Classification task.\nWe thoroughly examine the behavior of the LLM through an extensive ablation\nstudy. Our findings reveal that the integration of LLM-based embeddings, in\ncombination with general-purpose pre-trained embeddings, leads to substantial\nperformance improvements. Drawing insights from this ablation study, we conduct\na comparative analysis against competing models, thereby highlighting the\nstate-of-the-art performance achieved by the proposed approach.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the AAAI-MAKE 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.12151v3",
    "published_date": "2024-03-18 18:08:44 UTC",
    "updated_date": "2024-12-11 18:12:43 UTC"
  },
  {
    "arxiv_id": "2403.12143v3",
    "title": "Graph Neural Networks for Learning Equivariant Representations of Neural Networks",
    "authors": [
      "Miltiadis Kofinas",
      "Boris Knyazev",
      "Yan Zhang",
      "Yunlu Chen",
      "Gertjan J. Burghouts",
      "Efstratios Gavves",
      "Cees G. M. Snoek",
      "David W. Zhang"
    ],
    "abstract": "Neural networks that process the parameters of other neural networks find\napplications in domains as diverse as classifying implicit neural\nrepresentations, generating neural network weights, and predicting\ngeneralization errors. However, existing approaches either overlook the\ninherent permutation symmetry in the neural network or rely on intricate\nweight-sharing patterns to achieve equivariance, while ignoring the impact of\nthe network architecture itself. In this work, we propose to represent neural\nnetworks as computational graphs of parameters, which allows us to harness\npowerful graph neural networks and transformers that preserve permutation\nsymmetry. Consequently, our approach enables a single model to encode neural\ncomputational graphs with diverse architectures. We showcase the effectiveness\nof our method on a wide range of tasks, including classification and editing of\nimplicit neural representations, predicting generalization performance, and\nlearning to optimize, while consistently outperforming state-of-the-art\nmethods. The source code is open-sourced at\nhttps://github.com/mkofinas/neural-graphs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "In ICLR 2024. Source code: https://github.com/mkofinas/neural-graphs",
    "pdf_url": "http://arxiv.org/pdf/2403.12143v3",
    "published_date": "2024-03-18 18:01:01 UTC",
    "updated_date": "2024-07-23 16:30:10 UTC"
  },
  {
    "arxiv_id": "2403.12031v2",
    "title": "RouterBench: A Benchmark for Multi-LLM Routing System",
    "authors": [
      "Qitian Jason Hu",
      "Jacob Bieker",
      "Xiuyu Li",
      "Nan Jiang",
      "Benjamin Keigwin",
      "Gaurav Ranganath",
      "Kurt Keutzer",
      "Shriyash Kaustubh Upadhyay"
    ],
    "abstract": "As the range of applications for Large Language Models (LLMs) continues to\ngrow, the demand for effective serving solutions becomes increasingly critical.\nDespite the versatility of LLMs, no single model can optimally address all\ntasks and applications, particularly when balancing performance with cost. This\nlimitation has led to the development of LLM routing systems, which combine the\nstrengths of various models to overcome the constraints of individual LLMs.\nYet, the absence of a standardized benchmark for evaluating the performance of\nLLM routers hinders progress in this area. To bridge this gap, we present\nRouterBench, a novel evaluation framework designed to systematically assess the\nefficacy of LLM routing systems, along with a comprehensive dataset comprising\nover 405k inference outcomes from representative LLMs to support the\ndevelopment of routing strategies. We further propose a theoretical framework\nfor LLM routing, and deliver a comparative analysis of various routing\napproaches through RouterBench, highlighting their potentials and limitations\nwithin our evaluation framework. This work not only formalizes and advances the\ndevelopment of LLM routing systems but also sets a standard for their\nassessment, paving the way for more accessible and economically viable LLM\ndeployments. The code and data are available at\nhttps://github.com/withmartian/routerbench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12031v2",
    "published_date": "2024-03-18 17:59:04 UTC",
    "updated_date": "2024-03-28 17:56:28 UTC"
  },
  {
    "arxiv_id": "2403.12029v3",
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection",
    "authors": [
      "Justin Kay",
      "Timm Haucke",
      "Suzanne Stathatos",
      "Siqi Deng",
      "Erik Young",
      "Pietro Perona",
      "Sara Beery",
      "Grant Van Horn"
    ],
    "abstract": "Object detectors often perform poorly on data that differs from their\ntraining set. Domain adaptive object detection (DAOD) methods have recently\ndemonstrated strong results on addressing this challenge. Unfortunately, we\nidentify systemic benchmarking pitfalls that call past results into question\nand hamper further progress: (a) Overestimation of performance due to\nunderpowered baselines, (b) Inconsistent implementation practices preventing\ntransparent comparisons of methods, and (c) Lack of generality due to outdated\nbackbones and lack of diversity in benchmarks. We address these problems by\nintroducing: (1) A unified benchmarking and implementation framework, Align and\nDistill (ALDI), enabling comparison of DAOD methods and supporting future\ndevelopment, (2) A fair and modern training and evaluation protocol for DAOD\nthat addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset,\nCFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method,\nALDI++, that achieves state-of-the-art results by a large margin. ALDI++\noutperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy\nCityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to\noutperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and\nALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and\nDETR-based DAOD as well without additional hyperparameter tuning. Our\nframework, dataset, and state-of-the-art method offer a critical reset for DAOD\nand provide a strong foundation for future research. Code and data are\navailable: https://github.com/justinkay/aldi and\nhttps://github.com/visipedia/caltech-fish-counting.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "TMLR camera ready (Featured Certification). 33 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.12029v3",
    "published_date": "2024-03-18 17:58:02 UTC",
    "updated_date": "2025-03-17 20:18:16 UTC"
  },
  {
    "arxiv_id": "2403.12028v1",
    "title": "Ultraman: Single Image 3D Human Reconstruction with Ultra Speed and Detail",
    "authors": [
      "Mingjin Chen",
      "Junhao Chen",
      "Xiaojun Ye",
      "Huan-ang Gao",
      "Xiaoxue Chen",
      "Zhaoxin Fan",
      "Hao Zhao"
    ],
    "abstract": "3D human body reconstruction has been a challenge in the field of computer\nvision. Previous methods are often time-consuming and difficult to capture the\ndetailed appearance of the human body. In this paper, we propose a new method\ncalled \\emph{Ultraman} for fast reconstruction of textured 3D human models from\na single image. Compared to existing techniques, \\emph{Ultraman} greatly\nimproves the reconstruction speed and accuracy while preserving high-quality\ntexture details. We present a set of new frameworks for human reconstruction\nconsisting of three parts, geometric reconstruction, texture generation and\ntexture mapping. Firstly, a mesh reconstruction framework is used, which\naccurately extracts 3D human shapes from a single image. At the same time, we\npropose a method to generate a multi-view consistent image of the human body\nbased on a single image. This is finally combined with a novel texture mapping\nmethod to optimize texture details and ensure color consistency during\nreconstruction. Through extensive experiments and evaluations, we demonstrate\nthe superior performance of \\emph{Ultraman} on various standard datasets. In\naddition, \\emph{Ultraman} outperforms state-of-the-art methods in terms of\nhuman rendering quality and speed. Upon acceptance of the article, we will make\nthe code and data publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://air-discover.github.io/Ultraman/",
    "pdf_url": "http://arxiv.org/pdf/2403.12028v1",
    "published_date": "2024-03-18 17:57:30 UTC",
    "updated_date": "2024-03-18 17:57:30 UTC"
  },
  {
    "arxiv_id": "2403.12027v4",
    "title": "From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models",
    "authors": [
      "Kung-Hsiang Huang",
      "Hou Pong Chan",
      "Yi R. Fung",
      "Haoyi Qiu",
      "Mingyang Zhou",
      "Shafiq Joty",
      "Shih-Fu Chang",
      "Heng Ji"
    ],
    "abstract": "Data visualization in the form of charts plays a pivotal role in data\nanalysis, offering critical insights and aiding in informed decision-making.\nAutomatic chart understanding has witnessed significant advancements with the\nrise of large foundation models in recent years. Foundation models, such as\nlarge language models, have revolutionized various natural language processing\ntasks and are increasingly being applied to chart understanding tasks. This\nsurvey paper provides a comprehensive overview of the recent developments,\nchallenges, and future directions in chart understanding within the context of\nthese foundation models. We review fundamental building blocks crucial for\nstudying chart understanding tasks. Additionally, we explore various tasks and\ntheir evaluation metrics and sources of both charts and textual inputs. Various\nmodeling strategies are then examined, encompassing both classification-based\nand generation-based approaches, along with tool augmentation techniques that\nenhance chart understanding performance. Furthermore, we discuss the\nstate-of-the-art performance of each task and discuss how we can improve the\nperformance. Challenges and future directions are addressed, highlighting the\nimportance of several topics, such as domain-specific charts, lack of efforts\nin developing evaluation metrics, and agent-oriented settings. This survey\npaper serves as a comprehensive resource for researchers and practitioners in\nthe fields of natural language processing, computer vision, and data analysis,\nproviding valuable insights and directions for future research in chart\nunderstanding leveraging large foundation models. The studies mentioned in this\npaper, along with emerging new research, will be continually updated at:\nhttps://github.com/khuangaf/Awesome-Chart-Understanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "IEEE Transactions on Knowledge and Data Engineering (TKDE)",
    "pdf_url": "http://arxiv.org/pdf/2403.12027v4",
    "published_date": "2024-03-18 17:57:09 UTC",
    "updated_date": "2024-12-05 03:26:13 UTC"
  },
  {
    "arxiv_id": "2403.12026v2",
    "title": "FlexCap: Describe Anything in Images in Controllable Detail",
    "authors": [
      "Debidatta Dwibedi",
      "Vidhi Jain",
      "Jonathan Tompson",
      "Andrew Zisserman",
      "Yusuf Aytar"
    ],
    "abstract": "We introduce FlexCap, a vision-language model that generates region-specific\ndescriptions of varying lengths. FlexCap is trained to produce\nlength-conditioned captions for input boxes, enabling control over information\ndensity, with descriptions ranging from concise object labels to detailed\ncaptions. To achieve this, we create large-scale training datasets of image\nregion descriptions with varying lengths from captioned web images. We\ndemonstrate FlexCap's effectiveness in several applications: first, it achieves\nstrong performance in dense captioning tasks on the Visual Genome dataset.\nSecond, we show how FlexCap's localized descriptions can serve as input to a\nlarge language model to create a visual question answering (VQA) system,\nachieving state-of-the-art zero-shot performance on multiple VQA benchmarks.\nOur experiments illustrate FlexCap's utility for tasks including image\nlabeling, object attribute recognition, and visual dialog. Project webpage:\nhttps://flex-cap.github.io .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.12026v2",
    "published_date": "2024-03-18 17:57:02 UTC",
    "updated_date": "2025-01-28 23:14:21 UTC"
  },
  {
    "arxiv_id": "2403.12017v1",
    "title": "Supervised Fine-Tuning as Inverse Reinforcement Learning",
    "authors": [
      "Hao Sun"
    ],
    "abstract": "The prevailing approach to aligning Large Language Models (LLMs) typically\nrelies on human or AI feedback and assumes access to specific types of\npreference datasets. In our work, we question the efficacy of such datasets and\nexplore various scenarios where alignment with expert demonstrations proves\nmore realistic. We build a sequential decision-making framework to formulate\nthe problem of aligning LLMs using demonstration datasets. Drawing insights\nfrom inverse reinforcement learning and imitation learning, we introduce\nvarious approaches for divergence minimization in the LLM alignment tasks. Our\nanalysis highlights the mass-covering and mode-seeking behaviors of these\ndifferent approaches. Inclusively, we examine the pros and cons of the\nclassical supervised fine-tuning method, elaborating on scenarios where\ndifferent methods shine.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12017v1",
    "published_date": "2024-03-18 17:52:57 UTC",
    "updated_date": "2024-03-18 17:52:57 UTC"
  },
  {
    "arxiv_id": "2403.12014v2",
    "title": "EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents",
    "authors": [
      "Abhay Zala",
      "Jaemin Cho",
      "Han Lin",
      "Jaehong Yoon",
      "Mohit Bansal"
    ],
    "abstract": "Recent SOTA approaches for embodied learning via interaction directly employ\nlarge language models (LLMs) as agents to determine the next steps in an\nenvironment. Due to their world knowledge and reasoning capabilities, LLM\nagents achieve stronger performance than previous smaller agents based on\nreinforcement learning (RL); however, frequently calling LLMs is slow and\nexpensive. Instead of directly employing LLMs as agents, can we use LLMs'\nreasoning capabilities to adaptively create training environments to help\nsmaller RL agents learn useful skills that they are weak at? We propose EnvGen,\na novel framework to address this question. We first prompt an LLM to generate\ntraining environments by giving it the task description and simulator\nobjectives that the agents should learn and then asking it to generate a set of\nenvironment configurations (e.g., different terrains, items initially given to\nagents, etc.). Next, we train a small RL agent in a mixture of the original and\nLLM-generated environments. Then, we enable the LLM to continuously adapt the\ngenerated environments to progressively improve the skills that the agent is\nweak at, by providing feedback to the LLM in the form of the agent's\nperformance. We demonstrate the usefulness of EnvGen with comprehensive\nexperiments in Crafter and Heist environments. We find that a small RL agent\ntrained with EnvGen can outperform SOTA methods, including a GPT-4 agent, and\nlearns long-horizon tasks significantly faster. We also show that using an LLM\nto adapt environments dynamically outperforms curriculum learning approaches\nand how the environments are adapted to help improve RL agents' weaker skills\nover time. Additionally, EnvGen is substantially more efficient as it only uses\na small number of LLM calls (e.g., 4 in total), whereas LLM agents require\nthousands of calls. Lastly, we present detailed ablation studies for EnvGen\ndesign choices.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "COLM 2024; First two authors contributed equally; Project website:\n  https://envgen-llm.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2403.12014v2",
    "published_date": "2024-03-18 17:51:16 UTC",
    "updated_date": "2024-07-12 17:39:19 UTC"
  },
  {
    "arxiv_id": "2403.12010v1",
    "title": "VideoMV: Consistent Multi-View Generation Based on Large Video Generative Model",
    "authors": [
      "Qi Zuo",
      "Xiaodong Gu",
      "Lingteng Qiu",
      "Yuan Dong",
      "Zhengyi Zhao",
      "Weihao Yuan",
      "Rui Peng",
      "Siyu Zhu",
      "Zilong Dong",
      "Liefeng Bo",
      "Qixing Huang"
    ],
    "abstract": "Generating multi-view images based on text or single-image prompts is a\ncritical capability for the creation of 3D content. Two fundamental questions\non this topic are what data we use for training and how to ensure multi-view\nconsistency. This paper introduces a novel framework that makes fundamental\ncontributions to both questions. Unlike leveraging images from 2D diffusion\nmodels for training, we propose a dense consistent multi-view generation model\nthat is fine-tuned from off-the-shelf video generative models. Images from\nvideo generative models are more suitable for multi-view generation because the\nunderlying network architecture that generates them employs a temporal module\nto enforce frame consistency. Moreover, the video data sets used to train these\nmodels are abundant and diverse, leading to a reduced train-finetuning domain\ngap. To enhance multi-view consistency, we introduce a 3D-Aware Denoising\nSampling, which first employs a feed-forward reconstruction module to get an\nexplicit global 3D model, and then adopts a sampling strategy that effectively\ninvolves images rendered from the global 3D model into the denoising sampling\nloop to improve the multi-view consistency of the final images. As a\nby-product, this module also provides a fast way to create 3D assets\nrepresented by 3D Gaussians within a few seconds. Our approach can generate 24\ndense views and converges much faster in training than state-of-the-art\napproaches (4 GPU hours versus many thousand GPU hours) with comparable visual\nquality and consistency. By further fine-tuning, our approach outperforms\nexisting state-of-the-art methods in both quantitative metrics and visual\neffects. Our project page is aigc3d.github.io/VideoMV.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: aigc3d.github.io/VideoMV/",
    "pdf_url": "http://arxiv.org/pdf/2403.12010v1",
    "published_date": "2024-03-18 17:48:15 UTC",
    "updated_date": "2024-03-18 17:48:15 UTC"
  },
  {
    "arxiv_id": "2403.12009v2",
    "title": "Leveraging Spatial and Semantic Feature Extraction for Skin Cancer Diagnosis with Capsule Networks and Graph Neural Networks",
    "authors": [
      "K. P. Santoso",
      "R. V. H. Ginardi",
      "R. A. Sastrowardoyo",
      "F. A. Madany"
    ],
    "abstract": "In the realm of skin lesion image classification, the intricate spatial and\nsemantic features pose significant challenges for conventional Convolutional\nNeural Network (CNN)-based methodologies. These challenges are compounded by\nthe imbalanced nature of skin lesion datasets, which hampers the ability of\nmodels to learn minority class features effectively. Despite augmentation\nstrategies, such as those using Generative Adversarial Networks (GANs),\nprevious attempts have not fully addressed these complexities. This study\nintroduces an innovative approach by integrating Graph Neural Networks (GNNs)\nwith Capsule Networks to enhance classification performance. GNNs, known for\ntheir proficiency in handling graph-structured data, offer an advanced\nmechanism for capturing complex patterns and relationships beyond the\ncapabilities of traditional CNNs. Capsule Networks further contribute by\nproviding superior recognition of spatial hierarchies within images. Our\nresearch focuses on evaluating and enhancing the Tiny Pyramid Vision GNN (Tiny\nPyramid ViG) architecture by incorporating it with a Capsule Network. This\nhybrid model was applied to the MNIST:HAM10000 dataset, a comprehensive skin\nlesion dataset designed for benchmarking classification models. After 75 epochs\nof training, our model achieved a significant accuracy improvement, reaching\n89.23% and 95.52%, surpassing established benchmarks such as GoogLeNet\n(83.94%), InceptionV3 (86.82%), MobileNet V3 (89.87%), EfficientNet-B7\n(92.07%), ResNet18 (92.22%), ResNet34 (91.90%), ViT-Base (73.70%), and IRv2-SA\n(93.47%) on the same dataset. This outcome underscores the potential of our\napproach in overcoming the inherent challenges of skin lesion classification,\ncontributing to the advancement of image-based diagnosis in dermatology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This is the first version of our paper, we gladly expect feedback and\n  corrections if there is any mistake within our paper",
    "pdf_url": "http://arxiv.org/pdf/2403.12009v2",
    "published_date": "2024-03-18 17:47:39 UTC",
    "updated_date": "2024-03-19 07:11:28 UTC"
  },
  {
    "arxiv_id": "2403.12002v2",
    "title": "DreamMotion: Space-Time Self-Similar Score Distillation for Zero-Shot Video Editing",
    "authors": [
      "Hyeonho Jeong",
      "Jinho Chang",
      "Geon Yeong Park",
      "Jong Chul Ye"
    ],
    "abstract": "Text-driven diffusion-based video editing presents a unique challenge not\nencountered in image editing literature: establishing real-world motion. Unlike\nexisting video editing approaches, here we focus on score distillation sampling\nto circumvent the standard reverse diffusion process and initiate optimization\nfrom videos that already exhibit natural motion. Our analysis reveals that\nwhile video score distillation can effectively introduce new content indicated\nby target text, it can also cause significant structure and motion deviation.\nTo counteract this, we propose to match space-time self-similarities of the\noriginal video and the edited video during the score distillation. Thanks to\nthe use of score distillation, our approach is model-agnostic, which can be\napplied for both cascaded and non-cascaded video diffusion frameworks. Through\nextensive comparisons with leading methods, our approach demonstrates its\nsuperiority in altering appearances while accurately preserving the original\nstructure and motion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV 2024, Project page:\n  https://hyeonho99.github.io/dreammotion/",
    "pdf_url": "http://arxiv.org/pdf/2403.12002v2",
    "published_date": "2024-03-18 17:38:53 UTC",
    "updated_date": "2024-07-15 13:34:29 UTC"
  },
  {
    "arxiv_id": "2403.12000v1",
    "title": "Notochord: a Flexible Probabilistic Model for Real-Time MIDI Performance",
    "authors": [
      "Victor Shepardson",
      "Jack Armitage",
      "Thor Magnusson"
    ],
    "abstract": "Deep learning-based probabilistic models of musical data are producing\nincreasingly realistic results and promise to enter creative workflows of many\nkinds. Yet they have been little-studied in a performance setting, where the\nresults of user actions typically ought to feel instantaneous. To enable such\nstudy, we designed Notochord, a deep probabilistic model for sequences of\nstructured events, and trained an instance of it on the Lakh MIDI dataset. Our\nprobabilistic formulation allows interpretable interventions at a sub-event\nlevel, which enables one model to act as a backbone for diverse interactive\nmusical functions including steerable generation, harmonization, machine\nimprovisation, and likelihood-based interfaces. Notochord can generate\npolyphonic and multi-track MIDI, and respond to inputs with latency below ten\nmilliseconds. Training code, model checkpoints and interactive examples are\nprovided as open source software.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "12 pages, 6 figures. Proceedings of the 3rd Conference on AI Music\n  Creativity (2022, September 17)",
    "pdf_url": "http://arxiv.org/pdf/2403.12000v1",
    "published_date": "2024-03-18 17:35:02 UTC",
    "updated_date": "2024-03-18 17:35:02 UTC"
  },
  {
    "arxiv_id": "2403.11996v3",
    "title": "Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning",
    "authors": [
      "Markus J. Buehler"
    ],
    "abstract": "Leveraging generative Artificial Intelligence (AI), we have transformed a\ndataset comprising 1,000 scientific papers into an ontological knowledge graph.\nThrough an in-depth structural analysis, we have calculated node degrees,\nidentified communities and connectivities, and evaluated clustering\ncoefficients and betweenness centrality of pivotal nodes, uncovering\nfascinating knowledge architectures. The graph has an inherently scale-free\nnature, is highly connected, and can be used for graph reasoning by taking\nadvantage of transitive and isomorphic properties that reveal unprecedented\ninterdisciplinary relationships that can be used to answer queries, identify\ngaps in knowledge, propose never-before-seen material designs, and predict\nmaterial behaviors. We compute deep node embeddings for combinatorial node\nsimilarity ranking for use in a path sampling strategy links dissimilar\nconcepts that have previously not been related. One comparison revealed\nstructural parallels between biological materials and Beethoven's 9th Symphony,\nhighlighting shared patterns of complexity through isomorphic mapping. In\nanother example, the algorithm proposed a hierarchical mycelium-based composite\nbased on integrating path sampling with principles extracted from Kandinsky's\n'Composition VII' painting. The resulting material integrates an innovative set\nof concepts that include a balance of chaos/order, adjustable porosity,\nmechanical strength, and complex patterned chemical functionalization. We\nuncover other isomorphisms across science, technology and art, revealing a\nnuanced ontology of immanence that reveal a context-dependent heterarchical\ninterplay of constituents. Graph-based generative AI achieves a far higher\ndegree of novelty, explorative capacity, and technical detail, than\nconventional approaches and establishes a widely useful framework for\ninnovation by revealing hidden connections.",
    "categories": [
      "cs.LG",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.soft",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11996v3",
    "published_date": "2024-03-18 17:30:27 UTC",
    "updated_date": "2024-06-10 19:06:26 UTC"
  },
  {
    "arxiv_id": "2403.11984v1",
    "title": "Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching",
    "authors": [
      "Andrew Katz",
      "Mitchell Gerhardt",
      "Michelle Soledad"
    ],
    "abstract": "Feedback is a critical aspect of improvement. Unfortunately, when there is a\nlot of feedback from multiple sources, it can be difficult to distill the\ninformation into actionable insights. Consider student evaluations of teaching\n(SETs), which are important sources of feedback for educators. They can give\ninstructors insights into what worked during a semester. A collection of SETs\ncan also be useful to administrators as signals for courses or entire programs.\nHowever, on a large scale as in high-enrollment courses or administrative\nrecords over several years, the volume of SETs can render them difficult to\nanalyze. In this paper, we discuss a novel method for analyzing SETs using\nnatural language processing (NLP) and large language models (LLMs). We\ndemonstrate the method by applying it to a corpus of 5,000 SETs from a large\npublic university. We show that the method can be used to extract, embed,\ncluster, and summarize the SETs to identify the themes they express. More\ngenerally, this work illustrates how to use the combination of NLP techniques\nand LLMs to generate a codebook for SETs. We conclude by discussing the\nimplications of this method for analyzing SETs and other types of student\nwriting in teaching and research settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Natural language processing, large language models, generative AI,\n  student evaluations of teaching, codebook generation, qualitative data\n  analysis",
    "pdf_url": "http://arxiv.org/pdf/2403.11984v1",
    "published_date": "2024-03-18 17:21:35 UTC",
    "updated_date": "2024-03-18 17:21:35 UTC"
  },
  {
    "arxiv_id": "2403.15452v1",
    "title": "What Are Tools Anyway? A Survey from the Language Model Perspective",
    "authors": [
      "Zhiruo Wang",
      "Zhoujun Cheng",
      "Hao Zhu",
      "Daniel Fried",
      "Graham Neubig"
    ],
    "abstract": "Language models (LMs) are powerful yet mostly for text generation tasks.\nTools have substantially enhanced their performance for tasks that require\ncomplex skills. However, many works adopt the term \"tool\" in different ways,\nraising the question: What is a tool anyway? Subsequently, where and how do\ntools help LMs? In this survey, we provide a unified definition of tools as\nexternal programs used by LMs, and perform a systematic review of LM tooling\nscenarios and approaches. Grounded on this review, we empirically study the\nefficiency of various tooling methods by measuring their required compute and\nperformance gains on various benchmarks, and highlight some challenges and\npotential future research in the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15452v1",
    "published_date": "2024-03-18 17:20:07 UTC",
    "updated_date": "2024-03-18 17:20:07 UTC"
  },
  {
    "arxiv_id": "2403.11966v1",
    "title": "Informed Spectral Normalized Gaussian Processes for Trajectory Prediction",
    "authors": [
      "Christian Schlauch",
      "Christian Wirth",
      "Nadja Klein"
    ],
    "abstract": "Prior parameter distributions provide an elegant way to represent prior\nexpert and world knowledge for informed learning. Previous work has shown that\nusing such informative priors to regularize probabilistic deep learning (DL)\nmodels increases their performance and data-efficiency. However, commonly used\nsampling-based approximations for probabilistic DL models can be\ncomputationally expensive, requiring multiple inference passes and longer\ntraining times. Promising alternatives are compute-efficient last layer kernel\napproximations like spectral normalized Gaussian processes (SNGPs). We propose\na novel regularization-based continual learning method for SNGPs, which enables\nthe use of informative priors that represent prior knowledge learned from\nprevious tasks. Our proposal builds upon well-established methods and requires\nno rehearsal memory or parameter expansion. We apply our informed SNGP model to\nthe trajectory prediction problem in autonomous driving by integrating prior\ndrivability knowledge. On two public datasets, we investigate its performance\nunder diminishing training data and across locations, and thereby demonstrate\nan increase in data-efficiency and robustness to location-transfers over\nnon-informed and informed baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11966v1",
    "published_date": "2024-03-18 17:05:24 UTC",
    "updated_date": "2024-03-18 17:05:24 UTC"
  },
  {
    "arxiv_id": "2403.14712v1",
    "title": "AI for bureaucratic productivity: Measuring the potential of AI to help automate 143 million UK government transactions",
    "authors": [
      "Vincent J. Straub",
      "Youmna Hashem",
      "Jonathan Bright",
      "Satyam Bhagwanani",
      "Deborah Morgan",
      "John Francis",
      "Saba Esnaashari",
      "Helen Margetts"
    ],
    "abstract": "There is currently considerable excitement within government about the\npotential of artificial intelligence to improve public service productivity\nthrough the automation of complex but repetitive bureaucratic tasks, freeing up\nthe time of skilled staff. Here, we explore the size of this opportunity, by\nmapping out the scale of citizen-facing bureaucratic decision-making procedures\nwithin UK central government, and measuring their potential for AI-driven\nautomation. We estimate that UK central government conducts approximately one\nbillion citizen-facing transactions per year in the provision of around 400\nservices, of which approximately 143 million are complex repetitive\ntransactions. We estimate that 84% of these complex transactions are highly\nautomatable, representing a huge potential opportunity: saving even an average\nof just one minute per complex transaction would save the equivalent of\napproximately 1,200 person-years of work every year. We also develop a model to\nestimate the volume of transactions a government service undertakes, providing\na way for government to avoid conducting time consuming transaction volume\nmeasurements. Finally, we find that there is high turnover in the types of\nservices government provide, meaning that automation efforts should focus on\ngeneral procedures rather than services themselves which are likely to evolve\nover time. Overall, our work presents a novel perspective on the structure and\nfunctioning of modern government, and how it might evolve in the age of\nartificial intelligence.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14712v1",
    "published_date": "2024-03-18 17:03:17 UTC",
    "updated_date": "2024-03-18 17:03:17 UTC"
  },
  {
    "arxiv_id": "2403.11961v1",
    "title": "Enhanced Event-Based Video Reconstruction with Motion Compensation",
    "authors": [
      "Siying Liu",
      "Pier Luigi Dragotti"
    ],
    "abstract": "Deep neural networks for event-based video reconstruction often suffer from a\nlack of interpretability and have high memory demands. A lightweight network\ncalled CISTA-LSTC has recently been introduced showing that high-quality\nreconstruction can be achieved through the systematic design of its\narchitecture. However, its modelling assumption that input signals and output\nreconstructed frame share the same sparse representation neglects the\ndisplacement caused by motion. To address this, we propose warping the input\nintensity frames and sparse codes to enhance reconstruction quality. A\nCISTA-Flow network is constructed by integrating a flow network with CISTA-LSTC\nfor motion compensation. The system relies solely on events, in which predicted\nflow aids in reconstruction and then reconstructed frames are used to\nfacilitate flow estimation. We also introduce an iterative training framework\nfor this combined system. Results demonstrate that our approach achieves\nstate-of-the-art reconstruction accuracy and simultaneously provides reliable\ndense flow estimation. Furthermore, our model exhibits flexibility in that it\ncan integrate different flow networks, suggesting its potential for further\nperformance enhancement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 8 figures (supplementary material included)",
    "pdf_url": "http://arxiv.org/pdf/2403.11961v1",
    "published_date": "2024-03-18 16:58:23 UTC",
    "updated_date": "2024-03-18 16:58:23 UTC"
  },
  {
    "arxiv_id": "2403.11959v2",
    "title": "IVAC-P2L: Leveraging Irregular Repetition Priors for Improving Video Action Counting",
    "authors": [
      "Hang Wang",
      "Zhi-Qi Cheng",
      "Youtian Du",
      "Lei Zhang"
    ],
    "abstract": "Video Action Counting (VAC) is crucial in analyzing sports, fitness, and\neveryday activities by quantifying repetitive actions in videos. However,\ntraditional VAC methods have overlooked the complexity of action repetitions,\nsuch as interruptions and the variability in cycle duration. Our research\naddresses the shortfall by introducing a novel approach to VAC, called\nIrregular Video Action Counting (IVAC). IVAC prioritizes modeling irregular\nrepetition patterns in videos, which we define through two primary aspects:\nInter-cycle Consistency and Cycle-interval Inconsistency. Inter-cycle\nConsistency ensures homogeneity in the spatial-temporal representations of\ncycle segments, signifying action uniformity within cycles. Cycle-interval\ninconsistency highlights the importance of distinguishing between cycle\nsegments and intervals based on their inherent content differences. To\nencapsulate these principles, we propose a new methodology that includes\nconsistency and inconsistency modules, supported by a unique pull-push loss\n(P2L) mechanism. The IVAC-P2L model applies a pull loss to promote coherence\namong cycle segment features and a push loss to clearly distinguish features of\ncycle segments from interval segments. Empirical evaluations conducted on the\nRepCount dataset demonstrate that the IVAC-P2L model sets a new benchmark in\nVAC task performance. Furthermore, the model demonstrates exceptional\nadaptability and generalization across various video contents, outperforming\nexisting models on two additional datasets, UCFRep and Countix, without the\nneed for dataset-specific optimization. These results confirm the efficacy of\nour approach in addressing irregular repetitions in videos and pave the way for\nfurther advancements in video analysis and understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Source code: https://github.com/hwang-cs-ime/IVAC-P2L",
    "pdf_url": "http://arxiv.org/pdf/2403.11959v2",
    "published_date": "2024-03-18 16:56:47 UTC",
    "updated_date": "2024-03-20 11:58:23 UTC"
  },
  {
    "arxiv_id": "2404.07950v3",
    "title": "Reinforcement Learning with Generalizable Gaussian Splatting",
    "authors": [
      "Jiaxu Wang",
      "Qiang Zhang",
      "Jingkai Sun",
      "Jiahang Cao",
      "Gang Han",
      "Wen Zhao",
      "Weining Zhang",
      "Yecheng Shao",
      "Yijie Guo",
      "Renjing Xu"
    ],
    "abstract": "An excellent representation is crucial for reinforcement learning (RL)\nperformance, especially in vision-based reinforcement learning tasks. The\nquality of the environment representation directly influences the achievement\nof the learning task. Previous vision-based RL typically uses explicit or\nimplicit ways to represent environments, such as images, points, voxels, and\nneural radiance fields. However, these representations contain several\ndrawbacks. They cannot either describe complex local geometries or generalize\nwell to unseen scenes, or require precise foreground masks. Moreover, these\nimplicit neural representations are akin to a ``black box\", significantly\nhindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit\nscene representation and differentiable rendering nature, is considered a\nrevolutionary change for reconstruction and representation methods. In this\npaper, we propose a novel Generalizable Gaussian Splatting framework to be the\nrepresentation of RL tasks, called GSRL. Through validation in the RoboMimic\nenvironment, our method achieves better results than other baselines in\nmultiple tasks, improving the performance by 10%, 44%, and 15% compared with\nbaselines on the hardest task. This work is the first attempt to leverage\ngeneralizable 3DGS as a representation for RL.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages,2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.07950v3",
    "published_date": "2024-03-18 16:50:23 UTC",
    "updated_date": "2024-08-06 02:42:32 UTC"
  },
  {
    "arxiv_id": "2403.11942v2",
    "title": "Exploring Facial Expression Recognition through Semi-Supervised Pretraining and Temporal Modeling",
    "authors": [
      "Jun Yu",
      "Zhihong Wei",
      "Zhongpeng Cai",
      "Gongpeng Zhao",
      "Zerui Zhang",
      "Yongqi Wang",
      "Guochen Xie",
      "Jichao Zhu",
      "Wangyuan Zhu"
    ],
    "abstract": "Facial Expression Recognition (FER) plays a crucial role in computer vision\nand finds extensive applications across various fields. This paper aims to\npresent our approach for the upcoming 6th Affective Behavior Analysis\nin-the-Wild (ABAW) competition, scheduled to be held at CVPR2024. In the facial\nexpression recognition task, The limited size of the FER dataset poses a\nchallenge to the expression recognition model's generalization ability,\nresulting in subpar recognition performance. To address this problem, we employ\na semi-supervised learning technique to generate expression category\npseudo-labels for unlabeled face data. At the same time, we uniformly sampled\nthe labeled facial expression samples and implemented a debiased feedback\nlearning strategy to address the problem of category imbalance in the dataset\nand the possible data bias in semi-supervised learning. Moreover, to further\ncompensate for the limitation and bias of features obtained only from static\nimages, we introduced a Temporal Encoder to learn and capture temporal\nrelationships between neighbouring expression image features. In the 6th ABAW\ncompetition, our method achieved outstanding results on the official validation\nset, a result that fully confirms the effectiveness and competitiveness of our\nproposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11942v2",
    "published_date": "2024-03-18 16:36:54 UTC",
    "updated_date": "2024-03-19 17:20:59 UTC"
  },
  {
    "arxiv_id": "2403.11905v4",
    "title": "Tur[k]ingBench: A Challenge Benchmark for Web Agents",
    "authors": [
      "Kevin Xu",
      "Yeganeh Kordi",
      "Tanay Nayak",
      "Adi Asija",
      "Yizhong Wang",
      "Kate Sanders",
      "Adam Byerly",
      "Jingyu Zhang",
      "Benjamin Van Durme",
      "Daniel Khashabi"
    ],
    "abstract": "Can advanced multi-modal models effectively tackle complex web-based tasks?\nSuch tasks are often found on crowdsourcing platforms, where crowdworkers\nengage in challenging micro-tasks within web-based environments.\n  Building on this idea, we present TurkingBench, a benchmark consisting of\ntasks presented as web pages with textual instructions and multi-modal\ncontexts. Unlike previous approaches that rely on artificially synthesized web\npages, our benchmark uses natural HTML pages originally designed for\ncrowdsourcing workers to perform various annotation tasks. Each task's HTML\ninstructions are instantiated with different values derived from crowdsourcing\ntasks, creating diverse instances. This benchmark includes 32.2K instances\nspread across 158 tasks.\n  To support the evaluation of TurkingBench, we have developed a framework that\nlinks chatbot responses to actions on web pages (e.g., modifying a text box,\nselecting a radio button). We assess the performance of cutting-edge private\nand open-source models, including language-only and vision-language models\n(such as GPT4 and InternVL), on this benchmark. Our results show that while\nthese models outperform random chance, there is still significant room for\nimprovement. We hope that this benchmark will drive progress in the evaluation\nand development of web-based agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11905v4",
    "published_date": "2024-03-18 16:06:30 UTC",
    "updated_date": "2025-02-22 01:33:54 UTC"
  },
  {
    "arxiv_id": "2403.11901v4",
    "title": "Larimar: Large Language Models with Episodic Memory Control",
    "authors": [
      "Payel Das",
      "Subhajit Chaudhury",
      "Elliot Nelson",
      "Igor Melnyk",
      "Sarath Swaminathan",
      "Sihui Dai",
      "Aurélie Lozano",
      "Georgios Kollias",
      "Vijil Chenthamarakshan",
      "Jiří",
      "Navrátil",
      "Soham Dan",
      "Pin-Yu Chen"
    ],
    "abstract": "Efficient and accurate updating of knowledge stored in Large Language Models\n(LLMs) is one of the most pressing research challenges today. This paper\npresents Larimar - a novel, brain-inspired architecture for enhancing LLMs with\na distributed episodic memory. Larimar's memory allows for dynamic, one-shot\nupdates of knowledge without the need for computationally expensive re-training\nor fine-tuning. Experimental results on multiple fact editing benchmarks\ndemonstrate that Larimar attains accuracy comparable to most competitive\nbaselines, even in the challenging sequential editing setup, but also excels in\nspeed - yielding speed-ups of 8-10x depending on the base LLM - as well as\nflexibility due to the proposed architecture being simple, LLM-agnostic, and\nhence general. We further provide mechanisms for selective fact forgetting,\ninformation leakage prevention, and input context length generalization with\nLarimar and show their effectiveness. Our code is available at\nhttps://github.com/IBM/larimar",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.11901v4",
    "published_date": "2024-03-18 16:01:42 UTC",
    "updated_date": "2024-08-21 22:54:47 UTC"
  },
  {
    "arxiv_id": "2403.11894v4",
    "title": "From Explainable to Interpretable Deep Learning for Natural Language Processing in Healthcare: How Far from Reality?",
    "authors": [
      "Guangming Huang",
      "Yingya Li",
      "Shoaib Jameel",
      "Yunfei Long",
      "Giorgos Papanastasiou"
    ],
    "abstract": "Deep learning (DL) has substantially enhanced natural language processing\n(NLP) in healthcare research. However, the increasing complexity of DL-based\nNLP necessitates transparent model interpretability, or at least\nexplainability, for reliable decision-making. This work presents a thorough\nscoping review of explainable and interpretable DL in healthcare NLP. The term\n\"eXplainable and Interpretable Artificial Intelligence\" (XIAI) is introduced to\ndistinguish XAI from IAI. Different models are further categorized based on\ntheir functionality (model-, input-, output-based) and scope (local, global).\nOur analysis shows that attention mechanisms are the most prevalent emerging\nIAI technique. The use of IAI is growing, distinguishing it from XAI. The major\nchallenges identified are that most XIAI does not explore \"global\" modelling\nprocesses, the lack of best practices, and the lack of systematic evaluation\nand benchmarks. One important opportunity is to use attention mechanisms to\nenhance multi-modal XIAI for personalized medicine. Additionally, combining DL\nwith causal logic holds promise. Our discussion encourages the integration of\nXIAI in Large Language Models (LLMs) and domain-specific smaller models. In\nconclusion, XIAI adoption in healthcare requires dedicated in-house expertise.\nCollaboration with domain experts, end-users, and policymakers can lead to\nready-to-use XIAI methods across NLP and medical tasks. While challenges exist,\nXIAI techniques offer a valuable foundation for interpretable NLP algorithms in\nhealthcare.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by Computational and Structural\n  Biotechnology Journal",
    "pdf_url": "http://arxiv.org/pdf/2403.11894v4",
    "published_date": "2024-03-18 15:53:33 UTC",
    "updated_date": "2024-10-16 14:14:27 UTC"
  },
  {
    "arxiv_id": "2403.11887v1",
    "title": "SuperLoRA: Parameter-Efficient Unified Adaptation of Multi-Layer Attention Modules",
    "authors": [
      "Xiangyu Chen",
      "Jing Liu",
      "Ye Wang",
      "Pu Perry Wang",
      "Matthew Brand",
      "Guanghui Wang",
      "Toshiaki Koike-Akino"
    ],
    "abstract": "Low-rank adaptation (LoRA) and its variants are widely employed in\nfine-tuning large models, including large language models for natural language\nprocessing and diffusion models for computer vision. This paper proposes a\ngeneralized framework called SuperLoRA that unifies and extends different LoRA\nvariants, which can be realized under different hyper-parameter settings.\nIntroducing grouping, folding, shuffling, projecting, and tensor factoring,\nSuperLoRA offers high flexibility compared with other LoRA variants and\ndemonstrates superior performance for transfer learning tasks especially in the\nextremely few-parameter regimes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, 29 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.11887v1",
    "published_date": "2024-03-18 15:40:36 UTC",
    "updated_date": "2024-03-18 15:40:36 UTC"
  },
  {
    "arxiv_id": "2403.11886v2",
    "title": "QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback-based Self-Correction",
    "authors": [
      "Xiang Huang",
      "Sitao Cheng",
      "Shanshan Huang",
      "Jiayu Shen",
      "Yong Xu",
      "Chaoyun Zhang",
      "Yuzhong Qu"
    ],
    "abstract": "Employing Large Language Models (LLMs) for semantic parsing has achieved\nremarkable success. However, we find existing methods fall short in terms of\nreliability and efficiency when hallucinations are encountered. In this paper,\nwe address these challenges with a framework called QueryAgent, which solves a\nquestion step-by-step and performs step-wise self-correction. We introduce an\nenvironmental feedback-based self-correction method called ERASER. Unlike\ntraditional approaches, ERASER leverages rich environmental feedback in the\nintermediate steps to perform selective and differentiated self-correction only\nwhen necessary. Experimental results demonstrate that QueryAgent notably\noutperforms all previous few-shot methods using only one example on GrailQA and\nGraphQ by 7.0 and 15.0 F1. Moreover, our approach exhibits superiority in terms\nof efficiency, including runtime, query overhead, and API invocation costs. By\nleveraging ERASER, we further improve another baseline (i.e., AgentBench) by\napproximately 10 points, revealing the strong transferability of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 main conference. 22 pages,7 figures, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.11886v2",
    "published_date": "2024-03-18 15:39:14 UTC",
    "updated_date": "2024-06-13 13:18:43 UTC"
  },
  {
    "arxiv_id": "2403.11882v1",
    "title": "ReGenNet: Towards Human Action-Reaction Synthesis",
    "authors": [
      "Liang Xu",
      "Yizhou Zhou",
      "Yichao Yan",
      "Xin Jin",
      "Wenhan Zhu",
      "Fengyun Rao",
      "Xiaokang Yang",
      "Wenjun Zeng"
    ],
    "abstract": "Humans constantly interact with their surrounding environments. Current\nhuman-centric generative models mainly focus on synthesizing humans plausibly\ninteracting with static scenes and objects, while the dynamic human\naction-reaction synthesis for ubiquitous causal human-human interactions is\nless explored. Human-human interactions can be regarded as asymmetric with\nactors and reactors in atomic interaction periods. In this paper, we\ncomprehensively analyze the asymmetric, dynamic, synchronous, and detailed\nnature of human-human interactions and propose the first multi-setting human\naction-reaction synthesis benchmark to generate human reactions conditioned on\ngiven human actions. To begin with, we propose to annotate the actor-reactor\norder of the interaction sequences for the NTU120, InterHuman, and Chi3D\ndatasets. Based on them, a diffusion-based generative model with a Transformer\ndecoder architecture called ReGenNet together with an explicit distance-based\ninteraction loss is proposed to predict human reactions in an online manner,\nwhere the future states of actors are unavailable to reactors. Quantitative and\nqualitative results show that our method can generate instant and plausible\nhuman reactions compared to the baselines, and can generalize to unseen actor\nmotions and viewpoint changes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2024, Project Page:\n  https://liangxuy.github.io/ReGenNet/",
    "pdf_url": "http://arxiv.org/pdf/2403.11882v1",
    "published_date": "2024-03-18 15:33:06 UTC",
    "updated_date": "2024-03-18 15:33:06 UTC"
  },
  {
    "arxiv_id": "2403.11879v4",
    "title": "Unimodal Multi-Task Fusion for Emotional Mimicry Intensity Prediction",
    "authors": [
      "Tobias Hallmen",
      "Fabian Deuser",
      "Norbert Oswald",
      "Elisabeth André"
    ],
    "abstract": "In this research, we introduce a novel methodology for assessing Emotional\nMimicry Intensity (EMI) as part of the 6th Workshop and Competition on\nAffective Behavior Analysis in-the-wild. Our methodology utilises the Wav2Vec\n2.0 architecture, which has been pre-trained on an extensive podcast dataset,\nto capture a wide array of audio features that include both linguistic and\nparalinguistic components. We refine our feature extraction process by\nemploying a fusion technique that combines individual features with a global\nmean vector, thereby embedding a broader contextual understanding into our\nanalysis. A key aspect of our approach is the multi-task fusion strategy that\nnot only leverages these features but also incorporates a pre-trained\nValence-Arousal-Dominance (VAD) model. This integration is designed to refine\nemotion intensity prediction by concurrently processing multiple emotional\ndimensions, thereby embedding a richer contextual understanding into our\nframework. For the temporal analysis of audio data, our feature fusion process\nutilises a Long Short-Term Memory (LSTM) network. This approach, which relies\nsolely on the provided audio data, shows marked advancements over the existing\nbaseline, offering a more comprehensive understanding of emotional mimicry in\nnaturalistic settings, achieving the second place in the EMI challenge.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11879v4",
    "published_date": "2024-03-18 15:32:02 UTC",
    "updated_date": "2024-06-16 12:21:39 UTC"
  },
  {
    "arxiv_id": "2403.11865v2",
    "title": "Exploring Multi-modal Neural Scene Representations With Applications on Thermal Imaging",
    "authors": [
      "Mert Özer",
      "Maximilian Weiherer",
      "Martin Hundhausen",
      "Bernhard Egger"
    ],
    "abstract": "Neural Radiance Fields (NeRFs) quickly evolved as the new de-facto standard\nfor the task of novel view synthesis when trained on a set of RGB images. In\nthis paper, we conduct a comprehensive evaluation of neural scene\nrepresentations, such as NeRFs, in the context of multi-modal learning.\nSpecifically, we present four different strategies of how to incorporate a\nsecond modality, other than RGB, into NeRFs: (1) training from scratch\nindependently on both modalities; (2) pre-training on RGB and fine-tuning on\nthe second modality; (3) adding a second branch; and (4) adding a separate\ncomponent to predict (color) values of the additional modality. We chose\nthermal imaging as second modality since it strongly differs from RGB in terms\nof radiosity, making it challenging to integrate into neural scene\nrepresentations. For the evaluation of the proposed strategies, we captured a\nnew publicly available multi-view dataset, ThermalMix, consisting of six common\nobjects and about 360 RGB and thermal images in total. We employ cross-modality\ncalibration prior to data capturing, leading to high-quality alignments between\nRGB and thermal images. Our findings reveal that adding a second branch to NeRF\nperforms best for novel view synthesis on thermal images while also yielding\ncompelling results on RGB. Finally, we also show that our analysis generalizes\nto other modalities, including near-infrared images and depth maps. Project\npage: https://mert-o.github.io/ThermalNeRF/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCVW'24",
    "pdf_url": "http://arxiv.org/pdf/2403.11865v2",
    "published_date": "2024-03-18 15:18:55 UTC",
    "updated_date": "2024-08-23 09:40:59 UTC"
  },
  {
    "arxiv_id": "2403.11852v3",
    "title": "Reinforcement Learning with Latent State Inference for Autonomous On-ramp Merging under Observation Delay",
    "authors": [
      "Amin Tabrizian",
      "Zhitong Huang",
      "Peng Wei"
    ],
    "abstract": "This paper presents a novel approach to address the challenging problem of\nautonomous on-ramp merging, where a self-driving vehicle needs to seamlessly\nintegrate into a flow of vehicles on a multi-lane highway. We introduce the\nLane-keeping, Lane-changing with Latent-state Inference and Safety Controller\n(L3IS) agent, designed to perform the on-ramp merging task safely without\ncomprehensive knowledge about surrounding vehicles' intents or driving styles.\nWe also present an augmentation of this agent called AL3IS that accounts for\nobservation delays, allowing the agent to make more robust decisions in\nreal-world environments with vehicle-to-vehicle (V2V) communication delays. By\nmodeling the unobservable aspects of the environment through latent states,\nsuch as other drivers' intents, our approach enhances the agent's ability to\nadapt to dynamic traffic conditions, optimize merging maneuvers, and ensure\nsafe interactions with other vehicles. We demonstrate the effectiveness of our\nmethod through extensive simulations generated from real traffic data and\ncompare its performance with existing approaches. L3IS shows a 99.90% success\nrate in a challenging on-ramp merging case generated from the real US Highway\n101 data. We further perform a sensitivity analysis on AL3IS to evaluate its\nrobustness against varying observation delays, which demonstrates an acceptable\nperformance of 93.84% success rate in 1-second V2V communication delay.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11852v3",
    "published_date": "2024-03-18 15:02:46 UTC",
    "updated_date": "2024-06-21 15:31:50 UTC"
  },
  {
    "arxiv_id": "2403.13850v1",
    "title": "Spatio-Temporal Fluid Dynamics Modeling via Physical-Awareness and Parameter Diffusion Guidance",
    "authors": [
      "Hao Wu",
      "Fan Xu",
      "Yifan Duan",
      "Ziwei Niu",
      "Weiyan Wang",
      "Gaofeng Lu",
      "Kun Wang",
      "Yuxuan Liang",
      "Yang Wang"
    ],
    "abstract": "This paper proposes a two-stage framework named ST-PAD for spatio-temporal\nfluid dynamics modeling in the field of earth sciences, aiming to achieve\nhigh-precision simulation and prediction of fluid dynamics through\nspatio-temporal physics awareness and parameter diffusion guidance. In the\nupstream stage, we design a vector quantization reconstruction module with\ntemporal evolution characteristics, ensuring balanced and resilient parameter\ndistribution by introducing general physical constraints. In the downstream\nstage, a diffusion probability network involving parameters is utilized to\ngenerate high-quality future states of fluids, while enhancing the model's\ngeneralization ability by perceiving parameters in various physical setups.\nExtensive experiments on multiple benchmark datasets have verified the\neffectiveness and robustness of the ST-PAD framework, which showcase that\nST-PAD outperforms current mainstream models in fluid dynamics modeling and\nprediction, especially in effectively capturing local representations and\nmaintaining significant advantages in OOD generations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13850v1",
    "published_date": "2024-03-18 14:57:47 UTC",
    "updated_date": "2024-03-18 14:57:47 UTC"
  },
  {
    "arxiv_id": "2403.11843v1",
    "title": "Fuzzy Rough Choquet Distances for Classification",
    "authors": [
      "Adnan Theerens",
      "Chris Cornelis"
    ],
    "abstract": "This paper introduces a novel Choquet distance using fuzzy rough set based\nmeasures. The proposed distance measure combines the attribute information\nreceived from fuzzy rough set theory with the flexibility of the Choquet\nintegral. This approach is designed to adeptly capture non-linear relationships\nwithin the data, acknowledging the interplay of the conditional attributes\ntowards the decision attribute and resulting in a more flexible and accurate\ndistance. We explore its application in the context of machine learning, with a\nspecific emphasis on distance-based classification approaches (e.g. k-nearest\nneighbours). The paper examines two fuzzy rough set based measures that are\nbased on the positive region. Moreover, we explore two procedures for\nmonotonizing the measures derived from fuzzy rough set theory, making them\nsuitable for use with the Choquet integral, and investigate their differences.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11843v1",
    "published_date": "2024-03-18 14:53:48 UTC",
    "updated_date": "2024-03-18 14:53:48 UTC"
  },
  {
    "arxiv_id": "2403.11841v1",
    "title": "Pessimistic Causal Reinforcement Learning with Mediators for Confounded Offline Data",
    "authors": [
      "Danyang Wang",
      "Chengchun Shi",
      "Shikai Luo",
      "Will Wei Sun"
    ],
    "abstract": "In real-world scenarios, datasets collected from randomized experiments are\noften constrained by size, due to limitations in time and budget. As a result,\nleveraging large observational datasets becomes a more attractive option for\nachieving high-quality policy learning. However, most existing offline\nreinforcement learning (RL) methods depend on two key\nassumptions--unconfoundedness and positivity--which frequently do not hold in\nobservational data contexts. Recognizing these challenges, we propose a novel\npolicy learning algorithm, PESsimistic CAusal Learning (PESCAL). We utilize the\nmediator variable based on front-door criterion to remove the confounding bias;\nadditionally, we adopt the pessimistic principle to address the distributional\nshift between the action distributions induced by candidate policies, and the\nbehavior policy that generates the observational data. Our key observation is\nthat, by incorporating auxiliary variables that mediate the effect of actions\non system dynamics, it is sufficient to learn a lower bound of the mediator\ndistribution function, instead of the Q-function, to partially mitigate the\nissue of distributional shift. This insight significantly simplifies our\nalgorithm, by circumventing the challenging task of sequential uncertainty\nquantification for the estimated Q-function. Moreover, we provide theoretical\nguarantees for the algorithms we propose, and demonstrate their efficacy\nthrough simulations, as well as real-world experiments utilizing offline\ndatasets from a leading ride-hailing platform.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11841v1",
    "published_date": "2024-03-18 14:51:19 UTC",
    "updated_date": "2024-03-18 14:51:19 UTC"
  },
  {
    "arxiv_id": "2403.11838v2",
    "title": "Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models",
    "authors": [
      "Yi Luo",
      "Zhenghao Lin",
      "Yuhao Zhang",
      "Jiashuo Sun",
      "Chen Lin",
      "Chengjin Xu",
      "Xiangdong Su",
      "Yelong Shen",
      "Jian Guo",
      "Yeyun Gong"
    ],
    "abstract": "Large Language Models (LLMs) exhibit impressive capabilities but also present\nrisks such as biased content generation and privacy issues. One of the current\nalignment techniques includes principle-driven integration, but it faces\nchallenges arising from the imprecision of manually crafted rules and\ninadequate risk perception in models without safety training. To address these,\nwe introduce Guide-Align, a two-stage approach. Initially, a safety-trained\nmodel identifies potential risks and formulates specific guidelines for various\ninputs, establishing a comprehensive library of guidelines and a model for\ninput-guidelines retrieval. Subsequently, the retrieval model correlates new\ninputs with relevant guidelines, which guide LLMs in response generation to\nensure safe and high-quality outputs, thereby aligning with human values. An\nadditional optional stage involves fine-tuning a model with well-aligned\ndatasets generated through the process implemented in the second stage. Our\nmethod customizes guidelines to accommodate diverse inputs, thereby enhancing\nthe fine-grainedness and comprehensiveness of the guideline library.\nFurthermore, it incorporates safety expertise from a safety-trained LLM through\na lightweight retrieval model. We evaluate our approach on three benchmarks,\ndemonstrating significant improvements in LLM security and quality. Notably,\nour fine-tuned model, Labrador, even at 13 billion parameters, outperforms\nGPT-3.5-turbo and surpasses GPT-4 in alignment capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2403.11838v2",
    "published_date": "2024-03-18 14:48:29 UTC",
    "updated_date": "2024-03-23 06:26:41 UTC"
  },
  {
    "arxiv_id": "2403.11830v2",
    "title": "Problem space structural adversarial attacks for Network Intrusion Detection Systems based on Graph Neural Networks",
    "authors": [
      "Andrea Venturi",
      "Dario Stabili",
      "Mirco Marchetti"
    ],
    "abstract": "Machine Learning (ML) algorithms have become increasingly popular for\nsupporting Network Intrusion Detection Systems (NIDS). Nevertheless, extensive\nresearch has shown their vulnerability to adversarial attacks, which involve\nsubtle perturbations to the inputs of the models aimed at compromising their\nperformance. Recent proposals have effectively leveraged Graph Neural Networks\n(GNN) to produce predictions based also on the structural patterns exhibited by\nintrusions to enhance the detection robustness. However, the adoption of\nGNN-based NIDS introduces new types of risks. In this paper, we propose the\nfirst formalization of adversarial attacks specifically tailored for GNN in\nnetwork intrusion detection. Moreover, we outline and model the problem space\nconstraints that attackers need to consider to carry out feasible structural\nattacks in real-world scenarios. As a final contribution, we conduct an\nextensive experimental campaign in which we launch the proposed attacks against\nstate-of-the-art GNN-based NIDS. Our findings demonstrate the increased\nrobustness of the models against classical feature-based adversarial attacks,\nwhile highlighting their susceptibility to structure-based attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "preprint submitted to IEEE TIFS, under review",
    "pdf_url": "http://arxiv.org/pdf/2403.11830v2",
    "published_date": "2024-03-18 14:40:33 UTC",
    "updated_date": "2024-04-23 15:21:04 UTC"
  },
  {
    "arxiv_id": "2403.13849v1",
    "title": "Graphs Unveiled: Graph Neural Networks and Graph Generation",
    "authors": [
      "László Kovács",
      "Ali Jlidi"
    ],
    "abstract": "One of the hot topics in machine learning is the field of GNN. The complexity\nof graph data has imposed significant challenges on existing machine learning\nalgorithms. Recently, many studies on extending deep learning approaches for\ngraph data have emerged. This paper represents a survey, providing a\ncomprehensive overview of Graph Neural Networks (GNNs). We discuss the\napplications of graph neural networks across various domains. Finally, we\npresent an advanced field in GNNs: graph generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13849v1",
    "published_date": "2024-03-18 14:37:27 UTC",
    "updated_date": "2024-03-18 14:37:27 UTC"
  },
  {
    "arxiv_id": "2403.11821v5",
    "title": "A Survey on Quality Metrics for Text-to-Image Generation",
    "authors": [
      "Sebastian Hartwig",
      "Dominik Engel",
      "Leon Sick",
      "Hannah Kniesel",
      "Tristan Payer",
      "Poonam Poonam",
      "Michael Glöckler",
      "Alex Bäuerle",
      "Timo Ropinski"
    ],
    "abstract": "AI-based text-to-image models do not only excel at generating realistic\nimages, they also give designers more and more fine-grained control over the\nimage content. Consequently, these approaches have gathered increased attention\nwithin the computer graphics research community, which has been historically\ndevoted towards traditional rendering techniques, that offer precise control\nover scene parameters (e.g., objects, materials, and lighting). While the\nquality of conventionally rendered images is assessed through well established\nimage quality metrics, such as SSIM or PSNR, the unique challenges of\ntext-to-image generation require other, dedicated quality metrics. These\nmetrics must be able to not only measure overall image quality, but also how\nwell images reflect given text prompts, whereby the control of scene and\nrendering parameters is interweaved. Within this survey, we provide a\ncomprehensive overview of such text-to-image quality metrics, and propose a\ntaxonomy to categorize these metrics. Our taxonomy is grounded in the\nassumption, that there are two main quality criteria, namely compositional\nquality and general quality, that contribute to the overall image quality.\nBesides the metrics, this survey covers dedicated text-to-image benchmark\ndatasets, over which the metrics are frequently computed. Finally, we identify\nlimitations and open challenges in the field of text-to-image generation, and\nderive guidelines for practitioners conducting text-to-image evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.11821v5",
    "published_date": "2024-03-18 14:24:20 UTC",
    "updated_date": "2025-01-29 08:48:10 UTC"
  },
  {
    "arxiv_id": "2403.11807v7",
    "title": "How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments",
    "authors": [
      "Jen-tse Huang",
      "Eric John Li",
      "Man Ho Lam",
      "Tian Liang",
      "Wenxuan Wang",
      "Youliang Yuan",
      "Wenxiang Jiao",
      "Xing Wang",
      "Zhaopeng Tu",
      "Michael R. Lyu"
    ],
    "abstract": "Decision-making is a complex process requiring diverse abilities, making it\nan excellent framework for evaluating Large Language Models (LLMs). Researchers\nhave examined LLMs' decision-making through the lens of Game Theory. However,\nexisting evaluation mainly focus on two-player scenarios where an LLM competes\nagainst another. Additionally, previous benchmarks suffer from test set leakage\ndue to their static design. We introduce GAMA($\\gamma$)-Bench, a new framework\nfor evaluating LLMs' Gaming Ability in Multi-Agent environments. It includes\neight classical game theory scenarios and a dynamic scoring scheme specially\ndesigned to quantitatively assess LLMs' performance. $\\gamma$-Bench allows\nflexible game settings and adapts the scoring system to different game\nparameters, enabling comprehensive evaluation of robustness, generalizability,\nand strategies for improvement. Our results indicate that GPT-3.5 demonstrates\nstrong robustness but limited generalizability, which can be enhanced using\nmethods like Chain-of-Thought. We also evaluate 13 LLMs from 6 model families,\nincluding GPT-3.5, GPT-4, Gemini, LLaMA-3.1, Mixtral, and Qwen-2.\nGemini-1.5-Pro outperforms others, scoring of $69.8$ out of $100$, followed by\nLLaMA-3.1-70B ($65.9$) and Mixtral-8x22B ($62.4$). Our code and experimental\nresults are publicly available at https://github.com/CUHK-ARISE/GAMABench.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025; 11 pages of main text; 26 pages of appendices;\n  Included models: GPT-3.5-{0613, 1106, 0125}, GPT-4-0125, GPT-4o-0806,\n  Gemini-{1.0, 1.5)-Pro, LLaMA-3.1-{7, 70, 405}B, Mixtral-8x{7, 22}B,\n  Qwen-2-72B",
    "pdf_url": "http://arxiv.org/pdf/2403.11807v7",
    "published_date": "2024-03-18 14:04:47 UTC",
    "updated_date": "2025-03-06 18:58:23 UTC"
  },
  {
    "arxiv_id": "2403.11793v3",
    "title": "Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus",
    "authors": [
      "Seungpil Lee",
      "Woochang Sim",
      "Donghyeon Shin",
      "Wongyu Seo",
      "Jiwon Park",
      "Seokki Lee",
      "Sanha Hwang",
      "Sejin Kim",
      "Sundong Kim"
    ],
    "abstract": "The existing methods for evaluating the inference abilities of Large Language\nModels (LLMs) have been predominantly results-centric, making it challenging to\nassess the inference process comprehensively. We introduce a novel approach\nusing the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the\ninference and contextual understanding abilities of LLMs in a process-centric\nmanner, focusing on three key components from the Language of Thought\nHypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our\ncarefully designed experiments reveal that while LLMs demonstrate some\ninference capabilities, they still significantly lag behind human-level\nreasoning in these three aspects. The main contribution of this paper lies in\nintroducing the LoTH perspective, which provides a method for evaluating the\nreasoning process that conventional results-oriented approaches fail to\ncapture, thereby offering new insights into the development of human-level\nreasoning in artificial intelligence systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.SC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11793v3",
    "published_date": "2024-03-18 13:50:50 UTC",
    "updated_date": "2024-11-23 03:26:41 UTC"
  },
  {
    "arxiv_id": "2403.11790v1",
    "title": "Deep Medial Voxels: Learned Medial Axis Approximations for Anatomical Shape Modeling",
    "authors": [
      "Antonio Pepe",
      "Richard Schussnig",
      "Jianning Li",
      "Christina Gsaxner",
      "Dieter Schmalstieg",
      "Jan Egger"
    ],
    "abstract": "Shape reconstruction from imaging volumes is a recurring need in medical\nimage analysis. Common workflows start with a segmentation step, followed by\ncareful post-processing and,finally, ad hoc meshing algorithms. As this\nsequence can be timeconsuming, neural networks are trained to reconstruct\nshapes through template deformation. These networks deliver state-ofthe-art\nresults without manual intervention, but, so far, they have primarily been\nevaluated on anatomical shapes with little topological variety between\nindividuals. In contrast, other works favor learning implicit shape models,\nwhich have multiple benefits for meshing and visualization. Our work follows\nthis direction by introducing deep medial voxels, a semi-implicit\nrepresentation that faithfully approximates the topological skeleton from\nimaging volumes and eventually leads to shape reconstruction via convolution\nsurfaces. Our reconstruction technique shows potential for both visualization\nand computer simulations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.11790v1",
    "published_date": "2024-03-18 13:47:18 UTC",
    "updated_date": "2024-03-18 13:47:18 UTC"
  },
  {
    "arxiv_id": "2403.11786v1",
    "title": "Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained Large Language Models",
    "authors": [
      "Preetha Datta",
      "Fedor Vitiugin",
      "Anastasiia Chizhikova",
      "Nitin Sawhney"
    ],
    "abstract": "Extracting hyper-relations is crucial for constructing comprehensive\nknowledge graphs, but there are limited supervised methods available for this\ntask. To address this gap, we introduce a zero-shot prompt-based method using\nOpenAI's GPT-3.5 model for extracting hyper-relational knowledge from text.\nComparing our model with a baseline, we achieved promising results, with a\nrecall of 0.77. Although our precision is currently lower, a detailed analysis\nof the model outputs has uncovered potential pathways for future research in\nthis area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages + references",
    "pdf_url": "http://arxiv.org/pdf/2403.11786v1",
    "published_date": "2024-03-18 13:44:48 UTC",
    "updated_date": "2024-03-18 13:44:48 UTC"
  },
  {
    "arxiv_id": "2403.11780v3",
    "title": "Prompt-Singer: Controllable Singing-Voice-Synthesis with Natural Language Prompt",
    "authors": [
      "Yongqi Wang",
      "Ruofan Hu",
      "Rongjie Huang",
      "Zhiqing Hong",
      "Ruiqi Li",
      "Wenrui Liu",
      "Fuming You",
      "Tao Jin",
      "Zhou Zhao"
    ],
    "abstract": "Recent singing-voice-synthesis (SVS) methods have achieved remarkable audio\nquality and naturalness, yet they lack the capability to control the style\nattributes of the synthesized singing explicitly. We propose Prompt-Singer, the\nfirst SVS method that enables attribute controlling on singer gender, vocal\nrange and volume with natural language. We adopt a model architecture based on\na decoder-only transformer with a multi-scale hierarchy, and design a\nrange-melody decoupled pitch representation that enables text-conditioned vocal\nrange control while keeping melodic accuracy. Furthermore, we explore various\nexperiment settings, including different types of text representations, text\nencoder fine-tuning, and introducing speech data to alleviate data scarcity,\naiming to facilitate further research. Experiments show that our model achieves\nfavorable controlling ability and audio quality. Audio samples are available at\nhttp://prompt-singer.github.io .",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by NAACL 2024 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2403.11780v3",
    "published_date": "2024-03-18 13:39:05 UTC",
    "updated_date": "2025-01-06 09:08:24 UTC"
  },
  {
    "arxiv_id": "2403.11772v2",
    "title": "S-JEPA: towards seamless cross-dataset transfer through dynamic spatial attention",
    "authors": [
      "Pierre Guetschel",
      "Thomas Moreau",
      "Michael Tangermann"
    ],
    "abstract": "Motivated by the challenge of seamless cross-dataset transfer in EEG signal\nprocessing, this article presents an exploratory study on the use of Joint\nEmbedding Predictive Architectures (JEPAs). In recent years, self-supervised\nlearning has emerged as a promising approach for transfer learning in various\ndomains. However, its application to EEG signals remains largely unexplored. In\nthis article, we introduce Signal-JEPA for representing EEG recordings which\nincludes a novel domain-specific spatial block masking strategy and three novel\narchitectures for downstream classification. The study is conducted on a 54\nsubjects dataset and the downstream performance of the models is evaluated on\nthree different BCI paradigms: motor imagery, ERP and SSVEP. Our study provides\npreliminary evidence for the potential of JEPAs in EEG signal encoding.\nNotably, our results highlight the importance of spatial filtering for accurate\ndownstream classification and reveal an influence of the length of the\npre-training examples but not of the mask size on the downstream performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11772v2",
    "published_date": "2024-03-18 13:30:12 UTC",
    "updated_date": "2024-10-07 20:07:53 UTC"
  },
  {
    "arxiv_id": "2403.14711v1",
    "title": "Human-in-the-Loop AI for Cheating Ring Detection",
    "authors": [
      "Yong-Siang Shih",
      "Manqian Liao",
      "Ruidong Liu",
      "Mirza Basim Baig"
    ],
    "abstract": "Online exams have become popular in recent years due to their accessibility.\nHowever, some concerns have been raised about the security of the online exams,\nparticularly in the context of professional cheating services aiding malicious\ntest takers in passing exams, forming so-called \"cheating rings\". In this\npaper, we introduce a human-in-the-loop AI cheating ring detection system\ndesigned to detect and deter these cheating rings. We outline the underlying\nlogic of this human-in-the-loop AI system, exploring its design principles\ntailored to achieve its objectives of detecting cheaters. Moreover, we\nillustrate the methodologies used to evaluate its performance and fairness,\naiming to mitigate the unintended risks associated with the AI system. The\ndesign and development of the system adhere to Responsible AI (RAI) standards,\nensuring that ethical considerations are integrated throughout the entire\ndevelopment process.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to the AI4Ed Workshop at AAAI 2024 as a short paper",
    "pdf_url": "http://arxiv.org/pdf/2403.14711v1",
    "published_date": "2024-03-18 13:25:57 UTC",
    "updated_date": "2024-03-18 13:25:57 UTC"
  },
  {
    "arxiv_id": "2403.13018v1",
    "title": "Invisible Backdoor Attack Through Singular Value Decomposition",
    "authors": [
      "Wenmin Chen",
      "Xiaowei Xu"
    ],
    "abstract": "With the widespread application of deep learning across various domains,\nconcerns about its security have grown significantly. Among these, backdoor\nattacks pose a serious security threat to deep neural networks (DNNs). In\nrecent years, backdoor attacks on neural networks have become increasingly\nsophisticated, aiming to compromise the security and trustworthiness of models\nby implanting hidden, unauthorized functionalities or triggers, leading to\nmisleading predictions or behaviors. To make triggers less perceptible and\nimperceptible, various invisible backdoor attacks have been proposed. However,\nmost of them only consider invisibility in the spatial domain, making it easy\nfor recent defense methods to detect the generated toxic images.To address\nthese challenges, this paper proposes an invisible backdoor attack called DEBA.\nDEBA leverages the mathematical properties of Singular Value Decomposition\n(SVD) to embed imperceptible backdoors into models during the training phase,\nthereby causing them to exhibit predefined malicious behavior under specific\ntrigger conditions. Specifically, we first perform SVD on images, and then\nreplace the minor features of trigger images with those of clean images, using\nthem as triggers to ensure the effectiveness of the attack. As minor features\nare scattered throughout the entire image, the major features of clean images\nare preserved, making poisoned images visually indistinguishable from clean\nones. Extensive experimental evaluations demonstrate that DEBA is highly\neffective, maintaining high perceptual quality and a high attack success rate\nfor poisoned images. Furthermore, we assess the performance of DEBA under\nexisting defense measures, showing that it is robust and capable of\nsignificantly evading and resisting the effects of these defense measures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13018v1",
    "published_date": "2024-03-18 13:25:12 UTC",
    "updated_date": "2024-03-18 13:25:12 UTC"
  },
  {
    "arxiv_id": "2403.11755v3",
    "title": "Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs",
    "authors": [
      "M. Jehanzeb Mirza",
      "Leonid Karlinsky",
      "Wei Lin",
      "Sivan Doveh",
      "Jakub Micorek",
      "Mateusz Kozinski",
      "Hilde Kuehne",
      "Horst Possegger"
    ],
    "abstract": "Prompt ensembling of Large Language Model (LLM) generated category-specific\nprompts has emerged as an effective method to enhance zero-shot recognition\nability of Vision-Language Models (VLMs). To obtain these category-specific\nprompts, the present methods rely on hand-crafting the prompts to the LLMs for\ngenerating VLM prompts for the downstream tasks. However, this requires\nmanually composing these task-specific prompts and still, they might not cover\nthe diverse set of visual concepts and task-specific styles associated with the\ncategories of interest. To effectively take humans out of the loop and\ncompletely automate the prompt generation process for zero-shot recognition, we\npropose Meta-Prompting for Visual Recognition (MPVR). Taking as input only\nminimal information about the target task, in the form of its short natural\nlanguage description, and a list of associated class labels, MPVR automatically\nproduces a diverse set of category-specific prompts resulting in a strong\nzero-shot classifier. MPVR generalizes effectively across various popular\nzero-shot image recognition benchmarks belonging to widely different domains\nwhen tested with multiple LLMs and VLMs. For example, MPVR obtains a zero-shot\nrecognition improvement over CLIP by up to 19.8% and 18.2% (5.0% and 4.5% on\naverage over 20 datasets) leveraging GPT and Mixtral LLMs, respectively",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV Camera Ready. Code & Data:\n  https://jmiemirza.github.io/Meta-Prompting/",
    "pdf_url": "http://arxiv.org/pdf/2403.11755v3",
    "published_date": "2024-03-18 13:03:24 UTC",
    "updated_date": "2024-08-07 06:05:42 UTC"
  },
  {
    "arxiv_id": "2403.11734v2",
    "title": "Learning More Expressive General Policies for Classical Planning Domains",
    "authors": [
      "Simon Ståhlberg",
      "Blai Bonet",
      "Hector Geffner"
    ],
    "abstract": "GNN-based approaches for learning general policies across planning domains\nare limited by the expressive power of $C_2$, namely; first-order logic with\ntwo variables and counting. This limitation can be overcame by transitioning to\n$k$-GNNs, for $k=3$, wherein object embeddings are substituted with triplet\nembeddings. Yet, while $3$-GNNs have the expressive power of $C_3$, unlike $1$-\nand $2$-GNNs that are confined to $C_2$, they require quartic time for message\nexchange and cubic space to store embeddings, rendering them infeasible in\npractice. In this work, we introduce a parameterized version R-GNN[$t$] (with\nparameter $t$) of Relational GNNs. Unlike GNNs, that are designed to perform\ncomputation on graphs, Relational GNNs are designed to do computation on\nrelational structures. When $t=\\infty$, R-GNN[$t$] approximates $3$-GNNs over\ngraphs, but using only quadratic space for embeddings. For lower values of $t$,\nsuch as $t=1$ and $t=2$, R-GNN[$t$] achieves a weaker approximation by\nexchanging fewer messages, yet interestingly, often yield the expressivity\nrequired in several planning domains. Furthermore, the new R-GNN[$t$]\narchitecture is the original R-GNN architecture with a suitable transformation\napplied to the inputs only. Experimental results illustrate the clear\nperformance gains of R-GNN[$1$] over the plain R-GNNs, and also over Edge\nTransformers that also approximate $3$-GNNs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2403.11734v2",
    "published_date": "2024-03-18 12:42:53 UTC",
    "updated_date": "2025-02-18 14:42:02 UTC"
  },
  {
    "arxiv_id": "2403.14710v1",
    "title": "Use of recommendation models to provide support to dyslexic students",
    "authors": [
      "Gianluca Morciano",
      "José Manuel Alcalde-Llergo",
      "Andrea Zingoni",
      "Enrique Yeguas-Bolivar",
      "Juri Taborri",
      "Giuseppe Calabrò"
    ],
    "abstract": "Dyslexia is the most widespread specific learning disorder and significantly\nimpair different cognitive domains. This, in turn, negatively affects dyslexic\nstudents during their learning path. Therefore, specific support must be given\nto these students. In addition, such a support must be highly personalized,\nsince the problems generated by the disorder can be very different from one to\nanother. In this work, we explored the possibility of using AI to suggest the\nmost suitable supporting tools for dyslexic students, so as to provide a\ntargeted help that can be of real utility. To do this, we relied on\nrecommendation algorithms, which are a branch of machine learning, that aim to\ndetect personal preferences and provide the most suitable suggestions. We hence\nimplemented and trained three collaborative-filtering recommendation models,\nnamely an item-based, a user-based and a weighted-hybrid model, and studied\ntheir performance on a large database of 1237 students' information, collected\nwith a self-evaluating questionnaire regarding all the most used supporting\nstrategies and digital tools. Each recommendation model was tested with three\ndifferent similarity metrics, namely Pearson correlation, Euclidean distance\nand Cosine similarity. The obtained results showed that a recommendation system\nis highly effective in suggesting the optimal help tools/strategies for\neveryone. This demonstrates that the proposed approach is successful and can be\nused as a new and effective methodology to support students with dyslexia.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "36 pages, 4 figures and 6 tables. Preprint submitted to Expert\n  Systems with Applications",
    "pdf_url": "http://arxiv.org/pdf/2403.14710v1",
    "published_date": "2024-03-18 12:12:38 UTC",
    "updated_date": "2024-03-18 12:12:38 UTC"
  },
  {
    "arxiv_id": "2403.11703v1",
    "title": "LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images",
    "authors": [
      "Ruyi Xu",
      "Yuan Yao",
      "Zonghao Guo",
      "Junbo Cui",
      "Zanlin Ni",
      "Chunjiang Ge",
      "Tat-Seng Chua",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Gao Huang"
    ],
    "abstract": "Visual encoding constitutes the basis of large multimodal models (LMMs) in\nunderstanding the visual world. Conventional LMMs process images in fixed sizes\nand limited resolutions, while recent explorations in this direction are\nlimited in adaptivity, efficiency, and even correctness. In this work, we first\ntake GPT-4V and LLaVA-1.5 as representative examples and expose systematic\nflaws rooted in their visual encoding strategy. To address the challenges, we\npresent LLaVA-UHD, a large multimodal model that can efficiently perceive\nimages in any aspect ratio and high resolution. LLaVA-UHD includes three key\ncomponents: (1) An image modularization strategy that divides native-resolution\nimages into smaller variable-sized slices for efficient and extensible\nencoding, (2) a compression module that further condenses image tokens from\nvisual encoders, and (3) a spatial schema to organize slice tokens for LLMs.\nComprehensive experiments show that LLaVA-UHD outperforms established LMMs\ntrained with 2-3 orders of magnitude more data on 9 benchmarks. Notably, our\nmodel built on LLaVA-1.5 336x336 supports 6 times larger (i.e., 672x1088)\nresolution images using only 94% inference computation, and achieves 6.4\naccuracy improvement on TextVQA. Moreover, the model can be efficiently trained\nin academic settings, within 23 hours on 8 A100 GPUs (vs. 26 hours of\nLLaVA-1.5). We make the data and code publicly available at\nhttps://github.com/thunlp/LLaVA-UHD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.11703v1",
    "published_date": "2024-03-18 12:04:11 UTC",
    "updated_date": "2024-03-18 12:04:11 UTC"
  },
  {
    "arxiv_id": "2403.11671v1",
    "title": "HDLdebugger: Streamlining HDL debugging with Large Language Models",
    "authors": [
      "Xufeng Yao",
      "Haoyang Li",
      "Tsz Ho Chan",
      "Wenyi Xiao",
      "Mingxuan Yuan",
      "Yu Huang",
      "Lei Chen",
      "Bei Yu"
    ],
    "abstract": "In the domain of chip design, Hardware Description Languages (HDLs) play a\npivotal role. However, due to the complex syntax of HDLs and the limited\navailability of online resources, debugging HDL codes remains a difficult and\ntime-intensive task, even for seasoned engineers. Consequently, there is a\npressing need to develop automated HDL code debugging models, which can\nalleviate the burden on hardware engineers. Despite the strong capabilities of\nLarge Language Models (LLMs) in generating, completing, and debugging software\ncode, their utilization in the specialized field of HDL debugging has been\nlimited and, to date, has not yielded satisfactory results. In this paper, we\npropose an LLM-assisted HDL debugging framework, namely HDLdebugger, which\nconsists of HDL debugging data generation via a reverse engineering approach, a\nsearch engine for retrieval-augmented generation, and a retrieval-augmented LLM\nfine-tuning approach. Through the integration of these components, HDLdebugger\ncan automate and streamline HDL debugging for chip design. Our comprehensive\nexperiments, conducted on an HDL code dataset sourced from Huawei, reveal that\nHDLdebugger outperforms 13 cutting-edge LLM baselines, displaying exceptional\neffectiveness in HDL code debugging.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "13 pages,5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.11671v1",
    "published_date": "2024-03-18 11:19:37 UTC",
    "updated_date": "2024-03-18 11:19:37 UTC"
  },
  {
    "arxiv_id": "2403.12114v1",
    "title": "Safety Analysis of Autonomous Railway Systems: An Introduction to the SACRED Methodology",
    "authors": [
      "Josh Hunter",
      "John McDermid",
      "Simon Burton"
    ],
    "abstract": "As the railway industry increasingly seeks to introduce autonomy and machine\nlearning (ML), several questions arise. How can safety be assured for such\nsystems and technologies? What is the applicability of current safety standards\nwithin this new technological landscape? What are the key metrics to classify a\nsystem as safe? Currently, safety analysis for the railway reflects the failure\nmodes of existing technology; in contrast, the primary concern of analysis of\nautomation is typically average performance. Such purely statistical approaches\nto measuring ML performance are limited, as they may overlook classes of\nsituations that may occur rarely but in which the function performs\nconsistently poorly. To combat these difficulties we introduce SACRED, a safety\nmethodology for producing an initial safety case and determining important\nsafety metrics for autonomous systems. The development of SACRED is motivated\nby the proposed GoA-4 light-rail system in Berlin.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "S. Bernardi, T. Zoppi (Editors), \"Fast Abstracts and Student Forum\n  Proceedings - EDCC 2024 - 19th European Dependable Computing Conference,\n  Leuven, Belgium, 8-11 April 2024\"",
    "pdf_url": "http://arxiv.org/pdf/2403.12114v1",
    "published_date": "2024-03-18 11:12:19 UTC",
    "updated_date": "2024-03-18 11:12:19 UTC"
  },
  {
    "arxiv_id": "2403.13848v2",
    "title": "Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule Lists",
    "authors": [
      "Timothée Ly",
      "Julien Ferry",
      "Marie-José Huguet",
      "Sébastien Gambs",
      "Ulrich Aivodji"
    ],
    "abstract": "Differentially-private (DP) mechanisms can be embedded into the design of a\nmachine learning algorithm to protect the resulting model against privacy\nleakage. However, this often comes with a significant loss of accuracy due to\nthe noise added to enforce DP. In this paper, we aim at improving this\ntrade-off for a popular class of machine learning algorithms leveraging the\nGini impurity as an information gain criterion to greedily build interpretable\nmodels such as decision trees or rule lists. To this end, we establish the\nsmooth sensitivity of the Gini impurity, which can be used to obtain thorough\nDP guarantees while adding noise scaled with tighter magnitude. We illustrate\nthe applicability of this mechanism by integrating it within a greedy algorithm\nproducing rule list models, motivated by the fact that such models remain\nunderstudied in the DP literature. Our theoretical analysis and experimental\nresults confirm that the DP rule lists models integrating smooth sensitivity\nhave higher accuracy that those using other DP frameworks based on global\nsensitivity, for identical privacy budgets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13848v2",
    "published_date": "2024-03-18 10:44:22 UTC",
    "updated_date": "2024-11-12 09:21:13 UTC"
  },
  {
    "arxiv_id": "2403.11642v1",
    "title": "Guiding the generation of counterfactual explanations through temporal background knowledge for Predictive Process Monitoring",
    "authors": [
      "Andrei Buliga",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "Ivan Donadello",
      "Fabrizio Maria Maggi"
    ],
    "abstract": "Counterfactual explanations suggest what should be different in the input\ninstance to change the outcome of an AI system. When dealing with\ncounterfactual explanations in the field of Predictive Process Monitoring,\nhowever, control flow relationships among events have to be carefully\nconsidered. A counterfactual, indeed, should not violate control flow\nrelationships among activities (temporal background knowledege). Within the\nfield of Explainability in Predictive Process Monitoring, there have been a\nseries of works regarding counterfactual explanations for outcome-based\npredictions. However, none of them consider the inclusion of temporal\nbackground knowledge when generating these counterfactuals. In this work, we\nadapt state-of-the-art techniques for counterfactual generation in the domain\nof XAI that are based on genetic algorithms to consider a series of temporal\nconstraints at runtime. We assume that this temporal background knowledge is\ngiven, and we adapt the fitness function, as well as the crossover and mutation\noperators, to maintain the satisfaction of the constraints. The proposed\nmethods are evaluated with respect to state-of-the-art genetic algorithms for\ncounterfactual generation and the results are presented. We showcase that the\ninclusion of temporal background knowledge allows the generation of\ncounterfactuals more conformant to the temporal background knowledge, without\nhowever losing in terms of the counterfactual traditional quality metrics.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11642v1",
    "published_date": "2024-03-18 10:34:40 UTC",
    "updated_date": "2024-03-18 10:34:40 UTC"
  },
  {
    "arxiv_id": "2403.11626v1",
    "title": "QEAN: Quaternion-Enhanced Attention Network for Visual Dance Generation",
    "authors": [
      "Zhizhen Zhou",
      "Yejing Huo",
      "Guoheng Huang",
      "An Zeng",
      "Xuhang Chen",
      "Lian Huang",
      "Zinuo Li"
    ],
    "abstract": "The study of music-generated dance is a novel and challenging Image\ngeneration task. It aims to input a piece of music and seed motions, then\ngenerate natural dance movements for the subsequent music. Transformer-based\nmethods face challenges in time series prediction tasks related to human\nmovements and music due to their struggle in capturing the nonlinear\nrelationship and temporal aspects. This can lead to issues like joint\ndeformation, role deviation, floating, and inconsistencies in dance movements\ngenerated in response to the music. In this paper, we propose a\nQuaternion-Enhanced Attention Network (QEAN) for visual dance synthesis from a\nquaternion perspective, which consists of a Spin Position Embedding (SPE)\nmodule and a Quaternion Rotary Attention (QRA) module. First, SPE embeds\nposition information into self-attention in a rotational manner, leading to\nbetter learning of features of movement sequences and audio sequences, and\nimproved understanding of the connection between music and dance. Second, QRA\nrepresents and fuses 3D motion features and audio features in the form of a\nseries of quaternions, enabling the model to better learn the temporal\ncoordination of music and dance under the complex temporal cycle conditions of\ndance generation. Finally, we conducted experiments on the dataset AIST++, and\nthe results show that our approach achieves better and more robust performance\nin generating accurate, high-quality dance movements. Our source code and\ndataset can be available from https://github.com/MarasyZZ/QEAN and\nhttps://google.github.io/aistplusplus_dataset respectively.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.GR",
    "comment": "Accepted by The Visual Computer Journal",
    "pdf_url": "http://arxiv.org/pdf/2403.11626v1",
    "published_date": "2024-03-18 09:58:43 UTC",
    "updated_date": "2024-03-18 09:58:43 UTC"
  },
  {
    "arxiv_id": "2403.13847v2",
    "title": "Optimal Transport for Domain Adaptation through Gaussian Mixture Models",
    "authors": [
      "Eduardo Fernandes Montesuma",
      "Fred Maurice Ngolè Mboula",
      "Antoine Souloumiac"
    ],
    "abstract": "Machine learning systems operate under the assumption that training and test\ndata are sampled from a fixed probability distribution. However, this\nassumptions is rarely verified in practice, as the conditions upon which data\nwas acquired are likely to change. In this context, the adaptation of the\nunsupervised domain requires minimal access to the data of the new conditions\nfor learning models robust to changes in the data distribution. Optimal\ntransport is a theoretically grounded tool for analyzing changes in\ndistribution, especially as it allows the mapping between domains. However,\nthese methods are usually computationally expensive as their complexity scales\ncubically with the number of samples. In this work, we explore optimal\ntransport between Gaussian Mixture Models (GMMs), which is conveniently written\nin terms of the components of source and target GMMs. We experiment with 9\nbenchmarks, with a total of $85$ adaptation tasks, showing that our methods are\nmore efficient than previous shallow domain adaptation methods, and they scale\nwell with number of samples $n$ and dimensions $d$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 9 figures, 8 tables, accepted at Transactions on Machine\n  Learning Research",
    "pdf_url": "http://arxiv.org/pdf/2403.13847v2",
    "published_date": "2024-03-18 09:32:33 UTC",
    "updated_date": "2025-01-22 12:47:49 UTC"
  },
  {
    "arxiv_id": "2404.07948v1",
    "title": "Usability and Performance Analysis of Embedded Development Environment for On-device Learning",
    "authors": [
      "Enzo Scaffi",
      "Antoine Bonneau",
      "Frédéric Le Mouël",
      "Fabien Mieyeville"
    ],
    "abstract": "This research empirically examines embedded development tools viable for\non-device TinyML implementation. The research evaluates various development\ntools with various abstraction levels on resource-constrained IoT devices, from\nbasic hardware manipulation to deployment of minimalistic ML training. The\nanalysis encompasses memory usage, energy consumption, and performance metrics\nduring model training and inference and usability of the different solutions.\nArduino Framework offers ease of implementation but with increased energy\nconsumption compared to the native option, while RIOT OS exhibits efficient\nenergy consumption despite higher memory utilization with equivalent ease of\nuse. The absence of certain critical functionalities like DVFS directly\nintegrated into the OS highlights limitations for fine hardware control.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07948v1",
    "published_date": "2024-03-18 09:26:04 UTC",
    "updated_date": "2024-03-18 09:26:04 UTC"
  },
  {
    "arxiv_id": "2403.11598v2",
    "title": "Optimal Layout Synthesis for Deep Quantum Circuits on NISQ Processors with 100+ Qubits",
    "authors": [
      "Irfansha Shaik",
      "Jaco van de Pol"
    ],
    "abstract": "Layout synthesis is mapping a quantum circuit to a quantum processor. SWAP\ngate insertions are needed for scheduling 2-qubit gates only on connected\nphysical qubits. With the ever-increasing number of qubits in NISQ processors,\nscalable layout synthesis is of utmost importance. With large optimality gaps\nobserved in heuristic approaches, scalable exact methods are needed. While\nrecent exact and near-optimal approaches scale to moderate circuits, large deep\ncircuits are still out of scope.\n  In this work, we propose a SAT encoding based on parallel plans that apply 1\nSWAP and a group of CNOTs at each time step. Using domain-specific information,\nwe maintain optimality in parallel plans while scaling to large and deep\ncircuits. From our results, we show the scalability of our approach which\nsignificantly outperforms leading exact and near-optimal approaches (up to\n100x). For the first time, we can optimally map several 8, 14, and 16 qubit\ncircuits onto 54, 80, and 127 qubit platforms with up to 17 SWAPs. While adding\noptimal SWAPs, we also report near-optimal depth in our mapped circuits.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "7 Figures, 4 Tables, 1 Listing",
    "pdf_url": "http://arxiv.org/pdf/2403.11598v2",
    "published_date": "2024-03-18 09:19:01 UTC",
    "updated_date": "2024-07-22 12:00:02 UTC"
  },
  {
    "arxiv_id": "2403.11585v3",
    "title": "Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines",
    "authors": [
      "Ekaterina Trofimova",
      "Emil Sataev",
      "Andrey E. Ustyuzhanin"
    ],
    "abstract": "In the ever-evolving landscape of machine learning, seamless translation of\nnatural language descriptions into executable code remains a formidable\nchallenge. This paper introduces Linguacodus, an innovative framework designed\nto tackle this challenge by deploying a dynamic pipeline that iteratively\ntransforms natural language task descriptions into code through high-level\ndata-shaping instructions. The core of Linguacodus is a fine-tuned large\nlanguage model (LLM), empowered to evaluate diverse solutions for various\nproblems and select the most fitting one for a given task. This paper details\nthe fine-tuning process, and sheds light on how natural language descriptions\ncan be translated into functional code. Linguacodus represents a substantial\nleap towards automated code generation, effectively bridging the gap between\ntask descriptions and executable code. It holds great promise for advancing\nmachine learning applications across diverse domains. Additionally, we propose\nan algorithm capable of transforming a natural description of an ML task into\ncode with minimal human interaction. In extensive experiments on a vast machine\nlearning code dataset originating from Kaggle, we showcase the effectiveness of\nLinguacodus. The investigations highlight its potential applications across\ndiverse domains, emphasizing its impact on applied machine learning in various\nscientific fields.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11585v3",
    "published_date": "2024-03-18 08:58:47 UTC",
    "updated_date": "2024-11-21 16:28:03 UTC"
  },
  {
    "arxiv_id": "2403.11558v1",
    "title": "Reinforcement Learning with Token-level Feedback for Controllable Text Generation",
    "authors": [
      "Wendi Li",
      "Wei Wei",
      "Kaihe Xu",
      "Wenfeng Xie",
      "Dangyang Chen",
      "Yu Cheng"
    ],
    "abstract": "To meet the requirements of real-world applications, it is essential to\ncontrol generations of large language models (LLMs). Prior research has tried\nto introduce reinforcement learning (RL) into controllable text generation\nwhile most existing methods suffer from overfitting issues (finetuning-based\nmethods) or semantic collapse (post-processing methods). However, current RL\nmethods are generally guided by coarse-grained (sentence/paragraph-level)\nfeedback, which may lead to suboptimal performance owing to semantic twists or\nprogressions within sentences. To tackle that, we propose a novel reinforcement\nlearning algorithm named TOLE which formulates TOken-LEvel rewards for\ncontrollable text generation, and employs a \"first-quantize-then-noise\"\nparadigm to enhance the robustness of the RL algorithm.Furthermore, TOLE can be\nflexibly extended to multiple constraints with little computational expense.\nExperimental results show that our algorithm can achieve superior performance\non both single-attribute and multi-attribute control tasks. We have released\nour codes at https://github.com/WindyLee0822/CTG",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.11558v1",
    "published_date": "2024-03-18 08:18:37 UTC",
    "updated_date": "2024-03-18 08:18:37 UTC"
  },
  {
    "arxiv_id": "2403.11552v3",
    "title": "LLM3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning",
    "authors": [
      "Shu Wang",
      "Muzhi Han",
      "Ziyuan Jiao",
      "Zeyu Zhang",
      "Ying Nian Wu",
      "Song-Chun Zhu",
      "Hangxin Liu"
    ],
    "abstract": "Conventional Task and Motion Planning (TAMP) approaches rely on manually\ncrafted interfaces connecting symbolic task planning with continuous motion\ngeneration. These domain-specific and labor-intensive modules are limited in\naddressing emerging tasks in real-world settings. Here, we present LLM^3, a\nnovel Large Language Model (LLM)-based TAMP framework featuring a\ndomain-independent interface. Specifically, we leverage the powerful reasoning\nand planning capabilities of pre-trained LLMs to propose symbolic action\nsequences and select continuous action parameters for motion planning.\nCrucially, LLM^3 incorporates motion planning feedback through prompting,\nallowing the LLM to iteratively refine its proposals by reasoning about motion\nfailure. Consequently, LLM^3 interfaces between task planning and motion\nplanning, alleviating the intricate design process of handling domain-specific\nmessages between them. Through a series of simulations in a box-packing domain,\nwe quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP\nproblems and the efficiency in selecting action parameters. Ablation studies\nunderscore the significant contribution of motion failure reasoning to the\nsuccess of LLM^3. Furthermore, we conduct qualitative experiments on a physical\nmanipulator, demonstrating the practical applicability of our approach in\nreal-world settings.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IROS 2024. Codes available: https://github.com/AssassinWS/LLM-TAMP",
    "pdf_url": "http://arxiv.org/pdf/2403.11552v3",
    "published_date": "2024-03-18 08:03:47 UTC",
    "updated_date": "2024-08-21 09:46:35 UTC"
  },
  {
    "arxiv_id": "2403.11536v1",
    "title": "OCR is All you need: Importing Multi-Modality into Image-based Defect Detection System",
    "authors": [
      "Chih-Chung Hsu",
      "Chia-Ming Lee",
      "Chun-Hung Sun",
      "Kuang-Ming Wu"
    ],
    "abstract": "Automatic optical inspection (AOI) plays a pivotal role in the manufacturing\nprocess, predominantly leveraging high-resolution imaging instruments for\nscanning purposes. It detects anomalies by analyzing image textures or\npatterns, making it an essential tool in industrial manufacturing and quality\ncontrol. Despite its importance, the deployment of models for AOI often faces\nchallenges. These include limited sample sizes, which hinder effective feature\nlearning, variations among source domains, and sensitivities to changes in\nlighting and camera positions during imaging. These factors collectively\ncompromise the accuracy of model predictions. Traditional AOI often fails to\ncapitalize on the rich mechanism-parameter information from machines or inside\nimages, including statistical parameters, which typically benefit AOI\nclassification. To address this, we introduce an external modality-guided data\nmining framework, primarily rooted in optical character recognition (OCR), to\nextract statistical features from images as a second modality to enhance\nperformance, termed OANet (Ocr-Aoi-Net). A key aspect of our approach is the\nalignment of external modality features, extracted using a single\nmodality-aware model, with image features encoded by a convolutional neural\nnetwork. This synergy enables a more refined fusion of semantic representations\nfrom different modalities. We further introduce feature refinement and a gating\nfunction in our OANet to optimize the combination of these features, enhancing\ninference and decision-making capabilities. Experimental outcomes show that our\nmethodology considerably boosts the recall rate of the defect detection model\nand maintains high robustness even in challenging scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11536v1",
    "published_date": "2024-03-18 07:41:39 UTC",
    "updated_date": "2024-03-18 07:41:39 UTC"
  },
  {
    "arxiv_id": "2403.13017v1",
    "title": "Impart: An Imperceptible and Effective Label-Specific Backdoor Attack",
    "authors": [
      "Jingke Zhao",
      "Zan Wang",
      "Yongwei Wang",
      "Lanjun Wang"
    ],
    "abstract": "Backdoor attacks have been shown to impose severe threats to real\nsecurity-critical scenarios. Although previous works can achieve high attack\nsuccess rates, they either require access to victim models which may\nsignificantly reduce their threats in practice, or perform visually noticeable\nin stealthiness. Besides, there is still room to improve the attack success\nrates in the scenario that different poisoned samples may have different target\nlabels (a.k.a., the all-to-all setting). In this study, we propose a novel\nimperceptible backdoor attack framework, named Impart, in the scenario where\nthe attacker has no access to the victim model. Specifically, in order to\nenhance the attack capability of the all-to-all setting, we first propose a\nlabel-specific attack. Different from previous works which try to find an\nimperceptible pattern and add it to the source image as the poisoned image, we\nthen propose to generate perturbations that align with the target label in the\nimage feature by a surrogate model. In this way, the generated poisoned images\nare attached with knowledge about the target class, which significantly\nenhances the attack capability.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13017v1",
    "published_date": "2024-03-18 07:22:56 UTC",
    "updated_date": "2024-03-18 07:22:56 UTC"
  },
  {
    "arxiv_id": "2403.15449v3",
    "title": "Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech",
    "authors": [
      "Ghadi Alyahya",
      "Abeer Aldayel"
    ],
    "abstract": "Examining the factors that the counterspeech uses are at the core of\nunderstanding the optimal methods for confronting hate speech online. Various\nstudies have assessed the emotional base factors used in counter speech, such\nas emotional empathy, offensiveness, and hostility. To better understand the\ncounterspeech used in conversations, this study distills persuasion modes into\nreason, emotion, and credibility and evaluates their use in two types of\nconversation interactions: closed (multi-turn) and open (single-turn)\nconcerning racism, sexism, and religious bigotry. The evaluation covers the\ndistinct behaviors seen with human-sourced as opposed to machine-generated\ncounterspeech. It also assesses the interplay between the stance taken and the\nmode of persuasion seen in the counterspeech.\n  Notably, we observe nuanced differences in the counterspeech persuasion modes\nused in open and closed interactions, especially in terms of the topic, with a\ngeneral tendency to use reason as a persuasion mode to express the counterpoint\nto hate comments. The machine-generated counterspeech tends to exhibit an\nemotional persuasion mode, while human counters lean toward reason.\nFurthermore, our study shows that reason tends to obtain more supportive\nreplies than other persuasion modes. The findings highlight the potential for\nincorporating persuasion modes into studies about countering hate speech, as\nthey can serve as an optimal means of explainability and pave the way for the\nfurther adoption of the reply's stance and the role it plays in assessing what\ncomprises the optimal counterspeech.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to appear @ ICWSM 2025. The link to the camera-ready paper\n  will be added soon",
    "pdf_url": "http://arxiv.org/pdf/2403.15449v3",
    "published_date": "2024-03-18 07:20:35 UTC",
    "updated_date": "2025-04-14 16:35:50 UTC"
  },
  {
    "arxiv_id": "2404.16852v1",
    "title": "A Disease Labeler for Chinese Chest X-Ray Report Generation",
    "authors": [
      "Mengwei Wang",
      "Ruixin Yan",
      "Zeyi Hou",
      "Ning Lang",
      "Xiuzhuang Zhou"
    ],
    "abstract": "In the field of medical image analysis, the scarcity of Chinese chest X-ray\nreport datasets has hindered the development of technology for generating\nChinese chest X-ray reports. On one hand, the construction of a Chinese chest\nX-ray report dataset is limited by the time-consuming and costly process of\naccurate expert disease annotation. On the other hand, a single natural\nlanguage generation metric is commonly used to evaluate the similarity between\ngenerated and ground-truth reports, while the clinical accuracy and\neffectiveness of the generated reports rely on an accurate disease labeler\n(classifier). To address the issues, this study proposes a disease labeler\ntailored for the generation of Chinese chest X-ray reports. This labeler\nleverages a dual BERT architecture to handle diagnostic reports and clinical\ninformation separately and constructs a hierarchical label learning algorithm\nbased on the affiliation between diseases and body parts to enhance text\nclassification performance. Utilizing this disease labeler, a Chinese chest\nX-ray report dataset comprising 51,262 report samples was established. Finally,\nexperiments and analyses were conducted on a subset of expert-annotated Chinese\nchest X-ray reports, validating the effectiveness of the proposed disease\nlabeler.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16852v1",
    "published_date": "2024-03-18 07:10:33 UTC",
    "updated_date": "2024-03-18 07:10:33 UTC"
  },
  {
    "arxiv_id": "2403.11506v1",
    "title": "End-To-End Underwater Video Enhancement: Dataset and Model",
    "authors": [
      "Dazhao Du",
      "Enhan Li",
      "Lingyu Si",
      "Fanjiang Xu",
      "Jianwei Niu"
    ],
    "abstract": "Underwater video enhancement (UVE) aims to improve the visibility and frame\nquality of underwater videos, which has significant implications for marine\nresearch and exploration. However, existing methods primarily focus on\ndeveloping image enhancement algorithms to enhance each frame independently.\nThere is a lack of supervised datasets and models specifically tailored for UVE\ntasks. To fill this gap, we construct the Synthetic Underwater Video\nEnhancement (SUVE) dataset, comprising 840 diverse underwater-style videos\npaired with ground-truth reference videos. Based on this dataset, we train a\nnovel underwater video enhancement model, UVENet, which utilizes inter-frame\nrelationships to achieve better enhancement performance. Through extensive\nexperiments on both synthetic and real underwater videos, we demonstrate the\neffectiveness of our approach. This study represents the first comprehensive\nexploration of UVE to our knowledge. The code is available at\nhttps://anonymous.4open.science/r/UVENet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11506v1",
    "published_date": "2024-03-18 06:24:46 UTC",
    "updated_date": "2024-03-18 06:24:46 UTC"
  },
  {
    "arxiv_id": "2403.11504v1",
    "title": "MLVICX: Multi-Level Variance-Covariance Exploration for Chest X-ray Self-Supervised Representation Learning",
    "authors": [
      "Azad Singh",
      "Vandan Gorade",
      "Deepak Mishra"
    ],
    "abstract": "Self-supervised learning (SSL) is potentially useful in reducing the need for\nmanual annotation and making deep learning models accessible for medical image\nanalysis tasks. By leveraging the representations learned from unlabeled data,\nself-supervised models perform well on tasks that require little to no\nfine-tuning. However, for medical images, like chest X-rays, which are\ncharacterized by complex anatomical structures and diverse clinical conditions,\nthere arises a need for representation learning techniques that can encode\nfine-grained details while preserving the broader contextual information. In\nthis context, we introduce MLVICX (Multi-Level Variance-Covariance Exploration\nfor Chest X-ray Self-Supervised Representation Learning), an approach to\ncapture rich representations in the form of embeddings from chest X-ray images.\nCentral to our approach is a novel multi-level variance and covariance\nexploration strategy that empowers the model to detect diagnostically\nmeaningful patterns while reducing redundancy effectively. By enhancing the\nvariance and covariance of the learned embeddings, MLVICX promotes the\nretention of critical medical insights by adapting both global and local\ncontextual details. We demonstrate the performance of MLVICX in advancing\nself-supervised chest X-ray representation learning through comprehensive\nexperiments. The performance enhancements we observe across various downstream\ntasks highlight the significance of the proposed approach in enhancing the\nutility of chest X-ray embeddings for precision medical diagnosis and\ncomprehensive image analysis. For pertaining, we used the NIH-Chest X-ray\ndataset, while for downstream tasks, we utilized NIH-Chest X-ray, Vinbig-CXR,\nRSNA pneumonia, and SIIM-ACR Pneumothorax datasets. Overall, we observe more\nthan 3% performance gains over SOTA SSL approaches in various downstream tasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11504v1",
    "published_date": "2024-03-18 06:19:37 UTC",
    "updated_date": "2024-03-18 06:19:37 UTC"
  },
  {
    "arxiv_id": "2403.11496v1",
    "title": "MCD: Diverse Large-Scale Multi-Campus Dataset for Robot Perception",
    "authors": [
      "Thien-Minh Nguyen",
      "Shenghai Yuan",
      "Thien Hoang Nguyen",
      "Pengyu Yin",
      "Haozhi Cao",
      "Lihua Xie",
      "Maciej Wozniak",
      "Patric Jensfelt",
      "Marko Thiel",
      "Justin Ziegenbein",
      "Noel Blunder"
    ],
    "abstract": "Perception plays a crucial role in various robot applications. However,\nexisting well-annotated datasets are biased towards autonomous driving\nscenarios, while unlabelled SLAM datasets are quickly over-fitted, and often\nlack environment and domain variations. To expand the frontier of these fields,\nwe introduce a comprehensive dataset named MCD (Multi-Campus Dataset),\nfeaturing a wide range of sensing modalities, high-accuracy ground truth, and\ndiverse challenging environments across three Eurasian university campuses. MCD\ncomprises both CCS (Classical Cylindrical Spinning) and NRE (Non-Repetitive\nEpicyclic) lidars, high-quality IMUs (Inertial Measurement Units), cameras, and\nUWB (Ultra-WideBand) sensors. Furthermore, in a pioneering effort, we introduce\nsemantic annotations of 29 classes over 59k sparse NRE lidar scans across three\ndomains, thus providing a novel challenge to existing semantic segmentation\nresearch upon this largely unexplored lidar modality. Finally, we propose, for\nthe first time to the best of our knowledge, continuous-time ground truth based\non optimization-based registration of lidar-inertial data on large survey-grade\nprior maps, which are also publicly released, each several times the size of\nexisting ones. We conduct a rigorous evaluation of numerous state-of-the-art\nalgorithms on MCD, report their performance, and highlight the challenges\nawaiting solutions from the research community.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by The IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.11496v1",
    "published_date": "2024-03-18 06:00:38 UTC",
    "updated_date": "2024-03-18 06:00:38 UTC"
  },
  {
    "arxiv_id": "2403.11495v1",
    "title": "Semantic-Enhanced Representation Learning for Road Networks with Temporal Dynamics",
    "authors": [
      "Yile Chen",
      "Xiucheng Li",
      "Gao Cong",
      "Zhifeng Bao",
      "Cheng Long"
    ],
    "abstract": "In this study, we introduce a novel framework called Toast for learning\ngeneral-purpose representations of road networks, along with its advanced\ncounterpart DyToast, designed to enhance the integration of temporal dynamics\nto boost the performance of various time-sensitive downstream tasks.\nSpecifically, we propose to encode two pivotal semantic characteristics\nintrinsic to road networks: traffic patterns and traveling semantics. To\nachieve this, we refine the skip-gram module by incorporating auxiliary\nobjectives aimed at predicting the traffic context associated with a target\nroad segment. Moreover, we leverage trajectory data and design pre-training\nstrategies based on Transformer to distill traveling semantics on road\nnetworks. DyToast further augments this framework by employing unified\ntrigonometric functions characterized by their beneficial properties, enabling\nthe capture of temporal evolution and dynamic nature of road networks more\neffectively. With these proposed techniques, we can obtain representations that\nencode multi-faceted aspects of knowledge within road networks, applicable\nacross both road segment-based applications and trajectory-based applications.\nExtensive experiments on two real-world datasets across three tasks demonstrate\nthat our proposed framework consistently outperforms the state-of-the-art\nbaselines by a significant margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11495v1",
    "published_date": "2024-03-18 05:59:56 UTC",
    "updated_date": "2024-03-18 05:59:56 UTC"
  },
  {
    "arxiv_id": "2403.11492v2",
    "title": "SmartRefine: A Scenario-Adaptive Refinement Framework for Efficient Motion Prediction",
    "authors": [
      "Yang Zhou",
      "Hao Shao",
      "Letian Wang",
      "Steven L. Waslander",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "abstract": "Predicting the future motion of surrounding agents is essential for\nautonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed\nenvironments. Context information, such as road maps and surrounding agents'\nstates, provides crucial geometric and semantic information for motion behavior\nprediction. To this end, recent works explore two-stage prediction frameworks\nwhere coarse trajectories are first proposed, and then used to select critical\ncontext information for trajectory refinement. However, they either incur a\nlarge amount of computation or bring limited improvement, if not both. In this\npaper, we introduce a novel scenario-adaptive refinement strategy, named\nSmartRefine, to refine prediction with minimal additional computation.\nSpecifically, SmartRefine can comprehensively adapt refinement configurations\nbased on each scenario's properties, and smartly chooses the number of\nrefinement iterations by introducing a quality score to measure the prediction\nquality and remaining refinement potential of each scenario. SmartRefine is\ndesigned as a generic and flexible approach that can be seamlessly integrated\ninto most state-of-the-art motion prediction models. Experiments on Argoverse\n(1 & 2) show that our method consistently improves the prediction accuracy of\nmultiple state-of-the-art prediction models. Specifically, by adding\nSmartRefine to QCNet, we outperform all published ensemble-free works on the\nArgoverse 2 leaderboard (single agent track) at submission. Comprehensive\nstudies are also conducted to ablate design choices and explore the mechanism\nbehind multi-iteration refinement. Codes are available at\nhttps://github.com/opendilab/SmartRefine/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Camera-ready version for CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.11492v2",
    "published_date": "2024-03-18 05:53:20 UTC",
    "updated_date": "2024-03-19 17:04:35 UTC"
  },
  {
    "arxiv_id": "2403.11487v3",
    "title": "Can LLMs Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis",
    "authors": [
      "Vishnu Sashank Dorbala",
      "Sanjoy Chowdhury",
      "Dinesh Manocha"
    ],
    "abstract": "We present a novel approach to automatically synthesize \"wayfinding\ninstructions\" for an embodied robot agent. In contrast to prior approaches that\nare heavily reliant on human-annotated datasets designed exclusively for\nspecific simulation platforms, our algorithm uses in-context learning to\ncondition an LLM to generate instructions using just a few references. Using an\nLLM-based Visual Question Answering strategy, we gather detailed information\nabout the environment which is used by the LLM for instruction synthesis. We\nimplement our approach on multiple simulation platforms including Matterport3D,\nAI Habitat and ThreeDWorld, thereby demonstrating its platform-agnostic nature.\nWe subjectively evaluate our approach via a user study and observe that 83.3%\nof users find the synthesized instructions accurately capture the details of\nthe environment and show characteristics similar to those of human-generated\ninstructions. Further, we conduct zero-shot navigation with multiple approaches\non the REVERIE dataset using the generated instructions, and observe very close\ncorrelation with the baseline on standard success metrics (< 1% change in SR),\nquantifying the viability of generated instructions in replacing\nhuman-annotated data. We finally discuss the applicability of our approach in\nenabling a generalizable evaluation of embodied navigation policies. To the\nbest of our knowledge, ours is the first LLM-driven approach capable of\ngenerating \"human-like\" instructions in a platform-agnostic manner, without\ntraining.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "14 Pages",
    "pdf_url": "http://arxiv.org/pdf/2403.11487v3",
    "published_date": "2024-03-18 05:38:07 UTC",
    "updated_date": "2024-04-02 04:27:55 UTC"
  },
  {
    "arxiv_id": "2403.13846v3",
    "title": "A Clustering Method with Graph Maximum Decoding Information",
    "authors": [
      "Xinrun Xu",
      "Manying Lv",
      "Zhanbiao Lian",
      "Yurong Wu",
      "Jin Yan",
      "Shan Jiang",
      "Zhiming Ding"
    ],
    "abstract": "The clustering method based on graph models has garnered increased attention\nfor its widespread applicability across various knowledge domains. Its\nadaptability to integrate seamlessly with other relevant applications endows\nthe graph model-based clustering analysis with the ability to robustly extract\n\"natural associations\" or \"graph structures\" within datasets, facilitating the\nmodelling of relationships between data points. Despite its efficacy, the\ncurrent clustering method utilizing the graph-based model overlooks the\nuncertainty associated with random walk access between nodes and the embedded\nstructural information in the data. To address this gap, we present a novel\nClustering method for Maximizing Decoding Information within graph-based\nmodels, named CMDI. CMDI innovatively incorporates two-dimensional structural\ninformation theory into the clustering process, consisting of two phases: graph\nstructure extraction and graph vertex partitioning. Within CMDI, graph\npartitioning is reformulated as an abstract clustering problem, leveraging\nmaximum decoding information to minimize uncertainty associated with random\nvisits to vertices. Empirical evaluations on three real-world datasets\ndemonstrate that CMDI outperforms classical baseline methods, exhibiting a\nsuperior decoding information ratio (DI-R). Furthermore, CMDI showcases\nheightened efficiency, particularly when considering prior knowledge (PK).\nThese findings underscore the effectiveness of CMDI in enhancing decoding\ninformation quality and computational efficiency, positioning it as a valuable\ntool in graph-based clustering analyses.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 9 figures, IJCNN 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.13846v3",
    "published_date": "2024-03-18 05:18:19 UTC",
    "updated_date": "2025-04-01 08:10:49 UTC"
  },
  {
    "arxiv_id": "2403.11483v1",
    "title": "Open-World Semi-Supervised Learning for Node Classification",
    "authors": [
      "Yanling Wang",
      "Jing Zhang",
      "Lingxi Zhang",
      "Lixin Liu",
      "Yuxiao Dong",
      "Cuiping Li",
      "Hong Chen",
      "Hongzhi Yin"
    ],
    "abstract": "Open-world semi-supervised learning (Open-world SSL) for node classification,\nthat classifies unlabeled nodes into seen classes or multiple novel classes, is\na practical but under-explored problem in the graph community. As only seen\nclasses have human labels, they are usually better learned than novel classes,\nand thus exhibit smaller intra-class variances within the embedding space\n(named as imbalance of intra-class variances between seen and novel classes).\nBased on empirical and theoretical analysis, we find the variance imbalance can\nnegatively impact the model performance. Pre-trained feature encoders can\nalleviate this issue via producing compact representations for novel classes.\nHowever, creating general pre-trained encoders for various types of graph data\nhas been proven to be challenging. As such, there is a demand for an effective\nmethod that does not rely on pre-trained graph encoders. In this paper, we\npropose an IMbalance-Aware method named OpenIMA for Open-world semi-supervised\nnode classification, which trains the node classification model from scratch\nvia contrastive learning with bias-reduced pseudo labels. Extensive experiments\non seven popular graph benchmarks demonstrate the effectiveness of OpenIMA, and\nthe source code has been available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICDE 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.11483v1",
    "published_date": "2024-03-18 05:12:54 UTC",
    "updated_date": "2024-03-18 05:12:54 UTC"
  },
  {
    "arxiv_id": "2403.11473v1",
    "title": "Word Order's Impacts: Insights from Reordering and Generation Analysis",
    "authors": [
      "Qinghua Zhao",
      "Jiaang Li",
      "Lei Li",
      "Zenghui Zhou",
      "Junfeng Liu"
    ],
    "abstract": "Existing works have studied the impacts of the order of words within natural\ntext. They usually analyze it by destroying the original order of words to\ncreate a scrambled sequence, and then comparing the models' performance between\nthe original and scrambled sequences. The experimental results demonstrate\nmarginal drops. Considering this findings, different hypothesis about word\norder is proposed, including ``the order of words is redundant with lexical\nsemantics'', and ``models do not rely on word order''. In this paper, we\nrevisit the aforementioned hypotheses by adding a order reconstruction\nperspective, and selecting datasets of different spectrum. Specifically, we\nfirst select four different datasets, and then design order reconstruction and\ncontinuing generation tasks. Empirical findings support that ChatGPT relies on\nword order to infer, but cannot support or negate the redundancy relations\nbetween word order lexical semantics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11473v1",
    "published_date": "2024-03-18 04:45:44 UTC",
    "updated_date": "2024-03-18 04:45:44 UTC"
  },
  {
    "arxiv_id": "2403.11468v2",
    "title": "CollagePrompt: A Benchmark for Budget-Friendly Visual Recognition with GPT-4V",
    "authors": [
      "Siyu Xu",
      "Yunke Wang",
      "Daochang Liu",
      "Bo Du",
      "Chang Xu"
    ],
    "abstract": "Recent advancements in generative AI have suggested that by taking visual\nprompts, GPT-4V can demonstrate significant proficiency in visual recognition\ntasks. Despite its impressive capabilities, the financial cost associated with\nGPT-4V's inference presents a substantial barrier to its wide use. To address\nthis challenge, we propose a budget-friendly collage prompting task that\ncollages multiple images into a single visual prompt and makes GPT-4V perform\nvisual recognition on several images simultaneously, thereby reducing the cost.\nWe collect a dataset of various collage prompts to assess its performance in\nGPT-4V's visual recognition. Our evaluations reveal several key findings: 1)\nRecognition accuracy varies with different positions in the collage. 2)\nGrouping images of the same category together leads to better visual\nrecognition results. 3) Incorrect labels often come from adjacent images. These\nfindings highlight the importance of image arrangement within collage prompt.\nTo this end, we construct a benchmark called CollagePrompt, which offers a\nplatform for designing collage prompt to achieve more cost-effective visual\nrecognition with GPT-4V. A baseline method derived from genetic algorithms to\noptimize collage layouts is proposed and two metrics are introduced to measure\nthe efficiency of the optimized collage prompt. Our benchmark enables\nresearchers to better optimize collage prompts, thus making GPT-4V more\ncost-effective in visual recognition. The code and data are available at this\nproject page https://collageprompting.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NAACL2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.11468v2",
    "published_date": "2024-03-18 04:41:38 UTC",
    "updated_date": "2025-02-06 12:55:33 UTC"
  },
  {
    "arxiv_id": "2403.11456v4",
    "title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models",
    "authors": [
      "Huy Nghiem",
      "Hal Daumé III"
    ],
    "abstract": "The widespread use of social media necessitates reliable and efficient\ndetection of offensive content to mitigate harmful effects. Although\nsophisticated models perform well on individual datasets, they often fail to\ngeneralize due to varying definitions and labeling of \"offensive content.\" In\nthis paper, we introduce HateCOT, an English dataset with over 52,000 samples\nfrom diverse sources, featuring explanations generated by GPT-3.5Turbo and\ncurated by humans. We demonstrate that pretraining on HateCOT significantly\nenhances the performance of open-source Large Language Models on three\nbenchmark datasets for offensive content detection in both zero-shot and\nfew-shot settings, despite differences in domain and task. Additionally,\nHateCOT facilitates effective K-shot fine-tuning of LLMs with limited data and\nimproves the quality of their explanations, as confirmed by our human\nevaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2403.11456v4",
    "published_date": "2024-03-18 04:12:35 UTC",
    "updated_date": "2024-10-05 21:37:55 UTC"
  },
  {
    "arxiv_id": "2403.12109v1",
    "title": "GCAM: Gaussian and causal-attention model of food fine-grained recognition",
    "authors": [
      "Guohang Zhuang",
      "Yue Hu",
      "Tianxing Yan",
      "JiaZhan Gao"
    ],
    "abstract": "Currently, most food recognition relies on deep learning for category\nclassification. However, these approaches struggle to effectively distinguish\nbetween visually similar food samples, highlighting the pressing need to\naddress fine-grained issues in food recognition. To mitigate these challenges,\nwe propose the adoption of a Gaussian and causal-attention model for\nfine-grained object recognition.In particular, we train to obtain Gaussian\nfeatures over target regions, followed by the extraction of fine-grained\nfeatures from the objects, thereby enhancing the feature mapping capabilities\nof the target regions. To counteract data drift resulting from uneven data\ndistributions, we employ a counterfactual reasoning approach. By using\ncounterfactual interventions, we analyze the impact of the learned image\nattention mechanism on network predictions, enabling the network to acquire\nmore useful attention weights for fine-grained image recognition. Finally, we\ndesign a learnable loss strategy to balance training stability across various\nmodules, ultimately improving the accuracy of the final target recognition. We\nvalidate our approach on four relevant datasets, demonstrating its excellent\nperformance across these four datasets.We experimentally show that GCAM\nsurpasses state-of-the-art methods on the ETH-FOOD101, UECFOOD256, and\nVireo-FOOD172 datasets. Furthermore, our approach also achieves\nstate-of-the-art performance on the CUB-200 dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.12109v1",
    "published_date": "2024-03-18 03:39:54 UTC",
    "updated_date": "2024-03-18 03:39:54 UTC"
  },
  {
    "arxiv_id": "2403.11432v2",
    "title": "Demystifying the Physics of Deep Reinforcement Learning-Based Autonomous Vehicle Decision-Making",
    "authors": [
      "Hanxi Wan",
      "Pei Li",
      "Arpan Kusari"
    ],
    "abstract": "With the advent of universal function approximators in the domain of\nreinforcement learning, the number of practical applications leveraging deep\nreinforcement learning (DRL) has exploded. Decision-making in autonomous\nvehicles (AVs) has emerged as a chief application among them, taking the sensor\ndata or the higher-order kinematic variables as the input and providing a\ndiscrete choice or continuous control output. There has been a continuous\neffort to understand the black-box nature of the DRL models, but so far, there\nhasn't been any discussion (to the best of authors' knowledge) about how the\nmodels learn the physical process. This presents an overwhelming limitation\nthat restricts the real-world deployment of DRL in AVs. Therefore, in this\nresearch work, we try to decode the knowledge learnt by the attention-based DRL\nframework about the physical process. We use a continuous proximal policy\noptimization-based DRL algorithm as the baseline model and add a multi-head\nattention framework in an open-source AV simulation environment. We provide\nsome analytical techniques for discussing the interpretability of the trained\nmodels in terms of explainability and causality for spatial and temporal\ncorrelations. We show that the weights in the first head encode the positions\nof the neighboring vehicles while the second head focuses on the leader vehicle\nexclusively. Also, the ego vehicle's action is causally dependent on the\nvehicles in the target lane spatially and temporally. Through these findings,\nwe reliably show that these techniques can help practitioners decipher the\nresults of the DRL algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted for peer-review",
    "pdf_url": "http://arxiv.org/pdf/2403.11432v2",
    "published_date": "2024-03-18 02:59:13 UTC",
    "updated_date": "2024-06-13 15:03:40 UTC"
  },
  {
    "arxiv_id": "2403.13845v1",
    "title": "Learning to better see the unseen: Broad-Deep Mixed Anti-Forgetting Framework for Incremental Zero-Shot Fault Diagnosis",
    "authors": [
      "Jiancheng Zhao",
      "Jiaqi Yue",
      "Chunhui Zhao"
    ],
    "abstract": "Zero-shot fault diagnosis (ZSFD) is capable of identifying unseen faults via\npredicting fault attributes labeled by human experts. We first recognize the\ndemand of ZSFD to deal with continuous changes in industrial processes, i.e.,\nthe model's ability to adapt to new fault categories and attributes while\navoiding forgetting the diagnosis ability learned previously. To overcome the\nissue that the existing ZSFD paradigm cannot learn from evolving streams of\ntraining data in industrial scenarios, the incremental ZSFD (IZSFD) paradigm is\nproposed for the first time, which incorporates category increment and\nattribute increment for both traditional ZSFD and generalized ZSFD paradigms.\nTo achieve IZSFD, we present a broad-deep mixed anti-forgetting framework\n(BDMAFF) that aims to learn from new fault categories and attributes. To tackle\nthe issue of forgetting, BDMAFF effectively accumulates previously acquired\nknowledge from two perspectives: features and attribute prototypes. The feature\nmemory is established through a deep generative model that employs\nanti-forgetting training strategies, ensuring the generation quality of\nhistorical categories is supervised and maintained. The diagnosis model SEEs\nthe UNSEEN faults with the help of generated samples from the generative model.\nThe attribute prototype memory is established through a diagnosis model\ninspired by the broad learning system. Unlike traditional incremental learning\nalgorithms, BDMAFF introduces a memory-driven iterative update strategy for the\ndiagnosis model, which allows the model to learn new faults and attributes\nwithout requiring the storage of all historical training samples. The\neffectiveness of the proposed method is verified by a real hydraulic system and\nthe Tennessee-Eastman benchmark process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13845v1",
    "published_date": "2024-03-18 02:50:42 UTC",
    "updated_date": "2024-03-18 02:50:42 UTC"
  },
  {
    "arxiv_id": "2405.01555v4",
    "title": "Digital Twin-Empowered Task Assignment in Aerial MEC Network: A Resource Coalition Cooperation Approach with Generative Model",
    "authors": [
      "Xin Tang",
      "Qian Chen",
      "Rong Yu",
      "Xiaohuan Li"
    ],
    "abstract": "To meet the demands for ubiquitous communication and temporary edge computing\nin 6G networks, aerial mobile edge computing (MEC) networks have been\nenvisioned as a new paradigm. However, dynamic user requests pose challenges\nfor task assignment strategies. Most of the existing research assumes that the\nstrategy is deployed on ground-based stations or UAVs, which will be\nineffective in an environment lacking infrastructure and continuous energy\nsupply. Moreover, the resource mutual exclusion problem of dynamic task\nassignment has not been effectively solved. Toward this end, we introduce the\ndigital twin (DT) into the aerial MEC network to study the resource coalition\ncooperation approach with the generative model (GM), which provides a\npreliminary coalition structure for the coalition game. Specifically, we\npropose a novel network framework that is composed of an application plane, a\nphysical plane, and a virtual plane. After that, the task assignment problem is\nsimplified to convex optimization programming with linear constraints. And\nthen, we also propose a resource coalition cooperation approach that is based\non a transferable utility (TU) coalition game to obtain an approximate optimal\nsolution. Numerical results confirm the effectiveness of our proposed approach\nin terms of energy consumption and utilization of resources.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.01555v4",
    "published_date": "2024-03-18 02:28:10 UTC",
    "updated_date": "2024-10-26 12:09:26 UTC"
  },
  {
    "arxiv_id": "2403.11420v1",
    "title": "Neural network representation of quantum systems",
    "authors": [
      "Koji Hashimoto",
      "Yuji Hirono",
      "Jun Maeda",
      "Jojiro Totsuka-Yoshinaka"
    ],
    "abstract": "It has been proposed that random wide neural networks near Gaussian process\nare quantum field theories around Gaussian fixed points. In this paper, we\nprovide a novel map with which a wide class of quantum mechanical systems can\nbe cast into the form of a neural network with a statistical summation over\nnetwork parameters. Our simple idea is to use the universal approximation\ntheorem of neural networks to generate arbitrary paths in the Feynman's path\nintegral. The map can be applied to interacting quantum systems / field\ntheories, even away from the Gaussian limit. Our findings bring machine\nlearning closer to the quantum world.",
    "categories": [
      "hep-th",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "hep-th",
    "comment": "24 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.11420v1",
    "published_date": "2024-03-18 02:20:22 UTC",
    "updated_date": "2024-03-18 02:20:22 UTC"
  },
  {
    "arxiv_id": "2403.11418v1",
    "title": "Variational Sampling of Temporal Trajectories",
    "authors": [
      "Jurijs Nazarovs",
      "Zhichun Huang",
      "Xingjian Zhen",
      "Sourav Pal",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ],
    "abstract": "A deterministic temporal process can be determined by its trajectory, an\nelement in the product space of (a) initial condition $z_0 \\in \\mathcal{Z}$ and\n(b) transition function $f: (\\mathcal{Z}, \\mathcal{T}) \\to \\mathcal{Z}$ often\ninfluenced by the control of the underlying dynamical system. Existing methods\noften model the transition function as a differential equation or as a\nrecurrent neural network. Despite their effectiveness in predicting future\nmeasurements, few results have successfully established a method for sampling\nand statistical inference of trajectories using neural networks, partially due\nto constraints in the parameterization. In this work, we introduce a mechanism\nto learn the distribution of trajectories by parameterizing the transition\nfunction $f$ explicitly as an element in a function space. Our framework allows\nefficient synthesis of novel trajectories, while also directly providing a\nconvenient tool for inference, i.e., uncertainty estimation, likelihood\nevaluations and out of distribution detection for abnormal trajectories. These\ncapabilities can have implications for various downstream tasks, e.g.,\nsimulation and evaluation for reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11418v1",
    "published_date": "2024-03-18 02:12:12 UTC",
    "updated_date": "2024-03-18 02:12:12 UTC"
  },
  {
    "arxiv_id": "2403.11415v2",
    "title": "DreamSampler: Unifying Diffusion Sampling and Score Distillation for Image Manipulation",
    "authors": [
      "Jeongsol Kim",
      "Geon Yeong Park",
      "Jong Chul Ye"
    ],
    "abstract": "Reverse sampling and score-distillation have emerged as main workhorses in\nrecent years for image manipulation using latent diffusion models (LDMs). While\nreverse diffusion sampling often requires adjustments of LDM architecture or\nfeature engineering, score distillation offers a simple yet powerful\nmodel-agnostic approach, but it is often prone to mode-collapsing. To address\nthese limitations and leverage the strengths of both approaches, here we\nintroduce a novel framework called {\\em DreamSampler}, which seamlessly\nintegrates these two distinct approaches through the lens of regularized latent\noptimization. Similar to score-distillation, DreamSampler is a model-agnostic\napproach applicable to any LDM architecture, but it allows both distillation\nand reverse sampling with additional guidance for image editing and\nreconstruction. Through experiments involving image editing, SVG reconstruction\nand etc, we demonstrate the competitive performance of DreamSampler compared to\nexisting approaches, while providing new applications. Code:\nhttps://github.com/DreamSampler/dream-sampler",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.11415v2",
    "published_date": "2024-03-18 02:08:58 UTC",
    "updated_date": "2024-09-23 06:47:08 UTC"
  },
  {
    "arxiv_id": "2403.15447v3",
    "title": "Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression",
    "authors": [
      "Junyuan Hong",
      "Jinhao Duan",
      "Chenhui Zhang",
      "Zhangheng Li",
      "Chulin Xie",
      "Kelsey Lieberman",
      "James Diffenderfer",
      "Brian Bartoldson",
      "Ajay Jaiswal",
      "Kaidi Xu",
      "Bhavya Kailkhura",
      "Dan Hendrycks",
      "Dawn Song",
      "Zhangyang Wang",
      "Bo Li"
    ],
    "abstract": "Compressing high-capability Large Language Models (LLMs) has emerged as a\nfavored strategy for resource-efficient inferences. While state-of-the-art\n(SoTA) compression methods boast impressive advancements in preserving benign\ntask performance, the potential risks of compression in terms of safety and\ntrustworthiness have been largely neglected. This study conducts the first,\nthorough evaluation of three (3) leading LLMs using five (5) SoTA compression\ntechniques across eight (8) trustworthiness dimensions. Our experiments\nhighlight the intricate interplay between compression and trustworthiness,\nrevealing some interesting patterns. We find that quantization is currently a\nmore effective approach than pruning in achieving efficiency and\ntrustworthiness simultaneously. For instance, a 4-bit quantized model retains\nthe trustworthiness of its original counterpart, but model pruning\nsignificantly degrades trustworthiness, even at 50% sparsity. Moreover,\nemploying quantization within a moderate bit range could unexpectedly improve\ncertain trustworthiness dimensions such as ethics and fairness. Conversely,\nextreme quantization to very low bit levels (3 bits) tends to reduce\ntrustworthiness significantly. This increased risk cannot be uncovered by\nlooking at benign performance alone, in turn, mandating comprehensive\ntrustworthiness evaluation in practice. These findings culminate in practical\nrecommendations for simultaneously achieving high utility, efficiency, and\ntrustworthiness in LLMs. Code and models are available at\nhttps://decoding-comp-trust.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML'24",
    "pdf_url": "http://arxiv.org/pdf/2403.15447v3",
    "published_date": "2024-03-18 01:38:19 UTC",
    "updated_date": "2024-06-04 05:40:12 UTC"
  },
  {
    "arxiv_id": "2403.11402v1",
    "title": "Embracing the Generative AI Revolution: Advancing Tertiary Education in Cybersecurity with GPT",
    "authors": [
      "Raza Nowrozy",
      "David Jam"
    ],
    "abstract": "The rapid advancement of generative Artificial Intelligence (AI)\ntechnologies, particularly Generative Pre-trained Transformer (GPT) models such\nas ChatGPT, has the potential to significantly impact cybersecurity. In this\nstudy, we investigated the impact of GPTs, specifically ChatGPT, on tertiary\neducation in cybersecurity, and provided recommendations for universities to\nadapt their curricula to meet the evolving needs of the industry. Our research\nhighlighted the importance of understanding the alignment between GPT's\n``mental model'' and human cognition, as well as the enhancement of GPT\ncapabilities to human skills based on Bloom's taxonomy. By analyzing current\neducational practices and the alignment of curricula with industry\nrequirements, we concluded that universities providing practical degrees like\ncybersecurity should align closely with industry demand and embrace the\ninevitable generative AI revolution, while applying stringent ethics oversight\nto safeguard responsible GPT usage. We proposed a set of recommendations\nfocused on updating university curricula, promoting agility within\nuniversities, fostering collaboration between academia, industry, and\npolicymakers, and evaluating and assessing educational outcomes.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11402v1",
    "published_date": "2024-03-18 01:20:38 UTC",
    "updated_date": "2024-03-18 01:20:38 UTC"
  },
  {
    "arxiv_id": "2403.11401v2",
    "title": "Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning",
    "authors": [
      "Rao Fu",
      "Jingyu Liu",
      "Xilun Chen",
      "Yixin Nie",
      "Wenhan Xiong"
    ],
    "abstract": "This paper introduces Scene-LLM, a 3D-visual-language model that enhances\nembodied agents' abilities in interactive 3D indoor environments by integrating\nthe reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a\nhybrid 3D visual feature representation, that incorporates dense spatial\ninformation and supports scene state updates. The model employs a projection\nlayer to efficiently project these features in the pre-trained textual\nembedding space, enabling effective interpretation of 3D visual information.\nUnique to our approach is the integration of both scene-level and ego-centric\n3D information. This combination is pivotal for interactive planning, where\nscene-level data supports global planning and ego-centric data is important for\nlocalization. Notably, we use ego-centric 3D frame features for feature\nalignment, an efficient technique that enhances the model's ability to align\nfeatures of small objects within the scene. Our experiments with Scene-LLM\ndemonstrate its strong capabilities in dense captioning, question answering,\nand interactive planning. We believe Scene-LLM advances the field of 3D visual\nunderstanding and reasoning, offering new possibilities for sophisticated agent\ninteractions in indoor settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11401v2",
    "published_date": "2024-03-18 01:18:48 UTC",
    "updated_date": "2024-03-22 18:52:51 UTC"
  },
  {
    "arxiv_id": "2403.11395v2",
    "title": "Automated data processing and feature engineering for deep learning and big data applications: a survey",
    "authors": [
      "Alhassan Mumuni",
      "Fuseini Mumuni"
    ],
    "abstract": "Modern approach to artificial intelligence (AI) aims to design algorithms\nthat learn directly from data. This approach has achieved impressive results\nand has contributed significantly to the progress of AI, particularly in the\nsphere of supervised deep learning. It has also simplified the design of\nmachine learning systems as the learning process is highly automated. However,\nnot all data processing tasks in conventional deep learning pipelines have been\nautomated. In most cases data has to be manually collected, preprocessed and\nfurther extended through data augmentation before they can be effective for\ntraining. Recently, special techniques for automating these tasks have emerged.\nThe automation of data processing tasks is driven by the need to utilize large\nvolumes of complex, heterogeneous data for machine learning and big data\napplications. Today, end-to-end automated data processing systems based on\nautomated machine learning (AutoML) techniques are capable of taking raw data\nand transforming them into useful features for Big Data tasks by automating all\nintermediate processing stages. In this work, we present a thorough review of\napproaches for automating data processing tasks in deep learning pipelines,\nincluding automated data preprocessing--e.g., data cleaning, labeling, missing\ndata imputation, and categorical data encoding--as well as data augmentation\n(including synthetic data generation using generative AI methods) and feature\nengineering--specifically, automated feature extraction, feature construction\nand feature selection. In addition to automating specific data processing\ntasks, we discuss the use of AutoML methods and tools to simultaneously\noptimize all stages of the machine learning pipeline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Journal of Information and Intelligence (2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.11395v2",
    "published_date": "2024-03-18 01:07:48 UTC",
    "updated_date": "2024-03-19 09:36:27 UTC"
  },
  {
    "arxiv_id": "2403.13844v1",
    "title": "Scheduled Knowledge Acquisition on Lightweight Vector Symbolic Architectures for Brain-Computer Interfaces",
    "authors": [
      "Yejia Liu",
      "Shijin Duan",
      "Xiaolin Xu",
      "Shaolei Ren"
    ],
    "abstract": "Brain-Computer interfaces (BCIs) are typically designed to be lightweight and\nresponsive in real-time to provide users timely feedback. Classical feature\nengineering is computationally efficient but has low accuracy, whereas the\nrecent neural networks (DNNs) improve accuracy but are computationally\nexpensive and incur high latency. As a promising alternative, the\nlow-dimensional computing (LDC) classifier based on vector symbolic\narchitecture (VSA), achieves small model size yet higher accuracy than\nclassical feature engineering methods. However, its accuracy still lags behind\nthat of modern DNNs, making it challenging to process complex brain signals. To\nimprove the accuracy of a small model, knowledge distillation is a popular\nmethod. However, maintaining a constant level of distillation between the\nteacher and student models may not be the best way for a growing student during\nits progressive learning stages. In this work, we propose a simple scheduled\nknowledge distillation method based on curriculum data order to enable the\nstudent to gradually build knowledge from the teacher model, controlled by an\n$\\alpha$ scheduler. Meanwhile, we employ the LDC/VSA as the student model to\nenhance the on-device inference efficiency for tiny BCI devices that demand low\nlatency. The empirical results have demonstrated that our approach achieves\nbetter tradeoff between accuracy and hardware efficiency compared to other\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a full paper by the tinyML Research Symposium 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.13844v1",
    "published_date": "2024-03-18 01:06:29 UTC",
    "updated_date": "2024-03-18 01:06:29 UTC"
  },
  {
    "arxiv_id": "2403.12108v3",
    "title": "Does AI help humans make better decisions? A statistical evaluation framework for experimental and observational studies",
    "authors": [
      "Eli Ben-Michael",
      "D. James Greiner",
      "Melody Huang",
      "Kosuke Imai",
      "Zhichao Jiang",
      "Sooahn Shin"
    ],
    "abstract": "The use of Artificial Intelligence (AI), or more generally data-driven\nalgorithms, has become ubiquitous in today's society. Yet, in many cases and\nespecially when stakes are high, humans still make final decisions. The\ncritical question, therefore, is whether AI helps humans make better decisions\ncompared to a human-alone or AI-alone system. We introduce a new methodological\nframework to empirically answer this question with a minimal set of\nassumptions. We measure a decision maker's ability to make correct decisions\nusing standard classification metrics based on the baseline potential outcome.\nWe consider a single-blinded and unconfounded treatment assignment, where the\nprovision of AI-generated recommendations is assumed to be randomized across\ncases with humans making final decisions. Under this study design, we show how\nto compare the performance of three alternative decision-making\nsystems--human-alone, human-with-AI, and AI-alone. Importantly, the AI-alone\nsystem includes any individualized treatment assignment, including those that\nare not used in the original study. We also show when AI recommendations should\nbe provided to a human-decision maker, and when one should follow such\nrecommendations. We apply the proposed methodology to our own randomized\ncontrolled trial evaluating a pretrial risk assessment instrument. We find that\nthe risk assessment recommendations do not improve the classification accuracy\nof a judge's decision to impose cash bail. Furthermore, we find that replacing\na human judge with algorithms--the risk assessment score and a large language\nmodel in particular--leads to a worse classification performance.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.12108v3",
    "published_date": "2024-03-18 01:04:52 UTC",
    "updated_date": "2024-10-11 23:05:37 UTC"
  },
  {
    "arxiv_id": "2403.11381v2",
    "title": "Can LLM-Augmented autonomous agents cooperate?, An evaluation of their cooperative capabilities through Melting Pot",
    "authors": [
      "Manuel Mosquera",
      "Juan Sebastian Pinzon",
      "Manuel Rios",
      "Yesid Fonseca",
      "Luis Felipe Giraldo",
      "Nicanor Quijano",
      "Ruben Manrique"
    ],
    "abstract": "As the field of AI continues to evolve, a significant dimension of this\nprogression is the development of Large Language Models and their potential to\nenhance multi-agent artificial intelligence systems. This paper explores the\ncooperative capabilities of Large Language Model-augmented Autonomous Agents\n(LAAs) using the well-known Meltin Pot environments along with reference models\nsuch as GPT4 and GPT3.5. Preliminary results suggest that while these agents\ndemonstrate a propensity for cooperation, they still struggle with effective\ncollaboration in given environments, emphasizing the need for more robust\narchitectures. The study's contributions include an abstraction layer to adapt\nMelting Pot game scenarios for LLMs, the implementation of a reusable\narchitecture for LLM-mediated agent development - which includes short and\nlong-term memories and different cognitive modules, and the evaluation of\ncooperation capabilities using a set of metrics tied to the Melting Pot's\n\"Commons Harvest\" game. The paper closes, by discussing the limitations of the\ncurrent architectural framework and the potential of a new set of modules that\nfosters better cooperation among LAAs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.11381v2",
    "published_date": "2024-03-18 00:13:43 UTC",
    "updated_date": "2024-06-19 16:23:05 UTC"
  },
  {
    "arxiv_id": "2403.15445v1",
    "title": "Decoding Multilingual Topic Dynamics and Trend Identification through ARIMA Time Series Analysis on Social Networks: A Novel Data Translation Framework Enhanced by LDA/HDP Models",
    "authors": [
      "Samawel Jaballi",
      "Azer Mahjoubi",
      "Manar Joundy Hazar",
      "Salah Zrigui",
      "Henri Nicolas",
      "Mounir Zrigui"
    ],
    "abstract": "In this study, the authors present a novel methodology adept at decoding\nmultilingual topic dynamics and identifying communication trends during crises.\nWe focus on dialogues within Tunisian social networks during the Coronavirus\nPandemic and other notable themes like sports and politics. We start by\naggregating a varied multilingual corpus of comments relevant to these\nsubjects. This dataset undergoes rigorous refinement during data preprocessing.\nWe then introduce our No-English-to-English Machine Translation approach to\nhandle linguistic differences. Empirical tests of this method showed high\naccuracy and F1 scores, highlighting its suitability for linguistically\ncoherent tasks. Delving deeper, advanced modeling techniques, specifically LDA\nand HDP models are employed to extract pertinent topics from the translated\ncontent. This leads to applying ARIMA time series analysis to decode evolving\ntopic trends. Applying our method to a multilingual Tunisian dataset, we\neffectively identified key topics mirroring public sentiment. Such insights\nprove vital for organizations and governments striving to understand public\nperspectives during crises. Compared to standard approaches, our model\noutperforms, as confirmed by metrics like Coherence Score, U-mass, and Topic\nCoherence. Additionally, an in-depth assessment of the identified topics\nrevealed notable thematic shifts in discussions, with our trends identification\nindicating impressive accuracy, backed by RMSE-based analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15445v1",
    "published_date": "2024-03-18 00:01:10 UTC",
    "updated_date": "2024-03-18 00:01:10 UTC"
  }
]