[
  {
    "arxiv_id": "2407.15283v1",
    "title": "Enhancing Hardware Fault Tolerance in Machines with Reinforcement Learning Policy Gradient Algorithms",
    "authors": [
      "Sheila Schoepp",
      "Mehran Taghian",
      "Shotaro Miwa",
      "Yoshihiro Mitsuka",
      "Shadan Golestan",
      "Osmar Zaïane"
    ],
    "abstract": "Industry is rapidly moving towards fully autonomous and interconnected\nsystems that can detect and adapt to changing conditions, including machine\nhardware faults. Traditional methods for adding hardware fault tolerance to\nmachines involve duplicating components and algorithmically reconfiguring a\nmachine's processes when a fault occurs. However, the growing interest in\nreinforcement learning-based robotic control offers a new perspective on\nachieving hardware fault tolerance. However, limited research has explored the\npotential of these approaches for hardware fault tolerance in machines. This\npaper investigates the potential of two state-of-the-art reinforcement learning\nalgorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), to\nenhance hardware fault tolerance into machines. We assess the performance of\nthese algorithms in two OpenAI Gym simulated environments, Ant-v2 and\nFetchReach-v1. Robot models in these environments are subjected to six\nsimulated hardware faults. Additionally, we conduct an ablation study to\ndetermine the optimal method for transferring an agent's knowledge, acquired\nthrough learning in a normal (pre-fault) environment, to a (post-)fault\nenvironment in a continual learning setting. Our results demonstrate that\nreinforcement learning-based approaches can enhance hardware fault tolerance in\nsimulated machines, with adaptation occurring within minutes. Specifically, PPO\nexhibits the fastest adaptation when retaining the knowledge within its models,\nwhile SAC performs best when discarding all acquired knowledge. Overall, this\nstudy highlights the potential of reinforcement learning-based approaches, such\nas PPO and SAC, for hardware fault tolerance in machines. These findings pave\nthe way for the development of robust and adaptive machines capable of\neffectively operating in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15283v1",
    "published_date": "2024-07-21 22:24:16 UTC",
    "updated_date": "2024-07-21 22:24:16 UTC"
  },
  {
    "arxiv_id": "2407.15273v1",
    "title": "Unifying Invariant and Variant Features for Graph Out-of-Distribution via Probability of Necessity and Sufficiency",
    "authors": [
      "Xuexin Chen",
      "Ruichu Cai",
      "Kaitao Zheng",
      "Zhifan Jiang",
      "Zhengting Huang",
      "Zhifeng Hao",
      "Zijian Li"
    ],
    "abstract": "Graph Out-of-Distribution (OOD), requiring that models trained on biased data\ngeneralize to the unseen test data, has considerable real-world applications.\nOne of the most mainstream methods is to extract the invariant subgraph by\naligning the original and augmented data with the help of environment\naugmentation. However, these solutions might lead to the loss or redundancy of\nsemantic subgraphs and result in suboptimal generalization. To address this\nchallenge, we propose exploiting Probability of Necessity and Sufficiency (PNS)\nto extract sufficient and necessary invariant substructures. Beyond that, we\nfurther leverage the domain variant subgraphs related to the labels to boost\nthe generalization performance in an ensemble manner. Specifically, we first\nconsider the data generation process for graph data. Under mild conditions, we\nshow that the sufficient and necessary invariant subgraph can be extracted by\nminimizing an upper bound, built on the theoretical advance of the probability\nof necessity and sufficiency. To further bridge the theory and algorithm, we\ndevise the model called Sufficiency and Necessity Inspired Graph Learning\n(SNIGL), which ensembles an invariant subgraph classifier on top of latent\nsufficient and necessary invariant subgraphs, and a domain variant subgraph\nclassifier specific to the test domain for generalization enhancement.\nExperimental results demonstrate that our SNIGL model outperforms the\nstate-of-the-art techniques on six public benchmarks, highlighting its\neffectiveness in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15273v1",
    "published_date": "2024-07-21 21:35:01 UTC",
    "updated_date": "2024-07-21 21:35:01 UTC"
  },
  {
    "arxiv_id": "2407.15259v1",
    "title": "New Rules for Causal Identification with Background Knowledge",
    "authors": [
      "Tian-Zuo Wang",
      "Lue Tao",
      "Zhi-Hua Zhou"
    ],
    "abstract": "Identifying causal relations is crucial for a variety of downstream tasks. In\nadditional to observational data, background knowledge (BK), which could be\nattained from human expertise or experiments, is usually introduced for\nuncovering causal relations. This raises an open problem that in the presence\nof latent variables, what causal relations are identifiable from observational\ndata and BK. In this paper, we propose two novel rules for incorporating BK,\nwhich offer a new perspective to the open problem. In addition, we show that\nthese rules are applicable in some typical causality tasks, such as determining\nthe set of possible causal effects with observational data. Our rule-based\napproach enhances the state-of-the-art method by circumventing a process of\nenumerating block sets that would otherwise take exponential complexity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15259v1",
    "published_date": "2024-07-21 20:21:21 UTC",
    "updated_date": "2024-07-21 20:21:21 UTC"
  },
  {
    "arxiv_id": "2407.21041v1",
    "title": "They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models",
    "authors": [
      "Mohammad Saeid Mahdavinejad",
      "Peyman Adibi",
      "Amirhassan Monadjemi",
      "Pascal Hitzler"
    ],
    "abstract": "Depression is a common mental health issue that requires prompt diagnosis and\ntreatment. Despite the promise of social media data for depression detection,\nthe opacity of employed deep learning models hinders interpretability and\nraises bias concerns. We address this challenge by introducing ProtoDep, a\nnovel, explainable framework for Twitter-based depression detection. ProtoDep\nleverages prototype learning and the generative power of Large Language Models\nto provide transparent explanations at three levels: (i) symptom-level\nexplanations for each tweet and user, (ii) case-based explanations comparing\nthe user to similar individuals, and (iii) transparent decision-making through\nclassification weights. Evaluated on five benchmark datasets, ProtoDep achieves\nnear state-of-the-art performance while learning meaningful prototypes. This\nmulti-faceted approach offers significant potential to enhance the reliability\nand transparency of depression detection on social media, ultimately aiding\nmental health professionals in delivering more informed care.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21041v1",
    "published_date": "2024-07-21 20:13:50 UTC",
    "updated_date": "2024-07-21 20:13:50 UTC"
  },
  {
    "arxiv_id": "2407.15255v3",
    "title": "Explaining Decisions of Agents in Mixed-Motive Games",
    "authors": [
      "Maayan Orner",
      "Oleg Maksimov",
      "Akiva Kleinerman",
      "Charles Ortiz",
      "Sarit Kraus"
    ],
    "abstract": "In recent years, agents have become capable of communicating seamlessly via\nnatural language and navigating in environments that involve cooperation and\ncompetition, a fact that can introduce social dilemmas. Due to the interleaving\nof cooperation and competition, understanding agents' decision-making in such\nenvironments is challenging, and humans can benefit from obtaining\nexplanations. However, such environments and scenarios have rarely been\nexplored in the context of explainable AI. While some explanation methods for\ncooperative environments can be applied in mixed-motive setups, they do not\naddress inter-agent competition, cheap-talk, or implicit communication by\nactions. In this work, we design explanation methods to address these issues.\nThen, we proceed to establish generality and demonstrate the applicability of\nthe methods to three games with vastly different properties. Lastly, we\ndemonstrate the effectiveness and usefulness of the methods for humans in two\nmixed-motive games. The first is a challenging 7-player game called no-press\nDiplomacy. The second is a 3-player game inspired by the prisoner's dilemma,\nfeaturing communication in natural language.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.15255v3",
    "published_date": "2024-07-21 19:56:04 UTC",
    "updated_date": "2025-01-27 15:13:46 UTC"
  },
  {
    "arxiv_id": "2407.15243v1",
    "title": "Genetic Algorithm to Optimize Design of Micro-Surgical Scissors",
    "authors": [
      "Fatemeh Norouziani",
      "Veerash Palanichamy",
      "Shivam Gupta",
      "Onaizah Onaizah"
    ],
    "abstract": "Microrobotics is an attractive area of research as small-scale robots have\nthe potential to improve the precision and dexterity offered by minimally\ninvasive surgeries. One example of such a tool is a pair of micro-surgical\nscissors that was developed for cutting of tumors or cancerous tissues present\ndeep inside the body such as in the brain. This task is often deemed difficult\nor impossible with conventional robotic tools due to their size and dexterity.\nThe scissors are designed with two magnets placed a specific distance apart to\nmaximize deflection and generate cutting forces. However, remote actuation and\nsize requirements of the micro-surgical scissors limits the force that can be\ngenerated to puncture the tissue. To address the limitation of small output\nforces, we use an evolutionary algorithm to further optimize the performance of\nthe scissors. In this study, the design of the previously developed untethered\nmicro-surgical scissors has been modified and their performance is enhanced by\ndetermining the optimal position of the magnets as well as the direction of\neach magnetic moment. The developed algorithm is successfully applied to a\n4-magnet configuration which results in increased net torque. This improvement\nin net torque is directly translated into higher cutting forces. The new\nconfiguration generates a cutting force of 58 mN from 80 generations of the\nevolutionary algorithm which is a 1.65 times improvement from the original\ndesign. Furthermore, the developed algorithm has the advantage that it can be\ndeployed with minor modifications to other microrobotic tools and systems,\nopening up new possibilities for various medical procedures and applications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for presentation at the International Conference on\n  Manipulation, Automation and Robotics at Small Scales (MARSS) 2024, Delft,\n  Netherlands",
    "pdf_url": "http://arxiv.org/pdf/2407.15243v1",
    "published_date": "2024-07-21 18:39:13 UTC",
    "updated_date": "2024-07-21 18:39:13 UTC"
  },
  {
    "arxiv_id": "2407.15239v3",
    "title": "Assessing Brittleness of Image-Text Retrieval Benchmarks from Vision-Language Models Perspective",
    "authors": [
      "Mariya Hendriksen",
      "Shuo Zhang",
      "Ridho Reinanda",
      "Mohamed Yahya",
      "Edgar Meij",
      "Maarten de Rijke"
    ],
    "abstract": "We examine the brittleness of the image-text retrieval (ITR) evaluation\npipeline with a focus on concept granularity. We start by analyzing two common\nbenchmarks, MS-COCO and Flickr30k, and compare them with augmented,\nfine-grained versions, MS-COCO-FG and Flickr30k-FG, given a specified set of\nlinguistic features capturing concept granularity. Flickr30k-FG and MS COCO-FG\nconsistently give rise to higher scores across all the selected features. To\nfurther our understanding of the impact of granularity we consider a novel\ntaxonomy of query perturbations. We apply these perturbations to the selected\ndatasets. We evaluate four diverse state-of-the-art Vision-Language models on\nboth the standard and fine-grained datasets under zero-shot conditions, with\nand without the applied perturbations. The results demonstrate that although\nperturbations generally degrade model performance, the fine-grained datasets\nexhibit a smaller performance drop than their standard counterparts. The\nrelative performance drop across all setups is consistent across all models and\ndatasets, indicating that the issue lies within the benchmarks themselves. We\nconclude by providing an agenda for improving ITR evaluation pipelines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15239v3",
    "published_date": "2024-07-21 18:08:44 UTC",
    "updated_date": "2024-10-28 17:52:17 UTC"
  },
  {
    "arxiv_id": "2407.15238v1",
    "title": "Variational Potential Flow: A Novel Probabilistic Framework for Energy-Based Generative Modelling",
    "authors": [
      "Junn Yong Loo",
      "Michelle Adeline",
      "Arghya Pal",
      "Vishnu Monn Baskaran",
      "Chee-Ming Ting",
      "Raphael C. -W. Phan"
    ],
    "abstract": "Energy based models (EBMs) are appealing for their generality and simplicity\nin data likelihood modeling, but have conventionally been difficult to train\ndue to the unstable and time-consuming implicit MCMC sampling during\ncontrastive divergence training. In this paper, we present a novel energy-based\ngenerative framework, Variational Potential Flow (VAPO), that entirely\ndispenses with implicit MCMC sampling and does not rely on complementary latent\nmodels or cooperative training. The VAPO framework aims to learn a potential\nenergy function whose gradient (flow) guides the prior samples, so that their\ndensity evolution closely follows an approximate data likelihood homotopy. An\nenergy loss function is then formulated to minimize the Kullback-Leibler\ndivergence between density evolution of the flow-driven prior and the data\nlikelihood homotopy. Images can be generated after training the potential\nenergy, by initializing the samples from Gaussian prior and solving the ODE\ngoverning the potential flow on a fixed time interval using generic ODE\nsolvers. Experiment results show that the proposed VAPO framework is capable of\ngenerating realistic images on various image datasets. In particular, our\nproposed framework achieves competitive FID scores for unconditional image\ngeneration on the CIFAR-10 and CelebA datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15238v1",
    "published_date": "2024-07-21 18:08:12 UTC",
    "updated_date": "2024-07-21 18:08:12 UTC"
  },
  {
    "arxiv_id": "2407.15235v1",
    "title": "TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data",
    "authors": [
      "Jipeng Zhang",
      "Yaxuan Qin",
      "Renjie Pi",
      "Weizhong Zhang",
      "Rui Pan",
      "Tong Zhang"
    ],
    "abstract": "Instruction tuning has achieved unprecedented success in NLP, turning large\nlanguage models into versatile chatbots. However, the increasing variety and\nvolume of instruction datasets demand significant computational resources. To\naddress this, it is essential to extract a small and highly informative subset\n(i.e., Coreset) that achieves comparable performance to the full dataset.\nAchieving this goal poses non-trivial challenges: 1) data selection requires\naccurate data representations that reflect the training samples' quality, 2)\nconsidering the diverse nature of instruction datasets, and 3) ensuring the\nefficiency of the coreset selection algorithm for large models. To address\nthese challenges, we propose Task-Agnostic Gradient Clustered COreset Selection\n(TAGCOS). Specifically, we leverage sample gradients as the data\nrepresentations, perform clustering to group similar data, and apply an\nefficient greedy algorithm for coreset selection. Experimental results show\nthat our algorithm, selecting only 5% of the data, surpasses other unsupervised\nmethods and achieves performance close to that of the full dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint. Our code and models are available at:\n  https://github.com/2003pro/TAGCOS",
    "pdf_url": "http://arxiv.org/pdf/2407.15235v1",
    "published_date": "2024-07-21 17:59:20 UTC",
    "updated_date": "2024-07-21 17:59:20 UTC"
  },
  {
    "arxiv_id": "2407.15229v2",
    "title": "A Practical Analysis of Human Alignment with *PO",
    "authors": [
      "Kian Ahrabian",
      "Xihui Lin",
      "Barun Patra",
      "Vishrav Chaudhary",
      "Alon Benhaim",
      "Jay Pujara",
      "Xia Song"
    ],
    "abstract": "At the forefront of state-of-the-art human alignment methods are preference\noptimization methods (*PO). Prior research has often concentrated on\nidentifying the best-performing method, typically involving a grid search over\nhyperparameters, which can be impractical for general practitioners. In this\npaper, we examine the robustness of existing state-of-the-art methods to\nvarying hyperparameters in a realistic out-of-distribution (OOD) scenario that\nmirrors real-world applications of human alignment. Our goal is to empirically\nfind the method that increases the likelihood of achieving better results\nthrough the lens of various metrics, such as KL divergence and response length.\nWe also introduce LN-DPO, a simple length-normalized version of DPO that is\nmore stable across hyperparameters, effectively reduces the average response\nlength, and improves performance. Our analysis of state-of-the-art\nreference-free (i.e., SimPO) and reference-dependent (i.e., DPO and LN-DPO)\nmethods reveals that they perform similarly at their peak (i.e., best possible\nscenario). However, we uncover that the pattern of change in performance\ngreatly varies as we move away from the best possible scenario.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 findings papers. 9 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.15229v2",
    "published_date": "2024-07-21 17:35:20 UTC",
    "updated_date": "2025-04-10 16:34:25 UTC"
  },
  {
    "arxiv_id": "2407.15224v1",
    "title": "PUFFLE: Balancing Privacy, Utility, and Fairness in Federated Learning",
    "authors": [
      "Luca Corbucci",
      "Mikko A Heikkila",
      "David Solans Noguero",
      "Anna Monreale",
      "Nicolas Kourtellis"
    ],
    "abstract": "Training and deploying Machine Learning models that simultaneously adhere to\nprinciples of fairness and privacy while ensuring good utility poses a\nsignificant challenge. The interplay between these three factors of\ntrustworthiness is frequently underestimated and remains insufficiently\nexplored. Consequently, many efforts focus on ensuring only two of these\nfactors, neglecting one in the process. The decentralization of the datasets\nand the variations in distributions among the clients exacerbate the complexity\nof achieving this ethical trade-off in the context of Federated Learning (FL).\nFor the first time in FL literature, we address these three factors of\ntrustworthiness. We introduce PUFFLE, a high-level parameterised approach that\ncan help in the exploration of the balance between utility, privacy, and\nfairness in FL scenarios. We prove that PUFFLE can be effective across diverse\ndatasets, models, and data distributions, reducing the model unfairness up to\n75%, with a maximum reduction in the utility of 17% in the worst-case scenario,\nwhile maintaining strict privacy guarantees during the FL training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15224v1",
    "published_date": "2024-07-21 17:22:18 UTC",
    "updated_date": "2024-07-21 17:22:18 UTC"
  },
  {
    "arxiv_id": "2407.15216v1",
    "title": "Explainability Paths for Sustained Artistic Practice with AI",
    "authors": [
      "Austin Tecks",
      "Thomas Peschlow",
      "Gabriel Vigliensoni"
    ],
    "abstract": "The development of AI-driven generative audio mirrors broader AI trends,\noften prioritizing immediate accessibility at the expense of explainability.\nConsequently, integrating such tools into sustained artistic practice remains a\nsignificant challenge. In this paper, we explore several paths to improve\nexplainability, drawing primarily from our research-creation practice in\ntraining and implementing generative audio models. As practical provisions for\nimproved explainability, we highlight human agency over training materials, the\nviability of small-scale datasets, the facilitation of the iterative creative\nprocess, and the integration of interactive machine learning as a mapping tool.\nImportantly, these steps aim to enhance human agency over generative AI systems\nnot only during model inference, but also when curating and preprocessing\ntraining data as well as during the training phase of models.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts\n  2024) arXiv:2406.14485",
    "pdf_url": "http://arxiv.org/pdf/2407.15216v1",
    "published_date": "2024-07-21 16:48:14 UTC",
    "updated_date": "2024-07-21 16:48:14 UTC"
  },
  {
    "arxiv_id": "2407.18333v1",
    "title": "AutoVCoder: A Systematic Framework for Automated Verilog Code Generation using LLMs",
    "authors": [
      "Mingzhe Gao",
      "Jieru Zhao",
      "Zhe Lin",
      "Wenchao Ding",
      "Xiaofeng Hou",
      "Yu Feng",
      "Chao Li",
      "Minyi Guo"
    ],
    "abstract": "Recently, the use of large language models (LLMs) for software code\ngeneration, e.g., C/C++ and Python, has proven a great success. However, LLMs\nstill suffer from low syntactic and functional correctness when it comes to the\ngeneration of register-transfer level (RTL) code, such as Verilog. To address\nthis issue, in this paper, we develop AutoVCoder, a systematic open-source\nframework that significantly improves the LLMs' correctness of generating\nVerilog code and enhances the quality of its output at the same time. Our\nframework integrates three novel techniques, including a high-quality hardware\ndataset generation approach, a two-round LLM fine-tuning method and a\ndomain-specific retrieval-augmented generation (RAG) mechanism. Experimental\nresults demonstrate that AutoVCoder outperforms both industrial and academic\nLLMs in Verilog code generation. Specifically, AutoVCoder shows a 0.5% and 2.2%\nimprovement in functional correctness on the EvalMachine and EvalHuman\nbenchmarks compared with BetterV, and also achieves a 3.4% increase in syntax\ncorrectness and a 3.4% increase in functional correctness on the RTLLM\nbenchmark compared with RTLCoder.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18333v1",
    "published_date": "2024-07-21 16:42:45 UTC",
    "updated_date": "2024-07-21 16:42:45 UTC"
  },
  {
    "arxiv_id": "2407.15211v2",
    "title": "Failures to Find Transferable Image Jailbreaks Between Vision-Language Models",
    "authors": [
      "Rylan Schaeffer",
      "Dan Valentine",
      "Luke Bailey",
      "James Chua",
      "Cristóbal Eyzaguirre",
      "Zane Durante",
      "Joe Benton",
      "Brando Miranda",
      "Henry Sleight",
      "John Hughes",
      "Rajashree Agrawal",
      "Mrinank Sharma",
      "Scott Emmons",
      "Sanmi Koyejo",
      "Ethan Perez"
    ],
    "abstract": "The integration of new modalities into frontier AI systems offers exciting\ncapabilities, but also increases the possibility such systems can be\nadversarially manipulated in undesirable ways. In this work, we focus on a\npopular class of vision-language models (VLMs) that generate text outputs\nconditioned on visual and textual inputs. We conducted a large-scale empirical\nstudy to assess the transferability of gradient-based universal image\n``jailbreaks\" using a diverse set of over 40 open-parameter VLMs, including 18\nnew VLMs that we publicly release. Overall, we find that transferable\ngradient-based image jailbreaks are extremely difficult to obtain. When an\nimage jailbreak is optimized against a single VLM or against an ensemble of\nVLMs, the jailbreak successfully jailbreaks the attacked VLM(s), but exhibits\nlittle-to-no transfer to any other VLMs; transfer is not affected by whether\nthe attacked and target VLMs possess matching vision backbones or language\nmodels, whether the language model underwent instruction-following and/or\nsafety-alignment training, or many other factors. Only two settings display\npartially successful transfer: between identically-pretrained and\nidentically-initialized VLMs with slightly different VLM training data, and\nbetween different training checkpoints of a single VLM. Leveraging these\nresults, we then demonstrate that transfer can be significantly improved\nagainst a specific target VLM by attacking larger ensembles of\n``highly-similar\" VLMs. These results stand in stark contrast to existing\nevidence of universal and transferable text jailbreaks against language models\nand transferable adversarial attacks against image classifiers, suggesting that\nVLMs may be more robust to gradient-based transfer attacks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Workshops: RBFM (Best Paper), Frontiers in AdvML (Oral),\n  Red Teaming GenAI (Oral), SoLaR (Spotlight), SATA",
    "pdf_url": "http://arxiv.org/pdf/2407.15211v2",
    "published_date": "2024-07-21 16:27:24 UTC",
    "updated_date": "2024-12-16 01:20:42 UTC"
  },
  {
    "arxiv_id": "2407.15208v2",
    "title": "Flow as the Cross-Domain Manipulation Interface",
    "authors": [
      "Mengda Xu",
      "Zhenjia Xu",
      "Yinghao Xu",
      "Cheng Chi",
      "Gordon Wetzstein",
      "Manuela Veloso",
      "Shuran Song"
    ],
    "abstract": "We present Im2Flow2Act, a scalable learning framework that enables robots to\nacquire real-world manipulation skills without the need of real-world robot\ntraining data. The key idea behind Im2Flow2Act is to use object flow as the\nmanipulation interface, bridging domain gaps between different embodiments\n(i.e., human and robot) and training environments (i.e., real-world and\nsimulated). Im2Flow2Act comprises two components: a flow generation network and\na flow-conditioned policy. The flow generation network, trained on human\ndemonstration videos, generates object flow from the initial scene image,\nconditioned on the task description. The flow-conditioned policy, trained on\nsimulated robot play data, maps the generated object flow to robot actions to\nrealize the desired object movements. By using flow as input, this policy can\nbe directly deployed in the real world with a minimal sim-to-real gap. By\nleveraging real-world human videos and simulated robot play data, we bypass the\nchallenges of teleoperating physical robots in the real world, resulting in a\nscalable system for diverse tasks. We demonstrate Im2Flow2Act's capabilities in\na variety of real-world tasks, including the manipulation of rigid,\narticulated, and deformable objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.15208v2",
    "published_date": "2024-07-21 16:15:02 UTC",
    "updated_date": "2024-10-04 04:05:27 UTC"
  },
  {
    "arxiv_id": "2408.01444v2",
    "title": "No Size Fits All: The Perils and Pitfalls of Leveraging LLMs Vary with Company Size",
    "authors": [
      "Ashok Urlana",
      "Charaka Vinayak Kumar",
      "Bala Mallikarjunarao Garlapati",
      "Ajeet Kumar Singh",
      "Rahul Mishra"
    ],
    "abstract": "Large language models (LLMs) are playing a pivotal role in deploying\nstrategic use cases across a range of organizations, from large pan-continental\ncompanies to emerging startups. The issues and challenges involved in the\nsuccessful utilization of LLMs can vary significantly depending on the size of\nthe organization. It is important to study and discuss these pertinent issues\nof LLM adaptation with a focus on the scale of the industrial concerns and\nbrainstorm possible solutions and prospective directions. Such a study has not\nbeen prominently featured in the current research literature. In this study, we\nadopt a threefold strategy: first, we conduct a case study with industry\npractitioners to formulate the key research questions; second, we examine\nexisting industrial publications to address these questions; and finally, we\nprovide a practical guide for industries to utilize LLMs more efficiently. We\nrelease the\nGitHub\\footnote{\\url{https://github.com/vinayakcse/IndustrialLLMsPapers}}\nrepository with the most recent papers in the field.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "COLING2025 Industry track",
    "pdf_url": "http://arxiv.org/pdf/2408.01444v2",
    "published_date": "2024-07-21 16:11:00 UTC",
    "updated_date": "2024-12-01 16:11:18 UTC"
  },
  {
    "arxiv_id": "2407.15202v1",
    "title": "Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors",
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Zhenyu He",
      "Jinhua Zhu",
      "Yingce Xia",
      "Shufang Xie",
      "Rui Yan"
    ],
    "abstract": "Drug-Target binding Affinity (DTA) prediction is essential for drug\ndiscovery. Despite the application of deep learning methods to DTA prediction,\nthe achieved accuracy remain suboptimal. In this work, inspired by the recent\nsuccess of retrieval methods, we propose $k$NN-DTA, a non-parametric\nembedding-based retrieval method adopted on a pre-trained DTA prediction model,\nwhich can extend the power of the DTA model with no or negligible cost.\nDifferent from existing methods, we introduce two neighbor aggregation ways\nfrom both embedding space and label space that are integrated into a unified\nframework. Specifically, we propose a \\emph{label aggregation} with\n\\emph{pair-wise retrieval} and a \\emph{representation aggregation} with\n\\emph{point-wise retrieval} of the nearest neighbors. This method executes in\nthe inference phase and can efficiently boost the DTA prediction performance\nwith no training cost. In addition, we propose an extension, Ada-$k$NN-DTA, an\ninstance-wise and adaptive aggregation with lightweight learning. Results on\nfour benchmark datasets show that $k$NN-DTA brings significant improvements,\noutperforming previous state-of-the-art (SOTA) results, e.g, on BindingDB\nIC$_{50}$ and $K_i$ testbeds, $k$NN-DTA obtains new records of RMSE\n$\\bf{0.684}$ and $\\bf{0.750}$. The extended Ada-$k$NN-DTA further improves the\nperformance to be $\\bf{0.675}$ and $\\bf{0.735}$ RMSE. These results strongly\nprove the effectiveness of our method. Results in other settings and\ncomprehensive studies/analyses also show the great potential of our $k$NN-DTA\napproach.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Accepted by 33rd ACM International Conference on Information and\n  Knowledge Management 2024 (CIKM 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.15202v1",
    "published_date": "2024-07-21 15:49:05 UTC",
    "updated_date": "2024-07-21 15:49:05 UTC"
  },
  {
    "arxiv_id": "2407.15200v3",
    "title": "HyperbolicLR: Epoch insensitive learning rate scheduler",
    "authors": [
      "Tae-Geun Kim"
    ],
    "abstract": "This study proposes two novel learning rate schedulers -- Hyperbolic Learning\nRate Scheduler (HyperbolicLR) and Exponential Hyperbolic Learning Rate\nScheduler (ExpHyperbolicLR) -- to address the epoch sensitivity problem that\noften causes inconsistent learning curves in conventional methods. By\nleveraging the asymptotic behavior of hyperbolic curves, the proposed\nschedulers maintain more stable learning curves across varying epoch settings.\nSpecifically, HyperbolicLR applies this property directly in the epoch-learning\nrate space, while ExpHyperbolicLR extends it to an exponential space. We first\ndetermine optimal hyperparameters for each scheduler on a small number of\nepochs, fix these hyperparameters, and then evaluate performance as the number\nof epochs increases. Experimental results on various deep learning tasks (e.g.,\nimage classification, time series forecasting, and operator learning)\ndemonstrate that both HyperbolicLR and ExpHyperbolicLR achieve more consistent\nperformance improvements than conventional schedulers as training duration\ngrows. These findings suggest that our hyperbolic-based schedulers offer a more\nrobust and efficient approach to deep network optimization, particularly in\nscenarios constrained by computational resources or time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.15200v3",
    "published_date": "2024-07-21 15:43:52 UTC",
    "updated_date": "2025-02-01 08:29:00 UTC"
  },
  {
    "arxiv_id": "2407.15192v2",
    "title": "Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge",
    "authors": [
      "Joshua Shay Kricheli",
      "Khoa Vo",
      "Aniruddha Datta",
      "Spencer Ozgur",
      "Paulo Shakarian"
    ],
    "abstract": "Recent advances in Hierarchical Multi-label Classification (HMC),\nparticularly neurosymbolic-based approaches, have demonstrated improved\nconsistency and accuracy by enforcing constraints on a neural model during\ntraining. However, such work assumes the existence of such constraints\na-priori. In this paper, we relax this strong assumption and present an\napproach based on Error Detection Rules (EDR) that allow for learning\nexplainable rules about the failure modes of machine learning models. We show\nthat these rules are not only effective in detecting when a machine learning\nclassifier has made an error but also can be leveraged as constraints for HMC,\nthereby allowing the recovery of explainable constraints even if they are not\nprovided. We show that our approach is effective in detecting machine learning\nerrors and recovering constraints, is noise tolerant, and can function as a\nsource of knowledge for neurosymbolic models on multiple datasets, including a\nnewly introduced military vehicle recognition dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15192v2",
    "published_date": "2024-07-21 15:12:19 UTC",
    "updated_date": "2025-04-23 01:11:24 UTC"
  },
  {
    "arxiv_id": "2407.15184v1",
    "title": "Decoding Multilingual Moral Preferences: Unveiling LLM's Biases Through the Moral Machine Experiment",
    "authors": [
      "Karina Vida",
      "Fabian Damken",
      "Anne Lauscher"
    ],
    "abstract": "Large language models (LLMs) increasingly find their way into the most\ndiverse areas of our everyday lives. They indirectly influence people's\ndecisions or opinions through their daily use. Therefore, understanding how and\nwhich moral judgements these LLMs make is crucial. However, morality is not\nuniversal and depends on the cultural background. This raises the question of\nwhether these cultural preferences are also reflected in LLMs when prompted in\ndifferent languages or whether moral decision-making is consistent across\ndifferent languages. So far, most research has focused on investigating the\ninherent values of LLMs in English. While a few works conduct multilingual\nanalyses of moral bias in LLMs in a multilingual setting, these analyses do not\ngo beyond atomic actions. To the best of our knowledge, a multilingual analysis\nof moral bias in dilemmas has not yet been conducted.\n  To address this, our paper builds on the moral machine experiment (MME) to\ninvestigate the moral preferences of five LLMs, Falcon, Gemini, Llama, GPT, and\nMPT, in a multilingual setting and compares them with the preferences collected\nfrom humans belonging to different cultures. To accomplish this, we generate\n6500 scenarios of the MME and prompt the models in ten languages on which\naction to take. Our analysis reveals that all LLMs inhibit different moral\nbiases to some degree and that they not only differ from the human preferences\nbut also across multiple languages within the models themselves. Moreover, we\nfind that almost all models, particularly Llama 3, divert greatly from human\nvalues and, for instance, prefer saving fewer people over saving more.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "to be published in AIES 2024 Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2407.15184v1",
    "published_date": "2024-07-21 14:48:13 UTC",
    "updated_date": "2024-07-21 14:48:13 UTC"
  },
  {
    "arxiv_id": "2407.15176v3",
    "title": "ReAttention: Training-Free Infinite Context with Finite Attention Scope",
    "authors": [
      "Xiaoran Liu",
      "Ruixiao Li",
      "Qipeng Guo",
      "Zhigeng Liu",
      "Yuerong Song",
      "Kai Lv",
      "Hang Yan",
      "Linlin Li",
      "Qun Liu",
      "Xipeng Qiu"
    ],
    "abstract": "The long-context capability of the Large Language Models (LLM) has made\nsignificant breakthroughs, but the maximum supported context length in length\nextrapolation remains a critical bottleneck limiting their practical\napplications. The constraint of context length in LLMs arises from the\nself-attention mechanism, which cannot effectively and efficiently capture the\nsemantic relationships within infinitely long contexts via the limited\npre-trained positional information and attention scope. In this work, we\npropose ReAttention, a training-free approach enabling LLM based on the\nself-attention mechanism to support an infinite context with a finite attention\nscope under sufficient memory resources. ReAttention performs the\nposition-agnostic top-$k$ attention before the ordinary position-aware\nself-attention, freeing LLMs from the length extrapolation issue. We validate\nthe performance of ReAttention on the LongBench, L-Eval, and InfiniteBench and\ndemonstrate that it is on par with traditional methods. Furthermore, we also\napply ReAttention on mainstream LLMs, including LLaMA3.1-8B and\nMistral-v0.3-7B, enabling them to support context lengths of at least 1M and\neven expanding the context length of LLaMA3.2-3B-chat by 128$\\times$ to 4M\nwithout any further training in Needle-In-A-Haystack tests. We also improve the\nefficiency of ReAttention with Triton and achieve an efficient extrapolation\nwithout additional overhead. The code is available at\nhttps://github.com/OpenMOSS/ReAttention.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 11 figures, Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.15176v3",
    "published_date": "2024-07-21 14:23:37 UTC",
    "updated_date": "2025-03-19 12:15:10 UTC"
  },
  {
    "arxiv_id": "2407.15174v2",
    "title": "TADA: Temporal Adversarial Data Augmentation for Time Series Data",
    "authors": [
      "Byeong Tak Lee",
      "Joon-myoung Kwon",
      "Yong-Yeon Jo"
    ],
    "abstract": "Domain generalization aim to train models to effectively perform on samples\nthat are unseen and outside of the distribution. Adversarial data augmentation\n(ADA) is a widely used technique in domain generalization. It enhances the\nmodel robustness by including synthetic samples designed to simulate potential\nunseen scenarios into the training datasets, which is then used to train the\nmodel. However, in time series data, traditional ADA approaches often fail to\naddress distribution shifts related to temporal characteristics. To address\nthis limitation, we propose Temporal Adversarial Data Augmentation (TADA) for\ntime series data, which incorporate time warping into ADA. Although time\nwarping is inherently non-differentiable, ADA relies on generating samples\nthrough backpropagation. We resolve this issue by leveraging the duality\nbetween phase shifts in the frequency domain and time shifts in the time\ndomain, thereby making the process differentiable. Our evaluations across\nvarious time series datasets demonstrate that TADA outperforms existing methods\nfor domain generalization. In addition, using distribution visualization, we\nconfirmed that the distribution shifts induced by TADA are clearly different\nfrom those induced by ADA, and together, they effectively simulate real-world\ndistribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15174v2",
    "published_date": "2024-07-21 14:21:00 UTC",
    "updated_date": "2024-10-15 09:54:22 UTC"
  },
  {
    "arxiv_id": "2407.15168v1",
    "title": "Mitigating Deep Reinforcement Learning Backdoors in the Neural Activation Space",
    "authors": [
      "Sanyam Vyas",
      "Chris Hicks",
      "Vasilios Mavroudis"
    ],
    "abstract": "This paper investigates the threat of backdoors in Deep Reinforcement\nLearning (DRL) agent policies and proposes a novel method for their detection\nat runtime. Our study focuses on elusive in-distribution backdoor triggers.\nSuch triggers are designed to induce a deviation in the behaviour of a\nbackdoored agent while blending into the expected data distribution to evade\ndetection. Through experiments conducted in the Atari Breakout environment, we\ndemonstrate the limitations of current sanitisation methods when faced with\nsuch triggers and investigate why they present a challenging defence problem.\nWe then evaluate the hypothesis that backdoor triggers might be easier to\ndetect in the neural activation space of the DRL agent's policy network. Our\nstatistical analysis shows that indeed the activation patterns in the agent's\npolicy network are distinct in the presence of a trigger, regardless of how\nwell the trigger is concealed in the environment. Based on this, we propose a\nnew defence approach that uses a classifier trained on clean environment\nsamples and detects abnormal activations. Our results show that even\nlightweight classifiers can effectively prevent malicious actions with\nconsiderable accuracy, indicating the potential of this research direction even\nagainst sophisticated adversaries.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.15168v1",
    "published_date": "2024-07-21 13:48:23 UTC",
    "updated_date": "2024-07-21 13:48:23 UTC"
  },
  {
    "arxiv_id": "2407.15161v2",
    "title": "FFHFlow: A Flow-based Variational Approach for Learning Diverse Dexterous Grasps with Shape-Aware Introspection",
    "authors": [
      "Qian Feng",
      "Jianxiang Feng",
      "Zhaopeng Chen",
      "Rudolph Triebel",
      "Alois Knoll"
    ],
    "abstract": "Synthesizing diverse dexterous grasps from uncertain partial observation is\nan important yet challenging task for physically intelligent embodiments.\nPrevious works on generative grasp synthesis fell short of precisely capturing\nthe complex grasp distribution and reasoning about shape uncertainty in the\nunstructured and often partially perceived reality. In this work, we introduce\na novel model that can generate diverse grasps for a multi-fingered hand while\nintrospectively handling perceptual uncertainty and recognizing unknown object\ngeometry to avoid performance degradation. Specifically, we devise a Deep\nLatent Variable Model (DLVM) based on Normalizing Flows (NFs), facilitating\nhierarchical and expressive latent representation for modeling versatile\ngrasps. Our model design counteracts typical pitfalls of its popular\nalternative in generative grasping, i.e., conditional Variational Autoencoders\n(cVAEs) whose performance is limited by mode collapse and miss-specified prior\nissues. Moreover, the resultant feature hierarchy and the exact flow likelihood\ncomputation endow our model with shape-aware introspective capabilities,\nenabling it to quantify the shape uncertainty of partial point clouds and\ndetect objects of novel geometry. We further achieve performance gain by fusing\nthis information with a discriminative grasp evaluator, facilitating a novel\nhybrid way for grasp evaluation. Comprehensive simulated and real-world\nexperiments show that the proposed idea gains superior performance and higher\nrun-time efficiency against strong baselines, including diffusion models. We\nalso demonstrate substantial benefits of greater diversity for grasping objects\nin clutter and a confined workspace in the real world.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "First two authors contributed equally, whose ordering decided via\n  coin-tossing. Under Reivew",
    "pdf_url": "http://arxiv.org/pdf/2407.15161v2",
    "published_date": "2024-07-21 13:33:08 UTC",
    "updated_date": "2024-12-18 09:07:47 UTC"
  },
  {
    "arxiv_id": "2407.15160v2",
    "title": "When Can Transformers Count to n?",
    "authors": [
      "Gilad Yehudai",
      "Haim Kaplan",
      "Asma Ghandeharioun",
      "Mor Geva",
      "Amir Globerson"
    ],
    "abstract": "Large language models based on the transformer architectures can solve highly\ncomplex tasks. But are there simple tasks that such models cannot solve? Here\nwe focus on very simple counting tasks, that involve counting how many times a\ntoken in the vocabulary have appeared in a string. We show that if the\ndimension of the transformer state is linear in the context length, this task\ncan be solved. However, the solution we propose does not scale beyond this\nlimit, and we provide theoretical arguments for why it is likely impossible for\na size limited transformer to implement this task. Our empirical results\ndemonstrate the same phase-transition in performance, as anticipated by the\ntheoretical argument. Our results demonstrate the importance of understanding\nhow transformers can solve simple tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15160v2",
    "published_date": "2024-07-21 13:31:02 UTC",
    "updated_date": "2024-10-07 13:19:53 UTC"
  },
  {
    "arxiv_id": "2407.15155v1",
    "title": "Distilling Vision-Language Foundation Models: A Data-Free Approach via Prompt Diversification",
    "authors": [
      "Yunyi Xuan",
      "Weijie Chen",
      "Shicai Yang",
      "Di Xie",
      "Luojun Lin",
      "Yueting Zhuang"
    ],
    "abstract": "Data-Free Knowledge Distillation (DFKD) has shown great potential in creating\na compact student model while alleviating the dependency on real training data\nby synthesizing surrogate data. However, prior arts are seldom discussed under\ndistribution shifts, which may be vulnerable in real-world applications. Recent\nVision-Language Foundation Models, e.g., CLIP, have demonstrated remarkable\nperformance in zero-shot out-of-distribution generalization, yet consuming\nheavy computation resources. In this paper, we discuss the extension of DFKD to\nVision-Language Foundation Models without access to the billion-level\nimage-text datasets. The objective is to customize a student model for\ndistribution-agnostic downstream tasks with given category concepts, inheriting\nthe out-of-distribution generalization capability from the pre-trained\nfoundation models. In order to avoid generalization degradation, the primary\nchallenge of this task lies in synthesizing diverse surrogate images driven by\ntext prompts. Since not only category concepts but also style information are\nencoded in text prompts, we propose three novel Prompt Diversification methods\nto encourage image synthesis with diverse styles, namely Mix-Prompt,\nRandom-Prompt, and Contrastive-Prompt. Experiments on out-of-distribution\ngeneralization datasets demonstrate the effectiveness of the proposed methods,\nwith Contrastive-Prompt performing the best.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACMMM 2023",
    "pdf_url": "http://arxiv.org/pdf/2407.15155v1",
    "published_date": "2024-07-21 13:26:30 UTC",
    "updated_date": "2024-07-21 13:26:30 UTC"
  },
  {
    "arxiv_id": "2407.15143v2",
    "title": "Rethinking Feature Backbone Fine-tuning for Remote Sensing Object Detection",
    "authors": [
      "Yechan Kim",
      "JongHyun Park",
      "SooYeon Kim",
      "Moongu Jeon"
    ],
    "abstract": "Recently, numerous methods have achieved impressive performance in remote\nsensing object detection, relying on convolution or transformer architectures.\nSuch detectors typically have a feature backbone to extract useful features\nfrom raw input images. For the remote sensing domain, a common practice among\ncurrent detectors is to initialize the backbone with pre-training on ImageNet\nconsisting of natural scenes. Fine-tuning the backbone is then typically\nrequired to generate features suitable for remote-sensing images. However, this\ncould hinder the extraction of basic visual features in long-term training,\nthus restricting performance improvement. To mitigate this issue, we propose a\nnovel method named DBF (Dynamic Backbone Freezing) for feature backbone\nfine-tuning on remote sensing object detection. Our method aims to handle the\ndilemma of whether the backbone should extract low-level generic features or\npossess specific knowledge of the remote sensing domain, by introducing a\nmodule called 'Freezing Scheduler' to dynamically manage the update of backbone\nfeatures during training. Extensive experiments on DOTA and DIOR-R show that\nour approach enables more accurate model learning while substantially reducing\ncomputational costs. Our method can be seamlessly adopted without additional\neffort due to its straightforward design.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2407.15143v2",
    "published_date": "2024-07-21 12:32:00 UTC",
    "updated_date": "2024-08-08 05:15:07 UTC"
  },
  {
    "arxiv_id": "2407.15141v1",
    "title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
    "authors": [
      "Yu Zhang",
      "Ruijie Yu",
      "Kaipeng Zeng",
      "Ding Li",
      "Feng Zhu",
      "Xiaokang Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "abstract": "High-throughput reaction condition (RC) screening is fundamental to chemical\nsynthesis. However, current RC screening suffers from laborious and costly\ntrial-and-error workflows. Traditional computer-aided synthesis planning (CASP)\ntools fail to find suitable RCs due to data sparsity and inadequate reaction\nrepresentations. Nowadays, large language models (LLMs) are capable of tackling\nchemistry-related problems, such as molecule design, and chemical logic Q\\&A\ntasks. However, LLMs have not yet achieved accurate predictions of chemical\nreaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM\nthat learns a unified reaction representation from SMILES, reaction graphs, and\ntextual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we\nconstruct 1.2 million pair-wised Q\\&A instruction datasets. Our experimental\nresults demonstrate that MM-RCR achieves state-of-the-art performance on two\nopen benchmark datasets and exhibits strong generalization capabilities on\nout-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR\nhas the potential to accelerate high-throughput condition screening in chemical\nsynthesis.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15141v1",
    "published_date": "2024-07-21 12:27:26 UTC",
    "updated_date": "2024-07-21 12:27:26 UTC"
  },
  {
    "arxiv_id": "2407.15134v1",
    "title": "Proximal Policy Distillation",
    "authors": [
      "Giacomo Spigler"
    ],
    "abstract": "We introduce Proximal Policy Distillation (PPD), a novel policy distillation\nmethod that integrates student-driven distillation and Proximal Policy\nOptimization (PPO) to increase sample efficiency and to leverage the additional\nrewards that the student policy collects during distillation. To assess the\nefficacy of our method, we compare PPD with two common alternatives,\nstudent-distill and teacher-distill, over a wide range of reinforcement\nlearning environments that include discrete actions and continuous control\n(ATARI, Mujoco, and Procgen). For each environment and method, we perform\ndistillation to a set of target student neural networks that are smaller,\nidentical (self-distillation), or larger than the teacher network. Our findings\nindicate that PPD improves sample efficiency and produces better student\npolicies compared to typical policy distillation approaches. Moreover, PPD\ndemonstrates greater robustness than alternative methods when distilling\npolicies from imperfect demonstrations. The code for the paper is released as\npart of a new Python library built on top of stable-baselines3 to facilitate\npolicy distillation: `sb3-distill'.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15134v1",
    "published_date": "2024-07-21 12:08:54 UTC",
    "updated_date": "2024-07-21 12:08:54 UTC"
  },
  {
    "arxiv_id": "2407.15886v2",
    "title": "CatVTON: Concatenation Is All You Need for Virtual Try-On with Diffusion Models",
    "authors": [
      "Zheng Chong",
      "Xiao Dong",
      "Haoxiang Li",
      "Shiyue Zhang",
      "Wenqing Zhang",
      "Xujie Zhang",
      "Hanqing Zhao",
      "Dongmei Jiang",
      "Xiaodan Liang"
    ],
    "abstract": "Virtual try-on methods based on diffusion models achieve realistic effects\nbut often require additional encoding modules, a large number of training\nparameters, and complex preprocessing, which increases the burden on training\nand inference. In this work, we re-evaluate the necessity of additional modules\nand analyze how to improve training efficiency and reduce redundant steps in\nthe inference process. Based on these insights, we propose CatVTON, a simple\nand efficient virtual try-on diffusion model that transfers in-shop or worn\ngarments of arbitrary categories to target individuals by concatenating them\nalong spatial dimensions as inputs of the diffusion model. The efficiency of\nCatVTON is reflected in three aspects: (1) Lightweight network. CatVTON\nconsists only of a VAE and a simplified denoising UNet, removing redundant\nimage and text encoders as well as cross-attentions, and includes just 899.06M\nparameters. (2) Parameter-efficient training. Through experimental analysis, we\nidentify self-attention modules as crucial for adapting pre-trained diffusion\nmodels to the virtual try-on task, enabling high-quality results with only\n49.57M training parameters. (3) Simplified inference. CatVTON eliminates\nunnecessary preprocessing, such as pose estimation, human parsing, and\ncaptioning, requiring only a person image and garment reference to guide the\nvirtual try-on process, reducing over 49% memory usage compared to other\ndiffusion-based methods. Extensive experiments demonstrate that CatVTON\nachieves superior qualitative and quantitative results compared to baseline\nmethods and demonstrates strong generalization performance in in-the-wild\nscenarios, despite being trained solely on public datasets with 73K samples.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T42 (Primary) 168T45 (Secondary)",
      "I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.15886v2",
    "published_date": "2024-07-21 11:58:53 UTC",
    "updated_date": "2025-02-16 03:41:41 UTC"
  },
  {
    "arxiv_id": "2407.15130v2",
    "title": "DOPRA: Decoding Over-accumulation Penalization and Re-allocation in Specific Weighting Layer",
    "authors": [
      "Jinfeng Wei",
      "Xiaofeng Zhang"
    ],
    "abstract": "In this work, we introduce DOPRA, a novel approach designed to mitigate\nhallucinations in multi-modal large language models (MLLMs). Unlike existing\nsolutions that typically involve costly supplementary training data or the\nintegration of external knowledge sources, DOPRA innovatively addresses\nhallucinations by decoding specific weighted layer penalties and\nredistribution, offering an economical and effective solution without\nadditional resources. DOPRA is grounded in unique insights into the intrinsic\nmechanisms controlling hallucinations within MLLMs, especially the models'\ntendency to over-rely on a subset of summary tokens in the self-attention\nmatrix, neglecting critical image-related information. This phenomenon is\nparticularly pronounced in certain strata. To counteract this over-reliance,\nDOPRA employs a strategy of weighted overlay penalties and redistribution in\nspecific layers, such as the 12th layer, during the decoding process.\nFurthermore, DOPRA includes a retrospective allocation process that re-examines\nthe sequence of generated tokens, allowing the algorithm to reallocate token\nselection to better align with the actual image content, thereby reducing the\nincidence of hallucinatory descriptions in auto-generated captions. Overall,\nDOPRA represents a significant step forward in improving the output quality of\nMLLMs by systematically reducing hallucinations through targeted adjustments\nduring the decoding process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15130v2",
    "published_date": "2024-07-21 11:54:49 UTC",
    "updated_date": "2024-07-23 09:30:57 UTC"
  },
  {
    "arxiv_id": "2407.15124v2",
    "title": "Chemical Reaction Extraction from Long Patent Documents",
    "authors": [
      "Aishwarya Jadhav",
      "Ritam Dutt"
    ],
    "abstract": "The task of searching through patent documents is crucial for chemical patent\nrecommendation and retrieval. This can be enhanced by creating a patent\nknowledge base (ChemPatKB) to aid in prior art searches and to provide a\nplatform for domain experts to explore new innovations in chemical compound\nsynthesis and use-cases. An essential foundational component of this KB is the\nextraction of important reaction snippets from long patents documents which\nfacilitates multiple downstream tasks such as reaction co-reference resolution\nand chemical entity role identification. In this work, we explore the problem\nof extracting reactions spans from chemical patents in order to create a\nreactions resource database. We formulate this task as a paragraph-level\nsequence tagging problem, where the system is required to return a sequence of\nparagraphs that contain a description of a reaction. We propose several\napproaches and modifications of the baseline models and study how different\nmethods generalize across different domains of chemical patents.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Work completed in 2022 at Carnegie Mellon University",
    "pdf_url": "http://arxiv.org/pdf/2407.15124v2",
    "published_date": "2024-07-21 11:27:27 UTC",
    "updated_date": "2024-07-23 07:11:47 UTC"
  },
  {
    "arxiv_id": "2407.18271v4",
    "title": "Large Language Model for Verilog Generation with Code-Structure-Guided Reinforcement Learning",
    "authors": [
      "Ning Wang",
      "Bingkun Yao",
      "Jie Zhou",
      "Xi Wang",
      "Zhe Jiang",
      "Nan Guan"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have sparked significant\ninterest in the automatic generation of Register Transfer Level (RTL) designs,\nparticularly using Verilog. Current research on this topic primarily focuses on\npre-training and instruction tuning, but the effectiveness of these methods is\nconstrained by the limited availability of training data, as public Verilog\ncode is far less abundant than software code. In particular, these methods\nstruggle to effectively capture Verilog parallel code structures, which\nfundamentally differ from the imperative, sequential control flow typical in\nmost software programming languages. This paper introduces VeriSeek, an LLM\nenhanced by reinforcement learning using a limited amount of high-quality\ntraining data to achieve high Verilog code generation performance. Our\nreinforcement learning approach employs code structure information as feedback\nsignals to refine the pre-trained model, enabling it to effectively learn\nimportant patterns from Verilog code with parallel structures. Experiments show\nthat VeriSeek outperforms state-of-the-art methods across multiple benchmarks.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.18271v4",
    "published_date": "2024-07-21 11:25:21 UTC",
    "updated_date": "2025-04-19 09:25:52 UTC"
  },
  {
    "arxiv_id": "2408.03335v1",
    "title": "Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions",
    "authors": [
      "Naseem Khan",
      "Kashif Ahmad",
      "Aref Al Tamimi",
      "Mohammed M. Alani",
      "Amine Bermak",
      "Issa Khalil"
    ],
    "abstract": "Industry 5.0, which focuses on human and Artificial Intelligence (AI)\ncollaboration for performing different tasks in manufacturing, involves a\nhigher number of robots, Internet of Things (IoTs) devices and\ninterconnections, Augmented/Virtual Reality (AR), and other smart devices. The\nhuge involvement of these devices and interconnection in various critical\nareas, such as economy, health, education and defense systems, poses several\ntypes of potential security flaws. AI itself has been proven a very effective\nand powerful tool in different areas of cybersecurity, such as intrusion\ndetection, malware detection, and phishing detection, among others. Just as in\nmany application areas, cybersecurity professionals were reluctant to accept\nblack-box ML solutions for cybersecurity applications. This reluctance pushed\nforward the adoption of eXplainable Artificial Intelligence (XAI) as a tool\nthat helps explain how decisions are made in ML-based systems. In this survey,\nwe present a comprehensive study of different XAI-based intrusion detection\nsystems for industry 5.0, and we also examine the impact of explainability and\ninterpretability on Cybersecurity practices through the lens of Adversarial\nXIDS (Adv-XIDS) approaches. Furthermore, we analyze the possible opportunities\nand challenges in XAI cybersecurity systems for industry 5.0 that elicit future\nresearch toward XAI-based solutions to be adopted by high-stakes industry 5.0\napplications. We believe this rigorous analysis will establish a foundational\nframework for subsequent research endeavors within the specified domain.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "57 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.03335v1",
    "published_date": "2024-07-21 09:28:05 UTC",
    "updated_date": "2024-07-21 09:28:05 UTC"
  },
  {
    "arxiv_id": "2407.21040v1",
    "title": "Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned",
    "authors": [
      "Yuan Liao",
      "Jiang Bian",
      "Yuhui Yun",
      "Shuo Wang",
      "Yubo Zhang",
      "Jiaming Chu",
      "Tao Wang",
      "Kewei Li",
      "Yuchen Li",
      "Xuhong Li",
      "Shilei Ji",
      "Haoyi Xiong"
    ],
    "abstract": "While the field of NL2SQL has made significant advancements in translating\nnatural language instructions into executable SQL scripts for data querying and\nprocessing, achieving full automation within the broader data science pipeline\n- encompassing data querying, analysis, visualization, and reporting - remains\na complex challenge. This study introduces SageCopilot, an advanced,\nindustry-grade system system that automates the data science pipeline by\nintegrating Large Language Models (LLMs), Autonomous Agents (AutoAgents), and\nLanguage User Interfaces (LUIs). Specifically, SageCopilot incorporates a\ntwo-phase design: an online component refining users' inputs into executable\nscripts through In-Context Learning (ICL) and running the scripts for results\nreporting & visualization, and an offline preparing demonstrations requested by\nICL in the online phase. A list of trending strategies such as Chain-of-Thought\nand prompt-tuning have been used to augment SageCopilot for enhanced\nperformance. Through rigorous testing and comparative analysis against\nprompt-based solutions, SageCopilot has been empirically validated to achieve\nsuperior end-to-end performance in generating or executing scripts and offering\nresults with visualization, backed by real-world datasets. Our in-depth\nablation studies highlight the individual contributions of various components\nand strategies used by SageCopilot to the end-to-end correctness for data\nsciences.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.21040v1",
    "published_date": "2024-07-21 08:58:18 UTC",
    "updated_date": "2024-07-21 08:58:18 UTC"
  },
  {
    "arxiv_id": "2407.15089v1",
    "title": "Learning Physics for Unveiling Hidden Earthquake Ground Motions via Conditional Generative Modeling",
    "authors": [
      "Pu Ren",
      "Rie Nakata",
      "Maxime Lacour",
      "Ilan Naiman",
      "Nori Nakata",
      "Jialin Song",
      "Zhengfa Bi",
      "Osman Asif Malik",
      "Dmitriy Morozov",
      "Omri Azencot",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "abstract": "Predicting high-fidelity ground motions for future earthquakes is crucial for\nseismic hazard assessment and infrastructure resilience. Conventional empirical\nsimulations suffer from sparse sensor distribution and geographically localized\nearthquake locations, while physics-based methods are computationally intensive\nand require accurate representations of Earth structures and earthquake\nsources. We propose a novel artificial intelligence (AI) simulator, Conditional\nGenerative Modeling for Ground Motion (CGM-GM), to synthesize high-frequency\nand spatially continuous earthquake ground motion waveforms. CGM-GM leverages\nearthquake magnitudes and geographic coordinates of earthquakes and sensors as\ninputs, learning complex wave physics and Earth heterogeneities, without\nexplicit physics constraints. This is achieved through a probabilistic\nautoencoder that captures latent distributions in the time-frequency domain and\nvariational sequential models for prior and posterior distributions. We\nevaluate the performance of CGM-GM using small-magnitude earthquake records\nfrom the San Francisco Bay Area, a region with high seismic risks. CGM-GM\ndemonstrates a strong potential for outperforming a state-of-the-art\nnon-ergodic empirical ground motion model and shows great promise in seismology\nand beyond.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15089v1",
    "published_date": "2024-07-21 08:23:37 UTC",
    "updated_date": "2024-07-21 08:23:37 UTC"
  },
  {
    "arxiv_id": "2407.15086v1",
    "title": "MaxMI: A Maximal Mutual Information Criterion for Manipulation Concept Discovery",
    "authors": [
      "Pei Zhou",
      "Yanchao Yang"
    ],
    "abstract": "We aim to discover manipulation concepts embedded in the unannotated\ndemonstrations, which are recognized as key physical states. The discovered\nconcepts can facilitate training manipulation policies and promote\ngeneralization. Current methods relying on multimodal foundation models for\nderiving key states usually lack accuracy and semantic consistency due to\nlimited multimodal robot data. In contrast, we introduce an\ninformation-theoretic criterion to characterize the regularities that signify a\nset of physical states. We also develop a framework that trains a concept\ndiscovery network using this criterion, thus bypassing the dependence on human\nsemantics and alleviating costly human labeling. The proposed criterion is\nbased on the observation that key states, which deserve to be conceptualized,\noften admit more physical constraints than non-key states. This phenomenon can\nbe formalized as maximizing the mutual information between the putative key\nstate and its preceding state, i.e., Maximal Mutual Information (MaxMI). By\nemploying MaxMI, the trained key state localization network can accurately\nidentify states of sufficient physical significance, exhibiting reasonable\nsemantic compatibility with human perception. Furthermore, the proposed\nframework produces key states that lead to concept-guided manipulation policies\nwith higher success rates and better generalization in various robotic tasks\ncompared to the baselines, verifying the effectiveness of the proposed\ncriterion.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15086v1",
    "published_date": "2024-07-21 07:56:48 UTC",
    "updated_date": "2024-07-21 07:56:48 UTC"
  },
  {
    "arxiv_id": "2407.15078v1",
    "title": "Learning to Compile Programs to Neural Networks",
    "authors": [
      "Logan Weber",
      "Jesse Michel",
      "Alex Renda",
      "Michael Carbin"
    ],
    "abstract": "A $\\textit{neural surrogate of a program}$ is a neural network that mimics\nthe behavior of a program. Researchers have used these neural surrogates to\nautomatically tune program inputs, adapt programs to new settings, and\naccelerate computations. Researchers traditionally develop neural surrogates by\ntraining on input-output examples from a single program. Alternatively,\nlanguage models trained on a large dataset including many programs can consume\nprogram text, to act as a neural surrogate. Using a language model to both\ngenerate a surrogate and act as a surrogate, however, leading to a trade-off\nbetween resource consumption and accuracy. We present $\\textit{neural surrogate\ncompilation}$, a technique for producing neural surrogates directly from\nprogram text without coupling neural surrogate generation and execution. We\nimplement neural surrogate compilers using hypernetworks trained on a dataset\nof C programs and find that they produce neural surrogates that are\n$1.9$-$9.5\\times$ as data-efficient, produce visual results that are\n$1.0$-$1.3\\times$ more similar to ground truth, and train in $4.3$-$7.3\\times$\nfewer epochs than neural surrogates trained from scratch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15078v1",
    "published_date": "2024-07-21 07:04:52 UTC",
    "updated_date": "2024-07-21 07:04:52 UTC"
  },
  {
    "arxiv_id": "2407.15073v3",
    "title": "Multi-Agent Causal Discovery Using Large Language Models",
    "authors": [
      "Hao Duong Le",
      "Xin Xia",
      "Zhang Chen"
    ],
    "abstract": "Causal discovery aims to identify causal relationships between variables and\nis a critical research area in machine learning. Traditional methods focus on\nstatistical or machine learning algorithms to uncover causal links from\nstructured data, often overlooking the valuable contextual information provided\nby metadata. Large language models (LLMs) have shown promise in creating\nunified causal discovery frameworks by incorporating both structured data and\nmetadata. However, their potential in multi-agent settings remains largely\nunexplored. To address this gap, we introduce the Multi-Agent Causal Discovery\nFramework (MAC), which consists of two key modules: the Debate-Coding Module\n(DCM) and the Meta-Debate Module (MDM). The DCM begins with a multi-agent\ndebating and coding process, where agents use both structured data and metadata\nto collaboratively select the most suitable statistical causal discovery (SCD)\nmethod. The selected SCD is then applied to the structured data to generate an\ninitial causal graph. This causal graph is transformed into causal metadata\nthrough the Meta Fusion mechanism. With all the metadata, MDM then refines the\ncausal structure by leveraging a multi-agent debating framework. Extensive\nexperiments across five datasets demonstrate that MAC outperforms both\ntraditional statistical causal discovery methods and existing LLM-based\napproaches, achieving state-of-the-art performance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15073v3",
    "published_date": "2024-07-21 06:21:47 UTC",
    "updated_date": "2025-02-24 02:47:56 UTC"
  },
  {
    "arxiv_id": "2407.15060v1",
    "title": "MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation",
    "authors": [
      "Yun-Han Lan",
      "Wen-Yi Hsiao",
      "Hao-Chung Cheng",
      "Yi-Hsuan Yang"
    ],
    "abstract": "Existing text-to-music models can produce high-quality audio with great\ndiversity. However, textual prompts alone cannot precisely control temporal\nmusical features such as chords and rhythm of the generated music. To address\nthis challenge, we introduce MusiConGen, a temporally-conditioned\nTransformer-based text-to-music model that builds upon the pretrained MusicGen\nframework. Our innovation lies in an efficient finetuning mechanism, tailored\nfor consumer-grade GPUs, that integrates automatically-extracted rhythm and\nchords as the condition signal. During inference, the condition can either be\nmusical features extracted from a reference audio signal, or be user-defined\nsymbolic chord sequence, BPM, and textual prompts. Our performance evaluation\non two datasets -- one derived from extracted features and the other from\nuser-created inputs -- demonstrates that MusiConGen can generate realistic\nbacking track music that aligns well with the specified conditions. We\nopen-source the code and model checkpoints, and provide audio examples online,\nhttps://musicongen.github.io/musicongen_demo/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by the 25th International Society for Music Information\n  Retrieval (ISMIR)",
    "pdf_url": "http://arxiv.org/pdf/2407.15060v1",
    "published_date": "2024-07-21 05:27:53 UTC",
    "updated_date": "2024-07-21 05:27:53 UTC"
  },
  {
    "arxiv_id": "2407.15050v1",
    "title": "Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts",
    "authors": [
      "Yi Liu",
      "Chengjun Cai",
      "Xiaoli Zhang",
      "Xingliang Yuan",
      "Cong Wang"
    ],
    "abstract": "Large Vision Language Models (VLMs) extend and enhance the perceptual\nabilities of Large Language Models (LLMs). Despite offering new possibilities\nfor LLM applications, these advancements raise significant security and ethical\nconcerns, particularly regarding the generation of harmful content. While LLMs\nhave undergone extensive security evaluations with the aid of red teaming\nframeworks, VLMs currently lack a well-developed one. To fill this gap, we\nintroduce Arondight, a standardized red team framework tailored specifically\nfor VLMs. Arondight is dedicated to resolving issues related to the absence of\nvisual modality and inadequate diversity encountered when transitioning\nexisting red teaming methodologies from LLMs to VLMs. Our framework features an\nautomated multi-modal jailbreak attack, wherein visual jailbreak prompts are\nproduced by a red team VLM, and textual prompts are generated by a red team LLM\nguided by a reinforcement learning agent. To enhance the comprehensiveness of\nVLM security evaluation, we integrate entropy bonuses and novelty reward\nmetrics. These elements incentivize the RL agent to guide the red team LLM in\ncreating a wider array of diverse and previously unseen test cases. Our\nevaluation of ten cutting-edge VLMs exposes significant security\nvulnerabilities, particularly in generating toxic images and aligning\nmulti-modal prompts. In particular, our Arondight achieves an average attack\nsuccess rate of 84.5\\% on GPT-4 in all fourteen prohibited scenarios defined by\nOpenAI in terms of generating toxic text. For a clearer comparison, we also\ncategorize existing VLMs based on their safety levels and provide corresponding\nreinforcement recommendations. Our multimodal prompt dataset and red team code\nwill be released after ethics committee approval. CONTENT WARNING: THIS PAPER\nCONTAINS HARMFUL MODEL RESPONSES.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.15050v1",
    "published_date": "2024-07-21 04:37:11 UTC",
    "updated_date": "2024-07-21 04:37:11 UTC"
  },
  {
    "arxiv_id": "2407.15042v1",
    "title": "MedSAGa: Few-shot Memory Efficient Medical Image Segmentation using Gradient Low-Rank Projection in SAM",
    "authors": [
      "Navyansh Mahla",
      "Annie D'souza",
      "Shubh Gupta",
      "Bhavik Kanekar",
      "Kshitij Sharad Jadhav"
    ],
    "abstract": "The application of large-scale models in medical image segmentation demands\nsubstantial quantities of meticulously annotated data curated by experts along\nwith high computational resources, both of which are challenges in\nresource-poor settings. In this study, we present the Medical Segment Anything\nModel with Galore MedSAGa where we adopt the Segment Anything Model (SAM) to\nachieve memory-efficient, few-shot medical image segmentation by applying\nGradient Low-Rank Projection GaLore to the parameters of the image encoder of\nSAM. Meanwhile, the weights of the prompt encoder and mask decoder undergo full\nparameter fine-tuning using standard optimizers. We further assess MedSAGa's\nfew-shot learning capabilities, reporting on its memory efficiency and\nsegmentation performance across multiple standard medical image segmentation\ndatasets. We compare it with several baseline models, including LoRA fine-tuned\nSAM (SAMed) and DAE-Former. Experiments across multiple datasets and these\nbaseline models with different number of images for fine tuning demonstrated\nthat the GPU memory consumption of MedSAGa is significantly less than that of\nthe baseline models, achieving an average memory efficiency of 66% more than\ncurrent state-of-the-art (SOTA) models for medical image segmentation. The\ncombination of substantially lower memory requirements and comparable to SOTA\nresults in few-shot learning for medical image segmentation positions MedSAGa\nas an optimal solution for deployment in resource-constrained settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15042v1",
    "published_date": "2024-07-21 03:34:49 UTC",
    "updated_date": "2024-07-21 03:34:49 UTC"
  },
  {
    "arxiv_id": "2407.15041v1",
    "title": "Self-training Room Layout Estimation via Geometry-aware Ray-casting",
    "authors": [
      "Bolivar Solarte",
      "Chin-Hsuan Wu",
      "Jin-Cheng Jhang",
      "Jonathan Lee",
      "Yi-Hsuan Tsai",
      "Min Sun"
    ],
    "abstract": "In this paper, we introduce a novel geometry-aware self-training framework\nfor room layout estimation models on unseen scenes with unlabeled data. Our\napproach utilizes a ray-casting formulation to aggregate multiple estimates\nfrom different viewing positions, enabling the computation of reliable\npseudo-labels for self-training. In particular, our ray-casting approach\nenforces multi-view consistency along all ray directions and prioritizes\nspatial proximity to the camera view for geometry reasoning. As a result, our\ngeometry-aware pseudo-labels effectively handle complex room geometries and\noccluded walls without relying on assumptions such as Manhattan World or planar\nroom walls. Evaluation on publicly available datasets, including synthetic and\nreal-world scenarios, demonstrates significant improvements in current\nstate-of-the-art layout models without using any human annotation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV-2024",
    "pdf_url": "http://arxiv.org/pdf/2407.15041v1",
    "published_date": "2024-07-21 03:25:55 UTC",
    "updated_date": "2024-07-21 03:25:55 UTC"
  },
  {
    "arxiv_id": "2407.15036v1",
    "title": "AsyCo: An Asymmetric Dual-task Co-training Model for Partial-label Learning",
    "authors": [
      "Beibei Li",
      "Yiyuan Zheng",
      "Beihong Jin",
      "Tao Xiang",
      "Haobo Wang",
      "Lei Feng"
    ],
    "abstract": "Partial-Label Learning (PLL) is a typical problem of weakly supervised\nlearning, where each training instance is annotated with a set of candidate\nlabels. Self-training PLL models achieve state-of-the-art performance but\nsuffer from error accumulation problem caused by mistakenly disambiguated\ninstances. Although co-training can alleviate this issue by training two\nnetworks simultaneously and allowing them to interact with each other, most\nexisting co-training methods train two structurally identical networks with the\nsame task, i.e., are symmetric, rendering it insufficient for them to correct\neach other due to their similar limitations. Therefore, in this paper, we\npropose an asymmetric dual-task co-training PLL model called AsyCo, which\nforces its two networks, i.e., a disambiguation network and an auxiliary\nnetwork, to learn from different views explicitly by optimizing distinct tasks.\nSpecifically, the disambiguation network is trained with self-training PLL task\nto learn label confidence, while the auxiliary network is trained in a\nsupervised learning paradigm to learn from the noisy pairwise similarity labels\nthat are constructed according to the learned label confidence. Finally, the\nerror accumulation problem is mitigated via information distillation and\nconfidence refinement. Extensive experiments on both uniform and\ninstance-dependent partially labeled datasets demonstrate the effectiveness of\nAsyCo. The code is available at https://github.com/libeibeics/AsyCo.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, accepted by Science China, Information Science",
    "pdf_url": "http://arxiv.org/pdf/2407.15036v1",
    "published_date": "2024-07-21 02:08:51 UTC",
    "updated_date": "2024-07-21 02:08:51 UTC"
  },
  {
    "arxiv_id": "2407.15018v2",
    "title": "Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions",
    "authors": [
      "Sarah Wiegreffe",
      "Oyvind Tafjord",
      "Yonatan Belinkov",
      "Hannaneh Hajishirzi",
      "Ashish Sabharwal"
    ],
    "abstract": "Multiple-choice question answering (MCQA) is a key competence of performant\ntransformer language models that is tested by mainstream benchmarks. However,\nrecent evidence shows that models can have quite a range of performance,\nparticularly when the task format is diversified slightly (such as by shuffling\nanswer choice order). In this work we ask: how do successful models perform\nformatted MCQA? We employ vocabulary projection and activation patching methods\nto localize key hidden states that encode relevant information for predicting\nthe correct answer. We find that the prediction of a specific answer symbol is\ncausally attributed to a few middle layers, and specifically their multi-head\nself-attention mechanisms. We show that subsequent layers increase the\nprobability of the predicted answer symbol in vocabulary space, and that this\nprobability increase is associated with a sparse set of attention heads with\nunique roles. We additionally uncover differences in how different models\nadjust to alternative symbols. Finally, we demonstrate that a synthetic task\ncan disentangle sources of model error to pinpoint when a model has learned\nformatted MCQA, and show that logit differences between answer choice tokens\ncontinue to grow over the course of training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 (spotlight). Substantially updated from previous preprint\n  to contain experiments on 4-way multiple-choice with various answer choice\n  symbols, 3 open model families, and extensive activation patching results,\n  including on individual attention heads",
    "pdf_url": "http://arxiv.org/pdf/2407.15018v2",
    "published_date": "2024-07-21 00:10:23 UTC",
    "updated_date": "2025-03-07 22:41:19 UTC"
  }
]