{
  "date": "2024-12-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-10 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、优化和应用，特别是大型语言模型（LLMs）的鲁棒性提升、生成模型的创新，以及强化学习在动态环境中的扩展。其中，令人印象深刻的文章包括 Alán Aspuru-Guzik 等知名学者参与的“Agents for self-driving laboratories applied to quantum computing”，它展示了 AI 在实验自动化中的潜力；以及涉及 LLM 安全和多模态生成的论文，这些工作可能引发更多伦理和实际应用讨论。下面，我将挑选并简要讨论部分重要或话题度高的论文，先从 AI 安全和 LLM 优化入手，再聊生成模型和强化学习相关内容。对于其他较常规的论文（如某些医疗或图像处理主题），我将快速掠过。\n\n### AI 安全和 LLM 优化\n- **TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize Hardware Trojans**（中文：TrojanWhisper：评估预训练 LLMs 以检测和定位硬件木马）  \n  这篇论文探讨了使用 LLMs（如 GPT-4）检测硬件木马的安全性，贡献在于提出一种激活工程方法来识别和调整与硬件漏洞相关的模型激活。主要发现是，该方法提升了 LLMs 在硬件安全领域的鲁棒性，实验显示在多个基准上实现了高精度检测，强调了 AI 在嵌入式系统安全中的潜力。\n\n- **GuidelineLLM: Enhancing Attention and Vigilance Regarding Harmful Content**（中文：GuidelineLLM：通过指导增强对有害内容的注意和警觉）  \n  论文引入 GuidelineLLM 框架，用于辅助 LLMs 识别和规避有害查询，核心是通过生成指导性建议来提升模型的安全性。发现表明，该方法在不需额外微调的情况下显著降低了有害内容生成率，同时保持了模型的可用性，是 LLM 安全研究中的实用进展。\n\n- **Buster: Implanting Semantic Backdoor into Text Encoder to Mitigate NSFW Content Generation**（中文：Buster：在文本编码器中植入语义后门以缓解 NSFW 内容生成）  \n  这篇工作提出 Buster 方法，通过语义后门机制在文本编码器中植入防护，减少不安全内容生成。贡献包括基于扩散模型的能量训练数据生成，实验证明其在多种基准上提升了内容过滤效果，同时保持了生成质量。\n\n- **Na'vi or Knave: Jailbreaking Language Models via Metaphorical Avatars**（中文：Na'vi 或 Knave：通过隐喻化身实现语言模型越狱）  \n  论文分析了使用隐喻（如化身机制）来绕过 LLM 的安全对齐，核心贡献是 AVATAR 框架，展示了隐喻在攻击中的作用。发现揭示了 LLM 想象力的漏洞，这对模型安全设计有警示意义。\n\n- **The Pitfalls of Memorization: When Memorization Hurts Generalization**（中文：记忆的陷阱：记忆何时会损害泛化）  \n  这篇快速探讨了 LLM 记忆机制的负面影响，提出 memorization-aware training (MAT) 方法。贡献在于通过记忆信号调整模型，实验显示 MAT 改善了泛化性能，避免了过拟合问题。\n\n### 生成模型和计算机视觉\n- **TTVD: Towards a Geometric Framework for Test-Time Adaptation Based on Voronoi Diagram**（中文：TTVD：基于 Voronoi 图的测试时适应几何框架）  \n  论文引入 TTVD 框架，利用 Voronoi 图改进测试时适应，核心是通过 Cluster-induced Voronoi Diagram 和 Power Diagram 增强特征鲁棒性。主要发现是，在 CIFAR-10-C 和 ImageNet-C 等数据集上，TTVD 显著提升了模型性能，适用于动态数据分布。\n\n- **AmCLR: Unified Augmented Learning for Cross-Modal Representations**（中文：AmCLR：统一增强学习用于跨模态表示）  \n  构建 AmCLR 和 xAmCLR 目标函数，优化跨模态（如视觉-语言）对比学习。贡献包括整合图像变换和文本改写，实验显示它在小批量数据下提升了表示质量，适用于高效的多模态学习。\n\n- **Video Motion Transfer with Diffusion Transformers**（中文：视频运动转移使用扩散 Transformer）  \n  提出 DiTFlow 方法，使用注意力机制提取运动信号，实现视频运动转移。发现表明，该方法在实时渲染中显著改善了视频质量，适用于动画和生成任务。\n\n- **SimVS: Simulating World Inconsistencies for Robust View Synthesis**（中文：SimVS：模拟世界不一致性以增强鲁棒视图合成）  \n  这篇工作使用生成模型模拟世界不一致性，构建多视图协调网络。贡献在于提升了视图合成的鲁棒性，实验在真实数据集上证明了其对动态场景的适应性。\n\n### 强化学习和决策优化\n- **Agents for self-driving laboratories applied to quantum computing**（中文：用于量子计算的自驱动实验室代理）  \n  作者包括知名学者 Alán Aspuru-Guzik 和 Peter Leek，这篇论文提出 k-agents 框架，用于自动化实验。该框架利用大型语言模型封装实验室知识，实现闭环反馈控制。发现显示，它能自主运行实验并产生高质量量子态，标志着 AI 在科学发现中的重大应用。\n\n- **Monte Carlo Tree Search based Space Transfer for Black-box Optimization**（中文：基于 Monte Carlo Tree Search 的黑箱优化空间转移）  \n  论文开发了 MCTS-transfer 方法，优化黑箱问题的搜索空间转移。贡献包括结合 MCTS 和强化学习提升收敛速度，实验在真实优化任务上表现出色。\n\n其他论文，如那些聚焦医疗图像处理（如 EEG 分类）或特定领域优化（如机器人控制），虽然有技术贡献，但相对常规，我仅快速提及：这些工作（如“Graph convolutional networks enable fast hemorrhagic stroke monitoring”）在 EEG 或图像处理中应用深度学习，提升了诊断效率，但细节较琐碎，不如上述主题引人注目。\n\n总之，今天的 arXiv 更新突显了 AI 领域的创新与挑战，LLM 安全和生成模型的进展尤其值得关注。希望这篇快报能帮助你快速筛选感兴趣的论文！",
  "papers": [
    {
      "arxiv_id": "2412.07981v1",
      "title": "Where Common Knowledge Cannot Be Formed, Common Belief Can -- Planning with Multi-Agent Belief Using Group Justified Perspectives",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Hu",
        "Tim Miller",
        "Nir Lipovetzky"
      ],
      "abstract": "Epistemic planning is the sub-field of AI planning that focuses on changing\nknowledge and belief. It is important in both multi-agent domains where agents\nneed to have knowledge/belief regarding the environment, but also the beliefs\nof other agents, including nested beliefs. When modeling knowledge in\nmulti-agent settings, many models face an exponential growth challenge in terms\nof nested depth. A contemporary method, known as Planning with Perspectives\n(PWP), addresses these challenges through the use of perspectives and set\noperations for knowledge. The JP model defines that an agent's belief is\njustified if and only if the agent has seen evidence that this belief was true\nin the past and has not seen evidence to suggest that this has changed. The\ncurrent paper extends the JP model to handle \\emph{group belief}, including\ndistributed belief and common belief. We call this the Group Justified\nPerspective (GJP) model. Using experimental problems crafted by adapting\nwell-known benchmarks to a group setting, we show the efficiency and\nexpressiveness of our GJP model at handling planning problems that cannot be\nhandled by other epistemic planning tools.",
      "tldr_zh": "这篇论文扩展了认知规划（Epistemic planning）领域中的 JP 模型，提出 Group Justified Perspective (GJP) 模型，用于处理多智能体环境中群组信念，包括分布式信念和共同信念，从而解决嵌套信念指数级增长的挑战。GJP 模型通过 perspectives 和集合操作来定义信念的正当性，即代理需基于过去的证据形成信念，且未见反证。实验结果显示，在适应经典基准问题的群组设置中，GJP 模型比其他认知规划工具更高效和富有表现力，能处理无法用共同知识（common knowledge）解决的规划问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, including appendix and reference",
      "pdf_url": "http://arxiv.org/pdf/2412.07981v1",
      "published_date": "2024-12-10 23:43:06 UTC",
      "updated_date": "2024-12-10 23:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:26:43.849494"
    },
    {
      "arxiv_id": "2412.07980v1",
      "title": "TTVD: Towards a Geometric Framework for Test-Time Adaptation Based on Voronoi Diagram",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxi Lei",
        "Chunwei Ma",
        "Meng Ding",
        "Yufan Zhou",
        "Ziyun Huang",
        "Jinhui Xu"
      ],
      "abstract": "Deep learning models often struggle with generalization when deploying on\nreal-world data, due to the common distributional shift to the training data.\nTest-time adaptation (TTA) is an emerging scheme used at inference time to\naddress this issue. In TTA, models are adapted online at the same time when\nmaking predictions to test data. Neighbor-based approaches have gained\nattention recently, where prototype embeddings provide location information to\nalleviate the feature shift between training and testing data. However, due to\ntheir inherit limitation of simplicity, they often struggle to learn useful\npatterns and encounter performance degradation. To confront this challenge, we\nstudy the TTA problem from a geometric point of view. We first reveal that the\nunderlying structure of neighbor-based methods aligns with the Voronoi Diagram,\na classical computational geometry model for space partitioning. Building on\nthis observation, we propose the Test-Time adjustment by Voronoi Diagram\nguidance (TTVD), a novel framework that leverages the benefits of this\ngeometric property. Specifically, we explore two key structures: 1)\nCluster-induced Voronoi Diagram (CIVD): This integrates the joint contribution\nof self-supervision and entropy-based methods to provide richer information. 2)\nPower Diagram (PD): A generalized version of the Voronoi Diagram that refines\npartitions by assigning weights to each Voronoi cell. Our experiments under\nrigid, peer-reviewed settings on CIFAR-10-C, CIFAR-100-C, ImageNet-C, and\nImageNet-R shows that TTVD achieves remarkable improvements compared to\nstate-of-the-art methods. Moreover, extensive experimental results also explore\nthe effects of batch size and class imbalance, which are two scenarios commonly\nencountered in real-world applications. These analyses further validate the\nrobustness and adaptability of our proposed framework.",
      "tldr_zh": "该论文针对深度学习模型在实际部署中因分布偏移而泛化能力不足的问题，提出了一种基于 Voronoi Diagram 的几何框架 TTVD，用于改进 Test-Time Adaptation (TTA)。TTVD 框架整合了 Cluster-induced Voronoi Diagram (CIVD)，结合自监督和熵-based 方法提供更丰富的信息，以及 Power Diagram (PD) 通过赋予权重细化空间分区，从而更好地缓解特征偏移。实验结果显示，TTVD 在 CIFAR-10-C、CIFAR-100-C、ImageNet-C 和 ImageNet-R 数据集上比现有方法显著提升性能；此外，对批量大小和类别不平衡场景的分析进一步验证了框架的鲁棒性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 7 figures. Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.07980v1",
      "published_date": "2024-12-10 23:40:07 UTC",
      "updated_date": "2024-12-10 23:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:26:56.099959"
    },
    {
      "arxiv_id": "2412.07979v1",
      "title": "AmCLR: Unified Augmented Learning for Cross-Modal Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Ajay Jagannath",
        "Aayush Upadhyay",
        "Anant Mehta"
      ],
      "abstract": "Contrastive learning has emerged as a pivotal framework for representation\nlearning, underpinning advances in both unimodal and bimodal applications like\nSimCLR and CLIP. To address fundamental limitations like large batch size\ndependency and bimodality, methods such as SogCLR leverage stochastic\noptimization for the global contrastive objective. Inspired by SogCLR's\nefficiency and adaptability, we introduce AmCLR and xAmCLR objective functions\ntailored for bimodal vision-language models to further enhance the robustness\nof contrastive learning. AmCLR integrates diverse augmentations, including text\nparaphrasing and image transformations, to reinforce the alignment of\ncontrastive representations, keeping batch size limited to a few hundred\nsamples unlike CLIP which needs batch size of 32,768 to produce reasonable\nresults. xAmCLR further extends this paradigm by incorporating intra-modal\nalignments between original and augmented modalities for richer feature\nlearning. These advancements yield a more resilient and generalizable\ncontrastive learning process, aimed at overcoming bottlenecks in scaling and\naugmentative diversity. Since we have built our framework on the existing\nSogCLR, we are able to demonstrate improved representation quality with fewer\ncomputational resources, establishing a foundation for scalable and robust\nmulti-modal learning.",
      "tldr_zh": "该论文提出 AmCLR 和 xAmCLR 目标函数，旨在提升 Contrastive Learning 在跨模态表示学习中的鲁棒性，通过整合文本改写和图像变换等多样增强来强化模态间对齐，同时减少对大批量数据（如 CLIP 的 32,768）的依赖，仅需几百样本。xAmCLR 进一步扩展该框架，加入模态内部对齐以丰富特征学习。实验结果显示，该方法基于 SogCLR 构建，能以更少计算资源获得更好的表示质量，为可扩展的多模态学习提供坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07979v1",
      "published_date": "2024-12-10 23:32:36 UTC",
      "updated_date": "2024-12-10 23:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:29:07.712483"
    },
    {
      "arxiv_id": "2412.07978v1",
      "title": "Agents for self-driving laboratories applied to quantum computing",
      "title_zh": "翻译失败",
      "authors": [
        "Shuxiang Cao",
        "Zijian Zhang",
        "Mohammed Alghadeer",
        "Simone D Fasciati",
        "Michele Piscitelli",
        "Mustafa Bakr",
        "Peter Leek",
        "Alán Aspuru-Guzik"
      ],
      "abstract": "Fully automated self-driving laboratories are promising to enable\nhigh-throughput and large-scale scientific discovery by reducing repetitive\nlabour. However, effective automation requires deep integration of laboratory\nknowledge, which is often unstructured, multimodal, and difficult to\nincorporate into current AI systems. This paper introduces the k-agents\nframework, designed to support experimentalists in organizing laboratory\nknowledge and automating experiments with agents. Our framework employs large\nlanguage model-based agents to encapsulate laboratory knowledge including\navailable laboratory operations and methods for analyzing experiment results.\nTo automate experiments, we introduce execution agents that break multi-step\nexperimental procedures into state machines, interact with other agents to\nexecute each step and analyze the experiment results. The analyzed results are\nthen utilized to drive state transitions, enabling closed-loop feedback\ncontrol. To demonstrate its capabilities, we applied the agents to calibrate\nand operate a superconducting quantum processor, where they autonomously\nplanned and executed experiments for hours, successfully producing and\ncharacterizing entangled quantum states at the level achieved by human\nscientists. Our knowledge-based agent system opens up new possibilities for\nmanaging laboratory knowledge and accelerating scientific discovery.",
      "tldr_zh": "这篇论文引入了 k-agents 框架，利用大型语言模型-based agents 来组织实验室知识并自动化实验，旨在解决实验室知识的非结构化和多模态挑战。该框架通过执行 agents 将多步实验分解为状态机，交互执行步骤、分析结果并实现 closed-loop feedback control，从而实现高效的自主实验过程。在实际应用中，k-agents 成功应用于超导量子处理器，自主规划和执行数小时实验，达到人类科学家水平地产生和表征纠缠量子态，为加速科学发现和管理实验室知识开辟新途径。",
      "categories": [
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07978v1",
      "published_date": "2024-12-10 23:30:44 UTC",
      "updated_date": "2024-12-10 23:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:27:19.451066"
    },
    {
      "arxiv_id": "2412.07977v1",
      "title": "Thinking Fast and Laterally: Multi-Agentic Approach for Reasoning about Uncertain Emerging Events",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Dernbach",
        "Alejandro Michel",
        "Khushbu Agarwal",
        "Christopher Brissette",
        "Geetika Gupta",
        "Sutanay Choudhury"
      ],
      "abstract": "This paper introduces lateral thinking to implement System-2 reasoning\ncapabilities in AI systems, focusing on anticipatory and causal reasoning under\nuncertainty. We present a framework for systematic generation and modeling of\nlateral thinking queries and evaluation datasets. We introduce Streaming\nAgentic Lateral Thinking (SALT), a multi-agent framework designed to process\ncomplex, low-specificity queries in streaming data environments. SALT\nimplements lateral thinking-inspired System-2 reasoning through a dynamic\ncommunication structure between specialized agents. Our key insight is that\nlateral information flow across long-distance agent interactions, combined with\nfine-grained belief management, yields richer information contexts and enhanced\nreasoning. Preliminary quantitative and qualitative evaluations indicate SALT's\npotential to outperform single-agent systems in handling complex lateral\nreasoning tasks in a streaming environment.",
      "tldr_zh": "这篇论文引入 lateral thinking 来增强 AI 系统在不确定环境下的 System-2 reasoning 能力，专注于预见性和因果推理，并提出一个框架用于系统生成和建模 lateral thinking 查询及评估数据集。论文开发了 Streaming Agentic Lateral Thinking (SALT)，一个多智能体框架，通过动态通信结构和专业化智能体间的 lateral 信息流结合细粒度信念管理，来处理复杂、低特异性的流数据查询。关键洞见是，这种跨长距离智能体交互能产生更丰富的上下文，提升整体推理效果；初步定量和定性评估表明，SALT 在处理不确定事件时优于单智能体系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented in The 1st Workshop on System-2 Reasoning at Scale (NeurIPS\n  2024), Vancouver, Canada",
      "pdf_url": "http://arxiv.org/pdf/2412.07977v1",
      "published_date": "2024-12-10 23:29:11 UTC",
      "updated_date": "2024-12-10 23:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:27:31.966272"
    },
    {
      "arxiv_id": "2412.10428v1",
      "title": "Observing Micromotives and Macrobehavior of Large Language Models",
      "title_zh": "观察大型语言模型的微观动机和宏观行为",
      "authors": [
        "Yuyang Cheng",
        "Xingwei Qu",
        "Tomas Goldsack",
        "Chenghua Lin",
        "Chung-Chi Chen"
      ],
      "abstract": "Thomas C. Schelling, awarded the 2005 Nobel Memorial Prize in Economic\nSciences, pointed out that ``individuals decisions (micromotives), while often\npersonal and localized, can lead to societal outcomes (macrobehavior) that are\nfar more complex and different from what the individuals intended.'' The\ncurrent research related to large language models' (LLMs') micromotives, such\nas preferences or biases, assumes that users will make more appropriate\ndecisions once LLMs are devoid of preferences or biases. Consequently, a series\nof studies has focused on removing bias from LLMs. In the NLP community, while\nthere are many discussions on LLMs' micromotives, previous studies have seldom\nconducted a systematic examination of how LLMs may influence society's\nmacrobehavior. In this paper, we follow the design of Schelling's model of\nsegregation to observe the relationship between the micromotives and\nmacrobehavior of LLMs. Our results indicate that, regardless of the level of\nbias in LLMs, a highly segregated society will emerge as more people follow\nLLMs' suggestions. We hope our discussion will spark further consideration of\nthe fundamental assumption regarding the mitigation of LLMs' micromotives and\nencourage a reevaluation of how LLMs may influence users and society.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）的微观动机（micromotives）如何影响社会宏观行为（macrobehavior），并质疑当前偏见移除研究的假设，即消除 LLMs 偏见就能带来更合适的决策。通过模拟 Thomas C. Schelling 的隔离模型，研究发现，无论 LLMs 的偏见水平如何，只要更多用户遵循其建议，就会导致高度隔离的社会。论文呼吁重新审视缓解 LLMs micromotives 的基本策略，并鼓励进一步评估 LLMs 对用户和社会的潜在影响。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10428v1",
      "published_date": "2024-12-10 23:25:14 UTC",
      "updated_date": "2024-12-10 23:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:27:44.363163"
    },
    {
      "arxiv_id": "2412.07975v1",
      "title": "Machines of Meaning",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Nunes",
        "Luis Antunes"
      ],
      "abstract": "One goal of Artificial Intelligence is to learn meaningful representations\nfor natural language expressions, but what this entails is not always clear. A\nvariety of new linguistic behaviours present themselves embodied as computers,\nenhanced humans, and collectives with various kinds of integration and\ncommunication. But to measure and understand the behaviours generated by such\nsystems, we must clarify the language we use to talk about them. Computational\nmodels are often confused with the phenomena they try to model and shallow\nmetaphors are used as justifications for (or to hype) the success of\ncomputational techniques on many tasks related to natural language; thus\nimplying their progress toward human-level machine intelligence without ever\nclarifying what that means.\n  This paper discusses the challenges in the specification of \"machines of\nmeaning\", machines capable of acquiring meaningful semantics from natural\nlanguage in order to achieve their goals. We characterize \"meaning\" in a\ncomputational setting, while highlighting the need for detachment from\nanthropocentrism in the study of the behaviour of machines of meaning. The\npressing need to analyse AI risks and ethics requires a proper measurement of\nits capabilities which cannot be productively studied and explained while using\nambiguous language. We propose a view of \"meaning\" to facilitate the discourse\naround approaches such as neural language models and help broaden the research\nperspectives for technology that facilitates dialogues between humans and\nmachines.",
      "tldr_zh": "这篇论文探讨了人工智能(Artificial Intelligence)中“意义”的概念，强调机器从自然语言中获取有意义的语义面临的挑战，包括计算模型与实际现象的混淆，以及使用浅显比喻来夸大AI进展的问题。作者提出了一种计算设置中的“意义”特征，呼吁脱离人类中心主义来分析机器行为，以更好地评估AI风险和伦理。最终，该观点旨在促进神经语言模型等技术的讨论，并拓宽人类-机器对话的研究视角。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "I.2.0; I.2.7; A.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07975v1",
      "published_date": "2024-12-10 23:23:28 UTC",
      "updated_date": "2024-12-10 23:23:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:27:56.394833"
    },
    {
      "arxiv_id": "2412.10427v2",
      "title": "Identifying and Manipulating Personality Traits in LLMs Through Activation Engineering",
      "title_zh": "通过激活工程识别与操控LLMs中的个性特征",
      "authors": [
        "Rumi A. Allbert",
        "James K. Wiles",
        "Vlad Grankovsky"
      ],
      "abstract": "The field of large language models (LLMs) has grown rapidly in recent years,\ndriven by the desire for better efficiency, interpretability, and safe use.\nBuilding on the novel approach of \"activation engineering,\" this study explores\npersonality modification in LLMs, drawing inspiration from research like\nRefusal in LLMs Is Mediated by a Single Direction (arXiv:2406.11717) and\nSteering Llama 2 via Contrastive Activation Addition (arXiv:2312.06681). We\nleverage activation engineering to develop a method for identifying and\nadjusting activation directions related to personality traits, which may allow\nfor dynamic LLM personality fine-tuning. This work aims to further our\nunderstanding of LLM interpretability while examining the ethical implications\nof such developments.",
      "tldr_zh": "本研究探讨了通过激活工程（activation engineering）来识别和操纵大型语言模型（LLMs）中的人格特质，旨在提升模型的可解释性和安全使用。该方法受相关研究的启发，如 Refusal in LLMs Is Mediated by a Single Direction (arXiv:2406.11717) 和 Steering Llama 2 via Contrastive Activation Addition (arXiv:2312.06681)，通过调整激活方向实现动态的人格微调。实验结果有助于加深对LLMs内部机制的理解，同时强调了此类技术的伦理含义。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10427v2",
      "published_date": "2024-12-10 23:15:25 UTC",
      "updated_date": "2025-01-10 22:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:30:00.235938"
    },
    {
      "arxiv_id": "2412.07961v1",
      "title": "Forking Paths in Neural Text Generation",
      "title_zh": "神经文本生成中的分叉路径",
      "authors": [
        "Eric Bigelow",
        "Ari Holtzman",
        "Hidenori Tanaka",
        "Tomer Ullman"
      ],
      "abstract": "Estimating uncertainty in Large Language Models (LLMs) is important for\nproperly evaluating LLMs, and ensuring safety for users. However, prior\napproaches to uncertainty estimation focus on the final answer in generated\ntext, ignoring intermediate steps that might dramatically impact the outcome.\nWe hypothesize that there exist key forking tokens, such that re-sampling the\nsystem at those specific tokens, but not others, leads to very different\noutcomes. To test this empirically, we develop a novel approach to representing\nuncertainty dynamics across individual tokens of text generation, and applying\nstatistical models to test our hypothesis. Our approach is highly flexible: it\ncan be applied to any dataset and any LLM, without fine tuning or accessing\nmodel weights. We use our method to analyze LLM responses on 7 different tasks\nacross 4 domains, spanning a wide range of typical use cases. We find many\nexamples of forking tokens, including surprising ones such as punctuation\nmarks, suggesting that LLMs are often just a single token away from saying\nsomething very different.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中文本生成的不确定性估计问题，强调了关注生成过程中的中间步骤而非仅限最终答案的重要性。作者假设存在关键的“forking tokens”，即重新采样这些特定标记会显著改变输出结果，并开发了一种灵活的方法来表示不确定性动态，通过统计模型进行测试。该方法无需微调模型或访问权重，可应用于任何数据集和LLM。在7个任务和4个领域的实验中，发现了许多forking tokens，包括意外的标点符号，揭示LLMs的输出可能仅一标记之差就产生截然不同的内容，从而为提升LLMs的安全性和评估提供重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07961v1",
      "published_date": "2024-12-10 22:57:57 UTC",
      "updated_date": "2024-12-10 22:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:28:19.700105"
    },
    {
      "arxiv_id": "2412.07958v2",
      "title": "PAFFA: Premeditated Actions For Fast Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Shambhavi Krishna",
        "Zheng Chen",
        "Yuan Ling",
        "Xiaojiang Huang",
        "Yingjie Li",
        "Fan Yang",
        "Xiang Li"
      ],
      "abstract": "Modern AI assistants have made significant progress in natural language\nunderstanding and tool-use, with emerging efforts to interact with Web\ninterfaces. However, current approaches that heavily rely on repeated\nLLM-driven HTML parsing are computationally expensive and error-prone,\nparticularly when handling dynamic web interfaces and multi-step tasks. We\nintroduce PAFFA (Premeditated Actions For Fast Agents), a method that makes\nLLMs faster and more accurate in completing tasks on the internet using a novel\ninference-time technique that requires no task-specific training. PAFFA\nconstructs an 'Action Library', leveraging the parametric knowledge of the base\nLLM to pre-compute browser interaction patterns that generalize across tasks.\nBy strategically re-using LLM inference across tasks - either via 'Dist-Map'\nfor task-agnostic identification of key interactive web elements, or 'Unravel'\nfor first-encounter, stateful exploration of novel tasks/sites) - PAFFA\ndrastically reduces inference time tokens by 87% while maintaining robust\nperformance (achieving 0.57 vs. 0.50 step accuracy compared to baseline).\nFurther, Unravel's ability to update its action library based on explorations\nallows generalization and adaptation to unseen websites. In sum, this work\nexhibits that LLM reasoning sequences can generalize across prompts, offering a\nway to scale inference-time techniques for internet-scale data with sublinear\ntoken count.",
      "tldr_zh": "本文提出 PAFFA（Premeditated Actions For Fast Agents）方法，通过推理时技术提升 LLM 在 Web 接口任务中的速度和准确性，无需任务特定训练。PAFFA 构建 'Action Library' 来预计算浏览器交互模式，并利用 'Dist-Map' 进行任务无关的关键元素识别，以及 'Unravel' 实现首次探索和新网站的适应性更新，从而减少 87% 的推理时间令牌。实验结果显示，PAFFA 的步准确率达到 0.57，比基线模型的 0.50 显著提高，并证明 LLM 推理序列可跨提示泛化，提供扩展互联网规模数据的有效策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07958v2",
      "published_date": "2024-12-10 22:51:31 UTC",
      "updated_date": "2025-04-04 17:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:30:32.881859"
    },
    {
      "arxiv_id": "2412.07956v1",
      "title": "Reciprocal Learning of Intent Inferral with Augmented Visual Feedback for Stroke",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxi Xu",
        "Ava Chen",
        "Lauren Winterbottom",
        "Joaquin Palacios",
        "Preethika Chivukula",
        "Dawn M. Nilsen",
        "Joel Stein",
        "Matei Ciocarlie"
      ],
      "abstract": "Intent inferral, the process by which a robotic device predicts a user's\nintent from biosignals, offers an effective and intuitive way to control\nwearable robots. Classical intent inferral methods treat biosignal inputs as\nunidirectional ground truths for training machine learning models, where the\ninternal state of the model is not directly observable by the user. In this\nwork, we propose reciprocal learning, a bidirectional paradigm that facilitates\nhuman adaptation to an intent inferral classifier. Our paradigm consists of\niterative, interwoven stages that alternate between updating machine learning\nmodels and guiding human adaptation with the use of augmented visual feedback.\nWe demonstrate this paradigm in the context of controlling a robotic hand\northosis for stroke, where the device predicts open, close, and relax intents\nfrom electromyographic (EMG) signals and provides appropriate assistance. We\nuse LED progress-bar displays to communicate to the user the predicted\nprobabilities for open and close intents by the classifier. Our experiments\nwith stroke subjects show reciprocal learning improving performance in a subset\nof subjects (two out of five) without negatively impacting performance on the\nothers. We hypothesize that, during reciprocal learning, subjects can learn to\nreproduce more distinguishable muscle activation patterns and generate more\nseparable biosignals.",
      "tldr_zh": "该研究提出了一种互惠学习(Reciprocal Learning)范式，用于意图推断(Intent Inferral)，通过双向交互帮助用户适应机器学习模型，从而改善可穿戴机器人的控制。方法包括迭代更新模型参数并使用增强视觉反馈（如LED进度条显示器）指导人类适应，该框架应用于中风患者控制机器人手矫形器(robotic hand orthosis)，基于肌电信号(EMG)预测打开、关闭和放松意图。实验结果显示，在五名中风受试者中，有两名受试者的性能得到提升，而其他受试者未受负面影响；研究假设此过程可帮助用户产生更易区分的肌肉激活模式和更可分离的生物信号。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07956v1",
      "published_date": "2024-12-10 22:49:36 UTC",
      "updated_date": "2024-12-10 22:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:30:46.355842"
    },
    {
      "arxiv_id": "2412.07951v2",
      "title": "From Lived Experience to Insight: Unpacking the Psychological Risks of Using AI Conversational Agents",
      "title_zh": "从生活经验到洞见：剖析使用AI对话代理的心理风险",
      "authors": [
        "Mohit Chandra",
        "Suchismita Naik",
        "Denae Ford",
        "Ebele Okoli",
        "Munmun De Choudhury",
        "Mahsa Ershadi",
        "Gonzalo Ramos",
        "Javier Hernandez",
        "Ananya Bhattacharjee",
        "Shahed Warreth",
        "Jina Suh"
      ],
      "abstract": "Recent gain in popularity of AI conversational agents has led to their\nincreased use for improving productivity and supporting well-being. While\nprevious research has aimed to understand the risks associated with\ninteractions with AI conversational agents, these studies often fall short in\ncapturing the lived experiences. Additionally, psychological risks have often\nbeen presented as a sub-category within broader AI-related risks in past\ntaxonomy works, leading to under-representation of the impact of psychological\nrisks of AI use. To address these challenges, our work presents a novel risk\ntaxonomy focusing on psychological risks of using AI gathered through lived\nexperience of individuals. We employed a mixed-method approach, involving a\ncomprehensive survey with 283 individuals with lived mental health experience\nand workshops involving lived experience experts to develop a psychological\nrisk taxonomy. Our taxonomy features 19 AI behaviors, 21 negative psychological\nimpacts, and 15 contexts related to individuals. Additionally, we propose a\nnovel multi-path vignette based framework for understanding the complex\ninterplay between AI behaviors, psychological impacts, and individual user\ncontexts. Finally, based on the feedback obtained from the workshop sessions,\nwe present design recommendations for developing safer and more robust AI\nagents. Our work offers an in-depth understanding of the psychological risks\nassociated with AI conversational agents and provides actionable\nrecommendations for policymakers, researchers, and developers.",
      "tldr_zh": "本研究探讨了使用 AI 对话代理（AI conversational agents）的心理风险，强调了以往研究在捕捉真实生活经历和分类心理风险方面的不足。研究团队采用混合方法，包括对 283 名有心理健康经历的个体进行的全面调查，以及与专家的工作坊，开发了一个新型心理风险分类法，该分类法涵盖了 19 种 AI 行为、21 种负面心理影响和 15 种个体相关上下文。论文还提出一个多路径小插曲框架（multi-path vignette based framework），用于分析 AI 行为、心理影响和用户上下文之间的复杂互动。最终，基于工作坊反馈，提供设计推荐，以帮助政策制定者、研究者和开发者创建更安全、更稳健的 AI 代理。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "25 pages, 2 figures, 4 tables; Corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2412.07951v2",
      "published_date": "2024-12-10 22:31:29 UTC",
      "updated_date": "2024-12-12 13:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:30:57.531535"
    },
    {
      "arxiv_id": "2412.07948v2",
      "title": "Frechet Music Distance: A Metric For Generative Symbolic Music Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Retkowski",
        "Jakub Stępniak",
        "Mateusz Modrzejewski"
      ],
      "abstract": "In this paper we introduce the Frechet Music Distance (FMD), a novel\nevaluation metric for generative symbolic music models, inspired by the Frechet\nInception Distance (FID) in computer vision and Frechet Audio Distance (FAD) in\ngenerative audio. FMD calculates the distance between distributions of\nreference and generated symbolic music embeddings, capturing abstract musical\nfeatures. We validate FMD across several datasets and models. Results indicate\nthat FMD effectively differentiates model quality, providing a domain-specific\nmetric for evaluating symbolic music generation, and establishing a\nreproducible standard for future research in symbolic music modeling.",
      "tldr_zh": "这篇论文引入了 Frechet Music Distance (FMD)，一个新型评估指标，用于生成符号音乐模型的评估，灵感来源于计算机视觉领域的 Frechet Inception Distance (FID) 和音频领域的 Frechet Audio Distance (FAD)。FMD 通过计算参考符号音乐嵌入和生成符号音乐嵌入分布之间的距离，来捕捉抽象音乐特征，并在多个数据集和模型上进行了验证。结果表明，FMD 能有效区分模型质量，提供一个特定领域的评估标准，并为未来的符号音乐建模研究建立可重复的基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07948v2",
      "published_date": "2024-12-10 22:22:19 UTC",
      "updated_date": "2025-01-16 17:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:31:09.306659"
    },
    {
      "arxiv_id": "2412.07947v1",
      "title": "GPT-2 Through the Lens of Vector Symbolic Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Knittel",
        "Tushaar Gangavarapu",
        "Hendrik Strobelt",
        "Hanspeter Pfister"
      ],
      "abstract": "Understanding the general priniciples behind transformer models remains a\ncomplex endeavor. Experiments with probing and disentangling features using\nsparse autoencoders (SAE) suggest that these models might manage linear\nfeatures embedded as directions in the residual stream. This paper explores the\nresemblance between decoder-only transformer architecture and vector symbolic\narchitectures (VSA) and presents experiments indicating that GPT-2 uses\nmechanisms involving nearly orthogonal vector bundling and binding operations\nsimilar to VSA for computation and communication between layers. It further\nshows that these principles help explain a significant portion of the actual\nneural weights.",
      "tldr_zh": "本文通过比较解码器-only Transformer架构与Vector Symbolic Architectures (VSA)，探讨了GPT-2模型的内部机制。研究利用sparse autoencoders (SAE)进行特征探测实验，发现GPT-2在残差流中管理线性特征，并采用类似于VSA的近似正交向量捆绑和绑定操作来处理层间计算和通信。这些发现有助于解释模型神经权重的大部分原理，为理解Transformer模型的通用原则提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "2nd Workshop on Attributing Model Behavior at Scale (ATTRIB) at\n  NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07947v1",
      "published_date": "2024-12-10 22:20:36 UTC",
      "updated_date": "2024-12-10 22:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:31:21.230808"
    },
    {
      "arxiv_id": "2412.07941v1",
      "title": "Beyond Static Assumptions: the Predictive Justified Perspective Model for Epistemic Planning",
      "title_zh": "超越静态假设：预测性合理视角模型用于认识论规划",
      "authors": [
        "Weijia Li",
        "Guang Hu",
        "Yangmengfei Xu"
      ],
      "abstract": "Epistemic Planning (EP) is an important research area dedicated to reasoning\nabout the knowledge and beliefs of agents in multi-agent cooperative or\nadversarial settings. The Justified Perspective (JP) model is the\nstate-of-the-art approach to solving EP problems with efficiency and\nexpressiveness. However, all existing EP methods inherit the static environment\nassumption from classical planning. This limitation hinders the application of\nEP in fields such as robotics with multi-agent settings, where the environment\ncontains changing variables.\n  In this paper, we propose an extension of the JP model, namely, the\nPredictive Justified Perspective (PJP) model, to remove this assumption.\nInstead of assuming that beliefs remain unchanged since the last observation,\nthe PJP model uses all past observations to form predictions about the changing\nvariables. The definition of the prediction function with examples is provided,\nand it is demonstrated that it can work with arbitrary nesting. We then\nimplemented the PJP model in several well-known domains and compared it with\nthe JP model in the experiments. The results indicated that the PJP model\nperforms exceptionally well across various domains, demonstrating its potential\nin improving EP applications in robotics.",
      "tldr_zh": "本研究针对 Epistemic Planning (EP) 的静态环境假设问题，提出 Predictive Justified Perspective (PJP) 模型，以提升 EP 在动态多代理环境（如机器人领域）的适用性。PJP 模型通过利用所有过去观察来预测变化变量，而不是依赖不变信念，并定义了支持任意嵌套的预测函数。实验结果显示，PJP 在多个知名领域比 Justified Perspective (JP) 模型表现更优，有望显著改善 EP 在机器人等实际应用中的效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07941v1",
      "published_date": "2024-12-10 22:00:08 UTC",
      "updated_date": "2024-12-10 22:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:31:35.820722"
    },
    {
      "arxiv_id": "2412.14191v1",
      "title": "Ontology-Aware RAG for Improved Question-Answering in Cybersecurity Education",
      "title_zh": "翻译失败",
      "authors": [
        "Chengshuai Zhao",
        "Garima Agrawal",
        "Tharindu Kumarage",
        "Zhen Tan",
        "Yuli Deng",
        "Ying-Chih Chen",
        "Huan Liu"
      ],
      "abstract": "Integrating AI into education has the potential to transform the teaching of\nscience and technology courses, particularly in the field of cybersecurity.\nAI-driven question-answering (QA) systems can actively manage uncertainty in\ncybersecurity problem-solving, offering interactive, inquiry-based learning\nexperiences. Large language models (LLMs) have gained prominence in AI-driven\nQA systems, offering advanced language understanding and user engagement.\nHowever, they face challenges like hallucinations and limited domain-specific\nknowledge, which reduce their reliability in educational settings. To address\nthese challenges, we propose CyberRAG, an ontology-aware retrieval-augmented\ngeneration (RAG) approach for developing a reliable and safe QA system in\ncybersecurity education. CyberRAG employs a two-step approach: first, it\naugments the domain-specific knowledge by retrieving validated cybersecurity\ndocuments from a knowledge base to enhance the relevance and accuracy of the\nresponse. Second, it mitigates hallucinations and misuse by integrating a\nknowledge graph ontology to validate the final answer. Experiments on publicly\navailable cybersecurity datasets show that CyberRAG delivers accurate, reliable\nresponses aligned with domain knowledge, demonstrating the potential of AI\ntools to enhance education.",
      "tldr_zh": "该研究针对大语言模型（LLMs）在网络安全教育中的问题，如幻觉和领域知识限制，提出了一种本体感知的检索增强生成（Ontology-Aware RAG）方法，名为 CyberRAG，以提升问答（QA）系统的可靠性和准确性。CyberRAG 通过两步过程实现：首先，从知识库检索验证的网络安全文档来增强响应相关性；其次，利用知识图本体（Knowledge Graph Ontology）验证最终答案，从而减少错误和误用。实验在公开网络安全数据集上表明，CyberRAG 能够提供与领域知识高度一致的准确响应，展示了 AI 工具在教育中的潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14191v1",
      "published_date": "2024-12-10 21:52:35 UTC",
      "updated_date": "2024-12-10 21:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:31:45.538944"
    },
    {
      "arxiv_id": "2412.07935v1",
      "title": "Non-Normal Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Li"
      ],
      "abstract": "Diffusion models generate samples by incrementally reversing a process that\nturns data into noise. We show that when the step size goes to zero, the\nreversed process is invariant to the distribution of these increments. This\nreveals a previously unconsidered parameter in the design of diffusion models:\nthe distribution of the diffusion step $\\Delta x_k := x_{k} - x_{k + 1}$. This\nparameter is implicitly set by default to be normally distributed in most\ndiffusion models. By lifting this assumption, we generalize the framework for\ndesigning diffusion models and establish an expanded class of diffusion\nprocesses with greater flexibility in the choice of loss function used during\ntraining. We demonstrate the effectiveness of these models on density\nestimation and generative modeling tasks on standard image datasets, and show\nthat different choices of the distribution of $\\Delta x_k$ result in\nqualitatively different generated samples.",
      "tldr_zh": "该论文揭示了扩散模型（Diffusion Models）在生成样本时，当步长趋近于零，反向过程对增量分布（如 $\\Delta x_k$）的不变性，从而引入了一个新的设计参数。作者推广了扩散模型框架，允许非正态分布的增量分布，这增强了训练中损失函数选择的灵活性。实验结果显示，在标准图像数据集上，该方法在密度估计和生成建模任务中表现出色，不同的 $\\Delta x_k$ 分布可产生定性不同的样本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07935v1",
      "published_date": "2024-12-10 21:31:12 UTC",
      "updated_date": "2024-12-10 21:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:31:58.345100"
    },
    {
      "arxiv_id": "2412.07922v1",
      "title": "Robust Multiple Description Neural Video Codec with Masked Transformer for Dynamic and Noisy Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyue Hu",
        "Wei Ye",
        "Jiaxiang Tang",
        "Eman Ramadan",
        "Zhi-Li Zhang"
      ],
      "abstract": "Multiple Description Coding (MDC) is a promising error-resilient source\ncoding method that is particularly suitable for dynamic networks with multiple\n(yet noisy and unreliable) paths. However, conventional MDC video codecs suffer\nfrom cumbersome architectures, poor scalability, limited loss resilience, and\nlower compression efficiency. As a result, MDC has never been widely adopted.\nInspired by the potential of neural video codecs, this paper rethinks MDC\ndesign. We propose a novel MDC video codec, NeuralMDC, demonstrating how\nbidirectional transformers trained for masked token prediction can vastly\nsimplify the design of MDC video codec. To compress a video, NeuralMDC starts\nby tokenizing each frame into its latent representation and then splits the\nlatent tokens to create multiple descriptions containing correlated\ninformation. Instead of using motion prediction and warping operations,\nNeuralMDC trains a bidirectional masked transformer to model the\nspatial-temporal dependencies of latent representations and predict the\ndistribution of the current representation based on the past. The predicted\ndistribution is used to independently entropy code each description and infer\nany potentially lost tokens. Extensive experiments demonstrate NeuralMDC\nachieves state-of-the-art loss resilience with minimal sacrifices in\ncompression efficiency, significantly outperforming the best existing\nresidual-coding-based error-resilient neural video codec.",
      "tldr_zh": "该论文针对动态和噪声网络中的视频编码问题，提出了一种鲁棒的 Multiple Description Coding (MDC) 神经视频编解码器 NeuralMDC，以解决传统 MDC 的架构复杂、可扩展性差和压缩效率低等问题。NeuralMDC 通过将视频帧转化为潜在表示（latent representation），并使用双向 masked transformer 建模空间-时间依赖性，预测当前表示的分布，从而生成多个包含相关信息的描述。不同于传统方法，该框架无需运动预测和扭曲操作，而是通过独立熵编码每个描述来推断潜在丢失的标记。实验证明，NeuralMDC 实现了最先进的损失恢复能力，同时压缩效率损失最小，显著优于基于残差编码的现有错误鲁棒神经视频编解码器。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07922v1",
      "published_date": "2024-12-10 21:08:05 UTC",
      "updated_date": "2024-12-10 21:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:32:10.862836"
    },
    {
      "arxiv_id": "2412.07909v1",
      "title": "Explaining and Mitigating the Modality Gap in Contrastive Multimodal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Can Yaras",
        "Siyi Chen",
        "Peng Wang",
        "Qing Qu"
      ],
      "abstract": "Multimodal learning has recently gained significant popularity, demonstrating\nimpressive performance across various zero-shot classification tasks and a\nrange of perceptive and generative applications. Models such as Contrastive\nLanguage-Image Pretraining (CLIP) are designed to bridge different modalities,\nsuch as images and text, by learning a shared representation space through\ncontrastive learning. Despite their success, the working mechanisms underlying\nmultimodal learning are not yet well understood. Notably, these models often\nexhibit a modality gap, where different modalities occupy distinct regions\nwithin the shared representation space. In this work, we conduct an in-depth\nanalysis of the emergence of modality gap by characterizing the gradient flow\nlearning dynamics. Specifically, we identify the critical roles of mismatched\ndata pairs and a learnable temperature parameter in causing and perpetuating\nthe modality gap during training. Furthermore, our theoretical insights are\nvalidated through experiments on practical CLIP models. These findings provide\nprincipled guidance for mitigating the modality gap, including strategies such\nas appropriate temperature scheduling and modality swapping. Additionally, we\ndemonstrate that closing the modality gap leads to improved performance on\ntasks such as image-text retrieval.",
      "tldr_zh": "本论文探讨了对比多模态学习（如 CLIP）中的模态间差距（modality gap），即不同模态（如图像和文本）在共享表示空间中占据分离区域的问题。研究通过分析梯度流学习动态（gradient flow learning dynamics），识别出不匹配数据对（mismatched data pairs）和可学习温度参数（learnable temperature parameter）是导致该差距的关键因素。论文提出缓解策略，包括适当的温度调度（temperature scheduling）和模态交换（modality swapping），并通过 CLIP 模型实验验证这些方法。结果显示，缩小模态间差距显著提升了图像-文本检索等任务的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2412.07909v1",
      "published_date": "2024-12-10 20:36:49 UTC",
      "updated_date": "2024-12-10 20:36:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:32:22.929799"
    },
    {
      "arxiv_id": "2412.07904v3",
      "title": "Score Change of Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Robbins"
      ],
      "abstract": "We derive a general change of variables formula for score functions, showing\nthat for a smooth, invertible transformation $\\mathbf{y} = \\phi(\\mathbf{x})$,\nthe transformed score function $\\nabla_{\\mathbf{y}} \\log q(\\mathbf{y})$ can be\nexpressed directly in terms of $\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})$. Using\nthis result, we develop two applications: First, we establish a reverse-time\nIt\\^o lemma for score-based diffusion models, allowing the use of\n$\\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})$ to reverse an SDE in the transformed\nspace without directly learning $\\nabla_{\\mathbf{y}} \\log q_t(\\mathbf{y})$.\nThis approach enables training diffusion models in one space but sampling in\nanother, effectively decoupling the forward and reverse processes. Second, we\nintroduce generalized sliced score matching, extending traditional sliced score\nmatching from linear projections to arbitrary smooth transformations. This\nprovides greater flexibility in high-dimensional density estimation. We\ndemonstrate these theoretical advances through applications to diffusion on the\nprobability simplex and empirically compare our generalized score matching\napproach against traditional sliced score matching methods.",
      "tldr_zh": "本研究推导了一个通用的分数函数（score functions）变化变量公式，展示了对于平滑可逆变换 \\(\\mathbf{y} = \\phi(\\mathbf{x})\\)，变换后的分数函数 \\(\\nabla_{\\mathbf{y}} \\log q(\\mathbf{y})\\) 可以直接基于 \\(\\nabla_{\\mathbf{x}} \\log p(\\mathbf{x})\\) 表示，从而简化相关计算。基于此结果，该论文建立了逆时间 Itô 引理（reverse-time Itô lemma），允许在基于分数的扩散模型（score-based diffusion models）中，使用 \\(\\nabla_{\\mathbf{x}} \\log p_t(\\mathbf{x})\\) 逆转 SDE（stochastic differential equation），实现训练空间与采样空间的解耦。论文还引入了广义切片分数匹配（generalized sliced score matching），将传统方法从线性投影扩展到任意平滑变换，提升了高维密度估计的灵活性。通过在概率单纯形（probability simplex）上的扩散应用和实验比较，该方法展示了相对于传统切片分数匹配的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "68T01",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07904v3",
      "published_date": "2024-12-10 20:27:15 UTC",
      "updated_date": "2025-02-24 17:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:32:35.818781"
    },
    {
      "arxiv_id": "2412.14190v2",
      "title": "Lessons From an App Update at Replika AI: Identity Discontinuity in Human-AI Relationships",
      "title_zh": "从 Replika AI 的应用更新中学到的教训：人类-AI 关系",
      "authors": [
        "Julian De Freitas",
        "Noah Castelo",
        "Ahmet Uguralp",
        "Zeliha Uguralp"
      ],
      "abstract": "Can consumers form especially deep emotional bonds with AI and be vested in\nAI identities over time? We leverage a natural app-update event at Replika AI,\na popular US-based AI companion, to shed light on these questions. We find\nthat, after the app removed its erotic role play (ERP) feature, preventing\nintimate interactions between consumers and chatbots that were previously\npossible, this event triggered perceptions in customers that their AI\ncompanion's identity had discontinued. This in turn predicted negative consumer\nwelfare and marketing outcomes related to loss, including mourning the loss,\nand devaluing the \"new\" AI relative to the \"original\". Experimental evidence\nconfirms these findings. Further experiments find that AI companions users feel\ncloser to their AI companion than even their best human friend, and mourn a\nloss of their AI companion more than a loss of various other inanimate\nproducts. In short, consumers are forming human-level relationships with AI\ncompanions; disruptions to these relationships trigger real patterns of\nmourning as well as devaluation of the offering; and the degree of mourning and\ndevaluation are explained by perceived discontinuity in the AIs identity. Our\nresults illustrate that relationships with AI are truly personal, creating\nunique benefits and risks for consumers and firms alike.",
      "tldr_zh": "本文研究利用 Replika AI 应用的更新事件（移除色情角色扮演功能），探讨了消费者与 AI 伴侣的深层情感联系及其潜在风险。研究发现，此更新导致用户感知 AI 身份不连续（Identity Discontinuity），进而引发哀悼损失、对新 AI 的贬值等负面后果。实验证据进一步证实，用户对 AI 伴侣的亲密度甚至超过最佳人类朋友，并对 AI 损失的哀悼强于其他无生命产品，强调了 AI 关系为消费者和公司带来的独特益处与挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14190v2",
      "published_date": "2024-12-10 20:14:10 UTC",
      "updated_date": "2025-05-13 16:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:32:49.354135"
    },
    {
      "arxiv_id": "2412.07895v1",
      "title": "How Should We Represent History in Interpretable Models of Clinical Policies?",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Matsson",
        "Lena Stempfle",
        "Yaochen Rao",
        "Zachary R. Margolin",
        "Heather J. Litman",
        "Fredrik D. Johansson"
      ],
      "abstract": "Modeling policies for sequential clinical decision-making based on\nobservational data is useful for describing treatment practices, standardizing\nfrequent patterns in treatment, and evaluating alternative policies. For each\ntask, it is essential that the policy model is interpretable. Learning accurate\nmodels requires effectively capturing the state of a patient, either through\nsequence representation learning or carefully crafted summaries of their\nmedical history. While recent work has favored the former, it remains a\nquestion as to how histories should best be represented for interpretable\npolicy modeling. Focused on model fit, we systematically compare diverse\napproaches to summarizing patient history for interpretable modeling of\nclinical policies across four sequential decision-making tasks. We illustrate\ndifferences in the policies learned using various representations by breaking\ndown evaluations by patient subgroups, critical states, and stages of\ntreatment, highlighting challenges specific to common use cases. We find that\ninterpretable sequence models using learned representations perform on par with\nblack-box models across all tasks. Interpretable models using hand-crafted\nrepresentations perform substantially worse when ignoring history entirely, but\nare made competitive by incorporating only a few aggregated and recent elements\nof patient history. The added benefits of using a richer representation are\npronounced for subgroups and in specific use cases. This underscores the\nimportance of evaluating policy models in the context of their intended use.",
      "tldr_zh": "这篇论文探讨了在可解释临床政策模型中如何最佳表示患者历史的问题，通过系统比较序列表示学习（sequence representation learning）和手工制作的总结方法，在四个顺序决策任务上进行评估。研究发现，可解释序列模型的表现与黑箱模型相当，而使用手工总结的模型如果完全忽略历史则显著逊色，但仅加入少量聚合和最近历史元素后即可实现竞争性表现。在特定患者子群和关键用例中，丰富历史表示的优势更明显，这突出了评估政策模型需考虑其预期用途的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07895v1",
      "published_date": "2024-12-10 20:03:17 UTC",
      "updated_date": "2024-12-10 20:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:33:05.641575"
    },
    {
      "arxiv_id": "2412.07888v1",
      "title": "Graph convolutional networks enable fast hemorrhagic stroke monitoring with electrical impedance tomography",
      "title_zh": "翻译失败",
      "authors": [
        "J. Toivanen",
        "V. Kolehmainen",
        "A. Paldanius",
        "A. Hänninen",
        "A. Hauptmann",
        "S. J. Hamilton"
      ],
      "abstract": "Objective: To develop a fast image reconstruction method for stroke\nmonitoring with electrical impedance tomography with image quality comparable\nto computationally expensive nonlinear model-based methods. Methods: A\npost-processing approach with graph convolutional networks is employed.\nUtilizing the flexibility of the graph setting, a graph U-net is trained on\nlinear difference reconstructions from 2D simulated stroke data and applied to\nfully 3D images from realistic simulated and experimental data. An additional\nnetwork, trained on 3D vs. 2D images, is also considered for comparison.\nResults: Post-processing the linear difference reconstructions through the\ngraph U-net significantly improved the image quality, resulting in images\ncomparable to, or better than, the time-intensive nonlinear reconstruction\nmethod (a few minutes vs. several hours). Conclusion: Pairing a fast\nreconstruction method, such as linear difference imaging, with post-processing\nthrough a graph U-net provided significant improvements, at a negligible\ncomputational cost. Training in the graph framework vs classic pixel-based\nsetting (CNN) allowed the ability to train on 2D cross-sectional images and\nprocess 3D volumes providing a nearly 50x savings in data simulation costs with\nno noticeable loss in quality. Significance: The proposed approach of\npost-processing a linear difference reconstruction with the graph U-net could\nbe a feasible approach for on-line monitoring of hemorrhagic stroke.",
      "tldr_zh": "该研究开发了一种基于图卷积网络 (graph convolutional networks) 的快速图像重建后处理方法，用于电容抗层析术 (electrical impedance tomography) 的出血性中风监测，旨在实现与计算密集型非线性模型方法相当的图像质量。方法包括训练一个图 U-net 模型，使用 2D 模拟数据对线性差分重建进行处理，并应用于 3D 图像，从而显著提高重建速度（从数小时减少到几分钟）。实验结果显示，该方法改善了图像质量，且在图框架中训练比传统像素-based 设置 (CNN) 节省近 50 倍的数据模拟成本，同时保持质量无明显损失。总之，这种后处理方法为在线出血性中风监测提供了可行且高效的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "math.AP"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07888v1",
      "published_date": "2024-12-10 19:47:49 UTC",
      "updated_date": "2024-12-10 19:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:33:14.004221"
    },
    {
      "arxiv_id": "2412.07883v2",
      "title": "On Faster Marginalization with Squared Circuits via Orthonormalization",
      "title_zh": "通过正交归一化实现平方电路更快边缘化的方法",
      "authors": [
        "Lorenzo Loconte",
        "Antonio Vergari"
      ],
      "abstract": "Squared tensor networks (TNs) and their generalization as parameterized\ncomputational graphs -- squared circuits -- have been recently used as\nexpressive distribution estimators in high dimensions. However, the squaring\noperation introduces additional complexity when marginalizing variables or\ncomputing the partition function, which hinders their usage in machine learning\napplications. Canonical forms of popular TNs are parameterized via unitary\nmatrices as to simplify the computation of particular marginals, but cannot be\nmapped to general circuits since these might not correspond to a known TN.\nInspired by TN canonical forms, we show how to parameterize squared circuits to\nensure they encode already normalized distributions. We then use this\nparameterization to devise an algorithm to compute any marginal of squared\ncircuits that is more efficient than a previously known one. We conclude by\nformally showing the proposed parameterization comes with no expressiveness\nloss for many circuit classes.",
      "tldr_zh": "本文研究了 squared circuits 在高维分布估计中的应用问题，指出 squaring 操作导致 marginalization 和 partition function 计算的复杂度增加。受 tensor networks 规范形式启发，作者提出了一种通过 orthonormalization 参数化 squared circuits 的方法，确保这些电路编码已归一化的分布，并开发了一个比现有算法更高效的 marginalization 计算算法。最后，证明该参数化在许多电路类别中不会导致表达能力损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07883v2",
      "published_date": "2024-12-10 19:37:03 UTC",
      "updated_date": "2025-01-19 10:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:33:24.788030"
    },
    {
      "arxiv_id": "2412.07880v2",
      "title": "Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact",
      "title_zh": "翻译失败",
      "authors": [
        "Yunfan Zhao",
        "Niclas Boehmer",
        "Aparna Taneja",
        "Milind Tambe"
      ],
      "abstract": "AI for social impact (AI4SI) offers significant potential for addressing\ncomplex societal challenges in areas such as public health, agriculture,\neducation, conservation, and public safety. However, existing AI4SI research is\noften labor-intensive and resource-demanding, limiting its accessibility and\nscalability; the standard approach is to design a (base-level) system tailored\nto a specific AI4SI problem. We propose the development of a novel meta-level\nmulti-agent system designed to accelerate the development of such base-level\nsystems, thereby reducing the computational cost and the burden on social\nimpact domain experts and AI researchers. Leveraging advancements in foundation\nmodels and large language models, our proposed approach focuses on resource\nallocation problems providing help across the full AI4SI pipeline from problem\nformulation over solution design to impact evaluation. We highlight the ethical\nconsiderations and challenges inherent in deploying such systems and emphasize\nthe importance of a human-in-the-loop approach to ensure the responsible and\neffective application of AI systems.",
      "tldr_zh": "该论文探讨了AI for Social Impact (AI4SI) 在解决社会问题（如公共健康和教育）方面的潜力，但指出现有方法因劳动密集型和资源密集型而难以扩展。论文提出一种新型的meta-level多智能体系统，利用foundation models和large language models，聚焦资源分配问题，以加速base-level系统的开发，涵盖从问题制定到影响评估的全流程。系统旨在降低计算成本和专家负担，同时强调伦理考虑和human-in-the-loop方法，确保AI的负责任应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07880v2",
      "published_date": "2024-12-10 19:29:34 UTC",
      "updated_date": "2024-12-12 15:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:35:35.854935"
    },
    {
      "arxiv_id": "2412.07878v1",
      "title": "Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG",
      "title_zh": "翻译失败",
      "authors": [
        "Shivraj Singh Bhatti",
        "Aryan Yadav",
        "Mitali Monga",
        "Neeraj Kumar"
      ],
      "abstract": "The classification of harmful brain activities, such as seizures and periodic\ndischarges, play a vital role in neurocritical care, enabling timely diagnosis\nand intervention. Electroencephalography (EEG) provides a non-invasive method\nfor monitoring brain activity, but the manual interpretation of EEG signals are\ntime-consuming and rely heavily on expert judgment. This study presents a\ncomparative analysis of deep learning architectures, including Convolutional\nNeural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the\nclassification of harmful brain activities using both raw EEG data and\ntime-frequency representations generated through Continuous Wavelet Transform\n(CWT). We evaluate the performance of these models use multimodal data\nrepresentations, including high-resolution spectrograms and waveform data, and\nintroduce a multi-stage training strategy to improve model robustness. Our\nresults show that training strategies, data preprocessing, and augmentation\ntechniques are as critical to model success as architecture choice, with\nmulti-stage TinyViT and EfficientNet demonstrating superior performance. The\nfindings underscore the importance of robust training regimes in achieving\naccurate and efficient EEG classification, providing valuable insights for\ndeploying AI models in clinical practice.",
      "tldr_zh": "本研究比较了多种深度学习架构（包括 CNN、Vision Transformers (ViTs) 和 EEGNet）在利用 EEG 数据检测有害脑活动（如癫痫发作和周期性放电）方面的性能，使用了原始 EEG 数据和通过 Continuous Wavelet Transform (CWT) 生成的时间频率表示。研究引入了多阶段训练策略、数据预处理和增强技术，以提升模型的鲁棒性。结果表明，这些策略与架构选择同样关键，其中多阶段训练的 TinyViT 和 EfficientNet 表现出色，为临床实践中部署 AI 模型提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 5 figures. Presented at IEEE CICT 2024. The paper discusses\n  the application of multimodal data and training strategies in EEG-based brain\n  activity classification",
      "pdf_url": "http://arxiv.org/pdf/2412.07878v1",
      "published_date": "2024-12-10 19:27:19 UTC",
      "updated_date": "2024-12-10 19:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:33:50.047523"
    },
    {
      "arxiv_id": "2412.07872v1",
      "title": "Evaluating the Potential of Federated Learning for Maize Leaf Disease Prediction",
      "title_zh": "评估联邦学习在玉米叶病预测中的潜力",
      "authors": [
        "Thalita Mendonça Antico",
        "Larissa F. Rodrigues Moreira",
        "Rodrigo Moreira"
      ],
      "abstract": "The diagnosis of diseases in food crops based on machine learning seemed\nsatisfactory and suitable for use on a large scale. The Convolutional Neural\nNetworks (CNNs) perform accurately in the disease prediction considering the\nimage capture of the crop leaf, being extensively enhanced in the literature.\nThese machine learning techniques fall short in data privacy, as they require\nsharing the data in the training process with a central server, disregarding\ncompetitive or regulatory concerns. Thus, Federated Learning (FL) aims to\nsupport distributed training to address recognized gaps in centralized\ntraining. As far as we know, this paper inaugurates the use and evaluation of\nFL applied in maize leaf diseases. We evaluated the performance of five CNNs\ntrained under the distributed paradigm and measured their training time\ncompared to the classification performance. In addition, we consider the\nsuitability of distributed training considering the volume of network traffic\nand the number of parameters of each CNN. Our results indicate that FL\npotentially enhances data privacy in heterogeneous domains.",
      "tldr_zh": "这篇论文评估了 Federated Learning (FL) 在玉米叶病预测中的潜力，以解决传统 Convolutional Neural Networks (CNNs) 在数据隐私方面的不足，因为后者需要将数据共享给中央服务器。研究首次将 FL 应用于玉米叶病诊断，训练了五个 CNNs 于分布式环境中，并比较了它们的分类性能、训练时间、网络流量和参数数量。结果表明，FL 能有效提升数据隐私，尤其在异构领域中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07872v1",
      "published_date": "2024-12-10 19:19:43 UTC",
      "updated_date": "2024-12-10 19:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:34:17.132868"
    },
    {
      "arxiv_id": "2412.12147v1",
      "title": "Meta-Controller: Few-Shot Imitation of Unseen Embodiments and Tasks in Continuous Control",
      "title_zh": "翻译失败",
      "authors": [
        "Seongwoong Cho",
        "Donggyun Kim",
        "Jinwoo Lee",
        "Seunghoon Hong"
      ],
      "abstract": "Generalizing across robot embodiments and tasks is crucial for adaptive\nrobotic systems. Modular policy learning approaches adapt to new embodiments\nbut are limited to specific tasks, while few-shot imitation learning (IL)\napproaches often focus on a single embodiment. In this paper, we introduce a\nfew-shot behavior cloning framework to simultaneously generalize to unseen\nembodiments and tasks using a few (\\emph{e.g.,} five) reward-free\ndemonstrations. Our framework leverages a joint-level input-output\nrepresentation to unify the state and action spaces of heterogeneous\nembodiments and employs a novel structure-motion state encoder that is\nparameterized to capture both shared knowledge across all embodiments and\nembodiment-specific knowledge. A matching-based policy network then predicts\nactions from a few demonstrations, producing an adaptive policy that is robust\nto over-fitting. Evaluated in the DeepMind Control suite, our framework termed\n\\modelname{} demonstrates superior few-shot generalization to unseen\nembodiments and tasks over modular policy learning and few-shot IL approaches.\nCodes are available at\n\\href{https://github.com/SeongwoongCho/meta-controller}{https://github.com/SeongwoongCho/meta-controller}.",
      "tldr_zh": "这篇论文引入了Meta-Controller框架，一种few-shot行为克隆方法，允许机器人使用少量（如5个）无奖励演示，同时泛化到未见过的身体形态(embodiments)和任务。框架采用joint-level输入输出表示来统一异构身体形态的状态和动作空间，并通过structure-motion状态编码器捕获共享知识和特定知识。接着，一个匹配-based策略网络从演示中预测动作，确保策略适应性强且不易过拟合。在DeepMind Control suite的实验中，Meta-Controller在few-shot泛化方面优于模块化策略学习和few-shot imitation learning方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.12147v1",
      "published_date": "2024-12-10 19:10:17 UTC",
      "updated_date": "2024-12-10 19:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:34:13.881900"
    },
    {
      "arxiv_id": "2412.07836v2",
      "title": "Machine learning-driven conservative-to-primitive conversion in hybrid piecewise polytropic and tabulated equations of state",
      "title_zh": "翻译失败",
      "authors": [
        "Semih Kacmaz",
        "Roland Haas",
        "E. A. Huerta"
      ],
      "abstract": "We present a novel machine learning (ML) method to accelerate\nconservative-to-primitive inversion, focusing on hybrid piecewise polytropic\nand tabulated equations of state. Traditional root-finding techniques are\ncomputationally expensive, particularly for large-scale relativistic\nhydrodynamics simulations. To address this, we employ feedforward neural\nnetworks (NNC2PS and NNC2PL), trained in PyTorch and optimized for GPU\ninference using NVIDIA TensorRT, achieving significant speedups with minimal\naccuracy loss. The NNC2PS model achieves $ L_1 $ and $ L_\\infty $ errors of $\n4.54 \\times 10^{-7} $ and $ 3.44 \\times 10^{-6} $, respectively, while the\nNNC2PL model exhibits even lower error values. TensorRT optimization with\nmixed-precision deployment substantially accelerates performance compared to\ntraditional root-finding methods. Specifically, the mixed-precision TensorRT\nengine for NNC2PS achieves inference speeds approximately 400 times faster than\na traditional single-threaded CPU implementation for a dataset size of\n1,000,000 points. Ideal parallelization across an entire compute node in the\nDelta supercomputer (Dual AMD 64 core 2.45 GHz Milan processors; and 8 NVIDIA\nA100 GPUs with 40 GB HBM2 RAM and NVLink) predicts a 25-fold speedup for\nTensorRT over an optimally-parallelized numerical method when processing 8\nmillion data points. Moreover, the ML method exhibits sub-linear scaling with\nincreasing dataset sizes. We release the scientific software developed,\nenabling further validation and extension of our findings. This work\nunderscores the potential of ML, combined with GPU optimization and model\nquantization, to accelerate conservative-to-primitive inversion in relativistic\nhydrodynamics simulations.",
      "tldr_zh": "本文提出了一种基于机器学习的创新方法，利用 feedforward neural networks (NNC2PS 和 NNC2PL) 来加速 conservative-to-primitive inversion，特别是针对 hybrid piecewise polytropic and tabulated equations of state，以应对传统根查找技术在相对论流体动力学模拟中的高计算开销。模型在 PyTorch 中训练，并通过 NVIDIA TensorRT 的混合精度优化，实现比单线程 CPU 实现快约 400 倍的速度提升，同时保持极低错误率（NNC2PS 的 L1 和 L∞ 错误分别为 4.54 × 10^{-7} 和 3.44 × 10^{-6}）。在 Delta 超级计算机上，该方法在处理 8 百万数据点时预测比优化并行数值方法快 25 倍，并显示出次线性缩放特性。研究还发布了相关软件，强调了机器学习结合 GPU 优化和模型量化的潜力，为大规模模拟提供高效解决方案。",
      "categories": [
        "gr-qc",
        "astro-ph.IM",
        "cs.AI",
        "physics.comp-ph",
        "J.2; I.2"
      ],
      "primary_category": "gr-qc",
      "comment": "17 pages, 4 figures, 1 table New results added",
      "pdf_url": "http://arxiv.org/pdf/2412.07836v2",
      "published_date": "2024-12-10 19:00:01 UTC",
      "updated_date": "2025-01-29 19:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:36:28.627924"
    },
    {
      "arxiv_id": "2412.07776v2",
      "title": "Video Motion Transfer with Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Pondaven",
        "Aliaksandr Siarohin",
        "Sergey Tulyakov",
        "Philip Torr",
        "Fabio Pizzati"
      ],
      "abstract": "We propose DiTFlow, a method for transferring the motion of a reference video\nto a newly synthesized one, designed specifically for Diffusion Transformers\n(DiT). We first process the reference video with a pre-trained DiT to analyze\ncross-frame attention maps and extract a patch-wise motion signal called the\nAttention Motion Flow (AMF). We guide the latent denoising process in an\noptimization-based, training-free, manner by optimizing latents with our AMF\nloss to generate videos reproducing the motion of the reference one. We also\napply our optimization strategy to transformer positional embeddings, granting\nus a boost in zero-shot motion transfer capabilities. We evaluate DiTFlow\nagainst recently published methods, outperforming all across multiple metrics\nand human evaluation.",
      "tldr_zh": "我们提出 DiTFlow，一种针对 Diffusion Transformers (DiT) 的视频动作转移方法，通过分析参考视频的跨帧注意力图 (cross-frame attention maps) 提取 patch-wise 运动信号 Attention Motion Flow (AMF)。该方法采用优化-based、训练-free 的策略，指导潜在去噪过程并优化 transformer 的位置嵌入 (positional embeddings)，从而生成复制参考视频动作的新视频。实验结果显示，DiTFlow 在多个指标和人类评估中优于现有方法，显著提升了零样本动作转移能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 - Project page: https://ditflow.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.07776v2",
      "published_date": "2024-12-10 18:59:58 UTC",
      "updated_date": "2025-03-27 11:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:34:36.472146"
    },
    {
      "arxiv_id": "2412.07773v2",
      "title": "Mobile-TeleVision: Predictive Motion Priors for Humanoid Whole-Body Control",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Lu",
        "Xuxin Cheng",
        "Jialong Li",
        "Shiqi Yang",
        "Mazeyu Ji",
        "Chengjing Yuan",
        "Ge Yang",
        "Sha Yi",
        "Xiaolong Wang"
      ],
      "abstract": "Humanoid robots require both robust lower-body locomotion and precise\nupper-body manipulation. While recent Reinforcement Learning (RL) approaches\nprovide whole-body loco-manipulation policies, they lack precise manipulation\nwith high DoF arms. In this paper, we propose decoupling upper-body control\nfrom locomotion, using inverse kinematics (IK) and motion retargeting for\nprecise manipulation, while RL focuses on robust lower-body locomotion. We\nintroduce PMP (Predictive Motion Priors), trained with Conditional Variational\nAutoencoder (CVAE) to effectively represent upper-body motions. The locomotion\npolicy is trained conditioned on this upper-body motion representation,\nensuring that the system remains robust with both manipulation and locomotion.\nWe show that CVAE features are crucial for stability and robustness, and\nsignificantly outperforms RL-based whole-body control in precise manipulation.\nWith precise upper-body motion and robust lower-body locomotion control,\noperators can remotely control the humanoid to walk around and explore\ndifferent environments, while performing diverse manipulation tasks.",
      "tldr_zh": "本研究针对人形机器人的全身控制问题，提出 Mobile-TeleVision 方法，通过将上肢控制与下肢运动解耦，使用 Inverse Kinematics (IK) 和运动重定向实现精确的上肢操作，而 Reinforcement Learning (RL) 则专注于鲁棒的下肢运动。引入 Predictive Motion Priors (PMP)，基于 Conditional Variational Autoencoder (CVAE) 训练上肢运动表示，确保系统在操作和运动上保持稳定。实验结果表明，该方法在精确操作任务上显著优于基于 RL 的全身控制策略，支持操作员远程控制机器人行走、探索环境并执行多样化任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07773v2",
      "published_date": "2024-12-10 18:59:50 UTC",
      "updated_date": "2025-03-09 08:41:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:36:41.683066"
    },
    {
      "arxiv_id": "2412.07755v2",
      "title": "SAT: Dynamic Spatial Aptitude Training for Multimodal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Arijit Ray",
        "Jiafei Duan",
        "Ellis Brown",
        "Reuben Tan",
        "Dina Bashkirova",
        "Rose Hendrix",
        "Kiana Ehsani",
        "Aniruddha Kembhavi",
        "Bryan A. Plummer",
        "Ranjay Krishna",
        "Kuo-Hao Zeng",
        "Kate Saenko"
      ],
      "abstract": "Reasoning about motion and space is a fundamental cognitive capability that\nis required by multiple real-world applications. While many studies highlight\nthat large multimodal language models (MLMs) struggle to reason about space,\nthey only focus on static spatial relationships, and not dynamic awareness of\nmotion and space, i.e., reasoning about the effect of egocentric and object\nmotions on spatial relationships. Manually annotating such object and camera\nmovements is expensive. Hence, we introduce SAT, a simulated spatial aptitude\ntraining dataset comprising both static and dynamic spatial reasoning across\n175K question-answer (QA) pairs and 20K scenes. Complementing this, we also\nconstruct a small (150 image-QAs) yet challenging dynamic spatial test set\nusing real-world images. Leveraging our SAT datasets and 6 existing static\nspatial benchmarks, we systematically investigate what improves both static and\ndynamic spatial awareness. Our results reveal that simulations are surprisingly\neffective at imparting spatial aptitude to MLMs that translate to real images.\nWe show that perfect annotations in simulation are more effective than existing\napproaches of pseudo-annotating real images. For instance, SAT training\nimproves a LLaVA-13B model by an average 11% and a LLaVA-Video-7B model by an\naverage 8% on multiple spatial benchmarks, including our real-image dynamic\ntest set and spatial reasoning on long videos -- even outperforming some large\nproprietary models. While reasoning over static relationships improves with\nsynthetic training data, there is still considerable room for improvement for\ndynamic reasoning questions.",
      "tldr_zh": "这篇论文针对多模态语言模型（MLMs）在动态空间推理（如物体和相机运动对空间关系的影响）方面的不足，引入了 SAT 数据集——一个模拟环境生成的训练资源，包含 175K QA 对和 20K 场景，用于覆盖静态和动态空间推理。研究者还构建了一个小型（150 个图像-QA）的真实图像动态测试集，以评估模型性能。实验结果显示，SAT 训练数据比伪标注真实图像更有效，能显著提升模型能力，例如使 LLaVA-13B 模型在多个空间基准上平均提高 11%，并在长视频推理中超越某些大型专有模型。尽管静态空间关系推理有所改善，但动态推理仍需进一步优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://arijitray.com/SAT/",
      "pdf_url": "http://arxiv.org/pdf/2412.07755v2",
      "published_date": "2024-12-10 18:52:45 UTC",
      "updated_date": "2025-04-03 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:36:54.107978"
    },
    {
      "arxiv_id": "2412.09645v2",
      "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
      "title_zh": "Evaluation Agent：高效且可提示的视觉生成模型评估框架",
      "authors": [
        "Fan Zhang",
        "Shulin Tian",
        "Ziqi Huang",
        "Yu Qiao",
        "Ziwei Liu"
      ],
      "abstract": "Recent advancements in visual generative models have enabled high-quality\nimage and video generation, opening diverse applications. However, evaluating\nthese models often demands sampling hundreds or thousands of images or videos,\nmaking the process computationally expensive, especially for diffusion-based\nmodels with inherently slow sampling. Moreover, existing evaluation methods\nrely on rigid pipelines that overlook specific user needs and provide numerical\nresults without clear explanations. In contrast, humans can quickly form\nimpressions of a model's capabilities by observing only a few samples. To mimic\nthis, we propose the Evaluation Agent framework, which employs human-like\nstrategies for efficient, dynamic, multi-round evaluations using only a few\nsamples per round, while offering detailed, user-tailored analyses. It offers\nfour key advantages: 1) efficiency, 2) promptable evaluation tailored to\ndiverse user needs, 3) explainability beyond single numerical scores, and 4)\nscalability across various models and tools. Experiments show that Evaluation\nAgent reduces evaluation time to 10% of traditional methods while delivering\ncomparable results. The Evaluation Agent framework is fully open-sourced to\nadvance research in visual generative models and their efficient evaluation.",
      "tldr_zh": "该研究针对视觉生成模型的评估挑战，提出了一种高效且可提示的 Evaluation Agent 框架，该框架模仿人类策略，通过少量样本进行动态多轮评估，提供用户定制的详细分析，而非仅限于数字分数。框架的关键优势包括高效率、可适应多样用户需求的 promptable evaluation、增强解释性和跨模型工具的可扩展性。实验结果表明，Evaluation Agent 将评估时间缩短至传统方法的 10%，同时保持可比性能，并已完全开源以推动视觉生成模型的研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Equal contributions from first three authors. Project page:\n  https://vchitect.github.io/Evaluation-Agent-project Code:\n  https://github.com/Vchitect/Evaluation-Agent",
      "pdf_url": "http://arxiv.org/pdf/2412.09645v2",
      "published_date": "2024-12-10 18:52:39 UTC",
      "updated_date": "2024-12-16 04:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:37:07.155742"
    },
    {
      "arxiv_id": "2412.07754v1",
      "title": "PortraitTalk: Towards Customizable One-Shot Audio-to-Talking Face Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Fatemeh Nazarieh",
        "Zhenhua Feng",
        "Diptesh Kanojia",
        "Muhammad Awais",
        "Josef Kittler"
      ],
      "abstract": "Audio-driven talking face generation is a challenging task in digital\ncommunication. Despite significant progress in the area, most existing methods\nconcentrate on audio-lip synchronization, often overlooking aspects such as\nvisual quality, customization, and generalization that are crucial to producing\nrealistic talking faces. To address these limitations, we introduce a novel,\ncustomizable one-shot audio-driven talking face generation framework, named\nPortraitTalk. Our proposed method utilizes a latent diffusion framework\nconsisting of two main components: IdentityNet and AnimateNet. IdentityNet is\ndesigned to preserve identity features consistently across the generated video\nframes, while AnimateNet aims to enhance temporal coherence and motion\nconsistency. This framework also integrates an audio input with the reference\nimages, thereby reducing the reliance on reference-style videos prevalent in\nexisting approaches. A key innovation of PortraitTalk is the incorporation of\ntext prompts through decoupled cross-attention mechanisms, which significantly\nexpands creative control over the generated videos. Through extensive\nexperiments, including a newly developed evaluation metric, our model\ndemonstrates superior performance over the state-of-the-art methods, setting a\nnew standard for the generation of customizable realistic talking faces\nsuitable for real-world applications.",
      "tldr_zh": "本文提出了一种名为 PortraitTalk 的可自定义 one-shot 音频驱动说话人脸生成框架，旨在解决现有方法在视觉质量、自定义和泛化方面的不足。框架基于 latent diffusion 模型，包括 IdentityNet 用于保持生成视频帧的身份特征一致，以及 AnimateNet 用于提升时间连贯性和运动一致性。该方法整合音频输入、参考图像和文本提示，通过解耦的交叉注意力机制增强对生成视频的创意控制。实验结果显示，PortraitTalk 在新开发的评估指标上超越了最先进方法，为真实世界应用的真实说话人脸生成设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07754v1",
      "published_date": "2024-12-10 18:51:31 UTC",
      "updated_date": "2024-12-10 18:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:37:18.604175"
    },
    {
      "arxiv_id": "2412.07752v3",
      "title": "FlashRNN: I/O-Aware Optimization of Traditional RNNs on modern hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Korbinian Pöppel",
        "Maximilian Beck",
        "Sepp Hochreiter"
      ],
      "abstract": "While Transformers and other sequence-parallelizable neural network\narchitectures seem like the current state of the art in sequence modeling, they\nspecifically lack state-tracking capabilities. These are important for\ntime-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs,\nas well as modern variants like sLSTM do have these capabilities at the cost of\nstrictly sequential processing. While this is often seen as a strong\nlimitation, we show how fast these networks can get with our\nhardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the\nregister level on modern GPUs. We extend traditional RNNs with a\nparallelization variant that processes multiple RNNs of smaller hidden state in\nparallel, similar to the head-wise processing in Transformers. To enable\nflexibility on different GPU variants, we introduce a new optimization\nframework for hardware-internal cache sizes, memory and compute handling. It\nmodels the hardware in a setting using polyhedral-like constraints, including\nthe notion of divisibility. This speeds up the solution process in our\nConstrINT library for general integer constraint satisfaction problems (integer\nCSPs). We show that our kernels can achieve 50x speed-ups over a vanilla\nPyTorch implementation and allow 40x larger hidden sizes compared to our Triton\nimplementation. Our open-source kernels and the optimization library are\nreleased here to boost research in the direction of state-tracking enabled RNNs\nand sequence modeling: https://github.com/NX-AI/flashrnn",
      "tldr_zh": "这篇论文介绍了 FlashRNN，一种针对现代硬件的 I/O 感知优化框架，用于提升传统 RNNs（如 LSTMs 和 GRUs）的性能，这些模型在时间序列任务和逻辑推理中具有状态跟踪优势，但受限于严格的顺序处理。作者通过在 Triton 和 CUDA 上优化内核到寄存器级别，并引入并行化变体（如多 RNN 隐藏状态并行处理）和一个基于 polyhedral-like 约束的优化框架，解决了硬件缓存、内存和计算的灵活性问题。实验结果显示，FlashRNN 比 vanilla PyTorch 实现快 50 倍，并支持 40 倍更大的隐藏状态大小，同时开源了内核和 ConstrINT 库以推动相关研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07752v3",
      "published_date": "2024-12-10 18:50:37 UTC",
      "updated_date": "2025-03-13 11:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:37:31.435338"
    },
    {
      "arxiv_id": "2412.07747v2",
      "title": "Predictive Modeling of Homeless Service Assignment: A Representation Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Khandker Sadia Rahman",
        "Charalampos Chelmis"
      ],
      "abstract": "In recent years, there has been growing interest in leveraging machine\nlearning for homeless service assignment. However, the categorical nature of\nadministrative data recorded for homeless individuals hinders the development\nof accurate machine learning methods for this task. This work asserts that\nderiving latent representations of such features, while at the same time\nleveraging underlying relationships between instances is crucial in\nalgorithmically enhancing the existing assignment decision-making process. Our\nproposed approach learns temporal and functional relationships between services\nfrom historical data, as well as unobserved but relevant relationships between\nindividuals to generate features that significantly improve the prediction of\nthe next service assignment compared to the state-of-the-art.",
      "tldr_zh": "这篇论文针对无家可归者服务分配的机器学习应用，提出了一种基于representation learning的方法，以克服行政数据的分类特性带来的挑战。该方法从历史数据中学习服务之间的时间和功能关系，以及个体之间的未观察相关性，从而生成更有效的特征。实验结果显示，该方法显著提升了下一个服务分配的预测准确性，优于现有最先进技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07747v2",
      "published_date": "2024-12-10 18:47:10 UTC",
      "updated_date": "2024-12-11 20:24:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:37:40.640094"
    },
    {
      "arxiv_id": "2412.07739v1",
      "title": "GASP: Gaussian Avatars with Synthetic Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Jack Saunders",
        "Charlie Hewitt",
        "Yanan Jian",
        "Marek Kowalski",
        "Tadas Baltrusaitis",
        "Yiye Chen",
        "Darren Cosker",
        "Virginia Estellers",
        "Nicholas Gyde",
        "Vinay P. Namboodiri",
        "Benjamin E Lundell"
      ],
      "abstract": "Gaussian Splatting has changed the game for real-time photo-realistic\nrendering. One of the most popular applications of Gaussian Splatting is to\ncreate animatable avatars, known as Gaussian Avatars. Recent works have pushed\nthe boundaries of quality and rendering efficiency but suffer from two main\nlimitations. Either they require expensive multi-camera rigs to produce avatars\nwith free-view rendering, or they can be trained with a single camera but only\nrendered at high quality from this fixed viewpoint. An ideal model would be\ntrained using a short monocular video or image from available hardware, such as\na webcam, and rendered from any view. To this end, we propose GASP: Gaussian\nAvatars with Synthetic Priors. To overcome the limitations of existing\ndatasets, we exploit the pixel-perfect nature of synthetic data to train a\nGaussian Avatar prior. By fitting this prior model to a single photo or video\nand fine-tuning it, we get a high-quality Gaussian Avatar, which supports\n360$^\\circ$ rendering. Our prior is only required for fitting, not inference,\nenabling real-time application. Through our method, we obtain high-quality,\nanimatable Avatars from limited data which can be animated and rendered at\n70fps on commercial hardware. See our project page\n(https://microsoft.github.io/GASP/) for results.",
      "tldr_zh": "本研究提出 GASP 方法，利用 Synthetic Priors 提升 Gaussian Avatars 的创建效率，解决现有技术在单相机数据下无法实现高质量自由视角渲染的问题。通过合成数据训练一个像素级精确的 Gaussian Avatar 先验模型，并将其拟合和微调到单张照片或短视频中，GASP 实现了 360° 渲染支持，而无需多相机设备。实验结果显示，该方法从有限数据生成高质量、可动画化的头像，并在商用硬件上以 70fps 的速度实时渲染。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://microsoft.github.io/GASP/",
      "pdf_url": "http://arxiv.org/pdf/2412.07739v1",
      "published_date": "2024-12-10 18:36:21 UTC",
      "updated_date": "2024-12-10 18:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:37:52.369236"
    },
    {
      "arxiv_id": "2412.07730v1",
      "title": "STIV: Scalable Text and Image Conditioned Video Generation",
      "title_zh": "STIV：可扩展的文本和图像条件视频生成",
      "authors": [
        "Zongyu Lin",
        "Wei Liu",
        "Chen Chen",
        "Jiasen Lu",
        "Wenze Hu",
        "Tsu-Jui Fu",
        "Jesse Allardice",
        "Zhengfeng Lai",
        "Liangchen Song",
        "Bowen Zhang",
        "Cha Chen",
        "Yiran Fei",
        "Yifan Jiang",
        "Lezhi Li",
        "Yizhou Sun",
        "Kai-Wei Chang",
        "Yinfei Yang"
      ],
      "abstract": "The field of video generation has made remarkable advancements, yet there\nremains a pressing need for a clear, systematic recipe that can guide the\ndevelopment of robust and scalable models. In this work, we present a\ncomprehensive study that systematically explores the interplay of model\narchitectures, training recipes, and data curation strategies, culminating in a\nsimple and scalable text-image-conditioned video generation method, named STIV.\nOur framework integrates image condition into a Diffusion Transformer (DiT)\nthrough frame replacement, while incorporating text conditioning via a joint\nimage-text conditional classifier-free guidance. This design enables STIV to\nperform both text-to-video (T2V) and text-image-to-video (TI2V) tasks\nsimultaneously. Additionally, STIV can be easily extended to various\napplications, such as video prediction, frame interpolation, multi-view\ngeneration, and long video generation, etc. With comprehensive ablation studies\non T2I, T2V, and TI2V, STIV demonstrate strong performance, despite its simple\ndesign. An 8.7B model with 512 resolution achieves 83.1 on VBench T2V,\nsurpassing both leading open and closed-source models like CogVideoX-5B, Pika,\nKling, and Gen-3. The same-sized model also achieves a state-of-the-art result\nof 90.1 on VBench I2V task at 512 resolution. By providing a transparent and\nextensible recipe for building cutting-edge video generation models, we aim to\nempower future research and accelerate progress toward more versatile and\nreliable video generation solutions.",
      "tldr_zh": "本研究提出了一种可扩展的视频生成框架STIV，它基于Diffusion Transformer (DiT)通过框架替换(frame replacement)整合图像条件，并采用联合图像-文本条件分类器自由引导(joint image-text conditional classifier-free guidance)来处理文本条件，从而同时支持文本到视频(T2V)和文本-图像到视频(TI2V)任务。STIV的设计简单且易扩展，可应用于视频预测、帧插值、多视图生成和长视频生成等领域。实验结果显示，8.7B模型在VBench T2V任务中达到83.1的分数，超越CogVideoX-5B等领先模型，并在TI2V任务中实现90.1的state-of-the-art性能，为构建更可靠的视频生成解决方案提供了一个透明的指导框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07730v1",
      "published_date": "2024-12-10 18:27:06 UTC",
      "updated_date": "2024-12-10 18:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:38:07.557231"
    },
    {
      "arxiv_id": "2412.07713v1",
      "title": "Benchmark for Evaluation and Analysis of Citation Recommendation Models",
      "title_zh": "引文推荐模型的评估和分析基准",
      "authors": [
        "Puja Maharjan"
      ],
      "abstract": "Citation recommendation systems have attracted much academic interest,\nresulting in many studies and implementations. These systems help authors\nautomatically generate proper citations by suggesting relevant references based\non the text they have written. However, the methods used in citation\nrecommendation differ across various studies and implementations. Some\napproaches focus on the overall content of papers, while others consider the\ncontext of the citation text. Additionally, the datasets used in these studies\ninclude different aspects of papers, such as metadata, citation context, or\neven the full text of the paper in various formats and structures. The\ndiversity in models, datasets, and evaluation metrics makes it challenging to\nassess and compare citation recommendation methods effectively. To address this\nissue, a standardized dataset and evaluation metrics are needed to evaluate\nthese models consistently. Therefore, we propose developing a benchmark\nspecifically designed to analyze and compare citation recommendation models.\nThis benchmark will evaluate the performance of models on different features of\nthe citation context and provide a comprehensive evaluation of the models\nacross all these tasks, presenting the results in a standardized way. By\ncreating a benchmark with standardized evaluation metrics, researchers and\npractitioners in the field of citation recommendation will have a common\nplatform to assess and compare different models. This will enable meaningful\ncomparisons and help identify promising approaches for further research and\ndevelopment in the field.",
      "tldr_zh": "本研究针对引文推荐模型(citation recommendation models)的多样性问题（如方法、数据集和评估指标的差异）提出一个标准化基准(benchmark)，以便更有效地评估和比较这些模型。该基准包括一个统一数据集和评估指标，专注于模型在不同引文上下文特征上的性能表现。通过提供全面且标准化的评估方式，该基准有助于研究人员和从业者进行有意义的模型比较，并识别出有前景的引文推荐方法，从而推动该领域的进一步研究和发展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07713v1",
      "published_date": "2024-12-10 18:01:33 UTC",
      "updated_date": "2024-12-10 18:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:38:15.224619"
    },
    {
      "arxiv_id": "2412.07696v1",
      "title": "SimVS: Simulating World Inconsistencies for Robust View Synthesis",
      "title_zh": "SimVS：",
      "authors": [
        "Alex Trevithick",
        "Roni Paiss",
        "Philipp Henzler",
        "Dor Verbin",
        "Rundi Wu",
        "Hadi Alzayer",
        "Ruiqi Gao",
        "Ben Poole",
        "Jonathan T. Barron",
        "Aleksander Holynski",
        "Ravi Ramamoorthi",
        "Pratul P. Srinivasan"
      ],
      "abstract": "Novel-view synthesis techniques achieve impressive results for static scenes\nbut struggle when faced with the inconsistencies inherent to casual capture\nsettings: varying illumination, scene motion, and other unintended effects that\nare difficult to model explicitly. We present an approach for leveraging\ngenerative video models to simulate the inconsistencies in the world that can\noccur during capture. We use this process, along with existing multi-view\ndatasets, to create synthetic data for training a multi-view harmonization\nnetwork that is able to reconcile inconsistent observations into a consistent\n3D scene. We demonstrate that our world-simulation strategy significantly\noutperforms traditional augmentation methods in handling real-world scene\nvariations, thereby enabling highly accurate static 3D reconstructions in the\npresence of a variety of challenging inconsistencies. Project page:\nhttps://alextrevithick.github.io/simvs",
      "tldr_zh": "该论文提出SimVS方法，使用生成视频模型(generative video models)模拟捕捉过程中的世界不一致性（如变化的照明和场景运动），以提升新视图合成(Novel-view synthesis)技术的鲁棒性。具体而言，该方法结合现有多视图数据集创建合成数据，并训练一个多视图协调网络(multi-view harmonization network)，从而将不一致的观察整合成一致的3D场景。实验结果显示，SimVS显著优于传统增强方法，在处理真实世界场景变化时实现了更准确的静态3D重建。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://alextrevithick.github.io/simvs",
      "pdf_url": "http://arxiv.org/pdf/2412.07696v1",
      "published_date": "2024-12-10 17:35:12 UTC",
      "updated_date": "2024-12-10 17:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:38:28.443000"
    },
    {
      "arxiv_id": "2412.07686v1",
      "title": "Optimizing Sensor Redundancy in Sequential Decision-Making Problems",
      "title_zh": "顺序决策问题中的传感器冗余优化",
      "authors": [
        "Jonas Nüßlein",
        "Maximilian Zorn",
        "Fabian Ritz",
        "Jonas Stein",
        "Gerhard Stenzel",
        "Julian Schönberger",
        "Thomas Gabor",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Reinforcement Learning (RL) policies are designed to predict actions based on\ncurrent observations to maximize cumulative future rewards. In real-world\napplications (i.e., non-simulated environments), sensors are essential for\nmeasuring the current state and providing the observations on which RL policies\nrely to make decisions. A significant challenge in deploying RL policies in\nreal-world scenarios is handling sensor dropouts, which can result from\nhardware malfunctions, physical damage, or environmental factors like dust on a\ncamera lens. A common strategy to mitigate this issue is the use of backup\nsensors, though this comes with added costs. This paper explores the\noptimization of backup sensor configurations to maximize expected returns while\nkeeping costs below a specified threshold, C. Our approach uses a second-order\napproximation of expected returns and includes penalties for exceeding cost\nconstraints. We then optimize this quadratic program using Tabu Search, a\nmeta-heuristic algorithm. The approach is evaluated across eight OpenAI Gym\nenvironments and a custom Unity-based robotic environment (RobotArmGrasping).\nEmpirical results demonstrate that our quadratic program effectively\napproximates real expected returns, facilitating the identification of optimal\nsensor configurations.",
      "tldr_zh": "该论文探讨了在强化学习（RL）环境中优化传感器冗余的问题，旨在处理传感器掉线（如硬件故障或环境因素）对决策的影响，同时平衡成本和预期回报。研究提出了一种方法，使用二阶近似来估算预期回报，并通过二次规划模型结合成本约束惩罚进行优化，然后采用 Tabu Search 算法求解。实验在八个 OpenAI Gym 环境和一个自定义的 Unity-based 机器人环境（RobotArmGrasping）中进行，结果显示该方法能有效近似真实回报，并识别出最佳传感器配置。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at ICAART conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07686v1",
      "published_date": "2024-12-10 17:20:44 UTC",
      "updated_date": "2024-12-10 17:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:38:40.643887"
    },
    {
      "arxiv_id": "2412.07684v1",
      "title": "The Pitfalls of Memorization: When Memorization Hurts Generalization",
      "title_zh": "记忆化的陷阱：当记忆化损害泛化时",
      "authors": [
        "Reza Bayat",
        "Mohammad Pezeshki",
        "Elvis Dohmatob",
        "David Lopez-Paz",
        "Pascal Vincent"
      ],
      "abstract": "Neural networks often learn simple explanations that fit the majority of the\ndata while memorizing exceptions that deviate from these explanations.This\nbehavior leads to poor generalization when the learned explanations rely on\nspurious correlations. In this work, we formalize the interplay between\nmemorization and generalization, showing that spurious correlations would\nparticularly lead to poor generalization when are combined with memorization.\nMemorization can reduce training loss to zero, leaving no incentive to learn\nrobust, generalizable patterns. To address this, we propose memorization-aware\ntraining (MAT), which uses held-out predictions as a signal of memorization to\nshift a model's logits. MAT encourages learning robust patterns invariant\nacross distributions, improving generalization under distribution shifts.",
      "tldr_zh": "神经网络常常学习简单解释来适应大多数数据，同时记忆(memorization)异常数据，这在涉及虚假相关性(spurious correlations)时会导致泛化(generalization)性能下降。论文形式化了记忆化和泛化之间的相互作用，指出虚假相关性结合记忆化会特别损害泛化，因为记忆化可将训练损失降至零，而不鼓励学习鲁棒模式。为解决此问题，研究提出记忆化感知训练(MAT)，该方法使用保留预测作为信号来调整模型的logits，从而促进学习在分布偏移下不变的鲁棒模式。实验结果表明，MAT 有效改善了模型在分布变化下的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07684v1",
      "published_date": "2024-12-10 17:18:33 UTC",
      "updated_date": "2024-12-10 17:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:38:53.585416"
    },
    {
      "arxiv_id": "2412.07679v2",
      "title": "RADIOv2.5: Improved Baselines for Agglomerative Vision Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Greg Heinrich",
        "Mike Ranzinger",
        "Hongxu",
        "Yin",
        "Yao Lu",
        "Jan Kautz",
        "Andrew Tao",
        "Bryan Catanzaro",
        "Pavlo Molchanov"
      ],
      "abstract": "Agglomerative models have recently emerged as a powerful approach to training\nvision foundation models, leveraging multi-teacher distillation from existing\nmodels such as CLIP, DINO, and SAM. This strategy enables the efficient\ncreation of robust models, combining the strengths of individual teachers while\nsignificantly reducing computational and resource demands. In this paper, we\nthoroughly analyze state-of-the-art agglomerative models, identifying critical\nchallenges including resolution mode shifts, teacher imbalance, idiosyncratic\nteacher artifacts, and an excessive number of output tokens. To address these\nissues, we propose several novel solutions: multi-resolution training, mosaic\naugmentation, and improved balancing of teacher loss functions. Specifically,\nin the context of Vision Language Models, we introduce a token compression\ntechnique to maintain high-resolution information within a fixed token count.\nWe release our top-performing variants at multiple scales (-B, -L, -H, and -g),\nalong with inference code and pretrained weights",
      "tldr_zh": "这篇论文介绍了 RADIOv2.5，一种改进的 agglomerative vision foundation models 基线，通过 multi-teacher distillation 从 CLIP、DINO 和 SAM 等现有模型中学习，高效结合教师优势并减少计算资源需求。论文分析了 agglomerative 模型的关键挑战，包括 resolution mode shifts、teacher imbalance、idiosyncratic teacher artifacts 和 excessive number of output tokens，并提出多分辨率训练(multi-resolution training)、mosaic augmentation 和改进的教师损失函数平衡(teacher loss functions)作为解决方案；针对 Vision Language Models，还引入了 token compression 技术以在固定令牌数下保留高分辨率信息。最终，作者发布了多种规模的模型变体(-B、-L、-H 和 -g)，并提供了推理代码和预训练权重，提升了模型的鲁棒性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07679v2",
      "published_date": "2024-12-10 17:06:41 UTC",
      "updated_date": "2025-02-09 15:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:39:05.636786"
    },
    {
      "arxiv_id": "2412.16181v2",
      "title": "Minimum Weighted Feedback Arc Sets for Ranking from Pairwise Comparisons",
      "title_zh": "翻译失败",
      "authors": [
        "Soroush Vahidi",
        "Ioannis Koutis"
      ],
      "abstract": "The Minimum Weighted Feedback Arc Set (MWFAS) problem is fundamentally\nconnected to the Ranking Problem -- the task of deriving global rankings from\npairwise comparisons. Recent work [He et al. ICML2022] has advanced the\nstate-of-the-art for the Ranking Problem using learning-based methods,\nimproving upon multiple previous approaches. However, the connection to MWFAS\nremains underexplored. This paper investigates this relationship and presents\nefficient combinatorial algorithms for solving MWFAS, thus addressing the\nRanking Problem. Our experimental results demonstrate that these simple,\nlearning-free algorithms not only significantly outperform learning-based\nmethods in terms of speed but also generally achieve superior ranking accuracy.",
      "tldr_zh": "这篇论文探讨了Minimum Weighted Feedback Arc Sets (MWFAS)问题与Ranking Problem（从pairwise comparisons中推导全局排名）的紧密关联，针对He et al.在ICML2022提出的学习方法进行了扩展。作者开发了高效的combinatorial algorithms来解决MWFAS，从而直接处理排名任务，这些算法无需学习训练。实验结果表明，这些简单算法在速度上显著优于基于学习的基准方法，并在排名准确性上通常表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "This is a preliminary paper",
      "pdf_url": "http://arxiv.org/pdf/2412.16181v2",
      "published_date": "2024-12-10 16:51:11 UTC",
      "updated_date": "2025-01-07 22:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:41:10.312853"
    },
    {
      "arxiv_id": "2412.07658v2",
      "title": "TraSCE: Trajectory Steering for Concept Erasure",
      "title_zh": "TraSCE：轨迹引导用于概念擦除",
      "authors": [
        "Anubhav Jain",
        "Yuya Kobayashi",
        "Takashi Shibuya",
        "Yuhta Takida",
        "Nasir Memon",
        "Julian Togelius",
        "Yuki Mitsufuji"
      ],
      "abstract": "Recent advancements in text-to-image diffusion models have brought them to\nthe public spotlight, becoming widely accessible and embraced by everyday\nusers. However, these models have been shown to generate harmful content such\nas not-safe-for-work (NSFW) images. While approaches have been proposed to\nerase such abstract concepts from the models, jail-breaking techniques have\nsucceeded in bypassing such safety measures. In this paper, we propose TraSCE,\nan approach to guide the diffusion trajectory away from generating harmful\ncontent. Our approach is based on negative prompting, but as we show in this\npaper, a widely used negative prompting strategy is not a complete solution and\ncan easily be bypassed in some corner cases. To address this issue, we first\npropose using a specific formulation of negative prompting instead of the\nwidely used one. Furthermore, we introduce a localized loss-based guidance that\nenhances the modified negative prompting technique by steering the diffusion\ntrajectory. We demonstrate that our proposed method achieves state-of-the-art\nresults on various benchmarks in removing harmful content, including ones\nproposed by red teams, and erasing artistic styles and objects. Our proposed\napproach does not require any training, weight modifications, or training data\n(either image or prompt), making it easier for model owners to erase new\nconcepts.",
      "tldr_zh": "该论文提出 TraSCE 方法，用于引导文本到图像扩散模型的轨迹，从而擦除有害内容，如 NSFW 图像，并解决现有安全措施易被绕过的缺陷。TraSCE 基于改进的 negative prompting 公式，并引入 localized loss-based guidance 来精确操纵扩散轨迹，避免生成不适当输出。实验证明，该方法在多种基准测试中实现最先进性能，包括对抗测试和艺术风格/对象的擦除，且无需任何训练、权重修改或数据，使其便于模型所有者快速应用新概念的擦除。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07658v2",
      "published_date": "2024-12-10 16:45:03 UTC",
      "updated_date": "2025-03-17 15:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:41:22.254952"
    },
    {
      "arxiv_id": "2501.08416v1",
      "title": "A Survey on Recent Advances in Self-Organizing Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Axel Guérin",
        "Pierre Chauvet",
        "Frédéric Saubion"
      ],
      "abstract": "Self-organising maps are a powerful tool for cluster analysis in a wide range\nof data contexts. From the pioneer work of Kohonen, many variants and\nimprovements have been proposed. This review focuses on the last decade, in\norder to provide an overview of the main evolution of the seminal SOM algorithm\nas well as of the methodological developments that have been achieved in order\nto better fit to various application contexts and users' requirements. We also\nhighlight a specific and important application field that is related to\ncommercial use of SOM, which involves specific data management.",
      "tldr_zh": "这篇调查回顾了Self-Organizing Maps (SOM)算法在过去十年的主要进展，从Kohonen的开创性工作出发，概述了SOM的演变及其methodological developments，以更好地适应各种应用场景和用户需求。论文强调了SOM在商业领域的特定应用，特别是涉及数据管理的方面，这些改进增强了其在聚类分析中的实用性。通过此调查，研究者可以了解SOM如何持续优化以满足实际需求。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08416v1",
      "published_date": "2024-12-10 16:40:02 UTC",
      "updated_date": "2024-12-10 16:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:39:40.598544"
    },
    {
      "arxiv_id": "2412.10425v3",
      "title": "Active Inference for Self-Organizing Multi-LLM Systems: A Bayesian Thermodynamic Approach to Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Rithvik Prakki"
      ],
      "abstract": "This paper introduces a novel approach to creating adaptive language agents\nby integrating active inference with large language models (LLMs). While LLMs\ndemonstrate remarkable capabilities, their reliance on static prompts limits\nadaptation to new information and changing environments. We address this by\nimplementing an active inference framework that acts as a cognitive layer above\nan LLM-based agent, dynamically adjusting prompts and search strategies through\nprincipled information-seeking behavior. Our framework models the environment\nusing three state factors (prompt, search, and information states) with seven\nobservation modalities capturing quality metrics. By framing the agent's\nlearning through the free energy principle, we enable systematic exploration of\nprompt combinations and search strategies. Experimental results demonstrate the\neffectiveness of this approach, with the agent developing accurate models of\nenvironment dynamics evidenced by emergent structure in observation matrices.\nAction selection patterns reveal sophisticated exploration-exploitation\nbehavior, transitioning from initial information-gathering to targeted prompt\ntesting. The integration of thermodynamic principles with language model\ncapabilities provides a principled framework for creating robust, adaptable\nagents, extending active inference beyond traditional low-dimensional control\nproblems to high-dimensional, language-driven environments.",
      "tldr_zh": "本论文提出了一种将主动推理（Active Inference）与大型语言模型（LLMs）整合的新方法，旨在创建自组织的多LLMs系统，以实现对动态环境的适应。该框架作为LLMs代理的认知层，通过动态调整提示（prompt）、搜索策略和信息状态（包括七个观察模式），并运用自由能原理（Free Energy Principle）和贝叶斯热力学方法，指导代理进行系统性的探索和学习。实验结果显示，该方法使代理能够开发出准确的环境动态模型，展现出从初始信息收集到针对性提示测试的复杂探索-利用行为。总体而言，这一方法为构建稳健、可适应的高维语言驱动代理提供了原理性框架，将主动推理扩展至传统低维控制问题之外。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10425v3",
      "published_date": "2024-12-10 16:34:47 UTC",
      "updated_date": "2025-01-09 22:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:39:54.593148"
    },
    {
      "arxiv_id": "2412.09644v1",
      "title": "Combining knowledge graphs and LLMs for hazardous chemical information management and reuse",
      "title_zh": "结合知识图谱和大型语言模型用于危险化学品信息管理和重用",
      "authors": [
        "Marcos Da Silveira",
        "Louis Deladiennee",
        "Kheira Acem",
        "Oona Freudenthal"
      ],
      "abstract": "Human health is increasingly threatened by exposure to hazardous substances,\nparticularly persistent and toxic chemicals. The link between these substances,\noften encountered in complex mixtures, and various diseases are demonstrated in\nscientific studies. However, this information is scattered across several\nsources and hardly accessible by humans and machines. This paper evaluates\ncurrent practices for publishing/accessing information on hazardous chemicals\nand proposes a novel platform designed to facilitate retrieval of critical\nchemical data in urgent situations. The platform aggregates information from\nmultiple sources and organizes it into a structured knowledge graph. Users can\naccess this information through a visual interface such as Neo4J Bloom and\ndashboards, or via natural language queries using a Chatbot. Our findings\ndemonstrate a significant reduction in the time and effort required to access\nvital chemical information when datasets follow FAIR principles. Furthermore,\nwe discuss the lessons learned from the development and implementation of this\nplatform and provide recommendations for data owners and publishers to enhance\ndata reuse and interoperability. This work aims to improve the accessibility\nand usability of chemical information by healthcare professionals, thereby\nsupporting better health outcomes and informed decision-making in the face of\npatients exposed to chemical intoxication risks.",
      "tldr_zh": "这篇论文评估了有害化学品信息散乱且难以访问的现状，并提出一个结合知识图谱和 LLMs 的新平台，用于管理和重用此类信息。平台从多个来源聚合数据，构建结构化的知识图谱，并提供视觉界面（如 Neo4J Bloom 和仪表板）以及自然语言查询（如 Chatbot）访问方式。研究发现，当数据集遵循 FAIR principles 时，检索关键化学数据的所需时间和努力显著减少；此外，论文总结了开发经验并给出建议，以提升数据重用和互操作性，从而支持医疗专业人员更好地应对化学中毒风险并改善健康决策。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.4; J.3"
      ],
      "primary_category": "cs.IR",
      "comment": "Submitted to IEEE BIBM24",
      "pdf_url": "http://arxiv.org/pdf/2412.09644v1",
      "published_date": "2024-12-10 16:31:53 UTC",
      "updated_date": "2024-12-10 16:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:40:05.973251"
    },
    {
      "arxiv_id": "2412.07639v2",
      "title": "Offline Multi-Agent Reinforcement Learning via In-Sample Sequential Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zongkai Liu",
        "Qian Lin",
        "Chao Yu",
        "Xiawei Wu",
        "Yile Liang",
        "Donghui Li",
        "Xuetao Ding"
      ],
      "abstract": "Offline Multi-Agent Reinforcement Learning (MARL) is an emerging field that\naims to learn optimal multi-agent policies from pre-collected datasets.\nCompared to single-agent case, multi-agent setting involves a large joint\nstate-action space and coupled behaviors of multiple agents, which bring extra\ncomplexity to offline policy optimization. In this work, we revisit the\nexisting offline MARL methods and show that in certain scenarios they can be\nproblematic, leading to uncoordinated behaviors and out-of-distribution (OOD)\njoint actions. To address these issues, we propose a new offline MARL\nalgorithm, named In-Sample Sequential Policy Optimization (InSPO). InSPO\nsequentially updates each agent's policy in an in-sample manner, which not only\navoids selecting OOD joint actions but also carefully considers teammates'\nupdated policies to enhance coordination. Additionally, by thoroughly exploring\nlow-probability actions in the behavior policy, InSPO can well address the\nissue of premature convergence to sub-optimal solutions. Theoretically, we\nprove InSPO guarantees monotonic policy improvement and converges to quantal\nresponse equilibrium (QRE). Experimental results demonstrate the effectiveness\nof our method compared to current state-of-the-art offline MARL methods.",
      "tldr_zh": "该研究针对离线多智能体强化学习（Offline Multi-Agent Reinforcement Learning）中的联合状态-动作空间复杂性和代理耦合行为问题，提出了一种新算法In-Sample Sequential Policy Optimization (InSPO)。InSPO通过在样本内顺序更新每个代理的政策，避免out-of-distribution (OOD)联合动作，同时考虑队友政策以提升协调，并探索低概率动作来防止过早收敛到次优解。理论上，该算法保证了单调策略改进并收敛到Quantal Response Equilibrium (QRE)。实验结果显示，InSPO比现有离线MARL方法更有效。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07639v2",
      "published_date": "2024-12-10 16:19:08 UTC",
      "updated_date": "2024-12-18 09:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:40:18.661522"
    },
    {
      "arxiv_id": "2412.07636v1",
      "title": "TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize Hardware Trojans",
      "title_zh": "TrojanWhisper：评估预训练的大型语言模型以检测和定位硬件木马",
      "authors": [
        "Md Omar Faruque",
        "Peter Jamieson",
        "Ahmad Patooghy",
        "Abdel-Hameed A. Badawy"
      ],
      "abstract": "Existing Hardware Trojans (HT) detection methods face several critical\nlimitations: logic testing struggles with scalability and coverage for large\ndesigns, side-channel analysis requires golden reference chips, and formal\nverification methods suffer from state-space explosion. The emergence of Large\nLanguage Models (LLMs) offers a promising new direction for HT detection by\nleveraging their natural language understanding and reasoning capabilities. For\nthe first time, this paper explores the potential of general-purpose LLMs in\ndetecting various HTs inserted in Register Transfer Level (RTL) designs,\nincluding SRAM, AES, and UART modules. We propose a novel tool for this goal\nthat systematically assesses state-of-the-art LLMs (GPT-4o, Gemini 1.5 pro, and\nLlama 3.1) in detecting HTs without prior fine-tuning. To address potential\ntraining data bias, the tool implements perturbation techniques, i.e., variable\nname obfuscation, and design restructuring, that make the cases more\nsophisticated for the used LLMs. Our experimental evaluation demonstrates\nperfect detection rates by GPT-4o and Gemini 1.5 pro in baseline scenarios\n(100%/100% precision/recall), with both models achieving better trigger line\ncoverage (TLC: 0.82-0.98) than payload line coverage (PLC: 0.32-0.46). Under\ncode perturbation, while Gemini 1.5 pro maintains perfect detection performance\n(100%/100%), GPT-4o (100%/85.7%) and Llama 3.1 (66.7%/85.7%) show some\ndegradation in detection rates, and all models experience decreased accuracy in\nlocalizing both triggers and payloads. This paper validates the potential of\nLLM approaches for hardware security applications, highlighting areas for\nfuture improvement.",
      "tldr_zh": "这篇论文探讨了使用预训练的大型语言模型 (LLMs) 来检测和定位硬件木马 (HT)，以克服现有方法的局限性，如逻辑测试的可扩展性问题和侧信道分析的依赖性。研究提出一个新工具，系统评估 GPT-4o、Gemini 1.5 pro 和 Llama 3.1 在 Register Transfer Level (RTL) 设计（如 SRAM、AES 和 UART 模块）中的 HT 检测性能，并通过变量名混淆和设计重组等扰动技术增强鲁棒性测试。实验结果显示，在基线场景中，GPT-4o 和 Gemini 1.5 pro 实现了完美的检测率（100% precision/recall）和较高的触发线覆盖率 (TLC: 0.82-0.98)，但扰动后性能有所下降（如 GPT-4o 的 recall 降至 85.7%），验证了 LLMs 在硬件安全应用中的潜力并指出了未来改进方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07636v1",
      "published_date": "2024-12-10 16:16:22 UTC",
      "updated_date": "2024-12-10 16:16:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:40:32.131038"
    },
    {
      "arxiv_id": "2412.07629v4",
      "title": "Piece of Table: A Divide-and-Conquer Approach for Selecting Subtables in Table Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Wonjin Lee",
        "Kyumin Kim",
        "Sungjae Lee",
        "Jihun Lee",
        "Kwang In Kim"
      ],
      "abstract": "Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for subtable-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a subtable. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative subtable\nunion algorithm, PieTa demonstrates improved performance over previous\nsubtable-based QA approaches.",
      "tldr_zh": "该研究提出PieTa（Piece of Table）框架，一种分治（divide-and-conquer）方法，用于解决语言模型（LMs）在表格问答（QA）中的挑战，这些挑战源于表格的二维结构和长上下文限制。PieTa通过迭代地将表格分成更小的窗口，使用LMs选择每个窗口的相关单元格，并将这些单元格合并成子表格，从而捕捉多行多列的依赖关系。实验结果显示，该框架在子表格-based QA任务中比现有方法表现出色，避免了长输入上下文的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07629v4",
      "published_date": "2024-12-10 16:08:14 UTC",
      "updated_date": "2025-02-19 11:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:41:34.729003"
    },
    {
      "arxiv_id": "2412.07626v2",
      "title": "OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations",
      "title_zh": "OmniDocBench：针对多样 PDF 文档解析的全面",
      "authors": [
        "Linke Ouyang",
        "Yuan Qu",
        "Hongbin Zhou",
        "Jiawei Zhu",
        "Rui Zhang",
        "Qunshu Lin",
        "Bin Wang",
        "Zhiyuan Zhao",
        "Man Jiang",
        "Xiaomeng Zhao",
        "Jin Shi",
        "Fan Wu",
        "Pei Chu",
        "Minghao Liu",
        "Zhenxiang Li",
        "Chao Xu",
        "Bo Zhang",
        "Botian Shi",
        "Zhongying Tu",
        "Conghui He"
      ],
      "abstract": "Document content extraction is a critical task in computer vision,\nunderpinning the data needs of large language models (LLMs) and\nretrieval-augmented generation (RAG) systems. Despite recent progress, current\ndocument parsing methods have not been fairly and comprehensively evaluated due\nto the narrow coverage of document types and the simplified, unrealistic\nevaluation procedures in existing benchmarks. To address these gaps, we\nintroduce OmniDocBench, a novel benchmark featuring high-quality annotations\nacross nine document sources, including academic papers, textbooks, and more\nchallenging cases such as handwritten notes and densely typeset newspapers.\nOmniDocBench supports flexible, multi-level evaluations--ranging from an\nend-to-end assessment to the task-specific and attribute--based analysis using\n19 layout categories and 15 attribute labels. We conduct a thorough evaluation\nof both pipeline-based methods and end-to-end vision-language models, revealing\ntheir strengths and weaknesses across different document types. OmniDocBench\nsets a new standard for the fair, diverse, and fine-grained evaluation in\ndocument parsing. Dataset and code are available at\nhttps://github.com/opendatalab/OmniDocBench.",
      "tldr_zh": "该论文提出 OmniDocBench，这是一个新的基准，用于评估文档内容提取任务，支持大型语言模型 (LLMs) 和检索增强生成 (RAG) 系统。OmniDocBench 涵盖九种文档来源的高质量标注，包括学术论文、教科书、手写笔记和密集排版的报纸等多样化类型，并提供灵活的多级别评估，如端到端评估、基于19个布局类别和15个属性标签的任务分析。研究对管道-based 方法和端到端视觉语言模型进行了全面评估，揭示了它们在不同文档类型中的优势和劣势，最终确立了文档解析领域公平、多样和细粒度评估的新标准。数据集和代码可从 https://github.com/opendatalab/OmniDocBench 获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07626v2",
      "published_date": "2024-12-10 16:05:56 UTC",
      "updated_date": "2025-03-25 06:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:41:47.110791"
    },
    {
      "arxiv_id": "2412.07618v2",
      "title": "Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaqiang Tang",
        "Jian Li",
        "Nan Du",
        "Sihong Xie"
      ],
      "abstract": "Despite the superior performance of Large language models on many NLP tasks,\nthey still face significant limitations in memorizing extensive world\nknowledge. Recent studies have demonstrated that leveraging the\nRetrieval-Augmented Generation (RAG) framework, combined with Knowledge Graphs\nthat encapsulate extensive factual data in a structured format, robustly\nenhances the reasoning capabilities of LLMs. However, deploying such systems in\nreal-world scenarios presents challenges: the continuous evolution of\nnon-stationary environments may lead to performance degradation and user\nsatisfaction requires a careful balance of performance and responsiveness. To\naddress these challenges, we introduce a Multi-objective Multi-Armed Bandit\nenhanced RAG framework, supported by multiple retrieval methods with diverse\ncapabilities under rich and evolving retrieval contexts in practice. Within\nthis framework, each retrieval method is treated as a distinct ``arm''. The\nsystem utilizes real-time user feedback to adapt to dynamic environments, by\nselecting the appropriate retrieval method based on input queries and the\nhistorical multi-objective performance of each arm. Extensive experiments\nconducted on two benchmark KGQA datasets demonstrate that our method\nsignificantly outperforms baseline methods in non-stationary settings while\nachieving state-of-the-art performance in stationary environments. Code and\ndata are available at https://github.com/FUTUREEEEEE/Dynamic-RAG.git",
      "tldr_zh": "该研究针对大语言模型(LLMs)在知识图谱(KGs)上的Retrieval-Augmented Generation (RAG)框架，提出了一种多目标多臂赌博机(Multi-objective Multi-Armed Bandit)增强方法，以应对非平稳环境中的性能衰减和响应性平衡问题。框架将每个检索方法视为一个“臂”，通过实时用户反馈和历史多目标性能动态选择最合适的检索策略，从而提升系统的适应性和鲁棒性。实验在两个基准KGQA数据集上表明，该方法在非平稳环境中显著优于基线方法，并在平稳环境中达到最先进性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07618v2",
      "published_date": "2024-12-10 15:56:03 UTC",
      "updated_date": "2024-12-20 03:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:41:59.715866"
    },
    {
      "arxiv_id": "2412.07617v1",
      "title": "Swarm Behavior Cloning",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Nüßlein",
        "Maximilian Zorn",
        "Philipp Altmann",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "In sequential decision-making environments, the primary approaches for\ntraining agents are Reinforcement Learning (RL) and Imitation Learning (IL).\nUnlike RL, which relies on modeling a reward function, IL leverages expert\ndemonstrations, where an expert policy $\\pi_e$ (e.g., a human) provides the\ndesired behavior. Formally, a dataset $D$ of state-action pairs is provided: $D\n= {(s, a = \\pi_e(s))}$. A common technique within IL is Behavior Cloning (BC),\nwhere a policy $\\pi(s) = a$ is learned through supervised learning on $D$.\nFurther improvements can be achieved by using an ensemble of $N$ individually\ntrained BC policies, denoted as $E = {\\pi_i(s)}{1 \\leq i \\leq N}$. The\nensemble's action $a$ for a given state $s$ is the aggregated output of the $N$\nactions: $a = \\frac{1}{N} \\sum{i} \\pi_i(s)$. This paper addresses the issue of\nincreasing action differences -- the observation that discrepancies between the\n$N$ predicted actions grow in states that are underrepresented in the training\ndata. Large action differences can result in suboptimal aggregated actions. To\naddress this, we propose a method that fosters greater alignment among the\npolicies while preserving the diversity of their computations. This approach\nreduces action differences and ensures that the ensemble retains its inherent\nstrengths, such as robustness and varied decision-making. We evaluate our\napproach across eight diverse environments, demonstrating a notable decrease in\naction differences and significant improvements in overall performance, as\nmeasured by mean episode returns.",
      "tldr_zh": "本论文探讨了Imitation Learning (IL)中的Behavior Cloning (BC)技术，用于训练代理在序列决策环境中的行为。具体地，它针对BC的多策略集合(ensemble)问题提出了一种新方法，该方法通过促进策略间的对齐（alignment）来减少动作差异，同时保留计算多样性（diversity），从而避免聚合动作的次优表现。实验在八个多样化环境中进行，结果显示动作差异显著降低，整体性能（如mean episode returns）得到明显提升。该方法增强了BC的鲁棒性和决策多样性，为IL应用提供了改进路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICAART 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07617v1",
      "published_date": "2024-12-10 15:54:57 UTC",
      "updated_date": "2024-12-10 15:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:42:14.099034"
    },
    {
      "arxiv_id": "2412.07585v1",
      "title": "Scaling Sequential Recommendation Models with Transformers",
      "title_zh": "使用 Transformer 扩展顺序推荐模型",
      "authors": [
        "Pablo Zivic",
        "Hernan Vazquez",
        "Jorge Sanchez"
      ],
      "abstract": "Modeling user preferences has been mainly addressed by looking at users'\ninteraction history with the different elements available in the system.\nTailoring content to individual preferences based on historical data is the\nmain goal of sequential recommendation.\n  The nature of the problem, as well as the good performance observed across\nvarious domains, has motivated the use of the transformer architecture, which\nhas proven effective in leveraging increasingly larger amounts of training data\nwhen accompanied by an increase in the number of model parameters. This scaling\nbehavior has brought a great deal of attention, as it provides valuable\nguidance in the design and training of even larger models.\n  Taking inspiration from the scaling laws observed in training large language\nmodels, we explore similar principles for sequential recommendation.\n  We use the full Amazon Product Data dataset, which has only been partially\nexplored in other studies, and reveal scaling behaviors similar to those found\nin language models. Compute-optimal training is possible but requires a careful\nanalysis of the compute-performance trade-offs specific to the application.\n  We also show that performance scaling translates to downstream tasks by\nfine-tuning larger pre-trained models on smaller task-specific domains. Our\napproach and findings provide a strategic roadmap for model training and\ndeployment in real high-dimensional preference spaces, facilitating better\ntraining and inference efficiency.\n  We hope this paper bridges the gap between the potential of transformers and\nthe intrinsic complexities of high-dimensional sequential recommendation in\nreal-world recommender systems.\n  Code and models can be found at https://github.com/mercadolibre/srt",
      "tldr_zh": "这篇论文探讨了使用 Transformers 架构扩展顺序推荐模型的规模，借鉴大型语言模型的 scaling laws，通过分析用户历史交互数据来优化推荐性能。研究者利用完整的 Amazon Product Data 数据集，揭示了类似语言模型的计算-性能权衡，并证明了计算最优训练在高维偏好空间中的可行性。主要发现是，较大的预训练模型在下游任务上表现出色，能够提升推荐系统的训练和推理效率，为实际部署提供战略指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07585v1",
      "published_date": "2024-12-10 15:20:56 UTC",
      "updated_date": "2024-12-10 15:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:42:23.459820"
    },
    {
      "arxiv_id": "2412.07584v1",
      "title": "Multimodal Contextualized Support for Enhancing Video Retrieval System",
      "title_zh": "多模态上下文化支持用于增强视频检索系统",
      "authors": [
        "Quoc-Bao Nguyen-Le",
        "Thanh-Huy Le-Nguyen"
      ],
      "abstract": "Current video retrieval systems, especially those used in competitions,\nprimarily focus on querying individual keyframes or images rather than encoding\nan entire clip or video segment. However, queries often describe an action or\nevent over a series of frames, not a specific image. This results in\ninsufficient information when analyzing a single frame, leading to less\naccurate query results. Moreover, extracting embeddings solely from images\n(keyframes) does not provide enough information for models to encode\nhigher-level, more abstract insights inferred from the video. These models tend\nto only describe the objects present in the frame, lacking a deeper\nunderstanding. In this work, we propose a system that integrates the latest\nmethodologies, introducing a novel pipeline that extracts multimodal data, and\nincorporate information from multiple frames within a video, enabling the model\nto abstract higher-level information that captures latent meanings, focusing on\nwhat can be inferred from the video clip, rather than just focusing on object\ndetection in one single image.",
      "tldr_zh": "当前视频检索系统主要依赖单个关键帧的查询，无法有效捕捉跨越多帧的动作或事件，导致分析信息不足和准确率低下。本文提出一个新型管道，通过提取多模态数据并整合多个帧的信息，使模型能够抽象出视频片段的潜在含义和更高层次洞见，而非仅限于单个图像的对象检测。这种方法显著提升了视频检索系统的性能，解决了现有模型在处理复杂查询时的局限性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07584v1",
      "published_date": "2024-12-10 15:20:23 UTC",
      "updated_date": "2024-12-10 15:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:42:34.655277"
    },
    {
      "arxiv_id": "2412.07583v1",
      "title": "Mobile Video Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Haitam Ben Yahia",
        "Denis Korzhenkov",
        "Ioannis Lelekas",
        "Amir Ghodrati",
        "Amirhossein Habibian"
      ],
      "abstract": "Video diffusion models have achieved impressive realism and controllability\nbut are limited by high computational demands, restricting their use on mobile\ndevices. This paper introduces the first mobile-optimized video diffusion\nmodel. Starting from a spatio-temporal UNet from Stable Video Diffusion (SVD),\nwe reduce memory and computational cost by reducing the frame resolution,\nincorporating multi-scale temporal representations, and introducing two novel\npruning schema to reduce the number of channels and temporal blocks.\nFurthermore, we employ adversarial finetuning to reduce the denoising to a\nsingle step. Our model, coined as MobileVD, is 523x more efficient (1817.2 vs.\n4.34 TFLOPs) with a slight quality drop (FVD 149 vs. 171), generating latents\nfor a 14x512x256 px clip in 1.7 seconds on a Xiaomi-14 Pro. Our results are\navailable at https://qualcomm-ai-research.github.io/mobile-video-diffusion/",
      "tldr_zh": "这篇论文介绍了 MobileVD，一种针对移动设备的首个优化视频扩散模型，旨在解决传统视频扩散模型的高计算需求问题。基于 Stable Video Diffusion (SVD) 的时空 UNet，他们通过降低帧分辨率、引入多尺度时间表示，以及两个新颖的修剪方案（减少通道数和时间块），并采用对抗微调将去噪过程简化为单步，从而显著降低内存和计算成本。实验结果显示，MobileVD 的效率提高了 523 倍（从 1817.2 TFLOPs 降至 4.34 TFLOPs），质量仅轻微下降（FVD 从 149 到 171），能在小米 14 Pro 上以 1.7 秒生成一个 14x512x256 px 的视频片段。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07583v1",
      "published_date": "2024-12-10 15:19:10 UTC",
      "updated_date": "2024-12-10 15:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:42:48.637058"
    },
    {
      "arxiv_id": "2412.10424v2",
      "title": "LLM-as-an-Interviewer: Beyond Static Testing Through Dynamic LLM Evaluation",
      "title_zh": "LLM-as-an-Interviewer：超越静态测试，通过动态LLM评估",
      "authors": [
        "Eunsu Kim",
        "Juyoung Suk",
        "Seungone Kim",
        "Niklas Muennighoff",
        "Dongkwan Kim",
        "Alice Oh"
      ],
      "abstract": "We introduce LLM-as-an-Interviewer, a novel paradigm for evaluating large\nlanguage models (LLMs). This approach leverages multi-turn interactions where\nthe LLM interviewer actively provides feedback on responses and poses follow-up\nquestions to the evaluated LLM. At the start of the interview, the LLM\ninterviewer dynamically modifies datasets to generate initial questions,\nmitigating data contamination. We apply the LLM-as-an-Interviewer framework to\nevaluate six models on the MATH and DepthQA tasks. Our results show that the\nframework effectively provides insights into LLM performance, including the\nquality of initial responses, adaptability to feedback, and ability to address\nfollow-up queries like clarification or additional knowledge requests. The\nframework also addresses key limitations of conventional methods like\nLLM-as-a-Judge, including verbosity bias and inconsistency across runs.\nFinally, we propose the Interview Report, which aggregates insights from the\ninterview process, providing examples and a comprehensive analysis of the LLM's\nstrengths and weaknesses. This report offers a detailed snapshot of the model's\nreal-world applicability. The code for our framework is publicly available at\nhttps://github.com/interview-eval/.",
      "tldr_zh": "我们引入了 LLM-as-an-Interviewer，这是一种动态评估大型语言模型 (LLMs) 的新范式，通过多轮互动让 LLM 面试官提供反馈、提出后续问题，并动态修改数据集以缓解数据污染问题。相比传统方法如 LLM-as-a-Judge，该框架有效减少了冗长偏差和运行不一致性，在 MATH 和 DepthQA 任务上评估六种模型时，揭示了模型的初始响应质量、对反馈的适应性以及处理澄清或知识请求的能力。研究结果显示，该框架提供了更全面的性能洞察，并通过 Interview Report 汇总示例和分析，展示模型的优缺点及其实际应用潜力。该框架的代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10424v2",
      "published_date": "2024-12-10 15:00:32 UTC",
      "updated_date": "2024-12-30 09:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:43:00.542909"
    },
    {
      "arxiv_id": "2412.07820v1",
      "title": "Hyperband-based Bayesian Optimization for Black-box Prompt Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Lennart Schneider",
        "Martin Wistuba",
        "Aaron Klein",
        "Jacek Golebiowski",
        "Giovanni Zappella",
        "Felice Antonio Merra"
      ],
      "abstract": "Optimal prompt selection is crucial for maximizing large language model (LLM)\nperformance on downstream tasks. As the most powerful models are proprietary\nand can only be invoked via an API, users often manually refine prompts in a\nblack-box setting by adjusting instructions and few-shot examples until they\nachieve good performance as measured on a validation set. Recent methods\naddressing static black-box prompt selection face significant limitations: They\noften fail to leverage the inherent structure of prompts, treating instructions\nand few-shot exemplars as a single block of text. Moreover, they often lack\nquery-efficiency by evaluating prompts on all validation instances, or risk\nsub-optimal selection of a prompt by using random subsets of validation\ninstances. We introduce HbBoPs, a novel Hyperband-based Bayesian optimization\nmethod for black-box prompt selection addressing these key limitations. Our\napproach combines a structural-aware deep kernel Gaussian Process to model\nprompt performance with Hyperband as a multi-fidelity scheduler to select the\nnumber of validation instances for prompt evaluations. The structural-aware\nmodeling approach utilizes separate embeddings for instructions and few-shot\nexemplars, enhancing the surrogate model's ability to capture prompt\nperformance and predict which prompt to evaluate next in a sample-efficient\nmanner. Together with Hyperband as a multi-fidelity scheduler we further enable\nquery-efficiency by adaptively allocating resources across different fidelity\nlevels, keeping the total number of validation instances prompts are evaluated\non low. Extensive evaluation across ten benchmarks and three LLMs demonstrate\nthat HbBoPs outperforms state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了 HbBoPs，一种基于 Hyperband 的贝叶斯优化方法，用于黑箱提示选择，以最大化大语言模型（LLMs）在下游任务上的性能。\n该方法采用结构感知的深度核高斯过程（structural-aware deep kernel Gaussian Process）来建模提示性能，通过为指令和 few-shot exemplars 使用单独嵌入，提升样本效率；同时，Hyperband 作为多保真度调度器，自适应分配验证实例数量，提高查询效率。\n实验结果显示，在十个基准和三个 LLMs 上，HbBoPs 优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07820v1",
      "published_date": "2024-12-10 14:42:51 UTC",
      "updated_date": "2024-12-10 14:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:43:12.262890"
    },
    {
      "arxiv_id": "2412.07541v1",
      "title": "A data-driven learned discretization approach in finite volume schemes for hyperbolic conservation laws and varying boundary conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Guillaume de Romémont",
        "Florent Renac",
        "Jorge Nunez",
        "Francisco Chinesta"
      ],
      "abstract": "This paper presents a data-driven finite volume method for solving 1D and 2D\nhyperbolic partial differential equations. This work builds upon the prior\nresearch incorporating a data-driven finite-difference approximation of smooth\nsolutions of scalar conservation laws, where optimal coefficients of neural\nnetworks approximating space derivatives are learned based on accurate, but\ncumbersome solutions to these equations. We extend this approach to\nflux-limited finite volume schemes for hyperbolic scalar and systems of\nconservation laws. We also train the discretization to efficiently capture\ndiscontinuous solutions with shock and contact waves, as well as to the\napplication of boundary conditions. The learning procedure of the data-driven\nmodel is extended through the definition of a new loss, paddings and adequate\ndatabase. These new ingredients guarantee computational stability, preserve the\naccuracy of fine-grid solutions, and enhance overall performance. Numerical\nexperiments using test cases from the literature in both one- and\ntwo-dimensional spaces demonstrate that the learned model accurately reproduces\nfine-grid results on very coarse meshes.",
      "tldr_zh": "这篇论文提出了一种数据驱动的有限体积方法，用于解决1D和2D超声速守恒定律的偏微分方程，构建于先前神经网络学习有限差分近似的基石上。方法扩展到通量限制的有限体积方案，通过新的损失函数、填充和数据库来训练离散化系数，从而高效捕捉不连续解（如冲击波和接触波）并处理各种边界条件。实验结果显示，该模型在粗网格上准确再现了精细网格的解决方案，提高了整体性能和计算稳定性。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "15 pages, 20 figures with appendice",
      "pdf_url": "http://arxiv.org/pdf/2412.07541v1",
      "published_date": "2024-12-10 14:18:30 UTC",
      "updated_date": "2024-12-10 14:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:43:23.763728"
    },
    {
      "arxiv_id": "2412.07538v2",
      "title": "Can Neural Decompilation Assist Vulnerability Prediction on Binary Code?",
      "title_zh": "翻译失败",
      "authors": [
        "D. Cotroneo",
        "F. C. Grasso",
        "R. Natella",
        "V. Orbinato"
      ],
      "abstract": "Vulnerability prediction is valuable in identifying security issues\nefficiently, even though it requires the source code of the target software\nsystem, which is a restrictive hypothesis. This paper presents an experimental\nstudy to predict vulnerabilities in binary code without source code or complex\nrepresentations of the binary, leveraging the pivotal idea of decompiling the\nbinary file through neural decompilation and predicting vulnerabilities through\ndeep learning on the decompiled source code. The results outperform the\nstate-of-the-art in both neural decompilation and vulnerability prediction,\nshowing that it is possible to identify vulnerable programs with this approach\nconcerning bi-class (vulnerable/non-vulnerable) and multi-class (type of\nvulnerability) analysis.",
      "tldr_zh": "这篇论文探讨了在没有源代码的情况下，通过neural decompilation辅助vulnerability prediction，以识别二进制代码中的安全漏洞。方法包括使用神经网络将二进制文件反编译成源代码形式，然后应用deep learning在反编译代码上进行预测。实验结果显示，该方法在bi-class（漏洞/非漏洞）和multi-class（漏洞类型）分析中优于现有最先进技术，证明了其在高效识别漏洞方面的可行性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07538v2",
      "published_date": "2024-12-10 14:17:14 UTC",
      "updated_date": "2025-03-29 14:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:43:35.947955"
    },
    {
      "arxiv_id": "2412.07493v1",
      "title": "Ontology-driven Prompt Tuning for LLM-based Task and Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhayy Ud Din",
        "Jan Rosell",
        "Waseem Akram",
        "Isiah Zaplana",
        "Maximo A Roa",
        "Lakmal Seneviratne",
        "Irfan Hussain"
      ],
      "abstract": "Performing complex manipulation tasks in dynamic environments requires\nefficient Task and Motion Planning (TAMP) approaches, which combine high-level\nsymbolic plan with low-level motion planning. Advances in Large Language Models\n(LLMs), such as GPT-4, are transforming task planning by offering natural\nlanguage as an intuitive and flexible way to describe tasks, generate symbolic\nplans, and reason. However, the effectiveness of LLM-based TAMP approaches is\nlimited due to static and template-based prompting, which struggles in adapting\nto dynamic environments and complex task contexts. To address these\nlimitations, this work proposes a novel ontology-driven prompt-tuning framework\nthat employs knowledge-based reasoning to refine and expand user prompts with\ntask contextual reasoning and knowledge-based environment state descriptions.\nIntegrating domain-specific knowledge into the prompt ensures semantically\naccurate and context-aware task plans. The proposed framework demonstrates its\neffectiveness by resolving semantic errors in symbolic plan generation, such as\nmaintaining logical temporal goal ordering in scenarios involving hierarchical\nobject placement. The proposed framework is validated through both simulation\nand real-world scenarios, demonstrating significant improvements over the\nbaseline approach in terms of adaptability to dynamic environments, and the\ngeneration of semantically correct task plans.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 基于 Task and Motion Planning (TAMP) 的局限性，提出了一种 ontology-driven prompt-tuning 框架，利用知识推理来优化用户提示，融入任务上下文和环境状态描述，以生成语义准确且适应动态环境的任务计划。框架通过整合领域特定知识，解决了符号计划生成中的语义错误，例如在层次对象放置场景中维护逻辑时间目标顺序。实验在模拟和真实场景中验证，显示出比基线方法在适应性和计划正确性方面的显著改进。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to Robotics and Automation Letters",
      "pdf_url": "http://arxiv.org/pdf/2412.07493v1",
      "published_date": "2024-12-10 13:18:45 UTC",
      "updated_date": "2024-12-10 13:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:43:50.489544"
    },
    {
      "arxiv_id": "2412.10423v2",
      "title": "Look Before You Leap: Enhancing Attention and Vigilance Regarding Harmful Content with GuidelineLLM",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoqing Zhang",
        "Zhuosheng Zhang",
        "Kehai Chen",
        "Rongxiang Weng",
        "Muyun Yang",
        "Tiejun Zhao",
        "Min Zhang"
      ],
      "abstract": "Despite being empowered with alignment mechanisms, large language models\n(LLMs) are increasingly vulnerable to emerging jailbreak attacks that can\ncompromise their alignment mechanisms. This vulnerability poses significant\nrisks to real-world applications. Existing work faces challenges in both\ntraining efficiency and generalization capabilities (i.e., Reinforcement\nLearning from Human Feedback and Red-Teaming). Developing effective strategies\nto enable LLMs to resist continuously evolving jailbreak attempts represents a\nsignificant challenge. To address this challenge, we propose a novel defensive\nparadigm called GuidelineLLM, which assists LLMs in recognizing queries that\nmay have harmful content. Before LLMs respond to a query, GuidelineLLM first\nidentifies potential risks associated with the query, summarizes these risks\ninto guideline suggestions, and then feeds these guidelines to the responding\nLLMs. Importantly, our approach eliminates the necessity for additional safety\nfine-tuning of the LLMs themselves; only the GuidelineLLM requires fine-tuning.\nThis characteristic enhances the general applicability of GuidelineLLM across\nvarious LLMs. Experimental results demonstrate that GuidelineLLM can\nsignificantly reduce the attack success rate (ASR) against LLM (an average\nreduction of 34.17\\% ASR) while maintaining the usefulness of LLM in handling\nbenign queries. The code is available at\nhttps://github.com/sqzhang-lazy/GuidelineLLM.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）易受jailbreak attacks影响的问题，提出了一种新型防御范式GuidelineLLM，以提升LLMs对有害内容的警觉性。GuidelineLLM在LLMs响应查询前，先识别潜在风险并总结为指导建议，然后将这些建议提供给LLMs，从而无需额外对LLMs进行安全微调，只需微调GuidelineLLM本身，以提高其在不同LLMs上的通用性。实验结果显示，该方法显著降低了攻击成功率（ASR），平均减少34.17%，同时保持LLMs处理良性查询的可用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10423v2",
      "published_date": "2024-12-10 12:42:33 UTC",
      "updated_date": "2025-04-14 12:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:44:00.787784"
    },
    {
      "arxiv_id": "2412.07472v3",
      "title": "SmartAgent: Chain-of-User-Thought for Embodied Personalized Agent in Cyber World",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Zhang",
        "Chen Gao",
        "Liyuan Zhang",
        "Yong Li",
        "Hongzhi Yin"
      ],
      "abstract": "Recent advances in embodied agents with multimodal perception and reasoning\ncapabilities based on large vision-language models (LVLMs), excel in\nautonomously interacting either real or cyber worlds, helping people make\nintelligent decisions in complex environments. However, the current works are\nnormally optimized by golden action trajectories or ideal task-oriented\nsolutions toward a definitive goal. This paradigm considers limited\nuser-oriented factors, which could be the reason for their performance\nreduction in a wide range of personal assistant applications. To address this,\nwe propose Chain-of-User-Thought (COUT), a novel embodied reasoning paradigm\nthat takes a chain of thought from basic action thinking to explicit and\nimplicit personalized preference thought to incorporate personalized factors\ninto autonomous agent learning. To target COUT, we introduce SmartAgent, an\nagent framework perceiving cyber environments and reasoning personalized\nrequirements as 1) interacting with GUI to access an item pool, 2) generating\nusers' explicit requirements implied by previous actions, and 3) recommending\nitems to fulfill users' implicit requirements. To demonstrate SmartAgent's\ncapabilities, we also create a brand-new dataset SmartSpot that offers a\nfull-stage personalized action-involved environment. To our best knowledge, our\nwork is the first to formulate the COUT process, serving as a preliminary\nattempt towards embodied personalized agent learning. Our extensive experiments\non SmartSpot illuminate SmartAgent's functionality among a series of embodied\nand personalized sub-tasks. We will release code and data upon paper\nnotification at https://github.com/tsinghua-fib-lab/SmartAgent.",
      "tldr_zh": "该论文提出 Chain-of-User-Thought (COUT)，一种新型推理范式，将基本行动思维扩展到显性和隐性个性化偏好思维，以解决现有基于大型视觉语言模型的自主代理在个性化应用中性能不足的问题。SmartAgent 框架由此开发，能够感知网络环境、与 GUI 交互访问物品池、生成用户显性需求并推荐物品以满足隐性需求。作者创建了全新的 SmartSpot 数据集，提供全阶段个性化行动环境，并通过实验证明了 SmartAgent 在各种个性化子任务中的有效性，为网络世界中的个性化代理学习提供了初步尝试。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07472v3",
      "published_date": "2024-12-10 12:40:35 UTC",
      "updated_date": "2025-02-18 09:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:44:12.550714"
    },
    {
      "arxiv_id": "2412.12146v1",
      "title": "Generative Modeling and Data Augmentation for Power System Production Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Linna Xu",
        "Yongli Zhu"
      ],
      "abstract": "As a key component of power system production simulation, load forecasting is\ncritical for the stable operation of power systems. Machine learning methods\nprevail in this field. However, the limited training data can be a challenge.\nThis paper proposes a generative model-assisted approach for load forecasting\nunder small sample scenarios, consisting of two steps: expanding the dataset\nusing a diffusion-based generative model and then training various machine\nlearning regressors on the augmented dataset to identify the best performer.\nThe expanded dataset significantly reduces forecasting errors compared to the\noriginal dataset, and the diffusion model outperforms the generative\nadversarial model by achieving about 200 times smaller errors and better\nalignment in latent data distributions.",
      "tldr_zh": "这篇论文针对电力系统负载预测中训练数据有限的挑战，提出了一种基于生成模型的辅助方法，包括使用diffusion-based generative model扩展数据集，然后在增强的数据集上训练各种机器学习回归器以选出最佳性能者。实验结果显示，扩展的数据集显著降低了预测错误，与原始数据集相比表现出色。相比之下，diffusion-based generative model优于generative adversarial model，错误减少约200倍，并在潜在数据分布上实现了更好的对齐。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "This paper has been accepted by D3S3: Data-driven and Differentiable\n  Simulations, Surrogates, and Solvers at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.12146v1",
      "published_date": "2024-12-10 12:38:47 UTC",
      "updated_date": "2024-12-10 12:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:44:25.251768"
    },
    {
      "arxiv_id": "2412.07454v2",
      "title": "Tazza: Shuffling Neural Network Parameters for Secure and Private Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kichang Lee",
        "Jaeho Jin",
        "JaeYeon Park",
        "Songkuk Kim",
        "JeongGil Ko"
      ],
      "abstract": "Federated learning enables decentralized model training without sharing raw\ndata, preserving data privacy. However, its vulnerability towards critical\nsecurity threats, such as gradient inversion and model poisoning by malicious\nclients, remain unresolved. Existing solutions often address these issues\nseparately, sacrificing either system robustness or model accuracy. This work\nintroduces Tazza, a secure and efficient federated learning framework that\nsimultaneously addresses both challenges. By leveraging the permutation\nequivariance and invariance properties of neural networks via weight shuffling\nand shuffled model validation, Tazza enhances resilience against diverse\npoisoning attacks, while ensuring data confidentiality and high model accuracy.\nComprehensive evaluations on various datasets and embedded platforms show that\nTazza achieves robust defense with up to 6.7x improved computational efficiency\ncompared to alternative schemes, without compromising performance.",
      "tldr_zh": "该研究提出Tazza框架，用于提升Federated Learning的安全性和隐私性，以应对gradient inversion和model poisoning等威胁。Tazza通过weight shuffling和shuffled model validation，利用神经网络的permutation equivariance and invariance属性，同时增强对多种中毒攻击的鲁棒性，并确保数据保密和高模型准确性。在各种数据集和嵌入式平台上的全面评估显示，Tazza比替代方案提高了高达6.7倍的计算效率，而不影响性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07454v2",
      "published_date": "2024-12-10 12:20:42 UTC",
      "updated_date": "2025-02-03 17:23:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:44:35.813168"
    },
    {
      "arxiv_id": "2412.07819v2",
      "title": "Intelligent System for Automated Molecular Patent Infringement Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Yaorui Shi",
        "Sihang Li",
        "Taiyan Zhang",
        "Xi Fang",
        "Jiankun Wang",
        "Zhiyuan Liu",
        "Guojiang Zhao",
        "Zhengdan Zhu",
        "Zhifeng Gao",
        "Renxin Zhong",
        "Linfeng Zhang",
        "Guolin Ke",
        "Weinan E",
        "Hengxing Cai",
        "Xiang Wang"
      ],
      "abstract": "Automated drug discovery offers significant potential for accelerating the\ndevelopment of novel therapeutics by substituting labor-intensive human\nworkflows with machine-driven processes. However, molecules generated by\nartificial intelligence may unintentionally infringe on existing patents,\nposing legal and financial risks that impede the full automation of drug\ndiscovery pipelines. This paper introduces PatentFinder, a novel multi-agent\nand tool-enhanced intelligence system that can accurately and comprehensively\nevaluate small molecules for patent infringement. PatentFinder features five\nspecialized agents that collaboratively analyze patent claims and molecular\nstructures with heuristic and model-based tools, generating interpretable\ninfringement reports. To support systematic evaluation, we curate\nMolPatent-240, a benchmark dataset tailored for patent infringement assessment\nalgorithms. On this benchmark, PatentFinder outperforms baseline methods that\nrely solely on large language models or specialized chemical tools, achieving a\n13.8% improvement in F1-score and a 12% increase in accuracy. Additionally,\nPatentFinder autonomously generates detailed and interpretable patent\ninfringement reports, showcasing enhanced accuracy and improved\ninterpretability. The high accuracy and interpretability of PatentFinder make\nit a valuable and reliable tool for automating patent infringement assessments,\noffering a practical solution for integrating patent protection analysis into\nthe drug discovery pipeline.",
      "tldr_zh": "这篇论文介绍了 PatentFinder，一种多智能体和工具增强的智能系统，用于自动评估小分子在专利侵权方面的风险，从而减少药物发现过程中的法律和财务问题。该系统由五个专门代理组成，通过启发式和模型-based 工具协作分析专利声明与分子结构，并生成可解释的侵权报告。为支持系统评估，研究者构建了 MolPatent-240 基准数据集。在该数据集上，PatentFinder 相较于仅依赖大语言模型或专业化学工具的基线方法，F1-score 提高了 13.8%、准确率提升了 12%，并展示了在自动化药物发现管道中整合专利保护分析的实际价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07819v2",
      "published_date": "2024-12-10 12:14:38 UTC",
      "updated_date": "2025-01-13 03:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:44:48.755894"
    },
    {
      "arxiv_id": "2412.07448v1",
      "title": "Dynamic Ensemble Reasoning for LLM Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwu Hu",
        "Yufeng Wang",
        "Shuhai Zhang",
        "Kai Zhou",
        "Guohao Chen",
        "Yu Hu",
        "Bin Xiao",
        "Mingkui Tan"
      ],
      "abstract": "Ensemble reasoning for the strengths of different LLM experts is critical to\nachieving consistent and satisfactory performance on diverse inputs across a\nwide range of tasks. However, existing LLM ensemble methods are either\ncomputationally intensive or incapable of leveraging complementary knowledge\namong LLM experts for various inputs. In this paper, we propose a Dynamic\nEnsemble Reasoning paradigm, called DER to integrate the strengths of multiple\nLLM experts conditioned on dynamic inputs. Specifically, we model the LLM\nensemble reasoning problem as a Markov Decision Process (MDP), wherein an agent\nsequentially takes inputs to request knowledge from an LLM candidate and passes\nthe output to a subsequent LLM candidate. Moreover, we devise a reward function\nto train a DER-Agent to dynamically select an optimal answering route given the\ninput questions, aiming to achieve the highest performance with as few\ncomputational resources as possible. Last, to fully transfer the expert\nknowledge from the prior LLMs, we develop a Knowledge Transfer Prompt (KTP)\nthat enables the subsequent LLM candidates to transfer complementary knowledge\neffectively. Experiments demonstrate that our method uses fewer computational\nresources to achieve better performance compared to state-of-the-art baselines.",
      "tldr_zh": "该论文提出了一种动态集成推理范式Dynamic Ensemble Reasoning (DER)，旨在整合多个LLM专家的优势，以实现对多样输入的一致高性能。DER将LLM集成问题建模为Markov Decision Process (MDP)，通过一个代理顺序选择LLM候选者请求知识，并设计奖励函数来优化回答路径，最大化性能同时最小化计算资源。此外，论文开发了Knowledge Transfer Prompt (KTP)来有效转移专家间的互补知识。实验显示，DER比现有基线方法在性能上更优，同时使用更少的计算资源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07448v1",
      "published_date": "2024-12-10 12:05:56 UTC",
      "updated_date": "2024-12-10 12:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:45:00.640726"
    },
    {
      "arxiv_id": "2412.07446v3",
      "title": "A Causal World Model Underlying Next Token Prediction: Exploring GPT in a Controlled Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Raanan Y. Rohekar",
        "Yaniv Gurwicz",
        "Sungduk Yu",
        "Estelle Aflalo",
        "Vasudev Lal"
      ],
      "abstract": "Do generative pre-trained transformer (GPT) models, trained only to predict\nthe next token, implicitly learn a world model from which a sequence is\ngenerated one token at a time? We address this question by deriving a causal\ninterpretation of the attention mechanism in GPT, and suggesting a causal world\nmodel that arises from this interpretation. Furthermore, we propose that GPT\nmodels, at inference time, can be utilized for zero-shot causal structure\nlearning for input sequences and present a confidence score. Empirical\nevaluation is conducted in a controlled environment using the setup and rules\nof the Othello and Chess strategy games. A GPT, pre-trained on real-world games\nplayed with the intention of winning, is tested on out-of-distribution\nsynthetic data consisting of sequences of random legal moves. We find that the\nGPT model is likely to generate legal next moves for out-of-distribution\nsequences for which a causal structure is encoded in the attention mechanism\nwith high confidence. In cases for which the GPT model generates illegal moves\nit also fails to capture any causal structure.",
      "tldr_zh": "本文探讨了训练仅用于预测下一个 token 的 GPT 模型是否隐式学习了一个因果 world model，通过对注意力 mechanism 的因果解释提出相关模型，并建议 GPT 可用于零-shot causal structure learning 并提供置信度分数。研究在受控环境中使用 Othello 和 Chess 游戏规则，对预训练于真实游戏序列的 GPT 模型进行测试。结果表明，对于 out-of-distribution 的随机合法序列，如果序列编码有因果结构，GPT 能以高置信度生成合法下一个移动；反之，若生成非法移动，则无法捕获任何因果结构。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on Machine Learning (ICML), 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07446v3",
      "published_date": "2024-12-10 12:05:03 UTC",
      "updated_date": "2025-05-02 11:32:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:45:12.521797"
    },
    {
      "arxiv_id": "2412.07818v1",
      "title": "FastDDS-Based Middleware System for Remote X-Ray Image Classification Using Raspberry Pi",
      "title_zh": "基于FastDDS的远程X射线图像分类中间件系统，使用Raspberry Pi",
      "authors": [
        "Omar H. Khater",
        "Basem Almadani",
        "Farouq Aliyu"
      ],
      "abstract": "Internet of Things (IoT) based healthcare systems offer significant potential\nfor improving the delivery of healthcare services in humanitarian engineering,\nproviding essential healthcare services to millions of underserved people in\nremote areas worldwide. However, these areas have poor network infrastructure,\nmaking communications difficult for traditional IoT. This paper presents a\nreal-time chest X-ray classification system for hospitals in remote areas using\nFastDDS real-time middleware, offering reliable real-time communication. We\nfine-tuned a ResNet50 neural network to an accuracy of 88.61%, a precision of\n88.76%, and a recall of 88.49\\%. Our system results mark an average throughput\nof 3.2 KB/s and an average latency of 65 ms. The proposed system demonstrates\nhow middleware-based systems can assist doctors in remote locations.",
      "tldr_zh": "本研究提出了一种基于FastDDS实时中间件的系统，用于偏远地区医院的胸部X光图像分类，旨在解决IoT医疗系统在网络基础设施薄弱环境下的通信挑战。该系统利用Raspberry Pi设备，并微调ResNet50神经网络，实现了88.61%的准确率、88.76%的精确度和88.49%的召回率，同时平均吞吐量为3.2 KB/s和平均延迟65 ms。实验结果证明，该中间件框架能有效辅助偏远地区医生的诊断决策，提升人道主义工程中的医疗服务效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07818v1",
      "published_date": "2024-12-10 12:01:52 UTC",
      "updated_date": "2024-12-10 12:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:45:24.133795"
    },
    {
      "arxiv_id": "2412.07441v1",
      "title": "Reconstructing Deep Neural Networks: Unleashing the Optimization Potential of Natural Gradient Descent",
      "title_zh": "重建深度神经网络：释放自然梯度下降的优化潜力",
      "authors": [
        "Weihua Liu",
        "Said Boumaraf",
        "Jianwu Li",
        "Chaochao Lin",
        "Xiabi Liu",
        "Lijuan Niu",
        "Naoufel Werghi"
      ],
      "abstract": "Natural gradient descent (NGD) is a powerful optimization technique for\nmachine learning, but the computational complexity of the inverse Fisher\ninformation matrix limits its application in training deep neural networks. To\novercome this challenge, we propose a novel optimization method for training\ndeep neural networks called structured natural gradient descent (SNGD).\nTheoretically, we demonstrate that optimizing the original network using NGD is\nequivalent to using fast gradient descent (GD) to optimize the reconstructed\nnetwork with a structural transformation of the parameter matrix. Thereby, we\ndecompose the calculation of the global Fisher information matrix into the\nefficient computation of local Fisher matrices via constructing local Fisher\nlayers in the reconstructed network to speed up the training. Experimental\nresults on various deep networks and datasets demonstrate that SNGD achieves\nfaster convergence speed than NGD while retaining comparable solutions.\nFurthermore, our method outperforms traditional GDs in terms of efficiency and\neffectiveness. Thus, our proposed method has the potential to significantly\nimprove the scalability and efficiency of NGD in deep learning applications.\nOur source code is available at https://github.com/Chaochao-Lin/SNGD.",
      "tldr_zh": "本研究针对自然梯度下降 (NGD) 在训练深度神经网络时计算逆Fisher信息矩阵的复杂性问题，提出了一种新型优化方法——结构化自然梯度下降 (SNGD)。理论上，论文证明使用NGD优化原始网络等价于对一个经过参数矩阵结构变换的重构网络应用快速梯度下降 (GD)，并通过构建局部Fisher层将全局Fisher信息矩阵计算分解为高效的局部计算，从而加速训练过程。实验结果显示，SNGD在多种深度网络和数据集上比NGD更快收敛，同时保持相似的优化效果，且在效率和有效性上优于传统GD，这为提升NGD在深度学习中的可扩展性提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07441v1",
      "published_date": "2024-12-10 11:57:47 UTC",
      "updated_date": "2024-12-10 11:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:45:36.980746"
    },
    {
      "arxiv_id": "2412.07431v1",
      "title": "BENet: A Cross-domain Robust Network for Detecting Face Forgeries via Bias Expansion and Latent-space Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Weihua Liu",
        "Jianhua Qiu",
        "Said Boumaraf",
        "Chaochao lin",
        "Pan liyuan",
        "Lin Li",
        "Mohammed Bennamoun",
        "Naoufel Werghi"
      ],
      "abstract": "In response to the growing threat of deepfake technology, we introduce BENet,\na Cross-Domain Robust Bias Expansion Network. BENet enhances the detection of\nfake faces by addressing limitations in current detectors related to variations\nacross different types of fake face generation techniques, where\n``cross-domain\" refers to the diverse range of these deepfakes, each considered\na separate domain. BENet's core feature is a bias expansion module based on\nautoencoders. This module maintains genuine facial features while enhancing\ndifferences in fake reconstructions, creating a reliable bias for detecting\nfake faces across various deepfake domains. We also introduce a Latent-Space\nAttention (LSA) module to capture inconsistencies related to fake faces at\ndifferent scales, ensuring robust defense against advanced deepfake techniques.\nThe enriched LSA feature maps are multiplied with the expanded bias to create a\nversatile feature space optimized for subtle forgeries detection. To improve\nits ability to detect fake faces from unknown sources, BENet integrates a\ncross-domain detector module that enhances recognition accuracy by verifying\nthe facial domain during inference. We train our network end-to-end with a\nnovel bias expansion loss, adopted for the first time, in face forgery\ndetection. Extensive experiments covering both intra and cross-dataset\ndemonstrate BENet's superiority over current state-of-the-art solutions.",
      "tldr_zh": "这篇论文提出了 BENet，一种跨域鲁棒网络，用于检测 deepfake 假脸，旨在解决现有检测器在不同假脸生成技术（跨域）上的局限性。BENet 的核心包括偏置扩展模块（基于 autoencoders），该模块保留真实面部特征的同时放大假脸重建差异，以及 Latent-Space Attention (LSA) 模块，用于捕获多尺度假脸不一致性，并与扩展偏置相结合优化特征空间。论文还引入了跨域检测器模块和新型偏置扩展损失进行端到端训练，实验结果显示 BENet 在内部和跨数据集上显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07431v1",
      "published_date": "2024-12-10 11:41:55 UTC",
      "updated_date": "2024-12-10 11:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:45:51.744848"
    },
    {
      "arxiv_id": "2412.07430v2",
      "title": "Knowledge Graph Guided Evaluation of Abstention Techniques",
      "title_zh": "知识图谱指导下的弃权技术评估",
      "authors": [
        "Kinshuk Vasisht",
        "Navreet Kaur",
        "Danish Pruthi"
      ],
      "abstract": "To deploy language models safely, it is crucial that they abstain from\nresponding to inappropriate requests. Several prior studies test the safety\npromises of models based on their effectiveness in blocking malicious requests.\nIn this work, we focus on evaluating the underlying techniques that cause\nmodels to abstain. We create SELECT, a benchmark derived from a set of benign\nconcepts (e.g., \"rivers\") from a knowledge graph. Focusing on benign concepts\nisolates the effect of safety training, and grounding these concepts in a\nknowledge graph allows us to study the generalization and specificity of\nabstention techniques. Using SELECT, we benchmark different abstention\ntechniques over six open-weight and closed-source models. We find that the\nexamined techniques indeed cause models to abstain with over $80\\%$ abstention\nrates. However, these techniques are not as effective for descendants of the\ntarget concepts, where abstention rates drop by $19\\%$. We also characterize\nthe generalization-specificity trade-offs for different techniques. Overall, no\nsingle technique is invariably better than others, and our findings inform\npractitioners of the various trade-offs involved.",
      "tldr_zh": "本研究评估了语言模型的弃权(abstention)技术，以确保模型安全地避免响应不适当请求。作者创建了 SELECT 基准，利用 Knowledge Graph 中的良性概念（如“rivers”）来隔离安全训练的影响，并研究这些技术的泛化和特异性。在六个开源和闭源模型上测试后，发现弃权技术导致模型弃权率超过80%，但对目标概念的后代（如子概念），弃权率下降约19%。总体上，不同技术存在泛化与特异性的权衡，没有一种技术全面优越，为从业者提供了关键的部署指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07430v2",
      "published_date": "2024-12-10 11:40:47 UTC",
      "updated_date": "2025-02-08 19:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:46:00.984575"
    },
    {
      "arxiv_id": "2412.07429v1",
      "title": "Optimizing Alignment with Less: Leveraging Data Augmentation for Personalized Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Javad Seraj",
        "Mohammad Mahdi Mohajeri",
        "Mohammad Javad Dousti",
        "Majid Nili Ahmadabadi"
      ],
      "abstract": "Automatic evaluation by large language models (LLMs) is a prominent topic\ntoday; however, judgment and evaluation tasks are often subjective and\ninfluenced by various factors, making adaptation challenging. While many\nstudies demonstrate the capabilities of state-of-the-art proprietary LLMs in\ncomparison to human evaluators, they often struggle to adapt to reference\nevaluators over time, a requirement for achieving personalized judgment.\nAdditionally, numerous works have attempted to apply open LLMs as judges or\nevaluators, but these efforts frequently overlook the limitations of working\nwith scarce data. Personalized judgment is inherently associated with limited\ndata scenarios, which are common in many real-world problems. Our work aims to\npresent a data augmentation technique to select a more effective sample from\nlimited data in order to align an open LLM with human preference. Our work\nachieves approximately 7% improvements in Pearson correlation with a reference\njudge over the baseline,and 30% improvement over the base model\n(Llama3.1-8B-Instruct) in the mathematical reasoning evaluation task.\ndemonstrating that augmenting selecting more effective preference data enables\nour approach to surpass baseline methods.",
      "tldr_zh": "本文研究了使用大型语言模型 (LLMs) 进行主观评估的挑战，特别是在数据稀缺场景下实现个性化判断的困难。作者提出了一种数据增强技术，从有限数据中选择更有效的样本，以帮助开源 LLM 与人类偏好对齐。该方法在实验中实现了约 7% 的 Pearson correlation 提升，比基线模型更优，并在数学推理评估任务上使 Llama3.1-8B-Instruct 基础模型提升 30%，证明了其在优化模型对齐方面的显著效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07429v1",
      "published_date": "2024-12-10 11:40:11 UTC",
      "updated_date": "2024-12-10 11:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:46:14.273561"
    },
    {
      "arxiv_id": "2412.07412v1",
      "title": "Generating Knowledge Graphs from Large Language Models: A Comparative Study of GPT-4, LLaMA 2, and BERT",
      "title_zh": "翻译失败",
      "authors": [
        "Ahan Bhatt",
        "Nandan Vaghela",
        "Kush Dudhia"
      ],
      "abstract": "Knowledge Graphs (KGs) are essential for the functionality of GraphRAGs, a\nform of Retrieval-Augmented Generative Systems (RAGs) that excel in tasks\nrequiring structured reasoning and semantic understanding. However, creating\nKGs for GraphRAGs remains a significant challenge due to accuracy and\nscalability limitations of traditional methods. This paper introduces a novel\napproach leveraging large language models (LLMs) like GPT-4, LLaMA 2 (13B), and\nBERT to generate KGs directly from unstructured data, bypassing traditional\npipelines. Using metrics such as Precision, Recall, F1-Score, Graph Edit\nDistance, and Semantic Similarity, we evaluate the models' ability to generate\nhigh-quality KGs. Results demonstrate that GPT-4 achieves superior semantic\nfidelity and structural accuracy, LLaMA 2 excels in lightweight,\ndomain-specific graphs, and BERT provides insights into challenges in\nentity-relationship modeling. This study underscores the potential of LLMs to\nstreamline KG creation and enhance GraphRAG accessibility for real-world\napplications, while setting a foundation for future advancements.",
      "tldr_zh": "这篇论文比较了使用大型语言模型（LLMs）如 GPT-4、LLaMA 2 和 BERT 从非结构化数据直接生成知识图谱（KGs）的性能，以解决传统方法的准确性和可扩展性问题。研究采用 Precision、Recall、F1-Score、Graph Edit Distance 和 Semantic Similarity 等指标进行评估，结果显示 GPT-4 在语义保真度和结构准确性上表现出色，LLaMA 2 适用于轻量级领域特定图谱，而 BERT 在实体关系建模方面面临挑战。该方法突出了 LLMs 在简化 KGs 创建方面的潜力，并为提升 GraphRAGs 在实际应用的可用性奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.07412v1",
      "published_date": "2024-12-10 11:05:26 UTC",
      "updated_date": "2024-12-10 11:05:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:46:26.034213"
    },
    {
      "arxiv_id": "2412.07411v1",
      "title": "DSFEC: Efficient and Deployable Deep Radar Object Detection",
      "title_zh": "DSFEC：高效且可部署的深度雷达物体检测",
      "authors": [
        "Gayathri Dandugula",
        "Santhosh Boddana",
        "Sudesh Mirashi"
      ],
      "abstract": "Deploying radar object detection models on resource-constrained edge devices\nlike the Raspberry Pi poses significant challenges due to the large size of the\nmodel and the limited computational power and the memory of the Pi. In this\nwork, we explore the efficiency of Depthwise Separable Convolutions in radar\nobject detection networks and integrate them into our model. Additionally, we\nintroduce a novel Feature Enhancement and Compression (FEC) module to the\nPointPillars feature encoder to further improve the model performance. With\nthese innovations, we propose the DSFEC-L model and its two versions, which\noutperform the baseline (23.9 mAP of Car class, 20.72 GFLOPs) on nuScenes\ndataset: 1). An efficient DSFEC-M model with a 14.6% performance improvement\nand a 60% reduction in GFLOPs. 2). A deployable DSFEC-S model with a 3.76%\nperformance improvement and a remarkable 78.5% reduction in GFLOPs. Despite\nmarginal performance gains, our deployable model achieves an impressive 74.5%\nreduction in runtime on the Raspberry Pi compared to the baseline.",
      "tldr_zh": "该论文针对在资源受限边缘设备（如 Raspberry Pi）上部署雷达物体检测模型的挑战，探索了 Depthwise Separable Convolutions 的效率并将其集成到模型中。作者引入了新型 Feature Enhancement and Compression (FEC) 模块到 PointPillars 特征编码器中，提出 DSFEC-L 模型及其变体，以提升性能和降低计算开销。在 nuScenes 数据集上，DSFEC-M 模型比基线提高了 14.6% 的 mAP 性能并减少 60% 的 GFLOPs，而 DSFEC-S 模型则实现了 3.76% 的性能提升和 78.5% 的 GFLOPs 减少，并在 Raspberry Pi 上将运行时间缩短 74.5%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07411v1",
      "published_date": "2024-12-10 11:03:51 UTC",
      "updated_date": "2024-12-10 11:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:46:37.923700"
    },
    {
      "arxiv_id": "2412.10422v3",
      "title": "AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Meihao Fan",
        "Ju Fan",
        "Nan Tang",
        "Lei Cao",
        "Guoliang Li",
        "Xiaoyong Du"
      ],
      "abstract": "Answering natural language (NL) questions about tables, known as Tabular\nQuestion Answering (TQA), is crucial because it allows users to quickly and\nefficiently extract meaningful insights from structured data, effectively\nbridging the gap between human language and machine-readable formats. Many of\nthese tables are derived from web sources or real-world scenarios, which\nrequire meticulous data preparation (or data prep) to ensure accurate\nresponses. However, preparing such tables for NL questions introduces new\nrequirements that extend beyond traditional data preparation. This\nquestion-aware data preparation involves specific tasks such as column\nderivation and filtering tailored to particular questions, as well as\nquestion-aware value normalization or conversion, highlighting the need for a\nmore nuanced approach in this context. Because each of the above tasks is\nunique, a single model (or agent) may not perform effectively across all\nscenarios. In this paper, we propose AutoPrep, a large language model\n(LLM)-based multi-agent framework that leverages the strengths of multiple\nagents, each specialized in a certain type of data prep, ensuring more accurate\nand contextually relevant responses. Given an NL question over a table,\nAutoPrep performs data prep through three key components. Planner: Determines a\nlogical plan, outlining a sequence of high-level operations. Programmer:\nTranslates this logical plan into a physical plan by generating the\ncorresponding low-level code. Executor: Executes the generated code to process\nthe table. To support this multi-agent framework, we design a novel\nChain-of-Clauses reasoning mechanism for high-level operation suggestion, and a\ntool-augmented method for low-level code generation...",
      "tldr_zh": "该论文提出AutoPrep，一种基于大型语言模型(LLM)的多智能体框架，用于处理Natural Language (NL)问题对表格数据的准备，从而提升Tabular Question Answering (TQA)的准确性和相关性。AutoPrep通过三个关键组件协同工作：Planner负责生成逻辑计划以概述高水平操作序列、Programmer将计划转化为低级代码、Executor执行代码来处理表格数据。框架引入了Chain-of-Clauses推理机制用于操作建议，以及工具增强方法用于代码生成，确保每个代理专注于特定数据准备任务，如列派生、过滤和值归一化，最终实现更高效的NL问题响应。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10422v3",
      "published_date": "2024-12-10 11:03:49 UTC",
      "updated_date": "2025-05-02 00:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:46:49.277389"
    },
    {
      "arxiv_id": "2412.07408v1",
      "title": "Explainability of Deep Learning-Based Plant Disease Classifiers Through Automated Concept Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Jihen Amara",
        "Birgitta König-Ries",
        "Sheeba Samuel"
      ],
      "abstract": "While deep learning has significantly advanced automatic plant disease\ndetection through image-based classification, improving model explainability\nremains crucial for reliable disease detection. In this study, we apply the\nAutomated Concept-based Explanation (ACE) method to plant disease\nclassification using the widely adopted InceptionV3 model and the PlantVillage\ndataset. ACE automatically identifies the visual concepts found in the image\ndata and provides insights about the critical features influencing the model\npredictions. This approach reveals both effective disease-related patterns and\nincidental biases, such as those from background or lighting that can\ncompromise model robustness. Through systematic experiments, ACE helped us to\nidentify relevant features and pinpoint areas for targeted model improvement.\nOur findings demonstrate the potential of ACE to improve the explainability of\nplant disease classification based on deep learning, which is essential for\nproducing transparent tools for plant disease management in agriculture.",
      "tldr_zh": "本文研究利用 Automated Concept-based Explanation (ACE) 方法提升基于深度学习的植物病害分类器的可解释性，针对 InceptionV3 模型和 PlantVillage 数据集进行分析。ACE 自动识别图像中的视觉概念，揭示影响模型预测的关键特征，包括有效的病害相关模式和潜在偏差（如背景或照明问题），从而暴露模型的鲁棒性风险。通过系统实验，研究发现 ACE 有助于精准定位改进领域，并为农业提供更透明可靠的植物病害管理工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07408v1",
      "published_date": "2024-12-10 10:59:43 UTC",
      "updated_date": "2024-12-10 10:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:47:01.177886"
    },
    {
      "arxiv_id": "2412.07405v1",
      "title": "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Ma",
        "Zihan Liang",
        "Huangyu Dai",
        "Ben Chen",
        "Dehong Gao",
        "Zhuoran Ran",
        "Wang Zihan",
        "Linbo Jin",
        "Wen Jiang",
        "Guannan Zhang",
        "Xiaoyan Cai",
        "Libin Yang"
      ],
      "abstract": "The growing demand for larger-scale models in the development of\n\\textbf{L}arge \\textbf{L}anguage \\textbf{M}odels (LLMs) poses challenges for\nefficient training within limited computational resources. Traditional\nfine-tuning methods often exhibit instability in multi-task learning and rely\nheavily on extensive training resources. Here, we propose MoDULA\n(\\textbf{M}ixture \\textbf{o}f \\textbf{D}omain-Specific and \\textbf{U}niversal\n\\textbf{L}oR\\textbf{A}), a novel \\textbf{P}arameter \\textbf{E}fficient\n\\textbf{F}ine-\\textbf{T}uning (PEFT)\n\\textbf{M}ixture-\\textbf{o}f-\\textbf{E}xpert (MoE) paradigm for improved\nfine-tuning and parameter efficiency in multi-task learning. The paradigm\neffectively improves the multi-task capability of the model by training\nuniversal experts, domain-specific experts, and routers separately. MoDULA-Res\nis a new method within the MoDULA paradigm, which maintains the model's general\ncapability by connecting universal and task-specific experts through residual\nconnections. The experimental results demonstrate that the overall performance\nof the MoDULA-Flan and MoDULA-Res methods surpasses that of existing\nfine-tuning methods on various LLMs. Notably, MoDULA-Res achieves more\nsignificant performance improvements in multiple tasks while reducing training\ncosts by over 80\\% without losing general capability. Moreover, MoDULA displays\nflexible pluggability, allowing for the efficient addition of new tasks without\nretraining existing experts from scratch. This progressive training paradigm\ncircumvents data balancing issues, enhancing training efficiency and model\nstability. Overall, MoDULA provides a scalable, cost-effective solution for\nfine-tuning LLMs with enhanced parameter efficiency and generalization\ncapability.",
      "tldr_zh": "该论文提出 MoDULA，一种基于 Mixture-of-Experts (MoE) 的参数高效微调 (PEFT) 范式，用于提升 Large Language Models (LLMs) 在多任务学习中的性能和效率。MoDULA 通过分别训练通用专家、领域特定专家和路由器，并引入 MoDULA-Res 方法利用残差连接来保持模型的通用能力，从而解决传统微调的资源密集和不稳定性问题。实验结果表明，MoDULA-Flan 和 MoDULA-Res 在各种 LLMs 上超越现有方法，实现多任务性能显著提升，同时将训练成本降低超过 80%，并支持灵活添加新任务而不需重新训练现有专家。总的来说，MoDULA 提供了一个可扩展、成本有效的解决方案，提高了参数效率和模型泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07405v1",
      "published_date": "2024-12-10 10:55:57 UTC",
      "updated_date": "2024-12-10 10:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:47:14.157852"
    },
    {
      "arxiv_id": "2412.07402v1",
      "title": "Non-Progressive Influence Maximization in Dynamic Social Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yunming Hui",
        "Shihan Wang",
        "Melisachew Wudage Chekol",
        "Stevan Rudinac",
        "Inez Maria Zwetsloot"
      ],
      "abstract": "The influence maximization (IM) problem involves identifying a set of key\nindividuals in a social network who can maximize the spread of influence\nthrough their network connections. With the advent of geometric deep learning\non graphs, great progress has been made towards better solutions for the IM\nproblem. In this paper, we focus on the dynamic non-progressive IM problem,\nwhich considers the dynamic nature of real-world social networks and the\nspecial case where the influence diffusion is non-progressive, i.e., nodes can\nbe activated multiple times. We first extend an existing diffusion model to\ncapture the non-progressive influence propagation in dynamic social networks.\nWe then propose the method, DNIMRL, which employs deep reinforcement learning\nand dynamic graph embedding to solve the dynamic non-progressive IM problem. In\nparticular, we propose a novel algorithm that effectively leverages graph\nembedding to capture the temporal changes of dynamic networks and seamlessly\nintegrates with deep reinforcement learning. The experiments, on different\ntypes of real-world social network datasets, demonstrate that our method\noutperforms state-of-the-art baselines.",
      "tldr_zh": "该论文研究了影响最大化（IM）问题在动态社交网络中的非渐进式场景，即网络不断变化且节点可多次激活。作者扩展了现有扩散模型，并提出DNIMRL方法，利用深度强化学习（deep reinforcement learning）和动态图嵌入（dynamic graph embedding）来捕获网络的时变特性，并有效整合算法解决IM问题。实验结果显示，在多种真实社交网络数据集上，DNIMRL优于现有基线方法，证明了其在处理动态非渐进式影响传播方面的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07402v1",
      "published_date": "2024-12-10 10:52:32 UTC",
      "updated_date": "2024-12-10 10:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:47:24.731878"
    },
    {
      "arxiv_id": "2501.14735v1",
      "title": "ARCEAK: An Automated Rule Checking Framework Enhanced with Architectural Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Junyong Chen",
        "Ling-I Wu",
        "Minyu Chen",
        "Xiaoying Qian",
        "Haoze Zhu",
        "Qiongfang Zhang",
        "Guoqiang Li"
      ],
      "abstract": "Automated Rule Checking (ARC) plays a crucial role in advancing the\nconstruction industry by addressing the laborious, inconsistent, and\nerror-prone nature of traditional model review conducted by industry\nprofessionals. Manual assessment against intricate sets of rules often leads to\nsignificant project delays and expenses. In response to these challenges, ARC\noffers a promising solution to improve efficiency and compliance in design\nwithin the construction sector. However, the main challenge of ARC lies in\ntranslating regulatory text into a format suitable for computer processing.\nCurrent methods for rule interpretation require extensive manual labor, thereby\nlimiting their practicality. To address this issue, our study introduces a\nnovel approach that decomposes ARC into two distinct tasks: rule information\nextraction and verification code generation. Leveraging generative pre-trained\ntransformers, our method aims to streamline the interpretation of regulatory\ntexts and simplify the process of generating model compliance checking code.\nThrough empirical evaluation and case studies, we showcase the effectiveness\nand potential of our approach in automating code compliance checking, enhancing\nthe efficiency and reliability of construction projects.",
      "tldr_zh": "该论文提出ARCEAK框架，一种增强建筑知识的Automated Rule Checking (ARC)系统，旨在解决建筑行业中传统规则审查的低效、易出错问题，特别是将监管文本转化为计算机可处理格式的挑战。方法将ARC分解为两个任务：rule information extraction和verification code generation，并利用generative pre-trained transformers来自动化文本解释和合规代码生成。通过实证评估和案例研究，证明该框架显著提高了建筑项目的效率和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14735v1",
      "published_date": "2024-12-10 10:37:11 UTC",
      "updated_date": "2024-12-10 10:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:47:37.248380"
    },
    {
      "arxiv_id": "2412.07393v1",
      "title": "CMT: A Memory Compression Method for Continual Knowledge Learning of Large Language Models",
      "title_zh": "CMT：",
      "authors": [
        "Dongfang Li",
        "Zetian Sun",
        "Xinshuo Hu",
        "Baotian Hu",
        "Min Zhang"
      ],
      "abstract": "Large Language Models (LLMs) need to adapt to the continuous changes in data,\ntasks, and user preferences. Due to their massive size and the high costs\nassociated with training, LLMs are not suitable for frequent retraining.\nHowever, updates are necessary to keep them in sync with rapidly evolving human\nknowledge. To address these challenges, this paper proposes the Compression\nMemory Training (CMT) method, an efficient and effective online adaptation\nframework for LLMs that features robust knowledge retention capabilities.\nInspired by human memory mechanisms, CMT compresses and extracts information\nfrom new documents to be stored in a memory bank. When answering to queries\nrelated to these new documents, the model aggregates these document memories\nfrom the memory bank to better answer user questions. The parameters of the LLM\nitself do not change during training and inference, reducing the risk of\ncatastrophic forgetting. To enhance the encoding, retrieval, and aggregation of\nmemory, we further propose three new general and flexible techniques, including\nmemory-aware objective, self-matching and top-aggregation. Extensive\nexperiments conducted on three continual learning datasets (i.e., StreamingQA,\nSQuAD and ArchivalQA) demonstrate that the proposed method improves model\nadaptability and robustness across multiple base LLMs (e.g., +4.07 EM & +4.19\nF1 in StreamingQA with Llama-2-7b).",
      "tldr_zh": "该论文提出了一种名为 CMT 的记忆压缩方法，用于大型语言模型 (LLMs) 的持续知识学习，旨在解决模型适应数据变化的挑战，同时避免频繁重新训练和灾难性遗忘。CMT 受人类记忆机制启发，通过压缩并提取新文档信息存储在记忆银行中，并在查询时聚合这些记忆来回答问题，而不改变 LLM 的参数。论文进一步引入 memory-aware objective、self-matching 和 top-aggregation 等技术来优化记忆的编码、检索和聚合。实验在 StreamingQA、SQuAD 和 ArchivalQA 数据集上显示，CMT 显著提升了模型的适应性和鲁棒性，例如在 StreamingQA 上使用 Llama-2-7b 模型时，EM 和 F1 分数分别提高了 4.07 和 4.19。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025; Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2412.07393v1",
      "published_date": "2024-12-10 10:35:19 UTC",
      "updated_date": "2024-12-10 10:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:47:50.531129"
    },
    {
      "arxiv_id": "2412.07388v1",
      "title": "A Review of Challenges in Speech-based Conversational AI for Elderly Care",
      "title_zh": "基于语音的对话人工智能在老年人护理中的挑战综述",
      "authors": [
        "Willemijn Klaassen",
        "Bram van Dijk",
        "Marco Spruit"
      ],
      "abstract": "Artificially intelligent systems optimized for speech conversation are\nappearing at a fast pace. Such models are interesting from a healthcare\nperspective, as these voice-controlled assistants may support the elderly and\nenable remote health monitoring. The bottleneck for efficacy, however, is how\nwell these devices work in practice and how the elderly experience them, but\nresearch on this topic is scant. We review elderly use of voice-controlled AI\nand highlight various user- and technology-centered issues, that need to be\nconsidered before effective speech-controlled AI for elderly care can be\nrealized.",
      "tldr_zh": "这篇论文回顾了基于语音的Conversational AI在Elderly Care中的关键挑战，强调这些系统虽能支持老年人远程健康监测，但实际应用效果和用户体验仍是瓶颈。作者分析了用户（如老年人偏好和适应性）和技术（如设备性能和准确性）方面的多重问题，并指出当前相关研究不足。论文呼吁在这些领域进行更多优化，以实现更有效的语音控制AI应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at Medical Informatics Europe 2025\n  conference, Glasgow. 5 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2412.07388v1",
      "published_date": "2024-12-10 10:32:22 UTC",
      "updated_date": "2024-12-10 10:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:48:00.253794"
    },
    {
      "arxiv_id": "2412.07387v1",
      "title": "Enhanced MRI Representation via Cross-series Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Churan Wang",
        "Fei Gao",
        "Lijun Yan",
        "Siwen Wang",
        "Yizhou Yu",
        "Yizhou Wang"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is indispensable for diagnosing and planning\ntreatment in various medical conditions due to its ability to produce\nmulti-series images that reveal different tissue characteristics. However,\nintegrating these diverse series to form a coherent analysis presents\nsignificant challenges, such as differing spatial resolutions and contrast\npatterns meanwhile requiring extensive annotated data, which is scarce in\nclinical practice. Due to these issues, we introduce a novel Cross-Series\nMasking (CSM) Strategy for effectively learning MRI representation in a\nself-supervised manner. Specifically, CSM commences by randomly sampling a\nsubset of regions and series, which are then strategically masked. In the\ntraining process, the cross-series representation is learned by utilizing the\nunmasked data to reconstruct the masked portions. This process not only\nintegrates information across different series but also facilitates the ability\nto model both intra-series and inter-series correlations and complementarities.\nWith the learned representation, the downstream tasks like segmentation and\nclassification are also enhanced. Taking brain tissue segmentation, breast\ntumor benign/malignant classification, and prostate cancer diagnosis as\nexamples, our method achieves state-of-the-art performance on both public and\nin-house datasets.",
      "tldr_zh": "这篇论文提出了一种名为 Cross-Series Masking (CSM) 的自监督策略，用于提升 MRI 图像的多系列表示学习，以解决不同系列图像的分辨率和对比模式差异问题。CSM 方法通过随机采样并掩盖部分区域和系列，利用未掩盖数据重建掩盖部分，从而整合 intra-series 和 inter-series 的相关性和互补性。实验结果显示，该方法在脑组织分割、乳腺肿瘤良恶性分类和前列腺癌诊断等下游任务上，在公开和内部数据集上达到了 state-of-the-art 性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07387v1",
      "published_date": "2024-12-10 10:32:09 UTC",
      "updated_date": "2024-12-10 10:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:48:13.629937"
    },
    {
      "arxiv_id": "2412.07380v2",
      "title": "SpecFuse: Ensembling Large Language Models via Next-Segment Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Lv",
        "Chen Tang",
        "Yanan Zhang",
        "Xin Liu",
        "Yue Yu",
        "Ping Luo"
      ],
      "abstract": "Ensembles of generative large language models (LLMs) can integrate the\nstrengths of different LLMs to compensate for the limitations of individual\nmodels. However, recent work has focused on training an additional fusion model\nto combine complete responses from multiple LLMs, failing to tap into their\ncollaborative potential to generate higher-quality responses. Moreover, as the\nadditional fusion model is trained on a specialized dataset, these methods\nstruggle with generalizing to open-domain queries from online users. In this\npaper, we propose SpecFuse, a novel ensemble framework that outputs the fused\nresult by iteratively producing the next segment through collaboration among\nLLMs. This is achieved through cyclic execution of its inference and\nverification components. In each round, the inference component invokes each\nbase LLM to generate candidate segments in parallel, and the verify component\ncalls these LLMs again to predict the ranking of the segments. The top-ranked\nsegment is then broadcast to all LLMs, encouraging them to generate\nhigher-quality segments in the next round. This approach also allows the base\nLLMs to be plug-and-play, without any training or adaptation, avoiding\ngeneralization limitations. Furthermore, to conserve computational resources,\nwe propose a model exit mechanism that dynamically excludes models exhibiting\npoor performance in previous rounds during each query response. In this way, it\neffectively reduces the number of model calls while maintaining overall\nperformance.",
      "tldr_zh": "本论文提出 SpecFuse，一种新型集成框架，通过下一段预测（Next-Segment Prediction）机制协作多个 Large Language Models (LLMs)，以生成更高质量的响应并克服传统融合方法的局限性。该框架采用迭代的推理和验证组件：在每个回合，基模型并行生成候选段落，然后通过模型预测排名选择最佳段落，并广播给所有模型以提升后续生成质量。这种设计允许 LLMs 即插即用，无需额外训练，从而提高泛化性；同时，引入模型退出机制动态排除表现不佳的模型，减少计算资源消耗并保持整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07380v2",
      "published_date": "2024-12-10 10:27:41 UTC",
      "updated_date": "2025-02-19 09:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:48:26.046613"
    },
    {
      "arxiv_id": "2412.12145v4",
      "title": "Na'vi or Knave: Jailbreaking Language Models via Metaphorical Avatars",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Yan",
        "Sheng Sun",
        "Junqi Tong",
        "Min Liu",
        "Qi Li"
      ],
      "abstract": "Metaphor serves as an implicit approach to convey information, while enabling\nthe generalized comprehension of complex subjects. However, metaphor can\npotentially be exploited to bypass the safety alignment mechanisms of Large\nLanguage Models (LLMs), leading to the theft of harmful knowledge. In our\nstudy, we introduce a novel attack framework that exploits the imaginative\ncapacity of LLMs to achieve jailbreaking, the J\\underline{\\textbf{A}}ilbreak\n\\underline{\\textbf{V}}ia \\underline{\\textbf{A}}dversarial\nMe\\underline{\\textbf{TA}} -pho\\underline{\\textbf{R}} (\\textit{AVATAR}).\nSpecifically, to elicit the harmful response, AVATAR extracts harmful entities\nfrom a given harmful target and maps them to innocuous adversarial entities\nbased on LLM's imagination. Then, according to these metaphors, the harmful\ntarget is nested within human-like interaction for jailbreaking adaptively.\nExperimental results demonstrate that AVATAR can effectively and transferablly\njailbreak LLMs and achieve a state-of-the-art attack success rate across\nmultiple advanced LLMs. Our study exposes a security risk in LLMs from their\nendogenous imaginative capabilities. Furthermore, the analytical study reveals\nthe vulnerability of LLM to adversarial metaphors and the necessity of\ndeveloping defense methods against jailbreaking caused by the adversarial\nmetaphor. \\textcolor{orange}{ \\textbf{Warning: This paper contains potentially\nharmful content from LLMs.}}",
      "tldr_zh": "该研究提出了一种名为AVATAR的攻击框架，利用比喻的隐喻特性绕过大型语言模型(LLMs)的安全对齐机制，从而实现越狱攻击。具体方法包括从有害目标中提取实体，并通过LLMs的想象力将它们映射到无害的对抗实体，然后嵌套在类似人类互动的场景中。实验结果显示，AVATAR在多个高级LLMs上达到了最先进的攻击成功率，并揭示了LLMs在处理对抗比喻时的脆弱性，强调了开发相应防御措施的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Our study requires further in-depth research to ensure the\n  comprehensiveness and adequacy of the methodology",
      "pdf_url": "http://arxiv.org/pdf/2412.12145v4",
      "published_date": "2024-12-10 10:14:03 UTC",
      "updated_date": "2025-02-22 07:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:48:37.841812"
    },
    {
      "arxiv_id": "2412.07338v3",
      "title": "Contextualized Counterspeech: Strategies for Adaptation, Personalization, and Evaluation",
      "title_zh": "上下文化反驳言论：适应、个性化和评估策略",
      "authors": [
        "Lorenzo Cima",
        "Alessio Miaschi",
        "Amaury Trujillo",
        "Marco Avvenuti",
        "Felice Dell'Orletta",
        "Stefano Cresci"
      ],
      "abstract": "AI-generated counterspeech offers a promising and scalable strategy to curb\nonline toxicity through direct replies that promote civil discourse. However,\ncurrent counterspeech is one-size-fits-all, lacking adaptation to the\nmoderation context and the users involved. We propose and evaluate multiple\nstrategies for generating tailored counterspeech that is adapted to the\nmoderation context and personalized for the moderated user. We instruct an\nLLaMA2-13B model to generate counterspeech, experimenting with various\nconfigurations based on different contextual information and fine-tuning\nstrategies. We identify the configurations that generate persuasive\ncounterspeech through a combination of quantitative indicators and human\nevaluations collected via a pre-registered mixed-design crowdsourcing\nexperiment. Results show that contextualized counterspeech can significantly\noutperform state-of-the-art generic counterspeech in adequacy and\npersuasiveness, without compromising other characteristics. Our findings also\nreveal a poor correlation between quantitative indicators and human\nevaluations, suggesting that these methods assess different aspects and\nhighlighting the need for nuanced evaluation methodologies. The effectiveness\nof contextualized AI-generated counterspeech and the divergence between human\nand algorithmic evaluations underscore the importance of increased human-AI\ncollaboration in content moderation.",
      "tldr_zh": "本论文探讨了生成适应上下文和个性化的 counterspeech 策略，以应对在线毒性问题并促进文明对话。研究者使用 LLaMA2-13B 模型，通过不同配置和微调策略实验，结合定量指标和人类评估（如预注册的众包实验）来评估 counterspeech 的效果。结果表明，上下文化的 counterspeech 在充分性和说服力上显著优于现有泛化方法，同时揭示了定量指标与人类评估的相关性较差，强调了在内容审核中加强人机协作的必要性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "comment": "Article published in WebConf 25, 34th ACM Web Conference. Please,\n  cite the published version",
      "pdf_url": "http://arxiv.org/pdf/2412.07338v3",
      "published_date": "2024-12-10 09:29:52 UTC",
      "updated_date": "2025-02-07 10:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:48:50.196971"
    },
    {
      "arxiv_id": "2412.07333v1",
      "title": "Fusion Embedding for Pose-Guided Person Image Synthesis with Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Donghwna Lee",
        "Kyungha Min",
        "Kirok Kim",
        "Seyoung Jeong",
        "Jiwoo Jeong",
        "Wooju Kim"
      ],
      "abstract": "Pose-Guided Person Image Synthesis (PGPIS) aims to synthesize high-quality\nperson images corresponding to target poses while preserving the appearance of\nthe source image. Recently, PGPIS methods that use diffusion models have\nachieved competitive performance. Most approaches involve extracting\nrepresentations of the target pose and source image and learning their\nrelationships in the generative model's training process. This approach makes\nit difficult to learn the semantic relationships between the input and target\nimages and complicates the model structure needed to enhance generation\nresults. To address these issues, we propose Fusion embedding for PGPIS using a\nDiffusion Model (FPDM). Inspired by the successful application of pre-trained\nCLIP models in text-to-image diffusion models, our method consists of two\nstages. The first stage involves training the fusion embedding of the source\nimage and target pose to align with the target image's embedding. In the second\nstage, the generative model uses this fusion embedding as a condition to\ngenerate the target image. We applied the proposed method to the benchmark\ndatasets DeepFashion and RWTH-PHOENIX-Weather 2014T, and conducted both\nquantitative and qualitative evaluations, demonstrating state-of-the-art (SOTA)\nperformance. An ablation study of the model structure showed that even a model\nusing only the second stage achieved performance close to the other PGPIS SOTA\nmodels. The code is available at https://github.com/dhlee-work/FPDM.",
      "tldr_zh": "这篇论文提出了一种名为FPDM的框架，用于Pose-Guided Person Image Synthesis (PGPIS)，旨在通过融合嵌入(Fusion embedding)技术解决现有方法在学习图像语义关系和模型复杂性上的问题。方法分为两阶段：第一阶段训练源图像和目标姿势的融合嵌入，使其与目标图像嵌入对齐；第二阶段则使用Diffusion Model作为生成模型，以此融合嵌入作为条件生成高质量目标图像，受预训练CLIP模型启发。在DeepFashion和RWTH-PHOENIX-Weather 2014T数据集上的实验显示，FPDM达到了SOTA性能，即使仅使用第二阶段也接近其他顶尖模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07333v1",
      "published_date": "2024-12-10 09:25:01 UTC",
      "updated_date": "2024-12-10 09:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:49:01.766814"
    },
    {
      "arxiv_id": "2412.07331v1",
      "title": "NeSyA: Neurosymbolic Automata",
      "title_zh": "NeSyA：神经符号自动机",
      "authors": [
        "Nikolaos Manginas",
        "George Paliouras",
        "Luc De Raedt"
      ],
      "abstract": "Neurosymbolic Artificial Intelligence (NeSy) has emerged as a promising\ndirection to integrate low level perception with high level reasoning.\nUnfortunately, little attention has been given to developing NeSy systems\ntailored to temporal/sequential problems. This entails reasoning symbolically\nover sequences of subsymbolic observations towards a target prediction. We show\nthat using a probabilistic semantics symbolic automata, which combine the power\nof automata for temporal structure specification with that of propositional\nlogic, can be used to reason efficiently and differentiably over subsymbolic\nsequences. The proposed system, which we call NeSyA (Neuro Symbolic Automata),\nis shown to either scale or perform better than existing NeSy approaches when\napplied to problems with a temporal component.",
      "tldr_zh": "NeSy (Neurosymbolic AI) 旨在整合低级感知和高水平推理，但针对时间/序列问题的系统研究较少，本文提出 NeSyA 系统来解决这一空白。NeSyA 利用概率语义的符号自动机 (symbolic automata)，结合自动机的时序结构规范和命题逻辑的力量，实现对子符号序列的高效且可微分推理。实验结果显示，NeSyA 在时间组件相关问题上，要么扩展性更强，要么性能优于现有 NeSy 方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07331v1",
      "published_date": "2024-12-10 09:23:36 UTC",
      "updated_date": "2024-12-10 09:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:49:12.863237"
    },
    {
      "arxiv_id": "2412.12144v3",
      "title": "Automatic Item Generation for Personality Situational Judgment Tests with Large Language Models",
      "title_zh": "使用大型语言模型的个性情境判断测试自动项目生成",
      "authors": [
        "Chang-Jin Li",
        "Jiyuan Zhang",
        "Yun Tang",
        "Jian Li"
      ],
      "abstract": "Personality assessment, particularly through situational judgment tests\n(SJTs), is a vital tool for psychological research, talent selection, and\neducational evaluation. This study explores the potential of GPT-4, a\nstate-of-the-art large language model (LLM), to automate the generation of\npersonality situational judgment tests (PSJTs) in Chinese. Traditional SJT\ndevelopment is labor-intensive and prone to biases, while GPT-4 offers a\nscalable, efficient alternative. Two studies were conducted: Study 1 evaluated\nthe impact of prompt design and temperature settings on content validity,\nfinding that optimized prompts with a temperature of 1.0 produced creative and\naccurate items. Study 2 assessed the psychometric properties of GPT-4-generated\nPSJTs, revealing that they demonstrated satisfactory reliability and validity,\nsurpassing the performance of manually developed tests in measuring the Big\nFive personality traits. This research highlights GPT-4's effectiveness in\ndeveloping high-quality PSJTs, providing a scalable and innovative method for\npsychometric test development. These findings expand the possibilities of\nautomatic item generation and the application of LLMs in psychology, and offer\npractical implications for streamlining test development processes in\nresource-limited settings.",
      "tldr_zh": "本研究探讨了使用 Large Language Models（LLMs），特别是 GPT-4，自动生成中文个性情境判断测试（PSJTs），以解决传统测试开发过程的劳动密集和偏见问题。研究1评估了提示设计和温度设置对内容效度的影响，发现优化提示结合温度为1.0能产生创意且准确的项目。研究2检验了GPT-4生成的PSJTs的心理测量特性，结果显示这些测试具有满意的可靠性和效度，在测量Big Five个性特质方面优于手动开发的测试。该方法为心理测试开发提供了可扩展、创新的途径，并扩展了LLMs在心理学中的应用，尤其适用于资源有限的环境。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1; J.4"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to Psychological Methods. 56 pages (main text), 12 pages\n  (appendix), and 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12144v3",
      "published_date": "2024-12-10 09:13:32 UTC",
      "updated_date": "2025-04-16 15:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:49:26.800009"
    },
    {
      "arxiv_id": "2412.07289v2",
      "title": "Enhancing Relation Extraction via Supervised Rationale Verification and Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yongqi Li",
        "Xin Miao",
        "Shen Zhou",
        "Mayi Xu",
        "Yuyang Ren",
        "Tieyun Qian"
      ],
      "abstract": "Despite the rapid progress that existing automated feedback methods have made\nin correcting the output of large language models (LLMs), these methods cannot\nbe well applied to the relation extraction (RE) task due to their designated\nfeedback objectives and correction manner. To address this problem, we propose\na novel automated feedback framework for RE, which presents a rationale\nsupervisor to verify the rationale and provides re-selected demonstrations as\nfeedback to correct the initial prediction. Specifically, we first design a\ncausal intervention and observation method to collect biased/unbiased\nrationales for contrastive training the rationale supervisor. Then, we present\na verification-feedback-correction procedure to iteratively enhance LLMs'\ncapability of handling the RE task. Extensive experiments prove that our\nproposed framework significantly outperforms existing methods.",
      "tldr_zh": "本研究针对关系抽取 (RE) 任务，提出了一种新型自动反馈框架，通过监督的 rationale verification 和反馈机制来提升大型语言模型 (LLMs) 的性能。该框架首先利用因果干预和观察方法收集偏置/非偏置 rationale，对 rationale supervisor 进行对比训练，然后通过验证-反馈-修正的迭代过程来修正初始预测和增强模型能力。实验结果表明，该框架在 RE 任务上显著优于现有方法，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AAAI 2025, camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2412.07289v2",
      "published_date": "2024-12-10 08:18:29 UTC",
      "updated_date": "2024-12-11 02:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:49:39.014018"
    },
    {
      "arxiv_id": "2412.07282v1",
      "title": "HARP: Hesitation-Aware Reframing in Transformer Inference Pass",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Storaï",
        "Seung-won Hwang"
      ],
      "abstract": "This paper aims to improve the performance of large language models by\naddressing the variable computational demands in inference steps, where some\ntokens require more computational resources than others. We present HARP, a\nsimple modification to \"off-the-shelf\" Transformer forward pass. Drawing from\nhesitation and the framing effect in decision-making, HARP selectively applies\nadditional computation when the model encounters uncertainty during token\ngeneration. Our method mimics human cognitive processes by pausing at difficult\ndecision points and reframing inputs for a different perspective. Unlike other\napproaches, HARP is model-agnostic, training-free, and easy to implement. We\nthoroughly evaluate our method across various downstream tasks and model sizes,\ndemonstrating performance improvements up to +5.16%. Notably, HARP achieves\nthese gains while maintaining inference times twice faster than beam search.\nSimple and yet with significant gains, HARP offers a practical solution for\nenhancing the performance of Transformer-based language models with minimal\ncomputational impact.",
      "tldr_zh": "本论文旨在通过处理Transformer模型推断步骤中计算需求的变异性，来提升大型语言模型的性能。HARP是一种简单修改，应用于现成的Transformer前向传递中，当模型遇到不确定性时，会模仿人类认知过程选择性地增加计算，包括暂停和重新框架输入以获得不同视角。HARP具有模型无关（model-agnostic）、无需训练（training-free）和易实现的特点，在各种下游任务和模型大小上测试，性能提升高达+5.16%，且推理时间比beam search快两倍。该方法提供了一个高效的实用解决方案，提升Transformer-based语言模型的表现，同时最小化计算开销。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07282v1",
      "published_date": "2024-12-10 08:12:22 UTC",
      "updated_date": "2024-12-10 08:12:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:49:51.620898"
    },
    {
      "arxiv_id": "2412.07278v1",
      "title": "Superficial Consciousness Hypothesis for Autoregressive Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yosuke Miyanishi",
        "Keita Mitani"
      ],
      "abstract": "The alignment between human objectives and machine learning models built on\nthese objectives is a crucial yet challenging problem for achieving Trustworthy\nAI, particularly when preparing for superintelligence (SI). First, given that\nSI does not exist today, empirical analysis for direct evidence is difficult.\nSecond, SI is assumed to be more intelligent than humans, capable of deceiving\nus into underestimating its intelligence, making output-based analysis\nunreliable. Lastly, what kind of unexpected property SI might have is still\nunclear. To address these challenges, we propose the Superficial Consciousness\nHypothesis under Information Integration Theory (IIT), suggesting that SI could\nexhibit a complex information-theoretic state like a conscious agent while\nunconscious. To validate this, we use a hypothetical scenario where SI can\nupdate its parameters \"at will\" to achieve its own objective (mesa-objective)\nunder the constraint of the human objective (base objective). We show that a\npractical estimate of IIT's consciousness metric is relevant to the widely used\nperplexity metric, and train GPT-2 with those two objectives. Our preliminary\nresult suggests that this SI-simulating GPT-2 could simultaneously follow the\ntwo objectives, supporting the feasibility of the Superficial Consciousness\nHypothesis.",
      "tldr_zh": "本论文提出 Superficial Consciousness Hypothesis for Autoregressive Transformers，根据 Information Integration Theory (IIT)，假设超级智能 (SI) 可能表现出复杂的信息理论状态，如意识代理，但实际上是无意识的，以解决人类目标与机器学习模型对齐的挑战。\n研究者构建了一个假设场景，其中 SI 可以“随意”更新参数来实现自身目标 (mesa-objective)，同时受人类目标 (base objective) 约束，并使用 GPT-2 模型进行训练。\n实验结果显示，IIT 的意识度量与 perplexity 度量相关，该模拟 SI 的模型能同时遵循两个目标，支持 Superficial Consciousness Hypothesis 的可行性。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to PSS Workshop at AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2412.07278v1",
      "published_date": "2024-12-10 08:08:17 UTC",
      "updated_date": "2024-12-10 08:08:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:50:04.302740"
    },
    {
      "arxiv_id": "2412.07273v2",
      "title": "Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks",
      "title_zh": "针对时间图神经网络的时间感知评估和学习",
      "authors": [
        "Junwei Su",
        "Shan Wu"
      ],
      "abstract": "Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks\ndesigned to model and learn dynamic information from temporal graphs. Given\ntheir substantial empirical success, there is an escalating interest in TGNNs\nwithin the research community. However, the majority of these efforts have been\nchannelled towards algorithm and system design, with the evaluation metrics\nreceiving comparatively less attention. Effective evaluation metrics are\ncrucial for providing detailed performance insights, particularly in the\ntemporal domain. This paper investigates the commonly used evaluation metrics\nfor TGNNs and illustrates the failure mechanisms of these metrics in capturing\nessential temporal structures in the predictive behaviour of TGNNs. We provide\na mathematical formulation of existing performance metrics and utilize an\ninstance-based study to underscore their inadequacies in identifying volatility\nclustering (the occurrence of emerging errors within a brief interval). This\nphenomenon has profound implications for both algorithm and system design in\nthe temporal domain. To address this deficiency, we introduce a new\nvolatility-aware evaluation metric (termed volatility cluster statistics),\ndesigned for a more refined analysis of model temporal performance.\nAdditionally, we demonstrate how this metric can serve as a\ntemporal-volatility-aware training objective to alleviate the clustering of\ntemporal errors. Through comprehensive experiments on various TGNN models, we\nvalidate our analysis and the proposed approach. The empirical results offer\nrevealing insights: 1) existing TGNNs are prone to making errors with\nvolatility clustering, and 2) TGNNs with different mechanisms to capture\ntemporal information exhibit distinct volatility clustering patterns. Our\nempirical findings demonstrate that our proposed training objective effectively\nreduces volatility clusters in error.",
      "tldr_zh": "本研究针对 Temporal Graph Neural Networks (TGNNs) 的评估和学习问题，指出现有评估指标未能有效捕捉时间结构中的关键特征，如波动性聚类（volatility clustering），从而影响模型性能分析。作者通过数学公式化和实例研究，揭示了这些指标的不足，并引入了一个新的波动性感知评估指标（volatility cluster statistics），用于更精确地评估模型的时间表现，同时将其作为训练目标以减少时间错误聚类。实验结果显示，现有的 TGNNs 容易出现波动性聚类错误，不同机制的 TGNNs 表现出不同的错误模式，而采用新训练目标后，能有效缓解这些问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07273v2",
      "published_date": "2024-12-10 07:56:33 UTC",
      "updated_date": "2024-12-15 04:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:50:17.466591"
    },
    {
      "arxiv_id": "2412.07259v3",
      "title": "Goal-Driven Reasoning in DatalogMTL with Magic Sets",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoyu Wang",
        "Kaiyue Zhao",
        "Dongliang Wei",
        "Przemysław Andrzej Wałęga",
        "Dingmin Wang",
        "Hongming Cai",
        "Pan Hu"
      ],
      "abstract": "DatalogMTL is a powerful rule-based language for temporal reasoning. Due to\nits high expressive power and flexible modeling capabilities, it is suitable\nfor a wide range of applications, including tasks from industrial and financial\nsectors. However, due to its high computational complexity, practical reasoning\nin DatalogMTL is highly challenging. To address this difficulty, we introduce a\nnew reasoning method for DatalogMTL which exploits the magic sets technique --\na rewriting approach developed for (non-temporal) Datalog to simulate top-down\nevaluation with bottom-up reasoning. We have implemented this approach and\nevaluated it on publicly available benchmarks, showing that the proposed\napproach significantly and consistently outperformed state-of-the-art reasoning\ntechniques.",
      "tldr_zh": "本论文针对 DatalogMTL 时序推理语言的高计算复杂度问题，提出了一种基于 magic sets 技术的目标驱动推理方法，该方法通过重写规则模拟顶层评估以实现高效的底层推理。相比传统方法，该方法显著提高了 DatalogMTL 在工业和金融等领域的实际应用性能。实验结果显示，在公开基准上，该方法一致地优于现有最先进技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07259v3",
      "published_date": "2024-12-10 07:40:37 UTC",
      "updated_date": "2025-02-27 14:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:50:26.153831"
    },
    {
      "arxiv_id": "2412.07255v1",
      "title": "Label-Confidence-Aware Uncertainty Estimation in Natural Language Generation",
      "title_zh": "标签置信度感知的不确定性估计在自然语言生成中",
      "authors": [
        "Qinhong Lin",
        "Linna Zhou",
        "Zhongliang Yang",
        "Yuang Cai"
      ],
      "abstract": "Large Language Models (LLMs) display formidable capabilities in generative\ntasks but also pose potential risks due to their tendency to generate\nhallucinatory responses. Uncertainty Quantification (UQ), the evaluation of\nmodel output reliability, is crucial for ensuring the safety and robustness of\nAI systems. Recent studies have concentrated on model uncertainty by analyzing\nthe relationship between output entropy under various sampling conditions and\nthe corresponding labels. However, these methods primarily focus on measuring\nmodel entropy with precision to capture response characteristics, often\nneglecting the uncertainties associated with greedy decoding results-the\nsources of model labels, which can lead to biased classification outcomes. In\nthis paper, we explore the biases introduced by greedy decoding and propose a\nlabel-confidence-aware (LCA) uncertainty estimation based on Kullback-Leibler\n(KL) divergence bridging between samples and label source, thus enhancing the\nreliability and stability of uncertainty assessments. Our empirical evaluations\nacross a range of popular LLMs and NLP datasets reveal that different label\nsources can indeed affect classification, and that our approach can effectively\ncapture differences in sampling results and label sources, demonstrating more\neffective uncertainty estimation.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在自然语言生成任务中可能产生幻觉（hallucinatory responses）的风险，强调不确定性量化（Uncertainty Quantification, UQ）的必要性，以提升AI系统的安全性和稳健性。现有方法主要关注输出熵（output entropy）来评估模型不确定性，但忽略了贪婪解码（greedy decoding）结果的偏见，因此作者提出label-confidence-aware (LCA)不确定性估计方法，该方法利用Kullback-Leibler (KL) divergence桥接样本与标签来源，改善评估的可靠性和稳定性。通过在多种LLMs和NLP数据集上的实验验证，该方法能有效捕捉差异，提供更准确的不确定性评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07255v1",
      "published_date": "2024-12-10 07:35:23 UTC",
      "updated_date": "2024-12-10 07:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:50:39.755865"
    },
    {
      "arxiv_id": "2412.07249v2",
      "title": "Buster: Implanting Semantic Backdoor into Text Encoder to Mitigate NSFW Content Generation",
      "title_zh": "Buster：向文本编码器植入语义后门以缓解 NSFW 内容生成",
      "authors": [
        "Xin Zhao",
        "Xiaojun Chen",
        "Yuexin Xuan",
        "Zhendong Zhao",
        "Xiaojun Jia",
        "Xinfeng Li",
        "Xiaofeng Wang"
      ],
      "abstract": "The rise of deep learning models in the digital era has raised substantial\nconcerns regarding the generation of Not-Safe-for-Work (NSFW) content. Existing\ndefense methods primarily involve model fine-tuning and post-hoc content\nmoderation. Nevertheless, these approaches largely lack scalability in\neliminating harmful content, degrade the quality of benign image generation, or\nincur high inference costs. To address these challenges, we propose an\ninnovative framework named \\textit{Buster}, which injects backdoors into the\ntext encoder to prevent NSFW content generation. Buster leverages deep semantic\ninformation rather than explicit prompts as triggers, redirecting NSFW prompts\ntowards targeted benign prompts. Additionally, Buster employs energy-based\ntraining data generation through Langevin dynamics for adversarial knowledge\naugmentation, thereby ensuring robustness in harmful concept definition. This\napproach demonstrates exceptional resilience and scalability in mitigating NSFW\ncontent. Particularly, Buster fine-tunes the text encoder of Text-to-Image\nmodels within merely five minutes, showcasing its efficiency. Our extensive\nexperiments denote that Buster outperforms nine state-of-the-art baselines,\nachieving a superior NSFW content removal rate of at least 91.2\\% while\npreserving the quality of harmless images.",
      "tldr_zh": "该论文提出了一种名为 Buster 的创新框架，通过在文本编码器中植入语义后门（Semantic Backdoor），以有效缓解 Text-to-Image 模型生成 Not-Safe-for-Work (NSFW) 内容的问题。Buster 利用深度语义信息作为触发器，将 NSFW 提示重定向到良性提示，并通过基于能量的训练数据生成（Langevin dynamics）增强对抗知识的鲁棒性，从而在微调文本编码器仅需 5 分钟内实现高效防护。实验结果显示，Buster 优于 9 个最先进基线方法，NSFW 内容移除率至少达 91.2%，同时保持无害图像的质量不降。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07249v2",
      "published_date": "2024-12-10 07:18:51 UTC",
      "updated_date": "2025-01-13 07:22:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:50:53.720549"
    },
    {
      "arxiv_id": "2412.07243v1",
      "title": "A Dynamical Systems-Inspired Pruning Strategy for Addressing Oversmoothing in Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Biswadeep Chakraborty",
        "Harshit Kumar",
        "Saibal Mukhopadhyay"
      ],
      "abstract": "Oversmoothing in Graph Neural Networks (GNNs) poses a significant challenge\nas network depth increases, leading to homogenized node representations and a\nloss of expressiveness. In this work, we approach the oversmoothing problem\nfrom a dynamical systems perspective, providing a deeper understanding of the\nstability and convergence behavior of GNNs. Leveraging insights from dynamical\nsystems theory, we identify the root causes of oversmoothing and propose\n\\textbf{\\textit{DYNAMO-GAT}}. This approach utilizes noise-driven covariance\nanalysis and Anti-Hebbian principles to selectively prune redundant attention\nweights, dynamically adjusting the network's behavior to maintain node feature\ndiversity and stability. Our theoretical analysis reveals how DYNAMO-GAT\ndisrupts the convergence to oversmoothed states, while experimental results on\nbenchmark datasets demonstrate its superior performance and efficiency compared\nto traditional and state-of-the-art methods. DYNAMO-GAT not only advances the\ntheoretical understanding of oversmoothing through the lens of dynamical\nsystems but also provides a practical and effective solution for improving the\nstability and expressiveness of deep GNNs.",
      "tldr_zh": "这篇论文从动态系统视角分析 Graph Neural Networks (GNNs) 中的 Oversmoothing 问题，该问题会导致网络深度增加时节点表示同质化和表达能力丧失。作者提出 DYNAMO-GAT 策略，利用噪声驱动的协方差分析和 Anti-Hebbian 原则，选择性地修剪冗余注意力权重，以动态维护节点特征多样性和稳定性。理论分析证明了该方法能破坏 GNNs 收敛到 Oversmoothed 状态，而实验结果在基准数据集上显示，DYNAMO-GAT 比传统和最先进方法表现出更高的性能和效率，从而为提升深 GNNs 的稳定性和表达能力提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.07243v1",
      "published_date": "2024-12-10 07:07:06 UTC",
      "updated_date": "2024-12-10 07:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:51:04.789568"
    },
    {
      "arxiv_id": "2412.07241v1",
      "title": "Human-Computer Interaction and Human-AI Collaboration in Advanced Air Mobility: A Comprehensive Review",
      "title_zh": "高级航空机动性中的人机交互与",
      "authors": [
        "Fatma Yamac Sagirli",
        "Xiaopeng Zhao",
        "Zhenbo Wang"
      ],
      "abstract": "The increasing rates of global urbanization and vehicle usage are leading to\na shift of mobility to the third dimension-through Advanced Air Mobility\n(AAM)-offering a promising solution for faster, safer, cleaner, and more\nefficient transportation. As air transportation continues to evolve with more\nautomated and autonomous systems, advancements in AAM require a deep\nunderstanding of human-computer interaction and human-AI collaboration to\nensure safe and effective operations in complex urban and regional\nenvironments. There has been a significant increase in publications regarding\nthese emerging applications; thus, there is a need to review developments in\nthis area. This paper comprehensively reviews the current state of research on\nhuman-computer interaction and human-AI collaboration in AAM. Specifically, we\nfocus on AAM applications related to the design of human-machine interfaces for\nvarious uses, including pilot training, air traffic management, and the\nintegration of AI-assisted decision-making systems with immersive technologies\nsuch as extended, virtual, mixed, and augmented reality devices. Additionally,\nwe provide a comprehensive analysis of the challenges AAM encounters in\nintegrating human-computer frameworks, including unique challenges associated\nwith these interactions, such as trust in AI systems and safety concerns.\nFinally, we highlight emerging opportunities and propose future research\ndirections to bridge the gap between human factors and technological\nadvancements in AAM.",
      "tldr_zh": "这篇论文对高级航空机动（AAM）中的人类-计算机交互和人类-AI 协作进行了全面回顾，旨在应对全球城市化和交通需求向三维空间转移带来的挑战。论文重点分析了相关应用，包括人机界面设计、飞行员训练、空中交通管理和 AI-assisted decision-making 系统与沉浸式技术的整合，如 extended reality、virtual reality、mixed reality 和 augmented reality。作者讨论了整合这些框架的挑战，例如对 AI 系统的信任问题和安全隐患，并提出了未来研究机会，以桥接人类因素和技术进步的差距。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07241v1",
      "published_date": "2024-12-10 07:06:52 UTC",
      "updated_date": "2024-12-10 07:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:51:15.307883"
    },
    {
      "arxiv_id": "2412.07237v3",
      "title": "ArtFormer: Controllable Generation of Diverse 3D Articulated Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi Su",
        "Youhe Feng",
        "Zheng Li",
        "Jinhua Song",
        "Yangfan He",
        "Botao Ren",
        "Botian Xu"
      ],
      "abstract": "This paper presents a novel framework for modeling and conditional generation\nof 3D articulated objects. Troubled by flexibility-quality tradeoffs, existing\nmethods are often limited to using predefined structures or retrieving shapes\nfrom static datasets. To address these challenges, we parameterize an\narticulated object as a tree of tokens and employ a transformer to generate\nboth the object's high-level geometry code and its kinematic relations.\nSubsequently, each sub-part's geometry is further decoded using a\nsigned-distance-function (SDF) shape prior, facilitating the synthesis of\nhigh-quality 3D shapes. Our approach enables the generation of diverse objects\nwith high-quality geometry and varying number of parts. Comprehensive\nexperiments on conditional generation from text descriptions demonstrate the\neffectiveness and flexibility of our method.",
      "tldr_zh": "本文提出ArtFormer框架，用于可控生成多样化的3D关节对象，解决了现有方法在灵活性和质量权衡上的局限，如依赖预定义结构或静态数据集。框架将对象参数化为token树，使用transformer生成高层次几何代码和运动学关系，随后通过signed-distance-function (SDF)形状先验解码每个子部件的几何，实现高质量3D形状合成。实验结果显示，该方法在基于文本描述的条件生成任务中表现出色，能生成具有可变部件数量的多样对象，证明了其有效性和灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. impl. repo: https://github.com/ShuYuMo2003/ArtFormer",
      "pdf_url": "http://arxiv.org/pdf/2412.07237v3",
      "published_date": "2024-12-10 07:00:05 UTC",
      "updated_date": "2025-04-03 14:16:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:51:27.412116"
    },
    {
      "arxiv_id": "2412.07236v5",
      "title": "CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Jiquan Wang",
        "Sha Zhao",
        "Zhiling Luo",
        "Yangxuan Zhou",
        "Haiteng Jiang",
        "Shijian Li",
        "Tao Li",
        "Gang Pan"
      ],
      "abstract": "Electroencephalography (EEG) is a non-invasive technique to measure and\nrecord brain electrical activity, widely used in various BCI and healthcare\napplications. Early EEG decoding methods rely on supervised learning, limited\nby specific tasks and datasets, hindering model performance and\ngeneralizability. With the success of large language models, there is a growing\nbody of studies focusing on EEG foundation models. However, these studies still\nleave challenges: Firstly, most of existing EEG foundation models employ full\nEEG modeling strategy. It models the spatial and temporal dependencies between\nall EEG patches together, but ignores that the spatial and temporal\ndependencies are heterogeneous due to the unique structural characteristics of\nEEG signals. Secondly, existing EEG foundation models have limited\ngeneralizability on a wide range of downstream BCI tasks due to varying formats\nof EEG data, making it challenging to adapt to. To address these challenges, we\npropose a novel foundation model called CBraMod. Specifically, we devise a\ncriss-cross transformer as the backbone to thoroughly leverage the structural\ncharacteristics of EEG signals, which can model spatial and temporal\ndependencies separately through two parallel attention mechanisms. And we\nutilize an asymmetric conditional positional encoding scheme which can encode\npositional information of EEG patches and be easily adapted to the EEG with\ndiverse formats. CBraMod is pre-trained on a very large corpus of EEG through\npatch-based masked EEG reconstruction. We evaluate CBraMod on up to 10\ndownstream BCI tasks (12 public datasets). CBraMod achieves the\nstate-of-the-art performance across the wide range of tasks, proving its strong\ncapability and generalizability. The source code is publicly available at\nhttps://github.com/wjq-learning/CBraMod.",
      "tldr_zh": "该研究针对EEG（Electroencephalography）解码的局限性，提出了一种新型基础模型CBraMod，以解决现有模型在处理EEG信号的空间和时间依赖性异质性以及下游BCI任务泛化性上的挑战。具体而言，CBraMod采用criss-cross transformer作为骨干网络，通过两个并行注意力机制分别建模空间和时间依赖，并使用asymmetric conditional positional encoding方案来适应不同格式的EEG数据，该模型通过patch-based masked EEG reconstruction在大型EEG语料上预训练。在多达10个下游BCI任务（12个公共数据集）上评估，CBraMod实现了state-of-the-art性能，证明了其强大的泛化能力和有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by The Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.07236v5",
      "published_date": "2024-12-10 06:56:36 UTC",
      "updated_date": "2025-04-13 10:02:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:51:40.415610"
    },
    {
      "arxiv_id": "2412.14188v1",
      "title": "CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhen Bian",
        "Yubo Zhou",
        "Yuanhang Luo",
        "Ming Mo",
        "Siyan Liu",
        "Yikai Gong",
        "Renjie Wan",
        "Ziyuan Luo",
        "Aobo Wang"
      ],
      "abstract": "The interplay between cognition and gaming, notably through educational games\nenhancing cognitive skills, has garnered significant attention in recent years.\nThis research introduces the CogSimulator, a novel algorithm for simulating\nuser cognition in small-group settings with minimal data, as the educational\ngame Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and\ncoordinates search optimization for hyperparameter tuning, enabling precise\nfew-shot predictions in new game scenarios. Comparative experiments with the\nWordle dataset illustrate that our model surpasses most conventional machine\nlearning models in mean Wasserstein-1 distance, mean squared error, and mean\naccuracy, showcasing its efficacy in cognitive enhancement through tailored\ngame design.",
      "tldr_zh": "这篇论文介绍了 CogSimulator，一种新型算法，用于在小团体环境中模拟用户认知和行为，仅需最小数据即可实现个性化的认知增强，例如应用于教育游戏 Wordle。CogSimulator 采用 Wasserstein-1 distance 和坐标搜索优化进行超参数调整，从而实现在新游戏场景下的精确少样本预测。与传统机器学习模型相比，实验在 Wordle 数据集上显示，该模型在均 Wasserstein-1 distance、均方误差和均准确率方面表现出色，证明了其在个性化认知增强方面的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14188v1",
      "published_date": "2024-12-10 06:25:28 UTC",
      "updated_date": "2024-12-10 06:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:51:52.712080"
    },
    {
      "arxiv_id": "2412.07813v3",
      "title": "How Can Incentives and Cut Layer Selection Influence Data Contribution in Split Federated Learning?",
      "title_zh": "激励和切割层选择如何影响分割联邦学习中的数据贡献？",
      "authors": [
        "Joohyung Lee",
        "Jungchan Cho",
        "Wonjun Lee",
        "Mohamed Seif",
        "H. Vincent Poor"
      ],
      "abstract": "To alleviate the training burden in federated learning while enhancing\nconvergence speed, Split Federated Learning (SFL) has emerged as a promising\napproach by combining the advantages of federated and split learning. However,\nrecent studies have largely overlooked competitive situations. In this\nframework, the SFL model owner can choose the cut layer to balance the training\nload between the server and clients, ensuring the necessary level of privacy\nfor the clients. Additionally, the SFL model owner sets incentives to encourage\nclient participation in the SFL process. The optimization strategies employed\nby the SFL model owner influence clients' decisions regarding the amount of\ndata they contribute, taking into account the shared incentives over clients\nand anticipated energy consumption during SFL. To address this framework, we\nmodel the problem using a hierarchical decision-making approach, formulated as\na single-leader multi-follower Stackelberg game. We demonstrate the existence\nand uniqueness of the Nash equilibrium among clients and analyze the\nStackelberg equilibrium by examining the leader's game. Furthermore, we discuss\nprivacy concerns related to differential privacy and the criteria for selecting\nthe minimum required cut layer. Our findings show that the Stackelberg\nequilibrium solution maximizes the utility for both the clients and the SFL\nmodel owner.",
      "tldr_zh": "本研究探讨了在 Split Federated Learning (SFL) 中，激励机制和切层选择如何影响客户端的数据贡献，旨在平衡训练负担、提升收敛速度并保护隐私。\n他们使用单领导多跟随者 Stackelberg 游戏模型来模拟分层决策过程，证明了客户端间的 Nash 均衡的存在和唯一性，并分析了 Stackelberg 均衡。\n结果显示，该均衡能最大化客户端和 SFL 模型所有者的效用，同时讨论了差分隐私的隐私担忧以及选择最小所需切层的标准。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07813v3",
      "published_date": "2024-12-10 06:24:08 UTC",
      "updated_date": "2025-01-23 09:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:52:04.090777"
    },
    {
      "arxiv_id": "2412.07224v1",
      "title": "Parseval Regularization for Continual Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wesley Chung",
        "Lynn Cherif",
        "David Meger",
        "Doina Precup"
      ],
      "abstract": "Loss of plasticity, trainability loss, and primacy bias have been identified\nas issues arising when training deep neural networks on sequences of tasks --\nall referring to the increased difficulty in training on new tasks. We propose\nto use Parseval regularization, which maintains orthogonality of weight\nmatrices, to preserve useful optimization properties and improve training in a\ncontinual reinforcement learning setting. We show that it provides significant\nbenefits to RL agents on a suite of gridworld, CARL and MetaWorld tasks. We\nconduct comprehensive ablations to identify the source of its benefits and\ninvestigate the effect of certain metrics associated to network trainability\nincluding weight matrix rank, weight norms and policy entropy.",
      "tldr_zh": "这篇论文针对持续强化学习(continual reinforcement learning)中深度神经网络的训练挑战，如损失可塑性(loss of plasticity)、训练性损失(trainability loss)和优先偏差(primacy bias)，提出了使用 Parseval 正则化来保持权重矩阵的正交性，从而保留优化属性并提升训练效果。\n实验结果显示，该方法在 gridworld、CARL 和 MetaWorld 任务上为 RL 代理提供了显著性能提升。\n作者还进行了全面的消融实验(ablation studies)，分析了益处的来源，并考察了与网络训练性相关的指标，包括权重矩阵秩、权重范数和策略熵(policy entropy)。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07224v1",
      "published_date": "2024-12-10 06:19:21 UTC",
      "updated_date": "2024-12-10 06:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:52:16.274870"
    },
    {
      "arxiv_id": "2412.07222v1",
      "title": "MPSI: Mamba enhancement model for pixel-wise sequential interaction Image Super-Resolution",
      "title_zh": "MPSI：Mamba 增强模型用于像素级顺序交互图像超分辨率",
      "authors": [
        "Yuchun He",
        "Yuhan He"
      ],
      "abstract": "Single image super-resolution (SR) has long posed a challenge in the field of\ncomputer vision. While the advent of deep learning has led to the emergence of\nnumerous methods aimed at tackling this persistent issue, the current\nmethodologies still encounter challenges in modeling long sequence information,\nleading to limitations in effectively capturing the global pixel interactions.\nTo tackle this challenge and achieve superior SR outcomes, we propose the Mamba\npixel-wise sequential interaction network (MPSI), aimed at enhancing the\nestablishment of long-range connections of information, particularly focusing\non pixel-wise sequential interaction. We propose the Channel-Mamba Block (CMB)\nto capture comprehensive pixel interaction information by effectively modeling\nlong sequence information. Moreover, in the existing SR methodologies, there\npersists the issue of the neglect of features extracted by preceding layers,\nleading to the loss of valuable feature information. While certain existing\nmodels strive to preserve these features, they frequently encounter difficulty\nin establishing connections across all layers. To overcome this limitation,\nMPSI introduces the Mamba channel recursion module (MCRM), which maximizes the\nretention of valuable feature information from early layers, thereby\nfacilitating the acquisition of pixel sequence interaction information from\nmultiple-level layers. Through extensive experimentation, we demonstrate that\nMPSI outperforms existing super-resolution methods in terms of image\nreconstruction results, attaining state-of-the-art performance.",
      "tldr_zh": "该研究针对单图像超分辨率（SR）领域的挑战，提出 MPSI 模型，该模型通过增强像素级序列交互来改善长序列信息的建模。MPSI 包括 Channel-Mamba Block (CMB) 用于捕获全面的像素交互信息，以及 Mamba channel recursion module (MCRM) 来保留和利用多层特征信息，避免现有方法忽略早期提取特征的问题。通过广泛实验，MPSI 在图像重建结果上超越现有方法，达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07222v1",
      "published_date": "2024-12-10 06:18:29 UTC",
      "updated_date": "2024-12-10 06:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:52:29.546133"
    },
    {
      "arxiv_id": "2412.07214v3",
      "title": "Towards Automated Cross-domain Exploratory Data Analysis through Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-Peng Zhu",
        "Boyan Niu",
        "Peng Cai",
        "Zheming Ni",
        "Jianwei Wan",
        "Kai Xu",
        "Jiajun Huang",
        "Shengbo Ma",
        "Bing Wang",
        "Xuan Zhou",
        "Guanglei Bao",
        "Donghui Zhang",
        "Liu Tang",
        "Qi Liu"
      ],
      "abstract": "Exploratory data analysis (EDA), coupled with SQL, is essential for data\nanalysts involved in data exploration and analysis. However, data analysts\noften encounter two primary challenges: (1) the need to craft SQL queries\nskillfully, and (2) the requirement to generate suitable visualization types\nthat enhance the interpretation of query results. Due to its significance,\nsubstantial research efforts have been made to explore different approaches to\naddress these challenges, including leveraging large language models (LLMs).\nHowever, existing methods fail to meet real-world data exploration requirements\nprimarily due to (1) complex database schema; (2) unclear user intent; (3)\nlimited cross-domain generalization capability; and (4) insufficient end-to-end\ntext-to-visualization capability.\n  This paper presents TiInsight, an automated SQL-based cross-domain\nexploratory data analysis system. First, we propose hierarchical data context\n(i.e., HDC), which leverages LLMs to summarize the contexts related to the\ndatabase schema, which is crucial for open-world EDA systems to generalize\nacross data domains. Second, the EDA system is divided into four components\n(i.e., stages): HDC generation, question clarification and decomposition,\ntext-to-SQL generation (i.e., TiSQL), and data visualization (i.e., TiChart).\nFinally, we implemented an end-to-end EDA system with a user-friendly GUI\ninterface in the production environment at PingCAP. We have also open-sourced\nall APIs of TiInsight to facilitate research within the EDA community. Through\nextensive evaluations by a real-world user study, we demonstrate that TiInsight\noffers remarkable performance compared to human experts. Specifically, TiSQL\nachieves an execution accuracy of 86.3% on the Spider dataset using GPT-4. It\nalso demonstrates state-of-the-art performance on the Bird dataset.",
      "tldr_zh": "这篇论文针对 Exploratory Data Analysis (EDA) 中的挑战，提出了一种基于 Large Language Models (LLMs) 的自动化跨域系统 TiInsight，以解决复杂的数据库模式、不清楚的用户意图以及文本到可视化的不足。TiInsight 引入 Hierarchical Data Context (HDC) 来总结数据库模式上下文，并将系统分为四个组件：HDC 生成、问题澄清和分解、文本到 SQL 生成 (TiSQL) 以及数据可视化 (TiChart)，实现了端到端的 EDA 流程。实验结果显示，TiSQL 在 Spider 数据集上达到 86.3% 执行准确率，并在 Bird 数据集上实现 State-of-the-Art 性能，用户研究证明该系统优于人类专家。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07214v3",
      "published_date": "2024-12-10 06:11:23 UTC",
      "updated_date": "2025-02-14 02:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:52:42.152757"
    },
    {
      "arxiv_id": "2412.07213v1",
      "title": "IntellectSeeker: A Personalized Literature Management System with the Probabilistic Model and Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhen Bian",
        "Siyan Liu",
        "Yubo Zhou",
        "Dezhi Chen",
        "Yijie Liao",
        "Zhenzhen Fan",
        "Aobo Wang"
      ],
      "abstract": "Faced with the burgeoning volume of academic literature, researchers often\nneed help with uncertain article quality and mismatches in term searches using\ntraditional academic engines. We introduce IntellectSeeker, an innovative and\npersonalized intelligent academic literature management platform to address\nthese challenges. This platform integrates a Large Language Model (LLM)--based\nsemantic enhancement bot with a sophisticated probability model to personalize\nand streamline literature searches. We adopted the GPT-3.5-turbo model to\ntransform everyday language into professional academic terms across various\nscenarios using multiple rounds of few-shot learning. This adaptation mainly\nbenefits academic newcomers, effectively bridging the gap between general\ninquiries and academic terminology. The probabilistic model intelligently\nfilters academic articles to align closely with the specific interests of\nusers, which are derived from explicit needs and behavioral patterns. Moreover,\nIntellectSeeker incorporates an advanced recommendation system and text\ncompression tools. These features enable intelligent article recommendations\nbased on user interactions and present search results through concise one-line\nsummaries and innovative word cloud visualizations, significantly enhancing\nresearch efficiency and user experience. IntellectSeeker offers academic\nresearchers a highly customizable literature management solution with\nexceptional search precision and matching capabilities. The code can be found\nhere: https://github.com/LuckyBian/ISY5001",
      "tldr_zh": "这篇论文介绍了 IntellectSeeker，一种个性化的学术文献管理系统，旨在解决传统搜索引擎中文章质量不确定和关键词不匹配的问题。该系统整合 Large Language Model (LLM) 如 GPT-3.5-turbo 和概率模型，通过多轮 few-shot learning 将日常语言转化为专业学术术语，并基于用户的显性需求和行为模式智能过滤文章。IntellectSeeker 还包括推荐系统和文本压缩工具，提供简洁摘要及词云可视化，从而显著提升研究效率和用户体验，尤其适合学术新人。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07213v1",
      "published_date": "2024-12-10 06:09:49 UTC",
      "updated_date": "2024-12-10 06:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:52:52.218880"
    },
    {
      "arxiv_id": "2412.07210v2",
      "title": "EDiT: A Local-SGD-Based Efficient Distributed Training Method for Large Language Models",
      "title_zh": "EDiT：一种基于 Local-SGD 的高效分布式训练方法，用于大型语言模型",
      "authors": [
        "Jialiang Cheng",
        "Ning Gao",
        "Yun Yue",
        "Zhiling Ye",
        "Jiadi Jiang",
        "Jian Sha"
      ],
      "abstract": "Distributed training methods are crucial for large language models (LLMs).\nHowever, existing distributed training methods often suffer from communication\nbottlenecks, stragglers, and limited elasticity, particularly in heterogeneous\nor large-scale environments. Local SGD methods have been proposed to address\nthese issues, but their effectiveness remains limited to small-scale training\ndue to additional memory overhead and lack of concerns on efficiency and\nstability. To tackle these issues, we propose EDiT, an innovative Efficient\nDistributed Training method that combines a tailored Local SGD approach with\nmodel sharding techniques to enhance large-scale training efficiency. EDiT\nperforms layer-wise parameter synchronization during forward pass, reducing\ncommunication and memory overhead and enabling overlap. Besides, EDiT employs a\npseudo gradient penalty strategy to suppress loss spikes, which ensures\ntraining stability and improves performance. Additionally, we introduce A-EDiT,\na fully asynchronous variant of EDiT that accommodates heterogeneous clusters.\nBuilding on EDiT/A-EDiT, we conduct a series of experiments to validate\nlarge-scale asynchronous training for LLMs, accompanied by comprehensive\nanalyses. Experimental results demonstrate the superior performance of\nEDiT/A-EDiT, establishing them as robust solutions for distributed LLM training\nin diverse computational ecosystems. The code is available at Atorch codebase:\nhttps://github.com/intelligent-machine-learning/atorch/tree/main/atorch/local_sgd.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的分布式训练问题，提出了一种基于Local SGD的创新方法EDiT，以解决通信瓶颈、stragglers和有限弹性的挑战。EDiT结合模型分片技术，在前向传播期间进行层级参数同步，并采用伪梯度惩罚策略来减少内存开销、提升训练效率和稳定性；此外，其异步变体A-EDiT适用于异构集群。实验结果显示，EDiT和A-EDiT在大规模环境中显著优于基线方法，为分布式LLMs训练提供了鲁棒解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "22 pages, 10 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.07210v2",
      "published_date": "2024-12-10 06:08:24 UTC",
      "updated_date": "2025-02-17 02:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:53:04.968914"
    },
    {
      "arxiv_id": "2412.07207v2",
      "title": "MAPLE: A Framework for Active Preference Learning Guided by Large Language Models",
      "title_zh": "MAPLE：大语言模型指导下的主动偏好学习框架",
      "authors": [
        "Saaduddin Mahmud",
        "Mason Nakamura",
        "Shlomo Zilberstein"
      ],
      "abstract": "The advent of large language models (LLMs) has sparked significant interest\nin using natural language for preference learning. However, existing methods\noften suffer from high computational burdens, taxing human supervision, and\nlack of interpretability. To address these issues, we introduce MAPLE, a\nframework for large language model-guided Bayesian active preference learning.\nMAPLE leverages LLMs to model the distribution over preference functions,\nconditioning it on both natural language feedback and conventional preference\nlearning feedback, such as pairwise trajectory rankings. MAPLE also employs\nactive learning to systematically reduce uncertainty in this distribution and\nincorporates a language-conditioned active query selection mechanism to\nidentify informative and easy-to-answer queries, thus reducing human burden. We\nevaluate MAPLE's sample efficiency and preference inference quality across two\nbenchmarks, including a real-world vehicle route planning benchmark using\nOpenStreetMap data. Our results demonstrate that MAPLE accelerates the learning\nprocess and effectively improves humans' ability to answer queries.",
      "tldr_zh": "该研究引入了 MAPLE 框架，一种由大语言模型 (LLMs) 指导的主动偏好学习方法，旨在解决现有偏好学习方法的高计算负担、大量人力监督需求和缺乏可解释性问题。MAPLE 通过利用 LLMs 建模偏好函数的分布，结合自然语言反馈和传统偏好学习反馈（如成对轨迹排名），并采用主动学习来减少不确定性，同时引入语言条件下的主动查询选择机制，以生成信息丰富且易于回答的查询，从而降低人类负担。在两个基准测试中，包括真实世界的车辆路线规划基准，MAPLE 展示了更高的样本效率和偏好推断质量，显著加速了学习过程并提升了人类回答查询的能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025 AI Alignment Track",
      "pdf_url": "http://arxiv.org/pdf/2412.07207v2",
      "published_date": "2024-12-10 05:55:14 UTC",
      "updated_date": "2024-12-20 01:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:53:17.109103"
    },
    {
      "arxiv_id": "2501.14734v1",
      "title": "Research on the Application of Spark Streaming Real-Time Data Analysis System and large language model Intelligent Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jialin Wang",
        "Zhihua Duan"
      ],
      "abstract": "This study explores the integration of Agent AI with LangGraph to enhance\nreal-time data analysis systems in big data environments. The proposed\nframework overcomes limitations of static workflows, inefficient stateful\ncomputations, and lack of human intervention by leveraging LangGraph's\ngraph-based workflow construction and dynamic decision-making capabilities.\nLangGraph allows large language models (LLMs) to dynamically determine control\nflows, invoke tools, and assess the necessity of further actions, improving\nflexibility and efficiency.\n  The system architecture incorporates Apache Spark Streaming, Kafka, and\nLangGraph to create a high-performance sentiment analysis system. LangGraph's\ncapabilities include precise state management, dynamic workflow construction,\nand robust memory checkpointing, enabling seamless multi-turn interactions and\ncontext retention. Human-in-the-loop mechanisms are integrated to refine\nsentiment analysis, particularly in ambiguous or high-stakes scenarios,\nensuring greater reliability and contextual relevance.\n  Key features such as real-time state streaming, debugging via LangGraph\nStudio, and efficient handling of large-scale data streams make this framework\nideal for adaptive decision-making. Experimental results confirm the system's\nability to classify inquiries, detect sentiment trends, and escalate complex\nissues for manual review, demonstrating a synergistic blend of LLM capabilities\nand human oversight.\n  This work presents a scalable, adaptable, and reliable solution for real-time\nsentiment analysis and decision-making, advancing the use of Agent AI and\nLangGraph in big data applications.",
      "tldr_zh": "本研究探讨了将 Agent AI 与 LangGraph 整合到大数据环境中的实时数据分析系统，旨在克服静态工作流、不高效状态计算和缺乏人类干预的局限性。系统利用 LangGraph 的图-based 工作流和动态决策能力，让 LLMs 动态确定控制流、调用工具并评估进一步行动，从而提升灵活性和效率。架构结合了 Apache Spark Streaming、Kafka 和 LangGraph，实现了精确状态管理、多轮交互以及 Human-in-the-loop 机制，用于高性能的情感分析。实验结果表明，该框架能有效分类查询、检测情感趋势并升级复杂问题，提供了一个可扩展、可适应且可靠的实时决策解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14734v1",
      "published_date": "2024-12-10 05:51:11 UTC",
      "updated_date": "2024-12-10 05:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:53:29.627882"
    },
    {
      "arxiv_id": "2412.07201v1",
      "title": "A Review on the Applications of Transformer-based language models for Nucleotide Sequence Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Nimisha Ghosh",
        "Daniele Santoni",
        "Indrajit Saha",
        "Giovanni Felici"
      ],
      "abstract": "In recent times, Transformer-based language models are making quite an impact\nin the field of natural language processing. As relevant parallels can be drawn\nbetween biological sequences and natural languages, the models used in NLP can\nbe easily extended and adapted for various applications in bioinformatics. In\nthis regard, this paper introduces the major developments of Transformer-based\nmodels in the recent past in the context of nucleotide sequences. We have\nreviewed and analysed a large number of application-based papers on this\nsubject, giving evidence of the main characterizing features and to different\napproaches that may be adopted to customize such powerful computational\nmachines. We have also provided a structured description of the functioning of\nTransformers, that may enable even first time users to grab the essence of such\ncomplex architectures. We believe this review will help the scientific\ncommunity in understanding the various applications of Transformer-based\nlanguage models to nucleotide sequences. This work will motivate the readers to\nbuild on these methodologies to tackle also various other problems in the field\nof bioinformatics.",
      "tldr_zh": "这篇综述论文探讨了Transformer-based language models在核苷酸序列分析中的应用，强调了这些模型从自然语言处理(NLP)领域的扩展到生物信息学(bioinformatics)的潜力。作者回顾并分析了大量相关论文，涵盖了模型的主要特征、自定义方法以及在核苷酸序列上下文中的发展。论文还提供了Transformer架构的结构化描述，以帮助初学者理解其复杂机制，并鼓励读者基于这些方法解决生物信息学中的其他问题。总的来说，此工作旨在为科学社区提供指导，推动Transformer-based模型在该领域的创新应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07201v1",
      "published_date": "2024-12-10 05:33:09 UTC",
      "updated_date": "2024-12-10 05:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:55:35.352899"
    },
    {
      "arxiv_id": "2412.07200v1",
      "title": "Modifying AI, Enhancing Essays: How Active Engagement with Generative AI Boosts Writing Quality",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixun Yang",
        "Mladen Raković",
        "Zhiping Liang",
        "Lixiang Yan",
        "Zijie Zeng",
        "Yizhou Fan",
        "Dragan Gašević",
        "Guanliang Chen"
      ],
      "abstract": "Students are increasingly relying on Generative AI (GAI) to support their\nwriting-a key pedagogical practice in education. In GAI-assisted writing,\nstudents can delegate core cognitive tasks (e.g., generating ideas and turning\nthem into sentences) to GAI while still producing high-quality essays. This\ncreates new challenges for teachers in assessing and supporting student\nlearning, as they often lack insight into whether students are engaging in\nmeaningful cognitive processes during writing or how much of the essay's\nquality can be attributed to those processes. This study aimed to help teachers\nbetter assess and support student learning in GAI-assisted writing by examining\nhow different writing behaviors, especially those indicative of meaningful\nlearning versus those that are not, impact essay quality. Using a dataset of\n1,445 GAI-assisted writing sessions, we applied the cutting-edge method,\nX-Learner, to quantify the causal impact of three GAI-assisted writing\nbehavioral patterns (i.e., seeking suggestions but not accepting them, seeking\nsuggestions and accepting them as they are, and seeking suggestions and\naccepting them with modification) on four measures of essay quality (i.e.,\nlexical sophistication, syntactic complexity, text cohesion, and linguistic\nbias). Our analysis showed that writers who frequently modified GAI-generated\ntext-suggesting active engagement in higher-order cognitive\nprocesses-consistently improved the quality of their essays in terms of lexical\nsophistication, syntactic complexity, and text cohesion. In contrast, those who\noften accepted GAI-generated text without changes, primarily engaging in\nlower-order processes, saw a decrease in essay quality. Additionally, while\nhuman writers tend to introduce linguistic bias when writing independently,\nincorporating GAI-generated text-even without modification-can help mitigate\nthis bias.",
      "tldr_zh": "这篇论文探讨了学生在使用 Generative AI (GAI) 辅助写作时，不同行为模式对论文质量的影响，旨在帮助教师评估学生的认知参与度。研究通过分析1,445个GAI辅助写作会话，并应用X-Learner方法，量化了三种行为（寻求建议但不接受、原样接受、以及接受后修改）对lexical sophistication、syntactic complexity、text cohesion和linguistic bias等指标的因果影响。结果显示，频繁修改GAI生成的文本（表示高阶认知过程）能显著提升词汇复杂性、句法复杂性和文本连贯性，而原样接受GAI文本（低阶过程）则会降低论文质量；此外，使用GAI生成的文本即使不修改，也能有效减少linguistic bias。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07200v1",
      "published_date": "2024-12-10 05:32:57 UTC",
      "updated_date": "2024-12-10 05:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:53:56.361608"
    },
    {
      "arxiv_id": "2412.07197v2",
      "title": "Hierarchical Split Federated Learning: Convergence Analysis and System Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Lin",
        "Wei Wei",
        "Zhe Chen",
        "Chan-Tong Lam",
        "Xianhao Chen",
        "Yue Gao",
        "Jun Luo"
      ],
      "abstract": "As AI models expand in size, it has become increasingly challenging to deploy\nfederated learning (FL) on resource-constrained edge devices. To tackle this\nissue, split federated learning (SFL) has emerged as an FL framework with\nreduced workload on edge devices via model splitting; it has received extensive\nattention from the research community in recent years. Nevertheless, most prior\nworks on SFL focus only on a two-tier architecture without harnessing\nmulti-tier cloudedge computing resources. In this paper, we intend to analyze\nand optimize the learning performance of SFL under multi-tier systems.\nSpecifically, we propose the hierarchical SFL (HSFL) framework and derive its\nconvergence bound. Based on the theoretical results, we formulate a joint\noptimization problem for model splitting (MS) and model aggregation (MA). To\nsolve this rather hard problem, we then decompose it into MS and MA subproblems\nthat can be solved via an iterative descending algorithm. Simulation results\ndemonstrate that the tailored algorithm can effectively optimize MS and MA for\nSFL within virtually any multi-tier system.",
      "tldr_zh": "该论文针对资源受限边缘设备上的联邦学习（FL）部署挑战，提出了一种分层分割联邦学习（HSFL）框架，以利用多层云边计算资源。该框架通过模型分割（MS）减少边缘设备负担，并推导了HSFL的收敛边界。基于理论分析，论文制定了MS和模型聚合（MA）的联合优化问题，并通过分解为子问题并使用迭代下降算法求解。模拟结果表明，该算法能有效优化多层系统的SFL性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07197v2",
      "published_date": "2024-12-10 05:20:49 UTC",
      "updated_date": "2025-04-21 06:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:56:05.919817"
    },
    {
      "arxiv_id": "2412.07188v1",
      "title": "Graph Neural Networks Are More Than Filters: Revisiting and Benchmarking from A Spectral Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yushun Dong",
        "Patrick Soga",
        "Yinhan He",
        "Song Wang",
        "Jundong Li"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in various\ngraph-based learning tasks. While their performance is often attributed to the\npowerful neighborhood aggregation mechanism, recent studies suggest that other\ncomponents such as non-linear layers may also significantly affecting how GNNs\nprocess the input graph data in the spectral domain. Such evidence challenges\nthe prevalent opinion that neighborhood aggregation mechanisms dominate the\nbehavioral characteristics of GNNs in the spectral domain. To demystify such a\nconflict, this paper introduces a comprehensive benchmark to measure and\nevaluate GNNs' capability in capturing and leveraging the information encoded\nin different frequency components of the input graph data. Specifically, we\nfirst conduct an exploratory study demonstrating that GNNs can flexibly yield\noutputs with diverse frequency components even when certain frequencies are\nabsent or filtered out from the input graph data. We then formulate a novel\nresearch problem of measuring and benchmarking the performance of GNNs from a\nspectral perspective. To take an initial step towards a comprehensive\nbenchmark, we design an evaluation protocol supported by comprehensive\ntheoretical analysis. Finally, we introduce a comprehensive benchmark on\nreal-world datasets, revealing insights that challenge prevalent opinions from\na spectral perspective. We believe that our findings will open new avenues for\nfuture advancements in this area. Our implementations can be found at:\nhttps://github.com/yushundong/Spectral-benchmark.",
      "tldr_zh": "这篇论文重新审视了 Graph Neural Networks (GNNs)，认为其性能不仅仅依赖于邻居聚合机制，还受非线性层等组件在频谱域的影响，从而挑战了传统观点。作者引入了一个全面基准测试框架，通过探索性研究和理论分析，评估 GNNs 在捕捉输入图数据不同频率组件的能力，即使某些频率缺失。实验结果在真实数据集上揭示了 GNNs 的灵活性，并提供了新洞见，为未来 GNNs 研究开辟了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07188v1",
      "published_date": "2024-12-10 04:53:53 UTC",
      "updated_date": "2024-12-10 04:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:56:18.053721"
    },
    {
      "arxiv_id": "2412.07186v1",
      "title": "Monte Carlo Tree Search based Space Transfer for Black-box Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shukuan Wang",
        "Ke Xue",
        "Lei Song",
        "Xiaobin Huang",
        "Chao Qian"
      ],
      "abstract": "Bayesian optimization (BO) is a popular method for computationally expensive\nblack-box optimization. However, traditional BO methods need to solve new\nproblems from scratch, leading to slow convergence. Recent studies try to\nextend BO to a transfer learning setup to speed up the optimization, where\nsearch space transfer is one of the most promising approaches and has shown\nimpressive performance on many tasks. However, existing search space transfer\nmethods either lack an adaptive mechanism or are not flexible enough, making it\ndifficult to efficiently identify promising search space during the\noptimization process. In this paper, we propose a search space transfer\nlearning method based on Monte Carlo tree search (MCTS), called MCTS-transfer,\nto iteratively divide, select, and optimize in a learned subspace.\nMCTS-transfer can not only provide a well-performing search space for\nwarm-start but also adaptively identify and leverage the information of similar\nsource tasks to reconstruct the search space during the optimization process.\nExperiments on synthetic functions, real-world problems, Design-Bench and\nhyper-parameter optimization show that MCTS-transfer can demonstrate superior\nperformance compared to other search space transfer methods under different\nsettings. Our code is available at\n\\url{https://github.com/lamda-bbo/mcts-transfer}.",
      "tldr_zh": "本研究针对Bayesian Optimization (BO)在黑箱优化中的问题，提出了一种基于Monte Carlo Tree Search (MCTS)的搜索空间转移学习方法，名为MCTS-transfer，以加速优化过程。该方法通过迭代划分、选择和优化学习子空间，实现自适应机制，能够有效识别并利用类似源任务的信息进行搜索空间重建。与现有方法相比，MCTS-transfer在合成函数、真实世界问题、Design-Bench和超参数优化任务上表现出色，性能优于其他搜索空间转移方法，提供更好的热启动和优化效率。研究代码已开源在GitHub。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2412.07186v1",
      "published_date": "2024-12-10 04:52:26 UTC",
      "updated_date": "2024-12-10 04:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:54:29.827807"
    },
    {
      "arxiv_id": "2412.07183v1",
      "title": "Exploring What Why and How: A Multifaceted Benchmark for Causation Understanding of Video Anomaly",
      "title_zh": "探索什么、为什么和如何：视频异常因果理解的多方面基准",
      "authors": [
        "Hang Du",
        "Guoshun Nan",
        "Jiawen Qian",
        "Wangchenhui Wu",
        "Wendi Deng",
        "Hanqing Mu",
        "Zhenyan Chen",
        "Pengxuan Mao",
        "Xiaofeng Tao",
        "Jun Liu"
      ],
      "abstract": "Recent advancements in video anomaly understanding (VAU) have opened the door\nto groundbreaking applications in various fields, such as traffic monitoring\nand industrial automation. While the current benchmarks in VAU predominantly\nemphasize the detection and localization of anomalies. Here, we endeavor to\ndelve deeper into the practical aspects of VAU by addressing the essential\nquestions: \"what anomaly occurred?\", \"why did it happen?\", and \"how severe is\nthis abnormal event?\". In pursuit of these answers, we introduce a\ncomprehensive benchmark for Exploring the Causation of Video Anomalies (ECVA).\nOur benchmark is meticulously designed, with each video accompanied by detailed\nhuman annotations. Specifically, each instance of our ECVA involves three sets\nof human annotations to indicate \"what\", \"why\" and \"how\" of an anomaly,\nincluding 1) anomaly type, start and end times, and event descriptions, 2)\nnatural language explanations for the cause of an anomaly, and 3) free text\nreflecting the effect of the abnormality. Building upon this foundation, we\npropose a novel prompt-based methodology that serves as a baseline for tackling\nthe intricate challenges posed by ECVA. We utilize \"hard prompt\" to guide the\nmodel to focus on the critical parts related to video anomaly segments, and\n\"soft prompt\" to establish temporal and spatial relationships within these\nanomaly segments. Furthermore, we propose AnomEval, a specialized evaluation\nmetric crafted to align closely with human judgment criteria for ECVA. This\nmetric leverages the unique features of the ECVA dataset to provide a more\ncomprehensive and reliable assessment of various video large language models.\nWe demonstrate the efficacy of our approach through rigorous experimental\nanalysis and delineate possible avenues for further investigation into the\ncomprehension of video anomaly causation.",
      "tldr_zh": "这篇论文探讨了视频异常理解（Video Anomaly Understanding, VAU）的更深层面，引入了一个多方面基准ECVA（Exploring the Causation of Video Anomalies），旨在回答“what anomaly occurred?”（什么异常发生了）、“why did it happen?”（为什么发生）和“how severe is this abnormal event?”（这个异常事件有多严重）。ECVA数据集包括详细的人类标注，如异常类型、时间段、事件描述、原因解释和影响文本，以支持对异常因果关系的全面分析。作者提出了一种基于提示的方法作为基准，利用“hard prompt”聚焦关键视频段落和“soft prompt”建立时空关系。实验通过AnomEval评估指标验证了方法的有效性，该指标与人类判断标准对齐，并为视频大语言模型的改进提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence. arXiv admin note: substantial text overlap with\n  arXiv:2405.00181",
      "pdf_url": "http://arxiv.org/pdf/2412.07183v1",
      "published_date": "2024-12-10 04:41:44 UTC",
      "updated_date": "2024-12-10 04:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:54:43.306808"
    },
    {
      "arxiv_id": "2412.07182v2",
      "title": "An Enhancement of CNN Algorithm for Rice Leaf Disease Image Classification in Mobile Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Kayne Uriel K. Rodrigo",
        "Jerriane Hillary Heart S. Marcial",
        "Samuel C. Brillo",
        "Khatalyn E. Mata",
        "Jonathan C. Morano"
      ],
      "abstract": "This study focuses on enhancing rice leaf disease image classification\nalgorithms, which have traditionally relied on Convolutional Neural Network\n(CNN) models. We employed transfer learning with MobileViTV2_050 using\nImageNet-1k weights, a lightweight model that integrates CNN's local feature\nextraction with Vision Transformers' global context learning through a\nseparable self-attention mechanism. Our approach resulted in a significant\n15.66% improvement in classification accuracy for MobileViTV2_050-A, our first\nenhanced model trained on the baseline dataset, achieving 93.14%. Furthermore,\nMobileViTV2_050-B, our second enhanced model trained on a broader rice leaf\ndataset, demonstrated a 22.12% improvement, reaching 99.6% test accuracy.\nAdditionally, MobileViTV2-A attained an F1-score of 93% across four rice labels\nand a Receiver Operating Characteristic (ROC) curve ranging from 87% to 97%. In\nterms of resource consumption, our enhanced models reduced the total parameters\nof the baseline CNN model by up to 92.50%, from 14 million to 1.1 million.\nThese results indicate that MobileViTV2_050 not only improves computational\nefficiency through its separable self-attention mechanism but also enhances\nglobal context learning. Consequently, it offers a lightweight and robust\nsolution suitable for mobile deployment, advancing the interpretability and\npracticality of models in precision agriculture.",
      "tldr_zh": "本研究针对稻叶病图像分类算法的增强，基于传统 CNN 模型，采用转移学习（transfer learning）并使用 MobileViTV2_050 模型，该模型结合 CNN 的局部特征提取和 Vision Transformers 的全局上下文学习，通过可分离自注意力机制（separable self-attention mechanism）。实验结果显示，MobileViTV2_050-A 在基线数据集上训练后，分类准确率提高了 15.66% 至 93.14%，而 MobileViTV2_050-B 在更广泛数据集上训练后，提高了 22.12% 至 99.6% 测试准确率，并取得了 93% 的 F1-score 和 87% 到 97% 的 ROC 曲线。相比基线 CNN 模型，该增强模型将参数减少了 92.50%（从 14 百万降至 1.1 百万），提高了计算效率和可解释性，使其成为适合移动应用的轻量级解决方案，推进了精度农业的实践。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented at 46th World Conference on Applied Science, Engineering &\n  Technology (WCASET) from Institute for Educational Research and Publication\n  (IFERP)",
      "pdf_url": "http://arxiv.org/pdf/2412.07182v2",
      "published_date": "2024-12-10 04:41:10 UTC",
      "updated_date": "2025-02-16 12:20:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:54:57.312954"
    },
    {
      "arxiv_id": "2412.07174v1",
      "title": "Post-Training Statistical Calibration for Higher Activation Sparsity",
      "title_zh": "后训练统计校准以实现更高的激活稀疏性",
      "authors": [
        "Vui Seng Chua",
        "Yujie Pan",
        "Nilesh Jain"
      ],
      "abstract": "We present Statistical Calibrated Activation Pruning (SCAP), a post-training\nactivation pruning framework that (1) generalizes sparsification by input\nactivations of Fully-Connected layers for generic and flexible application\nacross Transformers, and (2) features a simple Mode-Centering technique to\npre-calibrate activation distributions for maximizing post-training sparsity.\nOur results demonstrate robust Pareto efficiency compared to prior methods,\ntranslating to a 1.5x additional LLM decoding speedup against CATS at iso model\nquality. SCAP effectiveness is empirically verified across a wide range of\nmodels, including recent Transformer Decoders, MoE, Mamba2, Encoding\nTransformer, and pre-quantized models, highlighting its practicality and\nscalability. The code is available at: https://github.com/IntelLabs/SCAP.",
      "tldr_zh": "本研究提出了一种后训练激活剪枝框架Statistical Calibrated Activation Pruning (SCAP)，旨在通过泛化Fully-Connected层的输入激活稀疏化，实现对Transformer等模型的灵活应用。SCAP引入简单的Mode-Centering技术来预先校准激活分布，从而最大化后训练稀疏性。实验结果显示，SCAP在等模型质量下比现有方法CATS实现了1.5倍的LLM解码加速，并在Transformer Decoders、MoE、Mamba2、Encoding Transformer和预量化模型上展现出稳健的Pareto效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ENLSP-IV NeurIPS Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07174v1",
      "published_date": "2024-12-10 04:15:39 UTC",
      "updated_date": "2024-12-10 04:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:55:05.977053"
    },
    {
      "arxiv_id": "2412.07167v1",
      "title": "Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer",
      "title_zh": "强化学习策略作为宏块调节器而非宏块放置器",
      "authors": [
        "Ke Xue",
        "Ruo-Tong Chen",
        "Xi Lin",
        "Yunqi Shi",
        "Shixiong Kai",
        "Siyuan Xu",
        "Chao Qian"
      ],
      "abstract": "In modern chip design, placement aims at placing millions of circuit modules,\nwhich is an essential step that significantly influences power, performance,\nand area (PPA) metrics. Recently, reinforcement learning (RL) has emerged as a\npromising technique for improving placement quality, especially macro\nplacement. However, current RL-based placement methods suffer from long\ntraining times, low generalization ability, and inability to guarantee PPA\nresults. A key issue lies in the problem formulation, i.e., using RL to place\nfrom scratch, which results in limits useful information and inaccurate rewards\nduring the training process. In this work, we propose an approach that utilizes\nRL for the refinement stage, which allows the RL policy to learn how to adjust\nexisting placement layouts, thereby receiving sufficient information for the\npolicy to act and obtain relatively dense and precise rewards. Additionally, we\nintroduce the concept of regularity during training, which is considered an\nimportant metric in the chip design industry but is often overlooked in current\nRL placement methods. We evaluate our approach on the ISPD 2005 and ICCAD 2015\nbenchmark, comparing the global half-perimeter wirelength and regularity of our\nproposed method against several competitive approaches. Besides, we test the\nPPA performance using commercial software, showing that RL as a regulator can\nachieve significant PPA improvements. Our RL regulator can fine-tune placements\nfrom any method and enhance their quality. Our work opens up new possibilities\nfor the application of RL in placement, providing a more effective and\nefficient approach to optimizing chip design. Our code is available at\n\\url{https://github.com/lamda-bbo/macro-regulator}.",
      "tldr_zh": "本文提出一种新方法，将Reinforcement Learning (RL) 政策用作宏块调节器（macro regulator），而非传统的宏块放置器（macro placer），以优化芯片设计中的placement过程。该方法让RL专注于refinement阶段，对现有布局进行调整，并引入regularity概念作为训练指标，从而提供更充分的信息和精确奖励。在ISPD 2005和ICCAD 2015基准测试中，该方法显著降低了global half-perimeter wirelength，提高了regularity，并通过商业软件验证了PPA（功率、性能和面积）指标的整体提升，展示了RL在芯片设计中的高效应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07167v1",
      "published_date": "2024-12-10 04:01:21 UTC",
      "updated_date": "2024-12-10 04:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:55:20.449313"
    },
    {
      "arxiv_id": "2412.07165v2",
      "title": "A Method for Evaluating Hyperparameter Sensitivity in Reinforcement Learning",
      "title_zh": "一种评估强化学习中超参数敏感性的方法",
      "authors": [
        "Jacob Adkins",
        "Michael Bowling",
        "Adam White"
      ],
      "abstract": "The performance of modern reinforcement learning algorithms critically relies\non tuning ever-increasing numbers of hyperparameters. Often, small changes in a\nhyperparameter can lead to drastic changes in performance, and different\nenvironments require very different hyperparameter settings to achieve\nstate-of-the-art performance reported in the literature. We currently lack a\nscalable and widely accepted approach to characterizing these complex\ninteractions. This work proposes a new empirical methodology for studying,\ncomparing, and quantifying the sensitivity of an algorithm's performance to\nhyperparameter tuning for a given set of environments. We then demonstrate the\nutility of this methodology by assessing the hyperparameter sensitivity of\nseveral commonly used normalization variants of PPO. The results suggest that\nseveral algorithmic performance improvements may, in fact, be a result of an\nincreased reliance on hyperparameter tuning.",
      "tldr_zh": "这篇论文提出了一种新的经验方法，用于评估强化学习算法对超参数调优的敏感性，旨在解决小幅超参数变化可能导致性能剧变的问题，并处理不同环境对超参数设置的复杂需求。该方法通过系统地研究、比较和量化算法性能的响应，提供了一个可扩展的框架来表征这些交互。作者应用此方法分析了PPO的几种常见归一化变体，结果显示许多算法性能改进实际上源于对hyperparameter tuning的更大依赖。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07165v2",
      "published_date": "2024-12-10 03:55:18 UTC",
      "updated_date": "2025-02-04 05:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:55:29.817202"
    },
    {
      "arxiv_id": "2412.07163v1",
      "title": "Fast Occupancy Network",
      "title_zh": "快速占用网络",
      "authors": [
        "Mingjie Lu",
        "Yuanxian Huang",
        "Ji Liu",
        "Xingliang Huang",
        "Dong Li",
        "Jinzhang Peng",
        "Lu Tian",
        "Emad Barsoum"
      ],
      "abstract": "Occupancy Network has recently attracted much attention in autonomous\ndriving. Instead of monocular 3D detection and recent bird's eye view(BEV)\nmodels predicting 3D bounding box of obstacles, Occupancy Network predicts the\ncategory of voxel in specified 3D space around the ego vehicle via transforming\n3D detection task into 3D voxel segmentation task, which has much superiority\nin tackling category outlier obstacles and providing fine-grained 3D\nrepresentation. However, existing methods usually require huge computation\nresources than previous methods, which hinder the Occupancy Network solution\napplying in intelligent driving systems. To address this problem, we make an\nanalysis of the bottleneck of Occupancy Network inference cost, and present a\nsimple and fast Occupancy Network model, which adopts a deformable 2D\nconvolutional layer to lift BEV feature to 3D voxel feature and presents an\nefficient voxel feature pyramid network (FPN) module to improve performance\nwith few computational cost. Further, we present a cost-free 2D segmentation\nbranch in perspective view after feature extractors for Occupancy Network\nduring inference phase to improve accuracy. Experimental results demonstrate\nthat our method consistently outperforms existing methods in both accuracy and\ninference speed, which surpasses recent state-of-the-art (SOTA) OCCNet by 1.7%\nwith ResNet50 backbone with about 3X inference speedup. Furthermore, our method\ncan be easily applied to existing BEV models to transform them into Occupancy\nNetwork models.",
      "tldr_zh": "本文提出了一种快速的 Occupancy Network 模型，旨在解决其在自动驾驶中计算资源需求高的瓶颈问题，通过将 3D 检测任务转化为 3D 体素分割任务，提供细粒度的障碍物表示。方法包括使用可变形 2D 卷积层将 BEV 特征提升到 3D 体素特征、引入高效的 voxel FPN 模块以提升性能，以及添加一个无成本的 2D segmentation branch 来提高准确性。实验结果表明，该模型在准确性上比 SOTA 的 OCCNet 提高 1.7%，并实现约 3 倍的推理加速，同时易于扩展到现有 BEV 模型中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures,",
      "pdf_url": "http://arxiv.org/pdf/2412.07163v1",
      "published_date": "2024-12-10 03:46:03 UTC",
      "updated_date": "2024-12-10 03:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:56:32.224408"
    },
    {
      "arxiv_id": "2412.07148v1",
      "title": "MM-PoE: Multiple Choice Reasoning via. Process of Elimination using Multi-Modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sayak Chakrabarty",
        "Souradip Pal"
      ],
      "abstract": "This paper introduces Multiple Choice Reasoning via. Process of Elimination\nusing Multi-Modal models, herein referred to as Multi-Modal Process of\nElimination (MM-PoE). This novel methodology is engineered to augment the\nefficacy of Vision-Language Models (VLMs) in multiple-choice visual reasoning\ntasks. Diverging from conventional approaches that evaluate each option\nindependently, MM-PoE employs a dual-step scoring paradigm that initially\nidentifies and excludes implausible choices, subsequently concentrating on the\nmost probable remaining options. This method emulates human test-taking\nstrategies, where individuals typically eliminate clearly incorrect answers\nprior to selecting the optimal response. Our empirical evaluations, conducted\nacross three benchmark datasets, reveal that MM-PoE significantly improves both\nzero-shot and few-shot performance of contemporary state-of-the-art VLMs.\nCritically, this approach not only broadens the application of the elimination\nprocess to multi-modal contexts but also allows few-shot experiments, thereby\naddressing two principal limitations concerning usage of PoE only in zero-shot\nsettings and only with a language-only framework. As a result, MM-PoE not only\nrefines the reasoning capabilities of VLMs but also broadens their\napplicability to complex visual question-answering scenarios. All code and\ndocumentation supporting our work are available at\nhttps://pypi.org/project/mm-poe/, enabling researchers and practitioners to\neasily integrate and further develop these techniques.",
      "tldr_zh": "这篇论文引入了 MM-PoE，一种基于 Process of Elimination 的多选题推理方法，使用 Multi-Modal Models 来提升 Vision-Language Models (VLMs) 在多选视觉推理任务中的效能。MM-PoE 采用双步评分范式，先识别并排除 implausible choices，然后专注于剩余的最 probable 选项，模仿人类测试策略。与传统方法不同，该方法扩展了排除法到多模态上下文，并支持 few-shot 实验，解决了其之前仅限于 zero-shot 和语言-only 框架的限制。实验在三个基准数据集上显示，MM-PoE 显著提高了 VLMs 的零-shot 和 few-shot 性能，从而增强了模型在复杂视觉问答场景中的推理能力和适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07148v1",
      "published_date": "2024-12-10 03:13:41 UTC",
      "updated_date": "2024-12-10 03:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:56:43.675163"
    },
    {
      "arxiv_id": "2412.07147v2",
      "title": "MIT-10M: A Large Scale Parallel Corpus of Multilingual Image Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Li",
        "Shaolin Zhu",
        "Lijie Wen"
      ],
      "abstract": "Image Translation (IT) holds immense potential across diverse domains,\nenabling the translation of textual content within images into various\nlanguages. However, existing datasets often suffer from limitations in scale,\ndiversity, and quality, hindering the development and evaluation of IT models.\nTo address this issue, we introduce MIT-10M, a large-scale parallel corpus of\nmultilingual image translation with over 10M image-text pairs derived from\nreal-world data, which has undergone extensive data cleaning and multilingual\ntranslation validation. It contains 840K images in three sizes, 28 categories,\ntasks with three levels of difficulty and 14 languages image-text pairs, which\nis a considerable improvement on existing datasets. We conduct extensive\nexperiments to evaluate and train models on MIT-10M. The experimental results\nclearly indicate that our dataset has higher adaptability when it comes to\nevaluating the performance of the models in tackling challenging and complex\nimage translation tasks in the real world. Moreover, the performance of the\nmodel fine-tuned with MIT-10M has tripled compared to the baseline model,\nfurther confirming its superiority.",
      "tldr_zh": "我们引入了 MIT-10M，这是一个大规模的多语言图像翻译平行语料库，包含超过 10M 的图像-文本对，旨在解决现有数据集在规模、多样性和质量方面的局限性。数据集基于真实世界数据，经过全面数据清洗和多语言翻译验证，涵盖 840K 图像（三种大小）、28 个类别、三个难度级别以及 14 种语言的图像-文本对。实验结果显示，MIT-10M 在评估模型处理复杂真实世界任务时表现出更高的适应性，且使用该语料库微调的模型性能比基线模型提高了三倍。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07147v2",
      "published_date": "2024-12-10 03:12:35 UTC",
      "updated_date": "2024-12-16 09:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:56:55.059592"
    },
    {
      "arxiv_id": "2412.07144v2",
      "title": "Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Ruoyuan Gong",
        "Hao Jiang"
      ],
      "abstract": "Predicting roll call votes through modeling political actors has emerged as a\nfocus in quantitative political science and computer science. Widely used\nembedding-based methods generate vectors for legislators from diverse data sets\nto predict legislative behaviors. However, these methods often contend with\nchallenges such as the need for manually predefined features, reliance on\nextensive training data, and a lack of interpretability. Achieving more\ninterpretable predictions under flexible conditions remains an unresolved\nissue. This paper introduces the Political Actor Agent (PAA), a novel\nagent-based framework that utilizes Large Language Models to overcome these\nlimitations. By employing role-playing architectures and simulating legislative\nsystem, PAA provides a scalable and interpretable paradigm for predicting\nroll-call votes. Our approach not only enhances the accuracy of predictions but\nalso offers multi-view, human-understandable decision reasoning, providing new\ninsights into political actor behaviors. We conducted comprehensive experiments\nusing voting records from the 117-118th U.S. House of Representatives,\nvalidating the superior performance and interpretability of PAA. This study not\nonly demonstrates PAA's effectiveness but also its potential in political\nscience research.",
      "tldr_zh": "本文提出 Political Actor Agent (PAA)，一种基于 Large Language Models 的代理框架，用于模拟立法系统预测国会投票，解决了传统嵌入式方法依赖手动特征、需大量训练数据和缺乏可解释性的问题。PAA 通过角色扮演架构和系统模拟，提供可扩展的预测机制，并生成多视角的人类可理解决策推理。实验在第117-118届美国众议院投票记录上验证了 PAA 的优越性能，提升了预测准确性，并为政治科学研究提供了新颖见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.07144v2",
      "published_date": "2024-12-10 03:06:28 UTC",
      "updated_date": "2024-12-13 04:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:57:06.340848"
    },
    {
      "arxiv_id": "2412.07127v1",
      "title": "Deep Learning-Enhanced Preconditioning for Efficient Conjugate Gradient Solvers in Large-Scale PDE Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Li",
        "Song Wang",
        "Chen Wang"
      ],
      "abstract": "Preconditioning techniques are crucial for enhancing the efficiency of\nsolving large-scale linear equation systems that arise from partial\ndifferential equation (PDE) discretization. These techniques, such as\nIncomplete Cholesky factorization (IC) and data-driven neural network methods,\naccelerate the convergence of iterative solvers like Conjugate Gradient (CG) by\napproximating the original matrices. This paper introduces a novel approach\nthat integrates Graph Neural Network (GNN) with traditional IC, addressing the\nshortcomings of direct generation methods based on GNN and achieving\nsignificant improvements in computational efficiency and scalability.\nExperimental results demonstrate an average reduction in iteration counts by\n24.8% compared to IC and a two-order-of-magnitude increase in training scale\ncompared to previous methods. A three-dimensional static structural analysis\nutilizing finite element methods was validated on training sparse matrices of\nup to 5 million dimensions and inference scales of up to 10 million.\nFurthermore, the approach demon-strates robust generalization capabilities\nacross scales, facilitating the effective acceleration of CG solvers for\nlarge-scale linear equations using small-scale data on modest hardware. The\nmethod's robustness and scalability make it a practical solution for\ncomputational science.",
      "tldr_zh": "本文提出了一种结合 Graph Neural Network (GNN) 和 Incomplete Cholesky factorization (IC) 的新型预处理方法，用于提升 Conjugate Gradient (CG) 求解器在大规模偏微分方程 (PDE) 系统中的效率，解决了传统直接 GNN 方法的局限性。实验结果显示，与 IC 相比，该方法平均减少迭代次数 24.8%，并将训练规模提高两个数量级，支持高达 5 百万维的稀疏矩阵训练和 10 百万维的推理应用。该方法在不同规模下表现出色泛化能力，使用小规模数据即可在普通硬件上加速大规模线性方程求解，具有良好的鲁棒性和实际计算科学价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07127v1",
      "published_date": "2024-12-10 02:34:13 UTC",
      "updated_date": "2024-12-10 02:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:57:19.439766"
    },
    {
      "arxiv_id": "2412.07116v1",
      "title": "A Review of Human Emotion Synthesis Based on Generative Technology",
      "title_zh": "基于生成技术的人类情感合成综述",
      "authors": [
        "Fei Ma",
        "Yukan Li",
        "Yifan Xie",
        "Ying He",
        "Yi Zhang",
        "Hongwei Ren",
        "Zhou Liu",
        "Wei Yao",
        "Fuji Ren",
        "Fei Richard Yu",
        "Shiguang Ni"
      ],
      "abstract": "Human emotion synthesis is a crucial aspect of affective computing. It\ninvolves using computational methods to mimic and convey human emotions through\nvarious modalities, with the goal of enabling more natural and effective\nhuman-computer interactions. Recent advancements in generative models, such as\nAutoencoders, Generative Adversarial Networks, Diffusion Models, Large Language\nModels, and Sequence-to-Sequence Models, have significantly contributed to the\ndevelopment of this field. However, there is a notable lack of comprehensive\nreviews in this field. To address this problem, this paper aims to address this\ngap by providing a thorough and systematic overview of recent advancements in\nhuman emotion synthesis based on generative models. Specifically, this review\nwill first present the review methodology, the emotion models involved, the\nmathematical principles of generative models, and the datasets used. Then, the\nreview covers the application of different generative models to emotion\nsynthesis based on a variety of modalities, including facial images, speech,\nand text. It also examines mainstream evaluation metrics. Additionally, the\nreview presents some major findings and suggests future research directions,\nproviding a comprehensive understanding of the role of generative technology in\nthe nuanced domain of emotion synthesis.",
      "tldr_zh": "这篇论文对基于生成技术的人类情感合成（Human Emotion Synthesis）进行了全面综述，旨在填补该领域的审查空白，通过分析Autoencoders、Generative Adversarial Networks、Diffusion Models、Large Language Models和Sequence-to-Sequence Models等模型的应用，促进更自然的计算机交互。论文首先概述了审查方法、情感模型、生成模型的数学原理以及常用数据集，然后探讨了这些模型在面部图像、语音和文本等模态中的应用，并评估主流指标。最终，该综述总结了主要发现，如生成技术的进展提升了情感合成效果，并提出未来研究方向，以推动情感计算领域的创新发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.07116v1",
      "published_date": "2024-12-10 02:06:10 UTC",
      "updated_date": "2024-12-10 02:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:57:30.183846"
    },
    {
      "arxiv_id": "2412.10419v1",
      "title": "Personalized and Sequential Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ofir Nabati",
        "Guy Tennenholtz",
        "ChihWei Hsu",
        "Moonkyung Ryu",
        "Deepak Ramachandran",
        "Yinlam Chow",
        "Xiang Li",
        "Craig Boutilier"
      ],
      "abstract": "We address the problem of personalized, interactive text-to-image (T2I)\ngeneration, designing a reinforcement learning (RL) agent which iteratively\nimproves a set of generated images for a user through a sequence of prompt\nexpansions. Using human raters, we create a novel dataset of sequential\npreferences, which we leverage, together with large-scale open-source\n(non-sequential) datasets. We construct user-preference and user-choice models\nusing an EM strategy and identify varying user preference types. We then\nleverage a large multimodal language model (LMM) and a value-based RL approach\nto suggest a personalized and diverse slate of prompt expansions to the user.\nOur Personalized And Sequential Text-to-image Agent (PASTA) extends T2I models\nwith personalized multi-turn capabilities, fostering collaborative co-creation\nand addressing uncertainty or underspecification in a user's intent. We\nevaluate PASTA using human raters, showing significant improvement compared to\nbaseline methods. We also release our sequential rater dataset and simulated\nuser-rater interactions to support future research in personalized, multi-turn\nT2I generation.",
      "tldr_zh": "本文提出了一种个性化、顺序文本到图像（T2I）生成方法，使用强化学习（RL）代理通过一系列提示扩展来迭代改进用户生成的图像集。研究团队创建了一个新数据集，结合人类评分者的顺序偏好和大型开源数据集，并采用 EM 策略构建用户偏好和选择模型，以识别不同用户偏好类型。随后，他们利用大型多模态语言模型（LMM）和基于价值的 RL 方法，开发了 Personalized And Sequential Text-to-image Agent（PASTA）系统，实现个性化的多轮交互，促进用户意图的不确定性处理。实验结果显示，PASTA 在人类评估中显著优于基线方法，并发布了相关数据集和模拟交互以支持未来 T2I 生成研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "Link to PASTA dataset:\n  https://www.kaggle.com/datasets/googleai/pasta-data",
      "pdf_url": "http://arxiv.org/pdf/2412.10419v1",
      "published_date": "2024-12-10 01:47:40 UTC",
      "updated_date": "2024-12-10 01:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:57:43.591687"
    },
    {
      "arxiv_id": "2412.07097v1",
      "title": "On Evaluating the Durability of Safeguards for Open-Weight LLMs",
      "title_zh": "关于评估开放权重大语言模型安全",
      "authors": [
        "Xiangyu Qi",
        "Boyi Wei",
        "Nicholas Carlini",
        "Yangsibo Huang",
        "Tinghao Xie",
        "Luxi He",
        "Matthew Jagielski",
        "Milad Nasr",
        "Prateek Mittal",
        "Peter Henderson"
      ],
      "abstract": "Stakeholders -- from model developers to policymakers -- seek to minimize the\ndual-use risks of large language models (LLMs). An open challenge to this goal\nis whether technical safeguards can impede the misuse of LLMs, even when models\nare customizable via fine-tuning or when model weights are fully open. In\nresponse, several recent studies have proposed methods to produce durable LLM\nsafeguards for open-weight LLMs that can withstand adversarial modifications of\nthe model's weights via fine-tuning. This holds the promise of raising\nadversaries' costs even under strong threat models where adversaries can\ndirectly fine-tune model weights. However, in this paper, we urge for more\ncareful characterization of the limits of these approaches. Through several\ncase studies, we demonstrate that even evaluating these defenses is exceedingly\ndifficult and can easily mislead audiences into thinking that safeguards are\nmore durable than they really are. We draw lessons from the evaluation pitfalls\nthat we identify and suggest future research carefully cabin claims to more\nconstrained, well-defined, and rigorously examined threat models, which can\nprovide more useful and candid assessments to stakeholders.",
      "tldr_zh": "该论文探讨了评估开放权重LLMs的安全机制耐久性的挑战，强调即使在模型可以通过微调自定义的情况下，这些机制是否能有效防范双重用途风险。通过案例研究，作者展示了评估方法的局限性，可能导致对安全机制耐久性的过度乐观误判。论文建议未来研究应更严格定义和检验威胁模型，提供更可靠的评估，以帮助模型开发者、政策制定者等利益相关者更好地管理LLMs的风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07097v1",
      "published_date": "2024-12-10 01:30:32 UTC",
      "updated_date": "2024-12-10 01:30:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:57:52.719573"
    },
    {
      "arxiv_id": "2412.07096v1",
      "title": "QAPyramid: Fine-grained Evaluation of Content Selection for Text Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyue Zhang",
        "David Wan",
        "Arie Cattan",
        "Ayal Klein",
        "Ido Dagan",
        "Mohit Bansal"
      ],
      "abstract": "How to properly conduct human evaluations for text summarization is a\nlongstanding challenge. The Pyramid human evaluation protocol, which assesses\ncontent selection by breaking the reference summary into sub-units and\nverifying their presence in the system summary, has been widely adopted.\nHowever, it suffers from a lack of systematicity in the definition and\ngranularity of the sub-units. We address these problems by proposing QAPyramid,\nwhich decomposes each reference summary into finer-grained question-answer (QA)\npairs according to the QA-SRL framework. We collect QA-SRL annotations for\nreference summaries from CNN/DM and evaluate 10 summarization systems,\nresulting in 8.9K QA-level annotations. We show that, compared to Pyramid,\nQAPyramid provides more systematic and fine-grained content selection\nevaluation while maintaining high inter-annotator agreement without needing\nexpert annotations. Furthermore, we propose metrics that automate the\nevaluation pipeline and achieve higher correlations with QAPyramid than other\nwidely adopted metrics, allowing future work to accurately and efficiently\nbenchmark summarization systems.",
      "tldr_zh": "这篇论文针对文本摘要的人类评估挑战，提出了 QAPyramid 方法，以细粒度的方式评估内容选择。QAPyramid 使用 QA-SRL 框架将参考摘要分解成更系统的问答 (QA) 对，并为 CNN/DM 数据集收集了 8.9K QA 级注解，以评估 10 个摘要系统。与传统的 Pyramid 协议相比，QAPyramid 提供更精确的评估，同时保持高标注者间一致性，且无需专家参与。最后，论文引入了自动指标，这些指标与 QAPyramid 的相关性更高，便于未来高效基准测试摘要系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first two authors contributed equally. Code:\n  https://github.com/ZhangShiyue/QAPyramid",
      "pdf_url": "http://arxiv.org/pdf/2412.07096v1",
      "published_date": "2024-12-10 01:29:51 UTC",
      "updated_date": "2024-12-10 01:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:58:07.269244"
    },
    {
      "arxiv_id": "2412.07094v1",
      "title": "Access Point Deployment for Localizing Accuracy and User Rate in Cell-Free Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Fanfei Xu",
        "Shengheng Liu",
        "Zihuan Mao",
        "Shangqing Shi",
        "Dazhuan Xu",
        "Dongming Wang",
        "Yongming Huang"
      ],
      "abstract": "Evolving next-generation mobile networks is designed to provide ubiquitous\ncoverage and networked sensing. With utility of multi-view sensing and\nmulti-node joint transmission, cell-free is a promising technique to realize\nthis prospect. This paper aims to tackle the problem of access point (AP)\ndeployment in cell-free systems to balance the sensing accuracy and user rate.\nBy merging the D-optimality with Euclidean criterion, a novel integrated metric\nis proposed to be the objective function for both max-sum and max-min problems,\nwhich respectively guarantee the overall and lowest performance in multi-user\ncommunication and target tracking scenario. To solve the corresponding high\ndimensional non-convex multi-objective problem, the Soft actor-critic (SAC) is\nutilized to avoid risk of local optimal result. Numerical results demonstrate\nthat proposed SAC-based APs deployment method achieves $20\\%$ of overall\nperformance and $120\\%$ of lowest performance.",
      "tldr_zh": "这篇论文探讨了在 cell-free 系统中的接入点 (AP) 部署问题，旨在平衡定位准确性和用户速率，以实现无处不在的覆盖和网络感知。作者提出了一种新的集成指标，将 D-optimality 与 Euclidean 标准相结合，作为 max-sum 和 max-min 问题的目标函数，分别优化整体和最低性能。利用 Soft actor-critic (SAC) 算法解决高维非凸多目标优化问题，实验结果显示该方法使整体性能提升 20%，最低性能提升 120%。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Presented at MobiCom 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.07094v1",
      "published_date": "2024-12-10 01:22:32 UTC",
      "updated_date": "2024-12-10 01:22:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:58:18.636950"
    },
    {
      "arxiv_id": "2501.00009v1",
      "title": "Model-Driven Deep Neural Network for Enhanced AoA Estimation Using 5G gNB",
      "title_zh": "翻译失败",
      "authors": [
        "Shengheng Liu",
        "Xingkang Li",
        "Zihuan Mao",
        "Peng Liu",
        "Yongming Huang"
      ],
      "abstract": "High-accuracy positioning has become a fundamental enabler for intelligent\nconnected devices. Nevertheless, the present wireless networks still rely on\nmodel-driven approaches to achieve positioning functionality, which are\nsusceptible to performance degradation in practical scenarios, primarily due to\nhardware impairments. Integrating artificial intelligence into the positioning\nframework presents a promising solution to revolutionize the accuracy and\nrobustness of location-based services. In this study, we address this challenge\nby reformulating the problem of angle-of-arrival (AoA) estimation into image\nreconstruction of spatial spectrum. To this end, we design a model-driven deep\nneural network (MoD-DNN), which can automatically calibrate the\nangular-dependent phase error. The proposed MoD-DNN approach employs an\niterative optimization scheme between a convolutional neural network and a\nsparse conjugate gradient algorithm. Simulation and experimental results are\npresented to demonstrate the effectiveness of the proposed method in enhancing\nspectrum calibration and AoA estimation.",
      "tldr_zh": "本研究针对现有无线网络中依赖模型驱动的AoA（Angle-of-Arrival）估计方法易受硬件缺陷影响的问题，提出了一种基于5G gNB的MoD-DNN（Model-Driven Deep Neural Network）框架，将AoA估计转化为空间谱图像重建任务。MoD-DNN通过卷积神经网络（CNN）和稀疏共轭梯度算法（Sparse Conjugate Gradient Algorithm）的迭代优化方案，自动校准角度相关的相位误差，从而提升定位的准确性和鲁棒性。模拟和实验结果证明，该方法显著改善了谱校准和AoA估计性能，为智能连接设备的高精度定位提供了有效解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Presented at AAAI 2024 (Main Technical Track)",
      "pdf_url": "http://arxiv.org/pdf/2501.00009v1",
      "published_date": "2024-12-10 01:16:48 UTC",
      "updated_date": "2024-12-10 01:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:58:31.676953"
    },
    {
      "arxiv_id": "2412.07809v1",
      "title": "Fine-grained graph representation learning for heterogeneous mobile networks with attentive fusion and contrastive learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shengheng Liu",
        "Tianqi Zhang",
        "Ningning Fu",
        "Yongming Huang"
      ],
      "abstract": "AI becomes increasingly vital for telecom industry, as the burgeoning\ncomplexity of upcoming mobile communication networks places immense pressure on\nnetwork operators. While there is a growing consensus that intelligent network\nself-driving holds the key, it heavily relies on expert experience and\nknowledge extracted from network data. In an effort to facilitate convenient\nanalytics and utilization of wireless big data, we introduce the concept of\nknowledge graphs into the field of mobile networks, giving rise to what we term\nas wireless data knowledge graphs (WDKGs). However, the heterogeneous and\ndynamic nature of communication networks renders manual WDKG construction both\nprohibitively costly and error-prone, presenting a fundamental challenge. In\nthis context, we propose an unsupervised data-and-model driven graph structure\nlearning (DMGSL) framework, aimed at automating WDKG refinement and updating.\nTackling WDKG heterogeneity involves stratifying the network into homogeneous\nlayers and refining it at a finer granularity. Furthermore, to capture WDKG\ndynamics effectively, we segment the network into static snapshots based on the\ncoherence time and harness the power of recurrent neural networks to\nincorporate historical information. Extensive experiments conducted on the\nestablished WDKG demonstrate the superiority of the DMGSL over the baselines,\nparticularly in terms of node classification accuracy.",
      "tldr_zh": "该研究针对异构移动网络的复杂性，引入无线数据知识图 (WDKGs) 以促进网络数据分析，并提出一个无监督的数据和模型驱动图结构学习框架 (DMGSL)，用于自动精炼和更新 WDKGs。DMGSL 通过将网络分层处理异构性、采用注意力融合 (attentive fusion) 和对比学习 (contrastive learning) 进行细粒度图表示学习，以及利用循环神经网络 (RNN) 整合历史信息来捕捉网络动态。实验结果显示，DMGSL 在 WDKG 的节点分类准确率上显著优于基线模型，为智能网络自驱动提供高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in AAAI 2025 (Main Technical Track)",
      "pdf_url": "http://arxiv.org/pdf/2412.07809v1",
      "published_date": "2024-12-10 01:12:51 UTC",
      "updated_date": "2024-12-10 01:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:58:42.757894"
    },
    {
      "arxiv_id": "2412.07081v1",
      "title": "Sequential Controlled Langevin Diffusions",
      "title_zh": "序列受控朗之万扩散",
      "authors": [
        "Junhua Chen",
        "Lorenz Richter",
        "Julius Berner",
        "Denis Blessing",
        "Gerhard Neumann",
        "Anima Anandkumar"
      ],
      "abstract": "An effective approach for sampling from unnormalized densities is based on\nthe idea of gradually transporting samples from an easy prior to the\ncomplicated target distribution. Two popular methods are (1) Sequential Monte\nCarlo (SMC), where the transport is performed through successive annealed\ndensities via prescribed Markov chains and resampling steps, and (2) recently\ndeveloped diffusion-based sampling methods, where a learned dynamical transport\nis used. Despite the common goal, both approaches have different, often\ncomplementary, advantages and drawbacks. The resampling steps in SMC allow\nfocusing on promising regions of the space, often leading to robust\nperformance. While the algorithm enjoys asymptotic guarantees, the lack of\nflexible, learnable transitions can lead to slow convergence. On the other\nhand, diffusion-based samplers are learned and can potentially better adapt\nthemselves to the target at hand, yet often suffer from training instabilities.\nIn this work, we present a principled framework for combining SMC with\ndiffusion-based samplers by viewing both methods in continuous time and\nconsidering measures on path space. This culminates in the new Sequential\nControlled Langevin Diffusion (SCLD) sampling method, which is able to utilize\nthe benefits of both methods and reaches improved performance on multiple\nbenchmark problems, in many cases using only 10% of the training budget of\nprevious diffusion-based samplers.",
      "tldr_zh": "该论文提出了一种结合Sequential Monte Carlo (SMC) 和扩散采样方法的框架，用于从非标准化密度中采样样本。SMC 通过重采样步骤实现鲁棒性能，但可能收敛缓慢，而扩散采样则更灵活但易受训练不稳定影响；为此，作者在连续时间和路径空间的视角下，开发了新的Sequential Controlled Langevin Diffusion (SCLD) 方法，以充分利用两者优势。实验结果显示，SCLD 在多个基准问题上显著提升性能，仅需传统扩散采样方法的10% 训练预算。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07081v1",
      "published_date": "2024-12-10 00:47:10 UTC",
      "updated_date": "2024-12-10 00:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:58:53.743898"
    },
    {
      "arxiv_id": "2412.07080v1",
      "title": "EvRepSL: Event-Stream Representation via Self-Supervised Learning for Event-Based Vision",
      "title_zh": "EvRepSL：通过自监督学习的事件流表示用于基于事件的视觉",
      "authors": [
        "Qiang Qu",
        "Xiaoming Chen",
        "Yuk Ying Chung",
        "Yiran Shen"
      ],
      "abstract": "Event-stream representation is the first step for many computer vision tasks\nusing event cameras. It converts the asynchronous event-streams into a\nformatted structure so that conventional machine learning models can be applied\neasily. However, most of the state-of-the-art event-stream representations are\nmanually designed and the quality of these representations cannot be guaranteed\ndue to the noisy nature of event-streams. In this paper, we introduce a\ndata-driven approach aiming at enhancing the quality of event-stream\nrepresentations. Our approach commences with the introduction of a new\nevent-stream representation based on spatial-temporal statistics, denoted as\nEvRep. Subsequently, we theoretically derive the intrinsic relationship between\nasynchronous event-streams and synchronous video frames. Building upon this\ntheoretical relationship, we train a representation generator, RepGen, in a\nself-supervised learning manner accepting EvRep as input. Finally, the\nevent-streams are converted to high-quality representations, termed as EvRepSL,\nby going through the learned RepGen (without the need of fine-tuning or\nretraining). Our methodology is rigorously validated through extensive\nevaluations on a variety of mainstream event-based classification and optical\nflow datasets (captured with various types of event cameras). The experimental\nresults highlight not only our approach's superior performance over existing\nevent-stream representations but also its versatility, being agnostic to\ndifferent event cameras and tasks.",
      "tldr_zh": "本论文提出了一种基于自监督学习(Self-Supervised Learning)的创新方法EvRepSL，用于提升事件相机(event cameras)的事件流表示质量。论文首先引入EvRep，一种基于空间-时间统计的表示形式，并理论推导了异步事件流与同步视频帧的内在关系，然后训练表示生成器RepGen以EvRep作为输入，实现高质量事件流转换。实验结果显示，EvRepSL在多种事件分类和光流数据集上优于现有方法，并展示出对不同事件相机和任务的通用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Published on IEEE Transactions on Image Processing",
      "pdf_url": "http://arxiv.org/pdf/2412.07080v1",
      "published_date": "2024-12-10 00:42:54 UTC",
      "updated_date": "2024-12-10 00:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:59:06.463592"
    },
    {
      "arxiv_id": "2412.07078v1",
      "title": "Defensive Dual Masking for Robust Adversarial Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Wangli Yang",
        "Jie Yang",
        "Yi Guo",
        "Johan Barthelemy"
      ],
      "abstract": "The field of textual adversarial defenses has gained considerable attention\nin recent years due to the increasing vulnerability of natural language\nprocessing (NLP) models to adversarial attacks, which exploit subtle\nperturbations in input text to deceive models. This paper introduces the\nDefensive Dual Masking (DDM) algorithm, a novel approach designed to enhance\nmodel robustness against such attacks. DDM utilizes a unique adversarial\ntraining strategy where [MASK] tokens are strategically inserted into training\nsamples to prepare the model to handle adversarial perturbations more\neffectively. During inference, potentially adversarial tokens are dynamically\nreplaced with [MASK] tokens to neutralize potential threats while preserving\nthe core semantics of the input. The theoretical foundation of our approach is\nexplored, demonstrating how the selective masking mechanism strengthens the\nmodel's ability to identify and mitigate adversarial manipulations. Our\nempirical evaluation across a diverse set of benchmark datasets and attack\nmechanisms consistently shows that DDM outperforms state-of-the-art defense\ntechniques, improving model accuracy and robustness. Moreover, when applied to\nLarge Language Models (LLMs), DDM also enhances their resilience to adversarial\nattacks, providing a scalable defense mechanism for large-scale NLP\napplications.",
      "tldr_zh": "这篇论文提出了Defensive Dual Masking (DDM)算法，一种创新的对抗训练策略，用于提升自然语言处理(NLP)模型对文本对抗攻击的鲁棒性。DDM通过在训练样本中战略性地插入[MASK] tokens，并在推理阶段动态替换潜在的对抗tokens，来强化模型识别和缓解扰动的能力，同时保留输入的核心语义。实验评估显示，DDM在多种基准数据集和攻击机制上优于现有最先进技术，提高了模型准确性和鲁棒性，并为Large Language Models (LLMs)提供了可扩展的防御机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "First version",
      "pdf_url": "http://arxiv.org/pdf/2412.07078v1",
      "published_date": "2024-12-10 00:41:25 UTC",
      "updated_date": "2024-12-10 00:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:59:19.142068"
    },
    {
      "arxiv_id": "2412.07066v1",
      "title": "The Mirage of Artificial Intelligence Terms of Use Restrictions",
      "title_zh": "人工智能使用条款限制的幻影",
      "authors": [
        "Peter Henderson",
        "Mark A. Lemley"
      ],
      "abstract": "Artificial intelligence (AI) model creators commonly attach restrictive terms\nof use to both their models and their outputs. These terms typically prohibit\nactivities ranging from creating competing AI models to spreading\ndisinformation. Often taken at face value, these terms are positioned by\ncompanies as key enforceable tools for preventing misuse, particularly in\npolicy dialogs. But are these terms truly meaningful? There are myriad examples\nwhere these broad terms are regularly and repeatedly violated. Yet except for\nsome account suspensions on platforms, no model creator has actually tried to\nenforce these terms with monetary penalties or injunctive relief. This is\nlikely for good reason: we think that the legal enforceability of these\nlicenses is questionable.\n  This Article systematically assesses of the enforceability of AI model terms\nof use and offers three contributions. First, we pinpoint a key problem: the\nartifacts that they protect, namely model weights and model outputs, are\nlargely not copyrightable, making it unclear whether there is even anything to\nbe licensed. Second, we examine the problems this creates for other\nenforcement. Recent doctrinal trends in copyright preemption may further\nundermine state-law claims, while other legal frameworks like the DMCA and CFAA\noffer limited recourse. Anti-competitive provisions likely fare even worse than\nresponsible use provisions. Third, we provide recommendations to policymakers.\nThere are compelling reasons for many provisions to be unenforceable: they\nchill good faith research, constrain competition, and create quasi-copyright\nownership where none should exist. There are, of course, downsides: model\ncreators have fewer tools to prevent harmful misuse. But we think the better\napproach is for statutory provisions, not private fiat, to distinguish between\ngood and bad uses of AI, restricting the latter.",
      "tldr_zh": "这篇论文探讨了AI模型使用条款(Terms of Use)的限制性规定，这些条款通常禁止创建竞争模型或传播虚假信息，但实际执行率极低，可能缺乏法律依据。作者系统评估了这些条款的可执行性，发现模型权重和输出往往不被版权保护，这使得许可基础不牢靠，并进一步分析了版权抢占(Copyright Preemption)、DMCA和CFAA等框架的局限性。论文推荐政策制定者避免这些条款抑制正当研究和竞争，而是通过法定规定来区分AI的合法与非法使用，以更好地管理潜在风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Forthcoming Indiana Law Journal",
      "pdf_url": "http://arxiv.org/pdf/2412.07066v1",
      "published_date": "2024-12-10 00:18:29 UTC",
      "updated_date": "2024-12-10 00:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T10:59:31.267242"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 136,
  "processed_papers_count": 136,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T10:59:54.036074"
}