[
  {
    "arxiv_id": "2402.09448v1",
    "title": "A Comparative Study of Conventional and Tripolar EEG for High-Performance Reach-to-Grasp BCI Systems",
    "authors": [
      "Ali Rabiee",
      "Sima Ghafoori",
      "Anna Cetera",
      "Walter Besio",
      "Reza Abiri"
    ],
    "abstract": "This study aims to enhance BCI applications for individuals with motor\nimpairments by comparing the effectiveness of tripolar EEG (tEEG) with\nconventional EEG. The focus is on interpreting and decoding various grasping\nmovements, such as power grasp and precision grasp. The goal is to determine\nwhich EEG technology is more effective in processing and translating grasp\nrelated neural signals. The approach involved experimenting on ten healthy\nparticipants who performed two distinct grasp movements: power grasp and\nprecision grasp, with a no movement condition serving as the baseline. Our\nresearch presents a thorough comparison between EEG and tEEG in decoding\ngrasping movements. This comparison spans several key parameters, including\nsignal to noise ratio (SNR), spatial resolution via functional connectivity,\nERPs, and wavelet time frequency analysis. Additionally, our study involved\nextracting and analyzing statistical features from the wavelet coefficients,\nand both binary and multiclass classification methods were employed. Four\nmachine learning algorithms were used to evaluate the decoding accuracies. Our\nresults indicated that tEEG demonstrated superior performance over conventional\nEEG in various aspects. This included a higher signal to noise ratio, enhanced\nspatial resolution, and more informative data in ERPs and wavelet time\nfrequency analysis. The use of tEEG led to notable improvements in decoding\naccuracy for differentiating movement types. Specifically, tEEG achieved around\n90% accuracy in binary and 75.97% for multiclass classification. These results\nare markedly better than those from standard EEG, which recorded a maximum of\n77.85% and 61.27% in similar tasks, respectively. These findings highlight the\nsuperior effectiveness of tEEG over EEG in decoding grasp types and its\ncompetitive or superior performance in complex classifications compared with\nexisting research.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09448v1",
    "published_date": "2024-01-31 23:35:44 UTC",
    "updated_date": "2024-01-31 23:35:44 UTC"
  },
  {
    "arxiv_id": "2402.00234v2",
    "title": "Can Generative AI Support Patients' & Caregivers' Informational Needs? Towards Task-Centric Evaluation Of AI Systems",
    "authors": [
      "Shreya Rajagopal",
      "Jae Ho Sohn",
      "Hari Subramonyam",
      "Shiwali Mohan"
    ],
    "abstract": "Generative AI systems such as ChatGPT and Claude are built upon language\nmodels that are typically evaluated for accuracy on curated benchmark datasets.\nSuch evaluation paradigms measure predictive and reasoning capabilities of\nlanguage models but do not assess if they can provide information that is\nuseful to people. In this paper, we take some initial steps in developing an\nevaluation paradigm that centers human understanding and decision-making. We\nstudy the utility of generative AI systems in supporting people in a concrete\ntask - making sense of clinical reports and imagery in order to make a clinical\ndecision. We conducted a formative need-finding study in which participants\ndiscussed chest computed tomography (CT) scans and associated radiology reports\nof a fictitious close relative with a cardiothoracic radiologist. Using\nthematic analysis of the conversation between participants and medical experts,\nwe identified commonly occurring themes across interactions, including\nclarifying medical terminology, locating the problems mentioned in the report\nin the scanned image, understanding disease prognosis, discussing the next\ndiagnostic steps, and comparing treatment options. Based on these themes, we\nevaluated two state-of-the-art generative AI systems against the radiologist's\nresponses. Our results reveal variability in the quality of responses generated\nby the models across various themes. We highlight the importance of\npatient-facing generative AI systems to accommodate a diverse range of\nconversational themes, catering to the real-world informational needs of\npatients.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00234v2",
    "published_date": "2024-01-31 23:24:37 UTC",
    "updated_date": "2025-02-28 05:46:53 UTC"
  },
  {
    "arxiv_id": "2402.00901v1",
    "title": "Real Sparks of Artificial Intelligence and the Importance of Inner Interpretability",
    "authors": [
      "Alex Grzankowski"
    ],
    "abstract": "The present paper looks at one of the most thorough articles on the\nintelligence of GPT, research conducted by engineers at Microsoft. Although\nthere is a great deal of value in their work, I will argue that, for familiar\nphilosophical reasons, their methodology, !Blackbox Interpretability\"#is\nwrongheaded. But there is a better way. There is an exciting and emerging\ndiscipline of !Inner Interpretability\"#(and specifically Mechanistic\nInterpretability) that aims to uncover the internal activations and weights of\nmodels in order to understand what they represent and the algorithms they\nimplement. In my view, a crucial mistake in Black-box Interpretability is the\nfailure to appreciate that how processes are carried out matters when it comes\nto intelligence and understanding. I can#t pretend to have a full story that\nprovides both necessary and sufficient conditions for being intelligent, but I\ndo think that Inner Interpretability dovetails nicely with plausible\nphilosophical views of what intelligence requires. So the conclusion is modest,\nbut the important point in my view is seeing how to get the research on the\nright track. Towards the end of the paper, I will show how some of the\nphilosophical concepts can be used to further refine how Inner Interpretability\nis approached, so the paper helps draw out a profitable, future two-way\nexchange between Philosophers and Computer Scientists.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00901v1",
    "published_date": "2024-01-31 23:22:13 UTC",
    "updated_date": "2024-01-31 23:22:13 UTC"
  },
  {
    "arxiv_id": "2402.00232v1",
    "title": "Learning Label Hierarchy with Supervised Contrastive Learning",
    "authors": [
      "Ruixue Lian",
      "William A. Sethares",
      "Junjie Hu"
    ],
    "abstract": "Supervised contrastive learning (SCL) frameworks treat each class as\nindependent and thus consider all classes to be equally important. This\nneglects the common scenario in which label hierarchy exists, where\nfine-grained classes under the same category show more similarity than very\ndifferent ones. This paper introduces a family of Label-Aware SCL methods\n(LASCL) that incorporates hierarchical information to SCL by leveraging\nsimilarities between classes, resulting in creating a more well-structured and\ndiscriminative feature space. This is achieved by first adjusting the distance\nbetween instances based on measures of the proximity of their classes with the\nscaled instance-instance-wise contrastive. An additional instance-center-wise\ncontrastive is introduced to move within-class examples closer to their\ncenters, which are represented by a set of learnable label parameters. The\nlearned label parameters can be directly used as a nearest neighbor classifier\nwithout further finetuning. In this way, a better feature representation is\ngenerated with improvements of intra-cluster compactness and inter-cluster\nseparation. Experiments on three datasets show that the proposed LASCL works\nwell on text classification of distinguishing a single label among\nmulti-labels, outperforming the baseline supervised approaches. Our code is\npublicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00232v1",
    "published_date": "2024-01-31 23:21:40 UTC",
    "updated_date": "2024-01-31 23:21:40 UTC"
  },
  {
    "arxiv_id": "2402.09447v1",
    "title": "Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types",
    "authors": [
      "Ali Rabiee",
      "Sima Ghafoori",
      "Anna Cetera",
      "Reza Abiri"
    ],
    "abstract": "This research aims to decode hand grasps from Electroencephalograms (EEGs)\nfor dexterous neuroprosthetic development and Brain-Computer Interface (BCI)\napplications, especially for patients with motor disorders. Particularly, it\nfocuses on distinguishing two complex natural power and precision grasps in\naddition to a neutral condition as a no-movement condition using a new\nEEG-based BCI platform and wavelet signal processing. Wavelet analysis involved\ngenerating time-frequency and topographic maps from wavelet power coefficients.\nThen, by using machine learning techniques with novel wavelet features, we\nachieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement\nvs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs\nPrecision, demonstrating the effectiveness of these features in EEG-based grasp\ndifferentiation. In contrast to previous studies, a critical part of our study\nwas permutation feature importance analysis, which highlighted key features for\ngrasp classification. It revealed that the most crucial brain activities during\ngrasping occur in the motor cortex, within the alpha and beta frequency bands.\nThese insights demonstrate the potential of wavelet features in real-time\nneuroprosthetic technology and BCI applications.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.09447v1",
    "published_date": "2024-01-31 23:13:38 UTC",
    "updated_date": "2024-01-31 23:13:38 UTC"
  },
  {
    "arxiv_id": "2403.07885v1",
    "title": "MOD-CL: Multi-label Object Detection with Constrained Loss",
    "authors": [
      "Sota Moriyama",
      "Koji Watanabe",
      "Katsumi Inoue",
      "Akihiro Takemura"
    ],
    "abstract": "We introduce MOD-CL, a multi-label object detection framework that utilizes\nconstrained loss in the training process to produce outputs that better satisfy\nthe given requirements. In this paper, we use $\\mathrm{MOD_{YOLO}}$, a\nmulti-label object detection model built upon the state-of-the-art object\ndetection model YOLOv8, which has been published in recent years. In Task 1, we\nintroduce the Corrector Model and Blender Model, two new models that follow\nafter the object detection process, aiming to generate a more constrained\noutput. For Task 2, constrained losses have been incorporated into the\n$\\mathrm{MOD_{YOLO}}$ architecture using Product T-Norm. The results show that\nthese implementations are instrumental to improving the scores for both Task 1\nand Task 2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07885v1",
    "published_date": "2024-01-31 23:13:20 UTC",
    "updated_date": "2024-01-31 23:13:20 UTC"
  },
  {
    "arxiv_id": "2402.15514v2",
    "title": "Large Scale Generative AI Text Applied to Sports and Music",
    "authors": [
      "Aaron Baughman",
      "Stephen Hammer",
      "Rahul Agarwal",
      "Gozde Akay",
      "Eduardo Morales",
      "Tony Johnson",
      "Leonid Karlinsky",
      "Rogerio Feris"
    ],
    "abstract": "We address the problem of scaling up the production of media content,\nincluding commentary and personalized news stories, for large-scale sports and\nmusic events worldwide. Our approach relies on generative AI models to\ntransform a large volume of multimodal data (e.g., videos, articles, real-time\nscoring feeds, statistics, and fact sheets) into coherent and fluent text.\nBased on this approach, we introduce, for the first time, an AI commentary\nsystem, which was deployed to produce automated narrations for highlight\npackages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same\nvein, our solution was extended to create personalized content for ESPN Fantasy\nFootball and stories about music artists for the Grammy awards. These\napplications were built using a common software architecture achieved a 15x\nspeed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our\nwork was successfully deployed at the aforementioned events, supporting 90\nmillion fans around the world with 8 billion page views, continuously pushing\nthe bounds on what is possible at the intersection of sports, entertainment,\nand AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2402.15514v2",
    "published_date": "2024-01-31 22:47:01 UTC",
    "updated_date": "2024-02-28 00:03:57 UTC"
  },
  {
    "arxiv_id": "2402.00219v1",
    "title": "FedCore: Straggler-Free Federated Learning with Distributed Coresets",
    "authors": [
      "Hongpeng Guo",
      "Haotian Gu",
      "Xiaoyang Wang",
      "Bo Chen",
      "Eun Kyung Lee",
      "Tamar Eilam",
      "Deming Chen",
      "Klara Nahrstedt"
    ],
    "abstract": "Federated learning (FL) is a machine learning paradigm that allows multiple\nclients to collaboratively train a shared model while keeping their data\non-premise. However, the straggler issue, due to slow clients, often hinders\nthe efficiency and scalability of FL. This paper presents FedCore, an algorithm\nthat innovatively tackles the straggler problem via the decentralized selection\nof coresets, representative subsets of a dataset. Contrary to existing\ncentralized coreset methods, FedCore creates coresets directly on each client\nin a distributed manner, ensuring privacy preservation in FL. FedCore\ntranslates the coreset optimization problem into a more tractable k-medoids\nclustering problem and operates distributedly on each client. Theoretical\nanalysis confirms FedCore's convergence, and practical evaluations demonstrate\nan 8x reduction in FL training time, without compromising model accuracy. Our\nextensive evaluations also show that FedCore generalizes well to existing FL\nframeworks.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00219v1",
    "published_date": "2024-01-31 22:40:49 UTC",
    "updated_date": "2024-01-31 22:40:49 UTC"
  },
  {
    "arxiv_id": "2402.00163v1",
    "title": "Improving Object Detection Quality in Football Through Super-Resolution Techniques",
    "authors": [
      "Karolina Seweryn",
      "Gabriel Chęć",
      "Szymon Łukasik",
      "Anna Wróblewska"
    ],
    "abstract": "This study explores the potential of super-resolution techniques in enhancing\nobject detection accuracy in football. Given the sport's fast-paced nature and\nthe critical importance of precise object (e.g. ball, player) tracking for both\nanalysis and broadcasting, super-resolution could offer significant\nimprovements. We investigate how advanced image processing through\nsuper-resolution impacts the accuracy and reliability of object detection\nalgorithms in processing football match footage.\n  Our methodology involved applying state-of-the-art super-resolution\ntechniques to a diverse set of football match videos from SoccerNet, followed\nby object detection using Faster R-CNN. The performance of these algorithms,\nboth with and without super-resolution enhancement, was rigorously evaluated in\nterms of detection accuracy.\n  The results indicate a marked improvement in object detection accuracy when\nsuper-resolution preprocessing is applied. The improvement of object detection\nthrough the integration of super-resolution techniques yields significant\nbenefits, especially for low-resolution scenarios, with a notable 12\\% increase\nin mean Average Precision (mAP) at an IoU (Intersection over Union) range of\n0.50:0.95 for 320x240 size images when increasing the resolution fourfold using\nRLFN. As the dimensions increase, the magnitude of improvement becomes more\nsubdued; however, a discernible improvement in the quality of detection is\nconsistently evident. Additionally, we discuss the implications of these\nfindings for real-time sports analytics, player tracking, and the overall\nviewing experience. The study contributes to the growing field of sports\ntechnology by demonstrating the practical benefits and limitations of\nintegrating super-resolution techniques in football analytics and broadcasting.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00163v1",
    "published_date": "2024-01-31 20:37:35 UTC",
    "updated_date": "2024-01-31 20:37:35 UTC"
  },
  {
    "arxiv_id": "2402.00899v3",
    "title": "Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees",
    "authors": [
      "Ivan Y. Tyukin",
      "Tatiana Tyukina",
      "Daniel van Helden",
      "Zedong Zheng",
      "Evgeny M. Mirkes",
      "Oliver J. Sutton",
      "Qinghua Zhou",
      "Alexander N. Gorban",
      "Penelope Allison"
    ],
    "abstract": "We present a new methodology for handling AI errors by introducing weakly\nsupervised AI error correctors with a priori performance guarantees. These AI\ncorrectors are auxiliary maps whose role is to moderate the decisions of some\npreviously constructed underlying classifier by either approving or rejecting\nits decisions. The rejection of a decision can be used as a signal to suggest\nabstaining from making a decision. A key technical focus of the work is in\nproviding performance guarantees for these new AI correctors through bounds on\nthe probabilities of incorrect decisions. These bounds are distribution\nagnostic and do not rely on assumptions on the data dimension. Our empirical\nexample illustrates how the framework can be applied to improve the performance\nof an image classifier in a challenging real-world task where training data are\nscarce.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "68T05, 68T37"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00899v3",
    "published_date": "2024-01-31 20:36:13 UTC",
    "updated_date": "2024-02-13 15:53:06 UTC"
  },
  {
    "arxiv_id": "2402.00138v2",
    "title": "Decomposable Submodular Maximization in Federated Setting",
    "authors": [
      "Akbar Rafiey"
    ],
    "abstract": "Submodular functions, as well as the sub-class of decomposable submodular\nfunctions, and their optimization appear in a wide range of applications in\nmachine learning, recommendation systems, and welfare maximization. However,\noptimization of decomposable submodular functions with millions of component\nfunctions is computationally prohibitive. Furthermore, the component functions\nmay be private (they might represent user preference function, for example) and\ncannot be widely shared. To address these issues, we propose a {\\em federated\noptimization} setting for decomposable submodular optimization. In this\nsetting, clients have their own preference functions, and a weighted sum of\nthese preferences needs to be maximized. We implement the popular {\\em\ncontinuous greedy} algorithm in this setting where clients take parallel small\nlocal steps towards the local solution and then the local changes are\naggregated at a central server. To address the large number of clients, the\naggregation is performed only on a subsampled set. Further, the aggregation is\nperformed only intermittently between stretches of parallel local steps, which\nreduces communication cost significantly. We show that our federated algorithm\nis guaranteed to provide a good approximate solution, even in the presence of\nabove cost-cutting measures. Finally, we show how the federated setting can be\nincorporated in solving fundamental discrete submodular optimization problems\nsuch as Maximum Coverage and Facility Location.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00138v2",
    "published_date": "2024-01-31 19:32:33 UTC",
    "updated_date": "2024-06-03 06:05:29 UTC"
  },
  {
    "arxiv_id": "2402.00135v1",
    "title": "A Reinforcement Learning Based Controller to Minimize Forces on the Crutches of a Lower-Limb Exoskeleton",
    "authors": [
      "Aydin Emre Utku",
      "Suzan Ece Ada",
      "Muhammet Hatipoglu",
      "Mustafa Derman",
      "Emre Ugur",
      "Evren Samur"
    ],
    "abstract": "Metabolic energy consumption of a powered lower-limb exoskeleton user mainly\ncomes from the upper body effort since the lower body is considered to be\npassive. However, the upper body effort of the users is largely ignored in the\nliterature when designing motion controllers. In this work, we use deep\nreinforcement learning to develop a locomotion controller that minimizes ground\nreaction forces (GRF) on crutches. The rationale for minimizing GRF is to\nreduce the upper body effort of the user. Accordingly, we design a model and a\nlearning framework for a human-exoskeleton system with crutches. We formulate a\nreward function to encourage the forward displacement of a human-exoskeleton\nsystem while satisfying the predetermined constraints of a physical robot. We\nevaluate our new framework using Proximal Policy Optimization, a\nstate-of-the-art deep reinforcement learning (RL) method, on the MuJoCo physics\nsimulator with different hyperparameters and network architectures over\nmultiple trials. We empirically show that our learning model can generate joint\ntorques based on the joint angle, velocities, and the GRF on the feet and\ncrutch tips. The resulting exoskeleton model can directly generate joint\ntorques from states in line with the RL framework. Finally, we empirically show\nthat policy trained using our method can generate a gait with a 35% reduction\nin GRF with respect to the baseline.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 5 Figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00135v1",
    "published_date": "2024-01-31 19:20:56 UTC",
    "updated_date": "2024-01-31 19:20:56 UTC"
  },
  {
    "arxiv_id": "2401.18070v2",
    "title": "Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?",
    "authors": [
      "Andreas Opedal",
      "Alessandro Stolfo",
      "Haruki Shirakami",
      "Ying Jiao",
      "Ryan Cotterell",
      "Bernhard Schölkopf",
      "Abulhair Saparov",
      "Mrinmaya Sachan"
    ],
    "abstract": "There is increasing interest in employing large language models (LLMs) as\ncognitive models. For such purposes, it is central to understand which\nproperties of human cognition are well-modeled by LLMs, and which are not. In\nthis work, we study the biases of LLMs in relation to those known in children\nwhen solving arithmetic word problems. Surveying the learning science\nliterature, we posit that the problem-solving process can be split into three\ndistinct steps: text comprehension, solution planning and solution execution.\nWe construct tests for each one in order to understand whether current LLMs\ndisplay the same cognitive biases as children in these steps. We generate a\nnovel set of word problems for each of these tests, using a neuro-symbolic\napproach that enables fine-grained control over the problem features. We find\nevidence that LLMs, with and without instruction-tuning, exhibit human-like\nbiases in both the text-comprehension and the solution-planning steps of the\nsolving process, but not in the final step, in which the arithmetic expressions\nare executed to obtain the answer.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.18070v2",
    "published_date": "2024-01-31 18:48:20 UTC",
    "updated_date": "2024-06-17 15:08:05 UTC"
  },
  {
    "arxiv_id": "2401.18045v1",
    "title": "SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition",
    "authors": [
      "Yihan Wu",
      "Soumi Maiti",
      "Yifan Peng",
      "Wangyou Zhang",
      "Chenda Li",
      "Yuyue Wang",
      "Xihua Wang",
      "Shinji Watanabe",
      "Ruihua Song"
    ],
    "abstract": "Recent advancements in language models have significantly enhanced\nperformance in multiple speech-related tasks. Existing speech language models\ntypically utilize task-dependent prompt tokens to unify various speech tasks in\na single model. However, this design omits the intrinsic connections between\ndifferent speech tasks, which can potentially boost the performance of each\ntask. In this work, we propose a novel decoder-only speech language model,\nSpeechComposer, that can unify common speech tasks by composing a fixed set of\nprompt tokens. Built upon four primary tasks -- speech synthesis, speech\nrecognition, speech language modeling, and text language modeling --\nSpeechComposer can easily extend to more speech tasks via compositions of\nwell-designed prompt tokens, like voice conversion and speech enhancement. The\nunification of prompt tokens also makes it possible for knowledge sharing among\ndifferent speech tasks in a more structured manner. Experimental results\ndemonstrate that our proposed SpeechComposer can improve the performance of\nboth primary tasks and composite tasks, showing the effectiveness of the shared\nprompt tokens. Remarkably, the unified decoder-only model achieves a comparable\nand even better performance than the baselines which are expert models designed\nfor single tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.18045v1",
    "published_date": "2024-01-31 18:06:29 UTC",
    "updated_date": "2024-01-31 18:06:29 UTC"
  },
  {
    "arxiv_id": "2401.18040v2",
    "title": "Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability",
    "authors": [
      "Navin Kamuni",
      "Hardik Shah",
      "Sathishkumar Chintala",
      "Naveen Kunchakuri",
      "Sujatha Alla Old Dominion"
    ],
    "abstract": "End-to-end multi-task dialogue systems are usually designed with separate\nmodules for the dialogue pipeline. Among these, the policy module is essential\nfor deciding what to do in response to user input. This policy is trained by\nreinforcement learning algorithms by taking advantage of an environment in\nwhich an agent receives feedback in the form of a reward signal. The current\ndialogue systems, however, only provide meagre and simplistic rewards.\nInvestigating intrinsic motivation reinforcement learning algorithms is the\ngoal of this study. Through this, the agent can quickly accelerate training and\nimprove its capacity to judge the quality of its actions by teaching it an\ninternal incentive system. In particular, we adapt techniques for random\nnetwork distillation and curiosity-driven reinforcement learning to measure the\nfrequency of state visits and encourage exploration by using semantic\nsimilarity between utterances. Experimental results on MultiWOZ, a\nheterogeneous dataset, show that intrinsic motivation-based debate systems\noutperform policies that depend on extrinsic incentives. By adopting random\nnetwork distillation, for example, which is trained using semantic similarity\nbetween user-system dialogues, an astounding average success rate of 73% is\nachieved. This is a significant improvement over the baseline Proximal Policy\nOptimization (PPO), which has an average success rate of 60%. In addition,\nperformance indicators such as booking rates and completion rates show a 10%\nrise over the baseline. Furthermore, these intrinsic incentive models help\nimprove the system's policy's resilience in an increasing amount of domains.\nThis implies that they could be useful in scaling up to settings that cover a\nwider range of domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 figure, 18th IEEE International Conference on Semantic\n  Computing",
    "pdf_url": "http://arxiv.org/pdf/2401.18040v2",
    "published_date": "2024-01-31 18:03:39 UTC",
    "updated_date": "2024-03-25 23:03:58 UTC"
  },
  {
    "arxiv_id": "2401.18034v2",
    "title": "Paramanu: A Family of Novel Efficient Generative Foundation Language Models for Indian Languages",
    "authors": [
      "Mitodru Niyogi",
      "Arnab Bhattacharya"
    ],
    "abstract": "We present \"Paramanu\", a family of novel language models (LM) for Indian\nlanguages, consisting of auto-regressive monolingual, bilingual, and\nmultilingual models pretrained from scratch. Currently, it covers 10 languages\n(Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil,\nTelugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu). The models\nare pretrained on a single GPU with context size of 1024 and vary in size from\n13.29 million (M) to 367.5 M parameters. We proposed a RoPE embedding scaling\nmethod that enables us to pretrain language models from scratch at larger\nsequence length context size than typical GPU memory permits. We also\nintroduced a novel efficient Indic tokenizer, \"mBharat\", using a combination of\nBPE and Unigram, achieving the least fertility score and the ability to\ntokenize unseen languages in both the same script & Roman script. We also\nproposed and performed language-specific tokenization for multilingual models &\ndomain-specific tokenization for monolingual models. To address the \"curse of\nmultilinguality\" in our mParamanu model, we pretrained on comparable corpora\nbased on typological grouping within the same script. Our findings show a\nlanguage transfer phenomenon from low-resource to high-resource languages\nwithin languages of the same script & typology. Human evaluations for\nopen-ended text generation demonstrated that Paramanu models outperformed\nseveral LLMs, despite being 20 to 64 times smaller. We created\ninstruction-tuning datasets & instruction-tuned our models on 23,000\ninstructions in respective languages. Comparisons with multilingual LLMs across\nvarious benchmarks for natural language (NL) understanding, NL inference, &\nreading comprehension highlight the advantages of our models; leads to the\nconclusion that high quality generative LM are possible without high amount of\ncompute power & enormous number of parameters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.18034v2",
    "published_date": "2024-01-31 17:58:10 UTC",
    "updated_date": "2024-10-10 16:19:59 UTC"
  },
  {
    "arxiv_id": "2402.10930v3",
    "title": "ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters",
    "authors": [
      "Shiwei Liu",
      "Guanchen Tao",
      "Yifei Zou",
      "Derek Chow",
      "Zichen Fan",
      "Kauna Lei",
      "Bangfei Pan",
      "Dennis Sylvester",
      "Gregory Kielian",
      "Mehdi Saligane"
    ],
    "abstract": "The self-attention mechanism distinguishes transformer-based large language\nmodels (LLMs) apart from convolutional and recurrent neural networks. Despite\nthe performance improvement, achieving real-time LLM inference on silicon\nremains challenging due to the extensive use of Softmax in self-attention. In\naddition to the non-linearity, the low arithmetic intensity significantly\nlimits processing parallelism, especially when working with longer contexts. To\naddress this challenge, we propose Constant Softmax (ConSmax), a\nsoftware-hardware co-design that serves as an efficient alternative to Softmax.\nConSmax utilizes differentiable normalization parameters to eliminate the need\nfor maximum searching and denominator summation in Softmax. This approach\nenables extensive parallelization while still executing the essential functions\nof Softmax. Moreover, a scalable ConSmax hardware design with a bitwidth-split\nlook-up table (LUT) can achieve lossless non-linear operations and support\nmixed-precision computing. Experimental results show that ConSmax achieves a\nminuscule power consumption of 0.2mW and an area of 0.0008mm^2 at 1250MHz\nworking frequency in 16nm FinFET technology. For open-source contribution, we\nfurther implement our design with the OpenROAD toolchain under SkyWater's 130nm\nCMOS technology. The corresponding power is 2.69mW and the area is 0.007mm^2.\nConSmax achieves 3.35x power savings and 2.75x area savings in 16nm technology,\nand 3.15x power savings and 4.14x area savings with the open-source EDA\ntoolchain. In the meantime, it also maintains comparable accuracy on the GPT-2\nmodel and the WikiText103 dataset. The project is available at\nhttps://github.com/ReaLLMASIC/ConSmax",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.10930v3",
    "published_date": "2024-01-31 17:52:52 UTC",
    "updated_date": "2024-11-15 00:09:44 UTC"
  },
  {
    "arxiv_id": "2401.18028v2",
    "title": "Evaluating the Capabilities of LLMs for Supporting Anticipatory Impact Assessment",
    "authors": [
      "Mowafak Allaham",
      "Nicholas Diakopoulos"
    ],
    "abstract": "Gaining insight into the potential negative impacts of emerging Artificial\nIntelligence (AI) technologies in society is a challenge for implementing\nanticipatory governance approaches. One approach to produce such insight is to\nuse Large Language Models (LLMs) to support and guide experts in the process of\nideating and exploring the range of undesirable consequences of emerging\ntechnologies. However, performance evaluations of LLMs for such tasks are still\nneeded, including examining the general quality of generated impacts but also\nthe range of types of impacts produced and resulting biases. In this paper, we\ndemonstrate the potential for generating high-quality and diverse impacts of AI\nin society by fine-tuning completion models (GPT-3 and Mistral-7B) on a diverse\nsample of articles from news media and comparing those outputs to the impacts\ngenerated by instruction-based (GPT-4 and Mistral-7B-Instruct) models. We\nexamine the generated impacts for coherence, structure, relevance, and\nplausibility and find that the generated impacts using Mistral-7B, a small\nopen-source model fine-tuned on impacts from the news media, tend to be\nqualitatively on par with impacts generated using a more capable and larger\nscale model such as GPT-4. Moreover, we find that impacts produced by\ninstruction-based models had gaps in the production of certain categories of\nimpacts in comparison to fine-tuned models. This research highlights a\npotential bias in the range of impacts generated by state-of-the-art LLMs and\nthe potential of aligning smaller LLMs on news media as a scalable alternative\nto generate high quality and more diverse impacts in support of anticipatory\ngovernance approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages + research ethics and social impact statement, references,\n  and appendix. Under conference review",
    "pdf_url": "http://arxiv.org/pdf/2401.18028v2",
    "published_date": "2024-01-31 17:43:04 UTC",
    "updated_date": "2024-05-20 23:34:39 UTC"
  },
  {
    "arxiv_id": "2401.18018v4",
    "title": "On Prompt-Driven Safeguarding for Large Language Models",
    "authors": [
      "Chujie Zheng",
      "Fan Yin",
      "Hao Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Kai-Wei Chang",
      "Minlie Huang",
      "Nanyun Peng"
    ],
    "abstract": "Prepending model inputs with safety prompts is a common practice for\nsafeguarding large language models (LLMs) against queries with harmful intents.\nHowever, the underlying working mechanisms of safety prompts have not been\nunraveled yet, restricting the possibility of automatically optimizing them to\nimprove LLM safety. In this work, we investigate how LLMs' behavior (i.e.,\ncomplying with or refusing user queries) is affected by safety prompts from the\nperspective of model representation. We find that in the representation space,\nthe input queries are typically moved by safety prompts in a \"higher-refusal\"\ndirection, in which models become more prone to refusing to provide assistance,\neven when the queries are harmless. On the other hand, LLMs are naturally\ncapable of distinguishing harmful and harmless queries without safety prompts.\nInspired by these findings, we propose a method for safety prompt optimization,\nnamely DRO (Directed Representation Optimization). Treating a safety prompt as\ncontinuous, trainable embeddings, DRO learns to move the queries'\nrepresentations along or opposite the refusal direction, depending on their\nharmfulness. Experiments with eight LLMs on out-of-domain and jailbreak\nbenchmarks demonstrate that DRO remarkably improves the safeguarding\nperformance of human-crafted safety prompts, without compromising the models'\ngeneral performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.18018v4",
    "published_date": "2024-01-31 17:28:24 UTC",
    "updated_date": "2024-06-03 06:52:58 UTC"
  },
  {
    "arxiv_id": "2402.09445v2",
    "title": "iMove: Exploring Bio-impedance Sensing for Fitness Activity Recognition",
    "authors": [
      "Mengxi Liu",
      "Vitor Fortes Rey",
      "Yu Zhang",
      "Lala Shakti Swarup Ray",
      "Bo Zhou",
      "Paul Lukowicz"
    ],
    "abstract": "Automatic and precise fitness activity recognition can be beneficial in\naspects from promoting a healthy lifestyle to personalized preventative\nhealthcare. While IMUs are currently the prominent fitness tracking modality,\nthrough iMove, we show bio-impedence can help improve IMU-based fitness\ntracking through sensor fusion and contrastive learning.To evaluate our\nmethods, we conducted an experiment including six upper body fitness activities\nperformed by ten subjects over five days to collect synchronized data from\nbio-impedance across two wrists and IMU on the left wrist.The contrastive\nlearning framework uses the two modalities to train a better IMU-only\nclassification model, where bio-impedance is only required at the training\nphase, by which the average Macro F1 score with the input of a single IMU was\nimproved by 3.22 \\% reaching 84.71 \\% compared to the 81.49 \\% of the IMU\nbaseline model. We have also shown how bio-impedance can improve human activity\nrecognition (HAR) directly through sensor fusion, reaching an average Macro F1\nscore of 89.57 \\% (two modalities required for both training and inference)\neven if Bio-impedance alone has an average macro F1 score of 75.36 \\%, which is\noutperformed by IMU alone. In addition, similar results were obtained in an\nextended study on lower body fitness activity classification, demonstrating the\ngeneralisability of our approach.Our findings underscore the potential of\nsensor fusion and contrastive learning as valuable tools for advancing fitness\nactivity recognition, with bio-impedance playing a pivotal role in augmenting\nthe capabilities of IMU-based systems.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted by percom2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09445v2",
    "published_date": "2024-01-31 16:53:50 UTC",
    "updated_date": "2024-06-03 12:42:50 UTC"
  },
  {
    "arxiv_id": "2401.17985v2",
    "title": "Individual mapping of large polymorphic shrubs in high mountains using satellite images and deep learning",
    "authors": [
      "Rohaifa Khaldi",
      "Siham Tabik",
      "Sergio Puertas-Ruiz",
      "Julio Peñas de Giles",
      "José Antonio Hódar Correa",
      "Regino Zamora",
      "Domingo Alcaraz Segura"
    ],
    "abstract": "Monitoring the distribution and size of long-living large shrubs, such as\njunipers, is crucial for assessing the long-term impacts of global change on\nhigh-mountain ecosystems. While deep learning models have shown remarkable\nsuccess in object segmentation, adapting these models to detect shrub species\nwith polymorphic nature remains challenging. In this research, we release a\nlarge dataset of individual shrub delineations on freely available satellite\nimagery and use an instance segmentation model to map all junipers over the\ntreeline for an entire biosphere reserve (Sierra Nevada, Spain). To optimize\nperformance, we introduced a novel dual data construction approach: using\nphoto-interpreted (PI) data for model development and fieldwork (FW) data for\nvalidation. To account for the polymorphic nature of junipers during model\nevaluation, we developed a soft version of the Intersection over Union metric.\nFinally, we assessed the uncertainty of the resulting map in terms of canopy\ncover and density of shrubs per size class. Our model achieved an F1-score in\nshrub delineation of 87.87% on the PI data and 76.86% on the FW data. The R2\nand RMSE of the observed versus predicted relationship were 0.63 and 6.67% for\ncanopy cover, and 0.90 and 20.62 for shrub density. The greater density of\nlarger shrubs in lower altitudes and smaller shrubs in higher altitudes\nobserved in the model outputs was also present in the PI and FW data,\nsuggesting an altitudinal uplift in the optimal performance of the species.\nThis study demonstrates that deep learning applied on freely available\nhigh-resolution satellite imagery is useful to detect medium to large shrubs of\nhigh ecological value at the regional scale, which could be expanded to other\nhigh-mountains worldwide and to historical and forthcoming imagery.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17985v2",
    "published_date": "2024-01-31 16:44:20 UTC",
    "updated_date": "2024-10-01 08:25:14 UTC"
  },
  {
    "arxiv_id": "2401.17981v3",
    "title": "From Training-Free to Adaptive: Empirical Insights into MLLMs' Understanding of Detection Information",
    "authors": [
      "Qirui Jiao",
      "Daoyuan Chen",
      "Yilun Huang",
      "Yaliang Li",
      "Ying Shen"
    ],
    "abstract": "Despite the impressive capabilities of Multimodal Large Language Models\n(MLLMs) in integrating text and image modalities, challenges remain in\naccurately interpreting detailed visual elements. Vision detection models excel\nat recognizing fine-grained image details, prompting researchers to use them to\nenhance MLLMs. One effective strategy is to infuse detection information in\ntext format, which has proven simple and effective. However, most studies\nutilize this method without training, leaving the potential of adaptive\ntraining largely unexplored. Adaptive training could significantly enhance\nMLLMs' comprehension of unique inputs while filtering out irrelevant\ninformation. This paper addresses the crucial question: How does training\nimpact MLLMs' understanding of infused textual detection information? We\nsystematically experiment with various representative models to evaluate the\neffects of training-free, retraining, and fine-tuning strategies. We also\nexamine the influence of training on MLLMs' original abilities and the\ninterchangeability of detection models. Our findings indicate that fine-tuning\na pre-trained MLLM to incorporate textual detection information delivers\nsuperior results compared to training-free and retraining methods, improving\nperformance by 6.71% across 10 widely recognized benchmarks. Furthermore,\nfine-tuning enables MLLMs to retain performance enhancements even when\ndetection models are swapped, indicating improved understanding of formatted\ntextual data. We release our codes to support further exploration of fusion\nstrategies for vision detection models and the enhancement of MLLMs'\nfine-grained multimodal capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "32 pages, 22 tables, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17981v3",
    "published_date": "2024-01-31 16:38:32 UTC",
    "updated_date": "2024-12-19 11:25:34 UTC"
  },
  {
    "arxiv_id": "2401.17976v2",
    "title": "Circuit Partitioning for Multi-Core Quantum Architectures with Deep Reinforcement Learning",
    "authors": [
      "Arnau Pastor",
      "Pau Escofet",
      "Sahar Ben Rached",
      "Eduard Alarcón",
      "Pere Barlet-Ros",
      "Sergi Abadal"
    ],
    "abstract": "Quantum computing holds immense potential for solving classically intractable\nproblems by leveraging the unique properties of quantum mechanics. The\nscalability of quantum architectures remains a significant challenge.\nMulti-core quantum architectures are proposed to solve the scalability problem,\narising a new set of challenges in hardware, communications and compilation,\namong others. One of these challenges is to adapt a quantum algorithm to fit\nwithin the different cores of the quantum computer. This paper presents a novel\napproach for circuit partitioning using Deep Reinforcement Learning,\ncontributing to the advancement of both quantum computing and graph\npartitioning. This work is the first step in integrating Deep Reinforcement\nLearning techniques into Quantum Circuit Mapping, opening the door to a new\nparadigm of solutions to such problems.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17976v2",
    "published_date": "2024-01-31 16:33:12 UTC",
    "updated_date": "2024-07-24 06:39:57 UTC"
  },
  {
    "arxiv_id": "2401.17975v1",
    "title": "Understanding polysemanticity in neural networks through coding theory",
    "authors": [
      "Simon C. Marshall",
      "Jan H. Kirchner"
    ],
    "abstract": "Despite substantial efforts, neural network interpretability remains an\nelusive goal, with previous research failing to provide succinct explanations\nof most single neurons' impact on the network output. This limitation is due to\nthe polysemantic nature of most neurons, whereby a given neuron is involved in\nmultiple unrelated network states, complicating the interpretation of that\nneuron. In this paper, we apply tools developed in neuroscience and information\ntheory to propose both a novel practical approach to network interpretability\nand theoretical insights into polysemanticity and the density of codes. We\ninfer levels of redundancy in the network's code by inspecting the\neigenspectrum of the activation's covariance matrix. Furthermore, we show how\nrandom projections can reveal whether a network exhibits a smooth or\nnon-differentiable code and hence how interpretable the code is. This same\nframework explains the advantages of polysemantic neurons to learning\nperformance and explains trends found in recent results by Elhage et\nal.~(2022). Our approach advances the pursuit of interpretability in neural\nnetworks, providing insights into their underlying structure and suggesting new\navenues for circuit-level interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17975v1",
    "published_date": "2024-01-31 16:31:54 UTC",
    "updated_date": "2024-01-31 16:31:54 UTC"
  },
  {
    "arxiv_id": "2401.17972v1",
    "title": "MelNet: A Real-Time Deep Learning Algorithm for Object Detection",
    "authors": [
      "Yashar Azadvatan",
      "Murat Kurt"
    ],
    "abstract": "In this study, a novel deep learning algorithm for object detection, named\nMelNet, was introduced. MelNet underwent training utilizing the KITTI dataset\nfor object detection. Following 300 training epochs, MelNet attained an mAP\n(mean average precision) score of 0.732. Additionally, three alternative models\n-YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTI\ndataset and juxtaposed with MelNet for object detection.\n  The outcomes underscore the efficacy of employing transfer learning in\ncertain instances. Notably, preexisting models trained on prominent datasets\n(e.g., ImageNet, COCO, and Pascal VOC) yield superior results. Another finding\nunderscores the viability of creating a new model tailored to a specific\nscenario and training it on a specific dataset. This investigation demonstrates\nthat training MelNet exclusively on the KITTI dataset also surpasses\nEfficientDet after 150 epochs. Consequently, post-training, MelNet's\nperformance closely aligns with that of other pre-trained models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 9 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17972v1",
    "published_date": "2024-01-31 16:27:47 UTC",
    "updated_date": "2024-01-31 16:27:47 UTC"
  },
  {
    "arxiv_id": "2402.09444v3",
    "title": "Multimodal Action Quality Assessment",
    "authors": [
      "Ling-An Zeng",
      "Wei-Shi Zheng"
    ],
    "abstract": "Action quality assessment (AQA) is to assess how well an action is performed.\nPrevious works perform modelling by only the use of visual information,\nignoring audio information. We argue that although AQA is highly dependent on\nvisual information, the audio is useful complementary information for improving\nthe score regression accuracy, especially for sports with background music,\nsuch as figure skating and rhythmic gymnastics. To leverage multimodal\ninformation for AQA, i.e., RGB, optical flow and audio information, we propose\na Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models\nmodality-specific information and mixed-modality information. Our model\nconsists of with three modality-specific branches that independently explore\nmodality-specific information and a mixed-modality branch that progressively\naggregates the modality-specific information from the modality-specific\nbranches. To build the bridge between modality-specific branches and the\nmixed-modality branch, three novel modules are proposed. First, a\nModality-specific Feature Decoder module is designed to selectively transfer\nmodality-specific information to the mixed-modality branch. Second, when\nexploring the interaction between modality-specific information, we argue that\nusing an invariant multimodal fusion policy may lead to suboptimal results, so\nas to take the potential diversity in different parts of an action into\nconsideration. Therefore, an Adaptive Fusion Module is proposed to learn\nadaptive multimodal fusion policies in different parts of an action. This\nmodule consists of several FusionNets for exploring different multimodal fusion\nstrategies and a PolicyNet for deciding which FusionNets are enabled. Third, a\nmodule called Cross-modal Feature Decoder is designed to transfer cross-modal\nfeatures generated by Adaptive Fusion Module to the mixed-modality branch.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "I.2.10"
    ],
    "primary_category": "eess.SP",
    "comment": "IEEE Transactions on Image Processing 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.09444v3",
    "published_date": "2024-01-31 15:37:12 UTC",
    "updated_date": "2025-03-05 14:02:10 UTC"
  },
  {
    "arxiv_id": "2401.17914v1",
    "title": "Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning",
    "authors": [
      "Erwan Escudie",
      "Laetitia Matignon",
      "Jacques Saraydaryan"
    ],
    "abstract": "Learning robot navigation strategies among pedestrian is crucial for domain\nbased applications. Combining perception, planning and prediction allows us to\nmodel the interactions between robots and pedestrians, resulting in impressive\noutcomes especially with recent approaches based on deep reinforcement learning\n(RL). However, these works do not consider multi-robot scenarios. In this\npaper, we present MultiSoc, a new method for learning multi-agent socially\naware navigation strategies using RL. Inspired by recent works on multi-agent\ndeep RL, our method leverages graph-based representation of agent interactions,\ncombining the positions and fields of view of entities (pedestrians and\nagents). Each agent uses a model based on two Graph Neural Network combined\nwith attention mechanisms. First an edge-selector produces a sparse graph, then\na crowd coordinator applies node attention to produce a graph representing the\ninfluence of each entity on the others. This is incorporated into a model-free\nRL framework to learn multi-agent policies. We evaluate our approach on\nsimulation and provide a series of experiments in a set of various conditions\n(number of agents / pedestrians). Empirical results show that our method learns\nfaster than social navigation deep RL mono-agent techniques, and enables\nefficient multi-agent implicit coordination in challenging crowd navigation\nwith multiple heterogeneous humans. Furthermore, by incorporating customizable\nmeta-parameters, we can adjust the neighborhood density to take into account in\nour navigation strategy.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17914v1",
    "published_date": "2024-01-31 15:24:13 UTC",
    "updated_date": "2024-01-31 15:24:13 UTC"
  },
  {
    "arxiv_id": "2401.17895v1",
    "title": "ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields",
    "authors": [
      "Edward Bartrum",
      "Thu Nguyen-Phuoc",
      "Chris Xie",
      "Zhengqin Li",
      "Numair Khan",
      "Armen Avetisyan",
      "Douglas Lanman",
      "Lei Xiao"
    ],
    "abstract": "We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D scene\nediting method that enables the replacement of specific objects within a scene.\nGiven multi-view images of a scene, a text prompt describing the object to\nreplace, and a text prompt describing the new object, our Erase-and-Replace\napproach can effectively swap objects in the scene with newly generated content\nwhile maintaining 3D consistency across multiple viewpoints. We demonstrate the\nversatility of ReplaceAnything3D by applying it to various realistic 3D scenes,\nshowcasing results of modified foreground objects that are well-integrated with\nthe rest of the scene without affecting its overall integrity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "For our project page, see https://replaceanything3d.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2401.17895v1",
    "published_date": "2024-01-31 15:02:26 UTC",
    "updated_date": "2024-01-31 15:02:26 UTC"
  },
  {
    "arxiv_id": "2402.01766v3",
    "title": "LLM Voting: Human Choices and AI Collective Decision Making",
    "authors": [
      "Joshua C. Yang",
      "Damian Dailisan",
      "Marcin Korecki",
      "Carina I. Hausladen",
      "Dirk Helbing"
    ],
    "abstract": "This paper investigates the voting behaviors of Large Language Models (LLMs),\nspecifically GPT-4 and LLaMA-2, their biases, and how they align with human\nvoting patterns. Our methodology involved using a dataset from a human voting\nexperiment to establish a baseline for human preferences and conducting a\ncorresponding experiment with LLM agents. We observed that the choice of voting\nmethods and the presentation order influenced LLM voting outcomes. We found\nthat varying the persona can reduce some of these biases and enhance alignment\nwith human choices. While the Chain-of-Thought approach did not improve\nprediction accuracy, it has potential for AI explainability in the voting\nprocess. We also identified a trade-off between preference diversity and\nalignment accuracy in LLMs, influenced by different temperature settings. Our\nfindings indicate that LLMs may lead to less diverse collective outcomes and\nbiased assumptions when used in voting scenarios, emphasizing the need for\ncautious integration of LLMs into democratic processes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "econ.GN",
      "q-fin.EC",
      "68T05, 91B14, 91C20",
      "I.2.7; J.4; K.4.1"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in AAAI Conference on AI, Ethics, and Society (AIES)",
    "pdf_url": "http://arxiv.org/pdf/2402.01766v3",
    "published_date": "2024-01-31 14:52:02 UTC",
    "updated_date": "2024-08-14 13:41:02 UTC"
  },
  {
    "arxiv_id": "2402.00094v1",
    "title": "Deep Neural Networks: A Formulation Via Non-Archimedean Analysis",
    "authors": [
      "W. A. Zúñiga-Galindo"
    ],
    "abstract": "We introduce a new class of deep neural networks (DNNs) with multilayered\ntree-like architectures. The architectures are codified using numbers from the\nring of integers of non-Archimdean local fields. These rings have a natural\nhierarchical organization as infinite rooted trees. Natural morphisms on these\nrings allow us to construct finite multilayered architectures. The new DNNs are\nrobust universal approximators of real-valued functions defined on the\nmentioned rings. We also show that the DNNs are robust universal approximators\nof real-valued square-integrable functions defined in the unit interval.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "Primary 68T07, 65D15, Secondary 41A30, 11S85"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00094v1",
    "published_date": "2024-01-31 14:49:44 UTC",
    "updated_date": "2024-01-31 14:49:44 UTC"
  },
  {
    "arxiv_id": "2401.17870v2",
    "title": "Efficient Subseasonal Weather Forecast using Teleconnection-informed Transformers",
    "authors": [
      "Shan Zhao",
      "Zhitong Xiong",
      "Xiao Xiang Zhu"
    ],
    "abstract": "Subseasonal forecasting, which is pivotal for agriculture, water resource\nmanagement, and early warning of disasters, faces challenges due to the chaotic\nnature of the atmosphere. Recent advances in machine learning (ML) have\nrevolutionized weather forecasting by achieving competitive predictive skills\nto numerical models. However, training such foundation models requires\nthousands of GPU days, which causes substantial carbon emissions and limits\ntheir broader applicability. Moreover, ML models tend to fool the pixel-wise\nerror scores by producing smoothed results which lack physical consistency and\nmeteorological meaning. To deal with the aforementioned problems, we propose a\nteleconnection-informed transformer. Our architecture leverages the pretrained\nPangu model to achieve good initial weights and integrates a\nteleconnection-informed temporal module to improve predictability in an\nextended temporal range. Remarkably, by adjusting 1.1% of the Pangu model's\nparameters, our method enhances predictability on four surface and five\nupper-level atmospheric variables at a two-week lead time. Furthermore, the\nteleconnection-filtered features improve the spatial granularity of outputs\nsignificantly, indicating their potential physical consistency. Our research\nunderscores the importance of atmospheric and oceanic teleconnections in\ndriving future weather conditions. Besides, it presents a resource-efficient\npathway for researchers to leverage existing foundation models on versatile\ndownstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IGARSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17870v2",
    "published_date": "2024-01-31 14:27:35 UTC",
    "updated_date": "2024-02-05 12:43:24 UTC"
  },
  {
    "arxiv_id": "2401.17866v1",
    "title": "Making Sense of Knowledge Intensive Processes: an Oil & Gas Industry Scenario",
    "authors": [
      "Juliana Jansen Ferreira",
      "Vinícius Segura",
      "Ana Fucs",
      "Rogério de Paula"
    ],
    "abstract": "Sensemaking is a constant and ongoing process by which people associate\nmeaning to experiences. It can be an individual process, known as abduction, or\na group process by which people give meaning to collective experiences. The\nsensemaking of a group is influenced by the abduction process of each person\nabout the experience. Every collaborative process needs some level of\nsensemaking to show results. For a knowledge intensive process, sensemaking is\ncentral and related to most of its tasks. We present findings from a fieldwork\nexecuted in knowledge intensive process from the Oil and Gas industry. Our\nfindings indicated that different types of knowledge can be combined to compose\nthe result of a sensemaking process (e.g. decision, the need for more\ndiscussion, etc.). This paper presents an initial set of knowledge types that\ncan be combined to compose the result of the sensemaking of a collaborative\ndecision making process. We also discuss ideas for using systems powered by\nArtificial Intelligence to support sensemaking processes.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "9 pages. This paper was presented at the Sensemaking in a Senseless\n  World workshop during the 2018 ACM CHI Conference on Human Factors in\n  Computing Systems",
    "pdf_url": "http://arxiv.org/pdf/2401.17866v1",
    "published_date": "2024-01-31 14:25:05 UTC",
    "updated_date": "2024-01-31 14:25:05 UTC"
  },
  {
    "arxiv_id": "2401.17865v1",
    "title": "Manipulating Predictions over Discrete Inputs in Machine Teaching",
    "authors": [
      "Xiaodong Wu",
      "Yufei Han",
      "Hayssam Dahrouj",
      "Jianbing Ni",
      "Zhenwen Liang",
      "Xiangliang Zhang"
    ],
    "abstract": "Machine teaching often involves the creation of an optimal (typically\nminimal) dataset to help a model (referred to as the `student') achieve\nspecific goals given by a teacher. While abundant in the continuous domain, the\nstudies on the effectiveness of machine teaching in the discrete domain are\nrelatively limited. This paper focuses on machine teaching in the discrete\ndomain, specifically on manipulating student models' predictions based on the\ngoals of teachers via changing the training data efficiently. We formulate this\ntask as a combinatorial optimization problem and solve it by proposing an\niterative searching algorithm. Our algorithm demonstrates significant numerical\nmerit in the scenarios where a teacher attempts at correcting erroneous\npredictions to improve the student's models, or maliciously manipulating the\nmodel to misclassify some specific samples to the target class aligned with his\npersonal profits. Experimental results show that our proposed algorithm can\nhave superior performance in effectively and efficiently manipulating the\npredictions of the model, surpassing conventional baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17865v1",
    "published_date": "2024-01-31 14:23:51 UTC",
    "updated_date": "2024-01-31 14:23:51 UTC"
  },
  {
    "arxiv_id": "2402.03366v1",
    "title": "Uncertainty-Aware Explainable Recommendation with Large Language Models",
    "authors": [
      "Yicui Peng",
      "Hao Chen",
      "Chingsheng Lin",
      "Guo Huang",
      "Jinrong Hu",
      "Hui Guo",
      "Bin Kong",
      "Shu Hu",
      "Xi Wu",
      "Xin Wang"
    ],
    "abstract": "Providing explanations within the recommendation system would boost user\nsatisfaction and foster trust, especially by elaborating on the reasons for\nselecting recommended items tailored to the user. The predominant approach in\nthis domain revolves around generating text-based explanations, with a notable\nemphasis on applying large language models (LLMs). However, refining LLMs for\nexplainable recommendations proves impractical due to time constraints and\ncomputing resource limitations. As an alternative, the current approach\ninvolves training the prompt rather than the LLM. In this study, we developed a\nmodel that utilizes the ID vectors of user and item inputs as prompts for\nGPT-2. We employed a joint training mechanism within a multi-task learning\nframework to optimize both the recommendation task and explanation task. This\nstrategy enables a more effective exploration of users' interests, improving\nrecommendation effectiveness and user satisfaction. Through the experiments,\nour method achieving 1.59 DIV, 0.57 USR and 0.41 FCR on the Yelp, TripAdvisor\nand Amazon dataset respectively, demonstrates superior performance over four\nSOTA methods in terms of explainability evaluation metric. In addition, we\nidentified that the proposed model is able to ensure stable textual quality on\nthe three public datasets.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03366v1",
    "published_date": "2024-01-31 14:06:26 UTC",
    "updated_date": "2024-01-31 14:06:26 UTC"
  },
  {
    "arxiv_id": "2401.17842v2",
    "title": "Explainable Benchmarking for Iterative Optimization Heuristics",
    "authors": [
      "Niki van Stein",
      "Diederick Vermetten",
      "Anna V. Kononova",
      "Thomas Bäck"
    ],
    "abstract": "Benchmarking heuristic algorithms is vital to understand under which\nconditions and on what kind of problems certain algorithms perform well. In\nmost current research into heuristic optimization algorithms, only a very\nlimited number of scenarios, algorithm configurations and hyper-parameter\nsettings are explored, leading to incomplete and often biased insights and\nresults. This paper presents a novel approach we call explainable benchmarking.\nIntroducing the IOH-Xplainer software framework, for analyzing and\nunderstanding the performance of various optimization algorithms and the impact\nof their different components and hyper-parameters. We showcase the framework\nin the context of two modular optimization frameworks. Through this framework,\nwe examine the impact of different algorithmic components and configurations,\noffering insights into their performance across diverse scenarios. We provide a\nsystematic method for evaluating and interpreting the behaviour and efficiency\nof iterative optimization heuristics in a more transparent and comprehensible\nmanner, allowing for better benchmarking and algorithm design.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Submitted to ACM TELO",
    "pdf_url": "http://arxiv.org/pdf/2401.17842v2",
    "published_date": "2024-01-31 14:02:26 UTC",
    "updated_date": "2024-02-23 09:11:37 UTC"
  },
  {
    "arxiv_id": "2401.17839v1",
    "title": "Global-Liar: Factuality of LLMs over Time and Geographic Regions",
    "authors": [
      "Shujaat Mirza",
      "Bruno Coelho",
      "Yuyuan Cui",
      "Christina Pöpper",
      "Damon McCoy"
    ],
    "abstract": "The increasing reliance on AI-driven solutions, particularly Large Language\nModels (LLMs) like the GPT series, for information retrieval highlights the\ncritical need for their factuality and fairness, especially amidst the rampant\nspread of misinformation and disinformation online. Our study evaluates the\nfactual accuracy, stability, and biases in widely adopted GPT models, including\nGPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated\ninformation dissemination.\n  We introduce 'Global-Liar,' a dataset uniquely balanced in terms of\ngeographic and temporal representation, facilitating a more nuanced evaluation\nof LLM biases. Our analysis reveals that newer iterations of GPT models do not\nalways equate to improved performance. Notably, the GPT-4 version from March\ndemonstrates higher factual accuracy than its subsequent June release.\nFurthermore, a concerning bias is observed, privileging statements from the\nGlobal North over the Global South, thus potentially exacerbating existing\ninformational inequities. Regions such as Africa and the Middle East are at a\ndisadvantage, with much lower factual accuracy. The performance fluctuations\nover time suggest that model updates may not consistently benefit all regions\nequally.\n  Our study also offers insights into the impact of various LLM configuration\nsettings, such as binary decision forcing, model re-runs and temperature, on\nmodel's factuality. Models constrained to binary (true/false) choices exhibit\nreduced factuality compared to those allowing an 'unclear' option. Single\ninference at a low temperature setting matches the reliability of majority\nvoting across various configurations. The insights gained highlight the need\nfor culturally diverse and geographically inclusive model training and\nevaluation. This approach is key to achieving global equity in technology,\ndistributing AI benefits fairly worldwide.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 12 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17839v1",
    "published_date": "2024-01-31 13:57:24 UTC",
    "updated_date": "2024-01-31 13:57:24 UTC"
  },
  {
    "arxiv_id": "2401.17838v1",
    "title": "A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction",
    "authors": [
      "Wenshuo Chao",
      "Zhaopeng Qiu",
      "Likang Wu",
      "Zhuoning Guo",
      "Zhi Zheng",
      "Hengshu Zhu",
      "Hao Liu"
    ],
    "abstract": "The rapidly changing landscape of technology and industries leads to dynamic\nskill requirements, making it crucial for employees and employers to anticipate\nsuch shifts to maintain a competitive edge in the labor market. Existing\nefforts in this area either rely on domain-expert knowledge or regarding skill\nevolution as a simplified time series forecasting problem. However, both\napproaches overlook the sophisticated relationships among different skills and\nthe inner-connection between skill demand and supply variations. In this paper,\nwe propose a Cross-view Hierarchical Graph learning Hypernetwork (CHGH)\nframework for joint skill demand-supply prediction. Specifically, CHGH is an\nencoder-decoder network consisting of i) a cross-view graph encoder to capture\nthe interconnection between skill demand and supply, ii) a hierarchical graph\nencoder to model the co-evolution of skills from a cluster-wise perspective,\nand iii) a conditional hyper-decoder to jointly predict demand and supply\nvariations by incorporating historical demand-supply gaps. Extensive\nexperiments on three real-world datasets demonstrate the superiority of the\nproposed framework compared to seven baselines and the effectiveness of the\nthree modules.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, AAAI24",
    "pdf_url": "http://arxiv.org/pdf/2401.17838v1",
    "published_date": "2024-01-31 13:56:08 UTC",
    "updated_date": "2024-01-31 13:56:08 UTC"
  },
  {
    "arxiv_id": "2402.01765v1",
    "title": "LLMs Simulate Big Five Personality Traits: Further Evidence",
    "authors": [
      "Aleksandra Sorokovikova",
      "Natalia Fedorova",
      "Sharwin Rezagholi",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "An empirical investigation into the simulation of the Big Five personality\ntraits by large language models (LLMs), namely Llama2, GPT4, and Mixtral, is\npresented. We analyze the personality traits simulated by these models and\ntheir stability. This contributes to the broader understanding of the\ncapabilities of LLMs to simulate personality traits and the respective\nimplications for personalized human-computer interaction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; J.4; I.2.1"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01765v1",
    "published_date": "2024-01-31 13:45:25 UTC",
    "updated_date": "2024-01-31 13:45:25 UTC"
  },
  {
    "arxiv_id": "2401.17828v2",
    "title": "Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation",
    "authors": [
      "Rozhan Ahmadi",
      "Shohreh Kasaei"
    ],
    "abstract": "In recent years, weakly supervised semantic segmentation using image-level\nlabels as supervision has received significant attention in the field of\ncomputer vision. Most existing methods have addressed the challenges arising\nfrom the lack of spatial information in these labels by focusing on\nfacilitating supervised learning through the generation of pseudo-labels from\nclass activation maps (CAMs). Due to the localized pattern detection of CNNs,\nCAMs often emphasize only the most discriminative parts of an object, making it\nchallenging to accurately distinguish foreground objects from each other and\nthe background. Recent studies have shown that Vision Transformer (ViT)\nfeatures, due to their global view, are more effective in capturing the scene\nlayout than CNNs. However, the use of hierarchical ViTs has not been\nextensively explored in this field. This work explores the use of Swin\nTransformer by proposing \"SWTformer\" to enhance the accuracy of the initial\nseed CAMs by bringing local and global views together. SWTformer-V1 generates\nclass probabilities and CAMs using only the patch tokens as features.\nSWTformer-V2 incorporates a multi-scale feature fusion mechanism to extract\nadditional information and utilizes a background-aware mechanism to generate\nmore accurate localization maps with improved cross-object discrimination.\nBased on experiments on the PascalVOC 2012 dataset, SWTformer-V1 achieves a\n0.98% mAP higher localization accuracy, outperforming state-of-the-art models.\nIt also yields comparable performance by 0.82% mIoU on average higher than\nother methods in generating initial localization maps, depending only on the\nclassification network. SWTformer-V2 further improves the accuracy of the\ngenerated seed CAMs by 5.32% mIoU, further proving the effectiveness of the\nlocal-to-global view provided by the Swin transformer. Code available at:\nhttps://github.com/RozhanAhmadi/SWTformer",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17828v2",
    "published_date": "2024-01-31 13:41:17 UTC",
    "updated_date": "2024-03-11 04:59:43 UTC"
  },
  {
    "arxiv_id": "2401.17827v1",
    "title": "Neural Machine Translation for Malayalam Paraphrase Generation",
    "authors": [
      "Christeena Varghese",
      "Sergey Koshelev",
      "Ivan P. Yamshchikov"
    ],
    "abstract": "This study explores four methods of generating paraphrases in Malayalam,\nutilizing resources available for English paraphrasing and pre-trained Neural\nMachine Translation (NMT) models. We evaluate the resulting paraphrases using\nboth automated metrics, such as BLEU, METEOR, and cosine similarity, as well as\nhuman annotation. Our findings suggest that automated evaluation measures may\nnot be fully appropriate for Malayalam, as they do not consistently align with\nhuman judgment. This discrepancy underscores the need for more nuanced\nparaphrase evaluation approaches especially for highly agglutinative languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.7.0; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17827v1",
    "published_date": "2024-01-31 13:40:00 UTC",
    "updated_date": "2024-01-31 13:40:00 UTC"
  },
  {
    "arxiv_id": "2402.00896v1",
    "title": "Privacy and Security Implications of Cloud-Based AI Services : A Survey",
    "authors": [
      "Alka Luqman",
      "Riya Mahesh",
      "Anupam Chattopadhyay"
    ],
    "abstract": "This paper details the privacy and security landscape in today's cloud\necosystem and identifies that there is a gap in addressing the risks introduced\nby machine learning models. As machine learning algorithms continue to evolve\nand find applications across diverse domains, the need to categorize and\nquantify privacy and security risks becomes increasingly critical. With the\nemerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML\nmodels) are deployed on the cloud by model providers and used by model\nconsumers. We first survey the AIaaS landscape to document the various kinds of\nliabilities that ML models, especially Deep Neural Networks pose and then\nintroduce a taxonomy to bridge this gap by holistically examining the risks\nthat creators and consumers of ML models are exposed to and their known\ndefences till date. Such a structured approach will be beneficial for ML model\nproviders to create robust solutions. Likewise, ML model consumers will find it\nvaluable to evaluate such solutions and understand the implications of their\nengagement with such services. The proposed taxonomies provide a foundational\nbasis for solutions in private, secure and robust ML, paving the way for more\ntransparent and resilient AI systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00896v1",
    "published_date": "2024-01-31 13:30:20 UTC",
    "updated_date": "2024-01-31 13:30:20 UTC"
  },
  {
    "arxiv_id": "2401.17812v1",
    "title": "Deterministic Computing Power Networking: Architecture, Technologies and Prospects",
    "authors": [
      "Qingmin Jia",
      "Yujiao Hu",
      "Xiaomao Zhou",
      "Qianpiao Ma",
      "Kai Guo",
      "Huayu Zhang",
      "Renchao Xie",
      "Tao Huang",
      "Yunjie Liu"
    ],
    "abstract": "With the development of new Internet services such as computation-intensive\nand delay-sensitive tasks, the traditional \"Best Effort\" network transmission\nmode has been greatly challenged. The network system is urgently required to\nprovide end-to-end transmission determinacy and computing determinacy for new\napplications to ensure the safe and efficient operation of services. Based on\nthe research of the convergence of computing and networking, a new network\nparadigm named deterministic computing power networking (Det-CPN) is proposed.\nIn this article, we firstly introduce the research advance of computing power\nnetworking. And then the motivations and scenarios of Det-CPN are analyzed.\nFollowing that, we present the system architecture, technological capabilities,\nworkflow as well as key technologies for Det-CPN. Finally, the challenges and\nfuture trends of Det-CPN are analyzed and discussed.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17812v1",
    "published_date": "2024-01-31 13:12:42 UTC",
    "updated_date": "2024-01-31 13:12:42 UTC"
  },
  {
    "arxiv_id": "2401.17809v4",
    "title": "SWEA: Updating Factual Knowledge in Large Language Models via Subject Word Embedding Altering",
    "authors": [
      "Xiaopeng Li",
      "Shasha Li",
      "Shezheng Song",
      "Huijun Liu",
      "Bin Ji",
      "Xi Wang",
      "Jun Ma",
      "Jie Yu",
      "Xiaodong Liu",
      "Jing Wang",
      "Weimin Zhang"
    ],
    "abstract": "The general capabilities of large language models (LLMs) make them the\ninfrastructure for various AI applications, but updating their inner knowledge\nrequires significant resources. Recent model editing is a promising technique\nfor efficiently updating a small amount of knowledge of LLMs and has attracted\nmuch attention. In particular, local editing methods, which directly update\nmodel parameters, are proven suitable for updating small amounts of knowledge.\nLocal editing methods update weights by computing least squares closed-form\nsolutions and identify edited knowledge by vector-level matching in inference,\nwhich achieve promising results. However, these methods still require a lot of\ntime and resources to complete the computation. Moreover, vector-level matching\nlacks reliability, and such updates disrupt the original organization of the\nmodel's parameters. To address these issues, we propose a detachable and\nexpandable Subject Word Embedding Altering (SWEA) framework, which finds the\nediting embeddings through token-level matching and adds them to the subject\nword embeddings in Transformer input. To get these editing embeddings, we\npropose optimizing then suppressing fusion method, which first optimizes\nlearnable embedding vectors for the editing target and then suppresses the\nKnowledge Embedding Dimensions (KEDs) to obtain final editing embeddings. We\nthus propose SWEA$\\oplus$OS method for editing factual knowledge in LLMs. We\ndemonstrate the overall state-of-the-art (SOTA) performance of SWEA$\\oplus$OS\non the CounterFact and zsRE datasets. To further validate the reasoning ability\nof SWEA$\\oplus$OS in editing knowledge, we evaluate it on the more complex\nRippleEdits benchmark. The results demonstrate that SWEA$\\oplus$OS possesses\nSOTA reasoning ability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI25. Our code is available at https://github.com/xpq-tech/SWEA",
    "pdf_url": "http://arxiv.org/pdf/2401.17809v4",
    "published_date": "2024-01-31 13:08:45 UTC",
    "updated_date": "2025-02-17 01:18:37 UTC"
  },
  {
    "arxiv_id": "2401.17805v1",
    "title": "Biospheric AI",
    "authors": [
      "Marcin Korecki"
    ],
    "abstract": "The dominant paradigm in AI ethics and value alignment is highly\nanthropocentric. The focus of these disciplines is strictly on human values\nwhich limits the depth and breadth of their insights. Recently, attempts to\nexpand to a sentientist perspective have been initiated. We argue that neither\nof these outlooks is sufficient to capture the actual complexity of the\nbiosphere and ensure that AI does not damage it. Thus, we propose a new\nparadigm -- Biospheric AI that assumes an ecocentric perspective. We discuss\nhypothetical ways in which such an AI might be designed. Moreover, we give\ndirections for research and application of the modern AI models that would be\nconsistent with the biospheric interests. All in all, this work attempts to\ntake first steps towards a comprehensive program of research that focuses on\nthe interactions between AI and the biosphere.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17805v1",
    "published_date": "2024-01-31 13:04:34 UTC",
    "updated_date": "2024-01-31 13:04:34 UTC"
  },
  {
    "arxiv_id": "2401.17802v2",
    "title": "Distillation Enhanced Time Series Forecasting Network with Momentum Contrastive Learning",
    "authors": [
      "Haozhi Gao",
      "Qianqian Ren",
      "Jinbao Li"
    ],
    "abstract": "Contrastive representation learning is crucial in time series analysis as it\nalleviates the issue of data noise and incompleteness as well as sparsity of\nsupervision signal. However, existing constrastive learning frameworks usually\nfocus on intral-temporal features, which fails to fully exploit the intricate\nnature of time series data. To address this issue, we propose DE-TSMCL, an\ninnovative distillation enhanced framework for long sequence time series\nforecasting. Specifically, we design a learnable data augmentation mechanism\nwhich adaptively learns whether to mask a timestamp to obtain optimized\nsub-sequences. Then, we propose a contrastive learning task with momentum\nupdate to explore inter-sample and intra-temporal correlations of time series\nto learn the underlying structure feature on the unlabeled time series.\nMeanwhile, we design a supervised task to learn more robust representations and\nfacilitate the contrastive learning process. Finally, we jointly optimize the\nabove two tasks. By developing model loss from multiple tasks, we can learn\neffective representations for downstream forecasting task. Extensive\nexperiments, in comparison with state-of-the-arts, well demonstrate the\neffectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17802v2",
    "published_date": "2024-01-31 12:52:10 UTC",
    "updated_date": "2024-06-25 04:34:38 UTC"
  },
  {
    "arxiv_id": "2401.17791v3",
    "title": "Graph Transformers without Positional Encodings",
    "authors": [
      "Ayush Garg"
    ],
    "abstract": "Recently, Transformers for graph representation learning have become\nincreasingly popular, achieving state-of-the-art performance on a wide-variety\nof graph datasets, either alone or in combination with message-passing graph\nneural networks (MP-GNNs). Infusing graph inductive-biases in the innately\nstructure-agnostic transformer architecture in the form of structural or\npositional encodings (PEs) is key to achieving these impressive results.\nHowever, designing such encodings is tricky and disparate attempts have been\nmade to engineer such encodings including Laplacian eigenvectors, relative\nrandom-walk probabilities (RRWP), spatial encodings, centrality encodings, edge\nencodings etc. In this work, we argue that such encodings may not be required\nat all, provided the attention mechanism itself incorporates information about\nthe graph structure. We introduce Eigenformer, a Graph Transformer employing a\nnovel spectrum-aware attention mechanism cognizant of the Laplacian spectrum of\nthe graph, and empirically show that it achieves performance competetive with\nSOTA Graph Transformers on a number of standard GNN benchmarks. Additionally,\nwe theoretically prove that Eigenformer can express various graph structural\nconnectivity matrices, which is particularly essential when learning over\nsmaller graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Independent Research",
    "pdf_url": "http://arxiv.org/pdf/2401.17791v3",
    "published_date": "2024-01-31 12:33:31 UTC",
    "updated_date": "2024-05-06 13:12:05 UTC"
  },
  {
    "arxiv_id": "2401.17783v1",
    "title": "SDRDPy: An application to graphically visualize the knowledge obtained with supervised descriptive rule algorithms",
    "authors": [
      "M. A. Padilla-Rascon",
      "P. Gonzalez",
      "C. J. Carmona"
    ],
    "abstract": "SDRDPy is a desktop application that allows experts an intuitive graphic and\ntabular representation of the knowledge extracted by any supervised descriptive\nrule discovery algorithm. The application is able to provide an analysis of the\ndata showing the relevant information of the data set and the relationship\nbetween the rules, data and the quality measures associated for each rule\nregardless of the tool where algorithm has been executed. All of the\ninformation is presented in a user-friendly application in order to facilitate\nexpert analysis and also the exportation of reports in different formats.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17783v1",
    "published_date": "2024-01-31 12:26:59 UTC",
    "updated_date": "2024-01-31 12:26:59 UTC"
  },
  {
    "arxiv_id": "2401.17776v1",
    "title": "Double InfoGAN for Contrastive Analysis",
    "authors": [
      "Florence Carton",
      "Robin Louiset",
      "Pietro Gori"
    ],
    "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and what\nis distinctive of a target domain compared to a background one. This is of\ngreat interest in many applications, such as medical imaging. Current\nstate-of-the-art (SOTA) methods are latent variable models based on VAE\n(CA-VAEs). However, they all either ignore important constraints or they don't\nenforce fundamental assumptions. This may lead to sub-optimal solutions where\ndistinctive factors are mistaken for common ones (or viceversa). Furthermore,\nthe generated images have a rather poor quality, typical of VAEs, decreasing\ntheir interpretability and usefulness. Here, we propose Double InfoGAN, the\nfirst GAN based method for CA that leverages the high-quality synthesis of GAN\nand the separation power of InfoGAN. Experimental results on four visual\ndatasets, from simple synthetic examples to complex medical images, show that\nthe proposed method outperforms SOTA CA-VAEs in terms of latent separation and\nimage quality. Datasets and code are available online.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17776v1",
    "published_date": "2024-01-31 12:16:39 UTC",
    "updated_date": "2024-01-31 12:16:39 UTC"
  },
  {
    "arxiv_id": "2401.17752v1",
    "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
    "authors": [
      "Mohammed Haroon Dupty",
      "Yanfei Dong",
      "Wee Sun Lee"
    ],
    "abstract": "Message passing Graph Neural Networks (GNNs) are known to be limited in\nexpressive power by the 1-WL color-refinement test for graph isomorphism. Other\nmore expressive models either are computationally expensive or need\npreprocessing to extract structural features from the graph. In this work, we\npropose to make GNNs universal by guiding the learning process with exact\nisomorphism solver techniques which operate on the paradigm of\nIndividualization and Refinement (IR), a method to artificially introduce\nasymmetry and further refine the coloring when 1-WL stops. Isomorphism solvers\ngenerate a search tree of colorings whose leaves uniquely identify the graph.\nHowever, the tree grows exponentially large and needs hand-crafted pruning\ntechniques which are not desirable from a learning perspective. We take a\nprobabilistic view and approximate the search tree of colorings (i.e.\nembeddings) by sampling multiple paths from root to leaves of the search tree.\nTo learn more discriminative representations, we guide the sampling process\nwith particle filter updates, a principled approach for sequential state\nestimation. Our algorithm is end-to-end differentiable, can be applied with any\nGNN as backbone and learns richer graph representations with only linear\nincrease in runtime. Experimental evaluation shows that our approach\nconsistently outperforms leading GNN models on both synthetic benchmarks for\nisomorphism detection as well as real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2022",
    "pdf_url": "http://arxiv.org/pdf/2401.17752v1",
    "published_date": "2024-01-31 11:26:03 UTC",
    "updated_date": "2024-01-31 11:26:03 UTC"
  },
  {
    "arxiv_id": "2401.17749v1",
    "title": "SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models",
    "authors": [
      "Xiao Shao",
      "Weifu Jiang",
      "Fei Zuo",
      "Mengqing Liu"
    ],
    "abstract": "Large language models (LLMs) have recently garnered significant\naccomplishments in various exploratory tasks, even surpassing the performance\nof traditional reinforcement learning-based methods that have historically\ndominated the agent-based field. The purpose of this paper is to investigate\nthe efficacy of LLMs in executing real-time strategy war tasks within the\nStarCraft II gaming environment. In this paper, we introduce SwarmBrain, an\nembodied agent leveraging LLM for real-time strategy implementation in the\nStarCraft II game environment. The SwarmBrain comprises two key components: 1)\na Overmind Intelligence Matrix, powered by state-of-the-art LLMs, is designed\nto orchestrate macro-level strategies from a high-level perspective. This\nmatrix emulates the overarching consciousness of the Zerg intelligence brain,\nsynthesizing strategic foresight with the aim of allocating resources,\ndirecting expansion, and coordinating multi-pronged assaults. 2) a Swarm\nReflexNet, which is agile counterpart to the calculated deliberation of the\nOvermind Intelligence Matrix. Due to the inherent latency in LLM reasoning, the\nSwarm ReflexNet employs a condition-response state machine framework, enabling\nexpedited tactical responses for fundamental Zerg unit maneuvers. In the\nexperimental setup, SwarmBrain is in control of the Zerg race in confrontation\nwith an Computer-controlled Terran adversary. Experimental results show the\ncapacity of SwarmBrain to conduct economic augmentation, territorial expansion,\nand tactical formulation, and it shows the SwarmBrain is capable of achieving\nvictory against Computer players set at different difficulty levels.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17749v1",
    "published_date": "2024-01-31 11:14:29 UTC",
    "updated_date": "2024-01-31 11:14:29 UTC"
  },
  {
    "arxiv_id": "2401.17741v1",
    "title": "Haris: an Advanced Autonomous Mobile Robot for Smart Parking Assistance",
    "authors": [
      "Layth Hamad",
      "Muhammad Asif Khan",
      "Hamid Menouar",
      "Fethi Filali",
      "Amr Mohamed"
    ],
    "abstract": "This paper presents Haris, an advanced autonomous mobile robot system for\ntracking the location of vehicles in crowded car parks using license plate\nrecognition. The system employs simultaneous localization and mapping (SLAM)\nfor autonomous navigation and precise mapping of the parking area, eliminating\nthe need for GPS dependency. In addition, the system utilizes a sophisticated\nframework using computer vision techniques for object detection and automatic\nlicense plate recognition (ALPR) for reading and associating license plate\nnumbers with location data. This information is subsequently synchronized with\na back-end service and made accessible to users via a user-friendly mobile app,\noffering effortless vehicle location and alleviating congestion within the\nparking facility. The proposed system has the potential to improve the\nmanagement of short-term large outdoor parking areas in crowded places such as\nsports stadiums. The demo of the robot can be found on\nhttps://youtu.be/ZkTCM35fxa0?si=QjggJuN7M1o3oifx.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in 2024 IEEE International Conference on Consumer\n  Electronics (ICCE), Las Vegas, NV, USA, 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17741v1",
    "published_date": "2024-01-31 11:00:26 UTC",
    "updated_date": "2024-01-31 11:00:26 UTC"
  },
  {
    "arxiv_id": "2401.17739v2",
    "title": "Operator learning without the adjoint",
    "authors": [
      "Nicolas Boullé",
      "Diana Halikias",
      "Samuel E. Otto",
      "Alex Townsend"
    ],
    "abstract": "There is a mystery at the heart of operator learning: how can one recover a\nnon-self-adjoint operator from data without probing the adjoint? Current\npractical approaches suggest that one can accurately recover an operator while\nonly using data generated by the forward action of the operator without access\nto the adjoint. However, naively, it seems essential to sample the action of\nthe adjoint. In this paper, we partially explain this mystery by proving that\nwithout querying the adjoint, one can approximate a family of non-self-adjoint\ninfinite-dimensional compact operators via projection onto a Fourier basis. We\nthen apply the result to recovering Green's functions of elliptic partial\ndifferential operators and derive an adjoint-free sample complexity bound.\nWhile existing theory justifies low sample complexity in operator learning,\nours is the first adjoint-free analysis that attempts to close the gap between\ntheory and practice.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.LG",
      "cs.NA"
    ],
    "primary_category": "math.NA",
    "comment": "54 pages, 5 figures, to appear in Journal of Machine Learning\n  Research",
    "pdf_url": "http://arxiv.org/pdf/2401.17739v2",
    "published_date": "2024-01-31 10:59:57 UTC",
    "updated_date": "2024-11-20 10:38:29 UTC"
  },
  {
    "arxiv_id": "2401.17733v1",
    "title": "Towards Physical Plausibility in Neuroevolution Systems",
    "authors": [
      "Gabriel Cortês",
      "Nuno Lourenço",
      "Penousal Machado"
    ],
    "abstract": "The increasing usage of Artificial Intelligence (AI) models, especially Deep\nNeural Networks (DNNs), is increasing the power consumption during training and\ninference, posing environmental concerns and driving the need for more\nenergy-efficient algorithms and hardware solutions. This work addresses the\ngrowing energy consumption problem in Machine Learning (ML), particularly\nduring the inference phase. Even a slight reduction in power usage can lead to\nsignificant energy savings, benefiting users, companies, and the environment.\nOur approach focuses on maximizing the accuracy of Artificial Neural Network\n(ANN) models using a neuroevolutionary framework whilst minimizing their power\nconsumption. To do so, power consumption is considered in the fitness function.\nWe introduce a new mutation strategy that stochastically reintroduces modules\nof layers, with power-efficient modules having a higher chance of being chosen.\nWe introduce a novel technique that allows training two separate models in a\nsingle training step whilst promoting one of them to be more power efficient\nthan the other while maintaining similar accuracy. The results demonstrate a\nreduction in power consumption of ANN models by up to 29.2% without a\nsignificant decrease in predictive performance.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17733v1",
    "published_date": "2024-01-31 10:54:34 UTC",
    "updated_date": "2024-01-31 10:54:34 UTC"
  },
  {
    "arxiv_id": "2402.00092v1",
    "title": "Episodic-free Task Selection for Few-shot Learning",
    "authors": [
      "Tao Zhang"
    ],
    "abstract": "Episodic training is a mainstream training strategy for few-shot learning. In\nfew-shot scenarios, however, this strategy is often inferior to some\nnon-episodic training strategy, e. g., Neighbourhood Component Analysis (NCA),\nwhich challenges the principle that training conditions must match testing\nconditions. Thus, a question is naturally asked: How to search for\nepisodic-free tasks for better few-shot learning? In this work, we propose a\nnovel meta-training framework beyond episodic training. In this framework,\nepisodic tasks are not used directly for training, but for evaluating the\neffectiveness of some selected episodic-free tasks from a task set that are\nperformed for training the meta-learners. The selection criterion is designed\nwith the affinity, which measures the degree to which loss decreases when\nexecuting the target tasks after training with the selected tasks. In\nexperiments, the training task set contains some promising types, e. g.,\ncontrastive learning and classification, and the target few-shot tasks are\nachieved with the nearest centroid classifiers on the miniImageNet,\ntiered-ImageNet and CIFAR-FS datasets. The experimental results demonstrate the\neffectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00092v1",
    "published_date": "2024-01-31 10:52:15 UTC",
    "updated_date": "2024-01-31 10:52:15 UTC"
  },
  {
    "arxiv_id": "2402.00089v2",
    "title": "SCAPE: Searching Conceptual Architecture Prompts using Evolution",
    "authors": [
      "Soo Ling Lim",
      "Peter J Bentley",
      "Fuyuki Ishikawa"
    ],
    "abstract": "Conceptual architecture involves a highly creative exploration of novel\nideas, often taken from other disciplines as architects consider radical new\nforms, materials, textures and colors for buildings. While today's generative\nAI systems can produce remarkable results, they lack the creativity\ndemonstrated for decades by evolutionary algorithms. SCAPE, our proposed tool,\ncombines evolutionary search with generative AI, enabling users to explore\ncreative and good quality designs inspired by their initial input through a\nsimple point and click interface. SCAPE injects randomness into generative AI,\nand enables memory, making use of the built-in language skills of GPT-4 to vary\nprompts via text-based mutation and crossover. We demonstrate that compared to\nDALL-E 3, SCAPE enables a 67% improvement in image novelty, plus improvements\nin quality and effectiveness of use; we show that in just three iterations\nSCAPE has a 24% image novelty increase enabling effective exploration, plus\noptimization of images by users. We use more than 20 independent architects to\nassess SCAPE, who provide markedly positive feedback.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "68W50, 68T07",
      "G.1.6; I.2.10"
    ],
    "primary_category": "cs.NE",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.00089v2",
    "published_date": "2024-01-31 10:25:45 UTC",
    "updated_date": "2024-04-02 10:05:33 UTC"
  },
  {
    "arxiv_id": "2401.17711v1",
    "title": "Prediction of multitasking performance post-longitudinal tDCS via EEG-based functional connectivity and machine learning methods",
    "authors": [
      "Akash K Rao",
      "Shashank Uttrani",
      "Vishnu K Menon",
      "Darshil Shah",
      "Arnav Bhavsar",
      "Shubhajit Roy Chowdhury",
      "Varun Dutt"
    ],
    "abstract": "Predicting and understanding the changes in cognitive performance, especially\nafter a longitudinal intervention, is a fundamental goal in neuroscience.\nLongitudinal brain stimulation-based interventions like transcranial direct\ncurrent stimulation (tDCS) induce short-term changes in the resting membrane\npotential and influence cognitive processes. However, very little research has\nbeen conducted on predicting these changes in cognitive performance\npost-intervention. In this research, we intend to address this gap in the\nliterature by employing different EEG-based functional connectivity analyses\nand machine learning algorithms to predict changes in cognitive performance in\na complex multitasking task. Forty subjects were divided into experimental and\nactive-control conditions. On Day 1, all subjects executed a multitasking task\nwith simultaneous 32-channel EEG being acquired. From Day 2 to Day 7, subjects\nin the experimental condition undertook 15 minutes of 2mA anodal tDCS\nstimulation during task training. Subjects in the active-control condition\nundertook 15 minutes of sham stimulation during task training. On Day 10, all\nsubjects again executed the multitasking task with EEG acquisition.\nSource-level functional connectivity metrics, namely phase lag index and\ndirected transfer function, were extracted from the EEG data on Day 1 and Day\n10. Various machine learning models were employed to predict changes in\ncognitive performance. Results revealed that the multi-layer perceptron and\ndirected transfer function recorded a cross-validation training RMSE of 5.11%\nand a test RMSE of 4.97%. We discuss the implications of our results in\ndeveloping real-time cognitive state assessors for accurately predicting\ncognitive performance in dynamic and complex tasks post-tDCS intervention",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, presented at the 30th International Conference on Neural\n  Information Processing (ICONIP2023), Changsha, China, November 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.17711v1",
    "published_date": "2024-01-31 10:03:27 UTC",
    "updated_date": "2024-01-31 10:03:27 UTC"
  },
  {
    "arxiv_id": "2401.17710v1",
    "title": "Aesthetic Preference Prediction in Interior Design: Fuzzy Approach",
    "authors": [
      "Ayana Adilova",
      "Pakizar Shamoi"
    ],
    "abstract": "Interior design is all about creating spaces that look and feel good.\nHowever, the subjective nature of aesthetic preferences presents a significant\nchallenge in defining and quantifying what makes an interior design visually\nappealing. The current paper addresses this gap by introducing a novel\nmethodology for quantifying and predicting aesthetic preferences in interior\ndesign. Our study combines fuzzy logic with image processing techniques. We\ncollected a dataset of interior design images from social media platforms,\nfocusing on essential visual attributes such as color harmony, lightness, and\ncomplexity. We integrate these features using weighted average to compute a\ngeneral aesthetic score. Our approach considers individual color preferences in\ncalculating the overall aesthetic preference. We initially gather user ratings\nfor primary colors like red, brown, and others to understand their preferences.\nThen, we use the pixel count of the top five dominant colors in the image to\nget the color scheme preference. The color scheme preference and the aesthetic\nscore are then passed as inputs to the fuzzy inference system to calculate an\noverall preference score. This score represents a comprehensive measure of the\nuser's preference for a particular interior design, considering their color\nchoices and general aesthetic appeal. We used the 2AFC (Two-Alternative Forced\nChoice) method to validate our methodology, achieving a notable hit rate of\n0.7. This study can help designers and professionals better understand and meet\npeople's interior design preferences, especially in a world that relies heavily\non digital media.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE conference for consideration",
    "pdf_url": "http://arxiv.org/pdf/2401.17710v1",
    "published_date": "2024-01-31 09:59:59 UTC",
    "updated_date": "2024-01-31 09:59:59 UTC"
  },
  {
    "arxiv_id": "2401.17700v1",
    "title": "Classification of executive functioning performance post-longitudinal tDCS using functional connectivity and machine learning methods",
    "authors": [
      "Akash K Rao",
      "Vishnu K Menon",
      "Shashank Uttrani",
      "Ayushman Dixit",
      "Dipanshu Verma",
      "Varun Dutt"
    ],
    "abstract": "Executive functioning is a cognitive process that enables humans to plan,\norganize, and regulate their behavior in a goal-directed manner. Understanding\nand classifying the changes in executive functioning after longitudinal\ninterventions (like transcranial direct current stimulation (tDCS)) has not\nbeen explored in the literature. This study employs functional connectivity and\nmachine learning algorithms to classify executive functioning performance\npost-tDCS. Fifty subjects were divided into experimental and placebo control\ngroups. EEG data was collected while subjects performed an executive\nfunctioning task on Day 1. The experimental group received tDCS during task\ntraining from Day 2 to Day 8, while the control group received sham tDCS. On\nDay 10, subjects repeated the tasks specified on Day 1. Different functional\nconnectivity metrics were extracted from EEG data and eventually used for\nclassifying executive functioning performance using different machine learning\nalgorithms. Results revealed that a novel combination of partial directed\ncoherence and multi-layer perceptron (along with recursive feature elimination)\nresulted in a high classification accuracy of 95.44%. We discuss the\nimplications of our results in developing real-time neurofeedback systems for\nassessing and enhancing executive functioning performance post-tDCS\nadministration.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, presented at the IEEE 20th India Council International\n  Conference (INDICON 2023), Hyderabad, India, December 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.17700v1",
    "published_date": "2024-01-31 09:45:03 UTC",
    "updated_date": "2024-01-31 09:45:03 UTC"
  },
  {
    "arxiv_id": "2401.17690v1",
    "title": "EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning",
    "authors": [
      "Jaeyeon Kim",
      "Jaeyoon Jung",
      "Jinjoo Lee",
      "Sang Hoon Woo"
    ],
    "abstract": "We propose EnCLAP, a novel framework for automated audio captioning. EnCLAP\nemploys two acoustic representation models, EnCodec and CLAP, along with a\npretrained language model, BART. We also introduce a new training objective\ncalled masked codec modeling that improves acoustic awareness of the pretrained\nlanguage model. Experimental results on AudioCaps and Clotho demonstrate that\nour model surpasses the performance of baseline models. Source code will be\navailable at https://github.com/jaeyeonkim99/EnCLAP . An online demo is\navailable at https://huggingface.co/spaces/enclap-team/enclap .",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.17690v1",
    "published_date": "2024-01-31 09:23:16 UTC",
    "updated_date": "2024-01-31 09:23:16 UTC"
  },
  {
    "arxiv_id": "2401.17671v1",
    "title": "Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain",
    "authors": [
      "Gavin Mischler",
      "Yinghao Aaron Li",
      "Stephan Bickel",
      "Ashesh D. Mehta",
      "Nima Mesgarani"
    ],
    "abstract": "Recent advancements in artificial intelligence have sparked interest in the\nparallels between large language models (LLMs) and human neural processing,\nparticularly in language comprehension. While prior research has established\nsimilarities in the representation of LLMs and the brain, the underlying\ncomputational principles that cause this convergence, especially in the context\nof evolving LLMs, remain elusive. Here, we examined a diverse selection of\nhigh-performance LLMs with similar parameter sizes to investigate the factors\ncontributing to their alignment with the brain's language processing\nmechanisms. We find that as LLMs achieve higher performance on benchmark tasks,\nthey not only become more brain-like as measured by higher performance when\npredicting neural responses from LLM embeddings, but also their hierarchical\nfeature extraction pathways map more closely onto the brain's while using fewer\nlayers to do the same encoding. We also compare the feature extraction pathways\nof the LLMs to each other and identify new ways in which high-performing models\nhave converged toward similar hierarchical processing mechanisms. Finally, we\nshow the importance of contextual information in improving model performance\nand brain similarity. Our findings reveal the converging aspects of language\nprocessing in the brain and LLMs and offer new directions for developing models\nthat align more closely with human cognitive processing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 5 figures and 4 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17671v1",
    "published_date": "2024-01-31 08:48:35 UTC",
    "updated_date": "2024-01-31 08:48:35 UTC"
  },
  {
    "arxiv_id": "2401.17661v1",
    "title": "Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle",
    "authors": [
      "Víctor Julio Ramírez-Durán",
      "Idoia Berges",
      "Arantza Illarramendi"
    ],
    "abstract": "Many different worldwide initiatives are promoting the transformation from\nmachine dominant manufacturing to digital manufacturing. Thus, to achieve a\nsuccessful transformation to Industry 4.0 standard, manufacturing enterprises\nare required to implement a clear roadmap. However, Small and Medium\nManufacturing Enterprises (SMEs) encounter many barriers and difficulties\n(economical, technical, cultural, etc.) in the implementation of Industry 4.0.\nAlthough several works deal with the incorporation of Industry 4.0 technologies\nin the area of the product and supply chain life cycles, which SMEs could use\nas reference, this is not the case for the customer life cycle. Thus, we\npresent two contributions that can help the software engineers of those SMEs to\nincorporate Industry 4.0 technologies in the context of the customer life\ncycle. The first contribution is a methodology that can help those software\nengineers in the task of creating new software services, aligned with Industry\n4.0, that allow to change how customers interact with enterprises and the\nexperiences they have while interacting with them. The methodology details a\nset of stages that are divided into phases which in turn are made up of\nactivities. It places special emphasis on the incorporation of semantics\ndescriptions and 3D visualization in the implementation of those new services.\nThe second contribution is a system developed for a real manufacturing\nscenario, using the proposed methodology, which allows to observe the\npossibilities that this kind of systems can offer to SMEs in two phases of the\ncustomer life cycle: Discover & Shop, and Use & Service.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted version of paper: V\\'ictor Julio Ram\\'irez-Dur\\'an, Idoia\n  Berges, Arantza Illarramendi: Towards the implementation of Industry 4.0: A\n  methodology-based approach oriented to the customer life cycle. Comput. Ind.\n  126: 103403 (2021). DOI: 10.1016/j.compind.2021.103403",
    "pdf_url": "http://arxiv.org/pdf/2401.17661v1",
    "published_date": "2024-01-31 08:31:08 UTC",
    "updated_date": "2024-01-31 08:31:08 UTC"
  },
  {
    "arxiv_id": "2401.17657v1",
    "title": "An attempt to generate new bridge types from latent space of energy-based model",
    "authors": [
      "Hongjun Zhang"
    ],
    "abstract": "Use energy-based model for bridge-type innovation. The loss function is\nexplained by the game theory, the logic is clear and the formula is simple and\nclear. Thus avoid the use of maximum likelihood estimation to explain the loss\nfunction and eliminate the need for Monte Carlo methods to solve the normalized\ndenominator. Assuming that the bridge-type population follows a Boltzmann\ndistribution, a neural network is constructed to represent the energy function.\nUse Langevin dynamics technology to generate a new sample with low energy\nvalue, thus a generative model of bridge-type based on energy is established.\nTrain energy function on symmetric structured image dataset of three span beam\nbridge, arch bridge, cable-stayed bridge, and suspension bridge to accurately\ncalculate the energy values of real and fake samples. Sampling from latent\nspace, using gradient descent algorithm, the energy function transforms the\nsampling points into low energy score samples, thereby generating new bridge\ntypes different from the dataset. Due to unstable and slow training in this\nattempt, the possibility of generating new bridge types is rare and the image\ndefinition of generated images is low.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.17657v1",
    "published_date": "2024-01-31 08:21:35 UTC",
    "updated_date": "2024-01-31 08:21:35 UTC"
  },
  {
    "arxiv_id": "2401.17645v1",
    "title": "ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search",
    "authors": [
      "Shuai Wang",
      "Shengyao Zhuang",
      "Bevan Koopman",
      "Guido Zuccon"
    ],
    "abstract": "Federated search, which involves integrating results from multiple\nindependent search engines, will become increasingly pivotal in the context of\nRetrieval-Augmented Generation pipelines empowering LLM-based applications such\nas chatbots. These systems often distribute queries among various search\nengines, ranging from specialized (e.g., PubMed) to general (e.g., Google),\nbased on the nature of user utterances. A critical aspect of federated search\nis resource selection - the selection of appropriate resources prior to issuing\nthe query to ensure high-quality and rapid responses, and contain costs\nassociated with calling the external search engines. However, current SOTA\nresource selection methodologies primarily rely on feature-based learning\napproaches. These methods often involve the labour intensive and expensive\ncreation of training labels for each resource. In contrast, LLMs have exhibited\nstrong effectiveness as zero-shot methods across NLP and IR tasks. We\nhypothesise that in the context of federated search LLMs can assess the\nrelevance of resources without the need for extensive predefined labels or\nfeatures. In this paper, we propose ReSLLM. Our ReSLLM method exploits LLMs to\ndrive the selection of resources in federated search in a zero-shot setting. In\naddition, we devise an unsupervised fine tuning protocol, the Synthetic Label\nAugmentation Tuning (SLAT), where the relevance of previously logged queries\nand snippets from resources is predicted using an off-the-shelf LLM and then in\nturn used to fine-tune ReSLLM with respect to resource selection. Our empirical\nevaluation and analysis details the factors influencing the effectiveness of\nLLMs in this context. The results showcase the merits of ReSLLM for resource\nselection: not only competitive effectiveness in the zero-shot setting, but\nalso obtaining large when fine-tuned using SLAT-protocol.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17645v1",
    "published_date": "2024-01-31 07:58:54 UTC",
    "updated_date": "2024-01-31 07:58:54 UTC"
  },
  {
    "arxiv_id": "2402.00086v1",
    "title": "Retrosynthesis prediction enhanced by in-silico reaction data augmentation",
    "authors": [
      "Xu Zhang",
      "Yiming Mo",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "abstract": "Recent advances in machine learning (ML) have expedited retrosynthesis\nresearch by assisting chemists to design experiments more efficiently. However,\nall ML-based methods consume substantial amounts of paired training data (i.e.,\nchemical reaction: product-reactant(s) pair), which is costly to obtain.\nMoreover, companies view reaction data as a valuable asset and restrict the\naccessibility to researchers. These issues prevent the creation of more\npowerful retrosynthesis models due to their data-driven nature. As a response,\nwe exploit easy-to-access unpaired data (i.e., one component of\nproduct-reactant(s) pair) for generating in-silico paired data to facilitate\nmodel training. Specifically, we present RetroWISE, a self-boosting framework\nthat employs a base model inferred from real paired data to perform in-silico\nreaction generation and augmentation using unpaired data, ultimately leading to\na superior model. On three benchmark datasets, RetroWISE achieves the best\noverall performance against state-of-the-art models (e.g., +8.6% top-1 accuracy\non the USPTO-50K test dataset). Moreover, it consistently improves the\nprediction accuracy of rare transformations. These results show that Retro-\nWISE overcomes the training bottleneck by in-silico reactions, thereby paving\nthe way toward more effective ML-based retrosynthesis models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00086v1",
    "published_date": "2024-01-31 07:40:37 UTC",
    "updated_date": "2024-01-31 07:40:37 UTC"
  },
  {
    "arxiv_id": "2401.17633v1",
    "title": "Navigating the OverKill in Large Language Models",
    "authors": [
      "Chenyu Shi",
      "Xiao Wang",
      "Qiming Ge",
      "Songyang Gao",
      "Xianjun Yang",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang",
      "Xun Zhao",
      "Dahua Lin"
    ],
    "abstract": "Large language models are meticulously aligned to be both helpful and\nharmless. However, recent research points to a potential overkill which means\nmodels may refuse to answer benign queries. In this paper, we investigate the\nfactors for overkill by exploring how models handle and determine the safety of\nqueries. Our findings reveal the presence of shortcuts within models, leading\nto an over-attention of harmful words like 'kill' and prompts emphasizing\nsafety will exacerbate overkill. Based on these insights, we introduce\nSelf-Contrastive Decoding (Self-CD), a training-free and model-agnostic\nstrategy, to alleviate this phenomenon. We first extract such over-attention by\namplifying the difference in the model's output distributions when responding\nto system prompts that either include or omit an emphasis on safety. Then we\ndetermine the final next-token predictions by downplaying the over-attention\nfrom the model via contrastive decoding. Empirical results indicate that our\nmethod has achieved an average reduction of the refusal rate by 20\\% while\nhaving almost no impact on safety.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17633v1",
    "published_date": "2024-01-31 07:26:47 UTC",
    "updated_date": "2024-01-31 07:26:47 UTC"
  },
  {
    "arxiv_id": "2401.17626v2",
    "title": "Generative AI to Generate Test Data Generators",
    "authors": [
      "Benoit Baudry",
      "Khashayar Etemadi",
      "Sen Fang",
      "Yogya Gamage",
      "Yi Liu",
      "Yuxin Liu",
      "Martin Monperrus",
      "Javier Ron",
      "André Silva",
      "Deepika Tiwari"
    ],
    "abstract": "Generating fake data is an essential dimension of modern software testing, as\ndemonstrated by the number and significance of data faking libraries. Yet,\ndevelopers of faking libraries cannot keep up with the wide range of data to be\ngenerated for different natural languages and domains. In this paper, we assess\nthe ability of generative AI for generating test data in different domains. We\ndesign three types of prompts for Large Language Models (LLMs), which perform\ntest data generation tasks at different levels of integrability: 1) raw test\ndata generation, 2) synthesizing programs in a specific language that generate\nuseful test data, and 3) producing programs that use state-of-the-art faker\nlibraries. We evaluate our approach by prompting LLMs to generate test data for\n11 domains. The results show that LLMs can successfully generate realistic test\ndata generators in a wide range of domains at all three levels of\nintegrability.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17626v2",
    "published_date": "2024-01-31 06:58:26 UTC",
    "updated_date": "2024-06-14 14:49:12 UTC"
  },
  {
    "arxiv_id": "2402.00085v2",
    "title": "Scheduled Curiosity-Deep Dyna-Q: Efficient Exploration for Dialog Policy Learning",
    "authors": [
      "Xuecheng Niu",
      "Akinori Ito",
      "Takashi Nose"
    ],
    "abstract": "Training task-oriented dialog agents based on reinforcement learning is\ntime-consuming and requires a large number of interactions with real users. How\nto grasp dialog policy within limited dialog experiences remains an obstacle\nthat makes the agent training process less efficient. In addition, most\nprevious frameworks start training by randomly choosing training samples, which\ndiffers from the human learning method and hurts the efficiency and stability\nof training. Therefore, we propose Scheduled Curiosity-Deep Dyna-Q (SC-DDQ), a\ncuriosity-driven curriculum learning framework based on a state-of-the-art\nmodel-based reinforcement learning dialog model, Deep Dyna-Q (DDQ).\nFurthermore, we designed learning schedules for SC-DDQ and DDQ, respectively,\nfollowing two opposite training strategies: classic curriculum learning and its\nreverse version. Our results show that by introducing scheduled learning and\ncuriosity, the new framework leads to a significant improvement over the DDQ\nand Deep Q-learning(DQN). Surprisingly, we found that traditional curriculum\nlearning was not always effective. Specifically, according to the experimental\nresults, the easy-first and difficult-first strategies are more suitable for\nSC-DDQ and DDQ. To analyze our results, we adopted the entropy of sampled\nactions to depict action exploration and found that training strategies with\nhigh entropy in the first stage and low entropy in the last stage lead to\nbetter performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2402.00085v2",
    "published_date": "2024-01-31 06:13:28 UTC",
    "updated_date": "2024-05-20 12:10:04 UTC"
  },
  {
    "arxiv_id": "2401.17617v1",
    "title": "Unveiling the Power of Self-supervision for Multi-view Multi-human Association and Tracking",
    "authors": [
      "Wei Feng",
      "Feifan Wang",
      "Ruize Han",
      "Zekun Qian",
      "Song Wang"
    ],
    "abstract": "Multi-view multi-human association and tracking (MvMHAT), is a new but\nimportant problem for multi-person scene video surveillance, aiming to track a\ngroup of people over time in each view, as well as to identify the same person\nacross different views at the same time, which is different from previous MOT\nand multi-camera MOT tasks only considering the over-time human tracking. This\nway, the videos for MvMHAT require more complex annotations while containing\nmore information for self learning. In this work, we tackle this problem with a\nself-supervised learning aware end-to-end network. Specifically, we propose to\ntake advantage of the spatial-temporal self-consistency rationale by\nconsidering three properties of reflexivity, symmetry and transitivity. Besides\nthe reflexivity property that naturally holds, we design the self-supervised\nlearning losses based on the properties of symmetry and transitivity, for both\nappearance feature learning and assignment matrix optimization, to associate\nthe multiple humans over time and across views. Furthermore, to promote the\nresearch on MvMHAT, we build two new large-scale benchmarks for the network\ntraining and testing of different algorithms. Extensive experiments on the\nproposed benchmarks verify the effectiveness of our method. We have released\nthe benchmark and code to the public.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17617v1",
    "published_date": "2024-01-31 06:12:28 UTC",
    "updated_date": "2024-01-31 06:12:28 UTC"
  },
  {
    "arxiv_id": "2402.00084v1",
    "title": "EPSD: Early Pruning with Self-Distillation for Efficient Model Compression",
    "authors": [
      "Dong Chen",
      "Ning Liu",
      "Yichen Zhu",
      "Zhengping Che",
      "Rui Ma",
      "Fachao Zhang",
      "Xiaofeng Mou",
      "Yi Chang",
      "Jian Tang"
    ],
    "abstract": "Neural network compression techniques, such as knowledge distillation (KD)\nand network pruning, have received increasing attention. Recent work `Prune,\nthen Distill' reveals that a pruned student-friendly teacher network can\nbenefit the performance of KD. However, the conventional teacher-student\npipeline, which entails cumbersome pre-training of the teacher and complicated\ncompression steps, makes pruning with KD less efficient. In addition to\ncompressing models, recent compression techniques also emphasize the aspect of\nefficiency. Early pruning demands significantly less computational cost in\ncomparison to the conventional pruning methods as it does not require a large\npre-trained model. Likewise, a special case of KD, known as self-distillation\n(SD), is more efficient since it requires no pre-training or student-teacher\npair selection. This inspires us to collaborate early pruning with SD for\nefficient model compression. In this work, we propose the framework named Early\nPruning with Self-Distillation (EPSD), which identifies and preserves\ndistillable weights in early pruning for a given SD task. EPSD efficiently\ncombines early pruning and self-distillation in a two-step process, maintaining\nthe pruned network's trainability for compression. Instead of a simple\ncombination of pruning and SD, EPSD enables the pruned network to favor SD by\nkeeping more distillable weights before training to ensure better distillation\nof the pruned network. We demonstrated that EPSD improves the training of\npruned networks, supported by visual and quantitative analyses. Our evaluation\ncovered diverse benchmarks (CIFAR-10/100, Tiny-ImageNet, full ImageNet,\nCUB-200-2011, and Pascal VOC), with EPSD outperforming advanced pruning and SD\ntechniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors are with equal contributions. Paper accepted by\n  AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.00084v1",
    "published_date": "2024-01-31 05:39:55 UTC",
    "updated_date": "2024-01-31 05:39:55 UTC"
  },
  {
    "arxiv_id": "2402.00083v1",
    "title": "Modeling Access Differences to Reduce Disparity in Resource Allocation",
    "authors": [
      "Kenya Andrews",
      "Mesrob Ohannessian",
      "Tanya Berger-Wolf"
    ],
    "abstract": "Motivated by COVID-19 vaccine allocation, where vulnerable subpopulations are\nsimultaneously more impacted in terms of health and more disadvantaged in terms\nof access to the vaccine, we formalize and study the problem of resource\nallocation when there are inherent access differences that correlate with\nadvantage and disadvantage. We identify reducing resource disparity as a key\ngoal in this context and show its role as a proxy to more nuanced downstream\nimpacts. We develop a concrete access model that helps quantify how a given\nallocation translates to resource flow for the advantaged vs. the\ndisadvantaged, based on the access gap between them. We then provide a\nmethodology for access-aware allocation. Intuitively, the resulting allocation\nleverages more vaccines in locations with higher vulnerable populations to\nmitigate the access gap and reduce overall disparity. Surprisingly, knowledge\nof the access gap is often not needed to perform access-aware allocation. To\nsupport this formalism, we provide empirical evidence for our access model and\nshow that access-aware allocation can significantly reduce resource disparity\nand thus improve downstream outcomes. We demonstrate this at various scales,\nincluding at county, state, national, and global levels.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Association for Computing Machinery (2022)",
    "pdf_url": "http://arxiv.org/pdf/2402.00083v1",
    "published_date": "2024-01-31 05:25:12 UTC",
    "updated_date": "2024-01-31 05:25:12 UTC"
  },
  {
    "arxiv_id": "2401.17600v1",
    "title": "Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data",
    "authors": [
      "Chenhui Zhang",
      "Sherrie Wang"
    ],
    "abstract": "Large Vision-Language Models (VLMs) have demonstrated impressive performance\non complex tasks involving visual input with natural language instructions.\nHowever, it remains unclear to what extent capabilities on natural images\ntransfer to Earth observation (EO) data, which are predominantly satellite and\naerial images less common in VLM training data. In this work, we propose a\ncomprehensive benchmark to gauge the progress of VLMs toward being useful tools\nfor EO data by assessing their abilities on scene understanding, localization\nand counting, and change detection tasks. Motivated by real-world applications,\nour benchmark includes scenarios like urban monitoring, disaster relief, land\nuse, and conservation. We discover that, although state-of-the-art VLMs like\nGPT-4V possess extensive world knowledge that leads to strong performance on\nopen-ended tasks like location understanding and image captioning, their poor\nspatial reasoning limits usefulness on object localization and counting tasks.\nOur benchmark will be made publicly available at https://vleo.danielz.ch/ and\non Hugging Face at\nhttps://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70\nfor easy model evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "62 pages; work in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.17600v1",
    "published_date": "2024-01-31 04:57:12 UTC",
    "updated_date": "2024-01-31 04:57:12 UTC"
  },
  {
    "arxiv_id": "2401.17592v2",
    "title": "Local Feature Matching Using Deep Learning: A Survey",
    "authors": [
      "Shibiao Xu",
      "Shunpeng Chen",
      "Rongtao Xu",
      "Changwei Wang",
      "Peng Lu",
      "Li Guo"
    ],
    "abstract": "Local feature matching enjoys wide-ranging applications in the realm of\ncomputer vision, encompassing domains such as image retrieval, 3D\nreconstruction, and object recognition. However, challenges persist in\nimproving the accuracy and robustness of matching due to factors like viewpoint\nand lighting variations. In recent years, the introduction of deep learning\nmodels has sparked widespread exploration into local feature matching\ntechniques. The objective of this endeavor is to furnish a comprehensive\noverview of local feature matching methods. These methods are categorized into\ntwo key segments based on the presence of detectors. The Detector-based\ncategory encompasses models inclusive of Detect-then-Describe, Joint Detection\nand Description, Describe-then-Detect, as well as Graph Based techniques. In\ncontrast, the Detector-free category comprises CNN Based, Transformer Based,\nand Patch Based methods. Our study extends beyond methodological analysis,\nincorporating evaluations of prevalent datasets and metrics to facilitate a\nquantitative comparison of state-of-the-art techniques. The paper also explores\nthe practical application of local feature matching in diverse domains such as\nStructure from Motion, Remote Sensing Image Registration, and Medical Image\nRegistration, underscoring its versatility and significance across various\nfields. Ultimately, we endeavor to outline the current challenges faced in this\ndomain and furnish future research directions, thereby serving as a reference\nfor researchers involved in local feature matching and its interconnected\ndomains. A comprehensive list of studies in this survey is available at\nhttps://github.com/vignywang/Awesome-Local-Feature-Matching .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by Information Fusion 2024. Project page:\n  https://github.com/vignywang/Awesome-Local-Feature-Matching",
    "pdf_url": "http://arxiv.org/pdf/2401.17592v2",
    "published_date": "2024-01-31 04:32:41 UTC",
    "updated_date": "2024-03-11 01:32:03 UTC"
  },
  {
    "arxiv_id": "2401.17585v1",
    "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks",
    "authors": [
      "Wenyue Hua",
      "Jiang Guo",
      "Mingwen Dong",
      "Henghui Zhu",
      "Patrick Ng",
      "Zhiguo Wang"
    ],
    "abstract": "Current approaches of knowledge editing struggle to effectively propagate\nupdates to interconnected facts. In this work, we delve into the barriers that\nhinder the appropriate propagation of updated knowledge within these models for\naccurate reasoning. To support our analysis, we introduce a novel\nreasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing\ndataset) -- which covers six common reasoning schemes in real world. We conduct\na thorough analysis of existing knowledge editing techniques, including input\naugmentation, finetuning, and locate-and-edit. We found that all model editing\nmethods show notably low performance on this dataset, especially in certain\nreasoning schemes. Our analysis over the chain-of-thought generation of edited\nmodels further uncover key reasons behind the inadequacy of existing knowledge\nediting methods from a reasoning standpoint, involving aspects on fact-wise\nediting, fact recall ability, and coherence in generation. We will make our\nbenchmark publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 14 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17585v1",
    "published_date": "2024-01-31 04:12:59 UTC",
    "updated_date": "2024-01-31 04:12:59 UTC"
  },
  {
    "arxiv_id": "2401.17583v3",
    "title": "Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion",
    "authors": [
      "Tairan He",
      "Chong Zhang",
      "Wenli Xiao",
      "Guanqi He",
      "Changliu Liu",
      "Guanya Shi"
    ],
    "abstract": "Legged robots navigating cluttered environments must be jointly agile for\nefficient task execution and safe to avoid collisions with obstacles or humans.\nExisting studies either develop conservative controllers (< 1.0 m/s) to ensure\nsafety, or focus on agility without considering potentially fatal collisions.\nThis paper introduces Agile But Safe (ABS), a learning-based control framework\nthat enables agile and collision-free locomotion for quadrupedal robots. ABS\ninvolves an agile policy to execute agile motor skills amidst obstacles and a\nrecovery policy to prevent failures, collaboratively achieving high-speed and\ncollision-free navigation. The policy switch in ABS is governed by a learned\ncontrol-theoretic reach-avoid value network, which also guides the recovery\npolicy as an objective function, thereby safeguarding the robot in a closed\nloop. The training process involves the learning of the agile policy, the\nreach-avoid value network, the recovery policy, and an exteroception\nrepresentation network, all in simulation. These trained modules can be\ndirectly deployed in the real world with onboard sensing and computation,\nleading to high-speed and collision-free navigation in confined indoor and\noutdoor spaces with both static and dynamic obstacles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Published at RSS 2024, Project website:\n  https://agile-but-safe.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2401.17583v3",
    "published_date": "2024-01-31 03:58:28 UTC",
    "updated_date": "2024-05-21 05:49:52 UTC"
  },
  {
    "arxiv_id": "2402.00893v1",
    "title": "MoDE: A Mixture-of-Experts Model with Mutual Distillation among the Experts",
    "authors": [
      "Zhitian Xie",
      "Yinger Zhang",
      "Chenyi Zhuang",
      "Qitao Shi",
      "Zhining Liu",
      "Jinjie Gu",
      "Guannan Zhang"
    ],
    "abstract": "The application of mixture-of-experts (MoE) is gaining popularity due to its\nability to improve model's performance. In an MoE structure, the gate layer\nplays a significant role in distinguishing and routing input features to\ndifferent experts. This enables each expert to specialize in processing their\ncorresponding sub-tasks. However, the gate's routing mechanism also gives rise\nto narrow vision: the individual MoE's expert fails to use more samples in\nlearning the allocated sub-task, which in turn limits the MoE to further\nimprove its generalization ability. To effectively address this, we propose a\nmethod called Mixture-of-Distilled-Expert (MoDE), which applies moderate mutual\ndistillation among experts to enable each expert to pick up more features\nlearned by other experts and gain more accurate perceptions on their original\nallocated sub-tasks. We conduct plenty experiments including tabular, NLP and\nCV datasets, which shows MoDE's effectiveness, universality and robustness.\nFurthermore, we develop a parallel study through innovatively constructing\n\"expert probing\", to experimentally prove why MoDE works: moderate distilling\nknowledge can improve each individual expert's test performances on their\nassigned tasks, leading to MoE's overall performance improvement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI-24",
    "pdf_url": "http://arxiv.org/pdf/2402.00893v1",
    "published_date": "2024-01-31 03:52:32 UTC",
    "updated_date": "2024-01-31 03:52:32 UTC"
  },
  {
    "arxiv_id": "2401.17580v2",
    "title": "Graph Contrastive Learning with Cohesive Subgraph Awareness",
    "authors": [
      "Yucheng Wu",
      "Leye Wang",
      "Xiao Han",
      "Han-Jia Ye"
    ],
    "abstract": "Graph contrastive learning (GCL) has emerged as a state-of-the-art strategy\nfor learning representations of diverse graphs including social and biomedical\nnetworks. GCL widely uses stochastic graph topology augmentation, such as\nuniform node dropping, to generate augmented graphs. However, such stochastic\naugmentations may severely damage the intrinsic properties of a graph and\ndeteriorate the following representation learning process. We argue that\nincorporating an awareness of cohesive subgraphs during the graph augmentation\nand learning processes has the potential to enhance GCL performance. To this\nend, we propose a novel unified framework called CTAug, to seamlessly integrate\ncohesion awareness into various existing GCL mechanisms. In particular, CTAug\ncomprises two specialized modules: topology augmentation enhancement and graph\nlearning enhancement. The former module generates augmented graphs that\ncarefully preserve cohesion properties, while the latter module bolsters the\ngraph encoder's ability to discern subgraph patterns. Theoretical analysis\nshows that CTAug can strictly improve existing GCL mechanisms. Empirical\nexperiments verify that CTAug can achieve state-of-the-art performance for\ngraph representation learning, especially for graphs with high degrees. The\ncode is available at https://doi.org/10.5281/zenodo.10594093, or\nhttps://github.com/wuyucheng2002/CTAug.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17580v2",
    "published_date": "2024-01-31 03:51:30 UTC",
    "updated_date": "2024-02-21 16:33:59 UTC"
  },
  {
    "arxiv_id": "2402.00892v1",
    "title": "EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks",
    "authors": [
      "Shijia Liao",
      "Shiyi Lan",
      "Arun George Zachariah"
    ],
    "abstract": "The advent of Large Models marks a new era in machine learning, significantly\noutperforming smaller models by leveraging vast datasets to capture and\nsynthesize complex patterns. Despite these advancements, the exploration into\nscaling, especially in the audio generation domain, remains limited, with\nprevious efforts didn't extend into the high-fidelity (HiFi) 44.1kHz domain and\nsuffering from both spectral discontinuities and blurriness in the\nhigh-frequency domain, alongside a lack of robustness against out-of-domain\ndata. These limitations restrict the applicability of models to diverse use\ncases, including music and singing generation. Our work introduces Enhanced\nVarious Audio Generation via Scalable Generative Adversarial Networks\n(EVA-GAN), yields significant improvements over previous state-of-the-art in\nspectral and high-frequency reconstruction and robustness in out-of-domain data\nperformance, enabling the generation of HiFi audios by employing an extensive\ndataset of 36,000 hours of 44.1kHz audio, a context-aware module, a\nHuman-In-The-Loop artifact measurement toolkit, and expands the model to\napproximately 200 million parameters. Demonstrations of our work are available\nat https://double-blind-eva-gan.cc.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00892v1",
    "published_date": "2024-01-31 03:31:03 UTC",
    "updated_date": "2024-01-31 03:31:03 UTC"
  },
  {
    "arxiv_id": "2401.17548v6",
    "title": "Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators",
    "authors": [
      "Lifan Zhao",
      "Yanyan Shen"
    ],
    "abstract": "Recently, channel-independent methods have achieved state-of-the-art\nperformance in multivariate time series (MTS) forecasting. Despite reducing\noverfitting risks, these methods miss potential opportunities in utilizing\nchannel dependence for accurate predictions. We argue that there exist locally\nstationary lead-lag relationships between variates, i.e., some lagged variates\nmay follow the leading indicators within a short time period. Exploiting such\nchannel dependence is beneficial since leading indicators offer advance\ninformation that can be used to reduce the forecasting difficulty of the lagged\nvariates. In this paper, we propose a new method named LIFT that first\nefficiently estimates leading indicators and their leading steps at each time\nstep and then judiciously allows the lagged variates to utilize the advance\ninformation from leading indicators. LIFT plays as a plugin that can be\nseamlessly collaborated with arbitrary time series forecasting methods.\nExtensive experiments on six real-world datasets demonstrate that LIFT improves\nthe state-of-the-art methods by 5.5% in average forecasting performance. Our\ncode is available at https://github.com/SJTU-Quant/LIFT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024. Code is at https://github.com/SJTU-DMTai/LIFT",
    "pdf_url": "http://arxiv.org/pdf/2401.17548v6",
    "published_date": "2024-01-31 02:26:09 UTC",
    "updated_date": "2024-08-13 05:31:22 UTC"
  },
  {
    "arxiv_id": "2401.17542v3",
    "title": "A Medical Data-Effective Learning Benchmark for Highly Efficient Pre-training of Foundation Models",
    "authors": [
      "Wenxuan Yang",
      "Weimin Tan",
      "Yuqi Sun",
      "Bo Yan"
    ],
    "abstract": "Foundation models, pre-trained on massive datasets, have achieved\nunprecedented generalizability. However, is it truly necessary to involve such\nvast amounts of data in pre-training, consuming extensive computational\nresources? This paper introduces data-effective learning, aiming to use data in\nthe most impactful way to pre-train foundation models. This involves strategies\nthat focus on data quality rather than quantity, ensuring the data used for\ntraining has high informational value. Data-effective learning plays a profound\nrole in accelerating foundation model training, reducing computational costs,\nand saving data storage, which is very important as the volume of medical data\nin recent years has grown beyond many people's expectations. However, due to\nthe lack of standards and comprehensive benchmarks, research on medical\ndata-effective learning is poorly studied. To address this gap, our paper\nintroduces a comprehensive benchmark specifically for evaluating data-effective\nlearning in the medical field. This benchmark includes a dataset with millions\nof data samples from 31 medical centers (DataDEL), a baseline method for\ncomparison (MedDEL), and a new evaluation metric (NormDEL) to objectively\nmeasure data-effective learning performance. Our extensive experimental results\nshow the baseline MedDEL can achieve performance comparable to the original\nlarge dataset with only 5% of the data. Establishing such an open\ndata-effective learning benchmark is crucial for the medical foundation model\nresearch community because it facilitates efficient data use, promotes\ncollaborative breakthroughs, and fosters the development of cost-effective,\nscalable, and impactful healthcare solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17542v3",
    "published_date": "2024-01-31 02:09:21 UTC",
    "updated_date": "2024-08-16 12:46:03 UTC"
  },
  {
    "arxiv_id": "2401.17527v2",
    "title": "Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming",
    "authors": [
      "Haotian Ling",
      "Zhihai Wang",
      "Jie Wang"
    ],
    "abstract": "Cutting planes (cuts) play an important role in solving mixed-integer linear\nprograms (MILPs), as they significantly tighten the dual bounds and improve the\nsolving performance. A key problem for cuts is when to stop cuts generation,\nwhich is important for the efficiency of solving MILPs. However, many modern\nMILP solvers employ hard-coded heuristics to tackle this problem, which tends\nto neglect underlying patterns among MILPs from certain applications. To\naddress this challenge, we formulate the cuts generation stopping problem as a\nreinforcement learning problem and propose a novel hybrid graph representation\nmodel (HYGRO) to learn effective stopping strategies. An appealing feature of\nHYGRO is that it can effectively capture both the dynamic and static features\nof MILPs, enabling dynamic decision-making for the stopping strategies. To the\nbest of our knowledge, HYGRO is the first data-driven method to tackle the cuts\ngeneration stopping problem. By integrating our approach with modern solvers,\nexperiments demonstrate that HYGRO significantly improves the efficiency of\nsolving MILPs compared to competitive baselines, achieving up to 31%\nimprovement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17527v2",
    "published_date": "2024-01-31 01:09:40 UTC",
    "updated_date": "2024-02-02 05:54:58 UTC"
  },
  {
    "arxiv_id": "2401.17513v2",
    "title": "A PNP ion channel deep learning solver with local neural network and finite element input data",
    "authors": [
      "Hwi Lee",
      "Zhen Chao",
      "Harris Cobb",
      "Yingjie Liu",
      "Dexuan Xie"
    ],
    "abstract": "In this paper, a deep learning method for solving an improved one-dimensional\nPoisson-Nernst-Planck ion channel (PNPic) model, called the PNPic deep learning\nsolver, is presented. In particular, it combines a novel local neural network\nscheme with an effective PNPic finite element solver. Since the input data of\nthe neural network scheme only involves a small local patch of coarse grid\nsolutions, which the finite element solver can quickly produce, the PNPic deep\nlearning solver can be trained much faster than any corresponding conventional\nglobal neural network solvers. After properly trained, it can output a\npredicted PNPic solution in a much higher degree of accuracy than the low cost\ncoarse grid solutions and can reflect different perturbation cases on the\nparameters, ion channel subregions, and interface and boundary values, etc.\nConsequently, the PNPic deep learning solver can generate a numerical solution\nwith high accuracy for a family of PNPic models. As an initial study, two types\nof numerical tests were done by perturbing one and two parameters of the PNPic\nmodel, respectively, as well as the tests done by using a few perturbed\ninterface positions of the model as training samples. These tests demonstrate\nthat the PNPic deep learning solver can generate highly accurate PNPic\nnumerical solutions.",
    "categories": [
      "physics.bio-ph",
      "cs.AI",
      "physics.comp-ph",
      "92-08"
    ],
    "primary_category": "physics.bio-ph",
    "comment": "17 pages, 4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.17513v2",
    "published_date": "2024-01-31 00:15:31 UTC",
    "updated_date": "2024-03-31 01:53:02 UTC"
  },
  {
    "arxiv_id": "2401.17511v1",
    "title": "Linguistically Communicating Uncertainty in Patient-Facing Risk Prediction Models",
    "authors": [
      "Adarsa Sivaprasad",
      "Ehud Reiter"
    ],
    "abstract": "This paper addresses the unique challenges associated with uncertainty\nquantification in AI models when applied to patient-facing contexts within\nhealthcare. Unlike traditional eXplainable Artificial Intelligence (XAI)\nmethods tailored for model developers or domain experts, additional\nconsiderations of communicating in natural language, its presentation and\nevaluating understandability are necessary. We identify the challenges in\ncommunication model performance, confidence, reasoning and unknown knowns using\nnatural language in the context of risk prediction. We propose a design aimed\nat addressing these challenges, focusing on the specific application of\nin-vitro fertilisation outcome prediction.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17511v1",
    "published_date": "2024-01-31 00:08:44 UTC",
    "updated_date": "2024-01-31 00:08:44 UTC"
  }
]