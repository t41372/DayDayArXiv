{
  "date": "2024-01-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-31 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型优化、LLMs 在医疗和实际应用中的创新、可解释性研究，以及机器学习在图像处理和机器人领域的进展，其中 LLMs 相关论文（如 Microsoft 工程师参与的内部分析）和生成式 AI 在体育的实际部署最为令人印象深刻。\n\n### 主要论文讨论\n我挑选了最具影响力和话题度的论文优先讨论，包括 LLMs、生成式 AI 和可解释性主题的代表作，其他论文则快速掠过。以下按主题归类，突出核心贡献。\n\n#### LLMs 和生成式 AI 应用（高话题度）\n- **Real Sparks of Artificial Intelligence and the Importance of Inner Interpretability**（真实 AI 火花：内部分析的重要性）  \n  作者包括 Alex Grzankowski，这篇论文批评了 Microsoft 工程师的黑盒可解释性方法，提出内部分析（Inner Interpretability）来理解模型的内部激活和算法。关键发现：内部分析能更好地揭示智能过程，建议哲学和计算机科学结合，为 LLMs 可解释性提供新方向。\n\n- **Can Generative AI Support Patients' & Caregivers' Informational Needs? Towards Task-Centric Evaluation Of AI Systems**（生成式 AI 是否能支持患者和护理者的信息需求？面向任务的 AI 系统评估）  \n  这篇论文评估了 ChatGPT 等模型在医疗决策中的实用性，通过主题分析（如解释医疗术语和治疗选项），发现模型在某些主题上响应质量不稳定。贡献：提出患者导向的评估框架，强调模型需适应真实信息需求。\n\n- **Large Scale Generative AI Text Applied to Sports and Music**（大规模生成式 AI 文本应用于体育和音乐）  \n  论文展示了 AI 在体育赛事（如 US Open）和音乐（如 Grammy）中的应用，通过多模态数据生成流畅文本。发现：系统实现了 15 倍速度提升和 82.00 Rouge-L 分数，支持 90 百万用户。亮点：实际部署效果出色，作者包括知名研究者如 Rogerio Feris。\n\n- **SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition**（SpeechComposer：通过提示组合统一多个语音任务）  \n  提出一个解码器-only 模型，通过提示组合处理语音合成、识别等任务。贡献：模型在多种任务上性能提升，支持知识共享，作者如 Shinji Watanabe 的参与增强了可信度。\n\n- **Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?**（语言模型在问题解决中是否表现出与人类学习者相同的认知偏差？）  \n  研究 LLMs（如 GPT-4）在算术问题中的偏差，分为文本理解、规划和执行步骤。发现：LLMs 在前两步类似人类，但执行步差异大。作者如 Bernhard Schölkopf 的知名度使这篇论文更具影响力。\n\n- **On Prompt-Driven Safeguarding for Large Language Models**（基于提示的 LLMs 安全机制）  \n  探索安全提示如何影响 LLMs 行为，提出 Directed Representation Optimization 方法。贡献：优化提示可减少有害响应，同时保持模型性能，在 ICML 2024 接受。\n\n其他 LLMs 相关论文（如 Paramanu、Global-Liar）快速提：它们聚焦印度语言模型和 LLMs 偏差，但贡献较局部，如 Paramanu 展示了小模型的高效性。\n\n#### 机器学习和图像处理优化（重要但次要话题）\n- **Learning Label Hierarchy with Supervised Contrastive Learning**（使用监督对比学习学习标签层次）  \n  提出 LASCL 方法，融入标签层次提升特征空间。发现：在多标签分类中，准确率优于基线，如 75.97% 多类分类准确率。\n\n- **MOD-CL: Multi-label Object Detection with Constrained Loss**（MOD-CL：使用约束损失的多标签对象检测）  \n  基于 YOLOv8 的框架，引入约束损失提升检测输出。贡献：在任务中显著提高分数，适合实际应用。\n\n- **Improving Object Detection Quality in Football Through Super-Resolution Techniques**（通过超分辨率技术提升足球对象检测质量）  \n  使用超分辨率预处理提升检测准确率，mAP 提高 12%。发现：对低分辨率场景特别有效。\n\n其他图像和检测论文（如 Wavelet Analysis、Attention Graph）快速掠过：它们优化 EEG 或对象检测，但未有突破性创新。\n\n#### 其他领域快速掠过\n其余论文涉及联邦学习（如 FedCore，减少训练时间 8 倍）、强化学习（如 A Reinforcement Learning Based Controller，降低机器人力学力 35%）、量子计算（如 Circuit Partitioning）和医疗应用（如 iMove、PF-GAN）。这些虽有技术贡献，但较专业或应用性弱，因此简要总结：联邦学习论文优化隐私和效率；医疗论文如 iMove 通过生物阻抗提升活动识别准确率 3.22%，但整体影响力不如 LLMs 主题。\n\n总之，今天的论文突显了 AI 模型在实际场景中的潜力，但也暴露了可解释性和偏差问题。感兴趣的读者可关注 LLMs 相关工作，了解更多创新应用！（全文精简，聚焦高影响力内容）",
  "papers": [
    {
      "arxiv_id": "2402.09448v1",
      "title": "A Comparative Study of Conventional and Tripolar EEG for High-Performance Reach-to-Grasp BCI Systems",
      "title_zh": "传统的和三极 EEG 在高性能伸手抓取脑机接口系统中的比较研究",
      "authors": [
        "Ali Rabiee",
        "Sima Ghafoori",
        "Anna Cetera",
        "Walter Besio",
        "Reza Abiri"
      ],
      "abstract": "This study aims to enhance BCI applications for individuals with motor\nimpairments by comparing the effectiveness of tripolar EEG (tEEG) with\nconventional EEG. The focus is on interpreting and decoding various grasping\nmovements, such as power grasp and precision grasp. The goal is to determine\nwhich EEG technology is more effective in processing and translating grasp\nrelated neural signals. The approach involved experimenting on ten healthy\nparticipants who performed two distinct grasp movements: power grasp and\nprecision grasp, with a no movement condition serving as the baseline. Our\nresearch presents a thorough comparison between EEG and tEEG in decoding\ngrasping movements. This comparison spans several key parameters, including\nsignal to noise ratio (SNR), spatial resolution via functional connectivity,\nERPs, and wavelet time frequency analysis. Additionally, our study involved\nextracting and analyzing statistical features from the wavelet coefficients,\nand both binary and multiclass classification methods were employed. Four\nmachine learning algorithms were used to evaluate the decoding accuracies. Our\nresults indicated that tEEG demonstrated superior performance over conventional\nEEG in various aspects. This included a higher signal to noise ratio, enhanced\nspatial resolution, and more informative data in ERPs and wavelet time\nfrequency analysis. The use of tEEG led to notable improvements in decoding\naccuracy for differentiating movement types. Specifically, tEEG achieved around\n90% accuracy in binary and 75.97% for multiclass classification. These results\nare markedly better than those from standard EEG, which recorded a maximum of\n77.85% and 61.27% in similar tasks, respectively. These findings highlight the\nsuperior effectiveness of tEEG over EEG in decoding grasp types and its\ncompetitive or superior performance in complex classifications compared with\nexisting research.",
      "tldr_zh": "这篇论文比较了传统 EEG 和三极 EEG (tEEG) 在高性能脑机接口 (BCI) 系统中的效果，专注于解码抓取动作如力量抓取和精确抓取，以提升运动障碍患者的辅助应用。研究方法包括让10名健康参与者进行抓取和无动作实验，分析信噪比 (SNR)、空间分辨率、事件相关电位 (ERPs) 和小波时频分析，并使用四种机器学习算法进行二元和多类分类。结果显示 tEEG 表现出色，具有更高的 SNR 和空间分辨率，在二元分类中达到约90%准确率，多类分类达75.97%，而传统 EEG 仅为77.85%和61.27%。这些发现强调了 tEEG 在抓取动作解码中的优势，有望提升 BCI 系统的性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09448v1",
      "published_date": "2024-01-31 23:35:44 UTC",
      "updated_date": "2024-01-31 23:35:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:43:13.588222"
    },
    {
      "arxiv_id": "2402.00234v2",
      "title": "Can Generative AI Support Patients' & Caregivers' Informational Needs? Towards Task-Centric Evaluation Of AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Rajagopal",
        "Jae Ho Sohn",
        "Hari Subramonyam",
        "Shiwali Mohan"
      ],
      "abstract": "Generative AI systems such as ChatGPT and Claude are built upon language\nmodels that are typically evaluated for accuracy on curated benchmark datasets.\nSuch evaluation paradigms measure predictive and reasoning capabilities of\nlanguage models but do not assess if they can provide information that is\nuseful to people. In this paper, we take some initial steps in developing an\nevaluation paradigm that centers human understanding and decision-making. We\nstudy the utility of generative AI systems in supporting people in a concrete\ntask - making sense of clinical reports and imagery in order to make a clinical\ndecision. We conducted a formative need-finding study in which participants\ndiscussed chest computed tomography (CT) scans and associated radiology reports\nof a fictitious close relative with a cardiothoracic radiologist. Using\nthematic analysis of the conversation between participants and medical experts,\nwe identified commonly occurring themes across interactions, including\nclarifying medical terminology, locating the problems mentioned in the report\nin the scanned image, understanding disease prognosis, discussing the next\ndiagnostic steps, and comparing treatment options. Based on these themes, we\nevaluated two state-of-the-art generative AI systems against the radiologist's\nresponses. Our results reveal variability in the quality of responses generated\nby the models across various themes. We highlight the importance of\npatient-facing generative AI systems to accommodate a diverse range of\nconversational themes, catering to the real-world informational needs of\npatients.",
      "tldr_zh": "这篇论文探讨了生成式 AI（如 ChatGPT 和 Claude）是否能有效支持患者和护理者在医疗决策中的信息需求，提出了一种以任务为中心的评估范式，强调人类理解和决策的核心。研究通过一个形成性需求调查，让参与者与心脏胸部放射科医生讨论虚构亲属的胸部 CT 扫描和报告，并使用 thematic analysis 识别常见主题，包括澄清医学术语、在图像中定位问题、理解疾病预后、讨论诊断步骤和比较治疗选项。评估结果显示，两款最先进 AI 系统的响应质量在不同主题上存在变异，突出了开发患者面向生成式 AI 系统以适应多样化真实需求的重要性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00234v2",
      "published_date": "2024-01-31 23:24:37 UTC",
      "updated_date": "2025-02-28 05:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:43:24.788961"
    },
    {
      "arxiv_id": "2402.00901v1",
      "title": "Real Sparks of Artificial Intelligence and the Importance of Inner Interpretability",
      "title_zh": "人工智能的真实火花以及内部可解释性的重要性",
      "authors": [
        "Alex Grzankowski"
      ],
      "abstract": "The present paper looks at one of the most thorough articles on the\nintelligence of GPT, research conducted by engineers at Microsoft. Although\nthere is a great deal of value in their work, I will argue that, for familiar\nphilosophical reasons, their methodology, !Blackbox Interpretability\"#is\nwrongheaded. But there is a better way. There is an exciting and emerging\ndiscipline of !Inner Interpretability\"#(and specifically Mechanistic\nInterpretability) that aims to uncover the internal activations and weights of\nmodels in order to understand what they represent and the algorithms they\nimplement. In my view, a crucial mistake in Black-box Interpretability is the\nfailure to appreciate that how processes are carried out matters when it comes\nto intelligence and understanding. I can#t pretend to have a full story that\nprovides both necessary and sufficient conditions for being intelligent, but I\ndo think that Inner Interpretability dovetails nicely with plausible\nphilosophical views of what intelligence requires. So the conclusion is modest,\nbut the important point in my view is seeing how to get the research on the\nright track. Towards the end of the paper, I will show how some of the\nphilosophical concepts can be used to further refine how Inner Interpretability\nis approached, so the paper helps draw out a profitable, future two-way\nexchange between Philosophers and Computer Scientists.",
      "tldr_zh": "这篇论文批评了 Microsoft 工程师对 GPT 智能的研究方法，即 Blackbox Interpretability，认为其忽略了内部过程在智能理解中的关键作用。作者提倡采用 Inner Interpretability，特别是 Mechanistic Interpretability，来揭示模型的内部激活、权重和算法，从而更准确地评估人工智能的智能性。论文认为，这种方法与哲学观点相符，并建议哲学家和计算机科学家开展合作，以优化未来研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00901v1",
      "published_date": "2024-01-31 23:22:13 UTC",
      "updated_date": "2024-01-31 23:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:43:34.636639"
    },
    {
      "arxiv_id": "2402.00232v1",
      "title": "Learning Label Hierarchy with Supervised Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixue Lian",
        "William A. Sethares",
        "Junjie Hu"
      ],
      "abstract": "Supervised contrastive learning (SCL) frameworks treat each class as\nindependent and thus consider all classes to be equally important. This\nneglects the common scenario in which label hierarchy exists, where\nfine-grained classes under the same category show more similarity than very\ndifferent ones. This paper introduces a family of Label-Aware SCL methods\n(LASCL) that incorporates hierarchical information to SCL by leveraging\nsimilarities between classes, resulting in creating a more well-structured and\ndiscriminative feature space. This is achieved by first adjusting the distance\nbetween instances based on measures of the proximity of their classes with the\nscaled instance-instance-wise contrastive. An additional instance-center-wise\ncontrastive is introduced to move within-class examples closer to their\ncenters, which are represented by a set of learnable label parameters. The\nlearned label parameters can be directly used as a nearest neighbor classifier\nwithout further finetuning. In this way, a better feature representation is\ngenerated with improvements of intra-cluster compactness and inter-cluster\nseparation. Experiments on three datasets show that the proposed LASCL works\nwell on text classification of distinguishing a single label among\nmulti-labels, outperforming the baseline supervised approaches. Our code is\npublicly available.",
      "tldr_zh": "这篇论文针对 Supervised Contrastive Learning (SCL) 忽略标签层次结构的问题，提出了一种 Label-Aware SCL (LASCL) 方法，通过利用类别间的相似性来优化特征空间。LASCL 包括 scaled instance-instance-wise contrastive 来根据类别接近度调整实例距离，以及 instance-center-wise contrastive 来将同类实例拉近到由可学习标签参数表示的中心，从而提升 intra-cluster compactness 和 inter-cluster separation。实验在三个数据集上证明，LASCL 在多标签文本分类任务中优于基线 Supervised 方法，提高了分类性能；此外，学到的标签参数可直接用作 nearest neighbor 分类器，无需进一步微调。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00232v1",
      "published_date": "2024-01-31 23:21:40 UTC",
      "updated_date": "2024-01-31 23:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:43:48.074540"
    },
    {
      "arxiv_id": "2402.09447v1",
      "title": "Wavelet Analysis of Noninvasive EEG Signals Discriminates Complex and Natural Grasp Types",
      "title_zh": "非侵入式 EEG 信号的小波分析区分复杂和自然抓取类型",
      "authors": [
        "Ali Rabiee",
        "Sima Ghafoori",
        "Anna Cetera",
        "Reza Abiri"
      ],
      "abstract": "This research aims to decode hand grasps from Electroencephalograms (EEGs)\nfor dexterous neuroprosthetic development and Brain-Computer Interface (BCI)\napplications, especially for patients with motor disorders. Particularly, it\nfocuses on distinguishing two complex natural power and precision grasps in\naddition to a neutral condition as a no-movement condition using a new\nEEG-based BCI platform and wavelet signal processing. Wavelet analysis involved\ngenerating time-frequency and topographic maps from wavelet power coefficients.\nThen, by using machine learning techniques with novel wavelet features, we\nachieved high average accuracies: 85.16% for multiclass, 95.37% for No-Movement\nvs Power, 95.40% for No-Movement vs Precision, and 88.07% for Power vs\nPrecision, demonstrating the effectiveness of these features in EEG-based grasp\ndifferentiation. In contrast to previous studies, a critical part of our study\nwas permutation feature importance analysis, which highlighted key features for\ngrasp classification. It revealed that the most crucial brain activities during\ngrasping occur in the motor cortex, within the alpha and beta frequency bands.\nThese insights demonstrate the potential of wavelet features in real-time\nneuroprosthetic technology and BCI applications.",
      "tldr_zh": "这篇论文使用小波分析（wavelet analysis）从非侵入性 EEG 信号中区分复杂的自然抓握类型，包括 power 和 precision grasps，以及中性条件（no-movement），以支持灵巧神经假肢开发和 BCI 应用。研究采用小波功率系数生成时间-频率图和地形图，并结合机器学习技术处理新颖的 wavelet 特征，实现了高准确率：多类85.16%、No-Movement vs Power 95.37%、No-Movement vs Precision 95.40%、以及 Power vs Precision 88.07%。通过 permutation feature importance 分析，论文发现抓握分类的关键特征主要位于运动皮层（motor cortex）的 alpha 和 beta 频段，这突显了 wavelet 特征在实时神经假肢技术和 BCI 应用中的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09447v1",
      "published_date": "2024-01-31 23:13:38 UTC",
      "updated_date": "2024-01-31 23:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:00.775791"
    },
    {
      "arxiv_id": "2403.07885v1",
      "title": "MOD-CL: Multi-label Object Detection with Constrained Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Sota Moriyama",
        "Koji Watanabe",
        "Katsumi Inoue",
        "Akihiro Takemura"
      ],
      "abstract": "We introduce MOD-CL, a multi-label object detection framework that utilizes\nconstrained loss in the training process to produce outputs that better satisfy\nthe given requirements. In this paper, we use $\\mathrm{MOD_{YOLO}}$, a\nmulti-label object detection model built upon the state-of-the-art object\ndetection model YOLOv8, which has been published in recent years. In Task 1, we\nintroduce the Corrector Model and Blender Model, two new models that follow\nafter the object detection process, aiming to generate a more constrained\noutput. For Task 2, constrained losses have been incorporated into the\n$\\mathrm{MOD_{YOLO}}$ architecture using Product T-Norm. The results show that\nthese implementations are instrumental to improving the scores for both Task 1\nand Task 2.",
      "tldr_zh": "论文提出了一种名为 MOD-CL 的多标签物体检测框架，通过引入 constrained loss 来优化训练过程，使输出更好地满足特定要求。框架基于 MOD_YOLO（建立在 YOLOv8 之上），并新增了 Corrector Model 和 Blender Model 模型，用于后续处理以生成更精确的受约束输出；同时，将 constrained losses 与 Product T-Norm 整合到 MOD_YOLO 架构中。实验结果显示，这些方法显著提升了 Task 1 和 Task 2 的分数，证明了其在多标签物体检测中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07885v1",
      "published_date": "2024-01-31 23:13:20 UTC",
      "updated_date": "2024-01-31 23:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:10.488923"
    },
    {
      "arxiv_id": "2402.15514v2",
      "title": "Large Scale Generative AI Text Applied to Sports and Music",
      "title_zh": "大规模生成式 AI 文本应用于体育和音乐",
      "authors": [
        "Aaron Baughman",
        "Stephen Hammer",
        "Rahul Agarwal",
        "Gozde Akay",
        "Eduardo Morales",
        "Tony Johnson",
        "Leonid Karlinsky",
        "Rogerio Feris"
      ],
      "abstract": "We address the problem of scaling up the production of media content,\nincluding commentary and personalized news stories, for large-scale sports and\nmusic events worldwide. Our approach relies on generative AI models to\ntransform a large volume of multimodal data (e.g., videos, articles, real-time\nscoring feeds, statistics, and fact sheets) into coherent and fluent text.\nBased on this approach, we introduce, for the first time, an AI commentary\nsystem, which was deployed to produce automated narrations for highlight\npackages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same\nvein, our solution was extended to create personalized content for ESPN Fantasy\nFootball and stories about music artists for the Grammy awards. These\napplications were built using a common software architecture achieved a 15x\nspeed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our\nwork was successfully deployed at the aforementioned events, supporting 90\nmillion fans around the world with 8 billion page views, continuously pushing\nthe bounds on what is possible at the intersection of sports, entertainment,\nand AI.",
      "tldr_zh": "这篇论文探讨了利用生成式 AI 模型处理大规模多模态数据（如 videos、articles 和 real-time scoring feeds），以生成连贯的文本内容，包括体育和音乐事件的评论及个性化新闻。研究团队首次引入了一个 AI 评论系统，并成功部署在 2023 US Open、Wimbledon 和 Masters 锦标赛上，同时扩展到 ESPN Fantasy Football 和 Grammy 奖的个性化内容生成。系统采用共同软件架构，实现了 15 倍速度提升，Rouge-L 平均 82.00 和 perplexity 6.6，并在全球支持 90 百万粉丝和 8 亿页面浏览，推动了 AI 在体育娱乐领域的应用边界。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.15514v2",
      "published_date": "2024-01-31 22:47:01 UTC",
      "updated_date": "2024-02-28 00:03:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:24.251793"
    },
    {
      "arxiv_id": "2402.00219v1",
      "title": "FedCore: Straggler-Free Federated Learning with Distributed Coresets",
      "title_zh": "翻译失败",
      "authors": [
        "Hongpeng Guo",
        "Haotian Gu",
        "Xiaoyang Wang",
        "Bo Chen",
        "Eun Kyung Lee",
        "Tamar Eilam",
        "Deming Chen",
        "Klara Nahrstedt"
      ],
      "abstract": "Federated learning (FL) is a machine learning paradigm that allows multiple\nclients to collaboratively train a shared model while keeping their data\non-premise. However, the straggler issue, due to slow clients, often hinders\nthe efficiency and scalability of FL. This paper presents FedCore, an algorithm\nthat innovatively tackles the straggler problem via the decentralized selection\nof coresets, representative subsets of a dataset. Contrary to existing\ncentralized coreset methods, FedCore creates coresets directly on each client\nin a distributed manner, ensuring privacy preservation in FL. FedCore\ntranslates the coreset optimization problem into a more tractable k-medoids\nclustering problem and operates distributedly on each client. Theoretical\nanalysis confirms FedCore's convergence, and practical evaluations demonstrate\nan 8x reduction in FL training time, without compromising model accuracy. Our\nextensive evaluations also show that FedCore generalizes well to existing FL\nframeworks.",
      "tldr_zh": "这篇论文介绍了FedCore，一种针对Federated Learning (FL)中straggler问题（即慢速客户端导致的效率瓶颈）的创新算法。FedCore通过在每个客户端分布式选择coresets（数据集的代表性子集）来实现无straggler训练，避免了传统集中式方法的隐私风险，并将coreset优化问题转化为k-medoids聚类问题以便分布式处理。实验结果显示，FedCore将FL训练时间减少8倍，同时保持模型准确性，并在现有FL框架中表现出良好的泛化性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00219v1",
      "published_date": "2024-01-31 22:40:49 UTC",
      "updated_date": "2024-01-31 22:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:34.793962"
    },
    {
      "arxiv_id": "2402.00163v1",
      "title": "Improving Object Detection Quality in Football Through Super-Resolution Techniques",
      "title_zh": "通过超分辨率技术改善足球中的物体检测质量",
      "authors": [
        "Karolina Seweryn",
        "Gabriel Chęć",
        "Szymon Łukasik",
        "Anna Wróblewska"
      ],
      "abstract": "This study explores the potential of super-resolution techniques in enhancing\nobject detection accuracy in football. Given the sport's fast-paced nature and\nthe critical importance of precise object (e.g. ball, player) tracking for both\nanalysis and broadcasting, super-resolution could offer significant\nimprovements. We investigate how advanced image processing through\nsuper-resolution impacts the accuracy and reliability of object detection\nalgorithms in processing football match footage.\n  Our methodology involved applying state-of-the-art super-resolution\ntechniques to a diverse set of football match videos from SoccerNet, followed\nby object detection using Faster R-CNN. The performance of these algorithms,\nboth with and without super-resolution enhancement, was rigorously evaluated in\nterms of detection accuracy.\n  The results indicate a marked improvement in object detection accuracy when\nsuper-resolution preprocessing is applied. The improvement of object detection\nthrough the integration of super-resolution techniques yields significant\nbenefits, especially for low-resolution scenarios, with a notable 12\\% increase\nin mean Average Precision (mAP) at an IoU (Intersection over Union) range of\n0.50:0.95 for 320x240 size images when increasing the resolution fourfold using\nRLFN. As the dimensions increase, the magnitude of improvement becomes more\nsubdued; however, a discernible improvement in the quality of detection is\nconsistently evident. Additionally, we discuss the implications of these\nfindings for real-time sports analytics, player tracking, and the overall\nviewing experience. The study contributes to the growing field of sports\ntechnology by demonstrating the practical benefits and limitations of\nintegrating super-resolution techniques in football analytics and broadcasting.",
      "tldr_zh": "这篇论文探讨了超分辨率（Super-Resolution）技术如何提升足球视频中物体检测（如球和球员）的准确性和可靠性，针对足球比赛的快速性和低分辨率挑战。研究方法包括将先进的超分辨率技术应用于SoccerNet的多样化视频集，然后使用Faster R-CNN进行物体检测，并比较处理前后性能。结果显示，超分辨率预处理显著提高了检测准确性，例如使用RLFN将320x240分辨率图像提升四倍，mAP（mean Average Precision）在IoU（Intersection over Union）范围0.50:0.95内提高了12%；虽然分辨率增加后改进幅度减小，但检测质量持续提升。该研究突出了超分辨率在实时体育分析、球员追踪和广播体验中的实际益处，并指出了其在足球技术领域的潜在应用和限制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00163v1",
      "published_date": "2024-01-31 20:37:35 UTC",
      "updated_date": "2024-01-31 20:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:48.118298"
    },
    {
      "arxiv_id": "2402.00899v3",
      "title": "Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan Y. Tyukin",
        "Tatiana Tyukina",
        "Daniel van Helden",
        "Zedong Zheng",
        "Evgeny M. Mirkes",
        "Oliver J. Sutton",
        "Qinghua Zhou",
        "Alexander N. Gorban",
        "Penelope Allison"
      ],
      "abstract": "We present a new methodology for handling AI errors by introducing weakly\nsupervised AI error correctors with a priori performance guarantees. These AI\ncorrectors are auxiliary maps whose role is to moderate the decisions of some\npreviously constructed underlying classifier by either approving or rejecting\nits decisions. The rejection of a decision can be used as a signal to suggest\nabstaining from making a decision. A key technical focus of the work is in\nproviding performance guarantees for these new AI correctors through bounds on\nthe probabilities of incorrect decisions. These bounds are distribution\nagnostic and do not rely on assumptions on the data dimension. Our empirical\nexample illustrates how the framework can be applied to improve the performance\nof an image classifier in a challenging real-world task where training data are\nscarce.",
      "tldr_zh": "本研究提出了一种弱监督学习器（Weakly Supervised Learners），用于修正AI错误，并提供可证明的性能保证（Provable Performance Guarantees）。这些辅助映射（auxiliary maps）通过批准或拒绝底层分类器（underlying classifier）的决策来运作，并通过错误决策概率的分布无关边界来确保性能。实证实验表明，该框架在训练数据稀缺的图像分类任务中显著提升了分类器的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T05, 68T37"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00899v3",
      "published_date": "2024-01-31 20:36:13 UTC",
      "updated_date": "2024-02-13 15:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:44:59.179829"
    },
    {
      "arxiv_id": "2402.00138v2",
      "title": "Decomposable Submodular Maximization in Federated Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Akbar Rafiey"
      ],
      "abstract": "Submodular functions, as well as the sub-class of decomposable submodular\nfunctions, and their optimization appear in a wide range of applications in\nmachine learning, recommendation systems, and welfare maximization. However,\noptimization of decomposable submodular functions with millions of component\nfunctions is computationally prohibitive. Furthermore, the component functions\nmay be private (they might represent user preference function, for example) and\ncannot be widely shared. To address these issues, we propose a {\\em federated\noptimization} setting for decomposable submodular optimization. In this\nsetting, clients have their own preference functions, and a weighted sum of\nthese preferences needs to be maximized. We implement the popular {\\em\ncontinuous greedy} algorithm in this setting where clients take parallel small\nlocal steps towards the local solution and then the local changes are\naggregated at a central server. To address the large number of clients, the\naggregation is performed only on a subsampled set. Further, the aggregation is\nperformed only intermittently between stretches of parallel local steps, which\nreduces communication cost significantly. We show that our federated algorithm\nis guaranteed to provide a good approximate solution, even in the presence of\nabove cost-cutting measures. Finally, we show how the federated setting can be\nincorporated in solving fundamental discrete submodular optimization problems\nsuch as Maximum Coverage and Facility Location.",
      "tldr_zh": "该论文针对可分解子模函数（decomposable submodular functions）的优化问题，提出了一种联邦优化（federated optimization）设置，以应对大量组件函数的计算开销和隐私挑战。方法包括在联邦环境中实现连续贪婪算法（continuous greedy algorithm），其中客户端并行执行本地步骤，并通过子采样和间歇性聚合显著降低通信成本，同时保证算法提供良好的近似解。最终，论文展示了该框架如何应用于离散子模优化问题，如 Maximum Coverage 和 Facility Location。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00138v2",
      "published_date": "2024-01-31 19:32:33 UTC",
      "updated_date": "2024-06-03 06:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:45:13.840271"
    },
    {
      "arxiv_id": "2402.00135v1",
      "title": "A Reinforcement Learning Based Controller to Minimize Forces on the Crutches of a Lower-Limb Exoskeleton",
      "title_zh": "翻译失败",
      "authors": [
        "Aydin Emre Utku",
        "Suzan Ece Ada",
        "Muhammet Hatipoglu",
        "Mustafa Derman",
        "Emre Ugur",
        "Evren Samur"
      ],
      "abstract": "Metabolic energy consumption of a powered lower-limb exoskeleton user mainly\ncomes from the upper body effort since the lower body is considered to be\npassive. However, the upper body effort of the users is largely ignored in the\nliterature when designing motion controllers. In this work, we use deep\nreinforcement learning to develop a locomotion controller that minimizes ground\nreaction forces (GRF) on crutches. The rationale for minimizing GRF is to\nreduce the upper body effort of the user. Accordingly, we design a model and a\nlearning framework for a human-exoskeleton system with crutches. We formulate a\nreward function to encourage the forward displacement of a human-exoskeleton\nsystem while satisfying the predetermined constraints of a physical robot. We\nevaluate our new framework using Proximal Policy Optimization, a\nstate-of-the-art deep reinforcement learning (RL) method, on the MuJoCo physics\nsimulator with different hyperparameters and network architectures over\nmultiple trials. We empirically show that our learning model can generate joint\ntorques based on the joint angle, velocities, and the GRF on the feet and\ncrutch tips. The resulting exoskeleton model can directly generate joint\ntorques from states in line with the RL framework. Finally, we empirically show\nthat policy trained using our method can generate a gait with a 35% reduction\nin GRF with respect to the baseline.",
      "tldr_zh": "本文使用 deep reinforcement learning 开发了一个控制器，旨在最小化下肢外骨骼用户拐杖上的地面反作用力 (GRF)，从而减少上身代谢能量消耗。研究设计了一个人类-外骨骼系统的模型和学习框架，并制定奖励函数来促进系统向前位移，同时满足物理机器人的预定约束。利用 Proximal Policy Optimization (PPO) 在 MuJoCo 模拟器上进行训练，结果显示该控制器能生成基于关节角度、速度和 GRF 的关节扭矩，并实现比基线减少 35% 的 GRF。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 5 Figures",
      "pdf_url": "http://arxiv.org/pdf/2402.00135v1",
      "published_date": "2024-01-31 19:20:56 UTC",
      "updated_date": "2024-01-31 19:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:45:24.531607"
    },
    {
      "arxiv_id": "2401.18070v2",
      "title": "Do Language Models Exhibit the Same Cognitive Biases in Problem Solving as Human Learners?",
      "title_zh": "语言模型在问题求解中是否表现出与人类学习者相同的认知偏差？",
      "authors": [
        "Andreas Opedal",
        "Alessandro Stolfo",
        "Haruki Shirakami",
        "Ying Jiao",
        "Ryan Cotterell",
        "Bernhard Schölkopf",
        "Abulhair Saparov",
        "Mrinmaya Sachan"
      ],
      "abstract": "There is increasing interest in employing large language models (LLMs) as\ncognitive models. For such purposes, it is central to understand which\nproperties of human cognition are well-modeled by LLMs, and which are not. In\nthis work, we study the biases of LLMs in relation to those known in children\nwhen solving arithmetic word problems. Surveying the learning science\nliterature, we posit that the problem-solving process can be split into three\ndistinct steps: text comprehension, solution planning and solution execution.\nWe construct tests for each one in order to understand whether current LLMs\ndisplay the same cognitive biases as children in these steps. We generate a\nnovel set of word problems for each of these tests, using a neuro-symbolic\napproach that enables fine-grained control over the problem features. We find\nevidence that LLMs, with and without instruction-tuning, exhibit human-like\nbiases in both the text-comprehension and the solution-planning steps of the\nsolving process, but not in the final step, in which the arithmetic expressions\nare executed to obtain the answer.",
      "tldr_zh": "这篇论文探讨大型语言模型 (LLMs) 在解决算术文字问题时，是否像人类学习者（尤其是儿童）一样表现出认知偏差。研究将问题解决过程分为三个步骤：文本理解 (text comprehension)、解决方案规划 (solution planning) 和解决方案执行 (solution execution)，并使用神经符号方法生成一组新的测试问题，以精细控制问题特征。结果表明，LLMs（无论是否经过指令微调）在文本理解和解决方案规划步骤中显示出与人类相似的偏差，但在执行算术表达式的最终步骤中则没有这种偏差。该研究为评估 LLMs 作为认知模型的适用性提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.18070v2",
      "published_date": "2024-01-31 18:48:20 UTC",
      "updated_date": "2024-06-17 15:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:45:37.532769"
    },
    {
      "arxiv_id": "2401.18045v1",
      "title": "SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition",
      "title_zh": "SpeechComposer：通过提示词组合统一多个语音任务",
      "authors": [
        "Yihan Wu",
        "Soumi Maiti",
        "Yifan Peng",
        "Wangyou Zhang",
        "Chenda Li",
        "Yuyue Wang",
        "Xihua Wang",
        "Shinji Watanabe",
        "Ruihua Song"
      ],
      "abstract": "Recent advancements in language models have significantly enhanced\nperformance in multiple speech-related tasks. Existing speech language models\ntypically utilize task-dependent prompt tokens to unify various speech tasks in\na single model. However, this design omits the intrinsic connections between\ndifferent speech tasks, which can potentially boost the performance of each\ntask. In this work, we propose a novel decoder-only speech language model,\nSpeechComposer, that can unify common speech tasks by composing a fixed set of\nprompt tokens. Built upon four primary tasks -- speech synthesis, speech\nrecognition, speech language modeling, and text language modeling --\nSpeechComposer can easily extend to more speech tasks via compositions of\nwell-designed prompt tokens, like voice conversion and speech enhancement. The\nunification of prompt tokens also makes it possible for knowledge sharing among\ndifferent speech tasks in a more structured manner. Experimental results\ndemonstrate that our proposed SpeechComposer can improve the performance of\nboth primary tasks and composite tasks, showing the effectiveness of the shared\nprompt tokens. Remarkably, the unified decoder-only model achieves a comparable\nand even better performance than the baselines which are expert models designed\nfor single tasks.",
      "tldr_zh": "该研究提出了一种名为SpeechComposer的decoder-only语音语言模型，通过组合固定的一组prompt tokens来统一多个语音任务，解决了现有模型忽略任务间内在联系的问题。模型基于四个主要任务——speech synthesis、speech recognition、speech language modeling和text language modeling——并能轻松扩展到如voice conversion和speech enhancement等复合任务，促进知识共享。实验结果显示，SpeechComposer在主要任务和复合任务上均提升了性能，甚至超过了专为单一任务设计的专家模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.18045v1",
      "published_date": "2024-01-31 18:06:29 UTC",
      "updated_date": "2024-01-31 18:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:45:46.740765"
    },
    {
      "arxiv_id": "2401.18040v2",
      "title": "Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic Motivation Reinforcement Learning Algorithms for Improved Training and Adaptability",
      "title_zh": "翻译失败",
      "authors": [
        "Navin Kamuni",
        "Hardik Shah",
        "Sathishkumar Chintala",
        "Naveen Kunchakuri",
        "Sujatha Alla Old Dominion"
      ],
      "abstract": "End-to-end multi-task dialogue systems are usually designed with separate\nmodules for the dialogue pipeline. Among these, the policy module is essential\nfor deciding what to do in response to user input. This policy is trained by\nreinforcement learning algorithms by taking advantage of an environment in\nwhich an agent receives feedback in the form of a reward signal. The current\ndialogue systems, however, only provide meagre and simplistic rewards.\nInvestigating intrinsic motivation reinforcement learning algorithms is the\ngoal of this study. Through this, the agent can quickly accelerate training and\nimprove its capacity to judge the quality of its actions by teaching it an\ninternal incentive system. In particular, we adapt techniques for random\nnetwork distillation and curiosity-driven reinforcement learning to measure the\nfrequency of state visits and encourage exploration by using semantic\nsimilarity between utterances. Experimental results on MultiWOZ, a\nheterogeneous dataset, show that intrinsic motivation-based debate systems\noutperform policies that depend on extrinsic incentives. By adopting random\nnetwork distillation, for example, which is trained using semantic similarity\nbetween user-system dialogues, an astounding average success rate of 73% is\nachieved. This is a significant improvement over the baseline Proximal Policy\nOptimization (PPO), which has an average success rate of 60%. In addition,\nperformance indicators such as booking rates and completion rates show a 10%\nrise over the baseline. Furthermore, these intrinsic incentive models help\nimprove the system's policy's resilience in an increasing amount of domains.\nThis implies that they could be useful in scaling up to settings that cover a\nwider range of domains.",
      "tldr_zh": "该研究探讨了如何通过内在动机强化学习算法提升端到-end多任务对话系统的训练和适应性，针对传统强化学习中简单奖励信号的局限性。研究者改进了随机网络蒸馏（random network distillation）和好奇心驱动强化学习（curiosity-driven reinforcement learning）技术，使用语义相似性来测量状态访问频率并鼓励探索，从而帮助代理更快学习并评估行动质量。在MultiWOZ数据集上的实验显示，内在动机方法显著优于外在奖励基线，如Proximal Policy Optimization (PPO)，成功率从60%提高到73%，预订率和完成率也提升10%。此外，这些算法增强了系统的领域适应性，有助于扩展到更多对话场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 1 figure, 18th IEEE International Conference on Semantic\n  Computing",
      "pdf_url": "http://arxiv.org/pdf/2401.18040v2",
      "published_date": "2024-01-31 18:03:39 UTC",
      "updated_date": "2024-03-25 23:03:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:45:59.958870"
    },
    {
      "arxiv_id": "2401.18034v2",
      "title": "Paramanu: A Family of Novel Efficient Generative Foundation Language Models for Indian Languages",
      "title_zh": "Paramanu：用于印度语言的新型高效生成式基础语言模型家族",
      "authors": [
        "Mitodru Niyogi",
        "Arnab Bhattacharya"
      ],
      "abstract": "We present \"Paramanu\", a family of novel language models (LM) for Indian\nlanguages, consisting of auto-regressive monolingual, bilingual, and\nmultilingual models pretrained from scratch. Currently, it covers 10 languages\n(Assamese, Bangla, Hindi, Konkani, Maithili, Marathi, Odia, Sanskrit, Tamil,\nTelugu) across 5 scripts (Bangla, Devanagari, Odia, Tamil, Telugu). The models\nare pretrained on a single GPU with context size of 1024 and vary in size from\n13.29 million (M) to 367.5 M parameters. We proposed a RoPE embedding scaling\nmethod that enables us to pretrain language models from scratch at larger\nsequence length context size than typical GPU memory permits. We also\nintroduced a novel efficient Indic tokenizer, \"mBharat\", using a combination of\nBPE and Unigram, achieving the least fertility score and the ability to\ntokenize unseen languages in both the same script & Roman script. We also\nproposed and performed language-specific tokenization for multilingual models &\ndomain-specific tokenization for monolingual models. To address the \"curse of\nmultilinguality\" in our mParamanu model, we pretrained on comparable corpora\nbased on typological grouping within the same script. Our findings show a\nlanguage transfer phenomenon from low-resource to high-resource languages\nwithin languages of the same script & typology. Human evaluations for\nopen-ended text generation demonstrated that Paramanu models outperformed\nseveral LLMs, despite being 20 to 64 times smaller. We created\ninstruction-tuning datasets & instruction-tuned our models on 23,000\ninstructions in respective languages. Comparisons with multilingual LLMs across\nvarious benchmarks for natural language (NL) understanding, NL inference, &\nreading comprehension highlight the advantages of our models; leads to the\nconclusion that high quality generative LM are possible without high amount of\ncompute power & enormous number of parameters.",
      "tldr_zh": "我们介绍了 Paramanu 系列高效生成基础语言模型，针对 10 种印度语言（包括 Assamese, Bangla, Hindi 等）和 5 种脚本（Bangla, Devanagari 等）从零预训练，模型参数从 13.29M 到 367.5M，使用单 GPU 和 1024 上下文大小。创新点包括 RoPE embedding scaling 方法以支持更大序列长度，以及 mBharat 标记器结合 BPE 和 Unigram，实现了高效标记并解决了多语模型的“curse of multilinguality”问题。实验结果显示，Paramanu 模型在自然语言理解、推理和阅读 comprehension 基准上优于其他 LLM，尽管参数少 20 到 64 倍，并观察到低资源语言向高资源语言的转移现象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.18034v2",
      "published_date": "2024-01-31 17:58:10 UTC",
      "updated_date": "2024-10-10 16:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:46:13.539055"
    },
    {
      "arxiv_id": "2402.10930v3",
      "title": "ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters",
      "title_zh": "翻译失败",
      "authors": [
        "Shiwei Liu",
        "Guanchen Tao",
        "Yifei Zou",
        "Derek Chow",
        "Zichen Fan",
        "Kauna Lei",
        "Bangfei Pan",
        "Dennis Sylvester",
        "Gregory Kielian",
        "Mehdi Saligane"
      ],
      "abstract": "The self-attention mechanism distinguishes transformer-based large language\nmodels (LLMs) apart from convolutional and recurrent neural networks. Despite\nthe performance improvement, achieving real-time LLM inference on silicon\nremains challenging due to the extensive use of Softmax in self-attention. In\naddition to the non-linearity, the low arithmetic intensity significantly\nlimits processing parallelism, especially when working with longer contexts. To\naddress this challenge, we propose Constant Softmax (ConSmax), a\nsoftware-hardware co-design that serves as an efficient alternative to Softmax.\nConSmax utilizes differentiable normalization parameters to eliminate the need\nfor maximum searching and denominator summation in Softmax. This approach\nenables extensive parallelization while still executing the essential functions\nof Softmax. Moreover, a scalable ConSmax hardware design with a bitwidth-split\nlook-up table (LUT) can achieve lossless non-linear operations and support\nmixed-precision computing. Experimental results show that ConSmax achieves a\nminuscule power consumption of 0.2mW and an area of 0.0008mm^2 at 1250MHz\nworking frequency in 16nm FinFET technology. For open-source contribution, we\nfurther implement our design with the OpenROAD toolchain under SkyWater's 130nm\nCMOS technology. The corresponding power is 2.69mW and the area is 0.007mm^2.\nConSmax achieves 3.35x power savings and 2.75x area savings in 16nm technology,\nand 3.15x power savings and 4.14x area savings with the open-source EDA\ntoolchain. In the meantime, it also maintains comparable accuracy on the GPT-2\nmodel and the WikiText103 dataset. The project is available at\nhttps://github.com/ReaLLMASIC/ConSmax",
      "tldr_zh": "该论文提出 ConSmax，一种硬件友好的 Softmax 替代方案，使用可学习的参数来优化 Transformer 模型中自注意力机制的计算效率，从而解决非线性运算和低算术强度带来的实时推理挑战。ConSmax 通过可微分归一化参数消除最大值搜索和分母求和，支持广泛的并行化，并设计了可扩展硬件架构，包括 bitwidth-split LUT，以实现无损非线性操作和混合精度计算。实验结果显示，在 16nm FinFET 技术下，ConSmax 实现了 3.35 倍功耗节省和 2.75 倍面积节省，同时在 GPT-2 模型和 WikiText103 数据集上保持可比准确性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10930v3",
      "published_date": "2024-01-31 17:52:52 UTC",
      "updated_date": "2024-11-15 00:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:46:24.286370"
    },
    {
      "arxiv_id": "2401.18028v2",
      "title": "Evaluating the Capabilities of LLMs for Supporting Anticipatory Impact Assessment",
      "title_zh": "评估大型语言模型支持预见性影响评估的能力",
      "authors": [
        "Mowafak Allaham",
        "Nicholas Diakopoulos"
      ],
      "abstract": "Gaining insight into the potential negative impacts of emerging Artificial\nIntelligence (AI) technologies in society is a challenge for implementing\nanticipatory governance approaches. One approach to produce such insight is to\nuse Large Language Models (LLMs) to support and guide experts in the process of\nideating and exploring the range of undesirable consequences of emerging\ntechnologies. However, performance evaluations of LLMs for such tasks are still\nneeded, including examining the general quality of generated impacts but also\nthe range of types of impacts produced and resulting biases. In this paper, we\ndemonstrate the potential for generating high-quality and diverse impacts of AI\nin society by fine-tuning completion models (GPT-3 and Mistral-7B) on a diverse\nsample of articles from news media and comparing those outputs to the impacts\ngenerated by instruction-based (GPT-4 and Mistral-7B-Instruct) models. We\nexamine the generated impacts for coherence, structure, relevance, and\nplausibility and find that the generated impacts using Mistral-7B, a small\nopen-source model fine-tuned on impacts from the news media, tend to be\nqualitatively on par with impacts generated using a more capable and larger\nscale model such as GPT-4. Moreover, we find that impacts produced by\ninstruction-based models had gaps in the production of certain categories of\nimpacts in comparison to fine-tuned models. This research highlights a\npotential bias in the range of impacts generated by state-of-the-art LLMs and\nthe potential of aligning smaller LLMs on news media as a scalable alternative\nto generate high quality and more diverse impacts in support of anticipatory\ngovernance approaches.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在支持预见性影响评估（Anticipatory Impact Assessment）方面的能力，旨在通过LLMs辅助专家识别新兴AI技术的潜在负面影响。研究者微调了完成模型（如GPT-3和Mistral-7B）使用新闻媒体数据，并与指令-based模型（如GPT-4和Mistral-7B-Instruct）进行比较，评估生成的冲击在连贯性、结构、相关性和可信度等方面的表现。结果显示，微调后的Mistral-7B模型生成的冲击质量和多样性与GPT-4相当，甚至在某些类别上更全面，而指令-based模型存在偏见，导致某些冲击类型缺失。该研究突出了使用较小LLM微调新闻媒体作为可扩展替代方案的潜力，以提升预见性治理的效率和全面性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages + research ethics and social impact statement, references,\n  and appendix. Under conference review",
      "pdf_url": "http://arxiv.org/pdf/2401.18028v2",
      "published_date": "2024-01-31 17:43:04 UTC",
      "updated_date": "2024-05-20 23:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:46:36.942424"
    },
    {
      "arxiv_id": "2401.18018v4",
      "title": "On Prompt-Driven Safeguarding for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chujie Zheng",
        "Fan Yin",
        "Hao Zhou",
        "Fandong Meng",
        "Jie Zhou",
        "Kai-Wei Chang",
        "Minlie Huang",
        "Nanyun Peng"
      ],
      "abstract": "Prepending model inputs with safety prompts is a common practice for\nsafeguarding large language models (LLMs) against queries with harmful intents.\nHowever, the underlying working mechanisms of safety prompts have not been\nunraveled yet, restricting the possibility of automatically optimizing them to\nimprove LLM safety. In this work, we investigate how LLMs' behavior (i.e.,\ncomplying with or refusing user queries) is affected by safety prompts from the\nperspective of model representation. We find that in the representation space,\nthe input queries are typically moved by safety prompts in a \"higher-refusal\"\ndirection, in which models become more prone to refusing to provide assistance,\neven when the queries are harmless. On the other hand, LLMs are naturally\ncapable of distinguishing harmful and harmless queries without safety prompts.\nInspired by these findings, we propose a method for safety prompt optimization,\nnamely DRO (Directed Representation Optimization). Treating a safety prompt as\ncontinuous, trainable embeddings, DRO learns to move the queries'\nrepresentations along or opposite the refusal direction, depending on their\nharmfulness. Experiments with eight LLMs on out-of-domain and jailbreak\nbenchmarks demonstrate that DRO remarkably improves the safeguarding\nperformance of human-crafted safety prompts, without compromising the models'\ngeneral performance.",
      "tldr_zh": "这篇论文探讨了使用 safety prompts 来保护 Large Language Models (LLMs) 的机制，发现这些提示会将查询在模型表示空间中推向“更高拒绝”的方向，从而使模型更倾向于拒绝提供帮助，即使查询是无害的。研究者观察到 LLMs 本身能够区分有害和无害查询，并据此提出 Directed Representation Optimization (DRO) 方法，将 safety prompts 视为可训练的嵌入，根据查询的有害性调整其表示方向。实验在八个 LLMs 上进行，证明 DRO 显著提升了 safety prompts 的安全性能，尤其在越界和越狱基准上，同时不影响模型的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.18018v4",
      "published_date": "2024-01-31 17:28:24 UTC",
      "updated_date": "2024-06-03 06:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:46:48.233919"
    },
    {
      "arxiv_id": "2402.09445v2",
      "title": "iMove: Exploring Bio-impedance Sensing for Fitness Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxi Liu",
        "Vitor Fortes Rey",
        "Yu Zhang",
        "Lala Shakti Swarup Ray",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "abstract": "Automatic and precise fitness activity recognition can be beneficial in\naspects from promoting a healthy lifestyle to personalized preventative\nhealthcare. While IMUs are currently the prominent fitness tracking modality,\nthrough iMove, we show bio-impedence can help improve IMU-based fitness\ntracking through sensor fusion and contrastive learning.To evaluate our\nmethods, we conducted an experiment including six upper body fitness activities\nperformed by ten subjects over five days to collect synchronized data from\nbio-impedance across two wrists and IMU on the left wrist.The contrastive\nlearning framework uses the two modalities to train a better IMU-only\nclassification model, where bio-impedance is only required at the training\nphase, by which the average Macro F1 score with the input of a single IMU was\nimproved by 3.22 \\% reaching 84.71 \\% compared to the 81.49 \\% of the IMU\nbaseline model. We have also shown how bio-impedance can improve human activity\nrecognition (HAR) directly through sensor fusion, reaching an average Macro F1\nscore of 89.57 \\% (two modalities required for both training and inference)\neven if Bio-impedance alone has an average macro F1 score of 75.36 \\%, which is\noutperformed by IMU alone. In addition, similar results were obtained in an\nextended study on lower body fitness activity classification, demonstrating the\ngeneralisability of our approach.Our findings underscore the potential of\nsensor fusion and contrastive learning as valuable tools for advancing fitness\nactivity recognition, with bio-impedance playing a pivotal role in augmenting\nthe capabilities of IMU-based systems.",
      "tldr_zh": "本论文提出 iMove 系统，利用生物阻抗 sensing 与 IMU 相结合，通过传感器融合和对比 learning，提升健身活动识别的准确性。研究在十个受试者进行的六种上身健身活动中收集同步数据，发现对比 learning 框架仅在训练阶段使用生物阻抗，即可将 IMU-only 模型的 Macro F1 分数从 81.49% 提高到 84.71%。此外，传感器融合直接整合两种模态，达到 89.57% 的 Macro F1 分数，尽管生物阻抗单独的得分仅为 75.36%。扩展实验证实该方法在下身健身活动分类上同样有效，突显了传感器融合和对比 learning 在推进 IMU-based 系统方面的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by percom2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09445v2",
      "published_date": "2024-01-31 16:53:50 UTC",
      "updated_date": "2024-06-03 12:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:47:01.759358"
    },
    {
      "arxiv_id": "2401.17985v2",
      "title": "Individual mapping of large polymorphic shrubs in high mountains using satellite images and deep learning",
      "title_zh": "利用卫星图像和深度",
      "authors": [
        "Rohaifa Khaldi",
        "Siham Tabik",
        "Sergio Puertas-Ruiz",
        "Julio Peñas de Giles",
        "José Antonio Hódar Correa",
        "Regino Zamora",
        "Domingo Alcaraz Segura"
      ],
      "abstract": "Monitoring the distribution and size of long-living large shrubs, such as\njunipers, is crucial for assessing the long-term impacts of global change on\nhigh-mountain ecosystems. While deep learning models have shown remarkable\nsuccess in object segmentation, adapting these models to detect shrub species\nwith polymorphic nature remains challenging. In this research, we release a\nlarge dataset of individual shrub delineations on freely available satellite\nimagery and use an instance segmentation model to map all junipers over the\ntreeline for an entire biosphere reserve (Sierra Nevada, Spain). To optimize\nperformance, we introduced a novel dual data construction approach: using\nphoto-interpreted (PI) data for model development and fieldwork (FW) data for\nvalidation. To account for the polymorphic nature of junipers during model\nevaluation, we developed a soft version of the Intersection over Union metric.\nFinally, we assessed the uncertainty of the resulting map in terms of canopy\ncover and density of shrubs per size class. Our model achieved an F1-score in\nshrub delineation of 87.87% on the PI data and 76.86% on the FW data. The R2\nand RMSE of the observed versus predicted relationship were 0.63 and 6.67% for\ncanopy cover, and 0.90 and 20.62 for shrub density. The greater density of\nlarger shrubs in lower altitudes and smaller shrubs in higher altitudes\nobserved in the model outputs was also present in the PI and FW data,\nsuggesting an altitudinal uplift in the optimal performance of the species.\nThis study demonstrates that deep learning applied on freely available\nhigh-resolution satellite imagery is useful to detect medium to large shrubs of\nhigh ecological value at the regional scale, which could be expanded to other\nhigh-mountains worldwide and to historical and forthcoming imagery.",
      "tldr_zh": "本研究利用卫星图像和deep learning技术，发布了一个大型数据集，并开发了实例分割模型来映射西班牙Sierra Nevada生物圈保护区以上多态性灌木（如杜松）的个体分布，以评估全球变化对高山生态系统的影响。研究引入了双重数据构建方法，使用photo-interpreted (PI) 数据开发模型和fieldwork (FW) 数据验证，并开发了软版本的Intersection over Union (IoU) 指标来处理灌木的多态性。模型在PI数据上达到87.87%的F1分数，在FW数据上达到76.86%，并准确预测了冠层覆盖（R2=0.63）和灌木密度（R2=0.90）的变化模式，如较大灌木在较低海拔和较小灌木在较高海拔的分布。这证明了deep learning在区域规模监测高生态价值灌木的潜力，可扩展到全球其他高山和历史/未来图像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17985v2",
      "published_date": "2024-01-31 16:44:20 UTC",
      "updated_date": "2024-10-01 08:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:47:19.344458"
    },
    {
      "arxiv_id": "2401.17981v3",
      "title": "From Training-Free to Adaptive: Empirical Insights into MLLMs' Understanding of Detection Information",
      "title_zh": "翻译失败",
      "authors": [
        "Qirui Jiao",
        "Daoyuan Chen",
        "Yilun Huang",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "Despite the impressive capabilities of Multimodal Large Language Models\n(MLLMs) in integrating text and image modalities, challenges remain in\naccurately interpreting detailed visual elements. Vision detection models excel\nat recognizing fine-grained image details, prompting researchers to use them to\nenhance MLLMs. One effective strategy is to infuse detection information in\ntext format, which has proven simple and effective. However, most studies\nutilize this method without training, leaving the potential of adaptive\ntraining largely unexplored. Adaptive training could significantly enhance\nMLLMs' comprehension of unique inputs while filtering out irrelevant\ninformation. This paper addresses the crucial question: How does training\nimpact MLLMs' understanding of infused textual detection information? We\nsystematically experiment with various representative models to evaluate the\neffects of training-free, retraining, and fine-tuning strategies. We also\nexamine the influence of training on MLLMs' original abilities and the\ninterchangeability of detection models. Our findings indicate that fine-tuning\na pre-trained MLLM to incorporate textual detection information delivers\nsuperior results compared to training-free and retraining methods, improving\nperformance by 6.71% across 10 widely recognized benchmarks. Furthermore,\nfine-tuning enables MLLMs to retain performance enhancements even when\ndetection models are swapped, indicating improved understanding of formatted\ntextual data. We release our codes to support further exploration of fusion\nstrategies for vision detection models and the enhancement of MLLMs'\nfine-grained multimodal capabilities.",
      "tldr_zh": "本研究探讨了多模态大语言模型（MLLMs）在理解注入文本格式的视觉检测信息时的表现，针对其在解释细粒度视觉元素方面的挑战。研究者通过实验比较了training-free、retraining和fine-tuning策略，结果显示fine-tuning方法在10个基准测试中提升了6.71%的性能，并使MLLMs在检测模型互换时保持增强效果。总体而言，该工作提供了实证洞见，证明了自适应训练能提升MLLMs的细粒度多模态能力，并公开了代码以支持进一步的融合策略探索。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 22 tables, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17981v3",
      "published_date": "2024-01-31 16:38:32 UTC",
      "updated_date": "2024-12-19 11:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:47:26.386769"
    },
    {
      "arxiv_id": "2401.17976v2",
      "title": "Circuit Partitioning for Multi-Core Quantum Architectures with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Arnau Pastor",
        "Pau Escofet",
        "Sahar Ben Rached",
        "Eduard Alarcón",
        "Pere Barlet-Ros",
        "Sergi Abadal"
      ],
      "abstract": "Quantum computing holds immense potential for solving classically intractable\nproblems by leveraging the unique properties of quantum mechanics. The\nscalability of quantum architectures remains a significant challenge.\nMulti-core quantum architectures are proposed to solve the scalability problem,\narising a new set of challenges in hardware, communications and compilation,\namong others. One of these challenges is to adapt a quantum algorithm to fit\nwithin the different cores of the quantum computer. This paper presents a novel\napproach for circuit partitioning using Deep Reinforcement Learning,\ncontributing to the advancement of both quantum computing and graph\npartitioning. This work is the first step in integrating Deep Reinforcement\nLearning techniques into Quantum Circuit Mapping, opening the door to a new\nparadigm of solutions to such problems.",
      "tldr_zh": "本文提出一种利用 Deep Reinforcement Learning 的新型方法，用于多核量子架构的电路分区，以解决量子计算可扩展性面临的挑战。该方法通过深度强化学习技术适应量子算法，使其适合不同量子核心的分配，这是首次将 Deep Reinforcement Learning 整合到 Quantum Circuit Mapping 中。该创新为量子计算和图分区领域开辟了新范式，推动了相关问题的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17976v2",
      "published_date": "2024-01-31 16:33:12 UTC",
      "updated_date": "2024-07-24 06:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:47:38.169459"
    },
    {
      "arxiv_id": "2401.17975v1",
      "title": "Understanding polysemanticity in neural networks through coding theory",
      "title_zh": "通过编码理论理解神经网络中的多义性",
      "authors": [
        "Simon C. Marshall",
        "Jan H. Kirchner"
      ],
      "abstract": "Despite substantial efforts, neural network interpretability remains an\nelusive goal, with previous research failing to provide succinct explanations\nof most single neurons' impact on the network output. This limitation is due to\nthe polysemantic nature of most neurons, whereby a given neuron is involved in\nmultiple unrelated network states, complicating the interpretation of that\nneuron. In this paper, we apply tools developed in neuroscience and information\ntheory to propose both a novel practical approach to network interpretability\nand theoretical insights into polysemanticity and the density of codes. We\ninfer levels of redundancy in the network's code by inspecting the\neigenspectrum of the activation's covariance matrix. Furthermore, we show how\nrandom projections can reveal whether a network exhibits a smooth or\nnon-differentiable code and hence how interpretable the code is. This same\nframework explains the advantages of polysemantic neurons to learning\nperformance and explains trends found in recent results by Elhage et\nal.~(2022). Our approach advances the pursuit of interpretability in neural\nnetworks, providing insights into their underlying structure and suggesting new\navenues for circuit-level interpretability.",
      "tldr_zh": "该论文探讨了神经网络中神经元的 polysemanticity（多义性）问题，即单个神经元参与多个不相关网络状态，导致可解释性挑战。作者引入神经科学和信息理论工具，包括分析激活协方差矩阵的 eigenspectrum 来评估网络代码的冗余度，以及使用 random projections 判断代码是否平滑，从而提升网络可解释性。研究揭示了 polysemantic 神经元对学习性能的优势，并解释了 Elhage et al. (2022) 的相关趋势，为神经网络的电路级 interpretability 提供了新理论洞见和实用途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17975v1",
      "published_date": "2024-01-31 16:31:54 UTC",
      "updated_date": "2024-01-31 16:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:47:52.132684"
    },
    {
      "arxiv_id": "2401.17972v1",
      "title": "MelNet: A Real-Time Deep Learning Algorithm for Object Detection",
      "title_zh": "MelNet：一种用于物体检测的实时深度",
      "authors": [
        "Yashar Azadvatan",
        "Murat Kurt"
      ],
      "abstract": "In this study, a novel deep learning algorithm for object detection, named\nMelNet, was introduced. MelNet underwent training utilizing the KITTI dataset\nfor object detection. Following 300 training epochs, MelNet attained an mAP\n(mean average precision) score of 0.732. Additionally, three alternative models\n-YOLOv5, EfficientDet, and Faster-RCNN-MobileNetv3- were trained on the KITTI\ndataset and juxtaposed with MelNet for object detection.\n  The outcomes underscore the efficacy of employing transfer learning in\ncertain instances. Notably, preexisting models trained on prominent datasets\n(e.g., ImageNet, COCO, and Pascal VOC) yield superior results. Another finding\nunderscores the viability of creating a new model tailored to a specific\nscenario and training it on a specific dataset. This investigation demonstrates\nthat training MelNet exclusively on the KITTI dataset also surpasses\nEfficientDet after 150 epochs. Consequently, post-training, MelNet's\nperformance closely aligns with that of other pre-trained models.",
      "tldr_zh": "这篇论文提出了一种名为 MelNet 的实时深度学习物体检测算法，并使用 KITTI 数据集进行训练，经过 300 个 epoch 后，MelNet 达到了 mAP 0.732 的性能。\nMelNet 与其他模型如 YOLOv5、EfficientDet 和 Faster-RCNN-MobileNetv3 在相同数据集上进行了比较，结果显示基于 ImageNet、COCO 和 Pascal VOC 等大型数据集的预训练模型在转移学习中表现出色。\n此外，研究发现，针对特定场景自定义模型并在特定数据集上训练（如 MelNet 在 KITTI 上训练）也非常可行，其性能在 150 个 epoch 后超过了 EfficientDet，并最终接近其他预训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17972v1",
      "published_date": "2024-01-31 16:27:47 UTC",
      "updated_date": "2024-01-31 16:27:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:48:03.900824"
    },
    {
      "arxiv_id": "2402.09444v3",
      "title": "Multimodal Action Quality Assessment",
      "title_zh": "多模态动作质量评估",
      "authors": [
        "Ling-An Zeng",
        "Wei-Shi Zheng"
      ],
      "abstract": "Action quality assessment (AQA) is to assess how well an action is performed.\nPrevious works perform modelling by only the use of visual information,\nignoring audio information. We argue that although AQA is highly dependent on\nvisual information, the audio is useful complementary information for improving\nthe score regression accuracy, especially for sports with background music,\nsuch as figure skating and rhythmic gymnastics. To leverage multimodal\ninformation for AQA, i.e., RGB, optical flow and audio information, we propose\na Progressive Adaptive Multimodal Fusion Network (PAMFN) that separately models\nmodality-specific information and mixed-modality information. Our model\nconsists of with three modality-specific branches that independently explore\nmodality-specific information and a mixed-modality branch that progressively\naggregates the modality-specific information from the modality-specific\nbranches. To build the bridge between modality-specific branches and the\nmixed-modality branch, three novel modules are proposed. First, a\nModality-specific Feature Decoder module is designed to selectively transfer\nmodality-specific information to the mixed-modality branch. Second, when\nexploring the interaction between modality-specific information, we argue that\nusing an invariant multimodal fusion policy may lead to suboptimal results, so\nas to take the potential diversity in different parts of an action into\nconsideration. Therefore, an Adaptive Fusion Module is proposed to learn\nadaptive multimodal fusion policies in different parts of an action. This\nmodule consists of several FusionNets for exploring different multimodal fusion\nstrategies and a PolicyNet for deciding which FusionNets are enabled. Third, a\nmodule called Cross-modal Feature Decoder is designed to transfer cross-modal\nfeatures generated by Adaptive Fusion Module to the mixed-modality branch.",
      "tldr_zh": "该论文探讨了动作质量评估(AQA)，强调传统方法仅依赖视觉信息（如RGB和optical flow）而忽略音频信息，尤其是对有背景音乐的体育项目（如花样滑冰）。为了整合多模态信息，作者提出Progressive Adaptive Multimodal Fusion Network (PAMFN)，该模型包括三个模态特定分支（处理各自模态信息）和一个混合模态分支，通过逐步聚合信息提升分数回归准确性。关键创新包括Modality-specific Feature Decoder（选择性传输模态特定信息）、Adaptive Fusion Module（学习适应不同动作部分的multimodal fusion策略，使用多个FusionNets和PolicyNet）和Cross-modal Feature Decoder（传输跨模态特征），从而实现更精确的AQA。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "I.2.10"
      ],
      "primary_category": "eess.SP",
      "comment": "IEEE Transactions on Image Processing 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09444v3",
      "published_date": "2024-01-31 15:37:12 UTC",
      "updated_date": "2025-03-05 14:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:48:15.849677"
    },
    {
      "arxiv_id": "2401.17914v1",
      "title": "Attention Graph for Multi-Robot Social Navigation with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Erwan Escudie",
        "Laetitia Matignon",
        "Jacques Saraydaryan"
      ],
      "abstract": "Learning robot navigation strategies among pedestrian is crucial for domain\nbased applications. Combining perception, planning and prediction allows us to\nmodel the interactions between robots and pedestrians, resulting in impressive\noutcomes especially with recent approaches based on deep reinforcement learning\n(RL). However, these works do not consider multi-robot scenarios. In this\npaper, we present MultiSoc, a new method for learning multi-agent socially\naware navigation strategies using RL. Inspired by recent works on multi-agent\ndeep RL, our method leverages graph-based representation of agent interactions,\ncombining the positions and fields of view of entities (pedestrians and\nagents). Each agent uses a model based on two Graph Neural Network combined\nwith attention mechanisms. First an edge-selector produces a sparse graph, then\na crowd coordinator applies node attention to produce a graph representing the\ninfluence of each entity on the others. This is incorporated into a model-free\nRL framework to learn multi-agent policies. We evaluate our approach on\nsimulation and provide a series of experiments in a set of various conditions\n(number of agents / pedestrians). Empirical results show that our method learns\nfaster than social navigation deep RL mono-agent techniques, and enables\nefficient multi-agent implicit coordination in challenging crowd navigation\nwith multiple heterogeneous humans. Furthermore, by incorporating customizable\nmeta-parameters, we can adjust the neighborhood density to take into account in\nour navigation strategy.",
      "tldr_zh": "这篇论文提出了 MultiSoc 方法，使用 Deep Reinforcement Learning 学习多机器人社会导航策略，专注于机器人与行人之间的交互建模。方法基于图表示，结合 Graph Neural Network 和注意力机制：首先通过 edge-selector 生成稀疏图，然后 crowd coordinator 应用节点注意力来表示实体间的相互影响，并整合到无模型 RL 框架中学习多代理策略。实验结果显示，MultiSoc 比单代理深度 RL 技术学习更快，并在模拟环境中实现高效的多代理隐式协调，尤其适用于多种条件下的拥挤场景，并允许通过自定义元参数调整邻域密度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17914v1",
      "published_date": "2024-01-31 15:24:13 UTC",
      "updated_date": "2024-01-31 15:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:48:27.454363"
    },
    {
      "arxiv_id": "2401.17895v1",
      "title": "ReplaceAnything3D:Text-Guided 3D Scene Editing with Compositional Neural Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Bartrum",
        "Thu Nguyen-Phuoc",
        "Chris Xie",
        "Zhengqin Li",
        "Numair Khan",
        "Armen Avetisyan",
        "Douglas Lanman",
        "Lei Xiao"
      ],
      "abstract": "We introduce ReplaceAnything3D model (RAM3D), a novel text-guided 3D scene\nediting method that enables the replacement of specific objects within a scene.\nGiven multi-view images of a scene, a text prompt describing the object to\nreplace, and a text prompt describing the new object, our Erase-and-Replace\napproach can effectively swap objects in the scene with newly generated content\nwhile maintaining 3D consistency across multiple viewpoints. We demonstrate the\nversatility of ReplaceAnything3D by applying it to various realistic 3D scenes,\nshowcasing results of modified foreground objects that are well-integrated with\nthe rest of the scene without affecting its overall integrity.",
      "tldr_zh": "本研究引入了ReplaceAnything3D模型（RAM3D），一种基于文本引导的3D场景编辑方法，利用Compositional Neural Radiance Fields技术来替换场景中的特定对象。用户只需提供多视图图像、描述要替换对象的文本提示以及新对象的文本提示，该方法便采用Erase-and-Replace策略，实现对象的有效交换，同时确保多视图下的3D一致性。实验结果展示了ReplaceAnything3D在各种真实3D场景中的应用能力，修改后的前景对象与场景其他部分无缝整合，而不影响整体完整性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "For our project page, see https://replaceanything3d.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2401.17895v1",
      "published_date": "2024-01-31 15:02:26 UTC",
      "updated_date": "2024-01-31 15:02:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:48:39.444115"
    },
    {
      "arxiv_id": "2402.01766v3",
      "title": "LLM Voting: Human Choices and AI Collective Decision Making",
      "title_zh": "LLM 投票：人类选择与 AI 集体决策系统",
      "authors": [
        "Joshua C. Yang",
        "Damian Dailisan",
        "Marcin Korecki",
        "Carina I. Hausladen",
        "Dirk Helbing"
      ],
      "abstract": "This paper investigates the voting behaviors of Large Language Models (LLMs),\nspecifically GPT-4 and LLaMA-2, their biases, and how they align with human\nvoting patterns. Our methodology involved using a dataset from a human voting\nexperiment to establish a baseline for human preferences and conducting a\ncorresponding experiment with LLM agents. We observed that the choice of voting\nmethods and the presentation order influenced LLM voting outcomes. We found\nthat varying the persona can reduce some of these biases and enhance alignment\nwith human choices. While the Chain-of-Thought approach did not improve\nprediction accuracy, it has potential for AI explainability in the voting\nprocess. We also identified a trade-off between preference diversity and\nalignment accuracy in LLMs, influenced by different temperature settings. Our\nfindings indicate that LLMs may lead to less diverse collective outcomes and\nbiased assumptions when used in voting scenarios, emphasizing the need for\ncautious integration of LLMs into democratic processes.",
      "tldr_zh": "这篇论文研究了大型语言模型 (LLMs) 如 GPT-4 和 LLaMA-2 的投票行为、偏见及其与人类投票模式的对齐度。作者采用人类投票实验数据集作为基准，并进行相应的 LLM 代理实验，探讨了投票方法、呈现顺序和 persona 变化对结果的影响，发现这些因素能减少偏见并提升对人类选择的契合度。实验结果显示，Chain-of-Thought 方法虽未改善预测准确性，但有助于 AI 在投票过程中的可解释性，同时LLMs 在温度设置下存在偏好多样性和对齐准确性之间的权衡，可能导致集体决策缺乏多样性和潜在偏见，因此需谨慎应用于民主进程。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "econ.GN",
        "q-fin.EC",
        "68T05, 91B14, 91C20",
        "I.2.7; J.4; K.4.1"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in AAAI Conference on AI, Ethics, and Society (AIES)",
      "pdf_url": "http://arxiv.org/pdf/2402.01766v3",
      "published_date": "2024-01-31 14:52:02 UTC",
      "updated_date": "2024-08-14 13:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:48:52.677946"
    },
    {
      "arxiv_id": "2402.00094v1",
      "title": "Deep Neural Networks: A Formulation Via Non-Archimedean Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "W. A. Zúñiga-Galindo"
      ],
      "abstract": "We introduce a new class of deep neural networks (DNNs) with multilayered\ntree-like architectures. The architectures are codified using numbers from the\nring of integers of non-Archimdean local fields. These rings have a natural\nhierarchical organization as infinite rooted trees. Natural morphisms on these\nrings allow us to construct finite multilayered architectures. The new DNNs are\nrobust universal approximators of real-valued functions defined on the\nmentioned rings. We also show that the DNNs are robust universal approximators\nof real-valued square-integrable functions defined in the unit interval.",
      "tldr_zh": "该研究提出了一种新的深度神经网络 (DNNs) 类，利用非-Archimedean local fields 的整数环来构建多层树状架构，这些环具有自然的无限根树层次化组织。作者通过这些环上的自然态射，创建了有限的多层架构，使 DNNs 成为这些环上定义的实值函数的鲁棒通用逼近器。此外，实验表明，这些 DNNs 也能鲁棒地逼近单位区间上定义的实值平方可积函数，从而扩展了神经网络的适用性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "Primary 68T07, 65D15, Secondary 41A30, 11S85"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00094v1",
      "published_date": "2024-01-31 14:49:44 UTC",
      "updated_date": "2024-01-31 14:49:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:49:02.409074"
    },
    {
      "arxiv_id": "2401.17870v2",
      "title": "Efficient Subseasonal Weather Forecast using Teleconnection-informed Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Zhao",
        "Zhitong Xiong",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Subseasonal forecasting, which is pivotal for agriculture, water resource\nmanagement, and early warning of disasters, faces challenges due to the chaotic\nnature of the atmosphere. Recent advances in machine learning (ML) have\nrevolutionized weather forecasting by achieving competitive predictive skills\nto numerical models. However, training such foundation models requires\nthousands of GPU days, which causes substantial carbon emissions and limits\ntheir broader applicability. Moreover, ML models tend to fool the pixel-wise\nerror scores by producing smoothed results which lack physical consistency and\nmeteorological meaning. To deal with the aforementioned problems, we propose a\nteleconnection-informed transformer. Our architecture leverages the pretrained\nPangu model to achieve good initial weights and integrates a\nteleconnection-informed temporal module to improve predictability in an\nextended temporal range. Remarkably, by adjusting 1.1% of the Pangu model's\nparameters, our method enhances predictability on four surface and five\nupper-level atmospheric variables at a two-week lead time. Furthermore, the\nteleconnection-filtered features improve the spatial granularity of outputs\nsignificantly, indicating their potential physical consistency. Our research\nunderscores the importance of atmospheric and oceanic teleconnections in\ndriving future weather conditions. Besides, it presents a resource-efficient\npathway for researchers to leverage existing foundation models on versatile\ndownstream tasks.",
      "tldr_zh": "本研究针对亚季节天气预报的挑战（如大气混沌性、机器学习（ML）模型的高训练成本和物理一致性问题），提出了一种高效的teleconnection-informed transformer框架。该框架基于预训练的Pangu模型，通过调整其1.1%的参数并集成teleconnection-informed temporal module，显著提升了预测准确性。在两周预测期内，该方法改善了四个地表和五个高层大气变量的预测性能，并增强了输出空间粒度以实现潜在物理一致性。该方法强调了大气和海洋teleconnections在天气驱动中的重要性，并为资源高效地利用现有基础模型应用于下游任务提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to IGARSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17870v2",
      "published_date": "2024-01-31 14:27:35 UTC",
      "updated_date": "2024-02-05 12:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:49:15.812812"
    },
    {
      "arxiv_id": "2401.17866v1",
      "title": "Making Sense of Knowledge Intensive Processes: an Oil & Gas Industry Scenario",
      "title_zh": "翻译失败",
      "authors": [
        "Juliana Jansen Ferreira",
        "Vinícius Segura",
        "Ana Fucs",
        "Rogério de Paula"
      ],
      "abstract": "Sensemaking is a constant and ongoing process by which people associate\nmeaning to experiences. It can be an individual process, known as abduction, or\na group process by which people give meaning to collective experiences. The\nsensemaking of a group is influenced by the abduction process of each person\nabout the experience. Every collaborative process needs some level of\nsensemaking to show results. For a knowledge intensive process, sensemaking is\ncentral and related to most of its tasks. We present findings from a fieldwork\nexecuted in knowledge intensive process from the Oil and Gas industry. Our\nfindings indicated that different types of knowledge can be combined to compose\nthe result of a sensemaking process (e.g. decision, the need for more\ndiscussion, etc.). This paper presents an initial set of knowledge types that\ncan be combined to compose the result of the sensemaking of a collaborative\ndecision making process. We also discuss ideas for using systems powered by\nArtificial Intelligence to support sensemaking processes.",
      "tldr_zh": "这篇论文探讨了 sensemaking（意义构建）在知识密集型过程中的核心作用，特别是以石油和天然气行业为例，强调它是个人（abduction）或群体过程，用于赋予集体经验以意义。通过实地调查，研究发现不同类型的知识可以结合组成 sensemaking 的结果，如决策或进一步讨论，并提出了一个初始知识类型集合作为协作决策过程的框架。论文还讨论了使用人工智能驱动系统来支持 sensemaking 的潜在想法，以提升知识密集型过程的效率。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages. This paper was presented at the Sensemaking in a Senseless\n  World workshop during the 2018 ACM CHI Conference on Human Factors in\n  Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2401.17866v1",
      "published_date": "2024-01-31 14:25:05 UTC",
      "updated_date": "2024-01-31 14:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:49:27.522063"
    },
    {
      "arxiv_id": "2401.17865v1",
      "title": "Manipulating Predictions over Discrete Inputs in Machine Teaching",
      "title_zh": "在机器教学中操纵离散输入的预测",
      "authors": [
        "Xiaodong Wu",
        "Yufei Han",
        "Hayssam Dahrouj",
        "Jianbing Ni",
        "Zhenwen Liang",
        "Xiangliang Zhang"
      ],
      "abstract": "Machine teaching often involves the creation of an optimal (typically\nminimal) dataset to help a model (referred to as the `student') achieve\nspecific goals given by a teacher. While abundant in the continuous domain, the\nstudies on the effectiveness of machine teaching in the discrete domain are\nrelatively limited. This paper focuses on machine teaching in the discrete\ndomain, specifically on manipulating student models' predictions based on the\ngoals of teachers via changing the training data efficiently. We formulate this\ntask as a combinatorial optimization problem and solve it by proposing an\niterative searching algorithm. Our algorithm demonstrates significant numerical\nmerit in the scenarios where a teacher attempts at correcting erroneous\npredictions to improve the student's models, or maliciously manipulating the\nmodel to misclassify some specific samples to the target class aligned with his\npersonal profits. Experimental results show that our proposed algorithm can\nhave superior performance in effectively and efficiently manipulating the\npredictions of the model, surpassing conventional baselines.",
      "tldr_zh": "这篇论文探讨了机器教学（machine teaching）在离散域（discrete domain）中的应用，焦点是通过高效修改训练数据来操纵学生模型的预测，以实现教师的目标。作者将这一任务表述为一个组合优化问题（combinatorial optimization problem），并提出了一种迭代搜索算法（iterative searching algorithm）来解决相关场景，如纠正错误预测或恶意操纵模型对特定样本的分类。实验结果显示，该算法在有效性和效率上均优于传统基线，为离散域的机器教学提供了新的方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17865v1",
      "published_date": "2024-01-31 14:23:51 UTC",
      "updated_date": "2024-01-31 14:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:49:39.048209"
    },
    {
      "arxiv_id": "2402.03366v1",
      "title": "Uncertainty-Aware Explainable Recommendation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yicui Peng",
        "Hao Chen",
        "Chingsheng Lin",
        "Guo Huang",
        "Jinrong Hu",
        "Hui Guo",
        "Bin Kong",
        "Shu Hu",
        "Xi Wu",
        "Xin Wang"
      ],
      "abstract": "Providing explanations within the recommendation system would boost user\nsatisfaction and foster trust, especially by elaborating on the reasons for\nselecting recommended items tailored to the user. The predominant approach in\nthis domain revolves around generating text-based explanations, with a notable\nemphasis on applying large language models (LLMs). However, refining LLMs for\nexplainable recommendations proves impractical due to time constraints and\ncomputing resource limitations. As an alternative, the current approach\ninvolves training the prompt rather than the LLM. In this study, we developed a\nmodel that utilizes the ID vectors of user and item inputs as prompts for\nGPT-2. We employed a joint training mechanism within a multi-task learning\nframework to optimize both the recommendation task and explanation task. This\nstrategy enables a more effective exploration of users' interests, improving\nrecommendation effectiveness and user satisfaction. Through the experiments,\nour method achieving 1.59 DIV, 0.57 USR and 0.41 FCR on the Yelp, TripAdvisor\nand Amazon dataset respectively, demonstrates superior performance over four\nSOTA methods in terms of explainability evaluation metric. In addition, we\nidentified that the proposed model is able to ensure stable textual quality on\nthe three public datasets.",
      "tldr_zh": "本研究提出了一种不确定性感知的可解释推荐系统，利用大型语言模型 (LLMs) 生成针对用户的文本解释，但通过使用用户和物品 ID 向量作为提示输入到 GPT-2，并采用多任务学习框架联合优化推荐任务和解释任务，从而避免直接微调 LLMs 的资源消耗。该方法更有效地探索用户兴趣，提升了推荐准确性和用户满意度。在 Yelp、TripAdvisor 和 Amazon 数据集上的实验中，该模型在解释性指标（如 DIV 1.59、USR 0.57 和 FCR 0.41）上超过了四种最先进方法，并确保了文本质量的稳定表现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03366v1",
      "published_date": "2024-01-31 14:06:26 UTC",
      "updated_date": "2024-01-31 14:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:49:53.138932"
    },
    {
      "arxiv_id": "2401.17842v2",
      "title": "Explainable Benchmarking for Iterative Optimization Heuristics",
      "title_zh": "用于迭代优化启发式算法的可解释基准",
      "authors": [
        "Niki van Stein",
        "Diederick Vermetten",
        "Anna V. Kononova",
        "Thomas Bäck"
      ],
      "abstract": "Benchmarking heuristic algorithms is vital to understand under which\nconditions and on what kind of problems certain algorithms perform well. In\nmost current research into heuristic optimization algorithms, only a very\nlimited number of scenarios, algorithm configurations and hyper-parameter\nsettings are explored, leading to incomplete and often biased insights and\nresults. This paper presents a novel approach we call explainable benchmarking.\nIntroducing the IOH-Xplainer software framework, for analyzing and\nunderstanding the performance of various optimization algorithms and the impact\nof their different components and hyper-parameters. We showcase the framework\nin the context of two modular optimization frameworks. Through this framework,\nwe examine the impact of different algorithmic components and configurations,\noffering insights into their performance across diverse scenarios. We provide a\nsystematic method for evaluating and interpreting the behaviour and efficiency\nof iterative optimization heuristics in a more transparent and comprehensible\nmanner, allowing for better benchmarking and algorithm design.",
      "tldr_zh": "本论文针对迭代优化启发式算法（iterative optimization heuristics）的基准测试问题，提出了一种名为 explainable benchmarking 的新方法，以解决当前研究中场景和配置有限导致的偏差问题。研究团队开发了 IOH-Xplainer 软件框架，用于分析算法组件、超参数及其在不同场景下的性能影响，并通过两个模块化优化框架进行展示。该方法提供了一个系统化的评估和解释工具，提升了算法行为的透明度和效率，从而促进更好的算法设计和基准测试。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Submitted to ACM TELO",
      "pdf_url": "http://arxiv.org/pdf/2401.17842v2",
      "published_date": "2024-01-31 14:02:26 UTC",
      "updated_date": "2024-02-23 09:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:50:03.042084"
    },
    {
      "arxiv_id": "2401.17839v1",
      "title": "Global-Liar: Factuality of LLMs over Time and Geographic Regions",
      "title_zh": "Global-L",
      "authors": [
        "Shujaat Mirza",
        "Bruno Coelho",
        "Yuyuan Cui",
        "Christina Pöpper",
        "Damon McCoy"
      ],
      "abstract": "The increasing reliance on AI-driven solutions, particularly Large Language\nModels (LLMs) like the GPT series, for information retrieval highlights the\ncritical need for their factuality and fairness, especially amidst the rampant\nspread of misinformation and disinformation online. Our study evaluates the\nfactual accuracy, stability, and biases in widely adopted GPT models, including\nGPT-3.5 and GPT-4, contributing to reliability and integrity of AI-mediated\ninformation dissemination.\n  We introduce 'Global-Liar,' a dataset uniquely balanced in terms of\ngeographic and temporal representation, facilitating a more nuanced evaluation\nof LLM biases. Our analysis reveals that newer iterations of GPT models do not\nalways equate to improved performance. Notably, the GPT-4 version from March\ndemonstrates higher factual accuracy than its subsequent June release.\nFurthermore, a concerning bias is observed, privileging statements from the\nGlobal North over the Global South, thus potentially exacerbating existing\ninformational inequities. Regions such as Africa and the Middle East are at a\ndisadvantage, with much lower factual accuracy. The performance fluctuations\nover time suggest that model updates may not consistently benefit all regions\nequally.\n  Our study also offers insights into the impact of various LLM configuration\nsettings, such as binary decision forcing, model re-runs and temperature, on\nmodel's factuality. Models constrained to binary (true/false) choices exhibit\nreduced factuality compared to those allowing an 'unclear' option. Single\ninference at a low temperature setting matches the reliability of majority\nvoting across various configurations. The insights gained highlight the need\nfor culturally diverse and geographically inclusive model training and\nevaluation. This approach is key to achieving global equity in technology,\ndistributing AI benefits fairly worldwide.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）如 GPT-3.5 和 GPT-4 的事实准确性、稳定性和地理偏见，引入了“Global-Liar”数据集，该数据集在地理和时间上实现平衡，以更全面地检测模型偏差。  \n分析发现，新版本的 GPT 模型并非总是更可靠，例如 GPT-4 的 3 月版本比 6 月版本事实准确性更高，且存在显著偏见，优先 Global North（全球北方）地区的声明，而 Global South（全球南方）如非洲和中东的准确性较低。  \n此外，模型配置设置（如二元决策、温度参数和重跑）会影响事实性，其中允许“unclear”选项的模型表现更好，低温单次推理可媲美多数投票。  \n这项研究强调需要更具文化多样性和地理包容性的模型训练和评估，以促进全球公平的 AI 技术发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 12 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17839v1",
      "published_date": "2024-01-31 13:57:24 UTC",
      "updated_date": "2024-01-31 13:57:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:50:16.623762"
    },
    {
      "arxiv_id": "2401.17838v1",
      "title": "A Cross-View Hierarchical Graph Learning Hypernetwork for Skill Demand-Supply Joint Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Wenshuo Chao",
        "Zhaopeng Qiu",
        "Likang Wu",
        "Zhuoning Guo",
        "Zhi Zheng",
        "Hengshu Zhu",
        "Hao Liu"
      ],
      "abstract": "The rapidly changing landscape of technology and industries leads to dynamic\nskill requirements, making it crucial for employees and employers to anticipate\nsuch shifts to maintain a competitive edge in the labor market. Existing\nefforts in this area either rely on domain-expert knowledge or regarding skill\nevolution as a simplified time series forecasting problem. However, both\napproaches overlook the sophisticated relationships among different skills and\nthe inner-connection between skill demand and supply variations. In this paper,\nwe propose a Cross-view Hierarchical Graph learning Hypernetwork (CHGH)\nframework for joint skill demand-supply prediction. Specifically, CHGH is an\nencoder-decoder network consisting of i) a cross-view graph encoder to capture\nthe interconnection between skill demand and supply, ii) a hierarchical graph\nencoder to model the co-evolution of skills from a cluster-wise perspective,\nand iii) a conditional hyper-decoder to jointly predict demand and supply\nvariations by incorporating historical demand-supply gaps. Extensive\nexperiments on three real-world datasets demonstrate the superiority of the\nproposed framework compared to seven baselines and the effectiveness of the\nthree modules.",
      "tldr_zh": "这篇论文针对技能需求和供给的动态变化，提出了一种 CHGH（Cross-View Hierarchical Graph Learning Hypernetwork）框架，用于联合预测技能需求和供给。CHGH 包括 cross-view graph encoder 来捕捉需求与供给间的互联、hierarchical graph encoder 从集群视角建模技能的共同演化，以及 conditional hyper-decoder 通过整合历史需求-供给差距进行预测。与现有方法相比，该框架在三个真实数据集上的实验中优于七个基线模型，证明了其有效性和各模块的贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, AAAI24",
      "pdf_url": "http://arxiv.org/pdf/2401.17838v1",
      "published_date": "2024-01-31 13:56:08 UTC",
      "updated_date": "2024-01-31 13:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:50:27.124118"
    },
    {
      "arxiv_id": "2402.01765v1",
      "title": "LLMs Simulate Big Five Personality Traits: Further Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandra Sorokovikova",
        "Natalia Fedorova",
        "Sharwin Rezagholi",
        "Ivan P. Yamshchikov"
      ],
      "abstract": "An empirical investigation into the simulation of the Big Five personality\ntraits by large language models (LLMs), namely Llama2, GPT4, and Mixtral, is\npresented. We analyze the personality traits simulated by these models and\ntheir stability. This contributes to the broader understanding of the\ncapabilities of LLMs to simulate personality traits and the respective\nimplications for personalized human-computer interaction.",
      "tldr_zh": "本研究通过实证调查，进一步探讨了大型语言模型（LLMs）如 Llama2、GPT4 和 Mixtral 模拟 Big Five Personality Traits 的能力。研究分析了这些模型模拟的个性特质及其稳定性，结果表明 LLMs 在此方面的表现具有潜在可靠性。最终，这为理解 LLMs 在个性化人机交互中的应用提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7; J.4; I.2.1"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01765v1",
      "published_date": "2024-01-31 13:45:25 UTC",
      "updated_date": "2024-01-31 13:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:50:38.270972"
    },
    {
      "arxiv_id": "2401.17828v2",
      "title": "Leveraging Swin Transformer for Local-to-Global Weakly Supervised Semantic Segmentation",
      "title_zh": "利用 Swin Transformer 实现从局部到全局的弱监督语义分割",
      "authors": [
        "Rozhan Ahmadi",
        "Shohreh Kasaei"
      ],
      "abstract": "In recent years, weakly supervised semantic segmentation using image-level\nlabels as supervision has received significant attention in the field of\ncomputer vision. Most existing methods have addressed the challenges arising\nfrom the lack of spatial information in these labels by focusing on\nfacilitating supervised learning through the generation of pseudo-labels from\nclass activation maps (CAMs). Due to the localized pattern detection of CNNs,\nCAMs often emphasize only the most discriminative parts of an object, making it\nchallenging to accurately distinguish foreground objects from each other and\nthe background. Recent studies have shown that Vision Transformer (ViT)\nfeatures, due to their global view, are more effective in capturing the scene\nlayout than CNNs. However, the use of hierarchical ViTs has not been\nextensively explored in this field. This work explores the use of Swin\nTransformer by proposing \"SWTformer\" to enhance the accuracy of the initial\nseed CAMs by bringing local and global views together. SWTformer-V1 generates\nclass probabilities and CAMs using only the patch tokens as features.\nSWTformer-V2 incorporates a multi-scale feature fusion mechanism to extract\nadditional information and utilizes a background-aware mechanism to generate\nmore accurate localization maps with improved cross-object discrimination.\nBased on experiments on the PascalVOC 2012 dataset, SWTformer-V1 achieves a\n0.98% mAP higher localization accuracy, outperforming state-of-the-art models.\nIt also yields comparable performance by 0.82% mIoU on average higher than\nother methods in generating initial localization maps, depending only on the\nclassification network. SWTformer-V2 further improves the accuracy of the\ngenerated seed CAMs by 5.32% mIoU, further proving the effectiveness of the\nlocal-to-global view provided by the Swin transformer. Code available at:\nhttps://github.com/RozhanAhmadi/SWTformer",
      "tldr_zh": "这篇论文利用 Swin Transformer 提出 SWTformer 框架，针对弱监督语义分割中的问题，通过结合本地和全局视图来改进类激活图(CAMs)的生成，从而更好地区分前景对象和背景。SWTformer-V1 仅使用 patch tokens 生成类概率和 CAMs，提升了初始本地化准确性，而 SWTformer-V2 进一步整合多尺度特征融合和背景感知机制，提高了跨对象辨识能力。在 PascalVOC 2012 数据集实验中，SWTformer-V1 比最先进模型提高 0.98% mAP，SWTformer-V2 则额外提升 5.32% mIoU，展示了框架的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17828v2",
      "published_date": "2024-01-31 13:41:17 UTC",
      "updated_date": "2024-03-11 04:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:50:53.153618"
    },
    {
      "arxiv_id": "2401.17827v1",
      "title": "Neural Machine Translation for Malayalam Paraphrase Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Christeena Varghese",
        "Sergey Koshelev",
        "Ivan P. Yamshchikov"
      ],
      "abstract": "This study explores four methods of generating paraphrases in Malayalam,\nutilizing resources available for English paraphrasing and pre-trained Neural\nMachine Translation (NMT) models. We evaluate the resulting paraphrases using\nboth automated metrics, such as BLEU, METEOR, and cosine similarity, as well as\nhuman annotation. Our findings suggest that automated evaluation measures may\nnot be fully appropriate for Malayalam, as they do not consistently align with\nhuman judgment. This discrepancy underscores the need for more nuanced\nparaphrase evaluation approaches especially for highly agglutinative languages.",
      "tldr_zh": "这项研究探讨了利用英语改写资源和预训练的 Neural Machine Translation (NMT) 模型来生成马拉雅拉姆语（Malayalam）的四种改写方法。研究通过自动化指标如 BLEU、METEOR 和 cosine similarity，以及人工标注，对生成的改写进行评估。结果显示，这些自动化评估指标与人工判断不一致，突显了针对高度粘着语（如Malayalam）的改写评估需要更细致的方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.7.0; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17827v1",
      "published_date": "2024-01-31 13:40:00 UTC",
      "updated_date": "2024-01-31 13:40:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:51:02.687125"
    },
    {
      "arxiv_id": "2402.00896v1",
      "title": "Privacy and Security Implications of Cloud-Based AI Services : A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Alka Luqman",
        "Riya Mahesh",
        "Anupam Chattopadhyay"
      ],
      "abstract": "This paper details the privacy and security landscape in today's cloud\necosystem and identifies that there is a gap in addressing the risks introduced\nby machine learning models. As machine learning algorithms continue to evolve\nand find applications across diverse domains, the need to categorize and\nquantify privacy and security risks becomes increasingly critical. With the\nemerging trend of AI-as-a-Service (AIaaS), machine learned AI models (or ML\nmodels) are deployed on the cloud by model providers and used by model\nconsumers. We first survey the AIaaS landscape to document the various kinds of\nliabilities that ML models, especially Deep Neural Networks pose and then\nintroduce a taxonomy to bridge this gap by holistically examining the risks\nthat creators and consumers of ML models are exposed to and their known\ndefences till date. Such a structured approach will be beneficial for ML model\nproviders to create robust solutions. Likewise, ML model consumers will find it\nvaluable to evaluate such solutions and understand the implications of their\nengagement with such services. The proposed taxonomies provide a foundational\nbasis for solutions in private, secure and robust ML, paving the way for more\ntransparent and resilient AI systems.",
      "tldr_zh": "这篇论文调查了云端 AI 服务中的隐私和安全问题，特别关注机器学习模型（ML models）引入的风险，如数据泄露和模型漏洞。作者首先审视了 AI-as-a-Service (AIaaS) 景观，引入了一个 taxonomy 来全面分类 ML 模型创建者和消费者面临的威胁及其现有防御措施。最终，该框架为开发私有、安全和稳健的 ML 解决方案提供基础，帮助提升 AI 系统的透明度和弹性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00896v1",
      "published_date": "2024-01-31 13:30:20 UTC",
      "updated_date": "2024-01-31 13:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:51:14.681909"
    },
    {
      "arxiv_id": "2401.17812v1",
      "title": "Deterministic Computing Power Networking: Architecture, Technologies and Prospects",
      "title_zh": "确定性计算力网络：架构、技术和前景",
      "authors": [
        "Qingmin Jia",
        "Yujiao Hu",
        "Xiaomao Zhou",
        "Qianpiao Ma",
        "Kai Guo",
        "Huayu Zhang",
        "Renchao Xie",
        "Tao Huang",
        "Yunjie Liu"
      ],
      "abstract": "With the development of new Internet services such as computation-intensive\nand delay-sensitive tasks, the traditional \"Best Effort\" network transmission\nmode has been greatly challenged. The network system is urgently required to\nprovide end-to-end transmission determinacy and computing determinacy for new\napplications to ensure the safe and efficient operation of services. Based on\nthe research of the convergence of computing and networking, a new network\nparadigm named deterministic computing power networking (Det-CPN) is proposed.\nIn this article, we firstly introduce the research advance of computing power\nnetworking. And then the motivations and scenarios of Det-CPN are analyzed.\nFollowing that, we present the system architecture, technological capabilities,\nworkflow as well as key technologies for Det-CPN. Finally, the challenges and\nfuture trends of Det-CPN are analyzed and discussed.",
      "tldr_zh": "该论文探讨了传统“Best Effort”网络模式在处理计算密集型和延迟敏感任务时的局限性，强调了为新应用提供端到端传输确定性和计算确定性的必要性。作者提出了一种新网络范式——Deterministic Computing Power Networking (Det-CPN)，基于计算力和网络融合的研究，分析了其动机、应用场景以及系统架构、技术能力和工作流程。论文还讨论了Det-CPN的关键技术、面临的挑战和未来发展趋势，为构建更安全高效的网络系统提供了新思路。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17812v1",
      "published_date": "2024-01-31 13:12:42 UTC",
      "updated_date": "2024-01-31 13:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:51:26.875002"
    },
    {
      "arxiv_id": "2401.17809v4",
      "title": "SWEA: Updating Factual Knowledge in Large Language Models via Subject Word Embedding Altering",
      "title_zh": "SWEA：通过主题词嵌入修改更新大语言模型中的事实知识",
      "authors": [
        "Xiaopeng Li",
        "Shasha Li",
        "Shezheng Song",
        "Huijun Liu",
        "Bin Ji",
        "Xi Wang",
        "Jun Ma",
        "Jie Yu",
        "Xiaodong Liu",
        "Jing Wang",
        "Weimin Zhang"
      ],
      "abstract": "The general capabilities of large language models (LLMs) make them the\ninfrastructure for various AI applications, but updating their inner knowledge\nrequires significant resources. Recent model editing is a promising technique\nfor efficiently updating a small amount of knowledge of LLMs and has attracted\nmuch attention. In particular, local editing methods, which directly update\nmodel parameters, are proven suitable for updating small amounts of knowledge.\nLocal editing methods update weights by computing least squares closed-form\nsolutions and identify edited knowledge by vector-level matching in inference,\nwhich achieve promising results. However, these methods still require a lot of\ntime and resources to complete the computation. Moreover, vector-level matching\nlacks reliability, and such updates disrupt the original organization of the\nmodel's parameters. To address these issues, we propose a detachable and\nexpandable Subject Word Embedding Altering (SWEA) framework, which finds the\nediting embeddings through token-level matching and adds them to the subject\nword embeddings in Transformer input. To get these editing embeddings, we\npropose optimizing then suppressing fusion method, which first optimizes\nlearnable embedding vectors for the editing target and then suppresses the\nKnowledge Embedding Dimensions (KEDs) to obtain final editing embeddings. We\nthus propose SWEA$\\oplus$OS method for editing factual knowledge in LLMs. We\ndemonstrate the overall state-of-the-art (SOTA) performance of SWEA$\\oplus$OS\non the CounterFact and zsRE datasets. To further validate the reasoning ability\nof SWEA$\\oplus$OS in editing knowledge, we evaluate it on the more complex\nRippleEdits benchmark. The results demonstrate that SWEA$\\oplus$OS possesses\nSOTA reasoning ability.",
      "tldr_zh": "该论文提出了一种高效更新大型语言模型（LLMs）事实知识的方法，以解决现有本地编辑技术的计算资源密集和可靠性问题。作者引入了可拆卸且可扩展的 Subject Word Embedding Altering (SWEA) 框架，通过 token-level matching 找到编辑嵌入，并使用优化然后抑制融合方法（optimizing then suppressing fusion method）来优化可学习嵌入向量并抑制 Knowledge Embedding Dimensions (KEDs)。实验结果显示，SWEA$\\oplus$OS 方法在 CounterFact 和 zsRE 数据集上达到了最先进（SOTA）性能，并在更复杂的 RippleEdits 基准上展示了出色的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI25. Our code is available at https://github.com/xpq-tech/SWEA",
      "pdf_url": "http://arxiv.org/pdf/2401.17809v4",
      "published_date": "2024-01-31 13:08:45 UTC",
      "updated_date": "2025-02-17 01:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:51:39.836744"
    },
    {
      "arxiv_id": "2401.17805v1",
      "title": "Biospheric AI",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Korecki"
      ],
      "abstract": "The dominant paradigm in AI ethics and value alignment is highly\nanthropocentric. The focus of these disciplines is strictly on human values\nwhich limits the depth and breadth of their insights. Recently, attempts to\nexpand to a sentientist perspective have been initiated. We argue that neither\nof these outlooks is sufficient to capture the actual complexity of the\nbiosphere and ensure that AI does not damage it. Thus, we propose a new\nparadigm -- Biospheric AI that assumes an ecocentric perspective. We discuss\nhypothetical ways in which such an AI might be designed. Moreover, we give\ndirections for research and application of the modern AI models that would be\nconsistent with the biospheric interests. All in all, this work attempts to\ntake first steps towards a comprehensive program of research that focuses on\nthe interactions between AI and the biosphere.",
      "tldr_zh": "本文批评当前AI伦理和价值对齐的主导范式过于anthropocentric（人类中心主义），并指出最近的sentientist（有情主义）尝试仍不足以应对生物圈的复杂性，从而可能导致AI对其造成损害。作者提出Biospheric AI新范式，该范式采用ecocentric（生态中心主义）视角，旨在更全面地保护生物圈。论文讨论了设计这种AI的假设方法，并为现代AI模型的研究和应用提供方向，以符合生物圈利益。整体上，这是一个初步步骤，推动AI与生物圈互动的全面研究程序。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17805v1",
      "published_date": "2024-01-31 13:04:34 UTC",
      "updated_date": "2024-01-31 13:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:51:51.264964"
    },
    {
      "arxiv_id": "2401.17802v2",
      "title": "Distillation Enhanced Time Series Forecasting Network with Momentum Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haozhi Gao",
        "Qianqian Ren",
        "Jinbao Li"
      ],
      "abstract": "Contrastive representation learning is crucial in time series analysis as it\nalleviates the issue of data noise and incompleteness as well as sparsity of\nsupervision signal. However, existing constrastive learning frameworks usually\nfocus on intral-temporal features, which fails to fully exploit the intricate\nnature of time series data. To address this issue, we propose DE-TSMCL, an\ninnovative distillation enhanced framework for long sequence time series\nforecasting. Specifically, we design a learnable data augmentation mechanism\nwhich adaptively learns whether to mask a timestamp to obtain optimized\nsub-sequences. Then, we propose a contrastive learning task with momentum\nupdate to explore inter-sample and intra-temporal correlations of time series\nto learn the underlying structure feature on the unlabeled time series.\nMeanwhile, we design a supervised task to learn more robust representations and\nfacilitate the contrastive learning process. Finally, we jointly optimize the\nabove two tasks. By developing model loss from multiple tasks, we can learn\neffective representations for downstream forecasting task. Extensive\nexperiments, in comparison with state-of-the-arts, well demonstrate the\neffectiveness of DE-TSMCL, where the maximum improvement can reach to 27.3%.",
      "tldr_zh": "本文提出 DE-TSMCL，一种蒸馏增强框架，用于长序列时间序列预测，通过对比学习缓解数据噪声、不完整性和监督信号稀疏问题。框架设计了一个可学习的数据增强机制，适应性地决定是否掩盖时间戳以生成优化的子序列，并引入带有动量更新的对比学习任务来探索时间序列的 inter-sample 和 intra-temporal 相关性。同时，该框架结合监督任务进行联合优化，以学习更鲁棒的表示并提升下游预测性能。实验结果显示，DE-TSMCL 与最先进方法相比，最大改进可达 27.3%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17802v2",
      "published_date": "2024-01-31 12:52:10 UTC",
      "updated_date": "2024-06-25 04:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:52:05.225797"
    },
    {
      "arxiv_id": "2401.17791v3",
      "title": "Graph Transformers without Positional Encodings",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Garg"
      ],
      "abstract": "Recently, Transformers for graph representation learning have become\nincreasingly popular, achieving state-of-the-art performance on a wide-variety\nof graph datasets, either alone or in combination with message-passing graph\nneural networks (MP-GNNs). Infusing graph inductive-biases in the innately\nstructure-agnostic transformer architecture in the form of structural or\npositional encodings (PEs) is key to achieving these impressive results.\nHowever, designing such encodings is tricky and disparate attempts have been\nmade to engineer such encodings including Laplacian eigenvectors, relative\nrandom-walk probabilities (RRWP), spatial encodings, centrality encodings, edge\nencodings etc. In this work, we argue that such encodings may not be required\nat all, provided the attention mechanism itself incorporates information about\nthe graph structure. We introduce Eigenformer, a Graph Transformer employing a\nnovel spectrum-aware attention mechanism cognizant of the Laplacian spectrum of\nthe graph, and empirically show that it achieves performance competetive with\nSOTA Graph Transformers on a number of standard GNN benchmarks. Additionally,\nwe theoretically prove that Eigenformer can express various graph structural\nconnectivity matrices, which is particularly essential when learning over\nsmaller graphs.",
      "tldr_zh": "本研究质疑了 Graph Transformers 在图表示学习中依赖位置编码(Positional Encodings)的必要性，提出了一种无需这些编码的框架，通过将图结构信息融入注意力机制来提升性能。作者引入了 Eigenformer，这是一种采用谱感知注意力机制的 Graph Transformer，利用图 Laplacian 谱来捕捉结构信息。实验结果表明，Eigenformer 在多个标准 GNN 基准上与最先进模型的性能相当；此外，理论证明它能够表达各种图结构连接矩阵，这对小图学习特别重要。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Independent Research",
      "pdf_url": "http://arxiv.org/pdf/2401.17791v3",
      "published_date": "2024-01-31 12:33:31 UTC",
      "updated_date": "2024-05-06 13:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:52:15.355240"
    },
    {
      "arxiv_id": "2401.17783v1",
      "title": "SDRDPy: An application to graphically visualize the knowledge obtained with supervised descriptive rule algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "M. A. Padilla-Rascon",
        "P. Gonzalez",
        "C. J. Carmona"
      ],
      "abstract": "SDRDPy is a desktop application that allows experts an intuitive graphic and\ntabular representation of the knowledge extracted by any supervised descriptive\nrule discovery algorithm. The application is able to provide an analysis of the\ndata showing the relevant information of the data set and the relationship\nbetween the rules, data and the quality measures associated for each rule\nregardless of the tool where algorithm has been executed. All of the\ninformation is presented in a user-friendly application in order to facilitate\nexpert analysis and also the exportation of reports in different formats.",
      "tldr_zh": "本文介绍了 SDRDPy，一款桌面应用，旨在通过图形和表格形式直观地可视化由 supervised descriptive rule algorithms 提取的知识。应用能够分析数据集的相关信息、规则与数据之间的关系，以及每个规则的质量指标，无论算法在何种工具中执行。SDRDPy 以用户友好的界面便于专家进行深入分析，并支持导出报告到多种格式，从而提升了知识发现过程的可访问性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17783v1",
      "published_date": "2024-01-31 12:26:59 UTC",
      "updated_date": "2024-01-31 12:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:52:27.353920"
    },
    {
      "arxiv_id": "2401.17776v1",
      "title": "Double InfoGAN for Contrastive Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Florence Carton",
        "Robin Louiset",
        "Pietro Gori"
      ],
      "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and what\nis distinctive of a target domain compared to a background one. This is of\ngreat interest in many applications, such as medical imaging. Current\nstate-of-the-art (SOTA) methods are latent variable models based on VAE\n(CA-VAEs). However, they all either ignore important constraints or they don't\nenforce fundamental assumptions. This may lead to sub-optimal solutions where\ndistinctive factors are mistaken for common ones (or viceversa). Furthermore,\nthe generated images have a rather poor quality, typical of VAEs, decreasing\ntheir interpretability and usefulness. Here, we propose Double InfoGAN, the\nfirst GAN based method for CA that leverages the high-quality synthesis of GAN\nand the separation power of InfoGAN. Experimental results on four visual\ndatasets, from simple synthetic examples to complex medical images, show that\nthe proposed method outperforms SOTA CA-VAEs in terms of latent separation and\nimage quality. Datasets and code are available online.",
      "tldr_zh": "Contrastive Analysis (CA) 旨在比较目标域与背景域的共同点和差异点，尤其在医疗成像等应用中。现有的基于 VAE 的 SOTA 方法如 CA-VAEs 存在忽略约束和图像质量差的问题，导致潜在分离不准确。为解决这些问题，本文提出 Double InfoGAN，这是一种首次基于 GAN 的 CA 方法，结合 GAN 的高质量图像合成和 InfoGAN 的分离能力。在四个视觉数据集上的实验中，Double InfoGAN 在潜在分离和图像质量上优于现有 SOTA 方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17776v1",
      "published_date": "2024-01-31 12:16:39 UTC",
      "updated_date": "2024-01-31 12:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:52:40.218741"
    },
    {
      "arxiv_id": "2401.17752v1",
      "title": "PF-GNN: Differentiable particle filtering based approximation of universal graph representations",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Haroon Dupty",
        "Yanfei Dong",
        "Wee Sun Lee"
      ],
      "abstract": "Message passing Graph Neural Networks (GNNs) are known to be limited in\nexpressive power by the 1-WL color-refinement test for graph isomorphism. Other\nmore expressive models either are computationally expensive or need\npreprocessing to extract structural features from the graph. In this work, we\npropose to make GNNs universal by guiding the learning process with exact\nisomorphism solver techniques which operate on the paradigm of\nIndividualization and Refinement (IR), a method to artificially introduce\nasymmetry and further refine the coloring when 1-WL stops. Isomorphism solvers\ngenerate a search tree of colorings whose leaves uniquely identify the graph.\nHowever, the tree grows exponentially large and needs hand-crafted pruning\ntechniques which are not desirable from a learning perspective. We take a\nprobabilistic view and approximate the search tree of colorings (i.e.\nembeddings) by sampling multiple paths from root to leaves of the search tree.\nTo learn more discriminative representations, we guide the sampling process\nwith particle filter updates, a principled approach for sequential state\nestimation. Our algorithm is end-to-end differentiable, can be applied with any\nGNN as backbone and learns richer graph representations with only linear\nincrease in runtime. Experimental evaluation shows that our approach\nconsistently outperforms leading GNN models on both synthetic benchmarks for\nisomorphism detection as well as real-world datasets.",
      "tldr_zh": "本文提出 PF-GNN，一种基于粒子滤波的框架，用于提升消息传递 GNNs 的表达力，使其超越 1-WL color-refinement 测试的限制，并实现 universal 图表示。PF-GNN 通过模拟 Individualization and Refinement (IR) 范式的搜索树，并使用粒子滤波引导采样过程，生成更具辨别力的图嵌入，同时保持端到端可微和线性运行时间增长。实验结果显示，该方法在合成图同构检测基准和真实数据集上， consistently outperforms 领先 GNN 模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2022",
      "pdf_url": "http://arxiv.org/pdf/2401.17752v1",
      "published_date": "2024-01-31 11:26:03 UTC",
      "updated_date": "2024-01-31 11:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:52:53.502778"
    },
    {
      "arxiv_id": "2401.17749v1",
      "title": "SwarmBrain: Embodied agent for real-time strategy game StarCraft II via large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Shao",
        "Weifu Jiang",
        "Fei Zuo",
        "Mengqing Liu"
      ],
      "abstract": "Large language models (LLMs) have recently garnered significant\naccomplishments in various exploratory tasks, even surpassing the performance\nof traditional reinforcement learning-based methods that have historically\ndominated the agent-based field. The purpose of this paper is to investigate\nthe efficacy of LLMs in executing real-time strategy war tasks within the\nStarCraft II gaming environment. In this paper, we introduce SwarmBrain, an\nembodied agent leveraging LLM for real-time strategy implementation in the\nStarCraft II game environment. The SwarmBrain comprises two key components: 1)\na Overmind Intelligence Matrix, powered by state-of-the-art LLMs, is designed\nto orchestrate macro-level strategies from a high-level perspective. This\nmatrix emulates the overarching consciousness of the Zerg intelligence brain,\nsynthesizing strategic foresight with the aim of allocating resources,\ndirecting expansion, and coordinating multi-pronged assaults. 2) a Swarm\nReflexNet, which is agile counterpart to the calculated deliberation of the\nOvermind Intelligence Matrix. Due to the inherent latency in LLM reasoning, the\nSwarm ReflexNet employs a condition-response state machine framework, enabling\nexpedited tactical responses for fundamental Zerg unit maneuvers. In the\nexperimental setup, SwarmBrain is in control of the Zerg race in confrontation\nwith an Computer-controlled Terran adversary. Experimental results show the\ncapacity of SwarmBrain to conduct economic augmentation, territorial expansion,\nand tactical formulation, and it shows the SwarmBrain is capable of achieving\nvictory against Computer players set at different difficulty levels.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在实时策略游戏StarCraft II中的应用，引入SwarmBrain智能体，以挑战传统强化学习方法。SwarmBrain包括两个核心组件：Overmind Intelligence Matrix，由先进的LLMs驱动，负责宏观策略如资源分配、领土扩张和多线攻击协调；以及Swarm ReflexNet，使用条件-响应状态机提供快速战术响应，以缓解LLMs推理延迟。实验结果显示，SwarmBrain控制Zerg种族成功击败不同难度级别的计算机对手，在经济增强、领土扩张和战术制定方面表现出色，证明了LLMs在代理游戏环境中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17749v1",
      "published_date": "2024-01-31 11:14:29 UTC",
      "updated_date": "2024-01-31 11:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:53:03.013948"
    },
    {
      "arxiv_id": "2401.17741v1",
      "title": "Haris: an Advanced Autonomous Mobile Robot for Smart Parking Assistance",
      "title_zh": "翻译失败",
      "authors": [
        "Layth Hamad",
        "Muhammad Asif Khan",
        "Hamid Menouar",
        "Fethi Filali",
        "Amr Mohamed"
      ],
      "abstract": "This paper presents Haris, an advanced autonomous mobile robot system for\ntracking the location of vehicles in crowded car parks using license plate\nrecognition. The system employs simultaneous localization and mapping (SLAM)\nfor autonomous navigation and precise mapping of the parking area, eliminating\nthe need for GPS dependency. In addition, the system utilizes a sophisticated\nframework using computer vision techniques for object detection and automatic\nlicense plate recognition (ALPR) for reading and associating license plate\nnumbers with location data. This information is subsequently synchronized with\na back-end service and made accessible to users via a user-friendly mobile app,\noffering effortless vehicle location and alleviating congestion within the\nparking facility. The proposed system has the potential to improve the\nmanagement of short-term large outdoor parking areas in crowded places such as\nsports stadiums. The demo of the robot can be found on\nhttps://youtu.be/ZkTCM35fxa0?si=QjggJuN7M1o3oifx.",
      "tldr_zh": "这篇论文介绍了 Haris，一种先进的自主移动机器人系统，用于通过车牌识别跟踪拥挤停车场的车辆位置。系统采用 SLAM（Simultaneous Localization and Mapping）技术实现自主导航和精确停车区域映射，同时利用计算机视觉和 ALPR（Automatic License Plate Recognition）进行物体检测及车牌号码与位置数据的关联。Haris 通过后端服务同步信息，并提供用户友好的移动应用，帮助用户轻松定位车辆、缓解停车拥堵，并适用于体育场等大型室外停车区的管理。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in 2024 IEEE International Conference on Consumer\n  Electronics (ICCE), Las Vegas, NV, USA, 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17741v1",
      "published_date": "2024-01-31 11:00:26 UTC",
      "updated_date": "2024-01-31 11:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:53:15.989833"
    },
    {
      "arxiv_id": "2401.17739v2",
      "title": "Operator learning without the adjoint",
      "title_zh": "无需伴随的算子学习",
      "authors": [
        "Nicolas Boullé",
        "Diana Halikias",
        "Samuel E. Otto",
        "Alex Townsend"
      ],
      "abstract": "There is a mystery at the heart of operator learning: how can one recover a\nnon-self-adjoint operator from data without probing the adjoint? Current\npractical approaches suggest that one can accurately recover an operator while\nonly using data generated by the forward action of the operator without access\nto the adjoint. However, naively, it seems essential to sample the action of\nthe adjoint. In this paper, we partially explain this mystery by proving that\nwithout querying the adjoint, one can approximate a family of non-self-adjoint\ninfinite-dimensional compact operators via projection onto a Fourier basis. We\nthen apply the result to recovering Green's functions of elliptic partial\ndifferential operators and derive an adjoint-free sample complexity bound.\nWhile existing theory justifies low sample complexity in operator learning,\nours is the first adjoint-free analysis that attempts to close the gap between\ntheory and practice.",
      "tldr_zh": "本文探讨了operator learning中的一个关键谜题：如何从数据中恢复非自共轭算子，而无需访问其adjoint。论文证明，通过将算子投影到Fourier basis上，可以近似一族非自共轭的无穷维紧致算子，并应用于椭圆偏微分算子的Green's functions恢复。最终，研究导出了adjoint-free的样本复杂度界，这是首次提供不依赖adjoint的理论分析，缩小了理论与实践的差距。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "54 pages, 5 figures, to appear in Journal of Machine Learning\n  Research",
      "pdf_url": "http://arxiv.org/pdf/2401.17739v2",
      "published_date": "2024-01-31 10:59:57 UTC",
      "updated_date": "2024-11-20 10:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:53:27.889073"
    },
    {
      "arxiv_id": "2401.17733v1",
      "title": "Towards Physical Plausibility in Neuroevolution Systems",
      "title_zh": "迈向神经进化系统中的物理合理性",
      "authors": [
        "Gabriel Cortês",
        "Nuno Lourenço",
        "Penousal Machado"
      ],
      "abstract": "The increasing usage of Artificial Intelligence (AI) models, especially Deep\nNeural Networks (DNNs), is increasing the power consumption during training and\ninference, posing environmental concerns and driving the need for more\nenergy-efficient algorithms and hardware solutions. This work addresses the\ngrowing energy consumption problem in Machine Learning (ML), particularly\nduring the inference phase. Even a slight reduction in power usage can lead to\nsignificant energy savings, benefiting users, companies, and the environment.\nOur approach focuses on maximizing the accuracy of Artificial Neural Network\n(ANN) models using a neuroevolutionary framework whilst minimizing their power\nconsumption. To do so, power consumption is considered in the fitness function.\nWe introduce a new mutation strategy that stochastically reintroduces modules\nof layers, with power-efficient modules having a higher chance of being chosen.\nWe introduce a novel technique that allows training two separate models in a\nsingle training step whilst promoting one of them to be more power efficient\nthan the other while maintaining similar accuracy. The results demonstrate a\nreduction in power consumption of ANN models by up to 29.2% without a\nsignificant decrease in predictive performance.",
      "tldr_zh": "这篇论文针对人工智能（AI）模型，尤其是深度神经网络（DNNs）在训练和推理过程中的高能耗问题，提出了一种基于神经进化框架的优化方法，以最大化人工神经网络（ANN）模型的准确性同时最小化能耗。方法包括在适应度函数中纳入能耗因素，并引入一种新变异策略，优先选择能效更高的模块进行随机重新引入。此外，他们开发了一种新技术，在单次训练步骤中同时训练两个模型，使其中一个更注重能效而保持类似准确性。实验结果显示，该方法使ANN模型的能耗降低了高达29.2%，而预测性能未显著下降。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17733v1",
      "published_date": "2024-01-31 10:54:34 UTC",
      "updated_date": "2024-01-31 10:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:53:41.033538"
    },
    {
      "arxiv_id": "2402.00092v1",
      "title": "Episodic-free Task Selection for Few-shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Zhang"
      ],
      "abstract": "Episodic training is a mainstream training strategy for few-shot learning. In\nfew-shot scenarios, however, this strategy is often inferior to some\nnon-episodic training strategy, e. g., Neighbourhood Component Analysis (NCA),\nwhich challenges the principle that training conditions must match testing\nconditions. Thus, a question is naturally asked: How to search for\nepisodic-free tasks for better few-shot learning? In this work, we propose a\nnovel meta-training framework beyond episodic training. In this framework,\nepisodic tasks are not used directly for training, but for evaluating the\neffectiveness of some selected episodic-free tasks from a task set that are\nperformed for training the meta-learners. The selection criterion is designed\nwith the affinity, which measures the degree to which loss decreases when\nexecuting the target tasks after training with the selected tasks. In\nexperiments, the training task set contains some promising types, e. g.,\ncontrastive learning and classification, and the target few-shot tasks are\nachieved with the nearest centroid classifiers on the miniImageNet,\ntiered-ImageNet and CIFAR-FS datasets. The experimental results demonstrate the\neffectiveness of our approach.",
      "tldr_zh": "本论文质疑了少样本学习(few-shot learning)中主流的 episodic 训练策略，指出其往往不如某些非 episodic 训练策略（如 Neighbourhood Component Analysis, NCA）有效，因此提出了一种新型 meta-training 框架。框架中，不直接使用 episodic 任务进行训练，而是从任务集（如对比学习和分类任务）中选择 episodic-free 任务，并基于亲和力(affinity)——即评估使用选定任务训练后目标任务损失减少的程度——来优化选择。实验结果显示，该方法在 miniImageNet、tiered-ImageNet 和 CIFAR-FS 数据集上使用最近质心分类器取得了显著效果，证明了其在提升少样本学习性能方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00092v1",
      "published_date": "2024-01-31 10:52:15 UTC",
      "updated_date": "2024-01-31 10:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:53:53.364516"
    },
    {
      "arxiv_id": "2402.00089v2",
      "title": "SCAPE: Searching Conceptual Architecture Prompts using Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Soo Ling Lim",
        "Peter J Bentley",
        "Fuyuki Ishikawa"
      ],
      "abstract": "Conceptual architecture involves a highly creative exploration of novel\nideas, often taken from other disciplines as architects consider radical new\nforms, materials, textures and colors for buildings. While today's generative\nAI systems can produce remarkable results, they lack the creativity\ndemonstrated for decades by evolutionary algorithms. SCAPE, our proposed tool,\ncombines evolutionary search with generative AI, enabling users to explore\ncreative and good quality designs inspired by their initial input through a\nsimple point and click interface. SCAPE injects randomness into generative AI,\nand enables memory, making use of the built-in language skills of GPT-4 to vary\nprompts via text-based mutation and crossover. We demonstrate that compared to\nDALL-E 3, SCAPE enables a 67% improvement in image novelty, plus improvements\nin quality and effectiveness of use; we show that in just three iterations\nSCAPE has a 24% image novelty increase enabling effective exploration, plus\noptimization of images by users. We use more than 20 independent architects to\nassess SCAPE, who provide markedly positive feedback.",
      "tldr_zh": "本论文提出 SCAPE 工具，将进化算法（evolutionary algorithms）与生成 AI 相结合，用于概念建筑的创意探索，帮助用户通过简单界面从初始输入生成高质量、创新设计。SCAPE 通过注入随机性、利用 GPT-4 进行文本-based mutation and crossover 来变异提示，并启用记忆功能，从而提升生成过程的多样性和有效性。与 DALL-E 3 相比，SCAPE 实现了图像新颖性提高 67%，并在三轮迭代中增加 24% 的新颖性。实验结果显示，SCAPE 获得了超过 20 名建筑师的积极反馈，证明其在优化建筑设计方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "68W50, 68T07",
        "G.1.6; I.2.10"
      ],
      "primary_category": "cs.NE",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.00089v2",
      "published_date": "2024-01-31 10:25:45 UTC",
      "updated_date": "2024-04-02 10:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:54:04.457962"
    },
    {
      "arxiv_id": "2401.17711v1",
      "title": "Prediction of multitasking performance post-longitudinal tDCS via EEG-based functional connectivity and machine learning methods",
      "title_zh": "翻译失败",
      "authors": [
        "Akash K Rao",
        "Shashank Uttrani",
        "Vishnu K Menon",
        "Darshil Shah",
        "Arnav Bhavsar",
        "Shubhajit Roy Chowdhury",
        "Varun Dutt"
      ],
      "abstract": "Predicting and understanding the changes in cognitive performance, especially\nafter a longitudinal intervention, is a fundamental goal in neuroscience.\nLongitudinal brain stimulation-based interventions like transcranial direct\ncurrent stimulation (tDCS) induce short-term changes in the resting membrane\npotential and influence cognitive processes. However, very little research has\nbeen conducted on predicting these changes in cognitive performance\npost-intervention. In this research, we intend to address this gap in the\nliterature by employing different EEG-based functional connectivity analyses\nand machine learning algorithms to predict changes in cognitive performance in\na complex multitasking task. Forty subjects were divided into experimental and\nactive-control conditions. On Day 1, all subjects executed a multitasking task\nwith simultaneous 32-channel EEG being acquired. From Day 2 to Day 7, subjects\nin the experimental condition undertook 15 minutes of 2mA anodal tDCS\nstimulation during task training. Subjects in the active-control condition\nundertook 15 minutes of sham stimulation during task training. On Day 10, all\nsubjects again executed the multitasking task with EEG acquisition.\nSource-level functional connectivity metrics, namely phase lag index and\ndirected transfer function, were extracted from the EEG data on Day 1 and Day\n10. Various machine learning models were employed to predict changes in\ncognitive performance. Results revealed that the multi-layer perceptron and\ndirected transfer function recorded a cross-validation training RMSE of 5.11%\nand a test RMSE of 4.97%. We discuss the implications of our results in\ndeveloping real-time cognitive state assessors for accurately predicting\ncognitive performance in dynamic and complex tasks post-tDCS intervention",
      "tldr_zh": "本文研究旨在通过 EEG-based functional connectivity 和 machine learning 方法预测纵向 tDCS 干预后多任务认知表现的变化。实验涉及 40 名受试者，其中实验组接受 6 天 2mA 阳极 tDCS 刺激，控制组接受 sham 刺激，并使用 phase lag index 和 directed transfer function 等指标从 Day 1 和 Day 10 的 EEG 数据中提取特征。结果显示，multi-layer perceptron 模型在预测认知变化时取得了 5.11% 的交叉验证 RMSE 和 4.97% 的测试 RMSE，这为开发实时认知状态评估器提供了可靠基础，以评估动态复杂任务中的表现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "16 pages, presented at the 30th International Conference on Neural\n  Information Processing (ICONIP2023), Changsha, China, November 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.17711v1",
      "published_date": "2024-01-31 10:03:27 UTC",
      "updated_date": "2024-01-31 10:03:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:54:18.786247"
    },
    {
      "arxiv_id": "2401.17710v1",
      "title": "Aesthetic Preference Prediction in Interior Design: Fuzzy Approach",
      "title_zh": "室内设计中的审美偏好预测：模糊方法",
      "authors": [
        "Ayana Adilova",
        "Pakizar Shamoi"
      ],
      "abstract": "Interior design is all about creating spaces that look and feel good.\nHowever, the subjective nature of aesthetic preferences presents a significant\nchallenge in defining and quantifying what makes an interior design visually\nappealing. The current paper addresses this gap by introducing a novel\nmethodology for quantifying and predicting aesthetic preferences in interior\ndesign. Our study combines fuzzy logic with image processing techniques. We\ncollected a dataset of interior design images from social media platforms,\nfocusing on essential visual attributes such as color harmony, lightness, and\ncomplexity. We integrate these features using weighted average to compute a\ngeneral aesthetic score. Our approach considers individual color preferences in\ncalculating the overall aesthetic preference. We initially gather user ratings\nfor primary colors like red, brown, and others to understand their preferences.\nThen, we use the pixel count of the top five dominant colors in the image to\nget the color scheme preference. The color scheme preference and the aesthetic\nscore are then passed as inputs to the fuzzy inference system to calculate an\noverall preference score. This score represents a comprehensive measure of the\nuser's preference for a particular interior design, considering their color\nchoices and general aesthetic appeal. We used the 2AFC (Two-Alternative Forced\nChoice) method to validate our methodology, achieving a notable hit rate of\n0.7. This study can help designers and professionals better understand and meet\npeople's interior design preferences, especially in a world that relies heavily\non digital media.",
      "tldr_zh": "本文提出了一种基于 fuzzy logic 的新方法，用于量化并预测室内设计中的美学偏好，解决了主观性带来的挑战。方法结合图像处理技术，从社交媒体收集的图像数据集分析颜色和谐、光亮度和复杂性等属性，并通过加权平均计算美学分数，同时整合个体颜色偏好（如对红色、棕色的评分）和模糊推理系统（fuzzy inference system）生成整体偏好分数。实验使用 2AFC（Two-Alternative Forced Choice）方法验证，达到了 0.7 的命中率，这有助于设计师在数字媒体时代更好地理解和满足用户需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to IEEE conference for consideration",
      "pdf_url": "http://arxiv.org/pdf/2401.17710v1",
      "published_date": "2024-01-31 09:59:59 UTC",
      "updated_date": "2024-01-31 09:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:54:28.630735"
    },
    {
      "arxiv_id": "2401.17700v1",
      "title": "Classification of executive functioning performance post-longitudinal tDCS using functional connectivity and machine learning methods",
      "title_zh": "使用功能连接和机器学习方法对纵向",
      "authors": [
        "Akash K Rao",
        "Vishnu K Menon",
        "Shashank Uttrani",
        "Ayushman Dixit",
        "Dipanshu Verma",
        "Varun Dutt"
      ],
      "abstract": "Executive functioning is a cognitive process that enables humans to plan,\norganize, and regulate their behavior in a goal-directed manner. Understanding\nand classifying the changes in executive functioning after longitudinal\ninterventions (like transcranial direct current stimulation (tDCS)) has not\nbeen explored in the literature. This study employs functional connectivity and\nmachine learning algorithms to classify executive functioning performance\npost-tDCS. Fifty subjects were divided into experimental and placebo control\ngroups. EEG data was collected while subjects performed an executive\nfunctioning task on Day 1. The experimental group received tDCS during task\ntraining from Day 2 to Day 8, while the control group received sham tDCS. On\nDay 10, subjects repeated the tasks specified on Day 1. Different functional\nconnectivity metrics were extracted from EEG data and eventually used for\nclassifying executive functioning performance using different machine learning\nalgorithms. Results revealed that a novel combination of partial directed\ncoherence and multi-layer perceptron (along with recursive feature elimination)\nresulted in a high classification accuracy of 95.44%. We discuss the\nimplications of our results in developing real-time neurofeedback systems for\nassessing and enhancing executive functioning performance post-tDCS\nadministration.",
      "tldr_zh": "本研究使用功能连接和机器学习方法，分类纵向 tDCS（transcranial direct current stimulation）干预后执行功能的表现变化，这是该领域的首次探索。研究招募50名受试者，将其分为实验组和安慰剂对照组，通过EEG数据收集执行功能任务的表现，并在干预前后分析数据。采用部分定向相干性（partial directed coherence）和多层感知器（multi-layer perceptron）结合递归特征消除（recursive feature elimination）的算法，最终实现了95.44%的分类准确率。这些结果为开发实时神经反馈系统提供了重要启示，以评估和提升tDCS后的执行功能表现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, presented at the IEEE 20th India Council International\n  Conference (INDICON 2023), Hyderabad, India, December 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.17700v1",
      "published_date": "2024-01-31 09:45:03 UTC",
      "updated_date": "2024-01-31 09:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:54:41.808229"
    },
    {
      "arxiv_id": "2401.17690v1",
      "title": "EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyeon Kim",
        "Jaeyoon Jung",
        "Jinjoo Lee",
        "Sang Hoon Woo"
      ],
      "abstract": "We propose EnCLAP, a novel framework for automated audio captioning. EnCLAP\nemploys two acoustic representation models, EnCodec and CLAP, along with a\npretrained language model, BART. We also introduce a new training objective\ncalled masked codec modeling that improves acoustic awareness of the pretrained\nlanguage model. Experimental results on AudioCaps and Clotho demonstrate that\nour model surpasses the performance of baseline models. Source code will be\navailable at https://github.com/jaeyeonkim99/EnCLAP . An online demo is\navailable at https://huggingface.co/spaces/enclap-team/enclap .",
      "tldr_zh": "我们提出EnCLAP框架，用于自动音频标注（Automated Audio Captioning），它结合了神经音频编解码器EnCodec和音频-文本联合嵌入CLAP，以及预训练语言模型BART。EnCLAP引入了新的训练目标masked codec modeling，以提升语言模型对声学特征的感知能力。在AudioCaps和Clotho数据集上的实验显示，该框架超过了基线模型的表现，提供可访问的源代码和在线演示。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.17690v1",
      "published_date": "2024-01-31 09:23:16 UTC",
      "updated_date": "2024-01-31 09:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:54:53.141587"
    },
    {
      "arxiv_id": "2401.17671v1",
      "title": "Contextual Feature Extraction Hierarchies Converge in Large Language Models and the Brain",
      "title_zh": "语境特征提取层次结构在大语言模型和大脑中趋于收敛",
      "authors": [
        "Gavin Mischler",
        "Yinghao Aaron Li",
        "Stephan Bickel",
        "Ashesh D. Mehta",
        "Nima Mesgarani"
      ],
      "abstract": "Recent advancements in artificial intelligence have sparked interest in the\nparallels between large language models (LLMs) and human neural processing,\nparticularly in language comprehension. While prior research has established\nsimilarities in the representation of LLMs and the brain, the underlying\ncomputational principles that cause this convergence, especially in the context\nof evolving LLMs, remain elusive. Here, we examined a diverse selection of\nhigh-performance LLMs with similar parameter sizes to investigate the factors\ncontributing to their alignment with the brain's language processing\nmechanisms. We find that as LLMs achieve higher performance on benchmark tasks,\nthey not only become more brain-like as measured by higher performance when\npredicting neural responses from LLM embeddings, but also their hierarchical\nfeature extraction pathways map more closely onto the brain's while using fewer\nlayers to do the same encoding. We also compare the feature extraction pathways\nof the LLMs to each other and identify new ways in which high-performing models\nhave converged toward similar hierarchical processing mechanisms. Finally, we\nshow the importance of contextual information in improving model performance\nand brain similarity. Our findings reveal the converging aspects of language\nprocessing in the brain and LLMs and offer new directions for developing models\nthat align more closely with human cognitive processing.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 与人类大脑在语言处理中的相似性，特别关注特征提取层次结构的趋同。研究者分析了多种高性能 LLMs，发现这些模型在基准任务上性能提升时，不仅在预测神经响应方面更像大脑，而且其 hierarchical feature extraction 路径使用更少的层来实现相似的编码。结果显示，上下文信息在提升模型性能和大脑相似性方面至关重要，为开发更紧密对齐人类认知处理的模型提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 5 figures and 4 supplementary figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17671v1",
      "published_date": "2024-01-31 08:48:35 UTC",
      "updated_date": "2024-01-31 08:48:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:55:04.389090"
    },
    {
      "arxiv_id": "2401.17661v1",
      "title": "Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle",
      "title_zh": "翻译失败",
      "authors": [
        "Víctor Julio Ramírez-Durán",
        "Idoia Berges",
        "Arantza Illarramendi"
      ],
      "abstract": "Many different worldwide initiatives are promoting the transformation from\nmachine dominant manufacturing to digital manufacturing. Thus, to achieve a\nsuccessful transformation to Industry 4.0 standard, manufacturing enterprises\nare required to implement a clear roadmap. However, Small and Medium\nManufacturing Enterprises (SMEs) encounter many barriers and difficulties\n(economical, technical, cultural, etc.) in the implementation of Industry 4.0.\nAlthough several works deal with the incorporation of Industry 4.0 technologies\nin the area of the product and supply chain life cycles, which SMEs could use\nas reference, this is not the case for the customer life cycle. Thus, we\npresent two contributions that can help the software engineers of those SMEs to\nincorporate Industry 4.0 technologies in the context of the customer life\ncycle. The first contribution is a methodology that can help those software\nengineers in the task of creating new software services, aligned with Industry\n4.0, that allow to change how customers interact with enterprises and the\nexperiences they have while interacting with them. The methodology details a\nset of stages that are divided into phases which in turn are made up of\nactivities. It places special emphasis on the incorporation of semantics\ndescriptions and 3D visualization in the implementation of those new services.\nThe second contribution is a system developed for a real manufacturing\nscenario, using the proposed methodology, which allows to observe the\npossibilities that this kind of systems can offer to SMEs in two phases of the\ncustomer life cycle: Discover & Shop, and Use & Service.",
      "tldr_zh": "该研究针对中小制造企业(SMEs)在实施Industry 4.0时面临的经济、技术和文化障碍，提出了一种以客户生命周期为导向的方法论。该方法论帮助SMEs的软件工程师开发与Industry 4.0对齐的软件服务，强调语义描述和3D可视化，通过分阶段活动改善客户互动体验。具体而言，该方法论应用于一个真实制造场景的系统示范，展示了在客户生命周期的“Discover & Shop”和“Use & Service”阶段的潜力，从而为SMEs提供可行的转型路径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted version of paper: V\\'ictor Julio Ram\\'irez-Dur\\'an, Idoia\n  Berges, Arantza Illarramendi: Towards the implementation of Industry 4.0: A\n  methodology-based approach oriented to the customer life cycle. Comput. Ind.\n  126: 103403 (2021). DOI: 10.1016/j.compind.2021.103403",
      "pdf_url": "http://arxiv.org/pdf/2401.17661v1",
      "published_date": "2024-01-31 08:31:08 UTC",
      "updated_date": "2024-01-31 08:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:55:17.312973"
    },
    {
      "arxiv_id": "2401.17657v1",
      "title": "An attempt to generate new bridge types from latent space of energy-based model",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Zhang"
      ],
      "abstract": "Use energy-based model for bridge-type innovation. The loss function is\nexplained by the game theory, the logic is clear and the formula is simple and\nclear. Thus avoid the use of maximum likelihood estimation to explain the loss\nfunction and eliminate the need for Monte Carlo methods to solve the normalized\ndenominator. Assuming that the bridge-type population follows a Boltzmann\ndistribution, a neural network is constructed to represent the energy function.\nUse Langevin dynamics technology to generate a new sample with low energy\nvalue, thus a generative model of bridge-type based on energy is established.\nTrain energy function on symmetric structured image dataset of three span beam\nbridge, arch bridge, cable-stayed bridge, and suspension bridge to accurately\ncalculate the energy values of real and fake samples. Sampling from latent\nspace, using gradient descent algorithm, the energy function transforms the\nsampling points into low energy score samples, thereby generating new bridge\ntypes different from the dataset. Due to unstable and slow training in this\nattempt, the possibility of generating new bridge types is rare and the image\ndefinition of generated images is low.",
      "tldr_zh": "这篇论文尝试使用 energy-based model 从潜在空间生成新桥梁类型，通过博弈论解释损失函数，避免了最大似然估计和 Monte Carlo methods 的复杂性。作者假设桥梁类型遵循 Boltzmann distribution，构建神经网络来表示能量函数，并采用 Langevin dynamics 生成低能量样本，从而建立一个基于能量的生成模型。在包含梁桥、拱桥、悬索桥等对称结构图像的数据集上训练后，通过从潜在空间采样和 gradient descent algorithm 转换样本，论文成功生成了一些新桥梁类型，但由于训练不稳定和速度慢，生成可能性较低，且图像清晰度不高。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.17657v1",
      "published_date": "2024-01-31 08:21:35 UTC",
      "updated_date": "2024-01-31 08:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:55:29.972822"
    },
    {
      "arxiv_id": "2401.17645v1",
      "title": "ReSLLM: Large Language Models are Strong Resource Selectors for Federated Search",
      "title_zh": "ReSLLM：大语言模型是联邦搜索的强大资源选择器",
      "authors": [
        "Shuai Wang",
        "Shengyao Zhuang",
        "Bevan Koopman",
        "Guido Zuccon"
      ],
      "abstract": "Federated search, which involves integrating results from multiple\nindependent search engines, will become increasingly pivotal in the context of\nRetrieval-Augmented Generation pipelines empowering LLM-based applications such\nas chatbots. These systems often distribute queries among various search\nengines, ranging from specialized (e.g., PubMed) to general (e.g., Google),\nbased on the nature of user utterances. A critical aspect of federated search\nis resource selection - the selection of appropriate resources prior to issuing\nthe query to ensure high-quality and rapid responses, and contain costs\nassociated with calling the external search engines. However, current SOTA\nresource selection methodologies primarily rely on feature-based learning\napproaches. These methods often involve the labour intensive and expensive\ncreation of training labels for each resource. In contrast, LLMs have exhibited\nstrong effectiveness as zero-shot methods across NLP and IR tasks. We\nhypothesise that in the context of federated search LLMs can assess the\nrelevance of resources without the need for extensive predefined labels or\nfeatures. In this paper, we propose ReSLLM. Our ReSLLM method exploits LLMs to\ndrive the selection of resources in federated search in a zero-shot setting. In\naddition, we devise an unsupervised fine tuning protocol, the Synthetic Label\nAugmentation Tuning (SLAT), where the relevance of previously logged queries\nand snippets from resources is predicted using an off-the-shelf LLM and then in\nturn used to fine-tune ReSLLM with respect to resource selection. Our empirical\nevaluation and analysis details the factors influencing the effectiveness of\nLLMs in this context. The results showcase the merits of ReSLLM for resource\nselection: not only competitive effectiveness in the zero-shot setting, but\nalso obtaining large when fine-tuned using SLAT-protocol.",
      "tldr_zh": "本文提出 ReSLLM 方法，利用 Large Language Models (LLMs) 作为联邦搜索 (Federated Search) 中的资源选择器 (Resource Selection)，以零样本方式评估资源相关性，避免了传统基于特征学习的标签创建需求。ReSLLM 适用于 Retrieval-Augmented Generation (RAG) 管道中的 LLM 应用，如聊天机器人，帮助实现高质量、快速响应并降低成本。论文还引入 Synthetic Label Augmentation Tuning (SLAT) 协议，通过使用现成 LLM 预测历史查询和片段的相关性，进行无监督微调。实验结果显示，ReSLLM 在零样本设置下已具竞争力，经 SLAT 微调后性能显著提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17645v1",
      "published_date": "2024-01-31 07:58:54 UTC",
      "updated_date": "2024-01-31 07:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:55:42.768443"
    },
    {
      "arxiv_id": "2402.00086v1",
      "title": "Retrosynthesis prediction enhanced by in-silico reaction data augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Zhang",
        "Yiming Mo",
        "Wenguan Wang",
        "Yi Yang"
      ],
      "abstract": "Recent advances in machine learning (ML) have expedited retrosynthesis\nresearch by assisting chemists to design experiments more efficiently. However,\nall ML-based methods consume substantial amounts of paired training data (i.e.,\nchemical reaction: product-reactant(s) pair), which is costly to obtain.\nMoreover, companies view reaction data as a valuable asset and restrict the\naccessibility to researchers. These issues prevent the creation of more\npowerful retrosynthesis models due to their data-driven nature. As a response,\nwe exploit easy-to-access unpaired data (i.e., one component of\nproduct-reactant(s) pair) for generating in-silico paired data to facilitate\nmodel training. Specifically, we present RetroWISE, a self-boosting framework\nthat employs a base model inferred from real paired data to perform in-silico\nreaction generation and augmentation using unpaired data, ultimately leading to\na superior model. On three benchmark datasets, RetroWISE achieves the best\noverall performance against state-of-the-art models (e.g., +8.6% top-1 accuracy\non the USPTO-50K test dataset). Moreover, it consistently improves the\nprediction accuracy of rare transformations. These results show that Retro-\nWISE overcomes the training bottleneck by in-silico reactions, thereby paving\nthe way toward more effective ML-based retrosynthesis models.",
      "tldr_zh": "本论文针对机器学习（ML）在逆合成预测中的数据瓶颈问题，提出 RetroWISE 框架，通过 in-silico 反应数据增强方法利用易获取的非配对数据（如产品或反应物）生成配对训练数据，从而提升模型性能。该框架基于从真实配对数据推断的基模型，进行反应生成和增强，最终训练出更优模型。在三个基准数据集上，RetroWISE 超越最先进模型，例如在 USPTO-50K 测试集上 top-1 准确率提高 8.6%，并显著改善稀有转化的预测准确性。这些结果证明了 in-silico 反应增强在克服训练瓶颈方面的潜力，为更有效的 ML 逆合成模型铺平道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00086v1",
      "published_date": "2024-01-31 07:40:37 UTC",
      "updated_date": "2024-01-31 07:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:55:54.408187"
    },
    {
      "arxiv_id": "2401.17633v1",
      "title": "Navigating the OverKill in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chenyu Shi",
        "Xiao Wang",
        "Qiming Ge",
        "Songyang Gao",
        "Xianjun Yang",
        "Tao Gui",
        "Qi Zhang",
        "Xuanjing Huang",
        "Xun Zhao",
        "Dahua Lin"
      ],
      "abstract": "Large language models are meticulously aligned to be both helpful and\nharmless. However, recent research points to a potential overkill which means\nmodels may refuse to answer benign queries. In this paper, we investigate the\nfactors for overkill by exploring how models handle and determine the safety of\nqueries. Our findings reveal the presence of shortcuts within models, leading\nto an over-attention of harmful words like 'kill' and prompts emphasizing\nsafety will exacerbate overkill. Based on these insights, we introduce\nSelf-Contrastive Decoding (Self-CD), a training-free and model-agnostic\nstrategy, to alleviate this phenomenon. We first extract such over-attention by\namplifying the difference in the model's output distributions when responding\nto system prompts that either include or omit an emphasis on safety. Then we\ndetermine the final next-token predictions by downplaying the over-attention\nfrom the model via contrastive decoding. Empirical results indicate that our\nmethod has achieved an average reduction of the refusal rate by 20\\% while\nhaving almost no impact on safety.",
      "tldr_zh": "本研究探讨了大语言模型（Large Language Models）在追求安全时出现的overkill现象，即模型过度拒绝无害查询的问题。研究发现，模型内部的shortcuts导致对有害词（如'kill'）的过度关注，而强调安全的提示会进一步加剧这一问题。为缓解overkill，提出Self-Contrastive Decoding (Self-CD)，一种无需训练且模型无关的策略，通过对比模型在不同安全提示下的输出分布来减少过度关注。实验结果显示，该方法平均降低了20%的拒绝率，同时几乎不影响模型的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17633v1",
      "published_date": "2024-01-31 07:26:47 UTC",
      "updated_date": "2024-01-31 07:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:56:05.689021"
    },
    {
      "arxiv_id": "2401.17626v2",
      "title": "Generative AI to Generate Test Data Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Benoit Baudry",
        "Khashayar Etemadi",
        "Sen Fang",
        "Yogya Gamage",
        "Yi Liu",
        "Yuxin Liu",
        "Martin Monperrus",
        "Javier Ron",
        "André Silva",
        "Deepika Tiwari"
      ],
      "abstract": "Generating fake data is an essential dimension of modern software testing, as\ndemonstrated by the number and significance of data faking libraries. Yet,\ndevelopers of faking libraries cannot keep up with the wide range of data to be\ngenerated for different natural languages and domains. In this paper, we assess\nthe ability of generative AI for generating test data in different domains. We\ndesign three types of prompts for Large Language Models (LLMs), which perform\ntest data generation tasks at different levels of integrability: 1) raw test\ndata generation, 2) synthesizing programs in a specific language that generate\nuseful test data, and 3) producing programs that use state-of-the-art faker\nlibraries. We evaluate our approach by prompting LLMs to generate test data for\n11 domains. The results show that LLMs can successfully generate realistic test\ndata generators in a wide range of domains at all three levels of\nintegrability.",
      "tldr_zh": "这篇论文探讨了生成式 AI（特别是 Large Language Models，LLMs）在生成测试数据生成器方面的能力，以解决开发人员无法跟上不同自然语言和领域需求的挑战。研究设计了三种提示类型，包括直接生成原始测试数据、合成特定语言的程序来生成有用数据，以及创建使用 state-of-the-art faker 库的程序，并针对 11 个领域进行评估。结果显示，LLMs 能在所有三种集成级别成功生成现实且有效的测试数据生成器。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17626v2",
      "published_date": "2024-01-31 06:58:26 UTC",
      "updated_date": "2024-06-14 14:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:56:17.005092"
    },
    {
      "arxiv_id": "2402.00085v2",
      "title": "Scheduled Curiosity-Deep Dyna-Q: Efficient Exploration for Dialog Policy Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xuecheng Niu",
        "Akinori Ito",
        "Takashi Nose"
      ],
      "abstract": "Training task-oriented dialog agents based on reinforcement learning is\ntime-consuming and requires a large number of interactions with real users. How\nto grasp dialog policy within limited dialog experiences remains an obstacle\nthat makes the agent training process less efficient. In addition, most\nprevious frameworks start training by randomly choosing training samples, which\ndiffers from the human learning method and hurts the efficiency and stability\nof training. Therefore, we propose Scheduled Curiosity-Deep Dyna-Q (SC-DDQ), a\ncuriosity-driven curriculum learning framework based on a state-of-the-art\nmodel-based reinforcement learning dialog model, Deep Dyna-Q (DDQ).\nFurthermore, we designed learning schedules for SC-DDQ and DDQ, respectively,\nfollowing two opposite training strategies: classic curriculum learning and its\nreverse version. Our results show that by introducing scheduled learning and\ncuriosity, the new framework leads to a significant improvement over the DDQ\nand Deep Q-learning(DQN). Surprisingly, we found that traditional curriculum\nlearning was not always effective. Specifically, according to the experimental\nresults, the easy-first and difficult-first strategies are more suitable for\nSC-DDQ and DDQ. To analyze our results, we adopted the entropy of sampled\nactions to depict action exploration and found that training strategies with\nhigh entropy in the first stage and low entropy in the last stage lead to\nbetter performance.",
      "tldr_zh": "本文提出 Scheduled Curiosity-Deep Dyna-Q (SC-DDQ) 框架，这是一种基于好奇心驱动的课程学习方法，旨在提高强化学习在对话策略学习中的效率，减少对真实用户互动的依赖。SC-DDQ 建立在 Deep Dyna-Q (DDQ) 基础上，通过设计学习计划（如 easy-first 和 difficult-first 策略）来优化训练过程。实验结果显示，SC-DDQ 比 DDQ 和 DQN 显著提升性能，而传统课程学习并非总是有效。进一步分析表明，高熵初始阶段和低熵后续阶段的动作探索策略能带来更好的对话代理表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2402.00085v2",
      "published_date": "2024-01-31 06:13:28 UTC",
      "updated_date": "2024-05-20 12:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:56:29.575933"
    },
    {
      "arxiv_id": "2401.17617v1",
      "title": "Unveiling the Power of Self-supervision for Multi-view Multi-human Association and Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Feng",
        "Feifan Wang",
        "Ruize Han",
        "Zekun Qian",
        "Song Wang"
      ],
      "abstract": "Multi-view multi-human association and tracking (MvMHAT), is a new but\nimportant problem for multi-person scene video surveillance, aiming to track a\ngroup of people over time in each view, as well as to identify the same person\nacross different views at the same time, which is different from previous MOT\nand multi-camera MOT tasks only considering the over-time human tracking. This\nway, the videos for MvMHAT require more complex annotations while containing\nmore information for self learning. In this work, we tackle this problem with a\nself-supervised learning aware end-to-end network. Specifically, we propose to\ntake advantage of the spatial-temporal self-consistency rationale by\nconsidering three properties of reflexivity, symmetry and transitivity. Besides\nthe reflexivity property that naturally holds, we design the self-supervised\nlearning losses based on the properties of symmetry and transitivity, for both\nappearance feature learning and assignment matrix optimization, to associate\nthe multiple humans over time and across views. Furthermore, to promote the\nresearch on MvMHAT, we build two new large-scale benchmarks for the network\ntraining and testing of different algorithms. Extensive experiments on the\nproposed benchmarks verify the effectiveness of our method. We have released\nthe benchmark and code to the public.",
      "tldr_zh": "本论文探讨了多视角多人类关联和跟踪(MvMHAT)问题，这是一种新的视频监控任务，不仅在单一视角下跟踪人群，还需跨视角识别同一人。该方法采用自监督学习aware的端到端网络，利用空间-时间自一致性属性，包括reflexivity、symmetry和transitivity，通过设计基于symmetry和transitivity的自监督损失来优化外观特征学习和分配矩阵，从而实现高效的人群关联。论文贡献包括构建两个大规模MvMHAT基准数据集，并通过实验验证了方法的有效性，同时公开了数据集和代码以促进相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17617v1",
      "published_date": "2024-01-31 06:12:28 UTC",
      "updated_date": "2024-01-31 06:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:56:41.441089"
    },
    {
      "arxiv_id": "2402.00084v1",
      "title": "EPSD: Early Pruning with Self-Distillation for Efficient Model Compression",
      "title_zh": "EPSD：早期剪枝与自蒸馏用于高效模型压缩",
      "authors": [
        "Dong Chen",
        "Ning Liu",
        "Yichen Zhu",
        "Zhengping Che",
        "Rui Ma",
        "Fachao Zhang",
        "Xiaofeng Mou",
        "Yi Chang",
        "Jian Tang"
      ],
      "abstract": "Neural network compression techniques, such as knowledge distillation (KD)\nand network pruning, have received increasing attention. Recent work `Prune,\nthen Distill' reveals that a pruned student-friendly teacher network can\nbenefit the performance of KD. However, the conventional teacher-student\npipeline, which entails cumbersome pre-training of the teacher and complicated\ncompression steps, makes pruning with KD less efficient. In addition to\ncompressing models, recent compression techniques also emphasize the aspect of\nefficiency. Early pruning demands significantly less computational cost in\ncomparison to the conventional pruning methods as it does not require a large\npre-trained model. Likewise, a special case of KD, known as self-distillation\n(SD), is more efficient since it requires no pre-training or student-teacher\npair selection. This inspires us to collaborate early pruning with SD for\nefficient model compression. In this work, we propose the framework named Early\nPruning with Self-Distillation (EPSD), which identifies and preserves\ndistillable weights in early pruning for a given SD task. EPSD efficiently\ncombines early pruning and self-distillation in a two-step process, maintaining\nthe pruned network's trainability for compression. Instead of a simple\ncombination of pruning and SD, EPSD enables the pruned network to favor SD by\nkeeping more distillable weights before training to ensure better distillation\nof the pruned network. We demonstrated that EPSD improves the training of\npruned networks, supported by visual and quantitative analyses. Our evaluation\ncovered diverse benchmarks (CIFAR-10/100, Tiny-ImageNet, full ImageNet,\nCUB-200-2011, and Pascal VOC), with EPSD outperforming advanced pruning and SD\ntechniques.",
      "tldr_zh": "该论文提出了一种名为 EPSD 的框架，将 Early Pruning 和 Self-Distillation (SD) 相结合，用于高效的神经网络压缩，以解决传统 Knowledge Distillation (KD) 和 Network Pruning 方法中预训练复杂和计算成本高的难题。EPSD 通过在早期剪枝过程中识别并保留 distillable weights，确保剪枝后的网络保持良好的 trainability，并优化自蒸馏效果，从而提升整体压缩效率。实验结果显示，EPSD 在多个基准上（如 CIFAR-10/100、Tiny-ImageNet 和 ImageNet） outperform 了现有的高级剪枝和 SD 技术，证明了其在模型压缩方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors are with equal contributions. Paper accepted by\n  AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.00084v1",
      "published_date": "2024-01-31 05:39:55 UTC",
      "updated_date": "2024-01-31 05:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:56:53.056277"
    },
    {
      "arxiv_id": "2402.00083v1",
      "title": "Modeling Access Differences to Reduce Disparity in Resource Allocation",
      "title_zh": "建模访问差异以减少资源分配中的不平等",
      "authors": [
        "Kenya Andrews",
        "Mesrob Ohannessian",
        "Tanya Berger-Wolf"
      ],
      "abstract": "Motivated by COVID-19 vaccine allocation, where vulnerable subpopulations are\nsimultaneously more impacted in terms of health and more disadvantaged in terms\nof access to the vaccine, we formalize and study the problem of resource\nallocation when there are inherent access differences that correlate with\nadvantage and disadvantage. We identify reducing resource disparity as a key\ngoal in this context and show its role as a proxy to more nuanced downstream\nimpacts. We develop a concrete access model that helps quantify how a given\nallocation translates to resource flow for the advantaged vs. the\ndisadvantaged, based on the access gap between them. We then provide a\nmethodology for access-aware allocation. Intuitively, the resulting allocation\nleverages more vaccines in locations with higher vulnerable populations to\nmitigate the access gap and reduce overall disparity. Surprisingly, knowledge\nof the access gap is often not needed to perform access-aware allocation. To\nsupport this formalism, we provide empirical evidence for our access model and\nshow that access-aware allocation can significantly reduce resource disparity\nand thus improve downstream outcomes. We demonstrate this at various scales,\nincluding at county, state, national, and global levels.",
      "tldr_zh": "这篇论文针对资源分配中的访问差异问题（如COVID-19疫苗分配），形式化了如何减少资源差异（resource disparity），以帮助弱势群体获得更多资源。研究者开发了一个访问模型（access model），用于量化分配如何基于访问差距（access gap）转化为优势和劣势群体间的资源流动，并提出了一种访问感知分配方法，该方法通过向弱势人口较多的区域分配更多资源来缓解差距。令人意外的是，这种分配往往无需精确知道访问差距，就能显著降低资源差异并改善下游结果；实验在县、市、国家和全球层面提供了实证支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Association for Computing Machinery (2022)",
      "pdf_url": "http://arxiv.org/pdf/2402.00083v1",
      "published_date": "2024-01-31 05:25:12 UTC",
      "updated_date": "2024-01-31 05:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:57:06.079853"
    },
    {
      "arxiv_id": "2401.17600v1",
      "title": "Good at captioning, bad at counting: Benchmarking GPT-4V on Earth observation data",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhui Zhang",
        "Sherrie Wang"
      ],
      "abstract": "Large Vision-Language Models (VLMs) have demonstrated impressive performance\non complex tasks involving visual input with natural language instructions.\nHowever, it remains unclear to what extent capabilities on natural images\ntransfer to Earth observation (EO) data, which are predominantly satellite and\naerial images less common in VLM training data. In this work, we propose a\ncomprehensive benchmark to gauge the progress of VLMs toward being useful tools\nfor EO data by assessing their abilities on scene understanding, localization\nand counting, and change detection tasks. Motivated by real-world applications,\nour benchmark includes scenarios like urban monitoring, disaster relief, land\nuse, and conservation. We discover that, although state-of-the-art VLMs like\nGPT-4V possess extensive world knowledge that leads to strong performance on\nopen-ended tasks like location understanding and image captioning, their poor\nspatial reasoning limits usefulness on object localization and counting tasks.\nOur benchmark will be made publicly available at https://vleo.danielz.ch/ and\non Hugging Face at\nhttps://huggingface.co/collections/mit-ei/vleo-benchmark-datasets-65b789b0466555489cce0d70\nfor easy model evaluation.",
      "tldr_zh": "这篇论文评估了大型视觉语言模型（VLMs）如 GPT-4V 在地球观测（EO）数据上的性能，发现这些模型在自然图像任务上表现出色，但EO数据（如卫星和航拍图像）上存在局限。研究者提出一个全面基准测试，涵盖场景理解、对象定位和计数以及变化检测任务，并基于真实应用场景如城市监测、灾害救援、土地利用和保护进行评估。主要发现是，VLMs 凭借广泛的世界知识在图像描述和位置理解上表现强劲，但由于空间推理能力不足，在计数和定位任务上效果较差。该基准已公开可用，便于进一步模型评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "62 pages; work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.17600v1",
      "published_date": "2024-01-31 04:57:12 UTC",
      "updated_date": "2024-01-31 04:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:57:19.020940"
    },
    {
      "arxiv_id": "2401.17592v2",
      "title": "Local Feature Matching Using Deep Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Shibiao Xu",
        "Shunpeng Chen",
        "Rongtao Xu",
        "Changwei Wang",
        "Peng Lu",
        "Li Guo"
      ],
      "abstract": "Local feature matching enjoys wide-ranging applications in the realm of\ncomputer vision, encompassing domains such as image retrieval, 3D\nreconstruction, and object recognition. However, challenges persist in\nimproving the accuracy and robustness of matching due to factors like viewpoint\nand lighting variations. In recent years, the introduction of deep learning\nmodels has sparked widespread exploration into local feature matching\ntechniques. The objective of this endeavor is to furnish a comprehensive\noverview of local feature matching methods. These methods are categorized into\ntwo key segments based on the presence of detectors. The Detector-based\ncategory encompasses models inclusive of Detect-then-Describe, Joint Detection\nand Description, Describe-then-Detect, as well as Graph Based techniques. In\ncontrast, the Detector-free category comprises CNN Based, Transformer Based,\nand Patch Based methods. Our study extends beyond methodological analysis,\nincorporating evaluations of prevalent datasets and metrics to facilitate a\nquantitative comparison of state-of-the-art techniques. The paper also explores\nthe practical application of local feature matching in diverse domains such as\nStructure from Motion, Remote Sensing Image Registration, and Medical Image\nRegistration, underscoring its versatility and significance across various\nfields. Ultimately, we endeavor to outline the current challenges faced in this\ndomain and furnish future research directions, thereby serving as a reference\nfor researchers involved in local feature matching and its interconnected\ndomains. A comprehensive list of studies in this survey is available at\nhttps://github.com/vignywang/Awesome-Local-Feature-Matching .",
      "tldr_zh": "这篇调查论文概述了使用深度学习的局部特征匹配技术在计算机视觉领域的应用，包括图像检索、3D 重建和对象识别等方面，并讨论了如何应对视角和光照变化带来的准确性和鲁棒性挑战。论文将这些方法分为两类：Detector-based（包括 Detect-then-Describe、Joint Detection and Description、Describe-then-Detect 和 Graph Based 技术）和 Detector-free（包括 CNN Based、Transformer Based 和 Patch Based 方法），并通过常见数据集和指标进行定量比较。最终，论文探讨了局部特征匹配在 Structure from Motion、Remote Sensing Image Registration 和 Medical Image Registration 等领域的实际应用，总结了当前挑战并提出未来研究方向，作为相关领域研究者的参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Information Fusion 2024. Project page:\n  https://github.com/vignywang/Awesome-Local-Feature-Matching",
      "pdf_url": "http://arxiv.org/pdf/2401.17592v2",
      "published_date": "2024-01-31 04:32:41 UTC",
      "updated_date": "2024-03-11 01:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:57:30.821758"
    },
    {
      "arxiv_id": "2401.17585v1",
      "title": "Propagation and Pitfalls: Reasoning-based Assessment of Knowledge Editing through Counterfactual Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyue Hua",
        "Jiang Guo",
        "Mingwen Dong",
        "Henghui Zhu",
        "Patrick Ng",
        "Zhiguo Wang"
      ],
      "abstract": "Current approaches of knowledge editing struggle to effectively propagate\nupdates to interconnected facts. In this work, we delve into the barriers that\nhinder the appropriate propagation of updated knowledge within these models for\naccurate reasoning. To support our analysis, we introduce a novel\nreasoning-based benchmark -- ReCoE (Reasoning-based Counterfactual Editing\ndataset) -- which covers six common reasoning schemes in real world. We conduct\na thorough analysis of existing knowledge editing techniques, including input\naugmentation, finetuning, and locate-and-edit. We found that all model editing\nmethods show notably low performance on this dataset, especially in certain\nreasoning schemes. Our analysis over the chain-of-thought generation of edited\nmodels further uncover key reasons behind the inadequacy of existing knowledge\nediting methods from a reasoning standpoint, involving aspects on fact-wise\nediting, fact recall ability, and coherence in generation. We will make our\nbenchmark publicly available.",
      "tldr_zh": "这篇论文探讨了知识编辑方法在传播更新知识时的障碍，特别是对相互关联事实的推理准确性问题。作者引入了一个新基准数据集 ReCoE（Reasoning-based Counterfactual Editing dataset），它覆盖六种常见推理方案，用于评估现有技术如输入增强、微调和 locate-and-edit。实验结果显示，这些方法在 ReCoE 上表现显著低下，尤其在特定推理方案中；通过分析编辑后模型的 chain-of-thought 生成，论文揭示了关键不足，包括事实编辑能力、事实回忆和生成连贯性问题。作者计划公开该基准数据集，以推动相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 14 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17585v1",
      "published_date": "2024-01-31 04:12:59 UTC",
      "updated_date": "2024-01-31 04:12:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:57:43.917095"
    },
    {
      "arxiv_id": "2401.17583v3",
      "title": "Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion",
      "title_zh": "翻译失败",
      "authors": [
        "Tairan He",
        "Chong Zhang",
        "Wenli Xiao",
        "Guanqi He",
        "Changliu Liu",
        "Guanya Shi"
      ],
      "abstract": "Legged robots navigating cluttered environments must be jointly agile for\nefficient task execution and safe to avoid collisions with obstacles or humans.\nExisting studies either develop conservative controllers (< 1.0 m/s) to ensure\nsafety, or focus on agility without considering potentially fatal collisions.\nThis paper introduces Agile But Safe (ABS), a learning-based control framework\nthat enables agile and collision-free locomotion for quadrupedal robots. ABS\ninvolves an agile policy to execute agile motor skills amidst obstacles and a\nrecovery policy to prevent failures, collaboratively achieving high-speed and\ncollision-free navigation. The policy switch in ABS is governed by a learned\ncontrol-theoretic reach-avoid value network, which also guides the recovery\npolicy as an objective function, thereby safeguarding the robot in a closed\nloop. The training process involves the learning of the agile policy, the\nreach-avoid value network, the recovery policy, and an exteroception\nrepresentation network, all in simulation. These trained modules can be\ndirectly deployed in the real world with onboard sensing and computation,\nleading to high-speed and collision-free navigation in confined indoor and\noutdoor spaces with both static and dynamic obstacles.",
      "tldr_zh": "这篇论文提出Agile But Safe (ABS)框架，一种基于学习的控制方法，用于实现四足机器人在杂乱环境中的高速度运动，同时避免碰撞。ABS框架包括agile policy负责执行敏捷动作、recovery policy用于故障恢复，以及一个学到的reach-avoid value network来管理政策切换并作为优化目标，确保闭环安全。训练过程在模拟环境中完成所有模块，包括agile policy、reach-avoid value network、recovery policy和exteroception representation network，最终在真实世界部署中实现了高速度、无碰撞导航，适用于室内外静态和动态障碍场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at RSS 2024, Project website:\n  https://agile-but-safe.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2401.17583v3",
      "published_date": "2024-01-31 03:58:28 UTC",
      "updated_date": "2024-05-21 05:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:57:54.982028"
    },
    {
      "arxiv_id": "2402.00893v1",
      "title": "MoDE: A Mixture-of-Experts Model with Mutual Distillation among the Experts",
      "title_zh": "MoDE：一种在专家之间互惠蒸馏的混合专家模型",
      "authors": [
        "Zhitian Xie",
        "Yinger Zhang",
        "Chenyi Zhuang",
        "Qitao Shi",
        "Zhining Liu",
        "Jinjie Gu",
        "Guannan Zhang"
      ],
      "abstract": "The application of mixture-of-experts (MoE) is gaining popularity due to its\nability to improve model's performance. In an MoE structure, the gate layer\nplays a significant role in distinguishing and routing input features to\ndifferent experts. This enables each expert to specialize in processing their\ncorresponding sub-tasks. However, the gate's routing mechanism also gives rise\nto narrow vision: the individual MoE's expert fails to use more samples in\nlearning the allocated sub-task, which in turn limits the MoE to further\nimprove its generalization ability. To effectively address this, we propose a\nmethod called Mixture-of-Distilled-Expert (MoDE), which applies moderate mutual\ndistillation among experts to enable each expert to pick up more features\nlearned by other experts and gain more accurate perceptions on their original\nallocated sub-tasks. We conduct plenty experiments including tabular, NLP and\nCV datasets, which shows MoDE's effectiveness, universality and robustness.\nFurthermore, we develop a parallel study through innovatively constructing\n\"expert probing\", to experimentally prove why MoDE works: moderate distilling\nknowledge can improve each individual expert's test performances on their\nassigned tasks, leading to MoE's overall performance improvement.",
      "tldr_zh": "该论文针对 Mixture-of-Experts (MoE) 模型中 experts 的窄视野问题，提出 MoDE 方法，通过 experts 之间的 mutual distillation 机制，让每个 expert 学习其他 experts 的特征，从而更准确地处理其分配的子任务。MoDE 旨在提升 MoE 的泛化能力，并在表格、NLP 和 CV 数据集上的实验中证明其有效性、通用性和鲁棒性。研究还通过创新的 expert probing 实验，验证 moderate distilling knowledge 如何改善个体 experts 的性能，最终提升整体 MoE 模型的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2402.00893v1",
      "published_date": "2024-01-31 03:52:32 UTC",
      "updated_date": "2024-01-31 03:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:58:07.603064"
    },
    {
      "arxiv_id": "2401.17580v2",
      "title": "Graph Contrastive Learning with Cohesive Subgraph Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Yucheng Wu",
        "Leye Wang",
        "Xiao Han",
        "Han-Jia Ye"
      ],
      "abstract": "Graph contrastive learning (GCL) has emerged as a state-of-the-art strategy\nfor learning representations of diverse graphs including social and biomedical\nnetworks. GCL widely uses stochastic graph topology augmentation, such as\nuniform node dropping, to generate augmented graphs. However, such stochastic\naugmentations may severely damage the intrinsic properties of a graph and\ndeteriorate the following representation learning process. We argue that\nincorporating an awareness of cohesive subgraphs during the graph augmentation\nand learning processes has the potential to enhance GCL performance. To this\nend, we propose a novel unified framework called CTAug, to seamlessly integrate\ncohesion awareness into various existing GCL mechanisms. In particular, CTAug\ncomprises two specialized modules: topology augmentation enhancement and graph\nlearning enhancement. The former module generates augmented graphs that\ncarefully preserve cohesion properties, while the latter module bolsters the\ngraph encoder's ability to discern subgraph patterns. Theoretical analysis\nshows that CTAug can strictly improve existing GCL mechanisms. Empirical\nexperiments verify that CTAug can achieve state-of-the-art performance for\ngraph representation learning, especially for graphs with high degrees. The\ncode is available at https://doi.org/10.5281/zenodo.10594093, or\nhttps://github.com/wuyucheng2002/CTAug.",
      "tldr_zh": "该论文针对图对比学习(GCL)中随机拓扑增强（如均匀节点删除）可能破坏图内在属性的问题，提出了一种新框架CTAug，将凝聚子图意识无缝整合到现有GCL机制中。CTAug包括拓扑增强增强模块（生成保留凝聚属性的增强图）和图学习增强模块（提升图编码器识别子图模式的能力），理论分析证明其能严格改善GCL性能。实验结果显示，CTAug在图表示学习中，特别是高图上，达到了最先进水平，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17580v2",
      "published_date": "2024-01-31 03:51:30 UTC",
      "updated_date": "2024-02-21 16:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:58:18.710132"
    },
    {
      "arxiv_id": "2402.00892v1",
      "title": "EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shijia Liao",
        "Shiyi Lan",
        "Arun George Zachariah"
      ],
      "abstract": "The advent of Large Models marks a new era in machine learning, significantly\noutperforming smaller models by leveraging vast datasets to capture and\nsynthesize complex patterns. Despite these advancements, the exploration into\nscaling, especially in the audio generation domain, remains limited, with\nprevious efforts didn't extend into the high-fidelity (HiFi) 44.1kHz domain and\nsuffering from both spectral discontinuities and blurriness in the\nhigh-frequency domain, alongside a lack of robustness against out-of-domain\ndata. These limitations restrict the applicability of models to diverse use\ncases, including music and singing generation. Our work introduces Enhanced\nVarious Audio Generation via Scalable Generative Adversarial Networks\n(EVA-GAN), yields significant improvements over previous state-of-the-art in\nspectral and high-frequency reconstruction and robustness in out-of-domain data\nperformance, enabling the generation of HiFi audios by employing an extensive\ndataset of 36,000 hours of 44.1kHz audio, a context-aware module, a\nHuman-In-The-Loop artifact measurement toolkit, and expands the model to\napproximately 200 million parameters. Demonstrations of our work are available\nat https://double-blind-eva-gan.cc.",
      "tldr_zh": "该研究介绍了EVA-GAN，一种可扩展的Generative Adversarial Networks框架，旨在解决音频生成领域中现有模型的局限性，如频谱不连续、高频模糊以及对外域数据的鲁棒性不足。EVA-GAN利用36,000小时的44.1kHz高保真(HiFi)音频数据集、上下文感知模块(context-aware module)和Human-In-The-Loop工具体验工具，扩展模型参数至约2亿，提升了谱和高频重建质量。实验结果显示，EVA-GAN在音频生成性能上显著优于现有最先进模型，支持多样化应用如音乐和歌声生成。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00892v1",
      "published_date": "2024-01-31 03:31:03 UTC",
      "updated_date": "2024-01-31 03:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:58:31.600584"
    },
    {
      "arxiv_id": "2401.17548v6",
      "title": "Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators",
      "title_zh": "重新思考多元时间序列预测中的通道依赖：从领先指标学习",
      "authors": [
        "Lifan Zhao",
        "Yanyan Shen"
      ],
      "abstract": "Recently, channel-independent methods have achieved state-of-the-art\nperformance in multivariate time series (MTS) forecasting. Despite reducing\noverfitting risks, these methods miss potential opportunities in utilizing\nchannel dependence for accurate predictions. We argue that there exist locally\nstationary lead-lag relationships between variates, i.e., some lagged variates\nmay follow the leading indicators within a short time period. Exploiting such\nchannel dependence is beneficial since leading indicators offer advance\ninformation that can be used to reduce the forecasting difficulty of the lagged\nvariates. In this paper, we propose a new method named LIFT that first\nefficiently estimates leading indicators and their leading steps at each time\nstep and then judiciously allows the lagged variates to utilize the advance\ninformation from leading indicators. LIFT plays as a plugin that can be\nseamlessly collaborated with arbitrary time series forecasting methods.\nExtensive experiments on six real-world datasets demonstrate that LIFT improves\nthe state-of-the-art methods by 5.5% in average forecasting performance. Our\ncode is available at https://github.com/SJTU-Quant/LIFT.",
      "tldr_zh": "本论文重新审视了多变量时间序列 (MTS) 预测中的通道依赖性，认为现有的 channel-independent 方法虽减少了过拟合风险，但忽略了局部稳定的 lead-lag 关系，即滞后变量可跟随领先指标以获取提前信息。作者提出 LIFT 方法，该方法首先高效估计每个时间步的领先指标及其领先步，然后允许滞后变量利用这些信息，从而提升预测性能。实验结果显示，在六个真实世界数据集上，LIFT 平均提高了最先进方法的 5.5% 预测准确率，并可作为插件无缝集成到任意时间序列预测方法中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024. Code is at https://github.com/SJTU-DMTai/LIFT",
      "pdf_url": "http://arxiv.org/pdf/2401.17548v6",
      "published_date": "2024-01-31 02:26:09 UTC",
      "updated_date": "2024-08-13 05:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:58:44.600069"
    },
    {
      "arxiv_id": "2401.17542v3",
      "title": "A Medical Data-Effective Learning Benchmark for Highly Efficient Pre-training of Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Yang",
        "Weimin Tan",
        "Yuqi Sun",
        "Bo Yan"
      ],
      "abstract": "Foundation models, pre-trained on massive datasets, have achieved\nunprecedented generalizability. However, is it truly necessary to involve such\nvast amounts of data in pre-training, consuming extensive computational\nresources? This paper introduces data-effective learning, aiming to use data in\nthe most impactful way to pre-train foundation models. This involves strategies\nthat focus on data quality rather than quantity, ensuring the data used for\ntraining has high informational value. Data-effective learning plays a profound\nrole in accelerating foundation model training, reducing computational costs,\nand saving data storage, which is very important as the volume of medical data\nin recent years has grown beyond many people's expectations. However, due to\nthe lack of standards and comprehensive benchmarks, research on medical\ndata-effective learning is poorly studied. To address this gap, our paper\nintroduces a comprehensive benchmark specifically for evaluating data-effective\nlearning in the medical field. This benchmark includes a dataset with millions\nof data samples from 31 medical centers (DataDEL), a baseline method for\ncomparison (MedDEL), and a new evaluation metric (NormDEL) to objectively\nmeasure data-effective learning performance. Our extensive experimental results\nshow the baseline MedDEL can achieve performance comparable to the original\nlarge dataset with only 5% of the data. Establishing such an open\ndata-effective learning benchmark is crucial for the medical foundation model\nresearch community because it facilitates efficient data use, promotes\ncollaborative breakthroughs, and fosters the development of cost-effective,\nscalable, and impactful healthcare solutions.",
      "tldr_zh": "该论文引入了数据有效学习（data-effective learning）的概念，旨在通过强调数据质量而非数量来高效预训练基础模型（Foundation Models），从而减少计算资源消耗和数据存储需求，尤其适用于医疗领域的数据爆炸增长。研究者开发了一个全面的医疗基准，包括一个包含数百万样本的跨31个医疗中心的数据集（DataDEL）、一个基准方法（MedDEL）和一个新的评估指标（NormDEL），用于客观评估数据有效学习性能。实验结果显示，MedDEL 方法仅使用原数据集的5%即可实现相媲美的性能，这为医疗基础模型研究提供了高效、可扩展的框架，促进协作创新和成本效益高的医疗解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17542v3",
      "published_date": "2024-01-31 02:09:21 UTC",
      "updated_date": "2024-08-16 12:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:58:53.710206"
    },
    {
      "arxiv_id": "2401.17527v2",
      "title": "Learning to Stop Cut Generation for Efficient Mixed-Integer Linear Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Ling",
        "Zhihai Wang",
        "Jie Wang"
      ],
      "abstract": "Cutting planes (cuts) play an important role in solving mixed-integer linear\nprograms (MILPs), as they significantly tighten the dual bounds and improve the\nsolving performance. A key problem for cuts is when to stop cuts generation,\nwhich is important for the efficiency of solving MILPs. However, many modern\nMILP solvers employ hard-coded heuristics to tackle this problem, which tends\nto neglect underlying patterns among MILPs from certain applications. To\naddress this challenge, we formulate the cuts generation stopping problem as a\nreinforcement learning problem and propose a novel hybrid graph representation\nmodel (HYGRO) to learn effective stopping strategies. An appealing feature of\nHYGRO is that it can effectively capture both the dynamic and static features\nof MILPs, enabling dynamic decision-making for the stopping strategies. To the\nbest of our knowledge, HYGRO is the first data-driven method to tackle the cuts\ngeneration stopping problem. By integrating our approach with modern solvers,\nexperiments demonstrate that HYGRO significantly improves the efficiency of\nsolving MILPs compared to competitive baselines, achieving up to 31%\nimprovement.",
      "tldr_zh": "这篇论文针对混合整数线性规划（MILPs）求解中的切割平面（cuts）生成问题，提出了一种学习策略来决定何时停止生成cuts，以提高求解效率。作者将该问题形式化为强化学习问题，并开发了新型混合图表示模型（HYGRO），该模型能同时捕获MILPs的动态和静态特征，实现动态决策策略。实验结果显示，与现有基线方法相比，HYGRO在现代求解器中提高了MILPs求解效率，高达31%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17527v2",
      "published_date": "2024-01-31 01:09:40 UTC",
      "updated_date": "2024-02-02 05:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:59:07.283892"
    },
    {
      "arxiv_id": "2401.17513v2",
      "title": "A PNP ion channel deep learning solver with local neural network and finite element input data",
      "title_zh": "翻译失败",
      "authors": [
        "Hwi Lee",
        "Zhen Chao",
        "Harris Cobb",
        "Yingjie Liu",
        "Dexuan Xie"
      ],
      "abstract": "In this paper, a deep learning method for solving an improved one-dimensional\nPoisson-Nernst-Planck ion channel (PNPic) model, called the PNPic deep learning\nsolver, is presented. In particular, it combines a novel local neural network\nscheme with an effective PNPic finite element solver. Since the input data of\nthe neural network scheme only involves a small local patch of coarse grid\nsolutions, which the finite element solver can quickly produce, the PNPic deep\nlearning solver can be trained much faster than any corresponding conventional\nglobal neural network solvers. After properly trained, it can output a\npredicted PNPic solution in a much higher degree of accuracy than the low cost\ncoarse grid solutions and can reflect different perturbation cases on the\nparameters, ion channel subregions, and interface and boundary values, etc.\nConsequently, the PNPic deep learning solver can generate a numerical solution\nwith high accuracy for a family of PNPic models. As an initial study, two types\nof numerical tests were done by perturbing one and two parameters of the PNPic\nmodel, respectively, as well as the tests done by using a few perturbed\ninterface positions of the model as training samples. These tests demonstrate\nthat the PNPic deep learning solver can generate highly accurate PNPic\nnumerical solutions.",
      "tldr_zh": "本文提出了一种PNPic深度学习求解器，用于解决改进的一维Poisson-Nernst-Planck离子通道模型，该方法结合了新型局部神经网络方案和有限元求解器。相比传统全局神经网络求解器，该求解器仅使用粗网格局部数据作为输入，能显著加快训练速度，并输出更高精度的预测结果，同时适应参数、离子通道子区域、界面和边界值的扰动。实验测试显示，通过扰动一个或多个参数以及界面位置，该求解器能为一系列PNPic模型生成高度准确的数值解决方案。",
      "categories": [
        "physics.bio-ph",
        "cs.AI",
        "physics.comp-ph",
        "92-08"
      ],
      "primary_category": "physics.bio-ph",
      "comment": "17 pages, 4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.17513v2",
      "published_date": "2024-01-31 00:15:31 UTC",
      "updated_date": "2024-03-31 01:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:59:20.273901"
    },
    {
      "arxiv_id": "2401.17511v1",
      "title": "Linguistically Communicating Uncertainty in Patient-Facing Risk Prediction Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adarsa Sivaprasad",
        "Ehud Reiter"
      ],
      "abstract": "This paper addresses the unique challenges associated with uncertainty\nquantification in AI models when applied to patient-facing contexts within\nhealthcare. Unlike traditional eXplainable Artificial Intelligence (XAI)\nmethods tailored for model developers or domain experts, additional\nconsiderations of communicating in natural language, its presentation and\nevaluating understandability are necessary. We identify the challenges in\ncommunication model performance, confidence, reasoning and unknown knowns using\nnatural language in the context of risk prediction. We propose a design aimed\nat addressing these challenges, focusing on the specific application of\nin-vitro fertilisation outcome prediction.",
      "tldr_zh": "这篇论文探讨了在医疗AI中，使用自然语言传达不确定性的独特挑战，特别是针对患者的风险预测模型。与传统的XAI方法不同，它强调了沟通方式、呈现形式和可理解性的额外考虑。论文识别了模型性能、置信度、推理以及未知已知的沟通挑战，并提出了一种设计方案，针对体外受精结果预测的具体应用，以提升患者理解和信任。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17511v1",
      "published_date": "2024-01-31 00:08:44 UTC",
      "updated_date": "2024-01-31 00:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:59:31.919174"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 82,
  "processed_papers_count": 82,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T01:59:56.232476"
}