[
  {
    "arxiv_id": "2410.15536v2",
    "title": "GRS: Generating Robotic Simulation Tasks from Real-World Images",
    "authors": [
      "Alex Zook",
      "Fan-Yun Sun",
      "Josef Spjut",
      "Valts Blukis",
      "Stan Birchfield",
      "Jonathan Tremblay"
    ],
    "abstract": "We introduce GRS (Generating Robotic Simulation tasks), a system addressing\nreal-to-sim for robotic simulations. GRS creates digital twin simulations from\nsingle RGB-D observations with solvable tasks for virtual agent training. Using\nvision-language models (VLMs), our pipeline operates in three stages: 1) scene\ncomprehension with SAM2 for segmentation and object description, 2) matching\nobjects with simulation-ready assets, and 3) generating appropriate tasks. We\nensure simulation-task alignment through generated test suites and introduce a\nrouter that iteratively refines both simulation and test code. Experiments\ndemonstrate our system's effectiveness in object correspondence and task\nenvironment generation through our novel router mechanism.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15536v2",
    "published_date": "2024-10-20 23:33:06 UTC",
    "updated_date": "2025-04-04 23:56:25 UTC"
  },
  {
    "arxiv_id": "2410.15528v1",
    "title": "Improving Clinical Documentation with AI: A Comparative Study of Sporo AI Scribe and GPT-4o mini",
    "authors": [
      "Chanseo Lee",
      "Sonu Kumar",
      "Kimon A. Vogt",
      "Sam Meraj"
    ],
    "abstract": "AI-powered medical scribes have emerged as a promising solution to alleviate\nthe documentation burden in healthcare. Ambient AI scribes provide real-time\ntranscription and automated data entry into Electronic Health Records (EHRs),\nwith the potential to improve efficiency, reduce costs, and enhance\nscalability. Despite early success, the accuracy of AI scribes remains\ncritical, as errors can lead to significant clinical consequences.\nAdditionally, AI scribes face challenges in handling the complexity and\nvariability of medical language and ensuring the privacy of sensitive patient\ndata. This case study aims to evaluate Sporo Health's AI scribe, a multi-agent\nsystem leveraging fine-tuned medical LLMs, by comparing its performance with\nOpenAI's GPT-4o Mini on multiple performance metrics. Using a dataset of\nde-identified patient conversation transcripts, AI-generated summaries were\ncompared to clinician-generated notes (the ground truth) based on clinical\ncontent recall, precision, and F1 scores. Evaluations were further supplemented\nby clinician satisfaction assessments using a modified Physician Documentation\nQuality Instrument revision 9 (PDQI-9), rated by both a medical student and a\nphysician. The results show that Sporo AI consistently outperformed GPT-4o\nMini, achieving higher recall, precision, and overall F1 scores. Moreover, the\nAI generated summaries provided by Sporo were rated more favorably in terms of\naccuracy, comprehensiveness, and relevance, with fewer hallucinations. These\nfindings demonstrate that Sporo AI Scribe is an effective and reliable tool for\nclinical documentation, enhancing clinician workflows while maintaining high\nstandards of privacy and security.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15528v1",
    "published_date": "2024-10-20 22:48:40 UTC",
    "updated_date": "2024-10-20 22:48:40 UTC"
  },
  {
    "arxiv_id": "2410.15522v2",
    "title": "M-RewardBench: Evaluating Reward Models in Multilingual Settings",
    "authors": [
      "Srishti Gureja",
      "Lester James V. Miranda",
      "Shayekh Bin Islam",
      "Rishabh Maheshwary",
      "Drishti Sharma",
      "Gusti Winata",
      "Nathan Lambert",
      "Sebastian Ruder",
      "Sara Hooker",
      "Marzieh Fadaee"
    ],
    "abstract": "Reward models (RMs) have driven the state-of-the-art performance of LLMs\ntoday by enabling the integration of human feedback into the language modeling\nprocess. However, RMs are primarily trained and evaluated in English, and their\ncapabilities in multilingual settings remain largely understudied. In this\nwork, we conduct a systematic evaluation of several reward models in\nmultilingual settings. We first construct the first-of-its-kind multilingual RM\nevaluation benchmark, M-RewardBench, consisting of 2.87k preference instances\nfor 23 typologically diverse languages, that tests the chat, safety, reasoning,\nand translation capabilities of RMs. We then rigorously evaluate a wide range\nof reward models on M-RewardBench, offering fresh insights into their\nperformance across diverse languages. We identify a significant gap in RMs'\nperformances between English and non-English languages and show that RM\npreferences can change substantially from one language to another. We also\npresent several findings on how different multilingual aspects impact RM\nperformance. Specifically, we show that the performance of RMs is improved with\nimproved translation quality. Similarly, we demonstrate that the models exhibit\nbetter performance for high-resource languages. We release M-RewardBench\ndataset and the codebase in this study to facilitate a better understanding of\nRM evaluation in multilingual settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 6 figures, 10 tables. Website:\n  https://m-rewardbench.github.io/ , Updated results with latest models. Added\n  more author information",
    "pdf_url": "http://arxiv.org/pdf/2410.15522v2",
    "published_date": "2024-10-20 22:09:44 UTC",
    "updated_date": "2024-10-29 03:28:42 UTC"
  },
  {
    "arxiv_id": "2410.15509v1",
    "title": "Exploring Curriculum Learning for Vision-Language Tasks: A Study on Small-Scale Multimodal Training",
    "authors": [
      "Rohan Saha",
      "Abrar Fahim",
      "Alona Fyshe",
      "Alex Murphy"
    ],
    "abstract": "For specialized domains, there is often not a wealth of data with which to\ntrain large machine learning models. In such limited data / compute settings,\nvarious methods exist aiming to $\\textit{do more with less}$, such as\nfinetuning from a pretrained model, modulating difficulty levels as data are\npresented to a model (curriculum learning), and considering the role of model\ntype / size. Approaches to efficient $\\textit{machine}$ learning also take\ninspiration from $\\textit{human}$ learning by considering use cases where\nmachine learning systems have access to approximately the same number of words\nexperienced by a 13 year old child (100M words). We investigate the role of 3\nprimary variables in a limited data regime as part of the multimodal track of\nthe BabyLM challenge. We contrast: (i) curriculum learning, (ii), pretraining\n(with text-only data), (iii) model type. We modulate these variables and assess\nthem on two types of tasks: (a) multimodal (text+image), and (b) unimodal\n(text-only) tasks. We find that curriculum learning benefits multimodal\nevaluations over non-curriclum learning models, particularly when combining\ntext-only pretraining. On text-only tasks, curriculum learning appears to help\nmodels with smaller trainable parameter counts. We suggest possible reasons\nbased on architectural differences and training designs as to why one might\nobserve such results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "CoNLL BabyLM Challenge 2024 camera ready",
    "pdf_url": "http://arxiv.org/pdf/2410.15509v1",
    "published_date": "2024-10-20 21:03:51 UTC",
    "updated_date": "2024-10-20 21:03:51 UTC"
  },
  {
    "arxiv_id": "2410.15500v1",
    "title": "Anonymising Elderly and Pathological Speech: Voice Conversion Using DDSP and Query-by-Example",
    "authors": [
      "Suhita Ghosh",
      "Melanie Jouaiti",
      "Arnab Das",
      "Yamini Sinha",
      "Tim Polzehl",
      "Ingo Siegert",
      "Sebastian Stober"
    ],
    "abstract": "Speech anonymisation aims to protect speaker identity by changing personal\nidentifiers in speech while retaining linguistic content. Current methods fail\nto retain prosody and unique speech patterns found in elderly and pathological\nspeech domains, which is essential for remote health monitoring. To address\nthis gap, we propose a voice conversion-based method (DDSP-QbE) using\ndifferentiable digital signal processing and query-by-example. The proposed\nmethod, trained with novel losses, aids in disentangling linguistic, prosodic,\nand domain representations, enabling the model to adapt to uncommon speech\npatterns. Objective and subjective evaluations show that DDSP-QbE significantly\noutperforms the voice conversion state-of-the-art concerning intelligibility,\nprosody, and domain preservation across diverse datasets, pathologies, and\nspeakers while maintaining quality and speaker anonymity. Experts validate\ndomain preservation by analysing twelve clinically pertinent domain attributes.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15500v1",
    "published_date": "2024-10-20 20:40:56 UTC",
    "updated_date": "2024-10-20 20:40:56 UTC"
  },
  {
    "arxiv_id": "2410.15499v1",
    "title": "Improving Voice Quality in Speech Anonymization With Just Perception-Informed Losses",
    "authors": [
      "Suhita Ghosh",
      "Tim Thiele",
      "Frederic Lorbeer",
      "Frank Dreyer",
      "Sebastian Stober"
    ],
    "abstract": "The increasing use of cloud-based speech assistants has heightened the need\nfor effective speech anonymization, which aims to obscure a speaker's identity\nwhile retaining critical information for subsequent tasks. One approach to\nachieving this is through voice conversion. While existing methods often\nemphasize complex architectures and training techniques, our research\nunderscores the importance of loss functions inspired by the human auditory\nsystem. Our proposed loss functions are model-agnostic, incorporating\nhandcrafted and deep learning-based features to effectively capture quality\nrepresentations. Through objective and subjective evaluations, we demonstrate\nthat a VQVAE-based model, enhanced with our perception-driven losses, surpasses\nthe vanilla model in terms of naturalness, intelligibility, and prosody while\nmaintaining speaker anonymity. These improvements are consistently observed\nacross various datasets, languages, target speakers, and genders.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in NeurIPS 2024 Workshop (Audio Imagination)",
    "pdf_url": "http://arxiv.org/pdf/2410.15499v1",
    "published_date": "2024-10-20 20:33:44 UTC",
    "updated_date": "2024-10-20 20:33:44 UTC"
  },
  {
    "arxiv_id": "2410.15495v2",
    "title": "SEA: State-Exchange Attention for High-Fidelity Physics Based Transformers",
    "authors": [
      "Parsa Esmati",
      "Amirhossein Dadashzadeh",
      "Vahid Goodarzi",
      "Nicolas Larrosa",
      "Nicol√≤ Grilli"
    ],
    "abstract": "Current approaches using sequential networks have shown promise in estimating\nfield variables for dynamical systems, but they are often limited by high\nrollout errors. The unresolved issue of rollout error accumulation results in\nunreliable estimations as the network predicts further into the future, with\neach step's error compounding and leading to an increase in inaccuracy. Here,\nwe introduce the State-Exchange Attention (SEA) module, a novel\ntransformer-based module enabling information exchange between encoded fields\nthrough multi-head cross-attention. The cross-field multidirectional\ninformation exchange design enables all state variables in the system to\nexchange information with one another, capturing physical relationships and\nsymmetries between fields. Additionally, we introduce an efficient ViT-like\nmesh autoencoder to generate spatially coherent mesh embeddings for a large\nnumber of meshing cells. The SEA integrated transformer demonstrates the\nstate-of-the-art rollout error compared to other competitive baselines.\nSpecifically, we outperform PbGMR-GMUS Transformer-RealNVP and GMR-GMUS\nTransformer, with a reduction in error of 88% and 91%, respectively.\nFurthermore, we demonstrate that the SEA module alone can reduce errors by 97%\nfor state variables that are highly dependent on other states of the system.\nThe repository for this work is available at:\nhttps://github.com/ParsaEsmati/SEA",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.15495v2",
    "published_date": "2024-10-20 20:25:01 UTC",
    "updated_date": "2024-10-29 20:13:48 UTC"
  },
  {
    "arxiv_id": "2410.15490v3",
    "title": "Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI with a Focus on Model Confidence",
    "authors": [
      "Norbert Tihanyi",
      "Tamas Bisztray",
      "Richard A. Dubniczky",
      "Rebeka Toth",
      "Bertalan Borsos",
      "Bilel Cherif",
      "Mohamed Amine Ferrag",
      "Lajos Muzsai",
      "Ridhi Jain",
      "Ryan Marinelli",
      "Lucas C. Cordeiro",
      "Merouane Debbah",
      "Vasileios Mavroeidis",
      "Audun Josang"
    ],
    "abstract": "As machine intelligence evolves, the need to test and compare the\nproblem-solving abilities of different AI models grows. However, current\nbenchmarks are often simplistic, allowing models to perform uniformly well and\nmaking it difficult to distinguish their capabilities. Additionally, benchmarks\ntypically rely on static question-answer pairs that the models might memorize\nor guess. To address these limitations, we introduce Dynamic Intelligence\nAssessment (DIA), a novel methodology for testing AI models using dynamic\nquestion templates and improved metrics across multiple disciplines such as\nmathematics, cryptography, cybersecurity, and computer science. The\naccompanying dataset, DIA-Bench, contains a diverse collection of challenge\ntemplates with mutable parameters presented in various formats, including text,\nPDFs, compiled binaries, visual puzzles, and CTF-style cybersecurity\nchallenges. Our framework introduces four new metrics to assess a model's\nreliability and confidence across multiple attempts. These metrics revealed\nthat even simple questions are frequently answered incorrectly when posed in\nvarying forms, highlighting significant gaps in models' reliability. Notably,\nAPI models like GPT-4o often overestimated their mathematical capabilities,\nwhile ChatGPT-4o demonstrated better performance due to effective tool usage.\nIn self-assessment, OpenAI's o1-mini proved to have the best judgement on what\ntasks it should attempt to solve. We evaluated 25 state-of-the-art LLMs using\nDIA-Bench, showing that current models struggle with complex tasks and often\ndisplay unexpectedly low confidence, even with simpler questions. The DIA\nframework sets a new standard for assessing not only problem-solving but also a\nmodel's adaptive intelligence and ability to assess its limitations. The\ndataset is publicly available on the project's page:\nhttps://github.com/DIA-Bench.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15490v3",
    "published_date": "2024-10-20 20:07:36 UTC",
    "updated_date": "2024-11-22 20:15:01 UTC"
  },
  {
    "arxiv_id": "2410.15489v1",
    "title": "Generative AI Agents in Autonomous Machines: A Safety Perspective",
    "authors": [
      "Jason Jabbour",
      "Vijay Janapa Reddi"
    ],
    "abstract": "The integration of Generative Artificial Intelligence (AI) into autonomous\nmachines represents a major paradigm shift in how these systems operate and\nunlocks new solutions to problems once deemed intractable. Although generative\nAI agents provide unparalleled capabilities, they also have unique safety\nconcerns. These challenges require robust safeguards, especially for autonomous\nmachines that operate in high-stakes environments. This work investigates the\nevolving safety requirements when generative models are integrated as agents\ninto physical autonomous machines, comparing these to safety considerations in\nless critical AI applications. We explore the challenges and opportunities to\nensure the safe deployment of generative AI-driven autonomous machines.\nFurthermore, we provide a forward-looking perspective on the future of\nAI-driven autonomous systems and emphasize the importance of evaluating and\ncommunicating safety risks. As an important step towards addressing these\nconcerns, we recommend the development and implementation of comprehensive\nsafety scorecards for the use of generative AI technologies in autonomous\nmachines.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15489v1",
    "published_date": "2024-10-20 20:07:08 UTC",
    "updated_date": "2024-10-20 20:07:08 UTC"
  },
  {
    "arxiv_id": "2410.15483v3",
    "title": "Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning",
    "authors": [
      "Heshan Fernando",
      "Han Shen",
      "Parikshit Ram",
      "Yi Zhou",
      "Horst Samulowitz",
      "Nathalie Baracaldo",
      "Tianyi Chen"
    ],
    "abstract": "Post-training of pre-trained LLMs, which typically consists of the supervised\nfine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is\ncrucial to effective and safe LLM applications. The widely adopted approach in\npost-training popular open-source LLMs is to sequentially perform SFT and\nRLHF/DPO. However, sequential training is sub-optimal in terms of SFT and\nRLHF/DPO trade-off: the LLM gradually forgets about the first stage's training\nwhen undergoing the second stage's training. We theoretically prove the\nsub-optimality of sequential post-training. Furthermore, we propose a practical\njoint post-training framework with theoretical convergence guarantees and\nempirically outperforms sequential post-training framework, while having\nsimilar computational cost. Our code is available at\nhttps://github.com/heshandevaka/XRIGHT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15483v3",
    "published_date": "2024-10-20 19:38:41 UTC",
    "updated_date": "2025-02-05 22:57:29 UTC"
  },
  {
    "arxiv_id": "2410.15472v2",
    "title": "Multi-Layer Feature Fusion with Cross-Channel Attention-Based U-Net for Kidney Tumor Segmentation",
    "authors": [
      "Fnu Neha",
      "Arvind K. Bansal"
    ],
    "abstract": "Renal tumors, especially renal cell carcinoma (RCC), show significant\nheterogeneity, posing challenges for diagnosis using radiology images such as\nMRI, echocardiograms, and CT scans. U-Net based deep learning techniques are\nemerging as a promising approach for automated medical image segmentation for\nminimally invasive diagnosis of renal tumors. However, current techniques need\nfurther improvements in accuracy to become clinically useful to radiologists.\nIn this study, we present an improved U-Net based model for end-to-end\nautomated semantic segmentation of CT scan images to identify renal tumors. The\nmodel uses residual connections across convolution layers, integrates a\nmulti-layer feature fusion (MFF) and cross-channel attention (CCA) within\nencoder blocks, and incorporates skip connections augmented with additional\ninformation derived using MFF and CCA. We evaluated our model on the KiTS19\ndataset, which contains data from 210 patients. For kidney segmentation, our\nmodel achieves a Dice Similarity Coefficient (DSC) of 0.97 and a Jaccard index\n(JI) of 0.95. For renal tumor segmentation, our model achieves a DSC of 0.96\nand a JI of 0.91. Based on a comparison of available DSC scores, our model\noutperforms the current leading models.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.15472v2",
    "published_date": "2024-10-20 19:02:41 UTC",
    "updated_date": "2024-10-22 02:59:51 UTC"
  },
  {
    "arxiv_id": "2410.15471v2",
    "title": "Generative Models, Humans, Predictive Models: Who Is Worse at High-Stakes Decision Making?",
    "authors": [
      "Keri Mallari",
      "Julius Adebayo",
      "Kori Inkpen",
      "Martin T. Wells",
      "Albert Gordo",
      "Sarah Tan"
    ],
    "abstract": "Despite strong advisory against it, large generative models (LMs) are already\nbeing used for decision making tasks that were previously done by predictive\nmodels or humans. We put popular LMs to the test in a high-stakes decision\nmaking task: recidivism prediction. Studying three closed-access and\nopen-source LMs, we analyze the LMs not exclusively in terms of accuracy, but\nalso in terms of agreement with (imperfect, noisy, and sometimes biased) human\npredictions or existing predictive models. We conduct experiments that assess\nhow providing different types of information, including distractor information\nsuch as photos, can influence LM decisions. We also stress test techniques\ndesigned to either increase accuracy or mitigate bias in LMs, and find that\nsome to have unintended consequences on LM decisions. Our results provide\nadditional quantitative evidence to the wisdom that current LMs are not the\nright tools for these types of tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15471v2",
    "published_date": "2024-10-20 19:00:59 UTC",
    "updated_date": "2025-02-14 05:41:23 UTC"
  },
  {
    "arxiv_id": "2410.15470v1",
    "title": "Data Augmentation via Diffusion Model to Enhance AI Fairness",
    "authors": [
      "Christina Hastings Blow",
      "Lijun Qian",
      "Camille Gibson",
      "Pamela Obiomon",
      "Xishuang Dong"
    ],
    "abstract": "AI fairness seeks to improve the transparency and explainability of AI\nsystems by ensuring that their outcomes genuinely reflect the best interests of\nusers. Data augmentation, which involves generating synthetic data from\nexisting datasets, has gained significant attention as a solution to data\nscarcity. In particular, diffusion models have become a powerful technique for\ngenerating synthetic data, especially in fields like computer vision. This\npaper explores the potential of diffusion models to generate synthetic tabular\ndata to improve AI fairness. The Tabular Denoising Diffusion Probabilistic\nModel (Tab-DDPM), a diffusion model adaptable to any tabular dataset and\ncapable of handling various feature types, was utilized with different amounts\nof generated data for data augmentation. Additionally, reweighting samples from\nAIF360 was employed to further enhance AI fairness. Five traditional machine\nlearning models-Decision Tree (DT), Gaussian Naive Bayes (GNB), K-Nearest\nNeighbors (KNN), Logistic Regression (LR), and Random Forest (RF)-were used to\nvalidate the proposed approach. Experimental results demonstrate that the\nsynthetic data generated by Tab-DDPM improves fairness in binary\nclassification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2312.12560",
    "pdf_url": "http://arxiv.org/pdf/2410.15470v1",
    "published_date": "2024-10-20 18:52:31 UTC",
    "updated_date": "2024-10-20 18:52:31 UTC"
  },
  {
    "arxiv_id": "2410.15469v1",
    "title": "AssemblyComplete: 3D Combinatorial Construction with Deep Reinforcement Learning",
    "authors": [
      "Alan Chen",
      "Changliu Liu"
    ],
    "abstract": "A critical goal in robotics and autonomy is to teach robots to adapt to\nreal-world collaborative tasks, particularly in automatic assembly. The ability\nof a robot to understand the original intent of an incomplete assembly and\ncomplete missing features without human instruction is valuable but\nchallenging. This paper introduces 3D combinatorial assembly completion, which\nis demonstrated using combinatorial unit primitives (i.e., Lego bricks).\nCombinatorial assembly is challenging due to the possible assembly combinations\nand complex physical constraints (e.g., no brick collisions, structure\nstability, inventory constraints, etc.). To address these challenges, we\npropose a two-part deep reinforcement learning (DRL) framework that tackles\nteaching the robot to understand the objective of an incomplete assembly and\nlearning a construction policy to complete the assembly. The robot queries a\nstable object library to facilitate assembly inference and guide learning. In\naddition to the robot policy, an action mask is developed to rule out invalid\nactions that violate physical constraints for object-oriented construction. We\ndemonstrate the proposed framework's feasibility and robustness in a variety of\nassembly scenarios in which the robot satisfies real-life assembly with respect\nto both solution and runtime quality. Furthermore, results demonstrate that the\nproposed framework effectively infers and assembles incomplete structures for\nunseen and unique object types.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to 2025 American Control Conference (ACC)",
    "pdf_url": "http://arxiv.org/pdf/2410.15469v1",
    "published_date": "2024-10-20 18:51:17 UTC",
    "updated_date": "2024-10-20 18:51:17 UTC"
  },
  {
    "arxiv_id": "2410.15467v1",
    "title": "Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI",
    "authors": [
      "Hangzhi Guo",
      "Pranav Narayanan Venkit",
      "Eunchae Jang",
      "Mukund Srinath",
      "Wenbo Zhang",
      "Bonam Mingole",
      "Vipul Gupta",
      "Kush R. Varshney",
      "S. Shyam Sundar",
      "Amulya Yadav"
    ],
    "abstract": "The widespread adoption of large language models (LLMs) and generative AI\n(GenAI) tools across diverse applications has amplified the importance of\naddressing societal biases inherent within these technologies. While the NLP\ncommunity has extensively studied LLM bias, research investigating how\nnon-expert users perceive and interact with biases from these systems remains\nlimited. As these technologies become increasingly prevalent, understanding\nthis question is crucial to inform model developers in their efforts to\nmitigate bias. To address this gap, this work presents the findings from a\nuniversity-level competition, which challenged participants to design prompts\nfor eliciting biased outputs from GenAI tools. We quantitatively and\nqualitatively analyze the competition submissions and identify a diverse set of\nbiases in GenAI and strategies employed by participants to induce bias in\nGenAI. Our finding provides unique insights into how non-expert users perceive\nand interact with biases from GenAI tools.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15467v1",
    "published_date": "2024-10-20 18:44:45 UTC",
    "updated_date": "2024-10-20 18:44:45 UTC"
  },
  {
    "arxiv_id": "2410.15466v1",
    "title": "Keep Guessing? When Considering Inference Scaling, Mind the Baselines",
    "authors": [
      "Gal Yona",
      "Or Honovich",
      "Omer Levy",
      "Roee Aharoni"
    ],
    "abstract": "Scaling inference compute in large language models (LLMs) through repeated\nsampling consistently increases the coverage (fraction of problems solved) as\nthe number of samples increases. We conjecture that this observed improvement\nis partially due to the answer distribution of standard evaluation benchmarks,\nwhich is skewed towards a relatively small set of common answers. To test this\nconjecture, we define a baseline that enumerates answers according to their\nprevalence in the training set. Experiments spanning two domains --\nmathematical reasoning and factual knowledge -- reveal that this baseline\noutperforms repeated model sampling for some LLMs, while the coverage for\nothers is on par with that of a mixture strategy that obtains $k$ answers by\nusing only $10$ model samples and similarly guessing the remaining $k-10$\nattempts via enumeration. Our baseline enables a more accurate measurement of\nhow much repeated sampling improves coverage in such settings beyond\nprompt-agnostic guessing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15466v1",
    "published_date": "2024-10-20 18:43:05 UTC",
    "updated_date": "2024-10-20 18:43:05 UTC"
  },
  {
    "arxiv_id": "2411.03320v4",
    "title": "log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling",
    "authors": [
      "Xiao Hu",
      "Ziqi Chen",
      "Bo Peng",
      "Daniel Adu-Ampratwum",
      "Xia Ning"
    ],
    "abstract": "Accurate prediction of chemical reaction yields is crucial for optimizing\norganic synthesis, potentially reducing time and resources spent on\nexperimentation. With the rise of artificial intelligence (AI), there is\ngrowing interest in leveraging AI-based methods to accelerate yield predictions\nwithout conducting in vitro experiments. We present log-RRIM, an innovative\ngraph transformer-based framework designed for predicting chemical reaction\nyields. A key feature of log-RRIM is its integration of a cross-attention\nmechanism that focuses on the interplay between reagents and reaction centers.\nThis design reflects a fundamental principle in chemical reactions: the crucial\nrole of reagents in influencing bond-breaking and formation processes, which\nultimately affect reaction yields. log-RRIM also implements a local-to-global\nreaction representation learning strategy. This approach initially captures\ndetailed molecule-level information and then models and aggregates\nintermolecular interactions. Through this hierarchical process, log-RRIM\neffectively captures how different molecular fragments contribute to and\ninfluence the overall reaction yield, regardless of their size variations.\nlog-RRIM shows superior performance in our experiments, especially for medium\nto high-yielding reactions, proving its reliability as a predictor. The\nframework's sophisticated modeling of reactant-reagent interactions and precise\ncapture of molecular fragment contributions make it a valuable tool for\nreaction planning and optimization in chemical synthesis. The data and codes of\nlog-RRIM are accessible through https://github.com/ninglab/Yield_log_RRIM.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "45 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.03320v4",
    "published_date": "2024-10-20 18:35:56 UTC",
    "updated_date": "2025-03-09 03:43:34 UTC"
  },
  {
    "arxiv_id": "2410.15460v3",
    "title": "Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training",
    "authors": [
      "Shahrad Mohammadzadeh",
      "Juan David Guerra",
      "Marco Bonizzato",
      "Reihaneh Rabbany",
      "Golnoosh Farnadi"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed across various\nindustries, concerns regarding their reliability, particularly due to\nhallucinations - outputs that are factually inaccurate or irrelevant to user\ninput - have grown. Our research investigates the relationship between the\ntraining process and the emergence of hallucinations to address a key gap in\nexisting research that focuses primarily on post hoc detection and mitigation\nstrategies. Using models from the Pythia suite (70M - 12B parameters) and\nseveral hallucination detection metrics, we analyze hallucination trends\nthroughout training and explore LLM internal dynamics. We introduce Sensitivity\nDropout (SenD), a novel training protocol designed to mitigate hallucinations\nby reducing variance during training. SenD achieves this by deterministically\ndropping embedding indices with significant variability, referred to as\nSensitive Embedding Indices. In addition, we develop an unsupervised\nhallucination detection metric, Efficient EigenScore (EES), which approximates\nthe traditional EigenScore at 2x speed. This efficient metric is integrated\ninto our protocol, allowing SenD to be both computationally scalable and\neffective at reducing hallucinations. Our empirical evaluation demonstrates\nthat our approach improves LLM reliability at test time by up to 40% compared\nto normal training while also providing an efficient method to improve factual\naccuracy when adapting LLMs to Wikipedia, Medical, and LegalBench domains.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "math.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 15 figures, under review at ICLR, accepted to Safe\n  Generative AI Workshop @ NeurIPS 2024, resubmitting to change name to\n  appropriate name",
    "pdf_url": "http://arxiv.org/pdf/2410.15460v3",
    "published_date": "2024-10-20 18:18:23 UTC",
    "updated_date": "2025-01-07 14:56:42 UTC"
  },
  {
    "arxiv_id": "2410.15449v1",
    "title": "Heterogeneous Graph Reinforcement Learning for Dependency-aware Multi-task Allocation in Spatial Crowdsourcing",
    "authors": [
      "Yong Zhao",
      "Zhengqiu Zhu",
      "Chen Gao",
      "En Wang",
      "Jincai Huang",
      "Fei-Yue Wang"
    ],
    "abstract": "Spatial Crowdsourcing (SC) is gaining traction in both academia and industry,\nwith tasks on SC platforms becoming increasingly complex and requiring\ncollaboration among workers with diverse skills. Recent research works address\ncomplex tasks by dividing them into subtasks with dependencies and assigning\nthem to suitable workers. However, the dependencies among subtasks and their\nheterogeneous skill requirements, as well as the need for efficient utilization\nof workers' limited work time in the multi-task allocation mode, pose\nchallenges in achieving an optimal task allocation scheme. Therefore, this\npaper formally investigates the problem of Dependency-aware Multi-task\nAllocation (DMA) and presents a well-designed framework to solve it, known as\nHeterogeneous Graph Reinforcement Learning-based Task Allocation (HGRL-TA). To\naddress the challenges associated with representing and embedding diverse\nproblem instances to ensure robust generalization, we propose a multi-relation\ngraph model and a Compound-path-based Heterogeneous Graph Attention Network\n(CHANet) for effectively representing and capturing intricate relations among\ntasks and workers, as well as providing embedding of problem state. The task\nallocation decision is determined sequentially by a policy network, which\nundergoes simultaneous training with CHANet using the proximal policy\noptimization algorithm. Extensive experiment results demonstrate the\neffectiveness and generality of the proposed HGRL-TA in solving the DMA\nproblem, leading to average profits that is 21.78% higher than those achieved\nusing the metaheuristic methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15449v1",
    "published_date": "2024-10-20 17:00:45 UTC",
    "updated_date": "2024-10-20 17:00:45 UTC"
  },
  {
    "arxiv_id": "2410.15446v2",
    "title": "Concept Complement Bottleneck Model for Interpretable Medical Image Diagnosis",
    "authors": [
      "Hongmei Wang",
      "Junlin Hou",
      "Hao Chen"
    ],
    "abstract": "Models based on human-understandable concepts have received extensive\nattention to improve model interpretability for trustworthy artificial\nintelligence in the field of medical image analysis. These methods can provide\nconvincing explanations for model decisions but heavily rely on the detailed\nannotation of pre-defined concepts. Consequently, they may not be effective in\ncases where concepts or annotations are incomplete or low-quality. Although\nsome methods automatically discover effective and new visual concepts rather\nthan using pre-defined concepts or could find some human-understandable\nconcepts via large Language models, they are prone to veering away from medical\ndiagnostic evidence and are challenging to understand. In this paper, we\npropose a concept complement bottleneck model for interpretable medical image\ndiagnosis with the aim of complementing the existing concept set and finding\nnew concepts bridging the gap between explainable models. Specifically, we\npropose to use concept adapters for specific concepts to mine the concept\ndifferences and score concepts in their own attention channels to support\nalmost fairly concept learning. Then, we devise a concept complement strategy\nto learn new concepts while jointly using known concepts to improve model\nperformance. Comprehensive experiments on medical datasets demonstrate that our\nmodel outperforms the state-of-the-art competitors in concept detection and\ndisease diagnosis tasks while providing diverse explanations to ensure model\ninterpretability effectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, 5 figures,",
    "pdf_url": "http://arxiv.org/pdf/2410.15446v2",
    "published_date": "2024-10-20 16:52:09 UTC",
    "updated_date": "2024-12-24 04:23:50 UTC"
  },
  {
    "arxiv_id": "2410.15442v1",
    "title": "Exploring Social Desirability Response Bias in Large Language Models: Evidence from GPT-4 Simulations",
    "authors": [
      "Sanguk Lee",
      "Kai-Qi Yang",
      "Tai-Quan Peng",
      "Ruth Heo",
      "Hui Liu"
    ],
    "abstract": "Large language models (LLMs) are employed to simulate human-like responses in\nsocial surveys, yet it remains unclear if they develop biases like social\ndesirability response (SDR) bias. To investigate this, GPT-4 was assigned\npersonas from four societies, using data from the 2022 Gallup World Poll. These\nsynthetic samples were then prompted with or without a commitment statement\nintended to induce SDR. The results were mixed. While the commitment statement\nincreased SDR index scores, suggesting SDR bias, it reduced civic engagement\nscores, indicating an opposite trend. Additional findings revealed demographic\nassociations with SDR scores and showed that the commitment statement had\nlimited impact on GPT-4's predictive performance. The study underscores\npotential avenues for using LLMs to investigate biases in both humans and LLMs\nthemselves.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15442v1",
    "published_date": "2024-10-20 16:28:24 UTC",
    "updated_date": "2024-10-20 16:28:24 UTC"
  },
  {
    "arxiv_id": "2410.15440v1",
    "title": "Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering",
    "authors": [
      "Yanggyu Lee",
      "Jihie Kim"
    ],
    "abstract": "In the realm of Large Language Model (LLM) functionalities, providing\nreliable information is paramount, yet reports suggest that LLM outputs lack\nconsistency. This inconsistency, often at-tributed to randomness in token\nsampling, under-mines user trust as it leads to varying responses even for\nidentical queries. In this paper, we present a new approach for evaluating\nsemantic consistencies of LLM including comparison of alternative tech-niques.\nOur approach evaluates whether LLM re-sponses are semantically congruent for a\ngiven question, recognizing that as syntactically different sentences may\nconvey the same meaning. Here-tofore, To enhance LLM consistency, two main\napproaches have been explored: Leverage external knowledge as context like the\nRAG pattern or use Zero-shot-CoT to improve performance of LLM itself. We apply\nour evaluation approach to these techniques, and demonstrate to compare the\nim-pact of these methods on LLM response con-sistency across different domains\nof question an-swering tasks. Using the TruthfulQA dataset to assess LLM\nresponses, the study induces N re-sponses per question from the LLM and\nclusters semantically equivalent sentences to measure semantic consistency\nacross 37 categories. Through this, it quantitatively analyzes the\neffectiveness of the aforementioned methods in improving LLM performance before\nand after their adoption.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the Trustworthy AI Workshop at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15440v1",
    "published_date": "2024-10-20 16:21:25 UTC",
    "updated_date": "2024-10-20 16:21:25 UTC"
  },
  {
    "arxiv_id": "2411.00802v1",
    "title": "An Improved Chicken Swarm Optimization Algorithm for Handwritten Document Image Enhancement",
    "authors": [
      "Stanley Mugisha",
      "Lynn tar Gutu",
      "P Nagabhushan"
    ],
    "abstract": "Chicken swarm optimization is a new meta-heuristic algorithm which mimics the\nforaging hierarchical behavior of chicken. In this paper, we describe the\npreprocessing of handwritten document by contrast enhancement while preserving\ndetail with an improved chicken swarm optimization algorithm.The results of the\nalgorithm are compared with other existing meta heuristic algorithms like\nCuckoo Search, Firefly Algorithm and the Artificial bee colony. The proposed\nalgorithm considerably outperforms all the above by giving good results.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.4.3"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2411.00802v1",
    "published_date": "2024-10-20 16:10:13 UTC",
    "updated_date": "2024-10-20 16:10:13 UTC"
  },
  {
    "arxiv_id": "2410.15438v1",
    "title": "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs",
    "authors": [
      "Xin Zhou",
      "Ping Nie",
      "Yiwen Guo",
      "Haojie Wei",
      "Zhanqiu Zhang",
      "Pasquale Minervini",
      "Ruotian Ma",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) significantly improved the ability of\nLarge Language Models (LLMs) to solve knowledge-intensive tasks. While existing\nresearch seeks to enhance RAG performance by retrieving higher-quality\ndocuments or designing RAG-specific LLMs, the internal mechanisms within LLMs\nthat contribute to the effectiveness of RAG systems remain underexplored. In\nthis paper, we aim to investigate these internal mechanisms within the popular\nMixture-of-Expert (MoE)-based LLMs and demonstrate how to improve RAG by\nexamining expert activations in these LLMs. Our controlled experiments reveal\nthat several core groups of experts are primarily responsible for RAG-related\nbehaviors. The activation of these core experts can signify the model's\ninclination towards external/internal knowledge and adjust its behavior. For\ninstance, we identify core experts that can (1) indicate the sufficiency of the\nmodel's internal knowledge, (2) assess the quality of retrieved documents, and\n(3) enhance the model's ability to utilize context. Based on these findings, we\npropose several strategies to enhance RAG's efficiency and effectiveness\nthrough expert activation. Experimental results across various datasets and\nMoE-based LLMs show the effectiveness of our method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15438v1",
    "published_date": "2024-10-20 16:08:54 UTC",
    "updated_date": "2024-10-20 16:08:54 UTC"
  },
  {
    "arxiv_id": "2410.15437v1",
    "title": "AttCDCNet: Attention-enhanced Chest Disease Classification using X-Ray Images",
    "authors": [
      "Omar Hesham Khater",
      "Abdullahi Sani Shuaib",
      "Sami Ul Haq",
      "Abdul Jabbar Siddiqui"
    ],
    "abstract": "Chest X-rays (X-ray images) have been proven to be effective for the\ndiagnosis of chest diseases, including Pneumonia, Lung Opacity, and COVID-19.\nHowever, relying on traditional medical methods for diagnosis from X-ray images\nis prone to delays and inaccuracies because the medical personnel who evaluate\nthe X-ray images may have preconceived biases. For this reason, researchers\nhave proposed the use of deep learning-based techniques to facilitate the\ndiagnosis process. The preeminent method is the use of sophisticated\nConvolutional Neural Networks (CNNs). In this paper, we propose a novel\ndetection model named \\textbf{AttCDCNet} for the task of X-ray image diagnosis,\nenhancing the popular DenseNet121 model by adding an attention block to help\nthe model focus on the most relevant regions, using focal loss as a loss\nfunction to overcome the imbalance of the dataset problem, and utilizing\ndepth-wise convolution to reduce the parameters to make the model lighter.\nThrough extensive experimental evaluations, the proposed model demonstrates\nexceptional performance, showing better results than the original DenseNet121.\nThe proposed model achieved an accuracy, precision and recall of 94.94%, 95.14%\nand 94.53%, respectively, on the COVID-19 Radiography Dataset.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15437v1",
    "published_date": "2024-10-20 16:08:20 UTC",
    "updated_date": "2024-10-20 16:08:20 UTC"
  },
  {
    "arxiv_id": "2410.15423v1",
    "title": "Power Plays: Unleashing Machine Learning Magic in Smart Grids",
    "authors": [
      "Abdur Rashid",
      "Parag Biswas",
      "abdullah al masum",
      "MD Abdullah Al Nasim",
      "Kishor Datta Gupta"
    ],
    "abstract": "The integration of machine learning into smart grid systems represents a\ntransformative step in enhancing the efficiency, reliability, and\nsustainability of modern energy networks. By adding advanced data analytics,\nthese systems can better manage the complexities of renewable energy\nintegration, demand response, and predictive maintenance. Machine learning\nalgorithms analyze vast amounts of data from smart meters, sensors, and other\ngrid components to optimize energy distribution, forecast demand, and detect\nirregularities that could indicate potential failures. This enables more\nprecise load balancing, reduces operational costs, and enhances the resilience\nof the grid against disturbances. Furthermore, the use of predictive models\nhelps in anticipating equipment failures, thereby improving the reliability of\nthe energy supply. As smart grids continue to evolve, the role of machine\nlearning in managing decentralized energy sources and enabling real-time\ndecision-making will become increasingly critical. However, the deployment of\nthese technologies also raises challenges related to data privacy, security,\nand the need for robust infrastructure. Addressing these issues in this\nresearch authors will focus on realizing the full potential of smart grids,\nensuring they meet the growing energy demands while maintaining a focus on\nsustainability and efficiency using Machine Learning techniques. Furthermore,\nthis research will help determine the smart grid's essentiality with the aid of\nMachine Learning. Multiple ML algorithms have been integrated along with their\npros and cons. The future scope of these algorithms are also integrated.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.15423v1",
    "published_date": "2024-10-20 15:39:08 UTC",
    "updated_date": "2024-10-20 15:39:08 UTC"
  },
  {
    "arxiv_id": "2410.15420v1",
    "title": "Where to Build Food Banks and Pantries: A Two-Level Machine Learning Approach",
    "authors": [
      "Gavin Ruan",
      "Ziqi Guo",
      "Guang Lin"
    ],
    "abstract": "Over 44 million Americans currently suffer from food insecurity, of whom 13\nmillion are children. Across the United States, thousands of food banks and\npantries serve as vital sources of food and other forms of aid for food\ninsecure families. By optimizing food bank and pantry locations, food would\nbecome more accessible to families who desperately require it. In this work, we\nintroduce a novel two-level optimization framework, which utilizes the\nK-Medoids clustering algorithm in conjunction with the Open-Source Routing\nMachine engine, to optimize food bank and pantry locations based on real road\ndistances to houses and house blocks. Our proposed framework also has the\nadaptability to factor in considerations such as median household income using\na pseudo-weighted K-Medoids algorithm. Testing conducted with California and\nIndiana household data, as well as comparisons with real food bank and pantry\nlocations showed that interestingly, our proposed framework yields food pantry\nlocations superior to those of real existing ones and saves significant\ndistance for households, while there is a marginal penalty on the first level\nfood bank to food pantry distance. Overall, we believe that the second-level\nbenefits of this framework far outweigh any drawbacks and yield a net benefit\nresult.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15420v1",
    "published_date": "2024-10-20 15:31:24 UTC",
    "updated_date": "2024-10-20 15:31:24 UTC"
  },
  {
    "arxiv_id": "2410.15419v1",
    "title": "CASET: Complexity Analysis using Simple Execution Traces for CS* submissions",
    "authors": [
      "Aaryen Mehta",
      "Gagan Aryan"
    ],
    "abstract": "The most common method to auto-grade a student's submission in a CS1 or a CS2\ncourse is to run it against a pre-defined test suite and compare the results\nagainst reference results. However, this technique cannot be used if the\ncorrectness of the solution goes beyond simple output, such as the algorithm\nused to obtain the result. There is no convenient method for the graders to\nidentify the kind of algorithm used in solving a problem. They must read the\nsource code and understand the algorithm implemented and its features, which\nmakes the process tedious. We propose CASET(Complexity Analysis using Simple\nExecution Traces), a novel tool to analyze the time complexity of algorithms\nusing dynamic traces and unsupervised machine learning. CASET makes it\nconvenient for tutors to classify the submissions for a program into time\ncomplexity baskets. Thus, tutors can identify the algorithms used by the\nsubmissions without necessarily going through the code written by the students.\nCASET's analysis can be used to improve grading and provide detailed feedback\nfor submissions that try to match the results without a proper algorithm, for\nexample, hard-coding a binary result, pattern-matching the visible or common\ninputs. We show the effectiveness of CASET by computing the time complexity of\nmany classes of algorithms like sorting, searching and those using dynamic\nprogramming paradigm.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.15419v1",
    "published_date": "2024-10-20 15:29:50 UTC",
    "updated_date": "2024-10-20 15:29:50 UTC"
  },
  {
    "arxiv_id": "2410.15413v1",
    "title": "A Comprehensive Evaluation of Cognitive Biases in LLMs",
    "authors": [
      "Simon Malberg",
      "Roman Poletukhin",
      "Carolin M. Schuster",
      "Georg Groh"
    ],
    "abstract": "We present a large-scale evaluation of 30 cognitive biases in 20\nstate-of-the-art large language models (LLMs) under various decision-making\nscenarios. Our contributions include a novel general-purpose test framework for\nreliable and large-scale generation of tests for LLMs, a benchmark dataset with\n30,000 tests for detecting cognitive biases in LLMs, and a comprehensive\nassessment of the biases found in the 20 evaluated LLMs. Our work confirms and\nbroadens previous findings suggesting the presence of cognitive biases in LLMs\nby reporting evidence of all 30 tested biases in at least some of the 20 LLMs.\nWe publish our framework code to encourage future research on biases in LLMs:\nhttps://github.com/simonmalberg/cognitive-biases-in-llms",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15413v1",
    "published_date": "2024-10-20 15:07:51 UTC",
    "updated_date": "2024-10-20 15:07:51 UTC"
  },
  {
    "arxiv_id": "2410.15409v1",
    "title": "PEAS: A Strategy for Crafting Transferable Adversarial Examples",
    "authors": [
      "Bar Avraham",
      "Yisroel Mirsky"
    ],
    "abstract": "Black box attacks, where adversaries have limited knowledge of the target\nmodel, pose a significant threat to machine learning systems. Adversarial\nexamples generated with a substitute model often suffer from limited\ntransferability to the target model. While recent work explores ranking\nperturbations for improved success rates, these methods see only modest gains.\nWe propose a novel strategy called PEAS that can boost the transferability of\nexisting black box attacks. PEAS leverages the insight that samples which are\nperceptually equivalent exhibit significant variability in their adversarial\ntransferability. Our approach first generates a set of images from an initial\nsample via subtle augmentations. We then evaluate the transferability of\nadversarial perturbations on these images using a set of substitute models.\nFinally, the most transferable adversarial example is selected and used for the\nattack. Our experiments show that PEAS can double the performance of existing\nattacks, achieving a 2.5x improvement in attack success rates on average over\ncurrent ranking methods. We thoroughly evaluate PEAS on ImageNet and CIFAR-10,\nanalyze hyperparameter impacts, and provide an ablation study to isolate each\ncomponent's importance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15409v1",
    "published_date": "2024-10-20 14:55:08 UTC",
    "updated_date": "2024-10-20 14:55:08 UTC"
  },
  {
    "arxiv_id": "2410.15405v1",
    "title": "XAI-based Feature Ensemble for Enhanced Anomaly Detection in Autonomous Driving Systems",
    "authors": [
      "Sazid Nazat",
      "Mustafa Abdallah"
    ],
    "abstract": "The rapid advancement of autonomous vehicle (AV) technology has introduced\nsignificant challenges in ensuring transportation security and reliability.\nTraditional AI models for anomaly detection in AVs are often opaque, posing\ndifficulties in understanding and trusting their decision making processes.\nThis paper proposes a novel feature ensemble framework that integrates multiple\nExplainable AI (XAI) methods: SHAP, LIME, and DALEX with various AI models to\nenhance both anomaly detection and interpretability. By fusing top features\nidentified by these XAI methods across six diverse AI models (Decision Trees,\nRandom Forests, Deep Neural Networks, K Nearest Neighbors, Support Vector\nMachines, and AdaBoost), the framework creates a robust and comprehensive set\nof features critical for detecting anomalies. These feature sets, produced by\nour feature ensemble framework, are evaluated using independent classifiers\n(CatBoost, Logistic Regression, and LightGBM) to ensure unbiased performance.\nWe evaluated our feature ensemble approach on two popular autonomous driving\ndatasets (VeReMi and Sensor) datasets. Our feature ensemble technique\ndemonstrates improved accuracy, robustness, and transparency of AI models,\ncontributing to safer and more trustworthy autonomous driving systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages, 4 figures (including the subfigures)",
    "pdf_url": "http://arxiv.org/pdf/2410.15405v1",
    "published_date": "2024-10-20 14:34:48 UTC",
    "updated_date": "2024-10-20 14:34:48 UTC"
  },
  {
    "arxiv_id": "2410.15403v2",
    "title": "MMDS: A Multimodal Medical Diagnosis System Integrating Image Analysis and Knowledge-based Departmental Consultation",
    "authors": [
      "Yi Ren",
      "HanZhi Zhang",
      "Weibin Li",
      "Jun Fu",
      "Diandong Liu",
      "Tianyi Zhang",
      "Jie He",
      "Licheng Jiao"
    ],
    "abstract": "We present MMDS, a system capable of recognizing medical images and patient\nfacial details, and providing professional medical diagnoses. The system\nconsists of two core components:The first component is the analysis of medical\nimages and videos. We trained a specialized multimodal medical model capable of\ninterpreting medical images and accurately analyzing patients' facial emotions\nand facial paralysis conditions. The model achieved an accuracy of 72.59% on\nthe FER2013 facial emotion recognition dataset, with a 91.1% accuracy in\nrecognizing the \"happy\" emotion. In facial paralysis recognition, the model\nreached an accuracy of 92%, which is 30% higher than that of GPT-4o. Based on\nthis model, we developed a parser for analyzing facial movement videos of\npatients with facial paralysis, achieving precise grading of the paralysis\nseverity. In tests on 30 videos of facial paralysis patients, the system\ndemonstrated a grading accuracy of 83.3%.The second component is the generation\nof professional medical responses. We employed a large language model,\nintegrated with a medical knowledge base, to generate professional diagnoses\nbased on the analysis of medical images or videos. The core innovation lies in\nour development of a department-specific knowledge base routing management\nmechanism, in which the large language model categorizes data by medical\ndepartments and, during the retrieval process, determines the appropriate\nknowledge base to query. This significantly improves retrieval accuracy in the\nRAG (retrieval-augmented generation) process.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15403v2",
    "published_date": "2024-10-20 14:31:05 UTC",
    "updated_date": "2024-11-25 12:48:23 UTC"
  },
  {
    "arxiv_id": "2410.15396v1",
    "title": "The Best Defense is a Good Offense: Countering LLM-Powered Cyberattacks",
    "authors": [
      "Daniel Ayzenshteyn",
      "Roy Weiss",
      "Yisroel Mirsky"
    ],
    "abstract": "As large language models (LLMs) continue to evolve, their potential use in\nautomating cyberattacks becomes increasingly likely. With capabilities such as\nreconnaissance, exploitation, and command execution, LLMs could soon become\nintegral to autonomous cyber agents, capable of launching highly sophisticated\nattacks. In this paper, we introduce novel defense strategies that exploit the\ninherent vulnerabilities of attacking LLMs. By targeting weaknesses such as\nbiases, trust in input, memory limitations, and their tunnel-vision approach to\nproblem-solving, we develop techniques to mislead, delay, or neutralize these\nautonomous agents. We evaluate our defenses under black-box conditions,\nstarting with single prompt-response scenarios and progressing to real-world\ntests using custom-built CTF machines. Our results show defense success rates\nof up to 90\\%, demonstrating the effectiveness of turning LLM vulnerabilities\ninto defensive strategies against LLM-driven cyber threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15396v1",
    "published_date": "2024-10-20 14:07:24 UTC",
    "updated_date": "2024-10-20 14:07:24 UTC"
  },
  {
    "arxiv_id": "2410.15379v1",
    "title": "Synthetic Data Generation for Residential Load Patterns via Recurrent GAN and Ensemble Method",
    "authors": [
      "Xinyu Liang",
      "Ziheng Wang",
      "Hao Wang"
    ],
    "abstract": "Generating synthetic residential load data that can accurately represent\nactual electricity consumption patterns is crucial for effective power system\nplanning and operation. The necessity for synthetic data is underscored by the\ninherent challenges associated with using real-world load data, such as privacy\nconsiderations and logistical complexities in large-scale data collection. In\nthis work, we tackle the above-mentioned challenges by developing the Ensemble\nRecurrent Generative Adversarial Network (ERGAN) framework to generate\nhigh-fidelity synthetic residential load data. ERGAN leverages an ensemble of\nrecurrent Generative Adversarial Networks, augmented by a loss function that\nconcurrently takes into account adversarial loss and differences between\nstatistical properties. Our developed ERGAN can capture diverse load patterns\nacross various households, thereby enhancing the realism and diversity of the\nsynthetic data generated. Comprehensive evaluations demonstrate that our method\nconsistently outperforms established benchmarks in the synthetic generation of\nresidential load data across various performance metrics including diversity,\nsimilarity, and statistical measures. The findings confirm the potential of\nERGAN as an effective tool for energy applications requiring synthetic yet\nrealistic load data. We also make the generated synthetic residential load\npatterns publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.15379v1",
    "published_date": "2024-10-20 12:33:38 UTC",
    "updated_date": "2024-10-20 12:33:38 UTC"
  },
  {
    "arxiv_id": "2410.15374v1",
    "title": "Explainability of Point Cloud Neural Networks Using SMILE: Statistical Model-Agnostic Interpretability with Local Explanations",
    "authors": [
      "Seyed Mohammad Ahmadi",
      "Koorosh Aslansefat",
      "Ruben Valcarce-Dineiro",
      "Joshua Barnfather"
    ],
    "abstract": "In today's world, the significance of explainable AI (XAI) is growing in\nrobotics and point cloud applications, as the lack of transparency in\ndecision-making can pose considerable safety risks, particularly in autonomous\nsystems. As these technologies are integrated into real-world environments,\nensuring that model decisions are interpretable and trustworthy is vital for\noperational reliability and safety assurance. This study explores the\nimplementation of SMILE, a novel explainability method originally designed for\ndeep neural networks, on point cloud-based models. SMILE builds on LIME by\nincorporating Empirical Cumulative Distribution Function (ECDF) statistical\ndistances, offering enhanced robustness and interpretability, particularly when\nthe Anderson-Darling distance is used. The approach demonstrates superior\nperformance in terms of fidelity loss, R2 scores, and robustness across various\nkernel widths, perturbation numbers, and clustering configurations. Moreover,\nthis study introduces a stability analysis for point cloud data using the\nJaccard index, establishing a new benchmark and baseline for model stability in\nthis field. The study further identifies dataset biases in the classification\nof the 'person' category, emphasizing the necessity for more comprehensive\ndatasets in safety-critical applications like autonomous driving and robotics.\nThe results underscore the potential of advanced explainability models and\nhighlight areas for future research, including the application of alternative\nsurrogate models and explainability techniques in point cloud data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15374v1",
    "published_date": "2024-10-20 12:13:59 UTC",
    "updated_date": "2024-10-20 12:13:59 UTC"
  },
  {
    "arxiv_id": "2410.15371v1",
    "title": "FrameBridge: Improving Image-to-Video Generation with Bridge Models",
    "authors": [
      "Yuji Wang",
      "Zehua Chen",
      "Xiaoyu Chen",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "abstract": "Image-to-video (I2V) generation is gaining increasing attention with its wide\napplication in video synthesis. Recently, diffusion-based I2V models have\nachieved remarkable progress given their novel design on network architecture,\ncascaded framework, and motion representation. However, restricted by their\nnoise-to-data generation process, diffusion-based methods inevitably suffer the\ndifficulty to generate video samples with both appearance consistency and\ntemporal coherence from an uninformative Gaussian noise, which may limit their\nsynthesis quality. In this work, we present FrameBridge, taking the given\nstatic image as the prior of video target and establishing a tractable bridge\nmodel between them. By formulating I2V synthesis as a frames-to-frames\ngeneration task and modelling it with a data-to-data process, we fully exploit\nthe information in input image and facilitate the generative model to learn the\nimage animation process. In two popular settings of training I2V models, namely\nfine-tuning a pre-trained text-to-video (T2V) model or training from scratch,\nwe further propose two techniques, SNR-Aligned Fine-tuning (SAF) and neural\nprior, which improve the fine-tuning efficiency of diffusion-based T2V models\nto FrameBridge and the synthesis quality of bridge-based I2V models\nrespectively. Experiments conducted on WebVid-2M and UCF-101 demonstrate that:\n(1) our FrameBridge achieves superior I2V quality in comparison with the\ndiffusion counterpart (zero-shot FVD 83 vs. 176 on MSR-VTT and non-zero-shot\nFVD 122 vs. 171 on UCF-101); (2) our proposed SAF and neural prior effectively\nenhance the ability of bridge-based I2V models in the scenarios of fine-tuning\nand training from scratch. Demo samples can be visited at:\nhttps://framebridge-demo.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15371v1",
    "published_date": "2024-10-20 12:10:24 UTC",
    "updated_date": "2024-10-20 12:10:24 UTC"
  },
  {
    "arxiv_id": "2410.15369v1",
    "title": "Ethical AI in Retail: Consumer Privacy and Fairness",
    "authors": [
      "Anthonette Adanyin"
    ],
    "abstract": "The adoption of artificial intelligence (AI) in retail has significantly\ntransformed the industry, enabling more personalized services and efficient\noperations. However, the rapid implementation of AI technologies raises ethical\nconcerns, particularly regarding consumer privacy and fairness. This study aims\nto analyze the ethical challenges of AI applications in retail, explore ways\nretailers can implement AI technologies ethically while remaining competitive,\nand provide recommendations on ethical AI practices. A descriptive survey\ndesign was used to collect data from 300 respondents across major e-commerce\nplatforms. Data were analyzed using descriptive statistics, including\npercentages and mean scores. Findings shows a high level of concerns among\nconsumers regarding the amount of personal data collected by AI-driven retail\napplications, with many expressing a lack of trust in how their data is\nmanaged. Also, fairness is another major issue, as a majority believe AI\nsystems do not treat consumers equally, raising concerns about algorithmic\nbias. It was also found that AI can enhance business competitiveness and\nefficiency without compromising ethical principles, such as data privacy and\nfairness. Data privacy and transparency were highlighted as critical areas\nwhere retailers need to focus their efforts, indicating a strong demand for\nstricter data protection protocols and ongoing scrutiny of AI systems. The\nstudy concludes that retailers must prioritize transparency, fairness, and data\nprotection when deploying AI systems. The study recommends ensuring\ntransparency in AI processes, conducting regular audits to address biases,\nincorporating consumer feedback in AI development, and emphasizing consumer\ndata privacy.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "17 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.15369v1",
    "published_date": "2024-10-20 12:00:14 UTC",
    "updated_date": "2024-10-20 12:00:14 UTC"
  },
  {
    "arxiv_id": "2410.15362v1",
    "title": "Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models",
    "authors": [
      "Xiao Li",
      "Zhuhong Li",
      "Qiongxiu Li",
      "Bingze Lee",
      "Jinghao Cui",
      "Xiaolin Hu"
    ],
    "abstract": "Aligned Large Language Models (LLMs) have demonstrated remarkable performance\nacross various tasks. However, LLMs remain susceptible to jailbreak adversarial\nattacks, where adversaries manipulate prompts to elicit malicious responses\nthat aligned LLMs should have avoided. Identifying these vulnerabilities is\ncrucial for understanding the inherent weaknesses of LLMs and preventing their\npotential misuse. One pioneering work in jailbreaking is the GCG attack, a\ndiscrete token optimization algorithm that seeks to find a suffix capable of\njailbreaking aligned LLMs. Despite the success of GCG, we find it suboptimal,\nrequiring significantly large computational costs, and the achieved\njailbreaking performance is limited. In this work, we propose Faster-GCG, an\nefficient adversarial jailbreak method by delving deep into the design of GCG.\nExperiments demonstrate that Faster-GCG can surpass the original GCG with only\n1/10 of the computational cost, achieving significantly higher attack success\nrates on various open-source aligned LLMs. In addition, We demonstrate that\nFaster-GCG exhibits improved attack transferability when testing on\nclosed-sourced LLMs such as ChatGPT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15362v1",
    "published_date": "2024-10-20 11:27:41 UTC",
    "updated_date": "2024-10-20 11:27:41 UTC"
  },
  {
    "arxiv_id": "2410.15359v1",
    "title": "A Survey of Hallucination in Large Visual Language Models",
    "authors": [
      "Wei Lan",
      "Wenyi Chen",
      "Qingfeng Chen",
      "Shirui Pan",
      "Huiyu Zhou",
      "Yi Pan"
    ],
    "abstract": "The Large Visual Language Models (LVLMs) enhances user interaction and\nenriches user experience by integrating visual modality on the basis of the\nLarge Language Models (LLMs). It has demonstrated their powerful information\nprocessing and generation capabilities. However, the existence of\nhallucinations has limited the potential and practical effectiveness of LVLM in\nvarious fields. Although lots of work has been devoted to the issue of\nhallucination mitigation and correction, there are few reviews to summary this\nissue. In this survey, we first introduce the background of LVLMs and\nhallucinations. Then, the structure of LVLMs and main causes of hallucination\ngeneration are introduced. Further, we summary recent works on hallucination\ncorrection and mitigation. In addition, the available hallucination evaluation\nbenchmarks for LVLMs are presented from judgmental and generative perspectives.\nFinally, we suggest some future research directions to enhance the\ndependability and utility of LVLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15359v1",
    "published_date": "2024-10-20 10:58:58 UTC",
    "updated_date": "2024-10-20 10:58:58 UTC"
  },
  {
    "arxiv_id": "2410.15355v1",
    "title": "LAC: Graph Contrastive Learning with Learnable Augmentation in Continuous Space",
    "authors": [
      "Zhenyu Lin",
      "Hongzheng Li",
      "Yingxia Shao",
      "Guanhua Ye",
      "Yawen Li",
      "Quanqing Xu"
    ],
    "abstract": "Graph Contrastive Learning frameworks have demonstrated success in generating\nhigh-quality node representations.\n  The existing research on efficient data augmentation methods and ideal\npretext tasks for graph contrastive learning remains limited, resulting in\nsuboptimal node representation in the unsupervised setting.\n  In this paper, we introduce LAC, a graph contrastive learning framework with\nlearnable data augmentation in an orthogonal continuous space. To capture the\nrepresentative information in the graph data during augmentation, we introduce\na continuous view augmenter, that applies both a masked topology augmentation\nmodule and a cross-channel feature augmentation module to adaptively augment\nthe topological information and the feature information within an orthogonal\ncontinuous space, respectively. The orthogonal nature of continuous space\nensures that the augmentation process avoids dimension collapse.\n  To enhance the effectiveness of pretext tasks, we propose an\ninformation-theoretic principle named InfoBal and introduce corresponding\npretext tasks. These tasks enable the continuous view augmenter to maintain\nconsistency in the representative information across views while maximizing\ndiversity between views, and allow the encoder to fully utilize the\nrepresentative information in the unsupervised setting. Our experimental\nresults show that LAC significantly outperforms the state-of-the-art\nframeworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15355v1",
    "published_date": "2024-10-20 10:47:15 UTC",
    "updated_date": "2024-10-20 10:47:15 UTC"
  },
  {
    "arxiv_id": "2410.15346v2",
    "title": "YOLO-RD: Introducing Relevant and Compact Explicit Knowledge to YOLO by Retriever-Dictionary",
    "authors": [
      "Hao-Tang Tsui",
      "Chien-Yao Wang",
      "Hong-Yuan Mark Liao"
    ],
    "abstract": "Identifying and localizing objects within images is a fundamental challenge,\nand numerous efforts have been made to enhance model accuracy by experimenting\nwith diverse architectures and refining training strategies. Nevertheless, a\nprevalent limitation in existing models is overemphasizing the current input\nwhile ignoring the information from the entire dataset. We introduce an\ninnovative Retriever-Dictionary (RD) module to address this issue. This\narchitecture enables YOLO-based models to efficiently retrieve features from a\nDictionary that contains the insight of the dataset, which is built by the\nknowledge from Visual Models (VM), Large Language Models (LLM), or Visual\nLanguage Models (VLM). The flexible RD enables the model to incorporate such\nexplicit knowledge that enhances the ability to benefit multiple tasks,\nspecifically, segmentation, detection, and classification, from pixel to image\nlevel. The experiments show that using the RD significantly improves model\nperformance, achieving more than a 3\\% increase in mean Average Precision for\nobject detection with less than a 1% increase in model parameters. Beyond\n1-stage object detection models, the RD module improves the effectiveness of\n2-stage models and DETR-based architectures, such as Faster R-CNN and\nDeformable DETR. Code is released at https://github.com/henrytsui000/YOLO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15346v2",
    "published_date": "2024-10-20 09:38:58 UTC",
    "updated_date": "2025-02-08 10:50:55 UTC"
  },
  {
    "arxiv_id": "2410.15343v1",
    "title": "POSE: Pose estimation Of virtual Sync Exhibit system",
    "authors": [
      "Hao-Tang Tsui",
      "Yu-Rou Tuan",
      "Jia-You Chen"
    ],
    "abstract": "This work is a portable MetaVerse implementation, and we use 3D pose\nestimation with AI to make virtual avatars do synchronized actions and interact\nwith the environment. The motivation is that we find it inconvenient to use\njoysticks and sensors when playing with fitness rings. In order to replace\njoysticks and reduce costs, we developed a platform that can control virtual\navatars through pose estimation to identify the movements of real people, and\nwe also implemented a multi-process to achieve modularization and reduce the\noverall latency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15343v1",
    "published_date": "2024-10-20 09:34:15 UTC",
    "updated_date": "2024-10-20 09:34:15 UTC"
  },
  {
    "arxiv_id": "2410.15341v1",
    "title": "IKDP: Inverse Kinematics through Diffusion Process",
    "authors": [
      "Hao-Tang Tsui",
      "Yu-Rou Tuan",
      "Hong-Han Shuai"
    ],
    "abstract": "It is a common problem in robotics to specify the position of each joint of\nthe robot so that the endpoint reaches a certain target in space. This can be\nsolved in two ways, forward kinematics method and inverse kinematics method.\nHowever, inverse kinematics cannot be solved by an algorithm. The common method\nis the Jacobian inverse technique, and some people have tried to find the\nanswer by machine learning. In this project, we will show how to use the\nConditional Denoising Diffusion Probabilistic Model to integrate the solution\nof calculating IK. Index Terms: Inverse kinematics, Denoising Diffusion\nProbabilistic Model, self Attention, Transformer",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15341v1",
    "published_date": "2024-10-20 09:21:04 UTC",
    "updated_date": "2024-10-20 09:21:04 UTC"
  },
  {
    "arxiv_id": "2410.15322v2",
    "title": "FoMo: A Foundation Model for Mobile Traffic Forecasting with Diffusion Model",
    "authors": [
      "Haoye Chai",
      "Xiaoqian Qi",
      "Shiyuan Zhang",
      "Yong Li"
    ],
    "abstract": "Mobile traffic forecasting allows operators to anticipate network dynamics\nand performance in advance, offering substantial potential for enhancing\nservice quality and improving user experience. However, existing models are\noften task-oriented and are trained with tailored data, which limits their\neffectiveness in diverse mobile network tasks of Base Station (BS) deployment,\nresource allocation, energy optimization, etc. and hinders generalization\nacross different urban environments. Foundation models have made remarkable\nstrides across various domains of NLP and CV due to their multi-tasking\nadaption and zero/few-shot learning capabilities. In this paper, we propose an\ninnovative Foundation model for Mo}bile traffic forecasting (FoMo), aiming to\nhandle diverse forecasting tasks of short/long-term predictions and\ndistribution generation across multiple cities to support network planning and\noptimization. FoMo combines diffusion models and transformers, where various\nspatio-temporal masks are proposed to enable FoMo to learn intrinsic features\nof different tasks, and a contrastive learning strategy is developed to capture\nthe correlations between mobile traffic and urban contexts, thereby improving\nits transfer learning capability. Extensive experiments on 9 real-world\ndatasets demonstrate that FoMo outperforms current models concerning diverse\nforecasting tasks and zero/few-shot learning, showcasing a strong universality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15322v2",
    "published_date": "2024-10-20 07:32:16 UTC",
    "updated_date": "2025-01-14 06:59:12 UTC"
  },
  {
    "arxiv_id": "2410.15319v1",
    "title": "Causality for Large Language Models",
    "authors": [
      "Anpeng Wu",
      "Kun Kuang",
      "Minqin Zhu",
      "Yingrong Wang",
      "Yujia Zheng",
      "Kairong Han",
      "Baohong Li",
      "Guangyi Chen",
      "Fei Wu",
      "Kun Zhang"
    ],
    "abstract": "Recent breakthroughs in artificial intelligence have driven a paradigm shift,\nwhere large language models (LLMs) with billions or trillions of parameters are\ntrained on vast datasets, achieving unprecedented success across a series of\nlanguage tasks. However, despite these successes, LLMs still rely on\nprobabilistic modeling, which often captures spurious correlations rooted in\nlinguistic patterns and social stereotypes, rather than the true causal\nrelationships between entities and events. This limitation renders LLMs\nvulnerable to issues such as demographic biases, social stereotypes, and LLM\nhallucinations. These challenges highlight the urgent need to integrate\ncausality into LLMs, moving beyond correlation-driven paradigms to build more\nreliable and ethically aligned AI systems.\n  While many existing surveys and studies focus on utilizing prompt engineering\nto activate LLMs for causal knowledge or developing benchmarks to assess their\ncausal reasoning abilities, most of these efforts rely on human intervention to\nactivate pre-trained models. How to embed causality into the training process\nof LLMs and build more general and intelligent models remains unexplored.\nRecent research highlights that LLMs function as causal parrots, capable of\nreciting causal knowledge without truly understanding or applying it. These\nprompt-based methods are still limited to human interventional improvements.\nThis survey aims to address this gap by exploring how causality can enhance\nLLMs at every stage of their lifecycle-from token embedding learning and\nfoundation model training to fine-tuning, alignment, inference, and\nevaluation-paving the way for more interpretable, reliable, and\ncausally-informed models. Additionally, we further outline six promising future\ndirections to advance LLM development, enhance their causal reasoning\ncapabilities, and address the current limitations these models face.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15319v1",
    "published_date": "2024-10-20 07:22:23 UTC",
    "updated_date": "2024-10-20 07:22:23 UTC"
  },
  {
    "arxiv_id": "2410.15318v1",
    "title": "SNAP: Stopping Catastrophic Forgetting in Hebbian Learning with Sigmoidal Neuronal Adaptive Plasticity",
    "authors": [
      "Tianyi Xu",
      "Patrick Zheng",
      "Shiyan Liu",
      "Sicheng Lyu",
      "Isabeau Pr√©mont-Schwarz"
    ],
    "abstract": "Artificial Neural Networks (ANNs) suffer from catastrophic forgetting, where\nthe learning of new tasks causes the catastrophic forgetting of old tasks.\nExisting Machine Learning (ML) algorithms, including those using Stochastic\nGradient Descent (SGD) and Hebbian Learning typically update their weights\nlinearly with experience i.e., independently of their current strength. This\ncontrasts with biological neurons, which at intermediate strengths are very\nplastic, but consolidate with Long-Term Potentiation (LTP) once they reach a\ncertain strength. We hypothesize this mechanism might help mitigate\ncatastrophic forgetting. We introduce Sigmoidal Neuronal Adaptive Plasticity\n(SNAP) an artificial approximation to Long-Term Potentiation for ANNs by having\nthe weights follow a sigmoidal growth behaviour allowing the weights to\nconsolidate and stabilize when they reach sufficiently large or small values.\nWe then compare SNAP to linear weight growth and exponential weight growth and\nsee that SNAP completely prevents the forgetting of previous tasks for Hebbian\nLearning but not for SGD-base learning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, 11 figures, accepted at Montr\\'eal AI and Neuroscience\n  (MAIN) 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2410.15318v1",
    "published_date": "2024-10-20 07:20:33 UTC",
    "updated_date": "2024-10-20 07:20:33 UTC"
  },
  {
    "arxiv_id": "2410.15312v1",
    "title": "Synergistic Dual Spatial-aware Generation of Image-to-Text and Text-to-Image",
    "authors": [
      "Yu Zhao",
      "Hao Fei",
      "Xiangtai Li",
      "Libo Qin",
      "Jiayi Ji",
      "Hongyuan Zhu",
      "Meishan Zhang",
      "Min Zhang",
      "Jianguo Wei"
    ],
    "abstract": "In the visual spatial understanding (VSU) area, spatial image-to-text (SI2T)\nand spatial text-to-image (ST2I) are two fundamental tasks that appear in dual\nform. Existing methods for standalone SI2T or ST2I perform imperfectly in\nspatial understanding, due to the difficulty of 3D-wise spatial feature\nmodeling. In this work, we consider modeling the SI2T and ST2I together under a\ndual learning framework. During the dual framework, we then propose to\nrepresent the 3D spatial scene features with a novel 3D scene graph (3DSG)\nrepresentation that can be shared and beneficial to both tasks. Further,\ninspired by the intuition that the easier 3D$\\to$image and 3D$\\to$text\nprocesses also exist symmetrically in the ST2I and SI2T, respectively, we\npropose the Spatial Dual Discrete Diffusion (SD$^3$) framework, which utilizes\nthe intermediate features of the 3D$\\to$X processes to guide the hard X$\\to$3D\nprocesses, such that the overall ST2I and SI2T will benefit each other. On the\nvisual spatial understanding dataset VSD, our system outperforms the mainstream\nT2I and I2T methods significantly. Further in-depth analysis reveals how our\ndual learning strategy advances.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15312v1",
    "published_date": "2024-10-20 06:47:34 UTC",
    "updated_date": "2024-10-20 06:47:34 UTC"
  },
  {
    "arxiv_id": "2410.15311v1",
    "title": "Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game",
    "authors": [
      "Ruiqi Dong",
      "Zhixuan Liao",
      "Guangwei Lai",
      "Yuhan Ma",
      "Danni Ma",
      "Chenyou Fan"
    ],
    "abstract": "Large Language Models (LLMs) are pivotal AI agents in complex tasks but still\nface challenges in open decision-making problems within complex scenarios. To\naddress this, we use the language logic game ``Who is Undercover?'' (WIU) as an\nexperimental platform to propose the Multi-Perspective Team Tactic (MPTT)\nframework. MPTT aims to cultivate LLMs' human-like language expression logic,\nmulti-dimensional thinking, and self-perception in complex scenarios. By\nalternating speaking and voting sessions, integrating techniques like\nself-perspective, identity-determination, self-reflection, self-summary and\nmulti-round find-teammates, LLM agents make rational decisions through\nstrategic concealment and communication, fostering human-like trust.\nPreliminary results show that MPTT, combined with WIU, leverages LLMs'\ncognitive capabilities to create a decision-making framework that can simulate\nreal society. This framework aids minority groups in communication and\nexpression, promoting fairness and diversity in decision-making. Additionally,\nour Human-in-the-loop experiments demonstrate that LLMs can learn and align\nwith human behaviors through interactive, indicating their potential for active\nparticipation in societal decision-making.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15311v1",
    "published_date": "2024-10-20 06:41:31 UTC",
    "updated_date": "2024-10-20 06:41:31 UTC"
  },
  {
    "arxiv_id": "2410.15308v2",
    "title": "LlamaLens: Specialized Multilingual LLM for Analyzing News and Social Media Content",
    "authors": [
      "Mohamed Bayan Kmainasi",
      "Ali Ezzat Shahroor",
      "Maram Hasanain",
      "Sahinur Rahman Laskar",
      "Naeemul Hassan",
      "Firoj Alam"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable success as\ngeneral-purpose task solvers across various fields. However, their capabilities\nremain limited when addressing domain-specific problems, particularly in\ndownstream NLP tasks. Research has shown that models fine-tuned on\ninstruction-based downstream NLP datasets outperform those that are not\nfine-tuned. While most efforts in this area have primarily focused on\nresource-rich languages like English and broad domains, little attention has\nbeen given to multilingual settings and specific domains. To address this gap,\nthis study focuses on developing a specialized LLM, LlamaLens, for analyzing\nnews and social media content in a multilingual context. To the best of our\nknowledge, this is the first attempt to tackle both domain specificity and\nmultilinguality, with a particular focus on news and social media. Our\nexperimental setup includes 18 tasks, represented by 52 datasets covering\nArabic, English, and Hindi. We demonstrate that LlamaLens outperforms the\ncurrent state-of-the-art (SOTA) on 23 testing sets, and achieves comparable\nperformance on 8 sets. We make the models and resources publicly available for\nthe research community\n(https://huggingface.co/collections/QCRI/llamalens-672f7e0604a0498c6a2f0fe9).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "LLMs, Multilingual, Language Diversity, Large Language Models, Social\n  Media, News Media, Specialized LLMs, Fact-checking, Media Analysis, Arabic,\n  Hindi, English",
    "pdf_url": "http://arxiv.org/pdf/2410.15308v2",
    "published_date": "2024-10-20 06:37:37 UTC",
    "updated_date": "2025-02-27 07:01:29 UTC"
  },
  {
    "arxiv_id": "2410.15297v2",
    "title": "Redefining Proactivity for Information Seeking Dialogue",
    "authors": [
      "Jing Yang Lee",
      "Seokhwan Kim",
      "Kartik Mehta",
      "Jiun-Yu Kao",
      "Yu-Hsiang Lin",
      "Arpit Gupta"
    ],
    "abstract": "Information-Seeking Dialogue (ISD) agents aim to provide accurate responses\nto user queries. While proficient in directly addressing user queries, these\nagents, as well as LLMs in general, predominantly exhibit reactive behavior,\nlacking the ability to generate proactive responses that actively engage users\nin sustained conversations. However, existing definitions of proactive dialogue\nin this context do not focus on how each response actively engages the user and\nsustains the conversation. Hence, we present a new definition of proactivity\nthat focuses on enhancing the `proactiveness' of each generated response via\nthe introduction of new information related to the initial query. To this end,\nwe construct a proactive dialogue dataset comprising 2,000 single-turn\nconversations, and introduce several automatic metrics to evaluate response\n`proactiveness' which achieved high correlation with human annotation.\nAdditionally, we introduce two innovative Chain-of-Thought (CoT) prompts, the\n3-step CoT and the 3-in-1 CoT prompts, which consistently outperform standard\nprompts by up to 90% in the zero-shot setting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15297v2",
    "published_date": "2024-10-20 05:57:10 UTC",
    "updated_date": "2024-11-18 02:13:31 UTC"
  },
  {
    "arxiv_id": "2410.15293v1",
    "title": "Fractional-order spike-timing-dependent gradient descent for multi-layer spiking neural networks",
    "authors": [
      "Yi Yang",
      "Richard M. Voyles",
      "Haiyan H. Zhang",
      "Robert A. Nawrocki"
    ],
    "abstract": "Accumulated detailed knowledge about the neuronal activities in human brains\nhas brought more attention to bio-inspired spiking neural networks (SNNs). In\ncontrast to non-spiking deep neural networks (DNNs), SNNs can encode and\ntransmit spatiotemporal information more efficiently by exploiting biologically\nrealistic and low-power event-driven neuromorphic architectures. However, the\nsupervised learning of SNNs still remains a challenge because the\nspike-timing-dependent plasticity (STDP) of connected spiking neurons is\ndifficult to implement and interpret in existing backpropagation learning\nschemes. This paper proposes a fractional-order spike-timing-dependent gradient\ndescent (FO-STDGD) learning model by considering a derived nonlinear activation\nfunction that describes the relationship between the quasi-instantaneous firing\nrate and the temporal membrane potentials of nonleaky integrate-and-fire\nneurons. The training strategy can be generalized to any fractional orders\nbetween 0 and 2 since the FO-STDGD incorporates the fractional gradient descent\nmethod into the calculation of spike-timing-dependent loss gradients. The\nproposed FO-STDGD model is tested on the MNIST and DVS128 Gesture datasets and\nits accuracy under different network structure and fractional orders is\nanalyzed. It can be found that the classification accuracy increases as the\nfractional order increases, and specifically, the case of fractional order 1.9\nimproves by 155% relative to the case of fractional order 1 (traditional\ngradient descent). In addition, our scheme demonstrates the state-of-the-art\ncomputational efficacy for the same SNN structure and training epochs.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "15 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15293v1",
    "published_date": "2024-10-20 05:31:34 UTC",
    "updated_date": "2024-10-20 05:31:34 UTC"
  },
  {
    "arxiv_id": "2410.15285v2",
    "title": "Contextual Augmented Multi-Model Programming (CAMP): A Hybrid Local-Cloud Copilot Framework",
    "authors": [
      "Yuchen Wang",
      "Shangxin Guo",
      "Chee Wei Tan"
    ],
    "abstract": "The advancements in cloud-based Large Languages Models (LLMs) have\nrevolutionized AI-assisted programming. However, their integration into certain\nlocal development environments like ones within the Apple software ecosystem\n(e.g., iOS apps, macOS) remains challenging due to computational demands and\nsandboxed constraints. This paper presents CAMP, a multi-model AI-assisted\nprogramming framework that consists of a local model that employs\nRetrieval-Augmented Generation (RAG) to retrieve contextual information from\nthe codebase to facilitate context-aware prompt construction thus optimizing\nthe performance of the cloud model, empowering LLMs' capabilities in local\nIntegrated Development Environments (IDEs). The methodology is actualized in\nCopilot for Xcode, an AI-assisted programming tool crafted for Xcode that\nemploys the RAG module to address software constraints and enables diverse\ngenerative programming tasks, including automatic code completion,\ndocumentation, error detection, and intelligent user-agent interaction. The\nresults from objective experiments on generated code quality and subjective\nexperiments on user adoption collectively demonstrate the pilot success of the\nproposed system and mark its significant contributions to the realm of\nAI-assisted programming.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work is accepted to IEEE CAI2025",
    "pdf_url": "http://arxiv.org/pdf/2410.15285v2",
    "published_date": "2024-10-20 04:51:24 UTC",
    "updated_date": "2025-04-05 08:48:48 UTC"
  },
  {
    "arxiv_id": "2410.15281v3",
    "title": "Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Experiments, and Challenges",
    "authors": [
      "Can Cui",
      "Yunsheng Ma",
      "Zichong Yang",
      "Yupeng Zhou",
      "Peiran Liu",
      "Juanwu Lu",
      "Lingxi Li",
      "Yaobin Chen",
      "Jitesh H. Panchal",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han",
      "Ziran Wang"
    ],
    "abstract": "With the broader usage and highly successful development of Large Language\nModels (LLMs), there has been a growth of interest and demand for applying LLMs\nto autonomous driving technology. Driven by their natural language\nunderstanding and reasoning ability, LLMs have the potential to enhance various\naspects of autonomous driving systems, from perception and scene understanding\nto language interaction and decision-making. In this paper, we first introduce\nthe novel concept of designing LLMs for autonomous driving (LLM4AD). Then, we\npropose a comprehensive benchmark for evaluating the instruction-following\nabilities of LLM4AD in simulation. Furthermore, we conduct a series of\nexperiments on real-world vehicle platforms, thoroughly evaluating the\nperformance and potential of our LLM4AD systems. Finally, we envision the main\nchallenges of LLM4AD, including latency, deployment, security and privacy,\nsafety, trust and transparency, and personalization. Our research highlights\nthe significant potential of LLMs to enhance various aspects of autonomous\nvehicle technology, from perception and scene understanding to language\ninteraction and decision-making.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15281v3",
    "published_date": "2024-10-20 04:36:19 UTC",
    "updated_date": "2025-02-20 03:39:53 UTC"
  },
  {
    "arxiv_id": "2410.15279v1",
    "title": "ContextDet: Temporal Action Detection with Adaptive Context Aggregation",
    "authors": [
      "Ning Wang",
      "Yun Xiao",
      "Xiaopeng Peng",
      "Xiaojun Chang",
      "Xuanhong Wang",
      "Dingyi Fang"
    ],
    "abstract": "Temporal action detection (TAD), which locates and recognizes action\nsegments, remains a challenging task in video understanding due to variable\nsegment lengths and ambiguous boundaries. Existing methods treat neighboring\ncontexts of an action segment indiscriminately, leading to imprecise boundary\npredictions. We introduce a single-stage ContextDet framework, which makes use\nof large-kernel convolutions in TAD for the first time. Our model features a\npyramid adaptive context aggragation (ACA) architecture, capturing long context\nand improving action discriminability. Each ACA level consists of two novel\nmodules. The context attention module (CAM) identifies salient contextual\ninformation, encourages context diversity, and preserves context integrity\nthrough a context gating block (CGB). The long context module (LCM) makes use\nof a mixture of large- and small-kernel convolutions to adaptively gather\nlong-range context and fine-grained local features. Additionally, by varying\nthe length of these large kernels across the ACA pyramid, our model provides\nlightweight yet effective context aggregation and action discrimination. We\nconducted extensive experiments and compared our model with a number of\nadvanced TAD methods on six challenging TAD benchmarks: MultiThumos, Charades,\nFineAction, EPIC-Kitchens 100, Thumos14, and HACS, demonstrating superior\naccuracy at reduced inference speed.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15279v1",
    "published_date": "2024-10-20 04:28:19 UTC",
    "updated_date": "2024-10-20 04:28:19 UTC"
  },
  {
    "arxiv_id": "2410.15272v1",
    "title": "Performance-Driven QUBO for Recommender Systems on Quantum Annealers",
    "authors": [
      "Jiayang Niu",
      "Jie Li",
      "Ke Deng",
      "Mark Sanderson",
      "Yongli Ren"
    ],
    "abstract": "We propose Counterfactual Analysis Quadratic Unconstrained Binary\nOptimization (CAQUBO) to solve QUBO problems for feature selection in\nrecommender systems. CAQUBO leverages counterfactual analysis to measure the\nimpact of individual features and feature combinations on model performance and\nemploys the measurements to construct the coefficient matrix for a quantum\nannealer to select the optimal feature combinations for recommender systems,\nthereby improving their final recommendation performance. By establishing\nexplicit connections between features and the recommendation performance, the\nproposed approach demonstrates superior performance compared to the\nstate-of-the-art quantum annealing methods. Extensive experiments indicate that\nintegrating quantum computing with counterfactual analysis holds great promise\nfor addressing these challenges.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15272v1",
    "published_date": "2024-10-20 04:05:18 UTC",
    "updated_date": "2024-10-20 04:05:18 UTC"
  },
  {
    "arxiv_id": "2410.15264v3",
    "title": "AI Can Enhance Creativity in Social Networks",
    "authors": [
      "Raiyan Abdul Baten",
      "Ali Sarosh Bangash",
      "Krish Veera",
      "Gourab Ghoshal",
      "Ehsan Hoque"
    ],
    "abstract": "Can peer recommendation engines elevate people's creative performances in\nself-organizing social networks? Answering this question requires resolving\nchallenges in data collection (e.g., tracing inspiration links and\npsycho-social attributes of nodes) and intervention design (e.g., balancing\nidea stimulation and redundancy in evolving information environments). We\ntrained a model that predicts people's ideation performances using semantic and\nnetwork-structural features in an online platform. Using this model, we built\nSocialMuse, which maximizes people's predicted performances to generate peer\nrecommendations for them. We found treatment networks leveraging SocialMuse\noutperforming AI-agnostic control networks in several creativity measures. The\ntreatment networks were more decentralized than the control, as SocialMuse\nincreasingly emphasized network-structural features at large network sizes.\nThis decentralization spreads people's inspiration sources, helping inspired\nideas stand out better. Our study provides actionable insights into building\nintelligent systems for elevating creativity.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15264v3",
    "published_date": "2024-10-20 03:33:25 UTC",
    "updated_date": "2024-12-11 16:11:07 UTC"
  },
  {
    "arxiv_id": "2410.15262v1",
    "title": "HyQE: Ranking Contexts with Hypothetical Query Embeddings",
    "authors": [
      "Weichao Zhou",
      "Jiaxin Zhang",
      "Hilaf Hasson",
      "Anu Singh",
      "Wenchao Li"
    ],
    "abstract": "In retrieval-augmented systems, context ranking techniques are commonly\nemployed to reorder the retrieved contexts based on their relevance to a user\nquery. A standard approach is to measure this relevance through the similarity\nbetween contexts and queries in the embedding space. However, such similarity\noften fails to capture the relevance. Alternatively, large language models\n(LLMs) have been used for ranking contexts. However, they can encounter\nscalability issues when the number of candidate contexts grows and the context\nwindow sizes of the LLMs remain constrained. Additionally, these approaches\nrequire fine-tuning LLMs with domain-specific data. In this work, we introduce\na scalable ranking framework that combines embedding similarity and LLM\ncapabilities without requiring LLM fine-tuning. Our framework uses a\npre-trained LLM to hypothesize the user query based on the retrieved contexts\nand ranks the context based on the similarity between the hypothesized queries\nand the user query. Our framework is efficient at inference time and is\ncompatible with many other retrieval and ranking techniques. Experimental\nresults show that our method improves the ranking performance across multiple\nbenchmarks. The complete code and data are available at\nhttps://github.com/zwc662/hyqe",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15262v1",
    "published_date": "2024-10-20 03:15:01 UTC",
    "updated_date": "2024-10-20 03:15:01 UTC"
  },
  {
    "arxiv_id": "2410.15252v1",
    "title": "Lossless KV Cache Compression to 2%",
    "authors": [
      "Zhen Yang",
      "J. N. Han",
      "Kan Wu",
      "Ruobing Xie",
      "An Wang",
      "Xingwu Sun",
      "Zhanhui Kang"
    ],
    "abstract": "Large language models have revolutionized data processing in numerous\ndomains, with their ability to handle extended context reasoning receiving\nnotable recognition. To speed up inference, maintaining a key-value (KV) cache\nmemory is essential. Nonetheless, the growing demands for KV cache memory\ncreate significant hurdles for efficient implementation. This work introduces a\nnovel architecture, Cross-Layer Latent Attention (CLLA), aimed at compressing\nthe KV cache to less than 2% of its original size while maintaining comparable\nperformance levels. CLLA integrates multiple aspects of KV cache compression,\nincluding attention head/dimension reduction, layer sharing, and quantization\ntechniques, into a cohesive framework. Our extensive experiments demonstrate\nthat CLLA achieves lossless performance on most tasks while utilizing minimal\nKV cache, marking a significant advancement in practical KV cache compression.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15252v1",
    "published_date": "2024-10-20 02:17:35 UTC",
    "updated_date": "2024-10-20 02:17:35 UTC"
  },
  {
    "arxiv_id": "2410.15247v2",
    "title": "Tensor-Fused Multi-View Graph Contrastive Learning",
    "authors": [
      "Yujia Wu",
      "Junyi Mo",
      "Elynn Chen",
      "Yuzhou Chen"
    ],
    "abstract": "Graph contrastive learning (GCL) has emerged as a promising approach to\nenhance graph neural networks' (GNNs) ability to learn rich representations\nfrom unlabeled graph-structured data. However, current GCL models face\nchallenges with computational demands and limited feature utilization, often\nrelying only on basic graph properties like node degrees and edge attributes.\nThis constrains their capacity to fully capture the complex topological\ncharacteristics of real-world phenomena represented by graphs. To address these\nlimitations, we propose Tensor-Fused Multi-View Graph Contrastive Learning\n(TensorMV-GCL), a novel framework that integrates extended persistent homology\n(EPH) with GCL representations and facilitates multi-scale feature extraction.\nOur approach uniquely employs tensor aggregation and compression to fuse\ninformation from graph and topological features obtained from multiple\naugmented views of the same graph. By incorporating tensor concatenation and\ncontraction modules, we reduce computational overhead by separating feature\ntensor aggregation and transformation. Furthermore, we enhance the quality of\nlearned topological features and model robustness through noise-injected EPH.\nExperiments on molecular, bioinformatic, and social network datasets\ndemonstrate TensorMV-GCL's superiority, outperforming 15 state-of-the-art\nmethods in graph classification tasks across 9 out of 11 benchmarks while\nachieving comparable results on the remaining two. The code for this paper is\npublicly available at https://github.com/CS-SAIL/Tensor-MV-GCL.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15247v2",
    "published_date": "2024-10-20 01:40:12 UTC",
    "updated_date": "2025-03-09 01:31:59 UTC"
  },
  {
    "arxiv_id": "2410.15238v1",
    "title": "Economic Anthropology in the Era of Generative Artificial Intelligence",
    "authors": [
      "Zachary Sheldon",
      "Peeyush Kumar"
    ],
    "abstract": "This paper explores the intersection of economic anthropology and generative\nartificial intelligence (GenAI). It examines how large language models (LLMs)\ncan simulate human decision-making and the inductive biases present in AI\nresearch. The study introduces two AI models: C.A.L.L.O.N. (Conventionally\nAverage Late Liberal ONtology) and M.A.U.S.S. (More Accurate Understanding of\nSociety and its Symbols). The former is trained on standard data, while the\nlatter is adapted with anthropological knowledge. The research highlights how\nanthropological training can enhance LLMs' ability to recognize diverse\neconomic systems and concepts. The findings suggest that integrating economic\nanthropology with AI can provide a more pluralistic understanding of economics\nand improve the sustainability of non-market economic systems.",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15238v1",
    "published_date": "2024-10-20 00:27:33 UTC",
    "updated_date": "2024-10-20 00:27:33 UTC"
  },
  {
    "arxiv_id": "2410.15236v2",
    "title": "Jailbreaking and Mitigation of Vulnerabilities in Large Language Models",
    "authors": [
      "Benji Peng",
      "Keyu Chen",
      "Qian Niu",
      "Ziqian Bi",
      "Ming Liu",
      "Pohsun Feng",
      "Tianyang Wang",
      "Lawrence K. Q. Yan",
      "Yizhu Wen",
      "Yichao Zhang",
      "Caitlyn Heqi Yin"
    ],
    "abstract": "Large Language Models (LLMs) have transformed artificial intelligence by\nadvancing natural language understanding and generation, enabling applications\nacross fields beyond healthcare, software engineering, and conversational\nsystems. Despite these advancements in the past few years, LLMs have shown\nconsiderable vulnerabilities, particularly to prompt injection and jailbreaking\nattacks. This review analyzes the state of research on these vulnerabilities\nand presents available defense strategies. We roughly categorize attack\napproaches into prompt-based, model-based, multimodal, and multilingual,\ncovering techniques such as adversarial prompting, backdoor injections, and\ncross-modality exploits. We also review various defense mechanisms, including\nprompt filtering, transformation, alignment techniques, multi-agent defenses,\nand self-regulation, evaluating their strengths and shortcomings. We also\ndiscuss key metrics and benchmarks used to assess LLM safety and robustness,\nnoting challenges like the quantification of attack success in interactive\ncontexts and biases in existing datasets. Identifying current research gaps, we\nsuggest future directions for resilient alignment strategies, advanced defenses\nagainst evolving attacks, automation of jailbreak detection, and consideration\nof ethical and societal impacts. This review emphasizes the need for continued\nresearch and cooperation within the AI community to enhance LLM security and\nensure their safe deployment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15236v2",
    "published_date": "2024-10-20 00:00:56 UTC",
    "updated_date": "2025-05-08 13:35:24 UTC"
  }
]