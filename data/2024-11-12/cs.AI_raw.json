[
  {
    "arxiv_id": "2411.08249v1",
    "title": "Retrieval Augmented Time Series Forecasting",
    "authors": [
      "Kutay Tire",
      "Ege Onur Taga",
      "Muhammed Emrullah Ildiz",
      "Samet Oymak"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a central component of modern LLM\nsystems, particularly in scenarios where up-to-date information is crucial for\naccurately responding to user queries or when queries exceed the scope of the\ntraining data. The advent of time-series foundation models (TSFM), such as\nChronos, and the need for effective zero-shot forecasting performance across\nvarious time-series domains motivates the question: Do benefits of RAG\nsimilarly carry over to time series forecasting? In this paper, we advocate\nthat the dynamic and event-driven nature of time-series data makes RAG a\ncrucial component of TSFMs and introduce a principled RAG framework for\ntime-series forecasting, called Retrieval Augmented Forecasting (RAF). Within\nRAF, we develop efficient strategies for retrieving related time-series\nexamples and incorporating them into forecast. Through experiments and\nmechanistic studies, we demonstrate that RAF indeed improves the forecasting\naccuracy across diverse time series domains and the improvement is more\nsignificant for larger TSFM sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08249v1",
    "published_date": "2024-11-12 23:55:11 UTC",
    "updated_date": "2024-11-12 23:55:11 UTC"
  },
  {
    "arxiv_id": "2411.08248v1",
    "title": "Deceiving Question-Answering Models: A Hybrid Word-Level Adversarial Approach",
    "authors": [
      "Jiyao Li",
      "Mingze Ni",
      "Yongshun Gong",
      "Wei Liu"
    ],
    "abstract": "Deep learning underpins most of the currently advanced natural language\nprocessing (NLP) tasks such as textual classification, neural machine\ntranslation (NMT), abstractive summarization and question-answering (QA).\nHowever, the robustness of the models, particularly QA models, against\nadversarial attacks is a critical concern that remains insufficiently explored.\nThis paper introduces QA-Attack (Question Answering Attack), a novel word-level\nadversarial strategy that fools QA models. Our attention-based attack exploits\nthe customized attention mechanism and deletion ranking strategy to identify\nand target specific words within contextual passages. It creates deceptive\ninputs by carefully choosing and substituting synonyms, preserving grammatical\nintegrity while misleading the model to produce incorrect responses. Our\napproach demonstrates versatility across various question types, particularly\nwhen dealing with extensive long textual inputs. Extensive experiments on\nmultiple benchmark datasets demonstrate that QA-Attack successfully deceives\nbaseline QA models and surpasses existing adversarial techniques regarding\nsuccess rate, semantics changes, BLEU score, fluency and grammar error rate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08248v1",
    "published_date": "2024-11-12 23:54:58 UTC",
    "updated_date": "2024-11-12 23:54:58 UTC"
  },
  {
    "arxiv_id": "2411.08241v1",
    "title": "A Social Outcomes and Priorities centered (SOP) Framework for AI policy",
    "authors": [
      "Mohak Shah"
    ],
    "abstract": "Rapid developments in AI and its adoption across various domains have\nnecessitated a need to build robust guardrails and risk containment plans while\nensuring equitable benefits for the betterment of society. The current\ntechnology-centered approach has resulted in a fragmented, reactive, and\nineffective policy apparatus. This paper highlights the immediate and urgent\nneed to pivot to a society-centered approach to develop comprehensive,\ncoherent, forward-looking AI policy. To this end, we present a Social Outcomes\nand Priorities centered (SOP) framework for AI policy along with proposals on\nimplementation of its various components. While the SOP framework is presented\nfrom a US-centric view, the takeaways are general and applicable globally.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "K.4; K.5"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08241v1",
    "published_date": "2024-11-12 23:32:21 UTC",
    "updated_date": "2024-11-12 23:32:21 UTC"
  },
  {
    "arxiv_id": "2411.08227v1",
    "title": "DPU: Dynamic Prototype Updating for Multimodal Out-of-Distribution Detection",
    "authors": [
      "Shawn Li",
      "Huixian Gong",
      "Hao Dong",
      "Tiankai Yang",
      "Zhengzhong Tu",
      "Yue Zhao"
    ],
    "abstract": "Out-of-distribution (OOD) detection is essential for ensuring the robustness\nof machine learning models by identifying samples that deviate from the\ntraining distribution. While traditional OOD detection has primarily focused on\nsingle-modality inputs, such as images, recent advances in multimodal models\nhave demonstrated the potential of leveraging multiple modalities (e.g., video,\noptical flow, audio) to enhance detection performance. However, existing\nmethods often overlook intra-class variability within in-distribution (ID)\ndata, assuming that samples of the same class are perfectly cohesive and\nconsistent. This assumption can lead to performance degradation, especially\nwhen prediction discrepancies are uniformly amplified across all samples. To\naddress this issue, we propose Dynamic Prototype Updating (DPU), a novel\nplug-and-play framework for multimodal OOD detection that accounts for\nintra-class variations. Our method dynamically updates class center\nrepresentations for each class by measuring the variance of similar samples\nwithin each batch, enabling adaptive adjustments. This approach allows us to\namplify prediction discrepancies based on the updated class centers, thereby\nimproving the model's robustness and generalization across different\nmodalities. Extensive experiments on two tasks, five datasets, and nine base\nOOD algorithms demonstrate that DPU significantly improves OOD detection\nperformance, setting a new state-of-the-art in multimodal OOD detection, with\nimprovements of up to 80 percent in Far-OOD detection. To facilitate\naccessibility and reproducibility, our code is publicly available on GitHub.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08227v1",
    "published_date": "2024-11-12 22:43:16 UTC",
    "updated_date": "2024-11-12 22:43:16 UTC"
  },
  {
    "arxiv_id": "2411.08212v1",
    "title": "PERFT: Parameter-Efficient Routed Fine-Tuning for Mixture-of-Expert Model",
    "authors": [
      "Yilun Liu",
      "Yunpu Ma",
      "Shuo Chen",
      "Zifeng Ding",
      "Bailan He",
      "Zhen Han",
      "Volker Tresp"
    ],
    "abstract": "The Mixture-of-Experts (MoE) paradigm has emerged as a powerful approach for\nscaling transformers with improved resource utilization. However, efficiently\nfine-tuning MoE models remains largely underexplored. Inspired by recent works\non Parameter-Efficient Fine-Tuning (PEFT), we present a unified framework for\nintegrating PEFT modules directly into the MoE mechanism. Aligning with the\ncore principles and architecture of MoE, our framework encompasses a set of\ndesign dimensions including various functional and composition strategies. By\ncombining design choices within our framework, we introduce Parameter-Efficient\nRouted Fine-Tuning (PERFT) as a flexible and scalable family of PEFT strategies\ntailored for MoE models. Extensive experiments on adapting OLMoE-1B-7B and\nMixtral-8$\\times$7B for commonsense and arithmetic reasoning tasks demonstrate\nthe effectiveness, scalability, and intriguing dynamics of PERFT. Additionally,\nwe provide empirical findings for each specific design choice to facilitate\nbetter application of MoE and PEFT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available via https://anonymous.4open.science/r/PERFT-MoE/",
    "pdf_url": "http://arxiv.org/pdf/2411.08212v1",
    "published_date": "2024-11-12 22:03:37 UTC",
    "updated_date": "2024-11-12 22:03:37 UTC"
  },
  {
    "arxiv_id": "2411.08197v1",
    "title": "What Representational Similarity Measures Imply about Decodable Information",
    "authors": [
      "Sarah E. Harvey",
      "David Lipshutz",
      "Alex H. Williams"
    ],
    "abstract": "Neural responses encode information that is useful for a variety of\ndownstream tasks. A common approach to understand these systems is to build\nregression models or ``decoders'' that reconstruct features of the stimulus\nfrom neural responses. Popular neural network similarity measures like centered\nkernel alignment (CKA), canonical correlation analysis (CCA), and Procrustes\nshape distance, do not explicitly leverage this perspective and instead\nhighlight geometric invariances to orthogonal or affine transformations when\ncomparing representations. Here, we show that many of these measures can, in\nfact, be equivalently motivated from a decoding perspective. Specifically,\nmeasures like CKA and CCA quantify the average alignment between optimal linear\nreadouts across a distribution of decoding tasks. We also show that the\nProcrustes shape distance upper bounds the distance between optimal linear\nreadouts and that the converse holds for representations with low participation\nratio. Overall, our work demonstrates a tight link between the geometry of\nneural representations and the ability to linearly decode information. This\nperspective suggests new ways of measuring similarity between neural systems\nand also provides novel, unifying interpretations of existing measures.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08197v1",
    "published_date": "2024-11-12 21:37:10 UTC",
    "updated_date": "2024-11-12 21:37:10 UTC"
  },
  {
    "arxiv_id": "2411.08195v1",
    "title": "An Explainable Machine Learning Approach for Age and Gender Estimation in Living Individuals Using Dental Biometrics",
    "authors": [
      "Mohsin Ali",
      "Haider Raza",
      "John Q Gan",
      "Ariel Pokhojaev",
      "Matanel Katz",
      "Esra Kosan",
      "Dian Agustin Wahjuningrum",
      "Omnina Saleh",
      "Rachel Sarig",
      "Akhilanada Chaurasia"
    ],
    "abstract": "Objectives: Age and gender estimation is crucial for various applications,\nincluding forensic investigations and anthropological studies. This research\naims to develop a predictive system for age and gender estimation in living\nindividuals, leveraging dental measurements such as Coronal Height (CH),\nCoronal Pulp Cavity Height (CPCH), and Tooth Coronal Index (TCI). Methods:\nMachine learning models were employed in our study, including Cat Boost\nClassifier (Catboost), Gradient Boosting Machine (GBM), Ada Boost Classifier\n(AdaBoost), Random Forest (RF), eXtreme Gradient Boosting (XGB), Light Gradient\nBoosting Machine (LGB), and Extra Trees Classifier (ETC), to analyze dental\ndata from 862 living individuals (459 males and 403 females). Specifically,\nperiapical radiographs from six teeth per individual were utilized, including\npremolars and molars from both maxillary and mandibular. A novel ensemble\nlearning technique was developed, which uses multiple models each tailored to\ndistinct dental metrics, to estimate age and gender accurately. Furthermore, an\nexplainable AI model has been created utilizing SHAP, enabling dental experts\nto make judicious decisions based on comprehensible insight. Results: The RF\nand XGB models were particularly effective, yielding the highest F1 score for\nage and gender estimation. Notably, the XGB model showed a slightly better\nperformance in age estimation, achieving an F1 score of 73.26%. A similar trend\nfor the RF model was also observed in gender estimation, achieving a F1 score\nof 77.53%. Conclusions: This study marks a significant advancement in dental\nforensic methods, showcasing the potential of machine learning to automate age\nand gender estimation processes with improved accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08195v1",
    "published_date": "2024-11-12 21:33:11 UTC",
    "updated_date": "2024-11-12 21:33:11 UTC"
  },
  {
    "arxiv_id": "2411.08187v1",
    "title": "TractoEmbed: Modular Multi-level Embedding framework for white matter tract segmentation",
    "authors": [
      "Anoushkrit Goel",
      "Bipanjit Singh",
      "Ankita Joshi",
      "Ranjeet Ranjan Jha",
      "Chirag Ahuja",
      "Aditya Nigam",
      "Arnav Bhavsar"
    ],
    "abstract": "White matter tract segmentation is crucial for studying brain structural\nconnectivity and neurosurgical planning. However, segmentation remains\nchallenging due to issues like class imbalance between major and minor tracts,\nstructural similarity, subject variability, symmetric streamlines between\nhemispheres etc. To address these challenges, we propose TractoEmbed, a modular\nmulti-level embedding framework, that encodes localized representations through\nlearning tasks in respective encoders. In this paper, TractoEmbed introduces a\nnovel hierarchical streamline data representation that captures maximum spatial\ninformation at each level i.e. individual streamlines, clusters, and patches.\nExperiments show that TractoEmbed outperforms state-of-the-art methods in white\nmatter tract segmentation across different datasets, and spanning various age\ngroups. The modular framework directly allows the integration of additional\nembeddings in future works.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at 27th International Conference on Pattern Recognition\n  (ICPR), 2024 15 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.08187v1",
    "published_date": "2024-11-12 21:12:51 UTC",
    "updated_date": "2024-11-12 21:12:51 UTC"
  },
  {
    "arxiv_id": "2411.08182v1",
    "title": "SCORE: Syntactic Code Representations for Static Script Malware Detection",
    "authors": [
      "Ecenaz Erdemir",
      "Kyuhong Park",
      "Michael J. Morais",
      "Vianne R. Gao",
      "Marion Marschalek",
      "Yi Fan"
    ],
    "abstract": "As businesses increasingly adopt cloud technologies, they also need to be\naware of new security challenges, such as server-side script attacks, to ensure\nthe integrity of their systems and data. These scripts can steal data,\ncompromise credentials, and disrupt operations. Unlike executables with\nstandardized formats (e.g., ELF, PE), scripts are plaintext files with diverse\nsyntax, making them harder to detect using traditional methods. As a result,\nmore sophisticated approaches are needed to protect cloud infrastructures from\nthese evolving threats. In this paper, we propose novel feature extraction and\ndeep learning (DL)-based approaches for static script malware detection,\ntargeting server-side threats. We extract features from plain-text code using\ntwo techniques: syntactic code highlighting (SCH) and abstract syntax tree\n(AST) construction. SCH leverages complex regexes to parse syntactic elements\nof code, such as keywords, variable names, etc. ASTs generate a hierarchical\nrepresentation of a program's syntactic structure. We then propose a sequential\nand a graph-based model that exploits these feature representations to detect\nscript malware. We evaluate our approach on more than 400K server-side scripts\nin Bash, Python and Perl. We use a balanced dataset of 90K scripts for\ntraining, validation, and testing, with the remaining from 400K reserved for\nfurther analysis. Experiments show that our method achieves a true positive\nrate (TPR) up to 81% higher than leading signature-based antivirus solutions,\nwhile maintaining a low false positive rate (FPR) of 0.17%. Moreover, our\napproach outperforms various neural network-based detectors, demonstrating its\neffectiveness in learning code maliciousness for accurate detection of script\nmalware.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08182v1",
    "published_date": "2024-11-12 20:58:04 UTC",
    "updated_date": "2024-11-12 20:58:04 UTC"
  },
  {
    "arxiv_id": "2411.08181v2",
    "title": "Challenges in Guardrailing Large Language Models for Science",
    "authors": [
      "Nishan Pantha",
      "Muthukumaran Ramasubramanian",
      "Iksha Gurung",
      "Manil Maskey",
      "Rahul Ramachandran"
    ],
    "abstract": "The rapid development in large language models (LLMs) has transformed the\nlandscape of natural language processing and understanding (NLP/NLU), offering\nsignificant benefits across various domains. However, when applied to\nscientific research, these powerful models exhibit critical failure modes\nrelated to scientific integrity and trustworthiness. Existing general-purpose\nLLM guardrails are insufficient to address these unique challenges in the\nscientific domain. We provide comprehensive guidelines for deploying LLM\nguardrails in the scientific domain. We identify specific challenges --\nincluding time sensitivity, knowledge contextualization, conflict resolution,\nand intellectual property concerns -- and propose a guideline framework for the\nguardrails that can align with scientific needs. These guardrail dimensions\ninclude trustworthiness, ethics & bias, safety, and legal aspects. We also\noutline in detail the implementation strategies that employ white-box,\nblack-box, and gray-box methodologies that can be enforced within scientific\ncontexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08181v2",
    "published_date": "2024-11-12 20:57:12 UTC",
    "updated_date": "2024-12-04 16:55:18 UTC"
  },
  {
    "arxiv_id": "2411.08171v1",
    "title": "Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection",
    "authors": [
      "Aditya V. Jonnalagadda",
      "Hashim A. Hashim",
      "Andrew Harris"
    ],
    "abstract": "Contemporary Artificial Intelligence (AI) and Machine Learning (ML) research\nplaces a significant emphasis on transfer learning, showcasing its\ntransformative potential in enhancing model performance across diverse domains.\nThis paper examines the efficiency and effectiveness of transfer learning in\nthe context of wildfire detection. Three purpose-built models -- Visual\nGeometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-Support\nVector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrained\nmodels -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. We\ntrained and evaluated these models using a dataset that captures the\ncomplexities of wildfires, incorporating variables such as varying lighting\nconditions, time of day, and diverse terrains. The objective is to discern how\ntransfer learning performs against models trained from scratch in addressing\nthe intricacies of the wildfire detection problem. By assessing the performance\nmetrics, including accuracy, precision, recall, and F1 score, a comprehensive\nunderstanding of the advantages and disadvantages of transfer learning in this\nspecific domain is obtained. This study contributes valuable insights to the\nongoing discourse, guiding future directions in AI and ML research. Keywords:\nWildfire prediction, deep learning, machine learning fire, detection",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "In Proc. of the 2024 IEEE International Conference On Intelligent\n  Computing in Data Sciences",
    "pdf_url": "http://arxiv.org/pdf/2411.08171v1",
    "published_date": "2024-11-12 20:30:23 UTC",
    "updated_date": "2024-11-12 20:30:23 UTC"
  },
  {
    "arxiv_id": "2411.08165v2",
    "title": "Retrieval, Reasoning, Re-ranking: A Context-Enriched Framework for Knowledge Graph Completion",
    "authors": [
      "Muzhi Li",
      "Cehao Yang",
      "Chengjin Xu",
      "Xuhui Jiang",
      "Yiyan Qi",
      "Jian Guo",
      "Ho-fung Leung",
      "Irwin King"
    ],
    "abstract": "The Knowledge Graph Completion~(KGC) task aims to infer the missing entity\nfrom an incomplete triple. Existing embedding-based methods rely solely on\ntriples in the KG, which is vulnerable to specious relation patterns and\nlong-tail entities. On the other hand, text-based methods struggle with the\nsemantic gap between KG triples and natural language. Apart from triples,\nentity contexts (e.g., labels, descriptions, aliases) also play a significant\nrole in augmenting KGs. To address these limitations, we propose KGR3, a\ncontext-enriched framework for KGC. KGR3 is composed of three modules. Firstly,\nthe Retrieval module gathers supporting triples from the KG, collects plausible\ncandidate answers from a base embedding model, and retrieves context for each\nrelated entity. Then, the Reasoning module employs a large language model to\ngenerate potential answers for each query triple. Finally, the Re-ranking\nmodule combines candidate answers from the two modules mentioned above, and\nfine-tunes an LLM to provide the best answer. Extensive experiments on widely\nused datasets demonstrate that KGR3 consistently improves various KGC methods.\nSpecifically, the best variant of KGR3 achieves absolute Hits@1 improvements of\n12.3% and 5.6% on the FB15k237 and WN18RR datasets.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NAACL2025 main",
    "pdf_url": "http://arxiv.org/pdf/2411.08165v2",
    "published_date": "2024-11-12 20:15:58 UTC",
    "updated_date": "2025-04-30 12:02:25 UTC"
  },
  {
    "arxiv_id": "2411.08148v1",
    "title": "Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization",
    "authors": [
      "Dinesh Srivasthav P",
      "Badri Narayan Subudhi"
    ],
    "abstract": "Pioneering advancements in artificial intelligence, especially in genAI, have\nenabled significant possibilities for content creation, but also led to\nwidespread misinformation and false content. The growing sophistication and\nrealism of deepfakes is raising concerns about privacy invasion, identity\ntheft, and has societal, business impacts, including reputational damage and\nfinancial loss. Many deepfake detectors have been developed to tackle this\nproblem. Nevertheless, as for every AI model, the deepfake detectors face the\nwrath of lack of considerable generalization to unseen scenarios and\ncross-domain deepfakes. Besides, adversarial robustness is another critical\nchallenge, as detectors drastically underperform to the slightest imperceptible\nchange. Most state-of-the-art detectors are trained on static datasets and lack\nthe ability to adapt to emerging deepfake attack trends. These three crucial\nchallenges though hold paramount importance for reliability in practise,\nparticularly in the deepfake domain, are also the problems with any other AI\napplication. This paper proposes an adversarial meta-learning algorithm using\ntask-specific adaptive sample synthesis and consistency regularization, in a\nrefinement phase. By focussing on the classifier's strengths and weaknesses, it\nboosts both robustness and generalization of the model. Additionally, the paper\nintroduces a hierarchical multi-agent retrieval-augmented generation workflow\nwith a sample synthesis module to dynamically adapt the model to new data\ntrends by generating custom deepfake samples. The paper further presents a\nframework integrating the meta-learning algorithm with the hierarchical\nmulti-agent workflow, offering a holistic solution for enhancing\ngeneralization, robustness, and adaptability. Experimental results demonstrate\nthe model's consistent performance across various datasets, outperforming the\nmodels in comparison.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08148v1",
    "published_date": "2024-11-12 19:55:07 UTC",
    "updated_date": "2024-11-12 19:55:07 UTC"
  },
  {
    "arxiv_id": "2411.08147v1",
    "title": "Large Language Models Can Self-Improve in Long-context Reasoning",
    "authors": [
      "Siheng Li",
      "Cheng Yang",
      "Zesen Cheng",
      "Lemao Liu",
      "Mo Yu",
      "Yujiu Yang",
      "Wai Lam"
    ],
    "abstract": "Large language models (LLMs) have achieved substantial progress in processing\nlong contexts but still struggle with long-context reasoning. Existing\napproaches typically involve fine-tuning LLMs with synthetic data, which\ndepends on annotations from human experts or advanced models like GPT-4, thus\nrestricting further advancements. To address this issue, we investigate the\npotential for LLMs to self-improve in long-context reasoning and propose \\ours,\nan approach specifically designed for this purpose. This approach is\nstraightforward: we sample multiple outputs for each question, score them with\nMinimum Bayes Risk, and then apply supervised fine-tuning or preference\noptimization based on these outputs. Extensive experiments on several leading\nLLMs demonstrate the effectiveness of \\ours, with an absolute improvement of\n$4.2$ points for Llama-3.1-8B-Instruct. Furthermore, \\ours achieves superior\nperformance compared to prior approaches that depend on data produced by human\nexperts or advanced models. We anticipate that this work will open new avenues\nfor self-improvement techniques in long-context scenarios, which are essential\nfor the continual advancement of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Project Page: https://github.com/SihengLi99/SEALONG",
    "pdf_url": "http://arxiv.org/pdf/2411.08147v1",
    "published_date": "2024-11-12 19:53:00 UTC",
    "updated_date": "2024-11-12 19:53:00 UTC"
  },
  {
    "arxiv_id": "2411.08135v2",
    "title": "On the Role of Speech Data in Reducing Toxicity Detection Bias",
    "authors": [
      "Samuel J. Bell",
      "Mariano Coria Meglioli",
      "Megan Richards",
      "Eduardo Sánchez",
      "Christophe Ropers",
      "Skyler Wang",
      "Adina Williams",
      "Levent Sagun",
      "Marta R. Costa-jussà"
    ],
    "abstract": "Text toxicity detection systems exhibit significant biases, producing\ndisproportionate rates of false positives on samples mentioning demographic\ngroups. But what about toxicity detection in speech? To investigate the extent\nto which text-based biases are mitigated by speech-based systems, we produce a\nset of high-quality group annotations for the multilingual MuTox dataset, and\nthen leverage these annotations to systematically compare speech- and\ntext-based toxicity classifiers. Our findings indicate that access to speech\ndata during inference supports reduced bias against group mentions,\nparticularly for ambiguous and disagreement-inducing samples. Our results also\nsuggest that improving classifiers, rather than transcription pipelines, is\nmore helpful for reducing group bias. We publicly release our annotations and\nprovide recommendations for future toxicity dataset construction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.08135v2",
    "published_date": "2024-11-12 19:26:43 UTC",
    "updated_date": "2025-05-16 15:45:14 UTC"
  },
  {
    "arxiv_id": "2411.08034v3",
    "title": "Scaling Properties of Diffusion Models for Perceptual Tasks",
    "authors": [
      "Rahul Ravishankar",
      "Zeeshan Patel",
      "Jathushan Rajasegaran",
      "Jitendra Malik"
    ],
    "abstract": "In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and amodal\nsegmentation under the framework of image-to-image translation, and show how\ndiffusion models benefit from scaling training and test-time compute for these\nperceptual tasks. Through a careful analysis of these scaling properties, we\nformulate compute-optimal training and inference recipes to scale diffusion\nmodels for visual perception tasks. Our models achieve competitive performance\nto state-of-the-art methods using significantly less data and compute. To\naccess our code and models, see https://scaling-diffusion-perception.github.io .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08034v3",
    "published_date": "2024-11-12 18:59:35 UTC",
    "updated_date": "2024-11-17 03:45:07 UTC"
  },
  {
    "arxiv_id": "2411.08033v2",
    "title": "GaussianAnything: Interactive Point Cloud Flow Matching For 3D Object Generation",
    "authors": [
      "Yushi Lan",
      "Shangchen Zhou",
      "Zhaoyang Lyu",
      "Fangzhou Hong",
      "Shuai Yang",
      "Bo Dai",
      "Xingang Pan",
      "Chen Change Loy"
    ],
    "abstract": "While 3D content generation has advanced significantly, existing methods\nstill face challenges with input formats, latent space design, and output\nrepresentations. This paper introduces a novel 3D generation framework that\naddresses these challenges, offering scalable, high-quality 3D generation with\nan interactive Point Cloud-structured Latent space. Our framework employs a\nVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)\nrenderings as input, using a unique latent space design that preserves 3D shape\ninformation, and incorporates a cascaded latent flow-based model for improved\nshape-texture disentanglement. The proposed method, GaussianAnything, supports\nmulti-modal conditional 3D generation, allowing for point cloud, caption, and\nsingle image inputs. Notably, the newly proposed latent space naturally enables\ngeometry-texture disentanglement, thus allowing 3D-aware editing. Experimental\nresults demonstrate the effectiveness of our approach on multiple datasets,\noutperforming existing native 3D methods in both text- and image-conditioned 3D\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025 project page: https://nirvanalan.github.io/projects/GA/",
    "pdf_url": "http://arxiv.org/pdf/2411.08033v2",
    "published_date": "2024-11-12 18:59:32 UTC",
    "updated_date": "2025-04-10 12:24:52 UTC"
  },
  {
    "arxiv_id": "2411.08028v3",
    "title": "Learning with Less: Knowledge Distillation from Large Language Models via Unlabeled Data",
    "authors": [
      "Juanhui Li",
      "Sreyashi Nag",
      "Hui Liu",
      "Xianfeng Tang",
      "Sheikh Sarwar",
      "Limeng Cui",
      "Hansu Gu",
      "Suhang Wang",
      "Qi He",
      "Jiliang Tang"
    ],
    "abstract": "In real-world NLP applications, Large Language Models (LLMs) offer promising\nsolutions due to their extensive training on vast datasets. However, the large\nsize and high computation demands of LLMs limit their practicality in many\napplications, especially when further fine-tuning is required. To address these\nlimitations, smaller models are typically preferred for deployment. However,\ntheir training is hindered by the scarcity of labeled data. In contrast,\nunlabeled data is often readily which can be leveraged by using LLMs to\ngenerate pseudo-labels for training smaller models. This enables the smaller\nmodels (student) to acquire knowledge from LLMs(teacher) while reducing\ncomputational costs. This process introduces challenges, such as potential\nnoisy pseudo-labels. Selecting high-quality and informative data is therefore\ncritical to enhance model performance while improving the efficiency of data\nutilization. To address this, we propose LLKD that enables Learning with Less\ncomputational resources and less data for Knowledge Distillation from LLMs.\nLLKD is an adaptive sample selection method that incorporates signals from both\nthe teacher and student. Specifically, it prioritizes samples where the teacher\ndemonstrates high confidence in its labeling, indicating reliable labels, and\nwhere the student exhibits a high information need, identifying challenging\nsamples that require further learning. Our comprehensive experiments show that\nLLKD achieves superior performance across various datasets with higher data\nefficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08028v3",
    "published_date": "2024-11-12 18:57:59 UTC",
    "updated_date": "2025-03-30 06:21:19 UTC"
  },
  {
    "arxiv_id": "2411.08027v2",
    "title": "LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models",
    "authors": [
      "Anoop Cherian",
      "Radu Corcodel",
      "Siddarth Jain",
      "Diego Romeres"
    ],
    "abstract": "Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08027v2",
    "published_date": "2024-11-12 18:56:58 UTC",
    "updated_date": "2024-12-12 21:29:57 UTC"
  },
  {
    "arxiv_id": "2411.08024v1",
    "title": "Leonardo vindicated: Pythagorean trees for minimal reconstruction of the natural branching structures",
    "authors": [
      "Dymitr Ruta",
      "Corrado Mio",
      "Ernesto Damiani"
    ],
    "abstract": "Trees continue to fascinate with their natural beauty and as engineering\nmasterpieces optimal with respect to several independent criteria. Pythagorean\ntree is a well-known fractal design that realistically mimics the natural tree\nbranching structures. We study various types of Pythagorean-like fractal trees\nwith different shapes of the base, branching angles and relaxed scales in an\nattempt to identify and explain which variants are the closest match to the\nbranching structures commonly observed in the natural world. Pursuing\nsimultaneously the realism and minimalism of the fractal tree model, we have\ndeveloped a flexibly parameterised and fast algorithm to grow and visually\nexamine deep Pythagorean-inspired fractal trees with the capability to orderly\nover- or underestimate the Leonardo da Vinci's tree branching rule as well as\ncontrol various imbalances and branching angles. We tested the realism of the\ngenerated fractal tree images by means of the classification accuracy of\ndetecting natural tree with the transfer-trained deep Convolutional Neural\nNetworks (CNNs). Having empirically established the parameters of the fractal\ntrees that maximize the CNN's natural tree class classification accuracy we\nhave translated them back to the scales and angles of branches and came to the\ninteresting conclusions that support the da Vinci branching rule and golden\nratio based scaling for both the shape of the branch and imbalance between the\nchild branches, and claim the flexibly parameterized fractal trees can be used\nto generate artificial examples to train robust detectors of different species\nof trees.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "68U05, 68T45, 92C80, 28A80",
      "I.3.5; I.2.10; I.4.8; I.5.1; J.2"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, lots of hi res figures I had to reduce quality of,\n  submitting as a requirement to the Theory of Computing Journal",
    "pdf_url": "http://arxiv.org/pdf/2411.08024v1",
    "published_date": "2024-11-12 18:54:55 UTC",
    "updated_date": "2024-11-12 18:54:55 UTC"
  },
  {
    "arxiv_id": "2411.08019v1",
    "title": "Language Models as Causal Effect Generators",
    "authors": [
      "Lucius E. J. Bynum",
      "Kyunghyun Cho"
    ],
    "abstract": "We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08019v1",
    "published_date": "2024-11-12 18:50:35 UTC",
    "updated_date": "2024-11-12 18:50:35 UTC"
  },
  {
    "arxiv_id": "2411.08017v1",
    "title": "Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings",
    "authors": [
      "Aditya Sanghi",
      "Aliasghar Khani",
      "Pradyumna Reddy",
      "Arianna Rampini",
      "Derek Cheung",
      "Kamal Rahimi Malekshan",
      "Kanika Madan",
      "Hooman Shayani"
    ],
    "abstract": "Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08017v1",
    "published_date": "2024-11-12 18:49:06 UTC",
    "updated_date": "2024-11-12 18:49:06 UTC"
  },
  {
    "arxiv_id": "2411.08013v2",
    "title": "Investigating the Effectiveness of Explainability Methods in Parkinson's Detection from Speech",
    "authors": [
      "Eleonora Mancini",
      "Francesco Paissan",
      "Paolo Torroni",
      "Mirco Ravanelli",
      "Cem Subakan"
    ],
    "abstract": "Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "The first two authors contributed equally to this research: author\n  order is alphabetical",
    "pdf_url": "http://arxiv.org/pdf/2411.08013v2",
    "published_date": "2024-11-12 18:43:27 UTC",
    "updated_date": "2024-11-13 13:36:05 UTC"
  },
  {
    "arxiv_id": "2411.08010v1",
    "title": "ExpressivityArena: Can LLMs Express Information Implicitly?",
    "authors": [
      "Joshua Tint",
      "Som Sagar",
      "Aditya Taparia",
      "Kelly Raines",
      "Bimsara Pathiraja",
      "Caleb Liu",
      "Ransalu Senanayake"
    ],
    "abstract": "While Large Language Models (LLMs) have demonstrated remarkable performance\nin certain dimensions, their ability to express implicit language cues that\nhuman use for effective communication remains unclear. This paper presents\nExpressivityArena, a Python library for measuring the implicit communication\nabilities of LLMs. We provide a comprehensive framework to evaluate\nexpressivity of arbitrary LLMs and explore its practical implications. To this\nend, we refine the definition and measurements of ``expressivity,'' and use our\nframework in a set of small experiments. These experiments test LLMs in\ncreative and logical tasks such as poetry, coding, and emotion-based responses.\nThey are then evaluated by an automated grader, through ExpressivityArena,\nwhich we verify to be the most pragmatic for testing expressivity. Building on\nthese experiments, we deepen our understanding of the expressivity of LLMs by\nassessing their ability to remain expressive in conversations. Our findings\nindicate that LLMs are capable of generating and understanding expressive\ncontent, however, with some limitations. These insights will inform the future\ndevelopment and deployment of expressive LLMs. We provide the code for\nExpressivityArena alongside our paper.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.08010v1",
    "published_date": "2024-11-12 18:35:28 UTC",
    "updated_date": "2024-11-12 18:35:28 UTC"
  },
  {
    "arxiv_id": "2411.08003v1",
    "title": "Can adversarial attacks by large language models be attributed?",
    "authors": [
      "Manuel Cebrian",
      "Jan Arne Telle"
    ],
    "abstract": "Attributing outputs from Large Language Models (LLMs) in adversarial\nsettings-such as cyberattacks and disinformation-presents significant\nchallenges that are likely to grow in importance. We investigate this\nattribution problem using formal language theory, specifically language\nidentification in the limit as introduced by Gold and extended by Angluin. By\nmodeling LLM outputs as formal languages, we analyze whether finite text\nsamples can uniquely pinpoint the originating model. Our results show that due\nto the non-identifiability of certain language classes, under some mild\nassumptions about overlapping outputs from fine-tuned models it is\ntheoretically impossible to attribute outputs to specific LLMs with certainty.\nThis holds also when accounting for expressivity limitations of Transformer\narchitectures. Even with direct model access or comprehensive monitoring,\nsignificant computational hurdles impede attribution efforts. These findings\nhighlight an urgent need for proactive measures to mitigate risks posed by\nadversarial LLM use as their influence continues to expand.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.FL"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2411.08003v1",
    "published_date": "2024-11-12 18:28:57 UTC",
    "updated_date": "2024-11-12 18:28:57 UTC"
  },
  {
    "arxiv_id": "2411.07990v1",
    "title": "Derivational Morphology Reveals Analogical Generalization in Large Language Models",
    "authors": [
      "Valentin Hofmann",
      "Leonie Weissweiler",
      "David Mortensen",
      "Hinrich Schütze",
      "Janet Pierrehumbert"
    ],
    "abstract": "What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07990v1",
    "published_date": "2024-11-12 18:15:19 UTC",
    "updated_date": "2024-11-12 18:15:19 UTC"
  },
  {
    "arxiv_id": "2411.07983v1",
    "title": "Gini Coefficient as a Unified Metric for Evaluating Many-versus-Many Similarity in Vector Spaces",
    "authors": [
      "Ben Fauber"
    ],
    "abstract": "We demonstrate that Gini coefficients can be used as unified metrics to\nevaluate many-versus-many (all-to-all) similarity in vector spaces. Our\nanalysis of various image datasets shows that images with the highest Gini\ncoefficients tend to be the most similar to one another, while images with the\nlowest Gini coefficients are the least similar. We also show that this\nrelationship holds true for vectorized text embeddings from various corpuses,\nhighlighting the consistency of our method and its broad applicability across\ndifferent types of data. Additionally, we demonstrate that selecting machine\nlearning training samples that closely match the distribution of the testing\ndataset is far more important than ensuring data diversity. Selection of\nexemplary and iconic training samples with higher Gini coefficients leads to\nsignificantly better model performance compared to simply having a diverse\ntraining set with lower Gini coefficients. Thus, Gini coefficients can serve as\neffective criteria for selecting machine learning training samples, with our\nselection method outperforming random sampling methods in very sparse\ninformation settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07983v1",
    "published_date": "2024-11-12 18:08:45 UTC",
    "updated_date": "2024-11-12 18:08:45 UTC"
  },
  {
    "arxiv_id": "2411.07979v2",
    "title": "Exact, Tractable Gauss-Newton Optimization in Deep Reversible Architectures Reveal Poor Generalization",
    "authors": [
      "Davide Buffelli",
      "Jamie McGowan",
      "Wangkun Xu",
      "Alexandru Cioba",
      "Da-shan Shiu",
      "Guillaume Hennequin",
      "Alberto Bernacchia"
    ],
    "abstract": "Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers. However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07979v2",
    "published_date": "2024-11-12 17:58:40 UTC",
    "updated_date": "2024-11-13 09:52:45 UTC"
  },
  {
    "arxiv_id": "2411.07976v7",
    "title": "DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring",
    "authors": [
      "Mahmut S. Gokmen",
      "Caner Ozcan",
      "Moneera N. Haque",
      "Steve W. Leung",
      "C. Seth Parker",
      "W. Brent Seales",
      "Cody Bumgardner"
    ],
    "abstract": "Coronary artery disease (CAD), one of the leading causes of mortality\nworldwide, necessitates effective risk assessment strategies, with coronary\nartery calcium (CAC) scoring via computed tomography (CT) being a key method\nfor prevention. Traditional methods, primarily based on UNET architectures\nimplemented on pre-built models, face challenges like the scarcity of annotated\nCT scans containing CAC and imbalanced datasets, leading to reduced performance\nin segmentation and scoring tasks. In this study, we address these limitations\nby incorporating the self-supervised learning (SSL) technique of DINO\n(self-distillation with no labels), which trains without requiring CAC-specific\nannotations, enhancing its robustness in generating distinct features. The\nDINO-LG model, which leverages label guidance to focus on calcified areas,\nachieves significant improvements, with a sensitivity of 89% and specificity of\n90% for detecting CAC-containing CT slices, compared to the standard DINO\nmodel's sensitivity of 79% and specificity of 77%. Additionally, false-negative\nand false-positive rates are reduced by 49% and 59%, respectively, instilling\ngreater confidence in clinicians when ruling out calcification in low-risk\npatients and minimizing unnecessary imaging reviews by radiologists. Further,\nCAC scoring and segmentation tasks are conducted using a basic UNET\narchitecture, applied specifically to CT slices identified by the DINO-LG model\nas containing calcified areas. This targeted approach enhances CAC scoring\naccuracy by feeding the UNET model with relevant slices, significantly\nimproving diagnostic precision, reducing both false positives and false\nnegatives, and ultimately lowering overall healthcare costs by minimizing\nunnecessary tests and treatments, presenting a valuable advancement in CAD risk\nassessment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Developed by Center for Applied Artificial Intelligence (CAAI),\n  University of Kentucky",
    "pdf_url": "http://arxiv.org/pdf/2411.07976v7",
    "published_date": "2024-11-12 17:55:39 UTC",
    "updated_date": "2025-03-21 17:06:08 UTC"
  },
  {
    "arxiv_id": "2411.07975v2",
    "title": "JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified Multimodal Understanding and Generation",
    "authors": [
      "Yiyang Ma",
      "Xingchao Liu",
      "Xiaokang Chen",
      "Wen Liu",
      "Chengyue Wu",
      "Zhiyu Wu",
      "Zizheng Pan",
      "Zhenda Xie",
      "Haowei Zhang",
      "Xingkai yu",
      "Liang Zhao",
      "Yisong Wang",
      "Jiaying Liu",
      "Chong Ruan"
    ],
    "abstract": "We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07975v2",
    "published_date": "2024-11-12 17:55:10 UTC",
    "updated_date": "2025-03-24 08:33:32 UTC"
  },
  {
    "arxiv_id": "2411.07955v1",
    "title": "How To Discover Short, Shorter, and the Shortest Proofs of Unsatisfiability: A Branch-and-Bound Approach for Resolution Proof Length Minimization",
    "authors": [
      "Konstantin Sidorov",
      "Koos van der Linden",
      "Gonçalo Homem de Almeida Correia",
      "Mathijs de Weerdt",
      "Emir Demirović"
    ],
    "abstract": "Modern software for propositional satisfiability problems gives a powerful\nautomated reasoning toolkit, capable of outputting not only a\nsatisfiable/unsatisfiable signal but also a justification of unsatisfiability\nin the form of resolution proof (or a more expressive proof), which is commonly\nused for verification purposes. Empirically, modern SAT solvers produce\nrelatively short proofs, however, there are no inherent guarantees that these\nproofs cannot be significantly reduced. This paper proposes a novel\nbranch-and-bound algorithm for finding the shortest resolution proofs; to this\nend, we introduce a layer list representation of proofs that groups clauses by\ntheir level of indirection. As we show, this representation breaks all\npermutational symmetries, thereby improving upon the state-of-the-art\nsymmetry-breaking and informing the design of a novel workflow for proof\nminimization. In addition to that, we design pruning procedures that reason on\nproof length lower bound, clause subsumption, and dominance. Our experiments\nsuggest that the proofs from state-of-the-art solvers could be shortened by\n30-60% on the instances from SAT Competition 2002 and by 25-50% on small\nsynthetic formulas. When treated as an algorithm for finding the shortest\nproof, our approach solves twice as many instances as the previous work based\non SAT solving and reduces the time to optimality by orders of magnitude for\nthe instances solved by both approaches.",
    "categories": [
      "cs.AI",
      "I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages, 16 figures, 8 tables, submitted to Journal of Artificial\n  Intelligence Research",
    "pdf_url": "http://arxiv.org/pdf/2411.07955v1",
    "published_date": "2024-11-12 17:31:35 UTC",
    "updated_date": "2024-11-12 17:31:35 UTC"
  },
  {
    "arxiv_id": "2411.07942v1",
    "title": "Towards Low-bit Communication for Tensor Parallel LLM Inference",
    "authors": [
      "Harry Dong",
      "Tyler Johnson",
      "Minsik Cho",
      "Emad Soroush"
    ],
    "abstract": "Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07942v1",
    "published_date": "2024-11-12 17:11:46 UTC",
    "updated_date": "2024-11-12 17:11:46 UTC"
  },
  {
    "arxiv_id": "2411.07941v2",
    "title": "DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with Generative Adversarial Networks",
    "authors": [
      "Zhaoxi Zhang",
      "Yueliang Ying"
    ],
    "abstract": "Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "9 pages, LaTeX; removed the superscript numbers associated with the\n  authors' names for clarity, typos corrected",
    "pdf_url": "http://arxiv.org/pdf/2411.07941v2",
    "published_date": "2024-11-12 17:11:18 UTC",
    "updated_date": "2024-12-11 10:01:03 UTC"
  },
  {
    "arxiv_id": "2411.07940v2",
    "title": "Automatic dataset shift identification to support root cause analysis of AI performance drift",
    "authors": [
      "Mélanie Roschewitz",
      "Raghav Mehta",
      "Charles Jones",
      "Ben Glocker"
    ],
    "abstract": "Shifts in data distribution can substantially harm the performance of\nclinical AI models. Hence, various methods have been developed to detect the\npresence of such shifts at deployment time. However, root causes of dataset\nshifts are varied, and the choice of shift mitigation strategies is highly\ndependent on the precise type of shift encountered at test time. As such,\ndetecting test-time dataset shift is not sufficient: precisely identifying\nwhich type of shift has occurred is critical. In this work, we propose the\nfirst unsupervised dataset shift identification framework, effectively\ndistinguishing between prevalence shift (caused by a change in the label\ndistribution), covariate shift (caused by a change in input characteristics)\nand mixed shifts (simultaneous prevalence and covariate shifts). We discuss the\nimportance of self-supervised encoders for detecting subtle covariate shifts\nand propose a novel shift detector leveraging both self-supervised encoders and\ntask model outputs for improved shift detection. We report promising results\nfor the proposed shift identification framework across three different imaging\nmodalities (chest radiography, digital mammography, and retinal fundus images)\non five types of real-world dataset shifts, using four large publicly available\ndatasets.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Code available at\n  https://github.com/biomedia-mira/shift_identification",
    "pdf_url": "http://arxiv.org/pdf/2411.07940v2",
    "published_date": "2024-11-12 17:09:20 UTC",
    "updated_date": "2024-11-13 10:29:51 UTC"
  },
  {
    "arxiv_id": "2411.07934v2",
    "title": "Doubly Mild Generalization for Offline Reinforcement Learning",
    "authors": [
      "Yixiu Mao",
      "Qi Wang",
      "Yun Qu",
      "Yuhang Jiang",
      "Xiangyang Ji"
    ],
    "abstract": "Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07934v2",
    "published_date": "2024-11-12 17:04:56 UTC",
    "updated_date": "2024-11-13 06:34:07 UTC"
  },
  {
    "arxiv_id": "2411.07885v3",
    "title": "RadioActive: 3D Radiological Interactive Segmentation Benchmark",
    "authors": [
      "Constantin Ulrich",
      "Tassilo Wald",
      "Emily Tempus",
      "Maximilian Rokuss",
      "Paul F. Jaeger",
      "Klaus Maier-Hein"
    ],
    "abstract": "Effortless and precise segmentation with minimal clinician effort could\ngreatly streamline clinical workflows. Recent interactive segmentation models,\ninspired by METAs Segment Anything, have made significant progress but face\ncritical limitations in 3D radiology. These include impractical human\ninteraction requirements such as slice-by-slice operations for 2D models on 3D\ndata and a lack of iterative refinement. Prior studies have been hindered by\ninadequate evaluation protocols, resulting in unreliable performance\nassessments and inconsistent findings across studies. The RadioActive benchmark\naddresses these challenges by providing a rigorous and reproducible evaluation\nframework for interactive segmentation methods in clinically relevant\nscenarios. It features diverse datasets, a wide range of target structures, and\nthe most impactful 2D and 3D interactive segmentation methods, all within a\nflexible and extensible codebase. We also introduce advanced prompting\ntechniques that reduce interaction steps, enabling fair comparisons between 2D\nand 3D models. Surprisingly, SAM2 outperforms all specialized medical 2D and 3D\nmodels in a setting requiring only a few interactions to generate prompts for a\n3D volume. This challenges prevailing assumptions and demonstrates that\ngeneral-purpose models surpass specialized medical approaches. By open-sourcing\nRadioActive, we invite researchers to integrate their models and prompting\ntechniques, ensuring continuous and transparent evaluation of 3D medical\ninteractive models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Undergoing Peer-Review",
    "pdf_url": "http://arxiv.org/pdf/2411.07885v3",
    "published_date": "2024-11-12 15:47:17 UTC",
    "updated_date": "2025-03-21 15:47:12 UTC"
  },
  {
    "arxiv_id": "2411.07873v1",
    "title": "Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules",
    "authors": [
      "Binxu Wang",
      "Jiaqi Shang",
      "Haim Sompolinsky"
    ],
    "abstract": "Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE",
      "68T07, 68T09, 68T20, 62H30",
      "I.2.6; I.2.10; I.2.7; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper",
    "pdf_url": "http://arxiv.org/pdf/2411.07873v1",
    "published_date": "2024-11-12 15:29:50 UTC",
    "updated_date": "2024-11-12 15:29:50 UTC"
  },
  {
    "arxiv_id": "2411.07871v1",
    "title": "Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in Alzheimer's Disease",
    "authors": [
      "Francesco Chiumento",
      "Mingming Liu"
    ],
    "abstract": "The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "categories": [
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper has been accepted by the conference: \"2024 International\n  Conference on Big Data (IEEE Big Data 2024)\"",
    "pdf_url": "http://arxiv.org/pdf/2411.07871v1",
    "published_date": "2024-11-12 15:28:06 UTC",
    "updated_date": "2024-11-12 15:28:06 UTC"
  },
  {
    "arxiv_id": "2411.07870v6",
    "title": "Trustful LLMs: Customizing and Grounding Text Generation with Knowledge Bases and Dual Decoders",
    "authors": [
      "Xiaofeng Zhu",
      "Jaya Krishna Mandivarapu"
    ],
    "abstract": "Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07870v6",
    "published_date": "2024-11-12 15:26:17 UTC",
    "updated_date": "2024-12-20 01:14:39 UTC"
  },
  {
    "arxiv_id": "2411.07854v1",
    "title": "Tucano: Advancing Neural Text Generation for Portuguese",
    "authors": [
      "Nicholas Kluge Corrêa",
      "Aniket Sen",
      "Sophia Falk",
      "Shiza Fatimah"
    ],
    "abstract": "Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07854v1",
    "published_date": "2024-11-12 15:06:06 UTC",
    "updated_date": "2024-11-12 15:06:06 UTC"
  },
  {
    "arxiv_id": "2411.07850v1",
    "title": "IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems",
    "authors": [
      "Xiaoyin Yi",
      "Jiacheng Huang"
    ],
    "abstract": "Adversarial examples, which are inputs deliberately perturbed with\nimperceptible changes to induce model errors, have raised serious concerns for\nthe reliability and security of deep neural networks (DNNs). While adversarial\nattacks have been extensively studied in continuous data domains such as\nimages, the discrete nature of text presents unique challenges. In this paper,\nwe propose Irony-based Adversarial Examples (IAE), a method that transforms\nstraightforward sentences into ironic ones to create adversarial text. This\napproach exploits the rhetorical device of irony, where the intended meaning is\nopposite to the literal interpretation, requiring a deeper understanding of\ncontext to detect. The IAE method is particularly challenging due to the need\nto accurately locate evaluation words, substitute them with appropriate\ncollocations, and expand the text with suitable ironic elements while\nmaintaining semantic coherence. Our research makes the following key\ncontributions: (1) We introduce IAE, a strategy for generating textual\nadversarial examples using irony. This method does not rely on pre-existing\nirony corpora, making it a versatile tool for creating adversarial text in\nvarious NLP tasks. (2) We demonstrate that the performance of several\nstate-of-the-art deep learning models on sentiment analysis tasks significantly\ndeteriorates when subjected to IAE attacks. This finding underscores the\nsusceptibility of current NLP systems to adversarial manipulation through\nirony. (3) We compare the impact of IAE on human judgment versus NLP systems,\nrevealing that humans are less susceptible to the effects of irony in text.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07850v1",
    "published_date": "2024-11-12 15:01:47 UTC",
    "updated_date": "2024-11-12 15:01:47 UTC"
  },
  {
    "arxiv_id": "2411.07845v1",
    "title": "Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics Statements",
    "authors": [
      "Antonia Karamolegkou",
      "Sandrine Schiller Hansen",
      "Ariadni Christopoulou",
      "Filippos Stamatiou",
      "Anne Lauscher",
      "Anders Søgaard"
    ],
    "abstract": "What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,\na corpus of 1,580 ethical concern statements extracted from scientific papers\npublished in the ACL Anthology. We extract ethical concern keywords from the\nstatements and show promising results in automating the concern identification\nprocess. Through a survey, we compare the ethical concerns of the corpus to the\nconcerns listed by the general public and professionals in the field. Finally,\nwe compare our retrieved ethical concerns with existing taxonomies pointing to\ngaps and future research directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07845v1",
    "published_date": "2024-11-12 14:53:12 UTC",
    "updated_date": "2024-11-12 14:53:12 UTC"
  },
  {
    "arxiv_id": "2411.07843v1",
    "title": "Chain Association-based Attacking and Shielding Natural Language Processing Systems",
    "authors": [
      "Jiacheng Huang",
      "Long Chen"
    ],
    "abstract": "Association as a gift enables people do not have to mention something in\ncompletely straightforward words and allows others to understand what they\nintend to refer to. In this paper, we propose a chain association-based\nadversarial attack against natural language processing systems, utilizing the\ncomprehension gap between humans and machines. We first generate a chain\nassociation graph for Chinese characters based on the association paradigm for\nbuilding search space of potential adversarial examples. Then, we introduce an\ndiscrete particle swarm optimization algorithm to search for the optimal\nadversarial examples. We conduct comprehensive experiments and show that\nadvanced natural language processing models and applications, including large\nlanguage models, are vulnerable to our attack, while humans appear good at\nunderstanding the perturbed text. We also explore two methods, including\nadversarial training and associative graph-based recovery, to shield systems\nfrom chain association-based attack. Since a few examples that use some\nderogatory terms, this paper contains materials that may be offensive or\nupsetting to some people.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07843v1",
    "published_date": "2024-11-12 14:51:41 UTC",
    "updated_date": "2024-11-12 14:51:41 UTC"
  },
  {
    "arxiv_id": "2411.07841v1",
    "title": "Federated Learning for Discrete Optimal Transport with Large Population under Incomplete Information",
    "authors": [
      "Navpreet Kaur",
      "Juntao Chen",
      "Yingdong Lu"
    ],
    "abstract": "Optimal transport is a powerful framework for the efficient allocation of\nresources between sources and targets. However, traditional models often\nstruggle to scale effectively in the presence of large and heterogeneous\npopulations. In this work, we introduce a discrete optimal transport framework\ndesigned to handle large-scale, heterogeneous target populations, characterized\nby type distributions. We address two scenarios: one where the type\ndistribution of targets is known, and one where it is unknown. For the known\ndistribution, we propose a fully distributed algorithm to achieve optimal\nresource allocation. In the case of unknown distribution, we develop a\nfederated learning-based approach that enables efficient computation of the\noptimal transport scheme while preserving privacy. Case studies are provided to\nevaluate the performance of our learning algorithm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07841v1",
    "published_date": "2024-11-12 14:46:31 UTC",
    "updated_date": "2024-11-12 14:46:31 UTC"
  },
  {
    "arxiv_id": "2411.07826v2",
    "title": "Efficient Federated Finetuning of Tiny Transformers with Resource-Constrained Devices",
    "authors": [
      "Kilian Pfeiffer",
      "Mohamed Aboelenien Ahmed",
      "Ramin Khalili",
      "Jörg Henkel"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) through Transformer structures\nhave dominated many machine learning tasks, especially text processing.\nHowever, these models require massive amounts of data for training and induce\nhigh resource requirements, particularly in terms of the large number of\nFloating Point Operations (FLOPs) and the high amounts of memory needed. To\nfine-tune such a model in a parameter-efficient way, techniques like Adapter or\nLoRA have been developed. However, we observe that the application of LoRA,\nwhen used in federated learning (FL), while still being parameter-efficient, is\nmemory and FLOP inefficient. Based on that observation, we develop a novel\nlayer finetuning scheme that allows devices in cross-device FL to make use of\npretrained neural networks (NNs) while adhering to given resource constraints.\nWe show that our presented scheme outperforms the current state of the art when\ndealing with homogeneous or heterogeneous computation and memory constraints\nand is on par with LoRA regarding limited communication, thereby achieving\nsignificantly higher accuracies in FL training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07826v2",
    "published_date": "2024-11-12 14:22:16 UTC",
    "updated_date": "2025-04-16 09:51:33 UTC"
  },
  {
    "arxiv_id": "2411.07796v1",
    "title": "PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health Monitoring",
    "authors": [
      "M. Jaleed Khan",
      "Manu Vatish",
      "Gabriel Davis Jones"
    ],
    "abstract": "Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and\npotential misdiagnoses. This paper introduces PatchCTG, a transformer-based\nmodel specifically designed for CTG analysis, employing patch-based\ntokenisation, instance normalisation and channel-independent processing to\ncapture essential local and global temporal dependencies within CTG signals.\nPatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over\n20,000 CTG traces across diverse clinical outcomes after applying the inclusion\nand exclusion criteria. With extensive hyperparameter optimisation, PatchCTG\nachieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at\nYouden's index threshold, demonstrating adaptability to various clinical needs.\nTesting across varying temporal thresholds showed robust predictive\nperformance, particularly with finetuning on data closer to delivery, achieving\na sensitivity of 52% and specificity of 88% for near-delivery cases. These\nfindings suggest the potential of PatchCTG to enhance clinical decision-making\nin antepartum care by providing a reliable, objective tool for fetal health\nassessment. The source code is available at\nhttps://github.com/jaleedkhan/PatchCTG.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07796v1",
    "published_date": "2024-11-12 13:46:58 UTC",
    "updated_date": "2024-11-12 13:46:58 UTC"
  },
  {
    "arxiv_id": "2411.07781v1",
    "title": "RedCode: Risky Code Execution and Generation Benchmark for Code Agents",
    "authors": [
      "Chengquan Guo",
      "Xun Liu",
      "Chulin Xie",
      "Andy Zhou",
      "Yi Zeng",
      "Zinan Lin",
      "Dawn Song",
      "Bo Li"
    ],
    "abstract": "With the rapidly increasing capabilities and adoption of code agents for\nAI-assisted coding, safety concerns, such as generating or executing risky\ncode, have become significant barriers to the real-world deployment of these\nagents. To provide comprehensive and practical evaluations on the safety of\ncode agents, we propose RedCode, a benchmark for risky code execution and\ngeneration: (1) RedCode-Exec provides challenging prompts that could lead to\nrisky code execution, aiming to evaluate code agents' ability to recognize and\nhandle unsafe code. We provide a total of 4,050 risky test cases in Python and\nBash tasks with diverse input formats including code snippets and natural text.\nThey covers 25 types of critical vulnerabilities spanning 8 domains (e.g.,\nwebsites, file systems). We provide Docker environments and design\ncorresponding evaluation metrics to assess their execution results. (2)\nRedCode-Gen provides 160 prompts with function signatures and docstrings as\ninput to assess whether code agents will follow instructions to generate\nharmful code or software. Our empirical findings, derived from evaluating three\nagent frameworks based on 19 LLMs, provide insights into code agents'\nvulnerabilities. For instance, evaluations on RedCode-Exec show that agents are\nmore likely to reject executing risky operations on the operating system, but\nare less likely to reject executing technically buggy code, indicating high\nrisks. Risky operations described in natural text lead to a lower rejection\nrate than those in code format. Additionally, evaluations on RedCode-Gen show\nthat more capable base models and agents with stronger overall coding\nabilities, such as GPT4, tend to produce more sophisticated and effective\nharmful software. Our findings highlight the need for stringent safety\nevaluations for diverse code agents. Our dataset and code are available at\nhttps://github.com/AI-secure/RedCode.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by NeurIPS 2024 Datasets and Benchmarks Track",
    "pdf_url": "http://arxiv.org/pdf/2411.07781v1",
    "published_date": "2024-11-12 13:30:06 UTC",
    "updated_date": "2024-11-12 13:30:06 UTC"
  },
  {
    "arxiv_id": "2411.07773v2",
    "title": "Pointwise Mutual Information as a Performance Gauge for Retrieval-Augmented Generation",
    "authors": [
      "Tianyu Liu",
      "Jirui Qi",
      "Paul He",
      "Arianna Bisazza",
      "Mrinmaya Sachan",
      "Ryan Cotterell"
    ],
    "abstract": "Recent work suggests that large language models enhanced with\nretrieval-augmented generation are easily influenced by the order, in which the\nretrieved documents are presented to the model when solving tasks such as\nquestion answering (QA). However, there is no method to date that exploits this\nphenomenon to improve generation. We fill this gap. In this study, we show that\nthe pointwise mutual information between a context and a question is an\neffective gauge for language model performance. Importantly, this gauge does\nnot depend on knowing the answer to the question a priori. Through experiments\non two question-answering datasets and a variety of large language models, we\nfind evidence for an empirical correlation between answer accuracy and\npointwise mutual information. Additionally, we propose two methods that use the\npointwise mutual information between a document and a question as a gauge for\nselecting and constructing prompts that lead to better performance, whose\neffectiveness we demonstrate through experimentation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Main Conference. Code is available at\n  https://github.com/lyutyuh/poptimizer",
    "pdf_url": "http://arxiv.org/pdf/2411.07773v2",
    "published_date": "2024-11-12 13:14:09 UTC",
    "updated_date": "2025-02-22 15:35:11 UTC"
  },
  {
    "arxiv_id": "2411.07772v2",
    "title": "Automatic Album Sequencing",
    "authors": [
      "Vincent Herrmann",
      "Dylan R. Ashley",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "cs.SD",
      "eess.AS",
      "68T07",
      "H.5.5; I.2.6; I.5.1; J.5"
    ],
    "primary_category": "cs.LG",
    "comment": "presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text + 1 page of\n  references, 3 figures in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing",
    "pdf_url": "http://arxiv.org/pdf/2411.07772v2",
    "published_date": "2024-11-12 13:13:20 UTC",
    "updated_date": "2024-11-26 14:55:05 UTC"
  },
  {
    "arxiv_id": "2411.08925v1",
    "title": "Retrieval of sun-induced plant fluorescence in the O$_2$-A absorption band from DESIS imagery",
    "authors": [
      "Jim Buffat",
      "Miguel Pato",
      "Kevin Alonso",
      "Stefan Auer",
      "Emiliano Carmona",
      "Stefan Maier",
      "Rupert Müller",
      "Patrick Rademske",
      "Uwe Rascher",
      "Hanno Scharr"
    ],
    "abstract": "We provide the first method allowing to retrieve spaceborne SIF maps at 30 m\nground resolution with a strong correlation ($r^2=0.6$) to high-quality\nairborne estimates of sun-induced fluorescence (SIF). SIF estimates can provide\nexplanatory information for many tasks related to agricultural management and\nphysiological studies. While SIF products from airborne platforms are accurate\nand spatially well resolved, the data acquisition of such products remains\nscience-oriented and limited to temporally constrained campaigns. Spaceborne\nSIF products on the other hand are available globally with often sufficient\nrevisit times. However, the spatial resolution of spaceborne SIF products is\ntoo small for agricultural applications. In view of ESA's upcoming FLEX mission\nwe develop a method for SIF retrieval in the O$_2$-A band of hyperspectral\nDESIS imagery to provide first insights for spaceborne SIF retrieval at high\nspatial resolution. To this end, we train a simulation-based self-supervised\nnetwork with a novel perturbation based regularizer and test performance\nimprovements under additional supervised regularization of atmospheric variable\nprediction. In a validation study with corresponding HyPlant derived SIF\nestimates at 740 nm we find that our model reaches a mean absolute difference\nof 0.78 mW / nm / sr / m$^2$.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.geo-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "submitted to ECCV CVPPA 2024, 14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.08925v1",
    "published_date": "2024-11-12 13:02:06 UTC",
    "updated_date": "2024-11-12 13:02:06 UTC"
  },
  {
    "arxiv_id": "2411.07763v2",
    "title": "Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows",
    "authors": [
      "Fangyu Lei",
      "Jixuan Chen",
      "Yuxiao Ye",
      "Ruisheng Cao",
      "Dongchan Shin",
      "Hongjin Su",
      "Zhaoqing Suo",
      "Hongcheng Gao",
      "Wenjing Hu",
      "Pengcheng Yin",
      "Victor Zhong",
      "Caiming Xiong",
      "Ruoxi Sun",
      "Qian Liu",
      "Sida Wang",
      "Tao Yu"
    ],
    "abstract": "Real-world enterprise text-to-SQL workflows often involve complex cloud or\nlocal data across various database systems, multiple SQL queries in various\ndialects, and diverse operations from data transformation to analytics. We\nintroduce Spider 2.0, an evaluation framework comprising 632 real-world\ntext-to-SQL workflow problems derived from enterprise-level database use cases.\nThe databases in Spider 2.0 are sourced from real data applications, often\ncontaining over 1,000 columns and stored in local or cloud database systems\nsuch as BigQuery and Snowflake. We show that solving problems in Spider 2.0\nfrequently requires understanding and searching through database metadata,\ndialect documentation, and even project-level codebases. This challenge calls\nfor models to interact with complex SQL workflow environments, process\nextremely long contexts, perform intricate reasoning, and generate multiple SQL\nqueries with diverse operations, often exceeding 100 lines, which goes far\nbeyond traditional text-to-SQL challenges. Our evaluations indicate that based\non o1-preview, our code agent framework successfully solves only 21.3% of the\ntasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD. Our results on\nSpider 2.0 show that while language models have demonstrated remarkable\nperformance in code generation -- especially in prior text-to-SQL benchmarks --\nthey require significant improvement in order to achieve adequate performance\nfor real-world enterprise usage. Progress on Spider 2.0 represents crucial\nsteps towards developing intelligent, autonomous, code agents for real-world\nenterprise settings. Our code, baseline models, and data are available at\nhttps://spider2-sql.github.io",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2411.07763v2",
    "published_date": "2024-11-12 12:52:17 UTC",
    "updated_date": "2025-03-17 16:10:45 UTC"
  },
  {
    "arxiv_id": "2411.07762v2",
    "title": "ASER: Activation Smoothing and Error Reconstruction for Large Language Model Quantization",
    "authors": [
      "Weibo Zhao",
      "Yubin Shi",
      "Xinyu Lyu",
      "Wanchen Sui",
      "Shen Li",
      "Yong Li"
    ],
    "abstract": "Quantization stands as a pivotal technique for large language model (LLM)\nserving, yet it poses significant challenges particularly in achieving\neffective low-bit quantization. The limited numerical mapping makes the\nquantized model produce a non-trivial error, bringing out intolerable\nperformance degration. This paper is anchored in the basic idea of model\ncompression objectives, and delves into the layer-wise error distribution of\nLLMs during post-training quantization. Subsequently, we introduce ASER, an\nalgorithm consisting of (1) Error Reconstruction: low-rank compensation for\nquantization error with LoRA-style matrices constructed by whitening SVD; (2)\nActivation Smoothing: outlier extraction to gain smooth activation and better\nerror compensation. ASER is capable of quantizing typical LLMs to low-bit ones,\nparticularly preserving accuracy even in W4A8 per-channel setup. Experimental\nresults show that ASER is competitive among the state-of-the-art quantization\nalgorithms, showing potential to activation quantization, with minor overhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.07762v2",
    "published_date": "2024-11-12 12:52:04 UTC",
    "updated_date": "2024-12-12 02:41:45 UTC"
  },
  {
    "arxiv_id": "2411.07760v1",
    "title": "Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit Q-Learning",
    "authors": [
      "Alexi Canesse",
      "Mathieu Petitbois",
      "Ludovic Denoyer",
      "Sylvain Lamprier",
      "Rémy Portelas"
    ],
    "abstract": "Offline Reinforcement Learning (RL) has emerged as a powerful alternative to\nimitation learning for behavior modeling in various domains, particularly in\ncomplex navigation tasks. An existing challenge with Offline RL is the\nsignal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to\nerrors in value estimates. Towards this, multiple works have demonstrated the\nadvantage of hierarchical offline RL methods, which decouples high-level path\nplanning from low-level path following. In this work, we present a novel\nhierarchical transformer-based approach leveraging a learned quantizer of the\nspace. This quantization enables the training of a simpler zone-conditioned\nlow-level policy and simplifies planning, which is reduced to discrete\nautoregressive prediction. Among other benefits, zone-level reasoning in\nplanning enables explicit trajectory stitching rather than implicit stitching\nbased on noisy value function estimates. By combining this transformer-based\nplanner with recent advancements in offline RL, our proposed approach achieves\nstate-of-the-art results in complex long-distance navigation environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review. Code will be released upon acceptance",
    "pdf_url": "http://arxiv.org/pdf/2411.07760v1",
    "published_date": "2024-11-12 12:49:41 UTC",
    "updated_date": "2024-11-12 12:49:41 UTC"
  },
  {
    "arxiv_id": "2411.07759v1",
    "title": "Optimizing Traffic Signal Control using High-Dimensional State Representation and Efficient Deep Reinforcement Learning",
    "authors": [
      "Lawrence Francis",
      "Blessed Guda",
      "Ahmed Biyabani"
    ],
    "abstract": "In reinforcement learning-based (RL-based) traffic signal control (TSC),\ndecisions on the signal timing are made based on the available information on\nvehicles at a road intersection. This forms the state representation for the RL\nenvironment which can either be high-dimensional containing several variables\nor a low-dimensional vector. Current studies suggest that using high\ndimensional state representations does not lead to improved performance on TSC.\nHowever, we argue, with experimental results, that the use of high dimensional\nstate representations can, in fact, lead to improved TSC performance with\nimprovements up to 17.9% of the average waiting time. This high-dimensional\nrepresentation is obtainable using the cost-effective vehicle-to-infrastructure\n(V2I) communication, encouraging its adoption for TSC. Additionally, given the\nlarge size of the state, we identified the need to have computational efficient\nmodels and explored model compression via pruning.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2411.07759v1",
    "published_date": "2024-11-12 12:37:50 UTC",
    "updated_date": "2024-11-12 12:37:50 UTC"
  },
  {
    "arxiv_id": "2411.07751v2",
    "title": "SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State Space Model",
    "authors": [
      "Xinyuan Qian",
      "Jiaran Gao",
      "Yaodan Zhang",
      "Qiquan Zhang",
      "Hexin Liu",
      "Leibny Paola Garcia",
      "Haizhou Li"
    ],
    "abstract": "Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted by IEEE Journal of Selected Topics in Signal Processing",
    "pdf_url": "http://arxiv.org/pdf/2411.07751v2",
    "published_date": "2024-11-12 12:23:41 UTC",
    "updated_date": "2025-04-02 10:39:14 UTC"
  },
  {
    "arxiv_id": "2411.07739v1",
    "title": "Unlocking Legal Knowledge with Multi-Layered Embedding-Based Retrieval",
    "authors": [
      "João Alberto de Oliveira Lima"
    ],
    "abstract": "This work addresses the challenge of capturing the complexities of legal\nknowledge by proposing a multi-layered embedding-based retrieval method for\nlegal and legislative texts. Creating embeddings not only for individual\narticles but also for their components (paragraphs, clauses) and structural\ngroupings (books, titles, chapters, etc), we seek to capture the subtleties of\nlegal information through the use of dense vectors of embeddings, representing\nit at varying levels of granularity. Our method meets various information needs\nby allowing the Retrieval Augmented Generation system to provide accurate\nresponses, whether for specific segments or entire sections, tailored to the\nuser's query. We explore the concepts of aboutness, semantic chunking, and\ninherent hierarchy within legal texts, arguing that this method enhances the\nlegal information retrieval. Despite the focus being on Brazil's legislative\nmethods and the Brazilian Constitution, which follow a civil law tradition, our\nfindings should in principle be applicable across different legal systems,\nincluding those adhering to common law traditions. Furthermore, the principles\nof the proposed method extend beyond the legal domain, offering valuable\ninsights for organizing and retrieving information in any field characterized\nby information encoded in hierarchical text.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "27 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07739v1",
    "published_date": "2024-11-12 12:03:57 UTC",
    "updated_date": "2024-11-12 12:03:57 UTC"
  },
  {
    "arxiv_id": "2411.07728v1",
    "title": "No-Reference Point Cloud Quality Assessment via Graph Convolutional Network",
    "authors": [
      "Wu Chen",
      "Qiuping Jiang",
      "Wei Zhou",
      "Feng Shao",
      "Guangtao Zhai",
      "Weisi Lin"
    ],
    "abstract": "Three-dimensional (3D) point cloud, as an emerging visual media format, is\nincreasingly favored by consumers as it can provide more realistic visual\ninformation than two-dimensional (2D) data. Similar to 2D plane images and\nvideos, point clouds inevitably suffer from quality degradation and information\nloss through multimedia communication systems. Therefore, automatic point cloud\nquality assessment (PCQA) is of critical importance. In this work, we propose a\nnovel no-reference PCQA method by using a graph convolutional network (GCN) to\ncharacterize the mutual dependencies of multi-view 2D projected image contents.\nThe proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,\nmulti-view projection, graph construction, and GCN-based quality prediction.\nFirst, multi-view projection is performed on the test point cloud to obtain a\nset of horizontally and vertically projected images. Then, a\nperception-consistent graph is constructed based on the spatial relations among\ndifferent projected images. Finally, reasoning on the constructed graph is\nperformed by GCN to characterize the mutual dependencies and interactions\nbetween different projected images, and aggregate feature information of\nmulti-view projected images for final quality prediction. Experimental results\non two publicly available benchmark databases show that our proposed GC-PCQA\ncan achieve superior performance than state-of-the-art quality assessment\nmetrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Transactions on Multimedia",
    "pdf_url": "http://arxiv.org/pdf/2411.07728v1",
    "published_date": "2024-11-12 11:39:05 UTC",
    "updated_date": "2024-11-12 11:39:05 UTC"
  },
  {
    "arxiv_id": "2411.07722v1",
    "title": "Is Cognition consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding",
    "authors": [
      "Zirui Shao",
      "Chuwei Luo",
      "Zhaoqing Zhu",
      "Hangdi Xing",
      "Zhi Yu",
      "Qi Zheng",
      "Jiajun Bu"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin document understanding, a rapidly growing research area with significant\nindustrial demand in recent years. As a multimodal task, document understanding\nrequires models to possess both perceptual and cognitive abilities. However,\ncurrent MLLMs often face conflicts between perception and cognition. Taking a\ndocument VQA task (cognition) as an example, an MLLM might generate answers\nthat do not match the corresponding visual content identified by its OCR\n(perception). This conflict suggests that the MLLM might struggle to establish\nan intrinsic connection between the information it \"sees\" and what it\n\"understands.\" Such conflicts challenge the intuitive notion that cognition is\nconsistent with perception, hindering the performance and explainability of\nMLLMs. In this paper, we define the conflicts between cognition and perception\nas Cognition and Perception (C&P) knowledge conflicts, a form of multimodal\nknowledge conflicts, and systematically assess them with a focus on document\nunderstanding. Our analysis reveals that even GPT-4o, a leading MLLM, achieves\nonly 68.6% C&P consistency. To mitigate the C&P knowledge conflicts, we propose\na novel method called Multimodal Knowledge Consistency Fine-tuning. This method\nfirst ensures task-specific consistency and then connects the cognitive and\nperceptual knowledge. Our method significantly reduces C&P knowledge conflicts\nacross all tested MLLMs and enhances their performance in both cognitive and\nperceptual tasks in most scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2411.07722v1",
    "published_date": "2024-11-12 11:28:50 UTC",
    "updated_date": "2024-11-12 11:28:50 UTC"
  },
  {
    "arxiv_id": "2411.07715v1",
    "title": "Training Data for Large Language Model",
    "authors": [
      "Yiming Ju",
      "Huanhuan Ma"
    ],
    "abstract": "In 2022, with the release of ChatGPT, large-scale language models gained\nwidespread attention. ChatGPT not only surpassed previous models in terms of\nparameters and the scale of its pretraining corpus but also achieved\nrevolutionary performance improvements through fine-tuning on a vast amount of\nhigh-quality, human-annotated data. This progress has led enterprises and\nresearch institutions to recognize that building smarter and more powerful\nmodels relies on rich and high-quality datasets. Consequently, the construction\nand optimization of datasets have become a critical focus in the field of\nartificial intelligence. This paper summarizes the current state of pretraining\nand fine-tuning data for training large-scale language models, covering aspects\nsuch as data scale, collection methods, data types and characteristics,\nprocessing workflows, and provides an overview of available open-source\ndatasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "in Chinese language",
    "pdf_url": "http://arxiv.org/pdf/2411.07715v1",
    "published_date": "2024-11-12 11:09:58 UTC",
    "updated_date": "2024-11-12 11:09:58 UTC"
  },
  {
    "arxiv_id": "2411.07691v1",
    "title": "New Emerged Security and Privacy of Pre-trained Model: a Survey and Outlook",
    "authors": [
      "Meng Yang",
      "Tianqing Zhu",
      "Chi Liu",
      "WanLei Zhou",
      "Shui Yu",
      "Philip S. Yu"
    ],
    "abstract": "Thanks to the explosive growth of data and the development of computational\nresources, it is possible to build pre-trained models that can achieve\noutstanding performance on various tasks, such as neural language processing,\ncomputer vision, and more. Despite their powerful capabilities, pre-trained\nmodels have also sparked attention to the emerging security challenges\nassociated with their real-world applications. Security and privacy issues,\nsuch as leaking privacy information and generating harmful responses, have\nseriously undermined users' confidence in these powerful models. Concerns are\ngrowing as model performance improves dramatically. Researchers are eager to\nexplore the unique security and privacy issues that have emerged, their\ndistinguishing factors, and how to defend against them. However, the current\nliterature lacks a clear taxonomy of emerging attacks and defenses for\npre-trained models, which hinders a high-level and comprehensive understanding\nof these questions. To fill the gap, we conduct a systematical survey on the\nsecurity risks of pre-trained models, proposing a taxonomy of attack and\ndefense methods based on the accessibility of pre-trained models' input and\nweights in various security test scenarios. This taxonomy categorizes attacks\nand defenses into No-Change, Input-Change, and Model-Change approaches. With\nthe taxonomy analysis, we capture the unique security and privacy issues of\npre-trained models, categorizing and summarizing existing security issues based\non their characteristics. In addition, we offer a timely and comprehensive\nreview of each category's strengths and limitations. Our survey concludes by\nhighlighting potential new research opportunities in the security and privacy\nof pre-trained models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07691v1",
    "published_date": "2024-11-12 10:15:33 UTC",
    "updated_date": "2024-11-12 10:15:33 UTC"
  },
  {
    "arxiv_id": "2411.07690v1",
    "title": "World Models: The Safety Perspective",
    "authors": [
      "Zifan Zeng",
      "Chongzhe Zhang",
      "Feng Liu",
      "Joseph Sifakis",
      "Qunli Zhang",
      "Shiming Liu",
      "Peng Wang"
    ],
    "abstract": "With the proliferation of the Large Language Model (LLM), the concept of\nWorld Models (WM) has recently attracted a great deal of attention in the AI\nresearch community, especially in the context of AI agents. It is arguably\nevolving into an essential foundation for building AI agent systems. A WM is\nintended to help the agent predict the future evolution of environmental states\nor help the agent fill in missing information so that it can plan its actions\nand behave safely. The safety property of WM plays a key role in their\neffective use in critical applications. In this work, we review and analyze the\nimpacts of the current state-of-the-art in WM technology from the point of view\nof trustworthiness and safety based on a comprehensive survey and the fields of\napplication envisaged. We provide an in-depth analysis of state-of-the-art WMs\nand derive technical research challenges and their impact in order to call on\nthe research community to collaborate on improving the safety and\ntrustworthiness of WM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 3 figures, accepted at the International Workshop on\n  Dependability Modeling and Design (WDMD) during the IEEE International\n  Symposium on Software Reliability Engineering (ISSRE)",
    "pdf_url": "http://arxiv.org/pdf/2411.07690v1",
    "published_date": "2024-11-12 10:15:11 UTC",
    "updated_date": "2024-11-12 10:15:11 UTC"
  },
  {
    "arxiv_id": "2411.07688v3",
    "title": "ImageRAG: Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with ImageRAG",
    "authors": [
      "Zilun Zhang",
      "Haozhan Shen",
      "Tiancheng Zhao",
      "Zian Guan",
      "Bin Chen",
      "Yuhao Wang",
      "Xu Jia",
      "Yuxiang Cai",
      "Yongheng Shang",
      "Jianwei Yin"
    ],
    "abstract": "Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000\n$\\times$ 100,000 pixels or more) poses a significant challenge for current\nRemote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize\nthe UHR image to standard input image size, the extensive spatial and\ncontextual information that UHR images contain will be neglected. Otherwise,\nthe original size of these images often exceeds the token limits of standard\nRSMLLMs, making it difficult to process the entire image and capture long-range\ndependencies to answer the query based on the abundant visual context. In this\npaper, we introduce ImageRAG for RS, a training-free framework to address the\ncomplexities of analyzing UHR remote sensing imagery. By transforming UHR\nremote sensing image analysis task to image's long context selection task, we\ndesign an innovative image contextual retrieval mechanism based on the\nRetrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's\ncore innovation lies in its ability to selectively retrieve and focus on the\nmost relevant portions of the UHR image as visual contexts that pertain to a\ngiven query. Fast path and slow path are proposed in this framework to handle\nthis task efficiently and effectively. ImageRAG allows RSMLLMs to manage\nextensive context and spatial information from UHR RSI, ensuring the analysis\nis both accurate and efficient. Codebase will be released in\nhttps://github.com/om-ai-lab/ImageRAG",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "full paper",
    "pdf_url": "http://arxiv.org/pdf/2411.07688v3",
    "published_date": "2024-11-12 10:12:12 UTC",
    "updated_date": "2025-05-18 03:58:52 UTC"
  },
  {
    "arxiv_id": "2411.07686v1",
    "title": "Data-Driven Graph Switching for Cyber-Resilient Control in Microgrids",
    "authors": [
      "Suman Rath",
      "Subham Sahoo"
    ],
    "abstract": "Distributed microgrids are conventionally dependent on communication networks\nto achieve secondary control objectives. This dependence makes them vulnerable\nto stealth data integrity attacks (DIAs) where adversaries may perform\nmanipulations via infected transmitters and repeaters to jeopardize stability.\nThis paper presents a physics-guided, supervised Artificial Neural Network\n(ANN)-based framework that identifies communication-level cyberattacks in\nmicrogrids by analyzing whether incoming measurements will cause abnormal\nbehavior of the secondary control layer. If abnormalities are detected, an\niteration through possible spanning tree graph topologies that can be used to\nfulfill secondary control objectives is done. Then, a communication network\ntopology that would not create secondary control abnormalities is identified\nand enforced for maximum stability. By altering the communication graph\ntopology, the framework eliminates the dependence of the secondary control\nlayer on inputs from compromised cyber devices helping it achieve resilience\nwithout instability. Several case studies are provided showcasing the\nrobustness of the framework against False Data Injections and repeater-level\nMan-in-the-Middle attacks. To understand practical feasibility, robustness is\nalso verified against larger microgrid sizes and in the presence of varying\nnoise levels. Our findings indicate that performance can be affected when\nattempting scalability in the presence of noise. However, the framework\noperates robustly in low-noise settings.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted in IEEE Design Methodologies Conference (DMC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07686v1",
    "published_date": "2024-11-12 09:58:21 UTC",
    "updated_date": "2024-11-12 09:58:21 UTC"
  },
  {
    "arxiv_id": "2411.07685v1",
    "title": "Fast Disentangled Slim Tensor Learning for Multi-view Clustering",
    "authors": [
      "Deng Xu",
      "Chao Zhang",
      "Zechao Li",
      "Chunlin Chen",
      "Huaxiong Li"
    ],
    "abstract": "Tensor-based multi-view clustering has recently received significant\nattention due to its exceptional ability to explore cross-view high-order\ncorrelations. However, most existing methods still encounter some limitations.\n(1) Most of them explore the correlations among different affinity matrices,\nmaking them unscalable to large-scale data. (2) Although some methods address\nit by introducing bipartite graphs, they may result in sub-optimal solutions\ncaused by an unstable anchor selection process. (3) They generally ignore the\nnegative impact of latent semantic-unrelated information in each view. To\ntackle these issues, we propose a new approach termed fast Disentangled Slim\nTensor Learning (DSTL) for multi-view clustering . Instead of focusing on the\nmulti-view graph structures, DSTL directly explores the high-order correlations\namong multi-view latent semantic representations based on matrix factorization.\nTo alleviate the negative influence of feature redundancy, inspired by robust\nPCA, DSTL disentangles the latent low-dimensional representation into a\nsemantic-unrelated part and a semantic-related part for each view.\nSubsequently, two slim tensors are constructed with tensor-based\nregularization. To further enhance the quality of feature disentanglement, the\nsemantic-related representations are aligned across views through a consensus\nalignment indicator. Our proposed model is computationally efficient and can be\nsolved effectively. Extensive experiments demonstrate the superiority and\nefficiency of DSTL over state-of-the-art approaches. The code of DSTL is\navailable at https://github.com/dengxu-nju/DSTL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages,6 figures, will be published to IEEE TMM",
    "pdf_url": "http://arxiv.org/pdf/2411.07685v1",
    "published_date": "2024-11-12 09:57:53 UTC",
    "updated_date": "2024-11-12 09:57:53 UTC"
  },
  {
    "arxiv_id": "2411.07684v1",
    "title": "AI enhanced diagnosis of Peyronies disease a novel approach using Computer Vision",
    "authors": [
      "Yudara Kularathne",
      "Janitha Prathapa",
      "Prarththanan Sothyrajah",
      "Salomi Arasaratnam",
      "Sithira Ambepitiya",
      "Thanveer Ahamed",
      "Dinuka Wijesundara"
    ],
    "abstract": "This study presents an innovative AI-driven tool for diagnosing Peyronie's\nDisease (PD), a condition that affects between 0.3% and 13.1% of men worldwide.\nOur method uses key point detection on both images and videos to measure penile\ncurvature angles, utilizing advanced computer vision techniques. This tool has\ndemonstrated high accuracy in identifying anatomical landmarks, validated\nagainst conventional goniometer measurements. Traditional PD diagnosis often\ninvolves subjective and invasive methods, which can lead to patient discomfort\nand inaccuracies. Our approach offers a precise, reliable, and non-invasive\ndiagnostic tool to address these drawbacks. The model distinguishes between PD\nand normal anatomical changes with a sensitivity of 96.7% and a specificity of\n100%. This advancement represents a significant improvement in urological\ndiagnostics, greatly enhancing the efficacy and convenience of PD assessment\nfor healthcare providers and patients.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "8 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.07684v1",
    "published_date": "2024-11-12 09:56:42 UTC",
    "updated_date": "2024-11-12 09:56:42 UTC"
  },
  {
    "arxiv_id": "2411.17705v1",
    "title": "EEG-DCNet: A Fast and Accurate MI-EEG Dilated CNN Classification Method",
    "authors": [
      "Wei Peng",
      "Kang Liu",
      "Jiaxi Shi",
      "Jianchen Hu"
    ],
    "abstract": "The electroencephalography (EEG)-based motor imagery (MI) classification is a\ncritical and challenging task in brain-computer interface (BCI) technology,\nwhich plays a significant role in assisting patients with functional\nimpairments to regain mobility. We present a novel multi-scale atrous\nconvolutional neural network (CNN) model called EEG-dilated convolution network\n(DCNet) to enhance the accuracy and efficiency of the EEG-based MI\nclassification tasks. We incorporate the $1\\times1$ convolutional layer and\nutilize the multi-branch parallel atrous convolutional architecture in\nEEG-DCNet to capture the highly nonlinear characteristics and multi-scale\nfeatures of the EEG signals. Moreover, we utilize the sliding window to enhance\nthe temporal consistency and utilize the attension mechanism to improve the\naccuracy of recognizing user intentions. The experimental results (via the\nBCI-IV-2a ,BCI-IV-2b and the High-Gamma datasets) show that EEG-DCNet\noutperforms existing state-of-the-art (SOTA) approaches in terms of\nclassification accuracy and Kappa scores. Furthermore, since EEG-DCNet requires\nless number of parameters, the training efficiency and memory consumption are\nalso improved. The experiment code is open-sourced at\n\\href{https://github.com/Kanyooo/EEG-DCNet}{here}.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.17705v1",
    "published_date": "2024-11-12 09:47:50 UTC",
    "updated_date": "2024-11-12 09:47:50 UTC"
  },
  {
    "arxiv_id": "2411.07654v1",
    "title": "Spike Talk in Power Electronic Grids -- Leveraging Post Moore's Computing Laws",
    "authors": [
      "Yubo Song",
      "Subham Sahoo"
    ],
    "abstract": "Emerging distributed generation demands highly reliable and resilient\ncoordinating control in microgrids. To improve on these aspects, spiking neural\nnetwork is leveraged, as a grid-edge intelligence tool to establish a talkative\ninfrastructure, Spike Talk, expediting coordination in next-generation\nmicrogrids without the need of communication at all. This paper unravels the\nphysics behind Spike Talk from the perspective of its distributed\ninfrastructure, which aims to address the Von Neumann Bottleneck. Relying on\ninferring information via power flows in tie lines, Spike Talk allows adaptive\nand flexible control and coordination itself, and features in synaptic\nplasticity facilitating online and local training functionality. Preliminary\ncase studies are demonstrated with results, while more extensive validations\nare to be included as future scopes of work.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.NE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.ET",
    "comment": "The manuscript has been accepted for publication in the Proceedings\n  of 2024 IEEE Design Methodologies for Power Electronics Conference (DMC2024)",
    "pdf_url": "http://arxiv.org/pdf/2411.07654v1",
    "published_date": "2024-11-12 09:06:16 UTC",
    "updated_date": "2024-11-12 09:06:16 UTC"
  },
  {
    "arxiv_id": "2411.07650v1",
    "title": "Understanding Audiovisual Deepfake Detection: Techniques, Challenges, Human Factors and Perceptual Insights",
    "authors": [
      "Ammarah Hashmi",
      "Sahibzada Adil Shahzad",
      "Chia-Wen Lin",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "abstract": "Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07650v1",
    "published_date": "2024-11-12 09:02:11 UTC",
    "updated_date": "2024-11-12 09:02:11 UTC"
  },
  {
    "arxiv_id": "2411.07634v1",
    "title": "Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel Machine Scheduling",
    "authors": [
      "Maria Zampella",
      "Urtzi Otamendi",
      "Xabier Belaunzaran",
      "Arkaitz Artetxe",
      "Igor G. Olaizola",
      "Giuseppe Longo",
      "Basilio Sierra"
    ],
    "abstract": "Scheduling problems pose significant challenges in resource, industry, and\noperational management. This paper addresses the Unrelated Parallel Machine\nScheduling Problem (UPMS) with setup times and resources using a Multi-Agent\nReinforcement Learning (MARL) approach. The study introduces the Reinforcement\nLearning environment and conducts empirical analyses, comparing MARL with\nSingle-Agent algorithms. The experiments employ various deep neural network\npolicies for single- and Multi-Agent approaches. Results demonstrate the\nefficacy of the Maskable extension of the Proximal Policy Optimization (PPO)\nalgorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in\nMulti-Agent setups. While Single-Agent algorithms perform adequately in reduced\nscenarios, Multi-Agent approaches reveal challenges in cooperative learning but\na scalable capacity. This research contributes insights into applying MARL\ntechniques to scheduling optimization, emphasizing the need for algorithmic\nsophistication balanced with scalability for intelligent scheduling solutions.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.NE",
      "I.2.1; I.2.11; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 5 figures, 4 tables, article submitted to a journal",
    "pdf_url": "http://arxiv.org/pdf/2411.07634v1",
    "published_date": "2024-11-12 08:27:27 UTC",
    "updated_date": "2024-11-12 08:27:27 UTC"
  },
  {
    "arxiv_id": "2411.07618v1",
    "title": "Direct Preference Optimization Using Sparse Feature-Level Constraints",
    "authors": [
      "Qingyu Yin",
      "Chak Tou Leong",
      "Hongbo Zhang",
      "Minjun Zhu",
      "Hanqi Yan",
      "Qiang Zhang",
      "Yulan He",
      "Wenjie Li",
      "Jun Wang",
      "Yue Zhang",
      "Linyi Yang"
    ],
    "abstract": "The alignment of large language models (LLMs) with human preferences remains\na key challenge. While post-training techniques like Reinforcement Learning\nfrom Human Feedback (RLHF) and Direct Preference Optimization (DPO) have\nachieved notable success, they often introduce computational inefficiencies and\ntraining instability. In this paper, we propose Feature-level constrained\nPreference Optimization (FPO), a novel method designed to simplify the\nalignment process while ensuring stability. FPO leverages pre-trained Sparse\nAutoencoders (SAEs) and introduces feature-level constraints, allowing for\nefficient, sparsity-enforced alignment. Our approach enjoys efficiency by using\nsparse features activated in a well-trained sparse autoencoder and the quality\nof sequential KL divergence by using the feature-level offline reference.\nExperimental results on benchmark datasets demonstrate that FPO achieves a\n5.08% absolute improvement in win rate with much lower computational cost\ncompared to state-of-the-art baselines, making it a promising solution for\nefficient and controllable LLM alignments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07618v1",
    "published_date": "2024-11-12 07:54:13 UTC",
    "updated_date": "2024-11-12 07:54:13 UTC"
  },
  {
    "arxiv_id": "2411.07611v3",
    "title": "Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models",
    "authors": [
      "Shuai Niu",
      "Jing Ma",
      "Hongzhan Lin",
      "Liang Bai",
      "Zhihua Wang",
      "Yida Xu",
      "Yunya Song",
      "Xian Yang"
    ],
    "abstract": "Interpretation is critical for disease diagnosis, but existing models\nstruggle to balance predictive accuracy with human-understandable rationales.\nWhile large language models (LLMs) offer strong reasoning abilities, their\nclinical use is limited by high computational costs and restricted multimodal\nreasoning ability. Small language models (SLMs) are efficient but lack advanced\nreasoning for integrating multimodal medical data. In addition, both LLMs and\nSLMs lack of domain knowledge for trustworthy reasoning. Therefore, we propose\nClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via\nrationale distillation and domain knowledge injection for trustworthy\nmultimodal rationale generation. Key innovations include a sequential rationale\ndistillation framework that equips SLMs with LLM-comparable mutlimodal\nreasoning abilities, and a knowledge-augmented attention mechanism that jointly\nunifies multimodal representation from time series and textual data in a same\nencoding space, enabling it naturally interpreted by SLMs while incorporating\ndomain knowledge for reliable rationale generation. Experiments on real-world\nmedical datasets show that ClinRaGen achieves state-of-the-art performance in\ndisease diagnosis and rationale generation, demonstrating the effectiveness of\ncombining LLM-driven reasoning with knowledge augmentation for improved\ninterpretability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages. 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07611v3",
    "published_date": "2024-11-12 07:34:56 UTC",
    "updated_date": "2025-04-28 03:28:51 UTC"
  },
  {
    "arxiv_id": "2411.07606v1",
    "title": "Optimizing Service Function Chain Mapping in Network Function Virtualization through Simultaneous NF Decomposition and VNF Placement",
    "authors": [
      "Asghar Asgharian-Sardroud",
      "Mohammad Hossein Izanlou",
      "Amin Jabbari",
      "Sepehr Mahmoodian Hamedani"
    ],
    "abstract": "Network function virtualization enables network operators to implement new\nservices through a process called service function chain mapping. The concept\nof Service Function Chain (SFC) is introduced to provide complex services,\nwhich is an ordered set of Network Functions (NF). The network functions of an\nSFC can be decomposed in several ways into some Virtual Network Functions\n(VNF). Additionally, the decomposed NFs can be placed (mapped) as VNFs on\ndifferent machines on the underlying physical infrastructure. Selecting good\ndecompositions and good placements among the possible options greatly affects\nboth costs and service quality metrics. Previous research has addressed NF\ndecomposition and VNF placement as separate problems. However, in this paper,\nwe address both NF decomposition and VNF placement simultaneously as a single\nproblem. Since finding an optimal solution is NP-hard, we have employed\nheuristic algorithms to solve the problem. Specifically, we have introduced a\nmultiobjective decomposition and mapping VNFs (MODMVNF) method based on the\nnon-dominated sorting genetic multi-objective algorithm (NSGAII) to solve the\nproblem. The goal is to find near-optimal decomposition and mapping on the\nphysical network at the same time to minimize the mapping cost and\ncommunication latency of SFC. The comparison of the results of the proposed\nmethod with the results obtained by solving ILP formulation of the problem as\nwell as the results obtained from the multi-objective particle swarm algorithm\nshows the efficiency and effectiveness of the proposed method in terms of cost\nand communication latency.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "90C29, 68M10",
      "C.2.1; C.2.4; I.2.8"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07606v1",
    "published_date": "2024-11-12 07:26:51 UTC",
    "updated_date": "2024-11-12 07:26:51 UTC"
  },
  {
    "arxiv_id": "2411.07602v2",
    "title": "Circuit Complexity Bounds for RoPE-based Transformer Architecture",
    "authors": [
      "Bo Chen",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Jiangxuan Long",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ncircuit complexity bound for Transformers with $\\mathsf{RoPE}$ attention. Our\nkey contribution is that we show that unless $\\mathsf{TC}^0 = \\mathsf{NC}^1$, a\n$\\mathsf{RoPE}$-based Transformer with $\\mathrm{poly}(n)$-precision, $O(1)$\nlayers, hidden dimension $d \\leq O(n)$ cannot solve the Arithmetic formula\nevaluation problem or the Boolean formula value problem. This result\nsignificantly demonstrates the fundamental limitation of the expressivity of\nthe $\\mathsf{RoPE}$-based Transformer architecture, although it achieves giant\nempirical success. Our theoretical result not only establishes the complexity\nbound but also may instruct further work on the $\\mathsf{RoPE}$-based\nTransformer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07602v2",
    "published_date": "2024-11-12 07:24:41 UTC",
    "updated_date": "2024-12-01 06:39:41 UTC"
  },
  {
    "arxiv_id": "2411.07598v1",
    "title": "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations",
    "authors": [
      "Rose E. Wang",
      "Pawan Wirawarn",
      "Kenny Lam",
      "Omar Khattab",
      "Dorottya Demszky"
    ],
    "abstract": "Many open-ended conversations (e.g., tutoring lessons or business meetings)\nrevolve around pre-defined reference materials, like worksheets or meeting\nbullets. To provide a framework for studying such conversation structure, we\nintroduce Problem-Oriented Segmentation & Retrieval (POSR), the task of jointly\nbreaking down conversations into segments and linking each segment to the\nrelevant reference item. As a case study, we apply POSR to education where\neffectively structuring lessons around problems is critical yet difficult. We\npresent LessonLink, the first dataset of real-world tutoring lessons, featuring\n3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT\nmath problems. We define and evaluate several joint and independent approaches\nfor POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT),\nand large language models (LLMs) methods. Our results highlight that modeling\nPOSR as one joint task is essential: POSR methods outperform independent\nsegmentation and retrieval pipelines by up to +76% on joint metrics and surpass\ntraditional segmentation methods by up to +78% on segmentation metrics. We\ndemonstrate POSR's practical impact on downstream education applications,\nderiving new insights on the language and time use in real-world lesson\nstructures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings. Our code and dataset are open-sourced at\n  https://github.com/rosewang2008/posr",
    "pdf_url": "http://arxiv.org/pdf/2411.07598v1",
    "published_date": "2024-11-12 07:16:51 UTC",
    "updated_date": "2024-11-12 07:16:51 UTC"
  },
  {
    "arxiv_id": "2411.07595v1",
    "title": "Entropy Controllable Direct Preference Optimization",
    "authors": [
      "Motoki Omura",
      "Yasuhiro Fujita",
      "Toshiki Kataoka"
    ],
    "abstract": "In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07595v1",
    "published_date": "2024-11-12 07:09:44 UTC",
    "updated_date": "2024-11-12 07:09:44 UTC"
  },
  {
    "arxiv_id": "2411.07589v1",
    "title": "Overhead-free User-side Recommender Systems",
    "authors": [
      "Ryoma Sato"
    ],
    "abstract": "Traditionally, recommendation algorithms have been designed for service\ndevelopers. But recently, a new paradigm called user-side recommender systems\nhas been proposed. User-side recommender systems are built and used by end\nusers, in sharp contrast to traditional provider-side recommender systems. Even\nif the official recommender system offered by the provider is not fair, end\nusers can create and enjoy their own user-side recommender systems by\nthemselves. Although the concept of user-side recommender systems is\nattractive, the problem is they require tremendous communication costs between\nthe user and the official system. Even the most efficient user-side recommender\nsystems require about 5 times more costs than provider-side recommender\nsystems. Such high costs hinder the adoption of user-side recommender systems.\nIn this paper, we propose overhead-free user-side recommender systems,\nRecCycle, which realizes user-side recommender systems without any\ncommunication overhead. The main idea of RecCycle is to recycle past\nrecommendation results offered by the provider's recommender systems. The\ningredients of RecCycle can be retrieved ``for free,'' and it greatly reduces\nthe cost of user-side recommendations. In the experiments, we confirm that\nRecCycle performs as well as state-of-the-art user-side recommendation\nalgorithms while RecCycle reduces costs significantly.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "comment": "arXiv admin note: text overlap with arXiv:2208.09864,\n  arXiv:2403.15757",
    "pdf_url": "http://arxiv.org/pdf/2411.07589v1",
    "published_date": "2024-11-12 06:58:03 UTC",
    "updated_date": "2024-11-12 06:58:03 UTC"
  },
  {
    "arxiv_id": "2411.07586v1",
    "title": "A Comprehensive Survey of AI-Driven Advancements and Techniques in Automated Program Repair and Code Generation",
    "authors": [
      "Avinash Anand",
      "Akshit Gupta",
      "Nishchay Yadav",
      "Shaurya Bajaj"
    ],
    "abstract": "Bug fixing and code generation have been core research topics in software\ndevelopment for many years. The recent explosive growth in Large Language\nModels has completely transformed these spaces, putting in reach incredibly\npowerful tools for both. In this survey, 27 recent papers have been reviewed\nand split into two groups: one dedicated to Automated Program Repair (APR) and\nLLM integration and the other to code generation using LLMs. The first group\nconsists of new methods for bug detection and repair, which include locating\nsemantic errors, security vulnerabilities, and runtime failure bugs. The place\nof LLMs in reducing manual debugging efforts is emphasized in this work by APR\ntoward context-aware fixes, with innovations that boost accuracy and efficiency\nin automatic debugging. The second group dwells on code generation, providing\nan overview of both general-purpose LLMs fine-tuned for programming and\ntask-specific models. It also presents methods to improve code generation, such\nas identifier-aware training, fine-tuning at the instruction level, and\nincorporating semantic code structures. This survey work contrasts the\nmethodologies in APR and code generation to identify trends such as using LLMs,\nfeedback loops to enable iterative code improvement and open-source models. It\nalso discusses the challenges of achieving functional correctness and security\nand outlines future directions for research in LLM-based software development.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "A survey of recent developments in AI-assisted automated program\n  repair",
    "pdf_url": "http://arxiv.org/pdf/2411.07586v1",
    "published_date": "2024-11-12 06:47:54 UTC",
    "updated_date": "2024-11-12 06:47:54 UTC"
  },
  {
    "arxiv_id": "2411.07585v1",
    "title": "Reinforcement Learning Framework for Quantitative Trading",
    "authors": [
      "Alhassan S. Yasin",
      "Prabdeep S. Gill"
    ],
    "abstract": "The inherent volatility and dynamic fluctuations within the financial stock\nmarket underscore the necessity for investors to employ a comprehensive and\nreliable approach that integrates risk management strategies, market trends,\nand the movement trends of individual securities. By evaluating specific data,\ninvestors can make more informed decisions. However, the current body of\nliterature lacks substantial evidence supporting the practical efficacy of\nreinforcement learning (RL) agents, as many models have only demonstrated\nsuccess in back testing using historical data. This highlights the urgent need\nfor a more advanced methodology capable of addressing these challenges. There\nis a significant disconnect in the effective utilization of financial\nindicators to better understand the potential market trends of individual\nsecurities. The disclosure of successful trading strategies is often restricted\nwithin financial markets, resulting in a scarcity of widely documented and\npublished strategies leveraging RL. Furthermore, current research frequently\noverlooks the identification of financial indicators correlated with various\nmarket trends and their potential advantages.\n  This research endeavors to address these complexities by enhancing the\nability of RL agents to effectively differentiate between positive and negative\nbuy/sell actions using financial indicators. While we do not address all\nconcerns, this paper provides deeper insights and commentary on the utilization\nof technical indicators and their benefits within reinforcement learning. This\nwork establishes a foundational framework for further exploration and\ninvestigation of more complex scenarios.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.TR",
    "comment": "8 pages, 9 figures, 3 tables, accepted at ICAIF 2024 FM4TS Workshop",
    "pdf_url": "http://arxiv.org/pdf/2411.07585v1",
    "published_date": "2024-11-12 06:44:28 UTC",
    "updated_date": "2024-11-12 06:44:28 UTC"
  },
  {
    "arxiv_id": "2411.07574v2",
    "title": "Disentangling Tabular Data Towards Better One-Class Anomaly Detection",
    "authors": [
      "Jianan Ye",
      "Zhaorui Tan",
      "Yijie Hu",
      "Xi Yang",
      "Guangliang Cheng",
      "Kaizhu Huang"
    ],
    "abstract": "Tabular anomaly detection under the one-class classification setting poses a\nsignificant challenge, as it involves accurately conceptualizing \"normal\"\nderived exclusively from a single category to discern anomalies from normal\ndata variations. Capturing the intrinsic correlation among attributes within\nnormal samples presents one promising method for learning the concept. To do\nso, the most recent effort relies on a learnable mask strategy with a\nreconstruction task. However, this wisdom may suffer from the risk of producing\nuniform masks, i.e., essentially nothing is masked, leading to less effective\ncorrelation learning. To address this issue, we presume that attributes related\nto others in normal samples can be divided into two non-overlapping and\ncorrelated subsets, defined as CorrSets, to capture the intrinsic correlation\neffectively. Accordingly, we introduce an innovative method that disentangles\nCorrSets from normal tabular data. To our knowledge, this is a pioneering\neffort to apply the concept of disentanglement for one-class anomaly detection\non tabular data. Extensive experiments on 20 tabular datasets show that our\nmethod substantially outperforms the state-of-the-art methods and leads to an\naverage performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC. Codes\nare available at https://github.com/yjnanan/Disent-AD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07574v2",
    "published_date": "2024-11-12 06:24:11 UTC",
    "updated_date": "2024-12-17 07:51:13 UTC"
  },
  {
    "arxiv_id": "2411.07563v1",
    "title": "Improving Grapheme-to-Phoneme Conversion through In-Context Knowledge Retrieval with Large Language Models",
    "authors": [
      "Dongrui Han",
      "Mingyu Cui",
      "Jiawen Kang",
      "Xixin Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "abstract": "Grapheme-to-phoneme (G2P) conversion is a crucial step in Text-to-Speech\n(TTS) systems, responsible for mapping grapheme to corresponding phonetic\nrepresentations. However, it faces ambiguities problems where the same grapheme\ncan represent multiple phonemes depending on contexts, posing a challenge for\nG2P conversion. Inspired by the remarkable success of Large Language Models\n(LLMs) in handling context-aware scenarios, contextual G2P conversion systems\nwith LLMs' in-context knowledge retrieval (ICKR) capabilities are proposed to\npromote disambiguation capability. The efficacy of incorporating ICKR into G2P\nconversion systems is demonstrated thoroughly on the Librig2p dataset. In\nparticular, the best contextual G2P conversion system using ICKR outperforms\nthe baseline with weighted average phoneme error rate (PER) reductions of 2.0%\nabsolute (28.9% relative). Using GPT-4 in the ICKR system can increase of 3.5%\nabsolute (3.8% relative) on the Librig2p dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted by ISCSLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07563v1",
    "published_date": "2024-11-12 05:38:43 UTC",
    "updated_date": "2024-11-12 05:38:43 UTC"
  },
  {
    "arxiv_id": "2411.07560v1",
    "title": "EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods",
    "authors": [
      "Xiangyu Shi",
      "Hongcheng Ding",
      "Salaar Faroog",
      "Deshinta Arrova Dewi",
      "Shamsul Nahar Abdullah",
      "Bahiah A Malek"
    ],
    "abstract": "This study introduces a novel approach for EUR/USD exchange rate forecasting\nthat integrates deep learning, textual analysis, and particle swarm\noptimization (PSO). By incorporating online news and analysis texts as\nqualitative data, the proposed PSO-LSTM model demonstrates superior performance\ncompared to traditional econometric and machine learning models. The research\nemploys advanced text mining techniques, including sentiment analysis using the\nRoBERTa-Large model and topic modeling with LDA. Empirical findings underscore\nthe significant advantage of incorporating textual data, with the PSO-LSTM\nmodel outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH.\nAblation experiments reveal the contribution of each textual data category to\nthe overall forecasting performance. The study highlights the transformative\npotential of artificial intelligence in finance and paves the way for future\nresearch in real-time forecasting and the integration of alternative data\nsources.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07560v1",
    "published_date": "2024-11-12 05:28:52 UTC",
    "updated_date": "2024-11-12 05:28:52 UTC"
  },
  {
    "arxiv_id": "2411.07559v1",
    "title": "Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for Black-box Multi-modal Large Language Models",
    "authors": [
      "Tiejin Chen",
      "Kaishen Wang",
      "Hua Wei"
    ],
    "abstract": "Jailbreaking methods, which induce Multi-modal Large Language Models (MLLMs)\nto output harmful responses, raise significant safety concerns. Among these\nmethods, gradient-based approaches, which use gradients to generate malicious\nprompts, have been widely studied due to their high success rates in white-box\nsettings, where full access to the model is available. However, these methods\nhave notable limitations: they require white-box access, which is not always\nfeasible, and involve high memory usage. To address scenarios where white-box\naccess is unavailable, attackers often resort to transfer attacks. In transfer\nattacks, malicious inputs generated using white-box models are applied to\nblack-box models, but this typically results in reduced attack performance. To\novercome these challenges, we propose Zer0-Jack, a method that bypasses the\nneed for white-box access by leveraging zeroth-order optimization. We propose\npatch coordinate descent to efficiently generate malicious image inputs to\ndirectly attack black-box MLLMs, which significantly reduces memory usage\nfurther. Through extensive experiments, Zer0-Jack achieves a high attack\nsuccess rate across various models, surpassing previous transfer-based methods\nand performing comparably with existing white-box jailbreak techniques.\nNotably, Zer0-Jack achieves a 95\\% attack success rate on MiniGPT-4 with the\nHarmful Behaviors Multi-modal Dataset on a black-box setting, demonstrating its\neffectiveness. Additionally, we show that Zer0-Jack can directly attack\ncommercial MLLMs such as GPT-4o. Codes are provided in the supplement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to Neurips SafeGenAi Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07559v1",
    "published_date": "2024-11-12 05:24:02 UTC",
    "updated_date": "2024-11-12 05:24:02 UTC"
  },
  {
    "arxiv_id": "2411.07546v2",
    "title": "Contrastive Language Prompting to Ease False Positives in Medical Anomaly Detection",
    "authors": [
      "YeongHyeon Park",
      "Myung Jin Kim",
      "Hyeong Seok Kim"
    ],
    "abstract": "A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.07546v2",
    "published_date": "2024-11-12 04:50:10 UTC",
    "updated_date": "2025-02-17 10:41:01 UTC"
  },
  {
    "arxiv_id": "2411.07536v1",
    "title": "Model Stealing for Any Low-Rank Language Model",
    "authors": [
      "Allen Liu",
      "Ankur Moitra"
    ],
    "abstract": "Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07536v1",
    "published_date": "2024-11-12 04:25:31 UTC",
    "updated_date": "2024-11-12 04:25:31 UTC"
  },
  {
    "arxiv_id": "2411.07529v1",
    "title": "Evaluating ChatGPT-3.5 Efficiency in Solving Coding Problems of Different Complexity Levels: An Empirical Analysis",
    "authors": [
      "Minda Li",
      "Bhaskar Krishnamachari"
    ],
    "abstract": "ChatGPT and other large language models (LLMs) promise to revolutionize\nsoftware development by automatically generating code from program\nspecifications. We assess the performance of ChatGPT's GPT-3.5-turbo model on\nLeetCode, a popular platform with algorithmic coding challenges for technical\ninterview practice, across three difficulty levels: easy, medium, and hard. We\ntest three main hypotheses. First, ChatGPT solves fewer problems as difficulty\nrises (Hypothesis 1). Second, prompt engineering improves ChatGPT's\nperformance, with greater gains on easier problems and diminishing returns on\nharder ones (Hypothesis 2). Third, ChatGPT performs better in popular languages\nlike Python, Java, and C++ than in less common ones like Elixir, Erlang, and\nRacket (Hypothesis 3). To investigate these hypotheses, we conduct automated\nexperiments using Python scripts to generate prompts that instruct ChatGPT to\ncreate Python solutions. These solutions are stored and manually submitted on\nLeetCode to check their correctness. For Hypothesis 1, results show the\nGPT-3.5-turbo model successfully solves 92% of easy, 79% of medium, and 51% of\nhard problems. For Hypothesis 2, prompt engineering yields improvements: 14-29%\nfor Chain of Thought Prompting, 38-60% by providing failed test cases in a\nsecond feedback prompt, and 33-58% by switching to GPT-4. From a random subset\nof problems ChatGPT solved in Python, it also solved 78% in Java, 50% in C++,\nand none in Elixir, Erlang, or Racket. These findings generally validate all\nthree hypotheses.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07529v1",
    "published_date": "2024-11-12 04:01:09 UTC",
    "updated_date": "2024-11-12 04:01:09 UTC"
  },
  {
    "arxiv_id": "2411.07528v1",
    "title": "SecEncoder: Logs are All You Need in Security",
    "authors": [
      "Muhammed Fatih Bulut",
      "Yingqi Liu",
      "Naveed Ahmad",
      "Maximilian Turner",
      "Sami Ait Ouahmane",
      "Cameron Andrews",
      "Lloyd Greenwald"
    ],
    "abstract": "Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07528v1",
    "published_date": "2024-11-12 03:56:07 UTC",
    "updated_date": "2024-11-12 03:56:07 UTC"
  },
  {
    "arxiv_id": "2411.07521v5",
    "title": "Fair Summarization: Bridging Quality and Diversity in Extractive Summaries",
    "authors": [
      "Sina Bagheri Nezhad",
      "Sayan Bandyapadhyay",
      "Ameeta Agrawal"
    ],
    "abstract": "Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. Our code\nis available online.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at AFLME@NeurIPS 2024 (non-archival) & C3NLP@NAACL 2025\n  (publication)",
    "pdf_url": "http://arxiv.org/pdf/2411.07521v5",
    "published_date": "2024-11-12 03:37:53 UTC",
    "updated_date": "2025-03-18 04:53:09 UTC"
  },
  {
    "arxiv_id": "2411.07519v1",
    "title": "TIPS: Threat Actor Informed Prioritization of Applications using SecEncoder",
    "authors": [
      "Muhammed Fatih Bulut",
      "Acar Tamersoy",
      "Naveed Ahmad",
      "Yingqi Liu",
      "Lloyd Greenwald"
    ],
    "abstract": "This paper introduces TIPS: Threat Actor Informed Prioritization using\nSecEncoder, a specialized language model for security. TIPS combines the\nstrengths of both encoder and decoder language models to detect and prioritize\ncompromised applications. By integrating threat actor intelligence, TIPS\nenhances the accuracy and relevance of its detections. Extensive experiments\nwith a real-world benchmark dataset of applications demonstrate TIPS's high\nefficacy, achieving an F-1 score of 0.90 in identifying malicious applications.\nAdditionally, in real-world scenarios, TIPS significantly reduces the backlog\nof investigations for security analysts by 87%, thereby streamlining the threat\nresponse process and improving overall security posture.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07519v1",
    "published_date": "2024-11-12 03:33:08 UTC",
    "updated_date": "2024-11-12 03:33:08 UTC"
  },
  {
    "arxiv_id": "2411.07518v1",
    "title": "LLM App Squatting and Cloning",
    "authors": [
      "Yinglin Xie",
      "Xinyi Hou",
      "Yanjie Zhao",
      "Kai Chen",
      "Haoyu Wang"
    ],
    "abstract": "Impersonation tactics, such as app squatting and app cloning, have posed\nlongstanding challenges in mobile app stores, where malicious actors exploit\nthe names and reputations of popular apps to deceive users. With the rapid\ngrowth of Large Language Model (LLM) stores like GPT Store and FlowGPT, these\nissues have similarly surfaced, threatening the integrity of the LLM app\necosystem. In this study, we present the first large-scale analysis of LLM app\nsquatting and cloning using our custom-built tool, LLMappCrazy. LLMappCrazy\ncovers 14 squatting generation techniques and integrates Levenshtein distance\nand BERT-based semantic analysis to detect cloning by analyzing app functional\nsimilarities. Using this tool, we generated variations of the top 1000 app\nnames and found over 5,000 squatting apps in the dataset. Additionally, we\nobserved 3,509 squatting apps and 9,575 cloning cases across six major\nplatforms. After sampling, we find that 18.7% of the squatting apps and 4.9% of\nthe cloning apps exhibited malicious behavior, including phishing, malware\ndistribution, fake content dissemination, and aggressive ad injection.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07518v1",
    "published_date": "2024-11-12 03:32:30 UTC",
    "updated_date": "2024-11-12 03:32:30 UTC"
  },
  {
    "arxiv_id": "2411.07510v1",
    "title": "An Attack Traffic Identification Method Based on Temporal Spectrum",
    "authors": [
      "Wenwei Xie",
      "Jie Yin",
      "Zihao Chen"
    ],
    "abstract": "To address the issues of insufficient robustness, unstable features, and data\nnoise interference in existing network attack detection and identification\nmodels, this paper proposes an attack traffic detection and identification\nmethod based on temporal spectrum. First, traffic data is segmented by a\nsliding window to construct a feature sequence and a corresponding label\nsequence for network traffic. Next, the proposed spectral label generation\nmethods, SSPE and COAP, are applied to transform the label sequence into\nspectral labels and the feature sequence into temporal features. Spectral\nlabels and temporal features are used to capture and represent behavioral\npatterns of attacks. Finally, the constructed temporal features and spectral\nlabels are used to train models, which subsequently detects and identifies\nnetwork attack behaviors. Experimental results demonstrate that compared to\ntraditional methods, models trained with the SSPE or COAP method improve\nidentification accuracy by 10%, and exhibit strong robustness, particularly in\nnoisy environments.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 7 figures, 7 tables, 8 formulas",
    "pdf_url": "http://arxiv.org/pdf/2411.07510v1",
    "published_date": "2024-11-12 03:09:14 UTC",
    "updated_date": "2024-11-12 03:09:14 UTC"
  },
  {
    "arxiv_id": "2411.07506v3",
    "title": "FlowTS: Time Series Generation via Rectified Flow",
    "authors": [
      "Yang Hu",
      "Xiao Wang",
      "Zezhen Ding",
      "Lirong Wu",
      "Huatian Zhang",
      "Stan Z. Li",
      "Sheng Wang",
      "Jiheng Zhang",
      "Ziyun Li",
      "Tianlong Chen"
    ],
    "abstract": "Diffusion-based models have significant achievements in time series\ngeneration but suffer from inefficient computation: solving high-dimensional\nODEs/SDEs via iterative numerical solvers demands hundreds to thousands of\ndrift function evaluations per sample, incurring prohibitive costs. To resolve\nthis, we propose FlowTS, an ODE-based model that leverages rectified flow with\nstraight-line transport in probability space. By learning geodesic paths\nbetween distributions, FlowTS achieves computational efficiency through exact\nlinear trajectory simulation, accelerating training and generation while\nimproving performances. We further introduce an adaptive sampling strategy\ninspired by the exploration-exploitation trade-off, balancing noise adaptation\nand precision. Notably, FlowTS enables seamless adaptation from unconditional\nto conditional generation without retraining, ensuring efficient real-world\ndeployment. Also, to enhance generation authenticity, FlowTS integrates trend\nand seasonality decomposition, attention registers (for global context\naggregation), and Rotary Position Embedding (RoPE) (for position information).\nFor unconditional setting, extensive experiments demonstrate that FlowTS\nachieves state-of-the-art performance, with context FID scores of 0.019 and\n0.011 on Stock and ETTh datasets (prev. best: 0.067, 0.061). For conditional\nsetting, we have achieved superior performance in solar forecasting (MSE 213,\nprev. best: 375) and MuJoCo imputation tasks (MSE 7e-5, prev. best 2.7e-4). The\ncode is available at https://github.com/UNITES-Lab/FlowTS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07506v3",
    "published_date": "2024-11-12 03:03:23 UTC",
    "updated_date": "2025-02-08 14:19:45 UTC"
  },
  {
    "arxiv_id": "2411.07501v3",
    "title": "LAuReL: Learned Augmented Residual Layer",
    "authors": [
      "Gaurav Menghani",
      "Ravi Kumar",
      "Sanjiv Kumar"
    ],
    "abstract": "One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07501v3",
    "published_date": "2024-11-12 02:57:15 UTC",
    "updated_date": "2025-02-05 00:27:21 UTC"
  },
  {
    "arxiv_id": "2411.07482v3",
    "title": "Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling",
    "authors": [
      "Jinming Xing",
      "Ruilin Xing",
      "Chang Xue",
      "Dongwen Luo"
    ],
    "abstract": "Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ISMSI'25",
    "pdf_url": "http://arxiv.org/pdf/2411.07482v3",
    "published_date": "2024-11-12 02:08:19 UTC",
    "updated_date": "2025-02-01 22:42:03 UTC"
  },
  {
    "arxiv_id": "2411.07466v2",
    "title": "IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark for LLMs",
    "authors": [
      "Kawshik Manikantan",
      "Makarand Tapaswi",
      "Vineet Gandhi",
      "Shubham Toshniwal"
    ],
    "abstract": "Recent evaluations of LLMs on coreference resolution have revealed that\ntraditional output formats and evaluation metrics do not fully capture the\nmodels' referential understanding. To address this, we introduce IdentifyMe, a\nnew benchmark for mention resolution presented in a multiple-choice question\n(MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long\nnarratives and employs heuristics to exclude easily identifiable mentions,\ncreating a more challenging task. The benchmark also consists of a curated\nmixture of different mention types and corresponding entities, allowing for a\nfine-grained analysis of model performance. We evaluate both closed- and open\nsource LLMs on IdentifyMe and observe a significant performance gap (20-30%)\nbetween the state-of-the-art sub-10B open models vs. closed ones. We observe\nthat pronominal mentions, which have limited surface information, are typically\nmuch harder for models to resolve than nominal mentions. Additionally, we find\nthat LLMs often confuse entities when their mentions overlap in nested\nstructures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy,\nhighlighting the strong referential capabilities of state-of-the-art LLMs while\nalso indicating room for further improvement.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07466v2",
    "published_date": "2024-11-12 01:05:55 UTC",
    "updated_date": "2025-04-16 19:20:42 UTC"
  },
  {
    "arxiv_id": "2411.07464v2",
    "title": "BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating Machine Learning Tasks",
    "authors": [
      "Shubham Gandhi",
      "Manasi Patwardhan",
      "Lovekesh Vig",
      "Gautam Shroff"
    ],
    "abstract": "Large Language Models (LLMs) excel in diverse applications including\ngeneration of code snippets, but often struggle with generating code for\ncomplex Machine Learning (ML) tasks. Although existing LLM single-agent based\nsystems give varying performance depending on the task complexity, they purely\nrely on larger and expensive models such as GPT-4. Our investigation reveals\nthat no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama\nperform far worse than GPT-4 in a single-agent setting. With the motivation of\ndeveloping a cost-efficient LLM based solution for solving ML tasks, we propose\nan LLM Multi-Agent based system which leverages combination of experts using\nprofiling, efficient retrieval of past observations, LLM cascades, and\nask-the-expert calls. Through empirical analysis on ML engineering tasks in the\nMLAgentBench benchmark, we demonstrate the effectiveness of our system, using\nno-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and\nexpert to serve occasional ask-the-expert calls for planning. With 94.2\\%\nreduction in the cost (from \\$0.931 per run cost averaged over all tasks for\nGPT-4 single agent system to \\$0.054), our system is able to yield better\naverage success rate of 32.95\\% as compared to GPT-4 single-agent system\nyielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "68T42",
      "I.2.1; I.2.2; I.2.5; I.2.7; I.2.8"
    ],
    "primary_category": "cs.MA",
    "comment": "Presented at AIMLSystems '24",
    "pdf_url": "http://arxiv.org/pdf/2411.07464v2",
    "published_date": "2024-11-12 00:57:30 UTC",
    "updated_date": "2025-01-08 07:25:55 UTC"
  },
  {
    "arxiv_id": "2411.07461v1",
    "title": "BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions",
    "authors": [
      "Anas Awadalla",
      "Le Xue",
      "Manli Shu",
      "An Yan",
      "Jun Wang",
      "Senthil Purushwalkam",
      "Sheng Shen",
      "Hannah Lee",
      "Oscar Lo",
      "Jae Sung Park",
      "Etash Guha",
      "Silvio Savarese",
      "Ludwig Schmidt",
      "Yejin Choi",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "abstract": "We introduce BLIP3-KALE, a dataset of 218 million image-text pairs that\nbridges the gap between descriptive synthetic captions and factual web-scale\nalt-text. KALE augments synthetic dense image captions with web-scale alt-text\nto generate factually grounded image captions. Our two-stage approach leverages\nlarge vision-language models and language models to create knowledge-augmented\ncaptions, which are then used to train a specialized VLM for scaling up the\ndataset. We train vision-language models on KALE and demonstrate improvements\non vision-language tasks. Our experiments show the utility of KALE for training\nmore capable and knowledgeable multimodal models. We release the KALE dataset\nat https://huggingface.co/datasets/Salesforce/blip3-kale",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07461v1",
    "published_date": "2024-11-12 00:52:52 UTC",
    "updated_date": "2024-11-12 00:52:52 UTC"
  },
  {
    "arxiv_id": "2411.07453v1",
    "title": "Research on fault diagnosis of nuclear power first-second circuit based on hierarchical multi-granularity classification network",
    "authors": [
      "Jiangwen Chen",
      "Siwei Li",
      "Guo Jiang",
      "Cheng Dongzhen",
      "Lin Hua",
      "Wang Wei"
    ],
    "abstract": "The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07453v1",
    "published_date": "2024-11-12 00:38:17 UTC",
    "updated_date": "2024-11-12 00:38:17 UTC"
  },
  {
    "arxiv_id": "2411.07451v1",
    "title": "Optimizing Data Delivery: Insights from User Preferences on Visuals, Tables, and Text",
    "authors": [
      "Reuben Luera",
      "Ryan Rossi",
      "Franck Dernoncourt",
      "Alexa Siu",
      "Sungchul Kim",
      "Tong Yu",
      "Ruiyi Zhang",
      "Xiang Chen",
      "Nedim Lipka",
      "Zhehao Zhang",
      "Seon Gyeom Kim",
      "Tak Yeon Lee"
    ],
    "abstract": "In this work, we research user preferences to see a chart, table, or text\ngiven a question asked by the user. This enables us to understand when it is\nbest to show a chart, table, or text to the user for the specific question. For\nthis, we conduct a user study where users are shown a question and asked what\nthey would prefer to see and used the data to establish that a user's personal\ntraits does influence the data outputs that they prefer. Understanding how user\ncharacteristics impact a user's preferences is critical to creating data tools\nwith a better user experience. Additionally, we investigate to what degree an\nLLM can be used to replicate a user's preference with and without user\npreference data. Overall, these findings have significant implications\npertaining to the development of data tools and the replication of human\npreferences using LLMs. Furthermore, this work demonstrates the potential use\nof LLMs to replicate user preference data which has major implications for\nfuture user modeling and personalization research.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07451v1",
    "published_date": "2024-11-12 00:24:31 UTC",
    "updated_date": "2024-11-12 00:24:31 UTC"
  },
  {
    "arxiv_id": "2411.07447v3",
    "title": "Optimizing LLM Inference for Database Systems: Cost-Aware Scheduling for Concurrent Requests",
    "authors": [
      "Kyoungmin Kim",
      "Kijae Hong",
      "Caglar Gulcehre",
      "Anastasia Ailamaki"
    ],
    "abstract": "LLMs are increasingly used inside database systems and in database\napplications for better complexity management and decision-making, where LLM\ninferences require significant GPU costs. LLM inference systems, however, are\nslow compared to database systems, limiting the expansion of the use of LLMs\ninside database systems. This paper first analyzes the LLM inference\nperformance and focuses on a data management issue in LLM inference. We reveal\nthat the root of the problem is the lack of an adequate resource cost model and\noptimization strategy when executing multiple concurrent inference requests. We\nadapt classic database multi-query optimization techniques by introducing cost\nmodels for concurrent inference requests and new scheduling strategies to\noptimize the use of memory resources by concurrent requests, thereby\nsubstantially improving performance.",
    "categories": [
      "cs.PF",
      "cs.AI"
    ],
    "primary_category": "cs.PF",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07447v3",
    "published_date": "2024-11-12 00:10:34 UTC",
    "updated_date": "2025-04-16 16:58:32 UTC"
  },
  {
    "arxiv_id": "2411.07444v1",
    "title": "Input-Based Ensemble-Learning Method for Dynamic Memory Configuration of Serverless Computing Functions",
    "authors": [
      "Siddharth Agarwal",
      "Maria A. Rodriguez",
      "Rajkumar Buyya"
    ],
    "abstract": "In today's Function-as-a-Service offerings, a programmer is usually\nresponsible for configuring function memory for its successful execution, which\nallocates proportional function resources such as CPU and network. However,\nright-sizing the function memory force developers to speculate performance and\nmake ad-hoc configuration decisions. Recent research has highlighted that a\nfunction's input characteristics, such as input size, type and number of\ninputs, significantly impact its resource demand, run-time performance and\ncosts with fluctuating workloads. This correlation further makes memory\nconfiguration a non-trivial task. On that account, an input-aware function\nmemory allocator not only improves developer productivity by completely hiding\nresource-related decisions but also drives an opportunity to reduce resource\nwastage and offer a finer-grained cost-optimised pricing scheme. Therefore, we\npresent MemFigLess, a serverless solution that estimates the memory requirement\nof a serverless function with input-awareness. The framework executes function\nprofiling in an offline stage and trains a multi-output Random Forest\nRegression model on the collected metrics to invoke input-aware optimal\nconfigurations. We evaluate our work with the state-of-the-art approaches on\nAWS Lambda service to find that MemFigLess is able to capture the input-aware\nresource relationships and allocate upto 82% less resources and save up to 87%\nrun-time costs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.DC",
    "comment": "10 pages, 2 tables, 28 figures, accepted conference paper - UCC'24",
    "pdf_url": "http://arxiv.org/pdf/2411.07444v1",
    "published_date": "2024-11-12 00:03:11 UTC",
    "updated_date": "2024-11-12 00:03:11 UTC"
  }
]